URL: http://www.cse.ogi.edu/Sparse/paper/kolte.pldi.95.ps
Refering-URL: http://www.cse.ogi.edu/Sparse/sparse.range.html
Root-URL: http://www.cse.ogi.edu
Email: mwolfeg@cse.ogi.edu  
Title: Elimination of Redundant Array Subscript Range Checks  
Author: Priyadarshan Kolte and Michael Wolfe 
Address: fpkolte,  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Abstract: This paper presents a compiler optimization algorithm to reduce the run time overhead of array subscript range checks in programs without compromising safety. The algorithm is based on partial redundancy elimination and it incorporates previously developed algorithms for range check optimization. We implemented the algorithm in our research compiler, Nascent, and conducted experiments on a suite of 10 benchmark programs to obtain four results: (1) the execution overhead of naive range checking is high enough to merit optimization, (2) there are substantial differences between various optimizations, (3) loop-based optimizations that hoist checks out of loops are effective in eliminating about 98% of the range checks, and (4) more sophisticated analysis and optimization algorithms produce very marginal benefits. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, R. Sethi, and J. D. Ullman. </author> <booktitle> Compilers, Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: S 2 : A [2flN-1] = 1 ... (a) Without any optimization (b) With some optimization (c) With more optimization 2 Background and notation We assume that the reader is familiar with the control flow graph (CFG) abstraction of programs, natural loops, data flow analysis <ref> [1] </ref>, and the Static Single Assignment (SSA) representation of programs [6]. 2.1 Partial redundancy elimination Partial redundancy elimination (PRE) eliminates redundant computation of expressions in programs by moving invariant computations out of loops and also eliminating identical computations that are performed more than once on any execution path.
Reference: [2] <author> J. M. Asuru. </author> <title> Optimization of array subscript range checks. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> vol. 1, no. 2, </volume> <pages> 109-118, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The resulting program has only two range checks and is shown in Figure 1 (c). Researchers have studied range check optimization as applications of automated program verification [8, 17], abstract interpretation [4, 5, 11], and data flow analysis <ref> [2, 9, 10] </ref>. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks <ref> [2, 9, 10, 13] </ref>. Our algorithms are in the second group. Suzuki and Ishihata [17] and German [8] used Floyd-Hoare logics and theorem proving techniques to verify the absence of array range violations in programs. <p> In contrast to Gupta's rules for determining whether loop-limit substitution is applicable to a check within a loop, we use induction expressions and induction type classifications (invariant and linear) produced by Nascent. Our experimental results match the limited results presented by Gupta. Asuru <ref> [2] </ref> also extends Gupta's range check optimization algorithms. Our loop-limit substitution technique is similar to his conservative expression substitution algorithm. His technique of loop guard elimination is a restricted form for exploiting implications between conditional checks in the check implication graph.
Reference: [3] <author> P. Briggs and K. D. Cooper. </author> <title> Effective partial redundancy elimination. </title> <booktitle> Proceedings of the ACM SIGPLAN '94 Conference on Programming Language Design and Implementation, </booktitle> <pages> 159-170, </pages> <month> June, </month> <year> 1994. </year>
Reference-contexts: k 1 + m k 2 5flh+8 Linear A [k] = 2 fl m + 1 A [k 2 ] = 2 fl m + 1 2 fl m + 1 11 Invariant endfor endfor of range checks is similar to the global reassociation technique described by Briggs and Cooper <ref> [3] </ref>. The canonical form also simplifies the representation and manipulation of range checks within the compiler.
Reference: [4] <author> P. Cousot and R. Cousot. </author> <title> Abstract interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints. </title> <booktitle> Conference Record of the 4 th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> 238-252, </pages> <month> January, </month> <year> 1977. </year>
Reference-contexts: The resulting program has only two range checks and is shown in Figure 1 (c). Researchers have studied range check optimization as applications of automated program verification [8, 17], abstract interpretation <ref> [4, 5, 11] </ref>, and data flow analysis [2, 9, 10]. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> The first group concentrates on the problem of identifying range checks which can be evaluated at compile-time and eliminated from the program; this includes the automated program verification approach [8, 17] and the abstract interpretation approach <ref> [4, 5, 11, 14, 16] </ref>. The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. Our algorithms are in the second group. <p> Hence, we feel that this approach is not directly applicable to the problem of automatic range check optimization of arbitrary programs. The abstract interpretation algorithms <ref> [4, 5, 11, 14, 16] </ref> perform generation, propagation, and combination of assertions about the bounds of variables to determine compile-time checks.
Reference: [5] <author> P. Cousot and N. Halbwachs. </author> <title> Automatic discovery of linear restraints among variables of a program. </title> <booktitle> Conference Record of the 5 th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> 84-96, </pages> <month> January, </month> <year> 1978. </year>
Reference-contexts: The resulting program has only two range checks and is shown in Figure 1 (c). Researchers have studied range check optimization as applications of automated program verification [8, 17], abstract interpretation <ref> [4, 5, 11] </ref>, and data flow analysis [2, 9, 10]. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> The first group concentrates on the problem of identifying range checks which can be evaluated at compile-time and eliminated from the program; this includes the automated program verification approach [8, 17] and the abstract interpretation approach <ref> [4, 5, 11, 14, 16] </ref>. The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. Our algorithms are in the second group. <p> Hence, we feel that this approach is not directly applicable to the problem of automatic range check optimization of arbitrary programs. The abstract interpretation algorithms <ref> [4, 5, 11, 14, 16] </ref> perform generation, propagation, and combination of assertions about the bounds of variables to determine compile-time checks. <p> The different algorithms vary in the sophistication of the rules used for propagation and combination of the assertions: the rules implemented in the Karlsruhe Ada compiler [16] seem the simplest (and probably are the fastest) and those proposed by Cousot and Halbwachs <ref> [5] </ref> are quite complex.
Reference: [6] <author> R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman and F. K. Zadeck. </author> <title> Efficiently computing static single assignment form and the control dependence graph. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> vol. 13, no. 4, </volume> <pages> pp. 451-490, </pages> <month> October, </month> <year> 1991. </year>
Reference-contexts: = 1 ... (a) Without any optimization (b) With some optimization (c) With more optimization 2 Background and notation We assume that the reader is familiar with the control flow graph (CFG) abstraction of programs, natural loops, data flow analysis [1], and the Static Single Assignment (SSA) representation of programs <ref> [6] </ref>. 2.1 Partial redundancy elimination Partial redundancy elimination (PRE) eliminates redundant computation of expressions in programs by moving invariant computations out of loops and also eliminating identical computations that are performed more than once on any execution path.
Reference: [7] <author> M. P. Gerlek, E. Stoltz, and M. Wolfe. </author> <title> Beyond induction variables: Detecting and classifying sequences using a demand-driven SSA form. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <note> to appear. </note>
Reference-contexts: This project builds on previous work, especially on the algorithms presented by Gupta [9, 10]; our main contributions are: * use of partial redundancy elimination techniques [15, 12] for range check optimization; * a study of the advantages of using induction variables <ref> [7, 18] </ref> in range check optimization; * an implementation of a range check optimizer in our research Fortran compiler, Nascent; and * an experimental evaluation of the compile time cost and effectiveness of various optimizations on a suite of large programs. <p> We use the canonical form to denote range check statements in the rest of the paper. 2.3 Range checks using induction expressions The Nascent compiler uses SSA-based induction variable analysis techniques to associate induction expressions with all expressions in a program <ref> [7, 18] </ref>. Each loop in the program is assigned a basic loop variable which assumes values 0,1,: : : for every loop iteration; each expression in the loop is associated with an induction expression which is a function of the basic loop variable. <p> For our suite of test programs, we chose 10 scientific programs from the Perfect, Riceps, and Mendez benchmarks because these are known to contain substantial array-based computation <ref> [7] </ref>. The particular 10 programs chosen for this study satisfied two criteria: (1) the C back-end of Nascent is not mature and these programs required no manual editing to "fix" the C programs, and (2) they had moderate disk space and computation time requirements.
Reference: [8] <author> S. M. </author> <title> German. Automating proofs of the absence of common runtime errors. </title> <booktitle> Conference Record of the 5 th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> 105-118, </pages> <month> January, </month> <year> 1978. </year>
Reference-contexts: The resulting program has only two range checks and is shown in Figure 1 (c). Researchers have studied range check optimization as applications of automated program verification <ref> [8, 17] </ref>, abstract interpretation [4, 5, 11], and data flow analysis [2, 9, 10]. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> The first group concentrates on the problem of identifying range checks which can be evaluated at compile-time and eliminated from the program; this includes the automated program verification approach <ref> [8, 17] </ref> and the abstract interpretation approach [4, 5, 11, 14, 16]. The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. <p> The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. Our algorithms are in the second group. Suzuki and Ishihata [17] and German <ref> [8] </ref> used Floyd-Hoare logics and theorem proving techniques to verify the absence of array range violations in programs.
Reference: [9] <author> R. Gupta. </author> <title> A fresh look at optimizing array bound checking. </title> <booktitle> Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> 272-282, </pages> <month> June, </month> <year> 1990. </year>
Reference-contexts: The resulting program has only two range checks and is shown in Figure 1 (c). Researchers have studied range check optimization as applications of automated program verification [8, 17], abstract interpretation [4, 5, 11], and data flow analysis <ref> [2, 9, 10] </ref>. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. This project builds on previous work, especially on the algorithms presented by Gupta <ref> [9, 10] </ref>; our main contributions are: * use of partial redundancy elimination techniques [15, 12] for range check optimization; * a study of the advantages of using induction variables [7, 18] in range check optimization; * an implementation of a range check optimizer in our research Fortran compiler, Nascent; and * <p> For example, the transformation of the program in Figure 5 (a) to that in 5 (c) increases the number of checks performed on the path along the else branch. Check-strengthening, which was proposed by Gupta <ref> [9, 10] </ref>, considers program points just before range checks in the CFG for inserting new checks. <p> The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks <ref> [2, 9, 10, 13] </ref>. Our algorithms are in the second group. Suzuki and Ishihata [17] and German [8] used Floyd-Hoare logics and theorem proving techniques to verify the absence of array range violations in programs. <p> More recent approaches <ref> [9, 10] </ref> and our algo rithms handle checks with more complex range expressions and use data flow analysis to relax the restriction about checks in articulation nodes. <p> The range check optimization algorithm presented in this paper is based on work by Gupta <ref> [9, 10] </ref>. We use a partial redundancy elimination framework to implement the data flow analysis and optimizations described by Gupta. It is not clear how Gupta represents implications between checks in the compiler; we have proposed check implication graphs to denote and manipulate implications between checks.
Reference: [10] <author> R. Gupta. </author> <title> Optimizing array bound checks using flow analysis. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> vol. 2, </volume> <pages> nos. 1-4, 135-150, </pages> <address> March-December, </address> <year> 1993. </year>
Reference-contexts: The resulting program has only two range checks and is shown in Figure 1 (c). Researchers have studied range check optimization as applications of automated program verification [8, 17], abstract interpretation [4, 5, 11], and data flow analysis <ref> [2, 9, 10] </ref>. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. This project builds on previous work, especially on the algorithms presented by Gupta <ref> [9, 10] </ref>; our main contributions are: * use of partial redundancy elimination techniques [15, 12] for range check optimization; * a study of the advantages of using induction variables [7, 18] in range check optimization; * an implementation of a range check optimizer in our research Fortran compiler, Nascent; and * <p> For example, the transformation of the program in Figure 5 (a) to that in 5 (c) increases the number of checks performed on the path along the else branch. Check-strengthening, which was proposed by Gupta <ref> [9, 10] </ref>, considers program points just before range checks in the CFG for inserting new checks. <p> The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks <ref> [2, 9, 10, 13] </ref>. Our algorithms are in the second group. Suzuki and Ishihata [17] and German [8] used Floyd-Hoare logics and theorem proving techniques to verify the absence of array range violations in programs. <p> More recent approaches <ref> [9, 10] </ref> and our algo rithms handle checks with more complex range expressions and use data flow analysis to relax the restriction about checks in articulation nodes. <p> The range check optimization algorithm presented in this paper is based on work by Gupta <ref> [9, 10] </ref>. We use a partial redundancy elimination framework to implement the data flow analysis and optimizations described by Gupta. It is not clear how Gupta represents implications between checks in the compiler; we have proposed check implication graphs to denote and manipulate implications between checks.
Reference: [11] <author> W. H. Harrison. </author> <title> Compiler analysis for the value ranges for variables. </title> <journal> IEEE Transactions on Software Engineering, SE-3, </journal> <volume> 3, </volume> <pages> 243-250, </pages> <month> May, </month> <year> 1977. </year>
Reference-contexts: The resulting program has only two range checks and is shown in Figure 1 (c). Researchers have studied range check optimization as applications of automated program verification [8, 17], abstract interpretation <ref> [4, 5, 11] </ref>, and data flow analysis [2, 9, 10]. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> The first group concentrates on the problem of identifying range checks which can be evaluated at compile-time and eliminated from the program; this includes the automated program verification approach [8, 17] and the abstract interpretation approach <ref> [4, 5, 11, 14, 16] </ref>. The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. Our algorithms are in the second group. <p> Hence, we feel that this approach is not directly applicable to the problem of automatic range check optimization of arbitrary programs. The abstract interpretation algorithms <ref> [4, 5, 11, 14, 16] </ref> perform generation, propagation, and combination of assertions about the bounds of variables to determine compile-time checks.
Reference: [12] <author> J. Knoop, O. Ruthing, and B. Steffen. </author> <title> Lazy code motion. </title> <booktitle> Proceedings of the ACM SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> 224-234, </pages> <month> June, </month> <year> 1992. </year>
Reference-contexts: This project builds on previous work, especially on the algorithms presented by Gupta [9, 10]; our main contributions are: * use of partial redundancy elimination techniques <ref> [15, 12] </ref> for range check optimization; * a study of the advantages of using induction variables [7, 18] in range check optimization; * an implementation of a range check optimizer in our research Fortran compiler, Nascent; and * an experimental evaluation of the compile time cost and effectiveness of various optimizations <p> Although we use terms defined by Morel and Renvoise [15] in this paper, our implementation of PRE uses the safe-earliest and latest-not-isolated transformations developed by Knoop, Ruthing, and Steffen <ref> [12] </ref> because these transformations are conceptually simpler and more efficient than the techniques originally proposed by Morel and Ren-voise. The general strategy of PRE transformations of programs is as follows. 1. Identify sets of equivalent expressions. Expressions in the program are partitioned into equivalence classes. <p> The only redundant checks are due to availability and compile-time constants (in steps 4 and 5). The safe-earliest and latest-not-isolated transformations, developed by Knoop et al. for PRE of arithmetic expressions <ref> [12] </ref>, can be applied to the problem of range check placement if the anticipatable and available checks are computed as described in the previous subsection.
Reference: [13] <author> V. Markstein, J. Cocke, and P. Markstein. </author> <title> Optimization of range checking. </title> <booktitle> Proceedings of the SIGPLAN '82 Symposium on Compiler Construction, </booktitle> <pages> 114-119, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: Researchers have studied range check optimization as applications of automated program verification [8, 17], abstract interpretation [4, 5, 11], and data flow analysis [2, 9, 10]. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler <ref> [13] </ref>, the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks <ref> [2, 9, 10, 13] </ref>. Our algorithms are in the second group. Suzuki and Ishihata [17] and German [8] used Floyd-Hoare logics and theorem proving techniques to verify the absence of array range violations in programs. <p> Perhaps these compilers are conservative due to the Ada language requirement that the compiler is not permitted to move a computation to a program point which might change the exception handler that is invoked in case an exception occurs in the computation. Markstein, Cocke, and Markstein <ref> [13] </ref> presented the first paper that addresses the problem of reducing the execution overhead of range-checks.
Reference: [14] <author> E. Morel. </author> <title> Data flow analysis and global optimization. in Methods and tools for compiler construction, </title> <editor> B. Lorho (ed.), </editor> <publisher> Cambridge University Press, </publisher> <address> New York, 289-315, </address> <year> 1984. </year>
Reference-contexts: Researchers have studied range check optimization as applications of automated program verification [8, 17], abstract interpretation [4, 5, 11], and data flow analysis [2, 9, 10]. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler <ref> [14] </ref>, and the Karlsruhe Ada compiler [16]. <p> The first group concentrates on the problem of identifying range checks which can be evaluated at compile-time and eliminated from the program; this includes the automated program verification approach [8, 17] and the abstract interpretation approach <ref> [4, 5, 11, 14, 16] </ref>. The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. Our algorithms are in the second group. <p> Hence, we feel that this approach is not directly applicable to the problem of automatic range check optimization of arbitrary programs. The abstract interpretation algorithms <ref> [4, 5, 11, 14, 16] </ref> perform generation, propagation, and combination of assertions about the bounds of variables to determine compile-time checks. <p> Hence we expect the number of checks eliminated by these algorithms to be less than algorithms which insert checks. It seems curious that both the implementations of Ada compilers <ref> [14, 16] </ref> use partial redundancy elimination for the optimization of most program expressions, but not for optimizing range checks.
Reference: [15] <author> E. Morel and C. </author> <title> Renvoise. Global optimization by suppression of partial redundancies. </title> <journal> Communications of the ACM, </journal> <volume> vol. 2, no. 2, </volume> <pages> 96-103, </pages> <month> February, </month> <year> 1979. </year>
Reference-contexts: This project builds on previous work, especially on the algorithms presented by Gupta [9, 10]; our main contributions are: * use of partial redundancy elimination techniques <ref> [15, 12] </ref> for range check optimization; * a study of the advantages of using induction variables [7, 18] in range check optimization; * an implementation of a range check optimizer in our research Fortran compiler, Nascent; and * an experimental evaluation of the compile time cost and effectiveness of various optimizations <p> Although we use terms defined by Morel and Renvoise <ref> [15] </ref> in this paper, our implementation of PRE uses the safe-earliest and latest-not-isolated transformations developed by Knoop, Ruthing, and Steffen [12] because these transformations are conceptually simpler and more efficient than the techniques originally proposed by Morel and Ren-voise.
Reference: [16] <author> B. Schwarz, W. Kirchgassner, and R. Landwehr. </author> <title> An optimizer for Ada design, experiences and results. </title> <booktitle> Proceedings SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> 175-185, </pages> <month> June, </month> <year> 1988. </year>
Reference-contexts: Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler <ref> [16] </ref>. <p> The first group concentrates on the problem of identifying range checks which can be evaluated at compile-time and eliminated from the program; this includes the automated program verification approach [8, 17] and the abstract interpretation approach <ref> [4, 5, 11, 14, 16] </ref>. The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. Our algorithms are in the second group. <p> Hence, we feel that this approach is not directly applicable to the problem of automatic range check optimization of arbitrary programs. The abstract interpretation algorithms <ref> [4, 5, 11, 14, 16] </ref> perform generation, propagation, and combination of assertions about the bounds of variables to determine compile-time checks. <p> The different algorithms vary in the sophistication of the rules used for propagation and combination of the assertions: the rules implemented in the Karlsruhe Ada compiler <ref> [16] </ref> seem the simplest (and probably are the fastest) and those proposed by Cousot and Halbwachs [5] are quite complex. <p> Hence we expect the number of checks eliminated by these algorithms to be less than algorithms which insert checks. It seems curious that both the implementations of Ada compilers <ref> [14, 16] </ref> use partial redundancy elimination for the optimization of most program expressions, but not for optimizing range checks.
Reference: [17] <author> N. Suzuki and K. Ishihata. </author> <title> Implementation of an array bound checker. </title> <booktitle> Conference Record of the 4 th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> 132-143, </pages> <month> January, </month> <year> 1977. </year>
Reference-contexts: The resulting program has only two range checks and is shown in Figure 1 (c). Researchers have studied range check optimization as applications of automated program verification <ref> [8, 17] </ref>, abstract interpretation [4, 5, 11], and data flow analysis [2, 9, 10]. Range check optimizers have also been implemented in several compilers such as the IBM PL.8 compiler [13], the Alsys Ada compiler [14], and the Karlsruhe Ada compiler [16]. <p> The first group concentrates on the problem of identifying range checks which can be evaluated at compile-time and eliminated from the program; this includes the automated program verification approach <ref> [8, 17] </ref> and the abstract interpretation approach [4, 5, 11, 14, 16]. The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. <p> The second group aims to reduce the execution overhead of range checks which cannot be evaluated and eliminated at compile-time; this includes algorithms that perform data flow analysis and insertion of checks [2, 9, 10, 13]. Our algorithms are in the second group. Suzuki and Ishihata <ref> [17] </ref> and German [8] used Floyd-Hoare logics and theorem proving techniques to verify the absence of array range violations in programs.
Reference: [18] <author> M. Wolfe. </author> <title> Beyond induction variables. </title> <booktitle> Proceedings of the ACM SIGPLAN '92 Conference on Programming Language Design and Implementation, </booktitle> <pages> 162-174, </pages> <month> June, </month> <year> 1992. </year>
Reference-contexts: This project builds on previous work, especially on the algorithms presented by Gupta [9, 10]; our main contributions are: * use of partial redundancy elimination techniques [15, 12] for range check optimization; * a study of the advantages of using induction variables <ref> [7, 18] </ref> in range check optimization; * an implementation of a range check optimizer in our research Fortran compiler, Nascent; and * an experimental evaluation of the compile time cost and effectiveness of various optimizations on a suite of large programs. <p> We use the canonical form to denote range check statements in the rest of the paper. 2.3 Range checks using induction expressions The Nascent compiler uses SSA-based induction variable analysis techniques to associate induction expressions with all expressions in a program <ref> [7, 18] </ref>. Each loop in the program is assigned a basic loop variable which assumes values 0,1,: : : for every loop iteration; each expression in the loop is associated with an induction expression which is a function of the basic loop variable.
References-found: 18

