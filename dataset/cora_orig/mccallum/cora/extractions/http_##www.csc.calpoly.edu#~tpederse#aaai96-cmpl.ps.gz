URL: http://www.csc.calpoly.edu/~tpederse/aaai96-cmpl.ps.gz
Refering-URL: http://www.csc.calpoly.edu/~tpederse/pubs.html
Root-URL: http://www.csc.calpoly.edu
Email: fpedersen,kayaalp,rbruceg@seas.smu.edu  
Title: Significant Lexical Relationships  
Author: Ted Pedersen and Mehmet Kayaalp and Rebecca Bruce 
Address: Dallas, TX 75275-0122  
Affiliation: Department of Computer Science and Engineering Southern Methodist University  
Note: Appears in the Proceedings of the 13th National Conference on Artificial Intelligence, August 1996, Portland, OR  
Abstract: Statistical NLP inevitably deals with a large number of rare events. As a consequence, NLP data often violates the assumptions implicit in traditional statistical procedures such as significance testing. We describe a significance test, an exact conditional test, that is appropriate for NLP data and can be performed using freely available software. We apply this test to the study of lexical relationships and demonstrate that the results obtained using this test are both theoretically more reliable and different from the results obtained using previously applied tests. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Badsberg, J. </author> <year> 1995. </year> <title> An Environment for Graphical Models. </title> <type> Ph.D. Dissertation, </type> <institution> Aalborg University. </institution>
Reference-contexts: There are two ways to define the exact distribution of a test statistic: (1) enumerate all elements of that distribution as in Fisher's Exact Test (Fisher 1966), or (2) sample from that distribution using a Monte Carlo sampling scheme (Ripley 1987). The freely available software package CoCo <ref> (Badsberg 1995) </ref> implements the Monte Carlo sampling scheme described in (Kreiner 1987) and summarized below: 1. Generate a random sample of comparable tables from the model being tested. <p> This test, an exact conditional test, assigns significance by generating the exact distribution of the test statistic using a Monte Carlo sampling scheme. This test can be performed using a freely available software package called CoCo <ref> (Badsberg 1995) </ref>. Acknowledgments This research was supported by the Office of Naval Research under grant number N00014-95-1-0776.
Reference: <author> Church, K.; Gale, W.; Hanks, P.; and Hindle, D. </author> <year> 1991. </year> <title> Using statistics in lexical analysis. </title> <editor> In Zernik, U., ed., </editor> <title> Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: It also allows valid comparisons between different models and work done on different data samples. While other researchers have used significance tests to study NLP data ((Dunning 1993), <ref> (Church et al. 1991) </ref>) the tests used are often inappropriate for the type of data found in NLP and therefore produce erroneous results. <p> In both tests, the t-statistic is the difference between the observed value and the hypothesized value scaled by the estimated variance. These two formulations of the t-test are utilized in <ref> (Church et al. 1991) </ref> to perform the test for association and the bigram difference test. <p> In both formulations a first-order approximation is used to equate the variance of a series of Bernoulli trials recording the presence or absence of a single bigram with the observed relative frequency of the bigram in those trials (i.e., the sample mean). According to <ref> (Church et al. 1991) </ref>, lexical association can be evaluated using a one-sample t-test where the t-statistic compares the observed relative frequency of a bigram to the expected relative frequency under the model for independence. <p> This approach to assigning significance is based on the assumption that the sample means are normally distributed. When this assumption does not hold, the significance assigned can be incorrect. As shown in <ref> (Church et al. 1991) </ref>, the bigram difference test can be evaluated using a two-sample t-test where the t-statistic compares the relative frequencies of two bigrams.
Reference: <author> Cochran, W. </author> <year> 1952. </year> <title> The 2 test of goodness of fit. </title> <journal> Annals of Mathematical Statistics 23 </journal> <pages> 315-345. </pages>
Reference-contexts: It is well known that G 2 and X 2 hold to a 2 distribution when the minimum of the expected cell counts under the null hypothesis is five. An early summary of research leading to that conclusion is found in <ref> (Cochran 1952) </ref>. However, when some of the expected counts are less than five, the validity of the asymptotic approximation remains an active point of research. A summary of recent work can be found in (Read & Cressie 1988).
Reference: <author> Cressie, N., and Read, T. </author> <year> 1984. </year> <title> Multinomial goodness-of-fit tests. </title> <journal> Journal of the Royal Statistics Society Series B 46 </journal> <pages> 440-464. </pages>
Reference-contexts: In this section, we discuss three metrics that have been used to measure the fit of the models for association and difference: the likelihood ratio statistic G 2 , Pearson's X 2 statistic, and the t-statistic. power divergence family This family of statistics was introduced in <ref> (Cressie & Read 1984) </ref> and includes the well known goodness of fit statistics X 2 and G 2 . These statistics measure the divergence of observed (n ij ) and expected (m ij ) sample counts, where m ij is calculated assuming that the null hypothesis is correct.
Reference: <author> Dunning, T. </author> <year> 1993. </year> <title> Accurate methods for the statistics of surprise and coincidence. </title> <booktitle> Computational Linguistics 19(1) </booktitle> <pages> 61-74. </pages>
Reference-contexts: In general, the data in Figure 5 confirms the findings of <ref> (Dunning 1993) </ref>; based on a comparison to the exact conditional test, the 2 approximation to the distribution of G 2 is found to be more reliable than the normal approximation to the distribution of the t-statistic and the 2 approximation to the distribution of Pearson's X 2 . (Dunning 1993) showed <p> findings of <ref> (Dunning 1993) </ref>; based on a comparison to the exact conditional test, the 2 approximation to the distribution of G 2 is found to be more reliable than the normal approximation to the distribution of the t-statistic and the 2 approximation to the distribution of Pearson's X 2 . (Dunning 1993) showed that when the minimum of the expected values in a 2 fi 2 table is one, then G 2 holds more closely to 2 than X 2 . However, it is frequently the case that the minimum expected value is much less than one.
Reference: <author> Fisher, R. </author> <year> 1966. </year> <title> The Design of Experiments. </title> <address> New York, NY: </address> <note> Hafner, eighth edition. </note>
Reference-contexts: An alternative to using an asymptotic approximation to the distribution of a goodness of fit test statistic is to define its exact distribution. There are two ways to define the exact distribution of a test statistic: (1) enumerate all elements of that distribution as in Fisher's Exact Test <ref> (Fisher 1966) </ref>, or (2) sample from that distribution using a Monte Carlo sampling scheme (Ripley 1987). The freely available software package CoCo (Badsberg 1995) implements the Monte Carlo sampling scheme described in (Kreiner 1987) and summarized below: 1. Generate a random sample of comparable tables from the model being tested.
Reference: <author> Fisher, R. </author> <year> 1968. </year> <title> Statistical Methods for Research Workers. </title> <address> New York, NY: </address> <note> Hafner, thirteenth edition. </note>
Reference-contexts: However, it can also be shown that a two-sample t-test is identical to Pearson's X 2 test 1 when applied to a 2fi2 contingency table <ref> (Fisher 1968) </ref>. Thus, the two-sample t-test applied to 2 fi 2 contingency tables is appropriate only when the three conditions described in the previous section are met.
Reference: <author> Kreiner, S. </author> <year> 1987. </year> <title> Analysis of multidimensional contingency tables by exact conditional tests: Techniques and strategies. </title> <journal> Scandinavian Journal of Statistics 14 </journal> <pages> 97-112. </pages>
Reference-contexts: The freely available software package CoCo (Badsberg 1995) implements the Monte Carlo sampling scheme described in <ref> (Kreiner 1987) </ref> and summarized below: 1. Generate a random sample of comparable tables from the model being tested. A comparable table is one having the same marginal totals as the observed table. (Patefield 1981) presents an algorithm for I fi J tables. 2.
Reference: <author> Marcus, M.; Santorini, B.; and Marcinkiewicz, M. </author> <year> 1993. </year> <title> Building a large annotated corpus of English: The Penn Treebank. </title> <booktitle> Computational Linguistics 19(2) </booktitle> <pages> 313-330. </pages>
Reference-contexts: As an example, in a 132,755 word subset of the ACL/DCI Wall Street Journal corpus <ref> (Marcus, Santorini, & Marcinkiewicz 1993) </ref> there are 73,779 distinct bigrams. Of these, 81 percent occur once and 97 percent of them occur five times or less.
Reference: <author> Patefield, W. </author> <year> 1981. </year> <title> An efficient method of generating random R fi C tables with given row and column totals. </title> <journal> Applied Statistics 30 </journal> <pages> 91-97. </pages>
Reference-contexts: The freely available software package CoCo (Badsberg 1995) implements the Monte Carlo sampling scheme described in (Kreiner 1987) and summarized below: 1. Generate a random sample of comparable tables from the model being tested. A comparable table is one having the same marginal totals as the observed table. <ref> (Patefield 1981) </ref> presents an algorithm for I fi J tables. 2. Calculate the value of the test statistic for each of the tables in the random sample. 3.
Reference: <author> Read, T., and Cressie, N. </author> <year> 1988. </year> <title> Goodness-of-fit Statistics for Discrete Multivariate Data. </title> <address> New York, NY: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The 2 distribution is an asymptotic approximation for the distributions of G 2 and X 2 . More precisely, X 2 and G 2 are approximately 2 distributed when the following conditions regarding the data sample hold <ref> (Read & Cressie 1988) </ref>: 1. the sample size is large, 2. the number of cells in the contingency table is fixed and small relative to the sample size, and 3. the expected count under the hypothetical popula tion model for each cell is large. <p> An early summary of research leading to that conclusion is found in (Cochran 1952). However, when some of the expected counts are less than five, the validity of the asymptotic approximation remains an active point of research. A summary of recent work can be found in <ref> (Read & Cressie 1988) </ref>. There it is shown that when the individual cell counts in a table are all approximately equal, the asymptotic approximation holds for expected counts as small as one. Unfortunately, the counts in 2 fi 2 tables representing bigram data are almost always heavily skewed. <p> However, it is frequently the case that the minimum expected value is much less than one. In this case, the validity of the asymptotic approximation of G 2 is an open question <ref> (Read & Cressie 1988) </ref>. For example, in the case of the bigram new industry the significance values assigned by each test are different.
Reference: <author> Ripley, B. </author> <year> 1987. </year> <title> Stochastic Simulation. </title> <address> New York, NY: </address> <publisher> John Wiley. </publisher>
Reference-contexts: There are two ways to define the exact distribution of a test statistic: (1) enumerate all elements of that distribution as in Fisher's Exact Test (Fisher 1966), or (2) sample from that distribution using a Monte Carlo sampling scheme <ref> (Ripley 1987) </ref>. The freely available software package CoCo (Badsberg 1995) implements the Monte Carlo sampling scheme described in (Kreiner 1987) and summarized below: 1. Generate a random sample of comparable tables from the model being tested.
Reference: <author> Zipf, G. </author> <year> 1935. </year> <booktitle> The Psycho-Biology of Language. </booktitle> <address> Boston, MA: </address> <publisher> Houghton Mi*in. </publisher>
Reference-contexts: This follows from the distri-butional tendencies of individual words and bigrams as described by Zipf's Law <ref> (Zipf 1935) </ref>. Zipf found that if the frequencies of the words in a large text are ordered from most to least frequent, (f 1 ; f 2 ; : : :; f m ), these frequencies roughly obey: f i / 1 i .
References-found: 13

