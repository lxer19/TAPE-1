URL: file://ftp.cc.gatech.edu/pub/ai/ram/git-cc-92-57.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/projects/robot-learning.html
Root-URL: 
Email: fashwin,arkin,kennethm,rjcg@cc.gatech.edu  
Title: Case-based reactive navigation: A case-based method for on-line selection and adaptation of reactive control parameters
Author: Ashwin Ram Ronald C. Arkin Kenneth Moorman Russell J. Clark 
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: This article presents a new line of research investigating on-line learning mechanisms for autonomous intelligent agents. We discuss a case-based method for dynamic selection and modification of behavior assemblages for a navigational system. The case-based reasoning module is designed as an addition to a traditional reactive control system, and provides more flexible performance in novel environments without extensive high-level reasoning that would otherwise slow the system down. The method is implemented in the ACBARR (A Case-BAsed Reactive Robotic) system, and evaluated through empirical simulation of the system on several different environments, including "box canyon" environments known to be problematic for reactive control systems in general. fl Technical Report GIT-CC-92/57, College of Computing, Georgia Institute of Technology, Atlanta, Geor gia, 1992. 
Abstract-found: 1
Intro-found: 1
Reference: [Agre and Chapman, 1987] <author> P. Agre and D. Chapman. Pengi: </author> <title> An Implementation of a Theory of Activity. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 268-272. </pages> <publisher> AAAI, </publisher> <year> 1987. </year>
Reference-contexts: Firby has developed a different form of reactive control by utilizing modules called RAPs (Reactive Action Packages) which encapsulate tasks for a robot [Firby, 1989]. Situation-driven execution via goal satisfaction is the predominant mode of operation. Agre and Chapman in their PENGI system <ref> [Agre and Chapman, 1987] </ref> have used reactive control in the domain of game playing. Several behaviors are active at any time, controlling the strategies used by a video game penguin and its relationship with other objects and entities in the world.
Reference: [Amarel, 1968] <author> S. Amarel. </author> <title> On Representations of Problems of Reasoning about Actions. </title> <journal> Machine Intelligence, </journal> <volume> 3, </volume> <year> 1968. </year> <editor> Reprinted in B. L. Webber and N. J. Nilsson (eds.), </editor> <booktitle> Readings in Artificial Intelligence, </booktitle> <pages> pp. 2-22, </pages> <publisher> Tioga, </publisher> <address> Palo Alto, CA, </address> <year> 1981. </year>
Reference-contexts: Despite the assumptions of early work in reactive control, representational knowledge is important for robot navigation. The fundamental problem lies in representing what is appropriate for the task. Amarel's classic paper <ref> [Amarel, 1968] </ref> shows the importance of appropriate knowledge representation for problem solving using artificial intelligence. The question is, first, what needs to be represented for successful general-purpose mobile robot navigation, and, second, how it is to be represented.
Reference: [Arkin, 1989] <author> R. C. Arkin. </author> <title> Motor schema-based mobile robot navigation. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 8(4) </volume> <pages> 92-112, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: In contrast, the research presented in this paper is based on work in case-based reasoning. 1 2 Overview Reactive robotic control systems <ref> [Arkin, 1989; Brooks, 1986; Kaelbling, 1986; Payton, 1986] </ref> have produced impressive results in the area of generating intelligent robotic action. Unlike traditional approaches to robot control, these systems typically decompose actions into simple behaviors in order to produce rapid real-time response to the environment. <p> as box canyons, in which traditional reactive systems would perform poorly. 4 3 Background and related research Before presenting the technical details of our system, we discuss previous research in reactive control and in machine learning that forms the basis for our work. 3.1 Perception and reactive control Reactive control <ref> [Arkin, 1989; Brooks, 1986; Brooks, 1989; Kaelbling, 1986; Payton, 1986] </ref> is concerned with how to coordinate multiple motor behaviors. It is characterized by a tight coupling between perception and action with little or no intervening representation. <p> Several behaviors are active at any time, controlling the strategies used by a video game penguin and its relationship with other objects and entities in the world. Reactive navigation in our system <ref> [Arkin, 1989] </ref> addresses reactive control in a manner that is significantly different than the approaches described above. <p> The output of each primitive motor schema is combined using vector summation and normalization (keeping the resultant vector within the constraints of the actual robot's capabilities). This simple process can result in quite complex trajectories and behaviors as illustrated in the simulations and experiments reported in <ref> [Arkin, 1989] </ref>. To optimize system performance it is necessary to determine what gain values should be used to accomplish a specific task in a given environment. <p> To optimize system performance it is necessary to determine what gain values should be used to accomplish a specific task in a given environment. For instance, an exploration behavior can be observed by providing a relatively high gain and persistence to the Noise schema with an accompanying Avoid-Static-Obstacle schema <ref> [Arkin, 1989] </ref>. The task of determining appropriate a priori gain values is non-trivial in highly cluttered environments. For a given environment, this gain determination process involves empirical evaluation of the system's performance. The process is repeated until further changes result in no visible improvement. <p> For example, in a box canyon situation, the system, without a global picture of the entire world, does not have the knowledge to "back out" of the canyon and go around it. This has been referred to as the "fly-at-a-window" problem, <ref> [Arkin, 1989] </ref>. Usually, a high level of random noise is used to try to kick 29 the system out of the box canyon.
Reference: [Arkin, 1990] <author> R. C. Arkin. </author> <title> Integrating Behavioral, Perceptual, and World Knowledge in Reactive Navigation. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 6 </volume> <pages> 105-122, </pages> <year> 1990. </year>
Reference-contexts: For a given environment, this gain determination process involves empirical evaluation of the system's performance. The process is repeated until further changes result in no visible improvement. When structural environmental knowledge is available, this task becomes simpler <ref> [Arkin, 1990] </ref>, but for purely reactive systems with no knowledge of the world, highly complex environments can produce difficulty in reaching near optimal solutions. 8 Furthermore, once this "best set" of gain values is established for a given world, it will likely be less efficient for navigation in a different environment. <p> Short-term memory has also been utilized in other systems based on the AuRA architecture to provide information about spatial occupancy of recently visited areas <ref> [Arkin, 1990; Balch and Arkin, 1993] </ref>. 4.5 Case representation A case entry in ACBARR consists of three parts. The first part represents the types of environments in which the case is applicable, and is used to determine which case to switch to.
Reference: [Balch and Arkin, 1993] <author> T. Balch and R. C. Arkin. </author> <title> Avoiding the Past: A Simple but Effective Strategy for Reactive Navigation. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <address> Atlanta, GA, </address> <month> May </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: Short-term memory has also been utilized in other systems based on the AuRA architecture to provide information about spatial occupancy of recently visited areas <ref> [Arkin, 1990; Balch and Arkin, 1993] </ref>. 4.5 Case representation A case entry in ACBARR consists of three parts. The first part represents the types of environments in which the case is applicable, and is used to determine which case to switch to.
Reference: [Bennett, 1990] <author> S. W. Bennett. </author> <title> Reducing Real-world Failures of Approximate Explanation-Based Rules. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 226-234, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Bennett described a robotic arm controller based on an explanation-based learning system which uses approximations to deal with inconsistencies between its internal theory of actions such as grasping and real-world experience <ref> [Bennett, 1990] </ref>. Mitchell's Theo-Agent architecture is an explanation-based learning system which learns to be more reactive by generating rules from explanations of failure [Mitchell, 1990].
Reference: [Brooks and Connell, 1986] <author> R. Brooks and J. Connell. </author> <title> Asynchronous Distributed Control System for a Mobile Robot. </title> <editor> In W. Wolfe and N. Marquina, editors, </editor> <booktitle> Proceedings of the SPIE, Volume 727: Mobile Robots, </booktitle> <pages> pages 77-84, </pages> <address> Bellingham, WA, </address> <year> 1986. </year>
Reference-contexts: There are many representative examples of this form of navigation, a few of which will be described here. Brooks' subsumption architecture [Brooks, 1986] has demonstrated robust navigation for mobile vehicles in dynamically changing domains. It is a layered architecture, well-adapted for hardware implementation <ref> [Brooks and Connell, 1986] </ref>. It has been used in a wide range of robots, including legged ones [Brooks, 1989]. There is a deliberate avoidance of world modeling which is captured by the statement that the world is its own best model [Brooks, 1988].
Reference: [Brooks, 1986] <author> R. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2(1):14-23, </volume> <month> August </month> <year> 1986. </year>
Reference-contexts: In contrast, the research presented in this paper is based on work in case-based reasoning. 1 2 Overview Reactive robotic control systems <ref> [Arkin, 1989; Brooks, 1986; Kaelbling, 1986; Payton, 1986] </ref> have produced impressive results in the area of generating intelligent robotic action. Unlike traditional approaches to robot control, these systems typically decompose actions into simple behaviors in order to produce rapid real-time response to the environment. <p> as box canyons, in which traditional reactive systems would perform poorly. 4 3 Background and related research Before presenting the technical details of our system, we discuss previous research in reactive control and in machine learning that forms the basis for our work. 3.1 Perception and reactive control Reactive control <ref> [Arkin, 1989; Brooks, 1986; Brooks, 1989; Kaelbling, 1986; Payton, 1986] </ref> is concerned with how to coordinate multiple motor behaviors. It is characterized by a tight coupling between perception and action with little or no intervening representation. <p> Further, sensor data is normally channeled directly to the individual subtasks, reducing significantly the computational demand typically found in navigational regimes requiring world model building. There are many representative examples of this form of navigation, a few of which will be described here. Brooks' subsumption architecture <ref> [Brooks, 1986] </ref> has demonstrated robust navigation for mobile vehicles in dynamically changing domains. It is a layered architecture, well-adapted for hardware implementation [Brooks and Connell, 1986]. It has been used in a wide range of robots, including legged ones [Brooks, 1989].
Reference: [Brooks, 1988] <author> R. Brooks. </author> <title> Intelligence without representation. </title> <institution> Research paper, Massachussetts Institute of Technology, Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: It has been used in a wide range of robots, including legged ones [Brooks, 1989]. There is a deliberate avoidance of world modeling which is captured by the statement that the world is its own best model <ref> [Brooks, 1988] </ref>. Payton has described a collection of motor responses that are termed "reflexive behaviors" [Payton, 1986]. These behaviors react directly to sensory information yielding intelli 5 gent emergent behavior. Payton, Brooks, and several other proponents of reactive control incorporate the concept of arbitration.
Reference: [Brooks, 1989] <author> R. Brooks. </author> <title> A robot that walks: Emergent behaviors from a carefully evolved network. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 692-694, </pages> <address> Scottsdale, AZ, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: as box canyons, in which traditional reactive systems would perform poorly. 4 3 Background and related research Before presenting the technical details of our system, we discuss previous research in reactive control and in machine learning that forms the basis for our work. 3.1 Perception and reactive control Reactive control <ref> [Arkin, 1989; Brooks, 1986; Brooks, 1989; Kaelbling, 1986; Payton, 1986] </ref> is concerned with how to coordinate multiple motor behaviors. It is characterized by a tight coupling between perception and action with little or no intervening representation. <p> Brooks' subsumption architecture [Brooks, 1986] has demonstrated robust navigation for mobile vehicles in dynamically changing domains. It is a layered architecture, well-adapted for hardware implementation [Brooks and Connell, 1986]. It has been used in a wide range of robots, including legged ones <ref> [Brooks, 1989] </ref>. There is a deliberate avoidance of world modeling which is captured by the statement that the world is its own best model [Brooks, 1988]. Payton has described a collection of motor responses that are termed "reflexive behaviors" [Payton, 1986].
Reference: [Chien et al., 1991] <author> S. A. Chien, M. T. Gervasio, and G. F. DeJong. </author> <title> On Becoming Decreasingly Reactive: Learning to Deliberate Minimally. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 288-292, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Finally, unlike traditional case-based reasoning systems which rely on deep reasoning and analysis (e.g., [Hammond, 1989]), and unlike other machine learning "augmentations" to reactive control systems which fall back on non-reactive reasoning (e.g., <ref> [Chien et al., 1991] </ref>), our method does not require the system to "stop and think;" the system continues to perform reactively with very little performance overhead as compared to a "pure" reactive control system. The methods are fully implemented in ACBARR, A Case-BAsed Reactive Robotic system. <p> The minimal deliberation approach proposed by Chien combines reaction-based control with a classical planning system to create plans 11 for dealing with situations where reaction rules fail <ref> [Chien et al., 1991] </ref>. The problem with using explanation-based learning methods for reactive control is twofold. First, these methods involve deep reasoning and are typically too slow for the fast, reflexive behavior required in reactive control systems.
Reference: [Christiansen et al., 1990] <author> A. D. Christiansen, M. T. Mason, and T. M. Mitchell. </author> <title> Learning Reliable Strategies without Initial Physical Models. </title> <booktitle> In Proceedings of the IEEE Conference on Robotics and Automation, </booktitle> <pages> pages 1224-1230, </pages> <year> 1990. </year>
Reference-contexts: Much of the other work in applying machine learning to robotic control is not based on reactive control systems, but is aimed at systems which improve navigational ability by learning environmental features [Zelinsky, 1988] or developing models of actions in the environment <ref> [Christiansen et al., 1990] </ref>. The behavior based learning system proposed by Maes is a distributed algorithm in which the behaviors learn when to become active based on feedback during execution [Maes and Brooks, 1990].
Reference: [Clark et al., 1992] <author> R. J. Clark, R. C. Arkin, and A. Ram. </author> <title> Learning Momentum: On-line Performance Enhancement for Reactive Systems. </title> <booktitle> In Proceedings of the IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 111-116, </pages> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: This technique allows the system to fine tune its current behavior patterns to the exact environment in which it finds itself <ref> [Clark et al., 1992] </ref>. For example, if the robot has been in an open area for a period of time and has not encountered any obstacles, it picks up speed and does not worry as much about obstacles. <p> All test runs described were performed on Sun SparcStation 1s. For more information concerning the simulator, see <ref> [Clark et al., 1992] </ref>. 3 The representations of all ten cases are presented in the appendix. 24 7. Random: The system raises the noise gain and goal gain, leaves the obstacle gain at a medium level, and wanders for a period of time. This is useful for exploration. 8.
Reference: [Cohen and Howe, 1988] <author> P. R. Cohen and A. E. Howe. </author> <title> How evaluation guides AI research. </title> <journal> AI Magazine, </journal> <volume> 9(4) </volume> <pages> 35-43, </pages> <month> Winter </month> <year> 1988. </year>
Reference-contexts: to successfully navigate the standard box canyon problem (figure 6), the quasi-box canyon problem (a box canyon with an exit, figure 7), and the wall environment (figure 8) autonomously. 30 31 32 Method evaluation: In addition to evaluating the performance of the ACBARR system as a whole, several ablation studies <ref> [Cohen and Howe, 1988] </ref> were also performed in which the system was tested without one or more of its components in order to evaluate their impact. These studies lend insight into why the method works.
Reference: [Domeshek, 1992] <author> E. A. Domeshek. </author> <title> Do the right thing: A component theory for indexing stories as social advice. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, </address> <year> 1992. </year> <note> Available as Technical Report #26, </note> <institution> Northwestern University, Institute for the Learning Sciences, </institution> <address> Evanston, IL, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Ideally, similar things should be grouped together. However, the selection of the proper set of features to index the cases in memory is a difficult problem and an ongoing research issue. This indexing problem has been approached in a variety of ways (e.g, <ref> [Domeshek, 1992; Kolodner, 1992] </ref>), but each indexing method is chosen to be efficient for a given problem or situation. There are other problems inherent to the case-based paradigm which must be handled for ACBARR to be effective.
Reference: [Firby, 1989] <author> R. J. Firby. </author> <title> Adaptive Execution in Complex Dynamic Worlds. </title> <type> Ph.D. thesis, </type> <institution> Yale University, Department of Computer Science, </institution> <address> New Haven, CT, </address> <month> January </month> <year> 1989. </year> <note> Research Report YALEU/CSD/RR #673. </note>
Reference-contexts: The emphasis is on embedded systems for real-time control. A hierarchical competency level for behaviors is established which is mediated by a high-level controller. Firby has developed a different form of reactive control by utilizing modules called RAPs (Reactive Action Packages) which encapsulate tasks for a robot <ref> [Firby, 1989] </ref>. Situation-driven execution via goal satisfaction is the predominant mode of operation. Agre and Chapman in their PENGI system [Agre and Chapman, 1987] have used reactive control in the domain of game playing.
Reference: [Grefenstette and Ramsey, 1992] <author> J. J. Grefenstette and C. L. Ramsey. </author> <title> An Approach to Anytime Learning. </title> <editor> In D. Sleeman and P. Edwards, editors, </editor> <booktitle> Machine Learning: Proceedings of the Ninth International Conference, </booktitle> <pages> pages 189-195, </pages> <address> Aberdeen, Scotland, 1992. </address> <publisher> Morgan Kaufman. </publisher> <pages> 45 </pages>
Reference-contexts: For our 10 navigation task, this means that the system must be able to learn during actual performance on a wide range of problems. The ability to learn continuously in a changing environment has been called "anytime learning" <ref> [Grefenstette and Ramsey, 1992] </ref>. Furthermore, we cannot assume that the system will have all the knowledge needed to deal with the situation, even if the situation itself was anticipated by the designer.
Reference: [Hammond, 1989] <author> K. J. Hammond. </author> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <booktitle> Perspec--tives in Artificial Intelligence. </booktitle> <publisher> Academic Press, </publisher> <address> Boston, MA, </address> <year> 1989. </year>
Reference-contexts: Interestingly, case-based reasoning is used to realize this type of modification as well. Assemblages of behaviors represent cases, or standard scenarios known to the system, that can be used to guide performance in novel situations. As in a traditional case-based reasoning system <ref> [Hammond, 1989; Kolodner, 1990; Kolodner, 1992; Riesbeck and Schank, 1989] </ref>, a case is used to propose a plan or a solution (here, a behavior assemblage) to the problem (here, the current environmental configuration). However, our method differs from the traditional use of case-based reasoning in an important respect. <p> Finally, unlike traditional case-based reasoning systems which rely on deep reasoning and analysis (e.g., <ref> [Hammond, 1989] </ref>), and unlike other machine learning "augmentations" to reactive control systems which fall back on non-reactive reasoning (e.g., [Chien et al., 1991]), our method does not require the system to "stop and think;" the system continues to perform reactively with very little performance overhead as compared to a "pure" reactive <p> A recent approach in learning that cuts across the traditional inductive/analytical learning dichotomy derives from Schank's work on dynamic memory [Schank, 1982]. Case-based reasoning and learning programs deal with the issue of using past cases to understand, plan for, or learn from novel situations <ref> [Hammond, 1989; Kolodner, 1990] </ref>. The intent behind case-based reasoning is to avoid the effort involved in re-deriving these lessons, explanations or plans by simply reusing the results from previous cases. <p> Case retrieval and case modification rely both on similarity between situations, as in inductive learning, and causal theories, as in analytical learning. Both types of methods are also used for learning in case-based reasoning systems (e.g., <ref> [Hammond, 1989; Ram, 1993; Veloso and Carbonell, 1993] </ref>). Hammond's CHEF program is an example of early work in the application of CBR to non-real-time and non-reactive planning problems [Hammond, 1989]. However, learning and adaptation in CHEF is done through explanation-based reasoning, which requires a 12 detailed model of the domain. <p> Both types of methods are also used for learning in case-based reasoning systems (e.g., [Hammond, 1989; Ram, 1993; Veloso and Carbonell, 1993]). Hammond's CHEF program is an example of early work in the application of CBR to non-real-time and non-reactive planning problems <ref> [Hammond, 1989] </ref>. However, learning and adaptation in CHEF is done through explanation-based reasoning, which requires a 12 detailed model of the domain. This is exactly what reactive planning systems are trying to avoid. Kopeikina, Brandau and Lemmon describe an application of CBR to real-time control [Kopeikina et al., 1988].
Reference: [Kadanoff et al., 1986] <author> M. Kadanoff, F. Benayad-Cherif, A. Franklin, J. Maddox, L. Muller, B. Sert, and H. Moravec. </author> <title> Arbitration of Multiple Control Strategies for Mobile Robots. </title> <editor> In W. Wolfe and N. Marquina, editors, </editor> <booktitle> Proceedings of the SPIE, Volume 727: Mobile Robots, </booktitle> <pages> pages 77-84, </pages> <address> Bellingham, WA, </address> <year> 1986. </year>
Reference-contexts: Multiple behaviors compete for control of the vehicle with a winner-take-all mechanism deciding the result. Only one behavior dominates the vehicle at any time, although the dominant behavior can change frequently in rapid response to environmental sensing. Earlier work by Kadonoff also employs an arbitration scheme <ref> [Kadanoff et al., 1986] </ref>. Kaelbling has developed a reactive architecture [Kaelbling, 1986] that is an extension of Brooks' work. The emphasis is on embedded systems for real-time control. A hierarchical competency level for behaviors is established which is mediated by a high-level controller.
Reference: [Kaelbling, 1986] <author> L. Kaelbling. </author> <title> An Architecture for Intelligent Reactive Systems. </title> <type> Technical Note 400, </type> <institution> SRI International, </institution> <month> October </month> <year> 1986. </year>
Reference-contexts: In contrast, the research presented in this paper is based on work in case-based reasoning. 1 2 Overview Reactive robotic control systems <ref> [Arkin, 1989; Brooks, 1986; Kaelbling, 1986; Payton, 1986] </ref> have produced impressive results in the area of generating intelligent robotic action. Unlike traditional approaches to robot control, these systems typically decompose actions into simple behaviors in order to produce rapid real-time response to the environment. <p> as box canyons, in which traditional reactive systems would perform poorly. 4 3 Background and related research Before presenting the technical details of our system, we discuss previous research in reactive control and in machine learning that forms the basis for our work. 3.1 Perception and reactive control Reactive control <ref> [Arkin, 1989; Brooks, 1986; Brooks, 1989; Kaelbling, 1986; Payton, 1986] </ref> is concerned with how to coordinate multiple motor behaviors. It is characterized by a tight coupling between perception and action with little or no intervening representation. <p> Only one behavior dominates the vehicle at any time, although the dominant behavior can change frequently in rapid response to environmental sensing. Earlier work by Kadonoff also employs an arbitration scheme [Kadanoff et al., 1986]. Kaelbling has developed a reactive architecture <ref> [Kaelbling, 1986] </ref> that is an extension of Brooks' work. The emphasis is on embedded systems for real-time control. A hierarchical competency level for behaviors is established which is mediated by a high-level controller.
Reference: [Kolodner, 1990] <author> J. L. Kolodner. </author> <title> An introduction to case-based reasoning. </title> <type> Technical Report GIT-ICS-90/19, </type> <institution> Georgia Institute of Technology, School of Information and Computer Science, </institution> <address> Atlanta, GA, </address> <year> 1990. </year>
Reference-contexts: Interestingly, case-based reasoning is used to realize this type of modification as well. Assemblages of behaviors represent cases, or standard scenarios known to the system, that can be used to guide performance in novel situations. As in a traditional case-based reasoning system <ref> [Hammond, 1989; Kolodner, 1990; Kolodner, 1992; Riesbeck and Schank, 1989] </ref>, a case is used to propose a plan or a solution (here, a behavior assemblage) to the problem (here, the current environmental configuration). However, our method differs from the traditional use of case-based reasoning in an important respect. <p> A recent approach in learning that cuts across the traditional inductive/analytical learning dichotomy derives from Schank's work on dynamic memory [Schank, 1982]. Case-based reasoning and learning programs deal with the issue of using past cases to understand, plan for, or learn from novel situations <ref> [Hammond, 1989; Kolodner, 1990] </ref>. The intent behind case-based reasoning is to avoid the effort involved in re-deriving these lessons, explanations or plans by simply reusing the results from previous cases.
Reference: [Kolodner, 1992] <author> J. L. Kolodner. </author> <title> Case-based reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992. </year> <note> In press. </note>
Reference-contexts: Interestingly, case-based reasoning is used to realize this type of modification as well. Assemblages of behaviors represent cases, or standard scenarios known to the system, that can be used to guide performance in novel situations. As in a traditional case-based reasoning system <ref> [Hammond, 1989; Kolodner, 1990; Kolodner, 1992; Riesbeck and Schank, 1989] </ref>, a case is used to propose a plan or a solution (here, a behavior assemblage) to the problem (here, the current environmental configuration). However, our method differs from the traditional use of case-based reasoning in an important respect. <p> Ideally, similar things should be grouped together. However, the selection of the proper set of features to index the cases in memory is a difficult problem and an ongoing research issue. This indexing problem has been approached in a variety of ways (e.g, <ref> [Domeshek, 1992; Kolodner, 1992] </ref>), but each indexing method is chosen to be efficient for a given problem or situation. There are other problems inherent to the case-based paradigm which must be handled for ACBARR to be effective. <p> As a result, ACBARR employs a flat memory model of the case library <ref> [Kolodner, 1992] </ref>. Cases are located by a sequential search of the memory for index matches. Although generally an inefficient method, this suffices for the current system without significant slow-down.
Reference: [Kopeikina et al., 1988] <author> L. Kopeikina, R. Brandau, and A. Lemmon. </author> <title> Case-Based Reasoning for Continuous Control. </title> <booktitle> In Proceedings of a Workshop on Case-Based Reasoning, </booktitle> <pages> pages 250-259, </pages> <address> Clearwater Beach, FL, May 1988. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, learning and adaptation in CHEF is done through explanation-based reasoning, which requires a 12 detailed model of the domain. This is exactly what reactive planning systems are trying to avoid. Kopeikina, Brandau and Lemmon describe an application of CBR to real-time control <ref> [Kopeikina et al., 1988] </ref>. Their system, though not intended for robotics, is designed to handle the special issues of time-constrained processing and the need to represent cases that evolve over time. They suggest a system that performs the learning task in batch mode during off peak hours.
Reference: [Lebowitz, 1983] <author> M. Lebowitz. </author> <title> Generalization from Natural Language Text. </title> <journal> Cognitive Science, </journal> <volume> 7(1) </volume> <pages> 1-40, </pages> <year> 1983. </year>
Reference-contexts: Other systems encounter examples during problem solving or understanding, such as Lebowitz's IPP system <ref> [Lebowitz, 1983] </ref> or Ram's AQUA system [Ram, 1991; Ram, 1993] which learned by reading newspaper stories. Some systems, such as Rajamoney's program [Rajamoney, 1989] and Mitchell's LEX and LEX2 systems [Mitchell et al., 1986], create and explore their own examples.
Reference: [Maes and Brooks, 1990] <author> P. Maes and R. A. Brooks. </author> <title> Learning to Coordinate Behaviors. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 796-802, </pages> <address> Boston, MA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: The behavior based learning system proposed by Maes is a distributed algorithm in which the behaviors learn when to become active based on feedback during execution <ref> [Maes and Brooks, 1990] </ref>. One difference between this and our work is that our system learns varying levels of behavior "activation" rather than merely active versus inactive; also, our method is not based on statistical information.
Reference: [Michalski, 1983] <author> R. S. Michalski. </author> <title> A Theory and Methodology of Inductive Learning. </title> <journal> Artificial Intelligence, </journal> <volume> 20 </volume> <pages> 111-161, </pages> <year> 1983. </year>
Reference-contexts: There are two broad classes of learning algorithms, inductive (or data-driven), and analytical (or theory-driven) <ref> [Michalski, 1983] </ref>. Inductive learning involves building generalizations based on instances encountered by the system. For example, a system could learn what a cup is by analyzing several examples and non-examples of cups to determine the similarities and differences between them.
Reference: [Minton, 1988] <author> S. Minton. </author> <title> Learning effective search control knowledge: An explanation-based approach. </title> <type> Ph.D. thesis, </type> <institution> Carnegie-Mellon University, Computer Science Department, </institution> <address> Pittsburgh, PA, </address> <year> 1988. </year> <note> Technical Report CMU-CS-88-133. </note>
Reference-contexts: Analytical learning methods rely on a different assumption: the presence of a domain theory that provides a complete and correct causal model of the domain. While most of the work in induction has been in concept formation, explanation-based learning has also been applied to the learning of control strategies <ref> [Minton, 1988; Mitchell et al., 1986] </ref>. Bennett described a robotic arm controller based on an explanation-based learning system which uses approximations to deal with inconsistencies between its internal theory of actions such as grasping and real-world experience [Bennett, 1990].
Reference: [Mitchell et al., 1986] <author> T. M. Mitchell, R. Keller, and S. Kedar-Cabelli. </author> <title> Explanation-Based Generalization: </title>
Reference-contexts: Other systems encounter examples during problem solving or understanding, such as Lebowitz's IPP system [Lebowitz, 1983] or Ram's AQUA system [Ram, 1991; Ram, 1993] which learned by reading newspaper stories. Some systems, such as Rajamoney's program [Rajamoney, 1989] and Mitchell's LEX and LEX2 systems <ref> [Mitchell et al., 1986] </ref>, create and explore their own examples. <p> Analytical learning methods rely on a different assumption: the presence of a domain theory that provides a complete and correct causal model of the domain. While most of the work in induction has been in concept formation, explanation-based learning has also been applied to the learning of control strategies <ref> [Minton, 1988; Mitchell et al., 1986] </ref>. Bennett described a robotic arm controller based on an explanation-based learning system which uses approximations to deal with inconsistencies between its internal theory of actions such as grasping and real-world experience [Bennett, 1990].
References-found: 28

