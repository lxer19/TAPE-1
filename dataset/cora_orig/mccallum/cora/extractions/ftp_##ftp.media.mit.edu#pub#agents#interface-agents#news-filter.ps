URL: ftp://ftp.media.mit.edu/pub/agents/interface-agents/news-filter.ps
Refering-URL: http://agents.www.media.mit.edu/groups/agents/publications/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A Learning Approach to Personalized Information Filtering  
Author: by Beerud Dilip Sheth 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science in Computer Science and Engineering at the  All rights reserved. Author  Certified by Pattie Maes Assistant Professor of Media Arts and Sciences Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Date: February 1994  Jan 14, 1994  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1994.  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Ackley, D., Littman, M., </author> <title> Interactions between Learning and Evolution, Artificial Life II, Edited by C. </title> <editor> Langton, C. Taylor, J. Farmer and S. Rasmussen, </editor> <publisher> Addison Wesley, </publisher> <year> 1991. </year>
Reference-contexts: The algorithm used by the agent is described in the following chapter. The learning mechanism used in the information filtering agents is motivated by research in Genetic Algorithms and Artificial Evolution <ref> [1, 6, 15, 18, 19] </ref>. IF is effectively a dynamically changing search problem. Searching a large and changing space involves a trade-off between two objectives: (i) exploiting the currently available solution and (ii) further exploring the search space for a possibly better solution. <p> Several experiments have demonstrated that artificial evolution is helped by individual 16 learning <ref> [1, 19] </ref>. This phenomenon is also known as the "Baldwin effect": if the organisms evolved are allowed to learn during their lifetime, then the evolution towards a fitter species happens much faster. <p> Field scores must only be compared and added unless they are all on a unform scale. This can be achieved by normalizing the field vectors. The scalar product of two normalized vectors lies in the closed interval <ref> [-1, 1] </ref>. <p> Hence, document scores are constrained to be in the closed interval <ref> [-1, 1] </ref>. The highest score of 1 would only be assigned when the document and profile representations are identical. i.e.
Reference: [2] <author> Baclace, P. E., </author> <title> Personal Information Intake Filtering, Bellcore Information Filtering Workshop, </title> <month> November </month> <year> 1991. </year>
Reference-contexts: Interests may not always be well defined or might not always be well expressed. In addition, the users' interests cannot be assumed to be constant, as mentioned before. Filtering systems must therefore be responsive to dynamic user interests. Baclace <ref> [2] </ref> proposes a hybrid algorithm to evolve agents for information intake filtering. 14 Information intake filtering (IIF) refers to "prioritizing objects in a conceptual in-basket". The IIF agents learn using a combination of a genetic and economic algorithm. A number of different techniques have been used for modeling the user. <p> Another difference is that each profile individual in our system learns within it's lifetime taking advantage of the Baldwin effect described above. This is not the case in the other system. Our approach differs in many respects from Information Intake Filtering (IIF) <ref> [2] </ref> mentioned earlier. The first difference is that IIF is a subset of the personalized information filtering problem as defined in this thesis. By assuming an in-basket, it scales down the problem considerably to that of prioritizing articles that have already undergone one level of filtering before reaching the in-basket. <p> Calculating the proximity of profiles in the vector space representation is easy. The interesting problem is to devise a scheme which applies selective pressure on neighbouring profiles to move away from each other. The economic model for optimizing computational resources, as used by Baclace <ref> [2] </ref>, could possibly provide a solution. Users typically have special needs that must be integrated into the GA model. For example, a user might create a special high priority profile which must never be eliminated by the population, no matter what.
Reference: [3] <author> Berners-Lee, T., Cailliau, R., Groff, J., and Pollermann, B., </author> <title> World-Wide Web: The Information Universe, </title> <journal> Electronic Networking: Research, Applications and Poilicy, Meck-ler Publications, </journal> <volume> 2(1), </volume> <month> Spring </month> <year> 1992, </year> <pages> pp. 52-58. </pages>
Reference-contexts: WAIS allows users to provide relevance feedback to further specialize an initial query. Gopher [32] is primarily a tool for browsing through hierarchically organized documents, but it also allows to search for information using full-text indexes. In the World Wide Web (WWW) <ref> [3] </ref>, the information is organized using the hypertext paradigm where users can explore information by selecting hypertext links to other information. Documents also contain indexes which the user can search for. A number of commercial retrieval systems are available in the market.
Reference: [4] <author> Chin, D., </author> <title> Intelligent Interfaces as Agents, Intelligent User Interfaces, </title> <publisher> ACM Press, </publisher> <year> 1991, </year> <pages> pp. 177-206. </pages>
Reference-contexts: However, the disadvantage is that the burden of the programming task is on the user, which may not be desirable. The other approach is to knowledge-engineer the agent with substantial background knowledge about the application and the user. For example, UCEgo <ref> [4] </ref> helps the user to use the Unix operating system by making various suggestions to correct user mistakes. The advantage is that the user no longer has to program the agent the knowledge engineer will do that for her.
Reference: [5] <author> Deerwester, S., Dumais, S.T., Furnas, G.W., Landauer, T.K., Harshman, R., </author> <title> Indexing by Latent Semantic Analysis, </title> <journal> Journal of the American Society for Information Science, </journal> <volume> Vol. 41, No. 6, </volume> <year> 1990, </year> <pages> pp. 391-407. </pages>
Reference-contexts: Salton [38, 39] describes the use of statistical schemes such as probabilistic and vector space models for document representation and retrieval. The Smart system [42] is an example of a text processing and retrieval system based on the vector processing model. Latent Semantic Indexing (LSI) <ref> [5] </ref> is another example of a statistical method to capture the term associations in documents. The semantic approach to retrieval characterizes the documents and queries so as to represent the underlying meaning [17, 36]. It emphasizes natural language processing or the use of 12 AI-like frames.
Reference: [6] <author> DeJong, K.A., </author> <title> Adaptive System Design: A Genetic Approach, </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> Vol. 10 No. 9, </volume> <year> 1980. </year>
Reference-contexts: The algorithm used by the agent is described in the following chapter. The learning mechanism used in the information filtering agents is motivated by research in Genetic Algorithms and Artificial Evolution <ref> [1, 6, 15, 18, 19] </ref>. IF is effectively a dynamically changing search problem. Searching a large and changing space involves a trade-off between two objectives: (i) exploiting the currently available solution and (ii) further exploring the search space for a possibly better solution.
Reference: [7] <author> Belkin, N.J., Croft, W.B., </author> <title> Information Filtering and Information Retrieval: Two Sides of the Same Coin?, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 35 No. 12, </volume> <pages> pp. 29-38, </pages> <year> 1992. </year>
Reference-contexts: The contributions made by this thesis are as follows: * This thesis refines the statement of the personalized information filtering problem. Personalized filtering systems must be specialized to user interests, adaptive to preference changes and explore newer information domains. While the first two criteria have been addressed earlier <ref> [7, 39] </ref>, exploration has not been sufficiently emphasized before. * The vector space model for document representation has been generalized for use with documents containing more than just text. <p> Information filtering systems can help users by eliminating the irrelevant information and by bringing the relevant information to the user's attention. Filters are mediators between the sources of information and their end-users. Belkin and Croft <ref> [7] </ref> provide a good description of Information filtering (IF) and identify the similarities and differences with Information Retrieval (IR). Filtering contexts typically involve a dynamic stream of information, as opposed to static data bases used in traditional IR systems. <p> Information Retrieval is a well established field of information science that addresses issues of retrieval from a large collection of documents in response to user queries. Information Retrieval literature has recently begun to address issues of Information Filtering <ref> [7, 11, 13] </ref>. By comparison, Agent research is a relatively new field of study which has grown out of Artificial Intelligence (AI). Agent research is concerned with issues of designing intelligent and autonomous software for a variety of tasks. <p> Learning and adaptation is, however, of much greater importance in filtering contexts. Filtering is concerned with repeated use of the system by users with long term interests. Filtering systems are often used by larger communities of people, a large number of whom might not be highly motivated information seekers <ref> [7] </ref>. Interests may not always be well defined or might not always be well expressed. In addition, the users' interests cannot be assumed to be constant, as mentioned before. Filtering systems must therefore be responsive to dynamic user interests.
Reference: [8] <author> Cypher, A., ed. </author> <title> Watch what I do: Programming by Demonstration, </title> <publisher> MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1993. </year>
Reference-contexts: The distance metric for computation of document score and the effect of relevance feedback has also been generalized. 9 * Programming by demonstration <ref> [8] </ref> is proposed as an additional method of providing feedback to the filtering system.
Reference: [9] <author> Fischer, G., Stevens, C., </author> <title> Information access in complex, poorly structured information spaces. </title> <booktitle> Human Factors in Computing Systems CHI'91 Conference Proceedings, </booktitle> <year> 1991, </year> <pages> pp. 63-70. </pages>
Reference-contexts: Foltz [10] demonstrates the use of LSI for information filtering and evaluates it for filtering Netnews articles. [11] performs a similar experiment for the domain of technical reports. INFOSCOPE <ref> [9] </ref> consists of rule-based agents which observe usage patterns and make suggestions to the user. The agents monitor the contents of the messages that are deemed interesting or uninteresting, make statistical correlations and suggest changes to the user. <p> For example, INFOSCOPE learns using rule based systems which remember interesting topics covered in the past. New recommendations of topics are made to the user based on recency, frequency and spacing of past topics <ref> [9] </ref>. The disadvantage of such an approach is that it is constrained to making recommendations of topics which lie within the realm of user's past interests. On the other hand, we explicitly model exploration.
Reference: [10] <author> Foltz, P. W., </author> <title> Using Latent Semantic Indexing for information filtering, </title> <booktitle> Proceegings of the ACM Conference on Office Information Systems, </booktitle> <address> ACM/SIGOIS, New York, </address> <year> 1990, </year> <pages> pp. 40-47. </pages>
Reference-contexts: A variety of approaches have been used to get at the semantic contents of the documents. Oval [29] is an example of a system which uses a keyword-based approach to match user defined rules to incoming documents. Foltz <ref> [10] </ref> demonstrates the use of LSI for information filtering and evaluates it for filtering Netnews articles. [11] performs a similar experiment for the domain of technical reports. INFOSCOPE [9] consists of rule-based agents which observe usage patterns and make suggestions to the user.
Reference: [11] <author> Foltz, P.W., Dumais, T., </author> <title> Personalized Information Delivery: An Analysis of Information Filtering Methods, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 35 No. 12, </volume> <pages> pp. 51-60. 72 </pages>
Reference-contexts: Information Retrieval is a well established field of information science that addresses issues of retrieval from a large collection of documents in response to user queries. Information Retrieval literature has recently begun to address issues of Information Filtering <ref> [7, 11, 13] </ref>. By comparison, Agent research is a relatively new field of study which has grown out of Artificial Intelligence (AI). Agent research is concerned with issues of designing intelligent and autonomous software for a variety of tasks. <p> Oval [29] is an example of a system which uses a keyword-based approach to match user defined rules to incoming documents. Foltz [10] demonstrates the use of LSI for information filtering and evaluates it for filtering Netnews articles. <ref> [11] </ref> performs a similar experiment for the domain of technical reports. INFOSCOPE [9] consists of rule-based agents which observe usage patterns and make suggestions to the user. The agents monitor the contents of the messages that are deemed interesting or uninteresting, make statistical correlations and suggest changes to the user.
Reference: [12] <author> Gauch, S., Smith, J. B., </author> <title> An Expert System for Searching Full Text, </title> <journal> Information Pro--cessing and Management, </journal> <volume> 25(3), </volume> <year> 1989, </year> <pages> pp. 253-263. </pages>
Reference-contexts: It emphasizes natural language processing or the use of 12 AI-like frames. The third approach, also known as "smart" Boolean, takes advantage of the structural and contextual information typically available in retrieval systems. For example, this could involve the use of thesauri in which relationships among terms are encoded <ref> [12] </ref> or take advantage of context and structure generally available from the document terms [30]. CONIT [31] is an example of a system built in the "smart" Boolean framework.
Reference: [13] <author> Goldberg, G., Nichols, D., Oki, B.M., Terry, D., </author> <title> Using Collaborative Filtering to Weave an Information Tapestry, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 35 No. 12, </volume> <pages> pp. 61-70. </pages>
Reference-contexts: Information Retrieval is a well established field of information science that addresses issues of retrieval from a large collection of documents in response to user queries. Information Retrieval literature has recently begun to address issues of Information Filtering <ref> [7, 11, 13] </ref>. By comparison, Agent research is a relatively new field of study which has grown out of Artificial Intelligence (AI). Agent research is concerned with issues of designing intelligent and autonomous software for a variety of tasks. <p> The selection could either depend on personal criteria (e.g. endorsement by a friend), or on aggregate criteria (e.g. endorsements by more than half the group members). Tapestry <ref> [13] </ref> is an example of a collaborative environment that accepts information from many sources, allows detailed endorsements and defines a query language to access endorsed articles. The cognitive and social approaches are both just as valid for selecting documents.
Reference: [14] <author> Gordon, M., </author> <title> Probabilisitc and Genetic Algorithms for Document Retrieval, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 31 No. 10, </volume> <month> Oct. </month> <year> 1988. </year>
Reference-contexts: Another approach to modeling adaptation is the use of genetic algorithms (GA) to devise adaptive algorithms for information retrieval. Yang and Korfhage [47] evolve a population of query individuals to optimize the search. Gordon <ref> [14] </ref>, on the other hand, uses a method where competing representations are associated with documents. The representations are then altered over time using GA. Learning and adaptation is, however, of much greater importance in filtering contexts.
Reference: [15] <editor> Grefenstette, J.J., </editor> <booktitle> Proceedings of an International Conference on Genetic Algorithms and Their Applications, </booktitle> <institution> The Robotics Institute of Carnegie Mellon University, Pitts-burgh, </institution> <year> 1985. </year>
Reference-contexts: The algorithm used by the agent is described in the following chapter. The learning mechanism used in the information filtering agents is motivated by research in Genetic Algorithms and Artificial Evolution <ref> [1, 6, 15, 18, 19] </ref>. IF is effectively a dynamically changing search problem. Searching a large and changing space involves a trade-off between two objectives: (i) exploiting the currently available solution and (ii) further exploring the search space for a possibly better solution.
Reference: [16] <author> Grefenstette, J.J., </author> <title> Optimization of Control Parameters for Genetic Algorithms, </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> Vol. 16 No. 1, </volume> <year> 1986 </year>
Reference: [17] <author> Haase, K. B., FRAMER: </author> <title> A Persistent Portable Representation Library, Submitted to: </title> <booktitle> European Conference on Artificial Intelligence, </booktitle> <year> 1994. </year>
Reference-contexts: Latent Semantic Indexing (LSI) [5] is another example of a statistical method to capture the term associations in documents. The semantic approach to retrieval characterizes the documents and queries so as to represent the underlying meaning <ref> [17, 36] </ref>. It emphasizes natural language processing or the use of 12 AI-like frames. The third approach, also known as "smart" Boolean, takes advantage of the structural and contextual information typically available in retrieval systems. <p> Keyword-based filtering schemes have their limitations as mentioned in Chapter 6. An 69 option to overcome these limitations is to use techniques from the fields of natural language understanding and knowledge representation. For instance, FRAMER <ref> [17] </ref> is a knowledge representation library which can draw analogies in natural language texts. So, for example, if FRAMER infers that the news story A is analogous to the news story B, if the user likes document A, the agent could also recommend document B.
Reference: [18] <author> Holland, J.H., </author> <title> Adaptation in Natural and Artificial Systems, An Introductory Analysis with Applications to Biology, </title> <booktitle> Control and Artificial Intelligence, </booktitle> <publisher> University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: The user is no longer constrained to providing feedback only to the documents retrieved by the profiles, but can also pro-actively train the system using documents she found. * This thesis validates the use of Genetic Algorithms <ref> [18] </ref> for modeling adaptive and exploratory behavior in Filtering systems. * Experimental results show that using only relevance feedback is sufficient for special izing to user interests, but not satisfactory for modeling adaptive behavior. 1.3 Overview of this document The rest of this thesis is organized as follows. <p> The algorithm used by the agent is described in the following chapter. The learning mechanism used in the information filtering agents is motivated by research in Genetic Algorithms and Artificial Evolution <ref> [1, 6, 15, 18, 19] </ref>. IF is effectively a dynamically changing search problem. Searching a large and changing space involves a trade-off between two objectives: (i) exploiting the currently available solution and (ii) further exploring the search space for a possibly better solution. <p> Genetic Algorithms manage the trade-off between exploration and exploitation in a near optimal way | they exploit the solution found so far, while Crossover and Mutation operations provide a way of exploring the search space for better solutions <ref> [18] </ref>. Several experiments have demonstrated that artificial evolution is helped by individual 16 learning [1, 19]. This phenomenon is also known as the "Baldwin effect": if the organisms evolved are allowed to learn during their lifetime, then the evolution towards a fitter species happens much faster.
Reference: [19] <author> Hinton, G.E., Nowlan, S.J., </author> <title> How Learning can Guide Evolution, </title> <journal> Complex Systems, </journal> <volume> 1: </volume> <pages> 495-502, </pages> <year> 1987. </year>
Reference-contexts: The algorithm used by the agent is described in the following chapter. The learning mechanism used in the information filtering agents is motivated by research in Genetic Algorithms and Artificial Evolution <ref> [1, 6, 15, 18, 19] </ref>. IF is effectively a dynamically changing search problem. Searching a large and changing space involves a trade-off between two objectives: (i) exploiting the currently available solution and (ii) further exploring the search space for a possibly better solution. <p> Several experiments have demonstrated that artificial evolution is helped by individual 16 learning <ref> [1, 19] </ref>. This phenomenon is also known as the "Baldwin effect": if the organisms evolved are allowed to learn during their lifetime, then the evolution towards a fitter species happens much faster.
Reference: [20] <author> Horton, M., </author> <title> Standard for Interchange of USENET Messages, RFC-1036, USENET Project, </title> <month> December </month> <year> 1987. </year>
Reference-contexts: The structured part is the meta-information about the text of the article. This varies greatly depending on the source of news. There are a number of header lines that an article must have to adhere to the Standard for Interchange of USENET messages <ref> [20] </ref>. Some of the headers interesting for filtering purposes, that are mandated by the USENET protocol include Date, From, and Subject. Some suppliers of information provide additional information, which is optional. Such fields include pre-indexed keywords, Organization, (number of) Lines, Sender, Location and so on.
Reference: [21] <author> Kahle, B., </author> <title> An Information System for Corporate Users: Wide Area Information Servers, </title> <type> Thinking Machines technical report TMC-99, </type> <month> April </month> <year> 1991. </year>
Reference-contexts: With the Internet having seen an explosive growth in recent years, a number of services have arisen on the Internet to help users search and retrieve documents from servers around the world | WAIS, Gopher and World Wide Web to name a few. Wide Area Information Servers (WAIS) <ref> [21] </ref> is a networked based document indexing and retrieval system for textual data. The servers maintain inverted indexes of keywords that are used for efficient retrieval of documents. WAIS allows users to provide relevance feedback to further specialize an initial query.
Reference: [22] <author> Kay, A., </author> <title> Computer Software, </title> <journal> Scientific American, </journal> <volume> 251(3), </volume> <year> 1984, </year> <pages> pp. 53-59. </pages>
Reference-contexts: Interface Agents are computer programs that automate repetitive tasks to provide assistance to a user dealing with a particular computer application. The idea of employing agents to delegate computer-based tasks goes back to research by Negroponte [34] and Kay <ref> [22] </ref>. The research in this field is directed toward the ideal of agents that have high-level human-like communication skills and can accept high-level goals and reliably translate these to low level tasks. Two approaches have been traditionally used for designing interface agents.
Reference: [23] <author> Kozierok, R., Maes, P., </author> <title> A Learning Interface Agent for Scheduling Meetings, </title> <booktitle> ACM-SIGCHI International Workshop on Intelligent User Interfaces, </booktitle> <address> Florida, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: The agent can learn by observing the user and imitating her, by reacting to feedback from the user and by learning from training examples provided by the user. A meeting scheduling agent using the above approach is described in <ref> [23, 24] </ref>. The meeting scheduling agent uses 15 memory-based reasoning and reinforcement learning to automate actions for the user. It can also use rules provided by the user and learn from examples of meeting in hypothetical situations. An electronic mail agent is described in [28, 33].
Reference: [24] <author> Kozierok, R., </author> <title> A Learning Approach to Knowledge Acquisition for Intelligent Interface Agents, </title> <type> SM Thesis, </type> <institution> Department of Electrical Engineering and Computer Science, MIT, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: The agent can learn by observing the user and imitating her, by reacting to feedback from the user and by learning from training examples provided by the user. A meeting scheduling agent using the above approach is described in <ref> [23, 24] </ref>. The meeting scheduling agent uses 15 memory-based reasoning and reinforcement learning to automate actions for the user. It can also use rules provided by the user and learn from examples of meeting in hypothetical situations. An electronic mail agent is described in [28, 33].
Reference: [25] <author> Lai, K., Malone, T., Yu, K., </author> <title> Object Lens: A "SpreadSheet" for Cooperative work. </title> <journal> ACM Transactions on Office Information Systems 5(4), </journal> <year> 1988, </year> <pages> pp. 297-326. </pages>
Reference-contexts: Two approaches have been traditionally used for designing interface agents. The first approach is to make the end-user program the agent. An example is the Oval system <ref> [25] </ref> which allows users to program rules that dictate the agent's behavior. The advantage of this approach is that it gives the user total control. This makes it easy for the user to trust the rules, since she herself created them.
Reference: [26] <author> Lottor, M., </author> <title> Internet Growth (1981-1991), Request for Comments 1296, Network Information Systems Center, </title> <booktitle> SRI International, </booktitle> <month> Jan </month> <year> 1992. </year>
Reference-contexts: If the Internet is any indication, the number of people who have started using online services has increased dramatically in recent years, . The number of Internet hosts, i.e. machines which have direct connectivity, is over a million <ref> [26] </ref> and is growing exponentially. There are many more which connect to the Internet indirectly through intermediary services such as America Online and Compuserve. This explosive growth has fed the growth in the amount of information resources available over the networks.
Reference: [27] <author> Maes, P., </author> <title> Modeling Adaptive Autonomous Agents, To appear in: </title> <journal> Artificial Life Journal, </journal> <volume> Vol. 1, Nos. 1 & 2, </volume> <publisher> MIT Press, </publisher> <month> Summer </month> <year> 1994. </year> <month> 73 </month>
Reference-contexts: It is situated in the environment and interacts through sensors and actuators. Autonomous adaptive agents operate totally autonomously and become better over time at achieving its goals. Agents that are situated in the "cyberspace" environment are known as "software agents" or "interface agents" <ref> [27] </ref>. Interface Agents are computer programs that automate repetitive tasks to provide assistance to a user dealing with a particular computer application. The idea of employing agents to delegate computer-based tasks goes back to research by Negroponte [34] and Kay [22].
Reference: [28] <author> Maes, P., Kozierok, R., </author> <title> Learning Interface Agents, </title> <booktitle> Proceedings of AAAI, </booktitle> <year> 1993. </year>
Reference-contexts: Interface Agents are computer programs that learn the tastes and preferences of users and automate repetitive and predictable computer related tasks for them <ref> [28] </ref>. An information filtering agent learns the information related preferences of the user and automates some of the filtering tasks for the user. The contributions made by this thesis are as follows: * This thesis refines the statement of the personalized information filtering problem. <p> A third approach using machine learning techniques to overcome the shortcomings of the other two has been proposed by Maes and Kozierok <ref> [28] </ref>. The goal of this approach is to build Agents that acquire their competence and adapt to user requirements. In computer environments that involve a lot of repetitive tasks and where the individual differences outweigh the similarities, a machine learning approach has the potential to be very useful. <p> The meeting scheduling agent uses 15 memory-based reasoning and reinforcement learning to automate actions for the user. It can also use rules provided by the user and learn from examples of meeting in hypothetical situations. An electronic mail agent is described in <ref> [28, 33] </ref>. A number of products are commercially sold as agents in the market. Magnet, from No Hands Software, can automate filing, scheduling and similar tasks for the user. "Open Sesame!", from Charles River Associates Inc., is a learning agent that monitors the keyboard and mouse watching for repeating patterns.
Reference: [29] <author> Malone, T. W., Grant et al, </author> <title> Intelligent Information-Sharing Systems, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 30, No. 5, </volume> <month> May </month> <year> 1987, </year> <pages> pp. 390-402. </pages>
Reference-contexts: Applesearch, released by Apple, is quite similar to Hoover. Information Filtering In contrast to IR, IF has only recently started to attract attention. Based on a survey of information sharing in organizations, three approaches can be identified <ref> [29] </ref>. Depending on the manner in which documents are selected for the user, filtering systems can be classified as cognitive, social or economic. Cognitive systems choose documents based on the characteristics of their contents. Social systems select documents based on the recommendations and annotations of other users. <p> Social systems select documents based on the recommendations and annotations of other users. Economic systems select documents based on some computation of cost-benefit to the user and through some pricing mechanisms. A variety of approaches have been used to get at the semantic contents of the documents. Oval <ref> [29] </ref> is an example of a system which uses a keyword-based approach to match user defined rules to incoming documents. Foltz [10] demonstrates the use of LSI for information filtering and evaluates it for filtering Netnews articles. [11] performs a similar experiment for the domain of technical reports.
Reference: [30] <author> Marcus, R. S., </author> <booktitle> Computer and Human Understanding in Intelligent Retrieval Assistance, Proceedings of the 54th American Society for Information Science meeting, </booktitle> <volume> Vol. 28, </volume> <month> October </month> <year> 1991, </year> <pages> pp. 49-59. </pages>
Reference-contexts: Agent research is concerned with issues of designing intelligent and autonomous software for a variety of tasks. This thesis draws upon work from both these areas. 2.1.1 Information Retrieval and Filtering Information Retrieval Three main retrieval paradigms can be identified <ref> [30] </ref> in the IR literature: (i) statistical (ii) semantic and (iii) contextual/structural. The first approach emphasizes statistical correlations of word counts in documents and document collections. Salton [38, 39] describes the use of statistical schemes such as probabilistic and vector space models for document representation and retrieval. <p> For example, this could involve the use of thesauri in which relationships among terms are encoded [12] or take advantage of context and structure generally available from the document terms <ref> [30] </ref>. CONIT [31] is an example of a system built in the "smart" Boolean framework. The Internet is one of the largest publicly available "databases" of documents (among other things) and is a good testing ground for most retrieval techniques. <p> So, for example, if FRAMER infers that the news story A is analogous to the news story B, if the user likes document A, the agent could also recommend document B. Another option is to use the contextual/structural retrieval paradigm <ref> [30] </ref>. In this framework, the user can also provide qualitative relevance feedback explaining why a document is not relevant. It is worth exploring the possibility of using these approaches for building better filtering engines. There are certain issues that one must bear in mind while designing filtering systems.
Reference: [31] <author> Marcus, R. S., Reintjes, J.F., </author> <title> A Translating Computer Interface for End-User Operation of Heterogenous Retrieval Systems; Part I: Design; Part II: Evaluations, </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 32(4), </volume> <year> 1981, </year> <pages> pp. 287-303, pp. 304-317. </pages>
Reference-contexts: For example, this could involve the use of thesauri in which relationships among terms are encoded [12] or take advantage of context and structure generally available from the document terms [30]. CONIT <ref> [31] </ref> is an example of a system built in the "smart" Boolean framework. The Internet is one of the largest publicly available "databases" of documents (among other things) and is a good testing ground for most retrieval techniques.
Reference: [32] <author> McCahill, M., </author> <title> The Internet Gopher: A Distributed Server Information System, Con-neXions The Interoperability Report, </title> <publisher> Interop, Inc., </publisher> <address> 6(7), </address> <month> July </month> <year> 1992, </year> <pages> pp. 10-14. </pages>
Reference-contexts: Wide Area Information Servers (WAIS) [21] is a networked based document indexing and retrieval system for textual data. The servers maintain inverted indexes of keywords that are used for efficient retrieval of documents. WAIS allows users to provide relevance feedback to further specialize an initial query. Gopher <ref> [32] </ref> is primarily a tool for browsing through hierarchically organized documents, but it also allows to search for information using full-text indexes. In the World Wide Web (WWW) [3], the information is organized using the hypertext paradigm where users can explore information by selecting hypertext links to other information.
Reference: [33] <author> Metral, M., </author> <title> Design of a Generic Learning Interface Agent, </title> <type> SB Thesis, </type> <institution> Department of Media Art and Sciences, Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: The meeting scheduling agent uses 15 memory-based reasoning and reinforcement learning to automate actions for the user. It can also use rules provided by the user and learn from examples of meeting in hypothetical situations. An electronic mail agent is described in <ref> [28, 33] </ref>. A number of products are commercially sold as agents in the market. Magnet, from No Hands Software, can automate filing, scheduling and similar tasks for the user. "Open Sesame!", from Charles River Associates Inc., is a learning agent that monitors the keyboard and mouse watching for repeating patterns.
Reference: [34] <author> Negroponte, N., </author> <title> The Architecture Machine: Towards a more Human Environment, </title> <publisher> MIT Press, </publisher> <year> 1970. </year>
Reference-contexts: Interface Agents are computer programs that automate repetitive tasks to provide assistance to a user dealing with a particular computer application. The idea of employing agents to delegate computer-based tasks goes back to research by Negroponte <ref> [34] </ref> and Kay [22]. The research in this field is directed toward the ideal of agents that have high-level human-like communication skills and can accept high-level goals and reliably translate these to low level tasks. Two approaches have been traditionally used for designing interface agents.
Reference: [35] <author> Orwant, J., </author> <title> Doppelganger Goes To School: Machine Learning for User Modeling, </title> <type> SM Thesis, </type> <institution> Department of Media Art and Sciences, Massachusetts Institute of Technology, </institution> <month> Sept </month> <year> 1993. </year>
Reference-contexts: The IIF agents learn using a combination of a genetic and economic algorithm. A number of different techniques have been used for modeling the user. Doppelganger <ref> [35] </ref> is a user modeling system that acquires information through many sensors. For example, the "badge sensor" transmits physical location of the user while a "login sensor" tracks when people log in to computers. <p> Furthermore, it does not explore newer information domains, which is the function of the mutation operator in Newt. The use of an economic system with GA for assigning payoffs 17 is interesting, however, and deserves further research. Doppelganger <ref> [35] </ref> is a user modeling system briefly described above. The most important distinction with our approach to user modeling and is that Doppelganger is application independent. Calling it a user modeling shell would be more appropriate to distinguish it from user models that are domain dependent. <p> The amount of user interaction required can be further reduced by use of more intelligent interfaces. "Smart badges" have been used for user modeling <ref> [35] </ref> to detect the physical location of the user. A possible application to our filtering system is to automatically assume positive feedback if the user spends a long time in front of the computer when the document is displayed. This would lessen the burden of interaction for the user.
Reference: [36] <author> Rau, L. F., </author> <title> Conceptual Information Extraction and Retrieval from Natural Language Input, Proceedings of RIAO 88: User-Oriented Content-Based Text and Image Handling, </title> <month> March </month> <year> 1988, </year> <pages> pp. 424-437. </pages>
Reference-contexts: Latent Semantic Indexing (LSI) [5] is another example of a statistical method to capture the term associations in documents. The semantic approach to retrieval characterizes the documents and queries so as to represent the underlying meaning <ref> [17, 36] </ref>. It emphasizes natural language processing or the use of 12 AI-like frames. The third approach, also known as "smart" Boolean, takes advantage of the structural and contextual information typically available in retrieval systems.
Reference: [37] <author> Rocchio, J. J., Jr., </author> <title> Relevance Feedback in Information Retrieval, The Smart System | Experiments in Automatic Document Processing, </title> <editor> ed. Salton, G., </editor> <publisher> Prentice-Hall Inc., </publisher> <year> 1971, </year> <pages> pp. 337-354. </pages>
Reference-contexts: Relevance feedback refers to the reformulation of a search query in response to feedback provided by the user for the results of previous versions of the query. Work on Relevance Feedback methods in IR has a long history [38]. It has been used for the vector space model <ref> [37] </ref> and found to significantly improve performance [40]. Another approach to modeling adaptation is the use of genetic algorithms (GA) to devise adaptive algorithms for information retrieval. Yang and Korfhage [47] evolve a population of query individuals to optimize the search.
Reference: [38] <author> Salton, G., McGill, M. J., </author> <title> Introduction to Modern Information Retrieval, </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: The first approach emphasizes statistical correlations of word counts in documents and document collections. Salton <ref> [38, 39] </ref> describes the use of statistical schemes such as probabilistic and vector space models for document representation and retrieval. The Smart system [42] is an example of a text processing and retrieval system based on the vector processing model. <p> IR has mostly dealt with the learning issue through relevance feedback. Relevance feedback refers to the reformulation of a search query in response to feedback provided by the user for the results of previous versions of the query. Work on Relevance Feedback methods in IR has a long history <ref> [38] </ref>. It has been used for the vector space model [37] and found to significantly improve performance [40]. Another approach to modeling adaptation is the use of genetic algorithms (GA) to devise adaptive algorithms for information retrieval. <p> Implementation issues have been dealt with in the following chapter. 3.1 Representation The representation used for profiles and documents is based on the vector space representation, commonly used in the information retrieval literature <ref> [38] </ref>. In the vector space representation, documents and queries are both represented as vectors in some hyper-space. A distance metric which measures the proximity of vectors to each other is defined over the space. <p> The weight of the term depends on its frequency of occurence in the text and the number of documents it appears in. This is a well known term weighting method for the vector-space model in the information retrieval literature <ref> [38] </ref> and has been adapted for the present use. The weight of a keyword-term is the product of its term frequency and its inverse document frequency. The term frequency (tf) is the occurence frequency of the term in the text and is normally reflective of term importance.
Reference: [39] <author> Salton, G., </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer, </title> <publisher> Addison Wesley Publishing, </publisher> <year> 1989. </year>
Reference-contexts: The contributions made by this thesis are as follows: * This thesis refines the statement of the personalized information filtering problem. Personalized filtering systems must be specialized to user interests, adaptive to preference changes and explore newer information domains. While the first two criteria have been addressed earlier <ref> [7, 39] </ref>, exploration has not been sufficiently emphasized before. * The vector space model for document representation has been generalized for use with documents containing more than just text. <p> The first approach emphasizes statistical correlations of word counts in documents and document collections. Salton <ref> [38, 39] </ref> describes the use of statistical schemes such as probabilistic and vector space models for document representation and retrieval. The Smart system [42] is an example of a text processing and retrieval system based on the vector processing model.
Reference: [40] <author> Salton, G., Buckley, C. </author> <title> Improving retrieval performance by relevance feedback. </title> <address> JASIS 41, </address> <year> 1990, </year> <pages> pp. 288-297. </pages>
Reference-contexts: Work on Relevance Feedback methods in IR has a long history [38]. It has been used for the vector space model [37] and found to significantly improve performance <ref> [40] </ref>. Another approach to modeling adaptation is the use of genetic algorithms (GA) to devise adaptive algorithms for information retrieval. Yang and Korfhage [47] evolve a population of query individuals to optimize the search. Gordon [14], on the other hand, uses a method where competing representations are associated with documents. <p> One is that the appropriate profile is modified in response to the feedback. The other is that the fitness of the profile responsible for the article is appropriately modified. 3.3.1 Feedback for retrieved documents Relevance feedback has been used to improve the performance of retrieval systems <ref> [40] </ref>. For vector space representations, the method for query reformulation in response to user feedback is vector adjustment.
Reference: [41] <author> Salton, G., Buckley, C. </author> <title> A note on Term Weighting and Text Matching. </title> <type> TR 90-1166, </type> <institution> Department of Computer Science, Cornell University, </institution> <year> 1990. </year>
Reference-contexts: Words may also be truncated to word-stems. Generally speaking, a "term" is used for text identification. Since the terms are not all equally important for content representation, importance factors (or weights) are assigned to the terms in proportion to their presumed importance for text content identification <ref> [41] </ref>. A text is then representable as a vector of terms T i =&lt; w ij &gt; where wij represents the weight of term t j in text T i . In the information filtering context being considered in this thesis, documents contain more than just text.
Reference: [42] <editor> Salton, G., ed. </editor> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer, </title> <publisher> Addison Wesley Publishing, </publisher> <year> 1989. </year> <month> 74 </month>
Reference-contexts: The first approach emphasizes statistical correlations of word counts in documents and document collections. Salton [38, 39] describes the use of statistical schemes such as probabilistic and vector space models for document representation and retrieval. The Smart system <ref> [42] </ref> is an example of a text processing and retrieval system based on the vector processing model. Latent Semantic Indexing (LSI) [5] is another example of a statistical method to capture the term associations in documents. <p> The user profile is acquired by talking to the users and having them fill out templates. Personalized news is delivered frequently through facsimile or email messages. The filtering is done by the Smart system <ref> [42] </ref>, augmented by human supervision. Learning and Adaptation in IR and IF There is relatively little difference between IR and IF at an abstract level, since both are concerned with the task of getting information to people who need it.
Reference: [43] <author> Schneiderman, B., </author> <title> Direct Manipulation: A Step Beyond Programming Languages, </title> <journal> IEEE Computer, </journal> <volume> Vol. 16(8), </volume> <year> 1983, </year> <pages> pp 57-59. </pages>
Reference-contexts: The most commonly pervasive metaphor for computer interaction is the direct manipulation metaphor <ref> [43] </ref> as manifested in contemporary desktop systems. The direct manipulation metaphor requires incremental actions on individual objects. This is highly inefficient when users want to manipulate sets of objects not individual objects, i.e. they want organization above the level of individual objects [46].
Reference: [44] <author> Sheth, B., Maes, P., </author> <title> Evolving Agents for Personalized Information Filtering, </title> <booktitle> Proceedings of the ninth IEEE Conference on AI for Applications, </booktitle> <year> 1993. </year>
Reference: [45] <author> Suchak, M.A., GoodNews: </author> <title> A Collaborative Filter for Network News, </title> <type> SM Thesis, </type> <institution> Department of Electrical Engineering and Computer Science, MIT, </institution> <month> Feb </month> <year> 1994. </year>
Reference-contexts: Users collaborate to help each other filter documents. Eager readers would be the 13 first ones to read incoming articles and provide their endorsements, which will be used by passive readers to filter articles, as in GoodNews <ref> [45] </ref>. The selection could either depend on personal criteria (e.g. endorsement by a friend), or on aggregate criteria (e.g. endorsements by more than half the group members).
Reference: [46] <author> Whittaker, S., Stenton, P., </author> <booktitle> User Studies and the Design of Natural Language Systems, Proceedings of 4th Conference of the European Chapter of the Association of Computational Linguistics, </booktitle> <year> 1989, </year> <pages> pp. 116-123. </pages>
Reference-contexts: The direct manipulation metaphor requires incremental actions on individual objects. This is highly inefficient when users want to manipulate sets of objects not individual objects, i.e. they want organization above the level of individual objects <ref> [46] </ref>. All actions have to be initiated by the user, which places an enormous burden of knowledge on the user. It is also difficult to extract explanations from the system or carry out asynchronous acts.
Reference: [47] <author> Yang, J., Korfhage, R. R., </author> <title> Query Optimization in Information Retrieval Using Genetic Algorithms, </title> <booktitle> Proceedings of the 5th International Conference on Genetic Algorithms, </booktitle> <address> Urbana, IL, </address> <year> 1993, </year> <pages> pp. 603-611. 75 </pages>
Reference-contexts: It has been used for the vector space model [37] and found to significantly improve performance [40]. Another approach to modeling adaptation is the use of genetic algorithms (GA) to devise adaptive algorithms for information retrieval. Yang and Korfhage <ref> [47] </ref> evolve a population of query individuals to optimize the search. Gordon [14], on the other hand, uses a method where competing representations are associated with documents. The representations are then altered over time using GA. Learning and adaptation is, however, of much greater importance in filtering contexts. <p> The information filtering agent searches new domains for information which could be of potential interest to the user. It is quite possible that user may not have seen the topic before. Our approach is quite similar to the work described in Yang and Korfhage <ref> [47] </ref>. They evolve a population of query individuals, we evolve a population of profile individuals. However, they assume that user interests are fixed and strive towards convergence. We assume dynamic user interests and our goal is to continually adapt.
References-found: 47

