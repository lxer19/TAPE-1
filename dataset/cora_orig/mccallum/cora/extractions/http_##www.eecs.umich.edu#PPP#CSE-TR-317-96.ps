URL: http://www.eecs.umich.edu/PPP/CSE-TR-317-96.ps
Refering-URL: http://www.eecs.umich.edu/PPP/publist.html
Root-URL: http://www.cs.umich.edu
Email: estam@eecs.umich.edu  davidson@eecs.umich.edu  
Title: Early Design Cycle Timing Simulation of Caches Preliminary Exam Report  
Author: Edward S. Tam Advisor: Edward S. Davidson 
Date: September 9, 1996  
Address: Ann Arbor, Michigan  
Affiliation: Department of Electrical Engineering and Computer Science The University of Michigan  
Abstract-found: 0
Intro-found: 0
Reference: [Bakoglu90] <author> H. B. Bakoglu and T. Whiteside, </author> <title> "RISC System/6000 Hardware Overview," </title> <institution> IBM RISC System/6000 Technology SA23-2619, International Business Machines Corporation, </institution> <year> 1990. </year> <pages> pp. 8 - 15. </pages>
Reference-contexts: The processor and cache simulator combines J-D Wellmans RCM_brisc tool, which simulates an RS/6000-like <ref> [Bakoglu90] </ref> machine, with the LE cache model.
Reference: [Bedichek95] <author> R. C. Bedicheck, Talisman: </author> <title> Fast and Accurate Multicomputer Simulation, </title> <booktitle> Proceedings of the 1995 ACM SIGMETRICS Conference, </booktitle> <year> 1995. </year>
Reference-contexts: The LE cache model, in its current implementation, could easily have been combined with any other currently available instruction-level simulators such as Talisman <ref> [Bedichek95] </ref>, SimICS [Magnusson95], and others. This is possible because this implementation of the LE cache model maintains the state of the caches itself and does not take into account virtual memory or TLB effects.
Reference: [Bose96] <institution> Personal communication, </institution> <month> June, </month> <year> 1996. </year>
Reference-contexts: Still, this performance is quite acceptable given the intended use of the simulator in the early design cycle. This performance is particularly impressive since it has been asserted that industrial processor simulators rarely accurately model the final product <ref> [Bose96] </ref>. Having a highly configurable, semantically accurate simulator can be of great use in deciding what parameter changes to investigate early in the design cycle while they are not yet fixed in stone.
Reference: [Gallivan90] <author> K. Gallivan et al., </author> <title> Experimentally Cha racterizing the Behavior of Multiprocessor Memory Systems: A Case Study, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 16, </volume> <month> February, </month> <year> 1990, </year> <pages> pp. </pages> <month> 216-223. </month> <title> Early Design Cycle Timing Simulation of Caches Preliminary Exam Report 64 </title>
Reference-contexts: When array_size is less than 4K, the average access rate is one clock cycle per data element, so we conclude that all accesses are cache hits (in the cache region <ref> [Gallivan90] </ref>). The RS/6000 Model 320H being parameterized in fact has a 32 Kbyte data cache (= 4K * 8 bytes). When the array size increases beyond 4K, some misses will occur (in the transition region [Gallivan90]). <p> data element, so we conclude that all accesses are cache hits (in the cache region <ref> [Gallivan90] </ref>). The RS/6000 Model 320H being parameterized in fact has a 32 Kbyte data cache (= 4K * 8 bytes). When the array size increases beyond 4K, some misses will occur (in the transition region [Gallivan90]). If array_size exceeds the cache size by less than the size of one full cache column (one block of each associative set), some of the data will never be replaced. The access times level off at array_size = 5K (the memory region [Gallivan90]) for each stride used, so we conclude <p> misses will occur (in the transition region <ref> [Gallivan90] </ref>). If array_size exceeds the cache size by less than the size of one full cache column (one block of each associative set), some of the data will never be replaced. The access times level off at array_size = 5K (the memory region [Gallivan90]) for each stride used, so we conclude that a column Early Design Cycle Timing Simulation of Caches Preliminary Exam Report 35 is (5K - 4K)* 8 bytes = 8 K and that the cache is therefore 32K/8K = 4-way set associative, as documented [Hardell90].
Reference: [Hardell90] <author> W. R. Hardell et al., </author> <title> "Data Cache and Storage Control Units," </title> <institution> IBM RISC System/6000 Technology SA23-2619, International Business Machines Corporation, </institution> <year> 1990. </year> <pages> pp. 44 - 51. </pages>
Reference-contexts: However, the bus width between the cache and the next level of memory is normally smaller than the block size of the cache. For instance, in the RS/6000 Model 320H <ref> [Hardell90] </ref>, the block size is 64 bytes, but the cacheto-memory bus is only 8 bytes wide, causing a block of data to return to the cache in multiple cycles. <p> array_size = 5K (the memory region [Gallivan90]) for each stride used, so we conclude that a column Early Design Cycle Timing Simulation of Caches Preliminary Exam Report 35 is (5K - 4K)* 8 bytes = 8 K and that the cache is therefore 32K/8K = 4-way set associative, as documented <ref> [Hardell90] </ref>. The average miss penalty is also dependent upon the stride used to access the array. Since stride 8, 16, and 32 all have the same performance, the cache block size must be 8 * 8 = 64 bytes, as documented for the Model 320H. <p> The RS/6000 cache uses a cache reload buffer (CRB) and a store data buffer (SDB) to buffer the newly requested block and the evicted block, respectively <ref> [Hardell90] </ref>. This leads to an NOA value of 1, i.e. a hit-under-miss cache where a miss access that occurs while an earlier miss is outstanding will stall the cache.
Reference: [Hennessy96] <author> J. L. Hennessy and D. A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach, </title> <publisher> Morgan Kaufman Publishers Inc., </publisher> <address> San Francisco, California, </address> <year> 1996. </year> <pages> pp. 373 - 427. </pages>
Reference-contexts: The first level of the memory hierarchy encountered once the address leaves the CPU is generally a cache <ref> [Hennessy96] </ref>. The use of caches is based on the principle of locality, which says that most programs do not access all code or data uniformly. Instead, code or data is accessed in groups (spatial locality) or it is accessed repeatedly in a short period of time (temporal locality). <p> When a read miss occurs, a block in the cache is replaced with the desired data. There are several methods to determine which block should be replaced (Least Recently Used, random, and optimal, among others) <ref> [Hennessy96] </ref>. Some approximation of the LRU replacement algorithm is usually used in todays caches. Random replacement is sometimes used in large caches to reduce the Early Design Cycle Timing Simulation of Caches Preliminary Exam Report 5 implementation cost. Our simulations assume LRU replacement, but other strategies can be selected.
Reference: [Hill85] <author> M. D. Hill, </author> <title> DineroIII Documentation, </title> <institution> Unpublished UNIX-style Man Page, University of California, Berkeley, </institution> <month> October </month> <year> 1985. </year>
Reference-contexts: Furthermore, the statistics output by the LE tool aid the designers and programmers in determining the bottlenecks and underutilized resources of the configuration. 3.1 Currently available behavioral cache simulators Many behavioral cache simulators are currently available, including DineroIII <ref> [Hill85] </ref>, ACS [PARL95], Fast-Cache [Lebeck95], and others. <p> DineroIII and the Resource Conflict Methodology are described in the next two sections, followed by the implementation of the LE cache model. 4.1 DineroIII DineroIII <ref> [Hill85] </ref> is a parameterizeable, tracedriven cache simulator developed by Mark Hill. DineroIII takes a trace of memory accesses as input and determines, for each access, whether the access hits or misses based on the state of the cache at the time of the access.
Reference: [Lebeck95] <author> A. R. Lebeck and D. A. Wood, </author> <title> Active Memory: A New Abstraction for Memory-System Simulation, </title> <booktitle> Proceedings of the 1995 ACM SIGMETRICS Conference, </booktitle> <month> May, </month> <year> 1995. </year>
Reference-contexts: Furthermore, the statistics output by the LE tool aid the designers and programmers in determining the bottlenecks and underutilized resources of the configuration. 3.1 Currently available behavioral cache simulators Many behavioral cache simulators are currently available, including DineroIII [Hill85], ACS [PARL95], Fast-Cache <ref> [Lebeck95] </ref>, and others. <p> Other simulators which are much more detailed have reported success when their simulation output has come within 32% of actual execution times <ref> [Lebeck95] </ref>. Considering the fact that this simulator is supposed to give a good picture of program/processor performance and not the actual runtimes, the results look very good.
Reference: [Magnusson95] <author> P. Magnusson and B. Werner, </author> <title> Efficient Memory Simulation in SimICS, </title> <booktitle> Proceedings of the 28th Annual Simulation Symposium, </booktitle> <month> April, </month> <year> 1995. </year>
Reference-contexts: The LE cache model, in its current implementation, could easily have been combined with any other currently available instruction-level simulators such as Talisman [Bedichek95], SimICS <ref> [Magnusson95] </ref>, and others. This is possible because this implementation of the LE cache model maintains the state of the caches itself and does not take into account virtual memory or TLB effects.
Reference: [McMahon86] <author> F. H. McMahon, </author> <title> "The Livermore FORTRAN Kernel: A Computer Test of the Numerical Performance Range," </title> <type> Technical Report UCRL-53745, </type> <institution> Lawrence Livermore National Laboratory, </institution> <month> December </month> <year> 1986. </year>
Reference-contexts: Section 5.2.1 shows the results of simulating the load/store kernels on the three simulators, while Section 5.2.2 presents the simulation results for the first nine Livermore Loop Kernels <ref> [McMahon86] </ref>. Early Design Cycle Timing Simulation of Caches Preliminary Exam Report 39 5.2.1 Load/store kernel simulation performance We traced the execution of each load and store kernel running on an IBM RS/6000 Model 320H using the Atrace tracing package developed by Ravi Nair of the IBM T.J. Watson Research Lab.
Reference: [Olsson90] <author> B. Olsson et al., </author> <title> "RISC System/6000 Floating-Point Unit," </title> <institution> IBM RISC System/6000 Technology SA23-2619, International Business Machines Corporation, </institution> <year> 1990. </year> <pages> pp. 34 - 43. </pages>
Reference-contexts: cache characteristics of the RS/6000 Model 320H; these characteristics were obtained via the load/store kernels, as described above, and literature detailing the RS/6000's cache [Hardell90]<ref> [Olsson90] </ref>. The RS/6000 has one read port and one write port to the cache, and it is a write back, write allocate configuration, as described in [Olsson90]. The RS/6000 cache uses a cache reload buffer (CRB) and a store data buffer (SDB) to buffer the newly requested block and the evicted block, respectively [Hardell90].
Reference: [PARL95] <institution> Parallel Architecture Research Lab, README file, New Mexico State University, </institution> <address> New Mexico, </address> <year> 1995. </year>
Reference-contexts: Furthermore, the statistics output by the LE tool aid the designers and programmers in determining the bottlenecks and underutilized resources of the configuration. 3.1 Currently available behavioral cache simulators Many behavioral cache simulators are currently available, including DineroIII [Hill85], ACS <ref> [PARL95] </ref>, Fast-Cache [Lebeck95], and others.
Reference: [Rivers96] <author> J. A. Rivers and E. S. Davidson, </author> <title> Reducing Conflicts in Direct-Mapped Caches with a Temporality-Based Design, </title> <booktitle> Proceedings of the 1996 ICPP , vol. </booktitle> <address> I., Bloomingdale, IL, </address> <month> August 12-16, </month> <year> 1996, </year> <pages> pp. 151 - 160. </pages>
Reference-contexts: Since the LE cache model is implemented on top of the DineroIII behavioral cache simulator, any other work that has been built on the DineroIII platform will be easily incorporated into the LE cache simulator. An example is the nontemporal streaming (NTS) cache presented by Rivers <ref> [Rivers96] </ref>. This and other novel cache configurations can easily be incorporated into the LE simulation model, providing designers with effective performance estimates of a wider variety of target cache configurations, regardless of whether they are existing or new, novel configurations.
Reference: [Shih92] <author> T-P Shih, </author> <title> "Performance Evaluation of IBM RS/6000," Directed Study Report, </title> <institution> University of Michigan, Ann Arbor, Michigan, </institution> <year> 1992. </year>
Reference-contexts: The reason that the machine does not obtain 1 store per cycle is discussed in <ref> [Shih92] </ref>. From this figure, we can draw the same conclusions about the cache configuration as we did using the load kernel: the cache is 4-way set associative with 64 byte blocks and a 32 Kbyte capacity. Also, the maximum rate of servicing consecutive stores is one miss per 17.1 clocks.
Reference: [Mangionne-Smith93] <author> W. Mangionne-Smith et al., </author> <title> Approaching a Machine-Application Bound in Delivered Performance on Scientific Code, Proceedings of the IEEE: Special Early Design Cycle Timing Simulation of Caches Preliminary Exam Report 65 Issue on Computer Performance Evaluation, </title> <journal> vol. </journal> <volume> 81, </volume> <month> August, </month> <year> 1993, </year> <pages> pp. 1166-1178. </pages>
Reference-contexts: From the stride 8 curve, we also conclude that cache misses due to consecutive loads can be serviced at a maximum rate of one miss per 11.4 clocks. The bus width between the cache and the next level of memory can also be determined from this data, as in <ref> [Mangionne-Smith93] </ref>; the cache-to-memory bus width for this machine is 8 bytes.
Reference: [Shih96] <institution> T-P Shih , Goal-Directed Performance Tuning for Scientific Applications, </institution> <type> Ph.D. Dissertation, </type> <institution> University of Michigan, Ann Arbor, Michigan, </institution> <year> 1996. </year>
Reference-contexts: Also, knowledge of the number of trailing edge accesses can help the programmer lay out data and access memory in a more efficient manner so as to avoid these additional delays during program execution <ref> [Shih96] </ref>. 8.0 Conclusion A new cache model has been developed that incorporates various effects into the simulation of a sequence of memory accesses. In addition to nominal hit and coldstart/capacity/conflict misses, Early Design Cycle Timing Simulation of Caches Preliminary Exam Report 61 delayed hits are now modeled.
Reference: [Wellman95] <author> J-D Wellman and E. S. Davidson, </author> <title> "The Resource Conflict Methodology for Early-Stage Design Space Exploration of Superscalar RISC Processors," </title> <booktitle> Proceedings of the 1995 ICCD, </booktitle> <address> Austin, Texas, </address> <month> October 2-4, </month> <year> 1995. </year> <pages> pp. 110-115 </pages>
Reference-contexts: Specific latency-adding effects are derived from the experimental model as a function of the specific reference patterns in the trace. As a first step in assessing the correctness of the LE cache model, the cache simulator has been combined with J-D Wellman's RCM_brisc tool <ref> [Wellman95] </ref>, which is based upon his Resource Conflict Methodology (detailed in Section 4.2). Together, the combined tool, RCM_brisc+LE, simulates an RS/6000-like (POWER) microprocessor with cache. <p> Statistics reported at the end of the simulation include the number of read and write hits and misses to the cache, the number of words transferred, and the total number of memory accesses. 4.2 Resource Conflict Methodology The Resource Conflict Methodology (RCM) <ref> [Wellman95] </ref> was proposed by J-D Wellman as a technique for modeling and simulating computer systems early in the design cycle. Each element of the simulated processor is viewed as a resource that may be unavailable at a given time.
Reference: [Wellman96] <author> J-D Wellman, </author> <title> Processor Modeling and Evaluation Techniques for Early Design Stage Performance Comparison, </title> <booktitle> Ph.D. Dissertation in progress, </booktitle> <year> 1996. </year>
References-found: 18

