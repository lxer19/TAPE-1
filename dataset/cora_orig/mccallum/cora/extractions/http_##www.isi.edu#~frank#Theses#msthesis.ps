URL: http://www.isi.edu/~frank/Theses/msthesis.ps
Refering-URL: http://www.isi.edu/~frank/Theses/theses.html
Root-URL: http://www.isi.edu
Title: Adaptive and Automated Index Selection in Relational Databases  
Author: Martin Robert Frank 
Degree: A Thesis Presented To The Academic Faculty by  In Partial Fulfillment of the Requirements for the Degree Master of Science in  
Date: May 1991  
Affiliation: Information and Computer Science Georgia Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [BM72] <author> R. Bayer and E. McCreight. </author> <title> Organization and Maintenance of Large Ordered Indices. </title> <journal> Acta Informatica, </journal> <volume> 1, </volume> <year> 1972. </year>
Reference-contexts: Highly relevant research is discussed in detail while peripheral research is briefly mentioned. The original proposal of the relational model for database systems is [Cod70]. Bayer and McCreight <ref> [BM72] </ref> invented the B-tree structure for indices which is now a de-facto standard for secondary indices in commercial systems. Stonebraker was the first to thoroughly formalize the index selection problem in [Sto74]. The paper presents insight into the difficulty of the problem and derives solutions for special cases.
Reference: [BMT85] <author> R. Bonanno, D. Maio, and P. Tiberio. </author> <title> An Approximation Algorithm for Secondary Index Selection in Relational Database Physical Design. </title> <journal> Computer Journal, </journal> <volume> 28(4), </volume> <month> August </month> <year> 1985. </year>
Reference-contexts: To our knowledge no tracing tool exists that efficiently collects such statistical information. The query language is restricted: only restrictions of the kind "attribute = CHAPTER 2. SURVEY OF RELEVANT LITERATURE 9 value" no joins, range queries, nested queries etc. are considered. Bonanno et al. <ref> [BMT85] </ref> present an approximation algorithm for secondary index selection that is linear in the number of attributes, if the used join methods are separable (see [WWS81]).
Reference: [Cod70] <author> E. F. Codd. </author> <title> A Relational Model of Data for Large Shared Data Banks. </title> <journal> CACM, </journal> <volume> 13(6), </volume> <month> June </month> <year> 1970. </year>
Reference-contexts: Highly relevant research is discussed in detail while peripheral research is briefly mentioned. The original proposal of the relational model for database systems is <ref> [Cod70] </ref>. Bayer and McCreight [BM72] invented the B-tree structure for indices which is now a de-facto standard for secondary indices in commercial systems. Stonebraker was the first to thoroughly formalize the index selection problem in [Sto74].
Reference: [Com78] <author> D. Comer. </author> <title> The Difficulty of Optimum Index Selection. </title> <journal> ACM-TODS, </journal> <volume> 3(4), </volume> <month> De-cember </month> <year> 1978. </year>
Reference-contexts: SURVEY OF RELEVANT LITERATURE 8 configuration. Hammer and Chan envision fully-automated index selection in [HC76] but their approach is unrealistic for real-life databases in various ways. This research is summarized in section 2.3. Comer <ref> [Com78] </ref> proves that the optimum index selection problem is computationally costly (NP-complete) even without considering combined indices and multiple relations. Thus all practical index selection algorithms will be approximation algorithms. Schkolnick's survey paper [Sch78] summarizes research in the area and provides an ex tensive bibliography.
Reference: [Com79] <author> D. Comer. </author> <title> The Ubiquitous B-tree. </title> <journal> ACM Computing Surveys, </journal> <volume> 11(2), </volume> <month> June </month> <year> 1979. </year>
Reference-contexts: Thus all practical index selection algorithms will be approximation algorithms. Schkolnick's survey paper [Sch78] summarizes research in the area and provides an ex tensive bibliography. Comer discusses the use and performance of B-tree index variants in <ref> [Com79] </ref>. Whang et al. [WWS81] present an index selection method based on a set of join methods that is separable. This property reduces the index selection problem to finding a locally optimal index configuration for each relation. The method is restricted to single indices and specific join methods.
Reference: [FST88] <author> S. Finkelstein, M. Schkolnick, and P. Tiberio. </author> <title> Physical Database Design for Relational Databases. </title> <journal> ACM-TODS, </journal> <volume> 13(1), </volume> <month> March </month> <year> 1988. </year>
Reference-contexts: INTRODUCTION 4 to chose a good index configuration in the environment of a large integrated database. Tools were proposed which relieve some of this burden from the DBA, however even the most sophisticated ones like DBDSGN <ref> [FST88] </ref> still require the DBA to manually specify the workload. For this tool the designer has to specify the workload as a small set of weighted representative queries. <p> CHAPTER 1. INTRODUCTION 6 unlikely to capture real usage 3. Classify queries into categories, and adjust the weights of the categories for every incoming query. Weighted categories are the input for DBDSGN <ref> [FST88] </ref> so this tool would take care of the rest of the index selection procedure. <p> Schkolnick and Tiberio derive analytical formulas for the cost of Inserts, Deletes and Updates in [ST85]. Finkelstein, Schkolnick and Tiberio <ref> [FST88] </ref> describe the methodology used by DBDSGN, a tool for index selection which proposes physical designs for a representative transaction set. <p> Then secondary index selection is terminated without evaluating any other indices, with the tool possibly proposing an empty index set. 5. A more general problem that [WWS81] shares with <ref> [FST88] </ref> is that the "representative" query set might not be representative of the real workload. The problem here is that the representative set has to be of moderate size for complexity reasons. Assuming a transaction rate of hundred queries per minute for a large integrated database, CHAPTER 2. <p> So if the index selection tool is to be used on a weekly basis a moderate number of queries have to be selected to be representative. This selection is not trivial. 2.5 Finkelstein et al. 1988 <ref> [FST88] </ref> explains the index selection methodology used by the commercially available physical design tool RDT (Relational Design Tool) and its experimental prototype DBDSGN (DataBase DeSiGN Tool). 2.5.1 Content The input of the tool is a weighted representative set of transactions for which the index configuration is approximately optimized. <p> Thus in the local elimination for t 1 the join index might eliminate the restriction index. However if there is a restriction index on t 2 the optimizer may choose to use both restriction indices 4 This is a simplification. The original definition in <ref> [FST88] </ref> also requires that the storage cost of the *-dominated index is not significantly lower than the storage cost of the dominating index. CHAPTER 2. SURVEY OF RELEVANT LITERATURE 31 and perform a nested loop join on the reduced tables. <p> To our knowledge no tool was ever presented that is capable of detecting beneficial combined indices. 7 At this moment our tool is tailored for secondary indices, but the extension to include primary (clustered) indices is straightforward. The methodology would then be to present 7 DBDSGN <ref> [FST88] </ref> has the option of specifying particular combined indices to be evaluated but it cannot detect such desirable combined indices itself. CHAPTER 3. <p> a given statement it must be able to export the index set it would chose and it's cost estimate for processing the query using this set: optimizer (st: statement fi presented-with: index-set) ! chosen: index-set fi cost: real The difference of this requirement as compared to the existing EXPLAIN statements <ref> [FST88] </ref> is that the combined functionality of the EXPLAIN COST and EXPLAIN PLAN statements CHAPTER 3. THE PROPOSED TOOL 41 only provides for the following: optimizer (st: statement) ! chosen: index-set fi cost: real So EXPLAIN statements can only provide optimizer information based on the currently existing index configuration. <p> The simulations done in the context of this research also resulted in a ready-to-use o*ine tool, which tailors the physical database design to a batch of queries provided to the tool as does DBDSGN <ref> [FST88] </ref>.
Reference: [HC76] <author> M. Hammer and A. Chan. </author> <title> Index Selection in a Self-Adaptive Data Base Management System. </title> <booktitle> In Proceedings of the ACM-SIGMOD Conference in Washington D.C., </booktitle> <month> June </month> <year> 1976. </year>
Reference-contexts: Retain all queries until the next evaluation run 4 . This is the approach proposed in <ref> [HC76] </ref> for a severely restricted query language. + no information lost + minimal overhead at query execution large storage requirements complex evaluation 2. Keep some queries (e.g. every nth query). <p> INTRODUCTION 6 unlikely to capture real usage 3. Classify queries into categories, and adjust the weights of the categories for every incoming query. Weighted categories are the input for DBDSGN [FST88] so this tool would take care of the rest of the index selection procedure. Classification was done by <ref> [HC76] </ref> for a query language trivial to classify, classification has not been proposed for the general case. + minimal storage requirements + DBDSGN already takes care of a variety of physical factors, so the tool would just have to collect usage statistics classification of the queries seems impossible for an unrestricted <p> However the transaction model is restricted and a - computationally complex Knapsack problem has to be solved to find an optimal index 7 CHAPTER 2. SURVEY OF RELEVANT LITERATURE 8 configuration. Hammer and Chan envision fully-automated index selection in <ref> [HC76] </ref> but their approach is unrealistic for real-life databases in various ways. This research is summarized in section 2.3. Comer [Com78] proves that the optimum index selection problem is computationally costly (NP-complete) even without considering combined indices and multiple relations. Thus all practical index selection algorithms will be approximation algorithms. <p> See 2.1.2 for the general problems of analytical approaches for a statistics-collecting index selection tool. 2.3 Hammer and Chan 1976 The paper <ref> [HC76] </ref> first brought up the vision of fully automated index selection, where the system adopts the current index configuration based on automatically gathered statistics so that users do not even have to know about the concept of indices. <p> CHAPTER 2. SURVEY OF RELEVANT LITERATURE 23 The steps are: 1. Compute the reference frequency for each column in the database using the equivalent restriction frequencies for join queries. 2. Rank all columns in the database by frequency fi relation size fi (1 selectivity) as in <ref> [HC76] </ref>. The above expression denotes the maximum number of block accesses saved by an index on the column. 3. Let the index set s consist of all indices that have ever been used as a join index in the first phase. <p> CHAPTER 2. SURVEY OF RELEVANT LITERATURE 32 2.5.2 Discussion DBDSGN is the first commercial index selection tool. It does not deal with multiple indices but includes selection of the clustered index. All legal SQL statements are valid input for the tool. As in <ref> [HC76] </ref> index statistics 6 are observed for existing indices and estimated for nonexisting indices. If the estimations are consistently lower (or higher) than reality, then non-existing indices are favored above non-existing ones (or vice-versa). <p> The nice property of this approach is that no explicit statistics are stored, there is only a simple value per attribute which indicates its indexing desirability. Thus there is no need for a time-consuming evaluation run as in <ref> [HC76] </ref>. In their approach statistics are accumulated and evaluated later, consequently a large amount of data accumulates (storage consumption, complex evaluation) which can only be transformed into a useful format by the said run. This evaluation is trivial for our tool use the indices with positive indexing desirability. <p> Therefore this document does not contain sections like "assumptions about the query language", "... the storage organization", "... the optimizer", "... the join methods used", "... the indexing techniques" etc., as found in research at least partially based on analytical models ([Sto74] [Sch75] [YW75] <ref> [HC76] </ref> [WWS81] [ISR83]). 3.2.1 Cost Estimations for Virtual Index Configurations However we do require that the optimizer can export its behavior. <p> It may be desirable to combine the results of the last several recording periods. A standard solution also used in <ref> [HC76] </ref> is to use exponential smoothing to combine the results of the last recording periods. 4. Take index storage cost into account. So far our tool strictly optimizes the average query execution time without considering the tradeoff between execution time and index storage requirements.
Reference: [HS78] <author> E. Horowitz and S. Sahni. </author> <title> Fundamentals of Computer Algorithms. </title> <publisher> Computer Science Press, </publisher> <year> 1978. </year>
Reference-contexts: The main contribution is the reduction of the index selection problem to the knapsack problem (under the condition that the number of tuples in the relation is large). This makes well-known approximation algorithms for the knapsack problem from <ref> [HS78] </ref> applicable. The approach has the general problems of analytical cost formulas (outdated by changes to the system, substantial simplifications to allow analytical treatment) as well as the problem of collecting the statistical information used in the cost formula.
Reference: [ISR83] <author> M. Ip, L. Saxton, and V. Raghavan. </author> <title> On the Selection of an Optimal Set of Indexes. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-9(2), </volume> <month> March </month> <year> 1983. </year>
Reference-contexts: This property reduces the index selection problem to finding a locally optimal index configuration for each relation. The method is restricted to single indices and specific join methods. We will discuss this research in section 2.4. Ip et al. <ref> [ISR83] </ref> use a refined version of Schkolnick's [Sch75] probabilistic model of database activity in a single-relation environment. The refinement is that creation and storage costs of indices are modeled. <p> Therefore this document does not contain sections like "assumptions about the query language", "... the storage organization", "... the optimizer", "... the join methods used", "... the indexing techniques" etc., as found in research at least partially based on analytical models ([Sto74] [Sch75] [YW75] [HC76] [WWS81] <ref> [ISR83] </ref>). 3.2.1 Cost Estimations for Virtual Index Configurations However we do require that the optimizer can export its behavior.
Reference: [Ora88] <author> Oracle Corporation. </author> <title> ORACLE RDBMS Database Administrator's Guide Version 6.0, </title> <month> November </month> <year> 1988. </year> <title> Part No. </title> <publisher> 3601-V6.0. </publisher>
Reference-contexts: The sum of the cr and cur columns yields the total number of blocks accessed. rows The total number of rows processed. The Performance Tuning Guide [Ora89] describes the tracing facility in more detail. The Database Administrator's Guide <ref> [Ora88] </ref> gives an introduction into the concepts of the implementation of the ORACLE DBMS.
Reference: [Ora89] <author> Oracle Corporation. </author> <title> ORACLE RDBMS Performance Tuning Guide Version 6.0, </title> <month> August </month> <year> 1989. </year> <title> Part No. </title> <publisher> 5317-V6.0. </publisher>
Reference-contexts: The sum of the cr and cur columns yields the total number of blocks accessed. rows The total number of rows processed. The Performance Tuning Guide <ref> [Ora89] </ref> describes the tracing facility in more detail. The Database Administrator's Guide [Ora88] gives an introduction into the concepts of the implementation of the ORACLE DBMS.
Reference: [Sch75] <author> M. Schkolnick. </author> <title> The Optimal Selection of Secondary Indices for Files. </title> <journal> Information Systems, </journal> <volume> 1, </volume> <year> 1975. </year>
Reference-contexts: Stonebraker was the first to thoroughly formalize the index selection problem in [Sto74]. The paper presents insight into the difficulty of the problem and derives solutions for special cases. We will discuss this work in detail in section 2.1. Schkolnick <ref> [Sch75] </ref> presents a more general model of database activity than Stonebraker did and an algorithm that solves the index selection problem significantly faster than the naive approach. A detailed summary of this paper can be found in section 2.2. <p> This property reduces the index selection problem to finding a locally optimal index configuration for each relation. The method is restricted to single indices and specific join methods. We will discuss this research in section 2.4. Ip et al. [ISR83] use a refined version of Schkolnick's <ref> [Sch75] </ref> probabilistic model of database activity in a single-relation environment. The refinement is that creation and storage costs of indices are modeled. The main contribution is the reduction of the index selection problem to the knapsack problem (under the condition that the number of tuples in the relation is large). <p> In this case the physical characteristics have to be adjusted when the underlying hardware changes. The model becomes obsolete if there are changes to the query processing strategy or to other modeled aspects of the DBMS. 2.2 Schkolnick 1975 In the first part of <ref> [Sch75] </ref> a probabilistic model of database activity is constructed, including insertions and deletions. As in [Sto74] a cost function is derived that gives the expected average transaction execution cost depending on the index configuration. Only a single CHAPTER 2. <p> Therefore this document does not contain sections like "assumptions about the query language", "... the storage organization", "... the optimizer", "... the join methods used", "... the indexing techniques" etc., as found in research at least partially based on analytical models ([Sto74] <ref> [Sch75] </ref> [YW75] [HC76] [WWS81] [ISR83]). 3.2.1 Cost Estimations for Virtual Index Configurations However we do require that the optimizer can export its behavior.
Reference: [Sch78] <author> M. Schkolnick. </author> <title> A Survey of Physical Database Design Methodology and Techniques. </title> <booktitle> In Proceedings of the Very Large Data Base Conference in Berlin, Septem-ber 1978. </booktitle> <volume> 74 BIBLIOGRAPHY 75 </volume>
Reference-contexts: This research is summarized in section 2.3. Comer [Com78] proves that the optimum index selection problem is computationally costly (NP-complete) even without considering combined indices and multiple relations. Thus all practical index selection algorithms will be approximation algorithms. Schkolnick's survey paper <ref> [Sch78] </ref> summarizes research in the area and provides an ex tensive bibliography. Comer discusses the use and performance of B-tree index variants in [Com79]. Whang et al. [WWS81] present an index selection method based on a set of join methods that is separable.
Reference: [ST85] <author> M. Schkolnick and P. Tiberio. </author> <title> Estimating the Cost of Updates in a Relational Database. </title> <journal> ACM-TODS, </journal> <volume> 10(2), </volume> <month> June </month> <year> 1985. </year>
Reference-contexts: There are also the problems of the restricted join method set and of condensing the real workload into a small representative query set (part of the input to the tool). Schkolnick and Tiberio derive analytical formulas for the cost of Inserts, Deletes and Updates in <ref> [ST85] </ref>. Finkelstein, Schkolnick and Tiberio [FST88] describe the methodology used by DBDSGN, a tool for index selection which proposes physical designs for a representative transaction set.
Reference: [Sto74] <author> M. Stonebraker. </author> <title> The Choice of partial Inversions and Combined Indices. </title> <journal> International Journal of Computer and Information Sciences, </journal> <volume> 3(2), </volume> <month> June </month> <year> 1974. </year>
Reference-contexts: The original proposal of the relational model for database systems is [Cod70]. Bayer and McCreight [BM72] invented the B-tree structure for indices which is now a de-facto standard for secondary indices in commercial systems. Stonebraker was the first to thoroughly formalize the index selection problem in <ref> [Sto74] </ref>. The paper presents insight into the difficulty of the problem and derives solutions for special cases. We will discuss this work in detail in section 2.1. <p> Finkelstein, Schkolnick and Tiberio [FST88] describe the methodology used by DBDSGN, a tool for index selection which proposes physical designs for a representative transaction set. The details of this tool are discussed in section 2.5. 2.1 Stonebraker 1974 In <ref> [Sto74] </ref> a probabilistic model for database activity is presented and the index selection problem (for a single relation, no combined indices) is solved for certain special cases in polynomial time. 2.1.1 Content The problem is stated as finding the index configuration that minimizes the average expected query execution time which is <p> The model becomes obsolete if there are changes to the query processing strategy or to other modeled aspects of the DBMS. 2.2 Schkolnick 1975 In the first part of [Sch75] a probabilistic model of database activity is constructed, including insertions and deletions. As in <ref> [Sto74] </ref> a cost function is derived that gives the expected average transaction execution cost depending on the index configuration. Only a single CHAPTER 2. SURVEY OF RELEVANT LITERATURE 13 relation and no combined indices are considered. <p> In the second part, an algorithm is presented that finds an optimal index configuration provided that the target function is restricted to be regular; we will discuss this property shortly. It is shown that the algorithm runs in less then exponential time. 2.2.1 Content As in <ref> [Sto74] </ref> the cost function yields the average expected cost per transaction depending on the index configuration. <p> For regular functions it is guaranteed that the global optimum is among those sets. Schkolnick then proves that his particular cost function is regular and that an upper bound for the greedy algorithm is O (2 p 2.2.2 Discussion The model takes more statistical properties into account than <ref> [Sto74] </ref>. It is adaptable to different physical index schemes by providing the functions f and f 0 , which encapsulate the physical factors. An algorithm that finds the optimum index configuration under fairly general assumptions in less than O (2 n ) is presented. CHAPTER 2.
Reference: [WWS81] <author> K.Y. Whang, G. Wiederhold, and D. Sagalowicz. </author> <title> Separability an Approach to Physical Database Design. </title> <booktitle> In Proceedings of the Very Large Data Base Conference in Cannes, </booktitle> <month> September </month> <year> 1981. </year>
Reference-contexts: Thus all practical index selection algorithms will be approximation algorithms. Schkolnick's survey paper [Sch78] summarizes research in the area and provides an ex tensive bibliography. Comer discusses the use and performance of B-tree index variants in [Com79]. Whang et al. <ref> [WWS81] </ref> present an index selection method based on a set of join methods that is separable. This property reduces the index selection problem to finding a locally optimal index configuration for each relation. The method is restricted to single indices and specific join methods. <p> SURVEY OF RELEVANT LITERATURE 9 value" no joins, range queries, nested queries etc. are considered. Bonanno et al. [BMT85] present an approximation algorithm for secondary index selection that is linear in the number of attributes, if the used join methods are separable (see <ref> [WWS81] </ref>). However the performance of the algorithm is unclear, there is no theoretical bound on how far away the result may be from the true optimum. <p> In this case it would be better to do estimations for both partitions to guarantee uniform treatment even if more accurate data is available for s i . 2.4 Whang et al. 1981 <ref> [WWS81] </ref> is a theoretical approach to the multiple-relation single-index selection problem, assuming that the join methods used fulfill separability. This property reduces the problem to local optimization for each relation. CHAPTER 2. <p> Then secondary index selection is terminated without evaluating any other indices, with the tool possibly proposing an empty index set. 5. A more general problem that <ref> [WWS81] </ref> shares with [FST88] is that the "representative" query set might not be representative of the real workload. The problem here is that the representative set has to be of moderate size for complexity reasons. <p> The designer could choose not to specify any of these parameters but then the execution time would become impractical for a large database. The most significant problem is the same as in <ref> [WWS81] </ref> finding a "representative" transaction set for the real database usage. In a database of the magnitude of 100 relations this set would have to include at least one reference for each table and probably much more to be anywhere near realistic. <p> Therefore this document does not contain sections like "assumptions about the query language", "... the storage organization", "... the optimizer", "... the join methods used", "... the indexing techniques" etc., as found in research at least partially based on analytical models ([Sto74] [Sch75] [YW75] [HC76] <ref> [WWS81] </ref> [ISR83]). 3.2.1 Cost Estimations for Virtual Index Configurations However we do require that the optimizer can export its behavior.
Reference: [YW75] <author> P.C. Yue and C.K. Wong. </author> <title> Storage Cost Considerations in Secondary Index Selection. </title> <journal> International Journal of Computer and Information Sciences, </journal> <volume> 4(4), </volume> <month> De-cember </month> <year> 1975. </year>
Reference-contexts: Schkolnick [Sch75] presents a more general model of database activity than Stonebraker did and an algorithm that solves the index selection problem significantly faster than the naive approach. A detailed summary of this paper can be found in section 2.2. Yue and Wong <ref> [YW75] </ref> extend the optimality criterion for an index configuration to include the storage cost of the indices. However the transaction model is restricted and a - computationally complex Knapsack problem has to be solved to find an optimal index 7 CHAPTER 2. SURVEY OF RELEVANT LITERATURE 8 configuration. <p> Therefore this document does not contain sections like "assumptions about the query language", "... the storage organization", "... the optimizer", "... the join methods used", "... the indexing techniques" etc., as found in research at least partially based on analytical models ([Sto74] [Sch75] <ref> [YW75] </ref> [HC76] [WWS81] [ISR83]). 3.2.1 Cost Estimations for Virtual Index Configurations However we do require that the optimizer can export its behavior.
References-found: 17

