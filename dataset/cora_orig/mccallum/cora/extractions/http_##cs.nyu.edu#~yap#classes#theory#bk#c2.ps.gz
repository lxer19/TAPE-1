URL: http://cs.nyu.edu/~yap/classes/theory/bk/c2.ps.gz
Refering-URL: http://cs.nyu.edu/~yap/classes/theory/bk/
Root-URL: http://www.cs.nyu.edu
Title: Chapter 2 The Turing Model: Basic  
Note: 2.1 Introduction 2 One is reminded of Sir Arthur Eddington's elephants, in his essays in Nature of the Physical World. 51  
Abstract: Results We take the Turing model of computation as the canonical one in Complexity Theory. In this we are simply following the usual practice but other more logical reasons can be given: the fundamental analysis by which Turing arrives at his model is still one of the most cogent arguments in support of Church's thesis. 1 The simplicity of Turing's basic model is appealing. Despite the fact that Turing predated our computer age, there is a striking resemblance between his machines and modern notions of computation. Henceforth, any new model that we introduce shall (perhaps only implicitly) be compared with this canonical choice. Of course, Turing considered only the fundamental mode of computation but we can naturally adapt it to the other computational modes. Furthermore, we find it convenient to consider variants of the original Turing machine. Recall from chapter 1 that all these model-specific details turn out to be unimportant for the major conclusions of our theory. It is somewhat paradoxical that some form of these model-dependent details cannot be avoided in order to attain our model-independent conclusions. 2 In this chapter we will study some basic complexity results in the Turing model. For the time being, we restrict ourselves to the fundamental and the nondeterministic modes of computation. A Turing machine basically consists of a finite-state `black 1 According to Martin Davis [8] Godel did not believe in Church's thesis until he heard of Turing's results. Godel's skepticism arose from his insistence on an a priori analysis of the concept of computation (which is what Turing provided). The article contains an authoritative account of the origins of Church's thesis. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. O. Aanderaa. </author> <title> On k-tape versus (k 1)-tape real time computation. </title> <editor> In R. M. Karp, editor, </editor> <booktitle> Complexity of computation, </booktitle> <pages> pages 74-96. </pages> <publisher> Amer. Math. Soc., </publisher> <address> Providence, Rhode Island, </address> <year> 1974. </year>
Reference-contexts: Rabin [32] proved this for k = 1 and Aanderaa <ref> [1] </ref> showed this in general. See also [31]. 2.6 Simulation by Time In this section, we will bound space and reversal resources in terms of time. The results are of the form X-TIME-SPACE-REVERSAL (t; s; r) Y-TIME (t 0 ) where X; Y 2 fD; N g.
Reference: [2] <author> B. S. Baker and R. V. </author> <title> Book. </title> <journal> Reversal-bounded multipushdown machines. Journal of Computers and Systems Science, </journal> <volume> 8 </volume> <pages> 315-322, </pages> <year> 1974. </year>
Reference-contexts: Our intuition about reversals, relative to time or space, is much less developed. This is illustrated by a somewhat unexpected result from Baker and Book <ref> [2] </ref> about reversal complexity in the nondeterministic mode: Theorem 26 RE NREVERSAL (2). Proof. Without loss of generality, let L be a recursively enumerable language accepted by a simple Turing machine M.
Reference: [3] <author> R. V. Book and S. A. </author> <title> Greibach. </title> <journal> Quasi-realtime languages. Math. Systems Theory, </journal> <volume> 4 </volume> <pages> 97-111, </pages> <year> 1970. </year>
Reference-contexts: Nondeterminism is used in an essential way: the reader who is not familiar with nondeterministic computations will find the proof highly instructive. The proof is adapted from Book and Greibach <ref> [3] </ref>; the same ideas will be exploited later in this chapter when we consider the problem of reducing the number of work-tapes with no time loss.
Reference: [4] <author> R. V. Book, S. A. Greibach, and B. Wegbreit. </author> <title> Time and tape bounded Turing acceptors and AFL's. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 4 </volume> <pages> 606-621, </pages> <year> 1970. </year>
Reference-contexts: Although these results hold for nondeterministic as well as deterministic machines, our third result shows that we can do much better with nondeterministic simulation. This is the result of Book, Greibach and Wegbreit <ref> [4] </ref> showing that a nondeterministic 2-tape machine can simulate a k-tape machine without increasing the time, space or reversals by more than a constant factor. Finally, a tape-reduction result for deterministic reversals is indicated at the end of section 8. Such tape reduction theorems have important applications in later chapters.
Reference: [5] <author> R.V. Book and Chee Yap. </author> <title> On the computational power of reversal-bounded machines. </title> <booktitle> ICALP '77, </booktitle> <volume> 52 </volume> <pages> 111-119, </pages> <year> 1977. </year> <booktitle> Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag. </publisher>
Reference-contexts: SIMULATION BY REVERSAL 87 holds, provided we do not count reversals made by the input head. This extra condition of Rytter and Chrobak is essential, as pointed out by Liskiewicz 10 : Book and Yap <ref> [5] </ref> proved that all tally languages in DREVERSAL (O (1)) are regular. On the other hand, Mehlhorn and Alt (see section 11) has given a non-regular tally language. Thus corollary (ii) is a proper inclusion.
Reference: [6] <author> S.R. Buss, S.A. Cook, P.W. Dymond, and L. Hay. </author> <title> The log space oracle hierarchy collapses. </title> <type> Technical Report CS103, </type> <institution> Department of Comp. Sci. and Engin., University of California, </institution> <address> San Diego, </address> <year> 1987. </year>
Reference-contexts: Their solution was a surprise in two ways: the solution was surprisingly simple, and many researchers had expected the opposite result. The technique used in this result falls within a wider context that the interested reader may trace (for example, see <ref> [28, 38, 24, 6] </ref>). We emphasize that both results on complementation of space classes uses running complexity rather than accepting complexity. Recall our notation for running complexity classes are distinguished by the subscript `r', as in DSPACE r (s) or NSPACE r (s).
Reference: [7] <author> Ee-Chien Chang and Chee K. Yap. </author> <title> Improved deterministic time simulation of nondeterministic space for small space: a note. </title> <journal> Information Processing Letters, </journal> <volume> 55 </volume> <pages> 155-157, </pages> <year> 1995. </year>
Reference-contexts: The total time to accept is s (n) X n 2 log n O 1 (1) h = n 2 log n O 2 (1) s (n) : We now improve on the O (n 2 log n) factor. The idea <ref> [7] </ref> is to represent the input head positions implicitly. Let us call a storage configuration to be a `standard' configuration except that information about the input tape (i.e., the input word and the input head position) is omitted.
Reference: [8] <author> Martin Davis. </author> <title> Why Godel didn't have Church's Thesis. </title> <journal> Information and Computation, </journal> 54(1/2):3-24, 1982. 
Reference-contexts: For the time being, we restrict ourselves to the fundamental and the nondeterministic modes of computation. A Turing machine basically consists of a finite-state `black 1 According to Martin Davis <ref> [8] </ref> Godel did not believe in Church's thesis until he heard of Turing's results. Godel's skepticism arose from his insistence on an a priori analysis of the concept of computation (which is what Turing provided).
Reference: [9] <author> Jian er Chen. </author> <title> Tape reversal and parallel computation time. </title> <type> PhD thesis, </type> <institution> Courant Institute, </institution> <address> New York University, </address> <year> 1987. </year>
Reference-contexts: If L is accepted by a determinisitic multitape machine within r (n) reversals then it is accepted by a 2-tape deterministic machine within O (r (n) 2 ) reversals. Further results on reversal complexity can be found in <ref> [9] </ref>. 2.8.3 Reversal is more powerful than time, deterministically We now prove a result of Liskiewicz [26] showing that deterministic reversal is stronger than deterministic time by a square factor: Theorem 40 For all complexity function t (n) n, DTIME (t) DREVERSAL ( p A fundamental problem that we need to
Reference: [10] <author> Jian er Chen and Chee-Keng Yap. </author> <title> Reversal complexity. </title> <journal> SIAM J. Computing, </journal> <note> to appear, </note> <year> 1991. </year>
Reference-contexts: These results are from <ref> [10] </ref>. First we give a series of technical lemmas. Lemma 27 (Natural Number Generation) Given as input any integer r &gt; 0 in unary, the string 0# 1# 2# #2 r 1# can be generated by a 2-tape Turing machine M making O (r) reversals.
Reference: [11] <author> Patrick C. Fisher. </author> <title> The reduction of tape reversal for off-line one-tape Turing machines. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 2 </volume> <pages> 136-147, </pages> <year> 1968. </year> <note> 121 122 BIBLIOGRAPHY </note>
Reference-contexts: For simple Turing machines, reversal complexity seems to behave more to our expectation (based on our experience with time and space): Hartmanis [15] has shown that only regular languages can be accepted with O (1) reversals. Furthermore, Fis-cher <ref> [11] </ref> shows there is a linear speedup of reversals in this model. However, it is not clear that a linear speedup for reversals in the multi-tape machine model is possible in general.
Reference: [12] <author> J. Hartmanis and L. Berman. </author> <title> A note on tape bounds for sla language processing. </title> <booktitle> 16th Proc. IEEE Symp. Found. Comput. Sci., </booktitle> <pages> pages 65-70, </pages> <year> 1975. </year>
Reference-contexts: The requirement that s (n) &lt; 1 insures that we will get a decision eventually. Q.E.D. Historical note: Hopcroft and Ullman, [21] originally showed the above theorem under the restriction s (n) = (log n), using the idea of the counter mentioned above. Later Hartmanis and Berman <ref> [12] </ref> proved this in the case where the input alphabet is unary. We show an interesting consequence of the previous lemma: Theorem 45 If n s (n) &lt; 1 is an exact space-complexity then s (n) is space-constructible. Proof. Let M run in space exactly s.
Reference: [13] <author> J. Hartmanis, P. M. Lewis II, and R. E. Stearns. </author> <title> Hierarchies of memory limited computations. </title> <booktitle> IEEE Conf. Record on Switching Circuit Theory and Logical Design, </booktitle> <pages> pages 179-190, </pages> <year> 1965. </year>
Reference-contexts: It also illustrates our discussion in chapter 1 where we concluded that complexity functions must not be taken in an absolute sense, but only up to O-order. Our first theorem, taken from Stearns, Hartmanis and Lewis <ref> [13] </ref>, says that the space complexity of a problem can be reduced by any constant factor and it is sufficient to use a 1-tape acceptor. Theorem 1 (Space Compression) Let c &gt; 0 be any constant and s () a complexity function.
Reference: [14] <author> J. Hartmanis and R. E. Stearns. </author> <title> On the computational complexity of algorithms. </title> <journal> Trans. Amer. Math. Soc., </journal> <volume> 117 </volume> <pages> 285-306, </pages> <year> 1965. </year>
Reference-contexts: Then XSPACE (s) = XSPACE (O (s)): The reader can easily verify that theorem 1 and its corollary 2 hold if we use `running space' rather than `acceptance space' complexity. The next result from Hartmanis and Stearns <ref> [14] </ref> is the time analog of the previous theorem. 2.4.
Reference: [15] <author> Juris Hartmanis. </author> <title> Computational complexity of one-tape Turing machine computations. </title> <journal> Journal of the ACM, </journal> <volume> 15 </volume> <pages> 325-339, </pages> <year> 1968. </year>
Reference-contexts: For simple Turing machines, reversal complexity seems to behave more to our expectation (based on our experience with time and space): Hartmanis <ref> [15] </ref> has shown that only regular languages can be accepted with O (1) reversals. Furthermore, Fis-cher [11] shows there is a linear speedup of reversals in this model. However, it is not clear that a linear speedup for reversals in the multi-tape machine model is possible in general.
Reference: [16] <author> Juris Hartmanis. </author> <title> Tape-reversal bounded Turing machine computations. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 2 </volume> <pages> 117-135, </pages> <year> 1968. </year>
Reference-contexts: In some sense, reversal is a more powerful resource than either space or time, since for every k &gt; 0 there are non-regular languages that can be accepted using k reversals but that cannot be accepted using k 1 reversals <ref> [16] </ref>. In contrast, only regular languages can be accepted using a constant amount of space or time. Indeed, in section 6, the power of reversals is even more dramatically shown when we prove that all RE languages can be accepted with just two reversals when we allow nondeterminism.
Reference: [17] <author> F. C. Hennie and R. E. Stearns. </author> <title> Two-tape simulation of multitape Turing machines. </title> <journal> Journal of the ACM, </journal> <volume> 13(4) </volume> <pages> 533-546, </pages> <year> 1966. </year>
Reference-contexts: The first is a simple result which reduces k work-tapes to one work-tape, at the cost of increasing time quadratically. The second is a classic simulation of a k-tape machine by a 2-tape machine due to Hennie and Stearns <ref> [17] </ref>, in which the simulation is slower by a logarithmic factor. Although these results hold for nondeterministic as well as deterministic machines, our third result shows that we can do much better with nondeterministic simulation.
Reference: [18] <author> Frederick C. Hennie. One-tape, </author> <title> off-line Turing machine computations. </title> <journal> Information and Computation, </journal> <volume> 8(6) </volume> <pages> 553-578, </pages> <year> 1965. </year>
Reference-contexts: We first prove a lower bound on the simultaneous time-space complexity of L pal using an counting technique based on `crossing sequences'. The notion of crossing sequences is fairly general. It was originally developed by Hennie <ref> [18] </ref> for deterministic simple Turing machines, but we shall see that the technique extends to nondeterministic computations. It has recently resurfaced in proving lower bounds on VLSI computations.
Reference: [19] <author> Jia-wei Hong. </author> <title> A tradeoff theorem for space and reversal. </title> <journal> Theoretical Computer Science, </journal> <volume> 32 </volume> <pages> 221-224, </pages> <year> 1984. </year>
Reference-contexts: Since x is arbitrary, every input of length greater than n 0 is accepted or rejected according to the behavior of M on its prefix of length n 0 . Any such language is seen to be regular. Q.E.D. We now prove a result from Hong <ref> [19] </ref>. Recall the definition of product complexity classes in the last section. 2.11. ABSOLUTE LOWER BOUNDS 111 Theorem 54 Let f be complexity function such that f (n) = o (n). Then the product class NSPACE fi REVERSAL (f ) is precisely the class of regular languages.
Reference: [20] <author> Jia-wei Hong. </author> <title> Computation: Computability, Similarity and Duality. </title> <booktitle> Research notices in theoretical Computer Science. </booktitle> <publisher> Pitman Publishing Ltd., </publisher> <address> London, 1986. </address> <publisher> (available from John Wiley & Sons, </publisher> <address> New York). </address>
Reference-contexts: Clearly the reversal of C bounded by k + 1 times the the number of phases in C. Remarks: An alternative to our definition of reversal complexity is to discount reversals caused by the input head. Hong <ref> [20] </ref> (see section 8.3) uses this alternative. This would be consistent with our decision not to count the space used on the input tape. However, the real concern there was to admit sublinear space usage to distinguish problems with low space complexity.
Reference: [21] <author> J. Hopcroft and J. Ullman. </author> <title> Some results on tape bounded Turing machines. </title> <journal> Journal of the ACM, </journal> <volume> 16 </volume> <pages> 168-188, </pages> <year> 1969. </year>
Reference-contexts: The requirement that s (n) &lt; 1 insures that we will get a decision eventually. Q.E.D. Historical note: Hopcroft and Ullman, <ref> [21] </ref> originally showed the above theorem under the restriction s (n) = (log n), using the idea of the counter mentioned above. Later Hartmanis and Berman [12] proved this in the case where the input alphabet is unary. <p> Since f (jwj) h, and there are infinitely many such w's, we conclude f (n) 6= o (n). This contradicts our assumption on f . Q.E.D. We next prove a similar result of Hopcroft and Ullman <ref> [21] </ref>. To do this, we extend the notion of characteristic relations to allow the work-tape heads to move.
Reference: [22] <author> Neil Immerman. </author> <title> Nondeterministic space is closed under complement. Structure in Complexity Theory, </title> <booktitle> 3 </booktitle> <pages> 112-115, </pages> <year> 1988. </year>
Reference-contexts: The result for nondeterministic space classes solves an open problem problem dating back to Kuroda in 1964. The solution was independently obtained by Immerman <ref> [22] </ref> and Szelepcsenyi [37]. Their solution was a surprise in two ways: the solution was surprisingly simple, and many researchers had expected the opposite result. The technique used in this result falls within a wider context that the interested reader may trace (for example, see [28, 38, 24, 6]).
Reference: [23] <author> Kojiro Kobayashi. </author> <title> On proving time constructibility of functions. </title> <journal> Theoretical Computer Science, </journal> <volume> 35 </volume> <pages> 215-225, </pages> <year> 1985. </year>
Reference-contexts: N . (ii) Show a similar result for space-constructible f , but no longer assuming f (n) = !(n). [2.7] * Show that the following functions are time-constructible for any positive integer k: (i) n log k n, (ii) n k , (iii) n! (factorial), (iv) k n . (See <ref> [23] </ref> for a systematic treatment of such proofs.) [2.8] Redo the last problem for reversal-constructible. (Recall that reversal-constructible is defined slightly differently than in the case of time or space.) [2.9] Suppose f (n) n and g (n) is an integer for all n, and both f and g are time-constructible.
Reference: [24] <author> K.-J. Lange, B. Jenner, and B. Kirsig. </author> <title> The logarithmic alternation hierarchy collapses: A L 2 = A L 2 . Proc. Automata, </title> <journal> Languages and Programming, </journal> <volume> 14 </volume> <pages> 531-541, </pages> <year> 1987. </year>
Reference-contexts: Their solution was a surprise in two ways: the solution was surprisingly simple, and many researchers had expected the opposite result. The technique used in this result falls within a wider context that the interested reader may trace (for example, see <ref> [28, 38, 24, 6] </ref>). We emphasize that both results on complementation of space classes uses running complexity rather than accepting complexity. Recall our notation for running complexity classes are distinguished by the subscript `r', as in DSPACE r (s) or NSPACE r (s).
Reference: [25] <author> Ming Li. </author> <title> On one tape versus two stacks. </title> <type> Technical Report Tech. Report TR84-591, </type> <institution> Computer Science Dept., Cornell Univ., </institution> <month> Jan. </month> <year> 1984. </year>
Reference-contexts: Q.E.D. We know that the above simulation is essentially the best possible in the deterministic case: Maass [27] shows that there are languages which require time (n 2 ) on a 1-tape machine but can be accepted in real time by a 2-tape machine. See also <ref> [25] </ref>. Theorem 8 (Hennie-Stearns) If L is accepted by a k-tape Turing machine within time t (n) then it is accepted by a 2-tape Turing machine within time O (t (n) log t (n)). Proof.
Reference: [26] <author> Maciej Liskiewicz. </author> <title> On the relationship between deterministic time and deterministic reversal. </title> <journal> Information Processing Letters, </journal> <volume> 45 </volume> <pages> 143-146, </pages> <year> 1993. </year> <note> BIBLIOGRAPHY 123 </note>
Reference-contexts: Further results on reversal complexity can be found in [9]. 2.8.3 Reversal is more powerful than time, deterministically We now prove a result of Liskiewicz <ref> [26] </ref> showing that deterministic reversal is stronger than deterministic time by a square factor: Theorem 40 For all complexity function t (n) n, DTIME (t) DREVERSAL ( p A fundamental problem that we need to solve is the problem of retrieving data from a table.
Reference: [27] <author> Wolfgang Maass. </author> <title> Quadratic lower bounds for deterministic and nondeterministic one-tape Turing machines. </title> <booktitle> 16th Proc. ACM Symp. Theory of Comp. Sci., </booktitle> <pages> pages 401-408, </pages> <year> 1984. </year>
Reference-contexts: The claim about space and reversal usage of N is immediate. Q.E.D. We know that the above simulation is essentially the best possible in the deterministic case: Maass <ref> [27] </ref> shows that there are languages which require time (n 2 ) on a 1-tape machine but can be accepted in real time by a 2-tape machine. See also [25].
Reference: [28] <author> Stephen R. Mahaney. </author> <title> Sparse complete sets for NP: solution to a conjecture of Berman and Hartmanis. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 25 </volume> <pages> 130-143, </pages> <year> 1982. </year>
Reference-contexts: Their solution was a surprise in two ways: the solution was surprisingly simple, and many researchers had expected the opposite result. The technique used in this result falls within a wider context that the interested reader may trace (for example, see <ref> [28, 38, 24, 6] </ref>). We emphasize that both results on complementation of space classes uses running complexity rather than accepting complexity. Recall our notation for running complexity classes are distinguished by the subscript `r', as in DSPACE r (s) or NSPACE r (s).
Reference: [29] <author> H. Altand K. Mehlhorn. </author> <title> A language over a one symbol alphabet requiring only O(log log n) space. </title> <journal> SIGACT news, </journal> <volume> 7(4) </volume> <pages> 31-33, </pages> <month> Nov, </month> <year> 1975. </year>
Reference-contexts: In fact, the following language is an example. L 0 = f 1# 2# #n 1#n : n is a natural numberg where m denotes the binary representation of the integer m. There is another candidate language due to Mehlhorn and Alt <ref> [29] </ref>. It is rather interesting because it is over a single letter alphabet. First let q (n) denote the smallest number that does not divide an integer n.
Reference: [30] <author> Burkhard Monien and Ivan Hal Sudborough. </author> <title> On eliminating nondeterminism from Turing machines which use less than logarithm worktape space. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <volume> volume 71, </volume> <pages> pages 431-445, </pages> <address> Berlin, </address> <year> 1979. </year> <title> Springer-Verlag. </title> <booktitle> Proc. Symposium on Automata, Languages and Programming. </booktitle>
Reference-contexts: Our preceding proofs 114 CHAPTER 2. THE TURING MODEL: BASIC RESULTS would no longer be valid; indeed, it is easy to see that even non-recursively enumerable languages can be accepted this way (how?). We refer to <ref> [30] </ref> for languages with such low space complexity. To end this section, we note that the preceding absolute lower bounds are essentially tight in the following sense: (i) There are non-regular languages whose space-reversal product is O (n).
Reference: [31] <author> W. J. Paul, J. I. Seiferas, and J. Simon. </author> <title> An information-theoretic approach to time bounds for on-line computation. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 23 </volume> <pages> 108-126, </pages> <year> 1981. </year>
Reference-contexts: Rabin [32] proved this for k = 1 and Aanderaa [1] showed this in general. See also <ref> [31] </ref>. 2.6 Simulation by Time In this section, we will bound space and reversal resources in terms of time. The results are of the form X-TIME-SPACE-REVERSAL (t; s; r) Y-TIME (t 0 ) where X; Y 2 fD; N g.
Reference: [32] <author> Michael O. Rabin. </author> <title> Real time computation. </title> <journal> Israel J. of Math., </journal> <volume> 1(4) </volume> <pages> 203-211, </pages> <year> 1963. </year>
Reference-contexts: Remark: There are complexity differences between k and k + 1 tapes for all k when we restrict attention to real-time computations: more precisely, there are languages accepted in real-time by some (k + 1)-tape acceptor but not by any real-time k-tape acceptor. Rabin <ref> [32] </ref> proved this for k = 1 and Aanderaa [1] showed this in general. See also [31]. 2.6 Simulation by Time In this section, we will bound space and reversal resources in terms of time.
Reference: [33] <author> W. Rytter and M. Chrobak. </author> <title> A characterization of reversal-bounded multipush-down machine languages. </title> <journal> Theoretical Computer Science, </journal> <volume> 36 </volume> <pages> 341-344, </pages> <year> 1985. </year>
Reference-contexts: For instance, let s (n) = (n) = O (log r (n)). Then corollary (i) implies D-SPACE-REVERSAL (s; r) DSPACE (r log n) while the theorem yields the stronger D-SPACE-REVERSAL (s; r) DSPACE (r log log n). Remark: Rytter and Chrobak <ref> [33] </ref> have shown that the the converse of corollary (ii), DLOG DREVERSAL (O (1)); 2.8. SIMULATION BY REVERSAL 87 holds, provided we do not count reversals made by the input head.
Reference: [34] <author> W. J. Savitch. </author> <title> Relationships between nondeterministic and deterministic tape complexities. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 4 </volume> <pages> 177-192, </pages> <year> 1970. </year>
Reference-contexts: Q.E.D. We now obtain several interesting corollaries, including the well-known result of Savage <ref> [34] </ref>. Corollary 22 (i) (Savitch's theorem) If s (n) log n then NSPACE (s) DSPACE (s 2 ). (ii) If s (n) n then NTIME (s) DSPACE (s). (iii) If s (n) n, N-SPACE-REVERSAL (s; r) DSPACE (s log r).
Reference: [35] <author> Istvan Simon. </author> <title> On some subrecursive reducibilities. </title> <type> Technical Report Tech. Rep. </type> <institution> STAN-CS-77-608, Computer Sci. Dept., Stanford Univ., </institution> <month> April, </month> <year> 1977. </year> <type> (PhD Thesis). </type>
Reference-contexts: This corollary justifies our notation `PSPACE ' since we need not distinguish between `D-PSPACE' and `N-PSPACE'. The notations EXPS and EXPSPACE are likewise justified. We next simulate deterministic reversals by deterministic space. Istvan Simon <ref> [35] </ref> had shown how to simulate simultaneous time-reversal by space. Our next result strengthens his result to space-reversal. Theorem 24 If s (n) log n, D-SPACE-REVERSAL (s; r) DSPACE (r log s): Proof.
Reference: [36] <author> Michael Sipser. </author> <title> Halting space-bounded computations. </title> <journal> Theoretical Computer Science, </journal> <volume> 10 </volume> <pages> 335-338, </pages> <year> 1980. </year>
Reference-contexts: This proves (2.6). Note that the restriction t (n) &lt; 1 is essential and implies that M always halts. The main result of this subsection is to show the space analogue of (2.6) using a technique of Sipser <ref> [36] </ref>. Theorem 43 (Complement of deterministic space classes) If s (n) &lt; 1 for all n, then co-DSPACE r (s) = DSPACE r (s).
Reference: [37] <author> Robert Szelepcsenyi. </author> <title> The method of forcing for nondeterministic automata. </title> <journal> Bull. European Association Theor. Comp. Sci., </journal> <pages> pages 96-100, </pages> <year> 1987. </year>
Reference-contexts: The result for nondeterministic space classes solves an open problem problem dating back to Kuroda in 1964. The solution was independently obtained by Immerman [22] and Szelepcsenyi <ref> [37] </ref>. Their solution was a surprise in two ways: the solution was surprisingly simple, and many researchers had expected the opposite result. The technique used in this result falls within a wider context that the interested reader may trace (for example, see [28, 38, 24, 6]).
Reference: [38] <author> Seinosuke Toda. </author> <title> 2 SPACE(n) is closed under complement. </title> <journal> Journal of Computers and Systems Science, </journal> <volume> 35 </volume> <pages> 145-152, </pages> <year> 1987. </year> <note> 124 BIBLIOGRAPHY </note>
Reference-contexts: Their solution was a surprise in two ways: the solution was surprisingly simple, and many researchers had expected the opposite result. The technique used in this result falls within a wider context that the interested reader may trace (for example, see <ref> [28, 38, 24, 6] </ref>). We emphasize that both results on complementation of space classes uses running complexity rather than accepting complexity. Recall our notation for running complexity classes are distinguished by the subscript `r', as in DSPACE r (s) or NSPACE r (s).
References-found: 38

