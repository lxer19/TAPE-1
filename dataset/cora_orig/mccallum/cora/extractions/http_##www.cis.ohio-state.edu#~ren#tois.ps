URL: http://www.cis.ohio-state.edu/~ren/tois.ps
Refering-URL: http://www.cis.ohio-state.edu/~ren/
Root-URL: 
Title: DOCUMENT RANKING ON WEIGHT-PARTITIONED SIGNATURE FILES  
Author: By Liming Ren, M.S. Professor Mukesh Singhal, Adviser Professor Douglas S. Kerr Professor Harvey Friedman Adviser 
Degree: DISSERTATION Presented in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy in the  Dissertation Committee:  Approved by  
Date: 1998  
Affiliation: Graduate School of The Ohio State University  The Ohio State University  Department of Computer and Information Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> AHO, A. V. and ULLMAN, J. D. </author> <title> Optimal partial-match retrieval when fields are independently specified. </title> <journal> ACM Trans. Database Syst., </journal> <volume> 4(2) </volume> <pages> 168-179, </pages> <month> June, </month> <year> 1979. </year>
Reference-contexts: By using the angle, instead of the inner product, we effectively normalize the similarity value to numbers in interval <ref> [0; 1] </ref>. For this reason, the angle similarity is the most widely used similarity measure. By this similarity measure, documents can be sorted according to decreasing order and only the desired top documents are returned to the user.
Reference: [2] <author> BICKLE, P. and DOKSUM, K. A. </author> <title> Mathematical Statistics: Basic Ideas and Selected Topics. </title> <publisher> Holden-Day, Inc., </publisher> <year> 1977. </year>
Reference-contexts: We need some statistical results here. Given n signatures, let X n denote the number of signatures whose first bit are 0. Then X n has binomial distribution B (n; w) with mean nw and variance nw (1 w). According to The Central Limit Theorem <ref> [2] </ref>, X n nw p nw (1w) converges to the standard normal distribution N (0; 1) when n is large. Mathematically it is lim Pfj q zj "g = 0 where z ~ N (0; 1) is the standard normal distribution. <p> Followings are a few entries from the standard normal distribution table in [26]. ff 0.05 0.025 0.01 0.005 0.002 0.001 0.0004 2 1.96 2.24 2.57 2.81 3.09 3.27 3.49 A rule of thumb <ref> [2] </ref> is that for most purposes the approximation can be used when nw and n (1 w) are both larger than 5.
Reference: [3] <author> D. C. Blair. </author> <title> The data-document distinction in information retrieval. </title> <journal> Commun. ACM, </journal> <volume> 27(4), </volume> <month> April, </month> <year> 1984. </year>
Reference-contexts: Over the years, information retrieval systems have improved gradually. Various mathematical models have been proposed to represent content 1 identifier based information retrieval systems in the last 40 years. Several approaches have received the most attention, notably the Boolean model <ref> [3, 46, 49] </ref> which compares Boolean query statements with the term sets used to identify document content, the vector space model [46] which represents both queries and documents by vectors and computes similarities between queries and documents, and the probabilistic model based on the computation of relevance for the documents of <p> In other words, Boolean model ignores much of the syntactic, semantic and contextual information. Furthermore it cannot support document ranking effectively. The retrieval effectiveness of Boolean systems has been demonstrated to be unsatisfactory <ref> [3, 46, 49] </ref>. User needs to know how to formulate complex boolean queries using logical operators like "AND", "OR" and "NOT" etc.
Reference: [4] <author> Makris, C. Bozanis, P. and Tsakalidis, A. </author> <title> Parametric weighted filter: an efficient dynamic manipulation of signature files. </title> <journal> Computer Journal, </journal> <volume> 38(6), </volume> <year> 1995. </year>
Reference-contexts: This kind of storage saving does not occur only in the three partitioning methods developed by Lee and Leng. It happens to other key based partitioning methods, like Quick F ilter [41] and Parametric Weighted Filter <ref> [4] </ref>, as well. It is interesting to know how much space is saved by storing only one copy of the key. Finding the answer, surprisingly, turns out to be non-trivial. In this section, we will estimate the saving for the fixed-prefix partitioning. <p> Finding the answer, surprisingly, turns out to be non-trivial. In this section, we will estimate the saving for the fixed-prefix partitioning. The result should give us a good indication about storage savings about other methods, including Quick F ilter [41] and Parametric Weighted Filter <ref> [4] </ref>. For simplicity, we only consider the case where all partitions are generated. Thus the storage overhead is the storage of the partition keys, 2 k k, plus the storage overhead of the non-key part of signatures, (m k)n. These two terms together give us the new storage overhead.
Reference: [5] <author> Buckley, C. and Lewit, A. F. </author> <title> Optimization of inverted vector searches. </title> <booktitle> In Proceedings of the ACM SIGIR Conference, </booktitle> <pages> pages 97-110, </pages> <year> 1985. </year>
Reference-contexts: It is clear that the algorithm is applicable to other similarity measures. Some variations of the upperbound search algorithm have been proposed to improve retrieval efficiency by relaxing the stopping criterion. Buckley and Lewit <ref> [5] </ref> suggested that upperbound of the (T + 1) th document is compared with current score of the S th document, where S &lt; T . With this relaxation, the chance to meet the stopping criterion is enhanced because of a larger difference in scores. <p> If the search can be terminated early, we have better response time since short postings lists are processes first and the unprocessed lists are long. It has been found <ref> [5, 56] </ref> that the upperbound search algorithm is too conservative to yield any significant performance gain for inverted files. <p> Most of the time, almost all the query terms, thus most documents, must be processed in order to obtain all top documents. 75 Some variations of the upperbound search algorithm have been proposed to im-prove retrieval efficiency by relaxing the stopping criterion <ref> [5] </ref>, or applying probability on the upper bound computation [Perry, Willett 1983; Weiss 1981]. Again it has been found [Wong 1991] that those modified upperbound search algorithms fail to yield any real performance gain and the extra computation overhead induced to calculate probabilities is very expensive.
Reference: [6] <author> Chen, Ye-Sho and Leimkuhler, F. F. </author> <title> A relationship between lotka's law and bradford's law, and zipf's law. </title> <journal> Journal of American Society for Information Science, </journal> <volume> 37(5) </volume> <pages> 307-314, </pages> <year> 1986. </year>
Reference: [7] <author> CHRISTODOULAKIS, S. and FALOUTSOS, C. </author> <title> Design considerations for a message file server. </title> <journal> IEEE Trans. Soft. Eng., </journal> <volume> SE-10(2):201-210, </volume> <month> March, </month> <year> 1984. </year>
Reference-contexts: The EXP method is much worse than the other two methods. 64 65 66 for CACM (HL) 67 for TREC (HL) 68 The 20% space overhead folklore Unlike inverted files which may have more than 100% percentage overhead, it has been long believed <ref> [7] </ref> that signature file is typically 10-20% the size of primary database. However, if we cannot implement tf fl idf ranking, we cannot compare the storage overhead on equal footing. This remains a belief until now.
Reference: [8] <author> K. W. Church. </author> <booktitle> One term or two? In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <month> July, </month> <year> 1995. </year>
Reference-contexts: A related question is how effective is stemming and text normalization. With the rapid advance of IR system and computer power, some researchers begin to study ways to generate term correlations and the impact of stemming on text retrieval effectiveness. Church <ref> [8] </ref> studied the correlations between a term and its variants using statistical tools like Bahadur and Lazarsfeld (BL) expansion. He found that the correlation between a word and its variants tend to be small, but non-negligible. The correlation varies systematically depending on the words and the document collections involved. <p> He found that the correlation between a word and its variants tend to be small, but non-negligible. The correlation varies systematically depending on the words and the document collections involved. For examples, Church <ref> [8] </ref> found that &lt; 00 hostage 00 ; "hostages 00 &gt;= 0:5 and &lt; 00 anytime 00 ; "Anytime 00 &gt;= 0 in a collection of 1988 AP articles. 17 Upperbound search algorithm on an inverted file An inverted file usually is organized as a sorted list or a B-tree.
Reference: [9] <author> CROFT, W. B. and SAVINO, P. </author> <title> Implementing ranking strategies using text signatures. </title> <journal> ACM Trans. Off. Inf. Syst., </journal> <volume> 6(1) </volume> <pages> 42-62, </pages> <month> Jan., </month> <year> 1988. </year>
Reference-contexts: A signature encodes the presence of terms in a text. Therefore, it can easily support the Boolean retrieval model. However, in order to support document ranking, term frequencies must be stored; this is difficult to do on signatures, which are simple bit vectors. Croft and Savino <ref> [9] </ref> provide a ranking technique that combines the inverse document frequency with an estimated term frequency. The retrieval effectiveness suffers because of the approximation of the term frequency.
Reference: [10] <author> Dumais, Susan Deerwester, Scott and Harshman, Richard. </author> <title> Indexing by latent semantic analysis. </title> <journal> Journal of the Society for Information Science, </journal> <volume> 41(6), </volume> <pages> 199x. </pages>
Reference: [11] <author> Dillon, M. and Gray, A. </author> <title> Fully automatic syntax-based indexing. </title> <journal> Journal of ASIS, </journal> <volume> 34(2), </volume> <month> March, </month> <year> 1983. </year> <month> 131 </month>
Reference: [12] <author> C. Faloutsos. </author> <booktitle> Information Retrieval, chapter Signatures files, </booktitle> <pages> pages 44-65. </pages> <publisher> Pren--tice Hall, </publisher> <year> 1992. </year>
Reference: [13] <author> C. FALOUTSOS. </author> <title> Signature files. </title> <editor> In W. B. Frakes and R. Baeza-Yates, editors, </editor> <booktitle> Information Retrieval: Data structures and algorithms, chapter 3. </booktitle> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference: [14] <author> FALOUTSOS, C. and CHRISTODOULAKIS, S. </author> <title> Description and performance analysis of signature file methods for office filing. </title> <journal> ACM TOIS, </journal> <volume> 5 </volume> <pages> 237-257, </pages> <month> July, </month> <year> 1987. </year>
Reference-contexts: Thus, it has low processing overhead on insertion. Since signatures are conceptually organized as a sequential file, it is easy to partition a signature file for parallel processing [Stanfill and Kahle 1986]. It is generally believed <ref> [14, 41] </ref> that a signature file usually incurs 10-20% storage overhead.
Reference: [15] <author> E. A. Fox. </author> <title> Lexical relations: Enhancing effectiveness of information retrieval systems. </title> <journal> ACM SIGIR Forum, </journal> <volume> 15(3), </volume> <year> 1980. </year>
Reference-contexts: The most obvious way to extract identifiers is to use single term identifiers. To improve the precision and recall, many different ways to extract document identifiers have been attempted over the years with little success. Examples are thesauruses <ref> [15] </ref>, stemming [48, 18], related terms based statistical cooccurrence [61] and phrases [50] etc. G. Salton and C. Buckley [47] surveyed results in the area of retrieval systems for the last twenty five years.
Reference: [16] <author> Frakes, William B. and Baeza-Yates, Richard, </author> <title> editors. Information Retrieval. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference: [17] <author> Fukunaga, K. and Narendra, P. M. </author> <title> A branch and bound algorithms for computing k-nearest neighbors. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-24(7):750-753, </volume> <month> July, </month> <year> 1975. </year>
Reference: [18] <author> D. </author> <title> Harman. </title> <journal> How effective is suffixing? Journal of the American Society for Information Science, </journal> <volume> 42(1), </volume> <year> 1991. </year>
Reference-contexts: The most obvious way to extract identifiers is to use single term identifiers. To improve the precision and recall, many different ways to extract document identifiers have been attempted over the years with little success. Examples are thesauruses [15], stemming <ref> [48, 18] </ref>, related terms based statistical cooccurrence [61] and phrases [50] etc. G. Salton and C. Buckley [47] surveyed results in the area of retrieval systems for the last twenty five years.
Reference: [19] <author> D. HARMAN. </author> <title> Overview of the first text retrieval conference. </title> <booktitle> In Proceedings of the 16th Annual International ACM/SIGIR Conference on Research and Development in Information Retrieval (Pittsburgh, </booktitle> <address> Pa, </address> <month> June), </month> <pages> pages 36-47. </pages> <publisher> ACM, </publisher> <year> 1993a. </year>
Reference: [20] <author> D. HARMAN. </author> <title> Overview of the second text retrieval conference (trec-2). </title> <booktitle> In Proceedings of the 2nd Text Retrieval Conference, </booktitle> <pages> pages 1-20, </pages> <address> Gaithersburg, Md., </address> <month> Aug., </month> <year> 1993b. </year>
Reference: [21] <author> Baeza-Yates, R. A. Harman, D, Fox, E. and Lee, W. </author> <booktitle> Information Retrieval, chapter Inverted files, </booktitle> <pages> pages 28-43. </pages> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference: [22] <author> Iadh Ounis and Jean-Pierre Chevallet. </author> <title> Using conceptual graphs in a multifaceted logical model for information retrieval. </title> <booktitle> In Database and Expert Systems Applications. 7th International Conference, DEXA '96 Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <month> Sept., </month> <year> 1996. </year>
Reference: [23] <author> Jae Woo Chang Jae Soo Yoo, Yoon-Joon Lee and Myoung Ho Kim. </author> <title> The hs file: a new dynamic signature file method for efficient information retrieval. </title> <booktitle> In Database and Expert Systems Applications. 5th International Conference, DEXA '94 Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <month> Sept., </month> <year> 1994. </year> <month> 132 </month>
Reference-contexts: The performance of key-partitioned signature file organization [30, 31] and Quick Filter [41] suffers when the query signature has a low weight, i.e., only a small percentage of bits are set to 1. To solve this problem, Yoo et al. <ref> [23, 60] </ref> recently introduced a new dynamic signature file structure, the Hierarchical Signature (HS) file. The HS file works well in dynamic environments (frequent insertions, deletions and updates) and has significantly better retrieval efficiency.
Reference: [24] <author> Jeong-Ki Kim and Jae Woo Chang. </author> <title> A new dynamic signature file method in parallel processing environment. </title> <booktitle> In Database and Expert Systems Applications. 6th International Conference, DEXA '95 Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference: [25] <author> Choon-Hee Lee Jeong-Ki Kim and Jae-Woo Chang. </author> <title> Two-dimensional dynamic signature file method using extendible hashing and frame-slicing techniques. </title> <journal> Information Sciences, </journal> <pages> 98(1-4), </pages> <month> May </month> <year> 1997. </year>
Reference: [26] <author> JOHNSON, R. A. and WICHERN, Dean W. </author> <title> Applied Multivariate Statistical Analysis. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1988. </year>
Reference-contexts: Thus for large n, Pfj q j z 1 ff where z 1 ff 2 is tabulated in many statistics books. Followings are a few entries from the standard normal distribution table in <ref> [26] </ref>. ff 0.05 0.025 0.01 0.005 0.002 0.001 0.0004 2 1.96 2.24 2.57 2.81 3.09 3.27 3.49 A rule of thumb [2] is that for most purposes the approximation can be used when nw and n (1 w) are both larger than 5.
Reference: [27] <author> LEE, D. L. KIM, Y. M. and PATEL, G. </author> <title> Efficient signature file methods for text retrieval. </title> <journal> IEEE Trans. Data Knowl. Eng. </journal> <note> To be published, </note> <year> 1994. </year>
Reference: [28] <author> KNAUS, D. and SCHAUBE, P. </author> <title> Effective and efficient retrieval from large and dynamic document collections. </title> <booktitle> In Proceedings of the 2nd Text Retrieval Conference, </booktitle> <pages> pages 163-170, </pages> <address> Gaithersburg, Md., </address> <month> Aug., </month> <year> 1993. </year>
Reference: [29] <author> LEE, D. L. and CHUANG, H. </author> <title> Performance of document ranking and relevance feedback. </title> <note> Submitted for publication, </note> <year> 1994. </year>
Reference: [30] <author> LEE, D. L. and LENG, C.-W. </author> <title> Partitioned signature files: Design issues and performance evaluation. </title> <journal> ACM TOIS, </journal> <volume> 7(2) </volume> <pages> 158-180, </pages> <month> April, </month> <year> 1989. </year>
Reference-contexts: The second set of algorithms tries to achieve fast response time by reducing the generated signature file size. Various experimental results are presented to support our conclusions. In Chapter V, we continue the research started by Lee and Leng <ref> [30, 31] </ref>. A new partition method, called variable-prefix partitioning, is introduced. It achieves better search space reduction ratio. We also estimate the storage saving by storing only one copy of the partition keys. <p> It is well known that the signature file approach suffers from slow response time compared to the inverted file method. Some recent research on signature files has addressed the improvement of search speed, as exemplified by the partitioned signature file approach, Lee and Leng <ref> [30, 31] </ref> and Zezula et al. [63, 41]. To reduce the number of signatures searched, Lee and Leng [30, 31] proposed to partition signatures into a number of partitions by a deterministic mapping algorithm. Three partitioning algorithms, namely, the fixed-prefix, extended-prefix, and floating-key methods, were presented. <p> Some recent research on signature files has addressed the improvement of search speed, as exemplified by the partitioned signature file approach, Lee and Leng <ref> [30, 31] </ref> and Zezula et al. [63, 41]. To reduce the number of signatures searched, Lee and Leng [30, 31] proposed to partition signatures into a number of partitions by a deterministic mapping algorithm. Three partitioning algorithms, namely, the fixed-prefix, extended-prefix, and floating-key methods, were presented. Each method specifies a different way to extract keys from signatures. <p> The main reason for doing so is for load balancing since it has been shown that the probability of a partition being searched for a query solely depends on the number of zeros in the partition key <ref> [30] </ref>. The drawback is that different partitions may have different key lengths. The last partition method, floating-key method, selects keys differently. First, a key length, say k, is selected, and then the first k-substring of a signature which contains the least number of ones is selected as the key. <p> For simplicity, K P S was assumed only to take the values of 0; k; 2k; ; etc. 21 Lee and Leng <ref> [30, 31] </ref> have shown that floating-key partitioning results in more search space reduction than the fixed-prefix partitioning and extended-prefix partitioning. In [31], Lee and Leng proposed a general trie data structure to support these three partition schemes. The structure uses fixed size pages. <p> When a query signature S Q arrives, 22 p = g (S Q ; h; n) is calculated to access the page. The search reduction ratio achieved is between 15-80% depending on the level of hashing. The performance of key-partitioned signature file organization <ref> [30, 31] </ref> and Quick Filter [41] suffers when the query signature has a low weight, i.e., only a small percentage of bits are set to 1. To solve this problem, Yoo et al. [23, 60] recently introduced a new dynamic signature file structure, the Hierarchical Signature (HS) file. <p> Most notable ones are key-based signature file partitioning methods [Lee and Leng 1989; Zezula et al. 1991]. These algorithms have achieved remarkable search space reduction ratios with little overhead. Among the three partitioning methods, Lee and Leng <ref> [30, 31] </ref> have shown that floating-key partitioning yields the best search space reduction. All three partitioning methods introduce very little overhead. The reduction ratio ranges anywhere between 15% to 85% depending on the query signature weight. Many partitions are filtered out by the key comparison during search. <p> We will explore those ideas in future research. 91 92 93 CHAPTER 5 Key Partitioned Signature Files Many researchers have been studying new methods to speed up retrieval process by reducing the search space. Lee and Leng <ref> [30, 31] </ref> proposed several ways to partition the signature files according to certain keys of the signatures. With very little overhead, their methods reduce the number of signatures searched by 15% to 80%, depending on the query signature weight. <p> Simulation results are compared with results obtained by theoretical estimations. The results are plotted in Figure 5.1 for number of pages generated and We only plot the page search reduction ratio here since signature search reduction ratio is almost identical to page search reduction ratio <ref> [30, 31] </ref>. From Figure 5.1 and Figure 5.2, we can see results from the approximation formulas match simulation results very accurately. When the number of signatures reaches 250,000, the error for number of pages generated is under 0.3%. <p> In our simulation, we use signature length m = 512 and page size p = 16. Signature reduction ratio for the fixed-prefix method when k = 15 is obtained from <ref> [30] </ref>. Figure 5.3 shows the signature search reduction ratios of both the fixed-prefix partitioning and the variable-prefix partitioning. It is clear that the variable-prefix method performs better than the fixed-prefix method for large databases. The margin gets bigger as the number of signatures in the database increases. <p> Whereas for the variable-prefix method, no partition with more than p signatures is generated. Key matching algorithm eliminates more signatures than that of the fixed-prefix method. 5.2 Floating Key Partitioning Lee and Leng <ref> [30, 31] </ref> showed that the floating-key method has the best search reduction ratio. In this section, we show how the formulas obtained for the variable-prefix method can be used to estimate the number of pages generated and the search space reduction ratio for the floating-key partitioning method. <p> We can expect that the probability to be smaller than 0.5 due to the way this segment is selected. In the variable-prefix partitioning analysis, we know this probability affects the generated trie balance and many performance measures. In <ref> [30] </ref>, Lee and Leng obtained an analytical formula, P (j; i), for the probability that a signature is hashed into S (j) and whose key segment has exactly i bits set to 1. <p> The proofs for other functions are similar. fl 118 5.3 Storage Saving In the three partition schemas proposed in <ref> [30, 31] </ref>, all signatures with the same key are grouped into one partition. The key portions of the signatures need not be stored for every signature. <p> We also experiment TF-partitioned signature files 125 method under low storage. For long document collection, TF-partitioned signature files can achieve comparable precision and recall by doing exact matching on the top documents with 10% of space overhead. In the second part, we extend results obtained by Lee and Leng <ref> [30, 31] </ref>. A new way of organizing a signature file is presented to avoid the exhaustive search of all signatures. Instead of using fixed prefix key, our method uses variable prefix key. No link list is used at leaf nodes. New partitions (pages) are generated whenever an overflow occurs. <p> However, there are still many interesting and promising research areas that could be investigated to extend the current work. The key-based partition methods developed by Lee and Leng <ref> [30] </ref> and several search algorithms presented in this thesis all lead to significant improvements in response time. Interestingly, Lee and Leng's methods [30, 31] and our new fast search algorithms are not mutually exclusive. <p> The key-based partition methods developed by Lee and Leng [30] and several search algorithms presented in this thesis all lead to significant improvements in response time. Interestingly, Lee and Leng's methods <ref> [30, 31] </ref> and our new fast search algorithms are not mutually exclusive. We are investigating heuristics to integrate them together to improve search performance and reduce the effect of false drops. A possible scenario is described as follows.
Reference: [31] <author> LEE, D. L. and LENG, C.-W. </author> <title> A partitioned signature for multi-attribute and text retrieval. </title> <booktitle> In Proceedings of 6 th international conference on data engineering, </booktitle> <pages> pages 389-397, </pages> <address> Los Angeles, CA, </address> <month> Feb., </month> <year> 1990. </year>
Reference-contexts: The second set of algorithms tries to achieve fast response time by reducing the generated signature file size. Various experimental results are presented to support our conclusions. In Chapter V, we continue the research started by Lee and Leng <ref> [30, 31] </ref>. A new partition method, called variable-prefix partitioning, is introduced. It achieves better search space reduction ratio. We also estimate the storage saving by storing only one copy of the partition keys. <p> It is well known that the signature file approach suffers from slow response time compared to the inverted file method. Some recent research on signature files has addressed the improvement of search speed, as exemplified by the partitioned signature file approach, Lee and Leng <ref> [30, 31] </ref> and Zezula et al. [63, 41]. To reduce the number of signatures searched, Lee and Leng [30, 31] proposed to partition signatures into a number of partitions by a deterministic mapping algorithm. Three partitioning algorithms, namely, the fixed-prefix, extended-prefix, and floating-key methods, were presented. <p> Some recent research on signature files has addressed the improvement of search speed, as exemplified by the partitioned signature file approach, Lee and Leng <ref> [30, 31] </ref> and Zezula et al. [63, 41]. To reduce the number of signatures searched, Lee and Leng [30, 31] proposed to partition signatures into a number of partitions by a deterministic mapping algorithm. Three partitioning algorithms, namely, the fixed-prefix, extended-prefix, and floating-key methods, were presented. Each method specifies a different way to extract keys from signatures. <p> For simplicity, K P S was assumed only to take the values of 0; k; 2k; ; etc. 21 Lee and Leng <ref> [30, 31] </ref> have shown that floating-key partitioning results in more search space reduction than the fixed-prefix partitioning and extended-prefix partitioning. In [31], Lee and Leng proposed a general trie data structure to support these three partition schemes. The structure uses fixed size pages. <p> For simplicity, K P S was assumed only to take the values of 0; k; 2k; ; etc. 21 Lee and Leng [30, 31] have shown that floating-key partitioning results in more search space reduction than the fixed-prefix partitioning and extended-prefix partitioning. In <ref> [31] </ref>, Lee and Leng proposed a general trie data structure to support these three partition schemes. The structure uses fixed size pages. Signatures in each trie are partitioned into the left or right branch according to the value of the current bit position. <p> The time complexity for searching the trie structure is of the order of the number of partitions which actually match the query. The complexity for both insertion and deletion operations are O (k + p) <ref> [31] </ref>, where p is the page size and k the key length. Zezula et al. [41] proposed another partitioning scheme, named QuickF ilter. The basic idea is the same as Lee and Leng's approach, namely, to put similar signatures in the same page. <p> When a query signature S Q arrives, 22 p = g (S Q ; h; n) is calculated to access the page. The search reduction ratio achieved is between 15-80% depending on the level of hashing. The performance of key-partitioned signature file organization <ref> [30, 31] </ref> and Quick Filter [41] suffers when the query signature has a low weight, i.e., only a small percentage of bits are set to 1. To solve this problem, Yoo et al. [23, 60] recently introduced a new dynamic signature file structure, the Hierarchical Signature (HS) file. <p> Most notable ones are key-based signature file partitioning methods [Lee and Leng 1989; Zezula et al. 1991]. These algorithms have achieved remarkable search space reduction ratios with little overhead. Among the three partitioning methods, Lee and Leng <ref> [30, 31] </ref> have shown that floating-key partitioning yields the best search space reduction. All three partitioning methods introduce very little overhead. The reduction ratio ranges anywhere between 15% to 85% depending on the query signature weight. Many partitions are filtered out by the key comparison during search. <p> We will explore those ideas in future research. 91 92 93 CHAPTER 5 Key Partitioned Signature Files Many researchers have been studying new methods to speed up retrieval process by reducing the search space. Lee and Leng <ref> [30, 31] </ref> proposed several ways to partition the signature files according to certain keys of the signatures. With very little overhead, their methods reduce the number of signatures searched by 15% to 80%, depending on the query signature weight. <p> Proper key length needs to be selected first based on the number of signatures in database. This is not always possible if the database grows and shrinks over time. With the partition file structures introduced in <ref> [31] </ref>, it is possible to eliminate the limitation of partition key length. In the trie structure described in [31], key length k is increased or linked pages are used when the depth of the trie reaches k. <p> This is not always possible if the database grows and shrinks over time. With the partition file structures introduced in <ref> [31] </ref>, it is possible to eliminate the limitation of partition key length. In the trie structure described in [31], key length k is increased or linked pages are used when the depth of the trie reaches k. One natural way to generalize this is to split and create new partitions whenever it is necessary. The prefix is still used as the partition key but without any length limitation. <p> Let's study the case when the key length is k. For this case, we do induction on n. If n p, then by the insertion operation described in <ref> [31] </ref>, the trie will consist of at most one page at the root of the trie. Thus, we have dn=pe = 1 page generated. <p> The response time is mainly determined by the percentage of signatures searched since that percentage determines the number of disk accesses. Given a query signature S Q , the search process as described in <ref> [31] </ref>, starts with the root of the trie as follows. 1. If the first bit is zero, both the left and right branches have to be searched; otherwise, only the right child will be searched. 2. <p> Simulation results are compared with results obtained by theoretical estimations. The results are plotted in Figure 5.1 for number of pages generated and We only plot the page search reduction ratio here since signature search reduction ratio is almost identical to page search reduction ratio <ref> [30, 31] </ref>. From Figure 5.1 and Figure 5.2, we can see results from the approximation formulas match simulation results very accurately. When the number of signatures reaches 250,000, the error for number of pages generated is under 0.3%. <p> Whereas for the variable-prefix method, no partition with more than p signatures is generated. Key matching algorithm eliminates more signatures than that of the fixed-prefix method. 5.2 Floating Key Partitioning Lee and Leng <ref> [30, 31] </ref> showed that the floating-key method has the best search reduction ratio. In this section, we show how the formulas obtained for the variable-prefix method can be used to estimate the number of pages generated and the search space reduction ratio for the floating-key partitioning method. <p> The proofs for other functions are similar. fl 118 5.3 Storage Saving In the three partition schemas proposed in <ref> [30, 31] </ref>, all signatures with the same key are grouped into one partition. The key portions of the signatures need not be stored for every signature. <p> We also experiment TF-partitioned signature files 125 method under low storage. For long document collection, TF-partitioned signature files can achieve comparable precision and recall by doing exact matching on the top documents with 10% of space overhead. In the second part, we extend results obtained by Lee and Leng <ref> [30, 31] </ref>. A new way of organizing a signature file is presented to avoid the exhaustive search of all signatures. Instead of using fixed prefix key, our method uses variable prefix key. No link list is used at leaf nodes. New partitions (pages) are generated whenever an overflow occurs. <p> The key-based partition methods developed by Lee and Leng [30] and several search algorithms presented in this thesis all lead to significant improvements in response time. Interestingly, Lee and Leng's methods <ref> [30, 31] </ref> and our new fast search algorithms are not mutually exclusive. We are investigating heuristics to integrate them together to improve search performance and reduce the effect of false drops. A possible scenario is described as follows.
Reference: [32] <author> LEE, D. L. and Ren, L. </author> <title> Document ranking on weight-partitioned signature files. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 14(2) </volume> <pages> 109-137, </pages> <month> April, </month> <year> 1996. </year>
Reference: [33] <author> LIN, Z. and Faloutsos, C. </author> <title> Frame-sliced signature files. </title> <journal> IEEE Transaction on knowledge and data engineering, </journal> <volume> 4(3) </volume> <pages> 281-289, </pages> <year> 1992. </year>
Reference: [34] <author> LIPMAN, D. J. and PEARSON, W. R. </author> <title> Rapid and sensitive protein similarity searches. </title> <journal> Science, </journal> <volume> 227 </volume> <pages> 1435-1441, </pages> <month> March, </month> <year> 1985. </year>
Reference: [35] <institution> H.P. Luhn. </institution> <note> Keyword-in-context for technical literature (kwic) index). ASDD Report No. RC-127, </note> <month> August, </month> <year> 1959. </year>
Reference-contexts: In this dissertation, we study new techniques to make IR systems fast and accurate. In the late 1950s, Luhn <ref> [35] </ref> first suggested that the automatic text retrieval systems could be designed based on a comparison of content identifiers from the stored texts and user queries. Over the years, information retrieval systems have improved gradually.
Reference: [36] <author> Mohan, K. C. and Willett, P. </author> <title> Nearest neighbor searching in serial files using text signatures. </title> <journal> Journal of Info. Science, </journal> <volume> 11 </volume> <pages> 31-39, </pages> <year> 1985. </year>
Reference-contexts: When the document collection contains too many documents, it is necessary to find ways to avoid exhaustive search of the postings lists. One of the techniques is the so-called upperbound search algorithm developed by Smeaton, A. F. and C. J. van Rijsbergen [51], Mohan, K. C. and Willett, P. <ref> [36] </ref>, Weiss, S. F [55] and Wong, W. Y. P [56]. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in [36, 40, 51, 55, 56]. <p> F. and C. J. van Rijsbergen [51], Mohan, K. C. and Willett, P. [36], Weiss, S. F [55] and Wong, W. Y. P [56]. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in <ref> [36, 40, 51, 55, 56] </ref>. To make the presentation concise, we use S (D) to denote document D's score and S (T ) the T th document's score in a ranking when there is no confusion. <p> The uniqueness of TF-partitioned signature file structure calls for new algorithms to improve search reduction ratio. In this section, we introduce an upperbound search 74 algorithm which achieves good reduction ratio consistently. The concept of upper--bound search algorithm <ref> [51, 36, 40, 55, 56] </ref> has been employed in inverted file based systems with various degrees of success. <p> However we will see that upperbound search method yields significant better results with TF-partitioned signature files. 4.2 Upperbound Search Algorithm in Inverted File First we present a brief review of the upperbound search algorithm in an inverted file. Detailed information can be found in <ref> [51, 36, 40, 55, 56] </ref>. The upperbound search algorithm is used to search for certain prespecified, say top T , top documents in a document collection.
Reference: [37] <author> J. Nie. </author> <title> An outline of a general model for information retrieval systems. </title> <booktitle> In In Proceedings of SIGIR 88, </booktitle> <address> Grenoble. </address> <publisher> ACM, </publisher> <year> 1988. </year> <month> 133 </month>
Reference: [38] <author> CHRISTODOULAKIS, S. THEODORIDOU, M. HO, F. PARA, M and PATHRIA, A. </author> <title> Multimedia document presentation, information extraction and document formation in minos: A model and a system. </title> <journal> ACM Trans. Off. Inf. Syst., </journal> <volume> 4(4) </volume> <pages> 345-383, </pages> <month> Oct. </month> <year> 1986. </year>
Reference: [39] <author> P. K. PEARSON. </author> <title> Fast hashing of variable length text strings. </title> <journal> Communication of The ACM, </journal> <volume> 33(6), </volume> <month> June, </month> <year> 1990. </year>
Reference: [40] <author> Perry, S. A and Willett, P. </author> <title> A review of the use of inverted files for best match searching in information retrieval system. </title> <journal> Journal of Info. Science, </journal> <volume> 6 </volume> <pages> 59-66, </pages> <year> 1983. </year>
Reference-contexts: F. and C. J. van Rijsbergen [51], Mohan, K. C. and Willett, P. [36], Weiss, S. F [55] and Wong, W. Y. P [56]. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in <ref> [36, 40, 51, 55, 56] </ref>. To make the presentation concise, we use S (D) to denote document D's score and S (T ) the T th document's score in a ranking when there is no confusion. <p> The uniqueness of TF-partitioned signature file structure calls for new algorithms to improve search reduction ratio. In this section, we introduce an upperbound search 74 algorithm which achieves good reduction ratio consistently. The concept of upper--bound search algorithm <ref> [51, 36, 40, 55, 56] </ref> has been employed in inverted file based systems with various degrees of success. <p> However we will see that upperbound search method yields significant better results with TF-partitioned signature files. 4.2 Upperbound Search Algorithm in Inverted File First we present a brief review of the upperbound search algorithm in an inverted file. Detailed information can be found in <ref> [51, 36, 40, 55, 56] </ref>. The upperbound search algorithm is used to search for certain prespecified, say top T , top documents in a document collection.
Reference: [41] <author> ZEZULA, P. RABITTI, F. and TIBERIO, P. </author> <title> Dynamic partitioning of signature files. </title> <journal> ACM Trans. Inf. Syst., </journal> <volume> 9(4) </volume> <pages> 336-339, </pages> <month> Oct., </month> <year> 1991. </year>
Reference-contexts: Thus, it has low processing overhead on insertion. Since signatures are conceptually organized as a sequential file, it is easy to partition a signature file for parallel processing [Stanfill and Kahle 1986]. It is generally believed <ref> [14, 41] </ref> that a signature file usually incurs 10-20% storage overhead. <p> Some recent research on signature files has addressed the improvement of search speed, as exemplified by the partitioned signature file approach, Lee and Leng [30, 31] and Zezula et al. <ref> [63, 41] </ref>. To reduce the number of signatures searched, Lee and Leng [30, 31] proposed to partition signatures into a number of partitions by a deterministic mapping algorithm. Three partitioning algorithms, namely, the fixed-prefix, extended-prefix, and floating-key methods, were presented. <p> The complexity for both insertion and deletion operations are O (k + p) [31], where p is the page size and k the key length. Zezula et al. <ref> [41] </ref> proposed another partitioning scheme, named QuickF ilter. The basic idea is the same as Lee and Leng's approach, namely, to put similar signatures in the same page. However, Zezula et al. used linear hashing to partition signatures. <p> When a query signature S Q arrives, 22 p = g (S Q ; h; n) is calculated to access the page. The search reduction ratio achieved is between 15-80% depending on the level of hashing. The performance of key-partitioned signature file organization [30, 31] and Quick Filter <ref> [41] </ref> suffers when the query signature has a low weight, i.e., only a small percentage of bits are set to 1. To solve this problem, Yoo et al. [23, 60] recently introduced a new dynamic signature file structure, the Hierarchical Signature (HS) file. <p> All three partitioning methods introduce very little overhead. The reduction ratio ranges anywhere between 15% to 85% depending on the query signature weight. Many partitions are filtered out by the key comparison during search. Zezula and Tiberio et al. <ref> [41] </ref> proposed a new dynamic partition model, Quicker Filter, to reduce search reduction ratio. This method allocates signatures on disk based on linear hashing functions. However these algorithms do not perform well for query signatures with low weights, This deficiency limits the usefulness of these algorithms. <p> Any saving here comes absolutely free since it does not slow down the retrieval process. This kind of storage saving does not occur only in the three partitioning methods developed by Lee and Leng. It happens to other key based partitioning methods, like Quick F ilter <ref> [41] </ref> and Parametric Weighted Filter [4], as well. It is interesting to know how much space is saved by storing only one copy of the key. Finding the answer, surprisingly, turns out to be non-trivial. In this section, we will estimate the saving for the fixed-prefix partitioning. <p> Finding the answer, surprisingly, turns out to be non-trivial. In this section, we will estimate the saving for the fixed-prefix partitioning. The result should give us a good indication about storage savings about other methods, including Quick F ilter <ref> [41] </ref> and Parametric Weighted Filter [4]. For simplicity, we only consider the case where all partitions are generated. Thus the storage overhead is the storage of the partition keys, 2 k k, plus the storage overhead of the non-key part of signatures, (m k)n.
Reference: [42] <author> M.BOUGHANEM R.LAYAIDA and A.CARON. </author> <title> Construction an information retrieval system with neural networks. </title> <booktitle> In Database and Expert Systems Applications. 5th International Conference, DEXA '94 Proceedings. </booktitle> <publisher> Springer-Verlag, </publisher> <month> Sept., </month> <year> 1994. </year>
Reference: [43] <author> C. S ROBERTS. </author> <title> Partial-match retrieval via the method of superimposed codes. </title> <booktitle> In Proceedings of the IEEE, </booktitle> <volume> volume 67, </volume> <pages> pages 1624-1642, </pages> <month> Dec., </month> <year> 1979. </year>
Reference-contexts: S. Roberts <ref> [43] </ref> proved that the false drop probability is minimized when the probability of any bit position set to 1 is 0.5. Compared to inverted files, the signature file approach has two major advantages: * Its storage overhead can be controlled easily and in general is very low.
Reference: [44] <author> G. SALTON. </author> <title> The SMART Retrieval System-Experiments in Automatics Document Processing. </title> <address> Englewood Cliffs, </address> <publisher> N.J.:Prentice Hall, </publisher> <year> 1971. </year>
Reference-contexts: Terms in the top documents, which are most similar to the queries, may help generate improved queries using relevance feedback. This model has been used as the basis for many ranking retrieval experiments, in particular the SMART system <ref> [44] </ref> developed by G. Salton and his group. It is also used extensively in our research and in this dissertation. The original vector space model did not specify how to select the term weights.
Reference: [45] <author> G SALTON. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1983. </year>
Reference: [46] <author> G SALTON. </author> <title> Automatic Text Processing: The transformation, analysis, and retrieval of information by computer. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1989. </year>
Reference-contexts: Over the years, information retrieval systems have improved gradually. Various mathematical models have been proposed to represent content 1 identifier based information retrieval systems in the last 40 years. Several approaches have received the most attention, notably the Boolean model <ref> [3, 46, 49] </ref> which compares Boolean query statements with the term sets used to identify document content, the vector space model [46] which represents both queries and documents by vectors and computes similarities between queries and documents, and the probabilistic model based on the computation of relevance for the documents of <p> Several approaches have received the most attention, notably the Boolean model [3, 46, 49] which compares Boolean query statements with the term sets used to identify document content, the vector space model <ref> [46] </ref> which represents both queries and documents by vectors and computes similarities between queries and documents, and the probabilistic model based on the computation of relevance for the documents of a collection. <p> Of these models, the vector space model has been the most popular one because of its simplicity and effectiveness. The Boolean model and vector space model <ref> [46] </ref> represent both documents and queries as term vectors in the form D = &lt; w 1 ; w 2 ; ; w V &gt; where V is the size of the dictionary (or vocabulary), w j and w Q;j are term weights representing the importance of term j in document <p> In other words, Boolean model ignores much of the syntactic, semantic and contextual information. Furthermore it cannot support document ranking effectively. The retrieval effectiveness of Boolean systems has been demonstrated to be unsatisfactory <ref> [3, 46, 49] </ref>. User needs to know how to formulate complex boolean queries using logical operators like "AND", "OR" and "NOT" etc.
Reference: [47] <author> SALTON, G and BUCKLEY, C. </author> <title> Term-weighting approaches in automatics text retrieval. </title> <booktitle> Information Processing And Management, </booktitle> <volume> 24(5), </volume> <year> 1988. </year>
Reference-contexts: To improve the precision and recall, many different ways to extract document identifiers have been attempted over the years with little success. Examples are thesauruses [15], stemming [48, 18], related terms based statistical cooccurrence [61] and phrases [50] etc. G. Salton and C. Buckley <ref> [47] </ref> surveyed results in the area of retrieval systems for the last twenty five years. They concluded that "judicious use of single term identifiers is preferable to the incorporation of more complex entities extracted from the text themselves or obtained from available vocabulary schedules". <p> They concluded that "judicious use of single term identifiers is preferable to the incorporation of more complex entities extracted from the text themselves or obtained from available vocabulary schedules". Two main problems with producing complex text identifiers <ref> [47] </ref> are: 15 1. <p> On the other hand, when the construction criteria for the complex entities are relaxed, then some good identifiers are obtained. However many identifiers that do not prove useful are also returned. G. Salton and C. Buckley <ref> [47] </ref> experimented with 287 distinct combinations of term-weighting assignments. It was shown that appropriately weighted single term indexing systems consistently produce better results than other complex text representations. Among the many different term weighting schemes (to assign or calculate term weight w i;j and w Q;j ), G. <p> It was shown that appropriately weighted single term indexing systems consistently produce better results than other complex text representations. Among the many different term weighting schemes (to assign or calculate term weight w i;j and w Q;j ), G. Salton and C. Buckley <ref> [47] </ref> found that assignments based on some combinations of term frequency, document frequency and length normalization provide the best performance.
Reference: [48] <author> Salton, G. and Lest, M. </author> <title> Computer evaluation of indexing and text processing. </title> <journal> Journal of the American Indexing and Text Processing, </journal> <volume> 15(1), </volume> <year> 1968. </year>
Reference-contexts: The most obvious way to extract identifiers is to use single term identifiers. To improve the precision and recall, many different ways to extract document identifiers have been attempted over the years with little success. Examples are thesauruses [15], stemming <ref> [48, 18] </ref>, related terms based statistical cooccurrence [61] and phrases [50] etc. G. Salton and C. Buckley [47] surveyed results in the area of retrieval systems for the last twenty five years.
Reference: [49] <author> Fox, E. A. Salton, G. and Wu, H. </author> <title> Extended boolean information retrieval. </title> <journal> Commun. ACM, </journal> <volume> 26(12), </volume> <month> December </month> <year> 1983. </year>
Reference-contexts: Over the years, information retrieval systems have improved gradually. Various mathematical models have been proposed to represent content 1 identifier based information retrieval systems in the last 40 years. Several approaches have received the most attention, notably the Boolean model <ref> [3, 46, 49] </ref> which compares Boolean query statements with the term sets used to identify document content, the vector space model [46] which represents both queries and documents by vectors and computes similarities between queries and documents, and the probabilistic model based on the computation of relevance for the documents of <p> In other words, Boolean model ignores much of the syntactic, semantic and contextual information. Furthermore it cannot support document ranking effectively. The retrieval effectiveness of Boolean systems has been demonstrated to be unsatisfactory <ref> [3, 46, 49] </ref>. User needs to know how to formulate complex boolean queries using logical operators like "AND", "OR" and "NOT" etc.
Reference: [50] <author> A. F. Smeaton. </author> <title> Incorporating syntactic information into a document retrieval strategy: An investigation. </title> <booktitle> In Proc. 1986 ACM-SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Pisa, Italy, </address> <year> 1986. </year> <month> 134 </month>
Reference-contexts: To improve the precision and recall, many different ways to extract document identifiers have been attempted over the years with little success. Examples are thesauruses [15], stemming [48, 18], related terms based statistical cooccurrence [61] and phrases <ref> [50] </ref> etc. G. Salton and C. Buckley [47] surveyed results in the area of retrieval systems for the last twenty five years.
Reference: [51] <author> Smeaton, A. F. and C. J. van Rijsbergen. </author> <title> The nearest neighbor problem in information retrieval. an algorithm using upperbounds. </title> <journal> ACM SIGIR Forum, </journal> <volume> 16 </volume> <pages> 83-87, </pages> <year> 1981. </year>
Reference-contexts: When the document collection contains too many documents, it is necessary to find ways to avoid exhaustive search of the postings lists. One of the techniques is the so-called upperbound search algorithm developed by Smeaton, A. F. and C. J. van Rijsbergen <ref> [51] </ref>, Mohan, K. C. and Willett, P. [36], Weiss, S. F [55] and Wong, W. Y. P [56]. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in [36, 40, 51, 55, 56]. <p> F. and C. J. van Rijsbergen [51], Mohan, K. C. and Willett, P. [36], Weiss, S. F [55] and Wong, W. Y. P [56]. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in <ref> [36, 40, 51, 55, 56] </ref>. To make the presentation concise, we use S (D) to denote document D's score and S (T ) the T th document's score in a ranking when there is no confusion. <p> The uniqueness of TF-partitioned signature file structure calls for new algorithms to improve search reduction ratio. In this section, we introduce an upperbound search 74 algorithm which achieves good reduction ratio consistently. The concept of upper--bound search algorithm <ref> [51, 36, 40, 55, 56] </ref> has been employed in inverted file based systems with various degrees of success. <p> However we will see that upperbound search method yields significant better results with TF-partitioned signature files. 4.2 Upperbound Search Algorithm in Inverted File First we present a brief review of the upperbound search algorithm in an inverted file. Detailed information can be found in <ref> [51, 36, 40, 55, 56] </ref>. The upperbound search algorithm is used to search for certain prespecified, say top T , top documents in a document collection.
Reference: [52] <author> STANFILE, C. and KAHLE, B. </author> <title> Parallel free-text search on the connection machine system. </title> <journal> Commun. ACM, </journal> <volume> 29(12) </volume> <pages> 1229-1239, </pages> <month> Dec., </month> <year> 1986. </year>
Reference: [53] <author> C. J. van Rijsbergen. </author> <title> A non-classical logic for information retrieval. </title> <journal> The Computer Journal, </journal> <volume> 29(6), </volume> <year> 1986. </year>
Reference: [54] <author> C. J. van Rijsbergen. </author> <title> Information Retrieval. </title> <publisher> Butterworths, </publisher> <address> London, </address> <year> 1990. </year>
Reference: [55] <author> S. F. Weiss. </author> <title> A probabilistic algorithm for nearest neighbour searching, pages 325-333. </title> <editor> R.N. Oddy, S. E. Robertson, C. J. van Rijsbergen and P. W. Williams, </editor> <publisher> Butterworths, </publisher> <address> London, </address> <year> 1981. </year>
Reference-contexts: One of the techniques is the so-called upperbound search algorithm developed by Smeaton, A. F. and C. J. van Rijsbergen [51], Mohan, K. C. and Willett, P. [36], Weiss, S. F <ref> [55] </ref> and Wong, W. Y. P [56]. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in [36, 40, 51, 55, 56]. <p> F. and C. J. van Rijsbergen [51], Mohan, K. C. and Willett, P. [36], Weiss, S. F [55] and Wong, W. Y. P [56]. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in <ref> [36, 40, 51, 55, 56] </ref>. To make the presentation concise, we use S (D) to denote document D's score and S (T ) the T th document's score in a ranking when there is no confusion. <p> The uniqueness of TF-partitioned signature file structure calls for new algorithms to improve search reduction ratio. In this section, we introduce an upperbound search 74 algorithm which achieves good reduction ratio consistently. The concept of upper--bound search algorithm <ref> [51, 36, 40, 55, 56] </ref> has been employed in inverted file based systems with various degrees of success. <p> However we will see that upperbound search method yields significant better results with TF-partitioned signature files. 4.2 Upperbound Search Algorithm in Inverted File First we present a brief review of the upperbound search algorithm in an inverted file. Detailed information can be found in <ref> [51, 36, 40, 55, 56] </ref>. The upperbound search algorithm is used to search for certain prespecified, say top T , top documents in a document collection.
Reference: [56] <author> W. Y. P. WONG. </author> <title> Design And Performance Evaluation Of Access Method And Heuristic Techniques For Implementing Document Ranking Strategies. </title> <type> Ph.D. dissertation, </type> <institution> The Ohio State University, </institution> <year> 1991. </year>
Reference-contexts: One of the techniques is the so-called upperbound search algorithm developed by Smeaton, A. F. and C. J. van Rijsbergen [51], Mohan, K. C. and Willett, P. [36], Weiss, S. F [55] and Wong, W. Y. P <ref> [56] </ref>. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in [36, 40, 51, 55, 56]. <p> F. and C. J. van Rijsbergen [51], Mohan, K. C. and Willett, P. [36], Weiss, S. F [55] and Wong, W. Y. P [56]. Here we present a brief review of the upperbound search algorithm on the inverted file. Detailed information can be found in <ref> [36, 40, 51, 55, 56] </ref>. To make the presentation concise, we use S (D) to denote document D's score and S (T ) the T th document's score in a ranking when there is no confusion. <p> According to Figure 3.13, this corresponds to roughly 0.01% false drop probability and about 150 false drops generated from a query. Retrieval accuracy In their research on documents ranking, Wong and Lee <ref> [56, 58] </ref> introduce the concept of retrieval accuracy to measure the performance of their heuristic methods. They measure the percentages of top documents obtained at different check points of total disk access. <p> The uniqueness of TF-partitioned signature file structure calls for new algorithms to improve search reduction ratio. In this section, we introduce an upperbound search 74 algorithm which achieves good reduction ratio consistently. The concept of upper--bound search algorithm <ref> [51, 36, 40, 55, 56] </ref> has been employed in inverted file based systems with various degrees of success. <p> However we will see that upperbound search method yields significant better results with TF-partitioned signature files. 4.2 Upperbound Search Algorithm in Inverted File First we present a brief review of the upperbound search algorithm in an inverted file. Detailed information can be found in <ref> [51, 36, 40, 55, 56] </ref>. The upperbound search algorithm is used to search for certain prespecified, say top T , top documents in a document collection. <p> If the search can be terminated early, we have better response time since short postings lists are processes first and the unprocessed lists are long. It has been found <ref> [5, 56] </ref> that the upperbound search algorithm is too conservative to yield any significant performance gain for inverted files.
Reference: [57] <author> WONG, W. Y. P. and LEE, D. L. </author> <title> Signature file methods for implementing a ranking strategy. </title> <journal> Inf. Process. Manage., </journal> <volume> 26(5) </volume> <pages> 641-653, </pages> <month> Sept., </month> <year> 1990. </year>
Reference: [58] <author> WONG, W. Y. P. and LEE, D. L. </author> <title> implementations of partial document ranking using inverted files. </title> <journal> Inf. Process. Manage., </journal> <volume> 29(5) </volume> <pages> 647-699, </pages> <month> Sept., </month> <year> 1993. </year>
Reference-contexts: According to Figure 3.13, this corresponds to roughly 0.01% false drop probability and about 150 false drops generated from a query. Retrieval accuracy In their research on documents ranking, Wong and Lee <ref> [56, 58] </ref> introduce the concept of retrieval accuracy to measure the performance of their heuristic methods. They measure the percentages of top documents obtained at different check points of total disk access.
Reference: [59] <author> Wu, Sun and Manber, Udi. </author> <title> Fast text searching allowing errors. </title> <journal> Communications of ACM, </journal> <volume> 35(10), </volume> <month> October, </month> <year> 1992. </year>
Reference: [60] <author> Lee, Y.J. Yoo, J.S., Kim, M.H. and Im, B.M. </author> <title> Performance evaluation of dynamic signature file methods. </title> <booktitle> In Proceedings. Nineteenth Annual International Computer Software and Applications Conference (COMPSAC'95) (Cat. </booktitle> <address> No.95CB35838), </address> <year> 1995. </year>
Reference-contexts: The performance of key-partitioned signature file organization [30, 31] and Quick Filter [41] suffers when the query signature has a low weight, i.e., only a small percentage of bits are set to 1. To solve this problem, Yoo et al. <ref> [23, 60] </ref> recently introduced a new dynamic signature file structure, the Hierarchical Signature (HS) file. The HS file works well in dynamic environments (frequent insertions, deletions and updates) and has significantly better retrieval efficiency.
Reference: [61] <author> Buckley, C. Yu, C. T. and Salton, G. </author> <title> An evaluation of term dependence models in information retrieval. </title> <editor> In Salton, G. and Schneider, H. J., editors, </editor> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> volume 146. </volume> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1983. </year>
Reference-contexts: The most obvious way to extract identifiers is to use single term identifiers. To improve the precision and recall, many different ways to extract document identifiers have been attempted over the years with little success. Examples are thesauruses [15], stemming [48, 18], related terms based statistical cooccurrence <ref> [61] </ref> and phrases [50] etc. G. Salton and C. Buckley [47] surveyed results in the area of retrieval systems for the last twenty five years.
Reference: [62] <author> Lam, K. Yu, C. T., Buckley, C. and Falton, G. </author> <title> A generalized term dependence model in information retrieval. </title> <journal> Information Technology: Research and Development, </journal> <volume> 2(4), </volume> <month> Oct., </month> <year> 1983. </year>
Reference: [63] <author> P. Zezula. </author> <title> Linear hashing for signature files. </title> <booktitle> In Proceedings of the IFIP TC6 and TC8 International Symposium on Network Information Processing Systems, </booktitle> <month> May, </month> <year> 1989. </year> .[] 
Reference-contexts: Some recent research on signature files has addressed the improvement of search speed, as exemplified by the partitioned signature file approach, Lee and Leng [30, 31] and Zezula et al. <ref> [63, 41] </ref>. To reduce the number of signatures searched, Lee and Leng [30, 31] proposed to partition signatures into a number of partitions by a deterministic mapping algorithm. Three partitioning algorithms, namely, the fixed-prefix, extended-prefix, and floating-key methods, were presented.
References-found: 63

