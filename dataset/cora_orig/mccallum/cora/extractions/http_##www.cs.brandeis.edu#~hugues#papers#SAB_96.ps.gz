URL: http://www.cs.brandeis.edu/~hugues/papers/SAB_96.ps.gz
Refering-URL: http://www.cs.brandeis.edu/~hugues/publications.html
Root-URL: http://www.cs.brandeis.edu
Email: fhugues, pollackg@cs.brandeis.edu  
Title: Dynamics of Co-evolutionary Learning  
Author: Hugues Juille Jordan B. Pollack 
Address: Waltham, MA 02254-9110  
Affiliation: Computer Science Department Volen Center for Complex Systems Brandeis University  
Abstract: Co-evolutionary learning, which involves the embedding of adaptive learning agents in a fitness environment which dynamically responds to their progress, is a potential solution for many technological chicken and egg problems, and is at the heart of several recent and surprising successes, such as Sim's artificial robot and Tesauro's backgammon player. We recently solved the two spirals problem, a difficult neural network benchmark classification problem, using the genetic programming primitives set up by [Koza, 1992]. Instead of using absolute fitness, we use a relative fitness [Angeline & Pollack, 1993] based on a competition for coverage of the data set. As the population reproduces, the fitness function driving the selection changes, and subproblem niches are opened, rather than crowded out. The solutions found by our method have a symbiotic structure which suggests that by holding niches open, crossover is better able to discover modular build ing blocks.
Abstract-found: 1
Intro-found: 1
Reference: [Angeline, 1995] <author> Angeline, P. J. </author> <year> (1995). </year> <title> Two self-adaptive crossover operations for genetic programming. </title> <booktitle> In Advances in Genetic Programming II. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: The data set is composed of two sets of 97 points, on the plane between -7 and +7. These two intertwined spirals are shown as "fi" and "ffi" in figures 5 and 6. [Koza, 1992] and <ref> [Angeline, 1995] </ref> have also investigated this problem using the Genetic Programming paradigm. We used the same setup as them to define the problem and to perform our experiments.
Reference: [Angeline & Pollack, 1993] <author> Angeline, P. J. & Pollack, J. B. </author> <year> (1993). </year> <title> Competitive environments evolve better solutions for complex tasks. </title> <booktitle> In The Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pp. 264-270. </pages> <publisher> Mor-gan Kaufmann. </publisher>
Reference-contexts: pioneering work by Hillis on sorting networks [Hillis, 1992], by Tesauro on self-playing Backgammon learner [Tesauro, 1992] with a recent follow up by Pollack, Blair and Land [Pollack et al., 1996], by Sims and Ray in evolving life-forms [Sims, 1994, Ray, 1992], by Angeline and Pollack on co-evolving Tic-tac-toe players <ref> [Angeline & Pollack, 1993] </ref>. In the adaptive behavior community, there is a focus developing on co-evolution in predator/prey games [Reynolds, 1994, Miller & Cliff, 1994]. <p> For the relative fitness experiments, three values were tested for ff. Table 1 presents the different parameter settings for our experiments. The tournament-like competition was implemented to be a realistic model of competition. In particular, it could be used to co-evolve game strategies <ref> [Angeline & Pollack, 1993] </ref>. However, in the case of an inductive learning problem like the intertwined spirals, the set of test cases is well-defined, fixed and of manageable size.
Reference: [Carpenter et al., 1992] <author> Carpenter, G., Grossberg, S., Markuzon, N., Reynolds, J., & Rosen, D. </author> <year> (1992). </year> <title> Fuzzy artmap: A neural network architecture for incremental supervised learning of analog multidimensional maps. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3 </volume> <pages> 698-713. </pages>
Reference: [Fahlman & Lebiere, 1990] <author> Fahlman, S. E. & Lebiere, C. </author> <year> (1990). </year> <title> The cascade-correlation learning architecture. </title> <editor> In Touretzky (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2. </booktitle> <publisher> Morgan Kauffman. </publisher>
Reference: [Goldberg & Richardson, 1987] <author> Goldberg, D. E. & Richardson, J. J. </author> <year> (1987). </year> <title> Genetic algorithms with sharing for multimodal function optimization. </title> <editor> In Grefenstette, J. J. (Ed.), </editor> <booktitle> Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pp. 41-49. </pages> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: As we look at the All versus All tournament, which is not plausible for most tasks, we can see that the competitive fitness model of co-evolution approximates fitness sharing <ref> [Goldberg & Richardson, 1987] </ref>, which helps prevent premature convergence by increasing diversity in a population. Rosin and Belew's [Rosin & Belew, 1995] work on fitness sharing demonstrates this connection as well.
Reference: [Hillis, 1992] <author> Hillis, W. D. </author> <year> (1992). </year> <title> Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <editor> In Langton, C. et al. (Eds.), </editor> <booktitle> Artificial Life II, </booktitle> <pages> pp. 313-324. </pages> <publisher> Addison Wesley. </publisher>
Reference-contexts: In evolutionary computation however, it has been appropriated from its ecological roots to describe any iterated adaptation involving "arms-races", either between learning species or between a learner and its learning environment. Examples of co-evolutionary learning include the pioneering work by Hillis on sorting networks <ref> [Hillis, 1992] </ref>, by Tesauro on self-playing Backgammon learner [Tesauro, 1992] with a recent follow up by Pollack, Blair and Land [Pollack et al., 1996], by Sims and Ray in evolving life-forms [Sims, 1994, Ray, 1992], by Angeline and Pollack on co-evolving Tic-tac-toe players [Angeline & Pollack, 1993].
Reference: [Juille & Pollack, 1996] <author> Juille, H. & Pollack, J. B. </author> <year> (1996). </year> <title> Massively parallel genetic programming. </title> <editor> In Angeline & Kinnear (Eds.), </editor> <booktitle> Advances in Genetic Programming II. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: In this paper, only a tournament style of competitive evolution has been used and compared to canonical GP. A more general presentation of the different strategies that have been implemented can be found in <ref> [Juille & Pollack, 1996] </ref>. 3 The Spiral Problem and the Competi tive Evolution Paradigm 3.1 Presentation The intertwined spiral problem consists of learning to classify points on the plane into two classes according to two intertwined spirals. <p> Once individual fitness is evaluated, selection and recombination are performed according to a fitness proportionate rule. Details of the implementation of this model of tournament, and of selection and recombination procedures for MPGP can be found in <ref> [Juille & Pollack, 1996] </ref>. 3.2 Preliminary Results and Discussion For the two classes of experiments, we performed 25 runs and each run was stopped after 300 generations.
Reference: [Koza, 1992] <author> Koza, J. R. </author> <year> (1992). </year> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press. </publisher>
Reference-contexts: In the adaptive behavior community, there is a focus developing on co-evolution in predator/prey games [Reynolds, 1994, Miller & Cliff, 1994]. Using competitive fitness in a massively parallel implementation of the genetic programming (GP) paradigm <ref> [Koza, 1992] </ref> we solved the problem of intertwined spirals, a very difficult classification benchmark from the field of neural networks. <p> The data set is composed of two sets of 97 points, on the plane between -7 and +7. These two intertwined spirals are shown as "fi" and "ffi" in figures 5 and 6. <ref> [Koza, 1992] </ref> and [Angeline, 1995] have also investigated this problem using the Genetic Programming paradigm. We used the same setup as them to define the problem and to perform our experiments.
Reference: [Lang & Witbrock, 1988] <author> Lang, K. J. & Witbrock, M. J. </author> <year> (1988). </year> <title> Learning to tell two spirals apart. </title> <booktitle> In Proceedings of the 1988 Connectionist Summer Schools. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: [Lindgren, 1992] <author> Lindgren, K. </author> <year> (1992). </year> <title> Evolutionary phenomena in simple dynamics. </title> <editor> In Langton, C. et al. (Eds.), </editor> <booktitle> Artificial Life II, </booktitle> <pages> pp. 295-312. </pages> <publisher> Addison Wes-ley. </publisher>
Reference-contexts: Therefore, we want to study the dynamics of the evolution of group size with time. A simple rule for fitness proportionate reproduction, similar to the one used by <ref> [Lindgren, 1992] </ref> to model population evolution, gives us: s j (t + 1) = s j (t) fi 1 + ff fi f where: population in the case of an absolute fitness. population in the case of a relative fitness. * ff is a parameter that controls the speed of the
Reference: [Miller & Cliff, 1994] <author> Miller, G. F. & Cliff, D. </author> <year> (1994). </year> <title> Protean behavior in dynamic games. </title> <editor> In Cliff, D., Husbands, P., Meyer, J., & Wilson, S. (Eds.), </editor> <booktitle> From Animals to Animats 3: Proceedings of the Third International Conference on Simulation of Adaptive Behavior. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: In the adaptive behavior community, there is a focus developing on co-evolution in predator/prey games <ref> [Reynolds, 1994, Miller & Cliff, 1994] </ref>. Using competitive fitness in a massively parallel implementation of the genetic programming (GP) paradigm [Koza, 1992] we solved the problem of intertwined spirals, a very difficult classification benchmark from the field of neural networks.
Reference: [Perkis, 1994] <author> Perkis, T. </author> <year> (1994). </year> <title> Stack-based genetic programming. </title> <booktitle> In Proceedings of the 1994 IEEE World Congress on Computational Intelligence. </booktitle> <publisher> IEEE Press. </publisher>
Reference-contexts: Once a STOP instruction is executed for a processor, that processor becomes idle, leaving the result of its evaluation on the top of the stack. When all processors have reached their STOP instruction, the parallel evaluation of the entire population is complete. <ref> [Perkis, 1994] </ref> has already shown that the stack-based approach for Genetic Programming can be very efficient. 2.2 Models for Fitness Evaluation, Selection and Recombination The MasPar MP-2 is a 2-dimensional wrap-around mesh architecture.
Reference: [Pollack et al., 1996] <author> Pollack, J. B., Blair, A. D., & Land, M. </author> <year> (1996). </year> <title> Coevolution of a backgammon player. </title> <booktitle> To appear in the proceedings of the Fifth Artificial Life Conference. </booktitle>
Reference-contexts: Examples of co-evolutionary learning include the pioneering work by Hillis on sorting networks [Hillis, 1992], by Tesauro on self-playing Backgammon learner [Tesauro, 1992] with a recent follow up by Pollack, Blair and Land <ref> [Pollack et al., 1996] </ref>, by Sims and Ray in evolving life-forms [Sims, 1994, Ray, 1992], by Angeline and Pollack on co-evolving Tic-tac-toe players [Angeline & Pollack, 1993]. In the adaptive behavior community, there is a focus developing on co-evolution in predator/prey games [Reynolds, 1994, Miller & Cliff, 1994].
Reference: [Ray, 1992] <author> Ray, T. S. </author> <year> (1992). </year> <title> An approach to the synthesis of life. </title> <editor> In Langton, C. et al. (Eds.), </editor> <booktitle> Artificial Life II, </booktitle> <pages> pp. 371-408. </pages> <publisher> Addison Wesley. </publisher>
Reference-contexts: Examples of co-evolutionary learning include the pioneering work by Hillis on sorting networks [Hillis, 1992], by Tesauro on self-playing Backgammon learner [Tesauro, 1992] with a recent follow up by Pollack, Blair and Land [Pollack et al., 1996], by Sims and Ray in evolving life-forms <ref> [Sims, 1994, Ray, 1992] </ref>, by Angeline and Pollack on co-evolving Tic-tac-toe players [Angeline & Pollack, 1993]. In the adaptive behavior community, there is a focus developing on co-evolution in predator/prey games [Reynolds, 1994, Miller & Cliff, 1994].
Reference: [Reynolds, 1994] <author> Reynolds, C. W. </author> <year> (1994). </year> <title> Competition, coevolution, and the game of tag. </title> <booktitle> In Proceedings of the Fourth Artificial Life Conference. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: In the adaptive behavior community, there is a focus developing on co-evolution in predator/prey games <ref> [Reynolds, 1994, Miller & Cliff, 1994] </ref>. Using competitive fitness in a massively parallel implementation of the genetic programming (GP) paradigm [Koza, 1992] we solved the problem of intertwined spirals, a very difficult classification benchmark from the field of neural networks.
Reference: [Rosca & Ballard, 1996] <author> Rosca, J. P. & Ballard, D. H. </author> <year> (1996). </year> <title> Discovery of subroutines in genetic programming. </title> <editor> In Angeline & Kinnear (Eds.), </editor> <booktitle> Advances in Genetic Programming II. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: For the same experiments, we also observed the evolution of another measure in order to show that learning is more efficient in the case of co-evolution. Rosca <ref> [Rosca & Ballard, 1996] </ref> defined differential fitness as a measure of the fitness improvement in the population. He defined this measure for offspring i as follows: Differential Fitness (i) = Standard Fitness (i) min p2Parents (i) fStandard Fitness (p)g For an heuristic reason [Rosca & Ballard, 1996], the min of the <p> Rosca <ref> [Rosca & Ballard, 1996] </ref> defined differential fitness as a measure of the fitness improvement in the population. He defined this measure for offspring i as follows: Differential Fitness (i) = Standard Fitness (i) min p2Parents (i) fStandard Fitness (p)g For an heuristic reason [Rosca & Ballard, 1996], the min of the parents was taken to define the differential fitness. However, in our case, one is more interested in a measure that would indicate an improvement of offsprings over both parents.
Reference: [Rosin & Belew, 1995] <author> Rosin, C. D. & Belew, R. K. </author> <year> (1995). </year> <title> Methods for competitive co-evolution: Finding opponents worth beating. </title> <editor> In Eshelman, L. J. (Ed.), </editor> <booktitle> Proceedings of the Sixth International Conference on Genetic Algorithms, </booktitle> <address> San Mateo, California. </address> <publisher> Morgan Kauffmann. </publisher>
Reference-contexts: As we look at the All versus All tournament, which is not plausible for most tasks, we can see that the competitive fitness model of co-evolution approximates fitness sharing [Goldberg & Richardson, 1987], which helps prevent premature convergence by increasing diversity in a population. Rosin and Belew's <ref> [Rosin & Belew, 1995] </ref> work on fitness sharing demonstrates this connection as well.
Reference: [Sims, 1994] <author> Sims, K. </author> <year> (1994). </year> <title> Evolving 3d morphology and behavior by competition. </title> <editor> In Brooks & Maes (Eds.), </editor> <booktitle> Artificial Life IV, </booktitle> <pages> pp. 28-39. </pages> <publisher> MIT Press. </publisher>
Reference-contexts: Examples of co-evolutionary learning include the pioneering work by Hillis on sorting networks [Hillis, 1992], by Tesauro on self-playing Backgammon learner [Tesauro, 1992] with a recent follow up by Pollack, Blair and Land [Pollack et al., 1996], by Sims and Ray in evolving life-forms <ref> [Sims, 1994, Ray, 1992] </ref>, by Angeline and Pollack on co-evolving Tic-tac-toe players [Angeline & Pollack, 1993]. In the adaptive behavior community, there is a focus developing on co-evolution in predator/prey games [Reynolds, 1994, Miller & Cliff, 1994]. <p> From the recombinations between individuals of those two sub-populations one may expect the emergence of a better individual that combine the "advantages" of both. Several approaches may be used when simulating a competitive evolution <ref> [Sims, 1994] </ref>. In this work, each generation is composed of a sequence of competition rounds in which individuals are "randomly" paired up.
Reference: [Tesauro, 1992] <author> Tesauro, G. </author> <year> (1992). </year> <title> Practical issues in temporal difference learning. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 257-277. </pages>
Reference-contexts: Examples of co-evolutionary learning include the pioneering work by Hillis on sorting networks [Hillis, 1992], by Tesauro on self-playing Backgammon learner <ref> [Tesauro, 1992] </ref> with a recent follow up by Pollack, Blair and Land [Pollack et al., 1996], by Sims and Ray in evolving life-forms [Sims, 1994, Ray, 1992], by Angeline and Pollack on co-evolving Tic-tac-toe players [Angeline & Pollack, 1993].
References-found: 19

