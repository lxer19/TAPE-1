URL: ftp://ftp.idsia.ch/pub/techrep/IDSIA-08-98.ps.gz
Refering-URL: http://www.idsia.ch/techrep.html
Root-URL: http://www.idsia.ch/techrep.html
Title: H-PIPE: Facilitating Hierarchical Program Evolution through Skip Nodes  
Author: Rafa l Sa lustowicz and Jurgen Schmidhuber 
Keyword: Probabilistic Incremental Program Evolution, Structured Programs, Hierarchical Programs, Introns, Non-Coding Segments.  
Address: Corso Elvezia 36, 6900 Lugano, Switzerland  
Affiliation: IDSIA,  
Pubnum: Technical Report IDSIA-8-98  
Email: e-mail: frafal, juergeng@idsia.ch  
Phone: tel.: +41-91-9919838 fax: +41-91-9919839  
Abstract: To evolve structured programs we introduce H-PIPE, a hierarchical extension of Probabilistic Incremental Program Evolution (PIPE Sa lustowicz and Schmidhuber, 1997). Structure is induced by "hierarchical instructions" (HIs) limited to top-level, structuring program parts. "Skip nodes" (SNs) inspired by biology's introns (non-coding segments) allow for switching program parts on and off. In our experiments H-PIPE outperforms PIPE, and SNs facilitate synthesis of certain structured programs but not unstructured ones. We conclude that introns can be particularly useful in the presence of structural bias. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Angeline, P. J. and Pollack, J. B. </author> <year> (1992). </year> <title> The evolutionary induction of subroutines. </title> <booktitle> In Proceedings of the 14th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 236-241, </pages> <address> Hillsdale, NJ. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Typically subprograms are generated and/or extracted from evolved programs; they may then be called in a usually non-recursive fashion from different positions in the code. Examples are: "automatically defined functions" and encapsulation (Koza, 1992), module acquisition <ref> (Angeline and Pollack, 1992) </ref>, adaptive representations through learning (Rosca and Ballard, 1 1996), automatically defined macros (Spector, 1996).
Reference: <author> Baluja, S. and Caruana, R. </author> <year> (1995). </year> <title> Removing the genetics from the standard genetic algorithm. </title> <editor> In Prieditis, A. and Russell, S., editors, </editor> <booktitle> Machine Learning: Proceedings of the Twelfth International Conference, </booktitle> <pages> pages 38-46. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA. </address>
Reference-contexts: Section 4 concludes this paper. 2 Hierarchical Probabilistic Incremental Program Evolu tion Overview. First we will briefly review PIPE (Sa lustowicz and Schmidhuber, 1997), which combines probability vector coding of program instructions (Schmidhuber et al., 1997a, 1997b) , Po 2 pulation-Based Incremental Learning <ref> (PBIL - Baluja & Caruana, 1995) </ref>, and tree-coded programs like those used in variants of GP. Then we will describe HIs and SNs in detail. 2.1 Probabilistic Incremental Program Evolution (PIPE) Overview. In this section we first summarize PIPE's elementary data structures (programs and the probability distribution).
Reference: <author> Blickle, T. and Thiele, L. </author> <year> (1994). </year> <title> Genetic programming and redundancy. In Hopf, </title> <editor> J., editor, </editor> <booktitle> Genetic Algorithms within the Framework of Evolutionary Computation (Workshop at KI-94, Saarbrucken), </booktitle> <pages> pages 33-38, </pages> <address> Im Stadtwald, Building 44, </address> <institution> D-66123 Saarbrucken, Germany. Max-Planck-Institut fur Informatik (MPI-I-94-241). </institution>
Reference: <author> Cramer, N. L. </author> <year> (1985). </year> <title> A representation for the adaptive generation of simple sequential programs. </title> <editor> In Grefenstette, J., editor, </editor> <booktitle> Proceedings of an International Conference on Genetic Algorithms and Their Applications, </booktitle> <pages> pages 183-187, </pages> <address> Hillsdale, NJ. </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference: <author> Dickmanns, D., Schmidhuber, J., and Winklhofer, A. </author> <year> (1987). </year> <title> Der genetische Algorithmus: Eine Implementierung in Prolog. </title> <institution> Fortgeschrittenenpraktikum, Institut fur Informatik, Lehrstuhl Prof. Radig, Technische Universitat Munchen. </institution>
Reference-contexts: SNs function as gates that allow for keeping program parts dormant without losing them in the course of evolution. In combination with HIs they also enable H-PIPE to substitute program parts by superior partial solutions discovered at later evolutionary stages. Structure. Early genetic programming (GP) work <ref> (Dickmanns et al., 1987) </ref> as well as Adaptive Levin Search (Schmidhuber, 1997; Schmidhuber et al., 1997b) allow for powerful programs with arbitrary loops etc. Sometimes, however, it is beneficial to introduce inductive bias by appropriately constraining the search space of possible programs.
Reference: <author> Gruau, F. </author> <year> (1996). </year> <title> On using syntactic constraints with genetic programming. </title> <editor> In Angeline, P. J. and Kinnear, Jr., K. E., editors, </editor> <booktitle> Advances in Genetic Programming 2, chapter 19, </booktitle> <pages> pages 377-394. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA. </address>
Reference: <author> Haynes, T. </author> <year> (1996). </year> <title> Duplication of coding segments in genetic programming. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 344-349, </pages> <address> Portland, OR. </address>
Reference: <author> Koza, J. R. </author> <year> (1992). </year> <title> Genetic Programming On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press. </publisher>
Reference-contexts: The first reuses program parts, usually in a way less general than that achievable through arbitrary jumps. Typically subprograms are generated and/or extracted from evolved programs; they may then be called in a usually non-recursive fashion from different positions in the code. Examples are: "automatically defined functions" and encapsulation <ref> (Koza, 1992) </ref>, module acquisition (Angeline and Pollack, 1992), adaptive representations through learning (Rosca and Ballard, 1 1996), automatically defined macros (Spector, 1996). <p> Generic Random Constants. A generic random constant (GRC) (compare also "ephemeral random constant" <ref> (Koza, 1992) </ref>) is a zero argument function (a terminal). When accessed during program creation, it is either instantiated to a random value from a predefined, problem-dependent set of constants or a value previously stored together with the probability distribution (see below). Program Representation.
Reference: <author> Langdon, W. B. </author> <year> (1995). </year> <title> Directed crossover within genetic programming. Research Note RN/95/71, </title> <address> University College London, Gower Street, London WC1E 6BT, UK. </address>
Reference: <author> McPhee, N. F. and Miller, J. D. </author> <year> (1995). </year> <title> Accurate replication in genetic programming. </title> <editor> In Eshelman, L., editor, </editor> <booktitle> Genetic Algorithms: Proceedings of the Sixth International Conference (ICGA95), </booktitle> <pages> pages 303-309, </pages> <address> Pittsburgh, PA, USA. </address> <publisher> Morgan Kaufmann. 13 Nordin, </publisher> <editor> P., Francone, F., and Banzhaf, W. </editor> <year> (1996). </year> <title> Explicitly defined introns and destructive crossover in genetic programming. </title> <editor> In Angeline, P. J. and Kinnear, Jr., K. E., editors, </editor> <booktitle> Advances in Genetic Programming 2, chapter 6, </booktitle> <pages> pages 111-134. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA. </address>
Reference: <author> Pringle, W. R. </author> <year> (1995). </year> <title> ESP: Evolutionary structured programming. </title> <type> Technical report, </type> <institution> Penn State University, </institution> <address> Great Valley Campus, PA, USA. </address>
Reference: <author> Rosca, J. P. and Ballard, D. H. </author> <year> (1996). </year> <title> Discovery of subroutines in genetic programming. </title> <editor> In Angeline, P. and K. E. Kinnear, J., editors, </editor> <booktitle> Advances in Genetic Programming 2, page Chapter 9. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Typically subprograms are generated and/or extracted from evolved programs; they may then be called in a usually non-recursive fashion from different positions in the code. Examples are: "automatically defined functions" and encapsulation (Koza, 1992), module acquisition (Angeline and Pollack, 1992), adaptive representations through learning <ref> (Rosca and Ballard, 1 1996) </ref>, automatically defined macros (Spector, 1996). Other approaches do not generate or extract subprograms but restrict GP's recombination operator such that it cannot destroy certain program parts to be reused in the future (e.g., Langdon, 1995; Pringle, 1995; Zannoni and Reynolds, 1997).
Reference: <author> Sa lustowicz, R. P. and Schmidhuber, J. </author> <year> (1997). </year> <title> Probabilistic incremental program evolution. </title> <journal> Evolutionary Computation, </journal> <volume> 5(2) </volume> <pages> 123-141. </pages>
Reference-contexts: 1 Introduction and Previous Work Overview. Hierarchical Probabilistic Incremental Program Evolution (H-PIPE) is a novel method for synthesizing structured programs. It uses the PIPE paradigm <ref> (Sa lustowicz and Schmidhuber, 1997) </ref> to iteratively generate successive populations of functional programs from an adaptive probability distribution over all possible programs constructible from a predefined instruction set. <p> Outline. Section 2 describes the H-PIPE approach. Section 3 compares the use of HIs and SNs to standard PIPE on function regression and 6-bit parity. Section 4 concludes this paper. 2 Hierarchical Probabilistic Incremental Program Evolu tion Overview. First we will briefly review PIPE <ref> (Sa lustowicz and Schmidhuber, 1997) </ref>, which combines probability vector coding of program instructions (Schmidhuber et al., 1997a, 1997b) , Po 2 pulation-Based Incremental Learning (PBIL - Baluja & Caruana, 1995), and tree-coded programs like those used in variants of GP.
Reference: <author> Schmidhuber, J. </author> <year> (1997). </year> <title> Discovering neural nets with low Kolmogorov complexity and high generalization capability. </title> <booktitle> Neural Networks, </booktitle> <volume> 10(5) </volume> <pages> 857-873. </pages>
Reference-contexts: 1 Introduction and Previous Work Overview. Hierarchical Probabilistic Incremental Program Evolution (H-PIPE) is a novel method for synthesizing structured programs. It uses the PIPE paradigm <ref> (Sa lustowicz and Schmidhuber, 1997) </ref> to iteratively generate successive populations of functional programs from an adaptive probability distribution over all possible programs constructible from a predefined instruction set. <p> Outline. Section 2 describes the H-PIPE approach. Section 3 compares the use of HIs and SNs to standard PIPE on function regression and 6-bit parity. Section 4 concludes this paper. 2 Hierarchical Probabilistic Incremental Program Evolu tion Overview. First we will briefly review PIPE <ref> (Sa lustowicz and Schmidhuber, 1997) </ref>, which combines probability vector coding of program instructions (Schmidhuber et al., 1997a, 1997b) , Po 2 pulation-Based Incremental Learning (PBIL - Baluja & Caruana, 1995), and tree-coded programs like those used in variants of GP.
Reference: <author> Schmidhuber, J., Zhao, J., and Schraudolph, N. </author> <year> (1997a). </year> <title> Reinforcement learning with self-modifying policies. </title> <editor> In Thrun, S. and Pratt, L., editors, </editor> <title> Learning to learn. </title> <publisher> Kluwer. in press. </publisher>
Reference-contexts: Section 4 concludes this paper. 2 Hierarchical Probabilistic Incremental Program Evolu tion Overview. First we will briefly review PIPE (Sa lustowicz and Schmidhuber, 1997), which combines probability vector coding of program instructions <ref> (Schmidhuber et al., 1997a, 1997b) </ref> , Po 2 pulation-Based Incremental Learning (PBIL - Baluja & Caruana, 1995), and tree-coded programs like those used in variants of GP. Then we will describe HIs and SNs in detail. 2.1 Probabilistic Incremental Program Evolution (PIPE) Overview.
Reference: <author> Schmidhuber, J., Zhao, J., and Wiering, M. </author> <year> (1997b). </year> <title> Shifting inductive bias with success-story algorithm, adaptive Levin search, and incremental self-improvement. </title> <journal> Machine Learning, </journal> <volume> 28 </volume> <pages> 105-130. </pages>
Reference: <author> Spector, L. </author> <year> (1996). </year> <title> Simultaneous evolution of programs and their control structures. </title> <editor> In Angeline, P. and K. E. Kinnear, J., editors, </editor> <booktitle> Advances in Genetic Programming 2, page Chapter 7. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA. </address>
Reference-contexts: Examples are: "automatically defined functions" and encapsulation (Koza, 1992), module acquisition (Angeline and Pollack, 1992), adaptive representations through learning (Rosca and Ballard, 1 1996), automatically defined macros <ref> (Spector, 1996) </ref>. Other approaches do not generate or extract subprograms but restrict GP's recombination operator such that it cannot destroy certain program parts to be reused in the future (e.g., Langdon, 1995; Pringle, 1995; Zannoni and Reynolds, 1997).
Reference: <author> Whigham, P. A. </author> <year> (1995). </year> <title> Grammatically-based genetic programming. </title> <editor> In Rosca, J. P., editor, </editor> <booktitle> Proceedings of the Workshop on Genetic Programming: From Theory to Real-World Applications, </booktitle> <pages> pages 33-41, </pages> <address> Tahoe City, California, USA. </address>
Reference: <author> Wineberg, M. and Oppacher, F. </author> <year> (1996). </year> <title> The benefits of computing with introns. </title> <editor> In Koza, J. R., Goldberg, D. E., Fogel, D. B., and Riolo, R. L., editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> pages 410-415, </pages> <address> Stanford University, CA, USA. </address> <publisher> MIT Press. </publisher>
Reference: <author> Wong, M. L. and Leung, K. S. </author> <year> (1996). </year> <title> Evolving recursive functions for the even-parity problem using genetic programming. </title> <editor> In Angeline, P. J. and Kinnear, Jr., K. E., editors, </editor> <booktitle> Advances in Genetic Programming 2, chapter 11, </booktitle> <pages> pages 221-240. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA. </address>
Reference-contexts: The second variant uses grammars to induce structure, constrain the search space, and provide initial bias to speed up evolution. Examples are context-free (Whigham, 1995; Gruau, 1996) or logic grammars <ref> (Wong and Leung, 1996) </ref>. Hierarchical Instructions. H-PIPE's programs are composed of instructions from a fixed instruction set S = fI 1 ; I 2 ; : : : ; I z g.
Reference: <author> Zannoni, E. and Reynolds, R. G. </author> <year> (1997). </year> <title> Learning to control the program evolution process with cultural algorithms. </title> <journal> Evolutionary Computation, </journal> <volume> 5(2) </volume> <pages> 181-211. 14 </pages>
References-found: 21

