URL: http://www.cs.huji.ac.il/~feit/parsched/p-95-12.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~feit/parsched/parsched95.html
Root-URL: http://www.cs.huji.ac.il
Title: On the Benefits and Limitations of Dynamic Partitioning in Parallel Computer Systems  
Author: Mark S. Squillante 
Address: Yorktown Heights NY 10598, USA  
Affiliation: IBM T. J. Watson Research Center,  
Abstract: In this paper we analyze the benefits and limitations of dynamic partitioning across a wide range of parallel system environments. We formulate a general model of dynamic partitioning that can be fitted to measurement data to obtain a sufficiently accurate quantitative analysis of real parallel systems executing real scientific and/or commercial workloads. An exact solution of the model is obtained by employing matrix-geometric techniques. We then use this framework to explore the parallel system design space over which dynamic partitioning outperforms other space-sharing policies for a diverse set of application work-loads, quantifying the significant performance improvements within these regions. Our results show that these regions and the performance benefits of dynamic partitioning are heavily dependent upon its associated costs, the system load, and the workload characteristics. We also identify the regions of the design space over which dynamic partitioning performs poorly, quantifying the performance degradation and illustrating forms of unstable thrashing.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Asmussen, O. Nerman, and M. Olsson. </author> <title> Fitting phase type distributions via the EM algorithm. </title> <type> Tech. Rep. </type> <institution> 1994:23, Dept. Math., Chalmers Univ. Tech., </institution> <year> 1994. </year>
Reference-contexts: Just as important, however, is the fact that any real distribution can in principle be represented arbitrarily close by a phase-type distribution. Furthermore, a considerable body of research has examined the fitting of phase-type distributions to empirical data, and a number of algorithms have been developed for doing so <ref> [1, 5, 12, 13] </ref>. It is also well known that some steady-state measures (e.g., mean waiting time) often depend only upon the first few moments of the parameter distributions (as opposed to their detailed forms) in an important and general class of probability models [26, 27, 28].
Reference: 2. <author> S. L. Brumelle. </author> <title> Some inequalities for parallel-server queues. Op. </title> <journal> Res., </journal> <volume> 19 </volume> <pages> 402-413, </pages> <year> 1971. </year>
Reference-contexts: This is due to the fact that the SP (1) system is optimal in this case. The optimality of SP (1) for the linear workload follows directly from a result due to Brumelle <ref> [2] </ref>, where it is shown that the mean response time in a GI=GI=k queue with interarrival and service time distribution functions A (t) and B (t), respectively, is greater than or equal to the mean response time in the GI=GI=1 queue with the same interarrival time distribution and service time distribution
Reference: 3. <author> S.-H. Chiang, R. K. Mansharamani, and M. K. Vernon. </author> <title> Use of application characteristics and limited preemption for run-to-completion parallel processor scheduling policies. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> 33-44, </pages> <year> 1994. </year>
Reference-contexts: Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies <ref> [14, 42, 8, 21, 22, 33, 3, 25] </ref>. This approach tends to outperform its static counterparts by adapting partition sizes to the current load. However, the performance benefits of adaptive partitioning can be limited due to its inability to adjust scheduling decisions in response to subsequent workload changes.
Reference: 4. <author> K. Dussa, B. Carlson, L. Dowdy, and K.-H. Park. </author> <title> Dynamic partitioning in trans-puter environments. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> 203-213, </pages> <year> 1990. </year>
Reference-contexts: These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration. <p> In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application <ref> [4, 21, 22, 30] </ref>. Even with continuing reductions in the latency of interprocessor communication [41, 39], there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) [19, 20, 18]. <p> The times at which jobs arrive to the system are defined by the distributions A i , 0 i N , which are dependent upon the number of jobs i in the system. These arrival times are most often modeled by a Poisson distribution in the research literature <ref> [4, 42, 21, 22, 33, 17, 32, 25] </ref>.
Reference: 5. <author> M. J. Faddy. </author> <title> Fitting structured phase-type distributions. </title> <type> Tech. Rep., </type> <institution> Dept. Math., Univ. Queensland, Australia, </institution> <year> 1994. </year> <note> To appear, Appl. Stoch. Mod. Data Anal.. </note>
Reference-contexts: Just as important, however, is the fact that any real distribution can in principle be represented arbitrarily close by a phase-type distribution. Furthermore, a considerable body of research has examined the fitting of phase-type distributions to empirical data, and a number of algorithms have been developed for doing so <ref> [1, 5, 12, 13] </ref>. It is also well known that some steady-state measures (e.g., mean waiting time) often depend only upon the first few moments of the parameter distributions (as opposed to their detailed forms) in an important and general class of probability models [26, 27, 28].
Reference: 6. <author> D. G. Feitelson and B. Nitzberg. </author> <title> Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860. In Job Scheduling Strategies for Parallel Processing, </title> <editor> D. G. Feitelson and L. Rudolph (eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1995. </year> <note> Lecture Notes in Computer Science Vol. 949. </note>
Reference-contexts: The static scheduling approach, however, can lead to relatively low system throughputs and resource utilizations under nonuniform workloads [34, 21, 22, 25, 35], as is common in scientific/engineering computing environments <ref> [6] </ref>. Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies [14, 42, 8, 21, 22, 33, 3, 25]. <p> On the other hand, current and expected workloads for large-scale parallel computing environments consist of a mixture of such jobs with very different resource requirements, often resulting in a highly variable workload <ref> [29, 21, 22, 6] </ref>. We thus use model parameter distributions that reflect this variability in the resource requirements of the system workload. <p> A deterministic distribution has a coefficient of variation equal to 0. 2 There exists evidence suggesting that the coefficient of variation for the workload, in many cases, is larger than 1 <ref> [21, 22, 6] </ref>. We are currently working on results for the case of hyperexponential service time and reconfiguration overhead distributions to address such workloads, noting that the hyperexponential distribution is a very simple instance of a phase-type distribution. <p> In particular, we use a binary search 4 There exists evidence suggesting that the interarrival times of jobs, in some cases, is more variable than the exponential assumption considered here <ref> [6] </ref>.
Reference: 7. <author> G. C. Fox, M. A. Johnson, G. A. Lyzenga, S. W. Otto, J. K. Salmon, and D. W. Walker. </author> <title> Solving Problems on Concurrent Processors Volume I: General Techniques and Regular Problems. </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference-contexts: Throughout this section we let e S t (1) = 1000. The workload speedup function can be written as <ref> [7, 32] </ref> S (n) = 1 + f O (n) where f O () is used here to reflect the various types of overhead that can reduce the workload speedup function from being linear. <p> For a large class of parallel applications, the factor f O () is dominated by issues related to communication <ref> [7] </ref>. It therefore can be approximated within the context of our model by f O (n) = F n 1=d ; n 1; (15) where F is a constant that depends upon the system architecture and the application workload, and d is the system dimension. <p> In the results that follow, we consider the values F 2 f0:025; 0:175; 1:225g and d 2 f2; 3g which cover a range of parameters provided in <ref> [7] </ref>. We also consider the overheads f O (n) 2 f0; n 1g, which represent the extremes of linear and constant workload speedup functions.
Reference: 8. <author> D. Ghosal, G. Serazzi, and S. K. Tripathi. </author> <title> The processor working set and its use in scheduling multiprocessor systems. </title> <journal> IEEE Trans. Soft. Eng., </journal> <volume> 17 </volume> <pages> 443-453, </pages> <year> 1991. </year>
Reference-contexts: Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies <ref> [14, 42, 8, 21, 22, 33, 3, 25] </ref>. This approach tends to outperform its static counterparts by adapting partition sizes to the current load. However, the performance benefits of adaptive partitioning can be limited due to its inability to adjust scheduling decisions in response to subsequent workload changes.
Reference: 9. <author> A. Gupta, A. Tucker, and S. Urushibara. </author> <title> The impact of operating system scheduling policies and synchronization methods on the performance of parallel applications. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <year> 1991. </year>
Reference-contexts: These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration. <p> In uniform-access, shared-memory (UMA) systems, these overheads tend to be relatively small and thus the benefits of dynamic partitioning outweigh its associated costs. Several research studies have made this quite clear, showing that dynamic partitioning outperforms all other space-sharing strategies in many UMA environments <ref> [40, 14, 42, 9, 16] </ref>. In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application [4, 21, 22, 30].
Reference: 10. <author> L. Kleinrock. </author> <title> Queueing Systems Volume I: Theory. </title> <publisher> John Wiley and Sons, </publisher> <year> 1975. </year>
Reference-contexts: It is well known that the steady-state probability vector can be obtained by solving the global balance equations Q = 0; (3) together with the constraint that the sum of these components must be 1 <ref> [10] </ref>. We arrange the transition rate matrix Q of the Markov chain in the same order as the elements of the steady-state probability vector , and we block-partition the matrix according to the state space levels. <p> This service time assumption matches various instances of a workload based on measurement data of computational fluid dynamics applications [21, 22]. 2 1 The coefficient of variation is the ratio of the standard deviation to the mean <ref> [10] </ref>. A deterministic distribution has a coefficient of variation equal to 0. 2 There exists evidence suggesting that the coefficient of variation for the workload, in many cases, is larger than 1 [21, 22, 6]. <p> Hence, the mean job response time in the SP (K) system, denoted by T SP (K) , is obtained from the well-known solution of the M/M/K queueing system <ref> [10] </ref>.
Reference: 11. <author> L. Kleinrock. </author> <title> Queueing Systems Volume II: Computer Applications. </title> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: Response Time Contours (log scale) with respect to Dynamic and Optimal Static Partitioning, for P = 32 Fig. 3. Response Time Contours (log scale) with respect to Dynamic and Optimal Static Partitioning, for P = 64 to 1. Given the optimality of shortest-job-first in uniprocessor systems <ref> [11] </ref>, our results for linear workloads suggest that time sharing all of the processors among the jobs (in a sufficiently coarse manner to outweigh the overhead of context switching) may provide the best steady-state performance when the workload Fig. 4.
Reference: 12. <author> A. Lang. </author> <title> Parameter estimation for phase-type distributions, part I: Fundamentals and existing methods. </title> <type> Tech. Rep. 159, </type> <institution> Dept. Stats., Oregon State Univ., </institution> <year> 1994. </year>
Reference-contexts: Just as important, however, is the fact that any real distribution can in principle be represented arbitrarily close by a phase-type distribution. Furthermore, a considerable body of research has examined the fitting of phase-type distributions to empirical data, and a number of algorithms have been developed for doing so <ref> [1, 5, 12, 13] </ref>. It is also well known that some steady-state measures (e.g., mean waiting time) often depend only upon the first few moments of the parameter distributions (as opposed to their detailed forms) in an important and general class of probability models [26, 27, 28].
Reference: 13. <author> A. Lang and J. L. Arthur. </author> <title> Parameter estimation for phase-type distributions, part II: Computational evaluation. </title> <type> Tech. Rep. 160, </type> <institution> Dept. Stats., Oregon State Univ., </institution> <year> 1994. </year>
Reference-contexts: Just as important, however, is the fact that any real distribution can in principle be represented arbitrarily close by a phase-type distribution. Furthermore, a considerable body of research has examined the fitting of phase-type distributions to empirical data, and a number of algorithms have been developed for doing so <ref> [1, 5, 12, 13] </ref>. It is also well known that some steady-state measures (e.g., mean waiting time) often depend only upon the first few moments of the parameter distributions (as opposed to their detailed forms) in an important and general class of probability models [26, 27, 28].
Reference: 14. <author> S. T. Leutenegger and M. K. Vernon. </author> <title> The performance of multiprogrammed multiprocessor scheduling policies. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> 226-236, </pages> <year> 1990. </year>
Reference-contexts: Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies <ref> [14, 42, 8, 21, 22, 33, 3, 25] </ref>. This approach tends to outperform its static counterparts by adapting partition sizes to the current load. However, the performance benefits of adaptive partitioning can be limited due to its inability to adjust scheduling decisions in response to subsequent workload changes. <p> These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration. <p> In uniform-access, shared-memory (UMA) systems, these overheads tend to be relatively small and thus the benefits of dynamic partitioning outweigh its associated costs. Several research studies have made this quite clear, showing that dynamic partitioning outperforms all other space-sharing strategies in many UMA environments <ref> [40, 14, 42, 9, 16] </ref>. In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application [4, 21, 22, 30].
Reference: 15. <author> R. K. Mansharamani and M. K. Vernon. </author> <title> Properties of the EQS parallel processor allocation policy. </title> <type> Tech. Rep. 1192, </type> <institution> Univ. Wisconsin, Comp. Sci. Dept., </institution> <year> 1993. </year>
Reference-contexts: The mean response time under the optimal static partitioning policy, for a given arrival rate, is therefore given by T Opt-SP () = min f T SP (K) () g: (16) Our decision to consider equal-sized processor partitions is motivated by the results of recent studies <ref> [25, 15] </ref> showing that adaptive/static strategies in which the system is divided into equal-sized partitions outperform other adaptive/static policies when job service time requirements are not used in scheduling decisions.
Reference: 16. <author> C. McCann, R. Vaswani, and J. Zahorjan. </author> <title> A dynamic processor allocation policy for multiprogrammed shared-memory multiprocessors. </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> 11(2) </volume> <pages> 146-178, </pages> <year> 1993. </year>
Reference-contexts: These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration. <p> In uniform-access, shared-memory (UMA) systems, these overheads tend to be relatively small and thus the benefits of dynamic partitioning outweigh its associated costs. Several research studies have made this quite clear, showing that dynamic partitioning outperforms all other space-sharing strategies in many UMA environments <ref> [40, 14, 42, 9, 16] </ref>. In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application [4, 21, 22, 30].
Reference: 17. <author> C. McCann and J. Zahorjan. </author> <title> Processor allocation policies for message-passing parallel computers. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> 19-32, </pages> <year> 1994. </year>
Reference-contexts: The times at which jobs arrive to the system are defined by the distributions A i , 0 i N , which are dependent upon the number of jobs i in the system. These arrival times are most often modeled by a Poisson distribution in the research literature <ref> [4, 42, 21, 22, 33, 17, 32, 25] </ref>.
Reference: 18. <author> N. H. Naik, V. K. Naik, and M. Nicoules. </author> <title> Parallelization of a class of implicit finite difference schemes in computational fluid dynamics. </title> <journal> Intl. J. High-Speed Comp., </journal> <volume> 5, </volume> <year> 1993. </year>
Reference-contexts: Even with continuing reductions in the latency of interprocessor communication [41, 39], there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) <ref> [19, 20, 18] </ref>.
Reference: 19. <author> V. K. Naik. </author> <title> Performance effects of load imbalance in parallel CFD applications. </title> <booktitle> In Proc. SIAM Conf. Par. Proc., </booktitle> <year> 1992. </year>
Reference-contexts: Even with continuing reductions in the latency of interprocessor communication [41, 39], there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) <ref> [19, 20, 18] </ref>.
Reference: 20. <author> V. K. Naik. </author> <title> Scalability issues for a class of CFD applications. </title> <booktitle> In Proc. Scal. High Perf. Comp. Conf., </booktitle> <pages> 268-275, </pages> <year> 1992. </year>
Reference-contexts: Even with continuing reductions in the latency of interprocessor communication [41, 39], there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) <ref> [19, 20, 18] </ref>.
Reference: 21. <author> V. K. Naik, S. K. Setia, and M. S. Squillante. </author> <title> Performance analysis of job scheduling policies in parallel supercomputing environments. </title> <booktitle> In Proc. Supercomputing '93, </booktitle> <pages> 824-833, </pages> <year> 1993. </year>
Reference-contexts: This is due in part to its low system overhead and its simplicity from both the system and application viewpoints. The static scheduling approach, however, can lead to relatively low system throughputs and resource utilizations under nonuniform workloads <ref> [34, 21, 22, 25, 35] </ref>, as is common in scientific/engineering computing environments [6]. <p> Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies <ref> [14, 42, 8, 21, 22, 33, 3, 25] </ref>. This approach tends to outperform its static counterparts by adapting partition sizes to the current load. However, the performance benefits of adaptive partitioning can be limited due to its inability to adjust scheduling decisions in response to subsequent workload changes. <p> These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration. <p> In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application <ref> [4, 21, 22, 30] </ref>. Even with continuing reductions in the latency of interprocessor communication [41, 39], there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) [19, 20, 18]. <p> On the other hand, current and expected workloads for large-scale parallel computing environments consist of a mixture of such jobs with very different resource requirements, often resulting in a highly variable workload <ref> [29, 21, 22, 6] </ref>. We thus use model parameter distributions that reflect this variability in the resource requirements of the system workload. <p> This service time assumption matches various instances of a workload based on measurement data of computational fluid dynamics applications <ref> [21, 22] </ref>. 2 1 The coefficient of variation is the ratio of the standard deviation to the mean [10]. <p> A deterministic distribution has a coefficient of variation equal to 0. 2 There exists evidence suggesting that the coefficient of variation for the workload, in many cases, is larger than 1 <ref> [21, 22, 6] </ref>. We are currently working on results for the case of hyperexponential service time and reconfiguration overhead distributions to address such workloads, noting that the hyperexponential distribution is a very simple instance of a phase-type distribution. <p> The times at which jobs arrive to the system are defined by the distributions A i , 0 i N , which are dependent upon the number of jobs i in the system. These arrival times are most often modeled by a Poisson distribution in the research literature <ref> [4, 42, 21, 22, 33, 17, 32, 25] </ref>. <p> Several recent research studies, under different workload assumptions, have also shown that adaptive partitioning yields steady-state performance comparable to that of the optimal static partitioning policy for a given value of <ref> [21, 22, 33] </ref>. Hence, when this relation holds, the mean job response time under adaptive partitioning is accurately approximated by equation (16) and the results of the next section are also representative of a comparison between adaptive and dynamic partitioning policies. <p> An interruptible list, containing those jobs in execution that are eligible for reconfiguration, can be used to prevent thrashing by removing a job from the list (making it ineligible for repartitioning) for some period of time after it has been reconfigured <ref> [21, 22] </ref>. Since the costs of reconfiguration often depend upon the problem size [21, 22, 30], having the user provide such information can facilitate even better repartition-ing decisions by the scheduling policy. <p> Since the costs of reconfiguration often depend upon the problem size <ref> [21, 22, 30] </ref>, having the user provide such information can facilitate even better repartition-ing decisions by the scheduling policy.
Reference: 22. <author> V. K. Naik, S. K. Setia, and M. S. Squillante. </author> <title> Scheduling of large scientific applications on distributed memory multiprocessor systems. </title> <booktitle> In Proc. SIAM Conf. Par. Proc. Sci. Comp., </booktitle> <pages> 913-922, </pages> <year> 1993. </year>
Reference-contexts: This is due in part to its low system overhead and its simplicity from both the system and application viewpoints. The static scheduling approach, however, can lead to relatively low system throughputs and resource utilizations under nonuniform workloads <ref> [34, 21, 22, 25, 35] </ref>, as is common in scientific/engineering computing environments [6]. <p> Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies <ref> [14, 42, 8, 21, 22, 33, 3, 25] </ref>. This approach tends to outperform its static counterparts by adapting partition sizes to the current load. However, the performance benefits of adaptive partitioning can be limited due to its inability to adjust scheduling decisions in response to subsequent workload changes. <p> These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration. <p> In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application <ref> [4, 21, 22, 30] </ref>. Even with continuing reductions in the latency of interprocessor communication [41, 39], there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) [19, 20, 18]. <p> On the other hand, current and expected workloads for large-scale parallel computing environments consist of a mixture of such jobs with very different resource requirements, often resulting in a highly variable workload <ref> [29, 21, 22, 6] </ref>. We thus use model parameter distributions that reflect this variability in the resource requirements of the system workload. <p> This service time assumption matches various instances of a workload based on measurement data of computational fluid dynamics applications <ref> [21, 22] </ref>. 2 1 The coefficient of variation is the ratio of the standard deviation to the mean [10]. <p> A deterministic distribution has a coefficient of variation equal to 0. 2 There exists evidence suggesting that the coefficient of variation for the workload, in many cases, is larger than 1 <ref> [21, 22, 6] </ref>. We are currently working on results for the case of hyperexponential service time and reconfiguration overhead distributions to address such workloads, noting that the hyperexponential distribution is a very simple instance of a phase-type distribution. <p> The times at which jobs arrive to the system are defined by the distributions A i , 0 i N , which are dependent upon the number of jobs i in the system. These arrival times are most often modeled by a Poisson distribution in the research literature <ref> [4, 42, 21, 22, 33, 17, 32, 25] </ref>. <p> Several recent research studies, under different workload assumptions, have also shown that adaptive partitioning yields steady-state performance comparable to that of the optimal static partitioning policy for a given value of <ref> [21, 22, 33] </ref>. Hence, when this relation holds, the mean job response time under adaptive partitioning is accurately approximated by equation (16) and the results of the next section are also representative of a comparison between adaptive and dynamic partitioning policies. <p> An interruptible list, containing those jobs in execution that are eligible for reconfiguration, can be used to prevent thrashing by removing a job from the list (making it ineligible for repartitioning) for some period of time after it has been reconfigured <ref> [21, 22] </ref>. Since the costs of reconfiguration often depend upon the problem size [21, 22, 30], having the user provide such information can facilitate even better repartition-ing decisions by the scheduling policy. <p> Since the costs of reconfiguration often depend upon the problem size <ref> [21, 22, 30] </ref>, having the user provide such information can facilitate even better repartition-ing decisions by the scheduling policy.
Reference: 23. <author> R. D. Nelson and M. S. Squillante. </author> <title> The MAtrix-Geometric qUeueing model Solution package (MAGUS) user manual. </title> <type> Tech. Rep. RC, </type> <institution> IBM Res. Div., </institution> <year> 1994. </year>
Reference-contexts: The solution of the matrix R, the steady-state probability vector , and equations (9) - (11) are all efficiently computed by the routines provided by the MAGUS performance modeling tool <ref> [23, 36] </ref>. 4 Results Our dynamic partitioning model can be fitted to measurement data to obtain a sufficiently accurate quantitative analysis of dynamic partitioning in real parallel systems executing real scientific and/or commercial workloads. <p> We first provide some technical preliminaries that support the analysis of this section, including our assumptions based upon previous research. Our results, a portion of which are subsequently presented, were obtained with the MAGUS performance modeling tool <ref> [23, 36] </ref>. We assume throughout that M = 1, and thus N = P . 4.1 Preliminaries The execution time of many parallel applications on a fixed number of processors for a given problem size is either constant or bounded between relatively tight upper and lower bounds.
Reference: 24. <author> M. F. Neuts. </author> <title> Matrix-Geometric Solutions in Stochastic Models: An Algorithmic Approach. </title> <publisher> The Johns Hopkins Univ. Press, </publisher> <year> 1981. </year>
Reference-contexts: We formulate a general model of dynamic partitioning in parallel computer systems that can be fitted to measurement data to obtain a sufficiently accurate quantitative analysis of real parallel systems executing real scientific and/or commercial workloads. An exact solution of the model is obtained by employing matrix-geometric techniques <ref> [24] </ref>. In this paper we provide a less formal and rigorous description of our mathematical analysis, and we refer the interested reader to [37, 38] for additional technical details. <p> Multiple job arrivals, multiple job departures, and both an arrival and a departure within a small time interval are all assumed to occur with negligible probability, leading to a quasi-birth-death process <ref> [24] </ref> (although our analysis is easily extended to handle batch arrivals and/or departures as long as the batch sizes are bounded; see [38]). The use of phase-type distributions [24] for the parameters of our model is motivated in part by their important mathematical properties, which can be exploited to obtain a <p> arrival and a departure within a small time interval are all assumed to occur with negligible probability, leading to a quasi-birth-death process <ref> [24] </ref> (although our analysis is easily extended to handle batch arrivals and/or departures as long as the batch sizes are bounded; see [38]). The use of phase-type distributions [24] for the parameters of our model is motivated in part by their important mathematical properties, which can be exploited to obtain a tractable analytic model while capturing the fundamental aspects of dynamic partitioning. <p> This Markov chain has a particular structure that we exploit, using matrix-geometric techniques <ref> [24] </ref>, to obtain an exact model solution in an extremely efficient manner. In this section we provide a less formal and rigorous mathematical analysis of the model, and we refer the interested reader to [37, 38] for additional technical details. <p> Given the form in equation (4) for the transition rate matrix of the Markov chain, the solution of the global balance equations in (3) and the normalization constraint can be obtained exactly via matrix-geometric techniques <ref> [24] </ref>.
Reference: 25. <author> E. Rosti, E. Smirni, L. W. Dowdy, G. Serazzi, and B. M. Carlson. </author> <title> Robust partitioning policies of multiprocessor systems. </title> <booktitle> Perf. Eval., </booktitle> <volume> 19 </volume> <pages> 141-165, </pages> <year> 1994. </year>
Reference-contexts: This is due in part to its low system overhead and its simplicity from both the system and application viewpoints. The static scheduling approach, however, can lead to relatively low system throughputs and resource utilizations under nonuniform workloads <ref> [34, 21, 22, 25, 35] </ref>, as is common in scientific/engineering computing environments [6]. <p> Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies <ref> [14, 42, 8, 21, 22, 33, 3, 25] </ref>. This approach tends to outperform its static counterparts by adapting partition sizes to the current load. However, the performance benefits of adaptive partitioning can be limited due to its inability to adjust scheduling decisions in response to subsequent workload changes. <p> The times at which jobs arrive to the system are defined by the distributions A i , 0 i N , which are dependent upon the number of jobs i in the system. These arrival times are most often modeled by a Poisson distribution in the research literature <ref> [4, 42, 21, 22, 33, 17, 32, 25] </ref>. <p> The mean response time under the optimal static partitioning policy, for a given arrival rate, is therefore given by T Opt-SP () = min f T SP (K) () g: (16) Our decision to consider equal-sized processor partitions is motivated by the results of recent studies <ref> [25, 15] </ref> showing that adaptive/static strategies in which the system is divided into equal-sized partitions outperform other adaptive/static policies when job service time requirements are not used in scheduling decisions.
Reference: 26. <author> R. Schassberger. </author> <title> Insensitivity of steady-state distributions of generalized semi-Markov processes, part I. </title> <journal> Ann. Prob., </journal> <volume> 5(1) </volume> <pages> 87-99, </pages> <year> 1977. </year>
Reference-contexts: It is also well known that some steady-state measures (e.g., mean waiting time) often depend only upon the first few moments of the parameter distributions (as opposed to their detailed forms) in an important and general class of probability models <ref> [26, 27, 28] </ref>.
Reference: 27. <author> R. Schassberger. </author> <title> Insensitivity of steady-state distributions of generalized semi-Markov processes, part II. </title> <journal> Ann. Prob., </journal> <volume> 6(1) </volume> <pages> 85-93, </pages> <year> 1978. </year>
Reference-contexts: It is also well known that some steady-state measures (e.g., mean waiting time) often depend only upon the first few moments of the parameter distributions (as opposed to their detailed forms) in an important and general class of probability models <ref> [26, 27, 28] </ref>.
Reference: 28. <author> R. Schassberger. </author> <title> Insensitivity of steady-state distributions of generalized semi-Markov process with speeds. </title> <journal> Advs. Appl. Prob., </journal> <volume> 10 </volume> <pages> 836-851, </pages> <year> 1978. </year>
Reference-contexts: It is also well known that some steady-state measures (e.g., mean waiting time) often depend only upon the first few moments of the parameter distributions (as opposed to their detailed forms) in an important and general class of probability models <ref> [26, 27, 28] </ref>.
Reference: 29. <author> R. Schreiber and H. D. Simon. </author> <title> Towards the teraflops capability for CFD. </title> <editor> In H. D. Simon, editor, </editor> <title> Parallel CFD Implementations and Results Using Parallel Computers. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: On the other hand, current and expected workloads for large-scale parallel computing environments consist of a mixture of such jobs with very different resource requirements, often resulting in a highly variable workload <ref> [29, 21, 22, 6] </ref>. We thus use model parameter distributions that reflect this variability in the resource requirements of the system workload.
Reference: 30. <author> S. K. Setia. </author> <title> Scheduling on Multiprogrammed, Distributed Memory Parallel Com--puters. </title> <type> PhD thesis, </type> <institution> Dept. Comp. Sci., Univ. Maryland, College Park, MD, </institution> <year> 1993. </year>
Reference-contexts: In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application <ref> [4, 21, 22, 30] </ref>. Even with continuing reductions in the latency of interprocessor communication [41, 39], there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) [19, 20, 18]. <p> Since the costs of reconfiguration often depend upon the problem size <ref> [21, 22, 30] </ref>, having the user provide such information can facilitate even better repartition-ing decisions by the scheduling policy.
Reference: 31. <author> S. K. Setia, M. S. Squillante, and S. K. Tripathi. </author> <title> Processor scheduling on multipro-grammed, distributed memory parallel computers. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> 158-170, </pages> <year> 1993. </year>
Reference-contexts: We also note that the benefits of using time sharing together with a static partitioning policy have been observed for a different region of the parallel system design space <ref> [31] </ref>. We observe that the values of e R fl are also equal to zero for the constant workload.
Reference: 32. <author> S. K. Setia, M. S. Squillante, and S. K. Tripathi. </author> <title> Analysis of processor allocation in multiprogrammed, distributed-memory parallel processing systems. </title> <journal> IEEE Trans. Par. Dist. Syst., </journal> <volume> 5(4) </volume> <pages> 401-420, </pages> <year> 1994. </year>
Reference-contexts: Throughout this section we let e S t (1) = 1000. The workload speedup function can be written as <ref> [7, 32] </ref> S (n) = 1 + f O (n) where f O () is used here to reflect the various types of overhead that can reduce the workload speedup function from being linear. <p> The times at which jobs arrive to the system are defined by the distributions A i , 0 i N , which are dependent upon the number of jobs i in the system. These arrival times are most often modeled by a Poisson distribution in the research literature <ref> [4, 42, 21, 22, 33, 17, 32, 25] </ref>.
Reference: 33. <author> S. K. Setia and S. K. Tripathi. </author> <title> A comparative analysis of static processor partitioning policies for parallel computers. </title> <booktitle> In Proc. </booktitle> <volume> MASCOTS '93, </volume> <year> 1993. </year>
Reference-contexts: Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies <ref> [14, 42, 8, 21, 22, 33, 3, 25] </ref>. This approach tends to outperform its static counterparts by adapting partition sizes to the current load. However, the performance benefits of adaptive partitioning can be limited due to its inability to adjust scheduling decisions in response to subsequent workload changes. <p> The times at which jobs arrive to the system are defined by the distributions A i , 0 i N , which are dependent upon the number of jobs i in the system. These arrival times are most often modeled by a Poisson distribution in the research literature <ref> [4, 42, 21, 22, 33, 17, 32, 25] </ref>. <p> Several recent research studies, under different workload assumptions, have also shown that adaptive partitioning yields steady-state performance comparable to that of the optimal static partitioning policy for a given value of <ref> [21, 22, 33] </ref>. Hence, when this relation holds, the mean job response time under adaptive partitioning is accurately approximated by equation (16) and the results of the next section are also representative of a comparison between adaptive and dynamic partitioning policies.
Reference: 34. <author> K. C. Sevcik. </author> <title> Characterizations of parallelism in applications and their use in scheduling. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> 171-180, </pages> <year> 1989. </year>
Reference-contexts: This is due in part to its low system overhead and its simplicity from both the system and application viewpoints. The static scheduling approach, however, can lead to relatively low system throughputs and resource utilizations under nonuniform workloads <ref> [34, 21, 22, 25, 35] </ref>, as is common in scientific/engineering computing environments [6].
Reference: 35. <author> K. C. Sevcik. </author> <title> Application scheduling and processor allocation in multiprogrammed parallel processing systems. </title> <booktitle> Perf. Eval., </booktitle> <volume> 19 </volume> <pages> 107-140, </pages> <year> 1994. </year>
Reference-contexts: This is due in part to its low system overhead and its simplicity from both the system and application viewpoints. The static scheduling approach, however, can lead to relatively low system throughputs and resource utilizations under nonuniform workloads <ref> [34, 21, 22, 25, 35] </ref>, as is common in scientific/engineering computing environments [6]. <p> These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration.
Reference: 36. <author> M. S. Squillante. </author> <title> MAGIC: A computer performance modeling tool based on matrix-geometric techniques. </title> <booktitle> In Proc. Intl. Conf. Mod. Tech. Tools Comp. Perf. Eval., </booktitle> <pages> 411-425, </pages> <year> 1991. </year>
Reference-contexts: The solution of the matrix R, the steady-state probability vector , and equations (9) - (11) are all efficiently computed by the routines provided by the MAGUS performance modeling tool <ref> [23, 36] </ref>. 4 Results Our dynamic partitioning model can be fitted to measurement data to obtain a sufficiently accurate quantitative analysis of dynamic partitioning in real parallel systems executing real scientific and/or commercial workloads. <p> We first provide some technical preliminaries that support the analysis of this section, including our assumptions based upon previous research. Our results, a portion of which are subsequently presented, were obtained with the MAGUS performance modeling tool <ref> [23, 36] </ref>. We assume throughout that M = 1, and thus N = P . 4.1 Preliminaries The execution time of many parallel applications on a fixed number of processors for a given problem size is either constant or bounded between relatively tight upper and lower bounds.
Reference: 37. <author> M. S. Squillante. </author> <title> Analysis of dynamic partitioning in parallel systems. </title> <type> Tech. Rep. </type> <institution> RC 19950, IBM Res. Div., </institution> <year> 1995. </year>
Reference-contexts: An exact solution of the model is obtained by employing matrix-geometric techniques [24]. In this paper we provide a less formal and rigorous description of our mathematical analysis, and we refer the interested reader to <ref> [37, 38] </ref> for additional technical details. It is important to note that the computational efficiency of our approach allows us to examine the large design space of diverse parallel environments. <p> This Markov chain has a particular structure that we exploit, using matrix-geometric techniques [24], to obtain an exact model solution in an extremely efficient manner. In this section we provide a less formal and rigorous mathematical analysis of the model, and we refer the interested reader to <ref> [37, 38] </ref> for additional technical details. A closed-form solution for the specific case where the model parameters all have exponential distributions, and an analysis of optimal static partitioning under assumptions corresponding to those in Section 2 are also provided in [37]. <p> A closed-form solution for the specific case where the model parameters all have exponential distributions, and an analysis of optimal static partitioning under assumptions corresponding to those in Section 2 are also provided in <ref> [37] </ref>. <p> thus assume that jobs come 3 The details of exactly how the dynamic partitioning policy allocates processors to jobs when i does not evenly divide P , as well as the service rates for each of these cases, are easily incorporated in our model (see Sections 2 and 3, and <ref> [37, 38] </ref>). <p> Consider a system in which the processors are statically divided into K partitions each of size P=K, where only values of K that evenly divide P are examined. We refer to this system as SP (K). Under the above model parameter assumptions (see <ref> [37] </ref> for a more general analysis), this system is equivalent to an M/M/K queue with arrival rate and service rate S (P=K). <p> In the limit as the system approaches saturation, the probability that the system repartitions the processors tends toward 0, i.e., the frequency of reconfigurations decreases to 0 as the Markov chain spends essentially all of its time at or above level N (see <ref> [37] </ref> for the technical details). It therefore follows that the dynamic partitioning system converges toward SP (P ) in the limit as the system approaches saturation.
Reference: 38. <author> M. S. Squillante. </author> <title> On the benefits and limitations of dynamic partitioning in parallel computer systems. </title> <type> Tech. Rep. </type> <institution> RC 19951, IBM Res. Div., </institution> <year> 1995. </year>
Reference-contexts: An exact solution of the model is obtained by employing matrix-geometric techniques [24]. In this paper we provide a less formal and rigorous description of our mathematical analysis, and we refer the interested reader to <ref> [37, 38] </ref> for additional technical details. It is important to note that the computational efficiency of our approach allows us to examine the large design space of diverse parallel environments. <p> multiple job departures, and both an arrival and a departure within a small time interval are all assumed to occur with negligible probability, leading to a quasi-birth-death process [24] (although our analysis is easily extended to handle batch arrivals and/or departures as long as the batch sizes are bounded; see <ref> [38] </ref>). The use of phase-type distributions [24] for the parameters of our model is motivated in part by their important mathematical properties, which can be exploited to obtain a tractable analytic model while capturing the fundamental aspects of dynamic partitioning. <p> This Markov chain has a particular structure that we exploit, using matrix-geometric techniques [24], to obtain an exact model solution in an extremely efficient manner. In this section we provide a less formal and rigorous mathematical analysis of the model, and we refer the interested reader to <ref> [37, 38] </ref> for additional technical details. A closed-form solution for the specific case where the model parameters all have exponential distributions, and an analysis of optimal static partitioning under assumptions corresponding to those in Section 2 are also provided in [37]. <p> thus assume that jobs come 3 The details of exactly how the dynamic partitioning policy allocates processors to jobs when i does not evenly divide P , as well as the service rates for each of these cases, are easily incorporated in our model (see Sections 2 and 3, and <ref> [37, 38] </ref>).
Reference: 39. <author> C. A. Thekkath and H. M. Levy. </author> <title> Limits to low-latency communication on high-speed networks. </title> <journal> ACM Trans. Comp. Syst., </journal> <volume> 11(2) </volume> <pages> 179-203, </pages> <year> 1993. </year>
Reference-contexts: Even with continuing reductions in the latency of interprocessor communication <ref> [41, 39] </ref>, there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) [19, 20, 18].
Reference: 40. <author> A. Tucker and A. Gupta. </author> <title> Process control and scheduling issues for multipro-grammed shared-memory multiprocessors. </title> <booktitle> In Proc. ACM Symp. Op. Syst. Prin., </booktitle> <pages> 159-166, </pages> <year> 1989. </year>
Reference-contexts: These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration. <p> In uniform-access, shared-memory (UMA) systems, these overheads tend to be relatively small and thus the benefits of dynamic partitioning outweigh its associated costs. Several research studies have made this quite clear, showing that dynamic partitioning outperforms all other space-sharing strategies in many UMA environments <ref> [40, 14, 42, 9, 16] </ref>. In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application [4, 21, 22, 30].
Reference: 41. <author> T. von Eicken, D. E. Culler, S. C. Goldstein, and K. E. Schauser. </author> <title> Active messages: A mechanism for integrated communication and computation. </title> <booktitle> In Proc. Intl. Symp. Comp. Arch., </booktitle> <pages> 256-266, </pages> <year> 1992. </year>
Reference-contexts: Even with continuing reductions in the latency of interprocessor communication <ref> [41, 39] </ref>, there are other factors that can cause the cost of repartitioning to be significant for important classes of scientific/engineering applications (e.g., the need to reconfigure the application) [19, 20, 18].
Reference: 42. <author> J. Zahorjan and C. McCann. </author> <title> Processor scheduling in shared memory multiprocessors. </title> <booktitle> In Proc. ACM SIGMETRICS Conf., </booktitle> <pages> 214-225, </pages> <year> 1990. </year>
Reference-contexts: Adaptive partitioning policies, where the number of processors allocated to a job is determined when jobs arrive and depart based on the current system state, have also been considered in a number of research studies <ref> [14, 42, 8, 21, 22, 33, 3, 25] </ref>. This approach tends to outperform its static counterparts by adapting partition sizes to the current load. However, the performance benefits of adaptive partitioning can be limited due to its inability to adjust scheduling decisions in response to subsequent workload changes. <p> These potential problems are alleviated under dynamic partitioning, where the size of the partition allocated to a job can be modified during its execution, at the expense of increased overhead <ref> [40, 4, 14, 42, 9, 16, 21, 22, 35] </ref>. The runtime costs of a dynamic partitioning policy are heavily dependent upon the parallel architecture and application workload under consideration. <p> In uniform-access, shared-memory (UMA) systems, these overheads tend to be relatively small and thus the benefits of dynamic partitioning outweigh its associated costs. Several research studies have made this quite clear, showing that dynamic partitioning outperforms all other space-sharing strategies in many UMA environments <ref> [40, 14, 42, 9, 16] </ref>. In more distributed parallel environments (e.g., non-uniform-access, shared-memory and distributed-memory systems), however, the overheads of a dynamic partitioning policy can be significant due to factors such as data/job migration, processor preemption/coordination and, in some cases, reconfiguration of the application [4, 21, 22, 30]. <p> The times at which jobs arrive to the system are defined by the distributions A i , 0 i N , which are dependent upon the number of jobs i in the system. These arrival times are most often modeled by a Poisson distribution in the research literature <ref> [4, 42, 21, 22, 33, 17, 32, 25] </ref>.
References-found: 42

