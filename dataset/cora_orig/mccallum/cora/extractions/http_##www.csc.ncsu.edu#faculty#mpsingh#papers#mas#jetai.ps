URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/jetai.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/
Root-URL: http://www.csc.ncsu.edu
Email: singh@ncsu.edu  
Title: Semantical Considerations on Intention Dynamics for BDI Agents  Semantical Considerations on Intention Dynamics  
Author: Munindar P. Singh Munindar Singh 
Note: Short title:  is supported by the NCSU College of Engineering, the National Science Foun dation under grants IRI-9529179 and IRI-9624425 (Career Award), and IBM corporation.  
Date: October 24, 1997  
Address: Raleigh, NC 27695-8206, USA  
Affiliation: Department of Computer Science North Carolina State University  
Pubnum: +1.919.515.5677  
Abstract: The BDI paradigm is a powerful means for constructing intelligent agents in terms of their beliefs, desires, and intentions. For this paradigm to bear its full potential, it must incorporate considerations from rationality. This paper develops a set of postulates for intelligent agents who deliberate about their intentions and actions. However, even simple postulates can lead to paradoxical results when formalized naively. We propose an approach based on temporal possibility and action that avoids those problems. This approach incorporates a formal model based on branching time in which a probabilistic analysis of choice can be captured. In this manner, the intuitions of the BDI paradigm can be reconciled with those of rational agency. 
Abstract-found: 1
Intro-found: 1
Reference: [ Austin, 1962 ] <author> John L. Austin. </author> <title> How to Do Things with Words. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1962. </year>
Reference-contexts: P5 requires that the agent believe that his intention is necessary for p. This makes sense only for conditions that are fully under the control of the agent and cannot be caused by others. (About the only such conditions are an agent's speech acts <ref> [ Austin, 1962, p. 7 ] </ref> or conditions involving an agent's cognitive states.) However, most conditions are not like this. For example, if the agent does not open a particular door, someone else might, or it might open because of the breeze. Consequently, P5 is too strong.
Reference: [ Bratman, 1987 ] <author> Michael E. Bratman. </author> <title> Intention, Plans, and Practical Reason. </title> <publisher> Har-vard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference-contexts: Desires are typically treated as given. There is broad agreement that beliefs and intentions are subject to consistency and rationality requirements, whereas desires are not. Intentions mediate between an agent's desires and beliefs and relate most immediately to actions <ref> [ Bratman, 1987 ] </ref> . They are also more complex than beliefs. For these reasons, we focus primarily on intentions here. Most work on the formalization of intentions is logical or qualitative, not quantitative [ Cohen and Levesque, 1990; 2 Rao and Georgeff, 1991; Singh, 1994 ] . <p> Briefly, Dudley should realize that what happens in the world is not affected merely 5 by intending|i.e., he must act so that the chances of Nell being mashed are in fact reduced. Dudley's first postulate that an intention leads to a belief in its success is well received, e.g., <ref> [ Bratman, 1987, p. 37 ] </ref> . However, it can be safely weakened to allow a less confident agent than Dudley. Dudley's second postulate, namely, that he need not have an intention for something that is guaranteed is a special case of Les Lazy's postulate discussed below. <p> This inference might be termed consequential anti-closure: a most unusual problem for a logic of cognitive concepts! 4.4 Commitments Instead of trying to work around consequential anti-closure, we formalize the above requirement using commitments <ref> [ Bratman, 1987, ch. 2 ] </ref> [ Singh, 1996 ] . An agent has an intention only as long as he is committed to it.
Reference: [ Breiter and Sadek, 1996 ] <author> P. Breiter and M. D. Sadek. </author> <title> A rational agent as a kernel of a cooperative dialogue system: Implementing a logical theory of interaction. </title> <booktitle> In ECAI-96 Workshop on Agent Theories, Architectures, and Languages, </booktitle> <pages> pages 261-276. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year>
Reference: [ Castelfranchi, 1995 ] <author> Cristiano Castelfranchi. </author> <title> Commitments: From individual intentions to groups and organizations. </title> <booktitle> In Proceedings of the International Conference on Multiagent Systems, </booktitle> <pages> pages 41-48, </pages> <year> 1995. </year> <month> 25 </month>
Reference-contexts: An agent has an intention only as long as he is committed to it. This notion of commitment is internal or mental, and must be carefully distinguished from social commitment, which is also discussed in the AI literature <ref> [ Castelfranchi, 1995; Singh, 1998 ] </ref> . As before, let q entail 19 p.
Reference: [ Chellas, 1992 ] <author> Brian F. Chellas. </author> <title> Time and modality in the logic of agency. </title> <journal> Studia Logica, </journal> 51(3/4):485-517, 1992. 
Reference-contexts: Thus his intention should persist even though he should not aggressively act to achieve it. 3 Technical Framework For postulates such as the above to even be stated requires a formal model that includes not just time and action, but also possibility and choice <ref> [ Chellas, 1992 ] </ref> .
Reference: [ Cohen and Levesque, 1990 ] <author> Philip R. Cohen and Hector J. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 213-261, </pages> <year> 1990. </year>
Reference-contexts: In discrete models, one might encode paths in successor moments, but this would fail for nondiscrete models. Some of the present theories of intentions have some components of dynamism. For example, <ref> [ Cohen and Levesque, 1990 ] </ref> require that intentions be persistent, and embody this requirement in the semantics of intentions.
Reference: [ Doyle, 1992 ] <author> Jon Doyle. </author> <title> The roles of rationality in reasoning. </title> <journal> Computational Intelligence, </journal> <volume> 8(2) </volume> <pages> 326-335, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: By contrast, this paper develops a normative, quantitative view of BDI dynamics, albeit in a logical framework. It is often useful, and indeed customary, to assume that agents are rational <ref> [ Doyle, 1992 ] </ref> . They may not be perfect reasoners, but use their bounded resources as best they can. Rationality is essential to understanding how agents should act. Incorporating rationality in intention dynamics is thus crucial to the success of the program of research into BDI architectures.
Reference: [ Emerson, 1990 ] <author> E. A. Emerson. </author> <title> Temporal and modal logic. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume B. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: The problem is not so much with the details of these proposals as in their static formulation. Consequently, we formulate intentions and beliefs as "path 3 formulae" <ref> [ Emerson, 1990 ] </ref> . This can be adapted to most proposals. * The probabilistic theories of belief and action are restrictive. <p> A number of good approaches exist in the literature; for concreteness, we base our model on the presentation in <ref> [ Emerson, 1990 ] </ref> . 7 t 0 t 1 H H H H H H H H H H H H a moment action a action b : : : a path : : : : : : reality 0:25 0:25 H H H H H H H H H <p> The same action could be performed for different intentions; of course, several distinct and temporally isolated actions may have to be performed for a single intention. Syntax. The formal language of this paper, R, is CTL* (a propositional branching time logic <ref> [ Emerson, 1990 ] </ref> ) with some augmentations. Let be a set of atomic formulae; and A is a set of action symbols. <p> <ref> [ Emerson, 1990 ] </ref> ) with some augmentations. Let be a set of atomic formulae; and A is a set of action symbols. R may be defined by the following rules, which for ease of exposition simplify some of the structural aspects of the syntax of CTL* as given in [ Emerson, 1990 ] . R1. Atomic formulae: OE 2 R, for all OE 2 9 R2. Conjunction: p; q 2 R ) p ^ q 2 R R3. Negation: p 2 R ) :p 2 R R4. Until: p; q 2 R ) pUq 2 R R5. <p> The satisfaction conditions for the temporal operators are adapted from those in <ref> [ Emerson, 1990 ] </ref> . Formally, we have the following definitions: S1. M j= t iff t 2 [[ ]] S3. M j= t :p iff M 6j= t p S5.
Reference: [ Gardenfors, 1988 ] <author> Peter Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Wobcke independently observes the static nature of traditional approaches to the semantics of intentions. However, he does not propose a path-based semantics for intentions as here. Wobcke uses ideas from belief revision, including the rationality postulates for belief revision due to <ref> [ Gardenfors, 1988 ] </ref> . However, he does not propose any postulates involving intentions, as we have attempted to do.
Reference: [ Georgeff and Rao, 1995 ] <author> Michael P. Georgeff and Anand S. Rao. </author> <title> The semantics of intention maintenance for rational agents. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), </booktitle> <pages> pages 704-710, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction The BDI model is a powerful means to understand, study, and design intelligent agents <ref> [ Georgeff and Rao, 1995 ] </ref> . The BDI model presents an abstract architecture of intelligent agents in terms of their beliefs, d esires, and i ntentions. <p> This work allows nondeterministic models in which it formalizes know-how. It shows how an agent with the right knowhow can succeed with an intention if he selects actions from among those that will lead to success [ Newell, 1982 ] . <ref> [ Georgeff and Rao, 1995 ] </ref> formalize some properties of intention maintenance in a qualitative framework. They assume full determin 23 ism, and do not consider actions.
Reference: [ Georgeff, 1987 ] <author> Michael P. Georgeff. </author> <title> Planning. </title> <editor> In J. F. Traub, editor, </editor> <booktitle> Annual Review of Computer Science, </booktitle> <volume> Vol 2. </volume> <publisher> Annual Reviews, </publisher> <address> Palo Alto, </address> <year> 1987. </year>
Reference-contexts: This would hold if, e.g., the agent had currently adopted a plan corresponding to his intention. This postulate is apparent in the suggestion that intentions be treated as "adopted goals" <ref> [ Georgeff, 1987 ] </ref> , and is sufficiently strong to capture the relationship between intentions and actions. This would force Dudley to do something to save Nell's life. P4. Intentions are "adopted goals." That is, they must be acted for immedi ately.
Reference: [ Grosz and Sidner, 1990 ] <author> Barbara Grosz and Candace Sidner. </author> <title> Plans for discourse. </title> <editor> In P. Cohen, J. Morgan, and M. Pollack, editors, </editor> <booktitle> SDF Benchmark Series: Intentions in Communication, </booktitle> <pages> pages 417-444. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference: [ Haddawy, 1996 ] <author> Peter Haddawy. </author> <title> Believing change and changing belief. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics Special Issue on Higher-Order Uncertainty, </journal> <volume> 26(5), </volume> <month> May </month> <year> 1996. </year> <month> 26 </month>
Reference-contexts: This can be adapted to most proposals. * The probabilistic theories of belief and action are restrictive. One can either deal with subjective probabilities, which depend exclusively on the internal state of an agent, or objective chance, which depends exclusively on the state of the world. For example, <ref> [ Haddawy, 1996, p. 3 ] </ref> considers objective chance, dependent on the state of the world, and not on the agent's state. This is stronger than van Fraassen's requirement that the total history (as opposed to just the current state) determines chance [ van Fraassen, 1981, p. 336 ] .
Reference: [ Harper et al., 1981 ] <author> William L. Harper, Robert Stalnaker, and Glenn Pearce, edi-tors. </author> <title> IFS: Conditionals, Belief, Decision, Chance, and Time. </title> <publisher> Reidel, Dordrecht, Holland, </publisher> <year> 1981. </year>
Reference: [ McDermott, 1982 ] <author> Drew McDermott. </author> <title> A temporal logic for reasoning about processes and plans. </title> <journal> Cognitive Science, </journal> <volume> 6(2) </volume> <pages> 101-155, </pages> <year> 1982. </year>
Reference-contexts: These problems are thus a minimal set justifying the marriage of logical and probabilistic approaches to reasoning about intentions. 2.1 Dudley Dolittle A movie hero, Dudley, sees his heroine, Nell, lying tied to a railroad track <ref> [ McDermott, 1982, p. 102 ] </ref> . He figures "Nell is going to be mashed" and adopts an intention to save her. Being a hero, he is confident that he will succeed and therefore comes to believe that Nell will not be mashed, after all.
Reference: [ Newell, 1982 ] <author> Allen Newell. </author> <title> The knowledge level. </title> <journal> Artificial Intelligence, </journal> <volume> 18(1) </volume> <pages> 87-127, </pages> <year> 1982. </year>
Reference-contexts: This work allows nondeterministic models in which it formalizes know-how. It shows how an agent with the right knowhow can succeed with an intention if he selects actions from among those that will lead to success <ref> [ Newell, 1982 ] </ref> . [ Georgeff and Rao, 1995 ] formalize some properties of intention maintenance in a qualitative framework. They assume full determin 23 ism, and do not consider actions. <p> They capture a definition of "commit-to" that recalls the action selection condition of <ref> [ Newell, 1982 ] </ref> . Although the above approaches are useful contributions, in lacking a quantitative and explicitly normative stance, they fail to address crucial components of intention dynamics.
Reference: [ Pears, 1985 ] <author> D. F. Pears. </author> <title> Intention and belief. </title> <editor> In Bruce Vermazen and Merrill Hintikka, editors, </editor> <title> Essays on Davidson: Actions and Events. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1985. </year>
Reference-contexts: Then if he really intends to achieve p, he should not intend to achieve it! This generalizes the problem of akrasia, which occurs when an agent cannot act for his intentions <ref> [ Pears, 1985 ] </ref> . An akrastic agent cannot do any good, but Ken is worse: he causes harm! The theory must ensure that whereas Dudley and Les should act on their intentions, Ken should not act on his, at least not immediately.
Reference: [ Pollack, 1992 ] <author> Martha E. Pollack. </author> <title> The uses of plans. </title> <journal> Artificial Intelligence, </journal> <volume> 57(1) </volume> <pages> 43-68, </pages> <year> 1992. </year> <booktitle> Computers and Thought Award Lecture. </booktitle>
Reference: [ Rao and Georgeff, 1991 ] <author> Anand S. Rao and Michael P. Georgeff. </author> <title> Asymmetry thesis and side-effect problems in linear-time and branching-time intention logics. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), </booktitle> <pages> pages 498-504, </pages> <year> 1991. </year>
Reference-contexts: Some of the present theories of intentions have some components of dynamism. For example, [ Cohen and Levesque, 1990 ] require that intentions be persistent, and embody this requirement in the semantics of intentions. A number of authors, e.g., <ref> [ Rao and Georgeff, 1991; Singh, 1994 ] </ref> , have pointed this out as inappropriate, because it is both (a) rigid and (b) mixes the definitions of intentions with reasoning about intentions. [ Singh, 1994 ] develops a qualitative framework in which constraints on intentions, such as persistence, can be expressed.
Reference: [ Singh, 1994 ] <author> Munindar P. Singh. </author> <title> Multiagent Systems: A Theoretical Framework for Intentions, Know-How, and Communications. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1994. </year>
Reference-contexts: This would entail that the agent must choose all or none of the potential paths along which an action may be performed. Qualitative theories of know-how typically require this all or none selection <ref> [ Singh, 1994 ] </ref> , but we do not require that the agent have the necessary know-how. We develop alternative postulates in section 4. Given his beliefs and intentions, an agent is constrained to act in a certain manner, and to add or drop additional intentions and beliefs. <p> Some of the present theories of intentions have some components of dynamism. For example, [ Cohen and Levesque, 1990 ] require that intentions be persistent, and embody this requirement in the semantics of intentions. A number of authors, e.g., <ref> [ Rao and Georgeff, 1991; Singh, 1994 ] </ref> , have pointed this out as inappropriate, because it is both (a) rigid and (b) mixes the definitions of intentions with reasoning about intentions. [ Singh, 1994 ] develops a qualitative framework in which constraints on intentions, such as persistence, can be expressed. <p> A number of authors, e.g., [ Rao and Georgeff, 1991; Singh, 1994 ] , have pointed this out as inappropriate, because it is both (a) rigid and (b) mixes the definitions of intentions with reasoning about intentions. <ref> [ Singh, 1994 ] </ref> develops a qualitative framework in which constraints on intentions, such as persistence, can be expressed. This work allows nondeterministic models in which it formalizes know-how.
Reference: [ Singh, 1996 ] <author> Munindar P. Singh. </author> <title> Commitments in the architecture of a limited, rational agent. </title> <booktitle> In Proceedings of the Workshop on Theoretical and Practical Foundations of Intelligent Agents, </booktitle> <pages> pages 72-87. </pages> <publisher> Springer-Verlag, </publisher> <year> 1996. </year> <month> 27 </month>
Reference-contexts: This inference might be termed consequential anti-closure: a most unusual problem for a logic of cognitive concepts! 4.4 Commitments Instead of trying to work around consequential anti-closure, we formalize the above requirement using commitments [ Bratman, 1987, ch. 2 ] <ref> [ Singh, 1996 ] </ref> . An agent has an intention only as long as he is committed to it. This notion of commitment is internal or mental, and must be carefully distinguished from social commitment, which is also discussed in the AI literature [ Castelfranchi, 1995; Singh, 1998 ] . <p> However, he does not propose any postulates involving intentions, as we have attempted to do. Instead, Wobcke offers only specific examples of planning that involve adopting additional intentions based on current intentions and beliefs. <ref> [ Singh, 1996 ] </ref> develops a utility-based approach to commitments and precommit-ments. Singh attempts to formalize the conditions under which an agent should deliberate and the "conative" policies that affect when and how that deliberation is carried out.
Reference: [ Singh, 1998 ] <author> Munindar P. Singh. </author> <title> An ontology for commitments in multiagent sys-tems: Toward a unification of normative concepts. </title> <journal> Artificial Intelligence and Law, </journal> <note> 1998. In press. </note>
Reference-contexts: An agent has an intention only as long as he is committed to it. This notion of commitment is internal or mental, and must be carefully distinguished from social commitment, which is also discussed in the AI literature <ref> [ Castelfranchi, 1995; Singh, 1998 ] </ref> . As before, let q entail 19 p.
Reference: [ van Fraassen, 1981 ] <author> Bas C. van Fraassen. </author> <title> A temporal framework for conditionals and chance. </title> <editor> In [ Harper et al., </editor> <year> 1981 </year> <month> ] , pages 323-340. </month> <year> 1981. </year>
Reference-contexts: For example, [ Haddawy, 1996, p. 3 ] considers objective chance, dependent on the state of the world, and not on the agent's state. This is stronger than van Fraassen's requirement that the total history (as opposed to just the current state) determines chance <ref> [ van Fraassen, 1981, p. 336 ] </ref> . However, the objective chance depends on both the state of the world and the internal state of the agent. The agent's intentions determine his actions, and his actions influence what objectively transpires.
Reference: [ van Linder et al., 1996 ] <author> B. van Linder, W. van der Hoek, and J.-J. Ch. Meyer. </author> <title> For-malising motivational attitudes of agents: On preferences, goals and commitments. In Intelligent Agents II: Agent Theories, Architectures, </title> <booktitle> and Languages, </booktitle> <pages> pages 17-32, </pages> <year> 1996. </year>
Reference-contexts: They assume full determin 23 ism, and do not consider actions. However, they consider the interesting special case where an agent has only one intention in which some inferences can be drawn qualitatively, and without considering actions. <ref> [ van Linder et al., 1996 ] </ref> formalize various attitudes including commitments. They capture a definition of "commit-to" that recalls the action selection condition of [ Newell, 1982 ] .
Reference: [ Wobcke, 1995 ] <author> Wayne Wobcke. </author> <title> Plans and the revision of intentions. </title> <booktitle> In Proceedings of the Australian Workshop on Distributed Artificial Intelligence, LNAI 1087, </booktitle> <pages> pages 100-114, </pages> <address> Heidelberg, 1995. </address> <publisher> Springer-Verlag. </publisher> <pages> 28 </pages>
Reference-contexts: Although the above approaches are useful contributions, in lacking a quantitative and explicitly normative stance, they fail to address crucial components of intention dynamics. As we argued, qualitative approaches cannot accommodate all of the three intuitive problems described in section 2. <ref> [ Wobcke, 1995 ] </ref> studies plans and intention revision in a formal framework. Wobcke independently observes the static nature of traditional approaches to the semantics of intentions. However, he does not propose a path-based semantics for intentions as here.
References-found: 25

