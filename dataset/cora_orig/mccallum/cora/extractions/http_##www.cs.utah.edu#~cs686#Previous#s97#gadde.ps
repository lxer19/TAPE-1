URL: http://www.cs.utah.edu/~cs686/Previous/s97/gadde.ps
Refering-URL: http://www.cs.utah.edu/~cs686/Previous/s97/
Root-URL: 
Email: gadde@cs.duke.edu  misha@research.att.com  chase@cs.duke.edu  
Title: Reduce, Reuse, Recycle: An Approach to Building Large Internet Caches  
Author: Syam Gadde Michael Rabinovich Jeff Chase 
Address: Durham NC, 27708  Murray Hill, NJ 07974  Durham NC, 27708  
Affiliation: Dept. of Computer Science Duke University  AT&T Labs Research  Dept. of Computer Science Duke University  
Abstract: New demands brought by the continuing growth of the Internet will be met in part by more effective use of caching in the Web and other services. We have developed CRISP, a distributed Internet object cache targeted to the needs of the organizations that aggregate the end users of Internet services, particularly the commercial Internet Service Providers (ISPs) where much of the new growth occurs. A CRISP cache consists of a group of cooperating caching servers sharing a central directory of cached objects. This simple and obvious strategy is easily overlooked due to the well-known drawbacks of a centralized structure. However, we show that these drawbacks are easily overcome for well-configured CRISP caches. We outline the rationale behind the CRISP design, and report on early studies of CRISP caches in actual use and under synthetic load. While our experience with CRISP to date is at the scale of hundreds or thousands of clients, CRISP caches could be deployed to maximize capacity at any level of a regional or global cache hierarchy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Squid Internet Object Cache. URL:http://squid.nlanr.net/. </institution>
Reference-contexts: To the client, a CRISP cache appears exactly as a traditional proxy. CRISP's use of a central mapping service distinguishes it from other cooperative Internet caches, e.g., the Harvest cache [6], its successor Squid <ref> [1] </ref>, and Malpani et. al. [10]. In these systems, each proxy probes the cache by multicast-ing queries to all of its peers, to avoid relying on any single peer or a mapping server.
Reference: [2] <author> R. Alonso and M. A. </author> <title> Blaze. Dynamic hierarchical caching for large-scale distributed file systems. </title> <booktitle> In Proceedings of the USENIX Summer Conference, </booktitle> <month> June </month> <year> 1992. </year>
Reference-contexts: Unfortunately, multicasting increases network traffic and forces all caches to respond to each request in most cases. In effect, every caching server incurs the load of cache probes that are limited to the mapping server in CRISP. The Harvest cache and its predecessors <ref> [2] </ref> also support a hierarchy of caches, e.g., for regional or global caches. CRISP complements rather than replaces hierarchical caching.
Reference: [3] <author> M. Arlitt and C. L. Williamson. </author> <title> Web server workload charac terization: The search for invariants. </title> <booktitle> In ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, </booktitle> <year> 1996. </year>
Reference-contexts: The map is simply a hash of URLs, which are small relative to the Internet objects they name. A recent study <ref> [3] </ref> indicated that the average object is about 10K bytes. If we conservatively estimate the average URL size at 100 bytes, then the data that passes through the mapping service is about 1% of the aggregate size of the CRISP cache, e.g., a gigabyte of storage for a 100G cache.
Reference: [4] <author> Netscape Communications Corporation. </author> <title> Netscape Navigator 3.0 Automatic Proxy Configurations. </title> <note> Available at &lt;URL: http://home.netscape.com/comprod/products/navigator /ver sion 3.0/management/proxy/index.html&gt;, </note> <year> 1997. </year>
Reference-contexts: If a mapping server believes that a proxy has failed, it marks all cache directory entries from that cache as unavailable. Clients that were connected to the failed proxy must fail over to a secondary proxy, e.g., by using autoconfigu-ration scripts <ref> [4] </ref>. When a proxy rejoins the CRISP cache, it first registers itself with the mapping service to re-enable or restore the maps for cached objects that survived the failure.
Reference: [5] <author> A. Bestavros, R. Carter, M. Crovella, C. Cunha, A. Hed daya, and S. Mirdad. </author> <title> Application level document caching in the Internet. </title> <booktitle> In IEEE SDNE'96: The Second International Workshop on Services in Distributed and Networked Environ ments, </booktitle> <address> Whistler, British Columbia, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: On the other hand, site replication (e.g., mirroring) is still mostly manual and not easily hidden from users, although some progress has been made toward automating some aspects of it (most recently with geographical push-caching [7], document dissemination <ref> [5] </ref> and smart clients [12]). While these supply-side approaches contribute to scalability, we believe that the traditional demand-side approach demand-driven caching initiated by clients at their own expense and for their own benefit is still the most powerful and economically correct tool at our disposal.
Reference: [6] <author> A. Chankhunthod, P. Danzig, C. Neerdaels, M. F. Schwartz, and K. J. Worrell. </author> <title> A hierarchical Internet object cache. </title> <booktitle> In USENIX 1996 Annual Technical Conference, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: Section 3 presents some trace studies and early experiments, and Section 4 outlines our conclusions. 2 Architecture and Rationale The CRISP cache has been implemented and is in active use at AT&T Labs. Our current prototype is built on top of the Harvest cache <ref> [6] </ref>. Figure 1 depicts the structure of a CRISP cache. Each client (e.g., a browser) is bound to one of several caching servers or proxies, which cache objects on behalf of their clients. <p> To the client, a CRISP cache appears exactly as a traditional proxy. CRISP's use of a central mapping service distinguishes it from other cooperative Internet caches, e.g., the Harvest cache <ref> [6] </ref>, its successor Squid [1], and Malpani et. al. [10]. In these systems, each proxy probes the cache by multicast-ing queries to all of its peers, to avoid relying on any single peer or a mapping server.
Reference: [7] <author> J. Gwertzman and M. Seltzer. </author> <title> The case for geographical push-caching. </title> <booktitle> In Fifth Workshop on Hot Topics in Operat ing Systems, </booktitle> <year> 1995. </year>
Reference-contexts: On the other hand, site replication (e.g., mirroring) is still mostly manual and not easily hidden from users, although some progress has been made toward automating some aspects of it (most recently with geographical push-caching <ref> [7] </ref>, document dissemination [5] and smart clients [12]). While these supply-side approaches contribute to scalability, we believe that the traditional demand-side approach demand-driven caching initiated by clients at their own expense and for their own benefit is still the most powerful and economically correct tool at our disposal.
Reference: [8] <author> T. M. Kroeger, J. Mogul, and C. Maltzahn. </author> <title> Digital's web proxy traces. </title> <note> Available at&lt;URL: ftp://ftp.digital.com /pub/DEC/traces/proxy/webtraces.html&gt;. </note>
Reference-contexts: Our two largest traces are taken from the access logs from a centralized proxy cache used by thousands of the AT&T technical community, and a 24-hour subset (Aug. 29, 1996) of the publicly available proxy traces from Digital Equipment Corporation <ref> [8] </ref>. These traces are labeled AT&T and DEC in the figures, and represent accesses from 3806 and 3636 clients respectively. The Medium trace was taken from a proxy used by 218 researchers from one AT&T Bell Labs center.
Reference: [9] <author> A. Luotonen and K. Altis. </author> <title> World-wide Web prox ies. </title> <booktitle> First International Conference on the World-wide Web, </booktitle> <year> 1994. </year> <note> Available at &lt;URL:http://www.cern.ch/Papers /WWW94/luotonen.ps&gt;. </note>
Reference-contexts: In doing so, the ISP incidentally acts as a good citizen by reducing the load it places on Web servers and the Internet backbone. Some ISPs already service their Web clients through shared proxy servers <ref> [9] </ref>. We believe that the most effective caches will be those serving the largest user communities.
Reference: [10] <author> R. Malpani, J. Lorch, and D. Berger. </author> <title> Making World Wide Web caching servers cooperate. </title> <booktitle> In Fourth Interna tional World-wide Web Conference, </booktitle> <pages> pages 107117, </pages> <note> Decem ber 1995. </note>
Reference-contexts: To the client, a CRISP cache appears exactly as a traditional proxy. CRISP's use of a central mapping service distinguishes it from other cooperative Internet caches, e.g., the Harvest cache [6], its successor Squid [1], and Malpani et. al. <ref> [10] </ref>. In these systems, each proxy probes the cache by multicast-ing queries to all of its peers, to avoid relying on any single peer or a mapping server. If the request generates multiple hits, the requester can select its preferred site based on time to respond.
Reference: [11] <author> S. Williams, M. Abrams, C. R. Standridge, G. Abdulla, and E. A. Fox. </author> <title> Removal policies in network caches for World wide Web documents. </title> <booktitle> In ACM SIGCOMM '96: Applica tions, Technologies, Architectures and Protocols for Com puter Communication, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: We argue below that these well-known concerns are not a problem for well-configured CRISP caches, given the properties of Web access. Moreover, the CRISP structure can simplify approaches to other issues raised by widespread deployment of large Internet caches, including consistency management, automated load balancing, alternative replacement strategies <ref> [11] </ref>, and network-aware cache structure. For Internet caches, the simplest strategy for cooperative caching is the most effective as well as the easiest to implement and extend. Section 2 presents an overview of the CRISP cache and the case for a central mapping service for distributed Internet caches. <p> Our intent is to demonstrate the benefits of building large shared caches. For these experiments the caches used LRU replacement; alternative replacement policies tuned for Web access patterns would likely yield higher hit ratios <ref> [11] </ref>. CRISP caches could support alternative global replacement policies at the level of the mapping service. The behavior of a shared cache is affected by the degree of temporal locality in the reference streams from individual clients.
Reference: [12] <author> C. Yoshikawa, B. Chun, P. Eastham, A. Vahdat, T. Anderson, and D. Culler. </author> <title> Using smart clients to build scalable services, </title> <month> June </month> <year> 1996. </year> <note> To appear in USENIX 1997 Annual Technical Conference. </note>
Reference-contexts: On the other hand, site replication (e.g., mirroring) is still mostly manual and not easily hidden from users, although some progress has been made toward automating some aspects of it (most recently with geographical push-caching [7], document dissemination [5] and smart clients <ref> [12] </ref>). While these supply-side approaches contribute to scalability, we believe that the traditional demand-side approach demand-driven caching initiated by clients at their own expense and for their own benefit is still the most powerful and economically correct tool at our disposal.
References-found: 12

