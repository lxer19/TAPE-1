URL: file://ftp.cs.ucsd.edu/pub/baden/tr/cs94-355.ps.gz
Refering-URL: http://www.cs.ucsd.edu/~sfink/pub.html
Root-URL: http://www.cs.ucsd.edu
Title: Cluster Identification on a Distributed Memory Multiprocessor  
Author: Stephen J. Fink, Scott B. Baden, 
Note: To appear in the 1994 Scalable High Performance Computing Conference, May 23-25, 1994, Knoxvilee, TN, U.S.A.  
Date: March 1994  
Address: Karl Jansen(DESY-T, Hamburg, Germany)  La Jolla, California 92093-0114  
Affiliation: and  Department of Computer Science and Engineering University of California, San Diego  
Pubnum: CSE Technical Report Number CS94-355  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> K. P. Belkhale and P. Banerjee, </author> <title> "Parallel algorithms for geometric connected component labeling on a hypercube multiprocessor," </title> <journal> IEEE Transactions On Computers, </journal> <volume> vol. 41, </volume> <pages> pp. 699-709, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: 1 Introduction The connected component labeling problem arises in applications ranging from VLSI circuit extraction <ref> [1] </ref> to image component labeling [2]. The cluster identification problem is a variant of connected component labeling that occurs in cluster algorithms for spin models in statistical physics [3, 4, 5, 6]. <p> Previous approaches to cluster identification on distributed memory multiprocessors are reviewed in [3]. Our cluster identification method is based on Belkhale and Banerjee's hierarchical Quad algorithm for connected component labeling for VLSI circuit extraction on a hypercube multiprocessor <ref> [1] </ref>. Other hierarchical two-dimensional cluster identification methods have been implemented on vector [6] and SIMD [5] architectures. We have extended the Quad algorithm to more than two dimensions to simulate the Ising model on a higher dimensional lattice. <p> Step 2 is the bottleneck in the computation, and requires an efficient parallel cluster identification method. 3 Basic algorithm 3.1 Belkhale and Banerjee's Quad Algo rithm Our cluster identification method is based on Belkhale and Banerjee's Quad algorithm for geometric connected component labeling <ref> [1] </ref>. The Quad algorithm was developed to label connected sets of rectangles that represent VLSI circuits in a plane. It is straightforward to apply the same algorithm to label clusters on a two-dimensional lattice of spin values. <p> A brief overview of the Quad algorithm is presented here, using terminology assuming a two-dimensional lattice of spins rather than sets of connected rectangles in a plane. For a more complete description of the Quad algorithm, consult <ref> [1] </ref>. The Quad algorithm requires that the global two-dimensional lattice be partitioned blockwise across a logical array of processors. If the interconnection network has a hypercube topology, processors are assigned with a grey code mapping to reduce the number of hops between processors that exchange messages. <p> + Bff (B)), where P is the number of processors, ff () is the inverse of Ackerman's function, t s is the message startup time, t b is the communication time per byte, and B is is the number of border rectangles along a cross section of the global domain <ref> [1] </ref>. The number of border rectangles in VLSI circuit extraction applications corresponds to the number of border bonds in cluster identification applications. <p> We must therefore scale the problem size along with the problem dimensionality in order to realize equivalent performance for higher dimensional lattices. 4 Optimizations One limitation of the Quad algorithm is that the surface area of the information region grows in each stage <ref> [1] </ref>. In the last stage, each processor must handle a cross-section of the entire global domain. With many processors and large problem sizes, this can degrade the algorithm's performance [1]. <p> 4 Optimizations One limitation of the Quad algorithm is that the surface area of the information region grows in each stage <ref> [1] </ref>. In the last stage, each processor must handle a cross-section of the entire global domain. With many processors and large problem sizes, this can degrade the algorithm's performance [1]. Cluster configurations may exhibit some form of lo cality that can be exploited to improve running time of the Quad algorithm. The analysis above suggests that optimizations are most important in higher dimensions, where the surface area-to-volume ratio is large. <p> Cluster configurations exhibit two types of locality: * Type 1: Small clusters only affect cluster labels in a limited area. * Type 2: Adjacent lattice points are likely to be long the same cluster. Belkhale and Banerjee exploit Type 1 locality in two dimensions with the Overlap Quad algorithm <ref> [1] </ref>. In this algorithm, information regions overlap and only clusters that span the overlap region must be merged. Intuitively, small clusters are eliminated in early stages of the algorithm, leaving only large clusters to merge in later stages.
Reference: [2] <author> B. Falsafi and R. Miller, </author> <title> "Component labeling algorithms on an intel ipsc/2 hypercube," </title> <booktitle> in Proceedings of the Fifth Distributed Memory Computing Conference, </booktitle> <volume> vol. 1, </volume> <pages> pp. 159-164, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: 1 Introduction The connected component labeling problem arises in applications ranging from VLSI circuit extraction [1] to image component labeling <ref> [2] </ref>. The cluster identification problem is a variant of connected component labeling that occurs in cluster algorithms for spin models in statistical physics [3, 4, 5, 6]. In these applications, the graph to be labeled is a d-dimensional hypercubic lattice and edges may exist only between nearest-neighbor lattice points.
Reference: [3] <author> C. F. Baillie and P. D. Coddington, </author> <title> "Cluster identification algorithms for spin models | sequential and parallel," </title> <journal> Concurrency: Practice and Experience, </journal> <volume> vol. 3, </volume> <pages> pp. 129-144, </pages> <month> April </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The connected component labeling problem arises in applications ranging from VLSI circuit extraction [1] to image component labeling [2]. The cluster identification problem is a variant of connected component labeling that occurs in cluster algorithms for spin models in statistical physics <ref> [3, 4, 5, 6] </ref>. In these applications, the graph to be labeled is a d-dimensional hypercubic lattice and edges may exist only between nearest-neighbor lattice points. Accurate simulations of spin models require many iterations and large lattice sizes, so these applications are candidates for a parallel architecture. <p> Additionally, cluster configurations may be highly irregular, making communication and computation patterns hard to predict. Nevertheless, clusters may exhibit some form of locality that a parallel algorithm can exploit to perform global clustering efficiently. Previous approaches to cluster identification on distributed memory multiprocessors are reviewed in <ref> [3] </ref>. Our cluster identification method is based on Belkhale and Banerjee's hierarchical Quad algorithm for connected component labeling for VLSI circuit extraction on a hypercube multiprocessor [1]. Other hierarchical two-dimensional cluster identification methods have been implemented on vector [6] and SIMD [5] architectures. <p> Monte Carlo simulations of the Ising model generate a sequence of spin configurations. In conventional Monte Carlo Ising model simulations, a spin's value may or may not change depending on the values of its neighbors and a random variable <ref> [3] </ref>. These algorithms are appropriate for a parallel architecture since each spin update depends solely on local information. The interesting physics arises from spin configurations in the critical region, where phase transitions occur. In these configurations, neighboring spins form large clusters, in which all spins have the same value. <p> Breadth-First Search (BFS) has been shown to be an efficient algorithm to perform the sequential local labeling step <ref> [3] </ref>. Since BFS runs in O (jV j + jEj) [9], the local labeling phase runs in O (( N P )+( pdN P )). Thus, for any dimension lattice, the time for the local phase will dominate the time for the global phase as long as N is large.
Reference: [4] <author> D. W. Heerman and A. N. Burkitt, </author> <title> "Parallelization of the Ising model and its performance evaluation," </title> <journal> Parallel Computing, </journal> <volume> vol. 13, </volume> <pages> pp. 345-357, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction The connected component labeling problem arises in applications ranging from VLSI circuit extraction [1] to image component labeling [2]. The cluster identification problem is a variant of connected component labeling that occurs in cluster algorithms for spin models in statistical physics <ref> [3, 4, 5, 6] </ref>. In these applications, the graph to be labeled is a d-dimensional hypercubic lattice and edges may exist only between nearest-neighbor lattice points. Accurate simulations of spin models require many iterations and large lattice sizes, so these applications are candidates for a parallel architecture.
Reference: [5] <author> J. Apostolakis, P. Coddington, and E. Marinari, </author> <title> "A multi-grid cluster labeling scheme," </title> <journal> Europhysics Letters, </journal> <volume> vol. 17, </volume> <pages> pp. 189-194, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: 1 Introduction The connected component labeling problem arises in applications ranging from VLSI circuit extraction [1] to image component labeling [2]. The cluster identification problem is a variant of connected component labeling that occurs in cluster algorithms for spin models in statistical physics <ref> [3, 4, 5, 6] </ref>. In these applications, the graph to be labeled is a d-dimensional hypercubic lattice and edges may exist only between nearest-neighbor lattice points. Accurate simulations of spin models require many iterations and large lattice sizes, so these applications are candidates for a parallel architecture. <p> Accurate simulations of spin models require many iterations and large lattice sizes, so these applications are candidates for a parallel architecture. For parallel implementations of cluster algorithms, the cluster identification step is often the bottleneck in the computation <ref> [5] </ref>. Cluster identification is not ideally suited for a distributed memory parallel computer since the label of a fl This work was supported by ONR contract N00014-93-1-0152. Computer time on the Intel PARAGON at the San Diego Supercomputer Center was provided by a UCSD Division of Engineering Block Grant. <p> Our cluster identification method is based on Belkhale and Banerjee's hierarchical Quad algorithm for connected component labeling for VLSI circuit extraction on a hypercube multiprocessor [1]. Other hierarchical two-dimensional cluster identification methods have been implemented on vector [6] and SIMD <ref> [5] </ref> architectures. We have extended the Quad algorithm to more than two dimensions to simulate the Ising model on a higher dimensional lattice. Our extension abstracts away unnecessary spatial information to simplify implementation in more than two dimensions.
Reference: [6] <author> H. Mino, </author> <title> "A vectorized algorithm for cluster formation in the Swendson-Wang dynamics," </title> <journal> Computer Physics Communications, </journal> <volume> vol. 66, </volume> <pages> pp. 25-30, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction The connected component labeling problem arises in applications ranging from VLSI circuit extraction [1] to image component labeling [2]. The cluster identification problem is a variant of connected component labeling that occurs in cluster algorithms for spin models in statistical physics <ref> [3, 4, 5, 6] </ref>. In these applications, the graph to be labeled is a d-dimensional hypercubic lattice and edges may exist only between nearest-neighbor lattice points. Accurate simulations of spin models require many iterations and large lattice sizes, so these applications are candidates for a parallel architecture. <p> Our cluster identification method is based on Belkhale and Banerjee's hierarchical Quad algorithm for connected component labeling for VLSI circuit extraction on a hypercube multiprocessor [1]. Other hierarchical two-dimensional cluster identification methods have been implemented on vector <ref> [6] </ref> and SIMD [5] architectures. We have extended the Quad algorithm to more than two dimensions to simulate the Ising model on a higher dimensional lattice. Our extension abstracts away unnecessary spatial information to simplify implementation in more than two dimensions.
Reference: [7] <author> M. Fisher, </author> <title> "Scaling, universality and renormalization group theory," </title> <booktitle> in Lecture Notes in Physics, </booktitle> <volume> Vol. 186, </volume> <publisher> Springer Verlag, </publisher> <year> 1993. </year> <title> Num. Unopt. Opt. Opt. of Time Time Benefit Procs. per per (%) Iteration(s) Iteration(s) 8 1.0 0.96 4.0 32 2.7 2.3 15 128 4.5 3.1 31 512 7.7 4.0 48 Table 3: 3D Performance when the number of processors and problem size are scaled together. Lattice size is 15625 lattice points per processor. The optimized time is for runs using both bubble elimination and border compression. All runs are at c on an nCUBE/2. </title>
Reference-contexts: Section 4 describes optimizations to the basic algorithm, and Section 5 presents performance results from Intel PARAGON and nCUBE/2 implementations. 2 The Ising Model Many systems in physics such as binary fluids, liquid and gas systems, and magnets exhibit phase transitions. (For a good introduction see <ref> [7] </ref>.) In order to understand these "critical phenomena", models have been constructed in statistical mechanics. The simplest such model, the Ising model, gives qualitative and quantitative insights into the properties of phase transitions. In some cases, it can even be used to determine measurable quantities of physical systems.
Reference: [8] <author> R. H. Swendson and J.-S. Wang, </author> <title> "Nonuniversal critical dynamics in monte carlo simulations," </title> <journal> Physical Review Letters, </journal> <volume> vol. 58, </volume> <pages> pp. 86-88, </pages> <month> January </month> <year> 1987. </year>
Reference-contexts: Thus, even for correlation lengths ~ as small as 10 to 100, it is clear that critical-slowing down severely limits the effectiveness of local-update algorithms for the Ising model. In order to avoid critical slowing-down, Swendson and Wang's cluster algorithm updates whole regions of spins simultaneously <ref> [8] </ref>. This non-local update scheme generates independent configurations in fewer iterations that the conventional algorithms. The cluster algorithm has a much smaller value of z, often approaching 0. Therefore, it eliminates critical slowing-down completely. The Swendson-Wang cluster algorithm proceeds as follows: 1. Compute bonds between spins. <p> Border compression collapses these runs, leaving small effective information region borders. 5 Performance Results We have implemented the algorithm and optimizations as part of 2D and 3D Ising model simulations using Swendson and Wang's method <ref> [8] </ref>. The global lattice has a toroidal topology. When bubble elimination is employed, bubbles are eliminated between Manhat-tan neighbors only. Our implementations are written in C for either an nCUBE/2 or Intel PARAGON using the manufacturers' synchronous message-passing library routines. The local sequential labeling method is Breadth-First Search [9].
Reference: [9] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms. </title> <address> San Francisco: </address> <publisher> The MIT Press and McGraw-Hill Book Company, </publisher> <year> 1990. </year>
Reference-contexts: The messages contain the CCOMP set labels and border lists of the current information region. Processor Q 1 merges the CCOMP sets on the common border of the two information regions using a Union-Find data structure <ref> [9] </ref>. The other border lists of the two information regions are concatenated to form the information region for processor Q 1 in the next stage. <p> The total number of Union-Find operations performed by a processor at each stage is equal to the number of bonds on a border of the information region. Using the path compression and union by rank optimizations of Union-Find operations <ref> [9] </ref>, the total work spent merging clusters is O (pdN d1 d1 d )). (Our implementation uses the path compression heuristic but not union-by-rank.) Adding together communication and computation, the running time for global combining is O (log P t s + t b pdN d + pdN d ff (pdN <p> Breadth-First Search (BFS) has been shown to be an efficient algorithm to perform the sequential local labeling step [3]. Since BFS runs in O (jV j + jEj) <ref> [9] </ref>, the local labeling phase runs in O (( N P )+( pdN P )). Thus, for any dimension lattice, the time for the local phase will dominate the time for the global phase as long as N is large. <p> The global lattice has a toroidal topology. When bubble elimination is employed, bubbles are eliminated between Manhat-tan neighbors only. Our implementations are written in C for either an nCUBE/2 or Intel PARAGON using the manufacturers' synchronous message-passing library routines. The local sequential labeling method is Breadth-First Search <ref> [9] </ref>. All results in this sections use a block partitioning to distribute the global lattice across processors. All timing results include both local clustering time and global clustering time, but not processing unrelated to cluster identification.
Reference: [10] <author> R. C. Gonzalez and P. Wintz, </author> <title> Digital Image Processing. </title> <address> Reading, Massachusetts: </address> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1977. </year>
Reference-contexts: We compress the representation of each list using run-length encoding <ref> [10] </ref>.
References-found: 10

