URL: http://www.isp.pitt.edu/~rymon/papers/kdd96.ps
Refering-URL: http://www.isp.pitt.edu/~rymon/pubs.html
Root-URL: 
Email: Rymon@ISP.Pitt.edu  
Title: SE-trees Outperform Decision Trees in Noisy Domains  
Author: Ron Rymon 
Address: Pittsburgh Pittsburgh, PA 15260  
Affiliation: Intelligent Systems Program, 901 CL University of  
Abstract: As a classifier, a Set Enumeration (SE) tree can be viewed as a generalization of decision trees. It can be shown that, at the cost of a higher complexity, a single SE-tree encapsulates many alternative decision tree structures. An SE-tree enjoys several advantages over decision trees: it allows for domain-based user-specified bias, it supports a flexible tradeoff between the resources allocated to learning and the resulting accuracy, and it can combine knowledge induced from examples with other knowledge sources. In this paper, we empirically demonstrate that SE-trees enjoy a particular advantage over simple decision trees in noisy domains. This advantage manifests itself both in terms of accuracy, and in terms of consistency. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Breiman, L., Friedman, J., Olshen, R., and Stone, C., </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont. </address>
Reference: <author> Breiman, L., </author> <title> Bagging Predictors. </title> <type> Technical Report 421, </type> <institution> Department of Statistics, UC Berkeley. </institution>
Reference: <author> Buntine, W., </author> <title> Learning Classification Trees. </title> <booktitle> Artificial Intelligence Frontiers in Statistics, </booktitle> <editor> D. Hand (Ed), </editor> <publisher> Chapman and Hall. </publisher>
Reference: <author> Dietterich, T. G., and Kong, E. B., </author> <title> Machine Learning Bias, Statistical Bias, and Statistical Variance of Decision Tree Algorithms. </title> <type> Technical Report, </type> <institution> Department of Computer Science, Oregon State University. </institution>
Reference: <author> Kwok, S., and Carter, C., </author> <title> Multiple Decision Trees. </title> <booktitle> Uncertainty in Artificial Intelligence, </booktitle> <volume> 4, </volume> <pages> pp. 327-335. </pages>
Reference: <author> Quinlan, J. R., </author> <title> Induction of Decision Trees. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 81-106. </pages>
Reference: <author> Quinlan, J. R., C4.5: </author> <title> Programs for Empirical Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA. </address>
Reference: <author> Rymon, R., </author> <title> Search through Systematic Set Enumeration. </title> <booktitle> In Proceedings Third International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <address> Cambridge MA, </address> <pages> pp. 539-550. </pages>
Reference: <author> Rymon, R., </author> <title> An SE-tree-based Characterization of the Induction Problem. </title> <booktitle> In Proceedings Tenth International Conference on Machine Learning, </booktitle> <pages> pp. 268-275, </pages> <address> Amherst MA. </address>
Reference: <author> Rymon, R., </author> <title> On Kernel Rules and Prime Implicants. </title> <booktitle> In Proceedings Twelfth National Conference on Artificial Intelligence, </booktitle> <address> Seattle WA, </address> <pages> pp. 181-186. </pages> <address> http://www.isp.pitt.edu/~rymon/SE-Learn.html. </address>
References-found: 10

