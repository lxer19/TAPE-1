URL: ftp://theory.lcs.mit.edu/pub/tcryptol/96-01.ps
Refering-URL: http://theory.lcs.mit.edu/~tcryptol/1996/96-01.html
Root-URL: 
Email: canetti,rosario@theory.lcs.mit.edu  
Title: Incoercible Multiparty Computation (Extended Abstract)  
Author: Ran Canetti Rosario Gennaro 
Address: 545 Technology Square, Cambridge MA 02139, U.S.A.  
Affiliation: Laboratory for Computer Science, Massachusetts Institute of Technology,  
Date: May 17, 1996  
Abstract: In this work we present the first general and rigorous treatment of the coercion problem in secure computation. First we present a general definition of protocols that provide resilience to coercion. Our definition constitutes a natural extension of the general paradigm used for defining secure multiparty protocols. Next we show that if trapdoor permutations exist then any function can be incoercibly computed (i.e., computed by a protocol that provides resilience to coercion) in the presence of com-putationally bounded adversaries and only public communication channels. This holds as long as less than half the parties are coerced (or corrupted). In particular, ours are the first incoercible protocols without physical assumptions. Also, our protocols constitute an alternative solution to the recently solved adaptive security problem. Our techniques are quite surprising and include non-standard use of deniable encryptions. 
Abstract-found: 1
Intro-found: 1
Reference: [Be] <author> D. Beaver, </author> <title> "Foundations of Secure Interactive Computing", </title> <booktitle> CRYPTO, </booktitle> <year> 1991. </year>
Reference-contexts: Coming up with a definition that correctly captures this new type of attack turned out to be a non-trivial task. Moreover, our definition manages to incorporate this concern within the existing framework used for defining multiparty secure computation <ref> [MR, Be, CFGN, C] </ref>. In particular, it is immediate from our definition that any incoercible protocol is also (adaptively) secure in the standard sense. <p> This ideal model, described in the sequel, extends of the ideal model used to define `standard' security of multiparty protocols <ref> [MR, Be, CFGN, C] </ref>. Having formalized the notion of incoercible protocols, a simple argument now shows that incoercible secure computation is impossible when the adversary is computationally unbounded. Interestingly, this holds even if the communication channels are private (as in [BGW, CCD]). <p> ffi (n) is negligible then we say that fA n g and fB n g are computationally indistinguishable and write A n B n . 2.1 The basic definition Our definition builds on top of the existing framework used for defining multiparty computation secure against adaptive adversaries ([C, CFGN], following <ref> [MR, Be] </ref>). We proceed in three steps: First we describe the `mechanics' of a computation in the presence of a coercive adversary, emphasizing the difference from the `mechanics' of a computation in the presence of a standard adaptive adversary. <p> In other words, it seems that a coerced party can either `prove' that it has one input or `prove' that it has another input, but it cannot `prove' both claims at the same time. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>.
Reference: [BT] <editor> J. Benaloh and D. Tunistra, "Receipt-Free Secret-Ballot Elections", </editor> <booktitle> 26th STOC, </booktitle> <year> 1994, </year> <pages> pp. 544-552. </pages>
Reference-contexts: As long as enough parties remain uncorrupted, the parties can correctly compute any function of their inputs, while making sure that the adversary learns nothing from the computation other than the inputs and outputs of the corrupted parties. However, these protocols suffer from the following deficiency, pointed out in <ref> [He, BT] </ref>. Using any of these protocols, the public transcript of the communication can be used as an (involuntary) commitment of the parties to their inputs and outputs. <p> Other scenarios include electronic commerce, bidding, key-escrowing, and any computation done in the presence of some authority (say, a Mafia, an employer, or a government) that may become coercive. Coercion in the context of secret voting has been studied in the past <ref> [BT, SK, NR] </ref>. These studies, however, were limited. First, they consider only a simplified version of secret voting, where there are voting centers that cannot be coerced. Next, their constructions require physically secure communication channels during crucial parts of the computation.
Reference: [BCG] <author> M. Ben-Or, R. Canetti and O. Goldreich, </author> <title> "Asynchronous Secure Computations", </title> <booktitle> 25th STOC, </booktitle> <year> 1993, </year> <pages> pp. 52-61. </pages>
Reference-contexts: In other words, it seems that a coerced party can either `prove' that it has one input or `prove' that it has another input, but it cannot `prove' both claims at the same time. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>.
Reference: [BGW] <author> M. Ben-Or, S. Goldwasser and A. Wigderson, </author> " <title> Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation", </title> <booktitle> 20th STOC, </booktitle> <year> 1988, </year> <pages> pp. 1-10. </pages>
Reference-contexts: Having formalized the notion of incoercible protocols, a simple argument now shows that incoercible secure computation is impossible when the adversary is computationally unbounded. Interestingly, this holds even if the communication channels are private (as in <ref> [BGW, CCD] </ref>). Thus, our protocols are another demonstration of the interesting fact that constructions based on the computational limitations of the adversary can achieve qualitatively stronger results than constructions based on physical assumptions (such as private channels). On the construction. <p> Nevertheless, our solution achieves both incoercibility and adaptive security. For convenience, we use the [CFGN] protocol in our construction. However, we can do with protocols that achieve only a weaker security property, described in the sequel (the [GMW2] protocols, as well as the <ref> [BGW] </ref> protocols augmented with encrypting each message using standard encryption, have this property). In fact, our construction is an alternative to [CFGN] for obtaining adaptive security. (A third alternative is proposed in [CDNO].) We remark that [CFGN] construct yet another type of encryption functions, called non-committing encryption. <p> The same argument demonstrates that known constructions for secure multiparty computation (e.g., <ref> [GMW2, BGW, CCD, CFGN] </ref>) are coercible (i.e., not incoercible) even if the adversary is limited to probabilistic polynomial time. Moreover, the natural strategy of simply using deniable encryption (see Section 4 below) on top of previously known solutions is susceptible to the same difficulties. Computationally unbounded adversaries, private channels. <p> Thus, if the adversary corrupts or coerces t randomly chosen parties, it will `catch' P with probability O ( t n ). Consider for illustration the <ref> [BGW] </ref> construction for computing a function that whose output depends on P i 's input. Here the first step of P i is sharing its input among the other players using Shamir's secret sharing scheme. <p> Such protocols (for computing any function) can be constructed via, say, the <ref> [BGW] </ref> construction. <p> Remark. In fact, we do not need the full power of the [CFGN] construction. That is, a much weaker version of adaptive security, briefly sketched below, is sufficient. We remark that the [GMW2] construction, as well as the <ref> [BGW, CCD, RB] </ref> constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. An immediate consequence of this observation is that our construction, combined with ,say [GMW2], is an alternative construction to [CFGN] for obtaining full-fledged adaptively secure protocols.
Reference: [C] <author> R. Canetti, </author> <title> "Studies in Secure Multiparty Computation and Applications", </title> <type> Ph.D. Thesis, </type> <institution> Weizmann Institute of Science, </institution> <year> 1995. </year> <note> Available on-line at http://theory.lcs.mit.edu/~canetti </note>
Reference-contexts: Coming up with a definition that correctly captures this new type of attack turned out to be a non-trivial task. Moreover, our definition manages to incorporate this concern within the existing framework used for defining multiparty secure computation <ref> [MR, Be, CFGN, C] </ref>. In particular, it is immediate from our definition that any incoercible protocol is also (adaptively) secure in the standard sense. <p> This ideal model, described in the sequel, extends of the ideal model used to define `standard' security of multiparty protocols <ref> [MR, Be, CFGN, C] </ref>. Having formalized the notion of incoercible protocols, a simple argument now shows that incoercible secure computation is impossible when the adversary is computationally unbounded. Interestingly, this holds even if the communication channels are private (as in [BGW, CCD]). <p> Next we define an ideal model of computation, which represents the `most we can hope for' from incoercible computation. This ideal model is an extension of the ideal model used in <ref> [C, CFGN] </ref> to define adaptive security. Finally we say that a (real-life) computation is incoercible if it is equivalent | in a standard sense described in the sequel | to a computation in the ideal model. <p> In other words, it seems that a coerced party can either `prove' that it has one input or `prove' that it has another input, but it cannot `prove' both claims at the same time. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>.
Reference: [CDNO] <author> R. Canetti, C. Dwork, M. Naor and R. Ostrovsky, "Deniable Encryptions", </author> <title> manuscript. Available at the Theory of Cryptography Library, </title> <address> http://theory.lcs.mit.edu/ ~ tcryptol/ </address>
Reference-contexts: On the construction. We construct incoercible protocols for computing any function in the computational setting, as long as less than half of the parties are coerced or corrupted. A main tool in our construction is a new type of encryption schemes, called deniable encryptions <ref> [CDNO] </ref>. These schemes address the same problem as here, in the limited context of encryption. <p> In fact, our construction is an alternative to [CFGN] for obtaining adaptive security. (A third alternative is proposed in <ref> [CDNO] </ref>.) We remark that [CFGN] construct yet another type of encryption functions, called non-committing encryption. Non-committing encryptions have similar flavor to deniable ones, in that there exist ciphertexts that can be "opened" as encryptions of, say, both 1 and 0. <p> In the next two sections we describe how we overcome this problem. 4 Tools We describe two tools used in our construction: deniable encryption and general adaptively secure computation (in fact, only a limited version of the second tool is needed). 4.1 Deniable encryptions Deniable encryption schemes, recently introduced in <ref> [CDNO] </ref>, are two-party (public key) encryption protocols with the additional property that later, upon coercion, the sender can convincingly `lie' about the encrypted value. (That is, the sender can present `fake random input' that is consistent with the original ciphertext and an encrypted value different than the original one.) For self-containment, <p> key) encryption protocols with the additional property that later, upon coercion, the sender can convincingly `lie' about the encrypted value. (That is, the sender can present `fake random input' that is consistent with the original ciphertext and an encrypted value different than the original one.) For self-containment, and since the <ref> [CDNO] </ref> work is not yet widely accessible, we present here a sketch of the definition and constructions relevant to this work. (The construction appears in Appendix A.) We remark that our construction of incoercible protocols uses deniable encryption protocols as a general tool and does not rely on particular implementations. 10 <p> We now present a more precise definition. (The definition here is slightly more limited than the one in <ref> [CDNO] </ref>; this suffices for our needs.) With c = E e (m; r) we denote the encryption of m using random coins r. With E (m) we denote the random variable describing E (m; r) where the probability is over the choices of r and the random input of G. <p> We remark that schemes resilient against coercion of the receiver, or simultaneous coercion of both the sender and the receiver, are defined in a similar way. (For this work we only need schemes resilient against coercing the sender.) In Appendix A we sketch the <ref> [CDNO] </ref> encryption scheme. Appropriately choosing the security parameter, this scheme is 1 l k -sender deniable, for any constant k. 4.2 Adaptively secure computation Our construction also makes use of protocols for securely computing any function in the presence of adaptive adversaries (namely, adaptively secure protocols).
Reference: [CFGN] <author> R. Canetti, U. Feige, O. Goldreich and M. Naor, </author> <title> "Adaptively Secure Computation", </title> <booktitle> 28th STOC, </booktitle> <year> 1996. </year> <note> Also in MIT LCS TR No. 682, </note> <year> 1996. </year>
Reference-contexts: Coming up with a definition that correctly captures this new type of attack turned out to be a non-trivial task. Moreover, our definition manages to incorporate this concern within the existing framework used for defining multiparty secure computation <ref> [MR, Be, CFGN, C] </ref>. In particular, it is immediate from our definition that any incoercible protocol is also (adaptively) secure in the standard sense. <p> This ideal model, described in the sequel, extends of the ideal model used to define `standard' security of multiparty protocols <ref> [MR, Be, CFGN, C] </ref>. Having formalized the notion of incoercible protocols, a simple argument now shows that incoercible secure computation is impossible when the adversary is computationally unbounded. Interestingly, this holds even if the communication channels are private (as in [BGW, CCD]). <p> Consequently, coercion does not help in finding the transmitted value. A natural first attempt at constructing incoercible protocols may be to start with any standard secure protocol (say, <ref> [GMW2, CFGN] </ref>) and have the parties encrypt each message using deniable encryption. However, this simple solution does not work. Essentially, the reason is that each encrypted message (i.e., each ciphertext) has a unique receiver who can correctly decrypt it. <p> On incoercibility and adaptive security. Recently it was shown how to compute any function in the computational setting when the adversary is adaptive (i.e., when it can corrupt parties during the course of the computation based on the information gathered so far) <ref> [CFGN] </ref>. In principle, adaptive security (i.e., security against adaptive adversaries) is unrelated to incoercibility. In particular, the coercion problem remains even if the set of coerced parties is known in advance. Nevertheless, our solution achieves both incoercibility and adaptive security. For convenience, we use the [CFGN] protocol in our construction. <p> the information gathered so far) <ref> [CFGN] </ref>. In principle, adaptive security (i.e., security against adaptive adversaries) is unrelated to incoercibility. In particular, the coercion problem remains even if the set of coerced parties is known in advance. Nevertheless, our solution achieves both incoercibility and adaptive security. For convenience, we use the [CFGN] protocol in our construction. However, we can do with protocols that achieve only a weaker security property, described in the sequel (the [GMW2] protocols, as well as the [BGW] protocols augmented with encrypting each message using standard encryption, have this property). In fact, our construction is an alternative to [CFGN] <p> <ref> [CFGN] </ref> protocol in our construction. However, we can do with protocols that achieve only a weaker security property, described in the sequel (the [GMW2] protocols, as well as the [BGW] protocols augmented with encrypting each message using standard encryption, have this property). In fact, our construction is an alternative to [CFGN] for obtaining adaptive security. (A third alternative is proposed in [CDNO].) We remark that [CFGN] construct yet another type of encryption functions, called non-committing encryption. <p> In fact, our construction is an alternative to <ref> [CFGN] </ref> for obtaining adaptive security. (A third alternative is proposed in [CDNO].) We remark that [CFGN] construct yet another type of encryption functions, called non-committing encryption. Non-committing encryptions have similar flavor to deniable ones, in that there exist ciphertexts that can be "opened" as encryptions of, say, both 1 and 0. <p> Next we define an ideal model of computation, which represents the `most we can hope for' from incoercible computation. This ideal model is an extension of the ideal model used in <ref> [C, CFGN] </ref> to define adaptive security. Finally we say that a (real-life) computation is incoercible if it is equivalent | in a standard sense described in the sequel | to a computation in the ideal model. <p> Alternatively, the simulator is polynomial in the complexity of the function. 2 We assume that protocol does not instruct the parties to erase any data during the computation. Alternatively one may assume that the parties copy all data to a safe, non-erasable memory. See <ref> [CFGN] </ref> for a discussion on parties that avoid erasing data, and about semi-honest parties in general. 4 each party P i has an arbitrary fake input x 0 i . <p> This black-box represents the input-output relations of the real-life adversary described above. For concreteness, we present the following description of the "mechanics" of this black-box, representing a real-life adversary. (This description differs from the one in <ref> [CFGN] </ref> only in that coercion requests are added.) The black-box has a random tape, where it expects to find its random input, and an input-output tape. Once a special start input is given on the input-output tape, the interaction on this tape proceeds in iterations, as follows. <p> In other words, it seems that a coerced party can either `prove' that it has one input or `prove' that it has another input, but it cannot `prove' both claims at the same time. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>. <p> The same argument demonstrates that known constructions for secure multiparty computation (e.g., <ref> [GMW2, BGW, CCD, CFGN] </ref>) are coercible (i.e., not incoercible) even if the adversary is limited to probabilistic polynomial time. Moreover, the natural strategy of simply using deniable encryption (see Section 4 below) on top of previously known solutions is susceptible to the same difficulties. Computationally unbounded adversaries, private channels. <p> Consequently, P does not have to `lie' about any of its past messages. Instead P can present a different interpretation (i.e., a different random input) that will make the same transcript `look' like it resulted from a different input. However, known constructions (e.g., <ref> [GMW2, CFGN] </ref>) do not take advantage of this leeway, and are thus coercible. That is, these constructions do not allow a party to claim that his input was different than what was really used in the computation without `lying' about at least one of its outgoing or incoming messages. <p> Appropriately choosing the security parameter, this scheme is 1 l k -sender deniable, for any constant k. 4.2 Adaptively secure computation Our construction also makes use of protocols for securely computing any function in the presence of adaptive adversaries (namely, adaptively secure protocols). Such protocols were recently constructed in <ref> [CFGN] </ref>, where a definition is also given. Let us shortly review the [CFGN] definition. Adaptively secure protocols are defined using a similar framework as the one used here. That is, the real-life computation is compared, in the same way as here, with a computation in an ideal model. <p> Such protocols were recently constructed in <ref> [CFGN] </ref>, where a definition is also given. Let us shortly review the [CFGN] definition. Adaptively secure protocols are defined using a similar framework as the one used here. That is, the real-life computation is compared, in the same way as here, with a computation in an ideal model. <p> The real-life adversary is modified accordingly. (Ofcourse, adaptively secure protocols are not required to specify a faking algorithm for coerced parties.) 11 The <ref> [CFGN] </ref> construction starts with a protocol that is adaptively secure in the private channels setting (i.e., the setting where the adversary hears only messages sent to corrupted parties). Such protocols (for computing any function) can be constructed via, say, the [BGW] construction. <p> Such protocols (for computing any function) can be constructed via, say, the [BGW] construction. Next, each message sent in is encrypted using a special type of encryption function, called non-committing encryption. (non-committing encryptions are the heart of their construction.) 9 An important (for us) feature of the <ref> [CFGN] </ref> construction is that its security can be proven via black-box simulation, similar to the one described in Section 2. That is, for any protocol constructed via [CFGN] there exists a simulator (that is, an ideal-model adversary) S that carries out, with any real-life adversary, a simulated interaction that is indistinguishable <p> type of encryption function, called non-committing encryption. (non-committing encryptions are the heart of their construction.) 9 An important (for us) feature of the <ref> [CFGN] </ref> construction is that its security can be proven via black-box simulation, similar to the one described in Section 2. That is, for any protocol constructed via [CFGN] there exists a simulator (that is, an ideal-model adversary) S that carries out, with any real-life adversary, a simulated interaction that is indistinguishable &gt;from a real one. However, S does not know how to deal with coercive adversaries. <p> However, S does not know how to deal with coercive adversaries. That is, it does not know how to deal with coercion requests made by the black-box, and does not generate such requests in the ideal model. Remark. In fact, we do not need the full power of the <ref> [CFGN] </ref> construction. That is, a much weaker version of adaptive security, briefly sketched below, is sufficient. We remark that the [GMW2] construction, as well as the [BGW, CCD, RB] constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. <p> An immediate consequence of this observation is that our construction, combined with ,say [GMW2], is an alternative construction to <ref> [CFGN] </ref> for obtaining full-fledged adaptively secure protocols. We sketch this weaker version of adaptive security. <p> An extension that deals with the case of different, private outputs for different parties is described in Section 5.2. An analysis appears in Section 5.3. 5.1 Computing functions with a common output A naive attempt at constructing incoercible protocols may be to start with a known secure-but-coercible construction (say, <ref> [CFGN] </ref>), and encrypt each message using deniable encryption. However, the impossibility argument of Section 3 applies to this solution as well: in order to `lie' about its input, a coerced party has to `lie' about the plaintext of at least one ciphertext sent in the past. <p> Let 1 be the secure protocol computing the function F 1 (constructed e.g. using <ref> [CFGN] </ref>.) The players will perform 1 over the secret inputs i in a such a way that the i th output e ffi d (i) is privately known only to player P i . In Phase 1 the players will invoke n times protocol 1 on the following inputs. <p> This is the malleability problem of encryptions functions [DDN]. In our case the problem is solved by using a different encryption key for each party. Complexity of the construction. Let be the secure protocol for the computation of the function f that results from the construction of <ref> [CFGN] </ref>. Let 0 be the incoercible protocol for the computation of the same function that results from our construction above. We analyze the round and computational complexity of the two protocols. <p> With R 0 and C 0 denote the same quantities for 0 . Then it is easy to verify that R 0 = R + constant 1 and C 0 = C + constant 2 11 In fact, the zero-knowledge proof is not necessary if either of <ref> [GMW2, CFGN] </ref> is used in phases 1 and 3. This is so since the protocols 1 and 3 can be combined, in a natural way, into one protocol where each party P i has "intermediate output" ~ d (i) , and subsequently an additional input ~z. <p> Notice however that we cannot say anything in general about the increase in complexity needed to obtain incoercibility. Indeed let be an extremely efficient protocol that securely computes a function f , possibly not related to the construction of <ref> [CFGN] </ref>. Although our techniques can be used to make any protocol, including , incoercible, we cannot claim the same efficiency results outlined above.
Reference: [CCD] <author> D. Chaum, C. Crepeau and I Damgard, </author> <title> "Multiparty unconditionally secure protocols", </title> <booktitle> 20th STOC, </booktitle> <year> 1988, </year> <pages> pp. 11-19. </pages>
Reference-contexts: Having formalized the notion of incoercible protocols, a simple argument now shows that incoercible secure computation is impossible when the adversary is computationally unbounded. Interestingly, this holds even if the communication channels are private (as in <ref> [BGW, CCD] </ref>). Thus, our protocols are another demonstration of the interesting fact that constructions based on the computational limitations of the adversary can achieve qualitatively stronger results than constructions based on physical assumptions (such as private channels). On the construction. <p> The same argument demonstrates that known constructions for secure multiparty computation (e.g., <ref> [GMW2, BGW, CCD, CFGN] </ref>) are coercible (i.e., not incoercible) even if the adversary is limited to probabilistic polynomial time. Moreover, the natural strategy of simply using deniable encryption (see Section 4 below) on top of previously known solutions is susceptible to the same difficulties. Computationally unbounded adversaries, private channels. <p> Remark. In fact, we do not need the full power of the [CFGN] construction. That is, a much weaker version of adaptive security, briefly sketched below, is sufficient. We remark that the [GMW2] construction, as well as the <ref> [BGW, CCD, RB] </ref> constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. An immediate consequence of this observation is that our construction, combined with ,say [GMW2], is an alternative construction to [CFGN] for obtaining full-fledged adaptively secure protocols.
Reference: [DDN] <author> D. Dolev, C. Dwork, M. Naor, </author> <title> "Non-malleable Encryption", </title> <booktitle> 23th STOC, </booktitle> <year> 1991, </year> <pages> pp. 542-552. </pages>
Reference-contexts: Thus the protocol would cease to be secure even in the standard sense. This is the malleability problem of encryptions functions <ref> [DDN] </ref>. In our case the problem is solved by using a different encryption key for each party. Complexity of the construction. Let be the secure protocol for the computation of the function f that results from the construction of [CFGN].
Reference: [GL] <author> O. Goldreich and L. Levin, </author> <title> "A Hard-Core Predicate to any One-Way Function", </title> <booktitle> 21st STOC, </booktitle> <year> 1989, </year> <pages> pp. 25-32. </pages>
Reference: [GMW1] <author> O. Goldreich, S. Micali and A. Wigderson, </author> <title> "Proofs that yield nothing but their validity and a methodology of cryptographic protocol design", </title> <booktitle> 27th FOCS, </booktitle> <year> 1986, </year> <pages> pp. 174-187. </pages> <note> Journal version in JACM, vol.38, no.1, pp.691-729, </note> <year> 1991. </year>
Reference-contexts: This protocol is augmented with a zero-knowledge proof by each player P i that the input contributed during this phase is actually the share ~ d (i) it received in Phase 1. This an NP-statement, so it can be proven in zero-knowledge (say, using <ref> [GMW1] </ref>). 11 The faking algorithm. We specify the actions of player P i upon coercion. First P i hands his fake input x 0 i to the adversary. If x i = x 0 i then P i also hands his real random input r i .
Reference: [GMW2] <author> O. Goldreich, S. Micali and A. Wigderson, </author> <title> "How to Play any Mental Game", </title> <booktitle> 19th STOC, </booktitle> <year> 1987, </year> <pages> pp. 218-229. </pages>
Reference-contexts: Still, the parties want to compute some common function of their inputs in a secure way. Security here means maintaining correctness of the outputs while keeping the parties' internal data as private as possible. This is the well-known secure multiparty computation problem (e.g., <ref> [Y, GMW2] </ref>). The parties' distrust in each other is modeled via an adversary that corrupts parties, learns their inputs, and controls their behavior. <p> Consequently, coercion does not help in finding the transmitted value. A natural first attempt at constructing incoercible protocols may be to start with any standard secure protocol (say, <ref> [GMW2, CFGN] </ref>) and have the parties encrypt each message using deniable encryption. However, this simple solution does not work. Essentially, the reason is that each encrypted message (i.e., each ciphertext) has a unique receiver who can correctly decrypt it. <p> Nevertheless, our solution achieves both incoercibility and adaptive security. For convenience, we use the [CFGN] protocol in our construction. However, we can do with protocols that achieve only a weaker security property, described in the sequel (the <ref> [GMW2] </ref> protocols, as well as the [BGW] protocols augmented with encrypting each message using standard encryption, have this property). <p> We have tried to point these issues out in the presentation below and in Section 2.3. The real-life computation. We first describe the standard computational setting for secure multiparty computation <ref> [GMW2] </ref>. Next we incorporate coercion in this setting. <p> The same argument demonstrates that known constructions for secure multiparty computation (e.g., <ref> [GMW2, BGW, CCD, CFGN] </ref>) are coercible (i.e., not incoercible) even if the adversary is limited to probabilistic polynomial time. Moreover, the natural strategy of simply using deniable encryption (see Section 4 below) on top of previously known solutions is susceptible to the same difficulties. Computationally unbounded adversaries, private channels. <p> Consequently, P does not have to `lie' about any of its past messages. Instead P can present a different interpretation (i.e., a different random input) that will make the same transcript `look' like it resulted from a different input. However, known constructions (e.g., <ref> [GMW2, CFGN] </ref>) do not take advantage of this leeway, and are thus coercible. That is, these constructions do not allow a party to claim that his input was different than what was really used in the computation without `lying' about at least one of its outgoing or incoming messages. <p> Remark. In fact, we do not need the full power of the [CFGN] construction. That is, a much weaker version of adaptive security, briefly sketched below, is sufficient. We remark that the <ref> [GMW2] </ref> construction, as well as the [BGW, CCD, RB] constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. An immediate consequence of this observation is that our construction, combined with ,say [GMW2], is an alternative construction to [CFGN] for obtaining full-fledged adaptively <p> We remark that the <ref> [GMW2] </ref> construction, as well as the [BGW, CCD, RB] constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. An immediate consequence of this observation is that our construction, combined with ,say [GMW2], is an alternative construction to [CFGN] for obtaining full-fledged adaptively secure protocols. We sketch this weaker version of adaptive security. <p> With R 0 and C 0 denote the same quantities for 0 . Then it is easy to verify that R 0 = R + constant 1 and C 0 = C + constant 2 11 In fact, the zero-knowledge proof is not necessary if either of <ref> [GMW2, CFGN] </ref> is used in phases 1 and 3. This is so since the protocols 1 and 3 can be combined, in a natural way, into one protocol where each party P i has "intermediate output" ~ d (i) , and subsequently an additional input ~z.
Reference: [GM] <author> S. Goldwasser and S. Micali, </author> <title> "Probabilistic encryption", </title> <journal> JCSS, </journal> <volume> Vol. 28, No 2, </volume> <month> April </month> <year> 1984, </year> <pages> pp. 270-299. </pages>
Reference-contexts: A deniable encryption scheme contains a key-generation algorithm G, an encryption algorithm E and a decryption algorithm D that constitute a standard semantically secure encryption scheme as defined in <ref> [GM] </ref>, with the exception that there may be a negligible probability of decryption error. Furthermore, the sender should have a `faking algorithm' E with the following property.
Reference: [He] <author> A. Herzberg, </author> <note> Rump session presentations at CRYPTO'91. </note>
Reference-contexts: As long as enough parties remain uncorrupted, the parties can correctly compute any function of their inputs, while making sure that the adversary learns nothing from the computation other than the inputs and outputs of the corrupted parties. However, these protocols suffer from the following deficiency, pointed out in <ref> [He, BT] </ref>. Using any of these protocols, the public transcript of the communication can be used as an (involuntary) commitment of the parties to their inputs and outputs.
Reference: [MR] <author> S. Micali and P. Rogaway, </author> <title> "Secure Computation", </title> <note> in preparation. Preliminary version in CRYPTO 91. </note>
Reference-contexts: Coming up with a definition that correctly captures this new type of attack turned out to be a non-trivial task. Moreover, our definition manages to incorporate this concern within the existing framework used for defining multiparty secure computation <ref> [MR, Be, CFGN, C] </ref>. In particular, it is immediate from our definition that any incoercible protocol is also (adaptively) secure in the standard sense. <p> This ideal model, described in the sequel, extends of the ideal model used to define `standard' security of multiparty protocols <ref> [MR, Be, CFGN, C] </ref>. Having formalized the notion of incoercible protocols, a simple argument now shows that incoercible secure computation is impossible when the adversary is computationally unbounded. Interestingly, this holds even if the communication channels are private (as in [BGW, CCD]). <p> ffi (n) is negligible then we say that fA n g and fB n g are computationally indistinguishable and write A n B n . 2.1 The basic definition Our definition builds on top of the existing framework used for defining multiparty computation secure against adaptive adversaries ([C, CFGN], following <ref> [MR, Be] </ref>). We proceed in three steps: First we describe the `mechanics' of a computation in the presence of a coercive adversary, emphasizing the difference from the `mechanics' of a computation in the presence of a standard adaptive adversary. <p> In other words, it seems that a coerced party can either `prove' that it has one input or `prove' that it has another input, but it cannot `prove' both claims at the same time. The notion of equivalence of computations is standard <ref> [MR, Be, BCG, CFGN, C] </ref>.
Reference: [NR] <author> V. Niemi and A. Renvall, </author> <title> "How to prevent buying of votes in computer elections", </title> <booktitle> ASYACRYPT 1994, </booktitle> <pages> pp. 141-148. </pages>
Reference-contexts: Other scenarios include electronic commerce, bidding, key-escrowing, and any computation done in the presence of some authority (say, a Mafia, an employer, or a government) that may become coercive. Coercion in the context of secret voting has been studied in the past <ref> [BT, SK, NR] </ref>. These studies, however, were limited. First, they consider only a simplified version of secret voting, where there are voting centers that cannot be coerced. Next, their constructions require physically secure communication channels during crucial parts of the computation.
Reference: [RB] <author> T. Rabin and M. Ben-Or, </author> <title> "Verifiable Secret Sharing and Secure Computation with Honest Majority", </title> <booktitle> 21th STOC, </booktitle> <year> 1989, </year> <pages> pp. 73-85. </pages>
Reference-contexts: Remark. In fact, we do not need the full power of the [CFGN] construction. That is, a much weaker version of adaptive security, briefly sketched below, is sufficient. We remark that the [GMW2] construction, as well as the <ref> [BGW, CCD, RB] </ref> constructions augmented with standard (semantically secure) encryptions, can be shown to have this weaker version of adaptive security. An immediate consequence of this observation is that our construction, combined with ,say [GMW2], is an alternative construction to [CFGN] for obtaining full-fledged adaptively secure protocols.
Reference: [SK] <author> K. Sako and J. Kilian, </author> <title> "Receipt-Free Mix-Type Voting Scheme", </title> <booktitle> Eurocrypt 1995, </booktitle> <pages> pp. 393-403. </pages>
Reference-contexts: Other scenarios include electronic commerce, bidding, key-escrowing, and any computation done in the presence of some authority (say, a Mafia, an employer, or a government) that may become coercive. Coercion in the context of secret voting has been studied in the past <ref> [BT, SK, NR] </ref>. These studies, however, were limited. First, they consider only a simplified version of secret voting, where there are voting centers that cannot be coerced. Next, their constructions require physically secure communication channels during crucial parts of the computation.
Reference: [Sh] <author> A. Shamir, </author> <title> "How to share a secret", </title> <journal> CACM, </journal> <volume> vol.22, </volume> <month> Nov. </month> <year> 1979, </year> <pages> pp. 612-613. </pages>
Reference-contexts: Shamir's <ref> [Sh] </ref>.) Consider the following n-input, n-output function F 1 ( 1 ; : : : ; n ) = (e ffi d (1) ; : : : ; e ffi d (n) ) where (e; d (1) ; : : : ; d (n) ) = ~ G ( L i
Reference: [Y] <author> A. Yao, </author> <title> "Protocols for Secure Computation", </title> <booktitle> 23th FOCS, 1982, pp.160-164. </booktitle> <pages> 18 </pages>
Reference-contexts: Still, the parties want to compute some common function of their inputs in a secure way. Security here means maintaining correctness of the outputs while keeping the parties' internal data as private as possible. This is the well-known secure multiparty computation problem (e.g., <ref> [Y, GMW2] </ref>). The parties' distrust in each other is modeled via an adversary that corrupts parties, learns their inputs, and controls their behavior.
References-found: 20

