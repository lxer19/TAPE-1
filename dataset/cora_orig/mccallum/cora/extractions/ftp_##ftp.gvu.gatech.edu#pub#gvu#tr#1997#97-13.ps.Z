URL: ftp://ftp.gvu.gatech.edu/pub/gvu/tr/1997/97-13.ps.Z
Refering-URL: http://www.cs.gatech.edu/gvu/reports/1997/
Root-URL: 
Email: pitkow@parc.xerox.com  
Author: James Pitkow 
Address: Palo Alto California 94304 USA  
Affiliation: Xerox Palo Alto Research Center  
Abstract: In Search of Reliable Usage Data on the WWW J. Pitkow Proceedings of the Sixth International WWW Conference 1 GVU Technical Report: GIT-GVU-97-13 In Search of Reliable Usage Data on the WWW Abstract The WWW is currently the hottest testbed for future interactive digital systems. While much is understood technically about how the WWW functions, substantially less is known about how this technology is used collectively and on an individual basis. This disparity of knowledge exists largely as a direct consequence of the decentralized nature of Web. Since each user of the Web is not uniquely identifiable across the system and the system employs various levels of caching, measurement of actual usage is problematic. This paper establishes terminology to frame the problem of reliably determining usage of WWW resources while reviewing current practice and their shortcomings. A review of the various metrics and analyses that can be performed to determine usage is then presented. This is followed by a discussion of the strengths and weaknesses of the hit-metering proposal [Mogul and Leach 1997] currently in consideration by the HTTP working group. Lastly, new proposals, based upon serverside sampling are introduced and assessed against the other proposal. It is argued that serverside sampling provides more reliable and useful usage data while requiring no change to the current HTTP protocol and enhancing user privacy.
Abstract-found: 1
Intro-found: 1
Reference: [Catledge and Pitkow 1995] <author> Catledge, L. and Pitkow, J. </author> <title> (1995) Characterizing Browsing Behaviors on the World Wide Web. Computer Networks and ISDN Systems, </title> <type> 27(6). </type>
Reference-contexts: Another problem is determining when users leave the site since HTTP only sends get me this page messages and not Im leaving this page messages. However, if a statistically valid sample size is determined and the data collected, reasonable statements about the reading times of pages can be made. <ref> [Catledge and Pitkow 1995] </ref> first reported a session timeout period of 25.5 minutes, which was 1 standard deviations from the mean of 9.3 minutes between user interface events. <p> Attrition curves are defined as the plot of attrition ratios for all pages along a certain path. Other methods for analyzing hypertext paths include Markov Chain analysis [Guzdial 1994], Pathfinder Networks [Schvaneveldt 1990], and subsequence analysis <ref> [Catledge and Pitkow 1995] </ref>[Tauscher 1996]. Path information can also be used to cluster users as well [Yan, et al. 1996].
Reference: [Guzdial 1993] <author> Guzdial, M. </author> <year> (1993). </year> <title> Characterizing Process Change Using Log File Data. Graphics, Visualization, </title> <note> and Usability Center Technical Report 93-41. </note>
Reference: [Fielding et al 1997] <author> Fielding, R, Gettys, J., Mogul, J. C., Frystyk, H., and Berners-Lee, T. </author> <year> (1997). </year> <title> RFC 2068Hypertext Transfer ProtocolHTTP/1.1. </title> <institution> UC Irvine. Digital Equipment Corporation, MIT. </institution> <note> In Search of Reliable Usage Data on the WWW J. Pitkow Proceedings of the Sixth International WWW Conference 14 GVU Technical Report: GIT-GVU-97-13 </note>
Reference: [Hallam-Baker 1996] <author> Hallam-Baker, P. </author> <year> (1996). </year> <note> W3C Working Draft for Proxy Caches. WD-proxy960221. &lt;URL:http://www.w3.org/pub/WWW/TR/WD-proxy.html&gt;. Online resource. </note>
Reference-contexts: The two most notable are <ref> [Hallam-Baker 1996] </ref>, which proposes complete forwarding of access data from proxy-caches, and [Mogul and Leach 1997], which proposes a limited form of usage reporting by proxy-caches. Unfortunately, discussion and interest around [Hallam-Baker 1996] by the HTTP Working Group has not occurred in over half a year and as such, its RFC <p> The two most notable are <ref> [Hallam-Baker 1996] </ref>, which proposes complete forwarding of access data from proxy-caches, and [Mogul and Leach 1997], which proposes a limited form of usage reporting by proxy-caches. Unfortunately, discussion and interest around [Hallam-Baker 1996] by the HTTP Working Group has not occurred in over half a year and as such, its RFC status has been withdrawn. This, plus space considerations, limit the discussion by this paper to [Mogul and Leach 1997], which is commonly referred to as the hit-metering proposal.
Reference: [Internet Archives 1996] <institution> Internet Archives. </institution> <note> (1996) &lt;URL:http://www.archive.org&gt;. Online resource. </note>
Reference-contexts: While this is not a terribly large amount of data, it is roughly a third the size of all the current HTML content on the Internet <ref> [Internet Archives 1996] </ref>! Of course, there is also the time require to process that amount of data, which turns out to be a nontrivial., and typically dominates the cost equation as usage analysis.
Reference: [Interse 1996] <author> Interse Corporation. </author> <year> (1996) </year> <month> &lt;URL:http://www.interse.com&gt;. </month> <title> Online resource. </title>
Reference-contexts: Many of the commercially available log file analysis programs come with databases that match domain names to core demographics, e.g., Interse <ref> [Interse 1996] </ref>. Of course, the most obvious method of collecting additional demographics of users is by asking the actual users of the site. This is routinely accomplished via online registration forms. <p> A timeout period of 30 minutes has become the standard used by log file analysis programs, e.g., Interse <ref> [Interse 1996] </ref> and I/PRO [I/PRO 1996]. This value should be determined individually for each site being measured. At the site level, temporal analysis can reveal other useful metrics. The total duration of the visit, or session length, measures the amount of attention spent by visitors to the site.
Reference: [I/PRO 1996] <institution> Internet Profiles. </institution> <note> (1996) &lt;URL:http://www.ipro.com&gt;. Online resource. </note>
Reference-contexts: Other methods for collecting demographics of users at a site include Universal Registration Systems, e.g. I/PROs I/COUNT <ref> [I/PRO 1996] </ref>. These systems require a user to register only once in exchange for an identifier. This identifier can then be used across the set of participating sites. <p> A timeout period of 30 minutes has become the standard used by log file analysis programs, e.g., Interse [Interse 1996] and I/PRO <ref> [I/PRO 1996] </ref>. This value should be determined individually for each site being measured. At the site level, temporal analysis can reveal other useful metrics. The total duration of the visit, or session length, measures the amount of attention spent by visitors to the site.
Reference: [Mogul and Leach 1997] <author> Mogul, J. And Leach, P. J. </author> <year> (1997). </year> <note> Simple Hit-Metering for HTTP. Internet Draft draft-ietf-http-hit-metering-00.txt. HTTP Working Group. January 1997. This is a working draft. </note>
Reference-contexts: The two most notable are [Hallam-Baker 1996], which proposes complete forwarding of access data from proxy-caches, and <ref> [Mogul and Leach 1997] </ref>, which proposes a limited form of usage reporting by proxy-caches. Unfortunately, discussion and interest around [Hallam-Baker 1996] by the HTTP Working Group has not occurred in over half a year and as such, its RFC status has been withdrawn. <p> Unfortunately, discussion and interest around [Hallam-Baker 1996] by the HTTP Working Group has not occurred in over half a year and as such, its RFC status has been withdrawn. This, plus space considerations, limit the discussion by this paper to <ref> [Mogul and Leach 1997] </ref>, which is commonly referred to as the hit-metering proposal. Recently, [Mogul and Leach 1997] have generated a rather elegant proposal for hit-metering. <p> This, plus space considerations, limit the discussion by this paper to <ref> [Mogul and Leach 1997] </ref>, which is commonly referred to as the hit-metering proposal. Recently, [Mogul and Leach 1997] have generated a rather elegant proposal for hit-metering. Their work is aimed at removing the practice of cache-busting by sites wishing to gain an accurate count of the usage of the sites resources. <p> In that field, publishers try to determine the number of users who read a publication at least once. It does not try to measure the number of times users read the publication overall. Adhering to the same model, <ref> [Mogul and Leach 1997, page 5] </ref> specify a system whose goal is a best-efforts approximation of the true number of uses and/or reuses, not a guaranteed exact count. <p> So, did a significant decrease in traffic occur because of real usage of the site or because of proxy-cache failures, failures in the network, etc.? These sources of variability seriously undermine the confidence one can place upon the numbers reported using the system proposed by <ref> [Mogul and Leach 1997] </ref>, since results are not guaranteed to be either repeatable or reliable. <p> With respect to the Web, inferential statistics prescribes sampling of usage data to understand the number of users as well as the usage of a sites resources. This approach to collecting usage information via a subset of the population is diametrically opposed to the approach taken by cache-busting and <ref> [Mogul and Leach 1997] </ref>, which attempts to collect as much information about all users and usage as possible. With the increasing number of Web users, and the increasing number of pages made accessible, measuring each and every page request becomes quite expensive. <p> Still, both provide more protection of user privacy than cache-busting. 6 Conclusion This paper reviewed the current practices and limitation in the methods used to collected usage information on the WWW by first defining terminology. Since sever shortcomings exist in current practice, the latest proposal by the <ref> [Mogul and Leach 1997] </ref> was reviewed along with a new sampling based approach. Table 1 reviews the major dimensions along with the proposals were evaluated.
Reference: [Novak and Hoffman 1996] <author> Novak, T, and Hoffman, D. </author> <title> (1996) New Metrics for New Media: Toward the Development of Web Measurement Standards. Manuscript in progress. </title>
Reference-contexts: 1 Terminology Despite several efforts and widespread agreement on the need to establish a lingua-franca for usage and demographic collection, consensus does not exist [W3C 1996]. One of the more recent and comprehensive efforts <ref> [Novak and Hoffman 1996] </ref> provides a baseline of terminology specifically designed for the advertising and measurement communities. With the intent of generating consensus, this paper will build upon their framework for classifying visitors and terminology, clarifying and introducing new terminology as needed. <p> Visitors to WWW sites can be separated into the following categories: unidentified, session, tracked, and identified <ref> [Novak and Hoffman 1996] </ref>. For each class of visitors, a definition is provided followed by a discussion of the methods used to achieve each level of knowledge about visitors to a site.
Reference: [Pirolli, Pitkow, and Rao 1996] <author> Pirolli, P., Pitkow, J., and Rao, R. </author> <title> (1996) Silk From a Sows Ear: Extracting Usable Structure from the World Wide Web. </title> <booktitle> Conference on Human Factors in Computing Systems (CHI 96), </booktitle> <address> Vancouver, British Columbia, Canada. </address>
Reference-contexts: To uniquely identify users suspected of existing behind proxies (see Figure 1), session limits, the sites topology (the global hyperlink structure across pages), and browser characteristics can be used. One such algorithm implemented in <ref> [Pirolli, Pitkow, and Rao 1996] </ref> checks that each incoming request is reachable from the set of already visited pages. This is done by consulting the sites topology.
Reference: [PGP 1996] <institution> Pretty Good Privacy. </institution> <note> (1996) &lt;URL :http://www.pgp.com&gt;. Online resource. </note>
Reference: [Pitkow and Kehoe 1995] <author> Pitkow, J. and Kehoe, C. </author> <title> (1995) Results from Third World Wide Web User Survey. The World Wide Web Journal, </title> <type> 1(1). </type>
Reference-contexts: Others, however, will proceed to traverse the presented links, thus continuing down a path. Attrition, introduced initially with respect to the WWW by <ref> [Pitkow and Kehoe 1995] </ref>, can be understood as a measure of visitors who stop traversing verses the visitors who continue to traverse the hyperlinks from a given page. Attrition is typically calculated across a group of visitors, although it can be applied to individual visitors as well.
Reference: [Pitkow and Kehoe 1996] <author> Pitkow, J. and Kehoe, C. </author> <title> (1996) GVUs Sixth WWW User Survey. &lt;URL:http://www.ccc.gatech.edu/gvu/user_surveys/survey-10-1996&gt;. Online resource. </title>
Reference-contexts: This is routinely accomplished via online registration forms. However, GVUs most recent WWW User Survey data show that 33% of the over 14,500 respondents have falsified the information for online registration forms at least once <ref> [Pitkow and Kehoe 1996] </ref>. Over 10% reported that they provided incorrect information over 25% of the time. <p> As is turns out, Web users place great value on the anonymous nature of the Internet and are equally protective of their privacy online. Only one in five uses feel that identifiers that can track a user at a site across sessions, i.e., cookies, ought to even exist <ref> [Pitkow and Kehoe 1996] </ref>. How then do these proposals fair in the face of such opposition? Since cookies have already become the de-facto standard for sites interested in determining usage and the number of users, any proposal that further violates user privacy will most likely face serious opposition.
Reference: [Schvaneveldt 1990] <author> Schvaneveldt, R. </author> <title> (1999) Ed. Pathfinder Associative Networks: Studies in Knowledge Organization, </title> <publisher> Ablex Publishing Corporation, </publisher> <address> Norwood, NJ. </address>
Reference-contexts: Attrition curves are defined as the plot of attrition ratios for all pages along a certain path. Other methods for analyzing hypertext paths include Markov Chain analysis [Guzdial 1994], Pathfinder Networks <ref> [Schvaneveldt 1990] </ref>, and subsequence analysis [Catledge and Pitkow 1995][Tauscher 1996]. Path information can also be used to cluster users as well [Yan, et al. 1996].
Reference: [Tauscher 1996] <author> Tauscher, L. </author> <year> (1996). </year> <title> Evaluating History Mechanisms: An Empirical Study of Reuse and Patterns in World Wide Web Navigation. </title> <type> Masters Thesis, </type> <institution> Department of Computer Science, University of Calgary. </institution>
Reference: [W3C 1996] <institution> World Wide Web Consortium Workshop on Internet Survey Methodology and Web Demographics. </institution> <year> (1996). </year> <note> &lt;URL:http://www.ai.mit.edu/projects/iiip/conferences/survey96/progcopy.html&gt;. Online resource. </note>
Reference-contexts: 1 Terminology Despite several efforts and widespread agreement on the need to establish a lingua-franca for usage and demographic collection, consensus does not exist <ref> [W3C 1996] </ref>. One of the more recent and comprehensive efforts [Novak and Hoffman 1996] provides a baseline of terminology specifically designed for the advertising and measurement communities. <p> While cookies provide an already consistently implemented approach to identifying users, this is not the case for gathering reliable page views, temporal, and path information. This inability to gather solid data is the cause for much concern by the measurement community <ref> [W3C 1996] </ref>.
Reference: [Yan, et al. 1996] <author> Yan, T. W., Jacobsen, M, Garcia-Molina, H., and Umeshwar, D. </author> <title> (1996) From User Access Patterns to Dynamic Hypertext Linking. Computer Networks and ISDN Systems, </title> <type> 28(11). </type>
Reference-contexts: Other methods for analyzing hypertext paths include Markov Chain analysis [Guzdial 1994], Pathfinder Networks [Schvaneveldt 1990], and subsequence analysis [Catledge and Pitkow 1995][Tauscher 1996]. Path information can also be used to cluster users as well <ref> [Yan, et al. 1996] </ref>. While all these analyses provide insight into the behavior of visitors to a site and the usage of the sites resources, they are only as good as the data they analyze.
References-found: 17

