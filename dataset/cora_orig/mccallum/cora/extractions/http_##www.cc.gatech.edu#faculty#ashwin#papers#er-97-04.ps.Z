URL: http://www.cc.gatech.edu/faculty/ashwin/papers/er-97-04.ps.Z
Refering-URL: http://www.cs.gatech.edu/faculty/ashwin/ABSTRACTS-summary.html
Root-URL: 
Title: Case-Based Planning to Learn  
Author: J. William Murdock, Gordon Shippey, and Ashwin Ram 
Address: Atlanta, GA 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: Learning can be viewed as a problem of planning a series of modifications to memory. We adopt this view of learning and propose the applicability of the case-based planning methodology to the task of planning to learn. We argue that relatively simple, fine-grained primitive inferential operators are needed to support flexible planning. We show that it is possible to obtain the benefits of case-based reasoning within a planning to learn framework.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> M. Cox, </author> <title> Introspective Multistrategy Learning: Constructing a Learning Strategy Under Reasoning Failure, </title> <type> Ph.D. Thesis, Technical Report GIT-CC-96/06, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: In this view, modifications to memory are treated as planning operations and learning is done by constructing a plan over these operations. The work that has been done in this area has largely focussed on search-based planning algorithms such as non-linear planning; examples of this sort of work include <ref> [1, 3, 10, 14] </ref>. Furthermore, past work in this area has generally made use of large, complex learning algorithms as the operators for the planning algorithm; for example, Meta-AQUA [1] has a library of strategies such as explanation-based generalization which it combines to form learning plans. <p> Furthermore, past work in this area has generally made use of large, complex learning algorithms as the operators for the planning algorithm; for example, Meta-AQUA <ref> [1] </ref> has a library of strategies such as explanation-based generalization which it combines to form learning plans. We argue, however, that a system capable of a truly broad and flexible range of learning needs to be able to construct its own learning algorithms from more basic components.
Reference: 2. <author> K. Hammond, </author> <title> Case-Based Planning: Viewing Planning as a Memory Task. </title> <publisher> Academic Press, </publisher> <year> 1989. </year>
Reference-contexts: Furthermore, because these primitive building blocks are so general, it may not be possible to completely identify whether an operator is guaranteed to produce a correct result. Case-based planning provides an potential solution to these problems. Traditional case-based planning programs such as <ref> [2] </ref> have focused on planning in domains of physical action rather than in mental domains. More recent work [4, 8, 9] which has addressed mental domains has focused largely on the specific issue of using a "meta-level" CBR process to develop new adaptation strategies on top of more traditional CBR. <p> the new goal being examined, with a match between postcon-ditions requiring that they involve the same relation and have at least one of the arguments to the relation be equivalent (i.e. either they are the same node or they are both variables); this is similar to the similarity metric in <ref> [2, 16] </ref>. Thus, for example, (positional anaconda ?x) would match (positional texas-holdem ?y) but not (shown anaconda ?x) or (positional ?x strong).
Reference: 3. <author> L. Hunter, </author> <title> Planning to learn. </title> <booktitle> Proc. Twelfth Annual Conference of the Cognitive Science Society, </booktitle> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1990. </year>
Reference-contexts: In this view, modifications to memory are treated as planning operations and learning is done by constructing a plan over these operations. The work that has been done in this area has largely focussed on search-based planning algorithms such as non-linear planning; examples of this sort of work include <ref> [1, 3, 10, 14] </ref>. Furthermore, past work in this area has generally made use of large, complex learning algorithms as the operators for the planning algorithm; for example, Meta-AQUA [1] has a library of strategies such as explanation-based generalization which it combines to form learning plans.
Reference: 4. <author> D. Leake, </author> <title> Combining Rules and Cases to Learn Case Adaptation. </title> <booktitle> Proc. of the Seventeenth Annual Conference of the Cognitive Science Society, </booktitle> <year> 1995. </year>
Reference-contexts: Case-based planning provides an potential solution to these problems. Traditional case-based planning programs such as [2] have focused on planning in domains of physical action rather than in mental domains. More recent work <ref> [4, 8, 9] </ref> which has addressed mental domains has focused largely on the specific issue of using a "meta-level" CBR process to develop new adaptation strategies on top of more traditional CBR. In contrast, we are interested in how case-based planning can be extended into the mental domain of learning.
Reference: 5. <author> R. Michalski, </author> <title> Inferential Theory of Learning as a Conceptual Basis for Multistrategy Learning. </title> <journal> Machine Learning, </journal> <volume> 11, </volume> <year> 1993. </year>
Reference-contexts: We argue, however, that a system capable of a truly broad and flexible range of learning needs to be able to construct its own learning algorithms from more basic components. One approach to such basic components can be found in <ref> [5] </ref> which describes a taxonomy of knowledge transmutations which can be thought of as basic operations over knowledge elements. An example of one of these transmutations is generalize.
Reference: 6. <author> R. Michalski and A. Ram, </author> <title> Learning as goal-driven inference. In Goal-Driven Learning, </title> <editor> A. Ram and D. Leake (eds.), </editor> <publisher> MIT Press / Bradford Books, </publisher> <year> 1995. </year>
Reference-contexts: Our implementation uses a set of operations which is roughly (but not exactly) a subset of those defined by Michalski; see <ref> [6] </ref> for further discussion of knowledge planning using transmutation operators. In this paper we are concerned with the algorithms that are used to plan using such operators. Search-based methods for planning are powerful and broadly applicable.
Reference: 7. <author> T. Mitchell, R. Keller, S. Kedar-Cabelli, </author> <title> Explanation-Based Generalization: A Unifying View. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <year> 1986. </year>
Reference-contexts: If the player in this example had a deep understanding of what aspects of the rules of these two games affect whether the game is strongly positional then this player might be able to form generalizations for what constitutes a strongly positional poker game using a method such as EBG <ref> [7] </ref>. Similarly, if the player had a sufficiently large and diverse set of games for which this feature was known, then it would be possible to induce a decision tree mapping observable feature sets to the two positional classifications using a technique such as ID3 [11].
Reference: 8. <author> R. Oehlmann, </author> <title> Metacognitive adaptation: Regulating the plan transformation process. </title> <booktitle> In Proceedings of the AAAI-95 Fall Symposium on Adapation of Knowledge for Reuse, </booktitle> <editor> D. Aha and A. Ram (eds.), pp. </editor> <address> 73 - 79, San Mateo, CA: AAAI-Press. </address>
Reference-contexts: Case-based planning provides an potential solution to these problems. Traditional case-based planning programs such as [2] have focused on planning in domains of physical action rather than in mental domains. More recent work <ref> [4, 8, 9] </ref> which has addressed mental domains has focused largely on the specific issue of using a "meta-level" CBR process to develop new adaptation strategies on top of more traditional CBR. In contrast, we are interested in how case-based planning can be extended into the mental domain of learning.
Reference: 9. <author> R. Oehlmann, D. Sleeman, and P. Edwards, </author> <title> Learning plan transformations from self-questions: A memory-based approach. </title> <booktitle> In Proceedings of the 11th National Conference on Artificial Intelligence, </booktitle> <pages> pp. 520-525, </pages> <address> Cambridge, MA: AAAI-Press, </address> <year> 1993. </year>
Reference-contexts: Case-based planning provides an potential solution to these problems. Traditional case-based planning programs such as [2] have focused on planning in domains of physical action rather than in mental domains. More recent work <ref> [4, 8, 9] </ref> which has addressed mental domains has focused largely on the specific issue of using a "meta-level" CBR process to develop new adaptation strategies on top of more traditional CBR. In contrast, we are interested in how case-based planning can be extended into the mental domain of learning.
Reference: 10. <author> A. Quilici, </author> <title> Toward automatic acquisition of an advisory system's knowledge base. </title> <journal> Applied Intelligence, </journal> <note> In Press. </note>
Reference-contexts: In this view, modifications to memory are treated as planning operations and learning is done by constructing a plan over these operations. The work that has been done in this area has largely focussed on search-based planning algorithms such as non-linear planning; examples of this sort of work include <ref> [1, 3, 10, 14] </ref>. Furthermore, past work in this area has generally made use of large, complex learning algorithms as the operators for the planning algorithm; for example, Meta-AQUA [1] has a library of strategies such as explanation-based generalization which it combines to form learning plans.
Reference: 11. <author> J. Quinlan, </author> <title> Induction of Decision Trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <year> 1986. </year>
Reference-contexts: Similarly, if the player had a sufficiently large and diverse set of games for which this feature was known, then it would be possible to induce a decision tree mapping observable feature sets to the two positional classifications using a technique such as ID3 <ref> [11] </ref>. Lastly, a true expert at poker would probably already have in memory a precise normative characterization of what constitutes a strongly positional game and thus would be able to directly infer this feature from a description of the rules.
Reference: 12. <author> A. Ram and L. Hunter, </author> <title> The Use of Explicit Goals for Knowledge to Guide Inference and Learning. </title> <journal> Applied Intelligence, </journal> <volume> 2(1), </volume> <year> 1992. </year>
Reference-contexts: 1 Problem A recent view of learning is one in which learning is modeled as an active, deliberative, goal-driven process involving the explicit identification and pursuit of learning goals <ref> [12, 13] </ref>. In this view, modifications to memory are treated as planning operations and learning is done by constructing a plan over these operations.
Reference: 13. <author> A. Ram and D. Leake, </author> <title> Learning, Goals, and Learning Goals. In Goal-Driven Learning, </title> <editor> A. Ram and D. Leake (eds.), </editor> <publisher> MIT Press / Bradford Books, </publisher> <year> 1995. </year>
Reference-contexts: 1 Problem A recent view of learning is one in which learning is modeled as an active, deliberative, goal-driven process involving the explicit identification and pursuit of learning goals <ref> [12, 13] </ref>. In this view, modifications to memory are treated as planning operations and learning is done by constructing a plan over these operations.
Reference: 14. <institution> Learning by Observing and Understanding Expert Problem Solving, </institution> <type> Ph.D. Thesis, Technical Report GIT-CC-92/43, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: In this view, modifications to memory are treated as planning operations and learning is done by constructing a plan over these operations. The work that has been done in this area has largely focussed on search-based planning algorithms such as non-linear planning; examples of this sort of work include <ref> [1, 3, 10, 14] </ref>. Furthermore, past work in this area has generally made use of large, complex learning algorithms as the operators for the planning algorithm; for example, Meta-AQUA [1] has a library of strategies such as explanation-based generalization which it combines to form learning plans.
Reference: 15. <author> J. Scarne, </author> <title> Scarne's Guide to Modern Poker, </title> <publisher> Simon & Schuster, </publisher> <year> 1984. </year>
Reference-contexts: The rationale behind this analysis and the specific details of the different games are not particularly important; all of the information which our system has about these games is illustrated in figure 1. For a relatively complete treatment of poker in general, see <ref> [15] </ref>. 2 By strongly positional, we mean that the relative value of a hand is strongly affected by the position which the individual holding the hand is seated with respect to the dealer because of the additional knowledge that players have by seeing what other players have already bet before deciding
Reference: 16. <editor> Case-Based Reasoning in PRODIGY. </editor> <title> In Machine Learning: A Multistrategy Approach Volume IV, </title> <editor> R. Michalski and G. Tecuci (eds.), </editor> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <year> 1994. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: the new goal being examined, with a match between postcon-ditions requiring that they involve the same relation and have at least one of the arguments to the relation be equivalent (i.e. either they are the same node or they are both variables); this is similar to the similarity metric in <ref> [2, 16] </ref>. Thus, for example, (positional anaconda ?x) would match (positional texas-holdem ?y) but not (shown anaconda ?x) or (positional ?x strong).
References-found: 16

