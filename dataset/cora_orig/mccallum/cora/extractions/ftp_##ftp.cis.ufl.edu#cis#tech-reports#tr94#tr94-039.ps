URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr94/tr94-039.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr94-abstracts.html
Root-URL: http://www.cis.ufl.edu
Title: AN APPROXIMATE MINIMUM DEGREE ORDERING ALGORITHM  
Author: TIMOTHY A. DAVIS PATRICK AMESTOY AND IAIN S. DUFF 
Keyword: approximate minimum degree ordering algorithm, quotient graph, sparse matrices, graph algorithms, ordering algorithms  
Note: AMS classifications: 65F50, 65F05.  
Abstract: Computer and Information Sciences Dept., University of Florida, Technical Report TR-94-039, December, 1994 (revised July 1995). Abstract. An Approximate Minimum Degree ordering algorithm (AMD) for preordering a symmetric sparse matrix prior to numerical factorization is presented. We use techniques based on the quotient graph for matrix factorization that allow us to obtain computationally cheap bounds for the minimum degree. We show that these bounds are often equal to the actual degree. The resulting algorithm is typically much faster than previous minimum degree ordering algorithms, and produces results that are comparable in quality with the best orderings from other minimum degree algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> APPROXIMATE MINIMUM DEGREE 19 </institution>
Reference: [1] <author> P. R. Amestoy, </author> <title> Factorization of large sparse matrices based on a multifrontal approach in a multiprocessor environment, </title> <type> INPT PhD Thesis TH/PA/91/2, </type> <institution> CERFACS, Toulouse, France, </institution> <year> 1991. </year>
Reference-contexts: However, if the matrix A is positive-definite [21], a Cholesky factorization can safely be used. This technique of preceding the numerical factorization with a symbolic analysis can also be extended to unsymmetric systems although the numerical factorization phase must allow for subsequent numerical pivoting <ref> [1, 2, 16] </ref>. The goal of the preordering is to find a permutation matrix P so that the subsequent factorization has the least fill-in. Unfortunately, this problem is NP-complete [31], so heuristics are used. <p> We then formed the symmetric pattern of the permuted matrix plus its transpose. This is how a minimum degree ordering algorithm is used in MUPS <ref> [1, 2] </ref>. For these matrices, Table 6.1 lists the statistics for the symmetrized pattern. Table 6.1 lists the matrix name, the order, the number of nonzeros in lower triangular part, two statistics obtained with an exact minimum degree ordering (using d), and a description.
Reference: [2] <author> P. R. Amestoy, M. Dayd e, and I. S. Duff, </author> <title> Use of level 3 BLAS in the solution of full and sparse linear equations, in High Performance Computing: </title> <booktitle> Proceedings of the International Symposium on High Performance Computing, </booktitle> <address> Montpellier, France, 22-24 March, </address> <year> 1989, </year> <editor> J.-L. Delhaye and E. Gelenbe, eds., </editor> <address> Amsterdam, 1989, </address> <publisher> North Holland, </publisher> <pages> pp. 19-31. </pages>
Reference-contexts: However, if the matrix A is positive-definite [21], a Cholesky factorization can safely be used. This technique of preceding the numerical factorization with a symbolic analysis can also be extended to unsymmetric systems although the numerical factorization phase must allow for subsequent numerical pivoting <ref> [1, 2, 16] </ref>. The goal of the preordering is to find a permutation matrix P so that the subsequent factorization has the least fill-in. Unfortunately, this problem is NP-complete [31], so heuristics are used. <p> We then formed the symmetric pattern of the permuted matrix plus its transpose. This is how a minimum degree ordering algorithm is used in MUPS <ref> [1, 2] </ref>. For these matrices, Table 6.1 lists the statistics for the symmetrized pattern. Table 6.1 lists the matrix name, the order, the number of nonzeros in lower triangular part, two statistics obtained with an exact minimum degree ordering (using d), and a description.
Reference: [3] <author> C. Ashcraft, </author> <title> Compressed graphs and the minimum degree algorithm, </title> <journal> SIAM Journal on Scientific Computing, </journal> <note> (1995, to appear). </note>
Reference-contexts: A minimum degree algorithm based on the quotient graph is shown in Algorithm 1. It includes element absorption, mass elimination, supervariables, and external degrees. Super-variable detection is simplified by computing a hash function on each variable, so that not all pairs of variables need be compared <ref> [3] </ref>. Algorithm 1 does not include two 8 P. AMESTOY, T. A. DAVIS, , AND I. S. DUFF important features of Liu's Multiple Minimum Degree algorithm (MMD): incomplete update [17, 18] and multiple elimination [25]. <p> AMESTOY, T. A. DAVIS, , AND I. S. DUFF takes time that is proportional to the size of the workspace (normally fi (jAj)). In practice, elbow room of size n is sufficient. During the computation of our degree bounds, we compute the following hash function for supervariable detection <ref> [3] </ref>, Hash (i) = 8 : @ j2A i X e A mod (n 1) = + 1; which increases the degree computation time by a small constant factor. We place each supervariable i in a hash bucket according to Hash (i), taking time O (jLj) overall. <p> If two or more supervariables are placed in the same hash bucket, then each pair of supervariables i and j in the hash bucket are tested for indistinguishability. If the hash function results in no collisions then the total time taken by the comparison is O (jAj). Ashcraft <ref> [3] </ref> uses this hash function as a preprocessing step on the entire matrix (without the mod (n 1) term, and with an O (jV j log jV j) sort instead of jV j hash buckets). <p> Neither AMD nor MA27 take advantage of multiple elimination or incomplete update. Structural engineering matrices tend to have many rows of identical nonzero pat tern. Ashcraft has found that the total ordering time of MMD can be significantly improved by detecting these initial supervariables before starting the elimination <ref> [3] </ref>. We implemented Ashcraft's pre-compression algorithm, and modified MMD to allow for initial supervariables. We call the resulting code CMMD ("compressed" MMD). Pre-compression has little effect on AMD, since it finds these supervariables when their degrees are first updated.
Reference: [4] <author> C. Ashcraft and S. C. Eisenstat. </author> <type> personal communication. </type>
Reference-contexts: In our notation, their bound b d i is b d i = jA i n ij + e2E i 10 P. AMESTOY, T. A. DAVIS, , AND I. S. DUFF Since many pivotal variables are adjacent to two or fewer elements when selected, Ashcraft and Eisenstat <ref> [4] </ref> have suggested a combination of b d and d, e d = d if jE i j = 2 b d otherwise : Computing e d takes the same time as d or b d, except when jE i j = 2.
Reference: [5] <author> A. Berger, J. Mulvey, E. Rothberg, and R. Vanderbei, </author> <title> Solving multistage stochachas-tic programs using tree dissection, </title> <type> Tech. Report SOR-97-07, </type> <institution> Program in Statistics and Operations Research, Princeton University, Princeton, </institution> <address> New Jersey, </address> <year> 1995. </year>
Reference-contexts: The approximate degree bound d thus gives a very reliable estimation of the degree in the context of a minimum degree algorithm. The FINAN512 matrix is highly sensitive to tie-breaking variations. Its graph consists of two types of nodes: "constraint" nodes and "linking" nodes <ref> [5] </ref>. The constraint nodes form independent sparse subgraphs, connected together via a tree of linking nodes. <p> All constraint nodes should be ordered first, but linking nodes have low degree and tend to be selected first, which causes high fill-in. Using a tree dissection algorithm, Berger, Mulvey, Rothberg, and Vanderbei <ref> [5] </ref> obtain an ordering with only 1.83 million nonzeros in L. Table 6.3 lists the median ordering time (in seconds on a SUN SPARCstation 10) for each method. Ordering time twice that of the minimum median ordering time listed in the table (or higher) is underlined.
Reference: [6] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusets, </address> <publisher> and McGraw-Hill, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: If Algorithm 2 does not scan element e, the term w (e) is less than zero. Combining these two cases, we obtain jL e n L p j = w (e) if w (e) 0 jL e j otherwise 1 Asymptotic complexity notation is defined in <ref> [6] </ref>. We write f (n) = fi (g (n)) if there exist positive constants c 1 , c 2 , and n 0 such that 0 c 1 g (n) f (n) c 2 g (n) for all n &gt; n 0 .
Reference: [7] <author> T. A. Davis and I. S. Duff, </author> <title> Unsymmetric-pattern multifrontal methods for parallel sparse LU factorization, </title> <type> Tech. Report TR-91-023, </type> <institution> CIS Dept., Univ. of Florida, </institution> <address> Gainesville, FL, </address> <year> 1991. </year> <title> [8] , An unsymmetric-pattern multifrontal method for sparse LU factorization, </title> <type> Tech. Report TR-94-038, </type> <institution> CIS Dept., Univ. of Florida, </institution> <address> Gainesville, FL, </address> <year> 1994. </year> <note> (submitted to the SIAM Journal on Matrix Analysis and Applications in March 1993, revised). </note>
Reference-contexts: More recently, several researchers have relaxed this heuristic by computing upper bounds on the degrees, rather than the exact degrees, and selecting a node of minimum upper bound on the degree. This work includes that of Gilbert, Moler, and Schreiber [24], and Davis and Duff <ref> [7, 8] </ref>. Davis and Duff use degree bounds in the unsymmetric-pattern multifrontal method (UMFPACK), an unsymmetric Markowitz-style algorithm. In this paper, we describe an approximate minimum degree ordering algorithm based on the symmetric analogue of the degree bounds used in UMFPACK. <p> We assume that p is the kth pivot, and that we compute the bounds only for supervariables i 2 L p . Rather than computing the exact external degree, d i , our Approximate Minimum Degree algorithm (AMD) computes an upper bound <ref> [7, 8] </ref>, d i = min &gt; &gt; &lt; n k; k1 jA i n ij + jL p n ij + e2E i nfpg jL e n L p j &gt; &gt; = :(4.1) The first two terms (n k, the size of the active submatrix, and d k1 the
Reference: [9] <author> I. S. Duff, </author> <title> On algorithms for obtaining a maximum transversal, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 7 (1981), </volume> <pages> pp. 315-330. </pages>
Reference-contexts: The latter two are best-case and worst-case examples from the set of smaller matrices. For the unsymmetric matrices in the test set, we first used the maximum transver sal algorithm MC21 from the Harwell Subroutine Library <ref> [9] </ref> to reorder the matrix so that the permuted matrix has a zero-free diagonal. We then formed the symmetric pattern of the permuted matrix plus its transpose. This is how a minimum degree ordering algorithm is used in MUPS [1, 2].
Reference: [10] <author> I. S. Duff, A. M. Erisman, and J. K. Reid, </author> <title> Direct Methods for Sparse Matrices, </title> <publisher> London: Oxford Univ. Press, </publisher> <year> 1986. </year>
Reference-contexts: AMESTOY, T. A. DAVIS, , AND I. S. DUFF of the algorithm). This work includes that of Duff and Reid <ref> [10, 13, 14, 15] </ref>; George and McIntyre [23]; Eisenstat, Gursky, Schultz, and Sherman [17, 18]; George and Liu [19, 20, 21, 22]; and Liu [25].
Reference: [11] <author> I. S. Duff, R. G. Grimes, and J. G. Lewis, </author> <title> Sparse matrix test problems, </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 15 (1989), </volume> <pages> pp. </pages> <month> 1-14. </month> <title> [12] , Users' guide for the Harwell-Boeing sparse matrix collection (Release 1), </title> <type> Tech. Report RAL-92-086, </type> <institution> Rutherford Appleton Laboratory, </institution> <address> Didcot, Oxon, England, </address> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: We then compare the AMD algorithm with other established minimum degree codes (MMD and MA27). 6.1. Test Matrices. We tested all degree bounds and codes on all matrices in the Harwell/Boeing collection of type PUA, RUA, PSA, and RSA <ref> [11, 12] </ref> (at orion.cerfacs.fr or numerical.cc.rl.ac.uk), all non-singular matrices in Saad's SPARSKIT2 collection (at ftp.cs.umn.edu), all matrices in the University of Florida collection (available from ftp.cis.ufl.edu in the directory pub/umfpack/matrices), APPROXIMATE MINIMUM DEGREE 13 Table 6.1 Selected matrices in test set Matrix n nz Percentage of Description jE p j &gt;
Reference: [13] <author> I. S. Duff and J. K. Reid, </author> <title> A comparison of sparsity orderings for obtaining a pivotal sequence in Gaussian elimination, </title> <journal> Journal of the Institute of Mathematics and its Applications, </journal> <volume> 14 (1974), </volume> <pages> pp. </pages> <month> 281-291. </month> <title> [14] , MA27 A set of Fortran subroutines for solving sparse symmetric sets of linear equations, </title> <type> Tech. </type> <institution> Report AERE R10533, </institution> <address> HMSO, London, </address> <year> 1982. </year> <title> [15] , The multifrontal solution of indefinite sparse symmetric linear equations, </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 9 (1983), </volume> <pages> pp. </pages> <month> 302-325. </month> <title> [16] , The multifrontal solution of unsymmetric sets of linear equations, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 5 (1984), </volume> <pages> pp. 633-641. </pages>
Reference-contexts: AMESTOY, T. A. DAVIS, , AND I. S. DUFF of the algorithm). This work includes that of Duff and Reid <ref> [10, 13, 14, 15] </ref>; George and McIntyre [23]; Eisenstat, Gursky, Schultz, and Sherman [17, 18]; George and Liu [19, 20, 21, 22]; and Liu [25]. <p> Quotient graphs. In contrast to the elimination graph, the quotient graph models the factorization of A using an amount of storage that never exceeds the storage for the original graph, G 0 [21]. The quotient graph is also referred to as the APPROXIMATE MINIMUM DEGREE 3 generalized element model <ref> [13, 14, 15, 29] </ref>. An important component of a quotient graph is a clique. It is a particularly economic structure since a clique is represented by a list of its members rather than by a list of all the edges in the clique. <p> If i is selected, then j can be selected next without causing any additional fill-in. Selecting i and j together is called mass elimination [23]. Variables i and j are replaced in G by a supervariable containing both i and j, labeled by its principal variable (i, say) <ref> [13, 14, 15] </ref>. Variables that are not supervariables are called simple variables. In practice, new supervariables are constructed at step k only if both i and j are in L p (where p is the pivot selected at step k). <p> The AMD algorithm is based on the quotient graph data structure used in the MA27 minimum degree algorithm <ref> [13, 14, 15] </ref>. Initially, the sets A are stored, followed by a small amount of elbow room. When the set L p is formed, it is placed in the elbow room (or in place of A p if jE p j = 0).
Reference: [17] <author> S. C. Eisenstat, M. C. Gursky, M. H. Schultz, and A. H. Sherman, </author> <title> Yale sparse matrix package, I: The symmetric codes, International Journal for Numerical Methods in Engineering, </title> <booktitle> 18 (1982), </booktitle> <pages> pp. 1145-1151. </pages>
Reference-contexts: AMESTOY, T. A. DAVIS, , AND I. S. DUFF of the algorithm). This work includes that of Duff and Reid [10, 13, 14, 15]; George and McIntyre [23]; Eisenstat, Gursky, Schultz, and Sherman <ref> [17, 18] </ref>; George and Liu [19, 20, 21, 22]; and Liu [25]. More recently, several researchers have relaxed this heuristic by computing upper bounds on the degrees, rather than the exact degrees, and selecting a node of minimum upper bound on the degree. <p> Algorithm 1 does not include two 8 P. AMESTOY, T. A. DAVIS, , AND I. S. DUFF important features of Liu's Multiple Minimum Degree algorithm (MMD): incomplete update <ref> [17, 18] </ref> and multiple elimination [25]. With multiple elimination, an independent set of pivots with minimum degree is selected before any degrees are updated. If a variable is adjacent to two or more pivot elements, its degree is computed only once. <p> Multiple elimination [25] improves the minimum degree algorithm by updating the degree of a variable only once for each set of independent pivots. Incomplete degree update <ref> [17, 18] </ref> skips the degree update of outmatched variables. We cannot take full advantage of the incomplete degree update since it avoids the degree update for some supervariables adjacent to the pivot element. <p> In this case, it takes O (jA i j + jL e j) time to compute e d, whereas computing d or b d takes fi (jA i j) time. In the Yale Sparse Matrix Package <ref> [17] </ref> the jL e n L p j term for the E i = fe; pg case is computed by scanning L e once. It is then used to compute d i for all i 2 L p for which E i = fe; pg.
Reference: [18] <author> S. C. Eisenstat, M. H. Schultz, and A. H. Sherman, </author> <title> Algorithms and data structures for sparse symmetric Gaussian elimination, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 2 (1981), </volume> <pages> pp. 225-237. </pages>
Reference-contexts: AMESTOY, T. A. DAVIS, , AND I. S. DUFF of the algorithm). This work includes that of Duff and Reid [10, 13, 14, 15]; George and McIntyre [23]; Eisenstat, Gursky, Schultz, and Sherman <ref> [17, 18] </ref>; George and Liu [19, 20, 21, 22]; and Liu [25]. More recently, several researchers have relaxed this heuristic by computing upper bounds on the degrees, rather than the exact degrees, and selecting a node of minimum upper bound on the degree. <p> Algorithm 1 does not include two 8 P. AMESTOY, T. A. DAVIS, , AND I. S. DUFF important features of Liu's Multiple Minimum Degree algorithm (MMD): incomplete update <ref> [17, 18] </ref> and multiple elimination [25]. With multiple elimination, an independent set of pivots with minimum degree is selected before any degrees are updated. If a variable is adjacent to two or more pivot elements, its degree is computed only once. <p> Multiple elimination [25] improves the minimum degree algorithm by updating the degree of a variable only once for each set of independent pivots. Incomplete degree update <ref> [17, 18] </ref> skips the degree update of outmatched variables. We cannot take full advantage of the incomplete degree update since it avoids the degree update for some supervariables adjacent to the pivot element.
Reference: [19] <author> A. George and J. W. H. Liu, </author> <title> A fast implementation of the minimum degree algorithm using quotient graphs, </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 6 (1980), </volume> <pages> pp. </pages> <month> 337-358. </month> <title> [20] , A minimal storage implementation of the minimum degree algorithm, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 17 (1980), </volume> <pages> pp. </pages> <month> 282-299. </month> <title> [21] , Computer Solution of Large Sparse Positive Definite Systems, </title> <address> Englewood Cliffs, New Jersey: </address> <publisher> Prentice-Hall, </publisher> <year> 1981. </year> <title> [22] , The evolution of the minimum degree ordering algorithm, </title> <journal> SIAM Review, </journal> <volume> 31 (1989), </volume> <pages> pp. 1-19. </pages>
Reference-contexts: AMESTOY, T. A. DAVIS, , AND I. S. DUFF of the algorithm). This work includes that of Duff and Reid [10, 13, 14, 15]; George and McIntyre [23]; Eisenstat, Gursky, Schultz, and Sherman [17, 18]; George and Liu <ref> [19, 20, 21, 22] </ref>; and Liu [25]. More recently, several researchers have relaxed this heuristic by computing upper bounds on the degrees, rather than the exact degrees, and selecting a node of minimum upper bound on the degree.
Reference: [23] <author> A. George and D. R. McIntyre, </author> <title> On the application of the minimum degree algorithm to finite element systems, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 15 (1978), </volume> <pages> pp. 90-111. </pages>
Reference-contexts: AMESTOY, T. A. DAVIS, , AND I. S. DUFF of the algorithm). This work includes that of Duff and Reid [10, 13, 14, 15]; George and McIntyre <ref> [23] </ref>; Eisenstat, Gursky, Schultz, and Sherman [17, 18]; George and Liu [19, 20, 21, 22]; and Liu [25]. More recently, several researchers have relaxed this heuristic by computing upper bounds on the degrees, rather than the exact degrees, and selecting a node of minimum upper bound on the degree. <p> They will have the same degree until one is selected as pivot. If i is selected, then j can be selected next without causing any additional fill-in. Selecting i and j together is called mass elimination <ref> [23] </ref>. Variables i and j are replaced in G by a supervariable containing both i and j, labeled by its principal variable (i, say) [13, 14, 15]. Variables that are not supervariables are called simple variables.
Reference: [24] <author> J. R. Gilbert, C. Moler, and R. Schreiber, </author> <title> Sparse matrices in MATLAB: design and implementation, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 13 (1992), </volume> <pages> pp. 333-356. </pages>
Reference-contexts: More recently, several researchers have relaxed this heuristic by computing upper bounds on the degrees, rather than the exact degrees, and selecting a node of minimum upper bound on the degree. This work includes that of Gilbert, Moler, and Schreiber <ref> [24] </ref>, and Davis and Duff [7, 8]. Davis and Duff use degree bounds in the unsymmetric-pattern multifrontal method (UMFPACK), an unsymmetric Markowitz-style algorithm. In this paper, we describe an approximate minimum degree ordering algorithm based on the symmetric analogue of the degree bounds used in UMFPACK. <p> Computing our bound takes time proportional to the degree of the variable in the quotient graph, G. This is much faster than the time taken to compute the exact external degree (see Equation (3.3)). 4.1. Accuracy of our approximate degrees. Gilbert, Moler, and Schreiber <ref> [24] </ref> also use approximate external degrees that they can compute in the same time as our degree bound d. In our notation, their bound b d i is b d i = jA i n ij + e2E i 10 P. AMESTOY, T. A. DAVIS, , AND I. S.
Reference: [25] <author> J. W. H. Liu, </author> <title> Modification of the minimum-degree algorithm by multiple elimination, </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 11 (1985), </volume> <pages> pp. 141-153. </pages>
Reference-contexts: AMESTOY, T. A. DAVIS, , AND I. S. DUFF of the algorithm). This work includes that of Duff and Reid [10, 13, 14, 15]; George and McIntyre [23]; Eisenstat, Gursky, Schultz, and Sherman [17, 18]; George and Liu [19, 20, 21, 22]; and Liu <ref> [25] </ref>. More recently, several researchers have relaxed this heuristic by computing upper bounds on the degrees, rather than the exact degrees, and selecting a node of minimum upper bound on the degree. This work includes that of Gilbert, Moler, and Schreiber [24], and Davis and Duff [7, 8]. <p> We refer to t i as the true degree of variable i. Selecting the pivot with minimum external degree tends to produce a better ordering than selecting the pivot with minimum true degree <ref> [25] </ref> (also see Section 6.2). <p> Algorithm 1 does not include two 8 P. AMESTOY, T. A. DAVIS, , AND I. S. DUFF important features of Liu's Multiple Minimum Degree algorithm (MMD): incomplete update [17, 18] and multiple elimination <ref> [25] </ref>. With multiple elimination, an independent set of pivots with minimum degree is selected before any degrees are updated. If a variable is adjacent to two or more pivot elements, its degree is computed only once. A variable j is outmatched if Adj G (i) Adj G (j). <p> The total time for Algorithm 2 is fi ( i2L p The second loop to compute the upper bound degrees takes time fi ( i2L p which is thus equal to the total asymptotic time. Multiple elimination <ref> [25] </ref> improves the minimum degree algorithm by updating the degree of a variable only once for each set of independent pivots. Incomplete degree update [17, 18] skips the degree update of outmatched variables. <p> At most two garbage collections occurred for AMD, and at most three for the other methods (aggressive absorption reduces the memory requirements). 6.3. Comparing algorithms. In this section, we compare AMD with two other established minimum degree codes: Liu's Multiple Minimum Degree (MMD) code <ref> [25] </ref> and Duff and Reid's MA27 code [15]. MMD stores the element patterns L in a fragmented manner and requires no elbow room [20, 21]. It uses the exact external degree, d. MMD creates supervariables only when two variables i and j have no 16 P. AMESTOY, T. A.
Reference: [26] <author> H. M. Markowitz, </author> <title> The elimination form of the inverse and its application to linear programming, </title> <booktitle> Management Science, 3 (1957), </booktitle> <pages> pp. 255-269. </pages>
Reference-contexts: Because of this, the algorithm has received much attention over the past three decades. The algorithm is a symmetric analogue of Markowitz' method <ref> [26] </ref> and was first proposed by Tinney and Walker [30] as algorithm S2. Rose [27, 28] developed a graph theoretical model of Tinney and Walker's algorithm and renamed it the minimum degree algorithm, since it performs its pivot selection by selecting from a graph a node of minimum degree.
Reference: [27] <author> D. J. Rose, </author> <title> Symmetric Elimination on Sparse Positive Definite Systems and the Potential Flow Network Problem, </title> <type> PhD thesis, </type> <institution> Applied Math., Harvard Univ., </institution> <year> 1970. </year> <note> 20 P. </note> <author> AMESTOY, T. A. DAVIS, , AND I. S. </author> <title> DUFF [28] , A graph-theoretic study of the numerical solution of sparse positive definite systems of linear equations, in Graph Theory and Computing, </title> <editor> R. C. Read, ed., </editor> <address> New York: </address> <publisher> Academic Press, </publisher> <year> 1973, </year> <pages> pp. 183-217. </pages>
Reference-contexts: Because of this, the algorithm has received much attention over the past three decades. The algorithm is a symmetric analogue of Markowitz' method [26] and was first proposed by Tinney and Walker [30] as algorithm S2. Rose <ref> [27, 28] </ref> developed a graph theoretical model of Tinney and Walker's algorithm and renamed it the minimum degree algorithm, since it performs its pivot selection by selecting from a graph a node of minimum degree.
Reference: [29] <author> B. Speelpenning, </author> <title> The generalized element method, </title> <type> Tech. Report Technical Report UIUCDCS-R-78-946, </type> <institution> Dept. of Computer Science, Univ. of Illinois, Urbana, IL, </institution> <year> 1978. </year>
Reference-contexts: Quotient graphs. In contrast to the elimination graph, the quotient graph models the factorization of A using an amount of storage that never exceeds the storage for the original graph, G 0 [21]. The quotient graph is also referred to as the APPROXIMATE MINIMUM DEGREE 3 generalized element model <ref> [13, 14, 15, 29] </ref>. An important component of a quotient graph is a clique. It is a particularly economic structure since a clique is represented by a list of its members rather than by a list of all the edges in the clique.
Reference: [30] <author> W. F. Tinney and J. W. Walker, </author> <title> Direct solutions of sparse network equations by optimally ordered triangular factorization, </title> <booktitle> Proc. of the IEEE, 55 (1967), </booktitle> <pages> pp. 1801-1809. </pages>
Reference-contexts: Because of this, the algorithm has received much attention over the past three decades. The algorithm is a symmetric analogue of Markowitz' method [26] and was first proposed by Tinney and Walker <ref> [30] </ref> as algorithm S2. Rose [27, 28] developed a graph theoretical model of Tinney and Walker's algorithm and renamed it the minimum degree algorithm, since it performs its pivot selection by selecting from a graph a node of minimum degree.
Reference: [31] <author> M. Yannakakis, </author> <title> Computing the minimum fill-in is NP-complete, </title> <journal> SIAM J. Algebraic and Discrete Methods, </journal> <volume> 2 (1981), </volume> <pages> pp. 77-79. </pages> <note> Note: all University of Florida technical reports in this list of references are available in postscript form via anonymous ftp to ftp.cis.ufl.edu in the directory cis/tech-reports. </note>
Reference-contexts: The goal of the preordering is to find a permutation matrix P so that the subsequent factorization has the least fill-in. Unfortunately, this problem is NP-complete <ref> [31] </ref>, so heuristics are used. The minimum degree ordering algorithm is one of the most widely used heuristics, since it produces factors with relatively low fill-in on a wide range of matrices. Because of this, the algorithm has received much attention over the past three decades. <p> The minimum degree algorithm is a non-optimal greedy heuristic for reducing the number of new edges (fill-ins) introduced during the factorization. We have already noted that the optimal solution is NP-complete <ref> [31] </ref>. By minimizing the degree, the algorithm minimizes the upper bound on the fill-in caused by the kth pivot. Selecting p as pivot creates at most (t 2 p t p )=2 new edges in G. 3. Quotient graphs.
References-found: 23

