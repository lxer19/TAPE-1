URL: http://http.icsi.berkeley.edu/ftp/global/pub/ai/jagota/vol1_3.ps.gz
Refering-URL: http://http.icsi.berkeley.edu/ftp/global/pub/ai/jagota/
Root-URL: http://http.icsi.berkeley.edu
Title: A Brief History of Connectionism  
Author: David A. Medler 
Address: Alberta, Canada, T6G 2E9  
Affiliation: Biological Computation Project Department of Psychology, University of Alberta  
Abstract: Connectionist research is firmly established within the scientific community, especially within the multi-disciplinary field of cognitive science. This diversity, however, has created an environment which makes it difficult for connectionist researchers to remain aware of recent advances in the field, let alone understand how the field has developed. This paper attempts to address this problem by providing a brief guide to connectionist research. The paper begins by defining the basic tenets of connectionism. Next, the development of connectionist research is traced, commencing with connectionism's philosophical predecessors, moving to early psychological and neuropsychological influences, followed by the mathematical and computing contributions to connectionist research. Current research is then reviewed, focusing specifically on the different types of network architectures and learning rules in use. The paper concludes by suggesting that neural network research|at least in cognitive science|should move towards models that incorporate the relevant functional principles inherent in neurobiological systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Aizawa. </author> <title> Connectionism and artificial intelligence: History and philosophical interpretation. </title> <journal> Journal of Experimental Artificial Intelligence, </journal> <volume> 4 </volume> <pages> 295-313, </pages> <year> 1992. </year>
Reference: [2] <editor> J. A. Anderson, A. Pellionisz, and E. Rosenfeld, editors. </editor> <publisher> Neurocomputing 2. MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Aristotle (ca. 400 B.C.) has been cited <ref> [2] </ref> as the first scientist to propose some of the basic concepts of connectionism; that is, memory is composed of simple elements linked or connected to each other via a number of different mechanisms (such as temporal succession, object similarity, and spatial proximity).
Reference: [3] <editor> J. A. Anderson and E. Rosenfeld, editors. Neurocomputing. </editor> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: Thus, the net input to unit i that is connected to j other units is net i = j w ij output j + extinput i (8) 8 The term `generic' was first coined by <ref> [3] </ref> to describe this type of network architecture and is maintained here for consistency. <p> Thus, networks using this form of activation function can solve linearly inseparable problems without any hidden units. These networks have been termed Integration Devices by Ballard [6], and generic PDP nets by Anderson and Rosenfeld <ref> [3] </ref>. logistic|divides a pattern space into two distinct regions The power of these simple units emerges when they are connected together to form a network, or multi-layer perceptron (MLP). <p> Much of the early work on recurrent networks was pioneered by John Hopfield [47]. In fact, some have argued that it was because of Hopfield's stature as a well-known physicist that neural network research was made respectable again <ref> [3] </ref>. Hence, certain configurations of recurrent networks are referred to as Hopfield nets. One problem that plagued earlier versions of Hopfield networks, though, was that the networks tended to settle into local minimum instead of the global minimum.
Reference: [4] <author> M. A. Arbib, </author> <title> editor. The Handbook of Brain Theory and Neural Networks. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference: [5] <author> B. Aune. Rationalism, Empiricism, and Pragmatism: </author> <title> An Introduction. Random House, </title> <address> New York, </address> <year> 1970. </year>
Reference: [6] <author> D. H. Ballard. </author> <title> Cortical connections and parallel processing: Structure and function. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 9 </volume> <pages> 67-120, </pages> <year> 1986. </year>
Reference-contexts: Thus, networks using this form of activation function can solve linearly inseparable problems without any hidden units. These networks have been termed Integration Devices by Ballard <ref> [6] </ref>, and generic PDP nets by Anderson and Rosenfeld [3]. logistic|divides a pattern space into two distinct regions The power of these simple units emerges when they are connected together to form a network, or multi-layer perceptron (MLP). <p> Evidence from single-unit recordings (that is, record the output of the neuron with respect to its input) suggests that there are at least two functionally different types of neurons in the brain in regards to their output encodings <ref> [6] </ref>. This can be illustrated by comparing the recordings from neurons that function as a basic part of the oculomotor system to neurons in the visual areas of the cortex. <p> The first type of neurons|for example, those in the servo system controlling eye movement|have linear outputs whose firing rate is proportional to a scalar parameter such as the rate of eye rotation. These neurons could be characterized as summation or integration devices <ref> [6] </ref> and have the equivalent activation function as the logistic used in artificial neurons. The outputs of such neurons have two features|larger values mean more frequent pulses, and the output is one dimensional. From a physiological perspective, these neurons use frequency encoding. <p> From a physiological perspective, neurons with this type of firing pattern use spatial or place encoding. In other words, neurons using a nonmonotonic activation function could be viewed as encoding values. Consequently, Ballard <ref> [6] </ref> terms these neurons value units. As "the value unit way of representing information seems to be a property of most cortical cells" [6], p. 68, the logical move|from a cognitive science perspective|would be to incorporate this type of activation function into a connectionist network. 4.8.1 The Value Unit Architecture In <p> In other words, neurons using a nonmonotonic activation function could be viewed as encoding values. Consequently, Ballard <ref> [6] </ref> terms these neurons value units. As "the value unit way of representing information seems to be a property of most cortical cells" [6], p. 68, the logical move|from a cognitive science perspective|would be to incorporate this type of activation function into a connectionist network. 4.8.1 The Value Unit Architecture In considering a nonmonotonic activation function for artificial neurons, the most likely choice would be the Gaussian.
Reference: [7] <author> W. Bechtel. </author> <title> Contemporary connectionism: Are the new parallel distributed processing models cognitive or associationist? Behaviorism, </title> <booktitle> 13 </booktitle> <pages> 53-61, </pages> <year> 1985. </year>
Reference-contexts: As pointed out by Thorndike [109], however, connectionism should not be confused for associationism. Rather, connectionism has borrowed concepts from associationism and has expanded them. For example, connectionism employs such concepts as distributed representations, hidden units, and supervised learning| concepts foreign to associationism [8]. In fact, Bechtel <ref> [7] </ref> points out that connectionism embodies a very distinctive characteristic that distinguishes cognitivism from behaviourism and associationism; specifically, connectionist modelers postulate that the connections between units provide structure in which mental activity occurs, and this structure is important for mediating future behaviour. <p> On the other Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 66 hand, connectionism does embrace one very important aspect of associationism often missing from classical cognitive models; connectionism focuses on learning as a natural activity of the system being modeled. Consequently, Bechtel <ref> [7] </ref> concludes that connectionism may provide "a basis to draw together aspects of the two traditions that have generally been viewed as incommensurable" (p. 60). 3.2 Psychological Manifestations With the emergence of psychology as a distinct field from philosophy, the ideas underlying connectionism became more refined and based on the known
Reference: [8] <author> W. Bechtel and A. Abrahamsen. </author> <title> Connectionism and the Mind: An Introduction to Parallel Processing in Networks. </title> <publisher> Blackwell, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: Furthermore, the history of connectionist research is often overlooked, or at least misconstrued [81]. As a result, a view popular with current researchers is that connectionism really emerged in the 1980's|there is only brief mention of research before that time (e.g., <ref> [8] </ref>, [48]). Connectionism, however, has a very long past. In fact, one can trace the origin of connectionist ideas to the early Greek philosopher, Aristotle, and his ideas on mental associations. These ideas were elaborated by the British empiricists and then naturally extended by the founders of psychology. <p> And, the learning rule and environment are part of the computational and representational functions of the neuron. Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 64 To be fair, though, PDP models are simply a subclass of connectionist models. Therefore, Bechtel and Abrahamsen <ref> [8] </ref> have reduced the above list to four properties that distinguish the different types of connectionist architectures. These four properties are: 1. The connectivity of units, 2. The activation function of units, 3. The nature of the learning procedure that modifies the connections between units, and 4. <p> Therefore, human cognition is governed by physical laws and can by studied empirically. Within the empiricist tradition, accounting for psychological processes is known as associationism. The basic concepts of associationism are <ref> [8] </ref>: 1. mental elements or ideas become associated with one another through experience, 2. experience consists of such things as spatial contiguity, temporal contiguity, similarity, and dissimilarity of ideas, 3. complex ideas can be reduced to a set of simple ideas, 4. simple ideas are sensations, and 5. simple additive rules <p> As pointed out by Thorndike [109], however, connectionism should not be confused for associationism. Rather, connectionism has borrowed concepts from associationism and has expanded them. For example, connectionism employs such concepts as distributed representations, hidden units, and supervised learning| concepts foreign to associationism <ref> [8] </ref>. In fact, Bechtel [7] points out that connectionism embodies a very distinctive characteristic that distinguishes cognitivism from behaviourism and associationism; specifically, connectionist modelers postulate that the connections between units provide structure in which mental activity occurs, and this structure is important for mediating future behaviour.
Reference: [9] <author> I. S. N. Berkeley, M. R. W. Dawson, D. A. Medler, D. P. Schopflocher, and L. Hornsby. </author> <title> Density plots of hidden value unit activations reveal interpretable bands. </title> <journal> Connection Science, </journal> <volume> 7 </volume> <pages> 167-186, </pages> <year> 1995. </year>
Reference-contexts: modifications allow a network trained with the backpropagation algorithm to use non-monotonic activation functions. 4.8.3 Value Unit Performance Value unit networks have been applied to a wide variety of pattern classification tasks, from "toy" problems [24] [25] [72], to diagnosing Alzheimer's patients from SPECT data [20], to identifying logical problems <ref> [9] </ref>, to classifying mushrooms [22]. One of the surprising aspects of the value unit architecture is that, from an engineering perspective, they have been shown to converge faster and more reliably on linearly inseparable problems than the more traditional MLPs that use monotonic activation functions.
Reference: [10] <author> T. G. Bever, J. A. Fodor, and M. Garrett. </author> <title> A formal limitation of associationism. </title> <editor> In T. R. Dixon and D. L. Horton, editors, </editor> <booktitle> Verbal Behavior and General Behavior Theory, </booktitle> <pages> pages 582-585. </pages> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1968. </year>
Reference-contexts: ideas are sensations, and 5. simple additive rules are sufficient to predict complex ideas composed from simple ideas Although many associationist concepts are evident in the behaviourist movement in psychology, the cog-nitivist movement within psychology has dismissed associationism as inadequate to account for cognitive phenomenon such as recursive grammars (e.g., <ref> [10] </ref>). Not surprisingly, with assumptions founded in associationist theories, connectionism has often been mistaken for associationism (e.g., [32], footnote 29), and subsequently dismissed as a viable theory of cognition. As pointed out by Thorndike [109], however, connectionism should not be confused for associationism.
Reference: [11] <author> A. M. Burton. </author> <title> Learning new faces in an interactive activation and competition model. </title> <editor> In V. Bruce and G. W. Humphreys, editors, </editor> <booktitle> Object and Face Recognition, </booktitle> <pages> pages 313-348. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1994. </year>
Reference-contexts: Thus, the network is an unsupervised learning algorithm based on self-organizing principles. A similar learning rule|although less encompassing|for IAC networks has been proposed and tested <ref> [11] </ref> to train a face recognition network. Therefore, with these modifications, the IAC architecture could be said to bridge the gap between Old and New Connectionism.
Reference: [12] <author> G. A. Carpenter and S. Grossberg. </author> <title> Adaptive Resonance Theory (ART). </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 79-82. </pages>
Reference-contexts: ART was initially introduced by Grossberg [40] as a theory of human information processing: it has since evolved into a series of real-time neural network models that perform supervised and unsupervised category learning, pattern classification, and prediction <ref> [12] </ref>. The simplest ART network is a vector classifier|it accepts as input a vector and classifies it into a category depending on the stored pattern it most closely resembles. Once a pattern is found, it is modified (trained) to resemble the input vector. <p> ARTMAP combines two ART modules to perform supervised learning while fuzzy ARTMAP represents a synthesis of elements from neural networks, expert systems, and fuzzy logic <ref> [12] </ref>. Other systems have been developed to suit individual researcher's needs; for example, Hussain and Browse [54] developed ARTSTAR which uses a layer of INSTAR nodes to supervise and integrate multiple ART2 modules.
Reference: [13] <author> A. Cleermans, D. Servan-Schreiber, and J. L. McClelland. </author> <title> Finite state automata and simple recurrent networks. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 372-381, </pages> <year> 1989. </year>
Reference-contexts: To combat this problem, one can change the weights statistically instead of deterministically. This technique is known as simulated annealing, and networks trained using this method are known as Boltzmann machines [46]. It has been shown that recurrent networks can simulate finite state automata <ref> [13] </ref> and that one can construct a second-order recurrent network such that internal deterministic finite-state automata state representations remain stable [79]. Furthermore, it has been proven that finite size recurrent networks can simulate any multi-stack Turing Machine in real time and non-deterministic rational nets can simulate nondeterministic Turing Machines [101].
Reference: [14] <author> M. A. Cohen and S. Grossberg. </author> <title> Absolute stability of global pattern formation and parallel memory storage by competitive neural networks. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 13 </volume> <pages> 815-826, </pages> <year> 1983. </year>
Reference-contexts: That is, the network's response can be stable (successive iterations produce smaller and smaller output changes until the outputs become constant) or unstable (the network's outputs never cease changing). This stability issue proved a problem for early researchers, but Cohen and Grossberg <ref> [14] </ref> devised a theorem showing that at least a subset of recurrent networks were guaranteed to produce outputs with stable states.
Reference: [15] <author> A. Collins and E. E. Smith. </author> <booktitle> Readings in Cognitive Science: A Perspective from Psychology and Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: specialist in his own field but each possessing a thoroughly sound and trained acquaintance with the fields of his neighbors : : : ([120]; p. 9) Today, cognitive science can be defined as the interdisciplinary study of mind; It draws upon such diverse fields as Computing Science and Artificial Intelligence <ref> [15] </ref>, Linguistics [80], Neuroscience [85], Philosophy [59], and Psychology [36], to name but a few. Although each discipline has its own unique interpretation Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 63 of cognitive science, they are bound into a cohesive whole by a central tenet.
Reference: [16] <author> G. Cybenko. </author> <title> Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals, </title> <journal> and Systems, </journal> <volume> 2 </volume> <pages> 303-314, </pages> <year> 1989. </year>
Reference-contexts: Such networks have often been hailed as providing a simple universal learning mechanism for cognition (but see [34]). Moreover, the learning algorithms embodied within new connectionist models have created very powerful information processors|they are both universal function approximators <ref> [16] </ref> and arbitrary pattern classifiers [63]. As stated earlier, we are living in the aftermath of the neural network revolution. As a consequence, the number of different connectionist architectures available to researchers today is immense; to discuss them all is beyond the scope of this paper.
Reference: [17] <author> J. Davidoff. </author> <title> Color perception. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 210-215. </pages>
Reference-contexts: Such an activation function is readily apparent not only within the cones of the eye <ref> [17] </ref>, but also within the tuned neurons in the visual cortex [50].
Reference: [18] <author> M. R. W. Dawson. </author> <title> The how and why of what went where in apparent motion: Modeling solutions to the motion correspondence problem. </title> <journal> Psychological Review, </journal> <volume> 98 </volume> <pages> 569-603, </pages> <year> 1991. </year>
Reference-contexts: The weights represent the strength of connection (either excitatory or inhibitory) between two units. These three tenets allow a large spectrum of models (e.g., Selfridge's Pandemonium [100]; Rumelhart & McClelland's Past-Tense Acquisition Model [95]; Dawson's Motion Correspondence Model <ref> [18] </ref>) to fall within the classification of connectionist research. To understand how these different models fit into connectionist research today, one needs to be aware of how connectionist research has developed. The best way of accomplishing this is to start at the beginning.
Reference: [19] <author> M. R. W. Dawson. </author> <booktitle> Understanding Cognitive Science. </booktitle> <publisher> Blackwell, Oxford, </publisher> <year> 1998. </year> <booktitle> Neural Computing Surveys 1, </booktitle> <pages> 61-101, </pages> <year> 1998, </year> <note> http://www.icsi.berkeley.edu/~jagota/NCS 97 </note>
Reference: [20] <author> M. R. W. Dawson, A. Dobbs, H. R. Hooper, A. J. B. McEwan, J. Triscott, and J. Cooney. </author> <title> Artificial neural networks that use SPECT to identify patients with probable Alzheimers disease. </title> <journal> European Journal of Nuclear Medicine, </journal> <volume> 21 </volume> <pages> 1303-1311, </pages> <year> 1994. </year>
Reference-contexts: As noted earlier, connectionism is used in many different fields of science. For example, connectionist networks have been used for aiding astronomical work [106], assisting medical diagnosis <ref> [20] </ref>, regulating investment management [121], and controlling robotic limb movement [113]. Many of these systems, however, are approached from an engineering perspective; that is, the designers are only interested in making the networks as efficient as possible (in terms of network topology, correct responses, and generalization). <p> These modifications allow a network trained with the backpropagation algorithm to use non-monotonic activation functions. 4.8.3 Value Unit Performance Value unit networks have been applied to a wide variety of pattern classification tasks, from "toy" problems [24] [25] [72], to diagnosing Alzheimer's patients from SPECT data <ref> [20] </ref>, to identifying logical problems [9], to classifying mushrooms [22]. One of the surprising aspects of the value unit architecture is that, from an engineering perspective, they have been shown to converge faster and more reliably on linearly inseparable problems than the more traditional MLPs that use monotonic activation functions.
Reference: [21] <author> M. R. W. Dawson, S. C. Kremer, and T. N. Gannon. </author> <title> Identifying the trigger features for hidden units in a pdp model of the early visual pathway. </title> <booktitle> In Elio [28], </booktitle> <pages> pages 115-120. </pages>
Reference-contexts: That is, these "neuromorphic" networks should transcend the simplified components, layered architectures, and limited scale of the first and second generation networks. Results [24][72] <ref> [21] </ref> have shown that such principles can be successfully applied to network architectures and learning rules. Furthermore, these neuromorphic networks often result in unanticipated improvements in performance and interpretability [9][23] over standard networks. Thus, we may have lots to learn by returning to the "neural" roots of connectionism.
Reference: [22] <author> M. R. W. Dawson and D. A. Medler. </author> <title> Of mushrooms and machine learning: Identifying algorithms in a PDP network. </title> <journal> Canadian Artificial Intelligence, </journal> <volume> 38 </volume> <pages> 14-17, </pages> <year> 1996. </year>
Reference-contexts: trained with the backpropagation algorithm to use non-monotonic activation functions. 4.8.3 Value Unit Performance Value unit networks have been applied to a wide variety of pattern classification tasks, from "toy" problems [24] [25] [72], to diagnosing Alzheimer's patients from SPECT data [20], to identifying logical problems [9], to classifying mushrooms <ref> [22] </ref>. One of the surprising aspects of the value unit architecture is that, from an engineering perspective, they have been shown to converge faster and more reliably on linearly inseparable problems than the more traditional MLPs that use monotonic activation functions.
Reference: [23] <author> M. R. W. Dawson, D. A. Medler, and I. S. N. </author> <title> Berkeley. PDP networks can provide symbolic models that are not mere implementations of classical theories. </title> <journal> Philosophical Psychology, </journal> <volume> 10 </volume> <pages> 25-40, </pages> <year> 1997. </year>
Reference: [24] <author> M. R. W. Dawson and D. P. Schopflocher. </author> <title> Modifying the generalized delta rule to train networks of non-monotonic processors for pattern classification. </title> <journal> Connection Science, </journal> <volume> 4 </volume> <pages> 19-31, </pages> <year> 1992. </year>
Reference-contexts: Thus, a fully connected recurrent network is potentially a very powerful architecture for temporal processing; however, more efficient heuristics and algorithms for reliable learning are required. The third architecture to be discussed specifically is a variation on the generic PDP architecture developed by Dawson and Schopflocher <ref> [24] </ref>. These value unit networks use the same basic learning algorithm as the generic PDP architecture, but use a non-monotonic activation function|the Gaussian|in their processing units. This new activation function has been shown to have certain theoretical and practical advantages over standard backpropagation networks. <p> Adding recurrent connections to the generic PDP architecture is but one way of improving the performance of such networks. Another way is to use different activation functions within the processing units. Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 91 Such an approach was taken by Dawson and Schopflocher <ref> [24] </ref> when developing the value unit architecture. 4.8 Value Unit Networks Despite their immense theoretical power as universal function approximators and arbitrary pattern classifiers, networks trained with the GDR suffer from severe practical training problems. Networks are prone to local minima and notoriously slow if they do find a solution. <p> For example, value units actually require hidden units to solve linearly separable problems [71]. Furthermore, because the value unit uses a nonmonotonic activation function, it is not uniquely invertible, and therefore it has been suggested that theoretically, value units are not suitable for function approximation <ref> [24] </ref>. On the other hand, the RBF unit which also uses a nonmonotonic activation function is routinely used for function approximation [75][64]. As will be shown, however, the basis underlying the RBF network is different than the value unit. 17 . <p> These modifications allow a network trained with the backpropagation algorithm to use non-monotonic activation functions. 4.8.3 Value Unit Performance Value unit networks have been applied to a wide variety of pattern classification tasks, from "toy" problems <ref> [24] </ref> [25] [72], to diagnosing Alzheimer's patients from SPECT data [20], to identifying logical problems [9], to classifying mushrooms [22].
Reference: [25] <author> M. R. W. Dawson, D. P. Schopflocher, J. Kidd, and K. S. Shamanski. </author> <title> Training networks of value units. </title> <booktitle> In Proceedings of the Ninth Canadian Artificial Intelligence Conference, </booktitle> <pages> pages 244-250, </pages> <year> 1992. </year>
Reference-contexts: These modifications allow a network trained with the backpropagation algorithm to use non-monotonic activation functions. 4.8.3 Value Unit Performance Value unit networks have been applied to a wide variety of pattern classification tasks, from "toy" problems [24] <ref> [25] </ref> [72], to diagnosing Alzheimer's patients from SPECT data [20], to identifying logical problems [9], to classifying mushrooms [22].
Reference: [26] <author> K. Doya. </author> <title> Recurrent networks: Supervised learning. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 796-800. </pages>
Reference-contexts: One criticism leveled against the generic PDP architecture, however, is that is only capable of a static mapping of the input vectors. The brain, on the other hand, is not stateless but rather a high-dimensional nonlinear dynamical system <ref> [26] </ref>. Consequently, the recurrent network architecture pioneered by John Hop-field [47] will be briefly discussed. The basic characteristic of recurrent networks is that some processing activation (usually the output) at time t is re-used (usually as an input) at time t+1.
Reference: [27] <author> Y. Dudai. </author> <title> The Neurobiology of Memory. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1989. </year>
Reference-contexts: What, then, are the functional properties of the brain that are required for information processing? Connectionists adopt the view that the basic building block of the brain is the neuron. The neuron has six basic functional properties <ref> [27] </ref>. It is an input device receiving signals from the environment or other neurons. It is an integrative device integrating and manipulating the input. It is a conductive device conducting the integrated information over distances. It is an output device sending information to other neurons or cells. <p> Although the neurophysiology in Hebb's day was inadequate to support or deny Hebb's postulate, recent research has shown that Long-Term Potentiation (LTP) has those putative mechanisms required of Hebbian learning (e.g., <ref> [27] </ref>). Within connectionism, Hebbian learning is an unsupervised training algorithm in which the synaptic strength (weight) is increased if both the source neuron and target neuron are active at the same time. <p> Finally, a decay process should be added to the learning mechanism to account for the "use it or lose it" property evident in real neural circuits (e.g., <ref> [27] </ref>).
Reference: [28] <editor> R. Elio, editor. </editor> <booktitle> Proceedings of the Tenth Canadian Conference on Artificial Intelligence, </booktitle> <address> San Mateo, CA, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [29] <author> M. J. Farah. </author> <title> Neuropsychological inference with an interactive brain: A critique of the "locality" assumption. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 17 </volume> <pages> 43-104, </pages> <year> 1994. </year>
Reference: [30] <author> J. A. Feldman and D. H. Ballard. </author> <title> Connectionist models and their properties. </title> <journal> Connection Science, </journal> <volume> 6 </volume> <pages> 205-254, </pages> <year> 1982. </year>
Reference-contexts: It should be noted that 10 For example, Wasserman [114] argues that since input units do not compute any function, they should not be counted as a layer; therefore, he calls these two-layer networks. 11 The 100-step constraint is based on the processing speed of neurons <ref> [30] </ref>. Most complex behaviours occur in a few hundred milliseconds|this means entire behaviours are executed in less than a hundred time steps as opposed to the millions of time steps required by classical models.
Reference: [31] <author> D. Feldman-Stewart and D. J. K. Mewhort. </author> <title> Learning in small connectionist networks does not generalize to large networks. </title> <journal> Psychological Research, </journal> <volume> 56 </volume> <pages> 99-103, </pages> <year> 1994. </year>
Reference-contexts: Furthermore, the scaling of weights as the size of the problem space increases remains an issue <ref> [31] </ref>. 3.6 The Importance of Old Connectionism The publication of Perceptrons by Minsky and Papert in 1969 has taken on almost a mythical aura|it has been likened to the huntsman being sent out to bring back the heart of Snow White [81].
Reference: [32] <author> J. A. Fodor and Z. W. Pylyshyn. </author> <title> Connectionism and cognitive architecture: A critical analysis. </title> <journal> Cognition, </journal> <volume> 28 </volume> <pages> 3-71, </pages> <year> 1988. </year>
Reference-contexts: Not surprisingly, with assumptions founded in associationist theories, connectionism has often been mistaken for associationism (e.g., <ref> [32] </ref>, footnote 29), and subsequently dismissed as a viable theory of cognition. As pointed out by Thorndike [109], however, connectionism should not be confused for associationism. Rather, connectionism has borrowed concepts from associationism and has expanded them. <p> By studying the history of connectionism, we place ourselves in a knowledgeable position to support or deny claims about connectionism. For example, we now know that claims about connectionism merely being another form of associationism <ref> [32] </ref> are false. Furthermore,claims that connectionism may offer a Kuhnian-like paradigm shift for psychology [98] are not necessarily true either, especially when connectionism's rather long history is considered.
Reference: [33] <author> S. I. Gallant. </author> <title> Neural Network Learning and Expert Systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference: [34] <author> C. R. Gallistel. </author> <title> The replacement of general-purpose theories with adaptive specializations. </title> <editor> In M. S. Gazzaniga, editor, </editor> <booktitle> The Cognitive Neurosciences, </booktitle> <pages> pages 1255-1267. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: New Connectionism is characterized by computa-tionally powerful networks that can be fully trained. Such networks have often been hailed as providing a simple universal learning mechanism for cognition (but see <ref> [34] </ref>). Moreover, the learning algorithms embodied within new connectionist models have created very powerful information processors|they are both universal function approximators [16] and arbitrary pattern classifiers [63]. As stated earlier, we are living in the aftermath of the neural network revolution.
Reference: [35] <author> D. Gardner, </author> <title> editor. The Neurobiology of Neural Networks. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference: [36] <author> H. Gardner. </author> <title> The Mind/'s New Science. </title> <publisher> Basic Books, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: To understand what these goals are, however, we need to understand what cognitive science is. 2.1 Cognitive Science The "birth" of cognitive science is often traced back to the Symposium on Information Theory held on September 10-12, 1956 at M.I.T. <ref> [36] </ref>. There, researchers from various disciplines gathered to exchange ideas on communication and the human sciences. Three talks in particular, Miller's The magical number seven, Chomsky's Three models of language, and Newell and Simon's Logic theory machine, have been singled out as instrumental in seeding the cognitive science movement. <p> Following these talks, a perception began to emerge that "human experimental psychology, theoretical linguistics, and computer simulations of cognitive processes were all pieces of a larger whole" (Miller, 1979; p. 9; cited in <ref> [36] </ref>, p. 29). That is, there arose a belief that to understand the functioning of human cognition, one had to combine the efforts of several different disciplines. <p> thoroughly sound and trained acquaintance with the fields of his neighbors : : : ([120]; p. 9) Today, cognitive science can be defined as the interdisciplinary study of mind; It draws upon such diverse fields as Computing Science and Artificial Intelligence [15], Linguistics [80], Neuroscience [85], Philosophy [59], and Psychology <ref> [36] </ref>, to name but a few. Although each discipline has its own unique interpretation Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 63 of cognitive science, they are bound into a cohesive whole by a central tenet.
Reference: [37] <author> J. George N. Reeke and G. M. Edelman. </author> <title> Real brains and artificial intelligence. </title> <editor> In S. R. Graubard, editor, </editor> <booktitle> The Artificial Intelligence Debate. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference: [38] <author> F. Girosi and T. Poggio. </author> <title> Networks and the best approximation property. </title> <journal> Biological Cybernetics, </journal> <volume> 63 </volume> <pages> 169-176, </pages> <year> 1990. </year>
Reference-contexts: In general, an RBF network can be described as constructing global approximations to functions using combinations of basis functions centered around weight vectors. In fact, it has been shown that RBF networks are universal function approximators <ref> [38] </ref>. Practically, however, the approximated function must be smooth and piecewise continuous. Consequently, although RBF networks can be used for discrimination and classification tasks (see [64] for some examples), binary pattern classification functions that are not piecewise continuous (e.g., parity) pose problems for RBF networks [75].
Reference: [39] <author> S. Grossberg. </author> <title> Classical and instrumental learning by neural networks. </title> <booktitle> Progress in Theoretical Biology, </booktitle> <volume> 3 </volume> <pages> 51-141, </pages> <year> 1974. </year>
Reference-contexts: Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 83 4.3 Grossberg's Instars and Outstars Many of the ideas commonly used in artificial neural networks today can be attributed to Stephen Grossberg <ref> [39] </ref>. One such contribution is the instar and outstar configurations, which were originally proposed as models of certain biological functions. Basically, instars are neurons fed by a set of inputs through synaptic weights, while outstars are neurons driving a set of weights.
Reference: [40] <author> S. Grossberg. </author> <title> Adaptive pattern classification and universal recoding: I. parallel development and coding of neural feature detectors. </title> <journal> Biological Cybernetics, </journal> <volume> 23 </volume> <pages> 121-134, </pages> <year> 1976. </year> <booktitle> Neural Computing Surveys 1, </booktitle> <pages> 61-101, </pages> <year> 1998, </year> <note> http://www.icsi.berkeley.edu/~jagota/NCS 98 </note>
Reference-contexts: ART was initially introduced by Grossberg <ref> [40] </ref> as a theory of human information processing: it has since evolved into a series of real-time neural network models that perform supervised and unsupervised category learning, pattern classification, and prediction [12].
Reference: [41] <author> S. Grossberg. </author> <title> A theory of visual coding, memory, and development. </title> <editor> In E. L. J. Leeuwnberg and H. F. J. M. Buffart, editors, </editor> <title> Formal Theories of Visual Perception. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1978. </year>
Reference: [42] <author> S. J. Hanson and C. R. Olson. </author> <booktitle> Neural networks and natural intelligence: Notes from Mudville. Connection Science, </booktitle> <volume> 3 </volume> <pages> 332-335, </pages> <year> 1991. </year>
Reference: [43] <author> E. J. Hartman, J. D. Keeler, and J. M. Kowalski. </author> <title> Layered neural networks with gaussian hidden units as universal approximations. </title> <journal> Neural Computation, </journal> <volume> 2 </volume> <pages> 210-215, </pages> <year> 1990. </year>
Reference: [44] <author> D. O. Hebb. </author> <title> The Organization of Behaviour. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1949. </year>
Reference-contexts: That is, there arose a belief that to understand the functioning of human cognition, one had to combine the efforts of several different disciplines. In fact, similar sentiments had been expressed previously in the literature by such researchers as Hebb <ref> [44] </ref> and Wiener [120]. : : : a proper explanation of these blank spaces on the map of science (can) only be made by a team of scientists, each a specialist in his own field but each possessing a thoroughly sound and trained acquaintance with the fields of his neighbors : <p> Hebb (a student of Lashley). In his book, The Organization of Behaviour <ref> [44] </ref>, Hebb presented a theory of behaviour based as much as possible on the physiology of the nervous system. <p> The first modification would be to add a Hebbian-like learning mechanism to increase or decrease the weighted connections between nodes, so that those nodes that are active together become more strongly connected (either inhibitory or excitatory), and those nodes that are seldom active together weaken their connection <ref> [44] </ref>. The second modification would be to limit the maximum possible weight of any connection.
Reference: [45] <author> G. E. Hinton and J. A. Anderson, </author> <title> editors. Parallel Models of Associative Memory. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1981. </year>
Reference-contexts: Whereas previous researchers were interested in a connectionist theory of mind, the focus of research during the 1970's and early 1980's was more directed towards a connectionist theory of memory. This is exemplified by the work on associative memory models reported in Hinton and Anderson <ref> [45] </ref>. The models described in Parallel Models of Associative Memory were seen as a departure from standard memory models of the time for three distinct reasons (e.g., [97]): 1. The systems were assumed to have a neurophysiological foundation, 2.
Reference: [46] <author> G. E. Hinton and T. J. Sejnowski. </author> <title> Learning and relearning in Boltzman machines. </title> <editor> In Rumelhart et al. </editor> <volume> [96], </volume> <pages> pages 282-317. </pages>
Reference-contexts: To combat this problem, one can change the weights statistically instead of deterministically. This technique is known as simulated annealing, and networks trained using this method are known as Boltzmann machines <ref> [46] </ref>. It has been shown that recurrent networks can simulate finite state automata [13] and that one can construct a second-order recurrent network such that internal deterministic finite-state automata state representations remain stable [79].
Reference: [47] <author> J. J. </author> <title> Hopfield. Neural networks and physical systems with emergent collective computational abilities. </title> <booktitle> Proceedings of the National Academy of Sciences, </booktitle> <volume> 79 </volume> <pages> 2554-2558, </pages> <year> 1982. </year>
Reference-contexts: Researchers can be found in such fields as artificial intelligence [33][1], cognitive neuroscience [76], economics [117][121], linguistics [84], philosophy [48], and physics <ref> [47] </ref> to name but a few. It has even been suggested that connectionism represents a Kuhnian-like paradigm shift for psychology [98]. But, perhaps the field that has most benefited from connectionist research is the multidisciplinary field of cognitive science [8][19][96][69][108]. <p> One criticism leveled against the generic PDP architecture, however, is that is only capable of a static mapping of the input vectors. The brain, on the other hand, is not stateless but rather a high-dimensional nonlinear dynamical system [26]. Consequently, the recurrent network architecture pioneered by John Hop-field <ref> [47] </ref> will be briefly discussed. The basic characteristic of recurrent networks is that some processing activation (usually the output) at time t is re-used (usually as an input) at time t+1. <p> Stable networks are typified by weight matrices that are symmetrical along the main diagonal, with diagonal weights of zero (i.e., w ij = w ji ; w ii = 0). Much of the early work on recurrent networks was pioneered by John Hopfield <ref> [47] </ref>. In fact, some have argued that it was because of Hopfield's stature as a well-known physicist that neural network research was made respectable again [3]. Hence, certain configurations of recurrent networks are referred to as Hopfield nets.
Reference: [48] <author> T. Horgan and J. Tienson. </author> <title> Connectionism and the Philosophy of Psychology. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: Researchers can be found in such fields as artificial intelligence [33][1], cognitive neuroscience [76], economics [117][121], linguistics [84], philosophy <ref> [48] </ref>, and physics [47] to name but a few. It has even been suggested that connectionism represents a Kuhnian-like paradigm shift for psychology [98]. But, perhaps the field that has most benefited from connectionist research is the multidisciplinary field of cognitive science [8][19][96][69][108]. <p> Furthermore, the history of connectionist research is often overlooked, or at least misconstrued [81]. As a result, a view popular with current researchers is that connectionism really emerged in the 1980's|there is only brief mention of research before that time (e.g., [8], <ref> [48] </ref>). Connectionism, however, has a very long past. In fact, one can trace the origin of connectionist ideas to the early Greek philosopher, Aristotle, and his ideas on mental associations. These ideas were elaborated by the British empiricists and then naturally extended by the founders of psychology.
Reference: [49] <author> K. Hornik, M. Stinchcombe, and H. White. </author> <title> Multilayer feedforward networks are universal approxima-tors. </title> <booktitle> Neural Networks, </booktitle> <volume> 2 </volume> <pages> 359-366, </pages> <year> 1989. </year>
Reference: [50] <author> D. H. Hubel and T. N. Wiesel. </author> <title> Receptive fields of single neurons in the cat's striate cortex. </title> <journal> Journal of Physiology (London), </journal> <volume> 148 </volume> <pages> 574-591, </pages> <year> 1959. </year>
Reference-contexts: Such an activation function is readily apparent not only within the cones of the eye [17], but also within the tuned neurons in the visual cortex <ref> [50] </ref>.
Reference: [51] <author> C. L. Hull. </author> <booktitle> Principles of Behavior. </booktitle> <address> Appleton-Century-Crofts, New York, </address> <year> 1943. </year>
Reference-contexts: Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 69 3.2.4 Hull's Learning Rule In 1943, Clark L. Hull <ref> [51] </ref> set for himself the task of elaborating the laws of behaviour from a molar level description of neural activity (since the results of molecular neurophysiology at the time were inadequate). <p> The second modification would be to limit the maximum possible weight of any connection. The idea behind this restriction comes from Hull's <ref> [51] </ref> growth of habit strength and Minsky and Papert's [74] observation that network weights often grow without bound and there is no evidence that biological neural networks behave in this manner.
Reference: [52] <author> C. L. Hull and H. D. Baernstein. </author> <title> A mechanical parallel to the conditioned reflex. </title> <journal> Science, </journal> <volume> 70 </volume> <pages> 14-15, </pages> <year> 1929. </year>
Reference-contexts: Thus emerges in a perfectly natural manner a direct implication of the mechanistic tendency of modern psychology. Learning and thought are here conceived as by no means necessarily a function of living protoplasm any more than is aerial locomotion. <ref> [52] </ref> pp. 14-15. Perhaps the most influential event in the development of connectionism was the invention of the modern computer. Theories that could only be tested previously by observing the behaviour of animals or humans (e.g., [109][110][51]) could now be stated more formally and investigated on artificial computation devices.
Reference: [53] <author> W. S. Hunter. </author> <title> A consideration of Lashley's theory of the equipotentiality of cerebral action. </title> <journal> Journal of General Psychology, </journal> <volume> 3 </volume> <pages> 455-468, </pages> <year> 1930. </year>
Reference-contexts: In fact, recent lesioning experiments performed by connectionists (e.g., [29],[83]) would tend to agree with Lashley in terms of network processing being distributed and non-localized. Just as neuropsychologists have questioned Lashley's conclusions <ref> [53] </ref>, however, the conclusions derived from experiments on lesioned connectionist networks are also being challenged [73]). 3.3.2 Hebbian Learning Perhaps the most influential work in connectionism's history is the contribution of Canadian neuropsychol-ogist, Donald O. Hebb (a student of Lashley).
Reference: [54] <author> T. S. Hussain and R. A. Browse. ARTSTAR: </author> <title> A supervised adaptive resonance classifier. </title> <booktitle> In Elio [28], </booktitle> <pages> pages 121-130. </pages>
Reference-contexts: ARTMAP combines two ART modules to perform supervised learning while fuzzy ARTMAP represents a synthesis of elements from neural networks, expert systems, and fuzzy logic [12]. Other systems have been developed to suit individual researcher's needs; for example, Hussain and Browse <ref> [54] </ref> developed ARTSTAR which uses a layer of INSTAR nodes to supervise and integrate multiple ART2 modules.
Reference: [55] <author> W. James. </author> <booktitle> The Principles of Psychology, </booktitle> <volume> volume 1. </volume> <publisher> Dover, </publisher> <address> New York, </address> <year> 1890/1950. </year>
Reference-contexts: In fact, founding psychologists such as Spencer [103] and James <ref> [55] </ref> are often cited for early examples of connectionist networks|networks that combined associationist principles with neurology. The appearance of the hardline behaviourist movement (e.g., [115], [102]), by all accounts, should have signaled the demise of connectionist ideas in psychology 1 .
Reference: [56] <author> W. James. </author> <booktitle> The Principles of Psychology, </booktitle> <volume> volume 2. </volume> <publisher> Dover, </publisher> <address> New York, </address> <year> 1890/1950. </year>
Reference: [57] <author> T. Kohonen. </author> <title> Self-organized formation of topologically correct feature maps. </title> <journal> Biological Cybernetics, </journal> <volume> 43 </volume> <pages> 59-69, </pages> <year> 1982. </year>
Reference-contexts: First, Stephen Grossberg's [39][40] instar and outstar configurations and his Adaptive Resonance Theory (ART) networks will be introduced. Second, we will cover Teuvo Kohonen's <ref> [57] </ref> self-organizing maps (which are now commonly referred to as Kohonen networks). Coupled with the new learning rule for the IAC networks, these architectures provide a link from the"Old" to the "New" Connectionism. <p> The new architecture provides more robust classification performance by combining the output of several ART2 modules trained by supervision under different conditions. 4.5 Kohonen Networks A Kohonen network <ref> [57] </ref> can be characterized as a self-organizing map used for pattern recognition. It differs from the generic PDP architecture in several ways (see Section 4.6). First, application of an input vector to the network will cause activation in all output neurons: the neuron with the highest value represents the classification.
Reference: [58] <author> K. Lashley. </author> <title> In search of the engram. </title> <journal> Symposia of the Society for Experimental Biology, </journal> <volume> 4 </volume> <pages> 454-482, </pages> <year> 1950. </year>
Reference-contexts: Lashley's studies involved training an animal to perform some specific task (such as brightness discrimination or maze orientation) and lesioning a specific area of the cortex either before or after training. Lashley then recorded the behavioural effects of cortical lesions on retention and acquisition of knowledge. In 1950 <ref> [58] </ref>, he summarized 30 years of research into two principles: * The Equipotentiality Principle: all cortical areas can substitute for each other as far as learning is concerned. * The Mass Action Principle: the reduction in learning is proportional to the amount of tissue destroyed, and the more complex the learning
Reference: [59] <author> J. Leiber. </author> <title> An Invitation to Cognitive Science. </title> <publisher> Basil Blackwell, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: each possessing a thoroughly sound and trained acquaintance with the fields of his neighbors : : : ([120]; p. 9) Today, cognitive science can be defined as the interdisciplinary study of mind; It draws upon such diverse fields as Computing Science and Artificial Intelligence [15], Linguistics [80], Neuroscience [85], Philosophy <ref> [59] </ref>, and Psychology [36], to name but a few. Although each discipline has its own unique interpretation Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 63 of cognitive science, they are bound into a cohesive whole by a central tenet.
Reference: [60] <author> I. B. Levitan and L. K. Kaczmarek. </author> <title> The Neuron. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1991. </year>
Reference: [61] <author> M. S. Lewicki and T. J. Sejnowski. </author> <title> Bayesian unsurvised learning of higher order structure. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <volume> volume 9, </volume> <pages> pages 529-535, </pages> <year> 1997. </year>
Reference-contexts: Similarly, Bayesian theories are being incorporated in connectionism in order to understand aspects of rationality in human cognition [67] and to guide unsupervised learning of higher order structure in patterns <ref> [61] </ref>. As these new techniques are building upon the previous research presented in this paper, they will not be elaborated here.
Reference: [62] <author> P. H. Lindsay and D. A. Norman. </author> <title> Human Information Processing. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1972. </year> <booktitle> Neural Computing Surveys 1, </booktitle> <pages> 61-101, </pages> <year> 1998, </year> <note> http://www.icsi.berkeley.edu/~jagota/NCS 99 </note>
Reference-contexts: Thus a practical application of connectionist principles have been applied to pattern recognition. In fact, Pandemonium has been so successful as a model of human pattern recognition that it has been adopted and converted into a more traditional symbolic model (with connectionist principles appropriately ignored) by cognitive psychologists (e.g., <ref> [62] </ref>) 3.5.2 The Perceptron The perceptron, more precisely, the theory of statistical separability, seems to come closer to meeting the requirements of a functional explanation of the nervous system than any system previously proposed. [89] p. 449. (C) Symbolic Diagram. (Adapted from [90]; Figure 2, p. 86).
Reference: [63] <author> R. P. Lippman. </author> <title> An introduction of computing with neural nets. </title> <journal> IEEE ASSP Magazine, </journal> <volume> April:4-22, </volume> <year> 1987. </year>
Reference-contexts: Such networks have often been hailed as providing a simple universal learning mechanism for cognition (but see [34]). Moreover, the learning algorithms embodied within new connectionist models have created very powerful information processors|they are both universal function approximators [16] and arbitrary pattern classifiers <ref> [63] </ref>. As stated earlier, we are living in the aftermath of the neural network revolution. As a consequence, the number of different connectionist architectures available to researchers today is immense; to discuss them all is beyond the scope of this paper. <p> This increase in computational ability derives from the fact that a multilayer network can theoretically carve a pattern space into an arbitrary number of decision regions <ref> [63] </ref>. Furthermore, it can be shown that such networks are also universal function approximators|that is, they are able to solve any function approximation problem to an arbitrary degree of precision [16][43][49]. <p> The major advantage of multilayer networks over single layer networks is that they can theoretically carve a pattern space into an arbitrary number of decision regions and therefore solve any pattern classification problem <ref> [63] </ref>, overcoming one of the limitations cited by Minsky and Papert [74]. Furthermore, it can be shown that such networks are also universal function approximators|that is, they are able to solve any function approximation problem to an arbitrary degree of precision [16][43][49].
Reference: [64] <author> D. Lowe. </author> <title> Radial basis function networks. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 779-782. </pages>
Reference-contexts: In fact, it has been shown that RBF networks are universal function approximators [38]. Practically, however, the approximated function must be smooth and piecewise continuous. Consequently, although RBF networks can be used for discrimination and classification tasks (see <ref> [64] </ref> for some examples), binary pattern classification functions that are not piecewise continuous (e.g., parity) pose problems for RBF networks [75].
Reference: [65] <author> D. B. McCaughan. </author> <title> On the properties of periodic perceptrons. </title> <booktitle> In Proceedings of the 1997 International Conference on Neural Networks, </booktitle> <pages> pages 188-193, </pages> <year> 1997. </year>
Reference-contexts: If the problem was linearly inseparable, however, then the value unit architecture would be more appropriate. It should be noted that the field of connectionism is ever-evolving, and new architectures and learning rules are being constantly developed. For example, McCaughan <ref> [65] </ref> has trained networks that use a sinusoidal activation function and has found that such networks can solve both linearly separable and inseparable problems with relative ease.
Reference: [66] <author> J. L. McClelland. </author> <title> Retrieving general and specific information from stored knowledge of specifics. </title> <booktitle> In Proceedings of the Third Annual Meeting of the Cognitive Science Society, </booktitle> <pages> pages 170-172, </pages> <year> 1981. </year>
Reference-contexts: Connections between units may or may not be massively parallel in the sense that every unit is connected to every other unit. Moreover, connections may be "feed-forward" (i.e., signals being passed in one direction only [92], [93]), or "interactive" (i.e., bidirectional passing of signals <ref> [66] </ref>). Finally, the weights associated with the connections may be "hardwired", learned, or both. The weights represent the strength of connection (either excitatory or inhibitory) between two units. <p> After each of the main architectures is described, related network architectures will also be reviewed. These reviews will provide somewhat less detail as they are meant to provide only a cursory examination of comparable architectures. The first architecture to be described in detail is James McClelland's <ref> [66] </ref> Interactive Activation and Competition (IAC) model of information retrieval from stored knowledge. <p> This is because both networks use a Gaussian activation function in their processing units. As the section will show, however, the networks are not equivalent. 4.2 Interactive Activation and Competition Models McClelland's <ref> [66] </ref> Interactive Activation and Competition (IAC) model illustrates the power of a large network for retrieving general and specific information from stored knowledge of specifics. <p> Having analyzed the mathematical basis of the network, we can now turn our attention to a more specific example of the IAC architecture. McClelland's <ref> [66] </ref> network is based on the bi-directional interconnection of nodes. A node is a simple processing device that accumulates excitatory and inhibitory signals from other nodes via weighted connections and then adjusts its output to other nodes accordingly. <p> This means that we can wait for the network to reach equilibrium and a definite answer, or we can ask what the network's best "guess" to a question is before equilibrium is reached. The specific network reported <ref> [66] </ref> encodes information about the members of two gangs called the "Jets" and the "Sharks". Property cohorts include Name, Gang, Affiliation, Age, Education Status, Marital Status, and Occupation. Figure 8 illustrates the network's architecture and the individual properties within each cohort.
Reference: [67] <author> J. L. McClelland. </author> <title> Connectionist models and Bayesian inference. </title> <editor> In M. Oaksford and N. Chater, editors, </editor> <title> Rational Models of Cognition, chapter 2. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1998. </year>
Reference-contexts: In a different approach to connectionism, Zemel [122][123] has applied minimum description length analysis to connectionist networks in order to optimize their internal representations. Similarly, Bayesian theories are being incorporated in connectionism in order to understand aspects of rationality in human cognition <ref> [67] </ref> and to guide unsupervised learning of higher order structure in patterns [61]. As these new techniques are building upon the previous research presented in this paper, they will not be elaborated here.
Reference: [68] <editor> J. L. McClelland and D. E. Rumelhart, editors. </editor> <booktitle> Explorations In Parallel Distributed Processing. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: In this case, the network returns the individual Ken who fits all the characteristics except for education level <ref> [68] </ref>. Furthermore, if we sever the connection between the instance node Lance and the property "Burglar", the network is still able to return a value of "Burglar" when the property node "Lance" is activated even though Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 82 there is no direct connection.
Reference: [69] <author> J. L. McClelland, D. E. Rumelhart, </author> <title> and the PDP Research Group, editors. Parallel Distributed Processing, volume 2:Psychological and Biological Models. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference: [70] <author> W. S. McCulloch and W. Pitts. </author> <title> A logical calculus of the ideas immanent in nervous activity. </title> <journal> Bulletin of Mathematical Biophysics, </journal> <volume> 5 </volume> <pages> 115-133, </pages> <year> 1943. </year>
Reference-contexts: There are serious limitations with Hebbian learning as stated (e.g., the inability to learn certain patterns), but variations of this simple algorithm exist today (e.g., Signal Hebbian Learning; Differential Hebbian Learning; [114]). 3.4 The Mathematical Influence The next major formulation of connectionist theories can be attributed to McCulloch and Pitts <ref> [70] </ref>. In their seminal paper A logical calculus of the ideas immanent in nervous activity, they explicitly laid out the foundations of neural modelling in terms of propositional logic. To accomplish this, they simplified the activity of neurons into five functional states (p. 118): 1. <p> For example, we know that connectionist networks have the in principle power of a UTM <ref> [70] </ref>, but we also know that perceptron-like single layer networks are limited in their computational power [74]. Thus, we should focus current research on multilayer networks.
Reference: [71] <author> D. A. Medler. </author> <title> The Crossroads of Connectionism: </title> <type> Where Do We Go From Here? PhD thesis, </type> <institution> University of Alberta, </institution> <year> 1998. </year>
Reference-contexts: On the other hand, the nonmonotonicity of the activation function has the potential to limit the value unit architecture. For example, value units actually require hidden units to solve linearly separable problems <ref> [71] </ref>. Furthermore, because the value unit uses a nonmonotonic activation function, it is not uniquely invertible, and therefore it has been suggested that theoretically, value units are not suitable for function approximation [24]. <p> Consequently, the desired weight change for the connection originating from unit i and 17 In fact, recent results have shown that, in practice, value units can perform some types of function approximation tasks <ref> [71] </ref> Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 93 terminating at unit j for given pattern p can be computed as p w ij = j (ffi pj * pj )I pi (23) where ffi pj = (t pj o pj )G 0 (net pj ) is equivalent to ffi pj
Reference: [72] <author> D. A. Medler and M. R. W. Dawson. </author> <title> Training redundant artificial neural networks: </title> <journal> Imposing biology on technology. Psychological Research, </journal> <volume> 57 </volume> <pages> 54-62, </pages> <year> 1994. </year>
Reference-contexts: These modifications allow a network trained with the backpropagation algorithm to use non-monotonic activation functions. 4.8.3 Value Unit Performance Value unit networks have been applied to a wide variety of pattern classification tasks, from "toy" problems [24] [25] <ref> [72] </ref>, to diagnosing Alzheimer's patients from SPECT data [20], to identifying logical problems [9], to classifying mushrooms [22].
Reference: [73] <author> D. A. Medler, M. R. W. Dawson, A. Kingstone, and E. Panasiuk. </author> <title> The locality assumption revisited: The relation between internal structure and behavioral dissocations. </title> <journal> Cognitive Science, </journal> <note> under review, </note> <year> 1998. </year>
Reference-contexts: In fact, recent lesioning experiments performed by connectionists (e.g., [29],[83]) would tend to agree with Lashley in terms of network processing being distributed and non-localized. Just as neuropsychologists have questioned Lashley's conclusions [53], however, the conclusions derived from experiments on lesioned connectionist networks are also being challenged <ref> [73] </ref>). 3.3.2 Hebbian Learning Perhaps the most influential work in connectionism's history is the contribution of Canadian neuropsychol-ogist, Donald O. Hebb (a student of Lashley).
Reference: [74] <author> M. Minsky and S. A. Papert. </author> <title> Perceptrons: An Introduction to Computational Geometry. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <note> expanded edition, 1988/1969. </note>
Reference-contexts: The computer and its influence on learning theory can be credited with producing both positive and negative press for connectionism. Selfridge's Pandemonium [100] and Rosenblatt's Perceptrons [89][90] did much to further the concepts of connectionism. The proofs on the limitations of simple perceptrons by Minsky and Papert <ref> [74] </ref>, however, nearly caused the complete abandonment of connectionism. 3.5.1 Pandemonium Recognizing that previous attempts to get machines to imitate human data had all but failed, Selfridge [100] proposed a new paradigm for machine learning. <p> Conversely, some problems (e.g., determining if a figure was connected or not) were extremely difficult and required large networks to solve them. The main distinction between these two types of problems was not the size of the pattern space, but the concept of order <ref> [74] </ref>, p. 30. <p> At the time, however, there was no reliable method of training this intermediate level, and therefore perceptrons were limited to being trained on linearly separable problems only. Minsky and Papert <ref> [74] </ref> used a very simple and elegant example to show the practical limitations of perceptrons. The exclusive-or (XOR) problem (see Figure 5) contains four patterns of two inputs each; a pattern is a positive member of a set if either one of the input bits is on, but not both. <p> For example, we know that connectionist networks have the in principle power of a UTM [70], but we also know that perceptron-like single layer networks are limited in their computational power <ref> [74] </ref>. Thus, we should focus current research on multilayer networks. We know that there are guaranteed algorithms based very much on early behaviourist theorizing for training single layer networks [90], yet no such algorithm exists for multiple layer networks. <p> The second modification would be to limit the maximum possible weight of any connection. The idea behind this restriction comes from Hull's [51] growth of habit strength and Minsky and Papert's <ref> [74] </ref> observation that network weights often grow without bound and there is no evidence that biological neural networks behave in this manner. <p> the input, and j is the "bias" of the unit which is similar in function to a threshold. o pj = f (net pj ) = (1 + e net pj + j ) 1 (15) Units that use a function such as the logistic have an order of 1 <ref> [74] </ref> and are able to carve a pattern space into two distinct regions (see Figure 10). Thus, networks using this form of activation function can solve linearly inseparable problems without any hidden units. <p> The major advantage of multilayer networks over single layer networks is that they can theoretically carve a pattern space into an arbitrary number of decision regions and therefore solve any pattern classification problem [63], overcoming one of the limitations cited by Minsky and Papert <ref> [74] </ref>. Furthermore, it can be shown that such networks are also universal function approximators|that is, they are able to solve any function approximation problem to an arbitrary degree of precision [16][43][49]. <p> Thus, the GDR overcomes the earlier limitations of Old Connectionism by allowing multilayer networks to be trained on any information processing problem. As Minsky and Papert <ref> [74] </ref> point out in their Epilogue to Perceptrons, however, many problems still exist with the GDR and the generic PDP architecture. <p> Choosing the correct algorithm (network architecture) simply becomes a matter of comparing the computational competence between systems we are modeling. Finally, it should be noted that the fourth value unit network architecture (D) satisfies the Minsky and Papert's <ref> [74] </ref> limited order constraint, effectively addressing one of their concerns about neural networks. 4.9 The Radial Basis Function Network One of the misconceptions surrounding the value unit architecture is based upon its use of a Gaussian activation function.
Reference: [75] <author> J. Moody and C. J. Darken. </author> <title> Fast learning in networks of locally tuned processing units. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 281-294, </pages> <year> 1989. </year>
Reference-contexts: Also, the hidden unit activations adopted by value unit network often fall into distinct "bands", allowing for easier interpretation of the algorithms being carried out by the network. Finally, the last architecture to be briefly covered is the Radial Basis Function (RBF) network (e.g., <ref> [75] </ref>). The reason for covering the RBF architecture is that it and the value unit architecture are often confused. This is because both networks use a Gaussian activation function in their processing units. <p> This is because another network architecture, the Radial Basis Function (RBF) network <ref> [75] </ref> uses a similar activation function. That, however, is where the similarities end. The RBF network is a three-layer feedforward network that uses a linear transfer function for the output units and a nonlinear transfer function (normally the Gaussian) for the hidden units. <p> Practically, however, the approximated function must be smooth and piecewise continuous. Consequently, although RBF networks can be used for discrimination and classification tasks (see [64] for some examples), binary pattern classification functions that are not piecewise continuous (e.g., parity) pose problems for RBF networks <ref> [75] </ref>. Thus, RBF networks and value unit networks are not equivalent. 4.10 The Importance of New Connectionism The major turning point in connectionist research occurred with the discovery of methods for training multilayer networks.
Reference: [76] <author> M. C. Mozer, P. W. Halligan, and J. C. Marshall. </author> <title> The end of the line for a brain-damaged model of unilateral neglect. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 9 </volume> <pages> 171-190, </pages> <year> 1997. </year>
Reference-contexts: Researchers can be found in such fields as artificial intelligence [33][1], cognitive neuroscience <ref> [76] </ref>, economics [117][121], linguistics [84], philosophy [48], and physics [47] to name but a few. It has even been suggested that connectionism represents a Kuhnian-like paradigm shift for psychology [98]. But, perhaps the field that has most benefited from connectionist research is the multidisciplinary field of cognitive science [8][19][96][69][108].
Reference: [77] <author> A. Newell and H. A. Simon. </author> <title> Computer science as empirical inquiry: Symbols and search. </title> <journal> Communications of the ACM, </journal> <volume> 19 </volume> <pages> 113-126, </pages> <year> 1976. </year>
Reference-contexts: Furthermore, these processes posit representational or semantic states that are fully realized within the physical constraints of the brain. Traditionally, this information processing approach has been characterized by the physical symbol system hypothesis of Newell and Simon <ref> [77] </ref> which forms the basis of the "classical" approach to cognitive science. Basically, the hypothesis states that cognition is based upon patterns of information, that these patterns of information can be represented as symbols, and that these symbols can be manipulated.
Reference: [78] <author> D. A. Norman. </author> <title> Reflections on cognition and parallel distributed processing. </title> <editor> In McClelland et al. </editor> <volume> [69], </volume> <pages> pages 531-546. </pages>
Reference-contexts: In contrast, connectionism is often viewed as a radically different approach to studying the architecture of the mind, accounting for aspects of human cognition handled poorly by the traditional approaches (e.g., graceful degradation, content-addressable memory; <ref> [78] </ref>). What, then, are the properties of connectionism that distinguishes it from the traditional approach to cognitive science? 2.2 Connectionism Defined Connectionism|within cognitive science|is a theory of information processing. <p> These include graceful degradation, content-addressable memory, output availability, and iterative retrieval <ref> [78] </ref>. Furthermore, the network suggests that we may not need to store general information explicitly. The basic IAC network consists of processing units that are organized into competitive pools. <p> state of the network at the end of a cycle), iterative retrieval (e.g., finding the average property of a Jets member from all other possible properties), and graceful degradation (e.g., retrieval of information when connections are severed or incorrect information is given)|properties required in a model of human information processing <ref> [78] </ref>.
Reference: [79] <author> C. W. Omlin and C. L. Giles. </author> <title> Constructing deterministic finite-state automata in recurrent neural networks. </title> <journal> Journal of the ACM, </journal> <volume> 43 </volume> <pages> 937-972, </pages> <year> 1996. </year>
Reference-contexts: It has been shown that recurrent networks can simulate finite state automata [13] and that one can construct a second-order recurrent network such that internal deterministic finite-state automata state representations remain stable <ref> [79] </ref>. Furthermore, it has been proven that finite size recurrent networks can simulate any multi-stack Turing Machine in real time and non-deterministic rational nets can simulate nondeterministic Turing Machines [101]. Adding recurrent connections to the generic PDP architecture is but one way of improving the performance of such networks.
Reference: [80] <author> D. N. Osherson and H. Lasnik, </author> <title> editors. Language: An Invitation to Cognitive Science, volume 1. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: his own field but each possessing a thoroughly sound and trained acquaintance with the fields of his neighbors : : : ([120]; p. 9) Today, cognitive science can be defined as the interdisciplinary study of mind; It draws upon such diverse fields as Computing Science and Artificial Intelligence [15], Linguistics <ref> [80] </ref>, Neuroscience [85], Philosophy [59], and Psychology [36], to name but a few. Although each discipline has its own unique interpretation Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 63 of cognitive science, they are bound into a cohesive whole by a central tenet.
Reference: [81] <author> S. Papert. </author> <title> One AI or many? Daedalus, </title> <booktitle> 117 </booktitle> <pages> 1-14, </pages> <year> 1988. </year>
Reference-contexts: We are living in the aftermath" ([42], p. 332). Unfortunately, this revolution has created an environment in which researchers may find it difficult to keep up with recent advances in neural network research. Furthermore, the history of connectionist research is often overlooked, or at least misconstrued <ref> [81] </ref>. As a result, a view popular with current researchers is that connectionism really emerged in the 1980's|there is only brief mention of research before that time (e.g., [8], [48]). Connectionism, however, has a very long past. <p> Hence, their approach to the study of neural networks was based on studying the types of problems that were being proposed at the time|mainly visual pattern recognition <ref> [81] </ref>. In doing so, they discovered that some pattern recognition problems (e.g., distinguishing triangles from squares) were relatively easy and could be computed by simple networks. Conversely, some problems (e.g., determining if a figure was connected or not) were extremely difficult and required large networks to solve them. <p> Networks using linear threshold units still violate the limited order constraint when faced with linearly inseparable problems (but 7 Neural network research did not wane due to lack of interest, but because of lack of funding <ref> [81] </ref> Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 77 classification; therefore, a network requires no hidden units. (B) Linearly inseparable problem|the pattern space requires two (or more) hyperplanes to make the correct classification; therefore, a network requires a layer of internal units. see section 4.8). <p> size of the problem space increases remains an issue [31]. 3.6 The Importance of Old Connectionism The publication of Perceptrons by Minsky and Papert in 1969 has taken on almost a mythical aura|it has been likened to the huntsman being sent out to bring back the heart of Snow White <ref> [81] </ref>. Regardless of whether or not the work precipitated or merely coincided with the decline of connectionist research, it serves as a useful delineation between the "Old" and "New" connectionism. The examples of connectionist networks provided in this section are often classified under the term "Old Connectionism". <p> Furthermore, radial basis function networks will also be introduced as they use the same general framework but are differentiated by the net input function that they calculate and the activation function used within the processing units. 4.6.2 The Generalized Delta Rule Papert's <ref> [81] </ref> likening of Perceptrons to the huntsman being sent out to bring back Snow White's heart is appropriate, for the huntsman did not return with the heart of Snow White, but the heart of a deer.
Reference: [82] <author> W. D. Pierce and W. F. Epling. </author> <title> Behavior Analysis and Learning. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1995. </year> <booktitle> Neural Computing Surveys 1, </booktitle> <pages> 61-101, </pages> <year> 1998, </year> <note> http://www.icsi.berkeley.edu/~jagota/NCS 100 </note>
Reference-contexts: Although often considered one of the founding behaviourists (e.g., <ref> [82] </ref>), Thorndike was concerned with states of mind (cf., [115]), and how they changed with experience. More importantly, however, Thorndike can be considered one of the first true connectionists.
Reference: [83] <author> D. C. Plaut and T. Shallice. </author> <title> Perseverative and semantic influences on visual object naming errors in optic aphasia: A connectionist account. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 5 </volume> <pages> 89-117, </pages> <year> 1993. </year>
Reference: [84] <author> K. Plunkett. </author> <title> Connectionist approaches to language acquisition. </title> <editor> In P. Fletcher and B. MacWhinney, editors, </editor> <booktitle> The Handbook of Child Language, </booktitle> <pages> pages 36-72. </pages> <publisher> Blackwell, Oxford, </publisher> <year> 1995. </year>
Reference-contexts: Researchers can be found in such fields as artificial intelligence [33][1], cognitive neuroscience [76], economics [117][121], linguistics <ref> [84] </ref>, philosophy [48], and physics [47] to name but a few. It has even been suggested that connectionism represents a Kuhnian-like paradigm shift for psychology [98]. But, perhaps the field that has most benefited from connectionist research is the multidisciplinary field of cognitive science [8][19][96][69][108].
Reference: [85] <editor> M. I. Posner, editor. </editor> <booktitle> Foundations of Cognitive Science. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: field but each possessing a thoroughly sound and trained acquaintance with the fields of his neighbors : : : ([120]; p. 9) Today, cognitive science can be defined as the interdisciplinary study of mind; It draws upon such diverse fields as Computing Science and Artificial Intelligence [15], Linguistics [80], Neuroscience <ref> [85] </ref>, Philosophy [59], and Psychology [36], to name but a few. Although each discipline has its own unique interpretation Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 63 of cognitive science, they are bound into a cohesive whole by a central tenet.
Reference: [86] <author> Z. W. Pylyshyn. </author> <title> Computation and Cognition. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1984. </year>
Reference-contexts: Basically, the hypothesis states that cognition is based upon patterns of information, that these patterns of information can be represented as symbols, and that these symbols can be manipulated. Consequently, it is sometimes assumed that the architecture of the mind is the architecture of von Neumann style computers (e.g., <ref> [86] </ref>). In contrast, connectionism is often viewed as a radically different approach to studying the architecture of the mind, accounting for aspects of human cognition handled poorly by the traditional approaches (e.g., graceful degradation, content-addressable memory; [78]).
Reference: [87] <author> R. A. Rescorla and A. R. Wagner. </author> <title> A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement. </title> <editor> In A. H. Black and W. F. Prokasy, editors, </editor> <title> Classical Conditioning II: </title> <booktitle> Current Research and Theory, </booktitle> <pages> pages 64-69. </pages> <address> Appleton-Century-Crofts, New York, </address> <year> 1972. </year>
Reference-contexts: Consequently, the only way of inferring habit strength is to note the associations between the antecedent conditions which lead to habit formation and the behaviour which is the consequence of these same conditions. It has been pointed out [112] that this equation is a forerunner to the Rescorla-Wagner rule <ref> [87] </ref>, which has been shown [107] to be essentially identical to the Widrow-Hoff [118] rule for training Adaline units (see Equation 6).
Reference: [88] <author> H. Ritter. </author> <title> Self-organizing feature maps: Kohonen maps. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 846-851. </pages>
Reference-contexts: Such adaptive units can be organized into a layer to produce a feature map. A feature map is a nonlinear method of representing the original signal space and resembles the topographic maps found in many areas of the brain <ref> [88] </ref>. The feature map is produced by the unsupervised training of the adaptive units which gradually develop into a spatially organized array of feature detectors whence the position of the excited units signal statistically important features of the input signal.
Reference: [89] <author> F. Rosenblatt. </author> <title> The perceptron: A probabilistic model for information storage and organization in the brain. </title> <journal> Psychological Review, </journal> <volume> 65 </volume> <pages> 386-408, </pages> <year> 1958. </year>
Reference-contexts: converted into a more traditional symbolic model (with connectionist principles appropriately ignored) by cognitive psychologists (e.g., [62]) 3.5.2 The Perceptron The perceptron, more precisely, the theory of statistical separability, seems to come closer to meeting the requirements of a functional explanation of the nervous system than any system previously proposed. <ref> [89] </ref> p. 449. (C) Symbolic Diagram. (Adapted from [90]; Figure 2, p. 86). Although originally intended as a genotypic model of brain functioning [89][90], the perceptron has come to represent the genesis of machine pattern recognition.
Reference: [90] <author> F. Rosenblatt. </author> <title> Principles of Neurodynamics. </title> <publisher> Spartan, </publisher> <address> Washington, DC, </address> <year> 1962. </year>
Reference-contexts: connectionist principles appropriately ignored) by cognitive psychologists (e.g., [62]) 3.5.2 The Perceptron The perceptron, more precisely, the theory of statistical separability, seems to come closer to meeting the requirements of a functional explanation of the nervous system than any system previously proposed. [89] p. 449. (C) Symbolic Diagram. (Adapted from <ref> [90] </ref>; Figure 2, p. 86). Although originally intended as a genotypic model of brain functioning [89][90], the perceptron has come to represent the genesis of machine pattern recognition. <p> left to the reader to satisfy himself that a system with less "depth" than an elementary perceptron (i.e., one in which S-units are connected directly to the R- unit, with no intervening A-units) is incapable if representing C (W ), no matter how the values of the connections are distributed. <ref> [90] </ref> p. 101. 3.5.3 Adaline The next major formulation in learning rules for networks came from Widrow and Hoff [118]. <p> Thus, we should focus current research on multilayer networks. We know that there are guaranteed algorithms based very much on early behaviourist theorizing for training single layer networks <ref> [90] </ref>, yet no such algorithm exists for multiple layer networks. Can the same be said of biological learning? Finally, we should stop working in the "biological vacuum" and heed the echoing call for models of learning to be based more on the known neurophysiology of the brain.
Reference: [91] <author> D. E. Rumelhart, G. E. Hinton, and J. L. McClelland. </author> <title> A general framework for parallel distributed processing. </title> <editor> In Rumelhart et al. </editor> <volume> [96], </volume> <pages> pages 45-76. </pages>
Reference-contexts: It is a computational device mapping one type of information into another. And, it is a representational device subserving the formation of internal representations. Consequently, we would expect to find these functional properties within our artificial neural networks. As an example, Rumelhart, Hinton, and McClelland <ref> [91] </ref> (p. 46) list eight properties that are essential to Parallel Distributed Processing (PDP) models. * A set of processing units * A state of activation * An output function for each unit * A pattern of connectivity among units * A propagation rule for propagating patterns of activities through the <p> Because this rule is dependent on an external teacher it is termed supervised learning. The Widrow-Hoff rule is also known as the delta rule because the amount of learning is proportional to the difference between the output and the target <ref> [91] </ref>. 6 Note that at this point, presenting the first pattern to the network would produce an error that was small but not necessarily zero.
Reference: [92] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In Rumelhart et al. </editor> <volume> [96], </volume> <pages> pages 318-362. </pages>
Reference-contexts: Connections between units may or may not be massively parallel in the sense that every unit is connected to every other unit. Moreover, connections may be "feed-forward" (i.e., signals being passed in one direction only <ref> [92] </ref>, [93]), or "interactive" (i.e., bidirectional passing of signals [66]). Finally, the weights associated with the connections may be "hardwired", learned, or both. The weights represent the strength of connection (either excitatory or inhibitory) between two units. <p> Practically, for very large jRj, the amount of storage space required for the weights would overshadow the space required to simply represent the problem. Although advances in neural network research have produced methods for training multiple layers of units (e.g., <ref> [92] </ref> [93]), many of Minsky and Papert's concerns remain unanswered.
Reference: [93] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning representations by back-propagating errors. </title> <journal> Nature, </journal> <volume> 323 </volume> <pages> 533-536, </pages> <year> 1986. </year>
Reference-contexts: Connections between units may or may not be massively parallel in the sense that every unit is connected to every other unit. Moreover, connections may be "feed-forward" (i.e., signals being passed in one direction only [92], <ref> [93] </ref>), or "interactive" (i.e., bidirectional passing of signals [66]). Finally, the weights associated with the connections may be "hardwired", learned, or both. The weights represent the strength of connection (either excitatory or inhibitory) between two units. <p> Practically, for very large jRj, the amount of storage space required for the weights would overshadow the space required to simply represent the problem. Although advances in neural network research have produced methods for training multiple layers of units (e.g., [92] <ref> [93] </ref>), many of Minsky and Papert's concerns remain unanswered.
Reference: [94] <author> D. E. Rumelhart and J. L. McClelland. </author> <title> Levels indeed! a response to Broadbent. </title> <journal> Journal of Experimental Psychology: General, </journal> <volume> 114 </volume> <pages> 193-197, </pages> <year> 1985. </year>
Reference-contexts: Furthermore, many different types of network topologies can be used to solve the 4-parity problem (see section 3.4). As it has been argued that networks are algorithms <ref> [94] </ref>, this means that the different network topologies are different algorithmic descriptions for solving the 4-parity problem. Choosing the correct algorithm (network architecture) simply becomes a matter of comparing the computational competence between systems we are modeling.
Reference: [95] <author> D. E. Rumelhart and J. L. McClelland. </author> <title> On learning the past tense of English verbs. </title> <editor> In McClelland et al. </editor> <volume> [69], </volume> <pages> pages 216-271. </pages>
Reference-contexts: Finally, the weights associated with the connections may be "hardwired", learned, or both. The weights represent the strength of connection (either excitatory or inhibitory) between two units. These three tenets allow a large spectrum of models (e.g., Selfridge's Pandemonium [100]; Rumelhart & McClelland's Past-Tense Acquisition Model <ref> [95] </ref>; Dawson's Motion Correspondence Model [18]) to fall within the classification of connectionist research. To understand how these different models fit into connectionist research today, one needs to be aware of how connectionist research has developed. The best way of accomplishing this is to start at the beginning.
Reference: [96] <author> D. E. Rumelhart, J. L. McClelland, </author> <title> and the PDP Research Group, </title> <editor> editors. </editor> <booktitle> Parallel Distributed Processing, volume 1:Foundations. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference: [97] <author> D. E. Rumelhart and D. A. Norman. </author> <title> Parallel associative models of memory: Where do they fit? In Hinton and Anderson [45]. </title>
Reference-contexts: This is exemplified by the work on associative memory models reported in Hinton and Anderson [45]. The models described in Parallel Models of Associative Memory were seen as a departure from standard memory models of the time for three distinct reasons (e.g., <ref> [97] </ref>): 1. The systems were assumed to have a neurophysiological foundation, 2. The systems offered an alternative to the "spatial" metaphor of memory and retrieval, and 3. The systems assumed a parallel, distributed-processing system that did not require a central executive to coordinate processing.
Reference: [98] <author> W. Schneider. </author> <title> Connectionism: Is it a paradigm shift for psychology? Behavior Research Methods, Instruments, </title> <journal> and Computers, </journal> <volume> 19 </volume> <pages> 73-83, </pages> <year> 1987. </year>
Reference-contexts: Researchers can be found in such fields as artificial intelligence [33][1], cognitive neuroscience [76], economics [117][121], linguistics [84], philosophy [48], and physics [47] to name but a few. It has even been suggested that connectionism represents a Kuhnian-like paradigm shift for psychology <ref> [98] </ref>. But, perhaps the field that has most benefited from connectionist research is the multidisciplinary field of cognitive science [8][19][96][69][108]. As Hanson and Olson have stated: "The neural network revolution has happened. We are living in the aftermath" ([42], p. 332). <p> knowing the history of connectionism, not only are we in a position to counter the arguments against connectionism from the classical camp (e.g., knowing why connectionism is not associationism), but also we are in a position to evaluate claims from the connectionist camp that it may represent a paradigm shift <ref> [98] </ref>. To be effective researchers, we need to know both sides of the argument. The second and more important reason is that by studying the development of connectionism we can appraise the strengths and weaknesses of the connectionist approach to information processing and adjust our course of inquiry accordingly. <p> By studying the history of connectionism, we place ourselves in a knowledgeable position to support or deny claims about connectionism. For example, we now know that claims about connectionism merely being another form of associationism [32] are false. Furthermore,claims that connectionism may offer a Kuhnian-like paradigm shift for psychology <ref> [98] </ref> are not necessarily true either, especially when connectionism's rather long history is considered. On the other hand, we can support the claim that connectionist networks have the computational power to be a valuable tool within cognitive science.
Reference: [99] <author> O. G. Selfrdige and U. Neisser. </author> <title> Pattern recognition by machine. </title> <journal> Scientific American, </journal> <volume> 203 </volume> <pages> 60-67, </pages> <year> 1960. </year>
Reference-contexts: It should be noted that this second mechanism may be one of the first genetic machine learning algorithms. 5 "parallel processing seems to be the human way of handling pattern recognition" <ref> [99] </ref> p. 66. Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 73 Selfridge has demonstrated the effectiveness of Pandemonium on two different tasks: distinguishing dots and dashes in manually keyed Morse code [100], as well as recognizing 10 different hand-printed characters [99]. <p> seems to be the human way of handling pattern recognition" <ref> [99] </ref> p. 66. Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 73 Selfridge has demonstrated the effectiveness of Pandemonium on two different tasks: distinguishing dots and dashes in manually keyed Morse code [100], as well as recognizing 10 different hand-printed characters [99]. Thus a practical application of connectionist principles have been applied to pattern recognition.
Reference: [100] <author> O. G. Selfridge. Pandemonium: </author> <title> A paradigm for learning. </title> <editor> In D. V. Blake and A. M. Uttley, editors, </editor> <booktitle> Proceedings of the Symposium on Mechanisation of Thought Processes, </booktitle> <pages> pages 511-529, </pages> <address> London, </address> <year> 1959. </year> <editor> H. M. </editor> <publisher> Stationary Office. </publisher>
Reference-contexts: Furthermore, signals could be supplied from an external stimulus (such as light impinging on the retina) or from other processing units. The processing units (see Figure 1) may refer to neurons, mathematical functions, or even demons a la Selfridge <ref> [100] </ref>. Lastly, information may be encoded in the units either locally or in a distributed manner. Connections between units may or may not be massively parallel in the sense that every unit is connected to every other unit. <p> Finally, the weights associated with the connections may be "hardwired", learned, or both. The weights represent the strength of connection (either excitatory or inhibitory) between two units. These three tenets allow a large spectrum of models (e.g., Selfridge's Pandemonium <ref> [100] </ref>; Rumelhart & McClelland's Past-Tense Acquisition Model [95]; Dawson's Motion Correspondence Model [18]) to fall within the classification of connectionist research. To understand how these different models fit into connectionist research today, one needs to be aware of how connectionist research has developed. <p> Hence, theory generation and refinement could now be accomplished faster and with more precision by using the empirical results generated by the computer simulations. The computer and its influence on learning theory can be credited with producing both positive and negative press for connectionism. Selfridge's Pandemonium <ref> [100] </ref> and Rosenblatt's Perceptrons [89][90] did much to further the concepts of connectionism. <p> The proofs on the limitations of simple perceptrons by Minsky and Papert [74], however, nearly caused the complete abandonment of connectionism. 3.5.1 Pandemonium Recognizing that previous attempts to get machines to imitate human data had all but failed, Selfridge <ref> [100] </ref> proposed a new paradigm for machine learning. Pandemonium was introduced as a learning model that adaptively improved itself to handle pattern classification problems that could not be adequately specified in advance. <p> Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 73 Selfridge has demonstrated the effectiveness of Pandemonium on two different tasks: distinguishing dots and dashes in manually keyed Morse code <ref> [100] </ref>, as well as recognizing 10 different hand-printed characters [99]. Thus a practical application of connectionist principles have been applied to pattern recognition.
Reference: [101] <author> H. T. Siegelmann and E. D. Sontag. </author> <title> Analog computation via neural networks. </title> <journal> Theoretical Computing Science, </journal> <volume> 131 </volume> <pages> 331-360, </pages> <year> 1994. </year>
Reference-contexts: Furthermore, it has been proven that finite size recurrent networks can simulate any multi-stack Turing Machine in real time and non-deterministic rational nets can simulate nondeterministic Turing Machines <ref> [101] </ref>. Adding recurrent connections to the generic PDP architecture is but one way of improving the performance of such networks. Another way is to use different activation functions within the processing units.
Reference: [102] <author> B. F. Skinner. </author> <title> The Behavior of Organisms. </title> <address> Appleton-Century-Crofts, New York, </address> <year> 1938. </year>
Reference-contexts: In fact, founding psychologists such as Spencer [103] and James [55] are often cited for early examples of connectionist networks|networks that combined associationist principles with neurology. The appearance of the hardline behaviourist movement (e.g., [115], <ref> [102] </ref>), by all accounts, should have signaled the demise of connectionist ideas in psychology 1 . Surprisingly, however, it was behavioural psychologists (e.g., [109],[110],[51]), that finally made the distinction between associationism and connectionism [112]. <p> Intelligence grew as a function 1 Watson proposed that psychology should only be interested in objective, observable behaviour: "the consideration of the mind-body problem affects neither the type of problem selected nor the formulation of the solution of that problem" [115]p. 166. This is exemplified by Skinner's view <ref> [102] </ref> that behaviour could be studied without any appeal to the brain. Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 67 of the differentiation of external events into ordered states of consciousness. Thus, changes in the psychical states could be linked directly to changes in the external order.
Reference: [103] <author> H. Spencer. </author> <booktitle> The Principles of Psychology, volume 1. </booktitle> <address> D. </address> <publisher> Appleton and Company, </publisher> <address> New York, </address> <booktitle> 3rd edition, 1855/1910. Neural Computing Surveys 1, </booktitle> <pages> 61-101, </pages> <year> 1998, </year> <note> http://www.icsi.berkeley.edu/~jagota/NCS 101 </note>
Reference-contexts: In fact, founding psychologists such as Spencer <ref> [103] </ref> and James [55] are often cited for early examples of connectionist networks|networks that combined associationist principles with neurology. The appearance of the hardline behaviourist movement (e.g., [115], [102]), by all accounts, should have signaled the demise of connectionist ideas in psychology 1 .
Reference: [104] <author> H. Spencer. </author> <booktitle> The Principles of Psychology, volume 2. </booktitle> <address> D. </address> <publisher> Appleton and Company, </publisher> <address> New York, </address> <note> 3rd edition, 1855/1910. </note>
Reference: [105] <author> N. A. Stillings, M. H. Feinstein, J. L. Garfield, E. L. Rissland, D. A. Rosenbaum, S. E. Weisler, and L. Baker-Ward. </author> <title> Cognitive Science: An Introduction. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1987. </year>
Reference: [106] <author> M. C. Storrie-Lombardi and O. Lahav. </author> <title> Astronomy. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 107-110. </pages>
Reference-contexts: As noted earlier, connectionism is used in many different fields of science. For example, connectionist networks have been used for aiding astronomical work <ref> [106] </ref>, assisting medical diagnosis [20], regulating investment management [121], and controlling robotic limb movement [113]. Many of these systems, however, are approached from an engineering perspective; that is, the designers are only interested in making the networks as efficient as possible (in terms of network topology, correct responses, and generalization).
Reference: [107] <author> R. S. Sutton and A. G. Barto. </author> <title> Toward a modern theory of adaptive networks: Expectation and prediction. </title> <journal> Psychological Review, </journal> <volume> 88 </volume> <pages> 135-171, </pages> <year> 1981. </year>
Reference-contexts: It has been pointed out [112] that this equation is a forerunner to the Rescorla-Wagner rule [87], which has been shown <ref> [107] </ref> to be essentially identical to the Widrow-Hoff [118] rule for training Adaline units (see Equation 6). <p> Another pattern can now be presented to the network and the connections modified 6 . Convergence is achieved when the error (before adaptation) on any given pattern is small and there are small fluctuations about a stable root mean-square value. The Widrow-Hoff rule <ref> [107] </ref> is formulated as: r i = z [(t) y (t)]x i (t) (6) where t is the target pattern, y (t) is the network's output, and x i (t) is the input to the network. Because this rule is dependent on an external teacher it is termed supervised learning.
Reference: [108] <author> P. Thagard. </author> <title> Mind: Introduction to Cognitive Science. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference: [109] <author> E. L. Thorndike. </author> <title> The Fundamentals of Learning. </title> <institution> Teachers College, Columbia University, </institution> <address> New York, </address> <year> 1932. </year>
Reference-contexts: Not surprisingly, with assumptions founded in associationist theories, connectionism has often been mistaken for associationism (e.g., [32], footnote 29), and subsequently dismissed as a viable theory of cognition. As pointed out by Thorndike <ref> [109] </ref>, however, connectionism should not be confused for associationism. Rather, connectionism has borrowed concepts from associationism and has expanded them. For example, connectionism employs such concepts as distributed representations, hidden units, and supervised learning| concepts foreign to associationism [8]. <p> Although often considered one of the founding behaviourists (e.g., [82]), Thorndike was concerned with states of mind (cf., [115]), and how they changed with experience. More importantly, however, Thorndike can be considered one of the first true connectionists. In his book, The Fundamentals of Learning <ref> [109] </ref>, he differentiated between the principles of British associationism and what he had coined "new connectionism." He believed so much in this new connectionism that in 1949 he summarized what he considered his most important contributions to psychology under the title Selected Writings from a Connectionist's Psychology so that students may <p> Many psychologists would indeed deny that any system of connections was adequate to explain his behaviour, and would invoke powers of analysis, insight, purpose, and the like to supplement or replace the simple process of connection-forming by repetition and reward. (<ref> [109] </ref>, p. 355) Through a series of experiments, however, Thorndike [109] shows that there is "no sufficient reasons for ascribing any power over and above that of repetition and reward to any `higher powers' or `forms of thought' or `transcendent systems' " (p. 382) and thus "justif [ies] the connectionist's faith" (p. 4).
Reference: [110] <author> E. L. Thorndike. </author> <title> Selected Writings from a Connectionists Psychology. </title> <publisher> Greenwood Press, </publisher> <address> New York, </address> <year> 1949. </year>
Reference: [111] <author> A. M. </author> <title> Turing. On computable numbers, with an application to the Entscheidungsproblem. </title> <booktitle> Proceedings of the London Mathematical Society, Series 2, </booktitle> <volume> 42 </volume> <pages> 230-265, </pages> <year> 1936. </year>
Reference-contexts: Furthermore, such nets have the in principle computational power of a Universal Turing Machine. "If any number can be computed by an organism, it is computable by these definitions, and conversely" (p. 128). Since all information processing can be characterized by a Turing Machine (e.g., <ref> [111] </ref>), it was assumed that human cognition could also be characterized by a Turing Machine.
Reference: [112] <author> S. F. Walker. </author> <title> A brief history of connectionism and its psychological implications. </title> <journal> AI & Society, </journal> <volume> 4 </volume> <pages> 17-38, </pages> <year> 1990. </year>
Reference-contexts: The appearance of the hardline behaviourist movement (e.g., [115], [102]), by all accounts, should have signaled the demise of connectionist ideas in psychology 1 . Surprisingly, however, it was behavioural psychologists (e.g., [109],[110],[51]), that finally made the distinction between associationism and connectionism <ref> [112] </ref>. Following the demise of behaviourism and the rise of cognitivism and symbolic processing, connectionist research all but disappeared from psychological literature. It has only recently become vogue once again. <p> Thorndike's connectionism can be viewed as a turning point where theories of neural association became sub-symbolic and graduated from merely implementational accounts to accounts of the functional architecture <ref> [112] </ref>. In other words, the neural connections became a substitute for, instead of a mechanism of, ideational processes. Thus, his computational descriptions of the fundamentals of learning were couched in the language of connectionist principles. For example, to Thorndike, the most prevalent questions within learning theory were: 1. <p> Consequently, the only way of inferring habit strength is to note the associations between the antecedent conditions which lead to habit formation and the behaviour which is the consequence of these same conditions. It has been pointed out <ref> [112] </ref> that this equation is a forerunner to the Rescorla-Wagner rule [87], which has been shown [107] to be essentially identical to the Widrow-Hoff [118] rule for training Adaline units (see Equation 6).
Reference: [113] <author> J. Walter and K. Schulten. </author> <title> Implementation of self-organizing neural networks for visuo-motor control of an industrial robot. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 4 </volume> <pages> 86-95, </pages> <year> 1993. </year>
Reference-contexts: As noted earlier, connectionism is used in many different fields of science. For example, connectionist networks have been used for aiding astronomical work [106], assisting medical diagnosis [20], regulating investment management [121], and controlling robotic limb movement <ref> [113] </ref>. Many of these systems, however, are approached from an engineering perspective; that is, the designers are only interested in making the networks as efficient as possible (in terms of network topology, correct responses, and generalization). Consequently, this attitude towards connectionism could be characterized as the "engineering" approach.
Reference: [114] <author> P. D. Wasserman. </author> <title> Neural Computing: Theory and Practice. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: There are serious limitations with Hebbian learning as stated (e.g., the inability to learn certain patterns), but variations of this simple algorithm exist today (e.g., Signal Hebbian Learning; Differential Hebbian Learning; <ref> [114] </ref>). 3.4 The Mathematical Influence The next major formulation of connectionist theories can be attributed to McCulloch and Pitts [70]. In their seminal paper A logical calculus of the ideas immanent in nervous activity, they explicitly laid out the foundations of neural modelling in terms of propositional logic. <p> Furthermore, it can be shown that such networks are also universal function approximators|that is, they are able to solve any function approximation problem to an arbitrary degree of precision [16][43][49]. It should be noted that 10 For example, Wasserman <ref> [114] </ref> argues that since input units do not compute any function, they should not be counted as a layer; therefore, he calls these two-layer networks. 11 The 100-step constraint is based on the processing speed of neurons [30].
Reference: [115] <author> J. B. Watson. </author> <title> Psychology as the behaviorist views it. </title> <journal> Psychological Review, </journal> <volume> 20 </volume> <pages> 158-177, </pages> <year> 1913. </year>
Reference-contexts: In fact, founding psychologists such as Spencer [103] and James [55] are often cited for early examples of connectionist networks|networks that combined associationist principles with neurology. The appearance of the hardline behaviourist movement (e.g., <ref> [115] </ref>, [102]), by all accounts, should have signaled the demise of connectionist ideas in psychology 1 . Surprisingly, however, it was behavioural psychologists (e.g., [109],[110],[51]), that finally made the distinction between associationism and connectionism [112]. <p> Although often considered one of the founding behaviourists (e.g., [82]), Thorndike was concerned with states of mind (cf., <ref> [115] </ref>), and how they changed with experience. More importantly, however, Thorndike can be considered one of the first true connectionists.
Reference: [116] <author> P. J. Werbos. </author> <title> Backpropagation: Basics and new developments. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 134-139. </pages>
Reference-contexts: The generic PDP network is probably the most well known and most widely used architecture today it is estimated that about 70% of real-world network applications use the backpropagation learning algorithm <ref> [116] </ref>. Furthermore, the algorithm is suitable for both function approximation tasks and pattern classification problems. One criticism leveled against the generic PDP architecture, however, is that is only capable of a static mapping of the input vectors. <p> In fact, the GDR is simply a basic form of backpropagation. In its more general form <ref> [116] </ref>, backpropagation contributes to the prediction and control of large systems (in terms of optimal planning and reinforcement learning), and not simply to supervised learning as is often assumed. <p> Furthermore, it allows higher degrees of nonlinearity and precision to be applied to problems. Werbos <ref> [116] </ref> notes that since backpropagation is used in so many different applications, its actual definition has often become muddled and confused. Therefore, he offers these two standard definitions (p. 135, his italics): 1. <p> Neural Computing Surveys 1, 61-101, 1998, http://www.icsi.berkeley.edu/~jagota/NCS 88 2. Backpropagation is any technique for adapting the weights of parameters of a nonlinear system by somehow using such derivatives or the equivalent. What we are concerned with, however, is the special form of backpropagation for training neural networks. Werbos <ref> [116] </ref> calls this the basic form of backpropagation, although most researchers today simply refer to it as backprop. <p> In other words it is neither dependable nor efficient, though there are techniques for trying to improve this <ref> [116] </ref>. Another problem is that networks with only one layer of hidden units trained with the GDR still must violate the limited order constraint to solve linearly inseparable problems.
Reference: [117] <author> H. White. </author> <title> Economic prediction using neural networks: The case of IBM daily stock returns. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Networks, pages II-451-II-459, </booktitle> <address> San Diego, </address> <year> 1988. </year>
Reference: [118] <author> B. Widrow and M. E. Hoff. </author> <title> Adaptive switching circuits. </title> <booktitle> In 1960 IRE WESCON Convention Record, </booktitle> <pages> pages 96-104, </pages> <address> New York, </address> <year> 1960. </year> <pages> IRE. </pages>
Reference-contexts: It has been pointed out [112] that this equation is a forerunner to the Rescorla-Wagner rule [87], which has been shown [107] to be essentially identical to the Widrow-Hoff <ref> [118] </ref> rule for training Adaline units (see Equation 6). <p> in which S-units are connected directly to the R- unit, with no intervening A-units) is incapable if representing C (W ), no matter how the values of the connections are distributed. [90] p. 101. 3.5.3 Adaline The next major formulation in learning rules for networks came from Widrow and Hoff <ref> [118] </ref>. They developed "Adaline" (first for adaptive linear, then adaptive linear neuron, and later adaptive linear element as neural models became less popular) as an adaptive pattern classification machine to illustrate principles of adaptive behaviour and learning.
Reference: [119] <author> B. Widrow and M. A. Lehr. </author> <title> Perceptrons, Adalines, and backpropagation. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 719-724. </pages>
Reference-contexts: As the name implies, the GDR is a generalization of the Widrow-Hoff Delta Rule for training networks of Adaline units <ref> [119] </ref>. The training procedure, however, is commonly referred to as backpropagation of error, or backpropagation (backprop) for short. <p> Because the true gradient is often impractical and inefficient to obtain, the instantaneous gradient is often computed based on the square of the instantaneous error. The instantaneous gradient is used because it is an unbiased estimate of the true gradient and is easily computed from single data samples <ref> [119] </ref>. Therefore, to minimize E by gradient descent, the partial derivative of E with respect to each weight within the network needs to be computed.
Reference: [120] <author> N. Wiener. </author> <title> Cybernetics. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1948. </year>
Reference-contexts: That is, there arose a belief that to understand the functioning of human cognition, one had to combine the efforts of several different disciplines. In fact, similar sentiments had been expressed previously in the literature by such researchers as Hebb [44] and Wiener <ref> [120] </ref>. : : : a proper explanation of these blank spaces on the map of science (can) only be made by a team of scientists, each a specialist in his own field but each possessing a thoroughly sound and trained acquaintance with the fields of his neighbors : : : ([120];
Reference: [121] <author> A. D. Zapranis and A. N. Refenes. </author> <title> Investment management: Tactical assest allocation. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 491-495. </pages>
Reference-contexts: As noted earlier, connectionism is used in many different fields of science. For example, connectionist networks have been used for aiding astronomical work [106], assisting medical diagnosis [20], regulating investment management <ref> [121] </ref>, and controlling robotic limb movement [113]. Many of these systems, however, are approached from an engineering perspective; that is, the designers are only interested in making the networks as efficient as possible (in terms of network topology, correct responses, and generalization).
Reference: [122] <author> R. S. Zemel. </author> <title> A Minimum Description Length Framework for Unsupervised Learning. </title> <type> PhD thesis, </type> <institution> University of Toronto, </institution> <year> 1993. </year>
Reference: [123] <author> R. S. Zemel. </author> <title> Minimum description length analysis. </title> <booktitle> In Arbib [4], </booktitle> <pages> pages 572-575. </pages>
References-found: 123

