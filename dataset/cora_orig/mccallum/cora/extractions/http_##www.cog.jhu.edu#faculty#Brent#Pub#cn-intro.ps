URL: http://www.cog.jhu.edu/faculty/Brent/Pub/cn-intro.ps
Refering-URL: http://www.cog.jhu.edu/faculty/brent.html
Root-URL: 
Title: Advances in the Computational Study of Language Acquisition last fifteen years, the field of language
Author: Michael R. Brent 
Note: Over the  
Date: June 26, 1996  
Abstract: This paper provides a tutorial introduction to computational studies of how children learn their native languages. Its aim is to make recent advances accessible to the broader research community, and to place them in the context of current theoretical issues. The first section locates computational studies and behavioral studies within a common theoretical framework. The next two sections review two papers that appear in this volume: one on learning the meanings of words and one on learning the sounds of words. The following section highlights an idea which emerges independently in these two papers and which I have dubbed autonomous bootstrapping. Classical bootstrapping hypotheses propose that children begin to get a toe-hold in a particular linguistic domain, such as syntax, by exploiting information from another domain, such as semantics. Autonomous bootstrapping complements the cross-domain acquisition strategies of classical bootstrapping with strategies that apply within a single domain. Autonomous bootstrapping strategies work by representing partial and/or uncertain linguistic knowledge and using it to analyze the input. The next two sections review two more more contributions to this special issue: one on learning word meanings via selectional preferences and one on algorithms for setting grammatical parameters. The final section suggests directions for future research. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Armstrong, S. (Ed.). </author> <year> (1994). </year> <title> Using Large Corpora. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Bahl, L. R., Jelinek, F., & Mercer, R. L. </author> <year> (1983). </year> <title> A Maximum Likelihood Approach to Continuous Speech Recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5, </volume> <pages> 179-190. </pages>
Reference: <author> Brent, M. R. </author> <year> (1993). </year> <title> From Grammar to Lexicon: Unsupervised Learning of Lexical Syntax. </title> <journal> Computational Linguistics, </journal> <volume> 19, </volume> <pages> 243-262. </pages>
Reference-contexts: Although he does not provide details, Resnik reports that in his simulations the identification of direct object heads in child-directed speech requires little more than looking for the first noun to the right of the verb <ref> (also see Brent, Computational Language Acquisition 33 Brent, 1993, 1994) </ref>. Even this strategy suggests a fairly developed syntactic lexicon as well as rudimentary knowledge of word order.
Reference: <author> Brent, M. R. </author> <year> (1994). </year> <title> Acquisition of Subcategorization Frames Using Aggregated Evidence from Local Syntactic Cues. </title> <journal> Lingua, </journal> <volume> 92, </volume> <pages> 433-470. </pages>
Reference: <author> Carey, S. </author> <year> (1978). </year> <title> The Child as Word Learner. </title> <editor> In M. Halle, J. Bresnan, & G. </editor> <publisher> A. </publisher>
Reference-contexts: His inference rules, however, apply to a very broad class of representational systems. 5 Representing Partial Knowledge One of the key ideas that Siskind's algorithm models is that the meanings of words are refined gradually <ref> (Carey, 1978) </ref>. If this is correct, then children must be able to represent partial knowledge about the meanings of words. A simple example of partial knowledge is knowing that a particular conceptual symbol occurs in the meaning of a particular word.
Reference: <author> Miller (Eds.), </author> <title> Linguistic Theory and Psychological Reality, </title> <journal> chap. </journal> <volume> 8, </volume> <pages> pp. 265-293. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Chomsky, N. </author> <year> (1981). </year> <title> Lectures on Government and Binding, the Pisa Lectures, Vol. 9 of Studies in Generative Grammar. </title> <publisher> Dordrecht: Foris Publications. </publisher> <editor> Brent, </editor> <title> Computational Language Acquisition 40 Clark, </title> <editor> E. V. </editor> <year> (1987). </year> <title> The Principle of Contrast: A Constraint on Language Acquisition. </title> <editor> In B. MacWhinney (Ed.), </editor> <booktitle> The 20th Annual Carnegie Symposium on Cognition, </booktitle> <pages> pp. 1-33. </pages> <address> Teaneck, NJ: </address> <publisher> Erlbaum. </publisher>
Reference-contexts: Niyogi & Berwick: Parameter Setting Background Over the last fifteen years, substantial effort has been devoted to characterizing the major differences between languages in terms of a small set of parameters <ref> (Chomsky, 1981) </ref>. A frequently cited example is the headedness parameter. Languages such as English and French are said to be head-first, because verbs precede direct objects in verb phrases (VPs), prepositions are first in prepositional phrases (PPs), nouns precede relative clauses in noun phrases (NPs), and so on.
Reference: <author> Clark, E. V. </author> <year> (1993). </year> <title> The Lexicon in Acquisition. </title> <address> Cambridge, UK: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Clark, R., & Roberts, I. </author> <year> (1993). </year> <title> A Computational Model of Language Learn-ability and Language Change. </title> <journal> Linguistic Inquiry, </journal> <volume> 24, </volume> <pages> 299-345. </pages>
Reference: <author> Cutler, A., & Carter, D. M. </author> <year> (1987). </year> <title> The Predominance of Strong Initial Syllables in the English Vocabulary. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 2, </volume> <pages> 133-142. </pages>
Reference: <author> Elman, J. </author> <year> (1990). </year> <title> Finding Structure in Time. </title> <journal> Cognitive Science, </journal> <volume> 14, </volume> <pages> 179-211. </pages>
Reference: <author> Fernald, A., McRoberts, G. W., & Herrera, C. </author> <year> (1996). </year> <title> Effects of prosody and word position on infants' ability to recognize words in fluent speech. Journal of Experimental Psychology: Language, Memory, </title> <journal> Cognition, </journal> <note> in press. </note>
Reference: <author> Fisher, C., Gleitman, H., & Gleitman, L. R. </author> <year> (1991). </year> <title> On the Semantic Content of Subcategorization Frames. </title> <journal> Cognitive Psychology, </journal> <volume> 23 (3), </volume> <pages> 331-392. </pages>
Reference: <author> Fisher, C., & Tokura, H. </author> <year> (1996). </year> <title> Prosody in Speech to Infants: Direct and Indirect Acoustic Cues to Syntactic Structure. </title> <editor> In J. L. Morgan & K. De-muth (Eds.), </editor> <title> Signal to Syntax: Bootstrapping from Speech to Grammar in Early Acquisition, </title> <journal> pp. </journal> <pages> 343-364. </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Frank, R., & Kapur, S. </author> <year> (1995). </year> <title> On the Use of Triggers in Parameter Setting. </title> <note> To appear in Linguistic Inquiry. </note>
Reference: <author> Gelman, S. A., & Taylor, M. </author> <year> (1984). </year> <title> How Two-Year-Old Children Interpret Proper and Common Names for Unfamiliar Objects. Child Development, </title> <booktitle> 55, </booktitle> <pages> 1535-1540. </pages>
Reference: <author> Gibson, E., & Wexler, K. </author> <year> (1994). </year> <title> Triggers. </title> <journal> Linguistic Inquiry, </journal> <volume> 25, </volume> <pages> 405-457. </pages>
Reference: <author> Gleitman, L. </author> <year> (1990). </year> <title> The Structural Sources of Verb Meanings. </title> <journal> Language Acquisition, </journal> <volume> 1, </volume> <pages> 3-56. </pages>
Reference-contexts: And it's at least somewhat more natural to say I bought a Coke from the machine than to say that The machine sold me a Coke. <ref> (Gleitman, 1990, p. 22) </ref> However, if the frequencies of such distinguishing inputs were modeled accurately, it might be a very long time before they appeared in the simulated input.
Reference: <editor> Gleitman, L., & Landau, B. (Eds.). </editor> <year> (1994). </year> <title> The Acquisition of the Lexicon. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <address> Reprint of Lingua, </address> <note> vol. 92. Brent, Computational Language Acquisition 41 Gleitman, </note> <author> L. R., & Wanner, E. </author> <year> (1982). </year> <title> Language Acquisition: The State of the State of the Art. </title> <editor> In E. Wanner & L. R. Gleitman (Eds.), </editor> <booktitle> Language Acquisition: The state of the Art, </booktitle> <pages> pp. 3-48. </pages> <address> New York: </address> <publisher> Cambridge University Press. </publisher>
Reference: <author> Gold, E. M. </author> <year> (1967). </year> <title> Language Identification in the Limit. </title> <journal> Information and Control, </journal> <volume> 10, </volume> <pages> 447-474. </pages>
Reference: <author> Golinkoff, R., Hirsh-Pasek, K., Cauley, K., & Gordon, L. </author> <year> (1987). </year> <title> The Eyes Have It: Lexical and Syntactic Comprehension in a New Paradigm. </title> <journal> Journal of Child Language, </journal> <volume> 14, </volume> <pages> 23-45. </pages>
Reference: <author> Goodsitt, J. V., Morgan, J. L., & Kuhl, P. K. </author> <year> (1993). </year> <title> Perceptual Strategies in Prelingual Speech Segmentation. </title> <journal> Journal of Child Language, </journal> <volume> 20, </volume> <pages> 229-252. </pages>
Reference: <author> Grimshaw, J. </author> <year> (1981). </year> <title> Form, Function, and the Language Acquisition Device. </title> <booktitle> In The Logical Problem of Language Acquisition, </booktitle> <pages> pp. 165-210. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: For example, they use the knowledge that certain words refer to concrete objects to infer that those words belong to the syntactic category noun <ref> (Grimshaw, 1981) </ref>. Hypotheses of the form (1) attempt to answer a how question about task t|namely, how do children perform t.
Reference: <author> Hall, D. G. </author> <year> (1991). </year> <title> Acquiring Proper Nouns for Familiar and Unfamiliar Animate Objects: Two-year-olds' Word-Learning Biases. Child Development, </title> <booktitle> 62, </booktitle> <pages> 1142-1154. </pages>
Reference: <author> Jackendoff, R. </author> <year> (1983). </year> <title> Semantics and Cognition. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Siskind's approach is based on the conception of word meanings and utterance meanings as structured objects. As examples, he uses expressions reminiscent of Jackendoff's conceptual structures <ref> (Jackendoff, 1983) </ref>.
Reference: <author> Joshi, A. K. </author> <year> (1991). </year> <title> Natural Language Processing. </title> <journal> Science, </journal> <volume> 253, </volume> <pages> 1242-1248. </pages>
Reference: <author> Jusczyk, P. W. </author> <year> (1996). </year> <title> The Discovery of Spoken Language. </title> <publisher> Forthcoming book. </publisher>
Reference: <author> Jusczyk, P. W., Cutler, A., & Redanz, N. J. </author> <year> (1993). </year> <title> Infants' Preference for the Predominant Stress Patterns of English Words. Child Development, </title> <booktitle> 64, </booktitle> <pages> 675-687. </pages>
Reference: <author> Katz, N., Baker, E., & MacNamara, J. </author> <year> (1974). </year> <title> What's in a Name? A Study of How Children Learn Common and Proper Names. Child Development, </title> <booktitle> 45, </booktitle> <pages> 469-73. </pages>
Reference: <author> Landau, B., & Gleitman, L. </author> <year> (1985). </year> <title> Language and Experience. </title> <address> Cambridge, MA: </address> <publisher> Harvard University Press. </publisher>
Reference: <author> Levin, B., & Rappaport Hovav, M. </author> <year> (1995). </year> <title> Unaccusitivity. No. 26 in Linguistic Inquiry Monographs. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Lightfoot, D. W. </author> <year> (1991). </year> <title> How to Set Parameters. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <editor> Brent, </editor> <title> Computational Language Acquisition 42 MacWhinney, </title> <editor> B., & Leinbach, J. </editor> <year> (1991). </year> <title> Implementations are not Conceptualizations: Revising the Verb Learning Model. </title> <journal> Cognition, </journal> <volume> 40, </volume> <pages> 121-157. </pages>
Reference-contexts: For example, a single trigger sentence could lead a consistent algorithm to set a parameter permanently <ref> (e.g., Lightfoot, 1991) </ref>. Once one parameter has been set, only n 1 parameters remain to be set.
Reference: <author> MacWhinney, B., & Snow, C. </author> <year> (1985). </year> <title> The Child Language Data Exchange System. </title> <journal> Journal of Child Language, </journal> <volume> 12, </volume> <pages> 271-296. </pages>
Reference: <author> Marcus, G. </author> <year> (1993). </year> <title> Negative Evidence in Language Acquisition. </title> <journal> Cognition, </journal> <volume> 46, </volume> <pages> 53-85. </pages>
Reference: <author> Markman, E. M. </author> <year> (1988). </year> <title> Children's use of Mutual Exclusivity to Constrain the Meanings of Words. </title> <journal> Cognitive Psychology, </journal> <volume> 20, </volume> <pages> 1-27. </pages>
Reference: <author> Markman, E. M. </author> <year> (1994). </year> <title> Constraints on Word Meaning in Early Language Acquisition. </title> <editor> In L. Gleitman, & B. </editor> <booktitle> Landau (1994), </booktitle> <pages> pp. 199-227. </pages> <booktitle> Reprint of Lingua, </booktitle> <volume> vol. </volume> <pages> 92. </pages>
Reference-contexts: Similar problems have been discussed in the context of terms for superordinate, basic level, and subordinate categories, such as animal, dog, and collie, as well as terms for individuals and their categories, such as Daddy and man <ref> (see Markman, 1994, for a review) </ref>. Consider the case of terms for individuals and their categories. There is empirical evidence that children use at least three strategies to determine whether a word refers to an individual or its category.
Reference: <author> Marr, D. </author> <year> (1982). </year> <title> Vision. </title> <address> San Francisco: </address> <publisher> W.H. Freeman and Company. </publisher>
Reference: <author> McClelland, J. L., & Elman, J. L. </author> <year> (1986). </year> <title> The TRACE Model of Speech Perception. </title> <journal> Cognitive Psychology, </journal> <volume> 18, </volume> <pages> 1-86. </pages>
Reference: <author> McCloskey, M. </author> <year> (1991). </year> <title> Networks and Theories: The Place of Connectionism in Cognitive Science. </title> <journal> Psychological Science, </journal> <volume> 2 (6), </volume> <pages> 387-395. </pages>
Reference: <author> Miller, G. </author> <year> (1990). </year> <title> WordNet: An On-Line Lexical Database. </title> <journal> International Journal of Lexicography, </journal> <volume> 4 (3). </volume>
Reference: <author> Naigles, L. </author> <year> (1990). </year> <title> Children Use Syntax to Learn Verb Meanings. </title> <journal> Journal of Child Language, </journal> <volume> 17, </volume> <pages> 357-374. </pages>
Reference-contexts: The accompanying audio presents a novel verb|gorp|in a sentence. This verb is either in a transitive frame, e.g., Look! The duck is gorping the bunny or in an intransitive frame, e.g., Look! The duck and the bunny are gorping. <ref> (Naigles, 1990, p. 363) </ref> Subsequently, two new videotaped scenes are presented simultaneously. Each scene shows one of the two actions|either the transitive action or the intransitive action.
Reference: <author> Naigles, L., & Kako, E. T. </author> <year> (1993). </year> <title> First contact in verb acquisition: Defining a role for syntax. Child Development, </title> <booktitle> 64, </booktitle> <pages> 1665-1687. </pages>
Reference: <author> Nelson, D. G. K., Jusczyk, P. W., Mandel, D. R., Myers, J., Turk, A., & Gerken, L. A. </author> <year> (1995). </year> <title> The Headturn Preference Procedure for Testing Auditory Perception. </title> <booktitle> Infant Behavior and Development, </booktitle> <volume> 18, </volume> <pages> 111-116. </pages>
Reference: <author> Norris, D. </author> <year> (1994). </year> <title> SHORTLIST: A Connectionist Model of Continuous Speech Recognition. </title> <journal> Cognition, </journal> <volume> 52, </volume> <pages> 189-234. </pages>
Reference: <author> Pinker, S. </author> <year> (1979). </year> <title> Formal Models of Language Learning. </title> <journal> Cognition, </journal> <volume> 7, </volume> <pages> 217-283. </pages>
Reference-contexts: This is because any grammar that is consistent with every input sentence seen so far could turn out to be the target grammar. Thus, an algorithm that always maintains a consistent grammar as its current hypothesis has used every bit of definitive information provided by the input. <ref> (See Pinker, 1979, for a nice exposition of this point.) </ref> TLA and RSA, on the other hand, forget some of the information that was provided by the input and hence they tend to require more input before converging on the target.
Reference: <author> Pinker, S. </author> <year> (1984). </year> <title> Language Learnability and Language Development. </title> <address> Cam-bridge, MA: </address> <publisher> Harvard University Press. </publisher> <editor> Brent, </editor> <title> Computational Language Acquisition 43 Pinker, </title> <editor> S. </editor> <year> (1987). </year> <title> Resolving a Learnability Paradox in the Acquisition of the Verb Lexicon. Lexicon project working papers 17, </title> <institution> MIT Center for Cognitive Science, </institution> <address> Cambridge, MA. </address>
Reference-contexts: Strategies are often cast in terms of information sources. For instance, the semantic bootstrapping hypothesis asserts that children exploit their knowledge of the meanings of words as one source of information for inferring the syntactic categories of those words <ref> (Pinker, 1984, 1989) </ref>. For example, they use the knowledge that certain words refer to concrete objects to infer that those words belong to the syntactic category noun (Grimshaw, 1981). Hypotheses of the form (1) attempt to answer a how question about task t|namely, how do children perform t.
Reference: <author> Pinker, S. </author> <year> (1989). </year> <title> Learnability and Cognition: The Acquisition of Argument Structure. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <editor> Pinker, S., & Mehler, J. (Eds.). </editor> <year> (1988). </year> <title> Connections and Symbols. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. Reprint of Cognition, </publisher> <pages> 28. </pages>
Reference: <author> Plunkett, K., & Marchman, V. </author> <year> (1993). </year> <title> From Rote Learning to System Building: Acquiring Verb Morphology in Children and Connectionist Nets. </title> <journal> Cognition, </journal> <volume> 48, </volume> <pages> 21-69. </pages>
Reference: <author> Prince, A., & Smolensky, P. </author> <year> (1993). </year> <title> Optimality Theory: Constraint Interaction in Generative Grammar. </title> <type> Tech. rep., </type> <institution> Rutgers Center for Cognitive Science, Rutgers University, New Brunswick, and Computer Science Department, University of Colorado at Boulder. </institution>
Reference: <author> Rumelhart, D. E., & McClelland, J. L. </author> <year> (1986). </year> <title> On Learning the Past Tenses of English Verbs. </title> <editor> In J. L. McClelland & D. E. Rumelhart (Eds.), </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 2: Psychological and Biological Models. </booktitle> <address> Cambridge, MA: </address> <publisher> Brad-ford Books/MIT Press. </publisher>
Reference: <author> Saffran, J. R., Newport, E. L., & Aslin, R. N. </author> <year> (1995). </year> <title> Word Segmentation: The Role of Distributional Cues. </title> <publisher> In press. </publisher>
Reference: <author> Seidenberg, M. S. </author> <year> (1989). </year> <title> Visual Word Recognition and Pronunciation. </title> <editor> In W. Marslen-Wilson (Ed.), </editor> <booktitle> Lexical Representation and Process, </booktitle> <pages> pp. 25-74. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Seidenberg, M. S. </author> <year> (1993). </year> <title> Connectionist Models and Cognitive Theory. </title> <journal> Psychological Science, </journal> <volume> 4 (4), </volume> <pages> 228-335. </pages>
Reference: <author> Smolensky, P. </author> <year> (1988). </year> <title> On the Proper Treatment of Connectionism. </title> <journal> Behavioral and Brain Sciences, </journal> <volume> 11, </volume> <pages> 1-74. </pages>
Reference: <author> Spelke, E. </author> <year> (1976). </year> <title> Infants' Intermodal Perception of Events. </title> <journal> Cognitive Psychology, </journal> <volume> 8, </volume> <pages> 553-60. </pages>
Reference: <author> Tesar, B., & Smolensky, P. </author> <year> (1996). </year> <title> Learnability in Optimality Theory. Optimality Archive, </title> <institution> University of Colorado at Boulder. </institution>
Reference: <author> Zipf, G. </author> <year> (1949). </year> <title> Human Behavior and the Principle of Least Effort. </title> <address> New York, NY: </address> <publisher> Addison-Wesley. </publisher> <address> Brent, </address> <note> Computational Language Acquisition 44 14 Thanks to William Badecker, </note> <author> Sandor Brent, Timothy Cartwright, Bob Frank, Lila Gleit-man, Frantisek Kuminiak, Michael McCloskey, Philip Resnik, Jeff Siskind, Paul Smolensky, </author> <title> and Marni Soupcoff for their helpful comments. The author is a member of the Center for Language and Speech Processing at Johns Hopkins University. </title>
Reference-contexts: The strength of this preference increases as the frequency of the familiar word decreases. Thus, words that are both short and rare may not be segmented out. This trade-off is consistent with the observation that, in natural languages, short words are almost always common <ref> (Zipf, 1949) </ref>. Brent, Computational Language Acquisition 25 Overlapping familiar words. What does the DR strategy imply for overlapping familiar words? One interesting prediction arises when the choice between the overlapping words affects the number of words in the segmentation.
References-found: 58

