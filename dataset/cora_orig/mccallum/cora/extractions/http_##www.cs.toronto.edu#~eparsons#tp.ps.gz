URL: http://www.cs.toronto.edu/~eparsons/tp.ps.gz
Refering-URL: http://www.cs.toronto.edu/~eparsons/
Root-URL: http://www.cs.toronto.edu
Title: Thesis Proposal: Using Resource Requirements in Multiprogrammed Multiprocessor Scheduling distributions. In editors, Job Scheduling Strategies
Author: Eric W. Parsons D. G. Feitelson and L. Rudolph, Eric W. Parsons and Kenneth C. Sevcik. Eric W. Parsons and Kenneth C. Sevcik. 
Keyword: Performance Theory, Measurement and Evaluation of Computer and Communication Systems, 1996.  
Note: The document is organized as follows. First, a preliminary introduction of the thesis is presented. Section 3 describes the basic structure of the thesis, and provides a detailed section breakdown. Section 4 outlines the research that is currently underway, which will comprise the last major chapter of the thesis. Finally, conclusions are presented.  cessing, Lecture Notes in Computer Science Vol. 949, pages 127-145. Springer-Verlag, 1995. 2.  In Proceedings of the 1996 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, pages 57-67, 1996. 3.  To appear in Proceedings of the 1996 IFIP Working Group 7.3 Conference on  This thesis proposal only briefly describes these papers, focusing on their conclusions; the reader is encour aged to examine the papers for further details.  
Date: September 23, 1996 1 Preliminaries  
Abstract: This document is intended to be a thesis proposal, the next checkpoint in the author's PhD program. As such, some portions of the document (namely the introduction) represent actual sections of the thesis while others merely describe the contents of the thesis. This distinction will be made clear when necessary. In broad terms, the research has been focussed on the use of resource requirements of parallel jobs in the scheduling of these jobs in the context of large-scale multiprocessors. The two resource requirements investigated are (1) the service-times, and (2) the memory demands of jobs. In addition, a significant portion of the research has been devoted to the implementation of practical scheduling disciplines in the context of a real parallel system. This document presents the contributions made in these areas. Attached to this document are three papers that the author has published on parallel-job scheduling, the aggregate content of which represents a significant fraction of the thesis. These papers are: 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. M. </author> <title> Amdahl. Validity of the single processor approach to achieving large scale computing capabilities. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 483-485, </pages> <month> April </month> <year> 1967. </year>
Reference: [2] <author> Su-Hui Chiang, Rajesh K. Mansharamani, and Mary K. Vernon. </author> <title> Use of application characteristics and limited preemption for run-to-completion parallel processor scheduling policies. </title> <booktitle> In Proceedings of the 1994 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 33-44, </pages> <year> 1994. </year>
Reference: [3] <author> Derek L. Eager, John Zahorjan, and Edward D. Lazowska. </author> <title> Speedup versus efficiency in parallel systems. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38(3) </volume> <pages> 408-423, </pages> <month> March </month> <year> 1989. </year>
Reference: [4] <author> D. G. Feitelson and L. Rudolph. </author> <title> Gang scheduling performance benefits for fine-grain synchronization. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16 </volume> <pages> 306-318, </pages> <year> 1992. </year>
Reference: [5] <author> Dror G. Feitelson and Bill Nitzberg. </author> <title> Job characteristics of a production parallel scientific workload on the NASA Ames iPSC/860. </title> <editor> In D. G. Feitelson and L. Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949. </volume> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference: [6] <author> Dipak Ghosal, Guiseppe Serazzi, and Satish K. Tripathi. </author> <title> The processor working set and its use in scheduling multiprocess systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(5) </volume> <pages> 443-453, </pages> <month> May </month> <year> 1991. </year>
Reference: [7] <author> Ananth Y. Grama, Anshul Gupta, and Vipin Kumar. Isoefficiency: </author> <title> Measuring the scalability of parallel algorithms and architectures. </title> <journal> IEEE Parallel and Distributed Technology, </journal> <volume> 1(3) </volume> <pages> 12-21, </pages> <month> August </month> <year> 1993. </year>
Reference: [8] <author> Anoop Gupta, Andrew Tucker, and Shigeru Urushibara. </author> <title> The impact of operating system scheduling policies and synchronization methods on the performance of parallel applications. </title> <booktitle> In Proceedings of the 1991 ACM SIGMETRICS Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 120-132, </pages> <year> 1991. </year>
Reference: [9] <author> David A. Lifka. </author> <title> The ANL/IBM SP scheduling system. </title> <editor> In D. G. Feitelson and L. Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949, </volume> <pages> pages 295-303. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: thesis. 4.1.3 Parallel Scheduling Disciplines As mentioned earlier, a number of scheduling disciplines have been or will be developed under this framework. 5 These are shown in Table 2, and described in more detail below: LSF-EASY This discipline is a re-implementation of the EASY scheduler developed by Argonne National Laboratories <ref> [9] </ref>. 6 A user specifies, for each job, the number of processors required and the maximum duration for execution.
Reference: [10] <author> S. Majumdar, D. L. Eager, and R. B. Bunt. </author> <title> Scheduling in multiprogrammed parallel systems. </title> <booktitle> In Proceedings of the 1988 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 104-113, </pages> <month> May </month> <year> 1988. </year>
Reference: [11] <author> Cathy McCann, Raj Vaswani, and John Zahorjan. </author> <title> A dynamic processor allocation policy for multipro-grammed shared-memory multiprocessors. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2) </volume> <pages> 146-178, </pages> <month> May </month> <year> 1993. </year>
Reference: [12] <author> Cathy McCann and John Zahorjan. </author> <title> Scheduling memory constrained jobs on distributed memory parallel computers. </title> <type> Technical Report 94-10-05, </type> <institution> University of Washington, </institution> <month> October </month> <year> 1994. </year>
Reference: [13] <author> Vijay K. Naik, Sanjeev K. Setia, and Mark S. Squillante. </author> <title> Performance analysis of job scheduling policies in parallel supercomputing environments. </title> <booktitle> In Supercomputing '93, </booktitle> <pages> pages 824-833, </pages> <year> 1993. </year>
Reference: [14] <author> John K. Ousterhout. </author> <title> Scheduling techniques for concurrent systems. </title> <booktitle> In Proceedings of the 3rd International Conference on Distributed Computing (ICDCS), </booktitle> <pages> pages 22-30, </pages> <month> October </month> <year> 1982. </year>
Reference: [15] <author> Eric W. Parsons and Kenneth C. Sevcik. </author> <title> Multiprocessor scheduling for high-variability service time distributions. </title> <editor> In D. G. Feitelson and L. Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949, </volume> <pages> pages 127-145. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: If migration is supported and if the system can support (at times) multiple thread running on the same processor, then the class of disciplines to be presented in Chapter 3 of the thesis can be used <ref> [15] </ref>. These disciplines have been shown to perform nearly as well as equi-allocation, but do not require applications to be malleable, a significant advantage.
Reference: [16] <author> Eric W. Parsons and Kenneth C. Sevcik. </author> <title> Benefits of speedup knowledge in memory-constrained multiprocessor scheduling. </title> <booktitle> In To appear in Proceedings of the 1996 IFIP Working Group 7.3 Conference on Performance Theory, Measurement and Evaluation of Computer and Communication Systems, </booktitle> <year> 1996. </year>
Reference-contexts: Since it has been shown that performance benefits knowing speedup information can only be obtained if a large fraction of the workload (say 75%) has good speedup, and moreover, if larger-sized jobs tend to have better speedup than smaller-sized ones <ref> [16] </ref>, speedups will be chosen in the following way.
Reference: [17] <author> Eric W. Parsons and Kenneth C. Sevcik. </author> <title> Coordinated allocation of memory and processors in multiprocessors. </title> <booktitle> In Proceedings of the 1996 ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 57-67, </pages> <year> 1996. </year>
Reference: [18] <author> E. Rosti, E. Smirni, L. W. Dowdy, G. Serazzi, and B. M. Carlson. </author> <title> Robust partitioning policies of multiprocessor systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 141-165, </pages> <year> 1994. </year>
Reference: [19] <author> E. Rosti, E. Smirni, L. W. Dowdy, G. Serazzi, and B. M. Carlson. </author> <title> Robust partitioning policies of multiprocessor systems. Performance Evaluation, </title> <booktitle> 19 </booktitle> <pages> 141-165, </pages> <year> 1994. </year>
Reference: [20] <author> Sanjeev Setia. </author> <title> The interaction between memory allocations and adaptive partitioning in message-passing multiprocessors. </title> <editor> In D. G. Feitelson and L. Rudolph, editors, </editor> <title> Job Scheduling Strategies for Parallel Processing, </title> <booktitle> Lecture Notes in Computer Science Vol. </booktitle> <volume> 949, </volume> <pages> pages 146-164. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference: [21] <author> Kenneth C. Sevcik. </author> <title> Characterizations of parallelism in applications and their use in scheduling. </title> <booktitle> In Proceedings of the 1988 ACM SIGMETRICS International Conference on Measurement and Modelling of Computer Systems, </booktitle> <pages> pages 171-180, </pages> <month> May </month> <year> 1989. </year>
Reference: [22] <author> Andrew Tucker and Anoop Gupta. </author> <title> Process control and scheduling issues for multiprogrammed shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 159-166, </pages> <year> 1989. </year> <month> 18 </month>
References-found: 22

