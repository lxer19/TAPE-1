URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P229.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/preprints.htm
Root-URL: http://www.mcs.anl.gov
Title: STABLE PARALLEL ELIMINATION FOR BOUNDARY VALUE ODES  
Author: STEPHEN J. WRIGHT 
Keyword: Key words. Parallel algorithms, two-point boundary value problems, Gaussian elimination, stability  
Affiliation: DIVISION, ARGONNE NATIONAL LABORATORY  
Note: PREPRINT MCS-P229-0491, MCS  AMS(MOS) subject classifications. 65L10, 65L20, 65W05  
Abstract: A parallelizable and vectorizable algorithm for solving linear algebraic systems arising from two-point boundary value ODEs is described. The method is equivalent to Gaussian elimination, with row partial pivoting, applied to a certain row- and column- reordered version of the usual almost-block-diagonal coefficient matrix. Analytical and numerical evidence is presented to show that the algorithm is stable. Results from implementation on a shared-memory multiprocessor and a vector processor are given. The approach can be extended to handle problems with multipoint and integral conditions, or algebraic parameters. 1. Introduction. In a recent paper [11], we described a technique for solving the almost block-diagonal 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> U. M. Ascher and P. S. Y. Chan, </author> <title> On parallel methods for boundary value odes, </title> <journal> Computing, </journal> <volume> 46 (1991), </volume> <pages> pp. </pages> <month> 1-17. </month> <title> PARALLEL ELIMINATION FOR BOUNDARY VALUE ODEs 25 </title>
Reference-contexts: Four test problems are used to compare the relative execution speeds of the codes on the Alliant FX/8 and the CRAY Y-MP: Problem 2 (Ascher and Chan <ref> [1] </ref>) a = 0, b = 1, n = 2, y 0 (t) = cos 2!t ! + sin 2!t with f (t) chosen so that y (t) = e t (1; 1) T .
Reference: [2] <author> U. M. Ascher, R. M. M. Mattheij, and R. D. Russell, </author> <title> Numerical Solution of Boundary Value Problems for Ordinary Differential Equations, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1988. </year>
Reference-contexts: Then, in Section 4.3, we show that the "serial" variant of SLU is essentially equivalent to this block algorithm under certain reasonable assumptions. 4.1. Dichotomy and Conditioning. We start by briefly reviewing the salient points of the theory of dichotomy and conditioning, from Ascher, Mattheij, and Russell <ref> [2] </ref> and Mattheij [9]. <p> sufficient to define consistency constant L by L = 1 H 21 k 1 H 11 uk (where Y 1 1 and Y 2 1 are the first (n l) and last l columns of Y 1 , respectively) and assume that L is of "moderate size." It is known <ref> [2, p. 289] </ref> that if (3) is obtained by applying finite differencing to (1) with uniform mesh spacing h j t i+1 t i , and if the ODE (1) has the dichotomy (12), then the recurrence (13) has the dichotomy (14) with oe = e h and ae = e <p> ; i = 1; : : :; k + 1:(19) PARALLEL ELIMINATION FOR BOUNDARY VALUE ODEs 11 Note, in particular, that W 11 j+1 ) 1 = r=i r ) 1 ; i j; i (W 22 i1 22 j+1 ; i j + 1: As a special case of <ref> [2, Theorem 6.30] </ref>, we have the following: Theorem 4.1. Suppose the dichotomy (14) holds, with fundamental solution fY i g, and that the fundamental solution fZ i g with initial condition Z 1 = Q 0 is consistent with fY i g, with L of moderate size. <p> ~ E 2 ~ G 2 . . . ~ U k1 ~ E k1 ~ G k1 3 7 7 7 7 ; i i = ~ ~ H i k1 k1 = ~ ^ H k1 The entire process is almost identical to stabilized compactification (as described in <ref> [2, pp. 157-161] </ref>), the only difference being in the handling of the final 2n fi 2n block. Stability of the factorization (21) follows immediately from this relationship. <p> It is reasonable to expect that the behavior of the sequence fQ i g is governed by the behavior of PARALLEL ELIMINATION FOR BOUNDARY VALUE ODEs 23 some solution to the underlying continuous Lyapunov equation (see, for example, <ref> [2, 9] </ref>). Therefore, it tends to depend on i=k rather than k. <p> In this section, we show serial SLU orderings analogous to (20) for these more general problems. One form of the algebraic-parameter problem <ref> [2, p. 322] </ref> is y 0 = M (t; )y + q (t; ); t 2 [a; b]; y 2 Rl n ; 2 Rl r If this problem is linearized with respect to , and a finite-difference or multiple shooting method is applied, the following extended form of (3) is <p> The major difference is that the G i blocks will now have n + r columns, rather than n. The multipoint side condition problem (see <ref> [2, pp. 6,323] </ref>) is y 0 = M (t)y + q (t); t 2 [a; b]; y 2 Rl n ; PARALLEL ELIMINATION FOR BOUNDARY VALUE ODEs 24 P J a = 1 &lt; 2 &lt; : : : &lt; J = b: When the points 1 ; : : :
Reference: [3] <author> D. L. Brown and J. Lorenz, </author> <title> A high order method for stiff boundary value problems with turning points, </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 8 (1987), </volume> <pages> pp. 790-805. </pages>
Reference-contexts: Problem 3 (Brown and Lorenz <ref> [3] </ref>) a = 1, b = 1, n = 4, *y 00 2 t z 0 + z = * 2 cos t + 2 *z 00 = z p z (1) = 1 z (1) = e 2= * : Problem 4A a = 0, b = 1, n =
Reference: [4] <author> L. Dieci, M. R. Osborne, and R. D. Russell, </author> <title> A Riccati transformation method for solving linear BVPs. I: </title> <journal> Theoretical aspects, SIAM Journal on Numerical Analysis, </journal> <volume> 25 (1988), </volume> <pages> pp. 1055-1073. </pages>
Reference-contexts: We stress that this does not mean that "reimbedding," as described in Dieci, Osborne, and Russell <ref> [4] </ref> and Keller and Lentini [6], does not occur. On the contrary, in all the test examples, we observe reimbedding in the form of occasional changes in the internal pivot sequence from one stage to the next.
Reference: [5] <author> G. H. Golub and C. F. Van Loan, </author> <title> Matrix Computations, </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, MD, </address> <note> second ed., </note> <year> 1989. </year>
Reference-contexts: Stability of Structured Elimination. The stability of the SQR algorithms has been examined in [11] by using standard tools for the analysis of orthogonal factorizations from the numerical linear algebra literature (see, for example, Golub and Van Loan <ref> [5] </ref>). Similar tools can be used to analyze the SLU algorithms, since each variant of SLU is simply Gaussian elimination with row partial pivoting, applied to a row- and column-reordered version of the coefficient matrix in (3).
Reference: [6] <author> H. B. Keller and M. Lentini, </author> <title> Invariant imbedding, the box scheme and an equivalence between them, </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 19 (1982), </volume> <pages> pp. 942-962. </pages>
Reference-contexts: We stress that this does not mean that "reimbedding," as described in Dieci, Osborne, and Russell [4] and Keller and Lentini <ref> [6] </ref>, does not occur. On the contrary, in all the test examples, we observe reimbedding in the form of occasional changes in the internal pivot sequence from one stage to the next.
Reference: [7] <author> M. Lentini and V. Pereyra, </author> <title> An adaptive finite difference solver for nonlinear two-point boundary value problems with mild boundary layers, </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 14 (1977), </volume> <pages> pp. 91-111. </pages>
Reference-contexts: The ordering (4) is used if the end conditions are separated. Otherwise, left-hand and coupled conditions are listed first, and right-hand conditions are listed at the end. We denote these codes by ROWPP. * the DECOMP and SOLVE routines from the PASVA codes <ref> [7] </ref>. The DECOMP routine uses alternate row and column pivoting (as does the algorithm described in Varah [10]) but always eliminates by rows. * the structured orthogonal factorization algorithm from [11]. These codes are generically denoted by SQR. The structured elimination codes are referred to by the name SLU.
Reference: [8] <author> R. M. M. Mattheij, </author> <title> Stability of block LU-decompositions of matrices arising from BVP, </title> <journal> SIAM Journal on Algebraic and Discrete Methods, </journal> <volume> 5 (1984), </volume> <pages> pp. </pages> <month> 314-331. </month> <title> [9] , Decoupling and stability of algorithms for boundary value problems, </title> <journal> SIAM Review, </journal> <volume> 27 (1985), </volume> <pages> pp. 1-44. </pages>
Reference-contexts: We do this by using a style of analysis that was developed by Mattheij in a series of papers (see, for example <ref> [8] </ref>, [9]). Our approach is first to describe a block factorization algorithm, which is similar to "stable compactification" (Section 4.2). This algorithm performs the required decoupling of the growing and decaying modes.
Reference: [10] <author> J. M. Varah, </author> <title> Alternate row and column elimination for solving certain linear systems, </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 13 (1976), </volume> <pages> pp. 71-75. </pages>
Reference-contexts: Otherwise, left-hand and coupled conditions are listed first, and right-hand conditions are listed at the end. We denote these codes by ROWPP. * the DECOMP and SOLVE routines from the PASVA codes [7]. The DECOMP routine uses alternate row and column pivoting (as does the algorithm described in Varah <ref> [10] </ref>) but always eliminates by rows. * the structured orthogonal factorization algorithm from [11]. These codes are generically denoted by SQR. The structured elimination codes are referred to by the name SLU. The structured codes are subcategorized according to the number of levels.
Reference: [11] <author> S. J. Wright, </author> <title> Stable parallel algorithms for two-point boundary value problems, </title> <type> Tech. Rep. </type> <institution> MCS-P178-0990, Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Illinois, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: 1. Introduction. In a recent paper <ref> [11] </ref>, we described a technique for solving the almost block-diagonal system of linear equations that arise in various algorithms for solving two-point boundary value problems, such as collocation, multiple shooting, and finite differencing. <p> We show in Section 5 how the approach can be extended to handle problems with algebraic parameters or multipoint and integral side conditions. Some of the details of the problem and the structured factorization approach have been discussed in <ref> [11] </ref> and hence are omitted here. 2. The Algorithm. <p> A k C k 3 7 7 7 5 6 6 6 6 s 1 s 3 s k 3 7 7 7 5 2 6 6 6 4 f 1 . . . d b 7 7 7 7 :(4) Our algorithm starts, as in <ref> [11] </ref>, by choosing an integer P k=2, and a set of "separator" indices 0 = k 0 &lt; k 1 &lt; : : : &lt; k P = k; k j+1 k j + 2; j = 0; : : : ; P: Using these indices, we divide the coefficient matrix <p> As in <ref> [11] </ref>, this system has the form 2 6 6 4 ~ A 1 ~ C 1 . . . ~ A P ~ C P 7 7 7 2 6 6 4 s k 1 +1 . . . 3 7 7 5 2 6 6 4 ~ f 1 . <p> A reduced system of approximately half the size of the original system is produced. The code can be written so that the innermost (vectorized) loops have length k=2. This procedure is applied recursively; at each level the size of the remaining system is halved. For more details, see <ref> [11] </ref>. <p> We denote these codes by ROWPP. * the DECOMP and SOLVE routines from the PASVA codes [7]. The DECOMP routine uses alternate row and column pivoting (as does the algorithm described in Varah [10]) but always eliminates by rows. * the structured orthogonal factorization algorithm from <ref> [11] </ref>. These codes are generically denoted by SQR. The structured elimination codes are referred to by the name SLU. The structured codes are subcategorized according to the number of levels. For example, the one-level, two-level, and cyclic reduction variants of the SQR code are named SQR-1, SQR-2, and SQR-CR, respectively. <p> Stability of Structured Elimination. The stability of the SQR algorithms has been examined in <ref> [11] </ref> by using standard tools for the analysis of orthogonal factorizations from the numerical linear algebra literature (see, for example, Golub and Van Loan [5]).
References-found: 10

