URL: http://ai.eecs.umich.edu/people/douglasp/pubs/mlw95.ps
Refering-URL: http://ai.eecs.umich.edu/people/douglasp/pubs/mlw95.html
Root-URL: http://www.cs.umich.edu
Email: dpearson@umich.edu  huffman@tc.pw.com  
Title: Combining learning from instruction with recovery from incorrect knowledge  
Author: Douglas J. Pearson Scott B. Huffman Price Waterhouse 
Address: 1101 Beal Ave. Ann Arbor, MI 48109  68 Willow Road Menlo Park, CA 94025  
Affiliation: Artificial Intelligence Laboratory The University of Michigan  Technology Center  
Abstract-found: 0
Intro-found: 1
Reference: [Holland, 1986] <author> John H. Holland. </author> <title> Escaping brittleness: The possibilities of general-purpose learning algorithms applied to parallel rule-based systems. </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, editors, </editor> <booktitle> Machine Learning: An artificial intelligence approach, Volume II. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Thus, techniques for recovery from incorrect knowledge generally rely on weak inductive methods to correct the knowledge and then re-planning to resolve the current performance failure (e.g. EITHER [Ourston and Mooney, 1990], CLIPS-R [Murphy and Pazzani, 1994] and Classifiers <ref> [Holland, 1986] </ref>). IMPROV [Pearson and Laird, 1995], the recovery system used in this work, uses a weakly constrained search in the environment to find a recovery path, and an inductive category learner for credit assignment and knowledge correction.
Reference: [Huffman and Laird, 1994] <author> S. B. Huffman and J. E. Laird. </author> <title> Learning from highly flexible tutorial instruction. </title> <booktitle> In Proceedings of the 12th National Conference on Artificial Intelligence (AAAI-94), </booktitle> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: In this note, we describe an extension to IMPROV that allows an instructor to interactively guide various stages of the recovery process. The extension integrates IMPROV with Instructo-Soar <ref> [Huffman and Laird, 1994; Huffman, 1994] </ref>, an instructable agent that engages in an interactive natural language dialogue with an instructor to learn new tasks and other kinds of domain knowledge. Combining learning from instruction with recovery from incorrect knowledge makes both techniques stronger. <p> Next, we discuss IMPROV's recovery technique applied to the error, first with no instruction available, and then with instruction for each of the stages of the recovery process in turn. 2 Errorful knowledge learned from instruction Instructo-Soar uses a technique called situated explanation <ref> [Huffman, 1994; Huffman and Laird, 1994] </ref> to learn from instructions. Situated explanation combines analytic and inductive learning methods to learn new procedures and extensions of procedures for novel situations, and other domain knowledge such as control knowledge, knowledge of operators' effects, and state inferences.
Reference: [Huffman, 1994] <author> S. B. Huffman. </author> <title> Instructable autonomous agents. </title> <type> PhD thesis, </type> <institution> University of Michi-gan, Dept. of Electrical Engineering and Computer Science, </institution> <year> 1994. </year>
Reference-contexts: In this note, we describe an extension to IMPROV that allows an instructor to interactively guide various stages of the recovery process. The extension integrates IMPROV with Instructo-Soar <ref> [Huffman and Laird, 1994; Huffman, 1994] </ref>, an instructable agent that engages in an interactive natural language dialogue with an instructor to learn new tasks and other kinds of domain knowledge. Combining learning from instruction with recovery from incorrect knowledge makes both techniques stronger. <p> Next, we discuss IMPROV's recovery technique applied to the error, first with no instruction available, and then with instruction for each of the stages of the recovery process in turn. 2 Errorful knowledge learned from instruction Instructo-Soar uses a technique called situated explanation <ref> [Huffman, 1994; Huffman and Laird, 1994] </ref> to learn from instructions. Situated explanation combines analytic and inductive learning methods to learn new procedures and extensions of procedures for novel situations, and other domain knowledge such as control knowledge, knowledge of operators' effects, and state inferences.
Reference: [Miller, 1991] <author> Craig M. Miller. </author> <title> A constraint-motivated model of concept formation. </title> <booktitle> In The Thirteenth Annual Conference of the Cognitive Science Society, </booktitle> <pages> pages 827-831, </pages> <year> 1991. </year>
Reference-contexts: In the light example, both the correct and incorrect plans contain a single operator (push-button) with different instantiations, so it is identified as the erroneous operator. Once the operators with incorrect knowledge have been identified, IMPROV uses an incremental inductive category learner, SCA <ref> [Miller, 1991; Miller, 1993] </ref>, to identify how the operator is incorrect. The category being learned is which operator to select for a given state and goal. IMPROV is currently limited to correcting operator precondition knowledge.
Reference: [Miller, 1993] <author> Craig M. Miller. </author> <title> A model of concept acquisition in the context of a unified theory of cognition. </title> <type> PhD thesis, </type> <institution> The University of Michigan, Dept. of Computer Science and Electrical Engineering, </institution> <year> 1993. </year>
Reference-contexts: In the light example, both the correct and incorrect plans contain a single operator (push-button) with different instantiations, so it is identified as the erroneous operator. Once the operators with incorrect knowledge have been identified, IMPROV uses an incremental inductive category learner, SCA <ref> [Miller, 1991; Miller, 1993] </ref>, to identify how the operator is incorrect. The category being learned is which operator to select for a given state and goal. IMPROV is currently limited to correcting operator precondition knowledge. <p> As this induction is made without access to a causal theory or other knowledge source, the inductive guess may be wrong, leading to a future error and the need for another recovery. However, as the planner is complete and SCA can represent arbitrarily complex categories <ref> [Miller, 1993] </ref>, 2 the system will eventually converge to the correct knowledge. 4 Instruction to inform recovery We have augmented IMPROV by allowing an instructor to interrupt the recovery process at any time and provide instructions that guide the recovery.
Reference: [Mitchell et al., 1986] <author> Tom M. Mitchell, R. M. Keller, and S. T. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <year> 1986. </year>
Reference-contexts: Then, the agent attempts to explain, using a forward projection, why the instruction will lead to success in the situation. If this explanation succeeds, the agent can learn general knowledge from the in-struction (as in standard EBL <ref> [Mitchell et al., 1986] </ref>). If the explanation fails, it means the agent is missing some knowledge required to complete the explanation. The missing knowledge can be acquired either through further instruction, or in some cases through simple induction over the "gap" in the incomplete explanation.
Reference: [Murphy and Pazzani, 1994] <author> Patrick M. Murphy and Michael J. Pazzani. </author> <title> Revision of production system rule-bases. </title> <booktitle> In Proceedings of the International Conference on Machine Learning, </booktitle> <pages> pages 199-207, </pages> <year> 1994. </year>
Reference-contexts: Thus, techniques for recovery from incorrect knowledge generally rely on weak inductive methods to correct the knowledge and then re-planning to resolve the current performance failure (e.g. EITHER [Ourston and Mooney, 1990], CLIPS-R <ref> [Murphy and Pazzani, 1994] </ref> and Classifiers [Holland, 1986]). IMPROV [Pearson and Laird, 1995], the recovery system used in this work, uses a weakly constrained search in the environment to find a recovery path, and an inductive category learner for credit assignment and knowledge correction.
Reference: [Ourston and Mooney, 1990] <author> Dirk Ourston and Ray-mond J. Mooney. </author> <title> Changing the rules: A comprehensive approach to theory refinement. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 815-820, </pages> <year> 1990. </year>
Reference-contexts: Second, the agent must determine what knowledge caused the failure (a difficult credit assignment problem) and how to correct that knowledge. Thus, techniques for recovery from incorrect knowledge generally rely on weak inductive methods to correct the knowledge and then re-planning to resolve the current performance failure (e.g. EITHER <ref> [Ourston and Mooney, 1990] </ref>, CLIPS-R [Murphy and Pazzani, 1994] and Classifiers [Holland, 1986]). IMPROV [Pearson and Laird, 1995], the recovery system used in this work, uses a weakly constrained search in the environment to find a recovery path, and an inductive category learner for credit assignment and knowledge correction.
Reference: [Pearson and Laird, 1995] <author> Douglas J. Pearson and John E. Laird. </author> <title> Toward incremental knowledge correction for agents in complex environments. </title> <editor> In Stephen Muggleton, Donald Michie, and Koichi Fu-rukawa, editors, </editor> <booktitle> Machine Intelligence, </booktitle> <volume> volume 15. </volume> <publisher> Oxford University Press, </publisher> <year> 1995. </year>
Reference-contexts: Thus, techniques for recovery from incorrect knowledge generally rely on weak inductive methods to correct the knowledge and then re-planning to resolve the current performance failure (e.g. EITHER [Ourston and Mooney, 1990], CLIPS-R [Murphy and Pazzani, 1994] and Classifiers [Holland, 1986]). IMPROV <ref> [Pearson and Laird, 1995] </ref>, the recovery system used in this work, uses a weakly constrained search in the environment to find a recovery path, and an inductive category learner for credit assignment and knowledge correction.
References-found: 9

