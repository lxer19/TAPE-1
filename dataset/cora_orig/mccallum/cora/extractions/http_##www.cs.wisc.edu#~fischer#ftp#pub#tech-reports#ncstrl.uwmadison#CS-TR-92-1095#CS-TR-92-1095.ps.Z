URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1095/CS-TR-92-1095.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1095/
Root-URL: http://www.cs.wisc.edu
Title: Resource Allocation and Scheduling for Mixed Database Workloads  
Author: Kurt P. Brown Michael J. Carey David J. DeWitt Manish Mehta Jeffrey F. Naughton 
Note: This research was partially supported by IBM Corporation through a Research Initiation Grant and by the National Science Foundation under grants IRI-8657323 and IRI-9157357.  
Address: 1210 West Dayton Street Madison, WI 53706  
Affiliation: Computer Sciences Department University of Wisconsin  
Abstract: This paper investigates resource management and scheduling issues that arise when a relational DBMS is faced with a workload containing both short on-line transactions and long-running queries. Relevant issues include (i) how memory should be divided among the transactions and queries, (ii) the impact of serial versus concurrent execution of long-running queries, and (iii) tradeoffs between different scheduling strategies for complex multi-join queries. Through a series of simulation experiments based on a detailed DBMS simulation model, we show that previously proposed resource allocation and scheduling algorithms are inadequate for handling mixed workloads. One particularly interesting example of this occurs when running a query together with a stream of transactions: in many cases, beginning with the memory allocation deemed optimal by previously proposed buffer management schemes, taking memory away from the query improves the performance of both the transactions and the query. 
Abstract-found: 1
Intro-found: 1
Reference: [Agra89] <author> Agrawal, D. and Sengupta, S., </author> <title> "Modular Syncronization in Multiversion Databases: Version Control and Concurrency Control," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Bobe92a] <author> Bober, P., and Carey, M., </author> <title> "On Mixing Queries and Transactions via Multiversion Locking," </title> <booktitle> Proc. 8th IEEE Data Engineering Conf., </booktitle> <address> Phoenix, AZ, </address> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Bobe92b] <author> Bober, P., and Carey, M., </author> <title> "Multiversion Query Locking," </title> <booktitle> Proc. 18th Int'l. VLDB Conf., </booktitle> <address> Vancouver, BC, Canada, </address> <month> Aug. </month> <year> 1992, </year> <note> to appear. </note>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Bora90] <author> Boral, H. et al, </author> <title> "Prototyping Bubba: A Highly Parallel Database System," </title> <journal> IEEE Trans. on Knowledge and Data Engineering 2(1), </journal> <month> March </month> <year> 1990. </year>
Reference-contexts: As we will show in Section 4, such a narrow view of the buffer allocation problem can have serious negative performance consequences. A different approach to memory management was used by the Bubba parallel DBMS prototype <ref> [Cope88, Bora90] </ref>. A portion of Bubba's memory is dedicated to whole file caching, and files are placed in this cache in decreasing order of temperature. File temperature is defined as the ratio of a file's access rate (in block references per unit time) to its size (in blocks).
Reference: [Care86] <author> Carey, M. and Muhananna, W., </author> <title> "The Performance of Multiversion Concurrency Control Algorithms," </title> <journal> ACM TODS, </journal> <volume> 8(4), </volume> <month> December </month> <year> 1983. </year>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Chan82] <author> Chan, A., et al, </author> <title> "The Implementation of an Integrated Concurrency Control and Recovery Scheme," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1982. </year>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Chen92] <author> Chen, M., Yu, P., Wu, K., </author> <title> "Scheduling and Processor Allocation for Parallel Execution of Multi-Join Queries," </title> <booktitle> Proc. 8th IEEE Data Engineering Conf., </booktitle> <address> Phoenix, AZ, </address> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: In many instances, taking memory away from the join can actually improve the performance of both the short transactions and the join. Another example of the multiclass tradeoffs of interest here is in the area of complex, multi-join query scheduling. Most previously proposed complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref> attempt to maximize the utilization of resources in order to achieve minimum response times for complex queries, typically assuming that the entire system is available for allocation to any individual query. <p> Loosely related work exists in the area of buffer management algorithms [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] and complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. The algorithms proposed in both of these areas are less than ideal, however, when applied to workloads such as the one described in the introduction, as we will explain in the remainder of this section. <p> In the area of query scheduling, the vast majority of the literature concentrates on execution strategies for individual multi-join queries <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. None of this work addresses cases where another workload class competes with the multi-join queries for system resources, and as a result, the tradeoffs involved with allowing more than one of these queries to execute simultaneously with other workload components are as yet unexplored.
Reference: [Chou85] <author> Chou, H., and DeWitt, D., </author> <title> "An Evaluation of Buffer Management Strategies for Relational Database Systems, </title> <booktitle> Proc. 11th Int'l. VLDB Conf., </booktitle> <address> Stockholm, Sweden, </address> <month> Aug. </month> <year> 1985. </year>
Reference-contexts: Since there is no locality of reference within any given small transaction, previously proposed algorithms for relational database buffer management, such as <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, would allocate just one page (or at most a few pages) to each small transaction, allocating the remainder of the available memory to the join query. <p> Loosely related work exists in the area of buffer management algorithms <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref> and complex query scheduling strategies [Murp89, Schn90, Murp91, Wils91, Chen92]. <p> In the area of buffer management, two early algorithms proposed as alternatives to basic global LRU schemes were DBMIN <ref> [Chou85] </ref> and Hot Set [Sacc86]. Both of these algorithms require the query optimizer to determine a specific memory allocation for each query, allowing a new query to begin execution only when sufficient memory is available. <p> This is basically what the DBMIN, Hot Set, Cornell/Yu, MG-x-y, and Predictive Load Control relational buffer allocation strategies would do for this workload <ref> [Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, since each would view the memory requirements of any individual transaction as minimal. Conservative: A query is only allocated the minimum amount of memory that it needs to execute (slightly more than the square root of the inner relation size, in pages).
Reference: [Cope88] <editor> Copeland, G., et al, </editor> <booktitle> "Data Placement in Bubba" Proc. ACM SIGMOD Conf., </booktitle> <address> Chicago, IL, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: As we will show in Section 4, such a narrow view of the buffer allocation problem can have serious negative performance consequences. A different approach to memory management was used by the Bubba parallel DBMS prototype <ref> [Cope88, Bora90] </ref>. A portion of Bubba's memory is dedicated to whole file caching, and files are placed in this cache in decreasing order of temperature. File temperature is defined as the ratio of a file's access rate (in block references per unit time) to its size (in blocks). <p> One issue is the frequency and granularity with which temperature statistics should be maintained and utilized, and another issue is how much memory should be devoted to file caching versus other uses. Copeland et al <ref> [Cope88] </ref> suggests that the proper amount can be chosen through a "5 minute rule" type of analysis [Gray87].
Reference: [Corn89] <author> Cornell, D., and Yu, P., </author> <title> "Integration of Buffer Management and Query Optimization in Relational Database Environment, </title> <booktitle> Proc. 15th VLDB Conf., </booktitle> <address> Amsterdam, The Netherlands, </address> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: Since there is no locality of reference within any given small transaction, previously proposed algorithms for relational database buffer management, such as <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, would allocate just one page (or at most a few pages) to each small transaction, allocating the remainder of the available memory to the join query. <p> Loosely related work exists in the area of buffer management algorithms <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref> and complex query scheduling strategies [Murp89, Schn90, Murp91, Wils91, Chen92]. <p> A loosely related approach, based on a static, global analysis of a relational DBMS workload containing a known query mix, was proposed by Cornell and Yu and was shown to outperform the Hot Set algorithm <ref> [Corn89] </ref>. The Cornell/Yu algorithm integrates query optimization and buffer management by iterating between an optimizer whose objective function takes buffer allocation into account and a queueing network model that predicts disk response times based on a specific buffer allocation. <p> This is basically what the DBMIN, Hot Set, Cornell/Yu, MG-x-y, and Predictive Load Control relational buffer allocation strategies would do for this workload <ref> [Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, since each would view the memory requirements of any individual transaction as minimal. Conservative: A query is only allocated the minimum amount of memory that it needs to execute (slightly more than the square root of the inner relation size, in pages).
Reference: [DeWi84] <author> DeWitt, D., et al, </author> <title> "Implementation Techniques for Main Memory Database Systems," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: Any result tuples from the queries are "sent back to the terminals", an operation that consumes some small amount of processor cycles for network protocol overheads. The join algorithm used in the simulator is the centralized version of the hybrid hash join algorithm <ref> [DeWi84, Schn89] </ref>. - 6 - The centralized hybrid hash join algorithm [DeWi84] operates in three phases. In the first phase, the algorithm uses a hash function to divide the inner (smaller) relation, R, into N partitions. <p> The join algorithm used in the simulator is the centralized version of the hybrid hash join algorithm [DeWi84, Schn89]. - 6 - The centralized hybrid hash join algorithm <ref> [DeWi84] </ref> operates in three phases. In the first phase, the algorithm uses a hash function to divide the inner (smaller) relation, R, into N partitions.
Reference: [DeWi90] <author> DeWitt, D., et al, </author> <title> "The Gamma Database Machine Project," </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: DATABASE SYSTEM MODEL Since our eventual goal is to investigate resource allocation and scheduling for parallel database systems, we have implemented a simulator for a parallel database machine. The simulator is based upon an earlier, event-driven simulation model of the Gamma parallel database machine <ref> [DeWi90] </ref>. <p> A hashed partitioning strategy is used, where a randomizing function is applied to the key attribute of each tuple to select a particular disk drive. As is the case with Gamma <ref> [DeWi90] </ref>, "point" queries of the form "X.y = constant", can be routed directly to the particular disk where the selected tuple resides if y is the partitioning attribute of relation X. 3.5. Disks The simulated disks model a Fujitsu Model M2266 (1 GB, 5.25") disk drive.
Reference: [DuBo82] <author> DuBourdieu, D., </author> <title> "Implementation of Distributed Transactions," </title> <booktitle> Proc. 6th Berkeley Workshop on Distributed Data Management and Computer Networks, </booktitle> <year> 1982. </year>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Effe84] <author> Effelsberg, W., and Haerder, T., </author> <title> "Principles of Database Buffer Management," </title> <journal> ACM Trans. on Database Systems 9(4), </journal> <month> Dec. </month> <year> 1984. </year>
Reference-contexts: Since there is no locality of reference within any given small transaction, previously proposed algorithms for relational database buffer management, such as <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, would allocate just one page (or at most a few pages) to each small transaction, allocating the remainder of the available memory to the join query. <p> Loosely related work exists in the area of buffer management algorithms <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref> and complex query scheduling strategies [Murp89, Schn90, Murp91, Wils91, Chen92].
Reference: [Falo91] <author> Faloutsos, C., Ng, R., and Sellis, T., </author> <title> "Predictive Load Control for Flexible Buffer Allocation," </title> <booktitle> Proc. 17th Int'l. VLDB Conf., </booktitle> <address> Barcelona, Spain, </address> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: Since there is no locality of reference within any given small transaction, previously proposed algorithms for relational database buffer management, such as <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, would allocate just one page (or at most a few pages) to each small transaction, allocating the remainder of the available memory to the join query. <p> Loosely related work exists in the area of buffer management algorithms <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref> and complex query scheduling strategies [Murp89, Schn90, Murp91, Wils91, Chen92]. <p> This work was extended in <ref> [Falo91] </ref>, where two performance-predictive algorithms were described for deciding, at runtime, how many buffers to allocate to a query's locality sets. One algorithm, Predictor-TP, is based on optimizing predicted throughput, and the other, Predictor-EDU, is based on predicted disk utilization. <p> This is basically what the DBMIN, Hot Set, Cornell/Yu, MG-x-y, and Predictive Load Control relational buffer allocation strategies would do for this workload <ref> [Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, since each would view the memory requirements of any individual transaction as minimal. Conservative: A query is only allocated the minimum amount of memory that it needs to execute (slightly more than the square root of the inner relation size, in pages). <p> In retrospect, this is perhaps not surprising; however, it is interesting to note that the former is still viewed as an open problem <ref> [Falo91] </ref>, and that the latter has received virtually no attention in any of the published work on relational database buffer management. Our experimental results also clearly demonstrate that good resource allocation decisions depend on some nontrivial interactions between the characteristics of the workload and the system configuration.
Reference: [Ghan90] <author> Ghandeharizadeh, S. and D. J. DeWitt, </author> <title> "Hybrid-Range Partitioning Strategy: A New Declustering Strategy for Multiprocessor Database Machines," </title> <booktitle> Proc. 16th VLDB Conf., </booktitle> <address> Melbourne, Australia, </address> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: Thus, there is still no notion of any competition for resources outside of the operators within the single query. - 5 - had been validated against the actual Gamma implementation; it had also been used extensively in previous work on parallel database machines <ref> [Ghan90, Schn90, Hsia91] </ref>. The new simulator, which is much more modular, is written in the CSIM/C++ process-oriented simulation language [Schw90].
Reference: [Gray87] <author> Gray, J., and Putzolu, F., </author> <title> "The 5 Minute Rule for Trading Memory for Disk Accesses and the 10 Byte Rule for Trading Memory for CPU Time," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> San Fransisco, CA, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: Copeland et al [Cope88] suggests that the proper amount can be chosen through a "5 minute rule" type of analysis <ref> [Gray87] </ref>. Although such an approach is appropriate for configuring a DBMS, it is not applicable for a run-time algorithm that must decide (based on the current system state) on an appropriate memory allocation for each query.
Reference: [Gray91] <author> Gray, J., ed., </author> <title> The Benchmark Handbook for Database and Transaction Processing Systems, </title> <publisher> Morgan Kauf-man Publishers, Inc., </publisher> <year> 1991. </year>
Reference-contexts: The workload parameters for these experiments are summarized in Table 2. Transactions each access a fairly large (100MB) relation that can be thought of as roughly corresponding to the Account file in the TPC/A and TPC/B benchmarks <ref> [Gray91] </ref>. Each query computes the join of two other randomly chosen relations, each the same size.
Reference: [Haas90] <author> Haas, L., et al, </author> <title> "Starburst Mid-Flight: As the Dust Clears," </title> <journal> IEEE Trans. on Knowledge and Data Eng. </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: CPU and Memory Management The CPU is scheduled using a round-robin policy. The buffer pool models a set of main memory page frames. Page replacement in the buffer pool is controlled via the LRU policy extended with "love/hate" hints (like those used in the Starburst buffer manager <ref> [Haas90] </ref>). These hints are provided by the various relational operators when fixed pages are unpinned. For example, "love" hints are given by the index scan operator to keep index pages in memory; "hate" hints are used by the sequential scan operator to prevent buffer pool flooding.
Reference: [Hong91] <author> Hong, W., and Stonebraker, M., </author> <title> "Optimization of Parallel Query Execution Plans in XPRS," </title> <booktitle> Proc. 1st Int'l. Conf. on Parallel and Distributed Information Systems, </booktitle> <address> Miami Beach, FL, </address> <month> Dec. </month> <year> 1991. </year> <month> - 26 </month> - 
Reference: [Hsia91] <author> Hsiao, H. I. and D. J. DeWitt, </author> <title> "A Performance Study of Three High-Availability Data Replication Strategies," </title> <booktitle> Proc. 1st Int'l. Conf. on Parallel and Distributed Information Systems, </booktitle> <address> Miami Beach, FL, </address> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Thus, there is still no notion of any competition for resources outside of the operators within the single query. - 5 - had been validated against the actual Gamma implementation; it had also been used extensively in previous work on parallel database machines <ref> [Ghan90, Schn90, Hsia91] </ref>. The new simulator, which is much more modular, is written in the CSIM/C++ process-oriented simulation language [Schw90].
Reference: [Livn87] <author> Livny, M., S. Khoshafian, and H. Boral, </author> <title> "Multi-Disk Management Algorithms," </title> <booktitle> Proc. ACM SIGMETRICS Conf., </booktitle> <address> Banff, Alberta, Canada, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: Database The database itself is modeled as a set of relations, each of which can can have one or more associated B+ tree indices. These indices can be either clustered or unclustered. In the case of multiple disks, all relations (and their associated indices) are declustered <ref> [Ries78, Livn87] </ref> (horizontally partitioned) across all the disks in the configuration. A hashed partitioning strategy is used, where a randomizing function is applied to the key attribute of each tuple to select a particular disk drive.
Reference: [Merc92] <author> Merchant, A., Wu, K., Yu, P., Chen, M., </author> <title> "Performance Analysis of Dynamic Finite Versioning for Concurrent Transactions and Query Processing," </title> <booktitle> Proc. ACM SIGMETRICS Conf., </booktitle> <address> Newport, RI, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Moha92] <author> Mohan, C., Pirahesh, H., Lorie, R., </author> <title> "Efficient and Flexible Methods for Transient Versioning of Records to Avoid Locking by Read-Only Transactions," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> San Diego, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Murp89] <author> Murhpy, M. and Rotem, D., </author> <title> "Effective Resource Utilization for Multiprocessor Join Execution," </title> <booktitle> Proc. 15th VLDB Conf., </booktitle> <address> Amsterdam, The Netherlands, </address> <month> Aug. </month> <year> 1989. </year>
Reference-contexts: In many instances, taking memory away from the join can actually improve the performance of both the short transactions and the join. Another example of the multiclass tradeoffs of interest here is in the area of complex, multi-join query scheduling. Most previously proposed complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref> attempt to maximize the utilization of resources in order to achieve minimum response times for complex queries, typically assuming that the entire system is available for allocation to any individual query. <p> Loosely related work exists in the area of buffer management algorithms [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] and complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. The algorithms proposed in both of these areas are less than ideal, however, when applied to workloads such as the one described in the introduction, as we will explain in the remainder of this section. <p> In the area of query scheduling, the vast majority of the literature concentrates on execution strategies for individual multi-join queries <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. None of this work addresses cases where another workload class competes with the multi-join queries for system resources, and as a result, the tradeoffs involved with allowing more than one of these queries to execute simultaneously with other workload components are as yet unexplored.
Reference: [Murp91] <author> Murhpy, M. and Shan, M., </author> <title> "Execution Plan Balancing," </title> <booktitle> Proc. 1st Int'l. Conf. on Parallel and Distributed Information Systems, </booktitle> <address> Miami Beach, FL, </address> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: In many instances, taking memory away from the join can actually improve the performance of both the short transactions and the join. Another example of the multiclass tradeoffs of interest here is in the area of complex, multi-join query scheduling. Most previously proposed complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref> attempt to maximize the utilization of resources in order to achieve minimum response times for complex queries, typically assuming that the entire system is available for allocation to any individual query. <p> Loosely related work exists in the area of buffer management algorithms [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] and complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. The algorithms proposed in both of these areas are less than ideal, however, when applied to workloads such as the one described in the introduction, as we will explain in the remainder of this section. <p> In the area of query scheduling, the vast majority of the literature concentrates on execution strategies for individual multi-join queries <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. None of this work addresses cases where another workload class competes with the multi-join queries for system resources, and as a result, the tradeoffs involved with allowing more than one of these queries to execute simultaneously with other workload components are as yet unexplored.
Reference: [Ng91] <author> Ng, R., </author> <title> et al "Flexible Buffer Allocation Based on Marginal Gains," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Denver, CO, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Since there is no locality of reference within any given small transaction, previously proposed algorithms for relational database buffer management, such as <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, would allocate just one page (or at most a few pages) to each small transaction, allocating the remainder of the available memory to the join query. <p> Loosely related work exists in the area of buffer management algorithms <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref> and complex query scheduling strategies [Murp89, Schn90, Murp91, Wils91, Chen92]. <p> In this case, queries will be forced to queue for memory unnecessarily because their buffer allocations are too high; as a result, buffer utilization will decrease and performance will be suboptimal. The MG-x-y family of was algorithms proposed in <ref> [Ng91] </ref> to provide better buffer utilization than DBMIN, especially in cases with concurrent data sharing, by allocating free buffers to the query that is able to get the most "marginal benefit" from them (where marginal benefit is defined as a decrease in the number of buffer misses). <p> This is basically what the DBMIN, Hot Set, Cornell/Yu, MG-x-y, and Predictive Load Control relational buffer allocation strategies would do for this workload <ref> [Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, since each would view the memory requirements of any individual transaction as minimal. Conservative: A query is only allocated the minimum amount of memory that it needs to execute (slightly more than the square root of the inner relation size, in pages).
Reference: [Pira90] <author> Pirahesh, H., et al, </author> <title> "Parallelism in Relational Database Systems: </title> <booktitle> Architectual Issues and Design Approaches," IEEE 2nd Int'l Symposium on Databases in Parallel and Distributed Systems, </booktitle> <address> Dublin, Ireland, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: RELATED WORK Besides the large volume of work related to data contention cited in the introduction, there has been little published work that specifically addresses mixed workloads. A recent issues paper by Pirahesh et al <ref> [Pira90] </ref> discussed the - 2 - mixed workload problem, but other than suggesting that a resource governor and a concept of priority are required, it does not address the resource allocation and scheduling aspects of the problem in any detail.
Reference: [Reis80] <author> Reiser, M. and S. Lavenberg, </author> <title> "Mean Value Analysis of Closed Multichain Queueing Networks," </title> <type> JACM 27(2), </type> <month> April </month> <year> 1980. </year>
Reference-contexts: Our first cut at such a model is based on a simple queueing network that we solve using the Mean Value Analysis (MVA) technique <ref> [Reis80] </ref>. Our model is composed of three servers: an infinite capacity server that models the terminal think time, a fixed-rate (load-independent) CPU server scheduled using the processor sharing discipline, and a fixed-rate disk server scheduled in a first-come, first-served manner. The model has two closed job classes, transactions and queries.
Reference: [Ries78] <author> Ries, D. and R. Epstein, </author> <title> Evaluation of Distribution Criteria for Distributed Database Systems, </title> <type> UCB/ERL Technical Report M78/22, </type> <institution> UC Berkeley, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: Database The database itself is modeled as a set of relations, each of which can can have one or more associated B+ tree indices. These indices can be either clustered or unclustered. In the case of multiple disks, all relations (and their associated indices) are declustered <ref> [Ries78, Livn87] </ref> (horizontally partitioned) across all the disks in the configuration. A hashed partitioning strategy is used, where a randomizing function is applied to the key attribute of each tuple to select a particular disk drive.
Reference: [Sacc86] <author> Sacca, D., and Schkolnik, M., </author> <title> "Buffer Management in Relational Database Systems," </title> <journal> ACM Trans. on Database Systems 11(4), </journal> <month> Dec. </month> <year> 1986. </year>
Reference-contexts: Since there is no locality of reference within any given small transaction, previously proposed algorithms for relational database buffer management, such as <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, would allocate just one page (or at most a few pages) to each small transaction, allocating the remainder of the available memory to the join query. <p> Loosely related work exists in the area of buffer management algorithms <ref> [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] </ref> and complex query scheduling strategies [Murp89, Schn90, Murp91, Wils91, Chen92]. <p> In the area of buffer management, two early algorithms proposed as alternatives to basic global LRU schemes were DBMIN [Chou85] and Hot Set <ref> [Sacc86] </ref>. Both of these algorithms require the query optimizer to determine a specific memory allocation for each query, allowing a new query to begin execution only when sufficient memory is available. <p> This is basically what the DBMIN, Hot Set, Cornell/Yu, MG-x-y, and Predictive Load Control relational buffer allocation strategies would do for this workload <ref> [Chou85, Sacc86, Corn89, Ng91, Falo91] </ref>, since each would view the memory requirements of any individual transaction as minimal. Conservative: A query is only allocated the minimum amount of memory that it needs to execute (slightly more than the square root of the inner relation size, in pages).
Reference: [Schn89] <author> Schneider, D. and D. DeWitt, </author> <title> "A Performance Evaluation of Four Parallel Join Algorithms in a Shared-Nothing Multiprocessor Environment," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Any result tuples from the queries are "sent back to the terminals", an operation that consumes some small amount of processor cycles for network protocol overheads. The join algorithm used in the simulator is the centralized version of the hybrid hash join algorithm <ref> [DeWi84, Schn89] </ref>. - 6 - The centralized hybrid hash join algorithm [DeWi84] operates in three phases. In the first phase, the algorithm uses a hash function to divide the inner (smaller) relation, R, into N partitions.
Reference: [Schn90] <author> Schneider, D. and D. DeWitt, </author> <title> "Tradeoffs in Processing Complex Join Queries via Hashing in Multiprocessor Database Machines," </title> <booktitle> Proc. 16th VLDB Conf., </booktitle> <address> Melbourne, Australia, </address> <month> Aug. </month> <year> 1990. </year>
Reference-contexts: In many instances, taking memory away from the join can actually improve the performance of both the short transactions and the join. Another example of the multiclass tradeoffs of interest here is in the area of complex, multi-join query scheduling. Most previously proposed complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref> attempt to maximize the utilization of resources in order to achieve minimum response times for complex queries, typically assuming that the entire system is available for allocation to any individual query. <p> Loosely related work exists in the area of buffer management algorithms [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] and complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. The algorithms proposed in both of these areas are less than ideal, however, when applied to workloads such as the one described in the introduction, as we will explain in the remainder of this section. <p> In the area of query scheduling, the vast majority of the literature concentrates on execution strategies for individual multi-join queries <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. None of this work addresses cases where another workload class competes with the multi-join queries for system resources, and as a result, the tradeoffs involved with allowing more than one of these queries to execute simultaneously with other workload components are as yet unexplored. <p> Thus, there is still no notion of any competition for resources outside of the operators within the single query. - 5 - had been validated against the actual Gamma implementation; it had also been used extensively in previous work on parallel database machines <ref> [Ghan90, Schn90, Hsia91] </ref>. The new simulator, which is much more modular, is written in the CSIM/C++ process-oriented simulation language [Schw90]. <p> Our final set of experiments compares two strategies for scheduling complex, multi-join queries concurrently with a workload of short transactions. We again compare the two extreme ends of the resource requirement spectrum, which in this context are the left-deep and right-deep query execution strategies <ref> [Schn90] </ref>. We close the section with a very brief look at how the behaviors we observed for centralized systems match up with those exhibited by parallel systems. 4.1. <p> As in the previous experiments, we use the Responsible memory allocation strategy for dividing memory between the queries and transactions. Several execution strategies (left-deep, right deep, and bushy) have been proposed in the literature for executing multi-join queries <ref> [Schn90] </ref>. Each exploits intra-query concurrency in a different manner, so they have very different resource requirements. Since there are a large number of possible execution strategies, we decided to study the impact of the two extreme ends of the spectrum left-deep and right-deep query plans. <p> 40 60 80 100 500 1500 2500 join file size (Mbytes) R s o s t m s s c Complex query (1), 1 transaction class, 5 disks, 100 transaction terminals Since left- versus right-deep query plan performance is known to be sensitive to to the availability of disk bandwidth <ref> [Schn90] </ref>, we also conducted a five-disk version of the same experiment. In this case, each of the join relations resides on a separate disk.
Reference: [Schw90] <author> Schwetman, H., </author> <title> CSIM Users' Guide, </title> <type> MCC Technical Report No. </type> <institution> ACT-126-90, Microelectronics and Computer Technology Corp., Austin, TX, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: The new simulator, which is much more modular, is written in the CSIM/C++ process-oriented simulation language <ref> [Schw90] </ref>. The simulator accurately captures the algorithms and techniques used in Gamma, although it is primarily used in the special case of a single node, (i.e. centralized) system for the work reported here.
Reference: [Shap86] <author> Shapiro, L., </author> <title> "Join Processing in Database Systems with Large Main Memories," </title> <journal> ACM TODS, </journal> <volume> 11(3), </volume> <month> Sept. </month> <year> 1986. </year>
Reference-contexts: The necessary visit counts at the disk and CPU are calculated in our model using the same techniques that cost-based query optimizers would use. For example, the average number of visits to the disk and CPU by a hybrid hash join can be calculated using the equations presented in <ref> [Shap86] </ref>. The service time per CPU visit can be calculated from the number of instructions needed to perform each operation and the MIPS rating of the processor. The disk service time for the transactions is modeled as the cost of a - 23 - single page I/O.
Reference: [Srin92] <author> Srinivasan, V. and Carey, M. J., </author> <title> "Compensation-Based On-Line Query Processing," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> San Diego, CA, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
Reference: [Wils91] <author> Wilschut, A., and Apers, P., </author> <title> "Dataflow Query Execution in a Parallel Main-Memory Environment," </title> <booktitle> Proc. 1st Int'l. Conf. on Parallel and Distributed Information Systems, </booktitle> <address> Miami Beach, FL, </address> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: In many instances, taking memory away from the join can actually improve the performance of both the short transactions and the join. Another example of the multiclass tradeoffs of interest here is in the area of complex, multi-join query scheduling. Most previously proposed complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref> attempt to maximize the utilization of resources in order to achieve minimum response times for complex queries, typically assuming that the entire system is available for allocation to any individual query. <p> Loosely related work exists in the area of buffer management algorithms [Effe84, Chou85, Sacc86, Corn89, Ng91, Falo91] and complex query scheduling strategies <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. The algorithms proposed in both of these areas are less than ideal, however, when applied to workloads such as the one described in the introduction, as we will explain in the remainder of this section. <p> In the area of query scheduling, the vast majority of the literature concentrates on execution strategies for individual multi-join queries <ref> [Murp89, Schn90, Murp91, Wils91, Chen92] </ref>. None of this work addresses cases where another workload class competes with the multi-join queries for system resources, and as a result, the tradeoffs involved with allowing more than one of these queries to execute simultaneously with other workload components are as yet unexplored.
Reference: [Wu91] <author> Wu, K., Yu, P., Chen, S., </author> <title> Dynamic Finite Versioning for Concurrent Transaction and Query Processing, </title> <type> TR # RC 16633, </type> <institution> IBM T.J. Watson Research Center, </institution> <month> March </month> <year> 1991. </year> <month> - 27 </month> - 
Reference-contexts: However, the problem of achieving good performance for workloads that involve a mix of these activities is still open. The majority of research on the mixed workload problem deals with techniques for handling the data contention that can arise between short on-line transactions and long-running decision-support queries <ref> [DuBo82, Chan82, Care86, Agra89, Wu91, Bobe92a, Bobe92b, Merc92, Moha92, Srin92] </ref>. Very little work has been published dealing with the issues of resource allocation and/or scheduling in a mixed workload environment.
References-found: 38

