URL: ftp://erc.cat.syr.edu/ece/choudhary/PASSION/passion_report.ps.Z
Refering-URL: http://www.ece.nwu.edu/~choudhar/passion/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: @npac.syr.edu  
Title: as  PASSION: Parallel And Scalable Software for Input-Output  
Author: Alok Choudhary Rajesh Bordawekar Michael Harry Rakesh Krishnaiyer Ravi Ponnusamy Tarvinder Singh Rajeev Thakur choudhar, rajesh, mharry, rakesh, ravi, tpsingh, thakur 
Address: Syracuse, NY 13244  
Affiliation: ECE Dept., NPAC and CASE Center, Syracuse University,  
Note: Also available  
Pubnum: CRPC Technical Report CRPC-TR94483-S  
Abstract: NPAC Technical Report SCCS-636, Sept. 1994 Abstract We are developing a software system called PASSION: Parallel And Scalable Software for Input-Output which provides software support for high performance parallel I/O. PASSION provides support at the language, compiler, runtime as well as file system level. PASSION provides runtime procedures for parallel access to files (read/write), as well as for out-of-core computations. These routines can either be used together with a compiler to translate out-of-core data parallel programs written in a language like HPF, or used directly by application programmers. A number of optimizations such as Two-Phase Access, Data Sieving, Data Prefetching and Data Reuse have been incorporated in the PASSION Runtime Library for improved performance. PASSION also provides an initial framework for runtime support for out-of-core irregular problems. The goal of the PASSION compiler is to automatically translate out-of-core data parallel programs to node programs for distributed memory machines, with calls to the PASSION Runtime Library. At the language level, PASSION suggests extensions to HPF for out-of-core programs. At the file system level, PASSION provides support for buffering and prefetching data from disks. A portable parallel file system is also being developed as part of this project, which can be used across homogeneous or heterogeneous networks of workstations. PASSION also provides support for integrating data and task parallelism using parallel I/O techniques. We have used PASSION to implement a number of out-of-core applications such as a Laplace's equation solver, 2D FFT, Matrix Multiplication, LU Decomposition, image processing applications as well as unstructured mesh kernels in molecular dynamics and computational fluid dynamics. We are currently in the process of using PASSION in applications in CFD (3D turbulent flows), molecular structure calculations, seismic computations, and earth and space science applications such as Four-Dimensional Data Assimilation. PASSION is currently available on the Intel Paragon, Touchstone Delta and iPSC/860. Efforts are underway to port it to the IBM SP-1 and SP-2 using the Vesta Parallel File System. fl This work was supported in part by NSF Young Investigator Award CCR-9357840, grants from Intel SSD and IBM Corp., in part by USRA CESDIS Contract # 5555-26 and also in part by ARPA under contract # DABT63-91-C-0028. The content of the information does not necessarily reflect the position or the policy of the US Government and no official endorsement should be inferred. Rajeev Thakur is supported by a Syracuse University Graduate Fellowship. Michael Harry is supported by an ARPA Assert Fellowship. Rakesh Krishnaiyer is supported by the CASE Center, a NY State Advance Technology Center. This work was performed in part using the Intel Touchstone Delta and Paragon Systems operated by Caltech on behalf of the Concurrent Supercomputing Consortium. Access to this facility was provided by CRPC. This work was also performed in part using the Intel iPSC/860 and IBM SP-1/SP-2 at NPAC, the IBM SP-1 at Argonne National Laboratory and the Intel Paragon at the Jet Propulsion Laboratory. 
Abstract-found: 1
Intro-found: 1
Reference: [ACFK94] <author> B. Avalani, A. Choudhary, I. Foster, and R. Krishnaiyer. </author> <title> Integrating Task and Data Parallelism Using Parallel I/O Techniques. </title> <booktitle> In to appear in Proceedings of the International Workshop on Parallel Processing, </booktitle> <address> Bangalore, India, </address> <month> December </month> <year> 1994. </year>
Reference-contexts: The files in this case are smaller as the data is distributed over multiple files. We have implemented these two models for an image processing application on the Intel IPSC-860, details about which can be found in <ref> [ACFK94] </ref>. 9 Related Work There has been some related research in software support for high performance parallel I/O. Vesta is a parallel file system designed and developed at IBM T. J. Watson Research Center [CFPB93, CF94] which supports logical partitioning of files.
Reference: [AS79] <author> W. Abu-Sufah. </author> <title> Improving the Performance of Virtual Memory Computers. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, University of Illinois, </institution> <year> 1979. </year>
Reference-contexts: There has been a lot of work done in compiler optimizations for data locality. These techniques are also applicable for compiling out-of-core programs. Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment <ref> [AS79] </ref>. Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe [Wol89b, WB87, Wol87, Wol89a]. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr [Car93, CK94]. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88].
Reference: [BBO + 83] <author> B. Brooks, R. Bruccoleri, B. Olafson, D. States, S. Swaminathan, and M. Karplus. CHARMM: </author> <title> A Program for Macromolecular Energy Minimization and Dynamic Calculations. </title> <journal> Journal of Computational Chemistry, </journal> <volume> 4:187, </volume> <year> 1983. </year>
Reference-contexts: This makes it possible to utilize various preprocessing strategies to perform optimizations. Preprocessing methods for in-core computations have been developed [MSS + 88, Pon94] for a variety of unstructured problems including explicit multigrid unstructured computational fluid dynamic solvers [Mav91, HB91], molecular dynamics codes (CHARMM, AMBER, GROMOS, etc.) <ref> [BBO + 83] </ref>, and diagonal or polynomial preconditioned iterative linear solvers [VSM90]. 9 Table 4: Out-of-core 2D-FFT for 4K fi 4K array (time in sec., Slab size as a fraction of local array size) Processors Slab size Slab size Slab size Slab size 1/16 1/8 1/4 1/2 32 596.54 537.89 499.78
Reference: [BCF + 93] <author> Z. Bozkus, A. Choudhary, G. Fox, T. Haupt, and S. Ranka. </author> <title> Fortran 90D/HPF compiler for distributed memory MIMD computers: Design, implementation, and performance results. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 351-360, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: Data Reuse is described in further detail in [TBC94a]. 19 5 Compiler Support This section discusses the issues involved in compiling I/O intensive problems. The PASSION compiler is targeted for languages like Fortran 90D <ref> [BCF + 93] </ref> and High Performance Fortran [For93], which provide explicit directives to distribute arrays across the processors of a parallel system.
Reference: [BCT94] <author> R. Bordawekar, A. Choudhary, and R. Thakur. </author> <title> Data Access Reorganizations in Compiling Out-of-core Data Parallel Programs on Distributed Memory Machines. </title> <type> Technical Report SCCS-622, </type> <institution> NPAC, Syracuse University, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: At Syracuse University, we are investigating the I/O problem from a software perspective, including languages, compilers, runtime support and file system optimizations. The overall project is called PASSION which stands for Parallel And Scalable Software for Input-Output. PASSION provides support for compiling out-of-core data parallel programs <ref> [TBC94a, BCT94] </ref>, parallel input-output of data and parallel access to files [BdRC93], communication of out-of-core data, redistribution of data stored on disks, many optimizations including Data Prefetching from disks, Data Sieving, Data Reuse etc., as well as support at the file system level. <p> With prefetching on the other hand, data blocks had already been prefetched when the request arrived. We also tested an out-of-core matrix multiplication algorithm discussed in <ref> [BCT94] </ref> and generated access pattern information using read dependency analysis. The results obtained are listed in Table 13.
Reference: [BdRC93] <author> R. Bordawekar, J. del Rosario, and A. Choudhary. </author> <title> Design and Evaluation of Primitives for Parallel I/O. </title> <booktitle> In Proceedings of Supercomputing'93, </booktitle> <pages> pages 452-461, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The overall project is called PASSION which stands for Parallel And Scalable Software for Input-Output. PASSION provides support for compiling out-of-core data parallel programs [TBC94a, BCT94], parallel input-output of data and parallel access to files <ref> [BdRC93] </ref>, communication of out-of-core data, redistribution of data stored on disks, many optimizations including Data Prefetching from disks, Data Sieving, Data Reuse etc., as well as support at the file system level. We have also developed an initial framework for runtime support for out-of-core irregular problems. <p> Parallel Access to Files: PASSION provides support for parallel access to files for read/write operations, supports distribution of data on parallel file systems as well as distribution and redistribution of data among the processors of a distributed memory machine. It uses the Two-Phase Access Strat egy <ref> [dRBC93, BdRC93] </ref> for this purpose. Section 3 describes this work in further detail. 2. Out-of-Core Computations: Out-of-Core Computations are those in which the primary data structures are too large to fit in main memory and hence reside on disks. PASSION provides runtime, compiler and language support for these computations. <p> It has been observed that I/O performance is very good in the case of conforming distributions. Other data distributions give much lower performance. To alleviate this problem, the Two Phase Access Strategy has been proposed in <ref> [Bor93, BdRC93, dRBC93] </ref>. <p> Since the redistribution cost is very small as compared to the file access cost, the cost of accessing data becomes independent of the data distribution on the disks. This is found to give consistently good performance for all distributions <ref> [Bor93, BdRC93, dRBC93] </ref>. The Two-Phase Approach provides the following advantages over the conventional Direct Access Method:- 1. The distribution of data on disks is effectively hidden from the user. 2. It uses the higher bandwidth of the interconnection network. 3. It uses collective communication and collective I/O operations. 4. <p> Hence the name Partitioned-Incore Model. The reading of each partition and its in-core distribution among processors is done by the PASSION runtime system using the Two-Phase Data Access Method <ref> [BdRC93, dRBC93] </ref>. This model is useful when the data access pattern in the program has good locality. Otherwise, creating in-core partitions itself is difficult. 4.2 Runtime Support In out-of-core computations, data needs to be moved back and forth between main memory and disks. <p> From our earlier studies <ref> [BdRC93, Bor93] </ref>, we observed that the best performance need not necessarily be obtained when all processors performing computations also perform I/O. Thus, this provides the user the flexibility to specify a set of processors to perform I/O.
Reference: [BGMZ92] <author> P. Brezany, M. Gerndt, P. Mehrotra, and H. Zima. </author> <title> Concurrent File Operations in a High Performance Fortran. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <pages> pages 230-238, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Languages like Fortran D, High Performance Fortran provide explicit directives to describe distribution of data on processors. However, no directives are provided to specify data distribution on disks. Various attempts have been made to provide compiler directives for describing data distribution on disks (Vienna Fortran <ref> [BGMZ92, ZBC + 92] </ref>, HPF [Sni92]). However at present there is no consensus about how the distribution information should be passed to the compiler. There exist several problems in defining such directives. The out-of-core arrays used in the programs are stored as files. <p> An excellent description of compiler transformations is given in [BGS93]. Wolf and Lam propose an elegant loop transformation theory to improve locality and parallelism [WL91, Wol92] Language extensions for out-of-core data parallel programs are proposed by the Vienna Fortran group <ref> [BGMZ92] </ref>. Marc Snir of IBM has submitted a proposal [Sni92] for I/O in HPF to the HPF Forum. 10 Conclusions PASSION provides software support for high performance parallel I/O on distributed memory parallel computers.
Reference: [BGS93] <author> D. Bacon, S. Graham, and O. Sharp. </author> <title> Compiler Transformations for High-Performance Computing. </title> <type> Technical Report UCB/CSD-93-781, </type> <institution> Computer Science Division, University of California, Berkeley, Computer Science Division, University of California, </institution> <address> Berkeleyley, California 94720, </address> <year> 1993. </year>
Reference-contexts: Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr [Car93, CK94]. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in <ref> [BGS93] </ref>. Wolf and Lam propose an elegant loop transformation theory to improve locality and parallelism [WL91, Wol92] Language extensions for out-of-core data parallel programs are proposed by the Vienna Fortran group [BGMZ92].
Reference: [Bor93] <author> R. Bordawekar. </author> <title> Issues in Software Support for Parallel I/O. </title> <type> Master's thesis, </type> <institution> Dept. of Electrical and Computer Engineering, Syracuse University, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: It has been observed that I/O performance is very good in the case of conforming distributions. Other data distributions give much lower performance. To alleviate this problem, the Two Phase Access Strategy has been proposed in <ref> [Bor93, BdRC93, dRBC93] </ref>. <p> Since the redistribution cost is very small as compared to the file access cost, the cost of accessing data becomes independent of the data distribution on the disks. This is found to give consistently good performance for all distributions <ref> [Bor93, BdRC93, dRBC93] </ref>. The Two-Phase Approach provides the following advantages over the conventional Direct Access Method:- 1. The distribution of data on disks is effectively hidden from the user. 2. It uses the higher bandwidth of the interconnection network. 3. It uses collective communication and collective I/O operations. 4. <p> From our earlier studies <ref> [BdRC93, Bor93] </ref>, we observed that the best performance need not necessarily be obtained when all processors performing computations also perform I/O. Thus, this provides the user the flexibility to specify a set of processors to perform I/O.
Reference: [Car93] <author> Steve Carr. </author> <title> Memory-Hierarchy Management. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79]. Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe [Wol89b, WB87, Wol87, Wol89a]. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr <ref> [Car93, CK94] </ref>. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93].
Reference: [CCK90] <author> David Callahan, Steve Carr, and Ken Kennedy. </author> <title> Improving Register Allocation for Subscripted Variables. </title> <booktitle> Proc. of SIGPLAN'90 Conference on Program Language Design and Implementation, </booktitle> <month> June </month> <year> 1990. </year>
Reference-contexts: Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe [Wol89b, WB87, Wol87, Wol89a]. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr [Car93, CK94]. Callahan studies the problem of register allocation <ref> [CCK90] </ref>. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93].
Reference: [CF94] <author> P. Corbett and D. Feitelson. </author> <title> Overview of the Vesta Parallel File System. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <pages> pages 63-70, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Vesta is a parallel file system designed and developed at IBM T. J. Watson Research Center <ref> [CFPB93, CF94] </ref> which supports logical partitioning of files. PIOUS [MS94] is a parallel file system for a networked computing environment. File declustering, where different blocks are stored on distinct disks is suggested in [LKB87].
Reference: [CFPB93] <author> P. Corbett, D. Feitelson, J. Prost, and S. Baylor. </author> <title> Parallel Access to Files in the Vesta File System. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <pages> pages 472-481, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The need for high performance I/O is so significant that almost all the present generation parallel computers such as the Paragon, iPSC/860, Touchstone Delta, CM-5, SP-2, nCUBE2 etc. provide some kind of hardware and software support for parallel I/O <ref> [CFPB93, Pie89, DdR92] </ref>. At Syracuse University, we are investigating the I/O problem from a software perspective, including languages, compilers, runtime support and file system optimizations. The overall project is called PASSION which stands for Parallel And Scalable Software for Input-Output. <p> Vesta is a parallel file system designed and developed at IBM T. J. Watson Research Center <ref> [CFPB93, CF94] </ref> which supports logical partitioning of files. PIOUS [MS94] is a parallel file system for a networked computing environment. File declustering, where different blocks are stored on distinct disks is suggested in [LKB87].
Reference: [CK89] <author> S. Carr and K. Kennedy. </author> <title> Blocking Linear Algebra Codes for Memory Hierarchies. </title> <booktitle> Proc. of the Fourth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <year> 1989. </year>
Reference-contexts: In order to reduce the I/O cost, either the computation can be reordered (iteration blocking, tiling <ref> [Iri88, SD90, WL91, CK89] </ref>) according to the placement of data in files (to take advantage of data locality) or data can be reordered in files according to the computation. Reordering of data in files results in extra overhead. However, computation reordering may not always be trivial.
Reference: [CK94] <author> Steve Carr and Ken Kennedy. </author> <title> Scalar Replacement in the Presence of Conditional Control Flow. </title> <journal> Software-Practice and Experience, </journal> <volume> 24(1) </volume> <pages> 51-77, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79]. Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe [Wol89b, WB87, Wol87, Wol89a]. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr <ref> [Car93, CK94] </ref>. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93].
Reference: [CKP91] <author> D. Callahan, K. Kennedy, and A. Porterfield. </author> <title> Software Prefetching. </title> <booktitle> In Proceedings of ASPLOS 91, </booktitle> <pages> pages 40-52, </pages> <year> 1991. </year>
Reference-contexts: Kotz et. al. [EK89] use pattern predictors to predict an application's future access patterns to perform prefetching. More recently, Patterson et. al. [PGS93] discuss the benefits of disclosing application level hints about future I/O accesses. Prefetching for in-core problems is discussed in <ref> [MLG92, CKP91] </ref>. The effects of prefetching blocks of a file in a multiprocessor file system are studied in [D. 90]. Joel Saltz and his group at the University of Maryland have developed the PARTI/CHAOS toolkit, which is a collection of runtime library routines to handle in-core irregular computations [DSB91, SBW91].
Reference: [Cro89] <author> T. Crockett. </author> <title> File Concepts for Parallel I/O. </title> <booktitle> In Proceedings of Supercomputing '89, </booktitle> <pages> pages 574-579, </pages> <year> 1989. </year>
Reference-contexts: This is used in the Bridge File System [DSE88], in Intel's Concurrent File System (CFS) [Pie89] and in various RAID schemes [PGK88]. There are several schemes that allow for the exploitation of access pattern information. Crockett <ref> [Cro89] </ref> discusses parallel file accesses in relation to possible storage techniques. Kotz et. al. [EK89] use pattern predictors to predict an application's future access patterns to perform prefetching. More recently, Patterson et. al. [PGS93] discuss the benefits of disclosing application level hints about future I/O accesses.
Reference: [D. 90] <author> D. Kotz and C. Ellis. </author> <title> Prefetching in File Systems for MIMD Multiprocessors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <pages> pages 218-230, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: More recently, Patterson et. al. [PGS93] discuss the benefits of disclosing application level hints about future I/O accesses. Prefetching for in-core problems is discussed in [MLG92, CKP91]. The effects of prefetching blocks of a file in a multiprocessor file system are studied in <ref> [D. 90] </ref>. Joel Saltz and his group at the University of Maryland have developed the PARTI/CHAOS toolkit, which is a collection of runtime library routines to handle in-core irregular computations [DSB91, SBW91]. Compilation methods for irregular problems have been investigated by Ponnusamy [Pon94], Das [DPSM92] and Hanxleden [vKK + 92].
Reference: [DdR92] <author> E. DeBenedictis and J. del Rosario. </author> <title> nCUBE parallel i/o software. </title> <booktitle> In Proceedings of 11 th International Phoenix Conference on Computers and Communications, </booktitle> <pages> pages 117-124, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: The need for high performance I/O is so significant that almost all the present generation parallel computers such as the Paragon, iPSC/860, Touchstone Delta, CM-5, SP-2, nCUBE2 etc. provide some kind of hardware and software support for parallel I/O <ref> [CFPB93, Pie89, DdR92] </ref>. At Syracuse University, we are investigating the I/O problem from a software perspective, including languages, compilers, runtime support and file system optimizations. The overall project is called PASSION which stands for Parallel And Scalable Software for Input-Output.
Reference: [DMS + 94] <author> R. Das, D. J. Mavriplis, J. Saltz, S. Gupta, and R. Ponnusamy. </author> <title> The Design and Implementation of a Parallel Unstructured Euler Solver Using Software Primitives. </title> <journal> AIAA Journal, </journal> <volume> 32(3) </volume> <pages> 489-496, </pages> <month> March </month> <year> 1994. </year>
Reference-contexts: This array is called an indirection array. Prior knowledge of loop data access patterns (values of indir) makes it possible to predict which data elements need to be communicated between processors. By pre-processing data access patterns, optimizations such as software caching and communication vectorization <ref> [DMS + 94] </ref> can be performed. We have developed runtime routines in PASSION to solve out-of-core irregular problems on distributed memory machines. The out-of-core pre-processing phase analyzes data access patterns and computes a communication schedule [MSS + 88] as well as an I/O schedule. <p> It also determines the size of the extra buffer space needed for out-of-partition data for computation on each partition. Localization and schedule generation procedures are used for this step. * Perform address translation for references to out-of-partition elements <ref> [DMS + 94] </ref>. 4.4.3 Computation If there are P processing nodes, the computation involves reading in P partitions at a time from disks, evaluating partial results and storing them back on disks [Figure 9]. This process is repeated for all partitions and partial results are gathered.
Reference: [DPSM92] <author> R. Das, R. Ponnusamy, J. Saltz, and D. Mavriplis. </author> <title> Distributed Memory Compiler Methods for Irregular Problems Data Copy Reuse and Runtime Partitioning. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <booktitle> Languages, Compilers and Runtime Environments for Distributed Memory Machines, </booktitle> <pages> pages 185-220. </pages> <publisher> Elsevier Science Publishers, </publisher> <year> 1992. </year>
Reference-contexts: Joel Saltz and his group at the University of Maryland have developed the PARTI/CHAOS toolkit, which is a collection of runtime library routines to handle in-core irregular computations [DSB91, SBW91]. Compilation methods for irregular problems have been investigated by Ponnusamy [Pon94], Das <ref> [DPSM92] </ref> and Hanxleden [vKK + 92]. There has been a lot of work done in compiler optimizations for data locality. These techniques are also applicable for compiling out-of-core programs. Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79].
Reference: [dRBC93] <author> J. del Rosario, R. Bordawekar, and A. Choudhary. </author> <title> Improved parallel i/o via a two-phase runtime access strategy. </title> <booktitle> In Proceedings of the Workshop on I/O in Parallel Computer Systems at IPPS '93, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: Parallel Access to Files: PASSION provides support for parallel access to files for read/write operations, supports distribution of data on parallel file systems as well as distribution and redistribution of data among the processors of a distributed memory machine. It uses the Two-Phase Access Strat egy <ref> [dRBC93, BdRC93] </ref> for this purpose. Section 3 describes this work in further detail. 2. Out-of-Core Computations: Out-of-Core Computations are those in which the primary data structures are too large to fit in main memory and hence reside on disks. PASSION provides runtime, compiler and language support for these computations. <p> It has been observed that I/O performance is very good in the case of conforming distributions. Other data distributions give much lower performance. To alleviate this problem, the Two Phase Access Strategy has been proposed in <ref> [Bor93, BdRC93, dRBC93] </ref>. <p> Since the redistribution cost is very small as compared to the file access cost, the cost of accessing data becomes independent of the data distribution on the disks. This is found to give consistently good performance for all distributions <ref> [Bor93, BdRC93, dRBC93] </ref>. The Two-Phase Approach provides the following advantages over the conventional Direct Access Method:- 1. The distribution of data on disks is effectively hidden from the user. 2. It uses the higher bandwidth of the interconnection network. 3. It uses collective communication and collective I/O operations. 4. <p> Hence the name Partitioned-Incore Model. The reading of each partition and its in-core distribution among processors is done by the PASSION runtime system using the Two-Phase Data Access Method <ref> [BdRC93, dRBC93] </ref>. This model is useful when the data access pattern in the program has good locality. Otherwise, creating in-core partitions itself is difficult. 4.2 Runtime Support In out-of-core computations, data needs to be moved back and forth between main memory and disks. <p> No computation or synchronization is done on the LDI side of the system. The only exception to this is in the case of collective read accesses. Collective read access is a modified form of the two-phase access paradigm developed by del Rosario, Bordawekar, and Choudhary <ref> [dRBC93] </ref>.
Reference: [dRC94] <author> J. del Rosario and A. Choudhary. </author> <title> High performance i/o for parallel computers: Problems and prospects. </title> <booktitle> IEEE Computer, </booktitle> <month> March </month> <year> 1994. </year>
Reference-contexts: For example, a typical Grand Challenge Application at present could require 1Gbyte to 4Tbytes of data per run <ref> [dRC94] </ref>. These figures are expected to increase by orders of magnitude as teraflop machines make their appearance. Although supercomputers have very large main memories, the memory is not large enough to hold this much amount of data.
Reference: [dRHC94] <author> J. del Rosario, M. Harry, and A. Choudhary. </author> <title> The Design of VIP-FS: A Virtual Parallel File System for High Performance Parallel and Distributed Computing. </title> <type> Technical Report SCCS-628, </type> <institution> NPAC, Syracuse University, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: In an effort to provide a simple straight-forward interface to parallel I/O that is available in many environments we have developed VIP-FS, a VIrtual Parallel File System <ref> [dRHC94] </ref>. VIP-FS is a portable parallel file system for distributed computing that provides high level data mapping abstractions. The file system is deemed a virtual file system because it is implemented using multiple individual standard file systems integrated by a message passing system.
Reference: [DSB91] <author> R. Das, J. Saltz, and H. Berryman. </author> <title> A Manual for PARTI Runtime Primitives. </title> <type> Interim Report 17, </type> <institution> ICASE, NASA Langley Research Center, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: The effects of prefetching blocks of a file in a multiprocessor file system are studied in [D. 90]. Joel Saltz and his group at the University of Maryland have developed the PARTI/CHAOS toolkit, which is a collection of runtime library routines to handle in-core irregular computations <ref> [DSB91, SBW91] </ref>. Compilation methods for irregular problems have been investigated by Ponnusamy [Pon94], Das [DPSM92] and Hanxleden [vKK + 92]. There has been a lot of work done in compiler optimizations for data locality. These techniques are also applicable for compiling out-of-core programs.
Reference: [DSE88] <author> P. Dibble, M. Scott, and C. Ellis. </author> <title> Bridge: A High-Performance File System for Parallel Processors. </title> <booktitle> In Proceedings of the Eighth International Conference on Distributed Computer Systems, </booktitle> <pages> pages 154-161, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: J. Watson Research Center [CFPB93, CF94] which supports logical partitioning of files. PIOUS [MS94] is a parallel file system for a networked computing environment. File declustering, where different blocks are stored on distinct disks is suggested in [LKB87]. This is used in the Bridge File System <ref> [DSE88] </ref>, in Intel's Concurrent File System (CFS) [Pie89] and in various RAID schemes [PGK88]. There are several schemes that allow for the exploitation of access pattern information. Crockett [Cro89] discusses parallel file accesses in relation to possible storage techniques.
Reference: [EK89] <author> C. Ellis and D. Kotz. </author> <title> Prefetching in file systems for MIMD multiprocessors. </title> <booktitle> In Proceedings of the 1989 International Conference on Parallel Processing, </booktitle> <pages> pages I:306-314, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: There are several schemes that allow for the exploitation of access pattern information. Crockett [Cro89] discusses parallel file accesses in relation to possible storage techniques. Kotz et. al. <ref> [EK89] </ref> use pattern predictors to predict an application's future access patterns to perform prefetching. More recently, Patterson et. al. [PGS93] discuss the benefits of disclosing application level hints about future I/O accesses. Prefetching for in-core problems is discussed in [MLG92, CKP91].
Reference: [FAXC94] <author> I. Foster, B. Avalani, M. Xu, and A. Choudhary. </author> <title> A Compilation System that Integrates High Performance Fortran and Fortran M. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: These include redistribution of data at the time of communication, protocol for communication, providing information about the distribution in one task to the other etc. This work addresses these issues. In an integrated data/task parallel system <ref> [FAXC94] </ref>, CHANNELS can be used as a mode of communication between data parallel tasks. We use parallel I/O techniques to implement CHANNELS. A CHANNEL provides a uniform mode of communicating data between two data parallel tasks. Programs are constructed by using CHANNELS to plug together concurrent tasks.
Reference: [For93] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran Language Specification Version 1.0. </title> <type> Technical Report CRPC-TR92225, </type> <institution> Center for Research in Parallel Computing,Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: Data Reuse is described in further detail in [TBC94a]. 19 5 Compiler Support This section discusses the issues involved in compiling I/O intensive problems. The PASSION compiler is targeted for languages like Fortran 90D [BCF + 93] and High Performance Fortran <ref> [For93] </ref>, which provide explicit directives to distribute arrays across the processors of a parallel system. The compiler support is intended for programs with arrays that are too large to fit in main memory (out-of-core arrays) and for programs in which data has to be read from files.
Reference: [FWM94] <author> G. Fox, R. Williams, and P. Messina. </author> <title> Parallel Computing Works. </title> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <year> 1994. </year>
Reference-contexts: We have also developed an initial framework for runtime support for out-of-core irregular problems. This report gives an overview of the design and implementation of the various components of PASSION. 2 PASSION Overview PASSION provides software support for I/O intensive loosely synchronous problems <ref> [FWM94] </ref>. It has a layered approach and provides support at the compiler, runtime support and file system levels as shown in later sections. Further details may be obtained from papers and reports listed in Section 11. 1.
Reference: [HB91] <author> S. Hammond and T. Barth. </author> <title> An Optimal Massively Parallel Euler Solver for Unstructured Grids. </title> <journal> AIAA Journal, </journal> <note> AIAA Paper 91-0441, </note> <month> January </month> <year> 1991. </year>
Reference-contexts: This makes it possible to utilize various preprocessing strategies to perform optimizations. Preprocessing methods for in-core computations have been developed [MSS + 88, Pon94] for a variety of unstructured problems including explicit multigrid unstructured computational fluid dynamic solvers <ref> [Mav91, HB91] </ref>, molecular dynamics codes (CHARMM, AMBER, GROMOS, etc.) [BBO + 83], and diagonal or polynomial preconditioned iterative linear solvers [VSM90]. 9 Table 4: Out-of-core 2D-FFT for 4K fi 4K array (time in sec., Slab size as a fraction of local array size) Processors Slab size Slab size Slab size Slab
Reference: [Iri88] <author> Francois Irigoin. </author> <title> Code Generation for the Hyperplane Method and for Loop Interchange. </title> <type> Technical Report E102, </type> <institution> Ecole Des Mines De Paris, </institution> <month> October </month> <year> 1988. </year>
Reference-contexts: In order to reduce the I/O cost, either the computation can be reordered (iteration blocking, tiling <ref> [Iri88, SD90, WL91, CK89] </ref>) according to the placement of data in files (to take advantage of data locality) or data can be reordered in files according to the computation. Reordering of data in files results in extra overhead. However, computation reordering may not always be trivial. <p> Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe [Wol89b, WB87, Wol87, Wol89a]. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr [Car93, CK94]. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality <ref> [Iri88] </ref>. An excellent description of compiler transformations is given in [BGS93]. Wolf and Lam propose an elegant loop transformation theory to improve locality and parallelism [WL91, Wol92] Language extensions for out-of-core data parallel programs are proposed by the Vienna Fortran group [BGMZ92].
Reference: [Kot94] <author> D. Kotz. </author> <title> Disk-directed I/O for MIMD Multiprocessors. </title> <type> Technical Report PCS-TR94-226, </type> <institution> Dept. of Computer Science, Dartmouth College, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: Using local dataflow analysis, the compiler determines what data can be accessed using a single I/O request. The dataflow information can also be used to place I/O calls so that the overall I/O cost can be reduced. Strategies like two-phase access and disk-directed I/O <ref> [Kot94] </ref> can be used to optimize I/O from disks. Inter and Intra File Organizations: The final step in the local program optimization involves organization of data across files and within files. Depending on the underlying execution model, the compiler generates local array files.
Reference: [LKB87] <author> M. Livny, S. Khoshafian, and H. Boral. </author> <title> Multi-Disk Management Algorithms. </title> <booktitle> In Proceedings of the 1987 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 69-77, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Vesta is a parallel file system designed and developed at IBM T. J. Watson Research Center [CFPB93, CF94] which supports logical partitioning of files. PIOUS [MS94] is a parallel file system for a networked computing environment. File declustering, where different blocks are stored on distinct disks is suggested in <ref> [LKB87] </ref>. This is used in the Bridge File System [DSE88], in Intel's Concurrent File System (CFS) [Pie89] and in various RAID schemes [PGK88]. There are several schemes that allow for the exploitation of access pattern information. Crockett [Cro89] discusses parallel file accesses in relation to possible storage techniques.
Reference: [Mav91] <author> D. J. Mavriplis. </author> <title> Three Dimensional Unstructured Multigrid for the Euler Equations. </title> <booktitle> In AIAA 10th Computational Fluid Dynamics Conference, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: This makes it possible to utilize various preprocessing strategies to perform optimizations. Preprocessing methods for in-core computations have been developed [MSS + 88, Pon94] for a variety of unstructured problems including explicit multigrid unstructured computational fluid dynamic solvers <ref> [Mav91, HB91] </ref>, molecular dynamics codes (CHARMM, AMBER, GROMOS, etc.) [BBO + 83], and diagonal or polynomial preconditioned iterative linear solvers [VSM90]. 9 Table 4: Out-of-core 2D-FFT for 4K fi 4K array (time in sec., Slab size as a fraction of local array size) Processors Slab size Slab size Slab size Slab
Reference: [MLG92] <author> T. Mowry, M. Lam, and A. Gupta. </author> <title> Design and Evaluation of a Compiler Algorithm for Prefetching. </title> <booktitle> Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 62-73, </pages> <year> 1992. </year>
Reference-contexts: Kotz et. al. [EK89] use pattern predictors to predict an application's future access patterns to perform prefetching. More recently, Patterson et. al. [PGS93] discuss the benefits of disclosing application level hints about future I/O accesses. Prefetching for in-core problems is discussed in <ref> [MLG92, CKP91] </ref>. The effects of prefetching blocks of a file in a multiprocessor file system are studied in [D. 90]. Joel Saltz and his group at the University of Maryland have developed the PARTI/CHAOS toolkit, which is a collection of runtime library routines to handle in-core irregular computations [DSB91, SBW91].
Reference: [MS94] <author> S. Moyer and V. Sunderam. </author> <title> PIOUS: A Scalable Parallel I/O System for Distributed Computing Environments. </title> <booktitle> In Proceedings of the Scalable High Performance Computing Conference, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: Vesta is a parallel file system designed and developed at IBM T. J. Watson Research Center [CFPB93, CF94] which supports logical partitioning of files. PIOUS <ref> [MS94] </ref> is a parallel file system for a networked computing environment. File declustering, where different blocks are stored on distinct disks is suggested in [LKB87]. This is used in the Bridge File System [DSE88], in Intel's Concurrent File System (CFS) [Pie89] and in various RAID schemes [PGK88].
Reference: [MSS + 88] <author> R. Mirchandaney, J. H. Saltz, R. M. Smith, D. M. Nicol, and Kay Crowley. </author> <title> Principles of Runtime Support for Parallel Processors. </title> <booktitle> In Proceedings of the 1988 ACM International Conference on Supercomputing, </booktitle> <pages> pages 140-152, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Hence, optimizations that can be carried out at compile-time are limited. At runtime, however, the data access patterns of a loop-nest are usually known before entering the loop-nest. This makes it possible to utilize various preprocessing strategies to perform optimizations. Preprocessing methods for in-core computations have been developed <ref> [MSS + 88, Pon94] </ref> for a variety of unstructured problems including explicit multigrid unstructured computational fluid dynamic solvers [Mav91, HB91], molecular dynamics codes (CHARMM, AMBER, GROMOS, etc.) [BBO + 83], and diagonal or polynomial preconditioned iterative linear solvers [VSM90]. 9 Table 4: Out-of-core 2D-FFT for 4K fi 4K array (time in <p> By pre-processing data access patterns, optimizations such as software caching and communication vectorization [DMS + 94] can be performed. We have developed runtime routines in PASSION to solve out-of-core irregular problems on distributed memory machines. The out-of-core pre-processing phase analyzes data access patterns and computes a communication schedule <ref> [MSS + 88] </ref> as well as an I/O schedule. We describe our scheme using a computation kernel similar to the loop shown in Figure 7, on an unstructured mesh. Such a computation forms the core of many applications in fluid dynamics, molecular dynamics etc.
Reference: [PGK88] <author> D. Patterson, G. Gibson, and R. Katz. </author> <title> A Case for Redundant Arrays of Inexpensive Disks (RAID). </title> <booktitle> In ACM SIGMOD Conference, </booktitle> <pages> pages 109-116, </pages> <month> June </month> <year> 1988. </year>
Reference-contexts: PIOUS [MS94] is a parallel file system for a networked computing environment. File declustering, where different blocks are stored on distinct disks is suggested in [LKB87]. This is used in the Bridge File System [DSE88], in Intel's Concurrent File System (CFS) [Pie89] and in various RAID schemes <ref> [PGK88] </ref>. There are several schemes that allow for the exploitation of access pattern information. Crockett [Cro89] discusses parallel file accesses in relation to possible storage techniques. Kotz et. al. [EK89] use pattern predictors to predict an application's future access patterns to perform prefetching.
Reference: [PGS93] <author> D. Patterson, G. Gibson, and M. Satyanarayanan. </author> <title> A Status Report on Research in Transparent Informed Prefetching. </title> <type> Technical Report CMU-CS-93-113, </type> <institution> Carnegie Mellon University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: There are several schemes that allow for the exploitation of access pattern information. Crockett [Cro89] discusses parallel file accesses in relation to possible storage techniques. Kotz et. al. [EK89] use pattern predictors to predict an application's future access patterns to perform prefetching. More recently, Patterson et. al. <ref> [PGS93] </ref> discuss the benefits of disclosing application level hints about future I/O accesses. Prefetching for in-core problems is discussed in [MLG92, CKP91]. The effects of prefetching blocks of a file in a multiprocessor file system are studied in [D. 90].
Reference: [Pie89] <author> P. Pierce. </author> <title> A Concurrent File System for a Highly Parallel Mass Storage Subsystem. </title> <booktitle> In Proceedings of 4 th Conference on Hypercubes, Concurrent Computers and Applications, </booktitle> <pages> pages 155-160, </pages> <note> Match 1989. </note>
Reference-contexts: The need for high performance I/O is so significant that almost all the present generation parallel computers such as the Paragon, iPSC/860, Touchstone Delta, CM-5, SP-2, nCUBE2 etc. provide some kind of hardware and software support for parallel I/O <ref> [CFPB93, Pie89, DdR92] </ref>. At Syracuse University, we are investigating the I/O problem from a software perspective, including languages, compilers, runtime support and file system optimizations. The overall project is called PASSION which stands for Parallel And Scalable Software for Input-Output. <p> The performance of the Laplace equation solver on the Intel Touchstone Delta is given in Table 3. We use Intel's Concurrent File System (CFS) <ref> [Pie89] </ref> on the Delta which has 64 disks. The table compares the performance of the three methods | shift using direct file access, shift using Two Phase Method and shift using two phase with data reuse, an optimization described in Section 4.5.3. <p> PIOUS [MS94] is a parallel file system for a networked computing environment. File declustering, where different blocks are stored on distinct disks is suggested in [LKB87]. This is used in the Bridge File System [DSE88], in Intel's Concurrent File System (CFS) <ref> [Pie89] </ref> and in various RAID schemes [PGK88]. There are several schemes that allow for the exploitation of access pattern information. Crockett [Cro89] discusses parallel file accesses in relation to possible storage techniques. Kotz et. al. [EK89] use pattern predictors to predict an application's future access patterns to perform prefetching.
Reference: [Pon94] <author> R. Ponnusamy. </author> <title> Runtime Support and Compilation Methods for Irregular Computations on Distributed Memory Parallel Machines. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Syracuse University, Syracuse, </institution> <address> NY, </address> <month> May </month> <year> 1994. </year> <note> Available as NPAC Technical Report SCCS-633. 33 </note>
Reference-contexts: As the number of processors is increased to 64, the parallel file system is saturated with requests from all the processors, and therefore, the performance tends to degrade. 4.4 Runtime Support for Out-of-Core Unstructured Problems Unstructured or Irregular problems <ref> [Pon94] </ref> are an important subclass of scientific applications. In irregular problems, the data access patterns cannot be predicted until runtime. Hence, optimizations that can be carried out at compile-time are limited. At runtime, however, the data access patterns of a loop-nest are usually known before entering the loop-nest. <p> Hence, optimizations that can be carried out at compile-time are limited. At runtime, however, the data access patterns of a loop-nest are usually known before entering the loop-nest. This makes it possible to utilize various preprocessing strategies to perform optimizations. Preprocessing methods for in-core computations have been developed <ref> [MSS + 88, Pon94] </ref> for a variety of unstructured problems including explicit multigrid unstructured computational fluid dynamic solvers [Mav91, HB91], molecular dynamics codes (CHARMM, AMBER, GROMOS, etc.) [BBO + 83], and diagonal or polynomial preconditioned iterative linear solvers [VSM90]. 9 Table 4: Out-of-core 2D-FFT for 4K fi 4K array (time in <p> Joel Saltz and his group at the University of Maryland have developed the PARTI/CHAOS toolkit, which is a collection of runtime library routines to handle in-core irregular computations [DSB91, SBW91]. Compilation methods for irregular problems have been investigated by Ponnusamy <ref> [Pon94] </ref>, Das [DPSM92] and Hanxleden [vKK + 92]. There has been a lot of work done in compiler optimizations for data locality. These techniques are also applicable for compiling out-of-core programs. Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79].
Reference: [SBW91] <author> J. Saltz, H. Berryman, and J. Wu. </author> <title> Multiprocessors and Runtime Compilation. </title> <journal> Concurrency: Practice and Experience, </journal> <pages> pages 573-592, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: The effects of prefetching blocks of a file in a multiprocessor file system are studied in [D. 90]. Joel Saltz and his group at the University of Maryland have developed the PARTI/CHAOS toolkit, which is a collection of runtime library routines to handle in-core irregular computations <ref> [DSB91, SBW91] </ref>. Compilation methods for irregular problems have been investigated by Ponnusamy [Pon94], Das [DPSM92] and Hanxleden [vKK + 92]. There has been a lot of work done in compiler optimizations for data locality. These techniques are also applicable for compiling out-of-core programs.
Reference: [SD90] <author> R. Schriber and J. Dongarra. </author> <title> Automatic Blocking of Nested Loops. </title> <type> Technical report, </type> <institution> Research Institute for Advanced Computer Science, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: In order to reduce the I/O cost, either the computation can be reordered (iteration blocking, tiling <ref> [Iri88, SD90, WL91, CK89] </ref>) according to the placement of data in files (to take advantage of data locality) or data can be reordered in files according to the computation. Reordering of data in files results in extra overhead. However, computation reordering may not always be trivial.
Reference: [Sni92] <author> Marc Snir. </author> <title> Proposal for IO. </title> <note> Posted to HPFF I/O Forum by Marc Snir, </note> <month> July 7 </month> <year> 1992. </year>
Reference-contexts: However, no directives are provided to specify data distribution on disks. Various attempts have been made to provide compiler directives for describing data distribution on disks (Vienna Fortran [BGMZ92, ZBC + 92], HPF <ref> [Sni92] </ref>). However at present there is no consensus about how the distribution information should be passed to the compiler. There exist several problems in defining such directives. The out-of-core arrays used in the programs are stored as files. Hence in case of out-of-core problems, two distinct distributions exist. <p> An excellent description of compiler transformations is given in [BGS93]. Wolf and Lam propose an elegant loop transformation theory to improve locality and parallelism [WL91, Wol92] Language extensions for out-of-core data parallel programs are proposed by the Vienna Fortran group [BGMZ92]. Marc Snir of IBM has submitted a proposal <ref> [Sni92] </ref> for I/O in HPF to the HPF Forum. 10 Conclusions PASSION provides software support for high performance parallel I/O on distributed memory parallel computers.
Reference: [TBC94a] <author> R. Thakur, R. Bordawekar, and A. Choudhary. </author> <title> Compiler and Runtime Support for Out-of-Core HPF Programs. </title> <booktitle> In Proceedings of the 8 th ACM International Conference on Supercomputing, </booktitle> <pages> pages 382-391, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: At Syracuse University, we are investigating the I/O problem from a software perspective, including languages, compilers, runtime support and file system optimizations. The overall project is called PASSION which stands for Parallel And Scalable Software for Input-Output. PASSION provides support for compiling out-of-core data parallel programs <ref> [TBC94a, BCT94] </ref>, parallel input-output of data and parallel access to files [BdRC93], communication of out-of-core data, redistribution of data stored on disks, many optimizations including Data Prefetching from disks, Data Sieving, Data Reuse etc., as well as support at the file system level. <p> Table 2: Some of the PASSION Routines for Out-of-core Computations Array Management Routines PASSION Routine Function 1 PASSION read section Read a regular section from LAF to ICLA 2 PASSION write section Write a regular section from ICLA to LAF 3 PASSION read with reuse read section with data reuse <ref> [TBC94a] </ref> 4 PASSION prefetch read Asynchronous (non-blocking) read of a regular section 5 PASSION prefetch wait Wait for a prefetch to complete Communication Routines PASSION Routine Function 6 PASSION oc shift Shift type collective communication on out-of-core data 7 PASSION oc multicast Multicast communication on out-of-core data Mapping Routines PASSION Routine <p> Any arbitrary regular section of the can be read for an array stored in either row-major or column-major order. The information about the array such as its shape, size, distribution, storage format etc. is passed to the routines using a data structure called the Out-of-Core Array Descriptor (OCAD) <ref> [TBC94a] </ref>. The Data Sieving Method described in Section 4.5.1 is used for improved performance. 2. Communication Routines: The Communication Routines perform collective communication of data in the OCLA. We use the Explicit Communication Method described in [TBC94a]. <p> passed to the routines using a data structure called the Out-of-Core Array Descriptor (OCAD) <ref> [TBC94a] </ref>. The Data Sieving Method described in Section 4.5.1 is used for improved performance. 2. Communication Routines: The Communication Routines perform collective communication of data in the OCLA. We use the Explicit Communication Method described in [TBC94a]. The communication is done for the entire OCLA, i.e. all the off-processor data needed by the OCLA is fetched during the communication. This requires inter-processor communication as well as disk accesses. 3. Mapping Routines: The Mapping Routines perform data and processor/disk mappings. <p> The reuse thus eliminates the reading of two columns in this example. In general, the amount of data reuse would depend on the intersection of the sets of data needed for computations involving two consecutive slabs. Data Reuse is described in further detail in <ref> [TBC94a] </ref>. 19 5 Compiler Support This section discusses the issues involved in compiling I/O intensive problems. The PASSION compiler is targeted for languages like Fortran 90D [BCF + 93] and High Performance Fortran [For93], which provide explicit directives to distribute arrays across the processors of a parallel system.
Reference: [TBC + 94b] <author> R. Thakur, R. Bordawekar, A. Choudhary, R. Ponnusamy, and T. Singh. </author> <title> PASSION Runtime Library for Parallel I/O. </title> <booktitle> In Proceedings of the Scalable Parallel Libraries Conference, </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: The image is of size 2K fi 2K pixels. We observe that in all cases, prefetching improves performance significantly. Further details about Data Prefetching are given in <ref> [TBC + 94b] </ref>. 18 4.5.3 Data Reuse One way to reduce the amount of I/O is to reuse the data already fetched into main memory instead of reading it again from disk. This can be explained with the help of the Laplace equation solver program discussed earlier.
Reference: [vKK + 92] <author> R. von Hanxleden, K. Kennedy, C. Koelbel, R. Das, and J. Saltz. </author> <title> Compiler Analysis for Irregular Problems in Fortran D. </title> <booktitle> In Proceedings of the 5 th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: Joel Saltz and his group at the University of Maryland have developed the PARTI/CHAOS toolkit, which is a collection of runtime library routines to handle in-core irregular computations [DSB91, SBW91]. Compilation methods for irregular problems have been investigated by Ponnusamy [Pon94], Das [DPSM92] and Hanxleden <ref> [vKK + 92] </ref>. There has been a lot of work done in compiler optimizations for data locality. These techniques are also applicable for compiling out-of-core programs. Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79].
Reference: [VSM90] <author> P. Venkatkrishnan, J. Saltz, and D. Mavriplis. </author> <title> Parallel Preconditioned Iterative Methods for the Compressible Navier Stokes Equations. </title> <booktitle> In 12th International Conference on Numerical Methods in Fluid Dynamics, </booktitle> <address> Oxford, England, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Preprocessing methods for in-core computations have been developed [MSS + 88, Pon94] for a variety of unstructured problems including explicit multigrid unstructured computational fluid dynamic solvers [Mav91, HB91], molecular dynamics codes (CHARMM, AMBER, GROMOS, etc.) [BBO + 83], and diagonal or polynomial preconditioned iterative linear solvers <ref> [VSM90] </ref>. 9 Table 4: Out-of-core 2D-FFT for 4K fi 4K array (time in sec., Slab size as a fraction of local array size) Processors Slab size Slab size Slab size Slab size 1/16 1/8 1/4 1/2 32 596.54 537.89 499.78 456.35 real x (n node),y (n node) ! data arrays integer
Reference: [WB87] <author> M. Wolfe and U. Banerjee. </author> <title> Data Dependence and its Application to Parallel Processing. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 16(2) </volume> <pages> 137-178, </pages> <month> April </month> <year> 1987. </year>
Reference-contexts: These techniques are also applicable for compiling out-of-core programs. Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79]. Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe <ref> [Wol89b, WB87, Wol87, Wol89a] </ref>. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr [Car93, CK94]. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93].
Reference: [WL91] <author> M. Wolf and M. Lam. </author> <title> A Loop Transformation Theory and An Algorithm to Maximize Parallelism. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(4) </volume> <pages> 452-471, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: In order to reduce the I/O cost, either the computation can be reordered (iteration blocking, tiling <ref> [Iri88, SD90, WL91, CK89] </ref>) according to the placement of data in files (to take advantage of data locality) or data can be reordered in files according to the computation. Reordering of data in files results in extra overhead. However, computation reordering may not always be trivial. <p> Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93]. Wolf and Lam propose an elegant loop transformation theory to improve locality and parallelism <ref> [WL91, Wol92] </ref> Language extensions for out-of-core data parallel programs are proposed by the Vienna Fortran group [BGMZ92]. Marc Snir of IBM has submitted a proposal [Sni92] for I/O in HPF to the HPF Forum. 10 Conclusions PASSION provides software support for high performance parallel I/O on distributed memory parallel computers.
Reference: [Wol87] <author> M. Wolfe. </author> <title> Iteration space tiling for memory hierarchies. </title> <note> Extended version appeared in the Proceedings of the Third SIAM Conference on Parallel Processing, </note> <month> December </month> <year> 1987. </year>
Reference-contexts: These techniques are also applicable for compiling out-of-core programs. Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79]. Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe <ref> [Wol89b, WB87, Wol87, Wol89a] </ref>. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr [Car93, CK94]. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93].
Reference: [Wol89a] <author> M. Wolfe. </author> <title> More iteration space tiling. </title> <booktitle> Proceedings of Supercomputing'89, </booktitle> <month> November </month> <year> 1989. </year>
Reference-contexts: These techniques are also applicable for compiling out-of-core programs. Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79]. Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe <ref> [Wol89b, WB87, Wol87, Wol89a] </ref>. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr [Car93, CK94]. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93].
Reference: [Wol89b] <author> M. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: These techniques are also applicable for compiling out-of-core programs. Abu-Sufah investigates strategies to improve performance of fortran programs in virtual memory environment [AS79]. Compiler transformations such as tiling, strip-mining, loop interchange, loop skewing are proposed by Wolfe <ref> [Wol89b, WB87, Wol87, Wol89a] </ref>. Transformations like Unroll-and-Jam and Scalar Replacement are proposed by Carr [Car93, CK94]. Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93].
Reference: [Wol92] <author> M. Wolf. </author> <title> Improving Locality and parallelism in Nested Loops. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1992. </year> <month> CSL-TR-92-538. </month>
Reference-contexts: Callahan studies the problem of register allocation [CCK90]. Irigoin and Triolet also propose transformations to improve locality [Iri88]. An excellent description of compiler transformations is given in [BGS93]. Wolf and Lam propose an elegant loop transformation theory to improve locality and parallelism <ref> [WL91, Wol92] </ref> Language extensions for out-of-core data parallel programs are proposed by the Vienna Fortran group [BGMZ92]. Marc Snir of IBM has submitted a proposal [Sni92] for I/O in HPF to the HPF Forum. 10 Conclusions PASSION provides software support for high performance parallel I/O on distributed memory parallel computers.
Reference: [ZBC + 92] <author> H. Zima, P. Brezany, B. Chapman, P. Mehrotra, and A. Schwald. </author> <title> Vienna Fortran a Language Specification. </title> <type> Technical Report ICASE Interim Report 21, </type> <institution> MS 132c, ICASE, NASA, </institution> <address> Hampton VA 23681, </address> <year> 1992. </year>
Reference-contexts: Languages like Fortran D, High Performance Fortran provide explicit directives to describe distribution of data on processors. However, no directives are provided to specify data distribution on disks. Various attempts have been made to provide compiler directives for describing data distribution on disks (Vienna Fortran <ref> [BGMZ92, ZBC + 92] </ref>, HPF [Sni92]). However at present there is no consensus about how the distribution information should be passed to the compiler. There exist several problems in defining such directives. The out-of-core arrays used in the programs are stored as files.
References-found: 56

