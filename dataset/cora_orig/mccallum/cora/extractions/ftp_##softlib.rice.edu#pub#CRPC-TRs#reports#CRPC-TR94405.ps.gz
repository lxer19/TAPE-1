URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94405.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Email: fadve, chk, johnmcg@cs.rice.edu  
Title: Performance Analysis of Data Parallel Programs  
Author: Vikram S. Adve Charles Koelbel John M. Mellor-Crummey 
Address: Houston, TX 77251-1892  
Affiliation: Center for Research on Parallel Computation, Rice University  
Abstract: Effective strategies for performance analysis and tuning will be essential for the success of data parallel languages such as High-Performance Fortran (HPF) and Fortran D. Since compilers for these languages insert all communication, they have considerable knowledge about a program's dynamic structure and the relationship between its parallelism and communication. This paper explores how this compiler knowledge can be exploited to support performance evaluation and tuning. First, the compiler itself can use parameterized models to tune the performance of individual program phases; this approach can be effective provided that the compiler can test and handle violations of the model assumptions. Second, by exploiting compiler knowledge and introducing code transformations to improve monitorability, we can collect dynamic performance information that is far more compact than full communication traces, but well suited to the needs of tuning specific communication patterns. Third, we discuss why an understanding of the compiler's capabilities can be important for effective performance tuning. We use several Fortran 77D benchmark kernels to illustrate these points. Finally, through our studies of these benchmarks, we identify the need for several generally applicable compiler optimizations that improve communication and computation overlap.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Ball and J. R. Larus. </author> <title> Optimally profiling and tracing programs. </title> <booktitle> In POPL92, </booktitle> <pages> pages 59-70, </pages> <month> Jan </month> <year> 1992. </year>
Reference-contexts: Some previous performance tools have attempted to use program information to reduce the volume of information measured at runtime. Sequential profiling tools such as QPT <ref> [1] </ref> use control-flow analysis to reduce the volume of profiling or tracing data.
Reference: [2] <author> S. Bokhari. </author> <title> Communication overhead on the Intel iPSC/860 Hypercube. </title> <type> ICASE Report 10, </type> <institution> Institute for Computer Application in Science and Engineering, Hampton, VA, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: This approach is valid because T pipe (B) is convex in each interval of continuity. The approach should also be efficient if there are only a small number of discontinuities (e.g., the iPSC/860 has a single one at m 0 B = 100 <ref> [2] </ref>). 5 subroutine tridvpk (a,b,c,d,e,tot) real a (64),b (64),c (64),d (64),e (64),tot (64,64) common /dvars/ ..., f (64,64,64) parameter (n_proc = 8) decomposition d (64,64,64) align f with d distribute d (:,:,block) ... ! *** forward substitution *** do 20 k=2,64-1 do 20 i=1,64 20 continue ... (a) Fortran D code <p> Values of C l;comm and C f;comm were taken from Bokhari <ref> [2] </ref>. We also assumed a priori that C f;stage = 0; see the discussion in section 2.3. 6 in execution time is possible by adjusting the block size.
Reference: [3] <author> P. Brezany, M. Gerndt, V. Sipkova, and H. Zima. </author> <title> SUPERB support for irregular scientific computations. </title> <booktitle> In Proceedings of the 1992 Scalable High Performance Computing Conference, </booktitle> <address> Williamsburg, VA, </address> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: model of Section 2.1 as our basic method, although new performance measurements may require us to modify it in the future. (To our knowledge no distributed memory compiler has implemented an explicit model for pipeline optimization, although simple pipelining of loops has been implemented by several compilers, including Vienna Fortran <ref> [3] </ref> and Id Nouveau [21].) If the performance data is unreliable, compiler switches and directives will allow the programmer to specify the parameters directly. If user input is required, however, it may be simpler to specify the block size directly.
Reference: [4] <author> S. Chatterjee, J. Gilbert, F. Long, R. Schreiber, and S. Teng. </author> <title> Generating local addresses and communication sets for data-parallel programs. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: The Kali compiler previously implemented this optimization in the restricted case of FORALL statements embodying shift operations [16]. Of the enhancements required to the Fortran D compiler, relatively simple expressions are available to identify the nonlocal iterations for many common cases <ref> [4] </ref>. The details of the implementation are also relatively straightforward because the loop bodies can be kept intact. To our knowledge, no parallelizing compiler has attempted the more difficult analysis and reordering of computations needed in order to deduce the optimization for Dgefafrom the original source code of Figure 4.
Reference: [5] <author> J. Dongarra, J. Bunch, C. Moler, and G. Stewart. </author> <title> LINPACK User's Guide. </title> <publisher> SIAM Publications, </publisher> <address> Philadelphia, PA, </address> <year> 1979. </year>
Reference-contexts: Dgefa is a Linpack subroutine and a principal computational kernel in the Linpackd benchmark developed by Dongarra et al <ref> [5] </ref>. It performs LU decomposition using Gaussian elimination with partial pivoting.
Reference: [6] <author> T. Fahringer and H. Zima. </author> <title> A static parameter based performance prediction tool for parallel programs. </title> <booktitle> In Proceedings of the 1993 ACM International Conference on Supercomputing, </booktitle> <address> Tokyo, Japan, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: One such project is the Vienna Fortran Compilation System, which integrates a static performance prediction tool called PPPT into the compilation process <ref> [6] </ref>. In particular, PPPT uses sequential profiling to obtain iteration counts and branch frequencies and combines this information with static analysis of a parallelized program to predict a number of parallel performance metrics.
Reference: [7] <author> G. A. Geist, M. T. Heath, B. W. Peyton, and P. H. Worley. PICL: </author> <title> A portable instrumented communication library, C reference manual. </title> <type> Technical Report ORNL/TM-11130, </type> <institution> Oak Ridge National Laboratories, Oak Ridge, TN, </institution> <month> July </month> <year> 1990. </year>
Reference-contexts: The most common strategy for collecting dynamic information about message-passing programs involves tracing each communication event. Such a tracing methodology is embodied in packages such as the PICL communication primitives <ref> [7] </ref>. However, for understanding and tuning the performance of programs written in data parallel languages, this level of detail often appears unnecessary.
Reference: [8] <author> M. T. Heath and J. E. </author> <title> Finger. Visualizing performance of parallel programs. </title> <journal> IEEE Software, </journal> <pages> pages 29-39, </pages> <month> Sept. </month> <year> 1991. </year> <month> 19 </month>
Reference-contexts: We also assumed a priori that C f;stage = 0; see the discussion in section 2.3. 6 in execution time is possible by adjusting the block size. In fact, a space-time diagram of the pipeline execution viewed using ParaGraph <ref> [8] </ref> showed that, at the default block size of 8, pipeline stages are very small (resulting in frequent communication) and thus the startup phase is small as well. <p> Thus, we must also make some minor modifications to our runtime library. 5 6 Related Work Many previous performance tools for parallel systems support performance monitoring of parallel programs with explicit parallelism, communication and synchronization <ref> [17, 20, 8] </ref>, while some more recent tools support performance debugging of data-parallel programs at the language level [22, 14]. However, there is relatively little work that on integrating performance analysis and compilation, partly because of the lack of availability of sophisticated parallelizing compilers to the performance evaluation community.
Reference: [9] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specification. </title> <publisher> Scientific Pro--gramming, </publisher> <address> 2(1-2):1-170, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Data parallel languages such as High-Performance Fortran (HPF) <ref> [9, 15] </ref> and Fortran D [11] have attracted considerable attention as promising languages for writing portable parallel programs.
Reference: [10] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiler support for machine-independent parallel programming in Fortran D. </title> <editor> In J. Saltz and P. Mehrotra, editors, </editor> <title> Languages, Compilers, and Run-Time Environments for Distributed Memory Machines. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: This optimization has been implemented for the restricted case of FORALL statements in the Kali compiler [16] and previously suggested in <ref> [10] </ref>. The reduction in waiting time for message receives in the case of Red-Black SOR is small but significant since it reduces overhead idle time by nearly half, as shown by the measurements of the send and receive overhead given in Table 7.
Reference: [11] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Data parallel languages such as High-Performance Fortran (HPF) [9, 15] and Fortran D <ref> [11] </ref> have attracted considerable attention as promising languages for writing portable parallel programs. These languages support an abstract model of parallel programming in which users annotate a single-threaded program with data layout directives and a sophisticated compiler uses the directives to derive a single-program-multiple data (SPMD) parallel program.
Reference: [12] <author> S. Hiranandani, K. Kennedy, and C. Tseng. </author> <title> Preliminary experiences with the Fortran D compiler. </title> <booktitle> In Proceedings of Supercomputing '93, </booktitle> <address> Portland, OR, </address> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: The code generated by the compiler is shown in Figure 4b. The principal source of performance loss in this program is that other processors have to wait for the pivot processor to compute and broadcast the row-reduction factors for an elimination step. As Hiranandani et al. <ref> [12] </ref> have shown, an effective hand optimization is to overlap the processing and broadcast of factors for column k + 1 with the row-reduction operations that use the factors for column k. <p> In fact, this is the only method that our current compiler allows. Of the communication optimizations suggested by our performance studies, delaying the computations that access nonlocal data (as discussed for Dgefa and Red-Black SOR) requires a relatively straightforward enhancement, and has been previous discussed by Hiranandani et al. <ref> [12] </ref>. The Kali compiler previously implemented this optimization in the restricted case of FORALL statements embodying shift operations [16]. Of the enhancements required to the Fortran D compiler, relatively simple expressions are available to identify the nonlocal iterations for many common cases [4].
Reference: [13] <author> J. K. Hollingsworth and B. P. Miller. </author> <title> Dynamic control of performance monitoring on large scale parallel systems. </title> <booktitle> In International Conference on Supercomputing, </booktitle> <address> Tokyo, </address> <month> Jul </month> <year> 1993. </year>
Reference-contexts: Some previous performance tools have attempted to use program information to reduce the volume of information measured at runtime. Sequential profiling tools such as QPT [1] use control-flow analysis to reduce the volume of profiling or tracing data. Dynamic parallel instrumentation in the W 3 Search Model <ref> [13] </ref> reduces the instrumentation data volume by using sampled performance information to selectively insert instrumentation in interesting parts of a program at runtime, in order to answer specific performance queries.
Reference: [14] <author> R. B. Irvin and B. P. Miller. </author> <title> A performance tool for high-level parallel languages. </title> <type> Technical Report 1204, </type> <institution> WISCONSIN, </institution> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: also make some minor modifications to our runtime library. 5 6 Related Work Many previous performance tools for parallel systems support performance monitoring of parallel programs with explicit parallelism, communication and synchronization [17, 20, 8], while some more recent tools support performance debugging of data-parallel programs at the language level <ref> [22, 14] </ref>. However, there is relatively little work that on integrating performance analysis and compilation, partly because of the lack of availability of sophisticated parallelizing compilers to the performance evaluation community.
Reference: [15] <author> C. Koelbel, D. Loveman, R. Schreiber, G. Steele, Jr., and M. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction Data parallel languages such as High-Performance Fortran (HPF) <ref> [9, 15] </ref> and Fortran D [11] have attracted considerable attention as promising languages for writing portable parallel programs.
Reference: [16] <author> C. Koelbel, P. Mehrotra, and J. Van Rosendale. </author> <title> Supporting shared data structures on distributed memory machines. </title> <booktitle> In Proceedings of the Second ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> Seattle, WA, </address> <month> Mar. </month> <year> 1990. </year>
Reference-contexts: This optimization has been implemented for the restricted case of FORALL statements in the Kali compiler <ref> [16] </ref> and previously suggested in [10]. The reduction in waiting time for message receives in the case of Red-Black SOR is small but significant since it reduces overhead idle time by nearly half, as shown by the measurements of the send and receive overhead given in Table 7. <p> The Kali compiler previously implemented this optimization in the restricted case of FORALL statements embodying shift operations <ref> [16] </ref>. Of the enhancements required to the Fortran D compiler, relatively simple expressions are available to identify the nonlocal iterations for many common cases [4]. The details of the implementation are also relatively straightforward because the loop bodies can be kept intact.
Reference: [17] <author> B. P. Miller, M. Clark, J. K. Hollingsworth, S. Kierstead, S. Lim, and T. Torzewski. Ips-2: </author> <title> The second generation of a parallel program measurement system. </title> <journal> TOPDS, </journal> <volume> 1(2), </volume> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: Thus, we must also make some minor modifications to our runtime library. 5 6 Related Work Many previous performance tools for parallel systems support performance monitoring of parallel programs with explicit parallelism, communication and synchronization <ref> [17, 20, 8] </ref>, while some more recent tools support performance debugging of data-parallel programs at the language level [22, 14]. However, there is relatively little work that on integrating performance analysis and compilation, partly because of the lack of availability of sophisticated parallelizing compilers to the performance evaluation community.
Reference: [18] <author> J. Ramanujam. </author> <title> Compile-time Techniques for Parallel Execution of Loops on Distributed Memory Multiprocessors. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, Ohio State University, Columbus, OH, </institution> <year> 1990. </year>
Reference-contexts: Ramanujam and Sadayappan <ref> [18, 19] </ref> present a related model for choosing the optimal tile size for a wavefront computation; they too assume that communication latency is not overlapped with computation. 3 Our measurements of Erlebacher indicate that the influence of block sizes on communication time is signficant and therefore we incorporate block size in
Reference: [19] <author> J. Ramanujam and P. Sadayappan. </author> <title> Tiling multidimensional iteration spaces for nonshared memory machines. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <address> Albuquerque, NM, </address> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Ramanujam and Sadayappan <ref> [18, 19] </ref> present a related model for choosing the optimal tile size for a wavefront computation; they too assume that communication latency is not overlapped with computation. 3 Our measurements of Erlebacher indicate that the influence of block sizes on communication time is signficant and therefore we incorporate block size in
Reference: [20] <author> D. A. Reed, R. A. Aydt, T. M. Madhyastha, R. J. Noe, K. A. Shields, and B. W. Schwartz. </author> <title> An overview of the pablo performance analysis environment. </title> <type> Technical report, </type> <institution> UIUCCS, </institution> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: else receive [a (k+1,k)...a (NMAX,k)] endif L1 = k/n_proc +1 if (my_p .lt. pivot_proc) L1 = L1 + 1 do j = L1, NMAX/n_proc Compute row reduction for col j with factors of col k enddo endif enddo end (b) Compiler-generated code. of the program using the Pablo instrumentation library <ref> [20] </ref>. Table 6 shows the distribution of idle time by cause in the two versions of the program for a 1024 fi 1024 matrix on 32 processors. <p> Thus, we must also make some minor modifications to our runtime library. 5 6 Related Work Many previous performance tools for parallel systems support performance monitoring of parallel programs with explicit parallelism, communication and synchronization <ref> [17, 20, 8] </ref>, while some more recent tools support performance debugging of data-parallel programs at the language level [22, 14]. However, there is relatively little work that on integrating performance analysis and compilation, partly because of the lack of availability of sophisticated parallelizing compilers to the performance evaluation community.
Reference: [21] <author> A. Rogers and K. Pingali. </author> <title> Process decomposition through locality of reference. </title> <booktitle> In Proceedings of the SIGPLAN '89 Conference on Program Language Design and Implementation, </booktitle> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: The length of the initial and final phases is directly proportional to the pipeline granularity, whereas the communication overhead in the middle interval is inversely proportional to the pipeline granularity. In a study of a pipelined Gauss-Seidel relaxation, Rogers and Pingali <ref> [21] </ref> recognized this trade-off but did not present a model for choosing the pipeline granularity. <p> as our basic method, although new performance measurements may require us to modify it in the future. (To our knowledge no distributed memory compiler has implemented an explicit model for pipeline optimization, although simple pipelining of loops has been implemented by several compilers, including Vienna Fortran [3] and Id Nouveau <ref> [21] </ref>.) If the performance data is unreliable, compiler switches and directives will allow the programmer to specify the parameters directly. If user input is required, however, it may be simpler to specify the block size directly. In fact, this is the only method that our current compiler allows.
Reference: [22] <author> M. </author> <title> Thinking Machines Corp., Cambridge. Prism reference manual. </title> <type> Technical report, </type> <year> 1992. </year>
Reference-contexts: also make some minor modifications to our runtime library. 5 6 Related Work Many previous performance tools for parallel systems support performance monitoring of parallel programs with explicit parallelism, communication and synchronization [17, 20, 8], while some more recent tools support performance debugging of data-parallel programs at the language level <ref> [22, 14] </ref>. However, there is relatively little work that on integrating performance analysis and compilation, partly because of the lack of availability of sophisticated parallelizing compilers to the performance evaluation community.
Reference: [23] <author> R. van de Geijn. </author> <title> Massively parallel LINPACK benchmark on the Intel Touchstone Delta and iPSC/860 systems. </title> <booktitle> In 1991 Annual Users' Conference Proceedings, </booktitle> <address> Dallas, </address> <month> Oct. </month> <year> 1991. </year> <title> Intel Supercomputer Users' Group. </title> <type> 20 </type>
Reference-contexts: Van de Geijn's implementation of the Linpack benchmark on the Intel Delta applied this technique by 16 hand, as well as using a blocked form of Gaussian elimination to further vectorize communication <ref> [23] </ref>. In order to be able to carry out the optimizations from the rewritten source code of Figure 5b, the compiler enhancements required are somewhat more straightforward, although, to our knowledge, no parallelizing compiler has implemented this optimization either.
References-found: 23

