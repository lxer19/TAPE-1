URL: ftp://ftp.cse.ucsc.edu/pub/hsnlab/matching.ps.Z
Refering-URL: http://www.cse.ucsc.edu/research/hsnlab/projects/scheduling.html
Root-URL: http://www.cse.ucsc.edu
Title: Providing Bandwidth Guarantees in an Input-Buffered Crossbar Switch  
Author: Dimitrios Stiliadis Anujan Varma 
Date: August 4, 1994  
Address: Santa Cruz, CA 95064  
Affiliation: Computer Engineering Department University of California  
Abstract: This research is supported by the University of California MICRO program, NSF Young Investigator Award No. MIP-9257103, the Institute for Scientific Computing Research (ISCR) at Lawrence Livermore National Laboratory, and an equipment donation from Altera Corporation. A shortened version of this paper was presented at the IEEE INFOCOM '95 conference. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Zhang, "VirtualClock: </author> <title> a new traffic control algorithm for packet switching networks," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 101-124, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Implementation of these guarantees requires the use of appropriate traffic scheduling algorithms in the switches, so that the available resources are properly allocated to the individual traffic streams. A large number of such traffic scheduling algorithms have been proposed and analyzed in recent literature <ref> [1, 2, 3] </ref>. The difficulty of designing the scheduling algorithm is compounded by the fact that the small size of the ATM cell rules out a software implementation of the algorithm in most cases. These algorithms must, therefore, strike a compromise between performance and implementation complexity. <p> The second problem, that of allocating bandwidth among flows sharing a common link, can be tackled by one of the many scheduling algorithms in the literature <ref> [1, 2, 3] </ref>. Schemes providing hop-by-hop flow-control of virtual circuits can also limit the peak bandwidth usage of the individual flows [4, 5]. Many different architectures for ATM switch fabrics have been proposed in the literature. <p> The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin [13], generalized processor sharing [14, 15], VirtualClock <ref> [1] </ref>, and FIFO+ [3]; with the constraint that the aggregate bandwidth available for these flows is that provided through weighted probabilistic iterative matching.
Reference: [2] <author> A.Demers, S. Keshav, and S.Shenker, </author> <title> "Analysis and simulation of a fair queueing algorithm," </title> <journal> Journal of Internetworking Research and Experience, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 3-26, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Implementation of these guarantees requires the use of appropriate traffic scheduling algorithms in the switches, so that the available resources are properly allocated to the individual traffic streams. A large number of such traffic scheduling algorithms have been proposed and analyzed in recent literature <ref> [1, 2, 3] </ref>. The difficulty of designing the scheduling algorithm is compounded by the fact that the small size of the ATM cell rules out a software implementation of the algorithm in most cases. These algorithms must, therefore, strike a compromise between performance and implementation complexity. <p> The second problem, that of allocating bandwidth among flows sharing a common link, can be tackled by one of the many scheduling algorithms in the literature <ref> [1, 2, 3] </ref>. Schemes providing hop-by-hop flow-control of virtual circuits can also limit the peak bandwidth usage of the individual flows [4, 5]. Many different architectures for ATM switch fabrics have been proposed in the literature. <p> However, it does not allow any flexibility in bandwidth allocation. In addition, the algorithm is incapable of providing fairness among the input ports transmitting to a common output port if their bandwidth demands are not identical. According to the criteria defined in <ref> [2] </ref>, a network is fair if every user is allocated exactly the bandwidth it requested; in addition, if a user is removed from the system, the extra bandwidth will be distributed equally among the other competing flows. <p> This follows from the fact 9 that when all credits are satisfied, the algorithm reduces to simple iterative matching that allocates the bandwidth equally among all inputs requesting access to a given output port. In this sense, the algorithm meets the fairness criteria defined in <ref> [2, 16] </ref>. When an input-output connection increases its traffic rate, the performance of all others will be equally degraded, but they will still continue to receive at least their reserved bandwidth.
Reference: [3] <author> D. D. Clark, S. Shenker, and L. Zhang, </author> <title> "Supporting real-time applications in an integrated services packet network: Architecture and mechanism," </title> <booktitle> in Proc. AGM SIGCOMM '92, </booktitle> <pages> pp. 14-26, </pages> <month> August </month> <year> 1992. </year> <month> 28 </month>
Reference-contexts: Implementation of these guarantees requires the use of appropriate traffic scheduling algorithms in the switches, so that the available resources are properly allocated to the individual traffic streams. A large number of such traffic scheduling algorithms have been proposed and analyzed in recent literature <ref> [1, 2, 3] </ref>. The difficulty of designing the scheduling algorithm is compounded by the fact that the small size of the ATM cell rules out a software implementation of the algorithm in most cases. These algorithms must, therefore, strike a compromise between performance and implementation complexity. <p> The second problem, that of allocating bandwidth among flows sharing a common link, can be tackled by one of the many scheduling algorithms in the literature <ref> [1, 2, 3] </ref>. Schemes providing hop-by-hop flow-control of virtual circuits can also limit the peak bandwidth usage of the individual flows [4, 5]. Many different architectures for ATM switch fabrics have been proposed in the literature. <p> The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin [13], generalized processor sharing [14, 15], VirtualClock [1], and FIFO+ <ref> [3] </ref>; with the constraint that the aggregate bandwidth available for these flows is that provided through weighted probabilistic iterative matching.
Reference: [4] <author> H. T. Kung, T. Blackwell, and A. Chapman, </author> <title> "Credit-based flow control for ATM networks: Credit update protocol, adaptive credit allocation, and statistical multiplexing," </title> <booktitle> in Proc. </booktitle> <volume> SIG-COMM '94, </volume> <month> August </month> <year> 1994. </year>
Reference-contexts: The second problem, that of allocating bandwidth among flows sharing a common link, can be tackled by one of the many scheduling algorithms in the literature [1, 2, 3]. Schemes providing hop-by-hop flow-control of virtual circuits can also limit the peak bandwidth usage of the individual flows <ref> [4, 5] </ref>. Many different architectures for ATM switch fabrics have been proposed in the literature. The common fabric types include shared memory, bus, crossbar, and multistage networks (for a survey, see [6]). <p> Alternately, schemes for link-by-link flow control of virtual circuits can also limit the bandwidth of individual flows sharing a common link and hence can be used to implement flow-level bandwidth allocation <ref> [4, 5] </ref>. To implement bandwidth reservations, we divide the time axis into frames with a fixed number of slots per frame. In the context of ATM networks, a slot is equal to the time to transmit one 53-byte cell.
Reference: [5] <author> G. Varghese, C. Ozveren, and R. Simcoe, </author> <title> "Reliable and efficient hop-by-hop flow control," </title> <booktitle> in Proc. ACM SIGCOMM '94, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: The second problem, that of allocating bandwidth among flows sharing a common link, can be tackled by one of the many scheduling algorithms in the literature [1, 2, 3]. Schemes providing hop-by-hop flow-control of virtual circuits can also limit the peak bandwidth usage of the individual flows <ref> [4, 5] </ref>. Many different architectures for ATM switch fabrics have been proposed in the literature. The common fabric types include shared memory, bus, crossbar, and multistage networks (for a survey, see [6]). <p> Alternately, schemes for link-by-link flow control of virtual circuits can also limit the bandwidth of individual flows sharing a common link and hence can be used to implement flow-level bandwidth allocation <ref> [4, 5] </ref>. To implement bandwidth reservations, we divide the time axis into frames with a fixed number of slots per frame. In the context of ATM networks, a slot is equal to the time to transmit one 53-byte cell.
Reference: [6] <author> F. A. Tobagi, </author> <title> "Fast packet switch architectures for broadband integrated services digital networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 78, no. 1, </volume> <pages> pp. 133-167, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Schemes providing hop-by-hop flow-control of virtual circuits can also limit the peak bandwidth usage of the individual flows [4, 5]. Many different architectures for ATM switch fabrics have been proposed in the literature. The common fabric types include shared memory, bus, crossbar, and multistage networks (for a survey, see <ref> [6] </ref>). In this paper, we restrict ourselves to a nonblocking switch architecture, most often implemented by a crossbar switching network.
Reference: [7] <author> M. J. Karol, M. G. Hluchyj, and S. P. Morgan, </author> <title> "Input versus output queueing on a space-division packet switch," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 35, no. 12, </volume> <pages> pp. 1347-56, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: Head-of-line contention has been shown to reduce the throughput of a crossbar with input buffering to approximately 58% of its capacity when the traffic is uniformly distributed <ref> [7] </ref>. The alternative to input buffering is output buffering, where the buffers are located at the output of the switch. An arriving packet is moved immediately to the queue associated with its requested output. With an ideal implementation, output buffering can approach ideal throughput [7]. <p> when the traffic is uniformly distributed <ref> [7] </ref>. The alternative to input buffering is output buffering, where the buffers are located at the output of the switch. An arriving packet is moved immediately to the queue associated with its requested output. With an ideal implementation, output buffering can approach ideal throughput [7]. The problem, however, is its implementation complexity. An ideal implementation of output buffering in a crossbar switch with N ports requires the queue at each output be able to receive up to N packets in each cycle.
Reference: [8] <author> Y. S. Yeh, M. G. Hluchyj, and A. S. Acampora, </author> <title> "The knockout switch: A simple, modular architecture for high-performance packet switching," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. SAC-5, no. 8, </volume> <pages> pp. 1274-83, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: This is difficult to achieve in practice, except for very small N ; a practical implementation must limit the number of packets accepted by an output queue in one cycle. Many such implementations, for example, the Knockout Switch <ref> [8] </ref>, have been proposed in the literature. The performance of an input-buffered crossbar can be improved by allowing the switch to choose one of several packets in the queue to transmit in each cycle.
Reference: [9] <author> M. J. Karol, K. Y. Eng, and H. Obara, </author> <title> "Improving the performance of an input-queued ATM packet switches," </title> <booktitle> in Proc. INFOCOM '92, </booktitle> <volume> vol. 1, </volume> <pages> pp. 110-115, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: When the scheduler has access to more than one packet in each input buffer, the throughput can be maximized by matching the packets stored in the input queues to output ports such that the largest possible number of packets is scheduled for transmission in each cycle <ref> [9] </ref>. The problem of switching the maximum number of packets in a crossbar with windowed or randomly accessed queues can be reduced to the matching problem in a bipartite graph [10].
Reference: [10] <author> T. E. Anderson, S. S. Owicki, J. B. Saxe, and C. P. Thacker, </author> <title> "High speed switch scheduling for local area networks," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 11, no. 4, </volume> <pages> pp. 319-52, </pages> <month> November </month> <year> 1993. </year> <note> Also as Digital Systems Research Center Technical Report, No. 99. </note>
Reference-contexts: The problem of switching the maximum number of packets in a crossbar with windowed or randomly accessed queues can be reduced to the matching problem in a bipartite graph <ref> [10] </ref>. The bipartite graph is constructed by representing each input port with a vertex in a first group and each output port with a vertex in a second group. <p> This makes the use of an optimal algorithm almost impossible. In addition, an optimal algorithm may be inherently sequential and may not be able to take advantage of the parallel operations that can be implemented in hardware to speed up the algorithm. Anderson, et al. <ref> [10] </ref> designed an alternative to an optimal algorithm, called probabilistic iterative matching, for performing packet-scheduling in an input-buffered crossbar switch by finding maximal matchings in a bipartite graph [10]. The algorithm is simple and easily realizable in hardware. <p> Anderson, et al. <ref> [10] </ref> designed an alternative to an optimal algorithm, called probabilistic iterative matching, for performing packet-scheduling in an input-buffered crossbar switch by finding maximal matchings in a bipartite graph [10]. The algorithm is simple and easily realizable in hardware. In this algorithm, scheduling of packets in each cycle is made through a sequence of three actions. First, each input sends request signals in parallel to every output port with which it could be matched. <p> Although finding a maximal matching using the probabilistic matching algorithm may, in the worst case, take N iterations, an average of O (log 2 N ) iterations has been shown to be sufficient <ref> [10] </ref>. Simulations have shown that the algorithm was able to find a maximal matching in a 16 fi 16 switch after 4 iterations over 99.9% of the time [10]. Because of the probabilistic nature of the algorithm, it can only provide probabilistic upper bounds on packet delays. <p> in the worst case, take N iterations, an average of O (log 2 N ) iterations has been shown to be sufficient <ref> [10] </ref>. Simulations have shown that the algorithm was able to find a maximal matching in a 16 fi 16 switch after 4 iterations over 99.9% of the time [10]. Because of the probabilistic nature of the algorithm, it can only provide probabilistic upper bounds on packet delays. <p> In addition, in a network of switches, flows going through a large number of switches may receive considerably less bandwidth as compared to those going through a small number of switches <ref> [10] </ref>. Anderson, et al. [10] suggested two alternatives to probabilistic iterative matching for providing bandwidth guarantees. The first is restricted to Constant Bit Rate (CBR) traffic, where an explicit schedule of packet transmissions is constructed between input-output pairs taking into account the bandwidth demand of each flow. <p> In addition, in a network of switches, flows going through a large number of switches may receive considerably less bandwidth as compared to those going through a small number of switches <ref> [10] </ref>. Anderson, et al. [10] suggested two alternatives to probabilistic iterative matching for providing bandwidth guarantees. The first is restricted to Constant Bit Rate (CBR) traffic, where an explicit schedule of packet transmissions is constructed between input-output pairs taking into account the bandwidth demand of each flow. There are two problems with this approach. <p> Since the matching process is initiated by the outputs, it is possible that an input port is selected to receive the grant signal when it has no packets to transmit. This limits the maximum throughput of statistical matching to approximately 72% of the link capacity <ref> [10] </ref>. In addition, the algorithm involves computation of several probability distributions in each step, making a hardware implementation difficult. <p> The average number of iterations for probabilistic iterative matching to yield a maximal matching has been shown to be O (log 2 N ) <ref> [10] </ref>. This is because the number of unresolved requests is reduced by an average of at least 3 4 in each iteration. <p> Theorem 1: The average number of iterations to reach a maximal matching with WPIM is within (log 2 N + 4=3) for an N -port switch. Proof: The proof is identical to that of Anderson, et al. <ref> [10] </ref> except for the fact that not all requests submitted by input ports in each cycle participate in the matching process. Initially, a maximum of N 2 =4 requests is generated by the input ports. <p> With N 2 initial requests, the expected number of unresolved requests at the end of the ith iteration is no more than N 2 =4 i . The remainder of the proof follows the same steps as that of Anderson, et al. <ref> [10] </ref>, and are therefore omitted. Thus, the expected value of the number of iterations to reach convergence does not exceed log 2 N + 4=3. This concludes the proof of the theorem. <p> This causes the delay to be much higher compared to WPIM at low loads. Also, the maximum bandwidth utilization of statistical matching has been shown to be no more than 72% <ref> [10] </ref>. This causes the switch to saturate at a much lower load than in the case of WPIM, resulting in much higher delays at heavy load. <p> Observe that the misbehaving connection is able to use about 11% of the output bandwidth under statistical matching, although its reservation is only 5%. This is because our implementation of statistical matching employ two iterations, as discussed in <ref> [10] </ref>, which results in a higher service rate for input 4 than its reservation. Another advantage of weighted iterative matching is that it allows flexible allocation of bandwidth between real-time connections that require bandwidth guarantees and best-effort connections.
Reference: [11] <author> R. E. Tarjan, </author> <title> Data Structures and Network Algorithms. </title> <address> Murray Hill, NJ: </address> <institution> Bell Laboratories, </institution> <year> 1983. </year>
Reference-contexts: Optimal algorithms exist for bipartite matching with complexity of O (N 2 ) where N is the number of ports of the switch <ref> [11, 12] </ref>. However, the time available to compute a matching in an ATM switch is limited to the transmission time of a cell | less than 3 s at SONET OC-3 speeds. This makes the use of an optimal algorithm almost impossible.
Reference: [12] <author> R. M. Karp, U. V. Vazirani, and V. V. Vazirani, </author> <title> "An optimal algorithm for on-line bipartite matching," </title> <booktitle> in Proc. 22nd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pp. 352-358, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Optimal algorithms exist for bipartite matching with complexity of O (N 2 ) where N is the number of ports of the switch <ref> [11, 12] </ref>. However, the time available to compute a matching in an ATM switch is limited to the transmission time of a cell | less than 3 s at SONET OC-3 speeds. This makes the use of an optimal algorithm almost impossible.
Reference: [13] <author> M. Katevenis, S. Sidiropoulos, and C. Courcoubetis, </author> <title> "Weighted round-robin cell multiplexing in a general-purpose ATM switch chip," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, no. 8, </volume> <pages> pp. 1265-79, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin <ref> [13] </ref>, generalized processor sharing [14, 15], VirtualClock [1], and FIFO+ [3]; with the constraint that the aggregate bandwidth available for these flows is that provided through weighted probabilistic iterative matching.
Reference: [14] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow control the single node case," </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 344-357, </pages> <month> June </month> <year> 1993. </year> <month> 29 </month>
Reference-contexts: The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin [13], generalized processor sharing <ref> [14, 15] </ref>, VirtualClock [1], and FIFO+ [3]; with the constraint that the aggregate bandwidth available for these flows is that provided through weighted probabilistic iterative matching.
Reference: [15] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow con-trol in integrated services networks: the multiple node case," </title> <journal> IEEE/ACM Transactions on Networking, </journal> <volume> vol. 2, no. 2, </volume> <pages> pp. 137-150, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin [13], generalized processor sharing <ref> [14, 15] </ref>, VirtualClock [1], and FIFO+ [3]; with the constraint that the aggregate bandwidth available for these flows is that provided through weighted probabilistic iterative matching.
Reference: [16] <author> K. K. Ramakrishnan and R. Jain, </author> <title> "A binary feedback scheme for congestion avoidance in computer networks.," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 8, no. 2, </volume> <pages> pp. 158-81, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: This follows from the fact 9 that when all credits are satisfied, the algorithm reduces to simple iterative matching that allocates the bandwidth equally among all inputs requesting access to a given output port. In this sense, the algorithm meets the fairness criteria defined in <ref> [2, 16] </ref>. When an input-output connection increases its traffic rate, the performance of all others will be equally degraded, but they will still continue to receive at least their reserved bandwidth.
Reference: [17] <author> S. Shenker, </author> <title> "Making greed work in networks: A game-theoretic analysis of switch service disciplines," </title> <booktitle> in Proc. ACM SIGCOMM '94, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: In a real network, the traffic may exceed the capacity of the output link, either because of the burstiness of individual flows or because of greedy users. Users may act in a selfish manner by trying to utilize as much of the available bandwidth as possible <ref> [17] </ref>. Higher level protocols such as TCP incorporate mechanisms to utilize the maximum available bandwidth [18]. In addition, some of the input ports of the switch may need to use more than 1=N of the output bandwidth; probabilistic iterative matching can only guarantee them 1=N of the output bandwidth.
Reference: [18] <author> V. Jacobson, </author> <title> "Congestion avoidance and control," </title> <booktitle> in Proc. ACM SIGCOMM '88, </booktitle> <pages> pp. 314-29, </pages> <month> August </month> <year> 1988. </year> <month> 30 </month>
Reference-contexts: Users may act in a selfish manner by trying to utilize as much of the available bandwidth as possible [17]. Higher level protocols such as TCP incorporate mechanisms to utilize the maximum available bandwidth <ref> [18] </ref>. In addition, some of the input ports of the switch may need to use more than 1=N of the output bandwidth; probabilistic iterative matching can only guarantee them 1=N of the output bandwidth.
References-found: 18

