URL: http://www.cs.gatech.edu/reverse/repository/flexible.ps
Refering-URL: http://www.cs.gatech.edu/reverse/repos.html
Root-URL: 
Title: Flexible Control for Program Recognition  
Author: Linda M. Wills 
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Date: 134-143, May 1993.  
Note: Working Conference on Reverse Engineering. Baltimore, MD. pp.  
Abstract: Recognizing commonly used data structures and algorithms is a key activity in reverse engineering. Systems developed to automate this recognition process have been isolated, stand-alone systems, usually targeting a specific task. We are interested in applying recognition to multiple tasks requiring reverse engineering, such as inspecting, maintaining, and reusing software. This requires a flexible, adaptable recognition architecture, since the tasks vary in the amount and accuracy of knowledge available about the program, the requirements on recognition power, and the resources available. We have developed a recognition system based on graph parsing. It has a flexible, adaptable control structure that can accept advice from external agents. Its flexibility arises from using a chart parsing algorithm. We are studying this graph parsing approach to determine what types of advice can enhance its capabilities, performance, and scalability. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Bertels. </author> <title> Qualitative reasoning in novice program analysis. </title> <type> Technical report, </type> <institution> Universiteit Antwerpen, </institution> <month> June </month> <year> 1991. </year> <type> PhD thesis. </type>
Reference-contexts: Its flexibility arises from using a chart parsing algorithm which makes control and search strategies explicit. 1.1 Previous Recognition Work Several researchers have shown the feasibility of automating recognition and the usefulness of its results, most recently Bertels <ref> [1] </ref>, Hartman [6], Johnson [8], Letovsky [10], Murray [12], Ning [13], and Wills [18]. (See [19] for a more detailed description of these systems and earlier research in this area.) All existing recognition systems are isolated, standalone systems which are not expected to interact with people or with other reverse engineering
Reference: [2] <author> T. Biggerstaff. </author> <title> Design recovery for maintenance and reuse. </title> <journal> IEEE Computer, </journal> <volume> 22(7) </volume> <pages> 36-49, </pages> <month> July </month> <year> 1989. </year> <note> Also published as MCC Technical Report STP-378-88. </note>
Reference-contexts: They base this partitioning on design documentation and program comments or even simply names of subroutines and variables. The DESIRE system <ref> [2] </ref> attempts to automate this process. Based on a rich domain model, it recognizes patterns of organization and linguistic idioms in a program associated with concepts in the program's problem domain.
Reference: [3] <author> D. Brotsky. </author> <title> An algorithm for parsing flow graphs. </title> <type> Technical Report 704, </type> <institution> MIT Artificial Intelligence Lab., </institution> <month> March </month> <year> 1984. </year> <type> Master's thesis. </type>
Reference-contexts: It represents a program as a restricted form of directed acyclic graph, called a flow graph <ref> [3, 19] </ref>, which is annotated with attributes. Nodes in the flow graph represent functions, edges denote dataflow, and attributes capture control flow information. The cliche library is encoded as an attributed graph grammar, whose rules impose constraints on the attributes of flow graphs matching the rules' right-hand sides. <p> of the program's flow graph, it will be recognized by subgraph parsing. 2.2 Chart Parsing Flow Graphs To solve the subgraph parsing problem, GRASPR uses a graph parser which has evolved from Earley's string parsing algorithm [4], incorporating three key improvements: (1) generalization of string parsing to flow graphs (Brotsky <ref> [3] </ref>, Lutz [11]), (2) generalization of the control strategy to allow flexibility in the rule-invocation and search strategies employed (Kay [9], Thompson [16], Lutz [11]), and (3) extension of the grammar formalism to capture aggregation relationships (Wills [19]) between single inputs or outputs of a non-terminal left-hand side node and a
Reference: [4] <author> J. Earley. </author> <title> An efficient context-free parsing algorithm. </title> <journal> Comm. of the ACM, </journal> <volume> 13(2) </volume> <pages> 94-102, </pages> <year> 1970. </year>
Reference-contexts: or interleaved with unfamiliar code, but if it is localized in a sub-flow graph of the program's flow graph, it will be recognized by subgraph parsing. 2.2 Chart Parsing Flow Graphs To solve the subgraph parsing problem, GRASPR uses a graph parser which has evolved from Earley's string parsing algorithm <ref> [4] </ref>, incorporating three key improvements: (1) generalization of string parsing to flow graphs (Brotsky [3], Lutz [11]), (2) generalization of the control strategy to allow flexibility in the rule-invocation and search strategies employed (Kay [9], Thompson [16], Lutz [11]), and (3) extension of the grammar formalism to capture aggregation relationships (Wills
Reference: [5] <author> R. Hall. </author> <title> Program improvement by automatic redistribution of intermediate results. </title> <type> Technical Report 1251, </type> <institution> MIT Artificial Intelligence Lab., </institution> <month> February </month> <year> 1990. </year> <type> PhD thesis. </type>
Reference-contexts: This can then be confirmed by an external agent, such as a person, or by applying limited reasoning techniques to uncover dataflow equalities or conditional simplifications in simple cases <ref> [5, 10] </ref>. 3.2 Grammar Expressiveness Our graph formalism is expressive enough to capture general-purpose programming cliches, such as priority-queue insert, as well as cliches from the simulation domain. The formalism is able to concisely encode algorithmic and data aggregation cliches whose constraints are primarily based on data and control flow.
Reference: [6] <author> J. Hartman. </author> <title> Automatic control understanding for natural programs. </title> <type> Technical Report AI 91-161, </type> <institution> University of Texas at Austin, </institution> <year> 1991. </year> <type> PhD thesis. </type>
Reference-contexts: Its flexibility arises from using a chart parsing algorithm which makes control and search strategies explicit. 1.1 Previous Recognition Work Several researchers have shown the feasibility of automating recognition and the usefulness of its results, most recently Bertels [1], Hartman <ref> [6] </ref>, Johnson [8], Letovsky [10], Murray [12], Ning [13], and Wills [18]. (See [19] for a more detailed description of these systems and earlier research in this area.) All existing recognition systems are isolated, standalone systems which are not expected to interact with people or with other reverse engineering techniques. <p> More recent research includes some empirical analysis, typically studying the accuracy of recognition and the recognition rates over sets of programs (usually student programs in program tutoring applications [8, 12]). However, discussions of limitations (except Hartman's <ref> [6] </ref>) have focused mainly on implementational limitations, rather than on inherent limitations of the approach. They also do not describe how additional information or guidance from external agents can help. <p> The danger of static, a priori partitioning is that a cliche might be missed if it is not contained within some partition boundary. This technique works best if there are standard partitionings of cliches and the cliches appear in programs in these same organizations. (For example, Hartman <ref> [6] </ref> has identified a restricted class of cliches, called control concepts, that have this property.) GRASPR can use dynamic partitioning advice by incorporating it into the extendibility criterion so that items that are candidates for combination must represent recognitions of sub-flow graphs within the same partition.
Reference: [7] <author> D. Hutchens and V. Basili. </author> <title> System structure analysis: Clustering with data bindings. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 11(8), </volume> <month> August </month> <year> 1985. </year>
Reference-contexts: This information can be used to quickly draw attention to sections of the program where there may be cliches related to a particular concept. Other, more conventional techniques for reverse engineering large programs also provide ways of extracting possible partitions (e.g., by clustering <ref> [7] </ref> and slicing [17]). Partitioning and indexing advice can be used by GRASPR in two ways. One way is to use it to statically narrow down the grammar and input flow graph given to the parser beforehand.
Reference: [8] <author> W. L. Johnson. </author> <title> Intention-Based Diagnosis of Novice Programming Errors. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: Its flexibility arises from using a chart parsing algorithm which makes control and search strategies explicit. 1.1 Previous Recognition Work Several researchers have shown the feasibility of automating recognition and the usefulness of its results, most recently Bertels [1], Hartman [6], Johnson <ref> [8] </ref>, Letovsky [10], Murray [12], Ning [13], and Wills [18]. (See [19] for a more detailed description of these systems and earlier research in this area.) All existing recognition systems are isolated, standalone systems which are not expected to interact with people or with other reverse engineering techniques. <p> They all are committed to a rigid control strategy, typically targeting a particular application, such as debugging, restructuring, or documentation. Some <ref> [8, 12] </ref> have cost-cutting heuristics built in which are chosen on a trial-and-error basis. Some [8, 10, 12] search for a single best interpretation of the program, while permanently cutting off alternatives, so their power cannot be incrementally increased. <p> They all are committed to a rigid control strategy, typically targeting a particular application, such as debugging, restructuring, or documentation. Some [8, 12] have cost-cutting heuristics built in which are chosen on a trial-and-error basis. Some <ref> [8, 10, 12] </ref> search for a single best interpretation of the program, while permanently cutting off alternatives, so their power cannot be incrementally increased. They also cannot generate multiple views of the program when desired, nor provide partial information when only near-misses of cliches are present. <p> They also cannot generate multiple views of the program when desired, nor provide partial information when only near-misses of cliches are present. Some recognition techniques take as input information about the goals and purpose of the program (in the form of a specification <ref> [8] </ref> or model program [12]). While these techniques show the utility of these additional sources of information, they rely on this information being given as input, rather than accepting and responding to it if it is available for a given task. <p> Much of the early work in program recognition provides no evaluation of the representations or techniques used. More recent research includes some empirical analysis, typically studying the accuracy of recognition and the recognition rates over sets of programs (usually student programs in program tutoring applications <ref> [8, 12] </ref>). However, discussions of limitations (except Hartman's [6]) have focused mainly on implementational limitations, rather than on inherent limitations of the approach. They also do not describe how additional information or guidance from external agents can help.
Reference: [9] <author> M. Kay. </author> <title> Algorithm schemata and data structures in syntactic processing. </title> <editor> In B. Grosz, K. Sparck-Jones, and B. Webber, editors, </editor> <booktitle> Readings in Natural Language Processing, </booktitle> <pages> pages 35-70. </pages> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: subgraph parsing problem, GRASPR uses a graph parser which has evolved from Earley's string parsing algorithm [4], incorporating three key improvements: (1) generalization of string parsing to flow graphs (Brotsky [3], Lutz [11]), (2) generalization of the control strategy to allow flexibility in the rule-invocation and search strategies employed (Kay <ref> [9] </ref>, Thompson [16], Lutz [11]), and (3) extension of the grammar formalism to capture aggregation relationships (Wills [19]) between single inputs or outputs of a non-terminal left-hand side node and a tuple of inputs or outputs of a right-hand side sub-flow graph. (This is used to express the relationships between the <p> The flexible control strategy inherited from the chart parsers of Kay <ref> [9] </ref>, Thompson [16], and Lutz [11] gives GRASPR its flexibility, adaptability, and ability to accept advice.
Reference: [10] <author> S. Letovsky. </author> <title> Plan analysis of programs. </title> <type> Research Report 662, </type> <institution> Yale University, </institution> <month> December </month> <year> 1988. </year> <type> PhD Thesis. </type>
Reference-contexts: Its flexibility arises from using a chart parsing algorithm which makes control and search strategies explicit. 1.1 Previous Recognition Work Several researchers have shown the feasibility of automating recognition and the usefulness of its results, most recently Bertels [1], Hartman [6], Johnson [8], Letovsky <ref> [10] </ref>, Murray [12], Ning [13], and Wills [18]. (See [19] for a more detailed description of these systems and earlier research in this area.) All existing recognition systems are isolated, standalone systems which are not expected to interact with people or with other reverse engineering techniques. <p> They all are committed to a rigid control strategy, typically targeting a particular application, such as debugging, restructuring, or documentation. Some [8, 12] have cost-cutting heuristics built in which are chosen on a trial-and-error basis. Some <ref> [8, 10, 12] </ref> search for a single best interpretation of the program, while permanently cutting off alternatives, so their power cannot be incrementally increased. They also cannot generate multiple views of the program when desired, nor provide partial information when only near-misses of cliches are present. <p> Our recognition system is able to recognize structured programs and cliches containing conditionals, loops with any number of exits, recursion, aggregate data structures, and simple side effects due to assignments. With the exception of CPU <ref> [10] </ref>, existing recognition systems cannot handle aggregate data structure cliches and a majority do not handle recursion. We are working with programs that are in the 500 to 1000 line range. The largest program recognized by any existing recognition system is a 300-line database program recognized by CPU. <p> This can then be confirmed by an external agent, such as a person, or by applying limited reasoning techniques to uncover dataflow equalities or conditional simplifications in simple cases <ref> [5, 10] </ref>. 3.2 Grammar Expressiveness Our graph formalism is expressive enough to capture general-purpose programming cliches, such as priority-queue insert, as well as cliches from the simulation domain. The formalism is able to concisely encode algorithmic and data aggregation cliches whose constraints are primarily based on data and control flow.
Reference: [11] <author> R. Lutz. </author> <title> Chart parsing of flowgraphs. </title> <booktitle> In Proc. 11th Int. Joint Conf. Artificial Intelligence, </booktitle> <pages> pages 116-121, </pages> <address> Detroit, Michigan, </address> <year> 1989. </year>
Reference-contexts: program's flow graph, it will be recognized by subgraph parsing. 2.2 Chart Parsing Flow Graphs To solve the subgraph parsing problem, GRASPR uses a graph parser which has evolved from Earley's string parsing algorithm [4], incorporating three key improvements: (1) generalization of string parsing to flow graphs (Brotsky [3], Lutz <ref> [11] </ref>), (2) generalization of the control strategy to allow flexibility in the rule-invocation and search strategies employed (Kay [9], Thompson [16], Lutz [11]), and (3) extension of the grammar formalism to capture aggregation relationships (Wills [19]) between single inputs or outputs of a non-terminal left-hand side node and a tuple of <p> uses a graph parser which has evolved from Earley's string parsing algorithm [4], incorporating three key improvements: (1) generalization of string parsing to flow graphs (Brotsky [3], Lutz <ref> [11] </ref>), (2) generalization of the control strategy to allow flexibility in the rule-invocation and search strategies employed (Kay [9], Thompson [16], Lutz [11]), and (3) extension of the grammar formalism to capture aggregation relationships (Wills [19]) between single inputs or outputs of a non-terminal left-hand side node and a tuple of inputs or outputs of a right-hand side sub-flow graph. (This is used to express the relationships between the inputs and outputs of <p> the relationships between the inputs and outputs of an abstract operation on aggregate data structures and aggregates of the inputs and outputs of the lower-level operations that make up its concrete implementation.) The formalism was parser, with control knobs. also extended to handle variation in graphs due to structure-sharing (Lutz <ref> [11] </ref>, Wills [18, 19]) and aggregation organization (Wills [19]). The flexible control strategy inherited from the chart parsers of Kay [9], Thompson [16], and Lutz [11] gives GRASPR its flexibility, adaptability, and ability to accept advice. <p> operations that make up its concrete implementation.) The formalism was parser, with control knobs. also extended to handle variation in graphs due to structure-sharing (Lutz <ref> [11] </ref>, Wills [18, 19]) and aggregation organization (Wills [19]). The flexible control strategy inherited from the chart parsers of Kay [9], Thompson [16], and Lutz [11] gives GRASPR its flexibility, adaptability, and ability to accept advice.
Reference: [12] <author> W. Murray. </author> <title> Automatic Program Debugging for Intelligent Tutoring Systems. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Its flexibility arises from using a chart parsing algorithm which makes control and search strategies explicit. 1.1 Previous Recognition Work Several researchers have shown the feasibility of automating recognition and the usefulness of its results, most recently Bertels [1], Hartman [6], Johnson [8], Letovsky [10], Murray <ref> [12] </ref>, Ning [13], and Wills [18]. (See [19] for a more detailed description of these systems and earlier research in this area.) All existing recognition systems are isolated, standalone systems which are not expected to interact with people or with other reverse engineering techniques. <p> They all are committed to a rigid control strategy, typically targeting a particular application, such as debugging, restructuring, or documentation. Some <ref> [8, 12] </ref> have cost-cutting heuristics built in which are chosen on a trial-and-error basis. Some [8, 10, 12] search for a single best interpretation of the program, while permanently cutting off alternatives, so their power cannot be incrementally increased. <p> They all are committed to a rigid control strategy, typically targeting a particular application, such as debugging, restructuring, or documentation. Some [8, 12] have cost-cutting heuristics built in which are chosen on a trial-and-error basis. Some <ref> [8, 10, 12] </ref> search for a single best interpretation of the program, while permanently cutting off alternatives, so their power cannot be incrementally increased. They also cannot generate multiple views of the program when desired, nor provide partial information when only near-misses of cliches are present. <p> They also cannot generate multiple views of the program when desired, nor provide partial information when only near-misses of cliches are present. Some recognition techniques take as input information about the goals and purpose of the program (in the form of a specification [8] or model program <ref> [12] </ref>). While these techniques show the utility of these additional sources of information, they rely on this information being given as input, rather than accepting and responding to it if it is available for a given task. <p> Much of the early work in program recognition provides no evaluation of the representations or techniques used. More recent research includes some empirical analysis, typically studying the accuracy of recognition and the recognition rates over sets of programs (usually student programs in program tutoring applications <ref> [8, 12] </ref>). However, discussions of limitations (except Hartman's [6]) have focused mainly on implementational limitations, rather than on inherent limitations of the approach. They also do not describe how additional information or guidance from external agents can help.
Reference: [13] <author> J.Q. Ning. </author> <title> A knowledge-based approach to automatic program analysis. </title> <type> Technical report, </type> <institution> University of Illi-nois, Urbana-Champaign, </institution> <year> 1989. </year> <type> PhD thesis. </type>
Reference-contexts: Its flexibility arises from using a chart parsing algorithm which makes control and search strategies explicit. 1.1 Previous Recognition Work Several researchers have shown the feasibility of automating recognition and the usefulness of its results, most recently Bertels [1], Hartman [6], Johnson [8], Letovsky [10], Murray [12], Ning <ref> [13] </ref>, and Wills [18]. (See [19] for a more detailed description of these systems and earlier research in this area.) All existing recognition systems are isolated, standalone systems which are not expected to interact with people or with other reverse engineering techniques.
Reference: [14] <author> C. Rich and R. C. Waters. </author> <title> The Programmer's Apprentice. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <publisher> MA and ACM Press, </publisher> <address> Baltimore, MD, </address> <year> 1990. </year>
Reference-contexts: 1 Introduction An experienced programmer can often reconstruct much of the hierarchy of a program's design by recognizing commonly used data structures and algorithms and knowing how they typically implement higher-level abstractions. We call these commonly used computational structures cliches <ref> [14] </ref>. Examples of cliches are algorithmic computations, such as list enumeration, binary search, and event-driven simulation, and common data structures, such as priority queue and hash table. The recognition process, which we refer to as program recognition, provides a short-cut to understanding a program's design.
Reference: [15] <author> C. Rich and L. M. Wills. </author> <title> Recognizing a program's design: A graph-parsing approach. </title> <journal> IEEE Software, </journal> <volume> 7(1) </volume> <pages> 82-89, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: In addition, GRASPR is robust under variation due to delocalization of cliches, unfamiliar code, and function-sharing optimizations. (See <ref> [18, 19, 15] </ref> for details and examples of how these classes of variation are tolerated.) Difficulties arise when a program's data and control flow are implicit or derived or cannot be determined statically. For example, when a program accepts functional inputs, some data and control flow information is statically unavailable.
Reference: [16] <author> H. Thompson. </author> <title> Chart parsing and rule schemata in GPSG. </title> <booktitle> In Proc. 19th Annual Meeting of the ACL, </booktitle> <address> Stanford, CA, </address> <year> 1981. </year>
Reference-contexts: problem, GRASPR uses a graph parser which has evolved from Earley's string parsing algorithm [4], incorporating three key improvements: (1) generalization of string parsing to flow graphs (Brotsky [3], Lutz [11]), (2) generalization of the control strategy to allow flexibility in the rule-invocation and search strategies employed (Kay [9], Thompson <ref> [16] </ref>, Lutz [11]), and (3) extension of the grammar formalism to capture aggregation relationships (Wills [19]) between single inputs or outputs of a non-terminal left-hand side node and a tuple of inputs or outputs of a right-hand side sub-flow graph. (This is used to express the relationships between the inputs and <p> The flexible control strategy inherited from the chart parsers of Kay [9], Thompson <ref> [16] </ref>, and Lutz [11] gives GRASPR its flexibility, adaptability, and ability to accept advice.
Reference: [17] <author> M. Weiser. </author> <title> Program slicing. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 10 </volume> <pages> 352-357, </pages> <year> 1984. </year>
Reference-contexts: This information can be used to quickly draw attention to sections of the program where there may be cliches related to a particular concept. Other, more conventional techniques for reverse engineering large programs also provide ways of extracting possible partitions (e.g., by clustering [7] and slicing <ref> [17] </ref>). Partitioning and indexing advice can be used by GRASPR in two ways. One way is to use it to statically narrow down the grammar and input flow graph given to the parser beforehand.
Reference: [18] <author> L. Wills. </author> <title> Automated program recognition: A feasibility demonstration. </title> <journal> Artificial Intelligence, </journal> <volume> 45(1-2):113-172, </volume> <year> 1990. </year>
Reference-contexts: flexibility arises from using a chart parsing algorithm which makes control and search strategies explicit. 1.1 Previous Recognition Work Several researchers have shown the feasibility of automating recognition and the usefulness of its results, most recently Bertels [1], Hartman [6], Johnson [8], Letovsky [10], Murray [12], Ning [13], and Wills <ref> [18] </ref>. (See [19] for a more detailed description of these systems and earlier research in this area.) All existing recognition systems are isolated, standalone systems which are not expected to interact with people or with other reverse engineering techniques. <p> between the inputs and outputs of an abstract operation on aggregate data structures and aggregates of the inputs and outputs of the lower-level operations that make up its concrete implementation.) The formalism was parser, with control knobs. also extended to handle variation in graphs due to structure-sharing (Lutz [11], Wills <ref> [18, 19] </ref>) and aggregation organization (Wills [19]). The flexible control strategy inherited from the chart parsers of Kay [9], Thompson [16], and Lutz [11] gives GRASPR its flexibility, adaptability, and ability to accept advice. <p> In addition, GRASPR is robust under variation due to delocalization of cliches, unfamiliar code, and function-sharing optimizations. (See <ref> [18, 19, 15] </ref> for details and examples of how these classes of variation are tolerated.) Difficulties arise when a program's data and control flow are implicit or derived or cannot be determined statically. For example, when a program accepts functional inputs, some data and control flow information is statically unavailable.
Reference: [19] <author> L. Wills. </author> <title> Automated program recognition by graph parsing. </title> <type> Technical Report 1358, </type> <institution> MIT Artificial Intelligence Lab., </institution> <month> July </month> <year> 1992. </year> <type> PhD Thesis. </type>
Reference-contexts: This gains efficiency without permanently sacrificing completeness. Furthermore, the knowledge about the program, the requirements on recognition power, and the re-sources available typically change as the tasks are being performed. We have developed an experimental recognition system, called GRASPR <ref> [19] </ref>, which when given a library of cliches, finds all instances of cliches in a program. It can generate multiple views of a program as well as near-miss recognitions of cliches. It has a flexible, adaptable control structure that can accept advice and guidance from external agents. <p> from using a chart parsing algorithm which makes control and search strategies explicit. 1.1 Previous Recognition Work Several researchers have shown the feasibility of automating recognition and the usefulness of its results, most recently Bertels [1], Hartman [6], Johnson [8], Letovsky [10], Murray [12], Ning [13], and Wills [18]. (See <ref> [19] </ref> for a more detailed description of these systems and earlier research in this area.) All existing recognition systems are isolated, standalone systems which are not expected to interact with people or with other reverse engineering techniques. <p> It represents a program as a restricted form of directed acyclic graph, called a flow graph <ref> [3, 19] </ref>, which is annotated with attributes. Nodes in the flow graph represent functions, edges denote dataflow, and attributes capture control flow information. The cliche library is encoded as an attributed graph grammar, whose rules impose constraints on the attributes of flow graphs matching the rules' right-hand sides. <p> The rule for Equality-within-Epsilon constrains all the nodes that match its right-hand side to co-occur. The attribute-transfer rules specify how to synthesize the left-hand side node attributes from the attributes of the flow graph matching the right-hand side. (These are stated informally in Figure 2; see <ref> [19] </ref> for a formal description of the attribute language used in encoding cliches.) The parsing technique yields a hierarchical description of a plausible design of the program in the form of derivation trees, which we call design trees. These specify the cliches found and their relationships to each other. <p> To get around this limitation, we manually translated our example programs to pure (functional) versions and recognized pure cliches in them. Fortunately, the translation was straightforward and we plan to semi-automate it in the future by interleaving dataflow analysis with the recognition of stereotypical aliasing patterns <ref> [19] </ref>. Our cliche library contains a core set of general-purpose, "utility" cliches, along with a set of cliches from the domain of sequential simulation. These are encoded in approximately 200 graph grammar rules. <p> incorporating three key improvements: (1) generalization of string parsing to flow graphs (Brotsky [3], Lutz [11]), (2) generalization of the control strategy to allow flexibility in the rule-invocation and search strategies employed (Kay [9], Thompson [16], Lutz [11]), and (3) extension of the grammar formalism to capture aggregation relationships (Wills <ref> [19] </ref>) between single inputs or outputs of a non-terminal left-hand side node and a tuple of inputs or outputs of a right-hand side sub-flow graph. (This is used to express the relationships between the inputs and outputs of an abstract operation on aggregate data structures and aggregates of the inputs and <p> between the inputs and outputs of an abstract operation on aggregate data structures and aggregates of the inputs and outputs of the lower-level operations that make up its concrete implementation.) The formalism was parser, with control knobs. also extended to handle variation in graphs due to structure-sharing (Lutz [11], Wills <ref> [18, 19] </ref>) and aggregation organization (Wills [19]). The flexible control strategy inherited from the chart parsers of Kay [9], Thompson [16], and Lutz [11] gives GRASPR its flexibility, adaptability, and ability to accept advice. <p> an abstract operation on aggregate data structures and aggregates of the inputs and outputs of the lower-level operations that make up its concrete implementation.) The formalism was parser, with control knobs. also extended to handle variation in graphs due to structure-sharing (Lutz [11], Wills [18, 19]) and aggregation organization (Wills <ref> [19] </ref>). The flexible control strategy inherited from the chart parsers of Kay [9], Thompson [16], and Lutz [11] gives GRASPR its flexibility, adaptability, and ability to accept advice. This section conceptually describes this aspect of the parser and how it is used by GRASPR. (For more details, see [19].) The parser <p> organization (Wills <ref> [19] </ref>). The flexible control strategy inherited from the chart parsers of Kay [9], Thompson [16], and Lutz [11] gives GRASPR its flexibility, adaptability, and ability to accept advice. This section conceptually describes this aspect of the parser and how it is used by GRASPR. (For more details, see [19].) The parser maintains a database, called a chart, of partial and complete analyses of the input graph in the form of items. This is shown in Figure 4. A complete item represents the recognition of some sub-flow graph as some terminal or non-terminal in the grammar. <p> In each case, examples of some sources of difficulties are presented to illustrate the forms of guidance that would be useful to GRASPR. (For more details and examples, see <ref> [19] </ref>.) 3.1 Tolerating Variation Program recognition is difficult because cliches may appear in programs in a wide variety of forms. The flow graph representation for programs and cliches has significant advantages over the text-based representations used by many other recognition systems. <p> In addition, GRASPR is robust under variation due to delocalization of cliches, unfamiliar code, and function-sharing optimizations. (See <ref> [18, 19, 15] </ref> for details and examples of how these classes of variation are tolerated.) Difficulties arise when a program's data and control flow are implicit or derived or cannot be determined statically. For example, when a program accepts functional inputs, some data and control flow information is statically unavailable. <p> This is inherently exponential. (In fact, the subgraph parsing problem for flow graphs is NP-complete <ref> [19] </ref>, so it is unlikely that there is a subgraph parsing algorithm that is not exponential in the worst case.) However, in the practical application of graph parsing to recognizing complete instances of cliches, constraints are strong enough to prevent exponential behavior in practice. <p> come into play are: (1) constraints on node types, which correspond to function types, (2) edge connection constraints, which represent dataflow dependencies, (3) and co-occurrence constraints, which are a class of control flow constraints that require a set of functions to all be executed under the same control conditions. (See <ref> [19] </ref> for a detailed discussion and supporting statistics.) As we increase the recognition power of GRASPR to make it generate more partial recognitions of cliches, we lose the advantage of strong constraint pruning.
References-found: 19

