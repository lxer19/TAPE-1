URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1991/tr-91-049.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1991.html
Root-URL: http://www.icsi.berkeley.edu
Email: ahmad@icsi.berkeley.edu  
Title: VISIT: An Efficient Computational Model of Human Visual Attention  
Phone: (510) 643-4274 FAX (510) 643-7684  
Author: Subutai Ahmad 
Date: September 1991  
Address: 1947 Center Street Suite 600 Berkeley, California 94704  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  
Pubnum: TR-91-049  
Abstract: One of the challenges for models of cognitive phenomena is the development of efficient and exible interfaces between low level sensory information and high level processes. For visual processing, researchers have long argued that an attentional mechanism is required to perform many of the tasks required by high level vision. This thesis presents VISIT, a connectionist model of covert visual attention that has been used as a vehicle for studying this interface. The model is efficient, exible, and is biologically plausible. The complexity of the network is linear in the number of pixels. Effective parallel strategies are used to minimize the number of iterations required. The resulting system is able to efficiently solve two tasks that are particularly difficult for standard bottom-up models of vision: computing spatial relations and visual search. Simulations show that the networks behavior matches much of the known psychophysical data on human visual attention. The general architecture of the model also closely matches the known physiological data on the human attention system. Various extensions to VISIT are discussed, including methods for learning the component modules. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ahmad, S. and Omohundro, S. </author> <title> (1991) Efficient Visual Search: A Connectionist Solution. </title> <booktitle> In: Proceedings of the 13th Annual Confer ence of the Cognitive Science Society , Chicago, </booktitle> <month> August, </month> <year> 1991. </year>
Reference: <author> Ahmad, S., and Omohundro, S. </author> <title> (1990a) Equilateral Triangles: A Challenge for Connectionist Vision. </title> <booktitle> In: Proceedings of the 12th Annual Conference of the Cognitive Science Society, </booktitle> <publisher> MIT, </publisher> <month> July, </month> <year> 1990. </year>
Reference: <author> Ahmad, S., and Omohundro, S. </author> <title> (1990b) A Connectionist System for Extracting the Locations of Point Clusters. </title> <type> Technical Report TR-90-011, </type> <institution> International Computer Science Institute, </institution> <address> Berke-ley, CA. </address>
Reference: <author> Anastasio, T. J. </author> <title> (1991) A Recurrent Neural Network Model of Velocity Storage in the Vestibulo-Ocular Reex. </title> <editor> In: Lippman, R., Moody, J., and Touretzky, D.S. (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Anderson, C.H., and Van Essen, </author> <title> D.C. (1987) Shifter Circuits: A Computational Strategy for Dynamic Aspects of Visual Processing. </title> <journal> Proc. Natl. Academy. Sci., </journal> <volume> 84 </volume> <pages> 6297-6301. </pages>
Reference: <editor> Andersen, R.A., and Gnadt, J.W. (1989) Posterior parietal cortex. In: Wurtz, R.H., and Goldberg, M.E. (Eds.) </editor> <title> The Neurobiology of Saccadic Eye Movements. </title> <publisher> Elsevier, </publisher> <address> New York. </address>
Reference-contexts: It receives a significant projection from superior colliculus and is thought to be involved in the production of voluntary eye saccades <ref> (Andersen & Gnadt, 1989) </ref>. Experiments show that it is also involved in covert shifts of attention. Lesion studies have provided further evidence along these lines. (Posner et. al, 1984) found that damage to posterior parietal lobe led to deficits in the ability to disengage covert attention away from a target.
Reference: <author> Bair, W., and Koch, C. </author> <title> (1991) An Analog VLSI Chip for Finding Edges from Zero-crossings. </title> <editor> In: Lippman, R., Moody, J., and Touretzky, D.S. (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Bear, M., and Cooper, L. </author> <title> (1989) Molecular Mechanisms for Synaptic Modification in the Visual Cortex: Interaction between Theory and Experiment. </title> <editor> In: M. Gluck and D.E. Rumelhart (eds.), </editor> <title> Neuroscience and Connectionist Theory, </title> <publisher> Lawrence Erlbaum Associates, Inc.. </publisher>
Reference-contexts: Learning To Focus Attention Early in development, the primary visual areas self-organize to form retinotopic maps. There is evidence that only part of this process is genetically specified: the final maps are also dependent on the specific images that are experienced during development <ref> (Bear & Cooper, 1989) </ref>. Network simulations with unsupervised learning rules have been used to model aspects of this developmental process (Kohonen, 1984; Obermayer et. al, 1991). Typically these networks are presented with an ensemble of images.
Reference: <author> Becker, S. </author> <title> (1991) Unsupervised Learning Procedures for Neural Networks. </title> <note> To appear in: International Journal of Neural Systems, 12. </note>
Reference-contexts: Target detection times should remain constant. 41 It is interesting to note that a single Hebb neuron extracts the largest principal component of the input distribution and with inhibition, sets of Hebbian neurons can extract successively smaller components <ref> (Becker, 1991) </ref>. Moreover, as some researchers have demonstrated (e.g. Linsker 1989), simple Hebbian learning can lead to features that look very similar to the features in the visual cortex.
Reference: <author> Berger, A., Henik, A., and Rafal, R. </author> <title> (1991) Exogenous and Endogenous Orienting of Visual Attention. Poster presented at Recent Advances in the Analysis of Attention, </title> <address> Davis, CA. </address>
Reference: <author> Bruce, C.J., Desimone, R., and Gross, </author> <title> C.G. (1981) Visual properties of neurons in a polysensory 97 area in superior temporal sulcus of the macaque. </title> <journal> Journal of Neurophysiology, </journal> <volume> 46 </volume> <pages> 369-384. </pages>
Reference-contexts: Furthermore, as predicted by the theory, cells in IT are much more selective in their preferred stimulus than cells in earlier areas (Desimone, 1991). For example, some cells respond only to hands (Gross et. al, 1972) whereas some respond only to faces <ref> (Bruce et. al, 1981) </ref>, or even profiles of faces (Desimone et. al, 1984). However, contrary to the strictly feed-forward view, there exists strong evidence that spatial attention begins to play a major role in these areas.
Reference: <author> Bundesen, C. </author> <title> (1990) A Theory of Visual Attention. </title> <journal> Psychological Review, </journal> <volume> 97(4) </volume> <pages> 523-547. </pages>
Reference: <author> Cavanagh, P., Arguin, M., and Treisman, A. </author> <title> (1990) Effect of Surface Medium on Visual Search for Orientation and Size Features. </title> <journal> Journal of Experimental Psychology: Human Per ception and Performance, </journal> <volume> 16(3) </volume> <pages> 479-491. </pages>
Reference: <author> Cavanagh, P. </author> <year> (1990). </year> <title> Pursuing Moving Objects With Attention. </title> <booktitle> In: Proceedings of the 12th Annual Conference of the Cognitive Science Society, </booktitle> <pages> pp 1046-1047, </pages> <publisher> MIT, </publisher> <month> July, </month> <year> 1990. </year>
Reference: <author> Cave, K.R., and W olfe, J.M. </author> <title> (1990) Modeling the Role of Parallel Processing in V isual Search. </title> <journal> Cognitive Psychology, </journal> <volume> 22 </volume> <pages> 225-271. </pages>
Reference-contexts: This would necessitate a scan through the objects. Variation in irrelevant dimensions however should cause no activity in the relevant feature map, so SWIFT search will always locate the target in one step. 7.1.4 Fast Conjunction Search Large Variances in Search Slopes In <ref> (Cave & Wolfe, 1990) </ref> and (Treisman & Sato, 1990) the authors reported that search slopes could vary by a large amount across subjects. Conjunction searches of color and form produced wide variances. The slopes for some subjects were almost at, whereas others were quite steep. <p> If people can use such a general strategy for detecting feature combinations, why dont we get constant time search for all feature conjunctions? People only produce constant time search for very specific feature combinations, a fact that cannot be explained by the above mechanisms. <ref> (Cave & Wolfe, 1990) </ref> have suggested that this is due to varying amounts of noise in the system. There is no adequate explanation for the source of this noise, or why it should vary across individuals and across features.
Reference: <author> Chapman, D. </author> <title> (1990) Vision, Instruction, and Action. </title> <type> Ph.D. Thesis, </type> <institution> Massachusetts Institute of Technology. </institution>
Reference: <author> Corbetta, M., Miezin, F., Dobmeyer, S., Shulman, G., and Petersen, S. </author> <title> (1990) Attentional Modulation of Neural Processing of Shape, Color, and Velocity in Humans. </title> <booktitle> Science 248 </booktitle> <pages> 1556-1559. </pages>
Reference: <author> De Valois, R.L., and De Valois, K.K. </author> <title> (1988) Spatial Vision. </title> <publisher> Oxford University Press, </publisher> <address> New York. </address>
Reference-contexts: It is appealing to compare physiological properties of cells with the perceptual features studied by psychophysicists. Unfortunately the mapping between the two is not always clear. For example, some cells code for a combination of spatial frequency and orientation <ref> (De Valois & De Valois, 1988) </ref> which seems to be perceptually unnatural. There are also some discrepancies between psychological and physiological findings (Treisman & Sato, 1990). Nevertheless perceptual features are almost certainly derived from the responses of cells in V1 and V2. <p> To account for the perceptual grouping results, the system needs a smarter strategy for ranking image locations. As a first approximation, one might use multiple-scale spatial frequency detectors. (Neurons coding for spatial frequency are known to exist in V1 <ref> (De Valois & De Valois, 1988) </ref>.) In Figure 7.4, a low frequency feature map would have less activity in the right half of the image, indicating junction search, people will find the target (shaded horizontal bar) in constant time. 68 that the region probably contains a smaller group. <p> There is some evidence for this in the literature. In a review article <ref> (Wise & Desimone, 1988) </ref> mention that, even with voluntary effort, when presented with multiple targets simultaneously, the first eye saccade lands at an intermediate position. This is consistent with the notion that attention is required to individuate the locations of multiple objects.
Reference: <author> Desimone, R., Albright, T.D., Gross, C.G., and Bruce, C. </author> <title> (1984) Stimulus-selective properties of inferior temporal neurons in the macaque. </title> <journal> Journal of Neuroscience, </journal> <volume> 4 </volume> <pages> 2051-2062. </pages>
Reference-contexts: For example, some cells respond only to hands (Gross et. al, 1972) whereas some respond only to faces (Bruce et. al, 1981), or even profiles of faces <ref> (Desimone et. al, 1984) </ref>. However, contrary to the strictly feed-forward view, there exists strong evidence that spatial attention begins to play a major role in these areas.
Reference: <author> Desimone, Robert. </author> <title> (1991) FaceSelective Cells in the T emporal Cortex of Monkeys. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1) </volume> <pages> 1-8. </pages>
Reference-contexts: In V4 and IT receptive field sizes continue to increase such that in IT each cell responds to more than half of the visual field. Furthermore, as predicted by the theory, cells in IT are much more selective in their preferred stimulus than cells in earlier areas <ref> (Desimone, 1991) </ref>. For example, some cells respond only to hands (Gross et. al, 1972) whereas some respond only to faces (Bruce et. al, 1981), or even profiles of faces (Desimone et. al, 1984).
Reference: <author> Duncan, J. </author> <title> (1984) Selective Attention and the Organization of Visual Information. </title> <journal> Journal of Experimental Psychology: General, </journal> <volume> 113(4) </volume> <pages> 501-517. </pages>
Reference-contexts: As evidence to support this, Lappin (1967) reports experiments where subjects are faster at reporting multiple properties belonging to the same object than to different objects. This is true even when the objects are overlapping <ref> (Duncan, 1984) </ref>, a fact that cannot be explained by a purely location based theory. Although a detailed review of the object-based theories is beyond the scope of this thesis, it should be pointed out that object-based theories and spatial theories of attention do not necessarily conict with each other. <p> The literature on object based attention suggests that even when two objects are overlapping, people can attend to a single one (Section 6.1.5). One possible explanation is that the attention system attends to depth as well as two-dimensional regions <ref> (Duncan, 1984) </ref>. For example in Figure 8.4 (a) such a system would be able to segregate the horizontal object from the vertical one by attending to the near depth plane. The explanation pre 1.
Reference: <author> Duncan, J. and Humphreys, G.W. </author> <title> (1989) Visual search and stimulus similarity. </title> <journal> Psychological Review, </journal> <volume> 96 </volume> <pages> 433-458. </pages>
Reference: <author> Egeth, H.E., Virzi, R.A., and Garbart, H. </author> <title> (1984) Searching for Conjunctively Def ined Targets. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 10 </volume> (1):32-39. 
Reference-contexts: Several psychophysical experiments have pointed out other possibilities. (Yantis & Jonides, 1990) have shown that stimuli which appear abruptly are attended to sooner than persistent stimuli. This can be overriden by explicitly instructing the subject to concentrate on a particular location. Experiments on visual search by <ref> (Egeth et al, 1984) </ref> suggest that objects with the same features or form as the target object can get higher priority than other objects. (See Chapter 6 for more detail.) All of this suggests a much more dynamic and exible priority system than one which simply ranks the locations based on <p> As the focus of attention stabilizes on each location, an independent network checks the features of the current object against the stored target representation. This continues until a match is found or there are no more active error units. 1. SWIFT was inspired by the experiments in <ref> (Egeth et. al, 1984) </ref>. See Chapter 7. F T F T 34 5.2 Network Simulations In this section we discuss the performance of VISIT on search tasks. Figure 5.7 shows the output of our simulator. The graphics display on the left shows various portions of the network. <p> In addition, if a cue appears consistently on the wrong side, the subject learns through experience to shift attention automatically to the opposite box (this takes about 300 msecs). The experiments in <ref> (Egeth, Virzi, & Garbart, 1984) </ref> suggest that attention can be restricted to objects containing a particular feature if the subject is told about the feature in advance. (Yantis & Jonides, 1990) provide further evidence along these lines. <p> The answer is simple if SWIFT is used: searching the map with the least total activity will always produce the correct results. 7.1.3 Evidence for an Efficient Search Strategy Restricting Search to Objects with a Single Feature In <ref> (Egeth, Virzi, & Garbart, 1984) </ref> the authors contest the claim that for conjunctive search, attention must be directed serially to each stimulus in the display. They argue that subjects can restrict search to those objects that have the same color or form as the target object.
Reference: <author> Enns, J. T. and Rensink, R. A. </author> <title> (1991) Preattentive Recovery of Three-Dimensional Orientation from Line Drawings. </title> <note> To appear in Psychological Review. </note>
Reference: <author> Enns, J. T. and Rensink, R. A. </author> <title> (1991) A Model for the Rapid Interpretation of Line Drawings in Early Vision. In: Visual Search II, </title> <address> D. Brogan (Ed.). London: </address> <publisher> Taylor & Francis. </publisher>
Reference: <author> Feldman, J.A., and Ballard, D.H. </author> <title> (1982) Connectionist Models and their Properties. </title> <journal> Cognitive Science, </journal> <volume> 6 </volume> <pages> 205-254. </pages>
Reference-contexts: This is not an unreasonable assumption. Given the complex analog processing that occurs within neuronal dendritic branches, it is quite possible that a function as complex as maximum can be computed very quickly. An alternate way to do this is to construct a winner-take-all network <ref> (Feldman & Ballard, 1982) </ref> a - the appropriate binding networks. The signal unit fires when all of its inputs are equal. The first time it fires, cntrl-1 starts firing. The next time, cntrl-2 fires, and so on.
Reference: <author> Fukushima, K. </author> <title> (1986) A Neural Network Model for Selective Attention in Visual Pattern Recog 98 nition. </title> <journal> Biological Cybernetics, </journal> <volume> 55 </volume> <pages> 5-15. </pages>
Reference-contexts: AM has been used as a model of word recognition and can model many of the perceptual effects associated with reading. Some of the visual search results can be explained under suitable noise assumptions, as in Guided Search. <ref> (Fukushima, 1986) </ref> describes a model combining a log-depth hierarchical network and iterative relaxation. The output level of the network contains one unit per pattern to be recognized. Given an image the output nodes corresponding to the different patterns will each respond to some degree.
Reference: <author> Fukushima, K., Imagawa, T., and Ashida, E. </author> <title> (1991) Character Recognition With Selective Attention. </title> <booktitle> In: Proc. International Joint Conference on Neural Networks, </booktitle> <address> Seattle, </address> <year> 1991. </year>
Reference-contexts: However the process is quite slow since many iterations are required for the network to settle, and for each iteration the activity has to ow up and down a fairly deep hierarchy. The network has been used recently in the recognition of Chinese Kanji characters <ref> (Fukushima, Imagawa, & Ashida, 1991) </ref>. 94 10.3 Discussion VISIT incorporates a number of features of other models. The notion of a gating network and weights associated with feature maps is similar to the ideas in AM.
Reference: <author> Giles, C.L., Griffin, R.D., and Maxwell, T. </author> <title> (1987) Encoding Geometric Invariances in Higher Order Neural Networks. </title> <booktitle> In: Proceedings of the Conference on Neural Information Processing Systems. </booktitle>
Reference-contexts: If coarse coded representations are used, these numbers can be reduced somewhat but it is still unappealing due to is lack of generality. Techniques have been proposed for introducing translation and rotational invariance into networks <ref> (Giles et. al., 1987) </ref> which eliminate the need for independent feature detectors at every location. Unfortunately these methods require that every unit have a large (quadratic) number of connections with complicated weight linkages between them.
Reference: <author> Goggin, S.D., Johnson, K.M., and Gustafson, K.E. </author> <title> (1991) A Second-Order Translation, Rotation and Scale Invariant Neural Network. </title> <editor> In: Lippman, R., Moody, J., and Touretzky, D.S. (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Goldberg, M.E., and Segraves, M.A. </author> <title> (1989) The visual and frontal cortices. </title> <editor> In: Wurtz, R.H., and Goldberg, M.E. (Eds.) </editor> <title> The Neurobiology of Saccadic Eye Movements. </title> <publisher> Elsevier, </publisher> <address> New York. </address>
Reference-contexts: It is quite possible that both types exist. It is well known that eye movements have two forms: continuous pursuit when the eye is following a moving object, and jumpy saccades as when the eye fixates on a novel object <ref> (Wurtz & Goldberg, 1989) </ref>. There has been recent preliminary evidence indicating that covert attention is also used in motion computations (see Section 7.2.4) so it is quite plausible that covert attention contains analogous smooth pursuit and saccadic movements. <p> Long axons from retinal ganglion cells form the optic nerve which terminates at the 1. A detailed review of the biology of vision is beyond the scope of this thesis. Two good books dealing with the topics covered here are (Spillman & Werner, 1990) and <ref> (Wurtz & Goldberg, 1989) </ref>. For shorter reviews see (Van Essen & Anderson, 1990) and (Schiller, 1985). arrow are known to be bi-directional. Retina LGN Pulvinar MT IT V2 PP PreFront. 52 LGN. The optic radiation proceeds to the primary visual cortex. <p> As far as I am aware, this restriction is consistent with the physiological knowledge. There have been some non-local eye-saccade related effects reported in V1 and V2 such as an overall increase in activity just before saccades <ref> (Goldberg & Segraves, 1989) </ref>. <p> VISIT uses the same representation as the error maps in superior colliculus to assist in bottom-up attentional shifts. The superior colliculus is primarily involved in the generation of eye saccades <ref> (Wurtz & Goldberg, 1989) </ref> but it does have some relationship with covert attention. In (Posner, Cohen, & Rafal, 1982) the authors studied patients with a particular form of Parkinsons disease where the SC is damaged. 57 These patients are able to make horizontal, but not vertical eye saccades. <p> It is thought to have a role analogous to the superior colliculus, and is particularly sensitive to high-resolution color stimuli (Schiller, 1985). It may also be involved in saccades to complex stimuli <ref> (Goldberg & Segraves, 1989) </ref>. The role of the FEF in covert attention is not known. However, given the close correspondence between saccades and covert attention, a reasonable conjecture is that it plays the same role for attention. <p> Section 6.2 discussed various areas of the brain that seem to be involved in covert attention. It is interesting to note that all of these areas are also involved in eye saccades <ref> (Wurtz & Goldberg, 1989) </ref>. These experiments imply that the two systems are highly related but can be decoupled. There might be a good computational reason for this relationship. The covert attention system is much faster than eye saccades.
Reference: <author> Goldman-Rakic, P. </author> <title> (1991) Representations and Processes in Human Prefrontal Cortex. </title> <booktitle> Talk presented at the 13th Annual Conference of the Cognitive Science Society, </booktitle> <address> Chicago, </address> <month> August, </month> <year> 1991. </year>
Reference: <author> Goodhill, G.J., and Willshaw, </author> <title> D.J. (1990) Application of the elastic net algorithm to the formation of ocular dominance stripes. </title> <journal> Network, </journal> <volume> 1 </volume> <pages> 41-59. </pages>
Reference: <author> Gray, J.A., and Wedderburn, A.A.I. </author> <title> (1960) Grouping strategies with simultaneous stimuli. </title> <journal> Quarterly Journal of Experimental Psychology, </journal> <volume> 12 </volume> <pages> 180-184. </pages>
Reference: <author> Gross, C.G., Rocha-Miranda, C.E., and Bender, </author> <title> D.B. (1972) Visual properties of neurons in inf-erotemporal cortex of the macaque. </title> <journal> Journal of Neurophysiology, </journal> <volume> 35 </volume> <pages> 96-111. </pages>
Reference-contexts: Furthermore, as predicted by the theory, cells in IT are much more selective in their preferred stimulus than cells in earlier areas (Desimone, 1991). For example, some cells respond only to hands <ref> (Gross et. al, 1972) </ref> whereas some respond only to faces (Bruce et. al, 1981), or even profiles of faces (Desimone et. al, 1984). However, contrary to the strictly feed-forward view, there exists strong evidence that spatial attention begins to play a major role in these areas.
Reference: <author> Holtzman, J.D., Sidtis, J.J., Volpe, B.T., Wilson, D.H., and Gazzaniga, </author> <title> M.S. (1981) Dissociation of Spatial Information for Stimulus Localization and the Control of Attention. </title> <booktitle> Brain 104 </booktitle> <pages> 861-872. </pages>
Reference: <author> Horiuchi, T., Lazzaro, J., Moore, A., and Koch, C. </author> <title> (1991) A Delay-Line Based Motion Detection Chip. </title> <editor> In: Lippman, R., Moody, J., and Touretzky, D.S. (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Hubel, D.H. and W iesel, </author> <title> T.N. (1968) Receptive Fields and Functional Architecture of Monkey Striate Cortex. </title> <journal> Journal of Physiology, </journal> <volume> 195 </volume> <pages> 215-243. </pages>
Reference: <author> Humphreys, G., Quinlan, P., and Riddoch, M. </author> <title> (1989) Grouping Processes in Visual Search: Effects with Single and Conjunctive Feature T argets. </title> <journal> Journal of Experimental Psychology: </journal> <volume> General , 118(3) </volume> <pages> 258-279. </pages>
Reference: <author> Ivry, R., & Cohen, A. </author> <title> (1990) Dissociation of Short and Long Range Apparent Motion in Visual Search. Journal of Experimental Psychology: Human Per ception and Performance , 16:317 99 Jay, </title> <editor> M., and Sparks, D. </editor> <title> (1984) Auditory receptive fields in primate superior colliculus shift with changes in eye position. </title> <booktitle> Nature 309(5967) </booktitle> <pages> 345-347. </pages>
Reference: <author> Johnson, Mark H. </author> <title> (1990) Cortical Maturation and the Development of Visual Attention in Early Infancy. </title> <journal> Journal of Cognitive Neuroscience 2(2) </journal> <pages> 81-95. </pages>
Reference-contexts: In general however this type of learning is not well understood. For example, it is not all clear how a search strategy such as SWIFT could evolve. There has been some research on the development of attention in people which might prove relevant <ref> (Johnson, 1990) </ref>, but it is not yet at the point where detailed computational models can be formed. Methodologically, it is hard to test attentional behavior in infants which are only a few days old.
Reference: <author> Johnston, W.A., Farnham, J.M., and Hawley, K.J. </author> <title> (1991) Novel Popout: New Findings and Tentative Theory. Poster presented at Recent Advances in the Analysis of Attention, </title> <address> June 7-9, Davis, CA. </address>
Reference-contexts: The default weights are used in the absence of other information. Currently there is no mechanism for decaying priority values, but it could be added easily. An interesting twist to these effects is discussed by <ref> (Johnston, Farnham, & Hawley, 1991) </ref>. There is a well-known phenomenon that subjects respond faster to familiar words than unfamiliar words.
Reference: <author> Johnston, J.C., and Pashler , H. </author> <title> (1990) Close Binding of Identity and Location in V isual Feature Perception. Journal of Experimental Psychology: </title> <booktitle> Human Per ception and Performance , 16(4) </booktitle> <pages> 843-856. </pages>
Reference: <author> Jolicoeur, P., Ullman, S., and Mackay, M. </author> <title> (1986) Curve Tracing: A Possible Basic Operation in the Perception of Spatial Relations. </title> <journal> Memory and Cognition, </journal> <volume> 14 </volume> (2):129-140. 
Reference-contexts: Given a task specification, an intermediate system dynamically creates a sequential visual routine for solving it. This would involve initiating the primitives in some order. He proposed five specific primitives, including primitives for focusing attention, for marking locations, for spreading activation, for curve tracing, and for indexing. <ref> (Jolicoeur, Ullman, & Mackay, 1986) </ref> describe some direct psychophysical evidence in support of this framework. They find that the time required to report whether two stimuli lie on the same curve increases linearly with the distance between them.
Reference: <editor> Jones, E.G. </editor> <booktitle> (1985) The Thalamus. </booktitle> <publisher> Plenum Press, </publisher> <address> New York. </address>
Reference: <author> Julesz, B. and Bergen, J.R. </author> <year> (1987) </year> <month> Textons, </month> <title> The Fundamental Elements in Preattentive Vision and Perception of Textures. </title> <editor> In: Fischler, M.A. and Firschein, O. (Eds.) </editor> <booktitle> Readings in Computer Vision: Issues, Problems, Principles, and Paradigms. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: With a delay of 0 msecs, there is no cued-side advantage, but changes in reaction time can begin as soon as 50 msecs after cue presentation. By 150 msecs, there is a marked improvement in efficiency. <ref> (Julesz & Bergen, 1987) </ref> have reported similar figures - they claim that attention only takes about 40 msecs. In tasks that require multiple shifts of attention, such as visual search, figures as low as 20-30 msecs have been reported (Treisman, 1988). <p> These experiments imply that the two systems are highly related but can be decoupled. There might be a good computational reason for this relationship. The covert attention system is much faster than eye saccades. Covert attention shifts can occur as often as 25 times a second <ref> (Julesz & Bergen, 1987) </ref> whereas eye saccades only occur about 5-7 times per second. Since eye saccades are a more expensive operation (in terms of computation time), it makes sense to use the covert attention system to prune out candidate target locations for an eye saccade.
Reference: <author> Kahneman, D., Treisman, A., and Gibbs, B. </author> <title> (1991) The Reviewing of Object Files: Object Specific Integration of Information. </title> <journal> Cognitive Psychology, </journal> <note> in press. </note>
Reference-contexts: It is possible to explain all the results by postulating attentional mechanisms at the level of both spatial representations as well as higher-order object representations (e.g. as in the object-file model <ref> (Kahneman, Treisman, & Gibbs, 1991) </ref>). The effectiveness of high-level cues in attracting attention (in the absence of any image cues) seems to strongly argue for the existence of some sort of a spatial mechanism.
Reference: <author> Karni, A., and Sagi, D. </author> <title> (1990) Texture discrimination learning is specific for spatial location and background element orientation. </title> <booktitle> Paper presented at the Annual Meeting of the Association for Research in Vision and Opthalmology, </booktitle> <address> Sarasota, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Several people have shown that unsupervised learning rules, such as the Hebb rule, can lead to units with response characteristics similar to neurons in V1 (Linsker, 1989; Becker, 1991). Recent psychophysical studies suggest that this learning continues in adults. <ref> (Karni & Sagi, 1990) </ref> showed that adult subjects can improve feature discrimination through repeated presentations and that this improvement is retinally localized. (Ling-po & Pashler, 1991) have further showed that this learning is not completely unsupervised: the subject must be actively attending to that feature inputs. (3,3,0) (3,3,3) 88 for the
Reference: <author> Keeler, J.D., Rumelhart, D.E., and Leow, W. </author> <title> (1991) Integrated Segmentation and Recognition of Hand-Printed Numerals. </title> <editor> In: Lippman, R., Moody, J., and Touretzky, D.S. (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Klein, R. </author> <title> (1988) Inhibitory Tagging System Facilitates Visual Search. </title> <booktitle> Nature 334 </booktitle> <pages> 430-431. </pages>
Reference-contexts: In fact, inhibition of return always seems to accompany a saccade. Experiments in <ref> (Klein, 1988) </ref> suggest that it is active during serial visual search. Although the exact conditions under which inhibition of return operates is not completely known, overall it seems to be used in quite a sensible manner and only when the conditions require it. Clearly it is useful for visual search.
Reference: <author> Koch, C., and Ullman, S. </author> <title> (1985) Shifts in Selective Attention: Towards the Underlying Neural Circuitry. </title> <journal> Human Neurobiology, </journal> <volume> 4 </volume> <pages> 219-227. </pages>
Reference-contexts: The error vector representation was inspired by discoveries of a similar mechanism in the monkey superior colliculus for controlling eye saccades (see Chapter 6).The output of the confidence units is similar to the saliency map in <ref> (Koch & Ullman, 1985) </ref> (see Chapter 10), although in general many factors may contribute to the saliency of a given location. center of attention. <p> With an analog VLSI implementation it may be possible to overcome some of these limitations (Lazzaro et. al, 1989). A more robust alternative is to construct a log-depth pyramid shaped network as in <ref> (Koch and Ull-man, 1985) </ref> where each node computes the maximum of node values below it. However, since the human visual system is dealing with a very high resolution image (about 10 6 pixels), there just isnt time for a binary log-depth network.
Reference: <author> Kohonen, T. </author> <title> (1984) Self Organization and Associative Memory. </title> <publisher> Springer, </publisher> <address> Berlin. </address>
Reference: <author> Konishi, M. </author> <title> (1983) Centrally Synthesized Maps of Sensory Space. </title> <journal> Trends in Neuroscience, </journal> <volume> Sep-tember </volume> 1983 370-375. 
Reference-contexts: Attention is also useful in non-visual modalities as well. A good example is audition, where attention is often necessary to distinguish individual sounds. Topographic maps representing frequency, amplitude, and phase are known to exist in auditory cortex <ref> (Konishi, 1983) </ref>. If appropriate coordinates can be specified in these dimensions then a network like VISIT can easily implement an auditory attentional mechanism. Such a network could be used to model some of the results dealing with auditory attention (Gray & Wedderburn, 1960; Posner et. al, 1987).
Reference: <author> Kramer, A. F., and Jacobson, A. </author> <title> (1991) Perceptual Organization And Focused Attention: The Role 100 Of Objects And Proximity In Visual Processing. Perception & Psychophysics (in press). </title>
Reference-contexts: Although it may seem that VISIT has given up slow segmentation for a slow fine tuning process this is not a limiting factor. For many tasks object scale is unimportant so it is unnecessary to wait for the scaling mechanism to settle. At least one psychophysical study on attention <ref> (Kramer & Johnson, 1991) </ref> shows that the scale of an object does have an impact on performance. <p> The effectiveness of high-level cues in attracting attention (in the absence of any image cues) seems to strongly argue for the existence of some sort of a spatial mechanism. Recent experiments show that, with appropriate controls, both spatial proximity and grouping effects can be demonstrated <ref> (Kramer & Jacobson, 1991) </ref>.
Reference: <author> LaBerge, D. </author> <title> (1990) Thalamic and Cortical Mechanism of Attention Suggested by Recent Positron Emission Tomographic Experiments. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 2(4) </volume> <pages> 358-372. </pages>
Reference: <author> Lappin, J. </author> <title> (1967) Attention in the identification of stimuli in complex visual displays. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 75 </volume> <pages> 321-328. </pages>
Reference: <author> Lazzaro, K., R yckebusch, S., Mahowald, M.A., and Mead, </author> <title> C.A. (1989) W inner-Take-All Networks of O(N) Complexity. </title> <editor> In: Touretzky, D.S. (Ed.) </editor> <booktitle> Advances in Neural Information Processing Systems 1, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: It is also seems to be quite difficult to find the correct set of inhibitory weights to create a robust solution. With an analog VLSI implementation it may be possible to overcome some of these limitations <ref> (Lazzaro et. al, 1989) </ref>. A more robust alternative is to construct a log-depth pyramid shaped network as in (Koch and Ull-man, 1985) where each node computes the maximum of node values below it.
Reference: <author> Le Cun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., and Jackel, L.D. </author> <title> (1990) Handwritten Digit Recognition with a Back-Propagation Network. </title> <editor> In: Touretzky, D.S. (ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Linsker, R. </author> <title> (1989) How to Generate Ordered Maps by Maximizing the Mutual Information Between Input and Output Signals. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 402-411. </pages>
Reference-contexts: Target detection times should remain constant. 41 It is interesting to note that a single Hebb neuron extracts the largest principal component of the input distribution and with inhibition, sets of Hebbian neurons can extract successively smaller components (Becker, 1991). Moreover, as some researchers have demonstrated <ref> (e.g. Linsker 1989) </ref>, simple Hebbian learning can lead to features that look very similar to the features in the visual cortex.
Reference: <author> Livingstone, M., and Hubel, D. </author> <title> (1988) Segregation of Form, Color, Movement, and Depth: Anatomy, </title> <journal> Physiology, and Perception, Science, </journal> <volume> 240 </volume> <pages> 740-749. </pages>
Reference-contexts: It is known that low-level motion detectors are highly sensitive to luminance but not color <ref> (Livingstone & Hubel, 1988) </ref>. A circular counterfeit grating (two identical circular gratings moving in opposite directions, clockwise and anti-clockwise) was used. The key finding is that even when the two gratings were equi-luminant, subjects were still able to track their motion.
Reference: <author> Mahoney, J, V. </author> <title> (1987) Image Chunking: Defining Spatial Building Blocks for Scene Analysis. </title> <note> MIT Artificial Intelligence Laboratory Technical Report No. 980. </note>
Reference-contexts: Recovering more complex relations clearly requires some form of sequential processing, probably utilizing attention. Good examples are tasks like determining, in an image containing squares and 70 circles, whether there is a square next to the second largest circle <ref> (Mahoney, 1987) </ref>. It is highly unlikely that we have feed forward networks for computing such predicates. 7.2.4 Computing Motion There has been some recent evidence that covert attention is involved in the computation of motion. A simple demonstration of this is outlined in Figure 7.7.
Reference: <editor> McClelland, J.L., and Rumelhart, D.E. (Eds.) </editor> <booktitle> (1986) Parallel Distributed Pr ocessing: Explorations in the Microstructure of Cognition. </booktitle> <address> Cambridge, MA, </address> <publisher> MIT Press. </publisher>
Reference-contexts: With a compact representation, the network can easily learn the correct function with very few training examples. This was demonstrated by feeding the outputs of the working memory to a backpropagation network <ref> (McClelland & Rumelhart, 1986) </ref> which was used to learn to classify equilateral triangles. The training images consisted of random triangles, approximately 50% of which were equilateral. Some noise was added around each vertex. For each image the focus of attention was initialized to cover the entire image plane. <p> The only difference is that the unit uses a sigmoid instead of a threshold which results in a soft decision boundary instead of a hard one (Section 8.1.3). It is simple to modify back propagation to deal with second order units <ref> (Rumelhart & McClelland, 1986) </ref>. Given a second order unit and an error signal , the update rule for each weight is: (9.5) where is computed as in standard back propagation. Given appropriate teacher signals, second order threshold units using back propagation learning are capable of learning the correct mapping. <p> The net input to the unit was a second order weighted sum with one weight for every pair-wise conjunction of its 1. Second order units in turn are a special case of sigma-pi units <ref> (Rumelhart & McClelland, 1986) </ref>.
Reference: <author> McLeod, P., Driver, J., and Crisp, J. </author> <title> (1988) V isual Search for a Conjunction of Movement and Form is Parallel. </title> <journal> Nature, </journal> <volume> 332 </volume> <pages> 154-155. </pages>
Reference-contexts: Single feature searches produced consistently at slopes. A difficult search task (such as search for a ran 2 1 66 domly oriented T among randomly oriented Ls) produced consistently steep slopes. Conjunction Search in Constant Time Some authors have reported conjunctive searches which always result in at slopes. <ref> (McLeod, et. al, 1988) </ref> report that the detection of a moving X among static Xs and moving Os can be done in parallel. 1 (Nakayama and Silverman, 1986) tested conjunction searches using the features color, motion, and depth. <p> The actual images they used were 2D images, so a disparity based feature map cannot account for the results. Motion is another feature that seems to have similar characteristics. Preliminary experimental evidence along these lines is found in <ref> (McLeod et al, 1988) </ref> who show that conjunction targets defined by motion and form can be detected in constant time. (McLeod et. al, 1991) argue for the existence of a motion filter that can segregate moving objects by direction of motion. Attention is also useful in non-visual modalities as well.
Reference: <author> McLeod, P., Driver, J., Dienes, Z., and Crisp, J. </author> <title> (1991) Filtering by Movement in Visual Search. Journal of Experimental Psychology: </title> <booktitle> Human Perception and Performance 17(1) </booktitle> <pages> 55-64. </pages>
Reference-contexts: Motion is another feature that seems to have similar characteristics. Preliminary experimental evidence along these lines is found in (McLeod et al, 1988) who show that conjunction targets defined by motion and form can be detected in constant time. <ref> (McLeod et. al, 1991) </ref> argue for the existence of a motion filter that can segregate moving objects by direction of motion. Attention is also useful in non-visual modalities as well. A good example is audition, where attention is often necessary to distinguish individual sounds.
Reference: <author> Mead, C. </author> <title> (1989) Analog VLSI and Neural Systems. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA. </address>
Reference: <author> Mel, B.W., and Koch, C. </author> <title> (1990) Sigma-Pi Learning: On Radial Basis Functions and Cortical Associative Learning. </title> <editor> In: Touretzky, D.S. (ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: Second order units in turn are a special case of sigma-pi units (Rumelhart & McClelland, 1986). Such units have been proposed as a model of computation in cortical neurons <ref> (Mel & Koch, 1990) </ref>. s x ( ) 1 e x-+ r 2 x 2 - 2xX i y 2 - 2yY i X i 2 +( )-+ + w ikj D d i o k o j = d i 82 inputs.
Reference: <author> Minsky, M. and Papert, S. </author> <title> (1969) Perceptrons: An Introduction to Computational Geometry. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: A better strategy would be to have one central process for detecting complex features that can be directed towards any region in the image. As early as 1969, Minsky and Papert presented formal proofs for these intuitive arguments <ref> (Minsky & Papert, 1969) </ref>. They showed that several simple visual predicates cannot be efficiently computed by feed forward threshold networks. For example, they proved that the connectivity predicate (the task of determining whether a curve is connected) requires an exponential number of weights.
Reference: <author> Moran, J., and Desimone, R. </author> <title> (1985) Selective Attention Gates Visual Processing in the Extrastriate 101 Cortex. </title> <booktitle> Science 229. </booktitle> <month> March </month> <year> 1985. </year>
Reference-contexts: There have been some non-local eye-saccade related effects reported in V1 and V2 such as an overall increase in activity just before saccades (Goldberg & Segraves, 1989). No local attentional effects have yet been seen, although people have actively looked for it <ref> (Moran & Des-imone, 1985) </ref>; 6.2.2 Areas V4 and IT In the traditional hierarchical view of the visual system, areas V4 and IT (inferotemporal cortex) would represent levels 4 and 5, after LGN, V1, and V2. There is some evidence in favor of this viewpoint.
Reference: <author> Mountcastle, V.B., Lynch, J.C., Georgopoulos, A., and Sakata, H. </author> <title> (1975) Posterior parietal association cortex of the monkey: command function for operations within extrapersonal space. </title> <journal> Journal of Neurophysiology, </journal> <volume> 38 </volume> <pages> 871-907. </pages>
Reference-contexts: They found that the activity of these neurons increased when the animal was in a state of attentive fixation. In an earlier paper, in the context of eye saccades they show that these neurons start firing about 55 msecs before an actual saccade <ref> (Mountcastle et. al, 1975) </ref>. They proposed that the posterior parietal cortex incorporated a general command center for oculomotor responses. (Mountcastle et. al, 1975) also found cells in posterior parietal areas that were sensitive to the direction of voluntary saccades, but not to spontaneous saccades. <p> In an earlier paper, in the context of eye saccades they show that these neurons start firing about 55 msecs before an actual saccade <ref> (Mountcastle et. al, 1975) </ref>. They proposed that the posterior parietal cortex incorporated a general command center for oculomotor responses. (Mountcastle et. al, 1975) also found cells in posterior parietal areas that were sensitive to the direction of voluntary saccades, but not to spontaneous saccades. One possibility is that these areas also encode a high-level priority map and that the superior colliculus is responsible only for spontaneous shifts of attention.
Reference: <author> Mountcastle, V.B., Anderson, R.A., and Motter, </author> <title> B.C. (1981) The Inuence of Attention Fixation Upon the Excitability of the Light-Sensitive Neurons of the Posterior Parietal Cortex. </title> <journal> The Journal of Neuroscience, </journal> <volume> 1(11) </volume> <pages> 1218-1235. </pages>
Reference-contexts: Lesion studies have provided further evidence along these lines. (Posner et. al, 1984) found that damage to posterior parietal lobe led to deficits in the ability to disengage covert attention away from a target. These functions are consistent with portions of the control network in VISIT. In <ref> (Mountcastle et. al, 1981) </ref> the authors tested the effect of behavioral state on light-sensitive neurons in the posterior parietal cortex (area 7) in monkeys. They found that the activity of these neurons increased when the animal was in a state of attentive fixation.
Reference: <author> Mozer, M. </author> <title> (1991) The Perception of Multiple Objects: A Connectionist Appr oach. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: It can be quite high if there are similar regions of activity that are widely separated. In simulations, AM with a 36x6 image array took anywhere from 20 to 100 iterations to settle <ref> (Mozer, 1991) </ref>. A second issue is that the region selection is based completely on local information. There is no explicit mechanism for using top-down location information to shift attention. AM has been used as a model of word recognition and can model many of the perceptual effects associated with reading.
Reference: <author> Mozer, M. </author> <title> (1988) A Connectionist Model of Selective Attention in Visual Perception. </title> <booktitle> In: Proceedings of the 10th Annual Meeting of the Cognitive Science Society. </booktitle>
Reference: <author> Nakayama, K., and Silverman, G. </author> <title> (1986) Serial and Parallel Processing of Visual Feature Conjunctions. </title> <journal> Nature, </journal> <volume> 320 </volume> <pages> 264-265. </pages>
Reference-contexts: Conjunction Search in Constant Time Some authors have reported conjunctive searches which always result in at slopes. (McLeod, et. al, 1988) report that the detection of a moving X among static Xs and moving Os can be done in parallel. 1 <ref> (Nakayama and Silverman, 1986) </ref> tested conjunction searches using the features color, motion, and depth. They found that motion-color conjunctions required serial processing, whereas depth-color and depth-motion conjunctions could be processed in parallel.
Reference: <author> Nissen, M.J. </author> <title> (1985) Accessing Features And Objects: Is Location Special? In: Posner , M.I. </title> <editor> and Marin, O.S.M., (Eds.), </editor> <booktitle> Attention And Performance XI (pp. </booktitle> <pages> 205-219). </pages> <publisher> Erlbaum, </publisher> <address> Hillsdale, NJ. </address>
Reference: <author> OConnell, K.M., and T reisman, A. </author> <title> (1991) Abstract Coding of Orientation as a V isual Feature. </title> <note> Submitted to Perception & Psychophysics. </note>
Reference-contexts: The experimental evidence for this is not completely clear. <ref> (OConnell & Treis-man, 1991) </ref> have recently done some experiments along this line. They show that oriented dot pairs can pop out in a field of horizontal dot pairs. The result holds even if the dots are of different colors.
Reference: <author> Obermayer, K., Ritter, H., and Schulten, K. </author> <title> (1991) Development and Spatial Structure of Cortical Feature Maps: A Model Study. </title> <editor> In: Touretzky, D.S., Lippman, R. (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 3. </booktitle>
Reference: <author> Pashler, H. </author> <title> (1988) Cross-dimensional interaction and texture segregation. </title> <journal> Perception & Psychophysics, </journal> <volume> 43(4) </volume> <pages> 307-318. </pages>
Reference: <author> Petersen, S.E., Robinson, D.L., and Keys, W. </author> <title> (1985) Pulvinar nuclei of the behaving rhesus monkey: Visual responses and their modulations. </title> <journal> Journal of Neurophysiology, </journal> <volume> 54 </volume> <pages> 867-886. </pages>
Reference-contexts: There is some fairly convincing evidence now that the pulvinar is in fact directly involved in the gating operation. Recordings of cells in the lateral pulvinar of awake, behaving monkeys have demonstrated a spatially localized enhancement effect tied to selective attention <ref> (Petersen et. al, 1985) </ref>. When presented with a stimulus in their receptive fields, these cells show an increase in their firing rate when the animal attends to it. This enhancement is seen regardless of whether the animal is about to make an eye saccade to that location.
Reference: <author> Petersen, S.E., Robinson, D.L., and Morris, J.D. </author> <title> (1987) Contributions of the pulvinar to visual spatial attention. </title> <journal> Neuropsychology, </journal> <volume> 25 </volume> <pages> 97-105. </pages>
Reference-contexts: The above studies have support from alternate experimental methods. Lesion studies and PET scans suggest that the pulvinar is involved in covert attention, particularly in the gating operation. Patients with thalamic lesions have difficulty engaging attention and inhibiting crosstalk from other locations <ref> (Petersen et. al, 1987) </ref>. In particular, these patients responded slower to cued targets even though there was sufficient time to attend. Lesioned monkeys give slower responses when competing events are present in the visual field (Posner & Petersen, 1990).
Reference: <author> Pomerleau, D. A. </author> <title> (1991) Rapidly Adapting Artificial Neural Networks for Autonomous Navigation. </title> <editor> In: Lippman, R., Moody, J., and Touretzky, D.S. (eds.), </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Posner, M.I., Cohen, Y., and Rafal, R.D. </author> <title> (1982) Neural Systems Control of Spatial Orienting. </title> <journal> Phil. </journal>
Reference-contexts: An easy way to do this is to inhibit the priority units corresponding to the object currently being visited. A similar scheme is believed to exist in people and has been termed inhibition of return <ref> (Posner, Cohen, & Rafal, 1982) </ref>. To implement this, we include an additional control signal that fires just before attention shifts to a new location. All the units that are within the focus of attention shut themselves off until a subsequent reset signal. <p> To facilitate comparison the text is divided into two broad topics: the mechanics of visual attention (how it is implemented), and its use. 6.1 Psychophysical Insights Into the Implementation 6.1.1 Evidence that Attention Exists The first experimental evidence for covert visual attention was obtained from reaction time studies <ref> (for a review see Posner, Cohen, & Rafal, 1982) </ref>. In a typical experiment, subjects are shown a display consisting of three squares. The task is to press a button as soon as the target object appears in one of the boxes and the reaction time of the subject is measured. <p> Saccadic eye movements are ruled out in these experiments. This clearly demonstrates that an internal change in processing efficiency occurs and that the effect is spatially localized. 6.1.2 How Long Does Attention Take? By varying the delay between the presentation of the cue and the target, <ref> (Posner, Cohen, & Rafal, 1982) </ref> were able to study the speed with which attention can work. With a delay of 0 msecs, there is no cued-side advantage, but changes in reaction time can begin as soon as 50 msecs after cue presentation. <p> The literature shows that several types of bottom up cues can attract attention. For example, an object containing a distinctive feature often attracts attention. In addition, changes in image features are often powerful cues for attracting attention. For example, in <ref> (Posner, Cohen, & Rafal, 1982) </ref>, both increases or decreases in edge intensity resulted in a cued-side advantage. (Yantis & Jonides, 1990) show that 47 stimuli appearing suddenly are more likely to attract attention than persistent stimuli. <p> Follow-up experiments suggest that after a delay, stimuli which had appeared abruptly have the same priority as non-abrupt stimuli, suggestive of a priority value that decays with time (Yantis & Jones, 1990). Top Down Processing Top down information can also have a large inuence on attended locations. In <ref> (Posner, Cohen, & Rafal, 1982) </ref>, a high-level cue (such as a central arrow indicating direction) could serve to attract attention. In addition, if a cue appears consistently on the wrong side, the subject learns through experience to shift attention automatically to the opposite box (this takes about 300 msecs). <p> This effect was found even at the extremely brief duration of 33 msecs! These results suggest that a SWIFT type search strategy might even play a role for very high-level features, such as novelty or familiarity. 6.1.4 Inhibition of return <ref> (Posner, Cohen & Rafal, 1982) </ref> have compared the efficiency of cued locations against other locations of equal eccentricity after initial cue onset. The results suggest that attention shifts temporarily decrease the priority of locations after the initial visit. <p> Interestingly, this mechanism seems to be quite selective. Inhibition of return does not occur with central locations but seems to co-occur only with shifts to peripheral locations <ref> (Posner, Cohen & Rafal, 1982) </ref>. Experiments reported in (Rafal et. al, 1989) show that the inhibition does not occur with endogenously generated shifts of attention (e.g. one induced by a high-level stimuli such as an arrow) unless the subject is about to make a saccade to that location. <p> VISIT uses the same representation as the error maps in superior colliculus to assist in bottom-up attentional shifts. The superior colliculus is primarily involved in the generation of eye saccades (Wurtz & Goldberg, 1989) but it does have some relationship with covert attention. In <ref> (Posner, Cohen, & Rafal, 1982) </ref> the authors studied patients with a particular form of Parkinsons disease where the SC is damaged. 57 These patients are able to make horizontal, but not vertical eye saccades. <p> Delay 72 ship. 7.3.1 Relationship to Eye Saccades Covert attention seems to be very closely related to eye saccades. The experiments described in <ref> (Posner et. al, 1982) </ref> show that covert attention almost always moves to the intended target of an eye saccade about 200 msecs before the eyes begin to move. Clearly the converse is not true: attention movements do not always result in eye movements. In (Posner et. al, 1982) patients unable to <p> The experiments described in <ref> (Posner et. al, 1982) </ref> show that covert attention almost always moves to the intended target of an eye saccade about 200 msecs before the eyes begin to move. Clearly the converse is not true: attention movements do not always result in eye movements. In (Posner et. al, 1982) patients unable to saccade in the vertical direction were also slower at shifting attention vertically. Section 6.2 discussed various areas of the brain that seem to be involved in covert attention.
Reference: <author> Trans. R. </author> <title> Soc. </title> <journal> Lond. </journal> <volume> B 298, </volume> <pages> pp 187-198. </pages>
Reference: <author> Posner, M.I., Walker, J.A., Friedrich, F.J., and Rafal, R.D. </author> <title> (1984) Effects of Parietal Injury on Co 102 vert Orienting of Attention. </title> <journal> The Journal of Neuroscience, </journal> <volume> 4(7) </volume> <pages> 1863-1874. </pages>
Reference-contexts: It receives a significant projection from superior colliculus and is thought to be involved in the production of voluntary eye saccades (Andersen & Gnadt, 1989). Experiments show that it is also involved in covert shifts of attention. Lesion studies have provided further evidence along these lines. <ref> (Posner et. al, 1984) </ref> found that damage to posterior parietal lobe led to deficits in the ability to disengage covert attention away from a target. These functions are consistent with portions of the control network in VISIT.
Reference: <author> Posner, M.I., and Petersen, </author> <title> S.E. (1990) The Attention System of the Human Brain. </title> <journal> Annual Review of Neuroscience, </journal> <volume> 13 </volume> <pages> 25-42. </pages>
Reference-contexts: Patients with thalamic lesions have difficulty engaging attention and inhibiting crosstalk from other locations (Petersen et. al, 1987). In particular, these patients responded slower to cued targets even though there was sufficient time to attend. Lesioned monkeys give slower responses when competing events are present in the visual field <ref> (Posner & Petersen, 1990) </ref>. LaBerge (1990) presents PET scans of human subjects taken during a letter discrimination task. By varying the difficulty of the discrimination he was able to regulate the amount of attention required. <p> The experiments showed that although the patients were still able to move their covert attention in both the horizontal and vertical directions, the speed of orienting in the vertical direction was much slower. In addition <ref> (Posner & Petersen, 1990) </ref> mention that patients with this damage shift attention to previously attended locations as readily as new ones, indicating a deficit in the inhibition of return mechanism. The deficits are consistent with the functionality of the priority map in VISIT. <p> The deficits are consistent with the functionality of the priority map in VISIT. Psychophysical experiments strongly suggest a linkage between the saccadic and covert attention systems (see Section 7.3.1). Since covert attention almost always shifts to a location just prior to an eye saccade <ref> (Posner & Petersen, 1990) </ref>, it is possible that the same neural hardware serves as the basic priority maps for both the covert attentional and saccadic mechanisms. 6.2.5 Posterior Parietal Cortex The posterior parietal cortex contains neurons responsive to visual stimuli. <p> The role of V4 and IT is not quite clear since it also seems to gate activity. It is possible that it is an additional gating system imposed on top of the early features. <ref> (Posner & Petersen, 1990) </ref> have proposed a slightly different hypothesis. They suggest that neurons in parietal lobe disengage attention from the present focus, those in superior colliculus shift attention to the target, and neurons in pulvinar engage attention on it. It is interesting to compare the two.
Reference: <author> Rafal, R.D., and Inhof f, A.W. </author> <title> (1986) Midbrain Mechanisms for Orienting V isual Attention. </title> <booktitle> In: Proceedings of the 8th Annual Conference of the Cognitive Science Society, </booktitle> <address> Amherst, MA. </address>
Reference: <author> Rafal, R.D., Posner, M.I., Friedman, J.H., Inhoff, A.W., and Bernstein, E. </author> <title> (1988) Orienting of Visual Attention in Progressive Supranuclear Palsy. </title> <booktitle> Brain 111 </booktitle> <pages> 267-280. </pages>
Reference: <author> Rafal, R.D., Calabresi, P.A., Brennan, C.W., and Sciolto, </author> <title> T.K. (1989) Saccade Preparation Inhibits Reorienting to Recently Attended Locations. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 15(4) </volume> <pages> 673-685. </pages>
Reference-contexts: Interestingly, this mechanism seems to be quite selective. Inhibition of return does not occur with central locations but seems to co-occur only with shifts to peripheral locations (Posner, Cohen & Rafal, 1982). Experiments reported in <ref> (Rafal et. al, 1989) </ref> show that the inhibition does not occur with endogenously generated shifts of attention (e.g. one induced by a high-level stimuli such as an arrow) unless the subject is about to make a saccade to that location.
Reference: <author> Ramachandran, V. S. </author> <title> (1988) Perceiving Shape from Shading. In: Rock, </title> <editor> I. (Ed.) </editor> <title> The Perceptual World: Readings From Scientific American, W.H. </title> <publisher> Freeman, </publisher> <address> New York. </address>
Reference: <author> Robinson, D.L., and McClurkin, J.W. </author> <title> (1989) The visual superior colliculus and pulvinar. </title> <editor> In: Wurtz, R.H., and Goldberg, M.E. (Eds.) </editor> <title> The Neurobiology of Saccadic Eye Movements. </title> <publisher> Elsevier, </publisher> <address> New York. </address>
Reference: <author> Rock, I., Linnett, C.M., Grant, P., and Mack, A. </author> <title> (1990) Results of a New Method for Investigating Inattention in Visual Perception. </title> <booktitle> Paper presented at 31st annual meeting of the Psychonomic Society, </booktitle> <address> New Orleans, LA, </address> <month> November, </month> <year> 1990. </year>
Reference-contexts: Using this configuration the network can efficiently access both local and global feature information simultaneously. There is some psychological evidence to support this. Even when attention is highly focused, people are able to report primitive features of objects appearing outside the focus of attention, but not combinations of features <ref> (Rock et. al, 1990) </ref>. Gate Units Gated Feature Maps A x A r Feature Image Maps Global ORs 32 5.1.3 The Priority Network The job of the priority network is to rank image locations in order of relevance.
Reference: <author> Rose, D., and Dobson, V.G., Eds. </author> <title> (1985) Models of the Visual Cortex. </title> <publisher> John Wiley & Sons, </publisher> <address> NY. </address>
Reference: <author> Sandon, P. A. </author> <title> (1990) Simulating Visual Attention. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 2(3) </volume> <pages> 213-231. </pages>
Reference: <author> Schiller, P.H., and Lee, K. </author> <title> (1991) The Role of the Primate Extrastriate Area V4 in Vision. </title> <booktitle> Science 251 </booktitle> <pages> 1251-1253, </pages> <month> 8 March </month> <year> 1991. </year>
Reference: <author> Schiller, P.H. </author> <title> (1985) A Model for the Generation of Visually Guided Saccadic Eye Movements. </title> <editor> In: Rose, D., and Dobson, V.G. (Eds.) </editor> <title> Models of the Visual Cortex. </title> <publisher> John Wiley & Sons, </publisher> <address> NY. </address>
Reference-contexts: A detailed review of the biology of vision is beyond the scope of this thesis. Two good books dealing with the topics covered here are (Spillman & Werner, 1990) and (Wurtz & Goldberg, 1989). For shorter reviews see (Van Essen & Anderson, 1990) and <ref> (Schiller, 1985) </ref>. arrow are known to be bi-directional. Retina LGN Pulvinar MT IT V2 PP PreFront. 52 LGN. The optic radiation proceeds to the primary visual cortex. The LGN is part of the thalamus (Figure 6.3 and Figure 6.4) and is the primary target of retinal axons. <p> It is thought to have a role analogous to the superior colliculus, and is particularly sensitive to high-resolution color stimuli <ref> (Schiller, 1985) </ref>. It may also be involved in saccades to complex stimuli (Goldberg & Segraves, 1989). The role of the FEF in covert attention is not known. However, given the close correspondence between saccades and covert attention, a reasonable conjecture is that it plays the same role for attention.
Reference: <author> Sejnowski, T.J. </author> <title> (1986) Open Questions About Computation in Cerebral Cortex. </title> <editor> In McClelland, J.L., and Rumelhart, D.E. (Eds.) </editor> <booktitle> Parallel Distributed Processing: Explorations in the Micro-structure of Cognition. </booktitle> <address> Cambridge, MA, </address> <publisher> MIT Press. </publisher>
Reference-contexts: This dilemma is called the binding problem and appears in several different forms. Sejnowski refers to it as one of the fundamental open problems in neural computation and writes: the binding problem is a touchstone for testing network models that claim to have psychological validity <ref> (Sejnowski, 1986) </ref>. Obviously, people can associate feature combinations with objects, so there must be a way around the binding problem. We know of some operations that can be performed efficiently in parallel. For example it is possible to compute a global OR of each feature map.
Reference: <author> Sparks, D. L. </author> <title> (1986) Translation of Sensory Signals into Commands for Control of Saccadic Eye Movements: Role of Primate Superior Colliculus, </title> <journal> Physiological Reviews, </journal> <volume> 66 (1). </volume>
Reference-contexts: This is supported by the fact that the different maps are always in spatial register, i.e. that neighboring neurons in different maps are always referring to the same absolute spatial location (Jay & Sparks, 1984). The deep layers of the superior colliculus contain error maps for eye saccades <ref> (Sparks, 1986) </ref>. These neurons are laid out retinotopically in clusters, but at each location the cluster activity represents a value in motor coordinates. That is, they code the direction and amplitude of the eye saccade that would foveate on that spot.
Reference: <author> Spillman, L., and W erner, J.S. </author> <title> (1990) Visual Perception: </title> <booktitle> The Neur ophysiological Foundations. </booktitle> <publisher> 103 Academic Press, Inc., </publisher> <address> Berkeley, CA. </address>
Reference-contexts: Long axons from retinal ganglion cells form the optic nerve which terminates at the 1. A detailed review of the biology of vision is beyond the scope of this thesis. Two good books dealing with the topics covered here are <ref> (Spillman & Werner, 1990) </ref> and (Wurtz & Goldberg, 1989). For shorter reviews see (Van Essen & Anderson, 1990) and (Schiller, 1985). arrow are known to be bi-directional. Retina LGN Pulvinar MT IT V2 PP PreFront. 52 LGN. The optic radiation proceeds to the primary visual cortex.
Reference: <author> Srinivas, K., and Barnden, J. </author> <title> (1989) Temporal Winner Take All Networks for arbitrary selection in connectionist and neural networks. </title> <booktitle> In: Proceedings of the International Joint Confer ence on Neural Networks, </booktitle> <year> 1989. </year>
Reference-contexts: It might be feasible if every level computed the max over a large number of neurons. For digital implementations, an attractive possibility is the mechanism described in <ref> (Srinivas and Barnden, 1989) </ref>. Their network selects the maximum in time logarithmic in the number of active units, and not the total number of units. Given that top-down mechanisms can often eliminate many of the locations in parallel, this scheme is likely to provide a fast response time.
Reference: <author> Suarez, H., and Koch, C. </author> <title> (1989) Linking Linear Threshold Units with Quadratic Models of Motion Perception. </title> <journal> Neural Computation, </journal> <volume> 1(3) </volume> <pages> 318-320. </pages>
Reference: <author> Treisman, A., and Gelade. </author> <title> (1980) A Feature Integration Theory of Attention. </title> <journal> Cognitive Psychology, </journal> <volume> 12 </volume> <pages> 97-136. </pages>
Reference-contexts: In our architecture, search will always be linear in M. Note that the above equation correctly predicts the time required for the original single and conjunctive feature searches. In conjunctive feature searches <ref> (Treisman & Gelade, 1980) </ref>, if the features of the distractors are chosen randomly, on average , thus the model predicts search time that is linear in D. <p> Most of the experiments are aimed at uncovering the boundary conditions for these two modes. The following sections review some of this literature and its relationship to VISIT. 7.1.1 Single vs. Conjunctive Feature Search In <ref> (Treisman & Gelade, 1980) </ref> the authors suggested that search for a target defined by a conjunction of features requires serial search, whereas single feature search does not.
Reference: <author> Treisman, A., and Schmidt, H. </author> <title> (1982) Illusory Conjunctions in the Perception of Objects. </title> <journal> Cognitive Psychology, </journal> <volume> 14 </volume> <pages> 107-141. </pages>
Reference-contexts: The visual search experiments provide some support for this argument. In addition <ref> (Treisman & Schmidt, 1982) </ref> present some direct evidence. Subjects were shown an image containing two letters of different colors. When the exposure time was very short, subjects would often switch the colors of the two objects. These illusory conjunctions did not occur when there was sufficient time to focus.
Reference: <author> Treisman, A., and Paterson, R. </author> <title> (1984) Emergent Features, Attention and Object Perception. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 10(1) </volume> <pages> 12-31. </pages>
Reference: <author> Treisman, A. </author> <title> (1988) Features and Objects: The Fourteenth Bartlett Memorial Lecture. </title> <journal> The Quarterly Journal of Experimental Psychology, </journal> <volume> 40A (2). </volume>
Reference-contexts: Perhaps the most pertinent to the binding problem is the work on visual search <ref> (Treisman & Gormican, 1988) </ref>. <p> By 150 msecs, there is a marked improvement in efficiency. (Julesz & Bergen, 1987) have reported similar figures - they claim that attention only takes about 40 msecs. In tasks that require multiple shifts of attention, such as visual search, figures as low as 20-30 msecs have been reported <ref> (Treisman, 1988) </ref>. Given that individual neurons can only fire once every 5-10 msecs, this leaves at most 4-10 sequential steps per shift. These values are quite astonishing considering that each shift entails disengaging attention from the current location, deciding which location to visit next, and performing the actual shift. <p> Searching for a line oriented 18 o among vertical lines can be done in constant time, but searching (a) 63 for a vertical line among these oblique lines takes linear time <ref> (Treisman & Gormican, 1988) </ref>. This asymmetry is explained by assuming that the early representation includes a finite number of orientations that are coarse coded, with units for vertical and some orientation greater than 18 o . <p> When the exposure time was very short, subjects would often switch the colors of the two objects. These illusory conjunctions did not occur when there was sufficient time to focus. It has also been shown that prior expectations can eliminate these effects <ref> (Treisman, 1988) </ref>. For example subjects do not switch features if it leads to a nonsense assignment. VISIT is consistent with this. When attention is diffused over more than one object, the network cannot associate the active features with any one object.
Reference: <author> Treisman, A., and Gormican, S. </author> <title> (1988) Feature Analysis in Early Vision: Evidence From Search Asymmetries. </title> <journal> Psychological Review, </journal> <volume> 95(1) </volume> <pages> 15-48. </pages>
Reference-contexts: Perhaps the most pertinent to the binding problem is the work on visual search <ref> (Treisman & Gormican, 1988) </ref>. <p> By 150 msecs, there is a marked improvement in efficiency. (Julesz & Bergen, 1987) have reported similar figures - they claim that attention only takes about 40 msecs. In tasks that require multiple shifts of attention, such as visual search, figures as low as 20-30 msecs have been reported <ref> (Treisman, 1988) </ref>. Given that individual neurons can only fire once every 5-10 msecs, this leaves at most 4-10 sequential steps per shift. These values are quite astonishing considering that each shift entails disengaging attention from the current location, deciding which location to visit next, and performing the actual shift. <p> Searching for a line oriented 18 o among vertical lines can be done in constant time, but searching (a) 63 for a vertical line among these oblique lines takes linear time <ref> (Treisman & Gormican, 1988) </ref>. This asymmetry is explained by assuming that the early representation includes a finite number of orientations that are coarse coded, with units for vertical and some orientation greater than 18 o . <p> When the exposure time was very short, subjects would often switch the colors of the two objects. These illusory conjunctions did not occur when there was sufficient time to focus. It has also been shown that prior expectations can eliminate these effects <ref> (Treisman, 1988) </ref>. For example subjects do not switch features if it leads to a nonsense assignment. VISIT is consistent with this. When attention is diffused over more than one object, the network cannot associate the active features with any one object.
Reference: <author> Treisman, A., and Sato, S. </author> <title> (1990) Conjunction Search Revisited. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 16 </volume> (3):459-478. 
Reference-contexts: Unfortunately the mapping between the two is not always clear. For example, some cells code for a combination of spatial frequency and orientation (De Valois & De Valois, 1988) which seems to be perceptually unnatural. There are also some discrepancies between psychological and physiological findings <ref> (Treisman & Sato, 1990) </ref>. Nevertheless perceptual features are almost certainly derived from the responses of cells in V1 and V2. There are many correlations between perceptual features and V1 cell properties, so as a first approximation VISIT models the two as being identical. <p> This would necessitate a scan through the objects. Variation in irrelevant dimensions however should cause no activity in the relevant feature map, so SWIFT search will always locate the target in one step. 7.1.4 Fast Conjunction Search Large Variances in Search Slopes In (Cave & Wolfe, 1990) and <ref> (Treisman & Sato, 1990) </ref> the authors reported that search slopes could vary by a large amount across subjects. Conjunction searches of color and form produced wide variances. The slopes for some subjects were almost at, whereas others were quite steep. Single feature searches produced consistently at slopes. <p> They found that motion-color conjunctions required serial processing, whereas depth-color and depth-motion conjunctions could be processed in parallel. Recently <ref> (Treisman & Sato, 1990) </ref> and (Wolfe, Cave & Franzel, 1989) have suggested models where conjunctions can be detected in constant time with top-down information. <p> Since the features can be learned through experience, the particular combinations represented would vary from individual to individual. 1. Although, in what seems to be a direct contradiction to this result, <ref> (Treisman and Sato, 1990) </ref> report that conjunctions of motion and orientation produced the steepest slopes in their subjects. 67 Both assumptions have some evidence to support it. <p> However it was not consistent with some of the newer results, such as search within a feature, the parallel processing of conjunctions, etc. The theory has since been modified to include a notion of priority similar to that discussed in Section 5.3.2 <ref> (Treisman & 90 Sato, 1990) </ref>, but the mechanisms for setting the priority levels have not yet been specified clearly. 10.1.2 Guided Search Guided Search was proposed by Cave and Wolfe (1990) to account for the results obtained in visual search experiments that conict with Feature Integration Theory.
Reference: <author> Tsotsos, J. </author> <title> (1990) Analyzing V ision at the Complexity Level. </title> <booktitle> Behavioral and Brain Sciences , 13 </booktitle> <pages> 423-469. </pages>
Reference: <author> Ullman, S. </author> <title> (1984) Visual Routines. </title> <journal> Cognition, </journal> <volume> 18 </volume> <pages> 97-159. </pages>
Reference: <author> Van Essen, D., and Anderson, C. H. </author> <title> (1990) Information Processing Strategies and Pathways in the Primate Retina and Visual Cortex. In: An introduction to neural and electronic networks, </title> <editor> Zor-netzer, S.F., Davis, J.L., and Lau, C. (Eds). </editor> <publisher> Academic Press, </publisher> <year> 1990. </year>
Reference-contexts: To see this, consider the nature of massively parallel visual processing. In the brain, early stages contain individual neurons dedicated to computing local features at every image location in parallel (see Figure 2.1). There are neurons for detecting orientation, color, motion, depth, spatial frequency, etc. <ref> (Van Essen & Anderson, 1990) </ref>. In terms of computation time this is a very efficient strategy. Due to the large number of pixels in realistic images, most researchers agree that similar parallel processing is required for computational vision. <p> A detailed review of the biology of vision is beyond the scope of this thesis. Two good books dealing with the topics covered here are (Spillman & Werner, 1990) and (Wurtz & Goldberg, 1989). For shorter reviews see <ref> (Van Essen & Anderson, 1990) </ref> and (Schiller, 1985). arrow are known to be bi-directional. Retina LGN Pulvinar MT IT V2 PP PreFront. 52 LGN. The optic radiation proceeds to the primary visual cortex. <p> For example, it is known that area MT contains cells which are tuned to both direction of motion as well as orientation <ref> (Van Essen & Anderson, 1990) </ref>.
Reference: <author> Williams, R.J. and Zipser, D. </author> <title> (1988) A Learning Algorithm for Continually Running Fully Recurrent Neural Networks. </title> <institution> University of California at San Diego, </institution> <type> ICS Tech Report #8805. </type>
Reference-contexts: It should also be possible to construct a reinforcement learning scenario so that a global signal can be used to train the map. A more difficult problem is training the control networks. This system is characterized by feedback pathways, interesting dynamics, and not much regularity. <ref> (Williams & Zipser, 1988) </ref> describe experiments showing how some simple control structures can be learned in recurrent networks. In general however this type of learning is not well understood. For example, it is not all clear how a search strategy such as SWIFT could evolve.
Reference: <author> Wise, S.P., and Desimone, R. </author> <title> (1988) Behavioral Neurophysiology: Insights into Seeing and Grasping. </title> <booktitle> Science 242 </booktitle> <pages> 736-740. </pages>
Reference-contexts: There is some evidence for this in the literature. In a review article <ref> (Wise & Desimone, 1988) </ref> mention that, even with voluntary effort, when presented with multiple targets simultaneously, the first eye saccade lands at an intermediate position. This is consistent with the notion that attention is required to individuate the locations of multiple objects.
Reference: <author> Wolfe, J.M., Cave, K.R., and Franzel, </author> <title> S.L. (1989) Guided Search: An alternative to the modified feature integration model for visual search. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 15 </volume> <pages> 419-433. </pages>
Reference-contexts: They found that motion-color conjunctions required serial processing, whereas depth-color and depth-motion conjunctions could be processed in parallel. Recently (Treisman & Sato, 1990) and <ref> (Wolfe, Cave & Franzel, 1989) </ref> have suggested models where conjunctions can be detected in constant time with top-down information.
Reference: <author> Wurtz, R.H., and Goldber g, </author> <title> M.E., Eds. (1989) The Neurobiology of Saccadic Eye Movements . 104 Elsevier, </title> <address> New York. </address>
Reference-contexts: It is quite possible that both types exist. It is well known that eye movements have two forms: continuous pursuit when the eye is following a moving object, and jumpy saccades as when the eye fixates on a novel object <ref> (Wurtz & Goldberg, 1989) </ref>. There has been recent preliminary evidence indicating that covert attention is also used in motion computations (see Section 7.2.4) so it is quite plausible that covert attention contains analogous smooth pursuit and saccadic movements. <p> Long axons from retinal ganglion cells form the optic nerve which terminates at the 1. A detailed review of the biology of vision is beyond the scope of this thesis. Two good books dealing with the topics covered here are (Spillman & Werner, 1990) and <ref> (Wurtz & Goldberg, 1989) </ref>. For shorter reviews see (Van Essen & Anderson, 1990) and (Schiller, 1985). arrow are known to be bi-directional. Retina LGN Pulvinar MT IT V2 PP PreFront. 52 LGN. The optic radiation proceeds to the primary visual cortex. <p> VISIT uses the same representation as the error maps in superior colliculus to assist in bottom-up attentional shifts. The superior colliculus is primarily involved in the generation of eye saccades <ref> (Wurtz & Goldberg, 1989) </ref> but it does have some relationship with covert attention. In (Posner, Cohen, & Rafal, 1982) the authors studied patients with a particular form of Parkinsons disease where the SC is damaged. 57 These patients are able to make horizontal, but not vertical eye saccades. <p> Section 6.2 discussed various areas of the brain that seem to be involved in covert attention. It is interesting to note that all of these areas are also involved in eye saccades <ref> (Wurtz & Goldberg, 1989) </ref>. These experiments imply that the two systems are highly related but can be decoupled. There might be a good computational reason for this relationship. The covert attention system is much faster than eye saccades.
Reference: <author> Yantis, S., and Jonides, J. </author> <title> (1990) Abrupt Visual Onsets and Selective Attention: Voluntary Versus Automatic Allocation. </title> <journal> Journal of Experimental Psychology: Human Per ception and Performance, </journal> <volume> 16(1) </volume> <pages> 121-134. </pages>
Reference-contexts: In the previous chapter larger point clusters were always given higher priority than small ones. This was sufficient for sparse dot-images, but for cluttered, realistic scenes this simple model will result in very inefficient search sequences. Several psychophysical experiments have pointed out other possibilities. <ref> (Yantis & Jonides, 1990) </ref> have shown that stimuli which appear abruptly are attended to sooner than persistent stimuli. This can be overriden by explicitly instructing the subject to concentrate on a particular location. <p> For example, an object containing a distinctive feature often attracts attention. In addition, changes in image features are often powerful cues for attracting attention. For example, in (Posner, Cohen, & Rafal, 1982), both increases or decreases in edge intensity resulted in a cued-side advantage. <ref> (Yantis & Jonides, 1990) </ref> show that 47 stimuli appearing suddenly are more likely to attract attention than persistent stimuli. <p> Follow-up experiments suggest that after a delay, stimuli which had appeared abruptly have the same priority as non-abrupt stimuli, suggestive of a priority value that decays with time <ref> (Yantis & Jones, 1990) </ref>. Top Down Processing Top down information can also have a large inuence on attended locations. In (Posner, Cohen, & Rafal, 1982), a high-level cue (such as a central arrow indicating direction) could serve to attract attention. <p> The experiments in (Egeth, Virzi, & Garbart, 1984) suggest that attention can be restricted to objects containing a particular feature if the subject is told about the feature in advance. <ref> (Yantis & Jonides, 1990) </ref> provide further evidence along these lines. They report that, although abrupt stimuli seem to have higher priority over non-abrupt stimuli, this can be overridden if the subject is already focused on another task. <p> Integrating Top Down and Bottom Up Information These experiments together illustrate a highly exible system for deciding on the next location. Both top-down and bottom-up information must play a role. <ref> (Yantis & Jonides, 1990) </ref> suggest a hierarchical priority system that assigns variable priorities to spatial locations. In their scheme, locations which are currently being attended to have higher priority than abrupt onsets which in turn have higher priority than non-onsets. VISIT implements a generalized version of the above hypothesis.
Reference: <author> Yantis, S. and Johnston, </author> <title> J.C. (1990) On the Locus of Visual Selection: Evidence from Focused Attention Tasks. Journal of Experimental Psychology: </title> <booktitle> Human Per ception and Performance , 16(1) </booktitle> <pages> 135-149. </pages>
Reference-contexts: In the previous chapter larger point clusters were always given higher priority than small ones. This was sufficient for sparse dot-images, but for cluttered, realistic scenes this simple model will result in very inefficient search sequences. Several psychophysical experiments have pointed out other possibilities. <ref> (Yantis & Jonides, 1990) </ref> have shown that stimuli which appear abruptly are attended to sooner than persistent stimuli. This can be overriden by explicitly instructing the subject to concentrate on a particular location. <p> For example, an object containing a distinctive feature often attracts attention. In addition, changes in image features are often powerful cues for attracting attention. For example, in (Posner, Cohen, & Rafal, 1982), both increases or decreases in edge intensity resulted in a cued-side advantage. <ref> (Yantis & Jonides, 1990) </ref> show that 47 stimuli appearing suddenly are more likely to attract attention than persistent stimuli. <p> Follow-up experiments suggest that after a delay, stimuli which had appeared abruptly have the same priority as non-abrupt stimuli, suggestive of a priority value that decays with time <ref> (Yantis & Jones, 1990) </ref>. Top Down Processing Top down information can also have a large inuence on attended locations. In (Posner, Cohen, & Rafal, 1982), a high-level cue (such as a central arrow indicating direction) could serve to attract attention. <p> The experiments in (Egeth, Virzi, & Garbart, 1984) suggest that attention can be restricted to objects containing a particular feature if the subject is told about the feature in advance. <ref> (Yantis & Jonides, 1990) </ref> provide further evidence along these lines. They report that, although abrupt stimuli seem to have higher priority over non-abrupt stimuli, this can be overridden if the subject is already focused on another task. <p> Integrating Top Down and Bottom Up Information These experiments together illustrate a highly exible system for deciding on the next location. Both top-down and bottom-up information must play a role. <ref> (Yantis & Jonides, 1990) </ref> suggest a hierarchical priority system that assigns variable priorities to spatial locations. In their scheme, locations which are currently being attended to have higher priority than abrupt onsets which in turn have higher priority than non-onsets. VISIT implements a generalized version of the above hypothesis.
Reference: <author> Yantis, S., and Johnson, D. </author> <title> (1990) Mechanisms of Attentional Priority. </title> <journal> Journal of Experimental Psychology: Human Perception and Performance, </journal> <volume> 16(4) </volume> <pages> 812-825. </pages>
Reference-contexts: In the previous chapter larger point clusters were always given higher priority than small ones. This was sufficient for sparse dot-images, but for cluttered, realistic scenes this simple model will result in very inefficient search sequences. Several psychophysical experiments have pointed out other possibilities. <ref> (Yantis & Jonides, 1990) </ref> have shown that stimuli which appear abruptly are attended to sooner than persistent stimuli. This can be overriden by explicitly instructing the subject to concentrate on a particular location. <p> For example, an object containing a distinctive feature often attracts attention. In addition, changes in image features are often powerful cues for attracting attention. For example, in (Posner, Cohen, & Rafal, 1982), both increases or decreases in edge intensity resulted in a cued-side advantage. <ref> (Yantis & Jonides, 1990) </ref> show that 47 stimuli appearing suddenly are more likely to attract attention than persistent stimuli. <p> Follow-up experiments suggest that after a delay, stimuli which had appeared abruptly have the same priority as non-abrupt stimuli, suggestive of a priority value that decays with time <ref> (Yantis & Jones, 1990) </ref>. Top Down Processing Top down information can also have a large inuence on attended locations. In (Posner, Cohen, & Rafal, 1982), a high-level cue (such as a central arrow indicating direction) could serve to attract attention. <p> The experiments in (Egeth, Virzi, & Garbart, 1984) suggest that attention can be restricted to objects containing a particular feature if the subject is told about the feature in advance. <ref> (Yantis & Jonides, 1990) </ref> provide further evidence along these lines. They report that, although abrupt stimuli seem to have higher priority over non-abrupt stimuli, this can be overridden if the subject is already focused on another task. <p> Integrating Top Down and Bottom Up Information These experiments together illustrate a highly exible system for deciding on the next location. Both top-down and bottom-up information must play a role. <ref> (Yantis & Jonides, 1990) </ref> suggest a hierarchical priority system that assigns variable priorities to spatial locations. In their scheme, locations which are currently being attended to have higher priority than abrupt onsets which in turn have higher priority than non-onsets. VISIT implements a generalized version of the above hypothesis.
Reference: <author> Yantis, S. and Jones, E. </author> <title> (1991) Mechanisms of Attention Selection: Temporally modulated priority tags. </title> <journal> Perception & Psychophysics, </journal> <note> in press. </note>
Reference: <author> Yarbus, A. </author> <title> (1967) Eye Movements and Vision. </title> <publisher> Plenum Press, </publisher> <address> New York. </address>
Reference: <author> Zemel, R., Mozer, M., and Hinton, G. </author> <title> (1989) TRAFFIC: Recognizing Objects Using Hierarchical Reference Frame Transformations. </title> <editor> In: Touretzky, D.S. (ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2. </booktitle>
Reference: <author> Zipser, D., and Andersen, R.. </author> <title> (1988) A BackPropagation Programmed Network that Simulates Response Properties of a Subset of Posterior Parietal Neurons. </title> <journal> Nature, </journal> <volume> 331 </volume> <pages> 679-684. 105 </pages>
Reference-contexts: It should also be possible to construct a reinforcement learning scenario so that a global signal can be used to train the map. A more difficult problem is training the control networks. This system is characterized by feedback pathways, interesting dynamics, and not much regularity. <ref> (Williams & Zipser, 1988) </ref> describe experiments showing how some simple control structures can be learned in recurrent networks. In general however this type of learning is not well understood. For example, it is not all clear how a search strategy such as SWIFT could evolve.
References-found: 119

