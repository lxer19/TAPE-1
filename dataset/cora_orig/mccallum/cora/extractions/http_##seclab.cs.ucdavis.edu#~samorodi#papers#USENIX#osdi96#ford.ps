URL: http://seclab.cs.ucdavis.edu/~samorodi/papers/USENIX/osdi96/ford.ps
Refering-URL: http://seclab.cs.ucdavis.edu/~samorodi/papers/USENIX/osdi96/
Root-URL: http://www.cs.ucdavis.edu
Email: Email: office@usenix.org  
Title: CPU Inheritance Scheduling  
Phone: 1. Phone: 510 528-8649 2. FAX: 510 548-5738 3.  4.  
Author: Bryan Ford and Sai Susarla 
Affiliation: University of Utah  
Web: WWW URL: http://www.usenix.org  
Date: October 1996  
Note: The following paper was originally published in the Proceedings of the USENIX 2nd Symposium on Operating Systems Design and Implementation Seattle, Washington,  For more information about USENIX Association contact:  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, and M. Young. </author> <title> Mach: A New Kernel Foundation for UNIX Development. </title> <booktitle> In Proc. of the Summer 1986 USENIX Conf., </booktitle> <pages> pages 93-112, </pages> <month> June </month> <year> 1986. </year>
Reference-contexts: coexisting processor scheduling policies, in order to meet individual applications' needs as well as to utilize the system's processor resources more efficiently. 2.1 Related Work One simple approach to providing real-time support in systems with traditional timesharing schedulers, which has been adopted by many commonly-used systems such as Unix, Mach <ref> [1, 4] </ref>, and Windows NT [25], and has even become part of the POSIX standard [17], is support for fixed-priority threads.
Reference: [2] <author> A. Adl-Tabatabai, G. Langdale, S. Lucco, and R. Wahbe. </author> <title> Efficient and Language-Independent Mobile Programs. </title> <booktitle> In Proc. ACM SIGPLAN Symp. on Programming Language Design and Implementation, </booktitle> <pages> pages 127-136, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: This is especially true when completely unknown, untrusted code is downloaded and run in a secure environment such as that provided by Java [13] or OmniWare <ref> [2] </ref>. Schedulers have been designed that address this problem by providing flexible hierarchical control over CPU usage at different administrative boundaries [5, 14, 15, 30, 31, 32].
Reference: [3] <author> T. E. Anderson, B. N. Bershad, E. D. Lazowska, and H. M. Levy. </author> <title> Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism. </title> <journal> ACM Trans. Comput. Syst., </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <month> Feb. </month> <year> 1992. </year>
Reference-contexts: However, there is nothing to prevent client threads from explicitly communicating with their schedulers through some additional interface. One particularly useful explicit interface is sched-uler activations <ref> [3] </ref>, which allows clients to determine initially and later track the number of actual processors available to them. Clients can then create or destroy threads as appropriate in order to make use of all available processors without creating superfluous threads that compete with each other uselessly on a single processor.
Reference: [4] <author> D. L. Black. </author> <title> Scheduling and Resource Management Techniques for Multiprocessors. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <month> July </month> <year> 1990. </year>
Reference-contexts: coexisting processor scheduling policies, in order to meet individual applications' needs as well as to utilize the system's processor resources more efficiently. 2.1 Related Work One simple approach to providing real-time support in systems with traditional timesharing schedulers, which has been adopted by many commonly-used systems such as Unix, Mach <ref> [1, 4] </ref>, and Windows NT [25], and has even become part of the POSIX standard [17], is support for fixed-priority threads. <p> As with scheduling policies, there are many possible CPU accounting mechanisms, each with different cost/benefit tradeoffs. The CPU inheritance scheduling framework allows a variety of accounting policies to be implemented by scheduler threads. There are two well-known approaches to CPU usage accounting: statistical and time stamp-based <ref> [4] </ref>. With statistical accounting, the scheduler wakes up on every clock tick, checks the currently running thread, and charges the entire time quantum to that thread. This method is quite efficient, since the scheduler generally wakes up on every clock tick anyway; however, it provides limited accuracy.
Reference: [5] <author> A. C. Bomberger and N. </author> <title> Hardy. </title> <booktitle> The KeyKOS Nanok-ernel Architecture. In Proc. of the USENIX Workshop on Micro-kernels and Other Kernel Architectures, </booktitle> <pages> pages 95-112, </pages> <address> Seattle, WA, </address> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: This is especially true when completely unknown, untrusted code is downloaded and run in a secure environment such as that provided by Java [13] or OmniWare [2]. Schedulers have been designed that address this problem by providing flexible hierarchical control over CPU usage at different administrative boundaries <ref> [5, 14, 15, 30, 31, 32] </ref>. However, it is not yet clear how these algorithms will address other needs, such as those of hard real-time applications; certainly it seems unlikely that a single holy grail of scheduling policies will be found.
Reference: [6] <author> O.-J. Dahl. </author> <title> Hierarchical Program Structures. </title> <booktitle> Structured Programming, </booktitle> <pages> pages 175-220, </pages> <year> 1972. </year>
Reference-contexts: Both Aegis's scheduling mechanism and our framework are based on the use of a directed yield primitive which allows application-level threads to schedule each other; this core concept originally comes from coroutines <ref> [6] </ref>, in which directed yield is the only way thread switching is done. We believe our scheduling framework could be implemented in an Exokernel environment through the use of suitable kernel primitives, application-level support code, and standardized inter-process scheduling protocols.
Reference: [7] <author> S. Davari and L. Sha. </author> <title> Sources of Unbounded Priority Inversions in Real-time Systems and a Comparative Study of Possible Solutions. </title> <journal> ACM Operating Systems Review, </journal> <volume> 23(2) </volume> <pages> 110-120, </pages> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: Finally, most existing systems still suffer from various priority inversion problems. Priority inversion occurs when a high-priority thread requesting a service has to wait arbitrarily long for a low-priority thread to finish being serviced. This problem can be addressed in priority-based scheduling algorithms by supporting priority inheritance <ref> [7, 26] </ref>, wherein the thread holding up the service inherits the priority of the highest priority thread waiting for service. In some cases this approach can be adapted to other scheduling policies, such as with ticket transfer in lottery scheduling [31].
Reference: [8] <author> D. R. Engler, M. F. Kaashoek, and J. O'Toole Jr. Exokernel: </author> <title> An Operating System Architecture for Application-level Resource Management. </title> <booktitle> In Proc. of the 15th ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 251-266, </pages> <address> Copper Mountain, CO, </address> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: The only existing system we know of that allows different scheduling policies to be imple mented in separate, unprivileged protection domains is the Aegis Exokernel <ref> [8] </ref>. However, the Aegis scheduling mechanism was not described at length and does not address important issues such as timing, CPU usage accounting, and multiprocessor scheduling.
Reference: [9] <author> R. B. Essick. </author> <title> An Event-based Fair Share Scheduler. </title> <booktitle> In Proc. of the Winter 1990 USENIX Conf., </booktitle> <pages> pages 147-161, </pages> <address> Washington, D.C., </address> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: Other scheduling policies, such as timesharing [23], fixed-priority [12, 17], threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share <ref> [9, 16, 19] </ref>, and lottery/stride scheduling [30, 31, 32], can be implemented in the same way.
Reference: [10] <author> B. Ford, M. Hibler, </author> <title> and Flux Project Members. Fluke: Flexible -kernel Environment (draft documents). </title> <institution> University of Utah. </institution> <note> Postscript and HTML available under http://www.cs.utah.edu/projects/- flux/fluke/html/, </note> <year> 1996. </year>
Reference-contexts: There should certainly be many points in the design space at which CPU inheritance scheduling is practical even for microkernels; we are currently working on a second prototype of the framework in our Fluke microkernel <ref> [10, 11] </ref> in order to evaluate the framework further in this light. 5.8 Code Complexity As a final useful metric of the practicality of our framework, we measured our prototype's code size and complexity in terms of both raw line count and lines containing semicolons.
Reference: [11] <author> B. Ford, M. Hibler, J. Lepreau, P. Tullmann, G. Back, and S. Clawson. </author> <title> Microkernels Meet Recursive Virtual Machines. </title> <booktitle> In Proc. of the Second Symp. on Operating Systems Design and Implementation, </booktitle> <address> Seattle, WA, Oct. 1996. </address> <publisher> USENIX Assoc. </publisher>
Reference-contexts: There should certainly be many points in the design space at which CPU inheritance scheduling is practical even for microkernels; we are currently working on a second prototype of the framework in our Fluke microkernel <ref> [10, 11] </ref> in order to evaluate the framework further in this light. 5.8 Code Complexity As a final useful metric of the practicality of our framework, we measured our prototype's code size and complexity in terms of both raw line count and lines containing semicolons.
Reference: [12] <author> D. B. Golub. </author> <title> Adding Real-Time Scheduling to the Mach Kernel. </title> <type> Master's thesis, </type> <institution> University of Pitts-burg, </institution> <year> 1993. </year>
Reference-contexts: On the other hand, if a different event causes the scheduler thread to wake up, the running thread is preempted and the CPU is given back to the scheduler immediately. Other scheduling policies, such as timesharing [23], fixed-priority <ref> [12, 17] </ref>, threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share [9, 16, 19], and lottery/stride scheduling [30, 31, 32], can be implemented in the same way.
Reference: [13] <author> J. Gosling and H. McGilton. </author> <title> The Java Language Environment: A White Paper. </title> <type> Technical report, </type> <institution> Sun Mi-crosystems Computer Company, </institution> <year> 1996. </year> <note> Available as http://java.sun.com/doc/language environment/. </note>
Reference-contexts: However, as distributed and mobile computing becomes more prevalent and administrative boundaries become increasingly blurred, this form of system security is becoming more important. This is especially true when completely unknown, untrusted code is downloaded and run in a secure environment such as that provided by Java <ref> [13] </ref> or OmniWare [2]. Schedulers have been designed that address this problem by providing flexible hierarchical control over CPU usage at different administrative boundaries [5, 14, 15, 30, 31, 32].
Reference: [14] <author> P. Goyal, X. Guo, and H. M. Vin. </author> <title> A Hierarchical CPU Scheduler For Multimedia Operations. </title> <booktitle> In Proc. of the Second Symp. on Operating Systems Design and Implementation, </booktitle> <address> Seattle, WA, Oct. 1996. </address> <publisher> USENIX As-soc. </publisher>
Reference-contexts: This is especially true when completely unknown, untrusted code is downloaded and run in a secure environment such as that provided by Java [13] or OmniWare [2]. Schedulers have been designed that address this problem by providing flexible hierarchical control over CPU usage at different administrative boundaries <ref> [5, 14, 15, 30, 31, 32] </ref>. However, it is not yet clear how these algorithms will address other needs, such as those of hard real-time applications; certainly it seems unlikely that a single holy grail of scheduling policies will be found.
Reference: [15] <author> N. </author> <title> Hardy. </title> <booktitle> The KeyKos Architecture. Operating Systems Review, </booktitle> <month> Sept. </month> <year> 1985. </year>
Reference-contexts: This is especially true when completely unknown, untrusted code is downloaded and run in a secure environment such as that provided by Java [13] or OmniWare [2]. Schedulers have been designed that address this problem by providing flexible hierarchical control over CPU usage at different administrative boundaries <ref> [5, 14, 15, 30, 31, 32] </ref>. However, it is not yet clear how these algorithms will address other needs, such as those of hard real-time applications; certainly it seems unlikely that a single holy grail of scheduling policies will be found.
Reference: [16] <author> G. J. Henry. </author> <title> The Fair Share Scheduler. </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <volume> 63(8), </volume> <month> Oct. </month> <year> 1984. </year>
Reference-contexts: Other scheduling policies, such as timesharing [23], fixed-priority [12, 17], threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share <ref> [9, 16, 19] </ref>, and lottery/stride scheduling [30, 31, 32], can be implemented in the same way.
Reference: [17] <author> Institute of Electrical and Electronics, Inc. </author> <title> IEEE Standard for Information Technology Portable Operating System Interface (POSIX) Part 1: System Application Programming Interface (API) Amendment 1: Realtime Extension [C Language], </title> <booktitle> 1994. </booktitle> <address> Std 1003.1b-1993. </address>
Reference-contexts: The opinions and conclusions contained in this document are those of the authors andshould not be interpreted as representing official views or policies of the U.S. Government. such as support for fixed-priority threads <ref> [17] </ref>, or several scheduling classes to which threads with different purposes can be assigned (e.g., real-time, interactive, or background)[25]. However, even these variants are generally hard-coded into the system implementation and cannot easily be adapted to the needs of individual applications. <p> On the other hand, if a different event causes the scheduler thread to wake up, the running thread is preempted and the CPU is given back to the scheduler immediately. Other scheduling policies, such as timesharing [23], fixed-priority <ref> [12, 17] </ref>, threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share [9, 16, 19], and lottery/stride scheduling [30, 31, 32], can be implemented in the same way. <p> utilize the system's processor resources more efficiently. 2.1 Related Work One simple approach to providing real-time support in systems with traditional timesharing schedulers, which has been adopted by many commonly-used systems such as Unix, Mach [1, 4], and Windows NT [25], and has even become part of the POSIX standard <ref> [17] </ref>, is support for fixed-priority threads. Although these systems generally still use conventional priority-based timesharing schedulers, they allow real-time applications to disable the normal dynamic priority adjustments on threads specifically designated as real-time threads, so that those threads always run at a programmer-defined priority.
Reference: [18] <author> E. D. Jensen. </author> <title> A Benefit Accrual Model of Real-Time. </title> <booktitle> In Proc. of the 10th IFAC Workshop on Distributed Computer Control Systems, </booktitle> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: By carefully assigning priorities to the real-time threads in the system and ensuring that all non-real-time threads execute at lower priority, it is possible to obtain the correct behavior for some applications. However, this approach has serious, well-known limitations; in many cases, entirely different non-priority-based scheduling policies are needed <ref> [18] </ref>. Even in normal interactive and batch-mode computing, traditional priority-based scheduling algorithms are showing their age. For example, these algorithms do not provide a clean way to encapsulate a set of processes/threads as a single unit to isolate and control their processor usage relative to the rest of the system.
Reference: [19] <author> J. Kay and P. Lauder. </author> <title> A Fair Share Scheduler. </title> <journal> Communications of the ACM, </journal> <volume> 31(1), </volume> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: Other scheduling policies, such as timesharing [23], fixed-priority [12, 17], threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share <ref> [9, 16, 19] </ref>, and lottery/stride scheduling [30, 31, 32], can be implemented in the same way.
Reference: [20] <author> J. Liedtke. </author> <title> On Micro-Kernel Construction. </title> <booktitle> In Proc. of the 15th ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 237-250, </pages> <address> Copper Mountain, CO, </address> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: For example, to keep the overhead under 2% for gcc in this system, the additional per-context switch cost must be no more than about 6s (see arrow B), which would be difficult even with L4's phenomenal 3.2s round-trip RPC time <ref> [20] </ref>.
Reference: [21] <author> J. Liedtke. </author> <title> A Short Note on Cheap Fine-grained Time Measurement. </title> <journal> ACM Operating Systems Review, </journal> <volume> 30(2) </volume> <pages> 92-94, </pages> <month> Apr. </month> <year> 1996. </year>
Reference-contexts: This method is quite efficient, since the scheduler generally wakes up on every clock tick anyway; however, it provides limited accuracy. A variation that provides better accuracy at slightly higher cost is to sample the current thread at random points between clock ticks <ref> [21] </ref>. Alternatively, with time stamp-based accounting, the scheduler reads the current time at every context switch and charges the appropriate thread for the time since the last context switch.
Reference: [22] <author> C. L. Liu and J. W. Layland. </author> <title> Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment. </title> <journal> Journal of the ACM, </journal> <volume> 20(1) </volume> <pages> 46-61, </pages> <month> Jan. </month> <year> 1973. </year>
Reference-contexts: Other scheduling policies, such as timesharing [23], fixed-priority [12, 17], threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic <ref> [22] </ref>, fair share [9, 16, 19], and lottery/stride scheduling [30, 31, 32], can be implemented in the same way.
Reference: [23] <author> J. M. McKinney. </author> <title> A survey of analytical time-sharing models. </title> <journal> Computing Surveys, </journal> <pages> page 105116, </pages> <month> jun </month> <year> 1969. </year>
Reference-contexts: On the other hand, if a different event causes the scheduler thread to wake up, the running thread is preempted and the CPU is given back to the scheduler immediately. Other scheduling policies, such as timesharing <ref> [23] </ref>, fixed-priority [12, 17], threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share [9, 16, 19], and lottery/stride scheduling [30, 31, 32], can be implemented in the same way.
Reference: [24] <author> L. McVoy and C. Staelin. lmbench: </author> <title> Portable Tools for Performance Analysis. </title> <booktitle> In Proc. of 1996 USENIX Conf., </booktitle> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: Suppose FreeBSD was changed so that all scheduling was done in user mode, adding approximately one additional context switch due to a sched-uler invocation for each existing process-to-process context switch. Based on context switch times we measured using the lmbench benchmark suite <ref> [24] </ref>, which are approximately 39s on this machine, plus an additional 11s to reflect the dispatcher's cost (Section 5.7.1), the overall overhead should still be negligible simply because FreeBSD does not context switch all that often (see arrow A on the graph).
Reference: [25] <author> Microsoft Corporation. </author> <title> Win32 Programmer's Reference, </title> <booktitle> 1993. </booktitle> <pages> 999 pp. </pages>
Reference-contexts: order to meet individual applications' needs as well as to utilize the system's processor resources more efficiently. 2.1 Related Work One simple approach to providing real-time support in systems with traditional timesharing schedulers, which has been adopted by many commonly-used systems such as Unix, Mach [1, 4], and Windows NT <ref> [25] </ref>, and has even become part of the POSIX standard [17], is support for fixed-priority threads. <p> Our prototype allows threads to wait on only one event at a time; however, there is nothing about the framework that makes it incompatible with thread models in which threads can wait on multiple events at once <ref> [25] </ref>. Although implemented in user space, our prototype is designed to reflect the structure and execution environment of an actual OS kernel running in privileged mode.
Reference: [26] <author> L. Sha, R. Rajkumar, and J. P. Lehoczky. </author> <title> Priority Inheritance Protocols: An Approach to Real-time Synchronization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 39(9) </volume> <pages> 1175-1185, </pages> <year> 1990. </year>
Reference-contexts: Finally, most existing systems still suffer from various priority inversion problems. Priority inversion occurs when a high-priority thread requesting a service has to wait arbitrarily long for a low-priority thread to finish being serviced. This problem can be addressed in priority-based scheduling algorithms by supporting priority inheritance <ref> [7, 26] </ref>, wherein the thread holding up the service inherits the priority of the highest priority thread waiting for service. In some cases this approach can be adapted to other scheduling policies, such as with ticket transfer in lottery scheduling [31].
Reference: [27] <author> M. S. Squillante and E. D. Lazowska. </author> <title> Using Processor-Cache Affinity Information in Shared-Memory Multiprocessor Scheduling. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(2) </volume> <pages> 131-143, </pages> <year> 1993. </year>
Reference-contexts: already running a high-priority client but another scheduler thread is running a low-priority client), it can interrupt the other scheduler thread's schedule operation by sending it a message or signal; this corresponds to sending inter-processor interrupts in traditional systems. 4.3.1 Processor Affinity Scheduling policies that take processor affinity into consideration <ref> [27, 28, 29] </ref>, can be implemented by treating each scheduler thread as a processor and attempting to schedule a client thread from the same scheduler thread that previously donated CPU time to that client thread.
Reference: [28] <author> J. Torrellas, A. Tucker, and A. Gupta. </author> <title> Evaluating the Performance of Cache-Affinity Scheduling in Shared-Memory Multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 24 </volume> <pages> 139-151, </pages> <year> 1995. </year>
Reference-contexts: already running a high-priority client but another scheduler thread is running a low-priority client), it can interrupt the other scheduler thread's schedule operation by sending it a message or signal; this corresponds to sending inter-processor interrupts in traditional systems. 4.3.1 Processor Affinity Scheduling policies that take processor affinity into consideration <ref> [27, 28, 29] </ref>, can be implemented by treating each scheduler thread as a processor and attempting to schedule a client thread from the same scheduler thread that previously donated CPU time to that client thread.
Reference: [29] <author> R. Vaswani and J. Zahorjan. </author> <title> The Implications of Cache Affinity on Processor Scheduling for Multipro-grammed, Shared Memory Multiprocessors. </title> <booktitle> In Proc. of the 13th ACM Symp. on Operating Systems Principles, </booktitle> <pages> pages 26-40, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: already running a high-priority client but another scheduler thread is running a low-priority client), it can interrupt the other scheduler thread's schedule operation by sending it a message or signal; this corresponds to sending inter-processor interrupts in traditional systems. 4.3.1 Processor Affinity Scheduling policies that take processor affinity into consideration <ref> [27, 28, 29] </ref>, can be implemented by treating each scheduler thread as a processor and attempting to schedule a client thread from the same scheduler thread that previously donated CPU time to that client thread.
Reference: [30] <author> C. A. Waldspurger. </author> <title> Lottery and Stride Scheduling: Flexible Proportional-Share Resource Management. </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: Other scheduling policies, such as timesharing [23], fixed-priority [12, 17], threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share [9, 16, 19], and lottery/stride scheduling <ref> [30, 31, 32] </ref>, can be implemented in the same way. <p> This is especially true when completely unknown, untrusted code is downloaded and run in a secure environment such as that provided by Java [13] or OmniWare [2]. Schedulers have been designed that address this problem by providing flexible hierarchical control over CPU usage at different administrative boundaries <ref> [5, 14, 15, 30, 31, 32] </ref>. However, it is not yet clear how these algorithms will address other needs, such as those of hard real-time applications; certainly it seems unlikely that a single holy grail of scheduling policies will be found.
Reference: [31] <author> C. A. Waldspurger and W. E. Weihl. </author> <title> Lottery Scheduling: Flexible Proportional-Share Resource Management. </title> <booktitle> In Proc. of the First Symp. on Operating Systems Design and Implementation, </booktitle> <pages> pages 1-11, </pages> <address> Mon-terey, CA, Nov. 1994. </address> <publisher> USENIX Assoc. </publisher>
Reference-contexts: Other scheduling policies, such as timesharing [23], fixed-priority [12, 17], threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share [9, 16, 19], and lottery/stride scheduling <ref> [30, 31, 32] </ref>, can be implemented in the same way. <p> This is especially true when completely unknown, untrusted code is downloaded and run in a secure environment such as that provided by Java [13] or OmniWare [2]. Schedulers have been designed that address this problem by providing flexible hierarchical control over CPU usage at different administrative boundaries <ref> [5, 14, 15, 30, 31, 32] </ref>. However, it is not yet clear how these algorithms will address other needs, such as those of hard real-time applications; certainly it seems unlikely that a single holy grail of scheduling policies will be found. <p> In some cases this approach can be adapted to other scheduling policies, such as with ticket transfer in lottery scheduling <ref> [31] </ref>. <p> The amount of CPU time allocated to the cooperative application remains unchanged, however, demonstrating load insulation. Since the timesharing-class scheduler and the web browser's scheduler are both lottery schedulers, this example is equivalent to the use of two currencies in a single lottery scheduler <ref> [31] </ref>. 2. The cooperative thread FIFO1 changes its computation so that it now consumes four times the amount of CPU time before yielding to FIFO2. The effective distribution of CPU time changes to 4:1, reflecting the fact that the FIFO scheduling policy makes no attempt at fairness.
Reference: [32] <author> C. A. Waldspurger and W. E. Weihl. </author> <title> Stride Scheduling: Deterministic Proportional-Share Resource Management. </title> <type> Technical Report MIT/LCS/TM-528, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: Other scheduling policies, such as timesharing [23], fixed-priority [12, 17], threads acting as schedulers, while the light circles represent ordinary threads. rate monotonic [22], fair share [9, 16, 19], and lottery/stride scheduling <ref> [30, 31, 32] </ref>, can be implemented in the same way. <p> This is especially true when completely unknown, untrusted code is downloaded and run in a secure environment such as that provided by Java [13] or OmniWare [2]. Schedulers have been designed that address this problem by providing flexible hierarchical control over CPU usage at different administrative boundaries <ref> [5, 14, 15, 30, 31, 32] </ref>. However, it is not yet clear how these algorithms will address other needs, such as those of hard real-time applications; certainly it seems unlikely that a single holy grail of scheduling policies will be found.
References-found: 32

