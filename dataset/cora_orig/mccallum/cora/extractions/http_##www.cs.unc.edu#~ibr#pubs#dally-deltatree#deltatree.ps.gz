URL: http://www.cs.unc.edu/~ibr/pubs/dally-deltatree/deltatree.ps.gz
Refering-URL: http://www.cs.unc.edu/~ibr/pubs.html
Root-URL: http://www.cs.unc.edu
Title: The Delta Tree: An Object-Centered Approach to Image-Based Rendering  
Author: William J. Dally Leonard McMillan Gary Bishop and Henry Fuchs 
Address: Chapel Hill  
Affiliation: Artificial Intelligence Laboratory, Massachusetts Institute of Technology Department of Computer Science, University of North Carolina at  
Abstract: This paper introduces the delta tree, a data structure that represents an object using a set of reference images. It also describes an algorithm for generating arbitrary reprojections of an object by traversing its delta tree. Delta trees are an efficient representation in terms of both storage and rendering performance. Each node of a delta tree stores an image taken from a point on a sampling sphere that encloses the object. Each image is compressed by discarding pixels that can be reconstructed by warping its ancestors images to the nodes viewpoint. The partial image stored at each node is divided into blocks and represented in the frequency domain. The rendering process generates an image at an arbitrary viewpoint by traversing the delta tree from a root node to one or more of its leaves. A subdivision algorithm selects only the required blocks from the nodes along the path. For each block, only the frequency components necessary to reconstruct the final image at an appropriate sampling density are used. This frequency selection mechanism handles both antialiasing and level-of-detail within a single framework. A complex scene is initially rendered by compositing images generated by traversing the delta trees of its components. Once the reference views of a scene are rendered once in this manner, the entire scene can be reprojected to an arbitrary viewpoint by traversing its own delta tree. Our approach is limited to generating views of an object from outside the objects convex hull. In practice we work around this problem by subdividing objects to render views from within the convex hull. 
Abstract-found: 1
Intro-found: 1
Reference: [Blinn76] <author> J. F. Blinn and M. E. Newell, </author> <title> Texture and Reflection in Computer Generated Images, </title> <journal> Commu nications of the ACM, </journal> <volume> vol. 19, no. 10, </volume> <pages> pp. 542-547, </pages> <month> October </month> <year> 1976. </year>
Reference-contexts: The set of nodes to traverse and the portion of each view to reproject are selected by a simple recursive subdivision algorithm to give a bandwidth-efficient playback. 2. Background and Related Work Image-based representations were first introduced to computer graphics in the form of texture mapping [Catmull74] <ref> [Blinn76] </ref> [Blinn78] [Heckbert86]. The advantage of textures is that they increase the apparent visual complexity of a scene while adding only a small cost to the rasterization process. Notice that there are significant parallels between the incremental computation of texture indices and the image warping process.
Reference: [Blinn78] <author> J. F. </author> <title> Blinn,Simulation of Wrinkled Surfaces, </title> <booktitle> Proceedings of SIGGRAPH 78, </booktitle> <address> (Atlanta, GA) August 23-25, </address> <year> 1978, </year> <pages> pp. 286-292. </pages>
Reference-contexts: The set of nodes to traverse and the portion of each view to reproject are selected by a simple recursive subdivision algorithm to give a bandwidth-efficient playback. 2. Background and Related Work Image-based representations were first introduced to computer graphics in the form of texture mapping [Catmull74] [Blinn76] <ref> [Blinn78] </ref> [Heckbert86]. The advantage of textures is that they increase the apparent visual complexity of a scene while adding only a small cost to the rasterization process. Notice that there are significant parallels between the incremental computation of texture indices and the image warping process.
Reference: [Catmull74] <author> E. Catmull, </author> <title> A Subdivision Algorithm for Computer Display of Curved Surfaces (Ph. </title> <address> D. </address> <institution> The sis), Department of Computer Science, University of Utah, Tech. Report UTEC-CSc-74-133, </institution> <month> Dec </month> <year> 1974. </year>
Reference-contexts: The set of nodes to traverse and the portion of each view to reproject are selected by a simple recursive subdivision algorithm to give a bandwidth-efficient playback. 2. Background and Related Work Image-based representations were first introduced to computer graphics in the form of texture mapping <ref> [Catmull74] </ref> [Blinn76] [Blinn78] [Heckbert86]. The advantage of textures is that they increase the apparent visual complexity of a scene while adding only a small cost to the rasterization process. Notice that there are significant parallels between the incremental computation of texture indices and the image warping process.
Reference: [Chen93] <author> S. E. Chen and L. Williams. </author> <title> View Interpolation for Image Synthesis, </title> <booktitle> Proceedings of SIG GRAPH 93, </booktitle> <address> (Anaheim, CA) August 1-6, </address> <year> 1993, </year> <pages> pp. 279-288. </pages>
Reference-contexts: The limitation of texture maps is that the image elements are constrained to follow the underlying geometry of the primitive upon which the texture is mapped. The recently introduced methods of view interpolation <ref> [Chen93] </ref>, Quicktime VR [Chen95], fundamental-matrix-based reprojection [Laveau94], and plenoptic modeling [McMillan95b]demonstrate the potential of the image-based rendering approach.
Reference: [Chen95] <author> S. E. Chen, </author> <title> Quicktime VR An Image-Based Approach to Virtual Environment Navagation, </title> <booktitle> Proceedings of SIGGRAPH 95, </booktitle> <address> (Los Angeles, CA) August 6-11, </address> <year> 1995, </year> <pages> pp. 29-38. </pages>
Reference-contexts: The limitation of texture maps is that the image elements are constrained to follow the underlying geometry of the primitive upon which the texture is mapped. The recently introduced methods of view interpolation [Chen93], Quicktime VR <ref> [Chen95] </ref>, fundamental-matrix-based reprojection [Laveau94], and plenoptic modeling [McMillan95b]demonstrate the potential of the image-based rendering approach. <p> Other researchers have also built image-based systems with an object-centered orientation. The digital compositing techniques [Porter84] [Duff85] have been used to construct complicated scenes by combining prerendered images that share a common viewpoint. Other object-centered approaches include the object-movie component of the QuicktimeVR system <ref> [Chen95] </ref> and the tree generation system described in [Max95]. 3. Definitions A reference image or view, , is a hybrid photometric/geometric representation of object x, with range data, taken from viewpoint p with a specified field-of-view.
Reference: [Crow84] <author> F. C. Crow, </author> <title> Summed-Area Tables for Texture Mapping, </title> <booktitle> Proceedings of SIGGRAPH 84, </booktitle> <address> (Min neapolis, Minnesota), </address> <month> July 23-27, </month> <year> 1984, </year> <pages> pp. 207-212. </pages>
Reference-contexts: Notice that there are significant parallels between the incremental computation of texture indices and the image warping process. Similarly, techniques such as MIP mapping [Williams83] and summed-area tables <ref> [Crow84] </ref> bear a strong resemblance to frequency-domain reconstruction methods. The limitation of texture maps is that the image elements are constrained to follow the underlying geometry of the primitive upon which the texture is mapped.
Reference: [Duff85] <author> T. Duff, </author> <title> Compositing 3-D Rendered Images, </title> <booktitle> Proceedings of SIGGRAPH 85, </booktitle> <address> (San Francisco, Minnesota), </address> <month> July 22-26, </month> <year> 1985, </year> <pages> pp. 41-44. </pages>
Reference-contexts: However, in many applications it is desirable to synthesize scenes from the bottom up by combining various precomputed image-based scene elements. This object-centered view characterizes the image-based rendering system described in this paper. Other researchers have also built image-based systems with an object-centered orientation. The digital compositing techniques [Porter84] <ref> [Duff85] </ref> have been used to construct complicated scenes by combining prerendered images that share a common viewpoint. Other object-centered approaches include the object-movie component of the QuicktimeVR system [Chen95] and the tree generation system described in [Max95]. 3.
Reference: [Heckbert86] <author> P. Heckbert, </author> <title> Survey of Texture Mapping, </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> vol. 6, no. 11, </volume> <month> November </month> <year> 1986, </year> <pages> pp. 56-67. </pages>
Reference-contexts: The set of nodes to traverse and the portion of each view to reproject are selected by a simple recursive subdivision algorithm to give a bandwidth-efficient playback. 2. Background and Related Work Image-based representations were first introduced to computer graphics in the form of texture mapping [Catmull74] [Blinn76] [Blinn78] <ref> [Heckbert86] </ref>. The advantage of textures is that they increase the apparent visual complexity of a scene while adding only a small cost to the rasterization process. Notice that there are significant parallels between the incremental computation of texture indices and the image warping process.
Reference: [Laveau94] <author> S. Laveau and O. Faugeras, </author> <title> 3-D Scene Representation as a Collection of Images and Fundamen tal Matrices, </title> <type> INRIA, Technical Report No. 2205, </type> <month> February </month> <year> 1994. </year>
Reference-contexts: The limitation of texture maps is that the image elements are constrained to follow the underlying geometry of the primitive upon which the texture is mapped. The recently introduced methods of view interpolation [Chen93], Quicktime VR [Chen95], fundamental-matrix-based reprojection <ref> [Laveau94] </ref>, and plenoptic modeling [McMillan95b]demonstrate the potential of the image-based rendering approach.
Reference: [Max95] <author> N. Max and K. Ohsaki, </author> <title> Rendering Trees from Precomputed Z-Buffer Views, </title> <booktitle> 6th Eurographics Workshop on Rendering, </booktitle> <address> (Dublin, Ireland) June 1995, </address> <pages> pp. 45-54. </pages>
Reference-contexts: The digital compositing techniques [Porter84] [Duff85] have been used to construct complicated scenes by combining prerendered images that share a common viewpoint. Other object-centered approaches include the object-movie component of the QuicktimeVR system [Chen95] and the tree generation system described in <ref> [Max95] </ref>. 3. Definitions A reference image or view, , is a hybrid photometric/geometric representation of object x, with range data, taken from viewpoint p with a specified field-of-view. A view is represented as a dense two-dimensional array of samples with a given width and height. <p> We rejected it, however, because the overhead of storing complete sets of partial views at each leaf, even with view sharing, was prohibitive. We decided not to store multiple samples at each pixel of a view, as is done in <ref> [Max95] </ref>. Storing multiple z-values per pixel significantly complicates the warper and scan converter. In particular, tests are required to determine which samples at adjacent pixels are on the same surface. Storing multiple samples per pixel also slows rendering as the redundant pixels are reprojected.
Reference: [McMillan95a] <author> L. McMillan and G. Bishop, </author> <title> Head-Tracked Stereo Display Using Image Warping, </title> <booktitle> 1995 IS&T/ The Delta Tree 12 SPIE Symposium on Electronic Imaging Science and Technology, SPIE Proceedings #2409A, </booktitle> <address> (San Jose, CA) February 5-10, </address> <year> 1995, </year> <pages> pp. 21-30. </pages>
Reference: [McMillan95b] <author> L. McMillan and G. Bishop, </author> <title> Plenoptic Modeling: An Image-Based Rendering System, </title> <booktitle> Proceed ings of SIGGRAPH 95, </booktitle> <address> (Los Angeles, CA) August 6-11, </address> <year> 1995, </year> <pages> pp. 39-46. </pages>
Reference-contexts: This method has the disadvantage that it still requires storage of an index vector to rapidly identify the nonzero pixels. 6.2 Reprojecting Views Our approach to reprojecting views is based on that of <ref> [McMillan95b] </ref>. Forward mapping is used to reproject a pixel at a point in the source image, a node of the delta tree, to a point in the target image , the view being generated.
Reference: [Plantinga90] <author> H. Plantinga and C. R. Dyer, </author> <title> Visibility, Occlusion, and the Aspect Graph, </title> <journal> International Journal of Computer Vision, </journal> <volume> vol. 5, no. 2, </volume> <year> 1990, </year> <pages> pp. 137-160. </pages>
Reference-contexts: Set Sufficient Set Object xt u v only u only surrounded by sample points q f,( ) The Delta Tree 4 Theoretically, determining the number of views required to represent an object is a difficult problem and there is a broad literature on determining the aspect graph of an object <ref> [Plantinga90] </ref>. In practice, however, we have found a simple regular grid on the sampling sphere generates a set of views which adequately covers the surface of most objects.
Reference: [Porter84] <author> T. Porter and T. Duff, </author> <title> Compositing Digital Images, </title> <booktitle> Proceedings of SIGGRAPH 84, </booktitle> <address> (Minneap olis, Minnesota), </address> <month> July 23-27, </month> <year> 1984, </year> <pages> pp. 253-259. </pages>
Reference-contexts: However, in many applications it is desirable to synthesize scenes from the bottom up by combining various precomputed image-based scene elements. This object-centered view characterizes the image-based rendering system described in this paper. Other researchers have also built image-based systems with an object-centered orientation. The digital compositing techniques <ref> [Porter84] </ref> [Duff85] have been used to construct complicated scenes by combining prerendered images that share a common viewpoint. Other object-centered approaches include the object-movie component of the QuicktimeVR system [Chen95] and the tree generation system described in [Max95]. 3.
Reference: [Williams83] <editor> L. Williams, Pyramidal Parametrics, </editor> <booktitle> Proceedings of SIGGRAPH 83, </booktitle> <address> (Detroit, MI), </address> <month> July 25-29 </month> <year> 1983, </year> <pages> pp. 1-11. </pages>
Reference-contexts: The advantage of textures is that they increase the apparent visual complexity of a scene while adding only a small cost to the rasterization process. Notice that there are significant parallels between the incremental computation of texture indices and the image warping process. Similarly, techniques such as MIP mapping <ref> [Williams83] </ref> and summed-area tables [Crow84] bear a strong resemblance to frequency-domain reconstruction methods. The limitation of texture maps is that the image elements are constrained to follow the underlying geometry of the primitive upon which the texture is mapped.
Reference: [Wolberg90] <author> G. Wolberg, </author> <title> Digital Image Warping, </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> California, </address> <year> 1990. </year>
Reference-contexts: In image-based approaches the computation required to render a scene is proportional to the number of pixels in the images that compose the scene model, independent of the scenes geometric complexity. Since the process of reprojecting an image to a new viewpoint, often called an image warp <ref> [Wolberg90] </ref>, uses fast incremental calculations, it can usually be accomplished faster than rendering a geometric model.
References-found: 16

