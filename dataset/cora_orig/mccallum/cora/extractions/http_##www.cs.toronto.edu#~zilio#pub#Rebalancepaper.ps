URL: http://www.cs.toronto.edu/~zilio/pub/Rebalancepaper.ps
Refering-URL: http://www.cs.toronto.edu/~zilio/
Root-URL: 
Title: Modeling On-line Rebalancing with Priorities and Executing on Parallel Database Systems  
Author: Daniel C. Zilio 
Abstract: Because changes to the database (DB) and workload occur during a DB system's lifetime, the physical DB design must evolve to sustain good performance. These changes are carried out by on-line reorganizations which access the DB and execute concurrently with the DB workload. Different performance intrusions are placed on the workload when a reorganization is assigned different priorities compared to the workload processes. Our work studies the effects of the reorganization priority-level on performance. There are two performance aspects of interest: the time taken for a reorganization and the intrusion the reorganization places on the workload. The reorganization we consider is a redistribution (rebalancing) of a relation across the nodes of a parallel shared-nothing system. A shared-nothing system contains multiple processors with their own local memory and disks, and these processors share only the interconnection network. We have seen that heavily loaded systems or highly imbalanced relations across the disks indicates the choice of a higher reorganization priority-level than the workload's. This paper also presents a metric and an analytic modeling method that can be useful for comparing reorganizations in general. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. K. Baru et al. </author> <title> DB2 Parallel Edition. </title> <journal> IBM Systems Journal, </journal> <pages> pages 292-322, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: The algorithms used simple predefined strategies, and they did not factor in the cost of movement into their decision. A few reorganization utilities have been described in the literature <ref> [18, 14, 15, 1, 12] </ref>. 2 Each utility provides a fixed reorganization and strategy, such as index creation. All of these utilities would be possible candidates for a decision algorithm to consider. Therefore, a method should be created to automatically choose a utility and compare different utilities.
Reference: [2] <author> Anna Brunstrom, Scott T. Leutenegger, and Rahul Simha. </author> <title> Experimental evaluation of dynamic data allocation strategies 11 queries/millisecond. in a distributed database with changing workloads. </title> <type> Technical Report NASA Contractor Report 195024, ICASE Report No. 95-2, </type> <institution> Institute for Computer Applications in Science and Engineering, NASA Lang-ley Research Center, Hampton, VA, </institution> <month> Jan-uary </month> <year> 1995. </year>
Reference-contexts: However, they did not present a metric, and they only considered the case where a single reorganization strategy is chosen. Some papers have dealt with load balancing where a small number of relation pages are moved from heavily-loaded nodes or disks to more lightly-loaded nodes <ref> [2, 19] </ref>. The algorithms used simple predefined strategies, and they did not factor in the cost of movement into their decision. A few reorganization utilities have been described in the literature [18, 14, 15, 1, 12]. 2 Each utility provides a fixed reorganization and strategy, such as index creation.
Reference: [3] <author> R. M. Bryant, A. E. Krzesinski, and P. Te-unissen. </author> <title> The mva pre-empt resume priority approximation. </title> <booktitle> In Proc. of the ACM SIGMETRICS Conf., </booktitle> <pages> pages 12-27, </pages> <address> Min-neapolis, MN, </address> <year> 1983. </year>
Reference-contexts: The estimates of A and were done using the BKT method as described in Bryant et al. and Ea ger et al. <ref> [3, 9] </ref>.
Reference: [4] <author> Raymond M. Bryant, Anthony E. Krzesin-ski, M. Seetha Lakshmi, , and K. Mani Chandy. </author> <title> The mva priority approximation. </title> <journal> ACM Trans. on Computer Systems, </journal> <pages> pages 335-359, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: We model each resource as an M/M/1 queueing service center with preemptive scheduling <ref> [10, 9, 4] </ref>. The interconnection network is modeled as a single server where the communication speed is the time it takes to send a message over the network. <p> This before state is used since we assume the new DB state is not made available to the workload until a reorganization commits. We used the approximate mean value analysis (AMVA) method to estimate costs with priorities and mixed-class workloads <ref> [9, 4] </ref>.
Reference: [5] <author> Alberto Capara, Matteo Fischetti, and Dario Maio. </author> <title> Exact and approximate algorithms for the index selection problem in physical database design. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <pages> pages 955-967, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Given that our decision includes index selection and data placement, our algorithm has at least as much complexity as these individual decisions. They were shown to be 3 NP-complete <ref> [6, 5, 13] </ref> and must be solved us-ing heuristics. The algorithm must also choose how a reorganization will execute, i.e., the execution plan of the reorganization, and how concurrent it will be with the workload processes.
Reference: [6] <author> Douglas Comer. </author> <title> The difficulty of optimum index selection. </title> <journal> ACM Trans. on Database Systems, </journal> <pages> pages 440-445, </pages> <month> December </month> <year> 1978. </year>
Reference-contexts: Given that our decision includes index selection and data placement, our algorithm has at least as much complexity as these individual decisions. They were shown to be 3 NP-complete <ref> [6, 5, 13] </ref> and must be solved us-ing heuristics. The algorithm must also choose how a reorganization will execute, i.e., the execution plan of the reorganization, and how concurrent it will be with the workload processes.
Reference: [7] <author> George Copeland, William Alexander, Ellen Boughter, and Tom Keller. </author> <title> Data placement in Bubba. </title> <booktitle> In Proc. of the ACM SIGMOD Conf., </booktitle> <pages> pages 99-108, </pages> <address> Chicago, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Therefore, the benefits of a reorganization were reaped up to the end of a DB's lifetime. They also only adjusted to one type of change - reclustering and they only considered one off-line method of reclustering. A reorganization method was given by Copeland et al. to re-decluster whole relations <ref> [7] </ref>. They briefly discussed the idea of comparing the benefits after a reorganization with the reorganization's cost so as to help guide the decision of whether to reorganize. However, they did not present a metric, and they only considered the case where a single reorganization strategy is chosen.
Reference: [8] <author> David J. DeWitt and Jim Gray. </author> <title> Parallel database systems: The future of high performance database systems. </title> <journal> Comm. of the ACM, </journal> <pages> pages 85-98, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Another aspect of the automatic algorithm is the availability of the DB during the reorganization. Today's DB systems must be available 24 hours a day 7 days a week, and hence a reorganization should allow the DB to be usable during its execution <ref> [8] </ref>. We call this type of reorganization an on-line reorganization. If the DB is made unavailable, the reorganization is called off-line. We concentrate on reorganizations for parallel shared-nothing DB systems.
Reference: [9] <author> Derek L. Eager and John N. Lipscomb. </author> <title> The amva priority approximation. </title> <booktitle> Performance Evaluation, </booktitle> <pages> pages 173-193, </pages> <year> 1988. </year>
Reference-contexts: We model each resource as an M/M/1 queueing service center with preemptive scheduling <ref> [10, 9, 4] </ref>. The interconnection network is modeled as a single server where the communication speed is the time it takes to send a message over the network. <p> This before state is used since we assume the new DB state is not made available to the workload until a reorganization commits. We used the approximate mean value analysis (AMVA) method to estimate costs with priorities and mixed-class workloads <ref> [9, 4] </ref>. <p> The estimates of A and were done using the BKT method as described in Bryant et al. and Ea ger et al. <ref> [3, 9] </ref>.
Reference: [10] <author> Edward D. Lazowska, John Zahorjan, G. Scott Graham, and Kenneth C. Sev-cik. </author> <title> Quantitative System Performance. </title> <publisher> Prentice-Hall, </publisher> <year> 1984. </year>
Reference-contexts: Using throughput to calculate the metric is limited because we viewed the queries as having given frequencies and thus would arrive with exponentially distributed in-terarrival times. The system must keep the throughput equal to these rates, otherwise it will become saturated over time <ref> [10] </ref>, thus making the use of throughput uninteresting. If we were to detect a potential saturated system state, then any reorganization that moves the system to an unsaturated state is a good choice. <p> We needed to estimate the parallel execution costs separately from the QNM estimations because the QNM formulas sum up all the residence times to get the response times <ref> [10] </ref>. <p> We model each resource as an M/M/1 queueing service center with preemptive scheduling <ref> [10, 9, 4] </ref>. The interconnection network is modeled as a single server where the communication speed is the time it takes to send a message over the network.
Reference: [11] <author> Guy M. Lohman and John A. Muck-stadt. </author> <title> Optimal policy for batch operations: Backup, checkpointing, reorganization, and updating. </title> <journal> ACM Trans. on Database Systems, </journal> <pages> pages 209-222, </pages> <month> September </month> <year> 1977. </year>
Reference-contexts: Before the experiments are presented in Section 5, we first describe our reorganization comparison metric and the analytic modeling method, in Sections 3 and 4, respectively. 1.1 Related Work Off-line reorganization studies for serial DB systems were some of the first to be done <ref> [11, 16, 20] </ref>. The authors were interested in determining the periodic times when a reorganization should be executed. Their assumption was that the workload cost and reorganization cost increased linearly based on the size of the DB.

Reference: [13] <author> Sriram Padmanabhan. </author> <title> Data Placement in Shared-Nothing Parallel Database Systems. </title> <type> PhD thesis, </type> <institution> EECS Dept., Univ. of Michigan-Ann Arbor, </institution> <year> 1992. </year>
Reference-contexts: Given that our decision includes index selection and data placement, our algorithm has at least as much complexity as these individual decisions. They were shown to be 3 NP-complete <ref> [6, 5, 13] </ref> and must be solved us-ing heuristics. The algorithm must also choose how a reorganization will execute, i.e., the execution plan of the reorganization, and how concurrent it will be with the workload processes.
Reference: [14] <author> Betty Salzberg and Allyn Dimock. </author> <title> Principles of transaction-based on-line reorganization. </title> <booktitle> In Proc. of the Int. Conf. on VLDB, </booktitle> <address> Vancouver, </address> <year> 1993. </year>
Reference-contexts: The algorithms used simple predefined strategies, and they did not factor in the cost of movement into their decision. A few reorganization utilities have been described in the literature <ref> [18, 14, 15, 1, 12] </ref>. 2 Each utility provides a fixed reorganization and strategy, such as index creation. All of these utilities would be possible candidates for a decision algorithm to consider. Therefore, a method should be created to automatically choose a utility and compare different utilities.
Reference: [15] <author> Gary S. Smith. </author> <title> Online reorganization of key-sequenced tables and files. </title> <type> Technical Report Tandem Systems Review, </type> <institution> Tandem Computers Inc., </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: The algorithms used simple predefined strategies, and they did not factor in the cost of movement into their decision. A few reorganization utilities have been described in the literature <ref> [18, 14, 15, 1, 12] </ref>. 2 Each utility provides a fixed reorganization and strategy, such as index creation. All of these utilities would be possible candidates for a decision algorithm to consider. Therefore, a method should be created to automatically choose a utility and compare different utilities.
Reference: [16] <author> Gary H. Sockut and Robert P. Goldberg. </author> <title> Database reorganization principles and practice. </title> <journal> ACM Computing Surveys, </journal> <pages> pages 371-395, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: Before the experiments are presented in Section 5, we first describe our reorganization comparison metric and the analytic modeling method, in Sections 3 and 4, respectively. 1.1 Related Work Off-line reorganization studies for serial DB systems were some of the first to be done <ref> [11, 16, 20] </ref>. The authors were interested in determining the periodic times when a reorganization should be executed. Their assumption was that the workload cost and reorganization cost increased linearly based on the size of the DB.
Reference: [17] <author> V. Srinivasan. </author> <title> On-Line Processing in Large-Scale Transaction Systems. </title> <type> PhD thesis, </type> <institution> Dept. of Comp. Science, Univ. of Wisconsin-Madison, Madison, WI, </institution> <year> 1992. </year>
Reference-contexts: All of these utilities would be possible candidates for a decision algorithm to consider. Therefore, a method should be created to automatically choose a utility and compare different utilities. To compare different index-creation utilities, Srinivasan provided a loss metric <ref> [17] </ref>. This metric multiplies the loss of throughput during the reorganization by the reorganization's response time. As a result of this metric, longer reorganizations incur a greater loss value unless offset by a lower throughput reduction.
Reference: [18] <author> V. Srinivasan and Michael J. Carey. </author> <title> Performance of on-line index construction algorithms. </title> <type> Technical Report TR-1047, </type> <institution> Dept. of Comp. Science, Univ. of Wisconsin-Madison, Madison, WI, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: The algorithms used simple predefined strategies, and they did not factor in the cost of movement into their decision. A few reorganization utilities have been described in the literature <ref> [18, 14, 15, 1, 12] </ref>. 2 Each utility provides a fixed reorganization and strategy, such as index creation. All of these utilities would be possible candidates for a decision algorithm to consider. Therefore, a method should be created to automatically choose a utility and compare different utilities.
Reference: [19] <author> Gerhard Weikum, Peter Zabback, and Peter Scheuermann. </author> <title> Dynamic file allocation in disk arrays. </title> <booktitle> In Proc. of the ACM SIG-MOD Conf., </booktitle> <pages> pages 406-415, </pages> <address> Denver, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: However, they did not present a metric, and they only considered the case where a single reorganization strategy is chosen. Some papers have dealt with load balancing where a small number of relation pages are moved from heavily-loaded nodes or disks to more lightly-loaded nodes <ref> [2, 19] </ref>. The algorithms used simple predefined strategies, and they did not factor in the cost of movement into their decision. A few reorganization utilities have been described in the literature [18, 14, 15, 1, 12]. 2 Each utility provides a fixed reorganization and strategy, such as index creation.
Reference: [20] <author> S. B. Yao, K. S. Das, and T. J. Teorey. </author> <title> A dynamic database reorganization algorithm. </title> <journal> ACM Trans. on Database Systems, </journal> <pages> pages 159-174, </pages> <month> June </month> <year> 1976. </year> <month> 13 </month>
Reference-contexts: Before the experiments are presented in Section 5, we first describe our reorganization comparison metric and the analytic modeling method, in Sections 3 and 4, respectively. 1.1 Related Work Off-line reorganization studies for serial DB systems were some of the first to be done <ref> [11, 16, 20] </ref>. The authors were interested in determining the periodic times when a reorganization should be executed. Their assumption was that the workload cost and reorganization cost increased linearly based on the size of the DB.
References-found: 19

