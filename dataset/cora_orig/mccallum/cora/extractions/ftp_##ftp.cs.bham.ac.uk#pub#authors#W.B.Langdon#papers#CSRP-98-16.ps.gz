URL: ftp://ftp.cs.bham.ac.uk/pub/authors/W.B.Langdon/papers/CSRP-98-16.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~wbl/biblio/gp-bibliography.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Boolean Functions Fitness Spaces  
Author: W. B. Langdon and R. Poli 
Address: Birmingham B15 2TT, UK  
Affiliation: School of Computer Science The University of Birmingham,  
Note: Late Breaking Papers at Genetic Programming 1998, J. R. Koza (editor)  
Pubnum: Technical Report: CSRP-98-16  
Email: fW.B.Langdon,R.Polig@cs.bham.ac.uk  
Phone: Tel: +44 (0) 121 414 4791 Fax: +44 (0) 121 414 4281  
Date: 15 June 1997  
Web: http://www.cs.bham.ac.uk/~wbl, rmp  
Abstract: We investigate the distribution of performance of the Boolean functions of 3 Boolean inputs (particularly that of the parity functions), the always-on-6 and even-6 parity functions. We us enumeration, uniform Monte-Carlo random sampling and sampling random full trees. As expected XOR dramatically changes the fitness distributions. In all cases once some minimum size threshold has been exceeded, the distribution of performance is approximately independent of program length. However the distribution of the performance of full trees is different from that of asymmetric trees and varies with tree depth. We consider but reject testing the No Free Lunch (NFL) theorems on these functions.
Abstract-found: 1
Intro-found: 1
Reference: [ Alonso and Schott, 1995 ] <author> Laurent Alonso and Rene Schott. </author> <title> Random Generation of Trees. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1995. </year>
Reference-contexts: Its fitness is the number of fitness cases when its output agrees with that of the target Boolean function. There are n (l+1)=2 jF j (l1)=2 fi (l1)! ((l+1)=2)!((l1)=2)! different trees of length l [ Koza, 1992, page 213 ] <ref> [ Alonso and Schott, 1995 ] </ref> . jF j is four (or five if XOR is included). (Note this formula is simple as each function (internal node) has two arguments). The number of programs rises rapidly (approximately exponentially) with increasing program length l (see Figures 1 and 2).
Reference: [ Koza, 1992 ] <author> John R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Natural Selection. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, USA, </address> <year> 1992. </year>
Reference-contexts: In Section 2 we describe the Boolean problems. Section 3 describes how we measure the performance spaces of these problems and gives our results. The ramped-half-and-half method <ref> [ Koza, 1992, page 93 ] </ref> is commonly used to generate the initial population in genetic programming (GP). Half the random programs generated by it are full. Therefore we also explicitly consider the subspace of full trees. <p> The program trees we will consider are composed of n terminals (D0, D1, . . . D n1 ) which are the Boolean inputs to the program and the Boolean logic functions AND, OR, NAND and NOR <ref> [ Koza, 1992 ] </ref> . These are sufficient to construct any Boolean function but we shall also investigate including the exclusive-or function (XOR) which is asymmetric. Note [ Koza, 1992 ] required all the functions to have the same arity, this is not required in our approach. <p> D n1 ) which are the Boolean inputs to the program and the Boolean logic functions AND, OR, NAND and NOR <ref> [ Koza, 1992 ] </ref> . These are sufficient to construct any Boolean function but we shall also investigate including the exclusive-or function (XOR) which is asymmetric. Note [ Koza, 1992 ] required all the functions to have the same arity, this is not required in our approach. The fitness of each tree is given by evaluating it as a logical expression for each of the 2 n possible combinations of D n inputs. <p> Its fitness is the number of fitness cases when its output agrees with that of the target Boolean function. There are n (l+1)=2 jF j (l1)=2 fi (l1)! ((l+1)=2)!((l1)=2)! different trees of length l <ref> [ Koza, 1992, page 213 ] </ref> [ Alonso and Schott, 1995 ] . jF j is four (or five if XOR is included). (Note this formula is simple as each function (internal node) has two arguments). <p> Functions are equivalent if permuting their inputs can produce the same functionality. By symmetry members of the same equivalence class will occur in the same numbers in the search space. Therefore we need only consider one representative function from each class <ref> [ Koza, 1992, page 215 ] </ref> . found when 10 million trees of length 41 were created at random. (The 80 equivalence classes are ordered along the x-axis in order of decreasing frequency). As expected there is good agreement with [ Koza, 1992, Table 9.3 ] . <p> As expected there is good agreement with <ref> [ Koza, 1992, Table 9.3 ] </ref> . <p> But it does add experimental weight to some of our claims about the nature of program fitness landscapes and their influence on the bloating phenomena [ Langdon and Poli, 1997 ] . On average half the random trees sampled using the ramped-half-and-half method <ref> [ Koza, 1992, page 93 ] </ref> are full. Therefore, particularly if the depth parameter is increased beyond the usual 6 (equivalent to maximum size of 63), the chances of finding at random both the even-3 and the odd-3 parity functions are considerably higher using it than using uniform search. <p> In contrast ramped-half-and-half is less likely to find solutions to the Santa Fe ant trail problem than uniform search (see [ Langdon and Poli, 1998, Table 3 ] ). This suggests that the best method to use to create the initial random population is problem dependent. In <ref> [ Koza, 1992, Chapter 9 ] </ref> GP performance is shown not to be the same as random search. <p> In <ref> [ Koza, 1992, Chapter 9 ] </ref> GP performance is shown not to be the same as random search. Indeed in the case of all but a few of the simplest problems which both GP and random search easily solve, GP performance is shown to be superior to random search. [ Koza, 1992, Chapter 9 ] treats in detail all the 256 Boolean functions with 3 bit inputs. (See also [ Lang, 1995 ] and [ Koza, 1995 ] ). <p> When <ref> [ Koza, 1992, page 211 ] </ref> compares the performance of GP with random search on these problems it explicitly assumes that programs of one length (41) are typical of the whole search space. In Section 3.1 we have verified this assumption. <p> The three input boolean functions are unusual in that 256 fitness functions have been investigated. However this is still a miniscule proportion of all the possible fitness functions and so NFL does not apply. Indeed the performance of three search algorithms (GP <ref> [ Koza, 1992 ] </ref> , hill climbing [ Lang, 1995 ] and uniform random search) are not identical when averaged across all 256 three input Boolean functions.
Reference: [ Koza, 1995 ] <author> John R. Koza. </author> <title> A response to the ML-95 paper entitled Hill climbing beats genetic search on a boolean circuit synthesis of Koza's. </title> <booktitle> Distributed 11 July 1995 at the 1995 International Machine Learning Conference in Tahoe City, </booktitle> <address> California, USA, </address> <month> 11 July </month> <year> 1995. </year>
Reference-contexts: but a few of the simplest problems which both GP and random search easily solve, GP performance is shown to be superior to random search. [ Koza, 1992, Chapter 9 ] treats in detail all the 256 Boolean functions with 3 bit inputs. (See also [ Lang, 1995 ] and <ref> [ Koza, 1995 ] </ref> ). When [ Koza, 1992, page 211 ] compares the performance of GP with random search on these problems it explicitly assumes that programs of one length (41) are typical of the whole search space. In Section 3.1 we have verified this assumption.
Reference: [ Lang, 1995 ] <author> Kevin J. Lang. </author> <title> Hill climbing beats genetic search on a boolean circuit synthesis of Koza's. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <address> Tahoe City, California, USA, July 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: in the case of all but a few of the simplest problems which both GP and random search easily solve, GP performance is shown to be superior to random search. [ Koza, 1992, Chapter 9 ] treats in detail all the 256 Boolean functions with 3 bit inputs. (See also <ref> [ Lang, 1995 ] </ref> and [ Koza, 1995 ] ). When [ Koza, 1992, page 211 ] compares the performance of GP with random search on these problems it explicitly assumes that programs of one length (41) are typical of the whole search space. <p> The three input boolean functions are unusual in that 256 fitness functions have been investigated. However this is still a miniscule proportion of all the possible fitness functions and so NFL does not apply. Indeed the performance of three search algorithms (GP [ Koza, 1992 ] , hill climbing <ref> [ Lang, 1995 ] </ref> and uniform random search) are not identical when averaged across all 256 three input Boolean functions. Conventionally the fitness of a Boolean function of n inputs is defined as the number of times its output matches that required when tested upon all possible combinations of inputs.
Reference: [ Langdon and Poli, 1997 ] <author> W. B. Langdon and R. Poli. </author> <title> Fitness causes bloat. </title> <editor> In P. K. Chawdhry, R. Roy, and R. K. Pan, editors, </editor> <booktitle> Second On-line World Conference on Soft Computing in Engineering Design and Manufacturing. </booktitle> <publisher> Springer-Verlag London, </publisher> <month> 23-27 June </month> <year> 1997. </year>
Reference-contexts: We expect this property to hold in many cases, however demonstrating it on 261 problems is not sufficient to prove it holds in general. But it does add experimental weight to some of our claims about the nature of program fitness landscapes and their influence on the bloating phenomena <ref> [ Langdon and Poli, 1997 ] </ref> . On average half the random trees sampled using the ramped-half-and-half method [ Koza, 1992, page 93 ] are full.
Reference: [ Langdon and Poli, 1998 ] <author> W. B. Langdon and R. Poli. </author> <title> Why ants are hard. </title> <editor> In John R. Koza, Wolfgang Banzhaf, Kumar Chellapilla, Kalyanmoy Deb, Marco Dorigo, David B. Fo-gel, Max H. Garzon, David E. Goldberg, Hitoshi Iba, and Rick Riolo, editors, </editor> <booktitle> Genetic Programming 1998: Proceedings of the Third Annual Conference, </booktitle> <institution> University of Wis-consin, Madison, Wisconsin, USA, </institution> <month> 22-25 July </month> <year> 1998. </year> <note> Mor-gan Kaufmann. </note>
Reference-contexts: 1 Introduction Our investigations of the artificial ant following the Santa Fe trail <ref> [ Langdon and Poli, 1998 ] </ref> suggests that, provided programs are big enough, the distribution of program fitnesses is roughly independent of their size. <p> In contrast ramped-half-and-half is less likely to find solutions to the Santa Fe ant trail problem than uniform search (see <ref> [ Langdon and Poli, 1998, Table 3 ] </ref> ). This suggests that the best method to use to create the initial random population is problem dependent. In [ Koza, 1992, Chapter 9 ] GP performance is shown not to be the same as random search.
Reference: [ Rosca, 1997 ] <author> Justinian P. Rosca. </author> <title> Hierarchical Learning with Procedural Abstraction Mechanisms. </title> <type> PhD thesis, </type> <institution> University of Rochester, Rochester, </institution> <address> NY 14627, </address> <month> February </month> <year> 1997. </year>
Reference-contexts: The number of programs with other scores falls exponentially away either side of the peak. trees with XOR Even sampling 10,000,000 points per length, only three programs (1 with 27 and two with 37) were found outside the range 28 : : : 36 hits. <ref> [ Rosca, 1997, Figure 4.1 ] </ref> reports similar behaviour on the even-5-parity problem. (Note that he used ramped-half-and-half, only sampled 16,000 programs and did not consider variation of the fitness distribution with length). <p> Looking at the short programs in Figure 9 shows they have an even tighter distribution of fitness. If this is also true for the even-5 parity problem then the range reported in <ref> [ Rosca, 1997 ] </ref> will be due to the larger of the trees he sampled, particularly the full trees. It seems reasonable to suggest that the difference between a range of fitness values reported by [ Rosca, 1997 ] on the even-5 parity problem (5) and that we find on the <p> If this is also true for the even-5 parity problem then the range reported in <ref> [ Rosca, 1997 ] </ref> will be due to the larger of the trees he sampled, particularly the full trees. It seems reasonable to suggest that the difference between a range of fitness values reported by [ Rosca, 1997 ] on the even-5 parity problem (5) and that we find on the even-6 parity problem (7 or 9) is indeed due to the peak in the fitness distribution being wider, rather than an artifact of the bias inherent in ramped-half-and-half. <p> The fitness distribution of the even-6 parity problem is much tighter than that of the binomial distribution that would be produced by selecting Boolean functions uniformly at random from the 2 2 n available. I.e. centred on n 2 with variance of n 4 <ref> [ Rosca, 1997, page 62 ] </ref> . The measured variance is only 0.12 rather than 1.5. Such a tight fitness distribution and in particular the absence of a high fitness tail suggests that the problem will be hard for any adaptive algorithm.
Reference: [ Wolpert and Macready, 1997 ] <author> David H. Wolpert and William G. Macready. </author> <title> No free lunch theorems for optimization. </title> <journal> IEEE Transactions on Evolutionary Computation, </journal> <volume> 1(1):6782, </volume> <month> April </month> <year> 1997. </year> <month> 9 </month>
Reference-contexts: A No Free Lunch Theorems (NFL) Roughly speaking NFL says the average performance of [search] algorithms across all possible problems is identical <ref> [ Wolpert and Macready, 1997, page 67 ] </ref> . There are only 256 (2 2 3 ) three input Boolean functions however it is not practical to use them to experimentally confirm any of the NFL theorems. This is because the number of fitness functions (i.e. problems) is too big.
References-found: 8

