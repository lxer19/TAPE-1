URL: http://www.cse.unsw.edu.au/~claude/research/papers/ilp_history.ps.gz
Refering-URL: http://www.cse.unsw.edu.au/~claude/research/ilp.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: claude@cse.unsw.edu.au  
Title: The Origins of Inductive Logic Programming: A Prehistoric Tale  
Author: Claude Sammut 
Note: IN TR OD UC TI ON  
Address: Sydney Australia 2052  
Affiliation: Department of Artificial Intelligence School of Computer Science and Engineering University of New South Wales  
Abstract: This paper traces the development of the main ideas that have led to the present state of knowledge in Inductive Logic Programming. The story begins with research in psychology on the subject of human concept learning. Results from this research influenced early efforts in Artificial Intelligence which combined with the formal methods of inductive inference to evolve into the present discipline of Inductive Logic Programming. Inductive Logic Programming is often considered to be a young discipline. However, it has its roots in research dating back nearly 40 years. This paper traces the development of ideas beginning in psychology and the effect they had on concept learning research in Artificial Intelligence. Independent of any requirement for a psychological basis, formal methods of inductive inference were developed. These separate streams eventually gave rise to Inductive Logic Programming. This account is not entirely unbiased. More attention is given to the work of those researchers who most influenced my own interest in machine learning. Being a retrospective paper, I do not attempt to describe recent developments in ILP. This account only includes research prior to 1991 the year in which the term Inductive Logic Programming was first used (Muggleton, 1991). This is the reason for the subtitle A Prehistoric Tale. The major headings in the paper are taken from the names of periods in the evolution of life on Earth. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Banerji, R. B. </author> <year> (1960). </year> <title> An Information Processing Program for Object Recognition. </title> <journal> General Systems, </journal> <volume> 5, </volume> <pages> 117-127. </pages>
Reference: <author> Banerji, R. B. </author> <year> (1962). </year> <title> The Description List of Concepts. </title> <journal> Communications of the Association for Computing Machinery, </journal> <volume> 5(8), </volume> <pages> 426-432. </pages> <note> 19 Banerji, </note> <author> R. B. </author> <year> (1964). </year> <title> A Language for the Description of Concepts. </title> <journal> General Systems, </journal> <volume> 9, </volume> <pages> 135-141. </pages>
Reference: <author> Banerji, R. B. </author> <year> (1969). </year> <title> Theory of Problem Solving - An Approach to Artificial Intelligence. </title> <address> New York: </address> <publisher> American Elsevier. </publisher>
Reference: <author> Banerji, R. B. </author> <year> (1980). </year> <title> Artificial Intelligence: A Theoretical Approach. </title> <address> New York: </address> <publisher> North Holland. </publisher>
Reference: <author> Bergadano, F., & Giordana, A. </author> <year> (1988). </year> <title> A knowledge intensive approach to concept induction. </title> <editor> In J. Laird (Eds.), </editor> <booktitle> Proceedings of the Fifth International Conference on Machine Learning. </booktitle> <pages> (pp. 305-317). </pages> <address> Ann Arbor: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Bruner, J. S., Goodnow, J. J., & Austin, G. A. </author> <year> (1956). </year> <title> A Study of Thinking. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference: <author> Buntine, W. </author> <year> (1986). </year> <title> Generalised Subsumption. </title> <booktitle> In Proceedings of European Conference on Artificial Intelligence. </booktitle> <address> London. </address>
Reference: <author> Buntine, W. </author> <year> (1988). </year> <title> Generalized Subsumption and its Applications to Induction and Redundancy. </title> <journal> Artificial Intelligence, </journal> <volume> 36, </volume> <pages> 149-176. </pages>
Reference-contexts: This provided DUCE with a very powerful tool for growing its language, in the sense of Banerji (1969). By combining DUCEs operators with the more powerful generalisation models of subsumption, it became possible to build a first-order learning system with similar properties. Muggleton teamed with Buntine <ref> (Muggleton and Buntine, 1988) </ref> to produce CIGOL. CIGOL interacts with an oracle to build logic programs from examples. It was this system that most clearly demonstrated that induction could be seen as the inverse of resolution theorem proving.
Reference: <author> Cohen, B. L. </author> <title> (1978) A Theory of Structural Concept Formation and Pattern R e c o g n i t i o n . Ph.D. </title> <type> Thesis, </type> <institution> Department of Computer Science, University of New South Wales. </institution>
Reference: <author> Cohen, B. L., & Sammut, C. A. </author> <year> (1980). </year> <title> Program Synthesis Through Concept Learning. </title> <editor> In Y. Kodratoff (Ed.), </editor> <booktitle> Proceedings of The International Workshop on Program Construction, </booktitle> <address> Bonas, France: </address> <publisher> I.N.R.I.A. </publisher>
Reference-contexts: It became clear to us that we were now overlapping with two other areas of research, namely, logic programming and automatic programming <ref> (Cohen and Sammut, 1980) </ref>. At about the same time, and unknown to us, Shapiro (1981a, b) was also making the same connections. Generalisation Marvins generalisation method was used by Buntine (1986, 1988) in his theory of generalised subsumption and this formed the foundation for Muggleton and Buntines (1988) absorption operator.
Reference: <author> Cohen, B. L., & Sammut, C. A. </author> <year> (1982). </year> <title> Object Recognition and Concept Learning with CONFUCIUS. </title> <journal> Pattern Recognition Journal, </journal> <volume> 15(4), </volume> <pages> 309-316. </pages>
Reference: <author> Emde, W. </author> <year> (1987). </year> <note> Noncumulative learning in METAXA.3. </note> <editor> In J. McDremott (Ed.), </editor> <booktitle> Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 208-210). </pages> <address> Milan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Emde, W., Habel, C. U., & Rollinger, C.-R. </author> <year> (1983). </year> <title> The discover of the equator or concept driven learning. </title> <editor> In A. Bundy (Ed.), </editor> <booktitle> E i g t h International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 455-458). </pages> <address> Karlsruhe: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> DeRaedt, L., & Bruynooghe, M. </author> <year> (1989). </year> <title> Towards friendly concept learners. </title>
Reference: <editor> In N. S. Sridharan (Ed.), </editor> <booktitle> Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 849-856). </pages> <address> Detroit, MI: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> De Raedt, L., & Bruynooghe, M. </author> <year> (1992). </year> <title> An Overview of the Interactive Concept-Learner and Theory Revisor CLINT. </title> <editor> In S. Muggleton (Eds.), </editor> <booktitle> Inductive Logic Programming. </booktitle> <pages> (pp. 163-191). </pages> <publisher> Academic Press. </publisher> <address> 20 Dietterich, T. </address> <year> (1978). </year> <title> INDUCE 1.1 - The program description and a user's guide No. </title> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign. </institution>
Reference: <author> Gold, E. M. </author> <year> (1967). </year> <title> Language Identification in the Limit. </title> <journal> Information and Control, </journal> <volume> 10, </volume> <pages> 447-474. </pages>
Reference: <author> Hayes-Roth, F. </author> <year> (1973). </year> <title> A Structural Approach to Pattern Learning and the Acquisition of Classificatory Power. </title> <booktitle> In First International Joint Conference on Pattern Recognition. </booktitle> <pages> (pp. 343-355). </pages>
Reference: <author> Hayes-Roth, F., & McDermott, J. </author> <year> (1977). </year> <title> Knowledge Acquisition from Structural Descriptions. </title> <booktitle> In Fifth International Joint Conference on Artificial Intelligence. </booktitle> <pages> (pp. 356-362). </pages>
Reference: <author> Hayes-Roth, F., & McDermott, J. </author> <year> (1978). </year> <title> An Interference Matching Technique for Inducing Abstractions. </title> <journal> Communications of the ACM, </journal> <volume> 21, </volume> <pages> 401-411. </pages>
Reference: <author> Helft, N. </author> <year> (1987). </year> <title> Inductive generalization: a logical framework. </title> <editor> In I. Bratko & N. Lavrac (Eds.), </editor> <booktitle> Progress in Machine Learning. </booktitle> <pages> (pp. 149-157). </pages> <address> Wilmslow: </address> <publisher> Sigma Press. </publisher>
Reference: <author> Helft, N. </author> <year> (1988). </year> <title> Learning systems of first-order rules. </title> <editor> In J. Laird (Eds.), </editor> <booktitle> Proceedings of the Fith Internaional Conference on Machine Learning. </booktitle> <pages> (pp. 395-401). </pages> <address> Ann Arbor: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kodratoff, Y., & Ganascia, J.-G. </author> <year> (1986). </year> <title> Improving the generalization step in learning. </title> <editor> In R. S. Michalski, J. G. Carbonell, & T. M. Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artifial Intelligence Approach. </booktitle> <volume> Volume 2. </volume> <pages> (pp. 215-244). </pages> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Lavrac, N., Dzeroski, S., & Grobelnik, M. </author> <year> (1991). </year> <title> Learning Non-Recursive Definitions of Relations with LINUS. </title> <editor> In Y. Kodratoff (Eds.), </editor> <booktitle> European Working Session on Learning. </booktitle> <pages> (pp. 265-281). </pages> <address> Porto, Portugal: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Michalski, R. S. </author> <year> (1973). </year> <title> Discovering Classification Rules Using Variable Valued Logic System VL1. </title> <booktitle> In Third International Joint Conference on Artificial Intelligence. </booktitle> <pages> (pp. 162-172). </pages>
Reference: <author> Michalski, R. S. </author> <year> (1980). </year> <title> Pattern Recognition as Rule-Guided Inference. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 2(4), </volume> <pages> 349-361. </pages>
Reference: <author> Michalski, R. S. </author> <year> (1983). </year> <title> A Theory and Methodology of Inductive Learning. </title>
Reference-contexts: Whereas most of the systems discussed in this paper are in some way related to inverting resolution, FOIL (Quinlan, 1990) uses a purely data-driven induction method. Quinlan uses a general-to-specific search based on the covering algorithm in Michalskis Aq <ref> (Michalski, 1983) </ref>.
Reference: <editor> In R. S. Michalski, J. G. Carbonell, & T. M. Mitchell (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach. </booktitle> <address> Palo Alto: </address> <publisher> Tioga. </publisher>
Reference: <author> Mozetic, I. </author> <year> (1987). </year> <title> The role of abstractions in learning qualitative models. </title>
Reference: <editor> In P. Langley (Eds.), </editor> <booktitle> Proceedings of the Fourth International 21 Workshop on Machine Learning. </booktitle> <pages> (pp. 242-255). </pages> <address> Irvine, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Muggleton, S. </author> <year> (1987). </year> <title> Duce, An oracle based approach to constructive induction. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence. </booktitle> <pages> (pp. 287-292). </pages> <address> Milan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Buntines work was important because it built a bridge between past research and what was to come in inverse resolution.. Muggleton Muggletons first foray in ILP was at a propositional level. His program, DUCE <ref> (Muggleton, 1987) </ref> used rewriting operators to transform a theory consisting of propositional Horn clauses into a smaller, more general theory. The operators are the propositional equivalent of what are now called inverse resolution operators.
Reference: <author> Muggleton, S., & Buntine, W. </author> <year> (1988). </year> <title> Machine invention of first-order predicates by inverting resolution. </title> <editor> In R. S. Michalski, T. M. Mitchell, & J. G. Carbonell (Eds.), </editor> <booktitle> Proceedings of the Fifth International Machine Learning Conference. </booktitle> <pages> (pp. 339-352). </pages> <address> Ann Arbor, Michigan: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This provided DUCE with a very powerful tool for growing its language, in the sense of Banerji (1969). By combining DUCEs operators with the more powerful generalisation models of subsumption, it became possible to build a first-order learning system with similar properties. Muggleton teamed with Buntine <ref> (Muggleton and Buntine, 1988) </ref> to produce CIGOL. CIGOL interacts with an oracle to build logic programs from examples. It was this system that most clearly demonstrated that induction could be seen as the inverse of resolution theorem proving.
Reference: <author> Muggleton, S., & Feng, C. </author> <year> (1990). </year> <title> Efficient induction of logic programs. </title> <booktitle> In First Conference on Algorithmic Learning Theory, </booktitle> <address> Tokyo: Omsha. </address>
Reference: <author> Muggleton, S. </author> <year> (1991). </year> <title> Inductive Logic Programming. </title> <journal> New Generation Computing, </journal> <volume> 8, </volume> <pages> 295-318. </pages>
Reference: <author> Pennypacker, J. C. </author> <year> (1963). </year> <title> An Elementary Information Processor for Object Recognition (SRC No. </title> <institution> 30-I-63-1). Case Institute of Technology. </institution>
Reference: <author> Plotkin, G. D. </author> <year> (1970). </year> <title> A Note on Inductive Generalization. </title> <editor> In B. Meltzer & D. Michie (Eds.), </editor> <booktitle> Machine Intelligence 5. </booktitle> <pages> (pp. 153-163). </pages> <publisher> Edinburgh University Press. </publisher>
Reference: <author> Plotkin, G. D. </author> <year> (1971a). </year> <title> A further note on inductive generalization. </title> <booktitle> In B. </booktitle>
Reference: <editor> Meltzer & D. Michie (Eds.), </editor> <booktitle> Machine Intelligence 6. </booktitle> <address> New York: </address> <publisher> Elsevier. </publisher>
Reference: <author> Plotkin, G. D. </author> <title> (1971b) Automatic Methods of Inductive Inference. </title> <type> Ph.D. Thesis, </type> <institution> Edinburgh University. </institution>
Reference: <author> Quinlan, J. R. </author> <year> (1986). </year> <title> Induction of Decision Trees. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <pages> 81-106. </pages>
Reference-contexts: FOIL finds conjunctions by specialising a clause. The program searches for literals to add to the clause and uses information gain, like ID3 <ref> (Quinlan, 1986) </ref>, to choose among the candidate literals. Although not directy related, FOIL solves some of the problems of Shapiros MIS. MIS uses a general-to-specific search to refine theories, but this search is very inefficient.
Reference: <author> Quinlan, J. R. </author> <year> (1990). </year> <title> Learning Logical Definitions from Relations. </title> <journal> Machine Learning, </journal> <volume> 5, </volume> <pages> 239-266. </pages>
Reference-contexts: But his work crystalised the field of ILP and sparked further research. 18 Quinlan Quinlans approach to learning relations expressed as Horn clauses is unusual. Whereas most of the systems discussed in this paper are in some way related to inverting resolution, FOIL <ref> (Quinlan, 1990) </ref> uses a purely data-driven induction method. Quinlan uses a general-to-specific search based on the covering algorithm in Michalskis Aq (Michalski, 1983).
Reference: <author> Reynolds, J. C. </author> <year> (1970). </year> <title> Transformational Systems and the Algebraic Structure of Atomic Formulas. </title> <editor> In B. Meltzer & D. Michie (Eds.), </editor> <booktitle> Machine Intelligence 5. </booktitle> <pages> (pp. 153-163). </pages>
Reference: <author> Rouveirol, C., & Puget, J.-F. </author> <year> (1990). </year> <title> Beyond Inversion of Resolution. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Sammut, C. A. </author> <year> (1981). </year> <title> Learning Concepts by Performing Experiments. </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, University of New South Wales. </institution> <note> 22 Sammut, </note> <author> C. A. </author> <year> (1985). </year> <title> Concept Development for Expert System Knowledge Bases. </title> <journal> Australian Computer Journal, </journal> <volume> 17(1). </volume>
Reference-contexts: Learned concepts were stored by the program and could be used in further learning. To facilitate matching examples with stored concepts, Cohen developed a complex pattern matching system. This would later be replaced by unification in Marvin <ref> (Sammut, 1981) </ref>, the successor to CONFUCIUS. MESOZOIC (MIDDLE LIFE) This period marks the emergence of the first programs that could claim to be performing inductive logic programming. Shapiro MIS and my program, Marvin, were both capable of learning concepts that could be executed as logic programs. <p> I showed, that this assumption was sufficient to ensure that only one example was needed to distinguish consistent and inconsistent hypotheses. Without that assumption, Marvin could not work. This problem could be helped if Marvin could invent its own predicates. Although it was never implemented, my Ph.D. thesis <ref> (Sammut, 1981) </ref> described what would later be called intra-construction (Sammut, 1985). Specialisation Few ILP systems combine both generalisation and specialisation. Marvin did not attempt to make least general generalisations. Instead, it made conservative generalisations, which might require refinement. <p> Buntine Wray Buntine revived interest in subsumption as a model for generalisation in his 1986 and 1988 papers. Buntine was particularly concerned to improve the notions of generalisation relative to a 17 background theory. The generalisation method employed in Marvin <ref> (Sammut, 1981) </ref> suggested Buntines improved model of generalisation. The following definition of generalisation is taken from Buntine (1988). <p> The operators are the propositional equivalent of what are now called inverse resolution operators. This method was, to some extent, suggested by the absorption operator, which was first used in Marvin <ref> (Sammut, 1981) </ref>. One of the most interesting features of DUCE, was that it could invent its own predicates (or theoretical terms). The inter-construction and intra-construction operators could introduce new symbols into the description language if they produced a reduction in the size of the theory.
Reference: <author> Sammut, C. A., & Banerji, R. B. </author> <year> (1986). </year> <title> Learning Concepts by Asking Questions. </title> <editor> In R. S. Michalski Carbonell, J.G. and Mitchell, T.M. (Eds.), </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol 2. </volume> <pages> (pp. 167-192). </pages> <address> Los Altos, California: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: These descriptions was turned into expressions in conjunctive normal form in first order logic. Eventually, I realised that I was dealing with the equivalent of Horn clauses. So by the time details of Marvin were published <ref> (Sammut and Banerji, 1986) </ref>, the program was seen as a true Inductive Logic Programming System. The learning algorithm is a combination of generalisation and object construction procedures.
Reference: <author> Shapiro, E. Y. </author> <year> (1981a). </year> <title> An Algorithm that Infers Theories from Facts. </title> <booktitle> In Proceedings of the Seventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> (pp. 446-451). </pages> <address> Vancouver: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Shapiro was also the first to explicitly use a Horn clause representation and employ the resolution procedure in his learning algorithm. The problem he tried to solve can be expressed as follows <ref> (Shapiro, 1981a) </ref>: In a model inference problem we assume some unknown model M for a given first order language L. We distinguish two types of sentences in L: observational sentences, which correspond to descriptions of experimental results, and hypotheses, which can serve as explanations for these results.
Reference: <author> Shapiro, E. Y. </author> <year> (1981b). </year> <title> Inductive Inference of Theories From Facts (Technical Report No. </title> <type> 192). </type> <institution> Yale University. </institution>
Reference: <author> Srinivasan, A., Muggleton, S., & Bain, M. </author> <year> (1992). </year> <title> Distinguishing Exceptions from Noise in Non-monotonic Learning. </title> <editor> In S. Muggleton (Ed.), </editor> <title> Second Interna ti ona l Work shop on Inductive Logic Programming, Tokyo: Vere, </title> <editor> S. </editor> <year> (1975). </year> <title> Induction of Concepts in the Predicate Calculus. </title> <booktitle> In Proceedings of the Fourth International Joint Conference on Artificial Intelligence. </booktitle> <pages> (pp. 351-356). </pages>
Reference: <author> Vere, S. A. </author> <year> (1977). </year> <title> Induction of Relational Productions in the Presence of Background Information. </title> <booktitle> In Proceedings of the Fifth International Joint Conference on Artificial Intelligence. </booktitle>
Reference: <author> Vere, S. A. </author> <year> (1978). </year> <title> Inductive Learning of Relational Productions. </title> <editor> In D. </editor> <publisher> A. </publisher>
Reference: <editor> W. a. F. Hayes-Roth (Eds.), </editor> <booktitle> Pattern-Directed Inference Systems. </booktitle> <pages> (pp. 281-295). </pages> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> Vere, S. A. </author> <year> (1980). </year> <title> Learning Disjunctive Concepts. </title> <type> Personal Communication. </type>
Reference: <author> Vere, S. A. </author> <year> (1980). </year> <title> Multilevel Counterfactuals for Generalizations of Relational Concepts and Productions. </title> <journal> Artificial Intelligence, </journal> <volume> 14(2), </volume> <pages> 139-164. </pages>
Reference: <author> Vere, S. A. </author> <year> (1981). </year> <institution> Constrained N-to-1 Generalizations (Technical Report) Jet Propulsion Laboratory, Pasadena. </institution>
References-found: 54

