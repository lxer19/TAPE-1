URL: http://www.cs.princeton.edu/~dpd/Papers/DobkinIEEE.ps.Z
Refering-URL: http://www.cs.princeton.edu/~dpd/Research.html
Root-URL: http://www.cs.princeton.edu
Title: Computational Geometry and Computer Graphics  
Author: David P. Dobkin+ 
Address: Princeton, NJ 08544  
Affiliation: Department of Computer Science Princeton University  
Abstract: Computer graphics is a defining application for computational geometry. The interaction between these fields is explored through two scenarios. Spatial subdivisions studied from the viewpoint of computational geometry are shown to have found application in computer graphics. Hidden surface removal problems of computer graphics have led to sweepline and area subdivision algorithms in computational geometry. The paper ends with two promising research areas with practical applications: precise computation and polyhedral decomposition. 
Abstract-found: 1
Intro-found: 1
Reference: [Al] <author> Almgren, F., </author> <title> ``The geometric calculus of variations and modeling natural phenomena'', Proceedings of the Workshop on Statistical thermodynamics and differential geometry of micro-structured material, Institute for Mathematics and Its Applications, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1991 </year>
Reference-contexts: We describe here a few situations which use these ideas. For further applications and properties of Voronoi diagrams and Delaunay triangulations, see [Au,PS2]. Almgren <ref> [Al] </ref> considers the problems of finding the surface of smallest area spanning a wire frame or the surface of smallest area which partitions space into regions of prescribed volumes. This is a classical problem in the area of minimal surface computation.
Reference: [AK] <author> Arvo, J. and Kirk, D., </author> <title> ``Fast ray tracing by ray classification'', </title> <journal> Computer Graphics, </journal> <volume> vol. 21, </volume> <year> 1987, </year> <pages> pp. </pages> <month> 55-64. </month> <title> [Au] ``Voronoi diagrams -- A survey of a fundamental geometric data structure'', </title> <journal> ACM Computing Surveys, </journal> <volume> 23, </volume> <year> 1991, </year> <pages> 345-405. </pages>
Reference-contexts: For example, a ray tracer will build an octree from the objects in the scene it is tracing making it possible to test a ray against a small number of objects (rather than the entire scene) to find its first intersection. Arvo and Kirk <ref> [AK] </ref> have extended these ideas even further using the 5 dimensional version of such trees to further speed ray tracing. In the ray tracing problem, one (or more) rays is traced for each pixel of an output scene.
Reference: [Bak1] <author> Baker, T.J., </author> <title> ``Automatic mesh generation for complex three-dimensional regions using a constrained Delaunay triangulation'', </title> <journal> Engineering with Computers, </journal> <volume> 5, </volume> <year> 1989, </year> <pages> 161-175. </pages>
Reference-contexts: This work is central in the field of visualizing mathematical phenomena. It would not have been possible without the advent of graphics hardware and computational geometry techniques. A related application concerns the problem of generating meshes for solving partial differential equations. Typical of such situations is that described in <ref> [Bak1, Bak2] </ref> for the computation of inviscid transonic flows over aerodynamic shapes. The goal is to produce a triangulation of the space surrounding the aerodynamic shape for which the individual simplices (in this case tetrahedra) are well behaved.
Reference: [Bak2] <author> Baker, T.J., </author> <title> ``Unstructured meshes and surface fidelity for complex shapes'', </title> <booktitle> AIAA Tenth Computational Fluid Dynamics Conference, Hawaii, </booktitle> <year> 1991. </year>
Reference-contexts: This work is central in the field of visualizing mathematical phenomena. It would not have been possible without the advent of graphics hardware and computational geometry techniques. A related application concerns the problem of generating meshes for solving partial differential equations. Typical of such situations is that described in <ref> [Bak1, Bak2] </ref> for the computation of inviscid transonic flows over aerodynamic shapes. The goal is to produce a triangulation of the space surrounding the aerodynamic shape for which the individual simplices (in this case tetrahedra) are well behaved.
Reference: [Bar] <author> Barber, C. B., </author> <title> ``Computational geometry with imprecise data and arithmetic'', </title> <type> PhD Thesis, </type> <institution> Department of Computer Science, Princeton University, </institution> <month> June, </month> <year> 1992. </year>
Reference-contexts: Other approaches involve backward error analyses. Here, we determine the precision at which computations must be done given the input precision and the nature of the computation <ref> [SSG, FM, Bar] </ref>. A third approach considers the problem of building a tracker which follows the computation and determines the precision as the computation proceeds [DS].
Reference: [Ba] <author> Baumgart, B., </author> <title> ``A polyhedron representation for computer vision'', </title> <booktitle> 1975 National Computer Conference, AFIPS Conference Proceedings, </booktitle> <volume> vol. 44, </volume> <publisher> AFIPS Press, </publisher> <year> 1976, </year> <pages> pp. 589-596. </pages>
Reference-contexts: These extensions involved techniques which were efficient enough to be implementable as well as solutions to related problems in higher dimensions or for special data sets. As this was happening, Baumgart developed the winged edge data structure <ref> [Ba] </ref> to support his research in computer vision. This structure would prove useful as a starting point for implementation methods I discuss below. 2.2. Setting for the problem Having briefly given the early history, I now set the notation that will be used in this section. <p> These difficulties arose because incidence relationships become more complex in the next dimension. It is no longer the case that a vertex (or face) has fixed degree. Indeed, while we can control one of these quantities (as in the case of a triangulation), we cannot control both. Baumgart <ref> [Ba] </ref> observed that for storing and manipulating planar subdivisions, the edge was the appropriate structure from which to record incidences. In particular, an edge of a planar subdivision connects exactly 2 vertices and separates exactly 2 faces. Baumgart implemented a winged edge structure where an edge stores this topological information.
Reference: [BS] <author> Beichl, I. and Sullivan, F., </author> <title> ``A C program for computing 3D Delaunay triangulations'', </title> <journal> unpublished software. </journal>
Reference-contexts: The InCircle primitive we used in 2D gives way to a InSphere primitive in 3D. Naive implementation of this primitive involves comparing sums of products of quadruples of inputs. Even for double precision computations, this computation can be unstable in the face of roundoff errors. Recently, Beichl and Sullivan <ref> [BS] </ref> have produced a code which solves these problems and gives adequate performance. They build the Delaunay triangulation in a shelling order using the QR technique of matrix factorization in an essential manner to handle problems of rounding.
Reference: [Ben] <author> Bentley, J.L., </author> <title> ``Multidimensional binary search trees used for associative searching'', </title> <journal> Communications of the ACM, </journal> <volume> 18, </volume> <pages> 509-517, </pages> <year> 1975. </year>
Reference-contexts: The subdivisions above lend themselves to asymptotically efficient searching schemes. However, the difficulty of searching on existing boundary elements can result in an overly complicated search scheme. In response to such problems, Bentley <ref> [Ben] </ref> developed an algorithm which was asymptotically less efficient but practically more implementable. He considered the problem of organizing a point set in E d for various searches and proposed a method of creating the k - d (i.e. k-dimensional) search tree. We describe here a 2 - d tree.
Reference: [BO78] <author> Bentley, J.L. and Ottman, Th., </author> <title> ``Algorithms for reporting and counting geometric intersections'', </title> <institution> Carnegie-Mellon University, </institution> <month> August </month> <year> 1978. </year>
Reference: [Ber] <author> Bern, M., Dobkin, D., Eppstein, D., and Grossman, R., </author> <title> ``Visibility with a moving point of view'', </title> <booktitle> Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1990, </year> <pages> 107-117. </pages>
Reference-contexts: There are numerous other examples where a sweepline is allowed to having non-trivial shape or where sweeping is done by a plane or higher dimensional object. Many of these examples aim at efficient solutions to generalizations of the hidden surface removal problem which originally motivated Wat-kins. The articles <ref> [Ber, Ya] </ref> provide pointers into this vast literature. 3.3. Extending the area subdivision paradigm The area subdivision technique proposed by Warnock built upon pre-existing ideas. For a survey of the rich history of these idea, see Samet's excellent books on the subject [Sa1, Sa2].
Reference: [BE] <author> Bern, M. and Eppstein, D., </author> <title> ``Polynomial-size nonobtuse triangulation of polygons'', </title> <booktitle> Proceedings of the ACM Symposium on Computational Geometry, </booktitle> <year> 1991, </year> <pages> pp. 342-350. </pages>
Reference-contexts: For example, consider the problem of producing a triangulation having no obtuse angles since these angles can cause problems for interpolation. Bern and Eppstein show that the addition of a polynomial number of points is always sufficient to generate such a triangulation <ref> [BE] </ref>. Another problem is that the Delaunay triangulation of n points in E 3 may have size O (n 2 ). It is natural to ask whether we can add points to the set to reduce the size of its Delaunay triangulation.
Reference: [BEG] <author> Bern, M., Eppstein, D. and Gilbert, J., </author> <booktitle> ``Provably good mesh generation'' Proceedings of the IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1990, </year> <pages> pp. 231-241. </pages>
Reference-contexts: It is natural to ask whether we can add points to the set to reduce the size of its Delaunay triangulation. Surprisingly, it is possible to add O (n) points and achieve a Delaunay triangulation of size O (n) <ref> [BEG] </ref>. 3. Algorithmic paradigms from Computer Graphics - 13 - 3.1. The Basic Techniques A central problem in computer graphics is the development of realistic renderings of complex scenes. In the 1960's, this quest led to the consideration of algorithms for accurately rendering 3 dimensional scenes on a graphics display.
Reference: [Br] <author> Brisson, E., </author> <title> ``Representing geometric structures in d dimensions: topology and order'', </title> <booktitle> Proceedings of the ACM Symposium on Computational Geometry, </booktitle> <year> 1989, </year> <pages> pp. 218-227. - 20 </pages> - 
Reference-contexts: Finally, we need primitives which supports procedures for creating basic building blocks and splicing pieces together to build an entire subdivision. Dobkin and Laszlo [DLa, La] have considered the problem in 3 dimensions and Brisson and Lienhardt <ref> [Br, Li] </ref> give general solutions in all dimensions. We will restrict our attention in what follows to the 3 dimensional case. In 3 dimensions, our primitive element is the facet-edge pair. This consists of an edge and one of the facets (ie polygons) to which it is adjacent.
Reference: [CE] <author> Chazelle, B. and Edelsbrunner, H., </author> <title> ``An optimal algorithm for intersecting line segments in the plane'', </title> <booktitle> Proceedings of the IEEE Symposium on Foundations of Computer Science, </booktitle> <year> 1988, </year> <pages> pp. 590-600. </pages>
Reference-contexts: In order to reduce the complexity, it was necessary to produce a sweepline algorithm which modified its sweep direction to respond to the data it was encountering. Such a technique, called topological sweep was developed initially for the problem of planar subdivision searching [Ed1]. Chazelle and Edelsbrunner <ref> [CE] </ref> were then able to extend it to give an optimal algorithm for the problem of reporting all intersecting segments. Their algorithm while more complex than those presented here, represents a significant theoretical breakthrough. They have implemented a version of their algorithm.
Reference: [Dey] <author> Dey, T., </author> <title> ``Triangulation and CSG representation of polyhedra with arbitrary genus'', </title> <booktitle> Proceedings of the ACM Symposium on Computational Geometry, </booktitle> <year> 1991, </year> <pages> pp. 364-372. </pages>
Reference: [De] <author> Delaunay, B., </author> <title> ``Sur la sphere vide'', </title> <journal> Izv. Akad. Nauk SSSR, Otdelenie Matematicheskii i Estestvennyka Nauk, </journal> <volume> vol. 7, </volume> <year> 1934, </year> <pages> pp. 793-800. </pages>
Reference-contexts: The region corresponding to a given site would then represent those points from which this is the site of choice for getting the commodity. Or, we might want to find for each site, the other site to which it is closest. The Delaunay triangulation <ref> [De] </ref> is also constructed from a set of sites. In the plane, we build a triangulation of a point set by connecting pairs of sites. This technique can be used to generate an exponential number of different triangulations. For many applications, some of these triangulations are preferable to others. <p> Recent results here apply deep results from probability theory (dealing with the Vapnik-Chervonenkis dimension) to obtain theoretical improvements [EW]. Other results give methods of extending range searching techniques to more sophisticated queries <ref> [DE] </ref>. 4. Conclusions and further results This paper has shown that the fields of computational geometry and computer graphics have had significant impact on one another. Indeed, a major frustration in writing this paper is that few of the exciting interactions can be explored.
Reference: [DE] <author> Dobkin, D. P. and Edelsbrunner, H., </author> <title> ``Space searching for intersecting objects'', </title> <journal> J. Algorithms, </journal> <volume> vol. 8, </volume> <year> 1987, </year> <pages> pp. 348-361. </pages>
Reference-contexts: The region corresponding to a given site would then represent those points from which this is the site of choice for getting the commodity. Or, we might want to find for each site, the other site to which it is closest. The Delaunay triangulation <ref> [De] </ref> is also constructed from a set of sites. In the plane, we build a triangulation of a point set by connecting pairs of sites. This technique can be used to generate an exponential number of different triangulations. For many applications, some of these triangulations are preferable to others. <p> Recent results here apply deep results from probability theory (dealing with the Vapnik-Chervonenkis dimension) to obtain theoretical improvements [EW]. Other results give methods of extending range searching techniques to more sophisticated queries <ref> [DE] </ref>. 4. Conclusions and further results This paper has shown that the fields of computational geometry and computer graphics have had significant impact on one another. Indeed, a major frustration in writing this paper is that few of the exciting interactions can be explored.
Reference: [DGHS] <author> Dobkin, D., Guibas, L., Hershberger, J., and Snoeyink, J., </author> <title> ``An efficient algorithm for finding the CSG representation of a simple polygon'', </title> <journal> Computer Graphics, </journal> <volume> vol. 22, </volume> <year> 1988, </year> <pages> pp. 31-40. </pages>
Reference: [DLa] <author> Dobkin, D. and Laszlo, M.J., </author> <title> ``Primitives for the manipulation of three-dimensional subdivisions'', </title> <journal> Algorithmica, </journal> <volume> vol. 4, </volume> <year> 1989, </year> <pages> pp. 3-32. </pages>
Reference-contexts: The element must also belong to rings of edges and facets which can be traversed to explore the full subdivision. Finally, we need primitives which supports procedures for creating basic building blocks and splicing pieces together to build an entire subdivision. Dobkin and Laszlo <ref> [DLa, La] </ref> have considered the problem in 3 dimensions and Brisson and Lienhardt [Br, Li] give general solutions in all dimensions. We will restrict our attention in what follows to the 3 dimensional case. In 3 dimensions, our primitive element is the facet-edge pair. <p> This geometry is used both to compute positions and to create images and videos of this process using the techniques of computer graphics. Their work has built upon theoeretical developments relating to the Delaunay triangulation and the data structure of <ref> [DLa] </ref> is central to their implementation. This work is central in the field of visualizing mathematical phenomena. It would not have been possible without the advent of graphics hardware and computational geometry techniques. A related application concerns the problem of generating meshes for solving partial differential equations.
Reference: [DL1] <author> Dobkin, D.P. and Lipton, R. J. </author> , <title> ``On some generalizations of binary search'', </title> <booktitle> Proceedings of the 6th ACM Symposium on the Theory of Computing, </booktitle> <pages> 310-316, </pages> <year> 1974. </year>
Reference-contexts: His work arose from the need of a statistics group within Bell Labs to be able to efficiently cluster data samples [Gr2]. In 1974, Dobkin and Lipton <ref> [DL1, DL2] </ref> gave the - 3 - first algorithms for searching in spatial subdivisions. Their work arose from an open problem given in Knuth [Kn] asking how to preprocess a set of points to be able to find nearest neighbors efficiently.
Reference: [DL2] <author> Dobkin, D. and Lipton, R., </author> <title> ``Multidimensional search problems'', </title> <journal> SIAM J. Computing, </journal> <volume> vol. 5, </volume> <year> 1976, </year> <pages> pp. 181-186. </pages>
Reference-contexts: His work arose from the need of a statistics group within Bell Labs to be able to efficiently cluster data samples [Gr2]. In 1974, Dobkin and Lipton <ref> [DL1, DL2] </ref> gave the - 3 - first algorithms for searching in spatial subdivisions. Their work arose from an open problem given in Knuth [Kn] asking how to preprocess a set of points to be able to find nearest neighbors efficiently.
Reference: [DS] <author> Dobkin, D. and Silver, D., </author> <title> ``Applied computational geometry: towards robust solutions of basic problems'', </title> <journal> JCSS, </journal> <volume> vol. 40, </volume> <year> 1990, </year> <pages> 70-87. </pages>
Reference-contexts: Here, we determine the precision at which computations must be done given the input precision and the nature of the computation [SSG, FM, Bar]. A third approach considers the problem of building a tracker which follows the computation and determines the precision as the computation proceeds <ref> [DS] </ref>. The idea is to detect when insufficient precision remains and backtrack to a point whence the computation can be redone at a higher precision. 4.2. Decomposition of polygons and polyhedra A recurrent theme in computer graphics is the modeling and rendering of complex objects.
Reference: [Dw1] <author> Dwyer, R. A., </author> <title> Software for computing Delaunay triangulation, </title> <year> 1987. </year>
Reference-contexts: Other operators can be defined to trace Next and Previous neighbors around the Destination vertex and Left face. These tools for defining quad edges and manipulating edge rings require less than 20 - 9 - lines of C code <ref> [Dw1] </ref> to implement. From these primitive components, Guibas and Stolfi derive an algebra of relations among the operators. This algebra allows them to build sophisticated procedures from repeated applications of their primitive operators. A key procedure implements the Splice operator allowing us to combine and separate subdivisions. <p> This is their major construction tool. The operator MakeEdge is a simple memory manager able to create an isolated new edge that can later be spliced to a subdivision. These two operators can be implemented in fewer than 50 lines of C code <ref> [Dw1] </ref>. Finally, there is the problem of using this derivation productively. The previous paragraphs describe the primitives necessary for manipulating the topology of subdivisions.
Reference: [Dw2] <author> Dwyer, R. A., </author> <title> ``A faster divide-and-conquer algorithm for constructing Delaunay triangulations'', </title> <journal> Algorithmica, </journal> <volume> vol. 2, </volume> <year> 1987, </year> <pages> pp. 137-152. </pages>
Reference: [Ed1] <author> Edelsbrunner, H., </author> <title> Algorithms in Combinatorial Geometry, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: The Voronoi diagram defines for each site the region of space for which it is the closest site. In the plane, the Delaunay triangulation has property that its minimum angle is maximal over all triangulations <ref> [Ed1] </ref>. The Voronoi diagram [Vo] is built from a set of input points, called sites. Corresponding to each site is the set of points of E d which are closer to that site than to any other site. <p> Now, the Delaunay triangulation is composed of simplices defined so that no additional site lies within their circumscribing d-sphere. Finally, the Voronoi diagram and Delaunay triangulation of a set of sites represented as graphs are duals in all dimensions. For further details, see <ref> [Ed1] </ref>. We conclude this section with one further observation relating the Delaunay triangulation (and so, also the Voronoi diagram) to the convex hull. <p> Then, we compute the convex hull of these points. Finally, the Delaunay triangulation can be derived from the projection of this convex hull back to E d . For further details on this derivation, see <ref> [Ed1] </ref>. 2.3. Towards implementation Having established sufficient background for Voronoi diagrams, Delaunay triangulations, and convex hulls, it remains to discuss the difficulties encountered with turning this theory into practice. As the results mentioned above appeared, implementations slowly followed. <p> In order to reduce the complexity, it was necessary to produce a sweepline algorithm which modified its sweep direction to respond to the data it was encountering. Such a technique, called topological sweep was developed initially for the problem of planar subdivision searching <ref> [Ed1] </ref>. Chazelle and Edelsbrunner [CE] were then able to extend it to give an optimal algorithm for the problem of reporting all intersecting segments. Their algorithm while more complex than those presented here, represents a significant theoretical breakthrough. They have implemented a version of their algorithm.
Reference: [Ed2] <author> Edelsbrunner, H., </author> <title> ``An acyclicity theorem in cell complexes in d dimensions'', </title> <booktitle> Proceedings of the ACM Symposium on Computational Geometry, </booktitle> <year> 1989, </year> <pages> pp. 145-151. </pages>
Reference-contexts: The transparency calculations now require that we do a process similar to hidden surface removal. A desirable triangulation would be the Delaunay for the reasons described previously. This turns out to be the correct choice due to the acyclicity condition of Edelsbrunner <ref> [Ed2] </ref> from the computational geometry literature. A practical solution to this problem is to find a well-behaved ordering of the tetrahedra. <p> It is easy to verify that there are subdivisions for which this is not - 12 - possible. In such cases, it is necessary to introduce new data values and further subdivide, a tedious task. Edelsbrunner <ref> [Ed2] </ref> shows that this can never be the case if the Delaunay triangulation is used. Max et al [Ma] are able to build a simpler algorithm because of this result. A final application area illustrates the use of properties of the Delaunay triangulation in a seemingly unrelated graphics problem.
Reference: [EM] <author> Edelsbrunner, H. and Mucke, E., </author> <title> ``A technique to cope with degenerate cases in geometric algorithms'', </title> <booktitle> Proceedings of the ACM Symposium on Computational Geometry, </booktitle> <year> 1988, </year> <pages> pp. 118-133. </pages>
Reference-contexts: This creates the need for a more thorough study of the problem. It is necessary to isolate the exact parts of the problem where numerical problems occur and to determine the effect they will have on the ultimate solution. Three approaches have been followed in exploring this problem. In <ref> [EM] </ref>, a method is presented to perturb the input to create a new input set which will be well behaved and yield the same result.
Reference: [Fo] <author> Fortune, S. </author> <title> ``A sweepline algorithm for Voronoi diagrams'', </title> <journal> Algorithmica, </journal> <volume> vol. 2, </volume> <year> 1987, </year> <pages> pp. 153-174. </pages>
Reference-contexts: Implementing Delaunay triangulations and Voronoi diagrams in 3 dimensions is more complex than the 2 dimensional process. Algorithms in 2 dimensions either rely upon recursive techniques (i.e. divide and merge as done by [GS]) or iterative techniques (e.g the sweepline algorithm of Fortune <ref> [Fo] </ref> discussed below). These algorithms succeed by building data structures to store information that is essentially 1 dimensional. For the divide and merge algorithms, this is the monotonic piecewise linear dividing line. For the sweep algorithms, it is the sweepline itself. Neither paradigm easily extends a dimension higher. <p> There are other extensions to sweepline algorithms which have appeared in the computational geometry literature. The Voronoi diagram algorithm of Fortune <ref> [Fo] </ref> is one that extends the paradigm and yields an immediately practical algorithm. Until his algorithm appeared, there were known techniques for finding the Voronoi diagram optimally through the use of recursion but no optimal incremental method was known. Incremental methods tend to be more robust for computational purposes.
Reference: [FM] <author> Fortune, S. and Milenkovic, V., </author> <title> ``Numerical stability of algorithms for line arrangements'', </title> <booktitle> Proceedings of the ACM Symposium on Computational Geometry, </booktitle> <year> 1991, </year> <pages> pp. 334-341. </pages>
Reference-contexts: Other approaches involve backward error analyses. Here, we determine the precision at which computations must be done given the input precision and the nature of the computation <ref> [SSG, FM, Bar] </ref>. A third approach considers the problem of building a tracker which follows the computation and determines the precision as the computation proceeds [DS].
Reference: [Fu] <author> Fuchs, H., Kedem, Z., and Naylor, B., </author> <title> ``On visible surface generation by a priori tree structures'', </title> <journal> Computer Graphics, </journal> <volume> vol. 14, </volume> <year> 1980, </year> <pages> pp. 124-133. </pages>
Reference-contexts: Others have extended his work to show that such a formula can be computed in O (nlogn) time. It has also been shown that no such formula exists for polytopes unless face halfspaces are repeated. See [DGHS,PY,Dey] for details. The binary space partition tree was introduced in <ref> [Fu] </ref> as a scheme for fast rendering of scenes in computer graphics. This is a scheme for creating a binary tree corresponding to a scene of polygons. The nodes of the tree are planes of support of individual polygons.
Reference: [Gr1] <author> Graham, R., </author> <title> ``An efficient algorithm for determining the convex hull of a finite planar set'', </title> <journal> Information Proc. Letters, </journal> <volume> vol. 1 , 1972, </volume> <pages> pp. 132-133. - 21 </pages> - 
Reference-contexts: We trace these data structures through the development of algorithms which can be feasibly implemented. We conclude the section with a description of application areas which build upon these techniques. 2.1. Roots of the problem In 1971, Graham <ref> [Gr1] </ref> published an algorithm for computing the convex hull of a set of points in the plane based on sorting the points by angle and then scanning them. His work arose from the need of a statistics group within Bell Labs to be able to efficiently cluster data samples [Gr2].
Reference: [Gr2] <author> Graham, R., </author> <title> private communication, </title> <year> 1987. </year>
Reference-contexts: His work arose from the need of a statistics group within Bell Labs to be able to efficiently cluster data samples <ref> [Gr2] </ref>. In 1974, Dobkin and Lipton [DL1, DL2] gave the - 3 - first algorithms for searching in spatial subdivisions. Their work arose from an open problem given in Knuth [Kn] asking how to preprocess a set of points to be able to find nearest neighbors efficiently.
Reference: [GS] <author> Guibas, L. and Stolfi, J., </author> <title> ``Primitives for the manipulation of general subdivisions and the computation of Voronoi diagrams'', </title> <journal> ACM Trans. Graphics, </journal> <volume> vol. 4, </volume> <year> 1985, </year> <pages> pp. </pages> <month> 74.123. </month>
Reference-contexts: Prior to the work I am about to describe, applications requiring Voronoi diagrams were typically done using naive techniques (requiring O (n 2 ) algorithms) rather than the O (n log n) algorithms I mention here. - 8 - Guibas and Stolfi <ref> [GS] </ref> provided an elegant extension to the winged edge structure. They begin with the observation that an edge potentially performs 4 tasks. It acts as a connector for 2 vertices and as a separator for 2 faces. <p> Implementing Delaunay triangulations and Voronoi diagrams in 3 dimensions is more complex than the 2 dimensional process. Algorithms in 2 dimensions either rely upon recursive techniques (i.e. divide and merge as done by <ref> [GS] </ref>) or iterative techniques (e.g the sweepline algorithm of Fortune [Fo] discussed below). These algorithms succeed by building data structures to store information that is essentially 1 dimensional. For the divide and merge algorithms, this is the monotonic piecewise linear dividing line.
Reference: [Ha] <author> H. </author> <title> Hadwiger, </title> <journal> ``Eulers charakteristic und kombinatorische geometrie'', J. Reine und Angew. Math., 1955, </journal> <volume> vol. 194, </volume> <pages> pp. 101-110. </pages>
Reference-contexts: Hence, by maintaining an ordering of triangles and tracking changes in the ordering, we can identify events of the third type. The mathematical basis for scan line algorithms of this type can be traced back at least as far as the work of Hadwiger <ref> [Ha] </ref>. Area subdivision algorithms make powerful use of basic ideas. Initially, the plane is considered as a single rectangle. And, the triangles of this rectangle are considered as the set of all input triangles.
Reference: [HW] <author> D. Haussler and E. Welzl, </author> <title> ``Partitioning and geometric embedding of range spaces of finite Vapnik-Chervonenkis dimension'', </title> <booktitle> Proceedings of the 3rd ACM Symposium on Computational Geometry, </booktitle> <year> 1987, </year> <pages> pp. 331-340. </pages>
Reference: [Kn] <author> Knuth, D., </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> vol. 3, </volume> <publisher> Addison-Wesley, </publisher> <address> Reading, Ma., </address> <year> 1973. </year>
Reference-contexts: In 1974, Dobkin and Lipton [DL1, DL2] gave the - 3 - first algorithms for searching in spatial subdivisions. Their work arose from an open problem given in Knuth <ref> [Kn] </ref> asking how to preprocess a set of points to be able to find nearest neighbors efficiently. In 1975, Shamos and Hoey [S, SH1] proposed efficient algorithms for finding a closest pair from a set of points.
Reference: [La] <author> M.J. Laszlo, </author> <title> ``A data structure for manipulating three-dimensional subdivisions'', </title> <type> PhD dissertation, </type> <institution> Princeton University, </institution> <year> 1987. </year>
Reference-contexts: The element must also belong to rings of edges and facets which can be traversed to explore the full subdivision. Finally, we need primitives which supports procedures for creating basic building blocks and splicing pieces together to build an entire subdivision. Dobkin and Laszlo <ref> [DLa, La] </ref> have considered the problem in 3 dimensions and Brisson and Lienhardt [Br, Li] give general solutions in all dimensions. We will restrict our attention in what follows to the 3 dimensional case. In 3 dimensions, our primitive element is the facet-edge pair.
Reference: [Li] <author> P. Lienhardt, </author> <title> ``Subdivision of n-dimensional spaces and n-dimensional generalized maps'' Proceedings 5th ACM Symposium on Computational Geometry, </title> <booktitle> 1989, </booktitle> <pages> pp. 228-236. </pages>
Reference-contexts: Finally, we need primitives which supports procedures for creating basic building blocks and splicing pieces together to build an entire subdivision. Dobkin and Laszlo [DLa, La] have considered the problem in 3 dimensions and Brisson and Lienhardt <ref> [Br, Li] </ref> give general solutions in all dimensions. We will restrict our attention in what follows to the 3 dimensional case. In 3 dimensions, our primitive element is the facet-edge pair. This consists of an edge and one of the facets (ie polygons) to which it is adjacent.
Reference: [Ma] <author> Max, N., Hanrahan, P. and R. Crawfis, </author> <title> ``Area and volume coherence for efficient visualization of 3D scalar functions'', </title> <journal> Computer Graphics, </journal> <volume> vol. 24, no. 5, </volume> <year> 1990, </year> <pages> pp. 27-33. </pages>
Reference-contexts: Reported computed times for the triangulation are half an hour on a single processor Cray 2. A second application involving Delaunay triangulation arises in the problem of volume visualization. Max, Hanrahan and Crawfis <ref> [Ma] </ref> present a technique for visualizing a 3D scalar function. In a typical volume visualization task, data is given at a collection of 3D points and the goal is to provide a useful rendering of the data. <p> In such cases, it is necessary to introduce new data values and further subdivide, a tedious task. Edelsbrunner [Ed2] shows that this can never be the case if the Delaunay triangulation is used. Max et al <ref> [Ma] </ref> are able to build a simpler algorithm because of this result. A final application area illustrates the use of properties of the Delaunay triangulation in a seemingly unrelated graphics problem. Painter and Sloan [PS1] consider the problem of successively refining image generation.
Reference: [Ne] <author> Neeman, H., </author> <title> ``A decomposition algorithm for visualizing irregular grids'', </title> <journal> Computer Graphics, </journal> <volume> vol. 24, no. 5, </volume> <year> 1990, </year> <pages> pp. 49-56. </pages>
Reference-contexts: Typical applications are to computational fluid dynamics and medical imaging. The octree is built from the data and then probed by the ray tracing algorithm. For examples, see <ref> [Ne, Wi] </ref>. Within the computational geometry study of such problems, there have been numerous range searching extensions of k-d trees. Recent results here apply deep results from probability theory (dealing with the Vapnik-Chervonenkis dimension) to obtain theoretical improvements [EW].
Reference: [PS] <author> Painter, J. and Sloan, K., </author> <title> ``Antialiased raytracing by adaptive progressive refinement'', </title> <journal> Computer Graphics, </journal> <volume> vol. 23, no. 3, </volume> <year> 1989, </year> <pages> pp. 281-288. </pages>
Reference-contexts: To do so, they have to modify the sweepline algorithm to enable them to determine events ``on-the-fly''. Their algorithm has a running time of O (nlog n + klog n) where k is the number of intersections reported. Full details are in <ref> [BO, PS] </ref>. The Bentley Ottman algorithm is not asymptotically optimal. Because it reports intersections in order based upon their x coordinate, it must sort all intersections and so cannot finish in the desired optimal time bound O (n log n + k).
Reference: [Pa] <author> Palios, L., </author> <title> ``Decomposition Algorithms in Computational Geometry'', </title> <type> PhD thesis, </type> <institution> Princeton University, Department of Computer Science, </institution> <month> March, </month> <year> 1992. </year>
Reference-contexts: These polyhedra are restricted to having only boundary intersections. We will further restrict our subdivisions to consist only of convex regions. Note that any subdivision can be transformed into one consisting of only convex regions with the possible addition of new vertices (see <ref> [Pa] </ref>). Thus, a planar subdivision is a subdivision of a portion of the plane into polygonal regions. An example is shown in Figure 1. Note that the vertices and polygons need not all have the same degree.
Reference: [PY] <author> Paterson, M. and Yao, F., </author> <title> ``Efficient binary space partitions for hidden-surface removal and solid modeling'', </title> <journal> Discrete and Computational Geometry, </journal> <volume> vol. 5, </volume> <year> 1990, </year> <pages> 485-503. </pages>
Reference-contexts: The nodes of the tree are planes of support of individual polygons. These nodes are meant to subdivide the scene into two nearly equal parts corresponding to the objects in each half space as defined by the partition plane. This problem was extended by <ref> [PY] </ref> to the general problem of finding a collection of arbitrary planes to subdivide a general scene. They show that a partition of size O (nlogn) for n edges in the plane.
Reference: [Pet] <author> Peterson, D., </author> <title> ``Halfspace representations of extrusions, solids of revolution and pyramids'', </title> <type> SANDIA Report SAND84-0572, </type> <institution> Sandia National Laboratories, </institution> <year> 1984. </year>
Reference-contexts: In the latter, we might want to render a scene in a sorted order by appropriate subdivision of space into regions each involving only a single object. Each of these problems arose in the computer graphics literature. And, each has motivated research in computational geometry. Peterson <ref> [Pet] </ref> proposed the problem of representing a polygon or polytope as a restricted CSG formula. His goal was to have a representation that consisted of intersections and unions of halfplanes (or halfspaces) of support of the edges (or faces) of the original object.
Reference: [SSG] <author> Salesin, D., Stolfi, J., and Guibas, L., </author> <title> ``Epsilon Geometry: Building robust algorithms from imprecise computations'', </title> <booktitle> Proceedings of the ACM Symposium on Computational Geometry, </booktitle> <year> 1989, </year> <pages> pp. 208-217. </pages>
Reference-contexts: Other approaches involve backward error analyses. Here, we determine the precision at which computations must be done given the input precision and the nature of the computation <ref> [SSG, FM, Bar] </ref>. A third approach considers the problem of building a tracker which follows the computation and determines the precision as the computation proceeds [DS].
Reference: [Sa1] <author> Samet, H., </author> <title> The design and analysis of spatial data structures, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1990. </year>
Reference-contexts: The articles [Ber, Ya] provide pointers into this vast literature. 3.3. Extending the area subdivision paradigm The area subdivision technique proposed by Warnock built upon pre-existing ideas. For a survey of the rich history of these idea, see Samet's excellent books on the subject <ref> [Sa1, Sa2] </ref>. Within the computational geometry community, these ideas were developed as an alternative method to the searching techniques described in the previous section. As this development proceeded, generalizations were developed which have since found significant application in the graphics community.
Reference: [Sa2] <author> Samet, H., </author> <title> Applications of spatial data structures: computer graphics, image processing and GIS, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1990. </year>
Reference-contexts: The articles [Ber, Ya] provide pointers into this vast literature. 3.3. Extending the area subdivision paradigm The area subdivision technique proposed by Warnock built upon pre-existing ideas. For a survey of the rich history of these idea, see Samet's excellent books on the subject <ref> [Sa1, Sa2] </ref>. Within the computational geometry community, these ideas were developed as an alternative method to the searching techniques described in the previous section. As this development proceeded, generalizations were developed which have since found significant application in the graphics community.
Reference: [S] <author> Shamos, M.I., </author> <title> ``Geometric complexity'', </title> <booktitle> Proceedings of the 7th ACM Symposium on the Theory of Computing, </booktitle> <pages> 224-233, </pages> <year> 1975. </year>
Reference-contexts: Their work arose from an open problem given in Knuth [Kn] asking how to preprocess a set of points to be able to find nearest neighbors efficiently. In 1975, Shamos and Hoey <ref> [S, SH1] </ref> proposed efficient algorithms for finding a closest pair from a set of points. This work became part of Shamos' thesis which initiated the field of computational geometry.
Reference: [SH1] <author> Shamos, M.I. and Hoey, D., </author> <title> ``Closest point problems'', </title> <booktitle> IEEE Symposium on foundations of computer science, </booktitle> <pages> 151-162, </pages> <year> 1975. </year> <month> - 22 </month> - 
Reference-contexts: Their work arose from an open problem given in Knuth [Kn] asking how to preprocess a set of points to be able to find nearest neighbors efficiently. In 1975, Shamos and Hoey <ref> [S, SH1] </ref> proposed efficient algorithms for finding a closest pair from a set of points. This work became part of Shamos' thesis which initiated the field of computational geometry.
Reference: [SH2] <author> Shamos, M.I. and Hoey, D., </author> <title> ``Geometric intersection problems'', </title> <booktitle> IEEE Symposium on foundations of computer science, </booktitle> <pages> 208-215, </pages> <year> 1976. </year>
Reference-contexts: To explore the possibilities, I briefly describe 2 algorithms built upon sweepline algorithms. First, we consider one of the earliest uses within computational geometry of the sweepline paradigm. Shamos and Hoey <ref> [SH2] </ref> considered the problem of determining whether any 2 of a collection of n line segments have a point in common. To understand their algorithm, imagine that all n segments were drawn in the plane and that we swept across them with a vertical line.
Reference: [Sp] <author> Sproull, </author> <title> R.F., ``Refinements to nearest-neighbor searching in k-dimensional trees'', </title> <journal> Algorithmica, </journal> <volume> vol. 6, </volume> <year> 1991, </year> <pages> pp. 579-589. </pages>
Reference-contexts: And, the value of v is chosen as the median among all possible values. Using these ideas, building and searching a k - d tree becomes an easy exercise. An improved implementation for k - d trees for nearest neighbor searching is given in <ref> [Sp] </ref>. Schemes for implementing k - d trees for dimensions 2 and 3 have been studied in numerous contexts. The 2 dimensional versions are a variant of the quadtree search structure which arose from Warnock's original algorithm. The 3 dimensional versions of quadtrees are called octrees.
Reference: [Vo] <author> Voronoi, G., </author> <title> ``Nouvelles applications des parametres continus a la theorie des formes quadratiques'', </title> <journal> Journal fur die reine und angewandte Mathema-tik, </journal> <volume> 133, </volume> <year> 1907, </year> <pages> 97-178; 134, </pages> <year> 1908, </year> <pages> 198-287; 136, </pages> <year> 1909, </year> <pages> 67-181. </pages>
Reference-contexts: The search algorithms, though motivated by real problems required enormous amounts of preprocessing time to generate search structures requiring unreasonable amounts of storage space. The closest point algorithms were based upon the rediscovery of the Voronoi diagram <ref> [Vo] </ref>. Techniques were given for computing the diagram efficiently in an asymptotic sense but these algorithms did not lend themselves to easy implementation. Computational geometry researchers continued to explore extensions of the algorithms given above and appropriate data structures for their implementation. <p> The Voronoi diagram defines for each site the region of space for which it is the closest site. In the plane, the Delaunay triangulation has property that its minimum angle is maximal over all triangulations [Ed1]. The Voronoi diagram <ref> [Vo] </ref> is built from a set of input points, called sites. Corresponding to each site is the set of points of E d which are closer to that site than to any other site.
Reference: [Wa69] <author> Warnock, J. E., </author> <title> ``A hidden-surface algorithm for computer generated halftone pictures'', </title> <institution> University of Utah Computer Science Department, </institution> <type> TR 4-15, </type> <year> 1969. </year>
Reference: [Wa70] <author> Watkins, G. S., </author> <title> ``A real-time visible surface algorithm'', </title> <institution> University of Utah Computer Science Department, UTEC-CSc-70-101, </institution> <month> June, </month> <year> 1970. </year>
Reference: [Wi] <author> Wilhelms, J. and van Gelder, A., </author> <title> ``Octrees for faster isosurface generation'', </title> <journal> Computer Graphics, </journal> <volume> vol. 24, no. 5, </volume> <year> 1990, </year> <pages> pp. 57-62. </pages>
Reference-contexts: Typical applications are to computational fluid dynamics and medical imaging. The octree is built from the data and then probed by the ray tracing algorithm. For examples, see <ref> [Ne, Wi] </ref>. Within the computational geometry study of such problems, there have been numerous range searching extensions of k-d trees. Recent results here apply deep results from probability theory (dealing with the Vapnik-Chervonenkis dimension) to obtain theoretical improvements [EW].
Reference: [Ya] <author> Yao, </author> <title> F.F., ``Computational geometry'', in Algorithms in Complexity, </title> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1990, </year> <pages> 345-490. </pages>
Reference-contexts: Thus, it is natural to ask the question: How do computer graphics and computational geometry interact? It is this question that motivates this paper. I explore here life at the interface between computational geometry and computer graphics. Rather than striving for completeness (see e.g. Yao <ref> [Ya] </ref> for a broader survey), I consider in detail two scenarios in which the two fields have overlapped. <p> There are numerous other examples where a sweepline is allowed to having non-trivial shape or where sweeping is done by a plane or higher dimensional object. Many of these examples aim at efficient solutions to generalizations of the hidden surface removal problem which originally motivated Wat-kins. The articles <ref> [Ber, Ya] </ref> provide pointers into this vast literature. 3.3. Extending the area subdivision paradigm The area subdivision technique proposed by Warnock built upon pre-existing ideas. For a survey of the rich history of these idea, see Samet's excellent books on the subject [Sa1, Sa2].
References-found: 56

