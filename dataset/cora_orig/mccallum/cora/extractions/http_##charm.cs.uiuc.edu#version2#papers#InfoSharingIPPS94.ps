URL: http://charm.cs.uiuc.edu/version2/papers/InfoSharingIPPS94.ps
Refering-URL: http://charm.cs.uiuc.edu/version2/papers/InfoSharingIPPS94.html
Root-URL: http://www.cs.uiuc.edu
Email: email: kale@cs.uiuc.edu  email: sinha@cs.uiuc.edu  
Title: Information sharing mechanisms in parallel programs  
Author: Laxmikant V. Kale Amitabh B. Sinha 
Address: Urbana, Illinois 61801.  Urbana, Illinois 61801  
Affiliation: Department of Computer Science, University Of Illinois at Urbana-Champaign,  Department of Computer Science, University Of Illinois at Urbana-Champaign,  
Abstract: Most parallel programming models provide a single generic mode in which processes can exchange information with each other. However, empirical observation of parallel programs suggest that processes share data in a few distinct and specific modes. We argue that such modes should be identified and explicitly supported in parallel languages and their associated models. The paper describes a set of information sharing abstractions that have been identified and implemented in the parallel programming language Charm. It can be seen that using these abstractions leads to improved clarity and expressiveness of user programs. In addition, the specificity provided by these abstractions can be exploited at compile-time and at run-time to provide the user with highly refined performance feedback and intelligent debugging tools.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Agha G.A. </author> <title> Actors: A Model of Concurrent Computation in Distributed Systems. </title> <publisher> MIT press, </publisher> <year> 1986. </year>
Reference-contexts: A compiler-writer might then have to automatically detect various modes of information sharing, imperfectly and conservatively, in order to produce more efficient object code. There exist other mechanisms to exchange information amongst parallel processes. The information sharing mechanisms provided by Actors <ref> [1] </ref>, Strand [2], and Linda [3] all suffer from the same problem: they are each only a universal information exchange mechanism. In an Actor program, messages are the sole means of information exchange. An actor can be used to implement the read-only mode of information exchange.
Reference: [2] <author> Foster I., Taylor S. Strand: </author> <title> New Concepts in Parallel Programming. </title> <publisher> Prentice Hall, </publisher> <year> 1990. </year>
Reference-contexts: A compiler-writer might then have to automatically detect various modes of information sharing, imperfectly and conservatively, in order to produce more efficient object code. There exist other mechanisms to exchange information amongst parallel processes. The information sharing mechanisms provided by Actors [1], Strand <ref> [2] </ref>, and Linda [3] all suffer from the same problem: they are each only a universal information exchange mechanism. In an Actor program, messages are the sole means of information exchange. An actor can be used to implement the read-only mode of information exchange.
Reference: [3] <author> Carriero N., Gelernter D. </author> <title> How to Write Parallel Programs: A Guide to the Perplexed. </title> <journal> ACM Computing Surveys, </journal> <pages> pages 323-357, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: A compiler-writer might then have to automatically detect various modes of information sharing, imperfectly and conservatively, in order to produce more efficient object code. There exist other mechanisms to exchange information amongst parallel processes. The information sharing mechanisms provided by Actors [1], Strand [2], and Linda <ref> [3] </ref> all suffer from the same problem: they are each only a universal information exchange mechanism. In an Actor program, messages are the sole means of information exchange. An actor can be used to implement the read-only mode of information exchange.
Reference: [4] <author> Kale L.V. </author> <title> The Design Philosophy of the Chare Kernel Parallel Programming System. </title> <type> Technical Report UIUCDCS-R-89-1555, </type> <institution> Dept. of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1989. </year>
Reference-contexts: In addition, the specificity provided by these abstractions can be exploited at compile-time and at run-time to provide the user with highly refined performance feedback and intelligent debugging tools. 2 In Section 2, we briefly describe Charm <ref> [4, 5, 6] </ref>. In Section 3, we present some specific modes of information sharing that are available in Charm. In Section 5, we discuss how these specific modes of information sharing have been implemented on different parallel machines.
Reference: [5] <author> Kale L.V. </author> <title> The Chare Kernel Parallel Programming System Programming System. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1990. </year>
Reference-contexts: In addition, the specificity provided by these abstractions can be exploited at compile-time and at run-time to provide the user with highly refined performance feedback and intelligent debugging tools. 2 In Section 2, we briefly describe Charm <ref> [4, 5, 6] </ref>. In Section 3, we present some specific modes of information sharing that are available in Charm. In Section 5, we discuss how these specific modes of information sharing have been implemented on different parallel machines.
Reference: [6] <author> Kale L.V. et al. </author> <title> The Chare Kernel Programming Language Manual. </title> <type> internal report. </type>
Reference-contexts: In addition, the specificity provided by these abstractions can be exploited at compile-time and at run-time to provide the user with highly refined performance feedback and intelligent debugging tools. 2 In Section 2, we briefly describe Charm <ref> [4, 5, 6] </ref>. In Section 3, we present some specific modes of information sharing that are available in Charm. In Section 5, we discuss how these specific modes of information sharing have been implemented on different parallel machines.
Reference: [7] <author> Edward W. Reingold, Jurg Nievergelt, and Narsingh Deo. </author> <title> Combinatorial Algorithms: Theory and Practice. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1977. </year>
Reference-contexts: be used. * If the information needs to be shared among most of the processes in the system, and it does not get accessed in the write-mode after being initialized, then a read-only or a write-once variable should be used. 4.1 The Traveling Salesman Problem The Traveling Salesman Problem (TSP) <ref> [7] </ref> is a typical example of an optimization problem solved using branch&bound techniques. In this problem a salesman must visit n cities, returning to the starting point, and is required to minimize the total cost of the trip.
Reference: [8] <author> J. D. C. Little, K. G. Murty, D. W. Sweeney, and C. Karel. </author> <title> An algorithm for the traveling salesman problem. </title> <journal> Operations Research, </journal> <volume> 11 </volume> <pages> 972-989, </pages> <year> 1963. </year>
Reference-contexts: Every pair of cities i and j has a cost C ij associated with them (if i = j, then C ij is assumed to be of infinite cost). In the branch&bound scheme originally proposed by Little, et. al. <ref> [8] </ref>. one starts with an initial partial solution, a cost function (C) and an infinite upper bound. A partial solution comprises a set of edges (pairs of cities) that have been included in the circuit, and a set of edges that have been excluded from the circuit.
Reference: [9] <author> M. Bellmore and G. Nemhauser. </author> <title> The traveling salesman problem: a survey. </title> <journal> Operations Research, </journal> <volume> 16 </volume> <pages> 538-558, </pages> <year> 1968. </year>
Reference: [10] <author> M. Held and R. Karp. </author> <title> The traveling salesman problem and minimum spanning trees. </title> <journal> Operations Research, </journal> <volume> 18 </volume> <pages> 1138-1162, </pages> <year> 1970. </year>
Reference: [11] <author> B. W. Wah, G. Li, and C. Yu. </author> <title> Multiprocessing of combinatorial search problems. </title> <editor> In V. Kumar, P. S. Gopalakrishnan, and L. N. Kamal, editors, </editor> <booktitle> Parallel Algorithms for Machine Intelligence and Vision. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference: [12] <author> B. Monien and O. Vornberger. </author> <title> Parallel processing of combinatorial search trees. </title> <booktitle> Proceedings International Workshop on Parallel Algorithms and Architectures, </booktitle> <publisher> Math. Research Nr. </publisher> <address> 38, Akadmie-Verlag, Berlin, </address> <year> 1987. </year>
Reference: [13] <author> Leah H. Jamieson. </author> <title> Characterizing parallel algorithms. </title> <editor> In Leah H. Jamieson, Dennis Gannon, and Robert J. Douglass, editors, </editor> <title> The characteristics of parallel algorithms. </title> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: Techniques for characterization of parallel algorithms have been studied before. E.g., Jamieson <ref> [13] </ref> used the characteristics of parallel algorithm, in conjunction with the characteristics of parallel architectures, to provide an understanding of how well the algorithm is suited to different architectures.
References-found: 13

