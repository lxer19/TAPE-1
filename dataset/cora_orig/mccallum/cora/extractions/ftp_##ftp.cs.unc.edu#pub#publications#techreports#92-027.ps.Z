URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/92-027.ps.Z
Refering-URL: ftp://ftp.cs.unc.edu/pub/publications/techreports/FILE.html
Root-URL: http://www.cs.unc.edu
Title: TABLE OF CONTENTS Executive Summary 154 Introduction 156 Overview 156 Perception 157 Vision Audition Haptics
Author: Gary Bishop, UNC-Chapel Hill (co-chair) William Bricken, U. Frederick Brooks, Jr., UNC-Chapel Hill Marcus Brown, U. Chris Burbeck, UNC-Chapel Hill Nat Durlach, M. I. T. Steve Ellis, NASA-Ames Henry Fuchs, UNC-Chapel Hill (co-chair) Mark Green, U. James Lackner, Michael McNeill, NCSA Michael Moshell, U. Warren Robinett, UNC-Chapel Hill Mandayam Srinivasan, M. I. T. Ivan Sutherland, Sun Microsystems Dick Urban, DARPA Elizabeth Wenzel, NASA-Ames 
Keyword: Hardware 166 Tracking Systems Haptic Systems Image Generators Visual Display Devices Audio Systems  
Address: Chapel Hill  Seattle  Alberta, Canada  Charlottesville  
Affiliation: University of North Carolina at  of Washington,  of Alabama, Tuscaloosa  Research Center  of  Brandeis University  of Central Florida Randy Pausch, U. of Virginia,  Research Center  
Date: March 23-24, 1992  
Note: 177 Research Directions in Virtual Environments Report of an NSF Invitational Workshop  163 Software 165  Applications 170 References 172 Appendix Taxonomies for Virtual Environments 173  
Abstract-found: 0
Intro-found: 1
Reference: <author> Begault, D. R. </author> <title> (1991) Perceptual effects of synthetic reverberation on 3-D audio systems. </title> <booktitle> 91st Convention of the Audio Engineering Society, </booktitle> <address> New York, </address> <note> Preprint 3212 (W-6). </note>
Reference-contexts: Other research suggests that such errors may be mitigated by providing more complex acoustic cues derived from reverberant environments <ref> (Begault, 1991) </ref>. Recently, some progress has been made in interactively synthesizing complex acoustic cues using a real-time implementation of the image model (Foster, et al., 1991) Nonspeech Audio Following from Gibson's ecological approach to perception, one can conceive of the audible world as a collection of acoustic "objects".
Reference: <author> Blattner, M. M., Sumikawa, D. A., & Greenberg, R. M. </author> <year> (1989). </year> <title> Earcons and Icons: Their Structure and Common Design Principles. </title> <journal> Human-Computer Interaction, </journal> <volume> 4, </volume> <pages> 11-44. </pages>
Reference-contexts: One can systematically manipulate these features, effectively creating an auditory symbology which operates on a continuum from "literal" everyday sounds to a completely abstract mapping of statistical data into sound parameters. Principles for design and synthesis can be gleaned from the fields of music <ref> (Blattner, Sumikawa, and Greenberg, 1989) </ref>, psychoacoustics (Patterson, 1982), and higher-level cognitive studies of the acoustical determinants of perceptual organization (Bregman, 1990; Buxton, Gaver, and Bly, 1989).
Reference: <author> Bregman, A. S. </author> <year> (1990). </year> <title> Auditory Scene Analysis. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Buxton, W., Gaver, W., & Bly, S. </author> <year> (1989). </year> <title> The use of non-speech audio at the interface. (Tutorial No. </title> <booktitle> 10). Presented at CHI'89, ACM Conference on Human Factors in Computing Systems, </booktitle> <address> New York: </address> <publisher> ACM Press. </publisher>
Reference: <author> Durlach, N. I. </author> <title> (1991) Auditory localization in teleoperator and virtual environment systems: Ideas, issues, and problems. </title> <journal> Perception, </journal> <volume> 20, </volume> <pages> 543-554. </pages>
Reference-contexts: The notion of super-auditory localization, or artificially enhanced localization cues, is also a promising area <ref> (Durlach, 1991) </ref>. 2. A fruitful area for joint basic and applied research is the development of perceptually-viable methods of simplifying the synthesis technique with the goal of maximizing the efficiency of algorithms for complex room modeling (increasing the number and complexity of modeled reflections). 3.
Reference: <author> Durlach, N.I., Pew, R.W., Aviles, </author> <title> W.A., DiZio, P.A., </title> <editor> and Zeltzer, D.L. (Eds.) </editor> <year> (1992). </year> <title> Virtual Environment Technology for Training (VETT). The Virtual Environment and Teleoperator Research Consortium (VETREC). </title> <type> Bolt, </type> <institution> Beranek, </institution> <note> and Newman Report 7661. </note>
Reference: <author> Cutting, James E. </author> <title> (1986) Perception with an eye for motion. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The separated patterns of contours and regions may then be interpreted as a surrounding space. Visual world The spatial interpretation of visual images is highly dependent upon the kinematic characteristics of the image motion, in particular those motions that are consequences of the observer himself <ref> (Cutting, 1986) </ref>. The patterns of image motion that are associated with observers' movements provide much of the necessary information for guidance through a cluttered environment and have provided Research in Virtual Environments 6 the basis for development of what J. J. Gibson described as a higher-order psychophysics.
Reference: <author> Elkind, Jerome I., Card, Stuart K., Hochberg, Julian, and Huey, Beverly M. </author> <title> (1989) Human performance models for computer-aided engineering, </title> <address> Washington D.C. </address> <publisher> National Academy Press. </publisher>
Reference-contexts: Typically, these experimental applications are not focused on synthesis of multisensory environments. They are, however, necessarily carefully calibrated and often automated for the conduct of an experiment. Digital signal processing is also extensively used to filter and analyze performance data <ref> (See Elkind, Card, and Hochberg, 1989) </ref>. Virtual environment (VE) technology is inherently an interdisciplinary field that will be likely to integrate the previous scientific work in perception and manual control (Ellis, 1991; Durlach et al, 1992).
Reference: <author> Ellis, Stephen R. </author> <title> (1991) The nature and origin of virtual environments: a bibliographical essay. </title> <booktitle> Computer Systems in Engineering, </booktitle> <volume> 2, 4, </volume> <pages> 321-47. </pages>
Reference: <author> Ellis, Stephen R., Kaiser, Mary K., and Grunwald, Arthur J.(eds) (1991). </author> <title> Pictorial communication in virtual and real environments, Taylor and Francis, </title> <address> London,and Bristol, NJ. </address>
Reference: <author> Foster, S.H., Wenzel, </author> <title> E.M., and Taylor, R.M. </title> <booktitle> (1991) Real- time synthesis of complex acoustic environments . Proceedings of the IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, </booktitle> <address> New Paltz, NY. </address> <booktitle> Howard, Ian (1982) Human visual orientation, </booktitle> <publisher> Wiley, </publisher> <address> New York. </address>
Reference-contexts: Other research suggests that such errors may be mitigated by providing more complex acoustic cues derived from reverberant environments (Begault, 1991). Recently, some progress has been made in interactively synthesizing complex acoustic cues using a real-time implementation of the image model <ref> (Foster, et al., 1991) </ref> Nonspeech Audio Following from Gibson's ecological approach to perception, one can conceive of the audible world as a collection of acoustic "objects".
Reference: <author> Lackner, J.R. </author> <title> Some aspects of sensory-motor control and adaptation in man. </title> <editor> In: R.D. Walk and H.L. Pick, Jr. (Eds.). </editor> <title> Intersensory Perception and Sensory Integration, </title> <address> New York, </address> <publisher> Plenum, </publisher> <pages> 143-173, </pages> <year> 1981. </year>
Reference: <author> Lackner, J.R. </author> <title> Human sensory-motor adaptation to the terrestrial force environment. </title> <booktitle> In: </booktitle> <address> D. </address> <note> Ingle, M. </note>
Reference: <editor> Jeannerod and D. Lee (Eds.). </editor> <title> Brain Mechanisms and Spatial Vision., </title> <publisher> Nijhoff, Amsterdam, </publisher> <pages> 175-210, </pages> <note> 1985.* </note> <author> Li, X., Logan, R. J., and Pastore, R. E. </author> <title> (1991) Perception of acoustic source characteristics. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 90, </volume> <pages> 3036-3049. </pages>
Reference: <author> Morse, P. M. and Ingard, K. U. </author> <booktitle> (1968) Theoretical Acoustics. </booktitle> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: Recently, a few studies have also been concerned with methods for directly characterizing and modeling environmental sounds such as walking sounds (Li, Logan, and Pastore, 1991). Other relevant research includes physically or structurally-based acoustic models of sound source characteristics such as radiation patterns <ref> (Morse and Ingard, 1968) </ref>. Needs Spatial Sound It seems clear that simple anechoic simulations of spatial cues will not be sufficient to minimize perceptual errors and maximize perceptual "presence". Dynamic modeling of complex acoustic environments requires enormous computational resources for real-time implementation in a truly interactive (head-tracked) display.
Reference: <author> Patterson, R. R. </author> <year> (1982). </year> <title> Guidelines for Auditory Warning Systems on Civil Aircraft. </title> <type> (Paper No. 82017), </type> <institution> London: Civil Aviation Authority. </institution>
Reference-contexts: Principles for design and synthesis can be gleaned from the fields of music (Blattner, Sumikawa, and Greenberg, 1989), psychoacoustics <ref> (Patterson, 1982) </ref>, and higher-level cognitive studies of the acoustical determinants of perceptual organization (Bregman, 1990; Buxton, Gaver, and Bly, 1989). Recently, a few studies have also been concerned with methods for directly characterizing and modeling environmental sounds such as walking sounds (Li, Logan, and Pastore, 1991).
Reference: <author> Treisman, A. </author> <booktitle> (1985) Preattentive processing in vision. Computer Vision, Graphics, and Image Processing, </booktitle> <pages> 31 156-177. </pages>
Reference-contexts: Some aspects of this image segregation appear to be the result of parallel processing while other show evidence of sequential processing <ref> (Treisman, 1985) </ref>. Once segregated, the contours and features collected into groups may be interpreted as objects in the space surrounding the observer. The separated patterns of contours and regions may then be interpreted as a surrounding space.
Reference: <author> Warren William, H., Jr., Mestre, Daniel R., Blackwell, Arshavir W., and Morris, Michael W. </author> <title> (1991) Perception of circular heading from optical flow. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 17, </volume> <pages> 28-43. </pages> <note> Research in Virtual Environments 27 Wenzel, </note> <author> E. M. </author> <title> (1992) Localization in virtual acoustic displays. Presence: </title> <booktitle> Teleoperators and Virtual Environments, </booktitle> <volume> 1, </volume> <pages> 80-107. </pages>
Reference-contexts: Just as motion of an observer causes global changes in the pattern of relative motion in the visual image, so to manipulative interaction with visible objects also produces characteristic visible transformations related to the object's position and identity, <ref> (e.g. Warren, et al, 1991) </ref>, which have been extensively studied to provide the bases for psychological and physiological theories of manipulative interaction. Visual orientation Visual information is not only important for local navigation while traversing an environment but also for global path planning and route selection.
Reference: <author> Wightman, F. L. & Kistler, D. J. </author> <title> (1989) Headphone simulation of free-field listening I: stimulus synthesis. </title> <journal> Journal of the Acoustical Society of America, </journal> <volume> 85, </volume> <pages> 858-867. </pages> <booktitle> Research in Virtual Environments 28 </booktitle>
Reference-contexts: In general, the synthesis technique involves the digital generation of stimuli using Head-Related Transfer Functions (HRTFs) measured in the ear canals of individual subjects or artificial heads for a large number of real source (loudspeakers) locations <ref> (e.g., Wightman & Kistler, 1989) </ref>.
References-found: 19

