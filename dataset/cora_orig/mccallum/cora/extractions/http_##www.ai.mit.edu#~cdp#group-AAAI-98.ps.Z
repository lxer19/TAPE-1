URL: http://www.ai.mit.edu/~cdp/group-AAAI-98.ps.Z
Refering-URL: http://www.ai.mit.edu/people/scaz/scaz.html
Root-URL: 
Email: fbrooks,ferrell,irie,cckemp,maddog,scaz,mattg@ai.mit.edu  
Title: Alternative Essences of Intelligence  
Author: Rodney A. Brooks, Cynthia Breazeal (Ferrell), Robert Irie, Charles C. Kemp, Matthew Marjanovic, Brian Scassellati, Matthew M. Williamson 
Address: Cambridge, MA, 02139, USA  
Affiliation: MIT Artificial Intelligence Lab,  
Abstract: We present a novel methodology for building humanlike artificially intelligent systems. We take as a model the only existing systems which are universally accepted as intelligent: humans. We emphasize building intelligent systems which are not masters of a single domain, but, like humans, are adept at performing a variety of complex tasks in the real world. Using evidence from cognitive science and neuroscience, we suggest four alternative essences of intelligence to those held by classical AI. These are the parallel themes of development, social interaction, embodiment, and integration. Following a methodology based on these themes, we have built a physical humanoid robot. In this paper we present our methodology and the insights it affords for facilitating learning, simplifying the computation underlying rich behavior, and building systems that can scale to more complex tasks in more challenging environments. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Ashby, W. R. </author> <year> (1960), </year> <title> Design for a Brain, second edn, </title> <publisher> Chapman and Hall. </publisher>
Reference: <author> Ballard, D., Hayhoe, M. & Pelz, J. </author> <year> (1995), </year> <title> `Memory representations in natural tasks', </title> <journal> Journal of Cognitive Neuroscience pp. </journal> <pages> 66-80. </pages>
Reference: <author> Baron-Cohen, S. </author> <year> (1995), </year> <title> Mindblindness, </title> <publisher> MIT Press. </publisher>
Reference: <author> Blythe, J. & Veloso, M. </author> <year> (1997), </year> <title> Analogical Replay for Efficient Conditional Planning, </title> <booktitle> in `Proceedings of American Association of Artificial Intelligence (AAAI-97)', </booktitle> <pages> pp. 668-673. </pages>
Reference: <author> Boutilier, C. & Brafman, R. I. </author> <year> (1997), </year> <title> Planning with Concurrent Interacting Actions, </title> <booktitle> in `Proceedings of American Association of Artificial Intelligence (AAAI-97)', </booktitle> <pages> pp. 720-726. </pages>
Reference: <author> Brafman, R. I. </author> <year> (1997), </year> <title> A Heuristic Variable Grid Solution Method for POMDPs, </title> <booktitle> in `Proceedings of American Association of Artificial Intelligence (AAAI-97)', </booktitle> <pages> pp. 727-733. </pages>
Reference: <author> Brooks, R. A. </author> <year> (1986), </year> <title> `A Robust Layered Control System for a Mobile Robot', </title> <journal> IEEE Journal of Robotics and Automation RA-2, </journal> <pages> 14-23. </pages>
Reference-contexts: Our systems are physically coupled with the world and operate directly in that world without any explicit representations of it <ref> (Brooks 1986, Brooks 1991b) </ref>. There are representations, or accumulations of state, but these only refer to the internal workings of the system; they are meaningless without interaction with the outside world.
Reference: <author> Brooks, R. A. </author> <year> (1991a), </year> <title> Intelligence Without Reason, </title> <booktitle> in `Proceedings of the 1991 International Joint Conference on Artificial Intelligence', </booktitle> <pages> pp. 569-595. </pages>
Reference-contexts: Introduction An early development in the history of AI was the claim of Newell & Simon (1961) that humans use physical symbol systems to "think". Over time, this has become adopted into Artificial Intelligence as an implicit and dominant hypothesis (see <ref> (Brooks 1991a) </ref> for a review). Although this assumption has begun to soften in recent years, a typical AI system still relies on uniform, explicit, internal representations of capabilities of the system, the state of the outside world, and the desired goals.
Reference: <author> Brooks, R. A. </author> <year> (1991b), </year> <title> `Intelligence Without Representation', </title> <journal> Artificial Intelligence Journal 47, </journal> <pages> 139-160. </pages> <note> originally appeared as MIT AI Memo 899 in May 1986. </note>
Reference: <author> Brooks, R. A. & Stein, L. A. </author> <year> (1994), </year> <title> `Building brains for bodies', </title> <booktitle> Autonomous Robots 1(1), </booktitle> <pages> 7-25. </pages>
Reference-contexts: Second, from an engineering perspective, these themes make the problems of building human intelligence easier. Embodiment A principle tenet of our methodology is to build and test real robotic systems. We believe that building human-like intelligence requires human-like interaction with the world <ref> (Brooks & Stein 1994) </ref>. Humanoid form is important to allow humans to interact with the robot in a natural way. In addition we believe that building a real system is computationally less complex than simulating such a system.
Reference: <author> Churchland, P., Ramachandran, V. & Sejnowski, T. </author> <year> (1994), </year> <title> A Critique of Pure Vision, </title> <editor> in C. Koch & J. Davis, eds, </editor> <title> `Large-Scale Neuronal Theories of the Brain', </title> <publisher> MIT Press. </publisher>
Reference: <author> Cohen, M. & Massaro, D. </author> <year> (1990), </year> <title> `Synthesis of visible speech', Behaviour Research Methods, </title> <booktitle> Intruments and Computers 22(2), </booktitle> <pages> pp. 260-263. </pages>
Reference-contexts: Vision can cause auditory illusions too, such as the McGurk effect <ref> (Cohen & Massaro 1990) </ref>. These studies demonstrate that humans' perception of their senses cannot be treated as completely independent processes. Methodology Our methodology|exploring themes of development, social interaction, physical interaction and integration while building real robots|is motivated by two ideas.
Reference: <author> Costello, T. </author> <year> (1997), </year> <title> Beyond Minimizing Change, </title> <booktitle> in `Proceedings of American Association of Artificial Intelligence (AAAI-97)', </booktitle> <pages> pp. 448-453. </pages>
Reference: <author> Damasio, A. R. </author> <year> (1994), </year> <title> Descartes' Error, G.P. </title> <publisher> Put-nam's Sons. </publisher>
Reference-contexts: Further, humans often do not use subroutine-like rules for making decisions. They are often more emotional than rational, and there is evidence that this emotional content is an important aspect of decision making <ref> (Damasio 1994) </ref>. Essences of Human Intelligence Since humans are vastly complex systems, we do not expect to duplicate every facet of their operation. However, we must be very careful not to ignore aspects of human intelligence solely because they appear complex.
Reference: <author> Diamond, A. </author> <year> (1990), </year> <title> Developmental Time Course in Human Infants and Infant Monkeys, and the Neural Bases of Inhibitory Control in Reaching, </title> <booktitle> in `The Development and Neural Bases of Higher Cognitive Functions', </booktitle> <volume> Vol. 608, </volume> <publisher> New York Academy of Sciences, </publisher> <pages> pp. 637-676. </pages>
Reference: <editor> Feigenbaum, E. A. & Feldman, J., eds (1963), </editor> <booktitle> Computers and Thought, </booktitle> <publisher> McGraw-Hill, </publisher> <address> New York. </address>
Reference: <author> Ferrell, C. </author> <year> (1996), </year> <title> Orientation Behavior using Registered Topographic Maps, in `From Animals to Ani-mats: </title> <booktitle> Proc 1996 Society of Adaptive Behavior', </booktitle> <address> Cape Cod, Massachusetts, </address> <pages> pp. 94-103. </pages>
Reference-contexts: A map used for a saccad-ing behavior (visual/eye-movement map), was reused to learn a reaching behavior (visual/arm-movement map). The learned saccadic behavior bootstrapped the reaching behavior, reducing the complexity of the overall learning task. Other examples of developmental learning that we have explored can be found in <ref> (Ferrell 1996) </ref>. Gradual increase in complexity The developmental process, starting with a simple system that gradually becomes more complex allows efficient learning throughout the whole process. For example, infants are born with low acuity vision which simplifies the visual input they must process. <p> By exploiting a gradual increase in complexity both internal and external, while reusing structures and information gained from previously learned behaviors, we hope to be able to learn increasingly sophisticated behaviors. We believe that these methods will allow us to construct systems which do scale autonomously <ref> (Ferrell & Kemp 1996) </ref>. Social Interaction Building social skills into an artificial intelligence provides not only a natural means of human-machine interaction but also a mechanism for bootstrapping more complex behavior.
Reference: <author> Ferrell, C. </author> <year> (1998a), </year> <title> Emotional Robots and Learning During Social Exchanges. </title> <note> Submitted to Autonomous Agents-98. </note>
Reference: <author> Ferrell, C. </author> <year> (1998b), </year> <title> `Learning by Scaffolding'. </title> <type> MIT Ph.D. Thesis Proposal. </type>
Reference-contexts: In addition to the full humanoid, we have also developed active head platforms, of similar design to Cog's head, as shown in Figure 2 (Scassellati 1998a). These self-contained systems allow us to concentrate on various issues in close human-machine interaction, including face detection, imitation, emotional display and communication, etc. <ref> (Scassellati 1998b, Ferrell 1998c) </ref>. Development Building systems developmentally facilitates learning both by providing a structured decomposition of skills and by gradually increasing the complexity of the task to match the competency of the system. Bootstrapping Development is an incremental process. <p> We are currently engaged in work studying bootstrapping new behaviors from social interactions. One research project focuses on building a robotic system capable of learning communication behaviors in a social context where the human provides various forms of scaffolding to facilitate the robot's learning task <ref> (Ferrell 1998b) </ref>. The system uses expressive facial gestures (see The caregiver can then regulate the complexity of the social interaction to optimize the robot's learning rate. Development of social interaction The social skills required to make use of scaffolding are complex.
Reference: <author> Ferrell, C. </author> <year> (1998c), </year> <title> A Motivational System for Regulating Human-Robot Interaction. </title> <note> Submitted to AAAI-98. </note>
Reference: <author> Ferrell, C. & Kemp, C. </author> <year> (1996), </year> <title> An Ontogenetic Perspective to Scaling Sensorimotor Intelligence, in `Embodied Cognition and Action: </title> <booktitle> Papers from the 1996 AAAI Fall Symposium', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: A map used for a saccad-ing behavior (visual/eye-movement map), was reused to learn a reaching behavior (visual/arm-movement map). The learned saccadic behavior bootstrapped the reaching behavior, reducing the complexity of the overall learning task. Other examples of developmental learning that we have explored can be found in <ref> (Ferrell 1996) </ref>. Gradual increase in complexity The developmental process, starting with a simple system that gradually becomes more complex allows efficient learning throughout the whole process. For example, infants are born with low acuity vision which simplifies the visual input they must process. <p> By exploiting a gradual increase in complexity both internal and external, while reusing structures and information gained from previously learned behaviors, we hope to be able to learn increasingly sophisticated behaviors. We believe that these methods will allow us to construct systems which do scale autonomously <ref> (Ferrell & Kemp 1996) </ref>. Social Interaction Building social skills into an artificial intelligence provides not only a natural means of human-machine interaction but also a mechanism for bootstrapping more complex behavior.
Reference: <author> Gazzaniga, M. S. & LeDoux, J. E. </author> <year> (1978), </year> <title> The Integrated Mind, </title> <publisher> Plenum Press, </publisher> <address> New York. </address>
Reference-contexts: When the right hemisphere then picked a shovel to correctly match the snow, the left hemisphere explained that you need a shovel to "clean out the chicken shed" <ref> (Gazzaniga & LeDoux 1978, p.148) </ref>. The separate halves of the subject independently acted appropriately, but one side falsely explained the choice of the other. This suggests that there are multiple independent control systems, rather than a single monolithic one. Humans are not general purpose.
Reference: <author> Greene, P. H. </author> <year> (1982), </year> <title> `Why is it easy to control your arms?', </title> <journal> Journal of Motor Behavior 14(4), </journal> <pages> 260-286. </pages>
Reference-contexts: By exploiting the properties of the complete system, certain seemingly complex tasks can be made computationally simple. For example, when putting a jug of milk in the refrigerator, you can exploit the pendulum action of your arm to move the milk <ref> (Greene 1982) </ref>. The swing of the jug does not need to be explicitly planned or controlled, since it is the natural behavior of the system. Instead of having to plan the whole motion, the system only has to modulate, guide and correct the natural dynamics.
Reference: <author> Hauskrecht, M. </author> <year> (1997), </year> <title> Incremental Methods for computing bounds in partially observable Markov decision processes, </title> <booktitle> in `Proceedings of American Association of Artificial Intelligence (AAAI-97)', </booktitle> <pages> pp. 734-739. </pages>
Reference: <author> Hobson, R. P. </author> <year> (1993), </year> <title> Autism and the Development of Mind, </title> <publisher> Erlbaum. </publisher>
Reference-contexts: The system uses expressive facial gestures (see The caregiver can then regulate the complexity of the social interaction to optimize the robot's learning rate. Development of social interaction The social skills required to make use of scaffolding are complex. Infants acquire these social skills through a developmental progression <ref> (Hobson 1993) </ref>. One of the earliest precursors is the ability to share attention with the caregiver. This ability can take many forms, from the recognition of a pointing gesture to maintaining eye contact. In our work, we have also examined social interaction from this developmental perspective.
Reference: <author> Irie, R. E. </author> <year> (1997), </year> <title> Multimodal Sensory Integration for Localization in a Humanoid Robot, </title> <booktitle> in `Proceedings of Second IJCAI Workshop on Computational Auditory Scene Analysis (CASA'97)', IJCAI-97. </booktitle>
Reference: <author> Johnson, M. H. </author> <year> (1993), </year> <title> Constraints on Cortical Plasticity, </title> <editor> in M. H. Johnson, ed., </editor> <title> `Brain Development and Cognition: A Reader', </title> <publisher> Blackwell, Oxford, </publisher> <pages> pp. 703-721. </pages>
Reference-contexts: For example, infants are born with low acuity vision which simplifies the visual input they must process. The infant's visual perfor mance develops in step with their ability to process the influx of stimulation <ref> (Johnson 1993) </ref>. The same is true for the motor system. Newborn infants do not have independent control over each degree of freedom of their limbs, but through a gradual increase in the granularity of their motor control they learn to coordinate the full complexity of their bodies.
Reference: <author> Karmiloff-Smith, A., Klima, E., Bellugi, U., Grant, J. & Baron-Cohen, S. </author> <year> (1995), </year> <title> `Is there a social module? Language, face processing, and theory of mind in individuals with Williams Syndrome', </title> <journal> Journal of Cognitive Neuroscience 7:2, </journal> <pages> 196-208. </pages>
Reference: <author> Knudsen, E. I. & Knudsen, P. F. </author> <year> (1985), </year> <title> `Vision Guides the Adjustment of Auditory Localization in Young Barn Owls', </title> <booktitle> Science 230, </booktitle> <pages> 545-548. </pages>
Reference-contexts: This interaction between the senses continues to develop, indeed related investigations with young owls have determined that visual stimuli greatly affect the development of sound localization. With a constant visual bias from prisms, owls adjusted their sound localization to match the induced visual errors <ref> (Knudsen & Knudsen 1985) </ref>. Irie (1997) built an auditory system for our robot that utilizes visual information to train auditory localization; the visually-determined location of a sound source with a corresponding motion is used to train an auditory spatial map.
Reference: <author> Lakoff, G. </author> <year> (1987), </year> <title> Women, Fire, and Dangerous Things: What Categories Reveal about the Mind, </title> <publisher> University of Chicago Press, Chicago, Illinois. </publisher>
Reference-contexts: Instead of having to plan the whole motion, the system only has to modulate, guide and correct the natural dynamics. For an embodied system, internal representations can be ultimately grounded in sensory-motor interactions with the world <ref> (Lakoff 1987) </ref>. Integration Humans have the capability to receive an enormous amount of information from the world. Visual, auditory, somatosensory, and olfactory cues are all processed simultaneously to provide us with our view of the world.
Reference: <author> Littman, M. L. </author> <year> (1997), </year> <title> Probabilistic Propositional Planning: Representations and Complexity, </title> <booktitle> in `Proceedings of American Association of Artificial Intelligence (AAAI-97)', </booktitle> <pages> pp. 748-754. </pages>
Reference: <author> Lobo, J., Mendez, G. & Taylor, S. R. </author> <year> (1997), </year> <title> Adding Knowledge to the Action Description Language A, </title> <booktitle> in `Proceedings of American Association of Artificial Intelligence (AAAI-97)', </booktitle> <pages> pp. 454-459. </pages>
Reference: <author> Marjanovic, M. J., Scassellati, B. & Williamson, M. M. </author> <year> (1996), </year> <title> Self-Taught Visually-Guided Pointing for a Humanoid Robot, </title> <booktitle> in `From Animals to Animats: Proceedings of 1996 Society of Adaptive Behavior', </booktitle> <address> Cape Cod, Massachusetts, </address> <pages> pp. 35-44. </pages>
Reference: <author> McCain, N. & Turner, H. </author> <year> (1997), </year> <title> Causal Theories of Action and Change, </title> <booktitle> in `Proceedings of American Association of Artificial Intelligence (AAAI-97)', </booktitle> <pages> pp. 460-465. </pages>
Reference: <author> McGeer, T. </author> <year> (1990), </year> <title> Passive Walking with Knees, </title> <booktitle> in `Proc 1990 IEEE Intl Conf on Robotics and Automation'. </booktitle>
Reference-contexts: In all cases, there is no central controller, and no modeling of the arms or the environment; the behavior of the whole system comes from the coupling of the arm and controller dynamics. Other researchers have built similar systems which exhibit complex behavior with either simple or no control <ref> (McGeer 1990, Schaal & Atkeson 1993) </ref> by exploiting the system dynamics. Sensory Integration Sensory Integration Simplifies Computation Some tasks are best suited for particular sensory modalities. Attempting to perform the task using only one modality is sometimes awkward and computationally intensive.
Reference: <author> Minsky, M. & Papert, S. </author> <year> (1970), </year> <title> `Draft of a proposal to ARPA for research on artificial intelligence at MIT, </title> <type> 1970-71'. </type>
Reference-contexts: However, we must be very careful not to ignore aspects of human intelligence solely because they appear complex. Classical and neo-classical AI tends to ignore or avoid these complexities, in an attempt to simplify the problem <ref> (Minsky & Papert 1970) </ref>. We believe that many of these discarded elements are essential to human intelligence and that they actually simplify the problem of creating human-like intelligence. Development Humans are not born with complete reasoning systems, complete motor systems, or even complete sensory systems.
Reference: <author> Newell, A. & Simon, H. </author> <year> (1961), </year> <title> GPS, a program that simulates thought, </title> <editor> in H. Billing, ed., `Lernende Auto-maten', R. </editor> <publisher> Oldenbourg, </publisher> <address> Munich, Germany, </address> <pages> pp. 109-124. </pages> <note> Reprinted in (Feigenbaum and Feldman, 1963, pp.279-293). </note>
Reference: <author> Pearl, J. </author> <year> (1988), </year> <title> Probabilistic Reasoning in Intelligent Systems, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference-contexts: These systems are dominated by search problems to both access the relevant facts, and determine how to apply them. Neo-classical AI adds Bayesian or other probabilistic ideas to this basic framework <ref> (Pearl 1988) </ref>. The underlying assumption of these approaches is that because a description of reasoning/behavior/- learning is possible at some level, then that description must be made explicit and internal to any mechanism that carries out the reasoning/behavior/learning.
Reference: <author> Peskin, J. & Scassellati, B. </author> <year> (1997), </year> <title> Image Stabilization through Vestibular and Retinal Feedback, </title> <editor> in R. Brooks, ed., </editor> <booktitle> `Research Abstracts', </booktitle> <institution> MIT Artificial Intelligence Laboratory. </institution>
Reference: <author> Rensink, R., O'Regan, J. & Clark, J. </author> <year> (1997), </year> <title> `To See or Not to See: The Need for Attention to Perceive Changes in Scenes', </title> <booktitle> Psychological Science 8, </booktitle> <pages> 368-373. </pages>
Reference: <author> Rosenschein, S. J. & Kaelbling, L. P. </author> <year> (1986), </year> <title> The Synthesis of Machines with Provable Epistemic Properties, </title> <editor> in J. Halpern, ed., </editor> <booktitle> `Proc. Conf. on Theoretical Aspects of Reasoning about Knowledge', </booktitle> <publisher> Morgan Kauf-mann Publishers, </publisher> <address> Los Altos, California, </address> <pages> pp. 83-98. </pages>
Reference: <author> Scassellati, B. </author> <year> (1996), </year> <title> Mechanisms of Shared Attention for a Humanoid Robot, in `Embodied Cognition and Action: </title> <booktitle> Papers from the 1996 AAAI Fall Symposium', </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: In our work, we have also examined social interaction from this developmental perspective. One research program focuses on a developmental implementation of shared attention mechanisms based upon normal child development, developmental models of autism 1 , and on models of the evolutionary development of social skills <ref> (Scassellati 1996) </ref>. The first step in this developmental progression is recognition of eye contact. Human infants are predisposed to attend to socially relevant stimuli, such as faces and objects that have humanlike motion.
Reference: <author> Scassellati, B. </author> <year> (1998a), </year> <title> A Binocular, Foveated Active Vision System, </title> <type> Technical report, </type> <institution> MIT Artificial Intelligence Lab. </institution> <note> In submission. </note>
Reference-contexts: These together present many opportunities for interaction between the robot and humans. In addition to the full humanoid, we have also developed active head platforms, of similar design to Cog's head, as shown in Figure 2 <ref> (Scassellati 1998a) </ref>. These self-contained systems allow us to concentrate on various issues in close human-machine interaction, including face detection, imitation, emotional display and communication, etc. (Scassellati 1998b, Ferrell 1998c).
Reference: <author> Scassellati, B. </author> <year> (1998b), </year> <title> Finding Eyes and Faces with a Foveated Vision System, </title> <journal> in `Proceedings of the American Association of Artificial Intelligence'. </journal> <note> Submitted to AAAI-98. </note>
Reference-contexts: In addition to the full humanoid, we have also developed active head platforms, of similar design to Cog's head, as shown in Figure 2 (Scassellati 1998a). These self-contained systems allow us to concentrate on various issues in close human-machine interaction, including face detection, imitation, emotional display and communication, etc. <ref> (Scassellati 1998b, Ferrell 1998c) </ref>. Development Building systems developmentally facilitates learning both by providing a structured decomposition of skills and by gradually increasing the complexity of the task to match the competency of the system. Bootstrapping Development is an incremental process.
Reference: <author> Scassellati, B. </author> <year> (1998c), </year> <title> Imitation and Mechanisms of Shared Attention: A Developmental Structure for Building Social Skills, in `Agents in Interaction Acquiring Competence through Imitation: </title> <booktitle> Papers from a Workshop at the Second International Conference on Autonomous Agents'. </booktitle>
Reference-contexts: The system is currently capable of detecting faces in its peripheral vision, saccading to the faces, and finding eyes within its foveal vision (Scas-sellati 1998b). This developmental chain has also produced a simple imitation behavior; the head will mimic yes/no head nods of the caregiver <ref> (Scassellati 1998c) </ref>. Physical Coupling Another aspect of our methodology is to exploit interaction and tight coupling between the robot and its environment to give complex behavior, to facilitate learning, and to avoid the use of explicit models.
Reference: <author> Schaal, S. & Atkeson, C. G. </author> <year> (1993), </year> <title> Open loop Stable Control Strategies for Robot Juggling, </title> <booktitle> in `Proceedings 1993 IEEE International Conference on Robotics and Automation', </booktitle> <volume> Vol. 3, </volume> <pages> pp. 913-918. </pages>
Reference: <author> Stroop, J. </author> <year> (1935), </year> <title> `Studies of interference in serial verbal reactions', </title> <journal> Journal of Experimental Psychology 18, </journal> <pages> 643-62. </pages>
Reference-contexts: However, humans seem to be proficient only in particular sets of skills, at the expense of other skills, often in non-obvious ways. A good example of this is the Stroop effect <ref> (Stroop 1935) </ref>. When presented with a list of words written in a variety of colors, performance in a color recognition and articulation task is actually dependent on the semantic content of the words; the task is very difficult if names of colors are printed in non-corresponding colors.
Reference: <author> Thelen, E. & Smith, L. </author> <year> (1994), </year> <title> A Dynamic Systems Approach to the Development of Cognition and Action, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: A process where the acuity of both sensory and motor systems are gradually increased significantly reduces the difficulty of the learning problem <ref> (Thelen & Smith 1994) </ref>. To further facilitate learning, the gradual increase in internal complexity associated with development should be accompanied by a gradual increase in the complexity of the external world. For an infant, the caregiver biases how learning proceeds by carefully structuring and controlling the complexity of the environment.
Reference: <author> Wason, P. C. </author> <year> (1966), </year> <title> New Horizons in Psychology, </title> <journal> Vol. </journal> <volume> 1, </volume> <publisher> Penguin Books, </publisher> <address> Harmondsworth, England, </address> <pages> pp. 135-51. </pages>
Reference: <author> Weiskrantz, L. </author> <year> (1986), </year> <title> Blindsight: A Case Study and Implications, </title> <publisher> Clarendon Press, Oxford. </publisher>
Reference-contexts: There is also evidence that there are multiple internal representations, which are not mutually consistent. For example, in the phenomena of blindsight, cortically blind patients can discriminate different visual stimuli, but actually report seeing nothing <ref> (Weiskrantz 1986) </ref>. This inconsistency would not be a feature of a single central model of visual space. These experiments and many others like it (e.g. (Rensink, O'Regan & Clark 1997, Gazzaniga & LeDoux 1978)) convincingly demonstrate that humans do not construct a full, monolithic model of the environment.
Reference: <author> Wertheimer, M. </author> <year> (1961), </year> <title> `Psychomotor coordination of auditory and visual space at birth', </title> <booktitle> Science 134, </booktitle> <pages> 1692. </pages>
Reference: <author> Williamson, M. M. </author> <year> (1998a), </year> <title> Exploiting natural dynamics in robot control, </title> <booktitle> in `Fourteenth European Meeting on Cybernetics and Systems Research (EMCSR '98)', </booktitle> <address> Vienna, Austria. </address>
Reference-contexts: One example of such a scheme is implemented to control our robot's arms. As detailed in <ref> (Williamson 1998a, Williamson 1998b) </ref>, a set of self-adaptive oscillators are used to drive the joints of the arm. Each joint is actuated by a single oscillator, using proprioceptive information at that joint to alter the frequency and phase of the joint motion.
Reference: <author> Williamson, M. M. </author> <year> (1998b), </year> <title> Rhythmic robot control using oscillators. </title> <note> Submitted to IROS '98. </note>
Reference: <author> Wood, D., Bruner, J. S. & Ross, G. </author> <year> (1976), </year> <title> `The role of tutoring in problem-solving', </title> <journal> Journal of Child Psychology and Psychiatry 17, </journal> <pages> 89-100. </pages>
Reference-contexts: Commonly scaffolding involves reducing distractions, marking the task's critical attributes, reducing the number of degrees of freedom in the target task, and enabling the subject to experience the end or outcome before the infant is cognitively or physically able of seeking and attaining it for herself <ref> (Wood, Bruner & Ross 1976) </ref>. We are currently engaged in work studying bootstrapping new behaviors from social interactions.
References-found: 54

