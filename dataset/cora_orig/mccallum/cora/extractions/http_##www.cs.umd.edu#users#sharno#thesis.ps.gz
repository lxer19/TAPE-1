URL: http://www.cs.umd.edu/users/sharno/thesis.ps.gz
Refering-URL: http://www.cs.umd.edu/users/sharno/
Root-URL: 
Title: The Extended Hypercube Protocol A New Multi-dimensional Replication Protocol  and Automatic Control  
Degree: A thesis submitted to the  in Partial fulfillment of the requirements for the degree of Master of Science By  
Date: 1997  
Address: Alexandria University  
Affiliation: Alexandria University Faculty of Engineering  Department of Computer Science  Eng. Tamer Mahmoud Elsharnouby  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Swarup Acharya and Stanley B. Zdonik. </author> <title> An efficient scheme for dynamic data replication. </title> <type> Technical Report CS-93-43, </type> <institution> Brown University, </institution> <month> September </month> <year> 1993. </year>
Reference-contexts: This protocol needs that the replicas connected in a virtual connection. So, any failure will result in reconstruction of the ring again. Also the sweep is costly, same as using anti-entropy techniques. 3.7 Dynamic Data Replication 3.7.1 Acharya Algorithm This protocol is proposed by Acharya and Zdonik <ref> [1] </ref>. It is a practical algorithm against the unrealistic assumptions mentioned in other protocols. Replication Scheme (RS) for an object is a subnet of the nodes in the network which hold a copy of that object.
Reference: [2] <author> Noha Adly. </author> <title> Replication in distributed systems. </title> <type> Technical report, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: Epsilon Serializability Epsilon serializability (ESR), a generalization of classic serializability (SR), explicitly allows some limited amount of inconsistency in transaction processing <ref> [36, 2, 34] </ref>. ESR enhances concurrency and availability since some non-SR execution schedules are permitted. For example, epsilon-transactions (ETs) that just perform queries may execute in spite of ongoing concurrent updates to the database. Thus, the query may view uncommitted, possibly inconsistent, data. <p> Most asynchronous protocols are placed in this category. They concede operation and cease commit till the result of validation. Others grant commit and then resolve conflicts using merging in later time. 12 3.3.3 Synchronous vs. Asynchronous Protocols Most replication control are encountered under synchronous <ref> [2] </ref> techniques. They are synchronous, in the sense that it requires atomic updating of some of the replicas to ensure consistent databases. <p> The problem is that the protocol has to merge the histories of locked quorum to determine the relevent state state of the instant of data object. Voting With Witnesses It is a variation of Gifford's weighting scheme [23] that aims to reduce the storage cost associated with replication <ref> [33, 2] </ref>. Some of the copies are replaced with small records, called witnesses, that keep only the status of the file but not the data. A witness has weight as if it is a normal copy, and thus, it can participate in a quorum. <p> If new replicas of the object can be created faster than a failure can be repaired, then better reliability can be achieved by creating new replicas on the available nodes in response to node failures. This technique is known as regeneration <ref> [35, 2] </ref>. Here, we have to care about number of copies all the time, whether sites crashed or recovered. If sites crash, we must check number of sites to decide whether to generate more copies or not. <p> So, it is suitable for rarely updated systems. The other main drawback is the bottleneck at root which is compared to primary copy system. Hierarchical Quorum Protocol The heirarchical protocol <ref> [2] </ref> is based on organizing the copies of an object into a logical multi-level hierarchy. The objective is to develop a synchronization scheme that scales well for large number of copies and minimizes the size of the quorum to reduce access times. <p> Theoretically, this protocol has increased performance but very complex and uses. To the best of our knowledge, no performance analysis is done for this protocol. 21 3.6 Asynchronous Protocols 3.6.1 Epidemic Algorithms It is a collection of algorithms <ref> [2] </ref>, which were described for distributing updates asynchronously and driving the replicas towards consistency. They are intended to maintain a widely replicated directory. The used communication methods are: direct mail, rumor mongery, and anti-entropy. <p> This may be good for small databases but for big ones, it is very costly. 3. Rumor Mongery: This technique sends updates of a replica to other replicas selected randomly using unreliable datagrams. Other techniques such as time-stamped anti-entropy and grapevine <ref> [2] </ref> 3.6.2 The Yellow Page Algorithm The Yellow Page (YP) [14] constitute a well-known distributed database for rarely update system data in LANs, such as ethernet addresses or service port numbers. As these data are rarely updated, the administrators need not to preserve consistency at all times. <p> They lean on multi-version timestamps. This protocol suffers from a number of problems: performance and consistency are very sensitive to periods between gossip messages, excess load on the network, and bad handling of failures <ref> [2] </ref>. Moreover, there is the huge storage needed for storing the multi-version replicas. Lazy Group Replication It allows any node to update any local data. When the transaction commits, a transaction is sent to every other node to apply the root transaction's updates to the replicas at destination node [25]. <p> When disconnection ceased, modifications are bred and it reverts to server replication. Hence, reads and writes are allowed during network partitioning. When the partition heals, conflicts are detected and replicas are marked inconsistent. Mechanisms rely on optimistic strategy. Detailed algorithm is described by Adly <ref> [2] </ref>. 3.6.6 Sweep Algorithm Here, updates are done at one copy and propagation is done due a sweep operation moving deterministically around a ring of servers held together by pointers from one server to the next. Unique timestamps such as devised by Lamport are used to resolve conflicts.
Reference: [3] <author> Atul Adya, Robert Graber, Barbara Liskov, and Umesh Maheshwari. </author> <title> Efficient optimistic concurrency control using loosely synchronized clocks. </title> <booktitle> In ACM Proceedings on Database Systems, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: We use loosely-synchronized timestamps. The scheme uses timestamps generated from local clocks to define the serial order of transaction. Full details of the algorithm is mentioned by Ozsu and Valduriez [32]. Whereas, generation of loosely-synchronized stamps is illustrated by Adya el al <ref> [3] </ref>. 55 Parameter Interpretation NumberOfPlanes Number of planes of the cuboid NumberOfRows Number of rows of the cuboid NumberOfColumns Number of columns of the cuboid TheCuboid the arrangement of sites in a cuboid l w length of the write quorum w w width of the write quorum h w height of
Reference: [4] <author> D. Agrawal and A. El Abbadi. </author> <title> The generalized tree quorum protocol: An efficient approach for manageming replicated data. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17(4) </volume> <pages> 689-717, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Up to our knowledge, there is no analysis of its performance, so we can not state its performance. In my opinion, a site will suffer from a long response time as the messages must go through all these sites. Tree Quorum Protocol This approach <ref> [4] </ref> for implementing quorums imposes a logical tree structure on the copies of an object x.
Reference: [5] <author> D. Agrawal and A. El Abbadi. </author> <title> Resilient logical structures for efficient management of replicated data. </title> <booktitle> In Proceedings of the 18th VLDB Conference, </booktitle> <address> Vancouver, British Columbia, Canada, </address> <year> 1992. </year>
Reference-contexts: The quorums created must follow the following theorem: 39 Theorem: Quorum Intersection Property For any two operations o [x] and o [x] on an object x, where at least one of them is a write, the quorums must have a nonempty intersection <ref> [5] </ref>. The grid protocol, mentioned in the previous chapter, propose a new quorum assignments. Assuming a grid of &lt; r; c &gt;, read operations are executed by acquiring a read quorum of c sites, one site in each of the different c columns.
Reference: [6] <author> Divyacant Agrawal, Omer Egeciogla, and Amr El Abbadi. </author> <title> Billiard quorums on the grid. </title> <type> Technical report, </type> <institution> University of California, Santa Barbara, </institution> <year> 1996. </year>
Reference-contexts: This protocol handles failures of sites in a bad way. There are some solutions to this problems. Agrawal and El Abbadi suggested a solution [7] for the second problem using reconfiguration of the grid. Billiard Quorums on the Grid This protocol <ref> [6] </ref> is just a modification to the grid protocol mentioned in the previous section. It reduces the quorum size required for voting by assuming the logical connection of the sites as modified grid. A modified grid is a grid where every site is apart two steps than nearest one. <p> Q wi must intersect with all the write quorums of the available protocols according to Write-Write Intersection Rule. 5.5 Quorum size The goal of most of the protocols is to decrease quorum size. That's because the communication cost is directly proportional to the size of quorums <ref> [6] </ref>. The Cheung grid protocol decreases the quorum size (2 p n 1 in n-sites grid), but the paid price is the reduction of availability. In the hypercube protocol, we may increase availability 48 against the increase of quorum size.
Reference: [7] <author> Divyakant Agrawal and Amr El Abbadi. </author> <title> Using reconfiguration for efficient management of replicated data. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 8(5), </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: But the sites are statically assigned so it can not reflect the failures of the sites. This protocol handles failures of sites in a bad way. There are some solutions to this problems. Agrawal and El Abbadi suggested a solution <ref> [7] </ref> for the second problem using reconfiguration of the grid. Billiard Quorums on the Grid This protocol [6] is just a modification to the grid protocol mentioned in the previous section. It reduces the quorum size required for voting by assuming the logical connection of the sites as modified grid. <p> This availability of the sites increases in this system as the operations are still proceeding even under the great number of failures. In Cheung algorithm, system will fail if an entire column fails, whereas our system (also proposed by Agrawal et al <ref> [7] </ref>) is still operable even under great number of failures. Figures 5.9 shows that during failure of a column (7 sites) in Chang algorithm, no operation can take place. In the majority grid assignment, system is still operable inspite the failure of 33 nodes.
Reference: [8] <author> Peter M. G. Apers, Alan R. Hevner, and S. Bing Yao. </author> <title> Optimization algorithms for distributed queries. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 57-68, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: If partitioning (fragmentation) is chosen, data can be distributed using vertical, horizontal, extended, or hybrid fragmentation. If replication is chosen, the choice is whether to fully or partially replicate data. Distributed Query Processing The problem is how to determine the nearly optimal strategy, <ref> [8, 41, 18, 22, 18] </ref>, for executing each query over the network. The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information.
Reference: [9] <author> Arthur J. Bernstein and Philip M. Lewis. </author> <title> Concurrency in Programming and Database Systems. </title> <editor> Jones and Bartlett, </editor> <year> 1993. </year>
Reference-contexts: Quorum Consensus Protocol Quorum consensus (QC) protocol is a generalization of majority consensus one. The basic idea is that when a transaction makes a request to read (write) a replicated 16 record, the concurrency control first locks some subset, called the read quorum (write quorum), before granting a request <ref> [9] </ref>. In the quorum consensus, a non-negative weight is assigned to each copy of a replicated data object x. <p> All copies must be known in advance to assign weights. Some modifications allow dynamic reconfiguration. Liu et al [27] introduced several modifications to the quorum consensus protocol which enhance QC performance. Replica Control can be for either typed or untyped databases. It is introduced by Bernstein and Lewis in <ref> [9] </ref>. It involves an extra history for abstract operations on data. The problem is that the protocol has to merge the histories of locked quorum to determine the relevent state state of the instant of data object.
Reference: [10] <author> Philip A. Bernstein and Nathan Goodman. </author> <title> Concurrency control in distributed database systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 13(2), </volume> <year> 1981. </year> <month> 74 </month>
Reference-contexts: The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information. Distributed Concurrency Control Concurrency control involves the synchronization of accesses to the distributed database, such that the integrity of the database is maintained. There are many techniques introduced <ref> [37, 10, 11, 24, 20] </ref>. They are all fall in either pessimistic class or optimistic class. The techniques used in their implementation fall in either locking class, or timestamping class. Distributed Deadlock Management The problems encounter in DDBMS are similar in nature as in operating systems.
Reference: [11] <author> Philip A. Bernstein and Nathan Goodman. </author> <title> A sophisticate's introduction to distributed database concurrency control. </title> <booktitle> In The Proceedings of the 8th VLDB Conference, </booktitle> <pages> pages 62-76, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information. Distributed Concurrency Control Concurrency control involves the synchronization of accesses to the distributed database, such that the integrity of the database is maintained. There are many techniques introduced <ref> [37, 10, 11, 24, 20] </ref>. They are all fall in either pessimistic class or optimistic class. The techniques used in their implementation fall in either locking class, or timestamping class. Distributed Deadlock Management The problems encounter in DDBMS are similar in nature as in operating systems. <p> We choose theories that affect replication control. 3.2.1 Serializability Serializability theory is a general concept which is defined over databases <ref> [15, 32, 11] </ref>. It depends on defining a schedule (or history) S which is a sequence of operations executed by a set of transactions T = fT 1 ; T 2 ; : : : ; T n g. Two operations conflict when they can not commute.
Reference: [12] <author> Philip A. Bernstein and Nathan Goodman. </author> <title> An algorithm for concurrency control and recovery in replicated distributed databases. </title> <journal> ACM TODS, </journal> <volume> 9(4) </volume> <pages> 596-615, </pages> <month> December </month> <year> 1984. </year>
Reference-contexts: Also, when the primary site fails, all the system will stop until electing another site to be the primary plus recovering all the lost locks. EMPACT [30] and Oracle use this protocol. 3.4.2 Primary Copy Protocol This protocol is known as unanimous agreement update protocol <ref> [12] </ref>. It follows the read-one-write-all approach. In the absence of failures, replica control can be easily achieved by assigning the readset to contain any copy of data item x, and assigning the write set to contain all the copies of x.
Reference: [13] <author> Philip A. Bernstein, Vassos Hadzilacos, and Nathan Goodman. </author> <title> Concurrency Control And Recovery in Database Systems. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1987. </year>
Reference-contexts: Global serializability must be maintained. This is achieved if O ij precedes O kl in the global schedule, O ij must precede O kl in each local schedule. Serializability for Replicated Data We will extend the basic serializability theory <ref> [13] </ref> by using two types of schedules: replicated data (RD) schedules and one-copy (1C) schedules. RD schedules represents the database system view of execution of operations on a replicated database. 1C schedules are quiet similar to the schedules defined in the above section. <p> It requires, among other things, that transactions attempt to update copies at down sites. If site failures persist for long periods, this is clearly inefficient. In addition, it is not possible to dynamically create or destroy copies at new sites. Directory-oriented available copies algorithm <ref> [13] </ref> rectifies these problems. The algorithm uses directories to define the set of sites that currently stores the copies of a data object: for each data object (x), there is a directory d (x) which contains listing of x's copies.
Reference: [14] <author> Clemens H. </author> <title> Cap. Distributed systems with data replication: A non technical survey. </title> <type> Technical Report IFI-TR-90.11, </type> <institution> Institut fur Informatik der Univeristat Zurich(IFI), </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: Of course, this approach is intimately connected with the specific semantics of the application and will not produce a general replication controlling mechanism <ref> [14] </ref>. Syntactic Consistency In every application a transaction will consist of reading data, doing some computation and finally writing some data. We concentrate on the fact that transaction reads and writes data. <p> When moving on to a system supporting multi-user distribution and replication, the only thing we have to guarantee is, that the behavior of the application is not changed, independent of its special semantics <ref> [14] </ref>. 11 3.3 Classification of Replication Control Proto- cols Replication control protocols are classified according to their features. There are many classification recognized in papers. Here, we quantifies different views of classification. 3.3.1 Locking Based vs. <p> The only difference is that ordinary transactions can only read directories. 3.4.5 The Token Algorithm In this generalization of the Primary Site protocol, the coordinating master is not chosen once and for ever (until its clearly failed), but may be dynamically identified as the unique holder of the exclusive token <ref> [14] </ref>. Other sites, several at the same time, may be holders of shared tokens. A write access is granted only to the holder of the exclusive token. <p> The Coteries Algorithm A coterie [21] is a group of sets of sites where the intersection of any two sets in the group must be not empty, e.g.; coterie = ffA; B; Cg; fB; C; Dg; fA; C; Dg; fA; D; Egg. In the coteries algorithm <ref> [14] </ref>, every operation on an item requires the agreement of all the sites in any set from the coterie. A read request is guaranteed to proceed due to the shared locks on all the sites of the set. <p> Rumor Mongery: This technique sends updates of a replica to other replicas selected randomly using unreliable datagrams. Other techniques such as time-stamped anti-entropy and grapevine [2] 3.6.2 The Yellow Page Algorithm The Yellow Page (YP) <ref> [14] </ref> constitute a well-known distributed database for rarely update system data in LANs, such as ethernet addresses or service port numbers. As these data are rarely updated, the administrators need not to preserve consistency at all times.
Reference: [15] <author> Stefano Ceri and Giuseppe Pelagatti. </author> <title> Distributed Databases: </title> <booktitle> Principles and Systems. </booktitle> <publisher> McGraw-Hill Book Company, </publisher> <year> 1985. </year>
Reference-contexts: A typical, but rather vague, definition of a distributed database is the following: A distributed database is a collection of data which belong logically to the same system but are spread over the sites of a computer network <ref> [15] </ref>. This definition emphasizes two equally important aspects of distributed databases: 1. Distribution Data are not resident at the same site, so a distributed database is distinguished from a single centralized database. 2. <p> We choose theories that affect replication control. 3.2.1 Serializability Serializability theory is a general concept which is defined over databases <ref> [15, 32, 11] </ref>. It depends on defining a schedule (or history) S which is a sequence of operations executed by a set of transactions T = fT 1 ; T 2 ; : : : ; T n g. Two operations conflict when they can not commute.
Reference: [16] <author> S. Cheung, M. Ammar, and M. Ahamad. </author> <title> Multi-dimensional voting: A general method for implementing synchronization in distributed systems. </title> <type> Technical Report GIT-ICS-89/35, </type> <institution> Georgia Institute of Technology, </institution> <month> October </month> <year> 1989. </year>
Reference-contexts: It is proven that these quorums are of size 2 log 3n . The algorithm does not perform very well during failures. 3.5.3 Higher Dimension Protocols Multi-dimensional Voting In multi-dimensional (MD) voting <ref> [16] </ref>, the vote assignment to each node, assumes N sites, and the quorum are k-dimensional vectors of non-negative integers. Formally, the MD vote assignment V N;k is N fl k matrix where positive non-zero value, v i;j , represents the vote assignment to node i in the j th dimension. <p> The node i have to consent l quorums, by gathering at least v i;j and j = 1; : : : ; l, from l different dimensions out of the available k ones in order to proceed. Efficient algorithms for vote assignments are mentioned by Cheung et al <ref> [16] </ref>. Theoretically, this protocol has increased performance but very complex and uses.
Reference: [17] <author> S. Cheung, M. Ammar, and M. Ahamad. </author> <title> The grid protocol: A high performance scheme for maintaining replicated data. </title> <booktitle> In Proceedings of the IEEE 6th International Conference on Data Engineering, </booktitle> <year> 1990. </year>
Reference-contexts: If sites crash, we must check number of sites to decide whether to generate more copies or not. If sites recover, we must check number of sites to decide to delete any copies or not. 3.5.2 Planner Protocols Grid Protocol This protocol is introduced by Cheung et al <ref> [17] </ref>. In the grid protocol, the nodes replicating the data are viewed as arranged in a rectangular grid, see figure 3.6. The number of nodes in a row and a column of the grid are M and N respectively. <p> The problem is whether to favor either the read or the write operations. The grid protocol, invented by Cheung, Ammar, and Ahamad <ref> [17] </ref>, favors the read by making the quorum so small compared to the quorums of the write. They chose read quorum to be &lt; 1; p n &gt; and write quorum to be &lt; p n; 1 &gt;.
Reference: [18] <author> Weimin Du, Ming-Chein Shan, and Umeshwar Dayal. </author> <title> Reducing multidatabase query response time by tree balancing. </title> <booktitle> In Proceedings, ACM Sigmoid, </booktitle> <pages> pages 293-303, </pages> <year> 1995. </year>
Reference-contexts: If partitioning (fragmentation) is chosen, data can be distributed using vertical, horizontal, extended, or hybrid fragmentation. If replication is chosen, the choice is whether to fully or partially replicate data. Distributed Query Processing The problem is how to determine the nearly optimal strategy, <ref> [8, 41, 18, 22, 18] </ref>, for executing each query over the network. The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information.
Reference: [19] <author> Arlette Ferrrier and Christine Stangret. </author> <title> Heterogeneity in the distributed database management system sirius-delta. </title> <booktitle> In The Proceedings of The Eighth International Conference on VLDB, </booktitle> <pages> pages 45-53, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: Heterogeneous Databases When there is no homogeneity among the databases in either data model or data language, it becomes necessary to provide a translation mechanism among database systems <ref> [26, 19] </ref>. 6 Replication The problem is to ensure the consistency of the replica. The de-tailed survey is on the next chapter.
Reference: [20] <author> Peter A. Franaszek, Jayant R. Haritsa, John T. Robinson, and Alexander Thomasian. </author> <title> Distributed concurrency control based on limited wait-depth. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 4(11) </volume> <pages> 1246-1264, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information. Distributed Concurrency Control Concurrency control involves the synchronization of accesses to the distributed database, such that the integrity of the database is maintained. There are many techniques introduced <ref> [37, 10, 11, 24, 20] </ref>. They are all fall in either pessimistic class or optimistic class. The techniques used in their implementation fall in either locking class, or timestamping class. Distributed Deadlock Management The problems encounter in DDBMS are similar in nature as in operating systems.
Reference: [21] <author> Hector Garcia-Molina and D. Barbara. </author> <title> How to assign votes in a distributed system. </title> <journal> Journal of ACM, </journal> <volume> 34(4), </volume> <month> October </month> <year> 1985. </year>
Reference-contexts: The algorithm uses timestamps to resolve the conflicts between two concurrent update operations. The main drawback of this algorithm is the huge number of messages required to collect votes. This results in degrading of response time and throughput of the system. The Coteries Algorithm A coterie <ref> [21] </ref> is a group of sets of sites where the intersection of any two sets in the group must be not empty, e.g.; coterie = ffA; B; Cg; fB; C; Dg; fA; C; Dg; fA; D; Egg.
Reference: [22] <author> Minos N. Garofalakis and Yannis E. Ioannids. </author> <title> Multi-dimensional resource scheduling for parallel queries. </title> <booktitle> In Proceedings, ACM Sigmoid, </booktitle> <pages> pages 365-376, </pages> <year> 1996. </year>
Reference-contexts: If partitioning (fragmentation) is chosen, data can be distributed using vertical, horizontal, extended, or hybrid fragmentation. If replication is chosen, the choice is whether to fully or partially replicate data. Distributed Query Processing The problem is how to determine the nearly optimal strategy, <ref> [8, 41, 18, 22, 18] </ref>, for executing each query over the network. The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information.
Reference: [23] <author> D. K. Gifford. </author> <title> Weighted voting for replicated data. </title> <booktitle> In Proceedings of the Seventh ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 150-159, </pages> <address> Pacific Grove, Calif., </address> <month> December </month> <year> 1979. </year>
Reference-contexts: After ascertainment, the operation will be executed else it is aborted and restarted again. The variation between protocols in this class is the method of gathering the votes and how to resolve them. This technique was first mentioned by Robert H. Thomas [38] and D. K. Gifford <ref> [23] </ref>. The elegant feature of this class is the ability to work in either optimistic or pessimistic way. Also, the replication control is distributed among sites. 3.3.2 Pessimistic vs. Optimistic Protocols Most invented protocols are pessimistic in nature. <p> It involves an extra history for abstract operations on data. The problem is that the protocol has to merge the histories of locked quorum to determine the relevent state state of the instant of data object. Voting With Witnesses It is a variation of Gifford's weighting scheme <ref> [23] </ref> that aims to reduce the storage cost associated with replication [33, 2]. Some of the copies are replaced with small records, called witnesses, that keep only the status of the file but not the data.
Reference: [24] <author> Virgil D. Gligor and Radu Popescu-Zeletin. </author> <title> Concurrency control issues in distributed heterogeneous database management systems. In Distributed Data Sharing Systems. F.A. </title> <editor> Scheriber and W. Litwin (Editors), </editor> <address> pages 43-56, </address> <year> 1985. </year>
Reference-contexts: The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information. Distributed Concurrency Control Concurrency control involves the synchronization of accesses to the distributed database, such that the integrity of the database is maintained. There are many techniques introduced <ref> [37, 10, 11, 24, 20] </ref>. They are all fall in either pessimistic class or optimistic class. The techniques used in their implementation fall in either locking class, or timestamping class. Distributed Deadlock Management The problems encounter in DDBMS are similar in nature as in operating systems.
Reference: [25] <author> Jim Gray, Pat Helland, Patrick O'Neil, and Dennis Shasha. </author> <title> The dangers of replication and a solution. </title> <booktitle> Sigmoid Record, </booktitle> <year> 1996. </year>
Reference-contexts: Moreover, there is the huge storage needed for storing the multi-version replicas. Lazy Group Replication It allows any node to update any local data. When the transaction commits, a transaction is sent to every other node to apply the root transaction's updates to the replicas at destination node <ref> [25] </ref>. Lazy Master Replication Master replication assigns an owner to each object. The owner stores the object's correct current value. Update are first done by the owner and then propagated to other replicas. Different objects may have different owners [25]. 3.6.4 Nonblocking Voting Protocols In voting techniques mentioned in section 3.5, <p> apply the root transaction's updates to the replicas at destination node <ref> [25] </ref>. Lazy Master Replication Master replication assigns an owner to each object. The owner stores the object's correct current value. Update are first done by the owner and then propagated to other replicas. Different objects may have different owners [25]. 3.6.4 Nonblocking Voting Protocols In voting techniques mentioned in section 3.5, reads and writes are blocked until finding a quorum. As the normal operation of any transaction requires validation then updating. The situation is reversed in nonblocking techniques as validation follows updating.
Reference: [26] <author> Michael Hammer and David Shipman. </author> <title> Reliability mechanisms for sdd-1: A system for distributed database. </title> <journal> ACM Transactions of Database Systems, </journal> <volume> 5(4) </volume> <pages> 431-461, </pages> <month> December </month> <year> 1980. </year>
Reference-contexts: So the alternatives, which are prevention, avoidance, and detection, are applicable to DDBMS [31]. Reliability of Distributed Database Management Systems This is one of the features of DDBMS. It needs techniques to detect failures and others to recover from them <ref> [26] </ref>. Operating System Support The support provided by operating systems for database operations does not correspond properly to the requirements of the DBMS. The challenge is to provide adequate and simple support for distributed database operations, as well as providing general support for other applications. <p> Heterogeneous Databases When there is no homogeneity among the databases in either data model or data language, it becomes necessary to provide a translation mechanism among database systems <ref> [26, 19] </ref>. 6 Replication The problem is to ensure the consistency of the replica. The de-tailed survey is on the next chapter.
Reference: [27] <author> M. L. Liu, D. Agrawal, and A. El Abbadi. </author> <title> An efficient implementation of the quorum consensus protocol. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of California at Santa Barbara, </institution> <year> 1994. </year>
Reference-contexts: Also, there is no special treatment for recovery as the the recovered copies will not contain the latest version. Conversely, QC protocol has some disadvantages. All copies must be known in advance to assign weights. Some modifications allow dynamic reconfiguration. Liu et al <ref> [27] </ref> introduced several modifications to the quorum consensus protocol which enhance QC performance. Replica Control can be for either typed or untyped databases. It is introduced by Bernstein and Lewis in [9]. It involves an extra history for abstract operations on data. <p> However, there is no bound on the delivery time of the network and messages can not get lost. This model is based on the work of Liu, Agrawal, and El Abbadi <ref> [28, 27] </ref>. As mentioned, the system consists of several sites. Each site has the structure portrayed in figure 6.2. Each site consists of : * Processing Unit: The unit which executes the functions of all the parts of the system. <p> Due to the mentioned reasons, the choice was very relevant to the model. However, there is no source for getting parameters setting. Some are obtained by logical assumptions based on other previously determined parameter settings. Most of the settings are comparable to the works of Liu in <ref> [28, 27] </ref>. Mainly, table 7.3 depends on this technique. Unfortunately, publicly available real access traces are mainly for read-shared systems and do not have a good mix of accesses which are both read and write. So details of the transactions are logically deduced.
Reference: [28] <author> M. L. Liu, D. Agrawal, and A. El Abbadi. </author> <type> What price replication? Technical report, </type> <institution> Department of Computer Science, University of California at Santa Barbara, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: Replication control has been subject of intensive research for quite some time, as we will see in the rest of the chapter. Opponents to the replication concept argue that most of the proposed algorithms are not implemented in a widely used systems like liu et al <ref> [28] </ref>. They prove by simulation that the replicated system does not outperform the non-replicated system. The results are not totally correct due to comparing non-replicated system protocol to some old protocols plus putting the assumption of short duration failures. <p> However, there is no bound on the delivery time of the network and messages can not get lost. This model is based on the work of Liu, Agrawal, and El Abbadi <ref> [28, 27] </ref>. As mentioned, the system consists of several sites. Each site has the structure portrayed in figure 6.2. Each site consists of : * Processing Unit: The unit which executes the functions of all the parts of the system. <p> Due to the mentioned reasons, the choice was very relevant to the model. However, there is no source for getting parameters setting. Some are obtained by logical assumptions based on other previously determined parameter settings. Most of the settings are comparable to the works of Liu in <ref> [28, 27] </ref>. Mainly, table 7.3 depends on this technique. Unfortunately, publicly available real access traces are mainly for read-shared systems and do not have a good mix of accesses which are both read and write. So details of the transactions are logically deduced.
Reference: [29] <author> J. Misra. </author> <title> Detection termination of distributed computations using markers. </title> <booktitle> In Proceedings of 2nd ACM Conference on Principles of Distributed Computing, </booktitle> <pages> pages 290-294, </pages> <address> Montereal, </address> <month> August </month> <year> 1983. </year>
Reference-contexts: This technique allows a return from the write request before all the copies have been updated. Token protocol faces some problems such as lost token. There are some techniques for regenerating lost tokens <ref> [29] </ref>. The other problem is that the exclusive token may be bounded in a small subset. 3.5 Voting Based Protocols Voting techniques depend on collecting a vote to determine whether to execute an operation using certain techniques, and after ascertainment, the operation proceed to read or write.
Reference: [30] <author> Alan Norman and Mark Anderton. Empact: </author> <title> A distributed database application. </title> <booktitle> In AFIPS Conference Proceedings, </booktitle> <volume> volume 52, </volume> <pages> pages 203-217, </pages> <year> 1983. </year>
Reference-contexts: It is obvious that this protocol suffers from the contention at high load rates. Also, when the primary site fails, all the system will stop until electing another site to be the primary plus recovering all the lost locks. EMPACT <ref> [30] </ref> and Oracle use this protocol. 3.4.2 Primary Copy Protocol This protocol is known as unanimous agreement update protocol [12]. It follows the read-one-write-all approach.
Reference: [31] <author> Ron Obermarck. </author> <title> Distributed deadlock detection algorithm. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 7(2) </volume> <pages> 187-208, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: The techniques used in their implementation fall in either locking class, or timestamping class. Distributed Deadlock Management The problems encounter in DDBMS are similar in nature as in operating systems. So the alternatives, which are prevention, avoidance, and detection, are applicable to DDBMS <ref> [31] </ref>. Reliability of Distributed Database Management Systems This is one of the features of DDBMS. It needs techniques to detect failures and others to recover from them [26]. Operating System Support The support provided by operating systems for database operations does not correspond properly to the requirements of the DBMS.
Reference: [32] <author> M. Tamer Ozsu and Patrick Valduriez. </author> <booktitle> Principles of Distributed Database Systems. Prentice-Hall International, </booktitle> <publisher> Inc., </publisher> <year> 1991. </year>
Reference-contexts: The existance of several autonomous processors results in the increase of performance through parallelism inherent in distributed systems. Replication of data at many sites, and lack of contention (bottlenecks) improve data accessibility, and thus performance. Economics There are two points of view <ref> [32] </ref> when compared to centralized system: * The first is in terms of communication costs. If databases are geographically dispersed and the applications running against them exhibit strong interaction of dispersed data, it may be much more economical to partition the application and do the processing locally at each site. <p> We choose theories that affect replication control. 3.2.1 Serializability Serializability theory is a general concept which is defined over databases <ref> [15, 32, 11] </ref>. It depends on defining a schedule (or history) S which is a sequence of operations executed by a set of transactions T = fT 1 ; T 2 ; : : : ; T n g. Two operations conflict when they can not commute. <p> A transaction is correct if its effect is a consistent database. The objective of concurrency control and replication control is to ensure consistency. There are four levels of consistency <ref> [32] </ref>. Dirty data refers to data values that have been written by a transaction prior to its commitment. 10 Level 3 Strong Consistency This class of the consistency has the most restrictive criteria on the operations of the transactions. Most protocols fall in this category. <p> We use loosely-synchronized timestamps. The scheme uses timestamps generated from local clocks to define the serial order of transaction. Full details of the algorithm is mentioned by Ozsu and Valduriez <ref> [32] </ref>.
Reference: [33] <author> J.F. Paris. </author> <title> Voting with witnesses. a consisitency scheme for replicated files. </title> <booktitle> In IEEE Proceedings of the 6th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 606-612, </pages> <year> 1986. </year>
Reference-contexts: The problem is that the protocol has to merge the histories of locked quorum to determine the relevent state state of the instant of data object. Voting With Witnesses It is a variation of Gifford's weighting scheme [23] that aims to reduce the storage cost associated with replication <ref> [33, 2] </ref>. Some of the copies are replaced with small records, called witnesses, that keep only the status of the file but not the data. A witness has weight as if it is a normal copy, and thus, it can participate in a quorum.
Reference: [34] <author> C. Pu and A. Leff. </author> <title> Replica control in distributed systems: An asynchronous approach. </title> <booktitle> In Proceedings, ACM Sigmoid, International Conference Management of Data, </booktitle> <pages> pages 277-386, </pages> <address> Denever, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Epsilon Serializability Epsilon serializability (ESR), a generalization of classic serializability (SR), explicitly allows some limited amount of inconsistency in transaction processing <ref> [36, 2, 34] </ref>. ESR enhances concurrency and availability since some non-SR execution schedules are permitted. For example, epsilon-transactions (ETs) that just perform queries may execute in spite of ongoing concurrent updates to the database. Thus, the query may view uncommitted, possibly inconsistent, data.
Reference: [35] <author> C. Pu, J.D. Noe, and Proudfoot. </author> <title> Regeneration of replicated object. </title> <booktitle> In IEEE Proceedings of the Snd International Conference on Data Engineering, </booktitle> <month> February </month> <year> 1986. </year>
Reference-contexts: If new replicas of the object can be created faster than a failure can be repaired, then better reliability can be achieved by creating new replicas on the available nodes in response to node failures. This technique is known as regeneration <ref> [35, 2] </ref>. Here, we have to care about number of copies all the time, whether sites crashed or recovered. If sites crash, we must check number of sites to decide whether to generate more copies or not.
Reference: [36] <author> Krithi Ramamritham and Calton Pu. </author> <title> A formal characterization of epsilon seri--alizability. </title> <journal> IEEE Transactions On Knowledge and Data Engineering, </journal> <volume> 7(6) </volume> <pages> 997-1007, </pages> <month> Decemebr </month> <year> 1995. </year>
Reference-contexts: Epsilon Serializability Epsilon serializability (ESR), a generalization of classic serializability (SR), explicitly allows some limited amount of inconsistency in transaction processing <ref> [36, 2, 34] </ref>. ESR enhances concurrency and availability since some non-SR execution schedules are permitted. For example, epsilon-transactions (ETs) that just perform queries may execute in spite of ongoing concurrent updates to the database. Thus, the query may view uncommitted, possibly inconsistent, data.
Reference: [37] <author> Daniel J. Rosenkrantz, Richard E. Stearns, and Philip M. Lewis II. </author> <title> System level concurrency control for distributed database systems. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 3(2) </volume> <pages> 178-198, </pages> <month> June </month> <year> 1978. </year>
Reference-contexts: The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information. Distributed Concurrency Control Concurrency control involves the synchronization of accesses to the distributed database, such that the integrity of the database is maintained. There are many techniques introduced <ref> [37, 10, 11, 24, 20] </ref>. They are all fall in either pessimistic class or optimistic class. The techniques used in their implementation fall in either locking class, or timestamping class. Distributed Deadlock Management The problems encounter in DDBMS are similar in nature as in operating systems.
Reference: [38] <author> Robert H. Thomas. </author> <title> A majority consensus approach to concurrency control for multiple copy databases. </title> <journal> ACM Transactions on Database System, </journal> <volume> 4(2), </volume> <month> June </month> <year> 1979. </year>
Reference-contexts: After ascertainment, the operation will be executed else it is aborted and restarted again. The variation between protocols in this class is the method of gathering the votes and how to resolve them. This technique was first mentioned by Robert H. Thomas <ref> [38] </ref> and D. K. Gifford [23]. The elegant feature of this class is the ability to work in either optimistic or pessimistic way. Also, the replication control is distributed among sites. 3.3.2 Pessimistic vs. Optimistic Protocols Most invented protocols are pessimistic in nature. <p> Planner protocols are subset from multi-dimensional one, but we classify them in a separate category due to their large number. 3.5.1 Linear Protocols Majority Consensus Protocol This protocol is introduced by Robert Thomas <ref> [38] </ref>. It was one of the first steps in decentralizing the replication control. Database sites vote on the acceptability of update requests. For a request to be accepted and applied to all database copies only majority are required. <p> The solution is to defer the voting until the first request is executed but consequently the possibility of deadlock is introduced. A similar solution mentioned in <ref> [38] </ref>. The site will vote with PASS if the current request conflicts with a pending request, else it will vote with OK. So the algorithm of the voting part is: 1. Compare the timestamps of the arriving request with that of the data. 38 2. <p> Vote REJ if the data is obsolete. 3. Vote Pass if the data is current and the request conflicts with other pending requests. 4. Otherwise, vote OK To simplify this solution, the site will never defer voting, which differs from that of Thomas <ref> [38] </ref> by cancelling the deferring process. 5.3 Resolution Part In order to demonstrate the resolution part, we will begin in the two-dimensional hypercube for simplicity. Then we will generalize it to three-dimensional one.
Reference: [39] <author> Robbert van Renesse and Andrew S. Tanenbaum. </author> <title> Voting with ghosts. </title> <booktitle> In In IEEE Proceedings of 8th International Conferenece on Distributed Computing System, </booktitle> <month> June </month> <year> 1988. </year>
Reference-contexts: So when quorums, whether reads or writes, are collected, the witnesses behave as other copies. This protocol has a single criterion: every quorum must contain at least one copy. Voting With Ghosts Voting with ghosts was first introduced by Van Renesse and Tanenbaum <ref> [39] </ref>. It uses QC protocol as its basis. One of the drawbacks of QC is: if one or more sites crash, 17 and the write quorum can no longer be acquired, the object will not be available for writing. This problem can be overcame by ghosts.
Reference: [40] <author> Bernd Walter and Erich J. Neuhold. Porel: </author> <title> A distributed database system. </title> <journal> IEEE Transactions on Computers, </journal> <year> 1984. </year>
Reference-contexts: This algorithm is similar in nature to two phase commit used in concurrency control. As usual, partitioned networks need special treatment. This protocol has a reduced availability when compared with other complex protocols. It is implemented in several distributed databases such as POREL <ref> [40] </ref>. 14 3.4.4 Directory-Oriented Available Copies Protocol The static assignment of copies to sites in the available copies algorithm of the previous section is a serious disadvantage. It requires, among other things, that transactions attempt to update copies at down sites.
Reference: [41] <author> Annita N. Wilschut, Jan Flokstra, and Peter M. G. Apers. </author> <title> Parallel evaluation of multi-join queries. </title> <booktitle> In Proceedings, ACM Sigmoid, </booktitle> <pages> pages 115-126, </pages> <year> 1995. </year>
Reference-contexts: If partitioning (fragmentation) is chosen, data can be distributed using vertical, horizontal, extended, or hybrid fragmentation. If replication is chosen, the choice is whether to fully or partially replicate data. Distributed Query Processing The problem is how to determine the nearly optimal strategy, <ref> [8, 41, 18, 22, 18] </ref>, for executing each query over the network. The obstacles for finding good solutions are communication costs, and lack of sufficient locally available information.
Reference: [42] <author> David D. Wright. </author> <title> On merging partitioned databases. </title> <booktitle> Sigmoid Record, </booktitle> <year> 1983. </year> <month> 77 </month>
Reference-contexts: Solutions to this problem fall in either two methods deterministic, or probabilistic. The former guarantees that conflicts are avoided. For example, in voting techniques, no partition may have the majority. The latter permits each partition to proceed with transactions then conflicts are resolved after healing the partitions <ref> [42] </ref>. 3.10.2 Detection of Mutual Inconsistency When the partitions of DDBS are healed, assuming probabilistic solutions mentioned in the previous section, a database is partitioned and each partition continue working. So inconsistencies are introduced. The problem begins after partitions merged. Somebody must detect the inconsistencies and repair it.
References-found: 42

