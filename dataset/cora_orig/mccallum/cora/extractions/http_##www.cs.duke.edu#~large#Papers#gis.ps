URL: http://www.cs.duke.edu/~large/Papers/gis.ps
Refering-URL: http://www.cs.duke.edu/~large/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Phone: 2  3  
Title: External-Memory Algorithms for Processing Line Segments in Geographic Information Systems (extended abstract)  
Author: Lars Arge ? Darren Erik Vengroff ?? and Jeffrey Scott Vitter ??? 
Address: Aarhus, Aarhus, Denmark  Providence, RI 02912, USA  Durham, NC 27708, USA  
Affiliation: 1 BRICS Department of Computer Science, University of  Department of Computer Science, Brown University,  Department of Computer Science, Duke University,  
Abstract: In the design of algorithms for large-scale applications it is essential to consider the problem of minimizing I/O communication. Geographical information systems (GIS) are good examples of such large-scale applications as they frequently handle huge amounts of spatial data. In this paper we develop efficient new external-memory algorithms for a number of important problems involving line segments in the plane, including trapezoid decomposition, batched planar point location, triangulation, red-blue line segment intersection reporting, and general line segment intersection reporting. In GIS systems, the first three problems are useful for rendering and modeling, and the latter two are frequently used for overlaying maps and extracting information from them.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. Aggarwal and J. S. Vitter. </author> <title> The input/output complexity of sorting and related problems. </title> <journal> Communications of the ACM, </journal> <volume> 31(9) </volume> <pages> 1116-1127, </pages> <month> Sept. </month> <year> 1988. </year>
Reference-contexts: from striping is thus M=DB rather than m, which works well when D is moderately sized as in current systems, but can cause loss of efficiency when D is very large. 1.2 Previous Results in I/O-Efficient Computation Early work on I/O algorithms concentrated on algorithms for sorting and permutation-related problems <ref> [1, 20, 21, 28] </ref>. External sorting requires fi (n log m n) I/Os, 1 which is the external-memory equivalent of the well-known fi (N log N ) time bound for sorting in internal memory.
Reference: 2. <author> D. S. Andrews, J. Snoeyink, J. Boritz, T. Chan, G. Denham, J. Harrison, and C. Zhu. </author> <title> Further comparisons of algorithms for geometric intersection problems. </title> <booktitle> In Proc. 6th Int'l. Symp. on Spatial Data Handling, </booktitle> <year> 1994. </year>
Reference-contexts: As mentioned, the red-blue line segment intersection problem is of special interest because it is an abstraction of the important map-overlay problem, which is the core of several vector-based GISs <ref> [2, 3, 22] </ref>. Our red-blue line segment intersection algorithm is optimal because the external-memory lower bound technique of [5] can be applied to the internal-memory lower bound of (N log N + T ) to get an (n log m n + t) I/O lower bound on the problem.
Reference: 3. <author> ARC/INFO. </author> <title> Understanding GIS|the ARC/INFO method. </title> <address> ARC/INFO, </address> <year> 1993. </year> <note> Rev. 6 for workstations. </note>
Reference-contexts: As mentioned, the red-blue line segment intersection problem is of special interest because it is an abstraction of the important map-overlay problem, which is the core of several vector-based GISs <ref> [2, 3, 22] </ref>. Our red-blue line segment intersection algorithm is optimal because the external-memory lower bound technique of [5] can be applied to the internal-memory lower bound of (N log N + T ) to get an (n log m n + t) I/O lower bound on the problem. <p> F A O (log m n) Fig. 2. An external-memory segment tree based on a buffer tree over a set of N seg ments, three of which, AB, CD, and EF , are shown. spans. Thus, CD is stored in <ref> [ 1 ; 3 ] </ref>. All segments that are not long are called short segments and are not stored in any multi-slab. Instead, they are passed down to lower levels of the tree where they may span recursively defined slabs and be stored.
Reference: 4. <author> L. Arge. </author> <title> The buffer tree: A new technique for optimal I/O-algorithms. </title> <booktitle> In Proc. of 4th Workshop on Algorithms and Data Structures, </booktitle> <year> 1995. </year>
Reference-contexts: Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [16] and graph problems [12]. In [5] a general connection between the comparison-complexity and the I/O complexity of a given problem is shown, and in <ref> [4] </ref> alternative solutions for some of the problems in [12] and [16] are derived by developing and using dynamic external-memory data structures. 1.3 Our Results In this paper, we combine and modify in novel ways several of the previously known techniques for designing efficient algorithms for external memory. <p> In particular we use the distribution sweeping and batched filtering paradigms of [16], the buffer tree data structure of <ref> [4] </ref>, and the deterministic distribution methods for parallel disks in [20]. 2 In addition we also develop a powerful new technique that can be regarded as a practical external-memory version of batched fractional cascading on an external-memory version of a segment tree. <p> To explicitly construct the trapezoids, we sort all trapezoid vertical segments by the IDs of the input segments they lie on, breaking ties by x coordinate. This takes O (n log m n) I/Os <ref> [4, 21] </ref>. Finally, we scan this sorted list, in which we find the two vertical edges of each trapezoid in adjacent positions. <p> The total amount of I/O used is thus O (n log m n). ut As described below, we solve EPD by building a data structure inspired by the buffer tree data structure of <ref> [4] </ref>. <p> Buffer Trees and External-Memory Segment Trees Buffer trees are data structures that can support the processing of a batch of N updates and K queries on an initially empty dynamic data structure of elements from a totally ordered set in O ((n + k) log m n + t) I/Os <ref> [4] </ref>. They can be used to implement sweepline algorithms in which the entire sequence of updates and queries is known in advance. <p> A segment tree stores a set of segments in one dimension. Given a query point, it returns the segments that contain the point. Such queries are called stabbing queries. An external-memory segment tree based on the approach in <ref> [4] </ref> is shown in Figure 2. The tree is perfectly balanced over the endpoints of the segments it represents and has branching factor p m=4. Each leaf represents M=2 consecutive segment endpoints. <p> Each leaf represents M=2 consecutive segment endpoints. The first level of the tree partitions the data into p m=4 slabs i , separated by dotted lines on Figure 2. Multi-slabs are defined as contiguous ranges of slabs, such as for example <ref> [ 1 ; 4 ] </ref>. There are m=8 + p m=4 multi-slabs. The key point is that the number of multi-slabs is a quadratic function of the branching factor. <p> Because of the size of the nodes and auxiliary multi-slab data, the buffer tree approach is inefficient for answering single queries. In batch dynamic environments, however, it can be used to develop optimal algorithms. In <ref> [4] </ref>, techniques are developed for using external-memory segment trees in a batch dynamic environment such that inserting N segments in the tree and performing K queries requires O ((n + k) log m n + t) I/Os. <p> In order to solve the EPD problem, we modify the external segment tree described above so that the segments fully spanning a given multi-slab are stored in y-order. This requires two significant improvements over existing techniques. First, as discussed in Section 2.2, the tree construction techniques of <ref> [4] </ref> must be modified in order to guarantee optimal performance when the tree is built. <p> An extended external segment tree is just an external segment tree as described in the last section built on non-intersecting segments, where the segments in each of the multi-slabs are sorted. In order to construct such a structure, we first use an optimal sorting algorithm <ref> [4, 21] </ref> to create a list of all the endpoints of the segments sorted by x-coordinate. This list is used during the whole algorithm to find the medians we use to split the interval associated with a given node into p m=4 vertical slabs. <p> Now as mentioned we cannot just sort the multi-slab lists in the case of intersecting segments. Instead we sort the lists according to left (or right) segment endpoint. The basic idea in our algorithm is now the following: We initialize one of the external-memory priority queues developed in <ref> [4] </ref> for each multi-slab list. Segments in these queues are sorted according to the order of the their endpoint on one of the boundaries the queue corresponds to, and the queues are structured so that a delete-min operation returns the topmost segment. <p> As the number of operations done on the queues is O (T ), the following lemma follows from the O ((log m n)=B) I/O bound on the insert and delete-min operations proven in <ref> [4] </ref>. Lemma 10. An extended external segment tree can be constructed on intersecting segments in O ((n + t) log m n) I/O operations, where T = B t is the number of inconsistencies (intersections) removed (reported). Filtering queries through the structure.
Reference: 5. <author> L. Arge, M. Knudsen, and K. Larsen. </author> <title> A general lower bound on the I/O-complexity of comparison-based algorithms. </title> <booktitle> In Proc. of 3rd Workshop on Algorithms and Data Structures, </booktitle> <volume> LNCS 709, </volume> <pages> pages 83-94, </pages> <year> 1993. </year>
Reference-contexts: More recently researchers have designed external-memory algorithms for a number of problems in different areas. 1 We define for convenience log m n = maxf1; (log n)= log mg. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [16] and graph problems [12]. In <ref> [5] </ref> a general connection between the comparison-complexity and the I/O complexity of a given problem is shown, and in [4] alternative solutions for some of the problems in [12] and [16] are derived by developing and using dynamic external-memory data structures. 1.3 Our Results In this paper, we combine and modify <p> As mentioned, the red-blue line segment intersection problem is of special interest because it is an abstraction of the important map-overlay problem, which is the core of several vector-based GISs [2, 3, 22]. Our red-blue line segment intersection algorithm is optimal because the external-memory lower bound technique of <ref> [5] </ref> can be applied to the internal-memory lower bound of (N log N + T ) to get an (n log m n + t) I/O lower bound on the problem.
Reference: 6. <author> T. M. Chan. </author> <title> A simple trapezoid sweep algorithm for reporting red/blue segment intersections. </title> <booktitle> In Proc. 6th Can. Conf. Comp. Geom., </booktitle> <year> 1994. </year>
Reference-contexts: Although a time-optimal internal-memory algorithm for the general intersection problem exists [8], a number of simpler solutions have been presented for the red-blue problem <ref> [6, 9, 19, 22] </ref>. Two of these algorithms [9, 22] are not plane-sweep algorithms, but both sort segments of the same color in a preprocessing step with a plane-sweep algorithm.
Reference: 7. <author> B. Chazelle. </author> <title> Triangulating a simple polygon in linear time. </title> <booktitle> In Proc. IEEE Foundation of Comp. Sci., </booktitle> <year> 1990. </year>
Reference-contexts: Such modifications lead to algorithms using O (N log B n) I/Os. For two of the algorithms the known optimal internal-memory algorithms <ref> [7, 8] </ref> are not plane-sweep algorithms 2 For brevity in this extended abstract, we restrict discussion to the one-disk model where D = 1. In the full version of this paper, we show how to use techniques from [20] to extend our results to the general D &gt; 1 model.
Reference: 8. <author> B. Chazelle and H. Edelsbrunner. </author> <title> An optimal algorithm for intersecting line segments in the plane. </title> <journal> JACM, </journal> <volume> 39 </volume> <pages> 1-54, </pages> <year> 1992. </year>
Reference-contexts: Such modifications lead to algorithms using O (N log B n) I/Os. For two of the algorithms the known optimal internal-memory algorithms <ref> [7, 8] </ref> are not plane-sweep algorithms 2 For brevity in this extended abstract, we restrict discussion to the one-disk model where D = 1. In the full version of this paper, we show how to use techniques from [20] to extend our results to the general D &gt; 1 model. <p> Although a time-optimal internal-memory algorithm for the general intersection problem exists <ref> [8] </ref>, a number of simpler solutions have been presented for the red-blue problem [6, 9, 19, 22]. Two of these algorithms [9, 22] are not plane-sweep algorithms, but both sort segments of the same color in a preprocessing step with a plane-sweep algorithm.
Reference: 9. <author> B. Chazelle, H. Edelsbrunner, L. J. Guibas, and M. Sharir. </author> <title> Algorithms for bichro--matic line-segment problems and polyhedral terrains. </title> <journal> Algorithmica, </journal> <volume> 11 </volume> <pages> 116-132, </pages> <year> 1994. </year>
Reference-contexts: Although a time-optimal internal-memory algorithm for the general intersection problem exists [8], a number of simpler solutions have been presented for the red-blue problem <ref> [6, 9, 19, 22] </ref>. Two of these algorithms [9, 22] are not plane-sweep algorithms, but both sort segments of the same color in a preprocessing step with a plane-sweep algorithm. <p> Although a time-optimal internal-memory algorithm for the general intersection problem exists [8], a number of simpler solutions have been presented for the red-blue problem [6, 9, 19, 22]. Two of these algorithms <ref> [9, 22] </ref> are not plane-sweep algorithms, but both sort segments of the same color in a preprocessing step with a plane-sweep algorithm. The authors of [22] claim that their algorithm will perform well with inadequate internal memory owing to the fact that data are mostly referenced sequentially. <p> To solve the first problem, we will take advantage of the internal memory that is available to us. The second problem is solved with a notion similar to fractional cascading <ref> [9, 10, 26] </ref>. The idea behind fractional cascading on internal-memory segment trees is that instead of searching for the same element in a number of sorted lists, we augment the list at a node with sample elements from lists at the node's children.
Reference: 10. <author> B. Chazelle and L. J. Guibas. Fractional cascading: I. </author> <title> a data structuring technique. </title> <journal> Algorithmica, </journal> <volume> 1 </volume> <pages> 133-162, </pages> <year> 1986. </year>
Reference-contexts: First, as discussed in Section 2.2, the tree construction techniques of [4] must be modified in order to guarantee optimal performance when the tree is built. Second, as discussed in Section 2.3 the batch filtering procedure must be augmented using techniques similar to fractional cascading <ref> [10] </ref>. 2.2 Constructing Extended External Segment Trees We will construct what we call an extended external segment tree using an approach based on distribution sweeping [16]. <p> To solve the first problem, we will take advantage of the internal memory that is available to us. The second problem is solved with a notion similar to fractional cascading <ref> [9, 10, 26] </ref>. The idea behind fractional cascading on internal-memory segment trees is that instead of searching for the same element in a number of sorted lists, we augment the list at a node with sample elements from lists at the node's children.
Reference: 11. <author> Y.-J. Chiang. </author> <title> Experiments on the practical I/O efficiency of geometric algorithms: Distribution sweep vs. plane sweep. </title> <booktitle> In Proc of 4th Workshop on Algorithms and Data Structures, </booktitle> <year> 1995. </year>
Reference-contexts: In most cases, these modified algorithms are plane-sweep algorithms modified to use B-tree-based dynamic data structures rather than binary tree-based dynamic data structures, following the example of a class of algorithms studied experimentally in <ref> [11] </ref>. Such modifications lead to algorithms using O (N log B n) I/Os. For two of the algorithms the known optimal internal-memory algorithms [7, 8] are not plane-sweep algorithms 2 For brevity in this extended abstract, we restrict discussion to the one-disk model where D = 1.
Reference: 12. <author> Y.-J. Chiang, M. T. Goodrich, E. F. Grove, R. Tamassia, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory graph algorithms. </title> <booktitle> In Proc. ACM-SIAM Symp. on Discrete Alg., </booktitle> <pages> pages 139-149, </pages> <month> Jan. </month> <year> 1995. </year>
Reference-contexts: More recently researchers have designed external-memory algorithms for a number of problems in different areas. 1 We define for convenience log m n = maxf1; (log n)= log mg. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [16] and graph problems <ref> [12] </ref>. In [5] a general connection between the comparison-complexity and the I/O complexity of a given problem is shown, and in [4] alternative solutions for some of the problems in [12] and [16] are derived by developing and using dynamic external-memory data structures. 1.3 Our Results In this paper, we combine <p> Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [16] and graph problems <ref> [12] </ref>. In [5] a general connection between the comparison-complexity and the I/O complexity of a given problem is shown, and in [4] alternative solutions for some of the problems in [12] and [16] are derived by developing and using dynamic external-memory data structures. 1.3 Our Results In this paper, we combine and modify in novel ways several of the previously known techniques for designing efficient algorithms for external memory. <p> To sort the segments we simply have to topologically sort G. As G is a planar s,t-graph of size O (N ) this can be done in O (n log m n) I/Os using an algorithm of <ref> [12] </ref>. Lemma 8.
Reference: 13. <author> R. F. Cromp. </author> <title> An intellegent information fusion system for handling the archiving and querying of terabyte-sized spatial databases. </title> <editor> In S. R. Tate ed., </editor> <title> Report on the Workshop on Data and Image Compression Needs and Uses in the Scientific Community, </title> <type> CESDIS Technical Report Series, </type> <month> TR-93-99, </month> <pages> pages 75-84, </pages> <year> 1993. </year>
Reference-contexts: In support of these applications, GIS systems store, manipulate, and search through enormous amounts of spatial data <ref> [13, 18, 25, 27] </ref>. <p> In support of these applications, GIS systems store, manipulate, and search through enormous amounts of spatial data [13, 18, 25, 27]. NASA's EOS project GIS system <ref> [13] </ref>, for example, is expected to manipulate petabytes (thousands of terabytes, or millions of gigabytes) of data! Typical subproblems that need to be solved in GIS systems include point location, triangulating maps, generating contours from triangulated elevation data, and producing map overlays, all of which require manipulation of line segments.
Reference: 14. <author> H. Edelsbrunner and M. H. Overmars. </author> <title> Batched dynamic solutions to decomposable searching problems. </title> <journal> Journal of Algorithms, </journal> <volume> 6 </volume> <pages> 515-542, </pages> <year> 1985. </year>
Reference-contexts: The queries that such sweepline algorithms ask of their dynamic data structures need not be answered in any particular order; the only requirement on the queries is that they must all eventually be answered. Such problems are known as batch dynamic problems <ref> [14] </ref>. For the problems we are considering in this paper, the known internal-memory solutions cannot be stated as batched dynamic algorithms (since the updates depend on the queries) or else the elements involved are not totally ordered. We are led instead to other approaches.
Reference: 15. <author> A. Fournier and D. Y. Montuno. </author> <title> Triangulating simple polygons and equivalent problems. </title> <journal> ACM Trans. on Graphics, </journal> <volume> 3(2) </volume> <pages> 153-174, </pages> <year> 1984. </year>
Reference-contexts: The multi-point planar point location problem can be solved using O ((n + k) log m n) I/O operations. After computing the trapezoid decomposition of a simple polygon, the polygon can be triangulated in O (n) I/Os using a slightly modified version of an algorithm from <ref> [15] </ref>: Lemma 7.
Reference: 16. <author> M. T. Goodrich, J.-J. Tsay, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory computational geometry. </title> <booktitle> In Proc. of IEEE Foundations of Comp. Sci., </booktitle> <pages> pages 714-723, </pages> <month> Nov. </month> <year> 1993. </year>
Reference-contexts: More recently researchers have designed external-memory algorithms for a number of problems in different areas. 1 We define for convenience log m n = maxf1; (log n)= log mg. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry <ref> [16] </ref> and graph problems [12]. In [5] a general connection between the comparison-complexity and the I/O complexity of a given problem is shown, and in [4] alternative solutions for some of the problems in [12] and [16] are derived by developing and using dynamic external-memory data structures. 1.3 Our Results In <p> Most notably I/O-efficient algorithms have been developed for a large number of computational geometry <ref> [16] </ref> and graph problems [12]. In [5] a general connection between the comparison-complexity and the I/O complexity of a given problem is shown, and in [4] alternative solutions for some of the problems in [12] and [16] are derived by developing and using dynamic external-memory data structures. 1.3 Our Results In this paper, we combine and modify in novel ways several of the previously known techniques for designing efficient algorithms for external memory. In particular we use the distribution sweeping and batched filtering paradigms of [16], the <p> and <ref> [16] </ref> are derived by developing and using dynamic external-memory data structures. 1.3 Our Results In this paper, we combine and modify in novel ways several of the previously known techniques for designing efficient algorithms for external memory. In particular we use the distribution sweeping and batched filtering paradigms of [16], the buffer tree data structure of [4], and the deterministic distribution methods for parallel disks in [20]. 2 In addition we also develop a powerful new technique that can be regarded as a practical external-memory version of batched fractional cascading on an external-memory version of a segment tree. <p> This enables us to improve on existing external-memory algorithms as well as to develop new algorithms and thus partially answer some open problems posed in <ref> [16] </ref>. In Section 2 we introduce the endpoint dominance problem, which is a sub-problem of trapezoid decomposition. We introduce an O (n log m n)-I/O algorithm to solve the endpoint dominance problem, and we use it to develop an algorithm with the same asymptotic I/O complexity for trapezoid decomposition. <p> Our results are summarized in Table 1. For all but the batched planar point location problem, no algorithms specifically designed for external memory were previously known. The batched planar point location algorithm that was previously known <ref> [16] </ref> only works when the planar subdivision is monotone, and the problems of triangulating a simple polygon and reporting intersections between other than orthogonal line segments are stated as open problems in [16]. <p> The batched planar point location algorithm that was previously known <ref> [16] </ref> only works when the planar subdivision is monotone, and the problems of triangulating a simple polygon and reporting intersections between other than orthogonal line segments are stated as open problems in [16]. For the sake of contrast, our results are also compared with modified internal-memory algorithms for the same problems. <p> In applications like EPD, where it is possible to process all N updates and then process all K queries, the technique reduces to batch filtering <ref> [16] </ref>, in which we push all queries through a given level of the tree before moving on to the next level. In order to solve the EPD problem, we modify the external segment tree described above so that the segments fully spanning a given multi-slab are stored in y-order. <p> Second, as discussed in Section 2.3 the batch filtering procedure must be augmented using techniques similar to fractional cascading [10]. 2.2 Constructing Extended External Segment Trees We will construct what we call an extended external segment tree using an approach based on distribution sweeping <ref> [16] </ref>. When we are building an external segment tree on non-intersecting segments in the plane we can talk about the order of segments in the same multi-slab just by comparing the order of their endpoints on one of the boundaries. <p> All K queries can be processed through the tree at once using batch filtering <ref> [16] </ref>. Unfortunately, the simple approach outlined in the preceding paragraph is not efficient. There are two problems that have to be dealt with. First, we must be able to look for a query point in many of the multi-slabs lists corresponding to a given node simultaneously. <p> The multi-point planar point location problem is the problem of reporting the location of K query points in a planar subdivision defined by N line segments. In <ref> [16] </ref> an O ((n+k) log m n)-I/O algorithm for this problem is given for monotone subdivisions of the plane. This result can be extended to arbitrary subdivisions using the algorithm developed in the previous section. Theorem 4 immediately implies the following: Lemma 6. <p> non-intersecting segments can be found in O (n log m n) I/Os. 4.1 Red-Blue Line Segment Intersection Using our ability to sort segments as described in the previous section, we can solve the red-blue line segment intersection in the optimal number of I/Os using a technique based on distribution sweeping <ref> [16] </ref>. Given input sets S r of red segments and S b of blue segments, we construct two intermediate sets T r and T b consisting of the red segments and the blue endpoints, and the blue segments and the red endpoints, respectively. <p> We sort both T r and T b in O (n log m n) I/Os using the algorithm from the previous section, and from now on we assume they are sorted. We now locate segment intersections by distribution sweeping <ref> [16] </ref> with a branching factor of p m. The structure of distribution sweeping is that we divide the plane into p m slabs, not unlike the way the plane was divided into slabs to build an external segments tree in Section 2.1. <p> Because T r and T b are sorted, we can locate interactions between long and short segments (both original and new short segments produced by cutting long segments) using a slightly modified version of the distribution-sweeping algorithm for solving orthogonal segment intersection <ref> [16] </ref>. We use the modified algorithm twice and treat long segments of one color as horizontal segments and short segments of the other color as vertical segments. Just as in the orthogonal case, all intersections are located and reported in O (n + t i ) I/Os.
Reference: 17. <author> L. M. Haas and W. F. Cody. </author> <title> Exploiting extensible dbms in integrated geographic information systems. </title> <booktitle> In Proc. of Advances in Spatial Databases, LNCS 525, </booktitle> <year> 1991. </year>
Reference-contexts: GIS systems are used for scientific applications such as environmental impact, wildlife repopulation, epidemiologic analysis, and earthquake studies and for commercial applications such as market analysis, utility facilities distribution, and mineral exploration <ref> [17] </ref>. In support of these applications, GIS systems store, manipulate, and search through enormous amounts of spatial data [13, 18, 25, 27].
Reference: 18. <author> R. Laurini and A. D. Thompson. </author> <title> Fundamentals of Spatial Information Systems. A.P.I.C. Series, </title> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: In support of these applications, GIS systems store, manipulate, and search through enormous amounts of spatial data <ref> [13, 18, 25, 27] </ref>.
Reference: 19. <author> H. G. Mairson and J. Stolfi. </author> <title> Reporting and counting intersections between two sets of line segments. </title> <editor> In R. Earnshaw (ed.), </editor> <booktitle> Theoretical Foundation of Computer Graphics and CAD, NATO ASI Series, </booktitle> <volume> Vol. F40, </volume> <pages> pages 307-326, </pages> <year> 1988. </year>
Reference-contexts: Although a time-optimal internal-memory algorithm for the general intersection problem exists [8], a number of simpler solutions have been presented for the red-blue problem <ref> [6, 9, 19, 22] </ref>. Two of these algorithms [9, 22] are not plane-sweep algorithms, but both sort segments of the same color in a preprocessing step with a plane-sweep algorithm.
Reference: 20. <author> M. H. Nodine and J. S. Vitter. </author> <title> Large-scale sorting in parallel memories. </title> <booktitle> In Proc. of 3rd Annual ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 29-39, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: from striping is thus M=DB rather than m, which works well when D is moderately sized as in current systems, but can cause loss of efficiency when D is very large. 1.2 Previous Results in I/O-Efficient Computation Early work on I/O algorithms concentrated on algorithms for sorting and permutation-related problems <ref> [1, 20, 21, 28] </ref>. External sorting requires fi (n log m n) I/Os, 1 which is the external-memory equivalent of the well-known fi (N log N ) time bound for sorting in internal memory. <p> In particular we use the distribution sweeping and batched filtering paradigms of [16], the buffer tree data structure of [4], and the deterministic distribution methods for parallel disks in <ref> [20] </ref>. 2 In addition we also develop a powerful new technique that can be regarded as a practical external-memory version of batched fractional cascading on an external-memory version of a segment tree. <p> For two of the algorithms the known optimal internal-memory algorithms [7, 8] are not plane-sweep algorithms 2 For brevity in this extended abstract, we restrict discussion to the one-disk model where D = 1. In the full version of this paper, we show how to use techniques from <ref> [20] </ref> to extend our results to the general D &gt; 1 model. Problem I/O bound of Result using modified new result internal memory algorithm Endpoint dominance. O (n log m n) O (N log B n) Trapezoid decomposition.
Reference: 21. <author> M. H. Nodine and J. S. Vitter. </author> <title> Deterministic distribution sort in shared and distributed memory multiprocessors. </title> <booktitle> In Proc. 5th ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 120-129, </pages> <month> June-July </month> <year> 1993. </year>
Reference-contexts: from striping is thus M=DB rather than m, which works well when D is moderately sized as in current systems, but can cause loss of efficiency when D is very large. 1.2 Previous Results in I/O-Efficient Computation Early work on I/O algorithms concentrated on algorithms for sorting and permutation-related problems <ref> [1, 20, 21, 28] </ref>. External sorting requires fi (n log m n) I/Os, 1 which is the external-memory equivalent of the well-known fi (N log N ) time bound for sorting in internal memory. <p> To explicitly construct the trapezoids, we sort all trapezoid vertical segments by the IDs of the input segments they lie on, breaking ties by x coordinate. This takes O (n log m n) I/Os <ref> [4, 21] </ref>. Finally, we scan this sorted list, in which we find the two vertical edges of each trapezoid in adjacent positions. <p> An extended external segment tree is just an external segment tree as described in the last section built on non-intersecting segments, where the segments in each of the multi-slabs are sorted. In order to construct such a structure, we first use an optimal sorting algorithm <ref> [4, 21] </ref> to create a list of all the endpoints of the segments sorted by x-coordinate. This list is used during the whole algorithm to find the medians we use to split the interval associated with a given node into p m=4 vertical slabs.
Reference: 22. <author> L. Palazzi and J. Snoeyink. </author> <title> Counting and reporting red/blue segment intersections. </title> <booktitle> In Proc. of 3th Workshop on Algorithms and Data Structures, </booktitle> <volume> LNCS 709, </volume> <pages> pages 530-540, </pages> <year> 1993. </year>
Reference-contexts: As mentioned, the red-blue line segment intersection problem is of special interest because it is an abstraction of the important map-overlay problem, which is the core of several vector-based GISs <ref> [2, 3, 22] </ref>. Our red-blue line segment intersection algorithm is optimal because the external-memory lower bound technique of [5] can be applied to the internal-memory lower bound of (N log N + T ) to get an (n log m n + t) I/O lower bound on the problem. <p> Although a time-optimal internal-memory algorithm for the general intersection problem exists [8], a number of simpler solutions have been presented for the red-blue problem <ref> [6, 9, 19, 22] </ref>. Two of these algorithms [9, 22] are not plane-sweep algorithms, but both sort segments of the same color in a preprocessing step with a plane-sweep algorithm. <p> Although a time-optimal internal-memory algorithm for the general intersection problem exists [8], a number of simpler solutions have been presented for the red-blue problem [6, 9, 19, 22]. Two of these algorithms <ref> [9, 22] </ref> are not plane-sweep algorithms, but both sort segments of the same color in a preprocessing step with a plane-sweep algorithm. The authors of [22] claim that their algorithm will perform well with inadequate internal memory owing to the fact that data are mostly referenced sequentially. <p> Two of these algorithms [9, 22] are not plane-sweep algorithms, but both sort segments of the same color in a preprocessing step with a plane-sweep algorithm. The authors of <ref> [22] </ref> claim that their algorithm will perform well with inadequate internal memory owing to the fact that data are mostly referenced sequentially.
Reference: 23. <author> Y. N. Patt. </author> <title> The I/O subsystem|a candidate for improvement. </title> <editor> Guest Editor's Introduction in IEEE Comp., </editor> <volume> 27(3) </volume> <pages> 15-16, </pages> <year> 1994. </year>
Reference-contexts: 1 Introduction The Input/Output communication between fast internal memory and slower external storage is the bottleneck in many large-scale applications. The significance of this bottleneck is increasing as internal computation gets faster, and especially as parallel computing gains popularity <ref> [23] </ref>. Currently, technological advances are increasing CPU speeds at an annual rate of 40-60% while disk transfer rates are only increasing by 7-10% annually [24].
Reference: 24. <author> C. Ruemmler and J. Wilkes. </author> <title> An introduction to disk drive modeling. </title> <journal> IEEE Comp., </journal> <volume> 27(3) </volume> <pages> 17-28, </pages> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: The significance of this bottleneck is increasing as internal computation gets faster, and especially as parallel computing gains popularity [23]. Currently, technological advances are increasing CPU speeds at an annual rate of 40-60% while disk transfer rates are only increasing by 7-10% annually <ref> [24] </ref>. Internal memory sizes are also increasing, but not nearly fast enough to meet the needs of important ? Supported in part by the ESPRIT II Basic Research Actions Program of the EC under contract No. 7141 (Project ALCOM II).
Reference: 25. <author> H. Samet. </author> <title> Applications of Spatial Data Structures: Computer Graphics, Image Processing, and GIS. </title> <publisher> Addison Wesley, </publisher> <address> MA, </address> <year> 1989. </year>
Reference-contexts: In support of these applications, GIS systems store, manipulate, and search through enormous amounts of spatial data <ref> [13, 18, 25, 27] </ref>.
Reference: 26. <author> V. K. Vaishnavi and D. Wood. </author> <title> Rectilinear line segment intersection, layered segment trees, </title> <journal> and dynamization. Journal of Algorithms, </journal> <volume> 3 </volume> <pages> 160-176, </pages> <year> 1982. </year>
Reference-contexts: To solve the first problem, we will take advantage of the internal memory that is available to us. The second problem is solved with a notion similar to fractional cascading <ref> [9, 10, 26] </ref>. The idea behind fractional cascading on internal-memory segment trees is that instead of searching for the same element in a number of sorted lists, we augment the list at a node with sample elements from lists at the node's children.
Reference: 27. <author> M. J. van Kreveld. </author> <title> Geographic information systems. </title> <type> Technical Report INF/DOC-95-01, </type> <institution> Utrecht University, </institution> <year> 1995. </year>
Reference-contexts: In support of these applications, GIS systems store, manipulate, and search through enormous amounts of spatial data <ref> [13, 18, 25, 27] </ref>. <p> As an illustration, the computation of new scenes or maps from existing information|also called map overlaying|is an important GIS operation. Some existing software packages are completely based on this operation <ref> [27] </ref>. Given two thematic maps (piecewise linear maps with, e.g., indications of lakes, roads, pollution level), the problem is to compute a new map in which the thematic attributes of each location is a function of the thematic attributes of the corresponding locations in the two input maps.
Reference: 28. <author> J. S. Vitter and E. A. M. Shriver. </author> <title> Algorithms for parallel memory, I: Two-level memories. </title> <journal> Algorithmica, </journal> <volume> 12(2-3):110-147, </volume> <year> 1994. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Values of D range up to 10 2 in current disk arrays. Large-scale problem instances can be in the range N = 10 10 to N = 10 12 . In order to study the performance of external-memory algorithms, we use the standard notion of I/O complexity <ref> [28] </ref>. We define an input/output operation (or simply I/O for short) to be the process of simultaneously reading or writing D blocks of data, one block to or from each of the D disks. The I/O complexity of an algorithm is simply the number of I/Os it performs. <p> For convenience we also define m = B which is the optimal degree of recursion or branching used in efficient external-memory algorithms. Note that there is no D term in the denominator of the definition of the branching factor m. Use of "striping" <ref> [28] </ref> corresponds to treating the D disks conceptually as one disk with a larger block size of DB; the resulting branching factor from striping is thus M=DB rather than m, which works well when D is moderately sized as in current systems, but can cause loss of efficiency when D is <p> from striping is thus M=DB rather than m, which works well when D is moderately sized as in current systems, but can cause loss of efficiency when D is very large. 1.2 Previous Results in I/O-Efficient Computation Early work on I/O algorithms concentrated on algorithms for sorting and permutation-related problems <ref> [1, 20, 21, 28] </ref>. External sorting requires fi (n log m n) I/Os, 1 which is the external-memory equivalent of the well-known fi (N log N ) time bound for sorting in internal memory.
References-found: 28

