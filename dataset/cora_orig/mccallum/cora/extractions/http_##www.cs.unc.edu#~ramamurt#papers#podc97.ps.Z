URL: http://www.cs.unc.edu/~ramamurt/papers/podc97.ps.Z
Refering-URL: http://www.cs.unc.edu/~ramamurt/papers.html
Root-URL: http://www.cs.unc.edu
Title: Implementing Wait-Free Objects on Priority-Based Systems (Extended Abstract)  
Author: James H. Anderson, Srikanth Ramamurthy, and Rohit Jain 
Address: Chapel Hill  
Affiliation: Department of Computer Science, University of North Carolina at  
Abstract: Wait-free objects are often implemented through the use of a helping scheme, whereby one process helps one or more other processes to complete an operation. This paper presents several new helping schemes that can be generally applied to efficiently implement a variety of different objects on priority-based uniprocessor and multiprocessor systems. Examples of such systems include lock-free multiprocessor kernels and real-time systems. Our helping schemes reduce overhead by exploiting the way in which processes are scheduled for execution in priority-based systems. We illustrate the use of these schemes by presenting wait-free implementations of linked lists and a multi-word compare-and-swap primitive. Performance results are presented that show that on priority-based systems our object implementations are an improvement over implementations developed previously for asynchronous systems.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> Universal Constructions for Multi-Object Operations, </title> <booktitle> Proc. of the 14th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 184-193. </pages>
Reference-contexts: Before a process is allowed to do this, however, it must first help any previously announced operation (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per process <ref> [1, 2, 8] </ref>. In addition, with incremental helping, each process helps at most one other process, while in helping schemes for asynchronous systems, each process helps all other processes in the worst case. In the second part of the paper, we consider the implementation of wait-free objects on priority-based multiprocessors. <p> Process q detects that p's operation is complete, so it announces its own operation, executes it, and relinquishes the processor to p. Process p detects that its operation has been completed, so it returns. and 68040 processors). Algorithms for implementing CAS2 are known <ref> [1, 4, 9] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton [6], but no current machines support this implementation. <p> However, while ensuring parallelism in this context is of theoretical importance, practical algorithms that are disjoint access parallel have remained elusive. Indeed, if existing algorithms are any indication <ref> [1, 4, 9] </ref>, disjoint access parallelism, while improving best-case complexity, results in enormous worst-case complexity. In our multiprocessor MWCAS implementation, a W -word MWCAS operation on P processors requires O (P W ) time. When considering multiprocessor workstations, it is reasonable to consider P to be a constant. <p> However, if this phase is successful i.e., Status [r] is 4 val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Status [3]: 0 Save <ref> [3; 1] </ref>: 22 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val count valid pid x: <p> 3 true 4 Val (z) = 8 Status [3]: 0 Save <ref> [3; 1] </ref>: 22 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: <p> Val (z) = 17 Status [3]: 1 Save <ref> [3; 1] </ref>: 22 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status <p> Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save <ref> [4; 1] </ref>: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) of <p> [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save <ref> [3; 1] </ref>: 22 Status [4]: 1 (d) of relevant shared variables are shown (a) at the beginning of the operation; (b) after the loop in lines 3..14; (c) at the end of the operation, assuming success; and (d) at the end of the operation, assuming failure on word z. <p> Insets (e) and (f) show the operation interleavings corresponding to insets (c) and (d), respectively. 2 Our uniprocessor MWCAS implementation is disjoint access parallel [9] and is much simpler and more efficient than previous 5 disjoint access parallel algorithms for asynchronous systems <ref> [1, 4, 9] </ref>. One disadvantage of our implementation is that certain bits within each accessed word must be reserved for control information (the count, valid, and pid fields). The multiprocessor implementation of Section 3.1 does not require such control information and could be applied within a uniprocessor system. <p> With this scheme, each read requires time proportional to 2 T . The implementation described in this subsection is obviously not disjoint access parallel [9], but is much simpler and more efficient than implementations that are <ref> [1, 4, 9] </ref>. Some limited degree of disjoint access parallelism could be achieved with our implementation by using a separate version counter for each set of MWCAS operations that may potentially transitively conflict. 3.2 Linked Lists Our linked-list implementation for multiprocessors is shown in Figure 8.
Reference: [2] <author> J. Anderson and M. Moir, </author> <title> Universal Constructions for Large Objects, </title> <booktitle> Proc. of the Ninth International Workshop on Distributed Algorithms, Lecture Notes in Computer Science 972, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995, </year> <pages> pp. 168-182. </pages>
Reference-contexts: Before a process is allowed to do this, however, it must first help any previously announced operation (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per process <ref> [1, 2, 8] </ref>. In addition, with incremental helping, each process helps at most one other process, while in helping schemes for asynchronous systems, each process helps all other processes in the worst case. In the second part of the paper, we consider the implementation of wait-free objects on priority-based multiprocessors. <p> As mentioned above, we make use of incremental helping in our multiprocessor implementations. In addition, we use two other new techniques, which we call cyclic helping and priority helping, respectively. The notion of cyclic helping is adapted from previous work of Anderson and Moir <ref> [2] </ref>. In this scheme, the processors are thought of as if they were part of a logical ring. Processes are helped through the use of a help counter, which cycles around the ring. <p> val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save <ref> [4; 2] </ref>: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) of relevant shared variables are <p> With wait-free algorithms, worst-case execution times are easily computed. The only other means of implementing wait-free linked lists that we know of is to use universal constructions <ref> [2, 8] </ref>. Although we did not test against such constructions, they entail moderate to high copying overhead.
Reference: [3] <author> J. Anderson and S. Ramamurthy, </author> <title> A Framework for Implementing Objects and Scheduling Tasks in Lock-Free Real-Time Systems, </title> <booktitle> Proc. of the 17th IEEE Real-Time Systems Symposium, </booktitle> <year> 1996, </year> <pages> pp. 94-105. </pages>
Reference-contexts: T is the worst-case time for a list operation. The constant 2 is used in the Q notation to more accurately reflect the cost of helping. Anderson and Ramamurthy <ref> [3] </ref>. Anderson and Ramamurthy's implementation is not strictly faithful to the semantics of MWCAS. In particular, it allows a MWCAS operation to fail if it is overlapped by another MWCAS operation that accesses a common word. <p> In particular, it allows a MWCAS operation to fail if it is overlapped by another MWCAS operation that accesses a common word. For the case in which the overlapping operation itself fails, it may be impossible to correctly linearize the operations in accordance with the semantics of MWCAS (see <ref> [3] </ref> for details). 2 In the implementation presented here, this problem is corrected. After considering MWCAS, we present an implementation of linked lists for priority-based uniprocessor systems. Our list implementation is based on a novel technique, which we call incremental helping. <p> However, if this phase is successful i.e., Status [r] is 4 val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Status <ref> [3] </ref>: 0 Save [3; 1]: 22 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val count <p> However, if this phase is successful i.e., Status [r] is 4 val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 8 3 true 4 Val (z) = 8 Status [3]: 0 Save <ref> [3; 1] </ref>: 22 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val count valid pid x: <p> 22 z: 8 3 true 4 Val (z) = 8 Status <ref> [3] </ref>: 0 Save [3; 1]: 22 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 <p> 3 true 4 Val (z) = 8 Status [3]: 0 Save <ref> [3; 1] </ref>: 22 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: <p> 0 true 4 Val (z) = 17 Status <ref> [3] </ref>: 1 Save [3; 1]: 22 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) <p> Val (z) = 17 Status [3]: 1 Save <ref> [3; 1] </ref>: 22 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status <p> 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status <ref> [3] </ref>: 0 Save [3; 1]: 22 Status [4]: 1 (d) of relevant shared variables are shown (a) at the beginning of the operation; (b) after the loop in lines 3..14; (c) at the end of the operation, assuming success; and (d) at the end of the operation, assuming failure on word <p> [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save <ref> [3; 1] </ref>: 22 Status [4]: 1 (d) of relevant shared variables are shown (a) at the beginning of the operation; (b) after the loop in lines 3..14; (c) at the end of the operation, assuming success; and (d) at the end of the operation, assuming failure on word z. <p> The current value of each word is now the desired new value, and all valid fields are true (so the value of Status [4] is no longer relevant). Before returning, process 4 updates Status <ref> [3] </ref> (line 19 of Figure 4) to indicate that process 3 (which must be of lower priority) has been interfered with. Inset (d) shows relevant variables at the termination of m, assuming an interference on word z by process 9 (which must be of higher-priority) with new value 56. <p> Inset (d) shows relevant variables at the termination of m, assuming an interference on word z by process 9 (which must be of higher-priority) with new value 56. Status [4] is now 1, indicating the failure of process 4's operation. Status <ref> [3] </ref> is left unchanged in this case. Observe that process 4 has successfully restored the original values of words x and y.
Reference: [4] <author> H. Attiya and E. Dagan, </author> <title> Universal Operations: Unary versus Binary, </title> <booktitle> Proc. of the 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1996, </year> <pages> pp. 223-232. 11 </pages>
Reference-contexts: Process q detects that p's operation is complete, so it announces its own operation, executes it, and relinquishes the processor to p. Process p detects that its operation has been completed, so it returns. and 68040 processors). Algorithms for implementing CAS2 are known <ref> [1, 4, 9] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton [6], but no current machines support this implementation. <p> However, while ensuring parallelism in this context is of theoretical importance, practical algorithms that are disjoint access parallel have remained elusive. Indeed, if existing algorithms are any indication <ref> [1, 4, 9] </ref>, disjoint access parallelism, while improving best-case complexity, results in enormous worst-case complexity. In our multiprocessor MWCAS implementation, a W -word MWCAS operation on P processors requires O (P W ) time. When considering multiprocessor workstations, it is reasonable to consider P to be a constant. <p> (z) = 8 Status [3]: 0 Save [3; 1]: 22 (a) val count valid pid x: 5 0 true 4 Val (x) = 5 y: 10 0 true 4 Val (y) = 10 z: 17 0 true 4 Val (z) = 17 Status [3]: 1 Save [3; 1]: 22 Status <ref> [4] </ref>: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: <p> Status [3]: 1 Save [3; 1]: 22 Status <ref> [4] </ref>: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; <p> Save [3; 1]: 22 Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save <ref> [4; 0] </ref>: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status <p> Status [4]: 2 (c) val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save <ref> [4; 1] </ref>: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) of <p> val count valid pid x: 5 0 false 4 Val (x) = 12 y: 10 1 false 4 Val (y) = 22 z: 17 2 false 4 Val (z) = 8 Status [3]: 0 Save [3; 1]: 22 Status [4]: 0 Save [4; 0]: 12 Save [4; 1]: 22 Save <ref> [4; 2] </ref>: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status [4]: 1 (d) of relevant shared variables are <p> 0]: 12 Save [4; 1]: 22 Save [4; 2]: 8 (b) val count valid pid x: 12 2 true 2 Val (x) = 12 y: 3 1 false 3 Val (y) = 22 z: 56 4 true 9 Val (z) = 56 Status [3]: 0 Save [3; 1]: 22 Status <ref> [4] </ref>: 1 (d) of relevant shared variables are shown (a) at the beginning of the operation; (b) after the loop in lines 3..14; (c) at the end of the operation, assuming success; and (d) at the end of the operation, assuming failure on word z. <p> Note that the current value of each word matches the desired old value. Inset (b) shows relevant variables after the first phase of m has completed, assuming no interferences by higher-priority processes. The current value of each word is unchanged. Note that changing the value of Status <ref> [4] </ref> from 0 to 2 in inset (b) would have the effect of atomically changing the current value of each of x, y, and z to the desired new value. Inset (c) shows relevant variables at the termination of m, assuming no interferences by higher-priority processes. <p> Inset (c) shows relevant variables at the termination of m, assuming no interferences by higher-priority processes. The current value of each word is now the desired new value, and all valid fields are true (so the value of Status <ref> [4] </ref> is no longer relevant). Before returning, process 4 updates Status [3] (line 19 of Figure 4) to indicate that process 3 (which must be of lower priority) has been interfered with. <p> Inset (d) shows relevant variables at the termination of m, assuming an interference on word z by process 9 (which must be of higher-priority) with new value 56. Status <ref> [4] </ref> is now 1, indicating the failure of process 4's operation. Status [3] is left unchanged in this case. Observe that process 4 has successfully restored the original values of words x and y. <p> Insets (e) and (f) show the operation interleavings corresponding to insets (c) and (d), respectively. 2 Our uniprocessor MWCAS implementation is disjoint access parallel [9] and is much simpler and more efficient than previous 5 disjoint access parallel algorithms for asynchronous systems <ref> [1, 4, 9] </ref>. One disadvantage of our implementation is that certain bits within each accessed word must be reserved for control information (the count, valid, and pid fields). The multiprocessor implementation of Section 3.1 does not require such control information and could be applied within a uniprocessor system. <p> With this scheme, each read requires time proportional to 2 T . The implementation described in this subsection is obviously not disjoint access parallel [9], but is much simpler and more efficient than implementations that are <ref> [1, 4, 9] </ref>. Some limited degree of disjoint access parallelism could be achieved with our implementation by using a separate version counter for each set of MWCAS operations that may potentially transitively conflict. 3.2 Linked Lists Our linked-list implementation for multiprocessors is shown in Figure 8.
Reference: [5] <author> B. Bershad, </author> <title> Practical Considerations for Non-Blocking Concurrent Objects, </title> <booktitle> Proc. of the 13th International Conference on Distributed Computing Systems, </booktitle> <year> 1993, </year> <pages> pp. 124-149. </pages>
Reference-contexts: An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton [6], but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad <ref> [5] </ref>, but this approach can be problematic to actually implement (see [6] for details). Fortunately, CCAS appears to be much easier to implement than CAS2. If CAS is available, then CCAS can be implemented in just a few instructions.
Reference: [6] <author> M. Greenwald and D. Cheriton, </author> <title> The Synergy Between Non-blocking Synchronization and Operating System Structure, </title> <booktitle> Proc. of the USENIX Association Second Symposium on Operating Systems Design and Implementation, </booktitle> <year> 1996, </year> <pages> pp. 123-136 </pages>
Reference-contexts: Lock-free kernel data structures facilitate the design of re-entrant kernels, because their use eliminates the possibility of deadlock resulting from a preempted object access. Examples of lock-free kernels include the Synthesis Kernel of Massalin and Pu [10] and the Cache Kernel of Greenwald and Cheriton <ref> [6] </ref>. One of the main lessons to be learned from [12] is that many problems that are either difficult or impossible to solve in a wait-free manner in asynchronous systems can be solved efficiently in a wait-free manner in priority-based systems. <p> Process p detects that its operation has been completed, so it returns. and 68040 processors). Algorithms for implementing CAS2 are known [1, 4, 9], but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton <ref> [6] </ref>, but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad [5], but this approach can be problematic to actually implement (see [6] for details). Fortunately, CCAS appears to be much easier to implement than CAS2. <p> An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton <ref> [6] </ref>, but no current machines support this implementation. An operating-system-based approach to implementing CAS2 has been proposed by Bershad [5], but this approach can be problematic to actually implement (see [6] for details). Fortunately, CCAS appears to be much easier to implement than CAS2. If CAS is available, then CCAS can be implemented in just a few instructions. <p> As a result, the code for the insert case actually becomes a bit simpler. 3.3 Performance Results We have conducted preliminary performance experiments that compare our multiprocessor wait-free linked-list implementation to a lock-free list implementation presented recently by Greenwald and Cheriton <ref> [6] </ref>. These experiments were performed on a five-processor SGI-R10000 machine. The priority-based preemption model was simulated at the user level. Our algorithm uses CCAS and Greenwald and Cheriton's uses CAS2, while the SGI-R10000 provides only CAS. <p> Another lock-free list implementation, which uses only CAS, was recently proposed by Valois [13]. Although we did not test against Valois' algorithm, Greenwald and Cheriton report that their algorithm is faster than his algorithm by a factor of about three under low contention, and about ten under high contention <ref> [6] </ref>. While our algorithm does not dramatically outperform Greenwald and Cheriton's, one should keep in mind that our algorithm is wait-free, whereas their algorithm and Valois' algorithm are only lock-free. This has important implications for hard real-time systems (one of the primary targets of our work).
Reference: [7] <author> M. Herlihy, </author> <title> Wait-Free Synchronization, </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 13(1), </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: Our work extends research reported in a recent paper by Ramamurthy, Moir, and Anderson [12] pertaining to the implementation of wait-free objects in priority-based real-time systems. The main contribution of their paper is a proof that any object with consensus number P in Herlihy's wait-free hierarchy <ref> [7] </ref> is universal for any number of processes executing on P processors in a priority-based real-time system. In addition, Ramamurthy et al. presented several wait-free implementations of compare-and-swap (CAS) from other primitives for real-time uniprocessors.
Reference: [8] <author> M. Herlihy, </author> <title> A Methodology for Implementing Highly Concurrent Data Objects, </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 15(5), </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: Before a process is allowed to do this, however, it must first help any previously announced operation (on its processor) to complete execution. This scheme requires only one announce variable per processor. In contrast, previous constructions for asynchronous systems require one announce variable per process <ref> [1, 2, 8] </ref>. In addition, with incremental helping, each process helps at most one other process, while in helping schemes for asynchronous systems, each process helps all other processes in the worst case. In the second part of the paper, we consider the implementation of wait-free objects on priority-based multiprocessors. <p> Our informal descriptions of the implementations do cover most of the formal properties needed for full proofs. 2 Uniprocessor Algorithms In this section, we present wait-free implementations of MWCAS and linked lists for priority-based uniprocessors. 4 For example, in Herlihy's construction <ref> [8] </ref>, two rounds of helping may be required, with N processes being helped per round. 5 For example, if processes p, q, and r concurrently perform MWCAS operations on words w and x, x and y, and y and z, respectively, then p has a direct conflict with q and transitive <p> With wait-free algorithms, worst-case execution times are easily computed. The only other means of implementing wait-free linked lists that we know of is to use universal constructions <ref> [2, 8] </ref>. Although we did not test against such constructions, they entail moderate to high copying overhead.
Reference: [9] <author> A. Israeli and L. Rappoport, </author> <title> Disjoint-Access-Parallel Implementations of Strong Shared Memory Primitives, </title> <booktitle> Proc. of the 13th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1994, </year> <pages> pp. 151-160 </pages>
Reference-contexts: Process q detects that p's operation is complete, so it announces its own operation, executes it, and relinquishes the processor to p. Process p detects that its operation has been completed, so it returns. and 68040 processors). Algorithms for implementing CAS2 are known <ref> [1, 4, 9] </ref>, but none are efficient enough to be practically applied. An efficient hardware-based implementation of CAS2 was recently proposed by Greenwald and Cheriton [6], but no current machines support this implementation. <p> In the latter part of the paper, we present performance results that show that our multiprocessor linked-list implementation is more efficient than alternative implementations on priority-based multiprocessor workstations. In work on multi-word synchronization primitives like MWCAS, Israeli and Rappoport introduced the important notion of disjoint access parallelism <ref> [9] </ref>. For a wait-free implementation to be disjoint access parallel, a process should only help other processes with which it has a transitive conflict. 5 Our multiprocessor MWCAS implementation does not have this property. <p> However, while ensuring parallelism in this context is of theoretical importance, practical algorithms that are disjoint access parallel have remained elusive. Indeed, if existing algorithms are any indication <ref> [1, 4, 9] </ref>, disjoint access parallelism, while improving best-case complexity, results in enormous worst-case complexity. In our multiprocessor MWCAS implementation, a W -word MWCAS operation on P processors requires O (P W ) time. When considering multiprocessor workstations, it is reasonable to consider P to be a constant. <p> Status [3] is left unchanged in this case. Observe that process 4 has successfully restored the original values of words x and y. Insets (e) and (f) show the operation interleavings corresponding to insets (c) and (d), respectively. 2 Our uniprocessor MWCAS implementation is disjoint access parallel <ref> [9] </ref> and is much simpler and more efficient than previous 5 disjoint access parallel algorithms for asynchronous systems [1, 4, 9]. One disadvantage of our implementation is that certain bits within each accessed word must be reserved for control information (the count, valid, and pid fields). <p> Insets (e) and (f) show the operation interleavings corresponding to insets (c) and (d), respectively. 2 Our uniprocessor MWCAS implementation is disjoint access parallel [9] and is much simpler and more efficient than previous 5 disjoint access parallel algorithms for asynchronous systems <ref> [1, 4, 9] </ref>. One disadvantage of our implementation is that certain bits within each accessed word must be reserved for control information (the count, valid, and pid fields). The multiprocessor implementation of Section 3.1 does not require such control information and could be applied within a uniprocessor system. <p> This ensures that any partially completed MWCAS is finished by the time the next read is performed. With this scheme, each read requires time proportional to 2 T . The implementation described in this subsection is obviously not disjoint access parallel <ref> [9] </ref>, but is much simpler and more efficient than implementations that are [1, 4, 9]. <p> With this scheme, each read requires time proportional to 2 T . The implementation described in this subsection is obviously not disjoint access parallel [9], but is much simpler and more efficient than implementations that are <ref> [1, 4, 9] </ref>. Some limited degree of disjoint access parallelism could be achieved with our implementation by using a separate version counter for each set of MWCAS operations that may potentially transitively conflict. 3.2 Linked Lists Our linked-list implementation for multiprocessors is shown in Figure 8.
Reference: [10] <author> H. Massalin and C. Pu, </author> <title> A Lock-Free Multiprocessor OS Kernel, </title> <type> Technical Report CUCS-005-01, </type> <institution> Computer Science Department, Columbia University, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: Lock-free kernel data structures facilitate the design of re-entrant kernels, because their use eliminates the possibility of deadlock resulting from a preempted object access. Examples of lock-free kernels include the Synthesis Kernel of Massalin and Pu <ref> [10] </ref> and the Cache Kernel of Greenwald and Cheriton [6]. One of the main lessons to be learned from [12] is that many problems that are either difficult or impossible to solve in a wait-free manner in asynchronous systems can be solved efficiently in a wait-free manner in priority-based systems.
Reference: [11] <author> R. Rajkumar, </author> <title> Synchronization In Real-Time Systems APriority Inheritance Approach, </title> <publisher> Kluwer Academic Pubs., </publisher> <year> 1991. </year>
Reference-contexts: Otherwise, if there are other announced operations on other processors with priority greater than q's but less than p's, p may be delayed unnecessarily. This is very similar to priority inheritance in real-time systems <ref> [11] </ref>.) Advancing the help counter in this scheme requires an O (P ) scan of the announce array.
Reference: [12] <author> S. Ramamurthy, M. Moir, and J. Anderson, </author> <title> Real-Time Object Sharing with Minimal System Support, </title> <booktitle> Proc. of the 15th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1996, </year> <pages> pp. 233-242. </pages>
Reference-contexts: We assume that processes are scheduled on a per-processor basis and do not migrate between processors during object accesses. Our work extends research reported in a recent paper by Ramamurthy, Moir, and Anderson <ref> [12] </ref> pertaining to the implementation of wait-free objects in priority-based real-time systems. The main contribution of their paper is a proof that any object with consensus number P in Herlihy's wait-free hierarchy [7] is universal for any number of processes executing on P processors in a priority-based real-time system. <p> Examples of lock-free kernels include the Synthesis Kernel of Massalin and Pu [10] and the Cache Kernel of Greenwald and Cheriton [6]. One of the main lessons to be learned from <ref> [12] </ref> is that many problems that are either difficult or impossible to solve in a wait-free manner in asynchronous systems can be solved efficiently in a wait-free manner in priority-based systems.
Reference: [13] <author> J. Valois, </author> <title> Lock-Free Linked Lists using Compare-and-Swap, </title> <booktitle> Proc. of the 14th ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995, </year> <pages> pp. 214-222. 12 </pages>
Reference-contexts: Our algorithm also outperforms theirs as the length of the list is increased, although graphs showing this have been omitted due to space limitations. Another lock-free list implementation, which uses only CAS, was recently proposed by Valois <ref> [13] </ref>. Although we did not test against Valois' algorithm, Greenwald and Cheriton report that their algorithm is faster than his algorithm by a factor of about three under low contention, and about ten under high contention [6].
References-found: 13

