URL: http://polaris.cs.uiuc.edu/reports/1519.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Title: c  
Author: flCopyright by Yunheung Paek 
Date: 1997  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Aho, R. Sethi, and J. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Mass., </address> <year> 1986. </year>
Reference-contexts: PUT/GET operations are useful for removing anti and output dependences, as illustrated in [28]. By using the function coalesce region and the region aggregation algorithm in the loop shown in Figure 2.21, the Region Processor calculates the region of upwards exposed uses <ref> [1] </ref> of array V as A 1 for each iteration I = t. <p> For instance, the Region Test would determine that the loop PREDIC do1000 in Figure 3.5 has only anti dependences; hence, this loop can be parallelized if the dependences are eliminated by renaming the array X as a private array and copying the upwards exposed use <ref> [1] </ref> regions of X to the private array with PUT/GET primitives.
Reference: [2] <author> American National Standards Institute, </author> <title> ANSI X3.9-1978 ISO 1539-1980. Programming Language FORTRAN, </title> <year> 1978. </year>
Reference-contexts: However, it is very difficult to achieve total compatibility. Therefore, CRAFT diverts from several conventional language features in the name of performance. Although there are numerous restrictions imposed by CRAFT, some of them include: * Fortran's sequence and storage association rules <ref> [2] </ref> do not apply to shared data. * Shared data may not be in EQUIVALENCE or blank COMMON. * Shared data may not be of type CHARACTER. 89 * Shared data may not be used as file specifiers. * The dimension size of shared arrays must be a power of two
Reference: [3] <author> C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel. TreadMarks: </author> <title> Shared Memory Computing on Networks of Workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> Feburary </month> <year> 1996. </year>
Reference-contexts: In all, these facts form a more compelling argument for the importance of parallelizing compilers for distributed memory machines over UMA machines. The most common approach to program distributed memory systems is to use standard message-passing libraries [45, 49], or - shared-memory programming models <ref> [3, 22, 27, 48, 64] </ref>. The message-passing programs based on the standard libraries are easy to port, but developing them requires sophisticated programming skills and a great deal of time because this work is usually done manually.
Reference: [4] <author> J. Anderson and M. Lam. </author> <title> Global Optimizations for Parallelism and Locality on Scalable Parallel Machines. </title> <booktitle> Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 112-125, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: In some cases, these work partitioning rules may sacrifice load balancing for low communication costs and simplification of loop scheduling. Sometimes parallelism is reduced to obtain better data locality <ref> [4] </ref>. The data-partition oriented approach often involves complex data and work partitioning, plus occasional data redistribution [19, 56] which may be needed when the access patterns change. The techniques based on this approach work well on applications with a regular memory access pattern.
Reference: [5] <author> R. Arpaci, D. Culler, A. Krishnamurthy, S. Steinberg, and K. Yelick. </author> <title> Empirical Evaluation of the CRAY-T3D: A Compiler Perspective. </title> <booktitle> International Symposium on Computer Architecture, </booktitle> <pages> pages 320-331, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Although the Polaris dependence analyzers [12, 69] can handle non-affine expressions, the other complexities involved in these access patterns prevent them from privatizing X to parallelize this loop. 18 2.1.2 Communication Analysis Communication optimization for distributed memory machines, such as the Cray T3D <ref> [5, 23, 39] </ref> and the SGI Origin [65], showed a need for gathering even more precise array access information for supporting efficient data movement and copying between distributed memories. <p> The PEs are 150 MHz DEC Alpha 21064 microprocessors. The interconnection network is a 3-D torus network with high throughput and low latency. Remote memory latency on the T3D ranges from 90 to 130 cycles <ref> [5] </ref>. Local memory latency is 22 cycles. The local memory is logically partitioned into private and shared address spaces. The shared memory in the T3D is no more than the collection of the shared address portions of all local memories.
Reference: [6] <author> E. Ayguade, J. Garcia, M. Girones, J. Labarta, J. Torres, and M. Valero. </author> <title> Detecting and Using Affinity in an Automatic Data Distribution Tool. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <pages> pages 61-75. </pages> <publisher> Springer Verlag, </publisher> <address> New York, New York, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: However, obtaining good performance from shared-memory programs still requires much work on the part of the programmer. In order to improve upon this situation, research is actively underway to automate as much as possible the process of generating efficient parallel programs <ref> [6, 8, 9, 19, 41, 56] </ref>. 4 This dissertation presents our recent work on the development of compiler algorithms to au-tomatically transform full sequential Fortran 77 codes into parallel form for distributed memory multiprocessors. <p> The approach consists of trying to find a good data partition <ref> [41, 6] </ref> that leads to low communication costs along with maximum possible parallelism. Work partitioning or computation assignment to processors is usually done as a function of the data layout, following strategies such as the owner-compute rule [68]. <p> This naive distribution policy facilitates the shared data copying scheme to some extent, as discussed in Section 3.2.4. For very regular programs, however, it has often been suggested that more sophisticated data distribution policies improve performance <ref> [6, 8, 9, 19, 41, 56] </ref>. Therefore, we need to apply access sensitive data distribution strategies mainly to those regular programs.
Reference: [7] <author> V. Balasundaram and K. Kennedy. </author> <title> A Techniques for Summarizing Data Access and its Use in Parallelism Enhancing Transformations. </title> <booktitle> Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1989. </year>
Reference-contexts: To simultaneously support powerful dependence analysis and communication analysis, a parallelizing compiler must have an efficient and flexible way of representing and manipulating memory access patterns. We found that most existing representations, such as triplet notation (also called regular section descriptor) [14, 20, 68, 70] and convex regions <ref> [7, 26] </ref> sometimes must discard critical information. This prevents the detection of parallelism in certain loops as well as prevents efficient communication analysis for data copying. <p> To gain simplicity, Blume and Eigenmann [14] excluded the stride from the triplet notation in their dependence test, but this was at the expense of accuracy. Convex regions [26] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [60, 67]. Balasundaram and Kennedy <ref> [7] </ref> proposed a simplified form of the convex region representation to detect task parallelism. Such representations are designed to balance their compile-time efficiency and accuracy.
Reference: [8] <author> R. Barua, D. Kranz, and A. Agarwal. </author> <title> Communication-Minimal Partitioning of Parallel Loops and Data Arrays for Cache-Coherent Distributed-Memory Multiprocessors. </title> <booktitle> In Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <address> New York, New York, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: However, obtaining good performance from shared-memory programs still requires much work on the part of the programmer. In order to improve upon this situation, research is actively underway to automate as much as possible the process of generating efficient parallel programs <ref> [6, 8, 9, 19, 41, 56] </ref>. 4 This dissertation presents our recent work on the development of compiler algorithms to au-tomatically transform full sequential Fortran 77 codes into parallel form for distributed memory multiprocessors. <p> This naive distribution policy facilitates the shared data copying scheme to some extent, as discussed in Section 3.2.4. For very regular programs, however, it has often been suggested that more sophisticated data distribution policies improve performance <ref> [6, 8, 9, 19, 41, 56] </ref>. Therefore, we need to apply access sensitive data distribution strategies mainly to those regular programs.
Reference: [9] <author> D. Bau, I. Kodukula, V. Kotlyar, K. Pingali, and P. Stodghill. </author> <title> Solving Alignment Using Elementary Linear Algebra. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <pages> pages 61-75. </pages> <publisher> Springer Verlag, </publisher> <address> New York, New York, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: However, obtaining good performance from shared-memory programs still requires much work on the part of the programmer. In order to improve upon this situation, research is actively underway to automate as much as possible the process of generating efficient parallel programs <ref> [6, 8, 9, 19, 41, 56] </ref>. 4 This dissertation presents our recent work on the development of compiler algorithms to au-tomatically transform full sequential Fortran 77 codes into parallel form for distributed memory multiprocessors. <p> This naive distribution policy facilitates the shared data copying scheme to some extent, as discussed in Section 3.2.4. For very regular programs, however, it has often been suggested that more sophisticated data distribution policies improve performance <ref> [6, 8, 9, 19, 41, 56] </ref>. Therefore, we need to apply access sensitive data distribution strategies mainly to those regular programs.
Reference: [10] <author> D. Bernstein, M. Breternitz, A. Gheith, and B. Mendelson. </author> <title> Solutions and Debugging for Data Consistency in Multiprocessors with Noncoherent Caches. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 23(1) </volume> <pages> 83-103, </pages> <year> 1995. </year>
Reference-contexts: More detailed descriptions of the machine can be found in other documents [22, 23, 24, 50]. 4.1.1 Hardware Characteristics While the lack of cache coherence in the Cray T3D helps to make the machine affordable and scalable, it also introduces some difficulties in the development of efficient programs <ref> [10] </ref>. The experimental results presented in this chapter give us hope that these programming difficulties can be overcome with the effective compiler techniques introduced in Chapter 3. The Cray T3D was designed mainly for large-scale parallel scientific applications.
Reference: [11] <author> M. Berry, D. Chen, P. Koss, D. Kuck, L. Pointer, S. Lo, Y. Pang, R. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox, P. Messina, D. Walker, C. Hsiung, 119 J. Schwarzmeier, K. Lue, S. Orszag, F. Seidl, O. Johnson, G. Swanson, R. Goodrum, and J. Martin. </author> <title> The Perfect Club Benchmarks: Effective Performance Evalution of Supercomputers. </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 3(3) </volume> <pages> 5-40, </pages> <month> Fall </month> <year> 1989. </year>
Reference-contexts: After this, we will detail each phase of the code transformation procedure shown in Figure 1.4. To evaluate the effectiveness of our techniques, we have conducted experiments on one of our target machines using various sequential codes from the SPEC95fp [62] and Perfect <ref> [11] </ref> benchmarks. We chose the Cray T3D [23] as our target machine in the experiment. In Chapter 3, the specification of the T3D and several code transformation issues that are T3D machine-dependent are first presented. <p> But, limited accuracy can prevent compiler transformations. We have found that, in some important cases, compiler techniques based on traditional access region representations are not effective due to either the inefficiency or inaccuracy of the representations. Based on our experience with the Perfect <ref> [11] </ref> and SPEC95fp [62] benchmarks, and other full scientific codes, we have developed the Access Region, a region access representation which takes advantage of the clear structure inherent in the array accesses of most scientific programs. Our design attempts to allow maximum accuracy without sacrificing efficiency. <p> B (h 1 ,...,h n ) 4.3 Benchmark Programs Table 4.3 briefly describes eleven programs that were used in our experiments. These programs come from either the SPEC95fp or the Perfect benchmarks. Detailed documents on these programs are available in <ref> [11, 62] </ref>. The table also shows the sequential execution times of each program on the Cray T3D. We used all these programs in the preliminary experiments presented in Section 4.4.
Reference: [12] <author> W. Blume. </author> <title> Symbolic Analysis Techniques for Effective Automatic Parallelization. </title> <type> PhD thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Science, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: The frontend passes, whose function is to identify implicit parallelism, include data dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization [14, 31, 59, 69]. To support data dependence analysis expressions with symbolic values, additional modules for powerful symbolic constant and range manipulation <ref> [12] </ref> have been implemented in Polaris. The frontend outputs the parallel program in IR form extended with annotations that identify the parallelism detected by these modules. Using the parallelism identified by the frontend, the backend applies machine-specific transformations and generates the target parallel program as output. <p> In our access region analysis, we employ various techniques already implemented in Polaris for this purpose, such as constant propagation, induction variable substitution, symbolic range propagation, and simplification of symbolic expressions <ref> [12] </ref>. 1.4 Organization of Dissertation The rest of this dissertation is organized as follows. In Chapter 2, we will discuss the access region analysis used in our code transformation algorithm. <p> There are also many other important compiler problems depending on the analysis, including dependence detection <ref> [12] </ref> and array privatization [69]. For access region analysis, it is necessary to represent the array accesses in some standard fashion. For instance, Tu and Padua [70] approximated access regions with the triplet notation in their array privatization work. <p> However, any representation which cannot handle non-affine expressions cannot represent this access region. Although the Polaris dependence analyzers <ref> [12, 69] </ref> can handle non-affine expressions, the other complexities involved in these access patterns prevent them from privatizing X to parallelize this loop. 18 2.1.2 Communication Analysis Communication optimization for distributed memory machines, such as the Cray T3D [5, 23, 39] and the SGI Origin [65], showed a need for gathering <p> In order to avoid that, we can extract predicates from the array dimension information to produce the region ((2J+(I-1)M)[J=1:N:1][I=1:J:1],MUST,WRITE,1 2J M ). In the operations in Section 2.4, this extra predicate will be used through the range dictionary <ref> [12] </ref> combined with various symbolic manipulation modules to supply accurate symbolic range information. 2.2.2 Abstract Access Form We have seen that, for the most part, within limited sections of a program, the access regions of interest have a regularity of structure. <p> The coalescing operation for a region with m stride/span pairs needs, in the worst case, m 2 m invocations of routine coalesce region for pair-wise comparisons. According to our study, coalescing in many cases <ref> [12] </ref> helps us to remove non-constant strides or spans from the access descriptor in the abstract form. The access descriptor A 2 I ;1 from TFFT2 in Figure 2.6, for example, can be coalesced to a simpler form A 1 2 ( N+1)1 + 3 by removing the index I. <p> We, therefore, found it necessary to parallelize very small loops to generate high quality parallel programs for distributed memory multiprocessors, thus motivating us to develop the Region Test discussed in the previous chapter. The Region test is similar to the Range Test <ref> [12] </ref>, the most powerful dependence test used by Polaris, in the sense that both are based on array access region analysis; but, the experiments showed that the Region Test can break many dependences that the Range Test conservatively assume present mainly because of the accuracy of the Access Region representation.
Reference: [13] <author> W. Blume, R. Doallo, R. Eigenmann, J. Grout, J. Hoeflinger, T. Lawrence, J. Lee, D. Padua, Y. Paek, W. Pottenger, L. Rauchwerger, and P. Tu. </author> <title> Parallel Programming with Polaris. </title> <journal> IEEE Computer, </journal> <volume> 29(12) </volume> <pages> 78-82, </pages> <month> December </month> <year> 1996. </year>
Reference-contexts: In this section, we divide the multiprocessor systems into two classes, subject to their memory organization, and compare several code transformation issues of parallelizing compilers between these classes of machines. The first class of machines we consider is shared-memory multiprocessors with Uniform Memory Access (UMA) architecture. Much work <ref> [13, 43, 58, 73] </ref> has been done in recent years on automatic parallelization of conventional sequential codes for these machines. <p> These algorithms have been implemented in Polaris <ref> [13, 51, 52] </ref>, a parallelizing compiler developed by the authors and others. The code transformation does not rely on directives or any other type of information from the programmer. The compiler gathers from the source code all the information needed to expose parallelism, distribute data, and control data movement. <p> Figure 1.2 demonstrates that Polaris substantially outperforms PFA, the native parallelizer of the SGI multiprocessors <ref> [13] </ref>. Despite these successful results on UMA machines, the original version of Polaris was not capable of generating efficient parallel codes for distributed memory machines listed in Figure 1.1 because of the naive code transformation algorithms implemented in its backend. <p> Similar access patterns also can be commonly found in full scientific programs <ref> [13] </ref>. do 50 I = M,N,5 STEMP = STEMP + SX (I)*SY (I) + SX (I+1)*SY (I+1) + * SX (I+2)*SY (I+2) + SX (I+3)*SY (I+3) + SX (I+4)*SY (I+4) 50 continue The access pattern generated by multiple indices with various strides is usually represented by an access region with the <p> This strategy has worked well on medium- and small-scale UMA shared-memory multiprocessors, where a few important loops in a program dominate the overall performance <ref> [13] </ref>. In large-scale multiprocessors, however, more accuracy has been found to be necessary because small unimportant loops often become important to determine the multiprocessor speedups, as illustrated in Table 3.1 where the serial coverage is the percentage of execution time consumed by serial loops. <p> Further--more, the analysis helped us to determine optimization techniques to handle these performance factors. Based on these previous studies, we proposed a new approach for the code transformation which was presented in Chapters 2 and 3. Our code transformation capitalizes on the traditional compiler techniques already implemented in Polaris <ref> [13, 52] </ref>. In addition, it uses several newly developed techniques for a distributed memory architecture, such as the Access Region, the Region Test, procedure data privatization, and data localization.
Reference: [14] <author> W. Blume and R. Eigenmann. </author> <title> The Range Test: A Dependence Test for Symbolic, Nonlinear Expressions. </title> <booktitle> Proceedings of Supercomputing '94, </booktitle> <pages> pages 528-537, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: For this reason, most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques <ref> [14, 30, 60, 61, 73] </ref>, dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches [38, 40, 72]. <p> After a program is converted into IR form, it is analyzed and transformed by a sequence of compiler passes, the modules implemented in Polaris. The frontend passes, whose function is to identify implicit parallelism, include data dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization <ref> [14, 31, 59, 69] </ref>. To support data dependence analysis expressions with symbolic values, additional modules for powerful symbolic constant and range manipulation [12] have been implemented in Polaris. The frontend outputs the parallel program in IR form extended with annotations that identify the parallelism detected by these modules. <p> To simultaneously support powerful dependence analysis and communication analysis, a parallelizing compiler must have an efficient and flexible way of representing and manipulating memory access patterns. We found that most existing representations, such as triplet notation (also called regular section descriptor) <ref> [14, 20, 68, 70] </ref> and convex regions [7, 26] sometimes must discard critical information. This prevents the detection of parallelism in certain loops as well as prevents efficient communication analysis for data copying. <p> For instance, Tu and Padua [70] approximated access regions with the triplet notation in their array privatization work. The same notation was used by Tseng [68] and Chatterjee, and Gilbert and Long [20] for message generation. To gain simplicity, Blume and Eigenmann <ref> [14] </ref> excluded the stride from the triplet notation in their dependence test, but this was at the expense of accuracy. Convex regions [26] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [60, 67]. <p> This is generally true because several references to a single array within a loop nest are generally accessed using the same loop indices and with similar subscript expressions. Experimental evidence for the regularity and similarity of array subscripting may be gleaned from the work of others <ref> [14, 60, 66] </ref> who note that their dependence tests, built to be effective and fast specifically for regular and similar access patterns, are successful for most access patterns encountered in real scientific programs. For a more specific description of similarity and regularity, consider the example in Figure 2.4. <p> These features provide a mechanism which can determine relationships between variables even when their exact values are unknown. This rich environment was crucial to the success of the Range Test <ref> [14] </ref>, and can enable many of the symbolic operations of the Region Processor. 54 The predicate for an access region R may be thought of as the pertinent information found in the gating information from the GSA form and in the value range constraints. <p> In the work presented here, we make use of both the traditional techniques based on the triplet notation and the new techniques based on the Access Region. 65 3.2.1 Parallelism Detection The techniques implemented in Polaris to detect parallelism include: dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization <ref> [14, 31, 59, 69] </ref>. Since these techniques are well documented in other places, we will not discuss them any further in this dissertation. The loops that are identified as parallel by these techniques are marked with parallel directives.
Reference: [15] <author> W. Blume, R. Eigenmann, K. Faigin, J. Grout, J. Hoeflinger, D. Padua, P. Petersen, W. Pottenger, L. Rauchwerger, P. Tu, and S. Weatherford. </author> <title> Polaris: The Next Generation in Parallelizing Compilers. </title> <booktitle> Proceedings of 7th Workshop on Language and Compilers for Parallel Computing, </booktitle> <pages> pages 10.1-10.18, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: During the sequential execution of an original program, we measured the percentage of overall running time of the program for each loop, and added the percentages of each parallelizable loop to obtain the total sum. We call this total sum parallel coverage <ref> [15] </ref>. Two dotted lines in Figure 4.7 plot the ideal speedups for programs with parallel coverage of 99% and 90% respectively. The ideal speedup, S, is calculated using Amdahl's equality: S = 1 P +1 c , where P is the number of processors and c is the parallel coverage.
Reference: [16] <author> S. Bokhari. </author> <title> Communuication Overhead on Intel Paragon, IBM SP2 and Meiko CS-2. </title> <type> Technical Report 28, </type> <institution> Institute for Computer Applications in Science and Engineering, NASA Langley Research Center, </institution> <year> 1995. </year>
Reference-contexts: Another reason is that PUT/GET operations have been rapidly gaining wide acceptance. Several portable shared-memory programming models [27, 45, 48] supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon <ref> [16] </ref>, and TMC CM-5 [34]. Furthermore, several existing and newly 64 proposed large-scale machines directly support these primitives in hardware [23, 24, 25, 32], which reduces the effect of the increased communication overhead resulting from the data copy operations.
Reference: [17] <author> M. Burke and R. Cytron. </author> <title> Interprocedural Dedependence Analysis and Parallelization. </title> <booktitle> Proceedings of the SIGPLAN Symposium on Compiler Construction, </booktitle> <pages> pages 162-175, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: If X is multi-dimensional, then the subscript expression is linearized <ref> [17] </ref> to generate s (I).
Reference: [18] <author> N. Carriero and D. Gelernter. </author> <title> Case Studies in Asynchronous Data Parallelism. </title> <journal> International Journal of Parallel Programming, </journal> <volume> 22(2) </volume> <pages> 129-149, </pages> <year> 1994. </year>
Reference-contexts: which has the following characteristics: * Single Program Multiple Data (SPMD) paradigm, * explicit synchronization through barriers and locks, * explicit data declaration as private or shared, and * asynchronous communication with PUT/GET primitives. 63 The parallel program is in SPMD form and follows the master/slave (or the master/worker) model <ref> [18] </ref> in which one of the parallel processors, the master, executes all sequential regions, and the other processors, the slaves, participate only in the computations of parallel regions.
Reference: [19] <author> B. Chapman, P. Mehrota, H. Moritsch, and H. Zima. </author> <title> Dynamic Data Distributions in Vienna Fortran. </title> <booktitle> Proceedings of Supercomputing '93, </booktitle> <pages> pages 284-293, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: However, obtaining good performance from shared-memory programs still requires much work on the part of the programmer. In order to improve upon this situation, research is actively underway to automate as much as possible the process of generating efficient parallel programs <ref> [6, 8, 9, 19, 41, 56] </ref>. 4 This dissertation presents our recent work on the development of compiler algorithms to au-tomatically transform full sequential Fortran 77 codes into parallel form for distributed memory multiprocessors. <p> In some cases, these work partitioning rules may sacrifice load balancing for low communication costs and simplification of loop scheduling. Sometimes parallelism is reduced to obtain better data locality [4]. The data-partition oriented approach often involves complex data and work partitioning, plus occasional data redistribution <ref> [19, 56] </ref> which may be needed when the access patterns change. The techniques based on this approach work well on applications with a regular memory access pattern. <p> A private variable is replicated to every local memory. In contrast, only one object for each shared variable exists in the system and is accessible to all processors. Shared arrays can be given BLOCK or CYCLIC distribution, similar to those in other parallel programming models <ref> [19, 64] </ref>. PUT/GET operations will be used to implement prefetching and poststoring schemes for the control of data movement between shared memory and private memory in the data localization phase shown in Figure 1.4. <p> In our experiments, each CRAFT process was allocated to a separate physical processor. Data objects can be declared as shared or private. Shared data can be distributed across memory using directives similar to those made popular by High Performance Fortran, Vienna Fortran, and other similar languages <ref> [19, 64, 68] </ref>. CRAFT uses `:block' for block distribution and `:block (N )' for block-cyclic distribution where N is an integer. The do shared directive of CRAFT is used to mark parallel loops. To illustrate its semantics, consider the loop in Figure 4.1. <p> This naive distribution policy facilitates the shared data copying scheme to some extent, as discussed in Section 3.2.4. For very regular programs, however, it has often been suggested that more sophisticated data distribution policies improve performance <ref> [6, 8, 9, 19, 41, 56] </ref>. Therefore, we need to apply access sensitive data distribution strategies mainly to those regular programs.
Reference: [20] <author> S. Chatterjee, J. Gilbert, F. Long, R. Schreiber, and S. Teng. </author> <title> Generating Local Address and Communication Sets for Data-Parallel Programs. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 26(1) </volume> <pages> 72-84, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: To simultaneously support powerful dependence analysis and communication analysis, a parallelizing compiler must have an efficient and flexible way of representing and manipulating memory access patterns. We found that most existing representations, such as triplet notation (also called regular section descriptor) <ref> [14, 20, 68, 70] </ref> and convex regions [7, 26] sometimes must discard critical information. This prevents the detection of parallelism in certain loops as well as prevents efficient communication analysis for data copying. <p> For access region analysis, it is necessary to represent the array accesses in some standard fashion. For instance, Tu and Padua [70] approximated access regions with the triplet notation in their array privatization work. The same notation was used by Tseng [68] and Chatterjee, and Gilbert and Long <ref> [20] </ref> for message generation. To gain simplicity, Blume and Eigenmann [14] excluded the stride from the triplet notation in their dependence test, but this was at the expense of accuracy. Convex regions [26] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [60, 67].
Reference: [21] <author> K. Cooper, M. Hall, and L. Torczon. </author> <title> An experiment with inline substitution. </title> <type> Technical Report COMP TR-90-128, </type> <institution> Department of Computer Science, Rice University, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: For this reason, most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques [14, 30, 60, 61, 73], dependence elimination techniques <ref> [21, 59, 69] </ref>, the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches [38, 40, 72].
Reference: [22] <author> Cray Research Inc. </author> <title> CRAY MPP Fortran Reference Manual, </title> <year> 1993. </year>
Reference-contexts: In all, these facts form a more compelling argument for the importance of parallelizing compilers for distributed memory machines over UMA machines. The most common approach to program distributed memory systems is to use standard message-passing libraries [45, 49], or - shared-memory programming models <ref> [3, 22, 27, 48, 64] </ref>. The message-passing programs based on the standard libraries are easy to port, but developing them requires sophisticated programming skills and a great deal of time because this work is usually done manually. <p> More detailed descriptions of the machine can be found in other documents <ref> [22, 23, 24, 50] </ref>. 4.1.1 Hardware Characteristics While the lack of cache coherence in the Cray T3D helps to make the machine affordable and scalable, it also introduces some difficulties in the development of efficient programs [10].
Reference: [23] <institution> Cray Research Inc. The CRAY T3D System Architecture, </institution> <year> 1993. </year>
Reference-contexts: This is the case in some systems, such as loosely-coupled multicomputers, and networks of workstations. But, our experience [54] tells us that we do not have to follow this approach for several existing machines <ref> [23, 25, 32, 33] </ref> which support very low remote memory latency; although the data partition issue still remains important in these machines, we have found that it is possible to obtain reasonable speedups for a wide spectrum of scientific applications on these machines even without sophisticated data partition algorithms. 10 Based <p> To evaluate the effectiveness of our techniques, we have conducted experiments on one of our target machines using various sequential codes from the SPEC95fp [62] and Perfect [11] benchmarks. We chose the Cray T3D <ref> [23] </ref> as our target machine in the experiment. In Chapter 3, the specification of the T3D and several code transformation issues that are T3D machine-dependent are first presented. <p> Although the Polaris dependence analyzers [12, 69] can handle non-affine expressions, the other complexities involved in these access patterns prevent them from privatizing X to parallelize this loop. 18 2.1.2 Communication Analysis Communication optimization for distributed memory machines, such as the Cray T3D <ref> [5, 23, 39] </ref> and the SGI Origin [65], showed a need for gathering even more precise array access information for supporting efficient data movement and copying between distributed memories. <p> The loop in Figure 2.2 is the most important in TFFT2; thus, good speedups were not possible without parallelizing this loop. To measure the effectiveness of the Region Test, we tested the performance of the TFFT2 benchmark on the Cray T3D <ref> [23] </ref> both with and without applying the Region Test. The results, shown in Table 2.1, demonstrate that the Region Test allows us to significantly reduce the parallel execution times. <p> Several portable shared-memory programming models [27, 45, 48] supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon [16], and TMC CM-5 [34]. Furthermore, several existing and newly 64 proposed large-scale machines directly support these primitives in hardware <ref> [23, 24, 25, 32] </ref>, which reduces the effect of the increased communication overhead resulting from the data copy operations. Our techniques can be applied to any distributed memory system that supports all these characteristics by either hardware or software. <p> Furthermore, in some non-cache coherent multiprocessor systems <ref> [23, 25] </ref>, shared data may not be cached, thereby causing performance degradation whenever the computation uses shared data. Data privatization presents additional benefits in these machines by providing more chances for processors to use data caches in their computations. <p> Instead of total data redistribution of the elements of X, the processors can prefetch and poststore the exact portions of X that they access in each loop. 74 3. Similar to data privatization, the scheme provides a benefit of helping processors to better utilize caches in non-cache coherent machines <ref> [23, 25] </ref>. In order to bring about all these benefits, this scheme should carry out efficient copying operations based on a very precise access region analysis. In Chapter 2, we discussed the access region analysis used in our code transformation algorithm. <p> In this section, we present our recent experiments on one of these systems: the Cray T3D <ref> [23] </ref>. Section 4.1 will first briefly describe the T3D. Section 4.2 will present several machine-dependent issues addressed by the Polaris code transformation for the T3D. Section 4.3 will briefly discuss the characteristics of the benchmark programs used in our experiments. <p> More detailed descriptions of the machine can be found in other documents <ref> [22, 23, 24, 50] </ref>. 4.1.1 Hardware Characteristics While the lack of cache coherence in the Cray T3D helps to make the machine affordable and scalable, it also introduces some difficulties in the development of efficient programs [10].
Reference: [24] <institution> Cray Research Inc. SHMEM Technical Note for Fortran, </institution> <year> 1994. </year>
Reference-contexts: We have observed that this predicate-based run-time test is useful for various programs, such as MDG and OCEAN from the Perfect benchmarks. 2.6.2 Communication Analysis Single-sided communication protocols <ref> [24, 27, 45, 48] </ref> in the form of PUT/GET primitives have been rapidly gaining wide acceptance. A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris. <p> Several portable shared-memory programming models [27, 45, 48] supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon [16], and TMC CM-5 [34]. Furthermore, several existing and newly 64 proposed large-scale machines directly support these primitives in hardware <ref> [23, 24, 25, 32] </ref>, which reduces the effect of the increased communication overhead resulting from the data copy operations. Our techniques can be applied to any distributed memory system that supports all these characteristics by either hardware or software. <p> More detailed descriptions of the machine can be found in other documents <ref> [22, 23, 24, 50] </ref>. 4.1.1 Hardware Characteristics While the lack of cache coherence in the Cray T3D helps to make the machine affordable and scalable, it also introduces some difficulties in the development of efficient programs [10]. <p> Various communication primitives, including single-sided communication primitives, are supported in the T3D hardware. Therefore, the T3D can compensate for its lack of hardware cache coherence through its hardware mechanisms that facilitate efficient software control of local memory coherency and PUT/GET operations through library primitives <ref> [24] </ref>. 86 4.1.2 Shared Memory Programming Like most other distributed memory machines, the Cray T3D supports the message-passing programming models through libraries, such as MPI and PVM. <p> be a power of two y . * Shared formal parameters may not be associated with private actual parameters, and their size and shape must match those of the corresponding actual parameters. * Shared data cannot be passed as parameters directly to PUT/GET primitives provided by the T3D PUT/GET library <ref> [24] </ref>. We have developed translation algorithms to resolve the semantical incompatibilities between CRAFT and Fortran 77 which occur when we translate Fortran to CRAFT as a result of all these restrictions. In the code transformation procedure shown in Figure 1.4, we did not explicitly mention these algorithms.
Reference: [25] <author> Cray Research Inc. </author> <title> The CRAY T3E-900 Scalable Parallel Processing System, </title> <year> 1996. </year>
Reference-contexts: This is the case in some systems, such as loosely-coupled multicomputers, and networks of workstations. But, our experience [54] tells us that we do not have to follow this approach for several existing machines <ref> [23, 25, 32, 33] </ref> which support very low remote memory latency; although the data partition issue still remains important in these machines, we have found that it is possible to obtain reasonable speedups for a wide spectrum of scientific applications on these machines even without sophisticated data partition algorithms. 10 Based <p> Several portable shared-memory programming models [27, 45, 48] supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon [16], and TMC CM-5 [34]. Furthermore, several existing and newly 64 proposed large-scale machines directly support these primitives in hardware <ref> [23, 24, 25, 32] </ref>, which reduces the effect of the increased communication overhead resulting from the data copy operations. Our techniques can be applied to any distributed memory system that supports all these characteristics by either hardware or software. <p> Furthermore, in some non-cache coherent multiprocessor systems <ref> [23, 25] </ref>, shared data may not be cached, thereby causing performance degradation whenever the computation uses shared data. Data privatization presents additional benefits in these machines by providing more chances for processors to use data caches in their computations. <p> Instead of total data redistribution of the elements of X, the processors can prefetch and poststore the exact portions of X that they access in each loop. 74 3. Similar to data privatization, the scheme provides a benefit of helping processors to better utilize caches in non-cache coherent machines <ref> [23, 25] </ref>. In order to bring about all these benefits, this scheme should carry out efficient copying operations based on a very precise access region analysis. In Chapter 2, we discussed the access region analysis used in our code transformation algorithm.
Reference: [26] <author> B. Creusillet and F. Irigoin. </author> <title> Exact vs. Approximate Array Region Analyses. </title> <booktitle> In Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <address> New York, New York, </address> <month> August </month> <year> 1996. </year> <month> 120 </month>
Reference-contexts: To simultaneously support powerful dependence analysis and communication analysis, a parallelizing compiler must have an efficient and flexible way of representing and manipulating memory access patterns. We found that most existing representations, such as triplet notation (also called regular section descriptor) [14, 20, 68, 70] and convex regions <ref> [7, 26] </ref> sometimes must discard critical information. This prevents the detection of parallelism in certain loops as well as prevents efficient communication analysis for data copying. <p> The same notation was used by Tseng [68] and Chatterjee, and Gilbert and Long [20] for message generation. To gain simplicity, Blume and Eigenmann [14] excluded the stride from the triplet notation in their dependence test, but this was at the expense of accuracy. Convex regions <ref> [26] </ref> express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests [60, 67]. Balasundaram and Kennedy [7] proposed a simplified form of the convex region representation to detect task parallelism. Such representations are designed to balance their compile-time efficiency and accuracy.
Reference: [27] <author> D. Culler, A. Dusseau, S. Goldstein, A. Krishnamurthy, S. Lumetta, T. Eicken, and K. Yelick. </author> <title> Parallel Programming in Split-C. </title> <booktitle> Proceedings of Supercomputing '93, </booktitle> <pages> pages 262-273, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: In all, these facts form a more compelling argument for the importance of parallelizing compilers for distributed memory machines over UMA machines. The most common approach to program distributed memory systems is to use standard message-passing libraries [45, 49], or - shared-memory programming models <ref> [3, 22, 27, 48, 64] </ref>. The message-passing programs based on the standard libraries are easy to port, but developing them requires sophisticated programming skills and a great deal of time because this work is usually done manually. <p> We have observed that this predicate-based run-time test is useful for various programs, such as MDG and OCEAN from the Perfect benchmarks. 2.6.2 Communication Analysis Single-sided communication protocols <ref> [24, 27, 45, 48] </ref> in the form of PUT/GET primitives have been rapidly gaining wide acceptance. A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris. <p> Another reason is that PUT/GET operations have been rapidly gaining wide acceptance. Several portable shared-memory programming models <ref> [27, 45, 48] </ref> supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon [16], and TMC CM-5 [34].
Reference: [28] <author> R. Cytron and J. Ferrante. </author> <booktitle> What's in a Name? Proceedings of the 1987 International Conference on Parallel Processing, </booktitle> <pages> pages 19-27, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris. PUT/GET operations are useful for removing anti and output dependences, as illustrated in <ref> [28] </ref>. By using the function coalesce region and the region aggregation algorithm in the loop shown in Figure 2.21, the Region Processor calculates the region of upwards exposed uses [1] of array V as A 1 for each iteration I = t. <p> The benefits of data privatization are many. One is that it removes some types of output and anti dependences, as discussed in <ref> [28] </ref>.
Reference: [29] <author> K. Faigin. </author> <title> The Polaris Internal Representation. </title> <type> Master's thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <year> 1994. </year>
Reference-contexts: Polaris was developed to overcome limitations in the analysis and transformation techniques implemented in other systems and to be robust enough to allow serious experimental studies. Taking a sequential Fortran 77 program as input, Polaris converts the program into its internal representation (IR) form <ref> [29] </ref>. The IR form includes an extensive collection of powerful 5 program manipulation operations that facilitate the implementation of compiler transformations in Polaris. After a program is converted into IR form, it is analyzed and transformed by a sequence of compiler passes, the modules implemented in Polaris.
Reference: [30] <author> G. Goff, K. Kennedy, and C. Tseng. </author> <title> Practical Dependence Testing. </title> <booktitle> In Proceedings of the ACM SIGPLAN 91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 15-29, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: For this reason, most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques <ref> [14, 30, 60, 61, 73] </ref>, dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches [38, 40, 72].
Reference: [31] <author> J. Grout. </author> <title> Inline Expansion for the Polaris Research Compiler. </title> <type> Master's thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: After a program is converted into IR form, it is analyzed and transformed by a sequence of compiler passes, the modules implemented in Polaris. The frontend passes, whose function is to identify implicit parallelism, include data dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization <ref> [14, 31, 59, 69] </ref>. To support data dependence analysis expressions with symbolic values, additional modules for powerful symbolic constant and range manipulation [12] have been implemented in Polaris. The frontend outputs the parallel program in IR form extended with annotations that identify the parallelism detected by these modules. <p> In the work presented here, we make use of both the traditional techniques based on the triplet notation and the new techniques based on the Access Region. 65 3.2.1 Parallelism Detection The techniques implemented in Polaris to detect parallelism include: dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization <ref> [14, 31, 59, 69] </ref>. Since these techniques are well documented in other places, we will not discuss them any further in this dissertation. The loops that are identified as parallel by these techniques are marked with parallel directives.
Reference: [32] <author> K. Hayashi, T. Doi, T. Horie, Y. Koyanagi, O. Shiraki, N. Imamura, T. Shimizu, H. Ishi-hara, and T. Shindo. </author> <title> AP1000+: </title> <booktitle> Architectural Support of PUT/GET Interface for Paral-lelizing Compiler. Proceedings of 6th International Conference on Architechtural Support for Programming Language and Operating Systems, </booktitle> <pages> pages 196-207, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: This is the case in some systems, such as loosely-coupled multicomputers, and networks of workstations. But, our experience [54] tells us that we do not have to follow this approach for several existing machines <ref> [23, 25, 32, 33] </ref> which support very low remote memory latency; although the data partition issue still remains important in these machines, we have found that it is possible to obtain reasonable speedups for a wide spectrum of scientific applications on these machines even without sophisticated data partition algorithms. 10 Based <p> Several portable shared-memory programming models [27, 45, 48] supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon [16], and TMC CM-5 [34]. Furthermore, several existing and newly 64 proposed large-scale machines directly support these primitives in hardware <ref> [23, 24, 25, 32] </ref>, which reduces the effect of the increased communication overhead resulting from the data copy operations. Our techniques can be applied to any distributed memory system that supports all these characteristics by either hardware or software.
Reference: [33] <institution> Hewlett-Packard CONVEX division. HP-CONVEX Exemplar S-Class and X-Class Systems Overview, </institution> <year> 1996. </year>
Reference-contexts: This is the case in some systems, such as loosely-coupled multicomputers, and networks of workstations. But, our experience [54] tells us that we do not have to follow this approach for several existing machines <ref> [23, 25, 32, 33] </ref> which support very low remote memory latency; although the data partition issue still remains important in these machines, we have found that it is possible to obtain reasonable speedups for a wide spectrum of scientific applications on these machines even without sophisticated data partition algorithms. 10 Based <p> the array access area for X in Figure 3.11), this private memory area can be liberated. 83 CHAPTER 4 EXPERIMENTS AND PERFORMANCE ANALYSIS To measure the effectiveness of our transformation techniques, the Polaris code generators have been implemented for various types of distributed memory systems, such as the Convex Exemplar <ref> [33] </ref>, and networks of workstations. In this section, we present our recent experiments on one of these systems: the Cray T3D [23]. Section 4.1 will first briefly describe the T3D. Section 4.2 will present several machine-dependent issues addressed by the Polaris code transformation for the T3D.
Reference: [34] <author> W. Hillis. </author> <title> The Connection Machine. </title> <publisher> The MIT Press, </publisher> <address> MA, </address> <year> 1985. </year>
Reference-contexts: Another reason is that PUT/GET operations have been rapidly gaining wide acceptance. Several portable shared-memory programming models [27, 45, 48] supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon [16], and TMC CM-5 <ref> [34] </ref>. Furthermore, several existing and newly 64 proposed large-scale machines directly support these primitives in hardware [23, 24, 25, 32], which reduces the effect of the increased communication overhead resulting from the data copy operations.
Reference: [35] <author> S. Hiranandani, Kennedy K, and C. Tseng. </author> <title> Evaluating Compiler Optimizations for Fortran D. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <pages> pages 27-45, </pages> <year> 1994. </year>
Reference-contexts: Therefore, the original algorithm may be modified to choose copy-level 1 if M is found to be too small, thereby reducing copying overhead without significantly consuming private memory. Another factor affecting the determination of the copy-level is whether the data pipelin-ing technique <ref> [68, 35] </ref> can be exploited in data copying operations. If the implementation of polaris put/get routines is non-blocking, then we may exploit data pipelining.
Reference: [36] <author> J. Hoefling, Y. Paek, and D. Padua. </author> <title> Region-based Parallelization Using the Region Test. </title> <type> Technical Report 1514, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing R&D, </institution> <year> 1996. </year>
Reference-contexts: In <ref> [36] </ref>, we formally propose a new dependence test, called the Region Test. Since we detailed the test in that previous work, we will only briefly mention the basic concepts of the Region Test in this section.
Reference: [37] <institution> IBM Corp. RS/6000 Scalable POWERparallel Systems(SP), </institution> <year> 1996. </year>
Reference-contexts: Another reason is that PUT/GET operations have been rapidly gaining wide acceptance. Several portable shared-memory programming models [27, 45, 48] supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 <ref> [37] </ref>, Intel Paragon [16], and TMC CM-5 [34]. Furthermore, several existing and newly 64 proposed large-scale machines directly support these primitives in hardware [23, 24, 25, 32], which reduces the effect of the increased communication overhead resulting from the data copy operations.
Reference: [38] <author> W. Jalby and U. Meier. </author> <title> Optimizing Matrix Operations on a Parallel Multiprocessor with a Memory Hierarchy. </title> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <address> St. Charles, IL, </address> <pages> pages 429-432, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques [14, 30, 60, 61, 73], dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches <ref> [38, 40, 72] </ref>. The work on parallelizing compilers for UMA machines also has given us the foundations necessary to tackle the study of compiler algorithms for more complex classes of machines like distributed memory multiprocessors, the target of the compiler project reported in this dissertation.
Reference: [39] <author> V. Karamcheti and A. Chien. </author> <title> A Comparison of Architectural Support for Messaging in the TMC CM-5 and the Cray T3D. </title> <booktitle> International Symposium on Computer Architecture, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: Although the Polaris dependence analyzers [12, 69] can handle non-affine expressions, the other complexities involved in these access patterns prevent them from privatizing X to parallelize this loop. 18 2.1.2 Communication Analysis Communication optimization for distributed memory machines, such as the Cray T3D <ref> [5, 23, 39] </ref> and the SGI Origin [65], showed a need for gathering even more precise array access information for supporting efficient data movement and copying between distributed memories.
Reference: [40] <author> K. Kennedy and K. McKinley. </author> <title> Maximizing Loop Parallelism and Improving Data Locality via Loop Fusion and Distribution. </title> <booktitle> Proceedings of 6th Workshop on Language and Compilers for Parallel Computing, </booktitle> <pages> pages 301-320, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques [14, 30, 60, 61, 73], dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches <ref> [38, 40, 72] </ref>. The work on parallelizing compilers for UMA machines also has given us the foundations necessary to tackle the study of compiler algorithms for more complex classes of machines like distributed memory multiprocessors, the target of the compiler project reported in this dissertation. <p> LT stands for the conventional loop transformation techniques, including loop fusion, loop distribution and loop interchange <ref> [40, 73] </ref>. These techniques are useful in our approach because they help neighboring loop nests to reuse data stored in local memory. <p> One technique we have already used for this purpose is conventional loop transformation, such as loop fusion, loop distribution, and loop interchange <ref> [40, 73] </ref>. Another, yet more general, technique we consider now is redundant PUT/GET elimination. We illustrate this technique using the example in Figure 5.1.
Reference: [41] <author> K.Kennendy and U. Kremer. </author> <title> Automatic Data Layout for High Performance Fortran. </title> <booktitle> Proceedings of Supercomputing '95, </booktitle> <month> November </month> <year> 1995. </year> <month> 121 </month>
Reference-contexts: However, obtaining good performance from shared-memory programs still requires much work on the part of the programmer. In order to improve upon this situation, research is actively underway to automate as much as possible the process of generating efficient parallel programs <ref> [6, 8, 9, 19, 41, 56] </ref>. 4 This dissertation presents our recent work on the development of compiler algorithms to au-tomatically transform full sequential Fortran 77 codes into parallel form for distributed memory multiprocessors. <p> The approach consists of trying to find a good data partition <ref> [41, 6] </ref> that leads to low communication costs along with maximum possible parallelism. Work partitioning or computation assignment to processors is usually done as a function of the data layout, following strategies such as the owner-compute rule [68]. <p> This naive distribution policy facilitates the shared data copying scheme to some extent, as discussed in Section 3.2.4. For very regular programs, however, it has often been suggested that more sophisticated data distribution policies improve performance <ref> [6, 8, 9, 19, 41, 56] </ref>. Therefore, we need to apply access sensitive data distribution strategies mainly to those regular programs.
Reference: [42] <author> D. Kuck. </author> <title> What Do Users of Parallel Computer Systems Really Need? International Journal of Parallel Programming, </title> <booktitle> 22(1) </booktitle> <pages> 99-127, </pages> <year> 1996. </year>
Reference-contexts: INTRODUCTION 1.1 Code Transformation for Multiprocessor Systems In the past two decades, as the limits of semiconductor technology are approached <ref> [42] </ref>, techniques for the architectural design of multiprocessor systems have been in great demand, and significant progress has been made in that research. As a result, these techniques are now commonly referred to as major breakthroughs in high-performance computing.
Reference: [43] <author> Kuck and Associate Inc. </author> <title> The KAP TM Preprocessor, </title> <year> 1995. </year>
Reference-contexts: In this section, we divide the multiprocessor systems into two classes, subject to their memory organization, and compare several code transformation issues of parallelizing compilers between these classes of machines. The first class of machines we consider is shared-memory multiprocessors with Uniform Memory Access (UMA) architecture. Much work <ref> [13, 43, 58, 73] </ref> has been done in recent years on automatic parallelization of conventional sequential codes for these machines.
Reference: [44] <author> R. Marcelin. </author> <title> Message Passing on the CRAY T3D. Massively Parallel Computing Group, </title> <address> NERSC, </address> <year> 1995. </year>
Reference-contexts: As built on very low level hardware primitives, Since this PUT/GET library in the T3D is built on very low level hardware primitives, it is implemented to be more efficient than other message-passing models currently implemented in the machine. In fact, in experiments conducted on a 16-processor partition <ref> [44] </ref>, the latency of a PUT operation in the T3D was measured at 2 sec and the peak throughput was measured at 116.8 MB/s, while the equivalent figures for PVM send/receive operations are 63 sec and 26 MB/s, respectively. 4.2 Code Transformation for the Cray T3D The code transformation algorithms for
Reference: [45] <author> Message Passing Interface Forum. </author> <title> MPI-2: Extensions to the Message-Passing Interface, </title> <month> January 12, </month> <year> 1996. </year>
Reference-contexts: In all, these facts form a more compelling argument for the importance of parallelizing compilers for distributed memory machines over UMA machines. The most common approach to program distributed memory systems is to use standard message-passing libraries <ref> [45, 49] </ref>, or - shared-memory programming models [3, 22, 27, 48, 64]. The message-passing programs based on the standard libraries are easy to port, but developing them requires sophisticated programming skills and a great deal of time because this work is usually done manually. <p> We have observed that this predicate-based run-time test is useful for various programs, such as MDG and OCEAN from the Perfect benchmarks. 2.6.2 Communication Analysis Single-sided communication protocols <ref> [24, 27, 45, 48] </ref> in the form of PUT/GET primitives have been rapidly gaining wide acceptance. A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris. <p> Another reason is that PUT/GET operations have been rapidly gaining wide acceptance. Several portable shared-memory programming models <ref> [27, 45, 48] </ref> supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon [16], and TMC CM-5 [34].
Reference: [46] <author> J. Moreira and C. Polychronopoulos. </author> <title> On the Implementation and Effectiveness of Au-toscheduling. </title> <type> Technical Report 1372, </type> <institution> Univ of Illinois at Urbana-Champaign, Cntr for Supercomputing Res & Dev, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques [14, 30, 60, 61, 73], dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling <ref> [46, 57] </ref>, and the techniques for optimizing data locality and reuse in caches [38, 40, 72].
Reference: [47] <author> A. Navarro, Y. Paek, E. Zapata, and D. Padua. </author> <title> Compiler Techniques for Effective Communication on Distributed-Memory Multiprocessors. </title> <booktitle> Proceedings of the 1997 International Conference on Parallel Processing, </booktitle> <month> August </month> <year> 1997. </year>
Reference-contexts: Although these techniques are not used to obtain the results reported in Chapter 3, they have been found helpful to further improve performance in our hand experiments <ref> [47] </ref>. 14 CHAPTER 2 ACCESS REGION ANALYSIS Communication optimization [54, 55] for distributed memory systems depends heavily on access region analysis, the analysis of array subscripting patterns in a program. There are also many other important compiler problems depending on the analysis, including dependence detection [12] and array privatization [69]. <p> In this section, we present our 112 recent study on some strategies to further improve our code transformation, as reported in a paper by the author and others <ref> [47] </ref>. 5.2.1 Redundant PUT/GET Elimination One important optimization is the reduction of communication overhead in the shared data copying scheme, which is achieved by reducing the number of PUT/GET operations.
Reference: [48] <author> J. Nielocha, R. Harrison, and R. Littlefield. </author> <title> Global Arrays: A Portable Shared-Memory Programming Model for Distributed Memory Computers. </title> <booktitle> Proceedings of Supercomputing '94, </booktitle> <pages> pages 340-349, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: In all, these facts form a more compelling argument for the importance of parallelizing compilers for distributed memory machines over UMA machines. The most common approach to program distributed memory systems is to use standard message-passing libraries [45, 49], or - shared-memory programming models <ref> [3, 22, 27, 48, 64] </ref>. The message-passing programs based on the standard libraries are easy to port, but developing them requires sophisticated programming skills and a great deal of time because this work is usually done manually. <p> We have observed that this predicate-based run-time test is useful for various programs, such as MDG and OCEAN from the Perfect benchmarks. 2.6.2 Communication Analysis Single-sided communication protocols <ref> [24, 27, 45, 48] </ref> in the form of PUT/GET primitives have been rapidly gaining wide acceptance. A great advantage of PUT/GET primitives is that their use of asynchronous data communication works well with the shared-memory programming paradigm, which is also assumed by Polaris. <p> Another reason is that PUT/GET operations have been rapidly gaining wide acceptance. Several portable shared-memory programming models <ref> [27, 45, 48] </ref> supporting PUT/GET operations already have been implemented on ordinary message-passing machines, such as the IBM SP-1/2 [37], Intel Paragon [16], and TMC CM-5 [34].
Reference: [49] <institution> Oak Ridge National Laboratory, Oak Ridge, TN. </institution> <note> PVM 3 User's Guide and Reference Manual. </note>
Reference-contexts: In all, these facts form a more compelling argument for the importance of parallelizing compilers for distributed memory machines over UMA machines. The most common approach to program distributed memory systems is to use standard message-passing libraries <ref> [45, 49] </ref>, or - shared-memory programming models [3, 22, 27, 48, 64]. The message-passing programs based on the standard libraries are easy to port, but developing them requires sophisticated programming skills and a great deal of time because this work is usually done manually.
Reference: [50] <author> W. Oed. </author> <title> The Cray Reseach Massively Parallel Processor System CRAY T3D. </title> <institution> Cray Research Inc., </institution> <year> 1993. </year>
Reference-contexts: More detailed descriptions of the machine can be found in other documents <ref> [22, 23, 24, 50] </ref>. 4.1.1 Hardware Characteristics While the lack of cache coherence in the Cray T3D helps to make the machine affordable and scalable, it also introduces some difficulties in the development of efficient programs [10]. <p> Table 4.2 summarizes the differences between CRAFT and HPF, as discussed in <ref> [50] </ref>.
Reference: [51] <author> D. Padua. </author> <title> Polaris: An Optimizing Compiler for Parallel Workstations and Scalable Multiprocessors. </title> <type> Technical Report 1475, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing Res. & Dev., </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: These algorithms have been implemented in Polaris <ref> [13, 51, 52] </ref>, a parallelizing compiler developed by the authors and others. The code transformation does not rely on directives or any other type of information from the programmer. The compiler gathers from the source code all the information needed to expose parallelism, distribute data, and control data movement.
Reference: [52] <author> D. Padua, R. Eigenmann, and J. Hoeflinger. </author> <title> Automatic Program Restructuring for Parallel Computing and the Polaris Fortran Translator. </title> <booktitle> Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> San Francisco, CA, </address> <pages> pages 647-649, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: These algorithms have been implemented in Polaris <ref> [13, 51, 52] </ref>, a parallelizing compiler developed by the authors and others. The code transformation does not rely on directives or any other type of information from the programmer. The compiler gathers from the source code all the information needed to expose parallelism, distribute data, and control data movement. <p> Further--more, the analysis helped us to determine optimization techniques to handle these performance factors. Based on these previous studies, we proposed a new approach for the code transformation which was presented in Chapters 2 and 3. Our code transformation capitalizes on the traditional compiler techniques already implemented in Polaris <ref> [13, 52] </ref>. In addition, it uses several newly developed techniques for a distributed memory architecture, such as the Access Region, the Region Test, procedure data privatization, and data localization.
Reference: [53] <author> Y. Paek, J. Hoefling, and D. Padua. </author> <title> Access Regions: Toward a Powerful Parallelizing Compiler. </title> <type> Technical Report 1508, </type> <institution> Univ. of Illinois at Urbana-Champaign, Center for Supercomputing R&D, </institution> <year> 1996. </year>
Reference-contexts: This prevents the detection of parallelism in certain loops as well as prevents efficient communication analysis for data copying. For this purpose, we have conducted an in-depth study of access patterns in many scientific benchmark programs to develop a new representation called the Access Region <ref> [53] </ref>, a generalization of traditional triplet notation. 12 Access region analysis often needs effective symbolic analysis because it must handle in its analysis many symbolic terms (for example, program variables whose values are unknown at compile time).
Reference: [54] <author> Y. Paek and D. Padua. </author> <title> Compiling for Scalable Multiprocessors with Polaris. In Parallel Processing Letters. </title> <publisher> World Scientific Publishing, </publisher> <address> UK, </address> <year> 1997. </year>
Reference-contexts: The data-partition oriented approach is particularly effective when remote memory accesses in the target machine are quite expensive. This is the case in some systems, such as loosely-coupled multicomputers, and networks of workstations. But, our experience <ref> [54] </ref> tells us that we do not have to follow this approach for several existing machines [23, 25, 32, 33] which support very low remote memory latency; although the data partition issue still remains important in these machines, we have found that it is possible to obtain reasonable speedups for a <p> Although these techniques are not used to obtain the results reported in Chapter 3, they have been found helpful to further improve performance in our hand experiments [47]. 14 CHAPTER 2 ACCESS REGION ANALYSIS Communication optimization <ref> [54, 55] </ref> for distributed memory systems depends heavily on access region analysis, the analysis of array subscripting patterns in a program. There are also many other important compiler problems depending on the analysis, including dependence detection [12] and array privatization [69]. <p> To make the loop nest parallel, we can eliminate the dependence by privatizing the array V and generating a GET for the upwards exposed use region. do I=1,M do L=I,1+M-I enddo V (K+(I-1)*N) = V (K+(I-1)*N) enddo enddo We also use PUT/GETs to implement the shared data copying scheme <ref> [54, 55] </ref> in SPMD parallel codes for distributed memory multiprocessors. In the scheme, we use shared memory as a repository of values for use in private memory. Before a parallel loop starts, the processors copy all data that is used in the loop from shared memory into private memory. <p> We will discuss how to deal with these non-privatized arrays in the next section. 3.2.4 Data Distribution and Localization We declare all non-privatized arrays as shared and BLOCK-distribute all their dimensions. Then, we apply the shared data copying scheme <ref> [54] </ref> to localize most of the accesses to these shared arrays that are made by the processors. In the scheme, shared memory is used as a repository of values for private memory, as shown in Figure 3.8.
Reference: [55] <author> Y. Paek and D. Padua. </author> <title> Automatic Parallelization for Non-cache Coherent Multiprocessors. </title> <booktitle> In Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <address> New York, New York, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: Although these techniques are not used to obtain the results reported in Chapter 3, they have been found helpful to further improve performance in our hand experiments [47]. 14 CHAPTER 2 ACCESS REGION ANALYSIS Communication optimization <ref> [54, 55] </ref> for distributed memory systems depends heavily on access region analysis, the analysis of array subscripting patterns in a program. There are also many other important compiler problems depending on the analysis, including dependence detection [12] and array privatization [69]. <p> To make the loop nest parallel, we can eliminate the dependence by privatizing the array V and generating a GET for the upwards exposed use region. do I=1,M do L=I,1+M-I enddo V (K+(I-1)*N) = V (K+(I-1)*N) enddo enddo We also use PUT/GETs to implement the shared data copying scheme <ref> [54, 55] </ref> in SPMD parallel codes for distributed memory multiprocessors. In the scheme, we use shared memory as a repository of values for use in private memory. Before a parallel loop starts, the processors copy all data that is used in the loop from shared memory into private memory.
Reference: [56] <author> D. Palermo and P. Banerjee. </author> <title> Automatic Selection of Dynamic Data Partitioning Schemes for Distributed-Memory Multicomputers. </title> <booktitle> In Lecture Notes in Computer Science, </booktitle> <pages> pages 392-406. </pages> <publisher> Springer Verlag, </publisher> <address> New York, New York, </address> <month> August </month> <year> 1995. </year> <month> 122 </month>
Reference-contexts: However, obtaining good performance from shared-memory programs still requires much work on the part of the programmer. In order to improve upon this situation, research is actively underway to automate as much as possible the process of generating efficient parallel programs <ref> [6, 8, 9, 19, 41, 56] </ref>. 4 This dissertation presents our recent work on the development of compiler algorithms to au-tomatically transform full sequential Fortran 77 codes into parallel form for distributed memory multiprocessors. <p> In some cases, these work partitioning rules may sacrifice load balancing for low communication costs and simplification of loop scheduling. Sometimes parallelism is reduced to obtain better data locality [4]. The data-partition oriented approach often involves complex data and work partitioning, plus occasional data redistribution <ref> [19, 56] </ref> which may be needed when the access patterns change. The techniques based on this approach work well on applications with a regular memory access pattern. <p> This naive distribution policy facilitates the shared data copying scheme to some extent, as discussed in Section 3.2.4. For very regular programs, however, it has often been suggested that more sophisticated data distribution policies improve performance <ref> [6, 8, 9, 19, 41, 56] </ref>. Therefore, we need to apply access sensitive data distribution strategies mainly to those regular programs.
Reference: [57] <author> C. Polychronopoulos. </author> <title> Parallel Programming and Compilers. </title> <publisher> Academic Publishers, </publisher> <address> MA, </address> <year> 1988. </year>
Reference-contexts: most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques [14, 30, 60, 61, 73], dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling <ref> [46, 57] </ref>, and the techniques for optimizing data locality and reuse in caches [38, 40, 72]. <p> We use the same loop scheduling scheme for the distributed memory architectures as Polaris currently uses for UMA architectures: cyclic schedules for triangular loops, and block schedules for square loops <ref> [57] </ref>. According to our experiments, these conventional static scheduling schemes provide relatively good load balancing between processors at low loop scheduling costs in most cases. 67 tioning module. P is the number of processors and my pid is the processor ID number between 0 and P-1.
Reference: [58] <author> C. Polychronopoulos, M. Girkar, M. Haghighat, C. Lee, B Leung, and D. Schouten. </author> <title> The structure of parafrase-2: An advanced parallelizing compiler for c and fortran. </title> <booktitle> In Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <address> New York, New York, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: In this section, we divide the multiprocessor systems into two classes, subject to their memory organization, and compare several code transformation issues of parallelizing compilers between these classes of machines. The first class of machines we consider is shared-memory multiprocessors with Uniform Memory Access (UMA) architecture. Much work <ref> [13, 43, 58, 73] </ref> has been done in recent years on automatic parallelization of conventional sequential codes for these machines.
Reference: [59] <author> W. Pottenger. </author> <title> Induction Variable Substitution and Reduction Recognition in the Polaris Parallelizing Compiler. </title> <type> Master's thesis, </type> <institution> Univ of Illinois at Urbana-Champaign, Cntr for Supercomputing Res & Dev, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: For this reason, most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques [14, 30, 60, 61, 73], dependence elimination techniques <ref> [21, 59, 69] </ref>, the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches [38, 40, 72]. <p> After a program is converted into IR form, it is analyzed and transformed by a sequence of compiler passes, the modules implemented in Polaris. The frontend passes, whose function is to identify implicit parallelism, include data dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization <ref> [14, 31, 59, 69] </ref>. To support data dependence analysis expressions with symbolic values, additional modules for powerful symbolic constant and range manipulation [12] have been implemented in Polaris. The frontend outputs the parallel program in IR form extended with annotations that identify the parallelism detected by these modules. <p> In the work presented here, we make use of both the traditional techniques based on the triplet notation and the new techniques based on the Access Region. 65 3.2.1 Parallelism Detection The techniques implemented in Polaris to detect parallelism include: dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization <ref> [14, 31, 59, 69] </ref>. Since these techniques are well documented in other places, we will not discuss them any further in this dissertation. The loops that are identified as parallel by these techniques are marked with parallel directives. <p> For the case of loops containing reductions <ref> [59, 74] </ref> it is necessary to modify the simple strategy used by Polaris for a parallel loop without reductions, as shown in Figure 3.3. cdir$ parallel (J) do J = 1, M enddo enddo The original array A in Figure 3.3 will be declared shared in the SPDM parallel code, and <p> The largest values are 0.9 for BDNA and 0.8 for MDG. This occurs because important arrays in both programs are privatized by the reduction recognition technique <ref> [59, 61] </ref> and, thus, have very few accesses to shared data.
Reference: [60] <author> W. Pugh. </author> <title> A Practical Algorithm for Exact Array Dependence Analysis. </title> <journal> Communications of the ACM, </journal> <volume> 35(8), </volume> <month> August </month> <year> 1992. </year>
Reference-contexts: For this reason, most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques <ref> [14, 30, 60, 61, 73] </ref>, dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches [38, 40, 72]. <p> To gain simplicity, Blume and Eigenmann [14] excluded the stride from the triplet notation in their dependence test, but this was at the expense of accuracy. Convex regions [26] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests <ref> [60, 67] </ref>. Balasundaram and Kennedy [7] proposed a simplified form of the convex region representation to detect task parallelism. Such representations are designed to balance their compile-time efficiency and accuracy. <p> However, forms that represent access patterns by sets of constraints typically must use a more general dependence test <ref> [60] </ref>, which is not effective for non-affine expressions. Forms that use the triplet notation cannot handle such complicated access patterns, as discussed earlier, but lend themselves to more efficient manipulation in many parts of a compiler. <p> This is generally true because several references to a single array within a loop nest are generally accessed using the same loop indices and with similar subscript expressions. Experimental evidence for the regularity and similarity of array subscripting may be gleaned from the work of others <ref> [14, 60, 66] </ref> who note that their dependence tests, built to be effective and fast specifically for regular and similar access patterns, are successful for most access patterns encountered in real scientific programs. For a more specific description of similarity and regularity, consider the example in Figure 2.4. <p> If a loss of accuracy is not allowed, then we could convert the problem of operations on access regions to an equivalent integer programming problem which different techniques based on Fourier-Motzkin variable elimination <ref> [60, 67] </ref> can handle since, as suggested in Theorem 2.3, both the problems can be interchangeably transformed. Although these integer programming techniques use worst-case exponential time algorithms, these also have proven to be efficient and successful in handling integer programming problems in real cases. <p> However, if the regions do not meet the similarity constraints, our representation allows us to simplify the regions and still use our operations, or else choose different techniques which might be a better fit <ref> [67, 60] </ref>. Since the access regions being operated on will often involve unknown values, the Region Processor is designed to proceed with the operations by making favorable assumptions, and to return the expressions representing those assumptions as conditions under which the result is correct.
Reference: [61] <author> L. Rauchwerger and D. Padua. </author> <title> The LRPD Test: Speculative Run-Time Parallelization of Loops with Privatization and Reduction Parallelization. </title> <booktitle> Proceedings of the SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: For this reason, most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques <ref> [14, 30, 60, 61, 73] </ref>, dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches [38, 40, 72]. <p> The triplet notation used by Polaris cannot support this manipulation and Polaris, therefore, simply serializes the loop. Without this mechanism, we might have to employ expensive run-time techniques <ref> [61, 63] </ref> in order to parallelize this loop. As another example, consider the loop in Figure 2.2, which can be found in FFT programs such as the TFFT2 benchmark. <p> Since intersection W (U) 1:t1:1 " W (U) t:M:1 is empty, we can prove that there is no dependence in the I-loop, thus making the loop parallel. Many compilers give up when confronted with unknown values. Run-time parallelization techniques have been proposed <ref> [61, 63] </ref> for these cases, but, until now, these have required the potentially high overhead involved in checking individual array accesses for dependence at run-time. We suggest a different approach where the conditions, which we call safe conditions, can be extracted from the code to test at run-time. <p> The largest values are 0.9 for BDNA and 0.8 for MDG. This occurs because important arrays in both programs are privatized by the reduction recognition technique <ref> [59, 61] </ref> and, thus, have very few accesses to shared data.
Reference: [62] <author> J. Reilly. </author> <title> SPEC95 Products and Benchmarks. </title> <journal> SPEC Newsletter, </journal> <month> September </month> <year> 1995. </year>
Reference-contexts: After this, we will detail each phase of the code transformation procedure shown in Figure 1.4. To evaluate the effectiveness of our techniques, we have conducted experiments on one of our target machines using various sequential codes from the SPEC95fp <ref> [62] </ref> and Perfect [11] benchmarks. We chose the Cray T3D [23] as our target machine in the experiment. In Chapter 3, the specification of the T3D and several code transformation issues that are T3D machine-dependent are first presented. <p> But, limited accuracy can prevent compiler transformations. We have found that, in some important cases, compiler techniques based on traditional access region representations are not effective due to either the inefficiency or inaccuracy of the representations. Based on our experience with the Perfect [11] and SPEC95fp <ref> [62] </ref> benchmarks, and other full scientific codes, we have developed the Access Region, a region access representation which takes advantage of the clear structure inherent in the array accesses of most scientific programs. Our design attempts to allow maximum accuracy without sacrificing efficiency. <p> B (h 1 ,...,h n ) 4.3 Benchmark Programs Table 4.3 briefly describes eleven programs that were used in our experiments. These programs come from either the SPEC95fp or the Perfect benchmarks. Detailed documents on these programs are available in <ref> [11, 62] </ref>. The table also shows the sequential execution times of each program on the Cray T3D. We used all these programs in the preliminary experiments presented in Section 4.4.
Reference: [63] <author> J. Saitz, R. Mirchandaney, and K Crowley. </author> <title> Run-time Parallelization and Scheduling of Loops. </title> <journal> IEEE Transactions on Computers, </journal> <month> May </month> <year> 1991. </year>
Reference-contexts: The triplet notation used by Polaris cannot support this manipulation and Polaris, therefore, simply serializes the loop. Without this mechanism, we might have to employ expensive run-time techniques <ref> [61, 63] </ref> in order to parallelize this loop. As another example, consider the loop in Figure 2.2, which can be found in FFT programs such as the TFFT2 benchmark. <p> Since intersection W (U) 1:t1:1 " W (U) t:M:1 is empty, we can prove that there is no dependence in the I-loop, thus making the loop parallel. Many compilers give up when confronted with unknown values. Run-time parallelization techniques have been proposed <ref> [61, 63] </ref> for these cases, but, until now, these have required the potentially high overhead involved in checking individual array accesses for dependence at run-time. We suggest a different approach where the conditions, which we call safe conditions, can be extracted from the code to test at run-time.
Reference: [64] <author> R. Schreiber. </author> <title> High Performance Fortran 2.0. </title> <booktitle> Workshop on Challenges in Compiling for Scalable Parallel Systems in conjuntion with IEEE 8th Symposium of Parallel and Distributed Processing, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: In all, these facts form a more compelling argument for the importance of parallelizing compilers for distributed memory machines over UMA machines. The most common approach to program distributed memory systems is to use standard message-passing libraries [45, 49], or - shared-memory programming models <ref> [3, 22, 27, 48, 64] </ref>. The message-passing programs based on the standard libraries are easy to port, but developing them requires sophisticated programming skills and a great deal of time because this work is usually done manually. <p> A private variable is replicated to every local memory. In contrast, only one object for each shared variable exists in the system and is accessible to all processors. Shared arrays can be given BLOCK or CYCLIC distribution, similar to those in other parallel programming models <ref> [19, 64] </ref>. PUT/GET operations will be used to implement prefetching and poststoring schemes for the control of data movement between shared memory and private memory in the data localization phase shown in Figure 1.4. <p> In our experiments, each CRAFT process was allocated to a separate physical processor. Data objects can be declared as shared or private. Shared data can be distributed across memory using directives similar to those made popular by High Performance Fortran, Vienna Fortran, and other similar languages <ref> [19, 64, 68] </ref>. CRAFT uses `:block' for block distribution and `:block (N )' for block-cyclic distribution where N is an integer. The do shared directive of CRAFT is used to mark parallel loops. To illustrate its semantics, consider the loop in Figure 4.1. <p> MPP Fortran extensions, such as CRAFT and HPF <ref> [64] </ref>, help the user attain high performance through distribution of data, while maintaining compatibility with conventional Fortran 77 or Fortran 90. However, it is very difficult to achieve total compatibility. Therefore, CRAFT diverts from several conventional language features in the name of performance.
Reference: [65] <author> SGI/Cray Research Inc. </author> <title> Origin T M and Onyx2 T M Programmer's Reference Manual, </title> <year> 1996. </year>
Reference-contexts: Although the Polaris dependence analyzers [12, 69] can handle non-affine expressions, the other complexities involved in these access patterns prevent them from privatizing X to parallelize this loop. 18 2.1.2 Communication Analysis Communication optimization for distributed memory machines, such as the Cray T3D [5, 23, 39] and the SGI Origin <ref> [65] </ref>, showed a need for gathering even more precise array access information for supporting efficient data movement and copying between distributed memories.
Reference: [66] <author> Zhiyu Shen, Zhiyuan Li, and Pen-Chung Yew. </author> <title> An Empirical Study of Fortran Programs for Parallelizing Compilers. </title> <journal> IEEE Transaction on Parallel and Distributed Systems, </journal> <volume> 1(3) </volume> <pages> 350-364, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: This is generally true because several references to a single array within a loop nest are generally accessed using the same loop indices and with similar subscript expressions. Experimental evidence for the regularity and similarity of array subscripting may be gleaned from the work of others <ref> [14, 60, 66] </ref> who note that their dependence tests, built to be effective and fast specifically for regular and similar access patterns, are successful for most access patterns encountered in real scientific programs. For a more specific description of similarity and regularity, consider the example in Figure 2.4.
Reference: [67] <author> P. Tang. </author> <title> Exact Side Effects for Interprocedural Dependence Analysis. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 102-114, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: To gain simplicity, Blume and Eigenmann [14] excluded the stride from the triplet notation in their dependence test, but this was at the expense of accuracy. Convex regions [26] express the geometrical shape of array accesses. They can be used with Fourier-Motzkin-based dependence tests <ref> [60, 67] </ref>. Balasundaram and Kennedy [7] proposed a simplified form of the convex region representation to detect task parallelism. Such representations are designed to balance their compile-time efficiency and accuracy. <p> If a loss of accuracy is not allowed, then we could convert the problem of operations on access regions to an equivalent integer programming problem which different techniques based on Fourier-Motzkin variable elimination <ref> [60, 67] </ref> can handle since, as suggested in Theorem 2.3, both the problems can be interchangeably transformed. Although these integer programming techniques use worst-case exponential time algorithms, these also have proven to be efficient and successful in handling integer programming problems in real cases. <p> However, if the regions do not meet the similarity constraints, our representation allows us to simplify the regions and still use our operations, or else choose different techniques which might be a better fit <ref> [67, 60] </ref>. Since the access regions being operated on will often involve unknown values, the Region Processor is designed to proceed with the operations by making favorable assumptions, and to return the expressions representing those assumptions as conditions under which the result is correct.
Reference: [68] <author> C. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <month> January </month> <year> 1993. </year>
Reference-contexts: The approach consists of trying to find a good data partition [41, 6] that leads to low communication costs along with maximum possible parallelism. Work partitioning or computation assignment to processors is usually done as a function of the data layout, following strategies such as the owner-compute rule <ref> [68] </ref>. In some cases, these work partitioning rules may sacrifice load balancing for low communication costs and simplification of loop scheduling. Sometimes parallelism is reduced to obtain better data locality [4]. <p> To simultaneously support powerful dependence analysis and communication analysis, a parallelizing compiler must have an efficient and flexible way of representing and manipulating memory access patterns. We found that most existing representations, such as triplet notation (also called regular section descriptor) <ref> [14, 20, 68, 70] </ref> and convex regions [7, 26] sometimes must discard critical information. This prevents the detection of parallelism in certain loops as well as prevents efficient communication analysis for data copying. <p> For access region analysis, it is necessary to represent the array accesses in some standard fashion. For instance, Tu and Padua [70] approximated access regions with the triplet notation in their array privatization work. The same notation was used by Tseng <ref> [68] </ref> and Chatterjee, and Gilbert and Long [20] for message generation. To gain simplicity, Blume and Eigenmann [14] excluded the stride from the triplet notation in their dependence test, but this was at the expense of accuracy. Convex regions [26] express the geometrical shape of array accesses. <p> Therefore, the original algorithm may be modified to choose copy-level 1 if M is found to be too small, thereby reducing copying overhead without significantly consuming private memory. Another factor affecting the determination of the copy-level is whether the data pipelin-ing technique <ref> [68, 35] </ref> can be exploited in data copying operations. If the implementation of polaris put/get routines is non-blocking, then we may exploit data pipelining. <p> In our experiments, each CRAFT process was allocated to a separate physical processor. Data objects can be declared as shared or private. Shared data can be distributed across memory using directives similar to those made popular by High Performance Fortran, Vienna Fortran, and other similar languages <ref> [19, 64, 68] </ref>. CRAFT uses `:block' for block distribution and `:block (N )' for block-cyclic distribution where N is an integer. The do shared directive of CRAFT is used to mark parallel loops. To illustrate its semantics, consider the loop in Figure 4.1.
Reference: [69] <author> P. Tu. </author> <title> Automatic Array Privatization and Demand-Driven Symbolic Analysis. </title> <type> PhD thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Dept. of Computer Science, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: For this reason, most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques [14, 30, 60, 61, 73], dependence elimination techniques <ref> [21, 59, 69] </ref>, the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches [38, 40, 72]. <p> After a program is converted into IR form, it is analyzed and transformed by a sequence of compiler passes, the modules implemented in Polaris. The frontend passes, whose function is to identify implicit parallelism, include data dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization <ref> [14, 31, 59, 69] </ref>. To support data dependence analysis expressions with symbolic values, additional modules for powerful symbolic constant and range manipulation [12] have been implemented in Polaris. The frontend outputs the parallel program in IR form extended with annotations that identify the parallelism detected by these modules. <p> There are also many other important compiler problems depending on the analysis, including dependence detection [12] and array privatization <ref> [69] </ref>. For access region analysis, it is necessary to represent the array accesses in some standard fashion. For instance, Tu and Padua [70] approximated access regions with the triplet notation in their array privatization work. <p> However, any representation which cannot handle non-affine expressions cannot represent this access region. Although the Polaris dependence analyzers <ref> [12, 69] </ref> can handle non-affine expressions, the other complexities involved in these access patterns prevent them from privatizing X to parallelize this loop. 18 2.1.2 Communication Analysis Communication optimization for distributed memory machines, such as the Cray T3D [5, 23, 39] and the SGI Origin [65], showed a need for gathering <p> 1, I, 1 enddo enddo Although we may lose accuracy of region information by the conversion to a MAY region in this example, this approximate information is no less accurate than can be represented by the triplet notation X (1:I:1,1:N:1) which can be converted to an approximate region X (1:N:1,1:N:1) <ref> [69] </ref>. <p> By subtracting the READ region from the WRITE region, we get an empty region, showing that the read region is equal to the write region regardless of the value of t. This implies that there exist anti and output dependences in the I-loop. Therefore, following the array privatization algorithm <ref> [69] </ref>, we can remove these dependences by privatizing X. Since X has no cross-iteration flow dependence in the I-loop, it no longer blocks the loop from being parallelized. The loop in Figure 2.2 is the most important in TFFT2; thus, good speedups were not possible without parallelizing this loop. <p> In the work presented here, we make use of both the traditional techniques based on the triplet notation and the new techniques based on the Access Region. 65 3.2.1 Parallelism Detection The techniques implemented in Polaris to detect parallelism include: dependence analysis, inlining, induction variable substitution, reduction recognition, and privatization <ref> [14, 31, 59, 69] </ref>. Since these techniques are well documented in other places, we will not discuss them any further in this dissertation. The loops that are identified as parallel by these techniques are marked with parallel directives. <p> Data privatization presents additional benefits in these machines by providing more chances for processors to use data caches in their computations. Data privatization in Polaris consists of two passes: loop and procedure privatizers. The loop privatizer <ref> [69] </ref> tries to find parts of a data object that are written prior to being read in each iteration of a loop.
Reference: [70] <author> P. Tu and D. Padua. </author> <title> Gated SSA-Based Demand-Driven Symbolic Analysis for Parallelizing Compilers. </title> <booktitle> Proceedings of the 9th ACM International Conference on Supercomputing, </booktitle> <pages> pages 414-423, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: To simultaneously support powerful dependence analysis and communication analysis, a parallelizing compiler must have an efficient and flexible way of representing and manipulating memory access patterns. We found that most existing representations, such as triplet notation (also called regular section descriptor) <ref> [14, 20, 68, 70] </ref> and convex regions [7, 26] sometimes must discard critical information. This prevents the detection of parallelism in certain loops as well as prevents efficient communication analysis for data copying. <p> There are also many other important compiler problems depending on the analysis, including dependence detection [12] and array privatization [69]. For access region analysis, it is necessary to represent the array accesses in some standard fashion. For instance, Tu and Padua <ref> [70] </ref> approximated access regions with the triplet notation in their array privatization work. The same notation was used by Tseng [68] and Chatterjee, and Gilbert and Long [20] for message generation. <p> The condition expressions could be evaluated at runtime, when perfect information is available, to choose between alternative transformations. The work of the Region Processor is supported by two important features of the Polaris compiler. First, the program is represented in Gated Single Assignment (GSA) form <ref> [70] </ref>. The GSA form makes it easy to determine which definition of a variable is used at any point in the program, and the conditions under which a certain definition is used.
Reference: [71] <author> S. Wallace. </author> <title> Teraflops into Laptops. </title> <booktitle> IEEE Parallel & Distributed Technologies, </booktitle> <pages> pages 8-9, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: Especially for UMA machines, academic prototypes and commercial products of the compilers have been available for many years <ref> [71] </ref>. The Polaris compiler is one of these academic prototypes developed at the University of Illinois. Like most others, the main objective of Polaris is to develop and implement effective parallelization techniques for scientific programs.
Reference: [72] <author> M. Wolf and M. Lam. </author> <title> A data locality optimizing algorithm. </title> <booktitle> In SIGPLAN NOTICES: Proceedings of the ACM SIGPLAN 91 Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Ontario, Canada, </address> <month> June 26-28, </month> <pages> pages 30-44. </pages> <publisher> ACM Press, </publisher> <year> 1991. </year> <month> 123 </month>
Reference-contexts: techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques [14, 30, 60, 61, 73], dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches <ref> [38, 40, 72] </ref>. The work on parallelizing compilers for UMA machines also has given us the foundations necessary to tackle the study of compiler algorithms for more complex classes of machines like distributed memory multiprocessors, the target of the compiler project reported in this dissertation.
Reference: [73] <author> M. Wolfe. </author> <title> Optimizing Supercompilers for Supercomputers. </title> <publisher> The MIT Press, </publisher> <address> MA, </address> <year> 1989. </year>
Reference-contexts: In this section, we divide the multiprocessor systems into two classes, subject to their memory organization, and compare several code transformation issues of parallelizing compilers between these classes of machines. The first class of machines we consider is shared-memory multiprocessors with Uniform Memory Access (UMA) architecture. Much work <ref> [13, 43, 58, 73] </ref> has been done in recent years on automatic parallelization of conventional sequential codes for these machines. <p> For this reason, most research on code transformation for UMA machines has focused on developing compiler techniques that are primarily for the frontend modules of parallelizing compilers, such as: effective dependence detection techniques <ref> [14, 30, 60, 61, 73] </ref>, dependence elimination techniques [21, 59, 69], the optimization techniques for parallel job and loop scheduling [46, 57], and the techniques for optimizing data locality and reuse in caches [38, 40, 72]. <p> LT stands for the conventional loop transformation techniques, including loop fusion, loop distribution and loop interchange <ref> [40, 73] </ref>. These techniques are useful in our approach because they help neighboring loop nests to reuse data stored in local memory. <p> One technique we have already used for this purpose is conventional loop transformation, such as loop fusion, loop distribution, and loop interchange <ref> [40, 73] </ref>. Another, yet more general, technique we consider now is redundant PUT/GET elimination. We illustrate this technique using the example in Figure 5.1.

References-found: 73

