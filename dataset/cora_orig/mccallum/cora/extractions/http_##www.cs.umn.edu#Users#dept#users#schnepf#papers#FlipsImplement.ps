URL: http://www.cs.umn.edu/Users/dept/users/schnepf/papers/FlipsImplement.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/schnepf/papers/
Root-URL: http://www.cs.umn.edu
Title: Building A Framework for FLexible Interactive Presentations  
Author: James A. Schnepf, Yen-Jen Lee, David H.C. Du, Joseph A. Konstan 
Address: Minneapolis, MN  
Affiliation: Distributed Multimedia Center Department of Computer Science University of Minnesota  
Abstract: As presentation technology advances, it is possible to incorporate a wider range of media including variable duration media such as simulations and animations. At the same time, users are able to take more control over presentations by controlling the rate and selection of media being played. To make full use of these advances, multimedia systems must support flexible presentations that incorporate many variations in the way they are played. As a result of content-based searches and other methods of selections such as a selection from an index of slides, viewers may skip to different parts of a presentation or start viewing a presentation in the middle. These presentations must remain semantically coherent in the face of these interactions. This paper presents the work we have done to design and implement a framework to support the inclusion of diverse media displayers into a presentation and to support user interaction. The implementation maintains a consistent and coherent presentation in the face of user interactions such as skipping forward and backward to different points within the presentation or modifying the speed of a single media segment. The implementation is modular and allows easy inclusion of new media types and displayers. The framework allows the displayer to control the navigation within an object (pause, fast-forward, reverse) while synchronization among objects is handled by the framework.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Schnepf, V. Mashayekhi, J. Riedl, and D. Du. </author> <title> Closing the gap in distance learning: Computer-supported, </title> <journal> participative, media-rich education. ED-TECH Review, </journal> <month> fall/winter </month> <year> 1994. </year>
Reference-contexts: The use of such presentations is particularly promising when instructors generate flexible presentations that involve students in interactive learning off campus as well as on campus <ref> [1] </ref>. Students control the pace of their learning by pausing, skipping forward and backward in the presentation, and interacting with dynamic media displayers 1 that incorporate viewer interaction into the presentation. Hypermedia objects, for example, allow a user to explore a presentation segment in greater or lesser detail.
Reference: [2] <author> Little T.D.C. etal. </author> <title> A digital on-demand video service supporting content-based queries. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 427-436. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Researchers have been developing schemes for content-based searches. Recent work on searches on video databases using metabases include the work of Little et al. <ref> [2] </ref> and Rowe et al. [3]. Row et al. have defined query interfaces that provide relational, hierarchical browsing, and keyword search operations to the metadata indices.
Reference: [3] <author> L.A. Rowe, J. S. Boreczky, and C. A. Eads. </author> <title> Indexes for user access to large video databases. In Proceedings of Storage and Retrieval for Image and Video Databases II, </title> <booktitle> IS&T/SPIE Symposium on Elec. </booktitle> <institution> Imaging Sci. & Tech., </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: Researchers have been developing schemes for content-based searches. Recent work on searches on video databases using metabases include the work of Little et al. [2] and Rowe et al. <ref> [3] </ref>. Row et al. have defined query interfaces that provide relational, hierarchical browsing, and keyword search operations to the metadata indices. But until now, there was not a reasonable way to jump into the middle of a presentation of multiple media streams based on these searches.
Reference: [4] <author> J. Schnepf, J. Konstan, and D. Du. </author> <title> Doing FLIPS: FLexible Interactive Presentation Synchronization. </title> <journal> IEEE Journal on Selected Areas in Communications. </journal> <note> To be published in special issue on multimedia synchronization. </note>
Reference-contexts: Our implementation provides the ability to view and interact with a flexible presentation that can incorporate standard media displayers as well as many nonstandard displayers such as simu 2 lations and visualizations. Our framework supports an event-based model, FLexible Interactive Presentation Synchronization (FLIPS) <ref> [4] </ref>, that can handle the synchronization of variable duration objects and a wider range of specifications than the typical binary equality relation of many models. This model, together with the enforcement mechanism, provides a richer presentation environment that supports user interaction in a multimedia presentation. <p> The entire specification is in effect a network of media objects connected by enabler and barrier links to the begin and end events of the objects. A detailed description is beyond the scope of this paper and can be found in <ref> [4] </ref>. A possible specification for the architecture example is shown in Figure 1. Enablers are represented as A ! B and barriers are shown as A a B. 3 Systems Design The FLIPS implementation is designed to support integrating external display applications for any media type into the presentation. <p> The presentation coordinator maintains the status of each object in the presentation. It maintains a valid global state in response to each event (i.e., DONE or JUMP message) by propagating changes in the network of objects until a consistent state is reached (the algorithm is described in <ref> [4] </ref>). The presentation coordinator is implemented in an event-driven manner. When an event arrives, the presentation coordinator determines a valid global state and sends STOP and START messages to the appropriate media displayers to achieve that state. This can best be understood by viewing an example.
Reference: [5] <author> L.A. Rowe and B.C. Smith. </author> <title> A continuous media player. </title> <booktitle> In Proceedings Third International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 237-249, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Fine-grain synchronization (e.g. lip-synching) is not handled directly, but is integrated by incorporating composite objects representing fine grain synchronization along with an appropriate displayer such as the Berkeley CM Player <ref> [5] </ref>. Our implementation is not an integrated display package but a presentation framework into which media objects and their displayers can easily be incorporated. It provides an enforcement mechanism that maintains a consistent and coherent playout of a presentation within the constraints specified. <p> If the slide corresponds to a different narrative, the appropriate narrative (or background music) is started. This differs from the timeline model such as is used in the CM Player <ref> [5] </ref>, where any shift in the presentation affects all the corresponding objects. In addition, each displayer could have its own user interface that allowed the viewer to control and interact with the individual object. The FLIPS model supports the specification of flexible presentations. <p> Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10].
Reference: [6] <author> T.D.C. Little and A. Ghafoor. </author> <title> Spatial-temporal composition of distributed multimedia objects for value-added networks. </title> <booktitle> IEEE Computer, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. <p> Much of this research has addressed static presentations with fixed objects of known duration [6, 7, 5, 8, 9, 10]. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal <ref> [11, 6, 7, 10] </ref>. Li, et al. [12] suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [7] <author> T.D.C. Little and A. Ghafoor. </author> <title> Synchronization and storage models for multimedia objects. </title> <journal> IEEE Journal on Selected Areas of Communications, </journal> <month> April </month> <year> 1990. </year>
Reference-contexts: Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. <p> Much of this research has addressed static presentations with fixed objects of known duration [6, 7, 5, 8, 9, 10]. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal <ref> [11, 6, 7, 10] </ref>. Li, et al. [12] suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [8] <author> B. Prabhakaran and S.V. Raghavan. </author> <title> Synchronization models for presentation with user participation. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 157-165. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10].
Reference: [9] <author> L. Hardman, G. vanRossum, and D. Bulterman. </author> <title> Structured multimedia authoring. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 283-289. </pages> <publisher> ACM, </publisher> <year> 1993. </year> <month> 11 </month>
Reference-contexts: Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10].
Reference: [10] <author> D. Wijesekera, D. Kenchamanna-Hosekote, and J. Srivastava. </author> <title> Specification, verification, and translation of multimedia compositions. </title> <type> Technical report, </type> <institution> University of Minnesota, </institution> <year> 1994. </year>
Reference-contexts: Much of this research has addressed static presentations with fixed objects of known duration <ref> [6, 7, 5, 8, 9, 10] </ref>. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. <p> Much of this research has addressed static presentations with fixed objects of known duration [6, 7, 5, 8, 9, 10]. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal <ref> [11, 6, 7, 10] </ref>. Li, et al. [12] suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [11] <author> A. Poggio. CCWS: </author> <title> A computer-based multimedia information system. </title> <booktitle> IEEE Computer, </booktitle> <month> Oct </month> <year> 1985. </year>
Reference-contexts: Much of this research has addressed static presentations with fixed objects of known duration [6, 7, 5, 8, 9, 10]. In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal <ref> [11, 6, 7, 10] </ref>. Li, et al. [12] suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [12] <author> L. Li, A. Karmouch, </author> <title> and N.D. Georganas. Multimedia teleorchestra with independent sources: Part 1 temporal modeling of collaborative multimedia scenarios. </title> <journal> ACM Multimedia Systems, </journal> <volume> 1(1) </volume> <pages> 143-153, </pages> <year> 1994. </year>
Reference-contexts: In many schemes, if two sets of objects are specified to be displayed in parallel, their durations not only must be known, but must be exactly equal [11, 6, 7, 10]. Li, et al. <ref> [12] </ref> suggest that this expectation is unreasonable since the duration information may not be known at the time of specification.
Reference: [13] <author> G. Blakowski et al. </author> <title> Tool support for the synchronization and presentation of distributed multimedia. </title> <journal> Computer Communications, </journal> <volume> 15(10) </volume> <pages> 611-618, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project <ref> [13] </ref>, Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. <ref> [13, 15, 17, 18] </ref> all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [14] <author> M. C. Buchanan and P. T. Zellweger. </author> <title> Scheduling multimedia documents using temporal constraints. </title> <booktitle> In Proceedings Third International Workshop on Network and Operating Systems Support for Digital Audio and Video, </booktitle> <pages> pages 237-249, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly <ref> [14] </ref>, CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Drapeau in [16] allows for varied media displayers to be incorporated, but these applications must be modified to work with the Maestro system. The work of Buchanan and Zellweger <ref> [14] </ref> is the closest to ours. They also handle variable duration objects and asynchronous events such as user interactions. Their scheme differs from ours in their mapping of events to a timeline.
Reference: [15] <author> G. van Rossum, J. Jansen, K. Mullender, and D. Bulterman. CMIFed: </author> <title> A presentation system for portable hypermedia documents. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 183-188. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed <ref> [15] </ref>, Maestro [16], Xavier [17], and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. <ref> [13, 15, 17, 18] </ref> all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [16] <author> G. Drapeau. </author> <title> Synchronization in the maestro multimedia authoring environment. </title> <booktitle> In Proceedings of ACM Multimedia 93, </booktitle> <pages> pages 331-339. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro <ref> [16] </ref>, Xavier [17], and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. As in the models discussed above, the support of user interaction and skips presume that all concurrent media are affected by a jump. Drapeau in <ref> [16] </ref> allows for varied media displayers to be incorporated, but these applications must be modified to work with the Maestro system. The work of Buchanan and Zellweger [14] is the closest to ours. They also handle variable duration objects and asynchronous events such as user interactions.
Reference: [17] <author> R. Hamakawa and J. Rekimoto. </author> <title> Object composition and playback models for handling multimedia data. </title> <journal> ACM Multimedia Systems, </journal> <volume> 2(1) </volume> <pages> 26-35, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier <ref> [17] </ref>, and Eventor [18]. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. <ref> [13, 15, 17, 18] </ref> all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
Reference: [18] <author> S.Eun, E.S. No, H.C. Kim, H. Yoon, and S. R. Maeng. Eventor: </author> <title> and authoring system for interactive multimedia applications. </title> <journal> ACM Multimedia Systems, </journal> <volume> 2(3) </volume> <pages> 129-140, </pages> <month> September </month> <year> 1994. </year> <month> 12 </month>
Reference-contexts: Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor <ref> [18] </ref>. [13, 15, 17, 18] all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types. <p> Implementations for coarse grain synchronization have been built by several research groups including the MODE project [13], Firefly [14], CMIFed [15], Maestro [16], Xavier [17], and Eventor [18]. <ref> [13, 15, 17, 18] </ref> all provide media displayers built into the presentation system. While this supports efficient implementations, it does not allow for quick and easy incorporation of new and varied media types.
References-found: 18

