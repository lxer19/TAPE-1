URL: http://www.cs.jhu.edu/~goodrich/pubs/cover.ps.gz
Refering-URL: http://www.cs.jhu.edu/~goodrich/pubs/index.html
Root-URL: http://www.cs.jhu.edu
Email: E-mail: hbr@cs.princeton.edu  E-mail: goodrich@cs.jhu.edu  
Title: Almost Optimal Set Covers in Finite VC-Dimension  
Author: Herv e Br onnimann Michael T. Goodrich 
Address: Princeton, NJ 08544, USA  Baltimore, MD 21218, USA  
Affiliation: Department of Computer Science Princeton University  Department of Computer Science Johns Hopkins University  
Abstract: We give a deterministic polynomial time method for finding a set cover in a set system (X; R) of VC-dimension d such that the size of our cover is at most a factor of O(d log(dc)) from the optimal size, c. For constant VC-dimension set systems, which are common in computational geometry, our method gives an O(log c) approximation factor. This improves the previous fi(log jXj) bound of the greedy method and challenges recent complexity-theoretic lower bounds for set covers (which don't make any assumptions about VC-dimension). We give several applications of our method to computational geometry, and we show that in some cases, such as those that arise in 3-d polytope approximation and 2-d disc covering, we can quickly find O(c)-sized covers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. M. Arkin, H. Meijer, J. S. B. Mitchell, D. Rappaport, and S. S. Skiena. </author> <title> Decision trees for geometric models. </title> <booktitle> In Proc. 9th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 369-378, </pages> <year> 1993. </year>
Reference-contexts: The aforementioned result shows that s d, but equality does not always occur, as there are systems in which the VC-exponent is non integral [2]. However, the VC-dimension is finite if and only if the VC-exponent is finite as well; s never takes values in the interval <ref> [0; 1] </ref>, and it is 0 if and only if R is finite [2] (whereas d is 0 if and only if R consists of one set). In particular, the VC-exponent concept only makes sense for an infinite set system, whereas the VC-dimension is more general. <p> Note that this is still O (n 4 log n), whereas the time consumed by the greedy method is O (n 4 ) (though Mitchell and Suri reduce it to O (n 3 ) when both polyhedra are convex.) 5.2 Decision Trees In <ref> [1] </ref>, Arkin et al. describe how to construct a point-probe decision tree for a set of non-degenerate polygons in the plane whose height is s 1 + dlog (k=(s 1))e, when given a hitting set of size s. <p> For some applications, the result serves to decide the position of a polygon in a scene <ref> [1] </ref>. While their approach is more general, the next result shows that we can get better performance ratio in the height of a decision tree for non-degenerate (i.e., general position) inputs. <p> This is implied by the fact that the p I 's are in general position (no three (I)'s form an arithmetic progression). Therefore S itself is shattered by its point set system. 9 Our algorithm, combined with the above observation, and the result of Arkin et al. <ref> [1] </ref> gives us a decision tree of smaller asymptotic depth than the greedy method for the non-degenerate arrangement of Arkin et al. 5 Moreover, our method can also be used to derive point-probe decision trees of improved depth for any set of general-position k-gons in the plane, for constant k, since
Reference: [2] <author> P. Assouad. </author> <title> Densite et dimension. Ann. Institut Fourier, </title> <journal> Grenoble, </journal> <volume> 3 </volume> <pages> 232-282, </pages> <year> 1983. </year>
Reference-contexts: For references, the reader is referred to the original paper by Vapnik and Cervonenkis [44] (from whom have derived the VC-initials ), or to the survey by Assouad <ref> [2] </ref>. Let (X; R) be a given set system. Given Y X, all the subsets of Y obtained as the intersection of Y and R ranging over R, form a set system called the system induced by R on Y , and denoted by R jY . <p> The aforementioned result shows that s d, but equality does not always occur, as there are systems in which the VC-exponent is non integral <ref> [2] </ref>. However, the VC-dimension is finite if and only if the VC-exponent is finite as well; s never takes values in the interval [0; 1], and it is 0 if and only if R is finite [2] (whereas d is 0 if and only if R consists of one set). <p> not always occur, as there are systems in which the VC-exponent is non integral <ref> [2] </ref>. However, the VC-dimension is finite if and only if the VC-exponent is finite as well; s never takes values in the interval [0; 1], and it is 0 if and only if R is finite [2] (whereas d is 0 if and only if R consists of one set). In particular, the VC-exponent concept only makes sense for an infinite set system, whereas the VC-dimension is more general. <p> In this system X is taken as a set of halfspaces in IR d and R is taken to be all combinatorially distinct ways if intersecting halfspaces in X by a simplex. It is well known (e.g., see <ref> [2] </ref>) that this system has a VC-dimension and a VC-exponent of d. The dual set system (R; X fl ) is defined by X fl = fR x : x 2 Xg, where R x consists of all the sets R 2 R that contain x. <p> It is also well known (e.g., see <ref> [2] </ref>) that the VC-dimension d fl of the dual (R; X fl ) is less than 2 d+1 , where d is the VC-dimension of the primal (X; R). Let (X; R) be a set system. <p> B) runs in T A (resp. T B ) time. That is, A run on input (X; R), w and r returns a net in T A (size (X; R); length (w); r) 1 This value has also gone by the names real density <ref> [2] </ref> and scaffold dimension [24]. 2 The term additive refers to the fact that w (Y ) = P y2Y w (y), with the usual abuse of notation w (y) = w (fyg). 3 Throughout the literature in computational geometry, the unit-cost (or real RAM) model is usually assumed.
Reference: [3] <author> E. Baum. </author> <title> On learning the union of halfspaces. </title> <journal> J. Compl., </journal> <volume> 6 </volume> <pages> 67-101, </pages> <year> 1990. </year>
Reference-contexts: However, Baum <ref> [3] </ref> argues that this only shows that we should look for hypotheses with more halfspaces. Indeed, Blumer et al. [7] and Baum [3] have proposed algorithms that output a hypothesis of size O (s log m). <p> However, Baum <ref> [3] </ref> argues that this only shows that we should look for hypotheses with more halfspaces. Indeed, Blumer et al. [7] and Baum [3] have proposed algorithms that output a hypothesis of size O (s log m). These algorithms are polynomial in fixed dimension (however, the dependence in the dimension is exponential).
Reference: [4] <author> M. Bellare, S. Goldwasser, C. Lund, and A. Russel. </author> <title> Efficient probabilistically checkable proofs and applications to approximation. </title> <booktitle> In Proc. 25th Annu. ACM Symp. Theory Comput., </booktitle> <pages> pages 294-304, </pages> <year> 1993. </year>
Reference-contexts: Yannakakis [33] have recently shown that, unless NP DTIME [n poly log n ], no polynomial time algorithm can approximate Set Cover within a factor better than ff = 1 4 ln jXj in the worst case, and, unless NP DTIME [n O (log log n) ], Bellare et al. <ref> [4] </ref> showed that no polynomial time algorithm can approximate Set Cover within a factor better than ff = ffi ln jXj in the worst case, for any constant ffi &lt; 1=8. Our results. <p> Thus, for set systems with bounded VC-exponent, we challenge the complexity-theoretic lower bounds of <ref> [4, 33] </ref> (which make no assumptions about the VC-exponent). In section 4, we indicate some examples on which Hochbaum's method [26] or the greedy methods [17, 28, 32] perform poorly, and show that our method outperforms them in some cases. <p> For example, if there is a constant sized hitting set, the algorithm runs in linear time. Furthermore, our algorithm seems to defeat known complexity-theoretic lower bounds <ref> [4, 33] </ref> (which make no assumptions about the VC-exponent), by being adaptive: the competitive ratio depends on the size of the optimal solution. However, the proof methods of [4, 33] require (to the best of our understanding) that the optimal hitting set is large. <p> Furthermore, our algorithm seems to defeat known complexity-theoretic lower bounds <ref> [4, 33] </ref> (which make no assumptions about the VC-exponent), by being adaptive: the competitive ratio depends on the size of the optimal solution. However, the proof methods of [4, 33] require (to the best of our understanding) that the optimal hitting set is large. It is thus not clear what the applicability of their results to ours is.
Reference: [5] <author> B. Berger, J. Rompel, and P. W. Shor. </author> <title> Efficient NC algorithms for set cover with applications to learning and geometry. </title> <booktitle> In Proc. 30th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <volume> volume 30, </volume> <pages> pages 54-59, </pages> <year> 1989. </year>
Reference: [6] <author> A. Blum and R. Rivest. </author> <title> Training a 3-node neural network is NP -complete. </title> <booktitle> In Proc. 1st Workshop Comput. Learning Theory, </booktitle> <pages> pages 9-18, </pages> <year> 1988. </year>
Reference-contexts: This ensures that, for subsequent examples, the label as computed with G will be correct (according to H) with probability at least 1 ". It has been proved by Blum and Rivest <ref> [6] </ref> that this problem admits no proper learning algorithm (for which the hypothesis also consists of s halfspaces) whose running time is polynomial in d, s, " 1 , ffi 1 , even if s = 2 (unless P = NP).
Reference: [7] <author> A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. </author> <title> Classifying learnable geometric concepts with the Vapnik-Chervonenkis dimension. </title> <journal> J. ACM, </journal> <volume> 36 </volume> <pages> 929-965, </pages> <year> 1989. </year>
Reference-contexts: As has been observed by Haussler and Welzl [25], set systems of VC-dimension d admit (1=r)-nets of size O (dr log (dr)). This bound has been improved by Blumer et al. <ref> [7] </ref> to O (dr log r) and this has been proved tight by Komlos et al. [30]. We can generalize this definition by putting an additive 2 weight function w on 2 X . <p> However, Baum [3] argues that this only shows that we should look for hypotheses with more halfspaces. Indeed, Blumer et al. <ref> [7] </ref> and Baum [3] have proposed algorithms that output a hypothesis of size O (s log m). These algorithms are polynomial in fixed dimension (however, the dependence in the dimension is exponential).
Reference: [8] <author> H. Bronnimann. </author> <title> Almost optimal polyhedral separators (Video). </title> <booktitle> In Proc. 10th Annu. ACM Symp. </booktitle> <institution> Comput. Geom., page not yet communicated, </institution> <year> 1994. </year>
Reference-contexts: Thus we could make the algorithm faster (for the same guaranteed ratio) by switching to the greedy method when c becomes too large. The algorithm of Theorem 5.2 has been animated into a video <ref> [8] </ref>, and Figure 2 shows snapshots illustrating different stages. But in three dimensions, we can actually do much better.
Reference: [9] <author> H. Bronnimann. </author> <title> An implementation of Min Hitting Set heuristics. </title> <type> Manuscript, </type> <year> 1994. </year>
Reference-contexts: The result, of course, is also valid for learning the union of concepts taken from a concept class that has finite VC-dimension. 6 Experimental Results Our algorithm has been implemented and the results will be described in <ref> [9] </ref>. There are many possible choices for implementation, as we have many ways to compute an "-net in practice, and they result in different performances. The first consists in choosing a random sample of size O (dc log c).
Reference: [10] <author> H. Bronnimann, B. Chazelle, and J. Matousek. </author> <title> Product range spaces, sensitive sampling, </title> <booktitle> and derandomization. In Proc. 34th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 400-409, </pages> <year> 1993. </year>
Reference-contexts: If (X; R) has a subsystem oracle of degree D, and VC-exponent d, it is clear that d D. Under this assumption, it has also been shown by Matousek et al. <ref> [36, 10] </ref> that one can find a (1=r)-net for (X; R) of size O (dr log (dr)) in O (d) 3D r D log D (rd)jXj time, for both the uniform and weighted cases. 3 The Main Algorithm The goal of this section is to prove our main theorem. <p> But one can find a (1=r)-net for (X; R) of size O (dr log (dr)) in O (d) 3D r D log D (rd)jXj time, for both the uniform and weighted cases, using the algorithm of <ref> [10] </ref>, in the real RAM model. In the bit model, the complexity of the weights should be taken into account, which may add at most an O (c log (jXj=c)) factor to the running time, as proved in the next section. <p> Therefore our hope is to find an net finder of size s, where s (x) = O (dx log (dx)). To find a (1=r)-net for the weighted cover set system, we simply use the algorithm of <ref> [10] </ref>, which computes a weighted (1=r)-net in O (nr d log d (dr)) time, using the reduction of Section 3.2 to take care of the weighted case. <p> The second possible choice is to use a computed "-net, with the algorithm of <ref> [10] </ref>, and this seems to yield results comparable to the greedy method. The third method of choice is to compute the net using the greedy method [14].
Reference: [11] <author> B. Chazelle. </author> <title> An optimal convex hull algorithm and new results on cuttings. </title> <booktitle> In Proc. 32nd Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 29-38, </pages> <year> 1991. </year>
Reference: [12] <author> B. Chazelle. </author> <title> Cutting hyperplanes for divide-and-conquer. </title> <journal> Discrete Comput. Geom., </journal> <volume> 9(2) </volume> <pages> 145-158, </pages> <year> 1993. </year>
Reference: [13] <author> B. Chazelle, H. Edelsbrunner, M. Grigni, L. Guibas, and M. Sharir. </author> <title> Improved bounds on weak "-nets for convex sets. </title> <booktitle> In Proc. 25th Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 495-504, </pages> <year> 1993. </year>
Reference: [14] <author> B. Chazelle and J. Friedman. </author> <title> A deterministic view of random sampling and its use in geometry. </title> <journal> Combinatorica, </journal> <volume> 10(3) </volume> <pages> 229-249, </pages> <year> 1990. </year>
Reference-contexts: The time taken by A is O (c log (n=c) (T A (nm; n log (n=c); c) + T B (nm; c)). If X has finite VC-dimension, then we may implement the net finder using the greedy method <ref> [14] </ref>, and the verifier by inspecting all of (X; R), both in polynomial time (in either the real RAM or bit models). But under standard computational assumptions, there are better implementations of the net finder and verifier. <p> The second possible choice is to use a computed "-net, with the algorithm of [10], and this seems to yield results comparable to the greedy method. The third method of choice is to compute the net using the greedy method <ref> [14] </ref>. Even though this does not guarantee the same performance as the second choice, it performs well in practice, and never returns anything bigger than that returned by the greedy set cover method.
Reference: [15] <author> B. Chazelle and J. Matousek. </author> <title> On linear-time deterministic algorithms for optimization problems in fixed dimension. </title> <booktitle> In Proc. 4th ACM-SIAM Sympos. Discrete Algorithms, </booktitle> <pages> pages 281-290, </pages> <year> 1993. </year> <month> 12 </month>
Reference-contexts: concept, by requiring that for all finite Y X we have jR jY j = O 0 + + jY j which is also O (jY j=d+1) d , then we can reduce the size of the hitting set to O (dc log c), as observed by Chazelle and Matousek <ref> [15] </ref>. (2) For a particular c, the algorithm will either say that there is no hitting set of size c, or it will output a hitting set of size O (dc log (dc)), which, of course, is different than saying that there is a hitting set of size c. (3) The
Reference: [16] <author> B. Chazelle and E. Welzl. </author> <title> Quasi-optimal range searching in spaces of finite VC-dimension. </title> <journal> Discrete Comput. Geom., </journal> <volume> 4 </volume> <pages> 467-489, </pages> <year> 1989. </year>
Reference: [17] <author> V. Chvatal. </author> <title> A greedy heuristic for the set-covering problem. </title> <journal> Math. Oper. Res., </journal> <volume> 4 </volume> <pages> 233-235, </pages> <year> 1979. </year>
Reference-contexts: The only known polynomial-time approximations algorithms for Set Cover with guaranteed performance ratios are the greedy algorithm <ref> [17, 28, 32] </ref>, which achieves an approximation factor of ff = (1 + ln A), where A denotes the size of the largest set in fl Supported in part by NSF Grant CCR-90-02352 and Ecole Normale Superieure. y This research supported by the NSF and DARPA under Grant CCR-8908092, and by <p> Thus, for set systems with bounded VC-exponent, we challenge the complexity-theoretic lower bounds of [4, 33] (which make no assumptions about the VC-exponent). In section 4, we indicate some examples on which Hochbaum's method [26] or the greedy methods <ref> [17, 28, 32] </ref> perform poorly, and show that our method outperforms them in some cases. Our algorithm, which is actually for the dual Hitting Set problem, is based upon a deterministic analogue of a randomized natural selection technique used by Clarkson [18, 19], Littlestone [31], and Welzl [45].
Reference: [18] <author> K. L. Clarkson. </author> <title> A Las Vegas algorithm for linear programming when the dimension is small. </title> <booktitle> In Proc. 29th Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 452-456, </pages> <year> 1988. </year>
Reference-contexts: Our algorithm, which is actually for the dual Hitting Set problem, is based upon a deterministic analogue of a randomized natural selection technique used by Clarkson <ref> [18, 19] </ref>, Littlestone [31], and Welzl [45]. <p> Lemma 3.4 If there is a hitting set of size c, the doubling process cannot iterate more than 4c log (n=c) times, and the total weight will not exceed n 4 =c 3 . Proof: Our proof follows arguments of Clarkson <ref> [18, 19] </ref>, Littlestone [31], and Welzl [45]. Let H be a hitting set of size c. Because the set R returned by B at each iteration satisfies w (R) w (X)=2c, the weight of X is not multiplied by more than a factor 1 + 1=2c in any iteration.
Reference: [19] <author> K. L. Clarkson. </author> <title> Algorithms for polytope covering and approximation. </title> <booktitle> In Proc. 3rd Workshop Algorithms Data Struct., volume 709 of Lecture Notes in Computer Science, </booktitle> <pages> pages 246-252. </pages> <publisher> Springer Verlag, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Our algorithm, which is actually for the dual Hitting Set problem, is based upon a deterministic analogue of a randomized natural selection technique used by Clarkson <ref> [18, 19] </ref>, Littlestone [31], and Welzl [45]. <p> Lemma 3.4 If there is a hitting set of size c, the doubling process cannot iterate more than 4c log (n=c) times, and the total weight will not exceed n 4 =c 3 . Proof: Our proof follows arguments of Clarkson <ref> [18, 19] </ref>, Littlestone [31], and Welzl [45]. Let H be a hitting set of size c. Because the set R returned by B at each iteration satisfies w (R) w (X)=2c, the weight of X is not multiplied by more than a factor 1 + 1=2c in any iteration. <p> Therefore the greedy strategy returns a polyhedron within O (d 2 log jQj) of the optimal. In a recent twist, Clarkson <ref> [19] </ref> applies ideas he used for small-dimensional linear programming to give a polynomial-time randomized method that produces an approximation within O (d 2 log (dc)) of the optimal c. In fact, the algorithm of this paper is a deterministic analogue of Clarkson's method in our more general framework 4 . <p> We have exhibited a variety of computational geometry problems that reduce to or use hitting sets, and for which the set systems have bounded VC-dimension. Interestingly enough, the algorithm was prompted by one of these problems for which Clarkson gave a randomized algorithm <ref> [19] </ref> (which is essentially the same as ours except that the net is picked as a random sample). 11 Our algorithm has been implemented, and the practical results are encouraging.
Reference: [20] <author> K. L. Clarkson and P. W. Shor. </author> <title> Applications of random sampling in computational geometry, II. </title> <journal> Discrete Comput. Geom., </journal> <volume> 4 </volume> <pages> 387-421, </pages> <year> 1989. </year>
Reference: [21] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: There are a host of NP-hard problems defined on set systems, with one of the chief such problems being that of finding a set cover of minimum size (e.g., see <ref> [21, 23] </ref>), where a set cover is a subcollection C R whose union is X and the size of C is simply the number of sets in C.
Reference: [22] <author> G. Das. </author> <title> Approximation schemes in computational geometry. </title> <type> Ph.D. thesis, </type> <institution> University of Wisconsin, </institution> <year> 1990. </year>
Reference-contexts: The problem of finding a separator polytope between P and Q with as few facets as possible is believed to be NP-hard, even in the three-dimensional case <ref> [22] </ref>, but one can find good approximations for it. Mitchell and Suri cast the problem as a hitting set problem [42]. Let H = H (Q) denote the set of supporting hyperplanes of Q.
Reference: [23] <author> M. R. Garey and D. S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> New York, NY, </address> <year> 1979. </year>
Reference-contexts: There are a host of NP-hard problems defined on set systems, with one of the chief such problems being that of finding a set cover of minimum size (e.g., see <ref> [21, 23] </ref>), where a set cover is a subcollection C R whose union is X and the size of C is simply the number of sets in C. <p> Thus, our interest is in finding minimum set covers and smallest hitting sets as quickly as possible. Unfortunately, the corresponding decision problems, Set Cover and Hitting Set, as we will call them, are both NP-complete <ref> [23, 29] </ref>. Moreover, even if each element of X is contained in just two sets, the Hitting Set problem is still NP-complete [29] (and is known as Vertex-Cover).
Reference: [24] <author> M. T. Goodrich. </author> <title> Geometric partitioning made easier, even in parallel. </title> <booktitle> In Proc. 9th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 73-82, </pages> <year> 1993. </year>
Reference-contexts: B) runs in T A (resp. T B ) time. That is, A run on input (X; R), w and r returns a net in T A (size (X; R); length (w); r) 1 This value has also gone by the names real density [2] and scaffold dimension <ref> [24] </ref>. 2 The term additive refers to the fact that w (Y ) = P y2Y w (y), with the usual abuse of notation w (y) = w (fyg). 3 Throughout the literature in computational geometry, the unit-cost (or real RAM) model is usually assumed.
Reference: [25] <author> D. Haussler and E. Welzl. </author> <title> "-nets and simplex range queries. </title> <journal> Discrete Comput. Geom., </journal> <volume> 2 </volume> <pages> 127-151, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction A set system (X; R) is a set X along with a collection R of subsets of X, which are sometimes called ranges <ref> [25] </ref>. Such entities have also been called hypergraphs and range spaces in the computational geometry literature (e.g., see [5, 10, 11, 12, 13, 14, 15, 16, 20, 24, 25, 34, 36, 35, 41, 37, 39, 40]), and they can be used to model a number of interesting computational geometry problems. <p> This technique can be viewed as "algorithmic Darwinism," for we iteratively select, in polynomial-time, a small-sized subset of X (known in the literature as an "-net <ref> [25] </ref>) that intersects all highly-weighted sets in R, and, if this set is not a hitting set, then we increase the weight of the elements in an R 2 R missed by this set. <p> Let (X; R) be a set system. If a subset N X intersects each set R 2 R of size bigger than "jXj, then we call N an "-net <ref> [25] </ref>. As has been observed by Haussler and Welzl [25], set systems of VC-dimension d admit (1=r)-nets of size O (dr log (dr)). This bound has been improved by Blumer et al. [7] to O (dr log r) and this has been proved tight by Komlos et al. [30]. <p> Let (X; R) be a set system. If a subset N X intersects each set R 2 R of size bigger than "jXj, then we call N an "-net <ref> [25] </ref>. As has been observed by Haussler and Welzl [25], set systems of VC-dimension d admit (1=r)-nets of size O (dr log (dr)). This bound has been improved by Blumer et al. [7] to O (dr log r) and this has been proved tight by Komlos et al. [30].
Reference: [26] <author> D. S. Hochbaum. </author> <title> Approximation algorithms for the set covering and vertex cover problems. </title> <journal> SIAM J. Comput., </journal> <volume> 11(3) </volume> <pages> 555-556, </pages> <year> 1982. </year>
Reference-contexts: R, and an algorithm of Hochbaum <ref> [26] </ref>, which achieves an approximation factor of ff = max x2X fjR x jg, where R x denotes the set of all R 2 R containing x. <p> Thus, for set systems with bounded VC-exponent, we challenge the complexity-theoretic lower bounds of [4, 33] (which make no assumptions about the VC-exponent). In section 4, we indicate some examples on which Hochbaum's method <ref> [26] </ref> or the greedy methods [17, 28, 32] perform poorly, and show that our method outperforms them in some cases.
Reference: [27] <author> D. S. Hochbaum and W. Maas. </author> <title> Approximation schemes for covering and packing problems in image processing and VLSI. </title> <journal> J. ACM, </journal> <volume> 32 </volume> <pages> 130-136, </pages> <year> 1985. </year>
Reference-contexts: The disc cover problem is to find a minimum number of discs in D that cover the points in S <ref> [27] </ref>. This problem is motivated by VLSI design criteria as well as viewing problems in astronomy. Matousek et al. [39] show that this set system admits O (r) sized (1=r)-net and, as indicated in Section 3.2, one can extend their algorithm to weighted point sets. <p> Note that our method never takes more than O (n 3 log n) time. This bound contrasts the bound of Hochbaum and Maas <ref> [27] </ref> for finding a constant-factor approximation to a disc cover, as their method requires all the discs in D to have the same radius and, even when all the parameters in their method are optimized for the running time, their method takes O (n 5 ) time. 5.4 Learning a Union
Reference: [28] <author> D. S. Johnson. </author> <title> Approximation algorithms for combinatorial problems. </title> <journal> J. Comput. Syst. Sci., </journal> <volume> 9 </volume> <pages> 256-278, </pages> <year> 1974. </year>
Reference-contexts: The only known polynomial-time approximations algorithms for Set Cover with guaranteed performance ratios are the greedy algorithm <ref> [17, 28, 32] </ref>, which achieves an approximation factor of ff = (1 + ln A), where A denotes the size of the largest set in fl Supported in part by NSF Grant CCR-90-02352 and Ecole Normale Superieure. y This research supported by the NSF and DARPA under Grant CCR-8908092, and by <p> Note that in the former case ff can be as large as (1 + ln jXj) and in the latter ff can be as large as jRj. Thus, as worst case bounds, the greedy algorithm achieves the best approximation factor, and Johnson <ref> [28] </ref> shows there are set systems where the greedy algorithm does indeed produce a set cover with approximation factor ff = (ln jXj + 1). <p> Thus, for set systems with bounded VC-exponent, we challenge the complexity-theoretic lower bounds of [4, 33] (which make no assumptions about the VC-exponent). In section 4, we indicate some examples on which Hochbaum's method [26] or the greedy methods <ref> [17, 28, 32] </ref> perform poorly, and show that our method outperforms them in some cases. Our algorithm, which is actually for the dual Hitting Set problem, is based upon a deterministic analogue of a randomized natural selection technique used by Clarkson [18, 19], Littlestone [31], and Welzl [45].
Reference: [29] <author> R. M. Karp. </author> <title> Reducibility among combinatorial problems. </title> <editor> In R. E. Miller and J. W. Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pages 85-103. </pages> <publisher> Plenum Press, </publisher> <address> New York, NY, </address> <year> 1972. </year>
Reference-contexts: Thus, our interest is in finding minimum set covers and smallest hitting sets as quickly as possible. Unfortunately, the corresponding decision problems, Set Cover and Hitting Set, as we will call them, are both NP-complete <ref> [23, 29] </ref>. Moreover, even if each element of X is contained in just two sets, the Hitting Set problem is still NP-complete [29] (and is known as Vertex-Cover). <p> Unfortunately, the corresponding decision problems, Set Cover and Hitting Set, as we will call them, are both NP-complete [23, 29]. Moreover, even if each element of X is contained in just two sets, the Hitting Set problem is still NP-complete <ref> [29] </ref> (and is known as Vertex-Cover).
Reference: [30] <author> J. Komlos, J. Pach, and G. Woeginger. </author> <title> Almost tight bounds for "-nets. </title> <journal> Discrete Comput. Geom., </journal> <volume> 7 </volume> <pages> 163-173, </pages> <year> 1992. </year>
Reference-contexts: As has been observed by Haussler and Welzl [25], set systems of VC-dimension d admit (1=r)-nets of size O (dr log (dr)). This bound has been improved by Blumer et al. [7] to O (dr log r) and this has been proved tight by Komlos et al. <ref> [30] </ref>. We can generalize this definition by putting an additive 2 weight function w on 2 X . In this formulation, an "-net is required to intersect every set of weight at least "w (X).
Reference: [31] <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithms. </title> <booktitle> In Proc. 28th IEEE Symp. Found. of Comput. Sci., </booktitle> <pages> pages 68-77, </pages> <year> 1987. </year>
Reference-contexts: Our algorithm, which is actually for the dual Hitting Set problem, is based upon a deterministic analogue of a randomized natural selection technique used by Clarkson [18, 19], Littlestone <ref> [31] </ref>, and Welzl [45]. <p> Lemma 3.4 If there is a hitting set of size c, the doubling process cannot iterate more than 4c log (n=c) times, and the total weight will not exceed n 4 =c 3 . Proof: Our proof follows arguments of Clarkson [18, 19], Littlestone <ref> [31] </ref>, and Welzl [45]. Let H be a hitting set of size c. Because the set R returned by B at each iteration satisfies w (R) w (X)=2c, the weight of X is not multiplied by more than a factor 1 + 1=2c in any iteration.
Reference: [32] <author> L. Lovasz. </author> <title> On the ratio of optimal integral and fractional covers. </title> <journal> Discrete Math., </journal> <volume> 13 </volume> <pages> 383-390, </pages> <year> 1975. </year>
Reference-contexts: The only known polynomial-time approximations algorithms for Set Cover with guaranteed performance ratios are the greedy algorithm <ref> [17, 28, 32] </ref>, which achieves an approximation factor of ff = (1 + ln A), where A denotes the size of the largest set in fl Supported in part by NSF Grant CCR-90-02352 and Ecole Normale Superieure. y This research supported by the NSF and DARPA under Grant CCR-8908092, and by <p> Thus, for set systems with bounded VC-exponent, we challenge the complexity-theoretic lower bounds of [4, 33] (which make no assumptions about the VC-exponent). In section 4, we indicate some examples on which Hochbaum's method [26] or the greedy methods <ref> [17, 28, 32] </ref> perform poorly, and show that our method outperforms them in some cases. Our algorithm, which is actually for the dual Hitting Set problem, is based upon a deterministic analogue of a randomized natural selection technique used by Clarkson [18, 19], Littlestone [31], and Welzl [45].
Reference: [33] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <booktitle> In Proc. 25th Annu. ACM Symp. Theory Comput., </booktitle> <pages> pages 286-293, </pages> <year> 1993. </year>
Reference-contexts: Thus, as worst case bounds, the greedy algorithm achieves the best approximation factor, and Johnson [28] shows there are set systems where the greedy algorithm does indeed produce a set cover with approximation factor ff = (ln jXj + 1). Interestingly, Lund and Yannakakis <ref> [33] </ref> have recently shown that, unless NP DTIME [n poly log n ], no polynomial time algorithm can approximate Set Cover within a factor better than ff = 1 4 ln jXj in the worst case, and, unless NP DTIME [n O (log log n) ], Bellare et al. [4] showed <p> Thus, for set systems with bounded VC-exponent, we challenge the complexity-theoretic lower bounds of <ref> [4, 33] </ref> (which make no assumptions about the VC-exponent). In section 4, we indicate some examples on which Hochbaum's method [26] or the greedy methods [17, 28, 32] perform poorly, and show that our method outperforms them in some cases. <p> For example, if there is a constant sized hitting set, the algorithm runs in linear time. Furthermore, our algorithm seems to defeat known complexity-theoretic lower bounds <ref> [4, 33] </ref> (which make no assumptions about the VC-exponent), by being adaptive: the competitive ratio depends on the size of the optimal solution. However, the proof methods of [4, 33] require (to the best of our understanding) that the optimal hitting set is large. <p> Furthermore, our algorithm seems to defeat known complexity-theoretic lower bounds <ref> [4, 33] </ref> (which make no assumptions about the VC-exponent), by being adaptive: the competitive ratio depends on the size of the optimal solution. However, the proof methods of [4, 33] require (to the best of our understanding) that the optimal hitting set is large. It is thus not clear what the applicability of their results to ours is.
Reference: [34] <author> J. Matousek. </author> <title> Construction of "-nets. </title> <journal> Discrete Comput. Geom., </journal> <volume> 5 </volume> <pages> 427-448, </pages> <year> 1990. </year>
Reference: [35] <author> J. Matousek. </author> <title> Approximations and optimal geometric divide-and-conquer. </title> <booktitle> In Proc. 23rd Annu. ACM Sympos. Theory Comput., </booktitle> <pages> pages 505-511, </pages> <year> 1991. </year> <note> Also to appear in J. </note> <institution> Comput. Syst. Sci. </institution>
Reference: [36] <author> J. Matousek. </author> <title> Cutting hyperplane arrangements. </title> <journal> Discrete Comput. Geom., </journal> <volume> 6 </volume> <pages> 385-406, </pages> <year> 1991. </year>
Reference-contexts: If (X; R) has a subsystem oracle of degree D, and VC-exponent d, it is clear that d D. Under this assumption, it has also been shown by Matousek et al. <ref> [36, 10] </ref> that one can find a (1=r)-net for (X; R) of size O (dr log (dr)) in O (d) 3D r D log D (rd)jXj time, for both the uniform and weighted cases. 3 The Main Algorithm The goal of this section is to prove our main theorem. <p> Here we mention a simple method for reducing the weighted case to an unweighted one, as outlined by Matousek <ref> [36] </ref>. First scale the weights such that w (X) = n. Then take bw (x) + 1c copies of each element x 2 X. Note that the multiset X 0 thus obtained contains all the elements of X and has a cardinal of at most 2n.
Reference: [37] <author> J. Matousek. </author> <title> Range searching with efficient hierarchical cuttings. </title> <booktitle> In Proc. 8th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 276-285, </pages> <year> 1992. </year>
Reference: [38] <author> J. Matousek. </author> <title> Reporting points in halfspaces. </title> <journal> Comput. Geom. Theory Appl., </journal> <volume> 2(3) </volume> <pages> 169-186, </pages> <year> 1992. </year>
Reference-contexts: The algorithm of Theorem 5.2 has been animated into a video [8], and Figure 2 shows snapshots illustrating different stages. But in three dimensions, we can actually do much better. In particular, we recall from Matousek et al. <ref> [39, 38] </ref> that the three dimensional halfspace set system admits "-nets of size O (1="), and as indicated in Section 3.2, their algorithm can be extended to the weighted case as well. <p> The cost of the computation of a (1=c)-net of size O (c) is O (nc), if c n ff <ref> [38] </ref>, and the cost of verifying is O (n log n) as argued above. Therefore we obtain the following strengthening of our previous theorem: 8 Theorem 5.2 Let Q P be two nested polyhedra in IR 3 with a total of n facets, one of them being convex.
Reference: [39] <author> J. Matousek, R. Seidel, and E. Welzl. </author> <title> How to net a lot with little: small "-nets for disks and halfspaces. </title> <booktitle> In Proc. 6th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 16-22, </pages> <year> 1990. </year>
Reference-contexts: The algorithm of Theorem 5.2 has been animated into a video [8], and Figure 2 shows snapshots illustrating different stages. But in three dimensions, we can actually do much better. In particular, we recall from Matousek et al. <ref> [39, 38] </ref> that the three dimensional halfspace set system admits "-nets of size O (1="), and as indicated in Section 3.2, their algorithm can be extended to the weighted case as well. <p> However, for large c n ff , we have to switch to a O (n 3 ) method to find the net <ref> [39] </ref>, yielding O (cn 3 log (n=c)) time. <p> The disc cover problem is to find a minimum number of discs in D that cover the points in S [27]. This problem is motivated by VLSI design criteria as well as viewing problems in astronomy. Matousek et al. <ref> [39] </ref> show that this set system admits O (r) sized (1=r)-net and, as indicated in Section 3.2, one can extend their algorithm to weighted point sets.
Reference: [40] <author> J. Matousek, E. Welzl, and L. Wernisch. </author> <title> Discrepancy and *-approximations for bounded VC-dimension. </title> <booktitle> In Proc. 32nd Annu. IEEE Sympos. Found. Comput. Sci., </booktitle> <pages> pages 424-430, </pages> <year> 1991. </year>
Reference: [41] <author> J. Matousek. </author> <title> Efficient partition trees. </title> <journal> Discrete Comput. Geom., </journal> <volume> 8 </volume> <pages> 315-334, </pages> <year> 1992. </year>
Reference: [42] <author> J. S. B. Mitchell and S. Suri. </author> <title> Separation and approximation of polyhedral surfaces. </title> <booktitle> In Proc. 3rd ACM-SIAM Sympos. Discrete Algorithms, </booktitle> <pages> pages 296-306, </pages> <year> 1992. </year>
Reference-contexts: The problem of finding a separator polytope between P and Q with as few facets as possible is believed to be NP-hard, even in the three-dimensional case [22], but one can find good approximations for it. Mitchell and Suri cast the problem as a hitting set problem <ref> [42] </ref>. Let H = H (Q) denote the set of supporting hyperplanes of Q. <p> In particular, it should be noted that the running time is always O (n 1+2ff log n), which improves on the O (n 4 ) time bound of Mitchell and Suri's method <ref> [42] </ref> for the general case. However, for large c n ff , we have to switch to a O (n 3 ) method to find the net [39], yielding O (cn 3 log (n=c)) time.
Reference: [43] <author> N. Sauer. </author> <title> On the densities of families of sets. </title> <journal> J. Combin. Theory, </journal> <volume> 13 </volume> <pages> 145-147, </pages> <year> 1972. </year>
Reference-contexts: Y is shattered by R if R jY = 2 Y . (X; R) is said to have VC-dimension d, if d is the smallest integer such that no d + 1 point subset Y X can be shattered. If Y is finite, it is well known <ref> [43, 44] </ref> that the number of sets of R jY is less than 0 + + jY j jY j d , where d is the VC-dimension of (X; R). 2 We call the VC-exponent 1 the infimum of all numbers s such that jR jY j = O (jY j
Reference: [44] <author> V. N. Vapnik and A. Ya. Cervonenkis. </author> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory Probab. Appl., </journal> <volume> 16 </volume> <pages> 264-280, </pages> <year> 1971. </year>
Reference-contexts: For references, the reader is referred to the original paper by Vapnik and Cervonenkis <ref> [44] </ref> (from whom have derived the VC-initials ), or to the survey by Assouad [2]. Let (X; R) be a given set system. <p> Y is shattered by R if R jY = 2 Y . (X; R) is said to have VC-dimension d, if d is the smallest integer such that no d + 1 point subset Y X can be shattered. If Y is finite, it is well known <ref> [43, 44] </ref> that the number of sets of R jY is less than 0 + + jY j jY j d , where d is the VC-dimension of (X; R). 2 We call the VC-exponent 1 the infimum of all numbers s such that jR jY j = O (jY j
Reference: [45] <author> E. Welzl. </author> <title> Partition trees for triangle counting and other range searching problems. </title> <booktitle> In Proc. 4th Annu. ACM Sympos. Comput. Geom., </booktitle> <pages> pages 23-33, </pages> <year> 1988. </year> <month> 13 </month>
Reference-contexts: Our algorithm, which is actually for the dual Hitting Set problem, is based upon a deterministic analogue of a randomized natural selection technique used by Clarkson [18, 19], Littlestone [31], and Welzl <ref> [45] </ref>. <p> Lemma 3.4 If there is a hitting set of size c, the doubling process cannot iterate more than 4c log (n=c) times, and the total weight will not exceed n 4 =c 3 . Proof: Our proof follows arguments of Clarkson [18, 19], Littlestone [31], and Welzl <ref> [45] </ref>. Let H be a hitting set of size c. Because the set R returned by B at each iteration satisfies w (R) w (X)=2c, the weight of X is not multiplied by more than a factor 1 + 1=2c in any iteration.
References-found: 45

