URL: ftp://dimacs.rutgers.edu/pub/dimacs/TechnicalReports/TechReports/1997/97-45.ps.gz
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1997.html
Root-URL: http://www.cs.rutgers.edu
Title: Some Pointed Questions Concerning Asymptotic Lower Bounds 1  
Author: by Eric Allender ; 
Note: DIMACS is a partnership of Rutgers University, Princeton University, AT&T Labs, Bellcore, and Bell Labs. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology.  
Abstract: DIMACS Technical Report 97-45 September 1997 1 A version of this paper originally appeared in the Computational Complexity Column in the Bulletin of the EATCS 62, June, 1997, pp. 96-103 2 Permanent Member 3 Supported in part by NSF grant CCR-9509603. This piece was written while the author was a visiting scholar at the Wilhelm-Schickard Institut fur Informatik, Universitat Tubingen, supported by DFG grant TU 7/117-1 
Abstract-found: 1
Intro-found: 1
Reference: [AAI97] <author> M. Agrawal, E. Allender, R. Impagliazzo, T. Pitassi, and S. Rudich. </author> <title> Reducing the complexity of reductions. </title> <note> To appear in Proc. 29th STOC, </note> <year> 1997. </year>
Reference-contexts: with a computational problem, the probability is quite high that it is complete for some complexity class in the existing literature, under AC 0 reducibility. (In fact, we now know that such problems are all isomorphic to the standard complete set for the complexity class, under depth-three AC 0 reductions <ref> [AAI97] </ref>. That is, the complete sets are all simple re-encodings of each other.) Second, note that the current list of complexity classes is defined using a fairly small number of basic concepts such as nondeterminism, counting, circuits, and reducibility.
Reference: [ALR97] <author> E. Allender, M. Loui, and K. Regan. </author> <title> Complexity Classes, Reducibility and Completeness, and Other Complexity Classes and Measures. Three chapters written for the Handbook on Algorithms and the Theory of Computation, </title> <editor> ed. M. Atallah, </editor> <publisher> CRC Press (to appear). </publisher>
Reference-contexts: Watch this space for continuing updates. Acknowledgments Observations similar to the ones expressed above have found their way into some chapters I recently collaborated on with Michael Loui and Ken Regan <ref> [ALR97] </ref>, and my interactions 2 Of course, I am guilty of oversimplification here. Complexity theory also works with the notions of average-case complexity and complexity of approximation.
Reference: [Al96] <author> E. Allender. </author> <title> Circuit complexity before the dawn of the new millennium. </title> <booktitle> In Proc. 16th Annual Conference on Foundations of Software Technology and Theoretical Computer Science (FST&TCS '96), volume 1180 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 1-18. </pages> <publisher> Springer Verlag, </publisher> <year> 1996. </year>
Reference-contexts: Although complexity classes and reducibilities have been some of our best tools for understanding these aspects, too, the "compartmentalization" provided by equivalence under interreducibility is not quite as tidy when considering these aspects. - 5 - with them certainly influenced what appears above. Related ideas are discussed in <ref> [Al96] </ref>. V. Vinay and Jack Lutz have each discussed the role of complexity theory in formulating hypotheses, both with me and in print [Vi94, Lu93]. I gratefully acknowledge their influence. Thanks also to Rolf Niedermeier and Jacobo Toran for their comments on a preliminary draft.
Reference: [Bar89] <author> D. A. </author> <title> Mix Barrington. </title> <booktitle> Bounded-width polynomial-size branching programs recog nize exactly those languages in NC 1 . Journal of Computer and System Sciences, </booktitle> <volume> 38 </volume> <pages> 150-164, </pages> <year> 1989. </year>
Reference-contexts: What is the practical significance of the fact that a problem is complete for DLOG under AC 0 reductions? It tells us that the problem is not likely to have NC 1 circuits or polynomial-size bounded-width branching programs (as this would imply DLOG = NC 1 <ref> [Bar89] </ref>). But how significant is this for a practitioner? There aren't many people building bounded-width branching programs for problems, and since any problem in DLOG has size n O (1) circuits of depth O (log 2 n), an !(log n) lower bound is of questionable significance for the real world.
Reference: [Bl67] <author> M. Blum. </author> <title> A machine-independent theory of the complexity of recursive functions. </title> <journal> J. Assn. Comp. Mach., </journal> <volume> 14 </volume> <pages> 322-336, </pages> <year> 1967. </year>
Reference-contexts: For the overwhelming majority 1 Of course, there is also the possibility that some of these problems have no optimal algorithm <ref> [Bl67] </ref>. - 3 - of computational problems that have been considered in the computing literature, one can find a complexity class for which the problem is complete.
Reference: [BG93] <author> J. Buss and J. Goldsmith. </author> <title> Nondeterminism within P. </title> <journal> SIAM Journal on Computing 22 </journal> <pages> 560-572, </pages> <year> 1993. </year>
Reference-contexts: However, this type of argument has been applied to only a handful of computational problems, and it proves nothing about the complexity of these problems on unrestricted models of computation. There are some special subclasses of P (such as classes studied in the work of Buss and Goldsmith <ref> [BG93] </ref>, or in the literature on Parameterized Complexity [HT96]) that help explain our current lack of a linear- or quadratic-time algorithm for a relatively small number of problems in P having a special structure.
Reference: [Co71] <author> S. Cook. </author> <title> The complexity of theorem-proving procedures. </title> <booktitle> In Proc. 3rd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 151-158, </pages> <year> 1971. </year>
Reference-contexts: Why is this significant? First, I would like to argue that it is significant because it was unexpected. The initial shock, of course, came with the papers of <ref> [Co71, Ka72] </ref> showing that the notion of NP-completeness is wildly successful at explaining the seeming intractability of many problems. Then there followed some results with a similar flavor (such as [SM73, Jon75] and others), showing that some other problems were complete for larger and smaller complexity classes.
Reference: [EP95] <author> J. Edmonds and C. Poon. </author> <title> A nearly optimal time-space lower bound for directed st-connectivity on the NNJAG model. </title> <booktitle> In Proc. 27th STOC, </booktitle> <year> 1995, </year> <pages> pp. 147-156. </pages>
Reference-contexts: That hasn't happened. For a very few problems in P, there are lower bounds on so-called "restricted models of computation" (such as the model used in <ref> [EP95] </ref>, for example, or the comparison-based sorting model, as another example). These bounds do provide an explanation for why some problems require lots of resources if a certain kind of algorithm is used.
Reference: [Eh75] <author> A. Ehrenfeucht. </author> <title> Practical decidability. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 11 </volume> <pages> 392-396, </pages> <year> 1975. </year>
Reference-contexts: However, it is almost never done. In fact, I am not aware of any other instance where concrete bounds of this sort were obtained. (Stockmeyer [Sto87] does mention the earlier work of Ehrenfeucht <ref> [Eh75] </ref> which has a similar flavor.) Why are results of this sort so rare? The answer, of course, is that this approach first requires an asymptotic lower bound, and we don't have many of those, either! But this should be seen as additional motivation for obtaining asymptotic lower bounds.
Reference: [HT96] <author> M. T. Hallett and H. T. Wareham. </author> <title> Parameterized Complexity Home Page. </title> <address> http://www-csc.uvic.ca/home/harold/W hier/W hier.html </address>
Reference-contexts: There are some special subclasses of P (such as classes studied in the work of Buss and Goldsmith [BG93], or in the literature on Parameterized Complexity <ref> [HT96] </ref>) that help explain our current lack of a linear- or quadratic-time algorithm for a relatively small number of problems in P having a special structure.
Reference: [Imm87] <author> N. Immerman. </author> <title> Languages that capture complexity classes. </title> <journal> SIAM Journal on Computing, </journal> <volume> 16 </volume> <pages> 760-778, </pages> <year> 1987. </year>
Reference-contexts: In fact, in almost all cases, the problem is complete for the complexity class using a very restrictive notion of reducibility (such as AC 0 reducibility, or even projections; see e.g. <ref> [Imm87] </ref>). Why is this significant? First, I would like to argue that it is significant because it was unexpected. The initial shock, of course, came with the papers of [Co71, Ka72] showing that the notion of NP-completeness is wildly successful at explaining the seeming intractability of many problems.
Reference: [Imm88] <author> N. Immerman. </author> <title> Nondeterministic space is closed under complement. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17 </volume> <pages> 935-938, </pages> <year> 1988. </year>
Reference-contexts: Seen in this light, it is clear why the breakthrough results of Immerman and Szelepcsenyi <ref> [Imm88, Sze88] </ref> were shocking at the same time that they were exhilarating. It had seemed that many problems naturally classified themselves as being complete for exactly one of - 4 - fNLOG, coNLOGg.
Reference: [JKL89] <author> B. Jenner, B. Kirsig, and K.-J. Lange. </author> <title> The Logarithmic Alternation Hierarchy Collapses: A L 2 = A L 2 . Information and Computation 80 </title> <month> 269-288 </month> <year> 1989. </year> <month> - 6 </month> - 
Reference-contexts: There seemed to be as much empirical grounds for the belief that these classes were distinct as for much of the rest of the framework provided by complexity theory. (There were smaller tremors provided by the earlier discovery that the alternating logspace hierarchy collapses <ref> [JKL89] </ref>; some computational problems had been thought to live on different levels of that hierarchy [RY86].) If the "empirical evidence" that NLOG 6= coNLOG was really just an illusion, how much can we trust the rest of the classification given by complexity classes? We need to understand these classes much better!
Reference: [Jon75] <author> N. D. Jones. </author> <title> Space bounded reducibility among combinatorial problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 11 </volume> <pages> 68-85, </pages> <year> 1975. </year>
Reference-contexts: The initial shock, of course, came with the papers of [Co71, Ka72] showing that the notion of NP-completeness is wildly successful at explaining the seeming intractability of many problems. Then there followed some results with a similar flavor (such as <ref> [SM73, Jon75] </ref> and others), showing that some other problems were complete for larger and smaller complexity classes. Over the course of the years, more complexity classes have been defined and studied and been shown to capture the complexity of various important computational problems.
Reference: [Ka72] <author> R. Karp. </author> <title> Reducibility among combinatorial problems. In R.E. </title> <editor> Miller and J.W. Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> pages 85-104. </pages> <publisher> Plenum Press, </publisher> <year> 1972. </year>
Reference-contexts: Why is this significant? First, I would like to argue that it is significant because it was unexpected. The initial shock, of course, came with the papers of <ref> [Co71, Ka72] </ref> showing that the notion of NP-completeness is wildly successful at explaining the seeming intractability of many problems. Then there followed some results with a similar flavor (such as [SM73, Jon75] and others), showing that some other problems were complete for larger and smaller complexity classes.
Reference: [Lu93] <author> J. Lutz. </author> <title> The quantitative structure of exponential time. </title> <booktitle> In Proc. 8th IEEE Conference on Structure in Complexity Theory, </booktitle> <year> 1993, </year> <pages> pp. 158-175. </pages>
Reference-contexts: Related ideas are discussed in [Al96]. V. Vinay and Jack Lutz have each discussed the role of complexity theory in formulating hypotheses, both with me and in print <ref> [Vi94, Lu93] </ref>. I gratefully acknowledge their influence. Thanks also to Rolf Niedermeier and Jacobo Toran for their comments on a preliminary draft.
Reference: [RY86] <author> L. Rosier and H. Yen. </author> <title> Logspace hierarchies, polynomial time, and the complexity of fairness problems concerning !-machines. </title> <booktitle> In Proc. 3rd Symposium on Theoretical Aspects of Computer Science (STACS '86), volume 210 of Lect. Notes in Comp. Sci., </booktitle> <pages> pages 306-320. </pages> <publisher> Springer Verlag, </publisher> <year> 1986. </year>
Reference-contexts: the belief that these classes were distinct as for much of the rest of the framework provided by complexity theory. (There were smaller tremors provided by the earlier discovery that the alternating logspace hierarchy collapses [JKL89]; some computational problems had been thought to live on different levels of that hierarchy <ref> [RY86] </ref>.) If the "empirical evidence" that NLOG 6= coNLOG was really just an illusion, how much can we trust the rest of the classification given by complexity classes? We need to understand these classes much better! Let me summarize the points I'm trying to make. 1.
Reference: [St74] <author> L. Stockmeyer. </author> <title> The complexity of decision problems in automata theory and logic. </title> <type> Technical Report MAC-TR-133, </type> <institution> Project MAC, M.I.T., </institution> <address> Cambridge, Mass., </address> <year> 1974. </year>
Reference-contexts: Yet, inside essentially every asymptotic lower bound in complexity theory, there hides a concrete statement about physical reality. It is best to illustrate this with an example. Here's my personal favorite: In Larry Stockmeyer's Ph.D. thesis <ref> [St74] </ref>, he shows that any circuit that takes as input a formula (in a certain logical system) with up to 616 symbols and produces as output a correct answer saying whether the formula is valid, requires at least 10 123 gates.
Reference: [Sto87] <author> L. Stockmeyer. </author> <title> Classifying the computational complexity of problems. </title> <journal> J. Symb. Logic, </journal> <volume> 52 </volume> <pages> 1-43, </pages> <year> 1987. </year>
Reference-contexts: However, it is almost never done. In fact, I am not aware of any other instance where concrete bounds of this sort were obtained. (Stockmeyer <ref> [Sto87] </ref> does mention the earlier work of Ehrenfeucht [Eh75] which has a similar flavor.) Why are results of this sort so rare? The answer, of course, is that this approach first requires an asymptotic lower bound, and we don't have many of those, either! But this should be seen as additional
Reference: [SM73] <author> L. Stockmeyer and A. Meyer. </author> <title> Word problems requiring exponential time: preliminary report. </title> <booktitle> In Proc. 5th STOC, </booktitle> <year> 1973, </year> <pages> pp. 1-9. </pages>
Reference-contexts: The initial shock, of course, came with the papers of [Co71, Ka72] showing that the notion of NP-completeness is wildly successful at explaining the seeming intractability of many problems. Then there followed some results with a similar flavor (such as <ref> [SM73, Jon75] </ref> and others), showing that some other problems were complete for larger and smaller complexity classes. Over the course of the years, more complexity classes have been defined and studied and been shown to capture the complexity of various important computational problems.
Reference: [Sze88] <author> R. Szelepcsenyi. </author> <title> The method of forced enumeration for nondeterministic automata. </title> <journal> Acta Informatica, </journal> <volume> 26 </volume> <pages> 279-284, </pages> <year> 1988. </year>
Reference-contexts: Seen in this light, it is clear why the breakthrough results of Immerman and Szelepcsenyi <ref> [Imm88, Sze88] </ref> were shocking at the same time that they were exhilarating. It had seemed that many problems naturally classified themselves as being complete for exactly one of - 4 - fNLOG, coNLOGg.
Reference: [Vi94] <author> V. Vinay. </author> <title> Rudiments of complexity theory for scientists and engineers. </title> <journal> Sadhana, </journal> <volume> Vol. 19, part 6, </volume> <month> Dec. </month> <year> 1994, </year> <pages> pp. 985-994. </pages>
Reference-contexts: Related ideas are discussed in [Al96]. V. Vinay and Jack Lutz have each discussed the role of complexity theory in formulating hypotheses, both with me and in print <ref> [Vi94, Lu93] </ref>. I gratefully acknowledge their influence. Thanks also to Rolf Niedermeier and Jacobo Toran for their comments on a preliminary draft.
References-found: 22

