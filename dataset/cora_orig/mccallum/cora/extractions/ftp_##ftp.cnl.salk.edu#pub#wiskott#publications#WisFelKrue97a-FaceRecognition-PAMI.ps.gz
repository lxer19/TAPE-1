URL: ftp://ftp.cnl.salk.edu/pub/wiskott/publications/WisFelKrue97a-FaceRecognition-PAMI.ps.gz
Refering-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Root-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/FaceProcessing.html
Title: Face Recognition by Elastic Bunch Graph Matching  
Author: Laurenz Wiskott, Jean-Marc Fellous, Norbert Kruger, and Christoph von der Malsburg 
Keyword: Index Terms: face recognition, different poses, Ga-bor wavelets, elastic graph matching, bunch graph, ARPA/ARL FERET database, Bochum database.  
Note: IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(7):775-779 (1997).  
Abstract: We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from the preceding one [1] in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small set of sample image graphs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Lades, J. C. Vorbruggen, J. Buhmann, J. Lange, C. von der Malsburg, R. P. Wurtz, and W. Ko-nen, </author> <title> "Distortion invariant object recognition in the dynamic link architecture," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 42, no. 3, </volume> <pages> pp. 300-311, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction The system presented here is based on a face recognition system described in <ref> [1] </ref>. In this preceding system, individual faces were represented by a rectangular graph, each node labeled with a set of complex Gabor wavelet coefficients, called a jet. Only the magnitudes of the coefficients were used for matching and recognition. <p> This can cause severe problems for matching. We therefore either ignore the phase or compensate for its variation explicitly. The similarity function S a (J ; J 0 ) = j j j j j j ignores phase <ref> [1] </ref>. <p> In these experiments we also flipped all left pose images over, so that to a large extent 4 the recognition was not only done across pose but also across mirror reflection. A second set of tests has been done on the Bochum database <ref> [1] </ref>. It contains neutral frontal views (fa), frontal views with different facial expression (fb), 11 ffi rotated poses (refered to as 15 ffi in [1] because the gaze is at 15 ffi , but the head rotation is less), 22 ffi rotated poses. <p> A second set of tests has been done on the Bochum database <ref> [1] </ref>. It contains neutral frontal views (fa), frontal views with different facial expression (fb), 11 ffi rotated poses (refered to as 15 ffi in [1] because the gaze is at 15 ffi , but the head rotation is less), 22 ffi rotated poses. For the Bochum database we did not use the normalization stage, because faces varied only little in size. <p> We used 108 neutral frontal views as a model gallery and the other images as probe galleries. The recognition rates for galleries fb, 11 ffi , and 22 ffi were 91%, 94%, and 88%, respectively. On the same galleries the preceding system <ref> [1] </ref> achieved 92%, 97%, and 85%. Thus the overall performance is the same. The performance on the fb-gallery is worse than for the corresponding fb-gallery of the FERET database, because the Bochum database shows more variation in facial expression, some faces being even half covered by a hand or hair. <p> For large rotation angles the performance degrades significantly. Our system perfoms well compared to other systems. Results of a blind test of different systems on the FERET database were published in [6, 7]. In comparison to the system <ref> [1] </ref> on the basis of which we have developed the system presented here we have made several major modifications. We now utilize wavelet phase information for accurate node localization. Previously, node localization was rather imprecise.
Reference: [2] <author> L. Wiskott, J.-M. Fellous, N. Kruger, and C. von der Malsburg, </author> <title> "Face recognition by elastic bunch graph matching," </title> <type> Tech. Rep. </type> <institution> IR-INI 96-08, Institut fur Neuroinformatik, </institution> <address> Ruhr-Universitat Bochum, D-44780 Bochum, Germany, </address> <year> 1996. </year>
Reference-contexts: This allows the system to find the fiducial points in one matching process, which eliminates the need for matching each model graph individually. This reduces computational effort significantly. A more detailed description of this system is given in <ref> [2] </ref>. 2 The System 2.1 Jets A jet is based on a wavelet transform, defined as a convolution of the image with a family of Gabor kernels [3] j (~x) = j k 2 2oe 2 exp (i ~ k j ~x) exp 2 (1) in the shape of plane waves <p> This can be done by maximizing S OE in its Taylor expansion around ~ d = 0, which is a constrained fit of the two-dimensional ~ d to the 40 phase differences OE j OE 0 j <ref> [2, 4] </ref>. Large displacements of up to 8 pixels can be estimated if the phases of higher frequency coefficients are corrected by multiples of 2 depending on the disparity estimated from lower frequency coefficients. It is a great advantage of this second similarity function that it yields this displacement information. <p> The manual selection of fiducial points could be replaced by grouping salient points on the basis of common motion [11]. Monitoring a rotating object by continuously applying elastic bunch graph matching can then reveal which nodes refer to corresponding fiducial points in different poses [12]. See <ref> [2] </ref> for a more detailed discussion. Acknowledgements We wish to thank Irving Biederman, Ladan Shams, Michael Lyons, and Thomas Maurer for very fruitful discussions and their help in the tests on the FERET database. Many thanks go to Thomas Maurer and Jan Vorbruggen for additional tests on the Bochum database.
Reference: [3] <author> J. G. Daugman, </author> <title> "Complete discrete 2-D Gabor transform by neural networks for image analysis and compression," </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> vol. 36, </volume> <pages> pp. 1169-1179, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: This reduces computational effort significantly. A more detailed description of this system is given in [2]. 2 The System 2.1 Jets A jet is based on a wavelet transform, defined as a convolution of the image with a family of Gabor kernels <ref> [3] </ref> j (~x) = j k 2 2oe 2 exp (i ~ k j ~x) exp 2 (1) in the shape of plane waves with wave vector ~ k j , restricted by a Gaussian envelope function with relative width oe = 2.
Reference: [4] <author> W. M. Theimer and H. A. Mallot, </author> <title> "Phase-based binocular vergence control and depth reconstruction using active vision," CVGIP: </title> <booktitle> Image Understanding, </booktitle> <volume> vol. 60, </volume> <pages> pp. 343-358, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: This can be done by maximizing S OE in its Taylor expansion around ~ d = 0, which is a constrained fit of the two-dimensional ~ d to the 40 phase differences OE j OE 0 j <ref> [2, 4] </ref>. Large displacements of up to 8 pixels can be estimated if the phases of higher frequency coefficients are corrected by multiples of 2 depending on the disparity estimated from lower frequency coefficients. It is a great advantage of this second similarity function that it yields this displacement information.
Reference: [5] <author> N. Kruger, M. Potzsch, and C. von der Malsburg, </author> <title> "Estimation of face position and pose with labeled graphs," </title> <booktitle> in Proceedings of the British Machine Vision Conference (BMVC96), </booktitle> <pages> pp. 735-743, </pages> <year> 1996. </year>
Reference-contexts: Each image has a label which indicates the pose, so that pose does not need to be determined automatically, though our system is able to determine pose automatically in the same way as size is estimated <ref> [5] </ref>. The two steps together take less than 30 seconds on a SPARCstation 10-512.
Reference: [6] <author> P. J. Rauss, J. Phillips, M. K. Hamilton, and A. T. DePersia, </author> <title> "FERET (face-recognition technology) recognition algorithms," </title> <booktitle> in Proc. of the Fifth Automatic Target Recognizer System and Technology Symposium, </booktitle> <year> 1996. </year>
Reference-contexts: We also showed robustness against rotation in depth up to about 22 ffi . For large rotation angles the performance degrades significantly. Our system perfoms well compared to other systems. Results of a blind test of different systems on the FERET database were published in <ref> [6, 7] </ref>. In comparison to the system [1] on the basis of which we have developed the system presented here we have made several major modifications. We now utilize wavelet phase information for accurate node localization. Previously, node localization was rather imprecise.
Reference: [7] <author> P. J. Phillips, P. J. Rauss, and S. Z. Der, </author> <title> "FERET (face recognition technology) recognition algorithm development and test report," </title> <type> Tech. Rep. </type> <institution> ARL-TR-995, U. S. Army Research Laboratory, </institution> <address> 2800 Powder Mill Road, Adelphi, MD 20783-1197, </address> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: We also showed robustness against rotation in depth up to about 22 ffi . For large rotation angles the performance degrades significantly. Our system perfoms well compared to other systems. Results of a blind test of different systems on the FERET database were published in <ref> [6, 7] </ref>. In comparison to the system [1] on the basis of which we have developed the system presented here we have made several major modifications. We now utilize wavelet phase information for accurate node localization. Previously, node localization was rather imprecise.
Reference: [8] <author> N. Kruger, </author> <title> "An algorithm for the learning of weights in discrimination functions using a priori constraints." </title> <journal> accepted for publication in IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <year> 1997. </year>
Reference-contexts: The increased matching accuracy, the object adapted graphs, and the face bunch graph provide the basis for further improvements. In an extension of the system presented here, Kr uger has developed a method for learning weights emphasizing those nodes which are more discriminative and more robust against noise <ref> [8] </ref>. On model galleries of size 130-150 and probe images of different pose, an average improvement of the first rank recognition rates of 6.5% has been achieved, from a mean performance of 19.8% without to 26.3% with weights.
Reference: [9] <author> T. Maurer and C. von der Malsburg, </author> <title> "Linear feature transformations to recognize faces rotated in depth," </title> <booktitle> in Proceedings of the International Conference on Artificial Neural Networks, ICANN'95, (Paris), </booktitle> <pages> pp. 353-358, </pages> <month> Oct. </month> <year> 1995. </year>
Reference-contexts: Another individual treatment of the nodes has been developed by Maurer & von der Malsburg <ref> [9] </ref>. They applied linear jet transformations to compensate for the effect of rotation in depth.
Reference: [10] <author> L. Wiskott, </author> <title> "Phantom faces for face analysis," </title> <journal> Pattern Recognition, </journal> <volume> vol. 30, no. 6, </volume> <pages> pp. 837-846, </pages> <year> 1997. </year>
Reference-contexts: On a frontal pose gallery of 90 faces and half profile probe images an average improvement of the first rank recognition rate of 15% was achieved, from 36% without rotation to 50% and 53% with rotation, depending on which pose was rotated. In <ref> [10] </ref> the bunch graph technique has been used to fairly reliably determine facial attributes from single images, such as sex or the presence of glasses or a beard.
Reference: [11] <author> B. S. Manjunath, R. Chellappa, and C. von der Malsburg, </author> <title> "A feature based approach to face recognition," </title> <type> Tech. Rep. </type> <institution> CAR-TR-604 or CS-TR-2834, Computer Vision Laboratory, University of Mary-land, </institution> <address> Colledge Park, MD 20742-3411, </address> <year> 1992. </year>
Reference-contexts: Future research on the basic system will have to focus on replacing the manual steps in the initial phase by automatic procedures. The manual selection of fiducial points could be replaced by grouping salient points on the basis of common motion <ref> [11] </ref>. Monitoring a rotating object by continuously applying elastic bunch graph matching can then reveal which nodes refer to corresponding fiducial points in different poses [12]. See [2] for a more detailed discussion.
Reference: [12] <author> T. Maurer and C. von der Malsburg, </author> <title> "Tracking and learning graphs on image sequences of faces," </title> <booktitle> in Proceedings of the ICANN 1996 (C. </booktitle> <editor> von der Malsburg, W. von Seelen, J. C. Vorbruggen, and B. Sendhoff, eds.), </editor> <booktitle> (Bochum), </booktitle> <pages> pp. 323-328, </pages> <publisher> Springer Verlag, </publisher> <month> July </month> <year> 1996. </year> <title> c fl1997 IEEE. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. </title> <type> 6 </type>
Reference-contexts: The manual selection of fiducial points could be replaced by grouping salient points on the basis of common motion [11]. Monitoring a rotating object by continuously applying elastic bunch graph matching can then reveal which nodes refer to corresponding fiducial points in different poses <ref> [12] </ref>. See [2] for a more detailed discussion. Acknowledgements We wish to thank Irving Biederman, Ladan Shams, Michael Lyons, and Thomas Maurer for very fruitful discussions and their help in the tests on the FERET database.
References-found: 12

