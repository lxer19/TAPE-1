URL: http://www.cs.huji.ac.il/papers/IP/quasi.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/index.html
Root-URL: 
Email: contact email: daphna@cs.huji.ac.il  
Title: Stability and Likelihood of Views of Three Dimensional Objects  
Author: Daphna Weinshall Michael Werman and Naftali Tishby ? 
Address: 91904 Jerusalem, Israel  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract: Can we say anything general about the distribution of two dimensional views of general three dimensional objects? In this paper we present a first formal analysis of the stability and likelihood of two dimensional views (under weak perspective projection) of three dimensional objects. This analysis is useful for various aspects of object recognition and database indexing. Examples are Bayesian recognition; indexing to a three dimensional database by invariants of two dimensional images; the selection of "good" templates that may reduce the complexity of correspondence between images and three dimensional objects; and ambiguity resolution using generic views. We show the following results: (1) Both the stability and likelihood of views do not depend on the particular distribution of points inside the object; they both depend on only three numbers, the three second moments of the object. (2) The most stable and the most likely views are the same view, which is the "flattest" view of the object. Under orthographic projection, we also show: (3) the distance between one image to another does not depend on the position of its viewpoint with respect to the object, but only on the (geodesic) distance between the viewpoints on the viewing sphere. We demonstrate these results with real and simulated data.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> E. M. Arkin, K. Kedem, J. S. B. Mitchell, J. Sprinzak, and M. Werman. </author> <title> Matching points into pairwise disjoint noise regions: Combinatorial bounds and algorithms. </title> <journal> ORSA Journal on Computing, </journal> <note> special issue on computational geometry, </note> <year> 1992. </year>
Reference-contexts: One solution is to use 2D templates for the direct matching of 2D images, which may reduce the complexity of search considerably from O (n 3 ) to O (dn 2 ), where d is the number of templates (see <ref> [1] </ref> for a discussion of algorithms for finding all such matches). The two dimensional templates are possibly grey-level images of the object, where distinctive features are used to determine stability and likelihood.
Reference: 2. <author> J. Ben-Arie. </author> <title> The probabilistic peaking effect of viewed angles and distances with application to 3-d object recognition. </title> <booktitle> T-PAMI, </booktitle> <pages> pages 760-774, </pages> <year> 1990. </year>
Reference-contexts: Surprisingly, this important question of image likelihood has been (almost) totally neglected. There is a single exception, a study of the distribution of views of simple "objects", specifically planar angles, reported by Ben-Arie <ref> [2] </ref> and later expanded by Burns et al. [3]. These papers analyzed (via simulations) the changes in the appearance of angles from different points of views, and numerically identified stable images. <p> The range # 2 <ref> [0; 2 ] </ref>; ' 2 [0; 2] gives a parameterization of half the viewing sphere in spherical coordinates whose pole is the Z-axis, where ' is the azimuth and # is the elevation. <p> The range # 2 [0; 2 ]; ' 2 <ref> [0; 2] </ref> gives a parameterization of half the viewing sphere in spherical coordinates whose pole is the Z-axis, where ' is the azimuth and # is the elevation. <p> Let V 0 #;';ff;fi denote another view, corresponding to a rotation in spherical coordinates on the viewing sphere, where the point #; ' is now the pole, ff 2 <ref> [0; 2 ] </ref> the elevation, and fi 2 [0; 2] the azimuth. The distance from V #;' to V 0 #;';ff;fi on the viewing sphere is parameterized by the elevation angle ff. <p> Let V 0 #;';ff;fi denote another view, corresponding to a rotation in spherical coordinates on the viewing sphere, where the point #; ' is now the pole, ff 2 [0; 2 ] the elevation, and fi 2 <ref> [0; 2] </ref> the azimuth. The distance from V #;' to V 0 #;';ff;fi on the viewing sphere is parameterized by the elevation angle ff.
Reference: 3. <author> J.B. Burns, R. Weiss, and E. Riseman. </author> <title> View variation of point-set and line segment features. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(1) </volume> <pages> 51-68, </pages> <year> 1993. </year>
Reference-contexts: Surprisingly, this important question of image likelihood has been (almost) totally neglected. There is a single exception, a study of the distribution of views of simple "objects", specifically planar angles, reported by Ben-Arie [2] and later expanded by Burns et al. <ref> [3] </ref>. These papers analyzed (via simulations) the changes in the appearance of angles from different points of views, and numerically identified stable images. <p> To be useful, such indices are typically invariant to some aspects of the imaging process. However, geometrical invariants for general 3D objects do not exist <ref> [3] </ref>. By identifying a set of "representative" 2D views of an object, such that any other image of the object is not too far from at least one image in this set, we can attach to each object a list of invariant indices which will have small errors.
Reference: 4. <author> W. T. Freeman. </author> <title> Exploiting the generic view assumption to estimate scene parameters. </title> <booktitle> In Proceedings of the 4th International Conference on Computer Vision, </booktitle> <pages> pages 347-356, </pages> <address> Berlin, Germany, 1993. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: More generally, the probabilistic characterization of views, as defined below, measures how generic viewpoints are. In ambiguous cases, the interpretation which involves a more generic view may be preferable (see also <ref> [4] </ref>). Indexing by invariants: To finesse correspondence, various algorithms look for indices which can be computed from 2D images, and directly point to the object (or a family of objects) in the database [5]. To be useful, such indices are typically invariant to some aspects of the imaging process.
Reference: 5. <author> Y. Lamdan and H. Wolfson. </author> <title> Geometric hashing: a general and efficient recognition scheme. </title> <booktitle> In Proceedings of the 2nd International Conference on Computer Vision, </booktitle> <pages> pages 238-251, </pages> <address> Tarpon Springs, FL, 1988. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: In ambiguous cases, the interpretation which involves a more generic view may be preferable (see also [4]). Indexing by invariants: To finesse correspondence, various algorithms look for indices which can be computed from 2D images, and directly point to the object (or a family of objects) in the database <ref> [5] </ref>. To be useful, such indices are typically invariant to some aspects of the imaging process. However, geometrical invariants for general 3D objects do not exist [3].
Reference: 6. <author> D. Weinshall, M. Werman, and N. Tishby. </author> <title> Stability and likelihood of views of three dimensional objects. </title> <type> TR 94-1, </type> <institution> Hebrew University, </institution> <year> 1993. </year>
Reference-contexts: There are cases in which it is more appropriate to use 2D affine normalization or orthographic projection. In these cases the two results described in the previous section still hold (see <ref> [6] </ref>). Under orthographic projection, the scale of the image is known and we want to avoid normalization, but rather compare the model to the image as is.
Reference: 7. <author> M. Werman and D. Weinshall. </author> <title> Similarity and affine distance between point sets. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(8) </volume> <pages> 810-814, </pages> <year> 1995. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: We therefore assume w.l.g. that the images are centered on the centroid of the object, so that the first moments of the object are 0. In <ref> [7] </ref> we define image distance measures, which satisfy all the properties of a metric, and which compare the images P and Q while taking into account the desired image equivalence discussed above.
References-found: 7

