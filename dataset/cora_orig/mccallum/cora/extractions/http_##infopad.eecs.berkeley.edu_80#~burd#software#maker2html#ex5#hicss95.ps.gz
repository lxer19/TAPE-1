URL: http://infopad.eecs.berkeley.edu:80/~burd/software/maker2html/ex5/hicss95.ps.gz
Refering-URL: http://infopad.eecs.berkeley.edu:80/~burd/software/maker2html/ex5/
Root-URL: http://www.cs.berkeley.edu
Title: Energy Efficient CMOS Microprocessor Design Throughput and area have been the main forces driving microprocessor
Author: Thomas D. Burd and Robert W. Brodersen 
Note: 1: Introduction  A  will be presented. This paper will conclude with the application of  The  This capacitance, C L can be expressed as: (EQ 1) C L C W C FIX  
Address: Berkeley  
Affiliation: University of California,  
Abstract: Reduction of power dissipation in microprocessor design is becoming a key design constraint. This is motivated not only by portable electronics, in which battery weight and size is critical, but by heat dissipation issues in larger desktop and parallel machines as well. By identifying the major modes of computation of these processors and by proposing figures of merit for each of these modes, a power analysis methodology is developed. It allows the energy efficiency of various architectures to be quantified, and provides techniques for either individually optimizing or trading off throughput and energy consumption. The methodology is then used to qualify three important design principles for energy efficient microprocessor design. An energy-efficient design methodology has been developed for signal processing applications, resulting in a strategy to provide orders of magnitude of power reduction [1]. These applications have a fixed throughput requirement due to a real-time constraint given by the application (e.g. video compression, speech recognition). Microprocessors targeted for general purpose computing, however, generally operate in one of two other computing modes. Either they are continuously providing useful computation, in which case maximum throughput is desired, or they are in a user interactive mode, in which case bursts of computation are desired. CMOS circuits have both static and dynamic power dissipation. Static power arises from bias and leakage currents. While statically-biased gates are usually found in a few specialized circuits such as PLAs, their use has been dramatically reduced in CMOS design. Furthermore, careful design of these gates generally makes their power contribution negligible in circuits that do use them [2]. Leakage currents from reverse-biased diodes of MOS transistors, and from MOS subthreshold conduction [3] also dissipate static power, but are insignificant in most designs. 
Abstract-found: 1
Intro-found: 0
Reference: [1] <author> A. Chandrakasan, A. Burstein, R.W. Brodersen, </author> <title> A Low Power Chipset for Portable Multimedia Applications, </title> <booktitle> Proceedings of the IEEE International Solid-State Circuits Conference, </booktitle> <month> Feb. </month> <year> 1994, </year> <pages> pp. 82-83. </pages>
Reference-contexts: An energy-efficient design methodology has been developed for signal processing applications, resulting in a strategy to provide orders of magnitude of power reduction <ref> [1] </ref>. These applications have a fixed throughput requirement due to a real-time constraint given by the application (e.g. video compression, speech recognition). Microprocessors targeted for general purpose computing, however, generally operate in one of two other computing modes. <p> average operations/ second T AVE can be characterized, then METR is a better metric of comparison. 4.1: Fixed Throughput Optimization Orders of magnitude of power reduction have been achieved in fixed throughput designs by optimizing at all levels of the design hierarchy, including circuit implementation, architecture design, and algorithmic decisions <ref> [1] </ref>. One such example is a video decompression system in which a decompressed NTSC-standard video stream is displayed at 30 frames/sec on a 4 active matrix color LCD. The entire implementation consists of four custom chips that consume less than 2mW [1]. <p> hierarchy, including circuit implementation, architecture design, and algorithmic decisions <ref> [1] </ref>. One such example is a video decompression system in which a decompressed NTSC-standard video stream is displayed at 30 frames/sec on a 4 active matrix color LCD. The entire implementation consists of four custom chips that consume less than 2mW [1]. There were three major design optimizations responsible for the power reduction. First, the algorithm was chosen to be vector quantization which requires fewer computations for decompression than other compression schemes, such as MPEG. <p> The basic transistor sizing methodology is to reduce every transistor not in the critical path to minimum size to minimize C EFF . There are a number of other techniques to minimize effective capacitance which are also viable for optimizing energy efficiency <ref> [1] </ref>.
Reference: [2] <author> T. Burd, </author> <title> Low-Power CMOS Cell Library Design Methodology, M.S. </title> <type> Thesis, </type> <institution> University of California, Berkeley, </institution> <year> 1994. </year>
Reference-contexts: Static power arises from bias and leakage currents. While statically-biased gates are usually found in a few specialized circuits such as PLAs, their use has been dramatically reduced in CMOS design. Furthermore, careful design of these gates generally makes their power contribution negligible in circuits that do use them <ref> [2] </ref>. Leakage currents from reverse-biased diodes of MOS transistors, and from MOS subthreshold conduction [3] also dissipate static power, but are insignificant in most designs.
Reference: [3] <author> S. Sze, </author> <title> Physics of Semiconductor Devices, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: Furthermore, careful design of these gates generally makes their power contribution negligible in circuits that do use them [2]. Leakage currents from reverse-biased diodes of MOS transistors, and from MOS subthreshold conduction <ref> [3] </ref> also dissipate static power, but are insignificant in most designs. The dominant component of power dissipation in CMOS is therefore dynamic, and arises from the charging and discharging of the circuit node capacitances found on the output of every logic gate.
Reference: [4] <author> H. Veendrick, </author> <title> Short-Circuit Dissipation of Static CMOS Circuitry and Its Impact on the Design of Buffer Circuits, </title> <journal> IEEE Jour. of Solid State Circuits, </journal> <month> Aug </month> <year> 1984, </year> <pages> pp. 468-473 </pages>
Reference-contexts: During a transition on the input of a CMOS gate both p and n channel devices may conduct simultaneously, briey establishing a short from V DD to ground. In properly designed circuits, however, this short-circuit current typically dissipates a small fraction (5-10%) of the dynamic power <ref> [4] </ref> and will be omitted in further analyses. 2.2: Circuit Delay To fully utilize its hardware, a digital circuits clock frequency, f CLK , should be operated at the maximum allowable frequency. This maximum frequency is just the inverse of the delay of the processors critical path.
Reference: [5] <author> A. Chandrakasan, S. Sheng, R.W. Brodersen, </author> <title> Low-Power CMOS Digital Design, </title> <journal> IEEE Journal of Solid State Circuits, </journal> <month> Apr. </month> <year> 1992, </year> <pages> pp. 473-484. </pages>
Reference-contexts: This maximum frequency is just the inverse of the delay of the processors critical path. Thus, the circuits throughput is proportional to 1/delay. Until recently, the long-channel delay model (in which device current is proportional to the square of the supply voltage) suitably modelled delays in CMOS circuits <ref> [5] </ref>. However, scaling the minimum device channel length, L MIN , to below 1 micron (which is common in todays process technology), degrades the performance of the device due to velocity saturation of the channel electrons. <p> predominantly found in digital signal processing applications in which the throughput is fixed by the rate of an incoming or outgoing real-time signal (e.g.: speech, video). (EQ 6) Previous work has shown that the metric of energy efficiency in Equation 6 is valid for the fixed throughput mode of computation <ref> [5] </ref>. A lower value implies a more energy efficient solution. If a design can be made twice as energy efficient (i.e. reduce the energy/operation by a factor of two), then its sustainable battery life has been doubled; equivalently, its power dissipation has been halved. <p> Architectural Level: The predominant technique to increase energy efficiency is architectural concurrency; with regards to processors, this is generally known as instruction-level parallelism (ILP). Previous work on fixed throughput applications demonstrated an energy efficiency improvement of approximately N on an N-way parallel/ pipelined architecture <ref> [5] </ref>. This assumes that the algorithm is fully vectorizable, and that N is not excessively large. Moderate pipelining (4 or 5 stages), while originally implemented purely for speed, also increases energy efficiency, particularly in RISC processors that operate near one cycle-per-instruction.
Reference: [6] <author> R. Muller, T. Kamins, </author> <title> Device Electronics for Integrated Circuits, </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1986 </year>
Reference-contexts: This phenomenon occurs when the electric field (V DD / L MIN ) in the channel exceeds 1V/um <ref> [6] </ref>. Power V DD f CLK a i C L i DV N Power V DD 2 (EQ 4) The change in performance can be analytically characterized by what is known as the short-channel or velocity-saturated delay model shown in Equation 4.
Reference: [7] <author> M. Horowitz, T. Indermaur, R. Gonzalez, </author> <title> Low-Power Digital Design, </title> <booktitle> Proceedings of the Symposium on Low Power Electronics, </booktitle> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Thus, a lower ETR represents a more energy efficient solution. The Energy-Delay Product <ref> [7] </ref> is a similar metric, but does not include the effects of architectural parallelism when the delay is taken to be the critical path delay. In most circuits, however, ETR is not constant for different values of throughput. <p> By using an algorithm implementation that requires fewer operations, both the throughput is increased, and less energy is consumed because the total amount of switched capacitance to execute the program has been reduced. A quadratic improvement in ETR can be achieved <ref> [7] </ref>. This does not always imply that the program with the smallest dynamic instruction count (path length) is the most energy efficient, since the switching activity per instruction must be evaluated. What needs to be minimized is the number of primitive operations: memory operations, ALU operations, etc. <p> SPEC is either SPECint92, or if a oating point unit is present, the average of SPECint92 and SPECfp92 <ref> [7] </ref>. A misused metric for measuring energy efficiency is SPEC/ Watt (or Dhrystones/Watt, MIPS/Watt, etc.). Processor B may boast a SPEC/Watt eight times greater than As, and declare that it is eight times as energy efficient.
Reference: [8] <author> D. Wall, </author> <title> Limits of Instruction-Level Parallelism, </title> <note> DEC WRL Research Report 93/6, </note> <month> Nov. </month> <year> 1993. </year>
Reference: [9] <author> M. Johnson, </author> <title> Superscalar Microprocessor Design, </title> <publisher> Prentice Hall, </publisher> <address> Englewood, NJ, </address> <year> 1990. </year>
Reference: [10] <author> M. Smith, M. Johnson, M. Horowitz, </author> <title> Limits on Multiple Issue Instruction, </title> <booktitle> Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> Apr. </month> <year> 1989. </year> <pages> pp 290-302 </pages>
Reference-contexts: Therefore, the achievable speedup, S, will be less than the number of simultaneous issuable instructions, and yields diminishing returns as the peak issue rate is increased. S has been shown to be between two and three for practical hardware implementations in current technology <ref> [10] </ref>. If the code is dynamically scheduled in employing superscalar operation, as is currently common to enable backwards binary compatibility, the C EFF of the processor will increase due to the implementation of the hardware scheduler.
Reference: [11] <author> T. Burd, B. Peters, </author> <title> A Power Analysis of a Microprocessor: </title>
References-found: 11

