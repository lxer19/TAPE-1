URL: http://www.cs.toronto.edu/~zilio/pub/ThesisMain.ps
Refering-URL: http://www.cs.toronto.edu/~zilio/
Root-URL: http://www.cs.toronto.edu
Title: Physical Database Design Decision Algorithms and Concurrent Reorganization for Parallel Database Systems  
Author: by Daniel C. Zilio 
Degree: A thesis submitted in conformity with the requirements for the degree of Doctor of Philosophy  
Note: c Copyright by Daniel C. Zilio 1998  
Address: Toronto  
Affiliation: Graduate Department of Computer Science University of  
Abstract-found: 0
Intro-found: 1
Reference: [AF77] <author> James E. Ames and Derrell Foster. </author> <title> Dynamic file assignment in a star network. </title> <booktitle> In Proc. of the Computing Networks Symp., </booktitle> <pages> pages 36-39, </pages> <address> Gaithersburg, Maryland, </address> <month> December </month> <year> 1977. </year>
Reference-contexts: Besides considering the benefit and cost of a reorganization, the work also demonstrated that the old file allocation influenced the choice of the next allocation. Ames and Foster developed a heuristic for the file re-assignment problem on a distributed system <ref> [AF77] </ref>. Their reorganization algorithm first uses the static file allocation algorithm to get the next best allocation. Another decision then determines the reorganization strategy to create this new allocation.
Reference: [Ape88] <author> Peter M. G. Apers. </author> <title> Data allocation in distributed database systems. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 13(3) </volume> <pages> 263-304, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: They demonstrated that, under different disk scheduling and query frequencies, full declustering resulted in reduced disk utilizations and greater I/O parallelism. There has also been work on horizontal and vertical partitioning over a distributed DB system <ref> [CNP82, OV91, Ape88] </ref>. Vertical partitioning involves the partitioning of the tuples themselves. These methods create fragments so that queries could execute locally at the nodes where the fragment includes all its required attributes. Fragments are placed to reduce the communication costs. <p> The structure of the algorithm was designed to be similar to algorithms presented previously in the literature <ref> [Ape88, CNP82, OV91, Jak80] </ref>. In these algorithms, the key of most importance in terms of query performance is chosen as the partitioning key for a relation. This method is also used in the DBA's rules of thumbs defined in Chapter 3.
Reference: [BAC + 90] <author> Haran Boral, William Alexander, Larry Clay, George Copeland, Scott Danforth, Michael Franklin, Brian Hart, Marc Smith, and Patrick Valduriez. </author> <title> Prototyping Bubba, a highly parallel database system. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 4-24, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer).
Reference: [BFG95] <author> Chaitanya K. Baru, Gilles Fecteau, and Ambuj Goyal. </author> <title> DB2 Parallel Edition. </title> <journal> IBM Systems Journal, </journal> <volume> 34(2) </volume> <pages> 292-322, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: We evaluate these physical DB design algorithms experimentally in Chapter 5, using various workloads. To carry out these experiments, we implemented our algorithms as a prototype tool for a real SN DBMS: IBM DB2 PE <ref> [BFG95] </ref>. In Chapter 6, we study reorganization. We provide methods to determine a reorganization's benefit and cost. This chapter also describes our method of estimating the workload costs during a reorganization, and presents some possible reorganization algorithms. We identify the appropriate priority of a reorganization in various experimental cases. <p> These problems are defined in the context of parallel shared-nothing (distributed-memory) systems. We concentrate on shared-nothing systems because they are consistent with the hardware systems commonly used by current DB vendors as relational database system platforms. For example, vendors such as Teradata [CK92], Tandem [CC93], IBM <ref> [BFG95] </ref>, In-formix [Cla93], and Sybase have introduced DB products implemented for SN systems. Therefore, SN systems are a good system to study, so we concentrated on them in this dissertation. In parallel shared-nothing systems, an interconnection network connects a set of autonomous processing nodes. <p> We thus evaluate a simple naive non-iterative algorithm not involving the query optimizer or workload cost estimator. The difference between the naive solution and an exhaustive algorithm's solution demonstrates the need for an in depth search. Our example involves using the IBM DB2 PE optimizer <ref> [BFG95] </ref> and the calculations in Appendix A to determine response times for a particular workload. We use the example values given for the system parameters in Tables 2.1 and 2.2. <p> However, the concept of collocating relations is not new. The IBM DB2 PE product introduced node groups that are similar to our relation groups, and DB2 PE allows the DBA to create groups, assign relations to groups, and define a data placement for each group <ref> [BFG95] </ref>. Padmanabhan proposes an assignment heuristic called the Disjoint Assignment by Priority (DAP) algorithm that allows some relations to be collocated [Pad92]. <p> Some utilities for concurrent reorganization exist in commercial products to redistribute or rebalance a parallel data placement (e.g., the RELOAD command and other utilities in the Tandem NonStop-SQL product [CC93, Smi90, Tro96] and the REDISTRIBUTE command in the IBM DB2 PE product <ref> [BFG95] </ref>). Omiecinski describes a concurrent method to convert an index structure from a B+tree to a linear hash file when dynamic access is more predominant than sequential access [Omi88]. <p> Validating a Reorganization's Response Time To validate some of our analytic estimations for reorganizations, we used the PART relation from the TPC-D DB, and distributed it across an IBM DB2 PE system <ref> [BFG95] </ref> with four nodes. This relation was specified to have no indexes in one case and a nonclustering index on P SIZE in another case. PART was also partitioned on P P ART KEY .
Reference: [BKL + 84] <author> Raymond M. Bryant, Anthony E. Krzesinski, M. Seetha Lakshmi, , and K. Mani Chandy. </author> <title> The MVA priority approximation. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 2(4) </volume> <pages> 335-359, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: Bryant et al. developed a mean value analysis (MVA) technique that estimates performance under priority scheduling for a multi-class QNM, including batch and transaction classes <ref> [BKL + 84] </ref>. <p> We model each resource as an M/M/1 server [LZGS84]. The scheduling discipline at the resources were chosen in two ways. In the first way, only the processors use preemptive (PR) priority scheduling <ref> [LZGS84, EL88, BKL + 84] </ref>, and the other resources (disks and interconnect network) use FCFS scheduling. In the figures, the label CPU PR denotes this case. In the second way, all resources use preemptive priority scheduling. The label ALL PR denotes this second case in the figures. <p> We use an approximate mean value analysis (aMVA) method (as seen in Figure 6.3) to estimate costs with priorities and mixed-class workloads <ref> [EL88, BKL + 84] </ref>.
Reference: [BKT83] <author> R. M. Bryant, A. E. Krzesinski, and P. Teunissen. </author> <title> The MVA pre-empt resume priority approximation. </title> <booktitle> In Proc. of the ACM Int. Conf. on Measurement and Modeling of Computer Systems, ACM SIGMETRICS, </booktitle> <pages> pages 12-27, </pages> <address> Minneapolis, MN, </address> <year> 1983. </year>
Reference-contexts: Estimates for A (s) and r;k (N ) were calculated using the BKT approximation method <ref> [EL88, BKT83] </ref>. In this method, A (s) r;k (N ) = Q r;k (N e s ) in which e s is the unit vector with one at the s-th position and Q r;k (N e s ) is the queue length at server k of customer type r.
Reference: [BLS95] <author> Anna Brunstrom, Scott T. Leutenegger, and Rahul Simha. </author> <title> Experimental evaluation of dynamic data allocation strategies in a distributed database with changing work-loads. </title> <type> Technical Report NASA Contractor Report 195024, ICASE Report No. 95-2, </type> <institution> Institute for Computer Applications in Science and Engineering, NASA Langley Research Center, Hampton, VA, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: In this and in other migration work, reorganization intrusions on the workload are ignored. Brunstrom et al. describe a method to dynamically redistribute partitions across a two node system <ref> [BLS95] </ref>. The redistribution is initiated because a node's utilization threshold is exceeded. Movements are made from the highest to the lowest utilized node, and the cost of the moves are not considered.
Reference: [BPS90] <author> Elena Barucci, Renzo Pinzani, and Renzo Sprugnoli. </author> <title> Optimal selection of secondary indexes. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 16(1) </volume> <pages> 32-38, </pages> <month> January </month> <year> 1990. </year> <month> 223 </month>
Reference-contexts: This combination of clustering and indexing selection is usually done because many DBMS systems only allow clustering by way 44 Reference Primary Multiple Optimizer Workload Relation Objective Chosen Attributes Decisions Function Per Key Separated [ISR83] NO NO NO SIMPLE YES #pages <ref> [BPS90] </ref> NO NO NO SIMPLE YES #pages [FON92] NO NO YES SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE YES #pages [Wha87] YES NO NO SQL <p> Algorithms for index selection are characterized in Table 3.1. All of these algorithms include the selection of both primary and secondary indexes except for the algorithms that only select secondary indexes, namely the algorithms by Ip et al. [ISR83], Barucci et al. <ref> [BPS90] </ref>, Frank et al. [FON92], Capara et al. [CFM95], and Gupta et al. [GHRU97]. The algorithms in the table also make decisions for more than one relation at the same time. <p> also included constraints that make the solution more realistic, such as the disk capacity constraint. 46 The method by Barucci et al. considered optimization techniques to be computationally expensive, and hence solved the problem using a simple heuristic based on the properties of their objective function (number of pages accessed) <ref> [BPS90] </ref>. These properties are denoted as follows: 1. If the addition of an index increases the response time cost function, then this index should never be added. 2. If the deletion of an index from a set increases the response time, then the index should not be deleted from consideration.
Reference: [CABK88] <author> George Copeland, William Alexander, Ellen Boughter, and Tom Keller. </author> <title> Data place-ment in Bubba. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 99-108, </pages> <address> Chicago, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Based on simulations, Ghandiharizadeh concluded 49 that the former methods outperform the latter [Gha90]. Although there have been many data placement methods proposed that depend on partitioning keys <ref> [CABK88, Gha90, DGS + 90, FM89, MD97, PB92] </ref>, little attention has been paid to partitioning key selection. All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys [CABK88, Gha90, PB92]. <p> All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys <ref> [CABK88, Gha90, PB92] </ref>. However, some techniques have been created to automate the partitioning key selection. These include: * a method for distributed DB systems; and * a tool in a commercial DB system. <p> Also, since communication is less expensive in a SN system, the goal is to reduce all resource costs. To deal with data placement on a SN system, Copeland et al. created a method for MCC's SN DB system called Bubba <ref> [CABK88] </ref>. Their method assumes that the degree of declustering of each relation is given, and determines where the relation's partitions should be placed. They also assume the user supplies access frequencies (heat) for the relations. <p> For medium and large relation sizes, full declustering is thus appropriate. For relations smaller than N umN odes fi ReadSize pages, he applied assignment methods such as the method by Copeland et al. <ref> [CABK88] </ref>, random assignment, or round-robin assignment. Copeland et al.'s method and a round-robin assignment resulted in similar performance, and outperformed the random method. 3.1.5 Physical DB Design Decision Algorithms The importance of determining all the decisions required for a physical DB design has been surveyed by Graefe [Gra93]. <p> Unfortunately, the method does not define how this reorganization cost is obtained. Copeland et al. presented a dynamic data placement algorithm similar to their static placement algorithm, and this dynamic algorithm determines a reorganization strategy <ref> [CABK88] </ref>. However, their method only allows this strategy to execute if the estimated work required for the reorganization (its calculation and units are not defined in the paper) is less than the performance improvement provided by the new placement.
Reference: [Cas86] <author> Ignacio R. Casas. Prophet: </author> <title> A layered analytical model for performance prediction of database systems. </title> <type> Technical Report CSRI-180, PhD Thesis, </type> <institution> Dept. of Computer Science, University of Toronto, </institution> <month> April </month> <year> 1986. </year>
Reference-contexts: YES YES SQL op. trees [GGS96] NO Weighted NO YES YES SQL op. trees [TO78] NO Weighted YES NO NO Network DB plan [Pad92] NO Weighted YES YES YES SQL op. trees [Ser84] YES QNM YES NO NO Hierarchical DB plans [OPSS89] YES QNM YES NO NO Control flow graphs <ref> [Cas86] </ref> YES QNM YES NO NO Network DB plans [Hys91] YES QNM YES YES YES SQL op. trees Table 3.2: Summary of query and workload cost estimation work. a single query's expected response time as the time to traverse the critical path in the query operation trees (i.e., query plans) when <p> However, this method is not easily used since it is difficult to construct control flow graphs with probabilities from parallel DB queries. Methods directly using query plans, possibly output from an optimizer, are more convenient. Two methods by Serry [Ser84] and Casas <ref> [Cas86] </ref> used the query plans for a hierarchical or network DB on a single node. Serry used Sevcik's framework to estimate the workload costs over a hierarchical DB [Ser84], while Casas created an analytic predictor called PROPHET to estimate the workload costs for network and hierarchical DB systems [Cas86]. <p> and Casas <ref> [Cas86] </ref> used the query plans for a hierarchical or network DB on a single node. Serry used Sevcik's framework to estimate the workload costs over a hierarchical DB [Ser84], while Casas created an analytic predictor called PROPHET to estimate the workload costs for network and hierarchical DB systems [Cas86]. Their work defined the parameters that each layer required as input from a higher layer or an external user, and provided methods to calculate the outputs from each layer using these parameters. They also described how the service times for a QNM can be derived from the query plans.
Reference: [CBC93] <author> Sunil Choenni, Henk M. Blanken, and Thiel Chang. </author> <title> On the selection of secondary indices in relational databases. </title> <journal> Data & Knowledge Engineering, </journal> <volume> 11(3) </volume> <pages> 207-233, </pages> <year> 1993. </year>
Reference-contexts: Function Per Key Separated [ISR83] NO NO NO SIMPLE YES #pages [BPS90] NO NO NO SIMPLE YES #pages [FON92] NO NO YES SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages <ref> [CBC93] </ref> YES NO NO SIMPLE YES #pages [Wha87] YES NO NO SQL YES I/O [FST88] YES NO YES SQL NO Query times [CN97] YES YES YES SQL NO Query times Table 3.1: Summary of index selection work. of a clustering index. <p> Because this method evaluates the query costs resulting from all candidate keys, it is too expensive to use in realistic settings. To avoid the expense of selecting primary and secondary indexes together in one algorithm, Choenni et al. suggested a two-phase method <ref> [CBC93] </ref>. The first phase determines the primary indexes, while the second selects the secondary indexes based on the primary indexes chosen in the first phase and on a performance property called sub-optimality. A set of indexes is suboptimal when it is optimal conditioned on the chosen primary indexes.
Reference: [CC93] <author> Liz Chambers and Dave Cracknell. </author> <title> Parallel features of NonStop SQL. </title> <booktitle> In Int. Conf. on Parallel and Distributed Information Systems, </booktitle> <pages> pages 69-70, </pages> <address> San Diego, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: These problems are defined in the context of parallel shared-nothing (distributed-memory) systems. We concentrate on shared-nothing systems because they are consistent with the hardware systems commonly used by current DB vendors as relational database system platforms. For example, vendors such as Teradata [CK92], Tandem <ref> [CC93] </ref>, IBM [BFG95], In-formix [Cla93], and Sybase have introduced DB products implemented for SN systems. Therefore, SN systems are a good system to study, so we concentrated on them in this dissertation. In parallel shared-nothing systems, an interconnection network connects a set of autonomous processing nodes. <p> In this section, we survey a few concurrent reorganization utilities. Some utilities for concurrent reorganization exist in commercial products to redistribute or rebalance a parallel data placement (e.g., the RELOAD command and other utilities in the Tandem NonStop-SQL product <ref> [CC93, Smi90, Tro96] </ref> and the REDISTRIBUTE command in the IBM DB2 PE product [BFG95]). Omiecinski describes a concurrent method to convert an index structure from a B+tree to a linear hash file when dynamic access is more predominant than sequential access [Omi88].
Reference: [CFM95] <author> Alberto Capara, Matteo Fischetti, and Dario Maio. </author> <title> Exact and approximate algorithms for the index selection problem in physical database design. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 7(6) </volume> <pages> 955-967, </pages> <month> December </month> <year> 1995. </year>
Reference-contexts: Although both the indexing and partitioning key decisions select subsets of attributes, the indexing problem requires finding more than one indexing key, and thus more than one subset of attributes can be chosen per relation. In fact, index selection has been shown to be NP-complete <ref> [Com78, CFM95] </ref>. Capara et al. equated the index selection problem to the knapsack problem to produce this result [CFM95]. 2.3.6 Interactions Among the Physical DB Design Decisions All these five decisions interact and affect each other. One interaction is between the decisions for clustering and indexing keys. <p> In fact, index selection has been shown to be NP-complete [Com78, CFM95]. Capara et al. equated the index selection problem to the knapsack problem to produce this result <ref> [CFM95] </ref>. 2.3.6 Interactions Among the Physical DB Design Decisions All these five decisions interact and affect each other. One interaction is between the decisions for clustering and indexing keys. <p> is usually done because many DBMS systems only allow clustering by way 44 Reference Primary Multiple Optimizer Workload Relation Objective Chosen Attributes Decisions Function Per Key Separated [ISR83] NO NO NO SIMPLE YES #pages [BPS90] NO NO NO SIMPLE YES #pages [FON92] NO NO YES SQL YES CPU or I/O <ref> [CFM95] </ref> NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE YES #pages [Wha87] YES NO NO SQL YES I/O [FST88] YES NO YES SQL NO Query times [CN97] YES YES YES SQL NO <p> All of these algorithms include the selection of both primary and secondary indexes except for the algorithms that only select secondary indexes, namely the algorithms by Ip et al. [ISR83], Barucci et al. [BPS90], Frank et al. [FON92], Capara et al. <ref> [CFM95] </ref>, and Gupta et al. [GHRU97]. The algorithms in the table also make decisions for more than one relation at the same time. <p> To provide some guarantees on the closeness of the resulting performance to the optimal, Capara et al. equated the secondary index selection problem to a 0-1 integer linear programming problem, and solved it with a branch-and-bound method <ref> [CFM95] </ref>. The objective function was a linear function based on processor and I/O costs, and they provided many pruning rules based on the linearity of the function. However, cost functions including congestion delays, such as response time, are non-linear.
Reference: [CK92] <author> Felipe Carino Jr. and Pekka Kostamaa. </author> <title> Exegesis of DBC/1012 and P-90 industrial supercomputer database machines. </title> <booktitle> In Int. PARLE'92 Conf. Parallel Architectures and Languages Europe, </booktitle> <address> Paris, June 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: These problems are defined in the context of parallel shared-nothing (distributed-memory) systems. We concentrate on shared-nothing systems because they are consistent with the hardware systems commonly used by current DB vendors as relational database system platforms. For example, vendors such as Teradata <ref> [CK92] </ref>, Tandem [CC93], IBM [BFG95], In-formix [Cla93], and Sybase have introduced DB products implemented for SN systems. Therefore, SN systems are a good system to study, so we concentrated on them in this dissertation. In parallel shared-nothing systems, an interconnection network connects a set of autonomous processing nodes.
Reference: [Cla93] <author> D. Clay. </author> <title> Informix Parallel Data Query. </title> <booktitle> In Int. Conf. on Parallel and Distributed Information Systems, </booktitle> <pages> pages 71-72, </pages> <address> San Diego, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: These problems are defined in the context of parallel shared-nothing (distributed-memory) systems. We concentrate on shared-nothing systems because they are consistent with the hardware systems commonly used by current DB vendors as relational database system platforms. For example, vendors such as Teradata [CK92], Tandem [CC93], IBM [BFG95], In-formix <ref> [Cla93] </ref>, and Sybase have introduced DB products implemented for SN systems. Therefore, SN systems are a good system to study, so we concentrated on them in this dissertation. In parallel shared-nothing systems, an interconnection network connects a set of autonomous processing nodes.
Reference: [CLYY92] <author> Ming-Syan Chen, Mingling Lo, Philip S. Yu, and Honesty C. Young. </author> <title> Using segmented right-deep trees for the execution of pipelined hash joins. </title> <booktitle> In Proc. of the 18th Int. Conf. on VLDB, </booktitle> <pages> pages 15-26, </pages> <address> Vancouver, </address> <month> August </month> <year> 1992. </year>
Reference-contexts: We focus on the estimation methods for parallel optimization. These estimators are similar because they calculate 60 Reference Congestion Cost Multiple Comm. Parallel Query Delays Calculation Queries System Plans Estimation <ref> [CLYY92] </ref> NO Weighted NO YES YES SQL op. trees [HM94] NO Weighted NO YES YES SQL op. trees [GGS96] NO Weighted NO YES YES SQL op. trees [TO78] NO Weighted YES NO NO Network DB plan [Pad92] NO Weighted YES YES YES SQL op. trees [Ser84] YES QNM YES NO NO <p> If a child pipelines its result to its parent, the parent's time is calculated as the maximum of its resource usage times and its child's estimated time. Chen et al. <ref> [CLYY92] </ref> as well as Hasan and Motwani [HM94] determine the estimations assuming that each operator fully executes on a single node, so they do not include intra-operator parallelism estimation. Ganguly et al. consider intra-operator parallelism [GGS96].
Reference: [CM83] <author> John V. Carlis and Salvatore T. </author> <month> March. </month> <title> Computer-aided physical database design methodology. </title> <journal> Computer Performance, </journal> <volume> 4(4) </volume> <pages> 198-214, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: Techniques have been proposed in the literature that address all the physical DB design decisions in one algorithm. Unfortunately, all these methods, such as the ones given in Section 3.1.1, were developed for single node DB systems, and thus did not deal with partitioning decisions <ref> [MS78, CM83, RS91] </ref>. March and Severance [MS78] as well as Carlis and March [CM83] developed methods to select a physical DB design including indexes and record segmentation. Record segmentation is a partitioning of the records of a relation between primary and secondary memory. <p> Unfortunately, all these methods, such as the ones given in Section 3.1.1, were developed for single node DB systems, and thus did not deal with partitioning decisions [MS78, CM83, RS91]. March and Severance [MS78] as well as Carlis and March <ref> [CM83] </ref> developed methods to select a physical DB design including indexes and record segmentation. Record segmentation is a partitioning of the records of a relation between primary and secondary memory. Their workload consisted of simple single relation selections.
Reference: [CN97] <author> Surajit Chaudhuri and Vivek Narasayya. </author> <title> An efficient, cost-driven index selection tool for Microsoft SQL Server. </title> <booktitle> In Proc. of the 23th Int. Conf. on VLDB, </booktitle> <pages> pages 146-155, </pages> <address> Athens, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE YES #pages [Wha87] YES NO NO SQL YES I/O [FST88] YES NO YES SQL NO Query times <ref> [CN97] </ref> YES YES YES SQL NO Query times Table 3.1: Summary of index selection work. of a clustering index. We thus focus on the index selection problem for the remainder of this section. Algorithms for index selection are characterized in Table 3.1. <p> The index set that leads to lowest query costs is chosen. Another method that avoids the separability property was developed by Chaudhuri and Narasayya for the Microsoft SQL Server <ref> [CN97] </ref>. The index selection method is the same as the ADD method. However, they added some extra enhancements. First, they included a module to select the important candidate indexes, which are the indexes whose attributes are directly used in the queries. <p> One method would be to use the module FormMultiAttributeKeys in conjunction with the module ConsiderCompletion to form an iterative method of creating the possible multi-attribute keys. This is similar to the method by Chaudhuri and Narasayya, except that multi-attribute keys of more than two attributes are allowed <ref> [CN97] </ref>. In the first pass through FormMultiAttributeKeys, no multi-attributes are created. In the second pass, attribute pairs are formed as the first multi-attribute keys. In the third pass, multi-attribute keys of three attributes are formed, and so on to the k-th pass.
Reference: [CNP82] <author> Stefano Ceri, Mauro Negri, and Giuseppe Pelagatti. </author> <title> Horizontal data partitioning in database design. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 128-136, </pages> <address> Orlando, FL, </address> <month> June </month> <year> 1982. </year> <month> 224 </month>
Reference-contexts: Ceri et al.'s method partitions the relations into subranges based on predicates (minterms) so as to reduce the amount of communication during query executions and thus localize the executions at the distributed system nodes where the partitions reside <ref> [CNP82] </ref>. These minterms are constructed from the query predicates, and the attributes in the predicates form the partitioning keys. <p> They demonstrated that, under different disk scheduling and query frequencies, full declustering resulted in reduced disk utilizations and greater I/O parallelism. There has also been work on horizontal and vertical partitioning over a distributed DB system <ref> [CNP82, OV91, Ape88] </ref>. Vertical partitioning involves the partitioning of the tuples themselves. These methods create fragments so that queries could execute locally at the nodes where the fragment includes all its required attributes. Fragments are placed to reduce the communication costs. <p> The structure of the algorithm was designed to be similar to algorithms presented previously in the literature <ref> [Ape88, CNP82, OV91, Jak80] </ref>. In these algorithms, the key of most importance in terms of query performance is chosen as the partitioning key for a relation. This method is also used in the DBA's rules of thumbs defined in Chapter 3.
Reference: [CNW83] <author> Stefano Ceri, Shamkant Navathe, and Gio Wiederhold. </author> <title> Distribution design of logical database schemas. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 9(4) </volume> <pages> 487-504, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer).
Reference: [Com78] <author> Douglas Comer. </author> <title> The difficulty of optimum index selection. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 3(4) </volume> <pages> 440-445, </pages> <month> December </month> <year> 1978. </year>
Reference-contexts: Although both the indexing and partitioning key decisions select subsets of attributes, the indexing problem requires finding more than one indexing key, and thus more than one subset of attributes can be chosen per relation. In fact, index selection has been shown to be NP-complete <ref> [Com78, CFM95] </ref>. Capara et al. equated the index selection problem to the knapsack problem to produce this result [CFM95]. 2.3.6 Interactions Among the Physical DB Design Decisions All these five decisions interact and affect each other. One interaction is between the decisions for clustering and indexing keys.
Reference: [Cor96] <author> IBM Corporation. </author> <title> DB2 Parallel Edition for AIX: Administration guide and reference, </title> <year> 1996. </year>
Reference-contexts: For most systems, the process of selecting the proper database design, including the partitioning, is left to the DBA. Methods used by these administrators often involve self-built tools based on observations, rules of thumb, and intuition. Some rules of thumb given for IBM DB2 PE <ref> [Cor96] </ref> are: * the partitioning key should include the most frequently joined columns; * the partitioning key should include columns that often participate in a GROUP BY clause; and * the partitioning key should have enough distinct values to allow a balanced distribution of tuples across the nodes.
Reference: [DF82] <author> Lawrence W. Dowdy and Derrell V. Foster. </author> <title> Comparative models of the file assignment problem. </title> <journal> ACM Computing Surveys, </journal> <volume> 14(2) </volume> <pages> 287-313, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: No other collocations were considered. 3.1.4 Data Placement Placing file partitions across a set of nodes was initially solved as a file assignment problem in which whole files were placed at a node. A survey of this work is given by Dowdy and Foster <ref> [DF82] </ref>. These problems were formulated as optimization problems with decision variables representing the placement of the files on specific nodes, and were solved by heuristics since 51 the problem was proven to be NP-complete [DF82]. The objective functions were weighted formulas, usually linear, of the resource costs. <p> A survey of this work is given by Dowdy and Foster <ref> [DF82] </ref>. These problems were formulated as optimization problems with decision variables representing the placement of the files on specific nodes, and were solved by heuristics since 51 the problem was proven to be NP-complete [DF82]. The objective functions were weighted formulas, usually linear, of the resource costs. Resource costs varied, but usually involved I/O and processing times with an equal weighting between them. <p> Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer).
Reference: [DG92] <author> David J. DeWitt and Jim Gray. </author> <title> Parallel database systems: The future of high performance database systems. </title> <journal> Comm. of the ACM, </journal> <volume> 35(6) </volume> <pages> 85-98, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Minimizing the interference of the reorganization with the workload is desirable in current and future DB systems since these systems require that the DB be available to users continuously (24 hours a day, seven days a week <ref> [DG92] </ref>). To provide for this availability during a reorganization, reorganizations must be designed to execute concurrently (on-line) with the normal DB workload while introducing minimal delays. A new physical DB design should be chosen such that the cost of the reorganization is outweighed by its benefit. <p> Each of the nodes has its own processor (s), local memory, and disk drive (s). Since shared-memory (SMP) machines provide good performance compared to a single processor machine, a node could be an SMP machine. Because SN systems can be constructed using off-the-shelf hardware, they have low price/performance ratios <ref> [DG92] </ref>. DB management systems on a shared-nothing system are constructed so that all the nodes of the system work together to provide the image of a single DBMS server. There are DB management processes on each node. Each node's processes handle the portion of the DB stored on its disks. <p> In the literature, the partitioning methods using these functions are called hash partitioning and range partitioning, respectively <ref> [DG92] </ref>. When the number of partitions equals the number of nodes, we call the partitioning a full declustering; otherwise the partitioning is called partial declustering. Once the number of partitions is determined, fragments must be mapped to partitions. <p> In current systems, it is preferred that the DB be available to the users at all times to prevent the queries from incurring excess delay <ref> [DG92] </ref>. Given this availability constraint, on-line execution strategies would cause lower delays for the workload queries. The priority at which the reorganization strategy executes relative to the queries' priorities directly affects the concurrency allowed. <p> Reorganization algorithms can be subdivided into: * off-line algorithms; and * concurrent reorganization algorithms. Because of the "24 fi 7" availability requirement, reorganization algorithms should provide for concurrent reorganizations <ref> [DG92] </ref>. However, the off-line algorithms cannot be ignored as they can be adapted to develop on-line algorithms. The utilities are also of interest because a good reorganization algorithm would use these utilities to construct reorganization strategies. We discuss some existing utilities in Section 3.2.1.
Reference: [DGS + 90] <author> David J. DeWitt, Shahram Ghandeharizadeh, D. A. Schneider, A. Bricker, Hui-I Hsaio, and R. Rasmussen. </author> <title> The GAMMA database machine project. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 44-62, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: Based on simulations, Ghandiharizadeh concluded 49 that the former methods outperform the latter [Gha90]. Although there have been many data placement methods proposed that depend on partitioning keys <ref> [CABK88, Gha90, DGS + 90, FM89, MD97, PB92] </ref>, little attention has been paid to partitioning key selection. All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys [CABK88, Gha90, PB92].
Reference: [EL88] <author> Derek L. Eager and John N. Lipscomb. </author> <title> The AMVA priority approximation. Performance Evaluation, </title> <booktitle> 8 </booktitle> <pages> 173-193, </pages> <year> 1988. </year>
Reference-contexts: Because the exact MVA method to model priority scheduling is a computationally expensive technique, Eager and Lipscomb formulated an approximate MVA (aMVA) approach, and described the technique that can be used when the workload is modeled with closed classes <ref> [EL88] </ref>. The method changes the residence time calculations by including the service times of higher and equal priority queries that obtain service before a given query. They applied the approach to three different MVA priority approximation techniques: * MVA-shadow approximation; * Bryant-Krzesinski-Teunissen (BKT) approximation; and * Chandy-Lakshmi (CL) approximation. <p> We model each resource as an M/M/1 server [LZGS84]. The scheduling discipline at the resources were chosen in two ways. In the first way, only the processors use preemptive (PR) priority scheduling <ref> [LZGS84, EL88, BKL + 84] </ref>, and the other resources (disks and interconnect network) use FCFS scheduling. In the figures, the label CPU PR denotes this case. In the second way, all resources use preemptive priority scheduling. The label ALL PR denotes this second case in the figures. <p> We use an approximate mean value analysis (aMVA) method (as seen in Figure 6.3) to estimate costs with priorities and mixed-class workloads <ref> [EL88, BKL + 84] </ref>. <p> Estimates for A (s) and r;k (N ) were calculated using the BKT approximation method <ref> [EL88, BKT83] </ref>. In this method, A (s) r;k (N ) = Q r;k (N e s ) in which e s is the unit vector with one at the s-th position and Q r;k (N e s ) is the queue length at server k of customer type r.
Reference: [Fle87] <author> R. Fletcher. </author> <title> Practical Methods of Optimization: 2nd Edition. </title> <publisher> John Wiley and Sons, </publisher> <year> 1987. </year>
Reference-contexts: Standard branch-and-bound algorithms are guaranteed 66 to find optimal solutions based on the cost model and assumptions made for the algorithm <ref> [LW66, Fle87, PR88, RND77] </ref>. A solution is a set of decision variables along with the values that are assigned to them. Two types of solutions exist. A solution that satisfies all constraints and in which all decision variables have been assigned values is called a complete solution. <p> This effectively removes all the solutions that can be derived from S c since cost (S c ) is a lower bound on all the solutions derivable from S c . This branching and pruning technique is always a part of branch-and-bound algorithm descriptions <ref> [Fle87, PR88] </ref>. As a consequence, determining a good lower bound that is as high as possible allows the algorithm to narrow the search space more effectively by allowing quicker progress toward finding a solution that minimizes the objective function. <p> We use this lower bound to check against the best known solution's ART. If the bound is greater than the best known ART, then this partial solution (X) is pruned. This follows the standard branch-and-bound technique <ref> [Fle87, PR88] </ref>. The lower bound is also used to choose the next partial solution to consider in the search, as in the standard branch-and-bound technique. The minimum cost of a query accounts for the minimum I/O and processor times for a query and any choice of partitioning, clustering, and indexing.
Reference: [FM89] <author> Christos Faloutsos and Dimitrios Metaxas. </author> <title> Declustering using error correcting codes. </title> <booktitle> In Proc. of the ACM SIGACT-SIGMOD-SIGART Symp. on Principles of Database Systems, </booktitle> <pages> pages 253-258, </pages> <address> Philadelphia, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: Based on simulations, Ghandiharizadeh concluded 49 that the former methods outperform the latter [Gha90]. Although there have been many data placement methods proposed that depend on partitioning keys <ref> [CABK88, Gha90, DGS + 90, FM89, MD97, PB92] </ref>, little attention has been paid to partitioning key selection. All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys [CABK88, Gha90, PB92].
Reference: [FON92] <author> Martin R. Frank, Edward R. Omiecinski, and Shamkant B. Navathe. </author> <title> Adaptive and automated index selection in RDBMS. </title> <booktitle> In Proc. of the Int. Conf. on Extending Database Technology (EDBT), </booktitle> <pages> pages 277-292, </pages> <address> Vienna, Austria, </address> <month> March </month> <year> 1992. </year>
Reference-contexts: This combination of clustering and indexing selection is usually done because many DBMS systems only allow clustering by way 44 Reference Primary Multiple Optimizer Workload Relation Objective Chosen Attributes Decisions Function Per Key Separated [ISR83] NO NO NO SIMPLE YES #pages [BPS90] NO NO NO SIMPLE YES #pages <ref> [FON92] </ref> NO NO YES SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE YES #pages [Wha87] YES NO NO SQL YES I/O [FST88] YES NO YES SQL <p> Algorithms for index selection are characterized in Table 3.1. All of these algorithms include the selection of both primary and secondary indexes except for the algorithms that only select secondary indexes, namely the algorithms by Ip et al. [ISR83], Barucci et al. [BPS90], Frank et al. <ref> [FON92] </ref>, Capara et al. [CFM95], and Gupta et al. [GHRU97]. The algorithms in the table also make decisions for more than one relation at the same time. <p> Another heuristic developed by Frank et al. constructs plausible sets of indexes that should be passed to an optimizer so as to determine the effects and resulting response time for a query using this set <ref> [FON92] </ref>. The set of plausible index sets for a query consist initially of all the indexes that could be used in the query.
Reference: [FST88] <author> S. Finkelstein, Mario Schkolnick, and Paulo Tiberio. </author> <title> Physical database design for relational databases. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 13(1) </volume> <pages> 91-128, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: NO SIMPLE YES #pages [FON92] NO NO YES SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE YES #pages [Wha87] YES NO NO SQL YES I/O <ref> [FST88] </ref> YES NO YES SQL NO Query times [CN97] YES YES YES SQL NO Query times Table 3.1: Summary of index selection work. of a clustering index. We thus focus on the index selection problem for the remainder of this section. Algorithms for index selection are characterized in Table 3.1. <p> All of these previous methods depend on the separability property, and thus their resulting decisions may not be optimal. Finkelstein et al. avoided this problem by eliminating the separability assumption as much as possible <ref> [FST88] </ref>. This algorithm uses an optimizer to help determine the cost effects of an index on the workload. <p> Second, a module is provided to include multi-attribute indexes consisting of two attributes. Third, their objective function is a sum of each query's estimated execution cost returned by the optimizer, which does not include congestion delays. This is similar to the objective function used by Finkelstein et al. <ref> [FST88] </ref>. One goal of their algorithm was to use a low number of optimizer calls by deriving the cost of an index set from atomic index sets for each query. Reducing the number of calls was deemed necessary since each call is time consuming. <p> Because of this, the decision to take the shortcut is left to the discretion of the DBA. Our shortcut involves an extra pre-scanning rule where we remove nonclustering indexing keys from the search. This rule is taken from Finkelstein et al.'s index selection algorithm <ref> [FST88] </ref>, and affects the selection of indexing keys that do not cluster a relation but that are involved in a join when the indexing and clustering decisions are tied together. <p> The workload ART resulting from each candidate physical DB design is used for comparing designs as in the PARING algorithm. This CR algorithm is adapted from an index selection algorithm by Finkelstein et al. <ref> [FST88] </ref>, which constructs a list of keys that are good candidates for indexing, and selects subsets of keys from this candidate key list. <p> The main idea of CR is to use the attribute aggregate weighting calculations to rank the keys. Weighting was not used in 107 Finkelstein's algorithm, so the number of possible keys considered by that algorithm is greater than CR's <ref> [FST88] </ref>. We use the same weighting as in the IR algorithm, which used it for partitioning key selection, but supplement it with weighting for indexable keys as described in Appendix C. <p> A solution that can have join keys added to it as partitioning, indexing, and clustering keys is also considered a partial solution. 2 The term survivor list was taken from Finkelstein et al.'s algorithm <ref> [FST88] </ref>. 108 algorithm CR Algorithm input: Query set Q, DB information, system information, ff pruning factor (0 ff 1) output: Complete solution S B having best cost: cost (Q; S B ) objective: Find a solution that minimizes average workload response time definitions: L is the set of keys (each composed <p> We also added the pruning of solutions with unused keys, as in the PARING algorithm. This rule causes our CR algorithm to differ even more from Finkelstein et al.'s <ref> [FST88] </ref> since they did not consider this extra pruning. 111 -- S.C Q.ES.C S.D Q.E S.D Q.E Q.E key decision variable. -- S.C Q.ES.C S.D Q.E S.D Q.E Q.E Q.E is to be chosen and all keys shown are assigned to the appropriate relation's partitioning key decision variable.
Reference: [GD90] <author> Shahram Ghandeharizadeh and David DeWitt. </author> <title> Hybrid-range partitioning: A new declustering strategy for multiprocessor database machines. </title> <booktitle> In Proc. of the 16th Int. Conf. on VLDB, </booktitle> <pages> pages 481-492, </pages> <address> Brisbane, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer).
Reference: [GGS96] <author> Sumit Ganguly, Ashkay Goel, and Avi Silberschatz. </author> <title> Efficient and accurate cost models for parallel query optimization. </title> <booktitle> In Proc. of the ACM SIGACT-SIGMOD-SIGART Symp. on Principles of Database Systems, </booktitle> <pages> pages 172-181, </pages> <address> Montreal, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: We focus on the estimation methods for parallel optimization. These estimators are similar because they calculate 60 Reference Congestion Cost Multiple Comm. Parallel Query Delays Calculation Queries System Plans Estimation [CLYY92] NO Weighted NO YES YES SQL op. trees [HM94] NO Weighted NO YES YES SQL op. trees <ref> [GGS96] </ref> NO Weighted NO YES YES SQL op. trees [TO78] NO Weighted YES NO NO Network DB plan [Pad92] NO Weighted YES YES YES SQL op. trees [Ser84] YES QNM YES NO NO Hierarchical DB plans [OPSS89] YES QNM YES NO NO Control flow graphs [Cas86] YES QNM YES NO NO <p> Chen et al. [CLYY92] as well as Hasan and Motwani [HM94] determine the estimations assuming that each operator fully executes on a single node, so they do not include intra-operator parallelism estimation. Ganguly et al. consider intra-operator parallelism <ref> [GGS96] </ref>. Because the timing formulas of all these optimization methods are just weighted sums of the estimated resource times, no congestion delays at the resources are considered.
Reference: [Gha90] <author> Shahram Ghandeharizadeh. </author> <title> Physical database design in multiprocessor database systems. </title> <type> Technical Report #964, PhD Thesis, </type> <institution> Computer Sciences Dept., Univ. of Wisconsin-Madison, </institution> <month> September </month> <year> 1990. </year>
Reference-contexts: There are hash and range partitioning that are based on partitioning keys; and there is the round-robin partitioning that does not depend on partitioning keys. Based on simulations, Ghandiharizadeh concluded 49 that the former methods outperform the latter <ref> [Gha90] </ref>. Although there have been many data placement methods proposed that depend on partitioning keys [CABK88, Gha90, DGS + 90, FM89, MD97, PB92], little attention has been paid to partitioning key selection. <p> Based on simulations, Ghandiharizadeh concluded 49 that the former methods outperform the latter [Gha90]. Although there have been many data placement methods proposed that depend on partitioning keys <ref> [CABK88, Gha90, DGS + 90, FM89, MD97, PB92] </ref>, little attention has been paid to partitioning key selection. All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys [CABK88, Gha90, PB92]. <p> All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys <ref> [CABK88, Gha90, PB92] </ref>. However, some techniques have been created to automate the partitioning key selection. These include: * a method for distributed DB systems; and * a tool in a commercial DB system. <p> These partial matches effects apply to the different types of partitioning that use multi-attribute partitioning, for example: * a grid-file approach, where each attribute corresponds to a dimension in the grid <ref> [Gha90, NHS84] </ref>; and * a partitioning approach, where the values for the attributes in the multi-attribute key are combined in a function to return one logical partition number, such as hash partitioning.
Reference: [GHRU97] <author> Himanshu Gupta, Venky Harinarayan, Anand Rajaraman, and Jeffrey D. Ullman. </author> <title> Index selection for OLAP. </title> <booktitle> In Proc. of the Int. Conf. on Data Engineering, </booktitle> <pages> pages 208-219, </pages> <address> Birmingham, U.K., April 1997. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: clustering by way 44 Reference Primary Multiple Optimizer Workload Relation Objective Chosen Attributes Decisions Function Per Key Separated [ISR83] NO NO NO SIMPLE YES #pages [BPS90] NO NO NO SIMPLE YES #pages [FON92] NO NO YES SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O <ref> [GHRU97] </ref> NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE YES #pages [Wha87] YES NO NO SQL YES I/O [FST88] YES NO YES SQL NO Query times [CN97] YES YES YES SQL NO Query times Table 3.1: Summary of index selection work. <p> All of these algorithms include the selection of both primary and secondary indexes except for the algorithms that only select secondary indexes, namely the algorithms by Ip et al. [ISR83], Barucci et al. [BPS90], Frank et al. [FON92], Capara et al. [CFM95], and Gupta et al. <ref> [GHRU97] </ref>. The algorithms in the table also make decisions for more than one relation at the same time. <p> However, cost functions including congestion delays, such as response time, are non-linear. Gupta et al. provide a method that selects single attribute and multi-attribute indexing keys <ref> [GHRU97] </ref>. Their algorithm determines secondary indexes for data warehousing views, and determines the views themselves. A greedy scheme is used for each iteration to find a new candidate view or index set that most reduces query costs compared to all other candidates. This method has some deficiencies.
Reference: [GJ78] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Intractability: A guide to the theory of NP-Completeness. W.H. </title> <publisher> Freeman and Co., </publisher> <year> 1978. </year>
Reference: [Gra93] <author> Goetz Graefe. </author> <title> Options in physical database design. </title> <journal> ACM SIGMOD Record, </journal> <volume> 22(3) </volume> <pages> 76-83, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: For a parallel DB system, another decision that can be made when choosing an index is whether to make the index a local or global index <ref> [Gra93] </ref>. A local index is really a group of indexes, where one index is created for each of the relation's partitions and the index referencing a partition is stored at the same node as the partition. <p> Copeland et al.'s method and a round-robin assignment resulted in similar performance, and outperformed the random method. 3.1.5 Physical DB Design Decision Algorithms The importance of determining all the decisions required for a physical DB design has been surveyed by Graefe <ref> [Gra93] </ref>. In this survey, Graefe stated the need to investigate indexing, clustering, and partitioning decisions, and noted that some of the physical DB design decisions are interdependent. In this section, we survey methods that were designed to make these interdependent choices.
Reference: [GS90] <author> Bezalel Gavish and Olivia R. Liu Sheng. </author> <title> Dynamic file migration in distributed computer systems. </title> <journal> Comm. of the ACM, </journal> <volume> 33(2) </volume> <pages> 177-189, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: A survey of the differences between these areas and the issues involved was presented by Gavish and Sheng <ref> [GS90] </ref>. File migration takes into account only local information at node pairs and moves files dynamically in an ad hoc fashion to adjust some problem in the system (usually reducing the load at highest utilized nodes).
Reference: [Hab90] <author> Franz Haberhauer. </author> <title> Physical database design aspects of relational DBMS implementations. </title> <journal> Information Systems, </journal> <volume> 15(3) </volume> <pages> 375-389, </pages> <year> 1990. </year>
Reference-contexts: We review these methods in Section 3.1.5. A survey of the issues relating to selecting a physical DB design, including the importance of using query plans from a DBMS optimizer to determine the effects of the DB design choices, is given by Haberhauer <ref> [Hab90] </ref>. 3.1.1 Clustering, Ordering, and Indexing Key Selection Although the ordering and clustering key selection is an important problem, only Jakobsson presented a method to select the ordering keys alone [Jak80].
Reference: [HCL + 90] <author> Laura M. Haas, Walter Chang, Guy M. Lohman, John McPherson, Paul F. Wilms, George Lapis, Bruce Lindsay, Hamid Pirahesh, Michael J. Carey, and Eugene Shekita. </author> <title> Starburst Mid-Flight: As the dust clears. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1) </volume> <pages> 143-160, </pages> <month> March </month> <year> 1990. </year>
Reference: [HL90] <author> Kien A. Hua and Chiang Lee. </author> <title> An adaptive data placement scheme for parallel database computer systems. </title> <booktitle> In Proc. of the 16th Int. Conf. on VLDB, </booktitle> <pages> pages 493-506, </pages> <address> Brisbane, Australia, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: A similar rebalancing algorithm to Copeland et al.'s was given by Hua and Lee, where the access frequency is replaced with the size of the partitions <ref> [HL90] </ref>. The grid cells of a multidimensional grid file are assumed to be the fragments that are placed on the nodes. <p> Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer).
Reference: [HM94] <author> Waqar Hasan and Rajeev Motwani. </author> <title> Optimization algorithms for exploiting the parallelism-communication tradeoff in pipelined parallelism. </title> <booktitle> In Proc. of the 20th Int. Conf. on VLDB, </booktitle> <pages> pages 36-47, </pages> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: We focus on the estimation methods for parallel optimization. These estimators are similar because they calculate 60 Reference Congestion Cost Multiple Comm. Parallel Query Delays Calculation Queries System Plans Estimation [CLYY92] NO Weighted NO YES YES SQL op. trees <ref> [HM94] </ref> NO Weighted NO YES YES SQL op. trees [GGS96] NO Weighted NO YES YES SQL op. trees [TO78] NO Weighted YES NO NO Network DB plan [Pad92] NO Weighted YES YES YES SQL op. trees [Ser84] YES QNM YES NO NO Hierarchical DB plans [OPSS89] YES QNM YES NO NO <p> If a child pipelines its result to its parent, the parent's time is calculated as the maximum of its resource usage times and its child's estimated time. Chen et al. [CLYY92] as well as Hasan and Motwani <ref> [HM94] </ref> determine the estimations assuming that each operator fully executes on a single node, so they do not include intra-operator parallelism estimation. Ganguly et al. consider intra-operator parallelism [GGS96].
Reference: [Hsa90] <author> Hui-I Hsaio. </author> <title> Performance and availability in database machines with replicated data. </title> <type> Technical Report #963, PhD Thesis, </type> <institution> Computer Sciences Dept., University of Wisconsin-Madison, </institution> <month> August </month> <year> 1990. </year>
Reference-contexts: No portions of the DB are replicated across two or more nodes. This was used because replication methods, such as Hsaio's method <ref> [Hsa90] </ref>, can be applied after our physical DB design is chosen. 4. The only index structures we consider for our systems are B-trees, which are used by current SN DB vendors. 5. All indexes are implemented as local indexes because current SN DB vendors use local indexes. <p> Replication of relations can be added. However, previous work such as Hsaio's chained declustering techniques that include replication with data placement have demonstrated that the replication decisions can be applied after the data placement is chosen <ref> [Hsa90] </ref>. The first four additions would present more cases for an algorithm to consider, and hence, a selection algorithm with intelligent pruning, such as the ones based on a branch-and-bound strategy, would be even more beneficial.
Reference: [Hys91] <author> William F. Hyslop. </author> <title> Performance prediction of relational database management systems. </title> <type> Technical Report CSRI-254, PhD Thesis, </type> <institution> Dept. of Computer Science, University of Toronto, </institution> <month> September </month> <year> 1991. </year> <month> 226 </month>
Reference-contexts: YES YES SQL op. trees [TO78] NO Weighted YES NO NO Network DB plan [Pad92] NO Weighted YES YES YES SQL op. trees [Ser84] YES QNM YES NO NO Hierarchical DB plans [OPSS89] YES QNM YES NO NO Control flow graphs [Cas86] YES QNM YES NO NO Network DB plans <ref> [Hys91] </ref> YES QNM YES YES YES SQL op. trees Table 3.2: Summary of query and workload cost estimation work. a single query's expected response time as the time to traverse the critical path in the query operation trees (i.e., query plans) when executing on a parallel SN system. <p> In their approaches, the processor and disk timings are estimated. Hyslop expanded upon the techniques by Sevcik and Casas to create a layered estimation method for a relational DB system that was applied to a parallel SN Teradata system <ref> [Hys91] </ref>. SQL-like operation trees are used to determine the service times of the resources. Communication times are included along with formulas to derive the parallel execution times for a query and its operators. <p> In our estimations, we used simple estimates for buffering and skew, and we ignored the delays resulting from concurrency control, data skew, load skew, recovery, logging, and 221 buffer management. More accurate calculations of these (such as the ones derived by Hyslop <ref> [Hys91] </ref>) would provide results closer to real query execution times. We included only congestion delays. This inclusion allows us to prune away designs along with any of their related designs that may result in the workload saturating the system.
Reference: [ISR83] <author> Maggie Y. L. Ip, L. V. Saxton, and Vijay V. Raghavan. </author> <title> On the selection of an optimal set of indexes. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 9(2) </volume> <pages> 135-143, </pages> <month> March </month> <year> 1983. </year>
Reference-contexts: This combination of clustering and indexing selection is usually done because many DBMS systems only allow clustering by way 44 Reference Primary Multiple Optimizer Workload Relation Objective Chosen Attributes Decisions Function Per Key Separated <ref> [ISR83] </ref> NO NO NO SIMPLE YES #pages [BPS90] NO NO NO SIMPLE YES #pages [FON92] NO NO YES SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE <p> Algorithms for index selection are characterized in Table 3.1. All of these algorithms include the selection of both primary and secondary indexes except for the algorithms that only select secondary indexes, namely the algorithms by Ip et al. <ref> [ISR83] </ref>, Barucci et al. [BPS90], Frank et al. [FON92], Capara et al. [CFM95], and Gupta et al. [GHRU97]. The algorithms in the table also make decisions for more than one relation at the same time. <p> We will now discuss the secondary index selection methods followed by the methods that select both the primary and secondary indexes. Ip et al. solved the index selection problem as a knapsack problem for each relation on a single node <ref> [ISR83] </ref>.
Reference: [Jak80] <author> Matti Jakobsson. </author> <title> Reducing block accesses in inverted files by partial clustering. </title> <journal> Information Systems, </journal> <volume> 5(1) </volume> <pages> 1-5, </pages> <year> 1980. </year>
Reference-contexts: using query plans from a DBMS optimizer to determine the effects of the DB design choices, is given by Haberhauer [Hab90]. 3.1.1 Clustering, Ordering, and Indexing Key Selection Although the ordering and clustering key selection is an important problem, only Jakobsson presented a method to select the ordering keys alone <ref> [Jak80] </ref>. He assumed that the probability of access, or access frequency, of each attribute in a relation was given, and created an ordering key by sorting all the attributes in descending order based on these probabilities. This sorted list becomes the ordering key. <p> The structure of the algorithm was designed to be similar to algorithms presented previously in the literature <ref> [Ape88, CNP82, OV91, Jak80] </ref>. In these algorithms, the key of most importance in terms of query performance is chosen as the partitioning key for a relation. This method is also used in the DBA's rules of thumbs defined in Chapter 3.
Reference: [LKB87] <author> Miron Livny, Setrag Khoshafian, and Haran Boral. </author> <title> Multi-disk management algorithms. </title> <booktitle> In Proc. of the ACM Int. Conf. on Measurement and Modeling of Computer Systems, ACM SIGMETRICS, </booktitle> <pages> pages 69-77, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: This decluster-ing spread the accesses to the relations across the nodes, thus spreading the I/O costs for the accesses across the nodes. To justify the usefulness of declustering, Livny et al. provided simulation studies to compare no declustering to full declustering over multi-disk subsystems <ref> [LKB87] </ref>. They demonstrated that, under different disk scheduling and query frequencies, full declustering resulted in reduced disk utilizations and greater I/O parallelism. There has also been work on horizontal and vertical partitioning over a distributed DB system [CNP82, OV91, Ape88]. Vertical partitioning involves the partitioning of the tuples themselves.
Reference: [LW66] <author> Eugene L. Lawler and D. E. Wood. </author> <title> Branch-and-bound methods: A survey. </title> <journal> Operations Research, </journal> <pages> pages 699-719, </pages> <month> July </month> <year> 1966. </year>
Reference-contexts: Standard branch-and-bound algorithms are guaranteed 66 to find optimal solutions based on the cost model and assumptions made for the algorithm <ref> [LW66, Fle87, PR88, RND77] </ref>. A solution is a set of decision variables along with the values that are assigned to them. Two types of solutions exist. A solution that satisfies all constraints and in which all decision variables have been assigned values is called a complete solution. <p> Using this relaxation follows the suboptimization alluded to by Lawler and Wood <ref> [LW66] </ref>. This is accomplished by pruning any partial solution for which cost (U c ; S c ) fi (1 + r) cost (Q; S min ). The pruning is possible because our cost function is monotonic.
Reference: [LZGS84] <author> Edward D. Lazowska, John Zahorjan, G. Scott Graham, and Kenneth C. Sevcik. </author> <title> Quantitative System Performance. </title> <publisher> Prentice-Hall, </publisher> <year> 1984. </year>
Reference-contexts: The errors due to QNM calculations are probably dominated by other errors in this application. We make the following assumptions: 1. Calculations of performance measures based on queuing network models are acceptably accurate <ref> [LZGS84] </ref>. 2. We assume an SQL class' arrivals are spread uniformly and independently over an interval of time. This models the average behaviour of the use of a real DB system. <p> To better estimate workload costs that include congestion delays, Sevcik [Sev81] constructed a layered framework. The highest layers involved the logical DB design, and the lowest layer modeled the execution of queries on the physical resources with a queuing network model (QNM), as defined by Lazowska et al. <ref> [LZGS84] </ref>. In Sevcik's method, each resource is modeled as a server with a queue, and a query's execution is broken down into its service times required for each resource. Because queuing is considered, the technique estimates the congestion delays that each query incurs due to the others. <p> This is done by using the utilizations to inflate the resource usage of a transaction's operators (R O s s;k = s;k S s;k ). This inflation method is used for modeling transaction class workloads in an open QNM <ref> [LZGS84] </ref>. <p> Determining this slowest node requires that we use information about the nodes at which an operator executes. The summation of the residence times in T O s uses the same technique as in the QNM estimations <ref> [LZGS84] </ref>, but accounts for the parallel execution among the nodes. These calculations are followed by the workload's average response time (ART ) calculation. Before determining the costs of an operator, the operator's children are investigated. <p> Thus, both the send and receive costs would be incurred at the overlapping nodes, so a sum of the send and receive costs at these nodes is used. Our cost estimation method as shown in Figure 4.13 differs from the approximate mean-value analysis (aMVA) method used in QNM literature <ref> [LZGS84] </ref>. <p> We model each resource as an M/M/1 server <ref> [LZGS84] </ref>. The scheduling discipline at the resources were chosen in two ways. In the first way, only the processors use preemptive (PR) priority scheduling [LZGS84, EL88, BKL + 84], and the other resources (disks and interconnect network) use FCFS scheduling. In the figures, the label CPU PR denotes this case. <p> We model each resource as an M/M/1 server [LZGS84]. The scheduling discipline at the resources were chosen in two ways. In the first way, only the processors use preemptive (PR) priority scheduling <ref> [LZGS84, EL88, BKL + 84] </ref>, and the other resources (disks and interconnect network) use FCFS scheduling. In the figures, the label CPU PR denotes this case. In the second way, all resources use preemptive priority scheduling. The label ALL PR denotes this second case in the figures. <p> The use of throughputs was also considered for the formulas instead of using response times. The system must be able to service the queries at their arrival rates, to avoid saturation <ref> [LZGS84] </ref>. Thus, the throughput for a query class should be equal to the class's arrival rate. However, the input arrival rate for a query class is assumed to be constant before, during, and after a reorganization.
Reference: [MD97] <author> Manish Mehta and David J. Dewitt. </author> <title> Data placement in shared-nothing parallel database systems. </title> <journal> The VLDB Journal, </journal> <volume> 6(1) </volume> <pages> 53-72, </pages> <month> January </month> <year> 1997. </year>
Reference-contexts: Based on simulations, Ghandiharizadeh concluded 49 that the former methods outperform the latter [Gha90]. Although there have been many data placement methods proposed that depend on partitioning keys <ref> [CABK88, Gha90, DGS + 90, FM89, MD97, PB92] </ref>, little attention has been paid to partitioning key selection. All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys [CABK88, Gha90, PB92]. <p> Mehta and DeWitt studied the placement problem using latencies that reflect the current state of the art, i.e., communication latencies that are similar to ones for an ATM switch <ref> [MD97] </ref>. Simulations were performed using simple and complex queries with various selectivities and frequencies of execution. He concluded that relations should be partitioned across a set of nodes such that each partition had at least ReadSize pages. For medium and large relation sizes, full declustering is thus appropriate. <p> Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer). <p> However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer). We used an algorithm by Mehta and DeWitt as our data placement approach <ref> [MD97] </ref> because it uses full declustering. The pseudo code for the algorithm is given in Figure 4.11.
Reference: [MS78] <author> Salvatore T. March and Dennis G. Severance. </author> <title> A mathematical modeling approach to the automatic selection of database designs. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 52-65, </pages> <address> Austin, TX, </address> <month> May </month> <year> 1978. </year>
Reference-contexts: Techniques have been proposed in the literature that address all the physical DB design decisions in one algorithm. Unfortunately, all these methods, such as the ones given in Section 3.1.1, were developed for single node DB systems, and thus did not deal with partitioning decisions <ref> [MS78, CM83, RS91] </ref>. March and Severance [MS78] as well as Carlis and March [CM83] developed methods to select a physical DB design including indexes and record segmentation. Record segmentation is a partitioning of the records of a relation between primary and secondary memory. <p> Unfortunately, all these methods, such as the ones given in Section 3.1.1, were developed for single node DB systems, and thus did not deal with partitioning decisions [MS78, CM83, RS91]. March and Severance <ref> [MS78] </ref> as well as Carlis and March [CM83] developed methods to select a physical DB design including indexes and record segmentation. Record segmentation is a partitioning of the records of a relation between primary and secondary memory. Their workload consisted of simple single relation selections.
Reference: [NHS84] <author> Jurg Nievergelt, Hans Hinterberger, and Kenneth C. Sevcik. </author> <title> The grid file: An adaptable symmetric multikey file structure. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 9(1) </volume> <pages> 38-71, </pages> <month> March </month> <year> 1984. </year>
Reference-contexts: These partial matches effects apply to the different types of partitioning that use multi-attribute partitioning, for example: * a grid-file approach, where each attribute corresponds to a dimension in the grid <ref> [Gha90, NHS84] </ref>; and * a partitioning approach, where the values for the attributes in the multi-attribute key are combined in a function to return one logical partition number, such as hash partitioning.
Reference: [OLS92] <author> Edward Omiecinski, Liehuey Lee, and Peter Scheuermann. </author> <title> Concurrent file reorganization for record clustering: A performance study. </title> <booktitle> In Proc. of the Int. Conf. on Data Engineering, </booktitle> <pages> pages 265-272, </pages> <address> Tempe, Arizona, February 1992. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: A reorganization decision algorithm could use this measure to select the candidate reorganization strategy with the shortest break-even point. Omiecinski et al. developed a concurrent reclustering method that made use of differential files <ref> [OLS92] </ref>. These files temporarily hold updates on pages currently being reorganized so that users can execute concurrently with the reorganization. This work also demonstrated the effects of intrusion on the workload throughput during and after a reorganization.
Reference: [Omi88] <author> Edward Omiecinski. </author> <title> Concurrent storage structure conversion from B+tree to linear hash file. </title> <booktitle> In Proc. of the Int. Conf. on Data Engineering, </booktitle> <pages> pages 589-596, </pages> <address> Los Angeles, February 1988. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Omiecinski describes a concurrent method to convert an index structure from a B+tree to a linear hash file when dynamic access is more predominant than sequential access <ref> [Omi88] </ref>. The method allows the partially created linear hash file to be accessible during a reorganization so that performance benefits from the reorganization can be reaped as early as possible. An interesting aspect of this work is the performance studies.
Reference: [OPSS89] <author> Salvatore Orlando, V. Perri, S. Scrivano, and W. Staniszkis. </author> <title> Database analyzer and predictor an overview. </title> <booktitle> In Proc. of the Int. Conf. on Data Engineering, </booktitle> <pages> pages 625-634, </pages> <address> Los Angeles, February 1989. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: YES YES SQL op. trees [HM94] NO Weighted NO YES YES SQL op. trees [GGS96] NO Weighted NO YES YES SQL op. trees [TO78] NO Weighted YES NO NO Network DB plan [Pad92] NO Weighted YES YES YES SQL op. trees [Ser84] YES QNM YES NO NO Hierarchical DB plans <ref> [OPSS89] </ref> YES QNM YES NO NO Control flow graphs [Cas86] YES QNM YES NO NO Network DB plans [Hys91] YES QNM YES YES YES SQL op. trees Table 3.2: Summary of query and workload cost estimation work. a single query's expected response time as the time to traverse the critical path <p> Several applications have been created to apply Sevcik's framework to different DB systems. Orlando et al. developed a layering approach for their Database Analyzer and Predictor CASE tool to support design selection and tuning for single node DB systems <ref> [OPSS89] </ref>. However, they assume the given query plans are control flow graphs, where operations are connected to other operations by edges, and each edge has a weight corresponding to the probability that the edge is traversed.
Reference: [OV91] <author> M. Tamer Ozsu and Patrick Valduriez. </author> <title> Principles of Distributed Database Systems. </title> <publisher> Prentice Hall, </publisher> <year> 1991. </year> <month> 227 </month>
Reference-contexts: They demonstrated that, under different disk scheduling and query frequencies, full declustering resulted in reduced disk utilizations and greater I/O parallelism. There has also been work on horizontal and vertical partitioning over a distributed DB system <ref> [CNP82, OV91, Ape88] </ref>. Vertical partitioning involves the partitioning of the tuples themselves. These methods create fragments so that queries could execute locally at the nodes where the fragment includes all its required attributes. Fragments are placed to reduce the communication costs. <p> The structure of the algorithm was designed to be similar to algorithms presented previously in the literature <ref> [Ape88, CNP82, OV91, Jak80] </ref>. In these algorithms, the key of most importance in terms of query performance is chosen as the partitioning key for a relation. This method is also used in the DBA's rules of thumbs defined in Chapter 3.
Reference: [Pad92] <author> Sriram Padmanabhan. </author> <title> Data Placement in Shared-Nothing Parallel Database Sys--tems. </title> <type> PhD thesis, </type> <institution> EECS Dept., Univ. of Michigan-Ann Arbor, </institution> <year> 1992. </year>
Reference-contexts: This decision problem is similar to the bin-packing problem where we are trying to place the fragments into partitions and thus into nodes such that our objective function is minimized. The data placement problem has been shown to be NP-complete by Padmanabhan <ref> [Pad92] </ref>. 2.3.4 Choosing Ordering or Clustering Attributes The fourth physical DB design decision is the choice of which attributes (if any) are used to order or cluster the tuples in each partition of a relation, where the same attributes are used for all partitions of a relation. <p> The operators in which we are interested are: join (JOIN), sort (SORT), insert (IUD), update (IUD), delete (IUD), communication send (SEND), communication receive (RECV), selection (SEL), and aggregation (AGG). This set of operations is similar to the set ad dressed in Padmanabhan's thesis <ref> [Pad92] </ref>. 4. Only placement information for an existing relation group is eligible as placement information for operator executions. One case where an operation does not use a relation group's placement information in determining an execution location is at the coordinating node of a query plan. 5. <p> Padmanabhan proposes an assignment heuristic called the Disjoint Assignment by Priority (DAP) algorithm that allows some relations to be collocated <ref> [Pad92] </ref>. Before assigning a relation R to a set of nodes, the priority of each of the other relations is calculated as the frequency of the joins between R and the other relation. <p> They also assumed that communication latencies are high. In Padmanabhan's placement work, high latency interconnection networks and overhead costs were used that were also higher than the costs found in present systems <ref> [Pad92] </ref>. His cost function is a sum of the resource costs (communication, processor, and I/O costs), which inflates the costs by 10% to estimate congestion delays. There was no justification of why the value of 10% was used. <p> Parallel Query Delays Calculation Queries System Plans Estimation [CLYY92] NO Weighted NO YES YES SQL op. trees [HM94] NO Weighted NO YES YES SQL op. trees [GGS96] NO Weighted NO YES YES SQL op. trees [TO78] NO Weighted YES NO NO Network DB plan <ref> [Pad92] </ref> NO Weighted YES YES YES SQL op. trees [Ser84] YES QNM YES NO NO Hierarchical DB plans [OPSS89] YES QNM YES NO NO Control flow graphs [Cas86] YES QNM YES NO NO Network DB plans [Hys91] YES QNM YES YES YES SQL op. trees Table 3.2: Summary of query and <p> Padmanabhan estimates the workload response times and throughputs of SQL operation trees for a parallel SN relational DB system <ref> [Pad92] </ref>. This method also obtains the cost of a query by calculating the time for its tree's critical path. Each query's cost is multiplied by some DBA defined factor (e.g., 10%) to include a rudimentary estimate of locking and resource 61 contention.
Reference: [PB92] <author> Sriram Padmanabhan and Chaitanya Baru. </author> <title> Data placement in shared-nothing parallel database systems. </title> <booktitle> In Proc. of the Int. Conf. on Information and Knowledge Management (CIKM), </booktitle> <pages> pages 345-352, </pages> <address> Baltimore, </address> <year> 1992. </year>
Reference-contexts: Based on simulations, Ghandiharizadeh concluded 49 that the former methods outperform the latter [Gha90]. Although there have been many data placement methods proposed that depend on partitioning keys <ref> [CABK88, Gha90, DGS + 90, FM89, MD97, PB92] </ref>, little attention has been paid to partitioning key selection. All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys [CABK88, Gha90, PB92]. <p> All the past data placement work for parallel DB systems assumed that appropriate partitioning keys had already been chosen. Some papers mentioned the importance of selecting partitioning keys <ref> [CABK88, Gha90, PB92] </ref>. However, some techniques have been created to automate the partitioning key selection. These include: * a method for distributed DB systems; and * a tool in a commercial DB system. <p> Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer).
Reference: [PBS97] <author> Eric W. Parsons, Mats Brorsson, and Kenneth C. Sevcik. </author> <title> Predicting the performance of distributed virtual shared memory applications. </title> <type> Technical Report CSRI-353, </type> <institution> Dept. of Computer Science, University of Toronto, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: The parameter I IO was determined by executing a single page read from a file. Our communication parameters (I ST ART COMM and I COMM ) were obtained from the measurements made independently by Parsons et al. <ref> [PBS97] </ref>. A comparison timing (I COMP ARE ) was determined by comparing two floats together. This timing in Table 2.2 is more closely related to cache-only access.
Reference: [PR88] <author> R. Gary Parker and Ronald L. Rardin. </author> <title> Discrete Optimization. </title> <publisher> Academic Press, </publisher> <year> 1988. </year>
Reference-contexts: Standard branch-and-bound algorithms are guaranteed 66 to find optimal solutions based on the cost model and assumptions made for the algorithm <ref> [LW66, Fle87, PR88, RND77] </ref>. A solution is a set of decision variables along with the values that are assigned to them. Two types of solutions exist. A solution that satisfies all constraints and in which all decision variables have been assigned values is called a complete solution. <p> This effectively removes all the solutions that can be derived from S c since cost (S c ) is a lower bound on all the solutions derivable from S c . This branching and pruning technique is always a part of branch-and-bound algorithm descriptions <ref> [Fle87, PR88] </ref>. As a consequence, determining a good lower bound that is as high as possible allows the algorithm to narrow the search space more effectively by allowing quicker progress toward finding a solution that minimizes the objective function. <p> We use this lower bound to check against the best known solution's ART. If the bound is greater than the best known ART, then this partial solution (X) is pruned. This follows the standard branch-and-bound technique <ref> [Fle87, PR88] </ref>. The lower bound is also used to choose the next partial solution to consider in the search, as in the standard branch-and-bound technique. The minimum cost of a query accounts for the minimum I/O and processor times for a query and any choice of partitioning, clustering, and indexing.
Reference: [Raa95] <author> Francois Raab (editor). </author> <title> TPC benchmark D (decision support) working draft 9.0. </title> <type> Technical report, </type> <institution> Transaction Processing Council (TPC), </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: Cardinalities of the relations and attributes can either be measured or estimated. For example, cardinalities for the TPC-D DB are estimated using information from the TPC-D description <ref> [Raa95] </ref>. The physical DB design information can either be given by the user (for components that are not to be chosen by a given algorithm) or are generated by the algorithms. Workloads are obtained from user inputs and by estimations. <p> We study the effects of the different reorganization priorities in this thesis. 2.5 Experimental Motivation We present an example using part of the TPC-D workload and database <ref> [Raa95] </ref> to provide evidence for the importance of physical DB design selection. We show the number of candidate designs and the range of their resulting average response times. In this example, we concentrate only on choosing the partitioning keys and relation groups. <p> The database relation sizes are the ones used for a 4 GB TPC-D benchmark DB (based on a scale factor of four in the benchmark). The workload consists of four queries, shown in Figure 2.6, each based on one of the queries in the TPC-D benchmark <ref> [Raa95] </ref>. In our example, the relative frequencies of the queries in the workload are given in Table 2.3. The arrival rates were determined by preserving the relative frequencies of the classes while setting the overall rate such that the bottleneck utilization for a naive solution was 60%.
Reference: [RE78] <author> Daniel Ries and Robert Epstein. </author> <title> Evaluation of distributed criteria for distributed database systems. </title> <type> Technical Report UCB/ERL M78/22, </type> <institution> University of Berkeley, </institution> <month> May </month> <year> 1978. </year>
Reference-contexts: This choice is derived from the system environment, which is specified by the definition of the system, DB, and workload structures of a specific system. A physical DB design is specified by binding the following design decisions: * how to horizontally partition <ref> [RE78] </ref> each relation, which includes the decisions of which combination of attributes (partitioning key) in the relation determine a relation's partitioning, how many partitions to create for each relation, and which nodes to use to store each relation's partitions; 2 * what indexes to create on each relation; and * how <p> Resource costs varied, but usually involved I/O and processing times with an equal weighting between them. To expand on the problem, Ries and Epstein considered horizontally partitioning (declus-tering) relations so that a relation's tuples are distributed across a set of partitions <ref> [RE78] </ref>. The partitions are placed disjointly on a set of distributed DB system nodes. This decluster-ing spread the accesses to the relations across the nodes, thus spreading the I/O costs for the accesses across the nodes.
Reference: [RM93] <author> Erhard Rahm and Robert Marek. </author> <title> Analysis of dynamic load balancing strategies for parallel shared nothing database systems. </title> <booktitle> In Proc. of the 19th Int. Conf. on VLDB, </booktitle> <pages> pages 182-193, </pages> <address> Dublin, Ireland, </address> <year> 1993. </year>
Reference-contexts: However, they did not fully justify this claim in their paper. Rahm and Marek provided simulations for a two relation database to demonstrate that, 52 for simple single join queries with low selectivities, partial declustering allows for lower re-sponse times and higher throughputs than full declustering <ref> [RM93] </ref>. They also assumed that communication latencies are high. In Padmanabhan's placement work, high latency interconnection networks and overhead costs were used that were also higher than the costs found in present systems [Pad92].
Reference: [RND77] <author> Edward Reingold, Jurg Nievergelt, and Narsingh Deo. </author> <title> Combinatorial Algorithms: Theory and Practice. </title> <publisher> Prentice Hall, </publisher> <year> 1977. </year>
Reference-contexts: Standard branch-and-bound algorithms are guaranteed 66 to find optimal solutions based on the cost model and assumptions made for the algorithm <ref> [LW66, Fle87, PR88, RND77] </ref>. A solution is a set of decision variables along with the values that are assigned to them. Two types of solutions exist. A solution that satisfies all constraints and in which all decision variables have been assigned values is called a complete solution.
Reference: [RS88] <author> Pasquale Rullo and Domenico Sacca. </author> <title> An automatic physical designer for network model databases. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 14(9) </volume> <pages> 1293-1306, </pages> <month> Septem-ber </month> <year> 1988. </year>
Reference-contexts: Optimizer Workload Relation Objective Chosen Attributes Decisions Function Per Key Separated [ISR83] NO NO NO SIMPLE YES #pages [BPS90] NO NO NO SIMPLE YES #pages [FON92] NO NO YES SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows <ref> [RS88] </ref> YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE YES #pages [Wha87] YES NO NO SQL YES I/O [FST88] YES NO YES SQL NO Query times [CN97] YES YES YES SQL NO Query times Table 3.1: Summary of index selection work. of a clustering index. <p> Because the performance resulting from selecting only secondary indexes is constrained by the chosen clustering, algorithms have been developed to include the selection of primary indexes. Rullo and Sacca select primary and secondary indexes for network databases <ref> [RS88] </ref>. Their method considers all possible candidate keys along with their effects on the queries' costs, and eliminates indexes that result in greater query costs than the costs resulting from the other indexes. <p> The remaining candidate attribute set is further reduced by eliminating indexes resulting in higher query costs than for other indexes, as in Rullo's and Sacca's method <ref> [RS88] </ref>. Each feasible subset of indexes from the remaining candidate set (survivor list) is then considered and the corresponding workload cost is determined. The index set that leads to lowest query costs is chosen.
Reference: [RS91] <author> Steve Rozen and Dennis Shasha. </author> <title> A framework for automating physical database design. </title> <booktitle> In Proc. of the 17th Int. Conf. on VLDB, </booktitle> <pages> pages 401-411, </pages> <address> Barcelona, Spain, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: Techniques have been proposed in the literature that address all the physical DB design decisions in one algorithm. Unfortunately, all these methods, such as the ones given in Section 3.1.1, were developed for single node DB systems, and thus did not deal with partitioning decisions <ref> [MS78, CM83, RS91] </ref>. March and Severance [MS78] as well as Carlis and March [CM83] developed methods to select a physical DB design including indexes and record segmentation. Record segmentation is a partitioning of the records of a relation between primary and secondary memory. <p> They provided no guarantee that the resulting performance was optimal. A more robust method by Rozen and Shasha selects features of a physical DB design that includes indexing, ordering, clustering, and vertical partitioning <ref> [RS91] </ref>. A set of these features that together make a feasible physical DB design was called a realizable feature set.
Reference: [RVVN90] <author> Pedro I. Rivera-Vega, Ravi Varadarjan, and Shamkant B. Navathe. </author> <title> Scheduling data redistribution in distributed databases. </title> <booktitle> In Proc. of the Int. Conf. on Data Engineering, </booktitle> <pages> pages 166-173, </pages> <address> Los Angeles, February 1990. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Rivera-Vega et al. describe a method to answer the question of how to reorganize <ref> [RVVN90] </ref>. They determine a schedule for redistributing relations across a distributed system such that the reorganization execution time is minimized. Since the redistribution is off-line, the schedule with least intrusion is the one with lowest execution time. They formulated the problem as an integer linear programming problem.
Reference: [Sch94] <author> Herbert Schwetman. </author> <title> CSIM17 Users' Guide. Mesquite Software, </title> <publisher> Inc., </publisher> <year> 1994. </year> <month> 228 </month>
Reference: [SD95] <author> Rick Stellwagen and David DeWitt. </author> <title> Configurator for the SYBASE parallel DB system, </title> <month> January </month> <year> 1995. </year> <title> (Information obtained through correspondance with the Configurator implementers and maintainers: </title> <institution> Rick Stellwagen of NCR in San Diego and David DeWitt of the Univ. of Wisconsin at Madison). </institution>
Reference-contexts: Thus, a DB design decision is not separable. As for existing partitioning key selection tools, only the Configurator tool for the Sybase parallel DB system (Navigator) <ref> [SD95] </ref> is applicable. This tool estimates the workload costs with analytic and simulation modeling. The modeling uses database, system, and workload characteristics to determine data placements including partitioning keys. <p> An existing physical DB design decision tool called the Configurator was developed for the Sybase Navigator parallel DB system <ref> [SD95] </ref>. It includes support for the partitioning problem, where the number of partitions, the locations of the partitions, and the partitioning keys are given as output. This tool determines all the physical DB design decisions, including the choice of clustering and nonclustering indexes, with the help of user interaction.
Reference: [Ser84] <author> Alan Eldin Ismail Serry. </author> <title> An analytical approach to modeling IMS systems. </title> <type> Technical Report CSRI-161, PhD Thesis, </type> <institution> Dept. of Computer Science, University of Toronto, </institution> <month> July </month> <year> 1984. </year>
Reference-contexts: Calculation Queries System Plans Estimation [CLYY92] NO Weighted NO YES YES SQL op. trees [HM94] NO Weighted NO YES YES SQL op. trees [GGS96] NO Weighted NO YES YES SQL op. trees [TO78] NO Weighted YES NO NO Network DB plan [Pad92] NO Weighted YES YES YES SQL op. trees <ref> [Ser84] </ref> YES QNM YES NO NO Hierarchical DB plans [OPSS89] YES QNM YES NO NO Control flow graphs [Cas86] YES QNM YES NO NO Network DB plans [Hys91] YES QNM YES YES YES SQL op. trees Table 3.2: Summary of query and workload cost estimation work. a single query's expected response <p> However, this method is not easily used since it is difficult to construct control flow graphs with probabilities from parallel DB queries. Methods directly using query plans, possibly output from an optimizer, are more convenient. Two methods by Serry <ref> [Ser84] </ref> and Casas [Cas86] used the query plans for a hierarchical or network DB on a single node. Serry used Sevcik's framework to estimate the workload costs over a hierarchical DB [Ser84], while Casas created an analytic predictor called PROPHET to estimate the workload costs for network and hierarchical DB systems <p> Methods directly using query plans, possibly output from an optimizer, are more convenient. Two methods by Serry <ref> [Ser84] </ref> and Casas [Cas86] used the query plans for a hierarchical or network DB on a single node. Serry used Sevcik's framework to estimate the workload costs over a hierarchical DB [Ser84], while Casas created an analytic predictor called PROPHET to estimate the workload costs for network and hierarchical DB systems [Cas86].
Reference: [Sev81] <author> Kenneth C. Sevcik. </author> <title> Data base system performance prediction using an analytic model. </title> <booktitle> In Proc. of the 6th Int. Conf. on VLDB, </booktitle> <pages> pages 182-198, </pages> <year> 1981. </year>
Reference-contexts: Each query's cost is multiplied by some DBA defined factor (e.g., 10%) to include a rudimentary estimate of locking and resource 61 contention. Workload performance is then calculated as a weighted average of these inflated single query costs. To better estimate workload costs that include congestion delays, Sevcik <ref> [Sev81] </ref> constructed a layered framework. The highest layers involved the logical DB design, and the lowest layer modeled the execution of queries on the physical resources with a queuing network model (QNM), as defined by Lazowska et al. [LZGS84].
Reference: [SG79] <author> Gary H. Sockut and Robert P. Goldberg. </author> <title> Database reorganization principles and practice. </title> <journal> ACM Computing Surveys, </journal> <volume> 11(4) </volume> <pages> 371-395, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: For a detailed survey of related reorganization work, including reorganization of the logical DB design and the issues involved, see the survey by Sockut and Goldberg <ref> [SG79] </ref> as well as the survey by Sockut and Iyer [SI93]. 3.2.1 Reorganization Utilities The work on utilities assumes that the DBA or a reorganization decision algorithm determines: * when to activate the utility; * how much to reorganize; and * which utility or set of utilities are used to construct
Reference: [Shn73] <author> Ben Shneiderman. </author> <title> Optimum data base reorganization points. </title> <journal> Comm. of the ACM, </journal> <volume> 16(6) </volume> <pages> 362-365, </pages> <month> June </month> <year> 1973. </year>
Reference-contexts: Some of the work on reclustering on a single node concentrates on the question of when to reorganize <ref> [Shn73, YDT76] </ref>. Workload response time was assumed to be a linear function of the database size between any two reorganization executions. <p> Using the linear functions, the starting performance (W b), and the database's lifetime allows the area under the performance curve to be calculable. The reorganization points are determined as the points that minimize the area. Shneiderman determined the reorganization points assuming the times between reorganizations were of equal length <ref> [Shn73] </ref>. Yao et al. calculated these points heuristically based on the recent past reorganization points [YDT76]. These methods demonstrated that a reorganization decision should take into consideration the reorganization's cost.
Reference: [SI93] <author> Gary H. Sockut and Balakrishna R. Iyer. </author> <title> Reorganizing databases concurrently with usage: A survey. </title> <type> Technical Report TR 03.488, </type> <institution> IBM Santa Teresa Laboratory, </institution> <address> San Jose, CA, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: For a detailed survey of related reorganization work, including reorganization of the logical DB design and the issues involved, see the survey by Sockut and Goldberg [SG79] as well as the survey by Sockut and Iyer <ref> [SI93] </ref>. 3.2.1 Reorganization Utilities The work on utilities assumes that the DBA or a reorganization decision algorithm determines: * when to activate the utility; * how much to reorganize; and * which utility or set of utilities are used to construct a reorganization strategy.
Reference: [SL76] <author> Dennis G. Severance and Guy M. Lohman. </author> <title> Differential files: Their application to the maintenance of large databases. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 1(3) </volume> <pages> 256-267, </pages> <month> September </month> <year> 1976. </year>
Reference-contexts: For concurrent reorganizations, we assume differential files are used to hold updates to records that are being reorganized <ref> [SL76] </ref>. We assume the cost related to using a differential file is negligible. Queuing Network Model Assumptions With reasonably accurate input values, QNM's have been shown to provide reasonably accurate performance predictions. The errors due to QNM calculations are probably dominated by other errors in this application.
Reference: [SL91] <author> Bernhard Seeger and Per-Ake Larson. </author> <booktitle> Multi-disk B-trees fl . In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 436-445, </pages> <address> Denver, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: An example partitioning of a global B-tree index was given by Seeger and Larson <ref> [SL91] </ref>. There are disadvantages, however, when too many indexes are created. First, the extra storage space for the indexes may exceed the disk space available after the relations are stored.
Reference: [Smi90] <author> Gary S. Smith. </author> <title> Online reorganization of key-sequenced tables and files. </title> <type> Technical Report Tandem Systems Review, </type> <institution> Tandem Computers Inc., </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: In this section, we survey a few concurrent reorganization utilities. Some utilities for concurrent reorganization exist in commercial products to redistribute or rebalance a parallel data placement (e.g., the RELOAD command and other utilities in the Tandem NonStop-SQL product <ref> [CC93, Smi90, Tro96] </ref> and the REDISTRIBUTE command in the IBM DB2 PE product [BFG95]). Omiecinski describes a concurrent method to convert an index structure from a B+tree to a linear hash file when dynamic access is more predominant than sequential access [Omi88].
Reference: [Soc78] <author> Gary H. Sockut. </author> <title> A performance model for computer data-base reorganization performed concurrently with usage. </title> <journal> Operations Research, </journal> <volume> 26(5) </volume> <pages> 789-804, </pages> <month> September </month> <year> 1978. </year>
Reference-contexts: In contrast to the work that ignores reorganization costs, Sockut developed a method to model a reclustering that executes with lower priority than the workload queries on a single disk system <ref> [Soc78] </ref>. This method determines the reorganization cost and whether a reorganization is actually desirable. A disk is modeled as a server with a priority queue, and the user workload and reorganization strategy are assumed to request service from the server.
Reference: [Sri92] <author> Venkatachary Srinivasan. </author> <title> On-Line Processing in Large-Scale Transaction Systems. </title> <type> PhD thesis, </type> <institution> Dept. of Comp. Science, Univ. of Wisconsin-Madison, Madison, WI, </institution> <year> 1992. </year>
Reference-contexts: For example, Srinivasan specified index creation methods that each use different methods for how an index is created and how updates during index creation are handled concurrently with the workload <ref> [Sri92] </ref>. Each method results in different amounts of interference to the concurrently executing workload. Unfortunately, the DBA is given the responsibility in commercial DB products of determining the trade-off and the tool (s) to apply in a given situation. <p> However, the reorganization had longer execution times, and the throughput improvement with the reclustered relation was not realized as quickly. Srinivasan developed concurrent index creation methods, and introduced a performance metric called the loss metric to compare the different creation methods <ref> [Sri92] </ref>. This metric is equal to the reorganization's response time multiplied by the difference between the throughput without the reorganization and with the reorganization.
Reference: [TO78] <author> Toby J. Teorey and Lewis B. Oberlander. </author> <title> Network database evaluation using analytical modeling. </title> <booktitle> In National Computer Conference and Exposition: AFIPS Conf. Proc., </booktitle> <pages> pages 833-842, </pages> <address> Anaheim, CA, </address> <month> June </month> <year> 1978. </year> <month> 229 </month>
Reference-contexts: These estimators are similar because they calculate 60 Reference Congestion Cost Multiple Comm. Parallel Query Delays Calculation Queries System Plans Estimation [CLYY92] NO Weighted NO YES YES SQL op. trees [HM94] NO Weighted NO YES YES SQL op. trees [GGS96] NO Weighted NO YES YES SQL op. trees <ref> [TO78] </ref> NO Weighted YES NO NO Network DB plan [Pad92] NO Weighted YES YES YES SQL op. trees [Ser84] YES QNM YES NO NO Hierarchical DB plans [OPSS89] YES QNM YES NO NO Control flow graphs [Cas86] YES QNM YES NO NO Network DB plans [Hys91] YES QNM YES YES YES <p> Instead of predicting the costs of single queries, methods were developed to predict workload costs. Teorey and Oberlander created a DB design evaluator to estimate the performance of physical DB designs for network databases <ref> [TO78] </ref>. The estimator uses processor and disk times in a sequential system, and determines the execution costs, without congestion delays, as a weighted sum of the I/O and CPU service times for the different operations in a plan.
Reference: [Tro96] <author> Jim Troisi. </author> <title> NonStop SQL/MP availability and database configuration operations. </title> <journal> IEEE Bulletin of the Technical Committee on Data Engineering, </journal> <volume> 19(2) </volume> <pages> 12-18, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: In this section, we survey a few concurrent reorganization utilities. Some utilities for concurrent reorganization exist in commercial products to redistribute or rebalance a parallel data placement (e.g., the RELOAD command and other utilities in the Tandem NonStop-SQL product <ref> [CC93, Smi90, Tro96] </ref> and the REDISTRIBUTE command in the IBM DB2 PE product [BFG95]). Omiecinski describes a concurrent method to convert an index structure from a B+tree to a linear hash file when dynamic access is more predominant than sequential access [Omi88].
Reference: [UAC + 97] <author> Jeffrey D. Ullman, Serge Abiteboul, Chris Clifton, Rajeev Motwani, Svet-lozar Nestorov, and Dick Tsur. </author> <title> A system for managing query flocks, </title> <month> May </month> <year> 1997. </year> <note> (This information can be obtained at: http://www-db.stanford.edu/ ull-man/pub/flocks.html). </note>
Reference-contexts: Throughout the rest of the thesis, we use the term key to define an ordered group of attributes in the same relation. 2.1.3 Workload Structure The workload is composed of a set of transaction classes, which are the same as query flocks defined by Ullman <ref> [UAC + 97] </ref>. A transaction class represents a set of queries or updates that are closely related.
Reference: [VBW95] <author> Radek Vingralek, Yuri Breitbart, and Gerhard Weikum. SNOWBALL: </author> <title> Scalable storage an networks of workstations with balanced load. </title> <type> Technical Report Tech. Report 260-95, </type> <institution> Dept. of Comp. Science, University of Kentucky, </institution> <year> 1995. </year>
Reference-contexts: Vingralek et al.'s method considers reorganizations to redistribute fragments across a network of workstations. The redistribution is usually carried out at low priority. However, the method increases the priority of a reorganization when the workload causes a resource to be 100% utilized without reorganization <ref> [VBW95] </ref>. The priority level chosen for a reorganization may also be affected by: * the complexity of the queries; * a bottleneck resource that is less than 100% utilized; and * the amount of data to reorganize. 59 However, Vingralek et al. did not consider these aspects.
Reference: [Wah84] <author> Benjamin Wah. </author> <title> File placement in distributed computer systems. </title> <journal> IEEE Computer, </journal> <volume> 17(1) </volume> <pages> 23-33, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer).
Reference: [Wha87] <author> Kyu-Young Whang. </author> <title> Index selection in relational databases, 1987. From book: Foundations of Data Organization, edited by S. </title> <editor> P. Ghosh, Y. Kambayashi, and K. </editor> <publisher> Tanaka. </publisher>
Reference-contexts: NO SIMPLE YES #pages [BPS90] NO NO NO SIMPLE YES #pages [FON92] NO NO YES SQL YES CPU or I/O [CFM95] NO NO NO SIMPLE YES CPU and I/O [GHRU97] NO YES NO SQL YES #rows [RS88] YES NO NO SIMPLE YES #pages [CBC93] YES NO NO SIMPLE YES #pages <ref> [Wha87] </ref> YES NO NO SQL YES I/O [FST88] YES NO YES SQL NO Query times [CN97] YES YES YES SQL NO Query times Table 3.1: Summary of index selection work. of a clustering index. We thus focus on the index selection problem for the remainder of this section. <p> Because of the indirect association of primary and secondary indexes, the performance resulting from a sub-optimal set of indexes was not guaranteed to be optimal. Another heuristic, presented by Whang, used the DROP method to select the primary and secondary indexes <ref> [Wha87] </ref>. Initially, the method uses indexes on all the attributes as the 48 first candidate index set. At each iteration, DROP removes and records the index that would cause the greatest decrease in the response time when it is deleted from the candidate set.
Reference: [Wol89] <author> Joel L. Wolf. </author> <title> The placement optimization program: A practical solution to the disk file assignment problem. </title> <booktitle> In Proc. of the ACM Int. Conf. on Measurement and Modeling of Computer Systems, ACM SIGMETRICS, </booktitle> <pages> pages 1-10, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: This method is useful for constructing an algorithm to select the reorganization strategy for a specific reorganization. In deciding what to reorganize, heuristics have been suggested. Wolf solved the file reassignment problem of placing whole files at each disk in a multi-disk single-node system by using a greedy heuristic <ref> [Wol89] </ref>. The heuristic attempted to move N files to obtain lower I/O costs, and included the reorganization costs as a constraint on N . Besides considering the benefit and cost of a reorganization, the work also demonstrated that the old file allocation influenced the choice of the next allocation. <p> Thus, the data placement algorithm uses the output from the relation group algorithm. The goal of data placement is to find the number of partitions and the node assignments that lead to the lowest average response time. Any one of many existing placement algorithms <ref> [BAC + 90, PB92, GD90, HL90, Wah84, Wol89, CNW83, DF82, MD97] </ref> could be used. However, from experience, we have seen that full declustering of relations leads to the best performance for large relations whenever the number of nodes is moderate (e.g., 128 or fewer).
Reference: [WWS85] <author> Kyu-Young Whang, Gio Wiederhold, and Daniel Sagalowicz. </author> <title> The property of separability and its application to physical database design, 1985. From the book: Query Processing in Database Systems, edited by: </title> <editor> Wom Kim, David S. Reiner, and Don S. </editor> <publisher> Batory. </publisher>
Reference-contexts: Fifth, to simplify the selection, most of the methods assume that the indexing decisions can be made independently for the different relations. This assumption is based on the property of separability described by Whang et al. <ref> [WWS85] </ref>. This property allows the selection algorithm to ignore multiple relation query operations (i.e., joins) when, for each join, the choice of an access structure (index) for one of the join's relations is unaffected by the decisions made for the other relation in the join. <p> This algorithm is based on an existing index selection algorithm. IR and CR are described in Section 4.2. Note that, for PARING and CR, the problem is tackled by avoiding the use of the separability property <ref> [WWS85] </ref> as much as possible. 4.1 PARING Algorithm Our PARtitioning, INdexing, clustering, and relation Groups selection algorithm (PARING) is based on a branch-and-bound strategy. Standard branch-and-bound algorithms are guaranteed 66 to find optimal solutions based on the cost model and assumptions made for the algorithm [LW66, Fle87, PR88, RND77]. <p> Our goal is to investigate whether adding more updates affects the indexes chosen by PARING. * Since we allow the elimination of nonclustering indexes in the pre-scanning phase, and since this elimination violates the property of separability <ref> [WWS85] </ref>, we carried out experiments for Section 5.2.7 to compare the ART and number of optimizer calls from PARING when nonclustering indexes are eliminated or not in the pre-scan. * For Section 5.2.8, we perform experiments to show whether it is better to select the partitioning, indexing, and clustering keys in
Reference: [WZS91] <author> Gerhard Weikum, Peter Zabback, and Peter Scheuermann. </author> <title> Dynamic file allocation in disk arrays. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 406-415, </pages> <address> Denver, </address> <month> May </month> <year> 1991. </year>
Reference-contexts: Weikum et al. presented a dynamic file allocation method for disk arrays that is similar to a migration approach because, on a file creation or expansion, the partitions of a file are moved from the highest to the lowest utilized disks <ref> [WZS91] </ref>. In this and in other migration work, reorganization intrusions on the workload are ignored. Brunstrom et al. describe a method to dynamically redistribute partitions across a two node system [BLS95]. The redistribution is initiated because a node's utilization threshold is exceeded.
Reference: [YDT76] <author> S. Bing Yao, K. Sundar Das, and Toby J. Teorey. </author> <title> A dynamic database reorganization algorithm. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 1(2) </volume> <pages> 159-174, </pages> <month> June </month> <year> 1976. </year>
Reference-contexts: Some of the work on reclustering on a single node concentrates on the question of when to reorganize <ref> [Shn73, YDT76] </ref>. Workload response time was assumed to be a linear function of the database size between any two reorganization executions. <p> The reorganization points are determined as the points that minimize the area. Shneiderman determined the reorganization points assuming the times between reorganizations were of equal length [Shn73]. Yao et al. calculated these points heuristically based on the recent past reorganization points <ref> [YDT76] </ref>. These methods demonstrated that a reorganization decision should take into consideration the reorganization's cost.
Reference: [ZJP94] <author> Daniel C. Zilio, Anant Jhingran, and Sriram Padmanabhan. </author> <title> Partitioning key selection for a shared-nothing parallel database system. </title> <type> Technical Report RC 19820 (87739) 11/10/94, </type> <institution> IBM T. J. Watson Research Center, </institution> <year> 1994. </year> <month> 230 </month>
Reference-contexts: a negative weight results when the load imbalance of executing a query on a single partition, and thus on a single node, causes greater contention than executing 1 This work was done jointly with Anant Jhingran and Sriram Padmanabhan, and its initial description can be found in Zilio et al. <ref> [ZJP94] </ref>. 104 Independent Relations Algorithm ------------------------- Input: DB, system, and workload information. Output: Complete partitioning key solution and its cost B 1. Pre-scan attributes to get the possible candidate keys (single and multi-attributes) for partitioning. This phase is the same as the pre-scan phase used in the PARING algorithm. 2.
References-found: 89

