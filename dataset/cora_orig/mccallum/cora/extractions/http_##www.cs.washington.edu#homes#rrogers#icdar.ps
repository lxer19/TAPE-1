URL: http://www.cs.washington.edu/homes/rrogers/icdar.ps
Refering-URL: http://www.cs.washington.edu/homes/rrogers/experiment.html
Root-URL: 
Email: E-mail: fjliang, rrogers, yun, haralickg@george.ee.washington.edu  
Phone: Tel: (206) 685-7629  
Title: UW-ISL Document Image Analysis Toolbox An Experimental Environment  
Author: Jisheng Liang, Richard Rogers Robert M. Haralick, Ihsin T. Phillips 
Address: Box 352500  Seattle, WA 98195  
Affiliation: Intelligent Systems Laboratory Department of Electrical Engineering,  University of Washington  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T.A. Bayer. </author> <title> Understanding Structured Text Documents by a Model Based Document Analysis System. </title> <booktitle> Proc. 2nd ICDAR, </booktitle> <pages> pp 448-453, </pages> <address> Japan, </address> <year> 1993. </year>
Reference: [2] <author> S. Chen. </author> <title> Document Layout Analysis Using Recursive Morphological Transforms. </title> <type> Ph.D. thesis, </type> <institution> Univ. of Washington, </institution> <year> 1995. </year>
Reference-contexts: In this section, we describes the document analysis algorithms in the toolbox 9 and the corresponding performance measures. 4.1 Layout Analysis The document layout analysis is a specific instance of a more general problem group in image analysis, that of image segmentation, classification and representation <ref> [2] </ref>. The segmentation process discovers various objects of interest A in an input document image. An object is a homogeneous region in a document image that corresponds to one type: character, word, text line, text block, text or non-text zone. The classification problem identifies the detected objects' types fi. <p> The mis-classification rate for text and non-text distinction is lower than 3%. Text-line Segmentation The layout analysis toolbox includes three different methods to extract text-line entities: the extracted word entities are grouped into lines based on a Probability Linear Displacement Model <ref> [2] </ref>; the text zones are segmented into lines by cutting the projection profile of connected component bounding boxes [5]; the connected components are grouped into lines by merging and splitting the connected component bounding boxes [9]. The algorithms are tested on UW-III database with a total of 105,439 text-lines. <p> 0.60% 0.06% Word Segmentation Two different word segmentation methods are provided in our tool box: the extracted text-lines are segmented into words based on the vertical projection profile of connected component bounding boxes within the text-line [5]; the black pixels are merged into word using recursive 13 morphological closing transform <ref> [2] </ref>. These methods are tested on UW-III database with a total of 828,201 words. The percentage of correct, splitting, merging, miss, and spurious detections for two algorithms are shown in Table 3. Table 3: Performance of word segmentation with respect to the ground truth. <p> The current algorithms to extract text-blocks are: grouping text-lines and making text-blocks by analyzing the alignment of neighboring text-line bounding boxes; characterizing the text-block structure based on the augmented Probabilistic Linear Displacement Model <ref> [2] </ref>. These methods are tested on UW-III database with a total of 21,738 text blocks. Table 4 illustrates the percentage of correct, splitting, merging, miss, and spurious detections for two algorithms. Table 4: Performance of text block segmentation with respect to the ground truth.
Reference: [3] <author> S. Chen. </author> <title> OCR Performance Evaluation Software User's Manual. </title> <type> ISL Report, </type> <institution> E.E. Dept., U. of Washington. </institution>
Reference-contexts: The OCR Performance Evaluation (OPE) Software <ref> [3] </ref> is provided in UW-I document image database.
Reference: [4] <author> G.S.D. Farrow, C.S. Xydeas, and J.P. Oakley. </author> <title> Conversion of Scanned Documents to the Open Document Architecture. </title> <booktitle> 1994 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP-94, </booktitle> <pages> pp 109-112, </pages> <address> Australia, </address> <year> 1994. </year>
Reference: [5] <author> J. Ha, R.M. Haralick, and I.T. Phillips. </author> <title> Document Page Decomposition using Bounding Boxes of Connected Components of Black Pixels. Document Recognition II, </title> <booktitle> SPIE Proceedings, </booktitle> <volume> vol. 2422, </volume> <pages> pp 140-151, </pages> <address> San Jose, </address> <month> February </month> <year> 1995. </year>
Reference-contexts: Given a document image, zone segmentation is the process to segment image into a set of zone entities. A document image may be segmented using the recursive X-Y cut based on bounding boxes of connected components <ref> [5] </ref>. This method is tested on UW-III database with a total of 1600 pages. Table 1 illustrates the percentage of correct, splitting, merging, miss, and spurious detections with respect to the ground truth. Of the 24,243 ground truth zones, 87:18% of them are correctly detected. <p> Text-line Segmentation The layout analysis toolbox includes three different methods to extract text-line entities: the extracted word entities are grouped into lines based on a Probability Linear Displacement Model [2]; the text zones are segmented into lines by cutting the projection profile of connected component bounding boxes <ref> [5] </ref>; the connected components are grouped into lines by merging and splitting the connected component bounding boxes [9]. The algorithms are tested on UW-III database with a total of 105,439 text-lines. The percentage of correct, splitting, merging, miss, and spurious detections for three algorithms are shown in Table 2. <p> 2.03% 0.01% 0.07% Projection 94.78% 0.12% 4.78% 0.28% 0.04% Group c.c. 97.56% 0.53% 1.26% 0.60% 0.06% Word Segmentation Two different word segmentation methods are provided in our tool box: the extracted text-lines are segmented into words based on the vertical projection profile of connected component bounding boxes within the text-line <ref> [5] </ref>; the black pixels are merged into word using recursive 13 morphological closing transform [2]. These methods are tested on UW-III database with a total of 828,201 words. The percentage of correct, splitting, merging, miss, and spurious detections for two algorithms are shown in Table 3.
Reference: [6] <author> R.M. Haralick and L.G. Shapiro. </author> <title> Computer and Robot Vision. Volume I, </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: The mis-classification rate is defined as, P (mis classif ication) = X X P (t; a): The economic gain or cost function can be calculated by giving weights to different assign ments <ref> [6] </ref>. 4.1.2 Algorithms in the Layout Analysis Toolbox Zone Segmentation A zone entity is a rectangular area that consists of homogeneous data (only one physical content type). <p> The consistent-labeling problem and corresponding procedures constitute a general framework for matching the extracted layout structure with the knowledge of style information <ref> [6] </ref>. An address block selection algorithm which finds the location of address block on a mail piece document has been developed. 4.4 Text Recognition Each extracted text line or word is fed to an optical character recognizer. Currently, we use the Field recognizer in the FormLib produced by RAF Technologies.
Reference: [7] <author> R.M. Haralick. </author> <title> Document Image Understanding: Geometric and Logical Layout. </title> <booktitle> Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pp. 385-90, </pages> <month> 21-23 June </month> <year> 1994. </year>
Reference-contexts: Unfortunately, many of the published papers just give illustrative results and hardly any have their techniques tested on significant sized data sets and give quantitative performance measures <ref> [7] </ref>. Many of the current systems have a sequence of modules and corresponding knowledge for a specific type of document, and hardly any show how to choose appropriate algorithms for different kinds of documents with various format, content and condition. <p> It is clear that many of the early work on document analysis system provide illustrative results and hardly any have their techniques tested on significant sized data sets and give quantitative performance measures <ref> [7] </ref>. The main reasons are the lack of accurate document ground truth to train and test the algorithms and the lack of appropriate and quantitative performance metrics and evaluation protocol.
Reference: [8] <author> J. Kanai, T.A. Nartker, S V. Rice, and G. Nagy. </author> <title> Performance Metrics for Document Understanding Systems. </title> <booktitle> Proc. 2nd ICDAR, </booktitle> <pages> pp 424-427, </pages> <address> Japan, </address> <year> 1993. </year> <month> 21 </month>
Reference-contexts: A performance evaluation needs a performance metric, ground-truth data, and an algorithm to match the output representation of document understanding algorithms with the ground-truth representation (See Figure 2). Statistical and display tools are also needed to help users categorize errors and analyze the cause of errors <ref> [8] </ref>. UW-III [14] is the third in a series of UW document image databases. It contains a total of 1600 English document images randomly selected from scientific and technical journals. The documents are in DAFS format and consist of accurately ground-truthed layout and logical structure, style, and content.
Reference: [9] <author> J. Liang, J. Ha, R. Rogers, B. Chanda, I.T. Phillips, and R.M. Haralick. </author> <title> The Prototype of A Complete Document Understanding System. </title> <booktitle> Proc. IAPR Workshop on Document Analysis Systems, </booktitle> <pages> pp 130-154, </pages> <year> 1996. </year>
Reference-contexts: the extracted word entities are grouped into lines based on a Probability Linear Displacement Model [2]; the text zones are segmented into lines by cutting the projection profile of connected component bounding boxes [5]; the connected components are grouped into lines by merging and splitting the connected component bounding boxes <ref> [9] </ref>. The algorithms are tested on UW-III database with a total of 105,439 text-lines. The percentage of correct, splitting, merging, miss, and spurious detections for three algorithms are shown in Table 2. Table 2: Performance of text line segmentation with respect to the ground truth.
Reference: [10] <author> J. Liang, I.T. Phillips, J. Ha, </author> <title> R.M. Haralick. Document Zone Classification Using the Sizes of Connected Components. </title> <booktitle> Proceedings of the SPIE, </booktitle> <volume> Vol 2660, </volume> <booktitle> Document Recognition III, </booktitle> <pages> pp 150-157, </pages> <address> San Jose, </address> <year> 1996. </year>
Reference-contexts: 2.15% We have developed a method using feature vector generation and classification to classify each given scientific and technical document zone into one of the eight labels: text of font size 8-12, text of font size 13-18, text of font size 19-36, display math, table, halftone, line drawing, and ruling <ref> [10] </ref>. We have tested our method on UW-I document image data set with 979 pages and a total of 13,726 zones. The mis-classification rate of the algorithm for all zone types is below 5%. The mis-classification rate for text and non-text distinction is lower than 3%.
Reference: [11] <author> J. Liang, R.M. Haralick, and I.T. Phillips. </author> <title> Performance Evaluation of Algorithms in ISL Document Layout Analysis Toolbox. </title> <type> ISL Technical Report, </type> <institution> University of Washington, </institution> <year> 1996. </year>
Reference: [12] <author> G.K. Myers and Prasanna G. Mulgaonkar. </author> <title> Automatic Extraction of Information from Printed Documents. </title> <booktitle> Fourth Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pp 81-88, </pages> <address> Las Vegas, </address> <year> 1995. </year>
Reference: [13] <author> G. Nagy, S. Seth, and M. Viswanathan. </author> <title> A Prototype Document Image Analysis System for Technical Journals. </title> <booktitle> IEEE Computer, </booktitle> <pages> pp 10-22, </pages> <month> July </month> <year> 1992. </year>
Reference: [14] <author> I.T. Phillips. </author> <title> User's Reference Manual for the UW English/Technical Document Image Database III. UW-III English/Technical Document Image Database Manual, </title> <year> 1996. </year>
Reference-contexts: A performance evaluation needs a performance metric, ground-truth data, and an algorithm to match the output representation of document understanding algorithms with the ground-truth representation (See Figure 2). Statistical and display tools are also needed to help users categorize errors and analyze the cause of errors [8]. UW-III <ref> [14] </ref> is the third in a series of UW document image databases. It contains a total of 1600 English document images randomly selected from scientific and technical journals. The documents are in DAFS format and consist of accurately ground-truthed layout and logical structure, style, and content.
Reference: [15] <author> RAF Technology, Inc., DAFS: </author> <title> Document Attribute Format Specification. </title> <year> 1995. </year>
Reference-contexts: The experimental environment should be flexible enough to support the performance characterization of different modules and the different specific system architectures, such as top-down, bottom-up 6 or hybrid. 3.1 Document Attribute Format Specification (DAFS) The Document Attribute Format Specification (DAFS) <ref> [15] </ref> has been developed as a document interchange format to encode decomposed documents and to allow representation of both the physical and logical information contained within a document image. The DAFS provides a format for breaking down documents into standardized entities.
Reference: [16] <author> Microsoft, </author> <title> Rich Text Format (RTF) Specification. </title> <year> 1994. </year>
Reference-contexts: An OCR engine is called to recognize the content of text entities. The generated layout and logical structure, and the text content are stored in a DAFS file. The DAFS to RTF conversion converts the DAFS file to an RTF file. The Rich Text Format Specification <ref> [16] </ref> is a method of encoding formatted text and graphics for easy transfer between applications, including word processors. Given the logical structure and contents expressed in DAFS format, we perform the "reverse encoding", map them into an RTF file, while the non-text regions are output as bitmap.
Reference: [17] <author> P. W. Palumbo, S. N. Srihari, J.Soh, R. Sridhar, and V. demjanenko. </author> <title> Postal Address Block Location in Real Time . IEEE Computer, </title> <type> pp 34-42, </type> <month> July </month> <year> 1992. </year>
Reference: [18] <author> T. Kanungo, </author> <title> R.M. Haralick. Automatic Generation of Character Groundtruth for Scanned Documents: A Closed-Loop Approach. </title> <booktitle> Proceedings of ICPR'96, </booktitle> <pages> pp 669-675, </pages> <year> 1996. </year>
Reference-contexts: However, the dominant font information for each zone may not be accurate enough for the evaluation of the font attribute detection algorithms. In UW-III database, a software package for the automatic generation of character-level ground-truth for scanned documents is provided <ref> [18] </ref>.
Reference: [19] <author> S.L. Taylor, M. Lipshutz, D.A. Dahl, and C. Weir. </author> <title> An Intelligent Document Understanding system . Proc. </title> <booktitle> 2nd ICDAR, </booktitle> <pages> pp 107-110, </pages> <address> Japan, </address> <year> 1993. </year> <month> 22 </month>
References-found: 19

