URL: http://www.netlib.org/scalapack/design.ps
Refering-URL: http://www.netlib.org/scalapack/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Design of a library of parallel preconditioners  
Author: Tony Chan and Victor Eijkhout 
Date: February 18, 1998  
Abstract: We outline the design principles underlying the ParPre library of parallel preconditioners. ParPre is a message passing library of distributed preconditioners for linear systems, written using MPI and Petsc. It comprises Schwarz methods, Schur system domain decompositioning, various parallel incomplete factorisations, and multilevel methods.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> O. Axelsson. </author> <title> A generalized SSOR method. </title> <journal> BIT, </journal> <volume> 12 </volume> <pages> 443-467, </pages> <year> 1972. </year>
Reference-contexts: = R i AR t and the preconditioner is multiplicatively defined as M 1 = i i : 2.4.3 Multiplicative Schwarz and Generalised Block SSOR Solving subdomains in sequence, and using boundary conditions established by earlier subdomain solves in the sequence, leads to a block version of the Generalised SSOR <ref> [1] </ref> method for a disjoint splitting in subdomains, and the Multiplicative Schwarz method for an overlapping splitting.
Reference: [2] <author> O. Axelsson and P. Vassilevski. </author> <title> Algebraic multilevel preconditioning methods, I. </title> <journal> Numer. Math, </journal> <volume> 56 </volume> <pages> 157-177, </pages> <year> 1989. </year>
Reference-contexts: On the other hand, if the matrix is block tri-diagonal and the subdomain method is taken to be an exact LU factorisation, the block SSOR method becomes an exact factorisation. 3 Multilevel methods The class of multilevel methods in ParPre comprises several methods named `algebraic multigrid' by their respective authors <ref> [2, 10] </ref>. It also contains a few methods that are more properly described as incomplete factorisation methods [8]. <p> Details on this polynomial formalism can be found in <ref> [2, 3] </ref>. 4 Practical aspects The ParPre package uses the Petsc library, and MPI. Since data structures are identical to (or inspired by) Petsc structures, ParPre is pretty much seamlessly integrated with Petsc.
Reference: [3] <author> Owe Axelsson and Victor Eijkhout. </author> <title> The nested recursive two-level factorization method for nine-point difference matrices. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 12 </volume> <pages> 1373-1400, </pages> <year> 1991. </year>
Reference-contexts: Details on this polynomial formalism can be found in <ref> [2, 3] </ref>. 4 Practical aspects The ParPre package uses the Petsc library, and MPI. Since data structures are identical to (or inspired by) Petsc structures, ParPre is pretty much seamlessly integrated with Petsc.
Reference: [4] <author> I.S. Duff and G.A. Meurant. </author> <title> The effect of ordering on preconditioned conjugate gradients. </title> <journal> BIT, </journal> <volume> 29 </volume> <pages> 635-657, </pages> <year> 1989. </year>
Reference-contexts: In the context of the parallel solution of PDEs, this measure is insufficient. Many classical methods such as SOR or ILU preconditioning are not very parallel in the natural matrix ordering, and orderings with more parallelism usually lead to slower converging iterative methods <ref> [4, 5, 7] </ref>. One then has the choice between taking these classical, typically purely algebraic, methods and finding some mean between increasing parallel and decreasing scalar performance, or taking a step back and considering methods that exhibit natural parallelism.
Reference: [5] <author> Victor Eijkhout. </author> <title> Analysis of parallel incomplete point factorizations. </title> <journal> Lin. Alg. Appl., </journal> <volume> 154-156:723-740, </volume> <year> 1991. </year>
Reference-contexts: In the context of the parallel solution of PDEs, this measure is insufficient. Many classical methods such as SOR or ILU preconditioning are not very parallel in the natural matrix ordering, and orderings with more parallelism usually lead to slower converging iterative methods <ref> [4, 5, 7] </ref>. One then has the choice between taking these classical, typically purely algebraic, methods and finding some mean between increasing parallel and decreasing scalar performance, or taking a step back and considering methods that exhibit natural parallelism.
Reference: [6] <author> Victor Eijkhout and Tony Chan. ParPre: </author> <title> A parallel preconditioners package, reference manual for version 2.0.17. </title> <type> Technical Report CAM Report 97-24, </type> <institution> UCLA, </institution> <year> 1997. </year>
Reference-contexts: One then has the choice between taking these classical, typically purely algebraic, methods and finding some mean between increasing parallel and decreasing scalar performance, or taking a step back and considering methods that exhibit natural parallelism. In the ParPre package <ref> [6] </ref>, we have largely taken the latter approach. In ParPre, we are able to reproduce some of the classical, more sequential, preconditioners, but the emphasis of the package is on two classes of naturally parallel methods: 1. Domain decomposition methods, and 2. Multilevel methods. <p> a subdomain solver looks as follows: PC the_pc; /* the parallel preconditioner */ - PC local_pc; /* a pointer to the local solver */ PCParallelGetLocalPC (the_pc,&local_pc); 3 /* example: set the local solve to full LU solve */ PCSetType (local_pc,PCLU); - Detailed explanation of these calls can be found in <ref> [6] </ref>. The boundary for the subdomain solves is determined by the connection scheme of the subdomains. This will be discussed in section 2.4. 2.3 Subdomain sequences Of the methods to follow, the Schur complement and Additive Schwarz methods process their subdomains in parallel. <p> In order to use ParPre with an arbitrary code, we have to focus on two issues: preconditioner creation and application. We will only discuss these issues in global terms; details can be found in <ref> [6] </ref>. 4.1 Preconditioner creation The basis for forming a preconditioner is a coefficient matrix. Given that ParPre is based on Petsc, it will not be a surprise that the matrix has to be in Petsc storage format.
Reference: [7] <author> Louis A. Hageman and David M. Young. </author> <title> Applied Iterative Methods. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: In the context of the parallel solution of PDEs, this measure is insufficient. Many classical methods such as SOR or ILU preconditioning are not very parallel in the natural matrix ordering, and orderings with more parallelism usually lead to slower converging iterative methods <ref> [4, 5, 7] </ref>. One then has the choice between taking these classical, typically purely algebraic, methods and finding some mean between increasing parallel and decreasing scalar performance, or taking a step back and considering methods that exhibit natural parallelism.
Reference: [8] <author> M.T. Jones and P.E. Plassmann. </author> <title> Parallel solution of unstructed, sparse systems of linear equations. In R.F. Sincovec, D.E. Keyes, M.R. Leuze, L.R. Petzold, and D.A. </title> <editor> Reed, editors, </editor> <booktitle> Proceedings of the Sixth SIAM conference on Parallel Processing for Scientific Computing, </booktitle> <pages> pages 471-475, </pages> <address> Philadelphia. </address> <publisher> SIAM. </publisher> <pages> 11 </pages>
Reference-contexts: It also contains a few methods that are more properly described as incomplete factorisation methods <ref> [8] </ref>. We formally define levels by: the sets L i for i = 1; : : : ; ` are called levels in the domain if they form a disjoint partitioning of the domain. <p> The exact definition of strong and weak connections is a heuristic, the fine-tuning of which can greatly influence the performance of the resulting method. 3.2 Multilevel factorisation methods The above parallel colouring heuristic was intended to be used in an ILU (0) type factorisation <ref> [8] </ref>. The independent sets are found by the following iteration: * Let G (A) = hV; Ei be the matrix graph, and set V 1 V , E 1 E. * Iterate for i = 1; : : : while V i 6= ;: 1.
Reference: [9] <author> M.T. Jones and P.E. Plassmann. </author> <title> A parallel graph coloring heuristic. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 14, </volume> <year> 1993. </year>
Reference-contexts: In a parallel context, these schemes may potentially have low parallelism, or lead to large numbers of synchronisation points between the processors. Therefore we use a parallel colouring heuristic <ref> [9] </ref> (we will interchangeably use the terms `colour' and `independent set'): * Let each node x be assigned a random number ff (x). * Identify the set S of all nodes such that they have a higher random number than their neighbours: S = fx: (x; y) 2 E ! ff
Reference: [10] <author> J.W. Ruge and K. Stuben. </author> <title> Algebraic multigrid. </title> <editor> In Stephen F. McCormick, editor, </editor> <title> Multigrid Methods. </title> <publisher> SIAM, </publisher> <year> 1987. </year> <note> chapter 4. 12 </note>
Reference-contexts: On the other hand, if the matrix is block tri-diagonal and the subdomain method is taken to be an exact LU factorisation, the block SSOR method becomes an exact factorisation. 3 Multilevel methods The class of multilevel methods in ParPre comprises several methods named `algebraic multigrid' by their respective authors <ref> [2, 10] </ref>. It also contains a few methods that are more properly described as incomplete factorisation methods [8]. <p> To construct it in parallel, each node needs to acquire knowledge of its neighbours; this can be done in one parallel exchange operation. With processors owning subsets of variables, each processor needs to exchange data only with processors having physically surrounding subsets of variables. As in <ref> [10] </ref>, we base the level sets not on the full matrix graph, but rather on the graph obtained by ignoring the weak connections.
References-found: 10

