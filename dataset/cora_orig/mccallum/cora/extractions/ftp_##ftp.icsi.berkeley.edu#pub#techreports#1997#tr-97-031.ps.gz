URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1997/tr-97-031.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1997.html
Root-URL: http://www.icsi.berkeley.edu
Email: hiro@icsi.berkeley.edu  
Title: More robust J-RASTA processing using spectral subtraction and harmonic sieving  
Phone: (510) 643-9153 FAX (510) 643-7684  
Author: Hiroaki Ogawa 
Note: On visiting  
Date: August 1997  
Address: I 1947 Center St. Suite 600 Berkeley, California 94704-1198  
Affiliation: INTERNATIONAL COMPUTER SCIENCE INSTITUTE  EE Division, Department of EECS, University of California, Berkeley  
Pubnum: TR-97-031  
Abstract: We investigated spectral subtraction (SS) and harmonic sieving (HS) techniques as preprocessing for J-RASTA processing to achieve more robust feature extraction for automatic speech recognition. We confirmed that spectral subtraction improved J-RASTA processing, and showed that harmonic sieving additively improved J-RASTA+SS. We investigated the performance with the Bellcore isolated digits task corrupted with car noise (additive noise) and linear distortion filter (convolutional noise). The J-RASTA+SS+HS system reduces the word error rate by 39% given pitch estimated from clean speech, and 35% given pitch estimated from corrupted speech. The system was also tested with several kind of noises from the NOISEX92 database; each noise sample was added with speech for a resulting of 0dB signal to noise ratio. SS significantly reduced word error rate for all type of noises (white noise 39%, pink noise 51%, car noise 78%, tank noise 59%, and machine gun noise 19%). Given correct pitch, HS additively reduced the word error rate for the first three noises (white noise 7%, pink noise 16%, and car noise 17%). fl Sony Corporation D21 Laboratory, 6-7-35 Kita-Shinagawa, Shinagawa-ku, Tokyo, JAPAN
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. J. F. Gales and S. J. Young. </author> <title> HMM recognition in noise using parallel model combination. </title> <booktitle> In Proceedings of Eurospeech '93, </booktitle> <pages> pages 837-840, </pages> <month> Sept </month> <year> 1993. </year>
Reference-contexts: One of the major schemes is noise modeling. The modeled noise is generally used to compensate the input signal, or to adapt the recognizer itself to the noisy environment. One well known parametric noise modeling for ASR is the parallel model combination (PMC) technique <ref> [1, 2] </ref>. Given a sample of background noise for training the model, it works very well with an HMM system. A non-parametric noise compensation, spectral subtraction (SS), is widely used in many speech applications.
Reference: [2] <author> M.J.F. Gales and S. J. Young. </author> <title> Cepstral parameter compensation for HMM recognition in noise. </title> <journal> Speech Communication, </journal> <volume> 12(3) </volume> <pages> 231-239, </pages> <year> 1993. </year>
Reference-contexts: One of the major schemes is noise modeling. The modeled noise is generally used to compensate the input signal, or to adapt the recognizer itself to the noisy environment. One well known parametric noise modeling for ASR is the parallel model combination (PMC) technique <ref> [1, 2] </ref>. Given a sample of background noise for training the model, it works very well with an HMM system. A non-parametric noise compensation, spectral subtraction (SS), is widely used in many speech applications.
Reference: [3] <author> J.A. Nolazco-Flores and S.J. Young. </author> <title> Continuous speech recognition in noise using spectral subtraction and HMM adaptation. </title> <booktitle> In ICASSP-94. 1994 IEEE International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> pages I-409-I-412. </pages> <publisher> IEEE, </publisher> <year> 1994. </year>
Reference-contexts: Although it requires estimation of the background noise and ad hoc spectral operations such as flooring, it has two merits: fewer assumption about the noise than a parametric model, and potential use as a preprocessing step to other methods. In fact, SS improves PMC+HMM systems in highly noisy environments <ref> [3] </ref>. An enhancement of dynamic features of the speech signal is another approach for robust feature extraction. The enhancement consequentially suppresses quai-stational background noise. Cepstral mean subtraction (CMS) and RASTA processing [4] are well known as robust feature extraction techniques that enhance dynamic features of speech. <p> Thus, it is expected that spectral compensation in the linear domain or in the logarithmic domain before J-RASTA processing could improve the robustness, especially in very adverse environments. 2.2 Spectral Subtraction (SS) Spectral subtraction (SS) is widely used for additive noise suppression <ref> [10, 3, 11] </ref>. Because of its simplicity, SS is easy to use for noise suppression and it can work well as frontend processing with another feature extraction technique. <p> The parallel model combination technique, which has been shown to make HMM ASR systems more robust, is also improved by spectral subtraction in highly noisy environments <ref> [3] </ref>. Similarly, we use the SS as preprocessing for J-RASTA in order to improve the robustness. <p> Although higher ff is effective for 0dB additive noise (solid line), it makes results worse than conventional J-RASTA processing for additive and convolutional noise (dashed line). A typical value for fi is 0.1 in the <ref> [3, 11] </ref>, but the word error rate is slightly reduced (less than 7%) by tuning fi to 0.3.
Reference: [4] <author> Hynek Hermansky and Nelson Morgan. </author> <title> Rasta processing of speech. </title> <journal> IEEE Transactions on Speech and Audio Processing, special issue on Robust Speech Recognition, </journal> <volume> 2(4) </volume> <pages> 578-589, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: In fact, SS improves PMC+HMM systems in highly noisy environments [3]. An enhancement of dynamic features of the speech signal is another approach for robust feature extraction. The enhancement consequentially suppresses quai-stational background noise. Cepstral mean subtraction (CMS) and RASTA processing <ref> [4] </ref> are well known as robust feature extraction techniques that enhance dynamic features of speech. These techniques effectively remove the spectral distortion (i.e., convolutional noise), which typically are introduced by the transmission channel (microphones, telephone lines, etc..). J-RASTA 1 [5] processing addresses the convolutional noise and additive noise. <p> J-RASTA 1 [5] processing addresses the convolutional noise and additive noise. J-RASTA balances the effect of convolutional noise with that of additive noise, and reduces both of them based on the signal to noise ratio (SNR). J-RASTA is very robust in some adverse environments <ref> [4] </ref>. However, since it is a trade-off between two kind of effects, it can not compensate for both of them completely. In other words, it could improve the robustness of J-RASTA to compensate the spectrum before J-RASTA in linear or logarithmic domains.
Reference: [5] <author> Nelson Morgan and Hynek Hermansky. </author> <title> RASTA extensions: Robustness to additive and convolutional noise. </title> <booktitle> In Proceedings of Workshop on Speech Processing in Adverse Conditions, </booktitle> <pages> pages 115-118, </pages> <year> 1992. </year>
Reference-contexts: Cepstral mean subtraction (CMS) and RASTA processing [4] are well known as robust feature extraction techniques that enhance dynamic features of speech. These techniques effectively remove the spectral distortion (i.e., convolutional noise), which typically are introduced by the transmission channel (microphones, telephone lines, etc..). J-RASTA 1 <ref> [5] </ref> processing addresses the convolutional noise and additive noise. J-RASTA balances the effect of convolutional noise with that of additive noise, and reduces both of them based on the signal to noise ratio (SNR). J-RASTA is very robust in some adverse environments [4].
Reference: [6] <author> R. H. Frazier, S. Samsam, L. D. Bradia, and A. V. Oppenheim. </author> <title> Enhancement of speech by adaptive filtering. </title> <booktitle> In Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 251-253, </pages> <month> April </month> <year> 1976. </year>
Reference-contexts: In other words, it could improve the robustness of J-RASTA to compensate the spectrum before J-RASTA in linear or logarithmic domains. Separation of speech from noisy signals based on typical structures of speech such as harmonic structure have been investigated, especially in speech enhancement <ref> [6, 7, 8, 9] </ref>. It is another way to compensate the corrupted speech. The possibility of improving ASR systems has been suggested, but has not been evaluated with ASR very much. We apply a harmonic sieving technique (HS) and a spectral subtraction (SS) technique as preprocessing of J-RASTA feature extraction. <p> However, in most ASR systems, this is smoothed out in order to reduce the variability of the speech spectrum. On the other hand, the harmonic structure has been investigated and used in speech enhancement, speech separation, and computational auditory scene analysis <ref> [6, 7, 8, 9] </ref>. These techniques can be effective for robust speech recognition, but they are not often evaluated in ASR system with real noise. We assume that the speech signal in the voiced region exists only in the harmonic structure.
Reference: [7] <author> Thomas W. Parsons. </author> <title> Separation of speech from interfering speech by means of harmonic selection. </title> <journal> The Journal of the Acoustical Society of America, </journal> <volume> 60(4) </volume> <pages> 911-918, </pages> - <year> 1976. </year>
Reference-contexts: In other words, it could improve the robustness of J-RASTA to compensate the spectrum before J-RASTA in linear or logarithmic domains. Separation of speech from noisy signals based on typical structures of speech such as harmonic structure have been investigated, especially in speech enhancement <ref> [6, 7, 8, 9] </ref>. It is another way to compensate the corrupted speech. The possibility of improving ASR systems has been suggested, but has not been evaluated with ASR very much. We apply a harmonic sieving technique (HS) and a spectral subtraction (SS) technique as preprocessing of J-RASTA feature extraction. <p> However, in most ASR systems, this is smoothed out in order to reduce the variability of the speech spectrum. On the other hand, the harmonic structure has been investigated and used in speech enhancement, speech separation, and computational auditory scene analysis <ref> [6, 7, 8, 9] </ref>. These techniques can be effective for robust speech recognition, but they are not often evaluated in ASR system with real noise. We assume that the speech signal in the voiced region exists only in the harmonic structure.
Reference: [8] <author> J. A. Naylor and S. F. Boll. </author> <title> Techniques for suppression of an interfering talker in co-channel speech. </title> <booktitle> In ICASSP-87. The 1987 International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <pages> pages 205-208, </pages> <year> 1987. </year>
Reference-contexts: In other words, it could improve the robustness of J-RASTA to compensate the spectrum before J-RASTA in linear or logarithmic domains. Separation of speech from noisy signals based on typical structures of speech such as harmonic structure have been investigated, especially in speech enhancement <ref> [6, 7, 8, 9] </ref>. It is another way to compensate the corrupted speech. The possibility of improving ASR systems has been suggested, but has not been evaluated with ASR very much. We apply a harmonic sieving technique (HS) and a spectral subtraction (SS) technique as preprocessing of J-RASTA feature extraction. <p> However, in most ASR systems, this is smoothed out in order to reduce the variability of the speech spectrum. On the other hand, the harmonic structure has been investigated and used in speech enhancement, speech separation, and computational auditory scene analysis <ref> [6, 7, 8, 9] </ref>. These techniques can be effective for robust speech recognition, but they are not often evaluated in ASR system with real noise. We assume that the speech signal in the voiced region exists only in the harmonic structure.
Reference: [9] <author> T. Nakatani, M. Goto, and H. Okuno. </author> <title> Localization by harmonic structure and its application to harmonic sound stream segregation. </title> <booktitle> In 1996 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 653-656, </pages> <year> 1996. </year>
Reference-contexts: In other words, it could improve the robustness of J-RASTA to compensate the spectrum before J-RASTA in linear or logarithmic domains. Separation of speech from noisy signals based on typical structures of speech such as harmonic structure have been investigated, especially in speech enhancement <ref> [6, 7, 8, 9] </ref>. It is another way to compensate the corrupted speech. The possibility of improving ASR systems has been suggested, but has not been evaluated with ASR very much. We apply a harmonic sieving technique (HS) and a spectral subtraction (SS) technique as preprocessing of J-RASTA feature extraction. <p> However, in most ASR systems, this is smoothed out in order to reduce the variability of the speech spectrum. On the other hand, the harmonic structure has been investigated and used in speech enhancement, speech separation, and computational auditory scene analysis <ref> [6, 7, 8, 9] </ref>. These techniques can be effective for robust speech recognition, but they are not often evaluated in ASR system with real noise. We assume that the speech signal in the voiced region exists only in the harmonic structure.
Reference: [10] <author> Steven F. Boll. </author> <title> Suppression of acoustic noise in speech using spectral subtraction. </title> <journal> IEEE Transactions on acoustics, speech, and signal processing, </journal> <volume> ASSP-27(2):113-120, </volume> <month> April </month> <year> 1979. </year> <month> 20 </month>
Reference-contexts: Thus, it is expected that spectral compensation in the linear domain or in the logarithmic domain before J-RASTA processing could improve the robustness, especially in very adverse environments. 2.2 Spectral Subtraction (SS) Spectral subtraction (SS) is widely used for additive noise suppression <ref> [10, 3, 11] </ref>. Because of its simplicity, SS is easy to use for noise suppression and it can work well as frontend processing with another feature extraction technique.
Reference: [11] <author> P. Lockwood, J. Boudy, and M. Blanchet. </author> <title> Non-linear spectral subtraction (NSS) and hidden markov models for robust speech recognition in car noise environments. </title> <booktitle> In ICASSP-92. 1992 International Conference on Acoustics, Speech, and Signal Processing, pages I-265-I-268. IEEE, </booktitle> <month> Mar. </month> <year> 1992. </year>
Reference-contexts: Thus, it is expected that spectral compensation in the linear domain or in the logarithmic domain before J-RASTA processing could improve the robustness, especially in very adverse environments. 2.2 Spectral Subtraction (SS) Spectral subtraction (SS) is widely used for additive noise suppression <ref> [10, 3, 11] </ref>. Because of its simplicity, SS is easy to use for noise suppression and it can work well as frontend processing with another feature extraction technique. <p> Although higher ff is effective for 0dB additive noise (solid line), it makes results worse than conventional J-RASTA processing for additive and convolutional noise (dashed line). A typical value for fi is 0.1 in the <ref> [3, 11] </ref>, but the word error rate is slightly reduced (less than 7%) by tuning fi to 0.3.
Reference: [12] <author> Hynek Hermansky and Nelson Morgan. </author> <title> Recognition of speech in additive and convolutional noise based on RASTA spectral processing. </title> <booktitle> In ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> volume 2, II-83-86, </volume> <year> 1993. </year> <note> IEEE. </note>
Reference-contexts: It is essential to estimate the background noise ~ N (!) for the spectral subtraction technique. We estimated it based on the distribution of power spectral magnitude for each frequency band <ref> [12, 13] </ref>. It is assumed that the occurrence of very high amplitude spectra are relatively rare, and they come from the speech signal. The spectral amplitude that is most frequently observed is taken as a mean of noise power at that frequency. <p> The spectral amplitude that is most frequently observed is taken as a mean of noise power at that frequency. The estimated noise is also used to calculate the signal to noise ratio (SNR) to determine the J value of J-RASTA processing <ref> [12] </ref>. 2.3 Harmonic Sieving (HS) Harmonic structure is one of the most obvious features of the speech signal. However, in most ASR systems, this is smoothed out in order to reduce the variability of the speech spectrum.
Reference: [13] <author> Hans-Gunter Hirsch. </author> <title> Estimation of noise spectrum and its application to SNR-estimation and speech enhancement. </title> <type> Technical Report TR-93-012, </type> <institution> International Computer Science Institute, </institution> <year> 1993. </year>
Reference-contexts: It is essential to estimate the background noise ~ N (!) for the spectral subtraction technique. We estimated it based on the distribution of power spectral magnitude for each frequency band <ref> [12, 13] </ref>. It is assumed that the occurrence of very high amplitude spectra are relatively rare, and they come from the speech signal. The spectral amplitude that is most frequently observed is taken as a mean of noise power at that frequency.
Reference: [14] <author> Dik J. </author> <title> Hermes. Pitch analysis. </title> <editor> In Martin Cooke, Steve Beet, and Malcolm Craw-ford, editors, </editor> <title> Visual Representation of Speech Signals, </title> <journal> Wiley professional computing, </journal> <volume> chapter 1, </volume> <pages> pages 3-25. </pages> <address> Chichester; New York, </address> <year> 1993. </year>
Reference-contexts: We can perform this scheme by using pitch detection and voiced-unvoiced detection. Many such algorithms have been investigated in the last few decades; there is a good summary in <ref> [14] </ref>. We used the subharmonic summation algorithm (SHS) [15] for pitch and voiced/unvoiced detection. In the SHS algorithm, each frame is analyzed by means of the discrete Fourier transform (DFT). The spectra are weighted (higher weight for lower frequency), and resampled in the logarithmic frequency domain with interpolation.
Reference: [15] <author> Dik J. </author> <title> Hermes. Measurement of pitch by subharmonic summation. </title> <journal> The Journal of the Acoustical Society of America, </journal> <volume> 83(1) </volume> <pages> 257-264, </pages> <month> Jan. </month> <year> 1988. </year>
Reference-contexts: We can perform this scheme by using pitch detection and voiced-unvoiced detection. Many such algorithms have been investigated in the last few decades; there is a good summary in [14]. We used the subharmonic summation algorithm (SHS) <ref> [15] </ref> for pitch and voiced/unvoiced detection. In the SHS algorithm, each frame is analyzed by means of the discrete Fourier transform (DFT). The spectra are weighted (higher weight for lower frequency), and resampled in the logarithmic frequency domain with interpolation. <p> In the experiment, the parameters of SS (ff; fi) and HS (l max ; f max ) were set to optimal values from previous sections; (1:0; 0:1); (8; 1000) 2 Although the pitch derived from clean speech also includes errors of around 1% <ref> [15] </ref>, we assume here that it is correct. 13 Average Pitch (Low-High) [Hz] l max 60-80 80-100 100-120 120-140 140-160 160-180 180-200 200-220 7 25.8 25.6 23.3 *23.6 *25.4 36.8 *28.8 32.5 9 *22.1 *23.8 23.3 24.6 27.8 38.4 30.7 32.5 13 *22.1 25.6 26.9 29.2 29.6 40.6 31.8 35.1 inf
Reference: [16] <author> H. Ney. </author> <title> Dynamic programming algorithm for optimal estimation of speech parameter contours. </title> <journal> IEEE Trans. SMC, </journal> <volume> 13 </volume> <pages> 208-214, </pages> <year> 1983. </year>
Reference-contexts: Instead of taking a maximum value in equation (2.5), we can estimate the pitch frequency from the lattice of the summation by using dynamic time warping <ref> [16] </ref>. We used the "post editing" algorithm to refine the accuracy of pitch frequency.
Reference: [17] <author> A. Varga, H.J.M. Steeneken, M. Tomlinson, and D. Jones. </author> <title> The NOISEX-92 study on the effect of additive noise on speech recognition. </title> <type> Technical report, </type> <institution> DRA Speech Research Unit, Malvern, </institution> <address> England, </address> <year> 1992. </year> <month> NoiseX92. </month>
Reference-contexts: We also compared the performances of J-RASTA, J-RASTA+SS, and J-RASTA+SS+HS in several noise environments using the NOISEX-92 database <ref> [17] </ref>. We used white noise, pink noise, car noise (Volvo), machine gun noise, and Leopard 2 military vehicle noise. Each noise was added to the speech signal with a 0dB SNR. The SNR was calculated based on the energy only over the speech segment.
Reference: [18] <author> Luc M. Van Immerseel and Jean-Pierre Martens. </author> <title> Pitch and voiced/unvoiced determination with an auditory model. </title> <journal> The Journal of the Acoustical Society of America, </journal> <volume> 91(6) </volume> <pages> 3511-3526, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: More robust pitch estimation or harmonic structure estimation algorithms are needed to derive the full performance. There are many pitch estimation algorithms, and some may be more robust than SHS. AMPEX (auditory model-based pitch extractor) <ref> [18] </ref> is another candidate we are considering. We obtained the AMPEX program, but we didn't use it due to time limitations. For harmonic structure estimation, a spectrogram which shows sharp harmonic structure is investigated in [19]. It could be useful for our approach.
Reference: [19] <author> Satoshi Imai Toshihiko Abe, Takao Kobayashi. </author> <title> The if spectrogram: A new spectral representation. </title> <booktitle> In ASVA 97: International symposium on simulation, visualization and auralization for acoustic research and education, </booktitle> <pages> pages 423-429, </pages> <month> April </month> <year> 1997. </year> <month> 21 </month>
Reference-contexts: AMPEX (auditory model-based pitch extractor) [18] is another candidate we are considering. We obtained the AMPEX program, but we didn't use it due to time limitations. For harmonic structure estimation, a spectrogram which shows sharp harmonic structure is investigated in <ref> [19] </ref>. It could be useful for our approach. Even though the correct pitch is given, the reduction of error by the HS scheme is not extremely large. Two reasons have been considered. First, the signal compensation of HS only covers voiced speech.
References-found: 19

