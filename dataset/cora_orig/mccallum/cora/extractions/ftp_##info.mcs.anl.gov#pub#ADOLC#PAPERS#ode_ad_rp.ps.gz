URL: ftp://info.mcs.anl.gov/pub/ADOLC/PAPERS/ode_ad_rp.ps.gz
Refering-URL: http://www.mcs.anl.gov/Projects/autodiff/AD_Tools/adolc.anl/adolc.html
Root-URL: http://www.mcs.anl.gov
Title: ODE Solving via Automatic Differentiation and Rational Prediction  
Author: Andreas Griewank 
Date: December 20, 1995  
Abstract: We consider the classical Taylor series approximation to the solution of initial value problems in ordinary differential equations and examine implicit variants for the numerical solution of stiff ODEs. The Taylor coefficients of the state vector are found to be closely related to those of the Jacobian of the right hand side along the solution trajectory. These connections between state and Jacobian coefficients are exploited for their efficient evaluation by automatic differentiation with a small number of forward and reverse sweeps. It is shown how these coefficients can be utilized in a new rational predictor for the Hermite-Obreshkov-Pade (HOP) methods, a family of high order numerical integrators, last examined by Wanner in the sixties. The linearly implicit predictor and the full HOP methods yield in the constant coefficient case Pade approximants of the matrix exponential. A- and L-stability is achieved for the diagonal and first two subdiagonal choices of the Pade parameter pair (q; p). Preliminary numerical results demonstrate that on stiff and highly oscillatory problems large steps can be realized with a single correction iteration and acceptable discretization error. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brett Averick, Jorge More, Christian Bischof, Alan Carle, and Andreas Griewank. </author> <title> Computing large sparse Jacobian matrices using automatic differentiation. </title> <note> to appear in SIAM Journal on Scientific Computing, </note> <year> 1993. </year>
Reference-contexts: ADOL-C yields the sparsity pattern for the partial Jacobians A j , which is then used by the routine that accumulates them to the total Jacobians B j . However, the sparsity structure is not yet exploited in the differentiation process itself, which could yield substantial savings <ref> [1] </ref>. It is hoped that the cost penalty n in going from the y j to the J j can be drastically reduced by a combination of the forward and reverse mode [7] that also takes account of the special role played by the time. <p> Now it can be verified, through repeated integration by parts, that for any smooth function g (s) on <ref> [0; 1] </ref> 0 q X (1) j c j g j (1) j=0 p;q where g j (s) = g (j) (s)=j! denotes the j-th Taylor coefficient as before.
Reference: [2] <author> Y. F. Chang and G. Corliss, </author> <title> Solving ordinary differential equations using Taylor series, </title> <journal> ACM Trans. Math. Software, </journal> <volume> 8(1982), </volume> <pages> 114-144. </pages>
Reference-contexts: Therefore using only half as many should roughly quarter the computational effort per step. 3 The HOP methods with rational Predictor While the classical Taylor series method implemented with AD <ref> [2] </ref> can be quite efficient on nonstiff problems, we have to find an implicit variant for the more interesting stiff case.
Reference: [3] <author> Andreas Griewank and George Corliss, </author> <title> editors. Automatic Differentiation of Algorithms: Theory, Implementation, and Applications. </title> <publisher> SIAM, </publisher> <address> Philadelphia, Penn., </address> <year> 1991. </year>
Reference-contexts: One of his students Bert Speelpenning [17] became a pioneer in automatic differentiation as he developed JAKE, probably the first, and definitely the most sophisticated implementation of the so-called reverse, or adjoint mode at the time. For more recent surveys on automatic differentiation see for example the proceedings <ref> [3] </ref> and the Siam News article [6]. There have been many implementations of the forward, or direct mode of automatic differentiation, some specifically for the purpose of integrating stiff systems.
Reference: [4] <author> G. F. Corliss, A. Griewank, P. Henneberger, G. Kirlinger, F. A. Potra, H. J. Stetter, </author> <title> High-Order Stiff ODE Solvers via Automatic Differentiation and Rational Prediction, </title> <type> Manuscript, </type> <note> submitted for publication, </note> <year> 1995. </year>
Reference-contexts: After convergence of the corrector, we will use the same higher order matrix information for the predictor on the next step. Wanner [22] showed how the derivative vectors and their Jacobians can be computed recursively in the forward mode. In our pilot implementation <ref> [4] </ref> we are using the forward mode for calculating the derivative vectors and the reverse mode for calculating the derivative matrices. This involves d forward sweeps and one reverse sweep through the sequence of elementary operations and functions defining the right hand side. <p> In Section 3 we describe the HOP methods with a rational predictor and provide estimates for the discretization error before and after a step is taken. In Section 4 we report some preliminary numerical results and draw some tentative conclusions. Proofs and more detailed derivations can be found in <ref> [4] </ref>. 2 IVPs and their Taylor Series Throughout this paper we consider an initial value problem y 0 (t) = f (y (t); t) ; y (0) = y 0 2 IR n (1) 4 Andreas Griewank with a righthand side f : D fi IR ae IR m 7! IR <p> The partial derivatives of the F t;j with respect to the y i for 0 i j are exactly the matrix coefficients discussed before, as shown in the following result from <ref> [4] </ref>. <p> The key advantage is that the predictor is rational in the function and derivative data, due to the inversion of the approximate Jacobian ~ R q;p R q;p . It has been shown in <ref> [4] </ref>, that in the linear case with constant coefficients the predictor is exact in that ~y + = y + so that no correction is necessary at all. <p> These notions were confirmed in a sizable number of numerical test runs, some which are reported in <ref> [4] </ref>. While the number of time-steps and corrections is generally quite low, the effort per step is of course significantly larger than for derivative-free methods, and in most cases the run-times of our code are not yet competitive. <p> Acknowledgements Much of the material in this paper is based on joint research with George Corliss, Petra Henneberger, Gabriela Kirlinger, Florian Potra, and H. J. 20 Andreas Griewank Stetter. The results of this collaboration will be published in the manuscript <ref> [4] </ref>, which benefited greatly from comments by Ian Gladwell. The numerical results were obtained by Petra Hennerberger with a code that has been developed over the years with the help of George Corliss and several students.
Reference: [5] <author> B. L. Ehle, </author> <title> A-stable methods and Pade approximations to the exponential, </title> <journal> SIAM J. Math. Anal. </journal> <volume> 4(1973), </volume> <pages> 671-680. </pages> <note> Manuscript, submitted for publication, </note> <year> 1995. </year>
Reference-contexts: It is well known <ref> [5] </ref> that integrators with this transfer function in the linear case are A-stable if and only if p q p + 2 and L-stable if p &lt; q p + 2.
Reference: [6] <author> Andreas Griewank. </author> <title> The chain rule revisited in scientific computing, </title> <journal> I-II. SIAM News, </journal> <month> May/July </month> <year> 1991. </year>
Reference-contexts: For more recent surveys on automatic differentiation see for example the proceedings [3] and the Siam News article <ref> [6] </ref>. There have been many implementations of the forward, or direct mode of automatic differentiation, some specifically for the purpose of integrating stiff systems.
Reference: [7] <author> Andreas Griewank and Shawn Reese, </author> <title> On the calculation of Jacobian matrices by the Markowitz rule. </title> <editor> In Andreas Griewank and George F. Corliss, editors, </editor> <title> Automatic Differentiation of Algorithms: Theory, </title> <booktitle> Implementation, and Application, </booktitle> <pages> pages 126-135. </pages> <publisher> SIAM, </publisher> <address> Philadelphia, Penn., </address> <year> 1991. </year>
Reference-contexts: It is hoped that the cost penalty n in going from the y j to the J j can be drastically reduced by a combination of the forward and reverse mode <ref> [7] </ref> that also takes account of the special role played by the time. Naturally, better methods for computing Jacobians will benefit many methods for the numerical analysis of nonlinear problems.
Reference: [8] <author> Andreas Griewank, David Juedes, and Jean Utke, ADOL-C, </author> <title> a package for the automatic differentiation of algorithms written in C/C++, </title> <journal> ACM Transactions on Mathematical Software, </journal> <note> to appear, 1995. First version submitted in 1991. </note>
Reference-contexts: Until then the HOP methods will only in special circumstances be run-time competitive with derivative-free state of the art integrators. In our package ADOL-C <ref> [8] </ref> the evaluation of the J j for j &lt; d by the reverse mode of automatic differentiation costs roughly n times as many units as the evaluation of the underlying y j for j d with storage of intermediates.
Reference: [9] <author> Andreas Griewank. </author> <title> Automatic Directional Differentiation of Nons-mooth Composite Functions , to appear in Proceedings of Seventh French-German Conference on Optimization, </title> <booktitle> Lecture Notes in Economics and Mathematical Systems, </booktitle> <publisher> Springer Verlag. </publisher>
Reference-contexts: Whereas all these building blocks are smooth in the interiors of their domains, the situation changes drastically if one admits the absolute value, Euclidean norms, and possibly even the Heavyside function to the pool of elementary functions. As shown in <ref> [9] </ref>, one can then still uniquely define and recursively compute arbitrarily many one-sided Taylor coefficients, which is of great potential use for the HOP methods and other one-step integrators.
Reference: [10] <author> E. Hairer, G. Wanner, </author> <title> Solving Ordinary Differential Equations II, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year> <title> ODE Solving via Automatic Differentiation and Rational Prediction 21 </title>
Reference-contexts: Extending the the terminology of <ref> [10] </ref> we refer to the numerical integrators defined by (17) as Hermite-Obreshkov-Pade methods.
Reference: [11] <author> E.Hairer, A.Murua, J.M.Sanz-Serna. </author> <title> The non-existence of symplectic multi-derivative Runge-Kutta methods, </title> <booktitle> BIT 34 (1994), </booktitle> <pages> 80-87. </pages>
Reference-contexts: It is not yet clear whether the well-known A- and L-stability results can be extended to nonlinear test functions. Even though it is known that the higher order HOP methods are not symplectic <ref> [11] </ref>, it is expected that the time-reversible (q; q) schemes perform reasonably well on Hamiltonian systems. Acknowledgements Much of the material in this paper is based on joint research with George Corliss, Petra Henneberger, Gabriela Kirlinger, Florian Potra, and H. J. 20 Andreas Griewank Stetter.
Reference: [12] <author> R. Lohner, </author> <title> Einschlieung der Losung gewohnlicher Anfangs-und Randwertaufgaben und Anwendungen, Dissertation, </title> <note> Karlsruhe 1988. </note>
Reference-contexts: While this is true in general, there has always been a group of theoreticians and practitioners who have developed and used Taylor series methods with the aim of achieving high accuracy and/or enclosing the exact solution in intervals <ref> [12, 18] </ref>.
Reference: [13] <author> Fredrick Munger. </author> <title> Applications of Definor Algebra to Ordinary Differential Equations, </title> <publisher> After Math Press, </publisher> <address> Instructor's Edition, </address> <year> 1990. </year>
Reference-contexts: Taylor series methods were apparently used to compute the reentry path of NASA space vehicles <ref> [13] </ref>, but they were mostly ignored by the main stream of researchers and implementers as the interest focused onto stiff problems, for which explicit methods are unsuitable.
Reference: [14] <author> N. Obreshkov, </author> <title> Neue Quadraturformeln, </title> <type> Abh. Preuss. Akad. </type> <institution> Wiss. Math. Nat. Kl., 4,(1940). </institution>
Reference-contexts: We will consider Hermite interpolants, i.e. polynomials that interpolate y 0 (t) and a certain number of its derivatives at the two endpoints t 0 and t + . The resulting quadrature formulas discovered by Obreshkov <ref> [14, 15] </ref> contain also the values of y (t) itself at the endpoints. Therefore, it is sufficient to annotate quantities by the subscripts 0 and + to indicate whether they belong to the left or right end of the interval.
Reference: [15] <author> N. Obreshkov, </author> <title> Sur le quadrature mecaniques (Bulgarian, French summary), </title> <journal> Spisanie Bulgar. Akad. Nauk, </journal> <volume> 65, </volume> <pages> 191-289(1942). </pages>
Reference-contexts: We will consider Hermite interpolants, i.e. polynomials that interpolate y 0 (t) and a certain number of its derivatives at the two endpoints t 0 and t + . The resulting quadrature formulas discovered by Obreshkov <ref> [14, 15] </ref> contain also the values of y (t) itself at the endpoints. Therefore, it is sufficient to annotate quantities by the subscripts 0 and + to indicate whether they belong to the left or right end of the interval.
Reference: [16] <author> H. Pade, </author> <title> Sur la representation approchee d'une fonction par des fractions rationelles, </title> <type> Thesis, Ann. de l' Ec. Nor. (3), 9(1892). </type>
Reference: [17] <author> B. Speelpenning. </author> <title> Compiling Fast Partial Derivatives of Functions Given by Algorithms, </title> <type> Ph.D. dissertation, </type> <institution> Department of Computer Science, University of Illinois at Urbana,(1980). </institution>
Reference-contexts: Bill Gear initially wrote a 'symbolic' differentiator to obtain the Jacobian of righthand sides for use in his Backward-Differentiation Codes for stiff problems. One of his students Bert Speelpenning <ref> [17] </ref> became a pioneer in automatic differentiation as he developed JAKE, probably the first, and definitely the most sophisticated implementation of the so-called reverse, or adjoint mode at the time. For more recent surveys on automatic differentiation see for example the proceedings [3] and the Siam News article [6].
Reference: [18] <author> H. J. Stetter, </author> <title> Validated solution of initial value problems for ODE, in Computer Arithmetic and Self Validating Numerical Methods, </title> <booktitle> Proceedings SCAN Basel 1989 , 171-187 (1990). </booktitle>
Reference-contexts: While this is true in general, there has always been a group of theoreticians and practitioners who have developed and used Taylor series methods with the aim of achieving high accuracy and/or enclosing the exact solution in intervals <ref> [12, 18] </ref>.
Reference: [19] <author> Karl Strehmel und Rudiger Weiner. </author> <title> Linear-implizite Runge-Kutta-Mathoden und ihre Anwendung, Teubner-Texte zur Mathematik, </title> <address> Stuttgart Leipzig, </address> <year> 1992. </year>
Reference-contexts: While this is true for the classical Taylor series method, the Hermite-Obreshkov-Pade (HOP) methods examined in the second part of this paper are fully implicit. Also, the predictor advocated here represents by itself a linearly implicit A-stable integrator, similar to the Rosenbrock methods considered in <ref> [19] </ref>. Two internationally renowned researchers, namely Wanner and Gear, considered automatic differentiation as a tool for the numerical solution of stiff systems more than twenty years ago. <p> Then, only lower order BDF, Rosenbrock <ref> [19] </ref>, or higher order Implicit Runge Kutta (IRK) and HOP methods are applicable. The numerical experiments reported in Section 4 were conducted on a forced harmonic oscillator, for which the eigenvalues of the Jacobian can be easily selected in the complex plane.
Reference: [20] <author> G. Wanner. </author> <title> On the integration of stiff differential equations. </title> <type> Technical Report, </type> <month> October </month> <year> 1976, </year> <institution> Universite de Geneve Section de Mathematique, </institution> <address> 1211 GENEVE 24th, Suisse. </address>
Reference-contexts: Derivation of the HOP methods Rather than pursuing the Hermite interpolation directly, one can derive the HOP methods much faster in the following way due to Wanner <ref> [20] </ref>.
Reference: [21] <author> G. Wanner. STIFFI, </author> <title> A Program for Ordinary Differential Equations. </title> <type> Technical Report, </type> <month> October </month> <year> 1976, </year> <institution> Universite de Geneve Section de Math-ematique, </institution> <address> 1211 GENEVE 24th, Suisse. </address>
Reference-contexts: Gerhard Wanner developed the theory of the class of integrators, which we call HOP (for Hermite-Obreshkov-Pade) methods here, and wrote a Fortran implementation STIFFI <ref> [21] </ref> based on a low order scheme from the family. Due to software limitations his method required a complete recoding of the righthand side by the user.
Reference: [22] <author> G. Wanner. </author> <title> Integration gewohnlicher Differentialgleichungen, </title> <publisher> Hochschultaschenbucher-Verlag, Bibliographisches Institut, </publisher> <address> Mannheim/Zurich, </address> <year> 1969. </year>
Reference-contexts: These higher order Jacobians are needed if one wants to apply Newton corrections to the algebraic system defining the HOP methods and other implicit integrators. After convergence of the corrector, we will use the same higher order matrix information for the predictor on the next step. Wanner <ref> [22] </ref> showed how the derivative vectors and their Jacobians can be computed recursively in the forward mode. In our pilot implementation [4] we are using the forward mode for calculating the derivative vectors and the reverse mode for calculating the derivative matrices. <p> Essentially, the same complexity applies for the dense forward mode, which was already advocated by Wanner <ref> [22] </ref> in the context of numerical ODE solving. ADOL-C yields the sparsity pattern for the partial Jacobians A j , which is then used by the routine that accumulates them to the total Jacobians B j .
References-found: 22

