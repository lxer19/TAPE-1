URL: http://www-ai.ijs.si/AramKaralic/bibliography/1997a.ps
Refering-URL: http://www-ai.ijs.si/AramKaralic/bibliography/1997a.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: aram.karalic@ijs.si  ivan.bratko@fri.uni-lj.si  Editor:  
Title: First Order Regression  
Author: ARAM KARALI C IVAN BRATKO 
Keyword: machine learning, inductive logic programming, regression, real-valued variables, first-order logic, applications of machine learning.  
Address: Ljubljana, Slovenia  Ljubljana, Slovenia  
Affiliation: Jozef Stefan Institute,  Faculty of Electrical Engineering and Computer Science, University of Ljubljana, and Jozef Stefan Institute,  
Note: 1-30 c Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Abstract: We present a new approach, called First Order Regression (FOR), to handling numerical information in Inductive Logic Programming (ILP). FOR is a combination of ILP and numerical regression. First-order logic descriptions are induced to carve out those subspaces that are amenable to numerical regression among real-valued variables. The program Fors is an implementation of this idea, where numerical regression is focused on a distinguished continuous argument of the target predicate. We show that this can be viewed as a generalisation of the usual ILP problem. Applications of Fors on several real-world data sets are described: the prediction of mutagenicity of chemicals, the modelling of liquid dynamics in a surge tank, predicting the roughness in steel grinding, finite element mesh design, and operator's skill reconstruction in electric discharge machining. A comparison of Fors' performance with previous results in these domains indicates that Fors is an effective tool for ILP applications that involve numerical data. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bratko, I., & Dzeroski, S. </author> <year> (1995). </year> <title> Engineering applications of ILP. </title> <journal> New Generation Computing, </journal> <volume> 13, </volume> <pages> 313-333. </pages> <note> 28 Camacho, </note> <author> R. </author> <year> (1994). </year> <title> Learning stage transition rules with Indlog. </title> <booktitle> Proceedings of the Fourth International Workshop on Inductive Logic Programming (ILP-94) (pp. </booktitle> <pages> 273-290), </pages> <address> Bad Honnef/Bonn, Germany: </address> <institution> Gesellschaft fur Mathematik und Datenverarbeitung Sankt Augustin. </institution>
Reference-contexts: 1. Introduction 2. Integrating ILP and Numerical Regression In analysing applications of ILP it has often been observed (e.g. <ref> (Bratko & Dzeroski, 1995) </ref>), that one of the major practical impediments is lack of facilities for handling numerical information in currently available ILP systems.
Reference: <author> Dolsak, B., Bratko, I., & Jezernik, A. </author> <year> (1994). </year> <title> Finite element mesh design: An engineering domain for ILP application. </title> <booktitle> Proceedings of the Fourth International Workshop on Inductive Logic Programming (ILP-94) (pp. </booktitle> <pages> 305-320), </pages> <address> Bad Honnef/Bonn, Germany. </address> <institution> Gesellschaft fur Mathematik und Datenverarbeitung Sankt Augustin. </institution>
Reference-contexts: Most of these problems have already been tackled with other ILP techniques (mutagenicity (Srinivasan et al., 1994), finite element mesh design <ref> (Dolsak et al., 1994) </ref>, regression tree based induction (steel grinding (Filipic et al., 1991)), and equation discovery techniques (liquid dynamics (Krizman et al., 1995)). This enables a comparison of Fors' performance with previous results. The electric discharge machining application has not been attempted previously. 3. <p> Considerable expertise, based on experience, is required for choosing appropriate number of elements, because one has to achieve sufficient accuracy of the computed solution and at the same time maintain CPU time at a reasonable level. In (Dolsak & Muggleton, 1992) and <ref> (Dolsak et al., 1994) </ref>, ILP has been applied to learn general rules about how to suitably partition a given object. In our experiment with Fors we used Dolsak's data (Dolsak et al., 1994). 14 f (LogAct,Compound,Logp,Lumo) :- % This clause covers 25 examples. <p> In (Dolsak & Muggleton, 1992) and <ref> (Dolsak et al., 1994) </ref>, ILP has been applied to learn general rules about how to suitably partition a given object. In our experiment with Fors we used Dolsak's data (Dolsak et al., 1994). 14 f (LogAct,Compound,Logp,Lumo) :- % This clause covers 25 examples. <p> Detailed description of the objects, as well as some pre vious work in the domain can be found in <ref> (Dolsak et al., 1994, Dolsak & Muggleton, 1992) </ref>. 15 In the experiments, four objects were used for learning and the remaining object was used for testing. This was repeated five times, for each possible choice of the objects for learning and testing.
Reference: <author> Dolsak, B. </author> <year> (1996). </year> <title> A Contribution to Mesh Design for Finite Element Method. </title> <type> PhD thesis, </type> <institution> University of Maribor, Faculty of Mechanical Engineering, Maribor, Slovenia. </institution>
Reference-contexts: It should be noted, however, that the simple accuracy is not the most natural measure of success in this domain and does not reflect well the actual applicability. Also, expert interpretation of the results of learning <ref> (Dolsak, 1996) </ref> favours relational representation as opposed to mere attribute representation. 16 f (N,Edge) :- quarter_circuit (Edge),N is 9,!. f (N,Edge) :- circuit_hole (Edge),N is 8,!. f (N,Edge) :- not_important (Edge),N is 1,!. f (N,Edge) :- short_for_hole (Edge),N is 1,!. f (N,Edge) :- short (Edge),N is 2,!. f (N,Edge) :- one_side_loaded <p> With FOR, as usual in ILP, the same effect is achieved by defining a single relation neighbour/2. It is also important to note that in the opinion of a FEM expert (T. Hellen, documented in <ref> (Dolsak, 1996) </ref>), the relational description better captures knowledge used by experts when designing FE meshes. 27 7.5.
Reference: <author> Dolsak, B., Jezernik, A., & Bratko, I. </author> <year> (1994). </year> <title> A knowledge base for finite element mesh design, </title> <booktitle> Artifical Intelligence in Engineering, </booktitle> <volume> 9, </volume> <pages> 19-27. </pages>
Reference-contexts: Most of these problems have already been tackled with other ILP techniques (mutagenicity (Srinivasan et al., 1994), finite element mesh design <ref> (Dolsak et al., 1994) </ref>, regression tree based induction (steel grinding (Filipic et al., 1991)), and equation discovery techniques (liquid dynamics (Krizman et al., 1995)). This enables a comparison of Fors' performance with previous results. The electric discharge machining application has not been attempted previously. 3. <p> Considerable expertise, based on experience, is required for choosing appropriate number of elements, because one has to achieve sufficient accuracy of the computed solution and at the same time maintain CPU time at a reasonable level. In (Dolsak & Muggleton, 1992) and <ref> (Dolsak et al., 1994) </ref>, ILP has been applied to learn general rules about how to suitably partition a given object. In our experiment with Fors we used Dolsak's data (Dolsak et al., 1994). 14 f (LogAct,Compound,Logp,Lumo) :- % This clause covers 25 examples. <p> In (Dolsak & Muggleton, 1992) and <ref> (Dolsak et al., 1994) </ref>, ILP has been applied to learn general rules about how to suitably partition a given object. In our experiment with Fors we used Dolsak's data (Dolsak et al., 1994). 14 f (LogAct,Compound,Logp,Lumo) :- % This clause covers 25 examples. <p> Detailed description of the objects, as well as some pre vious work in the domain can be found in <ref> (Dolsak et al., 1994, Dolsak & Muggleton, 1992) </ref>. 15 In the experiments, four objects were used for learning and the remaining object was used for testing. This was repeated five times, for each possible choice of the objects for learning and testing.
Reference: <author> Dolsak, B., & Muggleton, S. </author> <year> (1992). </year> <title> The application of inductive logic programming to finite-element mesh design. </title> <editor> Stephen Muggleton, editor, </editor> <booktitle> Inductive Logic Programming: </booktitle> <publisher> Academic Press. </publisher>
Reference-contexts: Considerable expertise, based on experience, is required for choosing appropriate number of elements, because one has to achieve sufficient accuracy of the computed solution and at the same time maintain CPU time at a reasonable level. In <ref> (Dolsak & Muggleton, 1992) </ref> and (Dolsak et al., 1994), ILP has been applied to learn general rules about how to suitably partition a given object. In our experiment with Fors we used Dolsak's data (Dolsak et al., 1994). 14 f (LogAct,Compound,Logp,Lumo) :- % This clause covers 25 examples.
Reference: <author> Dzeroski, S. </author> <year> (1991). </year> <title> Handling noise in inductive logic programming. </title> <type> Master's thesis, </type> <institution> University of Ljubljana, Faculty for Electrical Engineering and Computer Science, Ljubljana, Slovenia. </institution>
Reference-contexts: The induction took 51 minutes of CPU time on Sun SPARCstation 10. Usage of MDL pruning produced theories with slightly, but not significantly, lower accuracy. Table 3 compares achieved results with the results of the FOIL (Quinlan, 1990), mFOIL <ref> (Dzeroski, 1991) </ref>, GOLEM (Muggleton & Feng, 1990), MILP (Kovacic, 1995), and FFOIL (Quinlan, 1996). Results for FOIL and FFOIL were obtained from (Quinlan, 1996), results for GOLEM and MILP were obtained from (Kovacic, 1995). Table 3.
Reference: <author> Dzeroski, S. </author> <year> (1995). </year> <title> Numerical Constraints and Learnability in Inductive Logic Programming, </title> <type> PhD thesis, </type> <institution> University of Ljubljana, Faculty for Electrical Engineering and Computer Science, Ljubljana, Slovenia. </institution>
Reference-contexts: 1. Introduction 2. Integrating ILP and Numerical Regression In analysing applications of ILP it has often been observed (e.g. <ref> (Bratko & Dzeroski, 1995) </ref>), that one of the major practical impediments is lack of facilities for handling numerical information in currently available ILP systems. <p> Of all the related work, this is probably the most similar to Fors, but Srinivasan's approach still requires both positive and negative examples which is often unnatural in real-world domains. Induction of differential equations in Fors, as well as in Srinivasan's work, was inspired by the LAGRANGE program <ref> (Dzeroski & Todorovski, 1995) </ref>. 4. Hypothesis Language of Fors Here we give a precise definition of Fors' hypothesis language and corresponding declarations. A hypothesis induced by Fors is a Prolog program. Background knowledge consists of standard Prolog predicate procedures.
Reference: <author> Dzeroski, S., & Todorovski, L. </author> <year> (1995). </year> <title> Discovering dynamics: from inductive logic programming to machine discovery. </title> <journal> Journal of Intelligent Information Systems, </journal> <volume> 4, </volume> <pages> 89-108. </pages>
Reference-contexts: 1. Introduction 2. Integrating ILP and Numerical Regression In analysing applications of ILP it has often been observed (e.g. <ref> (Bratko & Dzeroski, 1995) </ref>), that one of the major practical impediments is lack of facilities for handling numerical information in currently available ILP systems. <p> Of all the related work, this is probably the most similar to Fors, but Srinivasan's approach still requires both positive and negative examples which is often unnatural in real-world domains. Induction of differential equations in Fors, as well as in Srinivasan's work, was inspired by the LAGRANGE program <ref> (Dzeroski & Todorovski, 1995) </ref>. 4. Hypothesis Language of Fors Here we give a precise definition of Fors' hypothesis language and corresponding declarations. A hypothesis induced by Fors is a Prolog program. Background knowledge consists of standard Prolog predicate procedures.
Reference: <author> Filipic, B., Junkar, M., Bratko, I., & Karalic, A. </author> <year> (1991). </year> <title> An application of machine learning to a metal-working process. </title> <booktitle> Proceedings of ITI-91, </booktitle> <pages> 167-172, </pages> <address> Cavtat, Croatia. </address>
Reference-contexts: Most of these problems have already been tackled with other ILP techniques (mutagenicity (Srinivasan et al., 1994), finite element mesh design (Dolsak et al., 1994), regression tree based induction (steel grinding <ref> (Filipic et al., 1991) </ref>), and equation discovery techniques (liquid dynamics (Krizman et al., 1995)). This enables a comparison of Fors' performance with previous results. The electric discharge machining application has not been attempted previously. 3. Integrating ILP and Numerical Regression 3.1. <p> An example of a control action is terminating the process when its performance falls below an unacceptable degree <ref> (Filipic et al., 1991) </ref>. Since control action is easily deducible from workpiece roughness, the subproblem of workpiece roughness estimation was addressed first. <p> <ref> (Filipic et al., 1991) </ref>. Since control action is easily deducible from workpiece roughness, the subproblem of workpiece roughness estimation was addressed first. Several machine learning techniques have already been applied to this problem, yielding encouraging results and showing that machine learning tools can produce adequate models of roughness prediction (see (Filipic et al., 1991) or review paper (Rowe et al., 1994)). 6.4.1. Experiments Measurement data were obtained from an experiment in which vibration signals generated by the grinding wheel and the workpiece were measured by an accelerometer sensor and processed by a spectrum analyser. <p> Simultaneously, workpiece surface roughness was measured. Two background knowledge literals were defined: =&lt; and &gt;=, enabling Fors to compare the frequencies. An experiment was then carried out to evaluate the contribution of so defined background knowledge compared to results obtained previously with attribute-based techniques <ref> (Filipic et al., 1991) </ref>. Several learning sessions were 19 performed with different pre-pruning mechanisms and results of each session were thoroughly evaluated by a domain expert. 6.4.2.
Reference: <author> Hamming, R. W. </author> <year> (1989). </year> <title> Digital Filters: </title> <publisher> Prentice-Hall. </publisher>
Reference-contexts: Approximation of a line for example e k is determined by examples e kDiffWin to e k+DiffWin . The reason that this method is preferred to methods which draw a polynomial through all the points is that this technique also acts as a simple high-pass filter <ref> (Hamming, 1989) </ref>. The technique was already successfully employed to automated modelling of dynamic systems from measurements in (Korenjak, 1994, Krizman, 1993). 5.6. Recursive Definitions The usage of recursive literals is controlled by the parameter LearnRecursive. When LearnRecursive is true, recursive literals are added as follows.
Reference: <author> Junkar, M., Filipic, B., & Bratko, I. </author> <year> (1991). </year> <title> Identifying the Grinding Process by Means of Inductive Machine Learning. </title> <booktitle> Computers in Industry, </booktitle> <pages> 17(2-3), 147-153. </pages>
Reference-contexts: Steel Grinding The task in steel grinding domain is to determine the roughness of the workpiece from the properties of the sound produced during the process of steel grinding <ref> (Junkar, et al., 1991) </ref>. The broader aim of the study was to elaborate the results from the point of view of machine control, where the task is to perform relevant control actions in response to parameter values monitored during the process execution.
Reference: <author> Junkar, M., Filipic, B., & Znidarsic, M. </author> <year> (1993). </year> <title> An AI approach to the selection of dielectricum in electrical discharge machining. </title> <booktitle> Proceedings of Third International Conference on Advanced Manufacturing Systems and Technology AMST'93, </booktitle> <address> Udine, Italy. </address>
Reference-contexts: Electrical Discharge Machining In electrical discharge machining (EDM), the workpiece surface is machined by electrical discharges occurring in the gap between two electrodes | the tool and the workpiece. The gap is continuously flushed by the third element, the dielectricum <ref> (Junkar et al., 1993) </ref>. The process consists of numerous randomly ignited monodis-charges generating crater-textured surface.
Reference: <author> Junkar, M., & Komel, I. </author> <year> (1996). </year> <title> Knowledge Acquisition for Adaptive Control of the EDM Process. </title> <booktitle> Proceedings of 15th IAESTED International Conference on Modelling, Identification and Control (pp. </booktitle> <pages> 295-297), </pages> <address> Innsbruck, Austria. </address>
Reference-contexts: In an automatic controller, the rules could be interpreted probabilistically, determining the proportion of the corresponding directions of change of gap and flow. The operator's and expert's comments on the model (documented in <ref> (Junkar & Komel, 1996) </ref> and (Komel, 1996)) were that most of the induced actions were logical. However, there were some comments about the understandability of the models: * In operator's opinion the decomposition of the problem (separate control rules for gap and flow) degraded model's understandability.
Reference: <author> Karalic, A. </author> <year> (1992). </year> <title> Employing linear regression in regression tree leaves. </title> <booktitle> Proceedings of ECAI'92 (European Conference on Artificial Intelligence) (pp. </booktitle> <pages> 440-441), </pages> <address> Vienna, Austria. </address>
Reference: <author> Karalic, A. </author> <year> (1995a). </year> <title> First Order Regression. </title> <type> PhD thesis, </type> <institution> University of Ljubljana, Faculty for Electrical Engineering and Computer Science. </institution>
Reference-contexts: We define First Order Regression (FOR) as a combination of Inductive Logic Programming, using first order logic, and numerical regression. The approach has been implemented in the program Fors (First Order Regression System, <ref> (Karalic, 1995a, Karalic, 1995b) </ref>). In the paper we present the basic ideas and algorithms of Fors, and several applications to real-world learning problems for which FOR seems to be a natural approach.
Reference: <author> Karalic, A. </author> <year> (1995b). </year> <title> First order regression: Application in real-world domains. </title> <booktitle> Proceedings of Artificial Intelligence Techniques | AIT'95, </booktitle> <address> Brno, Czech Republic. </address>
Reference: <author> Karalic, A. </author> <year> (1996). </year> <title> Producing More Comprehensible Models While Retaining Their Performance. </title> <booktitle> Proceedings of Information, Statistics and Induction in Science ISIS'96 (pp. </booktitle> <pages> 54-65), </pages> <address> Melbourne, Australia. </address>
Reference-contexts: When the MDL pruning is applied, only compressive hypotheses are considered promising, while uncompressive ones are discarded. To use MDL pruning in Fors, the MDL principle implementation had to be devised which can also handle real-valued variables. Details about the implementation can be found in <ref> (Karalic, 1996, Karalic, 1995a) </ref>. 5.4. Linear Regression To allow for detection of linear relationships between the real-valued attributes and the class, Fors has a facility to construct a regression plane through the class values of the covered examples. It is thus possible to add a literal of the form e.g.
Reference: <author> Komel, I. </author> <year> (1996). </year> <title> Surface Modelling and Expert Knowledge Acquisition for the Control of electrical Discharge Machining Process. </title> <type> Master's Thesis, </type> <institution> University of Ljubljana, Faculty of Mechanical Engineering. </institution>
Reference-contexts: In an automatic controller, the rules could be interpreted probabilistically, determining the proportion of the corresponding directions of change of gap and flow. The operator's and expert's comments on the model (documented in <ref> (Junkar & Komel, 1996) </ref> and (Komel, 1996)) were that most of the induced actions were logical. However, there were some comments about the understandability of the models: * In operator's opinion the decomposition of the problem (separate control rules for gap and flow) degraded model's understandability. <p> In an automatic controller, the rules could be interpreted probabilistically, determining the proportion of the corresponding directions of change of gap and flow. The operator's and expert's comments on the model (documented in (Junkar & Komel, 1996) and <ref> (Komel, 1996) </ref>) were that most of the induced actions were logical. However, there were some comments about the understandability of the models: * In operator's opinion the decomposition of the problem (separate control rules for gap and flow) degraded model's understandability. <p> It seems that the model correctly reproduces the operator's skill. The model has been installed on the actual machine to successfully replace the human operator. Expert evaluation together with the comparison of some other approaches to this problem can be found in <ref> (Komel, 1996) </ref>. 7. Discussion We presented a new approach, called First Order Regression (FOR), to handling numerical information in Inductive Logic programming.
Reference: <author> Kompare, B. </author> <year> (1995). </year> <institution> Faculty of Civil Engineering and Geodesy, Department for Hydroengineering, Institute for Sanitary Engineering. Ljubljana, Slovenia. </institution> <type> Personal communication. </type>
Reference-contexts: As a measure of a model's correctness, the difference between the behavior according to the model, and the measured behavior is taken. A domain expert <ref> (Kompare, 1995) </ref> suggested using a b = P N i=1 jh a (t i ) h b (t i )j as a difference measure a b between two behaviors a and b. Table 4 gives the quality of various models.
Reference: <author> Korenjak, B. </author> <year> (1994). </year> <title> Experimental Environment for Modelling of Dynamic Systems Using Artificial Intelligence Methods. </title> <type> Master's thesis, </type> <institution> University of Ljubljana, Faculty for Electrical Engineering and Computer Science, Ljubljana, Slovenia. </institution> <note> In Slovene. </note>
Reference-contexts: The reason that this method is preferred to methods which draw a polynomial through all the points is that this technique also acts as a simple high-pass filter (Hamming, 1989). The technique was already successfully employed to automated modelling of dynamic systems from measurements in <ref> (Korenjak, 1994, Krizman, 1993) </ref>. 5.6. Recursive Definitions The usage of recursive literals is controlled by the parameter LearnRecursive. When LearnRecursive is true, recursive literals are added as follows.
Reference: <author> Kovacic, M. </author> <year> (1995). </year> <title> Stochastic Inductive Logic Programming. </title> <type> PhD thesis, </type> <institution> Faculty of electrical Engineering and Computer Science, Ljubljana, Slovenia. </institution>
Reference-contexts: The induction took 51 minutes of CPU time on Sun SPARCstation 10. Usage of MDL pruning produced theories with slightly, but not significantly, lower accuracy. Table 3 compares achieved results with the results of the FOIL (Quinlan, 1990), mFOIL (Dzeroski, 1991), GOLEM (Muggleton & Feng, 1990), MILP <ref> (Kovacic, 1995) </ref>, and FFOIL (Quinlan, 1996). Results for FOIL and FFOIL were obtained from (Quinlan, 1996), results for GOLEM and MILP were obtained from (Kovacic, 1995). Table 3. <p> Table 3 compares achieved results with the results of the FOIL (Quinlan, 1990), mFOIL (Dzeroski, 1991), GOLEM (Muggleton & Feng, 1990), MILP <ref> (Kovacic, 1995) </ref>, and FFOIL (Quinlan, 1996). Results for FOIL and FFOIL were obtained from (Quinlan, 1996), results for GOLEM and MILP were obtained from (Kovacic, 1995). Table 3.
Reference: <author> Krizman, V. </author> <year> (1993). </year> <title> Handling Noisy Data in Automatic Modelling of Dynamical Systems. </title> <type> Master's thesis, </type> <institution> University of Ljubljana, Faculty for Electrical Engineering and Computer Science, Ljubljana, Slovenia. </institution> <note> In Slovene. 29 Krizman, </note> <author> V., Dzeroski, S., & Kompare, B. </author> <year> (1995). </year> <title> Discovering dynamics from measured data. </title> <booktitle> Working Notes of the MLNet Workshop on Statistics, Machine Learning, and Knowledge Discovery in Databases. </booktitle> <institution> Institute of Computer Science, </institution> <address> Heraklion, Greece. </address>
Reference-contexts: Expert's Evaluation and Conclusions The best theoretically derived model of this tank is considered by experts to be h = 0:05608 h 3:75771 _ hj _ hj: We will now evaluate the model induced by Fors and compare its performance with the models induced by GoldHorn <ref> (Krizman, 1993) </ref> and with the performance of the best known model (the "correct" model). Performance of the "correct" model will also be assessed because even this model does not reproduce the measured system's behavior perfectly.
Reference: <author> Lavrac, N., & Dzeroski, S. </author> <year> (1994). </year> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood, </publisher> <address> Chicester. </address>
Reference-contexts: The system learns from positive and negative examples. Indlog was applied to the problem of cloning pilot's flying skills with some good preliminary results. 4 LINUS and DINUS <ref> (Lavrac & Dzeroski, 1994, Dzeroski, 1995) </ref> map an ILP problem to a propositional learning problem. So the induction is delegated to an attribute-based learner. Employing regression tree induction program Retis (Kar-alic, 1992), LINUS and DINUS can efficiently handle numerical and noisy data.
Reference: <author> Li, M., & Vitanyi, P. </author> <year> (1993). </year> <title> An Introduction to Kolmogorov Complexity and its Applications. Texts and Monographs in Computer Science. </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The MDL principle states that the best theory to explain the data is the one which minimizes the sum of the length (in bits) of the theory description, and the length (in bits) of the data when coded with the help of the theory <ref> (Li & Vitanyi, 1993) </ref>. A hypothesis (clause) is considered compressive if the sum of the coding lengths of the clause and the additional information needed to precisely reconstruct the covered examples, using the clause, is smaller than the sum of coding lengths of examples' class values.
Reference: <author> Mizoguchi, F., & Ohwada, H. </author> <year> (1995). </year> <title> An inductive logic programming approach to constraint acquisition for constraint-based problem solving. </title> <booktitle> Proceedings of the 5th International Workshop on Inductive Logic Programming (ILP-95) (pp. </booktitle> <pages> 297-322): </pages> <institution> Katholieke Universiteit Leuven, Heverlee, Belgium. </institution>
Reference-contexts: So the induction is delegated to an attribute-based learner. Employing regression tree induction program Retis (Kar-alic, 1992), LINUS and DINUS can efficiently handle numerical and noisy data. They are however limited to essentially propositional hypothesis language. Mizoguchi and Ohwada's program <ref> (Mizoguchi & Ohwada, 1995) </ref> produces a constraint logic program from a set of problem solutions. They define constraint-based subsumption (C-subsumption), and use it in the construction of a hypothesis as the least general constraint set.
Reference: <author> Muggleton, S., & Feng, C. </author> <year> (1990). </year> <title> Efficient induction of logic programs. </title> <booktitle> Proceedings of the First Conference on Algorithmic Learning Theory, </booktitle> <address> Tokyo, Japan. </address>
Reference-contexts: The induction took 51 minutes of CPU time on Sun SPARCstation 10. Usage of MDL pruning produced theories with slightly, but not significantly, lower accuracy. Table 3 compares achieved results with the results of the FOIL (Quinlan, 1990), mFOIL (Dzeroski, 1991), GOLEM <ref> (Muggleton & Feng, 1990) </ref>, MILP (Kovacic, 1995), and FFOIL (Quinlan, 1996). Results for FOIL and FFOIL were obtained from (Quinlan, 1996), results for GOLEM and MILP were obtained from (Kovacic, 1995). Table 3.
Reference: <author> Muggleton, S., Srinivasan, A., Bain., M. </author> <year> (1992). </year> <title> Compression, significance and accuracy. </title> <booktitle> Proceedings of Machine Learning Conference 1992 (pp. </booktitle> <pages> 338-347), </pages> <month> Aberdeen. </month>
Reference-contexts: Considerable expertise, based on experience, is required for choosing appropriate number of elements, because one has to achieve sufficient accuracy of the computed solution and at the same time maintain CPU time at a reasonable level. In <ref> (Dolsak & Muggleton, 1992) </ref> and (Dolsak et al., 1994), ILP has been applied to learn general rules about how to suitably partition a given object. In our experiment with Fors we used Dolsak's data (Dolsak et al., 1994). 14 f (LogAct,Compound,Logp,Lumo) :- % This clause covers 25 examples.
Reference: <author> Posel, R. </author> <year> (1995). </year> <title> Expert System for Roughness Prediction During Steel Grinding. </title> <booktitle> Proceedings of Management of Inovative Technologies - MIT'95 (pp. </booktitle> <pages> 296-303), </pages> <address> Bled, Slovenia. </address>
Reference-contexts: Expert's Evaluation and Conclusions It turned out that the use of background knowledge did not bring any significant improvement in the model quality in terms of predictive accuracy. However, the newly induced models frequently contained background knowledge literals. It is interesting that according to domain experts <ref> (Posel, 1995) </ref>, this is a significant improvement, because newly induced models are more general than the models without background knowledge. This is because they do not rely so much on absolute numerical values for specific attribute value thresholds, but instead they evaluate attribute values relatively.
Reference: <author> Quinlan, R. </author> <year> (1990). </year> <title> Learning Logical Definitions From Relations. </title> <journal> Machine Learning, </journal> <volume> 3(5). </volume>
Reference-contexts: Because they always succeed, they were declared as total. With enabled learning of recursive definitions, Fors induced a correct definition of n!, also shown in Figure 1. 5. The Mechanisms of Fors 5.1. Algorithms Fors uses the covering approach similar to the one used in Foil <ref> (Quinlan, 1990) </ref>. The algorithm repeatedly constructs clauses. When a clause is found, all examples covered by the clause are removed from the learning set. The procedure is repeated while there are enough examples left (parameter MinExs). Finally, a default clause is added if necessary. <p> The induction took 51 minutes of CPU time on Sun SPARCstation 10. Usage of MDL pruning produced theories with slightly, but not significantly, lower accuracy. Table 3 compares achieved results with the results of the FOIL <ref> (Quinlan, 1990) </ref>, mFOIL (Dzeroski, 1991), GOLEM (Muggleton & Feng, 1990), MILP (Kovacic, 1995), and FFOIL (Quinlan, 1996). Results for FOIL and FFOIL were obtained from (Quinlan, 1996), results for GOLEM and MILP were obtained from (Kovacic, 1995). Table 3.
Reference: <author> Quinlan, R. </author> <year> (1996), </year> <institution> University of Sydney, Sydney, Australia, </institution> <type> Personal communication. </type>
Reference-contexts: Usage of MDL pruning produced theories with slightly, but not significantly, lower accuracy. Table 3 compares achieved results with the results of the FOIL (Quinlan, 1990), mFOIL (Dzeroski, 1991), GOLEM (Muggleton & Feng, 1990), MILP (Kovacic, 1995), and FFOIL <ref> (Quinlan, 1996) </ref>. Results for FOIL and FFOIL were obtained from (Quinlan, 1996), results for GOLEM and MILP were obtained from (Kovacic, 1995). Table 3. <p> Usage of MDL pruning produced theories with slightly, but not significantly, lower accuracy. Table 3 compares achieved results with the results of the FOIL (Quinlan, 1990), mFOIL (Dzeroski, 1991), GOLEM (Muggleton & Feng, 1990), MILP (Kovacic, 1995), and FFOIL <ref> (Quinlan, 1996) </ref>. Results for FOIL and FFOIL were obtained from (Quinlan, 1996), results for GOLEM and MILP were obtained from (Kovacic, 1995). Table 3.
Reference: <author> Quinlan, R., & Cameron-Jones, M. </author> <year> (1993). </year> <title> FOIL: A Midterm Report. </title> <booktitle> Proceedings of Sixth European Conference on Machine Learning, </booktitle> <pages> (pp. 3-20), </pages> <address> Vienna, Austria. </address>
Reference-contexts: The regression formulas would only involve this attribute. Consequently, Fors would tend to find rules that cover subsets of positive-only examples and negative-only examples. 3.2. Related Work Quinlan and Cameron-Jones <ref> (Quinlan & Cameron-Jones, 1993) </ref> report on useful, although rather basic capability of FOIL to handle, to some degree, real-valued variables.
Reference: <author> Quinlan, R., & Rivest., R. L. </author> <year> (1989). </year> <title> Inferring decision trees using the minimum description length principle. </title> <journal> Information and Computation, </journal> <volume> 80, </volume> <pages> 227-248. </pages>
Reference-contexts: It is an application of Rissanen's minimal description length (MDL) principle (Rissanen, 1978), which has become a common technique for estimating the point at which a theory starts overfitting the data, thus fitting the noise present in the data <ref> (Quinlan & Rivest, 1989, Muggleton et al., 1992, Kovacic, 1995) </ref>.
Reference: <author> Rissanen, J. </author> <year> (1978). </year> <title> Modelling by shortest data description. </title> <journal> Automatica, </journal> <volume> 14, </volume> <pages> 465-471. </pages>
Reference-contexts: When a clause with an error smaller than AllErr is encountered, it is considered as acceptable and the search is stopped. 9 MDL Pruning Another noise-fighting mechanism is the MDL-pruning. It is an application of Rissanen's minimal description length (MDL) principle <ref> (Rissanen, 1978) </ref>, which has become a common technique for estimating the point at which a theory starts overfitting the data, thus fitting the noise present in the data (Quinlan & Rivest, 1989, Muggleton et al., 1992, Kovacic, 1995).
Reference: <author> Rowe, W. B., Yan, L., Inasaki, I., & Malkin, S. </author> <year> (1994). </year> <journal> Applications of Artificial Intelligence in Grinding (Keynote paper). Annals of the CIRP, </journal> <volume> 43(2), </volume> <pages> 521-531. </pages>
Reference-contexts: Several machine learning techniques have already been applied to this problem, yielding encouraging results and showing that machine learning tools can produce adequate models of roughness prediction (see (Filipic et al., 1991) or review paper <ref> (Rowe et al., 1994) </ref>). 6.4.1. Experiments Measurement data were obtained from an experiment in which vibration signals generated by the grinding wheel and the workpiece were measured by an accelerometer sensor and processed by a spectrum analyser.
Reference: <author> Sebag, M., & Rouveirol, C. </author> <year> (1995). </year> <title> Constraint inductive logic programming. </title> <booktitle> Proceedings of the 5th International Workshop on Inductive Logic Programming (ILP-95) (pp. </booktitle> <pages> 297-322): </pages> <institution> Katholieke Universiteit Leuven, Heverlee, Belgium. </institution>
Reference-contexts: They define constraint-based subsumption (C-subsumption), and use it in the construction of a hypothesis as the least general constraint set. The idea is implemented in the system GKS and applied to the problem of spatial layout. GKS also learns from positive and negative examples. Sebag and Rouveirol's approach <ref> (Sebag & Rouveirol, 1995) </ref> is based on an idea of transforming a maximally discriminant generalisation problem into an equivalent constraint satisfaction problem. An induced hypothesis results from solving such a constraint satisfaction problem. Srinivasan's experiments in numerical reasoning in ILP (Srinivasan, 1996) involve numerical inequalities, linear regression and differential equations.
Reference: <author> Srinivasan, A. </author> <year> (1996). </year> <title> Experiments in numerical reasoning with ILP. </title> <editor> Michie, D., Muggleton, S., & Furukawa, K., editors, </editor> <booktitle> Machine Intelligence 15. </booktitle> <publisher> Oxford University Press. </publisher>
Reference-contexts: Sebag and Rouveirol's approach (Sebag & Rouveirol, 1995) is based on an idea of transforming a maximally discriminant generalisation problem into an equivalent constraint satisfaction problem. An induced hypothesis results from solving such a constraint satisfaction problem. Srinivasan's experiments in numerical reasoning in ILP <ref> (Srinivasan, 1996) </ref> involve numerical inequalities, linear regression and differential equations. Of all the related work, this is probably the most similar to Fors, but Srinivasan's approach still requires both positive and negative examples which is often unnatural in real-world domains.
Reference: <author> Srinivasan, A., & Muggleton, S. H. </author> <year> (1995). </year> <title> Comparing the use of background knowledge by two inductive logic programming systems. </title> <booktitle> Proceedings of the 5th International Workshop on Inductive Logic Programming (ILP-95) (pp. </booktitle> <pages> 199-230): </pages> <institution> Katholieke Universiteit Leuven, Heverlee, Belgium. </institution>
Reference-contexts: Srinivasan et al. (Srinivasan et al., 1994, Srinivasan 11 & Muggleton, 1995, Srinivasan et al., 1995) were the first to apply ILP program Progol to the mutagenicity problem with impressive results. 6.1.2. Data We have used data about 188 chemical compounds, studied in <ref> (Srinivasan et al., 1995) </ref>. Mutagenicity is a real number, so numerical regresion was naturally used for prediction. However, to enable comparison with previous work in this domain (Srinivasan et al., 1995), we measured Fors's accuracy in terms of binary predictions: discriminating compounds with positive log mutagenicity from those which have zero <p> Data We have used data about 188 chemical compounds, studied in <ref> (Srinivasan et al., 1995) </ref>. Mutagenicity is a real number, so numerical regresion was naturally used for prediction. However, to enable comparison with previous work in this domain (Srinivasan et al., 1995), we measured Fors's accuracy in terms of binary predictions: discriminating compounds with positive log mutagenicity from those which have zero or negative log mutagenicity, as done in (Srinivasan et al., 1995). Background knowledge consisted of two parts: primitive structural representation of molecules and generic structural knowledge. <p> However, to enable comparison with previous work in this domain <ref> (Srinivasan et al., 1995) </ref>, we measured Fors's accuracy in terms of binary predictions: discriminating compounds with positive log mutagenicity from those which have zero or negative log mutagenicity, as done in (Srinivasan et al., 1995). Background knowledge consisted of two parts: primitive structural representation of molecules and generic structural knowledge. Primitive structural representation is comprised of Prolog facts of the form: bond (Compound,Atom1,Atom2,Bondtype) and atm (Compound,Atom,Element,Atomtype,Charge). The data were originally obtained from the standard molecular modelling package QUANTA (Srinivasan et al., 1995). <p> as done in <ref> (Srinivasan et al., 1995) </ref>. Background knowledge consisted of two parts: primitive structural representation of molecules and generic structural knowledge. Primitive structural representation is comprised of Prolog facts of the form: bond (Compound,Atom1,Atom2,Bondtype) and atm (Compound,Atom,Element,Atomtype,Charge). The data were originally obtained from the standard molecular modelling package QUANTA (Srinivasan et al., 1995). There are 10136 ground facts about bond/4 and atm/5 for the 188 molecules. Generic structural knowledge defines elementary chemical concepts, such as methyl groups, hetero-aromatic rings, and the three distinct topological ways to connect three benzene rings. <p> Additionally, two real-valued attributes, describing important chemical properties, were utilized: a measure of hydrophobicity log P and the energy of the compound's lowest unoccupied molecular orbital * LUMO . 6.1.3. Experiments Ten-fold cross validation was used with exactly the same partitioning of the data as in <ref> (Srinivasan et al., 1995) </ref> of roughly same sized learning/testing example sets. The results of ten tests were then averaged. <p> Notice the accuracy 86:2 9:1 for the default settings of parameters (UseMDL =no, MinExs = 10, MaxRegVars = 0). Comparison with the performance of other algorithms, studied in <ref> (Srinivasan et al., 1995) </ref> is given in Table 2. <p> The results by Fors are compared with the results obtained with Progol, linear regression model, back-propagation neural network, and a version of CART. Srinivasan et al. <ref> (Srinivasan et al., 1995) </ref> give more details about these other algorithms. <p> Additionally, two non-structural attributes were used, which describe important chemical properties of the compounds. The results obtained with Fors were compared with 13 Table 2. Comparison of Fors with other systems in the mutagenicity domain. The results of other algorithms are taken from <ref> (Srinivasan et al., 1995) </ref> Algorithm Accuracy Linear regression + NS 85 3 Linear regression + NS + PS 89 2 Neural network + NS 86 3 Neural network + NS + PS 89 2 CART + NS 82 3 CART + NS + PS 88 2 Progol + NS + S
Reference: <author> Srinivasan, A., Muggleton, S. H., King, R. D., & Sternberg, M. J. E. </author> <year> (1994). </year> <title> Mutagenesis: ILP experiments in a non-determinate biological domain. </title> <booktitle> Proceedings of the Fourth International Workshop on Inductive Logic Programming (ILP-94), </booktitle> <pages> (pp. 217-232): </pages> <address> Bad Honnef/Bonn, Ger-many. </address> <institution> Gesellschaft fur Mathematik und Datenverarbeitung Sankt Augustin. </institution>
Reference-contexts: Most of these problems have already been tackled with other ILP techniques (mutagenicity <ref> (Srinivasan et al., 1994) </ref>, finite element mesh design (Dolsak et al., 1994), regression tree based induction (steel grinding (Filipic et al., 1991)), and equation discovery techniques (liquid dynamics (Krizman et al., 1995)). This enables a comparison of Fors' performance with previous results.
Reference: <author> Srinivasan, A., Stephen, S. H., Sternberg, M. J. E., & King, R. D. </author> <year> (1995). </year> <title> Theories for mutagenic-ity: a study in first-order and feature-based induction. </title> <type> Technical Report PRG-TR-8-95, </type> <institution> Oxford University Computing Laboratory, Oxford. </institution> <month> 30 </month>
Reference-contexts: Srinivasan et al. (Srinivasan et al., 1994, Srinivasan 11 & Muggleton, 1995, Srinivasan et al., 1995) were the first to apply ILP program Progol to the mutagenicity problem with impressive results. 6.1.2. Data We have used data about 188 chemical compounds, studied in <ref> (Srinivasan et al., 1995) </ref>. Mutagenicity is a real number, so numerical regresion was naturally used for prediction. However, to enable comparison with previous work in this domain (Srinivasan et al., 1995), we measured Fors's accuracy in terms of binary predictions: discriminating compounds with positive log mutagenicity from those which have zero <p> Data We have used data about 188 chemical compounds, studied in <ref> (Srinivasan et al., 1995) </ref>. Mutagenicity is a real number, so numerical regresion was naturally used for prediction. However, to enable comparison with previous work in this domain (Srinivasan et al., 1995), we measured Fors's accuracy in terms of binary predictions: discriminating compounds with positive log mutagenicity from those which have zero or negative log mutagenicity, as done in (Srinivasan et al., 1995). Background knowledge consisted of two parts: primitive structural representation of molecules and generic structural knowledge. <p> However, to enable comparison with previous work in this domain <ref> (Srinivasan et al., 1995) </ref>, we measured Fors's accuracy in terms of binary predictions: discriminating compounds with positive log mutagenicity from those which have zero or negative log mutagenicity, as done in (Srinivasan et al., 1995). Background knowledge consisted of two parts: primitive structural representation of molecules and generic structural knowledge. Primitive structural representation is comprised of Prolog facts of the form: bond (Compound,Atom1,Atom2,Bondtype) and atm (Compound,Atom,Element,Atomtype,Charge). The data were originally obtained from the standard molecular modelling package QUANTA (Srinivasan et al., 1995). <p> as done in <ref> (Srinivasan et al., 1995) </ref>. Background knowledge consisted of two parts: primitive structural representation of molecules and generic structural knowledge. Primitive structural representation is comprised of Prolog facts of the form: bond (Compound,Atom1,Atom2,Bondtype) and atm (Compound,Atom,Element,Atomtype,Charge). The data were originally obtained from the standard molecular modelling package QUANTA (Srinivasan et al., 1995). There are 10136 ground facts about bond/4 and atm/5 for the 188 molecules. Generic structural knowledge defines elementary chemical concepts, such as methyl groups, hetero-aromatic rings, and the three distinct topological ways to connect three benzene rings. <p> Additionally, two real-valued attributes, describing important chemical properties, were utilized: a measure of hydrophobicity log P and the energy of the compound's lowest unoccupied molecular orbital * LUMO . 6.1.3. Experiments Ten-fold cross validation was used with exactly the same partitioning of the data as in <ref> (Srinivasan et al., 1995) </ref> of roughly same sized learning/testing example sets. The results of ten tests were then averaged. <p> Notice the accuracy 86:2 9:1 for the default settings of parameters (UseMDL =no, MinExs = 10, MaxRegVars = 0). Comparison with the performance of other algorithms, studied in <ref> (Srinivasan et al., 1995) </ref> is given in Table 2. <p> The results by Fors are compared with the results obtained with Progol, linear regression model, back-propagation neural network, and a version of CART. Srinivasan et al. <ref> (Srinivasan et al., 1995) </ref> give more details about these other algorithms. <p> Additionally, two non-structural attributes were used, which describe important chemical properties of the compounds. The results obtained with Fors were compared with 13 Table 2. Comparison of Fors with other systems in the mutagenicity domain. The results of other algorithms are taken from <ref> (Srinivasan et al., 1995) </ref> Algorithm Accuracy Linear regression + NS 85 3 Linear regression + NS + PS 89 2 Neural network + NS 86 3 Neural network + NS + PS 89 2 CART + NS 82 3 CART + NS + PS 88 2 Progol + NS + S
References-found: 39

