URL: ftp://ftp.cs.wisc.edu/markhill/Papers/isca92_twopages.ps
Refering-URL: http://www.cs.wisc.edu/~markhill/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Tradeoffs in Supporting Two Page Sizes  
Author: Madhusudhan Talluri, Shing Kong, Mark D. Hill, David A. Patterson 
Keyword: Address translation, page size, translation loo-kaside buffer, virtual memory, working set size  
Address: Wisconsin Mail Stop: 29-225 571 Evans Hall Madison, Wisconsin 53706 2550 Garcia Ave. Berkeley, CA 94720 talluri@cs.wisc.edu Mountain View, CA 94043-1100  
Affiliation: Computer Sciences Dept. Sun Microsystems Laboratories, Inc. CS Division, UC Berkeley University of  
Date: June 1992.  
Note: To appear in the Nineteenth International Symposium on Computer Architecture,  
Abstract: As computer system main memories get larger and processor cycles-per-instruction (CPIs) get smaller, the time spent in handling translation lookaside buffer (TLB) misses could become a performance bottleneck. We explore relieving this bottleneck by (a) increasing the page size and (b) supporting two page sizes. We discuss how to build a TLB to support two page sizes and examine both alternatives experimentally with a dozen uniprogrammed, user-mode traces for the SPARC architecture. Our results show that increasing the page size to 32KB causes both a significant increase in average working set size (e.g., 60%) and a significant reduction in the TLB's contribution to CPI, CPI TLB , (namely a factor of eight) compared to using 4KB pages. Results for using two page sizes, 4KB and 32KB pages, on the other hand, show a small increase in working set size (about 10%) and variable decrease in CPI TLB , (from negligible to as good as found with the 32KB page size). CPI TLB when using two page sizes is consistently better for fully associative TLBs than for set-associative ones. Our results are preliminary, however, since (a) our traces do not include multiprogramming or operating system behavior, and (b) our page-size assignment policy may not reflect a real operating system's policy. hhhhhhhhhhhhhhhhhh * Talluri is supported in part by a summer internship at Sun Mi-crosystems Laboratories, Inc. and by National Science Foundation Award (MIPS-8957278); Kong is supported by Sun Microsystems Laboratories, Inc.; Hill is supported in part by a National Science Foundation Presidential Young Investigator Award (MIPS-8957278) with matching funds from A.T.& T. Bell Laboratories, Cray Research Foundation and Digital Equipment Corporation; Patterson is supported in part by DARPA/NASA Ames Research Center, Grant Number: NAG2-591. 
Abstract-found: 1
Intro-found: 1
Reference: [ASH86] <author> A. AGARWAL, R. L. SITES and M. HOROWITZ, ATUM: </author> <title> A New Technique for Capturing Address Traces Using Microcode, </title> <booktitle> Proc. Thirteenth Intl. Symp. on Computer Architecture , June 1986, </booktitle> <pages> 119-129. </pages>
Reference-contexts: Since our tracing tools did not allow us to generate such traces, we could not consider them in this study. The only public-domain traces with operating system behavior that we are aware of are the ATUM traces <ref> [ASH86] </ref>. We do not use these traces as they are too short to exercise the TLBs and the page-size assignment policy. 3.2. Metrics In choosing a new page size scheme a single larger page size or a two page size scheme we tradeoff increased memory demands against better TLB performance.
Reference: [AKB85] <author> C. A. ALEXANDER, W. M. KESHLEAR and F. BRIGGS, </author> <title> Translation Buffer Performance in a UNIX Environment, Computer Architecture News, </title> <month> December </month> <year> 1985, </year> <pages> 2-14. </pages>
Reference-contexts: For example, Tomcatv has a quickly degrading CPI TLB for increasing page sizes for two-way set-associative TLBs. The program's access pattern causes the TLB to thrash even with larger pages. Alexander et al. <ref> [AKB85] </ref> report similar behavior for different traces. We do not see any such anomalies for higher associativities, which indicates that they are due to interaction between the access pattern and the bits used to index the TLB.
Reference: [ApL91] <author> A. W. APPEL and K. LI, </author> <title> Virtual Memory Primitives for User Programs, </title> <booktitle> Proc. 4th Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> April </month> <year> 1991, </year> <pages> 96-107. </pages>
Reference-contexts: Second, as we will show, larger pages result in larger working sets due to internal fragmentation [Den70], i.e., memory wasted due to the page size being larger than what the program needs. Third, the protection granularity becomes coarser. Appel and Li <ref> [ApL91] </ref> describe some applications that would benefit from smaller pages.
Reference: [BlK92] <author> G. BLANCK and S. KRUEGER, </author> <title> The SuperSPARC Microprocessor, </title> <booktitle> COMPCON, </booktitle> <address> San Francisco, </address> <month> February, </month> <year> 1992, </year> <pages> 136-141. </pages>
Reference-contexts: The ETA10 [ETA86] supercomputer supports two page sizes a large page size of 64KW or 256KW and a small page size of 1KW, 2KW or 8KW (word is 64 bits). The R4000 [Sla91] supports thirteen page sizes (4KB to 16MB) and has a 48-entry fully associative TLB. SuperSPARC <ref> [BlK92] </ref> supports four pages sizes (4KB, 256KB, 16MB and 4GB) using a 64-entry fully-associative TLB. Hewlett Packard's PA-RISC 1.1 Architecture [HP90] has a 4-entry fully associative Block TLB for large pages (256KB to 16MB), and a separate fully-associative TLB for 4KB pages.
Reference: [ClE85] <author> D. W. CLARK and J. S. EMER, </author> <title> Performance of the VAX-11/780 Translation Buffer: Simulation and Measurement, </title> <journal> ACM Transactions on Computer Systems 3, </journal> <month> 1 (February </month> <year> 1985), </year> <pages> 31-62. </pages>
Reference-contexts: 1. Introduction A translation lookaside buffer (TLB) is a fast buffer containing recently used virtual-to-physical address translations <ref> [ClE85, HeP90, SaB81, Smi82] </ref>. Most computers that support paged virtual memory [Den70] use TLBs to reduce average address translation time. Ten years ago, TLB miss handling was responsible for only a small fraction of a machine's cycles-per-instruction (CPI). <p> Ten years ago, TLB miss handling was responsible for only a small fraction of a machine's cycles-per-instruction (CPI). A TLB could map a substantial fraction of main memory (e.g., 0.5MB), machines had large CPIs (e.g., 10 cycles), and programs had small working sets. For example, Clark and Emer <ref> [ClE85] </ref> report that the VAX-11/780 loses only 5% of its performance to TLB misses. Wood et al. [WEG86] report TLB miss rates to be around 0.03 - 3% for some machines built in the early 1980s.
Reference: [Cme91] <author> R. F. CMELIK, </author> <title> Introduction to SpixTools, </title> <type> Sun Microsystems Technical Memorandum, </type> <month> June </month> <year> 1991. </year>
Reference-contexts: We simulated the SPEC benchmarks [SPE89] by executing the programs and dynamically generating traces of their memory references, using the tracing tools shade <ref> [Cme91] </ref> and shadow [Hsu89]. We would prefer traces with multiprogrammed and operating-system behavior to exercise large TLBs. Since our tracing tools did not allow us to generate such traces, we could not consider them in this study.
Reference: [CDC81] <institution> CDC CYBER 200 Model 205 Computer System, </institution> <note> Hardware Reference Manual, </note> <institution> Control Data Corporation, </institution> <year> 1981. </year>
Reference-contexts: We are aware of two supercomputers and four recent microprocessor architectures that support multiple page sizes. However, there has been little software support for general use of the larger pages. The CDC CYBER 200 <ref> [CDC81] </ref> supported two page sizes (64KB and a selectable smaller page size) using a fully associative page table. The ETA10 [ETA86] supercomputer supports two page sizes a large page size of 64KW or 256KW and a small page size of 1KW, 2KW or 8KW (word is 64 bits).
Reference: [Den68] <author> P. J. DENNING, </author> <title> The Working Set Model for Program Behavior, </title> <journal> Communications of the ACM 11, </journal> <month> 5 (May </month> <year> 1968), </year> <pages> 323-333. </pages>
Reference-contexts: We measure TLB performance using contribution to CPI due to TLB miss handling, CPI TLB . We derive WS Normalized as follows. W (t, T, ps) is the set of distinct pages referenced in the interval [t -T +1,t], where T is a parameter of the working set algorithm <ref> [Den68] </ref> and ps specifies either a single page size or multiple page sizes and how to select between them. The working set size, w (t, T, ps), is the sum of the sizes of pages in W (t, T, ps).
Reference: [Den70] <author> P. J. DENNING, </author> <title> Virtual Memory, </title> <journal> Computing Surveys 2, </journal> <month> 3 (September </month> <year> 1970), </year> <pages> 153-189. </pages>
Reference-contexts: 1. Introduction A translation lookaside buffer (TLB) is a fast buffer containing recently used virtual-to-physical address translations [ClE85, HeP90, SaB81, Smi82]. Most computers that support paged virtual memory <ref> [Den70] </ref> use TLBs to reduce average address translation time. Ten years ago, TLB miss handling was responsible for only a small fraction of a machine's cycles-per-instruction (CPI). <p> Thus, established architectures like the IBM 370 and DEC VAX-11 still use their original page size. Second, as we will show, larger pages result in larger working sets due to internal fragmentation <ref> [Den70] </ref>, i.e., memory wasted due to the page size being larger than what the program needs. Third, the protection granularity becomes coarser. Appel and Li [ApL91] describe some applications that would benefit from smaller pages. <p> The graph shows that the working set size increases quite significantly by using larger page sizes. Doubling the page size increases working set size by only 1% to 30%. Doubling the page size does not double the working set size because programs exhibit spatial locality <ref> [Den70] </ref>. Programs like matrix300 and tomcatv, that traverse all their address space in a linear looping fashion, already have most of their address space in the working set and increasing page size does not affect their working set sizes much.
Reference: [ETA86] <institution> Mainframe Subsystem Instruction Specification for the ETA10, Rev: B, ETA Systems, Inc., </institution> <month> March </month> <year> 1986. </year>
Reference-contexts: However, there has been little software support for general use of the larger pages. The CDC CYBER 200 [CDC81] supported two page sizes (64KB and a selectable smaller page size) using a fully associative page table. The ETA10 <ref> [ETA86] </ref> supercomputer supports two page sizes a large page size of 64KW or 256KW and a small page size of 1KW, 2KW or 8KW (word is 64 bits). The R4000 [Sla91] supports thirteen page sizes (4KB to 16MB) and has a 48-entry fully associative TLB.
Reference: [HeP90] <author> J. L. HENNESSY and D. A. PATTERSON, </author> <title> Computer Architecture A Quantitative Approach, </title> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <year> 1990. </year>
Reference-contexts: 1. Introduction A translation lookaside buffer (TLB) is a fast buffer containing recently used virtual-to-physical address translations <ref> [ClE85, HeP90, SaB81, Smi82] </ref>. Most computers that support paged virtual memory [Den70] use TLBs to reduce average address translation time. Ten years ago, TLB miss handling was responsible for only a small fraction of a machine's cycles-per-instruction (CPI). <p> Option (c) will result in unused hardware if pages are not appropriately distributed between the two page sizes. 2.3. How to Handle Misses in a TLB that Supports Two Page Sizes The time taken to handle a miss, the miss penalty, is an important parameter in determining TLB performance <ref> [HeP90] </ref>. Supporting two page sizes makes miss handling more difficult as we do not know the page size for the memory reference that caused the miss. <p> We measure TLB performance as the contribution to CPI due to TLB miss handling, CPI TLB . This metric can be directly related to program execution time <ref> [HeP90] </ref>. CPI TLB is calculated as follows : CPI TLB = (TLB misses per instruction) (TLB miss penalty). From trace-driven simulations, we calculate the TLB misses per instruction (MPI) factor. The TLB miss penalty depends on both hardware and software and is more difficult to estimate (see Section 2.3).
Reference: [HP90] <institution> PA RISC 1.1 Architecture and Instruction Set Reference Manual, Hewlett Packard, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: The R4000 [Sla91] supports thirteen page sizes (4KB to 16MB) and has a 48-entry fully associative TLB. SuperSPARC [BlK92] supports four pages sizes (4KB, 256KB, 16MB and 4GB) using a 64-entry fully-associative TLB. Hewlett Packard's PA-RISC 1.1 Architecture <ref> [HP90] </ref> has a 4-entry fully associative Block TLB for large pages (256KB to 16MB), and a separate fully-associative TLB for 4KB pages.
Reference: [HiS89] <author> M. D. HILL and A. J. SMITH, </author> <title> Evaluating Associativity in CPU Caches, </title> <journal> IEEE Trans. on Computers C-38, </journal> <month> 12 (December </month> <year> 1989), </year> <pages> 1612-1630. </pages>
Reference-contexts: Simulation Technique Due to the large number of different TLB configurations that needed to be simulated and the long running time of the trace-driven simulations, it was not feasible to perform simulations one at a time. We performed TLB simulations with the cache simulator tycho. Tycho implements all-associativity simulation <ref> [HiS89] </ref>, a variation of stack simulation [MGS70]. We modified tycho to handle using index bits other than the least significant bits of the page number and to support two page sizes.
Reference: [Hsu89] <author> P. Y. HSU, </author> <title> Introduction to SHADOW, </title> <type> Sun Microsystems Technical Memorandum, </type> <month> July </month> <year> 1989. </year>
Reference-contexts: We simulated the SPEC benchmarks [SPE89] by executing the programs and dynamically generating traces of their memory references, using the tracing tools shade [Cme91] and shadow <ref> [Hsu89] </ref>. We would prefer traces with multiprogrammed and operating-system behavior to exercise large TLBs. Since our tracing tools did not allow us to generate such traces, we could not consider them in this study.
Reference: [INT91] <institution> Overview of the i860 XP Supercomputing Microprocessor, Intel Corporation, </institution> <year> 1991. </year>
Reference-contexts: SuperSPARC [BlK92] supports four pages sizes (4KB, 256KB, 16MB and 4GB) using a 64-entry fully-associative TLB. Hewlett Packard's PA-RISC 1.1 Architecture [HP90] has a 4-entry fully associative Block TLB for large pages (256KB to 16MB), and a separate fully-associative TLB for 4KB pages. The Intel i860 XP microprocessor <ref> [INT91] </ref> supports one very large page size with a 16-entry TLB for 4MB pages and a separate 64-entry TLB for 4KB pages (both TLBs are four-way set-associative). All require pages to be aligned. In this study we compare use of two page sizes versus a single page size.
Reference: [KJL89] <author> R. E. KESSLER, R. JOOSS, A. LEBECK and M. D. HILL, </author> <title> Inexpensive Implementations of Set-Associativity, </title> <booktitle> Proc. 16th Symp. on Computer Architecture , June 1989, </booktitle> <pages> 131-139. </pages>
Reference-contexts: If we have a miss, reprobe <ref> [KJL89] </ref> the TLB with the large page number. (c) Split TLBs: Have a separate TLB for each page size. This is similar to supporting split instruction and data TLBs. Access both TLBs in parallel using different page numbers (small and large).
Reference: [MGS70] <author> R. L. MATTSON, J. GECSEI, D. R. SLUTZ and I. L. TRAIGER, </author> <title> Evaluation Techniques for Storage Hierarchies, </title> <journal> IBM Systems Journal 9, </journal> <volume> 2 (1970), </volume> <pages> 78-117. </pages>
Reference-contexts: We performed TLB simulations with the cache simulator tycho. Tycho implements all-associativity simulation [HiS89], a variation of stack simulation <ref> [MGS70] </ref>. We modified tycho to handle using index bits other than the least significant bits of the page number and to support two page sizes.
Reference: [Org72] <author> E. J. ORGANICK, </author> <title> The Multics System: An Examination of Its Structure, </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1972. </year>
Reference-contexts: Fifth, external fragmentation is now possible, which does not exist with a single page size. External fragmentation is waste due to the page size being larger than a contiguous region of available memory. Nevertheless, supporting two page sizes is much simpler than supporting Multics-style segments <ref> [Org72] </ref> or many page sizes. Supporting segments that can be of arbitrary length starting at arbitrary addresses, requires TLBs to form physical addresses by addition than by concatenation, and software for mitigating external fragmentation is harder.
Reference: [SPA91] <institution> The SPARC Architecture Manual, </institution> <type> Version 8, </type> <institution> SPARC International Inc., </institution> <address> Menlo Park, CA., </address> <year> 1991. </year>
Reference-contexts: We estimate that miss-handling routines that support two page sizes take about 25% longer to execute than similar routines for a single page size. This estimate is based on routines written in assembly code for the SPARC architecture <ref> [SPA91] </ref>. Typical miss handlers use the least significant bits of the page number to index into a data structure, and this is more complicated with two page sizes. A multi-level table or split tables accessed by trying all page sizes in some order may be candidates for page-table data structures.
Reference: [SPE89] <editor> SPEC, Newsletter, </editor> <volume> Vol. 1, </volume> <year> 1989. </year>
Reference-contexts: Trace lengths are number of memory references made by the programs. "WS Size" is the average working set size for the program when using 4KB pages, with the working set parameter T equal to ten million references. We simulated the SPEC benchmarks <ref> [SPE89] </ref> by executing the programs and dynamically generating traces of their memory references, using the tracing tools shade [Cme91] and shadow [Hsu89]. We would prefer traces with multiprogrammed and operating-system behavior to exercise large TLBs.
Reference: [SaB81] <author> M. SATYANARAYANAN and D. BHANDARKAR, </author> <title> Design Trade-offs in VAX-11 Translation Buffer Organization, </title> <booktitle> IEEE Computer 14, </booktitle> <month> 12 (December </month> <year> 1981), </year> <pages> 103-111. </pages>
Reference-contexts: 1. Introduction A translation lookaside buffer (TLB) is a fast buffer containing recently used virtual-to-physical address translations <ref> [ClE85, HeP90, SaB81, Smi82] </ref>. Most computers that support paged virtual memory [Den70] use TLBs to reduce average address translation time. Ten years ago, TLB miss handling was responsible for only a small fraction of a machine's cycles-per-instruction (CPI).
Reference: [Sla91] <author> M. SLATER, </author> <title> MIPS Previews 64-Bit R4000 Architecture, </title> <type> Microprocessor Report 5, 2 (February 6, </type> <year> 1991), </year> <month> 1,6-9,18. </month>
Reference-contexts: The ETA10 [ETA86] supercomputer supports two page sizes a large page size of 64KW or 256KW and a small page size of 1KW, 2KW or 8KW (word is 64 bits). The R4000 <ref> [Sla91] </ref> supports thirteen page sizes (4KB to 16MB) and has a 48-entry fully associative TLB. SuperSPARC [BlK92] supports four pages sizes (4KB, 256KB, 16MB and 4GB) using a 64-entry fully-associative TLB.
Reference: [SlT74] <author> D. R. SLUTZ and I. L. TRAIGER, </author> <title> A Note on the Calculation of the Average Working Set Size, </title> <journal> Communications of the ACM 17, </journal> <month> 10 (October </month> <year> 1974), </year> <pages> 563-565. </pages>
Reference: [Slu75] <author> D. R. SLUTZ, </author> <title> A Relation Between Working Set and Optimal Algorithms for Segment Reference Strings, </title> <type> IBM Research Report RJ 1623, </type> <month> July </month> <year> 1975. </year>
Reference-contexts: We consumed 5.5 months of CPU time to collect the data, a subset of which we present in this paper. hhhhhhhhhhhhhhhhhh 1. We do not use Slutz's algorithm for multiple page sizes <ref> [Slu75] </ref> because it does not allow page sizes to change dynamically, which we assume in our page-size assignment policy (Section 3.4). 3.4. Policy for Page-Size Assignment To test the performance of TLBs supporting two page sizes, we need a policy to assign page sizes to regions of the address space.
Reference: [Smi82] <author> A. J. SMITH, </author> <title> Cache Memories, </title> <journal> Computing Surveys 14, </journal> <month> 3 (September, </month> <year> 1982), </year> <pages> 473 - 530. </pages>
Reference-contexts: 1. Introduction A translation lookaside buffer (TLB) is a fast buffer containing recently used virtual-to-physical address translations <ref> [ClE85, HeP90, SaB81, Smi82] </ref>. Most computers that support paged virtual memory [Den70] use TLBs to reduce average address translation time. Ten years ago, TLB miss handling was responsible for only a small fraction of a machine's cycles-per-instruction (CPI).
Reference: [WEG86] <author> D. A. WOOD, S. J. EGGERS, G. GIBSON, M. D. HILL, J. PENDLETON, S. A. RITCHIE, R. H. KATZ and D. A. PATTERSON, </author> <title> An In-Cache Address Translation Mechanism, </title> <booktitle> Proc. 13th Intl. Symp. on Computer Architecture, </booktitle> <address> Tokyo, Japan, </address> <month> June </month> <year> 1986. </year> <month> - 10 </month> - 
Reference-contexts: A TLB could map a substantial fraction of main memory (e.g., 0.5MB), machines had large CPIs (e.g., 10 cycles), and programs had small working sets. For example, Clark and Emer [ClE85] report that the VAX-11/780 loses only 5% of its performance to TLB misses. Wood et al. <ref> [WEG86] </ref> report TLB miss rates to be around 0.03 - 3% for some machines built in the early 1980s. However, technological and architectural trends have led to increasing main memory sizes, decreasing CPIs, and programs with larger working sets.
References-found: 26

