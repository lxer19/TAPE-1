URL: file://cse.ogi.edu/pub/ogipvm/papers/SC94.ps.gz
Refering-URL: http://www.cse.ogi.edu/~konuru/
Root-URL: http://www.cse.ogi.edu
Title: Adaptive Load Migration systems for PVM  
Author: Jeremy Casas, Ravi Konuru, Steve W. Otto, Robert Prouty, and Jonathan Walpole 
Address: PO Box 91000 Portland, OR 97291-1000, USA  
Affiliation: Department of Computer Science and Engineering Oregon Graduate Institute of Science Technology  
Note: ISSN 1063-9535. Copyright (c) 1994 IEEE. All rights reserved.  
Abstract: Adaptive load distribution is necessary for parallel applications to co-exist effectively with other jobs in a network of shared, heterogeneous workstations. We present three methods that provide such support for PVM applications. Two of these methods, MPVM and UPVM, adapt to changes in the workstation environment by transparently migrating the virtual processors (VPs) of the parallel application. A VP in MPVM is a Unix process, while UPVM defines lightweight, process-like VPs. The third method, ADM, is a programming methodology for writing programs that perform adaptive load distribution through data movement. These methods are discussed and compared in terms of effectiveness, usability, and performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adam Beguelin, Jack Dongarra, Al Geist, Robert Manchek, and Vaidy Sunderam. </author> <title> Heterogeneous network computing. </title> <booktitle> In Sixth SIAM Conference on Parallel Processing. </booktitle> <publisher> SIAM, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction Message-passing systems such as PVM <ref> [1, 2, 3] </ref> allow a heterogeneous network of parallel and serial computers to be programmed as a single computational resource. This resource appears to the application programmer as a distributed-memory virtual computer. PVM provides facilities for process initiation, communication and synchronization.
Reference: [2] <author> Jack Dongarra, G. A. Geist, Robert Manchek, and V. S. Sunderam. </author> <title> Integrated PVM framework supports heterogeneous network computing. </title> <journal> Computers in Physics, </journal> <volume> 7(2) </volume> <pages> 166-175, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Message-passing systems such as PVM <ref> [1, 2, 3] </ref> allow a heterogeneous network of parallel and serial computers to be programmed as a single computational resource. This resource appears to the application programmer as a distributed-memory virtual computer. PVM provides facilities for process initiation, communication and synchronization.
Reference: [3] <author> Adam Beguelin, Jack Dongarra, Al Geist, Robert Manchek, Steve Otto, and Jon Walpole. </author> <title> PVM: Experiences, current status and future direction. </title> <booktitle> In Supercomputing'93 Proceedings, </booktitle> <pages> pages 765-6, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Message-passing systems such as PVM <ref> [1, 2, 3] </ref> allow a heterogeneous network of parallel and serial computers to be programmed as a single computational resource. This resource appears to the application programmer as a distributed-memory virtual computer. PVM provides facilities for process initiation, communication and synchronization. <p> All of our systems assume the presence of a network-wide "global" scheduler (GS) that embodies decision-making policies for sensibly scheduling multiple parallel jobs. It is also responsible for initiating VP migration. The GS is part of the larger Concurrent Processing Environment (CPE) project, an ongoing research effort <ref> [3] </ref>. 2.1 MPVM MPVM is an extension of PVM to support transparent migration of process-based VPs. Migrating a process of a parallel application involves capturing the current execution state and transferring this state to another host.
Reference: [4] <author> M. Litzkow, M. Livny, and M. </author> <title> Mutka. Condor | a hunter of idle workstations. </title> <booktitle> In Proceedings of the 8th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 104-111, </pages> <address> San Jose, CA, </address> <month> June </month> <year> 1988. </year> <note> IEEE. </note>
Reference-contexts: For information on obtaining permission, send a blank email message to info.pub.permission@ieee.org. By choosing to view this document, you agree to all provisions of the copyright laws protecting it. or partially idle much of the time <ref> [4] </ref>, they are an attractive source of effectively free processing power. Shared, general-purpose worknets have certain key characteristics that affect execution of parallel applications. First, sharing implies that the load on individual processors and the network varies dynamically. This unpredictable variability can drastically degrade parallel application performance. <p> DataSize MigrationTime (seconds) 0.6 MB 1.75 5.8 MB 5.46 13.5 MB 12.41 Table 6: Obtrusiveness (same as migration) cost for ADMopt 5 Related Work There are a number of existing systems that address similar concerns as those of this paper. Condor <ref> [4, 10] </ref> schedules sequential applications on otherwise idle workstations while remaining unobtrusive to their owners. Condor advocates checkpoint-based migration both for unobtrusiveness and fault tolerance as opposed to the "migrate current state" policy we chose.
Reference: [5] <author> Message Passing Interface Forum. </author> <title> MPI: A message-passing interface standard. </title> <institution> Computer Science Dept. </institution> <type> Technical Report CS-94-230, </type> <institution> University of Tennessee, Knoxville, TN, </institution> <month> April </month> <year> 1994. </year> <journal> (To appear in the International Journal of Supercomputer Applications, </journal> <volume> Volume 8, Number 3/4, </volume> <year> 1994). </year>
Reference-contexts: We describe three methods that provide such support. Although the methods and our prototypes use PVM, the underlying concepts are applicable to other message-passing systems such as MPI <ref> [5] </ref>. The first system, Migratable PVM (MPVM), uses Unix processes as its virtual processors and allows the transparent migration of these processes. The processes of an MPVM application can be suspended on one workstation and subsequently resumed on another without any help from the application program.
Reference: [6] <author> Ravi Konuru, Jeremy Casas, Steve Otto, Robert Prouty, and Jonathan Walpole. </author> <title> A user-level process package for PVM. </title> <booktitle> In 1994 Scalable High-Performance Computing Conference, </booktitle> <pages> pages 48-55. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1994. </year>
Reference-contexts: The package is source-code compatible with PVM requiring no more than re-compilation and re-linking of PVM applications. The second system, UPVM, is a virtual pro ISSN 1063-9535. Copyright (c) 1994 IEEE. All rights reserved. cessor (VP) package that supports multi-threading and transparent migration for PVM applications <ref> [6] </ref>. The virtual processors are called User Level Processes (ULPs) and can be thought of as light-weight, Unix-like processes that are independently migratable. UPVM also supports a source-code compatible PVM interface often requiring no modification to the application source. <p> Only processes sending a message to the migrating process are blocked. Finally, the application resumes execu tion as if the migration never occurred. ISSN 1063-9535. Copyright (c) 1994 IEEE. All rights reserved. 2.2 UPVM UPVM is a package that supports multi-threading and transparent migration for PVM applications <ref> [6] </ref>. While MPVM provides transparent migration of processes, UPVM provides a set of "smaller" entities than processes to migrate, allowing load redistribution at a finer granularity. <p> In addition, UPVM adds extra information for remote messages that results in marginally slower remote communication than MPVM. However, if an application is divided into more than one VP per node, an application will run faster (than with PVM or MPVM) since UPVM optimizes local communication and context switch <ref> [6] </ref>. Specifically, context switch among ULPs is ISSN 1063-9535. Copyright (c) 1994 IEEE. All rights reserved. an order of magnitude better than that of processes. Further, in the case of message communication on the same processor, the UPVM library directly enters the message in the destination ULP receive queue.
Reference: [7] <author> Robert Prouty, Steve W. Otto, and Jonathan Walpole. </author> <title> Adaptive execution of data parallel computation on networks of heterogeneous workstations. </title> <type> Technical Report CSE-94-012, </type> <institution> Dept. of Computer Science and Engineering, Oregon Graduate Institute of Science & Technology, </institution> <year> 1994. </year>
Reference-contexts: The virtual processors are called User Level Processes (ULPs) and can be thought of as light-weight, Unix-like processes that are independently migratable. UPVM also supports a source-code compatible PVM interface often requiring no modification to the application source. Finally, Adaptive Data Movement (ADM) <ref> [7] </ref> is an application-level methodology that provides programmers with an infrastructure for developing adaptive computations based on work redistribution. Unlike MPVM and UPVM that support work distribution by migrating VPs, ADM provides work distribution through data movement by the application. Section 2, describes the systems in more detail.
Reference: [8] <author> M. Litzkow and M. Solomon. </author> <title> Supporting checkpoint and process migration outside the unix ker-nal. </title> <booktitle> In Usenix Winter Conference, </booktitle> <year> 1992. </year>
Reference-contexts: Subsequently, the system was ported to the SPARC architecture running SunOS 4.x. We have attempted to limit the dependence of the migration mechanism on the OS by using generic features found in most versions of Unix <ref> [8] </ref>. As long as a process can take a snap-shot of its register context and determine the extents of its writable data, heap, and stack space at run-time, porting is not difficult. Most Unix systems provide this capability. UPVM also runs on the same HP systems.
Reference: [9] <author> Etienne Barnard and Ronald Cole. </author> <title> A neural-net training program based on conjugate-gradient optimization. </title> <type> Technical Report CSE-89-014, </type> <institution> Dept. of Computer Science and Engineering, Ore-gon Graduate Institute of Science & Technology, </institution> <year> 1989. </year>
Reference-contexts: Migration cost. What is the time taken from the instant the migration event was received to the instant the migrated unit of work is integrated back into the parallel job? We applied the three methods to "Opt," a neural-network classifying application based on conjugate-gradient optimization <ref> [9] </ref>. Opt is generally employed as a speech classifier utilizing large (500KB to 400MB) training sets as input. Opt works by applying an initial neural net to a series of floating point vectors called exemplars (representing digitized speech sound) so that a gradient is found.
Reference: [10] <author> A. Bricker, M. Litzkow, and M. Livny. </author> <title> Condor technical summary. </title> <type> Technical report, </type> <institution> University of Wisconsin at Madison, </institution> <month> October </month> <year> 1991. </year>
Reference-contexts: DataSize MigrationTime (seconds) 0.6 MB 1.75 5.8 MB 5.46 13.5 MB 12.41 Table 6: Obtrusiveness (same as migration) cost for ADMopt 5 Related Work There are a number of existing systems that address similar concerns as those of this paper. Condor <ref> [4, 10] </ref> schedules sequential applications on otherwise idle workstations while remaining unobtrusive to their owners. Condor advocates checkpoint-based migration both for unobtrusiveness and fault tolerance as opposed to the "migrate current state" policy we chose.
Reference: [11] <author> Nenad Nedeljkovic and Michael J. Quinn. </author> <title> Data-parallel programming on a network of heterogeneous workstations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 5(4) </volume> <pages> 257-268, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Condor [4, 10] schedules sequential applications on otherwise idle workstations while remaining unobtrusive to their owners. Condor advocates checkpoint-based migration both for unobtrusiveness and fault tolerance as opposed to the "migrate current state" policy we chose. Data Parallel C (DPC) is a parallel programming environment <ref> [11] </ref> composed of a compiler and run-time environment that exports a SIMD, shared-address-space model. DPC is closest to our UPVM system. They both separate application-level parallelism from processor availability and make the efficient choice of one process per allocated processor.
Reference: [12] <author> N. Carriero, D. Galernter, D. Kaminsky, and J. Westbrook. </author> <title> Adaptive parallelism and piranha. </title> <note> available via anonymous ftp from dept-gw.cs.yale.edu as pub/piranha.ps.Z . ISSN 1063-9535. Copyright (c) 1994 IEEE. All rights reserved. </note>
Reference-contexts: Specifically, VP migration is possible only at the beginning or end of code segments that emulate a single VP. Piranha <ref> [12] </ref> is a system for adaptive parallel programming implemented on top of Linda. Piranha is very similar to ADM in that the application programmer structures the program in a certain way and writes certain functions that allow the application to adapt to a dynamic environment.
References-found: 12

