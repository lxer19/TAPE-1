URL: ftp://ftp.cs.cornell.edu/pub/chandra/others/shay.ps.Z
Refering-URL: http://www.cs.cornell.edu/Info/People/chandra/podc95/program.html
Root-URL: 
Title: Fast Distributed Construction of k-Dominating Sets and Applications (Extended Abstract)  
Author: Shay Kutten David Peleg 
Abstract: This paper presents a fast distributed algorithm to compute a small k-dominating set D (for any fixed k) and its induced graph partition (breaking the graph into radius k clusters centered around the vertices of D). The time complexity of the algorithm is O(k log fl n). Small k-dominating sets have applications in a number of areas, including routing with sparse routing tables via the scheme of [PU], the design of distributed data structures [P2], and center selection in a distributed network (cf. [BKP]). The main application described in this paper concerns a fast distributed algorithm for constructing a minimum weight spanning tree (MST). On an n-vertex network of diameter d, the new algorithm constructs an MST in time O( n log fl n + d), improving on the results of [GKP]. The new MST algorithm is conceptually simpler than the three-phase algorithm of [GKP]. In addition to exploiting small k-dominating sets, it uses a very simple convergecast protocol to inform a center about graph edges, that avoids forwarding messages about edges that close cycles. This convergecast protocol is similar to the one used in the third phase of the algorithm of [GKP], and most of the novelty lies in a new careful analysis proving that the convergecast process is fully pipelined, and no waiting occurs at intermediate nodes. This enables the new algorithm to skip the complicated second phase of the algorithm of [GKP].
Abstract-found: 1
Intro-found: 1
Reference: [AG] <author> Y. Afek and E. Gafni, </author> <title> Time and message bounds for election in synchronous and asynchronous complete networks, </title> <booktitle> Proc. 4th Symp. on Principles of Distributed Computing, </booktitle> <year> 1985, </year> <pages> 186-195. </pages>
Reference-contexts: Finally, in 3.2.3 we show how to improve the running time by a factor of log k, using an idea similar to those used before e.g. in <ref> [AG, G, CT, A2, JM] </ref>. 3.2.1 Constructing a (k + 1; O (k 2 )) spanning forest The algorithm DOM Partition 1 (k) described in Figure 5 for constructing this partition operates on a tree T via repetitive applications of Procedure Balanced DOM. <p> In the next subsection we give a more precise description of Procedure Simple MST, resulting in an improved time complexity of O (k), again using an idea similar to <ref> [AG, G, CT, A2, JM] </ref>. 4.3 Procedure Simple MST The (synchronous) algorithm operates in phases 1; 2; ::: log k+ 1, where phase i lasts exactly 5 2 i + 2 time units.
Reference: [AK] <author> S. Aggarwal and Shay Kutten, </author> <title> Time-Optimal Self Stabilizing Spanning Tree Algorithms, </title> <booktitle> Proc. 13th Conf. on Foundations of Software Technology and Theoretical Computer Science, </booktitle> <address> Bombay, India, </address> <month> December </month> <year> 1993. </year>
Reference: [A1] <author> Baruch Awerbuch, </author> <title> Complexity of network synchronization, </title> <journal> J. ACM, </journal> <volume> Vol. 32, </volume> <year> (1985), </year> <pages> 804-823. </pages>
Reference-contexts: We also assume that the computation performed by the network is synchronous. (This assumption is not essential, since our decision to ignore communication costs allows us to freely use a synchronizer of our choice; for example, we can use the simple synchronizer ff of <ref> [A1] </ref> whose cost in an asynchronous network is one message over each edge in each direction per round of the synchronous algorithm.) Still, we shall not adopt the extreme model employed in previous studies of locality issues [L], in which messages of arbitrary size are allowed to be transmitted in a
Reference: [A2] <author> B. Awerbuch, </author> <title> Optimal distributed algorithms for minimum-weight spanning tree, counting, leader election and related problems, </title> <booktitle> Proc. 19th Symp. on Theory of Computing, </booktitle> <pages> pp. 230-240, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: The algorithm presented in [GKP] has time complexity O (n :614 + Diam), hence it is neighborhood optimal for the case that Diam &gt; n :614 . Previous MST algorithms had running time O (n log n) [GHS], O (n log fl n)[CT, G], and O (n) <ref> [A2] </ref>. Using the fast k Dominating Set algorithm we manage to present an improved MST construction algorithm whose time complexity is O ( p n log fl n+Diam (G)). Thus the MST algorithm is now neighborhood optimal for all graphs with Diam &gt; n 1=2 log fl n. <p> We will also make the assumption that edge weights are polynomial in n, so an edge weight can be sent in a single message. (This assumption is required for the time analysis of the previous algorithms that use edge weights or nodes identity, e.g. <ref> [GHS, A2, GKP] </ref>.) Let us now define the Minimum Spanning Tree task solved later on as an application of the k Dominating Set algorithm. <p> Finally, in 3.2.3 we show how to improve the running time by a factor of log k, using an idea similar to those used before e.g. in <ref> [AG, G, CT, A2, JM] </ref>. 3.2.1 Constructing a (k + 1; O (k 2 )) spanning forest The algorithm DOM Partition 1 (k) described in Figure 5 for constructing this partition operates on a tree T via repetitive applications of Procedure Balanced DOM. <p> This procedure is basically a simplified version of the algorithms of <ref> [GHS, A2, G] </ref>. <p> This procedure is basically a simplified version of the algorithms of [GHS, A2, G]. The minor modifications necessary for the algorithm of <ref> [A2] </ref> result from the fact that we need to stop the algorithm after log (k + 1) phases, but to ensure that these phases do not last more than O (k) time, while in the [A2] algorithm O (n) time is allowed for O (log n) phases. <p> The minor modifications necessary for the algorithm of <ref> [A2] </ref> result from the fact that we need to stop the algorithm after log (k + 1) phases, but to ensure that these phases do not last more than O (k) time, while in the [A2] algorithm O (n) time is allowed for O (log n) phases. Rather than describing the somewhat involved algorithm of [A2] in its entirety along with our modifications, we present a version that is significantly simplified, due to our assumptions that the network is synchronized and that message complexity is ignored. <p> that we need to stop the algorithm after log (k + 1) phases, but to ensure that these phases do not last more than O (k) time, while in the <ref> [A2] </ref> algorithm O (n) time is allowed for O (log n) phases. Rather than describing the somewhat involved algorithm of [A2] in its entirety along with our modifications, we present a version that is significantly simplified, due to our assumptions that the network is synchronized and that message complexity is ignored. (The number of messages in our algorithm can be reduced, at the expense of simplicity). <p> Algorithms using similar ideas have appeared in the literature also in different contexts (cf. [JM]). 4.2 A High Level description The high level description of the Simple MST procedure we use here is similar to the algorithms of <ref> [GHS, A2] </ref>, and the differences concern mainly the termination rule and some implementation details 1 . Nodes group themselves into fragments of increasing size. Initially, all nodes are in singleton fragments. <p> In the next subsection we give a more precise description of Procedure Simple MST, resulting in an improved time complexity of O (k), again using an idea similar to <ref> [AG, G, CT, A2, JM] </ref>. 4.3 Procedure Simple MST The (synchronous) algorithm operates in phases 1; 2; ::: log k+ 1, where phase i lasts exactly 5 2 i + 2 time units. <p> Moreover, each tree of this forest is a fragment of the MST of the graph. Proof: The proof is just a simplified version of the proofs of the previous algorithms, e.g. <ref> [GHS, A2] </ref>. The lower bound of k + 1 on the size of fragments can be proved inductively, arguing that after phase i, every fragment is of size at least 2 i .
Reference: [AKMPV] <author> B. Awerbuch, S. Kutten, Y. Mansour, B. Patt--Shamir and G. Varghese, </author> <title> Time-Optimal Self Stabilizing Synchronization, </title> <booktitle> Proc. 25th Symp. on Theory of Computing, </booktitle> <address> San Diego, California, </address> <pages> pp. 652-661, </pages> <month> May </month> <year> 1993. </year>
Reference: [AGLP] <author> B. Awerbuch, A. Goldberg, M. Luby and S. Plotkin, </author> <title> Network decomposition and locality in distributed computation, </title> <booktitle> Proc. 30th Symp. on Foundations of Computer Science, </booktitle> <pages> pp. 364-375, </pages> <month> October </month> <year> 1989. </year>
Reference: [BKP] <author> J. Bar-Ilan, G. Kortsarz and D. Peleg, </author> <title> How to Allocate Network Centers, </title> <journal> J. of Algorithms, </journal> <volume> Vol. 15, </volume> <year> (1993), </year> <pages> 385-415. </pages>
Reference-contexts: Likewise, such sets are useful for efficient selection of network centers for server placement, where it is desired to ensure that each node in the network is sufficiently close to some server (cf. <ref> [BKP] </ref>). One application that we describe in detail in the paper concerns speeding up an algorithm for constructing a Minimum Spanning Tree (MST). Note that, informally speaking, MST can be thought of as a more "global" problem, as opposed to the k-Dominating Set problem which is more "local" in nature.
Reference: [CT] <author> F. Chin and H. F. Ting, </author> <title> An Almost Linear Time and O(n log(n) + e) Messages Distributed Algorithm for Minimum-Weight Spanning Trees, </title> <booktitle> 26th Symp. on Foundations of Computer Science, </booktitle> <month> Oct. </month> <year> 1985, </year> <pages> pages 257-266. </pages>
Reference-contexts: Finally, in 3.2.3 we show how to improve the running time by a factor of log k, using an idea similar to those used before e.g. in <ref> [AG, G, CT, A2, JM] </ref>. 3.2.1 Constructing a (k + 1; O (k 2 )) spanning forest The algorithm DOM Partition 1 (k) described in Figure 5 for constructing this partition operates on a tree T via repetitive applications of Procedure Balanced DOM. <p> In the next subsection we give a more precise description of Procedure Simple MST, resulting in an improved time complexity of O (k), again using an idea similar to <ref> [AG, G, CT, A2, JM] </ref>. 4.3 Procedure Simple MST The (synchronous) algorithm operates in phases 1; 2; ::: log k+ 1, where phase i lasts exactly 5 2 i + 2 time units.
Reference: [CGS] <author> E.J. Cockayne, B. Gamble and B. Shepherd, </author> <title> An Upper Bound for the k-Domination Number of a Graph, </title> <journal> J. of Graph Theory, </journal> <volume> Vol. 9, </volume> <year> (1985), </year> <pages> 533-534. </pages>
Reference-contexts: G is a subset D of vertices with the property that for every v 2 V there is some u 2 D such that dist (u; v) k. (This definition is identi cal to that of [CN, PU] for example, but differs from other previous usages of this notion, e.g., <ref> [CGS] </ref>.) For every such k-dominating set we shall define a partition P of the nodes, by associating with each node v 2 V a dominator D (v) 2 D, which is the node closest to v in the dominating set (breaking ties arbitrarily).
Reference: [CN] <author> G.J. Chang and G.L. Nemhauser, </author> <title> The k-Domination and k-Stability Problems on Sun-Free Chordal Graphs, </title> <journal> SIAM J. Alg. & Disc. Meth. </journal> <volume> Vol. 5, </volume> <year> (1984), </year> <pages> 332-345. </pages>
Reference-contexts: A k-dominating set for a graph G is a subset D of vertices with the property that for every v 2 V there is some u 2 D such that dist (u; v) k. (This definition is identi cal to that of <ref> [CN, PU] </ref> for example, but differs from other previous usages of this notion, e.g., [CGS].) For every such k-dominating set we shall define a partition P of the nodes, by associating with each node v 2 V a dominator D (v) 2 D, which is the node closest to v in
Reference: [G] <author> E. Gafni, </author> <title> Improvements in the time complexity of two message-optimal election algorithms, </title> <booktitle> Proc. 4th Symp. on Principles of Distributed Computing, </booktitle> <pages> pp. 175-185, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: Finally, in 3.2.3 we show how to improve the running time by a factor of log k, using an idea similar to those used before e.g. in <ref> [AG, G, CT, A2, JM] </ref>. 3.2.1 Constructing a (k + 1; O (k 2 )) spanning forest The algorithm DOM Partition 1 (k) described in Figure 5 for constructing this partition operates on a tree T via repetitive applications of Procedure Balanced DOM. <p> This procedure is basically a simplified version of the algorithms of <ref> [GHS, A2, G] </ref>. <p> In the next subsection we give a more precise description of Procedure Simple MST, resulting in an improved time complexity of O (k), again using an idea similar to <ref> [AG, G, CT, A2, JM] </ref>. 4.3 Procedure Simple MST The (synchronous) algorithm operates in phases 1; 2; ::: log k+ 1, where phase i lasts exactly 5 2 i + 2 time units.
Reference: [GHS] <author> R. Gallager, P. Humblet and P. Spira, </author> <title> A distributed algorithm for minimum-weight spanning trees, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 5 (1), </volume> <year> (1983), </year> <pages> 66-77. </pages>
Reference-contexts: The algorithm presented in [GKP] has time complexity O (n :614 + Diam), hence it is neighborhood optimal for the case that Diam &gt; n :614 . Previous MST algorithms had running time O (n log n) <ref> [GHS] </ref>, O (n log fl n)[CT, G], and O (n) [A2]. Using the fast k Dominating Set algorithm we manage to present an improved MST construction algorithm whose time complexity is O ( p n log fl n+Diam (G)). <p> We will also make the assumption that edge weights are polynomial in n, so an edge weight can be sent in a single message. (This assumption is required for the time analysis of the previous algorithms that use edge weights or nodes identity, e.g. <ref> [GHS, A2, GKP] </ref>.) Let us now define the Minimum Spanning Tree task solved later on as an application of the k Dominating Set algorithm. <p> This procedure is basically a simplified version of the algorithms of <ref> [GHS, A2, G] </ref>. <p> Algorithms using similar ideas have appeared in the literature also in different contexts (cf. [JM]). 4.2 A High Level description The high level description of the Simple MST procedure we use here is similar to the algorithms of <ref> [GHS, A2] </ref>, and the differences concern mainly the termination rule and some implementation details 1 . Nodes group themselves into fragments of increasing size. Initially, all nodes are in singleton fragments. <p> Moreover, each tree of this forest is a fragment of the MST of the graph. Proof: The proof is just a simplified version of the proofs of the previous algorithms, e.g. <ref> [GHS, A2] </ref>. The lower bound of k + 1 on the size of fragments can be proved inductively, arguing that after phase i, every fragment is of size at least 2 i .
Reference: [GKP] <author> J. Garay, S. Kutten and D. Peleg, </author> <title> A Sub-Linear Time Distributed Algorithm for Minimum-Weight Spanning Trees, </title> <booktitle> 34th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 659-668, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: A question raised in <ref> [GKP] </ref> is whether the MST problem can be solved in O (Diam) time, where Diam is the network diameter. Clearly R (M ST ) = Diam in certain graphs. Thus in terms of the definition above one can rephrase the question of [GKP]: "does there exist a neighborhood optimal algorithm for <p> A question raised in <ref> [GKP] </ref> is whether the MST problem can be solved in O (Diam) time, where Diam is the network diameter. Clearly R (M ST ) = Diam in certain graphs. Thus in terms of the definition above one can rephrase the question of [GKP]: "does there exist a neighborhood optimal algorithm for MST". The algorithm presented in [GKP] has time complexity O (n :614 + Diam), hence it is neighborhood optimal for the case that Diam &gt; n :614 . <p> Clearly R (M ST ) = Diam in certain graphs. Thus in terms of the definition above one can rephrase the question of <ref> [GKP] </ref>: "does there exist a neighborhood optimal algorithm for MST". The algorithm presented in [GKP] has time complexity O (n :614 + Diam), hence it is neighborhood optimal for the case that Diam &gt; n :614 . Previous MST algorithms had running time O (n log n) [GHS], O (n log fl n)[CT, G], and O (n) [A2]. <p> Thus the MST algorithm is now neighborhood optimal for all graphs with Diam &gt; n 1=2 log fl n. Let us hint about how the improved MST algorithm was obtained. As noted in <ref> [GKP] </ref>, the main obstacle for improving the time complexity is the congestion caused by the need to send the description of many edges. To (partially) overcome the congestion, the solution presented in [GKP] used several techniques to reduce the amount of information sent by combining it. <p> Let us hint about how the improved MST algorithm was obtained. As noted in <ref> [GKP] </ref>, the main obstacle for improving the time complexity is the congestion caused by the need to send the description of many edges. To (partially) overcome the congestion, the solution presented in [GKP] used several techniques to reduce the amount of information sent by combining it. One such technique was clustering, since the construction of a cluster can be relatively local (thus consuming little time). <p> One such technique was clustering, since the construction of a cluster can be relatively local (thus consuming little time). The idea was that the cluster can represent many edges and nodes, thus reducing the amount of information to be sent. To improve the results of <ref> [GKP] </ref> we essentially replace the clustering technique used there by the clustering constructed by the k Dominating Set algorithm. Another result presented in this paper is a new efficient pipelining technique, also aimed at overcoming congestion. This technique is motivated by the following complication in the solution of [GKP]. <p> results of <ref> [GKP] </ref> we essentially replace the clustering technique used there by the clustering constructed by the k Dominating Set algorithm. Another result presented in this paper is a new efficient pipelining technique, also aimed at overcoming congestion. This technique is motivated by the following complication in the solution of [GKP]. At a certain point in that algorithm, a center is informed about edges in the graph (those that connect clusters). Since there are "too many such edges", the algorithm of [GKP] employs a rather complex method for eliminating short cycles, and thus reducing the number of remaining edges. <p> This technique is motivated by the following complication in the solution of <ref> [GKP] </ref>. At a certain point in that algorithm, a center is informed about edges in the graph (those that connect clusters). Since there are "too many such edges", the algorithm of [GKP] employs a rather complex method for eliminating short cycles, and thus reducing the number of remaining edges. Instead, we use the new pipelining technique, which is very simple; the main novelty is in its analysis. As in [GKP], nodes on a tree forward the description of many edges to their <p> Since there are "too many such edges", the algorithm of <ref> [GKP] </ref> employs a rather complex method for eliminating short cycles, and thus reducing the number of remaining edges. Instead, we use the new pipelining technique, which is very simple; the main novelty is in its analysis. As in [GKP], nodes on a tree forward the description of many edges to their parents on the tree, so that eventually the description reaches the tree root. However, here a node avoids forwarding the description of cycle heavy edges. <p> Thus it seems that the convergecast may not be pipelined, and hence may take a long time. We prove that this simple convergecast is fully pipelined, and thus its running time is the one required, eliminating the need of the complex cycle elimination stage in <ref> [GKP] </ref>. This pipelining proof may be of interest in itself. 1.2 Model and Definitions We focus on the problem of devising a time efficient algorithm to construct a small k Dominating Set. <p> We will also make the assumption that edge weights are polynomial in n, so an edge weight can be sent in a single message. (This assumption is required for the time analysis of the previous algorithms that use edge weights or nodes identity, e.g. <ref> [GHS, A2, GKP] </ref>.) Let us now define the Minimum Spanning Tree task solved later on as an application of the k Dominating Set algorithm. <p> Algorithm Balanced DOM is a variant of the dominating set algorithm Small-Dom-Set in <ref> [GKP] </ref>. That algorithm computed an ordinary (not necessarily balanced) dominating set on a given tree, namely, a set satisfying properties (a) and (b) above, but not property (c). Algorithm Small-Dom-Set made use of an MIS procedure as a black box. Specifically, it used the deterministic distributed MIS algorithm of [PS]. <p> Thus the following can be said about Small-Dom-Set, preparing to use it in Algorithm Balanced DOM: Lemma 3.2 <ref> [GKP] </ref> There exists a distributed procedure Small-Dom-Set that, applied in a given n-vertex tree T for n 2, computes (in a synchronous manner) a dominating set D of size at most dn=2e using O (log n)-bit messages, and its time complexity is O (log fl n). <p> Furthermore, the output of the procedure has the property that each node in D has some neighbor outside D. The property described in the last statement of the lemma is not argued in <ref> [GKP] </ref>, but can easily be shown to hold. Note that even with these changes, Algorithm Small-Dom-Set does not guarantee property (c). <p> To see this, let us examine the status of v in the original partition produced on step (1). First we exclude the possibility that v has joined 1. Perform Algorithm Small-Dom-Set of <ref> [GKP] </ref> on the tree T . Let D and P be the output domi nating set and partition. 2. For every singleton fvg in P , v quits the set D, and selects an arbitrary neighbor u =2 D as its dominator, D (v) = u. 3.
Reference: [GPS] <author> A. V. Goldberg, S. Plotkin, and G. Shannon, </author> <title> Parallel symmetry breaking in sparse graphs, </title> <booktitle> Proc. 19th ACM Symp. on Theory of Computing, </booktitle> <year> 1987. </year>
Reference-contexts: Specifically, it used the deterministic distributed MIS algorithm of [PS]. Since Algorithm Small-Dom-Set uses the MIS procedure only for computing MIS on a tree, it is possible to replace the procedure of [PS] with the faster procedure of <ref> [GPS] </ref> (which computes an MIS on an n-vertex tree in time O (log fl n)).
Reference: [JM] <author> D.B. Johnson and P. Metaxas, </author> <title> Connected com ponents in O(lg 3=2 jV j) parallel time for the CREW PRAM, </title> <booktitle> Proc. 32nd IEEE Symp. on Foundations of Computer Science, </booktitle> <month> October </month> <year> 1991, </year> <pages> 688-697. </pages>
Reference-contexts: Finally, in 3.2.3 we show how to improve the running time by a factor of log k, using an idea similar to those used before e.g. in <ref> [AG, G, CT, A2, JM] </ref>. 3.2.1 Constructing a (k + 1; O (k 2 )) spanning forest The algorithm DOM Partition 1 (k) described in Figure 5 for constructing this partition operates on a tree T via repetitive applications of Procedure Balanced DOM. <p> Algorithms using similar ideas have appeared in the literature also in different contexts (cf. <ref> [JM] </ref>). 4.2 A High Level description The high level description of the Simple MST procedure we use here is similar to the algorithms of [GHS, A2], and the differences concern mainly the termination rule and some implementation details 1 . Nodes group themselves into fragments of increasing size. <p> In the next subsection we give a more precise description of Procedure Simple MST, resulting in an improved time complexity of O (k), again using an idea similar to <ref> [AG, G, CT, A2, JM] </ref>. 4.3 Procedure Simple MST The (synchronous) algorithm operates in phases 1; 2; ::: log k+ 1, where phase i lasts exactly 5 2 i + 2 time units.
Reference: [L] <author> N. Linial, </author> <title> Distributive graph algorithms global solutions from local data, </title> <booktitle> Proc. 28th IEEE Symp. on Foundations of Computer Science, </booktitle> <month> October </month> <year> 1987, </year> <pages> pp. 331-335. </pages>
Reference-contexts: Note that, informally speaking, MST can be thought of as a more "global" problem, as opposed to the k-Dominating Set problem which is more "local" in nature. We now present a formal notion of what we mean by a "fast" algorithm, which applies to both. Linial <ref> [L] </ref> proved lower bounds on the time complexity of distributed algorithms, even when assuming a very strong computational model (not assumed here) where messages can be of arbitrary length. Yet sending a message to a distance d still takes time d in this model. Thus the lower bounds of [L] actually <p> Linial <ref> [L] </ref> proved lower bounds on the time complexity of distributed algorithms, even when assuming a very strong computational model (not assumed here) where messages can be of arbitrary length. Yet sending a message to a distance d still takes time d in this model. Thus the lower bounds of [L] actually correspond only to the radius (around each node) from which information must be fetched in order to solve a given problem P . Let this radius be R (P ) for a given problem P . <p> of our choice; for example, we can use the simple synchronizer ff of [A1] whose cost in an asynchronous network is one message over each edge in each direction per round of the synchronous algorithm.) Still, we shall not adopt the extreme model employed in previous studies of locality issues <ref> [L] </ref>, in which messages of arbitrary size are allowed to be transmitted in a single time unit, since in this model the refined distinctions we focus on here disappear.
Reference: [P] <author> D. Peleg, </author> <title> Time-optimal leader election in general networks, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 8, </volume> <year> (1990), </year> <pages> 96-99. </pages>
Reference: [P2] <author> D. Peleg, </author> <title> Distributed Data Structures: A Complexity Oriented View, </title> <booktitle> Proc. 4th Int. Workshop on Distributed Algorithms, </booktitle> <address> Bari, Italy, </address> <month> Sept. </month> <year> 1990, </year> <pages> 71-89. </pages>
Reference-contexts: Hence the new construction can serve to speed up the preprocessing stage of that routing scheme. Efficient construction for k-dominating sets is also applicable in the context of distributed data structures <ref> [P2] </ref>, where it is proposed that a set of k-dominating centers can be selected for locating copies of a distributed directory.
Reference: [PS] <author> A. Panconesi and A. Srinivasan, </author> <title> Improved distributed algorithms for coloring and network decomposition problems, </title> <booktitle> Proc. 33rd Symp. on Theory of Computing, </booktitle> <year> 1992, </year> <pages> 581-592. </pages>
Reference-contexts: That algorithm computed an ordinary (not necessarily balanced) dominating set on a given tree, namely, a set satisfying properties (a) and (b) above, but not property (c). Algorithm Small-Dom-Set made use of an MIS procedure as a black box. Specifically, it used the deterministic distributed MIS algorithm of <ref> [PS] </ref>. Since Algorithm Small-Dom-Set uses the MIS procedure only for computing MIS on a tree, it is possible to replace the procedure of [PS] with the faster procedure of [GPS] (which computes an MIS on an n-vertex tree in time O (log fl n)). <p> Algorithm Small-Dom-Set made use of an MIS procedure as a black box. Specifically, it used the deterministic distributed MIS algorithm of <ref> [PS] </ref>. Since Algorithm Small-Dom-Set uses the MIS procedure only for computing MIS on a tree, it is possible to replace the procedure of [PS] with the faster procedure of [GPS] (which computes an MIS on an n-vertex tree in time O (log fl n)).
Reference: [PU] <author> D. Peleg and E. Upfal, </author> <title> A tradeoff between size and efficiency for routing tables, </title> <journal> J. of the ACM, </journal> <volume> Vol. 36, </volume> <year> (1989), </year> <pages> 510-530. </pages>
Reference-contexts: The time complexity of the algorithm is O (k log fl n). This new algorithm is useful for speeding up a number of distributed tasks. For example, this type of clusters was used in <ref> [PU] </ref> in the context of routing with sparse routing tables, although no distributed protocol was given there for computing them. Hence the new construction can serve to speed up the preprocessing stage of that routing scheme. <p> A k-dominating set for a graph G is a subset D of vertices with the property that for every v 2 V there is some u 2 D such that dist (u; v) k. (This definition is identi cal to that of <ref> [CN, PU] </ref> for example, but differs from other previous usages of this notion, e.g., [CGS].) For every such k-dominating set we shall define a partition P of the nodes, by associating with each node v 2 V a dominator D (v) 2 D, which is the node closest to v in <p> In the next section we give a fast algorithm for computing a k-dominating set on an n-node tree T in time O (k log fl n). In the following section we extend the result to a general graph. 2.1 Existence of Small k-Dominating Sets The following is well-known (cf. <ref> [PU] </ref>). Lemma 2.1 For every connected graph G of n vertices and for every k 1 there exists a k-dominating set D such that jDj maxf1; b n k+1 cg. <p> To motivate the distributed algorithm developed for the k-dominating set problem in Subsection 2.2, let us overview the (standard) proof outlined for the above lemma in <ref> [PU] </ref>. Let T be an arbitrary rooted spanning tree for G and denote its depth (the distance from the root) by h. If k h then D may consist of the root alone.
Reference: [T] <author> R.E. Tarjan, </author> <title> Data Structures and Network Algorithms, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1983. </year>
Reference-contexts: Proof: The fact that the resulting tree is an MST follows from the fact that the trees constructed in the first stage were fragments of the MST, and from the correctness of the "red rule" employed for edge elimination in the procedure (cf. <ref> [T] </ref>, p. 71). (Essentially the red rule says the an edge that is the heaviest on any cycle is not a part of any MST.) As for the running time, the bound is derived from the following facts.
References-found: 21

