URL: http://www.cs.pitt.edu/~suew/rabinovich1.ps
Refering-URL: http://www.cs.pitt.edu/~suew/dbwshop2.html
Root-URL: 
Email: jag@research.att.com  mumick@savera.com  misha@research.att.com  
Title: Asynchronous Version Advancement in a Distributed Three Version Database proposed protocol is valuable in large
Author: H. V. Jagadish Inderpal Singh Mumick Michael Rabinovich 
Note: The  
Affiliation: AT&T Laboratories  Savera Systems  AT&T Laboratories  
Abstract: We present an efficient protocol for multi-version concur-rency control in distributed databases. The protocol creates no more than three versions of any data item, while guaranteeing that (1) update transactions never interfere with read-only transactions, (2) the version advancement mechanism is completely asynchronous with (both update and read-only) user transactions, and (3) read-only transactions do not acquire locks and do not write control information into the data items being read. This is an improvement over existing multi-versioning schemes for distributed databases, which either require a potentially unlimited number of versions, or require coordination between version advancement and user transactions. Our protocol can be applied in a centralized system also, where the improvement over existing techniques is in reducing the number of versions from four to three. 
Abstract-found: 1
Intro-found: 1
Reference: [AS89] <author> D. Agrawal and S. Sengupta. </author> <title> Modular synchronization in multiversion databases: Version control and concurrency control. </title> <booktitle> ACM SIGMOD Conf. on the Management of Data, </booktitle> <pages> pages 408417, </pages> <year> 1989. </year>
Reference-contexts: 1. Introduction Databases often maintain multiple versions of data to avoid interference between read-only queries and update transactions. Many multi-versioning concurrency control protocols have been proposed, both for centralized and distributed databases (see, e.g., <ref> [SR81, BHR80, CG85, Wei87, CFL + 82, MPL92, AS89, BC92] </ref>). <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of <ref> [CFL + 82, AS89, WYC91, BC92, MPL92] </ref> address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of [CFL + 82, AS89, WYC91, BC92, MPL92] address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. Techniques suggested in <ref> [CFL + 82, CG85, AS89, BC92] </ref> achieve the non-interference requirement at 4 While [MPL92] contains the extension to distributed case, version advancement in the distributed case can interfere with and cause aborts of user transactions. the cost of potentially unlimited number of versions, while our AVA3 protocol creates at most three <p> Generalizing this scheme to a distributed database appears difficult because all servers would have to have a consistent global view on the slice conflict graph. <ref> [AS89] </ref> separates concerns of version control and con-currency control, by implementing the versioning mechanism in such a way that it can be used in conjunction with any concurrency control algorithm. Our protocol is predicated on the use of two-phase locking.
Reference: [BC92] <author> P. Bober and M. Carey. </author> <title> On mixing queries and transactions via multiversion locking. </title> <booktitle> In Proc. 8th IEEE Intl.Conf. on Data Engineering, </booktitle> <pages> pages 535 545, </pages> <year> 1992. </year>
Reference-contexts: 1. Introduction Databases often maintain multiple versions of data to avoid interference between read-only queries and update transactions. Many multi-versioning concurrency control protocols have been proposed, both for centralized and distributed databases (see, e.g., <ref> [SR81, BHR80, CG85, Wei87, CFL + 82, MPL92, AS89, BC92] </ref>). <p> Existing techniques that satisfy the non-interference requirement fall into two categories. Techniques belonging to the first category (see <ref> [CFL + 82, BC92] </ref> for centralized schemes and [CG85] for a distributed scheme) may create a potentially unlimited number of data versions due to a long-running read transaction. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of <ref> [CFL + 82, AS89, WYC91, BC92, MPL92] </ref> address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of [CFL + 82, AS89, WYC91, BC92, MPL92] address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. Techniques suggested in <ref> [CFL + 82, CG85, AS89, BC92] </ref> achieve the non-interference requirement at 4 While [MPL92] contains the extension to distributed case, version advancement in the distributed case can interfere with and cause aborts of user transactions. the cost of potentially unlimited number of versions, while our AVA3 protocol creates at most three <p> Whether our idea can be used in conjunction with other concurrency control protocols remains a question for future work. For the centralized case, the protocols of [WYC91, MPL92] requires up to four versions of data to guarantee non-interference of version advancement and user transactions, and the algorithm of <ref> [BC92] </ref> can be configured to require at most four versions (with the view sharing idea of Section 2.3 in [BC92]). Our AVA3 protocol in the centralized case reduces to a scheme that needs at most three versions to guarantee non-interference. <p> For the centralized case, the protocols of [WYC91, MPL92] requires up to four versions of data to guarantee non-interference of version advancement and user transactions, and the algorithm of <ref> [BC92] </ref> can be configured to require at most four versions (with the view sharing idea of Section 2.3 in [BC92]). Our AVA3 protocol in the centralized case reduces to a scheme that needs at most three versions to guarantee non-interference. On the other hand, in these protocols, read transactions that start immediately after version advancement always access the latest committed data, and then start falling behind.
Reference: [BHG87] <author> P.A. Bernstein, V. Hadzilacos, and N. Goodman. </author> <title> Concurrency Control and Recovery in Database Systems. </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: The actions performed by moveToFuture depend on the log and recovery scheme used. If any of the no-undo (otherwise known as no-steal) schemes <ref> [BHG87] </ref> are employed, the only action required of moveToFuture is to update the current version number of the subtransaction: V (T i ) = newV. <p> Such schemes have even been implemented in products, going back to Prime Computer's CODASYL system and Digital's Rdb/VMS. The general serializability theory for multiversion concurrency control with unlimited number of versions is described in <ref> [BHG87] </ref>. The theory for the case of a limited number of versions was developed in [Mor93]. The algorithms of [BHR80, SR81] never keep more than two versions of data, compared to our three versions.
Reference: [BHR80] <author> R. Bayer, H. Heller, and A. Reiser. </author> <title> Parallelism and recovery in database systems. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 5(2):139156, </volume> <month> June </month> <year> 1980. </year>
Reference-contexts: 1. Introduction Databases often maintain multiple versions of data to avoid interference between read-only queries and update transactions. Many multi-versioning concurrency control protocols have been proposed, both for centralized and distributed databases (see, e.g., <ref> [SR81, BHR80, CG85, Wei87, CFL + 82, MPL92, AS89, BC92] </ref>). <p> At the same time, while read-only queries should not fall too far behind the updates, it is not critical that the queries read the latest committed data. This non-interference requirement eliminates from consideration many protocols, like the two-version protocols of <ref> [BHR80, SR81] </ref> where interference between read and update transactions is still possible, and the protocol of [Wei87] that requires read transactions to write read timestamps to data items they access. Existing techniques that satisfy the non-interference requirement fall into two categories. <p> Finally, our protocol is extremely simple and lightweight. It does not require maintaining and manipulating the completed transaction lists as in [CG85], or lists of update transactions that accumulated since last version advancement as in [MPL92], or a transaction dependency graph of <ref> [BHR80] </ref>. Instead, our protocol maintains only a few integers per node and two integers per transaction, in addition to standard data structures for accessing data in de-sired versions. Our protocol achieves these results at the expense of allowing read transactions to access a stale snapshot of the data. <p> The general serializability theory for multiversion concurrency control with unlimited number of versions is described in [BHG87]. The theory for the case of a limited number of versions was developed in [Mor93]. The algorithms of <ref> [BHR80, SR81] </ref> never keep more than two versions of data, compared to our three versions. However, in [BHR80], a read-only query may delay the commitment of an update transaction, an update transaction may be aborted because of the versioning mechanism, and read-only queries incur overhead of obtaining read locks. <p> The theory for the case of a limited number of versions was developed in [Mor93]. The algorithms of [BHR80, SR81] never keep more than two versions of data, compared to our three versions. However, in <ref> [BHR80] </ref>, a read-only query may delay the commitment of an update transaction, an update transaction may be aborted because of the versioning mechanism, and read-only queries incur overhead of obtaining read locks. The algorithm of [SR81] may, in addition, also delay or abort queries.
Reference: [BPR + 96] <author> Phillip Bohannon, J. Parker, Rajeev Rastogi, S. Se-shadri, Avi Silberschatz, and S. Sudarshan. </author> <title> Distributed multi-level recovery in main memory databases. </title> <booktitle> In Proc. 4th Int. Conf. on Parallel and Distributed Information Systems (PDIS), </booktitle> <year> 1996. </year>
Reference-contexts: final version number of T i is included in the commit log record to ensure that, during recovery, T i 's log records are applied to the proper version. 1 V (T i ) can be less than V (T ) by at most 1 In the recovery scheme of <ref> [BPR + 96] </ref>, active (noncommitted) transactions are allowed to modify the database pages. However, the scheme ensures that, except during checkpoints, all modified pages as well as all undo log records of un-committed transactions remain in main memory. <p> Thus, copying into the new version will not overwrite updates of other transactions. The implementation of moveToFuture is similar for other redo/undo recovery schemes, such as Aries [MHL + 92]. However, without special optimizations to logging along the lines of <ref> [BPR + 96] </ref>, moveToFuture within Aries is more likely to involve disk accesses. Therefore, in situations where version advancement is executed frequently, the scheme of [BPR + 96] or no-undo schemes should be used. 5. <p> However, without special optimizations to logging along the lines of <ref> [BPR + 96] </ref>, moveToFuture within Aries is more likely to involve disk accesses. Therefore, in situations where version advancement is executed frequently, the scheme of [BPR + 96] or no-undo schemes should be used. 5. Example Execution Consider a distributed database with three sites i, j, and k, with data items w at i, x and y at j, and z at k. <p> We use T i to denote a subtransaction of transaction T at node i. 2 We can further reduce the likelihood of disk accesses during moveTo-Future by coordinating checkpoint and version advancement operations, so that they are not done at the same time. Given that checkpoints of <ref> [BPR + 96] </ref> do not interfere with user transactions, such coordination does not introduce any hidden synchronization between version advancement and user transactions.
Reference: [CFL + 82] <author> A. Chan, S. Fox, W-T.K. Lin, A. Nori, and D.R. Ries. </author> <title> The implementation of an integrated concur-rency control and recovery scheme. </title> <booktitle> In ACM SIG-MOD Conf. on the Management of Data, </booktitle> <pages> pages 184 191, </pages> <year> 1982. </year>
Reference-contexts: 1. Introduction Databases often maintain multiple versions of data to avoid interference between read-only queries and update transactions. Many multi-versioning concurrency control protocols have been proposed, both for centralized and distributed databases (see, e.g., <ref> [SR81, BHR80, CG85, Wei87, CFL + 82, MPL92, AS89, BC92] </ref>). <p> Existing techniques that satisfy the non-interference requirement fall into two categories. Techniques belonging to the first category (see <ref> [CFL + 82, BC92] </ref> for centralized schemes and [CG85] for a distributed scheme) may create a potentially unlimited number of data versions due to a long-running read transaction. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of <ref> [CFL + 82, AS89, WYC91, BC92, MPL92] </ref> address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of [CFL + 82, AS89, WYC91, BC92, MPL92] address the centralized database, 4 while [CG85] extends <ref> [CFL + 82] </ref> for the distributed case. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of [CFL + 82, AS89, WYC91, BC92, MPL92] address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. Techniques suggested in <ref> [CFL + 82, CG85, AS89, BC92] </ref> achieve the non-interference requirement at 4 While [MPL92] contains the extension to distributed case, version advancement in the distributed case can interfere with and cause aborts of user transactions. the cost of potentially unlimited number of versions, while our AVA3 protocol creates at most three
Reference: [CG85] <author> A. Chan and R. Gray. </author> <title> Implementing distributed read-only transactions. </title> <journal> IEEE Transactions on Software Engineering., </journal> <volume> 11(2):205212, </volume> <month> February </month> <year> 1985. </year>
Reference-contexts: 1. Introduction Databases often maintain multiple versions of data to avoid interference between read-only queries and update transactions. Many multi-versioning concurrency control protocols have been proposed, both for centralized and distributed databases (see, e.g., <ref> [SR81, BHR80, CG85, Wei87, CFL + 82, MPL92, AS89, BC92] </ref>). <p> Existing techniques that satisfy the non-interference requirement fall into two categories. Techniques belonging to the first category (see [CFL + 82, BC92] for centralized schemes and <ref> [CG85] </ref> for a distributed scheme) may create a potentially unlimited number of data versions due to a long-running read transaction. Read transactions incur the overhead of following a potentially unlimited chain of pointers to data versions to determine the version they can use. Moreover, in the distributed case [CG85], they have <p> schemes and <ref> [CG85] </ref> for a distributed scheme) may create a potentially unlimited number of data versions due to a long-running read transaction. Read transactions incur the overhead of following a potentially unlimited chain of pointers to data versions to determine the version they can use. Moreover, in the distributed case [CG85], they have to know in advance the set of sites they will visit. Techniques in the second category [MPL92, WYC91] introduce a separate version advancement procedure to move from one version to another, and require four versions to satisfy the non-interference requirement in a centralized database. <p> Finally, our protocol is extremely simple and lightweight. It does not require maintaining and manipulating the completed transaction lists as in <ref> [CG85] </ref>, or lists of update transactions that accumulated since last version advancement as in [MPL92], or a transaction dependency graph of [BHR80]. Instead, our protocol maintains only a few integers per node and two integers per transaction, in addition to standard data structures for accessing data in de-sired versions. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of [CFL + 82, AS89, WYC91, BC92, MPL92] address the centralized database, 4 while <ref> [CG85] </ref> extends [CFL + 82] for the distributed case. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of [CFL + 82, AS89, WYC91, BC92, MPL92] address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. Techniques suggested in <ref> [CFL + 82, CG85, AS89, BC92] </ref> achieve the non-interference requirement at 4 While [MPL92] contains the extension to distributed case, version advancement in the distributed case can interfere with and cause aborts of user transactions. the cost of potentially unlimited number of versions, while our AVA3 protocol creates at most three <p> On the other hand, a read transaction in these protocols always reads the latest version written by an update transaction with an earlier timestamp. In our AVA3 protocol, read transactions access increasingly obsolete data until the next version advancement occurs. Similar to AVA3 , protocols of <ref> [Wei87, CG85] </ref> modify the commit protocol of update transactions so that participating sites piggyback some information on their prepare messages. In [Wei87], this information includes timestamps of all accessed data items and is used to let the transaction coordinator choose a unique timestamp that is greater than all those timestamps. <p> In [Wei87], this information includes timestamps of all accessed data items and is used to let the transaction coordinator choose a unique timestamp that is greater than all those timestamps. This new timestamp is then sent to participants in the commit message and assigned to the accessed objects. In <ref> [CG85] </ref>, prepare messages carry local committed transaction lists, which are lists of transactions known to the participants to have committed. They are used by the coordinator to compute and distribute to the participants a new list, that includes transactions in all those lists.
Reference: [GO96] <author> S. Gukal and E. Omiecinski. </author> <title> Transient versioning for consistency and concurrency in client-serer systems. </title> <booktitle> In Proc. 4th IEEE Int. Conf on Parallel and Distributed Information Systems, </booktitle> <pages> pages 274285, </pages> <year> 1996. </year>
Reference-contexts: Upon detecting a mis-match, a participant moves the subtransaction into the version received with the commit message by means of moveToFuture function, and then commits. <ref> [GO96] </ref> proposes an interesting scheme to use old versions cached at the clients as different version of the data. Transactions choose slices in which to execute. A slice is a mutually consistent subset of pages in the database.
Reference: [JMR97a] <author> H. V. Jagadish, I. S. Mumick, and M. Rabi-novich. </author> <title> Asynchronous version advancement in a distributed three version database. </title> <type> Technical Report HA6177000-971201-02TM, </type> <institution> AT&T Laboratories, </institution> <month> December </month> <year> 1997. </year>
Reference-contexts: Properties and Correctness of the AVA3 Pro tocol The first theorem states correctness of the protocol, while the second establishes the non-interference property. See <ref> [JMR97a] </ref> for the proofs. Theorem 6.1 A schedule produced by the AVA3 protocol is equivalent to some serial schedule in which transactions are partially ordered by their version number, and within transactions of the same version number, the update transactions precede the read transactions.
Reference: [JMR97b] <author> H. V. Jagadish, I. S. Mumick, and M. Rabinovich. </author> <title> Scalable versioning in distributed databases with commuting updates. </title> <booktitle> In 13th IEEE Int. Conf. on Data Engineering, </booktitle> <pages> pages 520531, </pages> <year> 1997. </year>
Reference-contexts: Since read transactions are allowed to access out-of-date data anyway, this seems to be a small penalty for reducing the number of versions from four to three. Finally, the protocol of <ref> [JMR97b] </ref> targets the case when update transactions commute on individual nodes. For this workload, the protocol creates at most three versions of data and avoids any synchronization delays. <p> For this workload, the protocol creates at most three versions of data and avoids any synchronization delays. Our AVA3 protocol can also be applied to commuting updates, though it will lead to some updates becoming available for reads later than in the <ref> [JMR97b] </ref> protocol. 9. Conclusions The AVA3 protocol presented in this paper was motivated by several large distributed database applications within AT&T. These applications have continuous update streams and queries that need access to data.
Reference: [MHL + 92] <author> C. Mohan, D. Haderle, B. Lindsay, H. Pirahesh, and P. Schwartz. </author> <title> Aries: A transaction recovery method supporting fine-granularity locking and partial rollbacks using write-ahead logging. </title> <journal> ACM Transactions on Database Systems (TODS), </journal> <volume> 17(1):94162, </volume> <month> March </month> <year> 1992. </year>
Reference-contexts: In particular, it is guaranteed that none of these data items already exist in the new version due to another transaction. Thus, copying into the new version will not overwrite updates of other transactions. The implementation of moveToFuture is similar for other redo/undo recovery schemes, such as Aries <ref> [MHL + 92] </ref>. However, without special optimizations to logging along the lines of [BPR + 96], moveToFuture within Aries is more likely to involve disk accesses. Therefore, in situations where version advancement is executed frequently, the scheme of [BPR + 96] or no-undo schemes should be used. 5.
Reference: [MLO86] <author> C. Mohan, B Lindsay, and R. Obermarck. </author> <title> Transaction management in the R* distributed database management system. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 11(4):378396, </volume> <year> 1986. </year>
Reference-contexts: Query transactions do not obtain any locks, so they can read appropriate versions of a data item that is locked by an update transaction. The model of user transactions follows the R* system <ref> [MLO86] </ref>. An update transaction is submitted to one server first, which becomes the root of the transaction. It executes a root subtransaction and then sends children subtransac-tions to other nodes if necessary.
Reference: [Mor93] <author> T. Morzy. </author> <title> The correctness of concurrency control for multiversion database systems with limited number of versions. </title> <booktitle> In Proc. 9th IEEE Intl.Conf. on Data Engineering, </booktitle> <pages> pages 595604, </pages> <year> 1993. </year>
Reference-contexts: Such schemes have even been implemented in products, going back to Prime Computer's CODASYL system and Digital's Rdb/VMS. The general serializability theory for multiversion concurrency control with unlimited number of versions is described in [BHG87]. The theory for the case of a limited number of versions was developed in <ref> [Mor93] </ref>. The algorithms of [BHR80, SR81] never keep more than two versions of data, compared to our three versions.
Reference: [MPL92] <author> C. Mohan, H. Pirahesh, and R. Lorte. </author> <title> Efficient and flexible methods for transient versioning of records to avoid locking by read-only transactions. </title> <booktitle> In ACM SIGMOD Conf. on the Management of Data, </booktitle> <pages> pages 124133, </pages> <year> 1992. </year>
Reference-contexts: 1. Introduction Databases often maintain multiple versions of data to avoid interference between read-only queries and update transactions. Many multi-versioning concurrency control protocols have been proposed, both for centralized and distributed databases (see, e.g., <ref> [SR81, BHR80, CG85, Wei87, CFL + 82, MPL92, AS89, BC92] </ref>). <p> Read transactions incur the overhead of following a potentially unlimited chain of pointers to data versions to determine the version they can use. Moreover, in the distributed case [CG85], they have to know in advance the set of sites they will visit. Techniques in the second category <ref> [MPL92, WYC91] </ref> introduce a separate version advancement procedure to move from one version to another, and require four versions to satisfy the non-interference requirement in a centralized database. <p> Techniques in the second category [MPL92, WYC91] introduce a separate version advancement procedure to move from one version to another, and require four versions to satisfy the non-interference requirement in a centralized database. However, the extension to a distributed database discussed in <ref> [MPL92] </ref> requires version advancement to be coordinated with user operations: otherwise, autonomous version advancement may cause user operations to be aborted. Thus, the non-interference requirement is violated in the distributed case. <p> The read transactions are allowed to increment some main memory counters associated with the node using latches (no locks). For the centralized case (that is, when there is only one site) the AVA3 protocol reduces the number of versions needed to guarantee the non-interference requirement from four versions <ref> [MPL92, WYC91] </ref> to three versions. Finally, our protocol is extremely simple and lightweight. It does not require maintaining and manipulating the completed transaction lists as in [CG85], or lists of update transactions that accumulated since last version advancement as in [MPL92], or a transaction dependency graph of [BHR80]. <p> Finally, our protocol is extremely simple and lightweight. It does not require maintaining and manipulating the completed transaction lists as in [CG85], or lists of update transactions that accumulated since last version advancement as in <ref> [MPL92] </ref>, or a transaction dependency graph of [BHR80]. Instead, our protocol maintains only a few integers per node and two integers per transaction, in addition to standard data structures for accessing data in de-sired versions. <p> We assume that data structures and indices are built so that the following questions can be answered efficiently: (1) Does data item x exist in version v? and (2) What is the maximum existing version of x? Techniques to build such indices are discussed in <ref> [MPL92] </ref>. 3.1. Control State and Subroutines Control state: Each site i maintains the following three variables: * u i , an update version number. This is the version of data to be updated by any new update subtransaction at node i. * q i , a query version number. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of <ref> [CFL + 82, AS89, WYC91, BC92, MPL92] </ref> address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. <p> Algorithms of [CFL + 82, AS89, WYC91, BC92, MPL92] address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. Techniques suggested in [CFL + 82, CG85, AS89, BC92] achieve the non-interference requirement at 4 While <ref> [MPL92] </ref> contains the extension to distributed case, version advancement in the distributed case can interfere with and cause aborts of user transactions. the cost of potentially unlimited number of versions, while our AVA3 protocol creates at most three versions. <p> Our protocol is predicated on the use of two-phase locking. Whether our idea can be used in conjunction with other concurrency control protocols remains a question for future work. For the centralized case, the protocols of <ref> [WYC91, MPL92] </ref> requires up to four versions of data to guarantee non-interference of version advancement and user transactions, and the algorithm of [BC92] can be configured to require at most four versions (with the view sharing idea of Section 2.3 in [BC92]).
Reference: [SR81] <author> R.E. Stearns and D.J. Rosenkrantz. </author> <title> Distributed database concurrency controls using before-values. </title> <booktitle> In ACM SIGMOD Conf. on the Management of Data, </booktitle> <address> Ann Arbor., </address> <pages> pages 216223, </pages> <year> 1981. </year>
Reference-contexts: 1. Introduction Databases often maintain multiple versions of data to avoid interference between read-only queries and update transactions. Many multi-versioning concurrency control protocols have been proposed, both for centralized and distributed databases (see, e.g., <ref> [SR81, BHR80, CG85, Wei87, CFL + 82, MPL92, AS89, BC92] </ref>). <p> At the same time, while read-only queries should not fall too far behind the updates, it is not critical that the queries read the latest committed data. This non-interference requirement eliminates from consideration many protocols, like the two-version protocols of <ref> [BHR80, SR81] </ref> where interference between read and update transactions is still possible, and the protocol of [Wei87] that requires read transactions to write read timestamps to data items they access. Existing techniques that satisfy the non-interference requirement fall into two categories. <p> The general serializability theory for multiversion concurrency control with unlimited number of versions is described in [BHG87]. The theory for the case of a limited number of versions was developed in [Mor93]. The algorithms of <ref> [BHR80, SR81] </ref> never keep more than two versions of data, compared to our three versions. However, in [BHR80], a read-only query may delay the commitment of an update transaction, an update transaction may be aborted because of the versioning mechanism, and read-only queries incur overhead of obtaining read locks. <p> However, in [BHR80], a read-only query may delay the commitment of an update transaction, an update transaction may be aborted because of the versioning mechanism, and read-only queries incur overhead of obtaining read locks. The algorithm of <ref> [SR81] </ref> may, in addition, also delay or abort queries. The algorithm of [Wei87] require that read-only transactions write meta-information in the data items they read, and that update transactions write meta-information in all accessed data items at commit time. Thus, these techniques do not satisfy our non-interference requirements.
Reference: [Wei87] <author> William E. Weihl. </author> <title> Distributed version management for read-only actions. </title> <journal> IEEE Transactions on Software Engineering (SE), Vol.SE-13 ., SE-13(1):5564, </journal> <month> Jan-uary </month> <year> 1987. </year>
Reference-contexts: 1. Introduction Databases often maintain multiple versions of data to avoid interference between read-only queries and update transactions. Many multi-versioning concurrency control protocols have been proposed, both for centralized and distributed databases (see, e.g., <ref> [SR81, BHR80, CG85, Wei87, CFL + 82, MPL92, AS89, BC92] </ref>). <p> This non-interference requirement eliminates from consideration many protocols, like the two-version protocols of [BHR80, SR81] where interference between read and update transactions is still possible, and the protocol of <ref> [Wei87] </ref> that requires read transactions to write read timestamps to data items they access. Existing techniques that satisfy the non-interference requirement fall into two categories. <p> However, in [BHR80], a read-only query may delay the commitment of an update transaction, an update transaction may be aborted because of the versioning mechanism, and read-only queries incur overhead of obtaining read locks. The algorithm of [SR81] may, in addition, also delay or abort queries. The algorithm of <ref> [Wei87] </ref> require that read-only transactions write meta-information in the data items they read, and that update transactions write meta-information in all accessed data items at commit time. Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. <p> On the other hand, a read transaction in these protocols always reads the latest version written by an update transaction with an earlier timestamp. In our AVA3 protocol, read transactions access increasingly obsolete data until the next version advancement occurs. Similar to AVA3 , protocols of <ref> [Wei87, CG85] </ref> modify the commit protocol of update transactions so that participating sites piggyback some information on their prepare messages. In [Wei87], this information includes timestamps of all accessed data items and is used to let the transaction coordinator choose a unique timestamp that is greater than all those timestamps. <p> In our AVA3 protocol, read transactions access increasingly obsolete data until the next version advancement occurs. Similar to AVA3 , protocols of [Wei87, CG85] modify the commit protocol of update transactions so that participating sites piggyback some information on their prepare messages. In <ref> [Wei87] </ref>, this information includes timestamps of all accessed data items and is used to let the transaction coordinator choose a unique timestamp that is greater than all those timestamps. This new timestamp is then sent to participants in the commit message and assigned to the accessed objects.
Reference: [WYC91] <author> K. L. Wu, Philip S. Yu, and M. S. Chen. </author> <title> Dynamic, finite versioning for concurrent transaction and query processing. </title> <type> Technical Report RC 16633, </type> <institution> IBM T. J. Watson Research Center, </institution> <year> 1991. </year>
Reference-contexts: Read transactions incur the overhead of following a potentially unlimited chain of pointers to data versions to determine the version they can use. Moreover, in the distributed case [CG85], they have to know in advance the set of sites they will visit. Techniques in the second category <ref> [MPL92, WYC91] </ref> introduce a separate version advancement procedure to move from one version to another, and require four versions to satisfy the non-interference requirement in a centralized database. <p> The read transactions are allowed to increment some main memory counters associated with the node using latches (no locks). For the centralized case (that is, when there is only one site) the AVA3 protocol reduces the number of versions needed to guarantee the non-interference requirement from four versions <ref> [MPL92, WYC91] </ref> to three versions. Finally, our protocol is extremely simple and lightweight. It does not require maintaining and manipulating the completed transaction lists as in [CG85], or lists of update transactions that accumulated since last version advancement as in [MPL92], or a transaction dependency graph of [BHR80]. <p> Thus, these techniques do not satisfy our non-interference requirements. Several algorithms have been proposed that, like ours, satisfy the non-interference requirements. Algorithms of <ref> [CFL + 82, AS89, WYC91, BC92, MPL92] </ref> address the centralized database, 4 while [CG85] extends [CFL + 82] for the distributed case. <p> Our protocol is predicated on the use of two-phase locking. Whether our idea can be used in conjunction with other concurrency control protocols remains a question for future work. For the centralized case, the protocols of <ref> [WYC91, MPL92] </ref> requires up to four versions of data to guarantee non-interference of version advancement and user transactions, and the algorithm of [BC92] can be configured to require at most four versions (with the view sharing idea of Section 2.3 in [BC92]).
References-found: 17

