URL: http://www.ai.mit.edu/~mpf/homedir/files/limbo/Baggage/research.nj.nec.com/tr2.ps
Refering-URL: 
Root-URL: 
Email: sjsmith@cs.umd.edu  nau@cs.umd.edu  
Title: Strategic Planning for Imperfect-Information Games  
Author: Stephen J. J. Smith Dana S. Nau Dana S. Nau, 
Note: Address correspondence to  This work supported in part by an AT&T Ph.D. scholarship to Stephen J. J. Smith, Maryland Industrial Partnerships (MIPS) grant 501.15, Great Game Products, and NSF grants IRI-8907890 and NSFD CDR-88003012.  
Date: June 30, 1993  
Address: College Park, MD 20740  College Park, MD 20740  College Park, MD 20742.  
Affiliation: Computer Science Department University of Maryland  Institute for Advanced Computer Studies, Computer Science Department, and Institute for Systems Research University of Maryland  Computer Science Dept., University of Maryland,  
Abstract: Although game-tree search works well in perfect-information games, there are problems in trying to use it for imperfect-information games such as bridge. The lack of knowledge about the opponents' possible moves gives the game tree a very large branching factor, making the tree so immense that game-tree searching is infeasible. In this paper, we describe our approach for overcoming this problem. We develop a model of imperfect- information games, and describe how to represent information about the game using a modified version of a task network that is extended to represent multi-agency and uncertainty. We present a game- playing procedure that uses this approach to generate game trees in which the set of alternative choices is determined not by the set of possible actions, but by the set of available tactical and strategic schemes. In our tests of this approach on the game of bridge, we found that it generated trees having a much smaller branching factor than would have been generated by conventional game-tree search techniques. Thus, even in the worst case, the game tree contained only about 1300 nodes, as opposed to the approximately 6:01 fi 10 44 nodes that would have been produced by a brute-force game tree search in the worst case. Furthermore, our approach successfully solved typical bridge problems that matched situations in its knowledge base. These preliminary tests suggest that our approach has the potential to yield bridge-playing programs much better than existing ones|and thus we have begun to build a full implementation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Ballard. </author> <title> "The *-Minimax Search Procedure for Trees Containing Chance Nodes." </title> <booktitle> Artificial Intelligence 21 (1983): </booktitle> <pages> 327-350. </pages>
Reference-contexts: Some work has been done on extending game-tree search to deal with uncertainty, including Horacek's work on chess [13], and Ballard's work on backgammon <ref> [1] </ref>. <p> For example, in bridge, information from the bidding or from prior play often gives clues to the location of key cards. To represent this, we define P's belief function to be a probability function p : I fl ! <ref> [0; 1] </ref>, where [0; 1] is the set of reals falling between 0 and 1. To represent the possible actions of the players, we use STRIPS-style operators. <p> For example, in bridge, information from the bidding or from prior play often gives clues to the location of key cards. To represent this, we define P's belief function to be a probability function p : I fl ! <ref> [0; 1] </ref>, where [0; 1] is the set of reals falling between 0 and 1. To represent the possible actions of the players, we use STRIPS-style operators. <p> We define S to be the set of all states. We define I to be the set of all state information sets. An objective function is a partial function f : S ! <ref> [0; 1] </ref>. Intuitively, f (S) expresses the perceived benefit to P of the state S; where f (S) is undefined, this means that S's perceived benefit is not known. <p> For other states, f might well be undefined. Game-playing programs for perfect-information games make use of a static evaluation function, which is a total function e : S ! <ref> [0; 1] </ref> such that if S is a state and f (S) is defined, then e (S) = f (S). In imperfect- information games, it is difficult to use e (S) directly, because instead of knowing the state S, all P will know is the state information set I. <p> For each u i , let I i be the state information set contained in u i . Suppose we have already computed a utility value v i 2 <ref> [0; 1] </ref> for each u i .
Reference: [2] <author> H. J. Berliner, G. Goetsch, M. S. Campbell, and C. Ebeling. </author> <title> Measuring the performance potential of chess programs. </title> <booktitle> Artificial Intelligence 43 </booktitle> <pages> 7-20, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Although game-tree search works well in perfect-information games (such as chess <ref> [2, 16] </ref>, checkers [20], and othello [15]), it does not always work so well in other games. For example, the game of bridge is an imperfect-information game, in which no player has complete knowledge about the state of the world, the possible actions, and their effects.
Reference: [3] <author> A. W. Biermann. </author> <title> Theoretical issues related to computer game playing programs. </title> <type> Personal Computing, </type> <month> September </month> 1978 86-88. 
Reference-contexts: Since our approach avoids generating all possible moves for all agents, it is in essence a type of forward pruning. Although forward pruning has not worked very well in games such as chess <ref> [3, 27] </ref>, our study of forward pruning [23] suggests that forward pruning works best in situations where there is a high correlation among the minimax values of sibling nodes. We believe that bridge has this characteristic.
Reference: [4] <author> T. H. Cormen, C. E. Leiserson, and R. L. Rivest. </author> <title> Introduction to Algorithms. </title> <address> Cambridge, Massachusetts: </address> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference: [5] <author> K. Erol, D. S. Nau, and V. S. Subrahmanian. </author> <title> Complexity, decidability and undecidability results for domain-independent planning. </title> <note> 1992. Submitted for publication. </note>
Reference-contexts: However, since chess is a perfect-information game, Wilkins' work does not deal with uncertainty and incomplete information. Our work on hierarchical planning draws on Tate's [25, 26] which in turn draws on Sacerdoti's [17, 18]. In addition, some of our definitions were motivated by those in <ref> [5, 6] </ref>. 2 A Model of Imperfect-Information Games In this section, we describe a formalism for expressing imperfect-information games having the following characteristics: 1. Only one player may move at at time. 2. Each player need not have complete information about the current state S.
Reference: [6] <author> K. Erol, D. S. Nau, and J. Hendler. </author> <title> Toward a general framework for hierarchical task-network planning. </title> <booktitle> In AAAI Spring Symposium, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: However, since chess is a perfect-information game, Wilkins' work does not deal with uncertainty and incomplete information. Our work on hierarchical planning draws on Tate's [25, 26] which in turn draws on Sacerdoti's [17, 18]. In addition, some of our definitions were motivated by those in <ref> [5, 6] </ref>. 2 A Model of Imperfect-Information Games In this section, we describe a formalism for expressing imperfect-information games having the following characteristics: 1. Only one player may move at at time. 2. Each player need not have complete information about the current state S.
Reference: [7] <author> J. A. Feldman and Y. Yakimovsky. </author> <title> "Decision Theory and Artificial Intelligence I. A Semantics-Based Region Analyzer." </title> <booktitle> Artificial Intelligence 5 (1974): </booktitle> <pages> 349-371. </pages>
Reference-contexts: tree's leaf nodes are nodes at which the procedure does not have any methods to apply, either because the game has ended, or because the methods simply don't tell the procedure what to do. 3 We use the term "decision tree" as it is used in the decision theory literature <ref> [10, 7, 8] </ref>, to represent a structure similar to a game tree.
Reference: [8] <author> J. A. Feldman and R. F. Sproull. </author> <booktitle> "Decision Theory and Artificial Intelligence II: The Hungry Monkey." Cognitive Science 1 (1977): </booktitle> <pages> 158-192. </pages>
Reference-contexts: tree's leaf nodes are nodes at which the procedure does not have any methods to apply, either because the game has ended, or because the methods simply don't tell the procedure what to do. 3 We use the term "decision tree" as it is used in the decision theory literature <ref> [10, 7, 8] </ref>, to represent a structure similar to a game tree.
Reference: [9] <author> I. Frank, D. Basin, and A. Bundy. </author> <title> "An Adaptation of Proof-Planning to Declarer Play in Bridge." </title> <booktitle> In European Conference on Artificial Intelligence, </booktitle> <year> 1992. </year>
Reference-contexts: Recently, Frank and others <ref> [9] </ref> have proposed a proof-planning approach, but thus far, this approach has only been used for planning the play of a single suit. Some work has been done on extending game-tree search to deal with uncertainty, including Horacek's work on chess [13], and Ballard's work on backgammon [1].
Reference: [10] <author> S. </author> <title> French. Decision Theory: An Introduction to the Mathematics of Rationality. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1986. </year>
Reference-contexts: tree's leaf nodes are nodes at which the procedure does not have any methods to apply, either because the game has ended, or because the methods simply don't tell the procedure what to do. 3 We use the term "decision tree" as it is used in the decision theory literature <ref> [10, 7, 8] </ref>, to represent a structure similar to a game tree. <p> theory literature) has been created; P will, at the state information set associated with any decision node, simply choose the method that leads to the node with highest utility value. 5 This definition of external-agent criterion is somewhat different from the usual definition of decision criterion in decision theory (e.g. <ref> [10] </ref>, p. 28), which essentially defines decision criteria on a two-level structure of decision nodes and chance nodes, without the belief function p.
Reference: [11] <author> B. Gamback, M. Rayner, and B. Pell. </author> <title> "An Architecture for a Sophisticated Mechanical Bridge Player", </title> <editor> in: D. F. Beal and D.N.L. Levy(eds.), </editor> <booktitle> Heuristic Programming in Artificial Intelligence|The Second Computer Olympiad. </booktitle> <address> Chinchester, England: </address> <publisher> Ellis Horwood, </publisher> <year> 1990. </year>
Reference-contexts: Section 4 describes an abstract game-playing procedure based on this structure. Section 5 describes our preliminary tests of an implementation of this procedure in the game of bridge. Section 6 contains concluding remarks. 1.1 Related Work The strongest work on bridge has focused on bidding <ref> [11, 12] </ref>. However, there are no really good computer programs for card-playing in bridge|most of them can be beaten by a reasonably advanced novice. The approaches used in current programs are based almost exclusively on domain-specific techniques.
Reference: [12] <author> B. Gamback, M. Rayner, and B. Pell. </author> <title> "Pragmatic Reasoning in Bridge". Cambridge: </title> <type> Technical Report No. 299, </type> <institution> Computer Laboratory, University of Cambridge [1993]. </institution>
Reference-contexts: Section 4 describes an abstract game-playing procedure based on this structure. Section 5 describes our preliminary tests of an implementation of this procedure in the game of bridge. Section 6 contains concluding remarks. 1.1 Related Work The strongest work on bridge has focused on bidding <ref> [11, 12] </ref>. However, there are no really good computer programs for card-playing in bridge|most of them can be beaten by a reasonably advanced novice. The approaches used in current programs are based almost exclusively on domain-specific techniques.
Reference: [13] <author> H. Horacek. </author> <title> "Reasoning with Uncertainty in Computer Chess." </title> <booktitle> Artificial Intelligence 43 (1990): </booktitle> <pages> 37-56. </pages>
Reference-contexts: Recently, Frank and others [9] have proposed a proof-planning approach, but thus far, this approach has only been used for planning the play of a single suit. Some work has been done on extending game-tree search to deal with uncertainty, including Horacek's work on chess <ref> [13] </ref>, and Ballard's work on backgammon [1].
Reference: [14] <author> D. Knuth. </author> <booktitle> The Art of Computer Programming, </booktitle> <volume> vol. </volume> <month> 3: </month> <title> Sorting and Searching. </title> <address> Reading, Massachusetts: </address> <publisher> Addison Wesley, </publisher> <year> 1973. </year>
Reference-contexts: We are not employing decision trees (also, and less ambiguously, referred to as comparison trees <ref> [14] </ref>) as they are defined in the sorting literature ([4], p. 173.) We apologize for the confusion, but it is inescapable. 4 In the decision theory literature, what we call external-agent nodes are usually called chance nodes, because decision theorists usually assume that the external agent is random.
Reference: [15] <author> K.-F. Lee and S. Mahajan. </author> <title> The Development of a World Class Othello Program. </title> <booktitle> Artificial Intelligence 43 </booktitle> <pages> 21-36, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Although game-tree search works well in perfect-information games (such as chess [2, 16], checkers [20], and othello <ref> [15] </ref>), it does not always work so well in other games. For example, the game of bridge is an imperfect-information game, in which no player has complete knowledge about the state of the world, the possible actions, and their effects.
Reference: [16] <author> D. Levy and M. Newborn. </author> <title> All About Chess and Computers. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1982. </year>
Reference-contexts: 1 Introduction Although game-tree search works well in perfect-information games (such as chess <ref> [2, 16] </ref>, checkers [20], and othello [15]), it does not always work so well in other games. For example, the game of bridge is an imperfect-information game, in which no player has complete knowledge about the state of the world, the possible actions, and their effects.
Reference: [17] <author> E. D. Sacerdoti. </author> <title> "Planning in a Hierarchy of Abstraction Spaces." </title> <booktitle> Artifical Intelligence 5 (1974): </booktitle> <pages> 115135. </pages>
Reference-contexts: However, since chess is a perfect-information game, Wilkins' work does not deal with uncertainty and incomplete information. Our work on hierarchical planning draws on Tate's [25, 26] which in turn draws on Sacerdoti's <ref> [17, 18] </ref>. In addition, some of our definitions were motivated by those in [5, 6]. 2 A Model of Imperfect-Information Games In this section, we describe a formalism for expressing imperfect-information games having the following characteristics: 1. Only one player may move at at time. 2.
Reference: [18] <author> E. D. Sacerdoti. </author> <title> "The Non-Linear Nature of Plans." </title> <booktitle> IJCAI-75: </booktitle> <pages> pp. 206-214. </pages>
Reference-contexts: However, since chess is a perfect-information game, Wilkins' work does not deal with uncertainty and incomplete information. Our work on hierarchical planning draws on Tate's [25, 26] which in turn draws on Sacerdoti's <ref> [17, 18] </ref>. In addition, some of our definitions were motivated by those in [5, 6]. 2 A Model of Imperfect-Information Games In this section, we describe a formalism for expressing imperfect-information games having the following characteristics: 1. Only one player may move at at time. 2.
Reference: [19] <author> E. D. Sacerdoti. </author> <title> A Structure for Plans and Behavior. </title> <address> New York: </address> <publisher> American Elsevier Publishing Company, </publisher> <year> 1977. </year>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use instances of multi-agent methods|structures similar to the task decompositions used in hierarchical single- agent planning systems such as Nonlin [25, 26], NOAH <ref> [19] </ref>, and MOLGEN [24], but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task-network decomposition.
Reference: [20] <author> A. L. Samuel. </author> <title> Some studies in machine learning using the game of checkers. II Recent progress. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 2: </volume> <pages> 601-617, </pages> <year> 1967. </year>
Reference-contexts: 1 Introduction Although game-tree search works well in perfect-information games (such as chess [2, 16], checkers <ref> [20] </ref>, and othello [15]), it does not always work so well in other games. For example, the game of bridge is an imperfect-information game, in which no player has complete knowledge about the state of the world, the possible actions, and their effects.
Reference: [21] <author> S. J. J. Smith. </author> <title> "Game-Playing with Uncertainty: Reasoning Techniques." M. S. </title> <type> thesis, </type> <institution> University of Maryland at College Park, </institution> <year> 1991. </year>
Reference: [22] <author> S. J. J. Smith, D. S. Nau, and T. Throop. </author> <title> "A Hierarchical Approach to Strategic Planning with NonCooperating Agents under Conditions of Uncertainty." </title> <booktitle> In Proceedings of the First International Conference on AI Planning Systems, </booktitle> <pages> pages 299-300, </pages> <month> June </month> <year> 1992. </year>
Reference: [23] <author> S. J. J. Smith and D. S. Nau. </author> <title> Toward an analysis of forward pruning. </title> <note> 1993. Submitted for publication. </note>
Reference-contexts: Since our approach avoids generating all possible moves for all agents, it is in essence a type of forward pruning. Although forward pruning has not worked very well in games such as chess [3, 27], our study of forward pruning <ref> [23] </ref> suggests that forward pruning works best in situations where there is a high correlation among the minimax values of sibling nodes. We believe that bridge has this characteristic.
Reference: [24] <author> M. Stefik. </author> <title> Planning with Constraints (MOLGEN: </title> <booktitle> Part 1). Artificial Intelligence 16 </booktitle> <pages> 111-140, </pages> <year> 1981. </year>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use instances of multi-agent methods|structures similar to the task decompositions used in hierarchical single- agent planning systems such as Nonlin [25, 26], NOAH [19], and MOLGEN <ref> [24] </ref>, but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task-network decomposition.
Reference: [25] <author> A. Tate. </author> <title> Project Planning Using a Hierarchic Non-Linear Planner. </title> <note> Edinburgh: Research report no. 25, </note> <institution> Department of Artificial Intelligence, University of Edinburgh [1976]. </institution>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use instances of multi-agent methods|structures similar to the task decompositions used in hierarchical single- agent planning systems such as Nonlin <ref> [25, 26] </ref>, NOAH [19], and MOLGEN [24], but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task-network decomposition. <p> In their intent, these knowledge sources are similar to the multi-agent methods that we describe in Section 3. However, since chess is a perfect-information game, Wilkins' work does not deal with uncertainty and incomplete information. Our work on hierarchical planning draws on Tate's <ref> [25, 26] </ref> which in turn draws on Sacerdoti's [17, 18]. In addition, some of our definitions were motivated by those in [5, 6]. 2 A Model of Imperfect-Information Games In this section, we describe a formalism for expressing imperfect-information games having the following characteristics: 1.
Reference: [26] <author> A. Tate. </author> <title> "Generating Project Networks." </title> <booktitle> IJCAI-77: </booktitle> <pages> 888-893. </pages>
Reference-contexts: To represent the tactical and strategic schemes of card-playing in bridge, we use instances of multi-agent methods|structures similar to the task decompositions used in hierarchical single- agent planning systems such as Nonlin <ref> [25, 26] </ref>, NOAH [19], and MOLGEN [24], but modified to represent multi-agency and uncertainty. To generate game trees, we use a procedure similar to task-network decomposition. <p> In their intent, these knowledge sources are similar to the multi-agent methods that we describe in Section 3. However, since chess is a perfect-information game, Wilkins' work does not deal with uncertainty and incomplete information. Our work on hierarchical planning draws on Tate's <ref> [25, 26] </ref> which in turn draws on Sacerdoti's [17, 18]. In addition, some of our definitions were motivated by those in [5, 6]. 2 A Model of Imperfect-Information Games In this section, we describe a formalism for expressing imperfect-information games having the following characteristics: 1.
Reference: [27] <author> T. R. Truscott. </author> <title> Techniques used in minimax game-playing programs. </title> <type> Master's thesis, </type> <institution> Duke University, Durham, NC, </institution> <year> 1981. </year>
Reference-contexts: Since our approach avoids generating all possible moves for all agents, it is in essence a type of forward pruning. Although forward pruning has not worked very well in games such as chess <ref> [3, 27] </ref>, our study of forward pruning [23] suggests that forward pruning works best in situations where there is a high correlation among the minimax values of sibling nodes. We believe that bridge has this characteristic.
Reference: [28] <author> D. Wilkins. </author> <title> "Using Patterns and Plans in Chess." </title> <booktitle> Artificial Intelligence 14 (1980): </booktitle> <pages> 165-203. </pages>
Reference-contexts: However, these works do not deal with the kind of uncertainty that we discussed in Section 1, and thus it does not appear to us that these approaches would be sufficient to accomplish our objectives. 1 Wilkins <ref> [28, 29] </ref> uses "knowledge sources" to generate chess moves for both the player and the opponent, and then chooses the move to play by investigating the results. In their intent, these knowledge sources are similar to the multi-agent methods that we describe in Section 3.
Reference: [29] <author> D. Wilkins. </author> <title> "Using Knowledge to Control Tree Searching." </title> <booktitle> Artificial Intelligence 18 (1982): </booktitle> <pages> 1-51. 10 </pages>
Reference-contexts: However, these works do not deal with the kind of uncertainty that we discussed in Section 1, and thus it does not appear to us that these approaches would be sufficient to accomplish our objectives. 1 Wilkins <ref> [28, 29] </ref> uses "knowledge sources" to generate chess moves for both the player and the opponent, and then chooses the move to play by investigating the results. In their intent, these knowledge sources are similar to the multi-agent methods that we describe in Section 3.
References-found: 29

