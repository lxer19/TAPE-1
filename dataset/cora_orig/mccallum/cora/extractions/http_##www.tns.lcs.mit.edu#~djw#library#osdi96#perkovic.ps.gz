URL: http://www.tns.lcs.mit.edu/~djw/library/osdi96/perkovic.ps.gz
Refering-URL: http://www.tns.lcs.mit.edu/~djw/library/osdi96/index.html
Root-URL: 
Email: Email: office@usenix.org  
Title: Online Data-Race Detection via Coherency Guarantees  
Phone: 1. Phone: 510 528-8649 2. FAX: 510 548-5738 3.  4.  
Author: Dejan Perkovic and Peter J. Keleher 
Affiliation: University of Maryland  
Web: WWW URL: http://www.usenix.org  
Date: October 1996  
Note: The following paper was originally published in the Proceedings of the USENIX 2nd Symposium on Operating Systems Design and Implementation Seattle, Washington,  For more information about USENIX Association contact:  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> S. Adve and M. Hill. </author> <title> Weak ordering: A new definition. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 2-14, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Since our strategy relies on LRC consistency, our system is clearly applicable only for applications that will run properly on release-consistent systems, i.e. properly-labeled [6] or DRF1 <ref> [1] </ref> applications. The following definitions are assumed throughout the rest of the paper. Definition 1 A data race is defined as a pair of memory accesses in some execution, such that: 1. Both access the same shared variable, 2. At least one is a write, 3. <p> Each time a process executes a release or an acquire, a new interval begins and the current interval index is incremented. Intervals of different processes are related by a happens-before-1 partial ordering <ref> [1] </ref>: 1. intervals on a single processor are totally ordered by program order, 2. interval i p precedes interval j q if j q begins with the acquire corresponding to the release that concluded interval i p , and 3. the transitive closure of the above.
Reference: [2] <author> S. V. Adve, M. D. Hill, B. P. Miller, and R. H. B. </author> <title> Net zer. Detecting data races on weak memory systems. </title> <booktitle> In Proceedings of the 18th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 234-243, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: If global synchronization is either not used, or not used often enough, we can exploit CVM routines that allow global state to be consolidated between synchronizations. Currently, this mechanism is only used in CVM for garbage collection of consistency information in long-running, barrier-free programs. 6.4 Accuracy Adve <ref> [2] </ref> discusses three potential problems in the accuracy of race detection schemes in concert with weak memory systems, or systems that support memory models such as lazy release consistency. <p> Our work is closely related to work already alluded to in Section 5, a technique described (but not implemented) by Adve et al. <ref> [2] </ref>. The authors describe a post-mortem technique that creates trace logs containing synchronization events, information allowing their relative execution order to be derived, and computation events. Computation events correspond roughly to CVM's intervals.
Reference: [3] <author> T. R. Allen and D. A. Padua. </author> <title> Debugging fortran on a shared memory machine. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 721-727, </pages> <month> August </month> <year> 1987. </year>
Reference-contexts: This paper presents the design and evaluation of an online data-race detection technique for explicitly parallel shared-memory applications. This technique is applicable for shared memory programs written for the lazy-release-consistent (LRC) [9] memory model. Our work differs from previous work <ref> [3, 4, 5, 7, 16, 15] </ref> in that data-race detection is performed both on-the-fly and without compiler support.
Reference: [4] <author> J. Choi and S. L. Min. </author> <title> Race frontier: Reproducing data races in parallel program debugging. </title> <booktitle> In Proceedings of the 1991 Conference on the Principles and Practice of Parallel Programming, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: This paper presents the design and evaluation of an online data-race detection technique for explicitly parallel shared-memory applications. This technique is applicable for shared memory programs written for the lazy-release-consistent (LRC) [9] memory model. Our work differs from previous work <ref> [3, 4, 5, 7, 16, 15] </ref> in that data-race detection is performed both on-the-fly and without compiler support.
Reference: [5] <author> A. Dinning and E. Schonberg. </author> <title> An empirical com parison of monitoring algorithms for access anomaly detection. </title> <booktitle> In Proceedings of the 1990 Conference on the Principles and Practice of Parallel Programming, </booktitle> <pages> pages 1-10, </pages> <month> March </month> <year> 1990. </year>
Reference-contexts: This paper presents the design and evaluation of an online data-race detection technique for explicitly parallel shared-memory applications. This technique is applicable for shared memory programs written for the lazy-release-consistent (LRC) [9] memory model. Our work differs from previous work <ref> [3, 4, 5, 7, 16, 15] </ref> in that data-race detection is performed both on-the-fly and without compiler support. <p> However, as previously mentioned, most prior work has dealt with applications and systems in more specialized domains. Bitmaps have been used to track shared accesses before <ref> [5] </ref>, but we know of no other implementation of on-the-fly data-race detection for explicitly-parallel, shared-memory programs without compiler support. Our work is closely related to work already alluded to in Section 5, a technique described (but not implemented) by Adve et al. [2].
Reference: [6] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Since our strategy relies on LRC consistency, our system is clearly applicable only for applications that will run properly on release-consistent systems, i.e. properly-labeled <ref> [6] </ref> or DRF1 [1] applications. The following definitions are assumed throughout the rest of the paper. Definition 1 A data race is defined as a pair of memory accesses in some execution, such that: 1. Both access the same shared variable, 2. At least one is a write, 3. <p> Given the above definition for data races, our system will detect all data races that occur during a given execution. 3 Lazy Release Consistency and Data Races 3.1 Lazy Release Consistency Lazy release consistency [9] is a variant of eager release consistency (ERC) <ref> [6] </ref>, a relaxed memory consistency that allows the effects of shared memory accesses to be delayed until selected synchronization accesses occur. Simplifying matters somewhat, shared memory accesses are labeled either as ordinary or as synchronization accesses, with the latter category further divided into acquire and release accesses.
Reference: [7] <author> Robert Hood, Ken Kennedy, and John Mellor Crummey. </author> <title> Parallel program debugging with on-the-fly anomaly detection. </title> <booktitle> In Proceedings Supercomputing '90, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: This paper presents the design and evaluation of an online data-race detection technique for explicitly parallel shared-memory applications. This technique is applicable for shared memory programs written for the lazy-release-consistent (LRC) [9] memory model. Our work differs from previous work <ref> [3, 4, 5, 7, 16, 15] </ref> in that data-race detection is performed both on-the-fly and without compiler support.
Reference: [8] <author> P. Keleher. </author> <title> Distributed Shared Memory Using Lazy Re lease Consistency. </title> <type> PhD thesis, </type> <institution> Rice University, </institution> <year> 1994. </year>
Reference-contexts: Ideally, the system would be able to incrementally discard data races without global cooperation, but such mechanisms would increase the complexity of the underlying consistency protocol <ref> [8] </ref>. If global synchronization is either not used, or not used often enough, we can exploit CVM routines that allow global state to be consolidated between synchronizations.
Reference: [9] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy re lease consistency for software distributed shared memory. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: This paper presents the design and evaluation of an online data-race detection technique for explicitly parallel shared-memory applications. This technique is applicable for shared memory programs written for the lazy-release-consistent (LRC) <ref> [9] </ref> memory model. Our work differs from previous work [3, 4, 5, 7, 16, 15] in that data-race detection is performed both on-the-fly and without compiler support. <p> Our data-race detection system imposes no additional consistency or synchronization constraints. Given the above definition for data races, our system will detect all data races that occur during a given execution. 3 Lazy Release Consistency and Data Races 3.1 Lazy Release Consistency Lazy release consistency <ref> [9] </ref> is a variant of eager release consistency (ERC) [6], a relaxed memory consistency that allows the effects of shared memory accesses to be delayed until selected synchronization accesses occur.
Reference: [10] <author> P. Keleher, S. Dwarkadas, A. Cox, and W. Zwaenepoel. Treadmarks: </author> <title> Distributed shared memory on standard workstations and operating systems. </title> <booktitle> In Proceedings of the 1994 Winter Usenix Conference, </booktitle> <pages> pages 115-131, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: Application Characteristics systems such as TreadMarks <ref> [10] </ref>, CVM is written entirely as a user-level library and runs on most UNIX-like systems. Unlike TreadMarks, CVM was created specifically as a platform for protocol experimentation. The system is written in C++, and opaque interfaces are strictly enforced between different functional units of the system whenever possible. <p> We based our prototype on CVM's single-writer protocol in order to minimize complexity, but our algorithm will work identically with CVM's multi-writer protocol. Finally, comparison to determine if two intervals are concurrent is a constant-time process, as each interval is marked with a vector timestamp <ref> [14, 10] </ref>. Comparison of two concurrent intervals to determine whether their page lists overlap is currently O (n 2 ) in the size of the lists, as they are usually very small (i.e. less than ten).
Reference: [11] <author> Pete Keleher. </author> <title> The Coherent Virtual Machine. </title> <institution> Techni cal Report Maryland TR93-215, Department of Computer Science, University of Maryland, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: Our general approach is to run applications on a modified version of the Coherent Virtual Memory (CVM) <ref> [11, 12] </ref> system, a distributed shared memory (DSM) system that supports LRC. DSMs support the abstraction of shared memory for parallel applications running on CPUs connected by general-purpose interconnects, such as networks of workstations or distributed memory machines like the IBM SP-2. <p> No bitmap comparison would be performed, even though the intervals are concurrent. 4 Implementation We implemented our data-race detection on top of CVM <ref> [11, 12] </ref>, a software DSM that supports multiple protocols and consistency models.
Reference: [12] <author> Pete Keleher. </author> <title> The relative importance of concurrent writers and weak consistency models. </title> <booktitle> To appear in The Proceedings of the 16th International Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Our general approach is to run applications on a modified version of the Coherent Virtual Memory (CVM) <ref> [11, 12] </ref> system, a distributed shared memory (DSM) system that supports LRC. DSMs support the abstraction of shared memory for parallel applications running on CPUs connected by general-purpose interconnects, such as networks of workstations or distributed memory machines like the IBM SP-2. <p> No bitmap comparison would be performed, even though the intervals are concurrent. 4 Implementation We implemented our data-race detection on top of CVM <ref> [11, 12] </ref>, a software DSM that supports multiple protocols and consistency models. <p> However, none of these limitations are intrinsic to our approach. Our problem sizes are small because of message size limitations. We are modifying the underlying communication layer to alleviate this problem. The large page size exacerbates the problems of false sharing associated with single-writer protocols <ref> [12] </ref> protocols. We based our prototype on CVM's single-writer protocol in order to minimize complexity, but our algorithm will work identically with CVM's multi-writer protocol. Finally, comparison to determine if two intervals are concurrent is a constant-time process, as each interval is marked with a vector timestamp [14, 10]. <p> This overhead will be eliminated when we get the new version of ATOM. Second, we currently instrument both load and store instructions. This is necessary because our system is currently built on top of a single-writer LRC protocol <ref> [12] </ref>. Converting our system to use the multi-writer protocol would allow us to exploit existing diffs, which summarize per-page modifications, to extract write accesses. We would then be able to dispense with the monitoring of store instructions.
Reference: [13] <author> James R. Larus and Eric Schnarr. EEL: </author> <title> Machine independent executable editing. </title> <booktitle> In Proceedings of the SIGPLAN `95 Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: ATOM allows executable binaries to be analyzed and modified. We use ATOM to identify and instrument all loads and stores that may access shared memory. Although ATOM is available only for DEC Alpha systems, similar tools are becoming more common. EEL <ref> [13] </ref> provides similar support for Sparc and MIPS systems, and several machine vendors are working on such tools as well. The actual instrumentation consists of a procedure call to an analysis routine that sets a bit in a per-page bitmap if the instruction accesses shared memory.
Reference: [14] <author> F. Mattern. </author> <title> Virtual time and global states of distributed systems. </title> <booktitle> In Parallel & Distributed Algorithms, </booktitle> <pages> pages 215-226. </pages> <publisher> Elsevier Science Publishers, </publisher> <address> Amsterdam, </address> <year> 1989. </year>
Reference-contexts: We based our prototype on CVM's single-writer protocol in order to minimize complexity, but our algorithm will work identically with CVM's multi-writer protocol. Finally, comparison to determine if two intervals are concurrent is a constant-time process, as each interval is marked with a vector timestamp <ref> [14, 10] </ref>. Comparison of two concurrent intervals to determine whether their page lists overlap is currently O (n 2 ) in the size of the lists, as they are usually very small (i.e. less than ten).
Reference: [15] <author> John Mellor-Crummey. </author> <title> Compile-time support for ef ficient data race detection in shared-memory parallel programs. </title> <type> Technical Report CRPC-TR92232, </type> <institution> Rice University, </institution> <month> September </month> <year> 1992. </year>
Reference-contexts: This paper presents the design and evaluation of an online data-race detection technique for explicitly parallel shared-memory applications. This technique is applicable for shared memory programs written for the lazy-release-consistent (LRC) [9] memory model. Our work differs from previous work <ref> [3, 4, 5, 7, 16, 15] </ref> in that data-race detection is performed both on-the-fly and without compiler support.
Reference: [16] <author> R. H. B. Netzer and B. P. Miller. </author> <title> Improving the accu racy of data race detection. </title> <booktitle> In Proceedings of the 1991 Conference on the Principles and Practice of Parallel Programming, </booktitle> <month> April </month> <year> 1991. </year>
Reference-contexts: This paper presents the design and evaluation of an online data-race detection technique for explicitly parallel shared-memory applications. This technique is applicable for shared memory programs written for the lazy-release-consistent (LRC) [9] memory model. Our work differs from previous work <ref> [3, 4, 5, 7, 16, 15] </ref> in that data-race detection is performed both on-the-fly and without compiler support.
Reference: [17] <author> Robert H. B. Netzer and Barton P. Miller. </author> <title> On the com plexity of event ordering for shared-memory parallel program executions. </title> <booktitle> In 1990 International Conference on Parallel Processing, </booktitle> <pages> pages 93-97, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: 1 Introduction While potentially very useful, data-race detection mechanisms have yet to become widespread. Part of the problem is surely the restricted domain in which most such mechanisms operate, i.e. parallelizing compilers. Such restrictions are deemed necessary because data-race detection is generally NP-complete <ref> [17] </ref>, and exponential searches over a domain the size of the number of shared accesses in a program execution are prohibitively expensive. This paper presents the design and evaluation of an online data-race detection technique for explicitly parallel shared-memory applications. <p> In common with other dynamic systems, we address only the problem of detecting data races that occur in a given execution, not the more general problem of detecting all races allowed by program semantics <ref> [17] </ref>. Our general approach is to run applications on a modified version of the Coherent Virtual Memory (CVM) [11, 12] system, a distributed shared memory (DSM) system that supports LRC.
Reference: [18] <author> Robert H. B. Netzer and Barton P. Miller. </author> <title> What are race conditions? In ACM Letters on Programming Languages and Systems. </title> <publisher> ACM, </publisher> <month> March </month> <year> 1992. </year>
Reference-contexts: Both access the same shared variable, 2. At least one is a write, 3. The accesses are not ordered by system-visible syn chronization or program order. In the sense discussed by Netzer <ref> [18] </ref>, the races found by our system are actual data races, i.e. they are races that occur while the program is running on our system. <p> While runtime overhead and storage requirements can thereby be drastically reduced, the data race must occur in the second run exactly as in the first. This will happen if the application has no general races <ref> [18] </ref>, i.e. synchronization order is deterministic. This is not the case in either of the two applications for which we found data races.
Reference: [19] <author> M. A. Ronsse and W. Zwaenepoel. </author> <title> Execution replay for TreadMarks. </title> <note> Submitted for publication, </note> <year> 1996. </year>
Reference-contexts: We have also just become aware of unpublished work on execution replay in TreadMarks that could be used to implement race-detection schemes. The approach of the Reconstruction of Lamport Timestamps (ROLT) <ref> [19] </ref> technique is similar to the technique we described in Section 6.1 for identifying the instructions involved in races. Minimal ordering information saved during an initial run is used to enforce exactly the same interleaving of shared accesses and synchronization in a second run.
Reference: [20] <author> Daniel Scales and Kourosh Gharachorloo. </author> <title> Shasta: A low overhead, software-only approach for supporting fine-grain shared memory. </title> <booktitle> In Proceedings of the 7th Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: First, the ATOM team has promised a new version that allows instrumentation code to be inlined. The Shasta project <ref> [20] </ref> has already demonstrated a version of ATOM with this feature. Figure 3 shows that an average of 6.7% of our overhead is caused by the procedure call. This overhead will be eliminated when we get the new version of ATOM. Second, we currently instrument both load and store instructions.
Reference: [21] <author> Amitabh Srivastava and Alan Eustace. </author> <title> ATOM: A sys tem for building customized program analysis tools. </title> <booktitle> In Proceedings of the SIGPLAN `94 Conference on Programming Language Design and Implementation, </booktitle> <month> May </month> <year> 1994. </year>
Reference-contexts: We use the ATOM <ref> [21] </ref> code-rewriter to instrument shared accesses with calls to analysis routines. ATOM allows executable binaries to be analyzed and modified. We use ATOM to identify and instrument all loads and stores that may access shared memory.
Reference: [22] <author> S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. </author> <title> The SPLASH-2 programs: Characterization and methodological considerations. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 24-37, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The reads are left unsynchronized to improve performance; out-of-date tour bounds may cause redundant work to be performed, but do not violate correctness. Water-Nsquared, of the Splash2 <ref> [22] </ref> benchmark suite, had a data race that constituted a real bug. This bug has been reported to the Splash authors and fixed in their current version. <p> reduce the number of concurrent intervals. 5 Performance We evaluated the performance of our prototype by searching for data races in implementations of four common shared-memory applications: FFT (Fast Fourier Transform), SOR (Jacobi relaxation), TSP (branch and bound traveling salesman problem), and Water (a molecular dynamics simulation from the Splash2 <ref> [22] </ref> benchmark suite. All applications were run on DECstations with four 250 Mhz Alpha processors, connected by a 155 MBit ATM. We used only a single processor per machine in order to avoid bus contention.
References-found: 22

