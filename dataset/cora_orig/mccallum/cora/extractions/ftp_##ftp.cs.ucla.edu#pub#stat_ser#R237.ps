URL: ftp://ftp.cs.ucla.edu/pub/stat_ser/R237.ps
Refering-URL: http://singapore.cs.ucla.edu/csl_papers.html
Root-URL: http://www.cs.ucla.edu
Email: judea@cs.ucla.edu  
Title: Structural and Probabilistic Causality  
Author: Judea Pearl 
Address: Los Angeles, CA 90024  
Affiliation: Cognitive Systems Laboratory Computer Science Department University of California,  
Abstract: Competing theories of causation based on statistical and power accounts are assessed and related to the normative theories of probabilistic causality and structural modeling. Recent advances in graphical models enable us to cast discussions of these theories in precise mathematical language, thus clarifying their strengths and limitations. The inferential machinery that accompanies the graphical language provides solutions to a number of enduring problems of causal inference, including the analysis of actions, and the processing of counterfactual utterances.
Abstract-found: 1
Intro-found: 1
Reference: [Aldrich, 1994] <author> J. Aldrich. </author> <title> Correlations genuine and spurious in Pearson and Yule. </title> <type> Technical report, </type> <institution> University of Southampton, Department of Economics, UK, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: The dangers of describing the background too coarsely will be illustrated via two examples, one using the celebrated Simpson's paradox, the other the issue of interactive factors. Simpson's paradox [Simpson, 1951], first encountered by Pearson in 1899 <ref> [Aldrich, 1994] </ref>, refers to the phenomenon whereby an event C seems to increase the probability of E in a given population p and, at the same time, decrease the probability of E in every subpopulation of p.
Reference: [Balke and Pearl, 1994] <author> A. Balke and J. Pearl. </author> <title> Counterfactual probabilities: Computational methods, bounds, and applications. </title> <editor> In R. Lopez de Mantaras and D. Poole, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 10, </booktitle> <pages> pages 46-54. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1994. </year>
Reference-contexts: In general, at the ith stage of the construction, we select any minimal set of X i 's predecessors 4 Many more functions need be considered in cases where C interacts with other factors of E (see <ref> [Balke and Pearl, 1994] </ref>). 11 that shield X i from its other predecessors (as in Definition 2), call this set P A i (connoting "parents"), and draw an arrow from each member in P A i to X i . <p> However, the example also shows that the counterfactual probabilities computed under two different functional forms produced almost the same answer to a coun-terfactual query. This is no coincidence. In <ref> [Balke and Pearl, 1994] </ref>, a method is devised for computing sharp bounds on counterfactual probabilities, and, under certain circumstances, those bounds may collapse to point estimates. This method has been applied to the evaluation of causal effects in studies involving noncompliance and to determination of legal liability. <p> A related formulation of causal effects, based on event trees and counterfactual analysis, was developed by Robins (1986, pp. 1422-1425). Shafer (1995) offers a novel formulation of probabilistic causation, based also on event trees. Calculi for actions and counterfactu-als based on surgery semantics are developed in [Pearl, 1994] and <ref> [Balke and Pearl, 1994] </ref>, respectively. 5 Conclusions Statistical contingency models of causal induction have had two major advantages over their power-based rivals. First, statistics-based models are grounded in direct experience and, hence, promise to explicate the evidence and the processes responsible for acquiring cause-effect relationships from raw data.
Reference: [Balke and Pearl, 1995] <author> A. Balke and J. Pearl. </author> <title> Counterfactuals and policy analysis in structural models. </title> <editor> In P. Besnard and S. Hanks, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 11, </booktitle> <pages> pages 11-18. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <year> 1995. </year>
Reference: [Cartwright, 1989] <author> N. Cartwright. </author> <title> Nature's Capacities and Their Measurement. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1989. </year>
Reference-contexts: And philosophers have essentially abandoned the quest for the empirical basis of causation. Early attempts to reduce causality to probabilities got entangled in circular definitions (see Subsection 2.2) and recent theories, based on processes [Salmon, 1994] or capacities <ref> [Cartwright, 1989, chapter 4] </ref>, though conceptually appealing, have not been formalized with sufficient precision to describe how people learn, represent, and use causality in ordinary practice. A new perspective on the problem of causation has recently emerged from a rather unexpected direction artificial intelligence (AI). <p> This leads to a natural probabilistic definition of causal effects. 10 The standard example in the philosophical literature <ref> [Cartwright, 1989] </ref> involves the potential positive influence of birth-control pills on thrombosis, which might be masked by its negative effect on pregnancy (another cause of thrombosis).
Reference: [Cheng et al., 1995] <author> P.W. Cheng, J. Park, A. Yarlas, and K. Holyoak. </author> <title> Psychology of Learning and Motivation, chapter A causal-power theory of focal sets. </title> <year> 1995. </year>
Reference-contexts: Integrated models, in which causal judgment is shaped by both statistical data and preconceived notions of power <ref> [Cheng et al., 1995, this volume] </ref>, are more closely related to an action calculus formulated in [Pearl, 1994].
Reference: [Cheng, 1992] <author> P.W. Cheng. </author> <title> Separating causal laws from causal facts: Pressing the limits of statistical relevance. </title> <journal> Psychology of Learning and Motivation, </journal> <volume> 30 </volume> <pages> 215-264, </pages> <year> 1992. </year>
Reference-contexts: purpose of this paper is to summarize recent advances in causal reasoning, to show how they clarify, unify, and enrich previous approaches in philosophy, economics, and statistics, and to relate these advances to two models of causal judgment that have been proposed in the psychological literature: the statistical contingency model <ref> [Jenkins and Ward, 1965, Cheng, 1992] </ref> and the power-based model [Shultz, 1982]. The statistical contingency model and its variants are grounded in the philosophical literature of probabilistic causality, to be described and assessed in Section 2. <p> Manipulation subjugates the putative causal event to the sole influence of a known mechanism, thus overruling the influence of 7 uncontrolled factors which might also produce the putative effect. "The beauty of indepen-dent manipulation is, of course, that other factors can be kept constant without their being identified" <ref> [Cheng, 1992] </ref>. The independence is accomplished by subjecting the object of interest to the whims of one's volition, to ensure that the manipulation is not influenced by any environmental factor likely to produce the putative effect.
Reference: [Cooper and Herskovits, 1990] <author> G.F. Cooper and E. Herskovits. </author> <title> A Bayesian method for constructing Bayesian belief networks from databases. </title> <booktitle> Proceedings of the Conference on Uncertainty in AI, </booktitle> <pages> pages 86-94, </pages> <year> 1990. </year>
Reference-contexts: Alternative methods of identifying causal structures in data assign prior probabilities to the parameters of the network and use Bayes' rule to score the degree to which a given network fits the data <ref> [Cooper and Herskovits, 1990, Heckerman et al., 1994] </ref>.
Reference: [Cox, 1958] <author> D.R. Cox. </author> <title> The Planning of Experiments. </title> <publisher> John Wiley and Sons, </publisher> <address> NY, </address> <year> 1958. </year>
Reference-contexts: In general, it can be shown [Pearl, 1995] that: 1. The effect of interventions can often be identified (from nonexperimental data) without resorting to parametric models. 13 Most of the statistical literature is satisfied with informal warnings that "Z should be quite unaffected by X" <ref> [Cox, 1958, page 48] </ref>, which is necessary but not sufficient, or that X should not precede Z [Shafer, 1995, page 294], which is neither necessary nor sufficient.
Reference: [Davis, 1988] <author> W.A. Davis. </author> <title> Probabilistic theories of causation. </title> <editor> In James H. Fetzer, editor, </editor> <booktitle> Probability and Causality, </booktitle> <pages> pages 133-160. </pages> <address> D. </address> <publisher> Reidel, </publisher> <address> Dordrecht, </address> <year> 1988. </year>
Reference: [Eells, 1991] <author> E. Eells. </author> <title> Probabilistic Causality. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, MA, </address> <year> 1991. </year>
Reference-contexts: "causally irrelevant." Probabilistic causality deals with testing whether the proposed R and I labels are consistent with the pair &lt; P; O &gt; and that cause should both precede and increase the probability of 1 The phrases "hold F fixed" or "control for F ," used by both philosophers (e.g., <ref> [Eells, 1991] </ref>) and statisticians (e.g., [Pratt and Schlaifer, 1988]), connote external interventions and may, therefore, be misleading (see later sections on acting vs. seeing). <p> Currently, the most advanced consistency test is the one based on Eells' criterion of relevance <ref> [Eells, 1991] </ref>, which translates into: Consistency test: For each pair of variables labeled R (X; Y ), test whether (i) X precedes Y in O, and (ii) there exist x; x 0 ; y such that P (yjx; z) &gt; P (yjx 0 ; z) for some z in Z, where
Reference: [Fisher, 1970] <author> F.M. Fisher. </author> <title> A correspondence principle for simultaneous equations models. </title> <journal> Econometrica, </journal> <volume> 38 </volume> <pages> 73-92, </pages> <year> 1970. </year>
Reference: [Galles and Pearl, 1995] <author> D. Galles and J. Pearl. </author> <title> Testing identifiability of causal effects. </title> <editor> In P. Besnard and S. Hanks, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 11, </booktitle> <pages> pages 185-195. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Francisco, CA, </address> <year> 1995. </year> <month> 33 </month>
Reference-contexts: Moreover, polynomial tests are now available for deciding when P (x i j^x j ) is identifiable and for deriving closed-form expressions for P (x i j^x j ) in terms of observed quantities <ref> [Galles and Pearl, 1995] </ref>. 26 These tests and derivations are based on a symbolic calculus [Pearl, 1994b, 1995], to be described in the sequel, in which interventions, side by side with observations, are given explicit notation and are permitted to transform probability expressions.
Reference: [Geiger et al., 1990] <author> D. Geiger, T.S. Verma, and J. Pearl. </author> <title> Identifying independence in Bayesian networks. </title> <booktitle> In Networks, </booktitle> <volume> volume 20, </volume> <pages> pages 507-534. </pages> <publisher> John Wiley and Sons, </publisher> <address> Sussex, England, </address> <year> 1990. </year>
Reference-contexts: Theorem 1 <ref> [Verma and Pearl, 1990, Geiger et al., 1990] </ref>. For any three disjoint subsets of nodes (X; Y; Z) in a DAG G, Z d-separates X from Y in G if and only if X is independent of Y conditional on Z in every distribution represented by G.
Reference: [Geiger, 1990] <author> D. Geiger. Graphoids: </author> <title> A qualitative framework for probabilistic inference. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> Los Angeles, </address> <year> 1990. </year>
Reference: [Goldszmidt and Pearl, 1992] <author> M. Goldszmidt and J. Pearl. </author> <title> Default ranking: A practical framework for evidential reasoning, belief revision and update. </title> <booktitle> Proceedings of the Third International Conference on Knowledge Representation and Reasoning, </booktitle> <pages> pages 661-672, </pages> <year> 1992. </year>
Reference-contexts: Extensions to action representation in nonmonotonic reasoning and statistical analysis were reported in <ref> [Goldszmidt and Pearl, 1992, Pearl, 1993] </ref>. Graphical ramifications of this translation were explicated first in Spirtes et al. (1993) and later in Pearl (1993b). A related formulation of causal effects, based on event trees and counterfactual analysis, was developed by Robins (1986, pp. 1422-1425).
Reference: [Goldszmidt and Pearl, 1995] <author> M. Goldszmidt and J. Pearl. </author> <title> Qualitative probabilities for default reasoning, belief revision, and causal modeling. </title> <type> Technical Report R-161-L, </type> <institution> Computer Science Department, UCLA, </institution> <year> 1995. </year> <note> Forthcoming in Artificial Intelligence. </note>
Reference: [Good, 1961] <author> I.J. </author> <title> Good. A causal calculus, </title> <journal> I-II. British Journal for the Philosophy of Science, </journal> <volume> 11 </volume> <pages> 305-318, </pages> 12:43-51, 1961. Errata and corrigenda, 13:88. Reprinted in I.J. Good's Good Thinking, University of Minnesota Press, Minnesota, 1983. 
Reference: [Haavelmo, 1943] <author> T. Haavelmo. </author> <title> The statistical implications of a system of simultaneous equations. </title> <journal> Econometrica, </journal> <volume> 11 </volume> <pages> 1-12, </pages> <year> 1943. </year>
Reference-contexts: The roots of this account go back to path analysis in genetics [Wright, 1921] and structural equation models in econometrics <ref> [Haavelmo, 1943, Simon, 1953] </ref>, and it can justly be regarded as the mathematical basis for the power models used in the psychological literature. The basic idea behind the structural account was extended in [Pearl and Verma, 1991] for defining general probabilistic causal theories, as follows.
Reference: [Heckerman and Shachter, 1995] <author> D. Heckerman and R. Shachter. </author> <title> A definition and graphical representation for causality. </title> <booktitle> In Proceedings of the 11th Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 262-273, </pages> <address> San Mateo, CA, 1995. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: However, if the theory is represented implicitly in a form of a function F : Actions fi U ! V , (as is often assumed in decision theory <ref> [Savage, 1954, Heckerman and Shachter, 1995] </ref>), then Lemma 4 can be used to identify, given F , the unique set of direct causes for each variable X i . 9 We see that the distinctive characteristic of structural equations, which sets them apart from ordinary algebraic equations, is that meaning is
Reference: [Heckerman et al., 1994] <author> D. Heckerman, D. Geiger, and D. Chickering. </author> <title> Learning Bayesian networks: The combination of knowledge and statistical data. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <pages> pages 293-301, </pages> <address> San Mateo, CA, July 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Alternative methods of identifying causal structures in data assign prior probabilities to the parameters of the network and use Bayes' rule to score the degree to which a given network fits the data <ref> [Cooper and Herskovits, 1990, Heckerman et al., 1994] </ref>.
Reference: [Jenkins and Ward, 1965] <author> H. Jenkins and W. Ward. </author> <title> Judgement of contingency between responses and outcomes. </title> <journal> Psychological Monographs, </journal> <volume> 7 </volume> <pages> 1-17, </pages> <year> 1965. </year>
Reference-contexts: purpose of this paper is to summarize recent advances in causal reasoning, to show how they clarify, unify, and enrich previous approaches in philosophy, economics, and statistics, and to relate these advances to two models of causal judgment that have been proposed in the psychological literature: the statistical contingency model <ref> [Jenkins and Ward, 1965, Cheng, 1992] </ref> and the power-based model [Shultz, 1982]. The statistical contingency model and its variants are grounded in the philosophical literature of probabilistic causality, to be described and assessed in Section 2.
Reference: [Kim and Pearl, 1983] <author> J.H. Kim and J. Pearl. </author> <title> A computational model for combined causal and diagnostic reasoning in inference systems. </title> <booktitle> In Proceedings IJCAI-83, </booktitle> <pages> pages 190-193, </pages> <address> Karlsruhe, Germany, </address> <year> 1983. </year>
Reference-contexts: set P A j in a Bayesian network of P (v) constructed along the temporal order. 5 [Spohn, 1980, Mulaik, 1986] are among the few who advocated this transition in the philosophical literature, though it has been used routinely in path analysis [Wright, 1921] economics [Simon, 1953] and artificial intelligence <ref> [Kim and Pearl, 1983] </ref> 12 Definition 3 provides a natural generalization of deterministic causality, in the spirit of Mulaik, (1986).
Reference: [Koopman and Reiersol, 1950] <author> T.C. Koopman and O. Reiersol. </author> <title> The identification of structural characteristics. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 21 </volume> <pages> 165-181, </pages> <year> 1950. </year>
Reference-contexts: T 1 (v) = P T 2 (v), we have P T 1 (yj^x) = P T 2 (yj^x). 11 The notion of identifiability is central to much work in econometrics, where it has become synonymous to the identification of the functions ff i g or some of their parameters <ref> [Koopman and Reiersol, 1950] </ref>, mostly under conditions of additive Gaussian noise. Definition 8, which does not assume any parametric representation of the functions ff i g, extends the notion of identifiability to quantities Q that do not require the precision of parametric models.
Reference: [Lauritzen and Spiegelhalter, 1988] <author> S.L. Lauritzen and D.J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems(with discussion). </title> <journal> Journal of the Royal Statistical Society, Series B, </journal> <volume> 50(2) </volume> <pages> 157-224, </pages> <year> 1988. </year>
Reference: [Lewis, 1973] <author> D. Lewis. </author> <title> Counterfactuals. </title> <publisher> Basil Blackwell, Oxford, </publisher> <year> 1973. </year> <month> 34 </month>
Reference-contexts: The majority of the philosophers who have examined the semantics of counterfactual sentences have resorted to some version of Lewis' "closest world" approach: "C if it were A" is true, if C is true in worlds that are "closest" to the real world yet consistent with the counterfactual antecedent A <ref> [Lewis, 1973] </ref>. While the closest world approach leaves the precise specification of the closeness measure almost unconstrained, causal knowledge imposes very specific preferences as to which worlds should be considered closest to any given world. For example, consider an array of domino tiles standing close to each other. <p> In the domino example, finding tile i tipped and i + 1 erect requires the alteration of two basic mechanisms (i.e., two unexplained actions or "miracles" <ref> [Lewis, 1973] </ref>) compared with one altered mechanism for the world in which all j tiles, j &gt; i, are tipped. This paradigm conforms to our perception of causal influences and lends itself to economical machine representation.
Reference: [Mulaik, 1986] <author> S.A. Mulaik. </author> <title> Toward a synthesis of deterministic and probabilistic formula-tions of causal relations by the functional relation concept. </title> <journal> Philosophy of Science, </journal> <volume> 53 </volume> <pages> 313-332, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: We say that X i is a direct cause of X j if X i is a member of the parent set P A j in a Bayesian network of P (v) constructed along the temporal order. 5 <ref> [Spohn, 1980, Mulaik, 1986] </ref> are among the few who advocated this transition in the philosophical literature, though it has been used routinely in path analysis [Wright, 1921] economics [Simon, 1953] and artificial intelligence [Kim and Pearl, 1983] 12 Definition 3 provides a natural generalization of deterministic causality, in the spirit of
Reference: [Neyman, 1923] <author> J. Neyman. </author> <title> On the application of probability theory to agricultural experiments. Essay on principles. Section 9. </title> <journal> Statistical Science, </journal> <volume> 5(4) </volume> <pages> 465-480, </pages> <year> 1923. </year>
Reference-contexts: Statisticians, in contrast, have adopted Fisher's randomized experiment as the ruling paradigm for causal inference, with occasional excursions into its precursor the Neyman-Rubin model of potential response <ref> [Neyman, 1923, Rubin, 1974] </ref>. None of these paradigms and methodologies can serve as an adequate substitute for a comprehensive theory of causation, one suitable for explaining the ways people infer and process causal relationships.
Reference: [Otte, 1981] <author> R. Otte. </author> <title> A critque of suppes' theory of probabilistic causality. </title> <journal> Synthese, </journal> <volume> 48 </volume> <pages> 167-189, </pages> <year> 1981. </year>
Reference-contexts: This is precisely the ambiguity noticed in probabilistic causality <ref> [Otte, 1981] </ref>: even given complete specification of temporal ordering, probabilistic information fails to distinguish genuine from spurious causes when causal connections degenerate into deterministic, necessary and sufficient relationships. 6 Definition 3 6 We will argue later, in discussing the structural definition of causation, that neither causal chains nor causal forks can
Reference: [Pearl and Verma, 1991] <author> J. Pearl and T. Verma. </author> <title> A theory of inferred causation. </title> <editor> In J.A. Allen, R. Fikes, and E. Sandewall, editors, </editor> <booktitle> Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference, </booktitle> <pages> pages 441-452, </pages> <address> San Ma-teo, CA, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The statistical contingency model and its variants are grounded in the philosophical literature of probabilistic causality, to be described and assessed in Section 2. Related advancements in probabilistic causal discovery, based on the language of graphs <ref> [Pearl and Verma, 1991, Spirtes et al., 1993] </ref> are described in Section 3. <p> The distinction between transitive and intransitive dependencies has become the basis for algorithms aimed at extracting causal structures from raw statistical data. Several systems that systematically search and identify causal structures from empirical data have been developed [Pearl, 1988, page 387-397] and <ref> [Pearl and Verma, 1991, Spirtes et al., 1993] </ref>. <p> Technically, because these algorithms rely solely on conditional independence relationships, the structures found are valid only if one is willing to accept forms of guarantees that are 17 weaker than those obtained through controlled randomized experiments namely, minimal-ity and stability <ref> [Pearl and Verma, 1991] </ref>. Minimality guarantees that any other structure compatible with the data is necessarily less specific, and hence less falsifiable and less trustworthy, than the one (s) inferred. <p> The basic idea behind the structural account was extended in <ref> [Pearl and Verma, 1991] </ref> for defining general probabilistic causal theories, as follows.
Reference: [Pearl et al., 1990] <author> J. Pearl, D. Geiger, and T. Verma. </author> <title> The logic of influence diagrams. In R.M. </title> <editor> Oliver and J.Q. Smith, editors, </editor> <title> Influence Diagrams, </title> <booktitle> Belief Nets and Decision Analysis, </booktitle> <pages> pages 67-87. </pages> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference: [Pearl, 1988] <author> J. Pearl. </author> <booktitle> Probabilistic Reasoning in Intelligence Systems. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year> <note> (Revised 2nd printing, </note> <year> 1992). </year>
Reference-contexts: The result is a directed acyclic graph, called a "Bayesian network" in <ref> [Pearl, 1988] </ref>, in which an arrow from X i to X j assigns X i as a Markovian parent of X j , consistent with Definition 2. among the season of the year (X 1 ), whether rain falls (X 2 ) during the season, whether the sprinkler is on (X <p> The question of uniqueness also has a simple solution; if P (v) &gt; 0 for every configuration v, then the parent sets P A i are unique <ref> [Pearl, 1988, page 119] </ref> and, hence, there will be a unique set of direct causes for every variable. Causal ambiguities emerge when some configurations obtain zero probability, representing deterministic constraints. <p> A convenient way of characterizing the set of distributions represented by a DAG G is to list the set of (conditional) independencies that each such distribution must satisfy. These independencies can be read off the DAG by using a graphical criterion called d-separation <ref> [Pearl, 1988] </ref>. To test whether X is independent of Y given Z in the distributions represented by G, we need to examine G and test whether the nodes corresponding to variables Z d-separate all paths from nodes in X to nodes in Y . <p> Note that the ordering with which the graph was constructed does not enter into the d-separation criterion; it is only the topology of the resulting graph that determines the set of independencies that the probability P must satisfy. Indeed, the following theorem can be proven <ref> [Pearl, 1988, page 120] </ref>. Theorem 2 If a Bayesian network G is constructed recursively along some ordering O (as in Definition 2), then a construction along any ordering O 0 consistent with the direction of arrows in G would yield the same network. <p> The distinction between transitive and intransitive dependencies has become the basis for algorithms aimed at extracting causal structures from raw statistical data. Several systems that systematically search and identify causal structures from empirical data have been developed <ref> [Pearl, 1988, page 387-397] </ref> and [Pearl and Verma, 1991, Spirtes et al., 1993].
Reference: [Pearl, 1993] <author> J. Pearl. </author> <title> From Bayesian networks to causal networks. </title> <booktitle> In Proceedings of the Adaptive Computing and Information Processing Seminar, </booktitle> <pages> pages 25-27, </pages> <publisher> Brunel Conference Centre, </publisher> <address> London, </address> <month> January </month> <year> 1993. </year> <note> See also Statistical Science, </note> <month> 8(3):, </month> <pages> 266-269, </pages> <year> 1993. </year>
Reference-contexts: basis of the independencies embodied in Bayesian networks (Section 3.2), and they enable us to compute causal effects directly from the conditional probabilities P (x i jpa i ), without specifying either the functional form of the functions f i or the distributions P (u i ) of the disturbances <ref> [Pearl, 1993, Spirtes et al., 1993] </ref>. <p> Fortunately, certain causal effects are identifiable even in situations where members of pa j are unobservable <ref> [Pearl, 1993] </ref>. <p> However, a formal, general criterion for deciding whether a set of covariates Z (X 2 in our example) qualifies for adjustment has long been wanting [Smith, 1957, Wainer, 1991, Shafer, 1995]. 13 Theorem 5 provides such a criterion (called the "back-door criterion" in <ref> [Pearl, 1993] </ref>) which reads: Definition 10 Z is an admissible set of covariates relative to the effect of X on Y if: (i) no node in Z is a descendant of X, and (ii) Z d-separates X from Y along any path containing an arrow into X (equivalently, (Y k XjZ) <p> Extensions to action representation in nonmonotonic reasoning and statistical analysis were reported in <ref> [Goldszmidt and Pearl, 1992, Pearl, 1993] </ref>. Graphical ramifications of this translation were explicated first in Spirtes et al. (1993) and later in Pearl (1993b). A related formulation of causal effects, based on event trees and counterfactual analysis, was developed by Robins (1986, pp. 1422-1425).
Reference: [Pearl, 1994] <author> J. Pearl. </author> <title> A probabilistic calculus of actions. </title> <editor> In R. Lopez de Mantaras and D. Poole, editors, </editor> <booktitle> Uncertainty in Artificial Intelligence 10, </booktitle> <pages> pages 454-462. </pages> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, CA, </address> <year> 1994. </year>
Reference-contexts: Integrated models, in which causal judgment is shaped by both statistical data and preconceived notions of power [Cheng et al., 1995, this volume], are more closely related to an action calculus formulated in <ref> [Pearl, 1994] </ref>. In this formulation, prior causal knowledge is encoded qualitatively in the form of a graph containing both observed and unobserved variables, and the magnitudes of causal forces in the domain are inferred from both the probability of the observed variables and the topological features of the graph. <p> Generalization to multiple actions and conditional actions is straightforward. Multiple actions do (X = x), where X is a compound variable, result in a distribution similar to (17), except that all factors corresponding to the variables in X are removed from the product in (16). Stochastic conditional strategies <ref> [Pearl, 1994] </ref> of the form do (X j = x j ) with probability P fl (x j jpa fl j ) (20) where PA fl j is the support set of the decision strategy, also result in a product decomposition similar to (16), except that each factor P (x j <p> A related formulation of causal effects, based on event trees and counterfactual analysis, was developed by Robins (1986, pp. 1422-1425). Shafer (1995) offers a novel formulation of probabilistic causation, based also on event trees. Calculi for actions and counterfactu-als based on surgery semantics are developed in <ref> [Pearl, 1994] </ref> and [Balke and Pearl, 1994], respectively. 5 Conclusions Statistical contingency models of causal induction have had two major advantages over their power-based rivals.
Reference: [Pearl, 1995] <author> J. Pearl. </author> <title> Causal diagrams for experimental research. </title> <type> Technical Report R-218-B, </type> <institution> Computer Science Department, UCLA, </institution> <year> 1995. </year> <note> To appear in Biometrika, </note> <month> December </month> <year> 1995. </year>
Reference-contexts: The graphical definition of admissible covariates replaces statistical folklore with formal procedures, and should enable analysts to systematically select an optimal set of observations, namely, a set Z that minimizes measurement cost or sampling variability. In general, it can be shown <ref> [Pearl, 1995] </ref> that: 1.
Reference: [Pearson, 1911] <author> K. Pearson. </author> <title> Grammar of Science, </title> <editor> 3rd ed. A. and C. </editor> <publisher> Black Publishers, </publisher> <year> 1911. </year>
Reference: [Pratt and Schlaifer, 1988] <author> J.W. Pratt and R. Schlaifer. </author> <title> On the interpretation and observation of laws. </title> <journal> Journal of Econometrics, </journal> <volume> 39 </volume> <pages> 23-52, </pages> <year> 1988. </year>
Reference-contexts: with testing whether the proposed R and I labels are consistent with the pair &lt; P; O &gt; and that cause should both precede and increase the probability of 1 The phrases "hold F fixed" or "control for F ," used by both philosophers (e.g., [Eells, 1991]) and statisticians (e.g., <ref> [Pratt and Schlaifer, 1988] </ref>), connote external interventions and may, therefore, be misleading (see later sections on acting vs. seeing).
Reference: [Reichenbach, 1956] <author> H. Reichenbach. </author> <title> The Direction of Time. </title> <institution> University of California Press, Berkeley, </institution> <year> 1956. </year>
Reference: [Robins, 1986] <author> J.M. Robins. </author> <title> A new approach to causal inference in mortality studies with a sustained exposure period applications to control of the healthy workers survivor effect. </title> <booktitle> Mathematical Modeling, </booktitle> <volume> 7 </volume> <pages> 1393-1512, </pages> <year> 1986. </year>
Reference: [Rosenbaum and Rubin, 1983] <author> P. Rosenbaum and D. Rubin. </author> <title> The central role of propensity score in observational studies for causal effects. </title> <journal> Biometrica, </journal> <volume> 70 </volume> <pages> 41-55, </pages> <year> 1983. </year>
Reference-contexts: In some academic circles, a criterion called "ignorability" is invoked <ref> [Rosenbaum and Rubin, 1983] </ref>, which merely paraphrases the problem in the language of coun terfactuals.
Reference: [Rubin, 1974] <author> D.B. Rubin. </author> <title> Estimating causal effects of treatments in randomized and non-randomized studies. </title> <journal> Journal of Educational Psychology, </journal> <volume> 66 </volume> <pages> 688-701, </pages> <year> 1974. </year> <month> 35 </month>
Reference-contexts: Statisticians, in contrast, have adopted Fisher's randomized experiment as the ruling paradigm for causal inference, with occasional excursions into its precursor the Neyman-Rubin model of potential response <ref> [Neyman, 1923, Rubin, 1974] </ref>. None of these paradigms and methodologies can serve as an adequate substitute for a comprehensive theory of causation, one suitable for explaining the ways people infer and process causal relationships. <p> Moreover, the distribution of this random variable is easily seen to coincide with the causal effect P (yj^x): P ((Y (x) = y) = P (yj^x) 14 The term unit instead of context is often used in the statistical literature <ref> [Rubin, 1974] </ref>, where it normally stands for the identity of a specific individual in a population, namely, the set of attributes u that characterize that individual. In general, u may include the time of day, the experimental conditions under study, and so on.
Reference: [Russell, 1913] <author> B. Russell. </author> <title> On the notion of cause. </title> <booktitle> Proceedings of the Aristotelian Society, </booktitle> <volume> 13 </volume> <pages> 1-26, </pages> <year> 1913. </year>
Reference: [Salmon, 1984] <author> W.C. Salmon. </author> <title> Scientific Explanation and the Causal Structure of the World. </title> <publisher> Princeton University Press, Princeton, </publisher> <year> 1984. </year>
Reference-contexts: Otte (1981), W. Spohn (1980), W.C. Salmon (1984), N. Cartwright (1989), and E. Eells (1991). The current state of this program is rather disappointing considering its original aspirations. Salmon has abandoned the effort altogether, concluding that "causal relations are not appropriately analyzable in terms of statistical relevance relations" <ref> [Salmon, 1984, page 185] </ref>; instead, he has proposed an analysis in which "causal processes" are the basic building blocks.
Reference: [Salmon, 1994] <author> W. Salmon. </author> <title> Causality without counterfactuals. </title> <journal> Philosophy of Science Association, </journal> <volume> 61 </volume> <pages> 297-312, </pages> <year> 1994. </year>
Reference-contexts: And philosophers have essentially abandoned the quest for the empirical basis of causation. Early attempts to reduce causality to probabilities got entangled in circular definitions (see Subsection 2.2) and recent theories, based on processes <ref> [Salmon, 1994] </ref> or capacities [Cartwright, 1989, chapter 4], though conceptually appealing, have not been formalized with sufficient precision to describe how people learn, represent, and use causality in ordinary practice. A new perspective on the problem of causation has recently emerged from a rather unexpected direction artificial intelligence (AI).
Reference: [Savage, 1954] <author> L.J. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1954. </year>
Reference-contexts: However, if the theory is represented implicitly in a form of a function F : Actions fi U ! V , (as is often assumed in decision theory <ref> [Savage, 1954, Heckerman and Shachter, 1995] </ref>), then Lemma 4 can be used to identify, given F , the unique set of direct causes for each variable X i . 9 We see that the distinctive characteristic of structural equations, which sets them apart from ordinary algebraic equations, is that meaning is
Reference: [Shafer, 1995] <author> G. Shafer. </author> <title> The Art of Causal Conjecture. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year> <month> Forthcoming. </month>
Reference-contexts: However, a formal, general criterion for deciding whether a set of covariates Z (X 2 in our example) qualifies for adjustment has long been wanting <ref> [Smith, 1957, Wainer, 1991, Shafer, 1995] </ref>. 13 Theorem 5 provides such a criterion (called the "back-door criterion" in [Pearl, 1993]) which reads: Definition 10 Z is an admissible set of covariates relative to the effect of X on Y if: (i) no node in Z is a descendant of X, and <p> of interventions can often be identified (from nonexperimental data) without resorting to parametric models. 13 Most of the statistical literature is satisfied with informal warnings that "Z should be quite unaffected by X" [Cox, 1958, page 48], which is necessary but not sufficient, or that X should not precede Z <ref> [Shafer, 1995, page 294] </ref>, which is neither necessary nor sufficient. In some academic circles, a criterion called "ignorability" is invoked [Rosenbaum and Rubin, 1983], which merely paraphrases the problem in the language of coun terfactuals.
Reference: [Shultz, 1982] <author> T.R. Shultz. </author> <title> Rules of causal attribution. </title> <booktitle> Monographs of the Society for Research in Child Development, </booktitle> <volume> 47(1), </volume> <year> 1982. </year>
Reference-contexts: causal reasoning, to show how they clarify, unify, and enrich previous approaches in philosophy, economics, and statistics, and to relate these advances to two models of causal judgment that have been proposed in the psychological literature: the statistical contingency model [Jenkins and Ward, 1965, Cheng, 1992] and the power-based model <ref> [Shultz, 1982] </ref>. The statistical contingency model and its variants are grounded in the philosophical literature of probabilistic causality, to be described and assessed in Section 2.
Reference: [Simon, 1953] <author> H.A. Simon. </author> <title> Causal ordering and identifiability. </title> <editor> In W.C. Hood and T.C. Koopmans, editors, </editor> <booktitle> Studies in Econometric Method, </booktitle> <pages> pages 49-74. </pages> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1953. </year>
Reference-contexts: a member of the parent set P A j in a Bayesian network of P (v) constructed along the temporal order. 5 [Spohn, 1980, Mulaik, 1986] are among the few who advocated this transition in the philosophical literature, though it has been used routinely in path analysis [Wright, 1921] economics <ref> [Simon, 1953] </ref> and artificial intelligence [Kim and Pearl, 1983] 12 Definition 3 provides a natural generalization of deterministic causality, in the spirit of Mulaik, (1986). <p> The roots of this account go back to path analysis in genetics [Wright, 1921] and structural equation models in econometrics <ref> [Haavelmo, 1943, Simon, 1953] </ref>, and it can justly be regarded as the mathematical basis for the power models used in the psychological literature. The basic idea behind the structural account was extended in [Pearl and Verma, 1991] for defining general probabilistic causal theories, as follows.
Reference: [Simpson, 1951] <author> E.H. Simpson. </author> <title> The interpretation of interaction in contingency tables. </title> <journal> Journal of the Royal Statistical Society, Series B,13:238-241, </journal> <year> 1951. </year>
Reference-contexts: The dangers of describing the background too coarsely will be illustrated via two examples, one using the celebrated Simpson's paradox, the other the issue of interactive factors. Simpson's paradox <ref> [Simpson, 1951] </ref>, first encountered by Pearson in 1899 [Aldrich, 1994], refers to the phenomenon whereby an event C seems to increase the probability of E in a given population p and, at the same time, decrease the probability of E in every subpopulation of p.
Reference: [Skyrms, 1980] <author> B. Skyrms. </author> <title> Causal Necessity. </title> <publisher> Yale University Press, </publisher> <address> New Haven, </address> <year> 1980. </year>
Reference: [Smith, 1957] <author> H.F. Smith. </author> <title> Interpretation of adjusted treatment means and regressions in analysis of covariates. </title> <journal> Biometrics, </journal> <volume> 13 </volume> <pages> 282-308, </pages> <year> 1957. </year>
Reference-contexts: However, a formal, general criterion for deciding whether a set of covariates Z (X 2 in our example) qualifies for adjustment has long been wanting <ref> [Smith, 1957, Wainer, 1991, Shafer, 1995] </ref>. 13 Theorem 5 provides such a criterion (called the "back-door criterion" in [Pearl, 1993]) which reads: Definition 10 Z is an admissible set of covariates relative to the effect of X on Y if: (i) no node in Z is a descendant of X, and
Reference: [Sobel, 1990] <author> M.E. Sobel. </author> <title> Effect analysis and causation in linear structural equation models. </title> <journal> Psychometrika, </journal> <volume> 55(3) </volume> <pages> 495-515, </pages> <year> 1990. </year>
Reference: [Spiegelhalter et al., 1993] <author> D.J. Spiegelhalter, S.L. Lauritzen, P.A. Dawid, and R.G. Cowell. </author> <title> Bayesian analysis in expert systems. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 219-247, </pages> <year> 1993. </year>
Reference: [Spirtes et al., 1993] <author> P. Spirtes, C. Glymour, and R. Schienes. </author> <title> Causation, Prediction, and Search. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: The statistical contingency model and its variants are grounded in the philosophical literature of probabilistic causality, to be described and assessed in Section 2. Related advancements in probabilistic causal discovery, based on the language of graphs <ref> [Pearl and Verma, 1991, Spirtes et al., 1993] </ref> are described in Section 3. <p> The distinction between transitive and intransitive dependencies has become the basis for algorithms aimed at extracting causal structures from raw statistical data. Several systems that systematically search and identify causal structures from empirical data have been developed [Pearl, 1988, page 387-397] and <ref> [Pearl and Verma, 1991, Spirtes et al., 1993] </ref>. <p> basis of the independencies embodied in Bayesian networks (Section 3.2), and they enable us to compute causal effects directly from the conditional probabilities P (x i jpa i ), without specifying either the functional form of the functions f i or the distributions P (u i ) of the disturbances <ref> [Pearl, 1993, Spirtes et al., 1993] </ref>.
Reference: [Spohn, 1980] <author> W. Spohn. </author> <title> Stochastic independence, causal independence, </title> <journal> and shieldability. Journal of Philosophical Logic, </journal> <volume> 9 </volume> <pages> 73-99, </pages> <year> 1980. </year>
Reference-contexts: We say that X i is a direct cause of X j if X i is a member of the parent set P A j in a Bayesian network of P (v) constructed along the temporal order. 5 <ref> [Spohn, 1980, Mulaik, 1986] </ref> are among the few who advocated this transition in the philosophical literature, though it has been used routinely in path analysis [Wright, 1921] economics [Simon, 1953] and artificial intelligence [Kim and Pearl, 1983] 12 Definition 3 provides a natural generalization of deterministic causality, in the spirit of
Reference: [Strotz and Wold, 1960] <author> R.H. Strotz and H.O.A. </author> <title> Wold. Causal models in the social sciences. </title> <journal> Econometrica, </journal> <volume> 28 </volume> <pages> 417-427, </pages> <year> 1960. </year>
Reference: [Suppes, 1970] <author> P. Suppes. </author> <title> A Probabilistic Theory of Causation. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1970. </year>
Reference: [Verma and Pearl, 1990] <author> T. Verma and J. Pearl. </author> <title> Equivalence and synthesis of causal models. </title> <booktitle> In Uncertainty in Artificial Intelligence, pages 6,220-227, </booktitle> <address> Cambridge, MA, 1990. </address> <publisher> Elsevier Science Publishers. </publisher> <pages> 36 </pages>
Reference-contexts: Theorem 1 <ref> [Verma and Pearl, 1990, Geiger et al., 1990] </ref>. For any three disjoint subsets of nodes (X; Y; Z) in a DAG G, Z d-separates X from Y in G if and only if X is independent of Y conditional on Z in every distribution represented by G. <p> An important property that follows from the d-separation characterization is a criterion for determining whether two given DAGs are observationally equivalent, that is, whether every probability distribution that is represented by one of the DAGs is also represented by the other. Theorem 3 <ref> [Verma and Pearl, 1990] </ref> Two DAGs are observationally equivalent iff they have the same sets of edges and the same sets of v-structures, that is, two converging arrows whose tails are not connected by an arrow. 16 Observational equivalence places a limit on our ability to infer causal directionality from probabilities
Reference: [Wainer, 1991] <author> H. </author> <title> Wainer. Adjusting for differential base-rates: Lord's paradox again. </title> <journal> Psy--chological Bulletin, </journal> <volume> 109 </volume> <pages> 147-151, </pages> <year> 1991. </year>
Reference-contexts: However, a formal, general criterion for deciding whether a set of covariates Z (X 2 in our example) qualifies for adjustment has long been wanting <ref> [Smith, 1957, Wainer, 1991, Shafer, 1995] </ref>. 13 Theorem 5 provides such a criterion (called the "back-door criterion" in [Pearl, 1993]) which reads: Definition 10 Z is an admissible set of covariates relative to the effect of X on Y if: (i) no node in Z is a descendant of X, and
Reference: [Waldmann et al., 1995] <author> M.R. Waldmann, K.J. Holyoak, and A. Fratiannea. </author> <title> Causal models and the acquisition of category structure. </title> <journal> Journal of Experimental Psychology, </journal> <volume> 124 </volume> <pages> 181-206, </pages> <year> 1995. </year>
Reference-contexts: Regardless of the origins of this asymmetry, exploring whether it provides a significant source of causal information (or at least causal clues) in human learning is an interesting topic for research <ref> [Waldmann et al., 1995] </ref>. The distinction between transitive and intransitive dependencies has become the basis for algorithms aimed at extracting causal structures from raw statistical data.
Reference: [Wright, 1921] <author> S. Wright. </author> <title> Correlation and causation. </title> <journal> Journal of Agricultural Research, </journal> <volume> 20 </volume> <pages> 557-585, </pages> <year> 1921. </year>
Reference-contexts: X i is a member of the parent set P A j in a Bayesian network of P (v) constructed along the temporal order. 5 [Spohn, 1980, Mulaik, 1986] are among the few who advocated this transition in the philosophical literature, though it has been used routinely in path analysis <ref> [Wright, 1921] </ref> economics [Simon, 1953] and artificial intelligence [Kim and Pearl, 1983] 12 Definition 3 provides a natural generalization of deterministic causality, in the spirit of Mulaik, (1986). <p> The roots of this account go back to path analysis in genetics <ref> [Wright, 1921] </ref> and structural equation models in econometrics [Haavelmo, 1943, Simon, 1953], and it can justly be regarded as the mathematical basis for the power models used in the psychological literature.
References-found: 60

