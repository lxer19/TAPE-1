URL: http://www.cs.pitt.edu/~moir/Papers/moir-wdag97.ps
Refering-URL: http://www.cs.pitt.edu/~moir/papers.html
Root-URL: 
Title: Transparent Support for Wait-Free Transactions  
Author: Mark Moir 
Address: Pittsburgh, Pittsburgh, PA 15260.  
Affiliation: Department of Computer Science The University of  
Abstract: This paper concerns software support for non-blocking transactions in shared-memory multiprocessors. We present mechanisms that convert sequential transactions into lock-free or wait-free ones. In contrast to some previous mechanisms, ours support transactions for which the set of memory locations accessed cannot be determined in advance. Our implementations automatically detect and resolve conflicts between concurrent transactions, and allow transactions that do not conflict to execute in parallel. The key to the efficiency of our wait-free implementation lies in using a lock-free (but not wait-free) multi-word compare-and-swap (MWCAS) operation. By introducing communication between a high-level helping mechanism and the lock-free MWCAS, we show that an expensive wait-free MWCAS is not necessary to ensure wait-freedom.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Y. Afek, D. Dauber, and D. Touitou, </author> <title> "Wait-free Made Fast", </title> <booktitle> Proceedings of the 27th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1995. </year>
Reference-contexts: However, most synchronization primitives access a fixed set of locations, and can therefore be implemented using static transactions. (Israeli and Rappoport also presented lock-free constructions for multi-word synchronization primitives [7]; these constructions employ the costly recursive helping policy discussed above.) Most previous wait-free universal constructions <ref> [1, 3, 6] </ref> implement only one object: in order to use them to implement multiple objects and to allow operations to access multiple objects atomically, the objects must be considered as a single object. None of these wait-free constructions allow concurrent operations to execute in parallel. <p> This is because the objects to be accessed by these multi-object operations must be specified in advance; general implementations should not impose this restriction. Finally, efforts have been made to provide wait-free constructions that avoid excessive copying overhead <ref> [1, 3] </ref>, and that have time complexity that depends on contention, rather than on the number of processes [1, 4]. 1 However, none of these constructions allow operations to execute in parallel. 2 3 Conditionally Wait-Free MWCAS Implementation In this section we describe our conditionally wait-free MWCAS operation, which is used <p> Finally, efforts have been made to provide wait-free constructions that avoid excessive copying overhead [1, 3], and that have time complexity that depends on contention, rather than on the number of processes <ref> [1, 4] </ref>. 1 However, none of these constructions allow operations to execute in parallel. 2 3 Conditionally Wait-Free MWCAS Implementation In this section we describe our conditionally wait-free MWCAS operation, which is used by the lock-free and wait-free transaction implementations presented in the following two sections. <p> Therefore, process 0 has checked the locations accessed by its MWCAS operation (i.e., locations 1 and 3), and determined that process 1 caused its MWCAS to fail. Therefore, process 0 has requested help from process 1 by setting HELP <ref> [0; 1] </ref> to (0; true).
Reference: 2. <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Multi-Object Operations", </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: This allows the helping mechanism to cancel MWCAS operations that are no longer required to complete. Conditionally wait-free implementations have advantages over both lock-free and wait-free ones. First, the only known wait-free implementation of MWCAS has substantial space requirements, and is not very efficient <ref> [2] </ref>. By dropping the wait-freedom requirement, significantly more efficient implementations can be derived [7, 10]. Unfortunately, however, lock-free MWCAS operations do not guarantee termination. Thus, they are not useful for wait-free implementations. <p> None of these wait-free constructions allow concurrent operations to execute in parallel. Thus, considering multiple objects as one means that operations are executed sequentially, even if they access different objects. In <ref> [2] </ref>, Anderson and Moir present a wait-free universal construction that allows operations to atomically access multiple objects, and allows operations that access disjoint sets of objects to execute in parallel. <p> If the procedure eventually returns true, then the MWCAS operation terminates (possibly returning "quit"). 3 This allows our wait-free helping mechanism to determine which processes need help, and to inform processes that they have been helped. Our MWCAS implementation is based on the wait-free implementation presented in <ref> [2] </ref>. However, because the implementation presented here is not required to be wait-free, it is significantly simpler and more efficient, and uses substantially less space than the implementation in [2]. The resulting implementation is quite similar to the STM implementation of Shavit and Touitou [10]. <p> Our MWCAS implementation is based on the wait-free implementation presented in <ref> [2] </ref>. However, because the implementation presented here is not required to be wait-free, it is significantly simpler and more efficient, and uses substantially less space than the implementation in [2]. The resulting implementation is quite similar to the STM implementation of Shavit and Touitou [10]. Specifically, in both implementations, a process first locks each of the words it accesses using load-linked (LL) and store-conditional (SC) instructions, and then, if successful, modifies each word in accordance with the implemented operation. <p> If, in attempting to lock its words, a process p finds a word already locked by another process q, then p attempts to help q to complete its operation. In contrast to the implementations of <ref> [2, 5, 7] </ref>, STM and the implementation presented here do not continue this helping recursively. That is, if p fails to complete q's operation because of another process r, then p does not start to help r, but instead causes q to start its operation again. <p> As mentioned above, this implementation is largely based on the wait-free implementation presented in <ref> [2] </ref>. Due to space limitations, we therefore concentrate on the differences between these two implementations here, and defer a more detailed description to the full paper. There are two differences in the way the MWCAS operation presented here is called. <p> First, in the implementation of <ref> [2] </ref>, when a process p successfully locks a memory location, it potentially interferes with a lock attempt by another process | say q. Therefore, to ensure wait-freedom, p must detect this possibility and "help" q to complete its operation. To allow this interference to be detected, the implementation in [2] employs <p> of <ref> [2] </ref>, when a process p successfully locks a memory location, it potentially interferes with a lock attempt by another process | say q. Therefore, to ensure wait-freedom, p must detect this possibility and "help" q to complete its operation. To allow this interference to be detected, the implementation in [2] employs an access matrix (called AM). This matrix, which has one position for every process-memory location pair, imposes a significant space overhead. Moreover, in order to detect processes that concurrently access a memory location, a process must read all N matrix positions associated with that memory location. <p> Because the wait-freedom requirement is relaxed here, the access matrix is no longer required. This results in substantial space savings as well as improved best-case performance. Most of the differences between the implementation presented here and the one in <ref> [2] </ref> are a result of these changes. Specifically, there is no longer any need for processes to record each word that they access, nor to help other processes with which they concurrently access words in common.
Reference: 3. <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Large Objects", </title> <booktitle> Proceedings of the Ninth International Workshop on Distributed Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: However, most synchronization primitives access a fixed set of locations, and can therefore be implemented using static transactions. (Israeli and Rappoport also presented lock-free constructions for multi-word synchronization primitives [7]; these constructions employ the costly recursive helping policy discussed above.) Most previous wait-free universal constructions <ref> [1, 3, 6] </ref> implement only one object: in order to use them to implement multiple objects and to allow operations to access multiple objects atomically, the objects must be considered as a single object. None of these wait-free constructions allow concurrent operations to execute in parallel. <p> This is because the objects to be accessed by these multi-object operations must be specified in advance; general implementations should not impose this restriction. Finally, efforts have been made to provide wait-free constructions that avoid excessive copying overhead <ref> [1, 3] </ref>, and that have time complexity that depends on contention, rather than on the number of processes [1, 4]. 1 However, none of these constructions allow operations to execute in parallel. 2 3 Conditionally Wait-Free MWCAS Implementation In this section we describe our conditionally wait-free MWCAS operation, which is used <p> MWCAS 1 The constructions presented in [4] are not strictly speaking wait-free: they are designed to tolerate k1 failures, where k is a user-tunable parameter. While contention for the object remains below k, these constructions are effectively wait-free. 2 Actually, the constructions in <ref> [3] </ref> do allow read-only operations to execute in parallel. extends CAS in the natural way by accessing multiple addresses atomically. The parameters to MWCAS are the number of words, a list of addresses, a list of old values, and a list of new values. <p> Following the terminology of Shavit and Touitou [10], this array is referred to hereafter as the transactional memory. The transactional memory is in fact represented by a series of B blocks, each of which contains S words. (A similar approach was used in <ref> [3] </ref>.) We assume that an upper bound T is known on the number of blocks that are modified by any transaction, and that there are N processes. Each process has T "copy blocks", which are used to replace modified array blocks.
Reference: 4. <author> J. Anderson and M. Moir, </author> <title> "Using Local-Spin k-Exclusion Algorithms to Improve Wait-Free Object Implementations", </title> <note> to appear in Distributed Computing. </note>
Reference-contexts: Finally, efforts have been made to provide wait-free constructions that avoid excessive copying overhead [1, 3], and that have time complexity that depends on contention, rather than on the number of processes <ref> [1, 4] </ref>. 1 However, none of these constructions allow operations to execute in parallel. 2 3 Conditionally Wait-Free MWCAS Implementation In this section we describe our conditionally wait-free MWCAS operation, which is used by the lock-free and wait-free transaction implementations presented in the following two sections. <p> The CAS operation fails, returning false, if the old value differs from the current value stored at the specified address. Otherwise, the CAS succeeds, modifying the value at the specified address to the new value, and returns true. MWCAS 1 The constructions presented in <ref> [4] </ref> are not strictly speaking wait-free: they are designed to tolerate k1 failures, where k is a user-tunable parameter.
Reference: 5. <author> G. Barnes, </author> <title> "A Method for Implementing Lock-Free Shared Data Structures", </title> <booktitle> Proceedings of the Fifth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1993. </year>
Reference-contexts: Furthermore, these constructions do not allow concurrent operations to execute in parallel. Below we briefly describe efforts to address these problems. Barnes <ref> [5] </ref> recognizes the importance of allowing operations to execute in parallel where possible. He presents a mechanism in which an object is protected by a number of locks. <p> If, in attempting to lock its words, a process p finds a word already locked by another process q, then p attempts to help q to complete its operation. In contrast to the implementations of <ref> [2, 5, 7] </ref>, STM and the implementation presented here do not continue this helping recursively. That is, if p fails to complete q's operation because of another process r, then p does not start to help r, but instead causes q to start its operation again.
Reference: 6. <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(5), </volume> <year> 1993. </year>
Reference-contexts: As a result, there is increasing interest in non-blocking synchronization, and in particular, lock-free and wait-free implementations of shared objects. To ease the burden on programmers in using lock-free and wait-free shared objects, Herlihy proposed universal constructions <ref> [6] </ref>. A lock-free (wait-free) universal construction converts a sequential implementation of any shared object into a lock-free (wait-free) one. We present new lock-free and wait-free universal constructions, which we believe represent important progress towards the use of non-blocking shared object implementations. <p> In Sections 4 and 5, respectively, we present our lock-free and wait-free transaction implementations. Finally, in Section 6, we conclude, and discuss future work. Due to space limitations, a formal treatment of our results is deferred to a full version of the paper. 2 Related Work In Herlihy's constructions <ref> [6] </ref>, operations copy the entire shared object, sometimes more than once. The space required for these copies, as well as the time spent copying, is prohibitive for larger objects. To address this problem, Herlihy also designed a universal construction for "large" objects. <p> However, most synchronization primitives access a fixed set of locations, and can therefore be implemented using static transactions. (Israeli and Rappoport also presented lock-free constructions for multi-word synchronization primitives [7]; these constructions employ the costly recursive helping policy discussed above.) Most previous wait-free universal constructions <ref> [1, 3, 6] </ref> implement only one object: in order to use them to implement multiple objects and to allow operations to access multiple objects atomically, the objects must be considered as a single object. None of these wait-free constructions allow concurrent operations to execute in parallel. <p> This implementation does not incur the high overhead of existing wait-free MWCAS implementations. Nonetheless, it ensures wait-freedom by synchronizing with a higher-level helping mechanism. Our wait-free helping mechanism is substantially simpler than the one employed in Herlihy's wait-free construction <ref> [6] </ref>. This simplification is achieved by taking advantage of the MWCAS operation to avoid potential race conditions, and hence the complicated techniques used by Herlihy for dealing with them.
Reference: 7. <author> A. Israeli and L. Rappoport, </author> <title> "Disjoint-Access-Parallel Implementations of Strong Shared Memory Primitives", </title> <booktitle> Proceedings of the 13th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1994. </year>
Reference-contexts: Conditionally wait-free implementations have advantages over both lock-free and wait-free ones. First, the only known wait-free implementation of MWCAS has substantial space requirements, and is not very efficient [2]. By dropping the wait-freedom requirement, significantly more efficient implementations can be derived <ref> [7, 10] </ref>. Unfortunately, however, lock-free MWCAS operations do not guarantee termination. Thus, they are not useful for wait-free implementations. <p> As a result, it is not well suited to implementing general shared objects. However, most synchronization primitives access a fixed set of locations, and can therefore be implemented using static transactions. (Israeli and Rappoport also presented lock-free constructions for multi-word synchronization primitives <ref> [7] </ref>; these constructions employ the costly recursive helping policy discussed above.) Most previous wait-free universal constructions [1, 3, 6] implement only one object: in order to use them to implement multiple objects and to allow operations to access multiple objects atomically, the objects must be considered as a single object. <p> If, in attempting to lock its words, a process p finds a word already locked by another process q, then p attempts to help q to complete its operation. In contrast to the implementations of <ref> [2, 5, 7] </ref>, STM and the implementation presented here do not continue this helping recursively. That is, if p fails to complete q's operation because of another process r, then p does not start to help r, but instead causes q to start its operation again. <p> In this case, process p causes process q to release all of its locks, and 4 A technique similar to this one was first proposed by Israeli and Rappoport <ref> [7] </ref>. 5 This algorithm uses Load-Linked (LL), Validate (VL), and Store-Conditional (SC) instructions. We recently proposed a slight modification to the way these instructions are used in order to accommodate practical implementations of the ideal semantics of these instructions using limited forms commonly available in hardware [8]. <p> We will also evaluate the effectiveness of various optimizations not included here. Our implementations allow nonconflicting transactions to execute in parallel. This property was formalized by Israeli and Rappoport <ref> [7] </ref>, who defined the notion of disjoint access parallel implementations.
Reference: 8. <author> M. Moir, </author> <title> "Practical Implementations of Synchronization Primitives", </title> <booktitle> to appear in the 16th Annual ACM Symposium on Principles of Distributed Computing. </booktitle>
Reference-contexts: We recently proposed a slight modification to the way these instructions are used in order to accommodate practical implementations of the ideal semantics of these instructions using limited forms commonly available in hardware <ref> [8] </ref>. <p> In reality, it may eventually wrap around. Our construction is correct assuming no version counter wraps around during one transaction. A similar assumption is made and defended in <ref> [8] </ref>. parameters for the MWCAS are generated, and MWCAS is invoked. If the MW--CAS succeeds, then the transaction is completed. Otherwise, the transactional memory is not affected, and the transaction can be retried. Our lock-free transaction implementation is shown in Fig. 4.
Reference: 9. <author> G. Pfister and V. Norton, </author> <title> "Hot Spot Contention and Combining in Multistage Interconnection Networks", </title> <journal> IEEE Transactions on Computing, </journal> <volume> C-34, 10, </volume> <year> 1985. </year>
Reference-contexts: However, our algorithms are somewhat complicated by our efforts to achieve this property. We believe that better performance might be achieved by foregoing this requirement, while still striving to ensure maximum concurrency and to avoid hot spots <ref> [9] </ref> arising from excessive contention for shared variables. Our implementations allow transactions to execute in parallel even if they do access common parts of the transactional memory, provided the commonly accessed parts are not modified by the transactions.
Reference: 10. <author> N. Shavit and D. Touitou, </author> <title> "Software Transactional Memory", </title> <booktitle> Proceedings of the 14th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: Conditionally wait-free implementations have advantages over both lock-free and wait-free ones. First, the only known wait-free implementation of MWCAS has substantial space requirements, and is not very efficient [2]. By dropping the wait-freedom requirement, significantly more efficient implementations can be derived <ref> [7, 10] </ref>. Unfortunately, however, lock-free MWCAS operations do not guarantee termination. Thus, they are not useful for wait-free implementations. <p> This can give rise to long chains of useless helping. Finally, Barnes's method is not wait-free. Shavit and Touitou <ref> [10] </ref> present a method called software transactional mem-ory (STM). Their approach allows transactions to be executed in a lock-free (but not wait-free) manner, and also allows multiple transactions to execute in parallel, provided that they do not interfere with each other. <p> Shavit and Touitou present performance studies which suggest that this difference improves performance significantly. One limitation of STM (as presented in <ref> [10] </ref>) is that it does not support dynamic transactions. As a result, it is not well suited to implementing general shared objects. <p> However, because the implementation presented here is not required to be wait-free, it is significantly simpler and more efficient, and uses substantially less space than the implementation in [2]. The resulting implementation is quite similar to the STM implementation of Shavit and Touitou <ref> [10] </ref>. Specifically, in both implementations, a process first locks each of the words it accesses using load-linked (LL) and store-conditional (SC) instructions, and then, if successful, modifies each word in accordance with the implemented operation. <p> Specifically, there is no longer any need for processes to record each word that they access, nor to help other processes with which they concurrently access words in common. The final difference arises from the use of non-redundant helping (as introduced by Shavit and Touitou <ref> [10] </ref>). Using this helping policy, a process attempts to help only one process before retrying its own operation. To see how lock-freedom can be achieved despite this lack of additional helping, suppose that while helping process q, process p encounters a word locked by a third process r (line 8). <p> Therefore, the implementation is lock-free. 4 Lock-Free Transaction Implementation In this section, we describe our lock-free transaction implementation. This implementation provides the transaction programmer with the illusion of a contiguous array, which contains all data to be accessed by transactions. Following the terminology of Shavit and Touitou <ref> [10] </ref>, this array is referred to hereafter as the transactional memory.
Reference: 11. <author> J. Turek, D. Shasha, and S. Prakash, </author> <title> "Locking Without Blocking: Making Lock Based Concurrent Data Structure Algorithms Non-Blocking", </title> <booktitle> Proceedings of the 11th Symposium on Principles of Database Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Operations on the object acquire the locks associated with affected parts of the object in such a way that processes can "help" each other to perform operations and release locks. (A similar technique was proposed by Turek, Shasha, and Prakash <ref> [11] </ref>.) This technique guarantees lock-freedom. Barnes's method accommodates "dynamic" transactions. (A transaction is static if the memory locations it accesses are known in advance, and dynamic otherwise.) Nonetheless, this method has several drawbacks.
References-found: 11

