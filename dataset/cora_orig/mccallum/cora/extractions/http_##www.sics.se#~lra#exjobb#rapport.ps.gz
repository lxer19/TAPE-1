URL: http://www.sics.se/~lra/exjobb/rapport.ps.gz
Refering-URL: http://www.sics.se/~lra/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Socially Controlled Global Agent Systems  Examiner Magnus Boman Institutionen for Data- och Systemvetenskap  
Author: Lars Rasmusson, D Datatekniklinjen Sverker Janson Stockholms Universitet/KTH 
Degree: Master's Thesis Supervisor  
Date: 16 August 1996  
Address: Stockholm, Sweden  
Affiliation: Kungl Tekniska Hogskolan  Swedish Institute of Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Robert Axelrod. </author> <title> The Evolution of Co-operation. </title> <publisher> Penguin Books, </publisher> <year> 1984. </year>
Reference-contexts: The fitness is decided by how much income an agent generates from dealing with other agents. The game theoretic prisoner's dilemma is fundamental to problems of cooperation and in this work. Early computer simulations of this problems were performed and documented in Axelrod <ref> [1] </ref>, where a detailed account of the problem also is given. Wellman [30, 29] and the collection edited by Clearwater [4] treats the new paradigm of using economic mechanisms for resource allocation. In this paper, a design economy for reputation is evaluated, and the outlines of yet another, are contributed. <p> The prisoner's dilemma (name coined by A. Tucker and made famous by R. Axelrod in <ref> [1] </ref>) is a non-cooperative, 2-person, non zero-sum game with two agents. The agents have to decide whether to cooperate or defect from a deal.
Reference: [2] <author> Magnus Boman and Love Ekenberg. </author> <title> Eliminating paraconsistencies in 4-valued cooperative deductive multidatabase systems with classical negation. </title> <booktitle> In CKBS-94, </booktitle> <address> Keele, UK, 1994. </address> <publisher> Keele University Press. </publisher>
Reference-contexts: Hence, the group of agents can not build up a reputation. Trust is only considered from a personal account. Another formalization of trust from the domain of evaluating choices based on imprecise information is developed by Boman et al. <ref> [2, 5] </ref>. Many authors have performed simulations of ecological systems. However, not many of them deal with trust in an explicit manner. There are however some that do. 4 Smucker, Stanley and Ashlock perform simulations of agents with fixed, genetically coded strategies [22].
Reference: [3] <author> E. Clarke. </author> <title> Multipart priciing of public goods. Public Choice, </title> <booktitle> 11 </booktitle> <pages> 17-23, </pages> <year> 1971. </year>
Reference-contexts: Some of the suggested protocols have very nice properties, but have constraints on the agent society that cannot be guaranteed in an open agent world. This problem is illustrated with the Clarke Tax. The Clarke Tax <ref> [3, 6] </ref> is a one-shot voting-by-bid mechanism for group decision making that eliminates the advantage of giving false information by maximizing each agent's expected payoff if it reveals its true preferences. A bid is the true utility for an agent of an alternative.
Reference: [4] <author> Scott H. Clearwater. </author> <title> Market-based Control, A Paradigm for Distributed Resource Allocation. </title> <publisher> World Scientific, </publisher> <address> Palo Alto, CA, </address> <year> 1996. </year>
Reference-contexts: The game theoretic prisoner's dilemma is fundamental to problems of cooperation and in this work. Early computer simulations of this problems were performed and documented in Axelrod [1], where a detailed account of the problem also is given. Wellman [30, 29] and the collection edited by Clearwater <ref> [4] </ref> treats the new paradigm of using economic mechanisms for resource allocation. In this paper, a design economy for reputation is evaluated, and the outlines of yet another, are contributed.
Reference: [5] <author> Love Ekenberg, Magnus Boman, and Mats Danielsson. </author> <title> A tool for coordinating autonomous agents with conflicting goals. </title> <booktitle> In Proceedings of ICMAS-95, </booktitle> <address> San Francisco, </address> <year> 1995. </year>
Reference-contexts: Hence, the group of agents can not build up a reputation. Trust is only considered from a personal account. Another formalization of trust from the domain of evaluating choices based on imprecise information is developed by Boman et al. <ref> [2, 5] </ref>. Many authors have performed simulations of ecological systems. However, not many of them deal with trust in an explicit manner. There are however some that do. 4 Smucker, Stanley and Ashlock perform simulations of agents with fixed, genetically coded strategies [22].
Reference: [6] <author> E. Ephrati, Gliad Zlotkin, and J.S. Rosenschein. </author> <title> Meet your destiny: A non-manipulable meeting scheduler. </title> <booktitle> In Conference on Computer Supported Cooperative Work, </booktitle> <address> North Carolina, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: In this paper, a design economy for reputation is evaluated, and the outlines of yet another, are contributed. Methods for economic incentive manipulation to promote cooperation for agents with conflicting goals, "mechanism design", are developed by Ephrati <ref> [6] </ref> and Rosenschein and Zlotkin [18, 19]. An example is given that shows that some of these mechanisms fail since they demand control over parameters that can not be controlled in an open system. <p> Some of the suggested protocols have very nice properties, but have constraints on the agent society that cannot be guaranteed in an open agent world. This problem is illustrated with the Clarke Tax. The Clarke Tax <ref> [3, 6] </ref> is a one-shot voting-by-bid mechanism for group decision making that eliminates the advantage of giving false information by maximizing each agent's expected payoff if it reveals its true preferences. A bid is the true utility for an agent of an alternative. <p> See Figure 2. Revealing true preferences is a dominant strategy, since an agent overstating its preferences might end up paying more that the obtained utility. Understating preferences to save tax will not be compensated by the loss in utility <ref> [6] </ref>. Reducing agent communication before the vote, as in Clarke Tax, can 11 A B A B tax a1 4 2 result without a1 6 9 0 a2 6 0 a2 4 11 0 ----------- no tax for a1. The same thing holds for a2.
Reference: [7] <author> A. Fiat and A. Shamir. </author> <title> How to prove yourself: Practical solutions to identification and signature problems. </title> <booktitle> In Proceedings of Crypto 86, </booktitle> <pages> pages 181-187, </pages> <address> Santa Barbara, </address> <year> 1986. </year>
Reference-contexts: An agent can be anonymous by creating a new identity for each time it presents itself. Unforgeable transferable identities are easy to create using zero knowledge protocols <ref> [7] </ref>. The most most difficult thing to account for is unstealability, especially if the agent is mobile and running on a remote computer. 3 The envisioned agent market consists of agents who supply services.
Reference: [8] <author> Leonard N. Foner. </author> <title> Clustering and information sharing in an ecology of cooperating agents, or, how to gossip without spilling the beans. </title>
Reference-contexts: Agents choose to cooperate or defect entirely based on the history of previous encounters. Foner discusses the problem of how agents can share private information without revealing the agent's identity <ref> [9, 8] </ref>. This is one of the few papers with cooperative dilemmas where agents actually share information. However, the shared information is not information about information sharing (trust, reputation) which is the issue below.
Reference: [9] <author> Leonard N. Foner. </author> <title> A multi-agent referral system for matchmaking. </title> <booktitle> In Proc. 1st Intl. Conference and Exhibition on Practical Applications of Intelligent Agents and Multi-Agent Technology, PAAM'96, </booktitle> <pages> pages 871-893, </pages> <address> London, UK, </address> <year> 1996. </year>
Reference-contexts: Agents choose to cooperate or defect entirely based on the history of previous encounters. Foner discusses the problem of how agents can share private information without revealing the agent's identity <ref> [9, 8] </ref>. This is one of the few papers with cooperative dilemmas where agents actually share information. However, the shared information is not information about information sharing (trust, reputation) which is the issue below. <p> Since taste is a subjective measure there is need for several competing reviewer agents. It is possible to use the reviewers as tools for finding and categorizing information. Variations to this idea is today tried for filtering Usenet news <ref> [9] </ref>. 4.5 Certifier agents INTM RET PROM SPRE REEM PGET PGIVE no yes no no no no yes If a seller actively wants to be tested and recommended, he can use a certifier agent.
Reference: [10] <author> B.A. Huberman. </author> <title> The Ecology of Computation. </title> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: The new properties of information markets are treated by Varian [25, 26]. In ecological systems it is the combined behaviour of oneself and the others that determines ones fitness and survival. Treating program systems as ecological systems and ascribing fitness values to programs is treated by Huberman <ref> [10] </ref>, and Miller and Drexler [14]. The models of agent societies developed in this text are all cast in terms of ecologies. The fitness is decided by how much income an agent generates from dealing with other agents. <p> All we need then is for the system to generate low payoffs to defecting agents. The system is a simple computational ecology <ref> [10] </ref> that, together with a computational economy [13], will wipe out defecting agents. This is simulated in the wb system described below. Fixed strategies are a too simple minded model to be used for real agent models.
Reference: [11] <author> Christen Krogh. </author> <title> The rights of agents. </title> <booktitle> In Intelligent Agents Volume II - Proceedings of the 1995 Workshop on Agent Theories, Architectures and Languages (ATAL-95), Lecture Notes in Artificial Intelligence. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Since it is postulated that these identities will be decoupled from the originator of the agent, the answer is that such tendencies will have to be fought by using anonymous electronic identities. Another question is how disagreements between agents should be settled. Krogh <ref> [11] </ref> proposes that agent systems should have normative legal systems that should be used when such matters have to be settled. Such rules need not be coded into the system, globally enforced. They could be enforced by (yet) another agent. It is a typical example of a trusted third part.
Reference: [12] <author> Steven P. Marsh. </author> <title> Formalizing Trust as a Computational Concept. </title> <type> PhD thesis, </type> <institution> University of Sterling, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: The Economic Times dedicated an issue to the connection between economic rationality and criminal behaviour [24]. The connection between rationality and crime is what makes it necessary to have social control even in computerized complex systems. A formalization of the concept of trust is described by Marsh <ref> [12] </ref>. His formalization is based simply on individual grounds, and social mechanisms are not considered. Hence, the group of agents can not build up a reputation. Trust is only considered from a personal account. <p> It does not seem to be a good idea to build Internet agent systems security on assumptions that communication between agents is impossible. 3.3 Reinforcement learning It is common to propose agents that learn the behaviour of the other agents and adapt themselves accordingly. Vidal [27], Marsh <ref> [12] </ref>, and others, use the approach of individual reinforcement learning. Reinforcement learning consists of modifying ones behaviour towards something through repeated interactions with it. A behaviour is amplified by a good result, and it is weakened by a bad result.
Reference: [13] <author> M.S. Miller and K.E. Drexler. </author> <title> Comparative ecology: A computational perspective. </title> <editor> In B.A. Huberman, editor, </editor> <booktitle> The Ecology of Computation. </booktitle> <publisher> North-Holland, </publisher> <year> 1988. </year> <month> 35 </month>
Reference-contexts: All we need then is for the system to generate low payoffs to defecting agents. The system is a simple computational ecology [10] that, together with a computational economy <ref> [13] </ref>, will wipe out defecting agents. This is simulated in the wb system described below. Fixed strategies are a too simple minded model to be used for real agent models. Firstly, the cost in terms of unsuccessful deals for obtaining a cooperating population is extremely high.
Reference: [14] <author> M.S. Miller and K.E. Drexler. </author> <title> Market and computation: Agoric open systems. </title> <editor> In B.A. Huberman, editor, </editor> <booktitle> The Ecology of Computation. </booktitle> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: In ecological systems it is the combined behaviour of oneself and the others that determines ones fitness and survival. Treating program systems as ecological systems and ascribing fitness values to programs is treated by Huberman [10], and Miller and Drexler <ref> [14] </ref>. The models of agent societies developed in this text are all cast in terms of ecologies. The fitness is decided by how much income an agent generates from dealing with other agents. The game theoretic prisoner's dilemma is fundamental to problems of cooperation and in this work. <p> Since the ordinary customers must be indistinguishable from the reviewer agents, they must also be able to act incognito. Miller and Drexler <ref> [14] </ref> state that for ideal critics reviews the buyer has a large incentive to be anonymous (otherwise he/she cannot trust reviews as a means to find good deals), and the (non-malicious) seller has every reason to prove his identity to the buyers.
Reference: [15] <author> Eric Rasmusen. </author> <title> Games and Information. </title> <publisher> Blackwell, </publisher> <year> 1989. </year>
Reference-contexts: This text focuses on security problems caused by inter-agent actions. Agents that behave in such a way that they "steal" money from other agents without delivering something in return are said to have a "criminal" behavior. This be-haviour may be analyzed in a partly game theoretic way <ref> [15] </ref>. This approach is 3 taken below in calculations and reasonings of the expected payoff for different strategies.
Reference: [16] <author> Andreas Rasmusson. </author> <title> Personal security assistant for secure internet commerce. Accepted paper at the New Security Paradigms Workshop '96, </title> <year> 1996. </year>
Reference: [17] <author> Lars Rasmusson and Sverker Janson. </author> <title> Simulated social control for secure internet commerce. Accepted paper at the New Security Paradigms Workshop '96, </title> <note> 1996. URL: http://www.sics.se/~lra/ex-jobb/simsoccontr/simsoccontr.html. </note>
Reference-contexts: Section 9 introduces some ideas of a generalized service combiner agent from which many of the social control agents can be derived as special cases. The text is closed in section 10 with some comments on the legal status of agents to questions raised in a previous paper <ref> [17] </ref> in section 10. 1.6 Method The method for studying socially controlled systems is to see them as ecological systems with agents with private goals and governed by economic laws. Computer simulation of the systems have been performed. <p> The interesting thing is that it seems as if mechanism two converges towards the same equilibrium, albeit at a slower rate. rendez-vous mechanisms. 8 A commerce simulation workbench This section describes the initial implementation of a market governed completely by local decision rules. This is also described in <ref> [17] </ref>. To get some intuitive understanding of the global behaviour of strictly local behaviour rules, an experimental platform was set up. The system is called simwb and can be found at http://www.sics.se/~lra/simwb on the world wide web. Here is a short description of the system. <p> Below I repeat some of the experimental results from <ref> [17] </ref> together with new comments. 8.1.2 Simulation: one room, random choice Running a simulation in a one-room world with mostly good sellers where buyers randomly picks one of the sellers, we find that bad sellers who are charging a high price and giving a low value in return will make the
Reference: [18] <author> J. S. Rosenschein and G. Zlotkin. </author> <title> Rules of Encounter: Desiging Conventions for Automated Negotiation among Computers. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: In this paper, a design economy for reputation is evaluated, and the outlines of yet another, are contributed. Methods for economic incentive manipulation to promote cooperation for agents with conflicting goals, "mechanism design", are developed by Ephrati [6] and Rosenschein and Zlotkin <ref> [18, 19] </ref>. An example is given that shows that some of these mechanisms fail since they demand control over parameters that can not be controlled in an open system. <p> Viruses that have something useful to offer should of course be allowed to execute. They are not different from any other agent. 3.2 Clarke tax There is active work in the area of generating negotiation protocols that remove the incentive to defect <ref> [18] </ref>. Sandholm [20] uses the Contract Net protocol for trade of goods. Auctions such as the Vickrey auction [26] are designed to promote sharing of true information.
Reference: [19] <author> Jeffrey S. Rosenschein and Gilad Zlotkin. </author> <title> Consenting agents: Designing conventions for automated negotiation. </title>
Reference-contexts: In this paper, a design economy for reputation is evaluated, and the outlines of yet another, are contributed. Methods for economic incentive manipulation to promote cooperation for agents with conflicting goals, "mechanism design", are developed by Ephrati [6] and Rosenschein and Zlotkin <ref> [18, 19] </ref>. An example is given that shows that some of these mechanisms fail since they demand control over parameters that can not be controlled in an open system.
Reference: [20] <author> Tuomas Sandholm. Traconet: </author> <title> An implementation of the contract net protocol based on marginal cost calculations. Group Decision and Negotiation, </title> <note> in preparation, </note> <year> 1996. </year>
Reference-contexts: Viruses that have something useful to offer should of course be allowed to execute. They are not different from any other agent. 3.2 Clarke tax There is active work in the area of generating negotiation protocols that remove the incentive to defect [18]. Sandholm <ref> [20] </ref> uses the Contract Net protocol for trade of goods. Auctions such as the Vickrey auction [26] are designed to promote sharing of true information. Some of the suggested protocols have very nice properties, but have constraints on the agent society that cannot be guaranteed in an open agent world.
Reference: [21] <author> Tuomas Sandholm and V. Lesser. </author> <title> Equilibrium analysis of the possibilities of unenforced exchange in multiagent systems. </title> <address> Montreal, Canada, </address> <year> 1995. </year> <booktitle> 14th International Joint Conference on Artificial Intelligence (IJCAI-95). </booktitle>
Reference-contexts: Sandholm proposes a method to split large deals into smaller ones that each leave the future gain larger than the gain of defecting <ref> [21] </ref>. Not all problems however are suited for such division. The Economic Times dedicated an issue to the connection between economic rationality and criminal behaviour [24]. The connection between rationality and crime is what makes it necessary to have social control even in computerized complex systems.
Reference: [22] <author> Mark D. Smucker, E. Ann Stanley, and Dan Ashlock. </author> <title> Analyzing social network structures in the iterated prisoner's dilemma with choice and refusal. </title> <type> Technical Report CS-TR-94-1259, </type> <institution> Dept. of Computer Sciences, University of Wisconsin-Madison, </institution> <year> 1994. </year>
Reference-contexts: Many authors have performed simulations of ecological systems. However, not many of them deal with trust in an explicit manner. There are however some that do. 4 Smucker, Stanley and Ashlock perform simulations of agents with fixed, genetically coded strategies <ref> [22] </ref>. Agents choose to cooperate or defect entirely based on the history of previous encounters. Foner discusses the problem of how agents can share private information without revealing the agent's identity [9, 8]. This is one of the few papers with cooperative dilemmas where agents actually share information. <p> In agent systems, people are free to introduce new agents all the time. Agents do not have to wait for evolutionary processes to be created. Therefore, the system should also be stable with respect to such agents. Evolutionary systems have been found to be metastable <ref> [22] </ref>, meaning that the population cycles through a set of different configurations. Metastability is also applicable to agent systems, but it is unclear what happens to the metastability if external actors are monitoring the system's state and manipulate it accordingly. <p> Their salary would be the income their agents generated. The most needed agents get a large market, making them economically interesting to write, but will also meet competition. Metastability means that an ecologic system cycles through a number of different population configurations <ref> [22] </ref>. It can happen if the strategies of the agents are like in the "paper-stone-scissors" game (i.e. no dominant strategy).
Reference: [23] <author> Ken Steiglitz, Hichael L. Honig, and Leonard M. Cohen. </author> <title> A computational market model based on individual action. </title> <editor> In Scott H. Clearwater, editor, </editor> <title> Market-based Control, A Paradigm for Distributed Resource Allocation, chapter 1. </title> <publisher> World Scientific, </publisher> <address> Palo Alto, CA, </address> <year> 1996. </year>
Reference-contexts: Not so many buyers have to go bankrupt. 9 Arbitrage agents Arbitrage means making money by buying something cheap and selling it expensive. This section discusses the use of arbitrage agents as a means to combine and extend the range of services offered by agents. In Steiglitz et al. <ref> [23] </ref> the authors describe a market where price and demand affect each other. Agents can choose to dig gold or to bake bread and they decide every day which task they will perform. If the price of bread goes up, agents will start baking bread.
Reference: [24] <editor> Economic Times. </editor> <booktitle> The economics of crime, 1995. </booktitle> <volume> Vol. 4, No. </volume> <pages> 1. </pages>
Reference-contexts: Sandholm proposes a method to split large deals into smaller ones that each leave the future gain larger than the gain of defecting [21]. Not all problems however are suited for such division. The Economic Times dedicated an issue to the connection between economic rationality and criminal behaviour <ref> [24] </ref>. The connection between rationality and crime is what makes it necessary to have social control even in computerized complex systems. A formalization of the concept of trust is described by Marsh [12]. His formalization is based simply on individual grounds, and social mechanisms are not considered. <p> A typical system might support one per cent defection. Hopefully it will not do as badly as a human system like the USA tax system, estimated by the IRS to have a failure of total compliance of ninety per cent <ref> [24] </ref>! Simply running ecological simulations and watching the obtained equilibrium is not sufficient to analyse an agent system. At equilibrium, the system should be frozen, and we should calculate which agent strategy that can get 18 maximum profit.
Reference: [25] <author> Hal R. </author> <title> Varian. Buying, sharing and renting information goods. </title> <month> November </month> <year> 1995. </year>
Reference-contexts: The incentive for criminal behavior is considered to be calculable, and rational agents are expected to try to maximize their gain. 1.4 Related work An literature review over software agents can be found in Wooldridge Jennings [31]. The new properties of information markets are treated by Varian <ref> [25, 26] </ref>. In ecological systems it is the combined behaviour of oneself and the others that determines ones fitness and survival. Treating program systems as ecological systems and ascribing fitness values to programs is treated by Huberman [10], and Miller and Drexler [14].
Reference: [26] <author> Hal R. </author> <title> Varian. Economic mechanism design for computerized agents. </title> <booktitle> USENIX Workshop on Electronic Commerce, </booktitle> <address> New York, NY, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: The incentive for criminal behavior is considered to be calculable, and rational agents are expected to try to maximize their gain. 1.4 Related work An literature review over software agents can be found in Wooldridge Jennings [31]. The new properties of information markets are treated by Varian <ref> [25, 26] </ref>. In ecological systems it is the combined behaviour of oneself and the others that determines ones fitness and survival. Treating program systems as ecological systems and ascribing fitness values to programs is treated by Huberman [10], and Miller and Drexler [14]. <p> They are not different from any other agent. 3.2 Clarke tax There is active work in the area of generating negotiation protocols that remove the incentive to defect [18]. Sandholm [20] uses the Contract Net protocol for trade of goods. Auctions such as the Vickrey auction <ref> [26] </ref> are designed to promote sharing of true information. Some of the suggested protocols have very nice properties, but have constraints on the agent society that cannot be guaranteed in an open agent world. This problem is illustrated with the Clarke Tax.
Reference: [27] <author> Jose M. Vidal. </author> <title> Maintaining quality of service in economic multi-agent systems. </title> <institution> University of Michigan, </institution> <address> MI, </address> <month> April </month> <year> 1996. </year> <month> 36 </month>
Reference-contexts: This is one of the few papers with cooperative dilemmas where agents actually share information. However, the shared information is not information about information sharing (trust, reputation) which is the issue below. Vidal uses equilibrium theory and computer simulations of agents that can choose between defection and cooperation <ref> [27, 28] </ref>. The dilemma they study is whether a seller who has received money will provide the buyer with the goods which is a central dilemma also in this text. Vidal's agents have zero, one or two level models of their agents. <p> It does not seem to be a good idea to build Internet agent systems security on assumptions that communication between agents is impossible. 3.3 Reinforcement learning It is common to propose agents that learn the behaviour of the other agents and adapt themselves accordingly. Vidal <ref> [27] </ref>, Marsh [12], and others, use the approach of individual reinforcement learning. Reinforcement learning consists of modifying ones behaviour towards something through repeated interactions with it. A behaviour is amplified by a good result, and it is weakened by a bad result.
Reference: [28] <author> Jose M. Vidal and Edmund H. Durfee. </author> <title> Building agent models in economic societies of agents. </title> <institution> University of Michigan, </institution> <address> MI, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: This is one of the few papers with cooperative dilemmas where agents actually share information. However, the shared information is not information about information sharing (trust, reputation) which is the issue below. Vidal uses equilibrium theory and computer simulations of agents that can choose between defection and cooperation <ref> [27, 28] </ref>. The dilemma they study is whether a seller who has received money will provide the buyer with the goods which is a central dilemma also in this text. Vidal's agents have zero, one or two level models of their agents. <p> The quality of a social system should measure how close it approaches a system wide optimization of the resource transfers. Further, the system has to be able to work well with dynamic changes within itself. The quota of exploration and exploitation <ref> [28] </ref> tells us how willing the agents are to try new solutions or stick to old, safe solutions. If new agents are added, if agents disappear or if agents change their behavior, the system has to adjust itself without inflicting large costs on the agents. <p> Often it is substituted by a statistical probability of defection, like in Vidal's one-level model <ref> [28] </ref>. If this is calculated by a reinforcement learning algorithm where the learning rate is decreased, the sellers have an initial incentive to cooperate, but as the learning rate approaches zero, the sellers can defect safely, without the buyers stopping from requesting them.
Reference: [29] <author> Michael P. Wellman. </author> <title> A computational market model for distributed configuration design. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <address> Seattle, WA, </address> <month> August </month> <year> 1994. </year> <note> AAAI. </note>
Reference-contexts: The game theoretic prisoner's dilemma is fundamental to problems of cooperation and in this work. Early computer simulations of this problems were performed and documented in Axelrod [1], where a detailed account of the problem also is given. Wellman <ref> [30, 29] </ref> and the collection edited by Clearwater [4] treats the new paradigm of using economic mechanisms for resource allocation. In this paper, a design economy for reputation is evaluated, and the outlines of yet another, are contributed. <p> The incentive to defect is small if the net payoff for defection is lower than the net payoff for cooperation. 10 3.1 Computational economies The interesting idea of market-oriented programming and how to create design economies in the WALRAS system is described by Wellman in <ref> [29] </ref>. In their model the market is a tool for resource allocation, and it is argued that every computational problem can be transformed into one of resource allocation [30]. The agents' only means of communication is the trade of goods, in a protocol of iterated revealing of preference functions.
Reference: [30] <author> Michael P. Wellman. </author> <title> The economic approach to artificial intelligence. </title> <booktitle> ACM Computing Surveys Symposium, </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: The game theoretic prisoner's dilemma is fundamental to problems of cooperation and in this work. Early computer simulations of this problems were performed and documented in Axelrod [1], where a detailed account of the problem also is given. Wellman <ref> [30, 29] </ref> and the collection edited by Clearwater [4] treats the new paradigm of using economic mechanisms for resource allocation. In this paper, a design economy for reputation is evaluated, and the outlines of yet another, are contributed. <p> In their model the market is a tool for resource allocation, and it is argued that every computational problem can be transformed into one of resource allocation <ref> [30] </ref>. The agents' only means of communication is the trade of goods, in a protocol of iterated revealing of preference functions.
Reference: [31] <author> Michael Wooldridge and Nicholas R. Jennings. </author> <title> Intelligent agents: </title> <journal> Theory and practice. </journal> <note> Submitted to Knowledge Engineering Review, </note> <year> 1995. </year> <title> 37 Invited extended abstract for a panel discussion at the 19th National Infor--mation Systems Service Conference in Baltimore MA, </title> <note> in October 1996. Coauthored with Andreas Rasmusson and Sverker Janson. </note>
Reference-contexts: The incentive for criminal behavior is considered to be calculable, and rational agents are expected to try to maximize their gain. 1.4 Related work An literature review over software agents can be found in Wooldridge Jennings <ref> [31] </ref>. The new properties of information markets are treated by Varian [25, 26]. In ecological systems it is the combined behaviour of oneself and the others that determines ones fitness and survival.
References-found: 31

