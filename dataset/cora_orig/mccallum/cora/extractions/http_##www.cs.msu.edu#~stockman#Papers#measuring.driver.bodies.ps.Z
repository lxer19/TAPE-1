URL: http://www.cs.msu.edu/~stockman/Papers/measuring.driver.bodies.ps.Z
Refering-URL: http://www.cs.msu.edu/~stockman/pubs.html
Root-URL: http://www.cs.msu.edu
Title: Measuring Body Points on Automobile Drivers using Multiple Cameras  
Author: George Stockman, Jin-Long Chen, and Yuntao Cui Herbert Reynolds 
Date: July 5, 1996  
Address: East Lansing, MI 48824  
Affiliation: Computer Science Department  Biomechanics Department Michigan State University  
Abstract: Methods are given for measuring 3D points on human drivers of automobiles. Points are natural body features marked by special targets placed on the body. The measurements are needed for improved comfort and accomodation in automotive seat design. The measurement methods required hardware instrumentation in the automobile and development of algorithms for off-line processing of the acquired data. This paper describes the use of multiple cameras to measure 3D locations within the driver's workspace. Results obtained show that measurement error in X,Y, and Z coordinates is expected to be less than 1.0mm on the lab bench and 2.0mm in the car, and that combined 3D error is expected to be less than 2.0mm and 3.0mm respectively. fl This work was supported by research sponsored by Delphi Interior and Lighting Systems, General Motors Corporation 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. A. Adams and W. C. Hutton. </author> <title> The effect of posture on the lumbar spine. </title> <journal> Journal of Bone and Joint Surgery, </journal> <volume> 67-B(4):625-629, </volume> <year> 1985. </year>
Reference-contexts: Using the external body feature points we estimate the 3D position of the skeletal geometry of the vehicle operator. The position of the operator's skeleton defines the structure of posture that others <ref> [1, 9] </ref> have identified as a primary source of discomfort and fatigue in the operator. The targets described in this paper were, therefore, placed on the skin surface over skeletal landmarks that define the skeletal linkage system.
Reference: [2] <author> S. T. Barnard and M. A. Fischler. </author> <title> Computational stereo. </title> <journal> Computing Surveys, </journal> <volume> 14, </volume> <month> December </month> <year> 1982. </year>
Reference-contexts: Section 3 discusses the methods used to compute the 3D location of feature points visible in the images. 2.4 Related Background Multiple camera stereo has been the most commonly studied passive method for obtaining 3D scene data; <ref> [4, 2, 12, 8, 11] </ref> are representative samples of a large literature. The recent work by Jain et al [11] contains an excellent review of various solutions for the external and interior camera orientation 6 cushion. problems and for stereo system calibration. <p> Coordinates of the P i are in the global frame of the car, as defined by the driver seat mounts, so that both body structure and pose in the car can be computed from these same measurements. We adopted the general stereo approach <ref> [2, 8, 11] </ref>, where 3D coordinates are computed by observing the same feature point P i in two or more 2D images from cameras that are calibrated to the 3D workspace.
Reference: [3] <author> Y.T. Cui, J. Weng, and H. Reynolds. </author> <title> Optimal parameter estimation of ellipses. </title> <booktitle> In Proc. 8th Int. Conf. on Image Analysis and Processing, </booktitle> <address> Sanremo, Italy, </address> <month> Sep </month> <year> 1995, 1995. </year>
Reference-contexts: This effect only holds for a planar circular feature parallel to the image plane or for our spherical calibration beads which project a circle in any direction. An iterative ellipse fitting routine has been developed <ref> [3] </ref> to find the parameters of the best ellipse fitting boundary points of an elliptical region. The 3DAQ user has this option in defining image feature points.
Reference: [4] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: Section 3 discusses the methods used to compute the 3D location of feature points visible in the images. 2.4 Related Background Multiple camera stereo has been the most commonly studied passive method for obtaining 3D scene data; <ref> [4, 2, 12, 8, 11] </ref> are representative samples of a large literature. The recent work by Jain et al [11] contains an excellent review of various solutions for the external and interior camera orientation 6 cushion. problems and for stereo system calibration. <p> A reasonable location for the assumed intersection of skewed, but almost intersecting, lines can be defined as the midpoint of the shortest line segment connecting the two rays ( <ref> [4] </ref> Ch 10.6 or [8] Ch 14.6 ). Throughout the rest of this paper, we refer to this computation as intersecting the two rays. To combat the sources of error, we utilize multiple pairs of images to obtain multiple estimates for each scene point. <p> An approximation to the object point lies midway between two projecting rays at their point of closest approach, i.e. the midpoint of their common perpendicular. This midpoint can be computed in closed form using the method given by Duda and Hart <ref> [4] </ref> Section 10.6. If the rays are not close enough in approach, the computation can be discarded. If the accuracy of the two rays is different, the estimate can be moved closer to the more accurate ray as shown in the section below discussing error.
Reference: [5] <author> J. Fryer and D. Brown. </author> <title> Lens distortion for close-range photogrammetry. </title> <journal> Photogramm. Eng. and Remote Sensing, </journal> <volume> 52(1) </volume> <pages> 51-58, </pages> <year> 1986. </year>
Reference-contexts: We compensate for much of the nonlinear distortion by warping the image as needed to create the expected image of a grid; however, other distortions may still be present. For example, it is known that lens distortion varies with change of temperature and focusing <ref> [5] </ref>. Often, the 2D residuals resulting from camera calibration are of the order of 0.5 pixels even for calibration points. * Location of feature points in the image are subject to quantization errors and other effects in defining them. The auto-iris lens can blur the image features.
Reference: [6] <author> A. Goshtasby. </author> <title> Correction of image deformation from lens distortion using Bezier patches. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 47 </volume> <pages> 385-394, </pages> <year> 1989. </year>
Reference-contexts: Tsai [20] and Jain et al [11] describe techniques for correcting radial distortion. Basically, each image point is corrected by moving it along a radial from the image center an amount proportional to the square of its distance from the image center. We used the method described by Goshtasby <ref> [6] </ref> which can remove even nonsymmetrical distortions by providing parameters for local regions of the image. Goshtasby's method accounts for both radial distortion and also the tangential distortion which results from decentering the lens elements. <p> Each camera is used to acquire an image of a 12 13 checkerboard of precise black and white squares. Corners of the squares are automatically located in the image by an edge detection procedure that searches outward from the center square of the image. As in <ref> [6] </ref>, two lookup tables are produced which are used to smoothly map distorted image coordinates into corrected image coordinates. The tables are then used to warp all of the images taken by that particular camera/lens. <p> The four cameras were set up and the distortion mapping was computed for each before placing the camera in the car. All images would be warped using the appropriate look-up tables from Goshtasby's method before use in any further analysis <ref> [6] </ref>. The special jig was placed in the driver seat mounting and the centers of all calibration beads were located using a coordinate measuring device. Each of the four cameras were calibrated from images of the jig given to the 3DAQ program.
Reference: [7] <author> Ernest L. Hall, James K. B. Tio, Charles A. McPherson, and Firooz A. Sadjadi. </author> <title> Measuring Curved Surfaces for Robot Vision. </title> <journal> COMPUTER, </journal> <volume> 15(12) </volume> <pages> 42-54, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: y i 1 7 7 7 7 = 6 6 4 c 21 c 22 c 23 c 24 3 7 7 2 6 6 6 4 y i 1 7 7 7 7 Derivation of the camera matrix from a well-known calibration procedure is described by Hall et al <ref> [7] </ref> and Jain et al, [11]. The eleven unknown parameters of C can, in theory, be determined by knowing the 3D workspace coordinates [x i ; y i ; z i ] t and 2D image coordinates [u i ; v i ] t for 6 feature points.
Reference: [8] <author> R. Haralick and L. Shapiro. </author> <title> Computer and Robot Vision. </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year> <month> 24 </month>
Reference-contexts: Section 3 discusses the methods used to compute the 3D location of feature points visible in the images. 2.4 Related Background Multiple camera stereo has been the most commonly studied passive method for obtaining 3D scene data; <ref> [4, 2, 12, 8, 11] </ref> are representative samples of a large literature. The recent work by Jain et al [11] contains an excellent review of various solutions for the external and interior camera orientation 6 cushion. problems and for stereo system calibration. <p> Coordinates of the P i are in the global frame of the car, as defined by the driver seat mounts, so that both body structure and pose in the car can be computed from these same measurements. We adopted the general stereo approach <ref> [2, 8, 11] </ref>, where 3D coordinates are computed by observing the same feature point P i in two or more 2D images from cameras that are calibrated to the 3D workspace. <p> A reasonable location for the assumed intersection of skewed, but almost intersecting, lines can be defined as the midpoint of the shortest line segment connecting the two rays ( [4] Ch 10.6 or <ref> [8] </ref> Ch 14.6 ). Throughout the rest of this paper, we refer to this computation as intersecting the two rays. To combat the sources of error, we utilize multiple pairs of images to obtain multiple estimates for each scene point. <p> Residuals in camera calibration are of the order of 0.5 pixels in size. 16 Subpixel accuracy for image points Haralick and Shapiro <ref> [8] </ref>, in Chapter 20 of Volume II, show how to reduce quantization error by using the centroid of a circular disk as the feature point.
Reference: [9] <author> T. M. Hosea, S. Simon, J. Dlatizky, M. Wong, and C-C Hsieh. </author> <title> Myoelectric analysis of the paraspinal musculature in relation to automobile driving. </title> <journal> Spine, </journal> <volume> 11(9) </volume> <pages> 928-936, </pages> <year> 1986. </year>
Reference-contexts: Using the external body feature points we estimate the 3D position of the skeletal geometry of the vehicle operator. The position of the operator's skeleton defines the structure of posture that others <ref> [1, 9] </ref> have identified as a primary source of discomfort and fatigue in the operator. The targets described in this paper were, therefore, placed on the skin surface over skeletal landmarks that define the skeletal linkage system.
Reference: [10] <author> P. Cohen J. Weng and N. Rebibo. </author> <title> Motion and structure estimation from stereo image sequences. </title> <journal> IEEE Trans. on Robotics and Automation, </journal> <volume> 8 </volume> <pages> 362-382, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: Procedures are available for calibrating both image warping parameters and perspective model parameters in a single step: see, for example, the work of Tsai and Weng et al <ref> [20, 10] </ref>.
Reference: [11] <author> R. Jain, R. Kasturi, and B. Schunck. </author> <title> Machine Vision. </title> <publisher> McGraw-Hill, </publisher> <year> 1995. </year>
Reference-contexts: Section 3 discusses the methods used to compute the 3D location of feature points visible in the images. 2.4 Related Background Multiple camera stereo has been the most commonly studied passive method for obtaining 3D scene data; <ref> [4, 2, 12, 8, 11] </ref> are representative samples of a large literature. The recent work by Jain et al [11] contains an excellent review of various solutions for the external and interior camera orientation 6 cushion. problems and for stereo system calibration. <p> The recent work by Jain et al <ref> [11] </ref> contains an excellent review of various solutions for the external and interior camera orientation 6 cushion. problems and for stereo system calibration. <p> Coordinates of the P i are in the global frame of the car, as defined by the driver seat mounts, so that both body structure and pose in the car can be computed from these same measurements. We adopted the general stereo approach <ref> [2, 8, 11] </ref>, where 3D coordinates are computed by observing the same feature point P i in two or more 2D images from cameras that are calibrated to the 3D workspace. <p> 7 7 = 6 6 4 c 21 c 22 c 23 c 24 3 7 7 2 6 6 6 4 y i 1 7 7 7 7 Derivation of the camera matrix from a well-known calibration procedure is described by Hall et al [7] and Jain et al, <ref> [11] </ref>. The eleven unknown parameters of C can, in theory, be determined by knowing the 3D workspace coordinates [x i ; y i ; z i ] t and 2D image coordinates [u i ; v i ] t for 6 feature points. <p> An excellent survey of methods for determining the parameters of camera orientation is given by Jain et al <ref> [11] </ref>: the method which we used is described in Section 12.10.2. This method does not enforce the constraints of an orthonormal rotation matrix; however, a more general linear transformation can be modeled which allows certain assumptions about camera geometry to be relaxed. <p> Tsai [20] and Jain et al <ref> [11] </ref> describe techniques for correcting radial distortion. Basically, each image point is corrected by moving it along a radial from the image center an amount proportional to the square of its distance from the image center.
Reference: [12] <author> R. A. Jarvis. </author> <title> A Perspective on Range Finding Techniques for Computer Vision. </title> <address> IEEE-PAMI, PAMI-5(2):122-139, </address> <year> 1983. </year>
Reference-contexts: Section 3 discusses the methods used to compute the 3D location of feature points visible in the images. 2.4 Related Background Multiple camera stereo has been the most commonly studied passive method for obtaining 3D scene data; <ref> [4, 2, 12, 8, 11] </ref> are representative samples of a large literature. The recent work by Jain et al [11] contains an excellent review of various solutions for the external and interior camera orientation 6 cushion. problems and for stereo system calibration. <p> Measurement approaches using active illumination such as LIDAR <ref> [12] </ref>, which are very popular 7 in industry, are unusable because the lighting would annoy or harm the driver. Moreover, they would not be capable of producing video, nor would they be likely to improve measurement accuracy on the fiducial points.
Reference: [13] <author> G. Johansson. </author> <title> Perception of motion and changing form. </title> <journal> Scandanavian Journal of Psychology, </journal> <volume> 5 </volume> <pages> 181-208, </pages> <year> 1964. </year>
Reference-contexts: Moreover, they would not be capable of producing video, nor would they be likely to improve measurement accuracy on the fiducial points. Following the early research of Johansson, some systems use active points of illumination attached to the body <ref> [13] </ref> in order to simplify the identification of such points in the 2D images and to significantly compress the output. We decided early on that we wanted to be able to study full images of the driver.
Reference: [14] <author> I. Kakadiaris, D. Metaxas, and R. Bajscy. </author> <title> Active part-decomposition, shape and motion estimation of articulated objects: A physics-based approach. </title> <booktitle> In IEEE Comp. Vision and Pattern Rec., </booktitle> <address> Seattle, Wash., </address> <month> Jun 21-23 </month> <year> 1994. </year>
Reference-contexts: We decided early on that we wanted to be able to study full images of the driver. However, we do use tight-fitting body suits with specially reflective fiducial points (see Figure 1). Research has appeared very recently which has future potential for our problem <ref> [16, 14, 15] </ref>. Some success has been achieved in fitting rich articulated and deformable models to a sequence of images so that both structure and motion can be estimated.
Reference: [15] <author> K.Rohr. </author> <title> Towards model-based recognition of human movements in image sequences. </title> <journal> CVGIP: IU, </journal> <volume> 59(1) </volume> <pages> 94-115, </pages> <year> 1994. </year>
Reference-contexts: We decided early on that we wanted to be able to study full images of the driver. However, we do use tight-fitting body suits with specially reflective fiducial points (see Figure 1). Research has appeared very recently which has future potential for our problem <ref> [16, 14, 15] </ref>. Some success has been achieved in fitting rich articulated and deformable models to a sequence of images so that both structure and motion can be estimated.
Reference: [16] <author> A. Pentland. </author> <title> Automatic extraction of deformable part models. </title> <journal> Int. J. of Computer Vision, </journal> <volume> 4 </volume> <pages> 107-126, </pages> <year> 1990. </year>
Reference-contexts: We decided early on that we wanted to be able to study full images of the driver. However, we do use tight-fitting body suits with specially reflective fiducial points (see Figure 1). Research has appeared very recently which has future potential for our problem <ref> [16, 14, 15] </ref>. Some success has been achieved in fitting rich articulated and deformable models to a sequence of images so that both structure and motion can be estimated.
Reference: [17] <author> H. M. Reynolds. Erect, </author> <title> neutral and slump sitting postures; a study of the torso linkage system from shoulder to hip joint. </title> <type> Technical Report AL/CL-TR-1994-0151, USAF, </type> <institution> Air Force Material Command, Wright-Patterson Air Force Base, Dayton, Ohio, </institution> <year> 1994. </year>
Reference-contexts: Finding corresponding points automatically is possible and will be considered in the future when more development time is available. In previous work, Reynolds et al. computed internal location of various skeletal points by using stereo x-rays of cadavers with tungsten-carbide spheres inserted as feature points <ref> [18, 17] </ref>. Veress et al [21] and others [19] have shown that the stereophotogrammetric RMS accuracy is 0.1 to 0.4 mm using well-defined targets, such as the tungsten carbide spheres. In studies of living subjects who are not part of a medical investigation, implanting tungsten carbide spheres is impractical.
Reference: [18] <author> H. M. Reynolds, R. Halgren, and J. Marcus. </author> <title> Systems anthropometry: Development of a stereoradiographic measurement system. </title> <journal> J. Biomechanics, </journal> <volume> 2(4) </volume> <pages> 229-233, </pages> <year> 1982. </year>
Reference-contexts: Finding corresponding points automatically is possible and will be considered in the future when more development time is available. In previous work, Reynolds et al. computed internal location of various skeletal points by using stereo x-rays of cadavers with tungsten-carbide spheres inserted as feature points <ref> [18, 17] </ref>. Veress et al [21] and others [19] have shown that the stereophotogrammetric RMS accuracy is 0.1 to 0.4 mm using well-defined targets, such as the tungsten carbide spheres. In studies of living subjects who are not part of a medical investigation, implanting tungsten carbide spheres is impractical.
Reference: [19] <author> G. Selvick, P. Alberius, , and A. Aronson. </author> <title> The effect of posture on the lumbar spine. </title> <journal> Acta Rad. Diag., </journal> <volume> 24(4) </volume> <pages> 343-352, </pages> <year> 1994. </year>
Reference-contexts: In previous work, Reynolds et al. computed internal location of various skeletal points by using stereo x-rays of cadavers with tungsten-carbide spheres inserted as feature points [18, 17]. Veress et al [21] and others <ref> [19] </ref> have shown that the stereophotogrammetric RMS accuracy is 0.1 to 0.4 mm using well-defined targets, such as the tungsten carbide spheres. In studies of living subjects who are not part of a medical investigation, implanting tungsten carbide spheres is impractical.
Reference: [20] <author> R. Tsai. </author> <title> A versatile camera calibration technique for high accuracy 3d machine vision metrology using off-the-shelf cameras and lenses. </title> <journal> IEEE Trans. Robotics and Automation, </journal> <volume> 3, </volume> <month> August </month> <year> 1987. </year>
Reference-contexts: The recent work by Jain et al [11] contains an excellent review of various solutions for the external and interior camera orientation 6 cushion. problems and for stereo system calibration. A commonly used method for calibration is described by Tsai in <ref> [20] </ref> who reported the possibility of achieving accuracy of 1 part in 4000 using off-the-shelf cameras and lenses. The most difficult task in automatic depth reconstruction from stereo images is finding corresponding points in the images. <p> Tsai <ref> [20] </ref> and Jain et al [11] describe techniques for correcting radial distortion. Basically, each image point is corrected by moving it along a radial from the image center an amount proportional to the square of its distance from the image center. <p> Procedures are available for calibrating both image warping parameters and perspective model parameters in a single step: see, for example, the work of Tsai and Weng et al <ref> [20, 10] </ref>.
Reference: [21] <author> S.A. Veress, F.G. Lippert III, and T. Takamoto. </author> <title> An analytic approach to x-ray photogram-metry. </title> <journal> Photogrammetric Eng. and Remote Sensing, </journal> <volume> 43(12) </volume> <pages> 1503-1510, </pages> <year> 1977. </year>
Reference-contexts: In previous work, Reynolds et al. computed internal location of various skeletal points by using stereo x-rays of cadavers with tungsten-carbide spheres inserted as feature points [18, 17]. Veress et al <ref> [21] </ref> and others [19] have shown that the stereophotogrammetric RMS accuracy is 0.1 to 0.4 mm using well-defined targets, such as the tungsten carbide spheres. In studies of living subjects who are not part of a medical investigation, implanting tungsten carbide spheres is impractical. <p> The error from the current system is about 5 times that of other systems using surgically implanted spheres <ref> [21] </ref>. In conclusion, using our non-invasive procedures, the multiple camera system, in conjunction with a high definition pressure mapping of the interface between the seat and occupant, can be used to define 23 the position of the skeleton of a vehicle operator in the working environment.
References-found: 21

