URL: http://www.cirl.uoregon.edu/crawford/papers/3sat.ps
Refering-URL: http://www.cirl.uoregon.edu/constraints/links/sat.html
Root-URL: 
Email: jc@cs.uoregon.edu  lda@research.att.com  
Author: James M. Crawford Larry D. Auton 
Date: August 21, 1996  
Address: Eugene, OR 97403  600 Mountain Ave. Murray Hill, NJ 07974-0636  
Affiliation: Computational Intelligence Research Laboratory 1269 University of Oregon  AT&T Bell Laboratories  
Web: 3SAT  
Note: Random  This work has been supported by the Air Force Office of Scientific Research under grant number 92-0693 and by ARPA/Rome Labs under grant numbers F30602-91-C-0036 and F30602-93-C-00031. Some of this work was done while the first author was at AT&T Bell Laboratories.  
Abstract: Experimental Results on the Crossover Point in Abstract Determining whether a propositional theory is satisfiable is a prototypical example of an NP-complete problem. Further, a large number of problems that occur in knowledge-representation, learning, planning, and other ares of AI are essentially sat-isfiability problems. This paper reports on the most extensive set of experiments to date on the location and nature of the cross-over point in satisfiability problems. These experiments generally confirm previous results with two notable exceptions. First, we have found that neither of the functions previously proposed accurately models the location of the cross-over point. Second, we have found no evidence of any hard problems in the underconstrained region. In fact the hardest problems found in the undercon-strained region were many times easier than the easiest unsatisfiable problems found in the neighborhood of the cross-over point. We offer explanations for these apparent contradictions of previous results. 
Abstract-found: 1
Intro-found: 1
Reference: [Broder et al. 93] <author> Broder, A., Frieze, A., and Upfal, E. </author> <year> (1993). </year> <title> On the Satisfiability and Maximum Satisfiability of Random 3-CNF Formulas. </title> <booktitle> Fourth Annual ACM-SIAM Symposium on Discrete Algorithms. </booktitle>
Reference: [Cheeseman et al. 91] <author> Cheeseman, P., Kanefsky, B., and Taylor, W.M. </author> <year> (1991). </year> <title> Where the really hard problems are. </title> <booktitle> IJCAI-91, </booktitle> <pages> pp. 163-169. </pages>
Reference-contexts: This confirms past results <ref> [Cheeseman et al. 91, Mitchell et al. 92] </ref>. For randomly-generated problems, these critically-constrained problems are found in a narrow band near the crossover point. Empirically, the number of clauses required for crossover seems to be best modeled by the equation c = 4:258v + 58:26v 2=3 .
Reference: [Chvatal & Szemeredi 88] <author> Chvatal, V. and Szemeredi, E. </author> <year> (1988). </year> <title> Many Hard Examples for Resolution. </title> <journal> JACM 35:4, </journal> <pages> pp. 759-768. </pages>
Reference: [Crawford & Auton 93] <author> Crawford, J.M. and Auton L.D. </author> <year> (1993). </year> <title> Experimental Results on the Crossover Point in Satisfiability Problems. </title> <booktitle> AAAI-93, </booktitle> <pages> pp. 21-27. </pages>
Reference-contexts: We then focus on deriving the best estimate we can for the location of the fifty-percent point. We present data from 20 to 300 variables. It turns out that neither the simple linear function presented 5 in our past work <ref> [Crawford & Auton 93] </ref>, nor the finite-scaling model presented by Selman and Kirkpatrick [Kirkpatrick & Selman 94], fit particularly well. <p> If we fit this data to an equation of form: branches = 2 av+b we get: branches = 2 v=19:5+0:08 For comparison, for the algorithm described in our previous work <ref> [Crawford & Auton 93] </ref>, the number of branches grows as 2 v=17 . Freeman [Freeman 94] gets branches = 2 v=18:50:02 . 15 of the clause/variable ratio. The run times for tableau are quite competitive.
Reference: [Davis et al. 62] <author> Davis, M., Logemann, G., and Loveland, D. </author> <year> (1962). </year> <title> "A machine program for theorem proving", </title> <journal> CACM, </journal> <volume> 5, </volume> <year> 1962, </year> <pages> 394-397. </pages>
Reference-contexts: Run times are in seconds and are for a Sparc 10.51. 3 The Tableau Algorithm The basic algorithm underlying tableau is depth-first search with unit-propagation. This combination can be traced back at least as far as the work of Davis, Logemann, and Loveland <ref> [Davis et al. 62] </ref>. To this basic framework tableau adds a highly-optimized unit-propagation algorithm, and a set of special-purpose heuristics for selecting branch variables. Section 3.1 describes the basic algorithm, and sections 3.2 and 3.3, respectively, describe the unit-propagation algorithm and the heuristics.
Reference: [Dowling & Gallier 84] <author> Dowling, W.F. and Gallier, J.H. </author> <year> (1984). </year> <title> Linear-time algorithms for testing the satisfiability of propositional Horn formulae. </title> <journal> Journal of Logic Programming, </journal> <volume> 3, </volume> <pages> 267-284. </pages>
Reference-contexts: Run times are in seconds and are for a Sparc 10.51. x y 1 _ : : : _ y n of the number of variables. Number of branch points shown on log scale. (similarly for :x). Complete unit propagation takes time linear in the size of the theory <ref> [Dowling & Gallier 84] </ref>. 3.2 Fast Unit-Propagation The computational bottlenecks for tableau are the unit-propagator and the machinery needed to save the state of the search for backtracking. Tableau's data-structures are designed to simultaneously allow efficient unit-propagation and inexpensive backtracking.
Reference: [Dubois et al. 93] <author> Dubois, O., Andre, P., Boufkhad, Y., and Carlier, J. </author> <year> (1993). </year> <title> SAT versus UNSAT. Second DIMACS Challenge: Cliques, Coloring and Satisfiability. </title> <institution> Rutgers University, NJ. </institution>
Reference-contexts: Our primary preference criterion is to prefer variables that would cause a large number of unit-propagations. This heuristic is similar to one used in <ref> [Zabih & McAllester 88, Dubois et al. 93] </ref>. We have found that it is not cost-effective to actually compute the number of unit-propagations that would result from valuing a variable.
Reference: [Freeman 94] <author> Freeman, J.W. </author> <title> Improvements to propositional satisfiability search algorithms. (1994). </title> <institution> Doctoral Dissertation University of Pennsylvania, Philadelphia Pennsylvania. </institution>
Reference-contexts: In this experiment we compute the rate of growth of the number of branch points and the run time of tableau in the crossover region. Experimental Method Following Freeman <ref> [Freeman 94] </ref>, we varied the number of variables from 25 to 350 by 25, and choose the number of clauses to give approximately 50 percent satisfiability. We ran on 1000 instances at each point. Results The results are shown in the table in figure 13. <p> If we fit this data to an equation of form: branches = 2 av+b we get: branches = 2 v=19:5+0:08 For comparison, for the algorithm described in our previous work [Crawford & Auton 93], the number of branches grows as 2 v=17 . Freeman <ref> [Freeman 94] </ref> gets branches = 2 v=18:50:02 . 15 of the clause/variable ratio. The run times for tableau are quite competitive. <p> Tableau's data-structures are designed to simultaneously allow efficient unit-propagation and inexpensive backtracking. The key to inexpensive backtracking is being able to describe the state of the search as concisely as possible <ref> [Freeman 94] </ref>; the more concise the description the less copying needed when the state is saved and the less memory used. <p> This is similar to the heuristic used by Dubois in which preference is given to the variable that occurs most often in the shortest clauses in the theory. One question here is how to combine the counts of the number of positive and negative occurrences of variables. Following Freeman <ref> [Freeman 94] </ref> we use the equation: score (x) = pc (x) fl nc (x) fl 1024 + pc (x) + nc (x) + 1 (4) Where pc (x) (nc (x)) is the number of positive (negative) occurrences of x in binary clauses.
Reference: [Garey & Johnson 79] <author> Garey, M.R. and Johnson D.S. </author> <year> (1979). </year> <title> Computers and Intractability. W.H. </title> <publisher> Freeman and Co., </publisher> <address> New York. </address> <month> 23 </month>
Reference: [Gent & Walsh 94] <author> Gent, I.P., and Walsh, T. </author> <year> (1994). </year> <title> Easy problems are sometimes hard. </title> <journal> AIJ, </journal> <volume> 70, </volume> <pages> 335-345. </pages>
Reference-contexts: However, some researchers have found rare problems that seem to be harder than any problems in the crossover region <ref> [Gent & Walsh 94, Hogg & Williams 94] </ref>. The goal of this experiment was to look for such extremely hard problems. Experimental Method Following Gent and Walsh, we fixed the number of variables but varied the clause/variable ratio from 1.8 to 3.0.
Reference: [Hogg & Williams 94] <author> Hogg, T., and Williams, C.P. </author> <year> (1994). </year> <title> The hardest constraint problems: a double phase transition. </title> <journal> AIJ, </journal> <volume> 69, </volume> <pages> 359-377. </pages>
Reference-contexts: However, some researchers have found rare problems that seem to be harder than any problems in the crossover region <ref> [Gent & Walsh 94, Hogg & Williams 94] </ref>. The goal of this experiment was to look for such extremely hard problems. Experimental Method Following Gent and Walsh, we fixed the number of variables but varied the clause/variable ratio from 1.8 to 3.0.
Reference: [Kirkpatrick & Selman 94] <author> Kirkpatrick, S., and Selman, B. </author> <title> Critical Behavior in the satisfi-ability of random boolean expressions. </title> <journal> Science, </journal> <volume> 264, </volume> <pages> 1297-1301. </pages>
Reference-contexts: We present data from 20 to 300 variables. It turns out that neither the simple linear function presented 5 in our past work [Crawford & Auton 93], nor the finite-scaling model presented by Selman and Kirkpatrick <ref> [Kirkpatrick & Selman 94] </ref>, fit particularly well. <p> A different equation is suggested by Kirkpatrick and Selman <ref> [Kirkpatrick & Selman 94] </ref>. They use finite-size scaling methods from statistical physics to derive an equation of form: c = ff 0 v + ff 1 v 1u (2) They estimate ff 0 = 4:17, ff 1 = 3:1, and u = 2=3.
Reference: [Larrabee & Tsuji 93] <author> Larrabee, Tracy, and Tsuji, Yumi. </author> <year> (1993). </year> <title> Evidence for a Satisfiability Threshold for Random 2CNF Formulas. </title> <booktitle> Working Notes: AAAI Spring Symposium on AI and NP-Hard Problems. </booktitle> <institution> Stanford University, Stanford, </institution> <address> CA. </address>
Reference-contexts: As we shall see, near the crossover point the percent satisfiability curve is nearly linear. The slope of this line is fairly gentle for small numbers of variables (e.g., 20) but gets progressively steeper as the number of variables grows (see figure 2). Some past work <ref> [Larrabee & Tsuji 93] </ref> has suggested that this percent satisfiable curve "rotates" around the point at which the clause-variable ratio is 4.2. In other words, if the clause-variable ratio is fixed at 4.2 and the number of variables is increased, then the percent satisfiable will remain approximately constant. <p> At each point we ran 10000 experiments (above 200 variables 7 variables. we ran 1000 experiments at each point). Results The results are shown in figure 5. Discussion Past work <ref> [Larrabee & Tsuji 93] </ref> has suggested that the percent satisfiable curve "rotates" around the point at which the clause-variable ratio is 4.2. In other words, for any number of variables v, if the number of clauses is 4:2v then the percent satisfiable will be approximately constant.
Reference: [Minton et al. 90] <author> Minton, S., Johnson, M.D., Philips, A.B. and Laird, P. </author> <year> (1990). </year> <title> Solving large-scale constraint-satisfaction and scheduling problems using a heuristic repair method. </title> <booktitle> AAAI-90, </booktitle> <pages> pp. 17-24. </pages>
Reference-contexts: Similarly, if one encounters in practice a problem that is near the cross-over point, one can expect it to be difficult and thus avoid it (or plan to devote extra computational resources to it). Further, several algorithms have been proposed <ref> [Selman et al. 92, Minton et al. 90] </ref> that can often find solutions to constraint satisfaction problems, but which cannot show a problem unsolvable (they simply give up after a given number of tries).
Reference: [Mitchell et al. 92] <author> Mitchell, D., Selman, B., and Levesque, H. </author> <year> (1992). </year> <title> Hard and easy distributions of SAT problems. </title> <booktitle> AAAI-92, </booktitle> <pages> pp. 459-465. </pages>
Reference-contexts: However, the problems in between those with few solutions but lots of partial solutions seem to be quite hard. Interestingly, for randomly generated 3-SAT problems, these hard problems seem to occur very near the point at which half of the randomly generated problems are satisfiable <ref> [Mitchell et al. 92] </ref>. We refer to this point as the crossover point. Figure 1 shows the crossover effect graphically. One line shows the percent satisfiable, and the other shows problem difficulty. <p> This confirms past results <ref> [Cheeseman et al. 91, Mitchell et al. 92] </ref>. For randomly-generated problems, these critically-constrained problems are found in a narrow band near the crossover point. Empirically, the number of clauses required for crossover seems to be best modeled by the equation c = 4:258v + 58:26v 2=3 .
Reference: [Mitchell 93] <author> Mitchell, D. </author> <year> (1993). </year> <title> An Empirical Study of Random SAT. </title> <type> Master's Thesis, </type> <institution> Department of Computing Science, Simon Fraser University. </institution>
Reference-contexts: For other distributions, such as that given by the constant probability model, problem difficulty seems to grow much more slowly <ref> [Mitchell 93] </ref>. <p> model leads to a much different distribution of instances (and in particular in the constant probability model the mean of the difficulty of the problems in the crossover region does not seem to be that much higher than the mean of the difficulty of the problems in the underconstrained region <ref> [Mitchell 93] </ref>). 14 2.2.2 Experiment 5: Problem Difficulty in the Crossover Region Since the crossover region appears to hold the hardest test cases (at least for tableau on problems of this size) it makes sense to compare algorithms on instances drawn from this region.
Reference: [Selman et al. 92] <author> Selman, B., Levesque, H., and Mitchell, D. </author> <year> (1992). </year> <title> A new method for solving hard satisfiability problems. </title> <booktitle> AAAI-92, </booktitle> <pages> pp. 440-446. </pages>
Reference-contexts: Similarly, if one encounters in practice a problem that is near the cross-over point, one can expect it to be difficult and thus avoid it (or plan to devote extra computational resources to it). Further, several algorithms have been proposed <ref> [Selman et al. 92, Minton et al. 90] </ref> that can often find solutions to constraint satisfaction problems, but which cannot show a problem unsolvable (they simply give up after a given number of tries).
Reference: [Smullyan, 68] <author> Smullyan, R. M. </author> <title> (1968) First Order Logic. </title> <publisher> Springer-Verlag New York Inc. </publisher>
Reference: [Zabih & McAllester 88] <author> Zabih, R.D. and McAllester, D.A. </author> <year> (1988). </year> <title> A rearrangement search strategy for determining propositional satisfiability. </title> <booktitle> AAAI-88, </booktitle> <pages> pp. 155-160. </pages>
Reference-contexts: Our primary preference criterion is to prefer variables that would cause a large number of unit-propagations. This heuristic is similar to one used in <ref> [Zabih & McAllester 88, Dubois et al. 93] </ref>. We have found that it is not cost-effective to actually compute the number of unit-propagations that would result from valuing a variable.
References-found: 19

