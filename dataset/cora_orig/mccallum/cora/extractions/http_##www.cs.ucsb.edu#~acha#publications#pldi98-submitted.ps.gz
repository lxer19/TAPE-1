URL: http://www.cs.ucsb.edu/~acha/publications/pldi98-submitted.ps.gz
Refering-URL: http://www.cs.ucsb.edu/~acha/publications/pldi98-submitted.html
Root-URL: http://www.cs.ucsb.edu
Email: shamik@cs.umd.edu, acha@cs.ucsb.edu, saltz@cs.umd.edu  
Phone: Phone 301-405-2756  
Title: Deferred Data-Flow Analysis  
Author: Shamik D. Sharma Anurag Acharya Joel Saltz 
Note: Contact  
Address: Santa Barbara  
Affiliation: Department of Computer Science Department of Computer Science University of Maryland, College Park University of California,  
Abstract: Loss of precision due to the conservative nature of compile-time dataflow analysis is a general problem and impacts a wide variety of optimizations. We propose a limited form of runtime dataflow analysis, called deferred dataflow analysis (DDFA), which attempts to improve precision by performing most of the analysis at compile-time and using additional information at runtime to stitch together information collected at compile-time. We present an interprocedural DDFA framework that is applicable for arbitrary control structures including multi-way forks, recursion, separately compiled functions and higher-order functions. We present algorithms for construction of region summary functions and for composition and application of these functions. Dividing the analysis in this manner raises two concerns: (1) is it possible to generate correct and compact summary functions for regions? (2) is it possible to correctly and efficiently compose and apply these functions at run-time? To address these concerns, we show that DDFA terminates, is safe and provides good results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Acharya and J. Saltz. </author> <title> Dynamic linking for mobile programs. Mobile Object Systems, </title> <editor> J. Vitek and C. Tschudin (eds), </editor> <publisher> Springer Verlag Lecture Notes in Computer Science., </publisher> <year> 1997. </year>
Reference-contexts: Their goal is to eliminate conditionals; however the knowledge of these correlations could also be used to predict future control-flow decisions. The technique of delaying the collection of dataflow information was used in a limited form (only procedure return forks) in <ref> [1] </ref> to handle the problem of dynamic linking in mobile programs. DDFA is more general as it handles all types of forks.
Reference: [2] <author> F. Allen and J. Cocke. </author> <title> A program dataflow analysis procedure. </title> <journal> CACM, </journal> <volume> 19(3), </volume> <month> March </month> <year> 1976. </year>
Reference-contexts: In general, these conditions need not hold. Fortunately, however, these conditions do hold for most of the typical dataflow analysis frameworks. As pointed out in [17], the class of dataflow problems that allow compact and simple representations are the same class that allow elimination algorithms <ref> [2] </ref> (these algorithms also need to perform functional meets and compositions). This family includes the classical bit-vector dataflow problems. In particular, there exists a common class of dataflow problems, called 1-related problems, that always have compact representations and allow efficient manipulation [16].
Reference: [3] <author> T. Ball and J. Larus. </author> <title> Efficient path profiling. </title> <booktitle> In Proceedings of MIRCO-29, </booktitle> <year> 1996. </year>
Reference-contexts: DDFA needs to know about future control flow decisions in order to be effective. There has been considerable research recently in branch prediction [12, 19], profiling <ref> [3] </ref> and elimination of conditional branches. [14] has 6 Marking a non-lossy node as lossy does not hurt DDFA's correctness or the quality of the results; it only increases the number of regions that must be analyzed at runtime, thereby increasing space and time overheads. 11 reported the existence of significant
Reference: [4] <author> R. Bodik, R. Gupta, and M. Souffa. </author> <title> Interprocedural conditional branch elimination. </title> <booktitle> In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 14658, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Bodik et. al. <ref> [4] </ref> present techniques to statically detect these correlations. Their goal is to eliminate conditionals; however the knowledge of these correlations could also be used to predict future control-flow decisions.
Reference: [5] <author> C. Consel and F. Noel. </author> <title> A general approach to run-time specialization an its application to c. </title> <booktitle> In POPL'96, </booktitle> <pages> pages 14556, </pages> <year> 1996. </year>
Reference-contexts: The process usually involves generating parameterized code templates with holes in them; a runtime specializer plugs in these holes with runtime values and stitches the templates. Engler et. al. [8] allow programmers to construct and manipulate templates explicitly. Others, <ref> [5, 9, 13] </ref>, generate templates automatically. These efforts are concerned with generating optimized code based on runtime values, so they focus on lower-level optimizations like load-elimination, loop-unrolling, static branch-elimination etc. Similarly, DDFA generates information at compile-time for the use of a runtime-stitcher.
Reference: [6] <author> E. Duesterwald, R. Gupta, and M. Souffa. </author> <title> Demand-driven computation of interprocedural data flow. </title> <booktitle> In Proceedings of POPL, </booktitle> <year> 1995. </year>
Reference-contexts: DDFA does not modify code, except to insert a call to the runtime stitcher at each operation. Our use of summary functions have been adapted from previous research on interprocedural analysis, in particular Sharir et. al. [17] and Duesterwald et. al. <ref> [6] </ref>. An important distinction is that we apply these summary function at runtime. Another important distinction is that we use summary functions for regions instead of procedures this introduces an additional complications as regions can overlap and procedures cannot.
Reference: [7] <author> E.Duesterwald, R. Gupta, </author> <title> and M.L. Soffa. Reducing the cost of dataflow analysis by congurence partitioning. </title> <booktitle> In Fifth International Conference on Compiler Construction, number 786 in Lecture Notes on Computer Science, </booktitle> <pages> pages 357373. </pages> <publisher> Springer Verlag, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: Two-phase techniques have previously been used for inter-procedural flow analysis by others (e.g. Sharir et al [17] and Duesterwald et al <ref> [7] </ref>). In these techniques, the first phase computes a summary function for each procedure and the second phase applies these functions to obtain the inter-procedural dataflow properties. DDFA differs from these techniques in three important ways.
Reference: [8] <author> D. Engler, W.C. Hsieh, and M.F. Kaashoek. </author> <title> `c : A languages for high-level, efficient and machine-independent dynamic code generation. </title> <booktitle> In Proceedings of the ACM SIGPLAN Symposium on Principles of Programming Languages (POPL), </booktitle> <pages> pages 131144, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: The process usually involves generating parameterized code templates with holes in them; a runtime specializer plugs in these holes with runtime values and stitches the templates. Engler et. al. <ref> [8] </ref> allow programmers to construct and manipulate templates explicitly. Others, [5, 9, 13], generate templates automatically. These efforts are concerned with generating optimized code based on runtime values, so they focus on lower-level optimizations like load-elimination, loop-unrolling, static branch-elimination etc.
Reference: [9] <author> B. Grant, M. Mock, M. Phillpose, C. Chambers, and S. Eggers. </author> <title> Annotation-directed run-time specialization in c. </title> <booktitle> In PEPM'97, </booktitle> <year> 1997. </year>
Reference-contexts: The process usually involves generating parameterized code templates with holes in them; a runtime specializer plugs in these holes with runtime values and stitches the templates. Engler et. al. [8] allow programmers to construct and manipulate templates explicitly. Others, <ref> [5, 9, 13] </ref>, generate templates automatically. These efforts are concerned with generating optimized code based on runtime values, so they focus on lower-level optimizations like load-elimination, loop-unrolling, static branch-elimination etc. Similarly, DDFA generates information at compile-time for the use of a runtime-stitcher.
Reference: [10] <author> L. Hornof and J. </author> <title> Noye. Accurate binding-time analysis for imperative languages: Flow, context and return sensitivity. </title> <booktitle> In PEPM'97, </booktitle> <year> 1997. </year>
Reference-contexts: Sharing the region-tables for common regions among different op-domains that reach a procedure is non-trivial a fork within the procedure may be predictable at one op-node but not at another. We note that this problem is similar to context-sensitive binding-time analysis <ref> [10] </ref> and suggest a similar solution. For each op-domain that extend into a procedure, we mark each fork within the procedure as lp (lossy and predictable) or non-lp.
Reference: [11] <author> G. Kildall. </author> <title> A unified approach to global program analysis. </title> <booktitle> In First ACM Symposium on Principles of Programming Languages, pages 194206, </booktitle> <address> Boston, Massachusetts, </address> <month> January </month> <year> 1973. </year>
Reference-contexts: This part is relatively easy other than the fact that we are operating on the function lattice F , this step is identical to any normal dataflow analyses. Since F is distributive, monotone, bounded and closed under functional-composition and functional-meet, we can directly borrow proofs from Kildall <ref> [11] </ref>. Step 3 : This step shows that operating on the functional domain does not hurt the quality of the solution. In other words the FMOP solution is as good as the MOP solution.
Reference: [12] <author> A. Krall. </author> <title> Improving semi-static branch-prediction by code replication. </title> <booktitle> In ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: Another important distinction is that we use summary functions for regions instead of procedures this introduces an additional complications as regions can overlap and procedures cannot. DDFA needs to know about future control flow decisions in order to be effective. There has been considerable research recently in branch prediction <ref> [12, 19] </ref>, profiling [3] and elimination of conditional branches. [14] has 6 Marking a non-lossy node as lossy does not hurt DDFA's correctness or the quality of the results; it only increases the number of regions that must be analyzed at runtime, thereby increasing space and time overheads. 11 reported the
Reference: [13] <author> P. Lee and M. Leone. </author> <title> Optimizing ML with run-time code generation. </title> <booktitle> In Proceedings of the 1996 ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 13748, </pages> <year> 1996. </year>
Reference-contexts: The process usually involves generating parameterized code templates with holes in them; a runtime specializer plugs in these holes with runtime values and stitches the templates. Engler et. al. [8] allow programmers to construct and manipulate templates explicitly. Others, <ref> [5, 9, 13] </ref>, generate templates automatically. These efforts are concerned with generating optimized code based on runtime values, so they focus on lower-level optimizations like load-elimination, loop-unrolling, static branch-elimination etc. Similarly, DDFA generates information at compile-time for the use of a runtime-stitcher.
Reference: [14] <author> F. Mueller and D.B. Whalley. </author> <title> Avoiding conditional branches by code replication. </title> <booktitle> In ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1995. </year>
Reference-contexts: DDFA needs to know about future control flow decisions in order to be effective. There has been considerable research recently in branch prediction [12, 19], profiling [3] and elimination of conditional branches. <ref> [14] </ref> has 6 Marking a non-lossy node as lossy does not hurt DDFA's correctness or the quality of the results; it only increases the number of regions that must be analyzed at runtime, thereby increasing space and time overheads. 11 reported the existence of significant amounts of correlation among conditional branches.
Reference: [15] <author> S.S. Mukherjee, S.D. Sharma, M.D. Hill, J.R. Larus, A. Rogers, and J. Saltz. </author> <title> Efficient support for irregular applications on distributed-memory machines. </title> <booktitle> In PPOPP, </booktitle> <pages> pages 6879, </pages> <year> 1995. </year>
Reference-contexts: The analysis is conservative, because at runtime, a program will follow only one of these (possibly infinite) execution paths. For example, consider the problem of bulk-prefetching for distributed shared memory programs. Fetching data in small chunks can be expensive and prefetching data in bulk can significantly improve performance <ref> [15] </ref>. A commonly used conservative approach is to prefetch only the data that will definitely be required along all paths. This prevents needless communication, but may limit the effectiveness of prefetching. Figure 1 provides an illustration. <p> The cache of dataflow results need not be large. A two-entry cache should suffice for most cases as it handles the case where there is one path that is more frequently taken than others (A similar technique, called record-replay <ref> [15] </ref> has been shown to work well for optimizing communication in irregular parallel programs). Even when the algorithm has to be executed, it operates on the meta-CFG which has lp-regions instead of basic blocks, and summary functions instead of transfer functions.
Reference: [16] <author> Barry Rosen. </author> <title> Monoids for rapid data-flow analysis. </title> <booktitle> In POPL, </booktitle> <year> 1978. </year>
Reference-contexts: This family includes the classical bit-vector dataflow problems. In particular, there exists a common class of dataflow problems, called 1-related problems, that always have compact representations and allow efficient manipulation <ref> [16] </ref>. For 1-related problems it is easy to perform functional composition and functional meets; we show how this can be achieved using gen and kill sets.
Reference: [17] <author> M. Sharir and A. Pnueli. </author> <title> Two approaches for interprocedural data flow analysis, chapter Program Flow Analysis : theory and applications. </title> <publisher> Prentice-Hall, </publisher> <editor> Edited : S. Muchnik and N.D. Jones, </editor> <year> 1981. </year>
Reference-contexts: The key idea of DDFA is to divide the analysis into a compile-time phase and a runtime phase and to use runtime control-flow information to improve precision of analysis. Two-phase techniques have previously been used for inter-procedural flow analysis by others (e.g. Sharir et al <ref> [17] </ref> and Duesterwald et al [7]). In these techniques, the first phase computes a summary function for each procedure and the second phase applies these functions to obtain the inter-procedural dataflow properties. DDFA differs from these techniques in three important ways. <p> Similarly, within each lp-region, the paths v (n; e) contains all paths from between n 2 N v and e 2 exits (G v ) that lie entirely within G v . 3 As noted in <ref> [17] </ref>, F may not be a bounded lattice, even if L is bounded. However, if L is finite, then F must also be finite, and therefore bounded. <p> In general, these conditions need not hold. Fortunately, however, these conditions do hold for most of the typical dataflow analysis frameworks. As pointed out in <ref> [17] </ref>, the class of dataflow problems that allow compact and simple representations are the same class that allow elimination algorithms [2] (these algorithms also need to perform functional meets and compositions). This family includes the classical bit-vector dataflow problems. <p> We only provide an intuitive outline of our arguments in this abstract and refer the reader to [18] for more details. Our proofs are largely adapted from the proofs of the two-phase interprocedural analysis used in <ref> [17] </ref>. Termination: the builder terminates as each iteration causes the summary function of a region to move down the function lattice F . i+1 phi i is implied by monotonicity of transfer functions; termination follows because F is of bounded depth. <p> at least as good as the compile-time meet-over-all-paths solution: The idea here is to show that if we did not use any runtime information (knowledge of control-flow decisions), the results of DDFA's two-phase analysis 5 There are subtle differences between our path decomposition lemma and a similar lemma used in <ref> [17] </ref>. These differences stem from the fact that regions can overlap while procedure calls are completely nested. <p> Step 3 : This step shows that operating on the functional domain does not hurt the quality of the solution. In other words the FMOP solution is as good as the MOP solution. For this we just cite previous work on summary functions, in particular Theorem 7-3.4 in <ref> [17] </ref>. 4 Extensions to the basic framework In this section, we extend the basic framework to incorporate interprocedural analysis, higher-order functions and separately compiled functions. We also describe how the runtime analysis can be modified to look further ahead in the execution the goal being to optimize over multiple op-domains. <p> DDFA does not modify code, except to insert a call to the runtime stitcher at each operation. Our use of summary functions have been adapted from previous research on interprocedural analysis, in particular Sharir et. al. <ref> [17] </ref> and Duesterwald et. al. [6]. An important distinction is that we apply these summary function at runtime. Another important distinction is that we use summary functions for regions instead of procedures this introduces an additional complications as regions can overlap and procedures cannot.
Reference: [18] <author> Shamik Sharma, A. Acharya, and J. Saltz. </author> <title> Deferred data-flow analysis : Algorithms, proofs and applications. </title> <type> Technical report, </type> <institution> University of Maryland, </institution> <year> 1997. </year>
Reference-contexts: For conciseness, we limit ourselves to intuitive descriptions of the terms; for details we refer the reader to <ref> [18] </ref>. As mentioned in the introduction, DDFA is targeted towards optimization of heavy-weight operations (such as bulk-prefetch, garbage-collection, runtime compilation, remote procedure calls etc). We will refer to these operations as ops and the nodes representing them in the control-flow graph as op-nodes. <p> In this abstract, we do not describe this stage and assume that the op-domains and lp-regions have already been identified; we refer the reader to <ref> [18] </ref> for the details. The intuitive definitions presented above for op-domains and lp-regions indicate how they can be constructed. Note that, for op-domains that straddle procedure boundaries, care needs to be taken to preserve the calling context when computing the set of nodes reachable from an op-node. <p> These restrictions are for expositional simplicity. In section 4, we extend the framework to include interprocedural analysis, separately compiled code and higher-order functions. For conciseness, we defer the treatment of heavy-weight operations that can be repositioned to <ref> [18] </ref>. 3.1 Terms and definitions We characterize a global backward dataflow framework by the pair (L; F ), where L is a lattice of attribute information and F is a semi-lattice of monotone and distributive transfer-functions from L to L. <p> We show that: (1) DDFA terminates; (2) DDFA is safe; and (3) DDFA computes a solution that is no worse than a compile-time meet-over-all-paths solution. We only provide an intuitive outline of our arguments in this abstract and refer the reader to <ref> [18] </ref> for more details. Our proofs are largely adapted from the proofs of the two-phase interprocedural analysis used in [17].
Reference: [19] <author> C. Young, N. Gloy, and M. Smith. </author> <title> A comparative analysis of schemes for correlated branch prediction. </title> <booktitle> In Proceedings of the 22nd ISCA, </booktitle> <month> Jun </month> <year> 1995. </year> <month> 12 </month>
Reference-contexts: Another important distinction is that we use summary functions for regions instead of procedures this introduces an additional complications as regions can overlap and procedures cannot. DDFA needs to know about future control flow decisions in order to be effective. There has been considerable research recently in branch prediction <ref> [12, 19] </ref>, profiling [3] and elimination of conditional branches. [14] has 6 Marking a non-lossy node as lossy does not hurt DDFA's correctness or the quality of the results; it only increases the number of regions that must be analyzed at runtime, thereby increasing space and time overheads. 11 reported the
References-found: 19

