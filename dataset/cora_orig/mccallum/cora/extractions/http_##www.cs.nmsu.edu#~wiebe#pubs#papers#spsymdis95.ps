URL: http://www.cs.nmsu.edu/~wiebe/pubs/papers/spsymdis95.ps
Refering-URL: http://www.cs.nmsu.edu/~wiebe/pubs/index.html
Root-URL: http://www.cs.nmsu.edu
Email: wiebe@cs.nmsu.edu, rbruce@crl.nmsu.edu  
Title: Probabilistic Classifiers for Tracking Point of View  
Author: Janyce Wiebe and Rebecca Bruce 
Date: March 1995.  
Note: Appears in the working notes of Empirical Methods in Discourse, AAAI Spring Symposia series, Stanford University,  
Address: Las Cruces, NM 88003  
Affiliation: Computing Research Laboratory and Department of Computer Science New Mexico State University  
Abstract: This paper describes work in developing probabilistic classifiers for a discourse segmentation problem that involves segmentation, reference resolution, and belief. Specifically, the problem is to segment a text into blocks such that all subjective sentences in a block are from the point of view of the same agent, and to identify noun phrases that refer to that agent. In our method for developing classifiers (Bruce & Wiebe 1994ab), rather than making assumptions about which variables to use and how they are related, statistical techniques are used to explore these questions empirically. Further, the types of models used in this work can express complex relationships among diverse sets of variables. This work is part of a large project that is in an early stage of development. The contributions of this paper are an illustration of framing a high-level discourse problem in such a way that it is amenable to statistical processing while still retaining its core, and a description of a method for developing probabilistic classifiers that is well-suited for addressing problems in discourse processing. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aone, C. & McKee, D. </author> <year> 1993. </year> <title> A Language-Independent Anaphora Resolution System for Understanding Multilingual Texts. </title> <booktitle> In Procs. 31st Annual Meeting of the Assoc. for Computational Linguistics (ACL-93), </booktitle> <pages> pp. 156-163. </pages>
Reference: <author> Banfield, A. </author> <year> 1982. </year> <title> Unspeakable Sentences: </title> <booktitle> Narration and Representation in the Language of Fiction. </booktitle> <address> Boston, MA: </address> <publisher> Routledge & Kegan Paul. </publisher>
Reference-contexts: POV Tracking The general problem we address is tracking what Us-pensky (1973) calls the psychological point of view in narrative. Let subjective sentences <ref> (Banfield 1982) </ref> be ones that present the private states of agents (emotions, perceptions, propositional attitudes). The problem of tracking the (psychological) POV is determining, for each sentence, whether or not the sentence is subjective and, if it is, identifying the agent (s) whose POV is taken (the subjective agent).
Reference: <author> Bishop, Y. M., Fienberg, S., & Holland, P. </author> <year> 1975. </year> <title> Discrete Multivariate Analysis: Theory and Practice. </title> <publisher> Cambridge: The MIT Press. </publisher>
Reference-contexts: Graphical models are a subset of the class of hierarchical log-linear models and, as such, are well-suited to characterizing and studying the structure of data, that is, the interactions among variables as evidenced by the frequency with which the values of the variables co-occur <ref> (Bishop et al. 1975) </ref>. A log-linear model expresses the probability distribution of a set of variables as a function of the interdependencies that exist among those variables.
Reference: <author> Bruce, R. & Wiebe, J. </author> <year> 1994a. </year> <title> A New Approach To Word Sense Disambiguation. </title> <booktitle> In Procs. 1994 ARPA Human Language Technology Workshop, </booktitle> <pages> pp. 236-241. </pages>
Reference-contexts: The model expresses the relationships among the classification variable and variables that correspond to properties of the ambiguous object and the context in which it occurs. In our method for developing classifiers <ref> (Bruce & Wiebe 1994ab) </ref>, rather than making assumptions about which variables to use and how they are related, statistical techniques are used to explore these questions empirically. Further, the types of models used in this work can express complex relationships among diverse sets of variables. <p> In the remainder of this paper, we first discuss preprocessing using existing software and then specify the four classification problems addressed. We then present our method for developing probabilistic classifiers <ref> (Bruce & Wiebe 1994ab) </ref>, discuss related work, and conclude with examples and discussion.
Reference: <author> Bruce, R. & Wiebe, J. </author> <year> 1994b. </year> <title> Word-Sense Disambiguation Using Decomposable Models. </title> <booktitle> In Procs. 32nd Annual Meeting of the Assoc. for Computational Linguistics (ACL-94), </booktitle> <pages> pp. 139-146. </pages>
Reference: <author> Dempster, A.; Laird, N.; & Rubin, D. </author> <year> 1977. </year> <title> Maximum Likelihood From Incomplete Data Via the EM Algorithm. </title> <journal> Journal of the Royal Statistical Society B (39): </journal> <pages> 1-38. </pages>
Reference-contexts: It should be noted that there are many possible variations on this general algorithm (Rubin 1991). The procedure is a Bayesian approach to data augmentation that is very similar in spirit to the EM algorithm <ref> (Dempster et al. 1977) </ref>. The basic idea is straightforward.
Reference: <author> Fauconnier, G. </author> <year> 1985. </year> <title> Mental Spaces: Aspects of Meaning Construction in Natural Language. </title> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Geman, S. & Geman, D. </author> <year> 1984. </year> <title> Stochastic Relaxation, Gibbs Distributions and the Bayesian Restoration of Images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6: </volume> <pages> 721-741. </pages>
Reference-contexts: The scheme we will describe is a stochastic simulation technique referred to as The Gibbs sampler <ref> (Geman & Geman 1984) </ref>. It should be noted that there are many possible variations on this general algorithm (Rubin 1991). The procedure is a Bayesian approach to data augmentation that is very similar in spirit to the EM algorithm (Dempster et al. 1977). The basic idea is straightforward.
Reference: <author> Grosz, B.J. & Sidner, C.L. </author> <year> 1986. </year> <title> Attention, Intentions, and the Structure of Discourse. </title> <booktitle> Computational Linguistics 12(3): </booktitle> <pages> 175-204. </pages>
Reference-contexts: An NLP system must be able to recognize such discourse phenomena in order to recover information implicitly communicated in the discourse. The problem is related to other discourse problems, in that it involves discourse segmentation <ref> (Grosz & Sidner 1986) </ref> and a task akin to pronoun resolution (identifying the subjective agent). As discussed below, we plan to address a somewhat less fine-grained problem in the interests of feasibility; however, the new problem retains segmentation and addresses interactions between POV tracking and reference resolution. <p> Even without the phrase "these kings of the American road," it would be easy to interpret the first pronoun "them" as referring to the Americans, even though there are numerous competing discourse entities mentioned more recently (the policemen, the passers-by, etc.) <ref> (Grosz & Sidner 1986) </ref>. However, the subjective agent is often referred to non-pronominally as well. Our approach to developing models promises to identify correlations such as those between form of reference and POV.
Reference: <author> Hearst, M. </author> <year> 1994. </year> <title> Multi-Paragraph Segmentation of Expository Text. Procs. </title> <booktitle> 32nd Annual Meeting of the Assoc. for Computational Linguistics (ACL-94), </booktitle> <pages> pp. 9-16. </pages>
Reference: <author> Hearst, M. </author> <year> 1993. </year> <title> TextTiling: A Quantitative Approach to Discourse Segmentation. </title> <type> Technical Report 93/24, Sequoia 2000 Technical Report, </type> <institution> University of California, Berkely. </institution>
Reference-contexts: Related Work There has been recent growth in empirically-oriented work in discourse processing. Several researchers have addressed evaluation, investigating the degree to which human subjects agree with one another on discourse tasks <ref> (Passonneau & Litman 1993, Hirschberg & Grosz 1992, Hearst 1993) </ref>. Others have used frequency information to evaluate algorithms. Passonneau and Lit-man (1993) tagged a corpus with classes and features and tested algorithms hypothesized from the literature.
Reference: <author> Hirschberg, J. & Grosz, B. </author> <year> 1992. </year> <title> Intonational Features of Local and Global Discourse Structure. </title> <booktitle> In Procs. of the Darpa Workshop on Speech and Natural Language. </booktitle>
Reference: <author> Hirschberg, J. & Litman, D. </author> <year> 1993. </year> <title> Empirical Studies on the Disambiguation of Cue Phrases. </title> <booktitle> Computational Linguistics 19(3): </booktitle> <pages> 501-530. </pages>
Reference-contexts: Related Work There has been recent growth in empirically-oriented work in discourse processing. Several researchers have addressed evaluation, investigating the degree to which human subjects agree with one another on discourse tasks <ref> (Passonneau & Litman 1993, Hirschberg & Grosz 1992, Hearst 1993) </ref>. Others have used frequency information to evaluate algorithms. Passonneau and Lit-man (1993) tagged a corpus with classes and features and tested algorithms hypothesized from the literature.
Reference: <author> Irving, D. </author> <year> 1981. </year> <title> The War Between the Generals. </title> <address> New York, NY: Congdon & Weed. </address>
Reference-contexts: Sentence (a.2) is easily taken to present a private state of John's, but it leaves the agent and the type of private state entirely implicit. Similarly, consider the following discourse fragment from a non-fictional book about WWII <ref> (Irving 1981, p.7) </ref>: (b.1) The young Americans, on their part, had never seen anything like London. (b.2) The buildings were low and gnarled and barnacled with sooty decorations. (b.3) The policemen wore odd helmets, office workers wore bowlers, and passersby wore blank expressions|no eye contact. (b.4) What shocked them most, perhaps,
Reference: <author> Litman, D. </author> <year> 1994. </year> <title> Classifying Cue Phrases in Text and Speech Using Machine Learning. </title> <booktitle> In Procs. 12th National Conference on Artificial Intelligence (AAAI-94). </booktitle>
Reference: <author> Passonneau, R. & Litman, D. </author> <year> 1993. </year> <title> Intention-Based Segmentation: Human Reliability and Correlation with Linguistic Cues. </title> <booktitle> In Procs. 31st Annual Meeting of the Assoc. for Computational Linguistics (ACL-93), </booktitle> <pages> pp. 148-155. </pages>
Reference-contexts: Related Work There has been recent growth in empirically-oriented work in discourse processing. Several researchers have addressed evaluation, investigating the degree to which human subjects agree with one another on discourse tasks <ref> (Passonneau & Litman 1993, Hirschberg & Grosz 1992, Hearst 1993) </ref>. Others have used frequency information to evaluate algorithms. Passonneau and Lit-man (1993) tagged a corpus with classes and features and tested algorithms hypothesized from the literature.
Reference: <author> Pearl, J. </author> <year> 1988. </year> <title> Probabilistic Reasoning In Intelligent Systems: Networks of Plausible Inference. </title> <address> San Mateo, Ca.: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Not only does a dependency graph provide a clear interpretation of the interactions among variables, it also has been shown <ref> (Pearl 1988) </ref> to form the basis of a distributed computational architecture for probabilistic constraint propagation. An important subset of graphical models is the class of decomposable models. <p> The process of stochastic simulation is potentially slow. Hundreds of cycles may be required to achieve reasonable accuracy, with each cycle requiring time on the order of the sum of the number of variables and the number of interdependencies between variables <ref> (Pearl 1988) </ref>. Fortunately, the algorithm can be easily executed in parallel by concurrent processors. A further reduction in computation time can be realized by using simulated annealing as discussed by Geman and Geman (1984).
Reference: <author> Rubin, D. </author> <year> 1991. </year> <title> EM and Beyond. </title> <type> Psychometrika 56(2): </type> <pages> 241-254. </pages>
Reference-contexts: The scheme we will describe is a stochastic simulation technique referred to as The Gibbs sampler (Geman & Geman 1984). It should be noted that there are many possible variations on this general algorithm <ref> (Rubin 1991) </ref>. The procedure is a Bayesian approach to data augmentation that is very similar in spirit to the EM algorithm (Dempster et al. 1977). The basic idea is straightforward.
Reference: <author> Siegel, E. & McKeown, K. </author> <year> 1994. </year> <title> Emergent Linguistic Rules From Inducing Decision Trees: Disambiguating Discourse Clue Words. </title> <booktitle> In Procs. 12th National Conference on Artificial Intelligence (AAAI-94). </booktitle>
Reference-contexts: Her method is specific to using this one type of contextual feature. The most formal approach to developing models that has been applied to discourse problems makes use of decision trees to define the relationships among various contextual features and discourse ambiguities <ref> (Siegel & McKeown 1994, Soderland & Lehnert 1994, Lit-man 1994) </ref>. The tree construction process partitions the data according to the values of one contextual feature before considering the values of the next, thereby treating all features in each branch of the tree as interdependent.
Reference: <author> Soderland, S. & Lehnert, W. </author> <year> 1994. </year> <title> Corpus-Driven Knowledge Acquisition for Discourse Analysis. </title> <booktitle> In Procs. 12th National Conference on Artificial Intelligence (AAAI-94). </booktitle>
Reference-contexts: Her method is specific to using this one type of contextual feature. The most formal approach to developing models that has been applied to discourse problems makes use of decision trees to define the relationships among various contextual features and discourse ambiguities <ref> (Siegel & McKeown 1994, Soderland & Lehnert 1994, Lit-man 1994) </ref>. The tree construction process partitions the data according to the values of one contextual feature before considering the values of the next, thereby treating all features in each branch of the tree as interdependent.
Reference: <author> Uspensky, B. </author> <year> 1973. </year> <title> A Poetics of Composition. </title> <address> Berke-ley, CA: </address> <publisher> University of California Press. </publisher>
Reference: <author> Whittaker, J. </author> <year> 1990. </year> <title> Graphical Models In Applied Mul-tivariate Statistics. </title> <address> New York, NY: </address> <publisher> John Wiley & Sons. </publisher>
Reference-contexts: In this work, we make use of a more general class of models than used in most NLP applications <ref> (graphical models, Whittaker 1990) </ref>. Such models are capable of characterizing a rich set of relationships among a large number of variables, where these variables may be of different types as well as spatially separated.
Reference: <author> Wiebe, J. </author> <year> 1994. </year> <title> Tracking Point of View in Narrative. </title> <booktitle> Computational Linguistics 20(2): </booktitle> <pages> 233-287. </pages>
Reference: <author> Wiebe, J. </author> <year> 1990. </year> <title> Recognizing Subjective Sentences: </title>
Reference-contexts: Wiebe has developed an algorithm for tracking POV that decides, for each sentence whether or not it is subjective and, if it is, identifies the subjective agent <ref> (Wiebe 1990, 1994) </ref>. Many of the features used in this algorithm will be incorporated into our current work. Subjective sentences are ubiquitous in narrative, and there exist many closely related discourse/pragmatic phenomena. <p> The problems we address are as follows. Preprocessing classification problem. The objects are the main clauses of sentences. The classification variable is the type of state of affairs that the main clause of a sentence is about. The values are four broad classes drawn from the existing POV algorithm <ref> (Wiebe 1990, 1994) </ref>: private states (e.g., "believe", "hope"), non-private states (e.g., "be", "own"), private actions (e.g., "sigh"), and non-private actions (e.g., "shoot"). First POV classification problem. The objects are sentences.
References-found: 24

