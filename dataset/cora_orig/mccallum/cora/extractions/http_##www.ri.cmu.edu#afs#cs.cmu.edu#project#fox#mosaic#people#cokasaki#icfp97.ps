URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/fox/mosaic/people/cokasaki/icfp97.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/project/fox/mosaic/people/cokasaki/papers.html
Root-URL: 
Email: (cokasaki@cs.cmu.edu)  
Title: Catenable Double-Ended Queues  
Author: Chris Okasaki 
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract: Catenable double-ended queues are double-ended queues (deques) that support catenation (i.e., append) efficiently without sacrificing the efficiency of other operations. We present a purely functional implementation of catenable deques for which every operation, including catenation, takes O(1) amortized time. Kaplan and Tarjan have independently developed a much more complicated implementation of catenable deques that achieves similar worst-case bounds. The two designs are superficially similar, but differ in the underlying mechanism used to achieve efficiency in a persistent setting (i.e., when used in a non-single-threaded fashion). Their implementation uses a technique called recursive slowdown, while ours relies on the simpler mechanism of lazy evaluation. Besides lazy evaluation, our implementation also exemplifies the use of two additional language features: polymorphic recursion and views. Neither is indispensable, but both significantly simplify the presentation. 
Abstract-found: 1
Intro-found: 1
Reference: [2] <author> F. Warren Burton and Robert D. Cameron. </author> <title> Pattern matching with abstract data types. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(2):171190, </volume> <month> April </month> <year> 1993. </year>
Reference-contexts: However, our design is much simpler than theirs. Continuing in the tradition of [16, 17, 18], our implementation reinforces the important role of lazy evaluation in purely functional data structures. Our implementation also makes extensive use of two additional language features: polymorphic recursion [14, 7] and views <ref> [22, 2, 20] </ref>. Although neither is indispensable, both significantly simplify the presentation. We hope that this example will motivate more language designers to include these features in their languages. Section 2 briefly reviews related work. <p> Even though we treat p-deques as an abstract data type, we allow [ ], /, and . to be used in pattern matching. These kinds of abstract patterns are called views <ref> [22, 2, 20] </ref>. A [ ] pattern matches the empty deque. The pattern ph / pt means given a non-empty deque d, match pattern ph against lhd d and pattern pt against ltl d. The pattern pt . ph is interpreted similarly. <p> However, few current languages support these features, so we briefly sketch how the implementation changes without them. 5.1 Without Views Views <ref> [22, 2, 20] </ref> are a language mechanism allowing pattern matching on abstract datatypes. As with pattern matching in general, views are a syntactic convenience that can be replaced by explicit calls to case predicates (such as null) and access functions (such as lhd and ltl).
Reference: [3] <author> Tyng-Ruey Chuang and Benjamin Goldberg. </author> <title> Real-time de-ques, multihead Turing machines, and purely functional programming. </title> <booktitle> In Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 289298, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: Finally, Section 7 concludes with a few open problems. 2 Related Work Hood and Melville [9] presented the first purely functional implementation of queues to support all normal operations in O (1) time. In his thesis, Hood [8] extended this design to the double-ended case. Chuang and Goldberg <ref> [3] </ref> later re-invented Hood's data structure. Okasaki [16] simplified these implementations of queues and deques using lazy evaluation. Kaplan and Tarjan [11] introduced an entirely different implementation of deques, based on a technique called recursive slowdown. None of the above structures support catenation efficiently. <p> Let [ff] k + denote the subtype of p-deques of length k or greater. We assume that we are given an implementation of p-deques that supports each of the following operations in O (1) time (see, for example, <ref> [8, 3, 16] </ref>): [ ] : [ff] (the empty deque) / : ff fi [ff] ! [ff] (left cons) . : [ff] fi ff ! [ff] (right cons) lhd; rhd : [ff] 1 + ! ff (left and right head) ltl; rtl : [ff] 1 + ! [ff] (left and right
Reference: [4] <author> Paul F. Dietz. </author> <title> Fully persistent arrays. </title> <booktitle> In Workshop on Algorithms and Data Structures, volume 382 of LNCS, </booktitle> <pages> pages 6774. </pages> <publisher> Springer-Verlag, </publisher> <month> August </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Purely functional programming is gradually gaining recognition in the data structures community as an excellent medium for designing persistent (i.e., immutable) data structures. Several other general techniques for designing persistent data structures exist <ref> [5, 4] </ref>, but unfortunately, these other techniques break down when the data structure in question supports operations that combine two or more structures. Examples of such offending operations include catenating (i.e., appending) two sequences, unioning two sets, or merging two priority queues.
Reference: [5] <author> James R. Driscoll, Neil Sarnak, Daniel D. K. Sleator, and Robert E. Tarjan. </author> <title> Making data structures persistent. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 38(1):86124, </volume> <month> February </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Purely functional programming is gradually gaining recognition in the data structures community as an excellent medium for designing persistent (i.e., immutable) data structures. Several other general techniques for designing persistent data structures exist <ref> [5, 4] </ref>, but unfortunately, these other techniques break down when the data structure in question supports operations that combine two or more structures. Examples of such offending operations include catenating (i.e., appending) two sequences, unioning two sets, or merging two priority queues.
Reference: [6] <author> James R. Driscoll, Daniel D. K. Sleator, and Robert E. Tarjan. </author> <title> Fully persistent lists with catenation. </title> <journal> Journal of the ACM, </journal> <volume> 41(5):943959, </volume> <month> September </month> <year> 1994. </year>
Reference-contexts: Examples of such offending operations include catenating (i.e., appending) two sequences, unioning two sets, or merging two priority queues. Of these, sequence catenation has received the most attention <ref> [6, 1, 11, 17] </ref>. Two implementations of purely functional catenable lists have recently been proposed. Kaplan and Tarjan [11] described an approach that supports catenation and all other usual list operations in O (1) worst-case time. <p> Hughes [10] represented lists as functions in such a way that catenation becomes simple function composition, running in O (1) time. Unfortunately, his structure can only be inspected in toto it no longer supports individual head and tail operations efficiently. Driscoll, Sleator, and Tarjan <ref> [6] </ref> presented the first implementation of catenable lists to support all operations in sublogarithmic time: catenation in O (log log k) time, where k is the number of list operations (which may be much smaller than n), and all other operations in O (1) time.
Reference: [7] <author> Fritz Henglein. </author> <title> Type inference with polymorphic recursion. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 15(2):253289, </volume> <month> April </month> <year> 1993. </year>
Reference-contexts: However, our design is much simpler than theirs. Continuing in the tradition of [16, 17, 18], our implementation reinforces the important role of lazy evaluation in purely functional data structures. Our implementation also makes extensive use of two additional language features: polymorphic recursion <ref> [14, 7] </ref> and views [22, 2, 20]. Although neither is indispensable, both significantly simplify the presentation. We hope that this example will motivate more language designers to include these features in their languages. Section 2 briefly reviews related work. <p> Note that [ff] 1 is defined in terms of [CE ff] 1 . Supporting this kind of non-uniform type in a useful way requires polymorphic recursion <ref> [14, 7] </ref>. (See Section 5 for how to cope without polymorphic recursion.) The order of elements is from left to right at every level. <p> Even for a reader not comfortable with views, the version with views is probably easier to read for the gist of the implementation, although for such a reader the second version may be preferable for understanding the details. 5.2 Without Polymorphic Recursion Polymorphic recursion <ref> [14, 7] </ref> allows one to write recursive functions on non-uniform recursive datatypes. Without polymorphic recursion, recursive functions can be written only for uniform recursive types.
Reference: [8] <author> Robert Hood. </author> <title> The Efficient Implementation of Very-High-Level Programming Language Constructs. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> August </month> <year> 1982. </year> <note> (Cor-nell TR 82-503). </note>
Reference-contexts: Finally, Section 7 concludes with a few open problems. 2 Related Work Hood and Melville [9] presented the first purely functional implementation of queues to support all normal operations in O (1) time. In his thesis, Hood <ref> [8] </ref> extended this design to the double-ended case. Chuang and Goldberg [3] later re-invented Hood's data structure. Okasaki [16] simplified these implementations of queues and deques using lazy evaluation. Kaplan and Tarjan [11] introduced an entirely different implementation of deques, based on a technique called recursive slowdown. <p> Let [ff] k + denote the subtype of p-deques of length k or greater. We assume that we are given an implementation of p-deques that supports each of the following operations in O (1) time (see, for example, <ref> [8, 3, 16] </ref>): [ ] : [ff] (the empty deque) / : ff fi [ff] ! [ff] (left cons) . : [ff] fi ff ! [ff] (right cons) lhd; rhd : [ff] 1 + ! ff (left and right head) ltl; rtl : [ff] 1 + ! [ff] (left and right
Reference: [9] <author> Robert Hood and Robert Melville. </author> <title> Real-time queue operations in pure Lisp. </title> <journal> Information Processing Letters, </journal> <volume> 13(2):5053, </volume> <month> November </month> <year> 1981. </year>
Reference-contexts: Section 5 shows how to implement our data structure in a language without views or polymorphic recursion. Section 6 compares our data structure to the catenable deques of Kaplan and Tarjan [12]. Finally, Section 7 concludes with a few open problems. 2 Related Work Hood and Melville <ref> [9] </ref> presented the first purely functional implementation of queues to support all normal operations in O (1) time. In his thesis, Hood [8] extended this design to the double-ended case. Chuang and Goldberg [3] later re-invented Hood's data structure.
Reference: [10] <author> John Hughes. </author> <title> A novel representation of lists and its application to the function reverse. </title> <journal> Information Processing Letters, </journal> <volume> 22(3):141144, </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: Kaplan and Tarjan [11] introduced an entirely different implementation of deques, based on a technique called recursive slowdown. None of the above structures support catenation efficiently. My-ers [15] described an implementation of AVL trees that supports all relevant deque operations, including catenation, in O (log n) time. Hughes <ref> [10] </ref> represented lists as functions in such a way that catenation becomes simple function composition, running in O (1) time. Unfortunately, his structure can only be inspected in toto it no longer supports individual head and tail operations efficiently.
Reference: [11] <author> Haim Kaplan and Robert E. Tarjan. </author> <title> Persistent lists with catenation via recursive slow-down. </title> <booktitle> In ACM Symposium on Theory of Computing, </booktitle> <pages> pages 93102, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: Examples of such offending operations include catenating (i.e., appending) two sequences, unioning two sets, or merging two priority queues. Of these, sequence catenation has received the most attention <ref> [6, 1, 11, 17] </ref>. Two implementations of purely functional catenable lists have recently been proposed. Kaplan and Tarjan [11] described an approach that supports catenation and all other usual list operations in O (1) worst-case time. <p> Examples of such offending operations include catenating (i.e., appending) two sequences, unioning two sets, or merging two priority queues. Of these, sequence catenation has received the most attention [6, 1, 11, 17]. Two implementations of purely functional catenable lists have recently been proposed. Kaplan and Tarjan <ref> [11] </ref> described an approach that supports catenation and all other usual list operations in O (1) worst-case time. Okasaki [17] presented a much simpler implementation based on lazy evaluation that achieved similar amortized bounds. <p> In his thesis, Hood [8] extended this design to the double-ended case. Chuang and Goldberg [3] later re-invented Hood's data structure. Okasaki [16] simplified these implementations of queues and deques using lazy evaluation. Kaplan and Tarjan <ref> [11] </ref> introduced an entirely different implementation of deques, based on a technique called recursive slowdown. None of the above structures support catenation efficiently. My-ers [15] described an implementation of AVL trees that supports all relevant deque operations, including catenation, in O (log n) time. <p> Their implementation is persistent, but not purely functional. Buchsbaum and Tarjan [1] gave a purely functional implementation of catenable deques supporting deletion of the first or last element in O (log fl k) time, and all other operations in O (1) time. Kaplan and Tarjan <ref> [11] </ref> finally achieved an implementation of catenable lists that supports all operations, including catenation, in O (1) time. Their implementation is based on recursive slowdown and achieves its bounds in the worst case.
Reference: [12] <author> Haim Kaplan and Robert E. Tarjan. </author> <title> Purely functional lists with catenation via recursive slow-down. Draft revision of [11], </title> <month> August </month> <year> 1996. </year>
Reference-contexts: C533, issued by ESC/ENS under Contract No. F19628-95-C-0050. To appear in ICFP'97. operations in O (1) amortized time. Kaplan and Tarjan <ref> [12] </ref> have independently developed an implementation of catenable deques that achieves the same bounds in the worst case. However, our design is much simpler than theirs. Continuing in the tradition of [16, 17, 18], our implementation reinforces the important role of lazy evaluation in purely functional data structures. <p> Section 4 presents our implementation of catenable deques and its analysis. Section 5 shows how to implement our data structure in a language without views or polymorphic recursion. Section 6 compares our data structure to the catenable deques of Kaplan and Tarjan <ref> [12] </ref>. Finally, Section 7 concludes with a few open problems. 2 Related Work Hood and Melville [9] presented the first purely functional implementation of queues to support all normal operations in O (1) time. In his thesis, Hood [8] extended this design to the double-ended case. <p> The catenable deques in this paper are descended from Kaplan and Tarjan's implementation of catenable lists, but use lazy evaluation instead of recursive slowdown. In independent work, Kaplan and Tarjan <ref> [12] </ref> have also extended their implementation of catenable lists to the double-ended case. Modulo the difference between lazy evaluation and recursive slowdown, their approach is very similar to ours. For comparison purposes, we present their data structure in Section 6. <p> level p-deques contain elements of type ff, the second level p-deques contain elements of type CE ff, and so on), it also allows the type system to catch many more accidental violations of these invariants. 6 An Alternative Implementation of Catenable De ques The catenable deques of Kaplan and Tarjan <ref> [12] </ref> share a superficially similar structure with ours, but the two implementations are difficult to compare because of differences in their underlying mechanisms. To facilitate comparison, we adapt their implementation to our framework. This greatly simplifies many details of their structure, but also degrades its bounds from worst-case to amortized. <p> To facilitate comparison, we adapt their implementation to our framework. This greatly simplifies many details of their structure, but also degrades its bounds from worst-case to amortized. For the opposite view, see <ref> [12] </ref>, where Kaplan and Tarjan have adapted our implementation to their framework. In Kaplan and Tarjan's design, a left pair is a pair hf; ai, where f is a p-deque containing at least two elements and a is a c-deque of right pairs. <p> Which is to be preferred in practice can only be decided by a suitable empirical study. Unfortunately, we do not yet have enough experience with catenable dequesespecially persistent onesto determine an appropriate instruction mix for such a study. 7 Open Problems The catenable deques of Kaplan and Tarjan <ref> [12] </ref> are asymptotically optimal. However, they are rather complex, so one might hope that a simpler structure with equivalent asymptotic bounds would run faster in practice. The catenable deques described in this paper are simpler, but achieve only amortized rather than worst-case bounds. <p> Is a simpler worst-case approach possible? A second area of further research involves extending catenable deques with additional operations. For example, it is relatively easy to extend both our data structure and Kaplan and Tarjan's to support both reverse and findMin in O (1) time <ref> [12] </ref>.
Reference: [13] <author> Haim Kaplan and Robert E. Tarjan. </author> <title> Purely functional representations of catenable sorted lists. </title> <booktitle> In ACM Symposium on Theory of Computing, </booktitle> <pages> pages 202211, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Can either design be extended with efficient primitives for random access, such as looking up or updating the ith element, or inserting or deleting the ith element? Kaplan and Tarjan <ref> [13] </ref> have described a related data structure supporting these operations, but catenation in that design requires O (log log (minfn 1 ; n 2 g)) time. Is it possible to achieve constant-time catenation for such a data structure?
Reference: [14] <author> Alan Mycroft. </author> <title> Polymorphic type schemes and recursive definitions. </title> <booktitle> In International Symposium on Programming, volume 167 of LNCS, </booktitle> <pages> pages 217228. </pages> <publisher> Springer-Verlag, </publisher> <month> April </month> <year> 1984. </year>
Reference-contexts: However, our design is much simpler than theirs. Continuing in the tradition of [16, 17, 18], our implementation reinforces the important role of lazy evaluation in purely functional data structures. Our implementation also makes extensive use of two additional language features: polymorphic recursion <ref> [14, 7] </ref> and views [22, 2, 20]. Although neither is indispensable, both significantly simplify the presentation. We hope that this example will motivate more language designers to include these features in their languages. Section 2 briefly reviews related work. <p> Note that [ff] 1 is defined in terms of [CE ff] 1 . Supporting this kind of non-uniform type in a useful way requires polymorphic recursion <ref> [14, 7] </ref>. (See Section 5 for how to cope without polymorphic recursion.) The order of elements is from left to right at every level. <p> Even for a reader not comfortable with views, the version with views is probably easier to read for the gist of the implementation, although for such a reader the second version may be preferable for understanding the details. 5.2 Without Polymorphic Recursion Polymorphic recursion <ref> [14, 7] </ref> allows one to write recursive functions on non-uniform recursive datatypes. Without polymorphic recursion, recursive functions can be written only for uniform recursive types.
Reference: [15] <author> Eugene W. Myers. </author> <title> Efficient applicative data types. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 6675, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: Chuang and Goldberg [3] later re-invented Hood's data structure. Okasaki [16] simplified these implementations of queues and deques using lazy evaluation. Kaplan and Tarjan [11] introduced an entirely different implementation of deques, based on a technique called recursive slowdown. None of the above structures support catenation efficiently. My-ers <ref> [15] </ref> described an implementation of AVL trees that supports all relevant deque operations, including catenation, in O (log n) time. Hughes [10] represented lists as functions in such a way that catenation becomes simple function composition, running in O (1) time.
Reference: [16] <author> Chris Okasaki. </author> <title> Simple and efficient purely functional queues and deques. </title> <journal> Journal of Functional Programming, </journal> <volume> 5(4):583 592, </volume> <month> October </month> <year> 1995. </year>
Reference-contexts: F19628-95-C-0050. To appear in ICFP'97. operations in O (1) amortized time. Kaplan and Tarjan [12] have independently developed an implementation of catenable deques that achieves the same bounds in the worst case. However, our design is much simpler than theirs. Continuing in the tradition of <ref> [16, 17, 18] </ref>, our implementation reinforces the important role of lazy evaluation in purely functional data structures. Our implementation also makes extensive use of two additional language features: polymorphic recursion [14, 7] and views [22, 2, 20]. Although neither is indispensable, both significantly simplify the presentation. <p> In his thesis, Hood [8] extended this design to the double-ended case. Chuang and Goldberg [3] later re-invented Hood's data structure. Okasaki <ref> [16] </ref> simplified these implementations of queues and deques using lazy evaluation. Kaplan and Tarjan [11] introduced an entirely different implementation of deques, based on a technique called recursive slowdown. None of the above structures support catenation efficiently. <p> Let [ff] k + denote the subtype of p-deques of length k or greater. We assume that we are given an implementation of p-deques that supports each of the following operations in O (1) time (see, for example, <ref> [8, 3, 16] </ref>): [ ] : [ff] (the empty deque) / : ff fi [ff] ! [ff] (left cons) . : [ff] fi ff ! [ff] (right cons) lhd; rhd : [ff] 1 + ! ff (left and right head) ltl; rtl : [ff] 1 + ! [ff] (left and right
Reference: [17] <author> Chris Okasaki. Amortization, </author> <title> lazy evaluation, and persistence: Lists with catenation via lazy linking. </title> <booktitle> In IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 646654, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Examples of such offending operations include catenating (i.e., appending) two sequences, unioning two sets, or merging two priority queues. Of these, sequence catenation has received the most attention <ref> [6, 1, 11, 17] </ref>. Two implementations of purely functional catenable lists have recently been proposed. Kaplan and Tarjan [11] described an approach that supports catenation and all other usual list operations in O (1) worst-case time. <p> Of these, sequence catenation has received the most attention [6, 1, 11, 17]. Two implementations of purely functional catenable lists have recently been proposed. Kaplan and Tarjan [11] described an approach that supports catenation and all other usual list operations in O (1) worst-case time. Okasaki <ref> [17] </ref> presented a much simpler implementation based on lazy evaluation that achieved similar amortized bounds. <p> F19628-95-C-0050. To appear in ICFP'97. operations in O (1) amortized time. Kaplan and Tarjan [12] have independently developed an implementation of catenable deques that achieves the same bounds in the worst case. However, our design is much simpler than theirs. Continuing in the tradition of <ref> [16, 17, 18] </ref>, our implementation reinforces the important role of lazy evaluation in purely functional data structures. Our implementation also makes extensive use of two additional language features: polymorphic recursion [14, 7] and views [22, 2, 20]. Although neither is indispensable, both significantly simplify the presentation. <p> Kaplan and Tarjan [11] finally achieved an implementation of catenable lists that supports all operations, including catenation, in O (1) time. Their implementation is based on recursive slowdown and achieves its bounds in the worst case. Okasaki <ref> [17] </ref> gave a much simpler implementation based on lazy evaluation that also supports all operations in O (1) time, but only in the amortized sense. The catenable deques in this paper are descended from Kaplan and Tarjan's implementation of catenable lists, but use lazy evaluation instead of recursive slowdown. <p> The complete implementation of c-deques is summarized in 4.3 Analysis We first argue informally that every operation runs in O (1) amortized time. Then we prove this formally using a debit argument in the style of <ref> [17, 18, 19] </ref>. First, note that only ltl and rtl call themselves recursively. The remaining operations clearly run in O (1) time since none of them loop. Now consider ltl (the argument for rtl is similar). The first two cases terminate immediately. <p> how can we be sure that repeating this call n times will not take O (nk) time? We could satisfy the first concern using any of several formal techniques, such as the standard techniques of amortized analysis using credits or potential functions [21] or the non-standard debit techniques of Okasaki <ref> [17, 18, 19] </ref> for analyzing amortized data structures involving lazy evaluation. The basic approach under any of these methods is to establish an invariant and show that any individual call to ltl or rtl preserves the invariant, so any sequence of interleaved calls also preserves the invariant. <p> The key ingredient in this technique is the use of lazy evaluation to delay expensive computations. This allows the results of these computations to be shared via memoization among multiple threads of a non-single threaded computation. 1 See <ref> [17, 18, 19] </ref> for a fuller discussion of the role of lazy evaluation in persistent, amortized data structures. In a debit argument, every suspension is assigned a certain number of debits, which account for the cost of eventually executing the suspension. <p> The catenable deques described in this paper are simpler, but achieve only amortized rather than worst-case bounds. It is still an open problem whether the catenable lists of Okasaki <ref> [17] </ref> can be extended to the double-ended case. Such a data structure would likely be simpler yet, but would also achieve amortized rather than worst-case bounds. Is a simpler worst-case approach possible? A second area of further research involves extending catenable deques with additional operations.
Reference: [18] <author> Chris Okasaki. </author> <title> The role of lazy evaluation in amortized data structures. </title> <booktitle> In ACM SIGPLAN International Conference on Functional Programming, </booktitle> <pages> pages 6272, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: F19628-95-C-0050. To appear in ICFP'97. operations in O (1) amortized time. Kaplan and Tarjan [12] have independently developed an implementation of catenable deques that achieves the same bounds in the worst case. However, our design is much simpler than theirs. Continuing in the tradition of <ref> [16, 17, 18] </ref>, our implementation reinforces the important role of lazy evaluation in purely functional data structures. Our implementation also makes extensive use of two additional language features: polymorphic recursion [14, 7] and views [22, 2, 20]. Although neither is indispensable, both significantly simplify the presentation. <p> However, note that the recursive call to ltl is suspended by the / view. This use of lazy evaluation is critical if the data structure is to be efficient in a persistent setting <ref> [18] </ref>. We continue with the remaining clauses of ltl. <p> The complete implementation of c-deques is summarized in 4.3 Analysis We first argue informally that every operation runs in O (1) amortized time. Then we prove this formally using a debit argument in the style of <ref> [17, 18, 19] </ref>. First, note that only ltl and rtl call themselves recursively. The remaining operations clearly run in O (1) time since none of them loop. Now consider ltl (the argument for rtl is similar). The first two cases terminate immediately. <p> how can we be sure that repeating this call n times will not take O (nk) time? We could satisfy the first concern using any of several formal techniques, such as the standard techniques of amortized analysis using credits or potential functions [21] or the non-standard debit techniques of Okasaki <ref> [17, 18, 19] </ref> for analyzing amortized data structures involving lazy evaluation. The basic approach under any of these methods is to establish an invariant and show that any individual call to ltl or rtl preserves the invariant, so any sequence of interleaved calls also preserves the invariant. <p> The key ingredient in this technique is the use of lazy evaluation to delay expensive computations. This allows the results of these computations to be shared via memoization among multiple threads of a non-single threaded computation. 1 See <ref> [17, 18, 19] </ref> for a fuller discussion of the role of lazy evaluation in persistent, amortized data structures. In a debit argument, every suspension is assigned a certain number of debits, which account for the cost of eventually executing the suspension.
Reference: [19] <author> Chris Okasaki. </author> <title> Purely Functional Data Structures. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> September </month> <year> 1996. </year>
Reference-contexts: In addition, we provide a view for suspensions that allows forcing during pattern matching. When matching a suspension against a pattern p, we first force the suspension, and then match the resulting value against p. This style of notation for lazy evaluation is explored more thoroughly in <ref> [19] </ref>, along with many examples of its use. 4 Catenable Deques In this section, we present our implementation of c-deques. C-deques support exactly the same operations as p-deques, but improve the running time of 1 to O (1) amortized time. <p> The complete implementation of c-deques is summarized in 4.3 Analysis We first argue informally that every operation runs in O (1) amortized time. Then we prove this formally using a debit argument in the style of <ref> [17, 18, 19] </ref>. First, note that only ltl and rtl call themselves recursively. The remaining operations clearly run in O (1) time since none of them loop. Now consider ltl (the argument for rtl is similar). The first two cases terminate immediately. <p> how can we be sure that repeating this call n times will not take O (nk) time? We could satisfy the first concern using any of several formal techniques, such as the standard techniques of amortized analysis using credits or potential functions [21] or the non-standard debit techniques of Okasaki <ref> [17, 18, 19] </ref> for analyzing amortized data structures involving lazy evaluation. The basic approach under any of these methods is to establish an invariant and show that any individual call to ltl or rtl preserves the invariant, so any sequence of interleaved calls also preserves the invariant. <p> The key ingredient in this technique is the use of lazy evaluation to delay expensive computations. This allows the results of these computations to be shared via memoization among multiple threads of a non-single threaded computation. 1 See <ref> [17, 18, 19] </ref> for a fuller discussion of the role of lazy evaluation in persistent, amortized data structures. In a debit argument, every suspension is assigned a certain number of debits, which account for the cost of eventually executing the suspension.
Reference: [20] <author> Pedro Palao Gostanza, Ricardo Pe na, and Manuel Nunez. </author> <title> A new look at pattern matching in abstract data types. </title> <booktitle> In ACM SIGPLAN International Conference on Functional Programming, </booktitle> <pages> pages 110121, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: However, our design is much simpler than theirs. Continuing in the tradition of [16, 17, 18], our implementation reinforces the important role of lazy evaluation in purely functional data structures. Our implementation also makes extensive use of two additional language features: polymorphic recursion [14, 7] and views <ref> [22, 2, 20] </ref>. Although neither is indispensable, both significantly simplify the presentation. We hope that this example will motivate more language designers to include these features in their languages. Section 2 briefly reviews related work. <p> Even though we treat p-deques as an abstract data type, we allow [ ], /, and . to be used in pattern matching. These kinds of abstract patterns are called views <ref> [22, 2, 20] </ref>. A [ ] pattern matches the empty deque. The pattern ph / pt means given a non-empty deque d, match pattern ph against lhd d and pattern pt against ltl d. The pattern pt . ph is interpreted similarly. <p> However, few current languages support these features, so we briefly sketch how the implementation changes without them. 5.1 Without Views Views <ref> [22, 2, 20] </ref> are a language mechanism allowing pattern matching on abstract datatypes. As with pattern matching in general, views are a syntactic convenience that can be replaced by explicit calls to case predicates (such as null) and access functions (such as lhd and ltl).
Reference: [21] <author> Robert E. Tarjan. </author> <title> Amortized computational complexity. </title> <journal> SIAM Journal on Algebraic and Discrete Methods, </journal> <volume> 6(2):306318, </volume> <month> April </month> <year> 1985. </year>
Reference-contexts: example, if ltl xs recurses to depth k, how can we be sure that repeating this call n times will not take O (nk) time? We could satisfy the first concern using any of several formal techniques, such as the standard techniques of amortized analysis using credits or potential functions <ref> [21] </ref> or the non-standard debit techniques of Okasaki [17, 18, 19] for analyzing amortized data structures involving lazy evaluation.
Reference: [22] <author> Philip Wadler. </author> <title> Views: A way for pattern matching to cohabit with data abstraction. </title> <booktitle> In ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 307313, </pages> <month> January </month> <year> 1987. </year> <month> 9 </month>
Reference-contexts: However, our design is much simpler than theirs. Continuing in the tradition of [16, 17, 18], our implementation reinforces the important role of lazy evaluation in purely functional data structures. Our implementation also makes extensive use of two additional language features: polymorphic recursion [14, 7] and views <ref> [22, 2, 20] </ref>. Although neither is indispensable, both significantly simplify the presentation. We hope that this example will motivate more language designers to include these features in their languages. Section 2 briefly reviews related work. <p> Even though we treat p-deques as an abstract data type, we allow [ ], /, and . to be used in pattern matching. These kinds of abstract patterns are called views <ref> [22, 2, 20] </ref>. A [ ] pattern matches the empty deque. The pattern ph / pt means given a non-empty deque d, match pattern ph against lhd d and pattern pt against ltl d. The pattern pt . ph is interpreted similarly. <p> However, few current languages support these features, so we briefly sketch how the implementation changes without them. 5.1 Without Views Views <ref> [22, 2, 20] </ref> are a language mechanism allowing pattern matching on abstract datatypes. As with pattern matching in general, views are a syntactic convenience that can be replaced by explicit calls to case predicates (such as null) and access functions (such as lhd and ltl).
References-found: 21

