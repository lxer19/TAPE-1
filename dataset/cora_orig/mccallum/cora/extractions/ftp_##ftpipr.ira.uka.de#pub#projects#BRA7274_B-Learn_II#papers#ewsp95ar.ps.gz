URL: ftp://ftpipr.ira.uka.de/pub/projects/BRA7274_B-Learn_II/papers/ewsp95ar.ps.gz
Refering-URL: http://wwwipr.ira.uka.de/projects/blearn/blearnpub.html
Root-URL: 
Title: Learning to Guide a Robot via Perceptions  
Author: Anke Rieger 
Address: D-44221 Dortmund, Germany  
Affiliation: FB Informatik LS VIII, Universitat Dortmund  
Abstract: We address the problem of guiding a robot in such a way, that it can decide, based on perceived sensor data, which future actions to choose, in order to reach a goal. In order to realize this guidance, the robot has access to a (probabilistic) automaton (PA), whose final states represent concepts, which have to be recognized in order to verify, that a goal has been achieved. The contribution of this work is to learn these PA's from classified sensor data of robot traces through known environments. Within this framework, we account for the uncertainties arising from ambiguous perceptions.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dana Angluin. </author> <title> Learning regular sets from queries and counterexamples. </title> <journal> Information and Computation, </journal> <volume> 75 </volume> <pages> 87-106, </pages> <year> 1987. </year>
Reference-contexts: So the algorithm can be sketched as follows: Input: An observation sequence bf 1 : : : bf k . Output: The concepts, instances of which have been recognized during subintervals of the time interval <ref> [1; k] </ref>. <p> In principal, the first objective can also be achieved, by applying the L fl -algorithm, developed by Angluin <ref> [1] </ref>. There have been numerous approaches, based on L fl , for inferring automata, also with applications to robotics, e.g. [7],[10],[11]. The characteristic feature of these approaches is, that they work on representations in propositional logic.
Reference: [2] <author> T. Dean, D. Angluin, K. Basye, S. Engelson, L. Kaelbling, E. Kokkevis, and O. Maron. </author> <title> Inferring finite automata with stochastic output functions and an application to map learning. </title> <journal> Machine Learning, </journal> <volume> 18 </volume> <pages> 81-108, </pages> <year> 1995. </year>
Reference-contexts: Modifications of the algorithm seem to be possible, in order to apply it to our domain. Nevertheless, in our case, the construction of the prefix tree is a more straightforward way of attaining the automaton structure for a more complex representation. Dean et. al. <ref> [2] </ref> infer finite automata with stochastic output. The major difference to our approach lies in the use of the automata. For the overall goal to recognize operational concepts, independent of the specific environment, the automata serve to classify observation sequences, in order to derive higher-level descriptions of the robot's perceptions. <p> The major difference to our approach lies in the use of the automata. For the overall goal to recognize operational concepts, independent of the specific environment, the automata serve to classify observation sequences, in order to derive higher-level descriptions of the robot's perceptions. In <ref> [2] </ref>, the goal is to learn a map of the environment, which is represented by the automaton, i.e. the states represent landmarks of the environment. 8 Conclusion We have presented an approach to infer probabilistic automata, which can be used to classify sensor measurements.
Reference: [3] <author> J. A. Hendler. </author> <title> Integrating marker-passing and problem solving. </title> <editor> In A. Tate J. Allen, J. Hendler, editor, </editor> <booktitle> Readings in Planning, </booktitle> <pages> pages 275-287. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Using the DFA for object recognition When the robot moves through the environment, its sensors constantly perceive observations, each of which might be the beginning of a sequence, which is accepted by the automaton. Based on this idea, we can apply a simple marker passing method <ref> [3] </ref> to the DFA. Assume, that the robot has perceived a sequence of observations bf 1 : : : bf k during a period of time, in which no change of direction of movement took place.
Reference: [4] <author> F. Jelinek. </author> <title> Continuous speech recognition by statistical methods. </title> <journal> Proc. of the IEEE, </journal> <volume> 64 </volume> <pages> 532-556, </pages> <year> 1976. </year>
Reference-contexts: In our case, this distribution is trivial, as we have only one starting ste q 0 , whose probability is 1. fl denotes the observation probability distribution, which can be associated either with states (see [8]) or with state transitions (see <ref> [4] </ref>). <p> As there may be several possible paths, we use the Viterbi algorithm <ref> [4] </ref> to determine the state sequence, which maximizes this probability. We interpret the maximal acceptance probability of a sequence as posterior probability P (cjbf 1 : : : bf k ) of the concept c, which has been recognized most probably.
Reference: [5] <author> V. Klingspor, K. Morik, and A. Rieger. </author> <title> Learning concepts from sensor data of a mobile robot. </title> <note> (submitted to Machine Learning Journal), </note> <month> September </month> <year> 1994. </year>
Reference-contexts: 1 Introduction One problem in navigation is to guide a robot in such a way, that it can choose future actions, in order to achieve a goal, by taking into account perceived sensor data. In <ref> [5] </ref> and [6], operational concepts have been introduced, which are used by a human user to guide a robot. They constitute the basis for high-level planning, but are also symbolically grounded in robot perceptions. <p> As we are dealing with real-world data, we also have to account for the uncertainties and ambiguities, associated with the sensor measurements. In <ref> [5] </ref>, [6], we have used inductive logic programming algorithms, which learn deterministic rules, which derive higher-level action-oriented perceptual features from lower-level ones. These rules do not take into account the uncertainties, which are associated with sensor observations: rules were learned, which derive different concepts from the same sensor data. <p> So, the contribution of this work is to learn this automaton from classified sensor data of robot traces through known environments. 2 The Approach In <ref> [5] </ref>, operational concepts were developed, which are used by a robot to perform user-defined navigation tasks in a flexible way. Operational concepts offer an alternative to conventional robot programming.
Reference: [6] <author> K. Morik and A. Rieger. </author> <title> Learning action-oriented perceptual features for robot navigation. </title> <booktitle> In Proc. of the 1st European Workshop on Learning Robots, </booktitle> <year> 1993. </year> <note> also available as Research Report 3, </note> <institution> FB Informatik LS 8, Universitat Dortmund. </institution>
Reference-contexts: 1 Introduction One problem in navigation is to guide a robot in such a way, that it can choose future actions, in order to achieve a goal, by taking into account perceived sensor data. In [5] and <ref> [6] </ref>, operational concepts have been introduced, which are used by a human user to guide a robot. They constitute the basis for high-level planning, but are also symbolically grounded in robot perceptions. <p> As we are dealing with real-world data, we also have to account for the uncertainties and ambiguities, associated with the sensor measurements. In [5], <ref> [6] </ref>, we have used inductive logic programming algorithms, which learn deterministic rules, which derive higher-level action-oriented perceptual features from lower-level ones. These rules do not take into account the uncertainties, which are associated with sensor observations: rules were learned, which derive different concepts from the same sensor data. <p> If the robot executes this concept in the room, illustrated in Figure 2, the sensors on its right side will first perceive the doorframe, labeled 9, and then the wall, labeled 7. Correspondingly, the sensors on the robot's left side will perceive doorframe 3 and wall 5. In <ref> [6] </ref>, we introduced the term jump for these kind of "edge" groupings, consisting of two parallel walls. An example of a rule 1 , which has been learned, is the following: through_door (Tr,Start,End,parallel) &lt;- sg_jump (Tr,left,T1,T2,parallel) & sg_jump (Tr,right,T1,T2,parallel) & Start &lt; T1 & T2 &lt; End. <p> The measurements at time points 4 and 5 differ significantly, which is reflected by the incr peak predicate. We illustrate our approach to automata inference with the subtask of learning how to derive sensor features from basic features. In <ref> [6] </ref>, we have used inductive logic programming methods, which infer Horn clauses, such as s_jump (Tr,Sensor,T1,T4,parallel) &lt;- stable (Tr,Or,Sensor,T1,T2,Grad1) & incr_peak (Tr,Or,Sensor,T2,T3,Grad2) & stable (Tr,Or,Sensor,T3,T4,Grad3). The premises of these rules can be considered as sequences of temporally ordered observations, the conclusions as concept classifications. <p> There have been numerous approaches, based on L fl , for inferring automata, also with applications to robotics, e.g. [7],[10],[11]. The characteristic feature of these approaches is, that they work on representations in propositional logic. Therefore, they cannot be applied directly to the domain used in <ref> [6] </ref>, which is represented within a restricted first-order logic. Modifications of the algorithm seem to be possible, in order to apply it to our domain. Nevertheless, in our case, the construction of the prefix tree is a more straightforward way of attaining the automaton structure for a more complex representation.
Reference: [7] <author> R.E. Schapire R. L. Rivest. </author> <title> Inference of finite automata using homing sequences. In R.L. </title> <editor> Rivest S. J. Hanson, W. Remmele, editor, </editor> <booktitle> Machine Learning: From Theory to Applications, </booktitle> <pages> pages 51-73. </pages> <publisher> Springer, </publisher> <year> 1993. </year>
Reference: [8] <author> L. R. Rabiner. </author> <title> A tutorial on hidden Markov models and selected applications in speech recognition. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 77 </volume> <pages> 257-286, </pages> <year> 1989. </year>
Reference-contexts: In our case, this distribution is trivial, as we have only one starting ste q 0 , whose probability is 1. fl denotes the observation probability distribution, which can be associated either with states (see <ref> [8] </ref>) or with state transitions (see [4]).
Reference: [9] <author> A. S. Rao. </author> <title> Means-end plan recognition towards a theory of reactive recognition. </title> <editor> In J. Doyle, E. Sandewall, and P. Torasso, editors, </editor> <booktitle> Proc. 4th Int. Conf. on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 497-508, </pages> <year> 1994. </year>
Reference-contexts: They combine robot actions with the perceptions, which can be derived from the sensor data during execution, and which are used to recognize landmarks, which confirm successful goal achievement. Operational concepts can be used in plan-recognition systems (e.g. <ref> [9] </ref>), that reason about what kinds of actions might be supported by an observation, and about what kinds of actions might be performed in order to achieve a goal.
Reference: [10] <author> Wei-Min Shen. </author> <title> Learning finite automata using local distinguishing experiments. </title> <editor> In R. Bajcsy, editor, </editor> <booktitle> Proc. IJCAI 1993, </booktitle> <pages> pages 1088-1093. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference: [11] <author> W. Tzeng. </author> <title> Learning probabilistic automata and Markov chains via queries. </title> <journal> Machine Learning, </journal> <volume> 8 </volume> <pages> 151-166, </pages> <year> 1992. </year>
Reference: [12] <author> St. Wessel. </author> <title> Lernen qualitativer Merkmale aus numerischen Robotersensordaten. </title> <type> Master's thesis, </type> <institution> Universitat Dortmund, </institution> <year> 1995. </year> <note> in German. </note>
References-found: 12

