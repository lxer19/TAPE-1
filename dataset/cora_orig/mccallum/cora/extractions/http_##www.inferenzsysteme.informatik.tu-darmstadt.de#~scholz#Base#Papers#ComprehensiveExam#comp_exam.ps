URL: http://www.inferenzsysteme.informatik.tu-darmstadt.de/~scholz/Base/Papers/ComprehensiveExam/comp_exam.ps
Refering-URL: http://www.inferenzsysteme.informatik.tu-darmstadt.de/~scholz/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: MS Comprehensive  
Author: Ulrich Scholz 
Date: April 1995 March 3 April 3, 1995  
Pubnum: Examination  
Abstract-found: 0
Intro-found: 1
Reference: [Aho72] <author> A. V. Aho and J. D. Ullman, </author> <title> "The Theory of Parsing, Translation and Compiling, Vol. I: Parsing", </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N. J., </address> <year> 1972 </year>
Reference: [Aho73] <author> A. V. Aho and J. D. Ullman, </author> <title> "The Theory of Parsing, Translation and Compiling, Vol. II: Compiling", </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N. J., </address> <year> 1973 </year>
Reference: [Aho86] <author> A. V. Aho, R. Sethi, and J. D. Ullman, </author> <booktitle> "Compilers, Principles, Techniques, and Tools", </booktitle> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1986 </year>
Reference: [Chaitin81] <author> G. J. Chaitin, M. A. Auslander, A. K. Chandra, J. Cocke, M. E. Hopkins, and P. W. Mark-stein, </author> <title> "Register allocation via coloring", </title> <journal> Computer Languages, </journal> <volume> Vol. 6, </volume> <year> 1981, </year> <pages> pp. 47-57 </pages>
Reference-contexts: The theoretically infinite number of registers in the intermediate language has to be assigned to the limited resources of a real machine. If there are not enough, expensive loads and stores have to be inserted. <ref> [Chaitin81] </ref> presented a method to solve this problem via graph coloring. Graph theory examined the question if a given graph can be colored with n colors. This means that every node can be assigned a color so that no edge connects two nodes with the same.
Reference: [Chomsky56] <author> N. Chomsky, </author> <title> "Three models for the description of languages", </title> <journal> IRE Transactions on Information Theory, </journal> <volume> Vol. IT-2, No. 3, </volume> <month> March </month> <year> 1956, </year> <pages> pp. 113-124 </pages>
Reference-contexts: Beginning with the starting symbol, these replacements take place until no nonterminal is left. All resulting strings producible by a grammar, are called the language of this grammar. All these grammars can be grouped by the Chomsky hierarchy <ref> [Chomsky56] </ref>. Its four classes have differently restricted productions and therefore different expressionality. From the least to the most expressive they are called regular, context-free, context-sensitive, and unrestricted. 1 Comprehensive Examen, Spring 1995 | #13 Programming languages are usually context-sensitive.
Reference: [Donnelly92] <author> C. Donnelly and R. Stallman, "Bison, </author> <title> the YACC-compatible Parser Generator", </title> <note> Bison version 1.20, http://csugrad.cs.vt.edu:80/manuals/bison/bison toc.html, </note> <month> December </month> <year> 1992 </year>
Reference-contexts: Because of their size and the difficulties to implement them, they are usually generated by a tool called parser generator, an example is Bison <ref> [Donnelly92] </ref>. The input to Bison is machine-readable BNF, the parsing algorithm is LALR (1). To resolve conflicts, Bison offers several methods. Shift/reduce conflicts are solved by choosing shift, unless directed otherwise. It is possible to specify operator precedence to ease the task of writing the grammar.
Reference: [Johnson68] <author> W. L. Johnson, J. H. Porter, S. I. Ackerly, and D. T. Ross, </author> <title> "Automatic Generation of Efficient Lexical Processors Using Finite State Techniques", </title> <journal> Communications of the Association for Computer Machinery, </journal> <volume> Vol. 11, No. 12, </volume> <month> December </month> <year> 1968, </year> <pages> pp. 805-813 </pages>
Reference-contexts: No other part of the compiler has to deal with the raw program. In the early days of computer science, the lexical analysis was not a separate part. It was tied into the syntax analysis and caused a large part of the runtime of the compiler <ref> [Johnson68] </ref>. 3.1 Regular Languages The common way to describe the basic components of a program is using a regular language. It can be described by a regular grammar or regular expressions. The latter are first discussed in [Kleene56]. Their productions are very restricted. <p> This insight had influences in forming the way programming languages are constructed today. Before, `lexical properties have been assigned a very minor role in computer languages, . . . ' <ref> [Johnson68] </ref>. 1 IF IF = THEN THEN THEN = ELSE ELSE ELSE = END END can be a legal statement in APL. 2 Comprehensive Examen, Spring 1995 | #13 If the keywords of the language are reserved, the machine can distinguish between them and user defined symbols. <p> The entries have the function of vertices. 3.3 Scanner Generators It is quite easy to generate such a machine from regular expressions. Shortly after the basic research, it was recognized that this process can be automatized. One of the early generators is described in <ref> [Johnson68] </ref>. Usually one has to list regular expressions.
Reference: [Kastens80] <author> U. Kastens, </author> <title> "Ordered attribute grammars", </title> <journal> Acta Informatica, </journal> <volume> Vol. 13, No. 3, </volume> <month> March </month> <year> 1980, </year> <pages> pp. </pages> <address> 229-256 Comprehensive Examen, </address> <month> Spring </month> <year> 1995 </year> <month> | #13 </month>
Reference-contexts: Examples for this are if then else and operator precedence in expressions. In general language constructs can be modeled in a way which reflects their semantics. This is helpful for all following compiler stages. 5 Comprehensive Examen, Spring 1995 | #13 5.3 Ordered Attribute Grammars <ref> [Kastens80] </ref> introduced ordered attribute grammars. The properties of this subset of attribute grammars make them applicable to problems of compiler construction. Their expressionality is large enough to define the semantics of a programming language in it.
Reference: [Kastens82] <author> U. Kastens, B. Hutt, and E. Zimmermann, "GAG: </author> <title> A Practical Compiler Generator", </title> <publisher> Springer Verlag, </publisher> <year> 1982 </year>
Reference-contexts: One example is the GAG-system <ref> [Kastens82] </ref>. The input is written in Aladin, a language to specify the attribute rules and the context conditions.
Reference: [Kleene56] <author> S. C. Kleene, </author> <title> "Representations of events in nerve nets", </title> <booktitle> in [Shannon56], </booktitle> <pages> pp. 3-41 </pages>
Reference-contexts: It can be described by a regular grammar or regular expressions. The latter are first discussed in <ref> [Kleene56] </ref>. Their productions are very restricted. The left side of it is only a nonterminal, no context information is allowed to determine the production. Only one nonterminal is allowed on the right side of the production, and it has to be on the very right side of the string.
Reference: [Knuth62] <author> D. E. Knuth, </author> <title> "A history of writing compilers", </title> <journal> Computers and Automation, </journal> <month> December </month> <year> 1962, </year> <pages> pp. 8-18, </pages> <note> reprinted in [Pollack72] </note>
Reference-contexts: The nonterminals are nodes and the string consists out of the leaves being read from left to right. In case of a compiler, this structure is called parse tree. Early compilers used recursive descent. For every language construct, there was a function which could translate it, as described in <ref> [Knuth62] </ref>. With this technique, syntactical and semantical analysis was coupled, and the compilers were very inflexible. 4.2 Ambiguities There might be several ways to generate a sequence from a grammar. These ambiguities cause the existence of several parse trees for one sequence. <p> All the semantic information of the source program is stored in the compiler. This data has to be transformed in a way to allow the code generation do its task. An early technique was semantic evaluation through recursive calls. <ref> [Knuth62] </ref> describes this for expressions. In the early sixties, the idea of syntax directed translation was developed. Functions, which are associated with grammar rules, perform semantic actions and compute attributes.
Reference: [Knuth65] <author> D. E. Knuth, </author> <title> "On the Translation of Languages from Left to Right", </title> <journal> Information and Control, </journal> <volume> Vol. 8, No. 6, </volume> <month> December </month> <year> 1965, </year> <pages> pp. 607-639 </pages>
Reference-contexts: This is called shift-reduce parsing. The most general members of this group are LR (1)-parsers, which are introduced by <ref> [Knuth65] </ref>. The idea is to replace the leftmost substring in the input, which matches a right side of a production, by the nonterminal on the left of this production. This action is a reduction and the substring to be replaced is called handle.
Reference: [Knuth68] <author> D. E. Knuth, </author> <title> "Semantics of context-free languages", </title> <journal> Mathematical Systems Theory, </journal> <volume> Vol. 2, No. 2, </volume> <month> June </month> <year> 1968, </year> <pages> pp. 127-145 </pages>
Reference-contexts: An early technique was semantic evaluation through recursive calls. [Knuth62] describes this for expressions. In the early sixties, the idea of syntax directed translation was developed. Functions, which are associated with grammar rules, perform semantic actions and compute attributes. They are invoked when the rule is used. <ref> [Knuth68] </ref> introduced the idea of inherited attributes, which have made the evaluation much easier. 5.1 Attributes Attributes are values which can be associated with every grammar symbol. They can be computed from attributes of the production in which the symbol appears. <p> Furthermore Kastens gives an algorithm which determines whether a given attribute grammar is ordered or not. 5.4 Translation The dependence between attributes results in an order, in which they have to be evaluated, provided there is no circle. <ref> [Knuth68] </ref> gives an algorithm to prove noncircularity. The translation of the input program is the evaluation of semantic actions in the order indicated by this dependency. For s-attribute parse trees, the evaluation can be performed in the same pass as the LR-parser.
Reference: [Kruseman73] <author> F. E. J. Kruseman Arentz, P. J. W. Ten Hagen, and H. L. Oudshoorn, </author> <title> "An Algol 60 Compiler in Algol 60", </title> <publisher> Mathematisch Centrum Amsterdam, </publisher> <year> 1973 </year>
Reference-contexts: This translation is easy and can be performed automatically by a simple assembler. The appearance of machine independent languages made it necessary to use more powerful tools. These early compilers, as described in <ref> [Kruseman73] </ref>, were hand coded and applied methods, which were much less usable and general as the ones chosen today. This straight forward way of compiler construction had a drawback. They were written for only one special computers and no part of it could be reused with another language.
Reference: [Lewis68] <author> P. M. Lewis II and R. E. Stearns, </author> <title> "Syntax-Directed Transduction", </title> <journal> Journal of the Association for Computer Machinery, </journal> <volume> Vol. 15, No. 3, </volume> <month> July </month> <year> 1968, </year> <pages> pp. 465-488 </pages>
Reference-contexts: LR (1) or LALR (1) are in that family. All read the token stream from the left and use one symbol lookahead. 4.4 Top-Down Parsing As described in <ref> [Lewis68] </ref>, a top-down parsing algorithm like LL (1), tries to predict the productions of the leftmost nonterminal. It begins with the starting symbol of the grammar. This is possible if the grammar is not inherently ambiguous and if for every nonterminal, each production has a different terminal as leftmost symbol.
Reference: [Lewis76] <author> P. M. Lewis II, D. J. Rosenkrantz, and R. E. Stearns, </author> <title> "Compiler Design Theory", </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1976 </year>
Reference: [Minker80] <author> J. Minker and R. G. Minker, </author> <title> "Optimization of Boolean Expressions | Historical Developments", </title> <journal> Annals of the History of Computing, </journal> <volume> Vol. 2, No. 3, </volume> <month> July </month> <year> 1980, </year> <pages> pp. </pages> <editor> 227-238 [Naur63] ed. P. Naur, </editor> <title> "Revised report on the algorithmic language Algol 60", </title> <journal> Communications of the Association for Computer Machinery, </journal> <volume> Vol. 6, No. 1, </volume> <month> January </month> <year> 1963, </year> <pages> pp. </pages> <editor> 1-17 [Pollack72] ed. B. W. Pollack, </editor> <title> "Compiler Techniques", </title> <publisher> Auerbach Publishers Inc., Princeton, </publisher> <editor> N. J., </editor> <year> 1972 </year>
Reference-contexts: All these methods have to deal with subexpressions, which cause side effects. Only if the compiler can prove there is none or the semantic of the programming language allows to change them, these optimations can be applied. Some methods are described and shown in their historical context in <ref> [Minker80] </ref>. One method is to eliminate redundant computations. By computing p ^ q, with p = true, the result is determined after evaluating p. The whole expression can be written with control-flow statements in a way that the result is given at the earliest possible moment.
Reference: [Shannon56] <author> C. E. Shannon and J. McCarthy, </author> <title> "Automata Studies", </title> <publisher> Princeton University Press, </publisher> <year> 1956 </year>
Reference: [Valiant75] <author> L. G. Valiant, </author> <title> "General Context-Free Recognition in Less than Cubic Time", </title> <journal> Journal of Computer and Systems Sciences, </journal> <volume> Vol. 10, No. 2, </volume> <month> April </month> <year> 1975, </year> <pages> pp. 308-315 </pages>
Reference-contexts: The task of the syntax analysis is to construct the parse tree out of the token stream, delivered by the lexical analysis. The algorithm of Cocke-Younger-Kasami [Younger67], which was the first discovered, or the algorithm of Valiant <ref> [Valiant75] </ref>, which has actually the lowest time bound, can perform this task for all context-free languages. All general techniques are too slow for practical usage. The solution is to use a subset of all context-free languages. They restrict expressionality in favor of easier analysis. Some strings cannot be parsed.
Reference: [Wirth66] <author> N. Wirth and H. Weber, </author> <title> "Euler: A Generalization of Algol, and its Formal Definition: Part I", </title> <journal> Communications of the Association for Computer Machinery, </journal> <volume> Vol. 9, No. 1, </volume> <month> January </month> <year> 1966, </year> <pages> pp. 13-25 </pages>
Reference-contexts: This early technique was used without a grammar in Euler <ref> [Wirth66] </ref>. The underlying grammar has the property that no two nonterminals are consecutive. It can be used to parse expressions where the operations, hence the name, have different precedence. The algorithm uses three relations to structure the terminals, &lt;, : =, and &gt;.
Reference: [Younger67] <author> D. H. Younger, </author> <title> "Recognition and Parsing of Context-Free Languages in Time n 3 ", Information and Control, </title> <journal> Vol. </journal> <volume> 10, No. 2, </volume> <month> February </month> <year> 1967, </year> <pages> pp. 189-208 10 </pages>
Reference-contexts: One can use it to write an analyzing program or as an input to a generator. The task of the syntax analysis is to construct the parse tree out of the token stream, delivered by the lexical analysis. The algorithm of Cocke-Younger-Kasami <ref> [Younger67] </ref>, which was the first discovered, or the algorithm of Valiant [Valiant75], which has actually the lowest time bound, can perform this task for all context-free languages. All general techniques are too slow for practical usage. The solution is to use a subset of all context-free languages.
References-found: 21

