URL: ftp://ftp.cs.dartmouth.edu/TR/TR94-224.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/reports/abstracts/TR94-224/
Root-URL: http://www.cs.dartmouth.edu
Title: BMMC Permutations on a DECmpp 12000/Sx 2000  
Author: Kristin Bruhl 
Degree: Computer Science Honors Thesis  
Date: June 8, 1994  
Abstract-found: 0
Intro-found: 1
Reference: [CLR90] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: We address matrix elements beginning with 0. operations are performed on entire blocks. A block size of 1 allows manipulation of individual records. 2 The definitions and examples used in this chapter are taken from <ref> [CLR90, Section 31.1] </ref>. Chapter 2. Background 10 A vector is a matrix with just one column. For example, x = 6 6 2 5 7 7 is a vector of length 3. We use lowercase letters to denote vectors. The ith element of an n-vector is denoted x i .
Reference: [Cor92] <author> Thomas H. Cormen. </author> <title> Virtual Memory for Data-Parallel Computing. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Mas-sachusetts Institute of Technology, </institution> <year> 1992. </year> <note> Available as Technical Report MIT/LCS/TR-559. </note>
Reference-contexts: Effective algorithms that decrease the time required to permute the data within a parallel computer can yield a significant speed increase in running programs with large data sets. Cormen <ref> [Cor92, Cor93] </ref> has designed algorithms to improve performance when the data movement is defined by certain classes of permutations. This thesis will examine the performance of one of these classes, the bit-matrix-multiply/complement (BMMC) permutation, when implemented on the DECmpp. <p> This model is similar to the Vitter-Shriver scheme [VS90, NV91] for the layout of data on a parallel disk system, used by <ref> [Cor92, Cor93, CSW93] </ref>. In the Vitter-Shriver model, the independent processors are disks, rather than the PEs that we use. Accordingly, N records are stored on D disks. 1 The layout of records is shown 1 The Vitter-Shriver model also allows for blocks of records on each disk. <p> From all of the above, define a set of source addresses fx (0) ; x (1) ; : : : ; x (D1) g, which constitutes a 1-permutable set of blocks [Cor93]. We describe each step of the process, using a running example (from <ref> [Cor92] </ref>) to help in understanding. Finding a set of basis columns We first find a set S of d columns such that the submatrix A 0::d1;S , is nonsingular. As we stated in Section 2.3, since A is nonsingular, all of its rows are linearly independent. Chapter 4.
Reference: [Cor93] <author> Thomas H. Cormen. </author> <title> Fast permuting in disk arrays. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <note> 17(1-2):41-57, January and February 1993. </note>
Reference-contexts: Effective algorithms that decrease the time required to permute the data within a parallel computer can yield a significant speed increase in running programs with large data sets. Cormen <ref> [Cor92, Cor93] </ref> has designed algorithms to improve performance when the data movement is defined by certain classes of permutations. This thesis will examine the performance of one of these classes, the bit-matrix-multiply/complement (BMMC) permutation, when implemented on the DECmpp. <p> This model is similar to the Vitter-Shriver scheme [VS90, NV91] for the layout of data on a parallel disk system, used by <ref> [Cor92, Cor93, CSW93] </ref>. In the Vitter-Shriver model, the independent processors are disks, rather than the PEs that we use. Accordingly, N records are stored on D disks. 1 The layout of records is shown 1 The Vitter-Shriver model also allows for blocks of records on each disk. <p> We also mention a few coding issues which arose during implementation of the algorithm. 4.1 Cormen's BMMC Permutation Algorithm Cormen has developed an algorithm to perform any block BMMC permutation for which the block size is 1 on a Vitter-Shriver parallel disk system in only one pass over the data <ref> [Cor93] </ref>. To describe this algorithm, he relies on a technique of partitioning 26 Chapter 4. Approach 27 the data into disjoint sets and permuting these sets sequentially. We describe this decomposition, and then show how Cormen's algorithm uses this method. <p> permutation of source addresses to target addresses and a positive integer k, we define a k-permutable set of records as a set of kD source records such that 1. each disk contains exactly k of these source records, and 2. each disk has exactly k target records mapped to it <ref> [Cor93] </ref>. We sequentially permute sets of kD records at a time until the entire set of source records has been permuted. We call this sequence of sets a schedule. <p> From all of the above, define a set of source addresses fx (0) ; x (1) ; : : : ; x (D1) g, which constitutes a 1-permutable set of blocks <ref> [Cor93] </ref>. We describe each step of the process, using a running example (from [Cor92]) to help in understanding. Finding a set of basis columns We first find a set S of d columns such that the submatrix A 0::d1;S , is nonsingular. <p> ; x (1) ; : : : ; x (D1) ) the following way: x S = Q 1 A 0::d1;T bin T (i) bin (R (i)) c 0::d1 ; (i) x V = 0 The source addresses specified by the above method yield a 1-permutable set, as Cormen proves <ref> [Cor93] </ref>. Example: We let the complement vector c be all 0s to keep the example simple. Here we compute x (6) . We start by computing the bits in positions 1, 3, and 4, since S = f1; 3; 4g. <p> Cormen proves that this method does in fact generate a schedule given any 1-permutable set <ref> [Cor93] </ref>. 4.2 Using Cormen's Algorithm in the PE Array Cormen's algorithm for BMMC permutations was designed specifically for permuting data residing on a parallel disk array. However, we can use the same algorithm, with very little modification, to perform BMMC permutations on data residing on PEs within a PE array.
Reference: [CSW93] <author> Thomas H. Cormen, Thomas Sundquist, and Leonard F. Wisniewski. </author> <title> Asymptotically tight bounds for performing BMMC permutations on parallel disk systems. </title> <note> Submitted to IEEE Transactions on Parallel and Distributed Systems. Preliminary version appeared in Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, 1993. 62 Bibliography 63 </note>
Reference-contexts: This model is similar to the Vitter-Shriver scheme [VS90, NV91] for the layout of data on a parallel disk system, used by <ref> [Cor92, Cor93, CSW93] </ref>. In the Vitter-Shriver model, the independent processors are disks, rather than the PEs that we use. Accordingly, N records are stored on D disks. 1 The layout of records is shown 1 The Vitter-Shriver model also allows for blocks of records on each disk.
Reference: [Dig92a] <institution> Digital Equipment Corporation, Maynard, Massachusetts. </institution> <note> DECmpp Programming Language (ANSI) Reference Manual, Version 3.1 Field Test edition, </note> <month> December </month> <year> 1992. </year>
Reference: [Dig92b] <institution> Digital Equipment Corporation, Maynard, Massachusetts. </institution> <note> DECmpp Programming Language (ANSI) User's Guide, Version 3.1 Field Test edition, </note> <month> December </month> <year> 1992. </year>
Reference-contexts: We now proceed to examine the specific machine, the DECmpp 12000/Sx 2000, on which we perform the routing of these permutations. Chapter 3 The DECmpp Network In this chapter we describe the DECmpp 12000/Sx 2000, paying special attention to its array of parallel processors <ref> [Dig92b] </ref>. Then we will discuss a model for this network presented in [SS93], along with their work on routing permutations using this model. 3.1 The Machine The DECmpp 12000/Sx 2000 is a massively parallel processing system, made up of a console system and a data parallel unit (DPU).
Reference: [NV91] <author> Mark H. Nodine and Jeffrey Scott Vitter. </author> <title> Large-scale sorting in parallel memories. </title> <booktitle> In Proceedings of the 3rd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 29-39, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: This model is similar to the Vitter-Shriver scheme <ref> [VS90, NV91] </ref> for the layout of data on a parallel disk system, used by [Cor92, Cor93, CSW93]. In the Vitter-Shriver model, the independent processors are disks, rather than the PEs that we use.
Reference: [SS93] <author> Isaac D. Scherson and Raghu Subramanian. </author> <title> Efficient off-line routing of permutations on restricted access expanded delta networks. </title> <booktitle> In Proceedings of the 7th International Parallel Processing Symposium, </booktitle> <pages> pages 284-290, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Introduction 4 of the thesis. Chapter 3 describes the DECmpp 12000/Sx 2000, including the parallel processor array and the serial processors we also use. Chapter 3 also discusses a model of the network given by Scherson and Subramanian <ref> [SS93] </ref> and their work in routing permutations using this network model. Chapter 4 presents Cormen's algorithm for routing BMMC permutations. It explains how we modified this algorithm to make it compatible with the DECmpp environment and to maximize the benefit we can derive from running it on a parallel system. <p> In the context of an array of parallel processors, we use the term permutation to refer to an interprocessor communication in which each processor sends one piece of data and receives one piece of data <ref> [SS93] </ref>. 5 Chapter 2. Background 6 Frequently, a program will need to permute a vector of data larger than the number of processors on the machine. In this case, we can imagine a machine with enough processors to successfully complete the permutation. We call this a system of virtual processors. <p> Chapter 3 The DECmpp Network In this chapter we describe the DECmpp 12000/Sx 2000, paying special attention to its array of parallel processors [Dig92b]. Then we will discuss a model for this network presented in <ref> [SS93] </ref>, along with their work on routing permutations using this model. 3.1 The Machine The DECmpp 12000/Sx 2000 is a massively parallel processing system, made up of a console system and a data parallel unit (DPU). The console is a processor providing standard I/O devices. <p> We are concerned, then, not only with sending one record to or from each PE at one time, but also with sending only one record from and to each PE cluster. We will discuss this issue in depth in Chapter 4. 3.3 Expanded Delta Network Model Scherson and Subramanian <ref> [SS93] </ref> have examined the DECmpp global network 1 with respect to this restriction on accessing multiple PEs per cluster. They classify the network as an expanded delta network (EDN) and give an algorithm for routing permutations on the PEs through EDNs. <p> The port serialization we observed under the naive method is, as expected, significantly higher than under the permutable set methods. Figure 5.2 shows this data. The method of Subramanian and Scherson (given in <ref> [SS93] </ref>) which we discussed in Section 3.3 guarantees that every permutation can be routed in two passes through the DECmpp network. We implemented a specialized routing algorithm for BMMC permutations using their EDN model of the network.
Reference: [Sub93] <author> Raghu Subramanian. </author> <title> Private Communication, </title> <month> December </month> <year> 1993. </year>
Reference-contexts: These iterations are caused by two types of occurences in the network. One is contention for network ports. The other is congestion in the switches of the network, shown in Figure 3.2 as the lines between the three interior stages of the EDN <ref> [Sub93] </ref>. When we gathered data on port serialization under the three algorithms, we noted that in a small percentage of the runs, routerCount exceeds what we expect the port serialization to be under the PE-permutable set method and the cluster-permutable-set methods.
Reference: [VS90] <author> Jeffrey Scott Vitter and Elizabeth A. M. Shriver. </author> <title> Optimal disk I/O with parallel block transfer. </title> <booktitle> In Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 159-169, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: This model is similar to the Vitter-Shriver scheme <ref> [VS90, NV91] </ref> for the layout of data on a parallel disk system, used by [Cor92, Cor93, CSW93]. In the Vitter-Shriver model, the independent processors are disks, rather than the PEs that we use.
Reference: [Wis94] <author> Leneord Wisniewski. </author> <title> Private Communication, </title> <month> April </month> <year> 1994. </year>
Reference-contexts: Chapter 4. Approach 41 faster than accessing elements of an array as we would have done had we not packed the sets. * We used a method developed by Len Wisniewski <ref> [Wis94] </ref> for computing the set of basis columns, S. This method works as follows: 1. Create a submatrix A bottom of A, containing the lower d rows of A. 2. Find the leftmost column, j, of A bottom that contains a 1 and is not already in S. 3.
References-found: 11

