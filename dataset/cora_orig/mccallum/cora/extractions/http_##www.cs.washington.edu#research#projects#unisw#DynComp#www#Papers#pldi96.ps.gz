URL: http://www.cs.washington.edu/research/projects/unisw/DynComp/www/Papers/pldi96.ps.gz
Refering-URL: http://www.cs.washington.edu/research/projects/unisw/DynComp/www/Papers/pldi96-abstract.html
Root-URL: http://www.cs.washington.edu
Title: In PLDI96 Fast, Effective Dynamic Compilation  
Author: Joel Auslander, Matthai Philipose, Craig Chambers, Susan J. Eggers, and Brian N. Bershad 
Note: One mans variable is another mans constant. adapted from Alan J. Perlis [Per90]  
Affiliation: Department of Computer Science and Engineering University of Washington  
Abstract: Dynamic compilation enables optimizations based on the values of invariant data computed at run-time. Using the values of these run-time constants, a dynamic compiler can eliminate their memory loads, perform constant propagation and folding, remove branches they determine, and fully unroll loops they bound. However, the performance benefits of the more efficient, dynamically-compiled code are offset by the run-time cost of the dynamic compile. Our approach to dynamic compilation strives for both fast dynamic compilation and high-quality dynamically-compiled code: the programmer annotates regions of the programs that should be compiled dynamically; a static, optimizing compiler automatically produces pre-optimized machine-code templates, using a pair of dataow analyses that identify which variables will be constant at run-time; and a simple, dynamic compiler copies the templates, patching in the computed values of the run-time constants, to produce optimized, executable code. Our work targets general-purpose, imperative programming languages, initially C. Initial experiments applying dynamic compilation to C programs have produced speedups ranging from 1.2 to 1.8. 
Abstract-found: 1
Intro-found: 1
Reference: [ASU86] <author> A.V. Aho, R. Sethi, and J.D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: Second, we wished to support a variety of general-purpose programming languages, including C, without restricting their normal programming style. Accordingly, our analyses and transformations operate at the lower but more general level of control ow graphs connecting three-address code <ref> [ASU86] </ref>, rather than the higher, language-specific level of abstract syntax trees (as does some other work in this area [CN96,KR96,LL96]). Our analyses go to some length to support partially unstructured * control ow graphs well, since these graphs occur frequently in C programs.
Reference: [AWZ88] <author> B. Alpern, M.N. Wegman, and F.K. Zadeck. </author> <title> Detecting equality of variables in programs. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1988. </year> <note> [BSP + 95] B.N. </note> <author> Bershad, S. Savage, P. Pardyak, E.G. Sirer, M. Fiuczynski, D. Becker, S. Eggers, and C. Chambers. </author> <title> Extensibility, safety and performance in the SPIN operating system. </title> <booktitle> In Symposium on Operating Systems Principles, </booktitle> <month> November </month> <year> 1995. </year>
Reference-contexts: form --AfiT,Cs-,-AfiF,Cs-,Ds- to --Cs-,Ds-.) The following example illustrates the results of reachability analysis on an unstructured control ow graph for two different situations (the labels on the arcs * Alpern et al. extended f functions to include an argument representing the corresponding branch predicate, for structured if and loop constructs <ref> [AWZ88] </ref>. This would allow f to be treated as idempotent for all merges: if all the reaching definitions and the branch predicate were constant, then the result would be constant. Unfortunately, this technique does not extend easily to unstructured control flow graphs.
Reference: [CC95] <author> C. Click and K.D. Cooper. </author> <title> Combining analyses, combining optimizations. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 17(2), </volume> <month> March </month> <year> 1995. </year> <note> [CEA + 96] C. </note> <author> Chambers, S.J. Eggers, J. Auslander, M. Philipose, M. Mock, and P. Pardyak. </author> <title> Automatic dynamic compilation support for event dispatching in extensible systems. </title> <booktitle> In Workshop on Compiler Support for Systems Software, </booktitle> <month> February </month> <year> 1996. </year> <note> [CFR + 89] R. </note> <author> Cytron, J. Ferrante, B.K. Rosen, M.N. Wegman, and F.K. Zadeck. </author> <title> An efficient method of computing static single assignment form. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1989. </year>
Reference-contexts: Unfortunately, this technique does not extend easily to unstructured control flow graphs. The reachability analysis uses the results of run-time constants analysis to identify run-time constant branches, and the run-time constants analysis uses the results of reachability analysis to choose between f merge rules <ref> [CC95] </ref>. /* test is a constant */ if (test) - x 1 = 1; - else - x 2 = 2; /* x 1 and x 2 are constants */ x 3 = f (x 1 ,x 2 ); /* x 3 is constant */ t 1 ? x 3 :=
Reference: [CN96] <author> C. Consel and F. Nol. </author> <title> A general approach for run-time specialization and its application to C. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: Our compiler currently is only intraprocedural, but it can produce multiple compiled versions of a single dynamic region. Both Leone and Lee [LL96] and Consel and Nol <ref> [CN96] </ref> use a partial evaluation-based framework to build dynamic compilers. Leone and Lees system, called Fabius, applies dynamic compilation to a first-order, purely-functional subset of ML. The programmer uses explicit currying to indicate where dynamic compilation is to be applied.
Reference: [CU89] <author> C. Chambers and D. Ungar. </author> <title> Customization: Optimizing compiler technology for Self, a dynamically-typed object-oriented programming language. </title> <booktitle> In Conference on Programming Language Design and Implementation, </booktitle> <month> July </month> <year> 1989. </year>
Reference: [DS84] <author> L. Peter Deutsch and Allan M. Schiffman. </author> <title> Efficient implementation of the Smalltalk-80 system. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1984. </year>
Reference: [EHK96] <author> D.R. Engler, W.C. Hsieh, and M.F. Kaashoek. </author> <title> C: A language for high-level, efficient, and machine-independent dynamic code generation. </title> <booktitle> In Symposium on Principles of Programming Languages, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: Asymptotic Speedup (static/ dynamic region times) Breakeven Point Dynamic Compilation Overhead: set-up & stitcher (1000s cycles) Cycles/Instruction Stitched (number of instructions stitched) Reverse-polish stack-based desk calculator 2xy - 3y 2 - x 2 + (x+5) * 1.7 916 interpretations with different x, y values 452 734 Scalar-matrix multiply (adapted from <ref> [EHK96] </ref>) 800800 matrix, multi plied by all scalars 1..100 1.6 31,392 individual multi plications 260 4032 Sparse matrix-vector multiply 200200 matrix, 10 ele ments/row, 5% density 1.8 2645 matrix multiplications 83,700 7390 9696 matrix, 5 elements/ row, 5% density 1.5 1858 matrix multiplications 7,070 2478 Event dispatcher in an extensible OS <p> In a similar vein, Engler and Proebsting developed DCG [EP94], a library for constructing and manipulating expression trees that exploits the IBURG portable code generator library [Pro92]. The code generator infrastructure performed no optimizations other than instruction selection. Engler, Hsieh, and Kaashoek developed `C <ref> [EHK96] </ref>, an extension of the C language that makes constructing and manipulating expression trees look syntactically like fragments of C code, greatly easing the programming burden. DCG is used as the back-end infrastructure. More recently, Poletto, Engler, and Kaashoek have retargeted `C to use a template-based back-end [PEK96].
Reference: [EP94] <author> D.R. Engler and T.A. Proebsting. </author> <title> DCG: An efficient, retargetable dynamic code generation system. </title> <booktitle> In International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: They also developed a template-based approach. Their experiments demonstrated that these techniques outperformed the best statically-compiled, hand-tuned code in several applications. In a similar vein, Engler and Proebsting developed DCG <ref> [EP94] </ref>, a library for constructing and manipulating expression trees that exploits the IBURG portable code generator library [Pro92]. The code generator infrastructure performed no optimizations other than instruction selection.
Reference: [FRN84] <author> J.A. Fisher, J.C. Ruttenberg, and A. Nicolau. </author> <title> Parallel processing: A smart compiler and a dumb machine. </title> <booktitle> In Symposium on Compiler Construction, </booktitle> <year> 1984. </year>
Reference: [GKR95] <editor> B. Guenter, T.B. Knoblock, and E. Ruf. Specializing shaders. </editor> <booktitle> In SIGGRAPH 95, </booktitle> <year> 1995. </year>
Reference: [HU94] <author> U. Hlzle and D. Ungar. </author> <title> Optimizing dynamically-dispatched calls with run-time type feedback. </title> <booktitle> In Conference on Programming Language Design and Implementation, </booktitle> <month> June </month> <year> 1994. </year>
Reference: [JGS93] <author> N. Jones, C. Gomard, and P. Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference: [KEH93] <author> D. Keppel, S.J. Eggers, and R.R. Henry. </author> <title> Evaluating runtime-compiled, value-specific optimizations. </title> <type> Technical Report 93-11-02, </type> <institution> University of Washington, Department of Computer Science & Engineering, </institution> <year> 1993. </year> <month> 10 </month>
Reference-contexts: 1.8 2645 matrix multiplications 83,700 7390 9696 matrix, 5 elements/ row, 5% density 1.5 1858 matrix multiplications 7,070 2478 Event dispatcher in an extensible OS [BSP + 95,CEA + 96] 7 predicate types; 10 dif ferent event guards 1.4 722 event dispatches 638 357 (1667) Quicksort record sorter (extended from <ref> [KEH93] </ref>) 4 keys, each of a different type 1.2 3050 records 444 105 (65) 12 keys, each of a differ ent type 1.2 4760 records 790 400 (173) 8 Several optimizations, all applied dynamically, were responsible for the asymptotic speedups (Table 3).
Reference: [Kep96] <author> D. Keppel. </author> <title> Runtime code generation. </title> <type> Technical report, </type> <institution> University of Washington, Department of Computer Science & Engineering, </institution> <year> 1996. </year>
Reference: [KR96] <author> T.B. Knoblock and E. Ruf. </author> <title> Data specialization. </title> <booktitle> In Conference on Programming Language Design and Implementation, </booktitle> <month> May </month> <year> 1996. </year> <note> [LFK + 93] P.G. Lowney, S.M. </note> <author> Freudenberger, T.J. Karzes, W.D. Lichten-stein, R.P. Nix, J.S. ODonnell, and J.C. Ruttenberg. </author> <title> The Multi-flow trace scheduling compiler. </title> <journal> Journal of Supercomputing, </journal> <volume> 7, </volume> <year> 1993. </year>
Reference: [LL96] <author> M. Leone and P. Lee. </author> <title> Optimizing ML with run-time code generation. </title> <booktitle> In Conference on Programming Language Design and Implementation, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Our compiler currently is only intraprocedural, but it can produce multiple compiled versions of a single dynamic region. Both Leone and Lee <ref> [LL96] </ref> and Consel and Nol [CN96] use a partial evaluation-based framework to build dynamic compilers. Leone and Lees system, called Fabius, applies dynamic compilation to a first-order, purely-functional subset of ML. The programmer uses explicit currying to indicate where dynamic compilation is to be applied.
Reference: [PEK96] <author> M. Poletto, D.R. Engler, and M.F. Kaashoek. tcc: </author> <title> a template-based compiler for C. </title> <booktitle> In Workshop on Compiler Support for Systems Software, </booktitle> <month> February </month> <year> 1996. </year>
Reference-contexts: DCG is used as the back-end infrastructure. More recently, Poletto, Engler, and Kaashoek have retargeted `C to use a template-based back-end <ref> [PEK96] </ref>.
Reference: [Per90] <author> A.J. Perlis. </author> <booktitle> Epigrams on programming. In Communications of the ACM, </booktitle> <year> 1990. </year>
Reference: [PLR85] <author> R. Pike, B.N. Locanthi, and J.F. Reiser. </author> <title> Hardware/software trade-offs for bitmap graphics on the Blit. </title> <journal> Software Practice and Experience, </journal> <volume> 15(2), </volume> <year> 1985. </year>
Reference-contexts: optimizations by hand), but at the cost of longer dynamic compilation times (with the exception of template-based `C) and more tedious and error-prone programming work. 6.3 Other Dynamic Compilation Systems A number of previous systems have exploited dynamic compilation for run-time performance or exibility gains, for example, in graphics displaying <ref> [PLR85] </ref>, operating system operations [PAAB + 95,PMI88], and object-oriented systems [DS84,CU89,HU94].
Reference: [PMI88] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> (1), </volume> <month> winter </month> <year> 1988. </year>
Reference: [Pro92] <author> T.A. Proebsting. </author> <title> Simple and efficient BURS table generation. </title> <booktitle> In Conference on Programming Language Design and Implementation, </booktitle> <month> July </month> <year> 1992. </year>
Reference-contexts: They also developed a template-based approach. Their experiments demonstrated that these techniques outperformed the best statically-compiled, hand-tuned code in several applications. In a similar vein, Engler and Proebsting developed DCG [EP94], a library for constructing and manipulating expression trees that exploits the IBURG portable code generator library <ref> [Pro92] </ref>. The code generator infrastructure performed no optimizations other than instruction selection. Engler, Hsieh, and Kaashoek developed `C [EHK96], an extension of the C language that makes constructing and manipulating expression trees look syntactically like fragments of C code, greatly easing the programming burden.
Reference: [SZ88] <author> P. Sestoft and A.V. Zamulin. </author> <title> Annotated Bibliography on Partial Evaluation and Mixed Computation. </title> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference: [Wal86] <author> D.W. Wall. </author> <title> Global register allocation at link time. </title> <booktitle> In Symposium on Compiler Construction, </booktitle> <month> June </month> <year> 1986. </year> <month> 11 </month>
Reference-contexts: If all references to an array are through run-time constant offsets, then some array elements can be allocated to registers by the stitcher. We have begun experimenting with a variation of Walls register actions used in his link-time register allocator <ref> [Wal86] </ref>: the static compiler produces directives that indicate how to remove or modify instructions if a particular array element is stored in a register; the stitcher then executes these directives to eliminate loads, stores, and address arithmetic, after choosing registers for some number of array elements.
References-found: 23

