URL: http://www.cs.ucsd.edu/~silvia/CS96-512.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~silvia/
Root-URL: http://www.cs.ucsd.edu
Email: -silvia,berman-@cs.ucsd.edu  
Title: Modeling Contention Effects in Clustered Environments application, the local slowdown present in each node of
Author: Silvia M. Figueira and Francine Berman 
Web: http://www-cse.ucsd.edu/users/-silvia,berman  
Address: La Jolla, CA 92093-0114  
Affiliation: Department of Computer Science and Engineering University of California, San Diego  
Date: Dec 96  
Note: UCSD TR, CS96-512,  targeted  
Abstract: Data-parallel applications executing in clustered environments share resources with other applications. Since system load can vary dramatically, it is critical to provide an accurate model of the effects of contention on application performance in order to provide realistic assessments of application behavior. In this paper, we present a model to predict contention effects in clustered environments. This model provides a basis for predicting realistic execution times for applications on clusters of workstations and is parameterized by the data allocation policy employed by the 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Beguelin, J. Dongarra, G. Geist, R. Manchek, and V. Sunderam, </author> <title> Graphical Development Tools for Network-Based Concurrent Supercomputing, </title> <booktitle> in Proceedings of Supercomputing 91 </booktitle>
Reference-contexts: 1. Introduction Clusters of workstations have been used effectively as parallel machines for large, data-parallel, scientific applications <ref> [1, 4, 6, 13] </ref>. Workstations in such clusters are typically timeshared, causing competing applications to split CPU and memory capacity on each node.
Reference: [2] <author> F. Berman, R. Wolski, S. Figueira, J. Schopf, and G. Shao, </author> <title> Application-Level Scheduling on Distributed Heterogeneous Networks, </title> <booktitle> in Proceedings of Supercomputing96 , November 1996. </booktitle>
Reference-contexts: For this paper, we focus on loosely synchronous applications as classified by Fox [11]. These applications are coarse-grained data-parallel scientific applications in which computation and communication phases alternate. Such applications can profit from distribution in clustered environments as shown in <ref> [2] </ref>. The computational environment is a cluster of workstations, shared by CPU-bound serial and/or data-parallel distributed applications, which execute for the entire duration of the targeted application. Each node in the cluster has one CPU.
Reference: [3] <author> F. Berman and R. Wolski, </author> <title> Scheduling from the Perspective of the Application, </title> <booktitle> in Proceedings of the Fifth International Symposium on High-Performance Distributed Computing , pp. </booktitle> <volume> 100111, </volume> <month> August </month> <year> 1996. </year> <title> 500 600 700 800 no contention modeled measured t i m ( s c n s population size UCSD TR, </title> <address> CS96-512, </address> <month> Dec 96 </month>
Reference-contexts: When slowdown can be predicted accurately [9], this information can be used to improve scheduling decisions. Good scheduling is fundamental to the performance of parallel applications in shared distributed systems <ref> [3] </ref>, and an adequate contention model is critical to the development of performance-efficient schedules. In this paper, we develop a model for predicting the slowdown imposed on data-parallel applications executing on time-shared clusters of workstations.
Reference: [4] <author> A. Bricker, M. Litzkow, and M. Livny, </author> <title> Condor Technical Summary, </title> <type> Technical Report #1069, </type> <institution> University of Wisconsin, Computer Science Department, </institution> <month> May </month> <year> 1992. </year>
Reference-contexts: 1. Introduction Clusters of workstations have been used effectively as parallel machines for large, data-parallel, scientific applications <ref> [1, 4, 6, 13] </ref>. Workstations in such clusters are typically timeshared, causing competing applications to split CPU and memory capacity on each node.
Reference: [5] <author> W. L. Briggs, </author> <title> A Multigrid Tutorial, </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, Pennsylvania, </address> <year> 1987. </year>
Reference-contexts: In this section, we show a representative subset of the experiments performed on the homogeneous and heterogeneous clusters described above. 4.1 Experiments on the Homogeneous Cluster uniform data distribution policy. The experiment shown is a data-parallel Jacobi3D application <ref> [5] </ref> (developed using KeLP [10] and MPI [12]) which is executed for different problem sizes (given by ). The figure shows modeled and measured times for execution on 4 nodes of the DEC Alpha-Farm, where other applications are also executing. The data is distributed uniformly among the nodes. <p> This situation is illustrated in Figure 1. In this case, the Jacobi3D algorithm was slowed by a factor of 3 on the cluster. dedicated mode and with 2 different loads. constraint-based data distribution policy. Shown is a Multigrid application <ref> [5] </ref> (developed using KeLP [10] and MPI [12]) executed for different problem sizes (given by nodes of the DEC Alpha-farm. <p> Shown is a representative SOR application <ref> [5] </ref> developed using PVM [14] and executed on 4 nodes of the DEC Alpha-Farm. In both experiments data for the SOR application was distributed among the nodes according to the load. In experiment 1 ( ), there is also a CPU-bound data-parallel application executing on two of the nodes. <p> The experiment shown is a data-parallel Jacobi2D application <ref> [5] </ref> (developed using KeLP [10] and MPI [12]) executing for different problem sizes (given by ) on the four nodes of a cluster consisting of two DEC Alphas and two IBM RS-6000s. <p> Shown is a representative SOR application <ref> [5] </ref> developed using PVM [14] and executed for different problem sizes (given by ). The platform is a heterogeneous cluster consisting of two DEC Alphas and two IBM RS-6000s.
Reference: [6] <author> H. Dietz, W. Cohen, and B. Grant, </author> <title> Would you run it here...or there? (AHS: Automatic Heterogeneous Supercomputing), </title> <booktitle> in Proceedings of the International Conference on Parallel Processing , vol. II, </booktitle> <pages> pp. 217 221, </pages> <month> August </month> <year> 1993. </year>
Reference-contexts: 1. Introduction Clusters of workstations have been used effectively as parallel machines for large, data-parallel, scientific applications <ref> [1, 4, 6, 13] </ref>. Workstations in such clusters are typically timeshared, causing competing applications to split CPU and memory capacity on each node.
Reference: [7] <author> X. Du and X. Zhang, </author> <title> Coordinating Parallel Processes on Networks of Workstations, </title> <type> Technical Report, </type> <institution> High Performance Computing and Software Lab, University of Texas at San Antonio, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: The value for can be calculated as the ratio of the time to execute a task on the slowest node to the time to execute the same task on node (as described in <ref> [7] </ref>), such that the slowest node has the smallest weight. In a homogeneous cluster, . <p> Note that weights are application dependent <ref> [7, 8] </ref> and should be calculated with a benchmark that is representative of the class of the targeted application.
Reference: [8] <author> S. M. Figueira, </author> <title> Modeling the Effects of Contention on Application Performance in Multi-User Environments, </title> <type> Ph.D. Dissertation, </type> <institution> CSE Department, UCSD, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: Note that weights are application dependent <ref> [7, 8] </ref> and should be calculated with a benchmark that is representative of the class of the targeted application.
Reference: [9] <author> S. M. Figueira and F. Berman, </author> <title> Modeling the Effects of Contention on the Performance of Heterogeneous Applications, </title> <booktitle> in Proceedings of the Fifth International Symposium on High-Performance Distributed Computing , pp. </booktitle> <volume> 392401, </volume> <month> August </month> <year> 1996. </year>
Reference-contexts: The result of such sharing is that the fraction of resources available for a single distributed parallel application is reduced, causing a slowdown in the overall application performance. When slowdown can be predicted accurately <ref> [9] </ref>, this information can be used to improve scheduling decisions. Good scheduling is fundamental to the performance of parallel applications in shared distributed systems [3], and an adequate contention model is critical to the development of performance-efficient schedules.
Reference: [10] <author> S. J. Fink, S. B. Baden, and S. R. Kohn, </author> <title> Flexible Communication Mechanisms for Dynamic Structured Applications, </title> <booktitle> in Proceedings of the Third International Workshop on Parallel Algorithms for Irregularly Structured Problems , Santa Barbara, </booktitle> <address> CA, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: In this section, we show a representative subset of the experiments performed on the homogeneous and heterogeneous clusters described above. 4.1 Experiments on the Homogeneous Cluster uniform data distribution policy. The experiment shown is a data-parallel Jacobi3D application [5] (developed using KeLP <ref> [10] </ref> and MPI [12]) which is executed for different problem sizes (given by ). The figure shows modeled and measured times for execution on 4 nodes of the DEC Alpha-Farm, where other applications are also executing. The data is distributed uniformly among the nodes. <p> This situation is illustrated in Figure 1. In this case, the Jacobi3D algorithm was slowed by a factor of 3 on the cluster. dedicated mode and with 2 different loads. constraint-based data distribution policy. Shown is a Multigrid application [5] (developed using KeLP <ref> [10] </ref> and MPI [12]) executed for different problem sizes (given by nodes of the DEC Alpha-farm. Two of the nodes (nodes 2 and 3) also host a CPU-bound data-parallel application, and one of the nodes (node 1) also hosts two serial, CPU-bound applications, as shown in Figure 2. <p> The experiment shown is a data-parallel Jacobi2D application [5] (developed using KeLP <ref> [10] </ref> and MPI [12]) executing for different problem sizes (given by ) on the four nodes of a cluster consisting of two DEC Alphas and two IBM RS-6000s.
Reference: [11] <author> G. Fox, </author> <title> Hardware and Software Architectures for Irregular Problem Architectures, in Unstructured Scientific Computation on Scalable Multiprocessors , P. </title> <editor> Mehrotra, J. Saltz, and R. Voigt, </editor> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <pages> pp. 125160, </pages> <year> 1992. </year>
Reference-contexts: For this paper, we focus on loosely synchronous applications as classified by Fox <ref> [11] </ref>. These applications are coarse-grained data-parallel scientific applications in which computation and communication phases alternate. Such applications can profit from distribution in clustered environments as shown in [2].
Reference: [12] <author> Message-Passing Interface Forum, </author> <title> MPI: A Message-Passing Interface Standard, </title> <institution> University of Tennessee, Knoxville, TN, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: In this section, we show a representative subset of the experiments performed on the homogeneous and heterogeneous clusters described above. 4.1 Experiments on the Homogeneous Cluster uniform data distribution policy. The experiment shown is a data-parallel Jacobi3D application [5] (developed using KeLP [10] and MPI <ref> [12] </ref>) which is executed for different problem sizes (given by ). The figure shows modeled and measured times for execution on 4 nodes of the DEC Alpha-Farm, where other applications are also executing. The data is distributed uniformly among the nodes. <p> This situation is illustrated in Figure 1. In this case, the Jacobi3D algorithm was slowed by a factor of 3 on the cluster. dedicated mode and with 2 different loads. constraint-based data distribution policy. Shown is a Multigrid application [5] (developed using KeLP [10] and MPI <ref> [12] </ref>) executed for different problem sizes (given by nodes of the DEC Alpha-farm. Two of the nodes (nodes 2 and 3) also host a CPU-bound data-parallel application, and one of the nodes (node 1) also hosts two serial, CPU-bound applications, as shown in Figure 2. <p> The experiment shown is a data-parallel Jacobi2D application [5] (developed using KeLP [10] and MPI <ref> [12] </ref>) executing for different problem sizes (given by ) on the four nodes of a cluster consisting of two DEC Alphas and two IBM RS-6000s.
Reference: [13] <institution> NOW, </institution> <note> http://now.cs.berkeley.edu. </note>
Reference-contexts: 1. Introduction Clusters of workstations have been used effectively as parallel machines for large, data-parallel, scientific applications <ref> [1, 4, 6, 13] </ref>. Workstations in such clusters are typically timeshared, causing competing applications to split CPU and memory capacity on each node.
Reference: [14] <author> V. Sunderam, </author> <title> PVM: A Framework for Parallel Distributed Computing, </title> <journal> Concurrency: Practice and Experience , vol. </journal> <volume> 2, </volume> <editor> n. </editor> <volume> 4, </volume> <pages> pp. 315339, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Shown is a representative SOR application [5] developed using PVM <ref> [14] </ref> and executed on 4 nodes of the DEC Alpha-Farm. In both experiments data for the SOR application was distributed among the nodes according to the load. In experiment 1 ( ), there is also a CPU-bound data-parallel application executing on two of the nodes. <p> Shown is a representative SOR application [5] developed using PVM <ref> [14] </ref> and executed for different problem sizes (given by ). The platform is a heterogeneous cluster consisting of two DEC Alphas and two IBM RS-6000s. <p> Note that, even though there is one application executing on alpha , its local slowdown due to load imbalance is 1.33. data distribution on a heterogeneous cluster in dedicated mode and with contention. load-dependent data distribution policy with a Genetic Algorithm application [15] developed using PVM <ref> [14] </ref>. Shown are modeled and measured times for execution with different problem sizes (given by population size) on four nodes of a heterogeneous cluster consisting of two DEC Alphas and two IBM RS-6000s. In this experiment, the IBM RS-6000s are also executing a CPU-bound data-parallel application.
Reference: [15] <author> D. Whitley, T. Starkweather, and DUAnn Fuquay, </author> <title> Scheduling Problems and Traveling Salesman: The Genetic Edge Recombination Operator, </title> <booktitle> in Proceedings of International Conference on Genetic Algorithms 1989. </booktitle>
Reference-contexts: Note that, even though there is one application executing on alpha , its local slowdown due to load imbalance is 1.33. data distribution on a heterogeneous cluster in dedicated mode and with contention. load-dependent data distribution policy with a Genetic Algorithm application <ref> [15] </ref> developed using PVM [14]. Shown are modeled and measured times for execution with different problem sizes (given by population size) on four nodes of a heterogeneous cluster consisting of two DEC Alphas and two IBM RS-6000s. In this experiment, the IBM RS-6000s are also executing a CPU-bound data-parallel application.
References-found: 15

