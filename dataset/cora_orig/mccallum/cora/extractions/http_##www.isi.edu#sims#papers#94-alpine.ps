URL: http://www.isi.edu/sims/papers/94-alpine.ps
Refering-URL: http://www.isi.edu/~knoblock/
Root-URL: 
Email: Email: knoblock@isi.edu  
Title: Automatically Generating Abstractions for Planning  
Author: Craig A. Knoblock 
Note: To appear in Artificial Intelligence  
Address: 4676 Admiralty Way Marina del Rey, CA 90292  
Affiliation: Information Sciences Institute Computer Science Department University of Southern California  
Abstract: This article presents a completely automated approach to generating abstractions for planning. The abstractions are generated using a tractable, domain-independent algorithm whose only input is the definition of a problem to be solved and whose output is an abstraction hierarchy that is tailored to the particular problem. The algorithm generates abstraction hierarchies by dropping literals from the original problem definition. It forms abstractions that satisfy the ordered monotonicity property, which guarantees that the structure of an abstract solution is not changed in the process of refining it. The algorithm for generating abstractions is implemented in a system called alpine, which generates abstractions for a hierarchical version of the prodigy problem solver. The abstractions generated by alpine are tested in multiple domains on large problem sets and are shown to produce shorter solutions with significantly less search than planning without using abstraction. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: By Theorems 1 and 2, the constraints are sufficient to guarantee that a hierarchy built from these constraints will have the ordered monotonicity property. * Step 2 finds the strongly connected components of the graph using a depth-first search <ref> [1] </ref>. Two nodes in a directed graph are in the same strongly connected component if there is a path from one node to the other and back again. Thus, any node in a strongly connected component can be reached from any other node within the same component. <p> The complexity of steps 2-4 in the algorithm above is linear in the size of the graph. The complexity of both finding the strongly connected components of a directed graph and performing the topological sort is O (max (e; v)) <ref> [1] </ref>, where e is the number of edges (constraints) and v is the number of vertices (literals). Creating the reduced graph is also O (max (e; v)) since the new graph can be created by scanning through each of the vertices and edges once.
Reference: [2] <author> Alfred V. Aho, John E. Hopcroft, and Jeffrey D. Ullman. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1983. </year>
Reference-contexts: The literals within a node in the reduced graph must be placed in the same abstraction space and the constraints between nodes define a partial order of the possible abstraction hierarchies. * Step 4 transforms the partial order into a total order using a topological sort <ref> [2] </ref>. The total order defines a single ordered monotonic abstraction hierarchy. There may be a number of possible total orders for a given partial order and one order may be better than another. Section 4.3.3 describes the set of heuristics used to choose between the possible total orders.
Reference: [3] <author> John S. Anderson and Arthur M. Farley. </author> <title> Plan abstraction based on operator generalization. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <address> Saint Paul, MN, </address> <year> 1988, </year> <pages> 100-104. </pages>
Reference-contexts: While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies <ref> [3, 11, 53] </ref>. In most hierarchical planners, the designer of a planning domain must manually engineer the appropriate abstractions. This process is largely a black art since the properties of an effective abstraction hierarchy are not well understood. <p> Another limitation is that the predicate relaxation process may be very expensive and result in complex expressions that must be evaluated at planning time. Anderson <ref> [3] </ref> developed a system called planereus that automatically generates hierarchies of abstract operators and objects. The system constructs operator hierarchies by examining the operators that share common effects and forming new abstract operators that contain only the shared preconditions.
Reference: [4] <author> Fahiem Bacchus and Qiang Yang. </author> <title> The downward refinement property. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <address> Sydney, Australia, </address> <year> 1991, </year> <pages> 286-292. </pages>
Reference-contexts: Thus, using an abstraction space formed by dropping information it is difficult to guarantee the downward solution property. The same problem arises in the use of abstraction in theorem proving, where it is called the false proof problem [23, 51]. Bacchus and Yang <ref> [4, 5] </ref> identified a closely related property called the downward refinement property (DRP), which states that if a problem is solvable then any abstract solution must have a refinement. Thus, if a solution to a problem exists, then the conditions ignored 47 at the abstract level will be achievable.
Reference: [5] <author> Fahiem Bacchus and Qiang Yang. </author> <title> Downward refinement and the efficiency of hierarchical problem solving. </title> <institution> Research Report CS-92-45, Department of Computer Science, University of Waterloo, </institution> <year> 1992. </year>
Reference-contexts: Thus, using an abstraction space formed by dropping information it is difficult to guarantee the downward solution property. The same problem arises in the use of abstraction in theorem proving, where it is called the false proof problem [23, 51]. Bacchus and Yang <ref> [4, 5] </ref> identified a closely related property called the downward refinement property (DRP), which states that if a problem is solvable then any abstract solution must have a refinement. Thus, if a solution to a problem exists, then the conditions ignored 47 at the abstract level will be achievable. <p> More recently, Bacchus and Yang <ref> [5] </ref> developed a system called high-point that addresses this problem by combining their "near-DRP" property with alpine to generate abstractions. Fink [21] recently identified a number of refinements to the definition of justification that eliminate unnecessary operators in plans to various degrees.
Reference: [6] <author> Ranan B. Banerji and George W. Ernst. </author> <title> A comparison of three problem-solving methods. </title> <booktitle> In Proceedings of the Fifth International Joint Conference on Artificial Intelligence, </booktitle> <address> Cambridge, MA, </address> <year> 1977, </year> <pages> 442-449. </pages>
Reference-contexts: This is because it guarantees both that the problem will be solvable and that once a goal is satisfied it never needs to be violated to satisfy the remaining goals. Banerji and Ernst <ref> [6, 7] </ref> developed a formal model of difference ordering in gps [13], which requires that any goal condition that is already achieved cannot be reintroduced. This means that after a given difference is solved, the problem solver is prevented from reintroducing that difference.
Reference: [7] <author> Ranan B. Banerji and George W. Ernst. </author> <title> Some properties of GPS-type problem solvers. </title> <type> Technical Report 1179, </type> <institution> Department of Computer Engineering, Case Western Reserve University, </institution> <year> 1977. </year>
Reference-contexts: This is because it guarantees both that the problem will be solvable and that once a goal is satisfied it never needs to be violated to satisfy the remaining goals. Banerji and Ernst <ref> [6, 7] </ref> developed a formal model of difference ordering in gps [13], which requires that any goal condition that is already achieved cannot be reintroduced. This means that after a given difference is solved, the problem solver is prevented from reintroducing that difference.
Reference: [8] <author> Paul Benjamin, Leo Dorst, Indur Mandhyan, and Madeleine Rosar. </author> <title> An introduction to the decomposition of task representations in autonomous systems. </title> <editor> In D. Paul Benjamin, editor, </editor> <title> Change of Representation and Inductive Bias, </title> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1990, </year> <pages> 125-146. </pages>
Reference-contexts: A related idea is to construct macro objects instead of operators and then reason about the macro objects <ref> [8] </ref>. Other systems have also used macro operators, but instead of constructing a new macro space the macro operators are simply added to the original space [19, 26, 28, 38, 41, 52].
Reference: [9] <author> Jaime G. Carbonell, Craig A. Knoblock, and Steven Minton. </author> <title> PRODIGY: An integrated architecture for planning and learning. </title> <editor> In Kurt VanLehn, editor, </editor> <booktitle> Architectures for Intelligence, </booktitle> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1991, </year> <pages> 241-278. </pages>
Reference-contexts: This algorithm is implemented in the alpine system and the abstraction hierarchies generated by alpine are used in a version of the prodigy problem solver <ref> [9, 46] </ref> that was extended to plan hierarchically [35]. This article presents experimental results that demonstrate that alpine's abstractions provide significant reductions in search over planning without the use of abstraction. 1.1 Hierarchical Planning Planning involves finding a sequence of operators that solves a problem within a problem space.
Reference: [10] <author> Jie Cheng and Keki B. Irani. </author> <title> Ordering problem subgoals. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI, </address> <year> 1989, </year> <pages> 931-936. </pages>
Reference-contexts: This algorithm is less efficient than the one used by alpine and 46 does not provide a mechanism for grouping together differences if an ordering does not exist that satisfies the property. Irani and Cheng <ref> [10, 29] </ref> present an approach to ordering goals based on interactions determined statically from the operator definitions. For each problem the goal orderings are determined by backpropagating the goals through the operators to determine which of the other goals must already hold to apply the relevant operators.
Reference: [11] <author> Jens Christensen. </author> <title> Automatic Abstraction in Planning. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1991. </year>
Reference-contexts: This technique has been used successfully to reduce search in a number of planning systems, including gps [48], abstrips [53], abtweak [68], pablo <ref> [11] </ref>, and prodigy [32, 35]. While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies [3, 11, 53]. In most hierarchical planners, the designer of a planning domain must manually engineer the appropriate abstractions. <p> While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies <ref> [3, 11, 53] </ref>. In most hierarchical planners, the designer of a planning domain must manually engineer the appropriate abstractions. This process is largely a black art since the properties of an effective abstraction hierarchy are not well understood. <p> So refining an abstract plan at level i 1 can involve establishing literals at level i 1 and above. This formal definition captures the notion of plan refinement used in a number of different planners, including abstrips [53], abtweak [68], and pablo <ref> [11] </ref>. 2.4 Ordered Monotonicity Property Hierarchical planning reduces search by partitioning a problem into a number of smaller subproblems [33]. An effective partitioning of a problem requires that the subproblems can be solved without violating the conditions that were already achieved in the more abstract levels of the abstraction hierarchy. <p> This general approach has been referred to as state abstraction and was first used in Planning GPS [48]. This is also the approach used in abstrips [53] and pablo <ref> [11] </ref>, abtweak [68, 67], as well as alpine. absolver [47] also employs a form of state abstraction, but instead of refining abstract plans found using this simplified model, the abstract plans are used in the evaluation function of an admissible search procedure. <p> This limits the usefulness of the abstraction hierarchies since the bulk of the work would occur in the level with conditions that cannot be achieved by a short plan. pablo <ref> [11] </ref> is another system that generates abstractions for hierarchical planning. It uses a technique called predicate relaxation to determine the number of steps needed to achieve each predicate by partially evaluating the operators. <p> The augmented and ordered goals are then used in an admissible heuristic evaluation function. The augmentation of the goals is similar to the goal augmentation performed in alpine (Section 4.3.2), but the approach to ordering the goals is much more similar to the analysis in pablo <ref> [11] </ref>. Etzioni [16] developed a system called static, which statically analyzes the problem space definition to identify potential interactions. Based on these interactions, static generates a set of search control rules for prodigy to guide the problem solving.
Reference: [12] <author> Daniel S. Eavarone. </author> <title> A program that generates difference orderings for GPS. </title> <type> Technical Report SRC-69-6, </type> <institution> Systems Research Center, Case Western Reserve University, </institution> <year> 1969. </year>
Reference-contexts: The problem of finding good orderings of the differences has been extensively explored in gps and is closely related to the techniques for generating abstractions in alpine. The criterion for ordering the differences in <ref> [12, 15] </ref> is to attempt to find an ordering such that achieving one difference will not affect a difference reduced by operators selected earlier in the ordering. The algorithm for finding an ordering requires building a table of differences and finding a lower-triangular difference table.
Reference: [13] <author> George W. Ernst. </author> <title> Sufficient conditions for the success of GPS. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 16(4), </volume> <year> 1969, </year> <pages> 517-533. 55 </pages>
Reference-contexts: This is because it guarantees both that the problem will be solvable and that once a goal is satisfied it never needs to be violated to satisfy the remaining goals. Banerji and Ernst [6, 7] developed a formal model of difference ordering in gps <ref> [13] </ref>, which requires that any goal condition that is already achieved cannot be reintroduced. This means that after a given difference is solved, the problem solver is prevented from reintroducing that difference.
Reference: [14] <author> George W. Ernst and Michael M. Goldstein. </author> <title> Mechanical discovery of classes of problem--solving strategies. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 29(1), </volume> <year> 1982, </year> <pages> 1-23. </pages>
Reference-contexts: In a more recent system for generating difference orderings, Goldstein <ref> [14, 25] </ref> incorporated an additional restriction that also takes the preconditions into account and is thus analogous to the ordered monotonicity property. The system produces difference orderings by creating a difference table for the top-level goals and each set of precondition of the operators.
Reference: [15] <author> George W. Ernst and Allen Newell. </author> <title> GPS: A Case Study in Generality and Problem Solving. </title> <booktitle> ACM Monograph Series. </booktitle> <publisher> Academic Press, </publisher> <address> New York, NY, </address> <year> 1969. </year>
Reference-contexts: The problem of finding good orderings of the differences has been extensively explored in gps and is closely related to the techniques for generating abstractions in alpine. The criterion for ordering the differences in <ref> [12, 15] </ref> is to attempt to find an ordering such that achieving one difference will not affect a difference reduced by operators selected earlier in the ordering. The algorithm for finding an ordering requires building a table of differences and finding a lower-triangular difference table.
Reference: [16] <author> Oren Etzioni. </author> <title> A Structural Theory of Explanation-Based Learning. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1990. </year>
Reference-contexts: The results show that alpine reduces both solution time and solution length when compared with the basic prodigy system and performs comparably to hand-coded control knowledge. Second, it compares alpine's abstractions to the use of control knowledge acquired by explanation-based learning techniques <ref> [16, 44] </ref>. Again, the results show that alpine performs comparably to these techniques, but more importantly the combination of abstraction and control knowledge leads to performance that is better than any of the systems alone. <p> Minton [44] developed a system called prodigy/ebl that learns search control rules using explanation-based learning. More recently, Etzioni <ref> [16] </ref> developed a system called static that generates control rules using partial evaluation. This section compares the use of the abstractions generated by alpine to these two systems for learning search control knowledge. The learning systems are compared in the machine-shop scheduling domain that was described in the previous section. <p> The augmented and ordered goals are then used in an admissible heuristic evaluation function. The augmentation of the goals is similar to the goal augmentation performed in alpine (Section 4.3.2), but the approach to ordering the goals is much more similar to the analysis in pablo [11]. Etzioni <ref> [16] </ref> developed a system called static, which statically analyzes the problem space definition to identify potential interactions. Based on these interactions, static generates a set of search control rules for prodigy to guide the problem solving. <p> The article presented results on both generating and using abstractions on large sets of problems in multiple problem spaces. The use of abstraction is compared in prodigy to single-level problem solving, as well as problem solving with hand-coded control knowledge and control knowledge learned by ebl [44] and static <ref> [16] </ref>. The results show that the abstractions provide considerable reductions in search and improvements in solution quality over the basic prodigy system and provide comparable results to the EBL methods for learning control knowledge. Acknowledgments There are many people that contributed in one way or another to this work.
Reference: [17] <author> Oren Etzioni. </author> <title> A structural theory of explanation-based learning. </title> <journal> Artificial Intelligence, </journal> <volume> 60(1), </volume> <year> 1993, </year> <pages> 93-140. </pages>
Reference-contexts: The abstractions are generated by alpine and then used in the hierarchical ver 8 The idea of separating out the recursive literals was inspired by the work of Etzioni <ref> [17] </ref>, which identified the importance of nonrecursive explanations for explanation-based learning. 30 sion of prodigy. The section is divided into three subsections. The first subsection shows that alpine can generate effective abstraction hierarchies for a variety of problem domains.
Reference: [18] <author> Oren Etzioni and Ruth Etzioni. </author> <title> Statistical methods for analyzing speedup learning experiments. Machine Learning, </title> <publisher> forthcoming. </publisher>
Reference-contexts: To evaluate the statistical significance of the results in the experiment, we can apply the signed-rank test as presented by Etzioni and Etzioni <ref> [18] </ref>. This test generates an upper bound on what is called the p-value. The p-value is the probability that conclusions drawn from the data are in error. The lower the p-value, the stronger the evidence that the hypotheses are correct.
Reference: [19] <author> Richard E. Fikes, Peter E. Hart, and Nils J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3(4), </volume> <year> 1972, </year> <pages> 251-288. </pages>
Reference-contexts: A related idea is to construct macro objects instead of operators and then reason about the macro objects [8]. Other systems have also used macro operators, but instead of constructing a new macro space the macro operators are simply added to the original space <ref> [19, 26, 28, 38, 41, 52] </ref>.
Reference: [20] <author> Richard E. Fikes and Nils J. Nilsson. </author> <title> STRIPS: A new approach to the application of theorem proving to problem solving. </title> <journal> Artificial Intelligence, </journal> <volume> 2(3/4), </volume> <year> 1971, </year> <pages> 189-208. </pages>
Reference-contexts: However, what makes a good abstraction for one problem may make a bad abstraction for another. The algorithm presented in this paper generates abstraction hierarchies that are tailored to the individual problems. For example, the strips robot planning domain <ref> [20] </ref> involves using a robot to move boxes among rooms and opening and closing doors as necessary. For problems that simply involve moving boxes between rooms, doors are a detail that can be ignored since the robot can simply open the doors as needed. <p> The article describes these extensions in detail. 4 1.4 Experimental Results alpine has been successfully tested on a number of planning domains including the Tower of Hanoi, the original strips domain <ref> [20] </ref>, a more complex robot planning domain [44], and a machine-shop process planning and scheduling domain [44]. In all these domains, the system generates problem-specific abstraction hierarchies that provide significant reductions in search. <p> Using this extended algorithm, alpine is able to produce abstraction hierarchies for a variety of domains, including the Tower of Hanoi, the strips robot planning domain <ref> [20] </ref>, an extended version of the strips domain [44], and a machine-shop scheduling domain [44]. These results are described in Section 5. To illustrate these extensions, this section uses examples from the extended robot planning domain [44]. This domain is an augmented version of the original strips robot planning domain [20]. <p> <ref> [20] </ref>, an extended version of the strips domain [44], and a machine-shop scheduling domain [44]. These results are described in Section 5. To illustrate these extensions, this section uses examples from the extended robot planning domain [44]. This domain is an augmented version of the original strips robot planning domain [20]. In the original domain a robot can move among rooms, push boxes around, and open and close doors. In the augmented version, the robot can both push and carry objects and lock and unlock doors. <p> These domains were previously described in [44], where they were used to evaluate the effectiveness of the explanation-based learning (ebl) module in prodigy. 5.1.1 Extended STRIPS Domain This section describes the abstraction hierarchies generated by alpine for the extended version of the robot planning domain <ref> [20] </ref>, which includes locks, keys, and a robot that can both push and carry objects. The extensions to this domain make it considerably more complex since there are multiple ways to achieve the same goals and there are many potential dead-end search paths because of locked doors and unavailable keys. <p> The resulting abstraction hierarchies were then used for problem solving in an extended version of the strips planner <ref> [20] </ref>. This section compares the abstraction hierarchies generated by abstrips and alpine in the strips domain.
Reference: [21] <author> Eugene Fink. </author> <title> Justified plans and ordered hierarchies. </title> <type> Master's Thesis, </type> <institution> Department of Computer Science, University of Waterloo, </institution> <year> 1992. </year>
Reference-contexts: More recently, Bacchus and Yang [5] developed a system called high-point that addresses this problem by combining their "near-DRP" property with alpine to generate abstractions. Fink <ref> [21] </ref> recently identified a number of refinements to the definition of justification that eliminate unnecessary operators in plans to various degrees. He uses these refinements to restrict the definition of ordered monotonicity.
Reference: [22] <author> Eugene Fink and Qiang Yang. </author> <title> Automatically abstracting the effects of operators. </title> <editor> In J. Hendler, editor, </editor> <booktitle> Artificial Intelligence Planning Systems: Proceedings of the First International Conference (AIPS92), </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992, </year> <pages> 243-251. </pages>
Reference-contexts: The primary effects are implemented in prodigy by generating a set of control rules that select only the operators whose primary effects match a goal. The information about which effects are primary must be explicitly stated, however, recent work by Fink and Yang <ref> [22] </ref> describes an algorithm for automatically determining this information. 6 A problem space in prodigy can also include a set of control rules, but they only constrain the search space so alpine does not need to consider them to create ordered monotonic abstraction hierarchies. 22 4.1.2 Type Hierarchy The second component
Reference: [23] <author> Fausto Giunchiglia and Toby Walsh. </author> <title> Abstract theorem proving. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI, </address> <year> 1989, </year> <pages> 372-377. </pages>
Reference-contexts: Thus, using an abstraction space formed by dropping information it is difficult to guarantee the downward solution property. The same problem arises in the use of abstraction in theorem proving, where it is called the false proof problem <ref> [23, 51] </ref>. Bacchus and Yang [4, 5] identified a closely related property called the downward refinement property (DRP), which states that if a problem is solvable then any abstract solution must have a refinement.
Reference: [24] <author> Fausto Giunchiglia and Toby Walsh. </author> <title> A theory of abstraction. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 57(2-3), </pages> <year> 1992, </year> <pages> 323-390. </pages>
Reference-contexts: These abstraction spaces are called relaxed models [50] since they are formed by weakening the applicability conditions of the operators. Both reduced and relaxed models are what Giunchiglia and Walsh <ref> [24] </ref> refer to as TI (theorem increasing) abstractions since any theorem that holds in the ground space will hold in the abstract space, while the inverse does not hold. For the purposes of this paper, an abstraction space will be used to refer to a reduced model unless stated otherwise.
Reference: [25] <author> Michael M. Goldstein. </author> <title> The mechanical discovery of problem solving strategies. </title> <type> Technical Report ESCI-77-1, </type> <institution> Systems Engineering, Computer Engineering and Information Sciences, Case Western Reserve University, </institution> <year> 1978. </year>
Reference-contexts: In a more recent system for generating difference orderings, Goldstein <ref> [14, 25] </ref> incorporated an additional restriction that also takes the preconditions into account and is thus analogous to the ordered monotonicity property. The system produces difference orderings by creating a difference table for the top-level goals and each set of precondition of the operators.
Reference: [26] <author> H. Altay Guvenir and George W. Ernst. </author> <title> Learning problem solving strategies using refinement and macro generation. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 44(1-2), </pages> <year> 1990, </year> <pages> 209-243. </pages>
Reference-contexts: A related idea is to construct macro objects instead of operators and then reason about the macro objects [8]. Other systems have also used macro operators, but instead of constructing a new macro space the macro operators are simply added to the original space <ref> [19, 26, 28, 38, 41, 52] </ref>.
Reference: [27] <author> Robert Holte, Robert Zimmer, and Alan MacDonald. </author> <title> When does changing representation improve problem-solving performance? In Proceedings of the Workshop on Change of Representation and Problem Reformulation, </title> <institution> Nasa Ames Research Center, </institution> <type> Technical Report FIA-92-06, </type> <year> 1992, </year> <pages> 100-105. 56 </pages>
Reference-contexts: As shown in [33], the use of this particular abstraction hierarchy reduces the size of the search space from exponential to linear in the length of the solution. Holte, Zimmer and MacDonald <ref> [27] </ref> also showed both analytically and empirically that this decomposition of the problem will produce the shortest solution with the least amount of work. 20 4 Generating Abstractions in ALPINE alpine is a fully implemented system that generates abstraction hierarchies for the prodigy problem solver [46]. alpine is given a problem
Reference: [28] <author> Glenn A. Iba. </author> <title> A heuristic approach to the discovery of macro-operators. </title> <journal> Machine Learning, </journal> <volume> 3(4), </volume> <year> 1989, </year> <pages> 285-317. </pages>
Reference-contexts: A related idea is to construct macro objects instead of operators and then reason about the macro objects [8]. Other systems have also used macro operators, but instead of constructing a new macro space the macro operators are simply added to the original space <ref> [19, 26, 28, 38, 41, 52] </ref>.
Reference: [29] <author> Keki B. Irani and Jie Cheng. </author> <title> Subgoal ordering and goal augmentation for heuristic problem solving. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <address> Milan, Italy, </address> <year> 1987, </year> <pages> 1018-1024. </pages>
Reference-contexts: This algorithm is less efficient than the one used by alpine and 46 does not provide a mechanism for grouping together differences if an ordering does not exist that satisfies the property. Irani and Cheng <ref> [10, 29] </ref> present an approach to ordering goals based on interactions determined statically from the operator definitions. For each problem the goal orderings are determined by backpropagating the goals through the operators to determine which of the other goals must already hold to apply the relevant operators.
Reference: [30] <author> Craig A. Knoblock. </author> <title> Abstracting the Tower of Hanoi. In Proceedings of the Workshop on Automatic Generation of Approximations and Abstractions, </title> <address> Boston, MA, </address> <year> 1990, </year> <pages> 13-23. </pages>
Reference-contexts: As such, the algorithm will only find abstractions for a limited class of problem spaces. The next section describes a problem-specific version of this algorithm, which will produce abstractions for a wider class of problem spaces. 5 Charles Elkan pointed out that my original O (l 2 ) algorithm <ref> [30] </ref> could be transformed into a O (l) algorithm. 14 3.1.2 Problem-Specific Constraints Restriction 2 can be used to generate a set of problem-specific constraints that are sufficient to guarantee the ordered monotonicity property.
Reference: [31] <author> Craig A. Knoblock. </author> <title> Learning abstraction hierarchies for problem solving. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, MA, </address> <year> 1990, </year> <pages> 923-928. </pages>
Reference-contexts: While this constraint may be more restrictive than necessary, it provides a very effective heuristic for generating useful abstraction hierarchies. This constraint is captured by the ordered monotonicity property <ref> [31] </ref>. The ordered monotonicity property requires that every refinement of an abstract plan leaves the literals that comprise the abstract space unchanged. This property has two important features. First, it is computationally tractable to find abstraction hierarchies with this property from only the definition of the problem space.
Reference: [32] <author> Craig A. Knoblock. </author> <title> Automatically Generating Abstractions for Problem Solving. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: This technique has been used successfully to reduce search in a number of planning systems, including gps [48], abstrips [53], abtweak [68], pablo [11], and prodigy <ref> [32, 35] </ref>. While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies [3, 11, 53]. In most hierarchical planners, the designer of a planning domain must manually engineer the appropriate abstractions. <p> The third subsection compares alpine and abstrips in the original strips domain and shows that alpine produces abstractions that have a considerable performance advantage over those generated by ab-strips. The raw data from the experiments described in this section is available in <ref> [32] </ref>. 5.1 Empirical Results for ALPINE alpine generates abstraction hierarchies for a variety of problem-solving domains.
Reference: [33] <author> Craig A. Knoblock. </author> <title> Search reduction in hierarchical problem solving. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <address> Anaheim, CA, </address> <year> 1991, </year> <pages> 686-691. </pages>
Reference-contexts: For single-level planning the size of the search space is exponential in the solution length. Hierarchical planning reduces this complexity by taking a large complex problem and decomposing it into a number of smaller subproblems. See <ref> [33, 35] </ref> for a formal definition of hierarchical planning and an analysis of the search reduction. In addition, hierarchical planning can improve the performance of a learning system. <p> This formal definition captures the notion of plan refinement used in a number of different planners, including abstrips [53], abtweak [68], and pablo [11]. 2.4 Ordered Monotonicity Property Hierarchical planning reduces search by partitioning a problem into a number of smaller subproblems <ref> [33] </ref>. An effective partitioning of a problem requires that the subproblems can be solved without violating the conditions that were already achieved in the more abstract levels of the abstraction hierarchy. <p> Since the abstraction hierarchy has the ordered monotonicity property, at the next level only steps for moving the medium-size disk would need to be inserted. At the final level, the steps for moving the smallest disk would be inserted to complete the plan. As shown in <ref> [33] </ref>, the use of this particular abstraction hierarchy reduces the size of the search space from exponential to linear in the length of the solution.
Reference: [34] <author> Craig A. Knoblock. </author> <title> An analysis of ABSTRIPS. </title> <editor> In J. Hendler, editor, </editor> <booktitle> Artificial Intelligence Planning Systems: Proceedings of the First International Conference (AIPS92), </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992, </year> <pages> 126-135. </pages>
Reference-contexts: However, it does not actually guarantee this property since the algorithm assumes that the different goal conditions will not interact with one another. (See <ref> [34] </ref> for a detailed discussion of this point.) Another limitation of this approach is that the conditions that cannot be achieved by a short plan are placed in the same abstraction level.
Reference: [35] <author> Craig A. Knoblock. </author> <title> Generating Abstraction Hierarchies: An Automated Approach to Reducing Search in Planning. </title> <publisher> Kluwer Academic Publishers, Norwell, </publisher> <address> MA, </address> <year> 1993. </year>
Reference-contexts: This technique has been used successfully to reduce search in a number of planning systems, including gps [48], abstrips [53], abtweak [68], pablo [11], and prodigy <ref> [32, 35] </ref>. While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies [3, 11, 53]. In most hierarchical planners, the designer of a planning domain must manually engineer the appropriate abstractions. <p> This algorithm is implemented in the alpine system and the abstraction hierarchies generated by alpine are used in a version of the prodigy problem solver [9, 46] that was extended to plan hierarchically <ref> [35] </ref>. This article presents experimental results that demonstrate that alpine's abstractions provide significant reductions in search over planning without the use of abstraction. 1.1 Hierarchical Planning Planning involves finding a sequence of operators that solves a problem within a problem space. <p> For single-level planning the size of the search space is exponential in the solution length. Hierarchical planning reduces this complexity by taking a large complex problem and decomposing it into a number of smaller subproblems. See <ref> [33, 35] </ref> for a formal definition of hierarchical planning and an analysis of the search reduction. In addition, hierarchical planning can improve the performance of a learning system. <p> The abstraction hierarchy is then used in a hierarchical version of the prodigy problem solver <ref> [35] </ref>. To generate abstraction hierarchies, alpine uses an extended version of the problem-specific algorithm described in Section 3.
Reference: [36] <author> Craig A. Knoblock, Steven Minton, and Oren Etzioni. </author> <title> Integrating abstraction and explanation-based learning in PRODIGY. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <address> Anaheim, CA, </address> <year> 1991, </year> <pages> 541-546. </pages>
Reference-contexts: See [33, 35] for a formal definition of hierarchical planning and an analysis of the search reduction. In addition, hierarchical planning can improve the performance of a learning system. For an example see <ref> [36] </ref>, which describes the integration of abstraction and explanation-based learning in the context of the prodigy problem solver. 1.2 Abstraction Hierarchies While hierarchical planning has been used in a variety of planners to reduce search, the problem of how to find effective abstractions has not received as much attention. <p> This combination improves performance because the control rules provide search guidance within an abstraction level and the use of abstraction provides better coverage at a lower cost than just using the control rules. In <ref> [36] </ref> we show that integrating abstraction and the rules learned from ebl produce similar results. 39 5.3 Comparison of ALPINE and ABSTRIPS This section compares the abstractions generated by alpine to those generated by abstrips and shows that alpine produces better abstractions with less specific domain knowledge than abstrips. abstrips was
Reference: [37] <author> Craig A. Knoblock, Josh D. Tenenberg, and Qiang Yang. </author> <title> Characterizing abstraction hierarchies for planning. </title> <booktitle> In Proceedings of the Ninth National Conference on Artificial Intelligence, </booktitle> <address> Anaheim, CA, </address> <year> 1991, </year> <pages> 692-697. </pages>
Reference-contexts: 9fi 2 Ops () such that Justified (fi; S g ; ) and Establishes (ff; fi; u; ). 3 The formalization of refinement as well as the formalization of the ordered monotonicity property pre sented in the next section is based on joint work with Josh Tenenberg and Qiang Yang <ref> [37] </ref>. 8 The justification definition is extended to plans as follows: Justified (; S g ) if and only if for every operator ff 2 Ops (), Justified (ff; S g ; ). Any operator that is not justified is not needed to achieve the goal and can be removed.
Reference: [38] <author> Richard E. Korf. Macro-operators: </author> <title> A weak method for learning. </title> <journal> Artificial Intelligence, </journal> <volume> 26(1), </volume> <year> 1985, </year> <pages> 35-77. </pages>
Reference-contexts: A related idea is to construct macro objects instead of operators and then reason about the macro objects [8]. Other systems have also used macro operators, but instead of constructing a new macro space the macro operators are simply added to the original space <ref> [19, 26, 28, 38, 41, 52] </ref>. <p> However, it is unclear whether these refinements will generate improved hierarchies over those produced by alpine. In work on ordering goals for problem solving there are a set of closely related properties to those described above. In Korf's work on generating macro operators <ref> [38] </ref>, he identified a property called serial decomposability, which is sufficient to guarantee that a set of macros can serialize a problem.
Reference: [39] <author> Richard E. Korf. </author> <title> Planning as search: A quantitative approach. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1), </volume> <year> 1987, </year> <pages> 65-88. </pages>
Reference-contexts: Another problem-solving method, similar to the use of state abstractions, is the use of macro problem spaces. Instead of forming abstract problem spaces by constructing relaxed or reduced models of a problem space, operators are combined into macro operators to form a macro problem space <ref> [39] </ref>. This approach is similar to using state abstractions in that a problem is mapped into an abstract space, which is defined by a set of macro operators, and then solved in the abstract space.
Reference: [40] <author> John E. Laird, Allen Newell, and Paul S. Rosenbloom. </author> <title> SOAR: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1), </volume> <year> 1987, </year> <pages> 1-64. </pages>
Reference-contexts: All of these systems use techniques related to abstraction to learn information to guide the problem solver at various control choices. Unruh and Rosenbloom [62, 63] developed a weak method for soar <ref> [40] </ref> that dynamically forms control knowledge by dropping preconditions of operators. When soar is working on a goal and reaches an impasse, a point in the search where it does not know how to proceed, it performs a look-ahead search to resolve this impasse.
Reference: [41] <author> John E. Laird, Paul S. Rosenbloom, and Allen Newell. </author> <title> Chunking in Soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1(1), </volume> <year> 1986, </year> <pages> 11-46. </pages>
Reference-contexts: A related idea is to construct macro objects instead of operators and then reason about the macro objects [8]. Other systems have also used macro operators, but instead of constructing a new macro space the macro operators are simply added to the original space <ref> [19, 26, 28, 38, 41, 52] </ref>.
Reference: [42] <author> Vladimir Lifschitz. </author> <title> On the semantics of STRIPS. </title> <booktitle> In Proceedings of the Workshop on Reasoning about Actions and Plans, </booktitle> <address> Timberline, Oregon, </address> <year> 1986, </year> <pages> 1-9. 57 </pages>
Reference-contexts: 1 i n A plan is correct whenever the preconditions of each operator are satisfied in the state in which the operator is applied: P ff i S i1 1 i n 2 The formalization of problem solving presented in this section is loosely based on Lifschitz's formalization of strips <ref> [42] </ref>. 6 solves a problem = (S 0 ; S g ) whenever is correct and the goal S g is satisfied in the final state: S g A (; S 0 ). 2.2 Abstraction Spaces and Hierarchies In this paper, an abstraction space or abstract problem space is formed by
Reference: [43] <author> Steven Minton. </author> <title> Selectively generalizing plans for problem solving. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <address> Los Angeles, CA, </address> <year> 1985, </year> <pages> 596-599. </pages>
Reference-contexts: While this approach may reduce the depth of the search by providing sequences of operators that can solve entire problems, it has the problem that it can significantly increase the branching factor since the problem solver must consider the original operators as well as the new macros <ref> [43] </ref>. 44 6.2 Generating Abstractions alpine forms abstractions based on the ordered monotonicity property. This property guarantees that any plan for achieving a literal ignored at an abstract level will not add or delete a literal in a more abstract space.
Reference: [44] <author> Steven Minton. </author> <title> Learning Effective Search Control Knowledge: An Explanation-Based Approach. </title> <type> PhD thesis, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <year> 1988. </year>
Reference-contexts: The article describes these extensions in detail. 4 1.4 Experimental Results alpine has been successfully tested on a number of planning domains including the Tower of Hanoi, the original strips domain [20], a more complex robot planning domain <ref> [44] </ref>, and a machine-shop process planning and scheduling domain [44]. In all these domains, the system generates problem-specific abstraction hierarchies that provide significant reductions in search. <p> The article describes these extensions in detail. 4 1.4 Experimental Results alpine has been successfully tested on a number of planning domains including the Tower of Hanoi, the original strips domain [20], a more complex robot planning domain <ref> [44] </ref>, and a machine-shop process planning and scheduling domain [44]. In all these domains, the system generates problem-specific abstraction hierarchies that provide significant reductions in search. The algorithm for generating the abstractions is quite efficient and can generate an abstraction hierarchy for a problem in any of these domains in 0.3 to 4.5 CPU seconds. <p> The results show that alpine reduces both solution time and solution length when compared with the basic prodigy system and performs comparably to hand-coded control knowledge. Second, it compares alpine's abstractions to the use of control knowledge acquired by explanation-based learning techniques <ref> [16, 44] </ref>. Again, the results show that alpine performs comparably to these techniques, but more importantly the combination of abstraction and control knowledge leads to performance that is better than any of the systems alone. <p> Using this extended algorithm, alpine is able to produce abstraction hierarchies for a variety of domains, including the Tower of Hanoi, the strips robot planning domain [20], an extended version of the strips domain <ref> [44] </ref>, and a machine-shop scheduling domain [44]. These results are described in Section 5. To illustrate these extensions, this section uses examples from the extended robot planning domain [44]. This domain is an augmented version of the original strips robot planning domain [20]. <p> Using this extended algorithm, alpine is able to produce abstraction hierarchies for a variety of domains, including the Tower of Hanoi, the strips robot planning domain [20], an extended version of the strips domain <ref> [44] </ref>, and a machine-shop scheduling domain [44]. These results are described in Section 5. To illustrate these extensions, this section uses examples from the extended robot planning domain [44]. This domain is an augmented version of the original strips robot planning domain [20]. <p> a variety of domains, including the Tower of Hanoi, the strips robot planning domain [20], an extended version of the strips domain <ref> [44] </ref>, and a machine-shop scheduling domain [44]. These results are described in Section 5. To illustrate these extensions, this section uses examples from the extended robot planning domain [44]. This domain is an augmented version of the original strips robot planning domain [20]. In the original domain a robot can move among rooms, push boxes around, and open and close doors. In the augmented version, the robot can both push and carry objects and lock and unlock doors. <p> This section describes the abstractions generated by alpine on two domains, a robot planning domain and a machine-shop planning and scheduling domain, and presents empirical results on the effectiveness of these abstractions at reducing search in prodigy. These domains were previously described in <ref> [44] </ref>, where they were used to evaluate the effectiveness of the explanation-based learning (ebl) module in prodigy. 5.1.1 Extended STRIPS Domain This section describes the abstraction hierarchies generated by alpine for the extended version of the robot planning domain [20], which includes locks, keys, and a robot that can both push <p> The comparison was made on a set of 250 randomly generated problems, where the different configurations were each allowed to work on a problem until it was solved or the 600 CPU second time limit was exceeded. Of these problems, 100 were used in Minton's experiments <ref> [44] </ref> to test the EBL module. Because of the additional information about primary effects used in this comparison, these problems proved quite easy for the problem solver even without the use of abstraction. <p> It compares the performance of prodigy + alpine to prodigy with no control knowledge and prodigy with a set of hand-coded control rules 36 (prodigy + hcr). The hand-coded rules are the same rules that were used in the original comparisons with the EBL system <ref> [44] </ref>. All the configurations were run on 250 randomly generated problems including the 100 problems used for testing the EBL system. The comparison, shown in Figure 13, graphs the total time against an increasing time bound for solvable and unsolvable problems. <p> Minton <ref> [44] </ref> developed a system called prodigy/ebl that learns search control rules using explanation-based learning. More recently, Etzioni [16] developed a system called static that generates control rules using partial evaluation. This section compares the use of the abstractions generated by alpine to these two systems for learning search control knowledge. <p> The article presented results on both generating and using abstractions on large sets of problems in multiple problem spaces. The use of abstraction is compared in prodigy to single-level problem solving, as well as problem solving with hand-coded control knowledge and control knowledge learned by ebl <ref> [44] </ref> and static [16]. The results show that the abstractions provide considerable reductions in search and improvements in solution quality over the basic prodigy system and provide comparable results to the EBL methods for learning control knowledge.
Reference: [45] <author> Steven Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 42(2-3), </pages> <year> 1990, </year> <pages> 363-392. </pages>
Reference-contexts: Comparing the results of the different configurations on the set of test problems is complicated by the fact that some of the problems cannot be solved within the time limit. Similar comparisons in the past have been done using cumulative time graphs <ref> [45] </ref>, but Segre et al. [55] argue that such comparisons could be misleading because changing the time limit can change the results. To avoid this problem, the total time expended solving all of the problems is graphed against the CPU time bound. The resulting graph illustrates three things.
Reference: [46] <author> Steven Minton, Jaime G. Carbonell, Craig A. Knoblock, Daniel R. Kuokka, Oren Et-zioni, and Yolanda Gil. </author> <title> Explanation-based learning: A problem solving perspective. </title> <booktitle> Artificial Intelligence, </booktitle> <pages> 40(1-3), </pages> <year> 1989, </year> <pages> 63-118. </pages>
Reference-contexts: This algorithm is implemented in the alpine system and the abstraction hierarchies generated by alpine are used in a version of the prodigy problem solver <ref> [9, 46] </ref> that was extended to plan hierarchically [35]. This article presents experimental results that demonstrate that alpine's abstractions provide significant reductions in search over planning without the use of abstraction. 1.1 Hierarchical Planning Planning involves finding a sequence of operators that solves a problem within a problem space. <p> Holte, Zimmer and MacDonald [27] also showed both analytically and empirically that this decomposition of the problem will produce the shortest solution with the least amount of work. 20 4 Generating Abstractions in ALPINE alpine is a fully implemented system that generates abstraction hierarchies for the prodigy problem solver <ref> [46] </ref>. alpine is given a problem space specification and a problem to be solved and it produces a problem-specific abstraction hierarchy for the given problem. The abstraction hierarchy is then used in a hierarchical version of the prodigy problem solver [35].
Reference: [47] <author> Jack Mostow and Armand E. </author> <title> Prieditis. Discovering admissible heuristics by abstracting and optimizing: A transformational approach. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI, </address> <year> 1989, </year> <pages> 701-707. </pages>
Reference-contexts: This general approach has been referred to as state abstraction and was first used in Planning GPS [48]. This is also the approach used in abstrips [53] and pablo [11], abtweak [68, 67], as well as alpine. absolver <ref> [47] </ref> also employs a form of state abstraction, but instead of refining abstract plans found using this simplified model, the abstract plans are used in the evaluation function of an admissible search procedure.
Reference: [48] <author> Allen Newell and Herbert A. Simon. </author> <title> Human Problem Solving. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: This technique has been used successfully to reduce search in a number of planning systems, including gps <ref> [48] </ref>, abstrips [53], abtweak [68], pablo [11], and prodigy [32, 35]. While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies [3, 11, 53]. <p> Each abstraction space is a "simplification" of the original problem space, such as the relaxed and reduced models described in Section 2.2. This general approach has been referred to as state abstraction and was first used in Planning GPS <ref> [48] </ref>. <p> This is essentially a generate and test method for using abstractions to find control knowledge. The approach differs from the one used by alpine in that there is no analysis of the problem space. gps <ref> [48] </ref> is a means-ends analysis problem solver, which employs a table of differences to select relevant operators and thus focus the search. The problem solving proceeds by attempting to reduce the differences between the initial state and goal.
Reference: [49] <author> Nils J. Nilsson. </author> <booktitle> Principles of Artificial Intelligence. </booktitle> <publisher> Tioga Publishing Co., </publisher> <address> Palo Alto, CA, </address> <year> 1980. </year>
Reference-contexts: Thus, the abstraction hierarchies are based on the possible interactions, which are a superset of the actual interactions. As a result it will in many cases overconstrain the hierarchy, thus reducing the granularity of the possible abstraction hierarchies. The "blocks world" <ref> [49] </ref> is a domain in which alpine is unable to generate abstractions, 51 although there are ordered monotonic abstractions for some problems.
Reference: [50] <author> Judea Pearl. </author> <title> Heuristics: Intelligent Search Strategies for Computer Problem Solving. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1984. </year>
Reference-contexts: This type of abstraction space is called a reduced model [61]. A different approach was taken in abstrips [53], where the preconditions of the operators were assigned criticality values and all preconditions with criticality values below a certain threshold were ignored. These abstraction spaces are called relaxed models <ref> [50] </ref> since they are formed by weakening the applicability conditions of the operators.
Reference: [51] <author> David A. Plaisted. </author> <title> Theorem proving with abstraction. </title> <journal> Artificial Intelligence, </journal> <volume> 16(1), </volume> <year> 1981, </year> <pages> 47-108. </pages>
Reference-contexts: Thus, using an abstraction space formed by dropping information it is difficult to guarantee the downward solution property. The same problem arises in the use of abstraction in theorem proving, where it is called the false proof problem <ref> [23, 51] </ref>. Bacchus and Yang [4, 5] identified a closely related property called the downward refinement property (DRP), which states that if a problem is solvable then any abstract solution must have a refinement.
Reference: [52] <author> Patricia Riddle. </author> <title> Automating problem reformulation. </title> <editor> In D. Paul Benjamin, editor, </editor> <title> Change of Representation and Inductive Bias, </title> <publisher> Kluwer, </publisher> <address> Boston, MA, </address> <year> 1990, </year> <pages> 105-124. </pages>
Reference-contexts: A related idea is to construct macro objects instead of operators and then reason about the macro objects [8]. Other systems have also used macro operators, but instead of constructing a new macro space the macro operators are simply added to the original space <ref> [19, 26, 28, 38, 41, 52] </ref>.
Reference: [53] <author> Earl D. Sacerdoti. </author> <title> Planning in a hierarchy of abstraction spaces. </title> <journal> Artificial Intelligence, </journal> <volume> 5(2), </volume> <year> 1974, </year> <pages> 115-135. </pages>
Reference-contexts: This technique has been used successfully to reduce search in a number of planning systems, including gps [48], abstrips <ref> [53] </ref>, abtweak [68], pablo [11], and prodigy [32, 35]. While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies [3, 11, 53]. In most hierarchical planners, the designer of a planning domain must manually engineer the appropriate abstractions. <p> While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies <ref> [3, 11, 53] </ref>. In most hierarchical planners, the designer of a planning domain must manually engineer the appropriate abstractions. This process is largely a black art since the properties of an effective abstraction hierarchy are not well understood. <p> In the resulting abstraction space, a single abstract state corresponds to one or more states in the original problem space. This type of abstraction space is called a reduced model [61]. A different approach was taken in abstrips <ref> [53] </ref>, where the preconditions of the operators were assigned criticality values and all preconditions with criticality values below a certain threshold were ignored. These abstraction spaces are called relaxed models [50] since they are formed by weakening the applicability conditions of the operators. <p> So refining an abstract plan at level i 1 can involve establishing literals at level i 1 and above. This formal definition captures the notion of plan refinement used in a number of different planners, including abstrips <ref> [53] </ref>, abtweak [68], and pablo [11]. 2.4 Ordered Monotonicity Property Hierarchical planning reduces search by partitioning a problem into a number of smaller subproblems [33]. <p> Each abstraction space is a "simplification" of the original problem space, such as the relaxed and reduced models described in Section 2.2. This general approach has been referred to as state abstraction and was first used in Planning GPS [48]. This is also the approach used in abstrips <ref> [53] </ref> and pablo [11], abtweak [68, 67], as well as alpine. absolver [47] also employs a form of state abstraction, but instead of refining abstract plans found using this simplified model, the abstract plans are used in the evaluation function of an admissible search procedure. <p> An important feature of the ordered monotonicity property is that alpine can tractably generate problem-specific abstractions that have this property. abstrips <ref> [53] </ref> was the first system to automate the formation of abstraction hierarchies for hierarchical planning.
Reference: [54] <author> Earl D. Sacerdoti. </author> <title> A Structure for Plans and Behavior. </title> <publisher> American Elsevier, </publisher> <address> New York, NY, </address> <year> 1977. </year>
Reference-contexts: There are a set of abstractions for each operator, and each instance of an operator in an abstract plan can be expanded to a different level of detail during the refinement of a plan. Operator abstractions have been used extensively in least-commitment problem solvers such as noah <ref> [54] </ref>, molgen [58], nonlin [59], and sipe [64]. The difference between operator abstraction and state abstraction is small since operator abstraction can be used to implement state abstraction by imposing constraints on the order in which the operator abstractions are expanded.
Reference: [55] <author> Alberto Segre, Charles Elkan, and Alex Russell. </author> <title> A critical look at experimental evaluations of EBL. </title> <journal> Machine Learning, </journal> <volume> 6(2), </volume> <year> 1991, </year> <pages> 183-195. </pages>
Reference-contexts: Comparing the results of the different configurations on the set of test problems is complicated by the fact that some of the problems cannot be solved within the time limit. Similar comparisons in the past have been done using cumulative time graphs [45], but Segre et al. <ref> [55] </ref> argue that such comparisons could be misleading because changing the time limit can change the results. To avoid this problem, the total time expended solving all of the problems is graphed against the CPU time bound. The resulting graph illustrates three things.
Reference: [56] <author> David E. Smith and Mark A. Peot. </author> <title> A critical look at Knoblock's hierarchy mechanism. </title> <editor> In J. Hendler, editor, </editor> <booktitle> Artificial Intelligence Planning Systems: Proceedings of the First International Conference (AIPS92), </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1992, </year> <pages> 307-308. </pages>
Reference-contexts: This restriction requires that all the effects of each operator must be placed 4 As noted in <ref> [56] </ref>, distinguishing between positive and negative literals would provide slightly finer-grained hierarchies in some cases. <p> The property captures the idea that an abstract solution should solve some aspect of the problem, which can then be held invariant while the remaining unsolved aspects of the problem are successively elaborated. As noted by Smith and Peot <ref> [56] </ref>, this property addresses the problem of operator interference, but does not deal with the problem that the planner may select a set of bindings that prevent a solution from being refined and force the system to backtrack across abstraction levels.
Reference: [57] <author> David E. Smith and Mark A. Peot. </author> <title> Postponing conflicts in nonlinear planning. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <address> Washington, DC, </address> <year> 1993. </year>
Reference-contexts: This analysis differs from the analysis performed by alpine, since the control rules are based on necessary interactions, while the abstractions are based on possible interactions. Smith and Peot <ref> [57] </ref> developed an approach to analyzing potential conflicts in order to delay resolving conflicts for partial-order planning. The analysis used to determine which conflicts can be delayed is similar to the analysis performed by alpine.
Reference: [58] <author> Mark Stefik. </author> <title> Planning with constraints (MOLGEN: Part 1). </title> <journal> Artificial Intelligence, </journal> <volume> 16(2), </volume> <year> 1981, </year> <pages> 111-140. </pages>
Reference-contexts: There are a set of abstractions for each operator, and each instance of an operator in an abstract plan can be expanded to a different level of detail during the refinement of a plan. Operator abstractions have been used extensively in least-commitment problem solvers such as noah [54], molgen <ref> [58] </ref>, nonlin [59], and sipe [64]. The difference between operator abstraction and state abstraction is small since operator abstraction can be used to implement state abstraction by imposing constraints on the order in which the operator abstractions are expanded.
Reference: [59] <author> Austin Tate. </author> <title> Project planning using a hierarchic non-linear planner. </title> <type> Research Report 25, </type> <institution> Department of Artificial Intelligence, University of Edinburgh, Edinburgh, </institution> <address> Scotland, </address> <year> 1976. </year>
Reference-contexts: Operator abstractions have been used extensively in least-commitment problem solvers such as noah [54], molgen [58], nonlin <ref> [59] </ref>, and sipe [64]. The difference between operator abstraction and state abstraction is small since operator abstraction can be used to implement state abstraction by imposing constraints on the order in which the operator abstractions are expanded.
Reference: [60] <author> Austin Tate, James Hendler, and Mark Drummond. </author> <title> A review of AI planning techniques. In Readings in Planning, </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1990, </year> <pages> 26-49. </pages>
Reference-contexts: For a discussion of this issue see [65, chapter 4], and for a discussion of systems using various forms of "hierarchical abstraction" see <ref> [60] </ref>. 3 Ordered Monotonicity Property: For all abstract plans, all refinements of those plans leave the literals established in the abstract space unchanged. This property captures an important feature of abstraction spaces and can be used to generate abstraction hierarchies.
Reference: [61] <author> Josh D. Tenenberg. </author> <title> Abstraction in Planning. </title> <type> PhD thesis, </type> <institution> Computer Science Department, University of Rochester, </institution> <year> 1988. </year>
Reference-contexts: In the resulting abstraction space, a single abstract state corresponds to one or more states in the original problem space. This type of abstraction space is called a reduced model <ref> [61] </ref>. A different approach was taken in abstrips [53], where the preconditions of the operators were assigned criticality values and all preconditions with criticality values below a certain threshold were ignored. <p> The various properties that have been identified are all related to this general problem in one way or another. There is also a closely related issue in ordering goals. This section describes the various properties for both abstraction and goal ordering. The downward solution property, identified by Tenenberg <ref> [61] </ref> states that the existence of an abstract-level solution implies the existence of a ground-level solution. Ideally an abstraction space would have the downward solution property since once an abstract solution is found it is just a matter of refining it into a ground-level solution.
Reference: [62] <author> Amy Unruh and Paul S. Rosenbloom. </author> <title> Abstraction in problem solving and learning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> Detroit, MI, </address> <year> 1989, </year> <pages> 681-687. </pages>
Reference-contexts: There are many systems that use control knowledge, but this section only describes the most closely related ones. All of these systems use techniques related to abstraction to learn information to guide the problem solver at various control choices. Unruh and Rosenbloom <ref> [62, 63] </ref> developed a weak method for soar [40] that dynamically forms control knowledge by dropping preconditions of operators.
Reference: [63] <author> Amy Unruh and Paul S. Rosenbloom. </author> <title> Two new weak method increments for abstraction. In Proceedings of the Workshop on Automatic Generation of Approximations and Abstractions, </title> <address> Boston, MA, </address> <year> 1990, </year> <pages> 78-86. </pages>
Reference-contexts: There are many systems that use control knowledge, but this section only describes the most closely related ones. All of these systems use techniques related to abstraction to learn information to guide the problem solver at various control choices. Unruh and Rosenbloom <ref> [62, 63] </ref> developed a weak method for soar [40] that dynamically forms control knowledge by dropping preconditions of operators.
Reference: [64] <author> David E. Wilkins. </author> <title> Domain-independent planning: Representation and plan generation. </title> <journal> Artificial Intelligence, </journal> <volume> 22(3), </volume> <year> 1984, </year> <pages> 269-301. </pages>
Reference-contexts: Operator abstractions have been used extensively in least-commitment problem solvers such as noah [54], molgen [58], nonlin [59], and sipe <ref> [64] </ref>. The difference between operator abstraction and state abstraction is small since operator abstraction can be used to implement state abstraction by imposing constraints on the order in which the operator abstractions are expanded. <p> The difference between operator abstraction and state abstraction is small since operator abstraction can be used to implement state abstraction by imposing constraints on the order in which the operator abstractions are expanded. This is the approach taken in sipe <ref> [64, 65] </ref>, where the domain is partitioned into literals at different abstraction levels and operators for achieving those literals. Another problem-solving method, similar to the use of state abstractions, is the use of macro problem spaces.
Reference: [65] <author> David E. Wilkins. </author> <title> Practical Planning: Extending the Classical AI Planning Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: This property is captured by the ordered monotonicity property: 1 The terms "hierarchy" and "abstraction" have been used in a number of different ways in the planning literature. For a discussion of this issue see <ref> [65, chapter 4] </ref>, and for a discussion of systems using various forms of "hierarchical abstraction" see [60]. 3 Ordered Monotonicity Property: For all abstract plans, all refinements of those plans leave the literals established in the abstract space unchanged. <p> The difference between operator abstraction and state abstraction is small since operator abstraction can be used to implement state abstraction by imposing constraints on the order in which the operator abstractions are expanded. This is the approach taken in sipe <ref> [64, 65] </ref>, where the domain is partitioned into literals at different abstraction levels and operators for achieving those literals. Another problem-solving method, similar to the use of state abstractions, is the use of macro problem spaces.
Reference: [66] <author> Qiang Yang. </author> <title> Improving the Efficiency of Planning. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Maryland, </institution> <year> 1989. </year>
Reference-contexts: Another commonly used approach to hierarchical problem solving is to first build a plan out of a set of abstract operators and then refine the plan by selectively expanding individual operators into successively more detailed ones. The refinement is done using a set of action reductions <ref> [66] </ref>, which specify the relationship between an abstract operator and the refinements of that operator. This approach differs from state abstraction in that there is no abstraction of the state, but only of the operators. As such, this approach is sometimes referred to as operator abstraction.
Reference: [67] <author> Qiang Yang, Josh Tenenberg, and Steve Woods. </author> <title> Abstraction in nonlinear planning. </title> <institution> Research Report CS-91-65, Department of Computer Science, University of Waterloo, </institution> <year> 1991. </year>
Reference-contexts: This general approach has been referred to as state abstraction and was first used in Planning GPS [48]. This is also the approach used in abstrips [53] and pablo [11], abtweak <ref> [68, 67] </ref>, as well as alpine. absolver [47] also employs a form of state abstraction, but instead of refining abstract plans found using this simplified model, the abstract plans are used in the evaluation function of an admissible search procedure.
Reference: [68] <author> Qiang Yang and Josh D. Tenenberg. Abtweak: </author> <title> Abstracting a nonlinear, least commitment planner. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> Boston, MA, </address> <year> 1990, </year> <pages> 204-209. 59 </pages>
Reference-contexts: This technique has been used successfully to reduce search in a number of planning systems, including gps [48], abstrips [53], abtweak <ref> [68] </ref>, pablo [11], and prodigy [32, 35]. While hierarchical planning is a widely used planning technique, there are only a few systems that automate the construction of abstraction hierarchies [3, 11, 53]. In most hierarchical planners, the designer of a planning domain must manually engineer the appropriate abstractions. <p> So refining an abstract plan at level i 1 can involve establishing literals at level i 1 and above. This formal definition captures the notion of plan refinement used in a number of different planners, including abstrips [53], abtweak <ref> [68] </ref>, and pablo [11]. 2.4 Ordered Monotonicity Property Hierarchical planning reduces search by partitioning a problem into a number of smaller subproblems [33]. <p> This general approach has been referred to as state abstraction and was first used in Planning GPS [48]. This is also the approach used in abstrips [53] and pablo [11], abtweak <ref> [68, 67] </ref>, as well as alpine. absolver [47] also employs a form of state abstraction, but instead of refining abstract plans found using this simplified model, the abstract plans are used in the evaluation function of an admissible search procedure.
References-found: 68

