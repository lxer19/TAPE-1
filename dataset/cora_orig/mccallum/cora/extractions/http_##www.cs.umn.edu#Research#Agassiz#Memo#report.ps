URL: http://www.cs.umn.edu/Research/Agassiz/Memo/report.ps
Refering-URL: http://www.cs.umn.edu/Research/Agassiz/memo.html
Root-URL: http://www.cs.umn.edu
Email: E-mail: sycho@cs.umn.edu  
Title: On Implementing Software-Pipelining in GNU C Compiler (v0.3) (internal document)  
Author: Sangyeun Cho 
Date: November 14, 1996  
Address: Minneapolis, MN 55455, USA  
Affiliation: Agassiz Project Dept. of Computer Science University of Minnesota  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> ALTMAN, E. R. </author> <title> Optimal Software Pipelining with Function Unit and Register Constraints, </title> <type> Ph.D. Thesis, </type> <institution> McGill University, Montreal, Canada, </institution> <year> 1995. </year>
Reference-contexts: A key point in the algorithm is how to determine the legal ranges of an instruction based on previously scheduled instructions. Ruttenberg et al. [6] does not fully describe the techniques. However, Altman <ref> [1] </ref> does describe in detail some techniques to calculate the legal ranges. 3.1.6 Modulo variable expansion By overlapping iterations, we may violate anti-dependence relation between a use in earlier iteration and a definition in a later iteration. <p> What we do is to minimize the number of registers used by the modulo scheduler and guarantee that GCC register allocator will not have trouble later. Recent researches <ref> [1, 5] </ref> propose schemes to minimize the register requirements for a given loop to be software pipelined. Llosa [5] tries to minimize the life span of a variable to relieve the number of live variables by having the predecessor and successor nodes close to a node.
Reference: [2] <author> GLAMM, B. </author> <title> High-Level Information Functions for GCC, Agassiz Internal Document, </title> <month> March </month> <year> 1996. </year>
Reference-contexts: A straightforward algorithm to add a dependence between any two memory references in a DDG is sketched in Figure 3. check eq acc () and check lcdd () in Figure 3 are library functions which extract dependence information from HLI <ref> [2] </ref>. A register value defined may be used in the next iteration, but not in further iterations. This defuse can also create an inter-iteration dependence of distance 1 (always backward). A straightforward algorithm to add dependence arcs for such cases is given in Figure 4.
Reference: [3] <author> LAVERY, D. M. AND HWU, W. W. </author> <title> Unrolling-Based Optimizations for Modulo Scheduling, </title> <booktitle> in Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: Although the IMPACT compiler is equipped with a large number of optimization techniques, it is not clear in [8] how such techniques are related to the software pipelining scheduling. More recent work by Lavery et al. <ref> [3] </ref> performs loop unrolling, induction variable rewriting, induction variable expansion, and induction variable elimination. They also expand accumulator variables and rename them. 2.3.2 The case for integer code Integer codes are known to be harder to pipeline, and if not impossible, the performance gain is minimal [6].
Reference: [4] <author> LAVERY, D. M. AND HWU, W. W. </author> <title> Modulo Scheduling of Loops in Control-Intensive Non-Numeric Programs, </title> <booktitle> in Proceedings of the 29th Annual International Symposium on Microarchi-tecture, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: The SGI compiler can do this only when the C code looks somewhat canonical like codes in Fortran. * Loops in integer codes often iterate over data structures that truly have data dependences which prevent effective pipelining, linked lists for example. A recent work by Lavery and Hwu <ref> [4] </ref> focuses on the loops with early exits, which will be discussed in Section 2.3.2. More accurate data dependence analysis such as sophisticated pointer analysis will provide the software pipeliner with more opportunities for efficient code scheduling. <p> They also expand accumulator variables and rename them. 2.3.2 The case for integer code Integer codes are known to be harder to pipeline, and if not impossible, the performance gain is minimal [6]. Reasons picked up by Lavery and Hwu <ref> [4] </ref> include: * multiple control flow paths, * loops that are not based on a loop counter, and * multiple exits. They propose techniques to software pipeline loops with multiple control paths and multiple exits efficiently by having the most frequently taken paths into a superblock and pipelining it. <p> Worse, it is hard to estimate the latency of the function. To handle multiple control paths in the inner loop, there are two candidate techniques as introduced in earlier sections: if-conversion and path exclusion <ref> [4] </ref>. Implementing if-conversion in GCC requires modifications to the rtx structure, the machine description, and possibly the code generation. A new field or several need to be included in an rtx node to contain predicate variables. <p> It is required that we generate several different codes for the epilogue part, based on which loop back branch is taken and which variable is live out, etc. Further, if we software pipeline loops with early exits, another set of epilogue codes is necessary. Lavery and Hwu <ref> [4] </ref> extends the modulo scheduling technique to handle loops with early exits and presents a code generation scheme for epilogues. 11 3.1.9 DSP2RTL On successfully pipelining the loop, we need to regenerate RTL from DSP. The original loop body is discarded and new rtx's are generated.
Reference: [5] <author> LLOSA, J. </author> <title> Reducing the Impact of Register Pressure on Software Pipelined Loops, </title> <type> Ph.D. Thesis, </type> <institution> Universitat Politecnica de Catalunya, </institution> <address> Barcelona, Spain, </address> <year> 1996. </year>
Reference-contexts: Based on previous implementations in production compilers [6, 7] and research prototypes <ref> [8, 5] </ref>, some details of each step will be described in the following sections. 3.1.1 Selecting a loop To select a target loop for software pipelining, we need to traverse the GCC rtl, checking if an rtx node specifies itself as a starting point of a loop. <p> SGI compilers use extensive heuristics in the above algorithm. They use four priority heuristics - FDMS, FDNMS, HMS, and RHMS to sort the list of instructions. These heuristics are important in decreasing the register live ranges. Another list heuristic is described in Llosa <ref> [5] </ref>. Further, the SGI team uses heuristics to determine a point where the scheduler stops the backtracking and restarts scheduling. A key point in the algorithm is how to determine the legal ranges of an instruction based on previously scheduled instructions. <p> What we do is to minimize the number of registers used by the modulo scheduler and guarantee that GCC register allocator will not have trouble later. Recent researches <ref> [1, 5] </ref> propose schemes to minimize the register requirements for a given loop to be software pipelined. Llosa [5] tries to minimize the life span of a variable to relieve the number of live variables by having the predecessor and successor nodes close to a node. <p> What we do is to minimize the number of registers used by the modulo scheduler and guarantee that GCC register allocator will not have trouble later. Recent researches [1, 5] propose schemes to minimize the register requirements for a given loop to be software pipelined. Llosa <ref> [5] </ref> tries to minimize the life span of a variable to relieve the number of live variables by having the predecessor and successor nodes close to a node.
Reference: [6] <author> RUTTENBERG, J., GAO, G. R., STOUTCHININ, A., AND LICHTENSTEIN, W. </author> <title> Software Pipelining Showdown: Optimal vs. Heuristic Methods in a Production Compiler, </title> <booktitle> in Proceedings of the ACM SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <address> Philadelphia, Pennsylvania, </address> <pages> pp. 1 11, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: At the time the system shipped, it had the best reported performance on a number of important benchmarks, in particular for the SPECfp92. Measurements show that the compiler's software pipelining capabilities play the central role in delivering this performance on the R8000 <ref> [6] </ref>. 2.1.1 Compiler support The MIPSpro compiler performs a rich set of analysis and optimizations before its software pipelining phase. <p> They also expand accumulator variables and rename them. 2.3.2 The case for integer code Integer codes are known to be harder to pipeline, and if not impossible, the performance gain is minimal <ref> [6] </ref>. Reasons picked up by Lavery and Hwu [4] include: * multiple control flow paths, * loops that are not based on a loop counter, and * multiple exits. <p> Modulo scheduling provides good speedup across all the benchmarks and processors. 6 3 Implementation Strategy 3.1 Software pipelining steps The implementation will be composed of a number of different subpasses and algorithms as can be seen in Figure 1. Based on previous implementations in production compilers <ref> [6, 7] </ref> and research prototypes [8, 5], some details of each step will be described in the following sections. 3.1.1 Selecting a loop To select a target loop for software pipelining, we need to traverse the GCC rtl, checking if an rtx node specifies itself as a starting point of a <p> Note that current microprocessors only support predicated execution in a small set of instructions with limited predicate variables, and hence the algorithm has to do its best with the given support. Commercial compilers <ref> [6, 7] </ref> use if-conversion. 7 3.1.2 Pre-pass Things needed for software pipelining are done. They include * index variable reversal, * if-conversion (as described earlier), and * redundant memory reference elimination. <p> Enumeration of schedules This is the core part of the software pipelining. Since a general scheduling problem with resource constraints is an NP-complete problem, we need to employ a heuristic algorithm or a mixture of more than one algorithm. In this section, we describe and summarize the SGI approach <ref> [6] </ref> as a basis for our implementation. The algorithm of SGI compilers is: 1. Make a list of the operations to be scheduled. 2. <p> Further, the SGI team uses heuristics to determine a point where the scheduler stops the backtracking and restarts scheduling. A key point in the algorithm is how to determine the legal ranges of an instruction based on previously scheduled instructions. Ruttenberg et al. <ref> [6] </ref> does not fully describe the techniques. However, Altman [1] does describe in detail some techniques to calculate the legal ranges. 3.1.6 Modulo variable expansion By overlapping iterations, we may violate anti-dependence relation between a use in earlier iteration and a definition in a later iteration. <p> The initial list of instruction can be sorted based on Llosa's heuristics, or any one of four heuristics used in SGI compilers <ref> [6] </ref>. Once a schedule is made, we need to check whether the life time of a variable crosses over the iteration boundary and killed before its valid use, where we apply the modulo variable expansion.
Reference: [7] <author> TIRUMALAI, P., BEYLIN, B., AND SUBRAMANIAN, K. </author> <title> The Design of a Modulo Scheduler for a Superscalar RISC Processor, </title> <booktitle> in Proceedings of the 7th International Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: They utilize unrolling to achieve fractional II and remove some of the instructions <ref> [7] </ref>. More specifically, they partition nodes in the DDG into two classes: amortizable and non-amortizable. Amortizable nodes have the property that they need not be executed in every iteration. Instead, they may be executed once in some number of iterations with suitable adjustment to the code. <p> Modulo scheduling provides good speedup across all the benchmarks and processors. 6 3 Implementation Strategy 3.1 Software pipelining steps The implementation will be composed of a number of different subpasses and algorithms as can be seen in Figure 1. Based on previous implementations in production compilers <ref> [6, 7] </ref> and research prototypes [8, 5], some details of each step will be described in the following sections. 3.1.1 Selecting a loop To select a target loop for software pipelining, we need to traverse the GCC rtl, checking if an rtx node specifies itself as a starting point of a <p> Note that current microprocessors only support predicated execution in a small set of instructions with limited predicate variables, and hence the algorithm has to do its best with the given support. Commercial compilers <ref> [6, 7] </ref> use if-conversion. 7 3.1.2 Pre-pass Things needed for software pipelining are done. They include * index variable reversal, * if-conversion (as described earlier), and * redundant memory reference elimination. <p> Another approach is to estimate the register pressure, and when it is too high (higher than a threshold), try with different parameters such as II and load latency to come up with a schedule without spill codes <ref> [7] </ref>. This approach is attractive in our case since we don't have to worry about the hard register allocation as well as the spill code generation, but rather, can depend on GCC to do those for us. <p> Although loop unrolling can be done by GCC, we may need to suppress it; for those loops which cannot be software pipelined, loop unrolling can be applied as an alternative remedy for them <ref> [7] </ref>. <p> Compiler metrics The most important metric is II. According to Tirumalai et al. <ref> [7] </ref>, their compiler calculated II and measured II are very close to each other, validating their assumptions in memory access latency.
Reference: [8] <author> WARTER, N. J. </author> <title> Modulo Scheduling with Isomorphic Control Transformations, </title> <type> Ph.D. Thesis, </type> <institution> University of Illinois, Urbana-Champaign, Illinois, </institution> <year> 1994. </year> <month> 14 </month>
Reference-contexts: Most loops result in a stretch of less than 25%. Speedup Speedups ranging from 1 4.5fi were observed on the Livermore kernels. For programs in the SPECfp92 suite, speedups in the 1 2.3fi range were obtained. 2.3 Enhanced Modulo Scheduling: the IMPACT approach Warter <ref> [8] </ref> describes the Enhanced Modulo Scheduling, which enables software pipelining the inner loop with conditional if statements. If-Conversion transforms control dependencies into data dependencies, making the loop body a straight-lined code, and Reverse If-Conversion after modulo scheduling reconstructs the control structures. <p> Modulo Schedule Loop 8. Apply Modulo Variable Expansion 9. Generate Software Pipeline 10. Apply Reverse If-conversion Step 1 through 6 are performed before (or in preparation for) modulo scheduling. Although the IMPACT compiler is equipped with a large number of optimization techniques, it is not clear in <ref> [8] </ref> how such techniques are related to the software pipelining scheduling. More recent work by Lavery et al. [3] performs loop unrolling, induction variable rewriting, induction variable expansion, and induction variable elimination. <p> Based on previous implementations in production compilers [6, 7] and research prototypes <ref> [8, 5] </ref>, some details of each step will be described in the following sections. 3.1.1 Selecting a loop To select a target loop for software pipelining, we need to traverse the GCC rtl, checking if an rtx node specifies itself as a starting point of a loop.
References-found: 8

