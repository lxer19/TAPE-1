URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/ps/94-irs-gpod.ps.gz
Refering-URL: http://www.isr.ist.utl.pt/~jasv/vislab/publications/publications.html
Root-URL: 
Email: e-mail gaspar@kappa.ist.utl.pt  
Title: Ground Plane Obstacle Detection with a Stereo Vision System  
Author: Jose A. Gaspar Jose Santos-Victor Jo~ao Sentieiro 
Address: Av. Rovisco Pais, 1096 Lisboa Codex, PORTUGAL  
Affiliation: Instituto de Sistemas e Robotica, Instituto Superior Tecnico,  
Abstract: This paper presents a system for vision-based obstacle detection for mobile robots, developed within the framework of purposive vision.. A single camera and a set of flat mirrors are used to acquire two distinct images of the area in front of a mobile robot. The assumption that the robot is moving on the ground plane is explicitly used to constrain the perception problem. An obstacle is defined as any point laying outside of the ground plane. During a calibration phase, a set of correspondent points are used to robustly estimate the set of 8 parameters that fully describe the disparity map of the ground plane. The disparity map, Reference Map, establishes the disparity for every image pixel, provided that the corresponding 3D point is on the ground plane. During operation, to detect the presence of obstacles, the system has to check for the points where the Reference Map is violated. A real time implementation was developed yielding good results. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Y. Aloimonos, I. Weiss, A. Bandyopadhyay. </author> <title> Active Vision, </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(4) </volume> <pages> 333-356, </pages> <month> January </month> <year> 1988. </year>
Reference: 2. <author> P. Anandan. </author> <title> A computational framework and an algorithm for the measurement of visual motion, </title> <journal> International Journal of Computer Vision, </journal> <volume> 2(3) </volume> <pages> 283-310, </pages> <year> 1989. </year>
Reference-contexts: During normal operation, the expected correspondences (explicit in the RM) are checked by calculating the "Sum of Square Differences" (SSD) <ref> [2] </ref> values for every pixel, (x; y), in the right image, (I r ), and the potential correspondent pixel in the left image, (I l ), (see Figure 3c).
Reference: 3. <author> R. </author> <title> Bajcsy. Active Perception vs. Passive Perception, </title> <booktitle> Proceedings of IEEE workshop on Computer Vision, </booktitle> <address> Bellair, MI, </address> <month> October </month> <year> 1985, </year> <pages> pp. 55-59. </pages>
Reference: 4. <author> D. Ballard. </author> <title> Animate Vision, </title> <journal> Artificial Intelligence, </journal> <volume> 48 </volume> <pages> 57-86, </pages> <year> 1991. </year>
Reference: 5. <author> S. Cornell, J. Porril, J. </author> <title> Mayhew. GPOD under variable camera geometry using a predictive stereo matcher, </title> <month> BMVC </month> <year> 1992. </year>
Reference: 6. <author> F. Ferrari, G. Garibotto, S. Masciangelo, G. Sandini. VOILA, </author> <title> ESPRIT Project P2502 (ECCV 1992 Esprit Open Day). </title>
Reference-contexts: No reconstruction is performed for this problem. The system is based on a stereo algorithm for fast obstacle detection. Similarly to the work described in <ref> [6] </ref>, an obstacle is defined as any object which does not lay on the ground plane (also known as GPOD Ground Plane Obstacle Detection). With this constraint in mind, an o*ine procedure estimates a nominal disparity vector field, characterizing the ground plane. <p> If there is an obstacle in the scene, then these nominal disparity vectors will be violated. Therefore, during normal operation, the system should just check for violations of the expected disparities, instead of fully reestimating these values, as a traditional system would do. Relatively to the approach described in <ref> [6] </ref>, this work differs in two main points. On one hand the stereo setup is based on a single camera and a mirror system, thus avoiding gain and aperture mismatches between a two camera setup, and leading to a smaller, more compact structure. <p> estimated from a reduced number of disparity measurements, and global consistency of the whole disparity vector field is guaranteed. 2 Setup For the purpose being envisaged, the main approaches would either be based on optical flow (as in [8]), or on correspondence/disparity mechanisms (such as the stereo setup described in <ref> [6] </ref>). The optical flow approach uses a single camera mounted on a moving platform, but requires the knowledge of the camera trajectory. The robot motion used for the optical flow calibration (i.e. computing the flow corresponding to the ground plane) determines, to some extent, the permissible motion for current operation.
Reference: 7. <author> F. Ferrari, E. Grosso, G. Sandini, M. Magrassi. </author> <title> A stereo vision system for real time obstacle avoidance in unknown environment, </title> <booktitle> IEEE international workshop on Intelligent Robots and Systems, IROS 1990. </booktitle>
Reference: 8. <author> F. Guarnotta, D. Rizzieri, F. Tarocchi, M. Tistarelli, G. </author> <title> Sandini. Studio de un problema di 'obstacle avoidance' per un robot mobile, </title> <type> DIST Genova, internal report. </type>
Reference-contexts: Accordingly, these parameters can be estimated from a reduced number of disparity measurements, and global consistency of the whole disparity vector field is guaranteed. 2 Setup For the purpose being envisaged, the main approaches would either be based on optical flow (as in <ref> [8] </ref>), or on correspondence/disparity mechanisms (such as the stereo setup described in [6]). The optical flow approach uses a single camera mounted on a moving platform, but requires the knowledge of the camera trajectory.
Reference: 9. <author> H. Mallot, H. Bulthoff, J. Little, and S. Bohrer. </author> <title> Inverse perspective mapping simplifies opticla flow computation and obstacle detection. </title> <journal> Biological Cybernetics, </journal> <volume> 64 </volume> <pages> 177-185, </pages> <year> 1991. </year>
Reference: 10. <editor> J.L. Mundy and A. Zisserman (editors). </editor> <title> Geometrical Invariance in Computer Vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year> <title> This article was processed using the T E X macro package with IRS94 style </title>
Reference-contexts: Alternatively, the RM can be seen as a plane-to-plane projective transformation <ref> [10] </ref>: 2 x l 5 = 4 c 1 c 2 c 3 3 2 x r 1 5 (6) To estimate u, we need at least 4 point correspondences of the ground plane.
References-found: 10

