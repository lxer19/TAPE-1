URL: http://www.research.att.com/~lewis/papers/ittner95.ps
Refering-URL: http://www.research.att.com/~lewis/chronobib.html
Root-URL: 
Title: Text Categorization of Low Quality Images  
Author: David J. Ittner David D. Lewis and David D. Ahn 
Date: 301-315.  
Note: Appears (same pagination) in Fourth Annual Symposium on Document Analysis and Information Retrieval, Las Vegas, NV, April 1995. ISRI; Univ. of Nevada, Las Vegas, pp.  
Address: 600 Mountain Ave.; Murray Hill, NJ 07974  
Affiliation: AT&T Bell Laboratories;  
Abstract: Categorization of text images into content-oriented classes would be a useful capability in a variety of document handling systems. Many methods can be used to categorize texts once their words are known, but OCR can garble a large proportion of words, particularly when low quality images are used. Despite this, we show for one data set that fax quality images can be categorized with nearly the same accuracy as the original text. Further, the categorization system can be trained on noisy OCR output, without need for the true text of any image, or for editing of OCR output. The use of a vector space classifier and training method robust to large feature sets, combined with discarding of low frequency OCR output strings are the key to our approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. </author> <title> Agresti. "Categorical Data Analysis", </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: This gave us pairs of the form &lt; S (D i ; Q c ); class label &gt; where class label is 1 if the instance is a category member and 0 if not. We then applied logistic regression <ref> [1, 19] </ref> to these pairs.
Reference: [2] <author> H. Baird. </author> <title> "Anatomy of a Versatile Page Reader", </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 80(7) </volume> <pages> 1059-1065, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: This estimate is then used to decide whether or not to assign the category to the document, as described in Section 4.4. 3 The OCR System For our testing we used the experimental page reader described in <ref> [2] </ref>. The relevant stages of the page reader are: 1. geometric layout analysis: skew-correction, segmentation into text blocks, line finding within blocks, and character finding within lines.
Reference: [3] <author> H. Baird and R. Fosse. </author> <title> "A 100-Font Classifier", </title> <booktitle> 1st Int'l Conference on Document Analysis and Recognition, </booktitle> <pages> pp. 332-340, </pages> <address> St. Malo, France, </address> <year> 1991. </year>
Reference-contexts: We took no special precautions for the poor quality images of interest here. The methods used to construct the symbol classifier are described in <ref> [3] </ref>. The image training data, entirely synthetic at a resolution of 200x200dpi, included 25 commonly occuring font styles of the printable ASCII character set. Unless otherwise stated, the contextual analysis stage consisted primarily of 304 simple typographic morphology and spell-checks.
Reference: [4] <author> P. Biebricher, N. Fuhr, G. Lustig, M. Schwantner, and G. Knorz. </author> <title> "The Automatic Indexing System AIR/PHYS|From Research to Application", </title> <booktitle> 11th Int'l ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 333-342, </pages> <year> 1988. </year>
Reference-contexts: Dewey Decimal numbers, Com fl dji@research.att.com y To whom correspondence should be addressed. lewis@research.att.com z Current address: Harvard University; Department of Computer Science; Cambridge, MA 02138. puting Reviews categories) to documents to aid in their retrieval or routing <ref> [4, 14] </ref>. Text categorization can also aid other language processing tasks such as information extraction [21], word sense disambiguation [12], and even handwriting recognition [27]. This paper addresses the automated categorization of text images, based on the output of optical character recognition (OCR) applied to the image. <p> Conversely, category experts may not know how to build a good catego-rizer. The use of machine learning to automatically produce categorizers from documents categorized by experts has therefore received much attention. Large quantities of categorized documents may be available from past manual categorization <ref> [4] </ref>, or experts may be asked to categorize a small number of pivotal documents [19]. Our approach in this study was to train a single binary (yes/no) classifier for each category of interest.
Reference: [5] <author> C. Buckley, G. Salton, and J. Al-lan. </author> <title> "Automatic Retrieval with Locality Information Using SMART". </title> <editor> In D. K. Harman, ed., </editor> <booktitle> The First Text REtrieval Conference (TREC-1), </booktitle> <pages> pp. 59-72. </pages> <note> NIST Special Publication 500-207, </note> <month> March </month> <year> 1993. </year>
Reference-contexts: can be a function of the number of times the term occurs in that document, the number of documents the term occurs in, and other information. 302 Of the variety of weighting methods possible, we used the Cornell "ltc" weighting commonly used with the vector space model of text retrieval <ref> [5, 6] </ref>: w ik = q P t : Here N D is the number of documents in the training set, n k is the number of documents in which term k appears, and tf ik is: tf ik = 0 if f ik = 0 log (f ik ) +
Reference: [6] <author> C. Buckley, G. Salton, and J. Al-lan. </author> <title> "The Effect of Adding Relevance Information in a Relevance Feedback Environment", </title> <booktitle> 17th Int'l ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Dublin, Ireland, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: can be a function of the number of times the term occurs in that document, the number of documents the term occurs in, and other information. 302 Of the variety of weighting methods possible, we used the Cornell "ltc" weighting commonly used with the vector space model of text retrieval <ref> [5, 6] </ref>: w ik = q P t : Here N D is the number of documents in the training set, n k is the number of documents in which term k appears, and tf ik is: tf ik = 0 if f ik = 0 log (f ik ) + <p> The parameters fi and fl control the relative impact of positive and negative examples on the classifier. We used the standard values fi = 16 and fl = 4 <ref> [6] </ref>. The full Rocchio formula also takes into account terms suggested by a human user, but we omit this component. Other approaches to constructing a prototype-based classifier for text categorization have been proposed [35, 38]. <p> Other approaches to constructing a prototype-based classifier for text categorization have been proposed [35, 38]. Our reason for choosing Rocchio's algorithm was based on its ability to work well without sophisticated feature selection, in contrast to many learning algorithms used for relevance feedback <ref> [6] </ref>.
Reference: [7] <author> W. Cavnar and J. Trenkle. </author> <title> "N-Gram-Based Text Categorization", </title> <booktitle> Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pp. 171-179, </pages> <address> Las Ve-gas, Nevada, </address> <month> April, </month> <year> 1994. </year>
Reference-contexts: We could instead output at each point multiple word hypothesis, say those whose confidence is over a threshold. The confidence associated with each hypothesis could be accounted for in a probabilistic indexing model [9]. Nor is it necessary to output words. Other possibilities includes character n-grams <ref> [7] </ref> and word shape tokens [29]. On the text categorization side, we have tried only one, albeit plausible, approach to categorizing low quality images.
Reference: [8] <author> K. Church, W. Gale, J. Helfman, and D. Lewis. "Fax: </author> <title> An Alternative to SGML", </title> <booktitle> 16th International Conference on Computational Linguistics, </booktitle> <pages> pp. 525-529, </pages> <address> Kyoto, Japan, </address> <month> August, </month> <year> 1994. </year>
Reference-contexts: Users can interact with the document images, both when training categorizers and when using au 311 tomatically categorized documents. The OCR output need never be seen; it can be merely a data structure aiding an image-centered approach to document processing <ref> [8] </ref>. The ability to categorize text images should be a useful component in a variety of document processing systems. Acknowledgement We thank Henry Baird and Tin Ho for helpful comments on this paper.
Reference: [9] <author> W. Croft. </author> <title> "Experiments with Representation in a Document Retrieval System", </title> <journal> Information Technology: Research and Development, </journal> <volume> 2 </volume> <pages> 1-21, </pages> <year> 1983. </year>
Reference-contexts: We could instead output at each point multiple word hypothesis, say those whose confidence is over a threshold. The confidence associated with each hypothesis could be accounted for in a probabilistic indexing model <ref> [9] </ref>. Nor is it necessary to output words. Other possibilities includes character n-grams [7] and word shape tokens [29]. On the text categorization side, we have tried only one, albeit plausible, approach to categorizing low quality images.
Reference: [10] <author> W. Croft, S. Harding, K. Taghva, and J. Borsack. </author> <title> "An Evaluation of Information Retrieval Accuracy with Simulated OCR Output", </title> <booktitle> 3rd Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pp. 115-126, </pages> <address> Las Vegas, Nevada, </address> <month> April, </month> <year> 1994. </year>
Reference-contexts: This paper addresses the automated categorization of text images, based on the output of optical character recognition (OCR) applied to the image. Several recent studies have suggested that OCR output is quite adequate for the related task of text retrieval, at least when clean images are available <ref> [10, 32, 33] </ref>. Unfortunately, in practice not all images are clean. Even with high-resolution scanners, OCR systems are constantly faced with poor-quality images due to light originals, photocopies, poor contrast, etc.
Reference: [11] <author> M. de la Maza. </author> <title> "A Prototype Based Symbolic Concept Learning System", </title> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pp. 41-45, </pages> <year> 1991. </year>
Reference-contexts: We chose instead to adapt a classifier form and training method widely used in text retrieval. In vector space retrieval [28, pp. 313-319], a class is represented by a single idealized relevant document or prototype <ref> [11] </ref>, [30, Ch. 5]. In other words, the classifier has the same form (a vector of term weights) that documents do, and classification is done by measuring the similarity of test documents to the classifier.
Reference: [12] <author> W. Gale, K. Church, and D. Yarowsky. </author> <title> "A Method for Disambiguating Word Senses in a Large Corpus", </title> <journal> Computers and the Humanities, </journal> <volume> 26 </volume> <pages> 415-439, </pages> <year> 1993. </year>
Reference-contexts: Text categorization can also aid other language processing tasks such as information extraction [21], word sense disambiguation <ref> [12] </ref>, and even handwriting recognition [27]. This paper addresses the automated categorization of text images, based on the output of optical character recognition (OCR) applied to the image.
Reference: [13] <author> D. Harman. </author> <title> "Relevance Feedback and Other Query Modification Techniques" In Information Retrieval: Data Structures and Algorithms, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1992, </year> <pages> pp. 241-263. </pages>
Reference-contexts: In other words, the classifier has the same form (a vector of term weights) that documents do, and classification is done by measuring the similarity of test documents to the classifier. To produce the prototype for each class, we used Rocchio's algorithm <ref> [13] </ref>, [25], [28, pp. 319-321].
Reference: [14] <author> P. Hayes and S. Weinstein. "CONSTRUE/TIS: </author> <title> A System for Content-Based Indexing of a Database of News 312 Stories", </title> <booktitle> 2nd Conference on Innovative Applications of Artificial Intelligence, </booktitle> <year> 1990. </year>
Reference-contexts: Dewey Decimal numbers, Com fl dji@research.att.com y To whom correspondence should be addressed. lewis@research.att.com z Current address: Harvard University; Department of Computer Science; Cambridge, MA 02138. puting Reviews categories) to documents to aid in their retrieval or routing <ref> [4, 14] </ref>. Text categorization can also aid other language processing tasks such as information extraction [21], word sense disambiguation [12], and even handwriting recognition [27]. This paper addresses the automated categorization of text images, based on the output of optical character recognition (OCR) applied to the image.
Reference: [15] <author> R. </author> <title> Hoch. </title> <booktitle> "Using IR Techniques for Text Classification in Document Analysis" 17th Int'l ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 31-40, </pages> <address> Dublin, Ireland, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: On the other hand, research using artificial data has suggested that high error rates can be tolerable for text retrieval [31], and there has been some success at categorizing continuous speech data, where high word recognition error rates are currently inevitable [26]. In addition, Hoch <ref> [15] </ref> has presented an experiment in which images of 42 German business letters were categorized with 57% accuracy into one of six categories. While this is a promising initial result, a small data set and manual intervention at several points in the training process make the results difficult to interpret.
Reference: [16] <author> D. Ittner and H. Baird. </author> <title> "Language-Free Layout Analysis", </title> <booktitle> 2nd Int'l Conference on Document Analysis and Recognition, </booktitle> <pages> pp. 336-340, </pages> <address> Tsukuba Science City, Japan, </address> <month> October, </month> <year> 1993. </year>
Reference-contexts: The relevant stages of the page reader are: 1. geometric layout analysis: skew-correction, segmentation into text blocks, line finding within blocks, and character finding within lines. The underlying algorithms are described in <ref> [16] </ref>. 2. symbol recognition: classification of symbols by shape, inference of text size and baseline, segmentation of lines into words by spacing, and shape-directed resegmentation to handle touching and broken characters.
Reference: [17] <author> D. Ittner and H. Baird. </author> <title> "Programmable Contextual Analysis", </title> <booktitle> IAPR Workshop on Document Analysis Systems, </booktitle> <pages> pp. 77-92, </pages> <address> Kaiserslautern, Germany, </address> <year> 1994. </year>
Reference-contexts: If no alternatives spelled, then the top-choice remains, based only on shape recognition confidence. The programmable interface of the system made it particularly easy to vary the analysis and get at the internal data structures in a convenient way <ref> [17] </ref>. 4 Experiments Our main hypothesis was simply that fax quality images could in fact be categorized almost as accurately as the original text. This belief was motivated by the relatively good results of recent studies of text retrieval on OCR text.
Reference: [18] <author> D. Lewis. </author> <title> "Evaluating and Optimizing Autonomous Text Classification Systems". </title> <booktitle> Submitted to Eighteenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR-95). </booktitle>
Reference-contexts: Details on estimating, approximating, and optimizing effectiveness measures for binary 308 classification are presented elsewhere <ref> [18] </ref>. 5 Results Our two main hypotheses were that effective categorization of low quality images was possible, and that training of catego-rizers could be done even if no source of ground truth for the text was available.
Reference: [19] <author> D. Lewis and W. Gale. </author> <title> "A Sequential Algorithm for Training Text Classifiers", </title> <booktitle> 17th Int'l ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 3-12, </pages> <address> Dublin, Ireland, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: The use of machine learning to automatically produce categorizers from documents categorized by experts has therefore received much attention. Large quantities of categorized documents may be available from past manual categorization [4], or experts may be asked to categorize a small number of pivotal documents <ref> [19] </ref>. Our approach in this study was to train a single binary (yes/no) classifier for each category of interest. In this section, we describe how documents are represented in our categorization system and then describe the design and training of classifiers that can be applied to these document representations. <p> This gave us pairs of the form &lt; S (D i ; Q c ); class label &gt; where class label is 1 if the instance is a category member and 0 if not. We then applied logistic regression <ref> [1, 19] </ref> to these pairs.
Reference: [20] <author> D. Lewis and K. Sparck Jones. </author> <title> "Natural Language Processing for Information Retrieval", </title> <journal> Communications of the ACM, </journal> <note> to appear. </note>
Reference-contexts: In text retrieval, however, the user query provides at least a few strings that can be assumed to be good content indicators and likely to occur in relevant documents. The user query can compensate for many problems in a text representation <ref> [20] </ref>. Conversely, when analogous information is not available in a text categorization context, OCR errors become a particular problem.
Reference: [21] <author> D. Lewis and R. Tong. </author> <title> "Text Filtering in MUC-3 and MUC-4", </title> <booktitle> 4th Message Understanding Conference (MUC-4), </booktitle> <address> Los Altos, CA., </address> <pages> pp. 51-66, </pages> <month> June, </month> <year> 1992. </year>
Reference-contexts: Text categorization can also aid other language processing tasks such as information extraction <ref> [21] </ref>, word sense disambiguation [12], and even handwriting recognition [27]. This paper addresses the automated categorization of text images, based on the output of optical character recognition (OCR) applied to the image.
Reference: [22] <author> I. Phillips, S. Chen, and R. Haralick. </author> <title> "CD-ROM Document Database Standard", </title> <booktitle> 2nd Int'l Conference on Document Analysis and Recognition, </booktitle> <pages> pp. 478-483, </pages> <address> Tsukuba Science City, Japan, </address> <month> October, </month> <year> 1993. </year>
Reference-contexts: text classifier for each category was then trained on the training pages, and then the set of classifiers was tested on the test pages. 4.2 Data Set Our data set was taken from the database of pages from technical journals and reports distributed on CD-ROM by the University of Washington <ref> [22] </ref>. The CD contains images and corresponding text for 1000 pages of English-language reports from a wide range of disciplines. Categories were automatically assigned to each page based solely on the journal from which it was taken.
Reference: [23] <author> J. Quinlan. </author> <title> "The Effect of Noise on Concept Learning", </title> <editor> In R. S. Michalski, J. G. Carbonell, and T. M. Mitchell, eds., </editor> <booktitle> "Machine Learning. An Artificial Intelligence Approach. </booktitle> <volume> Volume II", </volume> <pages> pp. 149-166, </pages> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: A second hypothesis was that a fax categorization system could be trained on OCR output, without access to any original document text. We were motivated here by a number of results in pattern recognition and machine learning (e.g. <ref> [23] </ref>) that suggest that when feature noise is present in test data, learning is actually more effective when the noise is present in training data as well.
Reference: [24] <author> S. Rice, J. Kanai, and T. Nartker. </author> <booktitle> "The Third Annual Text of OCR Accuracy", UNLV Information Science Research Institute Annual Report, </booktitle> <year> 1994. </year>
Reference-contexts: Facsimile machines are increasingly popular and produce images which are particularly noisy: the digitization resolution is coarse, skew may be non-linear, scanlines are dropped due to communication errors, and so on. State of the art OCR does not provide accurate transcription on images of such quality <ref> [24] </ref>. The errors present in OCR-produced text pose the same problems for text categorization that they do for text retrieval [33]. Crucial words may be garbled, noise strings may distort statistical weighting for 301 mulas, and so on.
Reference: [25] <author> J. Rocchio, Jr. </author> <title> "Relevance Feedback in Information Retrieval", In The SMART Retrieval System: Experiments in Automatic Document Processing, </title> <publisher> Prentice-Hall, Inc, </publisher> <year> 1971, </year> <pages> pp. 68-73. </pages>
Reference-contexts: In other words, the classifier has the same form (a vector of term weights) that documents do, and classification is done by measuring the similarity of test documents to the classifier. To produce the prototype for each class, we used Rocchio's algorithm [13], <ref> [25] </ref>, [28, pp. 319-321].
Reference: [26] <author> R. Rose. </author> <title> "Techniques for Information Retrieval from Speech Messages", </title> <journal> The Lincoln Laboratory Journal, </journal> <volume> 4(1) </volume> <pages> 45-60, </pages> <year> 1991. </year>
Reference-contexts: On the other hand, research using artificial data has suggested that high error rates can be tolerable for text retrieval [31], and there has been some success at categorizing continuous speech data, where high word recognition error rates are currently inevitable <ref> [26] </ref>. In addition, Hoch [15] has presented an experiment in which images of 42 German business letters were categorized with 57% accuracy into one of six categories.
Reference: [27] <author> T. Rose and L. Evett. </author> <title> "Text Recognition using Collocations and Domain Codes", </title> <booktitle> Workshop on Very Large Corpora, </booktitle> <pages> pp. 65-73, </pages> <address> Columbus, OH, </address> <month> June </month> <year> 1993. </year> <institution> Association for Computational Linguistics. </institution>
Reference-contexts: Text categorization can also aid other language processing tasks such as information extraction [21], word sense disambiguation [12], and even handwriting recognition <ref> [27] </ref>. This paper addresses the automated categorization of text images, based on the output of optical character recognition (OCR) applied to the image.
Reference: [28] <author> G. Salton. </author> <title> "Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer", </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: We chose instead to adapt a classifier form and training method widely used in text retrieval. In vector space retrieval <ref> [28, pp. 313-319] </ref>, a class is represented by a single idealized relevant document or prototype [11], [30, Ch. 5]. In other words, the classifier has the same form (a vector of term weights) that documents do, and classification is done by measuring the similarity of test documents to the classifier. <p> In other words, the classifier has the same form (a vector of term weights) that documents do, and classification is done by measuring the similarity of test documents to the classifier. To produce the prototype for each class, we used Rocchio's algorithm [13], [25], <ref> [28, pp. 319-321] </ref>.
Reference: [29] <author> P. Sibun and A. Spitz. </author> <title> "Language Determination: Natural Language Processing from Scanned Document Images", </title> <booktitle> Fourth Conference on Applied Natural Language Processing, </booktitle> <pages> pp. 15-21, </pages> <address> Stuttgart, Germany, </address> <year> 1994. </year> <month> 313 </month>
Reference-contexts: The confidence associated with each hypothesis could be accounted for in a probabilistic indexing model [9]. Nor is it necessary to output words. Other possibilities includes character n-grams [7] and word shape tokens <ref> [29] </ref>. On the text categorization side, we have tried only one, albeit plausible, approach to categorizing low quality images.
Reference: [30] <author> E. Smith and D. Medin. </author> <title> "Categories and Concepts", </title> <publisher> Harvard University Press, </publisher> <address> Cambridge, MA, </address> <year> 1981. </year>
Reference-contexts: We chose instead to adapt a classifier form and training method widely used in text retrieval. In vector space retrieval [28, pp. 313-319], a class is represented by a single idealized relevant document or prototype [11], <ref> [30, Ch. 5] </ref>. In other words, the classifier has the same form (a vector of term weights) that documents do, and classification is done by measuring the similarity of test documents to the classifier. To produce the prototype for each class, we used Rocchio's algorithm [13], [25], [28, pp. 319-321].
Reference: [31] <author> S. Smith and C. Stanfill. </author> <title> "An Analysis of the Effects of Data Corruption on Text Retrieval Performance", </title> <type> Technical Report DR90-1, </type> <institution> Thinking Machines Corporation, </institution> <month> December, </month> <year> 1988. </year>
Reference-contexts: Conversely, when analogous information is not available in a text categorization context, OCR errors become a particular problem. On the other hand, research using artificial data has suggested that high error rates can be tolerable for text retrieval <ref> [31] </ref>, and there has been some success at categorizing continuous speech data, where high word recognition error rates are currently inevitable [26]. In addition, Hoch [15] has presented an experiment in which images of 42 German business letters were categorized with 57% accuracy into one of six categories.
Reference: [32] <author> K. Taghva, J. Borsack, and A. Condit. </author> <title> "Results of Applying Probabilistic IR to OCR Text", </title> <booktitle> 17th Int'l ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 202-211, </pages> <address> Dublin, Ireland, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: This paper addresses the automated categorization of text images, based on the output of optical character recognition (OCR) applied to the image. Several recent studies have suggested that OCR output is quite adequate for the related task of text retrieval, at least when clean images are available <ref> [10, 32, 33] </ref>. Unfortunately, in practice not all images are clean. Even with high-resolution scanners, OCR systems are constantly faced with poor-quality images due to light originals, photocopies, poor contrast, etc.
Reference: [33] <author> K. Taghva, J. Borsack, A. Condit, and S. Erva. </author> <title> "The Effects of Noisy Data on Text Retrieval", </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 45 </volume> <pages> 50-58, </pages> <year> 1994. </year>
Reference-contexts: This paper addresses the automated categorization of text images, based on the output of optical character recognition (OCR) applied to the image. Several recent studies have suggested that OCR output is quite adequate for the related task of text retrieval, at least when clean images are available <ref> [10, 32, 33] </ref>. Unfortunately, in practice not all images are clean. Even with high-resolution scanners, OCR systems are constantly faced with poor-quality images due to light originals, photocopies, poor contrast, etc. <p> State of the art OCR does not provide accurate transcription on images of such quality [24]. The errors present in OCR-produced text pose the same problems for text categorization that they do for text retrieval <ref> [33] </ref>. Crucial words may be garbled, noise strings may distort statistical weighting for 301 mulas, and so on. In text retrieval, however, the user query provides at least a few strings that can be assumed to be good content indicators and likely to occur in relevant documents.
Reference: [34] <author> J. Tague. </author> <title> "The pragmatics of information retrieval experimentation." In Information Retrieval Experiment, </title> <address> But-terworths, London, </address> <year> 1981, </year> <pages> pp. 59-102. </pages>
Reference-contexts: In addition to evaluating the effectiveness of a system in assigning a particular category, we would like measures of average effectiveness in assigning a set of categories. Two main methods, microaverag-ing and macroaveraging, have been used for this purpose in text retrieval <ref> [34] </ref>. In microaveraging the contingency tables for the individual categories are added cellwise, and then the effectiveness measures such as recall, F fi , and so on are computed. In macroaveraging effectiveness measures are computed separately for each category and averaged over the categories.
Reference: [35] <author> T. Tokunaga and M. Iwayama. </author> <title> "Text Categorization based on Weighted Inverse Document Frequency". </title> <type> Technical Report 94-TR0001, </type> <institution> Dept. of Computer Science, Tokyo Institute of Technology, </institution> <month> March, </month> <year> 1994. </year> <note> [36] "Ulrich's International Periodicals Directory", published by R.R. </note> <editor> Bowker, </editor> <publisher> Reed Reference Publishing Company. </publisher>
Reference-contexts: We used the standard values fi = 16 and fl = 4 [6]. The full Rocchio formula also takes into account terms suggested by a human user, but we omit this component. Other approaches to constructing a prototype-based classifier for text categorization have been proposed <ref> [35, 38] </ref>. Our reason for choosing Rocchio's algorithm was based on its ability to work well without sophisticated feature selection, in contrast to many learning algorithms used for relevance feedback [6].
Reference: [37] <editor> C. van Rijsbergen. </editor> <booktitle> "Information Retrieval", 2nd edition, </booktitle> <publisher> Butterworths, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: A single measure of system effectiveness which takes into account the relative value of recall and precision to the system's users is the F-measure (1.0 minus Van Rijsber-gen's E-measure <ref> [37, pp. 168-176] </ref>): F fi = (fi 2 + 1)a + b + fi 2 c (fi 2 + 1)P R (1) where P is precision and R is recall. The parameter fi ranges between 0 and infinity.
Reference: [38] <author> Y. Yang. </author> <title> "Expert Network: Effective and Efficient Learning from Human Decisions in Text Categorization and Retrieval", </title> <booktitle> 17th Int'l ACM/SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pp. 13-22, </pages> <address> Dublin, Ireland, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: We used the standard values fi = 16 and fl = 4 [6]. The full Rocchio formula also takes into account terms suggested by a human user, but we omit this component. Other approaches to constructing a prototype-based classifier for text categorization have been proposed <ref> [35, 38] </ref>. Our reason for choosing Rocchio's algorithm was based on its ability to work well without sophisticated feature selection, in contrast to many learning algorithms used for relevance feedback [6].
References-found: 37

