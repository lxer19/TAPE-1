URL: http://www.cs.nyu.edu/phd_students/parida/res/public/treeAlex98.ps.gz
Refering-URL: http://www.cs.nyu.edu/phd_students/parida/res/res.html
Root-URL: http://www.cs.nyu.edu
Email: e-mail: huson@math.princeton.edu  e-mail: nettles@central.cis.upenn.edu  e-mail: parida@cs.nyu.edu  e-mail: tandy@central.cis.upenn.edu  e-mail: yooseph@saul.cis.upenn.edu  
Title: The Disk-Covering Method for Tree Reconstruction  
Author: Daniel Huson Scott Nettles Laxmi Parida Tandy Warnow and Shibu Yooseph 
Address: Princeton University, Princeton NJ 08544-1000  Philadelphia PA 19104  New York University, New York City NY 10012  Philadelphia PA 19104  Piscataway, NJ 08854  
Affiliation: Program in Applied and Computational Mathematics  Department of Computer and Information Science University of Pennsylvania,  Courant Institute of Mathematical Sciences  Department of Computer and Information Science University of Pennsylvania,  DIMACS, Rutgers University,  
Abstract: Evolutionary tree reconstruction is a very important step in many biological research problems, and yet is extremely difficult for a variety of computational, statistical, and scientific reasons. In particular, the reconstruction of very large trees containing significant amounts of divergence is especially challenging. We present in this paper a new tree reconstruction method, which we call the Disk-Covering Method, which can be used to recover accurate estimations of the evolutionary tree for otherwise intractable datasets. DCM obtains a decomposition of the input dataset into small overlapping sets of closely related taxa, reconstructs trees on these subsets (using a "base" phylogenetic method of choice), and then combines the subtrees into one tree on the entire set of taxa. Because the subproblems analyzed by DCM are smaller, com-putationally expensive methods such as maximum likelihood estimation can be used without incurring too much cost. At the same time, because the taxa within each subset are closely related, even very simple methods (such as neighbor-joining) are much more likely to be highly accurate. The result is that DCM-boosted methods are typically faster and more accurate as compared to "naive" use of the same method. In this paper we describe the basic ideas and techniques in DCM, and demonstrate the advantages of DCM experimentally by simulating sequence evolution on a variety of trees.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agarwala, V. Bafna, M. Farach, B. Narayanan, M. Paterson, and M. </author> <title> Thorup, On the ap-proximability of numerical taxonomy: fitting distances by tree metrics, </title> <booktitle> Proceedings of the 7th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> (1996) </year> <month> 365-372. </month>
Reference-contexts: Inferring the leaf-labeled topology of the evolutionary tree is, unfortunately, enormously difficult. Computational difficulties arise because essentially all optimization problems involving tree reconstruction are NP-hard <ref> [1, 5, 14, 20, 23, 41] </ref>. (Some polynomial time approximations do exist, for example, a 3-approximation algorithm for the L 1 -nearest tree [1] and the standard trick to 2-approximate the maximum parsimony tree by constructing a minimum spanning tree, but they do not seem to be sufficiently accurate with respect <p> Inferring the leaf-labeled topology of the evolutionary tree is, unfortunately, enormously difficult. Computational difficulties arise because essentially all optimization problems involving tree reconstruction are NP-hard [1, 5, 14, 20, 23, 41]. (Some polynomial time approximations do exist, for example, a 3-approximation algorithm for the L 1 -nearest tree <ref> [1] </ref> and the standard trick to 2-approximate the maximum parsimony tree by constructing a minimum spanning tree, but they do not seem to be sufficiently accurate with respect to topology estimation.) Indeed, most of the techniques commonly used by biologists, for example, maximum parsimony (a sequence-based method aimed at minimizing the
Reference: [2] <author> K. </author> <title> Atteson,The performance of neighbor-joining algorithms of phylogeny reconstruction, </title> <booktitle> Computing and Combinatorics, Third Annual International Conference, </booktitle> <address> COCOON '97, Shanghai, China, </address> <month> August </month> <year> 1997, </year> <booktitle> Proceedings. Lecture Notes in Computer Science, </booktitle> <volume> 1276, </volume> <editor> Tao Jiang and D.T. Lee, (Eds.). </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> (1997) </year> <month> 101-110. </month>
Reference-contexts: Recent studies have established that while most distance-based methods work well for small trees, the sequence lengths that they require for highly accurate topology estimation for significantly divergent datasets can be beyond what is ever likely to be available <ref> [2, 19, 37, 38] </ref>. Heuristics to solve the NP-hard maximum parsimony problem do not seem to have the same degradation on large divergent trees [37], but they have other problems.
Reference: [3] <author> H.-J. Bandelt and A.W.M. Dress, </author> <title> A canonical decomposition theory for metrics on a finite set, </title> <booktitle> Advances in Mathematics, </booktitle> <month> 92 </month> <year> (1992) </year> <month> 47-105. </month>
Reference-contexts: Finally, first experiments with DCM-boosted split decomposition indicate that significant in-provements can be obtained over naive split decomposition, a method for producing splits graphs (essentially networks that can describe a number of conflicting trees) to represent phylogenetic relationships <ref> [3] </ref>. Conclusions and Acknowledgments We have presented a new method for tree reconstruction which can be used in conjunction with other phylogenetic tree reconstruction methods, recovering generally a much more accurate estimation of the true tree from shorter sequences than has typically been possible.
Reference: [4] <author> J. Barthelemy and F. McMorris, </author> <title> The median procedure for n-Trees, </title> <journal> Journal of Classification, </journal> <month> 3 </month> <year> (1986) </year> <month> 329-334. </month>
Reference-contexts: Note, if minimizing the false negative rate is most desirable, then the asymmetric median tree [34] is the preferred subtree merger method. However, there are many different consensus methods that can be considered. For an entry to the rich literature on consensus methods, see <ref> [13, 42, 4] </ref>. not agree on X. The strict consensus of the two subtrees induced by X is computed, and each tree is transformed (by edge-contractions) so as to induce that structure on X.
Reference: [5] <author> H. Bodlaender, M. Fellows, and T. Warnow, </author> <title> Two strikes against perfect phylogeny, </title> <booktitle> Proceedings, International Colloquium on Automata, Languages and Programming. Springer Verlag Lecture Notes in Computer Science, </booktitle> <month> 623 </month> <year> (1992) </year> <month> 273-283. </month>
Reference-contexts: Inferring the leaf-labeled topology of the evolutionary tree is, unfortunately, enormously difficult. Computational difficulties arise because essentially all optimization problems involving tree reconstruction are NP-hard <ref> [1, 5, 14, 20, 23, 41] </ref>. (Some polynomial time approximations do exist, for example, a 3-approximation algorithm for the L 1 -nearest tree [1] and the standard trick to 2-approximate the maximum parsimony tree by constructing a minimum spanning tree, but they do not seem to be sufficiently accurate with respect
Reference: [6] <author> M. Bonet, C.A. Phillips, T. Warnow, and S. Yooseph, </author> <title> Constructing evolutionary trees in the presence of polymorphic characters, </title> <note> to appear, SIAM J. Computing. (A preliminary version appeared in the ACM Symposium on the Theory of Computing, </note> <year> 1996.) </year>
Reference: [7] <author> M. Bonet, M. A. Steel, T. Warnow, and S. Yooseph. </author> <title> Faster algorithms for solving parsimony and compatibility, </title> <note> to appear, RECOMB 1998. </note>
Reference-contexts: Although this is generally an NP-hard problem, it can be solved very efficiently when the number of bipartitions which must be eliminated is small, using our techniques from <ref> [7, 34] </ref> (this problem is related to the tree compatibility problem, studied in [26, 45]). Since our experimental results showed that for most settings for w, the trees T w had low false positive rates, these fast algorithms can be applied to obtain asymmetric median trees efficiently.
Reference: [8] <author> P. Buneman, </author> <title> The recovery of trees from measures of dissimilarity, in Mathematics in the Archaeological and Historical Sciences, </title> <editor> F. R. Hodson, D. G. Kendall, P. Tautu, eds.; </editor> <publisher> Edinburgh University Press, Edinburgh, </publisher> <year> (1971) </year> <month> 387-395. </month>
Reference-contexts: in turn here. 3.1 Computing a Tree for a Given Width For most iid models of evolution, and some non-iid models as well, it is possible to define distances between sequences generated on trees under these models, in such a way that the distances converge in probability to an additive <ref> [8] </ref> distance matrix defining the model tree. Given this additive distance matrix recovering the edge-weighted model tree can be done in polynomial time (there are many 4 such algorithms, the first of which is due to Waterman [47]). <p> Figure 3 shows the result of one such experiment, based on the simple version of DCM in which we select the most resolved T w as the output tree, and using the Buneman Tree <ref> [8] </ref> as the base method. 4.2 Error Tolerance for Threshold Selection Using neighbor-joining, we find that unless the tree is very accurately inferred by naive neighbor-joining (which tends not to be the case with highly divergent datasets), any selection of w in the range [w 1 ; w fl ) obtains
Reference: [9] <author> P. Buneman, </author> <title> A characterization of rigid circuit graphs, </title> <journal> Discrete Mathematics, </journal> <month> 9 </month> <year> (1974) </year> <month> 205-212. </month>
Reference-contexts: We can show: Lemma 3.1 If d is an additive matrix, then the threshold graph d w is triangulated. (We omit the proof, but note that it depends upon the characterization of triangulated graphs as intersection graphs of subtrees of a tree <ref> [9] </ref>.) The threshold graph d w is likely to be close to triangulated, since it is close to D w , where D is the additive matrix corresponding to the true tree (in fact, for small w, even if D and d are very far apart, the graphs d w and
Reference: [10] <author> L. </author> <title> Cai,Fixed-parameter tractability of graph modification problems for hereditary properties, </title> <journal> Information Processing Letters, </journal> <month> 58 </month> <year> (1996) </year> <month> 171-176. </month>
Reference-contexts: Obtaining a minimal triangulation of a graph is in general NP-hard [48], but for the graphs we will consider, even simple heuristics work effectively and efficiently. Furthermore, it was recently shown that exact solutions can be obtained efficiently when the number of additional edges needed is small <ref> [10, 29] </ref>. Lemma 3.2 (from [24]).

Reference: [12] <author> X. Cousin, T. Hotelier, K. Giles, P. Lievin, J.-P. Toutant and A. Chatonnet, </author> <title> The alpha/beta fold family of proteins database and the cholinesterase gene server ESTHER, </title> <journal> Nucleic Acids Res., </journal> <month> 25 </month> <year> (1997) </year> <month> 143-146. </month>
Reference-contexts: For example, reconstructing the origin (or, as is more likely, the multiple origins) of photo-receptor molecules, requires high divergence datasets, as shown by Rice [35], as does reconstructing the tree of cholinesterases, neuroenzymes that are common targets of pesticides <ref> [12] </ref>. Understanding the origins of viruses that have been transferred to humans from other animals (for example, HIV) also involves hundreds of divergent taxa.
Reference: [13] <author> W.H.E. </author> <title> Day,Optimal algorithms for comparing trees with labelled leaves, </title> <journal> Journal of Classification 2, </journal> <year> (1995) </year> <month> 7-28. </month>
Reference-contexts: Note, if minimizing the false negative rate is most desirable, then the asymmetric median tree [34] is the preferred subtree merger method. However, there are many different consensus methods that can be considered. For an entry to the rich literature on consensus methods, see <ref> [13, 42, 4] </ref>. not agree on X. The strict consensus of the two subtrees induced by X is computed, and each tree is transformed (by edge-contractions) so as to induce that structure on X.
Reference: [14] <author> W.H.E. Day and D.S. Johnson, </author> <title> The computational complexity of inferring rooted phylogenies by parsimony, </title> <journal> Mathematical Biosciences, </journal> <month> 81 </month> <year> (1986) </year> <month> 33-42. </month>
Reference-contexts: Inferring the leaf-labeled topology of the evolutionary tree is, unfortunately, enormously difficult. Computational difficulties arise because essentially all optimization problems involving tree reconstruction are NP-hard <ref> [1, 5, 14, 20, 23, 41] </ref>. (Some polynomial time approximations do exist, for example, a 3-approximation algorithm for the L 1 -nearest tree [1] and the standard trick to 2-approximate the maximum parsimony tree by constructing a minimum spanning tree, but they do not seem to be sufficiently accurate with respect
Reference: [15] <author> P.L. Erdos, K. Rice, M. A. Steel, L. Szekely, and T. Warnow, </author> <note> The Short Quartet Method, to appear, Mathematical Modeling and Scientific Computing, Principia Scientia (1998). </note>
Reference-contexts: One attempt towards such a goal is the short quartet method [16]. This method can obtain completely accurate topology estimations from very short sequences, as was confirmed experimentally in <ref> [15] </ref>. Unfortunately, the short quartet method sometimes fails to return any tree at all, a serious limitation if the objective is to analyze a real data set! This paper focuses on a new method, or, more precisely, new class of methods, the disk-covering methods, or DCM. <p> the inability to control the divergence in the subproblems, or from difficulties in determining in how to arrange the obtained subtrees in a supertree. 2.1 An Insight from Short Quartet Methods The development of the short quartet method , or, more precisely, a whole set of short quartet methods (SQM) <ref> [15, 16, 17, 18, 19] </ref> provided a key insight into how to solve the problem of decomposing datasets into smaller, less divergent subproblems. <p> The subproblems we will analyze will correspond precisely to the maximal cliques of the triangulated supergraph of d w . By the results from the short quartet papers <ref> [15, 16, 18, 19] </ref>, small w values will generally suffice to define the tree T .
Reference: [16] <author> P. L. Erd-os, M. A. Steel, L. A. Szekely, and T. Warnow, </author> <title> Constructing big trees from short sequences, </title> <booktitle> ICALP'97, 24th International Colloquium on Automata, Languages, and Programming (Silver Jubilee of EATCS), </booktitle> <address> Bologna, Italy, </address> <month> July 7th-11th, </month> <year> 1997, </year> <editor> eds. G. Goos, J. Hartmanis, J. van Leeuwen, </editor> <booktitle> Lecture Notes in Computer Science 1256, </booktitle> <year> 1997. </year>
Reference-contexts: Consequently, what is needed are fast algorithms (at least, algorithms which are fast enough to be attractive to biologists) which have short sequence length requirements for accurate reconstructions of highly divergent trees. One attempt towards such a goal is the short quartet method <ref> [16] </ref>. This method can obtain completely accurate topology estimations from very short sequences, as was confirmed experimentally in [15]. <p> the inability to control the divergence in the subproblems, or from difficulties in determining in how to arrange the obtained subtrees in a supertree. 2.1 An Insight from Short Quartet Methods The development of the short quartet method , or, more precisely, a whole set of short quartet methods (SQM) <ref> [15, 16, 17, 18, 19] </ref> provided a key insight into how to solve the problem of decomposing datasets into smaller, less divergent subproblems. <p> We call this class of techniques the disk-covering methods, or DCM. DCM uses the key insight from SQM that each tree is reconstructible from its small width subtrees. Let us consider more fully how SQM works. Using techniques described in <ref> [16, 18, 19] </ref>, SQM can compute a bound on the width w such that if we know all subtrees on subsets of width at most w we can reconstruct the tree. <p> The subproblems we will analyze will correspond precisely to the maximal cliques of the triangulated supergraph of d w . By the results from the short quartet papers <ref> [15, 16, 18, 19] </ref>, small w values will generally suffice to define the tree T .
Reference: [17] <author> P. Erd-os, M. Steel, L. Szekely, and T. Warnow, </author> <title> Local quartet splits of a binary tree infer all quartet splits via one dyadic inference rule, </title> <journal> Computers and Artificial Intelligence, </journal> <month> 16(2) </month> <year> (1997) </year> <month> 217-227. </month>
Reference-contexts: the inability to control the divergence in the subproblems, or from difficulties in determining in how to arrange the obtained subtrees in a supertree. 2.1 An Insight from Short Quartet Methods The development of the short quartet method , or, more precisely, a whole set of short quartet methods (SQM) <ref> [15, 16, 17, 18, 19] </ref> provided a key insight into how to solve the problem of decomposing datasets into smaller, less divergent subproblems.
Reference: [18] <author> P. L. Erd-os, M. A. Steel, L. A. Szekely, and T. Warnow, </author> <title> A few logs suffice to build (almost) all trees I, submitted to Random Structures and Algorithms, </title> <type> DIMACS Technical Report 97-71, </type> <pages> pp. </pages> <note> 33, under http://www.dimacs.rutgers.edu/TechnicalReports/1997.html </note>
Reference-contexts: the inability to control the divergence in the subproblems, or from difficulties in determining in how to arrange the obtained subtrees in a supertree. 2.1 An Insight from Short Quartet Methods The development of the short quartet method , or, more precisely, a whole set of short quartet methods (SQM) <ref> [15, 16, 17, 18, 19] </ref> provided a key insight into how to solve the problem of decomposing datasets into smaller, less divergent subproblems. <p> We call this class of techniques the disk-covering methods, or DCM. DCM uses the key insight from SQM that each tree is reconstructible from its small width subtrees. Let us consider more fully how SQM works. Using techniques described in <ref> [16, 18, 19] </ref>, SQM can compute a bound on the width w such that if we know all subtrees on subsets of width at most w we can reconstruct the tree. <p> The subproblems we will analyze will correspond precisely to the maximal cliques of the triangulated supergraph of d w . By the results from the short quartet papers <ref> [15, 16, 18, 19] </ref>, small w values will generally suffice to define the tree T .
Reference: [19] <author> P. L. Erd-os, M. A. Steel, L. A. Szekely, and T. Warnow, </author> <title> A few logs suffice to build (almost) all trees II, </title> <note> submitted to Theor. Comp. Sci., DIMACS Technical Report 97-72, pp. 46, under http://www.dimacs.rutgers.edu/TechnicalReports/1997.html </note>
Reference-contexts: Recent studies have established that while most distance-based methods work well for small trees, the sequence lengths that they require for highly accurate topology estimation for significantly divergent datasets can be beyond what is ever likely to be available <ref> [2, 19, 37, 38] </ref>. Heuristics to solve the NP-hard maximum parsimony problem do not seem to have the same degradation on large divergent trees [37], but they have other problems. <p> In other words, maximal parsimony is inconsistent on some trees, even with iid site evolution [21] (by comparison, almost all distance based methods are consistent on all trees with iid site evolution <ref> [19] </ref>). Unfortunately, the inconsistency of maximum parsimony is not just a theoretical phenomenon, it occurs for real trees of biological interest as well. Research into the conditions under which maximum parsimony will be consistent has so far been inconclusive [21, 27, 30, 37, 44]. <p> Provided that decomposing the dataset and assembling the subtrees is not too expensive, then this strategy has an obvious computational advantage. However, if such strategies do nothing to reduce the divergence present in the subproblems, they can actually increase the sequence length requirements, as our results in <ref> [19] </ref> showed. <p> the inability to control the divergence in the subproblems, or from difficulties in determining in how to arrange the obtained subtrees in a supertree. 2.1 An Insight from Short Quartet Methods The development of the short quartet method , or, more precisely, a whole set of short quartet methods (SQM) <ref> [15, 16, 17, 18, 19] </ref> provided a key insight into how to solve the problem of decomposing datasets into smaller, less divergent subproblems. <p> We call this class of techniques the disk-covering methods, or DCM. DCM uses the key insight from SQM that each tree is reconstructible from its small width subtrees. Let us consider more fully how SQM works. Using techniques described in <ref> [16, 18, 19] </ref>, SQM can compute a bound on the width w such that if we know all subtrees on subsets of width at most w we can reconstruct the tree. <p> Indeed, given long enough finite length sequences, under such models even extremely simple techniques can recover the topology of the model tree with high probability <ref> [19] </ref>. Furthermore, it can be shown that essentially all distance-based methods are provably consistent (i.e. given long enough sequences, they obtain the true tree with high probability). <p> The subproblems we will analyze will correspond precisely to the maximal cliques of the triangulated supergraph of d w . By the results from the short quartet papers <ref> [15, 16, 18, 19] </ref>, small w values will generally suffice to define the tree T .
Reference: [20] <author> M. Farach, S. Kannan, and T. Warnow, </author> <title> A Robust Model for Finding Optimal Evolutionary Trees, </title> <journal> Algorithmica, special issue on Computational Biology, </journal> <note> 13(1) (1995) 155-179. (A preliminary version of this paper appeared at STOC 1993.) </note>
Reference-contexts: Inferring the leaf-labeled topology of the evolutionary tree is, unfortunately, enormously difficult. Computational difficulties arise because essentially all optimization problems involving tree reconstruction are NP-hard <ref> [1, 5, 14, 20, 23, 41] </ref>. (Some polynomial time approximations do exist, for example, a 3-approximation algorithm for the L 1 -nearest tree [1] and the standard trick to 2-approximate the maximum parsimony tree by constructing a minimum spanning tree, but they do not seem to be sufficiently accurate with respect
Reference: [21] <author> J. Felsenstein, </author> <title> Cases in which parsimony or compatibility methods will be positively misleading, </title> <journal> Syst. Zool. </journal> <volume> 27 (1978), </volume> <pages> 401-410. </pages>
Reference-contexts: Statistical analysis shows that, even with infinite length sequences, there are some datasets for which parsimony will fail to recover the correct tree. In other words, maximal parsimony is inconsistent on some trees, even with iid site evolution <ref> [21] </ref> (by comparison, almost all distance based methods are consistent on all trees with iid site evolution [19]). Unfortunately, the inconsistency of maximum parsimony is not just a theoretical phenomenon, it occurs for real trees of biological interest as well. <p> Unfortunately, the inconsistency of maximum parsimony is not just a theoretical phenomenon, it occurs for real trees of biological interest as well. Research into the conditions under which maximum parsimony will be consistent has so far been inconclusive <ref> [21, 27, 30, 37, 44] </ref>. Nevertheless, maximum parsimony receives a great deal of support from systematic biologists.
Reference: [22] <author> J. Felsenstein, </author> <title> Phylogenies from molecular sequences: inference and reliability, Annu. </title> <journal> Rev. </journal> <volume> Genet., </volume> <month> 22 </month> <year> (1988) </year> <month> 521-565. </month>
Reference-contexts: This work is quite preliminary, as it is clear that we will obtain much better results after fine-tuning the techniques to work with different phylogenetic methods. The reader interested in learning more about phylogenetic tree reconstruction methods should see <ref> [22, 43, 46] </ref> for a deeper introduction into the issues involved in phylogenetic analysis.
Reference: [23] <author> L. R. Foulds, R. L. Graham, </author> <title> The Steiner problem in phylogeny is NP-complete, </title> <journal> Adv. Appl. Math. </journal> <volume> 3 (1982), </volume> <pages> 43-49. </pages>
Reference-contexts: Inferring the leaf-labeled topology of the evolutionary tree is, unfortunately, enormously difficult. Computational difficulties arise because essentially all optimization problems involving tree reconstruction are NP-hard <ref> [1, 5, 14, 20, 23, 41] </ref>. (Some polynomial time approximations do exist, for example, a 3-approximation algorithm for the L 1 -nearest tree [1] and the standard trick to 2-approximate the maximum parsimony tree by constructing a minimum spanning tree, but they do not seem to be sufficiently accurate with respect
Reference: [24] <author> M.C. Golumbic. </author> <title> Algorithmic Graph Theory and Perfect Graphs. </title> <publisher> Academic Press Inc, </publisher> <year> 1980. </year>
Reference-contexts: A triangulated graph is a graph which has no cycles of size four or more that are induced by any set of nodes in the graph <ref> [24] </ref>; consequently, all cycles of size four or more contain chords. <p> Furthermore, it was recently shown that exact solutions can be obtained efficiently when the number of additional edges needed is small [10, 29]. Lemma 3.2 (from <ref> [24] </ref>).
Reference: [25] <editor> Green Plant Phylogeny Research Coordination Group, </editor> <booktitle> Summary report of Workshop #1: Current Status of the Phylogeny of the Charophyte Green Algae and the Embryophytes. </booktitle> <institution> University and Jepson Herbaria, University of California, Berkeley, </institution> <month> June 24-28, </month> <year> 1995. </year> <month> 7 January, </month> <year> 1996. </year>
Reference-contexts: This is because phylogenetic reconstruction methods require homologous sequences (i.e. sequences that have a common ancestor), and it is more difficult to get long homologous sequences between distantly related taxa than between closely related taxa <ref> [25] </ref>. Consequently, what is needed are fast algorithms (at least, algorithms which are fast enough to be attractive to biologists) which have short sequence length requirements for accurate reconstructions of highly divergent trees. One attempt towards such a goal is the short quartet method [16]. <p> However, if such strategies do nothing to reduce the divergence present in the subproblems, they can actually increase the sequence length requirements, as our results in [19] showed. Previous attempts along these lines <ref> [25, 32] </ref> have in general suffered either from difficulty in finding how to partition into subproblems, from the inability to control the divergence in the subproblems, or from difficulties in determining in how to arrange the obtained subtrees in a supertree. 2.1 An Insight from Short Quartet Methods The development of
Reference: [26] <author> D. Gusfield, </author> <title> Efficient algorithms for inferring evolutionary trees, Networks, </title> <month> 21 </month> <year> (1991) </year> <month> 19-28. </month>
Reference-contexts: Although this is generally an NP-hard problem, it can be solved very efficiently when the number of bipartitions which must be eliminated is small, using our techniques from [7, 34] (this problem is related to the tree compatibility problem, studied in <ref> [26, 45] </ref>). Since our experimental results showed that for most settings for w, the trees T w had low false positive rates, these fast algorithms can be applied to obtain asymmetric median trees efficiently.
Reference: [27] <author> D. Hillis, </author> <title> Inferring complex phylogenies, </title> <booktitle> Nature, </booktitle> <month> 383 12 September, </month> <year> 1996, </year> <pages> 130-131. </pages>
Reference-contexts: Unfortunately, the inconsistency of maximum parsimony is not just a theoretical phenomenon, it occurs for real trees of biological interest as well. Research into the conditions under which maximum parsimony will be consistent has so far been inconclusive <ref> [21, 27, 30, 37, 44] </ref>. Nevertheless, maximum parsimony receives a great deal of support from systematic biologists.
Reference: [28] <author> T.H. Jukes and C.R. </author> <title> Cantor,Evolution of Protein Molecules, in: H.N. Munro, ed., Mammalian Protein Metabolism, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> (1969) </year> <month> 21-132. </month>
Reference-contexts: Each point represents the average rates from 2-6 independently generated data sets. 4.1 Experimental Setup We used the Jukes-Cantor <ref> [28] </ref> model of evolution to generate DNA sequences.
Reference: [29] <author> H. Kaplan, R. Shamir, and R.E. Tarjan. </author> <title> Tractability of parameterized completion problems on chordal and interval graphs: minimum fill-in and physical mapping. </title> <booktitle> In Proceedings of the 35th Symposium on Foundations of Computer Science, </booktitle> <pages> pages 780-791. </pages> <publisher> IEEE Computer Science Press, Los Alamitos, </publisher> <address> California, </address> <year> 1994. </year> <note> To appear, SIAM J. Computing. </note>
Reference-contexts: Obtaining a minimal triangulation of a graph is in general NP-hard [48], but for the graphs we will consider, even simple heuristics work effectively and efficiently. Furthermore, it was recently shown that exact solutions can be obtained efficiently when the number of additional edges needed is small <ref> [10, 29] </ref>. Lemma 3.2 (from [24]).
Reference: [30] <author> J. Kim, </author> <title> General inconsistency conditions for maximum parsimony: effects of branch length and increasing number of taxa, </title> <journal> Syst. Biol., </journal> <month> 45(3) </month> <year> (1996) </year> <month> 363-374. </month>
Reference-contexts: Unfortunately, the inconsistency of maximum parsimony is not just a theoretical phenomenon, it occurs for real trees of biological interest as well. Research into the conditions under which maximum parsimony will be consistent has so far been inconclusive <ref> [21, 27, 30, 37, 44] </ref>. Nevertheless, maximum parsimony receives a great deal of support from systematic biologists.
Reference: [31] <author> D. R. Maddison, M. Ruvolo, and D. L. Swofford, </author> <title> Geographic origins of human mitochondrial DNA: phylogenetic evidence from control region sequences. </title> <note> Systematic Zoology , 41 (1992) 111-124. </note>
Reference-contexts: Inference of the geographic origin of humans requires at least 300 mitochondrial DNA sequences <ref> [31] </ref>, while the inference of the "tree of all life" requires sequences for at least 1200 taxa [40].
Reference: [32] <author> B. Mishler, </author> <title> Cladistic analysis of molecular and morphological data, </title> <journal> Am. J. Phys. </journal> <volume> Anthropol, </volume> <month> 94 </month> <year> (1994) </year> <month> 143-156. </month>
Reference-contexts: However, if such strategies do nothing to reduce the divergence present in the subproblems, they can actually increase the sequence length requirements, as our results in [19] showed. Previous attempts along these lines <ref> [25, 32] </ref> have in general suffered either from difficulty in finding how to partition into subproblems, from the inability to control the divergence in the subproblems, or from difficulties in determining in how to arrange the obtained subtrees in a supertree. 2.1 An Insight from Short Quartet Methods The development of
Reference: [33] <author> S. Naher and K. Mehlhorn, LEDA, </author> <title> a Platform for Combinatorial and Geometric Computing, </title> <journal> Communications of the ACM, </journal> <month> 8(1) </month> <year> (1995) </year> <month> 96-102. </month>
Reference-contexts: To find out, we have designed and implemented several variants of DCM in C++ based on <ref> [33] </ref>. Our experiments were designed to study how well DCM-boosted methods work compared to the un-boosted base methods, when applied to datasets generated by simulating evolution on a number of different model trees. 7 (disk-NJ) and for naive neighbor-joining (NJ), 93 taxon tree, equipped with maximum mutation probability 0:64.
Reference: [34] <author> C.A. Phillips and T. Warnow, </author> <title> The Asymmetric Median Tree: a new model for building consensus trees, </title> <journal> Discrete Applied Mathematics, Special Issue on Computational Molecular Biology, </journal> <month> 71 </month> <year> (1996) </year> <month> 311-335. </month>
Reference-contexts: Computing this minimum set of edges is straightforward and can be accomplished in O (np) time (where n is the overall number of taxa, and p is the number of trees). Note, if minimizing the false negative rate is most desirable, then the asymmetric median tree <ref> [34] </ref> is the preferred subtree merger method. However, there are many different consensus methods that can be considered. For an entry to the rich literature on consensus methods, see [13, 42, 4]. not agree on X. <p> The particular consensus that is motivated by the low false positive rates is the asymmetric median tree (developed by Phillips and Warnow, in <ref> [34] </ref>). An asymmetric median tree is formed by taking as many as the bipartitions present in the trees in the set as possible. <p> Although this is generally an NP-hard problem, it can be solved very efficiently when the number of bipartitions which must be eliminated is small, using our techniques from <ref> [7, 34] </ref> (this problem is related to the tree compatibility problem, studied in [26, 45]). Since our experimental results showed that for most settings for w, the trees T w had low false positive rates, these fast algorithms can be applied to obtain asymmetric median trees efficiently.
Reference: [35] <author> K. Rice. </author> <title> The origin, evolution, and classification of G-protein-coupled receptors, </title> <type> PhD. dissertation, </type> <institution> Harvard University, </institution> <year> (1994). </year>
Reference-contexts: For example, reconstructing the origin (or, as is more likely, the multiple origins) of photo-receptor molecules, requires high divergence datasets, as shown by Rice <ref> [35] </ref>, as does reconstructing the tree of cholinesterases, neuroenzymes that are common targets of pesticides [12]. Understanding the origins of viruses that have been transferred to humans from other animals (for example, HIV) also involves hundreds of divergent taxa.
Reference: [36] <author> K. Rice, M. Donoghue, and R. Olmstead, </author> <title> Analyzing large datasets: rbcL 500 revisited, Systematic Biology, </title> <year> (1997). </year>
Reference-contexts: Plant phylogeny (and specifically, the evolution of flowering plants) is one of the most hotly contested phylogenetic problems in biology today, and reconstruction of the evolution of plants involved analyzing DNA sequences for more than 500 plants <ref> [11, 36] </ref>. Inference of the geographic origin of humans requires at least 300 mitochondrial DNA sequences [31], while the inference of the "tree of all life" requires sequences for at least 1200 taxa [40]. <p> However, even if the heuristics are accurate, they can require extremely long computations. For example, one parsimony analysis by Rice and his colleagues <ref> [36] </ref> of a large (500 taxon) seed plant data set took almost a year to compute. Distance-based methods, such as neighbor-joining, which have computationally feasible, polynomial time solutions, would seem to offer a solution. Unfortunately these methods run into a statistical difficulty, especially for divergent datasets. <p> Negatives: C (T ) C (T 0 ); these are "edges" (bipartitions) in T missing from T 0 : The Robinson-Foulds distance is 1 2 jC (T )4C (T 0 )j, i.e. the average of the false positive and false negative rates [39]. the 500 taxon tree generated by Rice <ref> [36] </ref> using the rbcL dataset, with high mutation probabilities assigned to the edges.
Reference: [37] <author> K. Rice and T. Warnow, </author> <title> Parsimony is Hard to Beat!, </title> <booktitle> Computing and Combinatorics, Third Annual International Conference, COCOON '97, Shanghai, China, August 1997 Proceedings. Lecture Notes in Computer Science, </booktitle> <volume> 1276, </volume> <editor> Tao Jiang and D.T. Lee, (Eds.). </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin (1997) 124-133. </address>
Reference-contexts: Recent studies have established that while most distance-based methods work well for small trees, the sequence lengths that they require for highly accurate topology estimation for significantly divergent datasets can be beyond what is ever likely to be available <ref> [2, 19, 37, 38] </ref>. Heuristics to solve the NP-hard maximum parsimony problem do not seem to have the same degradation on large divergent trees [37], but they have other problems. <p> Heuristics to solve the NP-hard maximum parsimony problem do not seem to have the same degradation on large divergent trees <ref> [37] </ref>, but they have other problems. Statistical analysis shows that, even with infinite length sequences, there are some datasets for which parsimony will fail to recover the correct tree. <p> Unfortunately, the inconsistency of maximum parsimony is not just a theoretical phenomenon, it occurs for real trees of biological interest as well. Research into the conditions under which maximum parsimony will be consistent has so far been inconclusive <ref> [21, 27, 30, 37, 44] </ref>. Nevertheless, maximum parsimony receives a great deal of support from systematic biologists. <p> Earlier studies of maximum parsimony and neighbor-joining on this tree <ref> [37] </ref> showed that neighbor-joining had false negative and false positive rates of about 40%, even at 12; 800 nucleotides, while maximum parsimony converged to a tree which was not the model tree, and had false positive and false negative rates of about 8% for sequences of length 1000 12; 800. <p> By comparison, DCM neighbor-joining quickly achieves very low false positive and false negative rates, at 3; 000 nucleotides. 8 Each point represents the average rates from 10 independently generated data sets. These results are consistent with studies discussed in <ref> [37, 38] </ref> that demonstrated that the accuracy of distance-based methods degrades dramatically as the divergence increases; thus, by reducing to problems of smaller divergence, the accuracy is increased. In fact, when we combined DCM with other distance-based methods, we found even greater improvements than we found with neighbor-joining.
Reference: [38] <author> K. Rice, M. A. Steel, T. Warnow, S. Yooseph, </author> <title> Hybrid tree reconstruction methods, </title> <note> submitted for publication. </note>
Reference-contexts: Recent studies have established that while most distance-based methods work well for small trees, the sequence lengths that they require for highly accurate topology estimation for significantly divergent datasets can be beyond what is ever likely to be available <ref> [2, 19, 37, 38] </ref>. Heuristics to solve the NP-hard maximum parsimony problem do not seem to have the same degradation on large divergent trees [37], but they have other problems. <p> By comparison, DCM neighbor-joining quickly achieves very low false positive and false negative rates, at 3; 000 nucleotides. 8 Each point represents the average rates from 10 independently generated data sets. These results are consistent with studies discussed in <ref> [37, 38] </ref> that demonstrated that the accuracy of distance-based methods degrades dramatically as the divergence increases; thus, by reducing to problems of smaller divergence, the accuracy is increased. In fact, when we combined DCM with other distance-based methods, we found even greater improvements than we found with neighbor-joining.
Reference: [39] <author> D. F. Robinson and L. R. Foulds, </author> <title> Comparison of weighted labelled trees, </title> <booktitle> Lecture Notes in Mathematics Vol 748, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> (1979) </year> <month> 119-126. </month>
Reference-contexts: 0 missing from T , and * False Negatives: C (T ) C (T 0 ); these are "edges" (bipartitions) in T missing from T 0 : The Robinson-Foulds distance is 1 2 jC (T )4C (T 0 )j, i.e. the average of the false positive and false negative rates <ref> [39] </ref>. the 500 taxon tree generated by Rice [36] using the rbcL dataset, with high mutation probabilities assigned to the edges.
Reference: [40] <author> M. L. Sogin, G. Hinkle, and D. D. Leipe, </author> <title> Universal tree of life, </title> <note> Nature, 362 (1993) page 795. </note>
Reference-contexts: Inference of the geographic origin of humans requires at least 300 mitochondrial DNA sequences [31], while the inference of the "tree of all life" requires sequences for at least 1200 taxa <ref> [40] </ref>. Since the leaf-labeled topology of the evolutionary tree indicates the order of speciation events (or, in cases of gene trees, the order of gene duplication events), the central technical problem in understanding evolutionary history is reconstructing the topology of the phylogenetic tree.
Reference: [41] <author> M. A. Steel, </author> <title> The complexity of reconstructing trees from qualitative characters and subtrees, </title> <journal> J. Classification, </journal> <month> 9 </month> <year> (1992) </year> <month> 91-116. </month>
Reference-contexts: Inferring the leaf-labeled topology of the evolutionary tree is, unfortunately, enormously difficult. Computational difficulties arise because essentially all optimization problems involving tree reconstruction are NP-hard <ref> [1, 5, 14, 20, 23, 41] </ref>. (Some polynomial time approximations do exist, for example, a 3-approximation algorithm for the L 1 -nearest tree [1] and the standard trick to 2-approximate the maximum parsimony tree by constructing a minimum spanning tree, but they do not seem to be sufficiently accurate with respect
Reference: [42] <author> M.A. Steel and T. Warnow, </author> <title> Kaikoura tree theorems: computing the maximum agreement subtree, </title> <journal> Information Processing Letters, </journal> <month> 48 </month> <year> (1993) </year> <month> 72-82. </month>
Reference-contexts: Note, if minimizing the false negative rate is most desirable, then the asymmetric median tree [34] is the preferred subtree merger method. However, there are many different consensus methods that can be considered. For an entry to the rich literature on consensus methods, see <ref> [13, 42, 4] </ref>. not agree on X. The strict consensus of the two subtrees induced by X is computed, and each tree is transformed (by edge-contractions) so as to induce that structure on X.
Reference: [43] <author> D. L Swofford, G. J. Olsen, P. J. Waddell, D. M. Hillis, </author> <title> Chapter 11: Phylogenetic inference, in: Molecular Systematics, </title> <editor> D. M. Hillis, C. Moritz, B. K. Mable, eds., </editor> <booktitle> 2nd edition, </booktitle> <publisher> Sinauer Associates, Inc., </publisher> <address> Sunderland, </address> <year> (1996) </year> <month> 407-514. </month>
Reference-contexts: This work is quite preliminary, as it is clear that we will obtain much better results after fine-tuning the techniques to work with different phylogenetic methods. The reader interested in learning more about phylogenetic tree reconstruction methods should see <ref> [22, 43, 46] </ref> for a deeper introduction into the issues involved in phylogenetic analysis.
Reference: [44] <author> C. Tu*ey and M. A. Steel. </author> <title> Links between maximum likelihood and maximum parsimony under a simple model of site substitution. </title> <journal> Bulletin of Mathematical Biology, </journal> <month> 59(3) </month> <year> (1997) </year> <month> 581-607. </month>
Reference-contexts: Unfortunately, the inconsistency of maximum parsimony is not just a theoretical phenomenon, it occurs for real trees of biological interest as well. Research into the conditions under which maximum parsimony will be consistent has so far been inconclusive <ref> [21, 27, 30, 37, 44] </ref>. Nevertheless, maximum parsimony receives a great deal of support from systematic biologists.
Reference: [45] <author> T. Warnow, </author> <title> Tree Compatibility and Inferring Evolutionary History, </title> <journal> Journal of Algorithms, </journal> <note> 16 (1994) 388-407. (A preliminary version of this paper appeared at SODA 1993.) </note>
Reference-contexts: Although this is generally an NP-hard problem, it can be solved very efficiently when the number of bipartitions which must be eliminated is small, using our techniques from [7, 34] (this problem is related to the tree compatibility problem, studied in <ref> [26, 45] </ref>). Since our experimental results showed that for most settings for w, the trees T w had low false positive rates, these fast algorithms can be applied to obtain asymmetric median trees efficiently.
Reference: [46] <author> T. Warnow, </author> <title> Some combinatorial problems in Phylogenetics, </title> <booktitle> Invited to appear in the proceedings of the International Colloquium on Combinatorics and Graph Theory, </booktitle> <address> Balatonlelle, Hungary, </address> <month> July 15-20, </month> <year> 1996, </year> <editor> eds. A. Gyarfas, L. </editor> <title> Lovasz, L.A. </title> <journal> Szekely, in a forthcoming volume of Bolyai Society Mathematical Studies. </journal>
Reference-contexts: This work is quite preliminary, as it is clear that we will obtain much better results after fine-tuning the techniques to work with different phylogenetic methods. The reader interested in learning more about phylogenetic tree reconstruction methods should see <ref> [22, 43, 46] </ref> for a deeper introduction into the issues involved in phylogenetic analysis.
Reference: [47] <author> M.S. Waterman, T.F. Smith, </author> <title> and W.A. Beyer, Additive evolutionary trees, </title> <journal> Journal Theoretical Biol., </journal> <month> 64 </month> <year> (1977) </year> <month> 199-213. </month>
Reference-contexts: Given this additive distance matrix recovering the edge-weighted model tree can be done in polynomial time (there are many 4 such algorithms, the first of which is due to Waterman <ref> [47] </ref>). Indeed, given long enough finite length sequences, under such models even extremely simple techniques can recover the topology of the model tree with high probability [19].
Reference: [48] <author> M. Yannakakis, </author> <title> Computing the minimum fill-in is NP-complete, </title> <journal> SIAM J. Alg. Disc. Meth., </journal> <volume> 2, </volume> <year> (1981). </year>
Reference-contexts: Our experiments have indicated d w is often actually triangulated, and when it is not triangulated a few additional edges suffice to triangulate d w . Obtaining a minimal triangulation of a graph is in general NP-hard <ref> [48] </ref>, but for the graphs we will consider, even simple heuristics work effectively and efficiently. Furthermore, it was recently shown that exact solutions can be obtained efficiently when the number of additional edges needed is small [10, 29]. Lemma 3.2 (from [24]).
References-found: 47

