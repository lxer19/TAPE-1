URL: http://www.cs.brown.edu/research/graphics/research/pub/papers/vr93-hubbard.ps
Refering-URL: http://www.cs.wustl.edu/~pmh/research.html
Root-URL: 
Title: Interactive Collision Detection  
Author: Philip M. Hubbard 
Date: 1910,  
Address: Box  Providence, RI 02912  
Affiliation: Department of Computer Science  Brown University  
Abstract: Collision detection and response can make a virtual-reality application seem more believable. Unfortunately, existing collision-detection algorithms are too slow for interactive use. We present a new algorithm that is not only fast but also interruptible, allowing an application to trade quality for more speed. Our algorithm uses simple four-dimensional geometry to approximate motion, and sets of spheres to approximate three-dimensional surfaces. The algorithm allows a sample application to run 5 to 7 times faster than it runs with existing algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Baraff, D. and A. Witkin, </author> <title> "Dynamic Simulation of Non-Penetrating Flexible Bodies," </title> <booktitle> SIGGRAPH '92 Proceedings, Computer Graphics, </booktitle> <volume> Vol. 26, No. 2, </volume> <month> July </month> <year> 1992, </year> <pages> pp. 303-308. </pages>
Reference-contexts: The response algorithm corrects that behavior of the objects that would penetrate. Both parts of a collision-handling algorithm pose interesting problems, but we focus on detection algorithms. For a discussion of response algorithms, see the work of Baraff <ref> [1] </ref>. Despite the wealth of literature on detection algorithms, we have found no algorithms that adequately address the needs of interactive applications such as virtual reality. <p> set of all 4D faces into three subsets: F ff = ff j face f is normal to axis ffg; ff 2 fx; y; zg: These sets are important for the following reason: if two hyper-trapezoids T j and T k intersect for the first time at t i 2 <ref> [0; 1] </ref>, then there must be an intersection at t i between a face of T j in F ff and a face of T k in the same F ff , for some ff 2 fz; y; zg. The contra-positive of this assertion guides our intersection algorithm.
Reference: [2] <author> Cameron, S., </author> <title> "Collision Detection by Four Dimensional Intersection Testing," </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> Vol. 6, No. 3, </volume> <month> June </month> <year> 1990, </year> <pages> pp. 291-302. </pages>
Reference-contexts: Many authors describe solutions to these weaknesses. Few authors, however, address all three. Furthermore, the algorithms that most nearly solve all three impose restrictions on the agents, making these algorithms unsuitable for interactive applications. To eliminate the fixed-timestep weakness, many researchers use geometry with an explicit time dimension. Cameron <ref> [2] </ref> describes 4D bounds for agents modeled with Constructive Solid Geometry. Von Herzen et al. [16] use a Lipschitz condition to bound the space occupied by time-varying surfaces. Duff [5] couples octree-like subdivision with interval arithmetic. All of these techniques have limitations, however.
Reference: [3] <author> Cohen, M. F., S. E. Chen, J. R. Wallace and D. P. Greenberg, </author> <title> "A Progressive Refinement Approach to Fast Radiosity Image Generation," </title> <booktitle> SIGGRAPH '88 Proceedings, Computer Graphics, </booktitle> <volume> Vol. 22, No. 4, </volume> <month> August </month> <year> 1988, </year> <pages> pp. 75-84. </pages>
Reference-contexts: This approach gives the application program flexibility, allowing it to degrade the quality of detection whenever an increase in speed is important. Our approach is analogous to progressive refinement in rendering <ref> [3] </ref>. The success of this rendering technique suggests that our technique will prove valuable. Our algorithm is based on two forms of approximate geometry. The first is a four-dimensional (4D) structure we call a space-time bound.
Reference: [4] <author> Culley, R. K., and K. G. Kempf, </author> <title> "A Collision Detection Algorithm Based on Velocity and Distance Bounds," </title> <booktitle> Proceedings 1986 IEEE International Conference on Robotics and Automation, </booktitle> <volume> Vol. 2, </volume> <year> 1986., </year> <pages> pp. 1064-1069. </pages>
Reference-contexts: Only Von Herzen et al. and Duff consider motion involving acceleration. Most importantly, none of these techniques can handle motion that is not fully pre-specified. Thus, an interactive application cannot use any of these algorithms. Some researchers address the fixed-timestep weakness without assuming pre-specified motion. Culley and Kempf <ref> [4] </ref> show how to increase t when collisions cannot occur. Their technique cannot efficiently handle curved paths, nor does it eliminate the all-pairs weakness, but it inspired our work. Foisy et al. [6] use 4D structures somewhat similar to our space-time bounds to solve the fixed-timestep weakness.
Reference: [5] <author> Duff, T., </author> <title> "Interval Arithmetic and Recursive Subdivision for Implicit Functions and Constructive Solid Geometry," </title> <booktitle> SIGGRAPH '92 Proceedings, Computer Graphics, </booktitle> <volume> Vol. 26, No. 2, </volume> <month> July </month> <year> 1992, </year> <pages> pp. 131-138. </pages>
Reference-contexts: To eliminate the fixed-timestep weakness, many researchers use geometry with an explicit time dimension. Cameron [2] describes 4D bounds for agents modeled with Constructive Solid Geometry. Von Herzen et al. [16] use a Lipschitz condition to bound the space occupied by time-varying surfaces. Duff <ref> [5] </ref> couples octree-like subdivision with interval arithmetic. All of these techniques have limitations, however. Only Cameron and Duff address the all-pairs weakness. Only Von Herzen et al. and Duff consider motion involving acceleration. Most importantly, none of these techniques can handle motion that is not fully pre-specified.
Reference: [6] <author> Foisy, A., V. Hayward and S. Aubry, </author> <title> "The Use of Awareness in Collision Prediction," </title> <booktitle> Proceedings 1990 IEEE International Conference on Robotics and Automation, </booktitle> <volume> Vol. 1, </volume> <pages> pp. 338-343. </pages>
Reference-contexts: Some researchers address the fixed-timestep weakness without assuming pre-specified motion. Culley and Kempf [4] show how to increase t when collisions cannot occur. Their technique cannot efficiently handle curved paths, nor does it eliminate the all-pairs weakness, but it inspired our work. Foisy et al. <ref> [6] </ref> use 4D structures somewhat similar to our space-time bounds to solve the fixed-timestep weakness. Their approach will also remedy the all-pairs weakness in some|but not all|situations. Space subdivision is a popular way to mitigate the all-pairs weakness (although an (N 2 ) worst case still exists).
Reference: [7] <author> Goldsmith, J. and J. Salmon, </author> <title> "Automatic Creation of Object Hierarchies for Ray Tracing," </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> Vol. 7, No. 5, </volume> <month> May </month> <year> 1987, </year> <pages> pp. 14-19. </pages>
Reference-contexts: There is little relevant work in the literature. O'Rourke and Badler [9] cover a polyhedron by attaching spheres to its vertices. Their approach gives little control over the number of spheres in a set and produces redundant spheres. Goldsmith and Salmon <ref> [7] </ref> present an algorithm for improving bounding hierarchies for ray tracing. To build a sphere-tree, however, this algorithm must be given the lowest-level sphere set, so it is not a full solution. To remedy these problems, we developed our own approach.
Reference: [8] <author> Hubbard, P. M., </author> <title> "Space-Time Bounds for Collision Detection," </title> <type> Tech. Report CS-93-04, </type> <institution> Department of Computer Science, Brown University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: x (0), and a scalar M such that j x (t)j M; 0 t ^ t: From this upper bound we can conclude that jx (t) [x (0) + _ x (0)t]j 2 This assertion is related to Taylor's theorem; a proof is not difficult and we present it elsewhere <ref> [8] </ref>. The importance of Inequality 1 comes from its geometric interpretation. The inequality states that the position of A at time t will be within a distance (M=2)t 2 from the point x (0) + _ x (0)t. <p> It should be intuitively clear that this approach solves the fixed-timestep weakness. Section 6 presents the precise statement of this approach. The current section sketches how to compute t i while avoiding the all-pairs weakness; the details of this computation can be found elsewhere <ref> [8] </ref>. The main source of complexity in the intersection algorithm is the presence of cutting planes in space-time bounds. We simplify the algorithm by observing that an intersection between two hyper-trapezoid faces is a necessary condition for any sort of intersection between two space-time bounds. <p> This iteration is quite efficient, and is performed relatively rarely. The advance to t build + t may have allowed a pair of agents other than A 1 and A 2 to start penetrating; the pre-processing test detects these additional pairs, too. We discuss this subtle detail elsewhere <ref> [8] </ref>. 7 Sphere-trees Spheres are among the simplest geometric structures to check for penetration. If all agents were spheres, a pair-processing algorithm would be trivial. Few agents are closely approximated by a single sphere, but a set of partially-overlapping spheres can provide a more reasonable approximation. <p> The Unix clock routine measures the time each algorithm needed to find the first collision. We ran these tests on a DECstation 5000/200 PGX Turbo with 40Mb RAM. Although we tested various numbers of agents <ref> [8] </ref>, we present here only the results for 200 individual tests with 100 agents per test. Figure 6 graphs the speedup of our algorithm: the time spent by Turk's algorithm divided by the time spent by our algorithm.
Reference: [9] <author> O'Rourke, J. and N. Badler, </author> <title> "Decomposition of Three-Dimensional Objects into Spheres," </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 1, No. 3, </volume> <month> July </month> <year> 1979, </year> <pages> pp. 295-305. </pages>
Reference-contexts: Each lowest-level sphere also stores the part of the agent's surface it intersects, allowing the last step of the narrow phase (if reached) to detect penetration exactly. The problem remains of building the sphere-tree for each agent. There is little relevant work in the literature. O'Rourke and Badler <ref> [9] </ref> cover a polyhedron by attaching spheres to its vertices. Their approach gives little control over the number of spheres in a set and produces redundant spheres. Goldsmith and Salmon [7] present an algorithm for improving bounding hierarchies for ray tracing.
Reference: [10] <author> Preparata, F. P. and M. I. Shamos, </author> <title> Computational Geometry: An Introduction, </title> <publisher> Springer-Verlag (New York), </publisher> <year> 1985. </year>
Reference-contexts: The faces do actually intersect if their t = t i cross sections intersect. Since the two cross sections are isothetic squares with the same ff coordinate, checking for their intersection reduces to a simple two-dimensional problem. We use the Bentley-Ottmann algorithm <ref> [10] </ref> to find intersections between the 2D segments corresponding to F ff . This algorithm sweeps a line across the ff-t plane (from low t coordinates to high t coordinates), reporting every intersection it finds. <p> Whenever the algorithm finds two faces that intersect, it checks for intersections involving those faces and the cutting planes from their space-time bounds. The computation involves intersecting two 4D planes and determining when this intersection is inside the two hyper-trapezoids. The latter subproblem is a two-variable linear-programming problem <ref> [10] </ref>; since only a few constraints are involved, we solve this problem efficiently with straight-forward modifications to the Bentley-Ottmann algorithm. 6 Detecting collisions This section describes how our detection algorithm uses the results of Section 5.
Reference: [11] <author> Press, W. H., B. P. Flannery, S. A. Teukolsky and W. T. Vetterling, </author> <title> Numerical Recipes in C, </title> <publisher> Cambridge University Press (Cambridge), </publisher> <year> 1988. </year>
Reference-contexts: Notice that the resolution of the approximation doubles with each level. The sphere sets generated by an octree are not guaranteed to be optimal in any sense. Thus, we are exploring ways to tweak them with a simulated annealing algorithm <ref> [11] </ref>. The objective function measures the maximum distance from the agent's surface to the sphere set being tweaked. Note that this objective function also quantifies the accuracy provided by the detection algorithm. Even without tweaking, the sphere-trees we generate seem satisfactory in practice. <p> The graphs show that our algorithm was almost always faster than Turk's algorithm. The "overall" graph suggests that the ODE solver we used (a fourth-order Runge-Kutta method <ref> [11] </ref>) is a bottleneck; we anticipate that the "overall" speedups will be closer to the "detection-only" speedups if we use a faster ODE solver (e.g., a second-order Runge-Kutta method).
Reference: [12] <author> Sclaroff, S. and A. Pentland, </author> <title> "Generalized Implicit Functions for Computer Graphics," </title> <booktitle> SIGGRAPH '91 Proceedings, Computer Graphics, </booktitle> <volume> Vol. 25, No. 4, </volume> <month> July </month> <year> 1991, </year> <pages> pp. 247-250. </pages>
Reference-contexts: Turk's algorithm, in particular, is a viable approach because of its low overhead. We compare this algorithm to ours in Section 8. For pair processing, Thibault and Naylor [14] show how binary space partitioning (BSP) trees should accelerate polyhedral-penetration testing on the average. Sclaroff and Pentland <ref> [12] </ref> present an interesting pair-processing algorithm that approximates surfaces with deformed superquadrics.
Reference: [13] <author> Shaffer, C. A. and G. M. Herb, </author> <title> "A Real-Time Robot Arm Collision Avoidance System," </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> Vol. 8, No. 2, </volume> <month> April </month> <year> 1992, </year> <pages> pp. 149-160. </pages>
Reference-contexts: Their approach will also remedy the all-pairs weakness in some|but not all|situations. Space subdivision is a popular way to mitigate the all-pairs weakness (although an (N 2 ) worst case still exists). The algorithm of Shaffer and Herb <ref> [13] </ref> exemplifies the use of octrees by many researchers. Turk [15] presents a simpler technique that divides space uniformly. Although these algorithms do not address the fixed-timestep or pair-processing weaknesses, they are flexible enough to handle motion that is not fully pre-specified. <p> Hierarchical space-subdivision of this general form is common in computer graphics. A popular technique is the octree. Sphere-trees have advantages over oc-trees for collision detection, however. Detection algorithms that use octrees <ref> [13] </ref> must incur the cost of rebuilding their octrees or of moving agents between octants every time they call the pair-processing algorithm. A detection algorithm that uses sphere-trees, on the other hand, builds each agent's sphere-tree only once.
Reference: [14] <author> Thibault, W. C. and B. F. Naylor, </author> <title> "Set Operations on Polyhedra Using Binary Space Partitioning Trees," </title> <booktitle> SIGGRAPH '87 Proceedings, Computer Graphics, </booktitle> <volume> Vol. 21, No. 4, </volume> <month> July </month> <year> 1987, </year> <pages> pp. 153-162. </pages>
Reference-contexts: Turk's algorithm, in particular, is a viable approach because of its low overhead. We compare this algorithm to ours in Section 8. For pair processing, Thibault and Naylor <ref> [14] </ref> show how binary space partitioning (BSP) trees should accelerate polyhedral-penetration testing on the average. Sclaroff and Pentland [12] present an interesting pair-processing algorithm that approximates surfaces with deformed superquadrics. <p> We run this simulator on a Sun SPARCstation 10/30 GT with 32Mb RAM. The test of our narrow phase went as follows. We ran the simulator with our detection algorithm calling two pair-processing algorithms: our sphere-tree algorithm and an algorithm based on BSP trees <ref> [14] </ref>. The BSP algorithm gives exact rather than approximate results, so this test indicates what speed can be gained in return for degraded quality. Figure 8 gives the average speedup of the sphere-tree algorithm for one run of the simulator (which made 11,831 calls to each pair-processing algorithm).
Reference: [15] <author> Turk, G., </author> <title> "Interactive Collision Detection for Molecular Graphics," </title> <type> Tech. Report TR90-014, </type> <institution> Computer Science Department, The University of North Car-olina at Chapel Hill, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: Their approach will also remedy the all-pairs weakness in some|but not all|situations. Space subdivision is a popular way to mitigate the all-pairs weakness (although an (N 2 ) worst case still exists). The algorithm of Shaffer and Herb [13] exemplifies the use of octrees by many researchers. Turk <ref> [15] </ref> presents a simpler technique that divides space uniformly. Although these algorithms do not address the fixed-timestep or pair-processing weaknesses, they are flexible enough to handle motion that is not fully pre-specified. Turk's algorithm, in particular, is a viable approach because of its low overhead. <p> In general, building good sphere-trees remains an interesting research problem. 8 Performance We have evaluated the performance of our detection algorithm in several ways. First, we compared the broad phase to the broad phase of Turk's algorithm <ref> [15] </ref>. (Turk's algorithm needs no narrow phase since his application involves simple geometry.) The test program generates random configurations of iso-thetic cubes and applies forces to make them move.
Reference: [16] <author> Von Herzen, B., A. H. Barr and H. R. Zatz, </author> <title> "Geometric Collisions for Time-Dependent Parametric Surfaces," </title> <booktitle> SIGGRAPH '90 Proceedings, Computer Graphics, </booktitle> <volume> Vol. 24, No. 4, </volume> <month> August </month> <year> 1990, </year> <pages> pp. 39-48. </pages>
Reference-contexts: To eliminate the fixed-timestep weakness, many researchers use geometry with an explicit time dimension. Cameron [2] describes 4D bounds for agents modeled with Constructive Solid Geometry. Von Herzen et al. <ref> [16] </ref> use a Lipschitz condition to bound the space occupied by time-varying surfaces. Duff [5] couples octree-like subdivision with interval arithmetic. All of these techniques have limitations, however. Only Cameron and Duff address the all-pairs weakness. Only Von Herzen et al. and Duff consider motion involving acceleration.
References-found: 16

