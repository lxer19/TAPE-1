URL: ftp://ftp.cs.man.ac.uk/pub/ai/jls/aisb94.ps.Z
Refering-URL: http://www.cs.man.ac.uk/~magnus/magnus.html
Root-URL: http://www.cs.man.ac.uk
Title: A Statistical Mechanical Formulation of the Dynamics of Genetic Algorithms  
Author: Jonathan Shapiro, Adam Prugel-Bennett, and Magnus Rattray 
Address: Oxford Road Manchester M13 9PL  
Affiliation: Department of Computer Science, The University, Manchester  
Abstract: A statistical mechanical formulation of the dyamics of genetic algorithms is described. This formulation allows the derivation of equations which predict the distributions of fitness with the population at one generation in terms of the distribution at the previous generation. The effects of selection are problem independent, and the formulation predicts an optimal value of selection. Crossover and mutation are discussed in terms of a test problem search for the low energy states of a random spin chain. The theory is compared with simulations and the agreement is good. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J. H. Holland, </author> <title> Adaptation in Natural and Artificial Systems, </title> <institution> University of Michigan Press (Ann Arbor), </institution> <year> 1975. </year>
Reference-contexts: In order to optimize the performance of a GA, it is useful to understand its dynamics. A very general description of GA dynamics is given by the Schema picture of Holland <ref> [1] </ref>. Principles of GA design have been put forward by Goldberg [2] and made precise and extended to general representations by Radcliffe [3] based on this idea. However, this does not predict the dynamics of a particular genetic algorithm in detail.
Reference: 2. <author> D. E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning, </title> <publisher> Addison-Wesley (Reading, </publisher> <address> Mass), </address> <year> 1989. </year>
Reference-contexts: In order to optimize the performance of a GA, it is useful to understand its dynamics. A very general description of GA dynamics is given by the Schema picture of Holland [1]. Principles of GA design have been put forward by Goldberg <ref> [2] </ref> and made precise and extended to general representations by Radcliffe [3] based on this idea. However, this does not predict the dynamics of a particular genetic algorithm in detail. Alternatively, there are detailed mathematical formulations of genetic algorithms which do give a detailed description. <p> Thus we see for Boltzmann selection there is an optimal choice of the selection parameter, fi, and we can predict how it scales. Since the variance decreases as the population converges the degree of selection should be increased, as has already been observed <ref> [2] </ref>. 4 Crossover and Mutation 4.1 A Test Problem Crossover and mutation are problem specific. In order to study these, we must consider specific problems. Here we report studies of a GA which searches for low lying states of a one dimensional spin chain with random nearest-neighbor couplings.
Reference: 3. <author> N. J. Radcliffe, </author> <title> Equivalent Class Analysis of Genetic Algorithms, </title> <journal> Complex Systems 5, </journal> <month> 183 </month> <year> (1991). </year>
Reference-contexts: A very general description of GA dynamics is given by the Schema picture of Holland [1]. Principles of GA design have been put forward by Goldberg [2] and made precise and extended to general representations by Radcliffe <ref> [3] </ref> based on this idea. However, this does not predict the dynamics of a particular genetic algorithm in detail. Alternatively, there are detailed mathematical formulations of genetic algorithms which do give a detailed description.
Reference: 4. <author> M. D. Vose and G. E. Liepins, </author> <title> Punctuated Equilibria in Genetic Search, </title> <booktitle> Complex Systems 5, </booktitle> <pages> 31-44, </pages> <year> 1991. </year>
Reference-contexts: However, this does not predict the dynamics of a particular genetic algorithm in detail. Alternatively, there are detailed mathematical formulations of genetic algorithms which do give a detailed description. The two most developed are the Markov Chain formulation of Vose et. al. <ref> [4] </ref>, and the Walsh-function analysis introduced by Bethke [5] and much used by Goldberg and collaborators [6,7,8]. The former is a beautiful and exact theory of the evolution of a GA. It has been useful in revealing the types of dynamics which can occur (e.g. punctuated equilibria).
Reference: 5. <author> A. D. Bethke, </author> <title> Genetic Algorithms as Function Optimizers, </title> <type> Doctoral Dissertation, </type> <institution> University of Michigan, </institution> <year> 1981. </year>
Reference-contexts: Alternatively, there are detailed mathematical formulations of genetic algorithms which do give a detailed description. The two most developed are the Markov Chain formulation of Vose et. al. [4], and the Walsh-function analysis introduced by Bethke <ref> [5] </ref> and much used by Goldberg and collaborators [6,7,8]. The former is a beautiful and exact theory of the evolution of a GA. It has been useful in revealing the types of dynamics which can occur (e.g. punctuated equilibria).
Reference: 6. <author> D. E. Goldberg, </author> <title> Genetic Algorithms and Walsh Functions: Part I, a Gentle Introduction, </title> <journal> Complex Systems, </journal> <volume> 3, </volume> <pages> 129-152, </pages> <year> 1989. </year>
Reference: 7. <author> D. E. Goldberg, </author> <title> Genetic Algorithms and Walsh Functions: Part II, Deception and its Analysis, </title> <journal> Complex Systems, </journal> <volume> 3, </volume> <pages> 153-171, </pages> <year> 1989. </year>
Reference: 8. <author> D. E. Goldberg and M. Rudnick, </author> <title> Genetic Algorithms the Variance of Fitness, </title> <journal> Complex Systems, </journal> <volume> 5, </volume> <pages> 265-178, </pages> <year> 1991. </year>
Reference: 9. <author> M. Mezard, G. Parisi, and M. A. Virasoro, </author> <title> Spin Glass Theory and Beyond, </title> <publisher> World Scientific (Singapore) 1987. </publisher>
Reference-contexts: It is usually applied to the computation of thermodynamic properties of particles (e.g. molecules, electrons) interacting with a heat bath, but has also been applied recently to a host of other problems in coding theory, neural networks and optimization (for examples, see <ref> [9] </ref>). As an example, statistical mechanics was found to be useful in setting the parameters for simulated annealing [10]. Statistical Mechanics has been previously applied to the study of genetic dynamics (see for example [11]).
Reference: 10. <author> P. J. M. van Laarhoven and E. H. L. Aarts, </author> <title> Simulated Annealing: Theory and Applications, </title> <publisher> Kluwer Academic Press (Dordrecht) 1987. </publisher>
Reference-contexts: As an example, statistical mechanics was found to be useful in setting the parameters for simulated annealing <ref> [10] </ref>. Statistical Mechanics has been previously applied to the study of genetic dynamics (see for example [11]). However, these previous studies there was no notion of fitness; these were studies of genetic variability and converge through genetic drift.
Reference: 11. <author> C. </author> <title> Tsallis, Exactly Solvable Model for a Genetically Induced Geographical Distributions of a Population, </title> <journal> Physica A 194, </journal> <pages> 502-518, </pages> <year> 1993. </year>
Reference-contexts: As an example, statistical mechanics was found to be useful in setting the parameters for simulated annealing [10]. Statistical Mechanics has been previously applied to the study of genetic dynamics (see for example <ref> [11] </ref>). However, these previous studies there was no notion of fitness; these were studies of genetic variability and converge through genetic drift.
Reference: 12. <author> A. Prugel-Bennett and J.L. Shapiro, </author> <title> An Analysis of Genetic Algorithms Using Statistic Mechanics, </title> <journal> Phys. Rev. Lett., </journal> <volume> 72(9) p1305, </volume> <year> 1994. </year>
Reference-contexts: The formalism will be appropriate for studying very high-dimensional search spaces. It will allow the study of test problems which are complementary to the usual test-bed problems, namely one and two dimensional function optimization problems. We consider the evolution of the distribution of fitnesses within a population <ref> [12] </ref>. The goal is to predict the distribution of fitnesses at one timestep in terms of this distribution at the previous timestep. For example, suppose a GA is being used to find the minima of an objective function E. A typical evolution is shown in figure 1. <p> This arises because, by chance, some members of the population will not be selected while other members will be selected more than once. The effects of selection on higher cumulants can also be computed <ref> [12] </ref>. Selection introduces a skewness into the distribution which slows down the shift in the average energy and increases the rate of convergence.
Reference: 13. <author> M. Abramowitz and I.A. Segun, </author> <title> Handbook of Mathematical Functions, </title> <publisher> Dover Press, </publisher> <year> 1964. </year>
Reference-contexts: The 3 cumulant expansion is defined by the generating function which is given by the log of the Fourier transform of the distribution function <ref> [13] </ref> G (t) = log ( e itE ff E through the following equation for the n th cumulant n n = (i) n @ n Here &lt; &gt; denotes average over the distribution ae (E). (In statistical mechanics terminology, G (t) is the log of the partition function, and the
Reference: 14. <author> B. Derrida, </author> <title> Random-energy Model: An exactly Solvable Model of Disordered Sys--tems, </title> <journal> Phys. Rev. </journal> <volume> B24, </volume> <month> 2613 </month> <year> (1984). </year>
Reference-contexts: The solid lines are calculated by numerical integration. This is equivalent to a statistical mechanical model, the Random Energy Model, proposed by Derrida <ref> [14] </ref> as a model of spin-glasses, where fitness plays the role of energy. Using the methods which developed for this model, the cumulants after selection can be computed from those before. Details will be given elsewhere [12,14]. <p> It is a straight-forward calculation to find the distribution of energies after mutation. We will only describe the results here, refering the reading to the more detailed paper <ref> [14] </ref> for the calculation. Mutation changes the mean energy by a small amount proportional to 1 =N .
Reference: 15. <author> A. Prugel-Bennett and J.L. Shapiro, </author> <title> The Dynamics of Genetic Algorithms for the Ising Spin-Glass Chain, </title> <note> in preparation. </note>
Reference: 16. <author> T. Li, </author> <title> Phys. </title> <journal> Rev. </journal> <volume> B 24, </volume> <month> 6579 </month> <year> (1981). </year>
Reference: 17. <author> H. H. Chen and S. K. </author> <title> Ma, </title> <journal> J. Stat. Phys. </journal> <volume> 29, </volume> <month> 717 </month> <year> (1982). </year> <month> 9 </month>
References-found: 17

