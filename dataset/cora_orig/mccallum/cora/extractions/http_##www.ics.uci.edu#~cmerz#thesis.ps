URL: http://www.ics.uci.edu/~cmerz/thesis.ps
Refering-URL: http://www.aic.nrl.navy.mil/~aha/research/machine-learning.html
Root-URL: http://www.cs.cmu.edu/~jr6b
Title: Classification and Regression by Combining Models  
Author: Christopher J. Merz Professor Michael J. Pazzani, Chair Professor Padhraic Smyth Professor Dennis F. Kibler David H. Wolpert, Ph.D. 
Degree: DISSERTATION submitted in partial satisfaction of the requirements for the degree of DOCTOR OF PHILOSOPHY in Information and Computer Science by  Dissertation Committee:  
Date: 1998  
Affiliation: UNIVERSITY OF CALIFORNIA IRVINE  
Abstract-found: 0
Intro-found: 1
Reference: <author> Aha, D., Kibler, D., & Albert, M. </author> <year> (1991). </year> <title> Instance-based learning algorithms. </title> <journal> Machine Learning, </journal> <volume> 6 (1), </volume> <pages> 37-66. </pages>
Reference-contexts: Approaches in machine learning include decision trees ( Quinlan, 1986 ) , rule induction ( Clark & Niblett, 1989 ) , instance-based learning <ref> ( Aha, Kibler & Albert, 1991 ) </ref> , Bayesian classification ( Cheeseman & Stutz, 1995; Hanson, Stutz & Cheeseman, 1991 ) , and genetic algorithms ( Koza & Rice, 1991; Grefenstette, 1993a; Grefenstette, 1993b ) . <p> Approaches in machine learning include decision trees ( Quinlan, 1986 ) , rule induction ( Clark & 22 23 Niblett, 1989 ) , instance-based learning <ref> ( Aha, Kibler & Albert, 1991 ) </ref> , Bayesian classification ( Cheeseman & Stutz, 1995; Hanson, Stutz & Cheeseman, 1991 ) , and genetic algorithms ( Koza & Rice, 1991 ) . Each approach assumes a different set of possible search and representation strategies for ^ f .
Reference: <author> Ali, K. </author> <year> (1995). </year> <title> A comparison of methods for learning and combining evidence from multiple models. </title> <type> Technical Report UCI TR #95-47, </type> <institution> University of California, Irvine, Dept. of Information and Computer Sciences. </institution>
Reference-contexts: with homogeneous representations that differ in their method of search or in the data on which they are "trained." Examples of the heterogeneous approach are a set of decision trees built using various branch pruning techniques or splitting criteria; a set of decision lists where decision nodes are added stochastically <ref> ( Ali & Pazzani, 1995 ) </ref> ; or a set of neural networks whose weights are found using different gradient descent procedures or different initial weights ( Merz & Pazzani, 1996 ) . <p> They also use different search strategies (i.e., Bayesian classification ( Duda & Hart, 1973 ) , and nearest neighbor techniques). Fixing R and varying S In this approach, algorithms which have homogeneous representations but differ in their method of search are used. <ref> ( Ali & Pazzani, 1995 ) </ref> give an example of this generation scheme with decision lists (i.e., a list of rules) where conditions are added to a rule stochastically.
Reference: <author> Ali, K. </author> <year> (1996). </year> <title> Learning Probabilistic Relational Concept Descriptions. </title> <type> PhD thesis, </type> <institution> University of California, Irvine. </institution>
Reference: <author> Ali, K. & Pazzani, M. </author> <year> (1995). </year> <title> Learning multiple relational rule-based models. </title> <editor> In D. Fisher & H. Lenz (Eds.), </editor> <title> Learning from Data: </title> <journal> Artificial Intelligence and Statistics, </journal> <volume> Vol. </volume> <pages> 5. </pages> <address> Fort Lauderdale, FL: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: with homogeneous representations that differ in their method of search or in the data on which they are "trained." Examples of the heterogeneous approach are a set of decision trees built using various branch pruning techniques or splitting criteria; a set of decision lists where decision nodes are added stochastically <ref> ( Ali & Pazzani, 1995 ) </ref> ; or a set of neural networks whose weights are found using different gradient descent procedures or different initial weights ( Merz & Pazzani, 1996 ) . <p> They also use different search strategies (i.e., Bayesian classification ( Duda & Hart, 1973 ) , and nearest neighbor techniques). Fixing R and varying S In this approach, algorithms which have homogeneous representations but differ in their method of search are used. <ref> ( Ali & Pazzani, 1995 ) </ref> give an example of this generation scheme with decision lists (i.e., a list of rules) where conditions are added to a rule stochastically.
Reference: <author> Ali, K. & Pazzani, M. </author> <year> (1996). </year> <title> Error reduction through learning multiple descriptions. </title> <journal> Machine Learning, </journal> <volume> 24, </volume> <pages> 173. </pages>
Reference: <author> Battiti, R. & Colla, A. M. </author> <year> (1994). </year> <title> Democracy in neural nets: Voting schemes for classification. </title> <booktitle> Neural Networks, </booktitle> <volume> 7 (4), </volume> <pages> 691-707. </pages>
Reference: <author> Baxt, W. </author> <year> (1992). </year> <title> Improving the accuracy of an artificial neural network using multiple differently trained networks. </title> <journal> Neural Computation, </journal> <volume> 4 (5), </volume> <pages> 772-780. </pages>
Reference-contexts: When building each model in this approach, a different portion of the data set is withheld. Some methods use completely different training data partitions ( Meir, 1995; Krogh & Vedelsby, 1995; Chan & Stolfo, 1995; Wolpert, 1993 ) . Another data-partitioning approach was given in <ref> ( Baxt, 1992 ) </ref> where two different neural networks were trained each on data from a different class. The idea here was to produce networks which specialized on different types of examples developing a specific area of expertise.
Reference: <author> Breiman, L. </author> <year> (1994). </year> <title> Heuristics of instability in model selection. </title> <type> Technical report, </type> <institution> Department of Statistics, University of California at Berkeley. </institution>
Reference-contexts: A combining scheme should be "stable" by being insensitive to small changes in the prediction patterns of the learned models. Unstable combining schemes are likely to have a larger gap between the optimal combining scheme and the selected combining scheme. This difference is known as predictive loss <ref> ( Breiman, 1994 ) </ref> . A byproduct of the empirical investigation is the evidence that existing combining methods fail to satisfy one or more of the above mentioned criteria. <p> Each model is generated using the same algorithm, but different training data. The data for a particular model is obtained by sampling from the original training examples according to a probability distribution. The probability distribution is defined by the particular approach, "bagging" or "boosting." Bagging <ref> ( Breiman, 1994 ) </ref> is a method for exploiting the variance of a learning algorithm by applying it to various version of the data set, and averaging them (uniformly) for an overall reduction in variance, or prediction error. <p> The consistent results across multiple runs demonstrates how SCANN satisfies the item D4 in the desiderata: the ff-coefficients derived should have little variation with minor changes in F . This is echoed in Section 6.6.4 by the fact that the nearest neighbor algorithm is known to be stable <ref> ( Breiman, 1994 ) </ref> . The following experiment will demonstrate how SCANN handles items D2 and D3 in the desiderata. 128 `3' correspond to the members of ff c 1 , ff c 2 , and ff c 3 , respectively. <p> Two other methods for assigning fixed weights to each model are "bagging" <ref> ( Breiman, 1994 ) </ref> and "boosting" ( Schapire, 1990 ) . These methods are tightly coupled to the model generation phase rather than being general combining techniques. <p> In this case, model sets should only be generated using learning algorithms which are likely to produce different models with minor variations in the learning data. An algorithm's sensitivity to changes in the learning data is known as its stability <ref> ( Breiman, 1994 ) </ref> . Resampling techniques The most common methods for generating homogeneous model sets are based on repeated sampling of L 0 . Breiman ( 1996a ) gives one example of this called "bootstrap aggregating", or "bagging".
Reference: <author> Breiman, L. </author> <year> (1996a). </year> <title> Bagging predictors. </title> <journal> Machine Learning, </journal> <volume> 24 (2), </volume> <pages> 123-40. </pages>
Reference-contexts: More advanced techniques adjust the search bias so as to build accurate models 5 that make uncorrelated errors ( Opitz & Shavlik, 1996; Maclin & Shavlik, 1995 ) . Methods that combine homogeneous models which are trained on differing data samples include "bagging" <ref> ( Breiman, 1996a ) </ref> and "boosting" ( Schapire, 1990; Freund & Schapire, 1996 ) . Once a diverse set of models has been generated, the issue of how to combine them arises. Wolpert ( 1992 ) provided a general framework for doing so called stacked generalization or stacking. <p> The L 1 data was generated using the in-sample/out-of-sample approach described in Section 3.4.1. Level-1 induction occurred in PCR* using least square regression, and in SCANN using a nearest neighbor strategy. Another illustration of this framework is known as "bagging" <ref> ( Breiman, 1996a ) </ref> . The Level-0 induction process is to take a single algorithm and feed it N random samples drawn with replacement from L 0 . F consists of one learned model for each sample.
Reference: <author> Breiman, L. </author> <year> (1996b). </year> <title> Stacked regressions. </title> <journal> Machine Learning, </journal> <volume> 24 (1), </volume> <pages> 49-64. </pages>
Reference-contexts: Return L 1 This method of generating L 1 (also discussed in <ref> ( Breiman, 1996b ) </ref> is indicated by the dashed line in Figure 3.6 where the data generator also accesses the various learning methods to do the in-sample/out-of-sample processing. <p> Stacking with a collection of distinct level-0 learning algorithms ( Merz, 1995 ) is an example of the heterogeneous approach. A set of learned models generated from samples of the learning data (i.e., "bagging", <ref> ( Breiman, 1996b ) </ref> ) is an example of 4 For this particular error decomposition, it is assumed that the weights, ff i , sum to one. 49 a homogeneous set. Both types of model sets are used in the research described later. <p> The ff-coefficients are then derived as they are in PCR*. The end result is a more restricted set of coefficients. An iterative approach is used to search for (as discussed in ( Montgomery & Friedman, 1993 ) ). The Stacked Constrained Regression (SCR) procedure <ref> ( Breiman, 1996b ) </ref> is another method for combining regression estimates. The two main components of this approach are stacking and constrained regression. Stacking ( Wolpert, 1992 ) is simply a method of approximating the matrix of predictions, A F (see Section 3.4.1). <p> The collection of data sets with new representations are given to the learning algorithm to generate ^ f i (x). Another method of this kind is given by <ref> ( Breiman, 1996b ) </ref> . Here, subsets of the original variables were used to generate a collection of linear regression models.
Reference: <author> Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <booktitle> Wadsworth International Group. </booktitle> <volume> 195 196 Brodley, </volume> <editor> C. E. </editor> <year> (1995). </year> <title> Recursive automatic bias selection for classifier construction. </title> <journal> Machine Learning, </journal> <volume> 20, </volume> <pages> 63. </pages>
Reference: <author> Cesa-Bianchi, N., Freund, Y., Helmbold, D., & Haussler, D. </author> <year> (1993). </year> <title> How to use expert advice. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> (pp. 382-391). </pages> <note> Morgan Kaufmann. to appear in Journal of the Association for Computing Machinery, Schapire and Warmuth also on this article but too long. </note>
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1995). </year> <title> A comparative evaluation of voting and meta-learning on partitioned data. </title> <booktitle> In Proceedings of the 12th International Conference on Machine Learning, </booktitle> <pages> (pp. 90-98). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1996a). </year> <title> Scaling learning by meta-learning over disjoint and partially replicated data. </title> <booktitle> In Proceedings of the Ninth Florida Artificial Intelligence Research Symposium, </booktitle> <pages> (pp. 151-155). </pages>
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1996b). </year> <title> Sharing learned models among remote database partitions by local meta-learning. </title> <booktitle> In Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> (pp. 2-7). </pages> <publisher> The AAAI Press, </publisher> <address> Menlo Park. </address>
Reference-contexts: Chan and Stolfo ( 1995 ) present a method for scaling up ensemble methods when available data exceeds the size of main memory. Partitioning methods are also applicable in situations where learned models are developed in a distributed database environment <ref> ( Chan & Stolfo, 1996b ) </ref> , and it is not feasible for every algorithm to see the same training data. The mixture-of-experts approach may be viewed as a general purpose supervised learning algorithm, or an ensemble method which is tightly coupled with the model generation process.
Reference: <author> Chan, P. & Stolfo, S. </author> <year> (1997). </year> <title> On the accuracy of meta-learning for scalable data mining. </title> <journal> Journal Intelligent Information Systems, </journal> <volume> 8 (1), </volume> <pages> 5-28. </pages>
Reference: <author> Cheeseman, P. & Stutz, J. </author> <year> (1995). </year> <title> Bayesian classification (AUTOCLASS): Theory and results. </title> <editor> In U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, & R. Uthurusamy (Eds.), </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> The AAAI Press, </publisher> <address> Menlo Park. </address>
Reference: <author> Clark, P. & Niblett, T. </author> <year> (1989). </year> <title> The CN2 induction algorithm. </title> <journal> Machine Learning, </journal> <volume> 3 (4), </volume> <pages> 261-283. </pages>
Reference-contexts: The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) . Approaches in machine learning include decision trees ( Quinlan, 1986 ) , rule induction <ref> ( Clark & Niblett, 1989 ) </ref> , instance-based learning ( Aha, Kibler & Albert, 1991 ) , Bayesian classification ( Cheeseman & Stutz, 1995; Hanson, Stutz & Cheeseman, 1991 ) , and genetic algorithms ( Koza & Rice, 1991; Grefenstette, 1993a; Grefenstette, 1993b ) . <p> The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) . Approaches in machine learning include decision trees ( Quinlan, 1986 ) , rule induction <ref> ( Clark & 22 23 Niblett, 1989 ) </ref> , instance-based learning ( Aha, Kibler & Albert, 1991 ) , Bayesian classification ( Cheeseman & Stutz, 1995; Hanson, Stutz & Cheeseman, 1991 ) , and genetic algorithms ( Koza & Rice, 1991 ) . <p> The main difference between the two approaches is that C4.5 splits on a single attribute at a time while OC1 allows splits based on linear combinations of the attributes. Rule Induction In rule induction <ref> ( Clark & Niblett, 1989 ) </ref> , a set of "IF . . . THEN . . . " rules are generated. The "IF" portion is called the antecedent which a logical relation of the input attributes. The logical relation is usually a conjunction of attribute tests. <p> When classifying an example, the rules are typically applied in the order they were derived. If no rule antecedent is true, then a "default" rule is applied. Normally, this is the most frequent class observed in the training data. The rule induction algorithm used in this research is CN2 <ref> ( Clark & Niblett, 1989 ) </ref> . Instance-based Learning An instance-based learning algorithm stores a series of training instances in its memory and uses a distance metric to compare new instances to those stored. <p> A preliminary experiment was conducted for each data set (using only the training data) to determine the number of hidden units. Twenty percent of the training data were set aside as a validation set for determining when to stop training. The CN2 algorithm <ref> ( Clark & Niblett, 1989 ) </ref> was used to generate rule lists. Clark and Niblett's version 6.1 was used with the default parameters. Decision trees were generated using C4.5 ( Quinlan, 1993 ) , OC1 ( Murthy, Kasif, Salzberg & Beigel, 1993 ) .
Reference: <author> Cleeremans, A., Servan-Schreiber, D., & McClelland, J. </author> <year> (1989). </year> <title> Finite state automata and simple recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 1 (3), </volume> <pages> 372-381. </pages>
Reference-contexts: The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks <ref> ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) </ref> . <p> The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks <ref> ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) </ref> .
Reference: <author> Clemen, R. </author> <year> (1989). </year> <title> Combining forecast: A review and annotated bibliography. </title> <journal> International Journal on Forecasting, </journal> <volume> 5, </volume> <pages> 559-583. </pages> <note> 197 Comon, </note> <author> P. </author> <year> (1994). </year> <title> Independent component analysis, a new concept? Signal Processing, </title> <booktitle> 36, </booktitle> <pages> 287-314. </pages>
Reference: <author> Cost, S. & Salzberg, S. </author> <year> (1993). </year> <title> A weighted nearest neighbor algorithm for learning with symbolic features. </title> <journal> Machine Learning, </journal> <volume> 10 (1), </volume> <pages> 57-78. </pages>
Reference-contexts: Nominal attributes pose a problem because no order is imposed on their attribute values. Several Value Distance Metrics (VDM) have been developed to alleviate this problem. One example of this is the Modified Value Distance Metric (MVDM) of the PEBLS algorithm <ref> ( Cost & Salzberg, 1993 ) </ref> which calculates real-valued distances between instances with categorical attributes as follows: (x 1 ; x 2 ) = i=1 where ffi (x 1;i ; x 2;i ) = c=1 P (cjx v;i ) is the probability that value v was classified into category c. <p> Decision trees were generated using C4.5 ( Quinlan, 1993 ) , OC1 ( Murthy, Kasif, Salzberg & Beigel, 1993 ) . The default parameters were used for both algorithms. A second version of OC1 was run allowing only axis-parallel splits. Two nearest neighbor approaches were used: PEBLS <ref> ( Cost & Salzberg, 1993 ) </ref> and first nearest neighbor (1-NN). For PEBLS, numeric attributes were discretized into ten bins spanning the range of possible values. 145 A naive Bayesian classifier ( Duda & Hart, 1973 ) was also used.
Reference: <author> Dietterich, T. </author> <year> (1997). </year> <journal> Machine-learning research. AI Magazine, </journal> <volume> 18 (4), </volume> <pages> 97-136. </pages>
Reference-contexts: Model ^ f i (1 i 10) was set equal to f for each example with a 10% chance of being wrong, in which case one of the incorrect classes was selected at random. The examples were randomly divided into a training (2/3) and test (1/3) partition. Kappa-Error diagrams <ref> ( Margineantu & Dietterich, 1997 ) </ref> were used to visualize the differences between the models (see Figure 6.5). <p> This is due partly to the rapid, concurrent development of new approaches, and partly because not all techniques are applicable to the same types of model sets. Boosting appears to be the most effective method for generating a diverse model set <ref> ( Margineantu & Dietterich, 1997 ) </ref> . This is accomplished by continually refocusing on the parts of the examples space that the previously generated model found challenging.
Reference: <author> Dietterich, T. G. </author> <year> (1996). </year> <title> Statistical tests for comparing supervised classification learning algorithms. </title> <type> Technical report, </type> <institution> Dept. of Computer Science, Oregeon Statue University, Corvallis, </institution> <address> OR. </address>
Reference: <author> Dietterich, T. G., Kearns, M., & Mansour, Y. </author> <year> (1996). </year> <title> Applying the weak learning framework to understand and improve C4.5. </title> <booktitle> In Proceedings of the 13th International Conference on Machine Learning, </booktitle> <pages> (pp. 96-104). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Dongarra, J. & Grosse, E. </author> <year> (1998). </year> <note> Netlib repository. http://www.netlib.org/. </note>
Reference-contexts: Therefore, for larger data sets, only the right singular vectors need to be computed, thus reducing this stage to O ((N jY j) 3 ) time. The SVD package used in this research <ref> ( Dongarra & Grosse, 1998 ) </ref> allowed the user to specify which singular vectors were to be computed. 3. Nearest Neighbor.
Reference: <author> Draper, N. & Smith, H. </author> <year> (1981). </year> <title> Applied Regression Analysis. </title> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: Research in the areas of machine learning, neural networks and statistics has allowed learned models to take on a variety of forms. Statistical modeling approaches include linear least squares regression <ref> ( Draper & Smith, 1981 ) </ref> , splines ( Wahba, 1990; Friedman, 1991 ) , general additive models ( Hastie & Tibshirani, 1990 ) , and linear discriminant analysis ( MacLachlan, 1992 ) . <p> Research in the areas of machine learning, neural networks and statistics has allowed ^ f to take on a variety of forms. Statistical modeling approaches include linear least squares regression <ref> ( Draper & Smith, 1981 ) </ref> , splines ( Wahba, 1990; Friedman, 1991 ) , general additive models ( Hastie & Tibshirani, 1990 ) , and linear discriminant analysis ( MacLachlan, 1992 ) . <p> X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X OO inputs weights. 3.2.3 Statistical Methods Linear Least Squares Regression Methods Linear least squares regression <ref> ( Draper & Smith, 1981 ) </ref> attempts to assign weights to the input attributes so as to minimize the quadratic loss function (MSE). <p> Section 4.5 provides analytical explanation of how PCR* meets the guidelines defined above. An empirical evaluation of PCR* is given in Chapter 5. 4.3 Representation and Regression "PCR*" is named partly for the modeling method at its core, "Principal Components Regression" (see <ref> ( Draper & Smith, 1981 ) </ref> for a summary). This section discusses the central role PCR plays in representation and regression in PCR*. The asterisk in PCR* denotes the search associated with the representation and is discussed in Section 4.4. <p> The discussion now turns to methods capable to handling the multicollinearity problem without discarding any of the original models. Two statistical methods designed to handle multicollinearity are ridge regression and principal components regression <ref> ( Draper & Smith, 1981 ) </ref> . With minor adjustments, they can be applied to this problem. 4 Note that the constraint, P N i=1 ff i = 1, for GEM is a form of regularization ( Leblanc & Tibshirani, 1993 ) . <p> An evaluation of this approach (see Chapter 5 and ( Merz & Pazzani, 1997 ) ) revealed that it was not robust across a variety of domains. In Chapter 4, a framework was developed for applying principal components regression (PCR, see <ref> ( Draper & Smith, 1981 ) </ref> ). A summary of the process, called PCR*, is to: 1. Map the matrix of the learned models' predictions on the training examples to their principal components (as in ridge regression). 2.
Reference: <author> Drucker, H. & Cortes, C. </author> <year> (1996). </year> <title> Boosting decision trees. </title> <editor> In Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> (pp. 479-485). </pages> <publisher> The MIT Press. </publisher>
Reference: <author> Drucker, H., Cortes, C., Jackel, L. D., LeCun, Y., & Vapnik, V. </author> <year> (1994). </year> <title> Boosting and other ensemble methods. </title> <journal> Neural Computation, </journal> <volume> 6 (6), </volume> <pages> 1289-1301. </pages>
Reference: <author> Drucker, H., Cortes, C., Jackel, L. D., LeCun, Y., & Vapnik, V. </author> <year> (1994). </year> <title> Boosting and other machine learning algorithms. </title> <booktitle> In Proc. 11th International Conference on Machine Learning, </booktitle> <pages> (pp. 53-61). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Drucker, H., Schapire, R., & Simard, P. </author> <year> (1993a). </year> <title> Boosting performance in neural networks. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 7 (4), </volume> <pages> 705-719. </pages>
Reference: <author> Drucker, H., Schapire, R., & Simard, P. </author> <year> (1993b). </year> <title> Improving performance in neural networks using a boosting algorithm. </title> <editor> In Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5, </volume> <pages> (pp. 42-49). </pages> <note> Morgan Kaufmann. 198 Duda, </note> <author> R. & Hart, P. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> Addison-Wesley. </publisher>
Reference-contexts: To briefly summarize the experimental evaluation of these heuristics, the majority vote scheme outperformed the unison scheme, and the schemes based on probability distributions performed better than those based solely on class labels. Another study which also found that combining probabilities was more effective than combining class labels was <ref> ( Drucker, Schapire & Simard, 1993b ) </ref> . Ho et al. ( 1994 ) discuss several methods for combining class rankings. The simplest way to combine the rankings is to choose the class with the highest overall rank.
Reference: <author> Efron, B. </author> <year> (1979). </year> <journal> Computers and the theory of statistics: thinking the unthinkable. SIAM Review, </journal> <volume> 21, </volume> <pages> 460-480. </pages>
Reference: <author> Efron, B. & Tibshirani, R. </author> <year> (1993). </year> <title> An Introduction to the Bootstrap. </title> <address> London and New York: </address> <publisher> Chapman and Hall. </publisher>
Reference: <author> Fayyad, U. M., Weir, N., & Djorgovski, S. </author> <year> (1993). </year> <title> Automated cataloging and analysis of sky survey image databases: The SKICAT system. </title> <editor> In Bhargava, B., Finin, T., & Yesha, Y. (Eds.), </editor> <booktitle> Proceedings of the 2nd International Conference on Information and Knowledge Management, </booktitle> <pages> (pp. 527-536)., </pages> <address> New York, NY, USA. </address> <publisher> ACM Press. </publisher>
Reference-contexts: At NASA's Jet Propulsion Laboratory (JPL), inductive learning algorithms have been used to sift through large volumes of astronomical data. New red shift quasars have been discovered by the SKICAT project <ref> ( Fayyad, Weir & Djorgovski, 1993 ) </ref> . In the realm of prediction, inductive learning has greatly expedited the "knowledge acquisition bottleneck" problem: the process of taking observations about objects and converting it into a useful knowledge base to be used in an expert system.
Reference: <author> Fisher, R. A. </author> <year> (1936). </year> <title> The use of multiple measurements in taxonomic problems. </title> <journal> Annal of Eugenics, </journal> <volume> 7, </volume> <pages> 179-188. </pages>
Reference: <author> Freund, Y. </author> <year> (1995). </year> <title> Boosting a weak learning algorithm by majority. </title> <journal> Information and Computation, </journal> <volume> 121 (2), </volume> <pages> 256-285. </pages> <note> Also appeared in COLT90. </note>
Reference-contexts: Another error-based method for selecting the combining weights comes from the "boosting" literature (previously discussed in Section 8.3.2). A common combining strategy for boosting is the AdaBoost.M1 algorithm described in <ref> ( Freund & Schapire, 1995 ) </ref> . The i-th model's vote for a given class is a function of its error, * i , i.e., (1 * i ) In this scheme, learned models which make fewer errors (on the distribution of examples they see) tend to get higher weights.
Reference: <author> Freund, Y. & Schapire, R. E. </author> <year> (1995). </year> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <booktitle> In Proceedings of the Second European Conference on Computational Learning Theory, </booktitle> <pages> (pp. 23-37). </pages> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Another error-based method for selecting the combining weights comes from the "boosting" literature (previously discussed in Section 8.3.2). A common combining strategy for boosting is the AdaBoost.M1 algorithm described in <ref> ( Freund & Schapire, 1995 ) </ref> . The i-th model's vote for a given class is a function of its error, * i , i.e., (1 * i ) In this scheme, learned models which make fewer errors (on the distribution of examples they see) tend to get higher weights.
Reference: <author> Freund, Y. & Schapire, R. E. </author> <year> (1996). </year> <title> Experiments with a new boosting algorithm. </title> <booktitle> In Proceedings of the 13th International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Another avenue of further analysis is to explore and exploit SCANN's ability to combine any model set. In particular, it would be interesting to see how well SCANN combines a set of models derived using boosting <ref> ( Freund & Schapire, 1996 ) </ref> . Instead of using the single weight per model combining strategy of boosting, SCANN would provide a more dynamic combining scheme with one weight per class per model.
Reference: <author> Freund, Y., Seung, H. S., Shamir, E., & Tishby, N. </author> <year> (1993). </year> <title> Information, prediction, and query by committee. </title> <editor> In Hanson, S. J., Cowan, J. D., & Giles, C. L. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 5, </volume> <pages> (pp. 483-490). </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Friedman, J. H. </author> <year> (1991). </year> <title> Multivariate adaptive regression splines. </title> <journal> Annal of Statistics, </journal> <volume> 19, </volume> <pages> 1-141. </pages>
Reference-contexts: More elaborate Bayesian classification algorithms have been developed ( Pazzani, 1995; Cheeseman & Stutz, 1995; Hanson, Stutz & Cheeseman, 1991 ) , but only the naive Bayesian classifier is used for modeling in this work. Multivariate Adaptive Regression Splines Multivariate Adaptive Regression Splines <ref> ( Friedman, 1991 ) </ref> (MARS) is a flexible regression modeling technique for high dimensional data. It has the capability of modeling relationships between the input variables that are nearly additive or involve interactions (i.e., a product) of at most a few variables. <p> UCI-MC hansch 111 13 0 QSAR housing 506 12 12 UCI imports 160 15 15 UCI servo 167 4 0 UCI 5.3 Constituent Learners The set of learned models, F , were generated using Backpropagation networks (BP) ( Rumelhart, Hinton & Williams, 1986 ) and Multivariate Adaptive Regression Splines (MARS) <ref> ( Friedman, 1991 ) </ref> . <p> As noted in Section 4.6.1, the SCR strategy is computationally expensive, so a small number of models were used here to make the evaluation of SCR more tractable. 87 Twelve models were generated. Six were generated using MARS (version 3.5) <ref> ( Friedman, 1991 ) </ref> . In the first three models, the variables were entered in an unrestricted, restricted, and linear fashion, respectively.
Reference: <author> Friedman, J. H. </author> <year> (1996). </year> <title> On bias, variance, &lt; loss, and the curse of dimensionality. </title> <type> Technical report, </type> <institution> Department of Statistics, Stanford University. </institution> <note> 199 Geman, </note> <author> S., Bienenstock, E., & Doursat, R. </author> <year> (1992). </year> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4 (1), </volume> <pages> 1-58. </pages>
Reference: <author> Ghosh, J., Tumer, K., Beck, S., & Deuser, L. </author> <year> (1995). </year> <title> Integration of neural classifiers for passive sonar signals. </title> <editor> In C. T. Leondes (Ed.), </editor> <booktitle> In Digital Signal Processing Techniques and Applications. </booktitle> <publisher> Academic Press. </publisher>
Reference: <author> Greenacre, M. J. </author> <year> (1984). </year> <title> Theory and Application of Correspondence Analysis. </title> <publisher> London: Academic Press. </publisher>
Reference-contexts: Singular Value Decomposition (SVD) is a data summarization technique used at the heart of several common modeling techniques: Principal Components Analysis (PCA) ( Jolliffe, 1986 ) , Correspondence Analysis (CA) <ref> ( Greenacre, 1984 ) </ref> , and Linear Discriminant Analysis (LDA). <p> Eye color Hair color BLACK BROWN RED BLOND Brown 68 119 26 7 Blue 20 84 17 94 Hazel 15 54 14 10 Green 5 29 14 16 3.3.2 Correspondence Analysis Correspondence Analysis (CA) <ref> ( Greenacre, 1984 ) </ref> is a method for geometrically exploring the relationship between two categorical variables, v 1 and v 2 . <p> Chapter 6 The SCANN Algorithm 6.1 Overview This chapter presents SCANN, a method for combining classifiers. The problem of combining classifiers is defined and a desiderata for combining classifiers is given. The SCANN algorithm is presented in two parts. First, the intermediate representation based on Correspondence Analysis <ref> ( Greenacre, 1984 ) </ref> is described, and the process of classifying an example is specified. Then, a procedure is defined for searching through the representation space to find a final model with low prediction error. <p> Section 6.6 provides analytical explanation of how SCANN meets the desiderata defined above. An empirical evaluation of SCANN is given in Chapter 7. 107 6.3 Representation and Classification The representation used in SCANN is based upon the variates derived using correspondence analysis <ref> ( Greenacre, 1984 ) </ref> . Sections 6.3.1 and 6.3.2 show how stacking and CA are used to generate the new representation. A nearest neighbor strategy is then used to locate and classify test examples using the new representation (Section 6.3.3). <p> Return L 1 . 109 6.3.2 Correspondence Analysis Correspondence Analysis (CA) <ref> ( Greenacre, 1984 ) </ref> is a method for geometrically exploring the relationship between the rows and columns of a matrix whose entries are categorical. The goal here is to explore the relationship between the training examples and how they are classified by the learned models.
Reference: <author> Grefenstette, J. </author> <year> (1993a). </year> <title> Genetic algorithms. </title> <journal> IEEE Expert, </journal> <volume> 8 (5), </volume> <pages> 5-8. </pages>
Reference: <editor> Grefenstette, J. </editor> <booktitle> (1993b). Genetic algorithms and machine learning. In Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, </booktitle> <pages> (pp. 3-4). </pages> <publisher> ACM. </publisher>
Reference: <author> Hansen, L. K. & Salamon, P. </author> <year> (1990). </year> <title> Neural network ensembles. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-12 (10), </volume> <pages> 993-1001. </pages>
Reference: <author> Hanson, R., Stutz, J., & Cheeseman, P. </author> <year> (1991). </year> <title> Bayesian classification theory. </title> <type> Technical report, </type> <institution> NASA Ames TR FIA-90-12-7-01. </institution>
Reference: <author> Hashem, S. & Schmeiser, B. </author> <year> (1995). </year> <title> Improving model accuracy using optimal linear combinations of trained neural networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 6 (3), </volume> <pages> 792-794. </pages>
Reference: <author> Hastie, T. & Tibshirani, R. </author> <year> (1990). </year> <title> Generalized Additive Models. </title> <publisher> Chapman and Hall. </publisher>
Reference-contexts: Research in the areas of machine learning, neural networks and statistics has allowed learned models to take on a variety of forms. Statistical modeling approaches include linear least squares regression ( Draper & Smith, 1981 ) , splines ( Wahba, 1990; Friedman, 1991 ) , general additive models <ref> ( Hastie & Tibshirani, 1990 ) </ref> , and linear discriminant analysis ( MacLachlan, 1992 ) . The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) . <p> Research in the areas of machine learning, neural networks and statistics has allowed ^ f to take on a variety of forms. Statistical modeling approaches include linear least squares regression ( Draper & Smith, 1981 ) , splines ( Wahba, 1990; Friedman, 1991 ) , general additive models <ref> ( Hastie & Tibshirani, 1990 ) </ref> , and linear discriminant analysis ( MacLachlan, 1992 ) . The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) .
Reference: <author> Ho, K., Hull, J. J., & Srihari, S. N. </author> <year> (1994). </year> <title> Decision combination in multiple classifier systems. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-16 (1), </volume> <pages> 66-75. </pages>
Reference-contexts: Classification problems where there are many possible class labels and "near misses" are well suited for classifiers that use this reporting scheme. In this case, combining strategies which use class rankings are likely to be more robust <ref> ( Ho, Hull & Srihari, 1994 ) </ref> . <p> The latter selection step may be altered to be a combination (rather than a single selection) of the learned models within the region. In general, the partitions are derived from a set of mutually exclusive test conditions which divide up the input space. The partitions in <ref> ( Ho, Hull & Srihari, 1994 ) </ref> are derived from the level of agreement between the classifiers. A stricter set of test conditions are used in ( Merz, 1995 ) , where the partitions are identified by the precise voting pattern of the collection of classifiers. <p> The inclusion of probabilistic models may lead to a more robust combining scheme, e.g., class probabilities more accurately reflect the confidence a learned model has in its predictions. Applying SCANN to model sets that report class rankings may also be fruitful for tasks such character recognition <ref> ( Ho, Hull & Srihari, 1994 ) </ref> and information retrieval. 9.3 Summary Induction plays a central role in machine learning. Creating accurate classifiers and regressors from a set of examples is extremely important for tasks ranging from information retrieval to classifying astronomical data.
Reference: <author> Jackson, D. </author> <year> (1993). </year> <title> Stopping rules in principal components analysis: A comparison of heuristical and statistical approaches. </title> <journal> Ecology, </journal> <volume> 74 (8), </volume> <pages> 2204-2214. </pages>
Reference-contexts: The methods are commonly used methods described by <ref> ( Jackson, 1993 ) </ref> : * Kaiser-Guttman: This commonly used stopping rule is based on the average value of the eigenvalues. Only those components with eigenvalues ex ceeding the average are retained. * Scree Test: This rule is based on a plot of the eigenvalues.
Reference: <author> Jacobs, R. A. </author> <year> (1995). </year> <title> Methods for combining experts' porbability assesments. </title> <journal> Neural Computation, </journal> <volume> 7, </volume> <pages> 867-888. </pages> <note> 200 Jacobs, </note> <author> R. A. & Jordan, M. I. </author> <year> (1991). </year> <title> A competitive modular connectionist architecture. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> (pp. 767-773). </pages>
Reference-contexts: More work in this area is needed. The open issues mentioned here are all related to the overriding issue that the high correlation or dependence that typically occurs among the models makes combining the predictions of learned models difficult <ref> ( Jacobs, 1995 ) </ref> . <p> A good summary of methods for combining class probabilities is given in <ref> ( Jacobs, 1995 ) </ref> . The next two sections describe various combining strategies for these reporting schemes. Constant Weighting Functions Constant weighting functions for the classification task are slightly different than that of regression.
Reference: <author> Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. </author> <year> (1991). </year> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3 (1), </volume> <pages> 79-87. </pages>
Reference-contexts: The most prevalent method in the literature for dynamically deciding how to weight a collection of regressors (or classifiers) is the "mixture of experts" approach <ref> ( Jacobs, Jordan, Nowlan & Hinton, 1991 ) </ref> which consists of several different "expert" learned models (i.e., multilayer perceptrons) plus a gating network that decides which of the experts should be used for each case. Each expert reports a target attribute probability distribution for a given example. <p> However, they are not discussed in detail because the emphasis here is on the combining stage. 6.7.2 Non-Constant Weighting Functions The most prevalent method in the literature for dynamically deciding how to weight a collection of classifiers is the "mixture of experts" approach <ref> ( Jacobs, Jordan, Nowlan & Hinton, 1991 ) </ref> which consists of several different "expert" learned models (i.e., multilayer perceptrons) plus a gating network that decides which of the experts should be used for each case. Each expert reports a class probability distribution for a given example. <p> The class with the highest Borda count is selected as the prediction for the example presented. This approach is simple to implement and requires no training, however, it does not consider the differences in the individual classifiers' capabilities. Non-Constant Weighting Functions The "mixture of experts" approach <ref> ( Jacobs, Jordan, Nowlan & Hinton, 1991 ) </ref> is the most prevalent method for dynamically deciding how to weight a collection of classifiers. The architecture consists of several different "expert" learned models (i.e., multi-layer perceptrons) plus a gating network that decides how to weigh the experts for each case.
Reference: <author> Jolliffe, I. </author> <year> (1986). </year> <title> Principal Components Analysis. </title> <address> New York: </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Later in Chapters 4 33 and 6, SVD will be used at the core of two methods for combining the predictions of learned models. Singular Value Decomposition (SVD) is a data summarization technique used at the heart of several common modeling techniques: Principal Components Analysis (PCA) <ref> ( Jolliffe, 1986 ) </ref> , Correspondence Analysis (CA) ( Greenacre, 1984 ) , and Linear Discriminant Analysis (LDA).
Reference: <author> Jordan, M. I. & Jacobs, R. A. </author> <year> (1994). </year> <title> Hierarchical mixtures of experts and the EM algorithm. </title> <journal> Neural Computation, </journal> <volume> 6, </volume> <pages> 181-214. </pages>
Reference: <author> Jordan, M. I. & Lei, X. </author> <year> (1995). </year> <title> Convergence results for the EM approach to mixtures of experts architectures. </title> <booktitle> Neural Networks, </booktitle> <volume> 8 (9), </volume> <pages> 1409-1431. </pages>
Reference: <author> Kim, K. & Bartlett, E. B. </author> <year> (1995). </year> <title> Error estimation by series association for neural network systems. </title> <journal> Neural Computation, </journal> <volume> 7 (4), </volume> <pages> 799-808. </pages>
Reference: <author> Kivinen, J. & Warmuth, M. </author> <year> (1997). </year> <title> Exponentiated gradient descent versus gradient descent for linear predictors. </title> <journal> Information and Computation, </journal> <volume> 132 (1), </volume> <pages> 1-63. </pages>
Reference-contexts: This approach ameliorates, but does not solve, the problem because redundancy is an inherent part of the task of combining estimators. 2. Gradient descent procedures (i.e., Widrow-Hoff learning, GD, EG and EG + <ref> ( Kivinen & Warmuth, 1997 ) </ref> ) search for the coefficients by making iterative multiplicative or exponentiated updates to the ff-coefficients as a function of their performance on the training data. This avoids the matrix inversion step of standard linear regression methods which is susceptible to the multicollinearity problem. <p> More Advanced Combining Methods Now a more elaborate description is given of each of the methods briefly mentioned in Section 4.2.3. The gradient-descent procedures based on Widrow-Hoff learning <ref> ( Kivinen & Warmuth, 1997 ) </ref> are gradient descent (GD), and the exponentiated gradient procedures EG and EG + . These are iterative approaches where the weights, ff, are revised with multiplicative/exponentiated updates. <p> The mechanism for choosing the number of principal components to retain consistently chose the appropriate level of constraint. Gradient-descent procedures based on Widrow-Hoff learning <ref> ( Kivinen & Warmuth, 1997 ) </ref> may also be applicable, especially when the multicollinearity problem is present because the approach does not involve taking the inverse of a matrix. This is an iterative approach where the weights, ff, are revised with multiplicative updates.
Reference: <author> Kohavi, R. & Wolpert, D. H. </author> <year> (1996). </year> <title> Bias plus variance decomposition for zero-one loss functions. </title> <booktitle> In Proceedings of the 13th International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Kong, E. B. & Dietterich, T. G. </author> <year> (1995). </year> <title> Error-correcting output coding corrects bias and variance. </title> <booktitle> In Proceedings of the 12th International Conference on Machine Learning, </booktitle> <pages> (pp. 313-321). </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: In Rosen's decomposition of the ensemble error, he shows that ensemble error can be reduced by lowering the amount of covariance between networks. 167 Fixing S and varying R The error-correcting output coding (ECOC) of method <ref> ( Kong & Dietterich, 1995 ) </ref> is an interesting method for varying the representation. 1 They take a C-class (C 2) classification task and convert it to a large number of two-class classification problems. This transformation is accomplished by repeatedly recoding the class variable into different two-class variables.
Reference: <author> Koza, J. R. & Rice, J. P. </author> <year> (1991). </year> <title> A genetic approach to artificial intelligence. </title>
Reference-contexts: Approaches in machine learning include decision trees ( Quinlan, 1986 ) , rule induction ( Clark & 22 23 Niblett, 1989 ) , instance-based learning ( Aha, Kibler & Albert, 1991 ) , Bayesian classification ( Cheeseman & Stutz, 1995; Hanson, Stutz & Cheeseman, 1991 ) , and genetic algorithms <ref> ( Koza & Rice, 1991 ) </ref> . Each approach assumes a different set of possible search and representation strategies for ^ f . A representation, R, is the decision structure (i.e., a decision tree, or neural network, etc.) as derived from the attributes in the example space.
Reference: <editor> In C. G. Langton (Ed.), </editor> <booktitle> Artificial Life II Video Proceedings. </booktitle> <address> Sante Fe, New Mexico, USA: </address> <publisher> Addison-Wesley. </publisher>
Reference: <author> Krogh, A. & Vedelsby, J. </author> <year> (1995). </year> <title> Neural network ensembles, cross validation, and active learning. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> (pp. 231-238). </pages> <publisher> The MIT Press. </publisher>
Reference-contexts: When learned models make errors on different parts of the input space, it can be argued empirically ( Ali & Pazzani, 1996; Hashem & Schmeiser, 1995; Maclin & Shavlik, 1995 ) , and theoretically <ref> ( Krogh & Vedelsby, 1995 ) </ref> that combination schemes are less likely to make errors than any of the individual models. 2. Methods for combining the predictions of a set of learned models must not be sensitive to the inherent correlation of their predictions.
Reference: <author> Kubinyi, H. </author> <year> (1997). </year> <title> The QSAR and modelling society home page. 201 Lawson, </title> <editor> J. & Hanson, R. </editor> <year> (1974). </year> <title> Solving Least Squares Problems. </title> <address> New Jersey: </address> <publisher> Prentice-Hall. </publisher>
Reference-contexts: The "Source" column lists "UCI" for data sets taken from the UCI Machine Learning Repository ( Merz & Murphy, 1996 ) , "CMU" for data sets taken from the Statistics Library at Carnegie Mellon University ( Meyer, 1997 ) , "QSAR" for data sets taken from the QSAR Home Page <ref> ( Kubinyi, 1997 ) </ref> , and UCI-MC for a proprietary data set from the UCI Medical Center. The imports data set had 41 examples with missing values which were not used due to limitations in one of the learning algorithms used. 84 85 Table 5.1. Data set descriptions.
Reference: <author> Leblanc, M. & Tibshirani, R. </author> <year> (1993). </year> <title> Combining estimates in regression and classification. </title> <type> Technical report, </type> <institution> Department of Statistics, University of Toronto. </institution>
Reference-contexts: LRC is calculated the same way but with member, ^ f 0 which always predicts 1. According to <ref> ( Leblanc & Tibshirani, 1993 ) </ref> having the extra constant term will not be necessary (i.e., it will equal zero) because in practice, E [ ^ f i (x)] = E [f (x)] where E [] is with respect to the training data. 3 Note that the constraint, P N i=1 <p> not be necessary (i.e., it will equal zero) because in practice, E [ ^ f i (x)] = E [f (x)] where E [] is with respect to the training data. 3 Note that the constraint, P N i=1 ff i = 1, for GEM is a form of regularization <ref> ( Leblanc & Tibshirani, 1993 ) </ref> . The purpose of regularizing the weights is to provide an estimate which is less biased by the training sample. <p> LRC is calculated in a similar manner, but member ^ f 0 always predicts 1. According to <ref> ( Leblanc & Tibshirani, 1993 ) </ref> having the extra constant term is not necessary (i.e., it will equal zero) because in practice, E [ ^ f i (x)] = E [f (x)]. <p> With minor adjustments, they can be applied to this problem. 4 Note that the constraint, P N i=1 ff i = 1, for GEM is a form of regularization <ref> ( Leblanc & Tibshirani, 1993 ) </ref> . The purpose of regularizing the weights is to provide an estimate which is less biased by the training sample.
Reference: <author> Li, K.-C. </author> <year> (1985). </year> <title> From stein's unbiased risk estimates to the method of generalized cross-validation. </title> <journal> The Annals of Statistics, </journal> <volume> 13, </volume> <pages> 352-1377. </pages>
Reference-contexts: in Section 1.4, and an overview of the dissertation is given in Section 1.5. 1.1 Combining Multiple Learned Models In an attempt to overcome the selective superiority problem at the domain level, practitioners have relied upon nonparametric statistical methods like cross-validation ( Efron, 1979; Stone, 1977 ) and generalized cross-validation <ref> ( Li, 1985 ) </ref> to select a single model from a family of models. These "winner-takes-all" strategies estimate the generalization performance of a learning algorithm for a given learning set. The learned model produced by the learning algorithm with the best expected generalization performance is then selected.
Reference: <author> Lincoln, W. P. & Skrzypek, J. </author> <year> (1990). </year> <title> Synergy of clustering multiple backpropagation networks. </title> <editor> In Touretzky, D. S. (Ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> (pp. 650-657)., </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> MacLachlan, G. </author> <year> (1992). </year> <title> Discrimant Analysis and Statistical Pattern Recognition. </title> <address> New York: </address> <publisher> Wiley. </publisher>
Reference-contexts: Statistical modeling approaches include linear least squares regression ( Draper & Smith, 1981 ) , splines ( Wahba, 1990; Friedman, 1991 ) , general additive models ( Hastie & Tibshirani, 1990 ) , and linear discriminant analysis <ref> ( MacLachlan, 1992 ) </ref> . The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) . <p> Statistical modeling approaches include linear least squares regression ( Draper & Smith, 1981 ) , splines ( Wahba, 1990; Friedman, 1991 ) , general additive models ( Hastie & Tibshirani, 1990 ) , and linear discriminant analysis <ref> ( MacLachlan, 1992 ) </ref> . The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) .
Reference: <author> Maclin, R. & Shavlik, J. W. </author> <year> (1995). </year> <title> Combining the predictions of multiple classifiers: Using competitive learning to initialize neural networks. </title> <booktitle> In Proceedings of the 14th International Joint Conference on Artificial Intelligence. </booktitle>
Reference: <author> Madigan, D., Raftery, A., Volinsky, C., & Hoeting, J. </author> <year> (1996). </year> <title> Bayesian model averaging. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, (workshop on Integrating Multiple Learned Models). </booktitle> <publisher> IEEE Service Center. </publisher>
Reference: <author> Mangeas, M., Weigend, A. S., & Muller, C. </author> <year> (1995). </year> <title> Forecasting electricity demand using nonlinear mixture of experts. </title> <booktitle> In Proc. WCNN'95, World Congress on Neural Networks, </booktitle> <volume> volume II, </volume> <pages> (pp. 48-53). </pages> <month> INNS. </month>
Reference-contexts: More analysis and evaluation of the approach may be found in ( Jordan & Lei, 1995; Nowlan & Hinton, 1991 ) . Some applications of the approach may be found in ( Waterhouse & Robinson, 1995 ) , ( Zhao, Schwartz, Sroka & Makhoul, 1995 ) , <ref> ( Mangeas, Weigend & Muller, 1995 ) </ref> , ( Meila & Jordan, 1996 ) , ( Peng, Jacobs & Tanner, 1996 ) . Woods et al. ( 1997 ) combine predictions of a heterogeneous set of learned models using local accuracy estimates.
Reference: <author> Mani, G. </author> <year> (1991). </year> <title> Lowering variance of decisions by using artificial network portfolios. </title> <journal> Neural Computation, </journal> <volume> 3 (4), </volume> <pages> 484-486. </pages>
Reference: <author> Margineantu, D. D. & Dietterich, T. G. </author> <year> (1997). </year> <title> Pruning adaptive boosting. </title> <booktitle> In Proceedings of the 14th International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Model ^ f i (1 i 10) was set equal to f for each example with a 10% chance of being wrong, in which case one of the incorrect classes was selected at random. The examples were randomly divided into a training (2/3) and test (1/3) partition. Kappa-Error diagrams <ref> ( Margineantu & Dietterich, 1997 ) </ref> were used to visualize the differences between the models (see Figure 6.5). <p> This is due partly to the rapid, concurrent development of new approaches, and partly because not all techniques are applicable to the same types of model sets. Boosting appears to be the most effective method for generating a diverse model set <ref> ( Margineantu & Dietterich, 1997 ) </ref> . This is accomplished by continually refocusing on the parts of the examples space that the previously generated model found challenging.
Reference: <author> Meila, M. & Jordan, M. I. </author> <year> (1996). </year> <title> Learning fine motion by markov mixtures of experts. </title> <editor> In Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> (pp. 1003-1009). </pages> <publisher> The MIT Press. 202 Meir, R. </publisher> <year> (1995). </year> <title> Bias, variance and the combination of least squares estimators. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> (pp. 295-302). </pages> <publisher> The MIT Press. </publisher>
Reference-contexts: Some applications of the approach may be found in ( Waterhouse & Robinson, 1995 ) , ( Zhao, Schwartz, Sroka & Makhoul, 1995 ) , ( Mangeas, Weigend & Muller, 1995 ) , <ref> ( Meila & Jordan, 1996 ) </ref> , ( Peng, Jacobs & Tanner, 1996 ) . Woods et al. ( 1997 ) combine predictions of a heterogeneous set of learned models using local accuracy estimates.
Reference: <author> Merz, C. & Murphy, P. </author> <year> (1996). </year> <note> UCI repository of machine learning databases. http://www.ics.uci.edu/ mlearn/MLRepository.html. </note>
Reference-contexts: set of decision trees built using various branch pruning techniques or splitting criteria; a set of decision lists where decision nodes are added stochastically ( Ali & Pazzani, 1995 ) ; or a set of neural networks whose weights are found using different gradient descent procedures or different initial weights <ref> ( Merz & Pazzani, 1996 ) </ref> . More advanced techniques adjust the search bias so as to build accurate models 5 that make uncorrelated errors ( Opitz & Shavlik, 1996; Maclin & Shavlik, 1995 ) . <p> Variations of PCR* are explored in a third experiment where other methods of choosing the number of principal components are evaluated. 5.2 Regression Data Sets Table 5.1 summarizes the eight data sets used. The "Source" column lists "UCI" for data sets taken from the UCI Machine Learning Repository <ref> ( Merz & Murphy, 1996 ) </ref> , "CMU" for data sets taken from the Statistics Library at Carnegie Mellon University ( Meyer, 1997 ) , "QSAR" for data sets taken from the QSAR Home Page ( Kubinyi, 1997 ) , and UCI-MC for a proprietary data set from the UCI Medical <p> A series of experiments on a subset of the data sets is given to explain some of the design decisions of SCANN. 7.2 Classification Data Sets The data sets used were taken from the UCI Machine Learning Database Repository <ref> ( Merz & Murphy, 1996 ) </ref> , except for the unreleased medical data sets: retardation and dementia. A description of the data sets used is given in Table 7.1.
Reference: <author> Merz, C. & Pazzani, M. </author> <year> (1996). </year> <title> Handling redundancy in ensembles of learned models using principal components. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, (workshop on Integrating Multiple Learned Models). </booktitle> <publisher> IEEE Service Center. </publisher>
Reference-contexts: set of decision trees built using various branch pruning techniques or splitting criteria; a set of decision lists where decision nodes are added stochastically ( Ali & Pazzani, 1995 ) ; or a set of neural networks whose weights are found using different gradient descent procedures or different initial weights <ref> ( Merz & Pazzani, 1996 ) </ref> . More advanced techniques adjust the search bias so as to build accurate models 5 that make uncorrelated errors ( Opitz & Shavlik, 1996; Maclin & Shavlik, 1995 ) . <p> Variations of PCR* are explored in a third experiment where other methods of choosing the number of principal components are evaluated. 5.2 Regression Data Sets Table 5.1 summarizes the eight data sets used. The "Source" column lists "UCI" for data sets taken from the UCI Machine Learning Repository <ref> ( Merz & Murphy, 1996 ) </ref> , "CMU" for data sets taken from the Statistics Library at Carnegie Mellon University ( Meyer, 1997 ) , "QSAR" for data sets taken from the QSAR Home Page ( Kubinyi, 1997 ) , and UCI-MC for a proprietary data set from the UCI Medical <p> A series of experiments on a subset of the data sets is given to explain some of the design decisions of SCANN. 7.2 Classification Data Sets The data sets used were taken from the UCI Machine Learning Database Repository <ref> ( Merz & Murphy, 1996 ) </ref> , except for the unreleased medical data sets: retardation and dementia. A description of the data sets used is given in Table 7.1.
Reference: <author> Merz, C. J. </author> <year> (1995). </year> <title> Dynamical selection of learning algorithms. </title> <editor> In D. Fisher & H. Lenz (Eds.), </editor> <title> Learning from Data: </title> <journal> Artificial Intelligence and Statistics, </journal> <volume> 5. </volume> <publisher> Springer Verlag. </publisher>
Reference-contexts: How should the predictions of the learned models be combined? To achieve diversity in the errors of the learned models, several approaches have been tried. One way is to combine a set of learned models derived with heterogeneous representation and search biases <ref> ( Merz, 1995 ) </ref> , such as decision trees, decision lists, neural networks, etc. <p> Combining methods must be able to detect the parts of the example space where each learned model is proficient. Some learned models may be particularly effective on certain parts of the example space. Combination schemes that effectively exploit these pockets of expertise are needed. <ref> ( Merz, 1995 ) </ref> showed that some of the more elaborate stacking-based schemes that attempt to learn these specializations are less effective than simple voting schemes that do not attempt to learn. More work in this area is needed. <p> Model sets generated by the former approach are referred to as heterogeneous while model sets generated by the latter approach are referred to as homogeneous. Stacking with a collection of distinct level-0 learning algorithms <ref> ( Merz, 1995 ) </ref> is an example of the heterogeneous approach. <p> As in the case of regression, the simplest way of choosing the weights is simple averaging (i.e., ff i = 1=N ), also known as BEM or the plurality vote (PV). This approach has frequently been used as a "strawman" combining scheme for comparing to other combining schemes <ref> ( Merz, 1995 ) </ref> , or as a simple combining scheme to evaluate model generation strategies ( Breiman, 1996a; Maclin & Shavlik, 1995 ) . <p> This was referred earlier as the plurality vote (PV) and is also known as the basic ensemble method (BEM) ( Perrone & Cooper, 1993 ) . This approach has frequently been used as a "straw man" combining scheme for comparing to other combining schemes <ref> ( Merz, 1995 ) </ref> , or as a simple combining scheme to evaluate model generation strategies ( Breiman, 1996a; Maclin & Shavlik, 1995 ) . A more elaborate weighting scheme derived by Perrone and Cooper ( 1993 ) is the general ensemble method (GEM). <p> This approach has frequently been used as a baseline 178 combining scheme for comparing to other combining schemes <ref> ( Merz, 1995 ) </ref> , or as a simple combining scheme to evaluate model generation strategies ( Breiman, 1996a; Maclin & Shavlik, 1995 ) . The Generalized Ensemble Method (GEM) described earlier as a regression estimate combiner is also applicable to classification. Logistic regression is another method for combining classifiers. <p> In general, the partitions are derived from a set of mutually exclusive test conditions which divide up the input space. The partitions in ( Ho, Hull & Srihari, 1994 ) are derived from the level of agreement between the classifiers. A stricter set of test conditions are used in <ref> ( Merz, 1995 ) </ref> , where the partitions are identified by the precise voting pattern of the collection of classifiers.
Reference: <author> Merz, C. J. & Pazzani, M. J. </author> <year> (1997). </year> <title> Combining neural network regression estimates with regularized linear weights. </title> <editor> In Mozer, M., Jordan, M., & Petsche, T. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 9. </volume> <publisher> The MIT Press. </publisher>
Reference-contexts: When applying ridge regression in a case like this it is more convenient if we define z (equivalently) to be the principal components of f as is done in <ref> ( Merz & Pazzani, 1997 ) </ref> (a summary of this process is given in Chapter 4). The other major difference over linear regression is that the M fi M identity matrix, I M , multiplied by a constant, , is added to the matrix, z T z. <p> The end result is a more restricted set of coefficients, ff. As the coefficients become more restricted the resulting weighting function is more stable. Methods for searching for are discussed in ( Montgomery & Friedman, 1993 ) . An evaluation of this approach (see Chapter 5 and <ref> ( Merz & Pazzani, 1997 ) </ref> ) revealed that it was not robust across a variety of domains. In Chapter 4, a framework was developed for applying principal components regression (PCR, see ( Draper & Smith, 1981 ) ). A summary of the process, called PCR*, is to: 1.
Reference: <author> Meyer, M. </author> <year> (1997). </year> <note> The CMU statlib home page. </note>
Reference-contexts: The "Source" column lists "UCI" for data sets taken from the UCI Machine Learning Repository ( Merz & Murphy, 1996 ) , "CMU" for data sets taken from the Statistics Library at Carnegie Mellon University <ref> ( Meyer, 1997 ) </ref> , "QSAR" for data sets taken from the QSAR Home Page ( Kubinyi, 1997 ) , and UCI-MC for a proprietary data set from the UCI Medical Center. <p> CR and SCR rely upon constrained regression for setting the model weights. The constrained regression procedure used was the Bounded Variable Least Squares (BVLS) method of Stark and Parker ( 1995 ) . The code was obtained from the CMU StatLib repository <ref> ( Meyer, 1997 ) </ref> . BVLS is an enhanced version of the algorithm for constrained least squares regression given in Lawson and Hanson ( 1974 ) . The number of stacking partitions used in SCR was 10. 5.5 Experiments Two experiments were run to compare PCR* with other combining strategies.
Reference: <author> Montgomery, D. & Friedman, D. </author> <year> (1993). </year> <title> Prediction using regression models with multicollinear predictor variables. </title> <journal> IIE Transactions, </journal> <volume> 25 (3), </volume> <pages> 73-85. </pages>
Reference-contexts: Least squares regression methods which rely on matrix inversion for finding the weights can be made more reliable by constraining the types of weights they may produce. Ridge regression, RIDGE <ref> ( Montgomery & Friedman, 1993 ) </ref> has a parameter that may be used to restrict or "regularize" the ff-coefficients. Breiman ( 1996b ) has devised an approach based on constrained least squares regression ( Lawson & Hanson, 1974 ) where the coefficients are required to be nonnegative. <p> The ff-coefficients are then derived as they are in PCR*. The end result is a more restricted set of coefficients. An iterative approach is used to search for (as discussed in <ref> ( Montgomery & Friedman, 1993 ) </ref> ). The Stacked Constrained Regression (SCR) procedure ( Breiman, 1996b ) is another method for combining regression estimates. The two main components of this approach are stacking and constrained regression. <p> In ridge regression, the regularization parameter was set according to the iterative approach used in <ref> ( Montgomery & Friedman, 1993 ) </ref> . CR and SCR rely upon constrained regression for setting the model weights. The constrained regression procedure used was the Bounded Variable Least Squares (BVLS) method of Stark and Parker ( 1995 ) . <p> The end result is a more restricted set of coefficients, ff. As the coefficients become more restricted the resulting weighting function is more stable. Methods for searching for are discussed in <ref> ( Montgomery & Friedman, 1993 ) </ref> . An evaluation of this approach (see Chapter 5 and ( Merz & Pazzani, 1997 ) ) revealed that it was not robust across a variety of domains.
Reference: <author> Murthy, S., Kasif, S., Salzberg, S., & Beigel, R. </author> <year> (1993). </year> <title> OC1: Randomized induction of oblique decision trees. </title> <booktitle> In Proceedings of AAAI-93. </booktitle> <publisher> AAAI Pres. </publisher>
Reference-contexts: The two decision tree learning algorithms used in this research are C4.5 ( Quinlan, 1993 ) and OC1 <ref> ( Murthy, Kasif, Salzberg & Beigel, 1993 ) </ref> . The main difference between the two approaches is that C4.5 splits on a single attribute at a time while OC1 allows splits based on linear combinations of the attributes. <p> The CN2 algorithm ( Clark & Niblett, 1989 ) was used to generate rule lists. Clark and Niblett's version 6.1 was used with the default parameters. Decision trees were generated using C4.5 ( Quinlan, 1993 ) , OC1 <ref> ( Murthy, Kasif, Salzberg & Beigel, 1993 ) </ref> . The default parameters were used for both algorithms. A second version of OC1 was run allowing only axis-parallel splits. Two nearest neighbor approaches were used: PEBLS ( Cost & Salzberg, 1993 ) and first nearest neighbor (1-NN).
Reference: <author> Nowlan, S. J. </author> <year> (1990). </year> <title> Competing experts: An experimental investigation of associative mixture models. </title> <type> Technical Report CRG-TR-90-5, </type> <institution> Dept. of Computer Science, University of Toronto, Canada. </institution>
Reference: <author> Nowlan, S. J. & Hinton, G. E. </author> <year> (1991). </year> <title> Evaluation of adaptive mixtures of competing experts. </title> <editor> In Lippmann, R. P., Moody, J. E., & Touretzky, D. S. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 3, </volume> <pages> (pp. 774-780). </pages> <publisher> Morgan Kaufmann Publishers, Inc. 203 Opitz, </publisher> <editor> D. W. & Shavlik, J. W. </editor> <year> (1996). </year> <title> Generating accurate and diverse members of a neural-network ensemble. </title> <editor> In Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> (pp. 535-541). </pages> <publisher> The MIT Press. </publisher>
Reference-contexts: The most prevalent method in the literature for dynamically deciding how to weight a collection of regressors (or classifiers) is the "mixture of experts" approach <ref> ( Jacobs, Jordan, Nowlan & Hinton, 1991 ) </ref> which consists of several different "expert" learned models (i.e., multilayer perceptrons) plus a gating network that decides which of the experts should be used for each case. Each expert reports a target attribute probability distribution for a given example. <p> However, they are not discussed in detail because the emphasis here is on the combining stage. 6.7.2 Non-Constant Weighting Functions The most prevalent method in the literature for dynamically deciding how to weight a collection of classifiers is the "mixture of experts" approach <ref> ( Jacobs, Jordan, Nowlan & Hinton, 1991 ) </ref> which consists of several different "expert" learned models (i.e., multilayer perceptrons) plus a gating network that decides which of the experts should be used for each case. Each expert reports a class probability distribution for a given example. <p> The class with the highest Borda count is selected as the prediction for the example presented. This approach is simple to implement and requires no training, however, it does not consider the differences in the individual classifiers' capabilities. Non-Constant Weighting Functions The "mixture of experts" approach <ref> ( Jacobs, Jordan, Nowlan & Hinton, 1991 ) </ref> is the most prevalent method for dynamically deciding how to weight a collection of classifiers. The architecture consists of several different "expert" learned models (i.e., multi-layer perceptrons) plus a gating network that decides how to weigh the experts for each case.
Reference: <author> Pazzani, M. </author> <year> (1995). </year> <title> Searching for attribute dependencies in bayesian classifiers. </title> <booktitle> In Preliminary Papers of the Fifth International Workshop on Artificial Intelligence and Statistics. </booktitle> <address> Fort Lauderdale, FL: </address> <booktitle> Society for Artificial intelligence and Statistics. </booktitle>
Reference-contexts: with homogeneous representations that differ in their method of search or in the data on which they are "trained." Examples of the heterogeneous approach are a set of decision trees built using various branch pruning techniques or splitting criteria; a set of decision lists where decision nodes are added stochastically <ref> ( Ali & Pazzani, 1995 ) </ref> ; or a set of neural networks whose weights are found using different gradient descent procedures or different initial weights ( Merz & Pazzani, 1996 ) . <p> They also use different search strategies (i.e., Bayesian classification ( Duda & Hart, 1973 ) , and nearest neighbor techniques). Fixing R and varying S In this approach, algorithms which have homogeneous representations but differ in their method of search are used. <ref> ( Ali & Pazzani, 1995 ) </ref> give an example of this generation scheme with decision lists (i.e., a list of rules) where conditions are added to a rule stochastically.
Reference: <author> Peng, F., Jacobs, R. A., & Tanner, M. A. </author> <year> (1996). </year> <title> Bayesian inference in mixtures-of-experts and hierarchical mixtures-of-experts models with an application to speech recognition. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 91 (435), </volume> <pages> 953-960. </pages>
Reference-contexts: Some applications of the approach may be found in ( Waterhouse & Robinson, 1995 ) , ( Zhao, Schwartz, Sroka & Makhoul, 1995 ) , ( Mangeas, Weigend & Muller, 1995 ) , ( Meila & Jordan, 1996 ) , <ref> ( Peng, Jacobs & Tanner, 1996 ) </ref> . Woods et al. ( 1997 ) combine predictions of a heterogeneous set of learned models using local accuracy estimates. Accuracy estimates are obtained by observing the average performance of each learned model in the same "region" as the current test example.
Reference: <author> Perrone, M. P. </author> <year> (1993). </year> <title> Improving Regression Estimation: Averaging Methods for Variance Reduction with Extensions to General Convex Measure Optimization. </title> <type> PhD thesis, </type> <institution> Brown University, Institute for Brain and Neural Systems. </institution>
Reference-contexts: The most naive approach is uniform weighting, also known as the Basic Ensemble Method (BEM) <ref> ( Perrone & Cooper, 1993 ) </ref> . A more elaborate method would consider the unique contributions of each learned model and assign weights accordingly. Linear regression is an example of such a combining method. A thorough description of methods for combining regression estimates is given in Chapter 8. <p> This is undesirable because a combiner which varies its decision structure and output considerably as small changes occur in the predictions of the learned models is likely to overfit the data. 3. Specific methods designed for model combination may be used. One approach is the Generalized Ensemble Method (GEM) <ref> ( Perrone & Cooper, 1993 ) </ref> which is quite effective at finding unique contributions of individual 104 models, but extremely sensitive to redundancy in the model set. Other approaches discussed later in Section 6.7 place more emphasis on model generation and/or are more tightly coupled with the model generation process. <p> The simplest way of choosing the weights is giving each model equal weight (i.e., ff i = 1=N ), and predicting the class with the most frequent vote. This was referred earlier as the plurality vote (PV) and is also known as the basic ensemble method (BEM) <ref> ( Perrone & Cooper, 1993 ) </ref> . This approach has frequently been used as a "straw man" combining scheme for comparing to other combining schemes ( Merz, 1995 ) , or as a simple combining scheme to evaluate model generation strategies ( Breiman, 1996a; Maclin & Shavlik, 1995 ) .
Reference: <author> Perrone, M. P. </author> <year> (1994). </year> <title> Putting it all together: Methods for combining neural networks. </title> <editor> In Cowan, J. D., Tesauro, G., & Alspector, J. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 6, </volume> <pages> (pp. 1188-1189). </pages> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: If distinct patterns occur in the errors, e.g., ^ f i is particularly good at classifying class c, then the errors are said to be correlated. In the former case, a simple approach like plurality voting is most effective <ref> ( Perrone, 1994 ) </ref> . In the latter case, a more complex combining scheme is needed. An effective combining strategy must be able to adjust for both situations. Sections 6.6.1 and 6.6.2 evaluate how SCANN handles these two scenarios. The time complexity of SCANN is discussed in Section 6.6.3.
Reference: <author> Perrone, M. P. & Cooper, L. N. </author> <year> (1993). </year> <title> When networks disagree: Ensemble methods for hybrid neural networks. </title> <editor> In Mammone, R. J. (Ed.), </editor> <booktitle> Artificial Neural Networks for Speech and Vision, </booktitle> <pages> (pp. 126-142)., </pages> <address> London. </address> <publisher> Chapman & Hall. </publisher>
Reference-contexts: The most naive approach is uniform weighting, also known as the Basic Ensemble Method (BEM) <ref> ( Perrone & Cooper, 1993 ) </ref> . A more elaborate method would consider the unique contributions of each learned model and assign weights accordingly. Linear regression is an example of such a combining method. A thorough description of methods for combining regression estimates is given in Chapter 8. <p> This is undesirable because a combiner which varies its decision structure and output considerably as small changes occur in the predictions of the learned models is likely to overfit the data. 3. Specific methods designed for model combination may be used. One approach is the Generalized Ensemble Method (GEM) <ref> ( Perrone & Cooper, 1993 ) </ref> which is quite effective at finding unique contributions of individual 104 models, but extremely sensitive to redundancy in the model set. Other approaches discussed later in Section 6.7 place more emphasis on model generation and/or are more tightly coupled with the model generation process. <p> The simplest way of choosing the weights is giving each model equal weight (i.e., ff i = 1=N ), and predicting the class with the most frequent vote. This was referred earlier as the plurality vote (PV) and is also known as the basic ensemble method (BEM) <ref> ( Perrone & Cooper, 1993 ) </ref> . This approach has frequently been used as a "straw man" combining scheme for comparing to other combining schemes ( Merz, 1995 ) , or as a simple combining scheme to evaluate model generation strategies ( Breiman, 1996a; Maclin & Shavlik, 1995 ) .
Reference: <author> Press, W. H. </author> <year> (1992). </year> <title> Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing, </booktitle> <pages> (pp. 59-70). </pages> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Methods which use SVD typically consist of three steps: 1. The original input matrix Z is preprocessed by a normalization or transfor mation method. 2. The resulting transformation is decomposed into its basic structure using SVD (see <ref> ( Press, 1992 ) </ref> for an in-depth description of the algorithm). 3. <p> Therefore, matrix inversion takes O ((V + 1)N 3 ) time, where V is typically ten. 3. The Singular Value Decomposition of a matrix. The SVD of an N fiN matrix takes O (N 3 ) time (see <ref> ( Press, 1992 ) </ref> ). 72 Therefore, the total time complexity of PCR* is O (N 2 max (M; N )). 4.6 Related Work Alternate approaches to PCR* may be broken down into two major subgroups. <p> Therefore, the time complexity of this stage is a function of the constituent learning algorithms, A, i.e. O ( n 2 N 2. Correspondence Analysis. The dominating computation of this stage is the Singular Value Decomposition of A which takes O (max (M; N jY j) 3 ) time <ref> ( Press, 1992 ) </ref> . This computation may be prohibitive for data sets with many examples. However, SCANN does not make use of the left singular vectors contained in U which provide the coordinates of the training examples in the scaled space.
Reference: <author> Quinlan, J. </author> <year> (1986). </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 (1), </volume> <pages> 81-106. </pages>
Reference-contexts: The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) . Approaches in machine learning include decision trees <ref> ( Quinlan, 1986 ) </ref> , rule induction ( Clark & Niblett, 1989 ) , instance-based learning ( Aha, Kibler & Albert, 1991 ) , Bayesian classification ( Cheeseman & Stutz, 1995; Hanson, Stutz & Cheeseman, 1991 ) , and genetic algorithms ( Koza & Rice, 1991; Grefenstette, 1993a; Grefenstette, 1993b ) <p> The neural network community has developed various forms of feedforward networks ( Rumelhart, Hinton & Williams, 1986 ) , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) . Approaches in machine learning include decision trees <ref> ( Quinlan, 1986 ) </ref> , rule induction ( Clark & 22 23 Niblett, 1989 ) , instance-based learning ( Aha, Kibler & Albert, 1991 ) , Bayesian classification ( Cheeseman & Stutz, 1995; Hanson, Stutz & Cheeseman, 1991 ) , and genetic algorithms ( Koza & Rice, 1991 ) .
Reference: <author> Quinlan, J. R. </author> <year> (1996). </year> <title> Bagging, boosting, </title> <booktitle> and C4.5. In Proceedings of the Fourteenth National Conference on Artificial Intelligence. </booktitle>
Reference: <author> Quinlan, R. </author> <year> (1993). </year> <title> C4.5 Programs for Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. 204 Rao, </publisher> <editor> C. R. </editor> <year> (1948). </year> <title> The utilization of multiple measurements in problems of biological classification (with discussion). </title> <journal> Journal of the Royal Statistical Society series B, </journal> <volume> 10, </volume> <pages> 159-203. </pages>
Reference-contexts: The two decision tree learning algorithms used in this research are C4.5 <ref> ( Quinlan, 1993 ) </ref> and OC1 ( Murthy, Kasif, Salzberg & Beigel, 1993 ) . The main difference between the two approaches is that C4.5 splits on a single attribute at a time while OC1 allows splits based on linear combinations of the attributes. <p> The CN2 algorithm ( Clark & Niblett, 1989 ) was used to generate rule lists. Clark and Niblett's version 6.1 was used with the default parameters. Decision trees were generated using C4.5 <ref> ( Quinlan, 1993 ) </ref> , OC1 ( Murthy, Kasif, Salzberg & Beigel, 1993 ) . The default parameters were used for both algorithms. A second version of OC1 was run allowing only axis-parallel splits.
Reference: <author> Rao, J. & Tibshirani, R. </author> <year> (1997). </year> <title> The out-of-bootstrap method for model averaging and selection. </title> <type> Technical report, </type> <institution> Department of Statistics, University of Toronto. </institution>
Reference: <author> Raviv, Y. & Intrator, N. </author> <year> (1996). </year> <title> Bootstrapping with noise: An effective regularization technique. </title> <journal> Connection Science, </journal> <volume> 8 (3-4), </volume> <pages> 355-72. </pages>
Reference: <author> Rogova, G. </author> <year> (1994). </year> <title> Combining the results of neural network classifiers. </title> <booktitle> Neural Networks, </booktitle> <volume> 7 (5), </volume> <pages> 777-781. </pages>
Reference: <author> Rosen, B. E. </author> <year> (1996). </year> <title> Ensemble learning using decorrelated neural networks. </title> <journal> Connection Science, </journal> <volume> 8 (3-4), </volume> <pages> 373-83. </pages>
Reference: <author> Ruck, D. W., Rogers, S. K., Kabrisky, M., Oxley, M. E., & Suter, B. W. </author> <year> (1990). </year> <title> The multilayer perceptron ass an approximation to a bayes optimal discrimant function. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 1 (4), </volume> <pages> 296-298. </pages>
Reference: <author> Ruderman, D. L. </author> <year> (1994). </year> <title> Natural Ensembles and Sensory Signal Processing. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley. </institution>
Reference: <author> Rumelhart, D. E., Hinton, G. E., & Williams, R. J. </author> <year> (1986). </year> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart, J. L. McClelland, </editor> & <booktitle> the PDP research group. (Eds.), Parallel distributed processing: Explorations in the microstructure of cognition, Volume 1: Foundations. </booktitle> <publisher> MIT Press. </publisher>
Reference-contexts: The neural network community has developed various forms of feedforward networks <ref> ( Rumelhart, Hinton & Williams, 1986 ) </ref> , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) . <p> The neural network community has developed various forms of feedforward networks <ref> ( Rumelhart, Hinton & Williams, 1986 ) </ref> , and recurrent networks ( Cleeremans, Servan-Schreiber & McClelland, 1989 ) . <p> The non-linearity of the activation function gives neural networks greater representation power. The difficulty lies in setting the weights. The most widely know method for setting the weights is the error backpropagation algorithm <ref> ( Rumelhart, Hinton & Williams, 1986 ) </ref> . In this approach, a training pattern is applied to the input layer, and the hidden layer functions are applied to the inputs. <p> 252 14 14 CMU cpu 209 6 6 UCI dementia 118 26 26 UCI-MC hansch 111 13 0 QSAR housing 506 12 12 UCI imports 160 15 15 UCI servo 167 4 0 UCI 5.3 Constituent Learners The set of learned models, F , were generated using Backpropagation networks (BP) <ref> ( Rumelhart, Hinton & Williams, 1986 ) </ref> and Multivariate Adaptive Regression Splines (MARS) ( Friedman, 1991 ) . <p> The configurations of these methods are described here. The learning algorithms are described in more detail in Section 3.2.1. A standard implementation of Error Backpropagation (BP) <ref> ( Rumelhart, Hinton & Williams, 1986 ) </ref> was used to generate neural network models. All networks consisted of an input layer, a single hidden layer, and an output layer. For the input layer, a single input node was assigned to each numeric attribute. <p> Each new network's "fitness" is evaluated according to its accuracy and diversity. The most fit networks are retained for further "evolution", and the final population is retained for combination. The main adjustment in the search strategy occurs during backpropagation training <ref> ( Rumelhart, Hinton & Williams, 1986 ) </ref> where the current ensembles' erroneous examples are emphasized.
Reference: <author> Salzberg, S. </author> <year> (1997). </year> <title> On comparing classifiers: Pitfalls to avoid and a recommended approach. Data Mining and Knowledge Discovery, </title> <type> 1 (3). </type>
Reference: <author> Schapire, R. E. </author> <year> (1990). </year> <title> The strength of weak learnability. </title> <journal> Machine Learning, </journal> <volume> 5 (2), </volume> <pages> 197-227. </pages>
Reference-contexts: Two other methods for assigning fixed weights to each model are "bagging" ( Breiman, 1994 ) and "boosting" <ref> ( Schapire, 1990 ) </ref> . These methods are tightly coupled to the model generation phase rather than being general combining techniques.
Reference: <author> Schapire, R. E., Freund, Y., Bartlett, P., & Lee, W. S. </author> <year> (1997). </year> <title> Boosting the margin: A new explanation for the effectiveness of voting methods. </title> <booktitle> In Proceedings of the 14th International Conference on Machine Learning. </booktitle> <publisher> Morgan Kaufmann. 205 Seung, </publisher> <editor> H. S., Opper, M., & Sompolinsky, H. </editor> <year> (1992). </year> <title> Query by committee. </title>
Reference: <editor> In Haussler, D. (Ed.), </editor> <booktitle> Proceedings of the 5th Annual ACM Workshop on Computational Learning Theory, </booktitle> <pages> (pp. 287-294). </pages> <publisher> ACM Press. </publisher>
Reference: <author> Shannon, W. & Banks, D. </author> <year> (1997). </year> <title> A distance metric for classification trees. </title> <booktitle> In Preliminary Papers of the Sixth International Workshop on Artificial Intelligence and Statistics. </booktitle> <address> Fort Lauderdale, FL: </address> <booktitle> Society for Artificial intelligence and Statistics. </booktitle>
Reference: <author> Shao, J. </author> <year> (1996). </year> <title> Bootstrap model selection. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 91, </volume> <pages> 655-665. </pages>
Reference: <author> Sollich, P. & Krogh, A. </author> <year> (1996). </year> <title> Learning with ensembles: How overfitting can be useful. </title> <editor> In Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> (pp. 190-196). </pages> <publisher> The MIT Press. </publisher>
Reference: <author> Stark, P. & Parker, R. </author> <year> (1995). </year> <title> Bounded-variable least-squares: an algorithm and applications. </title> <journal> Computational Statistics, </journal> <volume> 10 (2), </volume> <pages> 129-41. </pages>
Reference: <author> Stone, M. </author> <year> (1977). </year> <title> Asymptotics for and against cross-validation. </title> <journal> Biometrika, </journal> <volume> 64, </volume> <pages> 29-35. </pages>
Reference: <author> Tibshirani, R. </author> <year> (1996). </year> <title> Bias, variance and prediction error for classification rules. </title> <type> Technical report, </type> <institution> Department of Statistics, University of Toronto. </institution>
Reference: <author> Tresp, V. & Taniguchi, M. </author> <year> (1995). </year> <title> Combining estimators using non-constant weighting functions. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> (pp. 419-426). </pages> <publisher> The MIT Press. </publisher>
Reference-contexts: Another data-partitioning approach was given in ( Baxt, 1992 ) where two different neural networks were trained each on data from a different class. The idea here was to produce networks which specialized on different types of examples developing a specific area of expertise. In <ref> ( Tresp & Taniguchi, 1995 ) </ref> , the examples of L 0 were divided into k clusters, each cluster was then split in half randomly yielding two training sets. Multi-layer perceptrons (MLP) were then trained on each of the new training sets.

Reference: <author> Tumer, K. & Ghosh, J. </author> <year> (1995b). </year> <title> Order statistics combiners for neural classifiers. </title> <booktitle> World Congress on Neural Networks, </booktitle> <volume> Vol. I, </volume> <pages> 31-34. </pages>
Reference: <author> Tumer, K. & Ghosh, J. </author> <year> (1996a). </year> <title> Analysis of decision boundaries in linearly combined neural classifiers. </title> <journal> Pattern Recognition, </journal> <volume> 29 (2), </volume> <pages> 341-348. </pages>
Reference: <author> Tumer, K. & Ghosh, J. </author> <year> (1996b). </year> <title> Classifier combining: Analytical results and implications. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, (workshop on Integrating Multiple Learned Models). </booktitle> <publisher> IEEE Service Center. </publisher>
Reference: <author> Tumer, K. & Ghosh, J. </author> <year> (1996c). </year> <title> Estimating the bayes error rate through classifier combining. </title> <booktitle> In Proceedings of the 13th International Conference on Pattern Recognition. </booktitle>
Reference: <author> Wahba, G. </author> <year> (1990). </year> <title> Spline functions for observational data. </title> <booktitle> In CBMS-NSF Regional Conference series, </booktitle> <publisher> SIAM. </publisher>
Reference: <author> Wan, E. A. </author> <year> (1990). </year> <title> Neural network classification: A bayesian interpretation. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 1 (4), </volume> <pages> 303-304. </pages>
Reference: <author> Waterhouse, S., MacKay, D., & Robinson, T. </author> <year> (1996). </year> <title> Bayesian methods for mixtures of experts. </title> <editor> In Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> (pp. 351-357). </pages> <publisher> The MIT Press. </publisher>
Reference: <author> Waterhouse, S. R. & Robinson, A. J. </author> <year> (1994). </year> <title> Classification using hierarchical mixtures of experts. </title> <booktitle> In Proceedings of the 1994 IEEE Workshop on Neural Networks for Signal Processing IV, </booktitle> <pages> (pp. 177-186). </pages> <publisher> IEEE Press. </publisher>
Reference: <author> Waterhouse, S. R. & Robinson, A. J. </author> <year> (1995). </year> <title> Non-linear prediction of acoustic vectors using hierarchical mixtures of experts. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> (pp. 835-842). </pages> <publisher> The MIT Press. 207 Waterhouse, </publisher> <editor> S. R. & Robinson, A. J. </editor> <year> (1996). </year> <title> Constructive algorithms for hierarchical mixtures of experts. </title> <editor> In Touretzky, D. S., Mozer, M. C., & Hasselmo, M. E. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 8, </volume> <pages> (pp. 584-590). </pages> <publisher> The MIT Press. </publisher>
Reference-contexts: These gating functions make "soft" splits allowing an example to lie simultaneously in multiple regions. More analysis and evaluation of the approach may be found in ( Jordan & Lei, 1995; Nowlan & Hinton, 1991 ) . Some applications of the approach may be found in <ref> ( Waterhouse & Robinson, 1995 ) </ref> , ( Zhao, Schwartz, Sroka & Makhoul, 1995 ) , ( Mangeas, Weigend & Muller, 1995 ) , ( Meila & Jordan, 1996 ) , ( Peng, Jacobs & Tanner, 1996 ) .
Reference: <author> Wolpert, D. & Macready, W. </author> <year> (1998). </year> <title> Combining stacking with bagging to improve a learning algorithm. </title> <note> To appear in Machine Learning, </note> ?? (?), ?? <author> Wolpert, D. H. </author> <year> (1992). </year> <title> Stacked generalization. </title> <booktitle> Neural Networks, </booktitle> <volume> 5, </volume> <pages> 241-259. </pages>
Reference: <author> Wolpert, D. H. </author> <year> (1993). </year> <title> Combining generealizers using partitions of the learning set. </title>
Reference: <editor> In L. Nadel & D. Stein (Eds.), </editor> <booktitle> Lectures in Complex Systems. </booktitle> <publisher> Addison-Wesley. </publisher>
Reference: <author> Woods, K., Kegelmeyer, W., & Bowyer, K. </author> <year> (1997). </year> <title> Combination of multiple classifiers using local accuracy estimates. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-19 (4), </volume> <pages> 405-10. </pages>
Reference: <author> Xu, L., Jordan, M. I., & Hinton, G. E. </author> <year> (1995). </year> <title> An alternative model for mixtures of experts. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> (pp. 633-640). </pages> <publisher> The MIT Press. </publisher>
Reference: <author> Y. Shimshoni, N. I. </author> <year> (1995). </year> <title> Automatic discrimination between local earthquakes and quarry blasts by integrating ensembles of neural networks. </title> <booktitle> In Workshop on AI and Seismology, </booktitle> <address> Luxembourg. </address>
Reference: <author> Zhang, P. </author> <year> (1993). </year> <title> Model selection via multifold cross-validation. </title> <journal> The Annals of Statistics, </journal> <volume> 21, </volume> <pages> 299-311. </pages>
Reference: <author> Zhao, Y., Schwartz, R., Sroka, J., & Makhoul, J. </author> <year> (1995). </year> <title> Hierarchical mixtures of experts methodology applied to continuous speech recognition. </title> <editor> In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 7, </volume> <pages> (pp. 859-865). </pages> <publisher> The MIT Press. </publisher>
Reference-contexts: More analysis and evaluation of the approach may be found in ( Jordan & Lei, 1995; Nowlan & Hinton, 1991 ) . Some applications of the approach may be found in ( Waterhouse & Robinson, 1995 ) , <ref> ( Zhao, Schwartz, Sroka & Makhoul, 1995 ) </ref> , ( Mangeas, Weigend & Muller, 1995 ) , ( Meila & Jordan, 1996 ) , ( Peng, Jacobs & Tanner, 1996 ) .
References-found: 127

