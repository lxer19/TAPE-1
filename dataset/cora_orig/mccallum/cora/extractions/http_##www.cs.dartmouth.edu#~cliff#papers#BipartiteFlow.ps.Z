URL: http://www.cs.dartmouth.edu/~cliff/papers/BipartiteFlow.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~cliff/papers/
Root-URL: http://www.cs.dartmouth.edu
Title: IMPROVED ALGORITHMS FOR BIPARTITE NETWORK FLOW  
Author: RAVINDRA K. AHUJA JAMES B. ORLIN CLIFFORD STEIN AND ROBERT E. TARJAN 
Keyword: Key words. Network flow, bipartite graphs, maximum flow, minimum-cost flow, parametric maximum flow, parallel algorithms  
Date: 2  
Note: 1 time and that the analogous version of Ahuja and Orlin's excess scaling algorithm runs in O(n 1 m n  AMS subject classifications. 90B10 68Q25 68R10  
Abstract: In this paper, we study network flow algorithms for bipartite networks. A network G = (V; E) is called bipartite if its vertex set V can be partitioned into two subsets V 1 and V 2 such that all edges have one endpoint in V 1 and the other in V 2 . Let n = jV j, n 1 = jV 1 j, n 2 = jV 2 j, m = jEj and assume without loss of generality that n 1 n 2 . We call a bipartite network unbalanced if n 1 t n 2 and balanced otherwise. (This notion is necessarily imprecise.) We show that several maximum flow algorithms can be substantially sped up when applied to unbalanced networks. The basic idea in these improvements is a two-edge push rule that allows us to "charge" most computation to vertices in V 1 , and hence develop algorithms whose running times depend on n 1 rather than n. For example, we show that the two-edge push version of Goldberg and Tarjan's FIFO preflow push algorithm runs in O(n 1 m + n 3 1 log U ) time, where U is the largest edge capacity. We also extend our ideas to dynamic tree implementations, parametric maximum flows, and minimum-cost flows. 1. Introduction. In this paper, we study network flow algorithms for bipartite 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. K. Ahuja, T. L. Magnanti, and J. B. Orlin, </author> <title> Network flows, </title> <booktitle> in Handbook in operations research and management science, Volume 1: Optimization, </booktitle> <editor> G. Nemhauser, A. H. G. R. Kan, and M. J. Todd, eds., </editor> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1990, </year> <pages> pp. 211-360. </pages>
Reference: [2] <author> R. K. Ahuja and J. B. Orlin, </author> <title> A fast and simple algorithm for the maximum flow problem, </title> <journal> Operations Research, </journal> <volume> 37 (1989), </volume> <pages> pp. 748-759. </pages>
Reference-contexts: Column 3 of Table 1.1 summarizes these improvements for several network flow algorithms. We obtain further running-time improvements by modifying the algorithms. This modification applies only to preflow push algorithms <ref> [2, 3, 14, 15, 16, 17] </ref>; we call it the two-edge push rule. <p> n 2 1 n [21] does not apply FIFO preflow push n 3 n 2 1 n n 1 m + n 3 [15],[16] Highest label n 2 p m n 1 n m n 1 m preflow push [7] + minfn 3 1 ; n 2 p Excess scaling <ref> [2] </ref> nm + n 2 log U n 1 m + n 1 n log U n 1 m + n 2 1 log U Wave scaling [3] nm + n 2 p p 1 log U FIFO w/ dynamic trees nm log ( n 2 m ) n 1 m <p> n log U n 1 m + n 2 1 log U Wave scaling [3] nm + n 2 p p 1 log U FIFO w/ dynamic trees nm log ( n 2 m ) n 1 m log ( n 2 n 2 m + 2) Parallel excess scaling <ref> [2] </ref> n 2 log U log ( m n ), n 1 n log U log ( m 1 log U log ( m dm=ne processors dm=ne processors dm=n 1 e processors Parametric Flows GGT [14] n 3 n 1 n 2 n 2 GGT w/ nm log ( n 2 <p> Proof. Immediate from Lemma 5.3 by choosing p = maxf1; dn 1 = p 5.3. The Excess Scaling Algorithm. The excess scaling algorithm, due to Ahuja and Orlin <ref> [2] </ref>, incorporates scaling of the excesses into the generic preflow push algorithm, thereby reducing the number of nonsaturating pushes from O (n 2 m) to O (n 2 log U ). <p> No vertex ever has excess greater than . Proof. Invariant 1 is satisfied because the bipartite excess scaling algorithm is a special case of the generic algorithm and the generic algorithm satisfies it. For Invariants 2 and 3, see <ref> [2, 3] </ref>. We can use these invariants to establish a bound on the number of nonsaturating bipushes. We define a scaling phase to be a maximal period of time during which does not change. Lemma 5.6. <p> We assume familiarity with parallel prefix operations [22] and refer the reader to <ref> [2, 16, 26, 32] </ref> for examples of the use of parallel prefix operations in network flow algorithms. <p> Our algorithm will be the same as the excess-scaling algorithm of Section 5.3 with a parallel implementation of bipush/relabel and a few additional data structures. The same approach was taken by Ahuja and Orlin <ref> [2] </ref> in developing a parallel version of their original excess scaling algorithm. The first step in our algorithm is to transform the input graph so that each vertex has out-degree no greater than d.
Reference: [3] <author> R. K. Ahuja, J. B. Orlin, and R. Tarjan, </author> <title> Improved time bounds for the maximum flow problem, </title> <journal> SIAM J. Comput., </journal> <volume> 18 (1989), </volume> <pages> pp. 939-954. </pages>
Reference-contexts: Column 3 of Table 1.1 summarizes these improvements for several network flow algorithms. We obtain further running-time improvements by modifying the algorithms. This modification applies only to preflow push algorithms <ref> [2, 3, 14, 15, 16, 17] </ref>; we call it the two-edge push rule. <p> 2 p m n 1 n m n 1 m preflow push [7] + minfn 3 1 ; n 2 p Excess scaling [2] nm + n 2 log U n 1 m + n 1 n log U n 1 m + n 2 1 log U Wave scaling <ref> [3] </ref> nm + n 2 p p 1 log U FIFO w/ dynamic trees nm log ( n 2 m ) n 1 m log ( n 2 n 2 m + 2) Parallel excess scaling [2] n 2 log U log ( m n ), n 1 n log U <p> No vertex ever has excess greater than . Proof. Invariant 1 is satisfied because the bipartite excess scaling algorithm is a special case of the generic algorithm and the generic algorithm satisfies it. For Invariants 2 and 3, see <ref> [2, 3] </ref>. We can use these invariants to establish a bound on the number of nonsaturating bipushes. We define a scaling phase to be a maximal period of time during which does not change. Lemma 5.6. <p> Lemma 5.6. The bipartite excess scaling algorithm performs O (n 2 1 log U ) nonsat urating pushes and runs O (n 1 m + n 2 1 log U ) time. Proof. As in <ref> [3] </ref>, we consider the potential function = P e (v)d (v) , which by Invariant 1 is the same as P e (v)d (v) . By Invariant 3, at the beginning of a scaling phase, 4n 2 1 . The actions of the algorithm consist of bipushes and relabels. <p> The running time of the algorithm is O (n 1 m + n 2 1 log U ) plus the time required to select smallest-distance vertices for push/relabel steps. The bucket-based data structure described in <ref> [3] </ref> makes the total time for vertex selection O (n 1 m + n 2 1 log U ). 5.4. Variants of Excess Scaling. Ahuja, Orlin, and Tarjan [3] have developed two variants of the excess scaling algorithm that achieve improved time bounds. <p> The bucket-based data structure described in <ref> [3] </ref> makes the total time for vertex selection O (n 1 m + n 2 1 log U ). 5.4. Variants of Excess Scaling. Ahuja, Orlin, and Tarjan [3] have developed two variants of the excess scaling algorithm that achieve improved time bounds. The faster of these, called the wave scaling algorithm, runs in O (nm + n 2 p log U ) time. <p> In order to realize this bound, we must overcome a few obstacles. First, as in <ref> [3] </ref> and [15, 16], we need to limit the tree size. Moreover, we need to make the tree size bound solely a function of n 1 rather than n. Finally, we must deal with the fact that a cut can make a V 2 -vertex a tree root. <p> Given these building blocks we can give the procedure bi-tree push/relabel, which incorporates all of these ideas. The procedure appears in Figure 5.7. The basic idea is similar to that used in <ref> [3, 15, 16] </ref>, in that we do a tree-push, but only perform a link if the size of the resulting tree is not too large. We also have the additional constraint of not performing a link that will cause a V 2 -vertex to become a leaf.
Reference: [4] <author> D. Bertsekas, </author> <title> Distributed asynchronous relaxation methods for linear network flow problems, </title> <type> Tech. Report LIDS-P-1606, </type> <institution> MIT, Laboratory for Information and Decision Sciences, </institution> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: Let l be the number of edges on the longest simple cycle in the network. It can be shown that any feasible flow is *-optimal for * C and any *-optimal feasible flow for * &lt; 1=l is an optimum flow <ref> [4] </ref>. Since in a bipartite network every other vertex on a cycle must be a vertex in V 1 , any *-optimal feasible flow for * &lt; 1 2n 1 is an optimum flow.
Reference: [5] <author> D. Bertsekas and J. Eckstein, </author> <title> Dual coordinate step methods for linear network flow problems, </title> <journal> Mathematical Programming, </journal> <volume> 42 (1988), </volume> <pages> pp. 202-243. </pages>
Reference-contexts: They show that a specific implementation of the generic implementation, called the first-active method algorithm, performs O (n 3 ) nonsaturating pushes, as does a related method, the wave method. (The wave method was developed independently by Bertsekas and Eckstein <ref> [5] </ref>.) We shall show that an adaptation of the first-active method for bipartite networks performs O (n 3 1 ) nonsaturating bipushes. The first-active method uses the acyclicity of the admissible network.
Reference: [6] <author> R. P. Brent, </author> <title> The parallel evaluation of general arithmetic expressions, </title> <journal> Journal of the ACM, </journal> <volume> 21 (1974), </volume> <pages> pp. 201-208. </pages>
Reference-contexts: We explain how to reduce the in-degree; the out-degree can be reduced in a similar manner. First, we lexicographically sort the list of edges by their tails. This can be done on d processors in O (n 1 log m) time using Cole's sorting algorithm [8] and Brent's Theorem <ref> [6] </ref>. Next, we assign one processor to each of the last d edges on the list. In O (log d) time, we can determine if all these edges have the same tail. If so, we perform the splitting step, which can be done in O (1) time on d processors.
Reference: [7] <author> J. Cheriyan and S. N. Maheshwari, </author> <title> Analysis of preflow push algorithms for maximum network flow, </title> <journal> SIAM Journal on Computing, </journal> <volume> 18 (1989), </volume> <pages> pp. 1057-1086. </pages>
Reference-contexts: [21] n 1 m + n 3 MPM [27] n 3 n 2 1 n [21] does not apply FIFO preflow push n 3 n 2 1 n n 1 m + n 3 [15],[16] Highest label n 2 p m n 1 n m n 1 m preflow push <ref> [7] </ref> + minfn 3 1 ; n 2 p Excess scaling [2] nm + n 2 log U n 1 m + n 1 n log U n 1 m + n 2 1 log U Wave scaling [3] nm + n 2 p p 1 log U FIFO w/ dynamic <p> As each vertex examination entails at most one nonsaturating bipush, this gives a bound of O (n 3 1 ) on the number of nonsaturating bipushes and a bound of O (n 1 m + n 3 1 ) on the running time of the algorithm. Cheriyan and Maheshwari <ref> [7] </ref> showed by a clever argument that the highest label preflow push algorithm performs O (n 2 p m) nonsaturating pushes for general networks.
Reference: [8] <author> R. Cole, </author> <title> Parallel merge sort, </title> <journal> SIAM Journal of Computing, </journal> <volume> 17 (1988), </volume> <pages> pp. 770-785. </pages>
Reference-contexts: We explain how to reduce the in-degree; the out-degree can be reduced in a similar manner. First, we lexicographically sort the list of edges by their tails. This can be done on d processors in O (n 1 log m) time using Cole's sorting algorithm <ref> [8] </ref> and Brent's Theorem [6]. Next, we assign one processor to each of the last d edges on the list. In O (log d) time, we can determine if all these edges have the same tail.
Reference: [9] <author> W. Cunningham, </author> <title> Optimal attack and reinforcement of a network, </title> <journal> Journal of the ACM, </journal> <volume> 32 (1985), </volume> <pages> pp. 549-561. </pages>
Reference-contexts: We conclude by noting that the bipartite parametric flow problem has many applications including multiprocessor scheduling with release times and deadlines [21, 24], 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability <ref> [9, 19] </ref>, partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem [23, 31]. For all these problems we improve on or match the best known bounds. 7. Minimum-Cost Circulation. In this section we examine the minimum-cost flow problem on bipartite networks.
Reference: [10] <author> E. Dinic, </author> <title> Algorithm for solution of a problem of maximum flow in networks with power estimation, </title> <journal> Soviet Math. Dokl., </journal> <volume> 11 (1970), </volume> <pages> pp. 1277-1280. </pages>
Reference-contexts: Hence for unbalanced networks the path length is much less than n, and we get an automatic improvement in running times. As an example, consider Dinic's algorithm <ref> [10] </ref> for the maximum flow problem. This algorithm constructs O (L) layered networks and finds a blocking flow in each one. Each blocking flow computation performs O (m) augmentations and each augmentation takes O (L) time. Consequently, the running time of Dinic's algorithm is O (L 2 m). <p> Let U = maxfu (v; w) : (v; w) 2 Eg. Let source s and sink t be the two distinguished NETWORK FLOW IN BIPARTITE GRAPHS 3 Algorithm Running time, Running time, Running time, general network bipartite network modified version Maximum Flows Dinic <ref> [10] </ref> n 2 m n 2 1 m does not apply Karzanov [25] n 3 n 2 1 n [21] n 1 m + n 3 MPM [27] n 3 n 2 1 n [21] does not apply FIFO preflow push n 3 n 2 1 n n 1 m +
Reference: [11] <author> M. J. Eisner and D. G. Severance, </author> <title> Mathematical techniques for efficient record segmentation in large shared databases, </title> <journal> Journal of the ACM, </journal> <volume> 23 (1976), </volume> <pages> pp. 619-635. </pages>
Reference-contexts: many applications including multiprocessor scheduling with release times and deadlines [21, 24], 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability [9, 19], partitioning a data base between fast and slow memory <ref> [11] </ref>, and the sportswriter's end-of-season problem [23, 31]. For all these problems we improve on or match the best known bounds. 7. Minimum-Cost Circulation. In this section we examine the minimum-cost flow problem on bipartite networks.
Reference: [12] <author> L. R. Ford and D. R. Fulkerson, </author> <title> Maximal flow through a network, </title> <journal> Canad. J. Math., </journal> <volume> 8 (1956), </volume> <pages> pp. 399-404. </pages>
Reference-contexts: be pointed out the minimum cuts in the parametric maximum flow problem are nested, i.e., for 1 2 3 , with corresponding cuts (X 1 ; X 1 ); (X 2 ; X 2 ); (X 3 ; X 3 ), we have that X 1 X 2 X 3 <ref> [12] </ref>. This property allows us to store all l cuts in O (n + l) space, and recreate any one cut in O (n) time.
Reference: [13] <author> S. Fortune and J. Wyllie, </author> <title> Parallelism in random access machines, </title> <booktitle> in Proceedings of the 10th Annual ACM Symposium on Theory of Computing, </booktitle> <year> 1978, </year> <pages> pp. 114-118. </pages>
Reference-contexts: Proof. Apply Lemmas 5.13 and 5.14 and choose k = n 2 m + 2. 5.6. A Parallel Implementation. In this section, we give a parallel implementation of the bipartite excess scaling algorithm. Our model of computation is an exclusive-read exclusive-write parallel random access machine (EREW PRAM) <ref> [13] </ref>. Our algorithm runs in O (( n 1 m d + n 2 1 log U ) log d) time using d = d m n 1 e processors, thus achieving near-optimal speedup for the given number of processors.
Reference: [14] <author> G. Gallo, M. D. Grigoriadis, and R. E. Tarjan, </author> <title> A fast parametric maximum flow algorithm and applications, </title> <journal> SIAM Journal on Computing, </journal> <volume> 18 (1989), </volume> <pages> pp. </pages> <month> 30-55. </month> <title> NETWORK FLOW IN BIPARTITE GRAPHS 29 </title>
Reference-contexts: At first glance, it may appear that unbalanced networks are of limited practical utility. This is not true, however. Gusfield, Martel, and Fernandez-Baca [21] have compiled a list of many practical applications of unbalanced networks. Further applications of unbalanced networks appear in <ref> [14] </ref>. Specialized bipartite flow algorithms for unbalanced networks were first stud fl Department of Industrial and Management Engineering, Indian Institute of Technology, Kanpur 208016, India. <p> Column 3 of Table 1.1 summarizes these improvements for several network flow algorithms. We obtain further running-time improvements by modifying the algorithms. This modification applies only to preflow push algorithms <ref> [2, 3, 14, 15, 16, 17] </ref>; we call it the two-edge push rule. <p> n 1 m log ( n 2 n 2 m + 2) Parallel excess scaling [2] n 2 log U log ( m n ), n 1 n log U log ( m 1 log U log ( m dm=ne processors dm=ne processors dm=n 1 e processors Parametric Flows GGT <ref> [14] </ref> n 3 n 1 n 2 n 2 GGT w/ nm log ( n 2 m ) n 1 m log ( 1 dynamic trees [14] Min-Cost Flows Cost scaling [17] n 3 log (nC) n 2 1 n log (n 1 C) n 1 m + n 3 Cost <p> 1 n log U log ( m 1 log U log ( m dm=ne processors dm=ne processors dm=n 1 e processors Parametric Flows GGT <ref> [14] </ref> n 3 n 1 n 2 n 2 GGT w/ nm log ( n 2 m ) n 1 m log ( 1 dynamic trees [14] Min-Cost Flows Cost scaling [17] n 3 log (nC) n 2 1 n log (n 1 C) n 1 m + n 3 Cost scaling w/ nm log ( n 2 m ) n 1 m log ( n 2 n 2 m + 2) dynamic trees [17] log (nC) <p> Although this type of parameterization appears to be quite specialized, Gallo, Grigoriadis, and Tarjan <ref> [14] </ref> have pointed out that this parametric problem has many applications, in computing subgraph density and network vulnerability and in solving other problems, some of which are mentioned at the end of this section. <p> Clearly, for l different values of , a solution can be found using l invocations of a maximum flow algorithm. This approach takes no advantage of the similarity of the successive problems to be solved, however. Gallo, Grigoriadis, and Tarjan <ref> [14] </ref> gave an algorithm for finding the maximum flow for O (n) increasing values of in the same asymptotic time that it takes to run the Goldberg-Tarjan maximum flow algorithm once. <p> We can actually compute all of these breakpoints in O (n 2 + n 1 m log ( nn 1 m + 2)) time, and can do even better if we know a priori that l = o (n). This result directly follows from the results of <ref> [14] </ref> and the details appear in [35].
Reference: [15] <author> A. V. Goldberg, </author> <title> Efficient graph algorithms for sequential and parallel computers, </title> <type> PhD thesis, </type> <institution> MIT, </institution> <address> Cambridge, MA, </address> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: Column 3 of Table 1.1 summarizes these improvements for several network flow algorithms. We obtain further running-time improvements by modifying the algorithms. This modification applies only to preflow push algorithms <ref> [2, 3, 14, 15, 16, 17] </ref>; we call it the two-edge push rule. <p> We call this algorithm the generic bipartite dynamic tree algorithm. The correctness of this algorithm is straightforward to verify (see <ref> [15] </ref>, [16]). We show that this implementation yields an efficient algorithm. Lemma 5.8. The number of tree-push/relabel operations done by the generic bipartite dynamic tree algorithm is O (n 1 m). Proof. Each tree-push/relabel operation either relabels a vertex or pushes flow along a tree path. <p> In order to realize this bound, we must overcome a few obstacles. First, as in [3] and <ref> [15, 16] </ref>, we need to limit the tree size. Moreover, we need to make the tree size bound solely a function of n 1 rather than n. Finally, we must deal with the fact that a cut can make a V 2 -vertex a tree root. <p> The bi-send operation We also want to maintain the invariant that no tree have more than k vertices (k will be chosen later). As in <ref> [15, 16] </ref> we achieve this by preceding each link operation by a calculation of whether or not the result of the link will be a tree of greater than k vertices. If so, we do not perform the link. <p> Given these building blocks we can give the procedure bi-tree push/relabel, which incorporates all of these ideas. The procedure appears in Figure 5.7. The basic idea is similar to that used in <ref> [3, 15, 16] </ref>, in that we do a tree-push, but only perform a link if the size of the resulting tree is not too large. We also have the additional constraint of not performing a link that will cause a V 2 -vertex to become a leaf.
Reference: [16] <author> A. V. Goldberg and R. E. Tarjan, </author> <title> A new approach to the maximum flow problem, </title> <journal> Journal of the ACM, </journal> <volume> 35 (1988), </volume> <pages> pp. </pages> <month> 921-940. </month> <title> [17] , Solving minimum-cost flow problems by successive approximation, </title> <journal> Mathematics of Operations Research, </journal> <volume> 15 (1990), </volume> <pages> pp. 430-466. </pages>
Reference-contexts: Column 3 of Table 1.1 summarizes these improvements for several network flow algorithms. We obtain further running-time improvements by modifying the algorithms. This modification applies only to preflow push algorithms <ref> [2, 3, 14, 15, 16, 17] </ref>; we call it the two-edge push rule. <p> It is easy to establish that this flow is maximum. We shall briefly discuss the worst-case time complexity of the algorithm. (We refer the reader to the paper of Goldberg and Tarjan <ref> [16] </ref> for a complete discussion of the algorithm.) We begin by stating two lemmas from [15],[16]. Lemma 3.1. [15],[16] The generic preflow push algorithm maintains valid distance labels at each step. Moreover, each relabeling of a vertex v strictly increases d (v). Lemma 3.2. [15],[16] At any time during the preflow <p> Summing over all edges gives the bound. Lemma 3.6. The preflow push algorithm performs O (n 2 1 m) nonsaturating pushes. Proof. Omitted. (Analogous to the proof of Lemma 3.10 in <ref> [16] </ref>.) The results in Column 3 of Table 1.1 for preflow push algorithms all follow from the known results by using Corollaries 3.4 and 3.5 to replace certain O (n) bounds in the general case with O (n 1 ) bounds in the bipartite case. <p> We call this algorithm the generic bipartite dynamic tree algorithm. The correctness of this algorithm is straightforward to verify (see [15], <ref> [16] </ref>). We show that this implementation yields an efficient algorithm. Lemma 5.8. The number of tree-push/relabel operations done by the generic bipartite dynamic tree algorithm is O (n 1 m). Proof. Each tree-push/relabel operation either relabels a vertex or pushes flow along a tree path. <p> In order to realize this bound, we must overcome a few obstacles. First, as in [3] and <ref> [15, 16] </ref>, we need to limit the tree size. Moreover, we need to make the tree size bound solely a function of n 1 rather than n. Finally, we must deal with the fact that a cut can make a V 2 -vertex a tree root. <p> The bi-send operation We also want to maintain the invariant that no tree have more than k vertices (k will be chosen later). As in <ref> [15, 16] </ref> we achieve this by preceding each link operation by a calculation of whether or not the result of the link will be a tree of greater than k vertices. If so, we do not perform the link. <p> Given these building blocks we can give the procedure bi-tree push/relabel, which incorporates all of these ideas. The procedure appears in Figure 5.7. The basic idea is similar to that used in <ref> [3, 15, 16] </ref>, in that we do a tree-push, but only perform a link if the size of the resulting tree is not too large. We also have the additional constraint of not performing a link that will cause a V 2 -vertex to become a leaf. <p> We assume familiarity with parallel prefix operations [22] and refer the reader to <ref> [2, 16, 26, 32] </ref> for examples of the use of parallel prefix operations in network flow algorithms. <p> Overall this time would be O (ml) and for larger values of l would be a bottleneck. In order to achieve a faster time bound we maintain exact distance labels of vertices as explained in <ref> [16] </ref>. Maintaining exact distance labels requires some additional effort but no more than O (n 1 m) time over all iterations.
Reference: [18] <author> A. V. Goldberg, R. E. Tarjan, and E. Tardos, </author> <title> Network flow algorithms, in Paths, Flows, </title> <editor> and VLSI-Layout, B. Korte, L. Lovasz, H. Promel, and A. Shriver, eds., </editor> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990, </year> <pages> pp. 101-164. </pages>
Reference: [19] <author> D. Gusfield, </author> <title> Connectivity and edge disjoint spanning trees, </title> <journal> Information Processing Letters, </journal> <volume> 16 (1983), </volume> <pages> pp. 87-89. </pages> <note> [20] , Computing the strength of a graph. submitted for publication, </note> <month> July </month> <year> 1989. </year>
Reference-contexts: We conclude by noting that the bipartite parametric flow problem has many applications including multiprocessor scheduling with release times and deadlines [21, 24], 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability <ref> [9, 19] </ref>, partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem [23, 31]. For all these problems we improve on or match the best known bounds. 7. Minimum-Cost Circulation. In this section we examine the minimum-cost flow problem on bipartite networks.
Reference: [21] <author> D. Gusfield, C. Martel, and D. Fernandez-Baca, </author> <title> Fast algorithms for bipartite network flow, </title> <journal> SIAM J. Comput., </journal> <month> 16 </month> <year> (1987). </year>
Reference-contexts: We show that several maximum flow algorithms can be substantially sped up when applied to unbalanced networks. At first glance, it may appear that unbalanced networks are of limited practical utility. This is not true, however. Gusfield, Martel, and Fernandez-Baca <ref> [21] </ref> have compiled a list of many practical applications of unbalanced networks. Further applications of unbalanced networks appear in [14]. Specialized bipartite flow algorithms for unbalanced networks were first stud fl Department of Industrial and Management Engineering, Indian Institute of Technology, Kanpur 208016, India. <p> Research at Princeton University partially supported by the National Science Foundation, Grant DCR-8605952, and the Office of Naval Research, Contract N00014-91-K-1463. 2 R. AHUJA, J. ORLIN, C. STEIN AND R. TARJAN ied by Gusfield, Martel, and Fernandez-Baca <ref> [21] </ref>. They developed modifications of the algorithms of Karzanov [25] and Malhotra, Pramodh Kumar, and Maheshwari (MPM)[27] for the maximum flow problem that improved their running times from O (n 3 ) to O (n 2 1 n 2 ). <p> source s and sink t be the two distinguished NETWORK FLOW IN BIPARTITE GRAPHS 3 Algorithm Running time, Running time, Running time, general network bipartite network modified version Maximum Flows Dinic [10] n 2 m n 2 1 m does not apply Karzanov [25] n 3 n 2 1 n <ref> [21] </ref> n 1 m + n 3 MPM [27] n 3 n 2 1 n [21] does not apply FIFO preflow push n 3 n 2 1 n n 1 m + n 3 [15],[16] Highest label n 2 p m n 1 n m n 1 m preflow push [7] <p> Algorithm Running time, Running time, Running time, general network bipartite network modified version Maximum Flows Dinic [10] n 2 m n 2 1 m does not apply Karzanov [25] n 3 n 2 1 n <ref> [21] </ref> n 1 m + n 3 MPM [27] n 3 n 2 1 n [21] does not apply FIFO preflow push n 3 n 2 1 n n 1 m + n 3 [15],[16] Highest label n 2 p m n 1 n m n 1 m preflow push [7] + minfn 3 1 ; n 2 p Excess scaling [2] nm + n 2 <p> This result directly follows from the results of [14] and the details appear in [35]. We conclude by noting that the bipartite parametric flow problem has many applications including multiprocessor scheduling with release times and deadlines <ref> [21, 24] </ref>, 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability [9, 19], partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem [23, 31]. <p> This result directly follows from the results of [14] and the details appear in [35]. We conclude by noting that the bipartite parametric flow problem has many applications including multiprocessor scheduling with release times and deadlines [21, 24], 0-1 integer programming problems [29, 30], maximum subgraph density <ref> [21] </ref>, finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability [9, 19], partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem [23, 31]. <p> Summary and Conclusions. We have considered a number of maximum flow algorithms and algorithms for other network flow problems for bipartite networks in which one side is much smaller than the other. Our work is motivated by and improves upon the work of Gusfield, Martel, and Fernandez-Baca <ref> [21] </ref>. In that paper, the authors demonstrated the importance of bipartite maximum flow problems in which one side is much smaller than the other. In addition, they showed that existing algorithms run much faster on these "unbalanced" networks. We have extended the results of Gusfield et al. in several ways.
Reference: [22] <author> W. Hillis and J. G.L. Steele, </author> <title> Data parallel algorithms, </title> <journal> Communications of the ACM, </journal> <volume> 29 (1986), </volume> <pages> pp. 1170-1183. </pages>
Reference-contexts: Our algorithm runs in O (( n 1 m d + n 2 1 log U ) log d) time using d = d m n 1 e processors, thus achieving near-optimal speedup for the given number of processors. We assume familiarity with parallel prefix operations <ref> [22] </ref> and refer the reader to [2, 16, 26, 32] for examples of the use of parallel prefix operations in network flow algorithms.
Reference: [23] <author> A. Hoffman and T. Rivlin, </author> <title> When is a team "mathematically" eliminated?, </title> <booktitle> in Symposium on Mathematical Programming, </booktitle> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1970, </year> <pages> pp. 391-396. </pages>
Reference-contexts: release times and deadlines [21, 24], 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability [9, 19], partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem <ref> [23, 31] </ref>. For all these problems we improve on or match the best known bounds. 7. Minimum-Cost Circulation. In this section we examine the minimum-cost flow problem on bipartite networks.
Reference: [24] <author> W. Horn, </author> <title> Some simple scheduling algorithms, </title> <journal> Naval Research Logistics Quarterly, </journal> <volume> 21 (1974), </volume> <pages> pp. 177-185. </pages>
Reference-contexts: This result directly follows from the results of [14] and the details appear in [35]. We conclude by noting that the bipartite parametric flow problem has many applications including multiprocessor scheduling with release times and deadlines <ref> [21, 24] </ref>, 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability [9, 19], partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem [23, 31].
Reference: [25] <author> A. V. Karzanov, </author> <title> Determining the maximal flow in a network by the method of preflows, </title> <journal> Soviet Math. Dokl., </journal> <volume> 15 (1974), </volume> <pages> pp. 434-437. </pages>
Reference-contexts: Research at Princeton University partially supported by the National Science Foundation, Grant DCR-8605952, and the Office of Naval Research, Contract N00014-91-K-1463. 2 R. AHUJA, J. ORLIN, C. STEIN AND R. TARJAN ied by Gusfield, Martel, and Fernandez-Baca [21]. They developed modifications of the algorithms of Karzanov <ref> [25] </ref> and Malhotra, Pramodh Kumar, and Maheshwari (MPM)[27] for the maximum flow problem that improved their running times from O (n 3 ) to O (n 2 1 n 2 ). <p> Let source s and sink t be the two distinguished NETWORK FLOW IN BIPARTITE GRAPHS 3 Algorithm Running time, Running time, Running time, general network bipartite network modified version Maximum Flows Dinic [10] n 2 m n 2 1 m does not apply Karzanov <ref> [25] </ref> n 3 n 2 1 n [21] n 1 m + n 3 MPM [27] n 3 n 2 1 n [21] does not apply FIFO preflow push n 3 n 2 1 n n 1 m + n 3 [15],[16] Highest label n 2 p m n 1 n <p> Thus we obtain the following result: Theorem 5.2. The bipartite FIFO preflow push algorithm runs in O (n 1 m + n 3 1 ) time. We note that this bound is also achieved by Karzanov's algorithm <ref> [25] </ref> if it is implemented using the two-edge push rule. A modification of Karzanov's algorithm by Tarjan [36], which he calls the wave algorithm, also has the same time bound. The analysis of both of these algorithms is straightforward and hence omitted. 5.2. The Highest-Label Preflow Push Algorithm.
Reference: [26] <author> T. Leighton, C. Leiserson, B. Maggs, S. Plotkin, and J. Wein, </author> <title> Advanced parallel and VLSI computation, </title> <booktitle> Research Seminar Series MIT/LCS/RSS 2, </booktitle> <publisher> MIT, </publisher> <year> 1988. </year>
Reference-contexts: We assume familiarity with parallel prefix operations [22] and refer the reader to <ref> [2, 16, 26, 32] </ref> for examples of the use of parallel prefix operations in network flow algorithms.
Reference: [27] <author> V. M. Malhotra, M. P. Kumar, and S. N. Maheshwari, </author> <title> An O(jV j 3 ) algorithm for finding maximum flows in networks, </title> <journal> Information Processing Letters, </journal> <volume> 7 (1978), </volume> <pages> pp. 277-278. </pages>
Reference-contexts: distinguished NETWORK FLOW IN BIPARTITE GRAPHS 3 Algorithm Running time, Running time, Running time, general network bipartite network modified version Maximum Flows Dinic [10] n 2 m n 2 1 m does not apply Karzanov [25] n 3 n 2 1 n [21] n 1 m + n 3 MPM <ref> [27] </ref> n 3 n 2 1 n [21] does not apply FIFO preflow push n 3 n 2 1 n n 1 m + n 3 [15],[16] Highest label n 2 p m n 1 n m n 1 m preflow push [7] + minfn 3 1 ; n 2 p
Reference: [28] <author> C. S. J. A. Nash-Williams, </author> <title> Edge disjoint spanning trees of finite graphs, </title> <journal> Journal of the London Mathematics Society, </journal> <volume> 36 (1961), </volume> <pages> pp. 445-450. </pages>
Reference-contexts: We conclude by noting that the bipartite parametric flow problem has many applications including multiprocessor scheduling with release times and deadlines [21, 24], 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph <ref> [28, 29, 30] </ref>, network vulnerability [9, 19], partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem [23, 31]. For all these problems we improve on or match the best known bounds. 7. Minimum-Cost Circulation.
Reference: [29] <author> J. Picard and M. Querayne, </author> <title> A network flow solution to some nonlinear 0-1 programming problems, with applications to graph theory, Networks, </title> <booktitle> 12 (1982), </booktitle> <pages> pp. </pages> <month> 141-159. </month> <title> [30] , Selected applications of minimum cuts in networks, </title> <journal> INFOR., </journal> <volume> 20 (1982), </volume> <pages> pp. 394-422. </pages>
Reference-contexts: This result directly follows from the results of [14] and the details appear in [35]. We conclude by noting that the bipartite parametric flow problem has many applications including multiprocessor scheduling with release times and deadlines [21, 24], 0-1 integer programming problems <ref> [29, 30] </ref>, maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability [9, 19], partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem [23, 31]. <p> We conclude by noting that the bipartite parametric flow problem has many applications including multiprocessor scheduling with release times and deadlines [21, 24], 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph <ref> [28, 29, 30] </ref>, network vulnerability [9, 19], partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem [23, 31]. For all these problems we improve on or match the best known bounds. 7. Minimum-Cost Circulation.
Reference: [31] <author> B. Schwartz, </author> <title> Possible winners in partially completed tournaments, </title> <journal> SIAM Review, </journal> <volume> 8 (1966), </volume> <pages> pp. 302-388. </pages>
Reference-contexts: release times and deadlines [21, 24], 0-1 integer programming problems [29, 30], maximum subgraph density [21], finding a maximum-size set of edge-disjoint spanning trees in an undirected graph [28, 29, 30], network vulnerability [9, 19], partitioning a data base between fast and slow memory [11], and the sportswriter's end-of-season problem <ref> [23, 31] </ref>. For all these problems we improve on or match the best known bounds. 7. Minimum-Cost Circulation. In this section we examine the minimum-cost flow problem on bipartite networks.
Reference: [32] <author> Y. Shiloach and U. Vishkin, </author> <title> An O(log n) parallel connectivity algorithm, </title> <journal> Journal of Algorithms, </journal> <volume> 3 (1982), </volume> <pages> pp. 57-67. </pages>
Reference-contexts: We assume familiarity with parallel prefix operations [22] and refer the reader to <ref> [2, 16, 26, 32] </ref> for examples of the use of parallel prefix operations in network flow algorithms.
Reference: [33] <author> D. Sleator and R. Tarjan, </author> <title> Self-adjusting binary search trees, </title> <journal> Journal of the ACM, </journal> <volume> 32 (1985), </volume> <pages> pp. 652-686. </pages>
Reference-contexts: The idea is to use a sophisticated data structure in order to push flow along a whole path in one step, rather than pushing flow along a single edge. The dynamic tree data structure of Sleator and Tarjan <ref> [34, 33, 37] </ref> is ideally suited for this purpose. The dynamic tree data structure allows the maintenance of a collection of vertex-disjoint rooted trees, each edge of which has an associated real value. We adopt the convention that tree edges are directed towards the root.
Reference: [34] <author> D. D. Sleator and R. Tarjan, </author> <title> A data structure for dynamic trees, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 26 (1983), </volume> <pages> pp. 362-391. </pages>
Reference-contexts: The idea is to use a sophisticated data structure in order to push flow along a whole path in one step, rather than pushing flow along a single edge. The dynamic tree data structure of Sleator and Tarjan <ref> [34, 33, 37] </ref> is ideally suited for this purpose. The dynamic tree data structure allows the maintenance of a collection of vertex-disjoint rooted trees, each edge of which has an associated real value. We adopt the convention that tree edges are directed towards the root. <p> The tree-push/relabel operation v by p (v) and regard each vertex as an ancestor and descendent of itself. We call a dynamic tree trivial if it contains only one V 2 -vertex and non-trivial otherwise. The data structure supports the operations in Figure 5.2. It is shown in <ref> [34] </ref> that if the maximum number of vertices in any tree is k, we can perform an arbitrary sequence of l tree operations in O (l log k) time. In maximum flow algorithms, the dynamic tree edges are a subset of the current edges.
Reference: [35] <author> C. Stein, </author> <title> Efficient algorithms for bipartite network flow. </title> <type> Unpublished Manuscript, </type> <year> 1987. </year>
Reference-contexts: AFOSR-88-0088 from the Air Force Office of Scientific Research, and by grants from Analog Devices, Apple Computers, Inc., and Prime Computer. z Department of Mathematics and Computer Science, Dartmouth College, Hanover, NH 03755 Some of the results in this paper were part of this author's undergraduate thesis at Princeton University <ref> [35] </ref>. Some of the work was done while this author was a graduate student at the Laboratory for Computer Science, M.I.T., Cambridge, MA 02139. Research partially supported by a graduate fellowship from AT&T. <p> This result directly follows from the results of [14] and the details appear in <ref> [35] </ref>.
Reference: [36] <author> R. E. Tarjan, </author> <title> A simple version of Karzanov's blocking flow algorithm, </title> <journal> Operations Research Letters, </journal> <volume> 2 (1981), </volume> <pages> pp. </pages> <month> 265-268. </month> <title> [37] , Data structures and network algorithms, </title> <publisher> SIAM, </publisher> <address> Philadelphia, PA, </address> <year> 1983. </year>
Reference-contexts: The bipartite FIFO preflow push algorithm runs in O (n 1 m + n 3 1 ) time. We note that this bound is also achieved by Karzanov's algorithm [25] if it is implemented using the two-edge push rule. A modification of Karzanov's algorithm by Tarjan <ref> [36] </ref>, which he calls the wave algorithm, also has the same time bound. The analysis of both of these algorithms is straightforward and hence omitted. 5.2. The Highest-Label Preflow Push Algorithm. The highest-label pre-flow push algorithm always pushes from an active vertex with highest distance label.
References-found: 33

