URL: ftp://mancos.cs.utah.edu/papers/thread-migrate.ps.Z
Refering-URL: ftp://mancos.cs.utah.edu/papers/thread-migrate.html
Root-URL: 
Title: Evolving Mach 3.0 to a Migrating Thread Model  
Author: Bryan Ford Jay Lepreau 
Affiliation: University of Utah  
Abstract: We have modified Mach 3.0 to treat cross-domain remote procedure call (RPC) as a single entity, instead of a sequence of message passing operations. With RPC thus elevated, we improved the transfer of control during RPC by changing the thread model. Like most operating systems, Mach views threads as statically associated with a single task, with two threads involved in an RPC. An alternate model is that of migrating threads, in which, during RPC, a single thread abstraction moves between tasks with the logical flow of control, and "server" code is passively executed. We have compatibly replaced Mach's static threads with migrating threads, in an attempt to isolate this aspect of operating system design and implementation. The key element of our design is a decoupling of the thread abstraction into the execution context and the schedulable thread of control, consisting of a chain of contexts. A key element of our implementation is that threads are now "based" in the kernel, and temporarily make excursions into tasks via upcalls. The new system provides more precisely defined semantics for thread manipulation and additional control operations, allows scheduling and accounting attributes to follow threads, simplifies kernel code, and improves RPC performance. We have retained the old thread and IPC interfaces for backwards compatibility, with no changes required to existing client programs and only a minimal change to servers, as demonstrated by a functional Unix single server and clients. The logical complexity along the critical RPC path has been reduced by a factor of nine. Local RPC, doing normal marshaling, has sped up by factors of 1.7-3.4. We conclude that a migrating-thread model is superior to a static model, that kernel-visible RPC is a prerequisite for this improvement, and that it is feasible to improve existing operating systems in this manner. 1 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Thomas E. Anderson, Brian N. Bershad, Edward D. Lazowska, and Henry M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(1) </volume> <pages> 53-79, </pages> <month> February </month> <year> 1992. </year>
Reference: [2] <author> J. S. Barrera. </author> <title> A fast Mach network IPC implementation. </title> <booktitle> In Proc. of the Second USENIX Mach Symposium, </booktitle> <pages> pages 1-12, </pages> <year> 1991. </year>
Reference: [3] <author> Brian N. Bershad, Thomas E. Anderson, Edward D. Lazowska, and Henry M. Levy. </author> <title> Lightweight remote procedure call. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 8(1) </volume> <pages> 37-55, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: In both of these systems a thread can migrate across nodes in a distributed environment, and indeed Alpha's term for a migrating thread is a "distributed thread." Psyche [27] is a single-address-space system that supports migrating threads. The Lightweight RPC system <ref> [3] </ref> on Taos exploited 3 migrating threads (control transfer) as a critical part of its design, but focused on high-performance local RPC, and included additional data transfer optimizations. This makes it difficult to isolate the benefits of the improved control transfer. <p> Using migrating threads for RPC provides benefits in performance, functionality, and in ease of implementation. Since RPC is very frequently used <ref> [3] </ref>, especially in newer microkernel-based operating systems where most internal system interactions are based on RPC, this aspect of the system can be of great importance in determining the performance and functionality of the system as a whole. <p> No synchronization, rescheduling, or full context switch need be done. Thread migration also permits optimizations such as those done in LRPC <ref> [3] </ref> and in other flexibly structured or shared address space systems, e.g., Lipto [15], FLEX [7], and Mach In-Kernel Servers [22, 17]. In these systems there is some degree of inter-domain memory sharing or protection relaxation, thus blurring domain boundaries. <p> This makes it feasible to decouple them entirely, enabling a full implementation of priority inheritance. The Mach message format imposes unnecessary overhead on migrating RPC. The migrating thread model enables other designs which could provide much higher performance, such as LRPC <ref> [3] </ref>. In cases where protection domains have been merged [22], much of the copying can be avoided. The migrating RPC mechanism can also be used in thread exception processing. This will allow a no-emulator server, such as OSF/1-MK5 [25], to do more efficient argument copying.
Reference: [4] <author> Andrew D. Birrell. </author> <title> An introduction to programming with threads. </title> <type> Technical Report SRC-35, </type> <institution> DEC Systems Research Center, </institution> <month> January </month> <year> 1989. </year>
Reference-contexts: We explain how kernel threads interact in implementing RPC, and the difference between implementing RPC with static and migrating threads. Threads As the term is used in most operating systems and thread packages, conceptually a thread is a sequential flow of control <ref> [4] </ref>. In traditional Unix, a single process contains only a single kernel-provided thread. Mach and many other modern operating systems support multiple threads per process (per task in Mach terminology), called kernel threads. <p> Alerts are much like those in Spring [19], The "Alert" and "TestAlert" facilities of Taos <ref> [4] </ref> are analogous, but apparently do not operate cross-domain. By default, new activations added to a thread's stack have alerts blocked, to prevent interference with an unwary server's functioning.
Reference: [5] <author> A. P. Black, N. Huchinson, E. Jul, H. Levy, and L. Carter. </author> <title> Distribution and abstract types in Emerald. </title> <journal> IEEE Trans on Software Engineering, </journal> <volume> SE-13(1):65-76, </volume> <year> 1987. </year>
Reference-contexts: This makes it difficult to isolate the benefits of the improved control transfer. Object-oriented systems have traditionally distinguished between "active" and "passive" objects, corresponding to static and migrating thread models [9]. Clouds [16] exemplifies a passive object (migrating thread) model, while Emerald <ref> [5] </ref>, as we do, provides both active and passive objects| support for both styles of execution. Chorus [26] can use only thread-switching between user-level tasks, but between tasks running in the kernel's protection domain it has "message handlers" which operate in a migrating thread model.
Reference: [6] <author> Alan C. Bomberger and Norman Hardy. </author> <booktitle> The KeyKOS nanokernel architecture. In Proc. of the USENIX Workshop on Micro-kernels and Other Kernel Architectures, </booktitle> <pages> pages 95-112, </pages> <address> Seattle, WA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: In well-designed servers providing "system" functions, we suspect that internal contention can be minimized so that the importance of RPC speed outweighs that of context switch speed. We point out that in many commercial microkernel-based systems, including QNX [20], Chorus [26], and KeyKOS <ref> [6] </ref>, OS servers do not generally multiplex user-level threads over multiple kernel threads. Instead, these systems either provide multithreading purely with kernel threads, or their functions are sufficiently decomposed so that each server can be based on a single kernel thread, requiring no internal synchronization.
Reference: [7] <author> John B. Carter, Bryan Ford, Mike Hibler, Ravindra Kuramkote, Jeffrey Law, Jay Lepreau, Douglas B. Orr, Leigh Stoller, and Mark Swanson. </author> <title> FLEX: A tool for building efficient and flexible systems. </title> <booktitle> In Proc. Fourth Workshop on Workstation Operating Systems, </booktitle> <month> October </month> <year> 1993. </year>
Reference-contexts: No synchronization, rescheduling, or full context switch need be done. Thread migration also permits optimizations such as those done in LRPC [3] and in other flexibly structured or shared address space systems, e.g., Lipto [15], FLEX <ref> [7] </ref>, and Mach In-Kernel Servers [22, 17]. In these systems there is some degree of inter-domain memory sharing or protection relaxation, thus blurring domain boundaries.
Reference: [8] <author> D. R. Cheriton. </author> <title> The V distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 31(3) </volume> <pages> 314-333, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: to itself. one can perform operations on the object it represents. 3 Sometimes this invocation of the scheduler is heavily optimized and inlined into the IPC path, but it is still there. 4 The "process model" is in contrast to the "interrupt model," as exemplified by the V operating system <ref> [8] </ref>, in which kernel code must explicitly save state before potentially blocking. 2 Static vs. Migrating Threads In actuality, there is a continuum between these two models.
Reference: [9] <author> Roger S. Chin and Samuel T. Chanson. </author> <title> Distributed object-based programming systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 23(1), </volume> <month> March </month> <year> 1991. </year>
Reference-contexts: In the object-oriented world, this is known as an "active object" model <ref> [9] </ref>, because a server "object" contains threads that actively provide service. Migrating Threads If RPC is fully visible to the kernel, an alternate model of control transfer can be implemented. Migrating threads allows threads to "move" from one task to another as part of their normal functioning. <p> This makes it difficult to isolate the benefits of the improved control transfer. Object-oriented systems have traditionally distinguished between "active" and "passive" objects, corresponding to static and migrating thread models <ref> [9] </ref>. Clouds [16] exemplifies a passive object (migrating thread) model, while Emerald [5], as we do, provides both active and passive objects| support for both styles of execution.
Reference: [10] <author> David D. Clark. </author> <title> The structuring of systems using upcalls. </title> <booktitle> In Proc. of the 10th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 171-180, </pages> <address> Orcas Island, WA, </address> <month> December </month> <year> 1985. </year>
Reference-contexts: The initial and normal location of a thread was in user space, and threads only "visited" the kernel occasionally, to request services. In our migrating thread implementation, the situation is in a sense reversed. A thread starts executing as a purely kernel-mode entity, and later makes an upcall <ref> [10] </ref> into user space to run user code. Conceptually, the kernel is "home base" for all threads: the only time user-level code is executed is during "temporary excursions" into a task.
Reference: [11] <author> Raymond K. Clark, E. Douglas Jensen, and Franklin D. Reynolds. </author> <title> An architectural overview of the Alpha real-time distributed kernel. </title> <booktitle> In Proc. of the USENIX Workshop on Micro-kernels and Other Kernel Architectures, </booktitle> <pages> pages 127-146, </pages> <address> Seattle, WA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Sun's Spring [19] operating system supports a migrating thread model very similar to ours, although it uses different terminology. Spring's "shuttle" corresponds to our "thread," and their "thread" corresponds to our "activation." Spring addresses the controllability issues but did not have to be concerned with backwards compatibility. Alpha <ref> [11] </ref> was probably the first system to fully adopt migrating threads. It is oriented to real-time constraints, and its migrating thread abstraction is especially important for carrying along scheduling, exception-handling, and resource attributes. <p> The majority of the benefits are linked to use with RPC and are described first. But there are also controllability advantages for threads during all kernel interaction, and these are outlined in section 3.2. In the context of the Alpha OS, <ref> [11] </ref> also discusses many advantages offered by migrating threads. 3.1 Remote Procedure Call Many of the advantages of migrating threads stem from their use in conjunction with RPC. Migrating threads provide a more appropriate underlying abstraction on which to build RPC interfaces than do static threads. <p> The "NORMA" (NO Remote Memory Access)[2] version of Mach 3.0 allows IPC between different nodes of a distributed memory multiprocessor, implemented in the microkernel. Extending the migrating thread system to encompass RPC between nodes should be done. The issues involved have already been explored in depth in Alpha <ref> [11] </ref>. Going in a different direction, our work allows improvements in Mach's support for real-time systems. At the implementation level, we have largely decoupled two portions of the thread abstraction: the schedulable entity (priority, scheduling policies, etc.) from the thread of control (the chain of activations).
Reference: [12] <author> Michael Condict. </author> <type> Personal communication, </type> <month> November </month> <year> 1993. </year>
Reference-contexts: The last aspect is particularly awkward because it requires surrounding every such blocking call with operations to wake up and manage server threads. If it does not, deadlock can result. Finally, substantial complexity is due to multiplexing cthreads over kernel threads, which cannot be done with migrating threads <ref> [12] </ref>. 8 However, if it is found necessary to limit the total number of executing threads in a particular server, in order to avoid saturation due to excessive kernel context switching, some of this simplification will not be present. 6.3 User-level Thread Issues The most important issue with migrating RPC is
Reference: [13] <author> Sadegh Davari and Lui Sha. </author> <title> Sources of unbounded priority inversions in real-time systems and a comparative study of possible solutions. </title> <journal> ACM Operating Systems Review, </journal> <volume> 23(2) </volume> <pages> 110-120, </pages> <month> April </month> <year> 1992. </year> <month> 17 </month>
Reference-contexts: Unless specific actions are taken, the attributes of the thread in the server will be completely unrelated to those of the client thread. This can cause the classic problems of starvation and priority inversion <ref> [13] </ref>, when a high-priority client is unfairly made to compete with low-priority clients that are accessing the same server. On the other hand, if the client thread migrates into the server to perform the operation, all such attributes can be properly maintained with no extra effort.
Reference: [14] <author> Richard P. Draves, Brian N. Bershad, Richard F. Rashid, and Randall W. Dean. </author> <title> Using continuations to implement thread management and communication in operating systems. </title> <booktitle> In Proc. of the 13th ACM Symposium on Operating Systems Principles, Asilomar, </booktitle> <address> CA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: This explicit saving of state is generically known as using a continuation, although our implementation is very different from the way continuations have been used in Mach in the past <ref> [14] </ref>. In particular, we confine continuations purely to "glue" (transition) code; all high-level kernel code uses an ordinary process model. 5 Controllability: Semantics, Interface, and Implementation In this section we describe the semantics of thread control operations, the interface to those operations, and some aspects of the implementation. <p> Those who differ are invited to inspect the original message path and try to hand-code it without changing its semantics. 15 8.6 Memory Use In the original microkernel, in general only a few kernel stacks (8K each) were required per processor, due to the continuations mechanism <ref> [14] </ref>. At the beginning of this project, we disabled continuations in order to simplify our work; this immediately raised kernel memory use to one kernel stack per thread.
Reference: [15] <author> Peter Druschel, Larry L. Peterson, and Norman C. Hutchinson. </author> <title> Beyond micro-kernel design: Decou-pling modularity and protection in Lipto. </title> <booktitle> In Proc. of the 12th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 512-520, </pages> <address> Yokohama, Japan, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: No synchronization, rescheduling, or full context switch need be done. Thread migration also permits optimizations such as those done in LRPC [3] and in other flexibly structured or shared address space systems, e.g., Lipto <ref> [15] </ref>, FLEX [7], and Mach In-Kernel Servers [22, 17]. In these systems there is some degree of inter-domain memory sharing or protection relaxation, thus blurring domain boundaries.
Reference: [16] <author> Partha Dasgupta et al. </author> <title> The design and implementation of the Clouds distributed operating system. </title> <journal> Computing Systems, </journal> <volume> 3(1), </volume> <month> Winter </month> <year> 1990. </year>
Reference-contexts: This makes it difficult to isolate the benefits of the improved control transfer. Object-oriented systems have traditionally distinguished between "active" and "passive" objects, corresponding to static and migrating thread models [9]. Clouds <ref> [16] </ref> exemplifies a passive object (migrating thread) model, while Emerald [5], as we do, provides both active and passive objects| support for both styles of execution.
Reference: [17] <author> Bryan Ford, Mike Hibler, and Jay Lepreau. </author> <title> Notes on thread models in Mach 3.0. </title> <type> Technical Report UUCS-93-012, </type> <institution> University of Utah Computer Science Department, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: No synchronization, rescheduling, or full context switch need be done. Thread migration also permits optimizations such as those done in LRPC [3] and in other flexibly structured or shared address space systems, e.g., Lipto [15], FLEX [7], and Mach In-Kernel Servers <ref> [22, 17] </ref>. In these systems there is some degree of inter-domain memory sharing or protection relaxation, thus blurring domain boundaries. RPC implemented by threads that migrate from one domain to another can take advantage of this boundary blurring, providing many optimizations in argument passing and stack handling. <p> Our earlier work on moving trusted servers into the kernel's protection domain and address space (INKS)[22] used ad-hoc thread migration. By re-working the thread abstraction from scratch, our new system solves all of the problems encountered <ref> [17] </ref>. The "NORMA" (NO Remote Memory Access)[2] version of Mach 3.0 allows IPC between different nodes of a distributed memory multiprocessor, implemented in the microkernel. Extending the migrating thread system to encompass RPC between nodes should be done. The issues involved have already been explored in depth in Alpha [11].
Reference: [18] <author> Bryan Ford and Jay Lepreau. </author> <title> Evolving Mach 3.0 to use migrating threads. </title> <type> Technical Report UUCS-93-022, </type> <institution> University of Utah, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: However, because of the problems with the complete controllability model, many of the things for which the CPU state control mechanisms are commonly thought to be useful, in fact cannot be reliably implemented in bounded time in Mach 3.0 <ref> [18] </ref>. For example, encapsulation of a task's state for checkpointing or transportation to another node either may require the controlling thread to wait an arbitrarily long time, or else requires aborting kernel operations, yielding potentially inaccurate state. <p> Also, kernel-visible synchronization will be necessary to fully implement priority inheritance, as we discuss in a longer paper <ref> [18] </ref>. <p> Desirable Modifications We anticipate that the Unix server could be made simpler with two modifications that take advantage of migrating threads. One is emulating Unix signals under Mach, and is described in <ref> [18] </ref>. Another is that because Mach 3.0 provides no standard way of propagating abort requests into RPCs, the Unix server must manually handle all Unix system call interruptions such as those caused by pending signals.
Reference: [19] <author> Graham Hamilton and Panos Kougiouris. </author> <title> The Spring nucleus: a microkernel for objects. </title> <booktitle> In Proc. of the Summer 1993 USENIX Conference, </booktitle> <pages> pages 147-159, </pages> <address> Cincinnati, OH, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: Finally, we present the implementation status and preliminary results, outline future work, and the conclusions we draw from this work. 2 Related Work Most operating systems use a static thread model, but there are a number of exceptions. Sun's Spring <ref> [19] </ref> operating system supports a migrating thread model very similar to ours, although it uses different terminology. Spring's "shuttle" corresponds to our "thread," and their "thread" corresponds to our "activation." Spring addresses the controllability issues but did not have to be concerned with backwards compatibility. <p> Alerts are much like those in Spring <ref> [19] </ref>, The "Alert" and "TestAlert" facilities of Taos [4] are analogous, but apparently do not operate cross-domain. By default, new activations added to a thread's stack have alerts blocked, to prevent interference with an unwary server's functioning.
Reference: [20] <author> Dan Hildebrand. </author> <title> An architectural overview of QNX. </title> <booktitle> In Proc. of the USENIX Workshop on Micro-kernels and Other Kernel Architectures, </booktitle> <pages> pages 113-126, </pages> <address> Seattle, WA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Migrating Threads In actuality, there is a continuum between these two models. For example, in some systems such as QNX <ref> [20] </ref>, certain client thread attributes, such as priority, can be passed along to ("inherited by") the server's thread. Or a service thread may retain no state between client invocations, only providing resources for execution, as in the Peregrine RPC system [21]. <p> While the existence of fast, efficient microkernels based on static threads demonstrates that high performance is possible in that model, such systems often impose semantic restrictions that distort their implementation towards a migrating thread model. For example, QNX <ref> [20] </ref>, a commercial real-time operating system, supports only unqueued, synchronous, direct process-to-process message passing with priority inheritance; this design makes it a de facto migrating threads system. <p> The distinction between the kernel and glue code is often 6 overlooked because both types of code usually execute in supervisor mode and are often linked together in a single binary image. However, this does not necessarily have to be the case; for example, in QNX <ref> [20] </ref>, the 7K "microkernel" consists of essentially nothing but glue code, while the "kernel proper" is placed in a specially privileged but otherwise ordinary process. <p> In well-designed servers providing "system" functions, we suspect that internal contention can be minimized so that the importance of RPC speed outweighs that of context switch speed. We point out that in many commercial microkernel-based systems, including QNX <ref> [20] </ref>, Chorus [26], and KeyKOS [6], OS servers do not generally multiplex user-level threads over multiple kernel threads. Instead, these systems either provide multithreading purely with kernel threads, or their functions are sufficiently decomposed so that each server can be based on a single kernel thread, requiring no internal synchronization.
Reference: [21] <author> D.B. Johnson and W. Zwaenepoel. </author> <title> The Peregrine high-performance RPC system. </title> <journal> Software | Practice and Experience, </journal> <volume> 23(2) </volume> <pages> 201-221, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: For example, in some systems such as QNX [20], certain client thread attributes, such as priority, can be passed along to ("inherited by") the server's thread. Or a service thread may retain no state between client invocations, only providing resources for execution, as in the Peregrine RPC system <ref> [21] </ref>. Thus it can become impossible to precisely classify every thread and RPC implementation.
Reference: [22] <author> Jay Lepreau, Mike Hibler, Bryan Ford, and Jeff Law. </author> <title> In-kernel servers on Mach 3.0: Implementation and performance. </title> <booktitle> In Proc. of the Third USENIX Mach Symposium, </booktitle> <pages> pages 39-55, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: No synchronization, rescheduling, or full context switch need be done. Thread migration also permits optimizations such as those done in LRPC [3] and in other flexibly structured or shared address space systems, e.g., Lipto [15], FLEX [7], and Mach In-Kernel Servers <ref> [22, 17] </ref>. In these systems there is some degree of inter-domain memory sharing or protection relaxation, thus blurring domain boundaries. RPC implemented by threads that migrate from one domain to another can take advantage of this boundary blurring, providing many optimizations in argument passing and stack handling. <p> The Mach message format imposes unnecessary overhead on migrating RPC. The migrating thread model enables other designs which could provide much higher performance, such as LRPC [3]. In cases where protection domains have been merged <ref> [22] </ref>, much of the copying can be avoided. The migrating RPC mechanism can also be used in thread exception processing. This will allow a no-emulator server, such as OSF/1-MK5 [25], to do more efficient argument copying.
Reference: [23] <author> Jochen Liedtke. </author> <title> Improving IPC by kernel design. </title> <booktitle> In Proc. of the 14th ACM Symposium on Operating Systems Principles, </booktitle> <address> Asheville, NC, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: For example, QNX [20], a commercial real-time operating system, supports only unqueued, synchronous, direct process-to-process message passing with priority inheritance; this design makes it a de facto migrating threads system. Other microkernels, such as L3 <ref> [23] </ref>, retain the full semantics of static threads, but to achieve high performance must impose severe restrictions on the flexibility of scheduling and other aspects of the system not directly related to RPC. <p> Although sometimes difficult, most architectures can achieve the single direct copy when the date are contiguous, for example by temporary mapping <ref> [23] </ref>.
Reference: [24] <institution> Open Systems Foundation and Carnegie Mellon Univ. </institution> <note> MACH 3 Kernel Interface, </note> <year> 1992. </year>
Reference-contexts: In the rest of this paper, we use the term "thread" to refer to a kernel thread, unless qualified. In most operating systems, a thread includes much more than the flow of control. For example, in Mach 3.0 <ref> [24] </ref> a thread also (i) is the schedulable entity, with priority and scheduling policy attributes; (ii) contains resource accounting statistics such as accumulated CPU time; (iii) contains the execution context of a computation|the state of the registers, program counter, stack pointer, and references to the containing task and designated exception handler;
Reference: [25] <author> Simon Patience. </author> <title> Redirecting system calls in Mach 3.0: An alternative to the emulator. </title> <booktitle> In Proc. of the Third USENIX Mach Symposium, </booktitle> <pages> pages 57-73, </pages> <address> Santa Fe, NM, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: In cases where protection domains have been merged [22], much of the copying can be avoided. The migrating RPC mechanism can also be used in thread exception processing. This will allow a no-emulator server, such as OSF/1-MK5 <ref> [25] </ref>, to do more efficient argument copying. We believe migrating RPC can also be leveraged by making the Mach pager interface synchronous, with a thread servicing its own page faults. This requires security to be explicitly provided when untrusted pagers are involved.
Reference: [26] <author> M. Rozier, V. Abrossimov, F. Armand, I. Boule, M. Gien, M. Guillemont, F. Herrmann, C. Kaiser, S. Langlois, P. Leonard, and W. Neuhauser. </author> <title> The Chorus distributed operating system. </title> <journal> Computing Systems, </journal> <volume> 1(4) </volume> <pages> 287-338, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Object-oriented systems have traditionally distinguished between "active" and "passive" objects, corresponding to static and migrating thread models [9]. Clouds [16] exemplifies a passive object (migrating thread) model, while Emerald [5], as we do, provides both active and passive objects| support for both styles of execution. Chorus <ref> [26] </ref> can use only thread-switching between user-level tasks, but between tasks running in the kernel's protection domain it has "message handlers" which operate in a migrating thread model. <p> In well-designed servers providing "system" functions, we suspect that internal contention can be minimized so that the importance of RPC speed outweighs that of context switch speed. We point out that in many commercial microkernel-based systems, including QNX [20], Chorus <ref> [26] </ref>, and KeyKOS [6], OS servers do not generally multiplex user-level threads over multiple kernel threads. Instead, these systems either provide multithreading purely with kernel threads, or their functions are sufficiently decomposed so that each server can be based on a single kernel thread, requiring no internal synchronization.
Reference: [27] <author> Michael L. Scott, Thomas J. LeBlanc, and Brian D. Marsh. </author> <title> Design rationale for Psyche, a general-purpose multiprocessor operating system. </title> <booktitle> In Proc. of the 1988 International Conference on Parallel Processing, </booktitle> <pages> pages 255-262, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: In both of these systems a thread can migrate across nodes in a distributed environment, and indeed Alpha's term for a migrating thread is a "distributed thread." Psyche <ref> [27] </ref> is a single-address-space system that supports migrating threads. The Lightweight RPC system [3] on Taos exploited 3 migrating threads (control transfer) as a critical part of its design, but focused on high-performance local RPC, and included additional data transfer optimizations.
Reference: [28] <author> Daniel Stodolsky, J. Bradley Chen, and Brian N. Bershad. </author> <title> Fast interrupt priority management in operating system kernels. </title> <booktitle> In Proc. of the Second USENIX Workshop on Micro-kernels and Other Kernel Architectures, </booktitle> <address> San Diego, CA, </address> <month> September </month> <year> 1993. </year>
Reference-contexts: Changing the interrupt priority level (IPL) is done four times on the switching path due to scheduler involvement, but not at all on the migrating path; while IPL changes are cheap on the PA-RISC, they are very expensive on some other architectures <ref> [28] </ref>, making migrating threads especially important on them.

References-found: 28

