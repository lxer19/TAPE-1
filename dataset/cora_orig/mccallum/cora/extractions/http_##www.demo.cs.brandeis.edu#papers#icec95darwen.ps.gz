URL: http://www.demo.cs.brandeis.edu/papers/icec95darwen.ps.gz
Refering-URL: http://www.demo.cs.brandeis.edu/papers/long.html
Root-URL: http://www.cs.brandeis.edu
Email: Email: darwen@cs.adfa.oz.au, xin@cs.adfa.oz.au  
Title: A Dilemma for Fitness Sharing with a Scaling Function  
Author: Paul Darwen and Xin Yao 
Address: Canberra AUSTRALIA  
Affiliation: Department of Computer Science University College, The University of New South Wales Australian Defence Force Academy,  
Abstract: Fitness sharing has been used widely in genetic algorithms for multi-objective function optimization and machine learning. It is often implemented with a scaling function, which adjusts an individual's raw fitness to improve the performance of the genetic algorithm. However, choosing a scaling function is an ad hoc affair that lacks sufficient theoretical foundation. Although this is already known, an explanation of why scaling works is lacking. This paper explains why a scaling function is often needed for fitness sharing. We investigate fitness sharing's performance at multi-objective optimization, demonstrate the need for a scaling function of some kind, and discuss what form of scaling function would be best. We provide both theoretical and empirical evidence that fitness sharing with a scaling function suffers a dilemma which can easily be mistaken for deception. Our theoretical analyses and empirical studies explain why a larger-than-necessary population is needed for fitness sharing with a scaling function to work, and give an explanation for common fixes such as further processing with a hill-climbing algorithm. Our explanation predicts that annealing the scaling power during a run will improve results, and we verify that it does. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. C. A. Andersen, </author> <title> A Constructive Algorithm for a Multilayer Perceptron based on Co-Operative Population Concepts in Genetic Algorithms. </title> <type> Master's thesis, </type> <institution> University of Queensland, </institution> <year> 1993. </year>
Reference-contexts: 1. Introduction Fitness sharing is a speciation method for genetic algorithms, allowing a GA population to find multiple optima in a multimodal search space. Fitness sharing has been used in machine learning <ref> [1] </ref> and multimodal function optimization [6]. Fitness sharing often uses a scaling function. However, choosing a scaling function is a procedure lacking theoretical conviction [5, page 124] [9].
Reference: [2] <author> D. Beasley, D. R. Bull, and R. R. Martin, </author> <title> "A sequential niche technique for multimodal function optimization," </title> <journal> Evolutionary Computation, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 101-125, </pages> <year> 1993. </year>
Reference-contexts: Thus, multiple optima are found from multiple runs. Beasley et al <ref> [2] </ref> take this a step further: each time the ordinary GA converges to an optimum, the payoff is reduced around that optimum to prevent the GA from converging there again, to prevent wasteful repetition. <p> Fitness sharing similarly reduces payoff, but at heavily-populated regions of the search space, and it does it dynamically during a single run, which reduces the repeated partial exploration suffered by sequential schemes like that of Beasley et al <ref> [2] </ref>. Nonetheless, fitness sharing has its own limitations, including the following: 1. s is the same for all individuals, so all optima in the search space must be equidistant or nearly so [12]. 2.
Reference: [3] <author> P. Darwen and X. Yao, </author> <title> "How good is fitness sharing with a scaling function," </title> <type> Tech. Rep. CS 8/95, </type> <institution> University College, The University of New South Wales, Canberra, </institution> <month> Apr. </month> <year> 1995. </year>
Reference-contexts: Any other distribution with more individuals at the edge of the payoff region would encourage individuals in the center, and vica-versa, so a uniform distribution is reasonable for this demonstration. The calculation of m k is available elsewhere <ref> [3] </ref>. (power = 1) for this population distribution. We see the highest shared payoff is not at the optimum, but a short Hamming distance away.
Reference: [4] <author> K. Deb and D. E. Goldberg, </author> <title> "An investigation of niche and species formation in genetic function optimization," </title> <booktitle> in Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pp. 42-50, </pages> <publisher> Morgan Kaufmann, </publisher> <month> June </month> <year> 1989. </year>
Reference-contexts: Secondly, the population must be large enough to maintain a subpopulation around each optimum. Like Deb and Goldberg <ref> [4, page 49] </ref>, we found that assortative crossover (crossover between similar parents) worked better than random crossover, and the experiments below use assortative crossover. Assortative mating produces few inter-species hybrids, so we may neglect crossover when sizing the population.
Reference: [5] <author> D. E. Goldberg, </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Fitness sharing has been used in machine learning [1] and multimodal function optimization [6]. Fitness sharing often uses a scaling function. However, choosing a scaling function is a procedure lacking theoretical conviction <ref> [5, page 124] </ref> [9]. Common scaling functions are known to suffer certain drawbacks, the most important of which is the need for post-processing with a hill-climbing algorithm. Why this need exists has been an open question. <p> Fitness Sharing and Multi-objective Op timization Fitness sharing modifies a search landscape by reducing payoff in densely-populated regions, encouraging search in unexplored regions and causing sub-populations to form. Consider an individual i with fitness f i . Its niche count m i <ref> [5, page 191] </ref> [10] measures how many other individuals with which i shares fitness. <p> With this explanation in mind, the reason why fitness scaling works becomes obvious. A scaling function is usually a power function <ref> [5, page 124] </ref> [6] [9, page 12]. <p> Optimal Scaling Function Why a power function? Choosing a scaling function is an ad hoc procedure that lacks a solid theoretical foundation <ref> [5, page 124] </ref>. Kreinovich et al [9] give the form of the optimal scaling function, given the criteria of certain properties of the search problem and assuming the scaling function's dimension.
Reference: [6] <author> D. E. Goldberg, K. Deb, and J. Horn, </author> <title> "Massive multimodality, deception, </title> <booktitle> and genetic algorithms," in Parallel Problem Solving from Nature 2, </booktitle> <pages> pp. 37-46, </pages> <publisher> North-Holland, </publisher> <month> Sep. </month> <year> 1992. </year>
Reference-contexts: 1. Introduction Fitness sharing is a speciation method for genetic algorithms, allowing a GA population to find multiple optima in a multimodal search space. Fitness sharing has been used in machine learning [1] and multimodal function optimization <ref> [6] </ref>. Fitness sharing often uses a scaling function. However, choosing a scaling function is a procedure lacking theoretical conviction [5, page 124] [9]. Common scaling functions are known to suffer certain drawbacks, the most important of which is the need for post-processing with a hill-climbing algorithm. <p> We explain both theoretically and empirically why a large population or similar fix is required in previous studies. 2.1. An Artificial Search Space The search space consists of all binary strings of length 30 bits, the same size used by Goldberg et al <ref> [6] </ref>. Of the 2 30 10 9 strings, only 10 are global optima. Unshared payoff is 1.0 for an exact match of an optimum, and declines linearly to zero for a 2 3 correct match, or 10 incorrect bits out of 30. <p> With this explanation in mind, the reason why fitness scaling works becomes obvious. A scaling function is usually a power function [5, page 124] <ref> [6] </ref> [9, page 12]. If we raise the unshared payoff to a power fi before sharing, we get a shared payoff that makes the optimum more attractive than the surrounding region: f s (f i ) m i function powers, at the same population distribution described above. 2.3. <p> For a deceptive search space, users often justify high scaling powers only to "increase the capacity of the niches centered on the global optima, relative to the niches centered on deceptive attractors" <ref> [6] </ref>, unaware of the additional effect of fitness sharing that this paper explains. Deception is only partly to blame. To compensate for high scaling powers, a larger population can achieve satisfactory results, by causing a rare "super-individual" to occur in every single payoff region. For example, Goldberg et al [6] used <p> attractors" <ref> [6] </ref>, unaware of the additional effect of fitness sharing that this paper explains. Deception is only partly to blame. To compensate for high scaling powers, a larger population can achieve satisfactory results, by causing a rare "super-individual" to occur in every single payoff region. For example, Goldberg et al [6] used fitness sharing on a deceptive space, and found that the algorithm worked well using a large population (of 5000 individuals) and a very high scaling power (of 15). <p> But our non-deceptive problem behaved similarly, and required a similar fix, suggesting that deception was only partly to blame. Also, they made no justification | "We achieved stable subpopulations at each global optima by using [a scaling power of] fi = 15 and a population size of 5000" <ref> [6] </ref>, indicating a trial-and-error increase of population and scaling power until global optima were found. This paper fully explains why high scaling powers with large populations were needed. It should be kept in mind that large populations usually require long computation time.
Reference: [7] <author> J. H. Holland, </author> <title> "Genetic algorithms," </title> <journal> Scientific American, </journal> <volume> vol. 267, </volume> <pages> pp. 44-50, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Our result also sheds light on another aspect of the speciated genetic algorithm. In nature, as in genetic search, evolution is good at finding near-optimal solutions but not optimal solutions, and so it is common to augment a GA with another method <ref> [7, page 50] </ref>, such as hill-climbing. Exactly why has been a mystery, until now. As shown in low power scaling causes subpopulations to form around an optimum, instead of at it. Hill-climbing is a rather ad hoc way to cover that gap.
Reference: [8] <author> J. Horn, D. E. Goldberg, and K. Deb, </author> <title> "Implicit niching in a learning classifier system: Nature's way," </title> <journal> Evolutionary Computation, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 37-66, </pages> <year> 1994. </year>
Reference-contexts: These limitations can cause fitness sharing to fail to find all optima if they are not equidistant and equal-valued, or if the estimated distance between optima is incorrect. To get around these problems, some schemes (in effect) do not use a fixed sharing radius <ref> [8, 12] </ref>. 1.2. Organization of this Paper In the rest of this paper, we will demonstrate that even without the above limitations, in a space where the peaks are equidistant and equal-valued, fitness sharing still finds fewer peaks than expected.
Reference: [9] <author> V. Kreinovich, C. Quintana, and O. Fuentes, </author> <title> "Genetic algorithms: What fitness scaling is optimal?," </title> <journal> Cybernetics and Systems, </journal> <volume> vol. 24, no. 1, </volume> <pages> pp. 9-26, </pages> <year> 1993. </year>
Reference-contexts: Fitness sharing has been used in machine learning [1] and multimodal function optimization [6]. Fitness sharing often uses a scaling function. However, choosing a scaling function is a procedure lacking theoretical conviction [5, page 124] <ref> [9] </ref>. Common scaling functions are known to suffer certain drawbacks, the most important of which is the need for post-processing with a hill-climbing algorithm. Why this need exists has been an open question. <p> The reason is that a scaling function is usually required to improve the results of fitness sharing. We briefly review why scaling is needed: it is known that for our and other similar problems, the best scaling function is a power function, (f) = f fi for some fi <ref> [9] </ref>. High values of fi cause premature convergence and missed optima, low values cause subpopulations to form around optima but not at them, similar to the effect of deception. In short, a power function is the best scaling function, but no constant scaling power can get around the above dilemma. <p> With this explanation in mind, the reason why fitness scaling works becomes obvious. A scaling function is usually a power function [5, page 124] [6] <ref> [9, page 12] </ref>. If we raise the unshared payoff to a power fi before sharing, we get a shared payoff that makes the optimum more attractive than the surrounding region: f s (f i ) m i function powers, at the same population distribution described above. 2.3. <p> Optimal Scaling Function Why a power function? Choosing a scaling function is an ad hoc procedure that lacks a solid theoretical foundation [5, page 124]. Kreinovich et al <ref> [9] </ref> give the form of the optimal scaling function, given the criteria of certain properties of the search problem and assuming the scaling function's dimension. <p> Space precludes a fuller discussion, but for problems of the form of our problem, which is typical of many but not all search problems, Kreinovich et al <ref> [9, page 18] </ref> have shown that: Fig. 2: Shared payoff at uniform population distribution for different scaling powers. Low fitness scaling means the highest shared payoff iis not at the optimum. 1. <p> For practicality's sake, we will consider a single-dimensional scaling function of the form (f ) = f fi . It is worth noting that Kreinovich et al <ref> [9] </ref> cannot tell us what power fi works best for a particular problem. In the next section, we will show that no power fi finds all optima even in our simple artificial problem, and thus that fitness sharing with power scaling has room for improvement. 2.4. <p> However, we cannot adjust the scaling power to achieve this without one of the above problems, and the best we can do is about 8 peaks found instead of 9.77 peaks. And since Kreinovich et al <ref> [9] </ref> show that the best single-dimensional scaling function for our problem is a power function, and no power meets our expectations, then no suitable single-dimensional scaling function exists.
Reference: [10] <author> S. W. Mahfoud, </author> <title> "Genetic drift in sharing methods," </title> <booktitle> in Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <pages> pp. 67-72, </pages> <publisher> IEEE Press, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Fitness Sharing and Multi-objective Op timization Fitness sharing modifies a search landscape by reducing payoff in densely-populated regions, encouraging search in unexplored regions and causing sub-populations to form. Consider an individual i with fitness f i . Its niche count m i [5, page 191] <ref> [10] </ref> measures how many other individuals with which i shares fitness. <p> To set s , you need to know a priori how far apart optima are, and their (unshared) fitness. Until you search the space, this information is unknown <ref> [10] </ref>. These limitations can cause fitness sharing to fail to find all optima if they are not equidistant and equal-valued, or if the estimated distance between optima is incorrect. To get around these problems, some schemes (in effect) do not use a fixed sharing radius [8, 12]. 1.2.
Reference: [11] <author> S. W. Mahfoud, </author> <title> "Population sizing for sharing methods," </title> <type> Tech. Rep. 94005, </type> <institution> Illinois Genetic Algorithms Laboratory, University of Illinois at Urbana-Champaign, </institution> <month> Aug. </month> <year> 1994. </year> <booktitle> To appear in the Third Workshop on the Foundations of Genetic Algorithms. </booktitle>
Reference-contexts: Assortative mating produces few inter-species hybrids, so we may neglect crossover when sizing the population. The minimum population size n for maintaining c species of equal fitness for G generations with probability fl is then <ref> [11, equation 13] </ref>: n = 1 G ln ( c1 (3) For c = 10 optima, maintained for G = 100 generations with probability fl = 0:999, the required population size is n = 131 individuals, so a population of 200 is enough to maintain subpopula-tions.
Reference: [12] <author> R. E. Smith, S. Forrest, and A. S. Perel-son, </author> <title> "Searching for diverse, cooperative populations with genetic algorithms," </title> <journal> Evolutionary Computation, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 127-149, </pages> <year> 1992. </year>
Reference-contexts: Nonetheless, fitness sharing has its own limitations, including the following: 1. s is the same for all individuals, so all optima in the search space must be equidistant or nearly so <ref> [12] </ref>. 2. To set s , you need to know a priori how far apart optima are, and their (unshared) fitness. Until you search the space, this information is unknown [10]. <p> These limitations can cause fitness sharing to fail to find all optima if they are not equidistant and equal-valued, or if the estimated distance between optima is incorrect. To get around these problems, some schemes (in effect) do not use a fixed sharing radius <ref> [8, 12] </ref>. 1.2. Organization of this Paper In the rest of this paper, we will demonstrate that even without the above limitations, in a space where the peaks are equidistant and equal-valued, fitness sharing still finds fewer peaks than expected. <p> If an individual partially matches more than one optimum, it receives the payoff from the closest match only, i.e., no addition. Incidentally, allowing addition of partial matches causes "generalizers" to evolve, with few species partially matching many optima, an interesting problem similar to the immune system <ref> [12] </ref>. The correct population size has two needs. First, the random first generation must sample individuals in each payoff region. Since the space contains a mere 2 30 10 9 strings, enumerative search is feasible and finds that each optima is surrounded by 2 fi 10 7 paying strings.
References-found: 12

