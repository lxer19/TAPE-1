URL: http://polaris.cs.uiuc.edu/reports/1514.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/polaris/rep2.html
Root-URL: http://www.cs.uiuc.edu
Email: fhoefling,paek,paduag@cs.uiuc.edu  
Title: Region-based Parallelization Using the Region Test  
Author: Jay Hoeflinger, Yunheung Paek, David Padua 
Address: 1304 West Springfield Avenue, Urbana, IL 61801, USA  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign,  
Abstract: fl In this paper, we discuss the advantages of using array access region summaries to parallelize programs. We reformulate the definition of the types of dependence in terms of array regions, and present a dependence test called the Region Test to use the definitions. The Region Test is designed to detect dependence between arbitrary regions of a program, including loop nests and whole subroutines. This allows us to exploit task parallelism, as well as loop parallelism. The Region Test also facilitates the generation of run-time dependence tests in situations where insufficient information exists at compile time to carry out the dependence test. Keywords: Compilers, Dependence Test, Parallelization 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Paek, J. Hoeflinger, D. Padua, </author> <title> Access Regions: Towards a Powerful Parallelizing Compiler, </title> <type> Tech. Report, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing R & D, </institution> <year> 1996, </year> <type> CSRD Report </type>
Reference-contexts: The increasing use of computers with large numbers of fast processors is making it ever more important for compilers to find large amounts parallelism within a program. In order to do that, compilers must have an efficient and flexible way of representing and using summarized access patterns <ref> [1] </ref>. For this purpose, a compiler typically uses a standard representation, such as triplet notation (also called regular section descriptor) [4, 5, 8], or convex regions [11, 12, 14]. These representations are based on a standard, simple access pattern, for purposes of efficiency. <p> This representation can be manipulated in a self-contained, abstract form, which has the desirable effect of allowing summarization and comparison of the access patterns of arrays in arbitrary program sections. In a previous paper <ref> [1] </ref>, we focused on the description of the Access Region form. The focus of this paper is a new dependence test, called the Region Test, which builds upon the Access Region representation. We are implementing the Region Test in the Polaris compiler [2]. <p> Based on the new index, we could generate the approximate region (A 1 2M M ,MAY,READ,T). In <ref> [1] </ref>, we detailed many other issues relating to the generation of Access Regions for array references in a program. 3.2 Operations on Access Regions Some of the basic operations [1] defined for Access Regions may be described briefly as follows: aggregation is a set union operation. <p> Based on the new index, we could generate the approximate region (A 1 2M M ,MAY,READ,T). In <ref> [1] </ref>, we detailed many other issues relating to the generation of Access Regions for array references in a program. 3.2 Operations on Access Regions Some of the basic operations [1] defined for Access Regions may be described briefly as follows: aggregation is a set union operation.
Reference: [2] <author> W. Blume, R. Doallo, R. Eigenmann, J. Grout, J. Hoeflinger, T. Lawrence, J. Lee, D. Padua, Y. Paek, W. Pottenger, L. Rauchwerger, P. Tu, </author> <title> Advanced Program Restructuring for High-Performance Computers with Polaris, </title> <booktitle> IEEE Computer, </booktitle> <month> Dec. </month> <year> 1996 </year>
Reference-contexts: In a previous paper [1], we focused on the description of the Access Region form. The focus of this paper is a new dependence test, called the Region Test, which builds upon the Access Region representation. We are implementing the Region Test in the Polaris compiler <ref> [2] </ref>. In Section 2, we first characterize the Region Test in comparison with other dependence tests. In Section 3, we formally describe the Access Region representation and operations on it. <p> Secondly, since this summarization can be performed over arbitrary sections of the program, this allows us to deal with task y parallelism as well as loop parallelism. This provides a tool for doing interprocedural dependence analysis without subroutine inlining <ref> [2, 22] </ref>. Thirdly, the Region Test helps us to move closer to the ideal, which is to use renaming to remove all anti and output dependences. This has been possible in only a limited way in the past, since precise region analysis has not been available.
Reference: [3] <author> Y. Paek, D. Padua, </author> <title> Automatic Parallelization Techniques for Distributed Memory Multiprocessors, </title> <type> Tech. Report, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing R & D, </institution> <year> 1996, </year> <type> CSRD Report </type>
Reference-contexts: This increased accuracy enables us to utilize copy-in/out operations to eliminate anti and output dependences, as shown in <ref> [3] </ref>. As an example, consider again the loop in Figure 1. Let the I-loop be a loop L that we are interested in. To determine the dependences carried by L, notice that the only references which could cause a cross-iteration dependence are to V and Y.
Reference: [4] <author> P. Tu, </author> <title> Automatic Array Privatization and Demand-Driven Symbolic Analysis, </title> <type> PhD Thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1995 </year>
Reference-contexts: In order to do that, compilers must have an efficient and flexible way of representing and using summarized access patterns [1]. For this purpose, a compiler typically uses a standard representation, such as triplet notation (also called regular section descriptor) <ref> [4, 5, 8] </ref>, or convex regions [11, 12, 14]. These representations are based on a standard, simple access pattern, for purposes of efficiency. <p> With the Access Region representation, we can more accurately represent the region of an array involved in a dependence, which is crucial to eliminating it. Finally, it incorporates array privatization <ref> [4] </ref> and run-time dependence testing under a uniform framework. 3 Access Regions The key to the precision and usefulness of the Region Test is the Access Region representation of array access patterns. <p> The condition expressions could be evaluated at runtime, when totally accurate information is available, to choose between alternative transformations. The work of the Region Processor is supported by two crucial features of Polaris. First, the program is represented in Gated Single Assignment (GSA) form <ref> [4] </ref>. The GSA form makes it easy to determine which definition of a variable is used at any point in the program, and the conditions under which the definition is used. <p> If L is eventually proven to be free of dependence, then it is identified as parallel. eliminate-dependences is composed of two parts: array privatization and copy-in/out operations. Our array priva-tization algorithm is based on the algorithm developed by Tu <ref> [4] </ref>. One main difference is that we use the Access Region representation, instead of the triplet notation, to summarize the array access patterns, giving us more opportunities to accurately capture the access patterns. <p> As a result of this process, the only dependence found is the self-output dependence caused by the write due to V (K+1,K+2). To remove this, we can privatize the region of V written in this reference, then copy the downwards exposed uses <ref> [4] </ref> out of the loop to the original array. This allows us to fully parallelize this loop. The Region Test can parallelize loops with very complex access patterns. It accomplishes this by summarizing accesses at a high level, which removes some of the low-level complexity of the access pattern.
Reference: [5] <author> W. Blume, </author> <title> Symbolic Analysis techniques for Effective Automatic Parallelization, </title> <type> PhD Thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1995 </year>
Reference-contexts: In order to do that, compilers must have an efficient and flexible way of representing and using summarized access patterns [1]. For this purpose, a compiler typically uses a standard representation, such as triplet notation (also called regular section descriptor) <ref> [4, 5, 8] </ref>, or convex regions [11, 12, 14]. These representations are based on a standard, simple access pattern, for purposes of efficiency. <p> Non-affine expressions sometimes occur in the original form of programs, and are often exposed during compiler transformations, due to the closed form expressions for induction variables, or the forward propagation of expressions. To solve this problem, the Range Test <ref> [5] </ref> was built to handle non-affine subscript expressions, through strong symbolic range analysis. The Range Test, the most powerful test used by Polaris, has shown good results in parallelizing many loops in real programs, but is not a multiple-subscript test, so is not effective for handling coupled-subscripts. <p> In this section we describe the representation and the operations defined for manipulating the representation. 3.1 Description of Access Regions Despite the apparent complexities of many data access patterns, our hand analysis and some experimental evidence <ref> [5] </ref> reveal that, quite often, the access regions of interest have a regularity of structure. By this we mean that the accesses seldom happen in random or chaotic ways. They are actually very structured, by design. Furthermore, related access regions often have a similarity of structure. <p> An array subscript expression need not be affine, but it is required to be a monotonic function [18] within the index ranges. Fortunately, most subscript expressions encountered in scientific programs are monotonic <ref> [5] </ref> (at least over the index ranges involved), and those few which are non-monotonic may be converted to a monotonic function with a possible accuracy loss. For instance in Figure 1, the subscript function for Z is II (J). <p> The GSA form makes it easy to determine which definition of a variable is used at any point in the program, and the conditions under which the definition is used. Second, Polaris has a rich symbolic expression environment <ref> [5] </ref>, consisting of expression simplification, range propagation and the range dictio nary, which makes the value ranges for variables available at any point in the program. <p> When a subscript expression contains a variable whose value cannot be expressed in terms of the loop indices, we must resort to using its symbolic range, obtained by something like interprocedural value propagation <ref> [5] </ref> (IPVP) and range propagation [7]. These techniques use abstract interpretation on the program to discover the range of values which a given variable may take on. For example, consider the loop in Figure 5.
Reference: [6] <author> L. Rauchwerger, D. Padua, </author> <title> The LRPD Test: Speculative Run-Time Parallelization of Loops with Privatization and Reduction Parallelization, </title> <booktitle> Proceedings of ACM SIG--PLAN'95 Conference on Programming Language Design and Implementation, </booktitle> <month> Jun. </month> <year> 1995 </year>
Reference-contexts: We have found that task parallelization increases parallelism in many benchmarks, such as HYDRO2D, and OCEAN. 4.5 Conditional Parallelization Many compilers give up when confronted with unknown values. Run-time parallelization techniques have been proposed <ref> [6, 9] </ref> for these cases, but until now, these have required the potentially high overhead involved in checking individual array accesses for dependence at run-time. We suggest a different approach, where the conditions, which we call safe conditions, can be extracted from the code to test at run-time.
Reference: [7] <author> W. Blume, R. Eigenmann, </author> <title> Demand-driven, Symbolic Range Propagation, </title> <booktitle> Proceedings of the Eighth Workshop on Languages and Compilers for Parallel Computing, </booktitle> <month> Aug. </month> <year> 1995 </year>
Reference-contexts: When a subscript expression contains a variable whose value cannot be expressed in terms of the loop indices, we must resort to using its symbolic range, obtained by something like interprocedural value propagation [5] (IPVP) and range propagation <ref> [7] </ref>. These techniques use abstract interpretation on the program to discover the range of values which a given variable may take on. For example, consider the loop in Figure 5. <p> Figure 10 shows the multiprocessor speedups of MDG on the Cray T3D. First, we used only the Range Test and other tranditional tests such as GCD test without expensive interprocedural constant propagations <ref> [7] </ref>, but these tests failed to parallelize the loops similar to the ones explained above.
Reference: [8] <author> S. Chatterjee, J. Gilbert, F. </author> <title> Long, Generating Local Address and Communication Sets for Data-Parallel Programs, </title> <booktitle> Proceedings of ACM SIGPLAN Symp. on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, </address> <month> May </month> <year> 1993 </year>
Reference-contexts: In order to do that, compilers must have an efficient and flexible way of representing and using summarized access patterns [1]. For this purpose, a compiler typically uses a standard representation, such as triplet notation (also called regular section descriptor) <ref> [4, 5, 8] </ref>, or convex regions [11, 12, 14]. These representations are based on a standard, simple access pattern, for purposes of efficiency.
Reference: [9] <author> J. Saitz, R. Mirchandaney, K Crowley, </author> <title> Run-time Paralleliza-tion and Scheduling of Loops, </title> <journal> IEEE Trans. Computers, </journal> <volume> Vol 40, </volume> <month> May </month> <year> 1991 </year>
Reference-contexts: We have found that task parallelization increases parallelism in many benchmarks, such as HYDRO2D, and OCEAN. 4.5 Conditional Parallelization Many compilers give up when confronted with unknown values. Run-time parallelization techniques have been proposed <ref> [6, 9] </ref> for these cases, but until now, these have required the potentially high overhead involved in checking individual array accesses for dependence at run-time. We suggest a different approach, where the conditions, which we call safe conditions, can be extracted from the code to test at run-time.
Reference: [10] <author> R. Cytron, J. Ferrante, </author> <title> What's in a Name?, </title> <booktitle> Proceedings of the 1987 International Conference on Parallel Processing, </booktitle> <month> Aug. </month> <year> 1987 </year>
Reference-contexts: Using the results from compute-dependences, the routine detect-loop-dependences determines whether L can be made parallel or must be serial. eliminate-dependences is used to eliminate anti and output dependences based on the ideas discussed by Cytron and Ferrante <ref> [10] </ref>, for all variables proven to have them. If L is eventually proven to be free of dependence, then it is identified as parallel. eliminate-dependences is composed of two parts: array privatization and copy-in/out operations. Our array priva-tization algorithm is based on the algorithm developed by Tu [4].
Reference: [11] <author> B. Creusillet, F. Irigoin, </author> <title> Exact vs. Approximate Array Region Analyses, </title> <booktitle> 9th Workshop on Language and Compilers for Parallel Computing, Lecture Notes in Computer Science, </booktitle> <address> Spring-Verlag, </address> <year> 1996 </year>
Reference-contexts: In order to do that, compilers must have an efficient and flexible way of representing and using summarized access patterns [1]. For this purpose, a compiler typically uses a standard representation, such as triplet notation (also called regular section descriptor) [4, 5, 8], or convex regions <ref> [11, 12, 14] </ref>. These representations are based on a standard, simple access pattern, for purposes of efficiency.
Reference: [12] <author> P. Tang, </author> <title> Exact Side Effects for Interprocedural Dependence Analysis, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 35, No. 8, </volume> <month> Aug. </month> <year> 1992 </year>
Reference-contexts: In order to do that, compilers must have an efficient and flexible way of representing and using summarized access patterns [1]. For this purpose, a compiler typically uses a standard representation, such as triplet notation (also called regular section descriptor) [4, 5, 8], or convex regions <ref> [11, 12, 14] </ref>. These representations are based on a standard, simple access pattern, for purposes of efficiency. <p> A common way to address these problems is to summarize the array accesses within program sections, then intersect them to determine dependence between the sections. To implement such summaries, several previous works <ref> [12, 14] </ref> used a set of constraints representing a convex region. The Region Test endeavors to combine the flexibility and efficiency of these summarization techniques with the symbolic strength of the Range Test. The Region Test has several advantages over other tests.
Reference: [13] <author> G. Goff, K. Kennedy, C. Tseng, </author> <title> Practical Dependence Testing, </title> <booktitle> Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <address> Toronto, Ontario, Canada, </address> <month> June 26-28, </month> <year> 1991 </year>
Reference-contexts: However, the simplicity of the tests results in some limitations. For instance, they are not effective for determining dependence for multidimensional arrays with coupled subscripts, as stated in <ref> [13] </ref>. Several multiple-subscript tests have been developed to overcome this limitation: the multidimensional GCD Test [19], the Power Test [25], the -test [21], and the Delta Test [13]. The above tests are exact in commonly occuring special cases, but in some cases are still too conservative. <p> For instance, they are not effective for determining dependence for multidimensional arrays with coupled subscripts, as stated in <ref> [13] </ref>. Several multiple-subscript tests have been developed to overcome this limitation: the multidimensional GCD Test [19], the Power Test [25], the -test [21], and the Delta Test [13]. The above tests are exact in commonly occuring special cases, but in some cases are still too conservative. The Omega Test [16] provides a more general method, based on sets of constraints representing a convex region, capable of handling dependence problems in terms of integer programming problems.
Reference: [14] <author> V. Balasundaram, K. Kennedy, </author> <title> A Techniques for Summarizing Data Access and its Use in Parallelism Enhancing Transformations, </title> <booktitle> Proceedings of ACM SIGPLAN'89 Conference on Programming Language Design and Implementation, </booktitle> <month> Jun. </month> <year> 1989 </year>
Reference-contexts: In order to do that, compilers must have an efficient and flexible way of representing and using summarized access patterns [1]. For this purpose, a compiler typically uses a standard representation, such as triplet notation (also called regular section descriptor) [4, 5, 8], or convex regions <ref> [11, 12, 14] </ref>. These representations are based on a standard, simple access pattern, for purposes of efficiency. <p> A common way to address these problems is to summarize the array accesses within program sections, then intersect them to determine dependence between the sections. To implement such summaries, several previous works <ref> [12, 14] </ref> used a set of constraints representing a convex region. The Region Test endeavors to combine the flexibility and efficiency of these summarization techniques with the symbolic strength of the Range Test. The Region Test has several advantages over other tests. <p> Here, we use the parbegin/parend construct as suggested by Dijkstra [23]. For task parallelization, we build a task dependence graph, similar to that proposed in the paper by Balasundaram and Kennedy <ref> [14] </ref>. The main difference between our technique and theirs is that we use Access Regions to summarize the array access of a given program section, so we can handle non-unit stride accesses efficiently. program in Figure 7. Each node i correponds to the i-th call to goo in the program.
Reference: [15] <author> K. Kennedy, K. McKinley, </author> <title> Maximizing Loop Parallelism and Improving Data Locality via Loop Fusion and Distribution, </title> <booktitle> Proc. 6th Workshop on Languages and Compilers for Parallel Computing, Lecture Notes in Computer Science, </booktitle> <address> Spring-Verlag, NY, </address> <month> Aug. </month> <year> 1993 </year>
Reference-contexts: To do this, they compare all pairs of array references which may contribute to a dependence within loops. So, we say that they are point-to-point tests. The dependence graph is very useful for parallelization and enables sophisticated loop transformations <ref> [15] </ref>. But, point-to-point methods may need O (n 2 ) comparisons where n is the number of array references in the loop. This can be very expensive if the loop contains many references.
Reference: [16] <author> W. Pugh, </author> <title> A Practical Algorithm for Exact Array Dependence Analysis, </title> <journal> Communications of the ACM, </journal> <volume> Vol. 35, No. 8, </volume> <month> Aug. </month> <year> 1992 </year>
Reference-contexts: Several multiple-subscript tests have been developed to overcome this limitation: the multidimensional GCD Test [19], the Power Test [25], the -test [21], and the Delta Test [13]. The above tests are exact in commonly occuring special cases, but in some cases are still too conservative. The Omega Test <ref> [16] </ref> provides a more general method, based on sets of constraints representing a convex region, capable of handling dependence problems in terms of integer programming problems. Although integer programming techniques use worst-case exponential time algorithms, the Omega Test has proven to be efficient and successful for solving dependence problems.
Reference: [17] <author> M. Burke, R. Cytron, </author> <title> Interprocedural Dedependence Analysis and Parallelization, </title> <booktitle> Proceedings of ACM SGIPLAN '86 Symposium on Compiler Construction, </booktitle> <address> Palo Alto, CA, </address> <month> July </month> <year> 1986, </year> <pages> pp 162-175 </pages>
Reference-contexts: If X is multi-dimensional, then we linearize z the subscript expression to generate f (I), similar to what was done by Burke and Cytron <ref> [17] </ref>. The Access Region R for X (f (I)) is a structured, symbolic set of subscript values of X, in the sense that, given a set of constants for all the variables involved, one could generate the precise set of array subscripts involved in the access pattern.
Reference: [18] <author> H. Zima, B. Chapman, </author> <title> Supercompilers for Parallel and Vector Computers, </title> <publisher> ACM Press, </publisher> <year> 1992 </year>
Reference-contexts: In Section 4, we describe how the Region Test deals with the dependence problem at the loop, interprocedural and task levels, and how it generates runtime dependence tests. 2 Related Work Two of the earliest dependence testing techniques were the GCD Test and the Banerjee Test <ref> [18] </ref>. In practice, these were simple, efficient, and successful at determining dependence, since most subscript expressions occuring in real scientific programs are very simple. However, the simplicity of the tests results in some limitations. <p> Alternatively, if we can afford to lose accuracy, we can represent this as (A 1 N1 +11,MAY,WRITE,T) where T represents TRUE, which means that there is no constraint on this region. An array subscript expression need not be affine, but it is required to be a monotonic function <ref> [18] </ref> within the index ranges. Fortunately, most subscript expressions encountered in scientific programs are monotonic [5] (at least over the index ranges involved), and those few which are non-monotonic may be converted to a monotonic function with a possible accuracy loss. <p> In this section we will show how to reformulate the definition of dependences in terms of regions, and how to use that reformulation to parallelize programs. 4.1 Dependences There are three types of dependence generally considered between array references inside a loop: flow, anti and output <ref> [18] </ref>. Each of these can exist between two different iterations of the loop (cross-iteration), or within a particular iteration of the loop (intra-iteration). A cross-iteration flow dependence occurs when an array element is written on one iteration, then the same element is read on a later iteration.
Reference: [19] <author> U. Utpal, </author> <title> Loop Transformations for Restructuring Compilers: The Foundations, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993 </year>
Reference-contexts: However, the simplicity of the tests results in some limitations. For instance, they are not effective for determining dependence for multidimensional arrays with coupled subscripts, as stated in [13]. Several multiple-subscript tests have been developed to overcome this limitation: the multidimensional GCD Test <ref> [19] </ref>, the Power Test [25], the -test [21], and the Delta Test [13]. The above tests are exact in commonly occuring special cases, but in some cases are still too conservative.
Reference: [20] <institution> CRAY T3D System Architecture Overview, Cray Research, </institution> <year> 1993 </year>
Reference-contexts: In fact, this loop is the most important in TFFT2. Therefore, without parallelizing this loop, good speedups are not possible. To measure the effectiveness of the Region Test, we tested the performance of the TFFT2 benchmark on the Cray T3D <ref> [20] </ref> both with and without application of the Region Test, and the results, shown in Table 1, demonstrate that the Region Test allows us to significantly reduce the parallel execution times.
Reference: [21] <author> Z. Li, P. Yew, and C. Zhu, </author> <title> Data Dependence Analysis on Multi-dimensional Array References, </title> <booktitle> Proceedings of the 1989 ACM International Conference on Supercomputing, </booktitle> <address> Crete, Greece, </address> <month> June, </month> <year> 1989 </year>
Reference-contexts: For instance, they are not effective for determining dependence for multidimensional arrays with coupled subscripts, as stated in [13]. Several multiple-subscript tests have been developed to overcome this limitation: the multidimensional GCD Test [19], the Power Test [25], the -test <ref> [21] </ref>, and the Delta Test [13]. The above tests are exact in commonly occuring special cases, but in some cases are still too conservative.
Reference: [22] <author> J. Grout, </author> <title> Inline Expansion for the Polaris Research Compiler, </title> <type> Master's thesis, </type> <institution> Univ. of Illinois at Urbana-Champaign, Cntr. for Supercomputing Res. & Dev., </institution> <month> May </month> <year> 1995 </year>
Reference-contexts: Secondly, since this summarization can be performed over arbitrary sections of the program, this allows us to deal with task y parallelism as well as loop parallelism. This provides a tool for doing interprocedural dependence analysis without subroutine inlining <ref> [2, 22] </ref>. Thirdly, the Region Test helps us to move closer to the ideal, which is to use renaming to remove all anti and output dependences. This has been possible in only a limited way in the past, since precise region analysis has not been available.
Reference: [23] <author> E. Dijkstra, </author> <title> Cooperating Sequential Processes, Programming Languages, </title> <publisher> Academic Press, </publisher> <address> NY, </address> <year> 1968 </year>
Reference-contexts: By doing so, we can increase parallelism 8-fold. Figure 8 shows the result after being parallelized and annotated with parallel section directives to direct processors to execute the program in parallel. Here, we use the parbegin/parend construct as suggested by Dijkstra <ref> [23] </ref>. For task parallelization, we build a task dependence graph, similar to that proposed in the paper by Balasundaram and Kennedy [14].
Reference: [24] <author> M. Berry, et. al, </author> <title> The Perfect Club Benchmarks: Effective Performance Evalution of Supercomputers, </title> <journal> Int'l Journal of Supercomputer Applications, </journal> <volume> Vol. 3, No. 3, </volume> <month> Fall </month> <year> 1989 </year>
Reference-contexts: For this purpose, a compiler typically uses a standard representation, such as triplet notation (also called regular section descriptor) [4, 5, 8], or convex regions [11, 12, 14]. These representations are based on a standard, simple access pattern, for purposes of efficiency. Through our analysis of the Perfect <ref> [24] </ref> and SPEC [26] benchmarks, and several full scientific codes from the National Center for Supercomputing Applications (NCSA), we found that these representations sometimes must discard critical information. This prevents the parallelization of certain loops.
Reference: [25] <author> M. Wolfe, C. Tseng, </author> <title> The Power Test for Data Dependence, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <month> Sep. </month> <year> 1992 </year>
Reference-contexts: However, the simplicity of the tests results in some limitations. For instance, they are not effective for determining dependence for multidimensional arrays with coupled subscripts, as stated in [13]. Several multiple-subscript tests have been developed to overcome this limitation: the multidimensional GCD Test [19], the Power Test <ref> [25] </ref>, the -test [21], and the Delta Test [13]. The above tests are exact in commonly occuring special cases, but in some cases are still too conservative.
Reference: [26] <author> J. Reilly, </author> <title> SPEC95 Products And Benchmarks, </title> <journal> SPEC Newsletter, </journal> <month> Sep. </month> <year> 1995 </year>
Reference-contexts: These representations are based on a standard, simple access pattern, for purposes of efficiency. Through our analysis of the Perfect [24] and SPEC <ref> [26] </ref> benchmarks, and several full scientific codes from the National Center for Supercomputing Applications (NCSA), we found that these representations sometimes must discard critical information. This prevents the parallelization of certain loops. This motivated us to develop a new representation called the Access Region, a generalization of triplet notation.
References-found: 26

