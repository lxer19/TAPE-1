URL: ftp://ftp.dcs.ex.ac.uk/pub/connect/305.ps.gz
Refering-URL: http://www.dcs.ex.ac.uk/research/neural/pub/pub.htm
Root-URL: 
Title: Replicability of Neural Computing Experiments  
Author: D. Partridge and W.B. Yates 
Date: August 18, 1995  
Address: Exeter EX4 4PT UK  
Affiliation: Department of Computer Science University of Exeter  
Abstract: If an experiment requires statistical analysis to establish a result, then one should do a better experiment. Ernest Rutherford, 1930 Most proponents of cold fusion reporting excess heat from their electrolysis experiments were claiming that one of the main characteristics of cold fusion was its irreproducibility | J.R. Huizenga, Cold Fusion, 1993, p. 78 Abstract Amid the ever increasing research into various aspects of neural computing, much progress is evident both from theoretical advances and from empirical studies. On the empirical side a wealth of data from experimental studies is being reported. It is, however, not clear how best to report neural computing experiments such that they may be replicated by other interested researchers. In particular, the nature of iterative learning on a randomised initial architecture, such as backpropagation training of a multilayer perceptron, is such that precise replication of a reported result is virtually impossible. The outcome is that experimental replication of reported results, a touchstone of "the scientific method", is not an option for researchers in this most popular subfield of neural computing. In this paper, we address this issue of replicability of experiments based on backpropagation training of multilayer perceptrons (although many of our results will be applicable to any other subfield that is plagued by the same characteristics). First, we attempt to produce a complete abstract specification of such a neural computing experiment. From this specification we identify the full range of parameters needed to support maximum replicability, and we use it to show why absolute replicability is not an option in practice. We propose a statistical framework to support replicability. We demonstrate this framework with some empirical studies of our own on both repli-cability with respect to experimental controls, and validity of implementations of the backpropagation algorithm. Finally, we suggest how the degree of replicability of a neural computing experiment can be estimated and reflected in the claimed precision for any empirical results reported. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E Barnard and J E W Holm. </author> <title> A comparative study of optimization techniques for backpropagation. </title> <journal> Neurocomputing, </journal> <volume> 6(1) </volume> <pages> 19-30, </pages> <year> 1994. </year>
Reference-contexts: Some aspects of the initial conditions are thought to be non-significant (e.g. batch or online update, an "implementation detail" within backpropagation, see <ref> [1] </ref>), and others are simply unrecognized as characteristics of the initial state (e.g. the composition of the training set). <p> The class of functions computed by this type of neural network is determined by the choice of activation function G (see [5]). In this study G is the logistic or sigmoid activation function (see [11], page 329) which has the form G : R ! <ref> [0; 1] </ref> and is defined by G (x) = 1 + e x : Later, when we come to specify our convergence criteria we shall, for the sake of clarity, represent our network as a parameterized function f : W n 0 where W = R and A = [0; 1], <p> ! <ref> [0; 1] </ref> and is defined by G (x) = 1 + e x : Later, when we come to specify our convergence criteria we shall, for the sake of clarity, represent our network as a parameterized function f : W n 0 where W = R and A = [0; 1], and n 0 = n (r + s) + n + s is the number of weights and biases, r is the number of inputs, and s is the number of outputs. 2.2 The Learning Algorithm We shall train our 2-layer feedforward neural network f : W n 0 <p> We shall abstract a functional representation of this precise, though informal description. The intention here is to make explicit the exact structure and semantics of the network task. Let S = <ref> [0; 1] </ref>fi [0; 1] represent the set of all data points, let a = (x 1 ; y 1 ) and b = (x 2 ; y 2 ) represent two consecutive data points and note that the function d (a; b) = (x 1 x 2 ) 2 + (y <p> We shall abstract a functional representation of this precise, though informal description. The intention here is to make explicit the exact structure and semantics of the network task. Let S = <ref> [0; 1] </ref>fi [0; 1] represent the set of all data points, let a = (x 1 ; y 1 ) and b = (x 2 ; y 2 ) represent two consecutive data points and note that the function d (a; b) = (x 1 x 2 ) 2 + (y 1 y <p> Formally, we require a neural network implementation of the bounded function f : S fi S fi <ref> [0; 1] </ref> ! B seed random number generator for i = 0 to 1000 do x 1 = random () y 1 = random () x 2 = random () y 2 = random () LENGTH1 = random () print &lt;x 1 ; y 1 ; x 2 ; y 2 <p> by f (a; b; LENGTH1) = 8 : 1 if d (a; b) &gt; LENGTH1; 0 otherwise, In fact, as our task will ultimately be executed on some digital computer, we shall restrict our attention to the finite subset of rationals, with 6 decimal places, in S fi S fi <ref> [0; 1] </ref>. 2.5 Training and Test Sets Many neural network experiments reported in the literature fail to adequately characterize the structure of the training and test sets. A consequence of this is that any reported training and generalization results are difficult to interpret, and virtually impossible to reproduce.
Reference: [2] <author> J Dugundji. </author> <title> Topology. </title> <publisher> Allyn and Bacon, </publisher> <year> 1966. </year>
Reference-contexts: We shall employ a stronger convergence citeria that addresses these deficiencies. Specifically let be a -finite measure defined on a -algebra in X (see [4]) and let d be a metric in Y (see <ref> [2] </ref>).
Reference: [3] <author> S E Fahlman. </author> <title> Faster-learning variations on back-propagation: An empirical study. </title> <editor> In D Touretzky, G E Hinton, and T J Sejnowski, editors, </editor> <booktitle> Proceedings of the 1988 Connectionist Models Summer School, </booktitle> <pages> pages 38-51. </pages> <publisher> Morgan Kaufman, </publisher> <year> 1988. </year>
Reference-contexts: 1 Introduction Experiments based on the iterative training of neural networks are known to be sensitive to initial conditions in weight space, and some studies have begun to explore the nature and extent of this sensitivity (see for example <ref> [3] </ref>, and [7]). However, the initial conditions for training involve much more than the initial position chosen (usually by means of some "random" procedure) in weight space. <p> neural network experiments, to introduce a statistical framework for improved replicability, and to begin to relate the degree of replicability achieved to the precision that can be justifiably associated with empirical results. 1.1 Background The sensitivity of backpropagation to initial conditions has been highlighted by a number of researchers, notably <ref> [3] </ref>, [7]. Kolen and Pollack reported that backpropagation is extremely sensitive to the choice of initial weights. While their study revealed some interesting chaotic behaviours and provided analytic insights into a number of observed phenomena, it does not have much impact from an engineering applications standpoint (as they freely admit). <p> Intuitively, in this case, our correctness specification implies that learning terminates when our neural network is "-close to our target function, on all but some fraction ffi of training patterns. 2.4 Task Specification Fahlman (see <ref> [3] </ref>) discusses the issue of suitable benchmark problems for neural computing experiments and comes out against (exclusive use of) popular choices such as XOR and parity because "generalization in the space of raw inputs is actually punished, since the nearest neighbors of an input pattern must produce the opposite answer from
Reference: [4] <author> P R Halmos. </author> <title> Measure Theory. </title> <publisher> D Van Nostrand, </publisher> <year> 1950. </year> <month> 25 </month>
Reference-contexts: We shall employ a stronger convergence citeria that addresses these deficiencies. Specifically let be a -finite measure defined on a -algebra in X (see <ref> [4] </ref>) and let d be a metric in Y (see [2]).
Reference: [5] <author> A K Hornik, A M Stinchcombe, and H White. </author> <title> Multilayer feedforward networks are universal approximators. </title> <booktitle> Neural Networks, </booktitle> <volume> 2(5) </volume> <pages> 359-366, </pages> <year> 1989. </year>
Reference-contexts: In this section we shall present a formal definition of our experiments with the intention of making explicit the experimental parameters and assumptions on which our studies depend. 2.1 The Neural Network We shall concern ourselves with a class of feedforward 2-layer neural networks based on a definition presented in <ref> [5] </ref>. They specify a 2-layer feedforward neural network over the real numbers R by a triple (r; A; G) consisting of a number r 2 N, a family of affine functions A, and an activation function G. <p> Our definition differs from the one found in <ref> [5] </ref> in that our multiple output networks have their own activation functions G, and biases b 0 k , though we note that this does not affect the class of functions computable by our network. <p> The class of functions computed by this type of neural network is determined by the choice of activation function G (see <ref> [5] </ref>).
Reference: [6] <author> J C Knight and N G Leveson. </author> <title> An experimental evaluation of the assumption of inde pendence in multiversion programming. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 12(1) </volume> <pages> 96-109, </pages> <year> 1986. </year>
Reference-contexts: The Launch Interceptor Problem, has been used in a number of software engineering experiments concerning correctness and reliability (see for example <ref> [6] </ref>). Our task is to implement one of the 15, so called, Launch Interceptor Conditions, LIC1. [6] specify LIC1 as a predicate that evaluates to true if: "There exists at least one set of two consecutive data points that are a distance greater than the length LENGTH1 apart. (0 LENGTH1)" where <p> The Launch Interceptor Problem, has been used in a number of software engineering experiments concerning correctness and reliability (see for example <ref> [6] </ref>). Our task is to implement one of the 15, so called, Launch Interceptor Conditions, LIC1. [6] specify LIC1 as a predicate that evaluates to true if: "There exists at least one set of two consecutive data points that are a distance greater than the length LENGTH1 apart. (0 LENGTH1)" where LENGTH1 is a parameter of the condition.
Reference: [7] <author> J F Kolen and J B Pollack. </author> <title> Backpropagation is sensitive to initial conditions. </title> <journal> Complex Systems, </journal> <volume> 4(3) </volume> <pages> 269-280, </pages> <year> 1990. </year>
Reference-contexts: 1 Introduction Experiments based on the iterative training of neural networks are known to be sensitive to initial conditions in weight space, and some studies have begun to explore the nature and extent of this sensitivity (see for example [3], and <ref> [7] </ref>). However, the initial conditions for training involve much more than the initial position chosen (usually by means of some "random" procedure) in weight space. <p> network experiments, to introduce a statistical framework for improved replicability, and to begin to relate the degree of replicability achieved to the precision that can be justifiably associated with empirical results. 1.1 Background The sensitivity of backpropagation to initial conditions has been highlighted by a number of researchers, notably [3], <ref> [7] </ref>. Kolen and Pollack reported that backpropagation is extremely sensitive to the choice of initial weights. While their study revealed some interesting chaotic behaviours and provided analytic insights into a number of observed phenomena, it does not have much impact from an engineering applications standpoint (as they freely admit).
Reference: [8] <author> B Littlewood and D R Miller. </author> <title> Conceptual modeling of coincident failures in mul tiversion software. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(12) </volume> <pages> 1596-1614, </pages> <year> 1989. </year>
Reference-contexts: = 20000 Test Pattern Generator specified fig. 2 Number of Test Patterns l = 161051 Table 1: Experimental Parameters 1. the "generalization diversity" or GD, that occurs within groups of networks (see [9]) and 2. the "inter-group diversity" that occurs between groups of networks as measured by the coefficient (see <ref> [8] </ref>). Consider a set A of N neural networks each trained to perform a well defined task. Assume that each network in A is trained using differing initial conditions and then evaluated on a set of l test patterns. <p> In order to measure the diversity between two groups of networks we shall employ a measure of correlation, (see <ref> [8] </ref>). Consider two non-empty sets of networks A and B, containing N A and N B networks respectively. Each network has been trained to perform a well defined task.
Reference: [9] <author> D Partridge. </author> <title> Network generalization differences quantified. </title> <type> Research Report 291, </type> <institution> University of Exeter, </institution> <year> 1994. </year>
Reference-contexts: specified in fig. 1 Number of Training Patterns m = 1000 Task-to-Net Mapping specified in text Epochs e = 20000 Test Pattern Generator specified fig. 2 Number of Test Patterns l = 161051 Table 1: Experimental Parameters 1. the "generalization diversity" or GD, that occurs within groups of networks (see <ref> [9] </ref>) and 2. the "inter-group diversity" that occurs between groups of networks as measured by the coefficient (see [8]). Consider a set A of N neural networks each trained to perform a well defined task. <p> More extensive studies (in <ref> [9] </ref>) confirm these tentative observations. In table 6 the inter-group failure correlation values are given. This quantity is a measure of the similarity between the variety of test failures in two groups of nets.
Reference: [10] <author> W H Press, B P Flannery, </author> <title> S A Teukolsky, and W T Vetterling. Numerical Recipes in C: </title> <booktitle> The Art of Scientific Computing. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: In general, we may either employ a system random number generator provided by the system vendor, or an abstract specification of a random number generator algorithm (see for example the specification of ran1 in <ref> [10] </ref>, page 210). By way of an illustration we have used an abstract algorithm to generate the weights, and the Silicon Graphics system supplied random number generator to produce the training set.
Reference: [11] <author> D E Rumelhart, G E Hinton, and R J Williams. </author> <title> Learning internal representation by error propagation. </title> <editor> In D E Rumelhart and J L McClelland, editors, </editor> <booktitle> Parallel Distributed Processing. Explorations in the Microstructure of Cognition. Volume 1: Foundations, </booktitle> <pages> pages 318-362. </pages> <publisher> MIT Press, </publisher> <year> 1986. </year> <month> 26 </month>
Reference-contexts: Most studies that use this type of network and training algorithm refer to the seminal paper in <ref> [11] </ref>, as the "definition" of their experimental setup. It is tacitly assumed that all these experiments use functionally identical versions of backpropagation, that is they differ only in implementation detail. Unfortunately, problems experienced by ourselves and other researchers in the field when trying to reproduce published experiments contradict this assumption. <p> The class of functions computed by this type of neural network is determined by the choice of activation function G (see [5]). In this study G is the logistic or sigmoid activation function (see <ref> [11] </ref>, page 329) which has the form G : R ! [0; 1] and is defined by G (x) = 1 + e x : Later, when we come to specify our convergence criteria we shall, for the sake of clarity, represent our network as a parameterized function f : W <p> The learning algorithm is a neural network based implementation of the steepest (gradient) descent optimization algorithm, due originally to Fermat (see <ref> [11] </ref>). A learning algorithm's task is encoded in a (usually finite) set of patterns P . <p> The learning algorithm itself is specified by three equations (see <ref> [11] </ref>, page 327). <p> The weight update equation (1) becomes p (0) w ji = 0 where t 2 T indexes the pattern being processed, and ff is a constant called the momentum which determines the effect of past weight updates on the current direction of movement in weight space (see <ref> [11] </ref>, page 330). The learning algorithm is also parameterized and must be initialized with a set of initial weights (for the network), denoted w 00 , and two learning parameters, denoted and ff.
References-found: 11

