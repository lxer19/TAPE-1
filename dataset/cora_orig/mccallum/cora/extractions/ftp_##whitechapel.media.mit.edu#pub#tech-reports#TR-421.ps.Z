URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-421.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: (drew, bobick@media.mit.edu)  
Title: Recognition and Interpretation of Parametric Gesture  
Author: Andrew D. Wilson Aaron F. Bobick 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: Vision and Modeling Group MIT Media Laboratory  
Abstract: M.I.T. Media Laboratory Perceptual Computing Section Technical Report No. 421 Submitted to: International Conference on Computer Vision, 1998 Abstract A new method for the representation, recognition, and interpretation of parameterized gesture is presented. By parameterized gesture we mean gestures that exhibit a meaningful variation; one example is a point gesture where the important parameter is direction. Our approach is to extend the standard hidden Markov model method of gesture recognition by including a global parametric variation in the output probabilities of the states of the HMM. Using a linear model to derive the theory, we formulate an expectation-maximization (EM) method for training the parametric HMM. During testing, the parametric HMM simultaneously recognizes the gesture and estimates the quantifying parameters. Using visually-derived and directly measured 3-dimensional hand position measurements as input, we present results on two different movements | a size gesture and a point gesture | and show robustness with respect to noise in the input features.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. F. Bobick A. D. Wilson and J. Cassell. </author> <title> Temporal classification of natural gesture and application to video coding. </title> <booktitle> Proc. Comp. Vis. and Pattern Rec., </booktitle> <year> 1997. </year> <note> to appear. </note>
Reference-contexts: Darrell [7] addresses the problem of crafting perceptual strategies automatically in part by training a model of attention. The model learns a policy to select features from the input using partially observable Markov decision process (POMDP). In <ref> [1] </ref> we used hand-tuned HMMs using temporal properties to recognize two broad classes of natural, spontaneous gesture. Campbell and Bobick [6] search for orthogonal projections of the feature space to find the most diagnostic projections in order to classify ballet steps.
Reference: [2] <author> A. Azarbayejani and A. Pentland. </author> <title> Real-time self-calibrating stereo person tracking using 3-D shape estimation from blob features. </title> <booktitle> In Proceedings of 13th ICPR, </booktitle> <address> Vienna, Austria, August 1996. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference: [3] <author> C. M. Bishop. </author> <title> Neural networks for pattern recognition. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1995. </year>
Reference: [4] <author> R.A. </author> <title> Brooks and T.O. Binford. Interpretive vision. </title> <booktitle> In AAAI-80, </booktitle> <pages> pages 21-24, </pages> <year> 1980. </year>
Reference-contexts: Their framework has been used, for example, to recover the camera angle relative to a known object in the field of view. Parameterized object recognition has sought to couple the matching problem with the estimation of parameters of the object. For example, ACRONYM (Brooks <ref> [4] </ref>) uses constraints on the free parameters that specify the shape of an object. The recognition is then a matter of satisfying these constraints and setting the free parameters. Potential approaches to parameterized object recognition are discussed in [10]. Recently there has been interest in methods that recover latent parameterizations.
Reference: [5] <author> M. Svensen C. M. Bishop and C. K. I. Williams. </author> <title> EM optimization of latent-variable density models. </title> <editor> In M. C. Moser D. S. Touretzky and M. E. Hasselmo, editors, </editor> <booktitle> Advances in neural information processing systems 8, </booktitle> <pages> pages 402-408. </pages> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: In his "family discovery" paradigm, Omohundro [14], for example, outlines a variety of approaches to learning the nonlinear manifold representing systematic variation. One of these techniques has been applied to the task of lip reading by Bregler and Omohundro. Bishop, Svensen and Williams <ref> [5] </ref> have also introduced techniques to learn latent parameterizations. Their system begins with an assumption of the dimensionality of the parameterization and uses an expectation-maximization framework to compute a manifold. Lastly we mention Tennenbaum and Freeman's work on separating style from content.
Reference: [6] <author> L. W. Campbell and A. F. Bobick. </author> <title> Recognition of human body motion using phase space constraints. </title> <booktitle> In Proc. Int. Conf. Comp. Vis., </booktitle> <year> 1995. </year>
Reference-contexts: The model learns a policy to select features from the input using partially observable Markov decision process (POMDP). In [1] we used hand-tuned HMMs using temporal properties to recognize two broad classes of natural, spontaneous gesture. Campbell and Bobick <ref> [6] </ref> search for orthogonal projections of the feature space to find the most diagnostic projections in order to classify ballet steps. In [20], we apply HMMs to the task of hand gesture recognition from video by training an eigenvector basis set of the images at each state.
Reference: [7] <author> T. Darrell and A. Pentland. </author> <title> Active gesture recognition using partially observable markov decision processes. </title> <booktitle> In ICPR96, </booktitle> <year> 1996. </year>
Reference-contexts: Perseus, for example, understands pointing gestures by detecting when the user's arm is extended. The system then finds the pointing direction by computing the line from the head to the user's hand. Darrell <ref> [7] </ref> addresses the problem of crafting perceptual strategies automatically in part by training a model of attention. The model learns a policy to select features from the input using partially observable Markov decision process (POMDP).
Reference: [8] <author> T.J. Darrell and A.P. Pentland. </author> <title> Space-time gestures. </title> <booktitle> Proc. Comp. Vis. and Pattern Rec., </booktitle> <pages> pages 335-340, </pages> <year> 1993. </year>
Reference-contexts: For example, Darrell and Pentland <ref> [8] </ref> applied dynamic time warping to match image template correlation scores against models to recognize hand gestures from video. A gesture model is represented by a temporal pattern of correlation scores. Schlenzig, Hunter and Jain [17] used HMMs and a rotation-invariant image representation to recognize hand gestures from video.
Reference: [9] <author> Trevor Darrell, Pattie Maes, Bruce Blumberg, and Alex Pentland. </author> <title> A novel environment for situated vision and behavior. </title> <booktitle> In Proc. of CVPR-94 Workshop 7 for Visual Behaviors, </booktitle> <pages> pages 68-72, </pages> <address> Seattle, Washing--ton, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: These are relevant for the present work in that the system is charged with the task of extracting a parameter important to the interaction as well as the task of recognizing that the gesture occurred. The ALIVE <ref> [9] </ref> and Perseus [12] systems are examples. The typical approach of these systems is to first identify static configurations of the user's body that are diagnostic of the gesture, and then use an unrelated method to extract the parameter of interest (e.g., direction of pointing).
Reference: [10] <author> W.E.L. Grimson, T. Lozano-Perez, </author> <title> and D.P. Hutten-locher. Object Recognition by Computer: The Role of Geometric Constraints. </title> <year> 1990. </year>
Reference-contexts: For example, ACRONYM (Brooks [4]) uses constraints on the free parameters that specify the shape of an object. The recognition is then a matter of satisfying these constraints and setting the free parameters. Potential approaches to parameterized object recognition are discussed in <ref> [10] </ref>. Recently there has been interest in methods that recover latent parameterizations. In his "family discovery" paradigm, Omohundro [14], for example, outlines a variety of approaches to learning the nonlinear manifold representing systematic variation.
Reference: [11] <author> R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton. </author> <title> Adaptive mixtures of local experts. </title> <journal> Neural Computation, </journal> <volume> 3 </volume> <pages> 79-87, </pages> <year> 1991. </year>
Reference-contexts: Each DTW model or HMM is associated with a point in parameter space. In learning, the problem of allocating training examples labeled by a continuous variable to one of a discrete set of models is eliminated by uniting the models in a mixture of experts framework <ref> [11] </ref>. In testing, the parameter is extracted by finding the best match among the models and looking up its associated parameter value. The dependency of the movement's form on the parameter is thus removed.
Reference: [12] <author> R.E. Kahn and M.J. Swain. </author> <title> Understanding people pointing: </title> <booktitle> The perseus system. In Proc. IEEE Int'l. Symp. on Comp. Vis., </booktitle> <pages> pages 569-574, </pages> <address> Coral Gables, Florida, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: These are relevant for the present work in that the system is charged with the task of extracting a parameter important to the interaction as well as the task of recognizing that the gesture occurred. The ALIVE [9] and Perseus <ref> [12] </ref> systems are examples. The typical approach of these systems is to first identify static configurations of the user's body that are diagnostic of the gesture, and then use an unrelated method to extract the parameter of interest (e.g., direction of pointing).
Reference: [13] <author> H. Murase and S. Nayar. </author> <title> Visual learning and recognition of 3-D objects from appearance. </title> <journal> Int. J. of Comp. Vis., </journal> <volume> 14 </volume> <pages> 5-24, </pages> <year> 1995. </year>
Reference-contexts: The state mem bership is thus invariant to variance along the eigenvectors. Although not applied to images directly, the present work is an extension of this earlier work in that the goal is to recover a parameterization of the systematic variation of the gesture. Murase and Nayar <ref> [13] </ref> parameterize meaningful variation in the appearance of images by computing a representation of the nonlinear manifold of the images in an eigenspace of the images. Their work is similar to ours in that training assumes that each input feature vector is labeled with the value of the parameterization.
Reference: [14] <author> S. M. Omohundro. </author> <title> Family discovery. </title> <editor> In M. C. Moser D. S. Touretzky and M. E. Hasselmo, editors, </editor> <booktitle> Advances in neural information processing systems 8, </booktitle> <pages> pages 402-408. </pages> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: The recognition is then a matter of satisfying these constraints and setting the free parameters. Potential approaches to parameterized object recognition are discussed in [10]. Recently there has been interest in methods that recover latent parameterizations. In his "family discovery" paradigm, Omohundro <ref> [14] </ref>, for example, outlines a variety of approaches to learning the nonlinear manifold representing systematic variation. One of these techniques has been applied to the task of lip reading by Bregler and Omohundro. Bishop, Svensen and Williams [5] have also introduced techniques to learn latent parameterizations.
Reference: [15] <author> H. Poizner, E. S. Klima, U. Bellugi, and R. B. Livingston. </author> <title> Motion analysis of grammatical processes in a visual-gestural language. </title> <booktitle> In ACM SIG-GRAPH/SIGART Interdisciplinary Workshop, Motion: Representation and Perception, </booktitle> <pages> pages 148-171, </pages> <address> Toronto, </address> <month> April </month> <year> 1983. </year>
Reference-contexts: For example, Starner and Pentland restrict the ASL alphabet to repeatable, non-varying gestures. In fact ASL is subject to complex grammatical processes that operate on multiple simultaneous levels. These kinds of variation in ASL are addressed in a machine perception framework by Poizner et al <ref> [15] </ref>. A number of systems have been developed which use gesture recognition within an interactive context.
Reference: [16] <author> L. R. Rabiner and B. H. Juang. </author> <title> An introduction to hidden markov models. </title> <journal> IEEE ASSP Magazine, </journal> <pages> pages 4-16, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: We begin with the usual HMM formulation <ref> [16] </ref> and change the form of the output probability 1 In such a situation it is not sufficient to simply interpolate the match scores of just a few models in a high dimensional space since either (1) there will be significant portions of the space for which there is no response <p> get the update equation for Z j : Z j = X fl ktj x kt T # " k;t k (8) Once the means are estimated, the covariance matrices j are updated in the usual way: j = k;t t fl ktj as is the matrix of transition probabilities <ref> [16] </ref>. 3.3 Testing In testing we are given an HMM and an input sequence. We wish to compute the value of and the probability that the HMM produced the sequence.
Reference: [17] <author> J. Schlenzig, E. Hunter, and R. Jain. </author> <title> Vision based hand gesture interpretation using recursive estimation. </title> <booktitle> In Proc. of the Twenty-Eighth Asilomar Conf. on Signals, Systems and Comp., </booktitle> <month> October </month> <year> 1994. </year>
Reference-contexts: For example, Darrell and Pentland [8] applied dynamic time warping to match image template correlation scores against models to recognize hand gestures from video. A gesture model is represented by a temporal pattern of correlation scores. Schlenzig, Hunter and Jain <ref> [17] </ref> used HMMs and a rotation-invariant image representation to recognize hand gestures from video. Starner and Pent-land [18] applied HMMs to recognize ASL sentences. None of these works have developed representations to learn meaningful variation of the gestures.
Reference: [18] <author> T. E. Starner and A. Pentland. </author> <title> Visual recognition of American Sign Language using hidden markov models. </title> <booktitle> In Proc. of the Intl. Workshop on Automatic Face-and Gesture-Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year>
Reference-contexts: A gesture model is represented by a temporal pattern of correlation scores. Schlenzig, Hunter and Jain [17] used HMMs and a rotation-invariant image representation to recognize hand gestures from video. Starner and Pent-land <ref> [18] </ref> applied HMMs to recognize ASL sentences. None of these works have developed representations to learn meaningful variation of the gestures. For example, Starner and Pentland restrict the ASL alphabet to repeatable, non-varying gestures. In fact ASL is subject to complex grammatical processes that operate on multiple simultaneous levels.
Reference: [19] <author> J. Tennenbaum and W. Freeman. </author> <title> Separating style from content. </title> <booktitle> In Advances in neural information processing systems 9, </booktitle> <year> 1997. </year>
Reference: [20] <author> A. D. Wilson and A. F. Bobick. </author> <title> Learning visual behavior for gesture analysis. </title> <booktitle> In Proc. IEEE Int'l. Symp. on Comp. Vis., Coral Gables, </booktitle> <address> Florida, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: In [1] we used hand-tuned HMMs using temporal properties to recognize two broad classes of natural, spontaneous gesture. Campbell and Bobick [6] search for orthogonal projections of the feature space to find the most diagnostic projections in order to classify ballet steps. In <ref> [20] </ref>, we apply HMMs to the task of hand gesture recognition from video by training an eigenvector basis set of the images at each state. An image's membership to each state is a function of the residual of the reconstruction of the image using the state's eigenvectors.
Reference: [21] <author> A. D. Wilson and A. F. Bobick. (tbd). </author> <year> 1997. </year> <note> (to appear). </note>
Reference-contexts: In such a case we may perform gradient descent to maximize Q in the maximization step of the EM algorithm (which would then be called a "generalized expectation-maximization" (GEM) algorithm). In <ref> [21] </ref> we use neural networks and GEM algorithms to model the subjective quality of a motion. 6 Conclusion A new method for the representation and recognition of parameterized gesture is presented. The basic idea is to parameterize the underlying output probabilities of the states of an HMM.
References-found: 21

