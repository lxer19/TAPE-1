URL: http://www.cs.nyu.edu/phd_students/baratloo/papers/tr1998-762.ps.gz
Refering-URL: http://www.cs.nyu.edu/phd_students/baratloo/html/publications.html
Root-URL: http://www.cs.nyu.edu
Email: fbaratloo,ayali,kedem,yuanyuang@cs.nyu.edu  
Title: Just-in-time Transparent Resource Management in Distributed Systems  
Author: Arash Baratloo Ayal Itzkovitz Zvi M. Kedem Yuanyuan Zhao 
Date: March 24, 1998  
Address: New York University  
Affiliation: Department of Computer Science  New York University Technion  
Pubnum: TR1998-762  
Abstract: This paper presents the design and the implementation of a resource management system for monitoring computing resources on a network and for dynamically allocating them to concurrently executing jobs. In particular, it is designed to support adaptive parallel computations|computations that benefit from addition of new machines, and can tolerate removal of machines while executing. The challenge for such a resource manager is to communicate the availability of resources to running programs even when the programs were not developed to work with external resource managers. Our main contribution is a novel mechanism addressing this issue, built on low-level features common to popular parallel programming systems. Existing resource management systems for adaptive computations either require tight integration with the operating system (DRMS), or require an integration with a programming system that is aware of external resource managers (e.g. Condor/CARMI, MPVM, Piranha). Thus in each case, their support is limited to a single type of programming system. In contrast, our resource management system is unique in supporting several unmodified parallel programming systems. Furthermore, the system runs with user-level privilege, and thus can not compromise the security of the network. The underlying mechanism and the overall system have been validated on a dynamically changing mix of jobs, some sequential, some PVM, some MPI, and some Calypso computations. We demonstrate the feasibility and the usefulness of our approach, thus showing how to construct a middleware resource management system to enhance the utilizations of distributed systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Agrawal and A. Ezzat. </author> <title> Location independent remote execution in NEST. </title> <journal> IEEE Transactions on Software Engineering, </journal> <year> 1987. </year>
Reference-contexts: Second, it shows that in the presence of adaptive programs, a resource manager can boost utilization of a network to above 99%. 7 Brief Overview of Selected Resource Management Systems Initial resource management services were designed at the operating system level, e.g., NEST <ref> [1] </ref>, V [34], Sprite [13], MOSIX [4] and Remote Unix [24]. Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell.
Reference: [2] <author> R. Arpaci, A. Dusseau, A. Vahdat, L. Liu, T. Anderson, and D. Patterson. </author> <title> The interaction of parallel and sequential workloads on a network of workstations. </title> <booktitle> In Proc. of SIGMETRICS, </booktitle> <year> 1995. </year>
Reference: [3] <author> M. Baker, G. Fox, and H. Yau. </author> <title> A review of commercial and research cluster management software. </title> <institution> Northeast Parallel Architectures Center, Syracuse University, </institution> <year> 1996. </year>
Reference: [4] <author> A. Barak, S. Guday, and R. Wheller. </author> <title> The MOSIX distributed operating system load balancing for Unix. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: Second, it shows that in the presence of adaptive programs, a resource manager can boost utilization of a network to above 99%. 7 Brief Overview of Selected Resource Management Systems Initial resource management services were designed at the operating system level, e.g., NEST [1], V [34], Sprite [13], MOSIX <ref> [4] </ref> and Remote Unix [24]. Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE [14], PBS [21], and LoadLever [22] were originally targeted to handle sequential batch jobs.
Reference: [5] <author> A. Baratloo, P. Dasgupta, and Z. Kedem. Calypso: </author> <title> A novel software system for fault-tolerant parallel processing on distributed platforms. </title> <booktitle> In Proc. of IEEE International Symposium on High-Performance Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: We refer to such computations as adaptive. Most master-slave PVM [18] programs, self-scheduling MPI [20] programs, and all Calypso <ref> [5] </ref> programs are adaptive. Indeed, such programs can run on a varying number of machines (as opposed to a fixed number), and remote processes can be added/removed at any time during the computation.
Reference: [6] <author> N. Carriero and D. Gelernter. </author> <title> Linda in context. </title> <journal> Communication of ACM, </journal> <year> 1989. </year>
Reference: [7] <author> N. Carriero, D. Gelernter, D. Kaminsky, and J. Westbrook. </author> <title> Adaptive parallelism with Piranha. </title> <type> Technical Report 954, </type> <institution> Yale University Department of Computer Science, </institution> <year> 1993. </year>
Reference-contexts: Resource management systems developed for adaptive programs such as Piranha <ref> [7] </ref>, MPVM [8], Condor/CARMI [33], and DRMS [26] are system specific. DRMS uses implementation-specific mechanisms to modify MPI routing tables; others, such as Piranha, MPVM, and CARMI, rely on system-specific interfaces to manage adaptive programs. <p> Process migration helps in dispersing a load of a heavily-loaded machine, but it does not increase the number processes in a parallel job. Systems such as Piranha <ref> [7] </ref>, MPVM [8], Condor/CARMI [33], and DRMS [26] specifically target parallel computations and are capable of dynamically allocating machines to a running job as resources become available, and deallocating machines if they are needed elsewhere.
Reference: [8] <author> J. Casas, D. Clark, R. Konuru, S. Otto, R. Prouty, and J. Walpole. MPVM: </author> <title> A migration transparent version of PVM. </title> <booktitle> Computing Systems, </booktitle> <year> 1995. </year>
Reference-contexts: Resource management systems developed for adaptive programs such as Piranha [7], MPVM <ref> [8] </ref>, Condor/CARMI [33], and DRMS [26] are system specific. DRMS uses implementation-specific mechanisms to modify MPI routing tables; others, such as Piranha, MPVM, and CARMI, rely on system-specific interfaces to manage adaptive programs. For example, CARMI depends on the job management API defined by PVM to provide its services. <p> Process migration helps in dispersing a load of a heavily-loaded machine, but it does not increase the number processes in a parallel job. Systems such as Piranha [7], MPVM <ref> [8] </ref>, Condor/CARMI [33], and DRMS [26] specifically target parallel computations and are capable of dynamically allocating machines to a running job as resources become available, and deallocating machines if they are needed elsewhere.
Reference: [9] <author> D. Cheng. </author> <title> A survey of parallel programming languages and tools. </title> <type> NAS Technical Report RND-93-005, </type> <institution> NASA Ames Research Center, </institution> <year> 1993. </year>
Reference: [10] <author> E. Chung, Y. Huang, and S. Yajnik. </author> <title> Checkpointing in CosMic: A user-level process migration environment. </title> <booktitle> In Proc. of Pacific Rim Symp. on Fault-Tolerant Computing, </booktitle> <year> 1997. </year>
Reference-contexts: 1 Introduction The number of networked machines in many organization is rapidly growing, while frequently many are underutilized or even idle <ref> [29, 34, 10, 13, 27] </ref>. Such environments are therefore potentially excellent platforms for executing compute-intensive parallel jobs as "guests," in addition to the regular applications for which the machines are designated.
Reference: [11] <author> K. Czajkowski, I. Foster, C. Kesselman, S. Martin, W. Smith and S. Tuecke. </author> <title> A Resource Management Architecture for Metacomputing. </title> <note> Available at http://www.globus.org/globus/papers.htm. </note>
Reference-contexts: It imposes no overhead at other times. In the next two sections we describe the goals and then the architecture of our system. The architecture supports interaction of users and running jobs with the resource manager. The specification for this interaction (with parts influenced by the Globus project <ref> [11] </ref>) is presented in Section 4. Section 5 describes the mechanism our resource manager utilizes to dynamically change the allocation of resources to running jobs. Experimental results are presented in Section 6. <p> We adopted the Resource Specification Language of Globus <ref> [11] </ref>, and extended the specification to support adaptive programs. See Figure 4 for the specification grammar. Specifically, we added adaptive, start script, and module parameters for users to describe the nature of their adaptive jobs.
Reference: [12] <author> L. Dikken, F. van Der Linden, J. Vesseur, and P. Sloot. DynamicPVM: </author> <title> Dynamic load balancing on parallel systems. </title> <booktitle> In Proc. High-Performance Computing and Networking, </booktitle> <year> 1994. </year>
Reference-contexts: Some attempts to dynamically load balance parallel jobs relied on techniques similar to load-balancing sequential jobs: process checkpointing and migration, e.g., GLUnix [35], PRM [28], and DynamicPVM <ref> [12] </ref>. Process migration helps in dispersing a load of a heavily-loaded machine, but it does not increase the number processes in a parallel job.
Reference: [13] <author> F. Douglis and J. Ousterhout. </author> <title> Transparent process migration: Design alternatives and the Sprite implementation. </title> <journal> Software Practice and Experience, </journal> <year> 1991. </year>
Reference-contexts: 1 Introduction The number of networked machines in many organization is rapidly growing, while frequently many are underutilized or even idle <ref> [29, 34, 10, 13, 27] </ref>. Such environments are therefore potentially excellent platforms for executing compute-intensive parallel jobs as "guests," in addition to the regular applications for which the machines are designated. <p> Second, it shows that in the presence of adaptive programs, a resource manager can boost utilization of a network to above 99%. 7 Brief Overview of Selected Resource Management Systems Initial resource management services were designed at the operating system level, e.g., NEST [1], V [34], Sprite <ref> [13] </ref>, MOSIX [4] and Remote Unix [24]. Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell.
Reference: [14] <author> D. Duke, T. Green, and J. Pasko. </author> <title> Research toward a heterogeneous networked computer cluster: The distributed queuing system version 3.0. </title> <institution> Supercomputer Computations Research Institute, Florida State University, </institution> <year> 1994. </year>
Reference-contexts: Furthermore, it should be able to simultaneously manage a variety of computations written using diverse programming systems. Existing resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE <ref> [14] </ref>, PBS [21], and IBM's LoadLever [22] were initially developed to manage sequential jobs. <p> Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE <ref> [14] </ref>, PBS [21], and LoadLever [22] were originally targeted to handle sequential batch jobs. While successful in this, their support for parallel applications is in some sense batch-like, and of restricted scope.
Reference: [15] <author> M. Eskicioglu. </author> <title> A comprehensive bibliography of distributed shared memory. </title> <booktitle> Operating Systems Review, </booktitle> <month> January </month> <year> 1996. </year>
Reference: [16] <author> R. Felderman, E. Schooler, and L. Kleinrock. </author> <title> The Benevolent Bandit laboratory: A testbed for distributed algorithms. </title> <journal> In IEEE Journal on Selected Areas in Communications, </journal> <year> 1989. </year>
Reference-contexts: The concept of the separation of the two management services was discussed in work by Benevolent Bandit Laboratory <ref> [16] </ref>. Resource managers for adaptive programs, such as Piranha, MPVM, Condor/CARMI, have integrated intra- and inter-job resource managers. The interaction between a PVM job and the CARMI resource manager, for example, is implemented through a system dependent API and communication libraries.
Reference: [17] <author> G. Fowler. </author> <title> The shell as a server. </title> <booktitle> In Cincinnati USENIX Conf. Proceedings, </booktitle> <year> 1993. </year>
Reference-contexts: Coshell <ref> [17] </ref> provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE [14], PBS [21], and LoadLever [22] were originally targeted to handle sequential batch jobs.
Reference: [18] <author> A. Geist, A. Beguelin, J. Dongarra, W. Jiang, R. Manchek, and V. Sunderam. </author> <title> PVM: Parallel virtual machine. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: We refer to such computations as adaptive. Most master-slave PVM <ref> [18] </ref> programs, self-scheduling MPI [20] programs, and all Calypso [5] programs are adaptive. Indeed, such programs can run on a varying number of machines (as opposed to a fixed number), and remote processes can be added/removed at any time during the computation.
Reference: [19] <author> T. Green and J. Snyder. DQS, </author> <title> a distributed queueing system. </title> <institution> Supercomputer Computations Research Institute, Florida State University, </institution> <year> 1991. </year> <month> 17 </month>
Reference: [20] <author> W. Gropp, E. Lust, and A. Skjellum. </author> <title> Using MPI: Portable parallel programming with the message--passing interface. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: We refer to such computations as adaptive. Most master-slave PVM [18] programs, self-scheduling MPI <ref> [20] </ref> programs, and all Calypso [5] programs are adaptive. Indeed, such programs can run on a varying number of machines (as opposed to a fixed number), and remote processes can be added/removed at any time during the computation.
Reference: [21] <author> R. Henderson and D. Tweten. </author> <title> Portable Batch System. NAS Scientific Computing Branch, </title> <institution> NASA Ames Research Center, </institution> <year> 1995. </year>
Reference-contexts: Furthermore, it should be able to simultaneously manage a variety of computations written using diverse programming systems. Existing resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE [14], PBS <ref> [21] </ref>, and IBM's LoadLever [22] were initially developed to manage sequential jobs. <p> Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE [14], PBS <ref> [21] </ref>, and LoadLever [22] were originally targeted to handle sequential batch jobs. While successful in this, their support for parallel applications is in some sense batch-like, and of restricted scope. To use these systems the user submits a job and specifies the number and the types of machines required.
Reference: [22] <institution> IBM. IBM LoadLeveler: General information. </institution> <address> 2nd edition, </address> <year> 1993. </year>
Reference-contexts: Furthermore, it should be able to simultaneously manage a variety of computations written using diverse programming systems. Existing resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE [14], PBS [21], and IBM's LoadLever <ref> [22] </ref> were initially developed to manage sequential jobs. <p> Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE [14], PBS [21], and LoadLever <ref> [22] </ref> were originally targeted to handle sequential batch jobs. While successful in this, their support for parallel applications is in some sense batch-like, and of restricted scope. To use these systems the user submits a job and specifies the number and the types of machines required.
Reference: [23] <author> J. Jones and C. Brickell. </author> <title> Second evaluation of job queuing/scheduling software: Phase I report. </title> <type> NAS Technical Report NAS-97-013, </type> <year> 1997. </year>
Reference-contexts: Existing resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE [14], PBS [21], and IBM's LoadLever [22] were initially developed to manage sequential jobs. In a recent study performed at NASA Ames Research Center <ref> [23] </ref>, six commercial and research resource management systems were evaluated and it was reported that "the bad news is the confirmation of continuing lack of JMS [Job Management System] support for parallel applications, parallel systems, and clusters of machines." In such systems, the allocation of machines is static and only done
Reference: [24] <author> M. Litzkow. </author> <title> UNIX: Turning idle workstations into cycle servers. </title> <booktitle> In Proc. Summer 1987 USENIX Conference, </booktitle> <year> 1987. </year>
Reference-contexts: that in the presence of adaptive programs, a resource manager can boost utilization of a network to above 99%. 7 Brief Overview of Selected Resource Management Systems Initial resource management services were designed at the operating system level, e.g., NEST [1], V [34], Sprite [13], MOSIX [4] and Remote Unix <ref> [24] </ref>. Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor [25], Utopia/LSF [36, 32], DQS/CODINE [14], PBS [21], and LoadLever [22] were originally targeted to handle sequential batch jobs.
Reference: [25] <author> M. Lizkow, M. Livny, and M. </author> <title> Mutka. Condor: A hunter of idle workstations. </title> <booktitle> In Proc. </booktitle> <address> ICDCS, </address> <year> 1988. </year>
Reference-contexts: Furthermore, it should be able to simultaneously manage a variety of computations written using diverse programming systems. Existing resource management systems such as Condor <ref> [25] </ref>, Utopia/LSF [36, 32], DQS/CODINE [14], PBS [21], and IBM's LoadLever [22] were initially developed to manage sequential jobs. <p> Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor <ref> [25] </ref>, Utopia/LSF [36, 32], DQS/CODINE [14], PBS [21], and LoadLever [22] were originally targeted to handle sequential batch jobs. While successful in this, their support for parallel applications is in some sense batch-like, and of restricted scope.
Reference: [26] <author> J. Moreira, V. Naik, and R. Konuru. </author> <title> A programming environment for dynamic resource allocation and data distribution. </title> <booktitle> In Proc. 9th Workshop on Languages and Compilers for Parallel Computing, </booktitle> <year> 1996. </year>
Reference-contexts: Resource management systems developed for adaptive programs such as Piranha [7], MPVM [8], Condor/CARMI [33], and DRMS <ref> [26] </ref> are system specific. DRMS uses implementation-specific mechanisms to modify MPI routing tables; others, such as Piranha, MPVM, and CARMI, rely on system-specific interfaces to manage adaptive programs. For example, CARMI depends on the job management API defined by PVM to provide its services. <p> Process migration helps in dispersing a load of a heavily-loaded machine, but it does not increase the number processes in a parallel job. Systems such as Piranha [7], MPVM [8], Condor/CARMI [33], and DRMS <ref> [26] </ref> specifically target parallel computations and are capable of dynamically allocating machines to a running job as resources become available, and deallocating machines if they are needed elsewhere. However, they are tightly integrated with either the underlying system or with the parallel programming environment they support.
Reference: [27] <author> M. Mutka and M. Livny. </author> <title> The available capacity of a privately owned workstation environment. Performance Evaluation, </title> <year> 1991. </year>
Reference-contexts: 1 Introduction The number of networked machines in many organization is rapidly growing, while frequently many are underutilized or even idle <ref> [29, 34, 10, 13, 27] </ref>. Such environments are therefore potentially excellent platforms for executing compute-intensive parallel jobs as "guests," in addition to the regular applications for which the machines are designated.
Reference: [28] <author> C. Neuman and S. Rao. </author> <title> The Prospero resource manager: A scalable framework for processor allocation in distributed systems. </title> <journal> Concurrency: Practice and Experience, </journal> <year> 1994. </year>
Reference-contexts: Some attempts to dynamically load balance parallel jobs relied on techniques similar to load-balancing sequential jobs: process checkpointing and migration, e.g., GLUnix [35], PRM <ref> [28] </ref>, and DynamicPVM [12]. Process migration helps in dispersing a load of a heavily-loaded machine, but it does not increase the number processes in a parallel job.
Reference: [29] <author> D. Nichols. </author> <title> Using idle workstations in a shared computing environment. </title> <booktitle> In Proc. of SOSP, </booktitle> <year> 1987. </year>
Reference-contexts: 1 Introduction The number of networked machines in many organization is rapidly growing, while frequently many are underutilized or even idle <ref> [29, 34, 10, 13, 27] </ref>. Such environments are therefore potentially excellent platforms for executing compute-intensive parallel jobs as "guests," in addition to the regular applications for which the machines are designated.
Reference: [30] <institution> Ohio Supercomputer Center. MPI primer/developing with LAM. Ohio State University, </institution> <year> 1996. </year>
Reference-contexts: Of course, "standard" non-adaptive programs are supported too. 3 * Simultaneous support for diverse programming systems: Support is provided for a mix of computations including sequential, PVM, LAM <ref> [30] </ref> (an implementation of the MPI standard), and Calypso, running concurrently on a heterogeneous network. * System independence: We treat parallel programming environments as COTS, and do not make any modifications to them.
Reference: [31] <author> J. Pruyne and M. Livny. </author> <title> Interfacing Condor and PVM to harness the cycles of workstation clusters. </title> <journal> Journal on Future Generations of Computer Systems, </journal> <year> 1996. </year>
Reference: [32] <author> Platform Computing Corporation. </author> <title> LSF User's and administrator's guide. </title> <address> Toronto, Canada, </address> <year> 1993. </year>
Reference-contexts: Furthermore, it should be able to simultaneously manage a variety of computations written using diverse programming systems. Existing resource management systems such as Condor [25], Utopia/LSF <ref> [36, 32] </ref>, DQS/CODINE [14], PBS [21], and IBM's LoadLever [22] were initially developed to manage sequential jobs. <p> Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor [25], Utopia/LSF <ref> [36, 32] </ref>, DQS/CODINE [14], PBS [21], and LoadLever [22] were originally targeted to handle sequential batch jobs. While successful in this, their support for parallel applications is in some sense batch-like, and of restricted scope.
Reference: [33] <author> J. Pruyne and M. Livny. </author> <title> Parallel processing on dynamic resources with CARMI. </title> <booktitle> In Job Scheduling Strategies for Parallel Processing-IPPS'95 Workshop Proceedings, </booktitle> <year> 1995. </year>
Reference-contexts: Resource management systems developed for adaptive programs such as Piranha [7], MPVM [8], Condor/CARMI <ref> [33] </ref>, and DRMS [26] are system specific. DRMS uses implementation-specific mechanisms to modify MPI routing tables; others, such as Piranha, MPVM, and CARMI, rely on system-specific interfaces to manage adaptive programs. For example, CARMI depends on the job management API defined by PVM to provide its services. <p> Process migration helps in dispersing a load of a heavily-loaded machine, but it does not increase the number processes in a parallel job. Systems such as Piranha [7], MPVM [8], Condor/CARMI <ref> [33] </ref>, and DRMS [26] specifically target parallel computations and are capable of dynamically allocating machines to a running job as resources become available, and deallocating machines if they are needed elsewhere. However, they are tightly integrated with either the underlying system or with the parallel programming environment they support.
Reference: [34] <author> M. Theimer and K. Lantz. </author> <title> Finding idle machines in a workstation-based distributed system. </title> <journal> IEEE Transactions on Software Engineering, </journal> <year> 1989. </year>
Reference-contexts: 1 Introduction The number of networked machines in many organization is rapidly growing, while frequently many are underutilized or even idle <ref> [29, 34, 10, 13, 27] </ref>. Such environments are therefore potentially excellent platforms for executing compute-intensive parallel jobs as "guests," in addition to the regular applications for which the machines are designated. <p> Second, it shows that in the presence of adaptive programs, a resource manager can boost utilization of a network to above 99%. 7 Brief Overview of Selected Resource Management Systems Initial resource management services were designed at the operating system level, e.g., NEST [1], V <ref> [34] </ref>, Sprite [13], MOSIX [4] and Remote Unix [24]. Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell.
Reference: [35] <author> A. Vahdat, D. Ghormley, and T. Anderson. </author> <title> Efficient, portable, and robust extension of operating system functionality. </title> <type> UC Berkeley Technical Report CS-94-842, </type> <year> 1994. </year>
Reference-contexts: Some attempts to dynamically load balance parallel jobs relied on techniques similar to load-balancing sequential jobs: process checkpointing and migration, e.g., GLUnix <ref> [35] </ref>, PRM [28], and DynamicPVM [12]. Process migration helps in dispersing a load of a heavily-loaded machine, but it does not increase the number processes in a parallel job.
Reference: [36] <author> S. Zhou, J. Wang, X. Zheng, and P. Delisle. </author> <title> Utopia: A load sharing facility for large, heterogeneous distributed computing systems. </title> <institution> Computer Systems Research Institute, University of Toronto, </institution> <year> 1992. </year> <month> 18 </month>
Reference-contexts: Furthermore, it should be able to simultaneously manage a variety of computations written using diverse programming systems. Existing resource management systems such as Condor [25], Utopia/LSF <ref> [36, 32] </ref>, DQS/CODINE [14], PBS [21], and IBM's LoadLever [22] were initially developed to manage sequential jobs. <p> Coshell [17] provided the same functionality, not as a part of the operating system, but as a UNIX shell. Resource management systems such as Condor [25], Utopia/LSF <ref> [36, 32] </ref>, DQS/CODINE [14], PBS [21], and LoadLever [22] were originally targeted to handle sequential batch jobs. While successful in this, their support for parallel applications is in some sense batch-like, and of restricted scope.
References-found: 36

