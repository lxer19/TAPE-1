URL: http://www.cs.kuleuven.ac.be/publicaties/rapporten/cw/CW250.ps.gz
Refering-URL: http://www.cs.kuleuven.ac.be/publicaties/rapporten/CW1997.html
Root-URL: 
Title: Constrained Partial Deduction and the Preservation of Characteristic Trees  
Author: Michael Leuschel and Danny De Schreye 
Keyword: Logic Programming, Program Specialisation, Partial Deduction, Constraints.  
Note: This is a revised version of CW 199 and CW 215.  CR Subject Classification I.2.2, D.1.2, I.2.3, F.4.1, D.1.6.  
Affiliation: Department of Computing Science, K.U.Leuven  
Date: 250, June 1997  
Pubnum: Report CW  
Abstract: Partial deduction strategies for logic programs often use an abstraction operator to guarantee the finiteness of the set of goals for which partial deductions are produced. Finding an abstraction operator which guarantees finiteness and does not lose relevant information is a difficult problem. In earlier work Gallagher and Bruynooghe proposed to base the abstraction operator on characteristic paths and trees, which capture the structure of the generated incomplete SLDNF-tree for a given goal. In this paper we exhibit the advantages of characteristic trees over purely syntactical measures: if characteristic trees can be preserved upon generali- sation, then we obtain an almost perfect abstraction operator, providing just enough polyvariance to avoid any loss of local specialisation. Unfortunately, the abstraction operators proposed in earlier work do not always preserve the characteristic trees upon generalisation. We show that this can lead to important specialisation losses as well as to non-termination of the partial deduction algorithm. Furthermore, this problem cannot be adequately solved in the ordinary partial deduction setting. We therefore extend the expressivity and precision of the Lloyd and Shep- herdson partial deduction framework by integrating constraints. We provide formal correctness results for the so obtained generic framework of constrained partial deduction. Within this new framework we are, among others, able to overcome the above mentioned problems by introducing an alternative abstraction operator, based on so called pruning constraints. We thus present a terminating partial deduction strategy which, for purely determinate unfolding rules, induces no loss of local specialisation due to the abstraction while ensuring correctness of the specialised programs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. R. Apt. </author> <title> Introduction to logic programming. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, chapter 10, </booktitle> <pages> pages 495-574. </pages> <publisher> North-Holland Amsterdam, </publisher> <year> 1990. </year>
Reference-contexts: We also discuss related work and other potential applications of the constrained partial deduction framework of Section 4. The conclusion can be found in Section 8. 2 Preliminaries and Motivations Throughout this paper, we suppose familiarity with basic notions in logic programming (see e.g. <ref> [1, 42] </ref>). Notational conventions are standard and self-evident. In particular, in programs, we denote variables through strings starting with (or usually just consisting of ) an uppercase symbol, while the names of constants, functions and predicates begin with a lower-case character. <p> Hence, as fl satisfies every n 2 prune P (B; t ), we can deduce that fl sat FT prune P (B; t ). 2. By the (correct version of the) lifting lemma <ref> [27, 43, 14, 1] </ref> we can deduce that t chpaths (P; B). Let us examine every p 2 t .
Reference: [2] <author> K. Benkerimi and P. M. Hill. </author> <title> Supporting transformations for the partial evaluation of logic programs. </title> <journal> Journal of Logic and Computation, </journal> <volume> 3(5) </volume> <pages> 469-486, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: For instance, instead of renaming A into the set A 0 above, A would be renamed into fmem a (L); mem b (X )g and the goal G would be renamed into mem a ([a; c]); mem b (b). For further details about filtering see e.g. [20] or <ref> [2] </ref> where the filtering phase is performed as a one-step post-processing renaming. See also [54], where filtering is obtained automatically when using folding to simulate partial evaluation. Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. <p> In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. [17, 18, 20, 38, 33, 34]) and adapted correctness results can be found in <ref> [2] </ref>. See also the more powerful filtering techniques in [41]. The local control component is encapsulated in the unfolding rule, defined above. In addition to local correctness, termination and precision, the requirements on unfolding rules also include avoiding search space explosion as well as work duplication. <p> An abstraction operator allowing just one version per predicate would have lost this local specialisation, while a method with unlimited polyvariance (also called dynamic renaming, in e.g. <ref> [2] </ref>) does not terminate. For this example, chabs P;U provides a terminating and fine grained control of polyvariance, conferring just as many versions as necessary. The abstraction operator chabs P;U is thus much more flexible than e.g. the static pre-processing renaming of [3, 50]). <p> Proof First note that the A; D-coveredness condition ensures that the renamings performed to obtain P 0 (according to Definition 4.11), as well as the renaming ff (G), are defined. The result then follows in a rather straightforward manner from the Theorems 3.5 and 4.11 in <ref> [2] </ref>. In [2] the filtering has been split into 2 phases: one which does just the renaming to ensure independence (called partial deduction with dynamic renaming; correctness of this phase is proven in Theorem 3.5 of [2]) and one which does the filtering (called post-processing renaming; the correctness of this phase <p> Proof First note that the A; D-coveredness condition ensures that the renamings performed to obtain P 0 (according to Definition 4.11), as well as the renaming ff (G), are defined. The result then follows in a rather straightforward manner from the Theorems 3.5 and 4.11 in <ref> [2] </ref>. In [2] the filtering has been split into 2 phases: one which does just the renaming to ensure independence (called partial deduction with dynamic renaming; correctness of this phase is proven in Theorem 3.5 of [2]) and one which does the filtering (called post-processing renaming; the correctness of this phase is proven <p> then follows in a rather straightforward manner from the Theorems 3.5 and 4.11 in <ref> [2] </ref>. In [2] the filtering has been split into 2 phases: one which does just the renaming to ensure independence (called partial deduction with dynamic renaming; correctness of this phase is proven in Theorem 3.5 of [2]) and one which does the filtering (called post-processing renaming; the correctness of this phase is proven in Theorem 4.11 of [2]). <p> split into 2 phases: one which does just the renaming to ensure independence (called partial deduction with dynamic renaming; correctness of this phase is proven in Theorem 3.5 of <ref> [2] </ref>) and one which does the filtering (called post-processing renaming; the correctness of this phase is proven in Theorem 4.11 of [2]). <p> Three minor technical issues have to be addressed in order to reuse the theorems from <ref> [2] </ref>: * Theorem 3.5 of [2] requires that no renaming be performed on G, i.e. ff (G) must be equal to G. <p> Three minor technical issues have to be addressed in order to reuse the theorems from <ref> [2] </ref>: * Theorem 3.5 of [2] requires that no renaming be performed on G, i.e. ff (G) must be equal to G. <p> Trivially the query new (X 1 ; : : : ; X k ) and G are equivalent wrt c.a.s. and finite failure (see also Lemma 2.2 in [19]). * Theorem 4.11 of <ref> [2] </ref> requires that G contains no variables or predicates in A. The requirement about the variables is not necessary in our case because we do not base our renaming on the mgu. <p> The requirement about the predicates is another way of ensuring that ff (G) must be equal to G, which can be circumvented in a similar way as for the first point above. 22 * Theorems 3.5 and 4.11 of <ref> [2] </ref> require that the predicates of the renaming do not occur in the original P . Our Definition 4.10 does not require this. This is of no importance as the original program is always "completely thrown away" in our approach. <p> Our Definition 4.10 does not require this. This is of no importance as the original program is always "completely thrown away" in our approach. We can still apply these theorems by using an intermediate renaming 0 which satisfies the requirements of Theorems 3.5 and 4.11 of <ref> [2] </ref> and then applying an additional one step post-processing renaming 00 , with ff = 0 00 , along with an extra application of Theorem 4.11 of [2]. 2 4.3.2 Correctness for Constrained Atoms Lemma 4.16 Let c 2 A be a constrained atom. <p> We can still apply these theorems by using an intermediate renaming 0 which satisfies the requirements of Theorems 3.5 and 4.11 of <ref> [2] </ref> and then applying an additional one step post-processing renaming 00 , with ff = 0 00 , along with an extra application of Theorem 4.11 of [2]. 2 4.3.2 Correctness for Constrained Atoms Lemma 4.16 Let c 2 A be a constrained atom. Let sat D c and let c be unsatisfiable. Then A and A have no common instance. Proof Suppose that A and A have a common instance Afl = A. <p> To that end we will use Lemma 4.17. However, this lemma talks about 10 Indeed, the same atom could in principle occur in several constrained atoms. This is not a problem, however, as the results in <ref> [2] </ref> carry over to multisets of atoms.
Reference: [3] <author> K. Benkerimi and J. W. Lloyd. </author> <title> A partial evaluation procedure for logic programs. </title> <editor> In S. Debray and M. Hermenegildo, editors, </editor> <booktitle> Proceedings of the North American Conference on Logic Programming, </booktitle> <pages> pages 343-358. </pages> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Then the following hold: 1. P 0 [ fGg has an SLDNF-refutation with computed answer iff P [ fGg does. 2. P 0 [ fGg has a finitely failed SLDNF-tree iff P [ fGg does. <ref> [3] </ref> also proposes an extension of Theorem 2.5 which uses a notion of coveredness instead of closedness. The basic idea is to restrict the attention to those parts of the specialised program P 0 which can be reached from G. <p> On the side of correctness there are two ways to ensure the independence condition. One is to apply a generalisation operator like the msg 2 on all the atoms in A which are not independent (first proposed in <ref> [3] </ref>). Applying this technique e.g. to the dependent set A = fmember (a; L); member (X; [b])g yields the independent set fmember (X; L)g. This approach also alleviates to some extent the global termination problem. <p> In [50] this problem has been remedied to some extent by using a static pre-processing renaming phase (as defined in <ref> [3] </ref>) which will generate one extra (renamed) version for the top-level atom to be specialised. However, this technique only works well if all relevant input can be consumed in one go (i.e. one unfolding) of this top-most atom. <p> For this example, chabs P;U provides a terminating and fine grained control of polyvariance, conferring just as many versions as necessary. The abstraction operator chabs P;U is thus much more flexible than e.g. the static pre-processing renaming of <ref> [3, 50] </ref>). The above example is thus very encouraging, and one might hope that chabs P;U always preserves the characteristic trees upon generalisation and that it might already provide a refined solution to the control of polyvariance problem. <p> Example 3.10 Let P be the following program, checking two lists for equality. (1) eqlist ([]; []) (2) eqlist ([H jX ]; [HjY ]) eqlist (X; Y ) 14 Given a purely determinate unfolding rule, the atoms A = eqlist ([1; 2]; L), B = eqlist (L; <ref> [3; 4] </ref>) have the same characteristic tree t = fh1 ffi 2; 1 ffi 2; 1 ffi 1ig. Unfortunately the abstraction operator chabs P;U is unable to preserve t . <p> If we use a strategy without renaming and an abstraction operator which allows only one msg per predicate, then partial deduction will not be able to remove the type checking. If we use the static renaming strategy of <ref> [3] </ref> then partial deduction is in this case able to remove the type checking while guaranteeing termination. However, this comes at the cost of a larger program (because of unnecessary polyvariance due to the static guidance).
Reference: [4] <author> R. Bol. </author> <title> Loop checking in partial deduction. </title> <journal> The Journal of Logic Programming, </journal> 16(1&2):25-46, 1993. 
Reference-contexts: The methods in [6, 50, 49, 46] are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. [13, 10]). Instead of well-founded ones, well-quasi orders can be used <ref> [4, 58] </ref>. Homeomorphic embedding [63, 40] on selected atoms has recently gained popularity as the basis for such an order. <p> Example 3.10 Let P be the following program, checking two lists for equality. (1) eqlist ([]; []) (2) eqlist ([H jX ]; [HjY ]) eqlist (X; Y ) 14 Given a purely determinate unfolding rule, the atoms A = eqlist ([1; 2]; L), B = eqlist (L; <ref> [3; 4] </ref>) have the same characteristic tree t = fh1 ffi 2; 1 ffi 2; 1 ffi 1ig. Unfortunately the abstraction operator chabs P;U is unable to preserve t .
Reference: [5] <author> A. Bossi, N. Cocco, and S. Dulli. </author> <title> A method for specialising logic programs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(2) </volume> <pages> 253-302, </pages> <year> 1990. </year>
Reference-contexts: Another method that might look like a viable alternative to our approach is the one of <ref> [5] </ref>, situated within the context of unfold/fold transformations. In particular, [5] contains many transformation rules and allows first-order logic formulas to be used to constrain the special- isation. It is thus a very powerful framework. <p> Another method that might look like a viable alternative to our approach is the one of <ref> [5] </ref>, situated within the context of unfold/fold transformations. In particular, [5] contains many transformation rules and allows first-order logic formulas to be used to constrain the special- isation. It is thus a very powerful framework. But also, because of that power, controlling it in an automatic way, as well as ensuring actual efficiency gains, is much more difficult. <p> It is thus a very powerful framework. But also, because of that power, controlling it in an automatic way, as well as ensuring actual efficiency gains, is much more difficult. A prototype for <ref> [5] </ref> exists, but the control heuristics as well as the correctness proofs are still left to the user. Let us also briefly discuss some further applications of constrained partial deduction, 39 beyond preserving characteristic trees.
Reference: [6] <author> M. Bruynooghe, D. De Schreye, and B. Martens. </author> <title> A general criterion for avoiding infinite unfolding during partial deduction. </title> <journal> New Generation Computing, </journal> <volume> 11(1) </volume> <pages> 47-79, </pages> <year> 1992. </year>
Reference-contexts: Termination can be ensured by imposing a depth bound, but much more refined approaches to ensure local termination exist. The methods in <ref> [6, 50, 49, 46] </ref> are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. [13, 10]). Instead of well-founded ones, well-quasi orders can be used [4, 58]. <p> So if we use renaming to ensure independence and suppose that the local termination and precision problems have been solved, e.g. by <ref> [6, 50, 49, 46] </ref>, we are still left with the problem of ensuring closedness and global termination while minimising the global precision loss.
Reference: [7] <author> D. Chan. </author> <title> Constructive negation based on the completed database. </title> <booktitle> In Proceedings of the Joint International Conference and Symposium on Logic Programming, </booktitle> <pages> pages 111-125, </pages> <address> Seattle, 1988. </address> <publisher> IEEE, MIT Press. </publisher>
Reference-contexts: So it is basically the same structure as the one used for CLP (F T ), as defined e.g. in [62]. 12 The same theory has also been used, for different purposes, in the constructive negation techniques (e.g. <ref> [7, 8, 15, 59, 66, 65] </ref>).
Reference: [8] <author> D. Chan and M. Wallace. </author> <title> A treatment of negation during partial evaluation. </title> <editor> In H. Abramson and M. Rogers, editors, </editor> <booktitle> Meta-Programming in Logic Programming, Proceedings of the Meta88 Workshop, </booktitle> <month> June </month> <year> 1988, </year> <pages> pages 299-318. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: So it is basically the same structure as the one used for CLP (F T ), as defined e.g. in [62]. 12 The same theory has also been used, for different purposes, in the constructive negation techniques (e.g. <ref> [7, 8, 15, 59, 66, 65] </ref>).
Reference: [9] <author> K. L. Clark. </author> <title> Negation as failure. </title> <editor> In H. Gallaire and J. Minker, editors, </editor> <booktitle> Logic and Data Bases, </booktitle> <pages> pages 293-322. </pages> <publisher> Plenum Press, </publisher> <year> 1978. </year>
Reference-contexts: For example, independently of D, :(X = c) 2 p (X) is a D-instance of true 2 p (X ) because every substitution satisfies true . In turn, if D contains e.g. Clark's equality theory (CET, see e.g. <ref> [9, 42] </ref>) then true 2 p (b) is a D-instance of :(X = c) 2 p (X ) because fX=bg sat D :(X = c) given CET (i.e. CET j= ~ 8 (:(b = c))). <p> Proof By definition A 1 6~ A 2 stands for ~ 8 vars (A 1 ) (:(A 1 = A 0 2 )) where A 0 2 has been obtained by standardising apart (wrt A 1 ). It is well known (see e.g. <ref> [9] </ref> or Lemma 15.2 in [42]) that if B and C are not unifiable then CETj= ~ 8 (:(B = C)). Now by definition of applying substitutions we have (A 1 6~ A 2 )fl = ~ 8 vars (A 1 fl) (:(A 1 fl = A 0 2 )).
Reference: [10] <author> D. De Schreye and S. Decorte. </author> <title> Termination of logic programs: The never ending story. </title> <journal> The Journal of Logic Programming, </journal> <volume> 19 & 20 </volume> <pages> 199-260, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Termination can be ensured by imposing a depth bound, but much more refined approaches to ensure local termination exist. The methods in [6, 50, 49, 46] are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. <ref> [13, 10] </ref>). Instead of well-founded ones, well-quasi orders can be used [4, 58]. Homeomorphic embedding [63, 40] on selected atoms has recently gained popularity as the basis for such an order.
Reference: [11] <author> D. A. de Waal and J. Gallagher. </author> <title> Specialisation of a unification algorithm. </title> <editor> In T. Clement and K.-K. Lau, editors, </editor> <title> Logic Program Synthesis and Transformation. </title> <booktitle> Proceedings of LOPSTR'91, </booktitle> <pages> pages 205-220, </pages> <address> Manchester, UK, </address> <year> 1991. </year>
Reference-contexts: So neither of the two approaches subsumes the other, they are complementary. Another related work is <ref> [11] </ref>, which uses abstract substitutions to prune resultants while unfolding. These abstract substitutions play a role very similar to the constraints in the current paper. However, no formal correctness or termination result is given in [11] (and the issue of preserving characteristic trees is not addressed). <p> Another related work is <ref> [11] </ref>, which uses abstract substitutions to prune resultants while unfolding. These abstract substitutions play a role very similar to the constraints in the current paper. However, no formal correctness or termination result is given in [11] (and the issue of preserving characteristic trees is not addressed). Indeed, as abstract substitutions of [11] are not necessarily downwards-closed, this seems to be a much harder task and a normal coveredness condition will not suffice to ensure correctness (for instance the atoms in the bodies of clauses might be <p> These abstract substitutions play a role very similar to the constraints in the current paper. However, no formal correctness or termination result is given in <ref> [11] </ref> (and the issue of preserving characteristic trees is not addressed). Indeed, as abstract substitutions of [11] are not necessarily downwards-closed, this seems to be a much harder task and a normal coveredness condition will not suffice to ensure correctness (for instance the atoms in the bodies of clauses might be further instantiated at run-time and thus, in the absence of downwards-closedness, no longer covered). <p> Our paper actually provides a framework within which correctness of <ref> [11] </ref> could be established for abstract substitutions which are downwards- closed. Another, more technical difference is that neither the method of [12, 21] nor the method of [11] preserve the finite failure semantics (i.e. infinite failure might be replaced by finite failure), while our approach, just like ordinary partial deduction, does. <p> Our paper actually provides a framework within which correctness of <ref> [11] </ref> could be established for abstract substitutions which are downwards- closed. Another, more technical difference is that neither the method of [12, 21] nor the method of [11] preserve the finite failure semantics (i.e. infinite failure might be replaced by finite failure), while our approach, just like ordinary partial deduction, does. Another method that might look like a viable alternative to our approach is the one of [5], situated within the context of unfold/fold transformations.
Reference: [12] <author> D. A. de Waal and J. Gallagher. </author> <title> The applicability of logic program analysis and trans-formation to theorem proving. </title> <editor> In A. Bundy, editor, </editor> <booktitle> Automated Deduction|CADE-12, </booktitle> <pages> pages 207-221. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: The details of this approach have been elaborated in [40, 35] (applied to [34], but the approach can be applied in exactly the same manner to the method of this paper). At first sight, the post-processing abstract interpretation phase of <ref> [12, 21] </ref>, detecting useless clauses, might seem like a viable alternative to using pruning constraints and the framework of constrained partial deduction. <p> However, such an approach can not bring back the precomputation that has been lost by an imprecise abstraction operator | it might only be able to bring back part of the pruning. But, when running the method of <ref> [12, 21] </ref> e.g. on the residual program P 0 of Example 3.11, no useless clauses are detected. <p> Our paper actually provides a framework within which correctness of [11] could be established for abstract substitutions which are downwards- closed. Another, more technical difference is that neither the method of <ref> [12, 21] </ref> nor the method of [11] preserve the finite failure semantics (i.e. infinite failure might be replaced by finite failure), while our approach, just like ordinary partial deduction, does.
Reference: [13] <author> N. Dershowitz and Z. Manna. </author> <title> Proving termination with multiset orderings. </title> <journal> Communications of the ACM, </journal> <volume> 22(8) </volume> <pages> 465-476, </pages> <year> 1979. </year>
Reference-contexts: Termination can be ensured by imposing a depth bound, but much more refined approaches to ensure local termination exist. The methods in [6, 50, 49, 46] are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. <ref> [13, 10] </ref>). Instead of well-founded ones, well-quasi orders can be used [4, 58]. Homeomorphic embedding [63, 40] on selected atoms has recently gained popularity as the basis for such an order.
Reference: [14] <author> K. </author> <title> Doets. </title> <journal> Levationis laus. Journal of Logic and Computation, </journal> <volume> 3(5) </volume> <pages> 487-516, </pages> <year> 1993. </year>
Reference-contexts: Hence, as fl satisfies every n 2 prune P (B; t ), we can deduce that fl sat FT prune P (B; t ). 2. By the (correct version of the) lifting lemma <ref> [27, 43, 14, 1] </ref> we can deduce that t chpaths (P; B). Let us examine every p 2 t .
Reference: [15] <author> W. Drabent. </author> <title> What is failure ? An apporach to constructive negation. </title> <journal> Acta Informatica, </journal> <volume> 32 </volume> <pages> 27-59, </pages> <year> 1995. </year>
Reference-contexts: So it is basically the same structure as the one used for CLP (F T ), as defined e.g. in [62]. 12 The same theory has also been used, for different purposes, in the constructive negation techniques (e.g. <ref> [7, 8, 15, 59, 66, 65] </ref>).
Reference: [16] <author> S. Etalle and M. Gabbrielli. </author> <title> A transformation system for modular CLP programs. </title> <editor> In L. Sterling, editor, </editor> <booktitle> Proceedings of the 12th International Conference on Logic Programming, </booktitle> <pages> pages 681-695. </pages> <publisher> The MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: To ensure this property we use the following definition of a derivation, adapted from <ref> [16] </ref>, in which substitutions are made explicit. This will also enable us to construct resultants in a straightforward manner. <p> However, establishing the correctness will become much more difficult because one cannot reuse the correctness results of standard partial deduction. In that context, we would like to mention [66], which extends constructive negation for CLP-programs, as well as recent work on the transformation of CLP-programs <ref> [16] </ref>. Note, however, that [16] is situated within the unfold/fold transformation paradigm and also that no concrete algorithms are presented. Finally, let us mention a recent extension of partial deduction, called conjunctive partial deduction [39, 22]. Conjunctive partial deduction handles conjunctions of atoms instead of just atoms. <p> However, establishing the correctness will become much more difficult because one cannot reuse the correctness results of standard partial deduction. In that context, we would like to mention [66], which extends constructive negation for CLP-programs, as well as recent work on the transformation of CLP-programs <ref> [16] </ref>. Note, however, that [16] is situated within the unfold/fold transformation paradigm and also that no concrete algorithms are presented. Finally, let us mention a recent extension of partial deduction, called conjunctive partial deduction [39, 22]. Conjunctive partial deduction handles conjunctions of atoms instead of just atoms.
Reference: [17] <author> J. Gallagher. </author> <title> A system for specialising logic programs. </title> <type> Technical Report TR-91-32, </type> <institution> University of Bristol, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: In addition to the conditions stated above, this abstraction operator should preserve as much of the specialisation that was (in principle) possible for the atoms in A. An approach which tries to achieve all these goals in an elegant and refined way is that of Gallagher and Bruynooghe <ref> [20, 17] </ref>. Its abstraction operator is based on the notions of characteristic path, characteristic tree and most specific generalisation. <p> Furthermore, if the characteristic trees are preserved by the generalisation then a lot of the specialisation that was possible within A will still be possible within A 0 . Unfortunately, although the approach is conceptually appealing, several errors turn up in the arguments provided in [20] and <ref> [17] </ref>. In the current paper we show that these errors can lead to relevant precision losses and even to non-termination of the partial deduction process. We will also show that these problems cannot be solved within the standard partial deduction approach based on [43]. <p> We therefore extend the standard partial deduction framework by integrating ideas from constraint logic programming (CLP) so as to be able to place constraints on the atoms in A. Within this new generic framework of constrained partial deduction we will be able to (significantly) adapt the approaches of <ref> [20, 17] </ref> to overcome the above mentioned problems. This is achieved by introducing an alternative abstraction operator, which is based on so called pruning constraints expressed using Clark's equality theory (CET). <p> This is achieved by introducing an alternative abstraction operator, which is based on so called pruning constraints expressed using Clark's equality theory (CET). For definite programs and purely determinate unfolding rules 1 , this adapted approach allows to solve all problems with the original formulations in [20] and <ref> [17] </ref>, thus ensuring the claimed termination and precision properties. The paper is structured as follows. In Section 2 we introduce partial deduction from a theoretical viewpoint, expose some of the practical difficulties, introduce the concepts of local and global precision and define the "control of polyvariance" problem. <p> We also make a first attempt at defining a proper abstraction operator and show its (substantial) difficulties. We also illustrate the problem with the approaches in [20] and <ref> [17] </ref>. In Section 4 we introduce the framework for constrained partial deduction along with a fundamental correctness result. In Section 5 we present a particular instance of the framework, based on Clark's equality theory, along with an algorithm and an associated abstraction operator. <p> Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. <ref> [17, 18, 20, 38, 33, 34] </ref>) and adapted correctness results can be found in [2]. See also the more powerful filtering techniques in [41]. The local control component is encapsulated in the unfolding rule, defined above. <p> In addition to local correctness, termination and precision, the requirements on unfolding rules also include avoiding search space explosion as well as work duplication. One particular class of unfolding rules, addressing the two latter points, are based on determinacy <ref> [20, 18, 17] </ref>. Basically these rules stop unfolding as soon as a choice-point is encountered. <p> The above definition of abstract guarantees that any partial deduction wrt A 0 is also correct wrt any atom in A. Note that sometimes an abstraction operator is also referred to as a generalisation operator. The following generic scheme, based on a similar one in <ref> [17, 18] </ref>, describes the basic layout of practically all algorithms for controlling partial deduction. <p> So an abstraction operator should focus on the "essential" structure of an SLDNF-tree and for instance disregard the particular substitutions and goals within the tree. The following two definitions, adapted from <ref> [17] </ref>, do just that: they characterise the essential structure of SLDNF-derivations and trees. Definition 3.2 (characteristic path) Let G 0 be a goal and let P be a normal program whose clauses are numbered. <p> However, this is of no relevance, because the failing branches do not materialise within the resultants (i.e. the specialised code generated for the atoms). In summary, characteristic trees seem to be an almost ideal vehicle for a refined control of polyvariance <ref> [20, 17] </ref>, a fact we will try to exploit in the following section. 3.2 An Abstraction Operator using Characteristic Trees The following definition captures a first attempt at using characteristic trees for the control of polyvariance. 12 Definition 3.6 (chabs P;U ) Let P be a normal program, U an unfolding <p> Indeed, chabs P;U (fA; Bg) = feqlist (X; Y )g whose characteristic tree is fh1 ffi 1i; h1 ffi 2ig and the precomputation and pruning performed on A and B has been lost. The previous example is taken from <ref> [17] </ref>, whose abstraction mechanism can solve the example. The following example can, however, not be solved by [17]. <p> The previous example is taken from <ref> [17] </ref>, whose abstraction mechanism can solve the example. The following example can, however, not be solved by [17]. <p> This quest is pursued in the remainder of this paper. 3.3 Characteristic Trees in the Literature Characteristic trees have been introduced in the context of definite programs and determinate unfolding rules by Gallagher and Bruynooghe in [20] and were later refined by Gallagher in <ref> [17] </ref> leading to the definitions that we have presented in this paper. Both [20] and [17] use a refined version of the abstraction operator chabs P;U and [17] uses a partial deduction algorithm very similar to Algorithm 2.9. In both [20] and [17] termination properties are claimed. <p> paper. 3.3 Characteristic Trees in the Literature Characteristic trees have been introduced in the context of definite programs and determinate unfolding rules by Gallagher and Bruynooghe in [20] and were later refined by Gallagher in <ref> [17] </ref> leading to the definitions that we have presented in this paper. Both [20] and [17] use a refined version of the abstraction operator chabs P;U and [17] uses a partial deduction algorithm very similar to Algorithm 2.9. In both [20] and [17] termination properties are claimed. No claim as to the preservation of characteristic trees is made in [17]. <p> in the context of definite programs and determinate unfolding rules by Gallagher and Bruynooghe in [20] and were later refined by Gallagher in <ref> [17] </ref> leading to the definitions that we have presented in this paper. Both [20] and [17] use a refined version of the abstraction operator chabs P;U and [17] uses a partial deduction algorithm very similar to Algorithm 2.9. In both [20] and [17] termination properties are claimed. No claim as to the preservation of characteristic trees is made in [17]. <p> [20] and were later refined by Gallagher in <ref> [17] </ref> leading to the definitions that we have presented in this paper. Both [20] and [17] use a refined version of the abstraction operator chabs P;U and [17] uses a partial deduction algorithm very similar to Algorithm 2.9. In both [20] and [17] termination properties are claimed. No claim as to the preservation of characteristic trees is made in [17]. However, the authors of [20] actually claim in Lemma 4.11 to have found an operator (namely chcall) which, in the case of definite programs and purely determinate unfolding rules without lookahead (cf. <p> Both [20] and <ref> [17] </ref> use a refined version of the abstraction operator chabs P;U and [17] uses a partial deduction algorithm very similar to Algorithm 2.9. In both [20] and [17] termination properties are claimed. No claim as to the preservation of characteristic trees is made in [17]. However, the authors of [20] actually claim in Lemma 4.11 to have found an operator (namely chcall) which, in the case of definite programs and purely determinate unfolding rules without lookahead (cf. Definition 2.7), preserves a structure quite similar to characteristic trees as of Definition 3.4. <p> Unfortunately this Lemma 4.11 is false and cannot be easily rectified. In Appendix A we provide a detailed description of a counterexample to this Lemma 4.11. Furthermore, in a lot of cases, the abstraction operators of [20] and <ref> [17] </ref> behave exactly like chabs P;U , and the examples in this paper and in [37] actually provide counterexamples not only for the precision claim of [20] but also for the termination claims of both [20] and [17]. There are in fact some further problems with the abstraction operator of [17]. <p> Furthermore, in a lot of cases, the abstraction operators of [20] and <ref> [17] </ref> behave exactly like chabs P;U , and the examples in this paper and in [37] actually provide counterexamples not only for the precision claim of [20] but also for the termination claims of both [20] and [17]. There are in fact some further problems with the abstraction operator of [17]. For instance the Example 3.9 with negation poses problems to [17] ([20] is restricted to definite programs, so the problem does not appear there) and unfolding rules which are not purely determinate can also cause problems. <p> <ref> [17] </ref> behave exactly like chabs P;U , and the examples in this paper and in [37] actually provide counterexamples not only for the precision claim of [20] but also for the termination claims of both [20] and [17]. There are in fact some further problems with the abstraction operator of [17]. For instance the Example 3.9 with negation poses problems to [17] ([20] is restricted to definite programs, so the problem does not appear there) and unfolding rules which are not purely determinate can also cause problems. <p> this paper and in [37] actually provide counterexamples not only for the precision claim of [20] but also for the termination claims of both [20] and <ref> [17] </ref>. There are in fact some further problems with the abstraction operator of [17]. For instance the Example 3.9 with negation poses problems to [17] ([20] is restricted to definite programs, so the problem does not appear there) and unfolding rules which are not purely determinate can also cause problems. More detailed descriptions can be found in [37] as well as in [36], where the counterexample to Lemma 4.11 of [20] was first presented. <p> The characteristic trees of both these atoms will be t = fh1 ffi 3ig. Applying the abstraction operator chabs P;U without constraints of Definition 3.6 (as well as the abstraction operators of <ref> [20, 17] </ref>) will give us as generalisation chabs P;U (S) = fsolve (X)g where solve (X) has the characteristic tree t 0 = fh1 ffi 1i; h1 ffi 2i; h1 ffi 3ig and local precision and specialisation has been lost due to the abstraction. <p> However, this comes at the cost of a larger program (because of unnecessary polyvariance due to the static guidance). Furthermore the program P can be slightly adapted such that 3; 4; 5; ::: renamed versions are required to remove the type checking. Also, the abstraction operators in <ref> [20, 17] </ref> or the abstraction operator chabs P;U without constraints of Definition 3.6 cannot adequately handle the above example and are not able to remove the type checking.
Reference: [18] <author> J. Gallagher. </author> <title> Tutorial on specialisation of logic programs. </title> <booktitle> In Proceedings of PEPM'93, the ACM Sigplan Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 88-98. </pages> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction Partial evaluation has received considerable attention in logic programming <ref> [18, 29, 53] </ref> and functional programming (see e.g. [25] and references therein). In [28] Komorowski introduced the topic in the logic programming setting and later, for pure logic programs, first refers to it as partial deduction. Another milestone is [43], where firm theoretical foundations for partial deduction are established. <p> These are all considerations generally delegated to the control of partial deduction, which we discuss next. 2.2 Control of Partial Deduction In partial deduction one usually distinguishes two levels of control <ref> [18, 51] </ref>: * the global control , in which one chooses the set A, i.e. one decides which atoms will be partially deduced, and * the local control , in which one constructs the finite (possibly incomplete) SLDNF-trees for each individual atom in A and thus determines what the definitions for <p> Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. <ref> [17, 18, 20, 38, 33, 34] </ref>) and adapted correctness results can be found in [2]. See also the more powerful filtering techniques in [41]. The local control component is encapsulated in the unfolding rule, defined above. <p> In addition to local correctness, termination and precision, the requirements on unfolding rules also include avoiding search space explosion as well as work duplication. One particular class of unfolding rules, addressing the two latter points, are based on determinacy <ref> [20, 18, 17] </ref>. Basically these rules stop unfolding as soon as a choice-point is encountered. <p> The above definition of abstract guarantees that any partial deduction wrt A 0 is also correct wrt any atom in A. Note that sometimes an abstraction operator is also referred to as a generalisation operator. The following generic scheme, based on a similar one in <ref> [17, 18] </ref>, describes the basic layout of practically all algorithms for controlling partial deduction.
Reference: [19] <author> J. Gallagher and M. Bruynooghe. </author> <title> Some low-level transformations for logic programs. </title> <editor> In M. Bruynooghe, editor, </editor> <booktitle> Proceedings of Meta90 Workshop on Meta Programming in Logic, </booktitle> <pages> pages 229-244, </pages> <address> Leuven, Belgium, </address> <year> 1990. </year>
Reference-contexts: Trivially the query new (X 1 ; : : : ; X k ) and G are equivalent wrt c.a.s. and finite failure (see also Lemma 2.2 in <ref> [19] </ref>). * Theorem 4.11 of [2] requires that G contains no variables or predicates in A. The requirement about the variables is not necessary in our case because we do not base our renaming on the mgu.
Reference: [20] <author> J. Gallagher and M. Bruynooghe. </author> <title> The derivation of an algorithm for program specialisation. </title> <journal> New Generation Computing, </journal> <volume> 9(3 & 4):305-333, 1991. 42 </volume>
Reference-contexts: In addition to the conditions stated above, this abstraction operator should preserve as much of the specialisation that was (in principle) possible for the atoms in A. An approach which tries to achieve all these goals in an elegant and refined way is that of Gallagher and Bruynooghe <ref> [20, 17] </ref>. Its abstraction operator is based on the notions of characteristic path, characteristic tree and most specific generalisation. <p> Furthermore, if the characteristic trees are preserved by the generalisation then a lot of the specialisation that was possible within A will still be possible within A 0 . Unfortunately, although the approach is conceptually appealing, several errors turn up in the arguments provided in <ref> [20] </ref> and [17]. In the current paper we show that these errors can lead to relevant precision losses and even to non-termination of the partial deduction process. We will also show that these problems cannot be solved within the standard partial deduction approach based on [43]. <p> We therefore extend the standard partial deduction framework by integrating ideas from constraint logic programming (CLP) so as to be able to place constraints on the atoms in A. Within this new generic framework of constrained partial deduction we will be able to (significantly) adapt the approaches of <ref> [20, 17] </ref> to overcome the above mentioned problems. This is achieved by introducing an alternative abstraction operator, which is based on so called pruning constraints expressed using Clark's equality theory (CET). <p> This is achieved by introducing an alternative abstraction operator, which is based on so called pruning constraints expressed using Clark's equality theory (CET). For definite programs and purely determinate unfolding rules 1 , this adapted approach allows to solve all problems with the original formulations in <ref> [20] </ref> and [17], thus ensuring the claimed termination and precision properties. The paper is structured as follows. In Section 2 we introduce partial deduction from a theoretical viewpoint, expose some of the practical difficulties, introduce the concepts of local and global precision and define the "control of polyvariance" problem. <p> We also make a first attempt at defining a proper abstraction operator and show its (substantial) difficulties. We also illustrate the problem with the approaches in <ref> [20] </ref> and [17]. In Section 4 we introduce the framework for constrained partial deduction along with a fundamental correctness result. In Section 5 we present a particular instance of the framework, based on Clark's equality theory, along with an algorithm and an associated abstraction operator. <p> We show that, for definite programs and certain unfolding rules, this approach ensures termination while providing a very precise and fine grained control of polyvariance. In Section 6 we present some results of an implementation 1 This same limitation is also present in <ref> [20] </ref>. We will, however, show how this limitation can be lifted in a rather straightforward manner. 2 of this approach. In the discussion in Section 7 we point out several ways to extend the method to normal programs and more powerful unfolding rules. <p> For instance, instead of renaming A into the set A 0 above, A would be renamed into fmem a (L); mem b (X )g and the goal G would be renamed into mem a ([a; c]); mem b (b). For further details about filtering see e.g. <ref> [20] </ref> or [2] where the filtering phase is performed as a one-step post-processing renaming. See also [54], where filtering is obtained automatically when using folding to simulate partial evaluation. Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. <p> Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. <ref> [17, 18, 20, 38, 33, 34] </ref>) and adapted correctness results can be found in [2]. See also the more powerful filtering techniques in [41]. The local control component is encapsulated in the unfolding rule, defined above. <p> In addition to local correctness, termination and precision, the requirements on unfolding rules also include avoiding search space explosion as well as work duplication. One particular class of unfolding rules, addressing the two latter points, are based on determinacy <ref> [20, 18, 17] </ref>. Basically these rules stop unfolding as soon as a choice-point is encountered. <p> However, this is of no relevance, because the failing branches do not materialise within the resultants (i.e. the specialised code generated for the atoms). In summary, characteristic trees seem to be an almost ideal vehicle for a refined control of polyvariance <ref> [20, 17] </ref>, a fact we will try to exploit in the following section. 3.2 An Abstraction Operator using Characteristic Trees The following definition captures a first attempt at using characteristic trees for the control of polyvariance. 12 Definition 3.6 (chabs P;U ) Let P be a normal program, U an unfolding <p> This quest is pursued in the remainder of this paper. 3.3 Characteristic Trees in the Literature Characteristic trees have been introduced in the context of definite programs and determinate unfolding rules by Gallagher and Bruynooghe in <ref> [20] </ref> and were later refined by Gallagher in [17] leading to the definitions that we have presented in this paper. Both [20] and [17] use a refined version of the abstraction operator chabs P;U and [17] uses a partial deduction algorithm very similar to Algorithm 2.9. In both [20] and [17] <p> of this paper. 3.3 Characteristic Trees in the Literature Characteristic trees have been introduced in the context of definite programs and determinate unfolding rules by Gallagher and Bruynooghe in <ref> [20] </ref> and were later refined by Gallagher in [17] leading to the definitions that we have presented in this paper. Both [20] and [17] use a refined version of the abstraction operator chabs P;U and [17] uses a partial deduction algorithm very similar to Algorithm 2.9. In both [20] and [17] termination properties are claimed. No claim as to the preservation of characteristic trees is made in [17]. <p> Bruynooghe in <ref> [20] </ref> and were later refined by Gallagher in [17] leading to the definitions that we have presented in this paper. Both [20] and [17] use a refined version of the abstraction operator chabs P;U and [17] uses a partial deduction algorithm very similar to Algorithm 2.9. In both [20] and [17] termination properties are claimed. No claim as to the preservation of characteristic trees is made in [17]. However, the authors of [20] actually claim in Lemma 4.11 to have found an operator (namely chcall) which, in the case of definite programs and purely determinate unfolding rules without lookahead <p> In both <ref> [20] </ref> and [17] termination properties are claimed. No claim as to the preservation of characteristic trees is made in [17]. However, the authors of [20] actually claim in Lemma 4.11 to have found an operator (namely chcall) which, in the case of definite programs and purely determinate unfolding rules without lookahead (cf. Definition 2.7), preserves a structure quite similar to characteristic trees as of Definition 3.4. <p> Unfortunately this Lemma 4.11 is false and cannot be easily rectified. In Appendix A we provide a detailed description of a counterexample to this Lemma 4.11. Furthermore, in a lot of cases, the abstraction operators of <ref> [20] </ref> and [17] behave exactly like chabs P;U , and the examples in this paper and in [37] actually provide counterexamples not only for the precision claim of [20] but also for the termination claims of both [20] and [17]. <p> Furthermore, in a lot of cases, the abstraction operators of <ref> [20] </ref> and [17] behave exactly like chabs P;U , and the examples in this paper and in [37] actually provide counterexamples not only for the precision claim of [20] but also for the termination claims of both [20] and [17]. There are in fact some further problems with the abstraction operator of [17]. For instance the Example 3.9 with negation poses problems to [17] ([20] is restricted to definite programs, so the problem does not appear there) and unfolding <p> Furthermore, in a lot of cases, the abstraction operators of <ref> [20] </ref> and [17] behave exactly like chabs P;U , and the examples in this paper and in [37] actually provide counterexamples not only for the precision claim of [20] but also for the termination claims of both [20] and [17]. There are in fact some further problems with the abstraction operator of [17]. For instance the Example 3.9 with negation poses problems to [17] ([20] is restricted to definite programs, so the problem does not appear there) and unfolding rules which are not purely determinate can also cause <p> negation poses problems to [17] (<ref> [20] </ref> is restricted to definite programs, so the problem does not appear there) and unfolding rules which are not purely determinate can also cause problems. More detailed descriptions can be found in [37] as well as in [36], where the counterexample to Lemma 4.11 of [20] was first presented. <p> The characteristic trees of both these atoms will be t = fh1 ffi 3ig. Applying the abstraction operator chabs P;U without constraints of Definition 3.6 (as well as the abstraction operators of <ref> [20, 17] </ref>) will give us as generalisation chabs P;U (S) = fsolve (X)g where solve (X) has the characteristic tree t 0 = fh1 ffi 1i; h1 ffi 2i; h1 ffi 3ig and local precision and specialisation has been lost due to the abstraction. <p> However, this comes at the cost of a larger program (because of unnecessary polyvariance due to the static guidance). Furthermore the program P can be slightly adapted such that 3; 4; 5; ::: renamed versions are required to remove the type checking. Also, the abstraction operators in <ref> [20, 17] </ref> or the abstraction operator chabs P;U without constraints of Definition 3.6 cannot adequately handle the above example and are not able to remove the type checking. <p> onemsg: This is an abstraction operator (already described in Section 2) which allows just one version per predicate and uses the msg to ensure this. 2. chabs: This is the abstraction operator defined in Definition 3.6 and which for the examples at hand basically behaves like the abstraction described in <ref> [20] </ref>. 3. chabsc: the characteristic tree preserving abstraction operator of Definition 5.12 used inside the constrained partial deduction algorithm described in this paper. Note that only onemsg and chabsc guarantee termination.
Reference: [21] <author> J. Gallagher and D. A. de Waal. </author> <title> Deletion of redundant unary type predicates from logic programs. </title> <editor> In K.-K. Lau and T. Clement, editors, </editor> <title> Logic Program Synthesis and Transformation. </title> <booktitle> Proceedings of LOPSTR'92, </booktitle> <pages> pages 151-167, </pages> <address> Manchester, UK, </address> <year> 1992. </year>
Reference-contexts: The details of this approach have been elaborated in [40, 35] (applied to [34], but the approach can be applied in exactly the same manner to the method of this paper). At first sight, the post-processing abstract interpretation phase of <ref> [12, 21] </ref>, detecting useless clauses, might seem like a viable alternative to using pruning constraints and the framework of constrained partial deduction. <p> However, such an approach can not bring back the precomputation that has been lost by an imprecise abstraction operator | it might only be able to bring back part of the pruning. But, when running the method of <ref> [12, 21] </ref> e.g. on the residual program P 0 of Example 3.11, no useless clauses are detected. <p> Our paper actually provides a framework within which correctness of [11] could be established for abstract substitutions which are downwards- closed. Another, more technical difference is that neither the method of <ref> [12, 21] </ref> nor the method of [11] preserve the finite failure semantics (i.e. infinite failure might be replaced by finite failure), while our approach, just like ordinary partial deduction, does.
Reference: [22] <author> R. Gluck, J. Jtrgensen, B. Martens, and M. H. Strensen. </author> <title> Controlling conjunctive partial deduction of definite logic programs. </title> <editor> In H. Kuchen and S. Swierstra, editors, </editor> <booktitle> Proceedings of the International Symposium on Programming Languages, Implementations, Logics and Programs (PLILP'96), </booktitle> <volume> LNCS 1140, </volume> <pages> pages 152-166, </pages> <address> Aachen, Germany, </address> <month> September </month> <year> 1996. </year> <note> Springer-Verlag. Extended version as Technical Report CW 226, K.U. Leuven. Available at http://www.cs.kuleuven.ac.be/~lpai. </note>
Reference-contexts: Note, however, that [16] is situated within the unfold/fold transformation paradigm and also that no concrete algorithms are presented. Finally, let us mention a recent extension of partial deduction, called conjunctive partial deduction <ref> [39, 22] </ref>. Conjunctive partial deduction handles conjunctions of atoms instead of just atoms. This means that when the unfolding rule stops, the atoms in the leaves of the SLD (NF)-tree are not automatically separated and treated in isolation.
Reference: [23] <author> P. Hill and J. Gallagher. </author> <title> Meta-programming in logic programming. </title> <type> Technical Report 94.22, </type> <institution> School of Computer Studies, University of Leeds, </institution> <year> 1994. </year> <booktitle> To be published in Handbook of Logic in Artificial Intelligence and Logic Programming, </booktitle> <volume> Vol. 5. </volume> <publisher> Oxford Science Publications, Oxford University Press. </publisher>
Reference-contexts: We can, however, still rename G 2 into G 00 2 = member a ([b; a]). Theorem 4.14 can then applied to deduce that using P 0 [ fG 00 2 g is correct. Example 5.20 Let P be the well known "vanilla" solve meta-interpreter (see e.g. <ref> [23, 47, 48] </ref>). (1) solve (empty) (2) solve (X&Y ) solve (X); solve (Y ) (3) solve (X) clause (X; B); solve (B) (4) clause (p (a)) (5) clause (p (b)) (6) clause (q (a)) (7) clause (q (b)) 34 Let us suppose we use a purely determinate unfolding rule U
Reference: [24] <author> J. Jaffar and M. J. Maher. </author> <title> Constraint logic programming: A survey. </title> <journal> The Journal of Logic Programming, </journal> <volume> 19 & 20 </volume> <pages> 503-581, </pages> <year> 1994. </year>
Reference-contexts: Also, from now on we will restrict ourselves to definite programs and goals. We will return to the problem of negative literals in Section 7. 4.1 Constraint Logic Programming To formalise constraints and their effect, we need some basic terminology from constraint logic programming (CLP) <ref> [24] </ref>. 16 First, the predicate symbols are partitioned into two disjoint sets c (the predicate sym-bols to be used for constraints, notably including "=") and b (the predicate symbols for user-defined predicates). The signature contains all predicate and function symbols with their associated arity.
Reference: [25] <author> N. D. Jones, C. K. Gomard, and P. Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction Partial evaluation has received considerable attention in logic programming [18, 29, 53] and functional programming (see e.g. <ref> [25] </ref> and references therein). In [28] Komorowski introduced the topic in the logic programming setting and later, for pure logic programs, first refers to it as partial deduction. Another milestone is [43], where firm theoretical foundations for partial deduction are established.
Reference: [26] <author> J. Jtrgensen, M. Leuschel, and B. Martens. </author> <title> Conjunctive partial deduction in practice. </title> <editor> In J. Gallagher, editor, </editor> <booktitle> Proceedings of the International Workshop on Logic Program Synthesis and Transformation (LOPSTR'96), </booktitle> <volume> LNCS 1207, </volume> <pages> pages 59-82, </pages> <address> Stockholm, Sweden, </address> <month> August </month> <year> 1996. </year> <note> Springer-Verlag. Also in the Proceedings of BENELOG'96. Extended ver-sion as Technical Report CW 242, K.U. Leuven. </note>
Reference-contexts: This means that when the unfolding rule stops, the atoms in the leaves of the SLD (NF)-tree are not automatically separated and treated in isolation. As such, the local precision problem disappears almost entirely and approaches based on determinate unfolding become much more viable (recent experiments in <ref> [26] </ref> confirm this, where determinate unfolding outperforms more eager unfolding rules based on well-founded or well-quasi measures).
Reference: [27] <author> H.-P. Ko and M. E. </author> <title> Nadel. Substitution and refutation revisited. </title> <editor> In K. Furukawa, editor, </editor> <booktitle> Logic Programming: Proceedings of the Eighth International Conference, </booktitle> <pages> pages 679-692. </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Hence, as fl satisfies every n 2 prune P (B; t ), we can deduce that fl sat FT prune P (B; t ). 2. By the (correct version of the) lifting lemma <ref> [27, 43, 14, 1] </ref> we can deduce that t chpaths (P; B). Let us examine every p 2 t .
Reference: [28] <author> J. Komorowksi. </author> <title> A Specification of an Abstract Prolog Machine and its Application to Partial Evaluation. </title> <type> PhD thesis, </type> <institution> Linkoping University, Sweden, 1981. Linkoping Studies in Science and Technology Dissertations 69. </institution>
Reference-contexts: 1 Introduction Partial evaluation has received considerable attention in logic programming [18, 29, 53] and functional programming (see e.g. [25] and references therein). In <ref> [28] </ref> Komorowski introduced the topic in the logic programming setting and later, for pure logic programs, first refers to it as partial deduction. Another milestone is [43], where firm theoretical foundations for partial deduction are established.
Reference: [29] <author> J. Komorowski. </author> <title> An introduction to partial deduction. </title> <editor> In A. Pettorossi, editor, </editor> <booktitle> Proceedings Meta'92, </booktitle> <volume> LNCS 649, </volume> <pages> pages 49-69. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Partial evaluation has received considerable attention in logic programming <ref> [18, 29, 53] </ref> and functional programming (see e.g. [25] and references therein). In [28] Komorowski introduced the topic in the logic programming setting and later, for pure logic programs, first refers to it as partial deduction. Another milestone is [43], where firm theoretical foundations for partial deduction are established.
Reference: [30] <author> K. Kunen. </author> <title> Answer sets and negation as failure. </title> <editor> In J.-L. Lassez, editor, </editor> <booktitle> Proceedings of the 4th International Conference on Logic Programming, </booktitle> <pages> pages 219-228. </pages> <publisher> The MIT Press, </publisher> <year> 1987. </year>
Reference-contexts: Note that CET is a complete theory <ref> [30] </ref> and we suppose that we have the required algorithms for satisfiability checking, simplification and projection at our disposal (see e.g. [66, 65, 60]). 5.1 Pruning Constraints As we have already seen in Section 3, when taking the msg of two atoms A and B with the same characteristic tree t
Reference: [31] <author> J. Lam and A. Kusalik. </author> <title> A comparative analysis of partial deductors for pure Prolog. </title> <type> Technical report, </type> <institution> Department of Computational Science, University of Saskatchewan, Canada, </institution> <month> May </month> <year> 1990. </year> <month> Revised April </month> <year> 1991. </year>
Reference-contexts: Note that only onemsg and chabsc guarantee termination. We compared the three approaches for the Lam & Kusalik benchmarks (see <ref> [31] </ref>, they can also be found in [46, 57]) without negation and built-in's: ancestor, depth, transpose. We also experimented with the rev checklist program from Example 5.21, which we specialised for the S = frev (L; []; R)g. Another experiment, member, consisted in a slight adaptation of Example 3.11.
Reference: [32] <author> J.-L. Lassez, M. Maher, and K. Marriott. </author> <title> Unification revisited. </title> <editor> In J. Minker, editor, </editor> <booktitle> Foundations of Deductive Databases and Logic Programming, </booktitle> <pages> pages 587-625. </pages> <address> MorganKaufmann, </address> <year> 1988. </year> <month> 43 </month>
Reference-contexts: Methods solely based on determinacy, avoid search space explosion and limit work duplication 3 , but can be somewhat too conservative. Also, in itself, determinate unfolding 2 Most specific generalisation, also known as anti-unification or least general generalisation, see for instance <ref> [32] </ref>. 3 Under the condition that non-determinate unfolding steps follow the computation rule of the underlying system. 6 does not guarantee termination, as there can be infinitely failing determinate computations. Termination can be ensured by imposing a depth bound, but much more refined approaches to ensure local termination exist.
Reference: [33] <author> M. Leuschel. </author> <title> Partial evaluation of the "real thing". </title> <editor> In L. Fribourg and F. Turini, editors, </editor> <title> Logic Program Synthesis and Transformation | Meta-Programming in Logic. </title> <booktitle> Proceedings of LOPSTR'94 and META'94, </booktitle> <volume> LNCS 883, </volume> <pages> pages 122-137, </pages> <address> Pisa, Italy, June 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. <ref> [17, 18, 20, 38, 33, 34] </ref>) and adapted correctness results can be found in [2]. See also the more powerful filtering techniques in [41]. The local control component is encapsulated in the unfolding rule, defined above.
Reference: [34] <author> M. Leuschel. </author> <title> Ecological partial deduction: Preserving characteristic trees without con-straints. </title> <editor> In M. Proietti, editor, </editor> <title> Logic Program Synthesis and Transformation. </title> <booktitle> Proceedings of LOPSTR'95, </booktitle> <volume> LNCS 1048, </volume> <pages> pages 1-16, </pages> <address> Utrecht, The Netherlands, </address> <month> September </month> <year> 1995. </year> <note> Springer-Verlag. </note>
Reference-contexts: Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. <ref> [17, 18, 20, 38, 33, 34] </ref>) and adapted correctness results can be found in [2]. See also the more powerful filtering techniques in [41]. The local control component is encapsulated in the unfolding rule, defined above. <p> Also see <ref> [34] </ref> which pushes the idea of imposing characteristic trees on the generalisation one step further. We can now adapt Algorithm 2.9 by incorporating constrained atoms into the partial deduction process and by using the abstraction operator of Definition 5.12. <p> A second possibility would be to extend the expressivity of the constraints. A promising approach in that direction is to extend the approach of computing fail substitutions [45]. There is, however, still a third possibility discussed in <ref> [34] </ref>. This method follows the same basic principle laid down in this paper, namely to use and preserve characteristic trees in order to obtain a fine-grained control of polyvariance, but achieves this without explicitly incorporating constraints into the partial deduction process. The central idea of [34] is actually rather simple (and <p> a third possibility discussed in <ref> [34] </ref>. This method follows the same basic principle laid down in this paper, namely to use and preserve characteristic trees in order to obtain a fine-grained control of polyvariance, but achieves this without explicitly incorporating constraints into the partial deduction process. The central idea of [34] is actually rather simple (and is a further development of the idea which we used in the previous section to transform any unfolding rule into a stable one): the method just imposes a characteristic tree on the generalisation. This characteristic tree acts as a sort of implicit local constraint. <p> As such the method does not have to impose any restriction on the unfolding rule, can handle negation (and some built-in's as well) while still ensuring termination. However, the simplicity comes at the price of some loss of precision because the implicit 38 constraints in <ref> [34] </ref> are only used locally (the method here, based on negative constraints, uses the constraints explicitly and propagates them globally via constrained atoms to be partially deduced). Also, the full instance relation now becomes undecidable, and a computable approximation has to be used. <p> Also, the full instance relation now becomes undecidable, and a computable approximation has to be used. Algorithm 5.16 based on chabsc P;U (as well as <ref> [34] </ref>) still requires an ad-hoc depth bound on characteristic trees to ensure termination. As a partial remedy we can easily extend the algorithm so that the precision of the characteristic trees is limited to a certain depth but the unfolding rule has no a priori depth bound. <p> The basic idea is to use a refined well-quasi order on characteristic trees which spots potential sequences of ever growing characteristic trees. The details of this approach have been elaborated in [40, 35] (applied to <ref> [34] </ref>, but the approach can be applied in exactly the same manner to the method of this paper). At first sight, the post-processing abstract interpretation phase of [12, 21], detecting useless clauses, might seem like a viable alternative to using pruning constraints and the framework of constrained partial deduction.
Reference: [35] <author> M. Leuschel. </author> <title> Advanced Techniques for Logic Program Specialisation. </title> <type> PhD thesis, K.U. </type> <institution> Leuven, </institution> <month> May </month> <year> 1997. </year> <note> Available at http://www.cs.kuleuven.ac.be/~michael. </note>
Reference-contexts: However, even with that improvement, the precision of characteristic trees is still limited and the depth bound can result in unsatisfactory, ad-hoc specialisation (see <ref> [40, 35] </ref>). For- tunately, by combining our approach with [51], it is possible to get rid of this ad-hoc depth bound. The basic idea is to use a refined well-quasi order on characteristic trees which spots potential sequences of ever growing characteristic trees. <p> The basic idea is to use a refined well-quasi order on characteristic trees which spots potential sequences of ever growing characteristic trees. The details of this approach have been elaborated in <ref> [40, 35] </ref> (applied to [34], but the approach can be applied in exactly the same manner to the method of this paper).
Reference: [36] <author> M. Leuschel and D. De Schreye. </author> <title> An almost perfect abstraction operator for partial deduction. </title> <type> Technical Report CW 199, </type> <institution> Departement Computerwetenschappen, K.U. Leuven, Belgium, </institution> <month> December </month> <year> 1994. </year>
Reference-contexts: For instance the Example 3.9 with negation poses problems to [17] ([20] is restricted to definite programs, so the problem does not appear there) and unfolding rules which are not purely determinate can also cause problems. More detailed descriptions can be found in [37] as well as in <ref> [36] </ref>, where the counterexample to Lemma 4.11 of [20] was first presented. <p> First note that Algorithm 5.16 solves all the problematic examples in <ref> [36] </ref> as well as the problematic non-termination example in [37].
Reference: [37] <author> M. Leuschel and D. De Schreye. </author> <title> An almost perfect abstraction operation for partial deduction using characteristic trees. </title> <type> Technical Report CW 215, </type> <institution> Departement Computerwetenschappen, K.U. Leuven, Belgium, </institution> <month> October </month> <year> 1995. </year>
Reference-contexts: However, if characteristic trees are not preserved by the abstraction operator, then the proof of Appendix B no longer holds and indeed termination is no longer guaranteed (even assuming a finite number of characteristic trees)! An example illustrating this, can be found in <ref> [37] </ref>. The example exploits the non-monotonic nature of Algorithm 2.9. <p> In Appendix A we provide a detailed description of a counterexample to this Lemma 4.11. Furthermore, in a lot of cases, the abstraction operators of [20] and [17] behave exactly like chabs P;U , and the examples in this paper and in <ref> [37] </ref> actually provide counterexamples not only for the precision claim of [20] but also for the termination claims of both [20] and [17]. There are in fact some further problems with the abstraction operator of [17]. <p> For instance the Example 3.9 with negation poses problems to [17] ([20] is restricted to definite programs, so the problem does not appear there) and unfolding rules which are not purely determinate can also cause problems. More detailed descriptions can be found in <ref> [37] </ref> as well as in [36], where the counterexample to Lemma 4.11 of [20] was first presented. <p> See <ref> [37] </ref> for further details. 26 In fact, purely determinate unfolding rules have the property that, if there is a failing branch, then the goal fails completely and the goal has an empty characteristic tree. So either there are no failed branches or the characteristic tree is empty. <p> In fact, given a (albeit unnatural) unstable unfolding rule, we can basically reconstruct the pattern of an example in <ref> [37] </ref> to obtain an oscillating behaviour of the partial deduction Algorithm 5.16. Proposition 5.18 If the set of different characteristic trees is finite and the unfolding rule U is stable, then Algorithm 5.16 terminates. <p> First note that Algorithm 5.16 solves all the problematic examples in [36] as well as the problematic non-termination example in <ref> [37] </ref>.
Reference: [38] <author> M. Leuschel and D. De Schreye. </author> <title> Towards creating specialised integrity checks through partial evaluation of meta-interpreters. </title> <booktitle> In Proceedings of PEPM'95, the ACM Sigplan Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 253-263, </pages> <address> La Jolla, California, June 1995. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. <ref> [17, 18, 20, 38, 33, 34] </ref>) and adapted correctness results can be found in [2]. See also the more powerful filtering techniques in [41]. The local control component is encapsulated in the unfolding rule, defined above.
Reference: [39] <author> M. Leuschel, D. De Schreye, and A. de Waal. </author> <title> A conceptual embedding of folding into par-tial deduction: Towards a maximal integration. </title> <editor> In M. Maher, editor, </editor> <booktitle> Proceedings of the Joint International Conference and Symposium on Logic Programming JICSLP'96, </booktitle> <pages> pages 319-332, </pages> <address> Bonn, Germany, </address> <month> September </month> <year> 1996. </year> <note> MIT Press. Extended version as Technical Report CW 225, K.U. Leuven. Available at http://www.cs.kuleuven.ac.be/~lpai. </note>
Reference-contexts: Note, however, that [16] is situated within the unfold/fold transformation paradigm and also that no concrete algorithms are presented. Finally, let us mention a recent extension of partial deduction, called conjunctive partial deduction <ref> [39, 22] </ref>. Conjunctive partial deduction handles conjunctions of atoms instead of just atoms. This means that when the unfolding rule stops, the atoms in the leaves of the SLD (NF)-tree are not automatically separated and treated in isolation.
Reference: [40] <author> M. Leuschel and B. Martens. </author> <title> Global control for partial deduction through characteristic atoms and global trees. </title> <editor> In O. Danvy, R. Gluck, and P. Thiemann, editors, </editor> <booktitle> Proceedings of the 1996 Dagstuhl Seminar on Partial Evaluation, </booktitle> <volume> LNCS 1110, </volume> <pages> pages 263-283, </pages> <publisher> Schlo Dagstuhl, </publisher> <year> 1996. </year> <note> Springer-Verlag. Extended version as Technical Report CW 220, K.U. Leuven. Available at http://www.cs.kuleuven.ac.be/~lpai. </note>
Reference-contexts: The methods in [6, 50, 49, 46] are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. [13, 10]). Instead of well-founded ones, well-quasi orders can be used [4, 58]. Homeomorphic embedding <ref> [63, 40] </ref> on selected atoms has recently gained popularity as the basis for such an order. <p> One might hope that chabs P;U ensures termination of partial deduction Algorithm 2.9 if the number of characteristic trees is finite (which can be ensured by using a depth-bound for characteristic trees 6 or by the more sophisticated technique of <ref> [40] </ref> | we will return to this issue in Section 7). Actually if the characteristic trees are preserved, then the abstraction operator chabs P;U does ensure termination of Algorithm 2.9. <p> The method presented in the remainder of this section can in fact be easily adapted in that direction, thus lifting the restriction on unfolding rules. A post-processing phase could be devised, e.g. based on techniques in <ref> [56, 40] </ref>, to then remove the unnecessary (cf. Section 3) polyvariance generated by such an approach. <p> It is, however, also possible not to impose any ad-hoc depth-bound on the unfolding rule and to impose the depth-bound only on characteristic paths and trees. A third alternative is presented in <ref> [40] </ref>, which gets rid of the depth bound altogether (see also the discussion in Section 7). 33 5.3 Some Examples In this section we illustrate the workings and the interest of the abstraction operator chabsc P;U along with Algorithm 5.16 on some practical examples. <p> However, even with that improvement, the precision of characteristic trees is still limited and the depth bound can result in unsatisfactory, ad-hoc specialisation (see <ref> [40, 35] </ref>). For- tunately, by combining our approach with [51], it is possible to get rid of this ad-hoc depth bound. The basic idea is to use a refined well-quasi order on characteristic trees which spots potential sequences of ever growing characteristic trees. <p> The basic idea is to use a refined well-quasi order on characteristic trees which spots potential sequences of ever growing characteristic trees. The details of this approach have been elaborated in <ref> [40, 35] </ref> (applied to [34], but the approach can be applied in exactly the same manner to the method of this paper).
Reference: [41] <author> M. Leuschel and M. H. Strensen. </author> <title> Redundant argument filtering of logic programs. </title> <editor> In J. Gallagher, editor, </editor> <booktitle> Proceedings of the International Workshop on Logic Program Synthesis and Transformation (LOPSTR'96), </booktitle> <volume> LNCS 1207, </volume> <pages> pages 83-103, </pages> <address> Stockholm, Sweden, </address> <month> August </month> <year> 1996. </year> <note> Springer-Verlag. Extended version as Technical Report CW 243, K.U. Leuven. </note>
Reference-contexts: In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. [17, 18, 20, 38, 33, 34]) and adapted correctness results can be found in [2]. See also the more powerful filtering techniques in <ref> [41] </ref>. The local control component is encapsulated in the unfolding rule, defined above. In addition to local correctness, termination and precision, the requirements on unfolding rules also include avoiding search space explosion as well as work duplication. <p> we can achieve preservation of characteristic trees using partial deduction of constrained atoms. 8 We will often take the liberty to not always explicitly mention the constraint domain D which was used to construct partial deductions and assume that D is fixed and known. 9 The more powerful optimisations in <ref> [41] </ref>, which remove redundant arguments, are not incorporated in this paper. They can easily be added as a post-processing phase. 20 Example 4.12 Let P be the program of Examples 3.8 and 4.9. Also let us use the same constraint structure D as in Example 4.9, containing Clark's equality theory.
Reference: [42] <author> J. W. Lloyd. </author> <title> Foundations of Logic Programming. </title> <publisher> Springer-Verlag, </publisher> <year> 1987. </year>
Reference-contexts: We also discuss related work and other potential applications of the constrained partial deduction framework of Section 4. The conclusion can be found in Section 8. 2 Preliminaries and Motivations Throughout this paper, we suppose familiarity with basic notions in logic programming (see e.g. <ref> [1, 42] </ref>). Notational conventions are standard and self-evident. In particular, in programs, we denote variables through strings starting with (or usually just consisting of ) an uppercase symbol, while the names of constants, functions and predicates begin with a lower-case character. <p> For example, independently of D, :(X = c) 2 p (X) is a D-instance of true 2 p (X ) because every substitution satisfies true . In turn, if D contains e.g. Clark's equality theory (CET, see e.g. <ref> [9, 42] </ref>) then true 2 p (b) is a D-instance of :(X = c) 2 p (X ) because fX=bg sat D :(X = c) given CET (i.e. CET j= ~ 8 (:(b = c))). <p> Proof By definition A 1 6~ A 2 stands for ~ 8 vars (A 1 ) (:(A 1 = A 0 2 )) where A 0 2 has been obtained by standardising apart (wrt A 1 ). It is well known (see e.g. [9] or Lemma 15.2 in <ref> [42] </ref>) that if B and C are not unifiable then CETj= ~ 8 (:(B = C)). Now by definition of applying substitutions we have (A 1 6~ A 2 )fl = ~ 8 vars (A 1 fl) (:(A 1 fl = A 0 2 )).
Reference: [43] <author> J. W. Lloyd and J. C. Shepherdson. </author> <title> Partial evaluation in logic programming. </title> <journal> The Journal of Logic Programming, </journal> <volume> 11(3& </volume> 4):217-242, 1991. 
Reference-contexts: 1 Introduction Partial evaluation has received considerable attention in logic programming [18, 29, 53] and functional programming (see e.g. [25] and references therein). In [28] Komorowski introduced the topic in the logic programming setting and later, for pure logic programs, first refers to it as partial deduction. Another milestone is <ref> [43] </ref>, where firm theoretical foundations for partial deduction are established. It introduces the notions of independence and closedness, which are properties of the set of atoms for which the partial deduction is performed. <p> In the current paper we show that these errors can lead to relevant precision losses and even to non-termination of the partial deduction process. We will also show that these problems cannot be solved within the standard partial deduction approach based on <ref> [43] </ref>. We therefore extend the standard partial deduction framework by integrating ideas from constraint logic programming (CLP) so as to be able to place constraints on the atoms in A. <p> That is why trivial trees are not allowed in Definitions 2.1 and 2.3. This is, however, not a sufficient condition for correctness of the specialised programs. In <ref> [43] </ref>, Lloyd and Shepherdson presented a fundamental correctness theorem for partial deduction. The two (additional) basic requirements for correctness of a partial deduction of P wrt A are the independence and closedness conditions. <p> The independence condition guarantees that the specialised program does not produce additional answers and the closedness condition guarantees that all calls, which might occur during the execution of the specialised program, are covered by some definition. The following summarises the correctness result of <ref> [43] </ref>: Definition 2.4 (A-closed, independence) Let S be a set of first order formulas and A a finite set of atoms. Then S is A-closed iff each atom in S containing a predicate symbol occurring in an atom in A is an instance of an atom in A. <p> Furthermore we say that A is independent iff no pair of atoms in A have a common instance. Theorem 2.5 (correctness of partial deduction <ref> [43] </ref>) Let P be a normal program, G a normal goal, A a finite, independent set of atoms, and P 0 a partial deduction of P wrt A such that P 0 [ fGg is A-closed. Then the following hold: 1. <p> Note that in Definition 4.11 the original program P is completely "thrown away". This is actually what a lot of practical partial evaluators for functional or logic programming languages do, but is unlike e.g. the definitions in <ref> [43] </ref> (cf. Definition 2.3). <p> p 62 chpaths (P; Gfl). 13 Note that when a selected literal does not unify with a particular clause then this does not correspond to a failed branch. 27 Proof (: Is a direct consequence of Lemma 4.11 a (for atomic goals) and Lemma 4.11 b (for general goals) in <ref> [43] </ref> (G can be seen as the head of a resultant which is constructed from a derivation whose characteristic path is p). ): Suppose that p 2 chpaths (P; Gfl). Let ffi 0 be a derivation for P [ fGflg with computed answer 0 and whose characteristic path is p. <p> Let ffi 0 be a derivation for P [ fGflg with computed answer 0 and whose characteristic path is p. We have that G is the head of the resultant R of the derivation ffi for P [ fGg. By Lemma 4.9 of <ref> [43] </ref> we can deduce that, because Gfl is an instance of G, the resultant R 0 of ffi 0 is in turn an instance of R. Hence we know that the head Gfl 0 of R 0 is also an instance of G. <p> Hence, as fl satisfies every n 2 prune P (B; t ), we can deduce that fl sat FT prune P (B; t ). 2. By the (correct version of the) lifting lemma <ref> [27, 43, 14, 1] </ref> we can deduce that t chpaths (P; B). Let us examine every p 2 t .
Reference: [44] <author> M. Maher. </author> <title> A logic programming view of CLP. </title> <editor> In D. S. Warren, editor, </editor> <booktitle> Proceedings of the 10th International Conference on Logic Programming, </booktitle> <pages> pages 737-753. </pages> <publisher> The MIT Press, </publisher> <year> 1993. </year> <month> 44 </month>
Reference-contexts: We will now define a counterpart to SLD-derivations for CLP-goals. In our context of partial deduction, the initial and final programs are just ordinary logic programs (i.e. they can be seen as CLP-programs using just equality constraints over the structure of feature terms F T , see <ref> [44] </ref>). In order for our constraint manipulations to be correct wrt the initial ordinary logic program, we have to ensure that equality is not handled in an unsound manner in the intermediate CLP-program. For instance, something like a = b should not succeed in the CLP-program.
Reference: [45] <author> J. Ma luszynski and T. Naslund. </author> <title> Fail substitutions for negation as failure. </title> <editor> In E. L. Lusk and R. A. Overbeek, editors, </editor> <booktitle> Logic Programming: Proceedings of the North American Conference, </booktitle> <pages> pages 461-476. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: For instance in the Example 5.9 above, the constraint would have to look like ^c = 8X::(p (Z) = p (s (X)))_ 8X::(p (Z) = p (s (s (X))))_ . . . . This idea is very related to the work in <ref> [45] </ref> which attempts to construct maximally general fail substitutions for negation as failure. Indeed for every resolvent goal G of a simple extension path we can attempt to construct a maximally general fail constraint ensuring that G fails. <p> A second possibility would be to extend the expressivity of the constraints. A promising approach in that direction is to extend the approach of computing fail substitutions <ref> [45] </ref>. There is, however, still a third possibility discussed in [34].
Reference: [46] <author> B. Martens. </author> <title> On the Semantics of Meta-Programming and the Control of Partial Deduction in Logic Programming. </title> <type> PhD thesis, K.U. </type> <institution> Leuven, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: Termination can be ensured by imposing a depth bound, but much more refined approaches to ensure local termination exist. The methods in <ref> [6, 50, 49, 46] </ref> are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. [13, 10]). Instead of well-founded ones, well-quasi orders can be used [4, 58]. <p> So if we use renaming to ensure independence and suppose that the local termination and precision problems have been solved, e.g. by <ref> [6, 50, 49, 46] </ref>, we are still left with the problem of ensuring closedness and global termination while minimising the global precision loss. <p> Unfortunately this process generally leads to non-termination (even when using the msg to ensure independence). The classical example illustrating this non-termination is the "reverse with accumulating parameter" program (see Example 3.7 below or e.g. <ref> [46, 50] </ref>). * Global Termination vs. Global Precision To ensure finiteness of A we can repeatedly apply an "abstraction" operator on A which generates a set of more general atoms. Unfortunately this induces a loss of global precision. <p> Note that only onemsg and chabsc guarantee termination. We compared the three approaches for the Lam & Kusalik benchmarks (see [31], they can also be found in <ref> [46, 57] </ref>) without negation and built-in's: ancestor, depth, transpose. We also experimented with the rev checklist program from Example 5.21, which we specialised for the S = frev (L; []; R)g. Another experiment, member, consisted in a slight adaptation of Example 3.11. The timing results are summarised in Table 1.
Reference: [47] <author> B. Martens and D. De Schreye. </author> <title> Two semantics for definite meta-programs, using the non-ground representation. </title> <editor> In K. R. Apt and F. Turini, editors, </editor> <booktitle> Meta-logics and Logic Programming, </booktitle> <pages> pages 57-82. </pages> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: We can, however, still rename G 2 into G 00 2 = member a ([b; a]). Theorem 4.14 can then applied to deduce that using P 0 [ fG 00 2 g is correct. Example 5.20 Let P be the well known "vanilla" solve meta-interpreter (see e.g. <ref> [23, 47, 48] </ref>). (1) solve (empty) (2) solve (X&Y ) solve (X); solve (Y ) (3) solve (X) clause (X; B); solve (B) (4) clause (p (a)) (5) clause (p (b)) (6) clause (q (a)) (7) clause (q (b)) 34 Let us suppose we use a purely determinate unfolding rule U
Reference: [48] <author> B. Martens and D. De Schreye. </author> <title> Why untyped non-ground meta-programming is not (much of) a problem. </title> <journal> The Journal of Logic Programming, </journal> <volume> 22(1) </volume> <pages> 47-99, </pages> <year> 1995. </year>
Reference-contexts: We can, however, still rename G 2 into G 00 2 = member a ([b; a]). Theorem 4.14 can then applied to deduce that using P 0 [ fG 00 2 g is correct. Example 5.20 Let P be the well known "vanilla" solve meta-interpreter (see e.g. <ref> [23, 47, 48] </ref>). (1) solve (empty) (2) solve (X&Y ) solve (X); solve (Y ) (3) solve (X) clause (X; B); solve (B) (4) clause (p (a)) (5) clause (p (b)) (6) clause (q (a)) (7) clause (q (b)) 34 Let us suppose we use a purely determinate unfolding rule U
Reference: [49] <author> B. Martens and D. De Schreye. </author> <title> Automatic finite unfolding using well-founded measures. </title> <journal> The Journal of Logic Programming, </journal> <volume> 28(2) </volume> <pages> 89-146, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: As common in partial deduction, the notion of SLDNF-trees is extended to also allow incomplete SLDNF-trees which, in addition to success and failure leaves, may also contain leaves where no literal has been selected for a further derivation step. Leaves of the latter kind will be called dangling <ref> [49] </ref>. <p> Termination can be ensured by imposing a depth bound, but much more refined approaches to ensure local termination exist. The methods in <ref> [6, 50, 49, 46] </ref> are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. [13, 10]). Instead of well-founded ones, well-quasi orders can be used [4, 58]. <p> So if we use renaming to ensure independence and suppose that the local termination and precision problems have been solved, e.g. by <ref> [6, 50, 49, 46] </ref>, we are still left with the problem of ensuring closedness and global termination while minimising the global precision loss.
Reference: [50] <author> B. Martens, D. De Schreye, and T. Horvath. </author> <title> Sound and complete partial deduction with unfolding based on well-founded measures. </title> <booktitle> Theoretical Computer Science, </booktitle> <address> 122(1-2):97117, </address> <year> 1994. </year>
Reference-contexts: Termination can be ensured by imposing a depth bound, but much more refined approaches to ensure local termination exist. The methods in <ref> [6, 50, 49, 46] </ref> are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. [13, 10]). Instead of well-founded ones, well-quasi orders can be used [4, 58]. <p> So if we use renaming to ensure independence and suppose that the local termination and precision problems have been solved, e.g. by <ref> [6, 50, 49, 46] </ref>, we are still left with the problem of ensuring closedness and global termination while minimising the global precision loss. <p> Unfortunately this process generally leads to non-termination (even when using the msg to ensure independence). The classical example illustrating this non-termination is the "reverse with accumulating parameter" program (see Example 3.7 below or e.g. <ref> [46, 50] </ref>). * Global Termination vs. Global Precision To ensure finiteness of A we can repeatedly apply an "abstraction" operator on A which generates a set of more general atoms. Unfortunately this induces a loss of global precision. <p> A very simple abstraction operator which ensures termination can be obtained by imposing a finite maximum number of atoms in A i and using the msg to stick to that finite number. For example, in <ref> [50] </ref> one atom per predicate is enforced by using the msg. However, using the msg in this way can induce an even bigger loss of precision (compared to using the msg to ensure independence) because it will now also be applied on independent atoms. <p> For instance, calculating the msg for the set of atoms fsolve (p (a)); solve (q (f (b)))g yields the atom solve (X ) and all potential for specialisation is probably lost. In <ref> [50] </ref> this problem has been remedied to some extent by using a static pre-processing renaming phase (as defined in [3]) which will generate one extra (renamed) version for the top-level atom to be specialised. <p> For this example, chabs P;U provides a terminating and fine grained control of polyvariance, conferring just as many versions as necessary. The abstraction operator chabs P;U is thus much more flexible than e.g. the static pre-processing renaming of <ref> [3, 50] </ref>). The above example is thus very encouraging, and one might hope that chabs P;U always preserves the characteristic trees upon generalisation and that it might already provide a refined solution to the control of polyvariance problem.
Reference: [51] <author> B. Martens and J. Gallagher. </author> <title> Ensuring global termination of partial deduction while allowing flexible polyvariance. </title> <editor> In L. Sterling, editor, </editor> <booktitle> Proceedings ICLP'95, </booktitle> <pages> pages 597613, </pages> <address> Kanagawa, Japan, </address> <month> June </month> <year> 1995. </year> <note> MIT Press. Extended version as Technical Report CSTR-94-16, </note> <institution> University of Bristol. </institution>
Reference-contexts: These are all considerations generally delegated to the control of partial deduction, which we discuss next. 2.2 Control of Partial Deduction In partial deduction one usually distinguishes two levels of control <ref> [18, 51] </ref>: * the global control , in which one chooses the set A, i.e. one decides which atoms will be partially deduced, and * the local control , in which one constructs the finite (possibly incomplete) SLDNF-trees for each individual atom in A and thus determines what the definitions for <p> For a recent approach (orthogonal to ours), which tackles this problem from another perspective, see <ref> [51] </ref>. In this approach structure is added to the set of atoms A allowing the abstraction operator to be applied more selectively. <p> However, even with that improvement, the precision of characteristic trees is still limited and the depth bound can result in unsatisfactory, ad-hoc specialisation (see [40, 35]). For- tunately, by combining our approach with <ref> [51] </ref>, it is possible to get rid of this ad-hoc depth bound. The basic idea is to use a refined well-quasi order on characteristic trees which spots potential sequences of ever growing characteristic trees.
Reference: [52] <author> S. Owen. </author> <title> Issues in the partial evaluation of meta-interpreters. </title> <editor> In H. Abramson and M. Rogers, editors, </editor> <booktitle> Meta-Programming in Logic Programming, Proceedings of the Meta88 Workshop, </booktitle> <month> June </month> <year> 1988, </year> <pages> pages 319-339. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: See also [54], where filtering is obtained automatically when using folding to simulate partial evaluation. Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in <ref> [52] </ref>. In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. [17, 18, 20, 38, 33, 34]) and adapted correctness results can be found in [2]. See also the more powerful filtering techniques in [41].
Reference: [53] <author> A. Pettorossi and M. Proietti. </author> <title> Transformation of logic programs: Foundations and techniques. </title> <journal> The Journal of Logic Programming, </journal> <volume> 19& 20 </volume> <pages> 261-320, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Partial evaluation has received considerable attention in logic programming <ref> [18, 29, 53] </ref> and functional programming (see e.g. [25] and references therein). In [28] Komorowski introduced the topic in the logic programming setting and later, for pure logic programs, first refers to it as partial deduction. Another milestone is [43], where firm theoretical foundations for partial deduction are established.
Reference: [54] <author> M. Proietti and A. Pettorossi. </author> <title> The loop absorption and the generalization strategies for the development of logic programs and partial deduction. </title> <journal> The Journal of Logic Programming, </journal> <volume> 16(1 </volume> & 2):123-162, May 1993. 
Reference-contexts: For further details about filtering see e.g. [20] or [2] where the filtering phase is performed as a one-step post-processing renaming. See also <ref> [54] </ref>, where filtering is obtained automatically when using folding to simulate partial evaluation. Filtering has also been referred to as "pushing down meta-arguments" in [64] or "PDMA" in [52]. In functional programming the term of "arity raising" has also been used.
Reference: [55] <author> T. C. Przymusinksi. </author> <title> On the declarative and procedural semantics of logic programs. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 5(2) </volume> <pages> 167-205, </pages> <year> 1989. </year>
Reference-contexts: In the context of SLDNF, this amounts to ensuring that A is ground and fails finitely. For the former, some form of groundness constraint seems to be required (this problem can be avoided if we use the SLS semantics of <ref> [55] </ref>). The latter is very similar to the difficulty encountered for non-failure preserving unfolding rules (cf. Example 5.9) because there can also be an infinite number of possibilities in which the subtree for A can be made to fail.
Reference: [56] <author> G. Puebla and M. Hermenegildo. </author> <title> Implementation of multiple specialization in logic pro-grams. </title> <booktitle> In Proceedings of PEPM'95, the ACM Sigplan Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 77-87, </pages> <address> La Jolla, California, June 1995. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The method presented in the remainder of this section can in fact be easily adapted in that direction, thus lifting the restriction on unfolding rules. A post-processing phase could be devised, e.g. based on techniques in <ref> [56, 40] </ref>, to then remove the unnecessary (cf. Section 3) polyvariance generated by such an approach.
Reference: [57] <author> D. Sahlin. </author> <title> An Automatic Partial Evaluator for Full Prolog. </title> <type> PhD thesis, </type> <institution> Swedish Institute of Computer Science, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: Note that only onemsg and chabsc guarantee termination. We compared the three approaches for the Lam & Kusalik benchmarks (see [31], they can also be found in <ref> [46, 57] </ref>) without negation and built-in's: ancestor, depth, transpose. We also experimented with the rev checklist program from Example 5.21, which we specialised for the S = frev (L; []; R)g. Another experiment, member, consisted in a slight adaptation of Example 3.11. The timing results are summarised in Table 1.
Reference: [58] <author> D. Sahlin. Mixtus: </author> <title> An automatic partial evaluator for full Prolog. </title> <journal> New Generation Computing, </journal> <volume> 12(1) </volume> <pages> 7-51, </pages> <year> 1993. </year> <month> 45 </month>
Reference-contexts: The methods in [6, 50, 49, 46] are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. [13, 10]). Instead of well-founded ones, well-quasi orders can be used <ref> [4, 58] </ref>. Homeomorphic embedding [63, 40] on selected atoms has recently gained popularity as the basis for such an order.
Reference: [59] <author> J. C. Shepherdson. </author> <title> Language and equality theory in logic programming. </title> <type> Technical Report PM-91-02, </type> <institution> University of Bristol, </institution> <year> 1991. </year>
Reference-contexts: So it is basically the same structure as the one used for CLP (F T ), as defined e.g. in [62]. 12 The same theory has also been used, for different purposes, in the constructive negation techniques (e.g. <ref> [7, 8, 15, 59, 66, 65] </ref>). <p> Because there is only one way in which failure can occur, it is possible to calculate a finite constraint c satisfying the above. 11 For a detailed study of the relation between the underlying language and equality theory we refer the reader to <ref> [59] </ref>. 12 We will actually restrict ourselves to a subset of CLP (FT ) in which satisfiability can be decided by simple matching.
Reference: [60] <author> D. A. Smith. </author> <title> Constraint operations for CLP(F T ). In K. </title> <editor> Furukawa, editor, </editor> <booktitle> Logic Programming: Proceedings of the Eighth International Conference, </booktitle> <pages> pages 760-774. </pages> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: Note that CET is a complete theory [30] and we suppose that we have the required algorithms for satisfiability checking, simplification and projection at our disposal (see e.g. <ref> [66, 65, 60] </ref>). 5.1 Pruning Constraints As we have already seen in Section 3, when taking the msg of two atoms A and B with the same characteristic tree t , we do not necessarily obtain an atom C which has the same characteristic tree. <p> As Algorithm 5.16 is based on the structure F T we conjecture that an adaptation of our technique might yield a refined specialisation technique for CLP (F T ) <ref> [60, 61, 62] </ref>. Also, it is actually not very difficult to adapt the framework of Section 4.2 to work on CLP-programs instead of ordinary logic programs | we just have to require that equality is handled in the same manner as in logic programming.
Reference: [61] <author> D. A. Smith. </author> <title> Partial evaluation of pattern matching in constraint logic programming languages. </title> <editor> In N. D. Jones and P. Hudak, editors, </editor> <booktitle> ACM Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 62-71. </pages> <publisher> ACM Press Sigplan Notices 26(9), </publisher> <year> 1991. </year>
Reference-contexts: As Algorithm 5.16 is based on the structure F T we conjecture that an adaptation of our technique might yield a refined specialisation technique for CLP (F T ) <ref> [60, 61, 62] </ref>. Also, it is actually not very difficult to adapt the framework of Section 4.2 to work on CLP-programs instead of ordinary logic programs | we just have to require that equality is handled in the same manner as in logic programming.
Reference: [62] <author> D. A. Smith and T. Hickey. </author> <title> Partial evaluation of a CLP language. </title> <editor> In S. Debray and M. Hermenegildo, editors, </editor> <booktitle> Proceedings of the North American Conference on Logic Programming, </booktitle> <pages> pages 119-138. </pages> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: So it is basically the same structure as the one used for CLP (F T ), as defined e.g. in <ref> [62] </ref>. 12 The same theory has also been used, for different purposes, in the constructive negation techniques (e.g. [7, 8, 15, 59, 66, 65]). <p> As Algorithm 5.16 is based on the structure F T we conjecture that an adaptation of our technique might yield a refined specialisation technique for CLP (F T ) <ref> [60, 61, 62] </ref>. Also, it is actually not very difficult to adapt the framework of Section 4.2 to work on CLP-programs instead of ordinary logic programs | we just have to require that equality is handled in the same manner as in logic programming.
Reference: [63] <author> M. H. Strensen and R. Gluck. </author> <title> An algorithm of generalization in positive supercompilation. </title> <editor> In J. W. Lloyd, editor, </editor> <booktitle> Proceedings of ILPS'95, the International Logic Programming Symposium, </booktitle> <pages> pages 465-479, </pages> <address> Portland, USA, December 1995. </address> <publisher> MIT Press. </publisher>
Reference-contexts: The methods in [6, 50, 49, 46] are based on well-founded orders, inspired by their usefulness in the context of static termination analysis (see e.g. [13, 10]). Instead of well-founded ones, well-quasi orders can be used [4, 58]. Homeomorphic embedding <ref> [63, 40] </ref> on selected atoms has recently gained popularity as the basis for such an order.
Reference: [64] <author> L. Sterling and R. D. Beer. </author> <title> Metainterpreters for expert system construction. </title> <journal> The Journal of Logic Programming, </journal> <volume> 6(1 </volume> & 2):163-178, 1989. 
Reference-contexts: For further details about filtering see e.g. [20] or [2] where the filtering phase is performed as a one-step post-processing renaming. See also [54], where filtering is obtained automatically when using folding to simulate partial evaluation. Filtering has also been referred to as "pushing down meta-arguments" in <ref> [64] </ref> or "PDMA" in [52]. In functional programming the term of "arity raising" has also been used. Renaming and filtering are used in a lot of practical approaches (e.g. [17, 18, 20, 38, 33, 34]) and adapted correctness results can be found in [2].
Reference: [65] <author> P. J. Stuckey. </author> <title> Constructive negation for constraint logic programming. </title> <booktitle> In Proceedings, Sixth Annual IEEE Symposium on Logic in Computer Science, </booktitle> <pages> pages 328-339, </pages> <address> Amsterdam, The Netherlands, July 1991. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: So it is basically the same structure as the one used for CLP (F T ), as defined e.g. in [62]. 12 The same theory has also been used, for different purposes, in the constructive negation techniques (e.g. <ref> [7, 8, 15, 59, 66, 65] </ref>). <p> Note that CET is a complete theory [30] and we suppose that we have the required algorithms for satisfiability checking, simplification and projection at our disposal (see e.g. <ref> [66, 65, 60] </ref>). 5.1 Pruning Constraints As we have already seen in Section 3, when taking the msg of two atoms A and B with the same characteristic tree t , we do not necessarily obtain an atom C which has the same characteristic tree.
Reference: [66] <author> P. J. Stuckey. </author> <title> Negation and constraint logic programming. </title> <journal> Information and Computation, </journal> <volume> 118(1) </volume> <pages> 12-33, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: So it is basically the same structure as the one used for CLP (F T ), as defined e.g. in [62]. 12 The same theory has also been used, for different purposes, in the constructive negation techniques (e.g. <ref> [7, 8, 15, 59, 66, 65] </ref>). <p> Note that CET is a complete theory [30] and we suppose that we have the required algorithms for satisfiability checking, simplification and projection at our disposal (see e.g. <ref> [66, 65, 60] </ref>). 5.1 Pruning Constraints As we have already seen in Section 3, when taking the msg of two atoms A and B with the same characteristic tree t , we do not necessarily obtain an atom C which has the same characteristic tree. <p> However, establishing the correctness will become much more difficult because one cannot reuse the correctness results of standard partial deduction. In that context, we would like to mention <ref> [66] </ref>, which extends constructive negation for CLP-programs, as well as recent work on the transformation of CLP-programs [16]. Note, however, that [16] is situated within the unfold/fold transformation paradigm and also that no concrete algorithms are presented.
Reference: [67] <author> V. F. Turchin. </author> <title> The concept of a supercompiler. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(3) </volume> <pages> 292-325, </pages> <year> 1986. </year>
Reference-contexts: In Section 3 we introduce the concepts of characteristic paths and trees and exhibit their significance for partial deduction. This is the first time that, to our knowledge, the interest and motivations of characteristic trees (or neighbourhoods in supercompilation of functional programs <ref> [67, 68] </ref> for that matter) are made explicit. We also make a first attempt at defining a proper abstraction operator and show its (substantial) difficulties. We also illustrate the problem with the approaches in [20] and [17]. <p> However, the generic framework is not restricted to this particular application nor the corresponding constraint structure. Amongst others, it can also be used to "drive negative information" (using the terminology of supercompilation <ref> [67, 68] </ref>), handle built-ins (like &lt; =2; n == =2) much more precisely and even make use of type information or argument size relations. We will briefly return to this issue in Section 7. <p> The following example illustrates this, where a form of "driving of negative information" (using the terminology of supercompilation <ref> [67, 68] </ref>) is achieved by constrained partial deduction.
Reference: [68] <author> V. F. Turchin. </author> <title> Program transformation with metasystem transitions. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(3) </volume> <pages> 283-313, </pages> <year> 1993. </year>
Reference-contexts: In Section 3 we introduce the concepts of characteristic paths and trees and exhibit their significance for partial deduction. This is the first time that, to our knowledge, the interest and motivations of characteristic trees (or neighbourhoods in supercompilation of functional programs <ref> [67, 68] </ref> for that matter) are made explicit. We also make a first attempt at defining a proper abstraction operator and show its (substantial) difficulties. We also illustrate the problem with the approaches in [20] and [17]. <p> However, the generic framework is not restricted to this particular application nor the corresponding constraint structure. Amongst others, it can also be used to "drive negative information" (using the terminology of supercompilation <ref> [67, 68] </ref>), handle built-ins (like &lt; =2; n == =2) much more precisely and even make use of type information or argument size relations. We will briefly return to this issue in Section 7. <p> The following example illustrates this, where a form of "driving of negative information" (using the terminology of supercompilation <ref> [67, 68] </ref>) is achieved by constrained partial deduction.
References-found: 68

