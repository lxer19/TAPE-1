URL: ftp://iamftp.unibe.ch/pub/TechReports/1993/iam-93-017.ps.gz
Refering-URL: 
Root-URL: 
Title: Vision Planner for an Intelligent Multisensory Vision System  
Author: X. Y. Jiang, H. Bunke 
Keyword: CR Categories and Subject Descriptors: I.2.8 [Problem Solving, Control Methods, and Search]: Plan execution, formation, generation; I.2.10 [Vision and Scene Understanding]: Architecture and control structures. Additional Key Words: Robot vision, multisensory vision system, planning.  
Address: Bern, Langgassstrasse 51, 3012 Bern, Switzerland  
Affiliation: Institut fur Informatik und angewandte Mathematik Universitat  
Abstract: In this paper we present a multisensory vision system that is intended to support the vision requirements of an intelligent robot system. Contrary to many other vision systems, our system has two significant new features. First, it contains multiple sensors, object representations, image analysis and interpretation methods in order to solve a number of different vision tasks. Secondly, it comprises a vision planner. Upon a task-level vision request from the robot system, the vision planner transforms it into appropriate sequences of concrete vision operations, executes these operations, and if necessary, finds out alternative strategies. Experimental results demonstrate the clear advantage of this combination of multiple resources with the vision planner in solving typical vi sion problems for robotic tasks.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Arman, J. K. Aggarwal, </author> <title> Model-based object recognition in dense-range images A review, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 25, No. 1, </volume> <pages> 5-43, </pages> <year> 1993. </year>
Reference-contexts: Instead, plenty of object recognition methods have been proposed in the literature <ref> [1, 2, 8, 18] </ref>. They differ from each other in sensory data type (intensity image, range data, ), object type they can handle (polyhedra, curved objects, ), scene complexity (objects are isolated, touching, or overlapping), scene and model features used, matching strategies, etc.
Reference: [2] <author> P. J. Besl, R. C. Jain, </author> <title> Three dimensional object recognition, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 17, No. 1, </volume> <pages> 75-145, </pages> <year> 1985. </year>
Reference-contexts: Instead, plenty of object recognition methods have been proposed in the literature <ref> [1, 2, 8, 18] </ref>. They differ from each other in sensory data type (intensity image, range data, ), object type they can handle (polyhedra, curved objects, ), scene complexity (objects are isolated, touching, or overlapping), scene and model features used, matching strategies, etc.
Reference: [3] <author> P. J. Besl, </author> <title> Active, optical range imaging sensors, </title> <journal> Machine Vision and Applications, </journal> <volume> Vol. 1, No. 2, </volume> <pages> 127-152, </pages> <year> 1988. </year> <note> Also in J. </note> <editor> L. C. Sanz (Ed.), </editor> <booktitle> Advances in machine vision, </booktitle> <pages> 1-63, </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Due to the two stage strategy this recognition method is computationally very efficient. 2.2 Object recognition in range images 2.2.1 Range sensing The range sensor we use is an active system based on the coded light approach <ref> [3] </ref>. Through a sequence of n binary patterns from a projector, 3-D space can be partitioned into 2 n thin regions. A camera receives n images, each corresponding to one binary pattern, and creates a stack of n bit maps assigning an n bit code to each observed scene point.
Reference: [4] <author> P. J. Besl, R. C. Jain, </author> <title> Segmentation via variable-order surface fitting, </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 10, No. 2, </volume> <pages> 167-192, </pages> <year> 1988. </year>
Reference-contexts: This makes the segmentation method very fast. 2.2.3 Range image segmentation through variable-order surface fitting Another region-based segmentation method [16] is an implementation and improvement of the algorithm described in <ref> [4, 5] </ref>. It segments range images into not only planar but also curved surface patches. In the first step, the range image is divided into subimages by jump edge detection.
Reference: [5] <author> P. J. Besl, </author> <title> Surfaces in range image understanding, </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: This makes the segmentation method very fast. 2.2.3 Range image segmentation through variable-order surface fitting Another region-based segmentation method [16] is an implementation and improvement of the algorithm described in <ref> [4, 5] </ref>. It segments range images into not only planar but also curved surface patches. In the first step, the range image is divided into subimages by jump edge detection.
Reference: [6] <author> P. J. Besl, </author> <title> The free-form surface matching problem, </title> <editor> in H. Freeman (Ed.), </editor> <title> Machine vision for three-dimensional scenes, </title> <address> 25-71, </address> <publisher> Academic Press, </publisher> <year> 1990. </year> <month> 21 </month>
Reference-contexts: First of all, more modules should be integrated into the system to extend the functionality of the system. Potential new modules could be the identification and localization of the topmost object in a pile of objects [20], matching of free-form surfaces <ref> [6] </ref>, a.s.o. In a working system the integration of the modules should be realized at a low level. That is, the modules are coded as subroutines and the exchange of information between the modules is done through internal data structures instead of files as in the current prototype.
Reference: [7] <author> B. Boyter, J. K. Aggarwal, </author> <title> Recognition of polyhedra from range data, </title> <journal> IEEE Expert, </journal> <volume> Vol. 1, No. 1, </volume> <pages> 47-59, </pages> <year> 1985. </year>
Reference-contexts: We have implemented an object recognition method using three-dimensional line segments <ref> [7] </ref>.
Reference: [8] <author> J. P. Brady, N. Nandhakumar, J. K. Aggarwal, </author> <title> Recent progress in object recognition from range data, </title> <journal> Image and Vision Computing, </journal> <volume> Vol. 7, No. 4, </volume> <pages> 295-307, </pages> <year> 1989. </year>
Reference-contexts: Instead, plenty of object recognition methods have been proposed in the literature <ref> [1, 2, 8, 18] </ref>. They differ from each other in sensory data type (intensity image, range data, ), object type they can handle (polyhedra, curved objects, ), scene complexity (objects are isolated, touching, or overlapping), scene and model features used, matching strategies, etc.
Reference: [9] <author> T. Glauser, E. Gmur, X. Y. Jiang, H. Bunke, </author> <title> Deductive generation of vision representations from CAD-models, </title> <booktitle> Proc. of 6th Scandinavian Conference on Image Analysis, </booktitle> <pages> 645-651, </pages> <address> Oulu, Finland, </address> <year> 1989. </year>
Reference-contexts: On the other hand, geometric representations common in CAD-systems usually cannot be directly applied for object recognition. To overcome this problem, we have built a CAD-interface <ref> [9] </ref> that automatically constructs the model representations from CAD-models generated by the commercial CAD-system Prime-Medusa. 3 Vision planner The ultimate goal of our multisensory vision system is to meet the needs of various vision tasks required by an intelligent robot system. <p> Some examples of these new developments are the fast range image segmentation method [12] and the object recognition method in intensity images [10, 11] and range images [19]. Also, the CAD-model transformation approach for automatic generation of vision models <ref> [9] </ref> is becoming more and more important and may make a large contribution to the area of automatic model construction.
Reference: [10] <author> E. Gmur, </author> <title> Robuste und effiziente Erkennung von 3D Objekten mittels Hypergraph-Homomorphismen, </title> <editor> in R. E. Grosskopf (Ed.), </editor> <booktitle> Mustererkennung 1990, </booktitle> <volume> Informatik-Fachberichte 254, </volume> <pages> 667-674, </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: The vision planner is described in detail in Section 3. 2.1 Object recognition in intensity images The intensity images are acquired by a CCD camera. From an intensity image, line and junction features are extracted by means of the following steps <ref> [10, 11] </ref>: convolution of the intensity image with a Gauss-Laplace operator; edge point detection by locating the zerocrossings in the convoluted image with subpixel accuracy; linking of the edge points to edge chains; segmentation of the edge chains into straight lines, arcs and ellipses; connection of the lines at junctions and <p> Some examples of these new developments are the fast range image segmentation method [12] and the object recognition method in intensity images <ref> [10, 11] </ref> and range images [19]. Also, the CAD-model transformation approach for automatic generation of vision models [9] is becoming more and more important and may make a large contribution to the area of automatic model construction.
Reference: [11] <author> E. Gmur, PHI-2: </author> <title> Ein effizientes und robustes Sichtsystem zur Erkennung dreidi-mensionaler Werkstucke, </title> <type> Technical Report, </type> <institution> IAM-90-016, </institution> <year> 1990. </year>
Reference-contexts: The vision planner is described in detail in Section 3. 2.1 Object recognition in intensity images The intensity images are acquired by a CCD camera. From an intensity image, line and junction features are extracted by means of the following steps <ref> [10, 11] </ref>: convolution of the intensity image with a Gauss-Laplace operator; edge point detection by locating the zerocrossings in the convoluted image with subpixel accuracy; linking of the edge points to edge chains; segmentation of the edge chains into straight lines, arcs and ellipses; connection of the lines at junctions and <p> Some examples of these new developments are the fast range image segmentation method [12] and the object recognition method in intensity images <ref> [10, 11] </ref> and range images [19]. Also, the CAD-model transformation approach for automatic generation of vision models [9] is becoming more and more important and may make a large contribution to the area of automatic model construction.
Reference: [12] <author> X. Y. Jiang, H. Bunke, </author> <title> Fast segmentation of range images into planar regions by scan line grouping, Machine Vision and Applications. </title> <note> (to appear) </note>
Reference-contexts: For the analysis of scenes containing only polyhedral objects it is adequate to segment range images into planar regions. A fast method for doing this <ref> [12] </ref> is based on the observation that in a scan line, the points belonging to a planar surface form a straight line segment. On the other hand, all points on a straight line segment surely belong to the same planar surface. <p> Although these new techniques have been developed in the context of our multisensory vision system, they are valuable in their own right and can also be used in other applications. Some examples of these new developments are the fast range image segmentation method <ref> [12] </ref> and the object recognition method in intensity images [10, 11] and range images [19]. Also, the CAD-model transformation approach for automatic generation of vision models [9] is becoming more and more important and may make a large contribution to the area of automatic model construction.
Reference: [13] <author> S. E. Keene, </author> <title> Object-oriented programming in Common Lisp, </title> <publisher> Addison Wesley, </publisher> <year> 1989. </year>
Reference-contexts: example above the execution of the sequence S 2 means just that of the modules M 23 ; ; M 2n . 4 Implementation We have implemented a prototype of the vision planner described in the last section on Sun workstations with Common Lisp and Common Lisp Object System (CLOS) <ref> [13, 15] </ref>. The current version runs in the interative Lisp environment. The communication with the robot system is simulated by a dialog with the user.
Reference: [14] <author> D. Nitzan, </author> <title> Development of intelligent robots: Achievements and issues, </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> Vol. 1, No. 1, </volume> <pages> 3-13, </pages> <year> 1985. </year>
Reference-contexts: It is thus commonly agreed that robots of the next generation, although not required to act or look like a human, should be able to perform tasks that need artificial intelligence and flexibility <ref> [14] </ref>. Artificial intelligence means here the ability of a robot to perceive the actual situation it is faced with which may not be known a priori, to decide what actions to be done, and to plan these actions accordingly.
Reference: [15] <editor> A. Paepcke (Ed.), </editor> <title> Object-oriented programming: the CLOS perspective, </title> <publisher> The MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: example above the execution of the sequence S 2 means just that of the modules M 23 ; ; M 2n . 4 Implementation We have implemented a prototype of the vision planner described in the last section on Sun workstations with Common Lisp and Common Lisp Object System (CLOS) <ref> [13, 15] </ref>. The current version runs in the interative Lisp environment. The communication with the robot system is simulated by a dialog with the user.
Reference: [16] <author> R. Robmann, Segmentierung von Tiefenbildern, </author> <type> Master's Thesis, </type> <year> 1991. </year>
Reference-contexts: Due to the use of straight line segments instead of the individual pixels, the data dimension that must be handled in the region growing process can be greatly reduced. This makes the segmentation method very fast. 2.2.3 Range image segmentation through variable-order surface fitting Another region-based segmentation method <ref> [16] </ref> is an implementation and improvement of the algorithm described in [4, 5]. It segments range images into not only planar but also curved surface patches. In the first step, the range image is divided into subimages by jump edge detection.
Reference: [17] <author> T. G. Stahs, F. M. Wahl, </author> <title> Fast and robust range data acquisition in a low-cost environment, </title> <booktitle> Proc. of ISPRS-Conference, SPIE Vol. 1395, </booktitle> <address> Zurich, 496-503, </address> <year> 1990. </year>
Reference-contexts: Our sensor acquires a range image of 512fi512 points and a registered intensity image in a few seconds. For more details see <ref> [17] </ref>. 5 We have established a range image database of about 20 scenes containing up to five polyhedral objects. 2.2.2 Range image segmentation through scan line grouping The goal of range image segmentation is to partition range images into surface patches useful for subsequent interpretation tasks.
Reference: [18] <author> P. Suetens, P. Fua, A. J. Hanson, </author> <title> Computational strategies for object recognition, </title> <journal> ACM Computing Surveys, </journal> <volume> Vol. 24, No. 1, </volume> <pages> 5-61, </pages> <year> 1992. </year>
Reference-contexts: Instead, plenty of object recognition methods have been proposed in the literature <ref> [1, 2, 8, 18] </ref>. They differ from each other in sensory data type (intensity image, range data, ), object type they can handle (polyhedra, curved objects, ), scene complexity (objects are isolated, touching, or overlapping), scene and model features used, matching strategies, etc.
Reference: [19] <author> A. Ueltschi, </author> <title> Modellbasierte Objekterkennung in Tiefenbildern, </title> <type> Technical Report, </type> <institution> IAM-93-018, </institution> <year> 1993. </year>
Reference-contexts: Note that since straight line segments are used for matching, this method works only for polyhedral objects. 2.2.5 Object recognition by subgraph isomorphism search We have developed another object recognition method by subgraph isomorphism search <ref> [19] </ref>. From the segmentation results we construct a scene graph where a node stands for a surface patch while an edge represents the neighborhood relationship between two surface patches. <p> Some examples of these new developments are the fast range image segmentation method [12] and the object recognition method in intensity images [10, 11] and range images <ref> [19] </ref>. Also, the CAD-model transformation approach for automatic generation of vision models [9] is becoming more and more important and may make a large contribution to the area of automatic model construction.
Reference: [20] <author> H. S. Yang, A. C. Kak, </author> <title> Determination of the identity, position and orientation of the topmost object in a pile, Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> Vol. 36, </volume> <pages> 229-255, </pages> <year> 1986. </year> <month> 22 </month>
Reference-contexts: First of all, more modules should be integrated into the system to extend the functionality of the system. Potential new modules could be the identification and localization of the topmost object in a pile of objects <ref> [20] </ref>, matching of free-form surfaces [6], a.s.o. In a working system the integration of the modules should be realized at a low level.
References-found: 20

