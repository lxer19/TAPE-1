URL: http://ptolemy.eecs.berkeley.edu/papers/erl-95-36/erl-95-36.ps.gz
Refering-URL: http://ptolemy.eecs.berkeley.edu/papers/erl-95-36/
Root-URL: 
Title: A HIERARCHICAL MULTIPROCESSOR SCHEDULING FRAMEWORK FOR SYNCHRONOUS DATAFLOW GRAPHS a clustering algorithm that reduces the
Author: Jos Luis Pino, Shuvra S. Bhattacharyya, and Edward A. Lee L. Pino and E. A. Lee S. S. Bhattacharyya 
Address: Berkeley, California 94720, USA.  East Tasman Drive, San Jose, California 95134, USA.  
Affiliation: Dept. of Electrical Engineering and Computer Sciences, University of California at  Semiconductor Research Laboratory, Hitachi America, Ltd., 201  
Note: J.  are with the  is with the  work is  is done in such a manner as to leave ample  
Date: May 30, 1995  
Pubnum: Technical Report: UCB/ERL M95/36  
Abstract: This research was partially funded as part of the Ptolemy project, which is supported by the Advanced Research Projects Agency and the U.S. Air Force (under the RASSP program, contract F33615-93-C-1317), the Semiconductor Research Corporation (project 94-DC-008), the National Science Foundation (MIP-9201605), the State of California MICRO program, and the following companies: Bellcore, Bell Northern Research, Dolby Laboratories, Hitachi, Mentor Graphics, Mitsubishi, NEC, Pacific Bell, Philips, and Rockwell. Jos Luis Pino is also supported by AT&T Bell Laboratories as part of the Cooperative Research Fellowship Program. ABSTRACT This paper discusses a hierarchical scheduling framework to reduce the complexity of scheduling synchronous dataow (SDF) graphs onto multiple processors. The core of this frame
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.L. Pino and E.A. Lee, </author> <title> Hierarchical static scheduling of dataow graphs onto multiple processors, </title> <booktitle> IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Detroit, Michigan, </address> <publisher> IEEE, </publisher> <year> 1995. </year>
Reference-contexts: Hierarchical scheduling algorithm We are now ready to present the proposed hierarchical scheduling algorithm. This algorithm will be implemented in the months to come within the Ptolemy project. 7.1 Initialization 1. Cluster nodes that are on SDF well-ordered URC subgraphs without internal state <ref> [1] </ref>. 2. Cluster nodes that share resource constraints which satisfy the SDF composition theorem. 3. Compute the repetitions vector, , . 4. Construct the acyclic SDF graph. 5. <p> Schedule user specified clusters with the given scheduler. 3. Schedule the clustered system with the user specified multiprocessor scheduler 8. Performance The hierarchical scheduling framework for user specified clustering has been implemented in Ptolemy <ref> [1] </ref>. Four signal processing applications have been synthesized for a heterogeneous multiprocessor consisting of a RISC and a DSP processor. An example system that was designed within this framework will be detailed in the following section.
Reference: [2] <author> J. Buck, S. Ha, E.A. Lee, and D.G. Messerschmitt, Ptolemy: </author> <title> A framework for simulating and prototyping heterogeneous systems, </title> <journal> International Journal of Computer Simulation, special issue on Simulation Software Development, </journal> <volume> vol. 4, </volume> <year> 1994, </year> <pages> p. 155-182. </pages>
Reference: [3] <author> J.L. Pino, S. Ha, E.A. Lee, and J.T. Buck, </author> <title> Software synthesis for DSP using Ptolemy, </title> <note> Journal of VLSI Signal Processing to appear in special issue on Synthesis for DSP, </note> <year> 1993. </year>
Reference: [4] <author> E.A. Lee and S. Ha, </author> <title> Scheduling strategies for multiprocessor real-time DSP, </title> <booktitle> IEEE Global Telecommunications Conference and Exhibition. Communications Technology for the 1990s and Beyond, </booktitle> <volume> vol. </volume> <pages> 2, </pages> <address> Dallas, TX, USA, </address> <publisher> IEEE, </publisher> <year> 1989, </year> <pages> p. 1279-1283. </pages>
Reference: [5] <author> D.G. Powell, E. A.Lee, and W.C. Newman, </author> <title> Direct synthesis of optimized DSP assembly code from signal ow block diagrams, </title> <booktitle> IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. </volume> <pages> 5, </pages> <address> San Francisco, CA, </address> <publisher> IEEE, </publisher> <year> 1992, </year> <pages> p. 553-556. 33 </pages>
Reference: [6] <author> S. Ritz, M. Pankert, and H. Meyr, </author> <title> High level software synthesis for signal processing systems, </title> <booktitle> International Conference on Application Specific Array Processors, </booktitle> <address> Berkeley, CA, USA, </address> <publisher> IEEE Computer Society Press, </publisher> <year> 1992, </year> <pages> p. 679-693. </pages>
Reference: [7] <author> E.A. Lee and D.G. Messerschmitt, </author> <title> Synchronous data ow, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 75, no. 9, </volume> <year> 1987, </year> <pages> p. 1235-1245. </pages>
Reference: [8] <author> J. Buck, S. Ha, E.A. Lee, and D.G. Messerschmitt, </author> <title> Multirate signal processing in Ptolemy, </title> <booktitle> IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. </volume> <pages> 2, </pages> <institution> Toronto, Ont., Canada, IEEE, </institution> <year> 1991, </year> <pages> p. 1245-1248. </pages>
Reference: [9] <author> H. Printz, </author> <title> Automatic mapping of large signal processing systems to a parallel machine, </title> <type> Ph.D. </type> <institution> Dissertation CMU-CS-91-101, Carnegie Mellon, </institution> <year> 1991. </year>
Reference: [10] <author> G.C. Sih and E.A. Lee, </author> <title> Dynamic-level scheduling for heterogeneous processor networks, </title> <booktitle> Second IEEE Symposium on Parallel and Distributed Processing, </booktitle> <address> Dallas, TX, USA, </address> <publisher> IEEE Computer Society Press, </publisher> <year> 1990, </year> <pages> p. 42-49. </pages>
Reference: [11] <author> M.R. Garey and D.S. Johnson, </author> <title> Computers and Intractability: A guide to the theory of NP-completeness, </title> <address> New York: </address> <publisher> W.H. Freeman, </publisher> <year> 1991. </year>
Reference: [12] <author> A. Gerasoulis and T. Yang, </author> <title> A comparison of clustering heuristics for scheduling directed acyclic graphs on multiprocessors, </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> vol. 16, no. 4, </volume> <year> 1992, </year> <pages> p. 276-291. </pages>
Reference: [13] <author> S.J. Kim and J.C. Browne, </author> <title> A general approach to mapping of parallel computations upon multiprocessor architectures, </title> <booktitle> International Conference on Parallel Processing, </booktitle> <volume> vol. </volume> <pages> 3, </pages> <institution> University Park, PA, USA, Pennsylvania State Univ, </institution> <year> 1988, </year> <pages> p. 1-8. </pages>
Reference: [14] <author> V. Sarkar, </author> <title> Partitioning and scheduling parallel programs for multiprocessors, </title> <address> Cambridge, Mass.: </address> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: This clustering does not hide any of the available parallelism that will be exposed in the final DAG. An example is shown in figure 13. Finally, the last clustering technique is based on an adaptation of Sarkars multiprocessor DAG scheduling heuristic to SDF graphs <ref> [14] </ref>. Sarkars algorithm is described below, and an example is shown in figure 14: 1. Sort arcs of a DAG in descending order of arc costs 2 2 3 3 1 1 1 1 1 26 2.
Reference: [15] <author> G.C. Sih and E.A. Lee, </author> <title> Declustering: A new multiprocessor scheduling technique, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <year> 1992. </year>
Reference: [16] <author> S.S. Bhattacharyya, </author> <title> Compiling dataow programs for digital signal processing, </title> <type> Ph.D. </type> <institution> Dissertation UCB/ERL M94/52, University of California at Berkeley, </institution> <year> 1994. </year>
Reference-contexts: Schedule SDF uniprocessor clusters with the loop scheduler of reference [18], which has time complexity that is , where , and is the set of nodes that are contained in the tightly interdependent components of the SDF graph <ref> [16] </ref>. 1 2. Schedule user specified clusters with the given scheduler. 3. Schedule the clustered system with the user specified multiprocessor scheduler 8. Performance The hierarchical scheduling framework for user specified clustering has been implemented in Ptolemy [1]. <p> Note that for all systems, the hierarchical scheduling time was around 1 - 2 orders of magnitude faster, while the 1. It has been observed that tightly interdependent components appear to be nonexistent in most practical SDF graph, and thus, the complexity is often simply <ref> [16] </ref>. q v i ( ) Kmax V P,( )&lt; v i V O m 2 q v ( ) +( ) m max V E,( )= T 2 28 generated code was 1 - 2 orders of magnitude smaller.
Reference: [17] <author> P.K. Murthy, S.S. Bhattacharyya, and E.A. Lee, </author> <title> Combined code and data minimization for synchronous dataow programs, </title> <institution> Memorandum UCB/ERL M94/93, Electronics Research Laboratory, University of California at Berkeley, December,1994. </institution>
Reference: [18] <author> S. S. Bhattacharyya, J. T. Buck, S. Ha, and E. A. Lee, </author> <title> Generating compact code from data-ow specifications of multirate signal processing algorithms, </title> <journal> IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications, </journal> <volume> vol. 42, no. 3, </volume> <pages> p. 138-150, </pages> <month> March, </month> <year> 1995. </year>
Reference-contexts: Repeat 1,2 until we reach a stopping condition. We plan on using a stopping condition similar to: . 7.3 Wrap up 1. Schedule SDF uniprocessor clusters with the loop scheduler of reference <ref> [18] </ref>, which has time complexity that is , where , and is the set of nodes that are contained in the tightly interdependent components of the SDF graph [16]. 1 2. Schedule user specified clusters with the given scheduler. 3. <p> Since we are able to use SDF uniprocessor schedulers on the SDF subgraph clusters, for this example, we are able to obtain a single appearance schedule which leads to very compact code. A single appearance schedule is an SDF schedule in which each node only appears once <ref> [18] </ref>. To obtain the single appearance schedule, three uniprocessor schedulers and one multiprocessor scheduler were used by the hierarchical scheduling framework. By using the cluster hierarchy, the multiprocessor scheduler only had to schedule a DAG with 8 nodes. The multiprocessor schedule generated from the fully schematic.
Reference: [19] <author> R. Tarjan, </author> <title> Depth-first search and linear graph algorithms, </title> <journal> SIAM Journal on Computing, </journal> <volume> vol. 1, no. 2, </volume> <pages> p. 146-160, </pages> <year> 1972. </year>
Reference: [20] <author> J.L. Pino, T.M. Parks, and E.A. Lee, </author> <title> Automatic code generation for heterogeneous multiprocessors, </title> <booktitle> IEEE International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <volume> vol. </volume> <pages> 2, </pages> <address> 34 Adelaide, South Australia, 1994, p. </address> <pages> 445-448. </pages>
Reference-contexts: This clustering technique empowers the user with fundamental scheduling decisions. A potential problem is that the user can introduce artificial deadlock. However, this error is easily caught at compile time <ref> [20] </ref>. We have implemented this technique in Ptolemy, where it has enabled the development of multiprocessor applications that have previously been impossible to synthesize using other SDF multiprocessing techniques. When we automatically cluster subgraphs, we must ensure that the constructed clusters do not introduce artificial deadlock.
Reference: [21] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest, </author> <title> Introduction to algorithms, </title> <address> New York: </address> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference: [22] <author> E.A. Lee and D.G. Messerschmitt, </author> <title> Digital communication, </title> <address> Boston: </address> <publisher> Kluwer Academic Publishers, </publisher> <year> 1994. </year>
Reference-contexts: Finally, there was vir tually no penalty for doing hierarchical scheduling, as can be seen in the makespans of the final multiprocessor schedules. 9. Acoustical modem example In this section we detail a 320 bps quadrature amplitude modulation (4-QAM) acoustical modem <ref> [22] </ref> that is scheduled onto two heterogeneous processors (RISC, DSP). The SDF specifi cation is shown in figure 17. A pseudo-random bit stream is generated on the workstation and then packed into a DSP word stream (22 bits/word).
Reference: [23] <author> E. A. Lee, </author> <title> A coupled hardware and software architecture for programmable digital signal processors, </title> <type> Ph. D. thesis, </type> <institution> Dept. of Electrical Engineering and Computer Sciences, University of California at Berkeley, </institution> <month> May, </month> <year> 1986. </year>
Reference: [24] <author> J.L. Pino, T.M. Parks, and E.A. Lee, </author> <title> Mapping multiple independent synchronous dataow graphs onto heterogeneous multiprocessors, </title> <booktitle> IEEE Asilomar Conference on Signals, Systems, and Computers, </booktitle> <address> Pacific Grove, CA, </address> <year> 1994. </year>
Reference-contexts: The received symbols are then decoded, packed and sent back to the workstation, where the errors are dis played to the user. The user can control the alignment of the symbol period and examine the resultant constellation and eye diagram using the peek/poke mechanism described in <ref> [24] </ref>.
Reference: [25] <author> S. S. Bhattacharyya and E. A. Lee, </author> <title> Scheduling synchronous dataow graphs for efficient looping, </title> <journal> Journal of VLSI Signal Processing, </journal> <month> December </month> <year> 1993. </year>
Reference: [26] <author> J. T. Buck, </author> <title> Scheduling dynamic dataow graphs with bounded memory using the token ow model, </title> <type> Ph.D. thesis, </type> <note> Memorandum UCB/ERL M93/69, </note> <month> September, </month> <year> 1993. </year>
Reference: [27] <author> S. </author> <title> How, Code generation for multirate DSP systems in Gabriel, </title> <institution> Memorandum UCB/ERL M94/82, Electronics Research Laboratory, University of California at Berkeley, </institution> <month> October, </month> <year> 1994. </year>
Reference: [28] <author> S. S. Bhattacharyya, P. K. Murthy, and E. A. Lee, </author> <title> Two complementary heuristics for translating graphical DSP programs into minimum memory implementations, </title> <institution> Memorandum UCB/ERL M95/3, Electronics Research Laboratory, University of California at Berkeley, </institution> <month> January, </month> <year> 1995. </year>
Reference: [29] <author> S. Ritz, M. Pankert, and H. Meyr, </author> <title> Optimum vectorization of scalable synchronous dataow graphs, </title> <booktitle> Proceedings of the International Conference on Application-Specific Array Processors, </booktitle> <address> Venice, </address> <month> October, </month> <year> 1993. </year>
Reference: [30] <author> R. M. Karp and R. E. Miller, </author> <title> Properties of a model for parallel computations: determinacy, termination and queuing, </title> <journal> SIAM Journal on Applied Mathematics, </journal> <volume> vol. 14, no. 6, </volume> <pages> p. 1390-1411, </pages> <month> November, </month> <year> 1966. </year>
Reference: [31] <author> G. Bilsen, M. Engels, R. Lauwereins, and J. A. Peperstraete, </author> <title> Cyclo-static data ow, </title> <booktitle> Proceeding of the International Conference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Detroit, </address> <month> May, </month> <year> 1995. </year>
References-found: 31

