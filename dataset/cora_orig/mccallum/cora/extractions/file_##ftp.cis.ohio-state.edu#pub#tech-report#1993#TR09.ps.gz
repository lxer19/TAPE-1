URL: file://ftp.cis.ohio-state.edu/pub/tech-report/1993/TR09.ps.gz
Refering-URL: ftp://ftp.cis.ohio-state.edu/pub/tech-report/TRList.html
Root-URL: 
Email: Email: -grichard, singhal-@cis.ohio-state.edu  
Title: Using Logging and Asynchronous Checkpointing to Implement Recoverable Distributed Shared Memory  
Author: Golden G. Richard III Mukesh Singhal 
Address: Columbus, OH 43210  
Affiliation: Department of Computer and Information Science The Ohio State University  
Abstract: Distributed shared memory provides a useful paradigm for developing distributed applications. As the number of processors in the system and running time of distributed applications increase, the likelihood of processor failure increases. A method of recovering processes running in a distributed shared memory environment which minimizes lost work and the cost of recovery is desirable so that long-running applications are not adversely affected by processor failure. This paper presents a technique for achieving recoverable distributed shared memory which utilizes asynchronous process checkpoints and logging of pages accessed via read operations on the shared address space. The proposed scheme supports local process recovery without forcing rollback of operational processes during recovery. Our method is particularly useful in environments where taking process checkpoints is expensive (e.g., in some UNIXfi 1 environments). Keywords: Distributed shared memory, crash recovery, checkpointing, logging. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ahamad, P. W. Hutto, R. John, </author> <title> "Implementing and Programming Causal Distributed Shared Memory," </title> <booktitle> Proceedings of the 10th International Conference on Distributed Computing Systems , Paris, </booktitle> <month> June </month> <year> 1990, </year> <pages> pp. 274-281. </pages>
Reference-contexts: DSM with less restrictive memory coherence requirements is more efficient to implement and is likely to provide greater levels of concurrency, but with potentially greater effort for the programmer. Cheriton [ 3] and Ahamad et al. <ref> [ 1] </ref> discuss approaches to implementing DSM with relaxed coherence semantics. 3 A Technique for Recoverable DSM Our objective is to develop a technique which allows local process recovery in a DSM system.
Reference: [2] <author> B. Bhargava, S. R. Lian, </author> <title> "Checkpointing and Rollback Recovery in Distributed Systems - An Optimistic Approach", </title> <booktitle> Proceedings of the 7th Symposium on Reliable Distributed Systems , Columbus, </booktitle> <address> OH, pp.3-12, </address> <month> October </month> <year> 1988. </year>
Reference-contexts: When a process crashes and restarts, it initiates a recovery phase which involves all processes exchanging information about the extent of their respective logged states; processes then rollback and replay messages to achieve the maximum possible global consistent state. Bhargava and Lian <ref> [ 2] </ref> present a recovery technique which uses a two-phase rollback algorithm. It minimizes overhead during normal execution and is therefore appropriate for environments where failure is infrequent. In the worst case, processes may have 16 to roll back to the beginning of execution.
Reference: [3] <author> D. R. Cheriton, </author> <title> "Problem Oriented Shared Memory: A Decentralized Approach to Distributed System Design," </title> <booktitle> Proceedings of the 6th International Conference on Distributed Computing Systems , May 1986. </booktitle>
Reference-contexts: This choice provides a programmer designing an application for a DSM system with the familiar coherence semantics of uniprocessors. DSM with less restrictive memory coherence requirements is more efficient to implement and is likely to provide greater levels of concurrency, but with potentially greater effort for the programmer. Cheriton <ref> [ 3] </ref> and Ahamad et al. [ 1] discuss approaches to implementing DSM with relaxed coherence semantics. 3 A Technique for Recoverable DSM Our objective is to develop a technique which allows local process recovery in a DSM system.
Reference: [4] <author> D. B. Johnson, W. Zwaenpoel, </author> <title> "Recovery in Distributed Systems Using Optimistic Message Logging and Checkpointing," </title> <journal> Journal of Algorithms, </journal> <volume> No. 11, </volume> <pages> pp. 462-491, </pages> <year> 1990. </year>
Reference-contexts: Having operational processes roll back and coordinate to achieve a consistent global state in a DSM system also complicates the management of page ownership information, since ownership of pages changes dynamically as the entire system progresses. Johnson and Zwaenpoel <ref> [ 4] </ref> present an optimistic message logging and checkpointing method for message-passing systems based on a central server which monitors the logging progress of the system and advances the global recovery state as processes log messages to stable storage.
Reference: [5] <author> T. Y. Juang, S. Venkatesan, </author> <title> "Crash Recovery With Little Overhead," </title> <booktitle> IEEE 11th International Conference on Distributed Computing Systems, </booktitle> <year> 1991. </year>
Reference-contexts: In the worst case, processes may have 16 to roll back to the beginning of execution. Strom and Yemini [ 12] present a technique based on optimistic message logging, rollback, and message replay which tolerates failure of an arbitrary number of processors. Juang and Venkatesan <ref> [ 5] </ref> describe methods for recovering processes which attach very little (or no) additional information to each application message. Establishment of a consistent global state is accomplished via a coordinated effort at recovery time.
Reference: [6] <author> K. Li, </author> <title> "Shared Virtual Memory on Loosely Coupled Multiprocessors," </title> <type> Ph.D. dissertation, Technical Report YALEU/DCS/RR-492, </type> <month> September </month> <year> 1986. </year>
Reference-contexts: 1 Introduction Traditionally programs running on a distributed system are structured as processes executing on physically distinct processors, with communication being accomplished by exchanging messages. Distributed shared memory <ref> [6] </ref> provides an attractive alternative with several benefits. <p> applications written for environments with a physically shared memory (such as tightly-coupled multiprocessors), the ability to easily share complex data structures among processes running on distinct processors, the presence of a very large virtual address space, and ease in performing process migration, whether for purposes of recovery or load balancing <ref> [6] </ref>. In a distributed shared memory (DSM) system, the shared address space is implemented in software, unlike the physically shared memory in tightly-coupled multiprocessors. <p> The proposed technique is incorporated into the protocol for maintaining memory coherence and is related to the Dynamic Distributed Manager algorithm presented in <ref> [ 6] </ref>. The unit of sharing is a page 1 . 4 Multiple concurrent readers (with no writers) for a page are allowed, but only a single writer (with no read-ers) is allowed. Pages and ownership information are distributed over the processors in the system. No central coordinator is assumed.
Reference: [7] <author> F. Mattern, </author> <title> "Virtual Time and Global States of Distributed Systems," Parallel and Distributed Algorithms, </title> <publisher> North-Holland, </publisher> <year> 1989, </year> <pages> pp. 215-226. </pages>
Reference-contexts: Each process i running on the processor maintains the data illustrated in Figure 4. TSi is a vector clock <ref> [7] </ref> for process i. A vector clock is an array of integers, one integer for each process in the system. The vector clock at process i ticks by incrementing the entry corresponding to process i whenever a shared memory access is performed by i.
Reference: [8] <author> B. Nitzberg, V. Lo, </author> <title> "Distributed Shared Memory: A Survey of Issues and Algorithms," </title> <booktitle> IEEE Computer, </booktitle> <month> August </month> <year> 1991. </year>
Reference-contexts: The memory coherence semantics for an implementation of DSM dictate how "current" shared pages read by a process must be. A number of choices for memory coherence semantics have been proposed, including strict, sequential, processor, weak, and release consistency <ref> [8] </ref>. We focus on strict consistency, which insures that the copy of a page p read by a process contains the most recently written value. This choice provides a programmer designing an application for a DSM system with the familiar coherence semantics of uniprocessors.
Reference: [9] <author> R. D. Schlichting, F. B. Schneider, </author> <title> "Fail-stop Processors: An Approach to Designing Fault-tolerant Computing Systems," </title> <journal> ACM Transactions on Computer Systems , vol. </journal> <volume> 1, no. 3, </volume> <pages> pp. 222-238, </pages> <month> August </month> <year> 1982. </year>
Reference-contexts: The local area network is assumed to provide fault-free communication, via FIFO channels, between the processors. Disk storage is assumed to be reliable. File servers must not remain down indefinitely after a crash and must resume fault-free operation after restoration. Processors are assumed to be failstop <ref> [ 9] </ref>; that is, they stop functioning without generating spurious or incorrect messages.
Reference: [10] <author> A. P. Sistla, J. L. Welch, </author> <title> "Efficient Distributed Recovery Using Message Logging," </title> <booktitle> Proceedings of the 8th Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1989. </year>
Reference-contexts: In either case, a crash of the processor previously executing i would not result in i being recovered and recreating the modifications. 4 Related Work Recovery in Message-passing Systems Sistla and Welch <ref> [ 10] </ref> present algorithms for processes recovery in a message-passing environment. When a process crashes and restarts, it initiates a recovery phase which involves all processes exchanging information about the extent of their respective logged states; processes then rollback and replay messages to achieve the maximum possible global consistent state.
Reference: [11] <author> S. H. Son, A. K. Agrawala, </author> <title> "Distributed Checkpointing for Globally Consistent States of Databases," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 15, no. 10, </volume> <month> October </month> <year> 1989. </year>
Reference-contexts: In the context of recovery in DSM systems, we are more interested in exploring fully-distributed approaches, to avoid the possible bottleneck that the central server introduces. Son and Agrawala <ref> [ 11] </ref> introduce a synchronous checkpointing technique for distributed database systems which allows (most) transactions to begin or continue execution even while a checkpointing operation is in progress.
Reference: [12] <author> R. E. Strom, S. Yemini, </author> <title> "Optimistic Recovery in Distributed Systems," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 3, no. 3, pp.204-226, </volume> <month> August </month> <year> 1985. </year>
Reference-contexts: It minimizes overhead during normal execution and is therefore appropriate for environments where failure is infrequent. In the worst case, processes may have 16 to roll back to the beginning of execution. Strom and Yemini <ref> [ 12] </ref> present a technique based on optimistic message logging, rollback, and message replay which tolerates failure of an arbitrary number of processors. Juang and Venkatesan [ 5] describe methods for recovering processes which attach very little (or no) additional information to each application message.
Reference: [13] <author> M. Stumm, S. Zhou, </author> <title> "Fault Tolerant Distributed Shared Memory Algorithms," </title> <booktitle> Proceedings of the 2nd Symposium on Parallel and Distributed Processing,, </booktitle> <pages> pp. 719-724, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: The twin-page disk mechanism allows incremental flushing of modified pages to disk. In some environments, taking process checkpoints frequently can result in a significant overhead and it is in these environments that our proposed technique provides an attractive alternative. 17 Fault Tolerance for DSM Stumm and Zhou <ref> [ 13] </ref> examine methods for making the centralserver, full-replication, migration, and read-replication algorithms single-fault tolerant in the absence of a shared disk.
Reference: [14] <author> M. Stumm, S. Zhou, </author> <title> "Algorithms Implementing Distributed Shared Memory," </title> <booktitle> IEEE Computer, </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: The address space is physically distributed over the processors in the system and the software layer implementing DSM provides a shared 1 UNIX is a trademark of Novell, Inc. 1 memory abstraction by transferring pages between processors as needed. Stumm and Zhou <ref> [ 14] </ref> examine four algorithms for implementing DSM: The centralserver algorithm utilizes a central server which controls all access to the DSM. The full-replication algorithm assumes that the shared data is replicated on all processors and updates are applied to all copies.
Reference: [15] <author> V. Tam, M. Hsu, </author> <title> "Fast Recovery in Distributed Shared Virtual Memory Systems," </title> <booktitle> IEEE 10th Inter--national Conference on Distributed Computing Systems, </booktitle> <year> 1990. </year>
Reference-contexts: This method has the benefit of not requiring shared stable storage, but at a potentially high communication cost, which must be paid all at once. Page Table Recovery Tam and Hsu <ref> [15] </ref> present a technique for fast recovery of the volatile page ownership information which is usually lost when a processor fails.
Reference: [16] <author> R. H. Thomas, </author> <title> "A Majority Consensus Approach to Concurrency Control for Multiple Copy Databases," </title> <journal> ACM Transactions on Database Systems, </journal> <pages> pp. 180-209, </pages> <month> June </month> <year> 1979. </year>
Reference-contexts: When a process performs a write operation during recovery, it compares its vector clock to the timestamp on the page to be modified. If the timestamp on the page is more recent than the process' vector clock value, then the write is not performed ("Thomas Write Rule" <ref> [ 16] </ref>). This prevents a process from overwriting a more current copy of p (and thereby prevents introduction of stale data which might persist even after recovery is complete).
Reference: [17] <author> K. Wu, W. Fuchs, </author> <title> "Recoverable Distributed Shared Virtual Memory," </title> <journal> IEEE Transactions on Computers, </journal> <volume> vol. 39, no. 4, </volume> <month> April </month> <year> 1990. </year> <month> 20 </month>
Reference-contexts: This capability is particularly important in systems which must be fault-tolerant but cannot afford the significant transaction-processing delays introduced by some checkpointing mechanisms. Process Recovery Under DSM Wu and Fuchs <ref> [ 17] </ref> present a checkpointing and recovery scheme for DSM which uses process checkpoints and a twin-page disk storage technique.
References-found: 17

