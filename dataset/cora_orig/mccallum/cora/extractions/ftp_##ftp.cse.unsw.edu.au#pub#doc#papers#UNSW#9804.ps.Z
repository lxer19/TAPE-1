URL: ftp://ftp.cse.unsw.edu.au/pub/doc/papers/UNSW/9804.ps.Z
Refering-URL: http://www.cse.unsw.edu.au/school/research/tr.html
Root-URL: http://www.cse.unsw.edu.au
Email: fkevine,gernotg@cse.unsw.edu.au  jochen@us.ibm.com  
Title: Page Tables for 64-Bit Computer Systems  
Author: Kevin Elphinstone, Gernot Heiser Jochen Liedtke 
Date: August 1998  
Web: http://www.cse.unsw.edu.au/ disy  
Address: Sydney 2052, Australia  30 Saw Mill River Road, Hawthorne, NY 10532, USA  Sydney 2052, Australia  
Affiliation: School of Computer Science and Engineering The University of New South Wales  IBM T. J. Watson Research Center  School of Computer Science and Engineering The University of New South Wales  
Pubnum: UNSW-CSE-TR-9804  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Richard Rashid, Avadis Tevanian, Jr., Michael Young, David Golub, Robert Baron, David Black, William J. Bolosky, and Jonathan Chew. </author> <title> Machine-independent virtual memory management for paged uniprocessor and multiprocessor architectures. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-37:896908, </volume> <year> 1988. </year>
Reference-contexts: This is a reflection of the fact that to date no single page table structure has been shown to provide the best performance in all relevant circumstances. At the same time, address-space usage by operating systems is changing. In particular, kernelised systems, such as those based on Mach <ref> [1] </ref>, make heavy use of virtual memory mappings in order to transfer data efficiently between different address spaces. This leads to sparsely populated address spaces, in contrast to the traditional two-segment model typical for UNIX systems.
Reference: [2] <author> Charles Lamb, Gordon Landis, Jack Orenstein, and Dan Weinreb. </author> <title> The ObjectStore database system. </title> <journal> Communications of the ACM, </journal> <volume> 34(10):5163, </volume> <month> October </month> <year> 1991. </year>
Reference-contexts: This leads to sparsely populated address spaces, in contrast to the traditional two-segment model typical for UNIX systems. Sparse address space use is also typical for some other client-server based systems, such as object-oriented databases <ref> [2] </ref>, or for single-address-space systems [35]. In order to get good performance out of such systems, it is important to use page tables which support efficiently the operations these kernels require. In this paper we examine these issues in detail.
Reference: [3] <author> Kevin Murray, Ashley Saulsbury, Tom Stiemerling, Tim Wilkinson, Paul Kelly, and Peter Os-mon. </author> <title> Design and implementation of an object-orientated 64-bit single address space microker-nel. </title> <booktitle> In Proceedings of the 2nd USENIX Workshop on Microkernels and other Kernel Architectures, </booktitle> <pages> pages 3143, </pages> <month> September </month> <year> 1993. </year>
Reference: [4] <author> Jeffrey S. Chase, Henry M. Levy, Michael J. Feeley, and Edward D. Lazowska. </author> <title> Sharing and protection in a single-address-space operating system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12:271307, </volume> <month> November </month> <year> 1994. </year>
Reference: [5] <author> Gernot Heiser, Kevin Elphinstone, Jerry Vochteloo, Stephen Russell, and Jochen Liedtke. </author> <title> The Mungi single-address-space operating system. </title> <journal> Software: Practice and Experience, </journal> <volume> 28(9):901 928, </volume> <month> August </month> <year> 1998. </year>
Reference: [6] <author> Integrated Device Technology. </author> <title> IDT79R4600 and IDT79R4700 RISC Processor Hardware User's Manual, </title> <month> April </month> <year> 1995. </year>
Reference-contexts: In order to get good performance out of such systems, it is important to use page tables which support efficiently the operations these kernels require. In this paper we examine these issues in detail. We use a representative architecture, the MIPS R4x00 family <ref> [6] </ref>, and our own implementation of the L4 microkernel [7,8] as a testbed. L4 is presently the fastest kernel available [9]; its low intrinsic overhead makes it particularly sensitive to page-table performance, and therefore an ideal target for such an investigation. <p> order to investigate the performance implications of these page table structures, we have performed a number of experiments, running a set of benchmarks on an instrumented -kernel. 3.1 Test bed As mentioned earlier, we use for our experiments the L4 -kernel [7, 8] running on a 100MHz MIPS R4700 processor <ref> [6] </ref>. The R4700 has a tagged, software-loaded TLB with 48 entries, each entry mapping a pair of contiguous virtual pages of 4kb each. The processor supports a 40-bit address space. However, we designed our page tables to work with full 64-bit addresses.
Reference: [7] <author> Jochen Liedtke. </author> <booktitle> On -kernel construction. In Proceedings of the 15th ACM Symposium on OS Principles, </booktitle> <pages> pages 237250, </pages> <address> Copper Mountain, CO, USA, </address> <month> December </month> <year> 1995. </year> <month> 17 </month>
Reference-contexts: tear-down cost and context switching overhead. 3 Methodology In order to investigate the performance implications of these page table structures, we have performed a number of experiments, running a set of benchmarks on an instrumented -kernel. 3.1 Test bed As mentioned earlier, we use for our experiments the L4 -kernel <ref> [7, 8] </ref> running on a 100MHz MIPS R4700 processor [6]. The R4700 has a tagged, software-loaded TLB with 48 entries, each entry mapping a pair of contiguous virtual pages of 4kb each. The processor supports a 40-bit address space.
Reference: [8] <author> Kevin Elphinstone, Gernot Heiser, and Jochen Liedtke. </author> <title> L4 Reference Manual MIPS R4x00. </title> <institution> School of Computer Science and Engineering, University of NSW, </institution> <address> Sydney 2052, Australia, </address> <month> December </month> <year> 1997. </year> <note> UNSW-CSE-TR-9709. Latest version available from http://www/cse/unsw.edu.au/ disy/. </note>
Reference-contexts: tear-down cost and context switching overhead. 3 Methodology In order to investigate the performance implications of these page table structures, we have performed a number of experiments, running a set of benchmarks on an instrumented -kernel. 3.1 Test bed As mentioned earlier, we use for our experiments the L4 -kernel <ref> [7, 8] </ref> running on a 100MHz MIPS R4700 processor [6]. The R4700 has a tagged, software-loaded TLB with 48 entries, each entry mapping a pair of contiguous virtual pages of 4kb each. The processor supports a 40-bit address space.
Reference: [9] <author> Jochen Liedtke, Kevin Elphinstone, Sebastian Sch onberg, Herrman Hartig, Gernot Heiser, Nay-eem Islam, and Trent Jaeger. </author> <title> Achieved IPC performance (still the foundation for efficiency). </title> <booktitle> In Proceedings of the 6th Workshop on Hot Topics in Operating Systems (HotOS), </booktitle> <pages> pages 2831, </pages> <address> Cape Cod, MA, USA, </address> <month> May </month> <year> 1997. </year> <note> IEEE. </note>
Reference-contexts: In this paper we examine these issues in detail. We use a representative architecture, the MIPS R4x00 family [6], and our own implementation of the L4 microkernel [7,8] as a testbed. L4 is presently the fastest kernel available <ref> [9] </ref>; its low intrinsic overhead makes it particularly sensitive to page-table performance, and therefore an ideal target for such an investigation. <p> The processor supports a 40-bit address space. However, we designed our page tables to work with full 64-bit addresses. L4 is known for low system-call overhead and efficient IPC. The MIPS version takes &lt;60 cycles to perform a null system call and &lt;100 cycles for a null IPC <ref> [9] </ref>. We created several versions of the kernel, each using a different page table structure. For the study of absolute TLB miss handling costs, each TLB refill hander was carefully instrumented.
Reference: [10] <author> Jerry Huck and Jim Hays. </author> <title> Architectural support for translation table management in large address space machines. </title> <booktitle> In Proceedings of the 20th International Symposium on Computer Architecture, </booktitle> <pages> pages 3950. </pages> <publisher> ACM, </publisher> <year> 1993. </year>
Reference-contexts: microkernels, which are supposed to present a platform on top of which a variety of different systems, traditional as well as novel, can be implemented. 2 Page Tables for 64-Bit Architectures In this section we give a brief description of various page table structures in use, for more details see <ref> [10] </ref>. 2.1 Linear and multi-level page tables In most 32-bit systems forward-mapped page tables are used, which consist of page table entries (PTEs) containing physical frame numbers and which are sorted by virtual page number.
Reference: [11] <author> Douglas W. Clark and Joel S. Emer. </author> <title> Performance of the VAX-11/780 translation buffer: Simulation and measurement. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3:3162, </volume> <year> 1985. </year>
Reference-contexts: However, if the appropriate page table page is not mapped, a secondary fault is generated. In 32-bit systems the mapping for any page of the page table can be 3 obtained from the root page which is held in unmapped memory. This approach has been used in the VAX <ref> [11] </ref>. For larger address spaces, multiple misses can occur, up to six cascaded faults for 64-bits. This is unavoidable, as it is infeasible to hold the complete LPT in physical memory.
Reference: [12] <author> John Cocke. </author> <title> Virtual to real address translation using hashing. </title> <journal> IBM Technical Disclosure Bulletin, </journal> <volume> 24(6), </volume> <month> November </month> <year> 1981. </year>
Reference-contexts: While both data structures work well in 32-bit address spaces, good performance in wide address spaces can only be expected as long as address space usage is compact. 2.2 Hashed page tables Large-address-space architectures generally use page tables based on the idea of an inverted page table (IPT) <ref> [12, 13] </ref>, which is a table sorted by frame numbers containing virtual page numbers. The index is obtained from a hash table. The more popular version combines the two tables, resulting in a table containing both, the virtual page number and the frame number [14].
Reference: [13] <author> Albert Chang and Mark F. Mergen. </author> <title> 801 Storage: Architecture and programming. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6:2850, </volume> <year> 1988. </year>
Reference-contexts: While both data structures work well in 32-bit address spaces, good performance in wide address spaces can only be expected as long as address space usage is compact. 2.2 Hashed page tables Large-address-space architectures generally use page tables based on the idea of an inverted page table (IPT) <ref> [12, 13] </ref>, which is a table sorted by frame numbers containing virtual page numbers. The index is obtained from a hash table. The more popular version combines the two tables, resulting in a table containing both, the virtual page number and the frame number [14].
Reference: [14] <author> John Rosenberg and David Abramson. </author> <title> MONADS-PCa capability-based workstation to support software engineering. </title> <booktitle> In Proceedings of the 18th Hawaii International Conference on System Sciences, </booktitle> <volume> volume 1, </volume> <pages> pages 22231. </pages> <publisher> IEEE, </publisher> <year> 1985. </year>
Reference-contexts: The index is obtained from a hash table. The more popular version combines the two tables, resulting in a table containing both, the virtual page number and the frame number <ref> [14] </ref>. It is indexed by some easily computable hash of the page number. Some data structure, usually a linear list, is used for resolving collisions. This structure is called a hashed page table (HPT). Clustered page tables (CPTs) are a variant of HPTs designed to reduce space needs [15].
Reference: [15] <author> Madhusudha Talluri, Mark D. Hill, and Yousef A. Khalid. </author> <title> A new page table for 64-bit address spaces. </title> <booktitle> In Proceedings of the 15th ACM Symposium on OS Principles, </booktitle> <pages> pages 184200, </pages> <address> Copper Mountain Resort, Co, USA, </address> <month> December </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: It is indexed by some easily computable hash of the page number. Some data structure, usually a linear list, is used for resolving collisions. This structure is called a hashed page table (HPT). Clustered page tables (CPTs) are a variant of HPTs designed to reduce space needs <ref> [15] </ref>. They store mapping information for several consecutive pages with a single tag. 2.3 Guarded page tables The guarded page table (GPT) is a forward-mapped structure recently proposed by Liedtke [16, 17], specifically to deal with sparse memory usage in large address spaces.
Reference: [16] <author> Jochen Liedtke. </author> <title> A basis for huge fine-grained address spaces and user level mapping. </title> <booktitle> In Proceedings of the 7th European Conference on Object Oriented Programming (ECOOP) Workshop on Granularity of Objects in Distributed Systems (GODS'93), </booktitle> <address> Kaiserslautern, Germany, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: Clustered page tables (CPTs) are a variant of HPTs designed to reduce space needs [15]. They store mapping information for several consecutive pages with a single tag. 2.3 Guarded page tables The guarded page table (GPT) is a forward-mapped structure recently proposed by Liedtke <ref> [16, 17] </ref>, specifically to deal with sparse memory usage in large address spaces. Sparsity is problematic in MPTs as it leads to page tables with very few (maybe only a single) valid mapping in intermediate nodes.
Reference: [17] <author> Jochen Liedtke. </author> <title> On the Realization Of Huge Sparsely-Occupied and Fine-Grained Address Spaces. </title> <publisher> Oldenbourg, </publisher> <address> Munich, Germany, </address> <year> 1996. </year>
Reference-contexts: Clustered page tables (CPTs) are a variant of HPTs designed to reduce space needs [15]. They store mapping information for several consecutive pages with a single tag. 2.3 Guarded page tables The guarded page table (GPT) is a forward-mapped structure recently proposed by Liedtke <ref> [16, 17] </ref>, specifically to deal with sparse memory usage in large address spaces. Sparsity is problematic in MPTs as it leads to page tables with very few (maybe only a single) valid mapping in intermediate nodes. <p> So far, practical experience with GPTs is very limited. Liedtke <ref> [17] </ref> published a number of theoretical results mostly concerned with the behaviour of GPTs under worst-case conditions. No results on GPT sizing under practical conditions have been published to date. For the purpose of comparing GPTs with other data structures we decided to use only GPTs of a fixed size.
Reference: [18] <author> Kavita Bala, M. Frans Kaashoek, and William E. Weihl. </author> <title> Software prefetching and caching for translation lookaside buffers. </title> <booktitle> In Proceedings of the 1st Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 243253, </pages> <address> Monterey, CA, USA, 1994. </address> <publisher> usenix. </publisher>
Reference-contexts: Multiple page size can also easily be supported. 2.4 Software TLB cache Instead of just using a page table for handling TLB misses, a software cache for TLB entries, called software TLB (STLB) or secondary TLB, can be used <ref> [18] </ref>. The TLB miss handler first attempts to load the missing entry from the STLB and only on a miss consults the proper page table. This can significantly speed up TLB miss handling when using forward-mapped page tables.
Reference: [19] <institution> Standard Performance Evaluation Corporation, Manassas, VA, USA. SPECint95 Benchmark/SPECfp95 Benchmark, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: All benchmarks were run in memory, i.e., there was no I/O activity during the runs. 3.3.1 Conventional benchmarks In order to examine the performance of traditional UNIX-like applications, we ran a subset of the SPEC95 benchmark <ref> [19] </ref>. The selected programs are characterised by high TLB miss handling overhead. In addition we used a number of other popular benchmarks from a collection maintained by Al Aburto [20]. Table 1 lists the benchmarks used. For simplicity we ran the gcc benchmark on a single input file only (1amptjp.i).
Reference: [20] <author> Al Aburto. </author> <title> Benchmark collection. </title> <address> URL ftp://ftp.nosc.mil/pub/aburto. </address>
Reference-contexts: The selected programs are characterised by high TLB miss handling overhead. In addition we used a number of other popular benchmarks from a collection maintained by Al Aburto <ref> [20] </ref>. Table 1 lists the benchmarks used. For simplicity we ran the gcc benchmark on a single input file only (1amptjp.i). Furthermore, we ran mm only using the normal algorithm, as the other algorithms do not exercise the TLB to any significant degree. All other benchmarks were run unmodified.
Reference: [21] <author> Kevin Elphinstone. </author> <title> Address space management issues in the Mungi operating system. </title> <type> Technical Report UNSW-CSE-TR-9312, </type> <institution> School of Computer Science and Engineering, University of NSW, </institution> <address> Sydney 2052, Australia, </address> <month> November </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: This is obviously a tough, and somewhat pathological benchmark, as the uniform distribution implies essentially no clustering of pages. The second benchmark, called file, allocates multi-page objects at uniformly distributed random addresses. The sizes of these objects are taken from a measured file system size distribution <ref> [21] </ref>. We expect this to be a more realistic model of sparse address-space usage in future 64-bit systems. 3.3.3 Tasking benchmarks Task creation and deletion costs were measured by executing the loop create task wait for IPC from child delete child 100 times.
Reference: [22] <author> Andrew W. Appel and Kai Li. </author> <title> Virtual memory primitives for user programs. </title> <booktitle> In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 96107, </pages> <year> 1991. </year>
Reference-contexts: The child does nothing but send a null IPC to the parent; it requires only a single page to run. 3.3.4 Mapping benchmarks Appel and Li <ref> [22] </ref> point out the importance of efficient virtual memory primitives. The primitive most relevant to this study is decreasing accessibility (unmapping or write protecting) of large regions of the address space (their PROTN operation). We implemented a version of Appel & Li's benchmark, using processes, client and server.
Reference: [23] <author> Richard Uhlig, David Nagle, Trevor Mudge, Stuart Sechrest, and Joel Emer. </author> <title> Instruction fetching: Coping with code bloat. </title> <booktitle> In Proceedings of the 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 34556, </pages> <address> Santa Margherita Ligure, Itay, </address> <month> June </month> <year> 1995. </year> <journal> ACM. </journal> <volume> 19 </volume>
Reference-contexts: In most cases, such a high hit rate will be accompanied by a high hit rate on user pages, in which case TLB miss handling costs are irrelevant. The cost of handling a secondary TLB miss is of the order of 400500 cycles <ref> [23] </ref>. 1 As it costs, in average, about 110 cycles to traverse the five upper levels of the MPT, this implies that the LPT would outperform the MPT when the TLB hit rate for page table accesses is about 80 % (higher if higher-level TLB misses occur).
References-found: 23

