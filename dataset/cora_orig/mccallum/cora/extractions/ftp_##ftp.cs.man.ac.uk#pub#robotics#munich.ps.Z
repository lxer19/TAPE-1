URL: ftp://ftp.cs.man.ac.uk/pub/robotics/munich.ps.Z
Refering-URL: http://www.cs.man.ac.uk/robotics/lopapers.html
Root-URL: 
Email: E-mail: ulrich@uk.ac.ed.edai  
Title: Location Recognition in a Mobile Robot Using Self-Organising Feature Maps 1  
Author: Ulrich Nehmzow, Tim Smithers and John Hallam 
Address: 5 Forrest Hill Edinburgh EH1 2QL Scotland  
Affiliation: Department of Artificial Intelligence University of Edinburgh  
Abstract: Self-organising structures are a dominant feature of the experimental mobile robots built in our "Really Useful Robots" project. This paper continues where [Nehmzow & Smithers 90] finished. It explains some initial experiments using self-organising feature maps, and how those maps can be used by a mobile robot to recognise locations in its environment. This location recognition capability is achieved without using sensory information. Instead information derived from the motor actions of the robot is used, and shown to be sufficient.
Abstract-found: 1
Intro-found: 1
Reference: [Allman 77] <author> John Allman, </author> <title> Evolution of the visual system in early primates, </title> <booktitle> Progress in Psychobiology and Physiological Psychology 7 pp.1-53, </booktitle> <year> 1977 </year>
Reference-contexts: primates) is organized in topographic fashion, each half of the visual field (of a macaque monkey) is projected onto the striate cortex in a systematic map [Hubel 79]. [Churchland 86] gives a good survey of topographic mappings in neural systems (for topographic mappings of the visual cortex see, for example, <ref> [Allman 77] </ref>). Similarly, somatotopic 3 maps can be found in the cortex. Very similar observations to those stated above can be made about such biological systems, ([Churchland 86]): * Map distortion is based on the population of neurons representing a particular body area.
Reference: [Canny 86] <author> John F. Canny, </author> <title> A Computational Approach to Edge Detection, </title> <journal> IEEE PAMI 8(6) pp. </journal> <pages> 679-698, </pages> <year> 1986 </year>
Reference-contexts: respects, the problem is similar to that encountered in the analysis of natural images in vision: the data is intrinsically multiscalar (though here it is temporal scale that is critical) and so must be subjected to a multiscalar analysis (for this analysis in images see [Marr & Hildreth 80] and <ref> [Canny 86] </ref>).
Reference: [Churchland 86] <author> Patricia Smith Churchland, </author> <title> Neurophilosophy, </title> <publisher> MIT Press Cam-bridge Mass. and London, </publisher> <address> England, </address> <year> 1986 </year>
Reference-contexts: The striate cortex, for example (one part of the visual system of primates) is organized in topographic fashion, each half of the visual field (of a macaque monkey) is projected onto the striate cortex in a systematic map [Hubel 79]. <ref> [Churchland 86] </ref> gives a good survey of topographic mappings in neural systems (for topographic mappings of the visual cortex see, for example, [Allman 77]). Similarly, somatotopic 3 maps can be found in the cortex. Very similar observations to those stated above can be made about such biological systems, ([Churchland 86]): *
Reference: [Clark et al. 88] <author> Sharon A. Clark, Terry Allard, William M. Jenkins and Michael M. Merzenich, </author> <title> Receptive fields in the body surface map in adult cortex defined by temporally correlated inputs, </title> <booktitle> Nature 332 31 pp. </booktitle> <pages> 444-445, </pages> <month> March </month> <year> 1988 </year>
Reference: [Hubel 79] <author> David H. </author> <title> Hubel,The visual cortex of normal and deprived monkeys, </title> <journal> American Scientist,67 No 5 pp. </journal> <pages> 532-543, </pages> <year> 1979 </year>
Reference-contexts: Topographic mappings such as these are common in biological nervous systems. The striate cortex, for example (one part of the visual system of primates) is organized in topographic fashion, each half of the visual field (of a macaque monkey) is projected onto the striate cortex in a systematic map <ref> [Hubel 79] </ref>. [Churchland 86] gives a good survey of topographic mappings in neural systems (for topographic mappings of the visual cortex see, for example, [Allman 77]). Similarly, somatotopic 3 maps can be found in the cortex.
Reference: [Kohonen 88] <author> Teuvo Kohonen, </author> <title> Self-Organization and Associative Memory, </title> <publisher> Springer Verlag Berlin, </publisher> <address> Heidelberg, New York, </address> <year> 1988 </year>
Reference-contexts: 1 Introduction Self-organising feature maps (SOFMs), <ref> [Kohonen 88] </ref>, can be used for simple navigation tasks. <p> The only information available to the network concerns motor action commands. 3 Early Experiments 3.1 Self-Organising Feature Maps The mathematics for the kind of self-organising feature maps (SOFMs) that we use can be found in <ref> [Kohonen 88] </ref> or in [Nehmzow & Smithers 90].
Reference: [Marr & Hildreth 80] <author> David C. Marr and Ellen C. Hildreth, </author> <title> Theory of Edge Detection, </title> <journal> Proc. R. Soc. </journal> <volume> London 207, </volume> <pages> pp. 187-217, </pages> <year> 1980 </year>
Reference-contexts: In some respects, the problem is similar to that encountered in the analysis of natural images in vision: the data is intrinsically multiscalar (though here it is temporal scale that is critical) and so must be subjected to a multiscalar analysis (for this analysis in images see <ref> [Marr & Hildreth 80] </ref> and [Canny 86]).
Reference: [Nehmzow & Smithers 90] <author> Ulrich Nehmzow and Tim Smithers, </author> <title> Mapbuilding using Self-Organising Networks, </title> <editor> in: Jean Arcady Meyer and Stewart Wilson (eds.), </editor> <booktitle> From Animals to Animats, Proceedings of SAB90 Paris, </booktitle> <pages> pp. 152-159, </pages> <publisher> MIT Press Cambridge Mass. and London, </publisher> <address> England, </address> <year> 1991 </year>
Reference-contexts: 1 Introduction Self-organising feature maps (SOFMs), [Kohonen 88], can be used for simple navigation tasks. In earlier work, <ref> [Nehmzow & Smithers 90] </ref>, we have shown that "Alder", the first of the "Really Useful Robots" (RUR) (see figure 1), is able to use a SOFM to recognize particular locations in a simple enclosure after it has had sufficient 1 Reprint from G. <p> The only information available to the network concerns motor action commands. 3 Early Experiments 3.1 Self-Organising Feature Maps The mathematics for the kind of self-organising feature maps (SOFMs) that we use can be found in [Kohonen 88] or in <ref> [Nehmzow & Smithers 90] </ref>. <p> This motivated our next experiments, in which different sized histories of actions were presented to separate SOFMs in parallel. 7 4 A SOFM Location Recognition System As in our earlier work on location recognition (see <ref> [Nehmzow & Smithers 90] </ref>), the method used is one in which location recognition is based upon the robot recognising its arrival at some location.
Reference: [Nehmzow et al. 89] <author> Ulrich Nehmzow, John Hallam and Tim Smithers, </author> <title> Really Useful Robots, </title> <editor> in: T. Kanade, F.C.A. Groen and L.O. Hertzberger (eds.), </editor> <booktitle> Intelligent Autonomous Systems, Proceedings of IAS 2, </booktitle> <pages> pp. 284-293, </pages> <address> ISBN 90-800410-1-7, Amsterdam 1989 13 </address>
Reference-contexts: For the same reason we aim to equip the robot with as little predefined knowledge about its environment as possible <ref> [Nehmzow et al. 89] </ref>. Information concerning landmarks is specialised information. Therefore, we decided to try to achieve similar results to those reported earlier, but this time using less specific input information. <p> For the location recognition experiments the robot is placed in an enclosure as shown in figure 2; it then follows the wall using a preprogrammed wall-following and obstacle-avoidance behaviour (alternatively these skills could be acquired by learning, see <ref> [Nehmzow et al. 89] </ref>). In other words, the robot is governed by its preprogrammed wall following behaviour which, of course, does use sensory information. <p> Whether tactile, ultrasonic, infrared or other sensors are used: the location recognition system stays the same. Second, with this approach the features to be identified by the SOFMs are spread out over time. This contrasts with our early work <ref> [Nehmzow et al. 89] </ref> in which the robot controller learns instantaneous reactions to sensor stimuli.
References-found: 9

