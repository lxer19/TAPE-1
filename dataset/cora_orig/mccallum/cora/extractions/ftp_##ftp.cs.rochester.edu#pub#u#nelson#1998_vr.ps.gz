URL: ftp://ftp.cs.rochester.edu/pub/u/nelson/1998_vr.ps.gz
Refering-URL: http://www.cs.rochester.edu/u/selinger/research.html
Root-URL: 
Email: (nelson, selinger)@cs.rochester.edu  
Title: Large-Scale tests of a Keyed, Appearance-Based 3-D Object Recognition System  
Author: Randal C. Nelson Andrea Selinger 
Keyword: Key Words: Object recognition, Appearance-based representations, Visual learning.  
Address: Rochester, NY 14627  
Affiliation: Department of Computer Science University of Rochester  
Abstract: We describe and analyze an appearance-based 3-D object recognition system that avoids some of the problems of previous appearance-based schemes. We describe various large-scale performance tests and report good performance for full-sphere/hemisphere recognition of up to 24 complex, curved objects, robustness against clutter and occlusion, and some intriguing generic recognition behavior. We also establish a protocol that permits performance in the presence of quantifiable amounts of clutter and occlusion to be predicted on the basis of simple score statistics derived from clean test images and pure clutter images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Nicholas Ayache and Olivier Faugeras. </author> <title> Hyper: a new approach for the recognition and positioning of two-dimensional objects. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 8(1) </volume> <pages> 44-54, </pages> <month> January </month> <year> 1986. </year>
Reference-contexts: substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) [29; 32; 2] but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) <ref> [34; 3; 1; 9] </ref>. However, these techniques are limited to a particular geometric schema, and even within their domain, especially with visual techniques, their performance is often unsatisfactory. Appearance-based object recognition methods have been proposed in order to make recognition systems more general, and more easily trainable from visual data.
Reference: [2] <author> Aaron F. Bobick and Robert C. Bolles. </author> <title> Representation space: An approach to the integration of visual information. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 492-499, </pages> <address> San Diego CA, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: There has been a substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) <ref> [29; 32; 2] </ref> but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) [34; 3; 1; 9].
Reference: [3] <author> Robert C. Bolles and R. A. Cain. </author> <title> Recognizing and localizing partially visible objects: The local-features-focus method. </title> <journal> International Journal of Robotics Research, </journal> <volume> 1(3):5782, </volume> <month> Fall </month> <year> 1982. </year>
Reference-contexts: substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) [29; 32; 2] but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) <ref> [34; 3; 1; 9] </ref>. However, these techniques are limited to a particular geometric schema, and even within their domain, especially with visual techniques, their performance is often unsatisfactory. Appearance-based object recognition methods have been proposed in order to make recognition systems more general, and more easily trainable from visual data.
Reference: [4] <author> R. Brunelli and Thomaso Poggio. </author> <title> Face recognition: Features versus templates. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 15(10) </volume> <pages> 1042-1062, </pages> <year> 1993. </year>
Reference-contexts: They have the advantage of being fairly general, and often easily trainable. In recent work, Poggio & Edelman (1990) [27] have recognized wire objects and Brunelli & Poggio (1993) <ref> [4] </ref> have recognized faces using appearance models. Rao & Ballard (1994) [28] describe an approach based on memorizing the responses of a set of steerable filters to images of objects. Mel (1994) [22] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues.
Reference: [5] <author> H. H. Bulthoff, S. Y. Edelman, and M. J. Tarr. </author> <title> How are three-dimensional objects represented in the brain? Cerebral Cortex, </title> <booktitle> 5(3) </booktitle> <pages> 247-260, </pages> <year> 1995. </year> <month> 29 </month>
Reference-contexts: More recent work, however, while confirming that people are indeed able to perform mental operations that seem most consistent with the existence of 3-D, object-centered representations, has raised questions about whether these representations are what is used for fast recognition (Bulthoff et al. 1995, Edelman & Bulthoff 1992) <ref> [5; 7] </ref>. It can be plausibly argued that the 3-D representations are used for example, for planning manipulations, while fast recognition uses a separate representation. The work most relevant to our approach is that of Bulthoff, Edelman & Tarr (1995) [5]. <p> It can be plausibly argued that the 3-D representations are used for example, for planning manipulations, while fast recognition uses a separate representation. The work most relevant to our approach is that of Bulthoff, Edelman & Tarr (1995) <ref> [5] </ref>. In their research they looked at the expected performance of several representations used in 3-D object recognition and compared it with the results obtained by psychophysical experiments.
Reference: [6] <author> Jin-Long Chen and George C. Stockman. </author> <title> Indexing to 3d model aspects using 2d contour features. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition (CVPR96, </booktitle> <pages> pages 913-920, </pages> <address> San Francisco CA, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Both Nayar's and Mohr's approaches carry out recognition tests only over a 1-dimensional range of views rather than over the full 2-D viewing sphere as we do in the tests on our model. In a slightly less image-like approach, Chen & Stockman (1996) <ref> [6] </ref> use contour features to index a 3-D model of local structure. This produces hypotheses that are then subject to global model verification. <p> On the other hand, Mohr's techniques probably perform better in the presence of clutter and occlusion since they work with many more, and much smaller features than we do. A third approach that has considerable similarity to ours is that of Chen and Stockman (1996) <ref> [6] </ref>. This method uses 2-D invariants of silhouette contour features to index a local (automatically derived) 3-D model. The method is tested on databases containing approximately 600 aspects. Both straight voting and Bayesian evidence combination are considered.
Reference: [7] <author> S. Edelman and H. H Bulthoff. </author> <title> Modeling human visual object recognition. </title> <booktitle> In International Joint Conference on Neural Networks (IJCNN92), </booktitle> <pages> pages 37-42, </pages> <address> Baltimore, MD, </address> <month> June 7-11 </month> <year> 1992. </year>
Reference-contexts: More recent work, however, while confirming that people are indeed able to perform mental operations that seem most consistent with the existence of 3-D, object-centered representations, has raised questions about whether these representations are what is used for fast recognition (Bulthoff et al. 1995, Edelman & Bulthoff 1992) <ref> [5; 7] </ref>. It can be plausibly argued that the 3-D representations are used for example, for planning manipulations, while fast recognition uses a separate representation. The work most relevant to our approach is that of Bulthoff, Edelman & Tarr (1995) [5]. <p> Their experiments showed that even in the case of human observers, generalization to novel views was severely limited, with performance dropping to chance levels at a misorientation of about 40 ffi relative to familiar views (Edelman & Bulthoff 1992) <ref> [7] </ref>. Also, in this human visual model, as in certain computational models, e.g. Edelman & Weinshall (1991) [8], views that "belong" together are more closely associated with each other. Computationally, this method of recognition is analogous to an attempt to express the input as an interpolation of the stored views.
Reference: [8] <author> S. Edelman and D. Weinshall. </author> <title> A self-organizing multiple-view representation of 3d objects. </title> <journal> Biological Cybernetics, </journal> <volume> 64 </volume> <pages> 209-219, </pages> <year> 1991. </year>
Reference-contexts: Also, in this human visual model, as in certain computational models, e.g. Edelman & Weinshall (1991) <ref> [8] </ref>, views that "belong" together are more closely associated with each other. Computationally, this method of recognition is analogous to an attempt to express the input as an interpolation of the stored views.
Reference: [9] <author> F.Stein and Gerard Medioni. </author> <title> Efficient 2-dimensional object recgnition. </title> <booktitle> In Proc. ICPR, </booktitle> <pages> pages 13-17, </pages> <address> Atlantic City NJ, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) [29; 32; 2] but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) <ref> [34; 3; 1; 9] </ref>. However, these techniques are limited to a particular geometric schema, and even within their domain, especially with visual techniques, their performance is often unsatisfactory. Appearance-based object recognition methods have been proposed in order to make recognition systems more general, and more easily trainable from visual data.
Reference: [10] <author> W. E. </author> <title> L Grimson. Object Recognition by Computer: The role of geometric constraints. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, </address> <year> 1990. </year>
Reference-contexts: Until recently, the most successful computational work on object recognition has used model-based approaches in which the image is matched against explicitly represented 3-D geometric models. Notable recent examples are Lowe (1987), Lamdan & Wolfson (1988), Huttenlocher & Ullman (1990), and Grimson (1990) <ref> [21; 19; 17; 10] </ref>. The 3-D geometric models on which these systems are based are both their strength and their weakness.
Reference: [11] <author> W. E. L. Grimson and Danial P. Huttenlocher. </author> <title> On the sensitivity of the hough transform for object recognition. </title> <journal> IEEE PAMI, </journal> <volume> 12(3) </volume> <pages> 255-274, </pages> <year> 1990. </year>
Reference-contexts: Analyses of fl Support for this work was provided by ONR grant N00014-93-I-0221, and NSF IIP Grant CDA-94-01142 1 the performance of some of these schemes is given by Grimson & Huttenlocher (1990a,b) <ref> [12; 11] </ref>.
Reference: [12] <author> W. E. L. Grimson and Daniel P. Huttenlocher. </author> <title> On the sensitivity of geometric hashing. </title> <booktitle> In 3rd International Conference on Computer Vision, </booktitle> <pages> pages 334-338, </pages> <year> 1990. </year>
Reference-contexts: Analyses of fl Support for this work was provided by ONR grant N00014-93-I-0221, and NSF IIP Grant CDA-94-01142 1 the performance of some of these schemes is given by Grimson & Huttenlocher (1990a,b) <ref> [12; 11] </ref>.
Reference: [13] <author> C. G. Gross. </author> <title> Representation of visual stimuli in the inferior temporal cortex. </title> <journal> Philosophical Transaction of the Royal Society of London B, </journal> <volume> 335 </volume> <pages> 3-10, </pages> <year> 1992. </year>
Reference-contexts: results on the existence of object specific cortical cells in monkeys and other animals, specifically on cells that seem to be selective for particular views of faces are intriguing, but still too preliminary to say much about the underlying implementation (Oram & Perret 1994, Perret & Oram 1993, Gross 1992) <ref> [25; 26; 13] </ref>. On the other hand, there is a body of psychophysical work that is relevant to the question.
Reference: [14] <author> P. Havalder, G. Medioni, and F. Stein. </author> <title> Percetual grouping for generic recognition. </title> <journal> Internation Journal of Computer Vision, </journal> <volume> 20(1-2):59-80, </volume> <month> October </month> <year> 1996. </year>
Reference-contexts: The solution is not to use arbitrary combinations, but to base the higher level feature groups on structural heuristics such as spatial adjacency and good continuation. Such perceptual grouping processes have been extensively researched in the last few years (Kubovy 1997, Havalder et al. 1996, Lowe 1986) <ref> [18; 14; 20] </ref>. Our keyed local contexts can be viewed as an example of perceptual grouping. The use of pose-insensitive, but not truly invariant features represents another necessary compromise. From a computational standpoint, true invariance is desirable, and a lot of research has gone into looking for invariant features.
Reference: [15] <author> Chien-Yuan Huang and Octavia I. </author> <title> Camps. Object recognition using appearance-based parts and relations. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition (CVPR97), </booktitle> <pages> pages 877-883, </pages> <address> San Juan, Puerto Rico, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: Murase & Nayar (1993) [23] find the major principal components of an image dataset, and use the projections of unknown images onto these as indices into a recognition memory. Huang & Camps (1997) <ref> [15] </ref> have recently adapted this approach to segmented image regions, thus obtaining some tolerance to clutter and occlusion. <p> On the other hand, the eigenspace techniques are much faster than ours, operating in a fraction of a second, whereas we take several seconds. Huang & Camps (1997) <ref> [15] </ref> recently modified the eigenspace approach to use regions extracted using a minimum description length (MDL) segmentation algorithm, and demonstrated some robustness to clutter and occlusion in find-object tasks, again using just a single azimuth circle.
Reference: [16] <author> Daniel P. Huttenlocher and Liana M. Loriga. </author> <title> Recognizing three-dimensional objects by comparing two-dimensional images. </title> <booktitle> In IEEE Conferens on Computer Vision and Pattern Recognition (CVPR96), </booktitle> <pages> pages 878-884, </pages> <address> San Francisco, CA, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Since the mean rank of the correct hypothesis is typically around 20 (in the best version), much of the power of the technique derives from the 3-D verification step. Another feature-based example is a recent generalization of the alignment method by Huttonlocher & Lorigo (1996) <ref> [16] </ref> which finds consistent point matches via linear combination of model feature images.
Reference: [17] <author> Daniel P. Huttenlocher and Shimon Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: Until recently, the most successful computational work on object recognition has used model-based approaches in which the image is matched against explicitly represented 3-D geometric models. Notable recent examples are Lowe (1987), Lamdan & Wolfson (1988), Huttenlocher & Ullman (1990), and Grimson (1990) <ref> [21; 19; 17; 10] </ref>. The 3-D geometric models on which these systems are based are both their strength and their weakness.
Reference: [18] <author> M. Kubovy. </author> <title> Gestalt laws of grouping revisited and quantified. </title> <booktitle> In Proc. SPIE Conference on Human Vision and Electronic Imaging, </booktitle> <pages> pages 402-408, </pages> <address> San Jose, CA, </address> <month> February </month> <year> 1997. </year>
Reference-contexts: The solution is not to use arbitrary combinations, but to base the higher level feature groups on structural heuristics such as spatial adjacency and good continuation. Such perceptual grouping processes have been extensively researched in the last few years (Kubovy 1997, Havalder et al. 1996, Lowe 1986) <ref> [18; 14; 20] </ref>. Our keyed local contexts can be viewed as an example of perceptual grouping. The use of pose-insensitive, but not truly invariant features represents another necessary compromise. From a computational standpoint, true invariance is desirable, and a lot of research has gone into looking for invariant features.
Reference: [19] <author> Y. Lamdan and H. J. Wolfson. </author> <title> Geometric hashing: A general and efficient model-based recognition scheme. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 238249, </pages> <address> Tampa FL, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: Until recently, the most successful computational work on object recognition has used model-based approaches in which the image is matched against explicitly represented 3-D geometric models. Notable recent examples are Lowe (1987), Lamdan & Wolfson (1988), Huttenlocher & Ullman (1990), and Grimson (1990) <ref> [21; 19; 17; 10] </ref>. The 3-D geometric models on which these systems are based are both their strength and their weakness.
Reference: [20] <author> David G. Lowe. </author> <title> Perceptual Organization and Visual Recognition. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1986. </year> <month> 30 </month>
Reference-contexts: The solution is not to use arbitrary combinations, but to base the higher level feature groups on structural heuristics such as spatial adjacency and good continuation. Such perceptual grouping processes have been extensively researched in the last few years (Kubovy 1997, Havalder et al. 1996, Lowe 1986) <ref> [18; 14; 20] </ref>. Our keyed local contexts can be viewed as an example of perceptual grouping. The use of pose-insensitive, but not truly invariant features represents another necessary compromise. From a computational standpoint, true invariance is desirable, and a lot of research has gone into looking for invariant features.
Reference: [21] <author> David G. Lowe. </author> <title> Three-dimensional object recognition from single two-dimensional im--ages. </title> <journal> Artificial Intelligence, </journal> <volume> 31 </volume> <pages> 355-395, </pages> <year> 1987. </year>
Reference-contexts: Until recently, the most successful computational work on object recognition has used model-based approaches in which the image is matched against explicitly represented 3-D geometric models. Notable recent examples are Lowe (1987), Lamdan & Wolfson (1988), Huttenlocher & Ullman (1990), and Grimson (1990) <ref> [21; 19; 17; 10] </ref>. The 3-D geometric models on which these systems are based are both their strength and their weakness.
Reference: [22] <author> Bartlett Mel. </author> <title> Object classification with high-dimensional vectors. </title> <booktitle> In Proc. Telluride Workshop on Neuromorphic Engineering, </booktitle> <address> Telluride CO, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: In recent work, Poggio & Edelman (1990) [27] have recognized wire objects and Brunelli & Poggio (1993) [4] have recognized faces using appearance models. Rao & Ballard (1994) [28] describe an approach based on memorizing the responses of a set of steerable filters to images of objects. Mel (1994) <ref> [22] </ref> takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues. Murase & Nayar (1993) [23] find the major principal components of an image dataset, and use the projections of unknown images onto these as indices into a recognition memory.
Reference: [23] <author> Hiroshi Murase and Shree K. Nayar. </author> <title> Learning and recognition of 3d objects from appearance. </title> <booktitle> In Proc. IEEE Workshop on Qualitative Vision, </booktitle> <pages> pages 39-50, </pages> <year> 1993. </year>
Reference-contexts: Rao & Ballard (1994) [28] describe an approach based on memorizing the responses of a set of steerable filters to images of objects. Mel (1994) [22] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues. Murase & Nayar (1993) <ref> [23] </ref> find the major principal components of an image dataset, and use the projections of unknown images onto these as indices into a recognition memory. Huang & Camps (1997) [15] have recently adapted this approach to segmented image regions, thus obtaining some tolerance to clutter and occlusion. <p> of 3-D shapes, ranging from sports cars and fighter planes to snakes and lizards over a full spherical or hemispherical range of views and over changes in scale. (More specifically, the system demonstrates recognition with full, 6DOF, orthographic invariance.) This is in contrast to results by Murase & Nayar (1993) <ref> [23] </ref> where only one of the two out-of-plane rotational degrees of freedom is spanned. We report the results of several large-scale performance tests, involving, over 2000 separate test images. In these experiments we investigate variation in performance with respect to increasing database size, clutter, and occlusion. <p> Of the appearance-based techniques not using color, the best results on large, real image databases have been reported by Murase & Nayar (1993), and Schmid & Mohr (1996) <ref> [23; 30] </ref>. Both groups present large scale tests on databases of real images. Nayar presents 27 results using eigenspace techniques for 3-D recognition in databases containing several tens of objects with accuracy comparable to what we report.
Reference: [24] <author> Randal. C. Nelson. </author> <title> Finding line segments by stick growing. </title> <journal> IEEE Trans PAMI, </journal> <volume> 16(5) </volume> <pages> 519-523, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: The system needs a particular shape or pattern to index on, and does not work well for objects whose character is statistical, such as generic trees or pine cones. Component boundaries were extracted by modifying a stick-growing method for finding segments developed recently by Nelson (1994) <ref> [24] </ref> so that it could follow curved boundaries. of the objects we later use for testing. Training images generally produce contours of about this quality.
Reference: [25] <author> M. W. Oram and D. I. Perret. </author> <title> Modeling visual recognition from neurobiological con-straints. Neural Networks, </title> <address> 7(6-7):945-972, </address> <year> 1994. </year>
Reference-contexts: results on the existence of object specific cortical cells in monkeys and other animals, specifically on cells that seem to be selective for particular views of faces are intriguing, but still too preliminary to say much about the underlying implementation (Oram & Perret 1994, Perret & Oram 1993, Gross 1992) <ref> [25; 26; 13] </ref>. On the other hand, there is a body of psychophysical work that is relevant to the question.
Reference: [26] <author> D. I. Perret and M. W. Oram. </author> <title> Neurophysiology of shape processing. </title> <journal> Image and Vision Computing, </journal> <volume> 11(6) </volume> <pages> 317-333, </pages> <month> July-August </month> <year> 1993. </year>
Reference-contexts: results on the existence of object specific cortical cells in monkeys and other animals, specifically on cells that seem to be selective for particular views of faces are intriguing, but still too preliminary to say much about the underlying implementation (Oram & Perret 1994, Perret & Oram 1993, Gross 1992) <ref> [25; 26; 13] </ref>. On the other hand, there is a body of psychophysical work that is relevant to the question.
Reference: [27] <author> Thomaso Poggio and Shimon Edelman. </author> <title> A network that learns to recognize threedimensional objects. </title> <journal> Nature, </journal> <volume> 343 </volume> <pages> 263-266, </pages> <year> 1990. </year>
Reference-contexts: Most of these operate by comparing a two-dimensional, image-like representation of object appearance against many prototype representations stored in a memory, and finding the closest match. They have the advantage of being fairly general, and often easily trainable. In recent work, Poggio & Edelman (1990) <ref> [27] </ref> have recognized wire objects and Brunelli & Poggio (1993) [4] have recognized faces using appearance models. Rao & Ballard (1994) [28] describe an approach based on memorizing the responses of a set of steerable filters to images of objects.
Reference: [28] <author> Rajesh P.N. Rao. </author> <title> Top-down gaze targeting for space-variant active vision. </title> <booktitle> In Proc. ARPA Image Understanding Workshop, </booktitle> <pages> pages 1049-1058, </pages> <address> Monterey CA, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: They have the advantage of being fairly general, and often easily trainable. In recent work, Poggio & Edelman (1990) [27] have recognized wire objects and Brunelli & Poggio (1993) [4] have recognized faces using appearance models. Rao & Ballard (1994) <ref> [28] </ref> describe an approach based on memorizing the responses of a set of steerable filters to images of objects. Mel (1994) [22] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues.
Reference: [29] <author> R. Kjeldsen Ruud M. Bolle and Daniel Sabbah. </author> <title> Primitive shape extraction from range data. </title> <booktitle> In Proc. IEEE Workshop on Computer Vision, </booktitle> <pages> pages 324-326, </pages> <address> Miami FL, </address> <month> NovDec </month> <year> 1989. </year>
Reference-contexts: There has been a substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) <ref> [29; 32; 2] </ref> but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) [34; 3; 1; 9].
Reference: [30] <author> C. Schmid and R. Mohr. </author> <title> Combining greyvalue invariants with local constraints for object recognition. </title> <booktitle> In Proc. CVPR96, </booktitle> <pages> pages 872-877, </pages> <address> San Francisco CA, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Huang & Camps (1997) [15] have recently adapted this approach to segmented image regions, thus obtaining some tolerance to clutter and occlusion. Schmid & Mohr (1996) <ref> [30] </ref> have recently reported good results for an appearance based system with a local-feature approach similar in spirit to what we use, though with different features and without using feature likelihood measures in the evidence combination scheme. <p> Of the appearance-based techniques not using color, the best results on large, real image databases have been reported by Murase & Nayar (1993), and Schmid & Mohr (1996) <ref> [23; 30] </ref>. Both groups present large scale tests on databases of real images. Nayar presents 27 results using eigenspace techniques for 3-D recognition in databases containing several tens of objects with accuracy comparable to what we report.
Reference: [31] <author> R. N. Shepard and L. A. Cooper. </author> <title> Mental Images and Their Transformations. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1982. </year>
Reference-contexts: Some early work addressed the problem of mental rotation of images of 3-D objects, and determined that people were, in general able to do this, and in a way that took increasing amounts of time as the required rotation was increased (Shepard & Cooper 1982, Tarr & Pinker 1989) <ref> [31; 33] </ref>. This was taken as evidence for the existence of internal 3-D object models.
Reference: [32] <editor> F. Solina and Ruzena Bajcsy. </editor> <title> Recovery of parameteric models from range images. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 12 </volume> <pages> 131-147, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: There has been a substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) <ref> [29; 32; 2] </ref> but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) [34; 3; 1; 9].
Reference: [33] <author> M. J. Tarr and S. Pinker. </author> <title> Mental rotation and orientation-dependence in shape recog-nition. </title> <journal> Cognitive Psychology, </journal> <volume> 21 </volume> <pages> 233-282, </pages> <year> 1989. </year>
Reference-contexts: Some early work addressed the problem of mental rotation of images of 3-D objects, and determined that people were, in general able to do this, and in a way that took increasing amounts of time as the required rotation was increased (Shepard & Cooper 1982, Tarr & Pinker 1989) <ref> [31; 33] </ref>. This was taken as evidence for the existence of internal 3-D object models. <p> All methods using viewpoint dependent two-dimensional representations may be considered as computa <p>- 5 tional variants of the empirically-based multiple-views-plus-transformation (MVPT) theory of recognition (Tarr & Pinker 1989) <ref> [33] </ref>.
Reference: [34] <author> Shimon Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Trans. PAMI, </journal> <volume> 13(10), </volume> <year> 1991. </year> <month> 31 </month>
Reference-contexts: substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) [29; 32; 2] but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) <ref> [34; 3; 1; 9] </ref>. However, these techniques are limited to a particular geometric schema, and even within their domain, especially with visual techniques, their performance is often unsatisfactory. Appearance-based object recognition methods have been proposed in order to make recognition systems more general, and more easily trainable from visual data.
References-found: 34

