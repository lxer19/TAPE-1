URL: ftp://ftp.cs.uu.nl/pub/RUU/CS/techreps/CS-1997/1997-06.ps.gz
Refering-URL: http://www.cs.ruu.nl/docs/research/publication/TechList1.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: An Integrated Modal Approach to Rational Agents  
Author: W. van der Hoek B. van Linder J.-J. Ch. Meyer 
Address: P.O. Box 80.089 3508 TB Utrecht The Netherlands  
Affiliation: Utrecht University Department of Computer Science  
Abstract: In this paper we give an overview of work we have done to provide a framework in which many aspects of rational agency are integrated. The various attitudes of a rational agent, viz. the informational as well as the motivational ones, are modelled in the framework by means of a variety of modal operators that are interpreted by means of possible worlds, as usual in modal logic. A main point here is that we incorporate all these modal operators into one model, so that in principle the various modal operators can be mixed to describe an agent's complex attitudes.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C.E. Alchourron, P. Gardenfors, and D. Makinson. </author> <title> On the logic of theory change: partial meet contraction and revision functions. </title> <journal> Journal of Symbolic Logic, </journal> <volume> 50 </volume> <pages> 510-530, </pages> <year> 1985. </year> <month> 34 </month>
Reference-contexts: The work of Alchourron, Gardenfors and Makinson (AGM, <ref> [1] </ref>) has become a standard reference in the area of belief revision.
Reference: [2] <author> M.A. Brown. </author> <title> On the logic of ability. </title> <journal> Journal of Philosophical Logic, </journal> <volume> 17:1--26, </volume> <year> 1988. </year>
Reference-contexts: We also introduces several epistemic attitudes ([25]), thus taking into account the source of the information the knowledge (the variants are called `beliefs') stems from. We have also come across several accounts of abilities in the literature. The approach of Brown <ref> [2] </ref> and Elgesem [6] is essentially endogenous in the sense that actions are not referred to explicitly. They propose modal operators, ranging over formulae, to formalise ability: A i ' is then to be read as `agent i is able to bring about circumstances in which ' is true'.
Reference: [3] <author> C. </author> <title> Castelfranchi. </title> <type> Personal communication. </type>
Reference-contexts: A possible extension was suggested by Castelfranchi <ref> [3] </ref>, and consists of refining the communication part of information acquisition.
Reference: [4] <author> P.R. Cohen and H.J. Levesque. </author> <title> Intention is choice with commitment. </title> <journal> Artificial Intelligence, </journal> <volume> 42 </volume> <pages> 213-261, </pages> <year> 1990. </year>
Reference-contexts: And we agree with her that it is the compositional behaviour of ability that should be at the focus of attention, here. There is also an extensive literature on motivational attitudes. Probably the most influential account of motivational attitudes is due to Cohen & Levesque <ref> [4] </ref>. Starting from the primitive notions of implicit goals and beliefs, Cohen & Levesque define so-called persistent goals, which are goals which agents give up only when they think they are either satisfied or will never be true, and intentions, both ranging over propositions and over actions.
Reference: [5] <author> F. Dignum and B. van Linder. </author> <title> Modelling social agents: Communication as action. </title> <editor> In J. Mueller, M. Wooldridge, and N. Jennings, editors, </editor> <booktitle> Intelligent Agents III -Proceedings of the 3rd International Workshop on Agent Theories, Architectures, and Languages (ATAL-96), </booktitle> <pages> pages 83-93, </pages> <year> 1996. </year>
Reference-contexts: His focus is slightly different, as well: less on the belief-revisional attitudes and more on the intricacies of intentional notions, as related to nondeterminism and know-how. Furthermore it considers communications as based on speech act theory, which is beyond the scope of our model (But cf. <ref> [5] </ref> for a first integrating attempt in this direction).
Reference: [6] <author> D. Elgesem. </author> <title> Action Theory and Modal Logic. </title> <type> PhD thesis, </type> <institution> Institute for Philosophy, University of Oslo, Oslo, Norway, </institution> <year> 1993. </year>
Reference-contexts: We also introduces several epistemic attitudes ([25]), thus taking into account the source of the information the knowledge (the variants are called `beliefs') stems from. We have also come across several accounts of abilities in the literature. The approach of Brown [2] and Elgesem <ref> [6] </ref> is essentially endogenous in the sense that actions are not referred to explicitly. They propose modal operators, ranging over formulae, to formalise ability: A i ' is then to be read as `agent i is able to bring about circumstances in which ' is true'.
Reference: [7] <author> R. Fagin, J.Y. Halpern, Y. Moses, and M.Y. Vardi. </author> <title> Reasoning about Knowledge. </title> <publisher> MIT Press, </publisher> <address> Cambridge MA, </address> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: The interpretation of the B x i now becomes: M; s j= B x This truth condition for the operators B x i ensures that the notions of belief satisfy at least the properties of the logic K45 (cf. <ref> [7] </ref>). To ensure that both B k i i behave knowledge-like (or S5-like), and to relate the different kinds of belief, we require some additional properties on our models, which will be made explicit in Section 3. <p> Dynamic logic has been studied extensively in computer science (see Gold-blatt's [9]), epistemic and doxastic logic have been of interest among philosophers since Hintikka's [11], and have since then been formalized and proven useful for computers science and artificial intelligence (see the volumes <ref> [7, 27] </ref>). It was Moore ([28, 29]) who realized that dynamic and epistemic logic can be perfectly combined into one modal framework for actions and knowledge.
Reference: [8] <author> P. Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts and London, England, </address> <year> 1988. </year>
Reference-contexts: The third clause states that in situations where some formula is already believed, nothing is changed as the result of an expansion with that formula. This latter property is suggested by the criterion of informational economy <ref> [8] </ref>, which states that since information is in general not gratuitous, unnecessary losses of information are to be avoided. A belief contraction is the change of belief through which in general some formula that is believed beforehand is no longer believed afterwards.
Reference: [9] <author> R. </author> <title> Goldblatt. </title> <booktitle> Axiomatising the Logic of Computer Programming, volume 130 of LNCS. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1982. </year>
Reference-contexts: Dynamic logic has been studied extensively in computer science (see Gold-blatt's <ref> [9] </ref>), epistemic and doxastic logic have been of interest among philosophers since Hintikka's [11], and have since then been formalized and proven useful for computers science and artificial intelligence (see the volumes [7, 27]).
Reference: [10] <author> R. Goldblatt. </author> <title> Logics of Time and Computation, </title> <booktitle> volume 7 of CSLI Lecture Notes. </booktitle> <publisher> CSLI, Stanford, </publisher> <year> 1992. </year> <note> Second edition. </note>
Reference-contexts: We will explain below why we generalize the function r from a world transformation (as it is usually defined in dynamic logic, cf. <ref> [10] </ref>) to a transformation on states (M; w). D also contains a capability function c where c (i; a)(w) is true exactly for those atomic actions a that i is capable of in w. The function r is extended to arbitrary actions in a way standard for dynamic logic (cf. [10]) <p> <ref> [10] </ref>) to a transformation on states (M; w). D also contains a capability function c where c (i; a)(w) is true exactly for those atomic actions a that i is capable of in w. The function r is extended to arbitrary actions in a way standard for dynamic logic (cf. [10]) and then [do i (ff)] is interpreted as the necessity operator for this extended r fl . In a similar fashion, c is extended for arbitrary actions.
Reference: [11] <author> J. Hintikka. </author> <title> Knowledge and Belief. </title> <publisher> Cornell University Press, </publisher> <address> Ithaca, NY, </address> <year> 1962. </year>
Reference-contexts: Dynamic logic has been studied extensively in computer science (see Gold-blatt's [9]), epistemic and doxastic logic have been of interest among philosophers since Hintikka's <ref> [11] </ref>, and have since then been formalized and proven useful for computers science and artificial intelligence (see the volumes [7, 27]). It was Moore ([28, 29]) who realized that dynamic and epistemic logic can be perfectly combined into one modal framework for actions and knowledge.
Reference: [12] <author> W. van der Hoek. </author> <title> Systems for knowledge and beliefs. </title> <journal> Journal of Logic and Computation, </journal> <volume> 3(2) </volume> <pages> 173-195, </pages> <year> 1993. </year>
Reference-contexts: This assumes that each agent knows, or has some awareness about how he comes to his beliefs, for instance whether :B c i :B c i ' hold. Such a systematic investigation is beyond the scope of this chapter, but one may read <ref> [12] </ref>. Thus, we introduce, for each ' 2 L 0 and t 2 fk; s; h; jg, an action inform ('; i; t), expressing that agent i is informed about ', and that the status of this fact at the sender's perspective is t.
Reference: [13] <author> W. van der Hoek, B. van Linder, and J.-J. Ch. Meyer. </author> <title> A logic of capabilities. </title> <editor> In A. Nerode and Yu. V. Matiyasevich, editors, </editor> <booktitle> Proceedings of the Third International Symposium on the Logical Foundations of Computer Science (LFCS'94), volume 813 of Lecture Notes in Computer Science, </booktitle> <pages> pages 366-378. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Doing so, we will try not to lose ourselves in technical details (these can be found elsewhere, <ref> [13, 24, 23, 25] </ref>), but rather provide the reader with an intuitive grasp for the ideas underlying our formal definitions. 2.1 Language The language L that we use to formalise these notions is based on a fixed set of propositional atoms, and the connectives ^; _; !; : to build formulas
Reference: [14] <author> W. van der Hoek, B. van Linder, and J.-J. Ch. Meyer. </author> <title> Unravelling non-determinism: On having the ability to choose (extended abstract). </title> <editor> In P. Jorrand and V. Sgurev, editors, </editor> <booktitle> Proceedings of the Sixth International Conference on Artificial Intelligence: Methodology, Systems, Applications (AIMSA'94), </booktitle> <pages> pages 163-172. </pages> <publisher> World Scientific, </publisher> <year> 1994. </year>
Reference-contexts: In our view modal logic has proven to be an excellent tool for this purpose. Finally we like to say some words on the restriction to deterministic actions in this paper. It has been shown in <ref> [14] </ref> that also nondeterminism can be treated within our framework by extending the set of action constructors by choice operators. In fact, in [14] we have considered two such operators: the internal non-deterministic operator models those choices that are to be made by the agent, and is therefore supposed to behave <p> Finally we like to say some words on the restriction to deterministic actions in this paper. It has been shown in <ref> [14] </ref> that also nondeterminism can be treated within our framework by extending the set of action constructors by choice operators. In fact, in [14] we have considered two such operators: the internal non-deterministic operator models those choices that are to be made by the agent, and is therefore supposed to behave angelic, i.e. as helpful as possible for the agent.
Reference: [15] <author> W. van der Hoek and J.-J. Ch. Meyer. </author> <title> Possible logics for belief. </title> <journal> Logique & Analyse, </journal> <volume> 127-128:177-194, </volume> <year> 1989. </year> <month> 35 </month>
Reference-contexts: j= (B o i ' ! ') T 3. j= X' ! XX' 4 5. j= (B k i ') ^ (B o i ) ^ (B c i ) Here, we will not address the problem of logical omniscience for belief op erators any further (for a discussion, see <ref> [35, 15] </ref>). Item 1 of theorem 3.1 says that knowledge and observational beliefs are veridical: they must be true. Item 2 states a weaker property, saying that one cannot have false beliefs. Items 3 and 4 are known as positive and negative introspection, respectively.
Reference: [16] <author> W. van der Hoek and J.-J.Ch. Meyer. </author> <title> Graded modalities for epistemic logic. </title> <institution> Logique et Analyse, 34(133-134):251-270, </institution> <year> 1991. </year>
Reference-contexts: Whenever an agent j informs an agent i of the truth of ', i's communicational belief cluster that is associated with j is revised with '. Over the different communicational belief clusters a kind of graded belief modality could be defined (in the spirit of <ref> [16] </ref>), which formalises the credibility attached to the agent's communicational beliefs. The formula B c;0:5 i ' would then be taken to represent that agent i communicationally believes ' with credibility 0:5, i.e. ' holds in at least half of the communicational belief clusters of i.
Reference: [17] <author> Z. Huang. </author> <title> Logics for belief dependence. </title> <editor> In E. Borger, H. Kleine Buning, M.M. Richter, and W. Schonfeld, editors, </editor> <booktitle> Computer Science Logic, 4th Workshop CSL'90, volume 533 of Lecture Notes in Computer Science, </booktitle> <pages> pages 274-288. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: For reasons of simplicity, we define the credibility of the sending agent as a binary notion, i.e. the agent is either credible or it is not credible, without distinguishing degrees of credibility. The notion of credibility is modelled through the so-called dependence operator, originally proposed by Huang <ref> [17] </ref>.
Reference: [18] <author> T.W.C. Huibers and B. van Linder. </author> <title> Formalising intelligent information retrieval agents. </title> <editor> In F. Johnson, editor, </editor> <booktitle> Proceedings of the 18th BCS IRSG Annual Colloquium on Information Retrieval Research, </booktitle> <pages> pages 125-143, </pages> <year> 1996. </year>
Reference-contexts: A preliminary formalisation of these intelligent information retrieval agents based on the framework proposed in this chapter was presented by Huibers & Van Linder <ref> [18] </ref>. 25 4 Setting Goals As explained in the introduction a rational agent does not only possess information processing capabilities; it should also be endowed with motivations and should be able to modify these.
Reference: [19] <author> H. Katsuno and A.O. Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <editor> In P. Gardenfors, editor, </editor> <booktitle> Belief revision, </booktitle> <pages> pages 183-203. </pages> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: One possible way of formalising this kind of extended communication is given in [23], where an additional modal operator is used to record the agents' requests. Another very interesting extension of the framework presented in this chapter concerns the incorporation of actions associated with belief updates (cf. <ref> [19] </ref>) in addition to the ones associated with belief revision that we considered here. Whereas belief revisions are changes in information on an unchanging world, updates are information changes that are associated with a change in the state of the world.
Reference: [20] <author> A. Kenny. </author> <title> Will, Freedom and Power. </title> <publisher> Basil Blackwell, Oxford, </publisher> <year> 1975. </year>
Reference-contexts: Although these notions are interconnected, they are surely not identical: the abilities of agents comprise mental and physical powers, moral capacities, and physical possibility, whereas the opportunity to perform actions is best described by the notion of circumstantial possibility (cf. <ref> [20] </ref>). To formalise the knowledge of agents on their practical (im)possibilities, we introduce the so-called Can-predicate and Cannot-predicate.
Reference: [21] <author> I. Levi. </author> <title> Direct inference. </title> <journal> The Journal of Philosophy, </journal> <volume> 74 </volume> <pages> 5-29, </pages> <year> 1977. </year>
Reference-contexts: A revision is a change of belief through which some formula is added to the beliefs of an agent, while preserving consistency. Our definition of actions that model revisions is based on the Levi identity <ref> [21] </ref>. Levi suggested that revisions can be defined in terms of contractions and expansions: a revision with ' can be defined as a contraction with :' followed by an expansion with '.
Reference: [22] <author> B. van Linder. </author> <title> Modal Logics for Rational Agents. </title> <type> PhD thesis, </type> <institution> Utrecht University, </institution> <year> 1996. </year>
Reference-contexts: Also note that in the `;-clause' for c fl we have chosen to model optimistic agents: as a consequence, we have that any agent finds itself capable of performing ff; fi, whenever it lacks the opportunity to perform ff (for a discussion on this choice, cf. <ref> [22] </ref>). To explain the content of the informational layer I of the model, recall that, concerning the declarative part, we had four informational operators B k i ; B o i i . <p> One easily verifies that the operators defined above satisfy logical omniscience property LO1. However, they generally don't satisfy all properties of Logical Omniscience. For instance, LO2 is not valid: for no tautology , one can have Saw i . A last property we mention (for more, see also <ref> [22, Proposition 5.12] </ref>) is the following weakening of LO3: if j= ' ! then j= B c i , and hence j= ' ! implies j= Heard i ' ! (Heard i _ Saw i _ B k i ) The latter implication expresses that if an agent believes a formula <p> These intuitive ideas are formalised in Definition 3.15. The definition of revise c below is in the same spirit of Definition 3.13 for revise o , we omit it here for reasons of space (see <ref> [22] </ref> for details).
Reference: [23] <author> B. van Linder, W. van der Hoek, and J.-J. Ch. Meyer. </author> <title> Communicating rational agents. </title> <editor> In B. Nebel and L. Dreschler-Fischer, editors, </editor> <booktitle> KI-94: Advances in Artificial Intelligence, volume 861 of Lecture Notes in Computer Science (subseries LNAI), </booktitle> <pages> pages 202-213. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: Doing so, we will try not to lose ourselves in technical details (these can be found elsewhere, <ref> [13, 24, 23, 25] </ref>), but rather provide the reader with an intuitive grasp for the ideas underlying our formal definitions. 2.1 Language The language L that we use to formalise these notions is based on a fixed set of propositional atoms, and the connectives ^; _; !; : to build formulas <p> In this extended form of communication an agent may request information on the truth or falsity of certain proposition from another, trusted, agent. One possible way of formalising this kind of extended communication is given in <ref> [23] </ref>, where an additional modal operator is used to record the agents' requests. Another very interesting extension of the framework presented in this chapter concerns the incorporation of actions associated with belief updates (cf. [19]) in addition to the ones associated with belief revision that we considered here.
Reference: [24] <author> B. van Linder, W. van der Hoek, and J.-J. Ch. Meyer. </author> <title> Tests as epistemic updates. In A.G. </title> <editor> Cohn, editor, </editor> <booktitle> Proceedings of the 11th European Conference on Artificial Intelligence (ECAI'94), </booktitle> <pages> pages 331-335. </pages> <publisher> John Wiley & Sons, </publisher> <year> 1994. </year>
Reference-contexts: Doing so, we will try not to lose ourselves in technical details (these can be found elsewhere, <ref> [13, 24, 23, 25] </ref>), but rather provide the reader with an intuitive grasp for the ideas underlying our formal definitions. 2.1 Language The language L that we use to formalise these notions is based on a fixed set of propositional atoms, and the connectives ^; _; !; : to build formulas
Reference: [25] <author> B. van Linder, W. van der Hoek, and J.-J. Ch. Meyer. </author> <title> Actions that make you change your mind. </title> <editor> In A. Laux and H. Wansing, editors, </editor> <booktitle> Knowledge and Belief in Philosophy and Artificial Intelligence, </booktitle> <pages> pages 103-146. </pages> <publisher> Akademie Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Doing so, we will try not to lose ourselves in technical details (these can be found elsewhere, <ref> [13, 24, 23, 25] </ref>), but rather provide the reader with an intuitive grasp for the ideas underlying our formal definitions. 2.1 Language The language L that we use to formalise these notions is based on a fixed set of propositional atoms, and the connectives ^; _; !; : to build formulas <p> These are functions : A fi W fi L 0 ! -(W ) that (whenever possible) select a subset of the set of epistemic alternatives in such a way that the resulting contract action behaves rationally. Without giving the full details here (see <ref> [25] </ref>, let us here mention the two requirements that (i; s; ') B k (i; s) and that (i; s; ') = (i; s 0 '), when 12 ever s 0 2 B k (i; s)) ), we claim that such a function can be defined in such a way that <p> Then, in <ref> [25] </ref> we show that these sets exactly satisfy the AGM postulates for AGM contraction, expansion and revision, respectively. There is one difference: whereas the AGM postulates assume classical logic as a backup system, in our setup this is provided by the agent's knowledge.
Reference: [26] <author> B. van Linder, J.-J. Ch. Meyer, and W. van der Hoek. </author> <title> Formalising motivational attitudes of agents using the karo framework. </title> <type> Technical Report UU-CS-1997-03, </type> <institution> Utrecht University, </institution> <year> 1997. </year>
Reference-contexts: For ease of presentation these are omitted here. Details can be found in <ref> [26] </ref>. in its agenda. In order to capture the notion of semantical equivalence of actions we use our transition systems again, and define the notion of a computation run. <p> definition, as compared to that of the commit to operator, is due to the fact that `committedness' is closed under taking prefixes 2 Actually, in order to let this notion be well-defined, we need certain minimality conditions which we omit here for simplicity's sake (for a more rigorous treatment, see <ref> [26] </ref>) 31 of (computation runs of) actions, so that in order to successfully uncommit to an action ff also all actions that have ff as a prefix (with respect to computation runs) should be removed from the agent's agenda.
Reference: [27] <author> J.-J. Ch. Meyer and W. van der Hoek. </author> <title> Epistemic Logic for AI and Computer Science. </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year>
Reference-contexts: Dynamic logic has been studied extensively in computer science (see Gold-blatt's [9]), epistemic and doxastic logic have been of interest among philosophers since Hintikka's [11], and have since then been formalized and proven useful for computers science and artificial intelligence (see the volumes <ref> [7, 27] </ref>). It was Moore ([28, 29]) who realized that dynamic and epistemic logic can be perfectly combined into one modal framework for actions and knowledge.
Reference: [28] <author> R.C. Moore. </author> <title> Reasoning about knowledge and action. </title> <type> Technical Report 191, </type> <institution> SRI International, </institution> <year> 1980. </year> <month> 36 </month>
Reference: [29] <author> R.C. Moore. </author> <title> A formal theory of knowledge and action. </title> <type> Technical Report 320, </type> <institution> SRI International, </institution> <year> 1984. </year>
Reference: [30] <author> G. Plotkin. </author> <title> A structural approach to operational semantics. </title> <type> Technical Report DAIME FN-19, </type> <institution> Aarhus University, </institution> <year> 1981. </year>
Reference: [31] <author> D. Poole. </author> <title> A logical framework for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 36 </volume> <pages> 27-47, </pages> <year> 1988. </year>
Reference-contexts: In terms of Reiter's framework, the kind of default reasoning that we consider here uses only supernormal defaults, i.e. defaults of the form : '='; these defaults can be seen as possible hypotheses in Poole's system <ref> [31] </ref>. Here we shall introduce these supernormal defaults as syntactical constructs that are at the agent's disposal.
Reference: [32] <author> A.S. Rao and M.P. Georgeff. </author> <title> Modeling rational agents within a BDI-architecture. </title> <editor> In J. Allen, R. Fikes, and E. Sandewall, editors, </editor> <booktitle> Proceedings of the Second International Conference on Principles of Knowledge Representation and Reasoning (KR'91), </booktitle> <pages> pages 473-484. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: An agent intends to do an action if it has the persistent goal to have done the action. In our approach we do not use such a reduction technique. Another important formalisation of motivational attitudes is proposed by Rao & Georgeff <ref> [32] </ref> in their BDI-architecture. Treating desires and intentions as primitive, Rao & Georgeff focus on the process of intention revision rather than the `commitment acquisition' which is essential in our formalisation.
Reference: [33] <author> R. Reiter. </author> <title> A logic for default reasoning. </title> <journal> Artificial Intelligence, </journal> <volume> 13 </volume> <pages> 81-132, </pages> <year> 1980. </year>
Reference-contexts: In general in default reasoning, plausible yet fallible conclusions are derived on the basis of the presence of certain information and the absence of other information. In the formalisation of default reasoning as proposed by Reiter <ref> [33] </ref>, defaults are formalised as special inference rules ' 1 : ' 2 =' 3 , which should be interpreted as stating that if ' 1 holds and it is consistent to assume ' 2 then ' 3 may be derived.
Reference: [34] <author> M.P. Singh. </author> <title> Multiagent Systems: A Theoretical Framework for Intentions, </title> <booktitle> Know-How and Communications, volume 799 of Lecture Notes in Computer Science (subseries LNAI). </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference: [35] <author> E. Thijsse. </author> <title> On total awareness logics (with special attention to mono-tonicity constraints and flexibility). </title> <editor> In M. de Rijke, editor, Diamonds and Defaults, </editor> <booktitle> volume 229 of Synthese Library, </booktitle> <pages> pages 309-347. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year> <month> 37 </month>
Reference-contexts: j= (B o i ' ! ') T 3. j= X' ! XX' 4 5. j= (B k i ') ^ (B o i ) ^ (B c i ) Here, we will not address the problem of logical omniscience for belief op erators any further (for a discussion, see <ref> [35, 15] </ref>). Item 1 of theorem 3.1 says that knowledge and observational beliefs are veridical: they must be true. Item 2 states a weaker property, saying that one cannot have false beliefs. Items 3 and 4 are known as positive and negative introspection, respectively.
References-found: 35

