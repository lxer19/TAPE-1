URL: ftp://theory.lcs.mit.edu/pub/cilk/cilk5.ps.gz
Refering-URL: http://theory.lcs.mit.edu/~cilk/abstracts/cilk5.html
Root-URL: 
Email: fathena,cel,randallg@lcs.mit.edu  
Title: The Implementation of the Cilk-5 Multithreaded Language  
Author: Matteo Frigo Charles E. Leiserson Keith H. Randall 
Keyword: Critical path, multithreading, parallel computing, programming language, runtime system, work.  
Address: 545 Technology Square Cambridge, Massachusetts 02139  
Affiliation: MIT Laboratory for Computer Science  
Abstract: The fifth release of the multithreaded language Cilk uses a provably good "work-stealing" scheduling algorithm similar to the first system, but the language has been completely redesigned and the runtime system completely reengineered. The efficiency of the new implementation was aided by a clear strategy that arose from a theoretical analysis of the scheduling algorithm: concentrate on minimizing overheads that contribute to the work, even at the expense of overheads that contribute to the critical path. Although it may seem counterintuitive to move overheads onto the critical path, this "work-first" principle has led to a portable Cilk-5 implementation in which the typical cost of spawning a parallel thread is only between 2 and 6 times the cost of a C function call on a variety of contemporary machines. Many Cilk programs run on one processor with virtually no degradation compared to equivalent C programs. This paper describes how the work-first principle was exploited in the design of Cilk-5's compiler and its runtime system. In particular, we present Cilk-5's novel "two-clone" compilation strategy and its Dijkstra-like mutual-exclusion protocol for implementing the ready deque in the work-stealing scheduler. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Andrew W. Appel and Zhong Shao. </author> <title> Empirical and analytic study of stack versus heap cost for languages with closures. </title> <journal> Journal of Functional Programming, </journal> <volume> 6(1) </volume> <pages> 47-74, </pages> <year> 1996. </year>
Reference-contexts: &lt;stdlib.h&gt; #include &lt;stdio.h&gt; #include &lt;cilk.h&gt; cilk int fib (int n) - if (n&lt;2) return n; else - int x, y; x = spawn fib (n-1); y = spawn fib (n-2); sync; return (x+y); - cilk int main (int argc, char *argv []) - int n, result; n = atoi (argv <ref> [1] </ref>); result = spawn fib (n); sync; printf ("Result: %d"n", result); return 0; - number in parallel (using a very bad algorithm). The basic Cilk language can be understood from an example. <p> On the downside, heap allocation can potentially waste more memory than stack allocation due to fragmentation. For a careful analysis of the relative merits of stack and heap based allocation that supports heap allocation, see the paper by Appel and Shao <ref> [1] </ref>. For an equally careful analysis that supports stack allocation, see [22].
Reference: [2] <author> Nimar S. Arora, Robert D. Blumofe, and C. Greg Plaxton. </author> <title> Thread scheduling for multiprogrammed multiprocessors. </title> <booktitle> In Proceedings of the Tenth Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <address> Puerto Vallarta, Mexico, </address> <month> June </month> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: For example, even if a worker is suspended by the operating system during the execution of pop, the infrequency of locking in the THE protocol means that a thief can usually complete a steal operation on the worker's deque. Recent work by Arora et al. <ref> [2] </ref> has shown that a completely nonblocking work-stealing scheduler can be implemented. Using these ideas, Lisiecki and Medina [21] have modified the Cilk-5 scheduler to make it completely non-blocking. Their experience is that the THE protocol greatly simplifies a nonblocking implementation.
Reference: [3] <author> Robert D. Blumofe. </author> <title> Executing Multithreaded Programs Efficiently. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: 1 Introduction Cilk is a multithreaded language for parallel programming that generalizes the semantics of C by introducing linguistic constructs for parallel control. The original Cilk-1 release <ref> [3, 4, 18] </ref> featured a provably efficient, randomized, "work-stealing" scheduler [3, 5], but the language was clumsy, because parallelism was exposed "by hand" using explicit continuation passing. The Cilk language implemented by This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) under Grant N00014-94-1-0985. <p> 1 Introduction Cilk is a multithreaded language for parallel programming that generalizes the semantics of C by introducing linguistic constructs for parallel control. The original Cilk-1 release [3, 4, 18] featured a provably efficient, randomized, "work-stealing" scheduler <ref> [3, 5] </ref>, but the language was clumsy, because parallelism was exposed "by hand" using explicit continuation passing. The Cilk language implemented by This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) under Grant N00014-94-1-0985. <p> To obtain efficiency, we have, of course, attempted to reduce scheduling overheads. Some overheads have a larger impact on execution time than others, however. A theoretical understanding of Cilk's scheduling algorithm <ref> [3, 5] </ref> has allowed us to identify and optimize the common cases. <p> First, we assume that Cilk's scheduler operates in practice according to the theoretical analysis presented in <ref> [3, 5] </ref>. Second, we assume that in the common case, ample "parallel slackness" [28] exists, that is, the average parallelism of a Cilk program exceeds the number of processors on which we run it by a sufficient margin. <p> Third, we assume (as is indeed the case) that every Cilk program has a C elision against which its one-processor performance can be measured. The theoretical analysis presented in <ref> [3, 5] </ref> cites two funda 3 mental lower bounds as to how fast a Cilk program can run. Let us denote by T P the execution time of a given computation on P processors. <p> In addition, the lower bound T P T 1 must hold, since a finite number of processors cannot execute faster than an infinite number. 3 Cilk's randomized work-stealing scheduler <ref> [3, 5] </ref> executes a Cilk computation on P processors in expected time T P = T 1 =P + O (T 1 ) ; (1) assuming an ideal parallel computer.
Reference: [4] <author> Robert D. Blumofe, Christopher F. Joerg, Bradley C. Kusz-maul, Charles E. Leiserson, Keith H. Randall, and Yuli Zhou. Cilk: </author> <title> An efficient multithreaded runtime system. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1) </volume> <pages> 55-69, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Cilk is a multithreaded language for parallel programming that generalizes the semantics of C by introducing linguistic constructs for parallel control. The original Cilk-1 release <ref> [3, 4, 18] </ref> featured a provably efficient, randomized, "work-stealing" scheduler [3, 5], but the language was clumsy, because parallelism was exposed "by hand" using explicit continuation passing. The Cilk language implemented by This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) under Grant N00014-94-1-0985. <p> Section 6 describes a dozen other diverse applications which were run on an 8-processor SMP with 3 This abstract model of execution time ignores real-life details, such as memory-hierarchy effects, but is nonetheless quite accurate <ref> [4] </ref>. considerable parallel slackness. The parallelisim of these applications increases with problem size, thereby ensuring they will run well on large machines. The third assumption behind the work-first principle is that every Cilk program has a C elision against which its one-processor performance can be measured. <p> The state-saving costs are small for fib, because all four architectures have write buffers that can hide the latency of the writes required. We also attempted to measure the critical-path overhead c 1 . We used the synthetic knary benchmark <ref> [4] </ref> to synthesize computations artificially with a wide range of work and critical-path lengths. Figure 8 shows the outcome from many such experiments. <p> In order to plot different computations on the same graph, we normalized the machine size and the speedup by dividing these values by the average parallelism P = T 1 =T 1 , as was done in <ref> [4] </ref>. For each run, the horizontal position of the plotted datum is the inverse of the slackness P=P , and thus, the normalized machine size is 1:0 when the number of processors is equal to the average parallelism.
Reference: [5] <author> Robert D. Blumofe and Charles E. Leiserson. </author> <title> Scheduling multithreaded computations by work stealing. </title> <booktitle> In Proceedings of the 35th Annual Symposium on Foundations of Computer Science (FOCS), </booktitle> <pages> pages 356-368, </pages> <address> Santa Fe, New Mex-ico, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Cilk is a multithreaded language for parallel programming that generalizes the semantics of C by introducing linguistic constructs for parallel control. The original Cilk-1 release [3, 4, 18] featured a provably efficient, randomized, "work-stealing" scheduler <ref> [3, 5] </ref>, but the language was clumsy, because parallelism was exposed "by hand" using explicit continuation passing. The Cilk language implemented by This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) under Grant N00014-94-1-0985. <p> To obtain efficiency, we have, of course, attempted to reduce scheduling overheads. Some overheads have a larger impact on execution time than others, however. A theoretical understanding of Cilk's scheduling algorithm <ref> [3, 5] </ref> has allowed us to identify and optimize the common cases. <p> First, we assume that Cilk's scheduler operates in practice according to the theoretical analysis presented in <ref> [3, 5] </ref>. Second, we assume that in the common case, ample "parallel slackness" [28] exists, that is, the average parallelism of a Cilk program exceeds the number of processors on which we run it by a sufficient margin. <p> Third, we assume (as is indeed the case) that every Cilk program has a C elision against which its one-processor performance can be measured. The theoretical analysis presented in <ref> [3, 5] </ref> cites two funda 3 mental lower bounds as to how fast a Cilk program can run. Let us denote by T P the execution time of a given computation on P processors. <p> In addition, the lower bound T P T 1 must hold, since a finite number of processors cannot execute faster than an infinite number. 3 Cilk's randomized work-stealing scheduler <ref> [3, 5] </ref> executes a Cilk computation on P processors in expected time T P = T 1 =P + O (T 1 ) ; (1) assuming an ideal parallel computer.
Reference: [6] <author> Richard P. Brent. </author> <title> The parallel evaluation of general arithmetic expressions. </title> <journal> Journal of the ACM, </journal> <volume> 21(2) </volume> <pages> 201-206, </pages> <month> April </month> <year> 1974. </year>
Reference-contexts: This equation resembles "Brent's theorem" <ref> [6, 15] </ref> and is optimal to within a constant factor, since T 1 =P and T 1 are both lower bounds. We call the first term on the right-hand side of Equation (1) the work term and the second term the critical-path term.
Reference: [7] <author> Guang-Ien Cheng, Mingdong Feng, Charles E. Leiserson, Keith H. Randall, and Andrew F. Stark. </author> <title> Detecting data races in Cilk programs that use locks. </title> <booktitle> In Proceedings of the Tenth Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <address> Puerto Vallarta, Mexico, </address> <month> June </month> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: We are currently investigating how to incorporate atomicity into the Cilk language so that protocol issues involved in locking can be avoided at the user level. To aid in the debugging of Cilk programs that use locks, we have been developing a tool called the "Nonde-terminator" <ref> [7, 13] </ref>, which detects common synchronization bugs called data races. 3 The work-first principle This section justifies the work-first principle stated in Section 1 by showing that it follows from three assumptions. First, we assume that Cilk's scheduler operates in practice according to the theoretical analysis presented in [3, 5].
Reference: [8] <institution> Cilk-5.1 (Beta 1) Reference Manual. </institution> <note> Available on the Internet from http://theory.lcs.mit.edu/~cilk. </note>
Reference-contexts: Computing facilities were provided by the MIT Xolas Project, thanks to a generous equipment donation from Sun Microsystems. To appear in Proceedings of the 1998 ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), Montreal, Canada, June 1998. our latest Cilk-5 release <ref> [8] </ref> still uses a theoretically efficient scheduler, but the language has been simplified considerably. It employs call/return semantics for parallelism and features a linguistically simple "inlet" mechanism for nondeterministic control. Cilk-5 is designed to run efficiently on contemporary symmetric multiprocessors (SMP's), which feature hardware support for shared memory. <p> Section 6 gives empirical evidence that the Cilk-5 scheduler is efficient. Finally, Section 7 presents related work and offers some conclusions. 2 The Cilk language This section presents a brief overview of the Cilk extensions to C as supported by Cilk-5. (For a complete description, consult the Cilk-5 manual <ref> [8] </ref>.) The key features of the language are the specification of parallelism and synchronization, through the spawn and sync keywords, and the specification of nondeterminism, using inlet and abort. #include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; #include &lt;cilk.h&gt; cilk int fib (int n) - if (n&lt;2) return n; else - int x, y; x <p> We compiled our programs with gcc 2.7.2 at optimization level -O3. For a full description of these programs, see the Cilk 5.1 manual <ref> [8] </ref>. The table shows the work of each Cilk program T 1 , the critical path T 1 , and the two derived quantities P and c 1 .
Reference: [9] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1990. </year>
Reference-contexts: Ordinarily, when a spawned procedure returns, the returned value is simply stored into a variable in its parent's frame: 1 This program uses an inefficient algorithm which runs in exponential time. Although logarithmic-time methods are known <ref> [9, p. 850] </ref>, this program nevertheless provides a good didactic example. 2 cilk int fib (int n) - inlet void summer (int result) - x += result; return; - if (n&lt;2) return n; else - summer (spawn fib (n-1)); summer (spawn fib (n-2)); sync; return (x); - x = spawn foo
Reference: [10] <author> David E. Culler, Anurag Sah, Klaus Erik Schauser, Thorsten von Eicken, and John Wawrzynek. </author> <title> Fine-grain parallelism with minimal hardware support: A compiler-controlled threaded abstract machine. </title> <booktitle> In Proceedings of the Fourth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), </booktitle> <pages> pages 164-175, </pages> <address> Santa Clara, California, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Cilk provides an inlet feature for this purpose, which was inspired in part by the inlet feature of TAM <ref> [10] </ref>. An inlet is essentially a C function internal to a Cilk procedure. In the normal syntax of Cilk, the spawning of a procedure must occur as a separate statement and not in an expression. <p> Cilk is a faithful extension of C, however, supporting the simplifying notion of a C elision and allowing Cilk to exploit the C compiler technology more readily. TAM <ref> [10] </ref> and Lazy Threads [14] also analyze many of the same overhead issues in a more general, "nonstrict" language setting, where the individual performances of a whole host of mechanisms are required for applications to obtain good overall performance.
Reference: [11] <author> E. W. Dijkstra. </author> <title> Solution of a problem in concurrent programming control. </title> <journal> Communications of the ACM, </journal> <volume> 8(9):569, </volume> <month> September </month> <year> 1965. </year>
Reference-contexts: The slow clone is executed in the infrequent case that parallel semantics and its concomitant bookkeeping are required. All communication due to scheduling occurs in the slow clone and contributes to critical-path overhead, but not to work overhead. The work-first principle also inspired a Dijkstra-like <ref> [11] </ref>, shared-memory, mutual-exclusion protocol as part of the runtime load-balancing scheduler. Cilk's scheduler uses a "work-stealing" algorithm in which idle processors, called thieves, "steal" threads from busy processors, called victims. Cilk's scheduler guarantees that the cost of stealing contributes only to critical-path overhead, and not to work overhead. <p> We also feel that the current overheads are sufficiently low that other problems, notably minimizing overheads for data synchronization, deserve more attention. 5 Implemention of work-stealing In this section, we describe Cilk-5's work-stealing mechanism, which is based on a Dijkstra-like <ref> [11] </ref>, shared-memory, mutual-exclusion protocol called the "THE" protocol. In accordance with the work-first principle, this protocol has been designed to minimize work overhead. For example, on a 167-megahertz UltraSPARC I, the fib program with the THE protocol runs about 25% faster than with hardware locking primitives. <p> This solution has the same fundamental problem as the interrupt and polling mechanisms just described, however. Whenever a worker pops a frame, it pays the heavy price to grab a lock, which contributes to work overhead. Consequently, we adopted a solution that employs Di-jkstra's protocol for mutual exclusion <ref> [11] </ref>, which assumes only that reads and writes are atomic. Because our protocol uses three atomic shared variables T, H, and E, we call it the THE protocol.
Reference: [12] <author> Marc Feeley. </author> <title> Polling efficiently on stock hardware. </title> <booktitle> In Proceedings of the 1993 ACM SIGPLAN Conference on Functional Programming and Computer Architecture, </booktitle> <pages> pages 179-187, </pages> <address> Copenhagen, Denmark, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: As an alternative to sending interrupts, thieves could post steal requests, and workers could periodically poll for them. Once again, however, a cost accrues to the work overhead, this time for polling. Techniques are known that can limit the overhead of polling <ref> [12] </ref>, but they require the support of a sophisticated compiler. The work-first principle suggests that it is reasonable to put substantial effort into minimizing work overhead in the work-stealing protocol.
Reference: [13] <author> Mingdong Feng and Charles E. Leiserson. </author> <title> Efficient detection of determinacy races in Cilk programs. </title> <booktitle> In Proceedings of the Ninth Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA), </booktitle> <pages> pages 1-11, </pages> <address> Newport, Rhode Island, </address> <month> June </month> <year> 1997. </year>
Reference-contexts: We are currently investigating how to incorporate atomicity into the Cilk language so that protocol issues involved in locking can be avoided at the user level. To aid in the debugging of Cilk programs that use locks, we have been developing a tool called the "Nonde-terminator" <ref> [7, 13] </ref>, which detects common synchronization bugs called data races. 3 The work-first principle This section justifies the work-first principle stated in Section 1 by showing that it follows from three assumptions. First, we assume that Cilk's scheduler operates in practice according to the theoretical analysis presented in [3, 5].
Reference: [14] <author> S. C. Goldstein, K. E. Schauser, and D. E. Culler. </author> <title> Lazy threads: Implementing a fast parallel call. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 37(1) </volume> <pages> 5-20, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: We believe that Cilk-5 work overhead is nearly as low as possible, given our goal of generating portable C output from our compiler. 7 Other researchers have been able to reduce overheads even more, however, at the expense of portability. For example, lazy threads <ref> [14] </ref> obtains efficiency at the expense of implementing its own calling conventions, stack layouts, etc. Although we could in principle incorporate such machine-dependent techniques into our compiler, we feel that Cilk-5 strikes a good balance between performance and portability. <p> Cilk is a faithful extension of C, however, supporting the simplifying notion of a C elision and allowing Cilk to exploit the C compiler technology more readily. TAM [10] and Lazy Threads <ref> [14] </ref> also analyze many of the same overhead issues in a more general, "nonstrict" language setting, where the individual performances of a whole host of mechanisms are required for applications to obtain good overall performance.
Reference: [15] <author> R. L. Graham. </author> <title> Bounds on multiprocessing timing anomalies. </title> <journal> SIAM Journal on Applied Mathematics, </journal> <volume> 17(2) </volume> <pages> 416-429, </pages> <month> March </month> <year> 1969. </year>
Reference-contexts: This equation resembles "Brent's theorem" <ref> [6, 15] </ref> and is optimal to within a constant factor, since T 1 =P and T 1 are both lower bounds. We call the first term on the right-hand side of Equation (1) the work term and the second term the critical-path term.
Reference: [16] <author> Dirk Grunwald. </author> <title> Heaps o' stacks: Time and space efficient threads without operating system support. </title> <type> Technical Report CU-CS-750-94, </type> <institution> University of Colorado, </institution> <month> November </month> <year> 1994. </year>
Reference-contexts: The generated C code has the same general structure as the C elision, with a few additional statements. In lines 4-5, an activation frame is allocated for fib and initialized. The Cilk runtime system uses activation frames to represent procedure instances. Using techniques similar to <ref> [16, 17] </ref>, our inlined allocator typically takes only a few cycles. The frame is initialized in line 5 by storing a pointer to a static structure, called a signature, describing fib. The first spawn in fib is translated into lines 12-18.
Reference: [17] <author> Dirk Grunwald and Richard Neves. </author> <title> Whole-program optimization for time and space efficient threads. </title> <booktitle> In Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), </booktitle> <pages> pages 50-59, </pages> <address> Cambridge, Massachusetts, </address> <month> Octo-ber </month> <year> 1996. </year>
Reference-contexts: The generated C code has the same general structure as the C elision, with a few additional statements. In lines 4-5, an activation frame is allocated for fib and initialized. The Cilk runtime system uses activation frames to represent procedure instances. Using techniques similar to <ref> [16, 17] </ref>, our inlined allocator typically takes only a few cycles. The frame is initialized in line 5 by storing a pointer to a static structure, called a signature, describing fib. The first spawn in fib is translated into lines 12-18.
Reference: [18] <author> Christopher F. Joerg. </author> <title> The Cilk System for Parallel Multi-threaded Computing. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> January </month> <year> 1996. </year>
Reference-contexts: 1 Introduction Cilk is a multithreaded language for parallel programming that generalizes the semantics of C by introducing linguistic constructs for parallel control. The original Cilk-1 release <ref> [3, 4, 18] </ref> featured a provably efficient, randomized, "work-stealing" scheduler [3, 5], but the language was clumsy, because parallelism was exposed "by hand" using explicit continuation passing. The Cilk language implemented by This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) under Grant N00014-94-1-0985.
Reference: [19] <author> Robert H. Halstead Jr. </author> <title> Multilisp: A language for concurrent symbolic computation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(4) </volume> <pages> 501-538, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: The abort statement, when executed inside an inlet, causes all of the already-spawned children of the procedure to terminate. We considered using "futures" <ref> [19] </ref> with implicit synchronization, as well as synchronizing on specific variables, instead of using the simple spawn and sync statements. We realized from the work-first principle, however, that different synchronization mechanisms could have an impact only on the critical-path of a computation, and so this issue was of secondary concern.
Reference: [20] <author> Leslie Lamport. </author> <title> How to make a multiprocessor computer that correctly executes multiprocess programs. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-28(9):690-691, </volume> <month> September </month> <year> 1979. </year>
Reference-contexts: The exception mechanism is used to implement Cilk's abort statement. Interestingly, this extension does not introduce any additional work overhead. The pseudocode of the simplified THE protocol is shown in Figure 4. Assume that shared memory is sequentially consistent <ref> [20] </ref>. 8 The code assumes that the ready deque is implemented as an array of frames. The head and tail of the deque are determined by two indices T and H, which are stored in shared memory and are visible to all processors.
Reference: [21] <author> Phillip Lisiecki and Alberto Medina. </author> <type> Personal communication. </type>
Reference-contexts: Recent work by Arora et al. [2] has shown that a completely nonblocking work-stealing scheduler can be implemented. Using these ideas, Lisiecki and Medina <ref> [21] </ref> have modified the Cilk-5 scheduler to make it completely non-blocking. Their experience is that the THE protocol greatly simplifies a nonblocking implementation. The simplified THE protocol can be extended to support the signaling of exceptions to a worker.
Reference: [22] <author> James S. Miller and Guillermo J. Rozas. </author> <title> Garbage collection is fast, but a stack is faster. </title> <type> Technical Report Memo 1462, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: For a careful analysis of the relative merits of stack and heap based allocation that supports heap allocation, see the paper by Appel and Shao [1]. For an equally careful analysis that supports stack allocation, see <ref> [22] </ref>. Thus, although the work-first principle gives a general understanding of where overheads should be borne, our experience with Cilk-4 showed that large enough critical-path overheads can tip the scales to the point where the assumptions underlying the principle no longer hold.
Reference: [23] <author> Robert C. Miller. </author> <title> A type-checking preprocessor for Cilk 2, a multithreaded C language. </title> <type> Master's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Specifically, move overheads out of the work and onto the critical path. The work-first principle played an important role during the design of earlier Cilk systems, but Cilk-5 exploits the principle more extensively. The work-first principle inspired a "two-clone" strategy for compiling Cilk programs. Our cilk2c compiler <ref> [23] </ref> is a type-checking, source-to-source translator that transforms a Cilk source into a C postsource which makes calls to Cilk's runtime library. The C postsource is then run through the gcc compiler to produce object code.
Reference: [24] <author> Eric Mohr, David A. Kranz, and Robert H. Halstead, Jr. </author> <title> Lazy task creation: A technique for increasing the granularity of parallel programs. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2(3) </volume> <pages> 264-280, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Lastly, we describe how the runtime system links together the actions of the fast and slow clones to produce a complete Cilk implementation. As in lazy task creation <ref> [24] </ref>, in Cilk-5 each processor, called a worker , maintains a ready deque (doubly-ended queue) of ready procedures (technically, procedure instances). Each deque has two ends, a head and a tail , from which procedures can be added or removed. <p> Mohr et al. <ref> [24] </ref> introduced lazy task creation in their implementation of the Mul-T language. Lazy task creation is similar in many ways to our lazy scheduling techniques. Mohr et al. report a work overhead of around 2 when comparing with serial T, the Scheme dialect on which Mul-T is based.
Reference: [25] <author> Joel Moses. </author> <title> The function of FUNCTION in LISP or why the FUNARG problem should be called the environment problem. </title> <type> Technical Report memo AI-199, </type> <institution> MIT Artificial Intelligence Laboratory, </institution> <month> June </month> <year> 1970. </year> <month> 11 </month>
Reference-contexts: In Cilk-4, the precursor to Cilk-5, we took the work-first principle to the extreme. Cilk-4 performed stack-based allocation of activation frames, since the work overhead of stack allocation is smaller than the overhead of heap allocation. Because of the "cactus stack" <ref> [25] </ref> semantics of the Cilk stack, 6 however, Cilk-4 had to manage the virtual-memory map on each processor explicitly, as was done in [27].
Reference: [26] <author> Rishiyur Sivaswami Nikhil. </author> <booktitle> Parallel Symbolic Computing in Cid. In Proc. Wkshp. on Parallel Symbolic Computing, </booktitle> <address> Beaune, France, </address> <publisher> Springer-Verlag LNCS 1068, </publisher> <pages> pages 217-242, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Mohr et al. report a work overhead of around 2 when comparing with serial T, the Scheme dialect on which Mul-T is based. Our research confirms the intuition behind their methods and shows that work overheads of close to 1 are achievable. The Cid language <ref> [26] </ref> is like Cilk in that it uses C as a base language and has a simple preprocessing compiler to convert parallel Cid constructs to C.
Reference: [27] <author> Per Stenstrom. </author> <title> VLSI support for a cactus stack oriented memory organization. </title> <booktitle> Proceedings of the Twenty-First Annual Hawaii International Conference on System Sciences, </booktitle> <volume> volume 1, </volume> <pages> pages 211-220, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Because of the "cactus stack" [25] semantics of the Cilk stack, 6 however, Cilk-4 had to manage the virtual-memory map on each processor explicitly, as was done in <ref> [27] </ref>. The work overhead in Cilk-4 for frame allocation was little more than that of incrementing the stack pointer, but whenever the stack pointer overflowed a page, an expensive user-level interrupt ensued, during which Cilk-4 would modify the memory map.
Reference: [28] <author> Leslie G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <month> August </month> <year> 1990. </year> <month> 12 </month>
Reference-contexts: First, we assume that Cilk's scheduler operates in practice according to the theoretical analysis presented in [3, 5]. Second, we assume that in the common case, ample "parallel slackness" <ref> [28] </ref> exists, that is, the average parallelism of a Cilk program exceeds the number of processors on which we run it by a sufficient margin. Third, we assume (as is indeed the case) that every Cilk program has a C elision against which its one-processor performance can be measured. <p> Define the average parallelism as P = T 1 =T 1 , which corresponds to the maximum possible speedup that the application can obtain. Define also the parallel slackness <ref> [28] </ref> to be the ratio P =P . The assumption of parallel slackness is that P =P c 1 , which means that the number P of processors is much smaller than the average parallelism P .
References-found: 28

