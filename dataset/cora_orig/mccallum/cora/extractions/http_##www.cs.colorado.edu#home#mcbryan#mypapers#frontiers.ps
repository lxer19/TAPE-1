URL: http://www.cs.colorado.edu/home/mcbryan/mypapers/frontiers.ps
Refering-URL: http://www.cs.colorado.edu/home/mcbryan/mypapers.html
Root-URL: http://www.cs.colorado.edu
Title: SOFTWARE ISSUES AT THE USER INTERFACE  
Author: Oliver A. McBryan* 
Date: August 1990.  
Note: Presented at Frontiers of Supercomputing II: A National Reassesessment, Los Alamos National Laboratory,  Research supported by the Air Force Office of Scientific Research, under grant AFOSR-89-0422  
Address: Boulder, CO 80309  
Affiliation: Department of Computer Science University of Colorado  
Abstract: We review software issues that are critical to the successful integration of parallel computers into mainstream scientific computing. Clearly a compiler is the most important software tool available to a user on most systems. We discuss compilers from the point of view of communication compilation their ability to generate efficient communication code automatically. We illustrate with two examples of distributed memory computers where almost all communication is handled by the compiler rather than by explicit calls to communication libraries. Closely related to compilation is the need for high quality debuggers. While single node debuggers are important, parallel machines have their own specialized debugging needs related to the complexity of interprocess communication and synchronization. We describe a powerful simulation tool we have developed for such systems and which has proved essential in porting large applications to distributed memory systems. Other important software tools include high level languages, libraries and visualization software. We discuss aspects of these systems briefly. Ultimately however, general purpose supercomputing environments are likely to include more than a single computer system. Parallel computers are often highly specialized, and rarely provide all of the facilities required by a complete application. Over the coming decade we will see the development of heterogeneous environments connecting diverse supercomputers (scalar, vector and parallel) along with high end graphics, disk farms and networking hubs. The real user interface challenge will then be to provide a unified picture of such systems to potential users. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> O. McBryan and R. Pozo, </author> <title> ``Performance Evaluation of the Myrias SPS-2 Computer,'' </title> <note> CS Dept Technical Report CU-CS-505-90 (to appear in Concurrency: Practice and Experience), </note> <institution> University of Colorado, Boulder, </institution> <year> 1990. </year>
Reference: 2. <author> O. McBryan, </author> <title> ``Optimization of Connection Machine Performance,'' </title> <journal> International Journal of High Speed Computing, </journal> <volume> vol. 2, no. 1, </volume> <pages> pp. 23-48, </pages> <year> 1990. </year>
Reference: 3. <author> O. McBryan, </author> <title> ``The Connection Machine: PDE Solution on 65536 Processors,'' </title> <journal> Parallel Computing, </journal> <volume> vol. 9, </volume> <pages> pp. 1-24, </pages> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference: 4. <author> M. Rosing and R. B. Schnabel, </author> <title> ``An Overview of Dino -- A New Language for Numerical Computation on Distributed Memory Multiprocessors,'' in Parallel Processing for Scientific Computation, </title> <editor> ed. G. </editor> <booktitle> Rodrigue, </booktitle> <pages> pp. 312-316, </pages> <publisher> SIAM, </publisher> <address> Philadephia, </address> <year> 1989. </year>
Reference: 5. <author> K. Solchenbach and U. Trottenberg, </author> <title> ``SUPRENUM System essentials and grid applications,'' </title> <journal> Parallel Computing, </journal> <volume> vol. 7, </volume> <publisher> North Holland, </publisher> <year> 1988. </year>
Reference: 6. <author> L. Compagnoni, S. Crivelli, S. Goldhaber, R. Loft, O. McBryan, A. Repenning, and R. Speer, </author> <title> A Simple Heterogeneous Computing Environment: Interfacing Graphics Workstations to a Connection Machine., </title> <type> CS Dept Technical Report, </type> <institution> University of Colorado, Boulder, </institution> <year> 1991, </year> <note> in preparation. </note>
Reference: 7. <author> Arnould, E. A., Bitz, F. J., Cooper, E. C., Kung, H. T., Sansom, R. D., and Steenkiste, P. A., </author> <title> ``The Design of Nectar: A Network Backplane for Heterogeneous Multicomputers,'' </title> <booktitle> in Proceedings of Third International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS III), </booktitle> <pages> pp. 205-216, </pages> <publisher> ACM, </publisher> <month> Apr </month> <year> 1989. </year>
Reference: 8. <author> C. Farhat, S. Lanteri, and L. Fezoui, </author> <title> ``Mixed Finite Volume/Finite Element Massively Parallel Computations: Euler Flows, Unstructured Grids, and Upwind Approximations,'' in Unstructured Massively Parallel Computations, </title> <editor> ed. R. Voigt, </editor> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference: 9. <author> A. Saati, S. Biringen, and C. Farhat, </author> <title> ``Solving Navier-Stokes Equations on a Massively Parallel Processor: Beyond the One Gigaflop Performance,'' </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> vol. 4, no. 1, </volume> <pages> pp. 72-80, </pages> <year> 1990. </year>
Reference: 10. <author> C. Farhat, N. Sobh, and K. C. Park, </author> <title> ``Transient Finite Element Computations on 65,536 Processors: </title> <journal> The Connection Machine,'' International Journal for Numerical Methods in Engineering, </journal> <volume> vol. 30, </volume> <pages> pp. 27-55, </pages> <year> 1990. </year>
References-found: 10

