URL: http://wwwipd.ira.uka.de/~prechelt/Biblio/patseries_st98.ps.gz
Refering-URL: 
Root-URL: 
Phone: +49/721/608-4068, Fax: +49/721/608-7343  
Title: A Series of Controlled Experiments on Design Patterns:  
Address: D-76128 Karlsruhe, Germany  
Affiliation: Fakultat fur Informatik, Universitat Karlsruhe  
Note: To appear in Proc. Softwaretechnik `98 (Softwaretechnik-Trends)  
Abstract: Methodology and Results Abstract Software design patterns are an idea that is intuitively appealing and has found many advocates. However, as scientists we must be concerned about gathering hard evidence for the claims of beneficial consequences of design patterns. This article describes the major claims and derives the corresponding research questions. It discusses the methodology of a research programme for investigating these questions and sketches the practical constraints that make this research difficult. It then shortly summarizes three controlled experiments that were successfully carried out within these constraints and lists the main results and their consequences, such as: One should document design patterns when they are used and one must not apply design patterns without judgement of alternatives. Finally, design considerations of a fourth experiment are discussed. The contribution of this paper is a description of important methodological aspects of practical experimental work and how these relate to the results obtained. Understanding these relations will be important in future empirical software engineering research. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Beck, J.O. Coplien, R. Crocker, L. Dominick, G. Meszaros, F. Paulisch, and J. Vlissides. </author> <title> Industrial experience with design patterns. </title> <booktitle> In 18th Intl. Conf. on Software Engineering, </booktitle> <pages> pages 103-114, </pages> <address> Berlin, March 1996. </address> <publisher> IEEE CS press. </publisher>
Reference-contexts: Other books followed, e.g. [2, 12], annual workshops are being held [11] to promote pattern mining and a consistent style of reporting patterns. Pattern practitioners published anecdo tal reports of successful use of design patterns in real projects and claim various advantages compared to former practice <ref> [1] </ref>. 1.1 The 'object-orientation effect' again? The enthusiasm with which design patterns are currently being adopted reminds one of the days when object-orientation (o-o) became popular: Huge successes were reported and many believed o-o to be the silver bullet.
Reference: [2] <author> Frank Buschmann, Regine Meunier, Hans Rohn-ert, Peter Sommerlad, and Michael Stal. </author> <title> Pattern-Oriented Software Architecture | A System of Patterns. </title> <publisher> John Wiley and Sons, </publisher> <address> Chichester, UK, </address> <year> 1996. </year>
Reference-contexts: The pattern literature is burgeoning. The first systematic collection of design patterns was published by Gamma, Helms, Johnson, and Vlissides [5] (nicknamed the "Gang of Four Book") and was a huge success. Other books followed, e.g. <ref> [2, 12] </ref>, annual workshops are being held [11] to promote pattern mining and a consistent style of reporting patterns.
Reference: [3] <author> Larry B. Christensen. </author> <title> Experimental Methodology. </title> <publisher> Allyn and Bacon, </publisher> <address> Needham Heights, MA, 6th edition, </address> <year> 1994. </year>
Reference-contexts: The discussion leads to certain design decisions for the research approach to assessing design patterns. 2.2.1 Laboratory versus field research The most fundamental distinction in empirical software engineering work is between studies in a 'clean', controlled laboratory setting (controlled experiments, <ref> [3] </ref>) versus studies 'in vivo', in real software engineering environments (field studies). The latter come either in the form of live observation or as postmortem data analysis ("software archeology"). Note that the laboratory versus field distinction is fuzzy because field studies may exhibit a semi-controlled environment, e.g. in case studies.
Reference: [4] <author> Bradley Efron and Robert Tibshirani. </author> <title> An introduction to the Bootstrap. Monographs on statistics and applied probability 57. </title> <publisher> Chapman and Hall, </publisher> <address> New York, London, </address> <year> 1993. </year>
Reference-contexts: The "points" judge the correctness of a solution. "Relevant points" are the points for the pattern-relevant subtasks only. Many distributions were distinctly non-normal, therefore I and p were computed using the percentile method after 10000 trials of Bootstrap resampling <ref> [4] </ref>. design pattern (PAT) version and the simpler alternative (ALT) version. Each dot marks one subject, the square is the arithmetic mean, the non-dotted line next to the square indicates plus/minus one standard error of the mean.
Reference: [5] <author> Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. </author> <title> Design Patterns: Elements of Reusable Object-Oriented Software. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1995. </year>
Reference-contexts: The idea of software design patterns is intuitively appealing and has quickly caught the attention of both practitioners and researchers. The pattern literature is burgeoning. The first systematic collection of design patterns was published by Gamma, Helms, Johnson, and Vlissides <ref> [5] </ref> (nicknamed the "Gang of Four Book") and was a huge success. Other books followed, e.g. [2, 12], annual workshops are being held [11] to promote pattern mining and a consistent style of reporting patterns.
Reference: [6] <author> Adam A. Porter, Harvey Siy, Carol A. Toman, and Lawrence G. Votta. </author> <title> An experiment to assess the cost-benefits of code inspections in large scale software development. </title> <booktitle> In Proc. Third ACM Sig-soft Symposium on the Foundations of Software Engineering, </booktitle> <year> 1995. </year>
Reference-contexts: See <ref> [6] </ref> as an example. 2.2.2 Subjects At the center of any empirical laboratory study are the designers or programmers. These subjects may either be junior or senior software professionals or students.
Reference: [7] <author> Lutz Prechelt. </author> <title> An experiment on the usefulness of design patterns: Detailed description and evaluation. </title> <type> Technical Report 9/1997, </type> <institution> Fakultat fur In-formatik, Universitat Karlsruhe, Germany, </institution> <month> June </month> <year> 1997. </year> <month> ftp.ira.uka.de. </month>
Reference-contexts: Even the latter programs were so thoroughly documented that quantitatively the removal of the design pattern documentation should not make any difference unless some specific quality of design pattern documentation is indeed important. The full documentation of the experiment is <ref> [7, 9, 8] </ref>. Question: Is claim CM true? Actually, our experiment avoids a severe problem for testing this claim: If one compared programs with patterns to different programs without, it would be unclear whether the results originate from communication improvements or from structural program differences.
Reference: [8] <author> Lutz Prechelt, Barbara Unger, Michael Philippsen, and Walter F. Tichy. </author> <title> Two controlled experiments assessing the usefulness of design pattern information during program maintenance. Empirical Software Engineering, </title> .(.):., . <note> 1998. Submitted. http://wwwipd.ira.u-ka.de/~prechelt/Biblio/. </note>
Reference-contexts: Even the latter programs were so thoroughly documented that quantitatively the removal of the design pattern documentation should not make any difference unless some specific quality of design pattern documentation is indeed important. The full documentation of the experiment is <ref> [7, 9, 8] </ref>. Question: Is claim CM true? Actually, our experiment avoids a severe problem for testing this claim: If one compared programs with patterns to different programs without, it would be unclear whether the results originate from communication improvements or from structural program differences. <p> These differences are statistically significant. We find claim CM supported and conclude that the communication improvement may become visible as either a productivity or a quality improvement, depending on the situation (program, maintainers, schedule pressure, etc). See <ref> [8] </ref> for further discussion of these results. 3.2 Experiment 2: Patterns versus alternative designs [maintenance] Experiment 2 investigated whether using patterns is beneficial at all (aside from documenting them) and whether the difference depends on the level of pattern knowledge. The detailed description of the experiment is [10].
Reference: [9] <author> Lutz Prechelt, Barbara Unger, and Douglas Schmidt. </author> <title> Replication of the first controlled experiment on the usefulness of design patterns: Detailed description and evaluation. </title> <type> Technical Report wucs-97-34, </type> <institution> Washington University, Dept. of CS, St. Louis, </institution> <month> December </month> <year> 1997. </year>
Reference-contexts: Even the latter programs were so thoroughly documented that quantitatively the removal of the design pattern documentation should not make any difference unless some specific quality of design pattern documentation is indeed important. The full documentation of the experiment is <ref> [7, 9, 8] </ref>. Question: Is claim CM true? Actually, our experiment avoids a severe problem for testing this claim: If one compared programs with patterns to different programs without, it would be unclear whether the results originate from communication improvements or from structural program differences. <p> Results: For one of the programs (involving an Observer pattern), the group with pattern documentation was much faster than the other in 1a; see also Table 1. Refer to <ref> [9] </ref> for a discussion of the more complex 1b results. For the other program (involving a Composite and a Visitor pattern), the group with pattern documentation either had far fewer errors (1a) or required less time (1b). These differences are statistically significant.
Reference: [10] <author> Lutz Prechelt, Barbara Unger, Walter F. Tichy, Peter Brossler, and Lawrence G. Votta. </author> <title> A controlled experiment in maintenance comparing design patterns to simpler solutions. </title> <journal> IEEE Trans. on Software Engineering, </journal> <note> 1998. To be submitted. http://wwwipd.ira.uka.de/~prechelt/Biblio/. </note>
Reference-contexts: See [8] for further discussion of these results. 3.2 Experiment 2: Patterns versus alternative designs [maintenance] Experiment 2 investigated whether using patterns is beneficial at all (aside from documenting them) and whether the difference depends on the level of pattern knowledge. The detailed description of the experiment is <ref> [10] </ref>. Question: Is the use of patterns beneficial (during maintenance) compared to simpler solutions of the same problem? This question includes aspects of claims QE and CM and it leads to the methodological problem of what is a fair alternative to a pattern for the comparison. <p> Their purpose was representing and pret-typrinting Boolean Formulas consisting of And, Or, Xor and Not terms and variables. The alternative version replaced the Visitor by methods distributed over all term classes. There were multiple maintenance tasks for each program that are described in detail in <ref> [10] </ref>. Results: In the specific setting of the experiment, all three possible outcomes occurred: For the program 'Stock Ticker', involving an Observer, the pattern program version took longer to maintain, in particular when the subjects had low levels of pattern knowledge (pretest); see Figure 1.
Reference: [11] <author> Douglas Schmidt. </author> <title> Collected papers from the PLoP '96 and EuroPLoP '96 conferences. </title> <type> Technical Report wucs-97-07, </type> <institution> Washington University, Dept. of CS, St. Louis, </institution> <month> February </month> <year> 1997. </year> <booktitle> (Conference "Pattern languages of programs"). </booktitle>
Reference-contexts: The pattern literature is burgeoning. The first systematic collection of design patterns was published by Gamma, Helms, Johnson, and Vlissides [5] (nicknamed the "Gang of Four Book") and was a huge success. Other books followed, e.g. [2, 12], annual workshops are being held <ref> [11] </ref> to promote pattern mining and a consistent style of reporting patterns.
Reference: [12] <author> Mary Shaw and David Garlan. </author> <title> Software Architecture | Perspectives on an Emerging Discipline. </title> <publisher> Prentice Hall, </publisher> <year> 1996. </year> <month> 8 </month>
Reference-contexts: The pattern literature is burgeoning. The first systematic collection of design patterns was published by Gamma, Helms, Johnson, and Vlissides [5] (nicknamed the "Gang of Four Book") and was a huge success. Other books followed, e.g. <ref> [2, 12] </ref>, annual workshops are being held [11] to promote pattern mining and a consistent style of reporting patterns.
References-found: 12

