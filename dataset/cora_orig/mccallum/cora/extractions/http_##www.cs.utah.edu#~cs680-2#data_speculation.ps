URL: http://www.cs.utah.edu/~cs680-2/data_speculation.ps
Refering-URL: http://www.cs.utah.edu/~cs680-2/index.html
Root-URL: 
Email: fsteffan,tcmg@cs.cmu.edu  
Title: The Potential for Using Thread-Level Data Speculation to Facilitate Automatic Parallelization  
Author: J. Gregory Steffan and Todd C. Mowry 
Address: Pittsburgh, PA 15213  
Affiliation: Computer Science Department Carnegie Mellon University  
Abstract: As we look to the future, and the prospect of a billion transistors on a chip, it seems inevitable that microprocessors will exploit having multiple parallel threads. To achieve the full potential of these single-chip multiprocessors, however, we must find a way to parallelize non-numeric applications. Unfortunately, compilers have had little success in parallelizing non-numeric codes due to their complex access patterns. This paper explores the potential for using thread-level data speculation (TLDS) to overcome this limitation by allowing the compiler to view parallelization solely as a cost/benefit tradeoff, rather than something which is likely to violate program correctness. Our experimental results demonstrate that with realistic compiler support, TLDS can offer significant program speedups. We also demonstrate that through modest hardware extensions, a generic single-chip multiprocessor could support TLDS by augmenting its cache coherence scheme to detect dependence violations, and by using the primary data caches to buffer speculative state. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Bugnion, J. M. Anderson, T. C. Mowry, M. Rosenblum, and M. S. Lam. </author> <title> Compiler-Directed Page Coloring for Multi processors. </title> <booktitle> In Proceedings of ASPLOS-VII, </booktitle> <pages> pages 244255, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: Instead, the preferred solution would be for the compiler to parallelize programs automatically. Unfortunately, compilers have only been successful so far at parallelizing the numeric applications commonly run on supercomputers <ref> [1, 7, 16] </ref>. For single-chip multiprocessing to have an impact on most users, we must also find a way to automatically parallelize non-numeric applications.
Reference: [2] <author> M. Fillo, S. W. Keckler, W. J. Dally, N. P. Carter, A. Chang, Y. Gurevich, and W. S. Lee. </author> <title> The M-Machine Multicomputer. </title> <booktitle> In Proceedings of ISCA 28, </booktitle> <month> December </month> <year> 1995. </year>
Reference-contexts: A number of options have been proposed, including integrating main memory onto the processor chip [17], supporting wider instruction issue, and executing multiple threads of control in parallel <ref> [2, 14, 24] </ref>. While these options may be mutually exclusive in the short term due to transistor constraints, in the long term we will eventually have enough resources to potentially combine several of these options. 0 To appear in HPCA-4, February 1-4, 1998. <p> Otherwise, all remaining cross-epoch register dependences are explicitly forwarded through memory. In addition to a data transfer mechanism, forwarding data also requires a form of producer-consumer synchronization (e.g., wait/signal or full/empty bits <ref> [2, 18] </ref>) so that the receiving processor knows when the value is ready. If multiple values are to be forwarded, the synchronization can occur at either a coarse granularity (once per epoch) or a fine granularity (once per value), as illustrated in Figures 4 (a) and 4 (b).
Reference: [3] <author> M. Franklin. </author> <title> The Multiscalar Architecture. </title> <type> PhD thesis, </type> <institution> Uni versity of Wisconsin Madison, </institution> <year> 1993. </year>
Reference-contexts: While instruction-level data speculation has received much attention [5, 9, 20], the only relevant work on thread-level data speculation for non-numeric codes when we performed our study was the Wisconsin Multiscalar architecture <ref> [3, 4, 21] </ref>. This tightly-coupled ring architecture assigns threads around the ring in program order, provides a hardware mechanism for forwarding register values between processors, and uses a centralized structure called the address resolution buffer (ARB) [4, 21] to detect data dependences through memory. <p> In addition to forwarding scalar memory dependences, we must also forward any register dependences. In contrast with the Multiscalar architecture <ref> [3, 4, 21] </ref>, we do not assume any register forwarding hardwareinstead, we forward register values explicitly through memory.
Reference: [4] <author> M. Franklin and G. S. Sohi. ARB: </author> <title> A Hardware Mecha nism for Dynamic Reordering of Memory References. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 45(5), </volume> <month> May </month> <year> 1996. </year>
Reference-contexts: While instruction-level data speculation has received much attention [5, 9, 20], the only relevant work on thread-level data speculation for non-numeric codes when we performed our study was the Wisconsin Multiscalar architecture <ref> [3, 4, 21] </ref>. This tightly-coupled ring architecture assigns threads around the ring in program order, provides a hardware mechanism for forwarding register values between processors, and uses a centralized structure called the address resolution buffer (ARB) [4, 21] to detect data dependences through memory. <p> This tightly-coupled ring architecture assigns threads around the ring in program order, provides a hardware mechanism for forwarding register values between processors, and uses a centralized structure called the address resolution buffer (ARB) <ref> [4, 21] </ref> to detect data dependences through memory. When an unsafe speculation is detected, a purely hardware-based mechanism squashes computation in reverse order around the ring until it can be safely restarted. <p> In addition to forwarding scalar memory dependences, we must also forward any register dependences. In contrast with the Multiscalar architecture <ref> [3, 4, 21] </ref>, we do not assume any register forwarding hardwareinstead, we forward register values explicitly through memory.
Reference: [5] <author> D. M. Gallagher, W. Y. Chen, S. A. Mahlke, J. C. Gyllenhaal, and W. W. Hwu. </author> <title> Dynamic Memory Disambiguation Using the Memory Conflict Buffer. </title> <booktitle> In Proceedings of ASPLOS-VI, </booktitle> <pages> pages 183195, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: At run-time, we can verify the safety of this speculation through either a simple software check or with special hardware support <ref> [5] </ref>. Thread-Level Data Speculation (TLDS) is analogous to instruction-level data speculation, except that the load and store are executed by separate threads of control which run in parallel, as illustrated in Figure 1 (c). <p> When such dependence violations are detected, a recovery action is taken such as partially re-executing the thread which performed the failed speculative load. While instruction-level data speculation has received much attention <ref> [5, 9, 20] </ref>, the only relevant work on thread-level data speculation for non-numeric codes when we performed our study was the Wisconsin Multiscalar architecture [3, 4, 21].
Reference: [6] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Pro ceedings of ISCA 17, </booktitle> <pages> pages 1526, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Since the synchronization indicating the oldest epoch is serialized, the memory consistency of the original sequential program will be preserved. Also, since the acts of waiting upon and signaling the oldest state are acquire and release operations, respectively, we can exploit relaxed memory consistency models <ref> [6, 11] </ref>. the thread immediately squashes any subsequent epochs and then recovers by re-executing the epoch body non-speculatively. This process could be optimized in several ways. First, an epoch could be interrupted and begin the recovery process immediately upon a data dependence violation.
Reference: [7] <author> G. Goff, K. Kennedy, and C. W. Tseng. </author> <title> Practical depen dence testing. </title> <booktitle> In Proceedings of PLDI '91, </booktitle> <pages> pages 1529, </pages> <month> June </month> <year> 1991. </year>
Reference-contexts: Instead, the preferred solution would be for the compiler to parallelize programs automatically. Unfortunately, compilers have only been successful so far at parallelizing the numeric applications commonly run on supercomputers <ref> [1, 7, 16] </ref>. For single-chip multiprocessing to have an impact on most users, we must also find a way to automatically parallelize non-numeric applications. <p> One of the primary challenges in automatic paralleliza-tion is determining whether data dependences exist between two potential threads that would prevent them from running safely in parallel. To address this problem in numeric codes, a considerable amount of research has focused on analyzing array accesses within DO loops <ref> [7] </ref>. Although progress has been made in this area, the problem is considerably more 1 (a) Original Execution (b) Instruction-Level Data Speculation (c) Thread-Level Data Speculation difficult for non-numeric codes due to their complex access patterns, including pointers to heap-allocated objects and complex control flow.
Reference: [8] <author> S. Gopal, T. N. Vijaykumar, J. E. Smith, and G. S. Sohi. </author> <title> Speculative Versioning Cache. </title> <type> Technical Report 1334, </type> <institution> Computer Sciences Department, University of Wisconsin Madison, </institution> <month> July </month> <year> 1997. </year>
Reference-contexts: Instead, we would prefer a more flexible topology where computation can be placed wherever we wish. (Concurrent with our work, researchers in the Stanford Hydra and Wisconsin Multiscalar projects have also explored distributed approaches to TLDS <ref> [8, 15] </ref>.) 1.2. Objectives and Overview Our goals in this paper are threefold: to quantify the potential performance advantages of TLDS, to propose cost-effective hardware support for TLDS, and to gain insight into the compiler support necessary to effectively exploit 2 TLDS.
Reference: [9] <author> A. S. Huang, G. Slavenburg, and J. P. Shen. </author> <title> Speculative Dis ambiguation: A Compilation Technique For Dynamic Mem ory Disambiguation. </title> <booktitle> In Proceedings of ISCA 21, </booktitle> <pages> pages 200 210, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: When such dependence violations are detected, a recovery action is taken such as partially re-executing the thread which performed the failed speculative load. While instruction-level data speculation has received much attention <ref> [5, 9, 20] </ref>, the only relevant work on thread-level data speculation for non-numeric codes when we performed our study was the Wisconsin Multiscalar architecture [3, 4, 21].
Reference: [10] <author> N. P. Jouppi. </author> <title> Improving Direct-Mapped Cache Performance by the Addition of a Small Fully-Associative Cache and Prefetch Buffers. </title> <booktitle> In Proceedings of ISCA 17, </booktitle> <pages> pages 364 373, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Since the threads are speculative, any stores which they perform must be buffered until it is certain that their results can be safely committed to memory. In this example, the first three epochs successfully complete without any problems. The fourth epoch, however, reads the value hash <ref> [10] </ref> before it is modified by epoch 1since this violates the original program semantics, we must recover by re-executing epoch 4. <p> Finally, rather than giving up when a speculatively accessed line is displaced, we could instead capture these lines within a small fully-associative victim cache <ref> [10] </ref>. Figure 9 (c) shows that by adding a relatively small victim cache (e.g., with four entries) to a 16KB two-way set-associative cache, we can retain nearly all speculatively accessed lines, thus avoiding unnecessary recovery.
Reference: [11] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy Release Consistency for Software Distributed Shared Memory. </title> <booktitle> In Proceedings of ISCA 19, </booktitle> <pages> pages 1321, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Since the synchronization indicating the oldest epoch is serialized, the memory consistency of the original sequential program will be preserved. Also, since the acts of waiting upon and signaling the oldest state are acquire and release operations, respectively, we can exploit relaxed memory consistency models <ref> [6, 11] </ref>. the thread immediately squashes any subsequent epochs and then recovers by re-executing the epoch body non-speculatively. This process could be optimized in several ways. First, an epoch could be interrupted and begin the recovery process immediately upon a data dependence violation.
Reference: [12] <author> A. Nicolau. </author> <title> Run-time Disambiguation: Coping with Stat ically Unpredictable Dependencies. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38:663678, </volume> <month> May </month> <year> 1989. </year>
Reference-contexts: Given the potentially large number of addresses that must be compared against each other to determine safety, and given the fact that the exact interleaving of accesses between threads is unknown a priori since they run asynchronously, a purely software-based approach of explicitly comparing memory addresses <ref> [12] </ref> would appear to be impractical. Instead, we propose extending a basic invalidation-based writeback cache coherence protocol to allow hardware to detect potential dependence violations with little overhead. The basic intuition behind our scheme is as follows.
Reference: [13] <author> R. S. Nikhil and Arvind. </author> <title> Can Dataflow Subsume Von Neu mann Computing. </title> <booktitle> In Proceedings of ISCA 16, </booktitle> <pages> pages 262 272, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: First, we need a way to create parallel threads and schedule the epochs onto them. One option is to dynamically create a new thread per epoch (perhaps using a lightweight fork instruction <ref> [13] </ref>), and another is to statically create one thread per processor and have them execute multiple epochs. Second, since dependence violations are detected by comparing epoch numbers, a mechanism is needed such that each thread's epoch number will be visible to the hardware.
Reference: [14] <author> K. Olukotun, B. A. Nayfeh, L. Hammond, K. Wilson, and K. Chang. </author> <title> The Case for a Single-Chip Multiprocessor. </title> <booktitle> In Proceedings of ASPLOS-VII, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: A number of options have been proposed, including integrating main memory onto the processor chip [17], supporting wider instruction issue, and executing multiple threads of control in parallel <ref> [2, 14, 24] </ref>. While these options may be mutually exclusive in the short term due to transistor constraints, in the long term we will eventually have enough resources to potentially combine several of these options. 0 To appear in HPCA-4, February 1-4, 1998.
Reference: [15] <author> J. Oplinger, D. Heine, S.-W. Liao, B. A. Nayfeh, M. S. Lam, and K. Olukotun. </author> <title> Software and Hardware for Exploiting Speculative Parallelism with a Multiprocessor. </title> <type> Technical Re port CSL-TR-97-715, </type> <institution> Stanford University, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: Instead, we would prefer a more flexible topology where computation can be placed wherever we wish. (Concurrent with our work, researchers in the Stanford Hydra and Wisconsin Multiscalar projects have also explored distributed approaches to TLDS <ref> [8, 15] </ref>.) 1.2. Objectives and Overview Our goals in this paper are threefold: to quantify the potential performance advantages of TLDS, to propose cost-effective hardware support for TLDS, and to gain insight into the compiler support necessary to effectively exploit 2 TLDS.
Reference: [16] <author> L. Rauchwerger and D. Padua. </author> <title> The LRPD Test: Specula tive Run-Time Parallelization of Loops With Privatization and Reduction Parallelization. </title> <booktitle> In Proceedings of PLDI '95, </booktitle> <pages> pages 218232, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Instead, the preferred solution would be for the compiler to parallelize programs automatically. Unfortunately, compilers have only been successful so far at parallelizing the numeric applications commonly run on supercomputers <ref> [1, 7, 16] </ref>. For single-chip multiprocessing to have an impact on most users, we must also find a way to automatically parallelize non-numeric applications.
Reference: [17] <author> A. Saulsbury, F. Pong, and A. Nowatzyk. </author> <title> Missing the Mem ory Wall: The Case For Processor/Memory Integration. </title> <booktitle> In Proceedings of ISCA 23, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: A number of options have been proposed, including integrating main memory onto the processor chip <ref> [17] </ref>, supporting wider instruction issue, and executing multiple threads of control in parallel [2, 14, 24].
Reference: [18] <author> B. J. Smith. </author> <booktitle> Architecture and Applications of the HEP Mul tiprocessor Computer System. SPIE, </booktitle> <address> 298:241248, </address> <year> 1981. </year>
Reference-contexts: Otherwise, all remaining cross-epoch register dependences are explicitly forwarded through memory. In addition to a data transfer mechanism, forwarding data also requires a form of producer-consumer synchronization (e.g., wait/signal or full/empty bits <ref> [2, 18] </ref>) so that the receiving processor knows when the value is ready. If multiple values are to be forwarded, the synchronization can occur at either a coarse granularity (once per epoch) or a fine granularity (once per value), as illustrated in Figures 4 (a) and 4 (b).
Reference: [19] <author> M. D. Smith. </author> <title> Tracing with pixie. </title> <type> Technical Report CSL-TR 91-497, </type> <institution> Stanford University, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: We compiled these applications with -O2 optimization using the standard MIPS compilers under IRIX 5.3, and did not modify the source code or object files in any way throughout this study. Our simulator reads traces generated by the MIPS pixie utility <ref> [19] </ref>, and models a perfectly-pipelined single-issue processor where each instruction completes in a single cycle. To locate speculative regionsi.e. sections of code that we wish to parallelize using TLDSwe first used the IRIX prof utility to identify regions that account for a large portion of total execution time.
Reference: [20] <author> M. D. Smith. </author> <title> Support for Speculative Execution in High Performance Processors. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: When such dependence violations are detected, a recovery action is taken such as partially re-executing the thread which performed the failed speculative load. While instruction-level data speculation has received much attention <ref> [5, 9, 20] </ref>, the only relevant work on thread-level data speculation for non-numeric codes when we performed our study was the Wisconsin Multiscalar architecture [3, 4, 21].
Reference: [21] <author> G. S. Sohi, S. Breach, and T. N. Vijaykumar. </author> <title> Multiscalar Processors. </title> <booktitle> In Proceedings of ISCA 22, </booktitle> <pages> pages 414425, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: While instruction-level data speculation has received much attention [5, 9, 20], the only relevant work on thread-level data speculation for non-numeric codes when we performed our study was the Wisconsin Multiscalar architecture <ref> [3, 4, 21] </ref>. This tightly-coupled ring architecture assigns threads around the ring in program order, provides a hardware mechanism for forwarding register values between processors, and uses a centralized structure called the address resolution buffer (ARB) [4, 21] to detect data dependences through memory. <p> This tightly-coupled ring architecture assigns threads around the ring in program order, provides a hardware mechanism for forwarding register values between processors, and uses a centralized structure called the address resolution buffer (ARB) <ref> [4, 21] </ref> to detect data dependences through memory. When an unsafe speculation is detected, a purely hardware-based mechanism squashes computation in reverse order around the ring until it can be safely restarted. <p> In addition to forwarding scalar memory dependences, we must also forward any register dependences. In contrast with the Multiscalar architecture <ref> [3, 4, 21] </ref>, we do not assume any register forwarding hardwareinstead, we forward register values explicitly through memory. <p> We find that the effects of false dependences due to this increased granularity are not detrimental to the performance of TLDS [23]. Third, we account for the time required to recover from unsuccessful speculation. In contrast with the Multiscalar architecture <ref> [21] </ref>, our model of TLDS involves software in the recovery process; hence we include an estimate of the time required to restore the initial state of the epoch and restart parallel execution, assuming that a violating epoch will wait to become the oldest epoch before attempting to restart. <p> Hence an important question is whether communicating through a shared L2 cache is fast enough, or whether faster communication mechanisms (e.g., direct register-to-register forwarding <ref> [21] </ref>) are strictly necessary. To address this question, we measured the impact of communication latency on our region speedups. Figure 6 includes the same cases shown earlier in Figure 5 (a), where the communication latency was assumed to be ten cycles (corresponding roughly to communicating through a shared L2 cache). <p> In contrast with the Multiscalar approach of performing rollback entirely in hardware <ref> [21] </ref>, we propose that software performs the bulk of the recovery process, and that hardware simply provides two key pieces of functionality: (i) detecting data dependence violations and notifying software when they occur, and (ii) buffering speculative stores so that software does not have to explicitly roll back their side effects
Reference: [22] <author> J. G. Steffan, C. B. Colohan, and T. C. Mowry. </author> <title> Architec tural Support for Thread-Level Data Speculation. </title> <institution> Techni cal Report CMU-CS-97-188, School of Computer Science, Carnegie Mellon University, </institution> <month> November </month> <year> 1997. </year>
Reference-contexts: In many cases, there is considerable flexibility in how these mechanisms might be implemented. Due to space constraints, our goal here is simply to raise the important issues rather than presenting a complete design (additional detail can be found in earlier publications <ref> [22, 23] </ref>). First, we need a way to create parallel threads and schedule the epochs onto them. <p> Further details on architectural support for TLDS can be found in a technical report <ref> [22] </ref>. 10 5. Compiler Support for TLDS The compiler clearly plays a crucial role in exploiting TLDS.
Reference: [23] <author> J. G. Steffan and T. C. Mowry. </author> <title> The Potential for Thread Level Data Speculation in Tightly-Coupled Multiproces sors. </title> <type> Technical Report CSRI-TR-356, </type> <institution> Computer Systems Research Institute, University of Toronto, </institution> <month> February </month> <year> 1997. </year>
Reference-contexts: If so, we explicitly identified these regions to our simulator through their instruction addresses. The simulator then measures the exact data dependences between epochs in each speculative region. (For further details on our experimental methodology, see <ref> [23] </ref>.) Since identifying speculative regions by hand was a time-consuming process, we were not able to explore all possible regions, particularly in large programs such as gcc. <p> Second, rather than tracking data dependences at a word granularity (as in Sections 3.3 and 3.2), we now track dependences at a cache line granularity of 32 bytes. We find that the effects of false dependences due to this increased granularity are not detrimental to the performance of TLDS <ref> [23] </ref>. Third, we account for the time required to recover from unsuccessful speculation. <p> In many cases, there is considerable flexibility in how these mechanisms might be implemented. Due to space constraints, our goal here is simply to raise the important issues rather than presenting a complete design (additional detail can be found in earlier publications <ref> [22, 23] </ref>). First, we need a way to create parallel threads and schedule the epochs onto them.
Reference: [24] <author> D. M. Tullsen, S. J. Eggers, and H. M. Levy. </author> <title> Simultaneous Multithreading: Maximizing On-Chip Parallelism. </title> <booktitle> In Pro ceedings of ISCA 22, </booktitle> <pages> pages 392403, </pages> <month> June </month> <year> 1995. </year> <month> 12 </month>
Reference-contexts: A number of options have been proposed, including integrating main memory onto the processor chip [17], supporting wider instruction issue, and executing multiple threads of control in parallel <ref> [2, 14, 24] </ref>. While these options may be mutually exclusive in the short term due to transistor constraints, in the long term we will eventually have enough resources to potentially combine several of these options. 0 To appear in HPCA-4, February 1-4, 1998.
References-found: 24

