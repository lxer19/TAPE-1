URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/papers/icec96_tutorial.ps.gz
Refering-URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/ea_general.html
Root-URL: http://ls11-www.informatik.uni-dortmund.de/people/baeck/ea_general.html
Title: Evolutionary Computation: An Overview  
Author: Thomas Back Hans-Paul Schwefel 
Address: Joseph-von-Fraunhofer-Str. 20 D-44227 Dortmund, Germany  D-44221 Dortmund, Germany  
Affiliation: Informatik Centrum Dortmund Center for Applied Systems Analysis (Casa)  Universitat Dortmund Fachbereich Informatik Lehrstuhl fur Systemanalyse  
Abstract: In this paper, we present an overview of the most important representatives of algorithms gleaned from natural evolution, so-called evolutionary algorithms. Evolution strategies, evolutionary programming, and genetic algorithms are summarized, with special emphasis on the principle of strategy parameter self-adaptation utilized by the first two algorithms to learn their own strategy parameters such as mutation variances and covariances. Some experimental results are presented which demonstrate the working principle and robustness of the self-adaptation methods used in evolution strategies and evolutionary programming. General principles of evolutionary algorithms are discussed, and we identify certain properties of natural evolution which might help to improve the problem solving capabilities of evolutionary algorithms even further. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. T. Alander. </author> <title> An indexed bibliography of genetic algorithms: </title> <type> Years 1957-1993. </type> <institution> Art of CAD Ltd, Espoo, Finland, </institution> <year> 1994. </year>
Reference: [2] <author> R. W. Anderson. </author> <title> Genetic mechanisms underlying the baldwin effect are evident in natural antibodies. </title> <editor> In J. R. McDonnell, R. G. Reynolds, and D. B. Fogel, editors, </editor> <booktitle> Proceedings of the Fourth Annual Conference on Evolutionary Programming, </booktitle> <pages> pages 547-564. </pages> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: flexible, starting with a coarse-grained, volume-oriented search and focusing on promising regions of the search space as the evolution proceeds. * Other topics, such as multi-cellularity and ontogeny of individuals, up to the development of their own brains (individual learning, such as accounted for by the Baldwin effect in evolution <ref> [2] </ref>), are usually not modeled in evolutionary algorithms. The self-adaptation of strategy parameters is just a first step into this direction, realizing the idea that each individual might have its own internal strategy to deal with its environment.
Reference: [3] <author> P. J. Angeline. </author> <title> The effects of noise on self-adaptive evolutionary optimization. </title> <editor> In L. J. Fogel, P. J. Angeline, and T. Back, editors, </editor> <booktitle> Proceedings of the Fifth Annual Conference on Evolutionary Programming. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference: [4] <author> Th. </author> <title> Back. Optimal mutation rates in genetic search. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth Interna tional Conference on Genetic Algorithms, </booktitle> <pages> pages 2-8. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: [5] <author> Th. </author> <title> Back. Evolutionary Algorithms in Theory and Practice. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1996. </year>
Reference: [6] <author> Th. Back, J. Heistermann, C. Kappler, and M. Zam-parelli. </author> <title> Evolutionary algorithms support refueling of pressurized water reactors. </title> <booktitle> In Proceedings of the Third IEEE Conference on Evolutionary Computation. </booktitle> <publisher> IEEE Press, </publisher> <address> Piscataway, NJ, </address> <year> 1996. </year>
Reference: [7] <author> Th. Back and M. Schutz. </author> <title> Intelligent mutation rate control in canonical genetic algorithms. </title> <editor> In Z. Ras, editor, </editor> <booktitle> Proceedings of the Ninth International Symposium on Methodologies for Intelligent Systems, Lecture Notes in Computer Science. </booktitle> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference: [8] <author> Th. Back and H.-P. Schwefel. </author> <title> Evolution strategies I: Variants and their computational implementation. </title> <editor> In G. Winter, J. Periaux, M. Galan, and P. Cuesta, editors, </editor> <booktitle> Genetic Algorithms in Engineering and Computer Science, chapter 6, </booktitle> <pages> pages 111-126. </pages> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1995. </year>
Reference: [9] <author> J. C. Bean. </author> <title> Genetics and random keys for sequences and optimization. </title> <type> Technical Report 92-43, </type> <institution> Department of Industrial and Operations Engineering, The University of Michigan, </institution> <address> Ann Arbor, MI, </address> <year> 1993. </year>
Reference-contexts: f1; : : :; ng ! f1; : : :; ng, a binary representation as used in canonical GAs is not well suited, because it is difficult to map binary strings to a permutation of integer values and preserve permutations under mutation and crossover (but it can be done, see <ref> [9] </ref>). Order-based GAs work directly on the permutation, applying specialized recombination (such as order crossover or partially matched crossover) and mutation operators (such as random exchanges of two elements of the permutation) which preserve permutations (see e.g. [24], pp. 166-179 for an overview). B.
Reference: [10] <author> H.-G. Beyer. </author> <title> Toward a theory of evolution strategies: Self-adaptation. </title> <journal> Evolutionary Computation, </journal> <volume> 3(3) </volume> <pages> 311-348, </pages> <year> 1995. </year>
Reference: [11] <author> L. Davis. </author> <title> Adapting operator probabilities in genetic algorithms. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 61-69. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference-contexts: Somewhere between evolution strategies and genetic algorithms, real-coded GAs typically do not use techniques of self-adaptation, but might utilize time-decreasing step sizes [38] or change operator probabilities based on their observed performance <ref> [11] </ref>. C. Classifier Systems Classifier Systems use an evolutionary algorithm to search the space of production rules (often encoded by strings over a ternary alphabet) of a learning system capable of induction and generalization [28] (see also [24], chapter 6).
Reference: [12] <editor> L. J. Eshelman, R. A. Caruna, and J. D. Schaffer. </editor> <title> Biases in the crossover landscape. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 10-19. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: [13] <editor> L. J. Eshelman and J. D. Schaffer. Crossover's niche. In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 9-14. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: [14] <author> T. C. Fogarty. </author> <title> Varying the probability of mutation in the genetic algorithm. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 104-109. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: [15] <author> D. B. Fogel. </author> <title> Evolving Artificial Intelligence. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> San Diego, CA, </address> <year> 1992. </year>
Reference: [16] <author> D. B. Fogel. </author> <title> Evolutionary Computation: Toward a New Philosophy of Machine Intelligence. </title> <publisher> IEEE Press, </publisher> <address> Piscataway, NJ, </address> <year> 1995. </year>
Reference-contexts: Mutation is guaranteed in any reproducing system in a positively entropic environment, and competition and selection are just the consequences of a population expanding in a finite environment (see e.g. [37], or <ref> [16] </ref>, chapter 2).
Reference: [17] <author> L. J. Fogel. </author> <title> Autonomous automata. </title> <journal> Industrial Research, </journal> <volume> 4 </volume> <pages> 14-19, </pages> <year> 1962. </year>
Reference: [18] <author> L. J. Fogel. </author> <title> Toward inductive inference automata. </title> <booktitle> In Proceedings of the International Federation for Information Processing Congress, </booktitle> <pages> pages 395-399, </pages> <address> Mu-nich, </address> <year> 1962. </year>
Reference: [19] <author> L. J. Fogel, A. J. Owens, and M. J. Walsh. </author> <title> Artificial Intelligence through Simulated Evolution. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1966. </year>
Reference: [20] <author> C. M. Fonseca and P. J. Fleming. </author> <title> An overview of evolutionary algorithms in multiobjective optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 3(1) </volume> <pages> 1-16, </pages> <year> 1995. </year>
Reference-contexts: In contrast, evolutionary algorithms often aim at finding a precise solution and converging to this solution. * In natural evolution, many criteria need to be met at the same time, while most evolutionary algorithms are designed for single fitness criteria (see <ref> [20] </ref> for an overview of the existing attempts to apply evolutionary algorithms to multiobjective optimization).
Reference: [21] <author> S. Freyer, D. Weuster-Botz, and C. Wandrey. </author> <title> Medi-enoptimierung mit Genetischen Algorithmen. </title> <journal> BioEn-gineering, </journal> 8(5+6):16-25, 1992. 
Reference: [22] <author> D. J. </author> <title> Futuyma. </title> <publisher> Evolutionsbiologie. Birkhauser Verlag, </publisher> <address> Basel, </address> <year> 1990. </year>
Reference-contexts: Others than this directed variant of selection, such as stabilizing selection (where individuals of medium value of a certain biological trait are preferred) or disruptive selection (where the individuals covering the extreme values of a biological trait are preferred) are also found in nature (e.g. <ref> [22] </ref>, pp. 174-175), but such schemes have not been transferred to evolutionary algorithms so far. From a theoretical point of view, it is an important goal to formulate general design principles for evolutionary algorithms and their variation operators, in order to allow for a more systematic development of such algorithms.
Reference: [23] <author> D. K. Gehlhaar and D. B. Fogel. </author> <title> Tuning evolutionary programming for conformationally flexible molecular docking. </title> <editor> In L. J. Fogel, P. J. Angeline, and T. Back, editors, </editor> <booktitle> Proceedings of the Fifth Annual Conference on Evolutionary Programming. </booktitle> <publisher> The MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1996. </year>
Reference: [24] <author> D. E. Goldberg. </author> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Order-based GAs work directly on the permutation, applying specialized recombination (such as order crossover or partially matched crossover) and mutation operators (such as random exchanges of two elements of the permutation) which preserve permutations (see e.g. <ref> [24] </ref>, pp. 166-179 for an overview). B. Real-Coded Genetic Algorithms Evolutionary algorithms that use a floating-point representation for search spaces M IR n have sometimes been called real-coded GAs [25]. <p> C. Classifier Systems Classifier Systems use an evolutionary algorithm to search the space of production rules (often encoded by strings over a ternary alphabet) of a learning system capable of induction and generalization [28] (see also <ref> [24] </ref>, chapter 6). Typically, the Michigan approach and the Pitt-sburgh approach are distinguished according to whether an individual corresponds with a rule of the rule-based system (Michigan approach), or with a complete rule base (Pitts-burgh approach). D.
Reference: [25] <author> D. E. Goldberg. </author> <title> The theory of virtual alphabets. </title> <editor> In H.-P. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature | Proceedings 1st Workshop PPSN I, volume 496 of Lecture Notes in Computer Science, </booktitle> <pages> pages 13-22. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: B. Real-Coded Genetic Algorithms Evolutionary algorithms that use a floating-point representation for search spaces M IR n have sometimes been called real-coded GAs <ref> [25] </ref>. Somewhere between evolution strategies and genetic algorithms, real-coded GAs typically do not use techniques of self-adaptation, but might utilize time-decreasing step sizes [38] or change operator probabilities based on their observed performance [11]. C.
Reference: [26] <author> J. H. Holland. </author> <title> Outline for a logical theory of adaptive systems. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 3 </volume> <pages> 297-314, </pages> <year> 1962. </year>
Reference: [27] <author> J. H. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, MI, </address> <year> 1975. </year>
Reference: [28] <author> J. H. Holland, K. J. Holyoak, R. E. Nisbett, and P. R. Thagard. </author> <title> Induction: Processes of Inference, Learning, and Discovery. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: C. Classifier Systems Classifier Systems use an evolutionary algorithm to search the space of production rules (often encoded by strings over a ternary alphabet) of a learning system capable of induction and generalization <ref> [28] </ref> (see also [24], chapter 6). Typically, the Michigan approach and the Pitt-sburgh approach are distinguished according to whether an individual corresponds with a rule of the rule-based system (Michigan approach), or with a complete rule base (Pitts-burgh approach). D.
Reference: [29] <author> K. A. De Jong. </author> <title> An analysis of the behaviour of a class of genetic adaptive systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1975. </year> <note> Diss. Abstr. Int. 36(10), 5140B, University Microfilms No. 76-9381. </note>
Reference: [30] <author> K. A. De Jong and J. Sarma. </author> <title> Generation gaps revisited. </title> <editor> In D. Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms 2, </booktitle> <pages> pages 19-28. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference: [31] <editor> K. E. Kinnear, editor. </editor> <booktitle> Advances in Genetic Programming. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: The dominant approach to genetic programming uses (a subset of) LISP programs as the search space [33], but other programming languages including machine code are also used (see e.g. <ref> [31] </ref>). V. Conclusions In the preceding section, we have presented a fairly brief overview of current algorithmic instantiations of the general idea to simulate processes of natural evolution on a computer in order to solve search and optimization problems in a variety of application fields.
Reference: [32] <editor> J. Klockgether and H.-P. Schwefel. Two-phase nozzle and hollow core jet experiments. In D.G. Elliott, editor, </editor> <booktitle> Proc. 11th Symp. Engineering Aspects of Mag-netohydrodynamics, </booktitle> <pages> pages 141-148, </pages> <institution> California Institute of Technology, </institution> <address> Pasadena CA, March 24-26, </address> <year> 1970. </year>
Reference: [33] <author> J. R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. Complex Adaptive Systems. </title> <publisher> The MIT Press, </publisher> <address> Cam-bridge, MA, </address> <year> 1992. </year>
Reference-contexts: D. Genetic Programming Genetic programming transfers the paradigm of evolutionary search to the space of computer programs in a language suitable to modification by operators such as mutation and recombination. The dominant approach to genetic programming uses (a subset of) LISP programs as the search space <ref> [33] </ref>, but other programming languages including machine code are also used (see e.g. [31]). V.
Reference: [34] <author> F. Kursawe. </author> <title> A variant of Evolution Strategies for vector optimization. </title> <editor> In H.-P. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature | Proceedings 1st Workshop PPSN I, volume 496 of Lecture Notes in Computer Science, </booktitle> <pages> pages 193-197. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: The concepts of diploidy or polyploidy , combined with dominance and recessivity <ref> [34] </ref> as well as the idea of introducing two sexes with different selection criteria might be helpful for such problems. * Natural evolution neither assumes global knowledge (about all fitness values of all individuals) nor a generational synchronization, while many evolutionary algorithms still identify an interation of the algorithm with one
Reference: [35] <author> F. Kursawe. </author> <title> Towards self-adapting evolution strategies. </title> <booktitle> In Proceedings of the Second IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 283-288. </pages> <publisher> IEEE Press, </publisher> <address> Piscataway, NJ, </address> <year> 1995. </year>
Reference: [36] <author> H. J. Lichtfuss. </author> <title> Evolution eines Rohrkrummers. </title> <institution> Dip-lomarbeit, Technische Universitat Berlin, </institution> <year> 1965. </year>
Reference: [37] <author> E. Mayr. </author> <title> Toward a new Philosophy of Biology: Observations of an Evolutionist. </title> <publisher> The Belknap Press of Harvard University Press, </publisher> <address> Cambridge, MA, and Lon-don, GB, </address> <year> 1988. </year>
Reference-contexts: Concerning natural evolution, the neo-Darwinian paradigm asserts that the basic processes of evolution are reproduction, mutation, competition, and selection. Mutation is guaranteed in any reproducing system in a positively entropic environment, and competition and selection are just the consequences of a population expanding in a finite environment (see e.g. <ref> [37] </ref>, or [16], chapter 2).
Reference: [38] <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference-contexts: introduction can be found (see also <ref> [38] </ref> for an excellent overview). A. <p> B. Real-Coded Genetic Algorithms Evolutionary algorithms that use a floating-point representation for search spaces M IR n have sometimes been called real-coded GAs [25]. Somewhere between evolution strategies and genetic algorithms, real-coded GAs typically do not use techniques of self-adaptation, but might utilize time-decreasing step sizes <ref> [38] </ref> or change operator probabilities based on their observed performance [11]. C. Classifier Systems Classifier Systems use an evolutionary algorithm to search the space of production rules (often encoded by strings over a ternary alphabet) of a learning system capable of induction and generalization [28] (see also [24], chapter 6).
Reference: [39] <author> H. Muhlenbein. </author> <title> How genetic algorithms really work: </title> <editor> I. mutation and hillclimbing. In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature 2, </booktitle> <pages> pages 15-25. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference: [40] <author> N. J. Radcliffe and P. D. Surry. </author> <title> Fitness variance of formae and performance prediction. </title> <editor> In M. D. Vose L. D. Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms 3, </booktitle> <pages> pages 51-72. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Francisco, CA, </address> <year> 1995. </year>
Reference-contexts: An attempt to formulate such principles is presented by Radcliffe and Surry, who generalize the definition of schemata from binary strings to arbitrary search spaces by introducing so-called formae <ref> [40] </ref>. They then introduce representation-independent recombination operators, which have features claimed to be helpful for evolutionary search. <p> These basic properties of variation operators can be used to classify the existing operators for different representations, and to identify those operators which should be best suited for a given search space. While the results reported in <ref> [40] </ref> are focused on the traveling salesman problem, it is certainly an interesting approach that might be a first step towards a general, representation-independent theory of evolutionary algorithms.
Reference: [41] <author> I. Rechenberg. </author> <title> Cybernetic solution path of an experimental problem. Royal Aircraft Establishment, Library translation No. </title> <type> 1122, </type> <institution> Farnborough, Hants., UK, </institution> <month> August </month> <year> 1965. </year>
Reference: [42] <author> I. Rechenberg. </author> <title> Evolutionsstrategie: Optimierung technischer Systeme nach Prinzipien der biologischen Evolution. </title> <address> Frommann-Holzboog, Stuttgart, </address> <year> 1973. </year>
Reference: [43] <editor> I. Rechenberg. </editor> <booktitle> Evolutionsstrategie '94, volume 1 of Werkstatt Bionik und Evolutionstechnik. </booktitle> <address> Frommann-Holzboog, Stuttgart, </address> <year> 1994. </year>
Reference: [44] <author> G. Rudolph. </author> <title> On correlated mutations in evolution strategies. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature 2, </booktitle> <pages> pages 105-114. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1992. </year>
Reference: [45] <author> G. Rudolph. </author> <title> Massively parallel simulated annealing and its relation to evolutionary algorithms. </title> <journal> Evolutionary Computation, </journal> <volume> 1(4) </volume> <pages> 361-382, </pages> <year> 1993. </year>
Reference: [46] <author> G. Rudolph and J. Sprave. </author> <title> A cellular genetic algorithm with self-adjusting acceptance threshold. </title> <booktitle> In Proceedings of the First IEE/IEEE International Conference on Genetic Algorithms in Engineering Systems: Innovations and Applications, </booktitle> <pages> pages 365-372. </pages> <publisher> IEE, </publisher> <address> London, </address> <year> 1995. </year>
Reference-contexts: Fine-grained asynchronously parallel variants of evolutionary algorithms, introducing local neighborhoods for recombination and selection and a time-space organization like in cellular automata <ref> [46] </ref> represent an attempt to overcome these restrictions. * Though a "recombination" operator is often used in evolutionary algorithms, no implementations have so far realized a real distinction of two different kinds of sexes | which might be helpful for meeting different criteria as well as different constraints. * The genotype-phenotype
Reference: [47] <author> N. Saravanan. </author> <title> Learning of strategy parameters in evolutionary programming: An empirical study. </title> <editor> In A. V. Sebald and L. J. Fogel, editors, </editor> <booktitle> Proceedings of the Third Annual Conference on Evolutionary Programming. World Scientific, </booktitle> <address> Singapore, </address> <year> 1994. </year>
Reference: [48] <author> N. Saravanan and D. B. Fogel. </author> <title> Evolving neurocontrol-lers using evolutionary programming. </title> <booktitle> In Proceedings of the First IEEE Conference on Evolutionary Computation, </booktitle> <volume> volume 1, </volume> <pages> pages 217-222. </pages> <publisher> IEEE Press, </publisher> <address> Pis-cataway, NJ, </address> <year> 1994. </year>
Reference: [49] <author> N. Saravanan, D. B. Fogel, and K. M. Nelson. </author> <title> A comparison of methods for self-adaptation in evolutionary algorithms. </title> <journal> BioSystems, </journal> <volume> 36 </volume> <pages> 157-166, </pages> <year> 1995. </year>
Reference: [50] <author> J. D. Schaffer, R. A. Caruana, L. J. Eshelman, and R. Das. </author> <title> A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 51-60. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: [51] <author> J. Schull. </author> <title> The view from the adaptive landscape. </title> <editor> In H.-P. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature | Proceedings 1st Workshop PPSN I, volume 496 of Lecture Notes in Computer Science, </booktitle> <pages> pages 415-427. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: which all might be exploited to obtain more powerful search algorithms and a better understanding of natural evolution: * Natural evolution works under dynamically changing environmental conditions, with instationary optima and even changing optimization criteria, and the individuals themselves are also changing the structure of the adaptive landscape during adaptation <ref> [51] </ref>. In evolutionary algorithms, environmental conditions are often static, but non-elitist variants are able to deal with changing environments.
Reference: [52] <author> H.-P. Schwefel. </author> <title> Kybernetische Evolution als Strategie der experimentellen Forschung in der Stromungstech-nik. </title> <institution> Diplomarbeit, Technische Universitat Berlin, </institution> <year> 1965. </year>
Reference: [53] <editor> H.-P. Schwefel. Projekt MHD-Staustrahlrohr: Experimentelle Optimierung einer Zweiphasenduse, Teil I. Technischer Bericht 11.034/68, </editor> <address> 35, AEG Forschungsinstitut, Berlin, </address> <month> October </month> <year> 1968. </year>
Reference: [54] <author> H.-P. Schwefel. </author> <title> Numerische Optimierung von Computer-Modellen mittels der Evolutionsstrategie, </title> <booktitle> volume 26 of Interdisciplinary Systems Research. </booktitle> <publisher> Birkhauser, </publisher> <address> Basel, </address> <year> 1977. </year>
Reference: [55] <author> H.-P. Schwefel. </author> <title> Numerical Optimization of Computer Models. </title> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1981. </year>
Reference: [56] <author> H.-P. Schwefel. </author> <title> Evolution and Optimum Seeking. </title> <booktitle> Sixth-Generation Computer Technology Series. </booktitle> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1995. </year>
Reference: [57] <author> H.-P. Schwefel and G. Rudolph. </author> <title> Contemporary evolution strategies. </title> <editor> In F. Moran, A. Moreno, J. J. Merelo, and P. Chacon, editors, </editor> <booktitle> Advances in Artificial Life. Third International Conference on Artificial Life, volume 929 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 893-907. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: is certainly worthwhile, however, to consider a more flexible life span concept for individuals in evolutionary algorithms than just the extremes of a maximum life span of one generation (as in a (; )-strategy) and of an unlimited life span (as in an elitist strategy), by introducing an aging parameter <ref> [57] </ref>. * The long-term goal of evolution consists in the main-tainance of evolvability of a population, guaranteed by mutation and a perservation of diversity within the population (the term meliorization describes this more appropriately than optimization or adaptation do).
Reference: [58] <author> G. Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: [59] <author> A. Torn and A. Zilinskas. </author> <title> Global Optimization, </title> <booktitle> volume 350 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference: [60] <author> D. Whitley. </author> <title> The GENITOR algorithm and selection pressure: Why rank-based allocation of reproductive trials is best. </title> <editor> In J. D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116-121. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: [61] <author> A. H. Wright. </author> <title> Genetic algorithms for real parameter optimization. </title> <editor> In G. J. E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 205-218. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference: [62] <author> M. Yanagiya. </author> <title> A simple mutation-dependent genetic algorithm. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> page 659. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
References-found: 62

