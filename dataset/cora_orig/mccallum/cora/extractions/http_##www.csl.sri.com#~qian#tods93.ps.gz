URL: http://www.csl.sri.com/~qian/tods93.ps.gz
Refering-URL: http://www.csl.sri.com/~qian/early-pubs.html
Root-URL: 
Title: The Deductive Synthesis of Database Transactions  for Knowledge Based Software Assistant.  
Author: Xiaolei Qian 
Keyword: Categories and Subject Descriptions: D.1.2[Programming Techniques]: Automatic Program ming; F.3.1[Logics and Meanings of Programs]: Specifying and Verifying and Reasoning about Programs|Logics of programs; H.2.0[Database Management]: General|Security, integrity, and protection; H.2.3[Database Management]: Languages|Database (persistent) programming lan guages; I.2.2[Artificial Intelligence]: Automatic Programming|Program synthesis General Terms: Design, Theory, Verification Additional Key Words and Phrases: Database Programming, Deductive Tableau, Integrity Con straints, Search Control, Transaction Logic, Transaction Synthesis  
Address: 333 Ravenswood Avenue, Menlo Park, CA 94025.  
Note: This work was supported in part by Defense Advanced Research Projects Agency under Contract N39-84-C-0211 for Knowledge Base Management Systems and by Rome Air Development Center under Contract F30602-86-C-0026  Author's current address:  
Affiliation: Department of Computer Science, Stanford University  Computer Science Laboratory, SRI International,  
Abstract: Database programming requires knowledge of database semantics both to maintain database integrity and to explore more optimization opportunities. Automated programming of database transactions is desirable and feasible. In general, transactions use simple constructs and algorithms; specifications of database semantics are available; and transactions perform small incremental updates to database contents. Automated programming in such a restricted but well-understood and important domain is promising. We approach the synthesis of database transactions that preserve the validity of integrity constraints using deductive techniques. A transaction logic for a fairly expressive class of transactions is developed as the formalism within which the synthesis is conducted. Transactions are generated as the by-product of proving specifications in the logic. The Manna-Waldinger deductive-tableau system is extended with inference rules for the extraction of transactions from proofs, which require the cooperation of multiple tableaux. Control strategies are developed that utilize the database semantics to reduce search effort in the synthesis process and to enhance y A preliminary version of this paper, entitled "Synthesizing Database Transactions", appeared in the Proceedings of the Sixteenth International Conference on Very Large Data Bases, 1990, 552-565. runtime efficiency of the generated transactions.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Burstall, R., </author> <title> "Formal Description of Program Structure and Semantics in First-Order Logic"; Machine Intelligence 5, </title> <editor> B. Meltzer and D. Michie (editors), </editor> <publisher> Edinburgh University Press, </publisher> <year> 1969, </year> <pages> 79-98. </pages>
Reference-contexts: The deductive synthesis of imperative programs has been approached with various forms of situational logic, which was first introduced by McCarthy as a very convenient formalism for describing situations, actions, and causality [25]. Burstall used the formalism to reason about programs that manipulate the states of a computation <ref> [1] </ref>. It was used in prow [39] to synthesize imperative programs. Manna and Waldinger took situational logic as a framework to formalize algol-like language constructs [18], such as pointers and procedure invocation.
Reference: [2] <author> Casanova, M., and Bernstein, P., </author> <title> "A Formal System for Reasoning about Programs Accessing a Relational Database"; ACM Transactions on Programming Languages and Systems 2:3, </title> <month> July </month> <year> 1980, </year> <pages> 386-414. </pages>
Reference-contexts: Program verification techniques are applied to transaction programming based on Hoare Logic [8], Dynamic Logic <ref> [2] </ref>, and Boyer-Moore Logic [35]. Program synthesis techniques are typically classified into two broad classes: deductive versus transformational approaches [34]. It is reasonable to view the transformational approach as extending the deductive approach with proven lemmas or correctness-preserving transformation rules. <p> Constructs supporting concurrent and parallel execution, such as abort/commit and guarded command, can be added to the language such that reasoning about concurrency control <ref> [2] </ref> and the synthesis of transactions for parallel architectures [6] are possible. Richer data modeling concepts can be incorporated into our language by adding more data types and operations, such as arithmetic and set-theoretic operations.
Reference: [3] <author> Codd, E. F., </author> <title> "A Relational Model of Data for Large Shared Data Banks"; Communications of the ACM 13:6, </title> <booktitle> 1970, </booktitle> <pages> 377-387. </pages>
Reference-contexts: 1 Introduction Databases are partial models of the real world that provide a means to record knowledge and facts about certain aspects of the real world. We use an extension of the relational model <ref> [3] </ref> as the underlying modeling mechanism, where facts become tabular data and knowledge consists of logical statements about the data called integrity constraints. A database schema describes the semantics of the data stored in the database by specifying the structure of relations and the relationships between data in different relations.
Reference: [4] <author> Constable, R., et al., </author> <title> Implementing Mathematics with the NuPrl Proof Development System, </title> <publisher> Prentice-Hall, </publisher> <year> 1986. </year>
Reference-contexts: It is reasonable to view the transformational approach as extending the deductive approach with proven lemmas or correctness-preserving transformation rules. Research in deductive program synthesis has concentrated primarily on the generation of applicative programs in classical logic [17] or various constructive logics <ref> [4, 24] </ref>, where specifications are theorems and programs are constructive proofs. Although classical logic can always be embedded into constructive logics [10], classical proofs cannot always be translated into constructive proofs [26]. <p> Using these techniques, we showed that all axioms of our transaction theory can be built into deduction rules (Section 6.5 in [31]). Very few theorem proving systems today actually support these techniques. The notion of proof plans was introduced in nuprl <ref> [4] </ref> as a means to encode programmer-supplied control strategies. Proper control has also been a key challenge to program synthesis. The control problem in program synthesis has two facets: the efficiency of the synthesis process and the efficiency of the synthesized programs.
Reference: [5] <author> Fagin, R., </author> <title> "Horn Clauses and Database Dependencies"; Journal of the ACM 29:4, </title> <booktitle> 1982, </booktitle> <pages> 952-985. </pages>
Reference-contexts: One class of uniform constraints is static constraints of the form (8s)(8x)ff, where ff is quantifier-free and all relations in ff occur negatively (Theorem 6.7 in Section 6.4.1 in [31]). A large number of commonly-seen integrity constraints belong to this class, such as the extended, equality-generating dependencies <ref> [5] </ref> and in particular functional dependencies. <p> Acyclicity requires that this referential relationship is not cyclic. The class of acyclic constraints is also uniform, because updates to relations can always be partially ordered (Theorem 6.8 in Section 6.4.1 in [31]). This class covers many commonly-seen integrity constraints, including the acyclic, extended, embedded, implicational dependencies <ref> [5] </ref>, such as acyclic referential integrity constraints. Uniform constraints can be built into the action axioms such that intermediate states of transaction execution are valid with respect to these constraints.
Reference: [6] <author> Finger, J., </author> <title> "Exploiting Constraints in Design Synthesis"; PhD Dissertation, </title> <type> Technical Report STAN-CS-88-1204, </type> <institution> Computer Science Department, Stanford University, </institution> <year> 1987. </year> <month> 46 </month>
Reference-contexts: Constructs supporting concurrent and parallel execution, such as abort/commit and guarded command, can be added to the language such that reasoning about concurrency control [2] and the synthesis of transactions for parallel architectures <ref> [6] </ref> are possible. Richer data modeling concepts can be incorporated into our language by adding more data types and operations, such as arithmetic and set-theoretic operations. By identifying the classes of transactions that compute those updates with decidable validity problems, more efficient synthesis algorithms are possible.
Reference: [7] <author> Freytag, J., and Goodman, N., </author> <title> "On the Translation of Relational Queries into Iterative Pro--grams"; ACM Transactions on Database Systems 14:1, </title> <booktitle> 1989, </booktitle> <pages> 1-27. </pages>
Reference-contexts: Transformational synthesis has been used intensively in database programming, such as query processing [38] and semantic query optimization [15], where declarative query specifications are transformed into executable and efficient query plans. Freytag and Goodman applied program transformation techniques to the synthesis of iterative programs from relational query specifications <ref> [7] </ref>. There has been essentially no work in the deductive synthesis of database transactions. There have been numerous proposals on improving the effectiveness of theorem proving systems. In particular, equational unification [23] and theory resolution [37] have been widely used by researchers.
Reference: [8] <author> Gardarin, G., and Melkanoff, M., </author> <booktitle> "Proving Consistency of Database Transactions"; Proceedings of the Fifth International Conference on Very Large Data Bases, </booktitle> <year> 1979, </year> <pages> 291-298. </pages>
Reference-contexts: Program verification techniques are applied to transaction programming based on Hoare Logic <ref> [8] </ref>, Dynamic Logic [2], and Boyer-Moore Logic [35]. Program synthesis techniques are typically classified into two broad classes: deductive versus transformational approaches [34]. It is reasonable to view the transformational approach as extending the deductive approach with proven lemmas or correctness-preserving transformation rules.
Reference: [9] <editor> Georgeff, M., and Lansky, A. (editors), </editor> <booktitle> Reasoning about Actions and Plans: Proceedings of the 1986 Workshop, </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: Mathematical induction was used as a proof construct from which recursive programs can be extracted. Specifications often have to be generalized first in order for the induction to be carried through. A related area of study is robot planning in AI <ref> [9] </ref>. Situational logic was first used in qa3 [11] to synthesize robot plans, which are straight line programs of basic actions. Hoare logic was used in plan synthesis methods based on goal reduction [30], which has the difficulty in generating plans with control structures more powerful than sequential composition.
Reference: [10] <author> Girard, J-Y., </author> <title> "A New Constructive Logic: Classical Logic"; Logic and Computation, </title> <month> April </month> <year> 1991. </year>
Reference-contexts: Research in deductive program synthesis has concentrated primarily on the generation of applicative programs in classical logic [17] or various constructive logics [4, 24], where specifications are theorems and programs are constructive proofs. Although classical logic can always be embedded into constructive logics <ref> [10] </ref>, classical proofs cannot always be translated into constructive proofs [26]. Hence, either constructive logics have to be used or proofs in classical logic have to be disciplined in order to synthesize programs from proofs.
Reference: [11] <author> Green, C., </author> <booktitle> "Application of Theorem Proving to Problem Solving"; Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <year> 1969, </year> <pages> 219-239. </pages>
Reference-contexts: Mathematical induction was used as a proof construct from which recursive programs can be extracted. Specifications often have to be generalized first in order for the induction to be carried through. A related area of study is robot planning in AI [9]. Situational logic was first used in qa3 <ref> [11] </ref> to synthesize robot plans, which are straight line programs of basic actions. Hoare logic was used in plan synthesis methods based on goal reduction [30], which has the difficulty in generating plans with control structures more powerful than sequential composition.
Reference: [12] <author> Henschen, L., McCune, W., and Naqvi, S., </author> <title> "Compiling Constraint-Checking Programs from First-Order Formulas"; Advances in Database Theory, Vol.2, </title> <editor> H. Gallaire, J. Minker, and J-M. Nicolas (editors), </editor> <publisher> Plenum Press, </publisher> <year> 1984, </year> <pages> 145-170. </pages>
Reference-contexts: Smith represented various classes of algorithms as design tactics to assist program derivations [36]. Finite differencing is a very effective program optimization technique, which replaces repeated, costly, and global computations by efficient, local, and incremental modifications [16, 29]. Constraint compilation methods based on finite differencing were proposed in <ref> [12, 13, 28] </ref>, which, when given a constraint-transaction pair, derive an incremental formula whose validity in an input state guarantees the correctness of the transaction execution in the input state with respect to the constraint.
Reference: [13] <author> Hsu, A., and Imielinski, T., </author> <booktitle> "Integrity Checking for Multiple Updates"; Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <year> 1985, </year> <pages> 152-168. </pages>
Reference-contexts: Smith represented various classes of algorithms as design tactics to assist program derivations [36]. Finite differencing is a very effective program optimization technique, which replaces repeated, costly, and global computations by efficient, local, and incremental modifications [16, 29]. Constraint compilation methods based on finite differencing were proposed in <ref> [12, 13, 28] </ref>, which, when given a constraint-transaction pair, derive an incremental formula whose validity in an input state guarantees the correctness of the transaction execution in the input state with respect to the constraint.
Reference: [14] <author> Kant, E., </author> <title> "On the Efficient Synthesis of Efficient Programs"; Artificial Intelligence 20, </title> <booktitle> 1983, </booktitle> <pages> 253-305. </pages>
Reference-contexts: The main difficulties include the generation of efficient algorithmic structures and data structures from declarative specifications. Within the transformational paradigm, Kant presented a framework for using analysis and searching knowledge to guide stepwise program refinement <ref> [14] </ref>. Control in deductive program synthesis boils down to control in theorem proving. Algorithm design has attracted a lot of attention recently. Smith represented various classes of algorithms as design tactics to assist program derivations [36]. <p> One important component still missing is an appropriate performance model, which can provide guidance to search reduction. One would hope for better results in the domain of database programming, since cost modeling is much better understood for databases than for general computation <ref> [14] </ref>. 6.4 Recapitulation Automation holds the only hope in solving the software crisis. Yet, forty years of experience in automated programming research tells us that general-purpose, fully-automated program synthesis| just like general-purpose problem solving systems|is unlikely to succeed in the foreseeable future.
Reference: [15] <author> King, J., </author> <title> "Query Optimization by Semantic Reasoning"; PhD Dissertation, </title> <type> Technical Report STAN-CS-81-857, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1981. </year>
Reference-contexts: They noticed however that fully rigorous theorem proving might not be suited to planning, where imprecise inference is often necessary. Transformational synthesis has been used intensively in database programming, such as query processing [38] and semantic query optimization <ref> [15] </ref>, where declarative query specifications are transformed into executable and efficient query plans. Freytag and Goodman applied program transformation techniques to the synthesis of iterative programs from relational query specifications [7]. There has been essentially no work in the deductive synthesis of database transactions.
Reference: [16] <author> Koenig, S., and Paige, R., </author> <title> "A Transformational Framework for the Automatic Control of Derived Data"; Proceedings of the Seventh International Conference on Very Large Data Bases, </title> <booktitle> 1981, </booktitle> <pages> 306-318. </pages>
Reference-contexts: Algorithm design has attracted a lot of attention recently. Smith represented various classes of algorithms as design tactics to assist program derivations [36]. Finite differencing is a very effective program optimization technique, which replaces repeated, costly, and global computations by efficient, local, and incremental modifications <ref> [16, 29] </ref>. Constraint compilation methods based on finite differencing were proposed in [12, 13, 28], which, when given a constraint-transaction pair, derive an incremental formula whose validity in an input state guarantees the correctness of the transaction execution in the input state with respect to the constraint.
Reference: [17] <author> Manna, Z., and Waldinger, R., </author> <title> "A Deductive Approach to Program Synthesis"; ACM Transactions on Programming Languages and Systems 2:1, </title> <month> January </month> <year> 1980, </year> <pages> 90-121. </pages>
Reference-contexts: It is reasonable to view the transformational approach as extending the deductive approach with proven lemmas or correctness-preserving transformation rules. Research in deductive program synthesis has concentrated primarily on the generation of applicative programs in classical logic <ref> [17] </ref> or various constructive logics [4, 24], where specifications are theorems and programs are constructive proofs. Although classical logic can always be embedded into constructive logics [10], classical proofs cannot always be translated into constructive proofs [26].
Reference: [18] <author> Manna, Z., and Waldinger, R., </author> <title> "Problematic Features of Programming Languages: </title> <note> A Situational-Calculus Approach"; Acta Informatica 16, </note> <year> 1981, </year> <pages> 371-426. </pages>
Reference-contexts: Thirdly, programming languages are complex objects with a large number of powerful constructs such as pointers, loops, procedures, and recursive data structures. In order to perform program synthesis, the semantics of these constructs must be completely specified first, which is again a very large and difficult task <ref> [18] </ref>. For the same reasons, however, a small number of simple language constructs|insert, delete, modify, test, and iterate for example|constitutes a reasonable transaction language. <p> Burstall used the formalism to reason about programs that manipulate the states of a computation [1]. It was used in prow [39] to synthesize imperative programs. Manna and Waldinger took situational logic as a framework to formalize algol-like language constructs <ref> [18] </ref>, such as pointers and procedure invocation. They also proposed a restricted variant, which we used to build our transaction theory, to avoid synthesizing 43 non-executable programs. This variant was applied to the deductive synthesis of imperative lisp programs [20].
Reference: [19] <author> Manna, Z., and Waldinger, R., </author> <booktitle> "Special Relations in Automated Deduction"; Journal of the ACM 33:1, </booktitle> <year> 1986, </year> <pages> 1-59. </pages>
Reference-contexts: There have been numerous proposals on improving the effectiveness of theorem proving systems. In particular, equational unification [23] and theory resolution [37] have been widely used by researchers. The strategic aspect of resolution with equality matching has also been investigated <ref> [19] </ref>. These strategies all share the common objective to build axioms into deduction rules. The benefit is to invoke these axioms only when needed, while their representation as assertions in the tableaux might cause numerous irrelevant consequences.
Reference: [20] <author> Manna, Z, and Waldinger, R., </author> <booktitle> "The Deductive Synthesis of Imperative LISP Programs"; Proceedings of AAAI , 1987, </booktitle> <pages> 155-160. </pages>
Reference-contexts: They also proposed a restricted variant, which we used to build our transaction theory, to avoid synthesizing 43 non-executable programs. This variant was applied to the deductive synthesis of imperative lisp programs <ref> [20] </ref>. Mathematical induction was used as a proof construct from which recursive programs can be extracted. Specifications often have to be generalized first in order for the induction to be carried through. A related area of study is robot planning in AI [9].
Reference: [21] <author> Manna, Z, and Waldinger, R., </author> <title> "How to Clear a Block: A Theory of Plans"; Journal of Automated Reasoning 3, </title> <booktitle> 1987, </booktitle> <pages> 343-377. </pages>
Reference-contexts: The equational unification algorithm might yield an infinite stream of most general unifiers <ref> [21] </ref>. 24 Split Rules 1. If an assertion is of the form ff ^ fi then add ff and fi to the assertion list. 2. If a goal is of the form fl _ ffi then add fl and ffi to the goal list. 3. <p> Hoare logic was used in plan synthesis methods based on goal reduction [30], which has the difficulty in generating plans with control structures more powerful than sequential composition. Manna and Waldinger recently adapted program synthesis techniques to the automated generation of recursive plans <ref> [21] </ref>. They noticed however that fully rigorous theorem proving might not be suited to planning, where imprecise inference is often necessary.
Reference: [22] <author> Manna, Z., and Waldinger, R., </author> <title> The Logical Basis for Computer Programming, Vol.2: Deductive Systems; Addison-Wesley, </title> <year> 1990. </year>
Reference-contexts: The process of transaction synthesis is illustrated by Figure 3. 4.1 Deductive-Tableau Synthesis System An appropriate proof system is necessary in order to carry out the deductive transaction synthesis outlined above. We extend the deductive-tableau proof system for first-order logic developed by Manna and Waldinger <ref> [22] </ref> to fulfill our need. Proofs in the system are represented as tables or deductive tableaux . <p> On the other 23 hand, if we replace a subformula with negative polarity in a tableau by another weaker formula, the resulting tableau is stronger than the original one 3 <ref> [22] </ref>. Based on the polarities of subformulas, we can define the force of quantifiers, which is either universal (denoted by "8") or existential (denoted by "9"). The force of quantifiers gives a syntactic indication of what role quantifiers play towards the truth of the tableau. <p> Two expressions p and q unify under a most general unifier with respect to an equation s = r, if s = r implies that p = q. There are six groups of deduction rules in the system. The propositional and predicate logic tautologies <ref> [22] </ref> are built into the rewrite rules. The split rules are used to decompose formulas in the tableau into smaller ones. The resolution rules are the major forms of conditional reasoning that prove formulas by case analysis. The equivalence rules and the equality rules are provided to perform equality reasoning.
Reference: [23] <author> Martelli, A., and Rossi, G., </author> <title> "An Algorithm for Unification in Equational Theories"; Proceedings of the Third Symposium on Logic Programming, </title> <booktitle> 1986, </booktitle> <pages> 180-186. 47 </pages>
Reference-contexts: Polarities and quantifier forces are represented as superscripts in deductive tableaux. 4.3 Deduction Rules We first introduce the basic forms of deduction rules in the deductive-tableau synthesis system without the transaction entries. The unification algorithm used in the system is based on equational unification <ref> [23] </ref>. Two expressions p and q unify under a most general unifier with respect to an equation s = r, if s = r implies that p = q. There are six groups of deduction rules in the system. <p> Freytag and Goodman applied program transformation techniques to the synthesis of iterative programs from relational query specifications [7]. There has been essentially no work in the deductive synthesis of database transactions. There have been numerous proposals on improving the effectiveness of theorem proving systems. In particular, equational unification <ref> [23] </ref> and theory resolution [37] have been widely used by researchers. The strategic aspect of resolution with equality matching has also been investigated [19]. These strategies all share the common objective to build axioms into deduction rules.
Reference: [24] <author> Martin-Lof, P., </author> <title> "An Intuitionistic Theory of Types: </title> <booktitle> Predicative Part"; Proceedings of Logic Colloquium 1973 , 1975, </booktitle> <pages> 73-118. </pages>
Reference-contexts: It is reasonable to view the transformational approach as extending the deductive approach with proven lemmas or correctness-preserving transformation rules. Research in deductive program synthesis has concentrated primarily on the generation of applicative programs in classical logic [17] or various constructive logics <ref> [4, 24] </ref>, where specifications are theorems and programs are constructive proofs. Although classical logic can always be embedded into constructive logics [10], classical proofs cannot always be translated into constructive proofs [26].
Reference: [25] <author> McCarthy, J., </author> <title> "Situations, Actions, and Causal Laws"; Semantic Information Processing , M. </title> <editor> Minsky (editor), </editor> <publisher> MIT Press, </publisher> <year> 1968, </year> <pages> 410-417. </pages>
Reference-contexts: We take a more liberal point of view, requiring only that a witness can be constructed. The deductive synthesis of imperative programs has been approached with various forms of situational logic, which was first introduced by McCarthy as a very convenient formalism for describing situations, actions, and causality <ref> [25] </ref>. Burstall used the formalism to reason about programs that manipulate the states of a computation [1]. It was used in prow [39] to synthesize imperative programs. Manna and Waldinger took situational logic as a framework to formalize algol-like language constructs [18], such as pointers and procedure invocation.
Reference: [26] <author> Murthy, C., </author> <title> "Classical Proofs as Programs: How, What, </title> <type> and Why"; Technical Report TR 91-1215, </type> <institution> Department of Computer Science, Cornell University, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Although classical logic can always be embedded into constructive logics [10], classical proofs cannot always be translated into constructive proofs <ref> [26] </ref>. Hence, either constructive logics have to be used or proofs in classical logic have to be disciplined in order to synthesize programs from proofs. For a proof of a specification theorem in classical logic to be constructive, the constructivists insist on having a translation into a constructive proof.
Reference: [27] <author> Nicolas, J-M., and Gallaire, H., </author> <title> "Data Base: Theory vs. Interpretation"; Logic and Databases, </title> <editor> H. Gallaire and J. Minker (editors), </editor> <publisher> Plenum Press, </publisher> <year> 1978, </year> <pages> 33-54. </pages>
Reference-contexts: A database schema describes the semantics of the data stored in the database by specifying the structure of relations and the relationships between data in different relations. We might view a database schema as a theory and a database as a model of the theory <ref> [27] </ref>. Integrity constraints represent the time-independent semantics of data in the database and serve as the validity criteria of data in the database.
Reference: [28] <author> Nicolas, J-M., </author> <title> "Logic for Improving Integrity Checking in Relational Data Bases"; Acta Infor-matica 18, </title> <booktitle> 1982, </booktitle> <pages> 227-253. </pages>
Reference-contexts: Smith represented various classes of algorithms as design tactics to assist program derivations [36]. Finite differencing is a very effective program optimization technique, which replaces repeated, costly, and global computations by efficient, local, and incremental modifications [16, 29]. Constraint compilation methods based on finite differencing were proposed in <ref> [12, 13, 28] </ref>, which, when given a constraint-transaction pair, derive an incremental formula whose validity in an input state guarantees the correctness of the transaction execution in the input state with respect to the constraint.
Reference: [29] <author> Paige, R., </author> <title> "Applications of Finite Differencing to Database Integrity Control and Query/Transaction Optimization"; Advances in Database Theory, Vol.2, </title> <editor> H. Gallaire, J. Minker, and J-M. Nicolas (editors), </editor> <publisher> Plenum Press, </publisher> <year> 1984, </year> <pages> 171-209. </pages>
Reference-contexts: Algorithm design has attracted a lot of attention recently. Smith represented various classes of algorithms as design tactics to assist program derivations [36]. Finite differencing is a very effective program optimization technique, which replaces repeated, costly, and global computations by efficient, local, and incremental modifications <ref> [16, 29] </ref>. Constraint compilation methods based on finite differencing were proposed in [12, 13, 28], which, when given a constraint-transaction pair, derive an incremental formula whose validity in an input state guarantees the correctness of the transaction execution in the input state with respect to the constraint.
Reference: [30] <author> Pednault, E., </author> <title> "Toward a Mathematical Theory of Plan Synthesis"; PhD Dissertation, </title> <institution> Computer Science Department, Stanford University, </institution> <year> 1987. </year>
Reference-contexts: A related area of study is robot planning in AI [9]. Situational logic was first used in qa3 [11] to synthesize robot plans, which are straight line programs of basic actions. Hoare logic was used in plan synthesis methods based on goal reduction <ref> [30] </ref>, which has the difficulty in generating plans with control structures more powerful than sequential composition. Manna and Waldinger recently adapted program synthesis techniques to the automated generation of recursive plans [21].
Reference: [31] <author> Qian, X., </author> <title> "The Deductive Synthesis of Database Transactions"; PhD Dissertation, </title> <type> Technical Report STAN-CS-89-1291, </type> <institution> Department of Computer Science, Stanford University, </institution> <month> November </month> <year> 1989. </year>
Reference-contexts: Finally, a brief literature survey and concluding remarks are provided in Section 6. The material of this paper is extracted from the author's thesis <ref> [31] </ref>. Because of the limitation on space, we will emphasize the key ideas and illustrate them with examples and intuitive arguments. <p> differentiation, a (conjunctive) incremental change :A 0 (s 0 ;t 1 ; a) to C 1 (s 0 ;t 1 ) is factored out from C 1 (s 0 ;t 1 ;insert E (a)), and hence G3 0 to obtain G4: A constraint differentiation algorithm is developed (Section 6.3 in <ref> [31] </ref>) to calculate the incre mental changes of transaction execution on constraint formulas. <p> One class of uniform constraints is static constraints of the form (8s)(8x)ff, where ff is quantifier-free and all relations in ff occur negatively (Theorem 6.7 in Section 6.4.1 in <ref> [31] </ref>). A large number of commonly-seen integrity constraints belong to this class, such as the extended, equality-generating dependencies [5] and in particular functional dependencies. <p> Acyclicity requires that this referential relationship is not cyclic. The class of acyclic constraints is also uniform, because updates to relations can always be partially ordered (Theorem 6.8 in Section 6.4.1 in <ref> [31] </ref>). This class covers many commonly-seen integrity constraints, including the acyclic, extended, embedded, implicational dependencies [5], such as acyclic referential integrity constraints. Uniform constraints can be built into the action axioms such that intermediate states of transaction execution are valid with respect to these constraints. <p> The benefit is to invoke these axioms only when needed, while their representation as assertions in the tableaux might cause numerous irrelevant consequences. Using these techniques, we showed that all axioms of our transaction theory can be built into deduction rules (Section 6.5 in <ref> [31] </ref>). Very few theorem proving systems today actually support these techniques. The notion of proof plans was introduced in nuprl [4] as a means to encode programmer-supplied control strategies. Proper control has also been a key challenge to program synthesis.
Reference: [32] <author> Qian, X. </author> <title> "An Axiom System for Database Transactions"; Information Processing Letters 36, </title> <month> November </month> <year> 1990, </year> <pages> 183-189. </pages>
Reference-contexts: We have shown elsewhere that our transaction language has exactly first-order expressive power [33], and our axiomatization of the language is sound and complete <ref> [32] </ref>. First-order expressiveness implies that specification is first-order: every property of transactions can be specified in first-order logic. The sound and complete axiomatization of our transaction language also provides the basis of control strategies, especially constraint differentiation and pre-compilation.
Reference: [33] <author> Qian, X. </author> <note> "The Expressive Power of the Bounded-Iteration Construct"; Acta Informatica 28, </note> <month> October </month> <year> 1991, </year> <pages> 631-656. </pages>
Reference-contexts: We have shown elsewhere that our transaction language has exactly first-order expressive power <ref> [33] </ref>, and our axiomatization of the language is sound and complete [32]. First-order expressiveness implies that specification is first-order: every property of transactions can be specified in first-order logic. The sound and complete axiomatization of our transaction language also provides the basis of control strategies, especially constraint differentiation and pre-compilation.
Reference: [34] <editor> Rich, C., and Waters, R. (editors), </editor> <booktitle> Readings in Artificial Intelligence and Software Engineering , Morgan Kaufmann, </booktitle> <year> 1986. </year>
Reference-contexts: the output state Employee (Jones,: : :) Secondly, while program specifications express what needs to be done, the algorithmic information about how to do it is not specified and is almost impossible to derive fully automatically because of the tremendous search effort involved on the part of the synthesis system <ref> [34] </ref>. However, transactions are dominated by data manipulation instead of complex computation. On the average, eighty percent of the common transaction code is about integrity constraint checking and enforcement. Simple algorithms and control structures|like case analysis|suffice. <p> Program verification techniques are applied to transaction programming based on Hoare Logic [8], Dynamic Logic [2], and Boyer-Moore Logic [35]. Program synthesis techniques are typically classified into two broad classes: deductive versus transformational approaches <ref> [34] </ref>. It is reasonable to view the transformational approach as extending the deductive approach with proven lemmas or correctness-preserving transformation rules.
Reference: [35] <author> Sheard, T., and Stemple, D., </author> <title> "Automatic Verification of Database Transaction Safety"; ACM Transactions on Database Systems 14:3, </title> <month> September </month> <year> 1989, </year> <pages> 322-368. </pages>
Reference-contexts: Program verification techniques are applied to transaction programming based on Hoare Logic [8], Dynamic Logic [2], and Boyer-Moore Logic <ref> [35] </ref>. Program synthesis techniques are typically classified into two broad classes: deductive versus transformational approaches [34]. It is reasonable to view the transformational approach as extending the deductive approach with proven lemmas or correctness-preserving transformation rules.
Reference: [36] <author> Smith, D., </author> <title> "Top-Down Synthesis of Divide-and-Conquer Algorithms"; Artificial Intelligence 27, </title> <booktitle> 1985, </booktitle> <pages> 43-96. </pages>
Reference-contexts: Control in deductive program synthesis boils down to control in theorem proving. Algorithm design has attracted a lot of attention recently. Smith represented various classes of algorithms as design tactics to assist program derivations <ref> [36] </ref>. Finite differencing is a very effective program optimization technique, which replaces repeated, costly, and global computations by efficient, local, and incremental modifications [16, 29].
Reference: [37] <author> Stickel, M., </author> <title> "Automated Deduction by Theory Resolution"; Journal of Automated Reasoning 1, </title> <booktitle> 1985, </booktitle> <pages> 333-355. </pages>
Reference-contexts: There has been essentially no work in the deductive synthesis of database transactions. There have been numerous proposals on improving the effectiveness of theorem proving systems. In particular, equational unification [23] and theory resolution <ref> [37] </ref> have been widely used by researchers. The strategic aspect of resolution with equality matching has also been investigated [19]. These strategies all share the common objective to build axioms into deduction rules.
Reference: [38] <author> Ullman, J., </author> <title> Principles of Database and Knowledge-Base Systems, </title> <publisher> Computer Science Press, </publisher> <year> 1988. </year>
Reference-contexts: Manna and Waldinger recently adapted program synthesis techniques to the automated generation of recursive plans [21]. They noticed however that fully rigorous theorem proving might not be suited to planning, where imprecise inference is often necessary. Transformational synthesis has been used intensively in database programming, such as query processing <ref> [38] </ref> and semantic query optimization [15], where declarative query specifications are transformed into executable and efficient query plans. Freytag and Goodman applied program transformation techniques to the synthesis of iterative programs from relational query specifications [7]. There has been essentially no work in the deductive synthesis of database transactions.
Reference: [39] <author> Waldinger, R., and Lee, R., "prow: </author> <booktitle> A Step Toward Automatic Program Writing"; Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <year> 1969, </year> <pages> 241-252. </pages>
Reference-contexts: Burstall used the formalism to reason about programs that manipulate the states of a computation [1]. It was used in prow <ref> [39] </ref> to synthesize imperative programs. Manna and Waldinger took situational logic as a framework to formalize algol-like language constructs [18], such as pointers and procedure invocation. They also proposed a restricted variant, which we used to build our transaction theory, to avoid synthesizing 43 non-executable programs.
Reference: [40] <author> Wiederhold, G., </author> <title> Database Design, </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year> <month> 48 </month>
Reference-contexts: Acyclic constraints are intended to model acyclic referential integrity constraints <ref> [40] </ref>. Relation R can be viewed as referring to S: the presence of a tuple in R demands the existence of a certain tuple in S. Acyclicity requires that this referential relationship is not cyclic.
References-found: 40

