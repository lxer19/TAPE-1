URL: http://www.cs.berkeley.edu/~leungt/Research/CVPR98_final.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~leungt/publications.html
Root-URL: 
Title: Probabilistic Affine Invariants for Recognition  
Author: Thomas K. Leung Michael C. Burl ; and Pietro Perona 
Affiliation: 1 University of California at  California Institute of Technology,  Jet Propulsion Laboratory,  
Address: Santa Barbara, CA,  Berkeley, 545 Soda Hall, Berkeley, CA 94720  MS 136-93, Pasadena, CA 91125  MS 525-3660, 4800 Oak Grove Drive, Pasadena, CA 91109  
Note: Proc. of the IEEE Conf. on Comp. Vision and Pattern Recognition,  
Email: leungt@cs.berkeley.edu, burl@aig.jpl.nasa.gov, perona@vision.caltech.edu  
Phone: 2  3  
Date: June 1998  
Abstract: Under a weak perspective camera model, the image plane coordinates in different views of a planar object are related by an affine transformation. Because of this property, researchers have attempted to use affine invariants for recognition. However, there are two problems with this approach: (1) objects or object classes with inherent variability cannot be adequately treated using invariants; and (2) in practice the calculated affine invariants can be quite sensitive to errors in the image plane measurements. In this paper we use probability distributions to address both of these difficulties. Under the assumption that the feature positions of a planar object can be modeled using a jointly Gaussian density, we have derived the joint density over the corresponding set of affine coordinates. Even when the assumptions of a planar object and a weak perspective camera model do not strictly hold, the results are useful because deviations from the ideal can be treated as deformability in the underlying object model. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T. Alter and D. Jacobs. </author> <title> "Error propagation in full 3d-from-2d object recognition". </title> <booktitle> In CVPR., </booktitle> <year> 1994. </year>
Reference-contexts: Though the affine co 1 ordinates are invariant under view point, however, in practice the calculated affine invariants can be quite sensitive to errors in the image plane measurement. Previous work has been performed to characterize the distribution of the error by bounds [12] or low order approximations <ref> [1] </ref>. In our study, image plane localization error is overcome by specifying joint probability distributions over the affine shape variables. By using probability distributions, we can model the effects of uncertainties in the positions of the basis points as well as handle deformable object classes. <p> and as follows: = L T - where L is defined as follows: L T 4 1 0 1 In this equation I and 0 are the N fi N identity and zero matrices, respectively, 1 is a N fi 1 vector of ones, and e 1 is the vector <ref> [1; 0; : : : ; 0] </ref> T . The next step is to transform Y to affine shape space by applying equation 1 to each pair (x fl i ; y fl i = 4; : : : ; N . <p> This in-variance is exploited by many object recognition systems [13, 20, 25] for indexing into an object database. However, it has been shown that, in practice, the calculated affine invariants can be quite sensitive to errors in the image plane measurements <ref> [1, 12, 20] </ref>. The affine shape density characterizes the positional uncertainties and correlations between features under errors in feature localization. Consider a planar object with N features. Assume that the errors for the localization of each feature are uncorrelated Gaussian distributions.
Reference: [2] <author> F.L. Bookstein. </author> <title> "Size and Shape Spaces for Landmark Data in Two Dimensions". </title> <journal> Statistical Science, </journal> <volume> 1(2), </volume> <year> 1986. </year>
Reference-contexts: The use of shape models to represent variation in biological samples (e.g. sea shells) was pioneered by Kendall [15] and Bookstein <ref> [2] </ref>, but has only recently been applied to computer vision. In [6] local part detectors and probabilistic shape models were combined to provide reliable localization of quasi-frontal faces in cluttered scenes and with partial occlusion.
Reference: [3] <author> J.Y. Bouguet. </author> <title> "3-D Photography System using Stripe Projection", 1997. </title> <type> private communication. </type>
Reference-contexts: By modeling the shape variables with a probability distribution, we can capture the degree of non-planarity and the effect of perspective projection. We illustrate these effects using data for human faces. We obtained "true" 3D locations of points on the human head using active lighting techniques <ref> [3] </ref>. We projected these points onto the image plane perspectively for different camera poses.
Reference: [4] <author> M.C. Burl. </author> <title> Recognition of Visual Object Classes. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering, Caltech, Pasadena, </institution> <address> CA, </address> <year> 1997. </year>
Reference-contexts: On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. Occlusion does not pose a big problem either. However, the features for geometry-based methods usually are very simple, thus not descriptive enough to provide good recognition performance. An emerging framework for recognition <ref> [4, 7, 8, 16, 19, 24] </ref> combines the image-based and geometry-based methods. Objects are modeled as a set of local parts arranged in a deformable spatial configuration. <p> In some applications, assuming a single multivari-ate Gaussian density (Equation 2) in the figure space distribution may seem too restrictive. Mixtures of Gaussians may be more appropriate. Extension of the affine shape density formula to a figure space distribution consisting of mixtures of Gaussians is straight forward. Burl <ref> [4] </ref> showed such a similar extension for the Euclidean shape density. Future work will include a quantitative investigation of performance with respect to pose variations and occlusions in the context of face detection. Thorough comparison with other face detection techniques will be performed.
Reference: [5] <author> M.C. Burl, U.M. Fayyad, P. Perona, P. Smyth, </author> <title> and M.P. Burl. "Automating the Hunt for Volcanoes on Venus". </title> <booktitle> In CVPR., </booktitle> <year> 1994. </year>
Reference-contexts: Two approaches have been developed to address this problem: (1) image-based methods <ref> [5, 18, 22] </ref>; and (2) geometry-based methods such as the generalized Hough transform [13], geometric hashing [20, 25], alignment [14], and geometric invariants [17]. Image-based methods have been shown to work well in many cases.
Reference: [6] <author> M.C. Burl, T.K. Leung, and P. Perona. </author> <title> "Face Localization via Shape Statistics". </title> <booktitle> In Intl. W. on Automatic Face and Gesture Recognition, </booktitle> <year> 1995. </year>
Reference-contexts: Various representations have been used to model spatial configurations including mutual distances [16], springs [26], energy functions over mesh grids [24], and eigenshapes [8]. A particularly promising approach is provided by probabilistic shape models <ref> [6, 7] </ref>. In this approach, configurations of labeled points are transformed to "shape space" by mapping two reference points to fixed positions. The coordinates of the remaining points then encode the shape of the object. <p> The use of shape models to represent variation in biological samples (e.g. sea shells) was pioneered by Kendall [15] and Bookstein [2], but has only recently been applied to computer vision. In <ref> [6] </ref> local part detectors and probabilistic shape models were combined to provide reliable localization of quasi-frontal faces in cluttered scenes and with partial occlusion. However, the method presented there is only able to deal with approximately 15 ffi of rotation in depth. <p> We can deal with such a large range of head poses because the affine shape density is affine invariant. The result is interesting because most other techniques are designed only for frontal faces <ref> [6, 21, 23] </ref>. At present, the detection rate of our algorithm is about 70% on the face databases used in [6, 16]. The major reason for the somewhat low detection rate is because of the poor performance of the local facial feature detectors. <p> The result is interesting because most other techniques are designed only for frontal faces [6, 21, 23]. At present, the detection rate of our algorithm is about 70% on the face databases used in <ref> [6, 16] </ref>. The major reason for the somewhat low detection rate is because of the poor performance of the local facial feature detectors. Using more sophisticated techniques and using more facial features will definitely improve the performance. <p> Our formulation can address the issue of occlusions very easily. Partial occlusions imply that some of the features are missing. The affine shape density for a subset of features can then be used to rank the incomplete constellation <ref> [6, 7, 16] </ref>. The use of local features and their arrangements has a significant advantage over techniques that use intensity based matching.
Reference: [7] <author> M.C. Burl and P. Perona. </author> <title> "Recognition of Planar Object Classes". </title> <booktitle> In CVPR., </booktitle> <year> 1996. </year>
Reference-contexts: On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. Occlusion does not pose a big problem either. However, the features for geometry-based methods usually are very simple, thus not descriptive enough to provide good recognition performance. An emerging framework for recognition <ref> [4, 7, 8, 16, 19, 24] </ref> combines the image-based and geometry-based methods. Objects are modeled as a set of local parts arranged in a deformable spatial configuration. <p> Various representations have been used to model spatial configurations including mutual distances [16], springs [26], energy functions over mesh grids [24], and eigenshapes [8]. A particularly promising approach is provided by probabilistic shape models <ref> [6, 7] </ref>. In this approach, configurations of labeled points are transformed to "shape space" by mapping two reference points to fixed positions. The coordinates of the remaining points then encode the shape of the object. <p> In this paper, we have made a contribution to the problem by deriving the joint probability distribution induced over a set of invariants given a jointly Gaussian figure space model. Our result simultaneously addresses both the difficulties mentioned above while extending the probabilistic shape framework <ref> [7, 10] </ref> from simple translation, scaling and image-plane rotation invariance to full affine invariance. In practice this will permit recognition over a broader range of rotations in depth. The approach may be applicable even when the assumptions of a planar object class and a weak perspective camera do not hold. <p> Our formulation can address the issue of occlusions very easily. Partial occlusions imply that some of the features are missing. The affine shape density for a subset of features can then be used to rank the incomplete constellation <ref> [6, 7, 16] </ref>. The use of local features and their arrangements has a significant advantage over techniques that use intensity based matching.
Reference: [8] <author> T.F. Cootes and C.J. Taylor. </author> <title> "Locating Objects of Varying Shape Using Statistical Feature Detectors". </title> <booktitle> In ECCV., </booktitle> <year> 1996. </year>
Reference-contexts: On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. Occlusion does not pose a big problem either. However, the features for geometry-based methods usually are very simple, thus not descriptive enough to provide good recognition performance. An emerging framework for recognition <ref> [4, 7, 8, 16, 19, 24] </ref> combines the image-based and geometry-based methods. Objects are modeled as a set of local parts arranged in a deformable spatial configuration. <p> Various representations have been used to model spatial configurations including mutual distances [16], springs [26], energy functions over mesh grids [24], and eigenshapes <ref> [8] </ref>. A particularly promising approach is provided by probabilistic shape models [6, 7]. In this approach, configurations of labeled points are transformed to "shape space" by mapping two reference points to fixed positions. The coordinates of the remaining points then encode the shape of the object.
Reference: [9] <author> M.S. Costa, R.M. Haralick, and L.G. Shapiro. </author> <title> Optimal affine-invariant point matching. </title> <booktitle> In 10 th ICPR., </booktitle> <year> 1990. </year>
Reference-contexts: In this paper, we extend the probabilistic shape approach to affine-invariant shape. Instead of mapping two points to reference positions, three points are used. The resulting shape variables are equivalent to the affine invariants that have been used in previous studies <ref> [9, 17, 20, 25] </ref>. In other words, for planar objects under a weak perspective camera model, the set of image plane transformations under all camera poses can be modeled using affine transformations.
Reference: [10] <author> I.L. Dryden and K.V. Mardia. </author> <title> "General Shape Distributions in a Plane". </title> <journal> Adv. Appl. Prob., </journal> <volume> 23, </volume> <year> 1991. </year>
Reference-contexts: We will now derive the probability density for the affine shape variables induced by a Gaussian figure space density. This result generalizes the work of Dry-den and Mardia <ref> [10] </ref>. We begin from the assumption that the figure space variables (x i ; y i ), for i = 1; : : : ; N are distributed according to a general 2N -dimensional Gaussian distribution. <p> In this paper, we have made a contribution to the problem by deriving the joint probability distribution induced over a set of invariants given a jointly Gaussian figure space model. Our result simultaneously addresses both the difficulties mentioned above while extending the probabilistic shape framework <ref> [7, 10] </ref> from simple translation, scaling and image-plane rotation invariance to full affine invariance. In practice this will permit recognition over a broader range of rotations in depth. The approach may be applicable even when the assumptions of a planar object class and a weak perspective camera do not hold.
Reference: [11] <author> J.N. Franklin. </author> <title> Matrix Theory. </title> <publisher> Prentice-Hall, </publisher> <year> 1968. </year>
Reference-contexts: there exists a nonsingular ma trix F such that: F T BF = fl 3 where fl = diagf 1 ; : : : ; 4 g consists of the eigenvalues of CB and I is the 4 fi 4 identity matrix. (See, for example, Theorem 2, pg 106 in <ref> [11] </ref>.) Upon introducing the following substitution: Fr = q Equation 3 simplifies to = (2) 3N e g=2 jCj Z jr T flrj N3 N = (2) 3N e g=2 jCj E r 1 E r 2 E r 3 E r 4 j i=1 i j (N3) (5) where the
Reference: [12] <author> W.E.L. Grimson, D.P. Huttenlocher, and D.W. Jacobs. </author> <title> "A Study of Affine Matching with Bounded Sensor Error". </title> <booktitle> In ECCV., </booktitle> <address> Berlin, </address> <year> 1992. </year>
Reference-contexts: Though the affine co 1 ordinates are invariant under view point, however, in practice the calculated affine invariants can be quite sensitive to errors in the image plane measurement. Previous work has been performed to characterize the distribution of the error by bounds <ref> [12] </ref> or low order approximations [1]. In our study, image plane localization error is overcome by specifying joint probability distributions over the affine shape variables. By using probability distributions, we can model the effects of uncertainties in the positions of the basis points as well as handle deformable object classes. <p> This in-variance is exploited by many object recognition systems [13, 20, 25] for indexing into an object database. However, it has been shown that, in practice, the calculated affine invariants can be quite sensitive to errors in the image plane measurements <ref> [1, 12, 20] </ref>. The affine shape density characterizes the positional uncertainties and correlations between features under errors in feature localization. Consider a planar object with N features. Assume that the errors for the localization of each feature are uncorrelated Gaussian distributions.
Reference: [13] <author> Y.C. Hecker and R.M. Bolle. </author> <title> "On Geometric Hashing and the Generalized Hough Transform". </title> <journal> IEEE Trans on Sys., Man., and Cybern., </journal> <volume> 24(9), </volume> <year> 1994. </year>
Reference-contexts: Two approaches have been developed to address this problem: (1) image-based methods [5, 18, 22]; and (2) geometry-based methods such as the generalized Hough transform <ref> [13] </ref>, geometric hashing [20, 25], alignment [14], and geometric invariants [17]. Image-based methods have been shown to work well in many cases. However, they suffer when there is large variation in camera pose or lighting or when there are occlusions. <p> Therefore, most of this chapter will be devoted to (3). 4.1 Feature Localization Error As we have mentioned before, the affine shape variables of a planar object under a weak perspective camera model are invariant to object pose. This in-variance is exploited by many object recognition systems <ref> [13, 20, 25] </ref> for indexing into an object database. However, it has been shown that, in practice, the calculated affine invariants can be quite sensitive to errors in the image plane measurements [1, 12, 20].
Reference: [14] <author> D.P. Huttenlocher and S. Ullman. </author> <title> "Recognizing Solid Objects by Alignment with an Image". </title> <journal> IJCV., </journal> <volume> 5(2), </volume> <year> 1990. </year>
Reference-contexts: Two approaches have been developed to address this problem: (1) image-based methods [5, 18, 22]; and (2) geometry-based methods such as the generalized Hough transform [13], geometric hashing [20, 25], alignment <ref> [14] </ref>, and geometric invariants [17]. Image-based methods have been shown to work well in many cases. However, they suffer when there is large variation in camera pose or lighting or when there are occlusions. On the other hand, geometry-based techniques can tackle pose or lighting variations naturally.
Reference: [15] <author> D.G. Kendall. </author> <title> "Shape Manifolds, Procrustean Metrics, and Complex Projective Spaces". </title> <journal> Bull. London Math Soc., </journal> <volume> 16, </volume> <year> 1984. </year>
Reference-contexts: Joint probability distributions are used in shape space to model variability in the object as well as any uncertainty in the shape variables resulting from uncertainty in the reference points. The use of shape models to represent variation in biological samples (e.g. sea shells) was pioneered by Kendall <ref> [15] </ref> and Bookstein [2], but has only recently been applied to computer vision. In [6] local part detectors and probabilistic shape models were combined to provide reliable localization of quasi-frontal faces in cluttered scenes and with partial occlusion. <p> Specifically, the image plane coordinates in view 1 can be related to the image plane coordinates in view 2 as follows: i i = M x i where M and b are constant (independent of i). Following the definition of Euclidean shape proposed by Kendall <ref> [15] </ref>, we will define affine shape as the information remaining in a planar configuration of labeled points after differences due to affine transformations have been factored out. Consider a new coordinate system in which (x 1 ; y 1 ) serves as the origin.
Reference: [16] <author> T.K. Leung, M.C. Burl, and P. Perona. </author> <title> "Finding Faces in Cluttered Scenes". </title> <booktitle> In ICCV, </booktitle> <address> Cambridge, MA, </address> <year> 1995. </year>
Reference-contexts: On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. Occlusion does not pose a big problem either. However, the features for geometry-based methods usually are very simple, thus not descriptive enough to provide good recognition performance. An emerging framework for recognition <ref> [4, 7, 8, 16, 19, 24] </ref> combines the image-based and geometry-based methods. Objects are modeled as a set of local parts arranged in a deformable spatial configuration. <p> Image-based methods (e.g., principal components, Ga bor wavelets, or other filters) represent local variations in parts of the object by the corresponding weighting coefficients, while geometry-based methods tie the parts together in an overall configuration. Various representations have been used to model spatial configurations including mutual distances <ref> [16] </ref>, springs [26], energy functions over mesh grids [24], and eigenshapes [8]. A particularly promising approach is provided by probabilistic shape models [6, 7]. In this approach, configurations of labeled points are transformed to "shape space" by mapping two reference points to fixed positions. <p> The result is interesting because most other techniques are designed only for frontal faces [6, 21, 23]. At present, the detection rate of our algorithm is about 70% on the face databases used in <ref> [6, 16] </ref>. The major reason for the somewhat low detection rate is because of the poor performance of the local facial feature detectors. Using more sophisticated techniques and using more facial features will definitely improve the performance. <p> Our formulation can address the issue of occlusions very easily. Partial occlusions imply that some of the features are missing. The affine shape density for a subset of features can then be used to rank the incomplete constellation <ref> [6, 7, 16] </ref>. The use of local features and their arrangements has a significant advantage over techniques that use intensity based matching.
Reference: [17] <editor> J.L. Mundy and A. Zisserman, editors. </editor> <booktitle> "Geometric In-variance in Computer Vision". Artificial Intelligence. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1992. </year>
Reference-contexts: Two approaches have been developed to address this problem: (1) image-based methods [5, 18, 22]; and (2) geometry-based methods such as the generalized Hough transform [13], geometric hashing [20, 25], alignment [14], and geometric invariants <ref> [17] </ref>. Image-based methods have been shown to work well in many cases. However, they suffer when there is large variation in camera pose or lighting or when there are occlusions. On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. <p> In this paper, we extend the probabilistic shape approach to affine-invariant shape. Instead of mapping two points to reference positions, three points are used. The resulting shape variables are equivalent to the affine invariants that have been used in previous studies <ref> [9, 17, 20, 25] </ref>. In other words, for planar objects under a weak perspective camera model, the set of image plane transformations under all camera poses can be modeled using affine transformations.
Reference: [18] <author> Hiroshi Murase and Shree Nayar. </author> <title> "Visual Learning and Recognition of 3-D Objects from Appearance". </title> <journal> IJCV, </journal> <volume> 14, </volume> <year> 1995. </year>
Reference-contexts: Two approaches have been developed to address this problem: (1) image-based methods <ref> [5, 18, 22] </ref>; and (2) geometry-based methods such as the generalized Hough transform [13], geometric hashing [20, 25], alignment [14], and geometric invariants [17]. Image-based methods have been shown to work well in many cases.
Reference: [19] <author> Arthur R. Pope and David G. Lowe. </author> <title> "Learning Feature Uncertainty Models for Object Recognition". </title> <booktitle> In IEEE Int. Sym. on Comp. Vis., </booktitle> <year> 1995. </year>
Reference-contexts: On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. Occlusion does not pose a big problem either. However, the features for geometry-based methods usually are very simple, thus not descriptive enough to provide good recognition performance. An emerging framework for recognition <ref> [4, 7, 8, 16, 19, 24] </ref> combines the image-based and geometry-based methods. Objects are modeled as a set of local parts arranged in a deformable spatial configuration.
Reference: [20] <author> I. Rigoutsos and R. Hummel. </author> <title> "A Bayesian Approach to Model-Matching with Geometric Hashing". </title> <journal> CVIU., </journal> <volume> 62(1), </volume> <year> 1995. </year>
Reference-contexts: Two approaches have been developed to address this problem: (1) image-based methods [5, 18, 22]; and (2) geometry-based methods such as the generalized Hough transform [13], geometric hashing <ref> [20, 25] </ref>, alignment [14], and geometric invariants [17]. Image-based methods have been shown to work well in many cases. However, they suffer when there is large variation in camera pose or lighting or when there are occlusions. On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. <p> In this paper, we extend the probabilistic shape approach to affine-invariant shape. Instead of mapping two points to reference positions, three points are used. The resulting shape variables are equivalent to the affine invariants that have been used in previous studies <ref> [9, 17, 20, 25] </ref>. In other words, for planar objects under a weak perspective camera model, the set of image plane transformations under all camera poses can be modeled using affine transformations. <p> The results derived here are applicable to both the hybrid methods and purely geometry-based methods. Our result is also applicable to the problem of rehashing the affine invariants studied in <ref> [20] </ref>. The outline of the paper is as follows. Section 2 introduces the basic terminology including a definition for affine shape. In Section 3 we derive the joint probability density over affine shape which results from assuming a (full) Gaussian object model. <p> Therefore, most of this chapter will be devoted to (3). 4.1 Feature Localization Error As we have mentioned before, the affine shape variables of a planar object under a weak perspective camera model are invariant to object pose. This in-variance is exploited by many object recognition systems <ref> [13, 20, 25] </ref> for indexing into an object database. However, it has been shown that, in practice, the calculated affine invariants can be quite sensitive to errors in the image plane measurements [1, 12, 20]. <p> This in-variance is exploited by many object recognition systems [13, 20, 25] for indexing into an object database. However, it has been shown that, in practice, the calculated affine invariants can be quite sensitive to errors in the image plane measurements <ref> [1, 12, 20] </ref>. The affine shape density characterizes the positional uncertainties and correlations between features under errors in feature localization. Consider a planar object with N features. Assume that the errors for the localization of each feature are uncorrelated Gaussian distributions.
Reference: [21] <author> H. Rowley, S. Baluja, and T. Kanade. </author> <title> Neural network-based face detection. </title> <booktitle> In CVPR., </booktitle> <year> 1996. </year>
Reference-contexts: We can deal with such a large range of head poses because the affine shape density is affine invariant. The result is interesting because most other techniques are designed only for frontal faces <ref> [6, 21, 23] </ref>. At present, the detection rate of our algorithm is about 70% on the face databases used in [6, 16]. The major reason for the somewhat low detection rate is because of the poor performance of the local facial feature detectors. <p> The use of local features and their arrangements has a significant advantage over techniques that use intensity based matching. In the face detection context, occlusions will present a very difficult situation in the intensity matching-based face detectors of Rowley et al <ref> [21] </ref> and Sung et al [23], while our system can deal with it naturally. In some applications, assuming a single multivari-ate Gaussian density (Equation 2) in the figure space distribution may seem too restrictive. Mixtures of Gaussians may be more appropriate.
Reference: [22] <author> L. Sirovich and M. Kirby. </author> <title> "Low Dimensional Procedure for the Characterization of Human Faces". </title> <journal> J. of Optical Society of America, </journal> <volume> 4(3), </volume> <year> 1987. </year>
Reference-contexts: Two approaches have been developed to address this problem: (1) image-based methods <ref> [5, 18, 22] </ref>; and (2) geometry-based methods such as the generalized Hough transform [13], geometric hashing [20, 25], alignment [14], and geometric invariants [17]. Image-based methods have been shown to work well in many cases.
Reference: [23] <author> K. Sung and T. Poggio. </author> <title> Example-based learning for view-based human face detection. </title> <type> Technical report, </type> <institution> MIT, </institution> <year> 1994. </year>
Reference-contexts: We can deal with such a large range of head poses because the affine shape density is affine invariant. The result is interesting because most other techniques are designed only for frontal faces <ref> [6, 21, 23] </ref>. At present, the detection rate of our algorithm is about 70% on the face databases used in [6, 16]. The major reason for the somewhat low detection rate is because of the poor performance of the local facial feature detectors. <p> The use of local features and their arrangements has a significant advantage over techniques that use intensity based matching. In the face detection context, occlusions will present a very difficult situation in the intensity matching-based face detectors of Rowley et al [21] and Sung et al <ref> [23] </ref>, while our system can deal with it naturally. In some applications, assuming a single multivari-ate Gaussian density (Equation 2) in the figure space distribution may seem too restrictive. Mixtures of Gaussians may be more appropriate.
Reference: [24] <author> L. Wiskott and C. von der Malsburg. </author> <title> "A Neural System for the Recognition of Partially Occluded Objects in Cluttered Scenes". </title> <journal> Int. J. of Pattern Recognition and Artificial Intelligence, </journal> <volume> 7(4), </volume> <year> 1993. </year>
Reference-contexts: On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. Occlusion does not pose a big problem either. However, the features for geometry-based methods usually are very simple, thus not descriptive enough to provide good recognition performance. An emerging framework for recognition <ref> [4, 7, 8, 16, 19, 24] </ref> combines the image-based and geometry-based methods. Objects are modeled as a set of local parts arranged in a deformable spatial configuration. <p> Various representations have been used to model spatial configurations including mutual distances [16], springs [26], energy functions over mesh grids <ref> [24] </ref>, and eigenshapes [8]. A particularly promising approach is provided by probabilistic shape models [6, 7]. In this approach, configurations of labeled points are transformed to "shape space" by mapping two reference points to fixed positions. The coordinates of the remaining points then encode the shape of the object.
Reference: [25] <author> H.J. Wolfson. </author> <title> "Model-Based Object Recognition by Geometric Hashing". </title> <booktitle> In 1 st ECCV., </booktitle> <year> 1990. </year>
Reference-contexts: Two approaches have been developed to address this problem: (1) image-based methods [5, 18, 22]; and (2) geometry-based methods such as the generalized Hough transform [13], geometric hashing <ref> [20, 25] </ref>, alignment [14], and geometric invariants [17]. Image-based methods have been shown to work well in many cases. However, they suffer when there is large variation in camera pose or lighting or when there are occlusions. On the other hand, geometry-based techniques can tackle pose or lighting variations naturally. <p> In this paper, we extend the probabilistic shape approach to affine-invariant shape. Instead of mapping two points to reference positions, three points are used. The resulting shape variables are equivalent to the affine invariants that have been used in previous studies <ref> [9, 17, 20, 25] </ref>. In other words, for planar objects under a weak perspective camera model, the set of image plane transformations under all camera poses can be modeled using affine transformations. <p> Therefore, most of this chapter will be devoted to (3). 4.1 Feature Localization Error As we have mentioned before, the affine shape variables of a planar object under a weak perspective camera model are invariant to object pose. This in-variance is exploited by many object recognition systems <ref> [13, 20, 25] </ref> for indexing into an object database. However, it has been shown that, in practice, the calculated affine invariants can be quite sensitive to errors in the image plane measurements [1, 12, 20].
Reference: [26] <author> A.L. Yuille. </author> <title> "Deformable Templates for Face Recognition". </title> <journal> J. of Cog. Neu., </journal> <volume> 3(1), </volume> <year> 1991. </year> <month> 7 </month>
Reference-contexts: Image-based methods (e.g., principal components, Ga bor wavelets, or other filters) represent local variations in parts of the object by the corresponding weighting coefficients, while geometry-based methods tie the parts together in an overall configuration. Various representations have been used to model spatial configurations including mutual distances [16], springs <ref> [26] </ref>, energy functions over mesh grids [24], and eigenshapes [8]. A particularly promising approach is provided by probabilistic shape models [6, 7]. In this approach, configurations of labeled points are transformed to "shape space" by mapping two reference points to fixed positions.
References-found: 26

