URL: http://www.cs.helsinki.fi/~oheinone/publications/Improving_the_Accessibility_of_SGML_Documents_-_A_Content-analytical_Approach.ps.gz
Refering-URL: http://www.cs.helsinki.fi/research/rati/sid.html
Root-URL: 
Email: mklemett-@cs.helsinki.t  
Title: Improving the Accessibility of SGML Documents A Content-analytical Approach catch parts of the elementary semantic
Author: Helena Ahonen Barbara Heikkinen Oskari Heinonen Mika Klemettinen -hahonen, bheikkin, oheinone, 
Keyword: Optimal creation of microdocuments would require thorough semantic analysis  
Date: May 1997.  
Note: of the text. However, it is possible to  To appear in SGML Europe '97, Barcelona, Spain,  
Address: P.O. Box 26, FIN00014 University of Helsinki, Finland  
Affiliation: Department of Computer Science, University of Helsinki  
Abstract: Document retrieval based on string searches typically returns either the whole document or just the occurrences of the searched words. What the user often is after, however, is microdocument: a part of the document that contains the occurrences and is reasonably self-contained. These microdocuments might, for instance, consist of several successive text paragraphs sharing a mutual subject. Single paragraphs, or corresponding close-to-leaf Sgml elements, do not convey enough of the contextual information. On the other hand, sections or subsections of a text document, such as a book or an article, can discuss many heterogeneous topics, and thus be too large a unit for retrieval or assembly. We claim that such microdocuments are both suitable retrievable units and appropriate units for document assembly, and that they can be reasonably well located using automatic techniques. Term-frequency distributions enable us to determine the locations of possible topic changes in the text. Based on this information, we can measure the similarity of two successive elements, and decide whether we wish to have them in the same microdocument. On the other hand, existing markup, for example classifying attributes, can be used in boundary detection. The microdocument, again, can be attributed with content information. The results of our preliminary experiments show that the presented approach works well in user-assisted topic-oriented microdocument detection. We currently study the usefulness of this technique in document assembly, i.e., in generating new documents from a collection of existing text documents. 
Abstract-found: 1
Intro-found: 1
Reference: [AHHK97] <author> Helena Ahonen, Barbara Heikkinen, Oskari Heinonen, and Pekka Kilpelinen. </author> <title> Assembling Documents from Digital Libraries. </title> <type> Unpublished manuscript, </type> <month> March </month> <year> 1997. </year>
Reference-contexts: Meaningful and reasonably sized fragments, i.e. microdocuments, are essential in the assembly process. In this article, we assume that the data consist of text documents having a typical section/subsection/paragraph structure, or a structure that can be mapped to a corresponding generalized structure <ref> [AHHK97] </ref>. The Standard Generalized Markup Language (Sgml) is a natural way of representing the structure. This paper is organized as follows. Section 2 introduces the concept of microdocu-ment as we see it. Then in Section 3, we describe the process of detecting topical mi-crodocuments.
Reference: [Cal94] <author> James P. Callan. </author> <title> Passage-Level Evidence in Document Retrieval. </title> <booktitle> In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Dublin, Ireland, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Passage retrieval, as part of information retrieval, attempts to improve precision and recall of query results by dividing documents into passages, in order to include some context around the hit words. The passages do not necessarily represent any semantically meaningful units, for instance in <ref> [Cal94] </ref>, the size of passages is txed. Moreover, text fragmentation is used for decomposition of continuous texts into hypertext [SSBM96].
Reference: [CLR94] <author> Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusetts, USA, </address> <year> 1990. </year>
Reference-contexts: We must also know when to stop the clustering process, i.e., when we have a suitable amount of fragments. Let us then concentrate on another solution. In order to utilize both the similarities and the lengths, we have employed what is called dynamic programming (see, e.g., <ref> [CLR94, Chapter 16] </ref>). Dynamic programming is used for getting an optimal splitting of the section in hand by recursively detning the value for optimal solution.
Reference: [Hea94] <author> Marti Hearst. </author> <title> Multi-Paragraph Segmentation of Expository Text. </title> <booktitle> In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Las Cruces, New Mexico, USA, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Furthermore, sections are often longer than desired with respect to the intended purpose. It would not make sense, anyway, to break against the existing section/subsection structure of the document by, for example, joining paragraphs over section boundaries. 1 Text fragmentation is also studied in <ref> [Hea94] </ref>, which introduces a method called Text--Tiling. Its approach, however, diers from the one that we have adopted. Passage retrieval, as part of information retrieval, attempts to improve precision and recall of query results by dividing documents into passages, in order to include some context around the hit words.
Reference: [Kim96] <author> W. Eliot Kimber. </author> <title> Re-usable SGML: Why I Demand SUBDOC. In SGML '96, </title> <address> Boston, Massachusetts, USA, </address> <year> 1996. </year>
Reference: [McF96] <author> John McFadden. </author> <title> Hybrid Distributed Database (HDDB) and the Future of SGML. </title> <booktitle> In SGML Europe '96, </booktitle> <address> Munich, Germany, </address> <year> 1996. </year>
Reference-contexts: The necessity of assembly is, however, clearly seen and considered to be of great importance <ref> [McF96, Sal89] </ref>. In our approach, assembling documents from a collection of Sgml documents has the following steps. 6 aries. 1. The user selects interesting document fragments by querying and browsing. 2. A new Dtd is formed. 3. A new document is constructed from the generalized elements. 4.
Reference: [Sal89] <author> Gerard Salton. </author> <title> Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, USA, </address> <year> 1989. </year>
Reference-contexts: We have considered two methods for similarity calculation. A trivial approach looks at only two successive paragraphs and calculates the similarity using the well-known cosine coecient formula (see, e.g. <ref> [Sal89] </ref>). The cosine coecient, in turn, uses the paragraph term-frequency vectors. Intuitively, if the vectors contain exactly the same terms in the 2 same proportions, their similarity value is 1.0; on the other extreme, the similarity of mutually exclusive term-frequency vectors is 0.0. <p> The necessity of assembly is, however, clearly seen and considered to be of great importance <ref> [McF96, Sal89] </ref>. In our approach, assembling documents from a collection of Sgml documents has the following steps. 6 aries. 1. The user selects interesting document fragments by querying and browsing. 2. A new Dtd is formed. 3. A new document is constructed from the generalized elements. 4.
Reference: [SSBM96] <author> Gerard Salton, Amit Singhal, Chris Buckley, and Mandar Mitra. </author> <title> Automatic Text Decomposition Using Text Segments and Text Themes. </title> <booktitle> In Proceedings of the Hypertext '96 Conference, </booktitle> <address> Washington D.C., USA, </address> <year> 1996. </year> <month> 9 </month>
Reference-contexts: The passages do not necessarily represent any semantically meaningful units, for instance in [Cal94], the size of passages is txed. Moreover, text fragmentation is used for decomposition of continuous texts into hypertext <ref> [SSBM96] </ref>. In this application also the similarities of non-consecutive pieces of text are important, since hypertext links can clearly implement non-linear structures. 3 Detecting Microdocuments Detecting microdocuments means basically breaking the document in smaller parts. If the document has a section/subsection-type structure, it is trst divided into these parts.
References-found: 8

