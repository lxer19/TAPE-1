URL: file://ftp.cs.utexas.edu/pub/neural-nets/papers/james.sardnet.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/nn/pages/publications/abstracts.html
Root-URL: 
Email: dljames,risto@cs.utexas.edu  
Title: SARDNET: A Self-Organizing Feature Map for Sequences  
Author: Daniel L. James and Risto Miikkulainen 
Address: Austin, TX 78712  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Abstract: A self-organizing neural network for sequence classification called SARDNET is described and analyzed experimentally. SARDNET extends the Kohonen Feature Map architecture with activation retention and decay in order to create unique distributed response patterns for different sequences. SARDNET yields extremely dense yet descriptive representations of sequential input in very few training iterations. The network has proven successful on mapping arbitrary sequences of binary and real numbers, as well as phonemic representations of English words. Potential applications include isolated spoken word recognition and cognitive science models of sequence processing.
Abstract-found: 1
Intro-found: 1
Reference: <author> Chappel, C. J., and Taylor, J. G. </author> <year> (1993). </year> <title> The temporal Kohonen map. Neural Networks, </title> <type> 6 441-445. 9 Kangas, </type> <institution> J. </institution> <year> (1991). </year> <title> Timedependent self-organizing maps for speech recognition. </title> <booktitle> In Proceedings of the International Conference on Artificial Neural Networks (Espoo, </booktitle> <address> Finland), 1591-1594. Amsterdam; New York: </address> <publisher> North-Holland. </publisher>
Reference: <author> Kohonen, T. </author> <year> (1989). </year> <title> Self-Organization and Associative Memory. </title> <address> Berlin; Heidelberg; New York: </address> <publisher> Springer. </publisher> <address> Third edition. </address>
Reference-contexts: Several researchers have proposed extending the self * To appear in G. Tesauro and D. S. Touretzky and T. K. Leen (editors), Advances in Neural Processing Systems 7, 1995. 2 organizing feature map <ref> (Kohonen 1989, 1990) </ref>, a highly successful static pattern classification method, to sequential information (Kangas 1991; Samarabandu and Jakubowicz 1990; Scholtes 1991). Below, three of the most recent of these networks are briefly described.
Reference: <author> Kohonen, T. </author> <year> (1990). </year> <title> The self-organizing map. </title> <booktitle> Proceedings of IEEE, </booktitle> <volume> 78 </volume> <pages> 1464-1480. </pages>
Reference: <author> Samarabandu, J. K., and Jakubowicz, O. G. </author> <year> (1990). </year> <title> Principles of sequential feature maps in multilevel problems. </title> <booktitle> In Proceedings of the International Joint Conference on Neural Networks (Washington, DC), </booktitle> <volume> vol. II, </volume> <pages> 683-686. </pages> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference: <author> Scholtes, J. C. </author> <year> (1991). </year> <title> Recurrent Kohonen self-organization in natural language processing. </title> <booktitle> In Proceedings of the International Conference on Artificial Neural Networks (Espoo, </booktitle> <address> Finland), 1751-1754. Amsterdam; New York: </address> <publisher> North-Holland. </publisher> <editor> van Harmelen, H. </editor> <year> (1993). </year> <title> Timedependent self-organizing feature map for speech recognition. </title> <type> Masters thesis, </type> <institution> University of Twente, Enschede, the Netherlands. </institution>
Reference: <author> Zandhuis, J. A. </author> <year> (1992). </year> <title> Storing sequential data in self-organizing feature maps. </title> <type> Internal Report MPI-NL-TG-4/92, </type> <institution> Max-Planck-Institute fr Psycholinguistik, Nijmegen, the Netherlands. </institution>
Reference-contexts: The SOFM-S is an improvement of TKM in that contextual information is not lost as quickly, but it still uses a single node to represent a sequence. The TRACE feature map <ref> (Zandhuis 1992) </ref> has two feature map layers. The first layer is a topological map of the individual input vectors, and is used to generate a trace (i.e." path) of the input sequence on the map. The second layer then maps the trace pattern to a single node.
References-found: 6

