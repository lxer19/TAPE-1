URL: http://www.research.att.com/~schapire/papers/SchapireSi98b.ps.Z
Refering-URL: http://www.research.att.com/~schapire/publist.html
Root-URL: 
Email: fschapire,singerg@research.att.com  
Title: DRAFT. BoosTexter: A System for Multiclass Multi-label Text Categorization  
Author: Robert E. Schapire Yoram Singer 
Date: March 18, 1998  
Address: 180 Park Avenue Florham Park, NJ 07932-0971 USA  
Affiliation: AT&T Labs  
Abstract: This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks. We first show how to extend the standard notion of classification by allowing each instance to be associated with multiple labels. We then discuss our approach for multiclass multi-label text categorization which is based on a new and improved family of boosting algorithms. We describe in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks. We present results comparing the performance of BoosTexter and a number of other text-categorization algorithms on a variety of tasks. We conclude by describing the application of our system to automatic call-type identification from unconstrained spoken customer responses.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Chidanand Apte, Fred Damerau, and Sholom Weiss. </author> <title> Towards language independent automated learning of text categorization methods. </title> <booktitle> In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 23-30, </pages> <year> 1994. </year>
Reference-contexts: We are especially interested in multiclass and multi-label problems, which we consider to be the most natural. Most of the research in text categorization has been devoted to binary problems (e.g. <ref> [17, 19, 32, 31, 1, 12] </ref> and the many references therein) where a document is classified as either "relevant" or "not relevant" with respect to a pre-determined topic.
Reference: [2] <author> Avrim Blum. </author> <title> Empirical support for winnow and weighted-majority based algorithms: results on a calendar scheduling domain. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 64-72, </pages> <year> 1995. </year>
Reference-contexts: These dot-products induce a ranking of the possible labels. We use this ranking to evaluate the performance of the classifier for each of the measures discussed in Section 5. Sleeping-experts. This is an algorithm originally proposed by Blum <ref> [2] </ref>, studied further by Freund et al. [9], and first applied to text categorization by Cohen and Singer [5]. Briefly, this algorithm classifies a document by thresholding a score which is a weighted combination of "experts" which are based on the word-grams appearing in the text.
Reference: [3] <author> Leo Breiman. </author> <title> Bias, variance, and arcing classifiers. </title> <type> Technical Report 460, </type> <institution> Statistics Department, University of California at Berkeley, </institution> <year> 1996. </year>
Reference-contexts: This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [4] <author> William Cohen. </author> <title> Fast effective rule induction. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 115-123, </pages> <year> 1995. </year>
Reference-contexts: Further description of this dataset is given in Table 12. We used 3-fold cross validation in our experiments with the newsgroup data. 6.2 Other algorithms We compared the various boosting algorithms to the following algorithms: RIPPER. This is Cohen's <ref> [4] </ref> rule-learning system as adapted to text categorization problems by Cohen and Signer [5]. RIPPER classifies a document by applying a set of boolean tests that check the absence (or presence) of words in the documents. RIPPER is not capable of dealing with multiple labels.
Reference: [5] <author> William W. Cohen and Yoram Singer. </author> <title> Context-sensitive learning methods for text categorization. </title> <booktitle> In Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 307-315, </pages> <year> 1996. </year>
Reference-contexts: We used 3-fold cross validation in our experiments with the newsgroup data. 6.2 Other algorithms We compared the various boosting algorithms to the following algorithms: RIPPER. This is Cohen's [4] rule-learning system as adapted to text categorization problems by Cohen and Signer <ref> [5] </ref>. RIPPER classifies a document by applying a set of boolean tests that check the absence (or presence) of words in the documents. RIPPER is not capable of dealing with multiple labels. RIPPER learns a classifier in the form of a boolean combination of simple terms. <p> We use this ranking to evaluate the performance of the classifier for each of the measures discussed in Section 5. Sleeping-experts. This is an algorithm originally proposed by Blum [2], studied further by Freund et al. [9], and first applied to text categorization by Cohen and Singer <ref> [5] </ref>. Briefly, this algorithm classifies a document by thresholding a score which is a weighted combination of "experts" which are based on the word-grams appearing in the text. This score can be used to rank the labels.
Reference: [6] <author> Harris Drucker and Corinna Cortes. </author> <title> Boosting decision trees. </title> <booktitle> In Advances in Neural Information Processing Systems 8, </booktitle> <pages> pages 479-485, </pages> <year> 1996. </year>
Reference-contexts: This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [7] <author> Yoav Freund and Robert E. Schapire. </author> <title> Experiments with a new boosting algorithm. </title> <booktitle> In Machine Learning: Proceedings of the Thirteenth International Conference, </booktitle> <pages> pages 148-156, </pages> <year> 1996. </year>
Reference-contexts: This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [8] <author> Yoav Freund and Robert E. Schapire. </author> <title> A decision-theoretic generalization of on-line learning and an application to boosting. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 55(1) </volume> <pages> 119-139, </pages> <month> August </month> <year> 1997. </year> <month> 23 </month>
Reference-contexts: Our approach is based on a new and improved family of boosting algorithms which we have described and analyzed in detail in a companion paper [29]. This new family extends and generalizes Freund and Schapire's AdaBoost algorithm <ref> [8] </ref>, which has been studied extensively and which has been shown to perform well on standard machine-learning tasks [3, 6, 7, 8, 20, 21, 23, 27, 28]. We present two extensions of AdaBoost that efficiently handle multi-label problems. <p> This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [9] <author> Yoav Freund, Robert E. Schapire, Yoram Singer, and Manfred K. Warmuth. </author> <title> Using and com-bining predictors that specialize. </title> <booktitle> In Proceedings of the Twenty-Ninth Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 334-343, </pages> <year> 1997. </year>
Reference-contexts: These dot-products induce a ranking of the possible labels. We use this ranking to evaluate the performance of the classifier for each of the measures discussed in Section 5. Sleeping-experts. This is an algorithm originally proposed by Blum [2], studied further by Freund et al. <ref> [9] </ref>, and first applied to text categorization by Cohen and Singer [5]. Briefly, this algorithm classifies a document by thresholding a score which is a weighted combination of "experts" which are based on the word-grams appearing in the text. This score can be used to rank the labels.
Reference: [10] <author> A. L. Gorin, B. A. Parker, R. M. Sachs, and J. G. Wilpon. </author> <title> How may I help you? In Proceedings Interactive Voice Technology for Telecommunications Applications (IVTTA), </title> <address> pages 57-60, </address> <year> 1996. </year>
Reference-contexts: There are fourteen call types, plus an `other' category. Some calls can be of more than one type (for instance, a call can be both collect and person-to-person). This task was previously studied by Gorin and others <ref> [11, 10, 24, 30] </ref>, and we used the same data, namely, a collection of 8,000 training utterances and 1,000 test utterances. Both the training and test utterances were all transcribed by humans from actual spoken responses.
Reference: [11] <author> A. L. Gorin, G. Riccardi, and J. H. Wright. </author> <title> How may I help you? Speech Communication, </title> <note> 1998 (to appear). </note>
Reference-contexts: There are fourteen call types, plus an `other' category. Some calls can be of more than one type (for instance, a call can be both collect and person-to-person). This task was previously studied by Gorin and others <ref> [11, 10, 24, 30] </ref>, and we used the same data, namely, a collection of 8,000 training utterances and 1,000 test utterances. Both the training and test utterances were all transcribed by humans from actual spoken responses.
Reference: [12] <author> David Hull, Jan Pedersen, and Hinrich Schutze. </author> <title> Method combination for document filtering. </title> <booktitle> In Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 279-288, </pages> <year> 1996. </year>
Reference-contexts: We are especially interested in multiclass and multi-label problems, which we consider to be the most natural. Most of the research in text categorization has been devoted to binary problems (e.g. <ref> [17, 19, 32, 31, 1, 12] </ref> and the many references therein) where a document is classified as either "relevant" or "not relevant" with respect to a pre-determined topic.
Reference: [13] <author> David J. Ittner, David D. Lewis, and David D. Ahn. </author> <title> Text categorization of low quality images. </title> <booktitle> In Symposium on Document Analysis and Information Retrieval, </booktitle> <pages> pages 301-315, </pages> <address> Las Vegas, NV, </address> <year> 1995. </year> <institution> ISRI; Univ. of Nevada, </institution> <address> Las Vegas. </address>
Reference-contexts: It does not provide a ranking of the possible labels for a given document. Therefore, the only performance measure we can use for comparison is the error rate. Rocchio. We implemented a version of Rocchio's algorithm [25], as adapted to text categorization by Ittner et al. <ref> [13] </ref> and modified to multiclass problems. In Rocchio, we represent the data (both training and test documents) as vectors of numeric weights.
Reference: [14] <author> T. Joachims. </author> <title> A probabilistic analysis of the Rochhio algorithm with TFIDF for text categorization. </title> <booktitle> In Machine Learning: Proceedings of the Fourteenth International Conference, </booktitle> <pages> pages 143-151, </pages> <year> 1997. </year>
Reference-contexts: UseNet data. This dataset consists of Usenet articles collected by Lang [16] from 20 different newsgroups. One thousand articles were collected for each newsgroup so there are 20,000 articles in the entire collection. This data was originally treated as single-labeled (see for instance Joachims <ref> [14] </ref>). However, since people tend to post articles to multiple newsgroups, we found, after examining the headers of the articles that about 4:5% of the articles are actually multi-labeled. Furthermore, we found 544 identical articles which were posted to more than one group. <p> This system includes other classification methods but, in all of the experiments we performed, Naive-Bayes and probabilistic TF-IDF performed better than the other methods available in Rainbow. Further description of Naive-Bayes and probabilistic TF-IDF for text categorization is given in <ref> [22, 14] </ref>. To handle multi-label data, we mapped to the single-label case by simply repeating each document once for each of its assigned labels. 6.3 Single-label corpora In the first set of experiments, we partitioned the Reuters corpus into six disjoint classes. These classes roughly constitute the top categorization hierarchy.
Reference: [15] <author> D. Koller and M. Sahami. </author> <title> Hierarchically classifying docuemnts using very few words. </title> <booktitle> In Machine Learning: Proceedings of the Fourteenth International Conference, </booktitle> <pages> pages 171-178, </pages> <year> 1997. </year>
Reference-contexts: This corpus is divided into categories which in turn are sub-divided into sub-categories. Except for the work of Koller and Sahami <ref> [15] </ref>, most of previous research using this corpus concentrated on binary classification. The classes that were typically used in binary classification experiments with the Reuters corpus are from the Commodity category.
Reference: [16] <author> K. Lang. Newsweeder: </author> <title> Learning to filter netnews. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 331-339, </pages> <year> 1995. </year>
Reference-contexts: We performed two sets of experiments with this corpus based on two different labeling schemes available for this corpus. UseNet data. This dataset consists of Usenet articles collected by Lang <ref> [16] </ref> from 20 different newsgroups. One thousand articles were collected for each newsgroup so there are 20,000 articles in the entire collection. This data was originally treated as single-labeled (see for instance Joachims [14]).
Reference: [17] <author> David Lewis. </author> <title> Representation and learning in information retrieval. </title> <type> Technical Report 91-93, </type> <institution> Computer Science Dept., University of Massachusetts at Amherst, </institution> <year> 1992. </year> <type> PhD Thesis. </type>
Reference-contexts: We are especially interested in multiclass and multi-label problems, which we consider to be the most natural. Most of the research in text categorization has been devoted to binary problems (e.g. <ref> [17, 19, 32, 31, 1, 12] </ref> and the many references therein) where a document is classified as either "relevant" or "not relevant" with respect to a pre-determined topic. <p> We followed the TF-IDF weighting [26] and defined the weight v i k to be: k = k log (N D =n k ) j=1 f i ; 2 "Function words" include high frequency but contentless words like `of' and `the'. We used the stop-list given by Lewis <ref> [17] </ref>. 12 Here, N D is the number of documents, n k is the number of documents in which the indexing term k appears. The weight f i k is log (m) + 1, where m is the number of occurrences of the indexing term k in document i.
Reference: [18] <author> David Lewis and Jason Catlett. </author> <title> Heterogeneous uncertainty sampling for supervised learning. </title> <booktitle> In Machine Learning: Proceedings of the Eleventh International Conference, </booktitle> <year> 1994. </year>
Reference-contexts: Since the focus of the paper is multiclass methods we used several other partitions and subsets of the data as we describe below. We used 3-fold cross validation in our experiments with this corpus. AP Titles. This is a corpus of AP newswire headlines <ref> [19, 18] </ref>. As for the Reuters corpus, previous work concentrated on binary classification by tagging documents as being relevant or irrelevant to topics like "federal budget" and "Nielsens ratings." The total number of documents in this corpus is 319,463.
Reference: [19] <author> David Lewis and William Gale. </author> <title> Training text classifiers by uncertainty sampling. </title> <booktitle> In Seventeenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <year> 1994. </year>
Reference-contexts: We are especially interested in multiclass and multi-label problems, which we consider to be the most natural. Most of the research in text categorization has been devoted to binary problems (e.g. <ref> [17, 19, 32, 31, 1, 12] </ref> and the many references therein) where a document is classified as either "relevant" or "not relevant" with respect to a pre-determined topic. <p> Since the focus of the paper is multiclass methods we used several other partitions and subsets of the data as we describe below. We used 3-fold cross validation in our experiments with this corpus. AP Titles. This is a corpus of AP newswire headlines <ref> [19, 18] </ref>. As for the Reuters corpus, previous work concentrated on binary classification by tagging documents as being relevant or irrelevant to topics like "federal budget" and "Nielsens ratings." The total number of documents in this corpus is 319,463.
Reference: [20] <author> Richard Maclin and David Opitz. </author> <title> An empirical evaluation of bagging and boosting. </title> <booktitle> In Proceedings of the Fourteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 546-551, </pages> <year> 1997. </year>
Reference-contexts: This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [21] <author> Dragos D. Margineantu and Thomas G. Dietterich. </author> <title> Pruning adaptive boosting. </title> <booktitle> In Machine Learning: Proceedings of the Fourteenth International Conference, </booktitle> <pages> pages 211-218, </pages> <year> 1997. </year>
Reference-contexts: This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [22] <author> Tom M. Mitchell. </author> <title> Machine Learning. </title> <publisher> McGraw Hill, </publisher> <year> 1997. </year>
Reference-contexts: For example, a news article may well be relevant to multiple topics. Call-types also are by 1 no means mutually exclusive (for instance, a call can be both collect and person-to-person). While a few methods have been devised for multiclass text categorization (see, for instance, Mitchell <ref> [22] </ref> and the references therein), the multi-label case, where a document may belong to more than one class, has received very little attention. The common approach for multiclass, multi-label text categorization is to break the task into disjoint binary categorization problems, one for each class. <p> This system includes other classification methods but, in all of the experiments we performed, Naive-Bayes and probabilistic TF-IDF performed better than the other methods available in Rainbow. Further description of Naive-Bayes and probabilistic TF-IDF for text categorization is given in <ref> [22, 14] </ref>. To handle multi-label data, we mapped to the single-label case by simply repeating each document once for each of its assigned labels. 6.3 Single-label corpora In the first set of experiments, we partitioned the Reuters corpus into six disjoint classes. These classes roughly constitute the top categorization hierarchy.
Reference: [23] <author> J. R. Quinlan. Bagging, </author> <title> boosting, </title> <booktitle> and C4.5. In Proceedings of the Thirteenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 725-730, </pages> <year> 1996. </year>
Reference-contexts: This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [24] <author> G. Riccardi, A.L. Gorin, A. Ljolje, and M. Riley. </author> <title> Spoken language understanding for automated call routing. </title> <booktitle> In Proc. ICASSP, </booktitle> <pages> pages 1143-1146, </pages> <year> 1997. </year> <month> 24 </month>
Reference-contexts: There are fourteen call types, plus an `other' category. Some calls can be of more than one type (for instance, a call can be both collect and person-to-person). This task was previously studied by Gorin and others <ref> [11, 10, 24, 30] </ref>, and we used the same data, namely, a collection of 8,000 training utterances and 1,000 test utterances. Both the training and test utterances were all transcribed by humans from actual spoken responses.
Reference: [25] <author> J. Rocchio. </author> <title> Relevance feedback information retrieval. </title> <editor> In Gerard Salton, editor, </editor> <booktitle> The Smart retrieval system|experiments in automatic document processing, </booktitle> <pages> pages 313-323. </pages> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1971. </year>
Reference-contexts: It does not provide a ranking of the possible labels for a given document. Therefore, the only performance measure we can use for comparison is the error rate. Rocchio. We implemented a version of Rocchio's algorithm <ref> [25] </ref>, as adapted to text categorization by Ittner et al. [13] and modified to multiclass problems. In Rocchio, we represent the data (both training and test documents) as vectors of numeric weights.
Reference: [26] <author> Gerard Salton. </author> <title> Developments in automatic text retrieval. </title> <journal> Science, </journal> <volume> 253 </volume> <pages> 974-980, </pages> <year> 1991. </year>
Reference-contexts: Precision. The above measures are not complete for multi-label classification problems: We can achieve good (low) coverage but suffer high one-error rates, and vice versa. In order to assess the label ranking of a multiclass system as a whole we borrowed a measure frequently used in information retrieval (IR) <ref> [26] </ref>. (Note however that the definition below as well as the whole setting is rather different than rank retrieval problems in IR.) Formally, we define precision with respect to a training set S to be precision S (H) = 1 m X 1 X jf` 0 2 Y i jrank f <p> The weight vector for the ith document is v i = (v i 2 ; : : : ; v i l ), where l is the number of indexing terms used. We use single words as terms. We followed the TF-IDF weighting <ref> [26] </ref> and defined the weight v i k to be: k = k log (N D =n k ) j=1 f i ; 2 "Function words" include high frequency but contentless words like `of' and `the'.
Reference: [27] <author> Robert E. Schapire. </author> <title> Using output codes to boost multiclass learning problems. </title> <booktitle> In Machine Learning: Proceedings of the Fourteenth International Conference, </booktitle> <year> 1997. </year>
Reference-contexts: This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [28] <author> Robert E. Schapire, Yoav Freund, Peter Bartlett, and Wee Sun Lee. </author> <title> Boosting the margin: A new explanation for the effectiveness of voting methods. </title> <booktitle> In Machine Learning: Proceedings of the Fourteenth International Conference, </booktitle> <year> 1997. </year>
Reference-contexts: This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks <ref> [3, 6, 7, 8, 20, 21, 23, 27, 28] </ref>. We present two extensions of AdaBoost that efficiently handle multi-label problems. In the first extension, the goal of the learning algorithm is to predict all and only all of the correct labels.
Reference: [29] <author> Robert E. Schapire Yoram Singer. </author> <title> Improved boosting algorithms using confidence-rated predictions. </title> <note> Submitted for publication. </note>
Reference-contexts: Rather than breaking a multiclass problem into separate binary problems, we devise text-categorization algorithms that efficiently represent and handle sets of labels. Our approach is based on a new and improved family of boosting algorithms which we have described and analyzed in detail in a companion paper <ref> [29] </ref>. This new family extends and generalizes Freund and Schapire's AdaBoost algorithm [8], which has been studied extensively and which has been shown to perform well on standard machine-learning tasks [3, 6, 7, 8, 20, 21, 23, 27, 28]. We present two extensions of AdaBoost that efficiently handle multi-label problems. <p> Precise evaluation measures are discussed in Section 5. Finally, to simplify the notation, for any predicate , let [[]] be 1 if holds and 0 otherwise. 3 Boosting algorithms for multi-label multiclass problems In a companion paper <ref> [29] </ref>, we introduced and analyzed two new boosting algorithms for multiclass, multi-label classification problems. Here, we review the two algorithms, discuss four versions of these algorithms, and describe an efficient implementation of the algorithms for the problem of text categorization. <p> This view of the algorithm leads to a simple analysis. Specifically, we have proved <ref> [29] </ref> a bound on the empirical Hamming loss of this algorithm, i.e., the fraction of examples i and labels ` for which the sign of f (x i ; `) differs from Y i f`g. <p> In words, W j` j` ) is the weight (with respect to the distribution D t ) of the documents in partition X j which are (are not) labeled by `. It can be shown <ref> [29] </ref> that Z t is minimized for a particular term by choosing c j` = 1 j` W ; (5) and by setting ff t = 1. <p> Hence, the term w has no influence on the classification if it does not appear in the document. As before, ff t is set to 1. Let X D t (i; `) be the weight of all the document that do not contain w. Then it can be shown <ref> [29] </ref> that Z t = W 0 + 2 `2Y W 1` ; (8) and, as before, on each round we choose a term w for which the value Z t is smallest. <p> With the same notation defined in Section 4.1, we set c j` = sign j` j` which can be viewed as a (weighted) majority vote over examples in block X j for each label `. Let X X fi fi W + W fi Then it can be shown <ref> [29] </ref> that, for the purposes of minimizing Z t , we should choose ff t = 1 1 r t giving Z t = 1 r 2 4.4 AdaBoost.MR with discrete predictions We next describe a weak learner for AdaBoost.MR. <p> The quantity r t can be computed efficiently in terms of the weights v t (defined in Eq. (3)). Let d t (i; `) = 1 X v t (i; ` 0 ) : Then it can be shown <ref> [29] </ref> that r t = i;` Thus, for a particular term w, we should choose c j` = sign 0 X d t (i; `) Y i f`g A which gives r t = j2f0;1g `2Y fi fi fi i:x i 2X j fi fi fi : (11) We thus choose
Reference: [30] <author> J.H. Wright, A.L. Gorin, and G. Riccardi. </author> <title> Automatic acquisition of salient grammar fragments for call-type classification. </title> <booktitle> In Proc. Eurospeech, </booktitle> <pages> pages 1419-1422, </pages> <year> 1997. </year>
Reference-contexts: There are fourteen call types, plus an `other' category. Some calls can be of more than one type (for instance, a call can be both collect and person-to-person). This task was previously studied by Gorin and others <ref> [11, 10, 24, 30] </ref>, and we used the same data, namely, a collection of 8,000 training utterances and 1,000 test utterances. Both the training and test utterances were all transcribed by humans from actual spoken responses. <p> We trained real AdaBoost.MH on this data using 300 rounds of boosting, and allowing sparse word trigrams for the terms used in forming the weak hypotheses. We compared our system to the best previous published work on this dataset, namely, that of Wright, Gorin, and Riccardi <ref> [30] </ref>. The results are shown in Figure 10 as a set of ROC curves. For the top set of curves, the algorithms 22 were tested using human-transcribed test data. <p> For the bottom set of curves, the test data were generated using an automatic speech recognizer (based on the same spoken utterances). The solid curves are for AdaBoost.MH, and the dashed curves are those of Wright, Gorin, and Riccardi <ref> [30] </ref>. The performance of the two algorithms is strikingly similar for most reject levels. However, AdaBoost.MH does significantly better on the transcribed data for moderately large reject levels of 40% or more.
Reference: [31] <author> Y. Yang and C.G. Chute. </author> <title> An example-based mapping method for text classification and retrieval. </title> <journal> ACM Transactions on Information Systems, </journal> <volume> 12(3), </volume> <year> 1994. </year>
Reference-contexts: We are especially interested in multiclass and multi-label problems, which we consider to be the most natural. Most of the research in text categorization has been devoted to binary problems (e.g. <ref> [17, 19, 32, 31, 1, 12] </ref> and the many references therein) where a document is classified as either "relevant" or "not relevant" with respect to a pre-determined topic.
Reference: [32] <author> Yiming Yang. </author> <title> Expert network: effective and efficient learning from human decisions in text categorization and retrieval. </title> <booktitle> In Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 13-22, </pages> <year> 1994. </year> <month> 25 </month>
Reference-contexts: We are especially interested in multiclass and multi-label problems, which we consider to be the most natural. Most of the research in text categorization has been devoted to binary problems (e.g. <ref> [17, 19, 32, 31, 1, 12] </ref> and the many references therein) where a document is classified as either "relevant" or "not relevant" with respect to a pre-determined topic.
References-found: 32

