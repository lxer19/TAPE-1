URL: http://www.merl.com/reports/TR96-37/TR96-37.ps.gz
Refering-URL: http://www.merl.com/reports/TR96-37/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: freeman@merl.com jbt@psyche.mit.edu  
Title: Learning bilinear models for two-factor problems in vision  
Author: W. T. Freeman J. B. Tenenbaum 
Address: 201 Broadway E10-210 Cambridge, MA 02139 Cambridge, MA 02139  
Affiliation: MERL, a Mitsubishi Electric Research Lab MIT Dept. of Brain and Cognitive Sciences  
Abstract: MERL Technical Report 96-37 MERL, a Mitsubishi Electric Research Lab 201 Broadway Cambridge, MA 02139 November, 1996 Abstract In many vision problems, we want to infer two (or more) hidden factors which interact to produce our observations. We may want to disentangle illuminant and object colors in color constancy; rendering conditions from surface shape in shape-from-shading; face identity and head pose in face recognition; or font and letter class in character recognition. We refer to these two factors generically as "style" and "content". Bilinear models offer a powerful framework for extracting the two-factor structure of a set of observations, and are familiar in computational vision from several well-known lines of research. This paper shows how bilinear models can be used to learn the style-content structure of a pattern analysis or synthesis problem, which can then be generalized to solve related tasks using different styles and/or content. We focus on three kinds of tasks: extrapolating the style of data to unseen content classes, classifying data with known content under a novel style, and translating two sets of data, generated in different styles and with distinct content, into each other's styles. We show examples from color constancy, face pose estimation, shape-from-shading, typography and speech. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. J. Atick, P. A. Griffin, and A. N. Redlich. </author> <title> Statistical approach to shape from shading: Reconstruction of 3d face surfaces from single 2d images. </title> <booktitle> Neural Computation, </booktitle> <year> 1995. </year> <note> in press. </note>
Reference-contexts: The quality of the synthesized results demonstrates that the style-content interaction model W learned during the training phase is sufficient to allow good recovery of both face shape and illuminant from a single image during the test phase. Atick <ref> [1] </ref> also showed that shape-from-shading from a single image could be solved by assuming a low-dimensional shape space. An explicit shape space is learned directly from 3-D range maps and built into a physical model of shading.
Reference: [2] <author> P. N. Belhumeur and D. J. Kriegman. </author> <title> What is the set of images of an object under all possible lighting conditions. </title> <booktitle> In Proc. IEEE CVPR, </booktitle> <pages> pages 270-277, </pages> <year> 1996. </year>
Reference-contexts: There are many reasons to choose a bilinear form for f: * Linear models have been successfully applied to many vision problems <ref> [23, 7, 24, 2, 13, 14, 19, 16] </ref>. These studies suggest that many data sets produced by varying a single style or content factor (with all other factors held constant) can be represented exactly or approximately by linear models.
Reference: [3] <author> D. Beymer and T. Poggio. </author> <title> Image representations for visual learning. </title> <journal> Science, </journal> <volume> 272 </volume> <pages> 1905-1909, </pages> <month> June 28 </month> <year> 1996. </year>
Reference-contexts: We need to represent shapes of different topologies in comparable forms. This motivates using a particle model to represent shape [20]. Further, we want the letters in our representation to behave like a linear vector space, where linear combinations of letters also look like letters. Beymer and Poggio <ref> [3] </ref> advocate a dense warp map for related problems. Combining the above, we chose to represent shape by the set of displacements that a set of particles would have to undergo from a reference shape to form the target shape. With identical particles, there are many possible such warp maps.
Reference: [4] <author> M. D'Zmura. </author> <title> Color constancy: surface color from changing illumination. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 9 </volume> <pages> 490-493, </pages> <year> 1992. </year>
Reference-contexts: We want to perceive the true shapes, colors, or faces, independent of the rendering conditions, or want to recognize the speaker's words independent of the accent. This style/content factorization is an essential problem in vision, and many researchers have addressed related issues (e.g., <ref> [10, 22, 4, 13] </ref>). A key feature of the style-content factorization, which has not been addressed in these previous papers, is that it is well-suited to learning the structure of analysis or synthesis problems, as we describe below. <p> One example is the "color constancy" problem <ref> [4, 13, 10, 5] </ref>. The spectrum of light reflecting off an object is a function of both the unknown illumination spec trum and the object's unknown reflectance spectrum. <p> They can effectively translate the observations of unknown colors, viewed under an unknown illumi-nant, to how they would appear under a canonical illuminant. This is the translation problem of Fig. 4. References <ref> [4, 13, 10] </ref> analyze the case of full training information, but do not address the translation problem. Our approach is to learn a W matrix for the training set. We then hold that fixed, and fit for both the a and b parameters for the new observations.
Reference: [5] <author> W. T. Freeman and D. H. Brainard. </author> <title> Bayesian decision theory, the maximum local mass estimate, and color constancy. </title> <booktitle> In Proc. 5th Intl. Conf. on Computer Vision, </booktitle> <pages> pages 210-217. </pages> <publisher> IEEE, </publisher> <year> 1995. </year>
Reference-contexts: One example is the "color constancy" problem <ref> [4, 13, 10, 5] </ref>. The spectrum of light reflecting off an object is a function of both the unknown illumination spec trum and the object's unknown reflectance spectrum. <p> Our approach is to learn a W matrix for the training set. We then hold that fixed, and fit for both the a and b parameters for the new observations. Then we can translate across style or content, as desired. In general, the color constancy problem is under-determined <ref> [5] </ref>. Researchers have proposed using additional constraints or visual cues, such as interreflec-tions or specular reflections. A nice property of the bilinear models is that these or other visual constaints can be learned. We show a synthetic example to illustrate this. <p> We have not yet undertaken the calibrated studies to determine how well this technique works for natural scenes.) Using a set of programs developed by Brainard <ref> [5] </ref>, we drew 30 random samples from a 3-dimensional linear model for surface reflectances, and 9 random samples from another 3-dimensional linear model for il-luminants. We rendered these, using the randomly drawn specularity values, creating the full training observation matrix corresponding.
Reference: [6] <author> I. Grebert, D. G. Stork, R. Keesing, and S. Mims. </author> <title> Connectionist generalization for production: An example from gridfont. </title> <booktitle> Neural Networks, </booktitle> <volume> 5 </volume> <pages> 699-710, </pages> <year> 1992. </year>
Reference-contexts: We applied the asymmetric bilinear model, in the representation above, to the extrapolation task of Fig. 2. Our shape representation allowed us to work with familiar and natural fonts, in contrast to earlier work on extrapolation in typography <ref> [6, 8] </ref> We digitized 62 letters (uppercase letters, lowercase letters, digits 0-9) of six fonts at 38 fi 38 pixels using Adobe Photoshop (uppercase letters shown in the first 5 columns and last column of Fig. 6).
Reference: [7] <author> P. W. Hallinan. </author> <title> A low-dimensional representation of human faces for arbitrary lighting conditions. </title> <booktitle> In Proc. IEEE CVPR, </booktitle> <pages> pages 995-999, </pages> <year> 1994. </year>
Reference-contexts: There are many reasons to choose a bilinear form for f: * Linear models have been successfully applied to many vision problems <ref> [23, 7, 24, 2, 13, 14, 19, 16] </ref>. These studies suggest that many data sets produced by varying a single style or content factor (with all other factors held constant) can be represented exactly or approximately by linear models.
Reference: [8] <author> D. Hofstadter. </author> <title> Fluid Concepts and Creative Analogies. </title> <publisher> Basic Books, </publisher> <year> 1995. </year>
Reference-contexts: We applied the asymmetric bilinear model, in the representation above, to the extrapolation task of Fig. 2. Our shape representation allowed us to work with familiar and natural fonts, in contrast to earlier work on extrapolation in typography <ref> [6, 8] </ref> We digitized 62 letters (uppercase letters, lowercase letters, digits 0-9) of six fonts at 38 fi 38 pixels using Adobe Photoshop (uppercase letters shown in the first 5 columns and last column of Fig. 6).
Reference: [9] <author> G. J. Klinker, S. A. Shafer, and T. Kanade. </author> <title> The measurement of highlights in color images. </title> <journal> Intl. J. Comp. Vis., </journal> <volume> 2(1) </volume> <pages> 7-32, </pages> <year> 1988. </year>
Reference-contexts: A nice property of the bilinear models is that these or other visual constaints can be learned. We show a synthetic example to illustrate this. Methods which exploit specularities to achieve color constancy typically require specularity levels large enough to dominate image chromaticity histograms <ref> [11, 9] </ref>. Here we show how small, random variations in specularity may also be used to achieve color constancy.
Reference: [10] <author> J. J. Koenderink and A. J. van Doorn. </author> <title> The generic bilinear calibration-estimation problem. </title> <note> Intl. J. Comp. Vis., 1996. in press. </note>
Reference-contexts: For example, in typography, character and font combine to yield the rendered letter, Fig. 1. We may think of one factor as "content" (the character) and the other as "style" (the font). Many estimation problems fit this form (see also <ref> [10, 15] </ref>). In speech recognition, the speaker's accent modulates words to produce sounds. In face recognition, a person's image is modulated by both their identity and by the orientation of their head. In shape-from-shading, both the shape of the object and the lighting conditions influence the image. <p> We want to perceive the true shapes, colors, or faces, independent of the rendering conditions, or want to recognize the speaker's words independent of the accent. This style/content factorization is an essential problem in vision, and many researchers have addressed related issues (e.g., <ref> [10, 22, 4, 13] </ref>). A key feature of the style-content factorization, which has not been addressed in these previous papers, is that it is well-suited to learning the structure of analysis or synthesis problems, as we describe below. <p> This enables better performance on a classification, extrapolation, or translation task with the test data than would have been possible without the initial training on the set of related observations. Singular value decomposition (SVD) can be used to fit the parameters of the asymmetric model <ref> [12, 13, 10, 21] </ref>. This technique works the same regardless of whether we have one or more observations for each style-content pair, as long as we have the same number of observations for each pair. <p> One example is the "color constancy" problem <ref> [4, 13, 10, 5] </ref>. The spectrum of light reflecting off an object is a function of both the unknown illumination spec trum and the object's unknown reflectance spectrum. <p> They can effectively translate the observations of unknown colors, viewed under an unknown illumi-nant, to how they would appear under a canonical illuminant. This is the translation problem of Fig. 4. References <ref> [4, 13, 10] </ref> analyze the case of full training information, but do not address the translation problem. Our approach is to learn a W matrix for the training set. We then hold that fixed, and fit for both the a and b parameters for the new observations.
Reference: [11] <author> H. Lee. </author> <title> Method for computing the scene-illuminant chromaticity from specular highlights. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 3(10) </volume> <pages> 1694-1699, </pages> <year> 1986. </year>
Reference-contexts: A nice property of the bilinear models is that these or other visual constaints can be learned. We show a synthetic example to illustrate this. Methods which exploit specularities to achieve color constancy typically require specularity levels large enough to dominate image chromaticity histograms <ref> [11, 9] </ref>. Here we show how small, random variations in specularity may also be used to achieve color constancy.
Reference: [12] <author> J. R. Magnus and H. Neudecker. </author> <title> Matrix differential calculus with applications in statistics and econometrics. </title> <publisher> Wiley, </publisher> <year> 1988. </year>
Reference-contexts: and vice versa, bilinear models are thus naturally promising candidates for modeling data produced by the inter action of individually linear factors. * Bilinear models inherit many convenient features of linear models: the are easy to fit (either with closed form solutions or efficient iterative solutions with guarantees of convergence <ref> [12] </ref>. <p> This enables better performance on a classification, extrapolation, or translation task with the test data than would have been possible without the initial training on the set of related observations. Singular value decomposition (SVD) can be used to fit the parameters of the asymmetric model <ref> [12, 13, 10, 21] </ref>. This technique works the same regardless of whether we have one or more observations for each style-content pair, as long as we have the same number of observations for each pair. <p> For the symmetric model, there is an iterative procedure for fitting model parameters to the data which converges to the least squares model fit <ref> [12, 13] </ref>. The algorithm iteratively applies SVD as in the asymmetric case, repeatedly re-ordering the observation matrix elements to alternate the roles of the style and content factors.
Reference: [13] <author> D. H. Marimont and B. A. Wandell. </author> <title> Linear models of surface and illuminant spectra. </title> <journal> J. Opt. Soc. Am. A, </journal> <volume> 9(11) </volume> <pages> 1905-1913, </pages> <year> 1992. </year>
Reference-contexts: We want to perceive the true shapes, colors, or faces, independent of the rendering conditions, or want to recognize the speaker's words independent of the accent. This style/content factorization is an essential problem in vision, and many researchers have addressed related issues (e.g., <ref> [10, 22, 4, 13] </ref>). A key feature of the style-content factorization, which has not been addressed in these previous papers, is that it is well-suited to learning the structure of analysis or synthesis problems, as we describe below. <p> There are many reasons to choose a bilinear form for f: * Linear models have been successfully applied to many vision problems <ref> [23, 7, 24, 2, 13, 14, 19, 16] </ref>. These studies suggest that many data sets produced by varying a single style or content factor (with all other factors held constant) can be represented exactly or approximately by linear models. <p> This enables better performance on a classification, extrapolation, or translation task with the test data than would have been possible without the initial training on the set of related observations. Singular value decomposition (SVD) can be used to fit the parameters of the asymmetric model <ref> [12, 13, 10, 21] </ref>. This technique works the same regardless of whether we have one or more observations for each style-content pair, as long as we have the same number of observations for each pair. <p> For the symmetric model, there is an iterative procedure for fitting model parameters to the data which converges to the least squares model fit <ref> [12, 13] </ref>. The algorithm iteratively applies SVD as in the asymmetric case, repeatedly re-ordering the observation matrix elements to alternate the roles of the style and content factors. <p> The algorithm iteratively applies SVD as in the asymmetric case, repeatedly re-ordering the observation matrix elements to alternate the roles of the style and content factors. We refer the reader to the pseudo-code in Ma rimont and Wandell <ref> [13] </ref>. 5 Extrapolation 5.1 Typography To show that the bilinear models can analyze and synthesize something like style even for a very nonlinear problem, we apply these models to typography. <p> One example is the "color constancy" problem <ref> [4, 13, 10, 5] </ref>. The spectrum of light reflecting off an object is a function of both the unknown illumination spec trum and the object's unknown reflectance spectrum. <p> They can effectively translate the observations of unknown colors, viewed under an unknown illumi-nant, to how they would appear under a canonical illuminant. This is the translation problem of Fig. 4. References <ref> [4, 13, 10] </ref> analyze the case of full training information, but do not address the translation problem. Our approach is to learn a W matrix for the training set. We then hold that fixed, and fit for both the a and b parameters for the new observations.
Reference: [14] <author> H. Murase and S. Nayar. </author> <title> Visual learning and recognition of 3-d objects from appearance. </title> <journal> Intl. J. Comp. Vis., </journal> <volume> 14 </volume> <pages> 5-24, </pages> <year> 1995. </year>
Reference-contexts: There are many reasons to choose a bilinear form for f: * Linear models have been successfully applied to many vision problems <ref> [23, 7, 24, 2, 13, 14, 19, 16] </ref>. These studies suggest that many data sets produced by varying a single style or content factor (with all other factors held constant) can be represented exactly or approximately by linear models.
Reference: [15] <author> S. M. Omohundro. </author> <title> Family discovery. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <year> 1995. </year>
Reference-contexts: For example, in typography, character and font combine to yield the rendered letter, Fig. 1. We may think of one factor as "content" (the character) and the other as "style" (the font). Many estimation problems fit this form (see also <ref> [10, 15] </ref>). In speech recognition, the speaker's accent modulates words to produce sounds. In face recognition, a person's image is modulated by both their identity and by the orientation of their head. In shape-from-shading, both the shape of the object and the lighting conditions influence the image.
Reference: [16] <author> A. P. Pentland. </author> <title> Linear shape from shading. </title> <journal> Intl. J. Comp. Vis., </journal> <volume> 1(4) </volume> <pages> 153-162, </pages> <year> 1990. </year>
Reference-contexts: There are many reasons to choose a bilinear form for f: * Linear models have been successfully applied to many vision problems <ref> [23, 7, 24, 2, 13, 14, 19, 16] </ref>. These studies suggest that many data sets produced by varying a single style or content factor (with all other factors held constant) can be represented exactly or approximately by linear models.
Reference: [17] <author> S. E. Sclaroff. </author> <title> Modal matching: a method for describing, comparing, and manipulating digital signals. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1995. </year>
Reference-contexts: With identical particles, there are many possible such warp maps. For our models to work well, we want similar warps to represent similarly shaped letters. To accomplish this, we use a physical model (in the spirit of <ref> [17, 18] </ref>, but with the goal of dense correspondence, rather than modal representation). We give each particle of the reference shape (taken to be the full rectangular bitmap) unit positive charge, and each pixel of the target letter negative charge proportional to its grey level intensity.
Reference: [18] <author> L. Shapiro and J. Brady. </author> <title> Feature-based correspondence: an eigenvector approach. </title> <journal> Image and Vision Computing, </journal> <volume> 10(5) </volume> <pages> 283-288, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: With identical particles, there are many possible such warp maps. For our models to work well, we want similar warps to represent similarly shaped letters. To accomplish this, we use a physical model (in the spirit of <ref> [17, 18] </ref>, but with the goal of dense correspondence, rather than modal representation). We give each particle of the reference shape (taken to be the full rectangular bitmap) unit positive charge, and each pixel of the target letter negative charge proportional to its grey level intensity.
Reference: [19] <author> A. Shashua. </author> <title> Geometry and photomnetry in 3D visual recognition. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <year> 1992. </year>
Reference-contexts: There are many reasons to choose a bilinear form for f: * Linear models have been successfully applied to many vision problems <ref> [23, 7, 24, 2, 13, 14, 19, 16] </ref>. These studies suggest that many data sets produced by varying a single style or content factor (with all other factors held constant) can be represented exactly or approximately by linear models.
Reference: [20] <author> R. Szeleski and D. Tonnesen. </author> <title> Surface modeling with oriented particle systems. </title> <booktitle> In Proc. </booktitle> <volume> SIG-GRAPH 92, volume 26, </volume> <pages> pages 185-194, </pages> <year> 1992. </year> <title> In Computer Graphics, </title> <booktitle> Annual Conference Series. </booktitle>
Reference-contexts: The extrapolation task is to synthesize letters in a new font, given a set of examples of letters in that font. The letter representation is important. We need to represent shapes of different topologies in comparable forms. This motivates using a particle model to represent shape <ref> [20] </ref>. Further, we want the letters in our representation to behave like a linear vector space, where linear combinations of letters also look like letters. Beymer and Poggio [3] advocate a dense warp map for related problems.
Reference: [21] <author> J. B. Tenenbaum and W. T. Freeman. </author> <title> Separable mixture models: Separating style and content. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <year> 1996. </year>
Reference-contexts: They can be embedded in a probabilistic model with gaussian noise to yield tractable maximum likelihood estimation with missing information, as de scribed in <ref> [21] </ref> and applied here in Section 4. * The models extend easily to multiple factors, yielding multilinear models. * Bilinear models are simple, yet seem capable of modeling real image data, so we want to take this approach as far as we can. <p> This enables better performance on a classification, extrapolation, or translation task with the test data than would have been possible without the initial training on the set of related observations. Singular value decomposition (SVD) can be used to fit the parameters of the asymmetric model <ref> [12, 13, 10, 21] </ref>. This technique works the same regardless of whether we have one or more observations for each style-content pair, as long as we have the same number of observations for each pair. <p> Note that this is formally identical to the Tomasi and Kanade's use of the SVD to solve the structure-from-motion problem under orthographic projection, but instead of camera motion and shape matrices replaced by style and content matrices respectively. See <ref> [21] </ref> for how to fit model to more complicated data patterns (e.g. varying numbers of observations per style and content, uncertain assignment of observations to styles or content classes). <p> EM iterates between estimating the parameters of a new head model B c fl ik (M-step), and (soft) assigning each image to the appropriate pose categories (E-step). For details of the EM algorithm applied to classification problems with a new style or content, see <ref> [21] </ref>. Classification performance is determined by the percentage of test images for which the probability of pose s, as given by EM, is greatest for the actual pose class. We repeated the experiment 11 times, leaving each of the 11 subjects out of the training set in turn. <p> Of course, exactly the same techniques can be applied to classifying content under varying styles, and <ref> [21] </ref> reports one example in the domain of speech recognition.
Reference: [22] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> Intl. J. Comp. Vis., </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: We want to perceive the true shapes, colors, or faces, independent of the rendering conditions, or want to recognize the speaker's words independent of the accent. This style/content factorization is an essential problem in vision, and many researchers have addressed related issues (e.g., <ref> [10, 22, 4, 13] </ref>). A key feature of the style-content factorization, which has not been addressed in these previous papers, is that it is well-suited to learning the structure of analysis or synthesis problems, as we describe below.
Reference: [23] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of cognitive neuroscience, </journal> <volume> 3(1), </volume> <year> 1991. </year>
Reference-contexts: There are many reasons to choose a bilinear form for f: * Linear models have been successfully applied to many vision problems <ref> [23, 7, 24, 2, 13, 14, 19, 16] </ref>. These studies suggest that many data sets produced by varying a single style or content factor (with all other factors held constant) can be represented exactly or approximately by linear models.
Reference: [24] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Pat. Anal. Mach. Intell., </journal> <volume> 13(10) </volume> <pages> 992-1006, </pages> <year> 1991. </year> <title> domain of typography. Training data included upper and lower case alphabets, and digits 0-9. Identity P s pose classification. P s Basis images Note that in the bilinear model, each basis face plays the same role across poses. </title>
Reference-contexts: There are many reasons to choose a bilinear form for f: * Linear models have been successfully applied to many vision problems <ref> [23, 7, 24, 2, 13, 14, 19, 16] </ref>. These studies suggest that many data sets produced by varying a single style or content factor (with all other factors held constant) can be represented exactly or approximately by linear models.
References-found: 24

