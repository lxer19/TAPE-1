URL: http://www.math.macalester.edu/~fox/cs88/papers/aaai96.ps
Refering-URL: http://www.math.macalester.edu/~fox/cs88/readings.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: mock@cs.ucdavis.edu  
Title: Hybrid Hill-Climbing and Knowledge-Based Techniques for Intelligent News Filtering  
Author: Kenrick J. Mock 
Keyword: Content Areas: software agents Abstract ID: A626 Word Count: 6728  
Address: JF2-76 2111 N.E. 25th Avenue Hillsboro, OR 97124  
Affiliation: Intel Corporation Intel Architecture Lab,  
Abstract: As the size of the Internet increases, the amount of data available to users has dramatically risen, resulting in an information overload for users. This work involved the creation of an intelligent information news filtering system named INFOS (Intelligent News Filtering Organizational System) to reduce the users search burden by automatically eliminating Usenet news articles predicted to be irrelevant. These predictions are learned automatically by adapting an internal user model that is based upon features taken from articles and collaborative features derived from other users. The features are manipulated through keyword-based techniques and knowledge-based techniques to perform the actual filtering. Knowledge-based systems have the advantage of analyzing input text in detail, but at the cost of computational complexity and the difficulty of scaling up to large domains. In contrast, statistical and keyword approaches scale up readily but result in a shallower understanding of the input. A hybrid system integrating both approaches improves accuracy over keyword approaches, supports domain knowledge, and retains scalability. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Brewer, R.S. & Johnson, P.M. </author> <year> (1994). </year> <title> Toward Collaborative Knowledge Management within Large, Dynamically Structured Information Systems. Internal Research Report, Collaborative Software Development Laboratory, </title> <institution> Department of Information and Computer Sciences, University of Hawaii. </institution> <note> WWW: http://www.ics.hawaii.edu/~csdl/urn. </note>
Reference: <author> Callan, J.P. Croft, W.B. </author> <year> (1993). </year> <title> An Approach to Incorporating CBR Concepts in IR Systems. </title> <booktitle> Proceedings of the 1993 Spring Symposium on Case-Based Reasoning and Information Retrieval, </booktitle> <publisher> AAAI Press, </publisher> <pages> pp 28-32. </pages>
Reference-contexts: In this way, cases are indexed via both conceptual (controlled) and keyword (uncontrolled) vocabularies, allowing conceptual retrieval when possible, and also keyword retrieval under unforeseen situations so that performance is still possible <ref> (Callan & Croft, 1993) </ref>. The method in which articles are indexed using the sense definitions is to construct a pointer to the file that contains currently defined sense in a global abstraction hierarchy. An example memory hierarchy with three cases is shown in figure 4.
Reference: <author> DeJong, G. </author> <year> (1982). </year> <title> An Overview of the FRUMP System. In W.G. </title> <editor> Lehnert & M. H. Ringle (Eds.), </editor> <booktitle> Strategies for Natural Language Processing, </booktitle> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum, </publisher> <pages> pp. 149-174. </pages>
Reference: <author> Eberts, R. </author> <year> (1991). </year> <title> Knowledge Acquisition Using Neural Networks for Intelligent Interface Design. </title> <booktitle> Proceedings of the 1991 IEEE International Conference on Systems, Man, and Cybernetics, </booktitle> <pages> pp. 1331-1335. </pages>
Reference: <author> Evans, D.A. Ginther-Webster, K. Hart, M. Lefferts, R.G. Monarch, I.A. </author> <year> (1991). </year> <title> Automatic Indexing Using Selective NLP and First-Order Thesauri. </title> <booktitle> Proceedings of the Intelligent Text and Image Handling Conference, Barcelona, Spain. </booktitle> <pages> pp 624-643. </pages>
Reference-contexts: Finally, a CBR system also provides an excellent opportunity to support information retrieval of previously read articles in addition to information filtering. 11 5.1 Index Extraction This work uses both controlled and uncontrolled index extraction as in the CLARIT system <ref> (Evans et. al., 1991) </ref>. In the controlled approach, a predefined list of terms or knowledge structures is used to guide the indexing process. This approach can disambiguate concepts with high accuracy; however, one most have a fully defined knowledge base and predict all the structures that may occur. <p> After candidate nouns and verbs have been identified, this information is used to index the document. In addition to the sense definition itself as an index, other relevancy statistics are also associated to each term, including frequency and rarity <ref> (Evans et. al, 1991) </ref>. Frequency is merely the number of times the term appears in the document / number of times the term has appeared in the domain. This measure operates upon the assumption that domain words appearing often are indicative of the document.
Reference: <author> Goldberg, D., Nichols, D., Oki, B., Terry, D. </author> <year> (1992). </year> <title> Using Collaborative Filtering to Weave an Information Tapestry. </title> <journal> Communications of the ACM, </journal> <volume> 35 (12), </volume> <pages> pp. 61-70. </pages>
Reference: <author> Jennings, A. & Higuchi, H. </author> <year> (1992). </year> <title> A Personal News Service Based on a User Model Neural Network. </title> <journal> IEICE Transactions Inf. & Systems, E75 D(2), </journal> <pages> pp. 198-209. </pages> <note> 17 Lang, </note> <author> K. </author> <year> (1995). </year> <title> NewsWeeder: Learning to Filter Netnews. </title> <booktitle> Proceedings of the Twelfth International Machine Learning Conference. </booktitle>
Reference-contexts: Class SimilarityCombn Acc SimilarityCombn j A Accepted SimilarityCombn j SimilarityCombn Acc A jected else Unknown t t t = - &gt; (Re ) ( ) : Re (3) However, how should these percentages be combined? What values should be assigned to constants K 1 through K 4 ? Some systems <ref> (Jennings & Higuchi, 1992) </ref> give higher weight to the subject features on the assumption that these are most predictive. To investigate which terms are actually most predictive, experiments were performed to evaluate the impact of each feature individually.
Reference: <author> Lashkari, Y., Metral, M., & Maes, P. </author> <year> (1994). </year> <title> Collaborative Interface Agents. </title> <booktitle> Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 444-449. </pages>
Reference: <author> Lenat, D.B. </author> <year> (1995). </year> <title> CYC: A Large-Scale Investment in Knowledge Infrastructure. </title> <journal> Communications of the ACM, </journal> <volume> 38 (11), </volume> <pages> pp. 32-38. </pages>
Reference-contexts: Other areas of proposed work include modifications for INFOS to run offline, a graphical user interface, self-modifying parameters, the incorporation of other knowledge bases such as CYC <ref> (Lenat, 1995) </ref>, and the application of filtering to the World Wide Web and intelligent tutoring systems. Additional information is available from the WWW at: http://phobos.cs.ucdavis.edu:8001/~mock/INFOS/infos.html 7. Summary As the information age grows in scale, the amount of incoming data becomes too large for humans to handle.
Reference: <author> Mauldin, M. L. </author> <year> (1991). </year> <title> Conceptual Information Retrieval: A case study in Adaptive Partial Parsing. </title> <publisher> Kluwer Academic Publishers. Norwell, </publisher> <address> MA. </address>
Reference-contexts: Although not designed to filter news, FRUMP actually addresses a more difficult problem - that of story understanding. A more recent work that also performs script based learning to understand and retrieve usenet news articles is Mauldins FERRET system <ref> (Mauldin, 1991) </ref>. In Ferret, a query and text 4 articles are parsed into Schanks Conceptual Dependency (CD) theory (Schank, 1977), which is intended to be an unambiguous representation for knowledge. In Ferret, once news articles and search queries are parsed into CD, predefined scripts are compared to the CD representations.
Reference: <author> Miller, G.A. </author> <year> (1995). </year> <title> WordNet: A Lexical Database for English. </title> <journal> Communications of the ACM, </journal> <volume> 38 (11), </volume> <pages> pp. 39-41. </pages>
Reference-contexts: The controlled approach in INFOS is composed of a knowledge-based method derived from WordNet, while the uncontrolled approach is composed of a keyword-based inverted index using features such as unknown words, author names, or collaborative data. INFOS uses WordNet <ref> (Miller, 1995) </ref> to map words into concepts, and these concepts are used as indices rather than the actual words. In the event that a word is missing from the WordNet lexicon, then that word is used in an inverted index to index the source document directly.
Reference: <author> Mock, K., Vemuri, V. </author> <year> (1994). </year> <title> Adaptive User Interface for Intelligent Information Filtering. </title> <booktitle> Proceedings of the Third Golden West International Conference on Intelligent Systems, </booktitle> <pages> pp 506-517. </pages>
Reference: <author> Paice, C.D. </author> <year> (1989). </year> <title> Automatic Generation and Evaluation of Back-of Book Indexes. Prospects for Intelligent Retrieval, </title> <booktitle> Informatics 10, </booktitle> <address> Cambridge MA. </address>
Reference-contexts: Consequently, INFOS attempts to find appropriate noun or verb phrases based upon Paices index extraction algorithm <ref> (Paice, 1989) </ref>. filtering. This algorithm assumes that sentences repeat an underlying concept within a topic neighborhood of a few sentences. Those words occurring with a high frequency are likely to be relevant to the topic at hand.
Reference: <author> Ram, A. </author> <year> (1992). </year> <title> Natural Language Understanding for Information-Filtering Systems. </title> <journal> Communications of the ACM, </journal> <volume> 35 (12), </volume> <pages> pp. 80-81. </pages>
Reference-contexts: More humanlike approaches to news understanding have been explored by DeJong (1982) and Mauldin (1991). The main advantage of a symbolic, knowledge-based approach is that the input text is understood as a human might understand the text, allowing for much greater understanding <ref> (Ram, 1992) </ref>. One of the earliest knowledge-based approaches to news story understanding is the FRUMP system developed by DeJong . FRUMP is given UPI news stories, processes the story by comparing with stereotypical events through a structure named a script, and provides a summary of the article.
Reference: <author> Resnick, P., et al. </author> <year> (1994). </year> <title> GroupLens: An Open Architecture for Collaborative Filtering of Netnews. Internal Research Report, </title> <institution> MIT Center for Coordination Science. </institution>
Reference: <author> Riecken, D. </author> <year> (1994). </year> <title> Intelligent Agents. </title> <journal> Communications of the ACM, </journal> <volume> 37 (7), </volume> <pages> pp. 18-21. </pages>
Reference-contexts: 1. The Information Overload Problem The goal of this project is to predict whether new news articles are likely to be of interest, or not of interest, based upon the prior behavior of the user. Systems that perform this type of intelligent behavior have recently been touted as intelligent agents <ref> (Riecken, 1994) </ref> by the media. The work proposed here follows the same vein; the system is intended to aid the user in her work rather than take over completely, watching and learning what the user does and what the user is interested in so that intelligent filtering may be performed.
Reference: <author> Salton, G. </author> <title> The SMART Retrieval System: Experiments in automatic document processing. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice-Hall, </publisher> <year> 1971. </year>
Reference: <author> Schank, R.C. & Abelson, R. </author> <year> (1977). </year> <title> Scripts, Plans, Goals, and Understanding. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, Publishers. </publisher>
Reference-contexts: A more recent work that also performs script based learning to understand and retrieve usenet news articles is Mauldins FERRET system (Mauldin, 1991). In Ferret, a query and text 4 articles are parsed into Schanks Conceptual Dependency (CD) theory <ref> (Schank, 1977) </ref>, which is intended to be an unambiguous representation for knowledge. In Ferret, once news articles and search queries are parsed into CD, predefined scripts are compared to the CD representations. As in FRUMP, the scripts represent stereotypical sequences of events and information.
Reference: <author> Sheth, B.D. </author> <year> (1994). </year> <title> A Learning Approach to Personalized Information Filtering. </title> <type> Masters Thesis. </type> <institution> Department of Computer Science and Engineering, Massachusetts Institute of Technology. </institution>
Reference-contexts: The similarity of a new article is computed by comparing it against classes instead of against individual articles, and the class most similar to the new article is used to predict the users interest in the unread article. The NewT system <ref> (Sheth, 1994) </ref> is based upon tf-idf and genetic algorithms for news filtering. The tf-idf method is also compared against Langs MDL method as a baseline for evaluation in NewsWeeder (Lang, 1995). More humanlike approaches to news understanding have been explored by DeJong (1982) and Mauldin (1991).
Reference: <author> Stevens, C. </author> <year> (1992). </year> <title> Knowledge-Based Assistance for Accessing Large, Poorly Structured Information Spaces. </title> <type> Ph.D. Dissertation Thesis. </type> <institution> Department of Computer Science, University of Colorado. </institution>
Reference-contexts: After keywords have been scanned from news articles, a popular method of indexing the news document with the extracted terms is to use rule-based agents to model a users usage patterns as in INFOSCOPE <ref> (Stevens, 1992) </ref>, or to couple the term-frequency with the inverse-document frequency. This method is often referred to as tf-idf (Salton, 1991). These two terms are combined by multiplying the term-frequency (tf) by 1/document-frequency (idf) to obtain a metric of relevancy for each term. <p> material from old articles removed. 4.1 Global Hill Climbing - A Simple, Keyword Scheme One of the requirements for the user model is that it must be very simple for users to modify and understand; if the model is too difficult to manipulate, the average user will never use it <ref> (Stevens, 1992) </ref>. In addition to simplicity, the model must also provide for good performance. Consequently, a keyword/feature based system was initially selected for the user model since it is easy to perform computationally and also easy for users to understand.
References-found: 20

