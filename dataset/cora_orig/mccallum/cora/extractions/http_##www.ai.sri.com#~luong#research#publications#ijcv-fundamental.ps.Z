URL: http://www.ai.sri.com/~luong/research/publications/ijcv-fundamental.ps.Z
Refering-URL: http://www.ai.sri.com/~luong/research/publications/publications.html
Root-URL: 
Email: luong,faugeras@sophia.inria.fr  
Title: The Fundamental matrix: theory, algorithms, and stability analysis  
Author: Q.-T. Luong and O.D. Faugeras 
Address: 2004 route des Lucioles, B.P. 93 06902 Sophia-Antipolis, France  
Affiliation: I.N.R.I.A.  
Abstract: In this paper we analyze in some detail the geometry of a pair of cameras, i.e. a stereo rig. Contrarily to what has been done in the past and is still done currently, for example in stereo or motion analysis, we do not assume that the intrinsic parameters of the cameras are known (coordinates of the principal points, pixels aspect ratio and focal lengths). This is important for two reasons. First, it is more realistic in applications where these parameters may vary according to the task (active vision). Second, the general case considered here, captures all the relevant information that is necessary for establishing correspondences between two pairs of images. This information is fundamentally projective and is hidden in a confusing manner in the commonly used formalism of the Essential matrix introduced by Longuet-Higgins [40]. This paper clarifies the projective nature of the correspondence problem in stereo and shows that the epipolar geometry can be summarized in one 3 fi 3 matrix of rank 2 which we propose to call the Fundamental matrix. After this theoretical analysis, we embark on the task of estimating the Fundamental matrix from point correspondences, a task which is of practical importance. We analyze theoretically, and compare experimentally using synthetic and real data, several methods of estimation. The problem of the stability of the estimation is studied from two complementary viewpoints. First we show that there is an interesting relationship between the Fundamental matrix and three-dimensional planes which induce homographies between the images and create unstabilities in the estimation procedures. Second, we point to a deep relation between the unstability of the estimation procedure and the presence in the scene of so-called critical surfaces which have been studied in the context of motion analysis. Finally we conclude by stressing the fact that we believe that the Fundamental matrix will play a crucial role in future applications of three-dimensional Computer Vision by greatly increasing its versatility, robustness and hence applicability to real difficult problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Adiv. </author> <title> Inherent ambiguities in recovering 3-D motion and structure from a noisy flow field. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11 </volume> <pages> 477-489, </pages> <year> 1989. </year>
Reference-contexts: In the two last cases, the nature of the (Euclidean) motion can be characterized from fundamental matrices. Note that whereas the two first cases are known in the context of motion analysis ([12, 79, 31, 71, 80], <ref> [12, 53, 1, 79, 29, 8] </ref>), the last one is specific to our problem, and comes from the fact that the fundamental matrix in the case of a pure translation depends only on two independent parameters, instead of seven.
Reference: [2] <author> E.B. Barrett, M.H. Brill, N.N. Haag, and P. M. Payton. </author> <title> Invariant linear methods in pho-togrammetry and model-matching. </title> <editor> In J.L. Mundy and A. &lt;Zisserman, editors, </editor> <booktitle> Geometric invariance in computer vision, chapter 14, </booktitle> <pages> pages 277-292. </pages> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images <ref> [2, 54, 9] </ref> (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11].
Reference: [3] <author> P.A. Beardsley. </author> <title> Applications of projective geometry to computer vision. </title> <type> PhD thesis, </type> <institution> University of Oxford, </institution> <year> 1992. </year>
Reference-contexts: Using the MAPLE system, we have shown that the two sets of constraints are equivalent. They can be included in the scheme for finding planes. A second method (also presented by <ref> [3] </ref>) uses only one plane . Let M be a space point which do not lie on , m and m 0 its two images by the two cameras. Let M 1 , the point of which has the same image by the first camera as M .
Reference: [4] <author> P.A. Beardsley, A. Zisserman, and D.W. Murray. </author> <title> Navigation using affine structure from motion. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 85-96, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: Its knowledge is essential for further use of the hierarchy of representations. For example, if an addition to the Fundamental matrix, a certain 3-D vector representing the plane at infinity is known, then affine structure (considered for instance in <ref> [60, 9, 66, 52, 4] </ref>) could be recovered. It is to be noted that there are no need for multiple matches across several frames, since the fundamental matrices can be computed independently from pairs of views.
Reference: [5] <author> F. L. Bookstein. </author> <title> Fitting conic sections to scattered data. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 9(1) </volume> <pages> 56-71, </pages> <month> Jan </month> <year> 1979. </year>
Reference-contexts: We have developed a method to perform the exact computation of this distance [42, 43], based on some special properties of the surface S, but this approach is computationally very expensive. The linear criterion can be considered as a generalization of the Bookstein distance <ref> [5] </ref> for conic fitting. The straightforward idea is to approximate the true distance of the point x to the surface by the number g (x; f ), in order to get a closed-form solution. A more precise approxi mation has been introduced by Sampson [64].
Reference: [6] <author> H.S.M. Coxeter. </author> <title> Projective Geometry. </title> <publisher> Springer Verlag, </publisher> <address> second edition, </address> <year> 1987. </year>
Reference-contexts: It is one of the reasons why projective geometry is emerging as an attractive framework for computer vision [55]. In this paper, we assume that the reader is familiar with some elementary projective geometry. Such material can be found in classical mathematic textbooks such as <ref> [65, 6, 21] </ref>, but also in the computer vision literature where it is presented in chapters of recent books [14, 34, 55], and articles [51, 33]. The main property of this camera model is thus that the relationship between the world coordinates and the pixel coordinates is linear projective.
Reference: [7] <author> K. Daniilidis. </author> <title> Zur Fehlerempfindlichkeit in der Ermittlung von Objektbeschreibungen und relativen Bewegugen aus monokularen Bildfolgen. </title> <type> PhD thesis, </type> <institution> University of Karsruhe, </institution> <year> 1992. </year>
Reference-contexts: the second order term [ffit; C 0 M; ffir fi CM] we obtain by expanding the products: = [t; C 0 M; ffir fi CM] + [ffit; C 0 M; CM] Using t = C 0 C and some standard properties of the triple product yields (as also found by <ref> [7] </ref>): = [(I + [ffir] fi )C 0 M ffir fi t + ffit; t; C 0 M] It is easy to see that this is equivalent to Horn's expression.
Reference: [8] <author> K. Daniilidis and H.-H. Nagel. </author> <title> Analytical results on error sensitivity of motion estimation from two views. </title> <journal> Image and Vision Computing, </journal> <volume> 8 </volume> <pages> 297-303, </pages> <year> 1990. </year>
Reference-contexts: In the two last cases, the nature of the (Euclidean) motion can be characterized from fundamental matrices. Note that whereas the two first cases are known in the context of motion analysis ([12, 79, 31, 71, 80], <ref> [12, 53, 1, 79, 29, 8] </ref>), the last one is specific to our problem, and comes from the fact that the fundamental matrix in the case of a pure translation depends only on two independent parameters, instead of seven.
Reference: [9] <author> S. Demey, A. Zisserman, </author> <title> and P.A. Beardsley. Affine and projective structure from motion. </title> <booktitle> In Proc. British Machine Vision Conference, </booktitle> <pages> pages 49-58, </pages> <address> Leeds, UK, </address> <year> 1992. </year>
Reference-contexts: * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images <ref> [2, 54, 9] </ref> (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. <p> Its knowledge is essential for further use of the hierarchy of representations. For example, if an addition to the Fundamental matrix, a certain 3-D vector representing the plane at infinity is known, then affine structure (considered for instance in <ref> [60, 9, 66, 52, 4] </ref>) could be recovered. It is to be noted that there are no need for multiple matches across several frames, since the fundamental matrices can be computed independently from pairs of views.
Reference: [10] <author> R. Deriche, Z. Zhang, Q.-T. Luong, and O.D. Faugeras. </author> <title> Robust recovery of the epipolar geometry for an uncalibrated stereo rig. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 567-576, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: Methods to obtain such correspondences at a subpixel precision are now available, but are detailed elsewhere <ref> [42, 10, 10] </ref>, since the emphasis of the paper is on geometric and algebraic relations which can be used to compute the fundamental matrix and to analyze its stability. Line correspondences are not sufficient with two views.
Reference: [11] <author> F. Devernay and O.D. Faugeras. </author> <title> Computing differential properties of 3-D shapes from stereoscopic images without 3-D models. </title> <booktitle> In cvpr, </booktitle> <pages> pages 208-213, </pages> <address> Seattle, WA, </address> <year> 1994. </year> <month> 42 </month>
Reference-contexts: images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) <ref> [63, 11] </ref>. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25]. The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views [76, 47].
Reference: [12] <author> J.Q. Fang and T.S. Huang. </author> <title> Some experiments on estimating the 3D motion parameters of a rigid body from two consecutive image frames. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 545-554, </pages> <year> 1984. </year>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [40] and has been extensively studied in the literature [38] [75] <ref> [12] </ref> [79] [37], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. <p> In the two last cases, the nature of the (Euclidean) motion can be characterized from fundamental matrices. Note that whereas the two first cases are known in the context of motion analysis ([12, 79, 31, 71, 80], <ref> [12, 53, 1, 79, 29, 8] </ref>), the last one is specific to our problem, and comes from the fact that the fundamental matrix in the case of a pure translation depends only on two independent parameters, instead of seven.
Reference: [13] <author> O.D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 563-578, </pages> <year> 1992. </year>
Reference-contexts: question "what is the Fundamental matrix good for ?" we now list a number of recent papers which have studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches <ref> [13, 23, 68, 59] </ref>, and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images <p> now list a number of recent papers which have studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure <ref> [13, 67, 69] </ref>, 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation
Reference: [14] <author> O.D. Faugeras. </author> <title> Three-dimensional computer vision: a geometric viewpoint. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: In this paper, we assume that the reader is familiar with some elementary projective geometry. Such material can be found in classical mathematic textbooks such as [65, 6, 21], but also in the computer vision literature where it is presented in chapters of recent books <ref> [14, 34, 55] </ref>, and articles [51, 33]. The main property of this camera model is thus that the relationship between the world coordinates and the pixel coordinates is linear projective. This property is independent of the choice of the coordinate systems in the retinal plane or in the three-dimensional space. <p> Indeed, suppose that we have m = Am 0 , then m 0 = A 1 ~ PM. A special case is the case where the change of coordinates represents the change from the pixel coordinates to the normalized pixel coordinates <ref> [16, 14] </ref>, accounting for the internal geometry of the camera. <p> We only know that f minimizes a known criterion, and this can be dealt with using a method based on the implicit functions theorem, presented in <ref> [14] </ref>, and used for instance in [77]. Two examples, one with epipoles near the image center, the other with epipoles far away, are given in figure 19, where we have superimposed the uncertainty ellipses corresponding to a 90% probability, computed from the exact point coordinates, and the image frames. <p> In relation (34), the matrices A and B do not play a symmetrical role, but this relation can be rewritten in a a more symmetrical way. Let us apply the formula for changing projective coordinates (see for example <ref> [14] </ref>): A = [g 0 2 g 0 2 0 0 0 0 0 0 3 | -z - Since [g 0 1 g 0 3 ] is invertible, there is a bijective relation between g 0 4 and ( 0 2 ; 0 3 ), thus we can rewrite (34)
Reference: [15] <author> O.D. Faugeras, B. Hotz, and al. </author> <title> Real time correlation-based stereo: algorithm, implementations and applications. </title> <journal> The International Journal of Computer Vision, </journal> <note> 1994. To appear. </note>
Reference-contexts: of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images <ref> [27, 15] </ref> and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25]. <p> two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) <ref> [15] </ref> (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25]. The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views [76, 47].
Reference: [16] <author> O.D. Faugeras, Q.-T. Luong, and S.J. Maybank. </author> <title> Camera self-calibration: theory and experiments. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 321-334, </pages> <address> Santa-Margerita, Italy, </address> <year> 1992. </year>
Reference-contexts: Indeed, suppose that we have m = Am 0 , then m 0 = A 1 ~ PM. A special case is the case where the change of coordinates represents the change from the pixel coordinates to the normalized pixel coordinates <ref> [16, 14] </ref>, accounting for the internal geometry of the camera. <p> It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. Some recent work has indeed pointed out that it is also relevant for the purpose of working from uncalibrated cameras [57], <ref> [16] </ref> [23]. In this framework, we obtain new results about the accuracy of this criterion, which will enable us to present a more robust approach. <p> from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera <ref> [51, 16, 44, 25] </ref>. The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views [76, 47]. As a consequence, it is a theoretical and practical tool of primary importance.
Reference: [17] <author> O.D. Faugeras and F. Lustman. </author> <title> Motion and Structure from Motion in a piecewise planar environment. </title> <journal> International Journal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 2(3) </volume> <pages> 485-508, </pages> <year> 1988. </year>
Reference-contexts: Predict-and-verify algorithms have been already developed by <ref> [17] </ref>, and more recently by [70] and [62], using uncalibrated cameras. The idea is to chose four points, to compute the homography, whose knowledge allows the position of the corresponding point of any new point on the plane to be predicted. <p> 205.67 353.92 209.81 PLANES 538.12 206.70 366.34 210.94 Table 5: Results obtained on the grid images. 4.5 Summary It is known, in the framework of motion analysis that when the points lie in a plane, the general methods will fail, and that some specific methods can be used [74] [38] <ref> [17] </ref>. We have shown that the situation is similar for the computation of the Fundamental matrix. We have established a very simple and important relation between the homography matrices obtained from the observation of planar surfaces and the Fundamental matrix.
Reference: [18] <author> O.D. Faugeras, F. Lustman, and G. Toscani. </author> <title> Motion and Structure from point and line matches. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 25-34, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: We see also that the constraints are actually the six equations which are derived from (22). Thus, in the case of a linear estimation of F, where the rank constraint is ignored, there remains two undetermined parameters for F, as shown previously by <ref> [18] </ref>. Taking into account this polynomial constraint would further restrain F to a one-parameter family.
Reference: [19] <author> O.D. Faugeras and L. Robert. </author> <title> What can two images tell us about a third one ? Technical Report RR-2018, </title> <note> INRIA, 1993. To appear in IJCV. </note>
Reference-contexts: 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) <ref> [19] </ref> (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account)
Reference: [20] <author> O.D. Faugeras and G. Toscani. </author> <title> The calibration problem for stereo. </title> <booktitle> In Proceedings of CVPR'86, </booktitle> <pages> pages 15-20, </pages> <year> 1986. </year>
Reference-contexts: This is done by camera calibration [73] <ref> [20] </ref>, which typically computes the 3 fi 4 projection matrices ~ P, which relate the image pixel coordinates to a world reference frame.
Reference: [21] <author> L.E. Garner. </author> <title> An outline of projective geometry. </title> <publisher> Elsevier North Holland, </publisher> <year> 1981. </year>
Reference-contexts: It is one of the reasons why projective geometry is emerging as an attractive framework for computer vision [55]. In this paper, we assume that the reader is familiar with some elementary projective geometry. Such material can be found in classical mathematic textbooks such as <ref> [65, 6, 21] </ref>, but also in the computer vision literature where it is presented in chapters of recent books [14, 34, 55], and articles [51, 33]. The main property of this camera model is thus that the relationship between the world coordinates and the pixel coordinates is linear projective.
Reference: [22] <author> P. Gros and L. Quan. </author> <title> 3d projective invariants from two images. In Geometric methods in computer vision II, </title> <booktitle> SPIE optical instrumentation and applied science, </booktitle> <address> San Diego, </address> <year> 1993. </year>
Reference-contexts: studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants <ref> [67, 24, 22] </ref>, * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo
Reference: [23] <author> R.I. </author> <title> Hartley. Estimation of relative camera positions for uncalibrated cameras. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 579-587, </pages> <year> 1992. </year>
Reference-contexts: It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. Some recent work has indeed pointed out that it is also relevant for the purpose of working from uncalibrated cameras [57], [16] <ref> [23] </ref>. In this framework, we obtain new results about the accuracy of this criterion, which will enable us to present a more robust approach. <p> question "what is the Fundamental matrix good for ?" we now list a number of recent papers which have studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches <ref> [13, 23, 68, 59] </ref>, and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images
Reference: [24] <author> R.I. </author> <title> Hartley. Cheirality invariants. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 745-753, </pages> <institution> U. of Maryland, </institution> <year> 1993. </year>
Reference-contexts: studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants <ref> [67, 24, 22] </ref>, * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo
Reference: [25] <author> R.I. </author> <title> Hartley. An algorithm for self calibration from several views. </title> <booktitle> In Proc. Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 908-912, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera <ref> [51, 16, 44, 25] </ref>. The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views [76, 47]. As a consequence, it is a theoretical and practical tool of primary importance.
Reference: [26] <author> R.I. </author> <title> Hartley. Projective reconstruction from line correspondences. </title> <booktitle> In Proc. Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 903-907, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: A first extension of this work is however to consider multiple views, which leads to complex dependencies between fundamental matrices [47]. A second extension of this work is to consider the case of lines, for which some results have been already obtained <ref> [26, 76] </ref>. However, correspondences between lines of at least three views are needed.
Reference: [27] <author> R.I. Hartley and R. Gupta. </author> <title> Computing matched-epipolar projections. </title> <booktitle> In Proc. Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 549-555, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: T F can also be obtained by remarking that the kernel of this matrix is the epipole e, thus: H T F ~ = [e 0 ] fi A third consequence of (22) is that the matrix H T maps epipolar lines to corresponding epipo-lar lines, as also found by <ref> [27, 68] </ref>. Let l and l 0 be correspondent epipolar lines, containing respectively the points m and m 0 = Hm. <p> of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images <ref> [27, 15] </ref> and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25].
Reference: [28] <author> B.K.P. Horn. </author> <title> Relative orientation. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 4(1) </volume> <pages> 59-78, </pages> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: They were then rediscovered and studied theoretically by 31 computer vision scientists in the case of reconstruction from optical flow [48] and point correspondences <ref> [41, 50, 28] </ref>. We are going to point out some practical consequences of the existence of such surfaces. Our approach is to provide algorithms which start from the data which is available to us in uncalibrated images, that is a set of point correspondences between two images. <p> Maybank [50] has shown that a configuration whose 3D reconstruction is unstable is close to a critical surface. We are going to provide evidence for the reciprocal property. The unstability is very clear in the formulation of Horn <ref> [28] </ref> which defines critical surfaces as sets of points M for which the variation of m 0 T Em is a second-order (quadratic) function of the parameters r, t.
Reference: [29] <author> B.K.P. Horn and E.J. Weldon. </author> <title> Direct methods for recovering motion. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 2(1) </volume> <pages> 51-76, </pages> <year> 1988. </year>
Reference-contexts: In the two last cases, the nature of the (Euclidean) motion can be characterized from fundamental matrices. Note that whereas the two first cases are known in the context of motion analysis ([12, 79, 31, 71, 80], <ref> [12, 53, 1, 79, 29, 8] </ref>), the last one is specific to our problem, and comes from the fact that the fundamental matrix in the case of a pure translation depends only on two independent parameters, instead of seven.
Reference: [30] <author> T.S. Huang and O.D. Faugeras. </author> <title> Some properties of the E-matrix in two view motion estimation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11 </volume> <pages> 1310-1312, </pages> <year> 1989. </year>
Reference-contexts: (used in (9)) are obtained from pixel coordinates (used in (2)) by a multiplication by the inverse of the intrinsic parameters matrix A, we have the relation: F = A 1T EA 1 (10) Unlike the essential matrix, which is characterized by the two constraints found by Huang and Faugeras <ref> [30] </ref> which are the nullity of the determinant and the equality of the two non-zero singular values, the only property of the Fundamental matrix is that it is of rank two.
Reference: [31] <author> C.P. Jerian and R. Jain. </author> <title> Structure from motion. a critical analysis of methods. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics, </journal> <volume> 21(3) </volume> <pages> 572-587, </pages> <year> 1991. </year>
Reference: [32] <author> D.G. Jones and J. Malik. </author> <title> A Computational Framework for Determining Stereo Correspondence from a Set of Linear Spatial Filters. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 395-410, </pages> <year> 1992. </year> <month> 43 </month>
Reference-contexts: Line correspondences are not sufficient with two views. Another approach is to use linear filters tuned to a range of orientations and scales. Jones and Malik <ref> [32] </ref> have shown that it is also possible in this framework to recover the location of epipolar lines. In section 2, we clarify the concept of Fundamental matrix, and show its relation with the epipolar transformation and the Essential matrix, and propose some parameterizations for its computation.
Reference: [33] <author> K. Kanatani. </author> <title> Computational projective geometry. Computer Vision, Graphics, </title> <booktitle> and Image Processing. Image Understanding, </booktitle> <volume> 54(3), </volume> <year> 1991. </year>
Reference-contexts: Such material can be found in classical mathematic textbooks such as [65, 6, 21], but also in the computer vision literature where it is presented in chapters of recent books [14, 34, 55], and articles <ref> [51, 33] </ref>. The main property of this camera model is thus that the relationship between the world coordinates and the pixel coordinates is linear projective. This property is independent of the choice of the coordinate systems in the retinal plane or in the three-dimensional space.
Reference: [34] <author> K. Kanatani. </author> <title> Geometric computation for machine vision. </title> <publisher> Oxford university press, </publisher> <year> 1992. </year>
Reference-contexts: In this paper, we assume that the reader is familiar with some elementary projective geometry. Such material can be found in classical mathematic textbooks such as [65, 6, 21], but also in the computer vision literature where it is presented in chapters of recent books <ref> [14, 34, 55] </ref>, and articles [51, 33]. The main property of this camera model is thus that the relationship between the world coordinates and the pixel coordinates is linear projective. This property is independent of the choice of the coordinate systems in the retinal plane or in the three-dimensional space.
Reference: [35] <author> S. Laveau and O.D. Faugeras. </author> <title> 3-D scene representation as a collection of images. </title> <booktitle> In Proc. International Conference on Pattern Recognition, </booktitle> <address> Jerusalem, Israel, </address> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: 23, 68, 59], and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images <ref> [35] </ref>, * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25].
Reference: [36] <author> J.M. Lawn and R. Cipolla. </author> <title> Robust egomotion estimation from affine motion parallax. </title> <type> Technical Report CUED/F-INFENG/TR 160, </type> <institution> University of cambridge, </institution> <month> Jan </month> <year> 1994. </year> <note> a shorter version appeared at ECCV'94. </note>
Reference-contexts: Though, we can see that the noisy epipolar lines obtained with the homography are very coherent in the image, as they lie very close to the corresponding points. The method might benefit from a more refined technique to find the intersection, such as used recently by <ref> [36] </ref> in a rather similar approach. We now turn to a comparison of the multiplane method and the general method. We have used a statistical method, as in 4.3. 50 to 100 points where placed randomly in a controlled number of planes.
Reference: [37] <author> C.H. Lee. </author> <title> Time-varying images: the effect of finite resolution on uniqueness. Computer Vision, Graphics, </title> <booktitle> and Image Processing. Image Understanding, </booktitle> <volume> 54(3) </volume> <pages> 325-332, </pages> <year> 1991. </year>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [40] and has been extensively studied in the literature [38] [75] [12] [79] <ref> [37] </ref>, for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation.
Reference: [38] <author> C. Longuet-Higgins. </author> <title> The reconstruction of a scene from two projections: configurations that defeat the 8-point algorithm. </title> <booktitle> In Proc. 1st Conf. on Artificial intelligence applications, </booktitle> <pages> pages 395-397, </pages> <address> Denver, </address> <year> 1984. </year>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [40] and has been extensively studied in the literature <ref> [38] </ref> [75] [12] [79] [37], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. <p> 523.04 205.67 353.92 209.81 PLANES 538.12 206.70 366.34 210.94 Table 5: Results obtained on the grid images. 4.5 Summary It is known, in the framework of motion analysis that when the points lie in a plane, the general methods will fail, and that some specific methods can be used [74] <ref> [38] </ref> [17]. We have shown that the situation is similar for the computation of the Fundamental matrix. We have established a very simple and important relation between the homography matrices obtained from the observation of planar surfaces and the Fundamental matrix.
Reference: [39] <author> H. C. Longuet-Higgins and K. Prazdny. </author> <title> The interpretation of moving retinal images. </title> <journal> Proceedings of the Royal Society of London, </journal> <volume> B 208 </volume> <pages> 385-387, </pages> <year> 1980. </year>
Reference-contexts: The line hm 0 1 ; m 0 2 i, as the image of an optical ray of the first camera, is an epipolar line. This idea generalizes to the case of uncalibrated cameras with an arbitrary motion the notion of motion parallax <ref> [39] </ref>. In the original formulation of the idea, the two points M 1 and M 2 considered were physical points. This requires significant discontinuities in depth and identification of points which are aligned.
Reference: [40] <author> H.C. Longuet-Higgins. </author> <title> A Computer Algorithm for Reconstructing a Scene from Two Projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: The expression (7) becomes: F ij = (p 0 1 fi e 0 ) i (p 1 fi e) j b 2 fi e 0 ) i (p 2 fi e) j c (p 0 2.5 Euclidean interpretation: Relation with Longuet-Higgins equation The Longuet-Higgins equation <ref> [40] </ref> applies when using normalized coordinates, and thus cali brated cameras. In that case, the 2-D projective coordinates of a pixel m are equivalent to the 3-D direction of the optical ray hC; mi, which is of course not the case with retinal (uncalibrated) coordinates. <p> Thus we know that if we are given 8 matches we will be able, in general, to determine a unique solution for F, defined up to a scale factor. This approach, known as the eight point algorithm, was introduced by Longuet-Higgins <ref> [40] </ref> and has been extensively studied in the literature [38] [75] [12] [79] [37], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. <p> This geometry is purely projective and independent of the intrinsic parameters of the cameras. Even though it is true that, by taking them into account, the fundamental matrix can be shown to be equivalent to the essential matrix introduced by Longuet-Higgins <ref> [40] </ref>, we believe and have shown, as well as others ([13, 23, 16, 68, 42, 47] just to cite the major papers), that abstracting the idea of the fundamental matrix has led to deep theoretical insights about the kind of three-dimensional information that can be recovered from sets of images (projective,
Reference: [41] <author> H.C. Longuet-Higgins. </author> <title> Multiple interpretations of a pair of images of a surface. </title> <journal> Proc. of the Royal Society London A, </journal> <volume> 418 </volume> <pages> 1-15, </pages> <year> 1988. </year>
Reference-contexts: They were then rediscovered and studied theoretically by 31 computer vision scientists in the case of reconstruction from optical flow [48] and point correspondences <ref> [41, 50, 28] </ref>. We are going to point out some practical consequences of the existence of such surfaces. Our approach is to provide algorithms which start from the data which is available to us in uncalibrated images, that is a set of point correspondences between two images. <p> shown [48] that the critical surfaces Q 1 and Q 2 are space quadrics containing the optical centers and the baseline of equations: (R 1 M + t 1 ) T E 2 M = 0 (25) It is known that the maximum number of ambiguous fundamental matrices is three <ref> [41] </ref>. Let us now characterize critical surfaces in terms of image quantities.
Reference: [42] <author> Q.-T. Luong. </author> <title> Matrice fondamentale et auto-calibration en vision par ordinateur. </title> <type> PhD thesis, </type> <institution> Universite de Paris-Sud, Orsay, </institution> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: Methods to obtain such correspondences at a subpixel precision are now available, but are detailed elsewhere <ref> [42, 10, 10] </ref>, since the emphasis of the paper is on geometric and algebraic relations which can be used to compute the fundamental matrix and to analyze its stability. Line correspondences are not sufficient with two views. <p> Let us point out to the two main drawbacks of the linear criterion. A more detailed analysis of the linear criterion is performed in <ref> [43, 42] </ref>, where some analytical results and numerical examples are provided. <p> But minimizing k i is the same than favoring the fundamental 9 matrices which yield epipoles near the image. This is in fact still valid in the general case <ref> [42] </ref>, and we conclude that the linear criterion shifts epipoles towards the image center. 3.2 Non-Linear criteria The distance to epipolar lines We now introduce a first non-linear approach, based on the geometric interpretation of criterion (11) given in 3.1. <p> We have developed a method to perform the exact computation of this distance <ref> [42, 43] </ref>, based on some special properties of the surface S, but this approach is computationally very expensive. The linear criterion can be considered as a generalization of the Bookstein distance [5] for conic fitting. <p> Taking into account this polynomial constraint would further restrain F to a one-parameter family. This line of reasoning can be extended to the case of noisy data, by considering the covariance matrices <ref> [45, 42] </ref> Experimental study: simulations We have first validated this result using an extensive simulation with noisy synthetic data. More detailed results are in [45, 42]. <p> This line of reasoning can be extended to the case of noisy data, by considering the covariance matrices <ref> [45, 42] </ref> Experimental study: simulations We have first validated this result using an extensive simulation with noisy synthetic data. More detailed results are in [45, 42]. Each trial has been done as in section 3.4, except that at each time we have also chosen n random 3D points on p random planes. <p> Some experimental comparison of the different computation methods can be found in <ref> [42] </ref>. Theoretical link between ambiguity and unstability Critical surfaces have been presented in (5.2) as sets of points yielding ambiguous interpretations of motion. Maybank [50] has shown that a configuration whose 3D reconstruction is unstable is close to a critical surface.
Reference: [43] <author> Q.-T. Luong, R. Deriche, O.D. Faugeras, and T. Papadopoulo. </author> <title> On determining the Fundamental matrix: analysis of different methods and experimental results. </title> <type> Technical Report RR-1894, </type> <institution> INRIA, </institution> <year> 1993. </year> <note> A shorter version appeared in the Israelian Conf. on Artificial Intelligence and Computer Vision. </note>
Reference-contexts: Let us point out to the two main drawbacks of the linear criterion. A more detailed analysis of the linear criterion is performed in <ref> [43, 42] </ref>, where some analytical results and numerical examples are provided. <p> We have developed a method to perform the exact computation of this distance <ref> [42, 43] </ref>, based on some special properties of the surface S, but this approach is computationally very expensive. The linear criterion can be considered as a generalization of the Bookstein distance [5] for conic fitting. <p> From the results of the simulation shown Fig. 4, it is clear that: 13 * The stability of the epipoles in each of the images is comparable, which was to be expected, since the criterion (2) is symmetrical. Note that the non-linear criteria proposed in <ref> [43] </ref> also share this property. * Once the epipoles are determined correctly, the computation of the homography is quite stable, and thus that the more unstable part of the computation is the determination of the epipoles.
Reference: [44] <author> Q.-T. Luong and O.D. Faugeras. </author> <title> Camera calibration, scene motion and structure recovery from point correspondences and fundamental matrices. </title> <note> Submitted to IJCV, </note> <year> 1993. </year>
Reference-contexts: from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera <ref> [51, 16, 44, 25] </ref>. The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views [76, 47]. As a consequence, it is a theoretical and practical tool of primary importance.
Reference: [45] <author> Q.-T. Luong and O.D. Faugeras. </author> <title> Determining the Fundamental matrix with planes: un-stability and new algorithms. </title> <booktitle> In Proc. Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 489-494, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: Taking into account this polynomial constraint would further restrain F to a one-parameter family. This line of reasoning can be extended to the case of noisy data, by considering the covariance matrices <ref> [45, 42] </ref> Experimental study: simulations We have first validated this result using an extensive simulation with noisy synthetic data. More detailed results are in [45, 42]. <p> This line of reasoning can be extended to the case of noisy data, by considering the covariance matrices <ref> [45, 42] </ref> Experimental study: simulations We have first validated this result using an extensive simulation with noisy synthetic data. More detailed results are in [45, 42]. Each trial has been done as in section 3.4, except that at each time we have also chosen n random 3D points on p random planes.
Reference: [46] <author> Q.-T. Luong and O.D. Faugeras. </author> <title> Stratifed projective motion analysis: Fundamental matrix and self-calibration. </title> <note> In preparation, </note> <year> 1994. </year>
Reference-contexts: It has to be noted that the choice of an error measure for the epipoles is not an obvious matter, since they are basically quantities of the projective plane, which has no metric. A further discussion of error measures can be found in <ref> [46] </ref>. All the graphs shown in this section are averaged over a few hundred trials. In a scheme where only such a small number of experiments are averaged, a single very large value could significantly affect statistics, and this is why the relative error is thresholded by 1. <p> We present briefly some experimental results in figure 22 and refer the interested reader to <ref> [46] </ref> for more simulations and qualitative explanations. In the simulations 100 series of entirely different displacements have been used.
Reference: [47] <author> Q.-T. Luong and T. Vieville. </author> <title> Canonical representations for the geometries of multiple projective views. CVGIP: </title> <booktitle> image understanding, </booktitle> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: We thus conclude from this simulation that an adequate measure for the stability of the fundamental matrix is the stability of one of its epipoles. Note that this is consistent with the findings of <ref> [47] </ref>, where it has been shown that the epipole plays a particular role in the projective description of the geometry of a system of two cameras. Non-linear criteria There are two different parameterizations, that are presented Section 3.3, and two different non-linear criteria, presented in Section 3.2. <p> The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views <ref> [76, 47] </ref>. As a consequence, it is a theoretical and practical tool of primary importance. Its knowledge is essential for further use of the hierarchy of representations. <p> It is to be noted that there are no need for multiple matches across several frames, since the fundamental matrices can be computed independently from pairs of views. A first extension of this work is however to consider multiple views, which leads to complex dependencies between fundamental matrices <ref> [47] </ref>. A second extension of this work is to consider the case of lines, for which some results have been already obtained [26, 76]. However, correspondences between lines of at least three views are needed.
Reference: [48] <author> S.J. Maybank. </author> <title> The angular velocity associated with the optical flow field arising from motion through a rigid environment. </title> <journal> Proc. of the Royal Society London A, </journal> <volume> 401 </volume> <pages> 317-326, </pages> <year> 1985. </year>
Reference-contexts: They were then rediscovered and studied theoretically by 31 computer vision scientists in the case of reconstruction from optical flow <ref> [48] </ref> and point correspondences [41, 50, 28]. We are going to point out some practical consequences of the existence of such surfaces. <p> It has been shown <ref> [48] </ref> that the critical surfaces Q 1 and Q 2 are space quadrics containing the optical centers and the baseline of equations: (R 1 M + t 1 ) T E 2 M = 0 (25) It is known that the maximum number of ambiguous fundamental matrices is three [41].
Reference: [49] <author> S.J. Maybank. </author> <title> The projective geometry of ambiguous surfaces. </title> <journal> Proc. of the Royal Society London A, </journal> <volume> 332 </volume> <pages> 1-47, </pages> <year> 1990. </year>
Reference-contexts: While the equation he obtains is quite different from (26), he finds properties similar to the one which are described by Maybank <ref> [49] </ref>. We are going to see that the two forms are indeed equivalent, which will prove that an ambiguous situation is also unstable.
Reference: [50] <author> S.J. Maybank. </author> <title> Properties of essential matrices. </title> <journal> International journal of imaging systems and technology, </journal> <volume> 2 </volume> <pages> 380-384, </pages> <year> 1990. </year>
Reference-contexts: They were then rediscovered and studied theoretically by 31 computer vision scientists in the case of reconstruction from optical flow [48] and point correspondences <ref> [41, 50, 28] </ref>. We are going to point out some practical consequences of the existence of such surfaces. Our approach is to provide algorithms which start from the data which is available to us in uncalibrated images, that is a set of point correspondences between two images. <p> Some experimental comparison of the different computation methods can be found in [42]. Theoretical link between ambiguity and unstability Critical surfaces have been presented in (5.2) as sets of points yielding ambiguous interpretations of motion. Maybank <ref> [50] </ref> has shown that a configuration whose 3D reconstruction is unstable is close to a critical surface. We are going to provide evidence for the reciprocal property.
Reference: [51] <author> S.J. Maybank and O.D. Faugeras. </author> <title> A Theory of Self-Calibration of a Moving Camera. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 123-151, </pages> <year> 1992. </year>
Reference-contexts: Such material can be found in classical mathematic textbooks such as [65, 6, 21], but also in the computer vision literature where it is presented in chapters of recent books [14, 34, 55], and articles <ref> [51, 33] </ref>. The main property of this camera model is thus that the relationship between the world coordinates and the pixel coordinates is linear projective. This property is independent of the choice of the coordinate systems in the retinal plane or in the three-dimensional space. <p> from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera <ref> [51, 16, 44, 25] </ref>. The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views [76, 47]. As a consequence, it is a theoretical and practical tool of primary importance.
Reference: [52] <author> P.F. McLauchlan, I.D. Reid, and D.W. Murray. </author> <title> Recursive affine structure and motion from image sequences. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 217-224, </pages> <address> Stockholm, Sweden, </address> <month> 1 </month> <year> 1994. </year> <month> 44 </month>
Reference-contexts: Its knowledge is essential for further use of the hierarchy of representations. For example, if an addition to the Fundamental matrix, a certain 3-D vector representing the plane at infinity is known, then affine structure (considered for instance in <ref> [60, 9, 66, 52, 4] </ref>) could be recovered. It is to be noted that there are no need for multiple matches across several frames, since the fundamental matrices can be computed independently from pairs of views.
Reference: [53] <author> A. Mitiche, X. Zhuang, and R. Haralick. </author> <title> Interpretation of optical flow by rotation de--coupling. </title> <booktitle> In Proc. IEEE workshop on computer vision, </booktitle> <pages> pages 195-200, </pages> <address> Miami Beach, FL, </address> <year> 1987. </year>
Reference-contexts: In the two last cases, the nature of the (Euclidean) motion can be characterized from fundamental matrices. Note that whereas the two first cases are known in the context of motion analysis ([12, 79, 31, 71, 80], <ref> [12, 53, 1, 79, 29, 8] </ref>), the last one is specific to our problem, and comes from the fact that the fundamental matrix in the case of a pure translation depends only on two independent parameters, instead of seven.
Reference: [54] <author> J. Mundy, R.P. Welty, M.H. Brill, P.M. Payton, and Barrett. </author> <title> 3-D model aligment without computing pose. </title> <booktitle> In Proc. DARPA Image Understanding Workshop, </booktitle> <pages> pages 727-735, </pages> <address> San Mateo, CA, </address> <year> 1992. </year>
Reference-contexts: * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images <ref> [2, 54, 9] </ref> (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11].
Reference: [55] <author> J. L. Mundy and A. Zisserman, </author> <title> editors. Geometric invariance in computer vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Even an approach where cameras are just calibrated individually for their 5 internal parameters, and the rigid displacement between them is estimated subsequently would require at least the estimation of 15 parameters. Thus a second approach is emerging <ref> [55] </ref>, which consists in using projective information , whose non-metric nature allows to use cameras whose internal parameters are unknown, This approach requires only geometric information which relates the different viewpoints, thus a much more small number of parameters have to be estimated. <p> Introducing projective coordinates induces a big simplification in the formulation of properties of cameras. It is one of the reasons why projective geometry is emerging as an attractive framework for computer vision <ref> [55] </ref>. In this paper, we assume that the reader is familiar with some elementary projective geometry. <p> In this paper, we assume that the reader is familiar with some elementary projective geometry. Such material can be found in classical mathematic textbooks such as [65, 6, 21], but also in the computer vision literature where it is presented in chapters of recent books <ref> [14, 34, 55] </ref>, and articles [51, 33]. The main property of this camera model is thus that the relationship between the world coordinates and the pixel coordinates is linear projective. This property is independent of the choice of the coordinate systems in the retinal plane or in the three-dimensional space.
Reference: [56] <author> E. Nishimura, G. Xu, and S. Tsuji. </author> <title> Motion segmentation and correspondence using epipolar constraint. </title> <booktitle> In Proc. 1st Asian Conf. Computer Vision, </booktitle> <pages> pages 199-204, </pages> <address> Osaka, Japan, </address> <year> 1993. </year>
Reference-contexts: Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions <ref> [56, 72, 78] </ref>, * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25].
Reference: [57] <author> S.I. Olsen. </author> <title> Epipolar line estimation. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 307-311, </pages> <year> 1992. </year>
Reference-contexts: It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. Some recent work has indeed pointed out that it is also relevant for the purpose of working from uncalibrated cameras <ref> [57] </ref>, [16] [23]. In this framework, we obtain new results about the accuracy of this criterion, which will enable us to present a more robust approach.
Reference: [58] <author> J. Philip. </author> <title> Estimation of three-dimensional motion of rigid objects from noisy observations. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(1) </volume> <pages> 61-66, </pages> <year> 1991. </year>
Reference-contexts: In our case, the function f associates to the coordinates of the point correspondences the entries of the fundamental matrices eventually found. In the case of a linear criterion, already studied in [79] and <ref> [58] </ref> (for the com-putationally identical case of the essential matrix computed from the eight point algorithm), we have an explicit formula for the function f . A different approach is needed to cope with the case of a nonlinear criterion, since we do not have an explicit expression for f.
Reference: [59] <author> J. Ponce, D.H. Marimont, and T.A. Cass. </author> <title> Analytical methods for uncalibrated stereo and motion reconstruction. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 463-470, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: question "what is the Fundamental matrix good for ?" we now list a number of recent papers which have studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches <ref> [13, 23, 68, 59] </ref>, and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images
Reference: [60] <author> L. Quan and R. Mohr. </author> <title> Affine shape representation from motion through reference points. </title> <journal> Journal of mathematical imaging and vision, </journal> <volume> 1 </volume> <pages> 145-151, </pages> <year> 1992. </year>
Reference-contexts: Its knowledge is essential for further use of the hierarchy of representations. For example, if an addition to the Fundamental matrix, a certain 3-D vector representing the plane at infinity is known, then affine structure (considered for instance in <ref> [60, 9, 66, 52, 4] </ref>) could be recovered. It is to be noted that there are no need for multiple matches across several frames, since the fundamental matrices can be computed independently from pairs of views.
Reference: [61] <author> L. Robert. </author> <title> Reconstruction de courbes et de surfaces par vision stereoscopique. Applications a la robotique mobile. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <year> 1993. </year>
Reference-contexts: But if one wants to proceed only from image measurements, the Fundamental matrix is the key concept, as it contains all the geometrical information relating two different images. One way to see it is to remember that the position along epipolar lines are related to the three-dimensional depth <ref> [61] </ref>. But if we do not have any knowledge about the scene geometry, we cannot infer such information. 4 Let us now express the epipolar constraint using the Fundamental matrix, in the case of uncalibrated cameras. <p> features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras <ref> [61] </ref> (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25]. The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views [76, 47].
Reference: [62] <author> L. Robert and O.D. Faugeras. </author> <title> Relative 3D Positioning and 3D Convex Hull Computation from a Weakly Calibrated Stereo Pair. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 540-543, </pages> <address> Berlin, Germany, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Predict-and-verify algorithms have been already developed by [17], and more recently by [70] and <ref> [62] </ref>, using uncalibrated cameras. The idea is to chose four points, to compute the homography, whose knowledge allows the position of the corresponding point of any new point on the plane to be predicted. <p> affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning <ref> [62] </ref>, * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25].
Reference: [63] <author> L. Robert and M. Hebert. </author> <title> Deriving orientation cues from stereo images. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 377-388, </pages> <address> Stockholm, Sweden, </address> <year> 1994. </year>
Reference-contexts: images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) <ref> [63, 11] </ref>. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25]. The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views [76, 47].
Reference: [64] <author> P.D. Sampson. </author> <title> Fitting conic sections to very scattered data. an iterative refinement of the Bookstein algorithm. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 18(1) </volume> <pages> 97-108, </pages> <month> Jan. </month> <year> 1982. </year>
Reference-contexts: The straightforward idea is to approximate the true distance of the point x to the surface by the number g (x; f ), in order to get a closed-form solution. A more precise approxi mation has been introduced by Sampson <ref> [64] </ref>.
Reference: [65] <author> J.G. Semple and G.T. Kneebone. </author> <title> Algebraic Projective Geometry. </title> <publisher> Oxford: Clarendon Press, </publisher> <year> 1952. </year> <note> Reprinted 1979. </note>
Reference-contexts: It is one of the reasons why projective geometry is emerging as an attractive framework for computer vision [55]. In this paper, we assume that the reader is familiar with some elementary projective geometry. Such material can be found in classical mathematic textbooks such as <ref> [65, 6, 21] </ref>, but also in the computer vision literature where it is presented in chapters of recent books [14, 34, 55], and articles [51, 33]. The main property of this camera model is thus that the relationship between the world coordinates and the pixel coordinates is linear projective. <p> The inverse of is 1 = B 1 0 A 1 . The point g 4 can be chosen arbitrarily, whereas the point g 0 4 is determined by <ref> [65] </ref>. Thus A depends on 8 parameters (the projective coordinates of the points g 0 i , i = 1; 2; 3; 4) and B depends on 6 parameters (the projective coordinates of the points g i , i = 1; 2; 3).
Reference: [66] <author> L.S. Shapiro, A. Zisserman, and M. Brady. </author> <title> Motion from point matches using affine epipolar geometry. </title> <type> Technical Report OUEL 1994/93, </type> <institution> Oxford University., </institution> <month> June </month> <year> 1993. </year> <note> A shorter version appeared at ECCV'94. </note>
Reference-contexts: Its knowledge is essential for further use of the hierarchy of representations. For example, if an addition to the Fundamental matrix, a certain 3-D vector representing the plane at infinity is known, then affine structure (considered for instance in <ref> [60, 9, 66, 52, 4] </ref>) could be recovered. It is to be noted that there are no need for multiple matches across several frames, since the fundamental matrices can be computed independently from pairs of views.
Reference: [67] <author> A. Shashua. </author> <title> On geometric and algebraic aspects of 3D affine and projective structures from perspective 2D views. </title> <booktitle> In Proceedings of the 2nd European Workshop on Invariants, </booktitle> <address> Ponta Delagada, Azores, </address> <year> 1993. </year> <note> Also MIT AI Memo No. 1405, </note> <month> July </month> <year> 1993. </year>
Reference-contexts: now list a number of recent papers which have studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure <ref> [13, 67, 69] </ref>, 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation <p> studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants <ref> [67, 24, 22] </ref>, * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions [56, 72, 78], * Stereo
Reference: [68] <author> A. Shashua. </author> <title> Projective depth: a geometric invariant for 3d reconstruction from two perspective/orthographic views and for visual recognition. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 583-590, </pages> <address> Berlin, Germany, </address> <year> 1993. </year>
Reference-contexts: T F can also be obtained by remarking that the kernel of this matrix is the epipole e, thus: H T F ~ = [e 0 ] fi A third consequence of (22) is that the matrix H T maps epipolar lines to corresponding epipo-lar lines, as also found by <ref> [27, 68] </ref>. Let l and l 0 be correspondent epipolar lines, containing respectively the points m and m 0 = Hm. <p> question "what is the Fundamental matrix good for ?" we now list a number of recent papers which have studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches <ref> [13, 23, 68, 59] </ref>, and of the relative affine structure [13, 67, 69], 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images
Reference: [69] <author> A. Shashua and N. Navab. </author> <title> Relative affine structure: Theory and application to 3D reconstruction from perspective views. </title> <booktitle> In Proc. Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 483-489, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: now list a number of recent papers which have studied tasks to be performed when the only information relating the cameras are the Fundamental matrix (or matrices): * Recovery of the 3D projective structure of a scene from point matches [13, 23, 68, 59], and of the relative affine structure <ref> [13, 67, 69] </ref>, 40 * Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation
Reference: [70] <author> D. Sinclair, A. Blake, S. Smith, and C. Rothwell. </author> <title> Planar region detection and motion recovery. </title> <booktitle> In Proc. British Machine Vision Conf., </booktitle> <pages> pages 59-68, </pages> <year> 1992. </year>
Reference-contexts: Predict-and-verify algorithms have been already developed by [17], and more recently by <ref> [70] </ref> and [62], using uncalibrated cameras. The idea is to chose four points, to compute the homography, whose knowledge allows the position of the corresponding point of any new point on the plane to be predicted.
Reference: [71] <author> M.E. Spetsakis. </author> <title> A linear algorithm for point and line-based structure from motion. Computer Vision, Graphics, </title> <booktitle> and Image Processing. Image Understanding, </booktitle> <volume> 56(2) </volume> <pages> 230-241, </pages> <year> 1992. </year>
Reference: [72] <author> P.H.S. Torr and D.W. Murray. </author> <title> Stochastic motion clustering. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 328-337, </pages> <address> Stocholm, Sweden, </address> <year> 1994. </year> <month> 45 </month>
Reference-contexts: Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions <ref> [56, 72, 78] </ref>, * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25].
Reference: [73] <author> R.Y. Tsai. </author> <title> An Efficient and Accurate Camera Calibration Technique for 3D Machine Vision. </title> <booktitle> In Proceedings CVPR '86, </booktitle> <address> Miami Beach, Florida, </address> <pages> pages 364-374. </pages> <publisher> IEEE, </publisher> <month> June </month> <year> 1986. </year>
Reference-contexts: This is done by camera calibration <ref> [73] </ref> [20], which typically computes the 3 fi 4 projection matrices ~ P, which relate the image pixel coordinates to a world reference frame.
Reference: [74] <author> R.Y. Tsai and T.S. Huang. </author> <title> Estimating Three-dimensional motion parameters of a rigid planar patch, II: singular value decomposition. </title> <journal> IEEE Transactions on Acoustic, Speech and Signal Processing, </journal> <volume> 30, </volume> <year> 1982. </year>
Reference-contexts: GENERAL 523.04 205.67 353.92 209.81 PLANES 538.12 206.70 366.34 210.94 Table 5: Results obtained on the grid images. 4.5 Summary It is known, in the framework of motion analysis that when the points lie in a plane, the general methods will fail, and that some specific methods can be used <ref> [74] </ref> [38] [17]. We have shown that the situation is similar for the computation of the Fundamental matrix. We have established a very simple and important relation between the homography matrices obtained from the observation of planar surfaces and the Fundamental matrix.
Reference: [75] <author> R.Y. Tsai and T.S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects wirth curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 13-27, </pages> <year> 1984. </year>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [40] and has been extensively studied in the literature [38] <ref> [75] </ref> [12] [79] [37], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation.
Reference: [76] <author> T. Vieville, Q.-T. Luong, and O.D. Faugeras. </author> <title> Motion of points and lines in the uncalibrated case. </title> <journal> Intl. Journal of Computer Vision, </journal> <note> 1994. To appear. </note>
Reference-contexts: The Fundamental matrix represents indeed the minimal information (two views, no additional hypotheses), in a hierarchy of representations obtained by making further assumptions and adding views <ref> [76, 47] </ref>. As a consequence, it is a theoretical and practical tool of primary importance. Its knowledge is essential for further use of the hierarchy of representations. <p> A first extension of this work is however to consider multiple views, which leads to complex dependencies between fundamental matrices [47]. A second extension of this work is to consider the case of lines, for which some results have been already obtained <ref> [26, 76] </ref>. However, correspondences between lines of at least three views are needed.
Reference: [77] <author> T. Vieville and P. Sander. </author> <title> Using pseudo kalman-filters in the presence of constraints. </title> <type> Technical Report RR-1669, </type> <institution> INRIA, </institution> <year> 1992. </year>
Reference-contexts: We only know that f minimizes a known criterion, and this can be dealt with using a method based on the implicit functions theorem, presented in [14], and used for instance in <ref> [77] </ref>. Two examples, one with epipoles near the image center, the other with epipoles far away, are given in figure 19, where we have superimposed the uncertainty ellipses corresponding to a 90% probability, computed from the exact point coordinates, and the image frames.
Reference: [78] <author> J. Weber and J. Malik. </author> <title> Rigid body segmentation and shape description from dense optical flow under weak perspective. </title> <institution> Dep. of EECS, University of California at Berkeley, </institution> <year> 1994. </year>
Reference-contexts: Obtention of projective invariants [67, 24, 22], * Prediction of image features in an image from image features in two other images [2, 54, 9] (positions) [19] (positions,orientations,curvatures), * Synthesis of an image from several images [35], * Convex-hull computation and plane positionning [62], * Segmentation of rigid independent motions <ref> [56, 72, 78] </ref>, * Stereo analysis: rectification of images [27, 15] and stereo matching with uncalibrated cameras [61] (feature-based) [15] (area-based) [63, 11]. (taking orientation into account) * Self-calibration of a moving camera [51, 16, 44, 25].
Reference: [79] <author> J. Weng, T.S. Huang, and N. Ahuja. </author> <title> Motion and structure from two perspective views: algorithms, error analysis and error estimation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11(5) </volume> <pages> 451-476, </pages> <year> 1989. </year>
Reference-contexts: This approach, known as the eight point algorithm, was introduced by Longuet-Higgins [40] and has been extensively studied in the literature [38] [75] [12] <ref> [79] </ref> [37], for the computation of the Essential matrix. It has proven to be very sensitive to noise. Our contribution is to study it in the more general framework of Fundamental matrix computation. <p> In our case, the function f associates to the coordinates of the point correspondences the entries of the fundamental matrices eventually found. In the case of a linear criterion, already studied in <ref> [79] </ref> and [58] (for the com-putationally identical case of the essential matrix computed from the eight point algorithm), we have an explicit formula for the function f . <p> t = t 2 t + R 2 R 1 t 5.3 Experimental results The nature of the motion Since the epipoles are a simple function of the camera displacement, we can expect that the stability of the fundamental matrix computation can be related to the stability of motion estimation <ref> [79] </ref>. We have studied three cases where the results are unstable: * small translational component, * translational component parallel to the image plane (the epipoles are far from the image center), * pure translation (the fundamental matrix is antisymmetric). <p> In the two last cases, the nature of the (Euclidean) motion can be characterized from fundamental matrices. Note that whereas the two first cases are known in the context of motion analysis ([12, 79, 31, 71, 80], <ref> [12, 53, 1, 79, 29, 8] </ref>), the last one is specific to our problem, and comes from the fact that the fundamental matrix in the case of a pure translation depends only on two independent parameters, instead of seven.
Reference: [80] <author> Z. Zhang and O.D. Faugeras. </author> <title> 3D dynamic scene analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year> <month> 46 </month>
References-found: 80

