URL: http://www.neci.nj.nec.com/homepages/waltz/waltz.comp.rev.ps
Refering-URL: http://www.neci.nj.nec.com/homepages/waltz/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: On Reasoning from Data  
Author: David Waltz Simon Kasif 
Abstract-found: 0
Intro-found: 1
Reference: [CMSW92] <author> R. Creecy, B. Masand, S. Smith, and D. L. Waltz. </author> <title> Trading MIPS and memory for knowledge engineering. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 48-64, </pages> <year> 1992. </year>
Reference: [CS93] <author> S. Cost and S. Salzberg. </author> <title> A weighted nearest neighbor algorithm for learning with symbolic features. </title> <journal> Machine Learning, </journal> <volume> 10(1) </volume> <pages> 57-78, </pages> <year> 1993. </year>
Reference-contexts: The MBR hypothesis suggests that we do not associate a static atomic symbol with an event. Each event is dynamically (incrementally) defined as an MBR-vector in a real valued space. For instance, Stanfill and Waltz ([SW86]) and later several papers (e.g., <ref> [CS93, RKSA94, ZMW92] </ref>) assume conditional independence of features given a partitioning of the domain into classes.
Reference: [Das91] <author> Belur V. Dasarathy, </author> <title> editor. Nearest neighbor (NN) norms: NN pattern classification techniques. </title> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1991. </year>
Reference-contexts: They also typically rely on laborious hand-coding, have difficulty coping with uncertainty and change, and rarely use statistical evaluation of the quality of specification in terms of its match to the observed data. Memory-based reasoning generalizes traditional nearest neighbor (NN) procedures used in pattern recognition (see <ref> [Das91] </ref>), and provides a practical framework for reasoning from stored data. Note that conventional NN methods typically do not use adaptive distance metrics, nor do they use local interpolating functions.
Reference: [Kol93] <author> J. Kolodner. </author> <title> Case-Based Reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year> <month> 4 </month>
Reference: [MAS95] <author> A. Moore, C. Atkeson, and S. Schaal. </author> <title> Memory-based learning for control. </title> <note> Arti--ficial Intelligence Review (to appear), </note> <year> 1995. </year>
Reference-contexts: Note that conventional NN methods typically do not use adaptive distance metrics, nor do they use local interpolating functions. The special case of MBR used in control applications often uses local functional approximation methods such as locally weighted regression (see <ref> [MAS95] </ref>). These methods typically do not use sophisticated model-based adaptive distance functions. Recently, several researchers in statistics have independently suggested adaptive kernel methods that bear strong similarity to MBR, another indication of the usefulness of the paradigm.
Reference: [MK93] <author> P. Maes and R. Kozierok. </author> <title> Learning interface agents. </title> <booktitle> In Proc. of the Eleventh National Conf. on Artificial Intelligence, </booktitle> <pages> pages 459-465, </pages> <address> Washington, D.C., 1993. </address> <publisher> MIT Press. </publisher>
Reference: [MLW92] <author> B. Masand, G. Linoff, and D. L. Waltz. </author> <title> Classifying news stories using memory based reasoning. </title> <booktitle> In Proceedings of the SIGIR, </booktitle> <pages> pages 59-65, </pages> <year> 1992. </year>
Reference: [Pea88] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: The user also specifies a set of probabilistic assumptions that are used to generate models (e.g., priors, independence assumptions specified as Bayes networks; see <ref> [Pea88] </ref>). * The MBR agent incrementally generates a rough probabilistic model of the environ ment. The model may contain new hidden variables. * The probabilistic model is used to induce an adaptive distance metric on the domain which induces an explicit transformation (MBR transform) on the static parts of data. <p> Each event is dynamically (incrementally) defined as an MBR-vector in a real valued space. For instance, Stanfill and Waltz ([SW86]) and later several papers (e.g., [CS93, RKSA94, ZMW92]) assume conditional independence of features given a partitioning of the domain into classes. This simple probabilistic model (a two-layer causal tree <ref> [Pea88] </ref>) induces a transformation that maps a symbol A associated with x j to a discrete probability distribution (p 1 ; p 2 : : : p k ) where p i is equal to the probability of the i-th class given x j = A.
Reference: [RKSA94] <author> J. Rachlin, S. Kasif, S. Salzberg, and D. Aha. </author> <title> Towards a better understanding of memory-based and bayesian classifiers. </title> <booktitle> In Proc. of the Eleventh Internatl. Conf. on Machine Learning, </booktitle> <pages> pages 242-250, </pages> <address> New Brunswick, NJ, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: The MBR hypothesis suggests that we do not associate a static atomic symbol with an event. Each event is dynamically (incrementally) defined as an MBR-vector in a real valued space. For instance, Stanfill and Waltz ([SW86]) and later several papers (e.g., <ref> [CS93, RKSA94, ZMW92] </ref>) assume conditional independence of features given a partitioning of the domain into classes.
Reference: [SW86] <author> C. Stanfill and D. Waltz. </author> <title> Toward memory-based reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1213-1228, </pages> <year> 1986. </year>
Reference: [Wal90] <author> D. L. Waltz. </author> <title> Eight principles for an intelligent robot. </title> <editor> In S. Wilson and J. Meyer, editors, SAB-90: </editor> <booktitle> Simulations of Animal Behavior, </booktitle> <pages> pages 462-465. </pages> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: This review has focused on application-oriented MBR rather than its cognitive interpretation. Discussion of a cognitive perspective is precluded by the length requirements of this review, but see <ref> [Wal90] </ref>. The authors urge readers to contrast Allen Newell's "symbol hypothesis" with MBR's nature incremental, model-based, constantly mutating in response to current beliefs, goals, and experiences. Much research must still be done to fully understand the relative capabilities and limitations of the methodology outlined above.
Reference: [ZMW92] <author> X. Zhang, J. P. Mesirov, and D. L. Waltz. </author> <title> A hybrid system for protein secondary structure prediction. </title> <journal> Journal of Molecular Biology, </journal> <volume> 225 </volume> <pages> 1049-1063, </pages> <year> 1992. </year> <month> 5 </month>
Reference-contexts: The MBR hypothesis suggests that we do not associate a static atomic symbol with an event. Each event is dynamically (incrementally) defined as an MBR-vector in a real valued space. For instance, Stanfill and Waltz ([SW86]) and later several papers (e.g., <ref> [CS93, RKSA94, ZMW92] </ref>) assume conditional independence of features given a partitioning of the domain into classes.
References-found: 12

