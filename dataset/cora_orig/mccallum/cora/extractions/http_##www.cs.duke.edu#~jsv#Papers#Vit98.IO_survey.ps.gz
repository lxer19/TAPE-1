URL: http://www.cs.duke.edu/~jsv/Papers/Vit98.IO_survey.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node23.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Author: Jeffrey Scott Vitter 
Keyword: External Memory Algorithms  
Date: June 18, 1998)  
Note: DIMACS Series in Discrete Mathematics and Theoretical Computer Science  (Draft,  
Abstract: Data sets in large applications are often too massive to fit completely inside the computer's internal memory. The resulting input/output communication (or I/O) between fast internal memory and slower external memory (such as disks) can be a major performance bottleneck. In this tutorial, we survey the state of the art in the design and analysis of external memory algorithms (also known as EM algorithms or out-of-core algorithms or I/O algorithms). External memory algorithms are often designed using the parallel disk model (PDM). The three machine-independent measures of an algorithm's performance in PDM are the number of I/O operations performed, the CPU time, and the amount of disk space used. PDM allows for multiple disks (or disk arrays) and parallel CPUs, and it can be generalized to handle cache hierarchies, hierarchical memory, and tertiary storage. We discuss a variety of problems and show how to solve them efficiently in external memory. Programming tools and environments are available for simplifying the programming task. Experiments on some newly developed algorithms for spatial databases incorporating these paradigms, implemented using TPIE (Transparent Parallel I/O programming Environment), show significant speedups over currently used methods. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Abello, A. Buchsbaum, and J. Westbrook. </author> <title> A functional approach to external memory graph algorithms. </title> <editor> In J. Abello and J. S. Vitter, editors, </editor> <title> External Memory Algorithms and Visualization, DIMACS series. </title> <publisher> American Mathematical Society, </publisher> <year> 1998. </year>
Reference-contexts: That assumption can be removed by use of the buffer tree data structure [9] (see Section 7.2). A practical, randomized implementation of list ranking appears in [96]. Recent work on other EM graph algorithms appears in <ref> [1, 10, 73, 56] </ref>. The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. Constructing classification trees in external memory for data mining is discussed in [113]. <p> For example, the range query [3; 5] fi <ref> [4; 1] </ref> is a (2; 1)-sided range query, since there are two sides in the x 1 dimension (namely, 3 x 1 and x 1 5) but only one side in the x 2 dimension (namely, x 2 4).
Reference: [2] <author> M. Adler. </author> <title> New coding techniques for improved bandwidth utilization. </title> <booktitle> In 37th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> 173-182, </pages> <address> Burlington, VT, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: It is conjectured that the sorting lower bound (2.1) remains valid even if the indivisibility assumption is lifted. However, for an artificial problem related to transposition, Adler <ref> [2] </ref> showed that removing the indivisibility assumption can lead to faster algorithms. A similar result is shown by Arge and Miltersen [15] for the decision problem of determining if the N data item values are distinct. Whether or not the conjecture is true is a challenging theoretical problem. 4.
Reference: [3] <author> P. K. Agarwal, L. Arge, J. Erickson, P. G. Franciosa, and J. S. Vitter. </author> <title> Efficient searching with linear constraints. </title> <booktitle> In Proc. 17th ACM Symposium on Principles of Database Systems, </booktitle> <year> 1998. </year>
Reference-contexts: For example, the range query <ref> [3; 5] </ref> fi [4; 1] is a (2; 1)-sided range query, since there are two sides in the x 1 dimension (namely, 3 x 1 and x 1 5) but only one side in the x 2 dimension (namely, x 2 4). <p> Queries take O (log log log B n) log B n + z) I/Os. The data structure uses O (n log 1+k n) space to support 3-D range queries in which 0 k 3 of the dimensions have finite ranges. Agarwal et al. <ref> [3] </ref> give near-optimal bounds for halfspace range searching 20 JEFFREY SCOTT VITTER in two dimensions and some variants in higher dimensions using another type of partitioning structure.
Reference: [4] <author> P. K. Agarwal, L. Arge, T. M. Murali, K. Varadarajan, and J. S. Vitter. </author> <title> I/O-efficient algorithms for contour line extraction and planar graph blocking. </title> <booktitle> In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1998. </year>
Reference-contexts: A practical, randomized implementation of list ranking appears in [96]. Recent work on other EM graph algorithms appears in [1, 10, 73, 56]. The problem of how to store graphs on disks for efficient traversal is discussed in <ref> [81, 4] </ref>. Constructing classification trees in external memory for data mining is discussed in [113]. The I/O complexity of several of the basic graph problems considered in [31, 102] remain open, including connectivity, topological sorting, shortest paths, breadth-first search, and depth-first search. <p> For example, the range query [3; 5] fi <ref> [4; 1] </ref> is a (2; 1)-sided range query, since there are two sides in the x 1 dimension (namely, 3 x 1 and x 1 5) but only one side in the x 2 dimension (namely, x 2 4). <p> The EM interval tree is used by [33] to extract at query time the boundary components of the isosurface (or contour) of a surface. A data structure for a related problem, which in addition has optimal output complexity, appears in <ref> [4] </ref>. Ramaswamy and Subramanian [87] introduce the notion of path caching to develop EM algorithms for (1; 1)-sided and (2; 1)-sided 2-D range queries. Their algorithms are optimal in criteria 1 and 2 but with higher storage overheads and amortized and/or nonoptimal update bounds.
Reference: [5] <author> P. K. Agarwal and J. Erickson. </author> <title> Geometric range searching and its relatives. </title> <editor> In B. Chazelle, E. Goodman, and R. Pollack, editors, </editor> <title> Discrete and Computational Geometry: Ten Years Later, 63-72. </title> <journal> American Mathematical Society Press, </journal> <note> to appear. </note>
Reference-contexts: For example, the range query <ref> [3; 5] </ref> fi [4; 1] is a (2; 1)-sided range query, since there are two sides in the x 1 dimension (namely, 3 x 1 and x 1 5) but only one side in the x 2 dimension (namely, x 2 4). <p> Callahan et al. [28] develop a dynamic EM data structure for use in several online problems such as finding an approximately nearest neighbor and maintaining the closest pair of vertices. Numerous other data structures have been developed for range queries and related problems on spatial data. We refer to <ref> [5, 80] </ref> for a survey. 9. String Processing Digital trie-based structures, in which branching decisions at each node are made based upon the values of particular bits in strings, are effective for string processing in internal memory. In EM applications, what is needed is a multiway digital structure.
Reference: [6] <author> A. Aggarwal and C. G. Plaxton. </author> <title> Optimal parallel sorting in multi-level storage. </title> <booktitle> Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> 659-668, </pages> <year> 1994. </year>
Reference-contexts: A final application of Columnsort [75] in conjunction with partial striping suffices to restore total order. An optimal deterministic merge sort, with somewhat higher constant factors than those of the distribution sort algorithms, was developed by Aggarwal and Plax-ton <ref> [6] </ref>, based upon the Sharesort hypercube sorting algorithm [40]. To guarantee even distribution during the merging, it employs two high-level merging schemes in which the scheduling is almost oblivious.
Reference: [7] <author> A. Aggarwal and J. S. Vitter. </author> <title> The input/output complexity of sorting and related problems. </title> <journal> Communications of the ACM, </journal> <volume> 31(9), </volume> <pages> 1116-1127, </pages> <year> 1988. </year>
Reference-contexts: Hong and Kung [62] developed a pebbling model of I/O for straightline computations, and Savage and Vitter [93] extended the model to deal with block transfer. Aggarwal and Vitter <ref> [7] </ref> generalized Floyd's I/O model to allow simultaneous block transfers, but the model was unrealistic in that the simultaneous transfers were allowed to take place on a single disk. They developed matching upper and lower I/O bounds for all parameter values for a host of problems. <p> The following proof of the permutation lower bound (2.4) of Theorem 2.2 is due to Aggarwal and Vitter <ref> [7] </ref>. The idea of the proof is to measure, for each t 0, the number of distinct orderings that are realizable by at least one sequence of t I/Os. <p> In the unlikely case that B log m = o (log n), the permuting bound is only (N=D), and we must resort to the comparison model to get the full EXTERNAL MEMORY ALGORITHMS (DRAFT, June 18, 1998) 13 lower bound (2.1) of Theorem 2.1 <ref> [7] </ref>. Arge et al. [14] show for the comparison model that any problem with an (N log N ) lower bound in the RAM model requires (n log m n) I/Os in PDM. <p> The same lower bound also applies to the FFT, since permutation networks can be built from a series of three FFTs. The lower bound for transposition involves a potential argument based on a togetherness relation <ref> [7] </ref>. Chiang et al. [31] and Arge [10] discuss lower bound reductions for several graph problems. Problems like list ranking and expression tree evaluation have the same nonlinear PDM lower bound as permuting.
Reference: [8] <author> M. Ajtai, M. Fredman, and J. Komlos. </author> <title> Hash functions for priority queues. </title> <journal> Information and Control, </journal> <volume> 63(3), </volume> <pages> 217-225, </pages> <year> 1984. </year>
Reference-contexts: Pointers to the B 1 strings could be stored, but access to them during search would require more than a constant number of I/Os. Their solution, called the blind trie, is based on the data structure of Ajtai et al. <ref> [8] </ref> that achieves B-way branching with a total storage of O (B) characters. Each internal node stores an index (a number from 0 to N ) and a one-character label for each of its outgoing edges.
Reference: [9] <author> L. Arge. </author> <title> The buffer tree: A new technique for optimal I/O-algorithms. </title> <booktitle> In Proceedings of the Workshop on Algorithms and Data Structures, </booktitle> <volume> LNCS 955, </volume> <pages> 334-345, </pages> <year> 1995. </year> <note> A complete version appears as BRICS technical report RS-96-28, </note> <institution> University of Aarhus. </institution>
Reference-contexts: An alternative sorting technique, with higher overhead, is to use the buffer tree data structure <ref> [9] </ref> described in Section 7.2, which was developed for batched dynamic applications. 2.2. Sorting by Merging. The merge paradigm is somewhat orthogonal to the distribution paradigm discussed above. <p> For list ranking, the optimality of the EM algorithm in [31] assumes that p m log m = (log n), which is usually true. That assumption can be removed by use of the buffer tree data structure <ref> [9] </ref> (see Section 7.2). A practical, randomized implementation of list ranking appears in [96]. Recent work on other EM graph algorithms appears in [1, 10, 73, 56]. The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. <p> The binary nature of the tree results in a data structure of height ~ lg n, yielding a total I/O bound of O (n lg n), which is still nonoptimal by a significant log m factor. Arge <ref> [9] </ref> developed the elegant buffer tree data structure to support batched dynamic operations such as in this example, where the queries do not have to be answered right away or in any particular order. The buffer tree is a balanced multiway tree, but with degree fi (m).
Reference: [10] <author> L. Arge. </author> <title> The I/O-complexity of ordered binary-decision diagram manipulation. </title> <booktitle> In Proceedings of the International Symposium on Algorithms and Computation, </booktitle> <volume> LNCS 1004, </volume> <pages> 82-91, </pages> <year> 1995. </year> <title> EXTERNAL MEMORY ALGORITHMS (DRAFT, </title> <address> June 18, </address> <year> 1998) </year> <month> 27 </month>
Reference-contexts: The same lower bound also applies to the FFT, since permutation networks can be built from a series of three FFTs. The lower bound for transposition involves a potential argument based on a togetherness relation [7]. Chiang et al. [31] and Arge <ref> [10] </ref> discuss lower bound reductions for several graph problems. Problems like list ranking and expression tree evaluation have the same nonlinear PDM lower bound as permuting. This situation is in contrast with the RAM model, in which the same problems can all be done in linear time. <p> That assumption can be removed by use of the buffer tree data structure [9] (see Section 7.2). A practical, randomized implementation of list ranking appears in [96]. Recent work on other EM graph algorithms appears in <ref> [1, 10, 73, 56] </ref>. The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. Constructing classification trees in external memory for data mining is discussed in [113].
Reference: [11] <author> L. Arge. </author> <title> External-memory algorithms with applications in geographic information systems. </title> <editor> In M. van Kreveld, J. Nievergelt, T. Roos, and P. Widmayer, editors, </editor> <title> Algorithmic Foundations of GIS. </title> <publisher> Springer-Verlag, LNCS 1340, </publisher> <year> 1997. </year>
Reference-contexts: Modified versions of PDM that integrate various aspects of parallel computation are developed in [41, 77]. Surveys of various aspects of I/O models and algorithms appear in <ref> [11, 95] </ref>. The same type of bottleneck that occurs between internal memory and external disk storage can also occur at other levels of the memory hierarchy, such as between data cache and level 2 cache, or between level 2 cache and DRAM, or between disk storage and tertiary devices.
Reference: [12] <author> L. Arge, P. Ferragina, R. Grossi, and J. Vitter. </author> <title> On sorting strings in external memory. </title> <booktitle> In Proceedings of the ACM Symposium on Theory of Computation, </booktitle> <pages> 540-548, </pages> <year> 1997. </year>
Reference-contexts: Farach and Ferragina [46] show how to construct SB-trees, suffix trees, and suffix arrays on strings of length N using O (n log m n) I/Os, which is optimal. Clark and Munro [34] give an alternate approach to suffix trees. Arge et al. <ref> [12] </ref> consider several models for the problem of sorting K strings of total length N in external memory. They develop efficient sorting algorithms in these models, making use of the SB-tree, buffer tree techniques, and a simplified version of the SB-tree for merging called the lazy trie. <p> We can sort K strings of total length N , where N 1 is the total length of the short strings, using the following number of I/Os: O K log M K + B N 1 Lower bounds for various models of how strings can be manipulated are given in <ref> [12] </ref>. 10. The TPIE External Memory Programming Environment There are three basic approaches to supporting development of I/O-efficient code, which we call array-oriented systems (such as PASSION and ViC*), access-oriented systems (such as the UNIX file system, Panda, and MPI-IO), and framework-oriented systems (such as TPIE).
Reference: [13] <author> L. Arge, K. H. Hinrichs, J. Vahrenhold, and J. S. Vitter. </author> <title> Efficient bulk operations on dynamic R-trees, 1998. </title> <type> Manuscript. </type>
Reference-contexts: Bulk loading a Hilbert R-tree is therefore easy once the center points are presorted, but the quality of the Hilbert R-tree in terms of query performance is not as good as that of an R*-tree, especially for higher-dimensional data [26, 66]. Arge et al. <ref> [13] </ref> and Bercken et al. [103] have independently devised fast bulk loading methods for R*-trees that are based upon buffer trees. The former method is especially efficient and can even support dynamic batched updates and queries. Experiments with this technique are discussed in Section 11. 8. <p> Batched Operations on R-trees. In the second experiment, three methods for building R-trees are evaluated in terms of their bulk loading time and the resulting query performance. The three methods tested are a newly developed buffer R-tree method <ref> [13] </ref> (labeled "buffer"), the naive sequential method for construction into R*-trees (labeled "naive"), and the best update algorithm for Hilbert R-trees (labeled "Hilbert") [66]. The experimental data came from TIGER/line road data sets from four U.S. states.
Reference: [14] <author> L. Arge, M. Knudsen, and K. Larsen. </author> <title> A general lower bound on the I/O-complexity of comparison-based algorithms. </title> <booktitle> In Proceedings of the 3rd Workshop on Algorithms and Data Structures, </booktitle> <volume> volume 709, </volume> <pages> 83-94. </pages> <booktitle> Lecture Notes in Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: In the unlikely case that B log m = o (log n), the permuting bound is only (N=D), and we must resort to the comparison model to get the full EXTERNAL MEMORY ALGORITHMS (DRAFT, June 18, 1998) 13 lower bound (2.1) of Theorem 2.1 [7]. Arge et al. <ref> [14] </ref> show for the comparison model that any problem with an (N log N ) lower bound in the RAM model requires (n log m n) I/Os in PDM.
Reference: [15] <author> L. Arge and P. Miltersen. </author> <title> On showing lower bounds for external-memory computational geometry problems. </title> <editor> In J. Abello and J. S. Vitter, editors, </editor> <title> External Memory Algorithms and Visualization, DIMACS series. </title> <publisher> American Mathematical Society, </publisher> <year> 1998. </year>
Reference-contexts: It is conjectured that the sorting lower bound (2.1) remains valid even if the indivisibility assumption is lifted. However, for an artificial problem related to transposition, Adler [2] showed that removing the indivisibility assumption can lead to faster algorithms. A similar result is shown by Arge and Miltersen <ref> [15] </ref> for the decision problem of determining if the N data item values are distinct. Whether or not the conjecture is true is a challenging theoretical problem. 4. Matrix and Grid Computations Dense matrices are generally represented in memory in row-major or column-major order.
Reference: [16] <author> L. Arge, O. Procopiuc, S. Ramaswamy, T. Suel, and J. S. Vitter. </author> <title> Scalable sweeping-based spatial join. </title> <booktitle> In Proceedings of the 24th International Conference on Very Large Databases, </booktitle> <address> New York, </address> <month> August </month> <year> 1998. </year>
Reference-contexts: Rectangle Intersection and Spatial Join. In the first experiment, three algorithms are implemented in TPIE for the problem of rectangle intersection, which is often the first step in a spatial join computation. The first method, called Scalable Sweeping-Based Spatial Join (SSSJ) <ref> [16] </ref>, is a robust new algorithm based upon the distribution sweep paradigm of Section 5. The other two methods are Partition-Based Spatial-Merge (QPBSM) used in Paradise [86] and a new modification called MPBSM that uses an improved dynamic data structure for intervals [16]. <p> first method, called Scalable Sweeping-Based Spatial Join (SSSJ) <ref> [16] </ref>, is a robust new algorithm based upon the distribution sweep paradigm of Section 5. The other two methods are Partition-Based Spatial-Merge (QPBSM) used in Paradise [86] and a new modification called MPBSM that uses an improved dynamic data structure for intervals [16]. The algorithms were tested on several data sets. The timing results for the two data sets in Figures 5 (a) and 5 (b) are given in Figures 5 (c) and 5 (d), respectively.
Reference: [17] <author> L. Arge, O. Procopiuc, S. Ramaswamy, T. Suel, and J. S. Vitter. </author> <title> Theory and practice of I/O-efficient algorithms for multidimensional batched searching problems. </title> <booktitle> In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1998. </year>
Reference-contexts: Computing the visibility of N segments from a point, 12. Performing Q ray-shooting queries in CSG models of size N , EXTERNAL MEMORY ALGORITHMS (DRAFT, June 18, 1998) 15 Goodrich et al. [54], Arge et al. [18], Arge et al. <ref> [17] </ref>, and Crauser et al. [39] develop EM algorithms for these problems using the following EM paradigms for batched problems: Distribution sweeping: a generalization of the distribution paradigm of Sec tion 2 for externalizing plane sweep algorithms; Persistent B-trees: an o*ine method for constructing an optimal-space persistent version of the B-tree <p> After the initial sorting preprocessing, each of the O (log m n) levels of recursion requires O (n) I/Os, yielding the desired bound (5.1). Arge et al. <ref> [17] </ref> develop a unified approach to distribution sweep in higher dimensions. A central operation in spatial databases is spatial join. A common preprocessing step is to find the pairwise intersections of the bounding boxes of the objects involved in the spatial join. <p> The problem of intersecting orthogonal rectangles can be solved by combining the previous algorithm for orthogonal segments with one for range searching. A unified approach, extendible to higher dimensions, is taken by Arge et al. <ref> [17] </ref> using distribution sweep. The objects that are stored in the data structure in this case are rectangles, not vertical segments. The branching factor is chosen to be fi ( p m ) rather than fi (m). <p> Arge et al. <ref> [17] </ref> also give an algorithm for finding all intersections among N line segments, but the output component of the I/O bound is slightly nonoptimal: z log m n rather than z.
Reference: [18] <author> L. Arge, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory algorithms for processing line segments in geographic information systems. </title> <journal> Algorithmica, </journal> <note> to appear. Special issue on cartography and geographic information systems. </note>
Reference-contexts: Computing the measure of the union of N orthogonal rectangles, 11. Computing the visibility of N segments from a point, 12. Performing Q ray-shooting queries in CSG models of size N , EXTERNAL MEMORY ALGORITHMS (DRAFT, June 18, 1998) 15 Goodrich et al. [54], Arge et al. <ref> [18] </ref>, Arge et al. [17], and Crauser et al. [39] develop EM algorithms for these problems using the following EM paradigms for batched problems: Distribution sweeping: a generalization of the distribution paradigm of Sec tion 2 for externalizing plane sweep algorithms; Persistent B-trees: an o*ine method for constructing an optimal-space persistent
Reference: [19] <author> L. Arge and J. S. Vitter. </author> <title> Optimal interval management in external memory. </title> <booktitle> In Proceedings of the 37th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> 560-569, </pages> <address> Burlington, VT, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Persistent versions of B-trees have been developed by Becker et al. [24] and Varman and Verma [105]. Lomet and Salzberg [79] explore mechanisms to add concurrency and recovery to B-trees. Arge and Vitter <ref> [19] </ref> give a useful variant of B-trees called weight-balanced B-trees with the property that the number of data items in any subtree of height h is fi (a h ), for some fixed parameter a of order B. (By contrast, the sizes of subtrees at level h in a regular B-tree <p> Weight-balanced B-trees were originally developed as part of an optimal dynamic data structure for stabbing queries and segment trees, but they can also be used to get improvements for algorithms developed in the RAM model <ref> [19, 56] </ref>. For example, by setting a to a constant, we get a simple, worst-case implementation of interval trees. They also serve as a simpler and worst-case alternative to the data structure in [114] for augmenting one-dimensional data structures with range restriction capabilities. <p> Arge and Vitter <ref> [19] </ref> design an interval tree based upon the weight-balanced B-tree that meets all four goals. It solves the problems of stabbing queries and dynamic interval management following up on earlier work by Kanellakis et al. [68].
Reference: [20] <author> R. Barve, P. B. Gibbons, B. Hillyer, Y. Matias, E. Shriver, and J. S. Vitter. </author> <title> Modeling and optimizing I/O throughput of multiple disks on a bus: the long version. </title> <type> Technical report, </type> <institution> Bell Labs, </institution> <year> 1997. </year>
Reference-contexts: More complex and precise disk models have been developed, such as the ones by Ruemmler and Wilkes [88], Shriver et al. [94], and Barve et al. <ref> [20] </ref>, which distinguish between sequential reads and random reads and consider the effects on throughput of features such as disk buffer caches and shared buses, which can reduce the time per I/O by eliminating or hiding the seek time, In practice, the effects of more complex models can often be realized
Reference: [21] <author> R. Barve, E. F. Grove, and J. S. Vitter. </author> <title> Simple randomized mergesort on parallel disks. </title> <journal> Parallel Computing, </journal> <volume> 23(4), </volume> <pages> 601-631, </pages> <year> 1997. </year>
Reference-contexts: The ratio of the number of I/Os used by simple randomized merge sort (SRM) to the number of I/Os used by merge sort with disk striping, during a merge of kD runs. The figures were obtained by simulation; they back up the (more pessimistic) analytic upper bound in <ref> [21] </ref>. D blocks needed for the output can always be read in by a single I/O operation, and thus the amount of buffer space needed for binary merging can be kept to a minimum. <p> To guarantee even distribution during the merging, it employs two high-level merging schemes in which the scheduling is almost oblivious. The most practical method for sorting is the simple randomized merge sort (SRM) algorithm of Barve et al. <ref> [21] </ref> (referred to as "randomized striping" by Knuth [71]). <p> The expected performance of SRM is not optimal for all parameter values, but it significantly outperforms the use of disk striping for reasonable values of the parameters, as shown in Table 1. Barve et al. <ref> [21] </ref> derive an upper bound on the I/O performance; the precise analysis is an interesting open problem [71]. 2.3. Permuting and Transposition.
Reference: [22] <author> R. Barve and J. S. Vitter. </author> <title> External memory algorithms with dynamically changing memory, 1998. </title> <type> Manuscript. </type>
Reference-contexts: The algorithms in the previous sections assume a fixed memory allocation; they must make use of virtual memory if the memory allocation is reduced, often causing a severe performance hit. Barve and Vitter <ref> [22] </ref> discuss the design and analysis of EM algorithms that adapt gracefully to changing memory allocations.
Reference: [23] <author> R. Bayer and E. McCreight. </author> <title> Organization of large ordered indexes. </title> <journal> Acta Inform., </journal> <volume> 1, </volume> <pages> 173-189, </pages> <year> 1972. </year>
Reference-contexts: A tree of degree B c , for fixed c &gt; 0, with n leaf nodes has height dc log B ne. The well-known B-tree due to Bayer and McCreight <ref> [23, 71] </ref> is a balanced multiway tree with height ~ log B n in which each node has degree fi (B). It supports dynamic dictionary operations and one-dimensional range queries in O (log B n + t) I/Os per operation.
Reference: [24] <author> B. Becker, S. Gschwind, T. Ohler, B. Seeger, and P. Widmayer. </author> <title> An asymptotically optimal multiversion B-tree. </title> <journal> The VLDB Journal, </journal> <volume> 5(4), </volume> <pages> 264-275, </pages> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: It supports dynamic dictionary operations and one-dimensional range queries in O (log B n + t) I/Os per operation. Persistent versions of B-trees have been developed by Becker et al. <ref> [24] </ref> and Varman and Verma [105]. Lomet and Salzberg [79] explore mechanisms to add concurrency and recovery to B-trees.
Reference: [25] <author> N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. </author> <title> The R*-tree: An efficient and robust access method for points and rectangles. </title> <booktitle> In Proceedings of the SIGMOD International Conference on Management of Data, </booktitle> <pages> 322-331, </pages> <year> 1990. </year>
Reference-contexts: In that case, the search must proceed to all such children. Several heuristics for where to insert new items into the R-tree and how to rebalance are surveyed in [51, 55]. The R*-tree of Beckmann et al. <ref> [25] </ref> seems to give best overall query performance. Constructing an R*-tree by repeated insertions, however, is extremely slow. A faster alternative is to use the Hilbert R-tree of Kamel and Faloutsos [64, 65].
Reference: [26] <author> S. Berchtold, C. Bohm, and H.-P. Kriegel. </author> <title> Improving the query performance of high-dimensional index structures by bulk load operations. </title> <booktitle> In International Conference on Extending Database Technology, </booktitle> <year> 1998. </year>
Reference-contexts: Bulk loading a Hilbert R-tree is therefore easy once the center points are presorted, but the quality of the Hilbert R-tree in terms of query performance is not as good as that of an R*-tree, especially for higher-dimensional data <ref> [26, 66] </ref>. Arge et al. [13] and Bercken et al. [103] have independently devised fast bulk loading methods for R*-trees that are based upon buffer trees. The former method is especially efficient and can even support dynamic batched updates and queries.
Reference: [27] <author> G. S. Brodal and J. Katajainen. </author> <title> Worst-case efficient external-memory priority queues. </title> <type> Technical Report DIKU Report 97/25, </type> <institution> University of Copenhagen, </institution> <month> October </month> <year> 1997. </year>
Reference-contexts: Buffer trees have an ever-expanding list of applications. They provide, for example, a natural amortized implementation of priority queues for use in applications like discrete event simulation, sweeping, and list ranking. Brodal and Kata-jainen <ref> [27] </ref> develop a worst-case optimal priority queue, in the sense that every sequence of B insert and delete min operations requires only O (log m n) I/Os. 7.3. R-trees. The R-tree of Guttman [59] and its many variants are an elegant generalization of the B-tree for storing geometric objects.
Reference: [28] <author> P. Callahan, M. T. Goodrich, and K. Ramaiyer. </author> <title> Topology B-trees and their applications. </title> <booktitle> In Proceedings of the Workshop on Algorithms and Data Structures, </booktitle> <volume> LNCS 955, </volume> <pages> 381-392, </pages> <year> 1995. </year>
Reference-contexts: Agarwal et al. [3] give near-optimal bounds for halfspace range searching 20 JEFFREY SCOTT VITTER in two dimensions and some variants in higher dimensions using another type of partitioning structure. Callahan et al. <ref> [28] </ref> develop a dynamic EM data structure for use in several online problems such as finding an approximately nearest neighbor and maintaining the closest pair of vertices. Numerous other data structures have been developed for range queries and related problems on spatial data.
Reference: [29] <author> B. Chazelle. </author> <title> Lower bounds for orthogonal range searching: I. the reporting case. </title> <journal> Journal of the ACM, </journal> <volume> 37(2), </volume> <pages> 200-212, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: The update times are amortized and slightly nonoptimal, and the space overhead for (2; 2)-sided queries is O On the other hand, Subramanian and Ramaswamy [98] prove a lower bound for an external memory version of the pointer machine model, based upon a result of Chazelle <ref> [29] </ref> for the RAM model, that no EM algorithm can achieve both criteria 1 and 2 using less than O space, even if we relax 1 to allow O I/Os, and thus their algorithm is near-optimal.
Reference: [30] <author> P. M. Chen, E. K. Lee, G. A. Gibson, R. H. Katz, and D. A. Patterson. </author> <title> RAID: high-performance, reliable secondary storage. </title> <journal> ACM Computing Surveys, </journal> <volume> 26(2), </volume> <pages> 145-185, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: In fact the access gap is growing, since the speed of memory chips is increasing more quickly than disk bandwidth and disk latency. The use of parallel processors further widens the gap. Storage systems such as RAID are being developed that use multiple disks to get more bandwidth <ref> [30, 61] </ref>. <p> All the methods we discuss, with the exception of Greed Sort in Section 2.2, use the disks independently for parallel read operations, but parallel writes are done in a striped manner, which facilitates the writing of parity error correction information <ref> [30, 61] </ref>. The lower bounds are discussed in Section 3. 2.1. Sorting by Distribution: Simultaneous Online Load Balancings. Distribution sort is a recursive process in which the data items to be sorted are partitioned by a set of S 1 partitioning elements into S buckets.
Reference: [31] <author> Y.-J. Chiang, , M. T. Goodrich, E. F. Grove, R. Tamassia, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory graph algorithms. </title> <booktitle> In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> 139-149, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: The same lower bound also applies to the FFT, since permutation networks can be built from a series of three FFTs. The lower bound for transposition involves a potential argument based on a togetherness relation [7]. Chiang et al. <ref> [31] </ref> and Arge [10] discuss lower bound reductions for several graph problems. Problems like list ranking and expression tree evaluation have the same nonlinear PDM lower bound as permuting. This situation is in contrast with the RAM model, in which the same problems can all be done in linear time. <p> They also show how to compute the trapezoidal decomposition for intersecting segments. 6. Batched Problems on Graphs The first work on EM graph algorithms was by Ullman and Yannakakis [102] for the problem of transitive closure. Chiang et al. <ref> [31] </ref> consider a variety of graph problems, several of which have upper and lower I/O bounds related to permuting. One key idea Chiang et al. exploit is that efficient EM algorithms can often be developed by a sequential simulation of a parallel algorithm for the same problem. <p> For list ranking, the optimality of the EM algorithm in <ref> [31] </ref> assumes that p m log m = (log n), which is usually true. That assumption can be removed by use of the buffer tree data structure [9] (see Section 7.2). A practical, randomized implementation of list ranking appears in [96]. <p> The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. Constructing classification trees in external memory for data mining is discussed in [113]. The I/O complexity of several of the basic graph problems considered in <ref> [31, 102] </ref> remain open, including connectivity, topological sorting, shortest paths, breadth-first search, and depth-first search.
Reference: [32] <author> Y.-J. Chiang. </author> <title> Experiments on the practical I/O efficiency of geometric algorithms: Distribution sweep vs. plane sweep. </title> <booktitle> In Proceedings of the 1995 Workshop on Algs. and Data Structures, </booktitle> <year> 1995. </year> <note> 28 JEFFREY SCOTT VITTER </note>
Reference-contexts: Empirical Comparisons In this section we examine the empirical performance of algorithms for two problems that arise in spatial databases. The TPIE system described in the previous section is used as the common implementation platform. Other recent experiments involving the paradigms discussed in this paper appear in <ref> [32, 63] </ref>. 11.1. Rectangle Intersection and Spatial Join. In the first experiment, three algorithms are implemented in TPIE for the problem of rectangle intersection, which is often the first step in a spatial join computation.
Reference: [33] <author> Y.-J. Chiang and C. T. Silva. </author> <title> I/O optimal isosurface extraction. </title> <booktitle> In Proceedings of the IEEE Visualization Conference, </booktitle> <year> 1997. </year>
Reference-contexts: It solves the problems of stabbing queries and dynamic interval management following up on earlier work by Kanellakis et al. [68]. Stabbing queries are equivalent to (1; 1)-sided range queries where the corner point is on the diagonal. The EM interval tree is used by <ref> [33] </ref> to extract at query time the boundary components of the isosurface (or contour) of a surface. A data structure for a related problem, which in addition has optimal output complexity, appears in [4].
Reference: [34] <author> D. R. Clark and J. I. Munro. </author> <title> Efficient suffix trees on secondary storage. </title> <booktitle> In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> 383-391, </pages> <address> Atlanta, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Ferragina and Grossi apply SB-trees to string matching, prefix search, and substring search. Farach and Ferragina [46] show how to construct SB-trees, suffix trees, and suffix arrays on strings of length N using O (n log m n) I/Os, which is optimal. Clark and Munro <ref> [34] </ref> give an alternate approach to suffix trees. Arge et al. [12] consider several models for the problem of sorting K strings of total length N in external memory.
Reference: [35] <author> K. L. Clarkson and P. W. Shor. </author> <title> Applications of random sampling in computational geometry, II. </title> <journal> Discrete and Computational Geometry, </journal> <volume> 4, </volume> <pages> 387-421, </pages> <year> 1989. </year>
Reference-contexts: External marriage-before-conquest : an EM analog to the well-known technique of Kirkpatrick and Seidel [70] for performing output-sensitive convex hull constructions. Randomized incremental construction with gradations: a localized version of the incremental construction paradigm of Clarkson and Shor <ref> [35] </ref>. The distribution sweep paradigm is fundamental to sweep line processes.
Reference: [36] <author> P. Corbett, D. Feitelson, S. Fineberg, Y. Hsu, B. Nitzberg, J.-P. Prost, M. Snir, B. Traversat, and P. Wong. </author> <title> Overview of the MPI-IO parallel I/O interface. </title> <editor> In R. Jain, J. Werth, and J. C. Browne, editors, </editor> <booktitle> Input/Output in Parallel and Distributed Computer Systems, volume 362 of The Kluwer International Series in Engineering and Computer Science, chapter 5, </booktitle> <pages> 127-146. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1996. </year>
Reference-contexts: If the ith key in the input of the sorting instance has key value x 6= 0, there is a nonzero matrix element in position (x; i). The reader is referred to <ref> [36, 78, 89, 101, 100, 108, 110] </ref> for further study of EM matrix algorithms. 5.
Reference: [37] <author> T. H. Cormen and D. M. Nicol. </author> <title> Performing out-of-core FFTs on parallel disk systems. </title> <booktitle> Parallel Computing, </booktitle> <year> 1998. </year> <note> To appear; available as Dartmouth Report PCS-TR96-294. </note>
Reference-contexts: A permutation network can be realized by a series of three FFTs [116]. Theorem 2.5. The number of I/Os using D disks required for computing the N -input FFT digraph or an N -input permutation network is given by the same bound (2:1) as for sorting. Cormen and Nicol <ref> [37] </ref> give some practical implementations for one-dimensional FFTs based upon the optimal PDM algorithm of [111]. The algorithms for FFT are faster and simpler than for sorting because the computation is nonadaptive in nature, and thus the communication pattern is oblivious. 3.
Reference: [38] <author> T. H. Cormen, T. Sundquist, and L. F. Wisniewski. </author> <title> Asymptotically tight bounds for performing BMMC permutations on parallel disk systems. </title> <journal> SIAM Journal on Computing, </journal> <note> to appear. </note>
Reference-contexts: BPC permutations are the special case in which A is a permutation matrix, in which each row and each column contain a single 1. BPC permutations include matrix transposition, bit-reversal permutations (which arise in the FFT), vector-reversal permutations, hypercube permutations, and matrix reblocking. Cormen et al. <ref> [38] </ref> characterize the optimal number of I/Os needed to perform any given BMMC permutation solely as a function of the associated matrix A, and they give an optimal algorithm for implementing it. Theorem 2.4 ([38]).
Reference: [39] <author> A. Crauser, P. Ferragina, K. Mehlhorn, U. Meyer, and E. Ramos. </author> <title> Randomized external-memory algorithms for geometric problems. </title> <booktitle> In Proceedings of the 14th ACM Symposium on Computational Geometry, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: Computing the visibility of N segments from a point, 12. Performing Q ray-shooting queries in CSG models of size N , EXTERNAL MEMORY ALGORITHMS (DRAFT, June 18, 1998) 15 Goodrich et al. [54], Arge et al. [18], Arge et al. [17], and Crauser et al. <ref> [39] </ref> develop EM algorithms for these problems using the following EM paradigms for batched problems: Distribution sweeping: a generalization of the distribution paradigm of Sec tion 2 for externalizing plane sweep algorithms; Persistent B-trees: an o*ine method for constructing an optimal-space persistent version of the B-tree data structure (see Section 7.1), <p> Arge et al. [17] also give an algorithm for finding all intersections among N line segments, but the output component of the I/O bound is slightly nonoptimal: z log m n rather than z. Crauser et al. <ref> [39] </ref> use an incremental randomized construction to attain the I/O bound (5.1) for line segment intersection and other problems. They also show how to compute the trapezoidal decomposition for intersecting segments. 6.
Reference: [40] <author> R. Cypher and G. Plaxton. </author> <title> Deterministic sorting in nearly logarithmic time on the hypercube and related computers. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 47(3), </volume> <pages> 501-548, </pages> <year> 1993. </year>
Reference-contexts: A final application of Columnsort [75] in conjunction with partial striping suffices to restore total order. An optimal deterministic merge sort, with somewhat higher constant factors than those of the distribution sort algorithms, was developed by Aggarwal and Plax-ton [6], based upon the Sharesort hypercube sorting algorithm <ref> [40] </ref>. To guarantee even distribution during the merging, it employs two high-level merging schemes in which the scheduling is almost oblivious. The most practical method for sorting is the simple randomized merge sort (SRM) algorithm of Barve et al. [21] (referred to as "randomized striping" by Knuth [71]).
Reference: [41] <author> F. Dehne, W. Dittrich, and D. Hutchinson. </author> <title> Efficient external memory algorithms by simulating coarse-grained parallel algorithms. </title> <booktitle> In Proceedings of the 9th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> 106-115, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Since the PDM model can be thought of as a more restrictive (and more realistic) version of their model, their lower bounds apply as well to PDM. Modified versions of PDM that integrate various aspects of parallel computation are developed in <ref> [41, 77] </ref>. Surveys of various aspects of I/O models and algorithms appear in [11, 95]. <p> of several other graph problems, the number of working processors in the parallel algorithm decreases geometrically with time, so the number of I/Os for the entire simulation is proportional to the number of I/Os used in the first phase, which is given by the sorting bound fi Dehne et al. <ref> [41] </ref> and Sibeyn and Kaufmann [97] show how to achieve the same I/O bound if log B = O by exploiting coarse-grained parallel algorithms whose data access characteristics permit the periodic sortings to be done with a linear number of I/Os.
Reference: [42] <author> H. B. Demuth. </author> <title> Electronic Data Sorting. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1956. </year> <note> A shortened version appears in IEEE Transactions on Computing, C-34(4):296-310, April 1985, special issue on sorting, </note> <author> E. E. Lindstrom, C. K. Wong, and J. S. Vitter, </author> <title> editors. </title>
Reference-contexts: The bottom line is that programs that perform well in terms of PDM will generally perform well when implemented on real systems. The study of the complexity of algorithms using external memory devices began more than 40 years ago with Demuth's Ph.D. thesis on sorting <ref> [42, 71] </ref>. In the early 1970s, Knuth [71] did an extensive study of sorting using magnetic tapes and (to a lesser extent) magnetic disks.
Reference: [43] <author> P. J. Denning. </author> <title> Working sets past and present. </title> <journal> IEEE Transactions on Software Engg.,, </journal> <volume> SE-6, </volume> <pages> 64-84, </pages> <year> 1980. </year>
Reference-contexts: Modern operating systems can take advantage of such access patterns by tracking the program's so-called "working set," which a vague notion that designates the data items that are being referenced repeatedly. <ref> [43] </ref>. If the working set is small, it can be cached in very high-speed memory so that access to it is fast.
Reference: [44] <author> D. J. DeWitt, J. F. Naughton, and D. A. Schneider. </author> <title> Parallel sorting on a shared-nothing architecture using probabilistic splitting. </title> <booktitle> In Proceedings of the First International Conference on Parallel and Distributed Information Systems, </booktitle> <pages> 280-291, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: DeWitt et al. <ref> [44] </ref> present a randomized distribution sort algorithm in a similar model to handle the case when sorting can be done in two passes. They use a sampling technique to find the partitioning elements and route the items in each bucket to a particular processor.
Reference: [45] <author> J. R. Driscoll, N. Sarnak, D. D. Sleator, and R. E. Tarjan. </author> <title> Making data structures persistent. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 38, </volume> <pages> 86-124, </pages> <year> 1989. </year>
Reference-contexts: sweeping: a generalization of the distribution paradigm of Sec tion 2 for externalizing plane sweep algorithms; Persistent B-trees: an o*ine method for constructing an optimal-space persistent version of the B-tree data structure (see Section 7.1), yielding a factor of B improvement over the generic persistence techniques of Driscoll et al. <ref> [45] </ref>. Batched filtering: a general method for performing simultaneous external memory searches in data structures that can be modeled as planar layered directed acyclic graphs and in external fractionally cascaded data structures; useful for 3-D convex hulls and batched point location.
Reference: [46] <author> M. Farach and P. Ferragina. </author> <title> Optimal suffix tree construction in external memory, November 1997. </title> <type> Manuscript. </type>
Reference-contexts: The pointers to the B children of the SB-tree node are also stored at the leaves. Ferragina and Grossi apply SB-trees to string matching, prefix search, and substring search. Farach and Ferragina <ref> [46] </ref> show how to construct SB-trees, suffix trees, and suffix arrays on strings of length N using O (n log m n) I/Os, which is optimal. Clark and Munro [34] give an alternate approach to suffix trees.
Reference: [47] <author> W. Feller. </author> <title> An Introduction to Probability Theory and its Applications, volume 1. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, third edition, </address> <year> 1968. </year>
Reference-contexts: But efficient deterministic methods exist for choosing S = p m partitioning elements [83, 111], which has the effect of doubling the number of levels of recursion. Probabilistic methods based upon random sampling can be found in <ref> [47] </ref>. In order to meet the sorting bound (2.1), the formation of the buckets at each level of recursion must be done in O (n=D) I/Os, which is easy to do for the single-disk case.
Reference: [48] <author> P. Ferragina and R. Grossi. </author> <title> A fully-dynamic data structure for external substring search. </title> <booktitle> In Proceedings of the 27th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> 693-702, </pages> <address> Las Vegas, </address> <year> 1995. </year>
Reference-contexts: In EM applications, what is needed is a multiway digital structure. Unfortunately, if the strings are long, there is no space to store them completely in each node, and if pointers to strings are used, the number of I/Os per node access will be large. Ferragina and Grossi <ref> [48, 49] </ref> develop an elegant generalization of the B-tree, called the SB-tree, for storing strings. The key problem they address is how to represent a single node that does B-way branching.
Reference: [49] <author> P. Ferragina and R. Grossi. </author> <title> Fast string searching in secondary storage: Theoretical developments and experimental results. </title> <booktitle> In Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> 373-382, </pages> <address> Atlanta, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: In EM applications, what is needed is a multiway digital structure. Unfortunately, if the strings are long, there is no space to store them completely in each node, and if pointers to strings are used, the number of I/Os per node access will be large. Ferragina and Grossi <ref> [48, 49] </ref> develop an elegant generalization of the B-tree, called the SB-tree, for storing strings. The key problem they address is how to represent a single node that does B-way branching.
Reference: [50] <author> R. W. Floyd. </author> <title> Permuting information in idealized two-level storage. </title> <editor> In R. Miller and J. Thatcher, editors, </editor> <booktitle> Complexity of Computer Computations, </booktitle> <pages> 105-109. </pages> <publisher> Plenum, </publisher> <year> 1972. </year>
Reference-contexts: In the early 1970s, Knuth [71] did an extensive study of sorting using magnetic tapes and (to a lesser extent) magnetic disks. At about the same time, Floyd <ref> [50, 71] </ref> considered a disk model akin to PDM for D = 1, P = 1, B = M=2 = fi (N c ), for constant c &gt; 0, and developed optimal upper and lower I/O bounds for sorting and matrix transposition.
Reference: [51] <author> V. Gaede and O. Gunther. </author> <title> Multidimensional access methods. </title> <journal> Computing Surveys, </journal> <note> 1998. to appear. </note>
Reference-contexts: In that case, the search must proceed to all such children. Several heuristics for where to insert new items into the R-tree and how to rebalance are surveyed in <ref> [51, 55] </ref>. The R*-tree of Beckmann et al. [25] seems to give best overall query performance. Constructing an R*-tree by repeated insertions, however, is extremely slow. A faster alternative is to use the Hilbert R-tree of Kamel and Faloutsos [64, 65].
Reference: [52] <author> M. Gardner. </author> <title> Magic Show, chapter 7. </title> <address> Knopf, New York, </address> <year> 1977. </year>
Reference-contexts: A perfect solution, in which the next D blocks needed for the merge are guaranteed to be on distinct disks, can be devised for the binary merging case R = 2 based upon the Gilbreath principle <ref> [52, 71] </ref>: The first run is striped in ascending order by disk number, and the other run is striped in descending order. The next 10 JEFFREY SCOTT VITTER D = 5 D = 10 D = 50 k = 10 0:61 0:52 0:40 Table 1.
Reference: [53] <author> G. A. Gibson, J. S. Vitter, and J. Wilkes. </author> <title> Report of the working group on storage I/O issues in large-scale computing. </title> <journal> ACM Computing Surveys, </journal> <volume> 28(4), </volume> <month> December </month> <year> 1996. </year> <note> Also available as http://www.cs.duke.edu/~jsv/SDCR96-IO/report.ps. </note>
Reference-contexts: The TPIE External Memory Programming Environment There are three basic approaches to supporting development of I/O-efficient code, which we call array-oriented systems (such as PASSION and ViC*), access-oriented systems (such as the UNIX file system, Panda, and MPI-IO), and framework-oriented systems (such as TPIE). We refer the reader to <ref> [53] </ref> for background. 22 JEFFREY SCOTT VITTER In this section we describe TPIE (Transparent Parallel I/O programming Environment) 3 [106, 108], which is used as the implementation platform for the experiments in the next section.
Reference: [54] <author> M. T. Goodrich, J.-J. Tsay, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory computational geometry. </title> <booktitle> In IEEE Foundations of Computer Science, </booktitle> <pages> 714-723, </pages> <year> 1993. </year>
Reference-contexts: Computing the measure of the union of N orthogonal rectangles, 11. Computing the visibility of N segments from a point, 12. Performing Q ray-shooting queries in CSG models of size N , EXTERNAL MEMORY ALGORITHMS (DRAFT, June 18, 1998) 15 Goodrich et al. <ref> [54] </ref>, Arge et al. [18], Arge et al. [17], and Crauser et al. [39] develop EM algorithms for these problems using the following EM paradigms for batched problems: Distribution sweeping: a generalization of the distribution paradigm of Sec tion 2 for externalizing plane sweep algorithms; Persistent B-trees: an o*ine method for
Reference: [55] <author> D. Greene. </author> <title> An implementation and performance analysis of spatial data access methods. </title> <booktitle> In Proceedings of the IEEE International Conference on Data Engineering, </booktitle> <pages> 606-615, </pages> <year> 1989. </year> <title> EXTERNAL MEMORY ALGORITHMS (DRAFT, </title> <address> June 18, </address> <year> 1998) </year> <month> 29 </month>
Reference-contexts: In that case, the search must proceed to all such children. Several heuristics for where to insert new items into the R-tree and how to rebalance are surveyed in <ref> [51, 55] </ref>. The R*-tree of Beckmann et al. [25] seems to give best overall query performance. Constructing an R*-tree by repeated insertions, however, is extremely slow. A faster alternative is to use the Hilbert R-tree of Kamel and Faloutsos [64, 65].
Reference: [56] <author> R. Grossi and G. F. </author> <title> Italiano. Efficient splitting and merging algorithms for order decomposable problems. </title> <booktitle> In 24th International Colloquium on Automata, Languages and Programming, volume 1256 of Lecture Notes in Computer Science, </booktitle> <pages> 605-615, </pages> <address> Bologna, Italy, </address> <month> July </month> <year> 1997. </year>
Reference-contexts: That assumption can be removed by use of the buffer tree data structure [9] (see Section 7.2). A practical, randomized implementation of list ranking appears in [96]. Recent work on other EM graph algorithms appears in <ref> [1, 10, 73, 56] </ref>. The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. Constructing classification trees in external memory for data mining is discussed in [113]. <p> Weight-balanced B-trees were originally developed as part of an optimal dynamic data structure for stabbing queries and segment trees, but they can also be used to get improvements for algorithms developed in the RAM model <ref> [19, 56] </ref>. For example, by setting a to a constant, we get a simple, worst-case implementation of interval trees. They also serve as a simpler and worst-case alternative to the data structure in [114] for augmenting one-dimensional data structures with range restriction capabilities.
Reference: [57] <author> R. Grossi and G. F. </author> <title> Italiano. Efficient cross-trees for external memory. </title> <editor> In J. Abello and J. S. Vitter, editors, </editor> <title> External Memory Algorithms and Visualization, DIMACS series. </title> <publisher> American Mathematical Society, </publisher> <year> 1998. </year>
Reference-contexts: For example, by setting a to a constant, we get a simple, worst-case implementation of interval trees. They also serve as a simpler and worst-case alternative to the data structure in [114] for augmenting one-dimensional data structures with range restriction capabilities. Grossi and Italiano <ref> [57] </ref> develop a multidimensional version of B-trees, called cross trees, that combine the data-driven partitioning of B-trees at the upper levels of the tree with the space-driven partitioning of methods like quad trees at the lower levels of the tree. <p> data structure is restricted to contain only a single copy of each item, Kanth and Sing [69] show for a restricted class of index-based trees that range queries in the worst case require (n 11=d + z) I/Os; a matching upper bound is provided by the cross tree data structure <ref> [57] </ref> of Section 7.1. Fundamentally different techniques are needed for higher dimensions and for non-orthogonal queries. Vengroff and Vitter [107] use a partitioning approach and compressed representation to get the first EM algorithms for three-dimensional range searching that are within a polylog factor of optimal.
Reference: [58] <author> S. K. S. Gupta, Z. Li, and J. H. Reif. </author> <title> Generating efficient programs for two-level memories from tensor-products. </title> <booktitle> In Proceedings of the Seventh IASTED/ISMM International Conference on Parallel and Distributed Computing and Systems, </booktitle> <pages> 510-513, </pages> <address> Washington, D.C., </address> <month> October </month> <year> 1995. </year>
Reference-contexts: Gupta et al. <ref> [58] </ref> show how to derive efficient EM algorithms automatically for computations expressed in tensor form.
Reference: [59] <author> A. Guttman. R-trees: </author> <title> A dynamic index structure for spatial searching. </title> <booktitle> In Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <pages> 47-57, </pages> <year> 1985. </year>
Reference-contexts: Brodal and Kata-jainen [27] develop a worst-case optimal priority queue, in the sense that every sequence of B insert and delete min operations requires only O (log m n) I/Os. 7.3. R-trees. The R-tree of Guttman <ref> [59] </ref> and its many variants are an elegant generalization of the B-tree for storing geometric objects. Internal nodes have degree fi (B) and leaves store fi (B) items. Each node in the tree has associated with it a bounding box (or bounding polygon) of all the elements in its subtree.
Reference: [60] <author> J. M. Hellerstein, E. Koutsoupias, and C. H. Papadimitriou. </author> <title> On the analysis of indexing schemes. </title> <booktitle> In Proceedings of the 16th ACM Symposium on Principles of Database Systems, </booktitle> <pages> 249-256, </pages> <address> Tucson, Arizona, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: Hellerstein et al. <ref> [60] </ref> consider a generalization of the layout-based lower bound argument of Kanellakis et al. [68] for studying the tradeoff between disk space overhead and query performance; the model does not distinguish, however, between query complexity and output complexity. Further results in the latter model appear in [72, 92].
Reference: [61] <author> L. Hellerstein, G. Gibson, R. M. Karp, R. H. Katz, and D. A. Patterson. </author> <title> Coding techniques for handling failures in large disk arrays. </title> <journal> Algorithmica, </journal> <pages> 12(2-3), 182-208, </pages> <year> 1994. </year>
Reference-contexts: In fact the access gap is growing, since the speed of memory chips is increasing more quickly than disk bandwidth and disk latency. The use of parallel processors further widens the gap. Storage systems such as RAID are being developed that use multiple disks to get more bandwidth <ref> [30, 61] </ref>. <p> All the methods we discuss, with the exception of Greed Sort in Section 2.2, use the disks independently for parallel read operations, but parallel writes are done in a striped manner, which facilitates the writing of parity error correction information <ref> [30, 61] </ref>. The lower bounds are discussed in Section 3. 2.1. Sorting by Distribution: Simultaneous Online Load Balancings. Distribution sort is a recursive process in which the data items to be sorted are partitioned by a set of S 1 partitioning elements into S buckets.
Reference: [62] <author> J. W. Hong and H. T. Kung. </author> <title> I/O complexity: The red-blue pebble game. </title> <booktitle> Proceedings of the 13th Annual ACM Symposium on Theory of Computation, </booktitle> <pages> 326-333, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: Hong and Kung <ref> [62] </ref> developed a pebbling model of I/O for straightline computations, and Savage and Vitter [93] extended the model to deal with block transfer. <p> The number of I/Os required to multiply two k fi k matrices or to compute the LU factorization of a k fi k matrix is fi k 3 = minfk; p Hong and Kung <ref> [62] </ref> and Nodine et al. [82] give optimal EM algorithms for iterative grid computations, and Leiserson et al. [76] show how to reduce the number of I/Os of naive multigrid implementations by a fi (M 1=5 ) factor.
Reference: [63] <author> D. Hutchinson, A. Maheshwari, J.-R. Sack, and R. Velicescu. </author> <title> Early experiences in implementing the buffer tree. </title> <booktitle> Workshop on Algorithm Engineering, </booktitle> <year> 1997. </year> <note> Electronic proceedings available at http://www.dsi.unive.it/~wae97/proceedings/. </note>
Reference-contexts: Empirical Comparisons In this section we examine the empirical performance of algorithms for two problems that arise in spatial databases. The TPIE system described in the previous section is used as the common implementation platform. Other recent experiments involving the paradigms discussed in this paper appear in <ref> [32, 63] </ref>. 11.1. Rectangle Intersection and Spatial Join. In the first experiment, three algorithms are implemented in TPIE for the problem of rectangle intersection, which is often the first step in a spatial join computation.
Reference: [64] <author> I. Kamel and C. Faloutsos. </author> <title> On packing R-trees. </title> <booktitle> In Proceedings of the 2nd International Conference on Information and Knowledge Management (CIKM), </booktitle> <pages> 490-499, </pages> <year> 1993. </year>
Reference-contexts: The R*-tree of Beckmann et al. [25] seems to give best overall query performance. Constructing an R*-tree by repeated insertions, however, is extremely slow. A faster alternative is to use the Hilbert R-tree of Kamel and Faloutsos <ref> [64, 65] </ref>. Each item is labeled with the position of its center on the Hilbert space-filling curve, and a B-tree is built on the totally ordered labels.
Reference: [65] <author> I. Kamel and C. Faloutsos. Hilbert R-tree: </author> <title> An improved R-tree using fractals. </title> <booktitle> In Proceedings of the 20th International Conference on Very Large Databases, </booktitle> <pages> 500-509, </pages> <year> 1994. </year>
Reference-contexts: The R*-tree of Beckmann et al. [25] seems to give best overall query performance. Constructing an R*-tree by repeated insertions, however, is extremely slow. A faster alternative is to use the Hilbert R-tree of Kamel and Faloutsos <ref> [64, 65] </ref>. Each item is labeled with the position of its center on the Hilbert space-filling curve, and a B-tree is built on the totally ordered labels.
Reference: [66] <author> I. Kamel, M. Khalil, and V. Kouramajian. </author> <title> Bulk insertion in dynamic R-trees. </title> <booktitle> In Proceedings of the 4th International Symposium on Spatial Data Handling, </booktitle> <volume> 3B, </volume> <pages> 31-42, </pages> <year> 1996. </year>
Reference-contexts: Bulk loading a Hilbert R-tree is therefore easy once the center points are presorted, but the quality of the Hilbert R-tree in terms of query performance is not as good as that of an R*-tree, especially for higher-dimensional data <ref> [26, 66] </ref>. Arge et al. [13] and Bercken et al. [103] have independently devised fast bulk loading methods for R*-trees that are based upon buffer trees. The former method is especially efficient and can even support dynamic batched updates and queries. <p> The three methods tested are a newly developed buffer R-tree method [13] (labeled "buffer"), the naive sequential method for construction into R*-trees (labeled "naive"), and the best update algorithm for Hilbert R-trees (labeled "Hilbert") <ref> [66] </ref>. The experimental data came from TIGER/line road data sets from four U.S. states. One experiment involved building an R-tree on the road data for each state and for each of four possible buffer sizes. The four buffer sizes were capable of storing 0, 600, 1,250, and 5,000 rectangles, respectively.
Reference: [67] <author> P. C. Kanellakis, G. M. Kuper, and P. Z. Revesz. </author> <title> Constraint query languages. </title> <booktitle> Proceedings of the 9th ACM Conference on Principles of Database Systems, </booktitle> <pages> 299-313, </pages> <year> 1990. </year>
Reference-contexts: Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases [74, 90, 91], geographic information systems (GIS) [74, 90, 104], constraint logic programming <ref> [67, 68] </ref>, object-oriented databases [117], statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year. A major challenge is to develop mechanisms for processing the data, or else much of it will be wasted.
Reference: [68] <author> P. C. Kanellakis, S. Ramaswamy, D. E. Vengroff, and J. S. Vitter. </author> <title> Indexing for data models with constraints and classes. </title> <booktitle> In Proceedings of the ACM Symposium on Principles of Database Systems, </booktitle> <pages> 233-243, </pages> <year> 1993. </year> <note> To appear in a special issue of Journ. Comput. Sys. Science. </note>
Reference-contexts: Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases [74, 90, 91], geographic information systems (GIS) [74, 90, 104], constraint logic programming <ref> [67, 68] </ref>, object-oriented databases [117], statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year. A major challenge is to develop mechanisms for processing the data, or else much of it will be wasted. <p> Experiments with this technique are discussed in Section 11. 8. Range Searching Multidimensional range search is a fundamental primitive in several large geometric applications and it provides indexing support for new constraint data models and object-oriented data models. (See <ref> [68] </ref> for background.) In d-dimensional space, we define a (s 1 ; s 2 ; : : : ; s d )-sided range query, where each s i 2 f1; 2g, to be an orthogonal range query with s i sides in the x i dimension. <p> In the two-dimensional cases studied in <ref> [68, 87, 98] </ref>, the authors use the terms "two-sided," "three-sided," and "four-sided" range query to mean what we call (1; 1)-sided, (2; 1)-sided, and (2; 2)-sided queries, respectively. <p> Arge and Vitter [19] design an interval tree based upon the weight-balanced B-tree that meets all four goals. It solves the problems of stabbing queries and dynamic interval management following up on earlier work by Kanellakis et al. <ref> [68] </ref>. Stabbing queries are equivalent to (1; 1)-sided range queries where the corner point is on the diagonal. The EM interval tree is used by [33] to extract at query time the boundary components of the isosurface (or contour) of a surface. <p> Hellerstein et al. [60] consider a generalization of the layout-based lower bound argument of Kanellakis et al. <ref> [68] </ref> for studying the tradeoff between disk space overhead and query performance; the model does not distinguish, however, between query complexity and output complexity. Further results in the latter model appear in [72, 92].
Reference: [69] <author> K. V. R. Kanth and A. K. </author> <title> Sing. Optimal dynamic range searching in non-replicating index structures. </title> <type> Technical Report CS97-13, </type> <institution> University of California at Santa Barbara, </institution> <month> July </month> <year> 1997. </year>
Reference-contexts: Further results in the latter model appear in [72, 92]. When the data structure is restricted to contain only a single copy of each item, Kanth and Sing <ref> [69] </ref> show for a restricted class of index-based trees that range queries in the worst case require (n 11=d + z) I/Os; a matching upper bound is provided by the cross tree data structure [57] of Section 7.1. Fundamentally different techniques are needed for higher dimensions and for non-orthogonal queries.
Reference: [70] <author> D. G. Kirkpatrick and R. Seidel. </author> <title> The ultimate planar convex hull algorithm? SIAM Journal on Computing, </title> <booktitle> 15, </booktitle> <pages> 287-299, </pages> <year> 1986. </year>
Reference-contexts: Online filtering: a technique based upon the work of Tamassia and Vitter [99] for online queries in data structures with fractional cascading. External marriage-before-conquest : an EM analog to the well-known technique of Kirkpatrick and Seidel <ref> [70] </ref> for performing output-sensitive convex hull constructions. Randomized incremental construction with gradations: a localized version of the incremental construction paradigm of Clarkson and Shor [35]. The distribution sweep paradigm is fundamental to sweep line processes.
Reference: [71] <author> D. E. Knuth. </author> <title> Sorting and Searching, </title> <booktitle> volume 3 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading MA, </address> <note> second edition, </note> <year> 1998. </year>
Reference-contexts: The bottom line is that programs that perform well in terms of PDM will generally perform well when implemented on real systems. The study of the complexity of algorithms using external memory devices began more than 40 years ago with Demuth's Ph.D. thesis on sorting <ref> [42, 71] </ref>. In the early 1970s, Knuth [71] did an extensive study of sorting using magnetic tapes and (to a lesser extent) magnetic disks. <p> The study of the complexity of algorithms using external memory devices began more than 40 years ago with Demuth's Ph.D. thesis on sorting [42, 71]. In the early 1970s, Knuth <ref> [71] </ref> did an extensive study of sorting using magnetic tapes and (to a lesser extent) magnetic disks. <p> In the early 1970s, Knuth [71] did an extensive study of sorting using magnetic tapes and (to a lesser extent) magnetic disks. At about the same time, Floyd <ref> [50, 71] </ref> considered a disk model akin to PDM for D = 1, P = 1, B = M=2 = fi (N c ), for constant c &gt; 0, and developed optimal upper and lower I/O bounds for sorting and matrix transposition. <p> In Section 13 we give some final remarks and discuss some ongoing work. 2. External Sorting and Related Problems The problem of sorting is a central problem in the field of external memory algorithms, partly because sorting and sorting-like operations account for a significant percentage of computer use <ref> [71] </ref>, and also because sorting is an important paradigm in the design of efficient EM algorithms. <p> At the end of the run formation phase, there are N=M = n=m (sorted) runs, each striped across the disks. (In actual implementations, the "replacement-selection" technique can be used to get runs of 2M data items, on the average, when M B <ref> [71] </ref>.) After the initial runs are formed, the merging phase begins. In each pass of the merging phase, groups of R runs are merged together. During each merge, one block from each run resides in internal memory. <p> A perfect solution, in which the next D blocks needed for the merge are guaranteed to be on distinct disks, can be devised for the binary merging case R = 2 based upon the Gilbreath principle <ref> [52, 71] </ref>: The first run is striped in ascending order by disk number, and the other run is striped in descending order. The next 10 JEFFREY SCOTT VITTER D = 5 D = 10 D = 50 k = 10 0:61 0:52 0:40 Table 1. <p> To guarantee even distribution during the merging, it employs two high-level merging schemes in which the scheduling is almost oblivious. The most practical method for sorting is the simple randomized merge sort (SRM) algorithm of Barve et al. [21] (referred to as "randomized striping" by Knuth <ref> [71] </ref>). <p> Barve et al. [21] derive an upper bound on the I/O performance; the precise analysis is an interesting open problem <ref> [71] </ref>. 2.3. Permuting and Transposition. Permuting is the special case of sorting in which the key values of the N data items form a permutation of f1, 2, : : : , N g. EXTERNAL MEMORY ALGORITHMS (DRAFT, June 18, 1998) 11 Theorem 2.2 ([7]). <p> A tree of degree B c , for fixed c &gt; 0, with n leaf nodes has height dc log B ne. The well-known B-tree due to Bayer and McCreight <ref> [23, 71] </ref> is a balanced multiway tree with height ~ log B n in which each node has degree fi (B). It supports dynamic dictionary operations and one-dimensional range queries in O (log B n + t) I/Os per operation.
Reference: [72] <author> E. Koutsoupias and D. S. Taylor. </author> <title> Tight bounds for 2-dimensional indexing schemes. </title> <booktitle> In Proceedings of the 17th ACM Symposium on Principles of Database Systems, </booktitle> <address> Seattle, Wash-ington, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: Hellerstein et al. [60] consider a generalization of the layout-based lower bound argument of Kanellakis et al. [68] for studying the tradeoff between disk space overhead and query performance; the model does not distinguish, however, between query complexity and output complexity. Further results in the latter model appear in <ref> [72, 92] </ref>.
Reference: [73] <author> V. Kumar and E. Schwabe. </author> <title> Improved algorithms and data structures for solving graph problems in external memory. </title> <booktitle> In Proceedings of the 8th IEEE Symposium on Parallel and Distributed Processing, </booktitle> <pages> 169-176, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: That assumption can be removed by use of the buffer tree data structure [9] (see Section 7.2). A practical, randomized implementation of list ranking appears in [96]. Recent work on other EM graph algorithms appears in <ref> [1, 10, 73, 56] </ref>. The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. Constructing classification trees in external memory for data mining is discussed in [113].
Reference: [74] <author> R. Laurini and D. Thompson. </author> <title> Fundamentals of Spatial Information Systems. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: The reader is referred to [36, 78, 89, 101, 100, 108, 110] for further study of EM matrix algorithms. 5. Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases <ref> [74, 90, 91] </ref>, geographic information systems (GIS) [74, 90, 104], constraint logic programming [67, 68], object-oriented databases [117], statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year. <p> The reader is referred to [36, 78, 89, 101, 100, 108, 110] for further study of EM matrix algorithms. 5. Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases [74, 90, 91], geographic information systems (GIS) <ref> [74, 90, 104] </ref>, constraint logic programming [67, 68], object-oriented databases [117], statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year.
Reference: [75] <author> T. Leighton. </author> <title> Tight bounds on the complexity of parallel sorting. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(4), </volume> <pages> 344-354, </pages> <month> April </month> <year> 1985. </year> <note> Special issue on sorting, </note> <author> E. E. Lindstrom and C. K. Wong and J. S. Vitter, </author> <title> editors. </title>
Reference-contexts: The resulting run that is produced is only an "approximately" merged run, but its saving grace is that no two inverted items are too far apart. A final application of Columnsort <ref> [75] </ref> in conjunction with partial striping suffices to restore total order. An optimal deterministic merge sort, with somewhat higher constant factors than those of the distribution sort algorithms, was developed by Aggarwal and Plax-ton [6], based upon the Sharesort hypercube sorting algorithm [40].
Reference: [76] <author> C. E. Leiserson, S. Rao, and S. Toledo. </author> <title> Efficient out-of-core algorithms for linear relaxation using blocking covers. </title> <booktitle> In IEEE Foundations of Comp. Sci., </booktitle> <pages> 704-713, </pages> <year> 1993. </year>
Reference-contexts: of I/Os required to multiply two k fi k matrices or to compute the LU factorization of a k fi k matrix is fi k 3 = minfk; p Hong and Kung [62] and Nodine et al. [82] give optimal EM algorithms for iterative grid computations, and Leiserson et al. <ref> [76] </ref> show how to reduce the number of I/Os of naive multigrid implementations by a fi (M 1=5 ) factor. Gupta et al. [58] show how to derive efficient EM algorithms automatically for computations expressed in tensor form.
Reference: [77] <author> Z. Li, P. H. Mills, and J. H. Reif. </author> <title> Models and resource metrics for parallel and distributed computation. </title> <booktitle> Parallel Algorithms and Applications, </booktitle> <volume> 8, </volume> <pages> 35-59, </pages> <year> 1996. </year>
Reference-contexts: Since the PDM model can be thought of as a more restrictive (and more realistic) version of their model, their lower bounds apply as well to PDM. Modified versions of PDM that integrate various aspects of parallel computation are developed in <ref> [41, 77] </ref>. Surveys of various aspects of I/O models and algorithms appear in [11, 95].
Reference: [78] <author> J. W. H. Liu. </author> <title> On the storage requirement in the out-of-core multifrontal method for sparse factorization. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 12(3), </volume> <pages> 249-264, </pages> <month> Sept. </month> <year> 1986. </year> <note> 30 JEFFREY SCOTT VITTER </note>
Reference-contexts: If the ith key in the input of the sorting instance has key value x 6= 0, there is a nonzero matrix element in position (x; i). The reader is referred to <ref> [36, 78, 89, 101, 100, 108, 110] </ref> for further study of EM matrix algorithms. 5.
Reference: [79] <author> D. B. Lomet and B. Salzberg. </author> <title> Concurrency and recovery for index trees. </title> <journal> The VLDB Journal, </journal> <volume> 6(3), </volume> <pages> 224-240, </pages> <year> 1997. </year>
Reference-contexts: It supports dynamic dictionary operations and one-dimensional range queries in O (log B n + t) I/Os per operation. Persistent versions of B-trees have been developed by Becker et al. [24] and Varman and Verma [105]. Lomet and Salzberg <ref> [79] </ref> explore mechanisms to add concurrency and recovery to B-trees.
Reference: [80] <author> J. Nievergelt and P. Widmayer. </author> <title> Spatial data structures: Concepts and design choices. </title> <editor> In M. van Kreveld, J. Nievergelt, T. Roos, and P. Widmayer, editors, </editor> <title> Algorithmic Foundations of GIS. </title> <publisher> Springer-Verlag, LNCS 1340, </publisher> <year> 1997. </year>
Reference-contexts: Callahan et al. [28] develop a dynamic EM data structure for use in several online problems such as finding an approximately nearest neighbor and maintaining the closest pair of vertices. Numerous other data structures have been developed for range queries and related problems on spatial data. We refer to <ref> [5, 80] </ref> for a survey. 9. String Processing Digital trie-based structures, in which branching decisions at each node are made based upon the values of particular bits in strings, are effective for string processing in internal memory. In EM applications, what is needed is a multiway digital structure.
Reference: [81] <author> M. H. Nodine, M. T. Goodrich, and J. S. Vitter. </author> <title> Blocking for external graph searching. </title> <journal> Algorithmica, </journal> <volume> 16(2), </volume> <pages> 181-214, </pages> <month> August </month> <year> 1996. </year>
Reference-contexts: A practical, randomized implementation of list ranking appears in [96]. Recent work on other EM graph algorithms appears in [1, 10, 73, 56]. The problem of how to store graphs on disks for efficient traversal is discussed in <ref> [81, 4] </ref>. Constructing classification trees in external memory for data mining is discussed in [113]. The I/O complexity of several of the basic graph problems considered in [31, 102] remain open, including connectivity, topological sorting, shortest paths, breadth-first search, and depth-first search.
Reference: [82] <author> M. H. Nodine, D. P. Lopresti, and J. S. Vitter. </author> <title> I/O overhead and parallel vlsi architectures for lattice computations. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 40(7), </volume> <pages> 843-852, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: The number of I/Os required to multiply two k fi k matrices or to compute the LU factorization of a k fi k matrix is fi k 3 = minfk; p Hong and Kung [62] and Nodine et al. <ref> [82] </ref> give optimal EM algorithms for iterative grid computations, and Leiserson et al. [76] show how to reduce the number of I/Os of naive multigrid implementations by a fi (M 1=5 ) factor.
Reference: [83] <author> M. H. Nodine and J. S. Vitter. </author> <title> Deterministic distribution sort in shared and distributed memory multiprocessors. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> 120-129, </pages> <month> June-July </month> <year> 1993. </year>
Reference-contexts: It seems difficult to find S = fi (m) partitioning elements using fi (n=D) I/Os and guarantee that the bucket sizes are within a constant factor of one another. But efficient deterministic methods exist for choosing S = p m partitioning elements <ref> [83, 111] </ref>, which has the effect of doubling the number of levels of recursion. Probabilistic methods based upon random sampling can be found in [47]. <p> The buckets are sorted individually in the second pass. An even better way to do distribution sort, and deterministically at that, is the BalanceSort method developed by Nodine and Vitter <ref> [83] </ref>. During the partitioning process, the algorithm tracks how evenly each bucket has been distributed so far among the disks.
Reference: [84] <author> M. H. Nodine and J. S. Vitter. </author> <title> Greed Sort: An optimal sorting algorithm for multiple disks. </title> <journal> Journal of the ACM, </journal> <volume> 42(4), </volume> <pages> 919-933, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: Unfortunately there is no analog to the Gilbreath principle for R &gt; 2, and as we have seen above it is necessary to use a large value of R in order to get an optimal sorting algorithm. The Greed Sort method of Nodine and Vitter <ref> [84] </ref> was the first optimal deterministic EM algorithm for sorting with multiple disks. It handles the case R &gt; 2 by relaxing the condition on the merging process.
Reference: [85] <author> H. Pang, M. Carey, and M. Livny. </author> <title> Memory-adaptive external sorts. </title> <booktitle> Proceedings of the 19th Conference on Very Large Data Bases, </booktitle> <year> 1993. </year>
Reference-contexts: Dynamic Memory Allocation The amount of memory allocated to a program may fluctuate during the course of execution because of demands placed on the system by other users and processes. EM algorithms must be able to adapt dynamically to whatever resources are available so as to preserve good performance <ref> [85] </ref>. The algorithms in the previous sections assume a fixed memory allocation; they must make use of virtual memory if the memory allocation is reduced, often causing a severe performance hit. Barve and Vitter [22] discuss the design and analysis of EM algorithms that adapt gracefully to changing memory allocations. <p> Barve and Vitter define the model in generality and give dynamically optimal strategies for sorting, matrix multiplication, and buffer trees operations. Their work represents the first theoretical model of dynamic allocation for EM algorithms. 26 JEFFREY SCOTT VITTER Pang et al. <ref> [85] </ref> and Zhang and Larson [118] give memory-adaptive merge sort algorithms, but their algorithms handle only special cases and can be made to perform poorly for certain patterns of memory allocation. 13.
Reference: [86] <author> J. M. Patel and D. J. DeWitt. </author> <title> Partition based spatial-merge join. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, volume 25, 2 of ACM SIGMOD Record, </booktitle> <pages> 259-270, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: The first method, called Scalable Sweeping-Based Spatial Join (SSSJ) [16], is a robust new algorithm based upon the distribution sweep paradigm of Section 5. The other two methods are Partition-Based Spatial-Merge (QPBSM) used in Paradise <ref> [86] </ref> and a new modification called MPBSM that uses an improved dynamic data structure for intervals [16]. The algorithms were tested on several data sets. The timing results for the two data sets in Figures 5 (a) and 5 (b) are given in Figures 5 (c) and 5 (d), respectively.
Reference: [87] <author> S. Ramaswamy and S. Subramanian. </author> <title> Path caching: a technique for optimal external searching. </title> <booktitle> Proceedings of the 13th ACM Conference on Principles of Database Systems, </booktitle> <year> 1994. </year>
Reference-contexts: In the two-dimensional cases studied in <ref> [68, 87, 98] </ref>, the authors use the terms "two-sided," "three-sided," and "four-sided" range query to mean what we call (1; 1)-sided, (2; 1)-sided, and (2; 2)-sided queries, respectively. <p> The EM interval tree is used by [33] to extract at query time the boundary components of the isosurface (or contour) of a surface. A data structure for a related problem, which in addition has optimal output complexity, appears in [4]. Ramaswamy and Subramanian <ref> [87] </ref> introduce the notion of path caching to develop EM algorithms for (1; 1)-sided and (2; 1)-sided 2-D range queries. Their algorithms are optimal in criteria 1 and 2 but with higher storage overheads and amortized and/or nonoptimal update bounds.
Reference: [88] <author> C. Ruemmler and J. Wilkes. </author> <title> An introduction to disk drive modeling. </title> <booktitle> IEEE Computer, </booktitle> <pages> 17-28, </pages> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: PDM is a good generic programming model that facilitates the design of I/O-efficient algorithms, especially when used in conjunction with the programming tools discussed in Section 10. More complex and precise disk models have been developed, such as the ones by Ruemmler and Wilkes <ref> [88] </ref>, Shriver et al. [94], and Barve et al. [20], which distinguish between sequential reads and random reads and consider the effects on throughput of features such as disk buffer caches and shared buses, which can reduce the time per I/O by eliminating or hiding the seek time, In practice, the
Reference: [89] <author> J. Salmon and M. Warren. </author> <title> Parallel out-of-core methods for N-body simulation. </title> <booktitle> In Proceedings of the Eighth SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <year> 1997. </year>
Reference-contexts: If the ith key in the input of the sorting instance has key value x 6= 0, there is a nonzero matrix element in position (x; i). The reader is referred to <ref> [36, 78, 89, 101, 100, 108, 110] </ref> for further study of EM matrix algorithms. 5.
Reference: [90] <author> H. Samet. </author> <title> Applications of Spatial Data Structures: Computer Graphics, Image Processing, and GIS. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The reader is referred to [36, 78, 89, 101, 100, 108, 110] for further study of EM matrix algorithms. 5. Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases <ref> [74, 90, 91] </ref>, geographic information systems (GIS) [74, 90, 104], constraint logic programming [67, 68], object-oriented databases [117], statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year. <p> The reader is referred to [36, 78, 89, 101, 100, 108, 110] for further study of EM matrix algorithms. 5. Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases [74, 90, 91], geographic information systems (GIS) <ref> [74, 90, 104] </ref>, constraint logic programming [67, 68], object-oriented databases [117], statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year. <p> Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases [74, 90, 91], geographic information systems (GIS) [74, 90, 104], constraint logic programming [67, 68], object-oriented databases [117], statistics, virtual reality systems, and computer graphics <ref> [90] </ref>. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year. A major challenge is to develop mechanisms for processing the data, or else much of it will be wasted.
Reference: [91] <author> H. Samet. </author> <title> The Design and Analysis of Spatial Data Structures. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: The reader is referred to [36, 78, 89, 101, 100, 108, 110] for further study of EM matrix algorithms. 5. Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases <ref> [74, 90, 91] </ref>, geographic information systems (GIS) [74, 90, 104], constraint logic programming [67, 68], object-oriented databases [117], statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year.
Reference: [92] <author> V. Samoldas and D. Miranker. </author> <title> A lower bound theorem for indexing schemes and its application to multidimensional range queries. </title> <booktitle> In Proc. 17th ACM Conf. on Princ. of Database Systems, </booktitle> <address> Seattle, WA, </address> <month> June </month> <year> 1998. </year>
Reference-contexts: Hellerstein et al. [60] consider a generalization of the layout-based lower bound argument of Kanellakis et al. [68] for studying the tradeoff between disk space overhead and query performance; the model does not distinguish, however, between query complexity and output complexity. Further results in the latter model appear in <ref> [72, 92] </ref>.
Reference: [93] <author> J. E. Savage and J. S. Vitter. </author> <title> Parallelism in space-time tradeoffs. </title> <editor> In F. P. Preparata, editor, </editor> <booktitle> Advances in Computing Research, </booktitle> <volume> Volume 4, </volume> <pages> 117-146. </pages> <publisher> JAI Press, </publisher> <year> 1987. </year>
Reference-contexts: Hong and Kung [62] developed a pebbling model of I/O for straightline computations, and Savage and Vitter <ref> [93] </ref> extended the model to deal with block transfer. Aggarwal and Vitter [7] generalized Floyd's I/O model to allow simultaneous block transfers, but the model was unrealistic in that the simultaneous transfers were allowed to take place on a single disk.
Reference: [94] <author> E. Shriver, A. Merchant, and J. Wilkes. </author> <title> An analytic behavior model for disk drives with readahead caches and request reordering. </title> <booktitle> In Joint International Conference on Measurement and Modeling of Computer Systems, </booktitle> <month> June </month> <year> 1998. </year>
Reference-contexts: PDM is a good generic programming model that facilitates the design of I/O-efficient algorithms, especially when used in conjunction with the programming tools discussed in Section 10. More complex and precise disk models have been developed, such as the ones by Ruemmler and Wilkes [88], Shriver et al. <ref> [94] </ref>, and Barve et al. [20], which distinguish between sequential reads and random reads and consider the effects on throughput of features such as disk buffer caches and shared buses, which can reduce the time per I/O by eliminating or hiding the seek time, In practice, the effects of more complex
Reference: [95] <author> E. A. M. Shriver and M. H. Nodine. </author> <title> An introduction to parallel I/O models and algorithms. </title> <editor> In R. Jain, J. Werth, and J. C. Browne, editors, </editor> <booktitle> Input/Output in Parallel and Distributed Computer Systems, chapter 2, </booktitle> <pages> 31-68. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1996. </year>
Reference-contexts: Modified versions of PDM that integrate various aspects of parallel computation are developed in [41, 77]. Surveys of various aspects of I/O models and algorithms appear in <ref> [11, 95] </ref>. The same type of bottleneck that occurs between internal memory and external disk storage can also occur at other levels of the memory hierarchy, such as between data cache and level 2 cache, or between level 2 cache and DRAM, or between disk storage and tertiary devices.
Reference: [96] <author> J. F. Sibeyn. </author> <title> From parallel to external list ranking. </title> <type> Technical Report MPI-I-97-1-021, </type> <institution> Max-Planck-Institut, </institution> <month> Sept. </month> <year> 1997. </year>
Reference-contexts: That assumption can be removed by use of the buffer tree data structure [9] (see Section 7.2). A practical, randomized implementation of list ranking appears in <ref> [96] </ref>. Recent work on other EM graph algorithms appears in [1, 10, 73, 56]. The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. Constructing classification trees in external memory for data mining is discussed in [113].
Reference: [97] <author> J. F. Sibeyn and M. Kaufmann. </author> <title> BSP-like external-memory computation. </title> <booktitle> In Proceedings of the 3rd Italian Conference on Algorithms and Complexity, </booktitle> <pages> 229-240, </pages> <year> 1997. </year>
Reference-contexts: the number of working processors in the parallel algorithm decreases geometrically with time, so the number of I/Os for the entire simulation is proportional to the number of I/Os used in the first phase, which is given by the sorting bound fi Dehne et al. [41] and Sibeyn and Kaufmann <ref> [97] </ref> show how to achieve the same I/O bound if log B = O by exploiting coarse-grained parallel algorithms whose data access characteristics permit the periodic sortings to be done with a linear number of I/Os.
Reference: [98] <author> S. Subramanian and S. Ramaswamy. </author> <title> The p-range tree: a new data structure for range searching in secondary memory. </title> <booktitle> Proceedings of the ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: In the two-dimensional cases studied in <ref> [68, 87, 98] </ref>, the authors use the terms "two-sided," "three-sided," and "four-sided" range query to mean what we call (1; 1)-sided, (2; 1)-sided, and (2; 2)-sided queries, respectively. <p> Ramaswamy and Subramanian [87] introduce the notion of path caching to develop EM algorithms for (1; 1)-sided and (2; 1)-sided 2-D range queries. Their algorithms are optimal in criteria 1 and 2 but with higher storage overheads and amortized and/or nonoptimal update bounds. Subramanian and Ramaswamy <ref> [98] </ref> present the P-range tree data structure for the (2; 1)-sided and (general) (2; 2)-sided 2-D range queries. The update times are amortized and slightly nonoptimal, and the space overhead for (2; 2)-sided queries is O On the other hand, Subramanian and Ramaswamy [98] prove a lower bound for an external <p> Subramanian and Ramaswamy <ref> [98] </ref> present the P-range tree data structure for the (2; 1)-sided and (general) (2; 2)-sided 2-D range queries. The update times are amortized and slightly nonoptimal, and the space overhead for (2; 2)-sided queries is O On the other hand, Subramanian and Ramaswamy [98] prove a lower bound for an external memory version of the pointer machine model, based upon a result of Chazelle [29] for the RAM model, that no EM algorithm can achieve both criteria 1 and 2 using less than O space, even if we relax 1 to allow O I/Os,
Reference: [99] <author> R. Tamassia and J. S. Vitter. </author> <title> Optimal cooperative search in fractional cascaded data structures. </title> <journal> Algorithmica, </journal> <volume> 15(2), </volume> <pages> 154-171, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: External fractional cascading: an EM analog to fractional cascading on a seg ment tree. Online filtering: a technique based upon the work of Tamassia and Vitter <ref> [99] </ref> for online queries in data structures with fractional cascading. External marriage-before-conquest : an EM analog to the well-known technique of Kirkpatrick and Seidel [70] for performing output-sensitive convex hull constructions. Randomized incremental construction with gradations: a localized version of the incremental construction paradigm of Clarkson and Shor [35].
Reference: [100] <author> S. Toledo. </author> <title> Out of core algorithms in numerical linear algebra, a survey. </title> <editor> In J. Abello and J. S. Vitter, editors, </editor> <title> External Memory Algorithms and Visualization, DIMACS series. </title> <publisher> American Mathematical Society, </publisher> <year> 1998. </year>
Reference-contexts: If the ith key in the input of the sorting instance has key value x 6= 0, there is a nonzero matrix element in position (x; i). The reader is referred to <ref> [36, 78, 89, 101, 100, 108, 110] </ref> for further study of EM matrix algorithms. 5.
Reference: [101] <author> S. Toledo and F. G. Gustavson. </author> <title> The design and implementation of SOLAR, a portable library for scalable out-of-core linear algebra computations. </title> <booktitle> In Proceedings of the Fourth Workshop on Input/Output in Parallel and Distributed Systems, </booktitle> <pages> 28-40, </pages> <address> Philadelphia, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: If the ith key in the input of the sorting instance has key value x 6= 0, there is a nonzero matrix element in position (x; i). The reader is referred to <ref> [36, 78, 89, 101, 100, 108, 110] </ref> for further study of EM matrix algorithms. 5.
Reference: [102] <author> J. D. Ullman and M. Yannakakis. </author> <title> The input/output complexity of transitive closure. </title> <journal> Annals of Mathematics and Artificial Intellegence, </journal> <volume> 3, </volume> <pages> 331-360, </pages> <year> 1991. </year> <title> EXTERNAL MEMORY ALGORITHMS (DRAFT, </title> <address> June 18, </address> <year> 1998) </year> <month> 31 </month>
Reference-contexts: They also show how to compute the trapezoidal decomposition for intersecting segments. 6. Batched Problems on Graphs The first work on EM graph algorithms was by Ullman and Yannakakis <ref> [102] </ref> for the problem of transitive closure. Chiang et al. [31] consider a variety of graph problems, several of which have upper and lower I/O bounds related to permuting. <p> The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. Constructing classification trees in external memory for data mining is discussed in [113]. The I/O complexity of several of the basic graph problems considered in <ref> [31, 102] </ref> remain open, including connectivity, topological sorting, shortest paths, breadth-first search, and depth-first search.
Reference: [103] <author> J. van den Bercken, B. Seeger, and P. Widmayer. </author> <title> A generic approach to bulk loading multidimensional index structures. </title> <booktitle> In Proceedings 23rd VLDB Conference, </booktitle> <pages> 406-415, </pages> <year> 1997. </year>
Reference-contexts: Bulk loading a Hilbert R-tree is therefore easy once the center points are presorted, but the quality of the Hilbert R-tree in terms of query performance is not as good as that of an R*-tree, especially for higher-dimensional data [26, 66]. Arge et al. [13] and Bercken et al. <ref> [103] </ref> have independently devised fast bulk loading methods for R*-trees that are based upon buffer trees. The former method is especially efficient and can even support dynamic batched updates and queries. Experiments with this technique are discussed in Section 11. 8.
Reference: [104] <author> M. van Kreveld, J. Nievergelt, T. Roos, and P. W. </author> <title> (Eds.). Algorithmic Foundations of GIS. </title> <publisher> LNCS 1340. Springer-Verlag, </publisher> <year> 1997. </year>
Reference-contexts: The reader is referred to [36, 78, 89, 101, 100, 108, 110] for further study of EM matrix algorithms. 5. Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases [74, 90, 91], geographic information systems (GIS) <ref> [74, 90, 104] </ref>, constraint logic programming [67, 68], object-oriented databases [117], statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year.
Reference: [105] <author> P. J. Varman and R. M. Verma. </author> <title> An efficient multiversion access structure. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 9(3), </volume> <pages> 391-409, </pages> <month> May/June </month> <year> 1997. </year>
Reference-contexts: It supports dynamic dictionary operations and one-dimensional range queries in O (log B n + t) I/Os per operation. Persistent versions of B-trees have been developed by Becker et al. [24] and Varman and Verma <ref> [105] </ref>. Lomet and Salzberg [79] explore mechanisms to add concurrency and recovery to B-trees.
Reference: [106] <author> D. E. Vengroff. </author> <title> TPIE User Manual and Reference. </title> <institution> Duke University, </institution> <year> 1995. </year> <note> The manual and software distribution are available on the web at http://www.cs.duke.edu/TPIE/. </note>
Reference-contexts: We refer the reader to [53] for background. 22 JEFFREY SCOTT VITTER In this section we describe TPIE (Transparent Parallel I/O programming Environment) 3 <ref> [106, 108] </ref>, which is used as the implementation platform for the experiments in the next section. TPIE is a comprehensive software package that helps programmers to develop high-level, portable, and efficient implementations of EM algorithms.
Reference: [107] <author> D. E. Vengroff and J. S. Vitter. </author> <title> Efficient 3-d range searching in external memory. </title> <booktitle> In Proceedings of the 28th Annual ACM Symposium on Theory of Computing, </booktitle> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: Fundamentally different techniques are needed for higher dimensions and for non-orthogonal queries. Vengroff and Vitter <ref> [107] </ref> use a partitioning approach and compressed representation to get the first EM algorithms for three-dimensional range searching that are within a polylog factor of optimal. They build a hierarchical partitioning structure in external memory so that the items in any specified range are densely contained in one region.
Reference: [108] <author> D. E. Vengroff and J. S. Vitter. </author> <title> I/O-efficient scientific computation using TPIE. </title> <booktitle> In Proceedings of the Goddard Conference on Mass Storage Systems and Technologies, volume II of NASA Conference Publication 3340, </booktitle> <pages> 553-570, </pages> <address> College Park, MD, </address> <month> September </month> <year> 1996. </year>
Reference-contexts: Sorting via disk striping is often more efficient in practice than more complicated techniques that utilize independent disks, since the (log m)= log (m=D) factor may be dwarfed by the additional overhead of using the disks independently <ref> [108] </ref>. In the following two subsections we discuss and analyze new external sorting algorithms based upon the distribution and merge paradigms. The SRM method, which uses a randomized merge technique, outperforms disk striping in practice for reasonable values of D (see Section 2.2). <p> If the ith key in the input of the sorting instance has key value x 6= 0, there is a nonzero matrix element in position (x; i). The reader is referred to <ref> [36, 78, 89, 101, 100, 108, 110] </ref> for further study of EM matrix algorithms. 5. <p> We refer the reader to [53] for background. 22 JEFFREY SCOTT VITTER In this section we describe TPIE (Transparent Parallel I/O programming Environment) 3 <ref> [106, 108] </ref>, which is used as the implementation platform for the experiments in the next section. TPIE is a comprehensive software package that helps programmers to develop high-level, portable, and efficient implementations of EM algorithms.
Reference: [109] <author> J. S. Vitter. </author> <title> Efficient memory access in large-scale computation. </title> <booktitle> In Proceedings of the 1991 Symposium on Theoretical Aspects of Computer Science, Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: If we use a B-tree to store the active vertical segments, each insertion and query uses O (log B n) I/Os, resulting in a huge I/O bound of O (N log B n), which is more than B times larger than the desired bound. One solution suggested in <ref> [109] </ref> is to use a binary tree in which items are pushed lazily down the tree in blocks of B items at a time.
Reference: [110] <author> J. S. Vitter. </author> <title> External memory algorithms. </title> <editor> In J. Abello and J. S. Vitter, editors, </editor> <title> External Memory Algorithms and Visualization, DIMACS series. </title> <publisher> American Mathematical Society, </publisher> <year> 1998. </year>
Reference-contexts: If the ith key in the input of the sorting instance has key value x 6= 0, there is a nonzero matrix element in position (x; i). The reader is referred to <ref> [36, 78, 89, 101, 100, 108, 110] </ref> for further study of EM matrix algorithms. 5.
Reference: [111] <author> J. S. Vitter and E. A. M. Shriver. </author> <title> Algorithms for parallel memory I: Two-level memories. </title> <journal> Algorithmica, </journal> <pages> 12(2-3), 110-147, </pages> <year> 1994. </year>
Reference-contexts: Storage systems such as RAID are being developed that use multiple disks to get more bandwidth [30, 61]. We can capture the main properties of magnetic disks and multiple disk systems by the commonly-used parallel disk model (PDM) introduced by Vitter and Shriver <ref> [111] </ref>: N = problem size (in units of data items); M = internal memory size (in units of data items); B = block transfer size (in units of data items); D = # independent disk drives; P = # CPUs; where M &lt; N , and 1 DB M=2. <p> It seems difficult to find S = fi (m) partitioning elements using fi (n=D) I/Os and guarantee that the bucket sizes are within a constant factor of one another. But efficient deterministic methods exist for choosing S = p m partitioning elements <ref> [83, 111] </ref>, which has the effect of doubling the number of levels of recursion. Probabilistic methods based upon random sampling can be found in [47]. <p> Choosing C = p D won't change the optimal sorting time by more than a constant factor, but as pointed out earlier, full striping (in which C = D) can be nonoptimal. Vitter and Shriver <ref> [111] </ref> use two randomized online techniques during the partitioning so that with high probability each bucket is well balanced across the D disks. (Partial striping is used so that the pointers needed to keep track of the layout of the buckets on the disks can fit in internal memory.) The first <p> The method is trivial if D = 1, but with multiple disks there may be bottlenecks on individual disks. One solution for doing the permuting in O (N=D) I/Os is to use randomized balancing strategies based upon <ref> [111] </ref>. Matrix transposition is the special case of permuting in which the permutation can be represented as a transposition of a matrix from row-major order into column major order. Theorem 2.3 ([7]). <p> The number of I/Os using D disks required for computing the N -input FFT digraph or an N -input permutation network is given by the same bound (2:1) as for sorting. Cormen and Nicol [37] give some practical implementations for one-dimensional FFTs based upon the optimal PDM algorithm of <ref> [111] </ref>. The algorithms for FFT are faster and simpler than for sorting because the computation is nonadaptive in nature, and thus the communication pattern is oblivious. 3. Lower Bounds on I/O In this section we prove the lower bounds from Theorems 2.1-2.5 in Section 2.
Reference: [112] <author> J. S. Vitter and E. A. M. Shriver. </author> <title> Algorithms for parallel memory II: Hierarchical multilevel memories. </title> <journal> Algorithmica, </journal> <pages> 12(2-3), 148-169, </pages> <year> 1994. </year>
Reference-contexts: The PDM model can be generalized to multilevel memory hierarchies, but for reasons of brevity and emphasis, we do not discuss such models here. We refer the reader to <ref> [112] </ref> and its references. 1.3. Overview of the Paper. In this paper we survey several useful paradigms for solving problems efficiently in external memory. The canonical EM problem is sorting, which we discuss in the next section along with the important paradigms of distribution and merging. <p> TPIE (Transparent Parallel I/O programming Environment), which we cover in Section 10, is used for the implementations. In Section 12 we describe EM algorithms that can adapt optimally to dynamically changing memory allocations. Generalizations of PDM to multilevel memory hierarchies are discussed separately in <ref> [112] </ref>. In Section 13 we give some final remarks and discuss some ongoing work. 2.
Reference: [113] <author> M. Wang, J. S. Vitter, and B. R. Iyer. </author> <title> Scalable mining for classification rules in relational databases. </title> <booktitle> In Proceedings of the International Database Engineering & Application Symposium, </booktitle> <institution> Cardiff, Wales, </institution> <month> July </month> <year> 1998. </year>
Reference-contexts: Recent work on other EM graph algorithms appears in [1, 10, 73, 56]. The problem of how to store graphs on disks for efficient traversal is discussed in [81, 4]. Constructing classification trees in external memory for data mining is discussed in <ref> [113] </ref>. The I/O complexity of several of the basic graph problems considered in [31, 102] remain open, including connectivity, topological sorting, shortest paths, breadth-first search, and depth-first search.
Reference: [114] <author> D. Willard and G. Lueker. </author> <title> Adding range restriction capability to dynamic data structures. </title> <journal> Journal of the ACM, </journal> <volume> 32(3), </volume> <pages> 597-617, </pages> <year> 1985. </year>
Reference-contexts: For example, by setting a to a constant, we get a simple, worst-case implementation of interval trees. They also serve as a simpler and worst-case alternative to the data structure in <ref> [114] </ref> for augmenting one-dimensional data structures with range restriction capabilities.
Reference: [115] <author> D. Womble, D. Greenberg, S. Wheat, and R. Riesen. </author> <title> Beyond core: Making parallel computer I/O practical. </title> <booktitle> In Proceedings of the 1993 DAGS/PC Symposium, </booktitle> <pages> 56-63, </pages> <address> Hanover, NH, </address> <month> June </month> <year> 1993. </year> <institution> Dartmouth Institute for Advanced Graduate Studies. </institution>
Reference: [116] <author> C. Wu and T. Feng. </author> <title> The universality of the shu*e-exchange network. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-30, </volume> <pages> 324-332, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: A permutation network can be realized by a series of three FFTs <ref> [116] </ref>. Theorem 2.5. The number of I/Os using D disks required for computing the N -input FFT digraph or an N -input permutation network is given by the same bound (2:1) as for sorting.
Reference: [117] <editor> S. B. Zdonik and D. Maier, editors. </editor> <booktitle> Readings in Object-Oriented Database Systems. </booktitle> <publisher> Morgan Kauffman, </publisher> <year> 1990. </year>
Reference-contexts: Batched Problems in Computational Geometry Problems involving massive amounts of geometric data are ubiquitous in spatial databases [74, 90, 91], geographic information systems (GIS) [74, 90, 104], constraint logic programming [67, 68], object-oriented databases <ref> [117] </ref>, statistics, virtual reality systems, and computer graphics [90]. NASA's Earth Observing System, for example, produces petabytes (10 15 bytes) of raster data per year. A major challenge is to develop mechanisms for processing the data, or else much of it will be wasted.
Reference: [118] <author> W. Zhang and P.-A. Larson. </author> <title> Dynamic memory adjustment for external mergesort. </title> <booktitle> Proceedings of the Twenty-third International Conference on Very Large Data Bases, </booktitle> <year> 1997. </year> <institution> Center for Geometric Computing, Department of Computer Science, Duke University, Durham, </institution> <address> NC 27708-0129, USA E-mail address: jsv@cs.duke.edu URL: http://www.cs.duke.edu/~jsv/ </address>
Reference-contexts: Barve and Vitter define the model in generality and give dynamically optimal strategies for sorting, matrix multiplication, and buffer trees operations. Their work represents the first theoretical model of dynamic allocation for EM algorithms. 26 JEFFREY SCOTT VITTER Pang et al. [85] and Zhang and Larson <ref> [118] </ref> give memory-adaptive merge sort algorithms, but their algorithms handle only special cases and can be made to perform poorly for certain patterns of memory allocation. 13. Conclusions In this paper we have described several useful paradigms for the design and implementation of efficient external memory algorithms.
References-found: 118

