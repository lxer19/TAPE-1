URL: http://www.cs.iastate.edu/tech-reports/TR92-13.ps
Refering-URL: http://www.cs.iastate.edu/tech-reports/catalog.html
Root-URL: 
Title: Measure, Stochasticity, and the Density of Hard Languages  
Author: TR - Jack H. Lutz and Elvira Mayordomo 
Address: 226 Atanasoff Ames, IA 50011  
Affiliation: Iowa State University of Science and Technology Department of Computer Science  
Date: May 1992  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> L. Berman and J. Hartmanis, </author> <title> On isomorphism and density of NP and other complete sets, </title> <journal> SIAM Journal on Computing 6 (1977), </journal> <pages> pp. 305-322. </pages>
Reference-contexts: That is, E 6 P btt (DENSE c ): 2 In fact, Watanabe's argument also works for P O (log n)tt -reducibility, i.e., E 6 P O (log n)tt (DENSE c ): 3. Mahaney [14], proving a conjecture of Berman and Hartmanis <ref> [1] </ref>, showed that, unless P = NP, no sparse language is P m -hard for NP. That is, P 6= NP ) NP 6 P m (SPARSE): 4.
Reference: [2] <author> H. Chernoff, </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations, </title> <journal> Annals of Mathematical Statistics, </journal> <note> 23 (1952) pp. 493-507. </note>
Reference: [3] <author> T. Hagerup and C. Rub, </author> <title> A guided tour of Chernoff bounds, </title> <booktitle> Information Processing Letters 33 (1990), </booktitle> <pages> pp. 305-308. </pages>
Reference-contexts: See <ref> [3] </ref>. 2 3 Measure and Weak Stochasticity In this section, after reviewing some fundamentals of measure in exponential time complexity classes, we prove the Weak Stochasticity Theorem. This theorem will be useful in the proof of our main result in x4.
Reference: [4] <author> D. W. Juedes and J. H. Lutz, </author> <title> Kolmogorov complexity, complexity cores, and the distribution of hardness, </title> <editor> in O. Watanabe (ed.), </editor> <title> Kol-mogorov Complexity: Theory and Relations to Computational Complexity, </title> <note> Springer-Verlag, to appear. </note>
Reference-contexts: For example, in ESPACE=DSPACE (2 linear ), it is known <ref> [10, 4] </ref> that almost every language has very high space-bounded Kolmogorov complexity. 4 A variety of sets X have been shown to have measure 0 in ESPACE, sim-ply by proving that every element of X has low space-bounded Kolmogorov complexity [10, 4, 13, 9]. <p> For example, in ESPACE=DSPACE (2 linear ), it is known [10, 4] that almost every language has very high space-bounded Kolmogorov complexity. 4 A variety of sets X have been shown to have measure 0 in ESPACE, sim-ply by proving that every element of X has low space-bounded Kolmogorov complexity <ref> [10, 4, 13, 9] </ref>. Thus high space-bounded Kolmogorov complexity is a "general purpose randomness property" of languages in ESPACE.
Reference: [5] <author> D. W. Juedes and J. H. Lutz, </author> <title> The complexity and distribution of hard problems, </title> <note> in preparation. </note>
Reference-contexts: negligibly small subset of E 2 , has recently been shown to have a number of plausible consequences: If (NPjE 2 ) 6= 0, then NP contains p-random languages [12]; NP contains E-bi-immune languages [15]; every P m -hard language for NP has an exponentially dense, exponentially hard complexity core <ref> [5] </ref>; and now, by Theorem 4.3 above, every P n ff tt -hard language for NP (ff &lt; 1) is exponentially dense. Further investigation of the consequences and plausibility of (NPjE 2 ) 6= 0 and related strong, measure-theoretic hypotheses is clearly indicated. 19
Reference: [6] <author> R. M. Karp and R. J. Lipton, </author> <title> Some connections between nonuniform and uniform complexity classes, </title> <booktitle> Proceedings of the 12th ACM Symposium on Theory of Computing (1980), </booktitle> <pages> pp. 302-309. </pages> <note> Also published as Turing machines that take advice, </note> <month> L'Enseignement Mathematique 28 </month> <year> (1982), </year> <pages> pp. 191-209. </pages>
Reference-contexts: Note that each S j consists of those languages A that are in infinitely many of the sets S [d j;k ]. We now formulate our notion of weak stochasticity. For this we need a few definitions. Our notion of advice classes is standard <ref> [6] </ref>. An advice function is a function h : N ! f0; 1g fl : Given a function q : N ! N, we write ADV (q) for the set of all advice functions h such that jh (n)j q (n) for all n 2 N.
Reference: [7] <author> A. N. Kolmogorov and V. A. Uspenskii, </author> <title> Algorithms and randomness, </title> <booktitle> translated in Theory of Probability and Its Applications 32 (1987), </booktitle> <pages> pp. 389-412. </pages>
Reference-contexts: If jC =n j 2 fln for all sufficiently large n, then our prediction scheme will be asymptotically no better than random coin-tossing, i.e., lim j (A 4 B) " C =n j = 2 Following the terminology of Kolmogorov <ref> [7] </ref>, we call such a property a stochasticity property of the language A. To be precise, the above result says that almost every language A 2 E is weakly (2 cn ; cn; 2 fln )-stochastic.
Reference: [8] <author> J. H. Lutz, </author> <title> Category and measure in complexity classes, </title> <journal> SIAM Journal on Computing 19 (1990), </journal> <pages> pp. 1100-1131. </pages>
Reference-contexts: prove that this holds for E 2 , i.e., for every real ff &lt; 1, (P n ff tt (DENSE c )jE 2 ) = 0: (1:2) Note that there is an enormous gap between polynomial and 2 n * growth rates. (Consider, for example the G i -hierarchy of <ref> [8] </ref>.) Thus, a conclusion that every P r -hard language for C is dense is much stronger than a conclusion that no sparse language is P r -hard for C. Much of our interest in (1.1) and (1.2) concerns the class NP and results 3 and 4 above.
Reference: [9] <author> J. H. Lutz, </author> <title> An upward measure separation theorem, </title> <booktitle> Theoretical Computer Science, 81 (1991), </booktitle> <pages> pp. 127-135. </pages>
Reference-contexts: For example, in ESPACE=DSPACE (2 linear ), it is known [10, 4] that almost every language has very high space-bounded Kolmogorov complexity. 4 A variety of sets X have been shown to have measure 0 in ESPACE, sim-ply by proving that every element of X has low space-bounded Kolmogorov complexity <ref> [10, 4, 13, 9] </ref>. Thus high space-bounded Kolmogorov complexity is a "general purpose randomness property" of languages in ESPACE.
Reference: [10] <author> J. H. Lutz, </author> <title> Almost everywhere high nonuniform complexity, </title> <journal> Journal of Computer and System Sciences 44 (1992), </journal> <note> to appear. </note>
Reference-contexts: this paper, Theorem 4.2, extends results 1 and 2 above by showing that, for every real ff &lt; 1, only a measure 0 subset of the languages in E are P n ff tt -reducible to non-dense languages. "Measure 0 subset" here refers to the resource-bounded measure theory of Lutz <ref> [10, 11] </ref>. In the notation of this theory, our main result says that, for every real ff &lt; 1, (P n ff tt (DENSE c )jE) = 0: (1:1) This means that P n ff tt (DENSE c )"E is a negligibly small subset of E [10, 11]. <p> measure theory of Lutz <ref> [10, 11] </ref>. In the notation of this theory, our main result says that, for every real ff &lt; 1, (P n ff tt (DENSE c )jE) = 0: (1:1) This means that P n ff tt (DENSE c )"E is a negligibly small subset of E [10, 11]. This result, which requires a completely different technique from Watanabe's result 2 above, extends result 2, both by imposing the measure 0 condition and by extending the truth table reducibility from O (log n) queries to n ff queries (ff &lt; 1). <p> Much of our interest in (1.1) and (1.2) concerns the class NP and results 3 and 4 above. It is well known that P NP E 2 . In fact, E 2 is the smallest deterministic time complexity class known to contain NP. It is easy to see <ref> [10] </ref> that (PjE) = (PjE 2 ) = 0, i.e., P has measure 0 in E and E 2 . 3 Ogiwara and Watanabe's proof of result 4 above does not appear to allow significant relaxation of either the query bound or the sparseness criterion. <p> For example, in ESPACE=DSPACE (2 linear ), it is known <ref> [10, 4] </ref> that almost every language has very high space-bounded Kolmogorov complexity. 4 A variety of sets X have been shown to have measure 0 in ESPACE, sim-ply by proving that every element of X has low space-bounded Kolmogorov complexity [10, 4, 13, 9]. <p> For example, in ESPACE=DSPACE (2 linear ), it is known [10, 4] that almost every language has very high space-bounded Kolmogorov complexity. 4 A variety of sets X have been shown to have measure 0 in ESPACE, sim-ply by proving that every element of X has low space-bounded Kolmogorov complexity <ref> [10, 4, 13, 9] </ref>. Thus high space-bounded Kolmogorov complexity is a "general purpose randomness property" of languages in ESPACE. <p> This theorem will be useful in the proof of our main result in x4. We also expect it to be useful in future investigations of the measure structure of E and E 2 . Resource-bounded measure <ref> [10, 11] </ref> is a very general theory whose special cases include classical Lebesgue measure, the measure structure of the class REC of all recursive languages, and measure in various complexity classes. <p> Then p 2 (Z) = 0. (The proof of Lemma 3.3 makes essential use of the fact that p 2 contains a universal function for p. It is not the case that p (Z) = 0.) It is shown in <ref> [10] </ref> that these definitions endow E and E 2 with internal measure structure. <p> Instead we use a sufficient condition, proved in <ref> [10] </ref>, for a set to have measure 0. To state this condition we need a polynomial notion of convergence for infinite series. All our series here consist of nonnegative terms.
Reference: [11] <author> J. H. Lutz, </author> <title> Resource-bounded measure, </title> <note> in preparation. 20 </note>
Reference-contexts: this paper, Theorem 4.2, extends results 1 and 2 above by showing that, for every real ff &lt; 1, only a measure 0 subset of the languages in E are P n ff tt -reducible to non-dense languages. "Measure 0 subset" here refers to the resource-bounded measure theory of Lutz <ref> [10, 11] </ref>. In the notation of this theory, our main result says that, for every real ff &lt; 1, (P n ff tt (DENSE c )jE) = 0: (1:1) This means that P n ff tt (DENSE c )"E is a negligibly small subset of E [10, 11]. <p> measure theory of Lutz <ref> [10, 11] </ref>. In the notation of this theory, our main result says that, for every real ff &lt; 1, (P n ff tt (DENSE c )jE) = 0: (1:1) This means that P n ff tt (DENSE c )"E is a negligibly small subset of E [10, 11]. This result, which requires a completely different technique from Watanabe's result 2 above, extends result 2, both by imposing the measure 0 condition and by extending the truth table reducibility from O (log n) queries to n ff queries (ff &lt; 1). <p> By the resource-bounded generalization of the Kolmogorov zero-one law <ref> [11] </ref>, "(NPjE 2 ) 6= 0" is equivalent to "(NPjE 2 ) = 1 or NP is not measurable in E 2 ", and similarly for E.) It follows immediately from (1.1) and (1.2) above that, for all ff &lt; 1, (NPjE) 6= 0 ) NP 6 P n ff tt <p> This theorem will be useful in the proof of our main result in x4. We also expect it to be useful in future investigations of the measure structure of E and E 2 . Resource-bounded measure <ref> [10, 11] </ref> is a very general theory whose special cases include classical Lebesgue measure, the measure structure of the class REC of all recursive languages, and measure in various complexity classes.
Reference: [12] <author> J. H. Lutz, </author> <title> Intrinsically pseudorandom sequences, </title> <note> in preparation. </note>
Reference-contexts: To be precise, the above result says that almost every language A 2 E is weakly (2 cn ; cn; 2 fln )-stochastic. The adverb "weakly" here defers to a stronger stochasticity property to be proven in <ref> [12] </ref>, but weak stochasticity is a powerful and convenient tool. For example, in x4 below we prove (1.1) by a combinatorial construction showing that no language in P n ff tt (DENSE c ) is weakly (2 3n ; 3n; 2 n 2 )-stochastic. <p> It was noted in Lemma 3.2 that p (X) = 0 implies p 2 (X) = 0. In fact, more is true. Lemma 3.3. <ref> [12] </ref> Let Z be the union of all sets X such that p (X) = 0. Then p 2 (Z) = 0. (The proof of Lemma 3.3 makes essential use of the fact that p 2 contains a universal function for p. <p> The hypothesis that (NPjE 2 ) 6= 0, i.e., that NP is not a negligibly small subset of E 2 , has recently been shown to have a number of plausible consequences: If (NPjE 2 ) 6= 0, then NP contains p-random languages <ref> [12] </ref>; NP contains E-bi-immune languages [15]; every P m -hard language for NP has an exponentially dense, exponentially hard complexity core [5]; and now, by Theorem 4.3 above, every P n ff tt -hard language for NP (ff &lt; 1) is exponentially dense.
Reference: [13] <author> J. H. Lutz and W. J. Schmidt, </author> <title> Circuit size relative to pseudorandom oracles, </title> <note> Theoretical Computer Science, to appear. </note>
Reference-contexts: For example, in ESPACE=DSPACE (2 linear ), it is known [10, 4] that almost every language has very high space-bounded Kolmogorov complexity. 4 A variety of sets X have been shown to have measure 0 in ESPACE, sim-ply by proving that every element of X has low space-bounded Kolmogorov complexity <ref> [10, 4, 13, 9] </ref>. Thus high space-bounded Kolmogorov complexity is a "general purpose randomness property" of languages in ESPACE.
Reference: [14] <author> S. R. Mahaney, </author> <title> Sparse complete sets for NP: Solution of a conjecture of Berman and Hartmanis, </title> <journal> Journal of Computer and System Sciences 25 (1982), </journal> <pages> pp. 130-143. </pages>
Reference-contexts: That is, E 6 P btt (DENSE c ): 2 In fact, Watanabe's argument also works for P O (log n)tt -reducibility, i.e., E 6 P O (log n)tt (DENSE c ): 3. Mahaney <ref> [14] </ref>, proving a conjecture of Berman and Hartmanis [1], showed that, unless P = NP, no sparse language is P m -hard for NP. That is, P 6= NP ) NP 6 P m (SPARSE): 4.
Reference: [15] <author> E. Mayordomo, </author> <title> Almost every set in exponential time is P-bi-immune, </title> <booktitle> Proceedings of the Seventeenth International Symposium on Mathematical Foundations of Computer Science, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1992, </year> <note> to appear. </note>
Reference-contexts: The hypothesis that (NPjE 2 ) 6= 0, i.e., that NP is not a negligibly small subset of E 2 , has recently been shown to have a number of plausible consequences: If (NPjE 2 ) 6= 0, then NP contains p-random languages [12]; NP contains E-bi-immune languages <ref> [15] </ref>; every P m -hard language for NP has an exponentially dense, exponentially hard complexity core [5]; and now, by Theorem 4.3 above, every P n ff tt -hard language for NP (ff &lt; 1) is exponentially dense.
Reference: [16] <author> A. R. Meyer, </author> <note> reported in [1]. </note>
Reference-contexts: Efforts to explain this observation (and similar observations for other classes and reducibilities) have yielded many results. We mention four that are particularly relevant to the work presented here: 1. Meyer <ref> [16] </ref> proved that every P m -hard language for E (or any larger class) is dense. That is, E 6 P m (DENSE c ); where DENSE c is the complement of DENSE and we write P r (S) = S P r (A). 2.
Reference: [17] <author> M. Ogiwara and O. Watanabe, </author> <title> On polynomial-time bounded truth-table reducibility of NP sets to sparse sets, </title> <journal> SIAM Journal on Computing 20 (1991), </journal> <pages> pp. 471-483. </pages>
Reference-contexts: Mahaney [14], proving a conjecture of Berman and Hartmanis [1], showed that, unless P = NP, no sparse language is P m -hard for NP. That is, P 6= NP ) NP 6 P m (SPARSE): 4. Ogiwara and Watanabe <ref> [17] </ref> extended Mahaney's result by proving that, unless P = NP, no sparse language is P btt -hard for NP.
Reference: [18] <author> O. Watanabe, </author> <title> On the Structure of Intractable Complexity Classes, </title> <type> Ph. D. thesis, </type> <institution> Department of Computer Science, Tokyo Institute of Technology, </institution> <year> 1987. </year>
Reference-contexts: Meyer [16] proved that every P m -hard language for E (or any larger class) is dense. That is, E 6 P m (DENSE c ); where DENSE c is the complement of DENSE and we write P r (S) = S P r (A). 2. Watanabe <ref> [18, 19] </ref> extended Meyer's result by proving that every P btt - hard language for E is dense. <p> Theorem 4.2. For every real ff &lt; 1, (P n ff tt (DENSE c )jE) = (P n ff tt (DENSE c )jE 2 ) = 0: Proof. This follows immediately from Theorem 3.7 and Lemma 4.1. 2 As noted in x1, Theorem 4.2 extends Watanabe's result <ref> [18, 19] </ref> that every P btt -hard language for E is dense, both by relaxing the query bound and by imposing the measure 0 condition: If a language A is even weakly P n ff tt - hard for E, in the sense that P n ff tt (A) does not
Reference: [19] <author> O. Watanabe, </author> <title> Polynomial time reducibility to a set of small density, </title> <booktitle> Proceedings of the Second Annual Structure in Complexity Theory Conference, </booktitle> <publisher> IEEE Press, </publisher> <year> 1987, </year> <pages> pp. 138-146. </pages>
Reference-contexts: Meyer [16] proved that every P m -hard language for E (or any larger class) is dense. That is, E 6 P m (DENSE c ); where DENSE c is the complement of DENSE and we write P r (S) = S P r (A). 2. Watanabe <ref> [18, 19] </ref> extended Meyer's result by proving that every P btt - hard language for E is dense. <p> Theorem 4.2. For every real ff &lt; 1, (P n ff tt (DENSE c )jE) = (P n ff tt (DENSE c )jE 2 ) = 0: Proof. This follows immediately from Theorem 3.7 and Lemma 4.1. 2 As noted in x1, Theorem 4.2 extends Watanabe's result <ref> [18, 19] </ref> that every P btt -hard language for E is dense, both by relaxing the query bound and by imposing the measure 0 condition: If a language A is even weakly P n ff tt - hard for E, in the sense that P n ff tt (A) does not
Reference: [20] <author> C. B. Wilson, </author> <title> Relativized circuit complexity, </title> <journal> Journal of Computer and System Sciences 31 (1985), </journal> <pages> pp. 169-181. 21 </pages>
Reference-contexts: It is an open question whether the query bound n ff can be significantly relaxed. A construction of Wilson <ref> [20] </ref> shows that there is an oracle B such that E B P B O (n)tt (SPARSE), so progress in this direction will require nonrelativizable techniques.
References-found: 20

