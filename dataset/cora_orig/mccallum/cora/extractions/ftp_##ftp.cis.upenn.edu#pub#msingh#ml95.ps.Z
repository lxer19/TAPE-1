URL: ftp://ftp.cis.upenn.edu/pub/msingh/ml95.ps.Z
Refering-URL: http://www.cis.upenn.edu/~msingh/frames/papers_list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: msingh@gradient.cis.upenn.edu  provan@camis.stanford.edu  
Title: A Comparison of Induction Algorithms for Selective and non-Selective Bayesian Classifiers  
Author: Moninder Singh Gregory M. Provan 
Address: Philadelphia, PA 19104-6389  2164 Staunton Court Palo Alto, CA, 94306  
Affiliation: Dept. of Computer and Information Science University of Pennsylvania  Institute for the Study of Learning and Expertise  
Note: Proceedings of the 12th International Conference on Machine Learning 497-505, 1995: Morgan Kaufmann.  
Abstract: In this paper we present a novel induction algorithm for Bayesian networks. This selective Bayesian network classifier selects a subset of attributes that maximizes predictive accuracy prior to the network learning phase, thereby learning Bayesian networks with a bias for small, high-predictive-accuracy networks. We compare the performance of this classifier with selective and non-selective naive Bayesian classifiers. We show that the selective Bayesian network classifier performs significantly better than both versions of the naive Bayesian classifier on almost all databases analyzed, and hence is an enhancement of the naive Bayesian classifier. Relative to the non-selective Bayesian network classifier, our selective Bayesian network classifier generates networks that are computationally simpler to evaluate and that display predictive accuracy comparable to that of Bayesian networks which model all features.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W. and Bankert, R. L. </author> <year> (1994). </year> <title> Feature selection for case-based classification of cloud types. </title> <booktitle> In AAAI Workshop on Case-based Reasoning, </booktitle> <pages> 106-112, </pages> <address> Seattle, WA. </address> <publisher> AAAI Press. </publisher>
Reference-contexts: It is expected that in such domains feature selection may not make a significant impact. One exception is the study of cloud classification by Aha and Bankert <ref> (Aha and Bankert, 1994) </ref>, in which a set of 204 attributes were significantly pruned, leading the greatly improved 4 Langley (Langley, 1994) presents a thorough review of feature selection approaches studied within the Machine Learning literature. performance. 5 Better understanding of data sets and of domains may lead to a deeper
Reference: <author> Amuallim, H. and Dietterich, T. G. </author> <year> (1991). </year> <title> Learning with Many Irrelevant Features. </title> <booktitle> In Proc. Conf. of the AAAI, </booktitle> <pages> 547-552. </pages> <publisher> AAAI Press, </publisher> <address> Menlo Park, CA. </address>
Reference-contexts: A filter model filters out less relevant features using an algorithm different from the induction algorithm used for the learning, and a wrapper model uses induction algorithm itself for feature selection. Three filter-model approaches that have been taken are: the FOCUS algorithm <ref> (Amuallim and Dietterich, 1991) </ref> the Relief algorithm (Kira and Rendell, 1992a,b) (which Kononenko has extended in (Kononenko, 1994)), and an extended nearest-neighbor algorithm (Cardie, 1993).
Reference: <author> Andersen, S. K., Olesen, K. G., Jensen, F. V. and Jensen, F. </author> <year> (1989). </year> <title> HUGIN|a Shell for Building Belief Universes for Expert Systems. </title> <booktitle> In Proc.IJCAI, </booktitle> <pages> 1080-1085. </pages>
Reference-contexts: In order to check the significance of the differences in predictive accuracies, calculate the t-value for the two-tailed paired-t test between the different pairs of algorithms. We performed inference on the networks using the Lauritzen-Spiegelhalter inference algorithm as implemented in the HUGIN <ref> (Andersen et. al., 1989) </ref> system. 4.2 RESULTS The average predictive accuracies of the networks generated by the four methods are shown in Table 2. Each result describes an average predictive accuracy on the test set for the 30 trials, followed by the sample standard deviation.
Reference: <author> Cardie, C. </author> <year> (1993). </year> <title> Using Decision Trees to Improve Case-based Learning. </title> <booktitle> In Proc. Machine Learning, </booktitle> <pages> 25-32. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Three filter-model approaches that have been taken are: the FOCUS algorithm (Amuallim and Dietterich, 1991) the Relief algorithm (Kira and Rendell, 1992a,b) (which Kononenko has extended in (Kononenko, 1994)), and an extended nearest-neighbor algorithm <ref> (Cardie, 1993) </ref>. Wrapper-based approaches have been studied in (John et. al., 1994; Caruana and Freitag, 1994; Langley and Sage, 1994), among others. 4 A growing consensus in this research is that the success of feature selection is strongly correlated to the data itself, as well as to the algorithm employed.
Reference: <author> Caruana, R. and Freitag, D. </author> <year> (1994). </year> <title> Greedy attribute selection. </title> <editor> In W. Cohen and H. Hirsch, editors, </editor> <booktitle> Proc. Machine Learning, </booktitle> <pages> 28-36. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Cooper, G. F. and Herskovits, E. </author> <year> (1992). </year> <title> A Bayesian Method for the Induction of of Probabilistic Networks from Data. </title> <booktitle> In Machine Learning 9, </booktitle> <pages> 54-62. </pages> <publisher> Kluwer. </publisher>
Reference-contexts: Despite its simplicity and the strong conditional independence assumptions it makes, the naive Bayesian classifier performs remarkably well. Within the Bayesian Artificial Intelligence community, the best-known Bayesian representation is the Bayesian network (Pearl, 1988). Induction algorithms for Bayesian networks (e.g. K2 <ref> (Cooper and Her-skovits, 1992) </ref>) have been applied to many domains; however, no one has yet compared the performance of these Bayesian network induction methods to other induction methods.
Reference: <author> Herskovits, E. and Cooper, G. F. </author> <year> (1990). </year> <title> KUTATO: An Entropy-Driven System for Construction of Probabilistic Expert Systems from Databases. </title> <booktitle> In Proc. Conf. Uncertainty in Artificial Intelligence, </booktitle> <pages> 54-62. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> John, G., Kohavi, R. and Pfleger, K. </author> <year> (1994). </year> <title> Irrelevant features and the subset selection problem. </title> <editor> In W. Co-hen and H. Hirsch, editors, </editor> <booktitle> Proc. Machine Learning, </booktitle> <pages> 121-129. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We call this approach K2-AS, since it uses the basic K2 algorithm allied with an Attribute Selection phase. The algorithm we use is what has been described as a wrapper model <ref> (John et. al., 1994) </ref>, in that "the feature subset selection algorithms conducts a search for a good subset using the induction algorithm itself as part of the evaluation function" (John et. al., 1994, page 124). Our learning approach consists of two main steps, attribute selection and network construction. <p> The algorithm we use is what has been described as a wrapper model (John et. al., 1994), in that "the feature subset selection algorithms conducts a search for a good subset using the induction algorithm itself as part of the evaluation function" <ref> (John et. al., 1994, page 124) </ref>. Our learning approach consists of two main steps, attribute selection and network construction. In the attribute selection phase, we choose the set of attributes from which the final network is constructed. <p> Another important point to note is that K2 is not a conditional metric, and hence, may not be the best metric to use for attribute selection in Bayesian networks. Singh and Provan (Singh and Provan, 1995) have proposed a filter model approach <ref> (John et. al., 1994) </ref> that uses a conditional, information-theoretic metric for attribute selection during the attribute selection phase and the K2 metric for constructing the final Bayesian network from the set of selected attributes. <p> Techniques developed include sequential backward selection (Marill and Green, 1963), branch&bound (Narendra and Fukunaga, 1977), and search algorithms (Siedlecki and Sklansky, 1988). Feature selection has received considerable attention in the last few years within the computational learning community, using both filter-based and wrapper-based approaches <ref> (John et. al., 1994) </ref>. A filter model filters out less relevant features using an algorithm different from the induction algorithm used for the learning, and a wrapper model uses induction algorithm itself for feature selection.
Reference: <author> Kira, K. and Rendell, L. </author> <year> (1992a). </year> <title> A practical approach to feature selection. </title> <booktitle> In Proc. Machine Learning, </booktitle> <pages> 249-256. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A filter model filters out less relevant features using an algorithm different from the induction algorithm used for the learning, and a wrapper model uses induction algorithm itself for feature selection. Three filter-model approaches that have been taken are: the FOCUS algorithm (Amuallim and Dietterich, 1991) the Relief algorithm <ref> (Kira and Rendell, 1992a,b) </ref> (which Kononenko has extended in (Kononenko, 1994)), and an extended nearest-neighbor algorithm (Cardie, 1993).
Reference: <author> Kira, K. and Rendell, L. </author> <year> (1992b). </year> <title> The Feature Selection Problem: Traditional Methods and a New Algorithm. </title> <booktitle> In Proc. AAAI, </booktitle> <pages> 129-134. </pages> <publisher> AAAI Press. </publisher>
Reference: <author> Kononenko, I. </author> <year> (1994). </year> <title> Estimating attributes: Analysis and extension of relief. </title> <booktitle> In Proc. European Conf. on Machine Learning, </booktitle> <pages> 171-182. </pages> <publisher> Springer Verlag. </publisher>
Reference-contexts: Three filter-model approaches that have been taken are: the FOCUS algorithm (Amuallim and Dietterich, 1991) the Relief algorithm (Kira and Rendell, 1992a,b) (which Kononenko has extended in <ref> (Kononenko, 1994) </ref>), and an extended nearest-neighbor algorithm (Cardie, 1993).
Reference: <author> Kononenko, I. </author> <year> (1990). </year> <title> Comparison of Inductive and noise Bayesian Learning Approaches to automatic knowledge acquisition. </title> <editor> In B. Wielinga et al. </editor> <booktitle> Current Trends in Knowledge Acquisition, </booktitle> <address> Amsterdam, </address> <publisher> IOS Press. </publisher>
Reference: <author> Langley, P. </author> <year> (1994). </year> <title> Selection of relevant features in machine learning. </title> <editor> In R. Greiner, editor, </editor> <booktitle> Proc. AAAI Fall Symposium on Relevance. </booktitle> <publisher> AAAI Press. </publisher>
Reference-contexts: Bayesian networks can account for correlations among attributes, so they are a natural extension of the naive approach. The selective naive Bayesian classifier <ref> (Langley and Sage, 1994) </ref> (referred to as naive-AS) is an extension to the naive Bayesian classifier, and is designed to perform better in domains with redundant attributes. The intuition is that if highly correlated attributes are not selected, the classifier should perform better given its attribute independence assumptions. <p> It is expected that in such domains feature selection may not make a significant impact. One exception is the study of cloud classification by Aha and Bankert (Aha and Bankert, 1994), in which a set of 204 attributes were significantly pruned, leading the greatly improved 4 Langley <ref> (Langley, 1994) </ref> presents a thorough review of feature selection approaches studied within the Machine Learning literature. performance. 5 Better understanding of data sets and of domains may lead to a deeper understanding of the role of feature selection, and improved performance from feature selection algorithms.
Reference: <author> Langley, P. </author> <year> (1993). </year> <title> Induction of Recursive Bayesian Classifiers In Proc. </title> <booktitle> European Conf. on Machine Learning, </booktitle> <pages> 153-164. </pages> <publisher> Springer Verlag. </publisher>
Reference-contexts: We refer to this naive Bayesian classifier (that models all attributes) as naive-ALL. Although its performance is remarkably good given its simplicity, this classifier is typically limited to learning classes that can be separated by a single decision boundary <ref> (Langley, 1993) </ref>, and in domains in which the attributes are correlated given the class variable, its performance can be worse than other approaches which can account for such correlations. Bayesian networks can account for correlations among attributes, so they are a natural extension of the naive approach.
Reference: <author> Langley, P. and Sage, S. </author> <year> (1994). </year> <title> Induction of selective Bayesian classifiers. </title> <booktitle> In Proc. Conf. on Uncertainty in AI, </booktitle> <pages> 399-406. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Bayesian networks can account for correlations among attributes, so they are a natural extension of the naive approach. The selective naive Bayesian classifier <ref> (Langley and Sage, 1994) </ref> (referred to as naive-AS) is an extension to the naive Bayesian classifier, and is designed to perform better in domains with redundant attributes. The intuition is that if highly correlated attributes are not selected, the classifier should perform better given its attribute independence assumptions. <p> It is expected that in such domains feature selection may not make a significant impact. One exception is the study of cloud classification by Aha and Bankert (Aha and Bankert, 1994), in which a set of 204 attributes were significantly pruned, leading the greatly improved 4 Langley <ref> (Langley, 1994) </ref> presents a thorough review of feature selection approaches studied within the Machine Learning literature. performance. 5 Better understanding of data sets and of domains may lead to a deeper understanding of the role of feature selection, and improved performance from feature selection algorithms.
Reference: <author> Madigan, D., Raftery, A., York, J., Bradshaw, J. and Almond, R. </author> <year> (1993). </year> <title> Strategies for Graphical Model Selection. </title> <booktitle> In Proc. International Workshop on AI and Statistics, </booktitle> <pages> 331-336. </pages>
Reference-contexts: Instead, the purpose of this paper is not to identify the Bayesian network with the highest predictive accuracy, but to identify a parsimonious model with good predictive accuracy. It is possible to compute multiple models and average over them, e.g. as proposed in <ref> (Madigan et. al., 1993) </ref>, to obtain the best predictive accuracy, and we hope to take this approach in future work. 7 CONCLUSION This paper introduces a feature-selection approach for learning Bayesian networks using a greedy search (i.e. K2-based) algorithm called CB.
Reference: <author> Marill, T. and Green, D. </author> <year> (1963). </year> <title> On the effectiveness of receptors in recognition systems. </title> <journal> IEEE Trans. on Information Theory, </journal> <volume> 9 </volume> <pages> 11-17. </pages>
Reference-contexts: In statistics, research on feature selection has focused primarily on selecting a subset of features within linear regression. Techniques developed include sequential backward selection <ref> (Marill and Green, 1963) </ref>, branch&bound (Narendra and Fukunaga, 1977), and search algorithms (Siedlecki and Sklansky, 1988). Feature selection has received considerable attention in the last few years within the computational learning community, using both filter-based and wrapper-based approaches (John et. al., 1994).
Reference: <author> Murphy, P. M. and Aha, D. W. </author> <year> (1992). </year> <title> UCI Repository of Machine Learning Databases. Machine-readable data repository, </title> <institution> Dept. of Information and Computer Science, Univ. of California, Irvine. </institution>
Reference-contexts: to test the quality of the network, we test the network for its predictive accuracy on the test data. 4 EXPERIMENTAL COMPARISON OF SELECTIVE BAYESIAN AND NAIVE BAYESIAN CLASSIFIERS In our experiments we used a variety of databases acquired from the University of California, Irvine repository of Machine Learning databases <ref> (Murphy and Aha, 1992) </ref>. The databases we used were Michal-ski's Soybean database, Schlimmer's Mushroom and Voting databases, the Gene-Splicing database due to Towell, Noordewier, and Shavlik, 3 and Shapiro's Chess Endgame database.
Reference: <author> Narendra, M. and Fukunaga, K. </author> <year> (1977). </year> <title> A branch and bound algorithm for feature subset selection. </title> <journal> IEEE Trans. on Computers, C-26(9):917-922. </journal>
Reference-contexts: In statistics, research on feature selection has focused primarily on selecting a subset of features within linear regression. Techniques developed include sequential backward selection (Marill and Green, 1963), branch&bound <ref> (Narendra and Fukunaga, 1977) </ref>, and search algorithms (Siedlecki and Sklansky, 1988). Feature selection has received considerable attention in the last few years within the computational learning community, using both filter-based and wrapper-based approaches (John et. al., 1994).
Reference: <author> Pazzani, M. </author> <year> (1995). </year> <title> Don't be so naive: Detecting dependencies when learning Bayesian Classifiers. </title> <note> Submitted for publication. </note>
Reference-contexts: On the other hand, Bayesian networks take into account these dependencies, and should have a better performance than the naive classifiers, especially in domains where the attributes are highly correlated. Similar improvements have been observed by Pazzani <ref> (Pazzani, 1995) </ref> whose `backward sequential elimination and joining algorithm' attempts to take into account the dependencies between various attributes by merging them into a single attribute.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Despite its simplicity and the strong conditional independence assumptions it makes, the naive Bayesian classifier performs remarkably well. Within the Bayesian Artificial Intelligence community, the best-known Bayesian representation is the Bayesian network <ref> (Pearl, 1988) </ref>. Induction algorithms for Bayesian networks (e.g. K2 (Cooper and Her-skovits, 1992)) have been applied to many domains; however, no one has yet compared the performance of these Bayesian network induction methods to other induction methods.
Reference: <author> Provan, G. and Singh, M. </author> <year> (1995). </year> <title> Learning Bayesian Networks using Feature Selection. </title> <booktitle> In Working Notes Fifth International Workshop on Artificial Intelligence and Statistics, </booktitle> <pages> 450-456. </pages>
Reference-contexts: Moreover, we have experimentally compared selective and non-selective Bayesian network classifiers, showing that the selective approach generates networks that are computationally simpler to evaluate and that display predictive accuracy comparable to that of Bayesian networks which model all features <ref> (Provan and Singh, 1995) </ref>. The selective Bayesian network thus seems to be a good compromise between naive Bayesian classifiers and non-selective Bayesian networks. We organize the remainder of the paper as follows. Section 2 summarizes the naive Bayesian classifier to which we compare our new learning approach. <p> Another important point to note is that K2 is not a conditional metric, and hence, may not be the best metric to use for attribute selection in Bayesian networks. Singh and Provan <ref> (Singh and Provan, 1995) </ref> have proposed a filter model approach (John et. al., 1994) that uses a conditional, information-theoretic metric for attribute selection during the attribute selection phase and the K2 metric for constructing the final Bayesian network from the set of selected attributes. <p> Experimental results show that the conditional metric-based approach produces Bayesian networks which exhibit better, or at least as good, predictive accuracy as that of networks produced by K2-AS. 6 RELATED WORK 6.1 COMPARISON OF SELECTIVE AND NON-SELECTIVE BAYESIAN NETWORK CLASSIFIERS In <ref> (Provan and Singh, 1995) </ref> we compare the performance of networks generated by K2-AS and a non-Selective Bayesian network classifier, CB, for the Chess, Soybean, Voting and Gene-splice databases studied here, as well as the Letter recognition database due to Slate. <p> A second benefit of using feature selection in Bayesian networks is that on some domains the learning rate is significantly faster <ref> (Provan and Singh, 1995) </ref>, indicating that feature selection is better for domains with little data. 6.2 FEATURE SELECTION Feature selection has been widely used in statistics and pattern recognition, and its use within the computational learning community has become quite widespread within the last few years. <p> K2-AS, by selecting a subset of features prior to learning the networks, not only significantly improves the inference efficiency of the resulting networks, but also achieves a predictive accuracy comparable to Bayesian networks learned using the full set of attributes <ref> (Provan and Singh, 1995) </ref>. The selective Bayesian network thus seems to be a good compromise between naive Bayesian classifiers and non-selective Bayesian networks. This work has raised several topics for further research that we are currently studying. <p> a conditional metric (and hence may not be the best metric to use for attribute selection in Bayesian networks), we are examining conditional 5 In this domain it is likely that the features were not pre-selected for relevance, as there was no a priori knowledge of relevance and irrelevance. metrics <ref> (Singh and Provan, 1995) </ref>. We are also in-vestigating whether there are statistical tests which could be performed on a database to identify the best Bayesian classifier to use, whether it is selective or not.
Reference: <author> Siedlecki, W. and Sklansky, J. </author> <year> (1988). </year> <title> On automatic feature selection. </title> <journal> Int. Jornal of Pattern Recognition and Artificial Intelligence, </journal> <volume> 2(2) </volume> <pages> 197-220. </pages>
Reference-contexts: In statistics, research on feature selection has focused primarily on selecting a subset of features within linear regression. Techniques developed include sequential backward selection (Marill and Green, 1963), branch&bound (Narendra and Fukunaga, 1977), and search algorithms <ref> (Siedlecki and Sklansky, 1988) </ref>. Feature selection has received considerable attention in the last few years within the computational learning community, using both filter-based and wrapper-based approaches (John et. al., 1994).
Reference: <author> Singh, M. and Provan, G. </author> <year> (1995). </year> <title> Efficient learning of selective Bayesian network classifiers. </title> <note> Submitted for publication. </note>
Reference-contexts: Moreover, we have experimentally compared selective and non-selective Bayesian network classifiers, showing that the selective approach generates networks that are computationally simpler to evaluate and that display predictive accuracy comparable to that of Bayesian networks which model all features <ref> (Provan and Singh, 1995) </ref>. The selective Bayesian network thus seems to be a good compromise between naive Bayesian classifiers and non-selective Bayesian networks. We organize the remainder of the paper as follows. Section 2 summarizes the naive Bayesian classifier to which we compare our new learning approach. <p> The learning algorithm that we use, called CB <ref> (Singh and Valtorta, 1995) </ref>, is a modified version of K2. Whereas K2 assumes a node ordering, CB uses conditional independence (CI) tests to generate a "good" node ordering, and then uses the K2 algorithm to generate the Bayesian network from the database D using this node ordering. <p> Since CB uses the K2 algorithm to generate the Bayesian network from a particular ordering, CB is correct in the same sense that K2 is <ref> (Singh and Val-torta, 1995) </ref>. <p> Since CB uses the K2 algorithm to generate the Bayesian network from a particular ordering, CB is correct in the same sense that K2 is (Singh and Val-torta, 1995). Singh and Valtorta show the importance of deriving a good node ordering <ref> (Singh and Valtorta, 1995) </ref>, given the n! possible node orderings on n features. 3.2 ATTRIBUTE SELECTION USING BAYESIAN NETWORKS We implemented the Attribute Selection Algorithm using the CB algorithm in both the attribute selection as well as the network construction phase. <p> Another important point to note is that K2 is not a conditional metric, and hence, may not be the best metric to use for attribute selection in Bayesian networks. Singh and Provan <ref> (Singh and Provan, 1995) </ref> have proposed a filter model approach (John et. al., 1994) that uses a conditional, information-theoretic metric for attribute selection during the attribute selection phase and the K2 metric for constructing the final Bayesian network from the set of selected attributes. <p> Experimental results show that the conditional metric-based approach produces Bayesian networks which exhibit better, or at least as good, predictive accuracy as that of networks produced by K2-AS. 6 RELATED WORK 6.1 COMPARISON OF SELECTIVE AND NON-SELECTIVE BAYESIAN NETWORK CLASSIFIERS In <ref> (Provan and Singh, 1995) </ref> we compare the performance of networks generated by K2-AS and a non-Selective Bayesian network classifier, CB, for the Chess, Soybean, Voting and Gene-splice databases studied here, as well as the Letter recognition database due to Slate. <p> A second benefit of using feature selection in Bayesian networks is that on some domains the learning rate is significantly faster <ref> (Provan and Singh, 1995) </ref>, indicating that feature selection is better for domains with little data. 6.2 FEATURE SELECTION Feature selection has been widely used in statistics and pattern recognition, and its use within the computational learning community has become quite widespread within the last few years. <p> K2-AS, by selecting a subset of features prior to learning the networks, not only significantly improves the inference efficiency of the resulting networks, but also achieves a predictive accuracy comparable to Bayesian networks learned using the full set of attributes <ref> (Provan and Singh, 1995) </ref>. The selective Bayesian network thus seems to be a good compromise between naive Bayesian classifiers and non-selective Bayesian networks. This work has raised several topics for further research that we are currently studying. <p> a conditional metric (and hence may not be the best metric to use for attribute selection in Bayesian networks), we are examining conditional 5 In this domain it is likely that the features were not pre-selected for relevance, as there was no a priori knowledge of relevance and irrelevance. metrics <ref> (Singh and Provan, 1995) </ref>. We are also in-vestigating whether there are statistical tests which could be performed on a database to identify the best Bayesian classifier to use, whether it is selective or not.
Reference: <author> Singh, M. and Valtorta, M. </author> <year> (1995). </year> <title> Construction of Bayesian Network Structures from Data: a Brief Survey and an Efficient Algorithm. </title> <journal> Int. Journal of Approximate Reasoning, </journal> <volume> 12, </volume> <pages> 111-131. </pages>
Reference-contexts: Moreover, we have experimentally compared selective and non-selective Bayesian network classifiers, showing that the selective approach generates networks that are computationally simpler to evaluate and that display predictive accuracy comparable to that of Bayesian networks which model all features <ref> (Provan and Singh, 1995) </ref>. The selective Bayesian network thus seems to be a good compromise between naive Bayesian classifiers and non-selective Bayesian networks. We organize the remainder of the paper as follows. Section 2 summarizes the naive Bayesian classifier to which we compare our new learning approach. <p> The learning algorithm that we use, called CB <ref> (Singh and Valtorta, 1995) </ref>, is a modified version of K2. Whereas K2 assumes a node ordering, CB uses conditional independence (CI) tests to generate a "good" node ordering, and then uses the K2 algorithm to generate the Bayesian network from the database D using this node ordering. <p> Since CB uses the K2 algorithm to generate the Bayesian network from a particular ordering, CB is correct in the same sense that K2 is <ref> (Singh and Val-torta, 1995) </ref>. <p> Since CB uses the K2 algorithm to generate the Bayesian network from a particular ordering, CB is correct in the same sense that K2 is (Singh and Val-torta, 1995). Singh and Valtorta show the importance of deriving a good node ordering <ref> (Singh and Valtorta, 1995) </ref>, given the n! possible node orderings on n features. 3.2 ATTRIBUTE SELECTION USING BAYESIAN NETWORKS We implemented the Attribute Selection Algorithm using the CB algorithm in both the attribute selection as well as the network construction phase. <p> Another important point to note is that K2 is not a conditional metric, and hence, may not be the best metric to use for attribute selection in Bayesian networks. Singh and Provan <ref> (Singh and Provan, 1995) </ref> have proposed a filter model approach (John et. al., 1994) that uses a conditional, information-theoretic metric for attribute selection during the attribute selection phase and the K2 metric for constructing the final Bayesian network from the set of selected attributes. <p> Experimental results show that the conditional metric-based approach produces Bayesian networks which exhibit better, or at least as good, predictive accuracy as that of networks produced by K2-AS. 6 RELATED WORK 6.1 COMPARISON OF SELECTIVE AND NON-SELECTIVE BAYESIAN NETWORK CLASSIFIERS In <ref> (Provan and Singh, 1995) </ref> we compare the performance of networks generated by K2-AS and a non-Selective Bayesian network classifier, CB, for the Chess, Soybean, Voting and Gene-splice databases studied here, as well as the Letter recognition database due to Slate. <p> A second benefit of using feature selection in Bayesian networks is that on some domains the learning rate is significantly faster <ref> (Provan and Singh, 1995) </ref>, indicating that feature selection is better for domains with little data. 6.2 FEATURE SELECTION Feature selection has been widely used in statistics and pattern recognition, and its use within the computational learning community has become quite widespread within the last few years. <p> K2-AS, by selecting a subset of features prior to learning the networks, not only significantly improves the inference efficiency of the resulting networks, but also achieves a predictive accuracy comparable to Bayesian networks learned using the full set of attributes <ref> (Provan and Singh, 1995) </ref>. The selective Bayesian network thus seems to be a good compromise between naive Bayesian classifiers and non-selective Bayesian networks. This work has raised several topics for further research that we are currently studying. <p> a conditional metric (and hence may not be the best metric to use for attribute selection in Bayesian networks), we are examining conditional 5 In this domain it is likely that the features were not pre-selected for relevance, as there was no a priori knowledge of relevance and irrelevance. metrics <ref> (Singh and Provan, 1995) </ref>. We are also in-vestigating whether there are statistical tests which could be performed on a database to identify the best Bayesian classifier to use, whether it is selective or not.
References-found: 25

