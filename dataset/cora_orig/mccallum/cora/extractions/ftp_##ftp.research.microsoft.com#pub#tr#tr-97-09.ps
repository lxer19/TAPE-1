URL: ftp://ftp.research.microsoft.com/pub/tr/tr-97-09.ps
Refering-URL: http://www.research.microsoft.com/~cohen/
Root-URL: http://www.research.microsoft.com
Title: Rendering Layered Depth Images  
Author: Steven J. Gortler Li-wei He Michael F. Cohen 
Address: One Microsoft Way Redmond, WA 98052  
Date: March 19, 1997  
Affiliation: Harvard University  Stanford University  Microsoft Research  Microsoft Research Advanced Technology Division Microsoft Corporation  
Pubnum: Technical Report MSTR-TR-97-09  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Shenchang Eric Chen and Lance Williams. </author> <title> View interpolation for image synthesis. </title> <booktitle> In Computer Graphics, Annual Conference Series, </booktitle> <year> 1993, </year> <pages> pages 279-288. 9 </pages>
Reference-contexts: This makes splatting an efficient solution to the resampling problem. 2 Previous Work Over the past few years, there have been many papers on image based rendering. In [7], Levoy and Whitted discuss rendering point data. Chen and Williams presented the idea of rendering from images <ref> [1] </ref>. Laveau and Faugeras discuss IBR using a backwards map [5]. McMillan and Bishop discuss IBR using cylindrical views [12]. Seitz and Dyer describe a system that allows a user to correctly model view transforms in a user controlled image morphing system [15].
Reference: [2] <author> William Dally, Leonard McMillan, Gary Bishop, and Henry Fuchs. </author> <title> The delta tree: An object centered approach to image based rendering. </title> <publisher> Mit ai technical memo, </publisher> <year> 1996. </year>
Reference-contexts: The geometry of this computation has been analyzed by McMillan [13], and efficient computation for the special case of orthographic input images is given in <ref> [2] </ref>. Let C 1 be the four by four matrix for the LDI camera.
Reference: [3] <author> Steven Gortler, Radek Grzeszczuk, Richard Szeliski, and Michael F. Cohen. </author> <booktitle> The lumi-graph. In Computer Graphics, Annual Conference Series, </booktitle> <year> 1996, </year> <pages> pages 43-54. </pages>
Reference-contexts: McMillan and Bishop discuss IBR using cylindrical views [12]. Seitz and Dyer describe a system that allows a user to correctly model view transforms in a user controlled image morphing system [15]. In a slightly different direction, Levoy and Hanrahan [6] and Gortler et al. <ref> [3] </ref> describe IBR methods using a large number of input images to sample the high dimensional radiance function. Max uses a representation similar to an LDI [9], but for a purpose quite different than ours; his purpose is high quality anti-aliasing, while our goal is efficiency.
Reference: [4] <author> Paul S. Heckbert and Henry P. Moreton. </author> <title> Interpolation for polygon texture mapping and shading. </title> <editor> In David Rogers and Rae Earnshaw, editors, </editor> <booktitle> State of the Art in Computer Graphics: Visualization and Modeling, </booktitle> <pages> pages 101-111. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: The size and footprint of the splat is based on an estimated size of the reprojected pixel. 3.1 Incremental Warping Computation The incremental warping computation is similar to the one used for certain texture mapping operations <ref> [4, 14] </ref>. The geometry of this computation has been analyzed by McMillan [13], and efficient computation for the special case of orthographic input images is given in [2]. Let C 1 be the four by four matrix for the LDI camera.
Reference: [5] <author> S. Laveau and O. D. Faugeras. </author> <title> 3-d scene representation as a collection of images. </title> <booktitle> In Twelfth International Conference on Pattern Recognition (ICPR'94), volume A, </booktitle> <pages> pages 689-691, </pages> <address> Jerusalem, Israel, October 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: A more serious problem occurs when the forward mapping spreads the pixels apart, creating gaps in the output picture (see Color Image (a)). Proposed solutions to this problem include performing a backwards mapping from the output sample location to the input image <ref> [5] </ref>. This is an expensive operation that require some amount of searching in the input image. Another possible solution is to think of the input image as a mesh of micro-polygons, and to scan-convert these polygons in the output image. <p> In [7], Levoy and Whitted discuss rendering point data. Chen and Williams presented the idea of rendering from images [1]. Laveau and Faugeras discuss IBR using a backwards map <ref> [5] </ref>. McMillan and Bishop discuss IBR using cylindrical views [12]. Seitz and Dyer describe a system that allows a user to correctly model view transforms in a user controlled image morphing system [15].
Reference: [6] <author> Mark Levoy and Pat Hanrahan. </author> <title> Light-field rendering. </title> <booktitle> In Computer Graphics, Annual Conference Series, </booktitle> <year> 1996, </year> <pages> pages 31-42. </pages>
Reference-contexts: McMillan and Bishop discuss IBR using cylindrical views [12]. Seitz and Dyer describe a system that allows a user to correctly model view transforms in a user controlled image morphing system [15]. In a slightly different direction, Levoy and Hanrahan <ref> [6] </ref> and Gortler et al. [3] describe IBR methods using a large number of input images to sample the high dimensional radiance function.
Reference: [7] <author> Mark Levoy and Turner Whitted. </author> <title> The use of points as a display primitive. </title> <type> UNC Technical Report 85-022, </type> <institution> University of North Carolina, </institution> <year> 1985. </year>
Reference-contexts: No z-buffer is required, so alpha-compositing can be done efficiently without depth sorting. This makes splatting an efficient solution to the resampling problem. 2 Previous Work Over the past few years, there have been many papers on image based rendering. In <ref> [7] </ref>, Levoy and Whitted discuss rendering point data. Chen and Williams presented the idea of rendering from images [1]. Laveau and Faugeras discuss IBR using a backwards map [5]. McMillan and Bishop discuss IBR using cylindrical views [12].
Reference: [8] <author> William R. Mark, Leonard McMillan, and Gary Bishop. </author> <title> Post-rendering 3d warping. In 1997 Symposium on Interactive 3D Graphics (to appear). </title> <publisher> ACM, </publisher> <year> 1997. </year>
Reference-contexts: Another possible solution is to think of the input image as a mesh of micro-polygons, and to scan-convert these polygons in the output image. This is an expensive operation, as it requires a polygon scan-convert setup for each input pixel <ref> [8] </ref>. The simplest solution to fill gaps in the output image is to predict the projected size of an input pixel in the new projected view, and to "splat" the input pixel into the output image using a precomputed footprint [12].
Reference: [9] <author> Nelson Max. </author> <title> Hierarchical rendering of trees from precomputed multi-layer z-buffers. </title> <booktitle> In Seventh Eurographics Workshop on Rendering, </booktitle> <pages> pages 166-175. Eurographics, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: In a slightly different direction, Levoy and Hanrahan [6] and Gortler et al. [3] describe IBR methods using a large number of input images to sample the high dimensional radiance function. Max uses a representation similar to an LDI <ref> [9] </ref>, but for a purpose quite different than ours; his purpose is high quality anti-aliasing, while our goal is efficiency. Max reports his rendering time as 5 minutes per frame while our goal is multiple frames per second. <p> This preprocess is similar to the rendering described by Max <ref> [9] </ref>. The construction of the layered depth image is effectively decoupled from the final rendering of images from desired viewpoints. Thus, the LDI construction does not need to run at multiple frames per second to allow interactive camera motion.
Reference: [10] <author> Leonard McMillan. </author> <title> A list-priority rendering algorithm for redisplaying projected surfaces. </title> <type> UNC Technical Report 95-005, </type> <institution> University of North Carolina, </institution> <year> 1995. </year>
Reference-contexts: Because the pixels of an image form a regular grid, image based rendering computations are largely incremental and inexpensive. Moreover McMillan has developed an ordering algorithm <ref> [10, 12] </ref> that ensures that pixels in the synthesized image are drawn back to front, and thus no depth comparisons are required. This also permits proper alpha compositing of pixels without depth sorting. Despite these advantage, there are still many problems with current image based rendering methods. <p> For output, Max warps to an LDI. This is done so that, in conjunction with an A-buffer, high quality, but somewhat expensive, anti-aliasing of the output picture can be performed. The system presented here relies heavily on McMillan's ordering algorithm <ref> [10, 11, 12] </ref>. <p> T 1;2 6 6 x 1 + 1 0 3 7 5 2 6 4 y 1 1 7 7 + T 1;2 6 6 1 0 3 7 5 = startVec + incrVec The warping algorithm proceeds using McMillan's ordering algorithm as in <ref> [10] </ref>. The LDI is broken up into four regions above and below and to the left and right of the epipolar point. For each quadrant, the LDI is traversed in (possibly reverse) scan line order. At the 6 beginning of each scan line, startVec is computed.
Reference: [11] <author> Leonard McMillan. </author> <title> Computing visibility without depth. </title> <type> unpublished manuscript, </type> <year> 1996. </year>
Reference-contexts: For output, Max warps to an LDI. This is done so that, in conjunction with an A-buffer, high quality, but somewhat expensive, anti-aliasing of the output picture can be performed. The system presented here relies heavily on McMillan's ordering algorithm <ref> [10, 11, 12] </ref>. <p> In other words, one of the quadrants is processed left to right, top to bottom, another is processed left to right, bottom to top, etc. McMillan discusses in detail the various special cases that arise and proves that this ordering is guaranteed to produce depth ordered output <ref> [11] </ref>. When warping from an LDI, there is effectively only one input camera view. Therefore one can use the ordering algorithm to order the layered depth pixels visited. Within each layered depth pixel, the layers are processed in back to front order. The formal proof of [11] applies, and the ordering <p> produce depth ordered output <ref> [11] </ref>. When warping from an LDI, there is effectively only one input camera view. Therefore one can use the ordering algorithm to order the layered depth pixels visited. Within each layered depth pixel, the layers are processed in back to front order. The formal proof of [11] applies, and the ordering algorithm is guaranteed to work. 3 Rendering System The layered depth image data structure is defined as follows. 4 LayeredDepthImage- Camera; LayeredDepthPixel [Xres,Yres]; - LayeredDepthPixel NumActiveLayers; DepthPixel [MaxLayers]; - DepthPixel RGBcolor; Zdepth; TableIndex; - The layered depth image contains camera information plus an array of size
Reference: [12] <author> Leonard McMillan and Gary Bishop. </author> <title> Plenoptic modeling: An image-based rendering system. </title> <booktitle> In Computer Graphics, Annual Conference Series, </booktitle> <year> 1995, </year> <pages> pages 39-46. </pages>
Reference-contexts: Because the pixels of an image form a regular grid, image based rendering computations are largely incremental and inexpensive. Moreover McMillan has developed an ordering algorithm <ref> [10, 12] </ref> that ensures that pixels in the synthesized image are drawn back to front, and thus no depth comparisons are required. This also permits proper alpha compositing of pixels without depth sorting. Despite these advantage, there are still many problems with current image based rendering methods. <p> The simplest solution to fill gaps in the output image is to predict the projected size of an input pixel in the new projected view, and to "splat" the input pixel into the output image using a precomputed footprint <ref> [12] </ref>. For the splats to combine smoothly in the output image, the outer regions of the splat should have fractional alpha values and be composed into the new image using the "over" operation. This requires the output pixels to be drawn in depth order. <p> In [7], Levoy and Whitted discuss rendering point data. Chen and Williams presented the idea of rendering from images [1]. Laveau and Faugeras discuss IBR using a backwards map [5]. McMillan and Bishop discuss IBR using cylindrical views <ref> [12] </ref>. Seitz and Dyer describe a system that allows a user to correctly model view transforms in a user controlled image morphing system [15]. <p> For output, Max warps to an LDI. This is done so that, in conjunction with an A-buffer, high quality, but somewhat expensive, anti-aliasing of the output picture can be performed. The system presented here relies heavily on McMillan's ordering algorithm <ref> [10, 11, 12] </ref>.
Reference: [13] <author> Leonard McMillan and Gary Bishop. </author> <title> Shape as a pertebation to projective mapping. </title> <type> unpublished manuscript, </type> <year> 1996. </year>
Reference-contexts: The size and footprint of the splat is based on an estimated size of the reprojected pixel. 3.1 Incremental Warping Computation The incremental warping computation is similar to the one used for certain texture mapping operations [4, 14]. The geometry of this computation has been analyzed by McMillan <ref> [13] </ref>, and efficient computation for the special case of orthographic input images is given in [2]. Let C 1 be the four by four matrix for the LDI camera.
Reference: [14] <author> Mark Segal, Carl Korobkin, Rolf van Widenfelt, Jim Foran, and Paul Haeberli. </author> <title> Fast shadows and lighting effects using texture mapping. </title> <journal> Computer Graphics, </journal> <volume> 26(2) </volume> <pages> 249-252, </pages> <year> 1992. </year>
Reference-contexts: The size and footprint of the splat is based on an estimated size of the reprojected pixel. 3.1 Incremental Warping Computation The incremental warping computation is similar to the one used for certain texture mapping operations <ref> [4, 14] </ref>. The geometry of this computation has been analyzed by McMillan [13], and efficient computation for the special case of orthographic input images is given in [2]. Let C 1 be the four by four matrix for the LDI camera.
Reference: [15] <author> Steven M. Seitz and Charles R. Dyer. </author> <title> View morphing. </title> <booktitle> In Computer Graphics, Annual Conference Series, </booktitle> <year> 1996, </year> <pages> pages 21-30. 10 </pages>
Reference-contexts: Laveau and Faugeras discuss IBR using a backwards map [5]. McMillan and Bishop discuss IBR using cylindrical views [12]. Seitz and Dyer describe a system that allows a user to correctly model view transforms in a user controlled image morphing system <ref> [15] </ref>. In a slightly different direction, Levoy and Hanrahan [6] and Gortler et al. [3] describe IBR methods using a large number of input images to sample the high dimensional radiance function.
References-found: 15

