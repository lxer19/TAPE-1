URL: ftp://ftp.cs.uu.nl/pub/RUU/CS/techreps/CS-1997/1997-18.ps.gz
Refering-URL: http://www.cs.ruu.nl/docs/research/publication/TechList1.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: jacques@cs.ruu.nl  
Title: Scheduling tree-structured programs in the LogP model LogP models with a finite number of processors.
Author: Jacques Verriet 
Note: P -approximation algorithm for  of d(d 1)(P 1) 1 communication operations.  
Address: P.O. Box 80.089, 3508 TB Utrecht, The Netherlands.  
Affiliation: Department of Computer Science, Utrecht University,  
Abstract: The LogP model is a model of parallel computation that characterises a parallel computer architecture by four parameters: the latency L, the overhead o, the gap g and the number of processors P . We study the problem of constructing minimum-length schedules for tree-structured programs in the LogP model. This problem is proved to be NP-hard, even for outtrees of height two in LogP models with an unlimited number of processors. For outtrees of height two, a 2-approximation algorithm is presented. For intrees of height two, two approximation algorithms are presented: a 3-approximation algorithm for LogP models with an unrestricted number of processors and a 4 2 For the problem of constructing minimum-length schedules for d-ary intrees in a LogP model with a finite number of processors, three approximation algorithms are presented that are applicable in many models of parallel computation. The first constructs schedules for full d-ary intrees of length at most 2 + 2 d times the length of an optimal schedule plus the time required for (d + 1)P 1 communication operations. The second constructs schedules on P processors of length at most d + 1 d 2 +d d+P times the length of a minimum-length schedule plus
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Adler, J.W. Byers and R.M. Karp. </author> <title> Parallel sorting with limited bandwidth. </title> <booktitle> In Proceedings of the 7th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 129-136, </pages> <year> 1995. </year>
Reference-contexts: Like for many other models of parallel computation, little is known about scheduling parallel programs in the LogP model. A few algorithms have been presented that construct schedules for common parallel programs in the LogP model. These programs include Fast Fourier Transform [7], sorting <ref> [1, 8] </ref> and broadcast [17]. In addition, Lowe and Zimmermann [20, 23] presented an algorithm that constructs schedules for communication structures G of PRAMs in LogP models with an unrestricted number of processors.
Reference: [2] <author> A. Aggarwal, A.K. Chandra and M. Snir. </author> <title> On communication latency in PRAM computations. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 11-21, </pages> <year> 1989. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency <ref> [2, 3, 21] </ref>, memory contention [14, 13] and asynchrony [6, 12]. The BSP model [22] and the LogP model [7, 9] are models of parallel computation that consist of a collection of processors that communicate using message passing.
Reference: [3] <author> A. Aggarwal, A.K. Chandra and M. Snir. </author> <title> Communication complexity in PRAMs. </title> <journal> Theoretical Computer Science, </journal> <volume> 71 </volume> <pages> 3-28, </pages> <year> 1990. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency <ref> [2, 3, 21] </ref>, memory contention [14, 13] and asynchrony [6, 12]. The BSP model [22] and the LogP model [7, 9] are models of parallel computation that consist of a collection of processors that communicate using message passing.
Reference: [4] <author> P. Chretienne. </author> <title> Tree scheduling with communication delays. </title> <journal> Discrete Applied Mathematics, </journal> <volume> 49 </volume> <pages> 129-141, </pages> <year> 1994. </year>
Reference-contexts: In that case, minimum-length schedules for send graphs on an unlimited number of processors can be constructed in polynomial time [5] and constructing minimum-length schedules for outtrees of height three is NP-hard, even if the number of children of the root equals the number of sinks <ref> [4] </ref>. 3.2 A 2-approximation algorithm In this section, we will present a simple 2-approximation algorithm for scheduling send graphs in the LogP model.
Reference: [5] <author> P. Chretienne and C. Picouleau. </author> <title> Scheduling with communication delays: a survey. </title> <editor> In P. Chretienne, E.G. Coffman, Jr., J.K. Lenstra and Z. Liu, editors, </editor> <booktitle> Scheduling Theory and its Applications, </booktitle> <pages> pages 65-90. </pages> <publisher> John Wiley & Sons, </publisher> <year> 1995. </year>
Reference-contexts: If g and o equal zero, then scheduling in the LogP model is a special case of scheduling with arc-dependent communication delays (latencies). In that case, minimum-length schedules for send graphs on an unlimited number of processors can be constructed in polynomial time <ref> [5] </ref> and constructing minimum-length schedules for outtrees of height three is NP-hard, even if the number of children of the root equals the number of sinks [4]. 3.2 A 2-approximation algorithm In this section, we will present a simple 2-approximation algorithm for scheduling send graphs in the LogP model.
Reference: [6] <author> R. Cole and O. Zajicek. </author> <title> The APRAM: Incorporating asynchrony into the PRAM model. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 169-178, </pages> <year> 1989. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency [2, 3, 21], memory contention [14, 13] and asynchrony <ref> [6, 12] </ref>. The BSP model [22] and the LogP model [7, 9] are models of parallel computation that consist of a collection of processors that communicate using message passing. These models are more realistic, because they include several aspects of real parallel computers.
Reference: [7] <author> D. Culler, R. Karp, D. Patterson, A. Sahay, K.E. Schauser, E. Santos, R. Subramonian and T. von Eicken. </author> <title> LogP: Towards a realistic model of parallel computation. </title> <booktitle> In Proceedings of the Fourth ACM-SIGPLAN Symposium on Principles and Practice of Parallel Processing, </booktitle> <pages> pages 1-12, </pages> <year> 1993. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency [2, 3, 21], memory contention [14, 13] and asynchrony [6, 12]. The BSP model [22] and the LogP model <ref> [7, 9] </ref> are models of parallel computation that consist of a collection of processors that communicate using message passing. These models are more realistic, because they include several aspects of real parallel computers. Both models characterise a parallel architecture by a few parameters that capture memory latency and bandwidth. <p> Like for many other models of parallel computation, little is known about scheduling parallel programs in the LogP model. A few algorithms have been presented that construct schedules for common parallel programs in the LogP model. These programs include Fast Fourier Transform <ref> [7] </ref>, sorting [1, 8] and broadcast [17]. In addition, Lowe and Zimmermann [20, 23] presented an algorithm that constructs schedules for communication structures G of PRAMs in LogP models with an unrestricted number of processors.
Reference: [8] <author> D.E. Culler, A.C. Dusseau, R.P. Martin and K.E. Schauser. </author> <title> Fast parallel sorting under LogP: from theory to practice. </title> <editor> In T. Hey and J. Ferrante, editors, </editor> <title> Portability and Performance for Parallel Processing, </title> <booktitle> chapter 4, </booktitle> <pages> pages 71-98. </pages> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: Like for many other models of parallel computation, little is known about scheduling parallel programs in the LogP model. A few algorithms have been presented that construct schedules for common parallel programs in the LogP model. These programs include Fast Fourier Transform [7], sorting <ref> [1, 8] </ref> and broadcast [17]. In addition, Lowe and Zimmermann [20, 23] presented an algorithm that constructs schedules for communication structures G of PRAMs in LogP models with an unrestricted number of processors.
Reference: [9] <author> D.E. Culler, R.M. Karp, D. Patterson, A. Sahay, E.E. Santos, K.E. Schauser, R. Subramonian and T. von Eicken. </author> <title> LogP. A practical model of parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 39(11) </volume> <pages> 78-85, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency [2, 3, 21], memory contention [14, 13] and asynchrony [6, 12]. The BSP model [22] and the LogP model <ref> [7, 9] </ref> are models of parallel computation that consist of a collection of processors that communicate using message passing. These models are more realistic, because they include several aspects of real parallel computers. Both models characterise a parallel architecture by a few parameters that capture memory latency and bandwidth.
Reference: [10] <author> S. Fortune and J. Wyllie. </author> <title> Parallelism in Random Access Machines. </title> <booktitle> In Proceedings of the Tenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 114-118, </pages> <year> 1978. </year>
Reference-contexts: 1 Introduction The PRAM <ref> [10] </ref> is the most common model of parallel computation. A PRAM consists of a collection of processors that execute a parallel program in a synchronous manner; processors communicate by writing and reading in global memory.
Reference: [11] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness. </title> <publisher> Freeman, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: This is obvious if the number of processors is finite. Using a polynomial reduction from Partition, we will show that is is also true for all fixed choices of L, o, g and P , such that maxfo; gg 1 and P = 1. Partition <ref> [11] </ref> is defined as follows. Problem. Partition Instance. A set A = fa 1 ; : : : ; a n g of positive integers. Question.
Reference: [12] <author> P.B. Gibbons. </author> <title> A more practical PRAM model. </title> <booktitle> In Proceedings of the 1989 ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 158-168, </pages> <year> 1989. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency [2, 3, 21], memory contention [14, 13] and asynchrony <ref> [6, 12] </ref>. The BSP model [22] and the LogP model [7, 9] are models of parallel computation that consist of a collection of processors that communicate using message passing. These models are more realistic, because they include several aspects of real parallel computers.
Reference: [13] <author> P.B. Gibbons, Y. Matias and V. Ramachandran. </author> <title> Efficient low-contention parallel algorithms. </title> <booktitle> In Proceedings of the 6th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 236-247, </pages> <year> 1994. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency [2, 3, 21], memory contention <ref> [14, 13] </ref> and asynchrony [6, 12]. The BSP model [22] and the LogP model [7, 9] are models of parallel computation that consist of a collection of processors that communicate using message passing. These models are more realistic, because they include several aspects of real parallel computers.
Reference: [14] <author> P.B. Gibbons, Y. Matias and V. Ramachandran. </author> <title> The QRQW PRAM: Accounting for contention in parallel algorithms. </title> <booktitle> In Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <pages> pages 638-648, </pages> <year> 1994. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency [2, 3, 21], memory contention <ref> [14, 13] </ref> and asynchrony [6, 12]. The BSP model [22] and the LogP model [7, 9] are models of parallel computation that consist of a collection of processors that communicate using message passing. These models are more realistic, because they include several aspects of real parallel computers.
Reference: [15] <author> R.L. Graham. </author> <title> Bounds on multiprocessing timing anomalies. </title> <journal> SIAM Journal on Applied Mathematics, </journal> <volume> 17(2) </volume> <pages> 416-429, </pages> <month> March </month> <year> 1969. </year>
Reference-contexts: The remaining sinks y m+1 ; : : : ; y n are scheduled after the communication tasks and sinks y 1 ; : : : ; y m on one of the processors. This is done by a straightforward modification of Graham's List scheduling algorithm <ref> [15] </ref>. For each task y i , choose a processor p, such that idle (p) is minimal. Schedule y i at time idle (p) on processor p and increase idle (p) by (y i ). Let ( m ; m ) be the schedule constructed by these two steps. <p> Let Y 2 be the set of these sources and Y 1 the set of the remaining sources. Moreover, let Y = Y 1 [ Y 2 . The sources of Y 1 are scheduled on processors 1; : : : ; P using Graham's List scheduling algorithm <ref> [15] </ref>. First set idle (p) = 0 for all processors p. For all tasks y in Y 1 , y is scheduled as early as possible on a processor that becomes idle as early as possible. If y is scheduled on processor p, then idle (p) is increased by (y).
Reference: [16] <author> T.-S. Hsu and D.R. Lopez. </author> <title> Bounds and algorithms for a practical task allocation model. </title> <editor> In T. Asano, Y. Igarashi, H. Nagamochi, S. Miyano and S. Suri, editors, </editor> <booktitle> Proceedings of the 7th International Symposium on Algorithms and Computation, volume 1178 of Lecture Notes in Computer Science, </booktitle> <pages> pages 397-406, </pages> <address> Berlin, 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: For this algorithm, we will assume that g does not exceed o. It is a 3-approximation algorithm for scheduling receive graphs in LogP models with an unrestricted number of processors. It corresponds to the 3-approximation algorithm of Hsu and Lopez <ref> [16] </ref> for scheduling send and receive graphs in a model of parallel computation that resembles the LogP model. Consider an instance (G; ; c; L; o; g; P ), such that G is a receive graph, g o and P = 1.
Reference: [17] <author> R.M. Karp, A. Sahay, E.E. Santos and K.E. Schauser. </author> <title> Optimal broadcast and summation in the LogP model. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 142-153, </pages> <year> 1993. </year>
Reference-contexts: Like for many other models of parallel computation, little is known about scheduling parallel programs in the LogP model. A few algorithms have been presented that construct schedules for common parallel programs in the LogP model. These programs include Fast Fourier Transform [7], sorting [1, 8] and broadcast <ref> [17] </ref>. In addition, Lowe and Zimmermann [20, 23] presented an algorithm that constructs schedules for communication structures G of PRAMs in LogP models with an unrestricted number of processors.
Reference: [18] <author> S.R. Kosaraju. </author> <title> Parallel evaluation of division-free arithmetic expressions. </title> <booktitle> In Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 231-239, </pages> <year> 1986. </year>
Reference-contexts: By (T ), we denote the sum of the task length of the task of T . The following lemma is similar to a lemma of Kosaraju <ref> [18] </ref> that considers the number of leafs of binary trees. Lemma 5.4. Let (T; ; c; L; o; g; P ) be a fi-restricted LogP instance, such that T is a d-ary intree and (T ) fi.
Reference: [19] <author> M. Kunde. </author> <title> Nonpreemptive LP-scheduling on homogeneous multiprocessor systems. </title> <journal> SIAM Journal on Computing, </journal> <volume> 10(1) </volume> <pages> 151-173, </pages> <month> February </month> <year> 1981. </year>
Reference-contexts: Then the length of the resulting schedule exceeds that of the communication-free schedule by the total duration of the communication operations. Constructing communication-free schedules corresponds to scheduling without communication delays and overheads. Kunde <ref> [19] </ref> proved that, for inforests, critical path scheduling constructs (communication-free) schedules of length at most 2 2 P +1 times the length of an optimal schedule.
Reference: [20] <author> W. Lowe and W. Zimmermann. </author> <title> Upper time bounds for executing PRAM-programs on the LogP-machine. </title> <booktitle> In Proceedings of the 9th ACM International Conference on Supercomputing, </booktitle> <pages> pages 41-50, </pages> <year> 1995. </year>
Reference-contexts: A few algorithms have been presented that construct schedules for common parallel programs in the LogP model. These programs include Fast Fourier Transform [7], sorting [1, 8] and broadcast [17]. In addition, Lowe and Zimmermann <ref> [20, 23] </ref> presented an algorithm that constructs schedules for communication structures G of PRAMs in LogP models with an unrestricted number of processors.
Reference: [21] <author> C. Martel and A. Raghunathan. </author> <title> Asynchronous PRAMs with memory latency. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 23 </volume> <pages> 10-26, </pages> <year> 1994. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency <ref> [2, 3, 21] </ref>, memory contention [14, 13] and asynchrony [6, 12]. The BSP model [22] and the LogP model [7, 9] are models of parallel computation that consist of a collection of processors that communicate using message passing.
Reference: [22] <author> L.G. Valiant. </author> <title> A bridging model for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 33(8) </volume> <pages> 103-111, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: There are several PRAM-based models that include aspects of real parallel machines, such as latency [2, 3, 21], memory contention [14, 13] and asynchrony [6, 12]. The BSP model <ref> [22] </ref> and the LogP model [7, 9] are models of parallel computation that consist of a collection of processors that communicate using message passing. These models are more realistic, because they include several aspects of real parallel computers.
Reference: [23] <author> W. Zimmermann and W. Lowe. </author> <title> An approach to machine-independent parallel programming. </title> <editor> In B. Buchberger and J. Volkert, editors, </editor> <booktitle> Proceedings of the Third Joint Conference on Vector and Parallel Processing, volume 854 of Lecture Notes in Computer Science, </booktitle> <pages> pages 277-288, </pages> <address> Berlin, 1994. </address> <publisher> Springer-Verlag. </publisher> <pages> 24 </pages>
Reference-contexts: A few algorithms have been presented that construct schedules for common parallel programs in the LogP model. These programs include Fast Fourier Transform [7], sorting [1, 8] and broadcast [17]. In addition, Lowe and Zimmermann <ref> [20, 23] </ref> presented an algorithm that constructs schedules for communication structures G of PRAMs in LogP models with an unrestricted number of processors.
References-found: 23

