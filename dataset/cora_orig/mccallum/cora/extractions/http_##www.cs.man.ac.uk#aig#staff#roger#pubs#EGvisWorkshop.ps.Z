URL: http://www.cs.man.ac.uk/aig/staff/roger/pubs/EGvisWorkshop.ps.Z
Refering-URL: http://www.cs.man.ac.uk/aig/staff/roger/webrefs.html
Root-URL: http://www.cs.man.ac.uk
Email: email (JANET): hubbold@uk.ac.man.cs  
Title: Interactive Scientific Visualisation A Position Paper  
Author: R.J. Hubbold 
Date: March 1990  
Address: Oxford Road Manchester M13 9PL  
Affiliation: Department of Computer Science University of Manchester  
Abstract: This paper summarises the author's views on current developments in interactive scientific visu-alisation. It is based on a talk presented at the Eurographics '89 conference, held in Hamburg in September 1989. The paper takes issue with the direction of some current work and identifies areas where new ideas are needed. It has three main sections: data presentation methods, current visual-isation system architectures, and a new approach based on parallel processing. 
Abstract-found: 1
Intro-found: 1
Reference: <institution> References </institution>
Reference: [1] <author> K. </author> <title> Akeley. </title> <journal> The Silicon Graphics 4D/240GTX superworkstation. IEEE Computer Graphics and Applications, </journal> <month> July </month> <year> 1989. </year>
Reference-contexts: The problems of round-trip delays are likely to become evident as X11 is more widely used.) 3.1 The Graphics Pipeline A useful way to characterise the graphics pipeline, proposed by Akeley <ref> [1] </ref>, is to divide it into five major sections: G-T-X-S-D: G is for Generation. It is concerned with the definition of graphic primitives, attributes and their structure in a format acceptable to the remainder of the pipeline. <p> The Titan can be characterised as a GTX-SD machine, in which only the scan-conversion (of triangles) and display are handled by special hardware. Arguments against the G-TXSD configuration are presented very cogently by Akeley <ref> [1] </ref>. 4 Parallel Processing and Interactive Visualisation Within five to ten years many large-scale simulations will be carried out on parallel computer systems. Parallel architectures will offer an opportunity to develop radically new solutions to problems, and very different visualisation methods and system architectures.
Reference: [2] <author> B. Borden. </author> <title> Graphics processing on a graphics supercomputer. </title> <journal> IEEE Computer Graphics and Applications, </journal> <month> July </month> <year> 1989. </year>
Reference-contexts: Hitherto, many workstations have implemented all stages of this process, except generation, in special hardware. They can be characterised as G-TXSD 1 systems. There are already indications that display manufacturers have begun to recognise the dangers of this black-box approach. Machines like the Ardent Titan <ref> [2] </ref> and Apollo DN10000 [20] carry out much of the graphics pipeline processing in their general purpose processors, rather than in special hardware, yielding greater flexibility. The Titan can be characterised as a GTX-SD machine, in which only the scan-conversion (of triangles) and display are handled by special hardware.
Reference: [3] <author> W.H. Clifford, J.I. McConnell, and J.S. Saltz. </author> <title> The development of PEX, a 3D graphics extension to X11. In D.A. </title> <editor> Duce and P. Jancene, editors, </editor> <booktitle> Proceedings Eurographics '88. </booktitle> <publisher> North-Holland, </publisher> <year> 1988. </year>
Reference-contexts: This is very much the strategy currently being pursued by researchers and by some hardware vendors. There is major interest in network computing which aims to put the display and interaction on the user's desktop, and developments such as the X Window System [12] and PEX <ref> [3] </ref> reinforce this direction. One clear benefit of the separation of the graphics from other parts of the application is that special-ised hardware can be designed to support the computationally-intensive parts of the graphics pipeline, especially transformations, clipping and rendering.
Reference: [4] <author> P.M. Dew, R.A. Earnshaw, and T.R. Heywood. </author> <title> Parallel Processing for Computer Vision and Display. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: There have also been several implementations of ray tracing, which integrates the different stages of the pipeline into a single algorithm. A good survey of alternative approaches can be found in <ref> [4] </ref> and [13]. Significantly, relatively little work seems to be in progress on examining new graphics architectures, in which application computations and visualisation algorithms are closely coupled and distributed over large numbers of processors. Deriving new solutions to visualisation tasks for parallel machines is a challenging problem.
Reference: [5] <author> R. Wilhelmson et al. </author> <title> Study of a numerically modelled severe storm. NCSA Video, </title> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1990. </year>
Reference-contexts: It is not obvious how to display multi-dimensional data. Experiments on this are progressing at a number of places. The NCSA in Illinois has produced a stunning example of three-dimensional animation showing the development of a major storm system <ref> [5] </ref>. Their display uses a variety of techniques, such as transparent surfaces, symbols, ribbons, arrows and colours to show a total of nine different dimensions in the model. Significant effort has been devoted to finding new ways to show all of these factors, including the involvement of artists.
Reference: [6] <author> D.P. Greenberg. </author> <title> Advances in global illumination algorithms (invited lecture). </title> <editor> In W. Hansmann, F.R.A. Hopgood, and W.Strasser, editors, </editor> <booktitle> Proceedings Eurographics '89. </booktitle> <publisher> North-Holland, </publisher> <year> 1989. </year>
Reference-contexts: Clearly, for some purposes this is a worthy goal see, for example, recent results from radiosity algorithms and their potential use in architecture <ref> [6] </ref>. Large numbers of problems, particularly simulations of physical phenomena, deal with situations which evolve over time, so the use of animation techniques seems a logical choice.
Reference: [7] <author> I. Herman and J. Reviczky. </author> <title> A means to improve the GKS-3D/PHIGS viewing pipeline implementation. </title> <editor> In G. Marechal, editor, </editor> <booktitle> Proceedings Eurographics '87. </booktitle> <publisher> North-Holland, </publisher> <year> 1987. </year> <month> 9 </month>
Reference-contexts: It then becomes possible to design an implementation in such a way that all transformations can be concatenated to yield a single composite matrix. This applies even to systems such as PHIGS, which has a large number of diferent transformation and clipping stages. <ref> [7] </ref>. However, care is needed to make sure that primitives are perspective invariant. This is true for lines, polygons and NURBS (hence the interest in the last of these). S is for Scan-conversion. This is the stage which is concerned with mapping a geometric definition into an image.
Reference: [8] <author> T. L. J. Howard. </author> <title> A shareable centralised database for KRT 3 a hierarchical graphics system based on PHIGS. </title> <editor> In G. Marechal, editor, </editor> <booktitle> Proceedings Eurographics '87. </booktitle> <publisher> North-Holland, </publisher> <year> 1987. </year>
Reference-contexts: This becomes a severe problem if the model can change significantly between frames. Anyone who requires convincing of this should compare structure generation times required by PHIGS implementations with the corresponding traversal and rendering times. (PHIGS data structures are complicated! <ref> [8] </ref>) In future, user-steered calculations will require improved user interfaces which permit the operator to interact more closely with application models. The aim should be to achieve near real-time semantic feedback, rather than simple, local input device echoing (lexical feedback).
Reference: [9] <author> International Standards Organisation (ISO). </author> <title> ISO-7942 Information Processing Systems Computer Graphics Graphical Kernel System (GKS) Functional Description, </title> <year> 1985. </year>
Reference-contexts: This arrangement demands ultra-high speed networks, and the funding of these was one of the report's recommendations. This separation of graphics and interaction from application computations is a familiar theme in computer graphics. For example, it underpins the design of graphics standards such as GKS <ref> [9] </ref> and PHIGS [10]. In this paper, it is argued that this approach creates inflexible systems which are not appropriate for the purposes of scientific visualisation. 1 As a starting point it is useful to define the term visualisation.
Reference: [10] <author> International Standards Organisation (ISO). </author> <title> ISO 9592 Information Processing Systems Computer Graphics Programmer's Hierarchical Interactive Graphics System (PHIGS), </title> <year> 1989. </year>
Reference-contexts: This arrangement demands ultra-high speed networks, and the funding of these was one of the report's recommendations. This separation of graphics and interaction from application computations is a familiar theme in computer graphics. For example, it underpins the design of graphics standards such as GKS [9] and PHIGS <ref> [10] </ref>. In this paper, it is argued that this approach creates inflexible systems which are not appropriate for the purposes of scientific visualisation. 1 As a starting point it is useful to define the term visualisation. The Oxford English Dictionary gives: Visualize: to form a mental vision, image, picture of.
Reference: [11] <author> M. Jern. </author> <title> Visualization of scientific data. </title> <editor> In W. Purgathofer and J. Schonhut, editors, </editor> <booktitle> Advances in Computer Graphics V, </booktitle> <address> EurographicSeminars. </address> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Several companies which market software for displaying information in this form are capitalising on interest in visualisation; see for example <ref> [11] </ref>. This type of presentation requires careful thought. In his excellent book Tufte [18] gives numerous examples of good and bad practice for the display of quantitative information. Computer-generated figures come in for some justified criticism.
Reference: [12] <author> Oliver Jones. </author> <title> Introduction to the X Window System. </title> <publisher> Prentice-Hall, </publisher> <year> 1989. </year>
Reference-contexts: This is very much the strategy currently being pursued by researchers and by some hardware vendors. There is major interest in network computing which aims to put the display and interaction on the user's desktop, and developments such as the X Window System <ref> [12] </ref> and PEX [3] reinforce this direction. One clear benefit of the separation of the graphics from other parts of the application is that special-ised hardware can be designed to support the computationally-intensive parts of the graphics pipeline, especially transformations, clipping and rendering.
Reference: [13] <editor> A.A.M. Kuijk and W. Strasser, editors. </editor> <booktitle> Advances in Computer Graphics Hardware II. </booktitle> <address> Eurograph-icSeminars. </address> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: There have also been several implementations of ray tracing, which integrates the different stages of the pipeline into a single algorithm. A good survey of alternative approaches can be found in [4] and <ref> [13] </ref>. Significantly, relatively little work seems to be in progress on examining new graphics architectures, in which application computations and visualisation algorithms are closely coupled and distributed over large numbers of processors. Deriving new solutions to visualisation tasks for parallel machines is a challenging problem.
Reference: [14] <author> G.M. Murch. </author> <title> Human factors of color displays. </title> <editor> In F.R.A. Hopgood, R.J. Hubbold, and D.A. Duce, editors, </editor> <booktitle> Advances in Computer Graphics II, </booktitle> <address> EurographicSeminars. </address> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: Notwithstanding such efforts, the use of three-dimensional techniques to display such results is still in its infancy, and users require training before they can interpret the results. Colour has no intuitively obvious interpretation, except that blue is usually regarded as cold (low) whilst red is hot (high). Some experts <ref> [14] </ref> advocate using the spectral order: (low) V I B G Y O R (high) to show a range of values.
Reference: [15] <author> T.H. Myer and I.E. Sutherland. </author> <title> On the design of display processors. </title> <journal> Comm. ACM, </journal> <volume> 11, </volume> <year> 1968. </year>
Reference-contexts: In a network environment a decision must be made about what tasks to perform locally and what to do remotely. This thorny issue, identified as long ago as 1968 by Myer and Sutherland <ref> [15] </ref>, has plagued system implementors for years. Any solution tends to be dominated by current hardware. As technology changes, the balance of processing for the ideal solution keeps migrating back and forth between the remote and local processors.
Reference: [16] <author> NSF. </author> <title> Visualization in scientific computing. </title> <journal> ACM Computer Graphics (Special Issue), </journal> <volume> 21, </volume> <year> 1987. </year>
Reference-contexts: 1 Introduction The upsurge of interest in visualisation was given a major impetus by a report prepared for the National Science Foundation in the USA (the ViSC report) <ref> [16] </ref>. The main thrust of this was to examine how the USA could remain competitive in this area, and therefore what research should be funded by the government.
Reference: [17] <author> V.S. Ramachandran. </author> <title> Perceiving shape from shading. </title> <publisher> Scientific American, </publisher> <month> August </month> <year> 1988. </year>
Reference-contexts: In a particularly interesting paper 3 <ref> [17] </ref>, Ramachandran argues that humans are conditioned to seeing objects illuminated from above.
Reference: [18] <author> Edward R. Tufte. </author> <title> The Visual Dispay of Quantitative Information. </title> <publisher> Graphics Press, </publisher> <address> Box 430, Cheshire, CT 06410, </address> <year> 1983. </year>
Reference-contexts: Several companies which market software for displaying information in this form are capitalising on interest in visualisation; see for example [11]. This type of presentation requires careful thought. In his excellent book Tufte <ref> [18] </ref> gives numerous examples of good and bad practice for the display of quantitative information. Computer-generated figures come in for some justified criticism. Indeed, it is difficult to see how some of the graphics in his book could be produced by a program without considerable difficulty.
Reference: [19] <author> C. Upson, T. Faulhaber Jr., D. Kamins, D. Laidlaw, D. Schlegel, J. Vroom, R. Gurwitz, and A. van Dam. </author> <title> The Application Visualization System: a computational environment for scientific visualization. </title> <journal> IEEE Computer Graphics and Applications, </journal> <month> July </month> <year> 1989. </year>
Reference-contexts: Techniques are needed which facilitate the display of different time steps, either side by side or superimposed, with transparency techniques and colouring schemes employed to highlight differ ences. One way to display motion in a continuum is to use particle clouds. Upson et al <ref> [19] </ref> report that motions of individual points can be tracked if the number of particles is small, but that as the point density is increased then ambiguities occur.
Reference: [20] <author> D. </author> <title> Voorhies. </title> <journal> Reduced-complexity graphics. IEEE Computer Graphics and Applications, </journal> <month> July </month> <year> 1989. </year>
Reference-contexts: Hitherto, many workstations have implemented all stages of this process, except generation, in special hardware. They can be characterised as G-TXSD 1 systems. There are already indications that display manufacturers have begun to recognise the dangers of this black-box approach. Machines like the Ardent Titan [2] and Apollo DN10000 <ref> [20] </ref> carry out much of the graphics pipeline processing in their general purpose processors, rather than in special hardware, yielding greater flexibility. The Titan can be characterised as a GTX-SD machine, in which only the scan-conversion (of triangles) and display are handled by special hardware.
References-found: 21

