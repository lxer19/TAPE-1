URL: http://www.ai.sri.com/~luong/research/publications/ijcv-self-calib.ps.Z
Refering-URL: http://www.ai.sri.com/~luong/research/publications/publications.html
Root-URL: 
Email: qtluong@nefeli.CS.Berkeley.EDU  faugeras@sophia.inria.fr  
Title: Self-calibration of a moving camera from point correspondences and fundamental matrices  
Author: Q.-T. LUONG O.D. FAUGERAS 
Keyword: Camera calibration, projective geometry, Euclidean geometry, Kruppa equations  
Address: 333 Ravenswood av, Menlo Park, CA 94025, USA  2004 route des Lucioles, B.P. 93 06902 Sophia-Antipolis, France  
Affiliation: SRI International,  I.N.R.I.A.,  
Note: International Journal of Computer Vision, 1, 5-40 (1) c 1 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Abstract: We address the problem of estimating three-dimensional motion, and structure from motion with an uncalibrated moving camera. We show that point correspondences between three images, and the fundamental matrices computed from these point correspondences, are sufficient to recover the internal orientation of the camera (its calibration), the motion parameters, and to compute coherent perspective projection matrices which enable us to reconstruct 3-D structure up to a similarity. In contrast with other methods, no calibration object with a known 3-D shape is needed, and no limitations are put upon the unknown motions to be performed or the parameters to be recovered, as long as they define a projective camera. The theory of the method, which is based on the constraint that the observed points are part of a static scene, thus allowing us to link the intrinsic parameters and the fundamental matrix via the absolute conic, is first detailed. Several algorithms are then presented, and their performances compared by means of extensive simulations and illustrated by several experiments with real images. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> N. Ayache. </author> <title> Stereovision and sensor fusion. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Self-calibration of a moving camera 39 5. As it is a classical tool in computer vision, we do not give details on the filter itself, and rather invite the interested reader to read the classical references [23] [39], or the more practical presentations which can be found in <ref> [1] </ref>, [11], and [52]. 6.
Reference: 2. <author> A. Basu. </author> <title> Active calibration: alternative strategy and analysis. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 495-500, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: However, with the exception of Hartley [19], all of them have put more limitations on their methods than we did, by adding supplementary constraints, such as an initial knowledge of camera parameters which are then only updated [5], or restriction on the camera motions [9], <ref> [2] </ref>, [8], [48], [20]. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
Reference: 3. <author> P. Brand, R. Mohr, and P. Bobet. Distorsions op-tiques: </author> <title> correction dans un modele projectif. </title> <type> Technical Report RR-1933, </type> <institution> INRIA, </institution> <year> 1993. </year>
Reference-contexts: If such a correction is needed, it can be performed in a way compatible with the projective linear framework which is presented in this paper, as demonstrated by the work of Brand, Mohr, and Bobet <ref> [3] </ref>. Moreover, we believe that for several computer vision applications, such a correction is not even needed. <p> There are also a number of high-quality lenses, some of which quite cheap, for which the distortion is neglectible. In our own experiments with off-the-shelf cameras, as well as those conducted by <ref> [3] </ref> it was found that 8 Luong and Faugeras the correction to be applied in order to obtain a projective linear model was sub-pixellic. Unless feature detectors reach the same precision, which is not always guaranteed even with state-of-the art algorithms, the additional correction is not very useful. <p> Results of the intrinsic parameters estimation. method ff u ff v u 0 v 0 2 grid, image 1 657 1003 244 256 -2.05e-06 grid, image 2 664 1015 232 257 -7.47e-07 grid, image 3 639 980 252 249 -2.60e-06 average, [s.d.] 653 [10] 999 [14] 242 [8] 254 <ref> [3] </ref> Kruppa polynomial 639 982 258 341 -6.11e-03 Kruppa iterative 640 936 206 284 -0.07 Kruppa iterative (center) 681 985 255 255 average, [s.d.] 653 [19] 967 [22] 239 [23] 293 [35] The scale factors are determined with a good accuracy, however, this is not the case for the coordinates of
Reference: 4. <author> H.S.M. Coxeter. </author> <title> Projective Geometry. </title> <publisher> Springer Ver-lag, </publisher> <address> second edition, </address> <year> 1987. </year>
Reference-contexts: Projective geometry is emerging as an attractive framework for com puter vision [40]. In this paper, we assume that the reader is familiar with some elemen tary projective geometry. Such material can be found in classical mathematic textbooks such as [42], <ref> [4] </ref>, [16], but also in the computer vision lit erature where it is presented in chapters of recent books [11], [25], [40], and articles [38], [24].
Reference: 5. <author> J. Crowley, P. Bobet, and C. Schmid. </author> <title> Maintaining stereo calibration by tracking image points. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 483-488, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: Thus a number of researchers have recently investigated self-calibration techniques. However, with the exception of Hartley [19], all of them have put more limitations on their methods than we did, by adding supplementary constraints, such as an initial knowledge of camera parameters which are then only updated <ref> [5] </ref>, or restriction on the camera motions [9], [2], [8], [48], [20]. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
Reference: 6. <author> R. Deriche and T. Blaszka. </author> <title> Recovering and characterizing image features using an efficient model based approach. </title> <booktitle> In Proc. International Conference on Computer Vision and Pattern Recognition, </booktitle> <year> 1993. </year>
Reference-contexts: We use between 20 and 30 corners, which are extracted with a sub-pixel accuracy, semi-automatically, by the program of T. Blaszka and R. Deriche <ref> [6] </ref>. Correspondence is performed manually. It should be noted that the corresponding points between pairs of images are different, that is, points need not be seen in the three views. Figure 13 shows the detected points of interest matched between image 1 and image 2.
Reference: 7. <author> R. Deriche, R. Vaillant, and O. Faugeras. </author> <title> From Noisy Edges Points to 3D Reconstruction of a Scene : A Robust Approach and Its Uncertainty Analysis, </title> <booktitle> volume 2, </booktitle> <pages> pages 71-79. </pages> <publisher> World Scientific, </publisher> <year> 1992. </year> <booktitle> Series in Machine Perception and Artificial Intelligence. </booktitle>
Reference-contexts: Fig. 16. Zoom on the photogrammetric triplet, showing corresponding epipolar lines. We have then performed a 3D trinocular reconstruction from the matched points, using our computed projection matrices as input for a the classical reconstruction algorithm of R. Vaillant and R. Deriche <ref> [7] </ref>. The 3D points are obtained in the coordinate system associated with one of the cameras, since we can reconstruct only up a similarity with the self-calibration technique.
Reference: 8. <author> L. Dron. </author> <title> Dynamic camera self-calibration from con-troled motion sequences. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 501-506, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: Table 7. Results of the intrinsic parameters estimation. method ff u ff v u 0 v 0 2 grid, image 1 657 1003 244 256 -2.05e-06 grid, image 2 664 1015 232 257 -7.47e-07 grid, image 3 639 980 252 249 -2.60e-06 average, [s.d.] 653 [10] 999 [14] 242 <ref> [8] </ref> 254 [3] Kruppa polynomial 639 982 258 341 -6.11e-03 Kruppa iterative 640 936 206 284 -0.07 Kruppa iterative (center) 681 985 255 255 average, [s.d.] 653 [19] 967 [22] 239 [23] 293 [35] The scale factors are determined with a good accuracy, however, this is not the case for the <p> However, with the exception of Hartley [19], all of them have put more limitations on their methods than we did, by adding supplementary constraints, such as an initial knowledge of camera parameters which are then only updated [5], or restriction on the camera motions [9], [2], <ref> [8] </ref>, [48], [20]. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
Reference: 9. <author> F. Du and M. Brady. </author> <title> Self-calibration of the intrinsic parameters of cameras for active vision systems. </title> <booktitle> In Proc. of the conf. on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 477-482, </pages> <address> New-York, </address> <year> 1993. </year>
Reference-contexts: However, with the exception of Hartley [19], all of them have put more limitations on their methods than we did, by adding supplementary constraints, such as an initial knowledge of camera parameters which are then only updated [5], or restriction on the camera motions <ref> [9] </ref>, [2], [8], [48], [20]. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated.
Reference: 10. <author> J.Q. Fang and T.S. Huang. </author> <title> Some experiments on estimating the 3D motion parameters of a rigid body from two consecutive image frames. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 545-554, </pages> <year> 1984. </year>
Reference-contexts: error on the rotation, initialization with the results of FACTOR (2) and an arbitrary motion (3) Note that even using MIN-LIN, the results are much more precise than those usually found by us Self-calibration of a moving camera 23 ing a purely linear methods such as the eight-point algorithm [46], <ref> [10] </ref>. Fig. 7. Relative error on the translation, initialization with the results of FACTOR (2) and an arbitrary motion (3) Sensitivity to errors on the intrinsic parameters Very few results are available concerning the sensitivity of motion and structure computations to errors on the intrinsic parameters [27]. <p> Table 7. Results of the intrinsic parameters estimation. method ff u ff v u 0 v 0 2 grid, image 1 657 1003 244 256 -2.05e-06 grid, image 2 664 1015 232 257 -7.47e-07 grid, image 3 639 980 252 249 -2.60e-06 average, [s.d.] 653 <ref> [10] </ref> 999 [14] 242 [8] 254 [3] Kruppa polynomial 639 982 258 341 -6.11e-03 Kruppa iterative 640 936 206 284 -0.07 Kruppa iterative (center) 681 985 255 255 average, [s.d.] 653 [19] 967 [22] 239 [23] 293 [35] The scale factors are determined with a good accuracy, however, this is not
Reference: 11. <author> O.D. Faugeras. </author> <title> Three-dimensional computer vision: a geometric viewpoint. </title> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: In this paper, we assume that the reader is familiar with some elemen tary projective geometry. Such material can be found in classical mathematic textbooks such as [42], [4], [16], but also in the computer vision lit erature where it is presented in chapters of recent books <ref> [11] </ref>, [25], [40], and articles [38], [24]. <p> The epipolar geometry. is closely related to the problem of camera calibration and motion estimation because it has the fundamental property of being invariant under rigid displacements, a fact already known to Cayley. The proof of this can be found in [14], <ref> [11] </ref>. Let us examine the consequences of this invariance. Since the absolute conic is invariant under rigid displacements, its image by the camera, which is also a conic with only complex points, does not depend on the pose of the camera. <p> Therefore, its equation in the retinal coordinate system (o; u; v) does not depend on the extrinsic parameters and depends only on the intrinsic parameters. By taking the identity displacement as extrinsic parameters, it is easily seen <ref> [11] </ref>, [30], that the matrix defining the equation of the image of the absolute conic in the retinal co ordinate system (o; u; v) is: B = A T A 1 (7) One of the important ideas which has emerged from our previous work [14], [38], [12] and will also become <p> Self-calibration of a moving camera 39 5. As it is a classical tool in computer vision, we do not give details on the filter itself, and rather invite the interested reader to read the classical references [23] [39], or the more practical presentations which can be found in [1], <ref> [11] </ref>, and [52]. 6.
Reference: 12. <author> O.D. Faugeras, Q.-T. Luong, and S.J. Maybank. </author> <title> Camera self-calibration: theory and experiments. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 321-334, </pages> <address> Santa-Margerita, Italy, </address> <year> 1992. </year>
Reference-contexts: it is easily seen [11], [30], that the matrix defining the equation of the image of the absolute conic in the retinal co ordinate system (o; u; v) is: B = A T A 1 (7) One of the important ideas which has emerged from our previous work [14], [38], <ref> [12] </ref> and will also become apparent in this paper, is that the absolute conic can be used as a calibration pattern for the camera. This calibration pattern has the nice properties of always being present and of being free. 2.2. <p> A snake-based ellipse localization program due to B. Bascle, has also been tried. 9. This is typical, more precise results have been some times achieved. 10.The methods described in this paper were first described in [30]. Parts of the results were presented in <ref> [12] </ref>, [32], [33].
Reference: 13. <author> O.D. Faugeras, F. Lustman, and G. Toscani. </author> <title> Motion and Structure from point and line matches. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 25-34, </pages> <month> June </month> <year> 1987. </year>
Reference-contexts: By combining the computation of motion with the computation of the intrinsic parameters we obtain another iterative approach to self-calibration, which we compare to the Kruppa approach. 4.1. Computing the motion after calibrating The motion determination problem from point correspondences is very classical. See <ref> [13] </ref> [43] [50] [21] for solutions similar to ours. There are two different solutions, both based on the computation of the fundamental matrix. <p> We have seen that during the course of intrinsic parameters estimation, we had to compute the fundamental matrix F, from which the essential matrix is immediately obtained: E = A T FA (20) The problem of finding the rotation R and the translation t from E is classical [29], [46], <ref> [13] </ref>, [18]. We denote this algorithm by FACTOR. An iterative solution An alternative method is to use directly the error function that has been used to determine the fundamental matrix.
Reference: 14. <author> O.D. Faugeras and S.J. Maybank. </author> <title> Motion from point matches: multiplicity of solutions. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 4(3) </volume> <pages> 225-246, </pages> <year> 1990. </year> <note> also INRIA Tech. Report 1157. </note>
Reference-contexts: The properties of the E-matrix are now well understood after the work of Faugeras, Huang, and Maybank [22], <ref> [14] </ref>, [37]. This matrix must satisfy a number of algebraic constraints which are not taken into account by the eight 6 Luong and Faugeras point algorithm. Taking these constraints into account forces to use nonlinear methods such as the five-point algorithm of Faugeras and Maybank [14]. <p> Faugeras, Huang, and Maybank [22], <ref> [14] </ref>, [37]. This matrix must satisfy a number of algebraic constraints which are not taken into account by the eight 6 Luong and Faugeras point algorithm. Taking these constraints into account forces to use nonlinear methods such as the five-point algorithm of Faugeras and Maybank [14]. The internal parameters of the cameras are traditionally determined by observing a known calibration object (see [45] for a review), prior to the execution of the vision task. However, there are several applications for which a calibration object is not available, or its use is too cumbersome. <p> The absolute conic was used in <ref> [14] </ref> to compute the number of solutions to the problem of estimating the motion of a camera from five point correspondences in two views and in [38] to study the problem of camera calibration. <p> The epipolar geometry. is closely related to the problem of camera calibration and motion estimation because it has the fundamental property of being invariant under rigid displacements, a fact already known to Cayley. The proof of this can be found in <ref> [14] </ref>, [11]. Let us examine the consequences of this invariance. Since the absolute conic is invariant under rigid displacements, its image by the camera, which is also a conic with only complex points, does not depend on the pose of the camera. <p> extrinsic parameters, it is easily seen [11], [30], that the matrix defining the equation of the image of the absolute conic in the retinal co ordinate system (o; u; v) is: B = A T A 1 (7) One of the important ideas which has emerged from our previous work <ref> [14] </ref>, [38], [12] and will also become apparent in this paper, is that the absolute conic can be used as a calibration pattern for the camera. This calibration pattern has the nice properties of always being present and of being free. 2.2. <p> The Kruppa equations: a geometric interpretation of the rigidity constraint The Kruppa equations [26] are obtained from a geometric interpretation of the rigidity constraints. They were first introduced in the field of computer vision by Faugeras and Maybank for the study of motion <ref> [14] </ref>, and then to develop a theory of self-calibration [38]. In this exposition, we will return to the original formulation, which doesn't assume that the two cameras are identical, which is useful to prove the equivalence of the Kruppa equations and the Huang and Faugeras constraint. <p> Table 7. Results of the intrinsic parameters estimation. method ff u ff v u 0 v 0 2 grid, image 1 657 1003 244 256 -2.05e-06 grid, image 2 664 1015 232 257 -7.47e-07 grid, image 3 639 980 252 249 -2.60e-06 average, [s.d.] 653 [10] 999 <ref> [14] </ref> 242 [8] 254 [3] Kruppa polynomial 639 982 258 341 -6.11e-03 Kruppa iterative 640 936 206 284 -0.07 Kruppa iterative (center) 681 985 255 255 average, [s.d.] 653 [19] 967 [22] 239 [23] 293 [35] The scale factors are determined with a good accuracy, however, this is not the case
Reference: 15. <author> O.D. Faugeras and G. Toscani. </author> <title> The calibration problem for stereo. </title> <booktitle> In Proceedings of CVPR'86, </booktitle> <pages> pages 15-20, </pages> <year> 1986. </year>
Reference-contexts: A pair of images with the detected corners superimposed. Note that only few of the points are on the calibration grid. The standard calibration is performed on each image, using the algorithm of Robert [41], which is a much improved version of the linear method of Faugeras and Toscani <ref> [15] </ref>. From the projection matrices obtained by this al gorithm, the three fundamental matrices F 12 , F 23 , F 13 are computed and used as a reference for the comparisons with our algorithm which computes the fundamental matrices from the point matches.
Reference: 16. <author> L.E. Garner. </author> <title> An outline of projective geometry. </title> <publisher> El-sevier North Holland, </publisher> <year> 1981. </year>
Reference-contexts: Projective geometry is emerging as an attractive framework for com puter vision [40]. In this paper, we assume that the reader is familiar with some elemen tary projective geometry. Such material can be found in classical mathematic textbooks such as [42], [4], <ref> [16] </ref>, but also in the computer vision lit erature where it is presented in chapters of recent books [11], [25], [40], and articles [38], [24].
Reference: 17. <author> G.H. Golub and C.F. Van Loan. </author> <title> Matrix computations. </title> <publisher> The John Hopkins University Press, </publisher> <year> 1989. </year>
Reference-contexts: Since B fl is proportional to the inverse of B, and since we are dealing with matrices defined up to a scale factor, we can take, using (7): K = AA T (14) This makes explicit the fact that the matrix A can be obtained uniquely from the Cholesky decomposition <ref> [17] </ref> of the symmetric matrix K when this matrix is positive definite, which is always the case since ! has only complex points.
Reference: 18. <author> R.I. </author> <title> Hartley. Estimation of relative camera positions for uncalibrated cameras. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 579-587, </pages> <year> 1992. </year>
Reference-contexts: But Trivedi pointed out that the three equations reduce to two independent equations, and a tautology, and thus that there are not enough constraints for the problem to be solved. Recently, Hartley <ref> [18] </ref> has brought a partial solution using a simplified camera model, where the only unknown is the focal distance, thus taking as a model for the intrinsic parameters: A = 4 0 1 0 3 2 1 0 0 0 0 k 0 5 He exhibits an algorithm to factor the <p> have seen that during the course of intrinsic parameters estimation, we had to compute the fundamental matrix F, from which the essential matrix is immediately obtained: E = A T FA (20) The problem of finding the rotation R and the translation t from E is classical [29], [46], [13], <ref> [18] </ref>. We denote this algorithm by FACTOR. An iterative solution An alternative method is to use directly the error function that has been used to determine the fundamental matrix.
Reference: 19. <author> R.I. </author> <title> Hartley. An algorithm for self calibration from several views. </title> <booktitle> In Proc. Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 908-912, </pages> <address> Seattle, WA, </address> <year> 1994. </year>
Reference-contexts: grid, image 2 664 1015 232 257 -7.47e-07 grid, image 3 639 980 252 249 -2.60e-06 average, [s.d.] 653 [10] 999 [14] 242 [8] 254 [3] Kruppa polynomial 639 982 258 341 -6.11e-03 Kruppa iterative 640 936 206 284 -0.07 Kruppa iterative (center) 681 985 255 255 average, [s.d.] 653 <ref> [19] </ref> 967 [22] 239 [23] 293 [35] The scale factors are determined with a good accuracy, however, this is not the case for the coordinates of the principal point. Thus the best is to assume that it is at the center of the image. <p> Thus a number of researchers have recently investigated self-calibration techniques. However, with the exception of Hartley <ref> [19] </ref>, all of them have put more limitations on their methods than we did, by adding supplementary constraints, such as an initial knowledge of camera parameters which are then only updated [5], or restriction on the camera motions [9], [2], [8], [48], [20]. <p> Another approach, which is complementary to the one described in this paper, is to use a stationary camera [20], [36]. More precise and robust results can be obtained, since the problem is more constrained. The only equivalent approach has been recently 10 presented by Hartley <ref> [19] </ref>. There are a number of similarities in the steps of the algorithm, although each step is quite differently done. The middle steps are in both methods non-iterative computations mixed with small-scale optimizations based on motion parameters in order to find an initialization for the camera parameters.
Reference: 20. <author> R.I. </author> <title> Hartley. Self-calibration from multiple views with a rotating camera. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 471-478, </pages> <address> Stockholm, Swe-den, </address> <year> 1994. </year>
Reference-contexts: However, self-calibration is even easier in this case, since instead of two quadratic constraints on the entries of K, one obtains five linear constraints on these entries, as shown in <ref> [20] </ref>, [36]. In the case where the displacement is a pure translation (the rotation is the identity R = I 3 ), it can be seen from (10) and (11) that the fundamental matrix is antisymmetric. <p> However, with the exception of Hartley [19], all of them have put more limitations on their methods than we did, by adding supplementary constraints, such as an initial knowledge of camera parameters which are then only updated [5], or restriction on the camera motions [9], [2], [8], [48], <ref> [20] </ref>. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated. <p> Another approach, which is complementary to the one described in this paper, is to use a stationary camera <ref> [20] </ref>, [36]. More precise and robust results can be obtained, since the problem is more constrained. The only equivalent approach has been recently 10 presented by Hartley [19]. There are a number of similarities in the steps of the algorithm, although each step is quite differently done.
Reference: 21. <author> B.K.P. Horn. </author> <title> Relative orientation. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 4(1) </volume> <pages> 59-78, </pages> <month> Jan. </month> <year> 1990. </year>
Reference-contexts: By combining the computation of motion with the computation of the intrinsic parameters we obtain another iterative approach to self-calibration, which we compare to the Kruppa approach. 4.1. Computing the motion after calibrating The motion determination problem from point correspondences is very classical. See [13] [43] [50] <ref> [21] </ref> for solutions similar to ours. There are two different solutions, both based on the computation of the fundamental matrix.
Reference: 22. <author> T.S. Huang and O.D. Faugeras. </author> <title> Some properties of the E-matrix in two view motion estimation. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 11 </volume> <pages> 1310-1312, </pages> <year> 1989. </year>
Reference-contexts: The properties of the E-matrix are now well understood after the work of Faugeras, Huang, and Maybank <ref> [22] </ref>, [14], [37]. This matrix must satisfy a number of algebraic constraints which are not taken into account by the eight 6 Luong and Faugeras point algorithm. Taking these constraints into account forces to use nonlinear methods such as the five-point algorithm of Faugeras and Maybank [14]. <p> It can be seen that the two equations (10) and (8) are equivalent, and that we have the relation: F = A T EA 1 Unlike the essential matrix, which is characterized by the two constraints found by Huang and Faugeras <ref> [22] </ref> which are the nullity of the determi nant and the equality of the two non-zero singular values, the only constraint on the fundamental matrix is that it is of rank two. 2.3. <p> 2 664 1015 232 257 -7.47e-07 grid, image 3 639 980 252 249 -2.60e-06 average, [s.d.] 653 [10] 999 [14] 242 [8] 254 [3] Kruppa polynomial 639 982 258 341 -6.11e-03 Kruppa iterative 640 936 206 284 -0.07 Kruppa iterative (center) 681 985 255 255 average, [s.d.] 653 [19] 967 <ref> [22] </ref> 239 [23] 293 [35] The scale factors are determined with a good accuracy, however, this is not the case for the coordinates of the principal point. Thus the best is to assume that it is at the center of the image.
Reference: 23. <author> A.M. Jazwinsky. </author> <title> Stochastic processes and filtering theory. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1970. </year>
Reference-contexts: 1015 232 257 -7.47e-07 grid, image 3 639 980 252 249 -2.60e-06 average, [s.d.] 653 [10] 999 [14] 242 [8] 254 [3] Kruppa polynomial 639 982 258 341 -6.11e-03 Kruppa iterative 640 936 206 284 -0.07 Kruppa iterative (center) 681 985 255 255 average, [s.d.] 653 [19] 967 [22] 239 <ref> [23] </ref> 293 [35] The scale factors are determined with a good accuracy, however, this is not the case for the coordinates of the principal point. Thus the best is to assume that it is at the center of the image. <p> The results improve if one considers more displace ments. See next paragraph. Self-calibration of a moving camera 39 5. As it is a classical tool in computer vision, we do not give details on the filter itself, and rather invite the interested reader to read the classical references <ref> [23] </ref> [39], or the more practical presentations which can be found in [1], [11], and [52]. 6.
Reference: 24. <author> K. Kanatani. </author> <title> Computational projective geometry. Computer Vision, Graphics, </title> <booktitle> and Image Processing. Image Understanding, </booktitle> <volume> 54(3), </volume> <year> 1991. </year>
Reference-contexts: Such material can be found in classical mathematic textbooks such as [42], [4], [16], but also in the computer vision lit erature where it is presented in chapters of recent books [11], [25], [40], and articles [38], <ref> [24] </ref>. Using equation (1) and the basic properties of changes of coordinate systems, we can ex press the relation between the image coordinates in the (o; u; v) coordinate system and the three dimensional coordinates in the O; x; y; z) coordi nate system by the following equation Fig. 1.
Reference: 25. <author> K. Kanatani. </author> <title> Geometric computation for machine vision. </title> <publisher> Oxford university press, </publisher> <year> 1992. </year>
Reference-contexts: In this paper, we assume that the reader is familiar with some elemen tary projective geometry. Such material can be found in classical mathematic textbooks such as [42], [4], [16], but also in the computer vision lit erature where it is presented in chapters of recent books [11], <ref> [25] </ref>, [40], and articles [38], [24].
Reference: 26. <author> E. Kruppa. </author> <title> Zur Ermittlung eines Objektes aus zwei Perspektiven mit innerer Orientierung. </title> <journal> Sitz.-Ber. Akad. Wiss., Wien, math. naturw. Kl., Abt. IIa., </journal> <volume> 122 </volume> <pages> 1939-1948, </pages> <year> 1913. </year>
Reference-contexts: It is why we are going to consider a geometrical interpretation of the rigidity constraint which yields low-order polynomial constraints. The Kruppa equations: a geometric interpretation of the rigidity constraint The Kruppa equations <ref> [26] </ref> are obtained from a geometric interpretation of the rigidity constraints. They were first introduced in the field of computer vision by Faugeras and Maybank for the study of motion [14], and then to develop a theory of self-calibration [38].
Reference: 27. <author> R. Kumar and A. Hanson. </author> <title> Sensibility of the pose refinement problem to accurate estimation of camera parameters. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <pages> pages 365-369, </pages> <address> Osaka, Japan, </address> <year> 1990. </year>
Reference-contexts: Fig. 7. Relative error on the translation, initialization with the results of FACTOR (2) and an arbitrary motion (3) Sensitivity to errors on the intrinsic parameters Very few results are available concerning the sensitivity of motion and structure computations to errors on the intrinsic parameters <ref> [27] </ref>. It is nevertheless an important issue, as it determines the precision of calibration that it is necessary to achieve to obtain a given precision on the three dimensional reconstruction, which is the final objective. We present here some experimental results which give an idea of the numerical values.
Reference: 28. <author> R.V.R. Kumar, A. Tirumalai, and R.C. Jain. </author> <title> A nonlinear optimization algorithm for the estimation of structure and motion parameters. </title> <booktitle> In Proc. International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 136-143, </pages> <year> 1989. </year>
Reference-contexts: 14 13 30 27 30 28 10 6 13 7 13 19 23 24 24 1.0 3 38 35 39 36 52 50 57 55 10 28 35 29 37 44 46 51 48 Thus, statistically, the global minimization gives better results, a finding consistent with those of [50] and <ref> [28] </ref>. However, if the starting point is precise, as in table 5, where it is found by the minimization method using a larger number of displacements, it can be seen that the results are slightly better, which may be due to the fact that uncertainty is taken into account.
Reference: 29. <author> H.C. Longuet-Higgins. </author> <title> A Computer Algorithm for Reconstructing a Scene from Two Projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year> <note> 40 Luong and Faugeras </note>
Reference-contexts: In this article we will assume the most general case of the full perspective image formation model. When matching points, two views are sufficient and the computation of the motion is usually based upon the estimation of a matrix called the Essential, or E-matrix after Longuet-Higgins <ref> [29] </ref> who first published a linear algorithm (called the eight-point algorithm because it requires eight point correspondences over two frames) for estimating this matrix and recover the camera displacement from it from a number of point matches. <p> Since the matrix is defined up to a scale factor, it depends upon seven independent parameters. Equation (8) is the analog in the uncalibrated case of the so-called Longuet-Higgins equation <ref> [29] </ref>. Indeed, in the case of calibrated cameras, the 2D projective coordinates of a point m give the 3-D direction of the optical ray Cm (see figure 2), which is of course not the case with retinal (uncalibrated) coordinates. <p> direct factorization We have seen that during the course of intrinsic parameters estimation, we had to compute the fundamental matrix F, from which the essential matrix is immediately obtained: E = A T FA (20) The problem of finding the rotation R and the translation t from E is classical <ref> [29] </ref>, [46], [13], [18]. We denote this algorithm by FACTOR. An iterative solution An alternative method is to use directly the error function that has been used to determine the fundamental matrix.
Reference: 30. <author> Q.-T. Luong. </author> <title> Matrice fondamentale et auto-calibration en vision par ordinateur. </title> <type> PhD thesis, </type> <institution> Uni-versite de Paris-Sud, Orsay, </institution> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: Therefore, its equation in the retinal coordinate system (o; u; v) does not depend on the extrinsic parameters and depends only on the intrinsic parameters. By taking the identity displacement as extrinsic parameters, it is easily seen [11], <ref> [30] </ref>, that the matrix defining the equation of the image of the absolute conic in the retinal co ordinate system (o; u; v) is: B = A T A 1 (7) One of the important ideas which has emerged from our previous work [14], [38], [12] and will also become apparent <p> It means that the most precise feature detectors need to be used. Some types of displacements will not work well, specifically those leading to nearly degenerate cases for Kruppa equations, mentioned in this section, and those leading to unstable computation of the fundamental matrix, which are studied in <ref> [30] </ref>, [35]. 20 Luong and Faugeras Another limitation might be that the method does not give an accurate estimation for the position of the principal point, and the angle of the retinal axes. <p> rather long focal length, which is not very favorable, and that among the three motions between pairs of images, the motion 2-3, whose translation vector was found to be t 23 = (1:186; 0:6623; 0:0857) T , is nearly parallel to the image plane, a defavorable configuration, as shown in <ref> [30] </ref>, [35]. However, the epipolar geometry found from the three projection matrices obtained by self-calibration is fairly coherent, as illustrated in figure 16, which shows a zoom with the epipolar lines of one the point of interest. Fig. 16. Zoom on the photogrammetric triplet, showing corresponding epipolar lines. <p> A snake-based ellipse localization program due to B. Bascle, has also been tried. 9. This is typical, more precise results have been some times achieved. 10.The methods described in this paper were first described in <ref> [30] </ref>. Parts of the results were presented in [12], [32], [33].
Reference: 31. <author> Q.-T. Luong, R. Deriche, O.D. Faugeras, and T. Pa-padopoulo. </author> <title> On determining the Fundamental matrix: analysis of different methods and experimental results. </title> <type> Technical Report RR-1894, </type> <institution> INRIA, </institution> <year> 1993. </year>
Reference-contexts: 627.92 950.11 245.16 300.56 Y 1,2,3 669.62 [42.6] 1013.85 [79.2] 260.16 [23.3] 270.23 [32.3] The experimental procedure consisted in choosing three displacements, generating point correspondences by projecting in the two retinas a set of random 3D points and adding Gaussian image noise, computing the fundamental matrix with a non-linear method <ref> [31] </ref> from these point correspondences, and then use the continuation algorithm to solve the Kruppa equations obtained from the fundamental matrices. <p> We denote this algorithm by FACTOR. An iterative solution An alternative method is to use directly the error function that has been used to determine the fundamental matrix. It differs from the previous one by the fact that it uses again the measured points In <ref> [31] </ref>, [51] different parameterizations for this matrix have been proposed to take into account constraints on its structure and linear and non-linear criteria for its estimation were also considered.
Reference: 32. <author> Q.-T. Luong and O.D. Faugeras. </author> <title> Self-calibration of a camera using multiples images. </title> <booktitle> In Proc. International Conference on Pattern Recognition, </booktitle> <pages> pages 9-12, </pages> <address> Den Hag, The Netherlands, </address> <year> 1992. </year>
Reference-contexts: A snake-based ellipse localization program due to B. Bascle, has also been tried. 9. This is typical, more precise results have been some times achieved. 10.The methods described in this paper were first described in [30]. Parts of the results were presented in [12], <ref> [32] </ref>, [33].
Reference: 33. <author> Q.-T. Luong and O.D. Faugeras. </author> <title> An optimization framework for efficient self-calibration and motion determination. </title> <booktitle> In Proc. International Conference on Pattern Recognition, pages A-248-252, </booktitle> <address> Jerusalem, Is-rael, </address> <year> 1994. </year>
Reference-contexts: A snake-based ellipse localization program due to B. Bascle, has also been tried. 9. This is typical, more precise results have been some times achieved. 10.The methods described in this paper were first described in [30]. Parts of the results were presented in [12], [32], <ref> [33] </ref>.
Reference: 34. <author> Q.-T. Luong and O.D. Faugeras. </author> <title> A stability analysis of the fundamental matrix. </title> <booktitle> In Proc. European Conference on Computer Vision, </booktitle> <pages> pages 577-588, </pages> <address> Stock-holm, Sweden, </address> <year> 1994. </year>
Reference-contexts: The uncertainty on the fundamental ma trices is needed. It is obtained using the method described in <ref> [34] </ref>, [35]. Statistical results have been conducted to see the effect of the increase of the number of displacements and to compare the Kalman method Self-calibration of a moving camera 19 to the batch minimization approach 6 .
Reference: 35. <author> Q.-T. Luong and O.D. Faugeras. </author> <title> The fundamental matrix: theory, algorithms, and stability analysis. </title> <journal> Intl. Journal of Computer Vision, </journal> <note> 1995. To appear. </note>
Reference-contexts: The uncertainty on the fundamental ma trices is needed. It is obtained using the method described in [34], <ref> [35] </ref>. Statistical results have been conducted to see the effect of the increase of the number of displacements and to compare the Kalman method Self-calibration of a moving camera 19 to the batch minimization approach 6 . <p> It means that the most precise feature detectors need to be used. Some types of displacements will not work well, specifically those leading to nearly degenerate cases for Kruppa equations, mentioned in this section, and those leading to unstable computation of the fundamental matrix, which are studied in [30], <ref> [35] </ref>. 20 Luong and Faugeras Another limitation might be that the method does not give an accurate estimation for the position of the principal point, and the angle of the retinal axes. <p> 257 -7.47e-07 grid, image 3 639 980 252 249 -2.60e-06 average, [s.d.] 653 [10] 999 [14] 242 [8] 254 [3] Kruppa polynomial 639 982 258 341 -6.11e-03 Kruppa iterative 640 936 206 284 -0.07 Kruppa iterative (center) 681 985 255 255 average, [s.d.] 653 [19] 967 [22] 239 [23] 293 <ref> [35] </ref> The scale factors are determined with a good accuracy, however, this is not the case for the coordinates of the principal point. Thus the best is to assume that it is at the center of the image. <p> long focal length, which is not very favorable, and that among the three motions between pairs of images, the motion 2-3, whose translation vector was found to be t 23 = (1:186; 0:6623; 0:0857) T , is nearly parallel to the image plane, a defavorable configuration, as shown in [30], <ref> [35] </ref>. However, the epipolar geometry found from the three projection matrices obtained by self-calibration is fairly coherent, as illustrated in figure 16, which shows a zoom with the epipolar lines of one the point of interest. Fig. 16. Zoom on the photogrammetric triplet, showing corresponding epipolar lines.
Reference: 36. <author> Q.-T. Luong and T. Vieville. </author> <title> Canonic representations for the geometries of multiple projective views. </title> <type> Technical Report UCB/CSD-93-772, </type> <institution> University of Califor-nia at Berkeley, </institution> <month> Sept </month> <year> 1993. </year> <note> A shorter version appeared in ECCV'94. </note>
Reference-contexts: However, self-calibration is even easier in this case, since instead of two quadratic constraints on the entries of K, one obtains five linear constraints on these entries, as shown in [20], <ref> [36] </ref>. In the case where the displacement is a pure translation (the rotation is the identity R = I 3 ), it can be seen from (10) and (11) that the fundamental matrix is antisymmetric. <p> Another approach, which is complementary to the one described in this paper, is to use a stationary camera [20], <ref> [36] </ref>. More precise and robust results can be obtained, since the problem is more constrained. The only equivalent approach has been recently 10 presented by Hartley [19]. There are a number of similarities in the steps of the algorithm, although each step is quite differently done.
Reference: 37. <author> S.J. Maybank. </author> <title> The projective geometry of ambiguous surfaces. </title> <journal> Proc. of the Royal Society London A, </journal> <volume> 332 </volume> <pages> 1-47, </pages> <year> 1990. </year>
Reference-contexts: The properties of the E-matrix are now well understood after the work of Faugeras, Huang, and Maybank [22], [14], <ref> [37] </ref>. This matrix must satisfy a number of algebraic constraints which are not taken into account by the eight 6 Luong and Faugeras point algorithm. Taking these constraints into account forces to use nonlinear methods such as the five-point algorithm of Faugeras and Maybank [14].
Reference: 38. <author> S.J. Maybank and O.D. Faugeras. </author> <title> A Theory of Self-Calibration of a Moving Camera. </title> <journal> The International Journal of Computer Vision, </journal> <volume> 8(2) </volume> <pages> 123-151, </pages> <year> 1992. </year>
Reference-contexts: Such material can be found in classical mathematic textbooks such as [42], [4], [16], but also in the computer vision lit erature where it is presented in chapters of recent books [11], [25], [40], and articles <ref> [38] </ref>, [24]. <p> The absolute conic was used in [14] to compute the number of solutions to the problem of estimating the motion of a camera from five point correspondences in two views and in <ref> [38] </ref> to study the problem of camera calibration. The absolute conic lies in the plane at infinity of equation T = 0 and its equation is X 2 + Y 2 + Z 2 = 0 (6) All points on that conic have complex coordinates. <p> parameters, it is easily seen [11], [30], that the matrix defining the equation of the image of the absolute conic in the retinal co ordinate system (o; u; v) is: B = A T A 1 (7) One of the important ideas which has emerged from our previous work [14], <ref> [38] </ref>, [12] and will also become apparent in this paper, is that the absolute conic can be used as a calibration pattern for the camera. This calibration pattern has the nice properties of always being present and of being free. 2.2. <p> They were first introduced in the field of computer vision by Faugeras and Maybank for the study of motion [14], and then to develop a theory of self-calibration <ref> [38] </ref>. In this exposition, we will return to the original formulation, which doesn't assume that the two cameras are identical, which is useful to prove the equivalence of the Kruppa equations and the Huang and Faugeras constraint. Let consider an epipolar plane , which is tangent to .
Reference: 39. <author> P.S. Maybeck. </author> <title> Stochastic models, estimation and control. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: The results improve if one considers more displace ments. See next paragraph. Self-calibration of a moving camera 39 5. As it is a classical tool in computer vision, we do not give details on the filter itself, and rather invite the interested reader to read the classical references [23] <ref> [39] </ref>, or the more practical presentations which can be found in [1], [11], and [52]. 6.
Reference: 40. <author> J. L. Mundy and A. Zisserman, </author> <title> editors. Geometric invariance in computer vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: The fact that no nonlinear camera distortion is considered allows us to use the powerful tools of projective geometry. Projective geometry is emerging as an attractive framework for com puter vision <ref> [40] </ref>. In this paper, we assume that the reader is familiar with some elemen tary projective geometry. Such material can be found in classical mathematic textbooks such as [42], [4], [16], but also in the computer vision lit erature where it is presented in chapters of recent books [11], [25], [40], <p> <ref> [40] </ref>. In this paper, we assume that the reader is familiar with some elemen tary projective geometry. Such material can be found in classical mathematic textbooks such as [42], [4], [16], but also in the computer vision lit erature where it is presented in chapters of recent books [11], [25], [40], and articles [38], [24].
Reference: 41. <author> L. Robert. </author> <title> Reconstruction de courbes et de surfaces par vision stereoscopique. Applications a la robotique mobile. </title> <type> PhD thesis, </type> <institution> Ecole Polytechnique, </institution> <year> 1993. </year>
Reference-contexts: Self-calibration of a moving camera 31 Fig. 13. A pair of images with the detected corners superimposed. Note that only few of the points are on the calibration grid. The standard calibration is performed on each image, using the algorithm of Robert <ref> [41] </ref>, which is a much improved version of the linear method of Faugeras and Toscani [15].
Reference: 42. <author> J.G. Semple and G.T. Kneebone. </author> <title> Algebraic Projective Geometry. </title> <publisher> Oxford: Clarendon Press, </publisher> <year> 1952. </year> <note> Reprinted 1979. </note>
Reference-contexts: Projective geometry is emerging as an attractive framework for com puter vision [40]. In this paper, we assume that the reader is familiar with some elemen tary projective geometry. Such material can be found in classical mathematic textbooks such as <ref> [42] </ref>, [4], [16], but also in the computer vision lit erature where it is presented in chapters of recent books [11], [25], [40], and articles [38], [24].
Reference: 43. <author> M.E. Spetsakis and J. Aloimonos. </author> <title> Optimal computing of structure from motion using point correspondances in two frames. </title> <booktitle> In Proc. International Conference on Computer Vision, </booktitle> <pages> pages 449-453, </pages> <year> 1988. </year>
Reference-contexts: By combining the computation of motion with the computation of the intrinsic parameters we obtain another iterative approach to self-calibration, which we compare to the Kruppa approach. 4.1. Computing the motion after calibrating The motion determination problem from point correspondences is very classical. See [13] <ref> [43] </ref> [50] [21] for solutions similar to ours. There are two different solutions, both based on the computation of the fundamental matrix.
Reference: 44. <author> H.P. Trivedi. </author> <title> Can multiple views make up for lack of camera registration ? Image and Vision Computing, </title> <booktitle> 6(1) </booktitle> <pages> 29-32, </pages> <year> 1988. </year>
Reference-contexts: A second expression of the rigidity constraints has been presented by Trivedi <ref> [44] </ref>. <p> Two types of numerical methods to solve the equations are then considered, and simulations are presented to as sess the strengths and weaknesses of each method. 3.1. Using three displacements of a moving cam era A moving camera In an earlier work, Trivedi <ref> [44] </ref> has considered the problem of computing only the coordinates of the principal point of each camera, that is to solve the self-calibration problem for the restricted model of intrinsic parameters: A = 4 0 1 v 0 3 2 1 0 u 0 0 1 v 0 0 0 1
Reference: 45. <author> R.Y. Tsai. </author> <title> Synopsis of Recent Progress on Camera Calibration for 3D Machine Vision. </title> <editor> In Oussama Khatib, John J. Craig, and Tomas Lozano-Perez, editors, </editor> <booktitle> The Robotics Review, </booktitle> <pages> pages 147-159. </pages> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Taking these constraints into account forces to use nonlinear methods such as the five-point algorithm of Faugeras and Maybank [14]. The internal parameters of the cameras are traditionally determined by observing a known calibration object (see <ref> [45] </ref> for a review), prior to the execution of the vision task. However, there are several applications for which a calibration object is not available, or its use is too cumbersome.
Reference: 46. <author> R.Y. Tsai and T.S. Huang. </author> <title> Uniqueness and estimation of three-dimensional motion parameters of rigid objects wirth curved surfaces. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 13-27, </pages> <year> 1984. </year>
Reference-contexts: factorization We have seen that during the course of intrinsic parameters estimation, we had to compute the fundamental matrix F, from which the essential matrix is immediately obtained: E = A T FA (20) The problem of finding the rotation R and the translation t from E is classical [29], <ref> [46] </ref>, [13], [18]. We denote this algorithm by FACTOR. An iterative solution An alternative method is to use directly the error function that has been used to determine the fundamental matrix. <p> Relative error on the rotation, initialization with the results of FACTOR (2) and an arbitrary motion (3) Note that even using MIN-LIN, the results are much more precise than those usually found by us Self-calibration of a moving camera 23 ing a purely linear methods such as the eight-point algorithm <ref> [46] </ref>, [10]. Fig. 7. Relative error on the translation, initialization with the results of FACTOR (2) and an arbitrary motion (3) Sensitivity to errors on the intrinsic parameters Very few results are available concerning the sensitivity of motion and structure computations to errors on the intrinsic parameters [27].
Reference: 47. <author> Shimon Ullman. </author> <title> The Interpretation of Visual Motion. </title> <publisher> MIT Press, </publisher> <year> 1979. </year>
Reference-contexts: This is the full perspective case. Other researchers have as fl This work was partially supported by the EC under Esprit grant 5390, Real Time Gaze Control sumed less general image formation models such as the orthographic model, for example Ullman <ref> [47] </ref>. In this article we will assume the most general case of the full perspective image formation model.
Reference: 48. <author> T. Vieville. </author> <title> Auto-calibration of visual sensor parameters on a robotic head. </title> <journal> Image and Vision Computing, </journal> <volume> 12, </volume> <year> 1994. </year>
Reference-contexts: However, with the exception of Hartley [19], all of them have put more limitations on their methods than we did, by adding supplementary constraints, such as an initial knowledge of camera parameters which are then only updated [5], or restriction on the camera motions [9], [2], [8], <ref> [48] </ref>, [20]. When the camera motion is exactly known in some reference frame, then these methods should be rather called "calibration from motion" than self-calibration, where motion and calibration are estimated. <p> However, one of the most reasonable restriction seems to be a partial control of the motion, which may be performed by a robotic head. In this context, one of the most general work is that of Vieville <ref> [48] </ref> where the only additional assumption is the fact that the motion is a fixed-axis rotation, something well-suited to robotics heads. Another approach, which is complementary to the one described in this paper, is to use a stationary camera [20], [36].
Reference: 49. <author> C.W. Wampler, A.P. Morgan, and A.J. Sommese. </author> <title> Numerical continuation methods for solving polynomial systems arising in kinematics. </title> <type> Technical Report GMR-6372, </type> <institution> General Motors Research Labs, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: Recently developed methods in numerical continuation can reliably compute all solutions to polynomial systems. These methods have been improved over a decade to provide reliable solutions to kinematics problems. The details of these improvements are omitted. The interested reader is referred for instance to <ref> [49] </ref> for a detailed tutorial presentation. The solution of a system of nonlinear equations by numerical continuation is suggested by the idea that small changes in the parameters of the system usually produce small changes in the solutions.
Reference: 50. <author> J. Weng, N. Ahuja, and T.S. Huang. </author> <title> Optimal motion and structure estimation. </title> <booktitle> In Proc. International Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 144-152, </pages> <year> 1989. </year>
Reference-contexts: 14 13 14 13 30 27 30 28 10 6 13 7 13 19 23 24 24 1.0 3 38 35 39 36 52 50 57 55 10 28 35 29 37 44 46 51 48 Thus, statistically, the global minimization gives better results, a finding consistent with those of <ref> [50] </ref> and [28]. <p> By combining the computation of motion with the computation of the intrinsic parameters we obtain another iterative approach to self-calibration, which we compare to the Kruppa approach. 4.1. Computing the motion after calibrating The motion determination problem from point correspondences is very classical. See [13] [43] <ref> [50] </ref> [21] for solutions similar to ours. There are two different solutions, both based on the computation of the fundamental matrix.
Reference: 51. <author> Z. Zhang, R. Deriche, O. Faugeras, and Q.-T. Luong. </author> <title> A robust technique for matching two uncalibrated images through the recovery of the unknown epipolar geometry. </title> <journal> Artificial Intelligence Journal, </journal> <note> 1995. To appear. </note>
Reference-contexts: We denote this algorithm by FACTOR. An iterative solution An alternative method is to use directly the error function that has been used to determine the fundamental matrix. It differs from the previous one by the fact that it uses again the measured points In [31], <ref> [51] </ref> different parameterizations for this matrix have been proposed to take into account constraints on its structure and linear and non-linear criteria for its estimation were also considered.
Reference: 52. <author> Z. Zhang and O.D. Faugeras. </author> <title> 3D dynamic scene analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: As it is a classical tool in computer vision, we do not give details on the filter itself, and rather invite the interested reader to read the classical references [23] [39], or the more practical presentations which can be found in [1], [11], and <ref> [52] </ref>. 6. The seemingly inferior results come from the fact that there was no requirements on these experiments on the minimum number of point matches generated, and thus often very few points have been used, in contrast with the previous experiments, where we started with at least 30 points 7.
References-found: 52

