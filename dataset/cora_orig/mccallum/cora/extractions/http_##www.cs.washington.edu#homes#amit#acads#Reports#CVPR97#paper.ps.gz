URL: http://www.cs.washington.edu/homes/amit/acads/Reports/CVPR97/paper.ps.gz
Refering-URL: http://www.cs.washington.edu/homes/amit/acads/Reports/CVPR97/
Root-URL: 
Email: email: suban@cse.iitd.ernet.in  
Title: Object Tracking using Affine Structure for Point Correspondences  
Author: Gurmeet Singh Manku Pankaj Jain Amit Aggarwal Lalit Kumar Subhashis Banerjee 
Address: New Delhi 110016  
Affiliation: Department of Computer Science and Engineering Indian Institute of Technology  
Abstract: A new object tracking algorithm based on affine structure has been developed and it is shown that the performance is better than that of a Kalman filter based correlation tracker. The algorithm is fast, reliable, viewpoint invariant, and insensitive to occlusion and/or individual corner disappearance or reappearance. Detailed experimental analysis on a long real image sequence is also presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Bar-Shalom and T. E. Fortmann. </author> <title> Tracking and Data Association. </title> <publisher> Academic Press., </publisher> <year> 1988. </year>
Reference-contexts: The position of each corner is predicted in the new frame using the Kalman filter prediction equation <ref> [1] </ref> and all corners found within a search area whose size depends on the predicted covariance matrix P are cross-correlated with the corner in the previous frame. <p> The best match, above a certain minimum threshold (typically 0.7) is selected and the Kalman filter's state vector and state covariance is updated using the standard equations <ref> [1] </ref>. For each corner unmatched in the previous frame (Kalman filter not initialized) the position in the next frame is predicted using the ego-motion of the camera. If a match is found successfully by cross-correlation then the Kalman filter for the corner is initialized.
Reference: [2] <author> A. Blake, R. Curwen, and A. Zisserman. </author> <title> A Framework for Spatio-temporal Control in the Tracking of Visual Contour. </title> <journal> Intl. J. Computer Vision, </journal> <volume> 11(2) </volume> <pages> 127-145, </pages> <year> 1993. </year>
Reference-contexts: On one hand, traditional approaches to tracking have been based primarily on intensity correlation matching, with the more sophisticated approaches employing recursive Kalman filtering [6, 7] for temporal consistency. Little attempt has been made to impose structural constraints on the features being tracked <ref> [2, 8] </ref>. On the other hand most approaches to structure and motion parameter estimation have assumed that reliable correspondences are already available [4, 9]. The successes of these approaches are crucially dependent on the correctness of the assumed correspondences.
Reference: [3] <author> C. Harris and M. Stephens. </author> <title> A Combined Corner and Edge Detector. </title> <booktitle> In Proc. 4th Alvey Vision Conf., </booktitle> <pages> pages 153-158, </pages> <year> 1988. </year>
Reference-contexts: note that in our algorithm it is not necessary to handle the degenerate (2D) and the nondegenerate (3D) cases separately in all the procedures mentioned above. 4 Results We have implemented the corner tracking algorithm in real-time (at 25 Hz) using a SUN machine for frame grabbing and corner detection <ref> [3] </ref> and a Pentium (120 M Hz) for tracking and robot control. We have carried out extensive experimentation on some image sequences. In what follows we present the tracking results in a 150 frames off-line sequence obtained at 7.5 Hz.
Reference: [4] <author> J. J. Koenderink and A. J. van Doorn. </author> <title> Affine Structure from Motion. </title> <journal> Journal of the Optical Society of America, Series A, </journal> <volume> 8 </volume> <pages> 377-385, </pages> <year> 1991. </year>
Reference-contexts: Little attempt has been made to impose structural constraints on the features being tracked [2, 8]. On the other hand most approaches to structure and motion parameter estimation have assumed that reliable correspondences are already available <ref> [4, 9] </ref>. The successes of these approaches are crucially dependent on the correctness of the assumed correspondences. Reid and Murray [6, 7] have developed a real-time object tracker which uses a constant image velocity Kalman filter to establish the point correspondences across frames. <p> The computation required in each frame is directly proportional to the number of corners tracked (O (n)), and consequently the algorithm can be implemented in real-time. We assume that the object in view is undergoing affine motion, which is more general than the customary assumption of rigid transformations <ref> [4] </ref>. We use the affine camera projective model [5, 4] and recover structure up to an arbitrary affine transformation. <p> We assume that the object in view is undergoing affine motion, which is more general than the customary assumption of rigid transformations [4]. We use the affine camera projective model <ref> [5, 4] </ref> and recover structure up to an arbitrary affine transformation. The affine camera model is valid when the field of view is small and the depth of the object is small compared to the viewing distance, which is expected in any foveal tracking application [5, 6]. <p> In the affine projection model [5] all projection rays are parallel and the epi-poles are at infinity resulting in parallel epipolar lines. Given n 4 point correspondences in two or more views, it is possible to determine the affine structure of the n point configuration <ref> [4] </ref> and the affine structure is invariant to affine motion. See [5] for an exposition of the affine multiple views geometry.
Reference: [5] <author> J. L. Mundy and A. Zisserman. </author> <title> Geometric Invariance in Computer Vision. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: We assume that the object in view is undergoing affine motion, which is more general than the customary assumption of rigid transformations [4]. We use the affine camera projective model <ref> [5, 4] </ref> and recover structure up to an arbitrary affine transformation. The affine camera model is valid when the field of view is small and the depth of the object is small compared to the viewing distance, which is expected in any foveal tracking application [5, 6]. <p> The affine camera model is valid when the field of view is small and the depth of the object is small compared to the viewing distance, which is expected in any foveal tracking application <ref> [5, 6] </ref>. When the perspective effects are small, it is convenient to assume the parallel projection model of the affine camera which explicitly models the ambiguities. Further, it is possible to detect when the affine camera approximation fails to hold. <p> In the affine projection model <ref> [5] </ref> all projection rays are parallel and the epi-poles are at infinity resulting in parallel epipolar lines. Given n 4 point correspondences in two or more views, it is possible to determine the affine structure of the n point configuration [4] and the affine structure is invariant to affine motion. <p> Given n 4 point correspondences in two or more views, it is possible to determine the affine structure of the n point configuration [4] and the affine structure is invariant to affine motion. See <ref> [5] </ref> for an exposition of the affine multiple views geometry.
Reference: [6] <author> I. D. Reid and D. W. Murray. </author> <title> Tracking Foveated Corner Clusters using Affine Structure. </title> <booktitle> In Proc. Intl. Conf. Computer Vision, </booktitle> <pages> pages 76-83, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Tracking and computation of structure and motion have been treated in the past as two separate problems. On one hand, traditional approaches to tracking have been based primarily on intensity correlation matching, with the more sophisticated approaches employing recursive Kalman filtering <ref> [6, 7] </ref> for temporal consistency. Little attempt has been made to impose structural constraints on the features being tracked [2, 8]. On the other hand most approaches to structure and motion parameter estimation have assumed that reliable correspondences are already available [4, 9]. <p> On the other hand most approaches to structure and motion parameter estimation have assumed that reliable correspondences are already available [4, 9]. The successes of these approaches are crucially dependent on the correctness of the assumed correspondences. Reid and Murray <ref> [6, 7] </ref> have developed a real-time object tracker which uses a constant image velocity Kalman filter to establish the point correspondences across frames. <p> The affine camera model is valid when the field of view is small and the depth of the object is small compared to the viewing distance, which is expected in any foveal tracking application <ref> [5, 6] </ref>. When the perspective effects are small, it is convenient to assume the parallel projection model of the affine camera which explicitly models the ambiguities. Further, it is possible to detect when the affine camera approximation fails to hold. <p> Further, it is possible to detect when the affine camera approximation fails to hold. In what follows we describe our new approach to feature tracking. In Sec. 2, we describe the Kalman filter based corner tracking algorithm <ref> [6] </ref> which we use to obtain the initial matches for our algorithm and discuss its limitations. In In Sec. 3, we describe our new algorithm for tracking using affine structure. <p> In In Sec. 3, we describe our new algorithm for tracking using affine structure. In Sec. 4 we present tracking results on a long real image sequence and compare the performance with the Kalman filter based tracking algorithm of <ref> [6] </ref>. 2 Kalman Filter based Tracking (Reid and Murray) Kalman filters comprise a class of linear unbiased minimum-error covariance sequential state estimation algorithms. A constant image-velocity Kalman filter is used for each corner [6] to be tracked. <p> a long real image sequence and compare the performance with the Kalman filter based tracking algorithm of <ref> [6] </ref>. 2 Kalman Filter based Tracking (Reid and Murray) Kalman filters comprise a class of linear unbiased minimum-error covariance sequential state estimation algorithms. A constant image-velocity Kalman filter is used for each corner [6] to be tracked. The state vector for any corner, x (k) is given by a 4 x 1 matrix [x (k); y (k); _x (k); _y (k)] T .
Reference: [7] <author> I. D. Reid and D. W. Murray. </author> <title> Active Tracking of Fo-veated Feature Clusters using Affine Structure. </title> <journal> Intl. J. Computer Vision, </journal> <volume> 18(1) </volume> <pages> 41-60, </pages> <year> 1996. </year>
Reference-contexts: 1 Introduction Tracking and computation of structure and motion have been treated in the past as two separate problems. On one hand, traditional approaches to tracking have been based primarily on intensity correlation matching, with the more sophisticated approaches employing recursive Kalman filtering <ref> [6, 7] </ref> for temporal consistency. Little attempt has been made to impose structural constraints on the features being tracked [2, 8]. On the other hand most approaches to structure and motion parameter estimation have assumed that reliable correspondences are already available [4, 9]. <p> On the other hand most approaches to structure and motion parameter estimation have assumed that reliable correspondences are already available [4, 9]. The successes of these approaches are crucially dependent on the correctness of the assumed correspondences. Reid and Murray <ref> [6, 7] </ref> have developed a real-time object tracker which uses a constant image velocity Kalman filter to establish the point correspondences across frames. <p> This is because the centroid tends to shift due to disappearance and re-appearance of feature points. Instead, as suggested in <ref> [7] </ref>, we determine the gaze point by determining the position of a fixed point in the new frame using the computed affine basis. Let the invariant affine coordinates of the gaze point be (ff, fi, fl) and let h be the basis matrix. <p> In particular, we have observed that the quality of gaze fixation is significantly better than the Kalman filter based algorithm when there is an abrupt change in the motion and the Kalman filters fail to predict accurately. Also, the structure based method of gaze fixation, as suggested in <ref> [7] </ref>, generates a smoother gaze demand as compared to center of mass tracking (Fig. 4) and results in a smaller camera speed (Fig. 5).
Reference: [8] <author> G. Sudhir, S. Banerjee, and A. Zisserman. </author> <title> Finding Point Correspondences in Motion Sequences Preserving Affine Structure. </title> <booktitle> In Proc. British Machine Vision Conf., </booktitle> <year> 1993. </year> <note> Also accepted for CVGIP: Image Understanding. </note>
Reference-contexts: On one hand, traditional approaches to tracking have been based primarily on intensity correlation matching, with the more sophisticated approaches employing recursive Kalman filtering [6, 7] for temporal consistency. Little attempt has been made to impose structural constraints on the features being tracked <ref> [2, 8] </ref>. On the other hand most approaches to structure and motion parameter estimation have assumed that reliable correspondences are already available [4, 9]. The successes of these approaches are crucially dependent on the correctness of the assumed correspondences.
Reference: [9] <author> C. Tomasi and T. Kanade. </author> <title> Shape and Motion from Image Streams under Orthography: A Factorization Method. </title> <journal> Intl. J. Computer Vision, </journal> <volume> 9 </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: Little attempt has been made to impose structural constraints on the features being tracked [2, 8]. On the other hand most approaches to structure and motion parameter estimation have assumed that reliable correspondences are already available <ref> [4, 9] </ref>. The successes of these approaches are crucially dependent on the correctness of the assumed correspondences. Reid and Murray [6, 7] have developed a real-time object tracker which uses a constant image velocity Kalman filter to establish the point correspondences across frames. <p> mass of matched corners; continue with the next frame; g Compute affine structure; Force matches using affine structure; (Sec. 3.5) Locate the Gaze point using its affine structure; (Sec. 3.7) Update Kalman filters for all matched corners; g 3.2 Initialization of basis and structure We use the Tomasi and Kanade <ref> [9] </ref> procedure to initialize the basis and the affine structure of the corners which have a match history of at least F 2 frames by constructing a 2F fi P measurement matrix W given below. We use F = 6 in our experiments.
References-found: 9

