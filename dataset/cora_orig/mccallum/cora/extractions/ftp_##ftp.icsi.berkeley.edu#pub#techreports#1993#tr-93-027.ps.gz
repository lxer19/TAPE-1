URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1993/tr-93-027.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1993.html
Root-URL: http://www.icsi.berkeley.edu
Email: email: thiebaux@irisa.fr.  email: hertz@icsi.berkeley.edu.  email: wds@cs.fit.edu  email: moti@cs.fit.edu  
Title: A Stochastic Model of Actions and Plans for Anytime Planning under Uncertainty  
Author: Sylvie Thiebaux Joachim Hertzberg William Shoaff Moti Schneider k k 
Note: Work done while the author was  On leave from  The author is partially funded by the German Federal Ministry for Research and Technology (BMFT) in the joint project TASSO under grant ITW8900A7.  
Address: 35042 Rennes, France,  ICSI, 1947 Center St., Berkeley, Ca 94704, USA,  Schlo Birlinghoven, 5205 Sankt Augustin 1, Germany.  Melbourne, Fl 32901, USA,  Melbourne, Fl 32901, USA,  
Affiliation: IRISA, Campus de Beaulieu,  at Florida Institute of Technology.  GMD, AI Division,  FIT, CS Department,  FIT, CS Department,  
Pubnum: TR-93-027  
Abstract: fl Thanks to Gerd Brewka, Marie-Odile Cordier, Tom Gordon, Gerd Grosse, Eric Jacopin, Jurgen Paulokat, Eric Rutten, Josef Schneeberger, and Qiang Yang for commenting on a previous version of this paper. A shorter version of this paper has appeared in [ Horz, 1993 ] . This version is submitted for publication. 
Abstract-found: 1
Intro-found: 1
Reference: [ Beetz and McDermott, 1992 ] <author> M. Beetz and D. McDermott. </author> <title> Declarative goals in reactive plans. </title> <editor> In [ Hendler, </editor> <year> 1992 </year> <month> ] , pages 3-12, </month> <year> 1992. </year>
Reference-contexts: Obviously, it is useful to combine work on these two topics, the perspective being to build planners that cope with uncertainty, and incrementally increase the plan quality if time permits. Examples of such works are <ref> [ Drummond and Bresina, 1990; Beetz and McDermott, 1992 ] </ref> . In a previous paper [ Thiebaux and Hertzberg, 1992 ] , we have described pascale, a system for planning under uncertainty. <p> Kanazawa and Dean [ 1989 ] follow this approach: their planner continually selects the behavior with maximal utility among those available. The model presented here aims at a combination anytime planner/reactive executor. As in <ref> [ Drummond et al., 1993; Beetz and McDermott, 1992 ] </ref> , it can be reasonably assumed, for a broad class of applications, that a reactive executor can be designed that uses default user-provided plans, thereby having some probability of solving a problem.
Reference: [ Boddy and Dean, 1989 ] <author> M. Boddy and T.L. Dean. </author> <title> Solving time-dependent planning problems. </title> <booktitle> In Proc. IJCAI-89, </booktitle> <pages> pages 979-984, </pages> <year> 1989. </year>
Reference-contexts: Under time pressure, a planner can produce some plan in a fixed amount of time, and improve the plan quality as more time is allocated. Anytime planning algorithms [ Dean and Boddy, 1988 ] implement this idea. They have been applied to solving time-dependent planning problems <ref> [ Boddy and Dean, 1989 ] </ref> and are also used for a broad class of planning applications, e.g. [ Zilberstein and Russel, 1992 ] .
Reference: [ Brewka and Hertzberg, To appear ] <author> G. Brewka and J. Hertzberg. </author> <title> How to do things with worlds: On formalizing actions and plans. </title> <journal> J. Logic and Computation, </journal> <note> To appear. Previous version as TASSO-Report No. 11, </note> <institution> GMD, </institution> <year> 1990. </year>
Reference-contexts: In a previous paper [ Thiebaux and Hertzberg, 1992 ] , we have described pascale, a system for planning under uncertainty. This system is based on a particular theory of actions with uncertain outcomes <ref> [ Brewka and Hertzberg, To appear ] </ref> , which deals explicitly with uncertainty arising from the incompleteness or ambiguity of information. pascale's representation of reaction plans allows them to be generated from first principles, as well as revised off or on-line; this proved to be a good basis for exhibiting reactivity. <p> To this end, the formalization uses a possible models variant of Nilsson's probabilistic logic, as a basis for both reasoning about actions in the spirit of <ref> [ Brewka and Hertzberg, To appear ] </ref> , and later, decision-theoretic planning. 2.1 Background on Possible Models And Probabilistic Logic We first set up the possible models framework our formalization is based on, recall some basics of Nilsson's probabilistic logic, and introduce an example-domain that will be used throughout the rest <p> We define: table2up = [ :ry ^ ot j (fupg; 0:8); (ffdg; 0:2); ry ^ ot j (fupg; 0:6); (ffdg; 0:4); :ot j (fg; 1) ] Under some assumptions about L discussed in <ref> [ Brewka and Hertzberg, To appear ] </ref> , the approach solves both frame and ramification problems; it is unnecessary to specify that the weather is unaffected and that the cup is not on the table any more. <p> valid a context of the form [ l j (f:lg; ); (fg; 1 ) ] even if fg f:lg, because :l is achieved with the first postcondition, while l remains with the second. 7 This example ends the description of our action formalization, about which details can be found in <ref> [ Brewka and Hertzberg, To appear; Thiebaux, 1992 ] </ref> . We have exemplified that this formalization copes with uncertainty at planning time, such as incompleteness or ambiguity in world state descriptions; it also copes with ambiguity and context dependency of actions effects.
Reference: [ Cheeseman, 1983 ] <author> P. Cheeseman. </author> <title> A method of computing generalized bayesian probability values for expert systems. </title> <booktitle> In Proc. IJCAI-83, </booktitle> <pages> pages 198-202, </pages> <year> 1983. </year>
Reference-contexts: The task of computing all possible models is the most costly of the whole procedure, being exponential in the cardinality of L. Once this step has been performed, it is fairly simple to determine an approximation of p, following the lines given in <ref> [ Cheeseman, 1983 ] </ref> . If P is, as before, the probabilistic background knowledge, this computation amounts to solving a non-linear system of k equations, where k = card (P ) + 1, i.e., the number of sentences, including true, for which an a-priori probability is available.
Reference: [ Chou and Winslett, 1991 ] <author> T. Chou and M. Winslett. Immortal: </author> <title> a model-based belief revision system. </title> <booktitle> In Proc. KR-91, </booktitle> <pages> pages 99-109, </pages> <year> 1991. </year>
Reference-contexts: Moreover, the availability of the possible models set makes validating action preconditions faster. 18 5 IMPLEMENTATION AND EXPERIMENTAL RESULTS However, we plan to use the more efficient algorithm described in <ref> [ Chou and Winslett, 1991 ] </ref> , which can trivially be adapted to our framework. 11 Instead of computing all possible models in a postcondition P ost and filtering maximally P ost-conform models with a possible model M in s, the latter algorithm incrementally updates M [ P ost so as <p> However, in the presence of a large logical background knowledge, those seem to be less efficient than the algorithm given in <ref> [ Chou and Winslett, 1991 ] </ref> . 19 computation time, for our cup example.
Reference: [ Chrisman and Simmons, 1991 ] <author> L. Chrisman and R. Simmons. </author> <title> Sensible planning: Focusing perceptual attention. </title> <booktitle> In Proc. AAAI-91, </booktitle> <pages> pages 756-761, </pages> <year> 1991. </year>
Reference-contexts: In general, a. and b. still induce an infinity of probability distributions. Among them, item c. selects the p with maximal entropy, because this distribution assumes minimal additional information beyond the background knowledge. Consider an example-domain inspired by <ref> [ Chrisman and Simmons, 1991 ] </ref> and shown in the left-hand side of Figure 1. The task of a robot is to manipulate a cup from a fixed position, using several actions to be detailed later. The cup can be either on the floor (of) or on a table (ot). <p> Provided that L is decidable, such a search always terminates, owing to the finiteness of the state space: possible models 8 Dealing with sensing leads to non-trivial problems that have been rarely discussed in the literature. <ref> [ Chrisman and Simmons, 1991 ] </ref> proposes a solution for generating optimal plans of actions given a static sensing policy, that might be adapted to fit with our framework 9 occur only once in a plan, even if generated by different tasks.
Reference: [ Cordier and Siegel, 1992 ] <author> M.O. Cordier and P. Siegel. </author> <title> A temporal revision model for reasoning about world change. </title> <booktitle> In Proc. KR-92, </booktitle> <pages> pages 732-739, </pages> <year> 1992. </year>
Reference: [ Dean and Boddy, 1988 ] <author> T.L. Dean and M. Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proc. AAAI-88, </booktitle> <pages> pages 49-54, </pages> <year> 1988. </year>
Reference-contexts: Implementing time-bounded rationality. Generating optimal plans from first principles takes time. Under time pressure, a planner can produce some plan in a fixed amount of time, and improve the plan quality as more time is allocated. Anytime planning algorithms <ref> [ Dean and Boddy, 1988 ] </ref> implement this idea. They have been applied to solving time-dependent planning problems [ Boddy and Dean, 1989 ] and are also used for a broad class of planning applications, e.g. [ Zilberstein and Russel, 1992 ] . <p> On-line, given that the world is in state M , a plan P is optimal for a problem if and only if the element of U (P) corresponding to the task to be applied in M (if any) is optimal. 4.3 Use and Design of Anytime Algorithms Anytime algorithms <ref> [ Dean and Boddy, 1988 ] </ref> are algorithms that return an answer for any allocation of computation time and are expected to return better answers when given more time.
Reference: [ Dean and Kanazawa, 1988 ] <author> T.L. Dean and K. </author> <title> Kanazawa. A model for reasoning about persistence and causation. </title> <journal> Comput. Intell., </journal> <volume> 5(3):142- 150, </volume> <year> 1988. </year>
Reference: [ Dean and Wellman, 1991 ] <author> T.L. Dean and M.P. Wellman. </author> <title> Planning and Control. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Moreover, uncertainty is also tackled by theory-oriented work in reasoning about action and change, e.g. [ Dean and Kanazawa, 1988; Brewka and Hertzberg, To appear; Cordier and Siegel, 1992 ] , with some texts, e.g. <ref> [ Hanks, 1990; Dean and Wellman, 1991 ] </ref> , explicitly relating theoretical concepts of reasoning about action to planning. Implementing time-bounded rationality. Generating optimal plans from first principles takes time.
Reference: [ Drummond and Bresina, 1990 ] <author> M. Drummond and J. Bresina. </author> <title> Anytime synthetic projection: Maximizing the probability of goal satisfaction. </title> <booktitle> In Proc. AAAI-90, </booktitle> <pages> pages 138-144, </pages> <year> 1990. </year> <note> REFERENCES 23 </note>
Reference-contexts: Obviously, it is useful to combine work on these two topics, the perspective being to build planners that cope with uncertainty, and incrementally increase the plan quality if time permits. Examples of such works are <ref> [ Drummond and Bresina, 1990; Beetz and McDermott, 1992 ] </ref> . In a previous paper [ Thiebaux and Hertzberg, 1992 ] , we have described pascale, a system for planning under uncertainty. <p> The framework also suggests a rational exploration of both state and search spaces, thereby facilitating the design of special-purpose anytime algorithms for off-line or on-line planning. The following algorithm, which can be viewed as a reformulation of the projection algorithm in <ref> [ Drummond and Bresina, 1990 ] </ref> without considering quantitative time, plans for the most probable evolution of the environment first. The search starts with a plan embryo containing the start task and the M-nodes corresponding to the initial situation of the problem. <p> To generate them, nothing about the initial situation is known, all actions are context free and unambiguous. Decision trees, as proposed by [ Feldman and Sproull, 1977 ] . No restrictions can be made to generate them. Situation-action rules as from <ref> [ Drummond, 1989; Drummond and Bresina, 1990 ] </ref> , see Sections 3 and 4. pascale plans, as described in [ Thiebaux and Hertzberg, 1992 ] : to generate them, possible models always have equiprobability.
Reference: [ Drummond et al., 1993 ] <author> M. Drummond, K. Swanson, J. Bresina, and R. Levinson. </author> <title> Reaction-first search. </title> <booktitle> In Proc. IJCAI-93, </booktitle> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: Kanazawa and Dean [ 1989 ] follow this approach: their planner continually selects the behavior with maximal utility among those available. The model presented here aims at a combination anytime planner/reactive executor. As in <ref> [ Drummond et al., 1993; Beetz and McDermott, 1992 ] </ref> , it can be reasonably assumed, for a broad class of applications, that a reactive executor can be designed that uses default user-provided plans, thereby having some probability of solving a problem. <p> This case leads to an important problem: since the incomplete plan might not lead to a solution, i.e., be a prefix of no solution, it might decrease the executor's performance. <ref> [ Drummond et al., 1993 ] </ref> presents the RFS type of search (Reaction-First Search) which is designed to solve this problem.
Reference: [ Drummond, 1989 ] <author> M. Drummond. </author> <title> Situated control rules. </title> <booktitle> In Proc. KR-89, </booktitle> <pages> pages 103-113, </pages> <year> 1989. </year>
Reference-contexts: First, there is more support for execution monitoring, compared to other approaches to encoding reactivity such as situation-action rules <ref> [ Drummond, 1989 ] </ref> . A plan can obviously be translated into a set of such rules, by interpreting M -nodes as IF parts, and the T - nodes as THEN parts. <p> To generate them, nothing about the initial situation is known, all actions are context free and unambiguous. Decision trees, as proposed by [ Feldman and Sproull, 1977 ] . No restrictions can be made to generate them. Situation-action rules as from <ref> [ Drummond, 1989; Drummond and Bresina, 1990 ] </ref> , see Sections 3 and 4. pascale plans, as described in [ Thiebaux and Hertzberg, 1992 ] : to generate them, possible models always have equiprobability.
Reference: [ Dubois and Prade, 1993 ] <author> D. Dubois and H. Prade. </author> <title> Belief revisions and updates in numerical formalisms. an overview, with new results for the possibilistic framework. </title> <booktitle> In Proc. IJCAI-93, </booktitle> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: It corresponds to the transfer of the probability mass of a possible model to its closest neighbours according to the event that has happened. In our case, these closest neighbours are the maximally conform models. <ref> [ Dubois and Prade, 1993 ] </ref> studies the probabilistic and possibilistic counterparts of belief revision and updates in detail. 7 Imposing that P ost j 1 i 6 P ost j 2 i for all two postconditions P ost j 1 i and P ost j 2 i is a too
Reference: [ Feldman and Sproull, 1977 ] <editor> J.A. Feldman and R.F. Sproull. </editor> <booktitle> Decision theory and artificial intelligence II: The hungry monkey. Cogn. Sci., </booktitle> <volume> 1 </volume> <pages> 158-192, </pages> <year> 1977. </year>
Reference-contexts: There is a variety of approaches for tackling some or many forms of uncertainty at planning or execution time; examples include reaction plans and reactive planning (see [ Schoppers, 1989 ] for a discussion and references), conditional planning [ Warren, 1976; Peot and Smith, 1992 ] , decision-theoretic planning methods <ref> [ Feldman and Sproull, 1977; Haddawy and Hanks, 1990 ] </ref> , or execution monitoring and replanning [ Fikes et al., 1972; Wilkins, 1988, Ch. 11 ] . <p> See [ Thiebaux and Hertzberg, 1992 ] for details. Universal plans, as proposed in [ Schoppers, 1987 ] . To generate them, nothing about the initial situation is known, all actions are context free and unambiguous. Decision trees, as proposed by <ref> [ Feldman and Sproull, 1977 ] </ref> . No restrictions can be made to generate them.
Reference: [ Fikes et al., 1972 ] <author> R.E. Fikes, P.E. Hart, and N.J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <editor> J. </editor> <booktitle> Art. Intell., </booktitle> <volume> 3 </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference-contexts: or execution time; examples include reaction plans and reactive planning (see [ Schoppers, 1989 ] for a discussion and references), conditional planning [ Warren, 1976; Peot and Smith, 1992 ] , decision-theoretic planning methods [ Feldman and Sproull, 1977; Haddawy and Hanks, 1990 ] , or execution monitoring and replanning <ref> [ Fikes et al., 1972; Wilkins, 1988, Ch. 11 ] </ref> . <p> As examples, let us mention Linear (strips type) plans. To generate them within our model, everything about the world must be known, all actions are context free and unambiguous. The reactive execution of such a plan is comparable to that of a strips triangle table <ref> [ Fikes et al., 1972 ] </ref> . See [ Thiebaux and Hertzberg, 1992 ] for details. Universal plans, as proposed in [ Schoppers, 1987 ] . To generate them, nothing about the initial situation is known, all actions are context free and unambiguous.
Reference: [ Garcia, 1993 ] <author> F. Garcia. </author> <title> Revision des croyances et revision du raisonnement pour la planification. </title> <type> PhD thesis, </type> <institution> Ecole Nationale Superieure de l'Aeronautique et de l'Espace, Toulouse, France, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: However, the algorithm must work on the complete state space at once. This is avoided by our model, which furthermore provides additional reasoning capabilities. Garcia <ref> [ Garcia, 1993 ] </ref> has developed time-independent non-linear and hiearchical planning algorithms, based on a formalization of actions similar to ours. This formalization takes into account context-dependent effects, and plans can be revised on-line, according to additional information acquired.
Reference: [ Gardenfors, 1988 ] <author> P. Gardenfors. </author> <title> Knowledge in Flux. </title> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: We allow actions to produce alternative outcomes with some probabilities, e.g., the action of tossing a coin. Independently from that, actions applied in different 4 Bayesian conditioning can be seen as the probabilistic counterpart of belief revision in the sense of <ref> [ Gardenfors, 1988 ] </ref> . 2.3 Coping With Uncertainty About Actions 5 contexts may produce differing outcomes, e.g., the action of toggling a light's switch switches the light on if it was off, and vice versa.
Reference: [ Ginsberg and Smith, 1988 ] <author> M.L. Ginsberg and D.E. Smith. </author> <title> Reasoning about action I: A possible worlds approach. </title> <editor> J. </editor> <booktitle> Art. Intell., </booktitle> <volume> 35 </volume> <pages> 165-195, </pages> <year> 1988. </year>
Reference-contexts: Possible models are in fact Herbrand Models of K, restricted to L. We use possible models instead of possible worlds to avoid syntax-dependent and unintuitive results obtained e.g. in <ref> [ Ginsberg and Smith, 1988 ] </ref> . For an arbitrary s 2 L, we define Def. 2.1 (Possible models in s) Let s 2 L and let K be the logical background knowledge.
Reference: [ Gordon et al., in preparation ] <author> T. Gordon, J. Hertzberg, and A. Horz. qwertz. </author> <title> a toolbox for building AI planners. </title> <note> in preparation. </note>
Reference-contexts: On the other hand, our method is more appropriate than RFS if the default plans have a low utility. 5 Implementation and Experimental Results pascale2, a domain-independent planning system based on our model, has been implemented in Standard ML on top of the qwertz toolbox <ref> [ Gordon et al., in preparation ] </ref> , a software toolbox for building planning systems developed at GMD. 17 The most time-critical task in pascale2 is that of computing the possible models and the probability distribution p in accord with the background knowledge.
Reference: [ Haddawy and Hanks, 1990 ] <author> P. Haddawy and S. Hanks. </author> <title> Issues in decision-theoretic planning: Symbolic goals and numeric utilities. In K.P. </title> <editor> Sycara, editor, </editor> <booktitle> Proc. DARPA Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pages 48-58, </pages> <address> San Diego, CA, </address> <year> 1990. </year>
Reference-contexts: There is a variety of approaches for tackling some or many forms of uncertainty at planning or execution time; examples include reaction plans and reactive planning (see [ Schoppers, 1989 ] for a discussion and references), conditional planning [ Warren, 1976; Peot and Smith, 1992 ] , decision-theoretic planning methods <ref> [ Feldman and Sproull, 1977; Haddawy and Hanks, 1990 ] </ref> , or execution monitoring and replanning [ Fikes et al., 1972; Wilkins, 1988, Ch. 11 ] . <p> We assume that each task in the plan is given a numerical utility which will mostly depend on the action from which the task is built and on its possible model predecessor. E.g., if utility is understood as goal-achievement probability, a step utility function <ref> [ Haddawy and Hanks, 1990 ] </ref> should be used, that maps the f inish tasks to 1 and other tasks to 0.
Reference: [ Haddawy and Hanks, 1992 ] <author> P. Haddawy and S. Hanks. </author> <title> Representations for decision-theoretic planning: Utility functions for deadline goals. </title> <booktitle> In Proc. KR-92, </booktitle> <pages> pages 71-82, </pages> <year> 1992. </year>
Reference-contexts: In this paper, we aim at viewing planning as a choice under uncertainty and time pressure, for which symbolic planning and decision theory act as two complementary functions. As Haddawy and Hanks <ref> [ Haddawy and Hanks, 1992 ] </ref> point out, Symbolic planning provides a computational theory of plan generation : : : Deci sion theory provides a normative model of choice under uncertainty.
Reference: [ Hanks, 1990 ] <author> S. Hanks. </author> <title> Practical temporal projection. </title> <booktitle> In Proc. AAAI-90, </booktitle> <pages> pages 158-163, </pages> <year> 1990. </year>
Reference-contexts: Moreover, uncertainty is also tackled by theory-oriented work in reasoning about action and change, e.g. [ Dean and Kanazawa, 1988; Brewka and Hertzberg, To appear; Cordier and Siegel, 1992 ] , with some texts, e.g. <ref> [ Hanks, 1990; Dean and Wellman, 1991 ] </ref> , explicitly relating theoretical concepts of reasoning about action to planning. Implementing time-bounded rationality. Generating optimal plans from first principles takes time.
Reference: [ Hendler, 1992 ] <editor> J. Hendler, editor. </editor> <booktitle> Artificial Intelligence Planning Systems: Proceedings of the First International Conference (AIPS92). </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1992. </year>
Reference: [ Horovitz, 1988 ] <author> E. Horovitz. </author> <title> Reasoning under varying und uncertain resource constraints. </title> <booktitle> In Proc. AAAI-88, </booktitle> <pages> pages 111-116, </pages> <year> 1988. </year>
Reference: [ Horz, 1993 ] <editor> A. Horz, editor. </editor> <booktitle> Beitrage zum 7. Workshop "Planen und Konfigurieren". Ar-beitspapiere der GMD Nr. </booktitle> <volume> 723, </volume> <month> January </month> <year> 1993. </year>
Reference: [ Howard, 1960 ] <author> R.A. Howard. </author> <title> Dynamic Programming and Markov Processes. </title> <publisher> MIT Press, </publisher> <year> 1960. </year> <note> 24 REFERENCES </note>
Reference-contexts: Koenig [ Koenig, 1991 ] shows how to elegantly model a planning problem as a Markov decision problem, and derive an anytime algorithm producing universal plans from the policy iteration algorithm <ref> [ Howard, 1960 ] </ref> . However, the algorithm must work on the complete state space at once. This is avoided by our model, which furthermore provides additional reasoning capabilities.
Reference: [ Kabanza, 1990 ] <author> F. Kabanza. </author> <title> Synthesis of reactive plans for multi-path environments. </title> <booktitle> In Proc. AAAI-90, </booktitle> <pages> pages 164-169, </pages> <year> 1990. </year>
Reference: [ Kanazawa and Dean, 1989 ] <author> K. Kanazawa and T.L. Dean. </author> <title> A model for projection and action. </title> <booktitle> In Proc. IJCAI-89, </booktitle> <pages> pages 985-990, </pages> <year> 1989. </year>
Reference: [ Katsuno and Mendelzon, 1991 ] <author> H. Katsuno and A.O. Mendelzon. </author> <title> On the difference between updating a knowledge base and revising it. </title> <booktitle> In Proc. KR-91, </booktitle> <pages> pages 387-394, </pages> <year> 1991. </year>
Reference-contexts: 0 fi 2 3 fi p s (M 2 ) p (table2up;s) (M 2 ) = (0 fi 1 2 + 1 fi 2 3 fi p s (M 2 ) 6 Lewis's [ 1976 ] imaging can be viewed as the probabilistic counterpart of updates in the sense of <ref> [ Katsuno and Mendelzon, 1991 ] </ref> . It corresponds to the transfer of the probability mass of a possible model to its closest neighbours according to the event that has happened.
Reference: [ Kemeny and Snell, 1960 ] <author> J. Kemeny and L. Snell. </author> <title> Finite Markov Chains. </title> <publisher> Van Nostrand, </publisher> <year> 1960. </year>
Reference-contexts: Furthermore, it allows one to select the parts of an unfinished plan to be extended first, thereby constituting a basis for designing special-purpose anytime algorithms. 4.1 Basic Results About Markov Chains We first recall basic results from Markov chain theory <ref> [ Kemeny and Snell, 1960 ] </ref> , and then explain how these results can be used to define the quality of a plan.
Reference: [ Koenig, 1991 ] <author> S. Koenig. </author> <title> Optimal probabilistic and decision-theoretic planning using markovian decision theory. </title> <type> Master's thesis, </type> <institution> University of California at Berkeley, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: Koenig <ref> [ Koenig, 1991 ] </ref> shows how to elegantly model a planning problem as a Markov decision problem, and derive an anytime algorithm producing universal plans from the policy iteration algorithm [ Howard, 1960 ] . However, the algorithm must work on the complete state space at once.
Reference: [ Lewis, 1976 ] <author> D.K. Lewis. </author> <title> Probabilities of conditionals and conditionals probabilities. </title> <journal> The Philosophical Rev., </journal> (85):297-315, 1976. 
Reference: [ Nilsson, 1986 ] <author> N.J. Nilsson. </author> <title> Probabilistic logic. </title> <editor> J. </editor> <booktitle> Art. Intell., </booktitle> <volume> 28(1) </volume> <pages> 71-87, </pages> <year> 1986. </year>
Reference: [ Peot and Smith, 1992 ] <author> M.A. Peot and D.E. Smith. </author> <title> Conditional nonlinear planning. </title> <editor> In [ Hendler, </editor> <year> 1992 </year> <month> ] , pages 189-197, </month> <year> 1992. </year>
Reference-contexts: There is a variety of approaches for tackling some or many forms of uncertainty at planning or execution time; examples include reaction plans and reactive planning (see [ Schoppers, 1989 ] for a discussion and references), conditional planning <ref> [ Warren, 1976; Peot and Smith, 1992 ] </ref> , decision-theoretic planning methods [ Feldman and Sproull, 1977; Haddawy and Hanks, 1990 ] , or execution monitoring and replanning [ Fikes et al., 1972; Wilkins, 1988, Ch. 11 ] .
Reference: [ Russel and Wefald, 1989 ] <author> S. Russel and E. Wefald. </author> <title> On optimal game-tree search using rational meta-reasoning. </title> <booktitle> In Proc. IJCAI-89, </booktitle> <pages> pages 334-340, </pages> <year> 1989. </year>
Reference: [ Schoppers, 1987 ] <author> M.J. Schoppers. </author> <title> Universal plans for reactive robots in unpredictable environments. </title> <booktitle> In Proc. IJCAI-87, </booktitle> <pages> pages 1039-1046, </pages> <year> 1987. </year>
Reference-contexts: Note that the framework does not presuppose that all the forms of uncertainty actually occur in every planning application. It enables a whole spectrum of implementations; special cases being, e.g., 2 2 FORMALIZING ACTIONS IN PROBABILISTIC LOGIC classical linear plans and universal plans <ref> [ Schoppers, 1987 ] </ref> . The paper is based on [ Thiebaux, 1992 ] , which contains additional details. It is organized as follows. Section 2 describes our formalization of actions which blends our previously used formalism with Nilsson's [ 1986 ] probabilistic logic. <p> The reactive execution of such a plan is comparable to that of a strips triangle table [ Fikes et al., 1972 ] . See [ Thiebaux and Hertzberg, 1992 ] for details. Universal plans, as proposed in <ref> [ Schoppers, 1987 ] </ref> . To generate them, nothing about the initial situation is known, all actions are context free and unambiguous. Decision trees, as proposed by [ Feldman and Sproull, 1977 ] . No restrictions can be made to generate them.
Reference: [ Schoppers, 1989 ] <author> M.J. Schoppers. </author> <title> In defense of reaction plans as caches. </title> <journal> AI Magazine, </journal> <volume> 10(4 (Winter)):51-60, </volume> <year> 1989. </year>
Reference-contexts: There is a variety of approaches for tackling some or many forms of uncertainty at planning or execution time; examples include reaction plans and reactive planning (see <ref> [ Schoppers, 1989 ] </ref> for a discussion and references), conditional planning [ Warren, 1976; Peot and Smith, 1992 ] , decision-theoretic planning methods [ Feldman and Sproull, 1977; Haddawy and Hanks, 1990 ] , or execution monitoring and replanning [ Fikes et al., 1972; Wilkins, 1988, Ch. 11 ] .
Reference: [ Thiebaux and Hertzberg, 1992 ] <author> S. Thiebaux and J. Hertzberg. </author> <title> A semi-reactive planner based on a possible models action formalization. </title> <editor> In [ Hendler, </editor> <year> 1992 </year> <month> ] , pages 228-235, </month> <year> 1992. </year>
Reference-contexts: Examples of such works are [ Drummond and Bresina, 1990; Beetz and McDermott, 1992 ] . In a previous paper <ref> [ Thiebaux and Hertzberg, 1992 ] </ref> , we have described pascale, a system for planning under uncertainty. <p> We do not yet exploit probabilistic information or deal with anytime planning issues; this will be done in the next section. We are summarizing key issues from <ref> [ Thiebaux and Hertzberg, 1992 ] </ref> here. Our description will be informal; the reader is referred to [ Thiebaux, 1992 ] for a more formal treatment. <p> Within our model, symbolic planning enables the search of a plan under uncertainty stemming from incomplete information about the start situation, from context dependency of actions, and from alternative action effects. We did not go into detail concerning these issues as they are presented elsewhere <ref> [ Thiebaux and Hertzberg, 1992 ] </ref> . The new issue is basically to introduce probabilities in order to both guide the search, and chose among feasible plan alternatives. <p> To generate them within our model, everything about the world must be known, all actions are context free and unambiguous. The reactive execution of such a plan is comparable to that of a strips triangle table [ Fikes et al., 1972 ] . See <ref> [ Thiebaux and Hertzberg, 1992 ] </ref> for details. Universal plans, as proposed in [ Schoppers, 1987 ] . To generate them, nothing about the initial situation is known, all actions are context free and unambiguous. Decision trees, as proposed by [ Feldman and Sproull, 1977 ] . <p> Decision trees, as proposed by [ Feldman and Sproull, 1977 ] . No restrictions can be made to generate them. Situation-action rules as from [ Drummond, 1989; Drummond and Bresina, 1990 ] , see Sections 3 and 4. pascale plans, as described in <ref> [ Thiebaux and Hertzberg, 1992 ] </ref> : to generate them, possible models always have equiprobability. A non-instance of our framework is, e.g., the planner by Kanazawa and Dean [ 1989 ] , whose causal model of the world is more expressive than ours.
Reference: [ Thiebaux, 1992 ] <author> S. Thiebaux. </author> <title> Anytime reaction planning in probabilistic logic. </title> <type> Master's thesis, </type> <institution> Florida Institute of Technology, </institution> <month> June </month> <year> 1992. </year>
Reference-contexts: It enables a whole spectrum of implementations; special cases being, e.g., 2 2 FORMALIZING ACTIONS IN PROBABILISTIC LOGIC classical linear plans and universal plans [ Schoppers, 1987 ] . The paper is based on <ref> [ Thiebaux, 1992 ] </ref> , which contains additional details. It is organized as follows. Section 2 describes our formalization of actions which blends our previously used formalism with Nilsson's [ 1986 ] probabilistic logic. <p> valid a context of the form [ l j (f:lg; ); (fg; 1 ) ] even if fg f:lg, because :l is achieved with the first postcondition, while l remains with the second. 7 This example ends the description of our action formalization, about which details can be found in <ref> [ Brewka and Hertzberg, To appear; Thiebaux, 1992 ] </ref> . We have exemplified that this formalization copes with uncertainty at planning time, such as incompleteness or ambiguity in world state descriptions; it also copes with ambiguity and context dependency of actions effects. <p> We do not yet exploit probabilistic information or deal with anytime planning issues; this will be done in the next section. We are summarizing key issues from [ Thiebaux and Hertzberg, 1992 ] here. Our description will be informal; the reader is referred to <ref> [ Thiebaux, 1992 ] </ref> for a more formal treatment. A plan is a bipartite directed graph with two types of nodes: T -nodes representing tasks, i.e., occurrences of actions in a plan, and M -nodes representing possible models.
Reference: [ Val, 1992 ] <author> A. Del Val. </author> <title> Computing knowledge base updates. </title> <booktitle> In Proc. KR-92, </booktitle> <pages> pages 740-750, </pages> <year> 1992. </year>
Reference-contexts: Experiments with pascale2 were conducted on a Sparc IPX workstation. Figure 5 shows the quality of the plans generated by the algorithm of Figure 4 as a function of 11 <ref> [ Val, 1992 ] </ref> also proposes algorithms for updating databases, based on a syntactic characterization of updates.
Reference: [ Wah and Chu, 1990 ] <author> B.W. Wah and L.C. Chu. </author> <title> T CA fl . a time constrained approximate A fl search algorithm. </title> <booktitle> In Proc. 1990 IEEE International Workshop on Tools for Artificial Intelligence, </booktitle> <pages> pages 314-320, </pages> <year> 1990. </year>
Reference-contexts: The a-priori quality estimation enables off-line planning using a general-purpose anytime algorithm, such as those based on expectation driven iterative refinement, e.g., <ref> [ Wah and Chu, 1990 ] </ref> . Furthermore, the updated estimations are suitable to incrementally improve an incomplete plan on-line, using the same general-purpose algorithms. The planner can interact with the execution monitor, and work with the updated estimation corresponding to the task currently executed.
Reference: [ Waldinger, 1977 ] <author> R. Waldinger. </author> <title> Achieving several goals simultaneously. </title> <journal> Machine Intelligence, </journal> <volume> 8 </volume> <pages> 94-136, </pages> <year> 1977. </year> <note> REFERENCES 25 </note>
Reference-contexts: Furthermore, restricting the search to valid plans reduces the search space considerably. We have not yet defined an appropriate version of regression <ref> [ Waldinger, 1977 ] </ref> for our action format, so that we presently do not generate plans in a backward fashion. In fact, it is highly questionable whether backward planning can bring advantages when planning under uncertainty and time pressure.
Reference: [ Warren, 1976 ] <author> D. H. D. Warren. </author> <title> Generating conditional plans and programs. </title> <booktitle> In AISB Summer Conference, </booktitle> <publisher> Edinburgh, </publisher> <pages> pages 344-354, </pages> <year> 1976. </year>
Reference-contexts: There is a variety of approaches for tackling some or many forms of uncertainty at planning or execution time; examples include reaction plans and reactive planning (see [ Schoppers, 1989 ] for a discussion and references), conditional planning <ref> [ Warren, 1976; Peot and Smith, 1992 ] </ref> , decision-theoretic planning methods [ Feldman and Sproull, 1977; Haddawy and Hanks, 1990 ] , or execution monitoring and replanning [ Fikes et al., 1972; Wilkins, 1988, Ch. 11 ] .
Reference: [ Wellman and Doyle, 1992 ] <author> M.P. Wellman and J. Doyle. </author> <title> Modular utility representation for decision-theoretic planning. </title> <editor> In [ Hendler, </editor> <year> 1992 </year> <month> ] , pages 236-242, </month> <year> 1992. </year>
Reference-contexts: Let aside the problem of building a multi-attribute utility function from individual attributes utilities, which is dealt with in <ref> [ Wellman and Doyle, 1992 ] </ref> , the plan quality is defined from the utility of tasks as follows. Def. 4.3 (Plan Quality) Let P be a plan, and (N N fi R) the matrix characterizing chain (P).
Reference: [ Wilkins, 1988 ] <author> D. Wilkins. </author> <title> Practical Planning. Extending the Classical AI Planning Paradigm. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: or execution time; examples include reaction plans and reactive planning (see [ Schoppers, 1989 ] for a discussion and references), conditional planning [ Warren, 1976; Peot and Smith, 1992 ] , decision-theoretic planning methods [ Feldman and Sproull, 1977; Haddawy and Hanks, 1990 ] , or execution monitoring and replanning <ref> [ Fikes et al., 1972; Wilkins, 1988, Ch. 11 ] </ref> .
Reference: [ Winslett, 1988 ] <author> M. Winslett. </author> <title> Reasoning about action using a possible models approach. </title> <booktitle> In Proc. AAAI-88, </booktitle> <pages> pages 89-93, </pages> <year> 1988. </year>
Reference: [ Zilberstein and Russel, 1992 ] <author> S. Zilberstein and S.J. Russel. </author> <title> Efficient ressource-bounded reasoning in AT-RALPH. </title> <editor> In [ Hendler, </editor> <year> 1992 </year> <month> ] , pages 260-266, </month> <year> 1992. </year>
Reference-contexts: Anytime planning algorithms [ Dean and Boddy, 1988 ] implement this idea. They have been applied to solving time-dependent planning problems [ Boddy and Dean, 1989 ] and are also used for a broad class of planning applications, e.g. <ref> [ Zilberstein and Russel, 1992 ] </ref> . Obviously, it is useful to combine work on these two topics, the perspective being to build planners that cope with uncertainty, and incrementally increase the plan quality if time permits. <p> Part of our future implementation work will be devoted to building more elaborate algorithms, and to their compilation into anytime algorithms with an optimal performance profile <ref> [ Zilberstein and Russel, 1992 ] </ref> . Experiments with pascale2 were conducted on a Sparc IPX workstation.
References-found: 48

