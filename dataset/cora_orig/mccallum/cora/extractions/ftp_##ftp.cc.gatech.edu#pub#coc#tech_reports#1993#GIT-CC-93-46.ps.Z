URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1993/GIT-CC-93-46.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.93.html
Root-URL: 
Title: Space-Efficient Atomic Snapshots in Synchronous Systems  
Author: Gil Neiger Ranu Singh 
Note: This research was supported in part by the National Science Foundation under grant CCR-9106627.  
Address: Atlanta, Georgia 30332-0280  
Affiliation: College of Computing Georgia Institute of Technology  
Date: July 28, 1993  
Pubnum: GIT-CC-93/46  
Abstract: We consider the problem of implementing an atomic snapshot memory in synchronous distributed systems. An atomic snapshot memory is an array of memory locations, one per processor. Each processor may update its own location or scan all locations atomically. We are interested in implementations that are space-efficient in the sense that they are honest. This means that the implementation may use no more shared memory than that of the array being implemented and that the memory truly reflect the contents of that array. If n is the number of processors involved, then the worst-case scanning time must be at least n. We show that the sum of the worst-case update and scanning times must be greater than b3n=2c. We exhibit two honest implementations. One has scans and updates with worst-case times of n + 1 for both operations; for scans, this is near the lower bound. The other requires longer scans (with worst-case time d3n=2e + 1) but shorter updates (with worst-case time dn=2e +1). Thus, both implementations have the sum of the worst-case times at 2n + O(1), which is within n=2 of the lower bound. Closing the gap between these algorithms and the combined lower bound remains an open problem. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Yehuda Afek, Hagit Attiya, Danny Dolev, Eli Gafni, Michael Merritt, and Nir Shavit. </author> <title> Atomic snapshots of shared memory. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 1-13. </pages> <publisher> ACM Press, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: There has been considerable research in the development of atomic snapshot memory. The problem was first explicitly considered by Afek et al. <ref> [1] </ref> and by Ander-son [2].
Reference: [2] <author> James H. Anderson. </author> <title> Composite registers. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 15-29. </pages> <publisher> ACM Press, </publisher> <month> August </month> <year> 1990. </year> <note> To appear in Distributed Computing. </note>
Reference-contexts: There has been considerable research in the development of atomic snapshot memory. The problem was first explicitly considered by Afek et al. [1] and by Ander-son <ref> [2] </ref>. Improved algorithms were developed later [3, 4, 8], with the fastest requiring O (n log n) low-level operations per update or scan. (Dwork et al. [5] studied a slightly weaker problem, while Gafni and Borowsky [6] considered a stronger version.) This paper takes a new approach to this problem.
Reference: [3] <author> Hagit Attiya, Maurice Herlihy, and Ophir Rachman. </author> <title> Efficient atomic snapshots using lattice agreement. </title> <editor> In A. Segall and S. Zaks, editors, </editor> <booktitle> Proceedings of the Sixth International Workshop on Distributed Algorithms, number 647 in Lecture Notes on Computer Science, </booktitle> <pages> pages 35-53. </pages> <publisher> Springer-Verlag, </publisher> <month> November </month> <year> 1992. </year>
Reference-contexts: There has been considerable research in the development of atomic snapshot memory. The problem was first explicitly considered by Afek et al. [1] and by Ander-son [2]. Improved algorithms were developed later <ref> [3, 4, 8] </ref>, with the fastest requiring O (n log n) low-level operations per update or scan. (Dwork et al. [5] studied a slightly weaker problem, while Gafni and Borowsky [6] considered a stronger version.) This paper takes a new approach to this problem.
Reference: [4] <author> Hagit Attiya and Ophir Rachman. </author> <title> Atomic snapshots in O(n log n) operations. </title> <booktitle> In Proceedings of the Twelfth ACM Symposium on Principles of Distributed Computing. </booktitle> <publisher> ACM Press, </publisher> <month> August </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: There has been considerable research in the development of atomic snapshot memory. The problem was first explicitly considered by Afek et al. [1] and by Ander-son [2]. Improved algorithms were developed later <ref> [3, 4, 8] </ref>, with the fastest requiring O (n log n) low-level operations per update or scan. (Dwork et al. [5] studied a slightly weaker problem, while Gafni and Borowsky [6] considered a stronger version.) This paper takes a new approach to this problem.
Reference: [5] <author> Cynthia Dwork, Maurice Herlihy, Serge Plotkin, and Orli Waarts. </author> <title> Time-lapse snapshots. </title> <booktitle> In Proceedings of the First Israel Symposium on Theory of Computing and Systems, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: The problem was first explicitly considered by Afek et al. [1] and by Ander-son [2]. Improved algorithms were developed later [3, 4, 8], with the fastest requiring O (n log n) low-level operations per update or scan. (Dwork et al. <ref> [5] </ref> studied a slightly weaker problem, while Gafni and Borowsky [6] considered a stronger version.) This paper takes a new approach to this problem. First, we restrict our domain to synchronous systems. We assume that processors have access to a global clock and can execute in lockstep.
Reference: [6] <author> Eli Gafni and Elizabeth Borowsky. </author> <title> Immediate atomic snapshots and fast renaming. </title> <booktitle> In Proceedings of the Twelfth ACM Symposium on Principles of Distributed Computing. </booktitle> <publisher> ACM Press, </publisher> <month> August </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: Improved algorithms were developed later [3, 4, 8], with the fastest requiring O (n log n) low-level operations per update or scan. (Dwork et al. [5] studied a slightly weaker problem, while Gafni and Borowsky <ref> [6] </ref> considered a stronger version.) This paper takes a new approach to this problem. First, we restrict our domain to synchronous systems. We assume that processors have access to a global clock and can execute in lockstep. This considerably simplifies the problem but does not trivialize it.
Reference: [7] <author> Maurice P. Herlihy and Jeannette M. Wing. </author> <title> Linearizability: A correctness condition for concurrent objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 463-492, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: This abstraction supports two operations: a processor may update one location in memory or it may atomically scan the entire memory. These operations are required to be linearizable <ref> [7] </ref>; this means that the overall execution should be consistent with one in which the operations executed serially in an order consistent with the order of operations whose execution does not overlap in real time). There has been considerable research in the development of atomic snapshot memory. <p> A read operation, of the form "read x i into `," reads the value of location x i and stores it in a local variable `. For the sake of simplicity, we assume that each memory access takes exactly one time unit. The memory is assumed to be linearizable <ref> [7] </ref>.
Reference: [8] <author> Amos Israel, Amnon Shaham, and Asaf Shirazi. </author> <title> Linear-time snapshot protocols for unbalanced systems. </title> <type> Unpublished manuscript, </type> <month> February </month> <year> 1993. </year>
Reference-contexts: There has been considerable research in the development of atomic snapshot memory. The problem was first explicitly considered by Afek et al. [1] and by Ander-son [2]. Improved algorithms were developed later <ref> [3, 4, 8] </ref>, with the fastest requiring O (n log n) low-level operations per update or scan. (Dwork et al. [5] studied a slightly weaker problem, while Gafni and Borowsky [6] considered a stronger version.) This paper takes a new approach to this problem.
Reference: [9] <author> Gil Neiger and Sam Toueg. </author> <title> Simulating synchronized clocks and common knowledge in distributed systems. </title> <journal> Journal of the ACM, </journal> <volume> 40(2) </volume> <pages> 334-367, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Because of this, our programming notation make use of wait statements, whose meaning should be clear from context. The synchronous abstraction described here is very strong and is not realized by most practical systems. However, Neiger and Toueg <ref> [9] </ref> have shown that it can be simulated in systems with approximately synchronized clocks, which can be practically implemented. (The results of Neiger and Toueg applied to systems with message passing; it is not hard to extend them to systems with shared memory.) This paper considers implementations of atomic snapshot memory.
References-found: 9

