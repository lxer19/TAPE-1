URL: http://www.iro.umontreal.ca/~lecuyer/myftp/papers/parmsrav.ps
Refering-URL: http://www.iro.umontreal.ca/~lecuyer/papers.html
Root-URL: http://www.iro.umontreal.ca
Title: ASYMPTOTIC EFFICIENCY OF PERTURBATION-ANALYSIS-BASED STOCHASTIC APPROXIMATION WITH AVERAGING  
Author: QIAN-YU TANG PIERRE L'ECUYER AND HAN-FU CHEN 
Keyword: Key words. perturbation analysis, asymptotic efficiency, central limit theorems, stochastic approximation, recursive estimation, queueing theory.  
Note: AMS subject classifications. 62L20, 93E12, 93E23, 93E30, 60F05, 60K25  
Abstract: Central limit theorems are obtained for the PARMSR (perturbation analysis Robbins-Monro single run) algorithm updated either after every regenerative cycle or after every fixed-length observation period, and with averaging of the iterates, for one-dependent regenerative processes. When the convergence to the optimizer is expressed in terms of the total observation time of the system (or the total computing budget in the case of a simulation), the convergence rate and the limit covariance matrix turn out to be the same for all updating schemes, and are optimal within the class of stochastic approximation algorithms, under certain assumptions. A bound on the strong convergence rate of the usual PARMSR algorithm updated after every fixed length observation period is established using a limit theorem on double array martingales. This is the key step for obtaining central limit theorems for the algorithms with averaging and has interest in its own right. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Asmussen, </author> <title> Applied Probability and Queues, </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Partially supported by the National Natural Science Foundation of China. 1 2 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN (see the next section for details). One-dependent regenerative is a weakened version of the classical notion of a regenerative stochastic process, and covers a broad class of systems <ref> [1, 29, 36] </ref>. The weakening is that adjacent regenerative cycles are allowed to be dependent. <p> If (A0) holds with F k m1 1 replaced by F k m 1 , the process is called classically regenerative. From the definition of J i and by Proposition V.1.1 of <ref> [1] </ref>, if (A0) holds for fX i ; i 0g, it also holds for fJ i ; i 0g with the same regeneration points. <p> It is well-known that Harris-recurrent Markov chains (HRMCs) are one-dependent regenerative processes for fixed ; this can be seen by applying the splitting technique due to [2]. HRMCs cover a very large class of models. We refer the reader to <ref> [1, 29, 30, 36] </ref> for appropriate background. <p> We refer the reader to [1, 29, 30, 36] for appropriate background. If E [j 1 ()] &lt; 1 and E i=1 jJ i ()j &lt; 1 for all 2 D, then J () in (1.2) is well defined on D and the renewal-reward theorem (see, e.g., <ref> [1] </ref> and [42]) says that J () = E [j 1 ()] 2 j 1 () X J i () 5 :(2.1) 2.2. Gradient Estimation via IPA and the PARMSR Algorithm. We now explain how IPA is used to estimate the gradient in this context.
Reference: [2] <author> K. B. Athreya and P. Ney, </author> <title> A new approach to the limit theorems of recurrent Markov chains, </title> <journal> Trans. Amer. Math. Soc., </journal> <volume> 245 (1978), </volume> <pages> pp. 493-501. </pages>
Reference-contexts: It is well-known that Harris-recurrent Markov chains (HRMCs) are one-dependent regenerative processes for fixed ; this can be seen by applying the splitting technique due to <ref> [2] </ref>. HRMCs cover a very large class of models. We refer the reader to [1, 29, 30, 36] for appropriate background.
Reference: [3] <author> H. F. Chen, </author> <title> Asymptotic efficient stochastic approximation, </title> <journal> Stochastics and Stochastics Reports, </journal> <volume> 45 (1993), </volume> <pages> pp. 1-16. </pages>
Reference-contexts: This has motivated the introduction of SA algorithms with averaging of the iterates, using a sequence of step sizes which decreases at a rate slower than 1=n (see <ref> [3, 5, 24, 31, 32, 43] </ref>). <p> 0 ) is asymptotically N (0; S fl ), with S fl = M 1 1 S fl 1 ) 0 , where S fl 0 is the asymptotic covariance matrix of (1= p P n j=1 " j , we say that the PARMSR algorithm is asymptotically optimal (see <ref> [3, 5, 43] </ref> for similar definitions in terms of n). This must be understood as optimal only within the class of SA algorithms and for the particular gradient estimator that is used. <p> Then, standard SA results are applicable. For case (F), the analysis is more difficult, primarily because the standard conditions on the observation noise, assumed in, e.g., <ref> [3, 24, 31, 32, 43] </ref>, do not hold. These authors require the observation noise to satisfy the properties of martingale differences, or of stationary OE-mixing processes, or of the infinite sum of a martingale difference sequence. <p> Observe that &lt; 1 in (A4), so the classical choice of a n = O (1=n) is not allowed. This (A4) is the usual condition of slowly decreasing step sizes (e.g., as in <ref> [3, 24, 32] </ref>). Conditions (A5) and (A6) are standard in the context of SA. (A5) asks the objective function to be locally quadratic around the optimizer 0 , while (A6) says that 0 should be an attractor point from every other point of D. <p> From (5.8) one derives n+1 0 a n+1 = ' n;n 0 p i=n 0 p (1) n X ' n;i+1 a i " i+1 n X ' n;i+1 o (a i ) a i " i+1 i=n 0 p In the proof of Theorem 2 of <ref> [3] </ref>, it is shown that E [k n 0 k 2 ] = O (a n ), so the last term on the right side of (5.11) converges to zero in probability via (5.10). <p> Similarly, we can prove that the first and the third terms converge to zero a.s.. Then, the result follows from standard martingale arguments. (iii). To prove (iii), we verify that all conditions of Theorem 2 in <ref> [3] </ref> are fulfilled. Using (2.9) in [3], it is easy to see that condition (A4) on the step sizes is equivalent to (1.5) and (1.6) in [3]. The condition on the existence of the Lyapunov function v () is put in (A6), which is weaker than A1) in [3] but is <p> Similarly, we can prove that the first and the third terms converge to zero a.s.. Then, the result follows from standard martingale arguments. (iii). To prove (iii), we verify that all conditions of Theorem 2 in <ref> [3] </ref> are fulfilled. Using (2.9) in [3], it is easy to see that condition (A4) on the step sizes is equivalent to (1.5) and (1.6) in [3]. The condition on the existence of the Lyapunov function v () is put in (A6), which is weaker than A1) in [3] but is consistent with A2 in [4] and <p> Then, the result follows from standard martingale arguments. (iii). To prove (iii), we verify that all conditions of Theorem 2 in <ref> [3] </ref> are fulfilled. Using (2.9) in [3], it is easy to see that condition (A4) on the step sizes is equivalent to (1.5) and (1.6) in [3]. The condition on the existence of the Lyapunov function v () is put in (A6), which is weaker than A1) in [3] but is consistent with A2 in [4] and A 4.3.3 in [7]. <p> 2 in <ref> [3] </ref> are fulfilled. Using (2.9) in [3], it is easy to see that condition (A4) on the step sizes is equivalent to (1.5) and (1.6) in [3]. The condition on the existence of the Lyapunov function v () is put in (A6), which is weaker than A1) in [3] but is consistent with A2 in [4] and A 4.3.3 in [7]. Note that we use a projection algorithm in (1.3) rather than a randomly varying truncation procedure as in [3, 4, 7]. Condition A2) in [3] is implied by our condition (A5). <p> Note that we use a projection algorithm in (1.3) rather than a randomly varying truncation procedure as in <ref> [3, 4, 7] </ref>. Condition A2) in [3] is implied by our condition (A5). We now check conditions A3) and A4) in [3], concerning the observation noise " n = " n + " n . <p> function v () is put in (A6), which is weaker than A1) in <ref> [3] </ref> but is consistent with A2 in [4] and A 4.3.3 in [7]. Note that we use a projection algorithm in (1.3) rather than a randomly varying truncation procedure as in [3, 4, 7]. Condition A2) in [3] is implied by our condition (A5). We now check conditions A3) and A4) in [3], concerning the observation noise " n = " n + " n . <p> Note that we use a projection algorithm in (1.3) rather than a randomly varying truncation procedure as in [3, 4, 7]. Condition A2) in <ref> [3] </ref> is implied by our condition (A5). We now check conditions A3) and A4) in [3], concerning the observation noise " n = " n + " n . Letting ffi = 0 in (5.5), by the Kronecker lemma it follows that as n ! 1, a n i=1 " i+1 ! 0 a.s., which is (2.5) in [3]. <p> now check conditions A3) and A4) in <ref> [3] </ref>, concerning the observation noise " n = " n + " n . Letting ffi = 0 in (5.5), by the Kronecker lemma it follows that as n ! 1, a n i=1 " i+1 ! 0 a.s., which is (2.5) in [3]. Since f" (1) f" 2n1 , F (2n1) , n 1g are martingale difference sequences, by (5.3) and (5.4) it is easy to derive that (2.6) and (2.7) in [3] are satisfied. <p> lemma it follows that as n ! 1, a n i=1 " i+1 ! 0 a.s., which is (2.5) in <ref> [3] </ref>. Since f" (1) f" 2n1 , F (2n1) , n 1g are martingale difference sequences, by (5.3) and (5.4) it is easy to derive that (2.6) and (2.7) in [3] are satisfied. From (5.7) it follows that k" n+1 k = O (k n n1 k) = O (a n1 kf n k). Then we derive that E [k" (2) n ), which satisfies A4) in [3]. We can thus apply Theorem 2 in [3] and this concludes the proof. <p> (5.3) and (5.4) it is easy to derive that (2.6) and (2.7) in <ref> [3] </ref> are satisfied. From (5.7) it follows that k" n+1 k = O (k n n1 k) = O (a n1 kf n k). Then we derive that E [k" (2) n ), which satisfies A4) in [3]. We can thus apply Theorem 2 in [3] and this concludes the proof. Proof of Theorem 4.1. For Theorem 4.1, we first give the proof for L = 1 for simplicity of writing, then extend the results to L &gt; 1. <p> that (2.6) and (2.7) in <ref> [3] </ref> are satisfied. From (5.7) it follows that k" n+1 k = O (k n n1 k) = O (a n1 kf n k). Then we derive that E [k" (2) n ), which satisfies A4) in [3]. We can thus apply Theorem 2 in [3] and this concludes the proof. Proof of Theorem 4.1. For Theorem 4.1, we first give the proof for L = 1 for simplicity of writing, then extend the results to L &gt; 1. <p> If conditions (A0)-(A11) are satisfied, with ffi 0 satisfying (A11), then a n+1 j=0 n ! 1 Proof. Since M 1 is stable, it is standard to derive that (see, e.g., <ref> [3] </ref> and [7]): k n;i k c 0 exp @ c j=i 1 a i = exp o (1) s=i ! sup n X a i exp @ rc j=i+1 1 n i=1 where c 0 and c are some constants and o (1) ! 0 as i ! 1. <p> It is shown in Lemma 1 of <ref> [3] </ref> that for all n j 1, G n;j defined by (5.46) are bounded. By Theorem 4.1, condition (A5), and (5.47), the lemma follows easily. Lemma 5.5. Suppose that conditions (A0)|(A11) are satisfied. <p> STOCHASTIC APPROXIMATION WITH AVERAGING 23 (i). By the definition (5.46), we get E 6 fl fl fl 1 n m=0 fl fl fl 2 7 1 E 4 m=0 3 E (j fl (0) i 1 n+1 X kG n;i k 2 ! 0 via Lemma 1 of <ref> [3] </ref>. By (5.59), it is easy to derive that 1= p P oe (n)1 in probability as n ! 1. (ii).
Reference: [4] <author> H. F. Chen, </author> <title> Stochastic approximation and its new applications, </title> <booktitle> Proc. 1994 Hong Kong International Workshop on New Directions in Control and Manufacturing, </booktitle> <pages> pp. 2-12, </pages> <year> 1994. </year>
Reference-contexts: By (5.5) and (5.7), the a.s. convergence of the algorithm follows from Theorem 3.1 in <ref> [4] </ref> (see also Theorem 2.4.1 in [7]). Note that we are using a projection algorithm in (1.3), rather than a randomly varying truncation procedure as in [4, 7]. But the convergence analysis works the same way, since 0 is assumed in (A5) to be in the interior of D. <p> By (5.5) and (5.7), the a.s. convergence of the algorithm follows from Theorem 3.1 in [4] (see also Theorem 2.4.1 in [7]). Note that we are using a projection algorithm in (1.3), rather than a randomly varying truncation procedure as in <ref> [4, 7] </ref>. But the convergence analysis works the same way, since 0 is assumed in (A5) to be in the interior of D. After establishing the convergence, by (5.5), (5.7), and Theorem 3.2.1 of [7], it follows that k n k = o (a ffi n ) a.s. (ii). <p> The condition on the existence of the Lyapunov function v () is put in (A6), which is weaker than A1) in [3] but is consistent with A2 in <ref> [4] </ref> and A 4.3.3 in [7]. Note that we use a projection algorithm in (1.3) rather than a randomly varying truncation procedure as in [3, 4, 7]. Condition A2) in [3] is implied by our condition (A5). <p> Note that we use a projection algorithm in (1.3) rather than a randomly varying truncation procedure as in <ref> [3, 4, 7] </ref>. Condition A2) in [3] is implied by our condition (A5). We now check conditions A3) and A4) in [3], concerning the observation noise " n = " n + " n . <p> The proof is in Guo, Huang, and Hannan [19]. See also [6]. Proof of Theorem 4.1 (i) for L = 1. The key idea lies in verifying that P 1 n=1 a n " n+1 converges a.s.. Then the desired result follows from Theorem 3.1 in <ref> [4] </ref> (see also Theorem 2.4.1 in [7]).
Reference: [5] <author> H. F. Chen, </author> <title> Continuous-time stochastic approximation: convergence and asymptotic efficiency, </title> <journal> Stochastics and Stochastics Reports, </journal> <volume> 51 (1994), </volume> <pages> pp. 111-132. </pages>
Reference-contexts: This has motivated the introduction of SA algorithms with averaging of the iterates, using a sequence of step sizes which decreases at a rate slower than 1=n (see <ref> [3, 5, 24, 31, 32, 43] </ref>). <p> 0 ) is asymptotically N (0; S fl ), with S fl = M 1 1 S fl 1 ) 0 , where S fl 0 is the asymptotic covariance matrix of (1= p P n j=1 " j , we say that the PARMSR algorithm is asymptotically optimal (see <ref> [3, 5, 43] </ref> for similar definitions in terms of n). This must be understood as optimal only within the class of SA algorithms and for the particular gradient estimator that is used.
Reference: [6] <author> H. F. Chen and L. Guo, </author> <title> Identification and Stochastic Adaptive Control, </title> <publisher> Birkhauser, </publisher> <year> 1991. </year>
Reference-contexts: In this paper, we first obtain a bound on the almost sure (a.s.) convergence rate of the usual PARMSR algorithm (without averaging), using a limit theorem on double array martingales borrowed from <ref> [6] </ref> and [19]. We then apply this result to obtain a central limit theorem showing the asymptotic optimality of the PARMSR algorithm with averaging for the case (F). <p> By (5.1) and condition (A3), k" n+1 k j fl 2D 2D which yields sup E k" n+1 k 2 j F (n1) &lt; 1 (5.4) by Schwarz inequality and (A3). Then, using the local convergence theorem of martin gales (see, e.g., <ref> [6, 20, 37] </ref>), it is seen that P 1 (1ffi) (1) P 1 (1ffi) (1) 1 a.s., which implies that 1 X a 1ffi (1) By Lemma 2 of [40] and condition (A3), one derives a n1 Z n ! 0 and a n1 j fl n ! 1 Using condition <p> Then, as n ! 1, max k j=1 Proof. The proof is in Guo, Huang, and Hannan [19]. See also <ref> [6] </ref>. Proof of Theorem 4.1 (i) for L = 1. The key idea lies in verifying that P 1 n=1 a n " n+1 converges a.s.. Then the desired result follows from Theorem 3.1 in [4] (see also Theorem 2.4.1 in [7]). <p> fl fl fl i=1 fl fl fl fi fi F (m) m=1 p a k m E j fl m+1 Z m+1 m=1 m +1=2 E j fl m+1 Z m+1 &lt; 1; a:s:; which implies 1 X 1 m i=1 by the local convergence theorem of martingales (see, e.g., <ref> [6, 20, 37] </ref>). By the Kro necker lemma, it follows from (5.49) that lim 1 n m=0 i=1 which gives lim 1 n m=0 i=1 since oe (n) n; 8 n 1. STOCHASTIC APPROXIMATION WITH AVERAGING 21 (iii).
Reference: [7] <author> H. F. Chen and Y. M. Zhu, </author> <title> Stochastic Approximation, </title> <publisher> Shanghai Scientific and Technological Publishers, </publisher> <year> 1996. </year>
Reference-contexts: See, e.g., <ref> [7, 22, 24, 28] </ref>. <p> In the context of queueing systems, for example, STOCHASTIC APPROXIMATION WITH AVERAGING 7 the set D may represent a stability region where the standard load conditions are fulfilled. In the case where D is unbounded, an SA procedure with randomly varying truncations can be employed (see, e.g., [3]-[5], and <ref> [7] </ref>). Condition (A7) requires that the regression function f () is sufficiently smooth. <p> By (5.5) and (5.7), the a.s. convergence of the algorithm follows from Theorem 3.1 in [4] (see also Theorem 2.4.1 in <ref> [7] </ref>). Note that we are using a projection algorithm in (1.3), rather than a randomly varying truncation procedure as in [4, 7]. But the convergence analysis works the same way, since 0 is assumed in (A5) to be in the interior of D. <p> By (5.5) and (5.7), the a.s. convergence of the algorithm follows from Theorem 3.1 in [4] (see also Theorem 2.4.1 in [7]). Note that we are using a projection algorithm in (1.3), rather than a randomly varying truncation procedure as in <ref> [4, 7] </ref>. But the convergence analysis works the same way, since 0 is assumed in (A5) to be in the interior of D. After establishing the convergence, by (5.5), (5.7), and Theorem 3.2.1 of [7], it follows that k n k = o (a ffi n ) a.s. (ii). <p> But the convergence analysis works the same way, since 0 is assumed in (A5) to be in the interior of D. After establishing the convergence, by (5.5), (5.7), and Theorem 3.2.1 of <ref> [7] </ref>, it follows that k n k = o (a ffi n ) a.s. (ii). <p> The condition on the existence of the Lyapunov function v () is put in (A6), which is weaker than A1) in [3] but is consistent with A2 in [4] and A 4.3.3 in <ref> [7] </ref>. Note that we use a projection algorithm in (1.3) rather than a randomly varying truncation procedure as in [3, 4, 7]. Condition A2) in [3] is implied by our condition (A5). <p> Note that we use a projection algorithm in (1.3) rather than a randomly varying truncation procedure as in <ref> [3, 4, 7] </ref>. Condition A2) in [3] is implied by our condition (A5). We now check conditions A3) and A4) in [3], concerning the observation noise " n = " n + " n . <p> See also [6]. Proof of Theorem 4.1 (i) for L = 1. The key idea lies in verifying that P 1 n=1 a n " n+1 converges a.s.. Then the desired result follows from Theorem 3.1 in [4] (see also Theorem 2.4.1 in <ref> [7] </ref>). Recall that the observation noise here is " n+1 = f n+1 f ( n ):(5.12) Denote D m;i = J (m+1) ;i ( k m ), the value of f k m +i obtained if k m +j is fixed at k m for j 0. (a). <p> If conditions (A0)-(A11) are satisfied, with ffi 0 satisfying (A11), then a n+1 j=0 n ! 1 Proof. Since M 1 is stable, it is standard to derive that (see, e.g., [3] and <ref> [7] </ref>): k n;i k c 0 exp @ c j=i 1 a i = exp o (1) s=i ! sup n X a i exp @ rc j=i+1 1 n i=1 where c 0 and c are some constants and o (1) ! 0 as i ! 1.
Reference: [8] <author> E. K. P. Chong and P. J. Ramadge, </author> <title> Convergence of recursive optimization algorithms using infinitesimal perturbation analysis estimates, Discrete Event Dynamic Systems: </title> <journal> Theory and Applications, </journal> <volume> 1 (1992), </volume> <pages> pp. 339-372. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> TANG, P. L'ECUYER, AND H. F. CHEN A classical example where (A1) to (A3) are verified in the literature is that of the GI=G=1 queue considered in <ref> [8, 9, 24, 26, 41] </ref>. Lemma 2.1. If conditions (A0)|(A3) hold, then for each 2 D, the IPA derivative estimator is strongly consistent for f () and f () = E [j 1 ()] 2 j 1 () X J ;i () 5 :(2.3) Proof. <p> This motivates taking L n+1 = j n+1 and K = 1 in (2.2). The PARMSR algorithm without averaging for case (R) is comprised of (1.3) and (2.2) (cf. <ref> [8, 14, 26, 27] </ref>), with ~ i = n1 for k n &lt; i k n+1 , and where 1 ; 0 2 D are initial values. Thus, f n+1 is viewed as an estimator of f ( n1 )j ( n1 ).
Reference: [9] <author> E. K. P. Chong and P. J. Ramadge, </author> <title> Optimization of queues using an infinitesimal perturbation analysis-based stochastic algorithm with general updates times, </title> <journal> SIAM J. Contr. Optim., </journal> <volume> 31 (1993), </volume> <pages> pp. 698-732. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> For the PARMSR algorithm with fixed-length observation period, the observation noise has a very complicated dynamic, as shown in previous convergence studies; see, e.g., <ref> [9, 10, 23, 26, 40, 41] </ref>. In this paper, we first obtain a bound on the almost sure (a.s.) convergence rate of the usual PARMSR algorithm (without averaging), using a limit theorem on double array martingales borrowed from [6] and [19]. <p> TANG, P. L'ECUYER, AND H. F. CHEN A classical example where (A1) to (A3) are verified in the literature is that of the GI=G=1 queue considered in <ref> [8, 9, 24, 26, 41] </ref>. Lemma 2.1. If conditions (A0)|(A3) hold, then for each 2 D, the IPA derivative estimator is strongly consistent for f () and f () = E [j 1 ()] 2 j 1 () X J ;i () 5 :(2.3) Proof. <p> For example, (A9) and (A10) have been verified 8 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN in <ref> [9, 10, 40, 41] </ref> in the context of a GI=G=1 queue, with some conditions on the service time and the interarrival time distributions. Theorem 4.1. For the PARMSR algorithm with fixed updating period L n = L, we have: (i).
Reference: [10] <author> E. K. P. Chong and P. J. Ramadge, </author> <title> Stochastic optimization of regenerative systems using infinitesimal perturbation analysis, </title> <journal> IEEE Trans. Automat. Contr., </journal> <volume> 39 (1994), </volume> <pages> pp. 1400-1410. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> For the PARMSR algorithm with fixed-length observation period, the observation noise has a very complicated dynamic, as shown in previous convergence studies; see, e.g., <ref> [9, 10, 23, 26, 40, 41] </ref>. In this paper, we first obtain a bound on the almost sure (a.s.) convergence rate of the usual PARMSR algorithm (without averaging), using a limit theorem on double array martingales borrowed from [6] and [19]. <p> p 1 &gt; 1 and i &gt; 0 are other constants such that for fl 1 in (A10), (1 + fl 1 (1 1=p 1 )) &gt; 1; 0 &lt; i &lt; ffi 0 ; fl 1 (1 1=p 1 ) 1=2; ffi 0 2 (0; 1=2]: Chong and Ramadge <ref> [10] </ref> have checked conditions (A9) and (A10) for certain classically regenerative systems, though the convergence rates of the PARMSR algorithms have not been studied there. For example, (A9) and (A10) have been verified 8 Q.-Y. TANG, P. L'ECUYER, AND H. F. <p> For example, (A9) and (A10) have been verified 8 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN in <ref> [9, 10, 40, 41] </ref> in the context of a GI=G=1 queue, with some conditions on the service time and the interarrival time distributions. Theorem 4.1. For the PARMSR algorithm with fixed updating period L n = L, we have: (i).
Reference: [11] <author> Y. S. Chow and H. Teicher, </author> <title> Probability Theory: Independence, Interchangeability, Martingale, Second Edition, </title> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: Then for any r &gt; 0, Ejz 1 j r &lt; 1 implies lim n 1=r z n = 0 a.s. Furthermore, if fz i ; i 1g are mutually independent, then the converse is true. Proof. The proof follows from the Borel-Cantelli lemma and Corollary 4.1.3 in <ref> [11] </ref>, pp. 90-91. See also Lemma 2 in [40]. STOCHASTIC APPROXIMATION WITH AVERAGING 11 Lemma 5.2. <p> For any ffi 0 2 (0; 1=2 (1 1=(2))), by condition (A4) and Theorem 3.2 it follows that 1 X 1 i 1 X 1 i i ) = i=1 p o 1 which gives lim 1 n j=1 via the Kronecker lemma (see, e.g., <ref> [11] </ref>). It is shown in Lemma 1 of [3] that for all n j 1, G n;j defined by (5.46) are bounded. By Theorem 4.1, condition (A5), and (5.47), the lemma follows easily. Lemma 5.5. Suppose that conditions (A0)|(A11) are satisfied. <p> Similar to (iv), we can prove that the fifth term on the right hand side of (5.48) converges to zero a.s., as n ! 1. (vi). By the central limit theorem for martingales (see, e.g., <ref> [11] </ref> and [20]), 1 n m=0 d n ! 1 We now show that oe (n) ! 1 ; a:s:(5.53) One can decompose 1 n X j i = n i=1 (i) 1 n X (j 1 ( k i1 ) j ( k i1 ))(5.54) 1 n X (j ( <p> To prove 1 n m=0 n ! 1 we need a central limit theorem for stopped martingales. We note that if the Kol mogorov inequality is replaced by Doob's inequality (see, e.g., <ref> [11] </ref>), the proof of Theorem 9.4.1 in [11] goes through for the stopped martingales. Then, by (5.52) and (5.53), (5.57) follows. Lemma 5.6. If the conditions of Theorem 4.1 (iii) are fulfilled, then 1= p P n 0 in probability as n ! 1. Proof. <p> To prove 1 n m=0 n ! 1 we need a central limit theorem for stopped martingales. We note that if the Kol mogorov inequality is replaced by Doob's inequality (see, e.g., <ref> [11] </ref>), the proof of Theorem 9.4.1 in [11] goes through for the stopped martingales. Then, by (5.52) and (5.53), (5.57) follows. Lemma 5.6. If the conditions of Theorem 4.1 (iii) are fulfilled, then 1= p P n 0 in probability as n ! 1. Proof.
Reference: [12] <author> P. Dupuis and H. J. Kushner, </author> <title> Stochastic approximations via large deviations: Asymptotic properties, </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> 23 (1985), </volume> <pages> pp. 675-696. </pages>
Reference-contexts: Another type of convergence rate, in the sense of large-deviation bounds on the probability of exit of a neighborhood of 0 by the tail process f n ; n n 0 g for large n 0 , is studied in <ref> [12] </ref>. We analyze the following two cases: * (R) The parameter n is updated after each regenerative cycle of the process fJ i ; i 0g (so, L n is random and represents the length of the nth regenerative cycle).
Reference: [13] <author> P. Dupuis and R. Simha, </author> <title> On Sampling Controlled Stochastic approximation, </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> 36 (1991), </volume> <pages> pp. </pages> <month> 915-924. </month> <title> STOCHASTIC APPROXIMATION WITH AVERAGING 25 </title>
Reference-contexts: See [34]-[35] on the identification of regeneration points for closed and open queueing networks. A third approach, not considered here, is to have L n ! 1 with n. This was studied in [28] for decreasing step sizes and in <ref> [13] </ref> for constant step sizes, without the averaging of the iterates. 4 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN The rest of the paper is organized as follows.
Reference: [14] <author> M. C. Fu, </author> <title> Convergence of a stochastic approximation algorithm for the GI/G/1 queue using infinitesimal perturbation analysis, </title> <journal> J. of Optim. Theory and Appl., </journal> <volume> 65 (1990), </volume> <pages> pp. 149-160. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> This motivates taking L n+1 = j n+1 and K = 1 in (2.2). The PARMSR algorithm without averaging for case (R) is comprised of (1.3) and (2.2) (cf. <ref> [8, 14, 26, 27] </ref>), with ~ i = n1 for k n &lt; i k n+1 , and where 1 ; 0 2 D are initial values. Thus, f n+1 is viewed as an estimator of f ( n1 )j ( n1 ).
Reference: [15] <author> P. Glasserman, </author> <title> Gradient Estimation via Perturbation Analysis, </title> <publisher> Kluwer Academic, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: The major advan tage of this averaging algorithm is that there is no need to know M 1 1 . Under appropriate smoothness conditions, infinitesimal perturbation analysis (IPA) offers viable means of estimating f () by observing a single sample path of the system (see Section 2.2 and, e.g., <ref> [15, 21, 25] </ref> and other references therein). <p> Assuming that these stochastic derivatives exist and under appropriate uniform integrability conditions (see <ref> [15, 25] </ref>), J ;i () is an unbiased IPA estimator of the gradient of E [J i ()]. Suppose now that is not fixed, but take the successive values f ~ i ; i 0g as in (1.1). This is what happens when the PARMSR algorithm is applied. <p> Glasserman and his co-authors <ref> [15] </ref>|[18] give several sets of sufficient conditions for this property to hold for fixed , for classically regenerative systems (see, e.g., Theorem 8.3 in [15], Theorem 5.4 in [16], and Theorem 5.6 in [17]). The following conditions ensure, among other things, that the IPA estimators are strongly consistent for f (), in the sense that lim t!1 (1=t) P t i=1 J ;i () = f () a.s.
Reference: [16] <author> P. Glasserman, </author> <title> Stationary waiting time derivatives, </title> <journal> QUESTA, </journal> <volume> 12 (1992), </volume> <pages> pp. 369-390. </pages>
Reference-contexts: Glasserman and his co-authors [15]|[18] give several sets of sufficient conditions for this property to hold for fixed , for classically regenerative systems (see, e.g., Theorem 8.3 in [15], Theorem 5.4 in <ref> [16] </ref>, and Theorem 5.6 in [17]). The following conditions ensure, among other things, that the IPA estimators are strongly consistent for f (), in the sense that lim t!1 (1=t) P t i=1 J ;i () = f () a.s. We denote J ;i () = dJ i ()=d.
Reference: [17] <author> P. Glasserman, </author> <title> Regenerative derivatives of regenerative sequences, </title> <journal> Adv. Appl. Prob., </journal> <volume> 25 (1993), </volume> <pages> pp. 116-139. </pages>
Reference-contexts: Glasserman and his co-authors [15]|[18] give several sets of sufficient conditions for this property to hold for fixed , for classically regenerative systems (see, e.g., Theorem 8.3 in [15], Theorem 5.4 in [16], and Theorem 5.6 in <ref> [17] </ref>). The following conditions ensure, among other things, that the IPA estimators are strongly consistent for f (), in the sense that lim t!1 (1=t) P t i=1 J ;i () = f () a.s. We denote J ;i () = dJ i ()=d.
Reference: [18] <author> P. Glasserman, J. Q. Hu, and S. G. Strickland, </author> <title> Strongly consistent steady-state derivative estimates, </title> <booktitle> Probability in the Engineering and Informational Sciences, 5 (1991), </booktitle> <pages> pp. 391-413. </pages>
Reference: [19] <author> L. Guo, D. W. Huang, and E. J. Hannan, </author> <title> On ARX (1) approximation, </title> <journal> J. Multivariate Analysis, </journal> <volume> 32 (1990), </volume> <pages> pp. 17-47. </pages>
Reference-contexts: In this paper, we first obtain a bound on the almost sure (a.s.) convergence rate of the usual PARMSR algorithm (without averaging), using a limit theorem on double array martingales borrowed from [6] and <ref> [19] </ref>. We then apply this result to obtain a central limit theorem showing the asymptotic optimality of the PARMSR algorithm with averaging for the case (F). <p> Then, as n ! 1, max k j=1 Proof. The proof is in Guo, Huang, and Hannan <ref> [19] </ref>. See also [6]. Proof of Theorem 4.1 (i) for L = 1. The key idea lies in verifying that P 1 n=1 a n " n+1 converges a.s.. Then the desired result follows from Theorem 3.1 in [4] (see also Theorem 2.4.1 in [7]).
Reference: [20] <author> P. Hall and C. C. Heyde, </author> <title> Martingale Limit Theory and Its Application. </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: By (5.1) and condition (A3), k" n+1 k j fl 2D 2D which yields sup E k" n+1 k 2 j F (n1) &lt; 1 (5.4) by Schwarz inequality and (A3). Then, using the local convergence theorem of martin gales (see, e.g., <ref> [6, 20, 37] </ref>), it is seen that P 1 (1ffi) (1) P 1 (1ffi) (1) 1 a.s., which implies that 1 X a 1ffi (1) By Lemma 2 of [40] and condition (A3), one derives a n1 Z n ! 0 and a n1 j fl n ! 1 Using condition <p> fl fl fl i=1 fl fl fl fi fi F (m) m=1 p a k m E j fl m+1 Z m+1 m=1 m +1=2 E j fl m+1 Z m+1 &lt; 1; a:s:; which implies 1 X 1 m i=1 by the local convergence theorem of martingales (see, e.g., <ref> [6, 20, 37] </ref>). By the Kro necker lemma, it follows from (5.49) that lim 1 n m=0 i=1 which gives lim 1 n m=0 i=1 since oe (n) n; 8 n 1. STOCHASTIC APPROXIMATION WITH AVERAGING 21 (iii). <p> Similar to (iv), we can prove that the fifth term on the right hand side of (5.48) converges to zero a.s., as n ! 1. (vi). By the central limit theorem for martingales (see, e.g., [11] and <ref> [20] </ref>), 1 n m=0 d n ! 1 We now show that oe (n) ! 1 ; a:s:(5.53) One can decompose 1 n X j i = n i=1 (i) 1 n X (j 1 ( k i1 ) j ( k i1 ))(5.54) 1 n X (j ( k i1
Reference: [21] <author> Y. C. Ho and X. R. Cao, </author> <title> Perturbation Analysis of Discrete Event Dynamic Systems, </title> <publisher> Kluwer Academic, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: The major advan tage of this averaging algorithm is that there is no need to know M 1 1 . Under appropriate smoothness conditions, infinitesimal perturbation analysis (IPA) offers viable means of estimating f () by observing a single sample path of the system (see Section 2.2 and, e.g., <ref> [15, 21, 25] </ref> and other references therein).
Reference: [22] <author> H. J. Kushner and D. S. Clark, </author> <title> Stochastic Approximation Methods for Constrained and Unconstrained Systems, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1978. </year>
Reference-contexts: See, e.g., <ref> [7, 22, 24, 28] </ref>.
Reference: [23] <author> H. J. Kushner and F. J. V azquez-Abad, </author> <title> Stochastic approximation methods for systems of interest over an infinite horizon, </title> <journal> SIAM J. on Control and Optim., </journal> <volume> 34 (1996), </volume> <pages> pp. 712-756. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> For the PARMSR algorithm with fixed-length observation period, the observation noise has a very complicated dynamic, as shown in previous convergence studies; see, e.g., <ref> [9, 10, 23, 26, 40, 41] </ref>. In this paper, we first obtain a bound on the almost sure (a.s.) convergence rate of the usual PARMSR algorithm (without averaging), using a limit theorem on double array martingales borrowed from [6] and [19].
Reference: [24] <author> H. J. Kushner and G. G. </author> <title> Yin Stochastic Approximation Algorithms and Applications, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1997. </year>
Reference-contexts: See, e.g., <ref> [7, 22, 24, 28] </ref>. <p> This has motivated the introduction of SA algorithms with averaging of the iterates, using a sequence of step sizes which decreases at a rate slower than 1=n (see <ref> [3, 5, 24, 31, 32, 43] </ref>). <p> Then, standard SA results are applicable. For case (F), the analysis is more difficult, primarily because the standard conditions on the observation noise, assumed in, e.g., <ref> [3, 24, 31, 32, 43] </ref>, do not hold. These authors require the observation noise to satisfy the properties of martingale differences, or of stationary OE-mixing processes, or of the infinite sum of a martingale difference sequence. <p> TANG, P. L'ECUYER, AND H. F. CHEN A classical example where (A1) to (A3) are verified in the literature is that of the GI=G=1 queue considered in <ref> [8, 9, 24, 26, 41] </ref>. Lemma 2.1. If conditions (A0)|(A3) hold, then for each 2 D, the IPA derivative estimator is strongly consistent for f () and f () = E [j 1 ()] 2 j 1 () X J ;i () 5 :(2.3) Proof. <p> Observe that &lt; 1 in (A4), so the classical choice of a n = O (1=n) is not allowed. This (A4) is the usual condition of slowly decreasing step sizes (e.g., as in <ref> [3, 24, 32] </ref>). Conditions (A5) and (A6) are standard in the context of SA. (A5) asks the objective function to be locally quadratic around the optimizer 0 , while (A6) says that 0 should be an attractor point from every other point of D.
Reference: [25] <author> P. L'Ecuyer, </author> <title> A Unified View of the IPA, SF, and LR Gradient Estimation Techniques, </title> <booktitle> Management Science, 36 (1990), </booktitle> <pages> 1364-1383. </pages>
Reference-contexts: The major advan tage of this averaging algorithm is that there is no need to know M 1 1 . Under appropriate smoothness conditions, infinitesimal perturbation analysis (IPA) offers viable means of estimating f () by observing a single sample path of the system (see Section 2.2 and, e.g., <ref> [15, 21, 25] </ref> and other references therein). <p> Assuming that these stochastic derivatives exist and under appropriate uniform integrability conditions (see <ref> [15, 25] </ref>), J ;i () is an unbiased IPA estimator of the gradient of E [J i ()]. Suppose now that is not fixed, but take the successive values f ~ i ; i 0g as in (1.1). This is what happens when the PARMSR algorithm is applied.
Reference: [26] <author> P. L'Ecuyer and P. W. Glynn, </author> <title> Stochastic optimization by simulation: convergence proofs for the GI/G/1 queue in steady-state, </title> <institution> Management Sci., </institution> <month> 40 </month> <year> (1994), </year> <pages> pp. 1562-1578. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> For the PARMSR algorithm with fixed-length observation period, the observation noise has a very complicated dynamic, as shown in previous convergence studies; see, e.g., <ref> [9, 10, 23, 26, 40, 41] </ref>. In this paper, we first obtain a bound on the almost sure (a.s.) convergence rate of the usual PARMSR algorithm (without averaging), using a limit theorem on double array martingales borrowed from [6] and [19]. <p> TANG, P. L'ECUYER, AND H. F. CHEN A classical example where (A1) to (A3) are verified in the literature is that of the GI=G=1 queue considered in <ref> [8, 9, 24, 26, 41] </ref>. Lemma 2.1. If conditions (A0)|(A3) hold, then for each 2 D, the IPA derivative estimator is strongly consistent for f () and f () = E [j 1 ()] 2 j 1 () X J ;i () 5 :(2.3) Proof. <p> This motivates taking L n+1 = j n+1 and K = 1 in (2.2). The PARMSR algorithm without averaging for case (R) is comprised of (1.3) and (2.2) (cf. <ref> [8, 14, 26, 27] </ref>), with ~ i = n1 for k n &lt; i k n+1 , and where 1 ; 0 2 D are initial values. Thus, f n+1 is viewed as an estimator of f ( n1 )j ( n1 ). <p> Condition (A8) requires the continuity of j () and H () at the optimizer 0 . This is a mild condition. See <ref> [26] </ref> for the verification in the context of a GI/G/1 queue. The following theorem contains our main results for case (R). Theorem 3.1. (i). Suppose that the conditions (A0)-(A7) hold with 0 4 in (A3), and that j () is Lipschitz with modulus B 2 .
Reference: [27] <author> P. L'Ecuyer, N. Giroux, and P. W. Glynn, </author> <title> Stochastic optimization by simulation: numerical experiments with the M/M/1 queue in steady-state, </title> <institution> Management Sci., </institution> <month> 40 </month> <year> (1994), </year> <pages> pp. 1245-1261. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> This motivates taking L n+1 = j n+1 and K = 1 in (2.2). The PARMSR algorithm without averaging for case (R) is comprised of (1.3) and (2.2) (cf. <ref> [8, 14, 26, 27] </ref>), with ~ i = n1 for k n &lt; i k n+1 , and where 1 ; 0 2 D are initial values. Thus, f n+1 is viewed as an estimator of f ( n1 )j ( n1 ).
Reference: [28] <author> P. L'Ecuyer and G. Yin, </author> <title> Budget-dependent convergence rate of stochastic approximation, </title> <journal> SIAM J. on Optim., </journal> <volume> 8 (1998), </volume> <pages> pp. 217-247. </pages>
Reference-contexts: See, e.g., <ref> [7, 22, 24, 28] </ref>. <p> Let N n represent the cumulative computing budget for the first n steps of the PARMSR algorithm. We express the convergence speed of the algorithm in terms of N n (as done, e.g., in <ref> [28] </ref>) instead of n. <p> See [34]-[35] on the identification of regeneration points for closed and open queueing networks. A third approach, not considered here, is to have L n ! 1 with n. This was studied in <ref> [28] </ref> for decreasing step sizes and in [13] for constant step sizes, without the averaging of the iterates. 4 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN The rest of the paper is organized as follows.
Reference: [29] <author> S. P. Meyn and R. L. Tweedie, </author> <title> Markov Chains and Stochastic Stability, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Partially supported by the National Natural Science Foundation of China. 1 2 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN (see the next section for details). One-dependent regenerative is a weakened version of the classical notion of a regenerative stochastic process, and covers a broad class of systems <ref> [1, 29, 36] </ref>. The weakening is that adjacent regenerative cycles are allowed to be dependent. <p> When this condition (A0) is satisfied, the controlled process fJ i ; i 0g is called (non-delayed) one-dependent regenerative. This extends the usual definition found, e.g., in <ref> [29, 36] </ref>: For the process fJ i (); i 0g, for which is fixed from the beginning, we get the usual definition of one-dependent regenerative, which we call in this paper one-dependent regenerative for fixed . The k m 's are called the regeneration points. <p> It is well-known that Harris-recurrent Markov chains (HRMCs) are one-dependent regenerative processes for fixed ; this can be seen by applying the splitting technique due to [2]. HRMCs cover a very large class of models. We refer the reader to <ref> [1, 29, 30, 36] </ref> for appropriate background.
Reference: [30] <author> E. Nummelin, </author> <title> General Irreducible Markov Chains and Non-negative Operators, </title> <publisher> Cambridge Univ. Press, </publisher> <address> New York, </address> <year> 1984 </year>
Reference-contexts: It is well-known that Harris-recurrent Markov chains (HRMCs) are one-dependent regenerative processes for fixed ; this can be seen by applying the splitting technique due to [2]. HRMCs cover a very large class of models. We refer the reader to <ref> [1, 29, 30, 36] </ref> for appropriate background.
Reference: [31] <author> B. T. Polyak, </author> <title> New method of stochastic approximation type procedure, </title> <journal> Automation and Remote Control, </journal> <volume> 51 (1990), </volume> <pages> pp. 937-946. </pages>
Reference-contexts: This has motivated the introduction of SA algorithms with averaging of the iterates, using a sequence of step sizes which decreases at a rate slower than 1=n (see <ref> [3, 5, 24, 31, 32, 43] </ref>). <p> Then, standard SA results are applicable. For case (F), the analysis is more difficult, primarily because the standard conditions on the observation noise, assumed in, e.g., <ref> [3, 24, 31, 32, 43] </ref>, do not hold. These authors require the observation noise to satisfy the properties of martingale differences, or of stationary OE-mixing processes, or of the infinite sum of a martingale difference sequence.
Reference: [32] <author> B. T. Polyak and A. B. Juditsky, </author> <title> Acceleration of Stochastic Approximation by Averaging, </title> <journal> SIAM J. Control and Optim., </journal> <volume> 30 (1992), </volume> <pages> pp. 838-855. </pages>
Reference-contexts: This has motivated the introduction of SA algorithms with averaging of the iterates, using a sequence of step sizes which decreases at a rate slower than 1=n (see <ref> [3, 5, 24, 31, 32, 43] </ref>). <p> Then, standard SA results are applicable. For case (F), the analysis is more difficult, primarily because the standard conditions on the observation noise, assumed in, e.g., <ref> [3, 24, 31, 32, 43] </ref>, do not hold. These authors require the observation noise to satisfy the properties of martingale differences, or of stationary OE-mixing processes, or of the infinite sum of a martingale difference sequence. <p> Observe that &lt; 1 in (A4), so the classical choice of a n = O (1=n) is not allowed. This (A4) is the usual condition of slowly decreasing step sizes (e.g., as in <ref> [3, 24, 32] </ref>). Conditions (A5) and (A6) are standard in the context of SA. (A5) asks the objective function to be locally quadratic around the optimizer 0 , while (A6) says that 0 should be an attractor point from every other point of D.
Reference: [33] <author> H. Robbins and S. Monro, </author> <title> A stochastic approximation method, </title> <journal> Ann. Math. Statist., </journal> <volume> 22 (1951), </volume> <pages> pp. 400-407. </pages>
Reference-contexts: We suppose that the root is the unique optimizer 0 of J (). The Robbins-Monro <ref> [33] </ref> SA algorithm has the general form n+1 = D ( n a n f n+1 )(1.3) with an initial value 0 , where fa n ; n 0g is a deterministic sequence of matrices called the step sizes, f n+1 = f ( n ) + " n+1 is an
Reference: [34] <author> K. Sigman, </author> <title> Notes on the stability of closed queueing networks, </title> <journal> J. Appl. Probab., </journal> <volume> 26 (1989), </volume> <pages> pp. 678-682; Corrections, </pages> <note> J. Appl. Probab., 27 (1990), p. 735. </note>
Reference: [35] <author> K. Sigman, </author> <title> The stability of open queueing networks, </title> <journal> Stoch. Processes and their Appls., </journal> <volume> 35 (1990), </volume> <pages> pp. 11-25. </pages>
Reference: [36] <author> K. Sigman and R. W. Wolff, </author> <title> A review of regenerative processes, </title> <journal> SIAM Review, </journal> <volume> 35 (1993), </volume> <pages> pp. 269-288. </pages>
Reference-contexts: Partially supported by the National Natural Science Foundation of China. 1 2 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN (see the next section for details). One-dependent regenerative is a weakened version of the classical notion of a regenerative stochastic process, and covers a broad class of systems <ref> [1, 29, 36] </ref>. The weakening is that adjacent regenerative cycles are allowed to be dependent. <p> When this condition (A0) is satisfied, the controlled process fJ i ; i 0g is called (non-delayed) one-dependent regenerative. This extends the usual definition found, e.g., in <ref> [29, 36] </ref>: For the process fJ i (); i 0g, for which is fixed from the beginning, we get the usual definition of one-dependent regenerative, which we call in this paper one-dependent regenerative for fixed . The k m 's are called the regeneration points. <p> It is well-known that Harris-recurrent Markov chains (HRMCs) are one-dependent regenerative processes for fixed ; this can be seen by applying the splitting technique due to [2]. HRMCs cover a very large class of models. We refer the reader to <ref> [1, 29, 30, 36] </ref> for appropriate background.
Reference: [37] <author> W. F. Stout, </author> <title> Almost Sure Convergence, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: By (5.1) and condition (A3), k" n+1 k j fl 2D 2D which yields sup E k" n+1 k 2 j F (n1) &lt; 1 (5.4) by Schwarz inequality and (A3). Then, using the local convergence theorem of martin gales (see, e.g., <ref> [6, 20, 37] </ref>), it is seen that P 1 (1ffi) (1) P 1 (1ffi) (1) 1 a.s., which implies that 1 X a 1ffi (1) By Lemma 2 of [40] and condition (A3), one derives a n1 Z n ! 0 and a n1 j fl n ! 1 Using condition <p> fl fl fl i=1 fl fl fl fi fi F (m) m=1 p a k m E j fl m+1 Z m+1 m=1 m +1=2 E j fl m+1 Z m+1 &lt; 1; a:s:; which implies 1 X 1 m i=1 by the local convergence theorem of martingales (see, e.g., <ref> [6, 20, 37] </ref>). By the Kro necker lemma, it follows from (5.49) that lim 1 n m=0 i=1 which gives lim 1 n m=0 i=1 since oe (n) n; 8 n 1. STOCHASTIC APPROXIMATION WITH AVERAGING 21 (iii).
Reference: [38] <author> R. Suri, </author> <title> Perturbation analysis: the state of the art and research issues explained via the GI/G/1 queue, </title> <booktitle> Proc. IEEE, 77 (1989), </booktitle> <pages> pp. 114-137. </pages>
Reference-contexts: Denoting N n = P n j=1 L j (with N 0 = 0), one has ~ i = n for N n i &lt; N n+1 . In <ref> [38, 39] </ref>, this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm.
Reference: [39] <author> R. Suri and Y. T. Leung, </author> <title> Single run optimization of discrete event simulations|An empirical study using the M/M/1 queue, </title> <journal> IIE Transactions, </journal> <volume> 21 (1989), </volume> <pages> pp. 35-49. </pages>
Reference-contexts: Denoting N n = P n j=1 L j (with N 0 = 0), one has ~ i = n for N n i &lt; N n+1 . In <ref> [38, 39] </ref>, this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm.
Reference: [40] <author> Q. Y. Tang and H. F. Chen, </author> <title> Convergence of perturbation analysis based optimization algorithm with fixed number of customers period, Discrete Event Dynamic Systems: </title> <journal> Theory and Appl., </journal> <volume> 4 (1994), </volume> <pages> pp. 359-375. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> For the PARMSR algorithm with fixed-length observation period, the observation noise has a very complicated dynamic, as shown in previous convergence studies; see, e.g., <ref> [9, 10, 23, 26, 40, 41] </ref>. In this paper, we first obtain a bound on the almost sure (a.s.) convergence rate of the usual PARMSR algorithm (without averaging), using a limit theorem on double array martingales borrowed from [6] and [19]. <p> For example, (A9) and (A10) have been verified 8 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN in <ref> [9, 10, 40, 41] </ref> in the context of a GI=G=1 queue, with some conditions on the service time and the interarrival time distributions. Theorem 4.1. For the PARMSR algorithm with fixed updating period L n = L, we have: (i). <p> Then, using the local convergence theorem of martin gales (see, e.g., [6, 20, 37]), it is seen that P 1 (1ffi) (1) P 1 (1ffi) (1) 1 a.s., which implies that 1 X a 1ffi (1) By Lemma 2 of <ref> [40] </ref> and condition (A3), one derives a n1 Z n ! 0 and a n1 j fl n ! 1 Using condition (A3) and (5.6), it follows from (1.3) and (2.2) that k n n1 k a n1 kf n k a ffi n1 j fl n ) a:s:; which gives <p> By the conditions (A2), (A3), and Lemma 2 of <ref> [40] </ref>, it is derived that p n ! 1, which yields that the fourth term on the right side of (5.11) converges to zero a.s.. Similarly, we can prove that the first and the third terms converge to zero a.s.. Then, the result follows from standard martingale arguments. (iii). <p> Furthermore, if fz i ; i 1g are mutually independent, then the converse is true. Proof. The proof follows from the Borel-Cantelli lemma and Corollary 4.1.3 in [11], pp. 90-91. See also Lemma 2 in <ref> [40] </ref>. STOCHASTIC APPROXIMATION WITH AVERAGING 11 Lemma 5.2. <p> The proof for the case L = 1 applies to the present setting if we replace n ; " n ; f n by e n ; e" n , and fi n , respectively (cf. <ref> [40] </ref> and [41]). We only mention the key point for Theorem 4.1 (iii).
Reference: [41] <author> Q. Y. Tang, H. F. Chen, and Z. J. Han, </author> <title> Convergence rates of Perturbation-Analysis-Robbins-Monro-Single-Run algorithms for single server queues, </title> <journal> IEEE Trans. on Autom. Contr., </journal> <volume> 42 (1997), </volume> <pages> pp. 1442-1447. </pages>
Reference-contexts: In [38, 39], this is called the PARMSR (perturbation analysis Robbins-Monro single run) algorithm. Considerable effort has been devoted, in recent years, to study the convergence of the PARMSR algorithm in the field of STOCHASTIC APPROXIMATION WITH AVERAGING 3 discrete event dynamic systems (DEDSs); see, e.g., <ref> [8, 9, 10, 14, 23, 26, 27, 40, 41] </ref>, among others. The convergence rate results mentioned previously for the SA algorithm, however, have been proved under conditions that do not hold in the PARMSR setup. <p> For the PARMSR algorithm with fixed-length observation period, the observation noise has a very complicated dynamic, as shown in previous convergence studies; see, e.g., <ref> [9, 10, 23, 26, 40, 41] </ref>. In this paper, we first obtain a bound on the almost sure (a.s.) convergence rate of the usual PARMSR algorithm (without averaging), using a limit theorem on double array martingales borrowed from [6] and [19]. <p> TANG, P. L'ECUYER, AND H. F. CHEN A classical example where (A1) to (A3) are verified in the literature is that of the GI=G=1 queue considered in <ref> [8, 9, 24, 26, 41] </ref>. Lemma 2.1. If conditions (A0)|(A3) hold, then for each 2 D, the IPA derivative estimator is strongly consistent for f () and f () = E [j 1 ()] 2 j 1 () X J ;i () 5 :(2.3) Proof. <p> For example, (A9) and (A10) have been verified 8 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN in <ref> [9, 10, 40, 41] </ref> in the context of a GI=G=1 queue, with some conditions on the service time and the interarrival time distributions. Theorem 4.1. For the PARMSR algorithm with fixed updating period L n = L, we have: (i). <p> Thus 1=2 ffi 0 can be arbitrarily close to 1=2 if condition (A3) is fulfilled with a very large 0 . This is different from our Theorem 3.1 and from Theorem 2.2 in <ref> [41] </ref>, where k n 0 k = o (a ffi n ) a.s. with ffi 2 [0; 1 1=(2)) depending on . In the latter setup, if is close to 1=2, ffi must be close to zero. <p> k m i=j (m+1) (D m;i f ( k m ))Ifj m+1 &gt; j 1 ( k m )g 1 X a k m 1 ( k m ) X (D m;i f ( k m ))Ifj m+1 &lt; j 1 ( k m )g: As in Lemma 3.4 of <ref> [41] </ref>, we can prove that each term on the right-hand side of (5.13) converges a.s. (b). From the result of step (a), analogous to Lemma 3.5 of [41], we obtain the almost sure convergence of P 1 12 Q.-Y. TANG, P. L'ECUYER, AND H. F. <p> m ) X (D m;i f ( k m ))Ifj m+1 &lt; j 1 ( k m )g: As in Lemma 3.4 of <ref> [41] </ref>, we can prove that each term on the right-hand side of (5.13) converges a.s. (b). From the result of step (a), analogous to Lemma 3.5 of [41], we obtain the almost sure convergence of P 1 12 Q.-Y. TANG, P. L'ECUYER, AND H. F. CHEN Proof of Theorem 4.1 (ii) for L = 1. We need the following definitions and lemma. <p> The proof for the case L = 1 applies to the present setting if we replace n ; " n ; f n by e n ; e" n , and fi n , respectively (cf. [40] and <ref> [41] </ref>). We only mention the key point for Theorem 4.1 (iii).
Reference: [42] <author> R. Wolff, </author> <title> Stochastic Modeling and the Theory of Queues, </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: We refer the reader to [1, 29, 30, 36] for appropriate background. If E [j 1 ()] &lt; 1 and E i=1 jJ i ()j &lt; 1 for all 2 D, then J () in (1.2) is well defined on D and the renewal-reward theorem (see, e.g., [1] and <ref> [42] </ref>) says that J () = E [j 1 ()] 2 j 1 () X J i () 5 :(2.1) 2.2. Gradient Estimation via IPA and the PARMSR Algorithm. We now explain how IPA is used to estimate the gradient in this context.
Reference: [43] <author> G. Yin, </author> <title> On extensions of Polyak's averaging approach to stochastic approximation, </title> <journal> Stochastics and Stochastics Reports, </journal> <volume> 36 (1991), </volume> <pages> pp. 245-264. </pages>
Reference-contexts: This has motivated the introduction of SA algorithms with averaging of the iterates, using a sequence of step sizes which decreases at a rate slower than 1=n (see <ref> [3, 5, 24, 31, 32, 43] </ref>). <p> 0 ) is asymptotically N (0; S fl ), with S fl = M 1 1 S fl 1 ) 0 , where S fl 0 is the asymptotic covariance matrix of (1= p P n j=1 " j , we say that the PARMSR algorithm is asymptotically optimal (see <ref> [3, 5, 43] </ref> for similar definitions in terms of n). This must be understood as optimal only within the class of SA algorithms and for the particular gradient estimator that is used. <p> Then, standard SA results are applicable. For case (F), the analysis is more difficult, primarily because the standard conditions on the observation noise, assumed in, e.g., <ref> [3, 24, 31, 32, 43] </ref>, do not hold. These authors require the observation noise to satisfy the properties of martingale differences, or of stationary OE-mixing processes, or of the infinite sum of a martingale difference sequence.
References-found: 43

