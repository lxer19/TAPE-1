URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1994/GIT-CC-94-29.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.94.html
Root-URL: 
Title: PORTS: Experiences with a Scheduler for Dynamic Real-Time Systems (Extended Abstract)  
Author: Kaushik Ghosh, Richard M. Fujimoto, and Karsten Schwan 
Date: June 24, 1994  
Address: Atlanta, GA, 30332.  
Affiliation: College of Computing Georgia Institute of Technology  
Abstract: This paper describes several of our experiences with a real-time scheduler. Using a robot control application program, we motivate the importance of supporting multiple schedulers within the same application program. We demonstrate the utility of speculative task execution in dynamic real-time systems, and describe the implementation of a scheduler for performing speculative execution and recovery. We show that existing real-time scheduler interfaces have scope for improvement, especially when scheduling latency must be low and when multiple schedulers used by a single application must co-exist on a single processor. A new scheduler interface is specified and its basic costs are evaluated experimentally. Preliminary measurements on a KSR-1 machine are quoted. The measurements demonstrate how the execution times of temporal queries may be reduced by use of access structures to scheduler data structures. Finally, there are several overheads associated with speculative execution, and multiple schedulers in a single application. We consider the problem of on-line reconfiguration of the several overheads associated with the speculative-execution paradigm for optimal performance in the face of these overheads. Initial performance measurements of the PORTS scheduler indicate that it is possible to perform real-time scheduling with latencies approximating those of proposed specialized scheduling co-processors.
Abstract-found: 1
Intro-found: 1
Reference: [BS91b] <author> Ben Blake and Karsten Schwan. </author> <title> Experimental evaluation of a real-time scheduler for a multiprocessor system. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 34-44, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: For scheduling, each node (processor) is treated as a uniprocessor engine. Multiprocessor scheduling as described in [SZG91, ZSA91] is not currently supported by PORTS in part due to its expense <ref> [BS91b] </ref> and due to the cost of task migration in NUMA and CC-COMA machines such as the KSR1, and in part due to the logical process and event model offered by the Time Warp kernel [Fuj89]. Multiprocessor support is discussed in greater detail in Section 4.
Reference: [CC89] <author> Houssine Chetto and Maryline Chetto. </author> <title> Some results of the earliest deadline scheduling algorithm. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(10) </volume> <pages> 1261-1269, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Third, this application requires the concurrent use of multiple scheduling policies, one addressing the reactive part and implemented using standard ED (Earliest Deadline First <ref> [CC89] </ref>) or priority based scheduling methods, the other addressing the speculatively executed deliberative part using the PORTS scheduler and its real-time speculative execution protocol. Fourth, scheduling latency should be low, since excessive overheads in rescheduling can lead to increased mission costs in terms of path lengths and energy expenditure.
Reference: [Car84] <author> Gene D. Carlow. </author> <title> Architecture of the space shuttle primary avionics software system. </title> <journal> Communications of the ACM, </journal> <volume> 27(9) </volume> <pages> 926-936, </pages> <month> Sept. </month> <year> 1984. </year>
Reference-contexts: 1 Introduction The diversity and complexity of modern real-time applications is moving `real-time systems' research from past work primarily addressing self-contained embedded systems such as flight control <ref> [Car84] </ref> toward addressing highly dynamic, distributed and parallel real-time applications. In essence, their characteristics (1) cannot be predicted a priori with any `tolerable' degree of certainty and (2) are subject to on-line change.
Reference: [Fuj89] <author> Richard M. Fujimoto. </author> <title> Time Warp on a Shared Memory Multiprocessor. </title> <journal> Transactions of the Society for Computer Simulation, </journal> <volume> 6(3) </volume> <pages> 211-239, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: in [SZG91, ZSA91] is not currently supported by PORTS in part due to its expense [BS91b] and due to the cost of task migration in NUMA and CC-COMA machines such as the KSR1, and in part due to the logical process and event model offered by the Time Warp kernel <ref> [Fuj89] </ref>. Multiprocessor support is discussed in greater detail in Section 4. The uniprocessor PORTS scheduler uses a variation of the ED algorithm for scheduling a speculatively executed task [GFS93b, GPFS93].
Reference: [GFS93b] <author> Kaushik Ghosh, Richard M. Fujimoto, and Karsten Schwan. </author> <title> Time warp simulation in time constrained systems. </title> <booktitle> Proceedings of the 7th Workshop on Parallel and Distributed Simulation (PADS), </booktitle> <month> May </month> <year> 1993. </year> <note> Expanded version available as technical report GIT-CC-92/46. </note>
Reference-contexts: Since the underlying system manages the speculative execution paradigm, speculative execution can remain totally transparent to the application writer, if desired. The PORTS system consists of its scheduler, a novel real-time variant of the Time Warp protocol [Jef85] for optimistic execution of time-constrained tasks (see <ref> [GFS93b, GPFS93] </ref>), and a kernel supporting task rollback and re-execution, all of which are implemented at the user level on a multiprocessor execution platform (a KSR-1 multiprocessor 1 ). The real-time applications targeted by the PORTS system are simulation programs executing jointly with actual electro-mechanical systems or with time-stepped simulations. <p> The PORTS scheduler supporting the speculative execution of the deliberative part is described next. Its real-time execution protocol is based on earlier, theoretical work described in <ref> [GFS93b, GPFS93] </ref>. We are not aware of any other implementation efforts concerning real-time schedulers for speculative task execution on multiprocessor systems. 2.2 The PORTS Scheduler The PORTS scheduler is replicated across all nodes of the parallel machine. For scheduling, each node (processor) is treated as a uniprocessor engine. <p> Multiprocessor support is discussed in greater detail in Section 4. The uniprocessor PORTS scheduler uses a variation of the ED algorithm for scheduling a speculatively executed task <ref> [GFS93b, GPFS93] </ref>.
Reference: [GL91] <author> Bill O. Gallmeister and Chris Lanier. </author> <title> Early experience with posix 1003.4 and posix 1003.4a. </title> <booktitle> In Proceedings of the Real-Time Systems Symposium, </booktitle> <pages> pages 190-198. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1991. </year>
Reference-contexts: Further, extant real-time thread packages typically do not differentiate between forking a thread on a processor and performing schedulability analysis for that thread. This has been the case with some of the past work of our group [SZG91], and elsewhere <ref> [GL91] </ref>. While this might have been justified in predictable environments where the periods of periodic tasks do not change dynamically, and they execute for intervals close to their worst-case execution estimates. However, our thesis is that for more dynamic and uncertain environments, forking and schedulability analysis should be clearly separated.
Reference: [GPFS93] <author> Kaushik Ghosh, Kiran Panesar, Richard M. Fujimoto, and Karsten Schwan. </author> <title> PORTS: A parallel, optimistic, real-time simulator. </title> <booktitle> Proceedings of the 8th Workshop on Parallel and Distributed Simulation (PADS), </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Since the underlying system manages the speculative execution paradigm, speculative execution can remain totally transparent to the application writer, if desired. The PORTS system consists of its scheduler, a novel real-time variant of the Time Warp protocol [Jef85] for optimistic execution of time-constrained tasks (see <ref> [GFS93b, GPFS93] </ref>), and a kernel supporting task rollback and re-execution, all of which are implemented at the user level on a multiprocessor execution platform (a KSR-1 multiprocessor 1 ). The real-time applications targeted by the PORTS system are simulation programs executing jointly with actual electro-mechanical systems or with time-stepped simulations. <p> The PORTS scheduler supporting the speculative execution of the deliberative part is described next. Its real-time execution protocol is based on earlier, theoretical work described in <ref> [GFS93b, GPFS93] </ref>. We are not aware of any other implementation efforts concerning real-time schedulers for speculative task execution on multiprocessor systems. 2.2 The PORTS Scheduler The PORTS scheduler is replicated across all nodes of the parallel machine. For scheduling, each node (processor) is treated as a uniprocessor engine. <p> Multiprocessor support is discussed in greater detail in Section 4. The uniprocessor PORTS scheduler uses a variation of the ED algorithm for scheduling a speculatively executed task <ref> [GFS93b, GPFS93] </ref>.
Reference: [GS93] <author> Ahmed Gheith and Karsten Schwan. </author> <title> Chaos-arc kernel support for multi-weight objects, invocations, and atomicity in real-time applications. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(1) </volume> <pages> 33-72, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: The undo/redo strategy supported by the PORTS scheduler may also be applied to fault tolerant applications. Specifically, in <ref> [GS93] </ref> the authors discuss mechanisms for undoing the effects of atomic real-time computations, and redoing other `versions' of these computations to perform `forward-recovery' in a timely manner. In contrast, the PORTS system uses a general-purpose speculative execution mechanism to tolerate unpredictable data-dependence and high-load situations. <p> In contrast, the PORTS system uses a general-purpose speculative execution mechanism to tolerate unpredictable data-dependence and high-load situations. Moreover, while the recovery mechanisms presented in <ref> [GS93] </ref> require application programmers to explicitly define recovery strategies, PORTS application software is written no differently than in `classical' execution mechanisms. Since the underlying system manages the speculative execution paradigm, speculative execution can remain totally transparent to the application writer, if desired.
Reference: [Jef85] <author> D. R. Jefferson. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3) </volume> <pages> 404-425, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: Since the underlying system manages the speculative execution paradigm, speculative execution can remain totally transparent to the application writer, if desired. The PORTS system consists of its scheduler, a novel real-time variant of the Time Warp protocol <ref> [Jef85] </ref> for optimistic execution of time-constrained tasks (see [GFS93b, GPFS93]), and a kernel supporting task rollback and re-execution, all of which are implemented at the user level on a multiprocessor execution platform (a KSR-1 multiprocessor 1 ).
Reference: [MD78] <author> A. K. Mok and M. L. Dertouzos. </author> <title> Multiprocessor scheduling in a hard real-time environment. </title> <booktitle> In Proceeding of The Seventh Texas Conference on Computer Systems, </booktitle> <month> November </month> <year> 1978. </year>
Reference-contexts: It has been proven that there can be no general optimal, multiprocessor, real-time scheduling algorithm <ref> [MD78] </ref>. Extant multiprocessor algorithms are but extensions of uniprocessor scheduling, with the different processors communicating among themselves (through a drafting or bidding approach) to ascertain which set of processors is the best candidate for running a new task.
Reference: [MEG94] <author> Bodhisattwa Mukherjee, Greg Eisenhauer, and Kaushik Ghosh. </author> <title> A machine independent interface for lightweight threads. </title> <booktitle> In Operating Systems Review of the ACM Special Interest Group on Operating Systems, </booktitle> <pages> pages 33 - 47, </pages> <month> January </month> <year> 1994. </year> <month> 12 </month>
Reference-contexts: Results are presented in Section 2.6. 2.4 Scheduler Interfaces We consider two interfaces: the interface between scheduler and low level dispatcher, and the interface that existing real-time thread packages offer <ref> [MEG94] </ref>. <p> (CC) NUMA (e.g., the MIT Alewife) and UMA machines (e.g., the Sequent Symmetry), and for cache-coherent cache-only-memory-access (CC-COMA) machines (e.g., the KSR1), the time for `warming up' the cache (or the `local attraction memory' in the case of CC-COMA machines) when a task writes `remote state' can become significant 8 <ref> [MEG94] </ref>. Consider a CC-NUMA machine, and a CC-COMA machine, each with two processors A and B, and a task T , most of the data accessed by which resides on one of the processors in each machine (say processor A).
Reference: [NRS + 93] <author> Douglas Niehaus, Krithi Ramamritham, John A. Stankovic, Gary Wallace, and Charles Weems. </author> <title> The spring scheduling co-processor: Design, use and performance. </title> <booktitle> In Proceedings of the Real-Time Systems Symposium, </booktitle> <pages> pages 106-111. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> December </month> <year> 1993. </year>
Reference-contexts: Initial performance measurements of the PORTS scheduler indicate that it is possible to perform real-time scheduling with latencies approximating those of proposed specialized scheduling co-processors <ref> [NRS + 93] </ref>. 2 Problem Statement and Solution Approach 2.1 Application The PORTS application discussed here consists of two interacting sets of software for robot control and navigation: (1) actual application code subject to timing constraints in execution and (2) speculatively executed simulation code which must `keep up' with (1). (1) <p> It should be noted that even for fairly large slot lists a maximum of 3000 slots in the list before garbage collection we perform within an order of magnitude of what researchers elsewhere have achieved (130 microseconds <ref> [NRS + 93] </ref>) using special-purpose scheduling co-processors running at the same clock speed as the KSR-1 (20 MHz). 3 Reconfiguration of Overheads: Garbage-Collection of Slots As mentioned before, frequent garbage-collection (GC) of `old' slots in the slot list makes scheduling faster.
Reference: [SZG91] <author> Karsten Schwan, Hongyi Zhou, and Ahmed Gheith. </author> <title> Multiprocessor real-time threads. </title> <journal> Operating Systems Review, </journal> <volume> 25(4) </volume> <pages> 35-46, </pages> <month> Oct. </month> <year> 1991. </year> <note> Also appears in the Jan. 1992 issue of Operating Systems Review. </note>
Reference-contexts: Next, we demonstrate the utility of speculative task execution. Third, and most relevant to general research in operating systems, we show that existing real-time scheduler interfaces, including POSIX real-time Unix and our own earlier work on real-time threads described in <ref> [SZG91] </ref> have scope for improvement, especially when scheduling latency must be low and when multiple schedulers used by a single application must co-exist on a single processor. A new scheduler interface is specified as one that supports specific types of temporal queries, and its basic costs are evaluated experimentally. <p> For scheduling, each node (processor) is treated as a uniprocessor engine. Multiprocessor scheduling as described in <ref> [SZG91, ZSA91] </ref> is not currently supported by PORTS in part due to its expense [BS91b] and due to the cost of task migration in NUMA and CC-COMA machines such as the KSR1, and in part due to the logical process and event model offered by the Time Warp kernel [Fuj89]. <p> Current standards being offered in real-time operating systems (e.g., POSIX real-time threads) do not differentiate task dispatching from schedulability analysis, and current interfaces offered for real-time threads <ref> [SZG91, TNR90b] </ref> do not differentiate thread creation and task scheduling by offering separate interfaces and possibly, distinct implementations for each. 2 The dispatcher's `ready list' of tasks is sorted according to deadline. 4 We base our statement concerning the necessity of distinguishing schedulability analysis and dispatching in real-time applications on experimental <p> At the lowest level, we have the dispatcher, one per processor. Further, extant real-time thread packages typically do not differentiate between forking a thread on a processor and performing schedulability analysis for that thread. This has been the case with some of the past work of our group <ref> [SZG91] </ref>, and elsewhere [GL91]. While this might have been justified in predictable environments where the periods of periodic tasks do not change dynamically, and they execute for intervals close to their worst-case execution estimates.
Reference: [TNR90b] <author> Hideyuki Tokuda, Tatsuo Nakajima, and Prithvi Rao. </author> <title> Real-time mach: Towards predictable real-time systems. </title> <booktitle> Proceedings of the USENIX 1990 Mach Workshop, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: Current standards being offered in real-time operating systems (e.g., POSIX real-time threads) do not differentiate task dispatching from schedulability analysis, and current interfaces offered for real-time threads <ref> [SZG91, TNR90b] </ref> do not differentiate thread creation and task scheduling by offering separate interfaces and possibly, distinct implementations for each. 2 The dispatcher's `ready list' of tasks is sorted according to deadline. 4 We base our statement concerning the necessity of distinguishing schedulability analysis and dispatching in real-time applications on experimental
Reference: [ZSA91] <author> Hongyi Zhou, Karsten Schwan, and Ian Akyildiz. </author> <title> Performance effects of information sharing in a distributed multiprocessor real-time scheduler. </title> <type> Technical report, </type> <institution> College of Computing, Georgia Tech, GIT-CC-91/40, </institution> <month> Sept. </month> <year> 1991. </year> <note> Abbreviated version in 1992 IEEE Real-Time Systems Symposium, Phoenix. 13 </note>
Reference-contexts: For scheduling, each node (processor) is treated as a uniprocessor engine. Multiprocessor scheduling as described in <ref> [SZG91, ZSA91] </ref> is not currently supported by PORTS in part due to its expense [BS91b] and due to the cost of task migration in NUMA and CC-COMA machines such as the KSR1, and in part due to the logical process and event model offered by the Time Warp kernel [Fuj89].
References-found: 15

