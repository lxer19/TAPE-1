URL: http://www.cs.toronto.edu/~ruppert/kshortest.ps
Refering-URL: http://www.cs.toronto.edu/~ruppert/index.html
Root-URL: 
Title: Finding the k Shortest Paths in Parallel  
Author: Eric Ruppert 
Keyword: Topics: parallel algorithms, data structures  
Address: Toronto, Ontario, Canada M5S 1A4  
Affiliation: Department of Computer Science University of Toronto  
Abstract: A concurrent-read exclusive-write PRAM algorithm is developed to find the k shortest paths between pairs of vertices in an edge-weighted directed graph. Repetitions of vertices along the paths are allowed. The algorithm computes an implicit representation of the k shortest paths to a given destination vertex from every vertex of a graph with n vertices and m edges, using O(m + nk log 2 k) work and O(log 3 k log fl k + log n(log log k + log fl n)) time, assuming that a shortest path tree rooted at the destination is precomputed. The paths themselves can be extracted from the implicit representation in O(log k+log n) time, and O(n log n + L) work, where L is the total length of the output.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. Borodin and J. E. Hopcroft. </author> <title> Routing, merging and sorting in parallel models of computation. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 30 </volume> <pages> 130-145, </pages> <year> 1985. </year>
Reference-contexts: Ties between edge weights can be broken according to some arbitrary lexicographic order on the edges. Each merge step can be performed in O (log log k) time and O (k) work using Borodin and Hopcroft's merging algorithm <ref> [1] </ref>, so the tree contraction takes O (log n log log k) time and O (nk) work in total. The num fields of the paths found during stage 0 can be filled in as follows. First, the depth of each vertex in T is computed using tree contraction.
Reference: 2. <author> Gen-Huey Chen and Yung-Chen Hung. </author> <title> Algorithms for the constrained quickest path problem and the enumeration of quickest paths. </title> <journal> Computers and operations research, </journal> <volume> 21(2) </volume> <pages> 113-118, </pages> <year> 1994. </year>
Reference-contexts: Subpaths of quickest paths need not be quickest paths themselves, so the approaches used to solve shortest path problems are not directly applicable to quickest path problems. Sequential algorithms for the k quickest paths problem have been studied previously <ref> [2, 3, 19] </ref>. The problem can be solved by first finding the k shortest paths (with respect to latency) that have capacity at least c, for each edge capacity c, and then choosing from among them the k paths that have the shortest overall transmission time [3].
Reference: 3. <author> Y. L. Chen. </author> <title> Finding the k quickest simple paths in a network. </title> <journal> Information Processing Letters, </journal> <volume> 50(2) </volume> <pages> 89-92, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Subpaths of quickest paths need not be quickest paths themselves, so the approaches used to solve shortest path problems are not directly applicable to quickest path problems. Sequential algorithms for the k quickest paths problem have been studied previously <ref> [2, 3, 19] </ref>. The problem can be solved by first finding the k shortest paths (with respect to latency) that have capacity at least c, for each edge capacity c, and then choosing from among them the k paths that have the shortest overall transmission time [3]. <p> The problem can be solved by first finding the k shortest paths (with respect to latency) that have capacity at least c, for each edge capacity c, and then choosing from among them the k paths that have the shortest overall transmission time <ref> [3] </ref>. Repeated use of the parallel k shortest paths algorithm yields a CREW PRAM implementation of this approach that finds the k quickest paths to a given destination vertex t from every vertex v.
Reference: 4. <author> Y. L. Chen and Y. H. Chin. </author> <title> The quickest path problem. </title> <journal> Computers and Operations Research, </journal> <volume> 17(2) </volume> <pages> 153-161, </pages> <year> 1990. </year>
Reference-contexts: This is the first parallel algorithm for this problem that runs in polylogarithmic time. The quickest paths problem <ref> [4] </ref> is a generalization of the shortest path problem. It is used to model the problem of transmitting data through a computer network. Each edge of a directed graph is assigned a positive capacity and a non-negative latency.
Reference: 5. <author> R. Cole. </author> <title> An optimally efficient selection algorithm. </title> <journal> Information Processing Letters, </journal> <volume> 26 </volume> <pages> 295-299, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: This can be done using O (log d v log fl d v ) time and O (d v ) work, where d v is the outdegree of v, using Cole's selection algorithm <ref> [5] </ref>. In total, this requires O (log d log fl d) time and O (m) work, where d is the maximum outdegree of any vertex in the graph.
Reference: 6. <author> R. Cole. </author> <title> Parallel merge sort. </title> <journal> SIAM Journal on Computing, </journal> <volume> 17(4) </volume> <pages> 770-785, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: In addition, O (log n) time and O (n) work is used to allocate the appropriate number of processors to each vertex using a prefix sum computation. Cole's parallel merge sort <ref> [6] </ref> can be used to sort the k 1 smallest edges out of each vertex in O (log k) time using n (k 1) processors. <p> Once the k elements of A i v are found using the algorithm of Lemma 4, they can be sorted in O (log k) time and O (k log k) work using Cole's parallel merge sort <ref> [6] </ref>. The ith stage of the algorithm that computes the arrays A i v (for all vertices v) therefore uses O (log 2 k log fl k) time and O (nk log k) work.
Reference: 7. <author> David Eppstein. </author> <title> Finding the k shortest paths. </title> <booktitle> In Proc. 35th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 154-165, </pages> <year> 1994. </year>
Reference-contexts: The problem of finding the k shortest paths in sequential models of computation was discussed as early as 1959 by Hoffman and Pavley [14]. Fox presents an algorithm that can be implemented to run in O (m + kn log n) time [9]. Epp-stein's recent sequential algorithm <ref> [7] </ref> is a significant improvement. It computes an implicit representation of the k shortest paths for a given source and destination in O (m + n log n + k) time. <p> u to t: ffi (u; v) = w (u; v) + dist (v; t) dist (u; t): The following lemma describes some properties of this measure. (a) Solid edges form the tree T (b) Values of ffi are shown for non-tree edges Fig. 1. an example graph Lemma 1 (Eppstein <ref> [7] </ref>). (i) ffi (u; v) 0 for all (u; v) 2 E. (iii) For any path p from s to t, weight (p) = dist (s; t) + X ffi (u; v) = dist (s; t) + X (u;v)2sidetracks (p) ffi (u; v): To find the k shortest paths from s <p> From now on, the weight function ffi will be used instead of w. 2.1 Eppstein's Sequential Algorithm Eppstein's sequential algorithm <ref> [7] </ref> computes an implicit representation of the k shortest paths. Each path's sidetracks sequence is represented as a modification of the sidetracks of a shorter path. <p> In fact, some properties of the paths can be computed without explicitly listing the edges in the path, as observed by Eppstein <ref> [7] </ref>. Suppose each edge in the graph is assigned a value from a semigroup, and the value of a path is defined as the product of the values of the edges along the path.
Reference: 8. <author> G. David Forney, Jr. </author> <title> The Viterbi algorithm. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 61(3) </volume> <pages> 268-278, </pages> <month> March </month> <year> 1973. </year>
Reference-contexts: More detailed descriptions of these applications may be found in [19]. The Viterbi decoding problem is to estimate the state sequence of a discrete-time Markov process, given noisy observations of its state transitions. This problem has applications in communications (see <ref> [8] </ref>). The list Viterbi decoding problem is to compute the k state sequences that are most likely to have occurred, given a particular sequence of observations. Sequential algorithms exist that construct a weighted directed acyclic graph in which each path between two fixed vertices describes a possible state sequence [8]. <p> (see <ref> [8] </ref>). The list Viterbi decoding problem is to compute the k state sequences that are most likely to have occurred, given a particular sequence of observations. Sequential algorithms exist that construct a weighted directed acyclic graph in which each path between two fixed vertices describes a possible state sequence [8]. The weight of the path corresponding to a state sequence is equal to the conditional probability that it occurred, given the observations. Sequential algorithms for this problem have appeared previously [20, 21], and a straightforward parallel implementation was described by Seshadri and Sundberg [20].
Reference: 9. <author> B. L. Fox. </author> <title> Calculating kth shortest paths. </title> <journal> INFOR; Canadian Journal of Operational Research, </journal> <volume> 11(1) </volume> <pages> 66-70, </pages> <year> 1973. </year>
Reference-contexts: The problem of finding the k shortest paths in sequential models of computation was discussed as early as 1959 by Hoffman and Pavley [14]. Fox presents an algorithm that can be implemented to run in O (m + kn log n) time <ref> [9] </ref>. Epp-stein's recent sequential algorithm [7] is a significant improvement. It computes an implicit representation of the k shortest paths for a given source and destination in O (m + n log n + k) time.
Reference: 10. <author> Greg N. Frederickson. </author> <title> An optimal algorithm for selection in a min-heap. </title> <journal> Information and Computation, </journal> <volume> 104 </volume> <pages> 197-214, </pages> <year> 1993. </year>
Reference-contexts: This correspondence is bijective and weight-preserving, so the k shortest s-t paths of G can be found by computing the k shortest paths that begin at s 0 in G 0 , using Frederickson's algorithm <ref> [10] </ref>.
Reference: 11. <author> Greg N. Frederickson and Donald B. Johnson. </author> <title> The complexity of selection and ranking in X + Y and matrices with sorted columns. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 24 </volume> <pages> 197-208, </pages> <year> 1982. </year>
Reference-contexts: A PRAM implementation of Frederickson and Johnson's sequential algorithm for selection in a matrix with sorted columns <ref> [11] </ref> may be used to find the required k paths. Lemma 4.
Reference: 12. <author> Michael L. Fredman and Robert Endre Tarjan. </author> <title> Fibonacci heaps and their uses in improved network optimization algorithms. </title> <journal> Journal of the ACM, </journal> <volume> 34(3) </volume> <pages> 596-615, </pages> <year> 1987. </year>
Reference-contexts: Some applications of the k shortest paths algorithm are described in Sect. 4. Previous Work Dijkstra's sequential algorithm computes the shortest path to a given destination vertex from every other vertex in O (m + n log n) time <ref> [12] </ref>. In parallel, the shortest path between each pair of vertices can be found using a min/sum transitive closure computation in O (log 2 n) time and O (n 3 log n) work on an EREW PRAM [17].
Reference: 13. <author> Y. Han, V. Pan, and J. Reif. </author> <title> Efficient parallel algorithms for computing all pair shortest paths in directed graphs. </title> <booktitle> In 4th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 353-362, </pages> <year> 1992. </year>
Reference-contexts: More complicated implementations of the transitive closure computation run in O (log 2 n) time using o (n 3 ) work on the EREW PRAM and in O (log n log log n) time on the CRCW PRAM <ref> [13] </ref>. There are no known polylogarithmic-time PRAM algorithms that find the shortest path from one particular vertex to another using less work than the all-pairs algorithm.
Reference: 14. <author> Walter Hoffman and Richard Pavley. </author> <title> A method of solution of the Nth best path problem. </title> <journal> Journal of the ACM, </journal> <volume> 6 </volume> <pages> 506-514, </pages> <year> 1959. </year>
Reference-contexts: The problem of finding the k shortest paths in sequential models of computation was discussed as early as 1959 by Hoffman and Pavley <ref> [14] </ref>. Fox presents an algorithm that can be implemented to run in O (m + kn log n) time [9]. Epp-stein's recent sequential algorithm [7] is a significant improvement.
Reference: 15. <author> Richard Karp and Vijaya Ramachandran. </author> <title> Parallel algorithms for shared-memory machines. </title> <editor> In Jan van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, volume A, </booktitle> <pages> pages 871-941. </pages> <publisher> Elsevier, </publisher> <year> 1990. </year>
Reference-contexts: It is assumed that the weights on the edges are positive, but the algorithm can easily be adapted to handle negative edge weights, as long as there are no negative cycles in the graph. The algorithm runs on a concurrent-read exclusive-write (CREW) PRAM. (See Karp and Ramachandran's survey <ref> [15] </ref> for definitions of PRAM models.) The algorithm finds the k shortest paths to t from every vertex in O (log k log k +log n log log k +log d log d) time using O (m+nk log 2 k) work, where d is the maximum outdegree of any vertex in <p> The k shortest paths from v to t can then be explicitly stored one after another in an array P of size L = P k j=1 l j . The starting location of each path in the array P can be found by performing a prefix sum (see <ref> [15] </ref>) on l 1 ; : : : ; l k . Suppose L= log (kn) processors are available. Each processor is assigned the task of filling in a block of the output array P of length log (kn).
Reference: 16. <author> N. Katoh, T. Ibaraki, and H. </author> <title> Mine. An efficient algorithm for K shortest simple paths. </title> <journal> Networks, </journal> <volume> 12 </volume> <pages> 411-427, </pages> <year> 1982. </year>
Reference-contexts: Sequential algorithms have been developed for other variations of the k shortest paths problem. Yen [23] gives an algorithm for the more difficult problem of finding the k shortest simple paths in O (kn 3 ) time. Katoh, Ibaraki and Mine <ref> [16] </ref> describe an O (kn 2 ) algorithm to find the k shortest simple paths in an undirected graph. 2 Preliminaries Let G = (V; E) be a directed graph with n vertices and m edges, where each edge (u; v) of E has a non-negative weight w (u; v).
Reference: 17. <author> Richard C. Paige and Clyde P. Kruskal. </author> <title> Parallel algorithms for shortest paths problems. </title> <booktitle> In Proceedings of the International Conference on Parallel Processing, </booktitle> <pages> pages 14-20, </pages> <year> 1985. </year>
Reference-contexts: In parallel, the shortest path between each pair of vertices can be found using a min/sum transitive closure computation in O (log 2 n) time and O (n 3 log n) work on an EREW PRAM <ref> [17] </ref>. More complicated implementations of the transitive closure computation run in O (log 2 n) time using o (n 3 ) work on the EREW PRAM and in O (log n log log n) time on the CRCW PRAM [13].
Reference: 18. <author> Margaret Reid-Miller, Gary L. Miller, and Francesmary Modugno. </author> <title> List ranking and parallel tree contraction. </title> <editor> In John H. Reif, editor, </editor> <title> Synthesis of Parallel Algorithms, chapter 3. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Tree contraction is used to compute the array of the k shortest edges whose tails are on the path from each vertex v to the destination t. The tree contraction is similar to that described in <ref> [18] </ref> for computing the minimum weight ancestor of each node in a node-weighted tree. Instead of each primitive operation finding the minimum of two node weights, it computes the k smallest elements in a pair of sorted arrays, each containing k elements. <p> The num fields of the paths found during stage 0 can be filled in as follows. First, the depth of each vertex in T is computed using tree contraction. The algorithm is similar to the computation of minimum ancestors in <ref> [18] </ref>, except that the minimization operations are replaced by additions, and each vertex in the tree is assigned a value of 1, except the root, which has value 0. This computation uses O (log n) time and O (n) work.
Reference: 19. <author> Eric Ruppert. </author> <title> Parallel algorithms for the k shortest paths and related problems. </title> <type> Master's thesis, </type> <institution> University of Toronto, </institution> <year> 1996. </year>
Reference-contexts: The implementation is straightforward except for the subproblem of weighted selection, which can be done by modifying Vishkin's parallel selection algo rithm [22]. Further details of the parallel implementation of Frederickson and Johnson's algorithm may be found in <ref> [19] </ref>. Once the k elements of A i v are found using the algorithm of Lemma 4, they can be sorted in O (log k) time and O (k log k) work using Cole's parallel merge sort [6]. <p> More detailed descriptions of these applications may be found in <ref> [19] </ref>. The Viterbi decoding problem is to estimate the state sequence of a discrete-time Markov process, given noisy observations of its state transitions. This problem has applications in communications (see [8]). <p> Subpaths of quickest paths need not be quickest paths themselves, so the approaches used to solve shortest path problems are not directly applicable to quickest path problems. Sequential algorithms for the k quickest paths problem have been studied previously <ref> [2, 3, 19] </ref>. The problem can be solved by first finding the k shortest paths (with respect to latency) that have capacity at least c, for each edge capacity c, and then choosing from among them the k paths that have the shortest overall transmission time [3].
Reference: 20. <author> Nambirajan Seshadri and Carl-Erik W. Sundberg. </author> <title> List Viterbi decoding algorithms with applications. </title> <journal> IEEE Transactions on Communications, </journal> <volume> 42(2/3/4 Part I):313-323, </volume> <year> 1994. </year>
Reference-contexts: The weight of the path corresponding to a state sequence is equal to the conditional probability that it occurred, given the observations. Sequential algorithms for this problem have appeared previously <ref> [20, 21] </ref>, and a straightforward parallel implementation was described by Seshadri and Sundberg [20]. <p> The weight of the path corresponding to a state sequence is equal to the conditional probability that it occurred, given the observations. Sequential algorithms for this problem have appeared previously [20, 21], and a straightforward parallel implementation was described by Seshadri and Sundberg <ref> [20] </ref>.
Reference: 21. <author> Frank K. Soong and Eng-Fong Huang. </author> <title> A tree-trellis based fast search for finding the N best sentence hypotheses in continuous speech recognition. </title> <booktitle> In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 705-708, </pages> <year> 1991. </year>
Reference-contexts: The weight of the path corresponding to a state sequence is equal to the conditional probability that it occurred, given the observations. Sequential algorithms for this problem have appeared previously <ref> [20, 21] </ref>, and a straightforward parallel implementation was described by Seshadri and Sundberg [20].
Reference: 22. <author> Uzi Vishkin. </author> <title> An optimal parallel algorithm for selection. </title> <booktitle> In Advances in Computing Research, </booktitle> <volume> volume 4, </volume> <pages> pages 79-86. </pages> <publisher> JAI Press, </publisher> <year> 1987. </year>
Reference-contexts: The implementation is straightforward except for the subproblem of weighted selection, which can be done by modifying Vishkin's parallel selection algo rithm <ref> [22] </ref>. Further details of the parallel implementation of Frederickson and Johnson's algorithm may be found in [19].
Reference: 23. <author> Jin Y. Yen. </author> <title> Finding the K shortest loopless paths. </title> <journal> Management Science, </journal> <volume> 17(11) </volume> <pages> 712-716, </pages> <month> July </month> <year> 1971. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: A brief description of Eppstein's algorithm is given in Sect. 2.1. The k shortest paths problem has not previously been studied in parallel models of computation. Sequential algorithms have been developed for other variations of the k shortest paths problem. Yen <ref> [23] </ref> gives an algorithm for the more difficult problem of finding the k shortest simple paths in O (kn 3 ) time.
References-found: 23

