URL: http://www.cs.helsinki.fi/~mannila/postscripts/attribute-oriented-induction.ps
Refering-URL: http://www.cs.helsinki.fi/~mannila/data-mining-publications.html
Root-URL: 
Title: Attribute-Oriented Induction and Conceptual Clustering  
Author: Oskari Heinonen and Heikki Mannila P. O. Box (Teollisuuskatu ) 
Address: Helsinki, Finland  
Date: Helsinki, February 1996 (Revised October 1996)  
Note: Series of Publications C, No. C-1996-2  The papers in the series are intended for internal use and are distributed by the authors.  
Affiliation: University of Helsinki Department of Computer Science  Department of Computer Science  University of  
Pubnum: FIN-00014  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. R. Anderberg. </author> <title> Cluster Analysis for Applications. Number 19 in Probability and Mathematical Statistics. </title> <publisher> Academic Press, </publisher> <address> New York, USA, </address> <year> 1973. </year>
Reference-contexts: The definition of distance in (3) depends naturally on the description language L used. The hierarchical agglomerative algorithm, also called the central agglomerative procedure <ref> [1] </ref>, for conceptual clustering can now be formulated as follows. 1. Given E = fe 1 ; : : : ; e n g, let ' i be a concept such that f (' i ) " E = fe i g. 2. <p> Furthermore, the quality measure (s) presented by Pitt & Reinke could give AOI a method for selecting the output generalized relation. Another possibility is to look at alternative implementations for AOI in terms of nonhierarchical clustering methods (see <ref> [1] </ref>). Conversely, conceptual clustering methods could benefit from looking at the successful choice of representation language in AOI.
Reference: [2] <author> D. Fisher and P. Langley. </author> <title> Approaches to conceptual clustering. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 691-697, </pages> <address> Los Angeles, CA, USA, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: By performing the generalization step once for both attributes, in either order, we get the generalized relation in Table 2. The relation could be further generalized by employing "ANY" values. 3 Conceptual clustering In this section we present the conceptual clustering problem, following the exposition of [6] (see also <ref> [2] </ref>). Let D denote the class of all objects of interest. A description language L = (S; f) is a set S of expressions together with a mapping f : S ! P (D), where P (D) denotes the powerset of D.
Reference: [3] <author> J. Han, Y. Cai, and N. Cercone. </author> <title> Concept-based data classification in relational databases. </title> <booktitle> In Workshop Notes of 1991 AAAI Workshop on Knowledge Discovery in Databases (KDD'91), </booktitle> <pages> pages 77-94, </pages> <address> Anaheim, CA, USA, </address> <month> July </month> <year> 1991. </year> <month> 6 </month>
Reference-contexts: This method seems to be applicable in diverse situations, and it often produces good results. Han et al. have shown how AOI can be incorporated in a data classification process <ref> [3] </ref>. In the process, classification is performed in the event space that has been reduced by first applying AOI to the initial data relation.
Reference: [4] <author> J. Han, Y. Cai, and N. Cercone. </author> <title> Knowledge discovery in databases: an attribute-oriented approach. </title> <booktitle> In Proceedings of the 18th VLDB Conference, </booktitle> <pages> pages 547-559, </pages> <address> Vancouver, British Columbia, Canada, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction In a series of papers <ref> [4, 5] </ref> Jiawei Han and coauthors have introduced a knowledge discovery method called attribute-oriented induction, AOI for short. This method seems to be applicable in diverse situations, and it often produces good results. Han et al. have shown how AOI can be incorporated in a data classification process [3]. <p> The connection between the two methods is discussed in Section 4, while Section 5 is a short conclusion. 2 Attribute-oriented induction We give here a simplified description of the attribute-oriented induction method; for details, see <ref> [4, 5] </ref>. Given a relation r over attributes fA 1 ; : : : ; A n g, and for all i a generalization hierarchy H i for the values of A i , repeatedly perform the so called attribute-oriented generalization step, and combine rows that thus become equal.
Reference: [5] <author> J. Han, Y. Cai, and N. Cercone. </author> <title> Data-driven discovery of quantitative rules in relational databases. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(1) </volume> <pages> 29-40, </pages> <month> February </month> <year> 1993. </year>
Reference-contexts: 1 Introduction In a series of papers <ref> [4, 5] </ref> Jiawei Han and coauthors have introduced a knowledge discovery method called attribute-oriented induction, AOI for short. This method seems to be applicable in diverse situations, and it often produces good results. Han et al. have shown how AOI can be incorporated in a data classification process [3]. <p> The connection between the two methods is discussed in Section 4, while Section 5 is a short conclusion. 2 Attribute-oriented induction We give here a simplified description of the attribute-oriented induction method; for details, see <ref> [4, 5] </ref>. Given a relation r over attributes fA 1 ; : : : ; A n g, and for all i a generalization hierarchy H i for the values of A i , repeatedly perform the so called attribute-oriented generalization step, and combine rows that thus become equal.
Reference: [6] <author> L. Pitt and R. E. Reinke. </author> <title> Criteria for polynomial-time (conceptual) clustering. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 371-396, </pages> <year> 1988. </year> <month> 7 </month>
Reference-contexts: In the process, classification is performed in the event space that has been reduced by first applying AOI to the initial data relation. In this note we point out that AOI itself can be viewed as a conceptual clustering method, as presented by Pitt & Reinke <ref> [6] </ref>, with a specialized concept description language. Our conclusion is that the success of AOI is due partly to the general usefulness of conceptual clustering, and partly to the successful choice of the description language. The paper is organized as follows. <p> By performing the generalization step once for both attributes, in either order, we get the generalized relation in Table 2. The relation could be further generalized by employing "ANY" values. 3 Conceptual clustering In this section we present the conceptual clustering problem, following the exposition of <ref> [6] </ref> (see also [2]). Let D denote the class of all objects of interest. A description language L = (S; f) is a set S of expressions together with a mapping f : S ! P (D), where P (D) denotes the powerset of D. <p> The goodness G of the clusterings is defined as a function of intraclus-ter tightness, similarity within clusters, and intercluster distance, unlikeness between clusters. An exact formulation of various possibilities of defining goodness is given in <ref> [6] </ref>. The surprising result of [6] is that the above algorithm produces, under fairly general conditions, an optimal clustering, i.e., one that has the best possible value of goodness. <p> The goodness G of the clusterings is defined as a function of intraclus-ter tightness, similarity within clusters, and intercluster distance, unlikeness between clusters. An exact formulation of various possibilities of defining goodness is given in <ref> [6] </ref>. The surprising result of [6] is that the above algorithm produces, under fairly general conditions, an optimal clustering, i.e., one that has the best possible value of goodness. <p> The tightness of a cluster can be defined based on the distance measure, for example as the distance between (a 1 ; : : : ; a n ) and ("ANY"; : : : ; "ANY"). This suggests that goodness, as presented by Pitt & Reinke <ref> [6] </ref>, can be used as the overall quality function in the AOI process. Now the instance of the conceptual clustering problem corresponding to the instance of AOI on relation r is defined as follows. <p> The process jumps over clusterings 2 and 5 . Clustering 3 corresponds to the generalized relation in Table 2. 5 Concluding remarks We have shown that the successful data mining method of attribute-oriented induction can be viewed as conceptual clustering as described in, e.g., <ref> [6] </ref>. In retrospect this correspondence is not particularly surprising: both AOI 5 and conceptual clustering are unsupervised methods producing disjunctive descriptions of their input. It seems to us that this connection could be useful in both directions.
References-found: 6

