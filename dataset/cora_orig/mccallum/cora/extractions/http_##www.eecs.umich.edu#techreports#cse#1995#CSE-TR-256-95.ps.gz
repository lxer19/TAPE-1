URL: http://www.eecs.umich.edu/techreports/cse/1995/CSE-TR-256-95.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse95.html
Root-URL: http://www.eecs.umich.edu
Email: flinear, davidsong@eecs.umich.edu  
Phone: Phone: (313) 936-2917  
Title: Automatic Generation of Performance Bounds on the KSR1  
Author: Hsien-Hsin Lee Edward S. Davidson 
Address: Ann Arbor, Michigan 48109  
Affiliation: Advanced Computer Architecture Laboratory Department of Electrical Engineering and Computer Science University of Michigan,  
Abstract: Performance evaluation techniques have become critical indices for both architecture designers and software developers in recent years. Automatic tools are in demand for characterizing performance easily. In addition, a good performance analyzer should be able to point out the amount of performance loss relative to an ideal, where it occurs, and its causes. In this paper, MACS bounds, a hierarchy of bounds for modeling the performance, will be introduced for loop-dominated scientific code. This model successively considers the peak floating-point performance of a Machine of interest (M), the essential operations in a high level Application code of interest (MA), the additional operations in the Compiler-generated workload (MAC), the compiler-generated Schedule for this workload (MACS), and the actual delivered performance. In ascending through the MACS bounds hierarchy from the M bound, the model becomes increasingly constrained as it moves in several steps from potentially deliverable toward actually delivered performance. Each step from one bound to the next quantifies a performance gap associated with particular causes. The bound methodology will then be applied to a multiple-processor system to predict the run-time bound of a scientific application. We present three automatic bound generators, K-MA, K MACSTAT and MACS GAP, based on our performance model on the KSR1 Massively Parallel Processing (MPP) machine. Finally, we will use the performance bound models and tools to experiment on a real parallel scientific application running on the KSR1. The analysis results of our selected loops will be illustrated by the MACS bounds hierarchy, machine utilization, and relative speed-up to uniprocessor. These information will be very useful for improving the performance of the application at the right point. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. H. Mangione-Smith, T-P. Shih, S. G. Abraham, E. S. Davidson, </author> <title> "Approaching a Machine-Application Bound in Delivered Performance on Scientific Code," </title> <booktitle> IEEE Proceedings, </booktitle> <address> pp.1166-1178, </address> <month> August, </month> <year> 1993. </year>
Reference-contexts: A hierarchical performance bounding methodology was originally developed by our research group in <ref> [1, 2] </ref>. In [4], this methodology was applied to build a performance model for the Kendall Square Research KSR1 machine. The preliminary performance analysis results based on the performance bounding methodology on the KSR1 using the Livermore Fortran Kernels 1-12 (LFK1-12) benchmark as an example are illustrated in [4, 5]. <p> Our research group has developed a hierarchical bounding methodology, called MACS bounds, for computing such bounds <ref> [1, 2, 9, 10] </ref>.
Reference: [2] <author> E. L. Boyd, E. S. Davidson, </author> <title> "Hierarchical Performance Modeling with MACS: A Case Study of the Convex C-240," </title> <booktitle> Proceedings of the 20th International Symposium on Computer Architecture, </booktitle> <address> pp.203-212, </address> <month> May, </month> <year> 1993. </year>
Reference-contexts: A hierarchical performance bounding methodology was originally developed by our research group in <ref> [1, 2] </ref>. In [4], this methodology was applied to build a performance model for the Kendall Square Research KSR1 machine. The preliminary performance analysis results based on the performance bounding methodology on the KSR1 using the Livermore Fortran Kernels 1-12 (LFK1-12) benchmark as an example are illustrated in [4, 5]. <p> Our research group has developed a hierarchical bounding methodology, called MACS bounds, for computing such bounds <ref> [1, 2, 9, 10] </ref>.
Reference: [3] <author> G. Bell, </author> <title> "Ultracomputers: A Teraflop Before Its Time," </title> <journal> Communications of the ACM, </journal> <volume> pp.27-47, </volume> <month> August, </month> <year> 1992. </year>
Reference-contexts: More powerful computers are demanded for many scientific applications over a range of many research and industrial fields. Although these MPP systems are both size and generation scalable <ref> [3] </ref> and the peak performance numbers claimed by the systems manufacturers are also scalable, the actual performance when running even those applications whose problems sizes are getting larger and larger today does not grow linearly with the scaled hardware components.
Reference: [4] <author> W. Azeem, </author> <title> "Modeling and Approaching the Deliverable Performance Capability of the KSR1 Processor," </title> <institution> University of Michigan, </institution> <type> Technical Report, </type> <institution> CSE-TR-164-93, </institution> <month> June, </month> <year> 1993. </year>
Reference-contexts: A hierarchical performance bounding methodology was originally developed by our research group in [1, 2]. In <ref> [4] </ref>, this methodology was applied to build a performance model for the Kendall Square Research KSR1 machine. The preliminary performance analysis results based on the performance bounding methodology on the KSR1 using the Livermore Fortran Kernels 1-12 (LFK1-12) benchmark as an example are illustrated in [4, 5]. <p> In [4], this methodology was applied to build a performance model for the Kendall Square Research KSR1 machine. The preliminary performance analysis results based on the performance bounding methodology on the KSR1 using the Livermore Fortran Kernels 1-12 (LFK1-12) benchmark as an example are illustrated in <ref> [4, 5] </ref>. In this paper, the KSR1 architecture will be presented in next section. In section 3 and section 4, we will develop the performance bounds model defined in [4, 5] into a more precise model for both sequential and parallel versions of scientific codes running on the KSR1. <p> the performance bounding methodology on the KSR1 using the Livermore Fortran Kernels 1-12 (LFK1-12) benchmark as an example are illustrated in <ref> [4, 5] </ref>. In this paper, the KSR1 architecture will be presented in next section. In section 3 and section 4, we will develop the performance bounds model defined in [4, 5] into a more precise model for both sequential and parallel versions of scientific codes running on the KSR1. <p> Previous work on defining bounds equations and analyzing the Livermore Fortran Kernels (LFKs) 1- 12 benchmarks on the KSR1 can be found in <ref> [4, 5] </ref>. We will extend the original model into a more precise one to more accurately and completely characterize the performance bounds of application codes. The performance bounds are expressed clock cycles per floating-point operation (CPF) or the number of clock cycles spent per iteration of innermost loop (CPL). <p> The compiler typically unrolls 2, 4, 8, or 16 iterations using a heuristic. Increasing the degree of unrolling will reduce the start-up and termination overheads. * Polycyclic loop scheduling: A re-targetable tool, called OCO (Object Code Optimizer) in <ref> [4] </ref>, can reschedule the KSR compiled code by using a polycyclic loop scheduling algorithm, also known as software pipelining. 5.4 Gap P (MACS ! Measured CPF/CPL Gap) Gap P results from cache miss penalties, internodal communication stalls, and context switches.
Reference: [5] <author> E. L. Boyd, W. Azeem, H-H. Lee, T-P. Shih, S-H. Hung, E. S. Davidson, </author> <title> "A Hierarchical Approach to Modeling and Improving the Performance of Scientific Applications on the KSR1," </title> <booktitle> 35 Proceedings of International Conference on Parallel Processing, </booktitle> <address> vol.III, pp.188-192, </address> <month> August, </month> <year> 1994. </year>
Reference-contexts: In [4], this methodology was applied to build a performance model for the Kendall Square Research KSR1 machine. The preliminary performance analysis results based on the performance bounding methodology on the KSR1 using the Livermore Fortran Kernels 1-12 (LFK1-12) benchmark as an example are illustrated in <ref> [4, 5] </ref>. In this paper, the KSR1 architecture will be presented in next section. In section 3 and section 4, we will develop the performance bounds model defined in [4, 5] into a more precise model for both sequential and parallel versions of scientific codes running on the KSR1. <p> the performance bounding methodology on the KSR1 using the Livermore Fortran Kernels 1-12 (LFK1-12) benchmark as an example are illustrated in <ref> [4, 5] </ref>. In this paper, the KSR1 architecture will be presented in next section. In section 3 and section 4, we will develop the performance bounds model defined in [4, 5] into a more precise model for both sequential and parallel versions of scientific codes running on the KSR1. <p> Previous work on defining bounds equations and analyzing the Livermore Fortran Kernels (LFKs) 1- 12 benchmarks on the KSR1 can be found in <ref> [4, 5] </ref>. We will extend the original model into a more precise one to more accurately and completely characterize the performance bounds of application codes. The performance bounds are expressed clock cycles per floating-point operation (CPF) or the number of clock cycles spent per iteration of innermost loop (CPL).
Reference: [6] <institution> KSR1 Principles of Operation, Kendall Square Research Corp., </institution> <month> October, </month> <year> 1992. </year> <title> [7] "Kendall Square Multiprocessor: Early experiences and performance", </title> <institution> Oak Ridge National Laboratory Technical Report ORNL/TM-12065, </institution> <month> April, </month> <year> 1992. </year>
Reference-contexts: Common techniques include loop fusion, loop blocking, loop interchange [13], and special functions such as the pref etch=poststore instructions of the KSR1 <ref> [6] </ref>.
Reference: [8] <author> K. Hwang, </author> <title> Advanced Computer Architecture: Parallelism, Scalability, Programmability, </title> <publisher> McGraw-Hill Inc., </publisher> <year> 1993. </year>
Reference: [9] <author> W. Meleis, </author> <title> "Reducing Memory Bandwidth Requirement in Scientific Code," Directed Study, </title> <institution> University of Michigan, </institution> <year> 1992. </year>
Reference-contexts: Our research group has developed a hierarchical bounding methodology, called MACS bounds, for computing such bounds <ref> [1, 2, 9, 10] </ref>.
Reference: [10] <author> W. H. Mangione-Smith, </author> <title> "Performance Bounds and Buffer Space Requirements for Concurrent Processors," </title> <type> Ph.D. dissertation, </type> <institution> University of Michigan, </institution> <year> 1991. </year>
Reference-contexts: Our research group has developed a hierarchical bounding methodology, called MACS bounds, for computing such bounds <ref> [1, 2, 9, 10] </ref>.
Reference: [11] <author> U. Banerjee, S-C. Chen, D. J. Kuck, R. A. Towle, </author> <title> "Time and Parallel Processor Bounds for Fortran-Like Loops," </title> <journal> IEEE Transactions on Computers, </journal> <volume> pp.660-670, </volume> <month> September, </month> <year> 1979. </year>
Reference-contexts: Given an application code, people may be interested in how fast this application can run on a machine of interest, namely, an upper bound on the achievable perfor 10 mance of the given application on the machine of interest <ref> [11] </ref>. Since software and hardware causes of performance degradation can be very intricate, it may not be clear which of several potential bottlenecks must be addressed in order to improve a poor performance. Many factors can affect the running time of the application.
Reference: [12] <author> T-P. Shih, E. S. Davidson, </author> <title> "Grouping Array Layouts to Reduce Communication and Improve Locality of Parallel Programs," </title> <note> submitted to 1994 International Conference on Parallel and Distributd Systems. </note>
Reference-contexts: Cache and internodal communication simulation enable the visualization of data structure movement in the memory hierarchy. Two tools, K-T race and K-Sim, developed by our group for the KSR1 will provide insights into cache and communication behavior. Gap P can be reduced by restructuring data reference patterns <ref> [12] </ref> in order to maximize the data reuse in the subcache and local cache levels to reduce the cache misses and internodal communication stalls. Common techniques include loop fusion, loop blocking, loop interchange [13], and special functions such as the pref etch=poststore instructions of the KSR1 [6].
Reference: [13] <author> H. Zima, B. Chapman, </author> <title> Supercompilers for Parallel and Vector Machines, </title> <publisher> Addison-Wesley, ACM Press, </publisher> <address> New York, 1991 36 APPENDIX: K-MACSTAT </address>
Reference-contexts: Gap P can be reduced by restructuring data reference patterns [12] in order to maximize the data reuse in the subcache and local cache levels to reduce the cache misses and internodal communication stalls. Common techniques include loop fusion, loop blocking, loop interchange <ref> [13] </ref>, and special functions such as the pref etch=poststore instructions of the KSR1 [6].
References-found: 12

