URL: http://cobar.cs.umass.edu/pubfiles/UM-CS-1995-088.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Title: Extracting Text From Greyscale Images  
Author: Victor Wu R. Manmatha 
Affiliation: Vision Lab, Computer Science Department,University of Massachusetts at Amherst.  
Note: This work is supported by the Center for Intelligent Information Retrieval and by NRaD grant number N66001-94-D-6054. This work is also partially supported by the  
Date: October, 1995  
Pubnum: CMPSCI TR95-88  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Lloyd Alan Fletcher and Rangachar Kasturi. </author> <title> A robust algorithm for text string separation from mixed text/graphics images. </title> <journal> IEEE Transactions on Pattern Analysis And Machine Intelligence, </journal> <volume> 10(6) </volume> <pages> 910-918, </pages> <month> Nov. </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Current OCR and page segmentation schemes are largely restricted to finding text against good clean backgrounds ([2], [6], <ref> [1] </ref>, [4], [3] ). However, text is often found in images or against shaded or textured backgrounds such as maps, financial documents and engineering drawings. <p> These include engineering drawings, maps, bar codes and newspapers, and envelopes [8]. 1 Many people have developed algorithms to do text extraction. However, most of them have severe limitations on the types of images. One group of the algorithms can only work with binary images <ref> [4, 5, 1] </ref>. The ones which can handle greyscale images either require that the images has few variation in intensity [6], require prior knowledge of the character stroke width [3], or require some prior information about the distribution of gray levels for text and non-text [7].
Reference: [2] <author> Anil K. Jain and Sushil Bhattachariee. </author> <title> Text segmentation using gabor filters for automatic document processing. </title> <journal> Machine Vision and Applications, </journal> <volume> 5, </volume> <year> 1992. </year>
Reference-contexts: Only one algorithm that we know of has addressed the issue of text strings at any orientation <ref> [2] </ref>. 3 System Overview This section provides an overview of the main components of our system. Details on the techniques used are provided in section 5.
Reference: [3] <author> Mohamed Kamel and Aiguo Zhao. </author> <title> Extraction of binary character/graphics images from grayscale document images. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 55(3) </volume> <pages> 203-217, </pages> <month> May. </month> <year> 1993. </year>
Reference-contexts: 1 Introduction Current OCR and page segmentation schemes are largely restricted to finding text against good clean backgrounds ([2], [6], [1], [4], <ref> [3] </ref> ). However, text is often found in images or against shaded or textured backgrounds such as maps, financial documents and engineering drawings. <p> One group of the algorithms can only work with binary images [4, 5, 1]. The ones which can handle greyscale images either require that the images has few variation in intensity [6], require prior knowledge of the character stroke width <ref> [3] </ref>, or require some prior information about the distribution of gray levels for text and non-text [7]. Only one algorithm that we know of has addressed the issue of text strings at any orientation [2]. 3 System Overview This section provides an overview of the main components of our system.
Reference: [4] <author> Su Liang and M. Ahmadi. </author> <title> A morphological approach to text string extraction from regular periodic overlapping text/background images. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 56(5) </volume> <pages> 402-413, </pages> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Current OCR and page segmentation schemes are largely restricted to finding text against good clean backgrounds ([2], [6], [1], <ref> [4] </ref>, [3] ). However, text is often found in images or against shaded or textured backgrounds such as maps, financial documents and engineering drawings. <p> These include engineering drawings, maps, bar codes and newspapers, and envelopes [8]. 1 Many people have developed algorithms to do text extraction. However, most of them have severe limitations on the types of images. One group of the algorithms can only work with binary images <ref> [4, 5, 1] </ref>. The ones which can handle greyscale images either require that the images has few variation in intensity [6], require prior knowledge of the character stroke width [3], or require some prior information about the distribution of gray levels for text and non-text [7].
Reference: [5] <author> Huizhu Luo and Its'hak Dinstein. </author> <title> Using directional mathematical morphology for separation of character strings from text/graphics image. </title> <booktitle> IAPR International Workshop on Structural and Syntactic Pattern Recognition, </booktitle> <address> Naharia, Israel, </address> <month> Oct </month> <year> 1994. </year>
Reference-contexts: These include engineering drawings, maps, bar codes and newspapers, and envelopes [8]. 1 Many people have developed algorithms to do text extraction. However, most of them have severe limitations on the types of images. One group of the algorithms can only work with binary images <ref> [4, 5, 1] </ref>. The ones which can handle greyscale images either require that the images has few variation in intensity [6], require prior knowledge of the character stroke width [3], or require some prior information about the distribution of gray levels for text and non-text [7].
Reference: [6] <author> Lawrence O'Gorman. </author> <title> Binarization and multithresholding of document images using connectivity. Computer Vision, </title> <journal> Graphics and Image Processing, </journal> <volume> 56(6) </volume> <pages> 494-506, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: 1 Introduction Current OCR and page segmentation schemes are largely restricted to finding text against good clean backgrounds ([2], <ref> [6] </ref>, [1], [4], [3] ). However, text is often found in images or against shaded or textured backgrounds such as maps, financial documents and engineering drawings. <p> However, most of them have severe limitations on the types of images. One group of the algorithms can only work with binary images [4, 5, 1]. The ones which can handle greyscale images either require that the images has few variation in intensity <ref> [6] </ref>, require prior knowledge of the character stroke width [3], or require some prior information about the distribution of gray levels for text and non-text [7].
Reference: [7] <author> Torfinn Taxt, Patrick J. Flynn, and Anil K. Jain. </author> <title> Segmentation of document images. </title> <journal> IEEE Transactions on Pattern Analysis And Machine Intelligence, </journal> <volume> 11(12) </volume> <pages> 1322-1329, </pages> <month> Dec. </month> <year> 1989. </year> <title> [8] ivind Due Trier and Torfinn Taxt. Evaluation of binarization methods for document images. </title> <journal> IEEE Transactions on Pattern Analysis And Machine Intelligence, </journal> 17(3):312-315, March 1995. 
Reference-contexts: The ones which can handle greyscale images either require that the images has few variation in intensity [6], require prior knowledge of the character stroke width [3], or require some prior information about the distribution of gray levels for text and non-text <ref> [7] </ref>. Only one algorithm that we know of has addressed the issue of text strings at any orientation [2]. 3 System Overview This section provides an overview of the main components of our system. Details on the techniques used are provided in section 5.

References-found: 7

