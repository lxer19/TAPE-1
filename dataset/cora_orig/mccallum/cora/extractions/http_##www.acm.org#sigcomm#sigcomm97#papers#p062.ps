URL: http://www.acm.org/sigcomm/sigcomm97/papers/p062.ps
Refering-URL: http://www.cs.gatech.edu/computing/classes/cs6380_97_fall/
Root-URL: 
Email: -cheshire,mgbaker-@cs.stanford.edu  
Title: 1 Consistent Overhead Byte Stuffing designed to incur low average overhead but have made little
Author: Stuart Cheshire and Mary Baker 
Note: To date, byte stuffing algorithms, such as those used by SLIP [RFC1055], PPP [RFC1662] and AX.25 [ARRL84], have been  
Address: Stanford, California 94305, USA  
Affiliation: Computer Science Department, Stanford University  
Abstract: Byte stuffing is a process that transforms a sequence of data bytes that may contain illegal or reserved values into a potentially longer sequence that contains no occurrences of those values. The extra length is referred to in this paper as the overhead of the algorithm. Some increasingly popular network devices, however, care more about the worst case. For example, the transmission time for ISM-band packet radio transmitters is strictly limited by FCC regulation. To adhere to this regulation, the practice is to set the maximum packet size artificially low so that no packet, even after worst case overhead, can exceed the transmission time limit. This paper presents a new byte stuffing algorithm, called Consistent Overhead Byte Stuffing (COBS), that tightly bounds the worst case overhead. It guarantees in the worst case to add no more than one byte in 254 to any packet. Furthermore, the algorithm is computationally cheap, and its average overhead is very competitive with that of existing algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [ARRL84] <editor> AX.25 Amateur Packet-Radio Link-Layer Protocol Version 2.0, </editor> <month> October </month> <year> 1984. </year> <title> Available from the American Radio R e lay League, Newington CT USA 06111, and other sources. </title>
Reference-contexts: In general, some added overhead (in terms of additional bytes transmitted over the serial m e-dium) is inevitable if we are to perform byte stuffing without loss of information. Current byte stuffing algorithms, such as those used by SLIP [RFC1055], PPP [RFC1662] and AX.25 <ref> [ARRL84] </ref>, have potentially high variance in per-packet overhead. For example, using PPP byte stuffing, the overall overhead (averaged over a large number of packets) is typically 1% or less, but ind i-vidual packets can increase in size by as much as 100%.
Reference: [CA-96.26] <institution> CERT SM Advisory CA-96.26. Denial-of-Service Attack via ping, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: Fragmentation and rea s-sembly code has proved notoriously difficult to get right, as evidenced by the recent spate of Internet Ping of death attacks exploiting a reassembly bug that exists in many implementations of IP <ref> [CA-96.26] </ref>. Link-layer fragmentation would also add protocol overhead, because the link-layer packet headers would have to contain additional fields to support the detection, ordering, and reassembly of fragments at the receiving end.
Reference: [Che95] <author> Stuart Cheshire and Mary Baker. </author> <title> Experi ences with a Wireless Network in MosquitoNet. </title> <booktitle> IEEE Micro, </booktitle> <month> February </month> <year> 1996. </year> <note> An earlier version of this paper appeared in Proceedings of the IEEE Hot Interco n nects Symposium 95, </note> <month> August </month> <year> 1995. </year>
Reference-contexts: For example, a radio interface that connects through the serial port like a Hayes modem might use an ASCII carriage return (byte value 0x0D) to mark the end of each packet <ref> [Che95] </ref>. By taking the output of COBS and XORing each byte with 0x0D before sending it to the radio, the COBS output is easily converted into a form suitable for transmission over this radio device.
Reference: [Che97] <author> Stuart Cheshire. </author> <title> Consistent Overhead Byte Stuffing, </title> <type> Ph.D. Thesis, </type> <institution> Computer Science Department, Stanford, </institution> <year> 1997. </year> <month> 12 </month>
Reference-contexts: A more exhaustive treatment of framing and data stuffing can be found in <ref> [Che97] </ref>. 3. Consistent Overhead Byte Stuffing Algorithms We first provide an overview of the encoding used by COBS and then describe the procedure for performing that encoding. <p> Finally, if even a single byte of overhead is unacceptable, a trivial modification to COBS to support Zero Pair Elimination makes it perform better than PPP, even for short packets. COBS/ZPE beats both PPPs average overhead and its worst case overhead. Further information about COBS is available in <ref> [Che97] </ref>. 7.
Reference: [Cla90] <author> David Clark and David Tennenhouse. </author> <title> Architectural Considerations for a New Generation of Protocols. </title> <booktitle> Proceedings of ACM SIGCOMM 1990, </booktitle> <month> September </month> <year> 1990. </year>
Reference-contexts: The receiver XORs each received byte with 0x0D to reverse the transformation before feeding it to the COBS decoder, so that the data is decoded correctly. Of course, in real implementations, the COBS encoding and the output conversion are performed in a single loop for efficiency reasons <ref> [Cla90] </ref>. 02 x 0C H e l l o W o r l d COBS takes its input data and encodes it as a series of variable length code blocks. Each code block begins with a single code byte (shown shaded), followed by zero or more data bytes.
Reference: [ECMA40] <institution> European Computer Manufacturers Association Standard ECMA-40: HDLC Frame Structure. </institution>
Reference-contexts: The amount of increase depends on the patterns of values that appear in the original data and can vary from no overhead at all to doubling the packet size (in the worst case for PPP). These are discussed in more detail below. HDLC <ref> [ECMA40] </ref> uses a bit stuffing scheme. It uses the binary sequence 01111110, called the Flag Sequence, to mark boundaries between packets. To eliminate this pattern from the data, the following transformation is used: whenever the transmitter observes five ones in a row, it inserts a zero immed i-ately following.
Reference: [Hum81] <author> Pierre Humblet. </author> <title> Generalization of Huffman Coding to Minimize the Pro b-ability of Buffer Overflow. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> Vol. IT-27, </volume> <pages> pp. 230-232, </pages> <month> March </month> <year> 1981. </year>
Reference-contexts: We have avoided using more computationally expensive compression algorithms such as Huffman encoding [Huff52] [Knu85] and Lempel Ziv [LZ77] [Wel84]. Although, like PPP, they may have good average performance, for some data they can make the packet bigger instead of smaller <ref> [Hum81] </ref>, and that is contrary to our goal of ensuring a tight bound on worst-case performance. We also believe it is inappropriate to attempt heavyweight compression at the link layer.
Reference: [Huff52] <author> D. A. Huffman. </author> <title> A Method for the Construction of Minimum-Redundancy Codes. </title> <booktitle> Proceedings of the IRE, </booktitle> <address> Vol.40, No.9, </address> <month> September </month> <year> 1952, </year> <month> pp.1098-1101. </month>
Reference-contexts: These padding zeroes waste precious bandwidth on slow wireless links, and using COBS/ZPE can help to mitigate this effect by encoding these patterns more efficiently. We have avoided using more computationally expensive compression algorithms such as Huffman encoding <ref> [Huff52] </ref> [Knu85] and Lempel Ziv [LZ77] [Wel84]. Although, like PPP, they may have good average performance, for some data they can make the packet bigger instead of smaller [Hum81], and that is contrary to our goal of ensuring a tight bound on worst-case performance.
Reference: [IEEE802.5] <institution> Token Ring Access Method and Physical Layer Specifications. Institute of Electr i-cal and Electronic Engineers, IEEE Sta n dard 802.5-1989, </institution> <year> 1989. </year>
Reference-contexts: In hardware systems low-level framing protocols are common. For example, in IBM Token Ring the electrical signalling on the wire uses Differential 3 Manchester Encoding, and packet boundaries are marked by a violation of those encoding rules <ref> [IEEE802.5] </ref>. Making the packet delimiter an illegal signal value is a very simple way to ensure that no packet payload can inadvertently generate that signal on the cable.
Reference: [ISO10918] <author> ISO Committee Draft 10918. </author> <title> Digital compression and coding of continuous tone still images, </title> <address> ISO/IEC 10918, </address> <year> 1991. </year>
Reference-contexts: We also believe it is inappropriate to attempt heavyweight compression at the link layer. The majority of compressible data is much more effectively compressed before it even reaches the IP layer using data-specific algorithms such as JPEG <ref> [ISO10918] </ref> for images and MPEG [ISO11172] for video. Finally, we expect to see more Internet traffic being encrypted in the future, particularly traffic over wireless links, and it is not possible to compress data after it has been properly encrypted.
Reference: [ISO11172] <author> ISO Committee Draft 11172. </author> <title> Information Technology-Coding of moving pictures and associated audio for digital storage media up to about 1.5 Mbit/s, </title> <address> ISO/IEC 11172-1, </address> <year> 1993. </year>
Reference-contexts: We also believe it is inappropriate to attempt heavyweight compression at the link layer. The majority of compressible data is much more effectively compressed before it even reaches the IP layer using data-specific algorithms such as JPEG [ISO10918] for images and MPEG <ref> [ISO11172] </ref> for video. Finally, we expect to see more Internet traffic being encrypted in the future, particularly traffic over wireless links, and it is not possible to compress data after it has been properly encrypted.
Reference: [Jac89] <author> V. Jacobson, C. Leres, and S. McCanne. tcpdump, &lt;ftp://ftp.ee.lbl.gov/tcpdump. tar.Z&gt;, </author> <month> June </month> <year> 1989. </year>
Reference-contexts: Experimental Results Real-world network traffic may not behave the same way as our theoretical traffic. In real-world traffic, small packets are common, and not all data is compressed and/or encrypted. To see how these factors affect the algorithms, we gathered traces of network traffic using tcpdump <ref> [Jac89] </ref> and compared how efficiently those packets were encoded by PPP, COBS 0.0% 0.2% 0.8% 100% Best (0%) Average (0.78%) Worst (100%) COBS Best (0.07%) COBS Average (0.23%) COBS Worst (0.40%) PPPs best, average, and worst cases vary widely.
Reference: [Knu85] <author> D. E. Knuth. </author> <title> Dynamic Huffman Coding. </title> <journal> Journal of Algorithms, </journal> <volume> Vol 6, </volume> <pages> pp 163-180, </pages> <year> 1985. </year>
Reference-contexts: These padding zeroes waste precious bandwidth on slow wireless links, and using COBS/ZPE can help to mitigate this effect by encoding these patterns more efficiently. We have avoided using more computationally expensive compression algorithms such as Huffman encoding [Huff52] <ref> [Knu85] </ref> and Lempel Ziv [LZ77] [Wel84]. Although, like PPP, they may have good average performance, for some data they can make the packet bigger instead of smaller [Hum81], and that is contrary to our goal of ensuring a tight bound on worst-case performance.
Reference: [LZ77] <author> J. Ziv and A. Lempel. </author> <title> A Universal Alg orithm for Sequential Data Compression. </title> <journal> IEEE Transactions on Information Theory, </journal> <month> May </month> <year> 1977. </year>
Reference-contexts: These padding zeroes waste precious bandwidth on slow wireless links, and using COBS/ZPE can help to mitigate this effect by encoding these patterns more efficiently. We have avoided using more computationally expensive compression algorithms such as Huffman encoding [Huff52] [Knu85] and Lempel Ziv <ref> [LZ77] </ref> [Wel84]. Although, like PPP, they may have good average performance, for some data they can make the packet bigger instead of smaller [Hum81], and that is contrary to our goal of ensuring a tight bound on worst-case performance.
Reference: [Pog96] <author> Elliot Poger. Radioscope, &lt;http:// mosquitonet . Stanford . EDU / ~elliot / RadioScope/&gt;, </author> <month> December </month> <year> 1996. </year>
Reference-contexts: It is simple to understand, easy to implement, and gives significant performance benefits by allowing much larger packets to be sent over a given piece of network hardware. COBS is easy to implement efficiently in software, even for primitive microprocessors. In one project in our group <ref> [Pog96] </ref> COBS has been implemented in handwritten eight-bit assembly code to allow a small embedded control device to connect to a wireless interface and communicate with Internet hosts using UDP/IP.
Reference: [RFC959] <author> J. Postel, J. Reynolds. </author> <title> File Transfer Protocol (FTP). </title> <type> RFC 959, </type> <month> October </month> <year> 1985. </year>
Reference-contexts: To see how COBS would perform under these conditions we captured a large bulk transfer of compressed image data. The data file was MIRV.MPG, a 15.3MB MPEG file of an MTV music video, and it was transferred using ftp <ref> [RFC959] </ref>. The trace contains 25,858 IP packets, totalling 18,269,430 bytes of data. The MTU of the wireless interface was 1088 bytes, giving a worst-case COBS overhead for large packets of five bytes.
Reference: [RFC1055] <author> J. Romkey. </author> <title> A Nonstandard For Trans mission Of IP Datagrams Over Serial Lines: SLIP. </title> <type> RFC 1055, </type> <month> June </month> <year> 1988. </year>
Reference-contexts: In general, some added overhead (in terms of additional bytes transmitted over the serial m e-dium) is inevitable if we are to perform byte stuffing without loss of information. Current byte stuffing algorithms, such as those used by SLIP <ref> [RFC1055] </ref>, PPP [RFC1662] and AX.25 [ARRL84], have potentially high variance in per-packet overhead. For example, using PPP byte stuffing, the overall overhead (averaged over a large number of packets) is typically 1% or less, but ind i-vidual packets can increase in size by as much as 100%.
Reference: [RFC1135] <author> J. Reynolds. </author> <title> The Helminthiasis (infest ation with parasitic worms) of the I n ternet. </title> <type> RFC 1135, </type> <month> December </month> <year> 1989. </year>
Reference-contexts: An attacker could use such packets to exploit the devices inability to send and/or receive worst-case packets, causing mischief ranging from simple denial of service attacks to the much more serious potential for exploiting finger-dmon-style runoff-the-end-of-the-array bugs <ref> [RFC1135] </ref>. This problem could be solved in a variety of ways. One solution would be to set the IP MTU close to the underlying device MTU, and use link-layer fragme n-tation and reassembly for packets that exceed the limit when encoded.
Reference: [RFC1662] <author> William Simpson. </author> <note> PPP in HDLC-like Framing. RFC 1662, </note> <month> July </month> <year> 1994. </year>
Reference-contexts: In general, some added overhead (in terms of additional bytes transmitted over the serial m e-dium) is inevitable if we are to perform byte stuffing without loss of information. Current byte stuffing algorithms, such as those used by SLIP [RFC1055], PPP <ref> [RFC1662] </ref> and AX.25 [ARRL84], have potentially high variance in per-packet overhead. For example, using PPP byte stuffing, the overall overhead (averaged over a large number of packets) is typically 1% or less, but ind i-vidual packets can increase in size by as much as 100%. <p> For this reason it is more common for software algorithms to use byte stuffing. PPP uses a byte stuffing scheme <ref> [RFC1662] </ref>. It uses a byte with value 0x7E (the same as the HDLC Flag Sequence) to mark boundaries between packets.
Reference: [RFC1883] <author> Steve Deering and Bob Hinden. </author> <title> Internet Protocol, Version 6 (IPv6) Specification. </title> <type> RFC 1883, </type> <month> December </month> <year> 1995. </year>
Reference-contexts: It is the large packets that cause problems, because the software must be able to ensure that they do not exceed the devices physical and regulatory limits. Another factor is that the move to IPv6 <ref> [RFC1883] </ref> in the future means that the very smallest packets, where PPP does better than COBS, will become increasingly uncommon.
Reference: [US94-15] <institution> United States Title 47 Code of Federal Regulations (CFR), Federal Communica tions Commission (FCC) Part 15, Low Power Device Regulations, Section 15.247. U.S. Government Printing Office. </institution>
Reference-contexts: Unlike telephone modems these devices are not insensitive to the packet sizes they have to send. Channel-hopping packet radios that operate in the unlicensed ISM (Industrial/Scientific/Medical) bands under the FCC Part 15 rules <ref> [US94-15] </ref> have a maximum transmission time which they are not allowed to exceed. Unexpectedly doubling the size of a packet could result in a packet that is too big to transmit legally.
Reference: [Wel84] <author> T. Welch. </author> <title> A Technique for High Performance Data Compression. </title> <address> Com puter, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: These padding zeroes waste precious bandwidth on slow wireless links, and using COBS/ZPE can help to mitigate this effect by encoding these patterns more efficiently. We have avoided using more computationally expensive compression algorithms such as Huffman encoding [Huff52] [Knu85] and Lempel Ziv [LZ77] <ref> [Wel84] </ref>. Although, like PPP, they may have good average performance, for some data they can make the packet bigger instead of smaller [Hum81], and that is contrary to our goal of ensuring a tight bound on worst-case performance.
References-found: 22

