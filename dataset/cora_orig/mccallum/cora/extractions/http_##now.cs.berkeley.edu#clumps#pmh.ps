URL: http://now.cs.berkeley.edu/clumps/pmh.ps
Refering-URL: http://now.cs.berkeley.edu/clumps/index.html
Root-URL: 
Title: Modeling Parallel Computers as Memory Hierarchies  on Programming Models for Massively Parallel Computers)  
Author: Bowen Alpern, Larry Carter, and Jeanne Ferrante 
Note: (1993 Conference  
Address: Yorktown Heights, N.Y. 10598  
Affiliation: IBM T.J. Watson Research Center  
Abstract: The Parallel Memory Hierarchy (PMH) model of computation uses a single mechanism to model the costs of both interprocessor communication and memory hierarchy traffic. A computer is modeled as a tree of memory modules with processors at the leaves. All data movement takes the form of block transfers between children and their parents. This paper assesses the strengths and weaknesses of the PMH model as a generic model. 
Abstract-found: 1
Intro-found: 1
Reference: [AACS87] <author> Aggarwal, A., B. Alpern, A. K. Chandra, and M. Snir, </author> <title> "A Model for Hierarchical Memory," </title> <booktitle> Proc. 19th Symp. on Theory of Comp., </booktitle> <month> May </month> <year> 1987, </year> <pages> pp. 305-314. </pages>
Reference-contexts: Similarly, there are numerous models for data movement in a memory hierarchy <ref> [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90] </ref>, and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [ACS87] <author> Aggarwal, A., A. K. Chandra, and M. Snir, </author> <title> "Hierarchical Memory with Block Transfer," </title> <booktitle> Proc 28th Symp. on Foundations of Comp. Sci., Octo-ber 1987, </booktitle> <pages> pp. 204-216. </pages>
Reference-contexts: Similarly, there are numerous models for data movement in a memory hierarchy <ref> [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90] </ref>, and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [ACS89] <author> Aggarwal, A., A. K. Chandra, and M. Snir, </author> <title> "On Communication Latency in PRAM Computations," </title> <booktitle> Proc 1989 ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1989, </year> <pages> pp. 11-21. </pages>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures.
Reference: [AV88] <author> Aggarwal, A. and J. Vitter, </author> <title> "IO Complexity of Sorting and Related Problems," </title> <journal> CACM, </journal> <month> Sep-tember </month> <year> 1988, </year> <pages> pp. 305-314. </pages>
Reference-contexts: Similarly, there are numerous models for data movement in a memory hierarchy <ref> [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90] </ref>, and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [AHU74] <author> Aho, A., J. Hopcroft, and J. Ullman, </author> <title> The Design and Analysis of Computer Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1974. </year>
Reference: [AABCH91] <author> Almasi, G., B. Alpern, L. Berman, L. Carter, and D. Hale, </author> <title> "A Case-study in Performance Programming: Seismic Migration ," High Performance Computing II, </title> <publisher> North Holland, </publisher> <month> Octo-ber </month> <year> 1991. </year>
Reference-contexts: Our model differs from these other models by allowing data to be stored in the intermediate nodes of the tree. This allows us to use the same structure to model the memory hierarchy, which in our experience <ref> [AABCH91, TAC92, ACFS93] </ref> is crucially important for developing high-performance programs. 3 Choosing a Specific Model A three-step approach can be used to derive a specific PMH model for a given architecture.
Reference: [AC93] <author> Alpern, B. and L. Carter, </author> <title> "Towards a Model for Portable Parallel Performance: Exposing the Memory Hierarchy," Workshop on Portability and Performance for Parallel Processing, </title> <address> Southamp-ton, England, </address> <month> July </month> <year> 1993, </year> <note> to be published by Wiley. </note>
Reference-contexts: The diversity of parallel machines, from massively parallel to vector supercomputers, from shared address space to message passing paradigms, from 2D mesh and hypercube to fat tree topologies, makes it difficult to write a single program that runs efficiently on these differing architectures <ref> [AC93] </ref>. Yet rewriting applications for each new computer is extremely expensive. One approach to developing portable software is to write a generic program | a program that, after machine-specific details have been supplied, results in a good implementation for that machine.
Reference: [ACS90] <author> Alpern, B., L. Carter, and T. Selker, </author> <title> "Visualizing Computer Memory Architectures," </title> <booktitle> IEEE Visualization '90 Conference, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: The Parallel Memory Hierarchy (PMH) model <ref> [ACF90, ACS90, ACFS93] </ref> studied in this paper models both types of data movement costs within the same framework | a tree of memory modules with processors at the leaves. It is most similar to the Fat Tree model [L85], but differs by having memory and message sizes made explicit.
Reference: [ACF90] <author> Alpern, B., L. Carter, and E. Feig, </author> <title> "Uniform Memory Hierarchies," </title> <booktitle> Proc 31st Symp. on Foundations of Comp. Sci., </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: The Parallel Memory Hierarchy (PMH) model <ref> [ACF90, ACS90, ACFS93] </ref> studied in this paper models both types of data movement costs within the same framework | a tree of memory modules with processors at the leaves. It is most similar to the Fat Tree model [L85], but differs by having memory and message sizes made explicit.
Reference: [ACFS93] <author> Alpern, B., L. Carter, E. Feig, and T. </author> <title> Selker "The Uniform Memory Hierarchy Model of Computation," </title> <journal> Algorithmica, </journal> <note> to appear. </note>
Reference-contexts: The Parallel Memory Hierarchy (PMH) model <ref> [ACF90, ACS90, ACFS93] </ref> studied in this paper models both types of data movement costs within the same framework | a tree of memory modules with processors at the leaves. It is most similar to the Fat Tree model [L85], but differs by having memory and message sizes made explicit. <p> Our model differs from these other models by allowing data to be stored in the intermediate nodes of the tree. This allows us to use the same structure to model the memory hierarchy, which in our experience <ref> [AABCH91, TAC92, ACFS93] </ref> is crucially important for developing high-performance programs. 3 Choosing a Specific Model A three-step approach can be used to derive a specific PMH model for a given architecture.
Reference: [ABetc92] <author> Anderson, E., Z. Bai, C. Bishof, J. Dem-mel, J.Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, S. Ostrouchov, amd D. Sorensen, </author> <title> LAPACK Users' Guide, </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: Yet rewriting applications for each new computer is extremely expensive. One approach to developing portable software is to write a generic program | a program that, after machine-specific details have been supplied, results in a good implementation for that machine. A well-known example is the LAPACK linear algebra library <ref> [ABetc92] </ref>, which include a blocking parameter NB that affects the size of submatrices that are passed to the Basic Linear Algebra Subroutines (BLAS). 1 Another class of examples is programs written (perhaps in PVM, Parmacs, or Express) for a collection of sequential processes that communicate by message-passing | in this case,
Reference: [AS91] <author> Anderson, R. and L. Snyder, </author> <title> "A Comparison of Shared and Nonshared Memory Models of Parallel Computation," </title> <booktitle> Proceedings of the IEEE, </booktitle> <month> April </month> <year> 1991, </year> <pages> pp. 480-487. </pages>
Reference-contexts: Undoubtedly the simplest generic model of parallel computers is the Parallel Random Access Machine (PRAM) [FW78]. There is a growing consensus that this model is too simple. Programs which make interprocessor communication explicit generally perform better than programs written for a PRAM <ref> [AS91, LS90, NS92] </ref>. A generic model defines a class of specific models. A specific model appropriate to a particular computer is obtained by specifying parameters 2 of the generic model.
Reference: [CZ89] <author> Cole, R. and O. Zajicek, </author> <title> "The APRAM: Incorporating Asynchrony in the PRAM Model," </title> <booktitle> Proc 1989 ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <month> June </month> <year> 1989, </year> <pages> pp. 169-178. </pages>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures.
Reference: [CKetc93] <author> Culler, D., R. Karp, D. Patterson, A. Sa--hay, K. Schauser, E. Santos, R. Subramonian, and T. von Eicken, </author> <title> "LogP: Towards a Realistic Model of Parallel Computation," </title> <booktitle> 4th Symp. on Principles and Practice of Parallel Programming, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures. <p> If these constraints are modeled conservatively, the ma chine's local memory and cache capacities are sev-erly underrepresented. An alternative, following 11 This formula is taken from a study of the communication speeds using the Active Message communication proto col <ref> [CKetc93, VCGS92] </ref>. common practice, is to ignoring such problems, hoping that applications will have enough local ity of reference to make use of the full memory sizes. 4.3 Other Computers The hardest common architecture for the PMH to model is a 2-dimensional mesh.
Reference: [FW78] <author> Fortune, S. and J. Wyllie, </author> <title> "Parallelism in Random Access Machines," </title> <booktitle> Proc. ACM STOC, </booktitle> <year> 1978, </year> <pages> pp. 114-118. </pages>
Reference-contexts: The generic model for many message-passing programs could be the Candidate Type Architecture [S86] which features a finite set of processors in a fixed (but unspecified) bounded degree graph. Undoubtedly the simplest generic model of parallel computers is the Parallel Random Access Machine (PRAM) <ref> [FW78] </ref>. There is a growing consensus that this model is too simple. Programs which make interprocessor communication explicit generally perform better than programs written for a PRAM [AS91, LS90, NS92]. A generic model defines a class of specific models. <p> Generally, all modules at a given level of the tree will have the same parameters. The p-processor PRAM model <ref> [FW78] </ref> is the special case of the PMH model with only two levels | a root (representing all of memory) with p children, each having blocksize 1, blockcount some small constant, and transfer time 1.
Reference: [F72] <author> Floyd, R. W., </author> <title> "Permuting Information in Idealized Two-Level Storage," Complexity of Computer Computations, </title> <publisher> Plenum Press, </publisher> <address> New York, </address> <year> 1972, </year> <pages> pp. 105-109. </pages>
Reference-contexts: Similarly, there are numerous models for data movement in a memory hierarchy <ref> [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90] </ref>, and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [FJetc88] <author> Fox, G. M. Johnson, G. Lyzenga, S. Otto, J. Salmon, D. Walker, </author> <title> Solving Problems on Concurrent Processors, Volume I, </title> <publisher> Prentice Hall, </publisher> <address> En-glewood Cliffs, </address> <year> 1988. </year>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93], and a vast literature (see <ref> [FJetc88, L91] </ref>) developing algorithms for different interconnection topologies and parallel architectures. Similarly, there are numerous models for data movement in a memory hierarchy [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90], and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [G89] <author> Gibbons, P., </author> <title> "A More Practical PRAM Model," </title> <booktitle> Proc. SPAA, </booktitle> <year> 1989, </year> <pages> pp. 158-168. </pages>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures.
Reference: [HR92] <author> Heywood, T. and S. Ranka, </author> <title> "A practical Hierarchical Model of Parallel Computation I. The Model," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 16, </volume> <year> 1992, </year> <pages> pp. 212-231. </pages>
Reference-contexts: Leis-erson [L85] gives an interesting justification for the validity of a tree model based on physical considerations. The H-PRAM model <ref> [HR92] </ref> is another model that assumes a tree organization for the processors. Our model differs from these other models by allowing data to be stored in the intermediate nodes of the tree.
Reference: [H91] <author> Hockney, R.W., </author> <title> "A Framework for Benchmark Performance Analysis," </title> <booktitle> Proc. 2nd Euroben Workshop, </booktitle> <month> Sept </month> <year> 1991. </year>
Reference-contexts: First, consider a 2-level PMH model. A natural parameter choice is s = L fl B and t = L. This blocksize s corresponds to Hockney's n 1 , the length for which the overhead due to latency exactly balances the time spent in useful communication <ref> [H91] </ref>. Figure 2 compares the two models; the dotted line is the L-B cost function, and the step function is the cost under the PMH model. 7 The relative error ( cost P MH cost LB cost LB ) is non-negative, it never exceeds 1, and it is asymptotically zero.
Reference: [HK81] <author> Hong, J-W. and H. T. Kung, </author> <title> "I/O Complexity: The Red-Blue Pebble Game," </title> <booktitle> Proc. 13th. Symp. on Theory of Comp., </booktitle> <month> May </month> <year> 1981. </year>
Reference-contexts: Similarly, there are numerous models for data movement in a memory hierarchy <ref> [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90] </ref>, and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [KSR91] <institution> Kendall Square Research Corporation, "KSR1 Principles of Operation," </institution> <month> October, </month> <year> 1991. </year>
Reference-contexts: The machine's hardware can, for instance, perform a parallel-prefix operation on a set of numbers | one on each processor | in perhaps 200 cycles. Our model's prediction is off by about a factor of 10. 4.2 KSR1 Briefly, the KSR1 architecture <ref> [KSR91] </ref> has a two-level hierarchy of rings, a single address space implemented on physically distributed memory, and high-performance RISC processors with large register sets and local caches.
Reference: [LTT89] <author> Lam, T., P. Tiwari, and M. Tompa, </author> <title> "Tradeoffs Between Communication and Space," </title> <booktitle> Proc. 21th Symp. on Theory of Comp., </booktitle> <month> May </month> <year> 1989, </year> <pages> pp. 217-226. </pages>
Reference-contexts: Similarly, there are numerous models for data movement in a memory hierarchy <ref> [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90] </ref>, and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [LCHW93] <author> Larus, J., S. Chandra, M. Hill and D. Wood, "CICO: </author> <title> A Shared-Memory Programming Performance Model," </title> <institution> University of Wisconsin at Madison, </institution> <year> 1993, </year> <note> to appear. </note>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures.
Reference: [L85] <author> Leiserson, C. E., "Fat-trees: </author> <title> Universal Networks for Hardware-efficient Supercomputing," </title> <journal> IEEE Trans. on Computing, </journal> <year> 1985, </year> <pages> pp 892-901. </pages>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures. <p> The Parallel Memory Hierarchy (PMH) model [ACF90, ACS90, ACFS93] studied in this paper models both types of data movement costs within the same framework | a tree of memory modules with processors at the leaves. It is most similar to the Fat Tree model <ref> [L85] </ref>, but differs by having memory and message sizes made explicit. It also differs from others models by allowing simultaneous data transfer at different levels of the memory hierarchy. <p> The use of a tree to model a parallel computer's communication structure is a compromise between the simplicity of the PRAM model, and the accuracy of an arbitrary graph structure. Leis-erson <ref> [L85] </ref> gives an interesting justification for the validity of a tree model based on physical considerations. The H-PRAM model [HR92] is another model that assumes a tree organization for the processors.
Reference: [L91] <author> Leighton, F., </author> <title> Introduction to Parallel Algorithms and Architectures: Networks and Algorithms, </title> <publisher> Morgan-Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93], and a vast literature (see <ref> [FJetc88, L91] </ref>) developing algorithms for different interconnection topologies and parallel architectures. Similarly, there are numerous models for data movement in a memory hierarchy [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90], and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [LS90] <author> Lin, C. and L. Snyder, </author> <title> "A Comparison of Programming Models for Shared Memory Multiprocessors," </title> <booktitle> Proc. ICPP Vol II, </booktitle> <month> August </month> <year> 1990, </year> <pages> pp. pp. 163-170. </pages>
Reference-contexts: Undoubtedly the simplest generic model of parallel computers is the Parallel Random Access Machine (PRAM) [FW78]. There is a growing consensus that this model is too simple. Programs which make interprocessor communication explicit generally perform better than programs written for a PRAM <ref> [AS91, LS90, NS92] </ref>. A generic model defines a class of specific models. A specific model appropriate to a particular computer is obtained by specifying parameters 2 of the generic model.
Reference: [NS92] <author> Ngo, T. and L. Snyder, </author> <title> "On the Influence of Programming Models on Shared Memory Computer Performance," </title> <booktitle> Proc. </booktitle> <address> SHPCC, </address> <year> 1992, </year> <pages> pp. pp. 284-291. </pages>
Reference-contexts: Undoubtedly the simplest generic model of parallel computers is the Parallel Random Access Machine (PRAM) [FW78]. There is a growing consensus that this model is too simple. Programs which make interprocessor communication explicit generally perform better than programs written for a PRAM <ref> [AS91, LS90, NS92] </ref>. A generic model defines a class of specific models. A specific model appropriate to a particular computer is obtained by specifying parameters 2 of the generic model.
Reference: [S86] <author> Snyder, L., </author> <title> "Type Architectures, Shared Memories, and the Corollary of Modest Potential," Annu. </title> <journal> Rev. Comput. Sci. </journal> <volume> 1, </volume> <year> 1986, </year> <pages> pp. 289-317. </pages>
Reference-contexts: Perhaps without being aware of it, programmers write generic programs for some generic model of computation. The generic model behind LAPACK is a sequential computer with a two-level memory hierarchy. The generic model for many message-passing programs could be the Candidate Type Architecture <ref> [S86] </ref> which features a finite set of processors in a fixed (but unspecified) bounded degree graph. Undoubtedly the simplest generic model of parallel computers is the Parallel Random Access Machine (PRAM) [FW78]. There is a growing consensus that this model is too simple. <p> These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures.
Reference: [SLM90] <author> Scott, M., T. LeBlanc, and B. Marsh, </author> <booktitle> "Multi-model Parallel Programming in Psyche," ACM Symp. on Principles and Practice of Parallel Programming, </booktitle> <year> 1990, </year> <pages> pp. 70-78. </pages>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures.
Reference: [TAC92] <author> Thomborson, C., B. Alpern and L. Carter, </author> <title> "Rectilinear Steiner Tree Minimization on a Workstation," </title> <booktitle> DIMACS Workshop on Computational Support For Discrete Mathematics, </booktitle> <month> March </month> <year> 1992, </year> <note> Also IBM RC 17680. </note>
Reference-contexts: Our model differs from these other models by allowing data to be stored in the intermediate nodes of the tree. This allows us to use the same structure to model the memory hierarchy, which in our experience <ref> [AABCH91, TAC92, ACFS93] </ref> is crucially important for developing high-performance programs. 3 Choosing a Specific Model A three-step approach can be used to derive a specific PMH model for a given architecture.
Reference: [V90] <author> Valiant, L. G., </author> <title> "A Bridging Model for Parallel Computation," </title> <journal> CACM, </journal> <month> August </month> <year> 1990, </year> <pages> pp. 103-111. </pages>
Reference-contexts: These costs come in two flavors: interprocessor communication and memory hierarchy traffic (e.g., between registers and cache, or between main memory and disk.) There are numerous models that address the cost of interprocessor communication <ref> [L85, S86, G89, ACS89, CZ89, SLM90, V90, CKetc93, LCHW93] </ref>, and a vast literature (see [FJetc88, L91]) developing algorithms for different interconnection topologies and parallel architectures.
Reference: [VS90] <author> Vitter, J.S. and E.A.M. Shriver, </author> <title> "Optimal Disk I/O with Parallel Block Transfer," </title> <booktitle> Proc. 22th Symp. on Theory of Comp., </booktitle> <month> May </month> <year> 1990. </year>
Reference-contexts: Similarly, there are numerous models for data movement in a memory hierarchy <ref> [F72, HK81, AACS87, ACS87, AV88, LTT89, VS90] </ref>, and many papers show that taking advantage of the memory hierarchy improves performance.
Reference: [VCGS92] <author> Von Eicken, T., D. Culler, S. Goldstein, and K. Schauser, </author> <title> "Active Messages: A Mechanism for Integrated Communication and Computation," </title> <booktitle> Proc. 19th Int'l. Symp. on Computer Architecture, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: If these constraints are modeled conservatively, the ma chine's local memory and cache capacities are sev-erly underrepresented. An alternative, following 11 This formula is taken from a study of the communication speeds using the Active Message communication proto col <ref> [CKetc93, VCGS92] </ref>. common practice, is to ignoring such problems, hoping that applications will have enough local ity of reference to make use of the full memory sizes. 4.3 Other Computers The hardest common architecture for the PMH to model is a 2-dimensional mesh.
References-found: 34

