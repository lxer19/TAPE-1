URL: http://www.isi.edu/sims/minton/papers/ijcai93.ps
Refering-URL: http://www.isi.edu/sims/minton/homepage.html
Root-URL: 
Email: minton@ptolemy.arc.nasa.gov  
Title: An Analytic Learning System for Specializing Heuristics  
Author: Steven Minton S. A. 
Note: U.  
Address: MS 269-2 Moffett Field, CA 94035-1000,  
Affiliation: Sterling Software AI Research Branch NASA Ames Research Center,  
Abstract: This paper describes how meta-level theories are used for analytic learning in Multi-tac. Multi-tac operationalizes generic heuristics for constraint-satisfaction problems, in order to create programs that are tailored to specific problems. For each of its generic heuristics, Multi-tac has a meta-theory specifically designed for operationalizing that heuristic. We present examples of the specialization process and discuss how the theories influence the tractability of the learning process. We also describe an empirical study showing that the specialized programs produced by Multi-tac compare favorably to hand-coded programs.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J.M. Crawford. </author> <title> A theoretical analysis of reasoning by symmetry in first-order logic. </title> <booktitle> In AAAI Workshop on Tractable Reasoning, </booktitle> <year> 1992. </year>
Reference-contexts: To see why this is true, consider that any solution where the node is colored green could be transformed into a solution where the node is colored red merely by interchanging the labels green and red on all nodes. This is an example of reasoning by symmetry <ref> [ 5; 1 ] </ref> . In the general case, we will consider symmetries where two values Val1 and Val2 are swapped, such that all the variables that are assigned Val1 are re-assigned Val2, and vice versa.
Reference: [2] <author> T. </author> <title> Ellman. Abstraction via approximate symmetry. </title> <booktitle> In IJCAI Proceedings, </booktitle> <year> 1993. </year>
Reference-contexts: This approach enables the system to be completely autonomous, in contrast to transformational systems that require the user to direct the transformational process. Nevertheless, the approach we employ for representing and reasoning about constraints could also be employed in a transformational system. Recently, Ellman <ref> [ 2 ] </ref> and Yoshikawa and Wada [ 16 ] have proposed new methods for improving CSP search. In the future we hope to incorporate these into Multi-tac, giving it a broader range of possible optimizations. 7 Conclusion This paper has advocated the use of meta-level theories for analytic learning.
Reference: [3] <author> O. Etzioni. </author> <title> A Structural Theory of Explanation-Based Learning. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon, </institution> <year> 1990. </year>
Reference-contexts: the heuristic. (For some heuristics there are several meta-theories, each one representing a different tactic for operationalizing the heuristic.) The specialization method is very similar to the EBS method used in Prodigy/ebl [ 9 ] , except that the entire set of possible specializations is generated (as in Etzioni's Static <ref> [ 3 ] </ref> ), rather than using an example to guide the specialization process. As discussed in section 6, the meta-theories are designed so that the set of possible specializations is not prohibitively large. <p> efficiency and robustness will both improve. (See [ 8 ] for a complete description of these experiments, as well as followup experiments.) 6 Discussion: Tractability of Analysis Multi-tac's approach to generating control knowledge is motivated in part by the Prodigy/ebl system [ 9 ] and Etzioni's subsequent work with Static <ref> [ 3 ] </ref> . Like Prodigy/ebl, Multi-tac produces control knowledge by specializing meta-level concepts. However, Prodigy's EBL module generates explanations from "first principles" in the following sense: the meta-theories used to explain the examples are essentially descriptions of the problem solver that are interpreted during the explanation process.
Reference: [4] <author> O. Etzioni and S. Minton. </author> <title> Why ebl produces overly-specific knowledge: A critique of the prodigy approaches. </title> <booktitle> In Machine Learning Conference Proceedings, </booktitle> <year> 1992. </year>
Reference-contexts: Indeed, our previous experience with Prodigy/ebl and Static indicates that we are much more likely to be successful if the analyses are simple. As discussed by Etzioni and Minton <ref> [ 4 ] </ref> , as the proofs become more complex, EBL is more likely to generate specializations that are overspecific in that they include irrelevant conditions.
Reference: [5] <author> E.C. Freuder. </author> <title> Eliminating interchangeable values in constraint satisfaction. </title> <booktitle> In AAAI Proceedings, </booktitle> <year> 1991. </year>
Reference-contexts: To see why this is true, consider that any solution where the node is colored green could be transformed into a solution where the node is colored red merely by interchanging the labels green and red on all nodes. This is an example of reasoning by symmetry <ref> [ 5; 1 ] </ref> . In the general case, we will consider symmetries where two values Val1 and Val2 are swapped, such that all the variables that are assigned Val1 are re-assigned Val2, and vice versa.
Reference: [6] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability. W.H. </title> <publisher> Freeman and Co., </publisher> <year> 1979. </year>
Reference-contexts: While all NP-complete problems can be reduced to a single problem type, such as Satisfiability, and then solved by some heuristic algorithm, this is generally a poor approach since the relative utility of many heuristics is problem-dependent <ref> [ 6 ] </ref> . Instead, one typically writes a program specifically for the problem at hand by modifying some "off-the-shelf" algorithm and adding appropriate heuristics. Although NP-complete problems are intractable in the worst case, relatively efficient programs can often be designed for specific applications. <p> A more interesting question is how the system performs on problems that are unfamiliar to the author and other project members. In order to gauge the system's current effectiveness, we selected two problems from the book "Computers and Intractability" <ref> [ 6 ] </ref> , Minimal Maximal Matching and K-Closure. These problems could be easily expressed in Multi-tac's language and, in addition, they appeared amenable to a backtracking approach (based on a cursory examination).
Reference: [7] <author> V. Kumar. </author> <title> Algorithms for constraint satisfaction problems. </title> <journal> AI Magazine, </journal> <volume> 13, </volume> <year> 1992. </year>
Reference-contexts: Currently only the backtracking strategy is implemented, so the remainder of the paper assumes a backtracking search. As in the standard CSP backtracking search <ref> [ 7 ] </ref> , the system selects a variable and then chooses a value for that variable. Backtracking occurs when all values for a variable fail to satisfy the constraints. <p> A system configuration consists of a combination of control rules and a variety of flag settings controlling other heuristic mechanisms (e.g., a flag indicates whether or not to use forward checking <ref> [ 7 ] </ref> ). The system carries out a utility evaluation process in which it searches for the most effective system configuration using a hill-climbing search.
Reference: [8] <author> S. Minton. </author> <title> Integrating heuristics for constraint satisfaction problems: A case study. </title> <booktitle> In AAAI Proceedings, </booktitle> <year> 1993. </year>
Reference-contexts: Thus, while the results indicate the potential of our approach, a more thorough evaluation must eventually be carried out. Of course, Multi-tac is still under development and with further work its efficiency and robustness will both improve. (See <ref> [ 8 ] </ref> for a complete description of these experiments, as well as followup experiments.) 6 Discussion: Tractability of Analysis Multi-tac's approach to generating control knowledge is motivated in part by the Prodigy/ebl system [ 9 ] and Etzioni's subsequent work with Static [ 3 ] .
Reference: [9] <author> S. Minton, J.G. Carbonell, C.A. Knoblock, D.R. Kuokka, O. Etzioni, and Y. Gil. </author> <title> Explanation-based learning: A problem solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40 </volume> <pages> 63-118, </pages> <year> 1989. </year>
Reference-contexts: This paper focuses on the knowledge that Multi-tac uses in order to operationalize generic heuristics, and how this approach differs from previous work in "analytic" (or knowledge-based) speed-up learning. Previous analytic speed-up methods, such as EBL, chunking, and derivational analogy, have been used primarily for caching problem-solving experience <ref> [ 9 ] </ref> . Typical EBL systems, for example, learn from problem-solving successes and/or failures by caching a knowledge structure summarizing the experience (e.g., a chunk) and then reusing that knowledge during subsequent problem solving. <p> Several analytic approaches have been used for speed-up learning, in which the goal is to improve problem-solving efficiency. For example, one approach is to apply EBL to generate possible search control rules <ref> [ 9 ] </ref> . These rules serve as "hypotheses" which are tested by evaluating their utility on a set of problem instances. We will use EBL to illustrate our argument here, although a variety of analytic approaches have been employed for speed-up learning. <p> This process involves incorporating information that is not normally used by the base-level problem solver. Although some forms of meta-reasoning have been employed in previous EBL systems (e.g., learning from goal-interactions <ref> [ 9 ] </ref> ) this approach remains largely unexplored. Meta-level analysis is particularly appropriate when the base-level theory is intractable and there is no obvious skew in the distribution of solutions. For example, consider an NP-hard problem such as scheduling or time-tabling. <p> The key lies in specializing those heuristics to a given problem and then selecting the most useful combination. As in the EBL paradigm <ref> [ 9 ] </ref> , the learning process requires a target concept and a theory describing the target concept. The result is a specialization of the target concept (i.e., a sufficient condition for the target concept). In Multi-tac each generic heuristic, such as Least-Constraining-Value-First, is a target concept. <p> To specialize the heuristic, we use a meta-theory which describes the heuristic. (For some heuristics there are several meta-theories, each one representing a different tactic for operationalizing the heuristic.) The specialization method is very similar to the EBS method used in Prodigy/ebl <ref> [ 9 ] </ref> , except that the entire set of possible specializations is generated (as in Etzioni's Static [ 3 ] ), rather than using an example to guide the specialization process. <p> is still under development and with further work its efficiency and robustness will both improve. (See [ 8 ] for a complete description of these experiments, as well as followup experiments.) 6 Discussion: Tractability of Analysis Multi-tac's approach to generating control knowledge is motivated in part by the Prodigy/ebl system <ref> [ 9 ] </ref> and Etzioni's subsequent work with Static [ 3 ] . Like Prodigy/ebl, Multi-tac produces control knowledge by specializing meta-level concepts.
Reference: [10] <author> S. Minton, M. Johnston, A.B. Philips, and P. Laird. </author> <title> Solving large scale constraint satisfaction and scheduling problems using a heuristic repair method. </title> <booktitle> In Proceedings AAAI-90, </booktitle> <year> 1990. </year>
Reference-contexts: The program synthesis process employed by Multi-tac is hierarchically organized. At the top level, the system chooses one of a set of generic constraint satisfaction search algorithms, including backtracking and iterative repair <ref> [ 10 ] </ref> . Currently only the backtracking strategy is implemented, so the remainder of the paper assumes a backtracking search. As in the standard CSP backtracking search [ 7 ] , the system selects a variable and then chooses a value for that variable.
Reference: [11] <author> J. Mostow. </author> <title> Machine transformation of advice into a heuristic search procedure. </title> <booktitle> In Machine Learning, An Artificial Intelligence Approach. </booktitle> <publisher> Tioga Press, </publisher> <year> 1983. </year>
Reference-contexts: 1 Introduction Multi-tac (Multi-Tactic Analytic Compiler) is a learning system for constraint-satisfaction problems (CSPs). The system operationalizes generic heuristics <ref> [ 11 ] </ref> , producing problem-specific versions of these heuristics, and then attempts to find the most useful combination of these heuristics on a set of training problems.
Reference: [12] <author> J. Mostow. </author> <title> A transformational approach to knowledge compilation. In M.R. </title> <editor> Lowry and R.D. McCart-ney, editors, </editor> <title> Automating Software Design. </title> <publisher> AAAI Press, </publisher> <year> 1991. </year>
Reference-contexts: One possibility is to start with intractable theories and to incrementally refine them. Multi-tac bears some resemblance to automatic programming systems that refine a high-level specification by applying correctness-preserving transformations. We were motivated particularly by Smith's Kids system [ 13 ] and related work on knowledge compilation (e.g., <ref> [ 12; 14 ] </ref> ). Our approach is primarily distinguished from these systems by the use of machine learning, in that we generate alternative search control rules and then test them on examples.
Reference: [13] <author> D.R. Smith. KIDS: </author> <title> A knowledge-based software development system. In M.R. </title> <editor> Lowry and R.D. McCartney, editors, </editor> <title> Automating Software Design. </title> <publisher> AAAI Press, </publisher> <year> 1991. </year>
Reference-contexts: During this search, the system evaluates the utility of a given configuration by compiling a Lisp program that implements the configuration, and then "experimenting" with the program by running it on a set of instances. (The compilation process also includes a variety of additional optimization techniques, such a finite differencing <ref> [ 13 ] </ref> and constraint simplification). The learning process impacts the efficiency of the target code in two ways. First, the generic heuristics are re-expressed as problem-specific rules. Second, the utility evaluation process searches for a combination of these heuristics that yields the best overall performance. <p> In the future, we hope to address this issue. One possibility is to start with intractable theories and to incrementally refine them. Multi-tac bears some resemblance to automatic programming systems that refine a high-level specification by applying correctness-preserving transformations. We were motivated particularly by Smith's Kids system <ref> [ 13 ] </ref> and related work on knowledge compilation (e.g., [ 12; 14 ] ). Our approach is primarily distinguished from these systems by the use of machine learning, in that we generate alternative search control rules and then test them on examples.
Reference: [14] <author> C. Tong. </author> <title> A divide and conquer approach to knowledge compilation. In M.R. </title> <editor> Lowry and R.D. McCart-ney, editors, </editor> <title> Automating Software Design. </title> <publisher> AAAI Press, </publisher> <year> 1991. </year>
Reference-contexts: One possibility is to start with intractable theories and to incrementally refine them. Multi-tac bears some resemblance to automatic programming systems that refine a high-level specification by applying correctness-preserving transformations. We were motivated particularly by Smith's Kids system [ 13 ] and related work on knowledge compilation (e.g., <ref> [ 12; 14 ] </ref> ). Our approach is primarily distinguished from these systems by the use of machine learning, in that we generate alternative search control rules and then test them on examples.
Reference: [15] <author> J.S. Turner. </author> <title> Almost all k-colorable graphs are easy to color. </title> <journal> Journal of Algorithms, </journal> <volume> 9 </volume> <pages> 63-82, </pages> <year> 1988. </year>
Reference-contexts: Although NP-complete problems are intractable in the worst case, relatively efficient programs can often be designed for specific applications. Indeed, for certain NP-complete problems, such as graph-coloring, simple heuristic methods can produce solutions in polynomial time with high probability even for "random" distributions <ref> [ 15 ] </ref> . In this paper, we adopt the standard terminology of computer science and use the term "problem" to refer to a generic problem class and "instance" to refer to a particular problem instance. <p> For example, on graph coloring, Multi-tac1.0 synthesizes the well-known "Brelaz" algorithm <ref> [ 15 ] </ref> . However, this is not very surprising since the author's previous familiarity with this algorithm influenced the design of Multi-tac. A more interesting question is how the system performs on problems that are unfamiliar to the author and other project members.
Reference: [16] <author> M. Yoshikawa and S. Wada. </author> <title> Constraint satisfaction with multi-dimensional domain. </title> <booktitle> In The First International Conference on Planning Systems, </booktitle> <year> 1992. </year>
Reference-contexts: Nevertheless, the approach we employ for representing and reasoning about constraints could also be employed in a transformational system. Recently, Ellman [ 2 ] and Yoshikawa and Wada <ref> [ 16 ] </ref> have proposed new methods for improving CSP search. In the future we hope to incorporate these into Multi-tac, giving it a broader range of possible optimizations. 7 Conclusion This paper has advocated the use of meta-level theories for analytic learning.
References-found: 16

