URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1992/Saad-ILQ.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1992/
Root-URL: http://www.cs.umn.edu
Title: Preconditioning techniques for nonsymmetric indefinite linear systems  
Author: Youcef Saad 
Note: A number of experiments are reported to compare these methods.  
Date: December 29, 1992  
Address: Urbana, Illinois 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at Urbana-Champaign  
Abstract: The standard preconditioning techniques for conjugate gradient methods often fail for matrices that are indefinite and/or strongly nonsymmetric. The most common alternatives considered for these cases are either to use expensive direct solvers or to resort to one of many techniques based on the normal equations. This paper examines several such alternatives and compares them. In particular an incomplete LQ factorization is proposed and some of its implementation details are described. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. C. Anderson and Y. Saad. </author> <title> Solving sparse triangular systems on parallel computers. </title> <journal> International Journal of High Speed Computing, </journal> <volume> 1 </volume> <pages> 73-96, </pages> <year> 1989. </year>
Reference-contexts: This question is identical with that of reordering a general sparse matrix by levels such that during the L-U solve phases in Preconditioned conjugate gradient methods, several unknowns can be solved for simultaneously <ref> [1] </ref>. The same technique can be used but it relies on an arbitrary choice of the first unknown. The problem of determining the best first element, i.e., the one that yields the smallest number of blocks k is a hard problem.
Reference: [2] <author> A. Bjork. </author> <title> Least Squares Methods. </title> <address> Elsevier/North-Holland, New-York, </address> <year> 1988. </year> <title> Handbook for Numerical Analysis Series, </title> <editor> P. G. Ciarlet, J. L. </editor> <booktitle> Lions eds. </booktitle>
Reference-contexts: When discretizing this equation we obtain a symmetric linear system that is often not positive definite. Another important example is that of least squares problems with constraints <ref> [2] </ref>. Most important, is the fact that in practice, many linear systems that arise in the course of a Newton type iteration may occasionally be indefinite to some degree, during the process.
Reference: [3] <author> A. Bjork and T. Elfving. </author> <title> Accelerated projection methods for computing pseudo-inverse solutions of systems of linear equations. </title> <journal> BIT, </journal> <volume> 19 </volume> <pages> 145-163, </pages> <year> 1979. </year>
Reference-contexts: quit. 4 CG/SSOR on the normal equations. 4.1 SSOR/NE for general sparse matrices In this section we will briefly discuss simple implementations of relaxation methods applied to the normal equations of the form A T Ax = A T b (17) AA T y = b: (18) Bjork and Elfving <ref> [3] </ref> have shown that in order to use relaxation schemes on the normal equations, one only needs to access one column A at a time for (17) and a row at a time for (18). For completeness we now explain how this can be achieved for (18) for example.
Reference: [4] <author> I. S. Duff, A. M. Erisman, and J. K. Reid. </author> <title> Direct Methods for Sparse Matrices. </title> <publisher> Clarendon Press, Oxford, </publisher> <year> 1986. </year>
Reference-contexts: Clearly, there are problems where direct methods will always be preferred, such as narrow banded systems or systems whose matrix has a graph that is close to that of a tree <ref> [4] </ref>. For a large class of problems, namely all those originating from three-dimensional Partial Differential Equations, iterative solvers may be far more effective than direct solvers. <p> We should mention that the idea of incomplete factorization based on a dropping strategy by magnitude rather than position is not new. For example Harwell's MA28 <ref> [4] </ref> includes an option to this effect and so does Zlatev's Y12M [13]. These codes incorporate a dropping tolerance strategy whereby elements whose magnitude fall below a certain tolerance factor are dropped as soon as they are generated.
Reference: [5] <author> H. C. Elman. </author> <title> Iterative Methods for Large Sparse Nonsymmetric Systems of Linear Equations. </title> <type> PhD thesis, </type> <institution> Yale University, Computer Science Dept., </institution> <address> New Haven, CT., </address> <year> 1982. </year>
Reference-contexts: If we denote this operator by Q 1 , then the usual conjugate gradient method applied to (18), sometimes referred to as Craig's method, with left preconditioning Q can be recast in the form <ref> [5] </ref>. Algorithm ?: CGNE/SSOR/ Left preconditioning 1. Start: Compute r 0 = b Ax 0 , z 0 = Q 1 r 0 , p 0 = A T z 0 . 2. Iterate. <p> The ILQ technique is a promising alternative to the standard ILU or to direct 15 solvers. Despite their poor reputation in handling most definite problems, the methods that are based on the normal equations seem to be quite useful for indefinite problems. As was already observed <ref> [5, 8] </ref>, normal equation approaches can be more effective than other approaches based on the direct equations. The best illustration of this fact is when the original matrix is orthogonal. Then its spectrum is ... 16
Reference: [6] <author> H. C. Elman. </author> <title> A stability analysis of incomplete LU factorizations. </title> <journal> Math. Comp., </journal> <volume> 47 </volume> <pages> 191-217, </pages> <year> 1986. </year>
Reference-contexts: On the other hand, when the original matrix is not diagonally dominant, L 1 or U 1 may have very large norms, thus causing the error L 1 EU 1 to have arbitrarily large eigenvalues. This form of unstabilty has been studied by Elman <ref> [6] </ref> who proposed a detailed analysis of ILU and MILU preconditioners. We also observed experimentally that ILU preconditioners can be very poor when L 1 or U 1 are large, and that this situation often occurs for indefinite problems, and for problems with large nonsymmetric parts.
Reference: [7] <author> C. I. Goldstein and E. Turkel. </author> <title> An iterative method for the Helmholtz equation. </title> <journal> Journal of Computational Physics, </journal> <volume> 49 </volume> <pages> 443-457, </pages> <year> 1983. </year>
Reference-contexts: Indefinite problems arise in many areas of scientific computing, one of the best known examples being perhaps the one arising from the Helmhotz equation u+k 2 (x; y)u = f , which occurs in different forms in various models of wave propagation <ref> [7] </ref>. When discretizing this equation we obtain a symmetric linear system that is often not positive definite. Another important example is that of least squares problems with constraints [2].
Reference: [8] <author> C. Kamath and A. Sameh. </author> <title> A projection method for solving nonsymmetric linear systems on multiprocessors. </title> <type> Technical Report 611, </type> <institution> CSRD, university of Illinois, Urbana, IL, </institution> <year> 1986. </year>
Reference-contexts: When the matrix is issued from an elliptic partial differential equation, one can easily reorder the unknowns so that the matrix A is block tridiagonal. This fact has been exploited by Kamath and Sameh <ref> [8] </ref> to devise a parallel scheme by grouping rows such that several simultaneous relaxation steps can be performed in parallel, see Section 4.3 for more details. 4.2 Implementations of SSOR/NE Preconditionings There are several ways of exploiting the relaxation schemes as preconditioners to conjugate gradient methods applied to either (17) or <p> The question that arises is how to find the partition S i . In certain simple cases, such as block-tridiagonal matrices this can be easily done <ref> [8] </ref>. For general sparse matrices, it is important to think in terms of the symmetric squared matrix AA T and the problem is to find a reordering of this matrix such that it has diagonal diagonal blocks. <p> The ILQ technique is a promising alternative to the standard ILU or to direct 15 solvers. Despite their poor reputation in handling most definite problems, the methods that are based on the normal equations seem to be quite useful for indefinite problems. As was already observed <ref> [5, 8] </ref>, normal equation approaches can be more effective than other approaches based on the direct equations. The best illustration of this fact is when the original matrix is orthogonal. Then its spectrum is ... 16
Reference: [9] <author> C. C. Paige and M. A. Saunders. </author> <title> An algorithm for sparse linear equations and sparse least squares. </title> <journal> ACM Trans. Math. Software, </journal> <volume> 8 </volume> <pages> 43-71, </pages> <year> 1982. </year>
Reference-contexts: The other options are obviously to use the normal equations (18) with again three different ways of preconditioning. Therefore, there are at least obvious six different algorithms. Moreover, one can also implement more robust algorithms such the LSQR technique <ref> [9] </ref>. We expect to see little differences for problems that are reasonably well conditioned (after preconditionings) between all these different options. For problems that are very poorly conditioned, the LSQR option may perform better [9]. 4.3 Parallel implementations As was mentioned before, it is possible in some well-known cases to reorder <p> Moreover, one can also implement more robust algorithms such the LSQR technique <ref> [9] </ref>. We expect to see little differences for problems that are reasonably well conditioned (after preconditionings) between all these different options. For problems that are very poorly conditioned, the LSQR option may perform better [9]. 4.3 Parallel implementations As was mentioned before, it is possible in some well-known cases to reorder the unknowns such that the matrix B = AA T (resp. B = A T A ) has diagonal blocks that are diagonal matrices.
Reference: [10] <author> Y. Saad and M. H. Schultz. </author> <title> GMRES: a generalized minimal residual algorithm for solving nonsymmetric linear systems. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 7 </volume> <pages> 856-869, </pages> <year> 1986. </year>
Reference-contexts: Method 2: CGNE/IC (0). Conjugate gradient method applied to the normal equations with Incomplete Choleski preconditioner. Method 3: GMRES/ILU (0). GMRES <ref> [10] </ref> applied to original system with ILU (0) preconditioning from the right, i.e., GMRES applied to AM 1 y = f . To test the pre-conditioner rather that the iterative solver (GMRES) we took in all tests the number of directions in GMRES to be 10. Method 4: GMRES/ILUP.
Reference: [11] <author> R. S. Varga. </author> <title> Matrix Iterative Analysis. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1962. </year>
Reference-contexts: If nothing in particular is known about the matrix AA T all that can be said is that the method will converge for any ! lying strictly between 0 and 2 <ref> [11] </ref> because the matrix is positive definite. Moreover, another question not addressed here is how can convergence be affected by various reorderings of the rows. When the matrix is issued from an elliptic partial differential equation, one can easily reorder the unknowns so that the matrix A is block tridiagonal.
Reference: [12] <author> J. W. Watts-III. </author> <title> A conjugate gradient truncated direct method for the iterative solution of the reservoir simulation pressure equation. </title> <journal> Society of Petroleum Engineer Journal, </journal> <volume> 21 </volume> <pages> 345-353, </pages> <year> 1981. </year>
Reference-contexts: By the nature of the algorithm adopted, it is the latest fill ins that are dropped from L. This resembles the level of fill-in strategy often used to generalize the ICCG (p) techniques to general matrices <ref> [12] </ref>. Unfortunately, even with this implementation, the occurrence of zero rows is not uncommon.
Reference: [13] <author> Z. Zlatev. </author> <title> Use of iterative refinement in the solution of sparse linear systems. </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 19 </volume> <pages> 381-399, </pages> <year> 1982. </year> <month> 17 </month>
Reference-contexts: We should mention that the idea of incomplete factorization based on a dropping strategy by magnitude rather than position is not new. For example Harwell's MA28 [4] includes an option to this effect and so does Zlatev's Y12M <ref> [13] </ref>. These codes incorporate a dropping tolerance strategy whereby elements whose magnitude fall below a certain tolerance factor are dropped as soon as they are generated.
References-found: 13

