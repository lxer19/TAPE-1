URL: http://www.cs.utexas.edu/users/skumar/reports/drqrouting.ps
Refering-URL: http://www.cs.utexas.edu/users/skumar/reports.html
Root-URL: 
Email: skumar@pine.ece.utexas.edu risto@cs.utexas.edu  
Title: DUAL REINFORCEMENT Q-ROUTING: AN ON-LINE ADAPTIVE ROUTING ALGORITHM 1  
Author: Shailesh Kumar Risto Miikkulainen 
Address: Austin, TX 78712 Austin, TX 78712  
Affiliation: The University of Texas at Austin The University of Texas at Austin Dept. of Elec. and Comp. Engg. Dept. of Computer Science  
Abstract: This paper describes and evaluates the Dual Reinforcement Q-Routing algorithm (DRQ-Routing) for adaptive packet routing in communication networks. Each node in the network has a routing decision maker that adapts, on-line, to learn routing policies that can sustain high network loads and have low average packet delivery time. These decision makers learn based on the information they get back from their neighboring nodes as they send packets to them (forward exploration similar to Q-Routing) and the information appended to the packets they receive from their neighboring nodes (backward exploration unique to DRQ-Routing). Experiments over several network topologies have shown that at low loads, DRQ-Routing learns the optimal policy more than twice as fast as Q-Routing, and at high loads, it learns routing policies that are more than twice as good as Q-Routing in terms of average packet delivery time. Further, DRQ-Routing is able to sustain higher network loads than Q-Routing and non-adaptive shortest-path routing. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Bellman, R., </author> <year> 1958, </year> <title> "On a Routing Problem," </title> <journal> Quarterly of Applied Mathematics, </journal> <volume> Vol. 16, </volume> <pages> pp. 87-90. </pages>
Reference: <author> Boyan, J. A., Littman, M. L., </author> <year> 1994, </year> <title> "Packet Routing in Dynamically Changing Networks: A Reinforcement Learning Approach," </title> <editor> In Cowan, J., Tesauro, G., Alspector, J., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 6. </booktitle> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Choi, S. P. M., Yeung, D.-Y., </author> <year> 1996, </year> <title> "Predictive Q-Routing: A Memory-based Reinforcement Learning Approach to Adaptive Traffic Control," </title> <editor> In Touretzky, D. S., Mozer, M. C., Hasselmo, M. E., editors, </editor> <booktitle> Advances in Neural Information Processing Systems 8, </booktitle> <pages> pp. 945-951. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: <author> Goetz, P., Kumar, S., Miikkulainen, R., </author> <year> 1996, </year> <title> "On-Line Adaptation of a Signal Predistorter through Dual Reinforcement Learning," </title> <booktitle> Proc. Machine Learning: Proceedings of the 13th Annual Conference (Bari, </booktitle> <address> Italy). </address>
Reference: <author> Littman, M., Boyan, J. A., </author> <year> 1993, </year> <title> "A Distributed Reinforcement Learning Scheme for Network Routing," </title> <booktitle> Proc. Proceedings of the First Internation Workshop on Applications of Neural Networks to Telecommunications, </booktitle> <address> Hillside, New Jersy, </address> <pages> pp. 45-51. </pages> <publisher> Erlbaum. </publisher>
Reference: <author> Tanenbaum, A., </author> <year> 1989, </year> <title> Computer Networks Prentice Hall, </title> <note> second edition. </note>
Reference: <author> Thrun, S. B., </author> <year> 1992, </year> <title> "The Role of Exploration in Learning Control," In White, </title> <editor> D. A., Sofge, D. A., editors, </editor> <title> Handbook of Intelligent Control: Neural, Fuzzy, and Adaptive Approaches. </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York. </address>
Reference: <author> Watkins, C. J. C. H., </author> <year> 1989, </year> <title> "Learning from Delayed Rewards," </title> <type> Ph.D. thesis, </type> <institution> University of Cambridge, </institution> <address> England. </address>
References-found: 8

