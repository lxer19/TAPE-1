URL: ftp://ftp.research.microsoft.com/pub/debull/mar98-letdraft.ps
Refering-URL: http://www.research.microsoft.com/research/db/debull/issues-list.htm
Root-URL: http://www.research.microsoft.com
Title: Special Issue on Mining of Large Datasets  Mining Databases: Towards Algorithms for Knowledge Discovery  
Author: TC Chair Betty Salzberg Claudio Bettini, X. Sean Wang, and Sushil Jajodia 
Note: Bulletin of the Technical Committee on Data Engineering March 1998 Vol. 21 No. 1 IEEE Computer Society Letters Letter from the new  1 Letter from the Editor-in-Chief David Lomet 2  Usama Fayyad 39 Announcements and Notices Work Activities Coordination and Collaboration WACC'99 back cover  
Abstract: Letter from the Special Issue Editor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Daniel Barbara 3 Data Mining and Database Systems: Where is the Intersection? . . . . . . . . . . . . . . . . . . . . . . . . Surajit Chaudhuri 4 Clustering Data Without Distance Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . G.D. Ramkumar and Arun Swami 9 Hypergraph Based Clustering in High-Dimensional Data Sets: A Summary of Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Eui-Hong Han, George Karypis, Vipin Kumar, and Bamshad Mobasher 15 Mining large itemsets for association rules . . . . . . . . . . . . . . . . . . . . . . . . . . Charu C. Aggarwal and Philip S. Yu 23 Mining Temporal Relationships with Multiple Granularities in Time Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Agrawal R. et. al. </editor> <booktitle> Fast Dicovery of Association Rules, </booktitle> <pages> pp. </pages> <note> 307-328 in [5]. </note>
Reference-contexts: This is an area we have been leveraging. Nonetheless, we have to guard against the following dangers when we consider scalable implementations: * Restricting choice of data mining tasks: While there has been an impressive amount of work related to association rules (see <ref> [1] </ref> for an overview) and their generalizations. Relatively less work has been done in the context of other classical data analysis technique, e.g., clustering, classification. * Scaling specific algorithms: There are literally many variants of classification or clustering algorithms. The specific choice of an algorithm will depend on an application.
Reference: [2] <author> Meo R., P. Giuseppe, Ceri S., </author> <title> A new SQL-like Operator for Mining Association Rules, </title> <booktitle> in Proc. of VLDB96, </booktitle> <pages> pp. 122-133, </pages> <address> Mumbai, India. </address>
Reference-contexts: However, for the set of primitives in this class to be useful, it is important that the operations be unbundled so that they may be shared. This issue is best illustrated through a recent SQL extension that has been proposed for association rules <ref> [2] </ref>. In that proposal, an extension is proposed to generate association rules. However, note that an alternative would have been to consider specifying frequent itemsets instead. An association rule can be derived easily with frequent itemsets as the primitive.
Reference: [3] <author> Chaudhuri S., Dayal U. </author> <title> An Overview of Datawarehousing and OLAP Technology, </title> <booktitle> in Sigmod Record, </booktitle> <month> March </month> <year> 1997. </year>
Reference-contexts: OLAP takes an important first step at the problem by allowing us to view data multidimensionally as a giant spreadsheet with sophisticated visual tools to browse and query the data (See <ref> [3] </ref> for a survey). Data Mining promises a giant leap over OLAP where instead of a power OLAP user navigating data, the mining tools will automatically discover interesting patterns.
Reference: [4] <author> Chaudhuri S., Fayyad U., Bernhardt J. </author> <title> Scalable Classifier over SQL Databases, </title> <note> in preparation. </note>
Reference-contexts: Therefore, any decision tree classifier can be minimally modified so that whenever counting or partitioning steps are needed, the classifier uses an interface to invoke a generic middleware that optimizes scalable implementations of those operations by leveraging the way most decision tree classifiers grow a tree <ref> [4] </ref>. <p> This count and split cycle is repeated until no new partitions are possible. 6 Recently, we built a scalable classifier <ref> [4] </ref> at Microsoft Research. Our approach exemplifies one of the several ways in which the problem of building SQL-aware systems may be approached. We started with a classical main-memory implementation of a decision tree classifier and Microsoft SQL Server. We augmented this set-up with a middleware to enhance performance. <p> Although the above seems too obvious to mention, there are few implementations of data mining algorithms today that take advantage of these functionality. The goal of harnessing the above functionality often lead to novel ways of staging computation. In <ref> [4] </ref>, we discuss how we can batch servicing multiple active nodes (i.e., nodes that are still being grown) of a scalable decision tree classification algorithm and exploit data structures in the database server. 4.2 SQL Extensions As we implement mining algorithms that generate SQL efficiently, we also will identify primitives that <p> While there has been substantial past research in this area, implementation issues related to processing sampling along with other relational operators continue to be an active area. In our recent work on building scalable classification algorithms over SQL subsystems <ref> [4] </ref>, we recognized that there is strong performance incentive to do batch aggregation. Intuitively, batch aggregation helps fully leverage a single data scan by evaluating multiple aggregation over the same data (or, query).
Reference: [5] <editor> Fayyad U. et. al. </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, </booktitle> <publisher> MIT Press, </publisher> <year> 1996. </year>
Reference-contexts: Examples of well-known techniques include decision-tree classification, clustering (see <ref> [5] </ref> for an overview of known techniques). Innovating in this space requires establishing statistical merit of a proposed technique and appears to have little interaction with database system issues. On a more pragmatic note, we seem to have a large number of established techniques in this space. Copyright 1998 IEEE.
Reference: [6] <author> Gray et al. </author> <title> Data Cube: A Relational Aggregation Operator Generalizing Group-By, Cross-Tab, and Sub Totals,in Data Mining and Knowledge Discovery, </title> <booktitle> 1(1), </booktitle> <pages> pp. 29-53, </pages> <year> 1997. </year>
Reference-contexts: Once again, we can draw similarities with the OLAP world. Generation of SQL queries against the backend clearly benefits from the CUBE construct <ref> [6] </ref>. We can identify two goals for studying possible extensions to SQL, extensions that: 1. strongly interact with core SQL primitives and can result in significant performance improvement. 2. encapsulate a set of useful data mining primitives. We feel that extensions that belong to (1) are extremely useful. <p> Having the ability to do multi-statement optimization of the above set of related queries and to exploit a single data scan to evaluate them greatly speed up the classification algorithms. Such batch aggregation functionality goes beyond the CUBE operator <ref> [6] </ref>. Both sampling and batch aggregation strongly interact with core SQL primitives and thus with the SQL relational engine implementations.
Reference: [7] <author> Han J. </author> <title> Towards On-Line Analytical Mining in Large Databases,to appear. </title>
Reference-contexts: This allows us to mine an arbitrary query, not necessarily just base data. Thus, it is possible for a power user to use OLAP tools to specify a subset of the data and then to invoke mining tools on that data (cf. <ref> [7] </ref>). Likewise, it is possible to exploit the data reduction capabilities of the data mining tools to identify a subset of data that is interesting and then the OLAP tools can explore the subset of the data using query features.

Reference: [1] <author> R. Agrawal, T. Imilienski, and A. Swami. </author> <title> Mining Association Rules between Sets of Items in Large Databases. </title> <booktitle> Proc. of the ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <pages> pages 207216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: This is an area we have been leveraging. Nonetheless, we have to guard against the following dangers when we consider scalable implementations: * Restricting choice of data mining tasks: While there has been an impressive amount of work related to association rules (see <ref> [1] </ref> for an overview) and their generalizations. Relatively less work has been done in the context of other classical data analysis technique, e.g., clustering, classification. * Scaling specific algorithms: There are literally many variants of classification or clustering algorithms. The specific choice of an algorithm will depend on an application.
Reference: [2] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules. </title> <booktitle> In Proceedings of the 20th VLDB Conference, </booktitle> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference-contexts: However, for the set of primitives in this class to be useful, it is important that the operations be unbundled so that they may be shared. This issue is best illustrated through a recent SQL extension that has been proposed for association rules <ref> [2] </ref>. In that proposal, an extension is proposed to generate association rules. However, note that an alternative would have been to consider specifying frequent itemsets instead. An association rule can be derived easily with frequent itemsets as the primitive.
Reference: [3] <author> E. Han, G. Karypis, V. Kumar, and B. Mobasher. </author> <title> Clustering based on association rule hypergraphs. </title> <booktitle> In Proc. Workshop on Research Issues on Data Mining and Knowledge Discovery, </booktitle> <year> 1997. </year>
Reference-contexts: OLAP takes an important first step at the problem by allowing us to view data multidimensionally as a giant spreadsheet with sophisticated visual tools to browse and query the data (See <ref> [3] </ref> for a survey). Data Mining promises a giant leap over OLAP where instead of a power OLAP user navigating data, the mining tools will automatically discover interesting patterns.
Reference: [4] <author> L. Kaufman and P.J. Rousseeuw. </author> <title> Finding Groups in Data: an Introduction to Cluster Analysis. </title> <publisher> John Wiley & Sons, </publisher> <year> 1990. </year>
Reference-contexts: Therefore, any decision tree classifier can be minimally modified so that whenever counting or partitioning steps are needed, the classifier uses an interface to invoke a generic middleware that optimizes scalable implementations of those operations by leveraging the way most decision tree classifiers grow a tree <ref> [4] </ref>. <p> This count and split cycle is repeated until no new partitions are possible. 6 Recently, we built a scalable classifier <ref> [4] </ref> at Microsoft Research. Our approach exemplifies one of the several ways in which the problem of building SQL-aware systems may be approached. We started with a classical main-memory implementation of a decision tree classifier and Microsoft SQL Server. We augmented this set-up with a middleware to enhance performance. <p> Although the above seems too obvious to mention, there are few implementations of data mining algorithms today that take advantage of these functionality. The goal of harnessing the above functionality often lead to novel ways of staging computation. In <ref> [4] </ref>, we discuss how we can batch servicing multiple active nodes (i.e., nodes that are still being grown) of a scalable decision tree classification algorithm and exploit data structures in the database server. 4.2 SQL Extensions As we implement mining algorithms that generate SQL efficiently, we also will identify primitives that <p> While there has been substantial past research in this area, implementation issues related to processing sampling along with other relational operators continue to be an active area. In our recent work on building scalable classification algorithms over SQL subsystems <ref> [4] </ref>, we recognized that there is strong performance incentive to do batch aggregation. Intuitively, batch aggregation helps fully leverage a single data scan by evaluating multiple aggregation over the same data (or, query).
Reference: [5] <author> R. Motwani and P. Raghavan. </author> <title> Randomized Algorithms. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1995. </year>
Reference-contexts: Examples of well-known techniques include decision-tree classification, clustering (see <ref> [5] </ref> for an overview of known techniques). Innovating in this space requires establishing statistical merit of a proposed technique and appears to have little interaction with database system issues. On a more pragmatic note, we seem to have a large number of established techniques in this space. Copyright 1998 IEEE.
Reference: [6] <author> R. T. Ng and Jiawei Han. </author> <title> Efficient and effective clustering methods for spatial data mining. </title> <booktitle> Proc. of the Int'l Conf. on Very Large Data Bases (VLDB), </booktitle> <year> 1994. </year>
Reference-contexts: Once again, we can draw similarities with the OLAP world. Generation of SQL queries against the backend clearly benefits from the CUBE construct <ref> [6] </ref>. We can identify two goals for studying possible extensions to SQL, extensions that: 1. strongly interact with core SQL primitives and can result in significant performance improvement. 2. encapsulate a set of useful data mining primitives. We feel that extensions that belong to (1) are extremely useful. <p> Having the ability to do multi-statement optimization of the above set of related queries and to exploit a single data scan to evaluate them greatly speed up the classification algorithms. Such batch aggregation functionality goes beyond the CUBE operator <ref> [6] </ref>. Both sampling and batch aggregation strongly interact with core SQL primitives and thus with the SQL relational engine implementations.
Reference: [7] <author> J. Ross Quinlan. C4.5: </author> <title> Programs for Machine Learning. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: This allows us to mine an arbitrary query, not necessarily just base data. Thus, it is possible for a power user to use OLAP tools to specify a subset of the data and then to invoke mining tools on that data (cf. <ref> [7] </ref>). Likewise, it is possible to exploit the data reduction capabilities of the data mining tools to identify a subset of data that is interesting and then the OLAP tools can explore the subset of the data using query features.
Reference: [8] <author> T. Zhang, R. Ramakrishnan, and M. Linvy. </author> <title> Birch: an efficient data clustering method for large databases. </title> <booktitle> In Proc. of the 1996 ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> Montreal, Quebec, </address> <year> 1996. </year>
Reference-contexts: It is surprising that although scalability of mining algorithms has been an active area of work, few significant pieces of work have looked at the issue of data mining algorithms for SQL systems. A nice study of a SQL-aware scalable implementation of association rules appear in <ref> [8] </ref>. Ad-hoc Mining Today's data mining algorithms are invoked on a materialized disk-resident data set. If data mining were to succeed, data mining must evolve to ad-hoc data mining where the data set which is mined is specified on-the-fly.
Reference: [9] <author> D. Fisher. </author> <title> Improving inference through conceptual clustering. </title> <booktitle> In 1987 AAAI Conference, </booktitle> <pages> pages 461465, </pages> <address> Seattle, Washington, </address> <year> 1987. </year>
Reference: [10] <author> D. Fisher. </author> <title> Optimization and simplification of hierarchical clusterings. </title> <booktitle> In Proc. of the First Int'l Conference on Knowledge Discovery and Data Mining, </booktitle> <pages> pages 118123, </pages> <address> Montreal, Quebec, </address> <year> 1995. </year>

Reference: [AS94] <author> R. Agrawal and R. Srikant. </author> <title> Fast algorithms for mining association rules. </title> <booktitle> In Proc. of the 20th VLDB Conference, </booktitle> <pages> pages 487499, </pages> <address> Santiago, Chile, </address> <year> 1994. </year>
Reference: [BDO95] <author> M.W. Berry, S.T. Dumais, and G.W. O'Brien. </author> <title> Using linear algebra for intelligent information retrieval. </title> <journal> SIAM Review, </journal> <volume> 37:573595, </volume> <year> 1995. </year>
Reference: [Ber76] <author> C. Berge. </author> <title> Graphs and Hypergraphs. </title> <publisher> American Elsevier, </publisher> <year> 1976. </year>
Reference: [BMS97] <author> S. Brin, R. Motwani, and C. Silversteim. </author> <title> Beyond market baskets: Generalizing association rules to correlations. </title> <booktitle> In Proc. of 1997 ACM-SIGMOD Int. Conf. on Management of Data, </booktitle> <address> Tucson, Arizona, </address> <year> 1997. </year>
Reference: [CHY96] <author> M.S. Chen, J. Han, and P.S. Yu. </author> <title> Data mining: An overview from database perspective. </title> <journal> IEEE Transactions on Knowledge and Data Eng., </journal> <volume> 8(6):866883, </volume> <month> December </month> <year> 1996. </year>
Reference: [CS96] <author> P. Cheeseman and J. Stutz. </author> <title> Baysian classification (autoclass): Theory and results. In U.M. </title> <editor> Fayyad, G. Piatetsky-Shapiro, P. Smith, and R. Uthurusamy, editors, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining, </booktitle> <pages> pages 153180. </pages> <publisher> AAAI/MIT Press, </publisher> <year> 1996. </year>
Reference: [Han98] <author> E.H. Han. </author> <title> Knowledge discovery in a large dimensional space using hypergraph models. </title> <type> Technical Report Thesis In Progress, </type> <institution> Department of Computer Science, University of Minnesota, M inneapolis, </institution> <year> 1998. </year>
Reference: [HBG + 98] <author> E.H. Han, D. Boley, M. Gini, R. Gross, K. Hastings, G. Karypis, V. Kumar, B. Mobasher, and J. Moore. We-bace: </author> <title> A web agent for document categorization and exploartion. </title> <booktitle> In Proc. of the 2nd International Conference on Autonomous Agents, </booktitle> <month> May </month> <year> 1998. </year> <month> 21 </month>
Reference: [HHS92] <author> N. Harris, L. Hunter, and D. States. Mega-classification: </author> <title> Discovering motifs in massive datastreams. </title> <booktitle> In Proceedings of the Tenth International Conference on Artificial Intelligence (AAAI), </booktitle> <year> 1992. </year>
Reference: [HKKM97a] <author> E.H. Han, G. Karypis, V. Kumar, and B. Mobasher. </author> <title> Clustering based on association rule hypergraphs (position paper). </title> <booktitle> In Proc. of the Workshop on Research Issues on Data Mining and Knowledge Discovery, </booktitle> <pages> pages 913, </pages> <address> Tucson, Arizona, </address> <year> 1997. </year>
Reference: [HKKM97b] <author> E.H. Han, G. Karypis, V. Kumar, and B. Mobasher. </author> <title> Clustering in a high-dimensional space using hyper-graph models. </title> <type> Technical Report TR-97-063, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, </institution> <year> 1997. </year>
Reference: [Jac91] <author> J. E. Jackson. </author> <title> A User's Guide To Principal Components. </title> <publisher> John Wiley & Sons, </publisher> <year> 1991. </year>
Reference: [JD88] <author> A.K. Jain and R. C. Dubes. </author> <title> Algorithms for Clustering Data. </title> <publisher> Prentice Hall, </publisher> <year> 1988. </year>
Reference: [KAKS97] <author> G. Karypis, R. Aggarwal, V. Kumar, and S. Shekhar. </author> <title> Multilevel hypergraph partitioning: Application in VLSI domain. </title> <booktitle> In Proceedings ACM/IEEE Design Automation Conference, </booktitle> <year> 1997. </year>
Reference: [Kar98] <author> G. Karypis. hMETIS 1.0.0. </author> <note> http://www.cs.umn.edu/~karypis/metis/hmetis/main.html, 1998. </note>
Reference: [MHB + 97] <author> J. Moore, E. Han, D. Boley, M. Gini, R. Gross, K. Hastings, G. Karypis, V. Kumar, and B. Mobasher. </author> <title> Web page categorization and feature selection using association rule and principal component clustering. </title> <booktitle> In 7th Workshop on Information Technologies and Systems, </booktitle> <month> Dec. </month> <year> 1997. </year>

Reference: [1] <author> Aggarwal C. C., and Yu P. S. </author> <title> Online Generation of Association Rules. </title> <booktitle> Proceedings of the International Conference on Data Engineering, </booktitle> <address> Orlando, Florida, </address> <month> February </month> <year> 1998. </year>
Reference-contexts: This is an area we have been leveraging. Nonetheless, we have to guard against the following dangers when we consider scalable implementations: * Restricting choice of data mining tasks: While there has been an impressive amount of work related to association rules (see <ref> [1] </ref> for an overview) and their generalizations. Relatively less work has been done in the context of other classical data analysis technique, e.g., clustering, classification. * Scaling specific algorithms: There are literally many variants of classification or clustering algorithms. The specific choice of an algorithm will depend on an application.
Reference: [2] <author> Aggarwal C. C., Sun Z., and Yu P. S. </author> <title> Generating Profile Association Rules. IBM Research Report, </title> <publisher> RC-21037. </publisher>
Reference-contexts: However, for the set of primitives in this class to be useful, it is important that the operations be unbundled so that they may be shared. This issue is best illustrated through a recent SQL extension that has been proposed for association rules <ref> [2] </ref>. In that proposal, an extension is proposed to generate association rules. However, note that an alternative would have been to consider specifying frequent itemsets instead. An association rule can be derived easily with frequent itemsets as the primitive.
Reference: [3] <author> Aggarwal C. C., and Yu P. S. </author> <title> A new framework for itemset generation. IBM Research Report, </title> <publisher> RC-21064. </publisher>
Reference-contexts: OLAP takes an important first step at the problem by allowing us to view data multidimensionally as a giant spreadsheet with sophisticated visual tools to browse and query the data (See <ref> [3] </ref> for a survey). Data Mining promises a giant leap over OLAP where instead of a power OLAP user navigating data, the mining tools will automatically discover interesting patterns.
Reference: [4] <author> Agrawal R., Imielinski T., and Swami A. </author> <title> Mining association rules between sets of items in very large databases. </title> <booktitle> Proceedings of the ACM SIGMOD Conference on Management of data, </booktitle> <pages> pages 207-216, </pages> <year> 1993. </year>
Reference-contexts: Therefore, any decision tree classifier can be minimally modified so that whenever counting or partitioning steps are needed, the classifier uses an interface to invoke a generic middleware that optimizes scalable implementations of those operations by leveraging the way most decision tree classifiers grow a tree <ref> [4] </ref>. <p> This count and split cycle is repeated until no new partitions are possible. 6 Recently, we built a scalable classifier <ref> [4] </ref> at Microsoft Research. Our approach exemplifies one of the several ways in which the problem of building SQL-aware systems may be approached. We started with a classical main-memory implementation of a decision tree classifier and Microsoft SQL Server. We augmented this set-up with a middleware to enhance performance. <p> Although the above seems too obvious to mention, there are few implementations of data mining algorithms today that take advantage of these functionality. The goal of harnessing the above functionality often lead to novel ways of staging computation. In <ref> [4] </ref>, we discuss how we can batch servicing multiple active nodes (i.e., nodes that are still being grown) of a scalable decision tree classification algorithm and exploit data structures in the database server. 4.2 SQL Extensions As we implement mining algorithms that generate SQL efficiently, we also will identify primitives that <p> While there has been substantial past research in this area, implementation issues related to processing sampling along with other relational operators continue to be an active area. In our recent work on building scalable classification algorithms over SQL subsystems <ref> [4] </ref>, we recognized that there is strong performance incentive to do batch aggregation. Intuitively, batch aggregation helps fully leverage a single data scan by evaluating multiple aggregation over the same data (or, query).
Reference: [5] <author> Agrawal R., and Srikant R. </author> <title> Fast Algorithms for Mining Association Rules in Large Databases. </title> <booktitle> Proceedings of the 20th International Conference on Very Large Data Bases, </booktitle> <pages> pages 478-499, </pages> <year> 1994. </year>
Reference-contexts: Examples of well-known techniques include decision-tree classification, clustering (see <ref> [5] </ref> for an overview of known techniques). Innovating in this space requires establishing statistical merit of a proposed technique and appears to have little interaction with database system issues. On a more pragmatic note, we seem to have a large number of established techniques in this space. Copyright 1998 IEEE.
Reference: [6] <author> Agrawal R., and Srikant R. </author> <title> Mining Sequential Patterns. </title> <booktitle> Proceedings of the 11th International Conference on Data Engineering, </booktitle> <pages> pages 3-14, </pages> <month> March </month> <year> 1995. </year>
Reference-contexts: Once again, we can draw similarities with the OLAP world. Generation of SQL queries against the backend clearly benefits from the CUBE construct <ref> [6] </ref>. We can identify two goals for studying possible extensions to SQL, extensions that: 1. strongly interact with core SQL primitives and can result in significant performance improvement. 2. encapsulate a set of useful data mining primitives. We feel that extensions that belong to (1) are extremely useful. <p> Having the ability to do multi-statement optimization of the above set of related queries and to exploit a single data scan to evaluate them greatly speed up the classification algorithms. Such batch aggregation functionality goes beyond the CUBE operator <ref> [6] </ref>. Both sampling and batch aggregation strongly interact with core SQL primitives and thus with the SQL relational engine implementations.
Reference: [7] <author> Agrawal R. and Shafer J. </author> <title> Parallel Mining of Association Rules: Design, Implementation, and Experience. </title> <type> Technical Report RJ10004, </type> <institution> IBM Almaden Research Center, </institution> <address> San Jose, CA 95120, </address> <month> Jan. </month> <year> 1996. </year>
Reference-contexts: This allows us to mine an arbitrary query, not necessarily just base data. Thus, it is possible for a power user to use OLAP tools to specify a subset of the data and then to invoke mining tools on that data (cf. <ref> [7] </ref>). Likewise, it is possible to exploit the data reduction capabilities of the data mining tools to identify a subset of data that is interesting and then the OLAP tools can explore the subset of the data using query features.
Reference: [8] <author> Bayardo R. J. </author> <title> Efficiently Mining Long Patterns from Databases. </title> <note> Unpublished Research Report. </note>
Reference-contexts: It is surprising that although scalability of mining algorithms has been an active area of work, few significant pieces of work have looked at the issue of data mining algorithms for SQL systems. A nice study of a SQL-aware scalable implementation of association rules appear in <ref> [8] </ref>. Ad-hoc Mining Today's data mining algorithms are invoked on a materialized disk-resident data set. If data mining were to succeed, data mining must evolve to ad-hoc data mining where the data set which is mined is specified on-the-fly.
Reference: [9] <author> Brin S., Motwani R. and Silverstein C. </author> <title> Beyond Market Baskets: Generalizing Association Rules to Correlations. </title> <booktitle> Proceedings of the ACM SIGMOD, </booktitle> <year> 1997. </year> <pages> pages 265-276. </pages>
Reference: [10] <author> Brin S., Motwani R. Ullman J. D. and Tsur S. </author> <title> Dynamic Itemset Counting and implication rules for Market Basket Data. </title> <booktitle> Proceedings of the ACM SIGMOD, </booktitle> <year> 1997. </year> <pages> pages 255-264. </pages>
Reference: [11] <author> Chen M. S., Han J., and Yu P. S. </author> <title> Data Mining: An Overview from Database Perspective. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 8(6): </volume> <pages> 866-883, </pages> <month> December </month> <year> 1996. </year>
Reference: [12] <author> Klementtinen M., Mannila H., Ronkainen P., Toivonen H., and Verkamo A. I. </author> <title> Finding interesting rules from large sets of discovered association rules. </title> <booktitle> Proceedings of the CIKM 1994. </booktitle>
Reference: [13] <author> Han J., and Fu Y. </author> <title> Discovery of Multi-level Association Rules From Large Databases. </title> <booktitle> Proceedings of the International Conference on Very Large Databases, </booktitle> <pages> pages 420-431, </pages> <address> Zurich, Switzerland, </address> <month> September </month> <year> 1995. </year>
Reference: [14] <author> Lent B., Swami A., and Widom J. </author> <title> Clustering Association Rules. </title> <booktitle> Proceedings of the Thirteenth International Conference on Data Engineering. </booktitle> <pages> pages 220-231, </pages> <address> Birmingham, UK, </address> <month> April </month> <year> 1997. </year> <month> 30 </month>
Reference: [15] <author> Mannila H., Toivonen H., and Verkamo A. I. </author> <title> Efficient algorithms for discovering association rules. </title> <booktitle> AAAI Workshop on Knowledge Discovery in Databases, </booktitle> <year> 1994, </year> <pages> pages 181-192. </pages>
Reference: [16] <author> Lin J.-L. and Dunham M. H. </author> <title> Mining Association Rules: </title> <booktitle> Anti-Skew Algorithms. Proceedings of the International Conference on Data Engineering, </booktitle> <address> Orlando, Florida, </address> <month> February </month> <year> 1998. </year>
Reference: [17] <author> Mueller A. </author> <title> Fast sequential and parallel methods for association rule mining: A comparison. </title> <type> Technical Report CS-TR-3515, </type> <institution> Department of Computer Science, University of Maryland, College Park, MD, </institution> <year> 1995. </year>
Reference: [18] <author> Ozden B., Ramaswamy S, and Silberschatz A. </author> <title> Cyclic Association Rules. </title> <booktitle> Proceedings of the International Conference on Data Engineering, </booktitle> <address> Orlando, Florida, </address> <month> February </month> <year> 1998. </year>
Reference: [19] <author> Park J. S., Chen M. S., and Yu P. S. </author> <title> An Effective Hash-based Algorithm for Mining Association Rules. </title> <booktitle> Proceedings of the ACM-SIGMOD Conference on Management of Data, </booktitle> <year> 1995. </year> <title> Extended version appears as: Using a Hash-based Method with Transaction Trimming for Mining Association Rules. </title> <journal> IEEE Transactions ob Knowledge and Data Engineering, </journal> <volume> Volume 9, no 5, </volume> <month> September </month> <year> 1997, </year> <pages> pages 813-825. </pages>
Reference: [20] <author> Park J. S., Chen M. S. and Yu P. S. </author> <title> Efficient Parallel Data Mining of Association Rules. </title> <booktitle> Fourth International Conference on Information and Knowledge Management, </booktitle> <address> Baltimore, Maryland, </address> <month> November </month> <year> 1995, </year> <pages> pages 31-36. </pages> <note> Technical Report RC20156, </note> <institution> IBM T. J. Watson Research Center, </institution> <month> August </month> <year> 1995. </year>
Reference: [21] <author> Savasere A., Omiecinski E., and Navathe S. B. </author> <title> An efficient algorithm for mining association rules in large databases. </title> <booktitle> Proceedings of the 21st International Conference on Very Large Databases, </booktitle> <year> 1995. </year>
Reference: [22] <author> Savasere A., Omiecinski E., and Navathe S. B. </author> <title> Mining for Strong Negative Associations in a Large Database of Customer Transactions. </title> <booktitle> Proceedings of the International Conference on Data Engineering, </booktitle> <month> February </month> <year> 1998. </year>
Reference: [23] <author> Rastogi R., and Shim K. </author> <title> Mining Optimized Association Rules with Categorical and Numeric Attributes. </title> <booktitle> Proceedings of the International Conference on Data Engineering, </booktitle> <address> Orlando, Florida, </address> <month> February </month> <year> 1998. </year>
Reference: [24] <author> Srikant R., and Agrawal R. </author> <title> Mining Generalized Association Rules. </title> <booktitle> Proceedings of the 21st International Conference on Very Large Data Bases,1995, </booktitle> <pages> pages 407-419. </pages>
Reference: [25] <author> Xiao Y. and Cheung D. W. </author> <title> Effects of data Skewness and Workload Balance in Parallel Data Mining. </title> <note> Unpublished Research Report. </note>
Reference: [26] <author> Srikant R., and Agrawal R. </author> <title> Mining quantitative association rules in large relational tables. </title> <booktitle> Proceedings of the ACM SIGMOD Conference on Management of Data, </booktitle> <year> 1996. </year> <pages> pages 1-12. </pages>
Reference: [27] <author> Toivonen H. </author> <title> Sampling Large Databases for Association Rules. </title> <booktitle> Proceedings of the 22nd International Conference on Very Large Databases, </booktitle> <address> Bombay, India, </address> <month> September </month> <year> 1996. </year>
Reference: [28] <author> Zaki M. J., Ogihara M., Parthasarathy S., and Li W. </author> <title> Parallel Data Mining for Association Rules on Shared-Memory Multi-processors. </title> <address> Supercomputing'96, Pittsburg, PA, </address> <pages> pages 17-22, </pages> <note> 1996 (also available as URCS Technical Report 618 , May 1996). </note>

References-found: 61

