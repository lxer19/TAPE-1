URL: http://www.pmg.lcs.mit.edu/~umesh/pubs/kernel.ps.gz
Refering-URL: http://www.pmg.lcs.mit.edu/~umesh/pubs/
Root-URL: 
Title: Extensible Operating Systems  
Author: Umesh Maheshwari 
Date: November 28, 1994  
Address: Cambridge MA 02139  
Affiliation: MIT Laboratory for Computer Science,  
Pubnum: Area Exam Report:  
Abstract: To exploit the high performance afforded by the hardware, applications must be allowed to customize the operating system according to their needs. A pertinent question is: What interface should the operating system kernel provide to the user-level code? This interface should be efficient, extensible, and safe, but need not provide high-level abstractions. Abstractions and policies are better left to user-level libraries and servers. This paper tries to find the suitable kernel interface by studying two areas: First, the implications of placing the system code in libraries, servers, and the kernel. Second, the appropriate level of kernel support for protected allocation of the various physical resources. The study includes an analysis of a range of existing and recently proposed kernels. 
Abstract-found: 1
Intro-found: 1
Reference: [ABB + 86] <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, and M. Young. </author> <title> Mach: a new kernel foundation for UNIX development. </title> <booktitle> Proc. Summer 1986 USENIX Conference, </booktitle> <pages> pages 93-112, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: This is a turnaround because the microkernels developed earlier were deemed to be slower than their monolithic counterparts due to extra communication with the system servers <ref> [ABB + 86] </ref>. It is now believed that small, extensible kernels can outperform their microkernel ancestors as well as monolithic systems.
Reference: [ABLL91] <author> T.E. Anderson, B.N. Bershad, E.D. Lazowska, and H.M. Levy. </author> <title> Scheduler activations: Effective kernel support for the user-level management of parallelism. </title> <booktitle> Proc. Thirteenth Symposium on Operating System Principles, </booktitle> <pages> pages 95-109, </pages> <month> October </month> <year> 1991. </year>
Reference: [And92] <author> T.E. Anderson. </author> <title> The case for application-specific operating systems. </title> <booktitle> In Third Workshop on Workstation Operating Systems, </booktitle> <pages> pages 92-94, </pages> <year> 1992. </year>
Reference-contexts: If the high performance afforded by the hardware is to be delivered to resource-intensive applications, the applications must be allowed to customize the operating system according to their specific needs. Resolving policy issues in the kernel only biases it towards some applications and makes it unsuitable for others <ref> [WCC + 74, And92, KLM + 93] </ref>. For example, the LRU policy used for page replacement is appropriate for most applications exhibiting spatial locality, but not for many database applications that scan their data sequentially.
Reference: [BCE + 94] <author> B.N. Bershad, C. Chambers, S. Eggers, C. Maeda, D. McNamee, P. Pardyak, S. Savage, and E. Sirer. </author> <title> Spin an extensible microkernel for application-specific operating system services. </title> <type> TR 94-03-03, </type> <institution> Univ. of Washington, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: How fair is it? (Could one application steal the shared resources?) 7. How programmable are the extensions? (Are the interfaces well-defined? Is there high-level language sup port?) 1.2 The Outline The three papers selected for my area exam are: Cache Kernel [CD94], from Stanford University. SPIN <ref> [BCE + 94] </ref>, from Univ. of Washington, Seattle. Scout [MMO + 94], from Univ. of Arizona, Tucson.
Reference: [BKW94] <author> K. Bala, M.F. Kaashoek, and W.E. Weihl. </author> <title> Software prefetching and caching for translation lookaside buffers. </title> <booktitle> In Proc. of the first Symp. on OSDI, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: As an optimization, the kernel maintains a software TLB in memory to provide a bigger cache of PTEs than the hardware TLB; also, the application can prefetch entries into the TLB ahead of demand <ref> [BKW94] </ref>. The application manages its own page table in the user space to handle TLB misses. To avoid the upcall into the user space on a TLB miss, the application can install its own TLB-miss handler into the kernel, which can then access the page table in the user space.
Reference: [CD94] <author> D. Cheriton and K. Duda. </author> <title> A caching model of operating system kernel functionality. </title> <booktitle> Proceedings of the Sixth SIGOPS European Workshop, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: How fair is it? (Could one application steal the shared resources?) 7. How programmable are the extensions? (Are the interfaces well-defined? Is there high-level language sup port?) 1.2 The Outline The three papers selected for my area exam are: Cache Kernel <ref> [CD94] </ref>, from Stanford University. SPIN [BCE + 94], from Univ. of Washington, Seattle. Scout [MMO + 94], from Univ. of Arizona, Tucson. <p> as suggested in the Bridge system (Section 3.4.4), the default system servers should be merged into the kernel in their entirety using software fault-isolation techniques to avoid IPC overhead. 5.4 Loading Code into the Kernel Some researchers find the idea of downloading application code into the kernel to be risky <ref> [CD94] </ref>. The idea is surely unconventional, but I consider it an inevitable development. The purpose of the hardware-enacted firewall between the kernel and the user mode is to disallow potentially unsafe code from accessing physical resources.
Reference: [Che84] <author> D. R. Cheriton. </author> <title> The v kernel: A software base for distributed systems. </title> <journal> IEEE Software, </journal> <volume> 1(2) </volume> <pages> 19-42, </pages> <year> 1984. </year>
Reference: [Cla85] <author> D.D. Clark. </author> <title> On the structuring of systems using up-calls. </title> <booktitle> Proceedings of the Tenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 171-180, </pages> <month> De-cember </month> <year> 1985. </year>
Reference-contexts: This interface is accessed through system calls, which usually involve a hardware trap to enter the privileged mode at a fixed location. Occasionally, the kernel also needs to make an upcall into an application/server <ref> [Cla85] </ref>; this happens in some systems, for example, when an application receives a signal, or when a server routine is invoked.
Reference: [DP93] <author> P. Druschel and L. L. Peterson. Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility. </title> <booktitle> Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 189-202, </pages> <year> 1993. </year>
Reference: [EKO94] <author> Dawson R. Engler, M. Frans Kaashoek, and James O'Toole. </author> <title> The operating system kernel as a secure programmable machine. </title> <booktitle> Proceedings of the Sixth SIGOPS European Workshop, </booktitle> <month> September </month> <year> 1994. </year>
Reference-contexts: Lately, some researchers have proposed that the kernel should shed not only policies but also the abstractions over physical resources, while retaining only the minimal control needed to ensure protected allocation <ref> [EKO94] </ref>. Other benefits of keeping system services outside the kernel are well known. Servers from third-party vendors can be installed as desired after the kernel is in place. In fact, multiple APIs may be provided by different servers on the same machine.
Reference: [Eng94] <author> D. Engler. </author> <type> Personal communication. </type> <month> November </month> <year> 1994. </year>
Reference-contexts: The compiler and the downloader execute in a trusted domain that is allowed to do this. As an aside, it is illuminating to compare the concepts used in SPIN to those in Thor <ref> [Mye93, Eng94] </ref>. Thor is not a kernel; it is an object-oriented database that allows application programs written in different languages to manipulate shared persistent objects. Thor objects are encapsulated in that they can be accessed only by invoking operations (cf. system calls). <p> to illegally access some kernel state.) Further, there are situations, such as a TLB miss, when the kernel code should restrict its activity to a fixed, small number of scratch registers to avoid having to save and restore other registers; it is difficult to translate high-level code under such restrictions <ref> [Eng94] </ref>. Another drawback of SPIN is that it encourages applica tions to download code for customizability, which may bloat the kernel unduly. Bloating can be remedied by providing a default SPI that is low-level enough for most applications to customize their policies without downloading code. <p> Although these abstractions hide resource-allocation details and provide a nice interface to program with, they do not hide one important aspect: performance. Often, kernel abstractions incur performance costs that could be avoided if applications were given direct control. Thus, abstractions are an inefficient mechanism to ensure insulation <ref> [Eng94] </ref>.
Reference: [EP94] <author> D.R. Engler and T.A. Proebsting. </author> <title> DCG: An efficient, retargetable dynamic code generation system. </title> <booktitle> Proceedings of ASPLOS-VI, </booktitle> <pages> pages 263-272, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: It makes the critical path explicit; i.e., the path across domains that the control most frequently follows. The compiler can segregate the critical path code to improve the locality of reference in the instruction cache. Also, parts of the critical path code can be generated dynamically for better performance <ref> [EP94] </ref>. Although the concept of path-based resource allocation and optimizations is tempting for applications doing bulk data transfers, I do not believe that it can replace the domain-based management for general purpose computing. <p> The Mach packet filter speeds up the matching process by merging the common prefixes of the filter predicates. Aegis uses a declarative language that allows greater merging, and exploits dynamic code generation to remove a layer of interpretation in the matching process <ref> [EP94] </ref> (code generation for filters was first proposed in [TNML93]). Network protocol execution can be split between a server and library code to provide both efficiency and some degree of security [TNML93, MB93]. Heavyweight and infrequent operations like connection startup happen through a trusted server.
Reference: [Fel92] <author> E. Felten. </author> <title> The case for application-specific communication protocols. </title> <booktitle> In Proc. of Intel Supercomputer Systems Division Technology Focus Division, </booktitle> <pages> pages 171-181, </pages> <year> 1992. </year>
Reference-contexts: Unfortunately, the code implementing the network protocols is usually quite bulky (30% of 4.3BSD Unix kernel). Further, due to changes in the network technology, this code is very prone to modifications and needs frequent experimentation [MRA87]. Researchers have also made a case for application-specific communication protocols <ref> [Fel92] </ref>. These reasons provide a strong incentive to move the network-protocol code outside the kernel. One option is for the kernel to forward all packets to a trusted server, which processes the packets according to suitable network protocols and then demultiplexes the packets to their destination applications.
Reference: [Fou93] <author> Open Software Foundation. </author> <title> Design of the OSF/1 Operating System. </title> <publisher> P T R Prentice Hall, </publisher> <year> 1993. </year>
Reference: [HC92] <author> Kieran Harty and David R. Cheriton. </author> <title> Application-controlled physical memory using external page-cache management. </title> <booktitle> Proc. of the Fifth Conf. on Architectural Support for Programming languages and Operating Systems, </booktitle> <pages> pages 187-199, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: V++ Before publishing the Cache Kernel, the designers of V++ suggested a powerful kernel interface that allows application to control page replacement, pinning, and prefetching, and to obtain the virtual to physical mappings <ref> [HC92] </ref>. A crucial primitive in this interface allows applications to migrate pages from one segment into another through remapping techniques.
Reference: [Hil93] <author> D. Hildebrand. </author> <title> A microkernel posix os for realtime embedded systems. </title> <booktitle> Proc. Embedded Computer Conference, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: Some of these systems have proven their viability in the commercial world; e.g., Amoeba, L3, Mach, and QNX. 1 Systems researchers have likened the move from monolithic kernels toward small, extensible kernels to that from CISC toward RISC in computer architecture <ref> [Hil93] </ref>. There are strong incentives behind the move toward smaller kernels. In the past, the reason commonly touted was to make the operating system more modular: to divide it into a small kernel, commonly known as a microkernel, and user-level servers. <p> In fact, multiple APIs may be provided by different servers on the same machine. In a network of computers, the servers can be shared across the network, so that most computers will need to run only the small kernel <ref> [Hil93] </ref>. This is especially desirable in small embedded systems. Further, the separation of the machine-dependent kernel from the machine-independent server modules makes the servers portable across platforms. The use of smaller kernels may potentially improve the robustness of the operating system.
Reference: [HK93] <author> Graham Hamilton and Panos Kougiouris. </author> <title> The Spring nucleus: A microkernel for objects. </title> <booktitle> Conference Proceedings of the USENIX Summer 1993 Technical Conference, </booktitle> <pages> pages 147-160, </pages> <month> June </month> <year> 1993. </year>
Reference: [HP91] <author> N.C. Hutchinson and L.L. Peterson. </author> <title> The x-kernel: an architecture for implementing network protocols. </title> <journal> IEEE Trans. on Soft. Eng., </journal> <volume> 17(1), </volume> <month> Jan. </month> <year> 1991. </year>
Reference: [HPM93] <author> G. Hamilton, M. L. Powell, and J. J. Mitchell. Subcontract: </author> <title> A flexible base for distributed programming. </title> <booktitle> Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 69-79, </pages> <year> 1993. </year>
Reference: [KCE92] <author> E. J. Koldinger, J. S. Chase, and S. J. Eggers. </author> <title> Architecture support for single address operating systems. </title> <booktitle> Architecture Support for Programming Languages and Operating Systems1991, </booktitle> <pages> pages 175-186, </pages> <year> 1992. </year>
Reference-contexts: It is possible to imagine a system where even the applications are merged into the kernel's address space an approach similar to single address-space operating systems <ref> [KCE92] </ref> except that protection between the subsystems would be based on software rather than hardware. However, a major problem with such a system would be to relocate and sandbox each application before executing it.
Reference: [Kle86] <author> S. R. Kleiman. Vnodes: </author> <title> An architecture for multiple file system types in sun unix. </title> <booktitle> Proc. Summer 1986 USENIX Conference, </booktitle> <pages> pages 238-247, </pages> <month> July </month> <year> 1986. </year>
Reference: [KLM + 93] <author> G. Kiczales, J. Lamping, C. Maeda, D. Keppel, and D. McNamee. </author> <title> The need for customizable operating systems. </title> <booktitle> In Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 165-170, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: If the high performance afforded by the hardware is to be delivered to resource-intensive applications, the applications must be allowed to customize the operating system according to their specific needs. Resolving policy issues in the kernel only biases it towards some applications and makes it unsuitable for others <ref> [WCC + 74, And92, KLM + 93] </ref>. For example, the LRU policy used for page replacement is appropriate for most applications exhibiting spatial locality, but not for many database applications that scan their data sequentially.
Reference: [KN93] <author> Y.A. Khalidi and M.N. Nelson. </author> <title> Extensible file systems in Spring. </title> <booktitle> Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <month> December </month> <year> 1993. </year>
Reference: [LCC94] <author> C. Lee, M. C. Chen, and R. Chang. </author> <title> Hipec: High performance external virtual memory caching. </title> <month> November </month> <year> 1994. </year>
Reference-contexts: Note that the kernel chooses the page to be evicted. (Extensions have been suggested to allow Mach servers to control page replacement.) Besides providing backup storage, a server can provide coherence for shared pages by ensuring that only one application has write access to a page. HiPEC In HiPEC <ref> [LCC94] </ref>, applications specify their own page-replacement policy through a set of commands stored in the user space that are interpreted by the kernel on a page fault. Each application has a separate pool of pages, and the stored commands help the kernel select the victim page.
Reference: [Lie] <author> J. Liedtke. </author> <title> Fast thread management and communication without continuations. Micro-kernels and Other Kernel Architectures, </title> <booktitle> USENIX, </booktitle> <pages> pages 213-221. </pages>
Reference: [Luc94] <author> S. Lucco. </author> <title> High-performance microkernel systems. </title> <month> November </month> <year> 1994. </year>
Reference: [MB93] <author> C. Maeda and B. Bershad. </author> <title> Protocol service decomposition for high-performance networking. </title> <booktitle> Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <year> 1993. </year>
Reference-contexts: Network protocol execution can be split between a server and library code to provide both efficiency and some degree of security <ref> [TNML93, MB93] </ref>. Heavyweight and infrequent operations like connection startup happen through a trusted server. The server installs a packet filter in the kernel to forward packets directly to the application. Applications cannot install their own filters; this ensure some security from one application stealing another's packets (maliciously or inadvertently).
Reference: [MMO + 94] <author> A.B. Montz, David Mosberger, S.W. O'Malley, L.L. Peterson, T.A. Proebsting, and J.H. Hartman. </author> <title> Scout: A 15 communication-oriented operating system. </title> <type> Technical Report TR 94-20, </type> <institution> University of Arizona, </institution> <address> Tucson, AZ, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: How programmable are the extensions? (Are the interfaces well-defined? Is there high-level language sup port?) 1.2 The Outline The three papers selected for my area exam are: Cache Kernel [CD94], from Stanford University. SPIN [BCE + 94], from Univ. of Washington, Seattle. Scout <ref> [MMO + 94] </ref>, from Univ. of Arizona, Tucson. Both Cache Kernel and SPIN provide application-specific customization of the kernel at runtime, but have different underlying philosophy: the Cache Kernel allows applications/servers to control the information cached by the kernel; SPIN works by downloading application-specific code into the kernel.
Reference: [MRA87] <author> J.C. Mogul, R.F. Rashid, and M.J. Accetta. </author> <title> The packet filter: An efficient mechanism for user-level network code. </title> <booktitle> In Proceedings of 11th SOSP, </booktitle> <pages> pages 39-51, </pages> <address> Austin, TX, </address> <month> November </month> <year> 1987. </year>
Reference-contexts: Such a facility favors fast development of new protocols, say, for RPC. Unfortunately, the code implementing the network protocols is usually quite bulky (30% of 4.3BSD Unix kernel). Further, due to changes in the network technology, this code is very prone to modifications and needs frequent experimentation <ref> [MRA87] </ref>. Researchers have also made a case for application-specific communication protocols [Fel92]. These reasons provide a strong incentive to move the network-protocol code outside the kernel. <p> When the kernel receives a packet from the network controller, it applies the filters, in some prioritized order, to the contents of the packet. When a filter matches the packet, the kernel forwards the packet to the application that installed it. In <ref> [MRA87] </ref>, a stack-based language was used to compose the filters, which were then interpreted by the kernel. The Mach packet filter speeds up the matching process by merging the common prefixes of the filter predicates.
Reference: [Mye93] <author> A. C. Myers. </author> <title> Resolving the integrity / performance conflict. </title> <booktitle> In Fourth Workshop on Workstation Operating Systems, </booktitle> <pages> pages 156-160, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: The compiler and the downloader execute in a trusted domain that is allowed to do this. As an aside, it is illuminating to compare the concepts used in SPIN to those in Thor <ref> [Mye93, Eng94] </ref>. Thor is not a kernel; it is an object-oriented database that allows application programs written in different languages to manipulate shared persistent objects. Thor objects are encapsulated in that they can be accessed only by invoking operations (cf. system calls). <p> Object-oriented databases add further value to persistent data by capturing its semantics besides the format <ref> [Mye93] </ref>. 4.7 Device I/O Applications need to perform I/O on devices such as terminals and disks. Traditionally, the kernel contains the device drivers (software) that operate on the corresponding device controllers (hardware) to provide a higher level read/write like interface.
Reference: [PMI88] <author> C. Pu, H. Massalin, and J. Ioannidis. </author> <title> The Synthesis kernel. </title> <journal> Computing Systems, </journal> <volume> 1(1) </volume> <pages> 11-32, </pages> <year> 1988. </year>
Reference: [TK94] <author> A.S. Tanenbaum and M. F. Kaashoek. </author> <title> The amoeba microkernel. </title> <journal> IEEE ??, pages 11-30B, </journal> <year> 1994. </year>
Reference: [TNML93] <author> C.A. Thekkath, T.D. Nguyen, E. Moy, and E. La-zowska. </author> <title> Implementing network protocols at user level. </title> <booktitle> Proceedings of the 1993 SIGCOMM Symposium on Communications Architecture, </booktitle> <year> 1993. </year>
Reference-contexts: Aegis uses a declarative language that allows greater merging, and exploits dynamic code generation to remove a layer of interpretation in the matching process [EP94] (code generation for filters was first proposed in <ref> [TNML93] </ref>). Network protocol execution can be split between a server and library code to provide both efficiency and some degree of security [TNML93, MB93]. Heavyweight and infrequent operations like connection startup happen through a trusted server. <p> Network protocol execution can be split between a server and library code to provide both efficiency and some degree of security <ref> [TNML93, MB93] </ref>. Heavyweight and infrequent operations like connection startup happen through a trusted server. The server installs a packet filter in the kernel to forward packets directly to the application. Applications cannot install their own filters; this ensure some security from one application stealing another's packets (maliciously or inadvertently).
Reference: [WCC + 74] <author> W. Wulf, E. Cohen, W. Corwin, A. Jones, R. Levin, C. Pierson, and F. Pollack. HYDRA: </author> <title> The kernel of a multiprocessing operating system. </title> <journal> Communications of the ACM, </journal> <volume> 17(6) </volume> <pages> 337-345, </pages> <month> July </month> <year> 1974. </year>
Reference-contexts: If the high performance afforded by the hardware is to be delivered to resource-intensive applications, the applications must be allowed to customize the operating system according to their specific needs. Resolving policy issues in the kernel only biases it towards some applications and makes it unsuitable for others <ref> [WCC + 74, And92, KLM + 93] </ref>. For example, the LRU policy used for page replacement is appropriate for most applications exhibiting spatial locality, but not for many database applications that scan their data sequentially.
Reference: [WLAG93] <author> R. Wahbe, S. Lucco, T. Anderson, and S. Graham. </author> <title> Efficient software-based fault isolation. </title> <booktitle> Proceedings of the Fourteenth ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 203-216, </pages> <year> 1993. </year>
Reference-contexts: The runtime checks include the use of sandboxing to restrict jumps to the user space, and loads and stores into the kernel space: a trusted module inserts code around indirect jump, load and store instructions to check the values at runtime <ref> [WLAG93] </ref>. Some privileged instructions need to be preceded by guards that check the required capabilities. Further, loop execution in the downloaded code can be limited by bounding loop iteration counts and by using timer interrupts.
Reference: [WW94] <author> C. A. Waldspurger and W. E. Weihl. </author> <title> Lottery scheduling: Flexible proportional-share resource management. </title> <month> November </month> <year> 1994. </year>
Reference-contexts: This automatically favors interactive threads over compute-intensive threads. To prevent long running threads from continually losing priority, usage-aging is used to gradually forget the usage penalty. 2. Proportional-share: Threads are given timeslices in proportion to their priorities <ref> [WW94] </ref>. This allows users (applications) to control the execution rates of applica tions (threads) in a predictable way. Most Unix systems use usage-aging; however, I believe that the lack of predicatable control would soon lead to the implementation of a variety of proportional-share policies. <p> Loading a thread makes it runnable, and unloading blocks it. Although this arrangement provides some flexibility, it does not admit many useful policies. For example, I can see no way of implementing a proportional-share policy called lottery scheduling <ref> [WW94] </ref>. So far I have discussed systems that schedule threads irrespective of whether the threads belong to the same or different domains.

References-found: 36

