URL: http://www-rali.iro.umontreal.ca/Publications/icslp-e.ps
Refering-URL: http://www-rali.iro.umontreal.ca/Publications.en.html
Root-URL: http://www.iro.umontreal.ca
Title: Towards an Automatic Dictation System for Translators the TransTalk Project  
Author: Marc Dymetman yy Julie Brousseau George Foster Pierre Isabelle Yves Normandin Pierre Plamondon 
Date: September 16, 1994  
Address: 1575, Boul. Chomedey, Laval H7V 2X2, Quebec, Canada  1801, McGill College, Montreal H3A 2NA, Quebec, Canada  
Affiliation: Centre d'Innovation en Technologies de l'Information (CITI)  Centre de Recherche Informatique de Montreal (CRIM)  
Abstract: Professional translators often dictate their translations orally and have them typed afterwards. The TransTalk project aims at automating the second part of this process. Its originality as a dictation system lies in the fact that both the acoustic signal produced by the translator and the source text under translation are made available to the system. Probable translations of the source text can be predicted and these predictions used to help the speech recognition system in its lexical choices. We present the results of the first prototype, which show a marked improvement in the performance of the speech recognition task when translation predictions are taken into account. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Peter F. Brown, Stanley F. Chen, Stephen A. Della Pietra, Vincent Della Pietra, Andrew S. Kehler, and Robert L. Mercer. </author> <title> Automatic speech recognition in machine aided translation. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 8 </volume> <pages> 177-187, </pages> <year> 1994. </year>
Reference-contexts: Conceptually, the main difference between a conventional "noisy channel" speech recognition system for French and TransTalk is that, instead of maxi 1 The idea was independently advanced by us [3] and by researchers at the IBM Thomas J. Watson Research Center <ref> [1] </ref>. 2 mizing in f the product p (s j f ) p (f ) of an "acoustic model" and a "language model" for French (where s stands for the acoustic signal and f for the French sentence), we maximize the product p (s j f) p (f j e) of
Reference: [2] <author> Peter F. Brown, Stephen A. Della Pietra, Vincent Della J. Pietra, and Robert L. Mercer. </author> <title> The mathematics of machine translation: Parameter estimation. </title> <journal> Computational Linguistics, </journal> <volume> 19(2) </volume> <pages> 263-312, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: In <ref> [2] </ref>, Brown et al. expand it as the product p (f ) p (e j f), to which it is proportional under maximization over f . <p> Because it is most valid when c consists of broad classifications 2 we use a minimal set of 15 classes which correspond to the major grammatical categories (noun, verb, etc). To incorporate translation information, we suppose, following Brown et al. <ref> [2] </ref>, that f and e are related via an alignment (see figure 2) in which each French word is connected to either a single English word in e or none at all.
Reference: [3] <author> Marc Dymetman, Steven Krauwer, and Herbert Ruessink. </author> <title> Robustness: A project proposal, </title> <month> October </month> <year> 1992. </year> <title> Unpublished EEC-Canada joint project proposal. </title>
Reference-contexts: Conceptually, the main difference between a conventional "noisy channel" speech recognition system for French and TransTalk is that, instead of maxi 1 The idea was independently advanced by us <ref> [3] </ref> and by researchers at the IBM Thomas J.
Reference: [4] <author> Pierre Isabelle, Marc Dymetman, George Foster, Jean-Marc Jutras, Elliott Macklovitch, Franois Perrault, Xiaobo Ren, and Michel Simard. </author> <title> Translation analysis and translation automation. </title> <booktitle> In Proceedings of the Fifth Internation Conference on Theoretical and Methodological Issues in Machine Translation, </booktitle> <pages> pages 201-217, </pages> <month> July </month> <year> 1993. </year>
Reference: [5] <author> Martin Kay, Jean Mark Gawron, and Peter Norvig. </author> <title> Verbmobil. A Translation System for Face-to-Face Dialog. Lecture Note No. 33. Center for the Study of Language and Information, </title> <publisher> Stanford, </publisher> <year> 1994. </year> <month> 9 </month>
Reference-contexts: 1 Introduction The integration of machine translation and speech technology is currently the focus of major projects in several countries <ref> [5, 6, 9] </ref>. Usually, the aim of these efforts is some type of speech-to-speech translation, where speech recognition, machine translation and speech synthesis are performed sequentially.
Reference: [6] <author> A. Kurematsu. </author> <title> Automatic telephone interpretation: A basic study. </title> <type> ATR Technical Report TR-I-0001, </type> <institution> ATR Interpreting Telephony Research Laboratories, </institution> <address> Japan, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: 1 Introduction The integration of machine translation and speech technology is currently the focus of major projects in several countries <ref> [5, 6, 9] </ref>. Usually, the aim of these efforts is some type of speech-to-speech translation, where speech recognition, machine translation and speech synthesis are performed sequentially.
Reference: [7] <author> R. Lacouture and R. De Mori. </author> <title> Lexical tree compression. </title> <booktitle> In Proceedings, Eurospeech Conference, </booktitle> <pages> pages 581-584, </pages> <address> Genova, Italy, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: The base pronunciations were obtained using a set of grapheme-to-phoneme rules which take into account phonetic particularities found in the French spoken in Quebec such as assibilation and vowel laxing. Recognition is performed with an n-best search of a compressed phonetic graph representing the entire 20,000 word vocabulary <ref> [7] </ref>. This graph is such that no two paths produce the same phone sequence and every path corresponds to a valid phonetic representation in the dictionary. A given path will therefore correspond to all lexicon entries sharing the same phonetics.
Reference: [8] <author> Michel Simard, George F. Foster, and Pierre Isabelle. </author> <title> Using cognates to align sentences in bilingual corpora. </title> <booktitle> In TMI-4, </booktitle> <address> Montreal, Canada, </address> <year> 1992. </year>
Reference-contexts: Bi-lexical parameters were estimated as part of a simplified translation model in which contextual information was assumed to be explicit: p (f; c j e) = A f ;e a i=1 To train this model, we first aligned the training corpus to the sentence level using the method described in <ref> [8] </ref>.
Reference: [9] <author> F. W. M. Stentiford and M. G. Steer. </author> <title> Machine translation of speech. </title> <editor> In C. Wheddon and R. Linggard, editors, </editor> <booktitle> Speech and Language Processing, </booktitle> <pages> pages 183-196. </pages> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1990. </year> <month> 10 </month>
Reference-contexts: 1 Introduction The integration of machine translation and speech technology is currently the focus of major projects in several countries <ref> [5, 6, 9] </ref>. Usually, the aim of these efforts is some type of speech-to-speech translation, where speech recognition, machine translation and speech synthesis are performed sequentially.
References-found: 9

