URL: ftp://ftp.huji.ac.il/users/yish/yish.icmas95.ps.gz
Refering-URL: http://www.cs.huji.ac.il/~yish/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: email: yish@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Time and the Prisoner's Dilemma addition, a variant of the repeated Prisoner's Dilemma game is
Author: Yishay Mor Jeffrey S. Rosenschein ph: ---- 
Note: In  
Address: Givat Ram, Jerusalem, Israel  
Affiliation: Computer Science Department Hebrew University  
Abstract: This paper examines the integration of computational complexity into game theoretic models. The example focused on is the Prisoner's Dilemma, repeated for a finite length of time. We show that a minimal bound on the players' computational ability is sufficient to enable cooperative behavior. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Axelrod. </author> <title> The Evolution of Cooperation. </title> <publisher> Basic Books, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: From the agent designer's point of view, it enables him to design a strategy that will impose cooperation on his agent's opponent. 1.1 Related Work A thorough and comprehensive survey of the basic literature on bounded rationality and repeated PD appears in [7]. Axelrod <ref> [2, 1] </ref> reports on his 1 This example is not as farfetched as it may seem. Hogg and Huberman [6] study the power of cooperation in distributed search problems. 2 famous computer tournament and analyzes social systems accordingly.
Reference: [2] <author> R. Axelrod and W. Hamilton. </author> <title> The evolution of cooperation. </title> <journal> Science, </journal> <volume> 211(4489) </volume> <pages> 1390-1396, </pages> <month> March </month> <year> 1981. </year>
Reference-contexts: From the agent designer's point of view, it enables him to design a strategy that will impose cooperation on his agent's opponent. 1.1 Related Work A thorough and comprehensive survey of the basic literature on bounded rationality and repeated PD appears in [7]. Axelrod <ref> [2, 1] </ref> reports on his 1 This example is not as farfetched as it may seem. Hogg and Huberman [6] study the power of cooperation in distributed search problems. 2 famous computer tournament and analyzes social systems accordingly.
Reference: [3] <author> Ken Binmore and Larry Samuelson. </author> <title> Drifting to equilibrium. </title> <type> Unpublished manuscript, </type> <month> March </month> <year> 1994. </year>
Reference-contexts: Sections 3 and 4 of this paper deal with a similar variation on the repeated PD game, in which players have the possibility of opting out. Several researchers (see <ref> [12, 3] </ref> for examples and further bibliography) took Axelrod's lead and investigated evolutionary models of games. Most, if not all, of these works studied populations of deterministic or stochastic automata with a small number of states.
Reference: [4] <author> L. Fortnow and D. Whang. </author> <title> Optimality and domination in repeated games with bounded players. </title> <type> Technical report, </type> <institution> Department of Computer Science University of Chicago, Chicago, </institution> <year> 1994. </year>
Reference-contexts: Hogg and Huberman [6] study the power of cooperation in distributed search problems. 2 famous computer tournament and analyzes social systems accordingly. Most of the work on this subject has centered on various automata as models of bounded rationality; <ref> [13, 5, 4] </ref> and others (see [7] for an extensive bibliography) deal with finite state automata with a limited number of states, and [11] examines Turing machines with a bounded number of states. <p> The possibility of opting out enables A to return to a cooperative 7 equilibrium. Generally, the existence of "vengeful strategies" (like GRIM) is problematic in the standard game context. Other researchers <ref> [5, 4] </ref> have dealt with these strategies by explicitly removing them from the set of strategies under consideration. Once opting out is introduced, this is no longer necessary.
Reference: [5] <author> I. Gilboa and D. Samet. </author> <title> Bounded vs. unbounded rationality: The tyranny of the weak. </title> <journal> Games and Economic Behavior, </journal> <volume> 1 </volume> <pages> 213-221, </pages> <year> 1989. </year>
Reference-contexts: Hogg and Huberman [6] study the power of cooperation in distributed search problems. 2 famous computer tournament and analyzes social systems accordingly. Most of the work on this subject has centered on various automata as models of bounded rationality; <ref> [13, 5, 4] </ref> and others (see [7] for an extensive bibliography) deal with finite state automata with a limited number of states, and [11] examines Turing machines with a bounded number of states. <p> The possibility of opting out enables A to return to a cooperative 7 equilibrium. Generally, the existence of "vengeful strategies" (like GRIM) is problematic in the standard game context. Other researchers <ref> [5, 4] </ref> have dealt with these strategies by explicitly removing them from the set of strategies under consideration. Once opting out is introduced, this is no longer necessary.
Reference: [6] <author> Tad Hogg and Bernardo A. Hubermann. </author> <title> Better than the best: The power of cooperation. </title> <editor> In L. Nadel and D. Stein, editors, </editor> <booktitle> Lectures in Complex Systems, </booktitle> <pages> pages 163-184. </pages> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: Axelrod [2, 1] reports on his 1 This example is not as farfetched as it may seem. Hogg and Huberman <ref> [6] </ref> study the power of cooperation in distributed search problems. 2 famous computer tournament and analyzes social systems accordingly.
Reference: [7] <author> Ehud Kalai. </author> <title> Bounded rationality and strategic complexity in repeated games. </title> <editor> In T. Ichiishi, A. Neyman, and Y. Tauman, editors, </editor> <booktitle> Game Theory and Aplications, </booktitle> <pages> pages 131-157. </pages> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1990. </year>
Reference-contexts: From the agent designer's point of view, it enables him to design a strategy that will impose cooperation on his agent's opponent. 1.1 Related Work A thorough and comprehensive survey of the basic literature on bounded rationality and repeated PD appears in <ref> [7] </ref>. Axelrod [2, 1] reports on his 1 This example is not as farfetched as it may seem. Hogg and Huberman [6] study the power of cooperation in distributed search problems. 2 famous computer tournament and analyzes social systems accordingly. <p> Hogg and Huberman [6] study the power of cooperation in distributed search problems. 2 famous computer tournament and analyzes social systems accordingly. Most of the work on this subject has centered on various automata as models of bounded rationality; [13, 5, 4] and others (see <ref> [7] </ref> for an extensive bibliography) deal with finite state automata with a limited number of states, and [11] examines Turing machines with a bounded number of states. <p> Previous work <ref> [7] </ref> focused on finite or infinite iterated PD (IPD). The basic idea is that two players play PD for N rounds. In each round, once both have made their move (effectively simultaneously), they get the payoffs defined by the PD game matrix.
Reference: [8] <author> Ron Kaniel. </author> <title> On the equipment rental problem. </title> <type> Master's thesis, </type> <institution> Hebrew University, </institution> <year> 1994. </year>
Reference-contexts: The intuition behind this is, that if maximizing expected payoff is too expensive computationally, the next best thing to do is to ensure the highest possible "security level," protecting oneself best against the worst (max-min). In order to evaluate satisfying strategies, we use the method of competitive analysis. Kaniel <ref> [8] </ref> names Sleator and Tarjan [17] as the initiators of this approach. The idea is to use the ratio between the satisfying strategy's payoff and that of a maximizing strategy as a quantifier of the satisfying strategy's performance. We begin by defining the concepts introduced above.
Reference: [9] <author> D. Kreps, P. Milgrom, J. Roberts, and R. Wilson. </author> <title> Rational cooperation in finitely repeated Prisoners' Dilemma. </title> <journal> ,journal of Economic Theory, </journal> <volume> 27(2) </volume> <pages> 245-252, </pages> <year> 1982. </year>
Reference: [10] <author> Yishay Mor. </author> <title> Computational approaches to rational choice. </title> <type> Master's thesis, </type> <institution> Hebrew University, </institution> <year> 1995. </year> <note> In preparation. </note>
Reference-contexts: Once opting out is introduced, this is no longer necessary. The possibility of opting out also makes the game less vulnerable to noise, and provides fertile ground for studying learning in the PD game context. These issues are beyond the scope of the current paper; see <ref> [10] </ref> for further discussion. One last motivation for this line of work is sociological: "breaking up a relationship" is a common way of punishing defectors in repeated human interactions. <p> Theorem 6 In the IPD game with opting out, if P &gt; Q, the only Nash equilibrium is &lt; D N ; D N &gt;. Proof. The standard reasoning of backward induction works in this game; see <ref> [10] </ref> for the full proof. From now on we will deal only with the OPD game. For simplicity's sake, we will assume Q = 0. Let us define the full context of the game. Rules of the OPD Game: 1. <p> C, we continue by induction. 5 Theorem 8 If there is a positive probability of at least one of the other players being cooperative, and rematching is instantaneous, then a player in the OPD game has a positive expected gain from opting out whenever the opponent waits. 6 5 See <ref> [10] </ref> for a more detailed proof. 6 The problematic condition is instantaneous rematching. There are 2 necessary and sufficient conditions for this to happen: 1. Opting out can be done in the same round the opponent waits. 2. <p> The second condition is unjustifiable in any realistic setting. The first condition returns to a player's ability to "watch the opponent" without waiting, mentioned in Footnote 4. In <ref> [10] </ref> we show different assumptions that make this condition possible. 9 Proof. This theorem follows directly from Theorem 3 and Theorem 7. The full proof can be found in [10]. 4 Sub-Optimal Strategies In considering whether to opt out or not, player A has to assess his expected payoff against his <p> The first condition returns to a player's ability to "watch the opponent" without waiting, mentioned in Footnote 4. In <ref> [10] </ref> we show different assumptions that make this condition possible. 9 Proof. This theorem follows directly from Theorem 3 and Theorem 7. The full proof can be found in [10]. 4 Sub-Optimal Strategies In considering whether to opt out or not, player A has to assess his expected payoff against his current opponent B, the probability B will opt out given A's actions, and his expected payoff after opting out. <p> His opponent can infer that playing against A he will receive 8 Actually, it is easy to show that const = 1 q fl [(r + 1)R S] where r is the expected number of rounds a player has to wait for a rematch <ref> [10] </ref>. 11 a payoff lower then the security level N fl R const, and will opt out. Let r be the expected number of rounds a player waits for a rematch. <p> If the time needed to compute the optimizing strategy is proportional to N , a satisfying strategy is de facto optimal for a CB player. The possibility of opting out makes cooperative, non-vengeful strategies even stronger. This tool can be further developed into a strategy-designing tool <ref> [10] </ref>. 5 Conclusions In Section 2 of this paper we introduced the finite time repeated PD game, and the notion of complexity bounded players. In doing so, we encapsulated both the player's utility and his inductive power into one parameter: his payoff in the game.
Reference: [11] <author> Megiddo N. and Wigderson A. </author> <title> On play by means of computing machines. </title> <booktitle> In Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> pages 259-274, </pages> <address> Monterey California, </address> <month> March </month> <year> 1986. </year>
Reference-contexts: Most of the work on this subject has centered on various automata as models of bounded rationality; [13, 5, 4] and others (see [7] for an extensive bibliography) deal with finite state automata with a limited number of states, and <ref> [11] </ref> examines Turing machines with a bounded number of states. The main drawback of the automata approach is that cooperative behavior is usually achieved by "exhausting" the machine|designing a game pattern that is so complex that the machine has to use all its computational power to follow it.
Reference: [12] <author> M. Nowak and K. Sigmund. </author> <title> A strategy of win-stay lose-shift that outperforms tit-for-tat in the prisoner's dilemma game. </title> <journal> Nature, </journal> <volume> 364 </volume> <pages> 56-58, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Sections 3 and 4 of this paper deal with a similar variation on the repeated PD game, in which players have the possibility of opting out. Several researchers (see <ref> [12, 3] </ref> for examples and further bibliography) took Axelrod's lead and investigated evolutionary models of games. Most, if not all, of these works studied populations of deterministic or stochastic automata with a small number of states.
Reference: [13] <author> Christos H. Papadimitriou. </author> <title> On players with a bounded ,number of states. </title> <journal> Games and Economic Behavior, </journal> <volume> 4 </volume> <pages> 122-131, </pages> <year> 1992. </year> <month> 13 </month>
Reference-contexts: Hogg and Huberman [6] study the power of cooperation in distributed search problems. 2 famous computer tournament and analyzes social systems accordingly. Most of the work on this subject has centered on various automata as models of bounded rationality; <ref> [13, 5, 4] </ref> and others (see [7] for an extensive bibliography) deal with finite state automata with a limited number of states, and [11] examines Turing machines with a bounded number of states. <p> Such a pattern is highly non-robust and will collapse in the presence of noise. Papadimitriou, in <ref> [13] </ref>, analyzes a 3-player variant of the PD game. This game is played in two stages: first, every player chooses a partner, then if two players choose each other, they play PD. <p> The key idea is that any computational process takes time for the player. Technically, we will say that a CB player can perform at most k binary XORs in one clock tick, and k &lt; log 2 N . 3 Papadimitriou <ref> [13] </ref> makes a distinction between design complexity and decision complexity. In our model, decision complexity forces a player to play W, while design complexity is not yet handled. <p> A similar idea appears in <ref> [13] </ref>. While in the previous section we only altered the nature of the players and the concept of iteration, here we change the rules of the game. This requires some justification. The motivation for OPD is that it allows players greater flexibility in choosing strategies.
Reference: [14] <author> A. Rapoport, A. Chammah, J. Dwyer, and J. Gyr. Three-person non-zero-sum nonnegotiable games. </author> <booktitle> Behavioral Science, </booktitle> <volume> 7 </volume> <pages> 38-58, </pages> <year> 1962. </year>
Reference-contexts: The "always defect" equilibrium of PD is in a sense paradoxical; it contradicts some of our basic intuitions about intelligent behavior, and stands in contrast to psychological evidence <ref> [14] </ref>. The root of this paradox is the assumption of rationality, which implies unlimited computational power; it is precisely the unlimited computational power of rational agents that both allows and requires them to perform the unlimited backward induction in the repeated PD.
Reference: [15] <author> Herbert A. Simon. </author> <booktitle> The Sciences of the Artificial. </booktitle> <publisher> The MIT Press, </publisher> <address> Cambridge Massachusetts, </address> <year> 1969. </year>
Reference-contexts: Formally, if is the set of all possible populations of players, and (S) is the expected payoff of S then the security level SL (S) is: min fl2 fj the population is flg 7 Herbert Simon <ref> [15, 16] </ref> coined the term "Satisficing" as an alternative to "Maximizing." Although our approach is close in spirit to his, it differs in its formalism.
Reference: [16] <author> Herbert A. Simon. </author> <title> Models of Bounded Rationality. </title> <publisher> The MIT Press, </publisher> <address> Cambridge Massachusetts, </address> <year> 1983. </year>
Reference-contexts: Formally, if is the set of all possible populations of players, and (S) is the expected payoff of S then the security level SL (S) is: min fl2 fj the population is flg 7 Herbert Simon <ref> [15, 16] </ref> coined the term "Satisficing" as an alternative to "Maximizing." Although our approach is close in spirit to his, it differs in its formalism.
Reference: [17] <author> D. D. Sleator and R. E. Tarjan. </author> <title> Amortized efficiency of list rules. </title> <journal> STOC, </journal> <volume> 16 </volume> <pages> 488-492, </pages> <year> 1984. </year>
Reference-contexts: In order to evaluate satisfying strategies, we use the method of competitive analysis. Kaniel [8] names Sleator and Tarjan <ref> [17] </ref> as the initiators of this approach. The idea is to use the ratio between the satisfying strategy's payoff and that of a maximizing strategy as a quantifier of the satisfying strategy's performance. We begin by defining the concepts introduced above.
References-found: 17

