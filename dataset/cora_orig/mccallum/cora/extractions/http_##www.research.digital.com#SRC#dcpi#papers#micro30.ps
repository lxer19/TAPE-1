URL: http://www.research.digital.com/SRC/dcpi/papers/micro30.ps
Refering-URL: http://www.research.digital.com/SRC/dcpi/pubs-and-talks.html
Root-URL: http://www.research.digital.com
Title: ProfileMe: Hardware Support for Instruction-Level Profiling on Out-of-Order Processors  
Author: Jeffrey Dean James E. Hicks Carl A. Waldspurger William E. Weihl George Chrysos 
Affiliation: Digital Equipment Corporation  
Abstract: Profile data is valuable for identifying performance bottlenecks and guiding optimizations. Periodic sampling of a processor's performance monitoring hardware is an effective, unobtrusive way to obtain detailed profiles. Unfortunately, existing hardware simply counts events, such as cache misses and branch mispredictions, and cannot accurately attribute these events to instructions, especially on out-of-order machines. We propose an alternative approach, called ProfileMe, that samples instructions. As a sampled instruction moves through the processor pipeline, a detailed record of all interesting events and pipeline stage latencies is collected. ProfileMe also support paired sampling, which captures information about the interactions between concurrent instructions, revealing information about useful concurrency and the utilization of various pipeline stages while an instruction is in flight. We describe an inexpensive hardware implementation of ProfileMe, outline a variety of software techniques to extract useful profile information from the hardware, and explain several ways in which this information can provide valuable feedback for programmers and optimizers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. G. Abraham and B. R. Rau. </author> <title> Predicting load latencies using cache profiling. </title> <type> Technical Report HPL-94-110, </type> <institution> Hewlett Packard Laboratories, </institution> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Improved instruction scheduling: One important aspect of instruction scheduling is the insertion of prefetches and the scheduling of loads and stores. The lack of information about actual latencies means that compilers schedule loads and stores assuming that they will hit in the data cache. Abraham and Rau <ref> [1] </ref> have experimented with using average load latencies to drive compiler optimizations, and more recently Luk and Mowry [13] have explored the use of path information to identify loads whose cache miss behavior is correlated with the execution path taken to reach the load.
Reference: [2] <author> J. Anderson, L. M. Berc, J. Dean, S. Ghemawat, M. R. Henzinger, S.-T. Leung, R. L. Sites, M. T. Vandevoorde, C. A. Waldspurger, and W. E. Weihl. </author> <title> Continuous profiling: Where have all the cycles gone? In Proc. </title> <booktitle> 16th Symp. on Operating System Principles, </booktitle> <month> Oct. </month> <year> 1997. </year>
Reference-contexts: Sampling has a number of advantages over other profiling methods, such as simulation or instrumentation: it works on unmodified programs, it profiles complete systems, and it can have very low overhead. Indeed, recent work <ref> [2] </ref> has shown that low-overhead sampling-based profiling can reveal detailed instruction-level information about pipeline stalls and their causes, and that this sort of information is extremely helpful in diagnosing and fixing performance problemsbut that work is limited to in-order processors, and its techniques do not extend to out-of-order processors. <p> By restricting the number of instructions simultaneously profiledto one or two instructionswe limit the hardware overhead. The run-time profiling overhead may be decreased arbitrarily by reducing the sampling rate, although previous work has shown that high frequency sampling can be implemented with relatively low overhead through careful programming <ref> [2] </ref>. <p> This latency is required to determine the degree of overlap of the instruction pair in the processor pipeline. 4.3 Amortizing Interrupt Delivery Costs Previous work has shown that the cost of delivering and processing performance interrupts is one of the most significant sources of overhead in sampling-based profiling systems <ref> [2] </ref>. ProfileMe makes it possible to reduce this overhead by providing additional hardware copies of profile registers and by buffering multiple samples before delivering a performance interrupt. <p> Space consumption can be reduced by processing some of the information as the samples are gathered, such as by aggregating samples for the same instruction, as is done for event-counter-based samples in DIGITAL's Continuous Profiling Infrastructure (DCPI) system <ref> [2] </ref>. Overhead can be further reduced by ignoring certain fields of the profile informa-tion except when gathering data for specific optimizations. Once the profile information has been collected, it can be analyzed to extract useful information. <p> An important attribute of our approach is that the com ponents of a metric such as wasted issue slots can be aggregated incrementally, enabling compact storage during data collection (as in the DCPI profiling system <ref> [2] </ref>). 5.2.4 Flexible Support for Concurrency Metrics Many other concurrency metrics can be estimated in a similar manner, such as the number of instructions that retired while I was in flight, or the number of instructions that issued around I.
Reference: [3] <author> T. Ball and J. R. Larus. </author> <title> Efficient path profiling. </title> <booktitle> In Proc. 29th Annual Intl. Symp. on Microarchitecture, </booktitle> <pages> pages 4657, </pages> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: Frequently executed paths were conventionally estimated by gathering basic block or control-flow graph edge counts and then using these counts to infer the hot paths. More recently, Ball and Larus <ref> [3] </ref> and Young et al. [19] proposed more advanced profiling methods to gather detailed path information directly. Although such techniques yield exact path counts, they require instrumenting the program and are therefore expensive and intrusive.
Reference: [4] <author> B. N. Bershad, D. Lee, T. H. Romer, and J. B. Chen. </author> <title> Avoiding conflict misses dynamically in large direct-mapped caches. </title> <booktitle> In Proc. Sixth Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 158170, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: ProfileMe provides a cheap way of gathering the data needed to drive these optimizations. Cache and TLB hit rate enhancement: Recent studies have shown that dynamically controlling the operating system's virtual-to-physical mapping policies using information about dynamic reference patterns can reduce conflict misses in large direct-mapped caches <ref> [4, 15] </ref>, lower TLB miss rates through the creation of superpages [16], and decrease the number of remote memory references in NUMA-based multiprocessors through replication and migration of pages [17]. <p> In many respects, these two designs are complementary: informing memory operations permit software to gain control very quickly after a cache miss, while a ProfileMe record contains more detailed information about an instruction's execution that can be used for later analysis. Bershad et al. <ref> [4] </ref> proposed specialized hardware called a cache miss lookaside (CML) buffer to identify virtual memory pages that suffer from a high L2 cache miss rate. Using the effective addresses and the latency information for loads and stores captured by ProfileMe, we can provide the same information as a CML buffer.
Reference: [5] <author> R. Cohn and P. G. Lowney. </author> <title> Hot cold optimization of large Windows/NT applications. </title> <booktitle> In Proc. 29th Annual Intl. Symp. on Microar-chitecture, </booktitle> <pages> pages 8089, </pages> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: a single concurrency metric, this flexibility makes paired sampling an attractive choice for capturing concurrency in formation on complex, out-of-order processors, because it leaves the door open for the design of new metrics and analysis techniques. 5.3 Path Profiles Many compiler optimizations, such as trace scheduling [9] and hot-cold optimization <ref> [5] </ref>, rely on predicting the heavily executed paths through a program. Frequently executed paths were conventionally estimated by gathering basic block or control-flow graph edge counts and then using these counts to infer the hot paths.
Reference: [6] <author> T. M. Conte, K. N. Menezes, and M. A. Hirsch. </author> <title> Accurate and practical profile-driven compilation using the profile buffer. </title> <booktitle> In Proc. 29th Annual Intl. Symp. on Microarchitecture, </booktitle> <pages> pages 3645, </pages> <month> Dec. </month> <year> 1996. </year>
Reference-contexts: Some processors, such as the Intel Pentium, have software readable branch target buffers (BTB). Conte et al. [7] showed how to cheaply estimate a program's edge execution frequencies by periodically reading the contents of the BTB. More recently, Conte et al. <ref> [6] </ref> proposed additional hardware called a profile buffer, which counts the number of times a branch is taken and not-taken.
Reference: [7] <author> T. M. Conte, B. A. Patel, and J. S. Cox. </author> <title> Using branch handling hardware to support profile-driven optimization. </title> <booktitle> In Proc. 27th Annual Intl. Symp. on Microarchitecture, </booktitle> <pages> pages 1221, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Using the effective addresses and the latency information for loads and stores captured by ProfileMe, we can provide the same information as a CML buffer. Some processors, such as the Intel Pentium, have software readable branch target buffers (BTB). Conte et al. <ref> [7] </ref> showed how to cheaply estimate a program's edge execution frequencies by periodically reading the contents of the BTB. More recently, Conte et al. [6] proposed additional hardware called a profile buffer, which counts the number of times a branch is taken and not-taken.
Reference: [8] <author> Digital Equipment Corporation. </author> <title> Alpha 21164 Microprocessor Hardware Reference Manual. </title> <address> Maynard, MA, </address> <year> 1995. </year> <title> Order Number EC-QAEQB-TE. </title>
Reference-contexts: Most modern microprocessors, including the Alpha 21164 <ref> [8] </ref>, Pentium Pro [11] and R10000 [14], provide performance counters that count a variety of events (e.g., branch mispredicts or data cache misses) and deliver an interrupt when the counters overflow. Event counters provide useful aggregate information, such as the total number of branch mispredicts during a program run. <p> Aside from the wide distribution of event samples, hardware event counters suffer from several additional problems. First, performance-counter interrupts may be deferred when running non-interruptible or high-priority system code, such as Alpha PALcode <ref> [8] </ref>. As a result, event samples will be incorrectly attributed to the instruction following the high-priority code, resulting in undesirable blind spots. In addition, there are typically many more events of interest than there are hardware counters, making it impossible to concurrently monitor all interesting events.
Reference: [9] <author> J. A. Fisher. </author> <title> Trace scheduling: A technique for global microcode compaction. </title> <journal> IEEE Trans. on Computing, </journal> <volume> 30(7):478490, </volume> <month> July </month> <year> 1981. </year>
Reference-contexts: mechanisms designed to measure a single concurrency metric, this flexibility makes paired sampling an attractive choice for capturing concurrency in formation on complex, out-of-order processors, because it leaves the door open for the design of new metrics and analysis techniques. 5.3 Path Profiles Many compiler optimizations, such as trace scheduling <ref> [9] </ref> and hot-cold optimization [5], rely on predicting the heavily executed paths through a program. Frequently executed paths were conventionally estimated by gathering basic block or control-flow graph edge counts and then using these counts to infer the hot paths.
Reference: [10] <author> M. Horowitz, M. Martonosi, T. C. Mowry, and M. D. Smith. </author> <title> Informing memory operations: Providing memory performance feedback in modern processors. </title> <booktitle> In Proc. 23nd Annual Intl. Symp. on Computer Architecture, </booktitle> <pages> pages 260270, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: ProfileMe also collects additional information for each sampled instruction, including branch directions, global branch histories, and branch mispredict information, all of which are useful for identifying the common paths. More recently, Horowitz et al. <ref> [10] </ref> proposed a hardware mechanism called informing loads, in which a memory operation can be followed by a conditional branch operation that is taken only if the memory operation misses in the cache.
Reference: [11] <author> Intel Corporation. </author> <title> Pentium(R) Pro Processor Developer's Manual. </title> <publisher> McGraw-Hill, </publisher> <month> June </month> <year> 1997. </year>
Reference-contexts: Most modern microprocessors, including the Alpha 21164 [8], Pentium Pro <ref> [11] </ref> and R10000 [14], provide performance counters that count a variety of events (e.g., branch mispredicts or data cache misses) and deliver an interrupt when the counters overflow. Event counters provide useful aggregate information, such as the total number of branch mispredicts during a program run.
Reference: [12] <author> D. Leibholz and R. Razdan. </author> <title> The Alpha 21264: A 500 MHz Out-of-Order Execution Microprocessor. </title> <booktitle> In IEEE CompCon'97, </booktitle> <month> Feb. </month> <year> 1997. </year>
Reference-contexts: Figure 1 depicts the pipeline of the Alpha 21264 processor <ref> [12] </ref>. Each cycle, the first stage of the pipeline fetches and decodes a group of instructions from the instruction cache starting at the current PC.
Reference: [13] <author> C.-K. Luk and T. C. Mowry. </author> <title> Predicting data cache misses in non-numeric applications through correlation profiling. </title> <booktitle> In Proc. 30th Annual Intl. Symp. on Microarchitecture, </booktitle> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: The lack of information about actual latencies means that compilers schedule loads and stores assuming that they will hit in the data cache. Abraham and Rau [1] have experimented with using average load latencies to drive compiler optimizations, and more recently Luk and Mowry <ref> [13] </ref> have explored the use of path information to identify loads whose cache miss behavior is correlated with the execution path taken to reach the load. ProfileMe provides a cheap way of gathering the data needed to drive these optimizations.
Reference: [14] <author> MIPS Technologies, Inc. </author> <title> MIPS R10000 Microprocessor User's Manual. </title> <address> Mountain View, CA, </address> <year> 1995. </year>
Reference-contexts: Most modern microprocessors, including the Alpha 21164 [8], Pentium Pro [11] and R10000 <ref> [14] </ref>, provide performance counters that count a variety of events (e.g., branch mispredicts or data cache misses) and deliver an interrupt when the counters overflow. Event counters provide useful aggregate information, such as the total number of branch mispredicts during a program run. <p> This smeared distribution of samples makes it nearly impossible to attribute an event to the instruction that caused it. Similar behavior occurs when counting other hardware events. This problem is also not specific to the Pentium Pro: we have observed similar behavior with the MIPS R10000's hardware event counters <ref> [14] </ref>. Aside from the wide distribution of event samples, hardware event counters suffer from several additional problems. First, performance-counter interrupts may be deferred when running non-interruptible or high-priority system code, such as Alpha PALcode [8].
Reference: [15] <author> T. H. Romer, D. Lee, B. N. Bershad, and J. B. Chen. </author> <title> Dynamic page mapping policies for cache conflict resolution on standard hardware. </title> <booktitle> In Proc. First Symp. on Operating Systems Design and Implementation, </booktitle> <pages> pages 255266, </pages> <year> 1994. </year>
Reference-contexts: ProfileMe provides a cheap way of gathering the data needed to drive these optimizations. Cache and TLB hit rate enhancement: Recent studies have shown that dynamically controlling the operating system's virtual-to-physical mapping policies using information about dynamic reference patterns can reduce conflict misses in large direct-mapped caches <ref> [4, 15] </ref>, lower TLB miss rates through the creation of superpages [16], and decrease the number of remote memory references in NUMA-based multiprocessors through replication and migration of pages [17].
Reference: [16] <author> T. H. Romer, W. H. Ohlrich, A. R. Karlin, and B. N. Bershad. </author> <title> Reducing TLB and memory overhead using online superpage promotion. </title> <booktitle> In Proc. 22nd Annual Intl. Symp. on Computer Architecture, </booktitle> <pages> pages 176187, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Cache and TLB hit rate enhancement: Recent studies have shown that dynamically controlling the operating system's virtual-to-physical mapping policies using information about dynamic reference patterns can reduce conflict misses in large direct-mapped caches [4, 15], lower TLB miss rates through the creation of superpages <ref> [16] </ref>, and decrease the number of remote memory references in NUMA-based multiprocessors through replication and migration of pages [17].
Reference: [17] <author> B. Verghese, S. Devine, A. Gupta, and M. Rosenblum. </author> <title> Operating system support for improving data locality on CC-NUMA compute servers. </title> <booktitle> In Proc. Seventh Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 279289, </pages> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: controlling the operating system's virtual-to-physical mapping policies using information about dynamic reference patterns can reduce conflict misses in large direct-mapped caches [4, 15], lower TLB miss rates through the creation of superpages [16], and decrease the number of remote memory references in NUMA-based multiprocessors through replication and migration of pages <ref> [17] </ref>. All of these schemes gather reference pattern information through either specialized hardware for gather ing cache miss addresses or specialized software schemes (e.g., flushing the TLB and observing the miss pattern that results).
Reference: [18] <author> D. W. Westcott and V. White. </author> <title> Instruction sampling instrumentation, </title> <month> Sept. </month> <year> 1992. </year> <type> U.S. Patent #5,151,981, </type> <institution> assigned to International Business Machines Corporation. </institution>
Reference-contexts: miss in the cache or TLB, ProfileMe provides the information needed to guide these policies, without additional hardware complexity. 8 Related Work The work most closely related to ProfileMe is a patent by Westcott and White, who also proposed a hardware mechanism for instruction-based sampling in an out-of-order execution machine <ref> [18] </ref>. Their system allows profiling of an instruction when its execution is assigned a particular internal instruction number instruction identifier (IID) in the processor's pipeline.
Reference: [19] <author> C. Young and M. D. Smith. </author> <title> Improving the accuracy of static branch prediction using branch correlation. </title> <booktitle> In Proc. Sixth Intl. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 232241, </pages> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: Frequently executed paths were conventionally estimated by gathering basic block or control-flow graph edge counts and then using these counts to infer the hot paths. More recently, Ball and Larus [3] and Young et al. <ref> [19] </ref> proposed more advanced profiling methods to gather detailed path information directly. Although such techniques yield exact path counts, they require instrumenting the program and are therefore expensive and intrusive.
References-found: 19

