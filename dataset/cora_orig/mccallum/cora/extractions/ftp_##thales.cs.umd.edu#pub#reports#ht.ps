URL: ftp://thales.cs.umd.edu/pub/reports/ht.ps
Refering-URL: ftp://thales.cs.umd.edu/pub/reports/Contents.html
Root-URL: 
Title: On Hyperbolic Triangularization: Stability and Pivoting  
Author: Michael Stewart G. W. Stewart 
Address: Mary-land, College Park, MD 20742.This  
Note: 0200. This work was supported in part by the Department of the Airforce under Grant F496220-95-1-0525-P00001  work was supported in part by the National Science Foundation under grant CCR 95503126.  
Date: March 1997 (Revised Novermber 1997)  
Affiliation: University of Maryland College Park Institute for Advanced Computer Studies TR-97-34 Department of Computer Science  Computer Sciences Laboratory, Research School of Information Sciences and Engineering, Aus-tralian National University, Canberra ACT  Department of Computer Science and Institute for Advanced Computer Studies, University of  
Pubnum: TR-3774  
Abstract: This paper treats the problem of triangularizing a matrix by hyperbolic Householder transformations. The stability of this method, which finds application in block updating and fast algorithms for Toeplitz-like matrices, has been analyzed only in special cases. Here we give a general analysis which shows that two distinct implementations of the individual transformations are relationally stable. The analysis also shows that pivoting is required for the entire triangularization algorithm to be stable. fl his report is available by anonymous ftp from thales.cs.umd.edu in the directory pub/reports or on the web at http://www.cs.umd.edu/ stewart/. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. N. Atkinson. </author> <title> Computing A T A B T B = L T DL using generalized hyperbolic transformations. </title> <journal> Linear Algebra and Its Applications, </journal> <volume> 194 </volume> <pages> 135-148, </pages> <year> 1993. </year> <title> Hyperbolic Triangularization 17 </title>
Reference-contexts: Although the problem can be treated as an update followed by a downdate, it is natural to treat in on its own Hyperbolic Triangularization 3 terms. The problem has been considered by Cybenko and Berry [7] in connection with fast algorithms for Toeplitz-like matrices and also by Atkinson <ref> [1] </ref>. Mixed problems arise naturally in computing the hyperbolic SVD; a description of the decomposition and signal processing applications are in [13]. The major contribution of this paper is a rounding-error analysis of the use of hyperbolic Householder transformations in the mixed problem. <p> The matrices R and R + will, in general, be well conditioned, and R + was obtained by a process involving a mixed update and downdate. The following display indicates the relation between the matrices ( indicates updating and downdating). R = (R 0 X) Z X <ref> [1; :] </ref> and R + = R 0 Y: We then took the algorithm through the valley of death by downdating Z and the last m 1 rows of X to get a matrix ~ R 0 , which in exact arithmethic would be R 0 , and then updating with
Reference: [2] <author> V. Belovitch. </author> <title> Classical Network Theory. Holden Day, </title> <address> San Francisco, CA, </address> <year> 1968. </year>
Reference-contexts: in which kc 1 k 2 kb 2 k 2 = kb 1 k 2 kc 2 k 2 : 1 Paul Van Dooren has informed us that the result is a folk theorem in circuit theory, although references to the general result seem to be hard to find (see <ref> [2] </ref> for a special case). The proof is adapted from a communication by Van Dooren.
Reference: [3] <author> A. Bjorck. </author> <title> Numerical Methods for Least Squares Problems. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1996. </year>
Reference-contexts: An obvious problem is that ^ A can be indefinite, in which case the problem has no (real) solution. A more subtle problem is that information present in the original problem may be only imperfectly represented in the Cholesky factor. For more on this see <ref> [17, 3] </ref>. The solution to the downdating problem may also be cast in terms of an orthogonal transformation. In particular, if Q R ! Y (1.1) then ^ R T ^ R = A Y T Y .
Reference: [4] <author> A. Bojanczyk, R. P. Brent, P. Van Dooren, and F. de Hoog. </author> <title> A note on downdating the Cholesky factorization. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 8 </volume> <pages> 210-221, </pages> <year> 1987. </year>
Reference-contexts: In consequence, if a Cholesky factor in the sequence is well conditioned it will be accurately computed. By way of previous results, relational stability was established in [17] for the linpack algorithm, in [5] for the block downdating problem and in <ref> [4] </ref> for the algorithm of [6]. The fact that downdating can be cast in terms of both orthogonal and S-orthogonal matrices suggests that there is a close relation between the two classes.
Reference: [5] <author> A. W. Bojanczyk and A. O. Steinhardt. </author> <title> Stability analysis of a Householder-based algorithm for downdating the Cholesky factorization. </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> 12 </volume> <pages> 1255-1265, </pages> <year> 1991. </year>
Reference-contexts: In [18] it is shown that relational stability is preserved under repeated updates and downdates. In consequence, if a Cholesky factor in the sequence is well conditioned it will be accurately computed. By way of previous results, relational stability was established in [17] for the linpack algorithm, in <ref> [5] </ref> for the block downdating problem and in [4] for the algorithm of [6]. The fact that downdating can be cast in terms of both orthogonal and S-orthogonal matrices suggests that there is a close relation between the two classes.
Reference: [6] <author> J. M. Chambers. </author> <title> Regression updating. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 66 </volume> <pages> 744-748, </pages> <year> 1971. </year>
Reference-contexts: In practice the matrix Q is usually computed as a product of hyperbolic rotations <ref> [10, 6] </ref> or hyperbolic Householder transformations [14, 15]. In this paper we will be concerned with the mixed updating problem of calculating the Cholesky factor of A + X T X Y T Y from that of A. <p> In consequence, if a Cholesky factor in the sequence is well conditioned it will be accurately computed. By way of previous results, relational stability was established in [17] for the linpack algorithm, in [5] for the block downdating problem and in [4] for the algorithm of <ref> [6] </ref>. The fact that downdating can be cast in terms of both orthogonal and S-orthogonal matrices suggests that there is a close relation between the two classes. In x2 we will show that there is indeed a general correspondence between orthogonal matrices with nonsingular principle minors and S-orthogonal matrices. <p> An important special case is when Q 11 is a scalar. In particular, if Q is a hyperbolic rotation | i.e., x and y are scalars | the second and third strategies listed above yield a mixed algorithm, first presented in <ref> [6] </ref>, that is relationally stable. Another case is when only x is a scalar and Q is a Householder transformation. Again the second and third strategies yield a relationally stable algorithm [14, 15]. 3.
Reference: [7] <author> G. Cybenko and M. Berry. </author> <title> Hyperbolic Householder algorithms for factoring structured matrices. </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 11 </volume> <pages> 499-520, </pages> <year> 1990. </year>
Reference-contexts: Although the problem can be treated as an update followed by a downdate, it is natural to treat in on its own Hyperbolic Triangularization 3 terms. The problem has been considered by Cybenko and Berry <ref> [7] </ref> in connection with fast algorithms for Toeplitz-like matrices and also by Atkinson [1]. Mixed problems arise naturally in computing the hyperbolic SVD; a description of the decomposition and signal processing applications are in [13].
Reference: [8] <author> J. J. Dongarra, J. R. Bunch, C. B. Moler, and G. W. Stewart. </author> <title> LINPACK User's Guide. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1979. </year>
Reference-contexts: Thus if Q is chosen so that ^ R is triangular, then ^ R is the solution to the downdating problem. Computing such an orthogonal transformation is the basis of a class of algorithms | linpack-type algorithms | for this problem see <ref> [8, 9, 16] </ref>. The Cholesky downdating problem can be solved more directly by an analogue of orthogonal triangularization which we will call hyperbolic triangularization. Specifically, a signature matrix is a diagonal matrix whose diagonal elements are 1.
Reference: [9] <author> L. Elden and H. Park. </author> <title> Block downdating of least squares solutions. </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 15 </volume> <pages> 1018-1034, </pages> <year> 1992. </year>
Reference-contexts: Thus if Q is chosen so that ^ R is triangular, then ^ R is the solution to the downdating problem. Computing such an orthogonal transformation is the basis of a class of algorithms | linpack-type algorithms | for this problem see <ref> [8, 9, 16] </ref>. The Cholesky downdating problem can be solved more directly by an analogue of orthogonal triangularization which we will call hyperbolic triangularization. Specifically, a signature matrix is a diagonal matrix whose diagonal elements are 1.
Reference: [10] <author> G. H. Golub. </author> <title> Matrix decompositions and statistical computation. </title> <editor> In R. C. Milton and J. A. Nelder, editors, </editor> <booktitle> Statistical Computation, </booktitle> <pages> pages 365-397, </pages> <address> New York, 1969. </address> <publisher> Academic Press. </publisher>
Reference-contexts: In practice the matrix Q is usually computed as a product of hyperbolic rotations <ref> [10, 6] </ref> or hyperbolic Householder transformations [14, 15]. In this paper we will be concerned with the mixed updating problem of calculating the Cholesky factor of A + X T X Y T Y from that of A.
Reference: [11] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland, 2nd edition, </address> <year> 1989. </year>
Reference-contexts: The matrix Q is usually generated as a product of Householder transformations or plane rotations. For details see, e.g., <ref> [11] </ref>. Now let Y be an n fi p matrix. The Cholesky downdating problem is to calculate the Cholesky factor ^ R of ^ A = A Y T Y from that of A. The downdating problem is 2 Hyperbolic Triangularization known to be difficult.
Reference: [12] <author> N. J. Higham. </author> <title> Accuracy and Stability of Numerical Algorithms. </title> <publisher> SIAM, </publisher> <address> Philadel-phia, </address> <year> 1996. </year>
Reference-contexts: Here is the computed quantity. The transformation is computed from x 1 and y 1 . 10 Hyperbolic Triangularization We will assume that the reader is familiar with the basics of rounding error analysis (see, e.g., <ref> [12] </ref>). Computations are assumed to be done in floating-point arithmetic with rounding unit * M . Since the object of the analysis is to establish relational stability and not to derive detailed error bounds, we will introduce the following notational simplification.
Reference: [13] <author> R. Onn, A. O. Steinhardt and A. Bojanczyk. </author> <title> The hyperbolic singular value decomposition and applications. </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> 39 </volume> <pages> 1575-1588, </pages> <year> 1991. </year>
Reference-contexts: The problem has been considered by Cybenko and Berry [7] in connection with fast algorithms for Toeplitz-like matrices and also by Atkinson [1]. Mixed problems arise naturally in computing the hyperbolic SVD; a description of the decomposition and signal processing applications are in <ref> [13] </ref>. The major contribution of this paper is a rounding-error analysis of the use of hyperbolic Householder transformations in the mixed problem.
Reference: [14] <author> C. M. Rader and A. O. Steinhardt. </author> <title> Hyperbolic Householder transformations. </title> <journal> IEEE Transactions on Acoustics, Speech and Signal Processing, </journal> <volume> 34 </volume> <pages> 1589-1602, </pages> <year> 1986. </year>
Reference-contexts: In practice the matrix Q is usually computed as a product of hyperbolic rotations [10, 6] or hyperbolic Householder transformations <ref> [14, 15] </ref>. In this paper we will be concerned with the mixed updating problem of calculating the Cholesky factor of A + X T X Y T Y from that of A. <p> Another case is when only x is a scalar and Q is a Householder transformation. Again the second and third strategies yield a relationally stable algorithm <ref> [14, 15] </ref>. 3. Hyperbolic Householder transformations and hyperbolic triangularization The correspondence result of the last section provides a natural way to move from elementary orthogonal transformations, which are used in updating, to S-orthogonal equivalents, which are used in downdating. <p> We shall see presently that singularity does not arise in our applications. Following the natural correspondence between the orthogonal and S-orthogonal cases, we refer to H as a hyperbolic Householder transformation. The hyperbolic Householder transformations of <ref> [14, 15] </ref> are symmetric and have the form S + uu T =c. Compu-tationally the two forms are essentially the same. However, the form given here relates more naturally via the correspondence theorem to standard Householder transformations.
Reference: [15] <author> C. M. Rader and A. O. Steinhardt. </author> <title> Hyperbolic Householder transforms. </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 9 </volume> <pages> 269-290, </pages> <year> 1988. </year> <note> Cited in [3]. 18 Hyperbolic Triangularization </note>
Reference-contexts: In practice the matrix Q is usually computed as a product of hyperbolic rotations [10, 6] or hyperbolic Householder transformations <ref> [14, 15] </ref>. In this paper we will be concerned with the mixed updating problem of calculating the Cholesky factor of A + X T X Y T Y from that of A. <p> Another case is when only x is a scalar and Q is a Householder transformation. Again the second and third strategies yield a relationally stable algorithm <ref> [14, 15] </ref>. 3. Hyperbolic Householder transformations and hyperbolic triangularization The correspondence result of the last section provides a natural way to move from elementary orthogonal transformations, which are used in updating, to S-orthogonal equivalents, which are used in downdating. <p> We shall see presently that singularity does not arise in our applications. Following the natural correspondence between the orthogonal and S-orthogonal cases, we refer to H as a hyperbolic Householder transformation. The hyperbolic Householder transformations of <ref> [14, 15] </ref> are symmetric and have the form S + uu T =c. Compu-tationally the two forms are essentially the same. However, the form given here relates more naturally via the correspondence theorem to standard Householder transformations.
Reference: [16] <author> M. A. Saunders. </author> <title> Large-scale linear programming using the Cholesky factorization. </title> <type> Technical Report CS252, </type> <institution> Computer Science Department, Stanford University, </institution> <year> 1972. </year> <note> Cited in [3]. </note>
Reference-contexts: Thus if Q is chosen so that ^ R is triangular, then ^ R is the solution to the downdating problem. Computing such an orthogonal transformation is the basis of a class of algorithms | linpack-type algorithms | for this problem see <ref> [8, 9, 16] </ref>. The Cholesky downdating problem can be solved more directly by an analogue of orthogonal triangularization which we will call hyperbolic triangularization. Specifically, a signature matrix is a diagonal matrix whose diagonal elements are 1.
Reference: [17] <author> G. W. Stewart. </author> <title> The effects of rounding error on an algorithm for downdating a Cholesky factorization. </title> <journal> Journal of the Institute for Mathematics and Applications, </journal> <volume> 23 </volume> <pages> 203-213, </pages> <year> 1979. </year>
Reference-contexts: An obvious problem is that ^ A can be indefinite, in which case the problem has no (real) solution. A more subtle problem is that information present in the original problem may be only imperfectly represented in the Cholesky factor. For more on this see <ref> [17, 3] </ref>. The solution to the downdating problem may also be cast in terms of an orthogonal transformation. In particular, if Q R ! Y (1.1) then ^ R T ^ R = A Y T Y . <p> Instead we call it relational stability. In [18] it is shown that relational stability is preserved under repeated updates and downdates. In consequence, if a Cholesky factor in the sequence is well conditioned it will be accurately computed. By way of previous results, relational stability was established in <ref> [17] </ref> for the linpack algorithm, in [5] for the block downdating problem and in [4] for the algorithm of [6]. The fact that downdating can be cast in terms of both orthogonal and S-orthogonal matrices suggests that there is a close relation between the two classes.
Reference: [18] <author> G. W. Stewart. </author> <title> On the stability of sequential updates and downdates. </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> 43 </volume> <pages> 1643-1648, </pages> <year> 1995. </year>
Reference-contexts: Since it is not possible to associate E exclusively with with the original data R, X and Y , this result is not backward stability. Instead we call it relational stability. In <ref> [18] </ref> it is shown that relational stability is preserved under repeated updates and downdates. In consequence, if a Cholesky factor in the sequence is well conditioned it will be accurately computed.
References-found: 18

