URL: http://www.cs.huji.ac.il/papers/IP/eccv96-dual.ps.gz
Refering-URL: http://www.cs.huji.ac.il/papers/IP/arpa.html
Root-URL: http://www.cs.huji.ac.il
Email: fwerman,daphnag@cs.huji.ac.il  
Phone: 2  
Title: Duality of multi-point and multi-frame Geometry: Fundamental Shape Matrices and Tensors  
Author: Daphna Weinshall Michael Werman and Amnon Shashua 
Address: Jerusalem 91904, Israel  32000 Haifa, Israel  
Affiliation: 1 Inst. of Computer Science, Hebrew University,  Dept. of Computer Science, Technion,  
Abstract: We provide a complete analysis of the geometry of N points in 1 image, employing a formalism in which multi-frame and multi-point geometries appear in symmetry: points and projections are interchangeable. We derive bilinear equations for 6 points, trilinear equations for 7 points, and quadrilinear equations for 8 points. The new equations are used to design new algorithms for the reconstruction of projective shape from many frames. Shape is represented by shape descriptors, which are sufficient for object recognition, and for the simulation of new images of the object. We further propose a linear shape reconstruction scheme which uses all the available data all points and all frames - simultaneously. Unlike previous approaches, the equations developed here lead to direct and linear computation of shape, without going through the cameras' geometry.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> S. Carlsson. </author> <title> Duality of reconstruction and positioning from projective views. </title> <booktitle> In IEEE Workshop on Representations of Visual Scenes, </booktitle> <address> Cambridge, Mass, </address> <year> 1995. </year>
Reference-contexts: This analysis provides the foundation for a computation where shape is computed first, and camera geometry second. A similar analysis was presented by Carlsson in <ref> [1] </ref> (see also [15]). More specifically, in Section 2 we show dual results to the ones obtained by computing camera geometry first. <p> We first observe that a projection matrix from a 3D projective world to a 2D projective image is really a point in P 3 (a geometrical interpretation of this point is given in <ref> [1] </ref>). We then observe that the relations between models, projections, and images can be written in a symmetrical form where models and projections are interchangeable. Using these observations, for every known relation between images and projection matrices we can derive a dual relation between images and models. <p> a basis in P 3 to a basis in P 2 , the projection matrix P is of the form [2]: P = 6 4 0 fi 0 ffi 3 7 We define a corresponding projection vector in P 3 (a geometrical interpretation of this vector can be found in <ref> [1] </ref>): p = ( ff fi fl ffi ) 2.2 Multi-frame and multi-point geometry Using Eq. (2) with the 5 + i model point M i and the j-th frame obtained by the projection camera p j , producing the image point (x ji ; y ji ; 1) gives: x <p> We selected a "good" basis of 5 points, using the procedure described in [14]. In each image, we transformed 4 of the basis points to the non-standard basis of P 2 : <ref> [1; 0; 1] </ref>, [0; 1; 1], [0; 0; 1], [1; 1; 1]. We used the image coordinates of the 5th point, and the x coordinate of the 6th point, to compute the shape of the remaining points as described above. <p> We selected a "good" basis of 5 points, using the procedure described in [14]. In each image, we transformed 4 of the basis points to the non-standard basis of P 2 : [1; 0; 1], <ref> [0; 1; 1] </ref>, [0; 0; 1], [1; 1; 1]. We used the image coordinates of the 5th point, and the x coordinate of the 6th point, to compute the shape of the remaining points as described above. <p> We selected a "good" basis of 5 points, using the procedure described in [14]. In each image, we transformed 4 of the basis points to the non-standard basis of P 2 : [1; 0; 1], [0; 1; 1], <ref> [0; 0; 1] </ref>, [1; 1; 1]. We used the image coordinates of the 5th point, and the x coordinate of the 6th point, to compute the shape of the remaining points as described above. <p> We selected a "good" basis of 5 points, using the procedure described in [14]. In each image, we transformed 4 of the basis points to the non-standard basis of P 2 : [1; 0; 1], [0; 1; 1], [0; 0; 1], <ref> [1; 1; 1] </ref>. We used the image coordinates of the 5th point, and the x coordinate of the 6th point, to compute the shape of the remaining points as described above. <p> The situation under perspective projection is more complex: [6, 7, 10, 4] (among others) showed how to linearly compute the camera calibration from 2-4 frames using all the points. Here (as well as in <ref> [1] </ref>) we showed how to linearly compute the projective shape of 6-8 points from all the frames. We also showed a 2-step algorithm to linearly compute the projective shape of all the points from all the frames.
Reference: 2. <author> O. Faugeras. </author> <booktitle> What can be seen in three dimensions with an uncalibrated stereo rig? In Proceedings of the 2nd European Conference on Computer Vision, </booktitle> <pages> pages 563-578, </pages> <address> Santa Margherita Ligure, Italy, 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: equality holds in P 2 : P M = m (2) Given our particular selection of projective bases, and using the fact that the first 4 points are transformed from a basis in P 3 to a basis in P 2 , the projection matrix P is of the form <ref> [2] </ref>: P = 6 4 0 fi 0 ffi 3 7 We define a corresponding projection vector in P 3 (a geometrical interpretation of this vector can be found in [1]): p = ( ff fi fl ffi ) 2.2 Multi-frame and multi-point geometry Using Eq. (2) with the 5 +
Reference: 3. <author> O. Faugeras and B. Mourrain. </author> <title> On the geometry and algebra of the point and line correspondences between N images. In Proceeding of the Europe-China Workshop on geometrical modeling and invariant for computer vision. </title> <publisher> Xidian University Press, </publisher> <year> 1995. </year>
Reference-contexts: shape descriptions are sufficient for the identification of novel images of the same object, and for the prediction of new images, as described in Section 5. 2 Algebraic and Geometrical derivation of Results In this section we derive bilinear, trilinear, and quadrilinear relations using a formalism analogous (but dual) to <ref> [3] </ref>. We show duality between multi-frame and multi-point geometries: every relation between the vector coordinates of one point in many images has an almost identical equivalent here, a relation between the vector coordinates of many points in 1 image.
Reference: 4. <author> R. </author> <title> Hartley. Lines and points in three views an integrated approach. </title> <booktitle> In Proceedings Image Understanding Workshop, </booktitle> <pages> pages 1009-10016, </pages> <address> San Mateo, CA, 1994. </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: The computation of these shape descriptors does not require the computation of camera parameters (camera calibration, see also [13]). Most of the literature on the subject followed the first path, namely, computing camera calibration first using techniques derived from multi-frame geometry (see, e.g., <ref> [6, 7, 10, 4] </ref>). Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper. <p> The situation under perspective projection is more complex: <ref> [6, 7, 10, 4] </ref> (among others) showed how to linearly compute the camera calibration from 2-4 frames using all the points. Here (as well as in [1]) we showed how to linearly compute the projective shape of 6-8 points from all the frames.
Reference: 5. <author> R. Kumar and A. R. Hanson. </author> <title> Sensitivity of the pose refinement problem to accurate estimation of camera parameters. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 365-369, </pages> <address> Osaka, Japan, 1990. </address> <publisher> IEEE, </publisher> <address> Wash-ington, DC. </address>
Reference-contexts: The depth values of the points in the first frame ranged from 13 to 33 feet; moreover, a wide-lens camera was used, causing distortions at the periphery which were not compensated for. (See a more detailed description in [9] Fig. 4, or <ref> [5] </ref> Fig. 3.) We computed the shape of the 32 points as described above, using all the 16 frames in the linear computation, and using the non-linear computation. <p> The depth values of the points in the first frame ranged from 550 to 700 mms, and were given. (See a more detailed description of the sequence in [9] Fig. 5, or <ref> [5] </ref> Fig. 2.) We rotated the box by up to 60 o , translated it in R 3 by up to 100 mms, and then projected it with uncalibrated perspective projection, to obtain new images of the box.
Reference: 6. <author> H. C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: The computation of these shape descriptors does not require the computation of camera parameters (camera calibration, see also [13]). Most of the literature on the subject followed the first path, namely, computing camera calibration first using techniques derived from multi-frame geometry (see, e.g., <ref> [6, 7, 10, 4] </ref>). Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper. <p> The situation under perspective projection is more complex: <ref> [6, 7, 10, 4] </ref> (among others) showed how to linearly compute the camera calibration from 2-4 frames using all the points. Here (as well as in [1]) we showed how to linearly compute the projective shape of 6-8 points from all the frames.
Reference: 7. <author> Q.-T. Luong and O. Faugeras. </author> <title> The fundamental matrix: theory, algorithms, and stability analysis. </title> <journal> International Journal of Computer Vision, </journal> <note> 1995. in press. </note>
Reference-contexts: The computation of these shape descriptors does not require the computation of camera parameters (camera calibration, see also [13]). Most of the literature on the subject followed the first path, namely, computing camera calibration first using techniques derived from multi-frame geometry (see, e.g., <ref> [6, 7, 10, 4] </ref>). Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper. <p> The situation under perspective projection is more complex: <ref> [6, 7, 10, 4] </ref> (among others) showed how to linearly compute the camera calibration from 2-4 frames using all the points. Here (as well as in [1]) we showed how to linearly compute the projective shape of 6-8 points from all the frames.
Reference: 8. <author> L. Quan. </author> <title> Invariants of 6 points from 3 uncalibrated images. </title> <booktitle> In Proceedings of the 3rd European Conference on Computer Vision, </booktitle> <pages> pages 459-470, </pages> <address> Stockholdm, Sweden, 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: 1 V6 2 V6 5 V6 1 V6 3 V6 4 + V6 2 V6 3 V6 4 V6 2 V6 3 V6 5 V6 2 V6 4 V6 5 + (where V6 i denotes the i-th component of the shape descriptor V6.) A similar non-linear constraint was derived in <ref> [8] </ref>. Optimally, the non-linear computation should use the solution of the linear system defined by all the frames, and project the result onto the surface defined by the equation above. The non linear computation normally gives 3 solutions. 2.
Reference: 9. <author> H. S. Sawhney, J. Oliensis, and A. R. Hanson. </author> <title> Description and reconstruction from image trajectories of rotational motion. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 494-498, </pages> <address> Osaka, Japan, 1990. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: The depth values of the points in the first frame ranged from 13 to 33 feet; moreover, a wide-lens camera was used, causing distortions at the periphery which were not compensated for. (See a more detailed description in <ref> [9] </ref> Fig. 4, or [5] Fig. 3.) We computed the shape of the 32 points as described above, using all the 16 frames in the linear computation, and using the non-linear computation. <p> The depth values of the points in the first frame ranged from 550 to 700 mms, and were given. (See a more detailed description of the sequence in <ref> [9] </ref> Fig. 5, or [5] Fig. 2.) We rotated the box by up to 60 o , translated it in R 3 by up to 100 mms, and then projected it with uncalibrated perspective projection, to obtain new images of the box.
Reference: 10. <author> A. Shashua and M. Werman. </author> <title> Trilinearity of three perspective views and its associated tensor. </title> <booktitle> In Proceedings of the 5th International Conference on Computer Vision, </booktitle> <address> Cambridge, MA, 1995. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: The computation of these shape descriptors does not require the computation of camera parameters (camera calibration, see also [13]). Most of the literature on the subject followed the first path, namely, computing camera calibration first using techniques derived from multi-frame geometry (see, e.g., <ref> [6, 7, 10, 4] </ref>). Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper. <p> The situation under perspective projection is more complex: <ref> [6, 7, 10, 4] </ref> (among others) showed how to linearly compute the camera calibration from 2-4 frames using all the points. Here (as well as in [1]) we showed how to linearly compute the projective shape of 6-8 points from all the frames.
Reference: 11. <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: With k frames and n + 4 points, we get the 2k fi n measurements matrix W whose ji element is x ji for j k, and y (jk)i for k &lt; j 2k (cf. <ref> [11, 14] </ref>). Now if we read W by columns, the i-th column gives us multi-camera geometry; if we read it by rows, the j-th and (j + k) th rows give us multi-point geometry in a single image. <p> Under weak perspective projection: [12] showed how to use all the points and 1.5 frames to linearly compute affine structure, [13] showed how to use all the frames of 4 points to linearly compute Euclidean structure, <ref> [11] </ref> used all the data to linearly compute affine shape and camera orientation, and [14] used all the data to linearly compute Euclidean shape.
Reference: 12. <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(10) </volume> <pages> 992-1006, </pages> <year> 1991. </year>
Reference-contexts: Under weak perspective projection: <ref> [12] </ref> showed how to use all the points and 1.5 frames to linearly compute affine structure, [13] showed how to use all the frames of 4 points to linearly compute Euclidean structure, [11] used all the data to linearly compute affine shape and camera orientation, and [14] used all the data
Reference: 13. <author> D. Weinshall. </author> <title> Model-based invariants for 3D vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 10(1) </volume> <pages> 27-42, </pages> <year> 1993. </year>
Reference-contexts: Thus we propose below new shape descriptors, describing the shape of 6-8 points, which can be directly and linearly computed from at least 2-4 images. The computation of these shape descriptors does not require the computation of camera parameters (camera calibration, see also <ref> [13] </ref>). Most of the literature on the subject followed the first path, namely, computing camera calibration first using techniques derived from multi-frame geometry (see, e.g., [6, 7, 10, 4]). Much less is known about multi-point geometry under perspective projection with uncalibrated cameras, and this gap is filled by our paper. <p> Under weak perspective projection: [12] showed how to use all the points and 1.5 frames to linearly compute affine structure, <ref> [13] </ref> showed how to use all the frames of 4 points to linearly compute Euclidean structure, [11] used all the data to linearly compute affine shape and camera orientation, and [14] used all the data to linearly compute Euclidean shape.
Reference: 14. <author> D. Weinshall and C. Tomasi. </author> <title> Linear and incremental acquisition of invariant shape models from image sequences. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17(5) </volume> <pages> 512-517, </pages> <year> 1995. </year>
Reference-contexts: With k frames and n + 4 points, we get the 2k fi n measurements matrix W whose ji element is x ji for j k, and y (jk)i for k &lt; j 2k (cf. <ref> [11, 14] </ref>). Now if we read W by columns, the i-th column gives us multi-camera geometry; if we read it by rows, the j-th and (j + k) th rows give us multi-point geometry in a single image. <p> This result gives us the following algorithm for the reconstruction of shape using many views and many points, for an object with n + 6 points: 1. Choose a subset of 6 "good" points (an algorithm on how to choose good basis points in described in <ref> [14] </ref>). 2. For every additional point M i , i 7: Using all available frames (but at least 3), compute the shape vector V7 i of the set of 7 points &lt; 1; 2; 3; 4; 5; 6; 6 + i &gt; 3. <p> The new images differed markedly from the original 8 images used for the computation of the shape vectors. We selected a "good" basis of 5 points, using the procedure described in <ref> [14] </ref>. In each image, we transformed 4 of the basis points to the non-standard basis of P 2 : [1; 0; 1], [0; 1; 1], [0; 0; 1], [1; 1; 1]. <p> Under weak perspective projection: [12] showed how to use all the points and 1.5 frames to linearly compute affine structure, [13] showed how to use all the frames of 4 points to linearly compute Euclidean structure, [11] used all the data to linearly compute affine shape and camera orientation, and <ref> [14] </ref> used all the data to linearly compute Euclidean shape. The situation under perspective projection is more complex: [6, 7, 10, 4] (among others) showed how to linearly compute the camera calibration from 2-4 frames using all the points.
Reference: 15. <author> D. Weinshall, M. Werman, and A. Shashua. </author> <title> Shape tensors for efficient and learnable indexing. </title> <booktitle> In Proceedings of the IEEE Workshop on Representations of Visual Scenes, </booktitle> <address> Cambridge, Mass, </address> <year> 1995. </year> <title> This article was processed using the L a T E X macro package with ECCV'96 style </title>
Reference-contexts: This analysis provides the foundation for a computation where shape is computed first, and camera geometry second. A similar analysis was presented by Carlsson in [1] (see also <ref> [15] </ref>). More specifically, in Section 2 we show dual results to the ones obtained by computing camera geometry first.
References-found: 15

