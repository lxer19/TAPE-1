URL: http://www.cs.brown.edu/people/tld/postscript/GreenwaldandDeanARPI-94.ps
Refering-URL: http://www.cs.brown.edu/people/tld/
Root-URL: 
Email: lgg@cs.brown.edu tld@cs.brown.edu  
Phone: (401) 863-7662 (401) 863-7645  
Title: Monte Carlo Simulation and Bottleneck-Centered Heuristics for Time-Critical Scheduling in Stochastic Domains  
Author: Lloyd Greenwald Thomas Dean 
Address: Box 1910, Providence, RI 02912  
Affiliation: Department of Computer Science Brown University,  
Abstract: In this work we extend the work of Dean, Kaelbling, Kirman and Nicholson on planning under time constraints in stochastic domains to handle more complicated scheduling problems. In scheduling problems the sources of complexity stem not only from large state spaces but from large action spaces as well. In these problems it is no longer tractable to compute optimal policies for restricted state spaces via policy iteration. We, instead, borrow from Operations Research in applying bottleneck-centered scheduling heuristics to improve initial policies and make use of Monte Carlo simulation for selectively constructing partial policies in large state spaces. Additionally, we employ a variant of Drummond's situated control rules to constrain the space of possible actions.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adams, J., Balas, E., and Zawack, D., </author> <title> The Shifting Bottleneck Procedure for Job Shop Scheduling, </title> <booktitle> Management Science, </booktitle> <month> 34(3) </month> <year> (1988) </year> <month> 391-401. </month>
Reference-contexts: Instead, we employ Monte Carlo simulation on a stochastic model of the environment to construct partial policies for a subset of the most probable reachable states and provide default reflexes to handle the remaining states. We then borrow from Operations Research in applying bottleneck-centered scheduling heuristics <ref> [1] </ref> to improve initial policies. Additionally, we employ a variant of Drummond's [5] situated control rules to constrain the space of possible actions. Monte Carlo simulation addresses both the large action space and the large state space issues. <p> Even with the simplification of the Markov assumption we are still dealing with the necessity of manipulating very large transition matrices. The transition matrix for the corresponding Markov decision process is a mapping from S (t) fi A (t) fi S (t+1) to <ref> [0; 1] </ref> at each time step t. Dean et al. [3] were able to explicitly represent restricted envelopes of the state space as automata (in order to reduce the size of the state space) and perform exhaustive search on these restricted automata in order to generate optimal policies. <p> This extension to our two phase approach is not discussed any further here. Note that in domains without preemption it is reasonable to constrain all assignments in a given state. The technique we describe for propagating constraints is based on the bottleneck-centered heuristics <ref> [1, 15] </ref> of Operations Research. Bottleneck-centered heuristics are a form of opportunistic scheduling in which critical points of resource contention are located and used to identify and remove potential for negative interactions between activities. Bottleneck-centered heuristics have demonstrated their effectiveness in deployed scheduling solutions [15]. <p> This work extends the work of Dean et al. [3] to handle more combinatorial scheduling problems. We have borrowed from the Operations Research literature on bottleneck-centered heuristics developed by Adams et al. <ref> [1] </ref> and analyzed by Muscettola [15]. We augment this work by borrowing from the work of Drummond [5]. The approach described in this paper borrows from and extends the anytime projection approach of Drummond and Bresina [6].
Reference: [2] <author> Dean, Thomas and Boddy, Mark, </author> <title> An Analysis of Time-Dependent Planning, </title> <booktitle> Proceedings AAAI-88, </booktitle> <address> St. Paul, Minnesota, </address> <publisher> AAAI, </publisher> <year> 1988, </year> <pages> 49-54. </pages>
Reference-contexts: Focusing on a restricted subset of the state space allows for the tractable application of exhaustive search techniques such as policy iteration in domains in which the number of possible transitions from any state is limited. Both phases are designed as anytime algorithms <ref> [2] </ref> in that the quality of output of each fl This work was supported in part by a National Science Foundation Presidential Young Investigator Award IRI-8957601 and by the Air Force and the Advanced Research Projects Agency of the Department of Defense under Contract No.
Reference: [3] <author> Dean, Thomas, Kaelbling, Leslie, Kirman, Jak, and Nicholson, Ann, </author> <title> Planning With Deadlines in Stochastic Domains, </title> <booktitle> Proceedings AAAI-93, </booktitle> <address> Washington, D.C., </address> <publisher> AAAI, </publisher> <year> 1993, </year> <pages> 574-579. </pages>
Reference-contexts: We develop a set of techniques that extend the work of Dean et al. <ref> [3] </ref> for solving time-critical planning problems. In that work a two phase iterative procedure is employed. The first phase determines a restricted subset of the state space on which to focus (called the envelope) and the second phase generates a policy mapping states to actions within this envelope. <p> And each action results in a distribution of next states as determined by the stochastic processes. In order to address the fundamental differences between traditional planning domains and more combinatorial scheduling domains this work departs from <ref> [3] </ref> both in how we restrict the state space and how we generate policies within the restricted state space. In planning domains, performing policy generation in a restricted envelope of states addresses the large state space issue. <p> The transition matrix for the corresponding Markov decision process is a mapping from S (t) fi A (t) fi S (t+1) to [0; 1] at each time step t. Dean et al. <ref> [3] </ref> were able to explicitly represent restricted envelopes of the state space as automata (in order to reduce the size of the state space) and perform exhaustive search on these restricted automata in order to generate optimal policies. <p> The techniques that we have explored here are complementary to that work and their integration will be discussed in future work. This work extends the work of Dean et al. <ref> [3] </ref> to handle more combinatorial scheduling problems. We have borrowed from the Operations Research literature on bottleneck-centered heuristics developed by Adams et al. [1] and analyzed by Muscettola [15]. We augment this work by borrowing from the work of Drummond [5].
Reference: [4] <author> Dean, Thomas and Wellman, Michael, </author> <title> Planning and Control, </title> <publisher> (Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1991). </year>
Reference-contexts: We distinguish between state and control in keeping with standard practice in the control literature. For a description of the motivation and use of this formalism for modeling dynamical systems see <ref> [4, 8, 12] </ref>. We motivate a specific form of this general approach in [11].
Reference: [5] <author> Drummond, Mark, </author> <title> Situated Control Rules, </title> <editor> Brachman, Ronald J., Levesque, Hector J., and Reiter, Raymond, (Eds.), </editor> <booktitle> Proceedings of the First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <publisher> (Morgan-Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1989). </year>
Reference-contexts: We then borrow from Operations Research in applying bottleneck-centered scheduling heuristics [1] to improve initial policies. Additionally, we employ a variant of Drummond's <ref> [5] </ref> situated control rules to constrain the space of possible actions. Monte Carlo simulation addresses both the large action space and the large state space issues. <p> However, if preemption is not feasible (as in the case of planes assigned to gates) then the dispatch scheduler only determines assignments for resources which are free or become free in that state. We augment the dispatch scheduler by borrowing from the work of Drummond <ref> [5] </ref> on situated control rules. For any state, a set of constraints limits the assignments possible for the dispatch scheduler. These limitations on assignments implicitly disable a subset of the action space. In Section 3.2 we discuss how these constraints on dispatch scheduling are derived. <p> This work extends the work of Dean et al. [3] to handle more combinatorial scheduling problems. We have borrowed from the Operations Research literature on bottleneck-centered heuristics developed by Adams et al. [1] and analyzed by Muscettola [15]. We augment this work by borrowing from the work of Drummond <ref> [5] </ref>. The approach described in this paper borrows from and extends the anytime projection approach of Drummond and Bresina [6]. There have been a variety of planning systems that are related to the problem.
Reference: [6] <author> Drummond, Mark and Bresina, John, </author> <title> Anytime Synthetic Projection: Maximizing the Probability of Goal Satisfaction, </title> <booktitle> Proceedings AAAI-90, </booktitle> <address> Boston, Massachusetts, </address> <publisher> AAAI, </publisher> <year> 1990, </year> <pages> 138-144. </pages>
Reference-contexts: We augment this work by borrowing from the work of Drummond [5]. The approach described in this paper borrows from and extends the anytime projection approach of Drummond and Bresina <ref> [6] </ref>. There have been a variety of planning systems that are related to the problem. Georgeff's procedural reasoning system [7] was designed for on-line use in evolving situations, but it simply executes user-supplied procedures rather than constructing plans of action on its own. <p> Georgeff's procedural reasoning system [7] was designed for on-line use in evolving situations, but it simply executes user-supplied procedures rather than constructing plans of action on its own. Systems 11 for synthesizing plans in stochastic domains, such as those by Drummond and Bresina <ref> [6] </ref>, and Kushmerick, Hanks and Weld [13] do not directly address the problem of generating plans given time and quality constraints. Lansky [14] has developed planning systems for deterministic domains that exploit structural properties of the state space to expedite planning.
Reference: [7] <author> Georgeff, Michael P. and Lansky, Amy L., </author> <title> Reactive Reasoning and Planning, </title> <booktitle> Proceedings AAAI-87, </booktitle> <address> Seattle, Washington, </address> <publisher> AAAI, </publisher> <year> 1987, </year> <pages> 677-682. </pages>
Reference-contexts: We augment this work by borrowing from the work of Drummond [5]. The approach described in this paper borrows from and extends the anytime projection approach of Drummond and Bresina [6]. There have been a variety of planning systems that are related to the problem. Georgeff's procedural reasoning system <ref> [7] </ref> was designed for on-line use in evolving situations, but it simply executes user-supplied procedures rather than constructing plans of action on its own.
Reference: [8] <author> Gopal, M., </author> <title> Modern Control System Theory, </title> <publisher> (Halsted Press, </publisher> <address> New York, </address> <year> 1985). </year>
Reference-contexts: We distinguish between state and control in keeping with standard practice in the control literature. For a description of the motivation and use of this formalism for modeling dynamical systems see <ref> [4, 8, 12] </ref>. We motivate a specific form of this general approach in [11].
Reference: [9] <author> Greenwald, Lloyd and Dean, Thomas, </author> <title> Anticipating Computational Demands when Solving Time-Critical Decision-Making Problems, </title> <booktitle> submitted to the Workshop on the Algorithmic Foundations of Robotics, </booktitle> <year> 1994. </year>
Reference-contexts: In <ref> [9, 11] </ref> this architecture is discussed in the context of planning. In Section 2.1 we describe this architecture in the context of scheduling. <p> In [9, 11] this architecture is discussed in the context of planning. In Section 2.1 we describe this architecture in the context of scheduling. In Section 2.2 we model the stochastic domain. 2.1 Scheduling and Execution In <ref> [9] </ref> we define embedded planning to be the problem of determining actions for an agent embedded in an uncertain environment with dynamics outside of the agent's control. The same description applies for scheduling in dynamic environments. <p> This architecture forms the backdrop for the scheduling techniques discussed in this paper. In future work we will describe how the framework of <ref> [9] </ref> can be used to focus deliberation in scheduling domains with particular regularity properties. 2.2 Scheduling in Stochastic Domains We model the stochastic scheduling domain as a state space S made up of state variables S = fX 1 ; X 2 ; : : : ; X n g. <p> A deliberation scheduler may allocate time to decision procedures that 6 compute policies independently for disjoint time windows (i.e., each decision procedure constructs a policy from scratch for a given set of time steps). This approach is taken in <ref> [9, 11] </ref>. Alternatively, the deliberation scheduler may employ a sliding time window in which the target time windows of each decision procedure overlap and make use of policies computed by prior decision procedures. <p> We use a hierarchy of anytime decision procedures guided by deliberation scheduling. Deliberation scheduling and compilation of anytime algorithms for this work are discussed in [10]. In <ref> [9] </ref> we discuss a general architecture for reasoning in stochastic domains in which the domain is assumed to obey certain regularity constraints. The techniques that we have explored here are complementary to that work and their integration will be discussed in future work.
Reference: [10] <author> Greenwald, Lloyd and Dean, Thomas, </author> <title> Deliberation Scheduling for Time-Critical Scheduling in Stochastic Domains, </title> <note> submitted to UAI-94, </note> <year> 1994. </year>
Reference-contexts: The flexibility inherent in these decision procedures allows for a more flexible allocation of processing time to satisfy an overall performance criterion. In this paper we focus on specific anytime decision procedures for policy generation and bottleneck detection. In <ref> [10] </ref> we explore the deliberation scheduling necessary to optimally allocate processing time between these decision procedures and across time windows. 2 Embedded Scheduling In this section we outline our basic architecture for on-line interaction of scheduling and execution in stochastic domains and describe tools for modeling the stochastic domains. <p> At the higher level, computation time is allocated among the decision procedures for disjoint or overlapping time windows. In <ref> [10] </ref> we discuss in detail these alternative deliberation scheduling approaches. In this section we present low-level anytime decision procedures that are consistent with either approach. As a starting point we assume that the deliberation scheduler calls a decision procedure with a specific target time window and resource allocation. <p> We apply deliberation scheduling a second time to allocate time between the different phases of processing at this level. In this section we discuss separately each phase of processing and discuss their interaction in more detail under the context of deliberation scheduling and compilation of anytime algorithms in <ref> [10] </ref>. Our general approach to policy generation consists of the following two phases: 1. Monte Carlo Simulation and Constrained Dispatch Scheduling 2. <p> We use a hierarchy of anytime decision procedures guided by deliberation scheduling. Deliberation scheduling and compilation of anytime algorithms for this work are discussed in <ref> [10] </ref>. In [9] we discuss a general architecture for reasoning in stochastic domains in which the domain is assumed to obey certain regularity constraints. The techniques that we have explored here are complementary to that work and their integration will be discussed in future work.
Reference: [11] <author> Greenwald, Lloyd and Dean, Thomas, </author> <title> Solving Time-Critical Decision-Making Problems with Predictable Computational Demands, </title> <booktitle> submitted to the Second International Conference on AI Planning Systems, </booktitle> <year> 1994. </year>
Reference-contexts: In <ref> [9, 11] </ref> this architecture is discussed in the context of planning. In Section 2.1 we describe this architecture in the context of scheduling. <p> We distinguish between state and control in keeping with standard practice in the control literature. For a description of the motivation and use of this formalism for modeling dynamical systems see [4, 8, 12]. We motivate a specific form of this general approach in <ref> [11] </ref>. This architecture demonstrates how slow, high-level systems (e.g., for planning and scheduling) might interact with faster, more reactive systems (e.g., for real-time execution and monitoring) and enables us to generate timely solutions to difficult combinatorial planning and scheduling problems. <p> A deliberation scheduler may allocate time to decision procedures that 6 compute policies independently for disjoint time windows (i.e., each decision procedure constructs a policy from scratch for a given set of time steps). This approach is taken in <ref> [9, 11] </ref>. Alternatively, the deliberation scheduler may employ a sliding time window in which the target time windows of each decision procedure overlap and make use of policies computed by prior decision procedures.
Reference: [12] <author> Kalman, R. E., Falb, P. L., and Arbib, M. A., </author> <title> Topics in Mathematical System Theory, </title> <publisher> (McGraw-Hill, </publisher> <address> New York, </address> <year> 1969). </year>
Reference-contexts: We distinguish between state and control in keeping with standard practice in the control literature. For a description of the motivation and use of this formalism for modeling dynamical systems see <ref> [4, 8, 12] </ref>. We motivate a specific form of this general approach in [11].
Reference: [13] <author> Kushmerick, Nicholas, Hanks, Steve, and Weld, Daniel, </author> <title> An Algorithm for Probabilistic Planning, </title> <type> Unpublished Manuscript, </type> <year> 1993. </year>
Reference-contexts: Georgeff's procedural reasoning system [7] was designed for on-line use in evolving situations, but it simply executes user-supplied procedures rather than constructing plans of action on its own. Systems 11 for synthesizing plans in stochastic domains, such as those by Drummond and Bresina [6], and Kushmerick, Hanks and Weld <ref> [13] </ref> do not directly address the problem of generating plans given time and quality constraints. Lansky [14] has developed planning systems for deterministic domains that exploit structural properties of the state space to expedite planning. Smith et al. [16] describe some initial efforts at building systems that modify plans incrementally.
Reference: [14] <author> Lansky, Amy L., </author> <title> Localized Event-Based Reasoning for Multiagent Domains, </title> <booktitle> Computational Intelligence, </booktitle> <month> 4(4) </month> <year> (1988). </year>
Reference-contexts: Systems 11 for synthesizing plans in stochastic domains, such as those by Drummond and Bresina [6], and Kushmerick, Hanks and Weld [13] do not directly address the problem of generating plans given time and quality constraints. Lansky <ref> [14] </ref> has developed planning systems for deterministic domains that exploit structural properties of the state space to expedite planning. Smith et al. [16] describe some initial efforts at building systems that modify plans incrementally.
Reference: [15] <author> Muscettola, Nicola, </author> <title> An Experimental Analysis of Bottleneck-Centered Opportunistic Scheduling, </title> <booktitle> Proceedings of the Second European Workshop on Planning, </booktitle> <address> Vadstena, Sweden, </address> <year> 1993. </year>
Reference-contexts: This extension to our two phase approach is not discussed any further here. Note that in domains without preemption it is reasonable to constrain all assignments in a given state. The technique we describe for propagating constraints is based on the bottleneck-centered heuristics <ref> [1, 15] </ref> of Operations Research. Bottleneck-centered heuristics are a form of opportunistic scheduling in which critical points of resource contention are located and used to identify and remove potential for negative interactions between activities. Bottleneck-centered heuristics have demonstrated their effectiveness in deployed scheduling solutions [15]. <p> Bottleneck-centered heuristics are a form of opportunistic scheduling in which critical points of resource contention are located and used to identify and remove potential for negative interactions between activities. Bottleneck-centered heuristics have demonstrated their effectiveness in deployed scheduling solutions <ref> [15] </ref>. We employ bottleneck-centered heuristics through two main steps. First, find a critical interaction (bottleneck) among activities; namely one which contributes directly to a high expected cost policy. In practice [15] critical interactions occur during time intervals in which there is a high demand/supply ratio for resources. <p> Bottleneck-centered heuristics have demonstrated their effectiveness in deployed scheduling solutions <ref> [15] </ref>. We employ bottleneck-centered heuristics through two main steps. First, find a critical interaction (bottleneck) among activities; namely one which contributes directly to a high expected cost policy. In practice [15] critical interactions occur during time intervals in which there is a high demand/supply ratio for resources. Second, identify an assignment of activities to resources that, if constrained, will both reduce the bottleneck and guarantee that an improved policy exists that may be found through dispatch scheduling. <p> This work extends the work of Dean et al. [3] to handle more combinatorial scheduling problems. We have borrowed from the Operations Research literature on bottleneck-centered heuristics developed by Adams et al. [1] and analyzed by Muscettola <ref> [15] </ref>. We augment this work by borrowing from the work of Drummond [5]. The approach described in this paper borrows from and extends the anytime projection approach of Drummond and Bresina [6]. There have been a variety of planning systems that are related to the problem.
Reference: [16] <author> Ow, P. S., Smith, S. F., and Thiriez, A., </author> <title> Reactive Plan Revision, </title> <booktitle> Proceedings AAAI-88, </booktitle> <address> St. Paul, Minnesota, </address> <publisher> AAAI, </publisher> <year> 1988. </year> <month> 12 </month>
Reference-contexts: Lansky [14] has developed planning systems for deterministic domains that exploit structural properties of the state space to expedite planning. Smith et al. <ref> [16] </ref> describe some initial efforts at building systems that modify plans incrementally. Neither Lansky or Smith et al.'s systems deal with uncertainty and Lansky's system cannot handle concurrent planning and execution.
References-found: 16

