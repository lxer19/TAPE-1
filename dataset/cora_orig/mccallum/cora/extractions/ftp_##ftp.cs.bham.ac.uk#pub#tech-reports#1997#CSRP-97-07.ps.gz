URL: ftp://ftp.cs.bham.ac.uk/pub/tech-reports/1997/CSRP-97-07.ps.gz
Refering-URL: http://www.cs.bham.ac.uk/~rmp/eebic/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-MAIL: fJ.Pujol,R.Polig@cs.bham.ac.uk  
Title: Evolution of the Topology and the Weights of Neural Networks using Genetic Programming with a
Author: Jo~ao Carlos Figueira Pujol and Riccardo Poli 
Date: February 6, 1997  
Address: Birmingham B15 2TT, UK  
Affiliation: School of Computer Science The University of Birmingham  
Pubnum: Technical Report CSRP-97-7  
Abstract: Genetic programming is a methodology for program development, consisting of a special form of genetic algorithm capable of handling parse trees representing programs, that has been successfully applied to a variety of problems. In this paper a new approach to the construction of neural networks based on genetic programming is presented. A linear chromosome is combined to a graph representation of the network and new operators are introduced, which allow the evolution of the architecture and the weights simultaneously without the need of local weight optimization. This paper describes the approach, the operators and reports results of the application of the model to several binary classification problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Haykin. </author> <title> Neural networks, a comprehensive foundation. </title> <publisher> Macmillan College Publishing Company, Inc., </publisher> <address> 866 Third Avenue, New York, New York 10022, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction The design of neural networks is still largely performed using lengthy process of trial and error definition of the topology, followed by the application of a learning algorithm such as backpropagation <ref> [1] </ref>. However, the literature describes some approaches which try to automatically determine the topology and the weights simultaneously, by deleting or adding structural elements (neurons and connections) to an existent unsatisfactory architecture.
Reference: [2] <author> R. Reed. </author> <title> Pruning algorithms: a survey. </title> <journal> IEEE Transactions on Nerual Networks, </journal> <volume> 4(5) </volume> <pages> 740-747, </pages> <year> 1993. </year>
Reference-contexts: However, the literature describes some approaches which try to automatically determine the topology and the weights simultaneously, by deleting or adding structural elements (neurons and connections) to an existent unsatisfactory architecture. Destructive approaches (see for example <ref> [2] </ref>) begin with a trained architecture richer than necessary and prune unimportant elements of the network, whereas constructive approaches [3, 4, 5, 6] begin with a small topology and add new elements as need arises during the training process.
Reference: [3] <author> M. Frean. </author> <title> The upstart algorithm: a method for constructing and training feed-forward neural networks. </title> <journal> Neural Computation, </journal> <volume> 2 </volume> <pages> 198-209, </pages> <year> 1990. </year>
Reference-contexts: Destructive approaches (see for example [2]) begin with a trained architecture richer than necessary and prune unimportant elements of the network, whereas constructive approaches <ref> [3, 4, 5, 6] </ref> begin with a small topology and add new elements as need arises during the training process. The disadvantage of these strategies is that they constrain the architecture of the networks evolved, either from the beginning, or through the structural modifications they introduce. <p> The disadvantage of these strategies is that they constrain the architecture of the networks evolved, either from the beginning, or through the structural modifications they introduce. For example, Fahlman [4] adds hidden neurons fully connected to existing ones in a feedforward architecture, Frean <ref> [3] </ref> uses threshold activation functions and adds new hidden neurons fully connected to the input layer, and Campbell et al. [6] use binary weights. Recently, new promising approaches based on evolutionary computation have been proposed for the development of artificial neural networks.
Reference: [4] <author> S. E. Fahlman and C. Lebiere. </author> <title> The cascade-correlation learning architecture. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 524-532. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Destructive approaches (see for example [2]) begin with a trained architecture richer than necessary and prune unimportant elements of the network, whereas constructive approaches <ref> [3, 4, 5, 6] </ref> begin with a small topology and add new elements as need arises during the training process. The disadvantage of these strategies is that they constrain the architecture of the networks evolved, either from the beginning, or through the structural modifications they introduce. <p> The disadvantage of these strategies is that they constrain the architecture of the networks evolved, either from the beginning, or through the structural modifications they introduce. For example, Fahlman <ref> [4] </ref> adds hidden neurons fully connected to existing ones in a feedforward architecture, Frean [3] uses threshold activation functions and adds new hidden neurons fully connected to the input layer, and Campbell et al. [6] use binary weights.
Reference: [5] <author> D. Chen, C. Giles, G. Sun, H. Chen, Y. Less, and M. Goudreau. </author> <title> Constructive learning of recurrent neural networks. </title> <booktitle> In IEEE International Conference on Neural Networks (ICNN), </booktitle> <pages> pages 1196-1201, </pages> <year> 1993. </year>
Reference-contexts: Destructive approaches (see for example [2]) begin with a trained architecture richer than necessary and prune unimportant elements of the network, whereas constructive approaches <ref> [3, 4, 5, 6] </ref> begin with a small topology and add new elements as need arises during the training process. The disadvantage of these strategies is that they constrain the architecture of the networks evolved, either from the beginning, or through the structural modifications they introduce.
Reference: [6] <author> C. Campbell and C. Vicente. </author> <title> The target switch algorithm: a constructive learning procedure for feed-forward neural network. </title> <journal> Neural Computation, </journal> <volume> 7 </volume> <pages> 1245-1264, </pages> <year> 1995. </year>
Reference-contexts: Destructive approaches (see for example [2]) begin with a trained architecture richer than necessary and prune unimportant elements of the network, whereas constructive approaches <ref> [3, 4, 5, 6] </ref> begin with a small topology and add new elements as need arises during the training process. The disadvantage of these strategies is that they constrain the architecture of the networks evolved, either from the beginning, or through the structural modifications they introduce. <p> For example, Fahlman [4] adds hidden neurons fully connected to existing ones in a feedforward architecture, Frean [3] uses threshold activation functions and adds new hidden neurons fully connected to the input layer, and Campbell et al. <ref> [6] </ref> use binary weights. Recently, new promising approaches based on evolutionary computation have been proposed for the development of artificial neural networks.
Reference: [7] <author> X. Yao. </author> <title> An overview of evolutionary computation. </title> <journal> Chinese Journal of Advanced Software Research, </journal> <volume> 3(1), </volume> <year> 1996. </year> <note> To be published. </note>
Reference-contexts: Recently, new promising approaches based on evolutionary computation have been proposed for the development of artificial neural networks. Evolutionary computation is a class of global search techniques based on the learning process of a population of individuals <ref> [7, 8, 9, 10, 11, 12] </ref>, each individual representing a potential solution to a given problem. Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution.
Reference: [8] <author> D. Fogel. </author> <title> Evolutionary computation: toward a new philosophy of machine Intelligence. </title> <publisher> IEEE PRess, </publisher> <address> Piscataway, NJ, USA, </address> <year> 1995. </year>
Reference-contexts: Recently, new promising approaches based on evolutionary computation have been proposed for the development of artificial neural networks. Evolutionary computation is a class of global search techniques based on the learning process of a population of individuals <ref> [7, 8, 9, 10, 11, 12] </ref>, each individual representing a potential solution to a given problem. Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution.
Reference: [9] <author> D. Goldberg. </author> <title> Genetic algorithm in search, optimization and machine learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusets, </address> <year> 1989. </year>
Reference-contexts: Recently, new promising approaches based on evolutionary computation have been proposed for the development of artificial neural networks. Evolutionary computation is a class of global search techniques based on the learning process of a population of individuals <ref> [7, 8, 9, 10, 11, 12] </ref>, each individual representing a potential solution to a given problem. Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution. <p> This problem has been reduced using evolutionary programming techniques [24, 19, 18, 25], which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material <ref> [9] </ref>. An alternative approach to the development of neural networks is to use genetic algorithms [26, 9] and genetic programming (GP)[27]. They are a class of the evolutionary algorithms which make large use of crossover as an evolution operator. <p> However, this approach misses the benefits of the exchange of genetic material [9]. An alternative approach to the development of neural networks is to use genetic algorithms <ref> [26, 9] </ref> and genetic programming (GP)[27]. They are a class of the evolutionary algorithms which make large use of crossover as an evolution operator. Genetic programming, originally developed to evolve computer programs, uses parse trees to represent neural networks. [27, 28, 29].
Reference: [10] <author> M. Mitchell. </author> <title> An introduction to genetic algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mas-sachusets, USA, </address> <year> 1996. </year>
Reference-contexts: Recently, new promising approaches based on evolutionary computation have been proposed for the development of artificial neural networks. Evolutionary computation is a class of global search techniques based on the learning process of a population of individuals <ref> [7, 8, 9, 10, 11, 12] </ref>, each individual representing a potential solution to a given problem. Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution.
Reference: [11] <author> L. Davis. </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Rheingold, </publisher> <address> New York, NY, </address> <year> 1991. </year>
Reference-contexts: Recently, new promising approaches based on evolutionary computation have been proposed for the development of artificial neural networks. Evolutionary computation is a class of global search techniques based on the learning process of a population of individuals <ref> [7, 8, 9, 10, 11, 12] </ref>, each individual representing a potential solution to a given problem. Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution.
Reference: [12] <author> Michalewicz Zbigniew. </author> <title> Genetic Algorithms [plus] Data Structures = Evolution Programs. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1994. </year>
Reference-contexts: Recently, new promising approaches based on evolutionary computation have been proposed for the development of artificial neural networks. Evolutionary computation is a class of global search techniques based on the learning process of a population of individuals <ref> [7, 8, 9, 10, 11, 12] </ref>, each individual representing a potential solution to a given problem. Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution.
Reference: [13] <author> S. Harp, T. Samad, and A. Guha. </author> <title> Toward the genetic synthesis of neural networks. </title> <editor> In J. Schaffer, editor, </editor> <booktitle> Proceedings of the 3rd International Conference on Genetic Algorithms (ICGA), </booktitle> <pages> pages 360-369, </pages> <address> San Mateo, CA, USA, </address> <year> 1989. </year>
Reference-contexts: Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution. Many methods perform separately the building of the architecture and the learning of the weights <ref> [13, 14, 15, 16, 17] </ref>. Although biologically plausible, this approach is very inefficient. Other methods include partial training by gradient descent or simulated annealing in the evolution process [18, 19], and transfer the learned weights to the offspring in a Lamarckian fashion, in order to speed up evolution.
Reference: [14] <author> M. Mandischer. </author> <title> Evolving recurrent neural networks with non-binary encoding. </title> <booktitle> In Proceedings of the 2nd IEEE Conference on Evolutionary Computation (ICEC), </booktitle> <volume> volume 2, </volume> <pages> pages 584-589, </pages> <address> Perth, Australia, </address> <month> Nov. </month> <year> 1995. </year> <month> 18 </month>
Reference-contexts: Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution. Many methods perform separately the building of the architecture and the learning of the weights <ref> [13, 14, 15, 16, 17] </ref>. Although biologically plausible, this approach is very inefficient. Other methods include partial training by gradient descent or simulated annealing in the evolution process [18, 19], and transfer the learned weights to the offspring in a Lamarckian fashion, in order to speed up evolution.
Reference: [15] <author> M. Mandischer. </author> <title> Representation and evolution of neural networks. </title> <booktitle> In Proceedings of the International Conference on Artificial Neural Nets and Genetic Algorithms (ANNGA), </booktitle> <pages> pages 643-649, </pages> <year> 1993. </year>
Reference-contexts: Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution. Many methods perform separately the building of the architecture and the learning of the weights <ref> [13, 14, 15, 16, 17] </ref>. Although biologically plausible, this approach is very inefficient. Other methods include partial training by gradient descent or simulated annealing in the evolution process [18, 19], and transfer the learned weights to the offspring in a Lamarckian fashion, in order to speed up evolution.
Reference: [16] <author> H. Kitano. </author> <title> Neurogenetic learning: an integrated method of designing and training neural networks using genetic algorithms. </title> <journal> Physica D, </journal> <volume> 75 </volume> <pages> 225-238, </pages> <year> 1994. </year>
Reference-contexts: Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution. Many methods perform separately the building of the architecture and the learning of the weights <ref> [13, 14, 15, 16, 17] </ref>. Although biologically plausible, this approach is very inefficient. Other methods include partial training by gradient descent or simulated annealing in the evolution process [18, 19], and transfer the learned weights to the offspring in a Lamarckian fashion, in order to speed up evolution.
Reference: [17] <author> S. Fujita and H. Nishimura. </author> <title> An evolutionary approach to associative memory in recurrent neural networks. </title> <booktitle> Neural Processing, </booktitle> <volume> 1(2), </volume> <year> 1994. </year>
Reference-contexts: Typical evolutionary algorithms update this population seeking for better regions of the search space using operations of selection, recombination and mutation, inspired by biological evolution. Many methods perform separately the building of the architecture and the learning of the weights <ref> [13, 14, 15, 16, 17] </ref>. Although biologically plausible, this approach is very inefficient. Other methods include partial training by gradient descent or simulated annealing in the evolution process [18, 19], and transfer the learned weights to the offspring in a Lamarckian fashion, in order to speed up evolution.
Reference: [18] <author> H. Braun and P. Zagorski. </author> <title> ENZO-M ahybrid approach for optmizing neural networks by evolution and learning. </title> <editor> In Y. Davidor, H. Schwefel, and H. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature (PPSN3), </booktitle> <volume> volume 866. </volume> <publisher> Springer-Verlag, </publisher> <year> 1994. </year> <note> Lecture Notes in Computer Science. </note>
Reference-contexts: Many methods perform separately the building of the architecture and the learning of the weights [13, 14, 15, 16, 17]. Although biologically plausible, this approach is very inefficient. Other methods include partial training by gradient descent or simulated annealing in the evolution process <ref> [18, 19] </ref>, and transfer the learned weights to the offspring in a Lamarckian fashion, in order to speed up evolution. <p> This can mislead the evolutionary process. Other methods try to develop the weights and the architecture concurrently, but impose restrictions on the value of the weights [20, 21, 22, 23]. This problem has been reduced using evolutionary programming techniques <ref> [24, 19, 18, 25] </ref>, which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material [9].
Reference: [19] <author> X. Yao and J. Liu. </author> <title> Evolutionary artificial neural networks that learn and generalize well. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Neural Networks, </booktitle> <address> Washington, DC, </address> <month> Jun. </month> <year> 1996. </year> <month> Submmitted. </month>
Reference-contexts: Many methods perform separately the building of the architecture and the learning of the weights [13, 14, 15, 16, 17]. Although biologically plausible, this approach is very inefficient. Other methods include partial training by gradient descent or simulated annealing in the evolution process <ref> [18, 19] </ref>, and transfer the learned weights to the offspring in a Lamarckian fashion, in order to speed up evolution. <p> This can mislead the evolutionary process. Other methods try to develop the weights and the architecture concurrently, but impose restrictions on the value of the weights [20, 21, 22, 23]. This problem has been reduced using evolutionary programming techniques <ref> [24, 19, 18, 25] </ref>, which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material [9].
Reference: [20] <author> V. Maniezzo. </author> <title> Genetic evolution of the topology and weight distribution of neural networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(1) </volume> <pages> 39-53, </pages> <month> Jan. </month> <year> 1994. </year>
Reference-contexts: This can mislead the evolutionary process. Other methods try to develop the weights and the architecture concurrently, but impose restrictions on the value of the weights <ref> [20, 21, 22, 23] </ref>. This problem has been reduced using evolutionary programming techniques [24, 19, 18, 25], which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material [9].
Reference: [21] <author> F. Gruau. </author> <title> Neural network synthesis using cellular encoding and the genetic algorithm. </title> <type> PhD thesis, </type> <institution> Laboratoire de L'informatique du Parallelisme, Ecole Normale Superiere de Lyon, Lyon, France, </institution> <year> 1994. </year>
Reference-contexts: This can mislead the evolutionary process. Other methods try to develop the weights and the architecture concurrently, but impose restrictions on the value of the weights <ref> [20, 21, 22, 23] </ref>. This problem has been reduced using evolutionary programming techniques [24, 19, 18, 25], which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material [9]. <p> However, these methods have been largely limited by the lack of good approaches to evolve the weights and the fact that parse trees are not a natural representation for neural networks. Indirect methods such as cellular encoding <ref> [21, 30] </ref> avoid the problem of representing the network directly as a parse tree, by representing the rules to construct 2 the network instead. However, there are still constraints on the weights evolved, and to construct the network from the rules at each generation can be a considerable overhead.
Reference: [22] <author> S. Nolfi and D. Parisi. </author> <title> Growing neural networks. </title> <type> Technical Report PCIA-95-15, </type> <institution> Rome, Italy, </institution> <month> Jun. </month> <year> 1991. </year>
Reference-contexts: This can mislead the evolutionary process. Other methods try to develop the weights and the architecture concurrently, but impose restrictions on the value of the weights <ref> [20, 21, 22, 23] </ref>. This problem has been reduced using evolutionary programming techniques [24, 19, 18, 25], which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material [9].
Reference: [23] <author> B. T. Zhang and H. Muhlenbein. </author> <title> Evolving optimal neural networks using genetic algorithms with Occam's razor. </title> <journal> Complex Systems, </journal> <volume> 7(3) </volume> <pages> 199-220, </pages> <year> 1993. </year>
Reference-contexts: This can mislead the evolutionary process. Other methods try to develop the weights and the architecture concurrently, but impose restrictions on the value of the weights <ref> [20, 21, 22, 23] </ref>. This problem has been reduced using evolutionary programming techniques [24, 19, 18, 25], which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material [9].
Reference: [24] <author> P. J. Angeline, G. M. Saunders, and J. B. Pollack. </author> <title> An evolutionary algorithm that constructs recurrent neural networks. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 5(1), </volume> <year> 1994. </year>
Reference-contexts: This can mislead the evolutionary process. Other methods try to develop the weights and the architecture concurrently, but impose restrictions on the value of the weights [20, 21, 22, 23]. This problem has been reduced using evolutionary programming techniques <ref> [24, 19, 18, 25] </ref>, which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material [9].
Reference: [25] <author> D. Fogel. </author> <title> Using evolutionary programming to create neural networks that are capable of playing Tic Tac Toe. </title> <booktitle> In IEEE International Conference on Neural Networks (ICNN). </booktitle> <publisher> IEEE Press, </publisher> <year> 1993. </year>
Reference-contexts: This can mislead the evolutionary process. Other methods try to develop the weights and the architecture concurrently, but impose restrictions on the value of the weights [20, 21, 22, 23]. This problem has been reduced using evolutionary programming techniques <ref> [24, 19, 18, 25] </ref>, which rely exclusively on mutation to adjust the weights and the architecture at each generation. However, this approach misses the benefits of the exchange of genetic material [9].
Reference: [26] <author> J. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <institution> University of Michigan Press, Ann Arbor, Michigan, </institution> <year> 1975. </year>
Reference-contexts: However, this approach misses the benefits of the exchange of genetic material [9]. An alternative approach to the development of neural networks is to use genetic algorithms <ref> [26, 9] </ref> and genetic programming (GP)[27]. They are a class of the evolutionary algorithms which make large use of crossover as an evolution operator. Genetic programming, originally developed to evolve computer programs, uses parse trees to represent neural networks. [27, 28, 29].
Reference: [27] <author> J. R. Koza. </author> <title> Genetic Programming, on the Programming of Computers by Means of Natural Selection. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, Massachusets, </address> <year> 1992. </year>
Reference-contexts: They are a class of the evolutionary algorithms which make large use of crossover as an evolution operator. Genetic programming, originally developed to evolve computer programs, uses parse trees to represent neural networks. <ref> [27, 28, 29] </ref>. However, these methods have been largely limited by the lack of good approaches to evolve the weights and the fact that parse trees are not a natural representation for neural networks. <p> Column 3 and 4 show the number of hidden nodes and the number of connections after applying the pruning strategy described, respectively. Column 5 shows the computational effort, i. e. the number of fitness evaluations, necessary to obtain a solution with 99% probability <ref> [27] </ref>, and column 6 shows the percentage of runs in which solutions were found. (Averages over the successful runs.) Apparently, node transfer crossover gives the best results in terms of effort and percentage of solutions found. However, Table 4 shows better results for one-point crossover applied to the XOR problem.
Reference: [28] <author> B. Zhang and H. Muehlenbein. </author> <title> Genetic programming of minimal neural nets using Occam's razor. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the 5th international conference on genetic algorithms (ICGA'93), </booktitle> <pages> pages 342-349. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year> <month> 19 </month>
Reference-contexts: They are a class of the evolutionary algorithms which make large use of crossover as an evolution operator. Genetic programming, originally developed to evolve computer programs, uses parse trees to represent neural networks. <ref> [27, 28, 29] </ref>. However, these methods have been largely limited by the lack of good approaches to evolve the weights and the fact that parse trees are not a natural representation for neural networks. <p> For the 3 bit parity problem, Yao et al. [33] reported an average of 739 generations to get a solution. The 4-bit parity solution reported by Zhang et al. <ref> [28] </ref> was achieved in fewer generations (9), but a population of 1000 individuals was used, and training by a hillclimbing procedure was performed at each generation.
Reference: [29] <author> B. Zhang and Muehlenbein. </author> <title> Synthesis of sigma-pi neural networks by the breeder genetic programming. </title> <booktitle> In Proceedings of IEEE International Conference on Evolutionary Computation (ICEC), World Congress on Computational Intelligence, </booktitle> <pages> pages 318-323, </pages> <address> Orlando, Florida, USA, </address> <month> Jun. </month> <title> 1994. </title> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: They are a class of the evolutionary algorithms which make large use of crossover as an evolution operator. Genetic programming, originally developed to evolve computer programs, uses parse trees to represent neural networks. <ref> [27, 28, 29] </ref>. However, these methods have been largely limited by the lack of good approaches to evolve the weights and the fact that parse trees are not a natural representation for neural networks.
Reference: [30] <author> F. Gruau, D. Whitley, and L. Pyeatt. </author> <title> A comparison between cellular encoding and direct encoding for genetic neural networks. </title> <editor> In J. Koza, D. Goldberg, D. Fogel, and R. Riolo, editors, </editor> <booktitle> Genetic Programming 1996: Proceedings of the First Annual Conference, </booktitle> <pages> pages 81-89, </pages> <address> Stanford University, CA, USA, </address> <month> Jul. </month> <title> 1996. </title> <publisher> MIT Press. </publisher>
Reference-contexts: However, these methods have been largely limited by the lack of good approaches to evolve the weights and the fact that parse trees are not a natural representation for neural networks. Indirect methods such as cellular encoding <ref> [21, 30] </ref> avoid the problem of representing the network directly as a parse tree, by representing the rules to construct 2 the network instead. However, there are still constraints on the weights evolved, and to construct the network from the rules at each generation can be a considerable overhead.
Reference: [31] <author> R. Poli. </author> <title> Some steps towards a form of parallel distributed genetic programming. </title> <booktitle> In Proceedings of the First On-line Workshop on Soft Computing, </booktitle> <month> Aug. </month> <year> 1996. </year>
Reference-contexts: Recently, a new form of GP, Parallel Distributed Genetic Programming (PDGP), in which programs are represented as graphs, has been applied to the development of neural networks with promising results <ref> [31, 32] </ref>. In PDGP, a two-dimensional grid is associated with the network to represent its layers. The genetic operators are specialized to act on this grid. <p> The only exception is when a terminal replaces a function, creating a connection to the input layer in the phenotype. This crossover operator is similar to the SANN crossover in PDGP <ref> [31] </ref>. * Linear sub-graph crossover. First a linear displacement is defined by the difference between the positions of node1 and node2 within the linear chromosome. Secondly, node2 is transferred to the first parent at the position of node1.
Reference: [32] <author> R. Poli. </author> <title> Discovery of symbolic, neuron-symbolic and neural networks with parallel distributed genetic programming. </title> <booktitle> In 3rd International Conference on Artificial Neural Networks and Genetic Algorithms (ICANNGA), </booktitle> <year> 1997. </year>
Reference-contexts: Recently, a new form of GP, Parallel Distributed Genetic Programming (PDGP), in which programs are represented as graphs, has been applied to the development of neural networks with promising results <ref> [31, 32] </ref>. In PDGP, a two-dimensional grid is associated with the network to represent its layers. The genetic operators are specialized to act on this grid.
Reference: [33] <author> X. Yao and Y. Shi. </author> <title> A preliminary study on designing artificial neural networks using co-evolution. </title> <booktitle> In Proceedings of the IEEE Singapore International Conference on Intelligent Control and Instrumentation, </booktitle> <pages> pages 149-154, </pages> <month> Jun. </month> <year> 1995. </year>
Reference-contexts: As expected, the pruning process tends to generate solutions with connections between the first layer and the output layer. Our results compare very favorably with those reported in the literature. To solve the XOR problem the following numbers of generations to attain solutions are reported: 90 <ref> [33] </ref>, 513 [34], less than 100 with a minimum solution at generation 200 [35], less than 40 for a neural network with 2 hidden neuron [36]. <p> Note that the values in Table 1 refer to the pruned solutions, larger solutions with two hidden neurons, for example, are obtained 11 much earlier. For the 3 bit parity problem, Yao et al. <ref> [33] </ref> reported an average of 739 generations to get a solution. The 4-bit parity solution reported by Zhang et al. [28] was achieved in fewer generations (9), but a population of 1000 individuals was used, and training by a hillclimbing procedure was performed at each generation.
Reference: [34] <author> K. Tang, C. Chan, K. Man, and S. Kwong. </author> <title> Genetic structure for nn topology and weights optimization. </title> <booktitle> In Porceedings of the International Conference on Genetic Algorithms in Engineering Systems: innovations and applications (GALESIA), </booktitle> <pages> pages 250-255, </pages> <month> Sept. </month> <year> 1995. </year>
Reference-contexts: As expected, the pruning process tends to generate solutions with connections between the first layer and the output layer. Our results compare very favorably with those reported in the literature. To solve the XOR problem the following numbers of generations to attain solutions are reported: 90 [33], 513 <ref> [34] </ref>, less than 100 with a minimum solution at generation 200 [35], less than 40 for a neural network with 2 hidden neuron [36]. Note that the values in Table 1 refer to the pruned solutions, larger solutions with two hidden neurons, for example, are obtained 11 much earlier.
Reference: [35] <author> D. Dasgupta and D. McGregor. </author> <title> Designing application-specific neural networks using the structured genetic algorithm. </title> <editor> In L. Whitley and J. Schaffer, editors, </editor> <booktitle> Proceedings of International Workshop on Combinations of Genetic Algorithms and Neural Networks (COGANN), </booktitle> <pages> pages 87-96. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> Jun. </month> <year> 1992. </year>
Reference-contexts: Our results compare very favorably with those reported in the literature. To solve the XOR problem the following numbers of generations to attain solutions are reported: 90 [33], 513 [34], less than 100 with a minimum solution at generation 200 <ref> [35] </ref>, less than 40 for a neural network with 2 hidden neuron [36]. Note that the values in Table 1 refer to the pruned solutions, larger solutions with two hidden neurons, for example, are obtained 11 much earlier.
Reference: [36] <editor> D. Fogel, L. Fogel, and V. Porto. </editor> <title> Evolving neural networks. </title> <journal> Biological Cybernetics, </journal> <volume> 63 </volume> <pages> 487-493, </pages> <year> 1990. </year>
Reference-contexts: To solve the XOR problem the following numbers of generations to attain solutions are reported: 90 [33], 513 [34], less than 100 with a minimum solution at generation 200 [35], less than 40 for a neural network with 2 hidden neuron <ref> [36] </ref>. Note that the values in Table 1 refer to the pruned solutions, larger solutions with two hidden neurons, for example, are obtained 11 much earlier. For the 3 bit parity problem, Yao et al. [33] reported an average of 739 generations to get a solution.
Reference: [37] <author> D. Whitley, T. Starkweather, and C. Bogart. </author> <title> Genetic algorithms and neural networks: Optimizing connections and connectivity. </title> <booktitle> Parallel Computing, </booktitle> <address> 14-3:347-361, </address> <year> 1990. </year> <month> 20 </month>
Reference-contexts: This problem was especially hard to solve: only a 2% of the runs were successful. A solution with 5 hidden neurons and 25 connections was obtained. Whitley et al. <ref> [37] </ref> reports a solution with 4 hidden neurons and 29 connections. Some experiments were also carried out in which both sigmoid and threshold functions were present in the function set. This interesting combination is shown in Figure 7 for the 4 parity and the 2 bit adder problems.
References-found: 37

