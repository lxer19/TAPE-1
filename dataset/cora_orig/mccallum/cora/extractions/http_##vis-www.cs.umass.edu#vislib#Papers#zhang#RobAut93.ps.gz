URL: http://vis-www.cs.umass.edu/vislib/Papers/zhang/RobAut93.ps.gz
Refering-URL: http://vis-www.cs.umass.edu/vislib/Papers/zhang/files.html
Root-URL: 
Email: NetAd zzhang@cs.umass.EDU  
Phone: Phone (413)545-0528  
Title: AUTOMATIC CALIBRATION AND VISUAL SERVOING FOR A ROBOT NAVIGATION SYSTEM  
Author: Zhongfei Zhang Richard Weiss Allen R. Hanson 
Address: Amherst, MA 01003  
Affiliation: Computer Science Department University of Massachusetts  
Abstract: This paper attacks the problem of automatic location of a mobile robot in an indoor environment. This may be used for calibration to locate the robot accurately before it starts to navigate, or it can be used in visual servoing as feed back to the controller which is maintaining the robot on a course. In this paper, we examine the problem in a special case, where the ground plane is assumed to be horizontal and there are two locally parallel side-lines available. This assumption holds in many indoor environments, such as hallways, where the system's success has been demonstrated. The algorithm uses geometric features such as vanishing points and line orientations. Both theoretical analysis and experimental results show that this algorithm works very robustly and accurately. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.T. Collins and R.S. Weiss. </author> <title> Vanishing point calculation as a statistical inference on the unit sphere. </title> <booktitle> In Proc. </booktitle> <address> ICCV, Osaka, Japan, </address> <month> Dec. </month> <year> 1990. </year> <note> IEEE. </note>
Reference-contexts: These three DOFs are independently measured by: vanishing point location, which is an efficient vehicle to estimate orientations <ref> [1, 3, 10] </ref>; orientation of side-lines, which can be used in a closed form solution for the lateral distance; and looming, which is used to estimate depth information [11]. By combining those techniques, we can accurately determine the pose of a robot in this environment. <p> The three measurements which are described in terms of the hallway axis are: orientation with respect to the axis, lateral distance from the axis, and depth distance along the axis. Based on these measurements, three techniques are developed. They are: using the vanishing point position to estimate orientation <ref> [1, 3, 10] </ref>; using the directional axis to obtain a closed form solution for the lateral distance; and using looming to estimate depth information [11].
Reference: [2] <author> C. Fennema, A. Hanson, E. Riseman, J. Bev eridge, and R. Kumar. </author> <title> Model-directed mobile robot navigation. </title> <journal> Trans. Systems, Man, and Cybernetics, </journal> <volume> 20(6) </volume> <pages> 1352-1369, </pages> <year> 1990. </year>
Reference-contexts: 1 INTRODUCTION Robot navigation has been the focus of attention of many researchers in recent years. Some of the systems need to be very accurately calibrated in order to perform navigation successfully <ref> [4, 2] </ref>. Calibration is the process of determining the relationship of sensor output to the actual value of the input. <p> Some of the systems need to be very accurately calibrated in order to perform navigation successfully [4, 2]. Calibration is the process of determining the relationship of sensor output to the actual value of the input. In the system described in <ref> [2] </ref>, it was necessary to position the robot/camera system by hand to within 0.1 inches and 0.1 ffi of a known position in a world coordinate system. This problem falls under the category of extrinsic camera calibration [9]. There are at least two reasons why automatic calibration is needed. <p> Thus, the requirements for a general purpose pose estimation algorithm are not the same as those for an automatic calibration algorithm. The technique used here for applying the pose algorithms is perceptual servoing <ref> [2] </ref>. In the calibration phase, the pose computed by the algorithm is used by the controller to move the robot to a prespecified world location. <p> Thus, we have a two step algorithm which first moves the robot to achieve the desired orientation and lateral displacement, then moves the robot to the desired distance along the axis using looming. Note that in the second loop, we use the perceptual servoing facility of our navigation system <ref> [2] </ref>. This guarantees that the robot will not move off the target directional axis during its moving toward the target pose.
Reference: [3] <author> K. Kanatani and Y. Onodera. </author> <title> Anatomy of cam era calibration using vanishing points. </title> <journal> IEICE Trans. Infor. Sys., </journal> <volume> 74(10) </volume> <pages> 3369-3378, </pages> <year> 1991. </year>
Reference-contexts: Tsuji et al [10] developed an algorithm to estimate and compensate for the camera pitch and roll during the dynamic navigation process. This was based on the motion of the vanishing point of the vertical lines on a Gaussian sphere. Katanani <ref> [3] </ref> used vanishing points for intrinsic camera calibration. Neither methods involved the estimation of position as well as orientation. <p> These three DOFs are independently measured by: vanishing point location, which is an efficient vehicle to estimate orientations <ref> [1, 3, 10] </ref>; orientation of side-lines, which can be used in a closed form solution for the lateral distance; and looming, which is used to estimate depth information [11]. By combining those techniques, we can accurately determine the pose of a robot in this environment. <p> The three measurements which are described in terms of the hallway axis are: orientation with respect to the axis, lateral distance from the axis, and depth distance along the axis. Based on these measurements, three techniques are developed. They are: using the vanishing point position to estimate orientation <ref> [1, 3, 10] </ref>; using the directional axis to obtain a closed form solution for the lateral distance; and using looming to estimate depth information [11].
Reference: [4] <author> D. Kriegman, E. Triendl, and T. Binford. </author> <title> Stereo vision and navigation in buildings for mobile robots. </title> <journal> Robotics and Automation, </journal> <volume> 5(6), </volume> <year> 1989. </year>
Reference-contexts: 1 INTRODUCTION Robot navigation has been the focus of attention of many researchers in recent years. Some of the systems need to be very accurately calibrated in order to perform navigation successfully <ref> [4, 2] </ref>. Calibration is the process of determining the relationship of sensor output to the actual value of the input.
Reference: [5] <author> E. Krotkov. </author> <title> Mobile robot localization using a single image. </title> <booktitle> In Proc. Robotics and Automation, </booktitle> <address> Scottsdale, Arizona, </address> <month> May </month> <year> 1989. </year> <note> IEEE. </note>
Reference-contexts: Their algorithm requires three images, in general, to give the pose information each time. Our algorithm uses only one image, but it assumes that the target pose information is given in advance. Krotkov <ref> [5] </ref> attacked the pose determination problem based on the same assumption of flat ground plane as we did here. However, he also assumed that there was always an environment map with the landmarks marked on it available.
Reference: [6] <author> R. Kumar and A. Hanson. </author> <title> Pose refinement: Ap plication to model extension and sensitivity to camera parameters. </title> <publisher> COINS TR90-112. </publisher>
Reference-contexts: In other words, automatic calibration can achieve greater accuracy than manual. This automatic calibration problem can be related to the general one of robot pose estimation <ref> [6, 7] </ref>; however, many standard pose estimation algorithms are not necessarily suitable for calibration. Kumar and Hanson [6] presented a pose estimation and refinement algorithm for computing the transform matrix between the world coordinates and image coordinates. <p> In other words, automatic calibration can achieve greater accuracy than manual. This automatic calibration problem can be related to the general one of robot pose estimation [6, 7]; however, many standard pose estimation algorithms are not necessarily suitable for calibration. Kumar and Hanson <ref> [6] </ref> presented a pose estimation and refinement algorithm for computing the transform matrix between the world coordinates and image coordinates. The algorithm works very robustly in the sense that it can handle a large percentage of outliers.
Reference: [7] <author> H-J Lee and C-T Deng. </author> <title> Camera model determi nation using multiple frames. </title> <booktitle> In Proc. CVPR, Lahaina, Hawaii, </booktitle> <month> June </month> <year> 1991. </year> <note> IEEE. </note>
Reference-contexts: In other words, automatic calibration can achieve greater accuracy than manual. This automatic calibration problem can be related to the general one of robot pose estimation <ref> [6, 7] </ref>; however, many standard pose estimation algorithms are not necessarily suitable for calibration. Kumar and Hanson [6] presented a pose estimation and refinement algorithm for computing the transform matrix between the world coordinates and image coordinates. <p> The algorithm works very robustly in the sense that it can handle a large percentage of outliers. However, it requires the correspondence between frames to be done before the algorithm can be applied. Lee and Deng <ref> [7] </ref> also presented an algorithm to estimate the pose information and camera parameters in a hallway environment. Like ours, their algorithm also assumes that the ground plane is flat 1 , and that there are some vertical landmarks available.
Reference: [8] <author> D. Lowe. </author> <title> The viewpoint consistency constraint. </title> <journal> IJCV, </journal> <volume> 1(1), </volume> <year> 1987. </year>
Reference-contexts: In addition, the algorithm can be extended to situations in which the camera axis is not parallel to the ground plane. no local map available at all. Lowe <ref> [8] </ref> used viewpoint consistency constraint to match a set of characteristic features against models and achieved relatively good results, although he did not report error measures. For calibration, accuracy is usually the most important criterion, while other applications may have less stringent requirements for accuracy.
Reference: [9] <author> R. Tsai. </author> <title> An efficient and accurate camera cal ibration technique. </title> <booktitle> In Proc. </booktitle> <address> CVPR '86, Miami Beach, </address> <month> June </month> <year> 1986. </year> <note> IEEE. </note>
Reference-contexts: In the system described in [2], it was necessary to position the robot/camera system by hand to within 0.1 inches and 0.1 ffi of a known position in a world coordinate system. This problem falls under the category of extrinsic camera calibration <ref> [9] </ref>. There are at least two reasons why automatic calibration is needed. First of all, calibration by hand is usually tedious and time-consuming. fl This work was supported in part by DARPA and TACOM under contract DAAE07-91-C-R035.
Reference: [10] <author> S. Tsuji, Y. Yagi, and M. Asada. </author> <title> Dynamic scene analysis for a mobile robot in a man-made environment. </title> <booktitle> In Proc. Robotics and Automation, </booktitle> <address> St. Louis, Missouri, </address> <month> March </month> <year> 1985. </year> <note> IEEE. </note>
Reference-contexts: In the literature of robot navigation and calibration, many researchers have used vanishing points as an efficient tool to estimate orientation. Tsuji et al <ref> [10] </ref> developed an algorithm to estimate and compensate for the camera pitch and roll during the dynamic navigation process. This was based on the motion of the vanishing point of the vertical lines on a Gaussian sphere. Katanani [3] used vanishing points for intrinsic camera calibration. <p> These three DOFs are independently measured by: vanishing point location, which is an efficient vehicle to estimate orientations <ref> [1, 3, 10] </ref>; orientation of side-lines, which can be used in a closed form solution for the lateral distance; and looming, which is used to estimate depth information [11]. By combining those techniques, we can accurately determine the pose of a robot in this environment. <p> The three measurements which are described in terms of the hallway axis are: orientation with respect to the axis, lateral distance from the axis, and depth distance along the axis. Based on these measurements, three techniques are developed. They are: using the vanishing point position to estimate orientation <ref> [1, 3, 10] </ref>; using the directional axis to obtain a closed form solution for the lateral distance; and using looming to estimate depth information [11].
Reference: [11] <author> L. Williams and A. Hanson. </author> <title> Translating optical flow into token matches and depth from looming. </title> <booktitle> In Proc. </booktitle> <address> ICCV, Clearwater, FL, </address> <month> Dec. </month> <year> 1988. </year> <note> IEEE. </note>
Reference-contexts: These three DOFs are independently measured by: vanishing point location, which is an efficient vehicle to estimate orientations [1, 3, 10]; orientation of side-lines, which can be used in a closed form solution for the lateral distance; and looming, which is used to estimate depth information <ref> [11] </ref>. By combining those techniques, we can accurately determine the pose of a robot in this environment. Empirically, the experiments show that the automatic calibration is more accurate than that done by hand. <p> Based on these measurements, three techniques are developed. They are: using the vanishing point position to estimate orientation [1, 3, 10]; using the directional axis to obtain a closed form solution for the lateral distance; and using looming to estimate depth information <ref> [11] </ref>. In the following analysis, we assume that the center of the robot is the same as the focal point of the camera, and that the intrinsic parameters are known.
Reference: [12] <author> Z. Zhang, R. Weiss, and A. Hanson. </author> <title> Automatic calibration for a robot navigation system. COINS TR92-70. Table 1 Parameters of Model Image and Thresholds Parameters X c Y c d ffiY t 255.5 240.2 0.0 245.0 Thresholds d l 0:02 ffi 0.1 ft. 0.1 ft. Table 2 </title>
Reference-contexts: A similar analysis has been done for lateral distance and for looming <ref> [12] </ref>. This analysis shows that the calibration of orientation is the most accurate, lateral distance is next at [10 5 ; 10 2 ], and looming is the least accurate at up to 0:1 ft.
References-found: 12

