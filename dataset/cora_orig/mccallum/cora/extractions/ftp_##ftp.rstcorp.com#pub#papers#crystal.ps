URL: ftp://ftp.rstcorp.com/pub/papers/crystal.ps
Refering-URL: http://www.rstcorp.com/fault-injection.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: A "Crystal Ball" for Software Liability  
Author: J. Voas, G. McGraw, L. Kassab, and L. Voas 
Keyword: fault injection, anomaly, safety, failure class, fault class, liability, risk  
Abstract: Software fault injection is an emerging technology that can be used to observe how software systems behave under experimentally-controlled, anomalous circumstances. In so doing, software fault injection acts as a "crystal ball," predicting how badly software might behave should things go awry (both internally and externally) during execution. Such predictions provide clues as to how robust a piece of code is, where in the code robustness is deficient, and most importantly, what level of liability is incurred by relying on a particular software system. Once we find places in the code that are intolerant to the occurrence of anomalous events, we have found a source of liability within the software. Fault injection is an efficient, scientific means for predicting how events might unfold in the future. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. ARLAT ET AL. </author> <title> Fault Injection for Dependability Validation: A Methodology and Some Applications. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 16(2) </volume> <pages> 166-182, </pages> <month> February </month> <year> 1990. </year>
Reference-contexts: are ideal starting points from which to develop simulated anomalies or define what output types are undesirable. 3.2 Injecting "Hypothesized" Anomalies The underlying ideas behind fault injection are not new, and there exists much literature describing how to employ them for hardware system validation, software testing, and hardware design validation <ref> [6, 9, 2, 1] </ref>. Unfortunately, the migration of those ideas into practical methods for software validation has not occurred, mainly due to concern about the plausibility of the anomalies injected. For example, in an integrated circuit, the failure classes are obvious: stuck-at-one, stuck-at-zero, etc.
Reference: [2] <author> J. A. CLARK AND D. K. PRADHAN. </author> <title> Fault Injection: A Method for Validating Computer-System Dependability. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 47-56, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: are ideal starting points from which to develop simulated anomalies or define what output types are undesirable. 3.2 Injecting "Hypothesized" Anomalies The underlying ideas behind fault injection are not new, and there exists much literature describing how to employ them for hardware system validation, software testing, and hardware design validation <ref> [6, 9, 2, 1] </ref>. Unfortunately, the migration of those ideas into practical methods for software validation has not occurred, mainly due to concern about the plausibility of the anomalies injected. For example, in an integrated circuit, the failure classes are obvious: stuck-at-one, stuck-at-zero, etc.
Reference: [3] <author> M. DARAN AND P. THEVENOD-FOSSE. </author> <title> Software error analysis: A real case study involving real faults and mutations. </title> <booktitle> Proc. of the ACM SIGSOFT ISSTA'95, </booktitle> <pages> pages 158-171, </pages> <year> 1995. </year>
Reference-contexts: If this claim is generally true, the absolute worst case induced by any member of b 0 might be discernible from observing what happens when simulating a subset of the members of B. Results substantiating this conjecture are not yet in hand, but given the results from <ref> [8, 3, 12] </ref> (in combination with the fact that there are no other liability measurement solutions in our immediate future), this hypothesis cannot be dismissed outright without some justification.
Reference: [4] <author> Data Processing Services, Inc. v. L. H. Smith Oil Corp., 492 N. E. </author> <title> 2d 314 (Ind.App. </title> <year> 1986). </year>
Reference-contexts: For most software practitioners, 1986 was probably not a particularly noteworthy year in the software industry. However 1986 was the year of the first court case ever to result in a software development company being found guilty of software engineering malpractice <ref> [4] </ref>. It is not unreasonable to foresee the day when even public domain software (provided freely without compensation or warranty) will result in litigation against its developers.
Reference: [5] <author> R. A. DEMILLO AND A. J. OFFUTT. </author> <title> Constraint-based automatic test data generation. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(9) </volume> <pages> 900-910, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: Further, the prototyping and commercialization of fault injection tools has been very limited (e.g., MOTHRA <ref> [5] </ref>, SafetyNet from RST, Fault Tolerance and Performance Evaluator from the University of Illinois, etc.). Without automated fault injection tools, the analysis is rarely feasible. <p> Software fault injection methods suffer from a similar intractability problem to the exhaustive testing problem: 3 MOTHRA is an example of a tool that employs an interpreter to avoid the compilation step, but it is quite primitive <ref> [5] </ref>. 4 Some control control systems can be instrumented non-intrusively. 6 anomalies outside the code. In this simple case, A and B are disjoint.
Reference: [6] <author> R. A. DEMILLO, R. J. LIPTON, AND F. G. SAYWARD. </author> <title> Hints on test data selection: Help for the practicing programmer. </title> <journal> IEEE Computer, </journal> <volume> 11(4) </volume> <pages> 34-41, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: Sensitivity is 2 Note that there are other applications of fault injection that require defective code to be simulated (e.g., mutation testing <ref> [6] </ref>). 4 the reaction of the software to the injections, and can be used to assess the risks associated with (1) and (3). <p> are ideal starting points from which to develop simulated anomalies or define what output types are undesirable. 3.2 Injecting "Hypothesized" Anomalies The underlying ideas behind fault injection are not new, and there exists much literature describing how to employ them for hardware system validation, software testing, and hardware design validation <ref> [6, 9, 2, 1] </ref>. Unfortunately, the migration of those ideas into practical methods for software validation has not occurred, mainly due to concern about the plausibility of the anomalies injected. For example, in an integrated circuit, the failure classes are obvious: stuck-at-one, stuck-at-zero, etc.
Reference: [7] <author> Prof. J. L. LIONS. </author> <title> Ariane 5 flight 501 failure: Report of the inquiry board. </title> <address> Paris, </address> <month> July 19, </month> <year> 1996. </year>
Reference-contexts: The code that caused the disaster on the Ariane 5 had not caused problems for the Ariane 4, and because the code had worked properly for the Ariane 4, it was assumed it would work well for the Ariane 5 <ref> [7] </ref>. It might appear that to assess risk, all we need to do is accurately quantify reliability. But 100% reliability does not necessarily mean 0% risk.
Reference: [8] <author> C. C. MICHAEL. </author> <title> On the regularity of error propagation in software. </title> <type> Technical report, </type> <institution> Reliable Software Technologies Corporation, Sterling, Virginia, </institution> <year> 1996. </year> <note> Research Division Technical Report RSTR-96-003-04. 13 </note>
Reference-contexts: By "representative", we mean that they will share both the likelihood of propagation and a similar output class. Recent research suggests that distinct, incorrect data states (for the same test case) often tend to exhibit similar propagation behaviors, regardless of exactly what the corruptions are <ref> [8] </ref>. As an example, suppose that at some point in the code some variable should have a value of 100, but has a value of 101. <p> If this claim is generally true, the absolute worst case induced by any member of b 0 might be discernible from observing what happens when simulating a subset of the members of B. Results substantiating this conjecture are not yet in hand, but given the results from <ref> [8, 3, 12] </ref> (in combination with the fact that there are no other liability measurement solutions in our immediate future), this hypothesis cannot be dismissed outright without some justification.
Reference: [9] <author> J. A. SOLHEIM AND J. H. ROWLAND. </author> <title> An Empirical Study of Testing and Integration Strategies Using Artificial Software Systems. </title> <journal> IEEE Trans. on Software Engineering, </journal> 19(10) 941-949, October 1993. 
Reference-contexts: are ideal starting points from which to develop simulated anomalies or define what output types are undesirable. 3.2 Injecting "Hypothesized" Anomalies The underlying ideas behind fault injection are not new, and there exists much literature describing how to employ them for hardware system validation, software testing, and hardware design validation <ref> [6, 9, 2, 1] </ref>. Unfortunately, the migration of those ideas into practical methods for software validation has not occurred, mainly due to concern about the plausibility of the anomalies injected. For example, in an integrated circuit, the failure classes are obvious: stuck-at-one, stuck-at-zero, etc.
Reference: [10] <author> F. SMITH. </author> <title> Law enforcement information sharing systems as part of the solution to the effective analysis and dissemination of computer network threat intelligence. </title> <booktitle> Proceedings of the Invitational Workshop on Computer Vulnerability Data Sharing, </booktitle> <month> June </month> <year> 1996. </year>
Reference-contexts: In fact, software, whether it is correct or not, may be especially susceptible to phantom risks wherein "legal liability [is] claimed and occasionally found for poorly supported but popularly endorsed allegations concerning cause and effect" <ref> [10, page 9] </ref>. Generally speaking, risk can be divided into two types: speculative and pure. Speculative risk can result either in a loss or a profit (e.g., investing in company stock may pay off or may not).
Reference: [11] <author> J. VOAS. </author> <title> P IE: A Dynamic Failure-Based Technique. </title> <journal> IEEE Trans. on Software Eng., </journal> <volume> 18(8) </volume> <pages> 717-727, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: Our approach for simulating the anomalies in the dotted circle in Figure 2 is to inject anomalies intrusively using state corruptions, not mutants. The code that we add to modify internal states is termed a perturbation function. A procedure for coding perturbation functions is further described in <ref> [11] </ref>. <p> Thus it is often interesting to inject faults into such systems (even though we know they are incorrect) to ascertain how likely it is that faults could be hiding from testing. This is the basis for Voas's testability model <ref> [11] </ref>. 9 may be known. However, empirical evidence for the benefit of selecting which anomalies to inject in a random fashion has been recorded in several real-world case studies [12].
Reference: [12] <author> J. VOAS, F. CHARRON, G. MCGRAW, K. MILLER, AND M. FRIEDMAN. </author> <title> Predicting How Badly `Good' Software can Behave. </title> <journal> IEEE Software, </journal> <note> To appear in early 1997. 14 </note>
Reference-contexts: This is the basis for Voas's testability model [11]. 9 may be known. However, empirical evidence for the benefit of selecting which anomalies to inject in a random fashion has been recorded in several real-world case studies <ref> [12] </ref>. In these examples, random sampling from without any knowledge of any of B's members was applied, yet weaknesses in these systems were discovered. <p> These 12 potential problems had not been discovered by any other software safety methodology. Successes using the same fault injection approach on a medical application are also provided in <ref> [12] </ref>. In these studies, no members of B were known, yet random sampling from discovered serious potential risks within the software that were quickly repaired, thus modifying P. <p> If this claim is generally true, the absolute worst case induced by any member of b 0 might be discernible from observing what happens when simulating a subset of the members of B. Results substantiating this conjecture are not yet in hand, but given the results from <ref> [8, 3, 12] </ref> (in combination with the fact that there are no other liability measurement solutions in our immediate future), this hypothesis cannot be dismissed outright without some justification.
References-found: 12

