URL: ftp://sound.media.mit.edu/pub/billg/docs/TR-342.ps.gz
Refering-URL: http://sound.media.mit.edu/papers.html
Root-URL: http://www.media.mit.edu
Email: email: billg@media.mit.edu  
Title: audio  
Author: William G. Gardner 
Address: 20 Ames Street, Room E15-401B Cambridge, MA 02139  
Affiliation: MIT Media Lab  
Note: Transaural 3-D  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 342 July 20, 1995 Abstract An audio system has been constructed that renders three-dimensional sound using conventional stereo loudspeakers. This paper discusses the im plementation and performance of the system.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ali Azarbayejani, Thad Starner, Bradley Horowitz, and Alex Pentland. </author> <title> Visually controlled graphics. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 15(6) </volume> <pages> 602-605, </pages> <month> June </month> <year> 1993. </year> <title> (Special Section on 3-D Modeling in Image Analysis and Synthesis). </title>
Reference-contexts: We intend to use a visual head tracking system being developed in the Vision and Modeling group at the Media Lab. The system uses two cameras to identify the 3-D position of the head and hands of a subject seated in front of the cameras <ref> [1] </ref>. A system to track position and orientation of a head can easily be constructed by requiring the subject to wear a cap marked with both a red dot and a green dot. By tracking the dots with stereo cameras, both orientation and position can be recovered.
Reference: [2] <author> Jens Blauert. </author> <title> Spatial Hearing. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: The interaural differences are particularly important cues, because they don't depend on the details of the source spectrum. Human auditory localization has been studied extensively <ref> [2, 22] </ref>. The directional dependent filtering to each ear can be expressed as a frequency response, called a head-related transfer function (HRTF) 1 , and thus a pair of HRTFs describes how sound from one location reaches the two ears.
Reference: [3] <author> Duane H. Cooper and Jerald L. Bauck. </author> <title> "Prospects for Transaural Recording". </title> <journal> J. Audio Eng. Soc., </journal> 37(1/2):3-19, 1989. 
Reference-contexts: The basic idea is to filter the binaural signal such that the subsequent stereo presentation produces the binaural signal at the ears of the listener. The technique was first put into 2 practice by Schroeder and Atal [16, 17] and later refined by Cooper and Bauck <ref> [3] </ref>, who referred to it as "transaural audio". The stereo listening situation is shown in figure 3, where ^x L and ^x R are the signals sent to the speakers, and y L and y R are the signals at the listener's ears. <p> be specified in terms of the ipsilateral (H i = H LL = H RR ) and contralateral (H c = H LR = H RL ) responses: H 1 = H 2 H c H i (4) Cooper and Bauck proposed using a "shu*er" implementation of the transaural filter <ref> [3] </ref>, which involves forming the sum and difference of x L and x R , filtering these signals, and then undoing the sum and difference operation. <p> In practice, the transaural filters are often based on a simplified head model. For instance, the responses H i and H c may be derived from a spherical head model <ref> [3] </ref>. This can lead to a simple implementation of the transaural filter, and one that is not specific to a particular listener. At high frequencies, where pinna response becomes important (&gt; 8 kHz), the head effectively acts as a ba*e, and therefore the crosstalk between channels is small.
Reference: [4] <author> P. Damaske. </author> <title> "Head-related Two-channel Stereophony with Loudspeaker Reproduction". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 50(4) </volume> <pages> 1109-1115, </pages> <year> 1971. </year>
Reference-contexts: The calibration procedure involves adjusting the parameters such that single sided noises are located as close as possible to their corresponding ears and the stereo noise is maximally enveloping <ref> [4, 8] </ref>. The interaural delay parameter has the most effect of steering the signal and changing the timbre, provided the gain parameter is sufficiently close to 1. The lowpass cuttoff has the most subtle effect.
Reference: [5] <author> N. I. Durlach, A. Rigopulos, X. D. Pang, W. S. Woods, A. Kulkarni, H. S. Colburn, and E. M. Wenzel. </author> <title> "On the Externalization of Auditory Images". </title> <journal> Presence, </journal> <volume> 1(2) </volume> <pages> 251-257, </pages> <year> 1992. </year>
Reference-contexts: Externalization can be improved by using the listener's own head responses, adding reverberation, and adding dynamic cues <ref> [5] </ref>. * Frontal sounds are localized between the ears or on top ot the head, rather than in front of the listener.
Reference: [6] <author> W. G. Gardner. </author> <title> "Efficient convolution without input-output delay". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 43(3) </volume> <pages> 127-136, </pages> <year> 1995. </year>
Reference-contexts: For efficiency, the convolution is accomplished using an overlap-save block convolver [15] based on the fast Fourier transform (FFT). Because the impulse response is 128 points long, the convolution is performed in 128-point blocks, using a 256-point real FFT <ref> [6] </ref>. The forward transforms of all HRTFs are pre-computed. For each 128-point block of input samples (every 4 msec), the forward transform of the samples is calculated, and then two spectral multiplies and two inverse FFTs are calculated to form the two 128-point blocks of output samples.
Reference: [7] <author> W. G. Gardner and K. D. Martin. </author> <title> "HRTF measurements of a KEMAR". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 97(6) </volume> <pages> 3907-3908, </pages> <year> 1995. </year>
Reference-contexts: The HRTFs were measured using a KE-MAR (Knowles Electronics Mannequin for Acoustics Re search), which is a high quality dummy-head microphone. The HRTFs were measured in 10 degree elevation increments from -40 to +90 degrees <ref> [7] </ref>. In the horizontal plane (0 degrees elevation), measurements were made every 5 3 symmetric listening arrangement. degrees of azimuth. In total, 710 directions were measured. The sampling density was chosen to be roughly in accordance with the localization resolution of humans. <p> It is dominated by the ear canal 2 The equalization would normally be done separately for each ear to adjust for differences between left and right channels. However, our HRTFs were derived from a single ear measured for the full 360 degrees azimuth <ref> [7] </ref>. resonance at 2-3 kHz. The low-frequency dropoff is a result of the poor low-frequency response of the measurement speaker. The inverse equalizing filter was gain limited to prevent excessive noise amplification at extreme frequen cies. It was desired to build a realtime spatializer on a Silicon Graphics Indigo workstation.
Reference: [8] <author> David Griesinger. </author> <title> "Theory and Design of a Digital Audio Signal Processor for Home Use". </title> <journal> J. Audio Eng. Soc., </journal> 37(1/2):40-50, 1989. 
Reference-contexts: The calibration procedure involves adjusting the parameters such that single sided noises are located as close as possible to their corresponding ears and the stereo noise is maximally enveloping <ref> [4, 8] </ref>. The interaural delay parameter has the most effect of steering the signal and changing the timbre, provided the gain parameter is sufficiently close to 1. The lowpass cuttoff has the most subtle effect.
Reference: [9] <author> David Griesinger. </author> <type> Personal communication, </type> <year> 1995. </year>
Reference-contexts: Furthermore, the variation in head response for different people is greatest at high frequencies [14]. Consequently, there is little point in modeling pinna response when constructing a transaural filter <ref> [9] </ref>. The transaural system is fragile in the sense that it only works for a single listener in a known position and orientation. <p> Lack of memory is not a problem in our implementation. 6 Implementation of transaural filter Our transaural filter is based on a simplified head model for sources at standard stereo speaker locations, which was suggested by David Griesinger <ref> [9] </ref>. The ipsilateral response is taken to be unity and the contralateral response is modeled as a delay, attenuation, and a lowpass filter.
Reference: [10] <author> J. M. Jot, Veronique Larcher, and Olivier Warusfel. </author> <title> "Digital signal processing issues in the context of binaural and transaural stereophony". </title> <journal> In Proc. Audio Eng. Soc. </journal> <volume> Conv., </volume> <year> 1995. </year>
Reference-contexts: One way to eliminate all factors which do not vary as a function of direction is to equalize the HRTFs to a diffuse-field reference <ref> [10] </ref>. <p> Many of these strategies are discussed in <ref> [10] </ref>. To obtain the best price/performance ratio, commercial spatializers attempt to be as efficient as possible, and usually run on dedicated DSPs. Consequently, the filters are modeled as efficiently as possible and the algorithms are hand-coded.
Reference: [11] <author> Keith D. Martin. </author> <title> A computational model of spatial hearing. </title> <type> Master's thesis, </type> <institution> MIT Dept. of Elec. Eng., </institution> <year> 1995. </year>
Reference-contexts: This is somewhat risky because the resulting interaural phase may be completely distorted. It would appear, however, that interaural amplitudes as a function of frequency encode more useful directional information than interaural phase <ref> [11] </ref>. Because interaural differences are of paramount importance for localization, any attempt to parameterize pairs of HRTFs to simplify implementation should focus on the interaural differences as an error metric.
Reference: [12] <author> Henrik Moller, Dorte Hammershoi, Clemen Boje Jensen, and Michael Fris Sorensen. </author> <title> "Transfer Characteristics of Headphones Measured on Human Ears". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 43(4) </volume> <pages> 203-217, </pages> <year> 1995. </year>
Reference-contexts: Three sliders are assigned to control azimuth, elevation, and distance (gain). A constant amount of reverberation can be mixed into the final output using an external reverberator as shown in figure 2. The spatializer was evaluated using headphones (AKG-K240, which are diffuse-field equalized <ref> [18, 12, 13] </ref>). The input sound, usually music of various sorts, was taken from one channel of a compact disc recording. The spatializer worked quite well for lateral and rear directions for all listeners. As expected, some listeners had problems with front-back reversals.
Reference: [13] <author> Henrik Moller, Clemen Boje Jensen, Dorte Hammer-shoi, and Michael Fris Sorensen. </author> <title> "Design Criteria 6 for Headphones". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 43(4) </volume> <pages> 218-232, </pages> <year> 1995. </year>
Reference-contexts: Three sliders are assigned to control azimuth, elevation, and distance (gain). A constant amount of reverberation can be mixed into the final output using an external reverberator as shown in figure 2. The spatializer was evaluated using headphones (AKG-K240, which are diffuse-field equalized <ref> [18, 12, 13] </ref>). The input sound, usually music of various sorts, was taken from one channel of a compact disc recording. The spatializer worked quite well for lateral and rear directions for all listeners. As expected, some listeners had problems with front-back reversals.
Reference: [14] <author> Henrik Moller, Michael Fris Sorensen, Dorte Hammer-shoi, and Clemen Boje Jensen. </author> <title> "Head-Related Transfer Functions of Human Subjects". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 43(5) </volume> <pages> 300-321, </pages> <year> 1995. </year>
Reference-contexts: Depending on the application, a head response may be measured at the entrance of the ear canal or at the eardrum. The ear canal response itself has been shown to be invariant of source position <ref> [14] </ref>. HRTFs are usually measured using human subjects or dummy-head microphones, and consist of response pairs, for the left and right ears, corresponding to a large number of source positions surrounding the head. <p> At high frequencies, where pinna response becomes important (&gt; 8 kHz), the head effectively acts as a ba*e, and therefore the crosstalk between channels is small. Furthermore, the variation in head response for different people is greatest at high frequencies <ref> [14] </ref>. Consequently, there is little point in modeling pinna response when constructing a transaural filter [9]. The transaural system is fragile in the sense that it only works for a single listener in a known position and orientation.
Reference: [15] <author> Alan V. Oppenheim and Ronald W. Schafer. </author> <title> Discrete Time Signal Processing. </title> <publisher> Prentice Hall, </publisher> <address> Engle-wood Cliffs, NJ, </address> <year> 1989. </year>
Reference-contexts: The spatializer simply convolves an monophonic input signal with a pair of HRTFs to produce a stereophonic (binaural) output. The HRTFs that are closest to the desired azimuth and elevation are used. For efficiency, the convolution is accomplished using an overlap-save block convolver <ref> [15] </ref> based on the fast Fourier transform (FFT). Because the impulse response is 128 points long, the convolution is performed in 128-point blocks, using a 256-point real FFT [6]. The forward transforms of all HRTFs are pre-computed.
Reference: [16] <author> M. R. Schroeder and B. S. Atal. </author> <title> "Computer simulation of sound transmission in rooms". </title> <journal> IEEE Conv. Record, </journal> <volume> 7 </volume> <pages> 150-155, </pages> <year> 1963. </year>
Reference-contexts: The basic idea is to filter the binaural signal such that the subsequent stereo presentation produces the binaural signal at the ears of the listener. The technique was first put into 2 practice by Schroeder and Atal <ref> [16, 17] </ref> and later refined by Cooper and Bauck [3], who referred to it as "transaural audio".
Reference: [17] <author> M. R. Schroeder, D. Gottlob, and K. F. Siebrasse. </author> <title> "Comparative Stude of European Concert Halls". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 56 </volume> <pages> 1195-1201, </pages> <year> 1974. </year>
Reference-contexts: The basic idea is to filter the binaural signal such that the subsequent stereo presentation produces the binaural signal at the ears of the listener. The technique was first put into 2 practice by Schroeder and Atal <ref> [16, 17] </ref> and later refined by Cooper and Bauck [3], who referred to it as "transaural audio".
Reference: [18] <author> G. Theile. </author> <title> "On the Standardization of the Frequency Response of High-Quality Studio Headphones". </title> <journal> J. Audio Eng. Soc., </journal> <volume> 34 </volume> <pages> 956-969, </pages> <year> 1986. </year>
Reference-contexts: Three sliders are assigned to control azimuth, elevation, and distance (gain). A constant amount of reverberation can be mixed into the final output using an external reverberator as shown in figure 2. The spatializer was evaluated using headphones (AKG-K240, which are diffuse-field equalized <ref> [18, 12, 13] </ref>). The input sound, usually music of various sorts, was taken from one channel of a compact disc recording. The spatializer worked quite well for lateral and rear directions for all listeners. As expected, some listeners had problems with front-back reversals.
Reference: [19] <author> E. M. Wenzel. </author> <title> "Localization in Virtual Acoustic Displays". </title> <journal> Presence, </journal> <volume> 1(1) </volume> <pages> 80-107, </pages> <year> 1992. </year>
Reference-contexts: There are several problems common to headphone spa-tializers: * The HRTFs used for sythesis are often a generic set and not the specific HRTFs of the listener. This can cause localization performance to suffer <ref> [19, 20] </ref>, particularly in regards to front-back discrimination, el beration. evation perception, and externalization. When the listener's own head responses are used, their localization performance is comparable to natural listening [21]. * The auditory scene created moves with the head. <p> This can be fixed by dynamically tracking the orientation of the head and updating the HRTFs appropriately. Localization performance and realism should both im prove when dynamic cues are added <ref> [19] </ref>. * The auditory images created are not perceived as being external to the head, but rather are localized at the head or inside the head. <p> Because we are used to seeing sound sources that are in front of the head, it is difficult to convince the perceptual system that a sound is coming from the front without a corresponding visual cue <ref> [19] </ref>. However, when using the listener's own HRTF's, frontal imaging with headphones can be excellent. 3 Principles of transaural audio Transaural audio is a method used to deliver binaural signals to the ears of a listener using stereo loudspeakers.
Reference: [20] <author> E. M. Wenzel, M. Arruda, D. J. Kistler, and F. L. Wightman. </author> <title> "Localization using nonindividualized head-related transfer functions". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 94(1) </volume> <pages> 111-123, </pages> <year> 1993. </year>
Reference-contexts: There are several problems common to headphone spa-tializers: * The HRTFs used for sythesis are often a generic set and not the specific HRTFs of the listener. This can cause localization performance to suffer <ref> [19, 20] </ref>, particularly in regards to front-back discrimination, el beration. evation perception, and externalization. When the listener's own head responses are used, their localization performance is comparable to natural listening [21]. * The auditory scene created moves with the head.
Reference: [21] <author> F. L. Wightman and D. J. Kistler. </author> <title> "Headphone simulation of free-field listening". </title> <journal> J. Acoust. Soc. Am., </journal> <volume> 85 </volume> <pages> 858-878, </pages> <year> 1989. </year>
Reference-contexts: This can cause localization performance to suffer [19, 20], particularly in regards to front-back discrimination, el beration. evation perception, and externalization. When the listener's own head responses are used, their localization performance is comparable to natural listening <ref> [21] </ref>. * The auditory scene created moves with the head. This can be fixed by dynamically tracking the orientation of the head and updating the HRTFs appropriately.
Reference: [22] <author> William A. Yost and George Gourevitch, </author> <title> editors. Directional Hearing. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: The interaural differences are particularly important cues, because they don't depend on the details of the source spectrum. Human auditory localization has been studied extensively <ref> [2, 22] </ref>. The directional dependent filtering to each ear can be expressed as a frequency response, called a head-related transfer function (HRTF) 1 , and thus a pair of HRTFs describes how sound from one location reaches the two ears.
References-found: 22

