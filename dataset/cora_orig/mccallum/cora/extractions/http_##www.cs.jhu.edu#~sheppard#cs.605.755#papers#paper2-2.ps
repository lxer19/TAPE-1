URL: http://www.cs.jhu.edu/~sheppard/cs.605.755/papers/paper2-2.ps
Refering-URL: http://www.cs.jhu.edu/~sheppard/cs.605.755/sched.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: An Overview of Genetic Algorithms: Part 2, Research Topics  
Author: David Beasley David R. Bull Ralph R. Martin 
Degree: c UCISA. All rights reserved.  
Note: No part of this article may be reproduced for commercial purposes.  
Date: 1993, 15(4) 170-181.  
Address: Cardiff, Cardiff, CF2 4YN, UK  BS8 1TR, UK  Cardiff, Cardiff, CF2 4YN, UK  
Affiliation: Department of Computing Mathematics, University of Wales College of  Department of Electrical and Electronic Engineering, University of Bristol, Bristol,  Department of Computing Mathematics, University of Wales College of  
Pubnum: University Computing,  
Abstract-found: 0
Intro-found: 1
Reference: [Ack87] <author> D.H. Ackley. </author> <title> An empirical study of bit vector function optimization. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 13, </booktitle> <pages> pages 170-204. </pages> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: However, a potential drawback of this technique which must be avoided is that it may reward operators which simply locate local optima, rather than helping to find the global optimum. Going in the opposite direction, several researchers vary the mutation probability by decreasing it exponentially during a run <ref> [Ack87, Bra91, Fog89, MJ91] </ref>. Unfortunately, no clear analysis or reasoning is given as to why this should lead to an improvement (although Fogarty [Fog89] provides experimental evidence). <p> The motivation seems to be that mutation probability is analogous to temperature in simulated annealing, and so mutation rate should be reduced to a low value to aid convergence. However, in Ackley's case <ref> [Ack87] </ref>, probability is varied from 0.25 to 0.02, and most would say that 0.02 is still a rather high value for mutation probability. Ackley does not appear to have thought this through. Fogarty does not say whether he thinks that the improvements he found would apply in other problem areas.
Reference: [Ang92] <author> Peter J. Angeline. </author> <title> Antonisse's extension to schema notation. </title> <address> GA-Digest, 6(35):-, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: But Antonisse [Ant89], interprets schemata differently, and concludes that, on the contrary, high-cardinality alphabets contain more schemata than binary ones. (This has been the subject of more recent discussion <ref> [Ang92, Ant92] </ref>.) Goldberg has now developed a theory which explains why high-cardinality representations can perform well [Gol90]. His theory of virtual alphabets says that each symbol converges within the first few generations, leaving only a small number of possible values.
Reference: [Ant89] <author> J. Antonisse. </author> <title> A new interpretation of schema notation that overturns the binary encoding constraint. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 86-91. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Higher cardinality alphabets have been used in some research, and some believe them to have advantages. Goldberg [Gol89a, p80][Gol89b] argues that theoretically, a binary representation gives the largest number of schemata, and so provides the highest degree of implicit parallelism. But Antonisse <ref> [Ant89] </ref>, interprets schemata differently, and concludes that, on the contrary, high-cardinality alphabets contain more schemata than binary ones. (This has been the subject of more recent discussion [Ang92, Ant92].) Goldberg has now developed a theory which explains why high-cardinality representations can perform well [Gol90].
Reference: [Ant92] <author> Jim Antonisse. Re: </author> <title> Antonisse's extension to schema notation. </title> <address> GA-Digest, 6(37):-, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: But Antonisse [Ant89], interprets schemata differently, and concludes that, on the contrary, high-cardinality alphabets contain more schemata than binary ones. (This has been the subject of more recent discussion <ref> [Ang92, Ant92] </ref>.) Goldberg has now developed a theory which explains why high-cardinality representations can perform well [Gol90]. His theory of virtual alphabets says that each symbol converges within the first few generations, leaving only a small number of possible values.
Reference: [BBM93a] <author> D. Beasley, D.R. Bull, and R.R. Martin. </author> <title> An overview of genetic algorithms: Part 1, fundamentals. </title> <journal> University Computing, </journal> <volume> 15(2) </volume> <pages> 58-69, </pages> <year> 1993. </year>
Reference-contexts: 1 Introduction Genetic algorithms, and other closely related areas such as genetic programming, evolution strategies and evolution programs, are the subject of an increasing amount of research interest. This two-part article is intended provide an insight into this field. In the first part of this article <ref> [BBM93a] </ref> we described the fundamental aspects of genetic algorithms (GAs). We explained their basic principles, such as task representation, fitness functions and reproduction operators. We explained how they work, and compared them with other search techniques. We described several practical aspects of GAs, and mentioned a number of applications. <p> This means that reordering operators such as inversion (see next section) are unnecessary, and we do not have to worry about positioning genes so as to promote building blocks. GA performance using 2-point crossover drops dramatically if the recommendations of the building block hypothesis <ref> [BBM93a] </ref> are not adhered to.
Reference: [BBM93b] <author> D. Beasley, D.R. Bull, and R.R. Martin. </author> <title> Reducing epistasis in combinatorial problems by expansive coding. </title> <editor> In S. Forrest, editor, </editor> <booktitle> Proceedings of the Fifth International Conference on Genetic Algorithms, </booktitle> <pages> pages 400-407. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Until such a time as we have GAs which are effective on problems of high epistasis, we must devise representation schemes (or crossover/mutation operators) which reduce epistasis to an acceptable level. A technique for achieving this, expansive coding, is presented by Beasley, Bull & Martin <ref> [BBM93b] </ref>. Expansive coding is a technique for designing reduced-epistasis representations for combinatorial problems. Rather than having a representation consisting of a small number of widely interacting genes, a representation is created with a much larger number of more weakly interacting genes.
Reference: [BBM93c] <author> D. Beasley, D.R. Bull, and R.R. Martin. </author> <title> A sequential niche technique for multimodal function optimization. </title> <journal> Evolutionary Computation, </journal> <volume> 1(2) </volume> <pages> 101-125, </pages> <year> 1993. </year>
Reference-contexts: One solution might be to iterate the GA, trying different values for niche radius. An optimum scheme for this could be worth investigating. A different approach to sharing is described by Beasley, Bull & Martin <ref> [BBM93c] </ref>. Their sequential niche method involves multiple runs of a GA, each locating one peak. After a peak has been located, the fitness function is modified so that the peak is effectively "cancelled out" from the fitness function.
Reference: [Bel89] <author> R.K. Belew. </author> <title> When both individuals and popluations search: adding simple learning to the genetic algorithm. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 34-41. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Schaffer [Sch85] encountered the simplest version of this problem|three valid states represented by 2 bits. He used fixed remapping|allowing one state to have two binary representations. He also tried using ternary coding to avoid the problem, but performance was inferior. Belew <ref> [Bel89] </ref> also used fixed remapping to solve the three-state problem.
Reference: [Boo85] <author> L. Booker. </author> <title> Improving the performance of genetic algorithms in classifier systems. </title> <editor> In J.J. Grefen-stette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 80-92. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: This again aids diversity, and indirectly encourages speciation. Stadnyk [Sta87] found better results using a variation on this. The sampling of individuals was biassed according to inverse fitness, so that new offspring replace others which are in the same niche and have low fitness. Booker <ref> [Boo85] </ref> uses restricted mating to encourage speciation. In this scheme, individuals are only allowed to mate if they are similar. The total reward available in any niche is fixed, and is distributed using a bucket-brigade mechanism. <p> But in a highly epistatic chromosome, there is no guarantee that these offspring will not be of low fitness, i.e. "lethals". Similarity of genotype does not guarantee similarity of phenotype. These effects limit the use of restricted mating. Restricted mating schemes of Booker <ref> [Boo85] </ref> and Deb & Goldberg [DG89] have been described above. These restrict mating on the basis of similarities between the genotypes or phenotypes.
Reference: [Boo87] <author> L. Booker. </author> <title> Improving search in genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 5, </booktitle> <pages> pages 61-73. </pages> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: This is less likely to happen with uniform crossover. They describe a new 2-point crossover operator such that if identical offspring are produced, two new cross points are chosen. (Booker <ref> [Boo87] </ref> introduced reduced surrogate crossover to achieve the same effect.) This operator was then found to perform better than uniform crossover on a test problem (but only slightly better). <p> This produces a search space which is larger, yet simpler and more easily solved. They demonstrate that this technique can design reduced complexity algorithms for signal processing. 7 Mutation and Nave Evolution Mutation is traditionally seen as a "background" operator <ref> [Boo87, p63] </ref>[DeJ85], responsible for re-introducing inadvertently "lost" gene values (alleles), preventing genetic drift, and providing a small element of random search in the vicinity of the population when it has largely converged. <p> Davis [Dav85b] tried linear variations in crossover and mutation probability, with crossover decreasing during the run, and mutation increasing (see above). Syswerda [Sys91] also found this advantageous. However, it imposes a fixed schedule. Booker <ref> [Boo87] </ref> utilises a dynamically variable crossover rate, depending on the spread of fitnesses. When the population converges, the crossover rate is reduced to give more opportunity for mutation to find new variations. This has a similar effect to Davis's linear technique, but has the advantage of being adaptive.
Reference: [Bra91] <author> M.F. Bramlette. </author> <title> Initialisation, mutation and selection methods in genetic algorithms for function optimization. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 100-107. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: His theory of virtual alphabets says that each symbol converges within the first few generations, leaving only a small number of possible values. In this way, each symbol effectively has only a low cardinality. Empirical studies of high-cardinality alphabets have typically used chromosomes where each symbol represents an integer <ref> [Bra91] </ref>, or a floating-point number [JM91, MJ91]. As Davis [Dav91d, p65] points out, problem parameters are often numeric, so representing them directly as numbers, rather than bit-strings, seems obvious, and may have advantages. One advantage is that we can more easily define meaningful, problem-specific "crossover" and "mutation" operators. <p> However, a potential drawback of this technique which must be avoided is that it may reward operators which simply locate local optima, rather than helping to find the global optimum. Going in the opposite direction, several researchers vary the mutation probability by decreasing it exponentially during a run <ref> [Ack87, Bra91, Fog89, MJ91] </ref>. Unfortunately, no clear analysis or reasoning is given as to why this should lead to an improvement (although Fogarty [Fog89] provides experimental evidence).
Reference: [CS91] <author> W. Crompton and N.M. Stephens. </author> <title> Using genetic algorithms to search for binary sequences with large merit factor. </title> <booktitle> In Proc. Third IMA Conf on Cryptography and Coding, </booktitle> <month> pages -, </month> <year> 1991. </year> <note> Not yet published. </note>
Reference-contexts: A technique which distributes population members to peaks in proportion to the fitness of the peak, as the methods described above do, will not be likely to find the global maximum if there are more peaks than population members. Crompton & Stephens <ref> [CS91] </ref> found that on a real problem, the introduction of niche formation by crowding gave no improvement. Deb's assumption that the function maxima are evenly distributed gives the upper bound on the niche radius, and better results might be obtained using a smaller value.
Reference: [Dav85a] <author> L. Davis. </author> <title> Applying adaptive algorithms to epistatic domains. </title> <booktitle> In 9th Int. Joint Conf. on AI, </booktitle> <pages> pages 162-164, </pages> <year> 1985. </year>
Reference-contexts: If genes in a chromosome have high epistasis, a new theory may have to be developed, and new algorithms developed to cope with this. The inspiration may once again come from natural genetics, where epistasis (in the GA sense) is very common. Davis <ref> [Dav85a] </ref> considers both these approaches. He converts a bin-packing problem, where the optimum positions for packing rectangles into a space must be found, into an order problem, where the order of packing the rectangles had to be found instead.
Reference: [Dav85b] <author> L. Davis. </author> <title> Job shop scheduling with genetic algorithms. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 136-140. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: Floating point representations have been widely explored [Whi89, JM91, MJ91, ES93], and Michalewicz has looked at a matrix as the data structure [Mic92]. 9 Dynamic Operator Probabilities During the course of a run, the optimal value for each operator probability may vary. Davis <ref> [Dav85b] </ref> tried linear variations in crossover and mutation probability, with crossover decreasing during the run, and mutation increasing (see above). Syswerda [Sys91] also found this advantageous. However, it imposes a fixed schedule. Booker [Boo87] utilises a dynamically variable crossover rate, depending on the spread of fitnesses.
Reference: [Dav89] <author> L. Davis. </author> <title> Adapting operator probabilities in genetic algorithms. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 61-69. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: When the population converges, the crossover rate is reduced to give more opportunity for mutation to find new variations. This has a similar effect to Davis's linear technique, but has the advantage of being adaptive. Davis <ref> [Dav89, Dav91d] </ref> describes another adaptive technique which is based directly on the success of an operator at producing good offspring. Credit is given to each operator when it produces a chromosome better than any other in the population.
Reference: [Dav90] <author> Y. Davidor. </author> <title> Epistasis variance: Suitability of a representation to genetic algorithms. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 369-383, </pages> <year> 1990. </year>
Reference-contexts: So, although Holland's convergence proof for a GA assumed low epistasis, there may be another, perhaps weaker, convergence proof for domains of high epistasis. Even rigourous definitions of "low epistasis" and "high epistasis" have yet to be formulated. Davidor <ref> [Dav90] </ref> has attempted to develop a technique which allows the degree of epistasis in a problem to be measured. Unfortunately an accurate assessment of epistasis can only be made with a time complexity comparable to an exhaustive search of the problem space.
Reference: [Dav91a] <author> Y. Davidor. </author> <title> A genetic algorithm applied to robot trajectory generation. </title> <editor> In L. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, chapter 12, </booktitle> <pages> pages 144-165. </pages> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year> <month> 12 </month>
Reference-contexts: The idea that crossover should be more probable at some string positions than others has some basis in nature, and several such methods have been described <ref> [SM87, Hol87, Dav91a, Lev91, LR91] </ref>. The general principle is that the GA adaptively learns which sites should be favoured for crossover. This information is recorded in a punctuation string, which is itself part of the chromosome, and so is crossed over and passed on to descendants. <p> Domain knowledge may be used to prevent obviously unfit chromosomes, or those which would violate problem constraints, from being produced in the first place. This avoids wasting time evaluating such individuals, and avoids introducing poor performers into the population. For example, Davidor <ref> [Dav91a] </ref> designed "analogous crossover" for his task in robotic trajectory generation. This used local information in the chromosome (i.e. the values of just a few genes) to decide which crossover sites would be certain to yield unfit offspring.
Reference: [Dav91b] <author> Y. Davidor. </author> <title> A naturally occuring niche and species phenomenon: the model and first results. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 257-263. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: This is an ideal method for use on a parallel processor system. (Fourman [Fou85] proposed a similar scheme.) However, there is no mechanism for explicitly preventing two or more subpopulations converging on the same niche. Davidor <ref> [Dav91b] </ref> used a similar approach, but instead of multiple subpopulations, the population was considered as spread evenly over a two-dimensional grid. A local mating scheme was used, achieving a similar 8 effect to multiple subpopulations, but without any explicit boundaries.
Reference: [Dav91c] <author> L. Davis. </author> <title> Bit climbing, representational bias and test suite design. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 18-23. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: This is how we shall use the term, unless otherwise stated. Tasks in which all genes are of type 0 or 1 can be solved efficiently by various simple techniques, such as hillclimbing, and do not require a GA <ref> [Dav91c] </ref>. GAs can, however, outperform simple techniques on more complex level 2 tasks exhibiting many interactions among the parameters|that is, with significant epistasis.
Reference: [Dav91d] <author> L. Davis. </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: Offspring have genes which inherit ordering information from each parent. This avoids the generation of offspring which violate problem constraints. Syswerda [Sys91] and Davis <ref> [Dav91d, p72] </ref> describe other order-based operators. <p> They investigate this hypothesis further [SE91], and find that crossover gives much faster evolution than a mutation-only population. However, in the end, mutation generally finds better solutions than a crossover-only regime. This is in agreement with Davis <ref> [Dav91d] </ref>, who points out that mutation becomes more productive, and crossover less productive, as the population converges. Despite its generally low probability of use, mutation is a very important operator. Its optimum probability is much more critical than that for crossover [SCLD89]. <p> In this way, each symbol effectively has only a low cardinality. Empirical studies of high-cardinality alphabets have typically used chromosomes where each symbol represents an integer [Bra91], or a floating-point number [JM91, MJ91]. As Davis <ref> [Dav91d, p65] </ref> points out, problem parameters are often numeric, so representing them directly as numbers, rather than bit-strings, seems obvious, and may have advantages. One advantage is that we can more easily define meaningful, problem-specific "crossover" and "mutation" operators. <p> When the population converges, the crossover rate is reduced to give more opportunity for mutation to find new variations. This has a similar effect to Davis's linear technique, but has the advantage of being adaptive. Davis <ref> [Dav89, Dav91d] </ref> describes another adaptive technique which is based directly on the success of an operator at producing good offspring. Credit is given to each operator when it produces a chromosome better than any other in the population. <p> Little work seems to have been done in this area|Goldberg [Gol89a, p148] provides a summary. 13 Knowledge-based Techniques While most research has gone into GAs using the traditional crossover and mutation operators, some have advocated designing new operators for each task, using domain knowledge <ref> [Dav91d] </ref>. This makes each GA more task specific (less robust), but may improve performance significantly. Where a GA is being designed to tackle a real-world problem, and has to compete with other search and optimisation techniques, the incorporation of domain knowledge often makes sense. <p> Goldberg [Gol89a, p201-6] describes techniques for adding knowledge-directed crossover and mutation. He also discusses the hybridisation of GAs with other search techniques (as does Davis <ref> [Dav91d] </ref>). 10 14 Redundant Value Mapping A problem occurs when a gene may only have a finite number of discrete valid values. <p> Where special-purpose techniques have been identified, work is still required to determine whether these can be extended to make them more general, or further specialised to make them more powerful. Theoretical research can greatly help progress in this area. Davis <ref> [Dav91d] </ref> describes a variety of promising ideas. Steady state replacement, fitness ranking, and 2-point crossover (modified so that offspring must differ from their parents) are often good methods to use, although with suitable parent selection techniques, generational replacement may be equally as good [GD91], and uniform crossover can have advantages.
Reference: [DC87] <author> L. Davis and S. Coombs. </author> <title> Genetic algorithms and communication link speed design: theoretical considerations. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 252-256. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: Goldberg [Gol85] describes how GA theory can be adapted to encompass order-based problems. He introduces the idea of order-schemata (o-schemata), and the PMX crossover method which processes o-schemata in an analogous way to conventional crossover and normal schemata. Davis & Coombs <ref> [DC87] </ref> point out that GAs have been made to work even in domains of high epistasis. So, although Holland's convergence proof for a GA assumed low epistasis, there may be another, perhaps weaker, convergence proof for domains of high epistasis.
Reference: [DeJ75] <author> K. DeJong. </author> <title> The Analysis and behaviour of a Class of Genetic Adaptive Systems. </title> <type> PhD thesis, </type> <institution> University of Michigan, </institution> <year> 1975. </year>
Reference-contexts: However, many different crossover algorithms have been devised, often involving more than one cut point. DeJong <ref> [DeJ75] </ref> investigated the effectiveness of multiple-point crossover, and concluded (as reported in [Gol89a, p119]) that 2-point crossover gives an improvement, but that adding further crossover points reduces the performance of the GA. The problem with adding additional crossover points is that building blocks are more likely to be disrupted. <p> This method helps to maintain diversity (since strings tend to replace others which are similar to themselves), and this helps prevent convergence on a single maximum. DeJong <ref> [DeJ75] </ref> generalised preselection in his crowding scheme. In this, offspring are compared with a few (typically 2 or 3) randomly chosen individuals from the population. The offspring replaces the most similar one found, using Hamming distance as the similarity measure. This again aids diversity, and indirectly encourages speciation.
Reference: [DeJ85] <author> K. DeJong. </author> <title> Genetic algorithms: A 10 year perspective. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 169-177. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: The problem is, what to do about them? This problem has not been greatly studied in the literature (perhaps because most research concentrates on continuous-valued functions, where the problem does not arise). A number of solutions are briefly mentioned by DeJong <ref> [DeJ85] </ref>: 1. Discard the chromosome as illegal. 2. Assign the chromosome low fitness. 3. Map the invalid code to a valid one. Solutions 1) and 2) would be expected to give poor performance, since we may be throwing away good gene values elsewhere in the chromosome.
Reference: [DG89] <author> K. Deb and D.E. Goldberg. </author> <title> An investigation of niche and species formation in genetic function optimization. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 42-50. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: In a 1-dimensional task, this method was shown to be able to distribute individuals to peaks in the fitness function in proportion to the height of the peak. In a later continuation of this work, Deb & Goldberg <ref> [DG89] </ref> show that sharing is superior to crowding. Genotypic sharing (based on some distance measure between chromosome strings) and phenotypic sharing (based on the distance between the decoded parameters) are analysed. Phenotypic sharing is shown to have advantages. <p> But in a highly epistatic chromosome, there is no guarantee that these offspring will not be of low fitness, i.e. "lethals". Similarity of genotype does not guarantee similarity of phenotype. These effects limit the use of restricted mating. Restricted mating schemes of Booker [Boo85] and Deb & Goldberg <ref> [DG89] </ref> have been described above. These restrict mating on the basis of similarities between the genotypes or phenotypes.
Reference: [DG91] <author> K. Deb and D.E. Goldberg. </author> <title> Analyzing deception in trap functions. </title> <type> Technical Report IlliGal 91009, </type> <institution> Illigal, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: Furthermore, a problem is referred to as fully deceptive if "all low-order schemata containing a suboptimal solution are better than other competing schemata" <ref> [DG91] </ref>. Deceptive problems are difficult to solve. However, Grefenstette [Gre93] cleverly demonstrates that this is not always the case. After the first generation, a GA does not get an unbiassed sample of points in the search space. Therefore it cannot estimate the global, unbiassed average fitness of a schema.
Reference: [DS90] <author> K. DeJong and W.M. Spears. </author> <title> An analysis of the interacting roles of population size and crossover in genetic algorithms. </title> <editor> In H.-P. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 38-47. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: In a slightly later paper, DeJong & Spears <ref> [DS90] </ref> conclude that modified 2-point crossover is best for large populations, but the increased disruption of uniform crossover is beneficial if the population size is small (in comparison to the problem complexity), and so gives a more robust performance. 2.4 Other crossover techniques Many other techniques have been suggested.
Reference: [ECS89] <editor> L.J. Eshelman, R. Caruna, and J.D. Schaffer. </editor> <title> Biases in the crossover landscape. </title> <editor> In J.D. Schaf-fer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 10-19. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Uniform crossover therefore appears to be more robust. Eshelman et al <ref> [ECS89] </ref> did an extensive comparison of different crossover operators, including 1-point, 2-point, multi-point and uniform crossover. These were analysed theoretically in terms of positional and distributional bias, and empirically, on several problems.
Reference: [EOR91] <author> Christer Ericson and Ivan Ordonez-Reinoso. </author> <title> Dialogue on uniform crossover. </title> <address> GA-Digest, 5(33):-, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: He concludes that "standard mutation and crossover are simply two forms of a more general exploration operator, that can perturb alleles based on any available information." Other good performances of nave evolution have been reported <ref> [EOR91, ES91, Esh91] </ref>.
Reference: [ES91] <editor> Larry J. Eshelman and J. David Schaffer. </editor> <title> GAs and very fast simulated re-annealing. </title> <address> GA-Digest, 5(37):-, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: He concludes that "standard mutation and crossover are simply two forms of a more general exploration operator, that can perturb alleles based on any available information." Other good performances of nave evolution have been reported <ref> [EOR91, ES91, Esh91] </ref>.
Reference: [ES93] <editor> Larry J. Eshelman and J. David Schaffer. </editor> <title> Real-coded genetic algorithms and interval schemata. </title> <editor> In L. Darrell Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <volume> 2, </volume> <pages> pages 187-202. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Schultz, lists various research using non-binary representations. These include Grefenstette's work which uses a rule-based representation to learn reactive strategies (or behaviours) for autonomous agents [SG90, Gre91]. Koza is using a process known as genetic programming to learn Lisp programs [Koz92]. Floating point representations have been widely explored <ref> [Whi89, JM91, MJ91, ES93] </ref>, and Michalewicz has looked at a matrix as the data structure [Mic92]. 9 Dynamic Operator Probabilities During the course of a run, the optimal value for each operator probability may vary.
Reference: [Esh91] <editor> Larry J. Eshelman. Bit-climbers and naive evolution. GA-Digest, 5(39):-, </editor> <month> December </month> <year> 1991. </year>
Reference-contexts: He concludes that "standard mutation and crossover are simply two forms of a more general exploration operator, that can perturb alleles based on any available information." Other good performances of nave evolution have been reported <ref> [EOR91, ES91, Esh91] </ref>. <p> He concludes that "standard mutation and crossover are simply two forms of a more general exploration operator, that can perturb alleles based on any available information." Other good performances of nave evolution have been reported [EOR91, ES91, Esh91]. According to Eshelman <ref> [Esh91] </ref>, "The key to nave evolution's success (assuming a bit-string representation) is the use of Gray coded parameters, making search much less susceptible to Hamming cliffs. : : : I do believe that nave evolution is a much more powerful algorithm than many people in the GA community have been willing
Reference: [Fog89] <author> T.C. Fogarty. </author> <title> Varying the probability of mutation in the genetic algorithm. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 104-109. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: However, a potential drawback of this technique which must be avoided is that it may reward operators which simply locate local optima, rather than helping to find the global optimum. Going in the opposite direction, several researchers vary the mutation probability by decreasing it exponentially during a run <ref> [Ack87, Bra91, Fog89, MJ91] </ref>. Unfortunately, no clear analysis or reasoning is given as to why this should lead to an improvement (although Fogarty [Fog89] provides experimental evidence). <p> Going in the opposite direction, several researchers vary the mutation probability by decreasing it exponentially during a run [Ack87, Bra91, Fog89, MJ91]. Unfortunately, no clear analysis or reasoning is given as to why this should lead to an improvement (although Fogarty <ref> [Fog89] </ref> provides experimental evidence). The motivation seems to be that mutation probability is analogous to temperature in simulated annealing, and so mutation rate should be reduced to a low value to aid convergence.
Reference: [Fou85] <author> M.P. Fourman. </author> <title> Compaction of symbolic layout using genetic algorithms. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 141-153. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: Grosso [GR87] simulates partial geographical isolation in nature by using multiple subpopulations and intermediate migration rates. This shows advantages over isolated subpopulations (no migration|equivalent to simply iterating the GA), and completely mixed (panmictic) populations. This is an ideal method for use on a parallel processor system. (Fourman <ref> [Fou85] </ref> proposed a similar scheme.) However, there is no mechanism for explicitly preventing two or more subpopulations converging on the same niche. Davidor [Dav91b] used a similar approach, but instead of multiple subpopulations, the population was considered as spread evenly over a two-dimensional grid.
Reference: [GB90] <author> D.E. Goldberg and C.L. </author> <title> Bridges. An analysis of a reordering operator on a GA-hard problem. </title> <journal> Biological Cybernetics, </journal> <volume> 62 </volume> <pages> 397-405, </pages> <year> 1990. </year>
Reference-contexts: Many researchers have used inversion in their work, although it seems few have attempted to justify it, or quantify its contribution. Goldberg & Bridges <ref> [GB90] </ref> analyse a reordering operator on a very small task, and show that it can bring advantages|although they conclude that their methods would not bring the same advantages on larger tasks.
Reference: [GD91] <author> D.E. Goldberg and K. Deb. </author> <title> A comparative analysis of selection schemes used in genetic algorithms. </title> <editor> In G.J.E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 69-93. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: Davis [Dav91d] describes a variety of promising ideas. Steady state replacement, fitness ranking, and 2-point crossover (modified so that offspring must differ from their parents) are often good methods to use, although with suitable parent selection techniques, generational replacement may be equally as good <ref> [GD91] </ref>, and uniform crossover can have advantages. Knowledge-based operators and dynamic operator probabilities are probably going to help solve real world problems.
Reference: [GDH92] <author> D.E. Goldberg, K. Deb, and J. Horn. </author> <title> Massive multimodality, deception, and genetic algorithms. </title> <editor> In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <volume> 2, </volume> <pages> pages 37-46. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: This showed a significant improvement. A difficulty arises with niche methods if there are many local maxima with fitnesses close to the global maximum <ref> [GDH92] </ref>. A technique which distributes population members to peaks in proportion to the fitness of the peak, as the methods described above do, will not be likely to find the global maximum if there are more peaks than population members.
Reference: [Gol85] <author> D.E. Goldberg. </author> <title> Alleles, loci, and the TSP. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 154-159. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: This information is recorded in a punctuation string, which is itself part of the chromosome, and so is crossed over and passed on to descendants. In this way, punctuation strings which lead to good offspring will themselves be propagated through the population. Goldberg <ref> [Gol85, Gol89a] </ref> describes a rather different crossover operator, partially matched crossover (PMX), for use in order-based problems. (In an order-based problem, such as the travelling salesperson problem, gene values are fixed, and the fitness depends on the order in which they appear.) In PMX it is not the values of the <p> This reduces the epistasis in the chromosome. Once the problem has been converted to an order-based one, 4 The fitness of a schema is the average, or expected fitness of chromosomes which contain that schema. 5 a modified GA theory is required. Goldberg <ref> [Gol85] </ref> describes how GA theory can be adapted to encompass order-based problems. He introduces the idea of order-schemata (o-schemata), and the PMX crossover method which processes o-schemata in an analogous way to conventional crossover and normal schemata.
Reference: [Gol87] <author> D.E. Goldberg. </author> <title> Simple genetic algorithms and the minimal, deceptive problem. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 6, </booktitle> <pages> pages 74-88. </pages> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: This is known as deception. Deception is a special case of epistasis, and it has been studied in depth by Goldberg <ref> [Gol87] </ref> [Gol89a, p46][DG91] and others. Deception is directly related to the detrimental effects of epistasis in a GA. Level 2 epistasis is necessary (but not sufficient) for deception.
Reference: [Gol89a] <author> D.E. Goldberg. </author> <title> Genetic Algorithms in search, optimization and machine learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: However, many different crossover algorithms have been devised, often involving more than one cut point. DeJong [DeJ75] investigated the effectiveness of multiple-point crossover, and concluded (as reported in <ref> [Gol89a, p119] </ref>) that 2-point crossover gives an improvement, but that adding further crossover points reduces the performance of the GA. The problem with adding additional crossover points is that building blocks are more likely to be disrupted. <p> This information is recorded in a punctuation string, which is itself part of the chromosome, and so is crossed over and passed on to descendants. In this way, punctuation strings which lead to good offspring will themselves be propagated through the population. Goldberg <ref> [Gol85, Gol89a] </ref> describes a rather different crossover operator, partially matched crossover (PMX), for use in order-based problems. (In an order-based problem, such as the travelling salesperson problem, gene values are fixed, and the fitness depends on the order in which they appear.) In PMX it is not the values of the <p> randomly chosen positions within the chromosome. (When these techniques are used, genes must carry with them some kind of "label", so that they may be correctly identified irrespective of their position within the chromosome.) The purpose of reordering is to attempt to find gene orderings which have better evolutionary potential <ref> [Gol89a, p166] </ref>. Many researchers have used inversion in their work, although it seems few have attempted to justify it, or quantify its contribution. <p> This is known as deception. Deception is a special case of epistasis, and it has been studied in depth by Goldberg [Gol87] <ref> [Gol89a, p46] </ref>[DG91] and others. Deception is directly related to the detrimental effects of epistasis in a GA. Level 2 epistasis is necessary (but not sufficient) for deception. <p> Higher cardinality alphabets have been used in some research, and some believe them to have advantages. Goldberg <ref> [Gol89a, p80] </ref>[Gol89b] argues that theoretically, a binary representation gives the largest number of schemata, and so provides the highest degree of implicit parallelism. <p> Restricted mating schemes of Booker [Boo85] and Deb & Goldberg [DG89] have been described above. These restrict mating on the basis of similarities between the genotypes or phenotypes. Other schemes which restrict mating using additional mating template codes (for example [Hol87, p88]) are summarised by Goldberg <ref> [Gol89a, p192] </ref>. 12 Diploidy and Dominance In the higher lifeforms, chromosomes contain two sets of genes, rather than just one. <p> There are probably other mechanisms we can use to achieve similar results (for example, keep a catalogue of the best individuals, and try reintroducing them into the population if performance falls). Little work seems to have been done in this area|Goldberg <ref> [Gol89a, p148] </ref> provides a summary. 13 Knowledge-based Techniques While most research has gone into GAs using the traditional crossover and mutation operators, some have advocated designing new operators for each task, using domain knowledge [Dav91d]. This makes each GA more task specific (less robust), but may improve performance significantly. <p> It can also be used to perform heuristic initialisation of the population, so that search begins with some reasonably good points, rather than a random set [Gre87, SG90]. Goldberg <ref> [Gol89a, p201-6] </ref> describes techniques for adding knowledge-directed crossover and mutation. He also discusses the hybridisation of GAs with other search techniques (as does Davis [Dav91d]). 10 14 Redundant Value Mapping A problem occurs when a gene may only have a finite number of discrete valid values.
Reference: [Gol89b] <author> D.E. Goldberg. </author> <title> Zen and the art of genetic algorithms. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 80-85. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference: [Gol90] <author> D.E. Goldberg. </author> <title> The theory of virtual alphabets. </title> <editor> In H.-P. Schwefel and R. Manner, editors, </editor> <booktitle> Parallel Problem Solving from Nature, </booktitle> <pages> pages 13-22. </pages> <publisher> Springer-Verlag, </publisher> <year> 1990. </year>
Reference-contexts: But Antonisse [Ant89], interprets schemata differently, and concludes that, on the contrary, high-cardinality alphabets contain more schemata than binary ones. (This has been the subject of more recent discussion [Ang92, Ant92].) Goldberg has now developed a theory which explains why high-cardinality representations can perform well <ref> [Gol90] </ref>. His theory of virtual alphabets says that each symbol converges within the first few generations, leaving only a small number of possible values. In this way, each symbol effectively has only a low cardinality.
Reference: [GR87] <author> D.E. Goldberg and J. Richardson. </author> <title> Genetic algorithms with sharing for multimodal function optimization. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 41-49. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: Of course, we would expect the population of a GA to converge on a peak of high fitness, but even where there are several peaks of equal fitness, the GA will still end up on a single one. This is due to genetic drift <ref> [GR87] </ref>. Several modifications to the traditional GA have been proposed to solve this problem, all with some basis in natural ecosystems [GR87]. The two basic techniques are to maintain diversity, or to share the payoff associated with a niche. Cavicchio [GR87] introduced a mechanism he called preselection, where offspring replace the <p> This is due to genetic drift <ref> [GR87] </ref>. Several modifications to the traditional GA have been proposed to solve this problem, all with some basis in natural ecosystems [GR87]. The two basic techniques are to maintain diversity, or to share the payoff associated with a niche. Cavicchio [GR87] introduced a mechanism he called preselection, where offspring replace the parent only if the offspring's fitness exceeds that of the inferior parent. <p> This is due to genetic drift <ref> [GR87] </ref>. Several modifications to the traditional GA have been proposed to solve this problem, all with some basis in natural ecosystems [GR87]. The two basic techniques are to maintain diversity, or to share the payoff associated with a niche. Cavicchio [GR87] introduced a mechanism he called preselection, where offspring replace the parent only if the offspring's fitness exceeds that of the inferior parent. There is fierce competition between parents and children, so the payoff is not so much shared as fought over, and the winner takes all. <p> The total reward available in any niche is fixed, and is distributed using a bucket-brigade mechanism. Booker's application is a classifier system, where it is easy to identify which niche an individual belongs to. In other applications, this is generally not a simple matter. Perry <ref> [GR87] </ref> solves the species membership problem using a similarity template called an external schema. However, this scheme requires advance knowledge of where the niches are, so is of limited use. Grosso [GR87] simulates partial geographical isolation in nature by using multiple subpopulations and intermediate migration rates. <p> In other applications, this is generally not a simple matter. Perry <ref> [GR87] </ref> solves the species membership problem using a similarity template called an external schema. However, this scheme requires advance knowledge of where the niches are, so is of limited use. Grosso [GR87] simulates partial geographical isolation in nature by using multiple subpopulations and intermediate migration rates. This shows advantages over isolated subpopulations (no migration|equivalent to simply iterating the GA), and completely mixed (panmictic) populations. <p> In nature, species only come into direct competition with each other if they are in the same niche. Since Davidor's GA eventually converges to a single species, there can only be one niche. Goldberg & Richardson <ref> [GR87] </ref> describe the advantages of sharing. Several individuals which occupy the same niche are made to share the fitness payoff among them. Once a niche has reached its "carrying capacity," it no longer appears rewarding in comparison with other, unfilled niches.
Reference: [Gre86] <author> J.J. Grefenstette. </author> <title> Optimization of control parameters for genetic algorithms. </title> <journal> IEEE Trans SMC, </journal> <volume> 16 </volume> <pages> 122-128, </pages> <year> 1986. </year>
Reference-contexts: In a static environment, if we really want to determine the best gene ordering (perhaps because we have a large number of problems, all with similar characteristics), we might try using a meta-GA, in the same way that Grefenstette <ref> [Gre86] </ref> used a meta-GA to determine a good set of GA parameters. A meta-GA has a population where each member is itself a GA. Each individual GA is configured to solve the same task, but using different parameters (in this case, different gene orderings).
Reference: [Gre87] <author> J.J. Grefenstette. </author> <title> Incorporating problem specific knowledge into genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <title> Genetic Algorithms and Simulated Annealing, </title> <booktitle> chapter 4, </booktitle> <pages> pages 42-60. </pages> <publisher> Pitman, </publisher> <year> 1987. </year>
Reference-contexts: Where a GA is being designed to tackle a real-world problem, and has to compete with other search and optimisation techniques, the incorporation of domain knowledge often makes sense. Suh & Van Gucht [SVG87] and Grefenstette <ref> [Gre87] </ref> argue that problem-specific knowledge can usefully be incorporated into the crossover operation. Domain knowledge may be used to prevent obviously unfit chromosomes, or those which would violate problem constraints, from being produced in the first place. <p> It can also be used to perform heuristic initialisation of the population, so that search begins with some reasonably good points, rather than a random set <ref> [Gre87, SG90] </ref>. Goldberg [Gol89a, p201-6] describes techniques for adding knowledge-directed crossover and mutation. He also discusses the hybridisation of GAs with other search techniques (as does Davis [Dav91d]). 10 14 Redundant Value Mapping A problem occurs when a gene may only have a finite number of discrete valid values.
Reference: [Gre91] <author> J.J. Grefenstette. </author> <title> Strategy acquisition with genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, chapter 14, </booktitle> <pages> pages 186-201. </pages> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: In GA-digest 5 volume 6 number 32 (September 1992), the editor, Alan C. Schultz, lists various research using non-binary representations. These include Grefenstette's work which uses a rule-based representation to learn reactive strategies (or behaviours) for autonomous agents <ref> [SG90, Gre91] </ref>. Koza is using a process known as genetic programming to learn Lisp programs [Koz92].
Reference: [Gre93] <author> John J. Grefenstette. </author> <title> Deception considered harmful. </title> <editor> In L. Darrell Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <volume> 2, </volume> <pages> pages 75-91. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Furthermore, a problem is referred to as fully deceptive if "all low-order schemata containing a suboptimal solution are better than other competing schemata" [DG91]. Deceptive problems are difficult to solve. However, Grefenstette <ref> [Gre93] </ref> cleverly demonstrates that this is not always the case. After the first generation, a GA does not get an unbiassed sample of points in the search space. Therefore it cannot estimate the global, unbiassed average fitness of a schema. It can only get a biassed estimate of schema fitness.
Reference: [GST90] <editor> N.P.O. Green, G.W. Stout, and D.J. Taylor. </editor> <booktitle> Biological Science 1 & 2. </booktitle> <publisher> Cambridge University Press, </publisher> <year> 1990. </year>
Reference-contexts: term epistasis in the sense of a "masking" or "switching" effect. "A gene is said to be epistatic when its presence suppresses the effect of a gene at another locus. 3 Epistatic genes are sometimes called inhibiting genes because of their effect on other genes which are described as hypostatic." <ref> [GST90] </ref>. Generally, though, there will be far more subtle and complex interactions among large overlapping groups of genes.
Reference: [Har88] <author> D.L. Hartl. </author> <title> A primer of population genetics. </title> <publisher> Sinauer Associates Inc., </publisher> <year> 1988. </year>
Reference-contexts: However, examples in nature show that asexual reproduction can evolve sophisticated creatures without crossover|for example bdelloid rotifers [MS89, p239]. Indeed, biologists see mutation as the main source of raw material for evolutionary change <ref> [Har88, p137] </ref>. Schaffer et al [SCLD89] did a large experiment to determine optimum parameters for GAs. They found that crossover had much less effect on performance than previously believed. They suggest that "nave evolution" (just selection and mutation) performs a hillclimb-like search which can be powerful without crossover.
Reference: [Hol75] <author> J.H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <year> 1975. </year>
Reference-contexts: Techniques for reordering the positions of genes in the chromosome during a run have been suggested. One such technique, inversion <ref> [Hol75] </ref>, works by reversing the order of genes between two randomly chosen positions within the chromosome. (When these techniques are used, genes must carry with them some kind of "label", so that they may be correctly identified irrespective of their position within the chromosome.) The purpose of reordering is to attempt
Reference: [Hol87] <author> J.H. Holland. </author> <title> Genetic algorithms and classifier systems: foundations and future directions. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 82-89. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: The idea that crossover should be more probable at some string positions than others has some basis in nature, and several such methods have been described <ref> [SM87, Hol87, Dav91a, Lev91, LR91] </ref>. The general principle is that the GA adaptively learns which sites should be favoured for crossover. This information is recorded in a punctuation string, which is itself part of the chromosome, and so is crossed over and passed on to descendants. <p> These effects limit the use of restricted mating. Restricted mating schemes of Booker [Boo85] and Deb & Goldberg [DG89] have been described above. These restrict mating on the basis of similarities between the genotypes or phenotypes. Other schemes which restrict mating using additional mating template codes (for example <ref> [Hol87, p88] </ref>) are summarised by Goldberg [Gol89a, p192]. 12 Diploidy and Dominance In the higher lifeforms, chromosomes contain two sets of genes, rather than just one.
Reference: [JM91] <author> C.Z. Janikow and Z. Michalewicz. </author> <title> An experimental comparison of binary and floating point representations in genetic algorithms. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 31-36. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: In this way, each symbol effectively has only a low cardinality. Empirical studies of high-cardinality alphabets have typically used chromosomes where each symbol represents an integer [Bra91], or a floating-point number <ref> [JM91, MJ91] </ref>. As Davis [Dav91d, p65] points out, problem parameters are often numeric, so representing them directly as numbers, rather than bit-strings, seems obvious, and may have advantages. One advantage is that we can more easily define meaningful, problem-specific "crossover" and "mutation" operators. <p> Geometric creep|multiply by a random amount close to one. For both creep operators, the randomly generated number may have a variety of distributions; uniform within a given range, exponential, Gaussian, binomial, etc. Janikow & Michalewicz <ref> [JM91] </ref> made a direct comparison between binary and floating-point representations, and found that the floating-point version gave faster, more consistent, and more accurate results. However, where problem parameters are not numeric, (for example in combinatorial optimisation problems), the advantages of high-cardinality alphabets may be harder to realise. <p> Schultz, lists various research using non-binary representations. These include Grefenstette's work which uses a rule-based representation to learn reactive strategies (or behaviours) for autonomous agents [SG90, Gre91]. Koza is using a process known as genetic programming to learn Lisp programs [Koz92]. Floating point representations have been widely explored <ref> [Whi89, JM91, MJ91, ES93] </ref>, and Michalewicz has looked at a matrix as the data structure [Mic92]. 9 Dynamic Operator Probabilities During the course of a run, the optimal value for each operator probability may vary.
Reference: [Koz92] <author> John R. Koza. </author> <title> Genetic Programming: On The Programming Of Computers By Means Of Natural Selection. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Schultz, lists various research using non-binary representations. These include Grefenstette's work which uses a rule-based representation to learn reactive strategies (or behaviours) for autonomous agents [SG90, Gre91]. Koza is using a process known as genetic programming to learn Lisp programs <ref> [Koz92] </ref>. Floating point representations have been widely explored [Whi89, JM91, MJ91, ES93], and Michalewicz has looked at a matrix as the data structure [Mic92]. 9 Dynamic Operator Probabilities During the course of a run, the optimal value for each operator probability may vary.
Reference: [Lev91] <author> J. Levenick. </author> <title> Inserting introns improves genetic algorithm success rate: taking a cue from biology. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 123-127. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The idea that crossover should be more probable at some string positions than others has some basis in nature, and several such methods have been described <ref> [SM87, Hol87, Dav91a, Lev91, LR91] </ref>. The general principle is that the GA adaptively learns which sites should be favoured for crossover. This information is recorded in a punctuation string, which is itself part of the chromosome, and so is crossed over and passed on to descendants.
Reference: [LR91] <author> S.J. Louis and G.J.E. Rawlins. </author> <title> Designer genetic algorithms: Genetic algorithms in structure design. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 53-60. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The idea that crossover should be more probable at some string positions than others has some basis in nature, and several such methods have been described <ref> [SM87, Hol87, Dav91a, Lev91, LR91] </ref>. The general principle is that the GA adaptively learns which sites should be favoured for crossover. This information is recorded in a punctuation string, which is itself part of the chromosome, and so is crossed over and passed on to descendants.
Reference: [Mic92] <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data Structures = Evolution Programs. </title> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: Koza is using a process known as genetic programming to learn Lisp programs [Koz92]. Floating point representations have been widely explored [Whi89, JM91, MJ91, ES93], and Michalewicz has looked at a matrix as the data structure <ref> [Mic92] </ref>. 9 Dynamic Operator Probabilities During the course of a run, the optimal value for each operator probability may vary. Davis [Dav85b] tried linear variations in crossover and mutation probability, with crossover decreasing during the run, and mutation increasing (see above). Syswerda [Sys91] also found this advantageous.
Reference: [MJ91] <author> Z. Michalewicz and C.Z. Janikow. </author> <title> Handling constraints in genetic algorithms. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 151-157. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: In this way, each symbol effectively has only a low cardinality. Empirical studies of high-cardinality alphabets have typically used chromosomes where each symbol represents an integer [Bra91], or a floating-point number <ref> [JM91, MJ91] </ref>. As Davis [Dav91d, p65] points out, problem parameters are often numeric, so representing them directly as numbers, rather than bit-strings, seems obvious, and may have advantages. One advantage is that we can more easily define meaningful, problem-specific "crossover" and "mutation" operators. <p> Schultz, lists various research using non-binary representations. These include Grefenstette's work which uses a rule-based representation to learn reactive strategies (or behaviours) for autonomous agents [SG90, Gre91]. Koza is using a process known as genetic programming to learn Lisp programs [Koz92]. Floating point representations have been widely explored <ref> [Whi89, JM91, MJ91, ES93] </ref>, and Michalewicz has looked at a matrix as the data structure [Mic92]. 9 Dynamic Operator Probabilities During the course of a run, the optimal value for each operator probability may vary. <p> However, a potential drawback of this technique which must be avoided is that it may reward operators which simply locate local optima, rather than helping to find the global optimum. Going in the opposite direction, several researchers vary the mutation probability by decreasing it exponentially during a run <ref> [Ack87, Bra91, Fog89, MJ91] </ref>. Unfortunately, no clear analysis or reasoning is given as to why this should lead to an improvement (although Fogarty [Fog89] provides experimental evidence).
Reference: [MS89] <author> J. Maynard Smith. </author> <title> Evolutionary Genetics. </title> <publisher> Oxford University Press, </publisher> <year> 1989. </year>
Reference-contexts: This is a far more difficult problem to solve. 3 Time spent trying to find better gene orderings may mean time taken away from finding good gene values. In nature, there are many mechanisms by which the arrangement of the chromosome (s) may evolve (known as karyotypic evolution) <ref> [MS89] </ref>; inversion is only one of them. In the short term, organisms will be favoured if they evolve to become well adapted to their environment. <p> run, and are only likely to be worthwhile if the results they provide can be reused many times. 4 Epistasis The term epistasis has been defined by geneticists as meaning that the influence of a gene on the fitness of an individual depends on what gene values are present elsewhere. <ref> [MS89] </ref> More specifically, geneticists use the term epistasis in the sense of a "masking" or "switching" effect. "A gene is said to be epistatic when its presence suppresses the effect of a gene at another locus. 3 Epistatic genes are sometimes called inhibiting genes because of their effect on other genes <p> It is generally held that crossover is the main force leading to a thorough search of the problem space. However, examples in nature show that asexual reproduction can evolve sophisticated creatures without crossover|for example bdelloid rotifers <ref> [MS89, p239] </ref>. Indeed, biologists see mutation as the main source of raw material for evolutionary change [Har88, p137]. Schaffer et al [SCLD89] did a large experiment to determine optimum parameters for GAs. They found that crossover had much less effect on performance than previously believed. <p> For example, a chromosome might contain several variants of a gene. Epistasis (in the sense of masking) could be used to ensure that only one of the variants were expressed in any particular individual. A situation like this occurs with haemoglobin production <ref> [MS89] </ref>. Different genes code for its production during different stages of development. During the foetal stage, one gene is switched on to produce haemoglobin, whilst later on a different gene is activated. There are a variety of biological metaphors we can use to inspire our development of GAs.
Reference: [Sch85] <author> J.D. Schaffer. </author> <title> Learning multiclass pattern discrimination. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the First International Conference on Genetic Algorithms, </booktitle> <pages> pages 74-79. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1985. </year>
Reference-contexts: Probabilistic remapping is a hybrid between these two techniques. Every gene value (not just the "excess" ones) is remapped to one of two valid values in a probabilistic way, such that each valid value is equally likely to be represented. Schaffer <ref> [Sch85] </ref> encountered the simplest version of this problem|three valid states represented by 2 bits. He used fixed remapping|allowing one state to have two binary representations. He also tried using ternary coding to avoid the problem, but performance was inferior. Belew [Bel89] also used fixed remapping to solve the three-state problem.
Reference: [SCLD89] <editor> J.D. Schaffer, R.A. Caruna, Eshelman L.J., and R. </editor> <title> Das. A study of control parameters affecting online performance of genetic algorithms for function optimization. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 51-60. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: However, examples in nature show that asexual reproduction can evolve sophisticated creatures without crossover|for example bdelloid rotifers [MS89, p239]. Indeed, biologists see mutation as the main source of raw material for evolutionary change [Har88, p137]. Schaffer et al <ref> [SCLD89] </ref> did a large experiment to determine optimum parameters for GAs. They found that crossover had much less effect on performance than previously believed. They suggest that "nave evolution" (just selection and mutation) performs a hillclimb-like search which can be powerful without crossover. <p> This is in agreement with Davis [Dav91d], who points out that mutation becomes more productive, and crossover less productive, as the population converges. Despite its generally low probability of use, mutation is a very important operator. Its optimum probability is much more critical than that for crossover <ref> [SCLD89] </ref>. Even if it is a "background operator," it should not be ignored. Spears [Spe93] closely compares crossover and mutation, and argues that there are some important characteristics of each operator that are not captured by the other.
Reference: [SD91] <author> W.M. Spears and K. DeJong. </author> <title> An analysis of multi-point crossover. </title> <editor> In G.J.E. Rawlins, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <pages> pages 301-315. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: No overall winner emerged, and in fact there was not more than about 20% difference in speed among the techniques (so perhaps we should not worry too much about which is the best method). They found that 8-point crossover was good on the problems they tried. Spears & DeJong <ref> [SD91] </ref> are very critical of multi-point and uniform crossover. They stick by the theoretical analyses which show 1- and 2-point crossover are optimal. They say that 2-point crossover will perform poorly when the population has largely converged, due to reduced crossover productivity.
Reference: [SE91] <editor> J.D. Schaffer and L.J. Eshelman. </editor> <title> On crossover as an evolutionarily viable strategy. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 61-68. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: They found that crossover had much less effect on performance than previously believed. They suggest that "nave evolution" (just selection and mutation) performs a hillclimb-like search which can be powerful without crossover. They investigate this hypothesis further <ref> [SE91] </ref>, and find that crossover gives much faster evolution than a mutation-only population. However, in the end, mutation generally finds better solutions than a crossover-only regime. This is in agreement with Davis [Dav91d], who points out that mutation becomes more productive, and crossover less productive, as the population converges.
Reference: [SG90] <author> A.C. Schultz and J.J. Grefenstette. </author> <title> Improving tactical plans with genetic algorithms. </title> <booktitle> In Proc. IEEE Conf. Tools for AI, </booktitle> <pages> pages 328-344. </pages> <publisher> IEEE Society Press, </publisher> <year> 1990. </year>
Reference-contexts: In GA-digest 5 volume 6 number 32 (September 1992), the editor, Alan C. Schultz, lists various research using non-binary representations. These include Grefenstette's work which uses a rule-based representation to learn reactive strategies (or behaviours) for autonomous agents <ref> [SG90, Gre91] </ref>. Koza is using a process known as genetic programming to learn Lisp programs [Koz92]. <p> It can also be used to perform heuristic initialisation of the population, so that search begins with some reasonably good points, rather than a random set <ref> [Gre87, SG90] </ref>. Goldberg [Gol89a, p201-6] describes techniques for adding knowledge-directed crossover and mutation. He also discusses the hybridisation of GAs with other search techniques (as does Davis [Dav91d]). 10 14 Redundant Value Mapping A problem occurs when a gene may only have a finite number of discrete valid values.
Reference: [SM87] <author> J.D. Schaffer and A. Morishma. </author> <title> An adaptive crossover distribution mechanism for genetic algorithms. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 36-40. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: The idea that crossover should be more probable at some string positions than others has some basis in nature, and several such methods have been described <ref> [SM87, Hol87, Dav91a, Lev91, LR91] </ref>. The general principle is that the GA adaptively learns which sites should be favoured for crossover. This information is recorded in a punctuation string, which is itself part of the chromosome, and so is crossed over and passed on to descendants.
Reference: [Spe93] <author> William M. Spears. </author> <title> Crossover or mutation? In L. </title> <editor> Darrell Whitley, editor, </editor> <booktitle> Foundations of Genetic Algorithms, </booktitle> <volume> 2, </volume> <pages> pages 221-237. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1993. </year>
Reference-contexts: Despite its generally low probability of use, mutation is a very important operator. Its optimum probability is much more critical than that for crossover [SCLD89]. Even if it is a "background operator," it should not be ignored. Spears <ref> [Spe93] </ref> closely compares crossover and mutation, and argues that there are some important characteristics of each operator that are not captured by the other. He further suggests that a suitably modified mutation operator can do everything that crossover can.
Reference: [Sta87] <author> I. Stadnyk. </author> <title> Schema recombination in a pattern recognition problem. </title> <editor> In J.J. Grefenstette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 27-35. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: In this, offspring are compared with a few (typically 2 or 3) randomly chosen individuals from the population. The offspring replaces the most similar one found, using Hamming distance as the similarity measure. This again aids diversity, and indirectly encourages speciation. Stadnyk <ref> [Sta87] </ref> found better results using a variation on this. The sampling of individuals was biassed according to inverse fitness, so that new offspring replace others which are in the same niche and have low fitness. Booker [Boo85] uses restricted mating to encourage speciation.
Reference: [SVG87] <author> J.Y. Suh and D. Van Gucht. </author> <title> Incorporating heuristic information into genetic search. </title> <editor> In J.J. Grefen-stette, editor, </editor> <booktitle> Proceedings of the Second International Conference on Genetic Algorithms, </booktitle> <pages> pages 100-107. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1987. </year>
Reference-contexts: This makes each GA more task specific (less robust), but may improve performance significantly. Where a GA is being designed to tackle a real-world problem, and has to compete with other search and optimisation techniques, the incorporation of domain knowledge often makes sense. Suh & Van Gucht <ref> [SVG87] </ref> and Grefenstette [Gre87] argue that problem-specific knowledge can usefully be incorporated into the crossover operation. Domain knowledge may be used to prevent obviously unfit chromosomes, or those which would violate problem constraints, from being produced in the first place. <p> Domain knowledge can also be used to design local improvement operators, which allow more efficient exploration of the search space around good points <ref> [SVG87] </ref>. It can also be used to perform heuristic initialisation of the population, so that search begins with some reasonably good points, rather than a random set [Gre87, SG90]. Goldberg [Gol89a, p201-6] describes techniques for adding knowledge-directed crossover and mutation.
Reference: [Sys89] <author> G. Syswerda. </author> <title> Uniform crossover in genetic algorithms. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 2-9. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year>
Reference-contexts: Offspring therefore contain a mixture of genes from each parent. The number of effective crossing points is not fixed, but will average L=2 (where L is the chromosome length). 2.3 Which technique is best? Arguments over which is the best crossover method to use still rage on. Syswerda <ref> [Sys89] </ref> argues in favour of uniform crossover. Under uniform crossover, schemata of a particular order 1 are equally likely to be disrupted, irrespective of their defining length. 2 With 2-point crossover, it is the defining length of the schemata which determines its likelihood of disruption, not its order. <p> Nor does it help if the relationships among the genes do not allow a simple linear ordering. If uniform crossover is used, gene order is irrelevant, so reordering is unnecessary. So, Syswerda <ref> [Sys89] </ref> argues, why bother with inversion? Reordering also greatly expands the search space. Not only is the GA trying to find good sets of gene values, it is simultaneously trying to discover good gene orderings too.
Reference: [Sys91] <author> G. Syswerda. </author> <title> Schedule optimization using genetic algorithms. </title> <editor> In L. Davis, editor, </editor> <booktitle> Handbook of Genetic Algorithms, chapter 21, </booktitle> <pages> pages 332-349. </pages> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: Offspring have genes which inherit ordering information from each parent. This avoids the generation of offspring which violate problem constraints. Syswerda <ref> [Sys91] </ref> and Davis [Dav91d, p72] describe other order-based operators. <p> Davis [Dav85b] tried linear variations in crossover and mutation probability, with crossover decreasing during the run, and mutation increasing (see above). Syswerda <ref> [Sys91] </ref> also found this advantageous. However, it imposes a fixed schedule. Booker [Boo87] utilises a dynamically variable crossover rate, depending on the spread of fitnesses. When the population converges, the crossover rate is reduced to give more opportunity for mutation to find new variations.
Reference: [VL91] <author> M. Vose and G. Liepins. </author> <title> Schema disruption. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the Fourth International Conference on Genetic Algorithms, </booktitle> <pages> pages 237-242. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: If treated as a coding problem, the solution is to find a different coding (representation) and decoding method which does not exhibit epistasis. This will then allow a conventional GA to be used. If this cannot be done, the second approach may have to be used. Vose & Liepins <ref> [VL91] </ref> show that in principle any problem can be coded in such a way as to make it as simple as the "counting ones task". Similarly, any coding can be made simple for a GA by using appropriately designed crossover and mutation operators.
Reference: [Whi89] <author> D. Whitley. </author> <title> The GENITOR algorithm and selection pressure: why rank-based allocation of reproductive trials is best. </title> <editor> In J.D. Schaffer, editor, </editor> <booktitle> Proceedings of the Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 116-121. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1989. </year> <month> 15 </month>
Reference-contexts: Schultz, lists various research using non-binary representations. These include Grefenstette's work which uses a rule-based representation to learn reactive strategies (or behaviours) for autonomous agents [SG90, Gre91]. Koza is using a process known as genetic programming to learn Lisp programs [Koz92]. Floating point representations have been widely explored <ref> [Whi89, JM91, MJ91, ES93] </ref>, and Michalewicz has looked at a matrix as the data structure [Mic92]. 9 Dynamic Operator Probabilities During the course of a run, the optimal value for each operator probability may vary.
References-found: 70

