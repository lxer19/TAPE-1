URL: http://www.cs.umn.edu/Users/dept/users/kencham/synchronization2.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kencham/
Root-URL: http://www.cs.umn.edu
Title: Specification and Use of of Approximate Synchronization in Multimedia Presentations  Keywords: multimedia, approximate synchronization, continuous media.  
Author: Duminda Wijesekera, Deepak Kenchammana-Hosekote and Jaideep Srivastava 
Date: January 15, 1994  
Abstract: Emergence of multimedia computing have brought forth new horizons and challenges to traditional computing. New notions of synchronization requirements is one such novelty of multimedia computations, which forms the subject matter of this publication. Up until the emergence of multimedia, all synchronizations were strict in the sense that simultaneaty, parallelism or sequencing of two streams of activity was describable by specifying time points in their execution histories. In the domain of multimedia, due to the grossness of human perception such stringent requirements can be relaxed. We investigate consequences of this new notion of synchrony and develop a hierarchical specification model for multimedia compositions. Relaxing synchronization points to time intervals make other known synchronization models a special cases ours. Algorithms to compile such multimedia specifications in to service requirements have been developed. The end result of this translation is an assignment of a range of time stamps to every sample in parallel media streams. Our time stamping algorithm extends existing algorithms in this area. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Allen, J.F., </author> <title> Maintaining Knowledge about Temporal Intervals. </title> <journal> Communications of the ACM, </journal> <month> November, </month> <year> 1983 </year>
Reference-contexts: Any two intervals can be combined in 11 different ways to produce more complex intervals by using constructs such as during, overlaps, starts, finishes, meets, inverses of these and equals <ref> [1] </ref>. These eleven relationships have been used to demonstrate the completeness of synchronization specifications of several existing working prototypes. (eg. Cmifed [3], SRT [7], OCPN [5]). In the OCPN model interval synchrony is specified by means of Petri nets.
Reference: [2] <author> Bach, M.J., </author> <title> The Design of the Unix Operating System. </title> <publisher> Prentice Hall, </publisher> <year> 1989 </year>
Reference-contexts: Though smaller intervals provide better synchronization, the length of such an interval cannot be made arbitrarily small due to limitations on the time it takes to correct. For example, the context switch time between two threads is approximately 0.1 milli seconds <ref> [2] </ref>. Therefore it is impossible to take corrective action at finer intervals. Notice that there are about 8.8 sound samples in the duration of a context switch.
Reference: [3] <author> Hardman, L., Bulterman, D.C.A., and van Rossum, G. </author> <title> The Amsterdam Hypermedia Model: Extending Hypertext to Support Real Multimedia. </title> <type> Technical Report 9306, </type> <institution> CWI, University Of Amsterdam </institution>
Reference-contexts: These eleven relationships have been used to demonstrate the completeness of synchronization specifications of several existing working prototypes. (eg. Cmifed <ref> [3] </ref>, SRT [7], OCPN [5]). In the OCPN model interval synchrony is specified by means of Petri nets. In Cmifed and SRT they are specified by means of a tree of which the internal nodes are parallel or sequential operators, and the leaves are atomic media instances. <p> This is further enhanced by providing a directed graph (as in hypertext) to navigate through a multimedia demonstration. There is a procedural language and declarative constants to coordinate between directed graphs and spatial frameworks. A substantial amount of applications have been built on top of Muse. CMIFed's <ref> [3] </ref> synchronization specification method uses a rooted tree in which leaves are atomic media instances with specified runtimes. Internal nodes are parallel or sequential operators. If two sub presentations are connected by a parallel operator then the composition shows its components simultaneously. <p> Our logical channels are abstractions of windows and not of screens. To uniquely specify a multimedia demonstration, the mapping f Stream : 7! Channel g must be specified <ref> [3] </ref>. Our approach to channel assignment is a two step process. In the first step, we rewrite the master normal form of a SRT in Media Type Normal Form.
Reference: [4] <author> Hodges, M.E., Sasnett, R., and Ackerman, </author> <title> M.S., A Construction Set for Multimedia Application. </title> <booktitle> IEEE Computer, </booktitle> <month> October, </month> <year> 1991. </year>
Reference-contexts: A strand is a sequence of continuously recorded video streams and/or audio samples. Their implementation uses a two layered software architecture: one to service system independent rope server and another to do device dependent storage management, which happens at the request of the rope server. Athena Muse system <ref> [4] </ref> uses a time line representation (which they call multidimentional spatial framework) to specify timing relations. This is further enhanced by providing a directed graph (as in hypertext) to navigate through a multimedia demonstration. There is a procedural language and declarative constants to coordinate between directed graphs and spatial frameworks.
Reference: [5] <author> Little, T.D.C., and Gafoor, A., </author> <title> Synchronization and Storage Model for Multimedia Objects, </title> <journal> Selected Areas in Communications, </journal> <volume> Vol 8, </volume> <year> 1990. </year>
Reference-contexts: An important aim of our work is to develop a model in which approximate synchrony can be specified so that it can be gainfully utilized at the resource scheduling level. All methods known to us of 1 specifying synchrony in multimedia compositions deal only with specifying exact synchrony <ref> [5] </ref>, [6], [10], [7], [11],[12]. 1.1 Previous Work Several mechanisms have been proposed to specify synchrony in multimedia compositions [5], [6], [10], [7], [11],[12]. They can be categorized as time point based, interval based, event based, or implicit specification methods. <p> All methods known to us of 1 specifying synchrony in multimedia compositions deal only with specifying exact synchrony <ref> [5] </ref>, [6], [10], [7], [11],[12]. 1.1 Previous Work Several mechanisms have been proposed to specify synchrony in multimedia compositions [5], [6], [10], [7], [11],[12]. They can be categorized as time point based, interval based, event based, or implicit specification methods. In time point based synchronization, there is a time line with respect to which one can specify beginning and ending times of each component of a presentation. <p> These eleven relationships have been used to demonstrate the completeness of synchronization specifications of several existing working prototypes. (eg. Cmifed [3], SRT [7], OCPN <ref> [5] </ref>). In the OCPN model interval synchrony is specified by means of Petri nets. In Cmifed and SRT they are specified by means of a tree of which the internal nodes are parallel or sequential operators, and the leaves are atomic media instances. <p> Traditional programming concepts such as CSP, semaphores, blocking and non blocking calls are used in this arena. Implicit synchrony is achieved by recod-ing and playing all synchronized media samples simultaneously side by side such as happens in traditional VCR players [12]. OCPN <ref> [5] </ref> was the first model to use graph based specifications. The specification is a Petri net in which places represent mutimedia objects for play out and arcs represent synchronization points. While capturing all temporal relationships among intervals, this model also facilitates the representation of forward and backward play out.
Reference: [6] <author> Little, T.D.C., Ghafoor, A., Chen, C.Y.R., Chang, C.S., and Berra B.P., </author> <title> Multimedia Synchronization, </title> <journal> Data Engineering Bulletin, </journal> <year> 1991 </year>
Reference-contexts: An important aim of our work is to develop a model in which approximate synchrony can be specified so that it can be gainfully utilized at the resource scheduling level. All methods known to us of 1 specifying synchrony in multimedia compositions deal only with specifying exact synchrony [5], <ref> [6] </ref>, [10], [7], [11],[12]. 1.1 Previous Work Several mechanisms have been proposed to specify synchrony in multimedia compositions [5], [6], [10], [7], [11],[12]. They can be categorized as time point based, interval based, event based, or implicit specification methods. <p> All methods known to us of 1 specifying synchrony in multimedia compositions deal only with specifying exact synchrony [5], <ref> [6] </ref>, [10], [7], [11],[12]. 1.1 Previous Work Several mechanisms have been proposed to specify synchrony in multimedia compositions [5], [6], [10], [7], [11],[12]. They can be categorized as time point based, interval based, event based, or implicit specification methods. In time point based synchronization, there is a time line with respect to which one can specify beginning and ending times of each component of a presentation.
Reference: [7] <author> Kim, W., Kenchammana-Hosekote, D., Lim, Ee-Peng., Srivastava, J., </author> <title> Synchronization Relation Tree : A Model for Temporal Synchronization in Multimedia Presentations Technical Report TR92-42, </title> <institution> Dept of Computer Science, Univ. of Minnesota </institution>
Reference-contexts: All methods known to us of 1 specifying synchrony in multimedia compositions deal only with specifying exact synchrony [5], [6], [10], <ref> [7] </ref>, [11],[12]. 1.1 Previous Work Several mechanisms have been proposed to specify synchrony in multimedia compositions [5], [6], [10], [7], [11],[12]. They can be categorized as time point based, interval based, event based, or implicit specification methods. <p> All methods known to us of 1 specifying synchrony in multimedia compositions deal only with specifying exact synchrony [5], [6], [10], <ref> [7] </ref>, [11],[12]. 1.1 Previous Work Several mechanisms have been proposed to specify synchrony in multimedia compositions [5], [6], [10], [7], [11],[12]. They can be categorized as time point based, interval based, event based, or implicit specification methods. In time point based synchronization, there is a time line with respect to which one can specify beginning and ending times of each component of a presentation. <p> These eleven relationships have been used to demonstrate the completeness of synchronization specifications of several existing working prototypes. (eg. Cmifed [3], SRT <ref> [7] </ref>, OCPN [5]). In the OCPN model interval synchrony is specified by means of Petri nets. In Cmifed and SRT they are specified by means of a tree of which the internal nodes are parallel or sequential operators, and the leaves are atomic media instances. <p> As with all constructs, SEQ and PAR have parameters and must obey certain rules. Next two sections describe these in detail. Thereafter we describe properties of trees that are produced by applying SEQ and PAR recursively on atomic intervals of media. We call such trees Synchronization Relation Trees (SRT <ref> [7] </ref>). 3.4 Sequential Composition The end result of executing a sequential construct is that media components are shown one after the other. Therefore the parameters of a sequential play out should be the order in which they play out.
Reference: [8] <author> Rangan, V. P., and Vin, H. V., </author> <title> Designing File Systems for Digital Audio and Video, </title> <booktitle> Proceedings of the 13 th Symposium on Operating System Principles., </booktitle> <month> October </month> <year> 1991 </year>
Reference: [9] <author> Rangan, V. P., and Vin, H. V., </author> <title> Designing a Multiuser HDTV Storage Server IEEE Selected Areas of in Communications, </title> <booktitle> Vol 11, </booktitle> <address> No1, </address> <month> Jan, </month> <year> 1993. </year>
Reference-contexts: When non zero asynchrony is specified for PAR nodes, a particular media granule may belong to different slice vectors with different time stamps. Time stamp generation in a similar context is discussed by Rangan <ref> [9] </ref> et.al. However they consider a set of media streams across which there is a single parameter of asynchrony that specifies the maximum tolerance between any pair of streams. Due to the tree structured hierarchical specification of SRT, we must satisfy a number of asynchronies across different streams.
Reference: [10] <author> Rangan, V. P., and et al. </author> <title> A Test bed for Digital Audio and video Usenix Proceedings, </title> <year> 1991 </year>
Reference-contexts: All methods known to us of 1 specifying synchrony in multimedia compositions deal only with specifying exact synchrony [5], [6], <ref> [10] </ref>, [7], [11],[12]. 1.1 Previous Work Several mechanisms have been proposed to specify synchrony in multimedia compositions [5], [6], [10], [7], [11],[12]. They can be categorized as time point based, interval based, event based, or implicit specification methods. <p> All methods known to us of 1 specifying synchrony in multimedia compositions deal only with specifying exact synchrony [5], [6], <ref> [10] </ref>, [7], [11],[12]. 1.1 Previous Work Several mechanisms have been proposed to specify synchrony in multimedia compositions [5], [6], [10], [7], [11],[12]. They can be categorized as time point based, interval based, event based, or implicit specification methods. In time point based synchronization, there is a time line with respect to which one can specify beginning and ending times of each component of a presentation. <p> This approach, while producing a scripted presentation using extensions of traditional programming methodologies, is capable of covering any jitter due to IO delays by using filler data that is specified in the restricted blocking. Work by Rangan et. al. <ref> [10] </ref> uses mutimedia ropes and strands as an abstraction for recording, storage and synchronization of audio and video streams. A strand is a sequence of continuously recorded video streams and/or audio samples.
Reference: [11] <author> Steinmetz, R., </author> <title> Synchronization Properties in Multimedia Systems. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> Vol 8, </volume> <month> April </month> <year> 1990 </year>
Reference-contexts: The specification is a Petri net in which places represent mutimedia objects for play out and arcs represent synchronization points. While capturing all temporal relationships among intervals, this model also facilitates the representation of forward and backward play out. Steinmetz <ref> [11] </ref> proposed extending a CSP based schema for synchronization including restricted blocking to cover the real time aspects of multimedia. <p> Figure 12 shows the composed presentation with calculated deviation sets for atomic intervals. Next two subsections illustrate the calculated show times for the granules with ideal time stamp 14, some possible wavefronts and one impossible wavefront. 20 Channel Show Time CLOCK (S) 14 A1 (master) 14 A2 <ref> [11, 17] </ref> I2 [11, 17] Table 3: Show Times for the fourteenth granules from different streams of the example SRT 6.3.1 Show Times Table ( 3) gives possible show times for granules with ideal time slice 14 in the different channels. These have been calculated using Algorithm ( 3). <p> Next two subsections illustrate the calculated show times for the granules with ideal time stamp 14, some possible wavefronts and one impossible wavefront. 20 Channel Show Time CLOCK (S) 14 A1 (master) 14 A2 <ref> [11, 17] </ref> I2 [11, 17] Table 3: Show Times for the fourteenth granules from different streams of the example SRT 6.3.1 Show Times Table ( 3) gives possible show times for granules with ideal time slice 14 in the different channels. These have been calculated using Algorithm ( 3).
Reference: [12] <author> Terry, D. and Swinehart, </author> <title> D.C. Managing Stored Voice in the Etherphone System. </title> <booktitle> ACM Transctions on Computer Systems, </booktitle> <address> Febraury, </address> <year> 1988 </year>
Reference-contexts: Traditional programming concepts such as CSP, semaphores, blocking and non blocking calls are used in this arena. Implicit synchrony is achieved by recod-ing and playing all synchronized media samples simultaneously side by side such as happens in traditional VCR players <ref> [12] </ref>. OCPN [5] was the first model to use graph based specifications. The specification is a Petri net in which places represent mutimedia objects for play out and arcs represent synchronization points.
Reference: [13] <author> Vin H.M. et.al., </author> <title> Multimedia Coferencing in the Etherphone Environment. </title> <booktitle> IEEE Computer, </booktitle> <month> October, </month> <year> 1991 </year>
References-found: 13

