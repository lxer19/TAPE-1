URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1089/CS-TR-92-1089.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-92-1089/
Root-URL: http://www.cs.wisc.edu
Title: Client-Server Caching Revisited  
Author: Michael J. Franklin Michael J. Carey 
Note: This work was partially supported by the Defense Advanced Research Projects Agency under contract DAAB07-92-C-Q508, by the Na tional Science Foundation under grant IRI-8657323, and by a research grant from IBM Corporation.  
Address: Wisconsin Madison  
Affiliation: Computer Sciences Department University of  
Abstract: Computer Sciences Technical Report #1089 May 1992 
Abstract-found: 1
Intro-found: 1
Reference: [Bell90] <author> Bellew, M., Hsu, M., and Tam, V.-O., </author> <title> "Update Propagation in Distributed Memory Hierarchy," </title> <booktitle> Proc. 6th Int'l. Conference on Data Engineering, </booktitle> <address> Los Angeles, CA, </address> <month> Feb. </month> <year> 1990. </year>
Reference-contexts: A study that is closely related to client-server caching is the work at Harvard on using Distributed Shared Virtual Memory (DSM) <ref> [Bell90] </ref> to support database systems. DSM is a technique that implements the abstraction of a system-wide single-level store in a distributed system [Li89]. Three algorithms for maintaining cache consistency were studied in [Bell90], one of which was a 2PL variant that used callbacks. <p> is closely related to client-server caching is the work at Harvard on using Distributed Shared Virtual Memory (DSM) <ref> [Bell90] </ref> to support database systems. DSM is a technique that implements the abstraction of a system-wide single-level store in a distributed system [Li89]. Three algorithms for maintaining cache consistency were studied in [Bell90], one of which was a 2PL variant that used callbacks. In a DSM system, there is no central server to manage copy information, so each page is statically assigned a "primary" site whose job it is to track the most recent "owner" of the page.
Reference: [Care91a] <author> Carey, M., Franklin, M., Livny, M., and Shekita, E., </author> <title> "Data Caching Tradeoffs in Client-Server DBMS Architectures", </title> <booktitle> Proc. ACM SIGMOD Int'l Conf. on Management of Data, </booktitle> <address> Denver, CO, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: For the remainder of the paper, we use the term "caching" to refer to inter-transaction caching. Despite the additional complexity, caching of data and locks has been shown to have the potential to provide substantial performance benefits <ref> [Wilk90, Care91a, Wang91] </ref>. <p> The Previous Study In an earlier paper we investigated the performance implications of caching data pages and/or locks at the client workstations of a page server database system <ref> [Care91a] </ref>. In that paper, five locking-based algorithms were compared: an algorithm that performed no caching, an algorithm that cached data (but not locks) at clients, and three variants of an Optimistic Two-Phase Locking (O2PL) algorithm that allowed caching of data pages and an optimistic form of lock caching. <p> This form of lock caching is optimistic in the sense that a local lock at one site does not guarantee the absence of conflicting local locks at other sites. The three O2PL-based cache consistency algorithms examined in <ref> [Care91a] </ref> differed in the actions that they performed at the remote sites once locks were obtained. One variant, called O2PL-Invalidate (O2PL-I), always removed the copies from the remote site. The second variant, O2PL-Propagate (O2PL-P), always sent new copies of the updated pages to the remote sites, thereby preserving replication. <p> Extensions to the Previous Study In this paper we extend the work of <ref> [Care91a] </ref> in three ways: 1. A Better Adaptive Heuristic: The first extension relates to the heuristics used to choose between invalidation and propagation in the O2PL-Dynamic algorithm. As stated above, the heuristic used in [Care91a] usually approached the performance level of the better of the two static O2PL algorithms for a <p> Extensions to the Previous Study In this paper we extend the work of <ref> [Care91a] </ref> in three ways: 1. A Better Adaptive Heuristic: The first extension relates to the heuristics used to choose between invalidation and propagation in the O2PL-Dynamic algorithm. As stated above, the heuristic used in [Care91a] usually approached the performance level of the better of the two static O2PL algorithms for a given workload, but it never exceeded or matched that level. Thus, the first issue addressed here is to find a better heuristic for the adaptive algorithm. 2. <p> The callback locking algorithms covered in this study both use invalidation to maintain consistency. 3. A CLIENT-SERVER CACHING MODEL This section presents an overview of the simulation model and workloads used in this study. A more detailed description of both can be found in <ref> [Care91a] </ref>. 3.1. The System Model event simulation language [Livn88]. It consists of components that model diskless client workstations and a server machine (with disks) that are connected over a simple network. <p> Results are presented for two different network bandwidths called "slow" (8 Mbits/sec) and "fast" (80 Mbits/sec); these correspond to slightly discounted bandwidths of Ethernet and FDDI technology, respectively. 4.1. A New Adaptive Heuristic As described earlier, the heuristic for the dynamic O2PL algorithm used in <ref> [Care91a] </ref> generally performed well, but it was never able to match the performance of the better of the other two O2PL algorithms for a given workload (except for with the PRIVATE workload, where all O2PL algorithms performed identically). <p> In all of the experiments described here, the O2PL-ND algorithm was run with a window size of 20 pages. An early concern with the new heuristic was whether it would be too sensitive to the window size. A series of studies using the parameters from <ref> [Care91a] </ref> found that in most cases, the algorithm was insensitive to the window size within a range of 10 to 100 pages (0.8% to 8% of the database size) [Fran92a]. <p> The lower performance of O2PL-P and O2PL-D, as compared to O2PL-I and O2PL-ND, is due to both messages and disk I/O. The additional messages are due to the propagations just described. As was seen in <ref> [Care91a] </ref>, the additional disk I/O is caused by slightly lower server and client buffer hit rates. These lower hit rates are the result of the fact that, with propagation of updates, pages are removed from - 13 - the client buffers only when they age out of the buffer pool. <p> This case shows a clear example of the effect of the new system parameter settings used in this study. In <ref> [Care91a] </ref>, which used slower CPUs and a faster network, the O2PL-D algorithm achieved performance much closer to that of O2PL-I for this case. The parameter settings used in [Care91a] were based on the intuition that the network itself would not ever be a bottleneck. <p> This case shows a clear example of the effect of the new system parameter settings used in this study. In <ref> [Care91a] </ref>, which used slower CPUs and a faster network, the O2PL-D algorithm achieved performance much closer to that of O2PL-I for this case. The parameter settings used in [Care91a] were based on the intuition that the network itself would not ever be a bottleneck. However, the continuing disparity in the performance increases of CPUs and networks has increased the likelihood of a network bottleneck arising. <p> The effect of these technology trends is an increase in the penalty paid for useless propagations and as a result, the relative performance of the O2PL-D algorithm suffers compared to what was observed in <ref> [Care91a] </ref>. These trends also exacerbate the performance problems incurred by the O2PL-P algorithm due to excessive propagation. In this case, the O2PL-P and O2PL-D algorithms become network-bound, while the O2PL-I and O2PL-ND algorithms approach a disk bottleneck at 25 clients. <p> Therefore, propagation of updates from other clients will typically not be helpful. - 15 - 4.1.4. Experiment 3: The FEED Workload In contrast to the HOTCOLD workload, where propagation is generally a bad idea, the FEED workload was shown in <ref> [Care91a] </ref> to benefit from propagation. This result also holds in general in this study, however, an exception arises in the case with small client buffer sizes and the slow network. The throughput results for this case are shown in Figure 8. <p> In this case, the results are similar to what was seen in <ref> [Care91a] </ref> invalidation has a slight advantage in this case. As a result, the O2PL-ND algorithm is able to fairly closely match the performance of the O2PL-I algorithm. 4.1.6. <p> The effect of the combination of the faster CPUs along with the slow network setting used in this study caused the advantages of O2PL-ND over O2PL-D to be greater than those seen when the parameters of <ref> [Care91a] </ref> were used. Thus, in situations where the network has a significant impact on performance, the O2PL-ND algorithm is a much better choice than O2PL-D. 4.2. <p> RELATED WORK In this section we briefly discuss work related to the specific issues that were addressed in this study. Work related to client-server caching in general is covered in <ref> [Care91a] </ref>. 5.1. Callback Locking As mentioned earlier, a callback locking algorithm is used to provide cache consistency in the Object-Store OODBMS and is described briefly in [Lamb91]. A callback locking algorithm for client-server database systems was studied in [Wang91]. <p> A performance study in [LaRo91] demonstrated that it was possible to find a set of default parameter settings that provided good performance over a range of NUMA work-loads. 6. CONCLUSIONS In this paper, we have presented several extensions to the earlier client-server caching study of <ref> [Care91a] </ref>. These are: a better heuristic for the dynamic O2PL algorithm, an investigation of callback locking algorithms, a re-examination of system resource parameters, and a workload with high data contention. <p> The advantages of the new heuristic were more significant than were seen when the parameters of <ref> [Care91a] </ref> were used, as the combination of faster CPUs and a slower network increased the negative effects of bad propagations. Two variants of callback locking were studied.
Reference: [Care91b] <author> Carey, M. and Livny, M., </author> <title> "Conflict Detection Tradeoffs for Replicated Data", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> Vol. 16, No.4, </volume> <month> December, </month> <year> 1991. </year>
Reference-contexts: Optimistic Two-Phase locking (O2PL) The O2PL schemes allow inter-transaction caching of data pages and and an optimistic form of lock caching. They are based on a read-one, write-all concurrency control protocol that was developed for replicated data in distributed databases and was studied in <ref> [Care91b] </ref>. The O2PL algorithms are "optimistic" in the sense that they defer the detection of conflicts among locks cached at multiple sites until transaction commit time. <p> The use of update-copy locks allows for quicker detection of certain deadlocks: When a conflict is detected between two update-copy locks or between an update-copy lock and a write lock, it is known that a deadlock has occurred or will shortly occur, and therefore, the deadlock can be resolved immediately <ref> [Care91b] </ref>. - 5 - 2.3. Callback Locking The third family of caching algorithms studied is callback locking. Callback locking allows caching of data pages and non-optimistic caching of locks.
Reference: [Cart91] <author> Carter, J., Bennett, J., and Zwaenepoel, W., </author> <title> "Implementation and Performance of Munin", </title> <booktitle> Proc. 13th ACM Symposium on Operating System Principles, </booktitle> <address> Pacific Grove, CA, </address> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: These issues are addressed in MUNIN <ref> [Cart91] </ref> by defining various types of sharing properties and allowing the programmer to annotate data declarations with a designation of the type of sharing used for each variable. These annotations serve as hints to MUNIN in deciding among propagation and invalidation, making replication decisions, etc.
Reference: [Dan92] <author> Dan, A., and Yu, P., </author> <title> "Performance Analysis of Coherency Control Policies through Lock Retention", to appear, </title> <booktitle> Proc. SIGMOD Int'l Conference on the Management of Data, </booktitle> <address> San Diego, CA, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: Given this facility, the callback-style algorithm typically had lower performance than one of the broadcast algorithms. More recently, a group at IBM Yorktown has investigated several related algorithms for the shared-disk environment <ref> [Dan92] </ref>. These algorithms included shared-disk equivalents of the C2PL, CB-Read and CB-Write algorithms. In that study, the performance differences seen among the algorithms were largely due to disk I/Os needed to force pages to stable storage for recovery purposes prior to transferring a page from one node to the next.
Reference: [Deux91] <editor> Deux, O., et al., </editor> <title> "The O2 System", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 34, No. 10, </volume> <month> Oct. </month> <year> 1991. </year>
Reference: [Exod91] <author> EXODUS Project Group, </author> <title> "EXODUS Storage Manager Architectural Overview", EXODUS Project Document, </title> <institution> University of Wisconsin - Madison, </institution> <month> Nov. </month> <year> 1991. </year>
Reference-contexts: Many recent systems have adopted the page server approach due its relative simplicity and potential performance advantages compared to an object server approach. These systems include: ObServer [Horn87], O2 [Deux90], Client-Server EXODUS <ref> [Exod91, Fran92c] </ref>, and ObjectStore [Lamb91].
Reference: [Fran92a] <author> Franklin, M., </author> <title> "Architectural Issues in Client-Server Database Systems", </title> <type> Ph.D. Dissertation Proposal, </type> <institution> University of Wisconsin-Madison, </institution> <month> January, </month> <year> 1992. </year>
Reference-contexts: A series of studies using the parameters from [Care91a] found that in most cases, the algorithm was insensitive to the window size within a range of 10 to 100 pages (0.8% to 8% of the database size) <ref> [Fran92a] </ref>. The only exception was the FEED workload when run with 5% client buffers, in which a slight sensitivity was noticeable for window sizes up to 50 pages. This case and the reasons for the insensitivity of the algorithm in the other cases are discussed in the following sections. 4.1.1. <p> These effects occur because the invalidation window is small relative to the database size. As the invalidate window size approaches the database size, the O2PL-ND algorithm becomes more like the original O2PL-D algorithm. In <ref> [Fran92a] </ref> it was seen that the number of propagations per committed transaction increases with the window size, but that it remains quite small in the range of window sizes tested (10 to 100).
Reference: [Fran92b] <author> Franklin, M., Carey, M., Livny, M., </author> <title> "Global Memory Management in Client-Server DBMS Architectures", </title> <booktitle> to appear Proc. 18th VLDB Conference, </booktitle> <address> San Diego, CA, </address> <month> August, </month> <year> 1992. </year>
Reference-contexts: Finally, we are currently investigating ways of more fully exploiting the memory and processing power of the workstations in a client-server database system. A first step in this direction is described in <ref> [Fran92b] </ref>.
Reference: [Fran92c] <author> Franklin, M., Zwilling, M., Tan, C., Carey, M., DeWitt, D., </author> <title> "Crash Recovery in Client-Server EXODUS", </title> <booktitle> to appear Proc. SIGMOD Int'l Conference on the Management of Data, </booktitle> <address> San Diego, CA, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: Many recent systems have adopted the page server approach due its relative simplicity and potential performance advantages compared to an object server approach. These systems include: ObServer [Horn87], O2 [Deux90], Client-Server EXODUS <ref> [Exod91, Fran92c] </ref>, and ObjectStore [Lamb91].
Reference: [Horn87] <author> M. Hornick and S. Zdonik, </author> <title> "A Shared, Segmented Memory System for an Object-Oriented Database," </title> <journal> ACM Transactions on Office Information Systems 5, </journal> <volume> 1, </volume> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: Many recent systems have adopted the page server approach due its relative simplicity and potential performance advantages compared to an object server approach. These systems include: ObServer <ref> [Horn87] </ref>, O2 [Deux90], Client-Server EXODUS [Exod91, Fran92c], and ObjectStore [Lamb91].
Reference: [Howa88] <author> Howard, J., et al, </author> <title> "Scale and Performance in a Distributed File System," </title> <journal> ACM Transactions on Computer Systems 6, </journal> <volume> 1, </volume> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: Thus, the first issue addressed here is to find a better heuristic for the adaptive algorithm. 2. Other Lock Caching Algorithms: The second extension is an analysis of an alternative approach to maintaining cache consistency known as as callback locking <ref> [Howa88, Lamb91, Wang91] </ref>. As with O2PL-based techniques, callback locking allows clients to cache both data pages and locks, but unlike O2PL, lock caching is not optimistic that is, sites are not allowed to simultaneously cache conflicting locks. <p> However, in CB-All this is done only to to simplify recovery, as no other sites can access a page while it is exclusively cached at another site. Callback algorithms were originally introduced to maintain cache consistency in distributed file systems such as the Andrew File System <ref> [Howa88] </ref> and the file system of the Sprite operating system [Nels88]. However, these systems provide a weaker form of consistency than that required by database systems. More recently, a callback locking algorithm that provides serializability has been employed in - 6 - the ObjectStore OODBMS. <p> As mentioned earlier, callback algorithms were initially developed for use in distributed file systems. However, these systems have different correctness criteria and workload characteristics than database systems. The Andrew File System <ref> [Howa88] </ref> uses a callback scheme to inform sites of pending modifications to files that they have cached. This scheme does not guarantee consistent updates, however. Files that must be kept consistent, such as directories, are handled by simply not allowing them to be updated at cached sites.
Reference: [Lamb91] <author> Lamb, C., Landis, G., Orenstein, J. Weinreb, D., </author> <title> "The ObjectStore Database System", </title> <journal> Communications of the ACM, </journal> <volume> Vol. 34, No. 10, </volume> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Many recent systems have adopted the page server approach due its relative simplicity and potential performance advantages compared to an object server approach. These systems include: ObServer [Horn87], O2 [Deux90], Client-Server EXODUS [Exod91, Fran92c], and ObjectStore <ref> [Lamb91] </ref>. <p> Thus, the first issue addressed here is to find a better heuristic for the adaptive algorithm. 2. Other Lock Caching Algorithms: The second extension is an analysis of an alternative approach to maintaining cache consistency known as as callback locking <ref> [Howa88, Lamb91, Wang91] </ref>. As with O2PL-based techniques, callback locking allows clients to cache both data pages and locks, but unlike O2PL, lock caching is not optimistic that is, sites are not allowed to simultaneously cache conflicting locks. <p> These algorithms are of interest because they provide an alternative (non-optimistic) implementation of lock caching and because at least one commercial OODBMS has adopted a callback algorithm <ref> [Lamb91] </ref>. 3. System Parameter and Workload Changes: This study uses updated system resource parameter values and a new workload. The system parameters have been updated to reflect the changes in hardware technology that have occurred in the two years since the earlier work was initiated. <p> Work related to client-server caching in general is covered in [Care91a]. 5.1. Callback Locking As mentioned earlier, a callback locking algorithm is used to provide cache consistency in the Object-Store OODBMS and is described briefly in <ref> [Lamb91] </ref>. A callback locking algorithm for client-server database systems was studied in [Wang91].
Reference: [LaRo91] <author> LaRowe, P., Ellis, C., Kaplan, </author> <title> L, "The Robustness of NUMA Memory Management", </title> <booktitle> Proc. 13th ACM Symposium on Operating System Principles, </booktitle> <address> Pacific Grove, CA, </address> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: These annotations serve as hints to MUNIN in deciding among propagation and invalidation, making replication decisions, etc. The DUnX system <ref> [LaRo91] </ref> uses a parameterized policy which chooses dynamically among page replacement options based on reference histories. The parameters allow a user to adjust the level of dynamism of the algorithms. A performance study in [LaRo91] demonstrated that it was possible to find a set of default parameter settings that provided good <p> The DUnX system <ref> [LaRo91] </ref> uses a parameterized policy which chooses dynamically among page replacement options based on reference histories. The parameters allow a user to adjust the level of dynamism of the algorithms. A performance study in [LaRo91] demonstrated that it was possible to find a set of default parameter settings that provided good performance over a range of NUMA work-loads. 6. CONCLUSIONS In this paper, we have presented several extensions to the earlier client-server caching study of [Care91a].
Reference: [Li89] <author> Li, K., Hudak, P., </author> <title> "Memory Coherence in Shared Virtual Memory Systems", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol., 7, No. 4, </volume> <month> Nov. </month> <year> 1989. </year>
Reference-contexts: A study that is closely related to client-server caching is the work at Harvard on using Distributed Shared Virtual Memory (DSM) [Bell90] to support database systems. DSM is a technique that implements the abstraction of a system-wide single-level store in a distributed system <ref> [Li89] </ref>. Three algorithms for maintaining cache consistency were studied in [Bell90], one of which was a 2PL variant that used callbacks.
Reference: [Livn88] <author> Livny, M., </author> <note> DeNet User's Guide, Version 1.0, Comp. </note> <institution> Sci. Dept., Univ. of Wisconsin, Madison, </institution> <year> 1988. </year>
Reference-contexts: A CLIENT-SERVER CACHING MODEL This section presents an overview of the simulation model and workloads used in this study. A more detailed description of both can be found in [Care91a]. 3.1. The System Model event simulation language <ref> [Livn88] </ref>. It consists of components that model diskless client workstations and a server machine (with disks) that are connected over a simple network.
Reference: [Nels88] <author> Nelson, M., Welch, B., and Ousterhout, J., </author> <title> "Caching in the Sprite Network File System," </title> <journal> ACM Transactions on Computer Systems 6, </journal> <volume> 1, </volume> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: Callback algorithms were originally introduced to maintain cache consistency in distributed file systems such as the Andrew File System [Howa88] and the file system of the Sprite operating system <ref> [Nels88] </ref>. However, these systems provide a weaker form of consistency than that required by database systems. More recently, a callback locking algorithm that provides serializability has been employed in - 6 - the ObjectStore OODBMS. <p> This scheme does not guarantee consistent updates, however. Files that must be kept consistent, such as directories, are handled by simply not allowing them to be updated at cached sites. The Sprite operating system <ref> [Nels88] </ref> provides consistent updates, but it does so by disallowing caching for files that are open for write access. This is done using a callback mechanism that informs sites that a file is no longer cachable. 5.2.
Reference: [Ston79] <author> Stonebraker, M., </author> <title> "Concurrency Control and Consistency of Multiple Copies of Data in Distributed INGRES," </title> <journal> IEEE Transactions on Software Engineering SE-5, </journal> <volume> 3, </volume> <month> May </month> <year> 1979. </year>
Reference-contexts: Since lock management is distributed in the O2PL algorithms, the clients are necessarily involved in deadlock detection. Locally, clients maintain a waits-for graph which is checked for cycles to detect deadlocks that are local to the client. Global deadlocks are detected using a centralized algorithm a la <ref> [Ston79] </ref>. The server periodically requests local waits-for graphs from the clients and combines them to build a global waits-for graph. As in the server-based case, deadlocks are resolved by aborting the youngest transaction.
Reference: [Wang91] <author> Wang, Y., Rowe, L., </author> <title> "Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture", </title> <booktitle> Proc. ACM SIGMOD Int'l Conference on Management of Data, </booktitle> <address> Denver, CO, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: For the remainder of the paper, we use the term "caching" to refer to inter-transaction caching. Despite the additional complexity, caching of data and locks has been shown to have the potential to provide substantial performance benefits <ref> [Wilk90, Care91a, Wang91] </ref>. <p> Thus, the first issue addressed here is to find a better heuristic for the adaptive algorithm. 2. Other Lock Caching Algorithms: The second extension is an analysis of an alternative approach to maintaining cache consistency known as as callback locking <ref> [Howa88, Lamb91, Wang91] </ref>. As with O2PL-based techniques, callback locking allows clients to cache both data pages and locks, but unlike O2PL, lock caching is not optimistic that is, sites are not allowed to simultaneously cache conflicting locks. <p> More recently, a callback locking algorithm that provides serializability has been employed in - 6 - the ObjectStore OODBMS. A callback locking algorithm which allows the caching of read locks but not write locks was studied in <ref> [Wang91] </ref>. An important area in which the callback algorithms of this study differ from the algorithm studied in [Wang91] is deadlock detection . In the latter algorithm, all cached locks are considered to be in-use for the purpose of computing the waits-for graph at the server. <p> A callback locking algorithm which allows the caching of read locks but not write locks was studied in <ref> [Wang91] </ref>. An important area in which the callback algorithms of this study differ from the algorithm studied in [Wang91] is deadlock detection . In the latter algorithm, all cached locks are considered to be in-use for the purpose of computing the waits-for graph at the server. This may result in an unnecessarily high abort rate due to phantom deadlocks, especially with large client caches. <p> This result supports the intuition behind the decision in <ref> [Wang91] </ref> to cache only read locks. buffer pools. As shown in Figure 15, all of the algorithms eventually become disk-bound in this case, so the messaging effects discussed in the previous case eventually have no impact on the throughput. As a result, the performance differences between the CB algorithms disappear. <p> Work related to client-server caching in general is covered in [Care91a]. 5.1. Callback Locking As mentioned earlier, a callback locking algorithm is used to provide cache consistency in the Object-Store OODBMS and is described briefly in [Lamb91]. A callback locking algorithm for client-server database systems was studied in <ref> [Wang91] </ref>. That study compared the callback algorithm with a caching 2PL algorithm (similar to C2PL) and two variants of a "no-wait" locking algorithm that allowed clients to access cached objects before they received a lock response from the server. <p> These results mostly agree with those presented in Section 4.2. However, <ref> [Wang91] </ref> did not investigate an algorithm that was comparable to O2PL-ND and did not study the implications of caching write locks. Also, as mentioned earlier, the [Wang91] callback algorithm did not use accurate information for deadlock detection, and would be susceptible to phantom deadlocks in situations with large client buffer pools. <p> These results mostly agree with those presented in Section 4.2. However, <ref> [Wang91] </ref> did not investigate an algorithm that was comparable to O2PL-ND and did not study the implications of caching write locks. Also, as mentioned earlier, the [Wang91] callback algorithm did not use accurate information for deadlock detection, and would be susceptible to phantom deadlocks in situations with large client buffer pools. The workload model used in [Wang91] provided an interesting notion of locality, one that was more dynamic than that of this study; however, it did not <p> Also, as mentioned earlier, the <ref> [Wang91] </ref> callback algorithm did not use accurate information for deadlock detection, and would be susceptible to phantom deadlocks in situations with large client buffer pools. The workload model used in [Wang91] provided an interesting notion of locality, one that was more dynamic than that of this study; however, it did not provide a way of controlling the nature of data sharing among clients.
Reference: [Wilk90] <author> Wilkinson, W., and Neimat, M.-A., </author> <title> "Maintaining Consistency of Client Cached Data," </title> <booktitle> Proc. 16th VLDB Conference, </booktitle> <address> Brisbane, Australia, </address> <month> Aug. </month> <year> 1990. </year> <month> - 29 </month> - 
Reference-contexts: For the remainder of the paper, we use the term "caching" to refer to inter-transaction caching. Despite the additional complexity, caching of data and locks has been shown to have the potential to provide substantial performance benefits <ref> [Wilk90, Care91a, Wang91] </ref>.
References-found: 20

