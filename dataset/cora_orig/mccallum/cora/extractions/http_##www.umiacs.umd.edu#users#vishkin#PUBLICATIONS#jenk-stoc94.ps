URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/jenk-stoc94.ps
Refering-URL: http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/papers.html
Root-URL: 
Title: Symmetry Breaking for Suffix Tree Construction (extended abstract)  
Author: Suleyman Cenk S ahinalp Uzi Vishkin 
Abstract: There are several serial algorithms for suffix tree construction which run in linear time, but the number of operations in the only parallel algorithm available, due to Apostolico, Iliopoulos, Landau, Schieber and Vishkin, is proportional to n log n. The algorithm is based on labeling substrings, similar to a classical serial algorithm, with the same operations bound, by Karp, Miller and Rosenberg. We show how to break symmetries that occur in the process of assigning labels using the Deterministic Coin Tossing (DCT) technique, and thereby reduce the number of labeled substrings to linear. We give several algorithms for suffix tree construction. One of them runs in O(log 2 n) parallel time and O(n) work for input strings whose characters are drawn from a constant size alphabet. 
Abstract-found: 1
Intro-found: 1
Reference: [AILSV88] <author> A. Apostolico, C. Iliopoulos, G. M. Landau, B. Schieber, and U. Vishkin, </author> <title> Parallel Construction of a Suffix Tree with Applications, </title> <journal> In Algorithmica, </journal> <volume> 3: </volume> <pages> 347-365, </pages> <year> 1988. </year>
Reference-contexts: An example of a suffix tree is given in Figure 1. Serial algorithms for suffix tree construction were given in [KMR72], [We73], and [Mc76]. The two latter algorithms achieve a linear running time for an alphabet whose size is constant. A parallel algorithm was given in <ref> [AILSV88] </ref>. A Symmetry Breaking Challenge: As in the algorithm of [KMR72] work complexity of the above mentioned parallel algorithm is O (n log n). The approach of [KMR72] and [AILSV88] does not lend itself to linear work for the following reason: As these algorithms progress, they label all n 1 substrings <p> A parallel algorithm was given in <ref> [AILSV88] </ref>. A Symmetry Breaking Challenge: As in the algorithm of [KMR72] work complexity of the above mentioned parallel algorithm is O (n log n). The approach of [KMR72] and [AILSV88] does not lend itself to linear work for the following reason: As these algorithms progress, they label all n 1 substrings of size 2, then all n 3-substrings of size 4, and in general all (n 2 i + 1)-substrings of size 2 i (1 i log n). <p> This is done using an mfim array L. For each such two-character substring ij, where 1 i; j m, the location of i is entered into entry L (i; j). This is similar to <ref> [AILSV88] </ref>. 3. Now, we attach labels to all block of size 3. For each three-character substring ijk, we obtain its label by reapplying the second substep to f k where f denotes the label of ij as computed in the second substep. The space complexity is O (m 2 ). <p> The space complexity is O (m 2 ). This can be reduced to O (m 1+* ), for any fixed * &gt; 0, as in <ref> [AILSV88] </ref>. Getting linear space using hashing (and thereby entering randomization), as suggested in [MV91], is also a possibility. An example for block partitioning and labeling is given in 2.3 Second Stage We define a core of iteration k recursively.
Reference: [BV88] <author> O. Berkman, and U. Vishkin, </author> <title> Recursive star-tree parallel data-structure, </title> <journal> In SIAM J. Computing, </journal> <volume> 22,2: </volume> <pages> 221-242, </pages> <year> 1993. </year>
Reference-contexts: To achieve this, we determine the size of each block. This can be obtained by first applying a nearest one procedure to determine the starting and ending locations of each block, which takes O (log m) time with linear work <ref> [BV88] </ref>. (Given an array of n bits, a nearest one procedure finds for each position in the array the nearest bits whose value is one to it the left and right of the position.) Then we label each block in O (1) time with O (m) work in three substeps. 1.
Reference: [BDHPRS89] <author> P. C. P. Bhatt, K. Diks, T. Hagerup, V. C. Prasad, T. Radzik, and S. Saxena, </author> <title> Improved Deterministic Parallel Integer Sorting, </title> <booktitle> In Information and Computation, </booktitle> <volume> 94: </volume> <pages> 29-47, </pages> <year> 1991. </year>
Reference-contexts: Complexity of Stage 3 The main problem of the third stage is the need for sorting to apply REFINE, CONTRACT and MERGE procedures. The range of elements to be sorted enables applying the integer sorting algorithm of <ref> [BDHPRS89] </ref>, so that this algorithm runs in logarithmic time; however its work complexity is O (m log log m) for a list of size m. 2.5 Complexity of the basic algorithm The basic algorithm runs in O (log 2 n) time and O (n log log n) work, for an alphabet <p> for the next iteration is O (n=(log fl n) 2 ). 3.2 Solution of the second and third problems The third stage of the optimal algorithm begins by using all but the last log log c log n iterations of the previous section; since the deterministic integer sorting algorithm of <ref> [BDHPRS89] </ref> needs O (m log log m) work for sorting m elements (from a range 1; : : : ; m 2 ), we can use it in each of these iterations, and still satisfy a linear work upper bound.
Reference: [BLMPSZ91] <author> G. E. Blelloch, C. E. Leiserson, B. M. Maggs, C. G. Plaxton, S. J Smith, M. Zagha, </author> <title> A Comparison of Sorting Algorithms for the Connection Machine CM-2, </title> <booktitle> In Proceedings of the 3 rd Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 3-16, </pages> <year> 1991. </year>
Reference: [CV86a] <author> R. Cole, and U. Vishkin, </author> <title> Deterministic Coin Toss ing with Applications to Parallel List Ranking, </title> <journal> In Information and Control, </journal> <volume> 70: </volume> <pages> 32-53, </pages> <year> 1986. </year>
Reference-contexts: Namely, we do not allow a substring of the form aa. The main idea behind the partitioning procedure below is the use of the deterministic coin tossing technique of Cole and Vishkin <ref> [CV86a] </ref> for dividing R C into blocks. 1. Put a divider to the left of r ff and to the right of r fi . <p> Recall that if we can restrict the range of the values to be sorted to integers between 1 and O (log 2 n), then we can apply the deterministic stable sorting algorithm of <ref> [CV86a] </ref> to achieve linear work in O (log 2 n) time. At this point we would like to present an overview of the improved third stage, starting from iteration k = log log c log n (from the end).
Reference: [CV86b] <author> R. Cole, and U. Vishkin, </author> <title> Deterministic Coin Toss ing and Accelerating Cascades: Micro and Macro Techniques for Designing Parallel Algorithms, </title> <booktitle> In Proceedings of the 18 th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 206-219, </pages> <year> 1986. </year>
Reference-contexts: The other iterations of the three stages of the Basic algorithm will remain unchanged. (The design of the optimal algorithm is essentially an application of the accelerating cascades method for deriving an efficient parallel algorithm from two or more algorithms for the same problem, see <ref> [CV86b] </ref>, or [Ja92].) We first explain how we solve the first problem and then the second and third problems. 3.1 Solution of the first problem: We start by discussing the emulation of the partitioning step in the first iteration (in the First and Second stage) of the Basic algorithm.
Reference: [Ga85] <author> Z. Galil, </author> <title> Optimal Parallel Algorithms for String Matching, </title> <journal> In Information and Control, </journal> <volume> 67: </volume> <pages> 144-157, </pages> <year> 1985. </year>
Reference-contexts: The general area of string matching has been enriched by parallel methods that enabled new serial algorithms as in this paper. Previous examples include <ref> [Ga85] </ref>, [Vi85], and [Vi91]. The new method is also relevant for sequence analysis in compressed data, since it allows for consistent compression of data. This can be done in the context of parallel or serial algorithms. 2 The Basic Algorithm We first describe a "basic" algorithm.
Reference: [Ja92] <author> J. Ja'Ja', </author> <title> An Introduction to Parallel Algorithms, </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: The other iterations of the three stages of the Basic algorithm will remain unchanged. (The design of the optimal algorithm is essentially an application of the accelerating cascades method for deriving an efficient parallel algorithm from two or more algorithms for the same problem, see [CV86b], or <ref> [Ja92] </ref>.) We first explain how we solve the first problem and then the second and third problems. 3.1 Solution of the first problem: We start by discussing the emulation of the partitioning step in the first iteration (in the First and Second stage) of the Basic algorithm.
Reference: [KMR72] <author> R. M. Karp, R. E. Miller, and A. L. Rosenberg, </author> <title> Rapid Identification of Repeated Patterns in Strings, Trees, and Arrays, </title> <booktitle> In Proceedings of the 4 th Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 125-136, </pages> <year> 1972. </year>
Reference-contexts: The substrings represented by two sibling edges must begin with different characters. An example of a suffix tree is given in Figure 1. Serial algorithms for suffix tree construction were given in <ref> [KMR72] </ref>, [We73], and [Mc76]. The two latter algorithms achieve a linear running time for an alphabet whose size is constant. A parallel algorithm was given in [AILSV88]. A Symmetry Breaking Challenge: As in the algorithm of [KMR72] work complexity of the above mentioned parallel algorithm is O (n log n). <p> Serial algorithms for suffix tree construction were given in <ref> [KMR72] </ref>, [We73], and [Mc76]. The two latter algorithms achieve a linear running time for an alphabet whose size is constant. A parallel algorithm was given in [AILSV88]. A Symmetry Breaking Challenge: As in the algorithm of [KMR72] work complexity of the above mentioned parallel algorithm is O (n log n). The approach of [KMR72] and [AILSV88] does not lend itself to linear work for the following reason: As these algorithms progress, they label all n 1 substrings of size 2, then all n 3-substrings of size 4, <p> The two latter algorithms achieve a linear running time for an alphabet whose size is constant. A parallel algorithm was given in [AILSV88]. A Symmetry Breaking Challenge: As in the algorithm of <ref> [KMR72] </ref> work complexity of the above mentioned parallel algorithm is O (n log n). The approach of [KMR72] and [AILSV88] does not lend itself to linear work for the following reason: As these algorithms progress, they label all n 1 substrings of size 2, then all n 3-substrings of size 4, and in general all (n 2 i + 1)-substrings of size 2 i (1 i log n).
Reference: [LZ77] <author> J. Ziv, and A. Lempel, </author> <title> A Universal Algorithm for Sequential Data Compression In IEEE Transactions on Information Theory, </title> <booktitle> 23: </booktitle> <pages> 337-343, </pages> <year> 1977. </year>
Reference: [MV91] <author> Y. Matias, and U. Vishkin, </author> <title> On Parallel Hashing and Integer Sorting, </title> <journal> In Journal of Algorithms, </journal> <volume> 12,4: </volume> <pages> 573-606, </pages> <year> 1991. </year>
Reference-contexts: The space complexity is O (m 2 ). This can be reduced to O (m 1+* ), for any fixed * &gt; 0, as in [AILSV88]. Getting linear space using hashing (and thereby entering randomization), as suggested in <ref> [MV91] </ref>, is also a possibility. An example for block partitioning and labeling is given in 2.3 Second Stage We define a core of iteration k recursively. Any k-substring S k;i induces, or spans another substring of input which is called a k-core.
Reference: [Mc76] <author> E. M. McCreight, </author> <title> A Space Economical Suffix Tree Construction Algorithm, </title> <journal> In Journal of the ACM, </journal> <volume> 23: </volume> <pages> 262-272, </pages> <year> 1976. </year>
Reference-contexts: The substrings represented by two sibling edges must begin with different characters. An example of a suffix tree is given in Figure 1. Serial algorithms for suffix tree construction were given in [KMR72], [We73], and <ref> [Mc76] </ref>. The two latter algorithms achieve a linear running time for an alphabet whose size is constant. A parallel algorithm was given in [AILSV88]. A Symmetry Breaking Challenge: As in the algorithm of [KMR72] work complexity of the above mentioned parallel algorithm is O (n log n).
Reference: [MSU94] <author> K. Mehlhorn, R. Sundar, and C. Uhrig, </author> <title> Main taining Dynamic Sequences under Equality Tests in Polylogarithmic Time, </title> <booktitle> to appear In Proceedings of the 5 th Annual ACM - SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1994. </year>
Reference-contexts: Comment. Our use of the deterministic coin tossing technique is novel. We use it for deriving "signatures" of strings, mapping similar substrings to the same signature. The only previous paper which made use of this technique for producing signatures is apparently by Mehlhorn, Sundar and Uhrig <ref> [MSU94] </ref>. They limited the use of these signatures to comparing full strings, and did not consider substrings. We had to develop significantly stronger tools for constructing suffix trees. Lemma 3 (consistency lemma) Let R d be a sub-string of R.
Reference: [S . V94] <author> S. C. S . ahinalp, and U. Vishkin, </author> <title> Symmetry Breaking in Suffix Tree Construction, </title> <note> In preparation </note>
Reference: [SV88] <author> B. Schieber, and U. Vishkin, </author> <title> On Finding Lowest Common Ancestors: Simplification and Paralleliza-tion, </title> <journal> In SIAM Journal of Computing, </journal> <volume> 17: </volume> <pages> 1253-1262, </pages> <year> 1988. </year>
Reference-contexts: The general idea is as follows. We first: (1) preprocess the tree T (k) 0 , so that the lowest common ancestor (LCA) of each pair of nodes in it can be retrieved in a constant number of operations ([BV88], <ref> [SV88] </ref>); and (2) sort the leaves of T (k) 0 according to their order of appearance in preorder traversal of T (k) 0 . For this the Euler Tour technique is applied.
Reference: [Vi85] <author> U. Vishkin, </author> <title> Optimal Parallel Pattern Matching in Strings, </title> <journal> In Information and Control, </journal> <volume> 67: </volume> <pages> 91-113, </pages> <year> 1985. </year>
Reference-contexts: The general area of string matching has been enriched by parallel methods that enabled new serial algorithms as in this paper. Previous examples include [Ga85], <ref> [Vi85] </ref>, and [Vi91]. The new method is also relevant for sequence analysis in compressed data, since it allows for consistent compression of data. This can be done in the context of parallel or serial algorithms. 2 The Basic Algorithm We first describe a "basic" algorithm.
Reference: [Vi91] <author> U. Vishkin, </author> <title> Deterministic Sampling ANew Tech nique for Fast Pattern Matching, </title> <journal> In SIAM Journal of Computing, </journal> <volume> 20: </volume> <pages> 22-40, </pages> <year> 1991. </year>
Reference-contexts: The general area of string matching has been enriched by parallel methods that enabled new serial algorithms as in this paper. Previous examples include [Ga85], [Vi85], and <ref> [Vi91] </ref>. The new method is also relevant for sequence analysis in compressed data, since it allows for consistent compression of data. This can be done in the context of parallel or serial algorithms. 2 The Basic Algorithm We first describe a "basic" algorithm.
Reference: [We73] <author> P. Weiner, </author> <title> Linear Pattern Matching Algorithm, </title> <booktitle> In Proceedings of the latexstoc:f inal:4:tex14 th IEEE Symposium on Switching and Automata Theory, pages latex stoc.final.4.tex1-11, </booktitle> <year> 1973. </year>
Reference-contexts: The substrings represented by two sibling edges must begin with different characters. An example of a suffix tree is given in Figure 1. Serial algorithms for suffix tree construction were given in [KMR72], <ref> [We73] </ref>, and [Mc76]. The two latter algorithms achieve a linear running time for an alphabet whose size is constant. A parallel algorithm was given in [AILSV88]. A Symmetry Breaking Challenge: As in the algorithm of [KMR72] work complexity of the above mentioned parallel algorithm is O (n log n).
References-found: 18

