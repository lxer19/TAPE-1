URL: http://www.ri.cmu.edu/afs/cs/project/stereo-machine/www/cvpr96.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs/project/stereo-machine/www/StereoMachine.html
Root-URL: 
Title: A Stereo Machine for Video-rate Dense Depth Mapping and Its New Applications  
Author: Takeo Kanade, Atsushi Yoshida, Kazuo Oda, Hiroshi Kano and Masaya Tanaka 
Address: 5000 Forbes Ave., Pittsburgh PA 15213  
Affiliation: The Robotics Institute, Carnegie Mellon University  
Abstract: We have developed a video-rate stereo machine that has the capability of generating a dense depth map at the video rate. The performance bench marks of the CMU video-rate stereo machine are: 1) multi image input of up to 6 cameras; 2) throughput of 30 million point disparity measurement per second; 3) frame rate of 30 frame/sec; 4) a dense depth map of up to 256 240 pixels; 5) disparity search range of up to 60 pixels; 6) high precision of depth output up to 8 bits (with interpolation). The capability of passively producing such a dense depth map (3D representation) of a scene at the video rate can open up a new class of applications of 3D vision: merging real and virtual worlds in real time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Nicholas Ayache and Francis Lustman, </author> <title> Trinocular stereovi-sion for robotics. </title> <type> Technical Report 1086, </type> <institution> INRIA, </institution> <month> Sept. </month> <year> 1989. </year>
Reference: [2] <author> P.J.Burt and E.H.Adelson, </author> <title> The Laplacian Pyramid as a Compact Image Code, IEEE Trans. on Communication, Vol.COM-Ball approaches Hit! Ball soars high and away Time balls point of view 31, </title> <publisher> No.4,pp.532-540. </publisher>
Reference-contexts: The maximum size of LOG filter becomes 2525 by this cascading technique. The LOG subsystem also has a multi-resolution capability which produces an image pyramid by repeatedly shrinking the images <ref> [2] </ref>.
Reference: [3] <author> Olivier Faugeras, </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig?, </title> <booktitle> In Computer Vision - ECCV 92, </booktitle> <volume> LNCS-Series Vol. 588, </volume> <publisher> Springer - Verlag, </publisher> <pages> pages 563-578, </pages> <year> 1992. </year>
Reference-contexts: Then the absolute difference , instead of the squared difference , has the following expression. (5) Here and are functions of rectified coordinates (s,t) and z, while and are functions of only (s,t). Either strong calibration methods [15, 9] or weak calibration methods <ref> [3] </ref> enable us to obtain these functions. The SSAD subsystem stores these functions in RAM in the form of tables. Using these tables, the SSAD hardware calculates absolute differences in the rectified coordinates (see Figure 8).
Reference: [4] <author> Olivier Faugeras, et al., </author> <title> Real time correlation based stereo: algorithm, implementations and applications, </title> <note> Research Report 2013, INRIA Sophia-Antipolis, </note> <year> 1993. </year>
Reference-contexts: The PRISM3 system developed by Teleos [12], the JPL stereo implemented on DataCube [10], CMUs Warp-based multi-baseline stereo [16], and INRIAs system <ref> [4] </ref> are among the most advanced real-time stereo systems; yet none of them are able to provide a complete video-rate output of range as dense as the input image with low latency. We have developed a video-rate stereo machine which has the throughput of 30 million pixel 2 /sec.
Reference: [5] <author> Pascal Fua, </author> <title> A parallel stereo algorithm that produces dense depth maps and preserves image features. </title> <type> Technical Report 1369, </type> <institution> Unite de Recherche, INRIA-Sophia Antipolis, France, </institution> <month> January </month> <year> 1991. </year>
Reference: [6] <author> Ali E.Kayaalp and James L. Eckman, </author> <title> A pipeline architecture for near real-time stereo range detection. </title> <type> Technical Report GDLS-AI-TR-88-1, </type> <institution> General Dynamics AI Lab, </institution> <month> November </month> <year> 1988. </year>
Reference: [7] <author> Takeo Kanade, P.J. Narayanan and Peter Rander, </author> <title> Virtualized Reality: Concepts and Early Results. </title> <booktitle> In Proc. of IEEE workshop on the Representation on Visual Scene, </booktitle> <address> Boston, </address> <month> June 25, </month> <year> 1995. </year>
Reference-contexts: The capability of producing a dense 3D representation at video rate opens up a new class of applications for 3D vision. We have been working on two such new applications: virtualized reality <ref> [7] </ref> and z keying. 5.1 Z Keying In visual media communication and display, it is often (a) the base camera image (b) a disparity map with 3 cameras (c) a disparity map with 5 cameras : a camera used : a camera unused : a camera used : a camera unused
Reference: [8] <author> Takeo Kanade, P.J. Narayanan and Peter Rander, </author> <title> Virtualized (Not Virtual) Reality. </title> <note> (to be presented) In Proc. of A presentation is schedule at the 15th International Display Research Conference (Asia Display 95), </note> <month> Oct 16-18, </month> <year> 1995, </year> <note> Hamamatsu, Japan. </note>
Reference-contexts: Figure 12 shows an example of a synthesized image sequence of a virtualized baseball scene. A scene of a person swinging a bat is captured, and the balls eye view is hit by the bat, and soars high and away into the sky <ref> [8] </ref>. Due to the limitations in image input and computation, this example was created off-line. 6 Conclusion This paper has presented the CMU video-rate stereo machine and a couple of its applications.

References-found: 8

