URL: http://www.research.digital.com/SRC/personal/monika/papers/monika-soda95.ps.gz
Refering-URL: http://www.research.digital.com/SRC/personal/monika/papers.html
Root-URL: http://www.research.digital.com
Title: Average Case Analysis of Dynamic Graph Algorithms  
Author: David Alberts Monika Rauch Henzinger 
Keyword: P l p  
Abstract: We present a model for edge updates with restricted randomness in dynamic graph algorithms and a general technique for analyzing the expected running time of an update operation. This model is able to capture the average case in many applications, since (1) it allows restrictions on the set of edges which can be used for insertions and (2) the type (insertion or deletion) of each update operation is arbitrary, i.e., not random. We use our technique to analyze existing and new dynamic algorithms for the following problems: maximum cardinality matching, minimum spanning forest, connectivity, 2-edge connectivity, k-edge connectivity, k-vertex connectivity, and bipartiteness. Given a random graph G with m 0 edges and n vertices and a sequence of l update operations such that the graph contains m i edges after operation i, the expected time for performing the updates for any l is O(l log n + m i ) in the case of minimum spanning forests, connectivity, 2-edge connectivity, and bipartiteness. The expected time per update operation is O(n) in the case of maximum matching. We also give improved bounds for k-edge and k-vertex connectivity. Additionally we give an insertions-only algorithm for maximum cardinality matching with worst-case O(n) amortized time per insertion. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Alberts and M. Rauch Henzinger. </author> <title> Average case analysis of dynamic graph algorithms. </title> <booktitle> In Proc. 6th Symp. on Discrete Algorithms, </booktitle> <pages> pages 312 - 321, </pages> <year> 1995. </year>
Reference-contexts: A preliminary version of this paper appeared in <ref> [1] </ref>. 2 A Model for Random Update Sequences To model the average case it is common practice to consider the expected performance with respect to a "random" input. So we have to define a probability distribution on possible updates.
Reference: [2] <author> H. Alt, K. Mehlhorn, H. Wagener, and E. Welzl. </author> <title> Congruence, similarity and symmetries of geometric objects. </title> <journal> Discrete Comp. Geom., </journal> <volume> 3:237 - 256, </volume> <year> 1988. </year>
Reference-contexts: Note that a dynamic algorithm which executes one phase of the static algorithm described by Tarjan in [33] for each update operation achieves an update time O (m). This was used for example in <ref> [2] </ref>. This is the only known improvement over recomputation from scratch which takes time O ( nm) [24, 35]. <p> Using just one phase of a static maximum cardinality matching algorithm per update leads to a dynamic algorithm with O (n + m) worst case update time (see, e.g., <ref> [2] </ref>). This is still the best known algorithm. In the following we show that a variant of this simple approach yields a bound of O (n) expected time for inputs which are random according to the rr-model.
Reference: [3] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: This graph is with equal probability any of the possible m-edge subgraphs of G = (V; E). If E is equal to V , then G is a random graph in the well-known G n;m model <ref> [3] </ref>.
Reference: [4] <author> J. Cheriyan, M. Y. Kao, and R. Thurimella. </author> <title> Algorithms for parallel k-vertex connectivity and sparse certificates. </title> <journal> SIAM J. Comput., </journal> <volume> 22:157 - 174, </volume> <year> 1993. </year>
Reference-contexts: We discuss next how to test dynamically if the graph is k-vertex connected. Lemma 9.1 also holds for k-vertex connectivity provided that T i is chosen to be a scan-first search forest of G n U i1 <ref> [4, 26] </ref>. To quickly test for the good case we define the smallest sparse k-edge connectivity certificate as follows: we number all vertices during a preprocessing phase with a unique label between 1 and n in an arbitrary, but fixed way.
Reference: [5] <author> L. P. Chew. </author> <title> Building voronoi diagrams for convex polygons in linear expected time. </title> <type> CS Tech Report TR90-147, </type> <institution> Dartmouth College, </institution> <year> 1986. </year>
Reference-contexts: There we have a worst case input graph and the algorithm works by maintaining a current solution while inserting the edges one by one in random order. In fact, backwards analysis first was used in computational geometry for exactly this purpose by Chew <ref> [5] </ref>.
Reference: [6] <author> K. L. Clarkson, K. Mehlhorn, and R. Seidel. </author> <title> Four results on randomized incremental constructions. </title> <journal> Comp. Geom.: Theory and Appl., </journal> <volume> 3:185 - 212, </volume> <year> 1993. </year>
Reference-contexts: The rr-model is a variation of a model for random update sequences used before in computational geometry (see, e.g., <ref> [6, 8, 25, 30] </ref>). Eppstein [8] considers the dynamic (geometric) maximum spanning tree problem and related problems for points in the plane. Exploiting their geometry, he gives data structures with polylogarithmic expected update times for these problems. <p> In contrast, we do not make any assumptions on the distribution of types of update operations. Thus, our analysis also applies if an adversary provides the (worst case) types of update operations. We adopt a generic model for random update sequences from computational geometry (see, e.g., <ref> [6, 8, 25, 30] </ref>). The dynamically changing object is a set E which is a random subset of a fixed set E, the universe.
Reference: [7] <author> J. Edmonds. </author> <title> Paths, trees, and flowers. </title> <journal> Canad. J. Math., </journal> <volume> 17:449 - 467, </volume> <year> 1965. </year>
Reference-contexts: If v is reachable, but only using odd alternating paths, then it is an odd vertex. Free vertices are also even. The sets of even and odd vertices are unique, i.e., they are independent of the particular choice of a maximum matching <ref> [7] </ref>. A non-reachable vertex is called out-of-forest vertex. 8.2 Data Structure and Suit (G) The data structure we maintain consists of a sparse blossom forest, parity informations (even, odd, or out-of-forest) for the vertices, and a list consisting of the edges in a current maximum matching. <p> Thus, it is trivial to answer a query. Additionally, we store at each node in the blossom forest a pointer to the tree that it belongs to. A blossom forest is a well-known data structure used in static maximum cardinality matching algorithms, see, e.g., <ref> [7, 23, 33] </ref>. Conceptually, the data structure is a sparse subgraph of the current graph G, which has the same matching number and the same parities as G. Even, odd, and out-of-forest vertices correspond to the Gallai-Edmonds-Decomposition of a graph. <p> In both cases this can be done in constant time. Tarjan [33] describes a static algorithm for computing a maximum matching in general graphs. This algorithm is a variant of Gabow's earlier implementation [14] of Edmond's algorithm <ref> [7] </ref>. Average Case Analysis of Dynamic Graph Algorithms 27 It proceeds in phases. In each phase it either constructs a sparse blossom forest, or it finds an augmenting path with respect to an intermediate matching computed so far and augments this matching in O (n + m) time.
Reference: [8] <author> D. Eppstein. </author> <title> Average case analysis of dynamic geometric optimization. </title> <booktitle> In Proc. 5th Symp. on Discrete Algorithms, </booktitle> <pages> pages 77 - 86, </pages> <year> 1994. </year>
Reference-contexts: The rr-model is a variation of a model for random update sequences used before in computational geometry (see, e.g., <ref> [6, 8, 25, 30] </ref>). Eppstein [8] considers the dynamic (geometric) maximum spanning tree problem and related problems for points in the plane. Exploiting their geometry, he gives data structures with polylogarithmic expected update times for these problems. <p> The rr-model is a variation of a model for random update sequences used before in computational geometry (see, e.g., [6, 8, 25, 30]). Eppstein <ref> [8] </ref> considers the dynamic (geometric) maximum spanning tree problem and related problems for points in the plane. Exploiting their geometry, he gives data structures with polylogarithmic expected update times for these problems. <p> In contrast, we do not make any assumptions on the distribution of types of update operations. Thus, our analysis also applies if an adversary provides the (worst case) types of update operations. We adopt a generic model for random update sequences from computational geometry (see, e.g., <ref> [6, 8, 25, 30] </ref>). The dynamically changing object is a set E which is a random subset of a fixed set E, the universe.
Reference: [9] <author> D. Eppstein. </author> <type> Personal communication, </type> <year> 1995. </year>
Reference-contexts: It is an interesting open question whether the data structure can be improved by distributing the costs of rebuilds over previous updates in a way that gives an expected time bound of O (n= p m + log n) per update. Eppstein <ref> [9] </ref> suggested that a good average case behavior for some of the above problems can also be shown for node insertions and deletions. Acknowledgments The authors would like to thank Emo Welzl for helpful discussions.
Reference: [10] <author> D. Eppstein, Z. Galil, and G. F. </author> <title> Italiano. Improved sparsification. </title> <type> Technical Report 93-20, </type> <institution> Dept. of Inf. and Comp. Sc., Univ. of Calif., </institution> <address> Irvine, CA 92717, </address> <year> 1993. </year>
Reference-contexts: In the case of maximum matching a query outputs a current maximum matching. Alternatively, a query could also be: "Is the edge e in the current graph in the current maximum matching?" Recently, a lot of work has been done on dynamic algorithms for various connectivity properties <ref> [10, 11, 12, 13, 18, 27, 28, 29] </ref>. The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17]. <p> The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) <ref> [10] </ref>. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17]. It is an open problem if the connected or 2-edge connected components of a graph can be maintained deterministically faster than O ( p n). <p> They can be updated within the same bounds for space and time. In the worst case the best deterministic bound is O ( p n) <ref> [10] </ref> and the best randomized algorithms take polylogarithmic time per update [19]. * We show that a conceptually simple dynamic algorithm for maximum cardinality matching has an average update time of O (n) with respect to the rr-model. <p> The third modification is necessary to speed up updates in the good case. Note that the running time of [12] can be reduced to O ( p n) using improved sparsification <ref> [10, 11] </ref>. Sparsification is a technique which was designed to reduce the number of edges that a dynamic graph algorithm has to deal with from m to O (n). <p> with a random subgraph of G of size m 0 for any m 0 , where m i is the number of edges in G after operation i. 6 Bipartiteness In this section we analyze the average case performance of an algorithm for dynamic bipartiteness due to Eppstein et al. <ref> [10, 11] </ref>. As in Section 5, we give each edge cost 1 and connect different connected components by dummy edges of cost 2. <p> This shows the claimed bounds on the running times. 8 Maximum Cardinality Matching Unlike minimum spanning tree and connectivity, the dynamic maximum matching problem is not solvable using sparsification <ref> [10, 11] </ref>, because there are no non-trivial certificates. However, there are sparse suitable subgraphs, so this problem reveals an interesting difference between the otherwise similar concepts of certificates and suitable subgraphs.
Reference: [11] <author> D. Eppstein, Z. Galil, G. F. Italiano, and A. Nissenzweig. </author> <title> Sparsification a technique for speeding up dynamic graph algorithms. </title> <booktitle> In Proc. 33rd Symp. on Foundations of Computer Science, </booktitle> <pages> pages 60 - 69, </pages> <year> 1992. </year>
Reference-contexts: In the case of maximum matching a query outputs a current maximum matching. Alternatively, a query could also be: "Is the edge e in the current graph in the current maximum matching?" Recently, a lot of work has been done on dynamic algorithms for various connectivity properties <ref> [10, 11, 12, 13, 18, 27, 28, 29] </ref>. The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17]. <p> Additionally we give an insertions-only algorithm for maximum cardinality matching with O (n) amortized time per insertion. In the case of k-edge and k-vertex connectivity we slightly improve the known bounds: * Eppstein et al. <ref> [11] </ref> describe an algorithm for dynamic k-edge connectivity with worst case update time O (k 2 n log (n=k)) using a minimum edge cut algorithm by Gabow [15]. <p> The third modification is necessary to speed up updates in the good case. Note that the running time of [12] can be reduced to O ( p n) using improved sparsification <ref> [10, 11] </ref>. Sparsification is a technique which was designed to reduce the number of edges that a dynamic graph algorithm has to deal with from m to O (n). <p> with a random subgraph of G of size m 0 for any m 0 , where m i is the number of edges in G after operation i. 6 Bipartiteness In this section we analyze the average case performance of an algorithm for dynamic bipartiteness due to Eppstein et al. <ref> [10, 11] </ref>. As in Section 5, we give each edge cost 1 and connect different connected components by dummy edges of cost 2. <p> A boundary vertex of a cluster is an endpoint of a tree edge connecting the cluster with a different cluster at the same level of the topology tree. The data structure in <ref> [11] </ref> consists of 1. the MST T 0 , 2. a topology tree T T where we store at each node C the distances between every pair of boundary vertices of C, 3. the corresponding 2-dimensional topology tree 2T T . <p> In <ref> [11] </ref> it is shown that the worst-case update time for this data structure is O ( p m). Our extensions only increase the running time by a constant factor. <p> Then we compare the parity of e with the parities of the selected edges stored at C fi D (if they exist) in constant time using the distance information in the data structure and the following lemma shown in <ref> [11] </ref>. Lemma 6.1 Let C and D be any two clusters at the same level of the topology tree, and let f 1 and f 2 be any two non-tree edges between C and D. <p> This shows the claimed bounds on the running times. 8 Maximum Cardinality Matching Unlike minimum spanning tree and connectivity, the dynamic maximum matching problem is not solvable using sparsification <ref> [10, 11] </ref>, because there are no non-trivial certificates. However, there are sparse suitable subgraphs, so this problem reveals an interesting difference between the otherwise similar concepts of certificates and suitable subgraphs. <p> Since there are at most n=2 phases, the total time is O ((n + m)n), i.e. the amortized time per insertion is O (n), provided the algorithm is started with an empty edge set. 9 k-Edge Connectivity and k-Vertex Connectivity Eppstein et al. <ref> [11] </ref> give a dynamic algorithm for k-edge connectivity with worst case update time O (k 2 n log (n=k)), which we slightly modify in order to speed up the good case. It uses an algorithm by Gabow [15] for the static problem and the following lemma.
Reference: [12] <author> G. N. Frederickson. </author> <title> Data structures for on-line updating of minimum spanning trees, with applications. </title> <journal> SIAM J. Comput., </journal> <volume> 14:781 - 798, </volume> <year> 1985. </year>
Reference-contexts: In the case of maximum matching a query outputs a current maximum matching. Alternatively, a query could also be: "Is the edge e in the current graph in the current maximum matching?" Recently, a lot of work has been done on dynamic algorithms for various connectivity properties <ref> [10, 11, 12, 13, 18, 27, 28, 29] </ref>. The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17]. <p> Average Case Analysis of Dynamic Graph Algorithms 3 1.2 New Results * Assuming that the weight of an edge is arbitrary, but fixed, we show that a modified version of Frederickson's topology tree data structure <ref> [12] </ref> for dynamic minimum spanning forests has an average case update time of O (log n + n= p m) plus amortized constant time. The data structure needs linear space and linear expected preprocessing time using [21]. <p> We did not include this for the sake of clarity, and since it was not needed for our applications. 4 Minimum Spanning Forests Frederickson <ref> [12] </ref> introduced the topology tree data structure to maintain a minimum spanning forest dynamically. In this section we slightly modify the topology tree data structure to give a dynamic minimum spanning forest algorithm with good average and the same worst-case performance as the algorithm in [12]. <p> 4 Minimum Spanning Forests Frederickson <ref> [12] </ref> introduced the topology tree data structure to maintain a minimum spanning forest dynamically. In this section we slightly modify the topology tree data structure to give a dynamic minimum spanning forest algorithm with good average and the same worst-case performance as the algorithm in [12]. This data structure is also the key data structure for the dynamic graph algorithms described in Sections 5, 6, and 7. To apply our technique of Section 3 we choose Suit (G) to consist of all minimum spanning trees of G. <p> Additionally, we modify the topology trees such that updates involving non-tree edges take time O (log n) plus amortized constant time for rebuilding parts of the data structure (good case), while the time for updates involving tree edges stays O ( p m) (bad case), which is the bound of <ref> [12] </ref>. By Theorem 3.1 this results in an average case update time with respect to the rr-model 8 David Alberts, Monika Rauch Henzinger of O (n= m + log n) expected time plus O (1) amortized time if we consider an arbitrary but fixed weight for every edge in G. <p> While the second modification leads immediately to an improvement, we show in Section 4.4 that the first modification leads to the desired amortized O (1) rebuild time per update. The third modification is necessary to speed up updates in the good case. Note that the running time of <ref> [12] </ref> can be reduced to O ( p n) using improved sparsification [10, 11]. Sparsification is a technique which was designed to reduce the number of edges that a dynamic graph algorithm has to deal with from m to O (n). <p> This implies that the probablity for a bad-case update is about 1=2. Hence, combining sparsification with our approach does not improve the running time. 4.1 Data Structure We first review parts of the data structure in <ref> [12, 13] </ref>, and make some changes needed to speed up the good case. We always keep the graph connected by dummy edges of weight 1. <p> Each leaf C fi D is labeled with the minimum edge cost of an edge between C and D or 1 if no such edge exists. Each internal node has degree at most four and is labeled with the minimum label of its children. See <ref> [12] </ref> for a detailed definition. The dynamic connectivity data structure of [12] consists of * a topology tree T T , * a 2-dimensional topology tree 2T T , and * a dynamic tree data structure storing the minimum spanning tree T 0 of G 0 . <p> Each internal node has degree at most four and is labeled with the minimum label of its children. See <ref> [12] </ref> for a detailed definition. The dynamic connectivity data structure of [12] consists of * a topology tree T T , * a 2-dimensional topology tree 2T T , and * a dynamic tree data structure storing the minimum spanning tree T 0 of G 0 . <p> We modify the data structure as follows: (A) We omit some of the nodes of 2T T with label 1 together with their whole subtree. (This does not create problems in the query or update algorithm of <ref> [12] </ref> since these subtrees do not store the cost of an edge, i.e. do not contain any useful information for the algorithms.) (B) At each leaf C fi D of 2T T we keep a priority queue of all non-tree edges with one endpoint in C and one endpoint in D. <p> An update operation (a) tests if the good case or the bad case occurs and (b) executes the corresponding algorithm. (a) The dynamic tree data structure that maintains T 0 is used (as in <ref> [12] </ref>) to decide which case occurs. (b) The algorithm consists of three steps: (b1) Updating the mapping from G to G 0 , i.e. maintaining G 0 as a degree-3 graph. This includes adding or removing the inserted or deleted edge and additional nodes and edges. <p> This includes adding or removing the inserted or deleted edge and additional nodes and edges. Since it is not explicitely stated in <ref> [12] </ref>, we give the details in Section 4.3. It takes constant time per update. Average Case Analysis of Dynamic Graph Algorithms 11 (b2) Updating the dynamic restricted partition and the structure of T T and 2T T . <p> Each step takes O (k) time, which gives a total time of O (k) for the bad case. Updating T T and the structure of 2T T whenever the dynamic restricted partition changes is identical to <ref> [12] </ref> and takes time O (k) per update. The procedure for the good case is described in Section 4.4 and takes time O (log n) plus constant amortized time. (b3) Updating the labels of 2T T and the dynamic tree. <p> The procedure for the good case is described in Section 4.4 and takes time O (log n) plus constant amortized time. (b3) Updating the labels of 2T T and the dynamic tree. For a bad-case update the algorithm consists of the algorithm in <ref> [12] </ref> plus the obvious updates of the priority queues. In the good case, let (x; y) be the edge that is updated, let C be the cluster containing x and let D be the cluster containing y. <p> If the cardinality of a new cluster is larger than 5k=3, this cluster is split using Lemma 4.1. The structure of T T and 2T T : We update T T as in <ref> [12] </ref>. If Condition (2) or (3) had to be restored (i.e. the update spent already O (k) time), we update 2T T as in [12]. <p> The structure of T T and 2T T : We update T T as in <ref> [12] </ref>. If Condition (2) or (3) had to be restored (i.e. the update spent already O (k) time), we update 2T T as in [12]. If only Condition (1) had to be restored (i.e. the update spent only O (1) time so far), the update added at most 6 constant size clusters. <p> G of size m 0 for any m 0 is O (l log n + i=1 n= m i ), where m i is the number of edges in G after operation i. 14 David Alberts, Monika Rauch Henzinger 5 Connectivity To maintain connectivity dynamically the algorithm by Frederickson in <ref> [12] </ref> assigns cost 1 to edges in the current graphs and connects different connected component by cost 2 (dummy) edges. Queries can be answered in worst case logarithmic time using the dynamic tree data structure representing T 0 . <p> of G between C and D of the same parity. 6.2 Updates An update operation (a) tests if the good case or the bad case occurs and (b) executes the corresponding algorithm. (a) The dynamic tree data structure that maintains the minimum spanning tree T 0 is used (as in <ref> [12] </ref>) to decide which case occurs. (b) The algorithm consists of three steps: (b1) Updating the mapping from G to G 0 , i.e. maintaining G 0 as a degree-3 graph. See Section 4.3.
Reference: [13] <author> G. N. Frederickson. </author> <title> Ambivalent data structures for dynamic 2-edge-connectivity and k smallest spanning trees. </title> <booktitle> In Proc. 32nd Symp. on Foundations of Computer Science, </booktitle> <pages> pages 632 - 641, </pages> <year> 1991. </year> <type> 30 David Alberts, Monika Rauch Henzinger </type>
Reference-contexts: In the case of maximum matching a query outputs a current maximum matching. Alternatively, a query could also be: "Is the edge e in the current graph in the current maximum matching?" Recently, a lot of work has been done on dynamic algorithms for various connectivity properties <ref> [10, 11, 12, 13, 18, 27, 28, 29] </ref>. The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17]. <p> This implies that the probablity for a bad-case update is about 1=2. Hence, combining sparsification with our approach does not improve the running time. 4.1 Data Structure We first review parts of the data structure in <ref> [12, 13] </ref>, and make some changes needed to speed up the good case. We always keep the graph connected by dummy edges of weight 1. <p> Our definition is a modification of the definition of a restricted partition of order k in <ref> [13] </ref>: Condition (3) is modified, since our amortized plan outline above would not apply: in the definition of [13] it is possible that two clusters C 1 and C 2 are merged and only O (1) updates have occurred since the creation of C 1 and C 2 . <p> Our definition is a modification of the definition of a restricted partition of order k in <ref> [13] </ref>: Condition (3) is modified, since our amortized plan outline above would not apply: in the definition of [13] it is possible that two clusters C 1 and C 2 are merged and only O (1) updates have occurred since the creation of C 1 and C 2 . <p> We say cluster C 2 is a tree neighbor of cluster C 1 if there exists a tree edge with one endpoint in C 1 and one endpoint in C 2 . To initialize the partition we first use the procedure given in <ref> [13] </ref>, which finds in linear time a partition of the vertices so that 10 David Alberts, Monika Rauch Henzinger (1) each cluster with tree degree 3 has cardinality 1, (2) each set in the partition is a cluster with tree degree 3 and cardinality k, (3') each essential cluster has a <p> It takes constant time per update. Average Case Analysis of Dynamic Graph Algorithms 11 (b2) Updating the dynamic restricted partition and the structure of T T and 2T T . In the bad case we restore Conditions (1) and (2) as in <ref> [13] </ref>, which modifies O (1) clusters. Each of the resulting (at most constant) essential clusters of size less than k=3 is merged with neighboring clusters until its size is at least k=3 or it is no longer essential. <p> with a random subgraph of G of size m 0 for any m 0 , where m i is the number of edges in G after operation i. 7 2-Edge Connectivity Frederickson gives a data structure, called ambivalent data structure, that answers 2-edge connectivity queries in time O (log n) <ref> [13] </ref>. It can be updated in time O ( p The basic idea is to maintain a spanning tree T of the graph G and coverage information for each tree edge. <p> A tree edge e is covered if there exists a non-tree edge (x; y) such that e lies on the tree path between x and y. As shown in <ref> [13] </ref>, two nodes u and v are 2-edge connected iff all edges in the tree path between u and v are covered. <p> We modify the ambivalent data structure and its update algorithm in order to speed up the good case. 7.1 Data Structure We first describe the data structure of <ref> [13] </ref> and then give our modifications. As in Section 4, the algorithm gives each edge G cost 1 and connects G by dummy edges of cost 2. We choose Suit (G) to consist of all minimum spanning trees of G. <p> The path associated with a cluster C is a subpath of the spanning tree T 0 , formed by edges of C. See <ref> [13] </ref> for the definition of complete and partial paths, For a node u 2 C, let proj (u) be the node on the partial path of C that is closest to u in T 0 and let dist (u; e) be the number of edges on the partial path of C <p> Since d is O (log n) 1 The definition of complete paths in <ref> [13] </ref> does not make them vertex-disjoint: The head of a complete path can be contained in another complete path. To make them vertex-disjoint we simply create a second copy of these shared nodes in the extended path data structure. <p> We use this data structure to maintain the complete and partial paths together with their coverage information. An edge e on a partial or complete path P is covered in the extended dynamic path data structure iff it is covered in the binary tree representation of <ref> [13] </ref>. Expressed more formally, the cover value of e is larger than 0 in the extended dynamic path data structure iff the somecov value of an ancestor of e is set to 1 in the binary tree representation of P . 2. <p> It takes time O (log n). We leave the details to the reader. 3. M ax-heaps: We do not keep maxcover values, but instead the corresponding maxcover edge at each node of 2T T . While the data structure in <ref> [13] </ref> used maxcover values to cover paths, our algorithm uses maxcoer edges instead. <p> The maximum element of the heap is the maxcover edge (C; D; e). (ii) If a node C of T T has a complete path, it has a degree-1 child C 1 in T T (see <ref> [13] </ref>). Let e be the tree edge incident to C 1 . <p> For all cluster D 6= C 1 on the same level as C 1 , the heap max (C) contains all non-tree edges (u; v) with u 2 C 1 and v 2 D in the order of the dist (u; e)-values. The algorithm of <ref> [13] </ref> recomputes this value, which is a maximum of O ( p m) numbers, from scratch after each update. We avoid this by adding the heap. 7.2 Updates We now describe the modified update algorithm. As in Section 4.2 an update executes Steps (a)- (b3). <p> Steps (a)-(b2) are identical to Section 4.2. Step (b3) updates the partial and complete paths, the labels of T T , the labels of 2T T , and the dynamic tree of T . In the bad case it updates the labels in the original datastructure as in <ref> [13] </ref> and it updates the new labels of the modified data structure in time O ( p m) in the straightforward way. The partial and complete paths are updated using the same operations as in [13], but using our new data structure instead of the binary tree data structure. <p> In the bad case it updates the labels in the original datastructure as in <ref> [13] </ref> and it updates the new labels of the modified data structure in time O ( p m) in the straightforward way. The partial and complete paths are updated using the same operations as in [13], but using our new data structure instead of the binary tree data structure. For each operation, its running time matches the running time of the binary tree representation. The algorithm for Step (b3) in the good case is given in Section 7.3.
Reference: [14] <author> H. N. Gabow. </author> <title> Implementation of algorithms for maximum matching on nonbipartite graphs. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Stanford University, Stanford, </institution> <address> CA, </address> <year> 1973. </year>
Reference-contexts: In both cases this can be done in constant time. Tarjan [33] describes a static algorithm for computing a maximum matching in general graphs. This algorithm is a variant of Gabow's earlier implementation <ref> [14] </ref> of Edmond's algorithm [7]. Average Case Analysis of Dynamic Graph Algorithms 27 It proceeds in phases.
Reference: [15] <author> H. N. Gabow. </author> <title> A matroid approach to finding edge connectivity and packing arborescences. </title> <booktitle> In Proc. 23rd Symp. on Theory of Computing, </booktitle> <pages> pages 112 - 122, </pages> <year> 1991. </year>
Reference-contexts: In the case of k-edge and k-vertex connectivity we slightly improve the known bounds: * Eppstein et al. [11] describe an algorithm for dynamic k-edge connectivity with worst case update time O (k 2 n log (n=k)) using a minimum edge cut algorithm by Gabow <ref> [15] </ref>. We show that (with a slight modification) its average case update time is O (min (1; kn=m)k 2 n log (n=k)) plus O (k) amortized time. This gives time O (min (1; n=m)n log n) plus amortized constant time for constant k. <p> It uses an algorithm by Gabow <ref> [15] </ref> for the static problem and the following lemma. Let G be a graph and T 1 = U 1 a spanning forest of G. Let T i be a spanning forest of G n U i1 and let U i be U i1 [ T i .
Reference: [16] <author> Z. Galil. </author> <title> Finding the vertex connectivity of graphs. </title> <journal> SIAM J. Comput., </journal> <volume> 9:197 - 199, </volume> <year> 1980. </year>
Reference-contexts: structure needs O (m + kn) space and preprocessing time. * We create a dynamic k-vertex connectivity algorithm, using the algorithm by Nagamochi and Ibaraki for finding sparse k-vertex certificates [26] and the O (k 3 n 1:5 + k 2 n 2 ) minimum vertex cut algorithm by Galil <ref> [16] </ref>. A query takes constant time. The average update time is O (min (1; kn=m)(k 3 n 1:5 +k 2 n 2 )), which is O (min (n 2 ; n 3 =m)) for constant k. The preprocessing time and the space requirement is linear. <p> In the bad case we additionally might have to check whether the new suitable subgraph S 0 k is k-vertex connected. For this purpose we use the (static) O (k 3 n 1:5 + k 2 n 2 ) time k-vertex algorithm by Galil <ref> [16] </ref>. This provides the following result.
Reference: [17] <author> M. Rauch Henzinger, M. </author> <title> Thorup. Improved sampling with applications to dynamic graph algorithms. </title> <note> To appear in Proc. ICALP '96, </note> <year> 1996. </year>
Reference-contexts: The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update <ref> [17] </ref>. It is an open problem if the connected or 2-edge connected components of a graph can be maintained deterministically faster than O ( p n). A second interesting question is if a maximum matching can be maintained in time o (m) per update.
Reference: [18] <author> M. Rauch Henzinger. </author> <title> Fully dynamic cycle equivalence in graphs. </title> <booktitle> In Proc. 35th Symp. on Foundations of Computer Science, </booktitle> <pages> pages 744 - 755, </pages> <year> 1994. </year>
Reference-contexts: In the case of maximum matching a query outputs a current maximum matching. Alternatively, a query could also be: "Is the edge e in the current graph in the current maximum matching?" Recently, a lot of work has been done on dynamic algorithms for various connectivity properties <ref> [10, 11, 12, 13, 18, 27, 28, 29] </ref>. The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17].
Reference: [19] <author> M. Rauch Henzinger and V. King. </author> <title> Randomized dynamic algorithms with polylogarithmic time per operation. </title> <booktitle> To appear in Proc. 27th Symp. on Theory of Computing, </booktitle> <year> 1995. </year>
Reference-contexts: They can be updated within the same bounds for space and time. In the worst case the best deterministic bound is O ( p n) [10] and the best randomized algorithms take polylogarithmic time per update <ref> [19] </ref>. * We show that a conceptually simple dynamic algorithm for maximum cardinality matching has an average update time of O (n) with respect to the rr-model. The algorithm is based on the static maximum matching algorithm described in [33].
Reference: [20] <author> R. M. Karp. </author> <type> personal communications. </type>
Reference-contexts: The rr-model is especially suited to capture the average case in many applications, since (1) it allows restrictions on the set of edges which can be used for insertions and (2) the type (insertion or deletion) of each update operation is arbitrary, i.e., not random. 1.1 Related Work Karp <ref> [20] </ref> gave a deletions-only connectivity algorithm. If the initial graph is random and random edges are deleted, the total expected time for a sequence of deletions is O (n 2 log n).
Reference: [21] <author> P. N. Klein and R. E. Tarjan. </author> <title> A linear-time algorithm for minimum spanning tree. </title> <booktitle> In Proc. 26th Symp. on Theory of Computing, </booktitle> <pages> pages 9 - 15, </pages> <year> 1994. </year>
Reference-contexts: The data structure needs linear space and linear expected preprocessing time using <ref> [21] </ref>. The best worst case update time for this problem is O ( p * Dynamic connectivity, 2-edge connectivity, and bipartiteness ("Is the current graph bipartite?") are closely related to the dynamic minimum spanning forest problem. They can be updated within the same bounds for space and time. <p> Amortizing the O (k) rebuilding cost over these updates gives an amortized constant rebuilding cost per update. 4.5 Final Result Choosing k = O ( p m) gives a data structure that fulfills the following lemma, using the linear expected time algorithm for minimum spanning trees <ref> [21] </ref> during preprocessing. Lemma 4.3 There exists a data structure that maintains a minimum spanning forest of a graph with any real-valued cost-function on the edges.
Reference: [22] <author> P. M. Lewis, R. E. Stearns, J. Hartmanis. </author> <title> Memory bounds for recognition of context-free and context-sensitve languages. </title> <booktitle> In IEEE Conference on Switching Theory and Logical Design, </booktitle> <pages> pages 191-202, </pages> <year> 1965. </year>
Reference: [23] <author> L. Lovasz and M. D. Plummer. </author> <title> Matching Theory, </title> <booktitle> volume 29 of Annals of Discrete Mathematics. </booktitle> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1986. </year>
Reference-contexts: One vertex is a trivial blossom. The easiest nontrivial case is just an odd cycle where all vertices but one are matched. Note that the definition of a blossom is not unique in the literature, we define it similar to <ref> [23] </ref>. A blossom which is not properly contained in another one is a maximal blossom. <p> Thus, it is trivial to answer a query. Additionally, we store at each node in the blossom forest a pointer to the tree that it belongs to. A blossom forest is a well-known data structure used in static maximum cardinality matching algorithms, see, e.g., <ref> [7, 23, 33] </ref>. Conceptually, the data structure is a sparse subgraph of the current graph G, which has the same matching number and the same parities as G. Even, odd, and out-of-forest vertices correspond to the Gallai-Edmonds-Decomposition of a graph. <p> Even, odd, and out-of-forest vertices correspond to the Gallai-Edmonds-Decomposition of a graph. For a definition and properties of this decomposition 3 The length of a path is the number of edges it contains. 26 David Alberts, Monika Rauch Henzinger see <ref> [23] </ref>. Since our algorithm maintains the partition of the vertices into even, odd, and out-of-forest vertices, it also maintains the Gallai-Edmonds-Decomposition of the graph. We define the set Suit (G) as follows.
Reference: [24] <author> S. Micali and V. Vazirani. </author> <title> An O(V 1=2 E) algorithm for finding maximum matching in general graphs. </title> <booktitle> In Proc. 21st Symp. on Foundations of Computer Science, </booktitle> <pages> pages 17 - 27, </pages> <year> 1980. </year>
Reference-contexts: This was used for example in [2]. This is the only known improvement over recomputation from scratch which takes time O ( nm) <ref> [24, 35] </ref>. We achieve better (average case) bounds for both problems in the following model of restricted randomness (rr-model): Given a random graph G with n vertices and m edges, an adversary can determine whether the type of the next operation is an insertion or a deletion. <p> The algorithm is based on the static maximum matching algorithm described in [33]. The space needed is linear and the preprocessing time is O ( p nm) using <ref> [24] </ref>. Additionally we give an insertions-only algorithm for maximum cardinality matching with O (n) amortized time per insertion. <p> These bad cases take O (n + m) time. All good cases can be handled in constant time, since we just update the adjacency structure of the graph. For preprocessing we use the static O ( nm) algorithm of Micali and Vazirani <ref> [24, 35] </ref> to construct a maximum matching in the initial random graph and one phase of Tarjan's algorithm to construct a sparse blossom forest with respect to the initial maximum matching. Using Theorem 3.1 we get the following result.
Reference: [25] <author> K. Mulmuley. </author> <title> Randomized, multidimensional search trees: dynamic sampling. </title> <booktitle> In Proc. 7th Symp. on Computational Geometry, </booktitle> <pages> pages 121 - 131, </pages> <year> 1991. </year>
Reference-contexts: The rr-model is a variation of a model for random update sequences used before in computational geometry (see, e.g., <ref> [6, 8, 25, 30] </ref>). Eppstein [8] considers the dynamic (geometric) maximum spanning tree problem and related problems for points in the plane. Exploiting their geometry, he gives data structures with polylogarithmic expected update times for these problems. <p> In contrast, we do not make any assumptions on the distribution of types of update operations. Thus, our analysis also applies if an adversary provides the (worst case) types of update operations. We adopt a generic model for random update sequences from computational geometry (see, e.g., <ref> [6, 8, 25, 30] </ref>). The dynamically changing object is a set E which is a random subset of a fixed set E, the universe.
Reference: [26] <author> H. Nagamochi and T. Ibaraki. </author> <title> Linear time algorithms for finding a sparse k-connected spanning subgraph of a k-connected graph. </title> <journal> Algorithmica, </journal> <volume> 7:583 - 596, </volume> <year> 1992. </year>
Reference-contexts: The data structure needs O (m + kn) space and preprocessing time. * We create a dynamic k-vertex connectivity algorithm, using the algorithm by Nagamochi and Ibaraki for finding sparse k-vertex certificates <ref> [26] </ref> and the O (k 3 n 1:5 + k 2 n 2 ) minimum vertex cut algorithm by Galil [16]. A query takes constant time. <p> Let T i be a spanning forest of G n U i1 and let U i be U i1 [ T i . Then U k is called a sparse k-edge connectivity certificate for G. Lemma 9.1 <ref> [26, 34] </ref> Let G be a graph and let U k be a sparse k-edge connectivity certificate for G. Then G is k-edge connected if and only if U k is k-edge connected. For notational convenience let U 0 be the empty graph. <p> We discuss next how to test dynamically if the graph is k-vertex connected. Lemma 9.1 also holds for k-vertex connectivity provided that T i is chosen to be a scan-first search forest of G n U i1 <ref> [4, 26] </ref>. To quickly test for the good case we define the smallest sparse k-edge connectivity certificate as follows: we number all vertices during a preprocessing phase with a unique label between 1 and n in an arbitrary, but fixed way. <p> To quickly test for the good case we define the smallest sparse k-edge connectivity certificate as follows: we number all vertices during a preprocessing phase with a unique label between 1 and n in an arbitrary, but fixed way. Then, we use the linear-time algorithm of <ref> [26] </ref> to find U k . This algorithm sometimes makes arbitrary choices which vertex to select next. We requiring that if more than one vertices can be selected, the algorithm has to use the one with the minimum label. <p> The resulting sparse k-edge connectivity certificate S k is called the smallest sparse k-edge connectivity certificate. We choose Suit (G) to be the unique smallest sparse k-edge connectivity certificate S k of G. Note that even with this additional requirement the algorithm of <ref> [26] </ref> runs in time O (m+n log n). Thus, we can test if the insertion of an edge e is a good case or bad case by running this algorithm on S k [ e in time O (kn + n log n).
Reference: [27] <author> M. H. Rauch. </author> <title> Fully dynamic biconnectivity in graphs. </title> <booktitle> In Proc. 33rd Symp. on Foundations of Computer Science, </booktitle> <pages> pages 50 - 59, </pages> <year> 1992. </year>
Reference-contexts: In the case of maximum matching a query outputs a current maximum matching. Alternatively, a query could also be: "Is the edge e in the current graph in the current maximum matching?" Recently, a lot of work has been done on dynamic algorithms for various connectivity properties <ref> [10, 11, 12, 13, 18, 27, 28, 29] </ref>. The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17].
Reference: [28] <author> M. H. Rauch. </author> <title> Improved data structures for fully dynamic biconnectivity. </title> <booktitle> In Proc. 26th Symp. on Theory of Computing, </booktitle> <pages> pages 686 - 695, </pages> <year> 1994. </year>
Reference-contexts: In the case of maximum matching a query outputs a current maximum matching. Alternatively, a query could also be: "Is the edge e in the current graph in the current maximum matching?" Recently, a lot of work has been done on dynamic algorithms for various connectivity properties <ref> [10, 11, 12, 13, 18, 27, 28, 29] </ref>. The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17].
Reference: [29] <author> J. H. Reif, P. G. Spirakis, and M. Yung. </author> <title> Re-randomization and average case analysis of fully dynamic graph algorithms. </title> <type> Alcom Technical Report TR 93.01.3. </type>
Reference-contexts: In the case of maximum matching a query outputs a current maximum matching. Alternatively, a query could also be: "Is the edge e in the current graph in the current maximum matching?" Recently, a lot of work has been done on dynamic algorithms for various connectivity properties <ref> [10, 11, 12, 13, 18, 27, 28, 29] </ref>. The current best deterministic bound for maintaining connected or 2-edge connected components of a graph is O ( p n) [10]. The best randomized algorithm achieves O (log 2 n), resp. O (log 3 n) per update [17]. <p> If the initial graph is random and random edges are deleted, the total expected time for a sequence of deletions is O (n 2 log n). In <ref> [29] </ref> a different random input model for dynamic graph algorithms is presented, called fair stochastic graph process (fsgp). It assumes that the type of the next operation as well as its parameter are chosen uniformly at random. <p> Since the rr-model does not make any assumptions about the distribution of the types of update operations, it is more general than a fsgp, which assumes that insertions (deletions) occur with probability 1=2. The algorithm, presented in <ref> [29] </ref> takes expected time O (lk log 3 n) maintaining the k-vertex connected components (k constant) for a sequence of l n 2 log n update operations. <p> For the average case analysis at least the edge to be inserted or deleted should be given with some probability distribution. Now two cases are possible: either the type of the update operation is random or not. Reif, Spirakis, and Yung <ref> [29] </ref> studied a model in which the probability of an insertion (deletion) is 1=2. In contrast, we do not make any assumptions on the distribution of types of update operations. Thus, our analysis also applies if an adversary provides the (worst case) types of update operations.
Reference: [30] <author> O. Schwarzkopf. </author> <title> Dynamic Maintenance of Convex Polytopes and Related Structures. </title> <type> PhD thesis, </type> <institution> Freie Universitat Berlin, </institution> <year> 1992. </year>
Reference-contexts: The rr-model is a variation of a model for random update sequences used before in computational geometry (see, e.g., <ref> [6, 8, 25, 30] </ref>). Eppstein [8] considers the dynamic (geometric) maximum spanning tree problem and related problems for points in the plane. Exploiting their geometry, he gives data structures with polylogarithmic expected update times for these problems. <p> In contrast, we do not make any assumptions on the distribution of types of update operations. Thus, our analysis also applies if an adversary provides the (worst case) types of update operations. We adopt a generic model for random update sequences from computational geometry (see, e.g., <ref> [6, 8, 25, 30] </ref>). The dynamically changing object is a set E which is a random subset of a fixed set E, the universe.
Reference: [31] <author> R. Seidel. </author> <title> Backwards analysis of randomized geometric algorithms. </title> <editor> In J. Pach, editor, </editor> <booktitle> New Trends in Discrete and Computational Geometry, </booktitle> <pages> pages 37 - 67. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1993. </year> <title> Average Case Analysis of Dynamic Graph Algorithms 31 </title>
Reference-contexts: In the case of dense graphs these improvements are exponential for some of the problems. After presenting the rr-model in Section 2 we give a general technique for analyzing the expected running time of an update operation using backwards analysis <ref> [31] </ref> in Section 3. As far as we know, this is the first application of backwards analysis to dynamic graph problems. <p> We use a technique called backwards analysis, which already lead to a variety of elegant proofs for randomized incremental geometric algorithms, see <ref> [31] </ref> and its references. If all updates are performed in approximately the same time bound, there is no need for an average case analysis.
Reference: [32] <author> D. D. Sleator and R. E. Tarjan. </author> <title> A data structure for dynamic trees. </title> <journal> J. Comput. Sys. Sci., </journal> <volume> 26:362 - 391, </volume> <year> 1983. </year>
Reference-contexts: These are called the selected edges. For each selected edge we maintain the distances of its endpoints to the boundary vertices of the corresponding clusters. We extend this data structure as follows to speed up updates in the good case. 1. We keep a dynamic tree data structure <ref> [32] </ref> of T 0 (for determining distances between nodes in T ) giving dashed edges length 0 and non-dashed edges length 1. Average Case Analysis of Dynamic Graph Algorithms 15 2. <p> We present the interface of the data structure next and give its implementation in Section 7.5. The extended dynamic path data structure extends the dynamic path data structure of <ref> [32] </ref>. <p> Instead we store the spanning tree of T 0 in a dynamic tree data structure <ref> [32] </ref> and keep for each tree edge e in C a cover-counter: If e is not on the partial path of C, its cover-counter counts the number of non-tree edges incident to C that cover e. If e is on the partial path of C, its cover-counter is always 1. <p> It is based on the dynamic paths data structure which Sleator and Tarjan used for their dynamic trees <ref> [32] </ref>. We consider the following problem. We are given a set of paths such that two paths are either vertex-disjoint or one path is contained in the other one. <p> In their paper on dynamic trees <ref> [32] </ref> Sleator and Tarjan introduce a data structure for the dynamic maintenance of a collection of vertex-disjoint edge weighted paths. Each path p has a head and a tail. The data structure supports 11 kinds of operations. A subset of them is quoted below from [32]. <p> their paper on dynamic trees <ref> [32] </ref> Sleator and Tarjan introduce a data structure for the dynamic maintenance of a collection of vertex-disjoint edge weighted paths. Each path p has a head and a tail. The data structure supports 11 kinds of operations. A subset of them is quoted below from [32]. <p> A Link or U nlink operation takes constant time since, as shown in <ref> [32] </ref>, the local information can be updated in constant time. Any of the other operations is enclosed in a sequence at most 2d U nlink and Link operations.
Reference: [33] <author> R. E. Tarjan. </author> <title> Data Structures and Network Algorithms, </title> <booktitle> volume 44 of CBMS-NSF Regional Conference Series in Applied Mathematics. Society for Industrial and Applied Mathematics, </booktitle> <address> Philadelphia, Pennsylvania, </address> <year> 1983. </year>
Reference-contexts: A second interesting question is if a maximum matching can be maintained in time o (m) per update. Note that a dynamic algorithm which executes one phase of the static algorithm described by Tarjan in <ref> [33] </ref> for each update operation achieves an update time O (m). This was used for example in [2]. This is the only known improvement over recomputation from scratch which takes time O ( nm) [24, 35]. <p> The algorithm is based on the static maximum matching algorithm described in <ref> [33] </ref>. The space needed is linear and the preprocessing time is O ( p nm) using [24]. Additionally we give an insertions-only algorithm for maximum cardinality matching with O (n) amortized time per insertion. <p> Thus, it is trivial to answer a query. Additionally, we store at each node in the blossom forest a pointer to the tree that it belongs to. A blossom forest is a well-known data structure used in static maximum cardinality matching algorithms, see, e.g., <ref> [7, 23, 33] </ref>. Conceptually, the data structure is a sparse subgraph of the current graph G, which has the same matching number and the same parities as G. Even, odd, and out-of-forest vertices correspond to the Gallai-Edmonds-Decomposition of a graph. <p> In case of an insertion, we can check whether one of the three conditions mentioned in Lemma 8.1 applies by using the parity information and the tree pointers at the vertices. In both cases this can be done in constant time. Tarjan <ref> [33] </ref> describes a static algorithm for computing a maximum matching in general graphs. This algorithm is a variant of Gabow's earlier implementation [14] of Edmond's algorithm [7]. Average Case Analysis of Dynamic Graph Algorithms 27 It proceeds in phases.
Reference: [34] <author> R. Thurimella. </author> <title> Techniques for the Design of Parallel Graph Algorithms. </title> <type> PhD thesis, </type> <institution> University of Texas, Austin, </institution> <year> 1989. </year>
Reference-contexts: Let T i be a spanning forest of G n U i1 and let U i be U i1 [ T i . Then U k is called a sparse k-edge connectivity certificate for G. Lemma 9.1 <ref> [26, 34] </ref> Let G be a graph and let U k be a sparse k-edge connectivity certificate for G. Then G is k-edge connected if and only if U k is k-edge connected. For notational convenience let U 0 be the empty graph.
Reference: [35] <author> V. V. Vazirani. </author> <title> A theory of alternating paths and blossoms for proving correctness of the O( V E) general graph maximum matching algorithm. </title> <journal> Combinatorica, </journal> <volume> 14(1):71 - 109, </volume> <year> 1994. </year>
Reference-contexts: This was used for example in [2]. This is the only known improvement over recomputation from scratch which takes time O ( nm) <ref> [24, 35] </ref>. We achieve better (average case) bounds for both problems in the following model of restricted randomness (rr-model): Given a random graph G with n vertices and m edges, an adversary can determine whether the type of the next operation is an insertion or a deletion. <p> These bad cases take O (n + m) time. All good cases can be handled in constant time, since we just update the adjacency structure of the graph. For preprocessing we use the static O ( nm) algorithm of Micali and Vazirani <ref> [24, 35] </ref> to construct a maximum matching in the initial random graph and one phase of Tarjan's algorithm to construct a sparse blossom forest with respect to the initial maximum matching. Using Theorem 3.1 we get the following result.
References-found: 35

