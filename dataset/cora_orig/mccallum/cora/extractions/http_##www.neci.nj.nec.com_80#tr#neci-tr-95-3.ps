URL: http://www.neci.nj.nec.com:80/tr/neci-tr-95-3.ps
Refering-URL: http://www.neci.nj.nec.com:80/tr/
Root-URL: 
Email: fsuresh,wrightg@research.nj.nec.com  
Title: Effective Flow Analysis for Avoiding Run-Time Checks analysis employs a novel approximation technique called polymorphic
Author: Suresh Jagannathan and Andrew Wright 
Note: The  
Date: May 1, 1995  
Address: 4 Independence Way, Princeton, NJ 08540  
Affiliation: NEC Research Institute,  
Abstract: This paper describes a general purpose program analysis that computes global control-flow and data-flow information for higher-order, call-by-value programs. This information can be used to drive global program optimizations such as inlining and run-time check elimination, as well as optimizations like constant folding and loop invariant code motion that are typically based on special-purpose local analyses. Experimental results derived from an implementation of the analysis for Scheme indicate that the analysis is extremely precise and has reasonable cost. In particular, it eliminates significantly more run-time checks than simple flow analyses (i.e. 0CFA) or analyses based on type inference.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> Alexander Aiken and Wimmers, Edward and T.K Lakshman. </author> <title> Soft Typing with Conditional Types. </title> <booktitle> In 21 th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 163-173, </pages> <year> 1994. </year>
Reference-contexts: Soft typing is a less restrictive alternative. Soft typing is a generalization of static type checking that accommodates both dynamic typing and static typing in one framework. A soft type checker infers types for identifiers and inserts run-time checks to transform untypable programs to typable form. Aiken et al. <ref> [1] </ref> describe a more sophisticated soft type system for a functional language. This system uses conditional types in a more powerful type language that should yield more a precise analysis 15 than the soft type system mentioned above, but no implementation is available for a realistic programming language.
Reference: 2. <author> Henk Barendregt. </author> <title> The Lambda Calculus. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1981. </year>
Reference-contexts: Constants include simple values like 0; 1; true, and false. Free variables (F V ) and 4 bound variables (BV ) are defined as usual <ref> [2] </ref>, except that a subscripted vari-able x l [l 0 ] must be bound by a let-expression with label l 0 , and an unsubscripted variable x l must be bound by a -expression. A program e l 0 0 is an expression with no free variables.
Reference: 3. <editor> William Clinger and Jonathan Rees, editors. </editor> <title> Revised 4 Report on the Algorithmic Language Scheme. </title> <journal> ACM Lisp Pointers, </journal> <volume> 4(3), </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: 1 Introduction Advanced programming languages such as Scheme <ref> [3] </ref> and ML [14] encourage a programming style that makes extensive use of data and procedural abstraction. Higher degrees of abstraction generally entail higher run-time overheads; hence, sophisticated compiler optimizations are essential if programs written in these languages are to compete with those written in lower-level languages such as C. <p> To investigate its effectiveness, we have implemented the analysis for Scheme. The implementation handles all of the constructs and operators specified in the R 4 RS report <ref> [3] </ref>, including variable-arity procedures, data structures, first-class continuations, and assignment. We use the analysis to avoid unnecessary run-time type checks at primitive operations.
Reference: 4. <author> Kent Dybvig. </author> <title> The Scheme Programming Language. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1987. </year>
Reference-contexts: These environments bind the variable upon which the type predicate test is performed to different abstract values consistent with the predicate check. (This environment splitting is not reflected in Fig. 1.) 5 Performance Our implementation runs on top of Chez <ref> [4] </ref>, a commercially available implementation of Scheme. At optimize-level 3, Chez eliminates almost all run-time checks, making no safety guarantees.
Reference: 5. <author> Marc Feeley, Marc Turcotte, and Guy Lapalme. </author> <title> Using MultiLisp for Solving Constraint Satistfaction Problems: An Application to Nucleic Acid 3D Structure Determination. </title> <journal> Lisp and Symbolic Computation, </journal> 7(2/3):231-248, 1994. 
Reference-contexts: Dynamic is an implementation of a tagging optimization algorithm [9] for Scheme. Nucleic is a constraint satisfaction algorithm used to determine the three-dimensional structure of nucleic acids <ref> [5] </ref>. It is floating-point intensive and uses an object package implemented using macros and vectors. Nucleic2 is a modified version of Nucleic described below. For several of the benchmarks, the analysis time required by soft typing is less than the time required for either form of flow analysis.
Reference: 6. <author> Leslie Greengard. </author> <title> The Rapid Evaluation of Potential Fields in Particle Systems. </title> <publisher> ACM Press, </publisher> <year> 1987. </year>
Reference-contexts: Graphs counts the number of directed graphs with a distinguished root and k vertices, each having out-degree at most 2. This program makes extensive use of mutation and vectors. Boyer is a term-rewriting theorem prover that allocates heavily. N-Body is a Scheme implementation [24] of the Green-gard multipole algorithm <ref> [6] </ref> for computing gravitational forces on point-masses 11 Benchmark Lines Sites Analysis Time (in seconds) Polymorphic Soft Typing 0CFA 1CFA Splitting Lattice 215 252 .26 .46 .13 .49 Browse 233 283 .21 .96 .18 .50 Check 278 376 1.94 1.76 12.42 10.97 Graphs 621 413 .30 .73 .22 1.10 Boyer 632
Reference: 7. <author> Christopher Haynes. Infer: </author> <title> A Statically-typed Dialect of Scheme. Preliminary Tutorial and Documentaion. </title> <type> Technical report, </type> <institution> Indiana University, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: While the analysis can reduce tagging overheads in many Scheme programs, it does not consider polymorphism or union types, and uses a coarse type approximation that is significantly more imprecise than control-flow analysis via polymorphic splitting. Soft typing [23] and Infer <ref> [7] </ref> are two other type systems implemented for Scheme that employ traditional type inference techniques to derive type information which can be then used to eliminate or obviate run-time checks. Infer is a statically typed polymorphic dialect of Scheme.
Reference: 8. <author> Nevin Heintze. </author> <title> Set-Based Analysis of ML Programs. </title> <booktitle> In Proceedings of the ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 306-317, </pages> <year> 1994. </year>
Reference-contexts: Many analyses with different cost and accuracy characteristics are possible, and the right combination is not readily apparent for a given optimization. For example, consider the following Scheme expression: (let ((f (lambda (x) x))) (f 1)) Simple control-flow analyses [21] or set-based analyses <ref> [8] </ref> determine that the application of f to 1 produces 1 as the result. These simple low-order polynomial-time analyses effectively determine all potential call sites for all procedures, but merge the values of arguments from all call sites. <p> Besides type inference and abstract interpretation, there has been recent work on using constraint systems <ref> [8, 16] </ref> to analyze high-level programs. These systems are based on an operational semantics that ignores all inter-variable dependencies. Consequently, while efficient implementations of these analyses can be built, it is unclear whether they provide the necessary precision to perform useful run-time check optimizations. <p> These systems are based on an operational semantics that ignores all inter-variable dependencies. Consequently, while efficient implementations of these analyses can be built, it is unclear whether they provide the necessary precision to perform useful run-time check optimizations. Refinements on these approaches that take into account polymorphism are possible <ref> [8] </ref>, but are ad hoc and do not fit neatly within the constraint framework. We conclude that flow analysis offers the possibility of distilling more precise information useful for run-time check elimination than unification-based type inference procedures.
Reference: 9. <author> Fritz Henglein. </author> <title> Global Tagging Optimization by Type Inference. </title> <booktitle> In Proceedings of the ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 205-215, </pages> <year> 1992. </year> <month> 16 </month>
Reference-contexts: Benchmark programs, their size (in lines of code), static incidences of run-time checks for these programs in the absence of any run-time check optimization, and analysis times under polymorphic splitting, soft typing, 0CFA, and 1CFA. distributed uniformly in a cube. Dynamic is an implementation of a tagging optimization algorithm <ref> [9] </ref> for Scheme. Nucleic is a constraint satisfaction algorithm used to determine the three-dimensional structure of nucleic acids [5]. It is floating-point intensive and uses an object package implemented using macros and vectors. Nucleic2 is a modified version of Nucleic described below. <p> Because this framework relies on call-string abstractions, and did not study the possibility of exploiting polymor-phism, its success was limited. Moreover, since no attempt was made to implement the interpretation for the entire Scheme language, making a quantified assessment of its utility is difficult. Henglein <ref> [9] </ref> describes a tagging optimization based on type inference. While the analysis can reduce tagging overheads in many Scheme programs, it does not consider polymorphism or union types, and uses a coarse type approximation that is significantly more imprecise than control-flow analysis via polymorphic splitting.
Reference: 10. <author> R. Hindley. </author> <title> The Principal Type-Scheme of an Object in Combinatory Logic. </title> <journal> Transactions of the American Mathematical Society, </journal> <volume> 146 </volume> <pages> 29-60, </pages> <month> December </month> <year> 1969. </year>
Reference-contexts: Nucleic2 is a modified version of Nucleic described below. For several of the benchmarks, the analysis time required by soft typing is less than the time required for either form of flow analysis. Because soft typing is based on a Hindley-Milner type inference framework <ref> [10, 13] </ref>, the body of a -expression is evaluated only once. Applications unify the type signature for a procedure's arguments with the type inferred for the formal, and thus do not require re-analysis of the procedure body.
Reference: 11. <author> Suresh Jagannathan and Stephen Weeks. </author> <title> A Unified Treatment of Flow Analysis in Higher-Order Languages. </title> <booktitle> In 22 th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 392-401, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: All rights reserved. We present a flow analysis framework for a call-by-value, higher-order lan-guage. The framework is parameterized over different approximations of exact values to abstract values, and hence can be used to construct a spectrum of analyses with different cost and accuracy characteristics <ref> [11, 21] </ref>. In particular, we study a novel approximation technique called polymorphic splitting that uses let-expressions as syntactic clues to gain precision. Polymorphic splitting borrows ideas from Hindley-Milner polymorphic type inference systems to create an analog to polymorphism for flow analysis. <p> A similar strictness constraint is introduced to cutoff evaluation of the function body if the abstract value of the argument position is unspecified. This strictness constraint corresponds to a reachability assertion <ref> [11] </ref>, and significantly reduces the number of abstract values generated by the analysis. 3.1 Polymorphic Splitting The last two rules of Fig. 1 for let-expressions and let-bound variables are the only rules that introduce new contours. <p> Run-time check elimination is one such example that is relevant in the context of languages such as Scheme or ML. Although the flow analysis problem has been well-studied [12], and although parameterizable systems have been investigated elsewhere <ref> [11, 21] </ref>, the applicability of such frameworks for optimizing realistic programs has enjoyed relatively little examination. When viewed in the context of run-time check elimination, flow analysis bears an interesting relationship to type inference [18].
Reference: 12. <author> Neil Jones and Stephen Muchnick. </author> <title> Flow Analysis and Optimization of Lisp-like Structures. </title> <booktitle> In 6 th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 244-256, </pages> <month> January </month> <year> 1979. </year>
Reference-contexts: Run-time check elimination is one such example that is relevant in the context of languages such as Scheme or ML. Although the flow analysis problem has been well-studied <ref> [12] </ref>, and although parameterizable systems have been investigated elsewhere [11, 21], the applicability of such frameworks for optimizing realistic programs has enjoyed relatively little examination. When viewed in the context of run-time check elimination, flow analysis bears an interesting relationship to type inference [18].
Reference: 13. <author> Robin Milner. </author> <title> A Theory of Type Polymorphism in Programming. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 17 </volume> <pages> 348-375, </pages> <year> 1978. </year>
Reference-contexts: Correctly disambiguating the two calls to (lambda (x) x) made via the two calls to g requires a 2CFA analysis that preserves two levels of call history. In contrast, polymorphic type inference algorithms <ref> [13, 23] </ref> correctly infer the proper type for f without requiring such tuning. Polymorphic type systems disambiguate different calls to a polymorphic procedure by effectively duplicating the procedure wherever it is referenced. <p> Nucleic2 is a modified version of Nucleic described below. For several of the benchmarks, the analysis time required by soft typing is less than the time required for either form of flow analysis. Because soft typing is based on a Hindley-Milner type inference framework <ref> [10, 13] </ref>, the body of a -expression is evaluated only once. Applications unify the type signature for a procedure's arguments with the type inferred for the formal, and thus do not require re-analysis of the procedure body.
Reference: 14. <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: 1 Introduction Advanced programming languages such as Scheme [3] and ML <ref> [14] </ref> encourage a programming style that makes extensive use of data and procedural abstraction. Higher degrees of abstraction generally entail higher run-time overheads; hence, sophisticated compiler optimizations are essential if programs written in these languages are to compete with those written in lower-level languages such as C.
Reference: 15. <author> John Mitchell. </author> <booktitle> Handbook of Theoretical Computer Science: Volume B, chapter Type Systems for Programming Languages, </booktitle> <pages> pages 367-453. </pages> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The abstract values of these bindings are not merged with abstract values associated with bindings of other applications of f in the let-body. It is well-known that quantification rules for type variables can be discarded in favor of a substitution rule on polymorphic variables <ref> [15] </ref>. Polymorphic splitting captures the essence of polymorphism by incorporating this observation into a flow-analysis framework. Like polymorphic type inference, polymorphic splitting relies only on lexical structure and is independent of dynamic contexts. In the above example, there are four distinct occurrences of let-bound variables in the let-body.
Reference: 16. <author> Jens Palsberg. </author> <title> Global Program Analysis in Constraint Form. </title> <booktitle> In Proceedings of the 1994 Colloquium on Trees in Algebra and Programming, </booktitle> <pages> pages 276-290. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year> <note> Appears as LNCS 787. </note>
Reference-contexts: Besides type inference and abstract interpretation, there has been recent work on using constraint systems <ref> [8, 16] </ref> to analyze high-level programs. These systems are based on an operational semantics that ignores all inter-variable dependencies. Consequently, while efficient implementations of these analyses can be built, it is unclear whether they provide the necessary precision to perform useful run-time check optimizations.
Reference: 17. <author> Jens Palsberg and Patrick O'Keefe. </author> <title> A Type System Equivalent to Flow Analysis. </title> <booktitle> In 22 th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 367-378, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: Since there are now two separate bindings for x corresponding to the two arguments passed to f , this analysis yields a more precise result. 3.2 Comparison to Type Inference For several important idioms, polymorphic-splitting results in finer precision than Hindley-Milner typing or safety analysis <ref> [17] </ref> as embodied by a 0CFA analysis.
Reference: 18. <author> Jens Palsberg and Michael Schwartzbach. </author> <title> Safety Analysis versus Type Inference. </title> <journal> Information and Computation, </journal> <note> to appear. </note>
Reference-contexts: When viewed in the context of run-time check elimination, flow analysis bears an interesting relationship to type inference <ref> [18] </ref>. However, there has been little work on extending the relation to polymorphism or to understand its implications on implementations. One important kind of run-time check optimization is elimination of type tags [22]. Shivers [20] used the term type recovery to describe a type-tag elimination optimization based on flow analysis.
Reference: 19. <author> Gordon D. Plotkin. </author> <title> Call-by-name, call-by-value and the lambda-calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 125-159, </pages> <year> 1975. </year>
Reference-contexts: We require every subexpression of a program to have a unique label, and occasionally omit labels from expressions to avoid clutter. The exact semantics for this language is an ordinary call-by-value semantics <ref> [19] </ref>. Recursive procedures can be constructed with the call-by-value Y combinator. Our analysis yields sets of abstract values.
Reference: 20. <author> Olin Shivers. </author> <title> Data-flow Analysis and Type Recovery in Scheme. </title> <booktitle> In Topics in Advanced Language Implementation. </booktitle> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Experimental results for realistic Scheme programs indicate that polymorphic splitting is extremely precise and has reasonable cost. The analysis eliminates significantly more run-time checks than comparable simple analyses (e.g. 0CFA <ref> [20] </ref>) or type-inference based techniques (e.g. soft typing [23]). While the computational cost of our analysis appears to be higher than that of type-inference based methods, analysis times are still within reason for including the analysis in an optimizing compiler. <p> However, there has been little work on extending the relation to polymorphism or to understand its implications on implementations. One important kind of run-time check optimization is elimination of type tags [22]. Shivers <ref> [20] </ref> used the term type recovery to describe a type-tag elimination optimization based on flow analysis. Because this framework relies on call-string abstractions, and did not study the possibility of exploiting polymor-phism, its success was limited.
Reference: 21. <author> Olin Shivers. </author> <title> Control-Flow Analysis of Higher-Order Languages or Taming Lambda. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie-Mellon University, </institution> <year> 1991. </year>
Reference-contexts: All rights reserved. We present a flow analysis framework for a call-by-value, higher-order lan-guage. The framework is parameterized over different approximations of exact values to abstract values, and hence can be used to construct a spectrum of analyses with different cost and accuracy characteristics <ref> [11, 21] </ref>. In particular, we study a novel approximation technique called polymorphic splitting that uses let-expressions as syntactic clues to gain precision. Polymorphic splitting borrows ideas from Hindley-Milner polymorphic type inference systems to create an analog to polymorphism for flow analysis. <p> Many analyses with different cost and accuracy characteristics are possible, and the right combination is not readily apparent for a given optimization. For example, consider the following Scheme expression: (let ((f (lambda (x) x))) (f 1)) Simple control-flow analyses <ref> [21] </ref> or set-based analyses [8] determine that the application of f to 1 produces 1 as the result. These simple low-order polynomial-time analyses effectively determine all potential call sites for all procedures, but merge the values of arguments from all call sites. <p> Consequently, any application of f in this framework yields f1,#tg as its result. Run-time check optimizations based on these analyses are unable to eliminate the unnecessary run-time check at the addition operation. A more sophisticated analysis <ref> [21] </ref> avoids merging information in syntactically distinct calls to the same procedure by treating the call site at which the procedure is applied as a disambiguation context; this analysis is referred to as 1CFA. <p> Run-time check elimination is one such example that is relevant in the context of languages such as Scheme or ML. Although the flow analysis problem has been well-studied [12], and although parameterizable systems have been investigated elsewhere <ref> [11, 21] </ref>, the applicability of such frameworks for optimizing realistic programs has enjoyed relatively little examination. When viewed in the context of run-time check elimination, flow analysis bears an interesting relationship to type inference [18].
Reference: 22. <author> Peter Steenkiste and John Hennessy. </author> <title> Tags and type checking in lisp. </title> <booktitle> In Proceedings of the Second Architectural Support for Programming Languages and Systems Symposium, </booktitle> <pages> pages 50-59, </pages> <year> 1987. </year>
Reference-contexts: However, there has been little work on extending the relation to polymorphism or to understand its implications on implementations. One important kind of run-time check optimization is elimination of type tags <ref> [22] </ref>. Shivers [20] used the term type recovery to describe a type-tag elimination optimization based on flow analysis. Because this framework relies on call-string abstractions, and did not study the possibility of exploiting polymor-phism, its success was limited.
Reference: 23. <author> Andrew Wright and Robert Cartwright. </author> <title> A Practical Soft Type System for Scheme. </title> <booktitle> In Proceedings of the ACM Symposium on Lisp and Functional Programming, </booktitle> <pages> pages 250-262, </pages> <year> 1994. </year>
Reference-contexts: Experimental results for realistic Scheme programs indicate that polymorphic splitting is extremely precise and has reasonable cost. The analysis eliminates significantly more run-time checks than comparable simple analyses (e.g. 0CFA [20]) or type-inference based techniques (e.g. soft typing <ref> [23] </ref>). While the computational cost of our analysis appears to be higher than that of type-inference based methods, analysis times are still within reason for including the analysis in an optimizing compiler. Furthermore, and perhaps surprisingly, our polymorphic splitting analysis is often faster than coarse analysis such as 0CFA. <p> Correctly disambiguating the two calls to (lambda (x) x) made via the two calls to g requires a 2CFA analysis that preserves two levels of call history. In contrast, polymorphic type inference algorithms <ref> [13, 23] </ref> correctly infer the proper type for f without requiring such tuning. Polymorphic type systems disambiguate different calls to a polymorphic procedure by effectively duplicating the procedure wherever it is referenced. <p> Data Structures. Elements of Scheme data structures can be mutated. The analysis tracks such assignments by recording them in the program point 10 that holds the value of the corresponding sub-expression. Unlike other static type systems proposed for Scheme <ref> [23] </ref>, assigning to data structures causes no loss in precision. Assigning to a field in a pair, for example, simply augments the abstract value set for that field. 2. Implicit Allocation. Certain Scheme constructs implicitly allocate storage. <p> Fig. 4 lists the benchmarks used to test the analysis, their size in number of lines of code, the number of sites where run-time checks would ordinarily be required in the absence of any optimizations, and the time to analyze them under polymorphic splitting, soft typing <ref> [23] </ref>, a 0CFA implementation, and a 1CFA implementation. The times were gathered on a 150 MHz MIPS R4400 with 1 GByte of memory. The program Lattice enumerates the lattice of maps between two lattices, and is purely functional. Browse is a database searching program that allocates extensively. <p> In many cases, the difference is significant. Interestingly, 0CFA also outperforms soft typing on several benchmarks. For example, the Lattice program has roughly half as many static checks when analyzed using 0CFA than using soft typing. The primary reason for this is the problem of reverse flow <ref> [23] </ref> in the soft-typing framework that leads to imprecise typing. Reverse flow refers to type information that flows both with and counter to the direction of value flow. Conditionals often cause reverse flow because the type rules for a conditional require both its branches to have the same type. <p> Henglein [9] describes a tagging optimization based on type inference. While the analysis can reduce tagging overheads in many Scheme programs, it does not consider polymorphism or union types, and uses a coarse type approximation that is significantly more imprecise than control-flow analysis via polymorphic splitting. Soft typing <ref> [23] </ref> and Infer [7] are two other type systems implemented for Scheme that employ traditional type inference techniques to derive type information which can be then used to eliminate or obviate run-time checks. Infer is a statically typed polymorphic dialect of Scheme.
Reference: 24. <author> Feng Zhao. </author> <title> An O(N ) Algorithm for Three-Dimensional N-Body Simulations. </title> <type> Master's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Mas-sachusetts Institute of Technology, </institution> <year> 1987. </year> <month> 17 </month>
Reference-contexts: Graphs counts the number of directed graphs with a distinguished root and k vertices, each having out-degree at most 2. This program makes extensive use of mutation and vectors. Boyer is a term-rewriting theorem prover that allocates heavily. N-Body is a Scheme implementation <ref> [24] </ref> of the Green-gard multipole algorithm [6] for computing gravitational forces on point-masses 11 Benchmark Lines Sites Analysis Time (in seconds) Polymorphic Soft Typing 0CFA 1CFA Splitting Lattice 215 252 .26 .46 .13 .49 Browse 233 283 .21 .96 .18 .50 Check 278 376 1.94 1.76 12.42 10.97 Graphs 621 413
References-found: 24

