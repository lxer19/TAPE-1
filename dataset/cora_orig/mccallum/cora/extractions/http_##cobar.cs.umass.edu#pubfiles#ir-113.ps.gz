URL: http://cobar.cs.umass.edu/pubfiles/ir-113.ps.gz
Refering-URL: http://cobar.cs.umass.edu/pubfiles/
Root-URL: 
Email: cahoon-@cs.umass.edu  
Title: A Performance Evaluation of Parallel Information Retrieval on Symmetrical Multiprocessors  
Author: Zhihong Lu Kathryn S. McKinley Brendon Cahoon -zlu, mckinley, 
Address: Amherst, MA 01003  
Affiliation: Department of Computer Science University of Massachusetts  
Abstract: Providing timely access to text collections both locally and across the Internet is instrumental in making information retrieval (IR) truly useful. In this paper, we investigate how to exploit a symmetrical multiprocessor architecture to build high performance IR servers. We start by implementing a multithreaded IR server and a multitasking IR server to investigate that how best to execute multiple IR commands in parallel. We use InQuery, an inference network, full-text IR retrieval engine, to provide the basic IR services [5, 6, 20]. To expedite our investigation of possible system configurations, characteristics of IR collections, and the basic IR system performance, we implement a simulator with numerous system parameters, such as the number of CPUs, threads, disks, collection size, and query characteristics. We then validate the simulator against our implementation. By using multiple threads, CPUs, and disks, we demonstrate scalable performance for a variety of system configurations. We also find bottlenecks where additional threads, CPUs, and disks either degrade or have no impact on performance. Our results suggest that information retrieval is easily parallelized, but because it performs significant amounts of both I/O and CPU processing, to produce scalable performance requires a careful balance of hardware resources. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Bailey and D. Hawking. </author> <title> A parallel architecture for query processing over a terabyte of text. </title> <type> Technical Report TR-CS-96-04, </type> <institution> The Australian National University, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. The previous work either investigates the IR system on massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref> or it investigates only a subset of the system on SMP architecture such as the disk system [14] or it compare the cost factors of SMP architecture with other architectures [8]. (Section 4 compares our work to previous research on parallel information retrieval in <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [8]. <p> Bailey and Hwaking report their IR system on Fujitsu AP1000, which is a 128-node distributed-memory multicomputers and each node has a 25 MHZ CPU and 16 MB memory <ref> [1] </ref>. Cringean et al. and Efraimidis et al. implement their IR systems on a transputer network, which belongs to the MIMD class of parallel computers [9, 11].
Reference: [2] <author> E.W. Brown, J.P Callan, W.B. Croft, and J.E.B. Moss. </author> <title> Supporting full-text information retrieval with a persistent object store. </title> <booktitle> In Proceedings of the 4th International Conference on Extending Database Technology (EDBT), </booktitle> <pages> pages 363-378, </pages> <address> Cambridge, UK, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: An inverted file contains term keys, their corresponding lists of documents, and frequency and position information in the original document files. Either a custom B* tree package with concurrency control or the Mneme persistent object store <ref> [2] </ref> manages the inverted files. The indexing overhead for a collection of documents is 30% to 40% of its original data size. For example, a 1.2 GB Tipster 1 collection [5] needs 0.5 GB extra disk space to store indexes. InQuery accepts both natural language and structured queries.
Reference: [3] <author> B. Cahoon and K. S. McKinley. </author> <title> Performance evaluation of a distributed architecture for information retrieval. </title> <booktitle> In Proceedings of the Nineteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 110-118, </pages> <address> Zurich, Switzerland, </address> <month> August </month> <year> 1996. </year>
Reference-contexts: A summary response includes the document titles and the first few sentences of the documents. A document command requests a document using its document identifier. The response includes the complete text of the document. 2.1.2 Simulation Model We use a simulation model we previously built for InQuery work <ref> [3, 4] </ref>. Because we use a more recent version of InQuery on a DEC AlphaServer 2100 5/250 clocked at 250 MHz instead of an MIPS R3000 clocked at 40 MHz, we validated query response time of our simulator again. <p> The parallel IR servers exploits parallelism as follows: (1) It executes multiple IR commands in parallel, by either multitasking or multithreading; or (2) It executes one command against multiple partitions of a collection in parallel. 2.2.1 Multithreading vs. Multitasking Since we already have distributed servers <ref> [3, 4] </ref> where each server is single-thread process built on a uniprocessor machine, we implemented a parallel server via multitasking. This version simply executes a light-weight broker and multiple executables of the single-thread server on the same machine, communicating by message passing [3, 4]. <p> Multitasking Since we already have distributed servers <ref> [3, 4] </ref> where each server is single-thread process built on a uniprocessor machine, we implemented a parallel server via multitasking. This version simply executes a light-weight broker and multiple executables of the single-thread server on the same machine, communicating by message passing [3, 4]. Another natural implementation of the parallel InQuery server is to use a thread package to build a shared-everything version, i.e., a multithreaded version. We use the POSIX thread package [16].
Reference: [4] <author> B. Cahoon and K. S. McKinley. </author> <title> Evaluating the performance of distributed architectures for information retrieval using a variety of workloads. </title> <note> Submitted for publication, </note> <year> 1997. </year>
Reference-contexts: A summary response includes the document titles and the first few sentences of the documents. A document command requests a document using its document identifier. The response includes the complete text of the document. 2.1.2 Simulation Model We use a simulation model we previously built for InQuery work <ref> [3, 4] </ref>. Because we use a more recent version of InQuery on a DEC AlphaServer 2100 5/250 clocked at 250 MHz instead of an MIPS R3000 clocked at 40 MHz, we validated query response time of our simulator again. <p> The parallel IR servers exploits parallelism as follows: (1) It executes multiple IR commands in parallel, by either multitasking or multithreading; or (2) It executes one command against multiple partitions of a collection in parallel. 2.2.1 Multithreading vs. Multitasking Since we already have distributed servers <ref> [3, 4] </ref> where each server is single-thread process built on a uniprocessor machine, we implemented a parallel server via multitasking. This version simply executes a light-weight broker and multiple executables of the single-thread server on the same machine, communicating by message passing [3, 4]. <p> Multitasking Since we already have distributed servers <ref> [3, 4] </ref> where each server is single-thread process built on a uniprocessor machine, we implemented a parallel server via multitasking. This version simply executes a light-weight broker and multiple executables of the single-thread server on the same machine, communicating by message passing [3, 4]. Another natural implementation of the parallel InQuery server is to use a thread package to build a shared-everything version, i.e., a multithreaded version. We use the POSIX thread package [16].
Reference: [5] <author> J. P. Callan, W. B. Croft, and J. Broglio. </author> <title> TREC and TIPSTER experiments with INQUERY. </title> <booktitle> Information Processing & Management, </booktitle> <volume> 31(3) </volume> <pages> 327-343, </pages> <month> May/June </month> <year> 1995. </year>
Reference-contexts: We also investigate the performance effects of partitioning a single collection across multiple disks. We find bottlenecks and in many instances, show scalable performance for small numbers of processors. Our IR server is based on InQuery, a full-text inference network based information retrieval engine <ref> [5, 6, 20] </ref>. Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. <p> Section 4 compares this work to previous work, and Section 5 summarizes our results and concludes. 2 A Parallel Information Retrieval Server This section describes the implementation of our parallel IR server, and simulator. We begin with a brief description of the InQuery retrieval engine <ref> [5, 6, 13] </ref>, the features we model, and a validation of our simulation of this basic functionality. <p> It uses an inference network model, which applies Bayesian inference networks to represent documents and queries, and views information retrieval as an inference or evidential reasoning process <ref> [5, 6, 20] </ref>. <p> Either a custom B* tree package with concurrency control or the Mneme persistent object store [2] manages the inverted files. The indexing overhead for a collection of documents is 30% to 40% of its original data size. For example, a 1.2 GB Tipster 1 collection <ref> [5] </ref> needs 0.5 GB extra disk space to store indexes. InQuery accepts both natural language and structured queries. The InQuery server supports a wide range of IR commands, such as query, document, and relevance feedback. The three basic IR commands are query, summary and document commands. <p> short queries [10], we experiment with a query set that consists of 1000 short queries, with an average length of 2 that mimic those found in the 103rd Congressional Record query sets [10], and use an observed query term frequency distribution obtained from their distribution in the Tipster query sets <ref> [5] </ref>. We vary the arrival rate and the size of collection in order to examine the scalability of the server as the number of clients and the size of the collection increases.
Reference: [6] <author> J. P. Callan, W. B. Croft, and S. M. Harding. </author> <title> The INQUERY retrieval system. </title> <booktitle> In Proceedings of the 3rd International Conference on Database and Expert System Applications, </booktitle> <address> Valencia, Spain, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: We also investigate the performance effects of partitioning a single collection across multiple disks. We find bottlenecks and in many instances, show scalable performance for small numbers of processors. Our IR server is based on InQuery, a full-text inference network based information retrieval engine <ref> [5, 6, 20] </ref>. Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. <p> Section 4 compares this work to previous work, and Section 5 summarizes our results and concludes. 2 A Parallel Information Retrieval Server This section describes the implementation of our parallel IR server, and simulator. We begin with a brief description of the InQuery retrieval engine <ref> [5, 6, 13] </ref>, the features we model, and a validation of our simulation of this basic functionality. <p> It uses an inference network model, which applies Bayesian inference networks to represent documents and queries, and views information retrieval as an inference or evidential reasoning process <ref> [5, 6, 20] </ref>.
Reference: [7] <author> J. P. Callan, Z. Lu, and W. B. Croft. </author> <title> Searching distributed collections with inference networks. </title> <booktitle> In Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Seattle, WA, </address> <month> July </month> <year> 1995. </year>
Reference: [8] <author> T. R. Couvreur, R. N. Benzel, S. F. Miller, D. N. Zeitler, D. L. Lee, M. Singhai, N. Shivaratri, and W. Y. P. Wong. </author> <title> An analysis of performance and cost factors in searching large text databases using parallel search systems. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 7(45) </volume> <pages> 443-464, </pages> <year> 1994. </year>
Reference-contexts: previous work either investigates the IR system on massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19] or it investigates only a subset of the system on SMP architecture such as the disk system [14] or it compare the cost factors of SMP architecture with other architectures <ref> [8] </ref>. (Section 4 compares our work to previous research on parallel information retrieval in more detail.) We started by building a parallel IR server for an SMP architecture, where all CPUs, disks, and memory are shared and communicate on a shared bus (see Figure 1). <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine <ref> [8] </ref>. They use different search algorithms on different hardware architectures. The experiments using a mainframe are most related to our work. They measure the response time under different query arrival rates and identify the query arrival rate the system can support within 30-40 seconds.
Reference: [9] <author> J. K. Cringean, R. England, G. A. Mason, and P. Willett. </author> <title> Parallel text searching in serial files using a processor farm. </title> <booktitle> In Proceedings of the Thirteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Brussels, Belgium, </address> <month> September </month> <year> 1990. </year>
Reference-contexts: Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. The previous work either investigates the IR system on massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref> or it investigates only a subset of the system on SMP architecture such as the disk system [14] or it compare the cost factors of SMP architecture with other architectures [8]. (Section 4 compares our work to previous research on parallel information retrieval in <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [8]. <p> Cringean et al. and Efraimidis et al. implement their IR systems on a transputer network, which belongs to the MIMD class of parallel computers <ref> [9, 11] </ref>. Our work uses a SMP and investigates the system performance when processing multiple queries. 5 Conclusion In this paper, we investigate building a parallel information retrieval server using a symmetrical multiprocessors to improve the system performance.
Reference: [10] <author> W. B. Croft, R. Cook, and D. Wilder. </author> <title> Providing government information on the internet: Experiences with THOMAS. </title> <booktitle> In The Second International Conference on the Theory and Practice of Digital Libraries, </booktitle> <address> Austin, TX, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: We assume the client arrival rate as a Poisson process. Each client issues a query and waits for response. For each query, the server performs two operations: query evaluation and retrieving the corresponding summaries. Since users typically enter short queries <ref> [10] </ref>, we experiment with a query set that consists of 1000 short queries, with an average length of 2 that mimic those found in the 103rd Congressional Record query sets [10], and use an observed query term frequency distribution obtained from their distribution in the Tipster query sets [5]. <p> Since users typically enter short queries <ref> [10] </ref>, we experiment with a query set that consists of 1000 short queries, with an average length of 2 that mimic those found in the 103rd Congressional Record query sets [10], and use an observed query term frequency distribution obtained from their distribution in the Tipster query sets [5]. We vary the arrival rate and the size of collection in order to examine the scalability of the server as the number of clients and the size of the collection increases.
Reference: [11] <author> P. Efraimidis, C. Glymidakis, B. Mamalis, P. Spirakis, and B. Tampakas. </author> <title> Parallel text retrieval on a high performance supercomputer using the vector space model. </title> <booktitle> In Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 58-66, </pages> <address> Seattle, WA, </address> <year> 1995. </year>
Reference-contexts: Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. The previous work either investigates the IR system on massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref> or it investigates only a subset of the system on SMP architecture such as the disk system [14] or it compare the cost factors of SMP architecture with other architectures [8]. (Section 4 compares our work to previous research on parallel information retrieval in <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [8]. <p> Cringean et al. and Efraimidis et al. implement their IR systems on a transputer network, which belongs to the MIMD class of parallel computers <ref> [9, 11] </ref>. Our work uses a SMP and investigates the system performance when processing multiple queries. 5 Conclusion In this paper, we investigate building a parallel information retrieval server using a symmetrical multiprocessors to improve the system performance.
Reference: [12] <editor> D. Harman, editor. </editor> <booktitle> The First Text REtrieval Conference (TREC-1). National Institute of Standards and Technology Special Publication 200-217, </booktitle> <address> Gaithersburg, MD, </address> <year> 1992. </year>
Reference: [13] <author> InQuery. </author> <title> An information engine for the u.s. economy. </title> <address> http://ciir.cs.umass.edu/info/highlights.html. </address>
Reference-contexts: Section 4 compares this work to previous work, and Section 5 summarizes our results and concludes. 2 A Parallel Information Retrieval Server This section describes the implementation of our parallel IR server, and simulator. We begin with a brief description of the InQuery retrieval engine <ref> [5, 6, 13] </ref>, the features we model, and a validation of our simulation of this basic functionality. <p> We then describe the multithreaded and multitasking implementations, and validate our simulator against the multithreaded implementation. 4 2.1 InQuery Retrieval Engine 2.1.1 InQuery InQuery is one of the most powerful and advanced full-text information retrieval engines in commercial or government use today <ref> [13] </ref>. It uses an inference network model, which applies Bayesian inference networks to represent documents and queries, and views information retrieval as an inference or evidential reasoning process [5, 6, 20].
Reference: [14] <author> B-S. Jeong and E. Omiecinski. </author> <title> Inverted file partitioning schemes in multiple disk systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 6(2) </volume> <pages> 142-153, </pages> <month> February </month> <year> 1995. </year> <month> 22 </month>
Reference-contexts: The previous work either investigates the IR system on massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19] or it investigates only a subset of the system on SMP architecture such as the disk system <ref> [14] </ref> or it compare the cost factors of SMP architecture with other architectures [8]. (Section 4 compares our work to previous research on parallel information retrieval in more detail.) We started by building a parallel IR server for an SMP architecture, where all CPUs, disks, and memory are shared and communicate <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Our contribution is that we focus on a single system and analyze how different parameters affect the system performance. Besides measuring response time, we also measure the system utilization and identify bottlenecks. Jeong and Omiecinski investigate two inverted file partitioning schemes in a shared-everything multiprocessor system <ref> [14] </ref>. One scheme partitions the posting file by term identifiers while the other scheme 19 partitions the posting file by document identifiers. They focus on the effect of adding disks on system per-formance. They show that response time decreases as the number of disks increases up to some threshold.
Reference: [15] <author> B. Mamalis, O. Spirakis, and Tampakas. </author> <title> Parallel techniques for efficient searching over very large text collections. </title> <booktitle> In Proceedings of The Fifth Text REtrieval Conference (TREC-5), </booktitle> <address> Gaithersburg, MD, </address> <year> 1996. </year> <institution> National Institute of Standards and Technology Special Publication. </institution>
Reference-contexts: Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. The previous work either investigates the IR system on massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref> or it investigates only a subset of the system on SMP architecture such as the disk system [14] or it compare the cost factors of SMP architecture with other architectures [8]. (Section 4 compares our work to previous research on parallel information retrieval in <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [8].
Reference: [16] <author> Open Software Foundation. </author> <title> OSF DCE Application Development Guide Core Components, </title> <year> 1994. </year>
Reference-contexts: Another natural implementation of the parallel InQuery server is to use a thread package to build a shared-everything version, i.e., a multithreaded version. We use the POSIX thread package <ref> [16] </ref>. Because threads within a process share the same virtual address space, context switching between threads is less expensive than that between processes. In addition, the cooperating threads communicate by simply accessing synchronized global or static variables; thus, we expect the multithreading to be more efficient than the multitasking.
Reference: [17] <author> C. Stanfill. </author> <title> Partitioned posting files: A parallel inverted file structure for information retrieval. </title> <booktitle> In Proceedings of the Thirteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 413-428, </pages> <address> Brussels, BELGIUM, </address> <year> 1990. </year>
Reference-contexts: Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. The previous work either investigates the IR system on massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref> or it investigates only a subset of the system on SMP architecture such as the disk system [14] or it compare the cost factors of SMP architecture with other architectures [8]. (Section 4 compares our work to previous research on parallel information retrieval in <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [8]. <p> The other related studies use MPPs and focus on how to speed up single query processing. Stanfill et al. implement their IR system on the connection machine (CM), which is a fine-grained, massively parallel distributed-memory SIMD architecture with up to 65,536 processing elements <ref> [17, 18, 19] </ref>. Bailey and Hwaking report their IR system on Fujitsu AP1000, which is a 128-node distributed-memory multicomputers and each node has a 25 MHZ CPU and 16 MB memory [1].
Reference: [18] <author> C. Stanfill and B. Kahle. </author> <title> Parallel free-text search on the connection machine system. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1229-1239, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. The previous work either investigates the IR system on massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref> or it investigates only a subset of the system on SMP architecture such as the disk system [14] or it compare the cost factors of SMP architecture with other architectures [8]. (Section 4 compares our work to previous research on parallel information retrieval in <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [8]. <p> The other related studies use MPPs and focus on how to speed up single query processing. Stanfill et al. implement their IR system on the connection machine (CM), which is a fine-grained, massively parallel distributed-memory SIMD architecture with up to 65,536 processing elements <ref> [17, 18, 19] </ref>. Bailey and Hwaking report their IR system on Fujitsu AP1000, which is a 128-node distributed-memory multicomputers and each node has a 25 MHZ CPU and 16 MB memory [1].
Reference: [19] <author> C. Stanfill, R. Thau, and D. Waltz. </author> <title> A parallel indexed algorithm for information retrieval. </title> <booktitle> In Proceedings of the Twelfth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <pages> pages 88-97, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. The previous work either investigates the IR system on massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref> or it investigates only a subset of the system on SMP architecture such as the disk system [14] or it compare the cost factors of SMP architecture with other architectures [8]. (Section 4 compares our work to previous research on parallel information retrieval in <p> These results suggest that we need to balance hardware resources carefully in order to achieve scalable performance. 4 Related Work There have been a number of papers regarding to using multiprocessor machines for information retrieval <ref> [1, 8, 9, 11, 14, 15, 17, 18, 19] </ref>. Most of them use a distributed memory, massively parallel processing (MPP) architecture [1, 9, 11, 15, 17, 18, 19]. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. <p> Most of them use a distributed memory, massively parallel processing (MPP) architecture <ref> [1, 9, 11, 15, 17, 18, 19] </ref>. Couvreur et al. analyze the tradeoff between performance and cost when searching large text collections. They use simulation models to investigate three different hardware architectures: a mainframe, a collection of RISC processors connected by a network and a special purpose machine [8]. <p> The other related studies use MPPs and focus on how to speed up single query processing. Stanfill et al. implement their IR system on the connection machine (CM), which is a fine-grained, massively parallel distributed-memory SIMD architecture with up to 65,536 processing elements <ref> [17, 18, 19] </ref>. Bailey and Hwaking report their IR system on Fujitsu AP1000, which is a 128-node distributed-memory multicomputers and each node has a 25 MHZ CPU and 16 MB memory [1].
Reference: [20] <author> H. R. </author> <title> Turtle. Inference Networks for Document Retrieval. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: We also investigate the performance effects of partitioning a single collection across multiple disks. We find bottlenecks and in many instances, show scalable performance for small numbers of processors. Our IR server is based on InQuery, a full-text inference network based information retrieval engine <ref> [5, 6, 20] </ref>. Our work is novel because it investigates a real, proven effective system under a variety of realistic workloads and hardware configurations on SMP architecture. <p> It uses an inference network model, which applies Bayesian inference networks to represent documents and queries, and views information retrieval as an inference or evidential reasoning process <ref> [5, 6, 20] </ref>.
Reference: [21] <author> C. L. Viles. </author> <title> Maintaining retrieval effectiveness in distributed, dynamic information retrieval systems. </title> <type> PhD thesis, </type> <institution> University of Virginia, </institution> <month> May </month> <year> 1996. </year>
Reference: [22] <author> E. M. Voorhees, N. K. Gupta, and B. Johnson-Laird. </author> <title> Learning collection fusion strategies. </title> <booktitle> In Proceedings of the Eighteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <address> Seattle, WA, </address> <year> 1995. </year>
References-found: 22

