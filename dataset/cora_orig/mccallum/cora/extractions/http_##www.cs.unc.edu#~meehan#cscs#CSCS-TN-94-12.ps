URL: http://www.cs.unc.edu/~meehan/cscs/CSCS-TN-94-12.ps
Refering-URL: http://www.cs.unc.edu/~meehan/resume/index.html
Root-URL: http://www.cs.unc.edu
Title: Race-Condition Detection in Multicomputer Programs  
Author: John Meehan 
Address: #3175, Sitterson Hall Chapel Hill, NC 27599-3175  
Affiliation: Computer Science Department University of North Carolina CB  
Note: Michael  
Pubnum: SeRD-CSCS TN-94-12  SeRD-CSCS Technical Note  
Email: meehan@cs.unc.edu  
Date: June 1994  
Abstract: In message-passing parallel programs a type of bug unique to parallel computing can occur. This type of error is due to multi-message races. A race occurs when messages are in transit at the same time and the corresponding receives can accept any of the messages. Most of the time, races are incorporated into programs for reasons such as enhancing load balancing. Sometimes a race causes erroneous execution that is hard to debug because of the non-deterministic nature of the program (i.e. if the messages in a race are not received in the same order as during the erroneous execution, the error might not occur). This paper addresses this problem by describing an efficient algorithm for tracing a given program execution and replaying that execution deterministically. The tracing and replaying algorithm will help the user reexecute a nondeterministic program deterministically. This reexecutability will allow a user to gather information on and facilitate removal of all non-deterministic errors. 
Abstract-found: 1
Intro-found: 1
Reference: [CS88] <author> D. Callahan and J. Sublock. </author> <title> Static analysis of low level synchronization. </title> <booktitle> In Proceedings of ACM/ONR Workshop on Parallel and Distributed Debugging, </booktitle> <pages> pages 100-111, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: The last two sections of the paper have timing results and conclusions. Two applications and three race-intensive test programs were tested and the results are discussed. 2 Background 2.1 Related Work There are three basic categories of race detection algorithms: after-the-fact analysis [HW93], compile-time analysis <ref> [CS88] </ref> and on-the-fly analysis [HMC90], [NM92a]. After-the-fact analysis involves tracing all of the messages in a program and checking for races after program execution. Compile-time analysis involves analyzing program semantics to determine potential races. On-the-fly strategies use information produced during execution to determine which message race.
Reference: [HMC90] <author> Kennedy K. Hood, R. and J. Mellor-Crummey. </author> <title> Parallel program debugging with on-the-fly anomaly detection. </title> <booktitle> In Proceedings of Supercomputing '90, </booktitle> <month> November </month> <year> 1990. </year>
Reference-contexts: The last two sections of the paper have timing results and conclusions. Two applications and three race-intensive test programs were tested and the results are discussed. 2 Background 2.1 Related Work There are three basic categories of race detection algorithms: after-the-fact analysis [HW93], compile-time analysis [CS88] and on-the-fly analysis <ref> [HMC90] </ref>, [NM92a]. After-the-fact analysis involves tracing all of the messages in a program and checking for races after program execution. Compile-time analysis involves analyzing program semantics to determine potential races. On-the-fly strategies use information produced during execution to determine which message race.
Reference: [HPF93] <author> HPFF (High Performance Fortran Forum). </author> <title> High Performance Fortran Language Specification: Version 1.0. </title> <journal> Scientific Programming, </journal> <volume> 2(1&2), </volume> <year> 1993. </year> <note> Special Issue. </note>
Reference-contexts: In collaboration with a team of researchers developing an HPF system at C&C Research Labs., NEC Tokyo, the tool environment allows profiling and debugging of "low level" MPI [MPI94] message passing programs, and "high level" High Performance Fortran (HPF) <ref> [HPF93] </ref> programs. In addition, the tools will support extensions to HPF to allow the effective parallelization of irregular finite-element based applications.
Reference: [HW93] <author> McDowell C. Helmbold, D. and J-Z Wang. </author> <title> Determining possible event orders by analyzing sequential traces. </title> <journal> In IEEE journal on Parallel and Distributed Systems, </journal> <note> 1993. 16 SeRD-CSCS TN-94-12 REFERENCES </note>
Reference-contexts: The last two sections of the paper have timing results and conclusions. Two applications and three race-intensive test programs were tested and the results are discussed. 2 Background 2.1 Related Work There are three basic categories of race detection algorithms: after-the-fact analysis <ref> [HW93] </ref>, compile-time analysis [CS88] and on-the-fly analysis [HMC90], [NM92a]. After-the-fact analysis involves tracing all of the messages in a program and checking for races after program execution. Compile-time analysis involves analyzing program semantics to determine potential races. On-the-fly strategies use information produced during execution to determine which message race.
Reference: [MPI94] <author> MPIF (Message Passing Interface Forum). </author> <title> MPI: A Message-Passing Interface Standard. </title> <type> Technical report, </type> <institution> University of Tennessee, Knoxville, TN, USA, </institution> <month> May </month> <year> 1994. </year> <note> Version 1.0. </note>
Reference-contexts: In collaboration with a team of researchers developing an HPF system at C&C Research Labs., NEC Tokyo, the tool environment allows profiling and debugging of "low level" MPI <ref> [MPI94] </ref> message passing programs, and "high level" High Performance Fortran (HPF) [HPF93] programs. In addition, the tools will support extensions to HPF to allow the effective parallelization of irregular finite-element based applications.
Reference: [NM92a] <author> Robert H. B. Netzer and Barton P. Miller. </author> <title> Optimal tracing and replay for debugging message-passing parallel programs. </title> <booktitle> In Proceedings of Supercomputing '92, </booktitle> <pages> pages 502-511, </pages> <address> Minneapolis, MN, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Two applications and three race-intensive test programs were tested and the results are discussed. 2 Background 2.1 Related Work There are three basic categories of race detection algorithms: after-the-fact analysis [HW93], compile-time analysis [CS88] and on-the-fly analysis [HMC90], <ref> [NM92a] </ref>. After-the-fact analysis involves tracing all of the messages in a program and checking for races after program execution. Compile-time analysis involves analyzing program semantics to determine potential races. On-the-fly strategies use information produced during execution to determine which message race. <p> Compile-time analysis involves analyzing program semantics to determine potential races. On-the-fly strategies use information produced during execution to determine which message race. The algorithm in this paper is an on-the-fly algorithm based loosely on Netzer and Miller's <ref> [NM92a] </ref> algorithm. Their algorithm uses vector timestamps appended to messages to determine where races occur. The major difference between the Netzer algorithm and the one described here is the FIFO assumption. <p> I will compare Miller and Netzer's <ref> [NM92a] </ref> frontier tracing and the tradition algorithm of tracing all messages with my own method. The first example will show that tracing all messages is sufficient to replay a race condition deterministically but is not necessary. <p> Since Msg2.2 knew of Msg0.1 there is no race and no information is stored. It can be easily seen that Msg0.1 and Msg2.1 do race since the second does not know of the first. As pointed out by Miller and Netzer <ref> [NM92a] </ref> only the information for the first of the two racing 8 SeRD-CSCS TN-94-12 5. THE ALGORITHM figure6a.ps 53 fi 88 mm messages needs to be stored for deterministic reexecution of the race. <p> SeRD-CSCS TN-94-12 9 5. THE ALGORITHM figure6b.ps 53 fi 88 mm 5.1.2 Implementation To implement the concept of knowledge between messages I used a technique similar to Netzer and Miller's vector timestamp <ref> [NM92a] </ref>. They suggest that each message should have the sending processor's vector timestamp appended to the end of it. Each processor has an internal clock which increments upon each event in the processor.
Reference: [NM92b] <author> Robert H. B. Netzer and Barton P. Miller. </author> <title> What are race conditions? some issues and formalizations. </title> <journal> ACM Letters on Programming Languages and Systems, </journal> <volume> 1 </volume> <pages> 74-88, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: The race detection functionality was implemented on the second layer of the MPI subset. The primitives involved in the race detection algorithm are MPI_Send, MPI_Recv, MPI_Ssend MPI_Probe MPI_Iprobe. MPI_Isend and MPI_Irecv also have potential nondeterminism due to a class of race known as data races <ref> [NM92b] </ref> but this is a different genus of races and is not considered in this algorithm. Race detection and deterministic replay facilities will be included to support PDT. The strategy will be to incorporate deterministic trace and replay into our communication platform.
Reference: [Sta93] <author> R. M. Stallman. </author> <title> GDB Manual: The GNU Source Level Debugger. Free Software Foundation, </title> <booktitle> 1993. </booktitle> <address> SeRD-CSCS TN-94-12 17 </address>
Reference-contexts: The race condition detection algorithm described in this paper will be integrated in PDT, Annai's parallel debugging tool. PDT can debug on several platforms, among others our 128 node NEC Cenju-3 DMPP. PDT is currently based on the Free Software Foundation's GNU gdb debugger <ref> [Sta93] </ref>, and already allows most of the functionality available in standard debuggers. A common debugging strategy involves reexecuting a program (on a given input) over and over, each time gaining more information about bugs. Such techniques can fail on message-passing programs.
References-found: 8

