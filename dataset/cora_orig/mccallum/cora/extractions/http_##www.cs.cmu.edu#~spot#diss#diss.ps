URL: http://www.cs.cmu.edu/~spot/diss/diss.ps
Refering-URL: http://www.cs.cmu.edu/~spot/diss/main.html
Root-URL: 
Title: Automatic Program Specialization for Interactive Media  
Author: Scott Draves 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy. Thesis Committee: Peter Lee, Chair William Scherlis Andy Witkin Olivier Danvy  
Note: c fl1997 Scott Draves  
Address: Pittsburgh, PA 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Date: July 23, 1997  
Pubnum: CMU-CS-97-159  
Abstract: This research was sponsored in part by the Defense Advanced Research Projects Agency CSTO under the title The Fox Project: Advanced Languages for Systems Software, ARPA Order No. C533, issued by ESC/ENS under Contract No. F19628-95-C-0050. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the U.S. Government. 
Abstract-found: 1
Intro-found: 1
Reference: [Andersen94] <author> Lars Ole Andersen. </author> <title> Program Analysis and Specialization for the C Programming Language. </title> <institution> DIKU 1994. </institution>
Reference-contexts: The VCODE back-end uses macros to emit code in one pass; is between 100 and 500. Familiar compile-time systems for C include C++ templates [SteLe95] and parser generators such as yacc [Johnson75] 4 . However, as corroborated by the work in compiler generation for C <ref> [CHNNV96, Andersen94] </ref>, we believe C's lack of static semantics makes these systems inherently more difficult to build, use, and understand. Fabius [LeLe96] uses fast automatic specialization for run-time code generation of a first-order subset of ML.
Reference: [ANSI90] <author> ANSI. </author> <title> ANSI/ISO 9899-1990: </title> <booktitle> Programming Languages - C. American National Standards Institute 1990. </booktitle>
Reference-contexts: While macro-expansion happens at compile time rather than run time, it is the form of metaprogramming that people today are most familiar with. Experience with second-generation lexical macro systems such as ANSI C's <ref> [ANSI90] </ref> and the omission of macros from typed languages such as Java [GoJoSte96] and SML [MiToHa90] has given macro systems something of a bad reputation. Despite this, s-expression systems continue to succeed with macros.
Reference: [ApMa91] <author> Andrew W Appel, David B MacQueen. </author> <title> Standard ML of New Jersey. </title> <booktitle> 3rd Symposium on Programming Language Implementation and Logic Programming, </booktitle> <year> 1991. </year>
Reference-contexts: This kind of manual control of inlining sometimes produces unexpectedly large results. Compilers for functional languages such as SML <ref> [ApMa91] </ref> and Haskell [JHHPW93] make much more sophisticated inlining decisions. One could use the safe, always-specialize heuristic, and use sophisticated inlining as a post-pass to remove the trivial calls.
Reference: [Appel92] <author> Andrew Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press 1992. </publisher>
Reference-contexts: The specializer is a compiler generator cogen. This chapter explains the mechanics of how cogen works, including the intermediate language and some important front-ends. Root is a simple abstract machine code, like higher-order three-address-code ([ASeUl86], p. 466) with an unlimited number of registers and in continuation-passing closure-passing style (CPS-CPS) <ref> [Appel92] </ref>. Thus the stack in a root program is explicitly represented as a data structure. The model includes data structures, arithmetic, an open set of primitive functions, and represents higher-order values with closures.
Reference: [ASeUl86] <author> A V Aho, R Sethi, J D Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley 1986. </publisher>
Reference-contexts: The standard approach to eliminating them is to apply common subexpres-sion elimination (CSE) and aliasing analysis (see Section 10.8 of <ref> [ASeUl86] </ref>) to residual programs. Efficient handling of stores is beyond such traditional techniques, however. We propose fast, optimistic sharing and static caching as an 3.2. SHARING AND CACHING 41 read esc. alternative. We implement this by replacing the load word primitive with a cached load procedure load word c.
Reference: [BiWe93] <author> Lars Birkedal, Morten Welinder. </author> <title> Partial Ealuation of Standard ML. </title> <publisher> DIKU-TR-93-22. </publisher>
Reference-contexts: This chapter is generally a review of Partial Evaluation (PE) practice; [CoDa98] and [JoGoSe93] are the standard texts of the field and may be considered references of first resort. [Jones91] is a theoretical introduction to operational behavior of specializers, and [Jones88] provides a practical description of first-order PE. <ref> [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] </ref> are system descriptions. It also defines some domains [Reynolds97] and their associated metavariables. The language is a call-by-value -calculus extended with integer constants, primitives, conditionals, a lift annotation, and explicit types on abstractions. I use the typewriter face for the terms of the object language.
Reference: [BoDa91] <author> A Bondorf, O Danvy. </author> <title> Automatic Autoprojection of Recursive Equations with Global Variables and Abstract Data Types. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 16 </volume> <pages> 151-195. </pages>
Reference-contexts: This chapter is generally a review of Partial Evaluation (PE) practice; [CoDa98] and [JoGoSe93] are the standard texts of the field and may be considered references of first resort. [Jones91] is a theoretical introduction to operational behavior of specializers, and [Jones88] provides a practical description of first-order PE. <ref> [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] </ref> are system descriptions. It also defines some domains [Reynolds97] and their associated metavariables. The language is a call-by-value -calculus extended with integer constants, primitives, conditionals, a lift annotation, and explicit types on abstractions. I use the typewriter face for the terms of the object language. <p> Similarly, if the value is used more than once, the effect may be duplicated. Most systems use let-insertion <ref> [BoDa91] </ref> to guarantee safety. The implementation of let-insertion is closely related to that of booleans, explained below [Bon-dorf92, Danvy96]. Note that the if0 clause requires that when a conditional has dynamic predicate, then both arms are also dynamic. Section 2.1 below shows how to implement a conditional without this restriction. <p> The question remains: when should the system inline, and when should it specialize, that is, test the memo-table and form a call? While it is safe to always specialize, the resulting code has many trivial calls. Many systems, including ours, use the dynamic-conditional heuristic <ref> [BoDa91] </ref>. The heuristic suggests that 28 CHAPTER 2. <p> Note that the correctness of polyvariant specialization and memoization has so far remained unaddressed. Safe handling of side-effects requires maintaining the order of computations. I believe the standard solution of let-insertion <ref> [BoDa91] </ref> could be incorporated to S without problems. Nitrous preserves order of computation because it processes programs in continuation-passing style. However, treating memory operations as generic side-effects is too restrictive (an exception is when the memory is mapped to an I/O device).
Reference: [BoDu93] <author> Anders Bondorf, Dirk Dussart. </author> <title> Handwriting Cogen for a CPS-Based Partial Evaluator. Partial Evaluation and Semantics-Based Program Manipulation, </title> <year> 1994. </year>
Reference-contexts: The binding times form a lattice because they represent partial information. It is always safe for the compiler to throw away information; this is called lifting and is the source of the lift annotation in the -language. Thus the bottom of the lattice is dynamic. <ref> [BoDu93] </ref> shows how to derive a cogen from -mix in two steps. The first step converts a specializer into a compiler generator by adding an extra level of quoting to S so static statements are copied into the compiler and dynamic ones are emitted.
Reference: [Bondorf92] <author> Anders Bondorf. </author> <title> Improving binding times without explicit CPS-conversion. </title> <booktitle> ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1992. </year>
Reference: [Carl96] <author> Stephen Carl. </author> <title> Syntactic Exposures ALexically-Scoped Macro Facility for Extensible Compilers. </title> <institution> University of Texas at Austin 1996. </institution> <type> 91 92 BIBLIOGRAPHY </type>
Reference-contexts: Thanks to Perry Cheng for helping collect the SML data. 1.4. CONTRIBUTIONS 11 variable capture pitfall [KFFD86] (see Figure 1.12). Scheme's syntax-rules [R4RS] fixed this hygiene problem for a limited class of rewriting macros. Further improvements are the subject of active research <ref> [Carl96, HiDyBru92] </ref>. Macros for typed languages are also certainly possible [Haynes93]. One way to think about BTA is as a static analysis that places the backquotes and commas automatically.
Reference: [ChaBleFi91] <author> Siddhartha Chatterjee, Guy E Blelloch, Allan L Fisher. </author> <title> Size and Access Inference for Data-Parallel Programs. </title> <booktitle> Conference on Programming Language Design and Implementation, </booktitle> <year> 1991. </year>
Reference-contexts: This transformation eliminates intermediate data structures, as illustrated in Figure 3.23. Furthermore, optimizing compilers for numerical and data-parallel languages such as High Performance Fortran and NESL perform extensive analysis to determine how to divide the computation into passes, layout the data-structures in memory, and coordinate multiple processors <ref> [SSOG93, ChaBleFi91] </ref>. Partial evaluation alone does not solve these problems. Specializing map f (map g l) has no effect. Instead, my approach is to specify procedures directly in one pass, and use specialization to efficiently implement (f o g).
Reference: [CHNNV96] <author> Charles Consel, Luke Hornof, Francois Noel, Jacque Noye, Nicolae Volanschi. </author> <title> A Uniform Approach for Compile-Time and Run-Time Specialization. </title> <booktitle> Dagstuhl Workshop on Partial Evaluation, </booktitle> <year> 1996. </year>
Reference-contexts: The VCODE back-end uses macros to emit code in one pass; is between 100 and 500. Familiar compile-time systems for C include C++ templates [SteLe95] and parser generators such as yacc [Johnson75] 4 . However, as corroborated by the work in compiler generation for C <ref> [CHNNV96, Andersen94] </ref>, we believe C's lack of static semantics makes these systems inherently more difficult to build, use, and understand. Fabius [LeLe96] uses fast automatic specialization for run-time code generation of a first-order subset of ML. <p> Essentially, it is a compiler generator where the syntax of currying indicates staged computation, including memoization. Because the binding times are implicit in every function call, no inter-procedural analysis is required. Its extensions run very fast ( is six). Tempo <ref> [CHNNV96] </ref> attempts to automate RTCG for use by operating systems. It applies binding-time analysis combined with various other analyses to ANSI C.
Reference: [CoDa89] <author> Charles Consel, Olivier Danvy. </author> <title> Partial Evaluation of Pattern Matching in Strings. </title> <journal> Information Processing Letters, </journal> <volume> 30 </volume> <pages> 79-86. </pages>
Reference-contexts: Figure 2.13 shows an example of a loop that unrolls several times before the static values match and the dynamic loop is found. A more practical example is the generation of KMP string-matching by specialization <ref> [CoDa89] </ref>. None of these results can be duplicated with a monovariant system. It can be dangerous, however, to rely on the memo-table to find fixed-points.
Reference: [CoDa98] <author> Charles Consel, Olivier Danvy. </author> <title> Partial Evaluation in Procedural Languages. </title> <publisher> MIT Press 1998. </publisher>
Reference-contexts: I then extend the calculus with products, booleans, and sums. The remaining sections discuss lifting, memoization, recursion, and compiler generation. The correctness of S is considered in Section 3.5. This chapter is generally a review of Partial Evaluation (PE) practice; <ref> [CoDa98] </ref> and [JoGoSe93] are the standard texts of the field and may be considered references of first resort. [Jones91] is a theoretical introduction to operational behavior of specializers, and [Jones88] provides a practical description of first-order PE. [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] are system descriptions.
Reference: [Consel88] <author> Charles Consel. </author> <title> New Insights into Partial Evaluation: The Schism Experiment. </title> <booktitle> European Symposium on Programming, </booktitle> <year> 1988. </year>
Reference-contexts: In practice, specializers do less work than is possible in order to avoid code-space explosion. The annotations and heuristics used to decide when to stop working are the subject of Section 2.2. Partial evaluation (PE) as described in <ref> [JoGoSe93, Consel88, WCRS91] </ref> is a syntax-directed, semantics-based, source-to-source program transformation that performs specialization. Although we say automatic, in fact some human input in the form of hints or annotations has proven necessary. One of the primary applications of PE is compiler generation, frequently abbreviated cogen. <p> This chapter is generally a review of Partial Evaluation (PE) practice; [CoDa98] and [JoGoSe93] are the standard texts of the field and may be considered references of first resort. [Jones91] is a theoretical introduction to operational behavior of specializers, and [Jones88] provides a practical description of first-order PE. <ref> [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] </ref> are system descriptions. It also defines some domains [Reynolds97] and their associated metavariables. The language is a call-by-value -calculus extended with integer constants, primitives, conditionals, a lift annotation, and explicit types on abstractions. I use the typewriter face for the terms of the object language.
Reference: [Consel90] <author> Charles Consel. </author> <title> Binding Time Analysis for Higher Order Untyped Functional Languages. </title> <booktitle> ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1990. </year>
Reference-contexts: We use familiar type constructors to denote circular binding times. Figure 4.13 depicts several useful examples. As in Schism <ref> [Consel90] </ref>, control-flow information appears in the binding times. Cogen supports arbitrary values in the binding times, including code pointers, the empty list, and other type tags. Such a binding time is denoted ( ] const c), or just c.
Reference: [Consel93] <author> Charles Consel. </author> <title> Polyvariant Binding-Time Analysis For Applicative Languages. Partial Evaluation and Semantics-Based Program Manipulation, </title> <year> 1993. </year>
Reference-contexts: A polyvariant BTA is one that effectively places lifts for this kind of system. Polyvariant BTA usually implemented with abstract interpretation <ref> [Consel93] </ref>. Thus a given piece of syntax may be both executed by S and emitted as residual. 2.1 Products and Sums This section adds product and sum types to the specializer.
Reference: [CPHP87] <author> P Caspi, D Pilaud, N Halbwachs, J A Plaice. Lustre: </author> <title> A Declarative Language for Programming Synchronous Systems. </title> <booktitle> Principles of Programming Languages, </booktitle> <year> 1987. </year>
Reference-contexts: Collapsible protocol languages such as [HaRe96, ProWa96] can handle more advanced control flow (our signals are push or pull, not both), but these systems do not address bits. The same is true of synchronous real-time languages like Signal [GuBoGaMa91] and Lustre <ref> [CPHP87] </ref>. Their compilers are mostly concerned with deriving global timing from local behavior. Past work in bit-level processing has not emphasized implementation on word machines.
Reference: [Danvy96] <author> Olivier Danvy. </author> <title> Type-Directed Partial Evaluation. </title> <booktitle> Principles of Programming Languages, </booktitle> <year> 1996. </year>
Reference-contexts: Similarly, if the value is used more than once, the effect may be duplicated. Most systems use let-insertion [BoDa91] to guarantee safety. The implementation of let-insertion is closely related to that of booleans, explained below <ref> [Bon-dorf92, Danvy96] </ref>. Note that the if0 clause requires that when a conditional has dynamic predicate, then both arms are also dynamic. Section 2.1 below shows how to implement a conditional without this restriction. <p> The type of the operator depends on how much of the recursion is to be expanded. In other words, the source program must be adjusted to support different binding times. Figures 2.8 and 2.9 show two versions of the power function specialized with Type Directed Partial Evaluation (TDPE) <ref> [Danvy96] </ref> 1 . A polyvariant specializer does not have this limitation, as the example in Figure 2.10 demonstrates. At a call site, a monovariant specializer like -mix [GoJo91] either inlines or residualizes. <p> The second step involves adding a continuation argument to S to allow propagation of a static context into the arms of a conditional with a dynamic test. One of the interesting results of <ref> [Danvy96] </ref> is how this property (the handling of sum-types and let-insertion) can be achieved while remaining in direct style by using shift/reset. <p> The compiler generated by cogen compiles Sal programs to root programs. It works in one-pass, performing CPS conversion, closure conversion using a linked representation, and executes tail-recursion without the stack. It generates some duplicate code unnecessarily, and is non-optimizing. Conversion to continuation-passing style is a standard result in PE <ref> [Danvy96] </ref>, but the others are new. It is possible to feed this generated code back into cogen. This is how the benchmarks of Section 5.2 were done. Examples of residual root code generated by this compiler appears in Ap-pendex A.6.
Reference: [DaPfe96] <author> Rowan Davies, Frank Pfenning. </author> <title> A Modal Analysis of Staged Computation. </title> <booktitle> Principles of Programming Languages, </booktitle> <year> 1996. </year>
Reference-contexts: This thesis concerns systems implemented directly with a static analysis known as binding-time analysis (BTA). Binding-time analysis classifies each variable and operation in the interpreter source text as either static (program) or dynamic (data). Basically, values that depend on dynamic values are dynamic. Recent research <ref> [DaPfe96] </ref> indicates that binding times can be modeled with temporal logic, and thus incorporated into type systems. Let us now feel how compiler generation fits into the situation from the previous section. Initially the programmer type-checks and debugs a one-stage interpreter.
Reference: [Detlefs96] <author> David Detlefs. </author> <title> An Overview of the Extended Static Checking System. </title> <booktitle> Workshop on Formal Methods in Software Practice, </booktitle> <year> 1996. </year>
Reference-contexts: As noted in Section 3.6, the natural way to address this is with generalized partial computation. But GPC is dependent on a theorem prover. We assume that some form of annotations (or interactivity) to guide the prover will be necessary. The Extended Static Checking (ESC) framework <ref> [Detlefs96] </ref> may prove suitable. Until more experience with better implementations of bit-addressing is col lected, these plans and analyses will remain rather speculative. 90 CHAPTER 6. CONCLUSION
Reference: [Deutsch94] <author> Alain Deutsch. </author> <title> Interprocedural May-Alias analysis for pointers: Beyond k-limiting. </title> <booktitle> Conference on Programming Language Design and Implementation, </booktitle> <year> 1994. </year> <note> BIBLIOGRAPHY 93 </note>
Reference-contexts: We chose to transparently thread an additional argument through all calls and returns by changing its implementation language. Note that safely eliminating loads in the presence of stores requires negative may-alias information (knowing that values will not be equal) <ref> [Deutsch94] </ref>. We have not yet implemented anything to guarantee this. A conspicuous variable is the size of the cache. How many previous loads should be remembered? Though this is currently left to the programmer (with init-cache in Nitrous), automation appears feasible.
Reference: [Draves95] <author> Scott Draves. </author> <title> Lightweight Languages for Interactive Graphics. </title> <publisher> CMU-CS-95-148. </publisher>
Reference-contexts: It uses a software implementation of a small fully associative cache. Because of the sharing analysis, the cache is classi fied as static and eliminated. More generally, this was the first research to explicitly apply partial evaluation to run-time code generation <ref> [Draves95] </ref>. The rest of the dissertation consists of five chapters and an appendix. Chapter 2 defines a specializer S and briefly discusses its implementation, Chapter 3 extends it to cover bit-addressing, and Chapter 4 describes the Nitrous implementation.
Reference: [Draves96] <author> Scott Draves. </author> <title> Compiler Generation for Interactive Graphics using Intermediate Code. </title> <booktitle> Dagstuhl Workshop on Partial Evaluation, </booktitle> <year> 1996. </year>
Reference-contexts: INTRODUCTION generation (where one generates a compiler from an interpreter written in a language defined by another interpreter). This system is the subject of Chapter 4 and a previous paper <ref> [Draves96] </ref>. Its relevant features are: Cyclic integers Standard PE systems have the ability to determine that #1 (s,d) is static 5 where s is static and d is dynamic. The value (s, d) is called a partially-static structure. Nitrous supports a kind of partially static integer I call cyclic integers. <p> (zero? C) S D f (imod C S) S (idiv C S) C (early= D D) S g f extensions for both S and D are created, the compiler chooses one statically (see Section 3.1). g early= conservative static equality of dynamic values, see Section 3.2. 4.2.5 Static Extensions Previously <ref> [Draves96] </ref>, the code pointer in a static closure (from a function or a continuation) was represented with a metastatic extension. The binding times in such an extension are fixed, which restricted the use of polyvariance and required additional annotation.
Reference: [Draves97] <author> Scott Draves. </author> <title> Implementing Bit-addressing with Specialization. </title> <booktitle> International Conference on Functional Programming, </booktitle> <year> 1997. </year>
Reference-contexts: The result is true if the compiler can prove that the values will be equal; false if they may not be equal. A specializer with these features is powerful enough to implement (among other things) the subject of Chapter 3 and <ref> [Draves97] </ref>: Bit-addressing This technique (one interface, one language) allows one to play with signal processing at the dataflow-level yet remain independent of the number of bits per sample. It uses a software implementation of a small fully associative cache.
Reference: [EngKaOT95] <author> Dawson Engler, M Frans Kaashoek, James O'Toole. Exokernel: </author> <title> An Operating System Architecture for Application-Level Resource Management. </title> <booktitle> Symposium on Operating Systems Principles, </booktitle> <year> 1995. </year>
Reference-contexts: This section uses a lot of jargon; explanations appear in the relevant references. Run-time code generation per se has long history including exile, reconsideration [KeEgHe91], and a growing body of research demonstrating substantial performance gains in operating systems <ref> [PuMaIo88, EngKaOT95, MuVoMa97] </ref>. I define of an RTCG system as the average number of cycles spent by the compiler per instruction generation.
Reference: [EnHsKa95] <author> Dawson Engler, Wilson Hsieh, M Frans Kaashoek. </author> <title> `C: A Language for High-Level, Efficient, and Machine-independent Dynamic Code Generation. </title> <booktitle> Conference on Programming Language Design and Implementation, </booktitle> <year> 1995. </year>
Reference-contexts: Further improvements are the subject of active research [Carl96, HiDyBru92]. Macros for typed languages are also certainly possible [Haynes93]. One way to think about BTA is as a static analysis that places the backquotes and commas automatically. The `C language (pronounced tick-C) <ref> [EnHsKa95] </ref> extends ANSI C with an interface for RTCG inspired by Lisp's backquote mechanism, though significantly more difficult to use due to limitations in the orthogonality, generality, and type regularity of the extensions. The recent implementation shows good performance in realistic situations with either of two backends [PoEnKa97].
Reference: [FriWa84] <author> Daniel P Friedman, Mitchell Wand. </author> <title> Reification: Reflection without Metaphysics. </title> <booktitle> ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1984. </year>
Reference-contexts: Lisp supports reflection with eval and compile. Reification is the opposite of reflection, that is, converting a value (possibly a function) into a corresponding text. Although reification is commonly available in debuggers and interpreters, not even Common LISP standardizes it. <ref> [FriWa84] </ref> defines and discusses these ideas in detail. Reification is sometimes called introspection [Thiemann96] Section 4. Root supports both reflection and reification. By supporting reflection we make code-producing functions first class.
Reference: [FuNoTa91] <author> Yoshihiko Futamura, Kenroku Nogi, Aki Takano. </author> <title> The essence of generalized partial computation. </title> <journal> Theoretical Computer Science, </journal> <volume> 90(1) </volume> <pages> 61-79. </pages>
Reference-contexts: The latter route leads to the technique of generalized partial computation <ref> [FuNoTa91, SoGluJo96] </ref>, wherein PE is extended with a theorem prover. Say we wrote bitcopy in bit-serial fashion, as in Figure 3.24. The rules of this chapter produce (assuming an 8-bit word for brevity) the obviously inefficient code in Figure 3.25.
Reference: [Futamura71] <author> Y Futamura. </author> <title> Partial evalutaion of computation process an approach to a compiler-compiler. </title> <journal> Systems, Computers, Controls, </journal> <volume> 2 </volume> <pages> 45-50. </pages>
Reference-contexts: SPECIALIZATION 9 least theoretically) [[spec]] spec f is a compiler for the language defined by the interpreter f . Another level of self-application yields [[spec]] spec spec, a compiler generator. These are known as the Futamura projections <ref> [Futamura71] </ref>. Research on practical compiler generation is widespread [Mosses78, JoSeSo85, Lee89]. This thesis concerns systems implemented directly with a static analysis known as binding-time analysis (BTA). Binding-time analysis classifies each variable and operation in the interpreter source text as either static (program) or dynamic (data). <p> A remarkably pleasing though seemingly less practical way of implementing [[cogen]] is by self-application of a specializer [[[[mix]] mix mix]], as suggested in <ref> [Futamura71] </ref> and first implemented in [JoSeSo85]. Specializers are classified as either offline or online. An online system works in one pass. Roughly, offline systems are suitable for compiler generation via self-application, and online systems are not. An offline system works in two phases.
Reference: [GluJo94] <author> Robert Gluck, Jesper Jrgensen. </author> <title> Generating Optimizing Specializers. </title> <booktitle> IEEE Computer Society International Conference on Computer Languages, </booktitle> <year> 1994. </year>
Reference-contexts: This is how rgb to mono and copy were built. The lift compiler (see Section 4.2.3) also uses two layers. Another possibility is to include a compiler generator as a primitive in Sal. Multi-stage application requires that the generated compilers create correctly annotated programs, which can be difficult. In <ref> [GluJo94, GluJo95] </ref> Gluck and Jrgensen present more rigourous and automatic treatments of layered systems using specializer projections and multi-stage binding-time analysis. This chapter is organized as follows. First, the intermediate language is presented, followed by the compiler generator, the Sal front end, and the conclusion.
Reference: [GluJo95] <author> Robert Gluck, Jesper Jrgensen. </author> <title> Efficient Multi-Level Generating Extensions for Program Specialization. </title> <booktitle> Programming Language Implementation and Logic Programming, </booktitle> <year> 1995. </year>
Reference-contexts: This is how rgb to mono and copy were built. The lift compiler (see Section 4.2.3) also uses two layers. Another possibility is to include a compiler generator as a primitive in Sal. Multi-stage application requires that the generated compilers create correctly annotated programs, which can be difficult. In <ref> [GluJo94, GluJo95] </ref> Gluck and Jrgensen present more rigourous and automatic treatments of layered systems using specializer projections and multi-stage binding-time analysis. This chapter is organized as follows. First, the intermediate language is presented, followed by the compiler generator, the Sal front end, and the conclusion.
Reference: [GoJo91] <author> Carsten K Gomard, Neil D Jones. </author> <title> A partial evaluator for the untyped lambda-calculus. </title> <journal> Journal of Functional Programming, </journal> <volume> 1 </volume> <pages> 21-69. </pages>
Reference-contexts: Note that the if0 clause requires that when a conditional has dynamic predicate, then both arms are also dynamic. Section 2.1 below shows how to implement a conditional without this restriction. S is similar to the -mix of <ref> [GoJo91] </ref>, but -mix uses uses a two-level input language where source s have been labeled either for execution or immediate residualization. S reserves judgment until the function is applied; S depends on a lift annotations to emit a lambda. Note that many cases are missing from S. <p> Figures 2.8 and 2.9 show two versions of the power function specialized with Type Directed Partial Evaluation (TDPE) [Danvy96] 1 . A polyvariant specializer does not have this limitation, as the example in Figure 2.10 demonstrates. At a call site, a monovariant specializer like -mix <ref> [GoJo91] </ref> either inlines or residualizes. A polyvariant specializer has the option of emitting a call to a 1 Danvy reports that a future version of TDPE does not have this restriction. 26 CHAPTER 2. <p> Thus the standard measure of correctness of specializers is satisfaction of the first Futamura projection: [[f ]] x y = ff [[[[spec]] f x]] y Note that this is a strong notion of correctness, defined by equivalence of terms. <ref> [GoJo91] </ref> contains such a proof for -mix where the equivalence permits ff-conversion (renaming variables). A similar proof for S would be unremarkable, except for the handling of the extension for cyclic integers. Here, the proof would use algebraic properites of the rules in Figures 3.6 and 3.7.
Reference: [GoJoSte96] <author> James Gosling, Bill Joy, Guy Steele. </author> <title> The Java Language Specification. </title> <publisher> Addison-Wesley 1996. 94 BIBLIOGRAPHY </publisher>
Reference-contexts: While macro-expansion happens at compile time rather than run time, it is the form of metaprogramming that people today are most familiar with. Experience with second-generation lexical macro systems such as ANSI C's [ANSI90] and the omission of macros from typed languages such as Java <ref> [GoJoSte96] </ref> and SML [MiToHa90] has given macro systems something of a bad reputation. Despite this, s-expression systems continue to succeed with macros. <p> Two factors that weigh against root: explicit types would simplify the implementation and formalization, and on some architectures good loops (e.g. PC-relative addressing or other special instructions) are difficult to produce. Using a language like the JVM <ref> [GoJoSte96] </ref>, or one of the intermediate languages of [TMCSHL96] would leverage existing research. 4.2 The Compiler Generator Cogen is directly implemented (rather than produced by self-application), poly-variant in binding times (it allows multiple binding time patterns per source procedure), performs polyvariant specialization with memo-tables, and handles higher-order control flow.
Reference: [Graham94] <author> Paul Graham. </author> <title> On Lisp: Advanced Techniques for Common LISP. </title> <publisher> Prentice-Hall 1994. </publisher>
Reference-contexts: However in the Common LISP world [Steele90], use of RTCG (via eval, compile, and defmacro) is considered an essential advanced technique <ref> [Graham94] </ref>. While macro-expansion happens at compile time rather than run time, it is the form of metaprogramming that people today are most familiar with.
Reference: [GuBoGaMa91] <author> P le Guernic, M le Borgne, T Gauthier, C le Maire. </author> <title> Programing Real-Time applications with Signal. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 79(9) </volume> <pages> 1305-1320. </pages>
Reference-contexts: Collapsible protocol languages such as [HaRe96, ProWa96] can handle more advanced control flow (our signals are push or pull, not both), but these systems do not address bits. The same is true of synchronous real-time languages like Signal <ref> [GuBoGaMa91] </ref> and Lustre [CPHP87]. Their compilers are mostly concerned with deriving global timing from local behavior. Past work in bit-level processing has not emphasized implementation on word machines.
Reference: [HaRe96] <author> Mark Hayden, Robbert van Renesse. </author> <title> Optimizing Layered Communication Protocols. </title> <publisher> Cornell-TR96-1613. </publisher>
Reference-contexts: An on-chip hardware cache makes this second read inexpensive, but with the software cache the situation is detected once at code-generation time. Specialization with sharing can replace a cache hit with a register reference. Collapsible protocol languages such as <ref> [HaRe96, ProWa96] </ref> can handle more advanced control flow (our signals are push or pull, not both), but these systems do not address bits. The same is true of synchronous real-time languages like Signal [GuBoGaMa91] and Lustre [CPHP87]. Their compilers are mostly concerned with deriving global timing from local behavior.
Reference: [Haynes93] <author> Christopher Haynes. Infer: </author> <title> A Statically-typed Dialect of Scheme. </title> <publisher> Indiana-CS-TR-93-367. </publisher>
Reference-contexts: CONTRIBUTIONS 11 variable capture pitfall [KFFD86] (see Figure 1.12). Scheme's syntax-rules [R4RS] fixed this hygiene problem for a limited class of rewriting macros. Further improvements are the subject of active research [Carl96, HiDyBru92]. Macros for typed languages are also certainly possible <ref> [Haynes93] </ref>. One way to think about BTA is as a static analysis that places the backquotes and commas automatically.
Reference: [Henglein91] <author> Fritz Henglein. </author> <title> Efficient Type Inference for Higher-Order Binding-Time Analysis. </title> <booktitle> International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <year> 1991. </year>
Reference-contexts: If each variable and procedure always has the same binding time, then a partial evaluator is said to be monovariant in binding times. The prototypical monovari-ant system is -mix. Monovariant BTA is well-understood and can be efficiently implemented with type-inference <ref> [Henglein91] </ref>. The problem with this kind of system is that frequently a procedure is applied to values with different binding times. For example, in one context I might apply power to static base and exponent, but in another, to dynamic base and static exponent. 2.1.
Reference: [HePa90] <author> John L Hennessy, David A Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann 1990. </publisher>
Reference: [HiDyBru92] <author> Robert Hieb, Kent Dybvig, Carl Bruggeman. </author> <title> Syntactic abstraction in scheme. </title> <note> Indiana University TR #355, </note> <year> 1992. </year>
Reference-contexts: Thanks to Perry Cheng for helping collect the SML data. 1.4. CONTRIBUTIONS 11 variable capture pitfall [KFFD86] (see Figure 1.12). Scheme's syntax-rules [R4RS] fixed this hygiene problem for a limited class of rewriting macros. Further improvements are the subject of active research <ref> [Carl96, HiDyBru92] </ref>. Macros for typed languages are also certainly possible [Haynes93]. One way to think about BTA is as a static analysis that places the backquotes and commas automatically.
Reference: [IEEE91] <author> IEEE. </author> <title> IEEE Standard 1076: VHDL Language Reference Manual. </title> <booktitle> IEEE 1991. </booktitle>
Reference-contexts: Past work in bit-level processing has not emphasized implementation on word machines. Although C allows one to specify the number of bits used to store a field in a structure, it does not provide for arrays of bits. The hardware design language VHDL <ref> [IEEE91] </ref>) allows specification of signals of particular numbers of bits, but lacks a compiler that produces fast code. There are two groups of examples, the audio group (Figure 5.6) and the video group (Figure 5.5).
Reference: [James1882] <author> William James. </author> <title> Subjective Effects of Nitrous Oxide. </title> <journal> Mind, </journal> <volume> Volume 7. </volume>
Reference-contexts: It is also a common medical anaesthetic. William James found that its subjective effect was to reveal the Hegelian synthesis <ref> [James1882] </ref>. 51 52 CHAPTER 4. NITROUS languages, and arrows denote program transformations. The ML front-end is hypothetical, and so is drawn with dotted lines. The specializer is a compiler generator cogen. This chapter explains the mechanics of how cogen works, including the intermediate language and some important front-ends.
Reference: [JHHPW93] <author> Simon L Peyton Jones, Cordy Hall, Kevin Hammond, Will Partain, Philip Wadler. </author> <title> The Glasgow Haskell compiler: a technical overview. </title> <booktitle> UK Joint Framework for Information Technology (JFIT), </booktitle> <year> 1993. </year>
Reference-contexts: This kind of manual control of inlining sometimes produces unexpectedly large results. Compilers for functional languages such as SML [ApMa91] and Haskell <ref> [JHHPW93] </ref> make much more sophisticated inlining decisions. One could use the safe, always-specialize heuristic, and use sophisticated inlining as a post-pass to remove the trivial calls. In the run-time environment we are interested in, feedback from execution or a inexpensive approximation may substitute for sophisticated inlining decisions. 30 CHAPTER 2.
Reference: [JoGoSe93] <author> Neil D Jones, Carsten K Gomard, Peter Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice-Hall 1993. </publisher>
Reference-contexts: In practice, specializers do less work than is possible in order to avoid code-space explosion. The annotations and heuristics used to decide when to stop working are the subject of Section 2.2. Partial evaluation (PE) as described in <ref> [JoGoSe93, Consel88, WCRS91] </ref> is a syntax-directed, semantics-based, source-to-source program transformation that performs specialization. Although we say automatic, in fact some human input in the form of hints or annotations has proven necessary. One of the primary applications of PE is compiler generation, frequently abbreviated cogen. <p> I then extend the calculus with products, booleans, and sums. The remaining sections discuss lifting, memoization, recursion, and compiler generation. The correctness of S is considered in Section 3.5. This chapter is generally a review of Partial Evaluation (PE) practice; [CoDa98] and <ref> [JoGoSe93] </ref> are the standard texts of the field and may be considered references of first resort. [Jones91] is a theoretical introduction to operational behavior of specializers, and [Jones88] provides a practical description of first-order PE. [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] are system descriptions.
Reference: [Johnson75] <author> Stephen C Johnson. </author> <title> YACC Yet Another Compiler-Compiler. </title> <institution> Bell Labs 1975. </institution>
Reference-contexts: The VCODE back-end uses macros to emit code in one pass; is between 100 and 500. Familiar compile-time systems for C include C++ templates [SteLe95] and parser generators such as yacc <ref> [Johnson75] </ref> 4 . However, as corroborated by the work in compiler generation for C [CHNNV96, Andersen94], we believe C's lack of static semantics makes these systems inherently more difficult to build, use, and understand. Fabius [LeLe96] uses fast automatic specialization for run-time code generation of a first-order subset of ML.
Reference: [Jones88] <author> Neil D Jones. </author> <title> Automatic Program Specialization: a Re-examination from Basic Principles. Partial Evaluation and Mixed Computation, 1988. BIBLIOGRAPHY 95 </title>
Reference-contexts: The correctness of S is considered in Section 3.5. This chapter is generally a review of Partial Evaluation (PE) practice; [CoDa98] and [JoGoSe93] are the standard texts of the field and may be considered references of first resort. [Jones91] is a theoretical introduction to operational behavior of specializers, and <ref> [Jones88] </ref> provides a practical description of first-order PE. [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] are system descriptions. It also defines some domains [Reynolds97] and their associated metavariables. The language is a call-by-value -calculus extended with integer constants, primitives, conditionals, a lift annotation, and explicit types on abstractions.
Reference: [Jones91] <author> Neil D Jones. </author> <title> Efficient Algebraic Operations on Programs. </title> <booktitle> Algebraic Methodology and Software Technology, </booktitle> <year> 1991. </year>
Reference-contexts: The remaining sections discuss lifting, memoization, recursion, and compiler generation. The correctness of S is considered in Section 3.5. This chapter is generally a review of Partial Evaluation (PE) practice; [CoDa98] and [JoGoSe93] are the standard texts of the field and may be considered references of first resort. <ref> [Jones91] </ref> is a theoretical introduction to operational behavior of specializers, and [Jones88] provides a practical description of first-order PE. [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] are system descriptions. It also defines some domains [Reynolds97] and their associated metavariables.
Reference: [JoSche86] <author> Ulrik Jrring, William Scherlis. </author> <title> Compilers and Staging Transformations. </title> <booktitle> Principles of Programming Languages, </booktitle> <year> 1986. </year>
Reference-contexts: The intention is that [[spec]] will do as much work of f as is possible knowing only its first argument and return a residual program that finishes the computation. This gives us a way of factoring or staging computations <ref> [JoSche86] </ref> and is most useful if we use this residual program many times. In practice, specializers do less work than is possible in order to avoid code-space explosion. The annotations and heuristics used to decide when to stop working are the subject of Section 2.2.
Reference: [JoSeSo85] <author> Neil D Jones, P Sestoft, H Sndergaard. </author> <title> An experiment in partial evaluation: The generation of a compiler generator. Rewriting Techniques and Applications, </title> <address> Dijon, France, </address> <year> 1985. </year>
Reference-contexts: SPECIALIZATION 9 least theoretically) [[spec]] spec f is a compiler for the language defined by the interpreter f . Another level of self-application yields [[spec]] spec spec, a compiler generator. These are known as the Futamura projections [Futamura71]. Research on practical compiler generation is widespread <ref> [Mosses78, JoSeSo85, Lee89] </ref>. This thesis concerns systems implemented directly with a static analysis known as binding-time analysis (BTA). Binding-time analysis classifies each variable and operation in the interpreter source text as either static (program) or dynamic (data). Basically, values that depend on dynamic values are dynamic. <p> A remarkably pleasing though seemingly less practical way of implementing [[cogen]] is by self-application of a specializer [[[[mix]] mix mix]], as suggested in [Futamura71] and first implemented in <ref> [JoSeSo85] </ref>. Specializers are classified as either offline or online. An online system works in one pass. Roughly, offline systems are suitable for compiler generation via self-application, and online systems are not. An offline system works in two phases.
Reference: [KeEgHe91] <author> D Keppel, S J Eggers, R R Henry. </author> <title> A Case for Runtime Code Generation. </title> <publisher> UW-CSE-91-11-04. </publisher>
Reference-contexts: This section uses a lot of jargon; explanations appear in the relevant references. Run-time code generation per se has long history including exile, reconsideration <ref> [KeEgHe91] </ref>, and a growing body of research demonstrating substantial performance gains in operating systems [PuMaIo88, EngKaOT95, MuVoMa97]. I define of an RTCG system as the average number of cycles spent by the compiler per instruction generation.
Reference: [KFFD86] <author> Eugene Kohlbecker, Daniel Friedman, Matthias Felleisen, Bruce Duba. </author> <title> Hygienic Macro Expansion. </title> <booktitle> ACM Conference on Lisp and Functional Programming, </booktitle> <year> 1986. </year>
Reference-contexts: The latter is estimated with the size of the compiler's output divided by the average number of bytes per instruction. Thanks to Perry Cheng for helping collect the SML data. 1.4. CONTRIBUTIONS 11 variable capture pitfall <ref> [KFFD86] </ref> (see Figure 1.12). Scheme's syntax-rules [R4RS] fixed this hygiene problem for a limited class of rewriting macros. Further improvements are the subject of active research [Carl96, HiDyBru92]. Macros for typed languages are also certainly possible [Haynes93].
Reference: [Lee89] <author> Peter Lee. </author> <title> Realistic Compiler Generation. </title> <publisher> MIT Press 1989. </publisher>
Reference-contexts: SPECIALIZATION 9 least theoretically) [[spec]] spec f is a compiler for the language defined by the interpreter f . Another level of self-application yields [[spec]] spec spec, a compiler generator. These are known as the Futamura projections [Futamura71]. Research on practical compiler generation is widespread <ref> [Mosses78, JoSeSo85, Lee89] </ref>. This thesis concerns systems implemented directly with a static analysis known as binding-time analysis (BTA). Binding-time analysis classifies each variable and operation in the interpreter source text as either static (program) or dynamic (data). Basically, values that depend on dynamic values are dynamic.
Reference: [LeLe96] <author> Peter Lee, Mark Leone. </author> <title> Optimizing ML with Run-Time Code Generation. </title> <booktitle> Conference on Programming Language Design and Implementation, </booktitle> <year> 1996. </year>
Reference-contexts: However, as corroborated by the work in compiler generation for C [CHNNV96, Andersen94], we believe C's lack of static semantics makes these systems inherently more difficult to build, use, and understand. Fabius <ref> [LeLe96] </ref> uses fast automatic specialization for run-time code generation of a first-order subset of ML. Essentially, it is a compiler generator where the syntax of currying indicates staged computation, including memoization. Because the binding times are implicit in every function call, no inter-procedural analysis is required.
Reference: [Leroy92] <author> Xavier Leroy. </author> <title> Unboxed objects and polymorphic typing. </title> <booktitle> Principles of Programming Languages, </booktitle> <year> 1992. </year>
Reference-contexts: Figure 3.10 shows an example of its use. Section 4.2.3 explains its implementation. (set-base m b) ! hb d ri While we currently rely on manual placement of set-base, we believe automation is possible because the analysis required appears similar to the un/boxing problem <ref> [Leroy92] </ref>. 3.1.1 Multiple Signals If a loop reads from multiple signals simultaneously, then in order to apply the these optimizations, it must be unrolled until all the signals return to their original alignment. Figure 3.11 illustrates such a situation.
Reference: [MiHraCru94] <author> Melanie Mitchell, James Crutchfield, Peter Hraber. </author> <title> Evolving Cellular Automata to Perform Computations: Mechanisms and Impediments. </title> <journal> Physica D, </journal> <volume> 75 </volume> <pages> 361-391. </pages>
Reference-contexts: The same idea applies to the parts of an operating system that implement network protocols. My final example: artificial evolution of two-dimensional cellular automata. The standard technique is to apply the genetic algorithm to lookup-tables indexed by all possible neighborhoods <ref> [MiHraCru94] </ref>. But if the cells have just three bits of state and a 3-by-3 neighborhood then the lookup-table would require 192 Mbytes (32 39 bits).
Reference: [MiToHa90] <author> Robin Milner, Mads Tofte, Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT 1990. </publisher>
Reference-contexts: While macro-expansion happens at compile time rather than run time, it is the form of metaprogramming that people today are most familiar with. Experience with second-generation lexical macro systems such as ANSI C's [ANSI90] and the omission of macros from typed languages such as Java [GoJoSte96] and SML <ref> [MiToHa90] </ref> has given macro systems something of a bad reputation. Despite this, s-expression systems continue to succeed with macros.
Reference: [Mogensen89] <author> Torben Mogensen. </author> <title> Binding Time Aspects of Partial Evaluation. </title> <institution> DIKU 1989. </institution>
Reference-contexts: Pairs in binding times are labeled with a cons point that identifies which instruction the pair came from. If the same label appears on a pair and a descendant of that pair then the graph-grammar is collapsed, perhaps forming a circularity <ref> [Mogensen89] </ref>. Figures 4.11 and 4.12 show two possibilities. The function of the cons-points would be better provided by explicit inductive types.
Reference: [Mosses78] <author> Peter Mosses. </author> <title> SIS, a Compiler-Generator System using Denotational Semantics. </title> <publisher> Aarhus-TR-1978. </publisher>
Reference-contexts: SPECIALIZATION 9 least theoretically) [[spec]] spec f is a compiler for the language defined by the interpreter f . Another level of self-application yields [[spec]] spec spec, a compiler generator. These are known as the Futamura projections [Futamura71]. Research on practical compiler generation is widespread <ref> [Mosses78, JoSeSo85, Lee89] </ref>. This thesis concerns systems implemented directly with a static analysis known as binding-time analysis (BTA). Binding-time analysis classifies each variable and operation in the interpreter source text as either static (program) or dynamic (data). Basically, values that depend on dynamic values are dynamic.
Reference: [Mossin93] <author> Christian Mossin. </author> <title> Partial evaluation of General Parsers. Partial Evaluation and Semantics-Based Program Manipulation, 1993. 96 BIBLIOGRAPHY </title>
Reference-contexts: It accepts and produces (and its compilers produce) programs written in an intermediate language similar to three-address code. This design allows low-overhead run-time code generation as well as multi-stage compiler 4 In fact, LR (k) parser generation is a special case of polyvariant compiler generation <ref> [Mossin93, SpeThi95] </ref>. 12 CHAPTER 1. INTRODUCTION generation (where one generates a compiler from an interpreter written in a language defined by another interpreter). This system is the subject of Chapter 4 and a previous paper [Draves96].
Reference: [MuVoMa97] <author> Gilles Muller, Eugen-Nicolae Volanschi, Renaud Marlet. </author> <title> Scaling up Partial Evaluation for Optimizing the Sun Commercial RPC Protocol. Partial Evaluation and Semantics-Based Program Manipulation, </title> <year> 1997. </year>
Reference-contexts: This section uses a lot of jargon; explanations appear in the relevant references. Run-time code generation per se has long history including exile, reconsideration [KeEgHe91], and a growing body of research demonstrating substantial performance gains in operating systems <ref> [PuMaIo88, EngKaOT95, MuVoMa97] </ref>. I define of an RTCG system as the average number of cycles spent by the compiler per instruction generation.
Reference: [PoEnKa97] <author> Massimiliano Polleto, Dawson Engler, M Frans Kasshoek. tcc: </author> <title> A System for Fast, Flexible, and High-level Dynamic Code Generation. </title> <booktitle> Conference on Programming Language Design and Implementation, </booktitle> <year> 1997. </year>
Reference-contexts: The recent implementation shows good performance in realistic situations with either of two backends <ref> [PoEnKa97] </ref>. Tcc's ICODE backend performs basic optimizations such as instruction scheduling, peephole, and register allocation, resulting in between 1000 and 2500. The VCODE back-end uses macros to emit code in one pass; is between 100 and 500.
Reference: [ProWa96] <author> Todd Proebsting, Scott Watterson. </author> <title> Filter Fusion. </title> <booktitle> Principles of Programming Languages, </booktitle> <year> 1996. </year>
Reference-contexts: An on-chip hardware cache makes this second read inexpensive, but with the software cache the situation is detected once at code-generation time. Specialization with sharing can replace a cache hit with a register reference. Collapsible protocol languages such as <ref> [HaRe96, ProWa96] </ref> can handle more advanced control flow (our signals are push or pull, not both), but these systems do not address bits. The same is true of synchronous real-time languages like Signal [GuBoGaMa91] and Lustre [CPHP87]. Their compilers are mostly concerned with deriving global timing from local behavior.
Reference: [PuMaIo88] <author> Calton Pu, Henry Massalin, John Ioannidis. </author> <title> The Synthesis Kernel. </title> <booktitle> Computing Systems, </booktitle> <year> 1988. </year>
Reference-contexts: This section uses a lot of jargon; explanations appear in the relevant references. Run-time code generation per se has long history including exile, reconsideration [KeEgHe91], and a growing body of research demonstrating substantial performance gains in operating systems <ref> [PuMaIo88, EngKaOT95, MuVoMa97] </ref>. I define of an RTCG system as the average number of cycles spent by the compiler per instruction generation.
Reference: [R4RS] <author> William Clinger, Jonathan Rees. </author> <title> Revised 4 Report on the Algorithmic Language Scheme. LISP Pointers, </title> <publisher> IV:1-55. </publisher>
Reference-contexts: The latter is estimated with the size of the compiler's output divided by the average number of bytes per instruction. Thanks to Perry Cheng for helping collect the SML data. 1.4. CONTRIBUTIONS 11 variable capture pitfall [KFFD86] (see Figure 1.12). Scheme's syntax-rules <ref> [R4RS] </ref> fixed this hygiene problem for a limited class of rewriting macros. Further improvements are the subject of active research [Carl96, HiDyBru92]. Macros for typed languages are also certainly possible [Haynes93]. One way to think about BTA is as a static analysis that places the backquotes and commas automatically.
Reference: [Reynolds97] <author> John Reynolds. </author> <note> Programming Languages Core Course Notes. unpublished 1997. </note>
Reference-contexts: It also defines some domains <ref> [Reynolds97] </ref> and their associated metavariables. The language is a call-by-value -calculus extended with integer constants, primitives, conditionals, a lift annotation, and explicit types on abstractions. I use the typewriter face for the terms of the object language. I use to denote a generic, black box binary primitive operation.
Reference: [Shivers91] <author> Olin Shivers. </author> <title> Control-Flow Analysis of Higher-Order Languages. </title> <institution> Carnegie Mellon University, School of Computer Science 1991. </institution>
Reference-contexts: Note that there are two versions of each extension. Cogen could avoid producing the (probably over-) specialized entry/exit code by checking for the 2 If instead of forgetting x and y completely, we approximated them with a set, the result would be control-flow analysis based on abstract interpretation <ref> [Shivers91] </ref>. 3 Only a irregular recursion really requires this, but append is easier to understand. 70 CHAPTER 4.
Reference: [SiHoMcA96] <author> Satnam Singh, Jonathan Hogg, Derek McAuley. </author> <title> Expressing Dynamic Reconfiguaration by Partial Evaluation. </title> <booktitle> Symposium on Field-Programmable Custom Computing Machines, </booktitle> <year> 1996. </year>
Reference: [SoGluJo96] <author> Morten Srensen, Robert Gluck, Neil Jones. </author> <title> A Positive Supercom-piler. </title> <journal> Journal of Functional Programming, </journal> <volume> 6(6) </volume> <pages> 811-838. </pages>
Reference-contexts: The latter route leads to the technique of generalized partial computation <ref> [FuNoTa91, SoGluJo96] </ref>, wherein PE is extended with a theorem prover. Say we wrote bitcopy in bit-serial fashion, as in Figure 3.24. The rules of this chapter produce (assuming an 8-bit word for brevity) the obviously inefficient code in Figure 3.25.
Reference: [Sperber96] <author> Michael Sperber. </author> <title> Self-Applicable Online Partial Evaluation. </title> <booktitle> Dagstuhl Workshop on Partial Evaluation, </booktitle> <year> 1996. </year>
Reference-contexts: Ideally, in an offline system all perform-vs-emit decisions are made in the BTA, but in reality most offline systems include polyvariance, which involves value-dependent decisions. Further hybridization is explored in <ref> [Sperber96] </ref>. The system from chapter 4 memoizes on binding times and static values, so it is also a hybrid. As a result, procedure contents are treated offline, but procedure calls are treated online. The system in Section 5.3 is online. <p> At this point we call cogen to get the metastatic extension, and then jump to that. Because we memoize on binding times, this results in lazy compiler generation; cogen is called at compile time. In this way, Nitrous is a hybrid between offline and online systems like <ref> [Sperber96] </ref>. This was a big change conceptually, but a small change in terms of the code and what actually happens. There are two places where static extensions are created: static recursions and higher-order values.
Reference: [SpeThi95] <author> Michael Sperber, Peter Thiemann. </author> <title> The Essence of LR Parsing. Partial Evaluation and Semantics-Based Program Manipulation, </title> <year> 1995. </year>
Reference-contexts: It accepts and produces (and its compilers produce) programs written in an intermediate language similar to three-address code. This design allows low-overhead run-time code generation as well as multi-stage compiler 4 In fact, LR (k) parser generation is a special case of polyvariant compiler generation <ref> [Mossin93, SpeThi95] </ref>. 12 CHAPTER 1. INTRODUCTION generation (where one generates a compiler from an interpreter written in a language defined by another interpreter). This system is the subject of Chapter 4 and a previous paper [Draves96].
Reference: [SSOG93] <author> J Subhlok, J Stichnoth, D O'Hallaron, T Gross. </author> <title> Exploiting Task and Data Parallelism on a Multicomputer. </title> <booktitle> Principles and Practice of Parallel Programming, </booktitle> <year> 1993. </year>
Reference-contexts: This transformation eliminates intermediate data structures, as illustrated in Figure 3.23. Furthermore, optimizing compilers for numerical and data-parallel languages such as High Performance Fortran and NESL perform extensive analysis to determine how to divide the computation into passes, layout the data-structures in memory, and coordinate multiple processors <ref> [SSOG93, ChaBleFi91] </ref>. Partial evaluation alone does not solve these problems. Specializing map f (map g l) has no effect. Instead, my approach is to specify procedures directly in one pass, and use specialization to efficiently implement (f o g).
Reference: [Steele90] <author> Guy Steele. </author> <title> Common Lisp the Language. </title> <publisher> Digital Press 1990. BIBLIOGRAPHY 97 </publisher>
Reference-contexts: For reference, a typical value of for a C or ML compiler is 175,000 3 In the C and C++ programming world the lack of portable interfaces and the difficult nature of RTCG prevent more wide-spread use. However in the Common LISP world <ref> [Steele90] </ref>, use of RTCG (via eval, compile, and defmacro) is considered an essential advanced technique [Graham94]. While macro-expansion happens at compile time rather than run time, it is the form of metaprogramming that people today are most familiar with.
Reference: [SteLe95] <author> A Stepanov, M Lee. </author> <title> The Standard Template Library. </title> <institution> Hewlett Packard Labs HPL-95-11. </institution>
Reference-contexts: Tcc's ICODE backend performs basic optimizations such as instruction scheduling, peephole, and register allocation, resulting in between 1000 and 2500. The VCODE back-end uses macros to emit code in one pass; is between 100 and 500. Familiar compile-time systems for C include C++ templates <ref> [SteLe95] </ref> and parser generators such as yacc [Johnson75] 4 . However, as corroborated by the work in compiler generation for C [CHNNV96, Andersen94], we believe C's lack of static semantics makes these systems inherently more difficult to build, use, and understand.
Reference: [Thiemann96] <author> Peter Thiemann. </author> <title> Cogen in six lines. </title> <booktitle> International Conference on Functional Programming, </booktitle> <year> 1996. </year>
Reference-contexts: This chapter is generally a review of Partial Evaluation (PE) practice; [CoDa98] and [JoGoSe93] are the standard texts of the field and may be considered references of first resort. [Jones91] is a theoretical introduction to operational behavior of specializers, and [Jones88] provides a practical description of first-order PE. <ref> [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] </ref> are system descriptions. It also defines some domains [Reynolds97] and their associated metavariables. The language is a call-by-value -calculus extended with integer constants, primitives, conditionals, a lift annotation, and explicit types on abstractions. I use the typewriter face for the terms of the object language. <p> Reification is the opposite of reflection, that is, converting a value (possibly a function) into a corresponding text. Although reification is commonly available in debuggers and interpreters, not even Common LISP standardizes it. [FriWa84] defines and discusses these ideas in detail. Reification is sometimes called introspection <ref> [Thiemann96] </ref> Section 4. Root supports both reflection and reification. By supporting reflection we make code-producing functions first class. Nitrous takes this a step further by using reification to make the compiler-producing function first class: rather than working with files, cogen just maps procedures to procedures.
Reference: [ThoDa95] <author> Nicholas Thompson, Roger Dannenberg. </author> <title> Optimizing Software Synthesis Performance. </title> <booktitle> International Computer Music Conference, </booktitle> <year> 1995. </year>
Reference-contexts: These routines have a special case for bytes, otherwise they call load/store sample. The vectors are 200 words long. Cs68 uses three passes, and rgb2m1 uses ten. The code appears in Appendix A.4. <ref> [ThoDa95] </ref> analizes buffered audio synthesis when all the data fit into an on-chip cache. They find (and this is corroborated by anecdotal evidence) that buffering reduces bandwidth by about 30%, and the cost is fairly independent of the number of passes over the buffers.
Reference: [TMCSHL96] <author> D Tarditi, G Morrisett, P Cheng, C Stone, R Harper, P Lee. </author> <title> TIL: A Type-Directed Optimizing Compiler for ML. </title> <booktitle> Conference on Programming Language Design and Implementation, </booktitle> <year> 1996. </year>
Reference-contexts: Two factors that weigh against root: explicit types would simplify the implementation and formalization, and on some architectures good loops (e.g. PC-relative addressing or other special instructions) are difficult to produce. Using a language like the JVM [GoJoSte96], or one of the intermediate languages of <ref> [TMCSHL96] </ref> would leverage existing research. 4.2 The Compiler Generator Cogen is directly implemented (rather than produced by self-application), poly-variant in binding times (it allows multiple binding time patterns per source procedure), performs polyvariant specialization with memo-tables, and handles higher-order control flow. This section summarizes how cogen and its extensions work.
Reference: [Wadler88] <author> Philip Wadler. </author> <title> Deforestation: Transforming Programs to Eliminate Trees. </title> <booktitle> European Symposium on Programming, </booktitle> <year> 1988. </year>
Reference-contexts: This section give some examples and suggests how to achieve them. An important transformation on programs that process streams of data is loop fusion. In the functional language community, a general form of this optimization is known as deforestation <ref> [Wadler88] </ref>. This transformation eliminates intermediate data structures, as illustrated in Figure 3.23. Furthermore, optimizing compilers for numerical and data-parallel languages such as High Performance Fortran and NESL perform extensive analysis to determine how to divide the computation into passes, layout the data-structures in memory, and coordinate multiple processors [SSOG93, ChaBleFi91].
Reference: [WCRS91] <author> Daniel Weise, Roland Conybeare, Erik Ruf, Scott Seligman. </author> <title> Automatic online program specialization. </title> <booktitle> International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <year> 1991. </year> <note> 98 BIBLIOGRAPHY </note>
Reference-contexts: In practice, specializers do less work than is possible in order to avoid code-space explosion. The annotations and heuristics used to decide when to stop working are the subject of Section 2.2. Partial evaluation (PE) as described in <ref> [JoGoSe93, Consel88, WCRS91] </ref> is a syntax-directed, semantics-based, source-to-source program transformation that performs specialization. Although we say automatic, in fact some human input in the form of hints or annotations has proven necessary. One of the primary applications of PE is compiler generation, frequently abbreviated cogen. <p> This chapter is generally a review of Partial Evaluation (PE) practice; [CoDa98] and [JoGoSe93] are the standard texts of the field and may be considered references of first resort. [Jones91] is a theoretical introduction to operational behavior of specializers, and [Jones88] provides a practical description of first-order PE. <ref> [WCRS91, Consel88, Thiemann96, BoDa91, BiWe93] </ref> are system descriptions. It also defines some domains [Reynolds97] and their associated metavariables. The language is a call-by-value -calculus extended with integer constants, primitives, conditionals, a lift annotation, and explicit types on abstractions. I use the typewriter face for the terms of the object language. <p> But if e is static, then lifting r prevents the simple static result we surely want. Nitrous and Schism use lift languages to give the programmer conditional lifting. Basically they work by reifying binding times. Other systems such as <ref> [WCRS91] </ref> contain analyses that identify and perform this lift, but miss-identify others. I believe that full automation (i.e. elimination of lift from the input language) is not yet feasible; binding-time and staging systems need some kind of manual control. 2.2.
References-found: 79

