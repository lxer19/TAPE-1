URL: http://www.cs.utexas.edu/users/less/compilers/chambers-pldi95.ps
Refering-URL: http://www.cs.utexas.edu/users/less/compiler.html
Root-URL: 
Note: Appeared in SIGPLAN95: Confer ence on Pr ogramming Language Design and Implementation (PLDI 95), June 1995. Abstract  
Abstract: Dynamic dispatching is a major source of runtime overhead in objectoriented languages, due both to the direct cost of method lookup and to the indirect effect of preventing other optimizations. To reduce this overhead, optimizing compilers for objectoriented languages analyze the classes of objects stored in program variables, with the goal of bounding the possible classes of message receivers enough so that the compiler can uniquely determine the tar get of a message send at compile time and replace the message send with a direct procedure call. Specialization is one important technique for improving the precision of this static class information: by compiling multiple versions of a method, each applicable to a subset of the possible ar gument classes of the method, more precise static information about the classes of the methods arguments is obtained. Previous specialization strategies have not been selective about where this technique is applied, and therefore tended to significantly increase compile time and code space usage, particularly for lar ge applications. In this paper, we present a more general framework for specialization in objectoriented languages and describe a goal-directed specialization algorithm that makes selective decisions to apply specialization to those cases where it provides the highest benefit. Our results show that our algorithm improves the performance of a group of sizeable programs by 65% to 275% while increasing compiled code space requirements by only 4% to 10%. Moreover, when compared to the previous state-of-the-art specialization scheme, our algorithm improves performance by 11% to 67% while simultaneously reducing code space requirements by 65% to 73%. 
Abstract-found: 1
Intro-found: 1
Reference: [Amiel et al. 94] <author> Eric Amiel, Olivier Gruber, and Eric Simon. </author> <title> Optimizing Multi-Method Dispatch Using Compressed Dispatch Tables. </title> <booktitle> In Proceedings OOPSLA 94, </booktitle> <pages> pages 244258, </pages> <address> Portland, Oregon, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: If the runtime system does not already support multi-methods, it must be extended to support them. A number of ef ficient strategies for multi-method lookup have been devised, including trees of single dispatch tables [Kiczales & Rodriguez 89], compressed multi-method dispatch tables <ref> [Chen et al. 94, Amiel et al. 94] </ref>, and polymorphic inline caches extended to support multiple ar guments [Hlzle et al. 91].
Reference: [Chambers & Ungar 89] <author> Craig Chambers and David Ungar. </author> <title> Customization: Optimizing Compiler Technology for Self, A Dynamically-Typed Object-Oriented Programming Language. </title> <journal> SIGPLAN Notices, </journal> <volume> 24(7):146160, </volume> <month> July </month> <year> 1989. </year> <booktitle> In Proceedings of the ACM SIGPLAN 89 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Customization is a simple specialization scheme used in the implementations of some objectoriented languages, including Self <ref> [Chambers & Ungar 89, Hlzle & Ungar 94] </ref>, Sather [Lim & Stolcke 91], and Trellis [Kilian 88]: a specialized version of each method is compiled for each class inheriting the method. <p> In the presence of lar ge, reusable libraries, we expect applications to use only a subset of the available classes and operations, and some of those only infrequently , and consequently simple customization is likely to be impractical. In systems employing dynamic compilation, such as the Self system <ref> [Chambers & Ungar 89] </ref>, customization can be done lazily by delaying the creation of a specialized version of a method until the particular specialized instance is actually needed at runtime, if at all.
Reference: [Chambers & Ungar 91] <author> Craig Chambers and David Ungar. </author> <title> Making Pure Object-Oriented Languages Practical. </title> <booktitle> In Proceedings OOPSLA 91, </booktitle> <pages> pages 115, </pages> <month> November </month> <year> 1991. </year> <journal> Published as ACM SIGPLAN Notices, </journal> <volume> volume 26, number 11. </volume>
Reference-contexts: Base Intraprocedural class analysis, inlining, splitting, CSE & constant propagation & folding, dead code elimination (to optimize away unneeded closure creations), and hard-wired class prediction for a small number of common messages such as if and +.This set of optimizations is roughly comparable to that performed by the Self-91 compiler <ref> [Chambers & Ungar 91] </ref>. The compiler produces one compiled version for each source method. Cust Base + simple customization: specialize each method for each inheriting class for the receiver argument. This corresponds to the approach take by the implementations of Sather, Trellis, and Self. <p> Our selective specialization algorithm increased code space by only 4-10% for the benchmarks, despite achieving the highest runtime performance. For lar ger programs, selective specialization may be the only practical specialization strategy in a statically-compiled system. 5 Related Work The implementations of Self <ref> [Chambers & Ungar 91] </ref>, Trellis [Kilian 88], and Sather [Lim & Stolcke 91] use customization to provide the compiler with additional information about the class of the receiver argument to a method, allowing many message sends within each customized version of the method to be statically-bound.
Reference: [Chambers 92] <author> Craig Chambers. </author> <title> The Design and Implementation of the SELF Compiler, an Optimizing Compiler for Object-Oriented Programming Languages. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <month> March </month> <year> 1992. </year>
Reference-contexts: Because sends to self tend to be fairly common in objectoriented programs, customization is ef fective at increasing execution performance: Self code runs 1.5 to 5 times faster as a result of customization, and customization was one of the single most important optimizations included in the Self compiler <ref> [Chambers 92] </ref>. Lea handsimulated customization in C++ for a Matrix class hierarchy, showing an order of-magnitude speedup, and ar gued for the inclusion of customization in C++ implementations [Lea 90].
Reference: [Chambers 93] <author> Craig Chambers. </author> <title> The Cecil Language: Specification and Rationale. </title> <type> Technical Report TR-93-03-05, </type> <institution> Department of Computer Science and Engineering. University of Washington, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: lead to a significant reduction in code space requirements over a system that employs simple customization. 4 Performance Evaluation To evaluate the ef fectiveness of our algorithm, we implemented several different specialization schemes in the context of the V ortex compiler for Cecil, a pure objectoriented language based on multi-methods <ref> [Chambers 93] </ref>. The implementation of our algorithm constructs a weighted call graph from profiles of the program and then generates a list of specialization directives using our algorithm. The compiler then executes the directives to produce the specialized versions of methods.
Reference: [Chambers et al. 89] <author> Craig Chambers, David Ungar, and Elgin Lee. </author> <title> An Efficient Implementation of SELF a Dynamically-Typed Object-Oriented Language Based on Prototypes. </title> <booktitle> In Proceedings OOPSLA 89, </booktitle> <pages> pages 4970, </pages> <month> October </month> <year> 1989. </year> <journal> Published as ACM SIGPLAN Notices, </journal> <volume> volume 24, number 10. </volume>
Reference-contexts: Some compilers for objectoriented languages implement a restricted form of specialization called customization, in which a specialized version of a method is compiled for each possible receiver class, and methods are never specialized for ar guments other than the receiver <ref> [Chambers et al. 89] </ref>. Although this strategy yields substantial performance improvements, it can also lead to a substantial increase in code size, especially for lar ge programs with deep inheritance hierarchies and a large number of methods.
Reference: [Chambers et al. 95] <author> Craig Chambers, Jeffrey Dean, and David Grove. </author> <title> A Framework for Selective Recompilation in the Presence of Complex Intermodule Dependencies. </title> <booktitle> In 17th International Conference on Software Engineering, </booktitle> <address> Seattle, WA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: This invalidates all information (including compiled code modules) that depended on the changed source information. Further details of this dependency representation and measurements of the amount of recompilation required for a 3-week period of programming can be found elsewhere <ref> [Chambers et al. 95] </ref>. 3.7.2 Gathering and Managing Profile Information Obtaining the profile data needed by the specialization algorithm requires that the program executable be built with the appropriate instrumentation.
Reference: [Chen et al. 94] <author> Weimin Chen, Volker Turau, and Wolfgang Klas. </author> <title> Efficient Dynamic Look-up Strategy for Multi-Methods. </title> <editor> In M. Tokoro and R. Pareschi, editors, </editor> <booktitle> Proceedings ECOOP 94, </booktitle> <pages> pages 408431, </pages> <address> Bologna, Italy, July 1994. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: If the runtime system does not already support multi-methods, it must be extended to support them. A number of ef ficient strategies for multi-method lookup have been devised, including trees of single dispatch tables [Kiczales & Rodriguez 89], compressed multi-method dispatch tables <ref> [Chen et al. 94, Amiel et al. 94] </ref>, and polymorphic inline caches extended to support multiple ar guments [Hlzle et al. 91].
Reference: [Cooper et al. 92] <author> Keith D. Cooper, Mary W. Hall, and Ken Kennedy. </author> <title> Procedure Cloning. </title> <booktitle> In Proceedings of 1992 IEEE International Conference on Computer Languages, </booktitle> <pages> pages 96 105, </pages> <address> Oakland, CA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Cooper, Hall, and Kennedy present a general framework for identifying when creating multiple, specialized copies of a procedure can provide additional information for solving interprocedural dataow optimization problems <ref> [Cooper et al. 92] </ref>.
Reference: [Dean & Chambers 94] <author> Jeffrey Dean and Craig Chambers. </author> <title> Towards Better Inlining Decisions Using Inlining Trials. </title> <booktitle> In Proceedings of the ACM Conference on LISP and Functional Programming 94, </booktitle> <pages> pages 273282, </pages> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Due to the indirect ef fects of optimizations such as inlining, the benefits of statically binding some message sends can be much higher than others. A more sophisticated heuristic could estimate the performance benefit of static binding, taking into account post-inlining optimizations <ref> [Dean & Chambers 94] </ref>. Third, the heuristic has no global view on the consumption of space during specialization. Alternatively , the algorithm could be provided with a fixed space budget, and could visit arcs in decreasing order of weight, specializing until the space budget was consumed.
Reference: [Dean et al. 95] <author> Jeffrey Dean, David Grove, and Craig Chambers. </author> <title> Optimization of Object-Oriented Programs Using Static Class Hierarchy Analysis. </title> <booktitle> In Proceedings ECOOP 95, </booktitle> <address> Aarhus, Denmark, </address> <month> August </month> <year> 1995. </year> <note> Springer-Verlag. </note>
Reference-contexts: For example, ApplicableClasses [[method E::m ()]] = &lt;-E,H,I-&gt;. For singly-dispatched languages, computing ApplicableClasses for each method is fairly straightforward. For multiply-dispatched languages, there are some subtleties in performing this computation efficiently; details of how this can be done can be found elsewhere <ref> [Dean et al. 95] </ref>. <p> The code space requirements of this configuration make it impractical for statically-compiled systems CHA Base + class hierarchy analysis. The class hierarchy of the whole program is examined to enable conversion of dynamically-bound calls to statically-bound calls when the compiler detects that there are no overriding methods <ref> [Dean et al. 95] </ref>. Selective CHA + our profile-guided selective specialization algorithm. <p> Specialization is only one technique for reducing dynamic-dispatching overhead in objectoriented programs. A number of other techniques have also demonstrated substantial performance improvements for programs with extensive dynamic dispatching, including whole-program class hierarchy analysis <ref> [Dean et al. 95] </ref>, profile-guided class prediction [Garrett et al. 94, Hlzle & Ungar 94], and interprocedural class inference [Palsber g & Schwartzbach 91, Plevyak & Chien 94].
Reference: [Garrett et al. 94] <author> Charlie Garrett, Jeffrey Dean, David Grove, and Craig Chambers. </author> <title> Measurement and Application of Dynamic Receiver Class Distributions. </title> <type> Technical Report UW-CS 94-03-05, </type> <institution> University of Washington, </institution> <month> March </month> <year> 1994. </year>
Reference-contexts: Additionally, for objectoriented programs we have observed that the kind of profile information needed to construct this call graph remains fairly constant across different inputs to a program and even as the program evolves <ref> [Garrett et al. 94] </ref>, so profiling can be done relatively infrequently and reused across many compilations. 3.7.3 Applicability to a Dynamic Compilation Environment Our algorithm is suitable for use in a dynamic compilation environment such as Self. <p> Specialization is only one technique for reducing dynamic-dispatching overhead in objectoriented programs. A number of other techniques have also demonstrated substantial performance improvements for programs with extensive dynamic dispatching, including whole-program class hierarchy analysis [Dean et al. 95], profile-guided class prediction <ref> [Garrett et al. 94, Hlzle & Ungar 94] </ref>, and interprocedural class inference [Palsber g & Schwartzbach 91, Plevyak & Chien 94].
Reference: [Grove & Torczon 93] <author> Dan Grove and Linda Torczon. </author> <title> Interprocedural Constant Propagation: A Study of Jump Function Implementations. </title> <journal> SIGPLAN Notices, </journal> <volume> 28(6):9099, </volume> <month> June </month> <year> 1993. </year> <booktitle> In Proceedings of the ACM SIGPLAN 93 Conference on Programming Language Design and Implementation. </booktitle>
Reference: [Hlzle & Ungar 94] <author> Urs Hlzle and David Ungar. </author> <title> Optimizing Dynamically-Dispatched Calls with Run-Time Type Feedback. </title> <journal> SIGPLAN Notices, </journal> <volume> 29(6):326336, </volume> <month> June </month> <year> 1994. </year> <booktitle> In Proceedings of the ACM SIGPLAN 94 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: Customization is a simple specialization scheme used in the implementations of some objectoriented languages, including Self <ref> [Chambers & Ungar 89, Hlzle & Ungar 94] </ref>, Sather [Lim & Stolcke 91], and Trellis [Kilian 88]: a specialized version of each method is compiled for each class inheriting the method. <p> Specialization is only one technique for reducing dynamic-dispatching overhead in objectoriented programs. A number of other techniques have also demonstrated substantial performance improvements for programs with extensive dynamic dispatching, including whole-program class hierarchy analysis [Dean et al. 95], profile-guided class prediction <ref> [Garrett et al. 94, Hlzle & Ungar 94] </ref>, and interprocedural class inference [Palsber g & Schwartzbach 91, Plevyak & Chien 94].
Reference: [Hlzle et al. 91] <author> Urs Hlzle, Craig Chambers, and David Ungar. </author> <title> Optimizing Dynamically-Typed Object-Oriented Languages With Polymorphic Inline Caches. </title> <editor> In P. America, editor, </editor> <booktitle> Proceedings ECOOP 91, </booktitle> <volume> LNCS 512, </volume> <pages> pages 2138, </pages> <address> Geneva, Switzerland, July 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: A number of ef ficient strategies for multi-method lookup have been devised, including trees of single dispatch tables [Kiczales & Rodriguez 89], compressed multi-method dispatch tables [Chen et al. 94, Amiel et al. 94], and polymorphic inline caches extended to support multiple ar guments <ref> [Hlzle et al. 91] </ref>. <p> The expense of profiling dynamically-dispatched message sends depends in lar ge part on the runtime systems message dispatching mechanism. Some systems, including the Cecil system in which we implemented the algorithm, use polymorphic inline caches <ref> [Hlzle et al. 91] </ref>: callsite-specific association lists mapping receiver classes to tar get methods.
Reference: [Ingalls 86] <author> Daniel H. H. Ingalls. </author> <title> A Simple Technique for Handling Multiple Polymorphism. </title> <booktitle> In Proceedings OOPSLA 86, </booktitle> <pages> pages 347349, </pages> <month> November </month> <year> 1986. </year> <journal> Published as ACM SIGPLAN Notices, </journal> <volume> volume 21, number 11. </volume>
Reference-contexts: Other arguments of the form Class::arg represent methods that are dispatched on multiple arguments (multi-methods). Alternatively, in a singly-dispatched language, they could be written in a double-dispatching style <ref> [Ingalls 86] </ref>. Dynamically-dispatched message sends are shown in this font.
Reference: [Jones et al. 93] <author> Neil D. Jones, Carstein K. Gomarde, and Peter Sestoft. </author> <title> Partial Evaluation and Automatic Program Generation. </title> <publisher> Prentice Hall, </publisher> <address> New York, NY, </address> <year> 1993. </year>
Reference-contexts: Finally, our algorithm exploits profile information to select only profitable specializations. Procedure specialization has been long incorporated as a principal technique in partial evaluation systems <ref> [Jones et al. 93] </ref>. Ruf, Katz, and Weise [Ruf & Weise 91, Katz & Weise 92] address the problem of avoiding overspecialization in their FUSE partial evaluator. Their work seeks to identify when two specializations generate the same code.
Reference: [Katz & Weise 92] <author> M. Katz and D. Weise. </author> <title> Towards a New Perspective on Partial Evaluation. </title> <booktitle> In Proceedings of the Workshop on Partial Evaluation and Semantics-Based Program Manipulation 92, </booktitle> <pages> pages 2936. </pages> <institution> Yale University, </institution> <year> 1992. </year>
Reference-contexts: Finally, our algorithm exploits profile information to select only profitable specializations. Procedure specialization has been long incorporated as a principal technique in partial evaluation systems [Jones et al. 93]. Ruf, Katz, and Weise <ref> [Ruf & Weise 91, Katz & Weise 92] </ref> address the problem of avoiding overspecialization in their FUSE partial evaluator. Their work seeks to identify when two specializations generate the same code.
Reference: [Kiczales & Rodriguez 89] <author> Gregor Kiczales and Luis Rodriguez. </author> <title> Efficient Method Dispatch in PCL. </title> <type> Technical Report SSL 89-95, </type> <institution> Xerox PARC Systems Sciences Laboratory, </institution> <year> 1989. </year>
Reference-contexts: If the runtime system does not already support multi-methods, it must be extended to support them. A number of ef ficient strategies for multi-method lookup have been devised, including trees of single dispatch tables <ref> [Kiczales & Rodriguez 89] </ref>, compressed multi-method dispatch tables [Chen et al. 94, Amiel et al. 94], and polymorphic inline caches extended to support multiple ar guments [Hlzle et al. 91].
Reference: [Kilian 88] <author> Michael F. Kilian. </author> <title> Why Trellis/Owl Runs Fast. </title> <type> Unpublished manuscript, </type> <month> March </month> <year> 1988. </year>
Reference-contexts: Customization is a simple specialization scheme used in the implementations of some objectoriented languages, including Self [Chambers & Ungar 89, Hlzle & Ungar 94], Sather [Lim & Stolcke 91], and Trellis <ref> [Kilian 88] </ref>: a specialized version of each method is compiled for each class inheriting the method. Within the customized version of a method, the exact class of the receiver is known, enabling the compiler to statically bind messages sent to the receiver formal parameter ( self). <p> Our selective specialization algorithm increased code space by only 4-10% for the benchmarks, despite achieving the highest runtime performance. For lar ger programs, selective specialization may be the only practical specialization strategy in a statically-compiled system. 5 Related Work The implementations of Self [Chambers & Ungar 91], Trellis <ref> [Kilian 88] </ref>, and Sather [Lim & Stolcke 91] use customization to provide the compiler with additional information about the class of the receiver argument to a method, allowing many message sends within each customized version of the method to be statically-bound.
Reference: [Lea 90] <editor> Doug Lea. Customization in C++. </editor> <booktitle> In Proceedings of the 1990 Usenix C++ Conference, </booktitle> <address> San Francisco, CA, </address> <month> April </month> <year> 1990. </year>
Reference-contexts: Lea handsimulated customization in C++ for a Matrix class hierarchy, showing an order of-magnitude speedup, and ar gued for the inclusion of customization in C++ implementations <ref> [Lea 90] </ref>. Unfortunately, this simple strategy for specialization suffers from the twin problems of overspecialization and underspecialization, because specialization is done without regard for its costs and benefits.
Reference: [Lim & Stolcke 91] <author> Chu-Cheow Lim and Andreas Stolcke. </author> <title> Sather Language Design and Performance Evaluation. </title> <type> Technical Report TR 91-034, </type> <institution> International Computer Science Institute, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: Customization is a simple specialization scheme used in the implementations of some objectoriented languages, including Self [Chambers & Ungar 89, Hlzle & Ungar 94], Sather <ref> [Lim & Stolcke 91] </ref>, and Trellis [Kilian 88]: a specialized version of each method is compiled for each class inheriting the method. <p> For lar ger programs, selective specialization may be the only practical specialization strategy in a statically-compiled system. 5 Related Work The implementations of Self [Chambers & Ungar 91], Trellis [Kilian 88], and Sather <ref> [Lim & Stolcke 91] </ref> use customization to provide the compiler with additional information about the class of the receiver argument to a method, allowing many message sends within each customized version of the method to be statically-bound.
Reference: [Palsberg & Schwartzbach 91] <author> Jens Palsberg and Michael I. Schwartzbach. </author> <title> Object-Oriented Type Inference. </title> <booktitle> In Proceedings OOPSLA 91, </booktitle> <pages> pages 146161, </pages> <month> November </month> <year> 1991. </year> <journal> Published as ACM SIGPLAN Notices, </journal> <volume> volume 26, number 11. </volume>
Reference: [Pande & Ryder 94] <author> Hemant D. Pande and Barbara G. Ryder. </author> <title> Static Type Determination for C++. </title> <booktitle> In Proceedings of Sixth USENIX C++ Technical Conference, </booktitle> <year> 1994. </year>
Reference: [Plevyak & Chien 94] <author> John Plevyak and Andrew A. Chien. </author> <title> Precise Concrete Type Inference for Object-Oriented Languages. </title> <booktitle> In Proceedings OOPSLA 94, </booktitle> <pages> pages 324340, </pages> <address> Portland, Oregon, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: A number of other techniques have also demonstrated substantial performance improvements for programs with extensive dynamic dispatching, including whole-program class hierarchy analysis [Dean et al. 95], profile-guided class prediction [Garrett et al. 94, Hlzle & Ungar 94], and interprocedural class inference <ref> [Palsber g & Schwartzbach 91, Plevyak & Chien 94] </ref>. All of these techniques are striving to eliminate dynamic dispatches and indirectly enable other optimizations, such as inlining, so it seems clear that the performance benefits of combining all of these techniques will not be strictly additive.
Reference: [Ruf & Weise 91] <author> E. Ruf and D. Weise. </author> <title> Using Types to Avoid Redundant Specialization. </title> <booktitle> In Proceedings of the Symposium on Partial Evaluation and Semantics-Based Program Manipulation 91, </booktitle> <pages> pages 321333. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: Finally, our algorithm exploits profile information to select only profitable specializations. Procedure specialization has been long incorporated as a principal technique in partial evaluation systems [Jones et al. 93]. Ruf, Katz, and Weise <ref> [Ruf & Weise 91, Katz & Weise 92] </ref> address the problem of avoiding overspecialization in their FUSE partial evaluator. Their work seeks to identify when two specializations generate the same code.
References-found: 26

