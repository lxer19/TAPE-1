URL: http://www.iscs.nus.sg/~liuh/critic.ps
Refering-URL: 
Root-URL: 
Email: fc.rowles, w.weng@trl.oz.au  
Title: Critics for Knowledge-Based Design Systems  
Author: H. Liu C.D. Rowles and W.X. Wen 
Keyword: Key Words: Knowledge-based Systems, Design, Critiquing, Knowledge Acquisition  
Address: 3168, Australia  
Affiliation: Artificial Intelligence Systems Telecom Research Laboratories Clayton, Vic.  
Abstract: Expert critics have been built to critique human performance in various areas such as engineering design, decision making, etc. We suggest that critics can also be useful in building and use of knowledge-based design systems (KBDSs). Knowledge engineers elicit knowledge from domain experts and build a knowledge-based design system. The system generates designs. The amount of knowledge the system possesses and the way it applies the knowledge directly influence the performance of its designs. Therefore, critics are proposed to assist (1) acquiring sufficient knowledge for constructing a desirable system, and (2) applying proper knowledge to generating designs. Methodologies of equipping a KBDS with critics are developed. Our practice in building and using a KBDS shows the applicability and capability of these critics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> John R. Anderson, C. Franklin Boyle, and Brian J. Reiser. </author> <title> Intelligent tutoring systems. </title> <journal> Science, </journal> <volume> 228 </volume> <pages> 456-462, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: Intelligent tutoring systems [18] also work on solutions and problems together, but they are for people who learn a new trade. These systems are designed and developed based on a relatively good understanding of domains and mastered skills. For example, the computer tutors of Anderson et al <ref> [1] </ref> were based on a set of pedagogical principles derived from ACT fl theory of cognition. In other words, the correct solutions are always known beforehand. In design, such knowledge is not available.
Reference: [2] <author> W.J. Clancey. </author> <title> Viewing knowledge bases as qualitative models. </title> <journal> IEEE Expert, </journal> <month> Summer, </month> <year> 1989. </year>
Reference-contexts: In general, like all models, knowledge bases are selective, based on assumptions, and prone to failure <ref> [2] </ref>. Biases, irrelevant or incomplete knowledge, misconceptions, and wrong assumptions are likely to be introduced into the system through these four processes and therefore affect the quality of the system's designs. Some effective means must be employed to reduce the likelihood of these factors being incorporated in a system.
Reference: [3] <editor> E.A. Feigenbaum and B.G. Buchanan. Dendral and meta-dendral: </editor> <title> roots of knowledge systems and expert system application. </title> <journal> Artificial Intelligence, </journal> <volume> 59(1 - 2), </volume> <year> 1993. </year>
Reference-contexts: All the four try to improve a KBDS by examining designs the KBDS produces. Moreover, Modify, Refine and ExpertExamine require the involvement of experts and/or knowledge engineers. Machine learning could be applied to knowledge base modification <ref> [3] </ref>, but it is outside the 8 scope of this paper. In the following, we will show the use of the critics in the construction and application of a practical KBDS called DS.
Reference: [4] <author> G. Fischer, A.C. Lemke, T. Mastaglio, and A.I. Morch. Critics: </author> <title> an emerging approach to knowledge-based human-computer interaction. </title> <journal> Int. J. Man-Machine Studies, </journal> <volume> 35(5) </volume> <pages> 695-721, </pages> <year> 1991. </year>
Reference-contexts: Expert critics were built to improve the performance of users [16]. Critics suggested by Fischer et al <ref> [4] </ref> are an important component of cooperative problem solving systems, especially when they are embedded in integrated design environments. A critic, by their definition, is a system that presents a reasoned opinion about a product or action generated by a human.
Reference: [5] <author> S. Kirkpatrick, C. D. Gellat, and M. P. Vecchi. </author> <title> Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220(4598) </volume> <pages> 671-680, </pages> <month> May </month> <year> 1983. </year>
Reference-contexts: In principle, the more problems studied, the more general the system could become. As is suggested in Algorithm 1, IS should be independent of DS. Our choice of IS is Simulated Annealing <ref> [5] </ref> that relies on an energy (cost) function, instead of the heuristics used in Algorithm 5 that are shown in Table 1 of section 3.2. This independent design system is called SA.
Reference: [6] <editor> D.B. Lenat and E.A. Feigenbaum. </editor> <booktitle> On the thresholds of knowledge. Artificial Intelligence, </booktitle> <pages> 47(1-3), </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: Too often, useful knowledge is omitted the adequacy problem. A critical question is how they can know if the knowledge obtained is sufficient for a given domain. Perfect knowledge is impossible to obtain, but sufficient knowledge is essential for a KBDS to succeed <ref> [6, 8] </ref>. In a moderately complex domain, it is difficult to find out what's missing, based on a handful of test cases. Increasing the number of cases studied can be time-consuming and is often impractical.
Reference: [7] <author> H. Liu, C.D. Rowles, and W. Wen. </author> <title> Design, evaluation and redesign. </title> <booktitle> In IEEE Conference on AI Applications, </booktitle> <month> March </month> <year> 1992. </year>
Reference-contexts: Such a method is expected to provide clues and directions to search for more knowledge and to reorganize knowledge. (2) Choosing proper knowledge As the knowledge accumulates in a particular design domain, we ultimately encounter the problem of choosing the most suitable knowledge for a particular case the application problem <ref> [7] </ref>. Not knowing all cases beforehand makes this problem extremely difficult. Heuristics employed by a KBDS may bring about global optimization. Carefully designed heuristic search may generally produce the expected results, but, it may also generate some unexpected (or poor) results in some cases.
Reference: [8] <author> H. Liu, W. Wen, </author> <title> and C.D. Rowles. Optimizing knowledge based system design. </title> <booktitle> In IEEE Conference on AI Applications, </booktitle> <month> February </month> <year> 1991. </year> <month> 21 </month>
Reference-contexts: Too often, useful knowledge is omitted the adequacy problem. A critical question is how they can know if the knowledge obtained is sufficient for a given domain. Perfect knowledge is impossible to obtain, but sufficient knowledge is essential for a KBDS to succeed <ref> [6, 8] </ref>. In a moderately complex domain, it is difficult to find out what's missing, based on a handful of test cases. Increasing the number of cases studied can be time-consuming and is often impractical.
Reference: [9] <author> D. G. Luenberger. </author> <title> Introduction to Linear and Nonlinear Programming. </title> <publisher> Addison-Wesley Pub. </publisher> <address> Comp., Reading, Massachusetts, </address> <year> 1973. </year>
Reference-contexts: The optimal design should, of course, have a minimal cost factor C. The choice of such a C is due to its simplicity and to that it reflects the nature of the underlying application <ref> [9] </ref>. It is noted that a linear cost factor is acceptable due to the presence of rules that have already selected between various possible designs such as minimum number of joints, etc. DS is rule-based, and SA is neural-network-based.
Reference: [10] <author> P.L. Miller. Attending: </author> <title> Critiquing a physician's management plan. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5 </volume> <pages> 449-61, </pages> <month> September </month> <year> 1983. </year>
Reference-contexts: Among many, an expert critic is one, which is a computer program that critiques human-generated solutions <ref> [10] </ref>. A survey of expert critics by Silverman [14] provides up-to-date work in the field. These critics have found many applications such 18 as decision making, engineering design, word processing, knowledge base acquisition, and software engineering.
Reference: [11] <author> D.L. Nazareth. </author> <title> Issues in the verification of rule-based systems. </title> <journal> Int. J. Man-Machine Studies, </journal> <volume> 30 </volume> <pages> 255-71, </pages> <year> 1989. </year>
Reference-contexts: Refining [13] is the process of fine tuning rules that discriminate between alternatives and help assure the validity of the resulting system within the model. When the knowledge is 19 incomplete, it is not suitable. Critiquing shares some similarities with verification <ref> [11] </ref>. Both attack the problems of knowledge redundancy and incompleteness.
Reference: [12] <author> C.D. Rowles, C. Leckie, H. Liu, and W. Wen. </author> <title> Automating the design of telecommunication distribution networks. </title> <booktitle> In International Conference on Artificial Intelligence in Design, </booktitle> <month> June </month> <year> 1991. </year>
Reference: [13] <author> D.L. Schmoldt. </author> <title> Refining rule bases for classification knowledge-based systems. </title> <journal> AI Applications, </journal> <volume> 3(3) </volume> <pages> 31-41, </pages> <year> 1989. </year>
Reference-contexts: The critics try to locate the differences between designs, and to find incorrectness or inconsistency of designs. Tutoring systems begin always with deviations of a solution from the standard one. Other relevant fields are the refinement and verification of knowledge-based systems. Refining <ref> [13] </ref> is the process of fine tuning rules that discriminate between alternatives and help assure the validity of the resulting system within the model. When the knowledge is 19 incomplete, it is not suitable. Critiquing shares some similarities with verification [11]. Both attack the problems of knowledge redundancy and incompleteness.
Reference: [14] <author> Barry G. Silverman. </author> <title> Survey of expert critiquing systems: Practical and theoretical frontiers. </title> <journal> Communications of the ACM, </journal> <volume> 35(4), </volume> <month> April </month> <year> 1992. </year>
Reference-contexts: Among many, an expert critic is one, which is a computer program that critiques human-generated solutions [10]. A survey of expert critics by Silverman <ref> [14] </ref> provides up-to-date work in the field. These critics have found many applications such 18 as decision making, engineering design, word processing, knowledge base acquisition, and software engineering. Expert critics scrutinize the solutions (e.g., designs) produced by humans in terms of clarity, coherence, correspondence, and workability tests. As defined in [14], <p> <ref> [14] </ref> provides up-to-date work in the field. These critics have found many applications such 18 as decision making, engineering design, word processing, knowledge base acquisition, and software engineering. Expert critics scrutinize the solutions (e.g., designs) produced by humans in terms of clarity, coherence, correspondence, and workability tests. As defined in [14], clarity means that all statements should be unambiguous; coherence deals with abstract truth, or the logical structure of statements; correspondence concerns the agreement of statements with reality; and workability means pragmatically verifying and validating a body of knowledge. Expert critics were built to improve the performance of users [16].
Reference: [15] <author> B.G. Silverman. </author> <title> Critiquing human judgment using knowledge-acquisition systems. </title> <journal> AI Magazine, </journal> <pages> pages 60-79, </pages> <month> Fall </month> <year> 1990. </year>
Reference-contexts: One way of implementing the critic is to build a strong model of a domain-trained knowledge engineer and to apply it to knowledge acquisition <ref> [15] </ref>. In general, we should try as strong a model as possible, to pool all available experts together, and to combine their expertise. When a domain is complex, building a strong model is a problem in itself.
Reference: [16] <author> B.G. Silverman and T.M. Mezher. </author> <title> Expert critics in engineering design: Lessons learned and research needs. </title> <journal> AI Magazine, </journal> <volume> 13(1), </volume> <month> Spring </month> <year> 1992. </year>
Reference-contexts: Expert critics were built to improve the performance of users <ref> [16] </ref>. Critics suggested by Fischer et al [4] are an important component of cooperative problem solving systems, especially when they are embedded in integrated design environments. A critic, by their definition, is a system that presents a reasoned opinion about a product or action generated by a human.
Reference: [17] <author> C. Tong and D. Sriram. </author> <title> Introduction. </title> <editor> In C. Tong and D. Sriram, editors, </editor> <booktitle> Artifical Intelligence in Engineering Design, </booktitle> <address> I,II,III. </address> <publisher> Academic Press, Inc., </publisher> <year> 1992. </year>
Reference-contexts: 1 Introduction Engineering design is a domain where a knowledge-based approach has often been adopted due to the very large number of factors that must be considered and the difficulty in accurately characterizing them <ref> [17] </ref>. A brute-force approach is out of the question for configuration design tasks due to its computational complexity. Experts design by following general rules, applying their knowledge, and using contextual sense and empirical insights. A knowledge-based design approach attempts to mechanically generate designs with reference to the behavior of experts.
Reference: [18] <author> E. </author> <title> Wenger. </title> <booktitle> Artificial Intelligence and Tutoring Systems. </booktitle> <publisher> Morgan Kaufman, </publisher> <address> Los Altos, </address> <year> 1987. </year>
Reference-contexts: Correctness and consistency checking critics are functioning in both stages. The alternative solution critic is only working in the second stage. The last three are used in a similar manner as are Fischer et al's critics, that is, being embedded in integrated design environments. Intelligent tutoring systems <ref> [18] </ref> also work on solutions and problems together, but they are for people who learn a new trade. These systems are designed and developed based on a relatively good understanding of domains and mastered skills.
References-found: 18

