URL: ftp://whitechapel.media.mit.edu/pub/tech-reports/TR-289.ps.Z
Refering-URL: http://www-white.media.mit.edu/cgi-bin/tr_pagemaker/
Root-URL: http://www.media.mit.edu
Email: popat@media.mit.edu picard@media.mit.edu  
Title: consensus in lossless image compression  
Author: Kris Popat and Rosalind W. Picard 
Address: 20 Ames St., Cambridge, MA 02139  
Affiliation: Room E15-383, The Media Laboratory Massachusetts Institute of Technology  
Note: Exaggerated  
Abstract: M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 289 Also appears in the Proceedings of the IEEE First International Conference on Image Processing, Austin, Texas, November 1994. Abstract Good probabilistic models are needed in data compression and many other applications. A good model must exploit contextual information, which requires high-order conditioning. As the number of conditioning variables increases, direct estimation of the distribution becomes exponentially more difficult. To circumvent this, we consider a means of adaptively combining several low-order conditional probability distributions into a single higher-order estimate, based on their degree of agreement. Though the technique is broadly applicable, image compression is singled out as a testing ground of its abilities. Good performance is demonstrated by experimental results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kris Popat and Rosalind W. </author> <title> Picard. A novel cluster-based probability model for texture synthesis, classification, and compression. </title> <booktitle> In Proc. SPIE Visual Communications '93, </booktitle> <address> Cambridge, Mass., </address> <year> 1993. </year>
Reference-contexts: In practice, however, there are difficulties with large neighborhoods. The difficulties can be traced to the fact that the number of possible values (states) of the neighborhood increases exponentially with neighborhood size. In previous papers we proposed a probability model that mitigates some of these difficulties <ref> [1, 2] </ref>. The model used clustering to summarize relevant information in the training data, and exploited the smoothness of the underlying probability law to effectively interpolate probability between conditioning states. When applied to lossless image compression, the technique allowed processing with large neighborhoods. <p> 4.71 4.06 3.93 reagan 7.32 4.76 4.52 4.51 4.13 4.12 tek-boat 7.59 6.08 5.66 5.61 5.58 5.52 tek-cute 6.96 4.68 4.71 4.73 4.15 4.12 tek-rose 7.41 6.77 6.04 5.87 5.92 5.82 vegas 7.49 4.62 4.48 4.46 4.23 4.23 wed 7.00 4.98 4.95 4.97 4.58 4.56 based kernel estimate (as in <ref> [1] </ref>) would be more appropriate. As a check, we repeated several of the compression experiments presented in this section using a cluster-based estimate, and found that the results were about the same. Different sets of estimates were obtained for each image being tested.
Reference: [2] <author> Kris Popat and Rosalind W. </author> <title> Picard. Cluster-based probability model applied to image restoration and compression. </title> <booktitle> In ICASSP-94: 1994 International Con 5 ference on Acoustics, Speech, and Signal Processing, </booktitle> <address> Adelaide, Australia, </address> <month> April </month> <year> 1994. </year> <note> IEEE. </note>
Reference-contexts: In practice, however, there are difficulties with large neighborhoods. The difficulties can be traced to the fact that the number of possible values (states) of the neighborhood increases exponentially with neighborhood size. In previous papers we proposed a probability model that mitigates some of these difficulties <ref> [1, 2] </ref>. The model used clustering to summarize relevant information in the training data, and exploited the smoothness of the underlying probability law to effectively interpolate probability between conditioning states. When applied to lossless image compression, the technique allowed processing with large neighborhoods. <p> Assume that fN j g are disjoint, so that each provides distinct contextual information about x. Since the neighborhoods are small, reliable estimates of p (xjN j ) are readily obtained in a variety of ways, for example by using the cluster-based probability model <ref> [2] </ref>. We therefore assume that such reliable estimates are available. We wish to estimate p (xjN ) by combining the small-neighborhood conditional PMF estimates in a manner consistent with the principles set forth in Sections 1 and 2.
Reference: [3] <author> Glen Langdon, Amit Gulati, and Ed Seiler. </author> <title> On the JPEG model for lossless image compression. </title> <booktitle> In Proc. IEEE Data Comp. Conf., </booktitle> <address> Utah, </address> <year> 1992. </year>
Reference-contexts: Compression schemes which preserve the image exactly are termed lossless. While lossy image compression systems typically compress by a factor of 10 or more while maintaining excellent image quality, lossless systems tend to give much worse compression factors (typically less than 2, see for example <ref> [3] </ref>). The exact amount of compression achieved depends on both the image's true statistical properties and the compression system's ability to exploit them. The first is beyond our control; the second is not.
Reference: [4] <author> Glen G. Langdon. </author> <title> An introduction to arithmetic coding. </title> <institution> IBM J. Res. Develop., </institution> <month> Mar. </month> <year> 1984. </year>
Reference-contexts: The first is beyond our control; the second is not. Consider the lossless compression system illustrated in quality of the PMF estimate provided to the arithmetic coder by the probability modeling unit for each pixel to be encoded <ref> [4] </ref>. Let x denote the next pixel to be encoded, and let X denote the set of values that can be assumed by x. For example, X = f0; : : : ; 255g.
Reference: [5] <author> Thomas Kailath. </author> <title> The divergence and Bhattacharyya distance measures in signal selection. </title> <journal> IEEE Trans. on Commun. Technology, </journal> <volume> COM-15(1):52-60, </volume> <month> Feb. </month> <year> 1967. </year>
Reference-contexts: To this end, we define a measure of agreement by summing the pointwise geometric mean of the conditional PMFs over x. This quantity, which we denote , can be recognized as the Bhattacharyya coefficient <ref> [5] </ref>: = x2X J Y p (xjN j ) : It is easy to verify that 0 1. When is close to unity, all of the conditional PMFs agree.
Reference: [6] <author> Kris Popat. </author> <title> Scalar quantization with arithmetic coding. </title> <type> Master's thesis, </type> <institution> Dept. of Elec. Eng. and Comp. Science, M.I.T., </institution> <address> Cambridge, Mass., </address> <year> 1990. </year> <month> 6 </month>
Reference-contexts: All are 8-bit monochrome, 512 fi 512, except for cman, which is 8-bit monochrome 256 fi 256. ous experience with arithmetic coding leads us to believe that these estimates are reliable predictors of actual performance, typically accurate to within a tenth of a bit per pixel <ref> [6] </ref>. Note that both the arithmetic and geometric means provide significant improvement over using p (xjN 1 ) alone. The geometric mean has a slight advantage over the arithmetic mean, in accordance with Principle 1.
References-found: 6

