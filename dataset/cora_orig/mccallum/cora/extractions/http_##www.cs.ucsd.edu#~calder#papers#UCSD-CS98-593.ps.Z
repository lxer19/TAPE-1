URL: http://www.cs.ucsd.edu/~calder/papers/UCSD-CS98-593.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~calder/papers.html
Root-URL: http://www.cs.ucsd.edu
Title: Profile Guided Load Marking for Memory Renaming  
Author: Glenn Reinman Brad Calder Dean Tullsen Gary Tyson Todd Austin 
Affiliation: Department of Computer Science and Engineering University of California, San Diego Electrical Engineering and Computer Science Department, University of Michigan Microcomputer Research Labs, Intel Corporation  
Abstract: UCSD Technical Report CS98-593, July 1998 Abstract Memory operations remain a significant bottleneck in dynamically scheduled pipelined processors, due in part to the inability to statically determine the existence of memory address dependencies. Hardware memory renaming techniques have been proposed which predict which stores a load might be dependent upon. These prediction techniques can be used to speculatively forward a value from a predicted store dependency to a load through a value prediction table; however, these techniques require large and time-consuming hardware tables. In this paper we propose a software-guided approach for identifying dependencies between store and load instructions and the Load Marking (LM) architecture to communicate these dependencies to the hardware. Compiler analysis and profiles are used to find important store/load relationships, and these relationships are identified during execution via hints or an n-bit tag. For those loads that are not marked for renaming, we then use additional profiling information to further classify the loads into those that have accurate value prediction and those that are largely independent of neighboring stores. These classifications allow the processor to apply the most appropriate aggressive form of execution for each load individually, minimizing the need for expensive recovery action. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. M. Anderson, L. M. Berc, J. Dean, S. G. Ghemawat, M. R. Henzinger, S-T. A. Leung, R. L. Sites, M.T. Vandevoorde, C. A. Waldspurger, W. E. Weihl, and G. Chrysos. </author> <title> Continous profiling: </title> <booktitle> Where have all the cycles gone? In Proceedings of the Sixteenth ACM Symposium on Operating System Principles, </booktitle> <month> October </month> <year> 1997. </year>
Reference: [2] <author> D.C. </author> <title> Burger and T.M. Austin. The simplescalar tool set, version 2.0. </title> <type> Technical Report CS-TR-97-1342, </type> <institution> University of Wisconsin, Madison, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: During our profiles, we collected data on temporal ordering of dependencies, the size of the MRT candidate set, the average number of stores upon which a load depends, and other useful metrics. The simulators used in this study are derived from the SimpleScalar/AXP tool set <ref> [2] </ref>, a suite of functional and timing simulation tools for the Alpha AXP ISA.
Reference: [3] <author> B. Calder, P. Feller, and A. Eustace. </author> <title> Value profiling. </title> <booktitle> In 30th International Symposium on Microarchitecture, </booktitle> <pages> pages 259269, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: Further work has looked at predicting the value of instructions using stride and context predictors [24, 21]. Recent research has shown that instruction values have predictable behavior between different inputs <ref> [3, 9] </ref>. These studies showed that profiling can be used to accurately guide last value prediction. <p> For the load instructions, we found the store list for most loads only contained a few important stores. Once these stores and the relative importance between the stores are found during profiling, profiling for a load instruction can be turned off as in convergent profiling <ref> [3] </ref>.
Reference: [4] <author> B. Calder, P. Feller, and A. Eustace. </author> <title> Value profiling and optimization. </title> <type> Technical Report UCSD-CS98-592, </type> <institution> University of California, </institution> <address> San Diego, </address> <month> July </month> <year> 1998. </year>
Reference-contexts: Prior research has shown that using sampling or convergent profiling for gathering similar profiling data can reduce the profiling cost to be smaller than a 10 time slow down, while still generating accurate profiling information <ref> [4] </ref>. 5 Identifying Loads and Stores for Memory Renaming The profile data described in the previous section characterizes each load in several ways, including its potential for renaming success. This section describes the process of translating the profile information into specific load marking and tagging decisions.
Reference: [5] <author> G. Chrysos and J. Emer. </author> <title> Memory dependence prediction using store sets. </title> <booktitle> In 25th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 142153, </pages> <month> June </month> <year> 1998. </year> <month> 28 </month>
Reference-contexts: Future processors will require more aggressive and speculative dynamic scheduling techniques to achieve high ILP. Hardware schemes have been proposed which enable load instructions to speculatively execute before stores, checking for mis-speculation by comparing their addresses in a later stage of the pipeline <ref> [11, 17, 5] </ref>. In fact, many current processors, such as the DEC Alpha 21264 [12] already contain hardware to predict that a load is not dependent upon any prior stores, allowing it to speculatively issue. <p> Moshovos et al. [17] proposed using hardware buffers to find store/load dependencies to provide selective speculation and to synchronize memory dependencies. Chyros and Emer <ref> [5] </ref> proposed using store sets to dynamically predict the exact store a load is dependent upon. Existing architectures, such as the DEC Alpha 21264, provide a simple but very accurate form of independence prediction.
Reference: [6] <author> T.M. Conte, K.N. Menezes, P.M. Mills, and B.A. Patel. </author> <title> Optimization of instruction fetch mechanisms for high issue rates. </title> <booktitle> In Proceedings of the 22nd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 333344, </pages> <address> Santa Margherita Ligure, Italy, </address> <month> June 2224, </month> <year> 1995. </year> <journal> ACM SIGARCH and IEEE Computer Society TCCA. </journal>
Reference-contexts: Our baseline simulation configuration models a future generation micro-architecture. We've selected the parameters to capture two underlying trends in micro-architecture design which serve to reinforce the benefits of our Load Marking architecture. First, the model has an aggressive fetch stage, employing a variant of the collapsing buffer <ref> [6] </ref>. The fetch unit can deliver two basic blocks from the I-cache per fetch cycle. If future generation micro-architectures wish to exploit more ILP, they will have to employ aggressive fetch designs like this or one that is comparable, such as the trace cache [20].
Reference: [7] <author> M. Franklin and G. S. Sohi. Arb: </author> <title> A hardware mechanism for dynamic reordering of memory references. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 46(5), </volume> <month> May </month> <year> 1996. </year>
Reference-contexts: Hardware solutions for these problems have been proposed, each showing improvements in processor performance. 2.1 Memory Address Disambiguation A number of dynamic memory disambiguation techniques have been proposed to improve the accuracy of dependence speculation <ref> [10, 7, 19] </ref>. The Memory Conflict Buffer (MCB) proposed by Gallagher et al. [10] provides a hardware solution with compiler support to allow load instructions to speculatively execute before stores. The addresses of speculative loads are stored with a conflict bit in the MCB. <p> They used value profiling to identify the load instructions to speculate, and they used value prediction hardware to predict the value of the speculated load instruction. A pure hardware approach for speculative load execution proposed by Franklin and Sohi <ref> [7] </ref>, called the Address Resolution Buffer (ARB), directs memory references to bins based on their address and uses the bins to enforce a temporal order among references to the same address.
Reference: [8] <author> C. Fu, M.D. Jennings, S.Y. Larin, </author> <title> and T.M. Conte. Value speculation scheduling for high performance processors. </title> <booktitle> In Eigth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1998. </year> <note> (to appear). </note>
Reference-contexts: They allow loads to be speculatively scheduled above stores, and in addition they execute the load in its original location. They then check the value of the speculative load with the correct value. If they are different a recovery sequence must be executed. Chao-ying et al. <ref> [8] </ref> examined a technique similar to Moudgill and Moreno, where they speculate a load and its dependent instructions, and then re-execute the load in its original place performing fix up code if the values are different.
Reference: [9] <author> F. Gabbay and A. Mendelson. </author> <booktitle> Can program profiling support value prediction? In 30th International Symposium on Microarchitecture, </booktitle> <pages> pages 270280, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: Further work has looked at predicting the value of instructions using stride and context predictors [24, 21]. Recent research has shown that instruction values have predictable behavior between different inputs <ref> [3, 9] </ref>. These studies showed that profiling can be used to accurately guide last value prediction. <p> Loads marked for value prediction use their PC to directly index into the value table. These loads blindly value predict using the value stored in the table entry, ignoring all renaming. It is similar to the scheme proposed in <ref> [14, 9] </ref>. However, since this scheme selectively predicts only those loads which are designated as candidates for memory renaming or value prediction, there is much lower contention among predicted instructions for entries in the value table and a much higher prediction accuracy.
Reference: [10] <author> D.M. Gallagher, W.Y. Chen, S.A. Mahlke, J.C. Gyllenhaal, and W.W. Hwu. </author> <title> Dynamic memory disambiguation using the memory conflict buffer. </title> <booktitle> In Six International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 183193, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: Hardware solutions for these problems have been proposed, each showing improvements in processor performance. 2.1 Memory Address Disambiguation A number of dynamic memory disambiguation techniques have been proposed to improve the accuracy of dependence speculation <ref> [10, 7, 19] </ref>. The Memory Conflict Buffer (MCB) proposed by Gallagher et al. [10] provides a hardware solution with compiler support to allow load instructions to speculatively execute before stores. The addresses of speculative loads are stored with a conflict bit in the MCB. <p> Hardware solutions for these problems have been proposed, each showing improvements in processor performance. 2.1 Memory Address Disambiguation A number of dynamic memory disambiguation techniques have been proposed to improve the accuracy of dependence speculation [10, 7, 19]. The Memory Conflict Buffer (MCB) proposed by Gallagher et al. <ref> [10] </ref> provides a hardware solution with compiler support to allow load instructions to speculatively execute before stores. The addresses of speculative loads are stored with a conflict bit in the MCB.
Reference: [11] <author> K. Gharachorloo, A. Gupta, and J. Hennessy. </author> <title> Two techniques to enhance the performance of memory consistency models. </title> <booktitle> In International Conference on Parallel Processing, </booktitle> <pages> pages 245257, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Future processors will require more aggressive and speculative dynamic scheduling techniques to achieve high ILP. Hardware schemes have been proposed which enable load instructions to speculatively execute before stores, checking for mis-speculation by comparing their addresses in a later stage of the pipeline <ref> [11, 17, 5] </ref>. In fact, many current processors, such as the DEC Alpha 21264 [12] already contain hardware to predict that a load is not dependent upon any prior stores, allowing it to speculatively issue. <p> It predicts whether or not a load's address is aliased with any prior store address. If the architecture predicts the load has no alias, the load will speculatively issue even before all prior store addresses have been calculated. Kourosh et al. <ref> [11] </ref> proposed blindly speculating loads (always predicting that there are no store aliases), applying this prediction in the presence of memory consistency. They showed that the common case is for a load to be independent of prior stores.
Reference: [12] <author> R.E. Kessler, E.J. McLellan, and D.A. Webb. </author> <title> The alpha 21264 microprosessor architecture. </title> <booktitle> In Proceedings of ICCD, </booktitle> <month> December </month> <year> 1998. </year> <note> (to appear). </note>
Reference-contexts: Hardware schemes have been proposed which enable load instructions to speculatively execute before stores, checking for mis-speculation by comparing their addresses in a later stage of the pipeline [11, 17, 5]. In fact, many current processors, such as the DEC Alpha 21264 <ref> [12] </ref> already contain hardware to predict that a load is not dependent upon any prior stores, allowing it to speculatively issue. If the address of a prior store is the same, then the load instruction has to re-execute. <p> Existing architectures, such as the DEC Alpha 21264, provide a simple but very accurate form of independence prediction. The 21264 uses a Wait Table to record the load instructions that have been found to be dependent upon a prior store <ref> [12] </ref>. If a load is found to be dependent upon a store, then its corresponding bit in the load table indexed by the instruction address is set. <p> To examine how this simple static predictor would perform, we compared it to 1-bit hardware techniques for independence prediction. We compared the static prediction to using a Wait Table, similar to the DEC Alpha 21264 architecture <ref> [12] </ref>, and we also compared it to simply using Blind independence prediction. We implemented the Wait Table architecture by associating one prediction bit with every instruction in the cache. If the bit is clear then a load would be speculatively executed.
Reference: [13] <author> D. Levitan, T. Thomas, and P. Tu. </author> <title> The powerpc 620 microprocessor: A high performance superscalar risc microprocessor. </title> <booktitle> In Proceedings of Spring CompCon, </booktitle> <year> 1995. </year>
Reference-contexts: The technique we simulate is similar to the load/store disambiguation methods used by the Pentium Pro [16] or the Power PC-620 <ref> [13] </ref>. Loads are stalled until all earlier store addresses are known. Once all earlier store addresses are available, the disambiguator can determine if the load value should be forwarded from a store in the store buffer or from the data cache.
Reference: [14] <author> M. H. Lipasti, C. B. Wilkerson, and J. P. Shen. </author> <title> Value locality and load value prediction. </title> <booktitle> In 17th International Conference on Architectural Support for Programming Languages and operating Systems, </booktitle> <pages> pages 138147, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: When the load executes, if the bit is not set then the load will speculatively issue, otherwise it will wait for all prior store addresses to complete before issuing. 2.3 Value Prediction Lipasti et al. <ref> [14] </ref> describe a mechanism in which the value of a load instruction is predicted based on the previous values loaded by that instruction. <p> Loads marked for value prediction use their PC to directly index into the value table. These loads blindly value predict using the value stored in the table entry, ignoring all renaming. It is similar to the scheme proposed in <ref> [14, 9] </ref>. However, since this scheme selectively predicts only those loads which are designated as candidates for memory renaming or value prediction, there is much lower contention among predicted instructions for entries in the value table and a much higher prediction accuracy.
Reference: [15] <author> S. McFarling. </author> <title> Combining branch predictors. </title> <type> Technical Report TN-36, </type> <institution> Digital Equipment Corporation, Western Research Lab, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: us to believe these effects are not large enough to justify two tables. 17 Fetch Interface delivers two basic blocks per cycle, but no more than 8 instructions total Instruction Cache 32k 2-way set-associative, 32 byte blocks, 6 cycle miss latency Branch Predictor hybrid - 8-bit gshare w/ 16k predictors <ref> [15] </ref> + 16k bimodal predictors 8 cycle mis-prediction penalty (minimum) Out-of-Order Issue out-of-order issue of up to 16 operations per cycle, 512 entry re-order buffer, 256 entry Mechanism load/store queue, loads may execute when all prior store addresses are known Architected Registers 32 integer, 32 floating point Functional Units 16-integer ALU,
Reference: [16] <institution> Intel boosts pentium pro to 200 mhz. </institution> <type> Microprocessor Report, 9(17), </type> <month> June </month> <year> 1995. </year>
Reference-contexts: The technique we simulate is similar to the load/store disambiguation methods used by the Pentium Pro <ref> [16] </ref> or the Power PC-620 [13]. Loads are stalled until all earlier store addresses are known. Once all earlier store addresses are available, the disambiguator can determine if the load value should be forwarded from a store in the store buffer or from the data cache.
Reference: [17] <author> A. Moshovos, S. E. Breach, T. N. Vijaykumar, and G. S. Sohi. </author> <title> Dynamic speculation and synchronization of data dependences. </title> <booktitle> In 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 181193, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Future processors will require more aggressive and speculative dynamic scheduling techniques to achieve high ILP. Hardware schemes have been proposed which enable load instructions to speculatively execute before stores, checking for mis-speculation by comparing their addresses in a later stage of the pipeline <ref> [11, 17, 5] </ref>. In fact, many current processors, such as the DEC Alpha 21264 [12] already contain hardware to predict that a load is not dependent upon any prior stores, allowing it to speculatively issue. <p> They showed that the common case is for a load to be independent of prior stores. Recently several hardware techniques have been proposed to more accurately identify which loads are independent of prior stores and even which store a load might be dependent upon. Moshovos et al. <ref> [17] </ref> proposed using hardware buffers to find store/load dependencies to provide selective speculation and to synchronize memory dependencies. Chyros and Emer [5] proposed using store sets to dynamically predict the exact store a load is dependent upon.
Reference: [18] <author> A. Moshovos and G.S. Sohi. </author> <title> Streamlining inter-operation memory communication via data dependence prediction. </title> <booktitle> In 30th International Symposium on Microarchitecture, </booktitle> <pages> pages 235245, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: If the dependencies could be determined early in the pipeline then the mis-speculations could be avoided. Two hardware approaches were recently proposed that also find dependencies between the load and store instructions and then use these dependencies during the fetch stage of the processor for Memory Renaming <ref> [18, 23] </ref>. The hardware would predict which loads were dependent upon stores to provide accurate value prediction and to enable loads to bypass memory by communicating the value of the store directly to the load instruction. These hardware techniques were successful at finding store/load dependencies. <p> When MRT tags are used, the tags are assigned by the compiler and are contained within the store and load instruction. A store and load with the same tag are mapped to the same value prediction entry in a table similar to those proposed in <ref> [18, 23] </ref>. Other loads are marked as either candidates for load value prediction or aggressive speculation based on program profiles. By only applying the appropriate optimization to each load, mis-speculations are reduced dramatically. <p> These studies showed that profiling can be used to accurately guide last value prediction. Our research extends these profile-guided techniques by not only predicting the value for load instructions, but also predicting load/store relationships and memory address disambiguation via profiling. 5 2.4 Memory Renaming Research by Moshovos et al <ref> [18] </ref> and Tyson and Austin [23] found that memory communication between store and load instructions can be accurately predicted in hardware. Both of these approaches used special store caches to find the load/store dependencies, and then an additional buffer to record the relationships found. <p> profiles to find dependencies between store and load instructions, and uses memory rename tags (MRT) to directly forward values from a store to a load instruction. 3.1.1 Load Marking Hints for Hardware Memory Renaming Compiler hints can improve the performance of the memory renaming architectures proposed by Moshovos and Sohi <ref> [18] </ref> and Tyson and Austin [23]. Stores and loads that are found via profiling/compiler analysis to benefit from memory renaming (MR) are marked for renaming. Loads which benefit more from value prediction are marked for value prediction, and all other loads are marked as non-speculative.
Reference: [19] <author> M. Moudgill and J. H. Moreno. </author> <title> Run-time detection and recovery from incorrectly reordered memory operations. </title> <institution> IBM Research Report, (RC 20857), </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: Hardware solutions for these problems have been proposed, each showing improvements in processor performance. 2.1 Memory Address Disambiguation A number of dynamic memory disambiguation techniques have been proposed to improve the accuracy of dependence speculation <ref> [10, 7, 19] </ref>. The Memory Conflict Buffer (MCB) proposed by Gallagher et al. [10] provides a hardware solution with compiler support to allow load instructions to speculatively execute before stores. The addresses of speculative loads are stored with a conflict bit in the MCB. <p> The check instruction checks the speculative load's conflict bit in the MCB; if not set, the speculation was correct, otherwise the load was mis-speculated. A similar approach for software-based speculative load execution was proposed by Moudgill and Moreno <ref> [19] </ref>. Instead of using a hardware buffer to check addresses, they check values. They allow loads to be speculatively scheduled above stores, and in addition they execute the load in its original location. They then check the value of the speculative load with the correct value.
Reference: [20] <author> E. Rotenberg, S. Bennett, and J. Smith. </author> <title> Trace cache: a low latency approach to high bandwidth instruction fetching. </title> <booktitle> In Proceedings of the 29th Annual ACM/IEEE International Symposium on Microarchitecture, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: The fetch unit can deliver two basic blocks from the I-cache per fetch cycle. If future generation micro-architectures wish to exploit more ILP, they will have to employ aggressive fetch designs like this or one that is comparable, such as the trace cache <ref> [20] </ref>. Second, we've given the processor a large window of execution, by modeling large reorder buffers and load/store queues.
Reference: [21] <author> Y. Sazeides and James E. Smith. </author> <title> The predictability of data values. </title> <booktitle> In 30th International Symposium on Microarchi-tecture, </booktitle> <pages> pages 248258, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: Further work has looked at predicting the value of instructions using stride and context predictors <ref> [24, 21] </ref>. Recent research has shown that instruction values have predictable behavior between different inputs [3, 9]. These studies showed that profiling can be used to accurately guide last value prediction.
Reference: [22] <author> A. Srivastava and A. Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In Proceedings of the Conference on Programming Language Design and Implementation, pages 196205. ACM, </booktitle> <year> 1994. </year>
Reference-contexts: The profiling data set is used to generate the load marking hints and tags. We then use the simulation data set to simulate the programs when gathering the statistical performance results. We used ATOM <ref> [22] </ref> to instrument the programs and gather the value profiles. The ATOM instrumentation tool has an interface that allows the elements of the program executable, such as instructions, basic blocks, and procedures, to be queried and manipulated.
Reference: [23] <author> G. Tyson and T. M. Austin. </author> <title> Improving the accuracy and performance of memory communication through renaming. </title> <booktitle> In 30th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 218227, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: If the dependencies could be determined early in the pipeline then the mis-speculations could be avoided. Two hardware approaches were recently proposed that also find dependencies between the load and store instructions and then use these dependencies during the fetch stage of the processor for Memory Renaming <ref> [18, 23] </ref>. The hardware would predict which loads were dependent upon stores to provide accurate value prediction and to enable loads to bypass memory by communicating the value of the store directly to the load instruction. These hardware techniques were successful at finding store/load dependencies. <p> When MRT tags are used, the tags are assigned by the compiler and are contained within the store and load instruction. A store and load with the same tag are mapped to the same value prediction entry in a table similar to those proposed in <ref> [18, 23] </ref>. Other loads are marked as either candidates for load value prediction or aggressive speculation based on program profiles. By only applying the appropriate optimization to each load, mis-speculations are reduced dramatically. <p> Our research extends these profile-guided techniques by not only predicting the value for load instructions, but also predicting load/store relationships and memory address disambiguation via profiling. 5 2.4 Memory Renaming Research by Moshovos et al [18] and Tyson and Austin <ref> [23] </ref> found that memory communication between store and load instructions can be accurately predicted in hardware. Both of these approaches used special store caches to find the load/store dependencies, and then an additional buffer to record the relationships found. <p> Our research shows that profiling can accurately find the important load/store dependencies. To evaluate the effectiveness of our Load Marking architecture, we compare our approach to the hardware memory communication approach of Tyson and Austin <ref> [23] </ref>. We obtained the modified version of the Sim-pleScalar simulation tools used for their study; we use a derivative of that simulator to perform our study and to provide IPC comparisons with their approach. <p> store and load instructions, and uses memory rename tags (MRT) to directly forward values from a store to a load instruction. 3.1.1 Load Marking Hints for Hardware Memory Renaming Compiler hints can improve the performance of the memory renaming architectures proposed by Moshovos and Sohi [18] and Tyson and Austin <ref> [23] </ref>. Stores and loads that are found via profiling/compiler analysis to benefit from memory renaming (MR) are marked for renaming. Loads which benefit more from value prediction are marked for value prediction, and all other loads are marked as non-speculative. <p> If the values are different, then the load was mis-speculated. Independence prediction can mispredict when a load is moved before a store it depends on. This would be detected by alias detection hardware when all earlier store addresses are known. We examine the same mis-speculation recovery options as <ref> [23] </ref>: squash and re-execute. Squash (re-fetch) recovery, which requires re-execution of all instructions after the load, is the simplest scheme. It re-fetches the 9 instructions from the cache on a mispredict, and is analogous to branch misprediction recovery. <p> When emulating the memory renaming experiments from <ref> [23] </ref>, we employed a 1024-entry, 2-way set associative store/load cache and a 1024 entry value file with LRU replacement. <p> To this end we examine the performance of three architectures that use the load marking information, and compare our results to the memory renaming architecture of Tyson and Austin <ref> [23] </ref>. The first architecture (LoadMark Hints) modifies the original memory renaming architecture to use LoadMark hints to indicate which stores and loads should use memory renaming, and which loads should use last value prediction. Only stores that are marked for renaming are put into the store cache. <p> Only stores that are marked for renaming are put into the store cache. Only loads that are marked for renaming search the store cache for a dependency. If a dependency is found, it is recorded in the store/load table described in <ref> [23] </ref>, so that both the store and load will use the same value table entry. Loads that are marked as last value prediction use the value table for last value prediction.
Reference: [24] <author> K. Wang and M. Franklin. </author> <title> Highly accurate data value prediction using hybrid predictors. </title> <booktitle> In 30th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 281290, </pages> <month> December </month> <year> 1997. </year> <month> 29 </month>
Reference-contexts: Further work has looked at predicting the value of instructions using stride and context predictors <ref> [24, 21] </ref>. Recent research has shown that instruction values have predictable behavior between different inputs [3, 9]. These studies showed that profiling can be used to accurately guide last value prediction.
References-found: 24

