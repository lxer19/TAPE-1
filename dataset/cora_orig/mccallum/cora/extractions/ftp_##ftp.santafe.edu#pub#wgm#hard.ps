URL: ftp://ftp.santafe.edu/pub/wgm/hard.ps
Refering-URL: http://www.aic.nrl.navy.mil/~spears/yin-yang.html
Root-URL: 
Email: (wgm@santafe.edu)  (dhw@santafe.edu)  
Title: What Makes An Optimization Problem Hard? SFI-TR-95-05-046  
Author: William G. Macready David H. Wolpert 
Date: February 8, 1996  
Address: 1399 Hyde Park Road Santa Fe, NM, 87501  
Affiliation: The Santa Fe Institute  
Abstract: We address the question: "Are some classes of combinatorial optimization problems intrinsically harder than others, without regard to the algorithm one uses, or can difficulty only be assessed relative to particular algorithms?" We provide a measure of the hardness of a particular optimization problem for a particular optimization algorithm and present two algorithm-independent quantities that use this measure to provide answers to our question. In the first of these we average hardness over all possible algorithms and show that according to this quantity, there are no distinctions between optimization problems. In this sense no problems are intrinsically harder than others. For the second quantity, rather than average over all algorithms, we consider the level of hardness of a problem (or class of problems) for the optimal algorithm. By this criteria there are classes of problems that are intrinsically harder than others.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D.H. Wolpert, </author> <note> W.G. Macready, SFI-TR-95-02-010, submitted to Oper. </note> <institution> Res., </institution> <year> (1995). </year>
Reference-contexts: Our 2 approach to these topics however is quite different and arises naturally in the context of a preliminary mathematical theory of search we have developed <ref> [1] </ref>. We begin in Section 2 by considering appropriate measures of gauging the performance of an algorithm on a particular cost function or across a set of cost functions. We point out the difficulty in defining such a measure and motivate the measure we suggest in this paper. <p> According to this measure there are some classes of problems that are intrinsically harder than others. We end by comparing our work to traditional computational complexity in Section 5. Conclusions and open issues are discussed in Section 6. 2 What is hard? Our notation follows that used in <ref> [1] </ref>. Formally, the optimization problem consists in locating the global extrema of a single valued mapping f : X ! Y, which we call the "cost function". We assume X and Y are finite and of size jX j and jYj respectively. <p> Any algorithm that re-visits points in X can be compressed into a more efficient one by eliminating the wasted effort of resampling points from f that have already been seen. This point is considered in greater detail in <ref> [1] </ref>. Thus we consider algorithms that generate a new distinct point at each iteration. In this case the output of m iterations of the algorithm is a population d m . Populations are ordered according to the time at which the algorithm generated the points. <p> To simplify our exposition we impose the restriction that the new point is selected deterministically (for the same population 3 the algorithm always chooses the same "new point"). However, as discussed in <ref> [1] </ref> most of our results apply equally well to algorithms which are stochastic and even to algorithms that re-visit the elements of the population. (We frame our analysis in such a way that the extension to stochastic algorithms will be clear.) Given these restrictions, an algorithm is a mapping a : <p> Intuitively, with the set of functions of in the context of supervised learning. To summarize: some classes of cost functions are harder than others for optimal algorithms. Given the close parallel between supervised learning and combinatorial optimization (see <ref> [1] </ref> and [5]), the results of this section are not too surprising. <p> In addition, we have designed our framework to be broad enough to consider all cost functions and algorithms simultaneously. It is only by including all cost functions and all algorithms within the same framework that one can understand the connection between an optimization problem and an effective algorithm <ref> [1] </ref>. In contrast, the field of computational complexity analyzes the relationship between particular sets of cost functions and particular associated algorithms. <p> As such, it forms a natural companion to <ref> [1] </ref>, where we investigated optimization from a "cost function perspective". We have found strong overlap between the algorithmic side of the mathematics of search and computational complexity. However, there are important foundational difference between the two subjects. <p> However, there are important foundational difference between the two subjects. We have tried to point out how the work described here differs from traditional computational complexity. Readers wishing deeper understanding of our motivations might consult <ref> [1] </ref>. We close by listing some future research directions. Firstly, there are a number of alternatives for algorithm-independent measures of the hardness of a P (f ). Some, briefly mentioned in the text, are quite similar to conventional computational complexity measures. <p> Two algorithms are close if the corresponding P (f )'s are close according to some metric on the space of probability distributions. See <ref> [1] </ref>.) What changes if we restrict ourselves to stochastic algorithms whose first point is uniformly randomly chosen? Other future work involves perturbing our same-equivalence-class assumption.
Reference: [2] <author> S. Kirkpatrick, C. D. Gelatt Jr., M. P. </author> <title> Vecchi, </title> <journal> Science, </journal> <volume> 220, 671, </volume> <year> (1983). </year>
Reference-contexts: We call an ordered sample of m distinct points from the cost function a "population" of size m and denote it by d m . In this paper we consider "search algorithms" like simulated annealing <ref> [2] </ref>, genetic algorithms [3], hill-climbing, etc. Any algorithm that re-visits points in X can be compressed into a more efficient one by eliminating the wasted effort of resampling points from f that have already been seen. This point is considered in greater detail in [1].
Reference: [3] <editor> S. Forrest, </editor> <booktitle> Science, </booktitle> <volume> 261, 872, </volume> <year> (1993). </year>
Reference-contexts: We call an ordered sample of m distinct points from the cost function a "population" of size m and denote it by d m . In this paper we consider "search algorithms" like simulated annealing [2], genetic algorithms <ref> [3] </ref>, hill-climbing, etc. Any algorithm that re-visits points in X can be compressed into a more efficient one by eliminating the wasted effort of resampling points from f that have already been seen. This point is considered in greater detail in [1].
Reference: [4] <author> D. Haussler, M. Kearns, R. </author> <title> Schapire, </title> <journal> Machine Learning, </journal> <volume> 14, 83, </volume> <year> (1994). </year>
Reference-contexts: Future work involves exploring such alternative definitions. It would also be interesting to carry out the analysis of optimal rather than averaged algorithms in more detail. In particular, the notions of information gain, and of the VC dimension and VC entropy <ref> [4] </ref> of a class jF j, may be helpful.
Reference: [5] <author> D.H. Wolpert, </author> <title> The lack of a priori distinctions between learning algorithms, and The existence of a priori distinctions between learning algorithms, </title> <note> submitted to Neural Computation, </note> <year> (1995). </year>
Reference-contexts: Intuitively, with the set of functions of in the context of supervised learning. To summarize: some classes of cost functions are harder than others for optimal algorithms. Given the close parallel between supervised learning and combinatorial optimization (see [1] and <ref> [5] </ref>), the results of this section are not too surprising.
Reference: [6] <author> C.H. Papadimitriou, </author> <title> Computational complexity, </title> <publisher> Addison-Wesley, </publisher> <year> (1994). </year>
Reference-contexts: the direct analogy of saying that the optimal search algorithm for a P (f ) performs with different efficacies for different P (f ). 5 Comparison to computational complexity The question, "how hard is an optimization problem?", has been investigated in theoretical computer science under the guise of computational complexity <ref> [6] </ref> and 11 information-based complexity [7]. Over the past 20 years a hierarchical classification of problem difficulties has been designed based on a standard computer the Turing machine.
Reference: [7] <author> J.F. Traub, G.W. Wasilkowski, and H. Wozniakowski, </author> <title> Information-Based Complexity, </title> <publisher> Academic Press:New York, </publisher> <year> (1988). </year> <month> 14 </month>
Reference-contexts: that the optimal search algorithm for a P (f ) performs with different efficacies for different P (f ). 5 Comparison to computational complexity The question, "how hard is an optimization problem?", has been investigated in theoretical computer science under the guise of computational complexity [6] and 11 information-based complexity <ref> [7] </ref>. Over the past 20 years a hierarchical classification of problem difficulties has been designed based on a standard computer the Turing machine.
References-found: 7

