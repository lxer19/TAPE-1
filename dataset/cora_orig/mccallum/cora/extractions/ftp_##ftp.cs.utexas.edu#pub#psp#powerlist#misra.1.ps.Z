URL: ftp://ftp.cs.utexas.edu/pub/psp/powerlist/misra.1.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/psp/
Root-URL: 
Email: misra@cs.utexas.edu  
Phone: (512) 471-9547  
Title: Powerlist: A Structure for Parallel Recursion  
Author: Jayadev Misra 
Date: March 5, 1994  
Address: Austin, Texas 78712  
Affiliation: Department of Computer Sciences The University of Texas at Austin  
Abstract: Many data parallel algorithms Fast Fourier Transform, Batcher's sorting networks and prefix-sum exhibit recursive structure. We propose a data structure, powerlist, that permits succinct descriptions of such algorithms, highlighting the roles of both parallelism and recursion. Simple algebraic properties of this data structure can be exploited to derive properties of these algorithms and, establish equivalence of different algorithms that solve the same problem.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Will Adams. </author> <title> Verifying adder circuits using powerlists. </title> <type> Technical Report TR 94-02, </type> <institution> Dept. of Computer Science, Univ. of Texas at Austin, Austin, Texas 78712, </institution> <month> Mar. </month> <year> 1994. </year>
Reference-contexts: The operator is scalar; so, it commutes with ./ . 20 3. The uniqueness of the solution of (DE) can be proved entirely within the powerlist algebra, similar to the derivation of Ladner-Fischer scheme given later in this section. 4. Adams <ref> [1] </ref> has specified the prefix-sum problem without postulating an explicit "0" element. For any , he introduces a binary operator ~ over two similar powerlists such that p ~ q = p fl q. The operator ~ can be defined without introducing a "0". <p> Kornerup [14] has developed certain strategies whereby each parallel step in a program is mapped to a constant number of local operations and communications at a hypercube node. Combinational circuit verification is an area in which the powerlist notation may be fruitfully employed. Adams <ref> [1] </ref> has proved the correctness of adder circuits using this notation. A ripple-carry adder is typically easy to describe and prove, whereas a carry-lookahead adder is much more difficult. Adams has described both circuits in our notation and proved their equivalence in a remarkably concise fashion.
Reference: [2] <author> J. Backus. </author> <title> Can programming be liberated from the von Neumann style? A functional style and its algebra of programs. </title> <journal> Communications of the ACM, </journal> <volume> 21(8) </volume> <pages> 613-641, </pages> <month> Aug. </month> <year> 1978. </year> <note> Turing Award Lecture (1977). </note>
Reference-contexts: i or u j v or u ./ v Examples h2i powerlist of length 1 containing a scalar hh2ii powerlist of length 1 containing a powerlist of length 1 of scalar h i not a powerlist h [ ]i powerlist of length 1 containing the empty linear list h h <ref> [2] </ref> [3 4 7]i h [4] [ ]i i powerlist of length 2, each element of which is a powerlist of length 2, whose elements are linear lists of numbers h h0 4i h1 5i h2 6i h3 7ii a representation of the matrix 4 5 6 7 where each column <p> The number of primes over f determines the dimension at which f is applied (the outermost dimension is numbered 0; therefore writing ./ , for instance, without primes, simply zips two lists). The operator for pointwise application also appears in Backus <ref> [2] </ref> and in Steele and Hillis [23]. Common special cases for the binary operator, op, are j and ./ and their pointwise application operators. <p> array can be embedded by embedding the left half of dimension 0 and the reverse of the right half in the two component hypercubes of a larger hypercube. 6 Remarks Related Work Applying uniform operations on aggregates of data have proved to be extremely powerful in APL [9]; see Backus <ref> [2] </ref> and Bird [4] for algebras of such operators. One of the earliest attempts at representing data parallel algorithms is in Preparata and Vuillemin [21].
Reference: [3] <author> K. Batcher. </author> <title> Sorting networks and their applications. </title> <booktitle> In Proc. AFIPS Spring Joint Computer Conference, </booktitle> <volume> volume 32, </volume> <pages> pages 307-314, </pages> <year> 1968. </year>
Reference-contexts: It can be implemented efficiently on a Butterfly network. The complexity of IFT is same as that of the FFT. 4.6 Batcher Sorting Networks In this section, we develop some elementary results about sorting and discuss two remarkable sorting methods due to Batcher <ref> [3] </ref>. We find it interesting that ./ (not j ) is the preferred operator in discussing the principles of parallel sorting. Henceforth, a list is sorted means that its elements are arranged in ascending order.
Reference: [4] <author> R. S. Bird. </author> <title> Lectures on constructive functional programming. </title> <editor> In Manfred Broy, editor, </editor> <booktitle> Constructive Methods in Computing Science, NATO ASI Series F: Computer and Systems Sciences, </booktitle> <pages> pages 151-216. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: or u ./ v Examples h2i powerlist of length 1 containing a scalar hh2ii powerlist of length 1 containing a powerlist of length 1 of scalar h i not a powerlist h [ ]i powerlist of length 1 containing the empty linear list h h [2] [3 4 7]i h <ref> [4] </ref> [ ]i i powerlist of length 2, each element of which is a powerlist of length 2, whose elements are linear lists of numbers h h0 4i h1 5i h2 6i h3 7ii a representation of the matrix 4 5 6 7 where each column is an element of the <p> Using INV1 and structural induction, it is easy to establish inv (inv P ) = P ; and for any scalar operator inv (P Q) = (inv P ) (inv Q) The last result holds for any permutation function in place of inv. 4.2 Reduction In the linear list theory <ref> [4] </ref>, reduction is a higher order function of two arguments, an associative binary operator and a list. Reduction applied to and [a 0 a 1 : : : a n ] yields (a 0 a 1 : : : a n ). <p> embedded by embedding the left half of dimension 0 and the reverse of the right half in the two component hypercubes of a larger hypercube. 6 Remarks Related Work Applying uniform operations on aggregates of data have proved to be extremely powerful in APL [9]; see Backus [2] and Bird <ref> [4] </ref> for algebras of such operators. One of the earliest attempts at representing data parallel algorithms is in Preparata and Vuillemin [21].
Reference: [5] <author> Guy E. Blelloch. </author> <title> Vector Models for Data-Parallel Computing. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: They have constructs similar to tie and zip, though they allow unbalanced decompositions of lists. An effective method of programming with vectors has been proposed by Blelloch <ref> [5, 6] </ref>. He proposes a small set of "vector-scan" instructions that may be used as primitives in describing parallel algorithms. <p> Thus parallel computations may have to be performed in a certain sequence and the sequence may depend on the data values during a computation. More general methods, as in Blelloch <ref> [5] </ref>, are then required. The powerlist notation can be integrated into a language that supports sequential computation. In particular, this notation blends well with ML [17] and LISP [16, 23]. A mixture of linear lists and powerlists can exploit the various combinations of sequential and parallel computing.
Reference: [6] <author> Guy E. Blelloch. NESL: </author> <title> A nested data-parallel language. </title> <type> Technical Report CMU-CS-93-129, </type> <institution> Carnegie-Mellon Univ., School of Computer Science, </institution> <month> April </month> <year> 1993. </year>
Reference-contexts: They have constructs similar to tie and zip, though they allow unbalanced decompositions of lists. An effective method of programming with vectors has been proposed by Blelloch <ref> [5, 6] </ref>. He proposes a small set of "vector-scan" instructions that may be used as primitives in describing parallel algorithms.
Reference: [7] <author> K. Mani Chandy and Jayadev Misra. </author> <title> Parallel Program Design: A Foundation. </title> <publisher> Addison Wesley, </publisher> <year> 1988. </year>
Reference-contexts: Therefore, FFT (p ./ q) can be computed in O (M log M ) sequential steps or O (log M ) parallel steps using O (M ) processors. The compactness of this description of FFT is in striking contrast to the usual descriptions; see, for instance, Chandy and Misra <ref> [7, Section 6.13] </ref>. The compactness can be attributed to the use of recursion and the avoidance of explicit indexing (of the elements), by employing j and ./ .
Reference: [8] <author> J. M. Cooley and J. W. Tukey. </author> <title> An algorithm for the machine calculation of complex Fourier series. </title> <journal> Math. Comp., </journal> <volume> 19 </volume> <pages> 297-301, </pages> <year> 1965. </year>
Reference-contexts: Since w (N ) is of a special form the Fourier Transform can be computed in O (M log M ) steps, using the the Fast Fourier Transform algorithm <ref> [8] </ref>. This algorithm also admits of an efficient implemntation, requiring O (log M ) steps on O (M ) processors. We derive the FFT algorithm below. We need the following two properties of w (N ).
Reference: [9] <author> K. Iverson. </author> <title> A Programming Language. </title> <publisher> John Wiley and Sons, </publisher> <year> 1962. </year>
Reference-contexts: that a nonsingleton array can be embedded by embedding the left half of dimension 0 and the reverse of the right half in the two component hypercubes of a larger hypercube. 6 Remarks Related Work Applying uniform operations on aggregates of data have proved to be extremely powerful in APL <ref> [9] </ref>; see Backus [2] and Bird [4] for algebras of such operators. One of the earliest attempts at representing data parallel algorithms is in Preparata and Vuillemin [21].
Reference: [10] <author> Geraint Jones and Mary Sheeran. </author> <title> Circuit design in Ruby. </title> <editor> In Jtrgen Staunstrup, editor, </editor> <title> Formal Methods for VLSI Design. </title> <publisher> North-Holland, </publisher> <year> 1990. </year>
Reference-contexts: Unlike our method he is able to control the division of the list and the number of iterations depending on the values of the data items, a necessary ingredient in many scientific problems. Jones and Sheeran <ref> [10] </ref> have developed a relational algebra for describing circuit components. A circuit component is viewed as a relation and the operators for combining relations are given 31 appropriate interpretations in the circuit domain.
Reference: [11] <author> D. Kapur and M. Subramaniam. </author> <title> Automated reasoning about parallel algorithms using powerlists. </title> <note> Manuscipt in preparation, </note> <year> 1994. </year>
Reference-contexts: We represent the n-bit 10 n = 0 h [ ]i n = 2 h [00] [01] <ref> [11] </ref> [10]i strings by linear lists of length n and a Gray code sequence by a powerlist whose elements are these linear lists. The standard Gray code sequence may be computed by function G, for any n. <p> Jones and Sheeran [10] have developed a relational algebra for describing circuit components. A circuit component is viewed as a relation and the operators for combining relations are given 31 appropriate interpretations in the circuit domain. Kapur and Subramaniam <ref> [11] </ref> have implemented the powerlist notation and proved many of the alogrithms in this paper using an inductive theorem prover, called RRL (Rewrite Rule Laboratory), that is based on equality reasoning and rewrite rules.
Reference: [12] <author> Richard M. Karp and Vijaya Ramachandran. </author> <title> Parallel algorithms for shared memory machines. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science. </booktitle> <publisher> Elsevier and the MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: paper appeared in [18]. y This material is based in part upon work supported by the Texas Advanced Research Program under Grant No. 003658-219 and by the National Science Foundation Award CCR 9111912. 1 A notable exception is the recursive description of a prefix sum algorithm in Karp and Ramachandran <ref> [12] </ref>. 1 A data structure, powerlist, is proposed in this paper that highlights the role of both parallelism and recursion. Many of the known parallel algorithms| FFT, Batcher Merge, Prefix Sum, embedding arrays in hypercubes, etc.|have surprisingly concise descriptions using powerlists.
Reference: [13] <author> D. E. Knuth. </author> <title> Sorting and Searching, </title> <booktitle> volume 3 of The Art of Computer Programming. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1973. </year>
Reference-contexts: In the rest of this section, we develop certain elementary facts about sorting and prove the correctness of bm. 15 Elementary Facts about Sorting We consider only "compare and swap" type sorting methods. It is known (see Knuth <ref> [13] </ref>) that such a sorting scheme is correct iff it sorts lists containing 0's and 1's only. Therefore, we restrict our discussion to powerlists containing 0's and 1's, only. For a powerlist p, let z p be the number of 0's in it.
Reference: [14] <author> Jacob Kornerup. </author> <title> Mapping Powerlists onto Hypercubes. </title> <type> PhD thesis, </type> <institution> The University of Texas at Austin, Department of Computer Sciences, </institution> <year> 1994. </year> <note> In preparation. 34 </note>
Reference-contexts: One of the fundamental problems with the powerlist notation is to devise compilation strategies for mapping programs (written in the powerlist notation) to specific architectures. The architecture that is the closest conceptually is the hypercube. Kornerup <ref> [14] </ref> has developed certain strategies whereby each parallel step in a program is mapped to a constant number of local operations and communications at a hypercube node. Combinational circuit verification is an area in which the powerlist notation may be fruitfully employed.
Reference: [15] <author> R. E. Ladner and M. J. Fischer. </author> <title> Parallel prefix computation. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 27 </volume> <pages> 831-838, </pages> <year> 1980. </year>
Reference-contexts: It can be shown that after completion of the computation at level (log 2 (len L)), processor i holds the i th element of (ps L). Another scheme, due to Ladner and Fischer <ref> [15] </ref>, first applies to adjacent elements x 2i ; x 2i+1 to compute the list hx 0 x 1 ; :: x 2i x 2i+1 ; ::i. This list has half as many elements as the original list; its prefix sum is then computed recursively.
Reference: [16] <author> John McCarthy, Paul W. Abrahams, Daniel J. Edwards, Timothy P. Hart, and Michael I. Levin. </author> <title> LISP 1.5 Programmer's Manual. </title> <publisher> MIT Press, </publisher> <year> 1962. </year>
Reference-contexts: Simple algebraic properties of powerlists permit us to deduce properties of these algorithms employing structural induction. 2 Powerlist The basic data structure on which recursion is employed (in LISP <ref> [16] </ref> or ML [17]) is a list. <p> More general methods, as in Blelloch [5], are then required. The powerlist notation can be integrated into a language that supports sequential computation. In particular, this notation blends well with ML [17] and LISP <ref> [16, 23] </ref>. A mixture of linear lists and powerlists can exploit the various combinations of sequential and parallel computing. A powerlist consisting of linear lists as components admits of parallel processing in which each component is processed sequentially.
Reference: [17] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: Simple algebraic properties of powerlists permit us to deduce properties of these algorithms employing structural induction. 2 Powerlist The basic data structure on which recursion is employed (in LISP [16] or ML <ref> [17] </ref>) is a list. A list is either empty or it is constructed by concatenating an element to a list. (We restrict ourselves to finite lists throughout this paper.) We call such a list linear (because the list length grows by 1 as a result of applying the basic constructor). <p> For instance, the following function, rev, reverses the order of the elements of the argument powerlist. rev hxi = hxi The case analysis, as for linear lists, is based on the length of the argument powerlist. We adopt the pattern matching scheme of ML <ref> [17] </ref> and Miranda [24] 2 to deconstruct the argument list into its components, p and q, in the recursive case. Deconstruction, in general, uses the operators j and ./ ; see Section 3. <p> More general methods, as in Blelloch [5], are then required. The powerlist notation can be integrated into a language that supports sequential computation. In particular, this notation blends well with ML <ref> [17] </ref> and LISP [16, 23]. A mixture of linear lists and powerlists can exploit the various combinations of sequential and parallel computing. A powerlist consisting of linear lists as components admits of parallel processing in which each component is processed sequentially.
Reference: [18] <author> J. Misra. Powerlist: </author> <title> A structure for parallel recursion (preliminary version). </title> <editor> In A.W. Roscoe, editor, </editor> <title> A Classical Mind : Essays in Honour of C.A.R. </title> <booktitle> Hoare, </booktitle> <pages> pages 295-316. </pages> <publisher> Prentice Hall International, </publisher> <year> 1994. </year>
Reference-contexts: Similarly, the connection structures are often explained pictorially, by displaying the connections between one "level" and the next. The mathematical properties of the algorithms and connection structures are rarely evident from these descriptions. fl A preliminary version of this paper appeared in <ref> [18] </ref>. y This material is based in part upon work supported by the Texas Advanced Research Program under Grant No. 003658-219 and by the National Science Foundation Award CCR 9111912. 1 A notable exception is the recursive description of a prefix sum algorithm in Karp and Ramachandran [12]. 1 A data
Reference: [19] <author> Z. G. Mou and P. Hudak. </author> <title> An algebraic model for divide-and-conquer algorithms and its parallelism. </title> <journal> The Journal of Supercomputing, </journal> <volume> 2(3) </volume> <pages> 257-278, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Their style of programming was imperative. It is not easy to apply algebraic manipulations to such programs. Their programming paradigm fits in well within our notation. Mou and Hudak <ref> [19] </ref> and Mou [20] propose a functional notation to describe divide and conquer-type parallel algorithms.
Reference: [20] <author> Z.G. Mou. Divacon: </author> <title> A parallel language for scientific computing based on divide-and-conquer. </title> <booktitle> In Proc. 3rd Symp. on the Frontiers of Massively Parallel Computation, </booktitle> <pages> pages 451-461, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Their style of programming was imperative. It is not easy to apply algebraic manipulations to such programs. Their programming paradigm fits in well within our notation. Mou and Hudak [19] and Mou <ref> [20] </ref> propose a functional notation to describe divide and conquer-type parallel algorithms.
Reference: [21] <author> Franco P. Preparata and Jean Vuillemin. </author> <title> The cube-connected cycles: A versatile network for parallel computation. </title> <journal> Communications of the ACM, </journal> <volume> 24(5) </volume> <pages> 300-309, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: One of the earliest attempts at representing data parallel algorithms is in Preparata and Vuillemin <ref> [21] </ref>. In their words, "an algorithm... performs a sequence of basic operations on pairs of data that are successively 2 (k1) ; 2 (k2) ; ::; 2 0 = 1 locations apart".
Reference: [22] <author> Guy L. Steele Jr. </author> <type> Personal communication. </type>
Reference-contexts: Powerlists of Arbitrary Length The lengths of the powerlists have been restricted to be of the form 2 n , n 0, because we could then develop a simple theory. For handling arbitrary length lists, Steele <ref> [22] </ref> suggests padding enough "dummy" elements to a list to make its length a power of 2. This scheme has the advantage that we still retain the simple algebraic laws of powerlist.
Reference: [23] <author> Guy L. Steele Jr. and Daniel Hillis. </author> <title> Connection Machine Lisp: Fine-grained parallel symbolic processing. </title> <booktitle> In Proc. 1986 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 279-297, </pages> <address> Cambridge, Mass., </address> <month> Aug </month> <year> 1986. </year> <note> ACM SIGPLAN/SIGACT/SIGART. </note>
Reference-contexts: The number of primes over f determines the dimension at which f is applied (the outermost dimension is numbered 0; therefore writing ./ , for instance, without primes, simply zips two lists). The operator for pointwise application also appears in Backus [2] and in Steele and Hillis <ref> [23] </ref>. Common special cases for the binary operator, op, are j and ./ and their pointwise application operators. <p> More general methods, as in Blelloch [5], are then required. The powerlist notation can be integrated into a language that supports sequential computation. In particular, this notation blends well with ML [17] and LISP <ref> [16, 23] </ref>. A mixture of linear lists and powerlists can exploit the various combinations of sequential and parallel computing. A powerlist consisting of linear lists as components admits of parallel processing in which each component is processed sequentially.
Reference: [24] <author> David Turner. </author> <title> An overview of Miranda. </title> <journal> ACM SIGPLAN Notices, </journal> <volume> 21 </volume> <pages> 156-166, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: For instance, the following function, rev, reverses the order of the elements of the argument powerlist. rev hxi = hxi The case analysis, as for linear lists, is based on the length of the argument powerlist. We adopt the pattern matching scheme of ML [17] and Miranda <ref> [24] </ref> 2 to deconstruct the argument list into its components, p and q, in the recursive case. Deconstruction, in general, uses the operators j and ./ ; see Section 3.
Reference: [25] <author> X. Wang and Z.G. Mou. </author> <title> A divide-and-conquer method of solving tridiag-onal systems on hypercube massively parallel computers. </title> <booktitle> In proc. of the 3rd IEEE symposium on parallel and distributed processing, </booktitle> <pages> pages 810-817, </pages> <address> Dallas, Tx., </address> <month> Dec. </month> <year> 1991. </year> <month> 35 </month>
Reference-contexts: Their notation is a vast improvement over Preparata and Vuillemin's in that changing from an imperative style to a functional style of programming allows more succinct expressions and the possibility of algebraic manipulations; the effectiveness of this programming style on a scientific problem may be seen in <ref> [25] </ref>. They have constructs similar to tie and zip, though they allow unbalanced decompositions of lists. An effective method of programming with vectors has been proposed by Blelloch [5, 6]. He proposes a small set of "vector-scan" instructions that may be used as primitives in describing parallel algorithms.
References-found: 25

