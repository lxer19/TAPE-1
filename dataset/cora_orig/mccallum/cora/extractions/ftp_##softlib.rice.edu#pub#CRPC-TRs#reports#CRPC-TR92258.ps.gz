URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR92258.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Email: choudhar/gcf/ranka@nova.npac.syr.edu  seema/ken/chk@rice.edu  jhs@icase.edu  
Phone: 315-443-1733  713-527-6009  
Title: Software support for irregular and loosely synchronous problems  
Author: Alok Choudhary Geoffrey Fox Sanjay Ranka Seema Hiranandani Ken Kennedy Charles Koelbel Joel Saltz 
Date: June 16, 1992  
Address: Syracuse, NY 13244-4100  Box 1892  Houston, TX 77251-1892  Hampton, VA 23665  
Affiliation: NPAC, 111 College Place Syracuse University  CITI,P.O.  Rice University  NASA Langley Research Center  
Pubnum: CRPC,  ICASE,MS 132C  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> E. Anderson and Y. </author> <title> Saad=2E Solving sparse triangular linear systems on parallel computers. </title> <journal> International Journal of High Speed Computing, </journal> <volume> 1(1) </volume> <pages> 73-95, </pages> <year> 1989. </year> <month> 18 </month>
Reference-contexts: In this section, we will only consider the case where each individual phase is a static single phase computation as defined above. Examples of these computations include unstructured multigrid (e.g. [26]), parallelized sparse triangular solver (e.g. <ref> [4, 1] </ref>), particle-in-cell codes (e.g. [38, 24]), and vortex blob calculations [3]. The key problem in implementation is again partitioning computation and data, but now the task is complicated because the interfaces between phases must be considered in the partitioning.
Reference: [2] <author> C. Ashcraft, S. C. Eisenstat, and J. W. H. Liu. </author> <title> A fan-in algorithm for distributed sparse numerical factorization. </title> <journal> SISSC, </journal> <volume> 11(3) </volume> <pages> 593-599, </pages> <year> 1990. </year>
Reference-contexts: We will 13 call this process runtime aggregation or runtime tiling. There have been a variety of numerical algorithms to carry out what we call runtime tiling for multiprocessor and vector computers, a small subset of this extensive collection of methods may be found in <ref> [21, 2] </ref>. 3.5 Static and Dynamic Structured Problems This class of problems consist of highly structured computations on sets of subdomains that are coupled in an irregular manner. The computations on each individual sub-domain are frequently highly structured, but the computational relationship between the subdomains is known only at runtime. <p> In such cases, it is often necessary to partition a problem in a way that takes into account all of the computational phases in an iteration. Further, there are issues related to partitioning and runtime aggregation <ref> [28, 21, 2] </ref>. which can affect the performance of these problems Secondly, we need to standardize extensions to Fortran D to facilitate the specification of partitioning strategies and irregular meshes.
Reference: [3] <author> S. Baden. </author> <title> Programming abstractions for dynamically partitioning and coordinating localized scientific calculations running on multiprocessors. </title> <note> To appear, SIAM J. </note> <institution> Sci. and Stat. Computation., </institution> <year> 1991. </year>
Reference-contexts: In this section, we will only consider the case where each individual phase is a static single phase computation as defined above. Examples of these computations include unstructured multigrid (e.g. [26]), parallelized sparse triangular solver (e.g. [4, 1]), particle-in-cell codes (e.g. [38, 24]), and vortex blob calculations <ref> [3] </ref>. The key problem in implementation is again partitioning computation and data, but now the task is complicated because the interfaces between phases must be considered in the partitioning. The synchronization and communication requirements are similarly complicated by the multiple phases.
Reference: [4] <author> D. Baxter, J. Saltz, M. Schultz, S. Eisentstat, and K. Crowley. </author> <title> An experimental study of methods for parallel preconditioned krylov methods. </title> <booktitle> In Proceedings of the 1988 Hypercube Multiprocessor Conference, </booktitle> <address> Pasadena CA, pages 1698,1711, </address> <month> January </month> <year> 1988. </year>
Reference-contexts: In this section, we will only consider the case where each individual phase is a static single phase computation as defined above. Examples of these computations include unstructured multigrid (e.g. [26]), parallelized sparse triangular solver (e.g. <ref> [4, 1] </ref>), particle-in-cell codes (e.g. [38, 24]), and vortex blob calculations [3]. The key problem in implementation is again partitioning computation and data, but now the task is complicated because the interfaces between phases must be considered in the partitioning.
Reference: [5] <author> H. Berryman, J. Saltz, and J. Scroggs. </author> <title> Execution time support for adaptive scientific algorithms on distributed memory machines, </title> <note> to appear in concurrency: Practice and experience 1991. Report 90-41, </note> <institution> ICASE, </institution> <month> May </month> <year> 1990. </year>
Reference-contexts: The key to efficiency on these problems is to aggressively apply optimizations to the regular subproblems, which can be implemented with lower overheads. Also, the larger granularity of the coupled subproblems can be exploited to reduce preprocessing overheads and also reduce memory requirements <ref> [5] </ref>. An example of this class is shock profiling as described in [5]. The basic problem is to solve a partial differential equation in the presence of a shock, computing the profile (detailed shape) of the shock. <p> Also, the larger granularity of the coupled subproblems can be exploited to reduce preprocessing overheads and also reduce memory requirements <ref> [5] </ref>. An example of this class is shock profiling as described in [5]. The basic problem is to solve a partial differential equation in the presence of a shock, computing the profile (detailed shape) of the shock. Resolution of the profile implies that a highly refined grid must be used in a neighborhood of the shock.
Reference: [6] <author> B. R. Brooks, R. E. Bruccoleri, B. D. Olafson, D. J. States, S. Swaminathan, and M. Karplus. Charmm: </author> <title> A program for macromolecular energy, minimization, and dynamics calculations. </title> <journal> Journal of Computational Chemistry, </journal> <volume> 4:187, </volume> <year> 1983. </year>
Reference-contexts: The changes may be gradual, reflecting adiabatic changes in the physical domain, or large-scale, reflecting additions to a data structure. Molecular dynamics applications often exhibit the first behavior because interactions between particles are implemented by neighbor lists which change as the atoms move <ref> [6] </ref>. Adaptive PDE solvers are often examples of the second behavior, as discussed below.
Reference: [7] <author> A. N. Choudhary and J. H. Patel. </author> <title> Parallel Archietctures and Parallel Algorithms for Integrated Vision Systems. </title> <publisher> Kluwer Academic Publisher, </publisher> <address> Boston, MA. </address> <year> 1990. </year>
Reference-contexts: Adaptive PDE solvers are often examples of the second behavior, as discussed below. Other examples with which we are familiar include some vision algorithms including region growing and labeling <ref> [7, 41] </ref>, statistical physics simulations near critical points [8], and the particle sorting phase of a direct monte carlo simulation [9]. The key problems in implementing these algorithms are to react quickly to changes in the data structure.
Reference: [8] <author> P. D. Coddington and C. F. Baillie. </author> <title> Cluster Algorithms for Spin Models on MIMD Parallel Computers. </title> <booktitle> The Fifth Distributed Memory Computing Conference, </booktitle> <address> April 9-12, Charleston, South Carolina. </address>
Reference-contexts: Adaptive PDE solvers are often examples of the second behavior, as discussed below. Other examples with which we are familiar include some vision algorithms including region growing and labeling [7, 41], statistical physics simulations near critical points <ref> [8] </ref>, and the particle sorting phase of a direct monte carlo simulation [9]. The key problems in implementing these algorithms are to react quickly to changes in the data structure.
Reference: [9] <author> L. Dagum. </author> <title> Data Parallel Sorting for Particle Simulation. </title> <institution> NASA Ames Research Report, </institution> <month> Sept., </month> <year> 1991. </year>
Reference-contexts: Adaptive PDE solvers are often examples of the second behavior, as discussed below. Other examples with which we are familiar include some vision algorithms including region growing and labeling [7, 41], statistical physics simulations near critical points [8], and the particle sorting phase of a direct monte carlo simulation <ref> [9] </ref>. The key problems in implementing these algorithms are to react quickly to changes in the data structure.
Reference: [10] <author> R. Das, J. Saltz, and H. Berryman. </author> <title> A manual for parti runtime primitives revision 1 (document and parti software available through netlib). </title> <type> Interim Report 91-17, </type> <institution> ICASE, </institution> <year> 1991. </year>
Reference-contexts: Reducing the overhead of these calls, both by reusing information computed in the calls and by performing the calls efficiently, is also vital for high efficiency. The PARTI library <ref> [10] </ref> and the Kali compiler [17] introduced the inspector/executor paradigm to perform these optimizations. In the remainder of this section, we describe some of the details that must be considered in implementing these kernels.
Reference: [11] <author> I. S. Duff and J. K. Reid. </author> <title> Direct Methods for Sparse Matrices. </title> <publisher> Oxford Science Publications, Oxford University Press, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: A more difficult problem is that of runtime aggregation of work and data. When we carry out sparse computations such as sparse triangular solves or sparse direct factorizations <ref> [11] </ref>, our runtime preprocessing can determine the number and content of the concurrent computational phases that will comprise a computation. We will 13 call this process runtime aggregation or runtime tiling.
Reference: [12] <author> D. J. Edelsohn, </author> <title> "Hierarchial Tree-Structures as Adaptive Meshes," </title> <institution> SCCS Report-193, Syracuse University. </institution> <month> 19 </month>
Reference-contexts: Examples of such problems include the adaptive mesh method described below and a combined hydrodynamics and particle astrophysical simulations implemented by Edelson at Syracuse <ref> [12] </ref>. The key to efficiency on these problems is to aggressively apply optimizations to the regular subproblems, which can be implemented with lower overheads. Also, the larger granularity of the coupled subproblems can be exploited to reduce preprocessing overheads and also reduce memory requirements [5].
Reference: [13] <author> G. C. Fox. </author> <title> What Have We Learnt from Using Real Parallel Machines to Solve Real Problems? The Third Conference on Hypercube Concurrent Computers and Applications, </title> <booktitle> Volume 2, </booktitle> <month> Jan., </month> <year> 1988. </year>
Reference-contexts: As mentioned in the previous sections, we intend to develop a parallel software environment for what we call loosely synchronous problems, linked to the Fortran D compiler project at Rice and Syracuse Universities. This concept has been explained in detail in <ref> [13, 14, 15] </ref>. The current Fortran D is designed to handle the special cases of synchronous problems and loosely synchronous problems with regular interconnection patterns. In extending the Fortran D environment, we have found it useful to divide this problem into several subclasses which are described below. <p> As described in Section 3.5, our classification is of course not complete and we are continuing our study of problem structures <ref> [13, 14] </ref>. 3.1 Static Single Phase Computations A static single phase computation consists of a single concurrent computational phase, which may be executed repeatedly without change. Examples of static single phase computations are iterative solvers using sparse matrix-vector multiplications (e.g. [32]) and explicit unstructured mesh fluids calculations (e.g. [42]).
Reference: [14] <author> G. C. Fox. </author> <title> Parallel Problem Architectures and Their Implications for Parallel Software Systems. </title> <booktitle> DARPA Workshop, </booktitle> <address> Providence, RI, </address> <month> Feb. </month> <note> 1991 (also SCCS-78). </note>
Reference-contexts: Our analysis of problem architecture or structure is based on a break up of each problem into spatial (data) and temporal (control) aspects. Following Fox <ref> [14] </ref> we describe three problem architecture classes in terms of their temporal (time or synchronization) structure. The temporal structure of a problem is analogous to the hardware classification into SIMD and MIMD. <p> As mentioned in the previous sections, we intend to develop a parallel software environment for what we call loosely synchronous problems, linked to the Fortran D compiler project at Rice and Syracuse Universities. This concept has been explained in detail in <ref> [13, 14, 15] </ref>. The current Fortran D is designed to handle the special cases of synchronous problems and loosely synchronous problems with regular interconnection patterns. In extending the Fortran D environment, we have found it useful to divide this problem into several subclasses which are described below. <p> As described in Section 3.5, our classification is of course not complete and we are continuing our study of problem structures <ref> [13, 14] </ref>. 3.1 Static Single Phase Computations A static single phase computation consists of a single concurrent computational phase, which may be executed repeatedly without change. Examples of static single phase computations are iterative solvers using sparse matrix-vector multiplications (e.g. [32]) and explicit unstructured mesh fluids calculations (e.g. [42]).
Reference: [15] <author> G. C. Fox. </author> <title> Fortran D as a Portable Software System for Parallel Computers. </title> <booktitle> Presentation at Supercomputing USA/Pacific '91 Conference, </booktitle> <address> Santa Clara, CA, </address> <note> June 1991 (also SCCS-91). </note>
Reference-contexts: As mentioned in the previous sections, we intend to develop a parallel software environment for what we call loosely synchronous problems, linked to the Fortran D compiler project at Rice and Syracuse Universities. This concept has been explained in detail in <ref> [13, 14, 15] </ref>. The current Fortran D is designed to handle the special cases of synchronous problems and loosely synchronous problems with regular interconnection patterns. In extending the Fortran D environment, we have found it useful to divide this problem into several subclasses which are described below.
Reference: [16] <author> G. Fox, S. Hiranandani, K. Kennedy, C. Koelbel, U. Kremer, C. Tseng, and M. Wu. </author> <title> Fortran D language specification. </title> <institution> Department of Computer Science Rice COMP TR90-141, Rice University, </institution> <note> December 1990 (also SCCS-42C). </note>
Reference-contexts: In such a problem, we can follow the common convention of carrying out computational work associated with computing a value for distributed array element y (i) on the processor onto which y (i) is mapped <ref> [16] </ref>. There are other common cases in which the assignment of distributed array elements to processors and assignment of work to processors cannot be coupled in such a straightforward fashion.
Reference: [17] <author> C. Koelbel and P. Mehrotra. </author> <title> Compiling global name-space loops for distributed execution (to appear: </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <month> july </month> <year> 1991). </year> <type> Report 90-70, </type> <institution> ICASE, </institution> <year> 1990. </year>
Reference-contexts: Reducing the overhead of these calls, both by reusing information computed in the calls and by performing the calls efficiently, is also vital for high efficiency. The PARTI library [10] and the Kali compiler <ref> [17] </ref> introduced the inspector/executor paradigm to perform these optimizations. In the remainder of this section, we describe some of the details that must be considered in implementing these kernels. In some cases, there is a straightforward relationship between the way we partition distributed arrays and the way we partition work.
Reference: [18] <author> G. C. Fox. </author> <title> Hardware and Software Architectures for Irregular Problems Architectures. Invited talk at ICASE Workshop on Unstructured Scientific Computations on Scalable Multiprocessors, </title> <address> Nagshead, NC, </address> <month> Oct., </month> <note> 1990 (also SCCS-111). </note>
Reference-contexts: This is similar to solving sparse triangular systems of linear equations arising from ILU preconditioning methods [36, 37]. Another example of this class is the tree generation phase of the adaptive fast multipole algorithms for particle dynamics <ref> [18, 33] </ref>. The key problem in implementing these algorithms is to detect and exploit opportunities for partial parallelization. In Figure 8, it is often possible to carry out many simultaneous row substitutions.
Reference: [19] <author> G. C. Fox, </author> <title> The Architecture of Problems and Portable Parallel Software Systems, Supercomputing 91, </title> <note> also SCCS-134. </note>
Reference-contexts: Because of this irregularity, it is difficult to give general methods for parallelizing asynchronous problems. Some run well with functional decompositions, some require real-time synchronization techniques, and some have never been run successfully on massively parallel machines. For a detailed description of these classes the reader is referred to <ref> [19] </ref>. The class of embarrassingly parallel problems contains those problems that are totally disconnected in space and time.
Reference: [20] <author> G. Fox, M. Johnson, G. Lyzenga, S. Otto, J. Salmon, and D. Walker. </author> <title> Solving Problems on Concurrent Computers. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1988. </year>
Reference-contexts: In Section 3 we describe different subclasses of irregular and loosely synchronous problems. In Section 4, we discuss several parallelization strategies for the inclusion of these problems in the solution space of Fortran D. 3 2 Problem Architectures We have looked at many applications in a detailed survey in <ref> [20] </ref>. Our analysis of problem architecture or structure is based on a break up of each problem into spatial (data) and temporal (control) aspects. Following Fox [14] we describe three problem architecture classes in terms of their temporal (time or synchronization) structure.
Reference: [21] <author> A. George, M. T. Heath, J. Liu, and E. Ng. </author> <title> Sparse cholesky factorization on a local memory multiprocessor. </title> <journal> SISSC, </journal> <pages> 327-340, </pages> <year> 1988. </year>
Reference-contexts: We will 13 call this process runtime aggregation or runtime tiling. There have been a variety of numerical algorithms to carry out what we call runtime tiling for multiprocessor and vector computers, a small subset of this extensive collection of methods may be found in <ref> [21, 2] </ref>. 3.5 Static and Dynamic Structured Problems This class of problems consist of highly structured computations on sets of subdomains that are coupled in an irregular manner. The computations on each individual sub-domain are frequently highly structured, but the computational relationship between the subdomains is known only at runtime. <p> In such cases, it is often necessary to partition a problem in a way that takes into account all of the computational phases in an iteration. Further, there are issues related to partitioning and runtime aggregation <ref> [28, 21, 2] </ref>. which can affect the performance of these problems Secondly, we need to standardize extensions to Fortran D to facilitate the specification of partitioning strategies and irregular meshes.
Reference: [22] <author> S. Hammond and R. Schreiber. </author> <title> Mapping unstructured grid problems to the connection machine. </title> <type> Report 90.22, </type> <institution> RIACS, </institution> <month> October </month> <year> 1990. </year>
Reference-contexts: Currently, partitioners are designed using programmers' a priori knowledge about a problem's computational structure and its expected computational behavior. There has been significant progress in the development of robust partitioners for static single phase loosely synchronous calculations see e.g. <ref> [35, 22] </ref> but much work remains to be done in order to deal with other problem classes. Similarly, we have proposed a scheme for integrating data partitioners into compilers that appears to be appropriate for static single and perhaps for multiphase loops [29].
Reference: [23] <author> P. C. Liewer, E. W. Leaver, V. K. Decyk and J. M. Dawson. </author> <title> Dynamic load balancing in a concurrent plasma PIC code on the JPL/Caltech Mark III hypercube. </title> <booktitle> Fifth Distributed Memory Computing Conference, </booktitle> <pages> 939-942, </pages> <year> 1990. </year> <month> 20 </month>
Reference: [24] <author> P. C. Liewer and V. K. Decyk. </author> <title> A General Concurrent Algorithm for Plasma Particle-in-Cell Simulation Codes. </title> <journal> Journal of Computational Physics, </journal> <volume> 85, 2, </volume> <pages> pp. 302-322, </pages> <year> 1989. </year>
Reference-contexts: In this section, we will only consider the case where each individual phase is a static single phase computation as defined above. Examples of these computations include unstructured multigrid (e.g. [26]), parallelized sparse triangular solver (e.g. [4, 1]), particle-in-cell codes (e.g. <ref> [38, 24] </ref>), and vortex blob calculations [3]. The key problem in implementation is again partitioning computation and data, but now the task is complicated because the interfaces between phases must be considered in the partitioning. The synchronization and communication requirements are similarly complicated by the multiple phases.
Reference: [25] <author> L. C. Lu and M.C. Chen. </author> <title> Parallelizing Loops with Indirect Array References or Pointers Proceedings of the Fourth Workshop on Languages and Compilers for Parallel Computing, </title> <month> August </month> <year> 1991. </year>
Reference-contexts: Much work is needed to generalize these methods before they are able to handle the more challenging classes of computations. Some preliminary work along these lines has been reported in [28] and <ref> [25] </ref>. Time dependent or iterative loosely synchronous computational problems can ex 15 wedge. 16 hibit a range of dynamic behaviors.
Reference: [26] <author> D. J. Mavriplis. </author> <title> Three dimensional unstructured multigrid for the euler equations, paper 91-1549cp. </title> <booktitle> In AIAA 10th Computational Fluid Dynamics Conference, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Such applications usually have several parallelizable loops that involve a variety of distributed arrays. In this section, we will only consider the case where each individual phase is a static single phase computation as defined above. Examples of these computations include unstructured multigrid (e.g. <ref> [26] </ref>), parallelized sparse triangular solver (e.g. [4, 1]), particle-in-cell codes (e.g. [38, 24]), and vortex blob calculations [3]. The key problem in implementation is again partitioning computation and data, but now the task is complicated because the interfaces between phases must be considered in the partitioning. <p> It is clear, however, that these computations can again 7 8 take advantage of saving information computed in the run-time environment. In the remainder of this section, we describe the unstructured multigrid application to show some of the implementation complexities of this class. Unstructured multigrid codes <ref> [26] </ref>, carry out mesh relaxation over each of several increasingly refined meshes M 1 ; :::; M n . Figure 3 and Figure 4 depict two levels of these meshes from a fluid dynamics code that we have parallelized.
Reference: [27] <author> D. Mavriplis. </author> <title> Unstructured and adaptive mesh generation for high reynolds number viscous flows. </title> <type> Report 91-25, </type> <institution> ICASE, </institution> <month> February </month> <year> 1991. </year>
Reference: [28] <author> R. Mirchandaney, J. H. Saltz, R. M. Smith, D. M. Nicol, and Kay Crowley. </author> <title> Principles of runtime support for parallel processors. </title> <booktitle> In Proceedings of the 1988 ACM International Conference on Supercomputing , St. Malo France, </booktitle> <pages> pages 140-152, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: Much work is needed to generalize these methods before they are able to handle the more challenging classes of computations. Some preliminary work along these lines has been reported in <ref> [28] </ref> and [25]. Time dependent or iterative loosely synchronous computational problems can ex 15 wedge. 16 hibit a range of dynamic behaviors. <p> In such cases, it is often necessary to partition a problem in a way that takes into account all of the computational phases in an iteration. Further, there are issues related to partitioning and runtime aggregation <ref> [28, 21, 2] </ref>. which can affect the performance of these problems Secondly, we need to standardize extensions to Fortran D to facilitate the specification of partitioning strategies and irregular meshes.
Reference: [29] <author> R. Das, R. Ponnusamy, J=2E Saltz, and D. Mavriplis. </author> <title> Distributed memory compiler methods for irregular problems data copy reuse and runtime partitioning, Compilers and Runtime Software for Scalable Multiprocessors, </title> <editor> J. Saltz and P. Mehrotra Editors, </editor> <address> Amsterdam, The Netherlands, </address> <note> To appear 1991. Elsevier. </note>
Reference-contexts: The synchronization and communication requirements are similarly complicated by the multiple phases. As for static single phase computations, this partitioning must be performed at run time. Saltz and his coworkers have recently extended the PARTI library to include incremental routines which will be applicable to these problems <ref> [29] </ref> It is not clear whether further extensions will also be needed. It is clear, however, that these computations can again 7 8 take advantage of saving information computed in the run-time environment. <p> Similarly, we have proposed a scheme for integrating data partitioners into compilers that appears to be appropriate for static single and perhaps for multiphase loops <ref> [29] </ref>. Much work is needed to generalize these methods before they are able to handle the more challenging classes of computations. Some preliminary work along these lines has been reported in [28] and [25]. <p> In <ref> [29] </ref>, we have proposed extensions (and developed runtime support) that fulfill the first two of the above mentioned goals. There is also a need for development of new data structures targeted towards problems in which highly structured computations on a set of subdomains are coupled in an irregular manner.
Reference: [30] <author> J. J. Quirk. </author> <title> An Adaptive Grid Algorithm for Computational Shock Hydrodynamics. </title> <type> PhD thesis, </type> <institution> Cranfield Institute of Technology, </institution> <address> United Kingdom, </address> <year> 1991 </year>
Reference-contexts: Adaptive algorithms are useful for solving Euler and Navier Stokes problems that arise in aerodynamics. In these algorithms, mesh refinement is carried out in portions of a computational domain where it is estimated that additional resolution may be required (e.g., see <ref> [39, 30] </ref>). The grid in Figure 6 is an adaptive refinement of the grid in airfoil to be simulated. Adaptive mesh refinement is achieved by adding new points in regions of large flow gradients.
Reference: [31] <author> James Quirk. </author> <title> An Alternative to Unstructured Grids for Computing gas dynamic flows around arbitrarily complex two-dimensional bodies , ICASE Report 92-7, </title> <year> 1992 </year>
Reference-contexts: An example of a mesh employed in such a full structured adaptive multigrid may be seen in Figure 10. This mesh is used in a solution of the Euler equations used to 14 simulate interaction of a planar shock wave with a double wedge <ref> [31] </ref>. 4 Conclusions In this paper, we presented a partial classification of scientific and engineering applications which are irregular and loosely synchronous from the perspective of parallel processing. This classification should be helpful in extending Fortran D to permit its application to a large class of loosely synchronous problems.
Reference: [32] <author> Y. Saad. </author> <title> Communication complexity of the gaussian elimination algorithm on multiprocessors. </title> <journal> Lin. Algebra Appl., 77:315 -340, </journal> <year> 1986. </year>
Reference-contexts: Examples of static single phase computations are iterative solvers using sparse matrix-vector multiplications (e.g. <ref> [32] </ref>) and explicit unstructured mesh fluids calculations (e.g. [42]). The key problem in efficiently executing these programs is partitioning the data and computation 5 S1 do i=3D1,N y (i) =3D y (i) + a (i,j)*x (col (i,j)) end do to minimize communication while balancing load.
Reference: [33] <author> J. K. Salmon. </author> <title> Parallel Hierarchical N-Body Methods. </title> <type> Tech. Report, </type> <institution> CRPC-90-14, Center for Research in Parallel Computing, Caltech, Pasadena, </institution> <address> CA, </address> <year> 1990. </year>
Reference-contexts: This is similar to solving sparse triangular systems of linear equations arising from ILU preconditioning methods [36, 37]. Another example of this class is the tree generation phase of the adaptive fast multipole algorithms for particle dynamics <ref> [18, 33] </ref>. The key problem in implementing these algorithms is to detect and exploit opportunities for partial parallelization. In Figure 8, it is often possible to carry out many simultaneous row substitutions.
Reference: [34] <author> J. Saltz, R. Mirchandaney, and K. Crowley. </author> <title> Run-time parallelization and scheduling of loops, </title> <note> to appear in IEEE Transations on Ccomputers, </note> <year> 1991. </year> <type> Report 90-34, </type> <institution> ICASE, </institution> <month> May </month> <year> 1990. </year> <month> 21 </month>
Reference-contexts: In such problems, we carry out a form of runtime preprocessing with the goal of defining a sequence of loosely synchronous computational phases. In bus based shared memory multiprocessors, we have demonstrated that it is possible to integrate runtime parallelization with compilers <ref> [34] </ref>. We anticipate that it will also be possible to link runtime parallelization with compilers aimed at scalable multiprocessors and have carried out preliminary work in this area. A more difficult problem is that of runtime aggregation of work and data.
Reference: [35] <author> H. Simon. </author> <title> Partitioning of unstructured mesh problems for parallel processing. </title> <booktitle> In Proceedings of the Conference on Parallel Methods on Large Scale Structural Analysis and Physics Applications. </booktitle> <publisher> Permagon Press, </publisher> <year> 1991. </year>
Reference-contexts: We have partitioned the grids in our example using the partitioner described in <ref> [35] </ref> with good results, but there are many other possible partitioners. 3.3 Adaptive Irregular Computations An adaptive irregular computation consists of a loosely synchronous computation executed repeatedly in which the data access pattern changes between iterations. <p> Currently, partitioners are designed using programmers' a priori knowledge about a problem's computational structure and its expected computational behavior. There has been significant progress in the development of robust partitioners for static single phase loosely synchronous calculations see e.g. <ref> [35, 22] </ref> but much work remains to be done in order to deal with other problem classes. Similarly, we have proposed a scheme for integrating data partitioners into compilers that appears to be appropriate for static single and perhaps for multiphase loops [29].
Reference: [36] <author> P Venkatakrishnan. </author> <title> Preconditioned conjugate gradient methods for the compressible navier stokes equations. </title> <journal> AIAA Journal, </journal> <month> June </month> <year> 1991. </year>
Reference-contexts: Figure 8 shows a the back substitution phase of a sparse matrix factorization, a simple algorithm of this type. This is similar to solving sparse triangular systems of linear equations arising from ILU preconditioning methods <ref> [36, 37] </ref>. Another example of this class is the tree generation phase of the adaptive fast multipole algorithms for particle dynamics [18, 33]. The key problem in implementing these algorithms is to detect and exploit opportunities for partial parallelization.
Reference: [37] <author> P. Venkatkrishnan, J. Saltz, and D. Mavriplis. </author> <title> Parallel preconditioned iterative methods for the compressible navier stokes equations. </title> <booktitle> In 12th International Conference on Numerical Methods in Fluid Dynamics, </booktitle> <address> Oxford, England, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Figure 8 shows a the back substitution phase of a sparse matrix factorization, a simple algorithm of this type. This is similar to solving sparse triangular systems of linear equations arising from ILU preconditioning methods <ref> [36, 37] </ref>. Another example of this class is the tree generation phase of the adaptive fast multipole algorithms for particle dynamics [18, 33]. The key problem in implementing these algorithms is to detect and exploit opportunities for partial parallelization.
Reference: [38] <author> D. W. Walker. </author> <title> Characterizing the Parallel Performance of a Large-Scale, Particle-In-Cell Plasma Simulation Code. </title> <journal> Concurrency: Practice and Experience, </journal> <year> 1990. </year>
Reference-contexts: In this section, we will only consider the case where each individual phase is a static single phase computation as defined above. Examples of these computations include unstructured multigrid (e.g. [26]), parallelized sparse triangular solver (e.g. [4, 1]), particle-in-cell codes (e.g. <ref> [38, 24] </ref>), and vortex blob calculations [3]. The key problem in implementation is again partitioning computation and data, but now the task is complicated because the interfaces between phases must be considered in the partitioning. The synchronization and communication requirements are similarly complicated by the multiple phases.
Reference: [39] <author> G. Warren, W. Anderson, J. Thomas, and T. Roberts. </author> <title> Grid convergence for adaptive methods, paper 91-1592. </title> <booktitle> In AIAA 10th Computational Fluid Dynamics Conference, </booktitle> <month> June </month> <year> 1991. </year>
Reference-contexts: Adaptive algorithms are useful for solving Euler and Navier Stokes problems that arise in aerodynamics. In these algorithms, mesh refinement is carried out in portions of a computational domain where it is estimated that additional resolution may be required (e.g., see <ref> [39, 30] </ref>). The grid in Figure 6 is an adaptive refinement of the grid in airfoil to be simulated. Adaptive mesh refinement is achieved by adding new points in regions of large flow gradients.
Reference: [40] <author> J. A. Webb. </author> <title> Adapt: Global Image Processing with the Split and Merge Model. </title> <type> Tech. Rep., </type> <institution> CMU-CS-91-129, Carnegie-Mellon University, </institution> <month> April, </month> <year> 1991. </year>
Reference: [41] <institution> The DARPA Image Understanding Benchmark for Parallel Computers. Journal of Parallel and Distributed Computing, </institution> <address> 11, </address> <publisher> Academic Pressm Jan. </publisher> <year> 1991. </year>
Reference-contexts: Adaptive PDE solvers are often examples of the second behavior, as discussed below. Other examples with which we are familiar include some vision algorithms including region growing and labeling <ref> [7, 41] </ref>, statistical physics simulations near critical points [8], and the particle sorting phase of a direct monte carlo simulation [9]. The key problems in implementing these algorithms are to react quickly to changes in the data structure.
Reference: [42] <author> D. L. Whitaker, D. C. Slack, and R. W. Walters. </author> <title> Solution algorithms for the two-dimensional euler equations on unstructured meshes. </title> <booktitle> In Proceedings AIAA 28th Aerospace Sciences Meeting, </booktitle> <address> Reno, Nevada, </address> <month> January </month> <year> 1990. </year>
Reference-contexts: Examples of static single phase computations are iterative solvers using sparse matrix-vector multiplications (e.g. [32]) and explicit unstructured mesh fluids calculations (e.g. <ref> [42] </ref>). The key problem in efficiently executing these programs is partitioning the data and computation 5 S1 do i=3D1,N y (i) =3D y (i) + a (i,j)*x (col (i,j)) end do to minimize communication while balancing load.
Reference: [43] <author> M. Y. Wu and G. Fox. </author> <title> Compiling F90D Programs for Distributed Memory MIMD Parallel Computers. </title> <type> Report SCCS-88, </type> <institution> CRPC-TR91126, </institution> <month> April </month> <year> 1991. </year> <month> 22 </month>
References-found: 43

