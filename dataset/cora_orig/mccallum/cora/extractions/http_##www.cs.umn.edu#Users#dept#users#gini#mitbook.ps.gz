URL: http://www.cs.umn.edu/Users/dept/users/gini/mitbook.ps.gz
Refering-URL: http://www.cs.umn.edu/Users/dept/users/gini/
Root-URL: http://www.cs.umn.edu
Title: Interacting with the real world: a way of teaching Artificial Intelligence concepts  
Author: Maria Gini, Dean Hougen, Alejandro Ozerkovsky, Paul Rybski, and Brian Schmalz, 
Affiliation: Department of Computer Science and Engineering, University of Minnesota  
Abstract: We describe a variety of projects developed as part of a course in Artificial Intelligence at the University of Minnesota. The projects cover navigation of small mobile robots and learning to accomplish simple tasks, and require a variety of approaches from neural networks to genetic programming to reactive behaviors. The projects have all been implemented on real robots. We discuss how the combination of robotics with Artificial Intelligence adds value to the learning of AI concepts and how the fun of building and programming a robot is a highly motivating force for the learning process. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. N. Amaral and K. Tumer. </author> <title> Designing genetic algorithms for the state assignment problem. </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> 25(4) </volume> <pages> 687-694, </pages> <year> 1995. </year>
Reference-contexts: Nicheal Kramer proposed evolving computer program code directly and demonstrated the evolution of simple arithmetic expressions in 1985, and John Koza [17] demonstrated the evolution of Lisp S-expressions (that are actually computer programs) in 1987. Genetic algorithms have mainly being used to solve a variety of optimization problems <ref> [7, 1] </ref> and in robotics (see, for instance, [19]). Genetic programming has been used mainly to generate programs in Lisp. In our work, we use robots (either simulated or real) that have a limited instruction set and we generate programs for them using genetic programming.
Reference: [2] <author> R. C. Arkin. </author> <title> Motor schema-based robot navigation. </title> <journal> Int'l Journal of Robotics Research, </journal> <volume> 8(4) </volume> <pages> 92-112, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: The more cluttered and uncertain the space is that the robot has to maneuver in, the more likely that it will get into a situation where it cannot recover from. Artificial Potential Fields <ref> [5, 2, 20] </ref> represent obstacles in an environment as "virtual forces". All objects in an environment that the robot wants to avoid can be thought of as emitting a virtual force that repels a robot that comes close to it.
Reference: [3] <author> R. C. Arkin. </author> <title> Cooperation without communication: Multi-agent schema based robot navigation. </title> <journal> Journal of Robotic Systems, </journal> <volume> 9(3) </volume> <pages> 351-364, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: The two robots evolve simultaneously, as a unit fighting for survival. Work has been done in evolving cooperation strategies <ref> [8, 3, 4] </ref>, and in generating heterogeneous agents [6, 26, 16], but there is almost no research done in evolving multiple agents simultaneously. The introduction of a second robot requires changes to the robot instructions and to the genetic programming system.
Reference: [4] <author> R. Beckers, O. E. Holland, and J. L. Deneubourg. </author> <title> From local actions to global tasks: Stigmergy in collective robotics. </title> <booktitle> In Artificial Life IV, </booktitle> <pages> pages 181-189. </pages> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The two robots evolve simultaneously, as a unit fighting for survival. Work has been done in evolving cooperation strategies <ref> [8, 3, 4] </ref>, and in generating heterogeneous agents [6, 26, 16], but there is almost no research done in evolving multiple agents simultaneously. The introduction of a second robot requires changes to the robot instructions and to the genetic programming system.
Reference: [5] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2(1):14-23, </volume> <month> March </month> <year> 1986. </year>
Reference-contexts: The more cluttered and uncertain the space is that the robot has to maneuver in, the more likely that it will get into a situation where it cannot recover from. Artificial Potential Fields <ref> [5, 2, 20] </ref> represent obstacles in an environment as "virtual forces". All objects in an environment that the robot wants to avoid can be thought of as emitting a virtual force that repels a robot that comes close to it.
Reference: [6] <author> S. C. T. Chou. </author> <title> Colony: an artificial life model for active autonomous objects. </title> <journal> Software Practice and Experience, </journal> <volume> 26(12) </volume> <pages> 1373-1384, </pages> <year> 1997. </year>
Reference-contexts: The two robots evolve simultaneously, as a unit fighting for survival. Work has been done in evolving cooperation strategies [8, 3, 4], and in generating heterogeneous agents <ref> [6, 26, 16] </ref>, but there is almost no research done in evolving multiple agents simultaneously. The introduction of a second robot requires changes to the robot instructions and to the genetic programming system.
Reference: [7] <author> D. E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: Nicheal Kramer proposed evolving computer program code directly and demonstrated the evolution of simple arithmetic expressions in 1985, and John Koza [17] demonstrated the evolution of Lisp S-expressions (that are actually computer programs) in 1987. Genetic algorithms have mainly being used to solve a variety of optimization problems <ref> [7, 1] </ref> and in robotics (see, for instance, [19]). Genetic programming has been used mainly to generate programs in Lisp. In our work, we use robots (either simulated or real) that have a limited instruction set and we generate programs for them using genetic programming.
Reference: [8] <author> T. Haynes, R. Wainright, and S. Sen. </author> <title> Evolving cooperation strategies. </title> <booktitle> In Proc. First Int'l Conference on Multi-Agent Systems, </booktitle> <year> 1995. </year>
Reference-contexts: The two robots evolve simultaneously, as a unit fighting for survival. Work has been done in evolving cooperation strategies <ref> [8, 3, 4] </ref>, and in generating heterogeneous agents [6, 26, 16], but there is almost no research done in evolving multiple agents simultaneously. The introduction of a second robot requires changes to the robot instructions and to the genetic programming system.
Reference: [9] <author> J. H. Holland. </author> <title> Adaptation in Natural and Artificial Systems. </title> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: One possible application of this is to smooth the surface of an ice ring, to paint a wall, or any other application that requires covering in a systematic way a determined area. Genetic algorithms have been invented by John H. Holland in the mid-1960's <ref> [9] </ref>. Nicheal Kramer proposed evolving computer program code directly and demonstrated the evolution of simple arithmetic expressions in 1985, and John Koza [17] demonstrated the evolution of Lisp S-expressions (that are actually computer programs) in 1987.
Reference: [10] <author> Dean F. Hougen. </author> <title> Use of an eligibility trace to self-organize output. </title> <booktitle> In Science of Artificial Neural Networks II, Proceedings SPIE, volume 1966, </booktitle> <pages> pages 436-447, </pages> <year> 1993. </year>
Reference-contexts: The work presented here is applicable to terminal feedback problems. The method combines the self-organizing capabilities of Kohonen Maps with the temporal sensitivity of eligibility traces. More details are given in <ref> [10, 11] </ref>. Neighborhood function The internal structure of the neural map is defined by a topological ordering of the neurons that remains unaltered as the network learns. We use a planar topology.
Reference: [11] <author> Dean F. Hougen, John Fischer, Maria Gini, and James Slagle. </author> <title> Fast connectionist learning for trailer backing using a real robot. </title> <booktitle> In Proc. of the Int'l Conf. on Robotics and Automation, </booktitle> <pages> pages 1917-1922, </pages> <year> 1996. </year>
Reference-contexts: The work presented here is applicable to terminal feedback problems. The method combines the self-organizing capabilities of Kohonen Maps with the temporal sensitivity of eligibility traces. More details are given in <ref> [10, 11] </ref>. Neighborhood function The internal structure of the neural map is defined by a topological ordering of the neurons that remains unaltered as the network learns. We use a planar topology.
Reference: [12] <author> J. A. Kangas, T. K. Kohonen, and J. T. Laaksonen. </author> <title> Variants of self-organizing maps. </title> <journal> IEEE Trans. on Neural Networks, </journal> <pages> pages 93-99, </pages> <year> 1990. </year>
Reference-contexts: Several variants on Kohonen's Self-Organizing Topological Feature Maps (Kohonen Maps) have been suggested <ref> [12] </ref>. These have included networks which allow the learning of output values as well (e.g. for the control of physical systems [22]). All of the variants involving output learning, however, have required the use of teachers or critics to provide desired responses or response evaluations (respectively) at each time step.
Reference: [13] <author> A. Klopf. </author> <title> Brain function and adaptive systems a heterostatic theory. </title> <booktitle> In Proceedings of the International Conference on Systems, Man, and Cybernetics, </booktitle> <year> 1974. </year>
Reference-contexts: The eligibility trace One function of biological neurons which has not been approximated in the more standard connectionist systems is what we refer to as the eligibility trace. It is known that many neurons become more amenable to change when they fire (see, e.g. <ref> [13] </ref>). This plasticity reduces with time, but provides an opportunity for learning based on feedback received by the neuron after its activity. All neural elements have an eligibility value associated with them. Initially, all neurons are given an eligibility value of zero.
Reference: [14] <author> T. K. Kohonen. </author> <title> Self-organizing and associative memory. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <note> 3rd edition, </note> <year> 1989. </year>
Reference-contexts: Approaches such as the Cerebellar Model Articulated Controller (CMAC) [25], adaptive fuzzy systems [15], backpropagation through time [18], and "fuzzy BOXES" [28] have all been applied to versions of this problem. 3.2 Our Solution Kohonen <ref> [14] </ref> has proposed a physiologically plausible method of cooperative and competitive organization for connectionist systems that allows them to self-organize around a set of input vectors. Several variants on Kohonen's Self-Organizing Topological Feature Maps (Kohonen Maps) have been suggested [12]. <p> The concept of the neighborhood relationship is borrowed from Kohonen's Self-Organizing Topological Feature Maps <ref> [14] </ref> where the neighborhoods are used for self-organization of the maps. 7 Competition Each neural element in the network is sensitive to a particular region in the input space of the problem. For the present application, the input dimensions are evenly partitioned into eight regions along each axis.
Reference: [15] <author> Seong-Gon Kong and Bart Kosko. </author> <title> Adaptive fuzzy systems for backing up a truck-and-trailer. </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> 3(2) </volume> <pages> 211-223, </pages> <year> 1992. </year>
Reference-contexts: The trailer-backing problem is gaining attention as a simple to understand yet difficult to solve learning-control problem. Approaches such as the Cerebellar Model Articulated Controller (CMAC) [25], adaptive fuzzy systems <ref> [15] </ref>, backpropagation through time [18], and "fuzzy BOXES" [28] have all been applied to versions of this problem. 3.2 Our Solution Kohonen [14] has proposed a physiologically plausible method of cooperative and competitive organization for connectionist systems that allows them to self-organize around a set of input vectors.
Reference: [16] <author> J. Koza, M.A. Keane, and J.P. Rice. </author> <title> Performance improvement of machine learning via automatic discovery of facilitating functions as applied to a problem of symbolic system identification. </title> <booktitle> In Proc. of the IEEE Int'l Conf. on Neural Networks, </booktitle> <pages> pages 191-198, </pages> <year> 1993. </year>
Reference-contexts: The two robots evolve simultaneously, as a unit fighting for survival. Work has been done in evolving cooperation strategies [8, 3, 4], and in generating heterogeneous agents <ref> [6, 26, 16] </ref>, but there is almost no research done in evolving multiple agents simultaneously. The introduction of a second robot requires changes to the robot instructions and to the genetic programming system.
Reference: [17] <author> John R. Koza. </author> <title> Genetic Programming: On the Programming of Computers by Means of Natural Selection. </title> <publisher> MIT Press, </publisher> <year> 1992. </year> <month> 21 </month>
Reference-contexts: Genetic algorithms have been invented by John H. Holland in the mid-1960's [9]. Nicheal Kramer proposed evolving computer program code directly and demonstrated the evolution of simple arithmetic expressions in 1985, and John Koza <ref> [17] </ref> demonstrated the evolution of Lisp S-expressions (that are actually computer programs) in 1987. Genetic algorithms have mainly being used to solve a variety of optimization problems [7, 1] and in robotics (see, for instance, [19]). Genetic programming has been used mainly to generate programs in Lisp.
Reference: [18] <author> D. Nguyen and B. Widrow. </author> <title> Neural networks for self-learning control systems. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 10(3) </volume> <pages> 18-23, </pages> <year> 1990. </year>
Reference-contexts: The trailer-backing problem is gaining attention as a simple to understand yet difficult to solve learning-control problem. Approaches such as the Cerebellar Model Articulated Controller (CMAC) [25], adaptive fuzzy systems [15], backpropagation through time <ref> [18] </ref>, and "fuzzy BOXES" [28] have all been applied to versions of this problem. 3.2 Our Solution Kohonen [14] has proposed a physiologically plausible method of cooperative and competitive organization for connectionist systems that allows them to self-organize around a set of input vectors.
Reference: [19] <author> Ashwin Ram, Ronald Arkin, Gary Boone, and Michael Pearce. </author> <title> Using genetic algorithms to learn reactive control parameters for autonomous robotic navigation. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 2(3) </volume> <pages> 277-305, </pages> <year> 1994. </year>
Reference-contexts: Genetic algorithms have mainly being used to solve a variety of optimization problems [7, 1] and in robotics (see, for instance, <ref> [19] </ref>). Genetic programming has been used mainly to generate programs in Lisp. In our work, we use robots (either simulated or real) that have a limited instruction set and we generate programs for them using genetic programming. We start by assuming there is a single robot (or agent).
Reference: [20] <author> S. Ratering and M. Gini. </author> <title> Robot navigation in a known environment with unknown moving obstacles. </title> <booktitle> Autonomous Robots, </booktitle> <volume> 1(2) </volume> <pages> 149-165, </pages> <year> 1995. </year>
Reference-contexts: The more cluttered and uncertain the space is that the robot has to maneuver in, the more likely that it will get into a situation where it cannot recover from. Artificial Potential Fields <ref> [5, 2, 20] </ref> represent obstacles in an environment as "virtual forces". All objects in an environment that the robot wants to avoid can be thought of as emitting a virtual force that repels a robot that comes close to it.
Reference: [21] <author> H. Ritter, T. Martinetz, and K. Schulten. </author> <title> Neural computation and self-organizing maps: an introduction. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference-contexts: Connectionist control-learning systems have recently received much attention, and numerous papers and several books have been published on this topic in the last five years (e.g. [27], <ref> [21] </ref>). Most of these works, however, have concentrated on simulated systems. Learning is generally classified into supervised and unsupervised learning. In supervised learning an agent or function, often called the teacher, provides the desired output response for each input vector.
Reference: [22] <author> H. Ritter and K. Schulten. </author> <title> Extending Kohonen's self-organizing mapping algorithm to learn balistic movements. </title> <editor> In R. Eckmiller and C. von der Malsberg, editors, </editor> <booktitle> Neural Computers, volume F41, </booktitle> <pages> pages 393-406. </pages> <publisher> Springer, </publisher> <address> Heidelberg, </address> <year> 1987. </year>
Reference-contexts: Several variants on Kohonen's Self-Organizing Topological Feature Maps (Kohonen Maps) have been suggested [12]. These have included networks which allow the learning of output values as well (e.g. for the control of physical systems <ref> [22] </ref>). All of the variants involving output learning, however, have required the use of teachers or critics to provide desired responses or response evaluations (respectively) at each time step. The work presented here is applicable to terminal feedback problems.
Reference: [23] <author> Stuart Russell and Peter Norvig. </author> <title> Artificial Intelligence. A modern approach. </title> <publisher> Prentice-Hall, </publisher> <year> 1995. </year>
Reference-contexts: The examples presented here are some of the class projects done by students taking a course in Artificial Intelligence at the University of Minnesota. The course is intended for senior undergraduate and first year graduate students. The textbook we use is Russell and Norvig <ref> [23] </ref>. As part of the course students are required to work on a term project related to the material covered. <p> Even though not too many students select robotics for their project, the robotics projects tend to be among the most interesting and generate more enthusiasm in the class when they are presented. The emphasis of the textbook <ref> [23] </ref> on building agents, makes robotics a perfect domain. All the projects described were initiated by students. Some have been later expanded into larger research projects. Most of the projects in robotics include building small robots with LEGOs and using a Mini Board and/or a Handy Board to control them.
Reference: [24] <author> J. Shackleton and M. Gini. </author> <title> Measuring the effectiveness of reinforcement learning for behavior-based robots. Adaptive Behavior, </title> <address> 5(3-4):365-390, </address> <year> 1997. </year>
Reference-contexts: Additional robotics projects done only in simulation (such as the project reported in <ref> [24] </ref> are not included here. 2 Surfing Artificial Potential Fields Programming an autonomous mobile robot to navigate in any sort of environment is probably one of the oldest problems faced by any robotics or artificial intelligence researcher.
Reference: [25] <author> Robert O. Shelton and James K. Peterson. </author> <title> Controlling a truck with an adaptive critic CMAC design. </title> <journal> Simulation, </journal> <volume> 58(5) </volume> <pages> 319-326, </pages> <year> 1992. </year>
Reference-contexts: The trailer-backing problem is gaining attention as a simple to understand yet difficult to solve learning-control problem. Approaches such as the Cerebellar Model Articulated Controller (CMAC) <ref> [25] </ref>, adaptive fuzzy systems [15], backpropagation through time [18], and "fuzzy BOXES" [28] have all been applied to versions of this problem. 3.2 Our Solution Kohonen [14] has proposed a physiologically plausible method of cooperative and competitive organization for connectionist systems that allows them to self-organize around a set of input
Reference: [26] <author> L. Spector. </author> <title> Automatic generation of intelligent agent programs. </title> <journal> IEEE Expert, </journal> <volume> 12(1) </volume> <pages> 3-4, </pages> <year> 1997. </year>
Reference-contexts: The two robots evolve simultaneously, as a unit fighting for survival. Work has been done in evolving cooperation strategies [8, 3, 4], and in generating heterogeneous agents <ref> [6, 26, 16] </ref>, but there is almost no research done in evolving multiple agents simultaneously. The introduction of a second robot requires changes to the robot instructions and to the genetic programming system.
Reference: [27] <author> III W. Thomas Miller, Richard S. Sutton, and Paul J. Werbos. </author> <title> Neural Networks for Control. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Connectionist control-learning systems have recently received much attention, and numerous papers and several books have been published on this topic in the last five years (e.g. <ref> [27] </ref>, [21]). Most of these works, however, have concentrated on simulated systems. Learning is generally classified into supervised and unsupervised learning. In supervised learning an agent or function, often called the teacher, provides the desired output response for each input vector.
Reference: [28] <author> N. Woodcock, N. J. Hallam, and P. D.Picton. </author> <title> Fuzzy BOXES as an alternative to neural networks for difficult control problems. </title> <booktitle> Artificial Inteligence in Engineering, </booktitle> <pages> pages 903-919, </pages> <year> 1991. </year> <month> 22 </month>
Reference-contexts: The trailer-backing problem is gaining attention as a simple to understand yet difficult to solve learning-control problem. Approaches such as the Cerebellar Model Articulated Controller (CMAC) [25], adaptive fuzzy systems [15], backpropagation through time [18], and "fuzzy BOXES" <ref> [28] </ref> have all been applied to versions of this problem. 3.2 Our Solution Kohonen [14] has proposed a physiologically plausible method of cooperative and competitive organization for connectionist systems that allows them to self-organize around a set of input vectors.
References-found: 28

