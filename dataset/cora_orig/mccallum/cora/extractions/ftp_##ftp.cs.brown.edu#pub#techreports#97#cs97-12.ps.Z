URL: ftp://ftp.cs.brown.edu/pub/techreports/97/cs97-12.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-97-12.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> H. Agrawal. </author> <title> Towards Automatic Debugging of Computer Programs. </title> <type> PhD thesis, </type> <institution> Purdue University, </institution> <month> August </month> <year> 1991. </year>
Reference-contexts: discuss how our new prototype debugger exploits the ability to trace and replay a program's execution, and what types of interfaces to program replay we hope to develop in the future. 1.1 Related Work The debugging framework we have implemented fits nicely within the debugging paradigm originally proposed by Agrawal <ref> [1] </ref>. Agrawal believed that there should be a systematic debugging paradigm based on execution backtracking.
Reference: [2] <author> H. Agrawal, R. DeMillo, and E. Spafford. </author> <title> An execution backtracking approach to program debugging. </title> <journal> IEEE Software, </journal> <pages> pages 21-26, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Agrawal believed that there should be a systematic debugging paradigm based on execution backtracking. The Spyder system he developed with DeMillo and Spafford <ref> [2] </ref> was a debugging tool which performed static analysis of a program in order to compute a change set of values which could potentially be modified by each statement so that the changes could be traced and restored.
Reference: [3] <author> J. Choi, B. Miller, and R. Netzer. </author> <title> Techniques for debugging parallel programs with flowback analysis. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 13(4) </volume> <pages> 491-530, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The PPD system also used the idea of compile-time analysis and program instrumentation and tracing to perform flowback analysis for debugging <ref> [3] </ref>. Both of these tools provided forms of execution replay, but were limited by the use of static analysis, which yielded unacceptable performance overheads and trace rates.
Reference: [4] <author> R. Faulkner and R. Gomes. </author> <title> The Process File System and process model in unix System V. </title> <booktitle> In Proceedings of the Winter 1991 USENIX Conference, </booktitle> <address> Dallas, TX, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Still, operating system developers are tuned in to the needs of tool developers, especially because advanced debugging tools benefit everyone who develops for a particular operating system. Advanced operating system support for debugging, such as the /proc filesystem <ref> [4] </ref>, already exists in several unix operating system variants. The Solaris /proc implementation provides the ability to trace the entry to and exit from system call traps. Perhaps in the future support could be added to obtain additional system call information such as affected memory regions. <p> The Solaris virtual memory system is page-based, and a process's address space consists of a set of mappings onto the address spaces of objects in the system's virtual memory [9]. The Solaris /proc filesystem <ref> [4] </ref> provides a facility for obtaining the set of mappings currently associated with a process address space, including the virtual address ranges and virtual memory page protections. During tracing, the instrumentation library uses this facility to record the set of mappings prior to the execution of each interval. <p> The process control code for a unix debugger is typically implemented using a set of operating system primitives to allow one process to control another, such as the Solaris /proc filesystem <ref> [4] </ref> or the ptrace (2) system call provided in some other systems. Our goal was to provide a simple but powerful programming interface which can be used in place of the process control layer provided by the operating system.
Reference: [5] <author> S. Feldman and C. Brown. IGOR: </author> <title> A system for program debugging via reversible execution. </title> <booktitle> In Proceedings of the SIGPLAN/SIGOPS Workshop on Parallel and Distributed Debugging, </booktitle> <address> Madison, WI, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: Previous work on dynamic analysis for program tracing has focused on the idea of intermediate process checkpoints. The igor system uses the operating system virtual memory facilities to periodically checkpoint the execution of a user program <ref> [5] </ref>. Past program states can be recreated from the checkpoints, but this technique traces orders of magnitude more data than necessary. Many techniques for improving incremental checkpoints have been proposed, including recent work by Plank, Xu, and Netzer on compressed differences [17]. <p> Previous work with tracing at the granularity of virtual memory pages produced impractical amounts of trace data; orders of magnitude more data than necessary was traced <ref> [5] </ref>. The monitoring machines use a comparatively large amount of storage during program execution, but pay dividends by yielding extremely fast instrumentation code and smaller trace sizes.
Reference: [6] <author> R. Garner. </author> <title> The SPARC Architecture Manual: Version 8. </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1992. </year>
Reference-contexts: Besides parsing the rules file and performing lexical matching and substitution, altr also automates a number of complicated instrumentation tasks for the developer. One task is to handle matched instructions which are currently located in the delay slot of a delayed control transfer instruction <ref> [6] </ref>.
Reference: [7] <author> J. Gilmore. </author> <note> Working in GDB. Cygnus Support, 1.84 edition, </note> <year> 1994. </year>
Reference-contexts: Our requirements for the back-end were as follows: * The library should provide the same basic facilities as the operating system interface for controlling processes, and should be easily pluggable into existing debugging systems. We used the requirements of the gdb target ops structure <ref> [7] </ref> as a measure of the requirements of a full-featured debugger. gdb uses this structure to store a vector of pointers to functions which implement various process control primitives in terms of the process control mechanism provided by a particular operating system variant.
Reference: [8] <author> R. Gingell, M. Lee, X. Dang, and M. Weeks. </author> <title> Shared libraries in SunOS. </title> <booktitle> In Proceedings of the Summer 1987 USENIX Conference, </booktitle> <address> Phoenix, AZ, </address> <year> 1987. </year>
Reference-contexts: user signal processing occurs, or to indicate that this signal was internal to the library and program execution should resume as if the signal never occurred. 3.2.1 Process Initialization Process startup on Solaris begins not in code in the actual executable, but rather in code in the run-time linker /usr/lib/ld.so.1 <ref> [8] </ref>. This program is responsible for mapping in all of the shared libraries upon which the user program depends, performing relocations if necessary, calling any initialization functions provided by the shared libraries, and then transferring control to the start routine embedded in the executable [21].
Reference: [9] <author> R. Gingell, J. Moran, and W. Shannon. </author> <title> Virtual memory architecture in SunOS. </title> <booktitle> In Proceedings of the Summer 1987 USENIX Conference, </booktitle> <address> Phoenix, AZ, </address> <year> 1987. </year>
Reference-contexts: The Solaris virtual memory system is page-based, and a process's address space consists of a set of mappings onto the address spaces of objects in the system's virtual memory <ref> [9] </ref>. The Solaris /proc filesystem [4] provides a facility for obtaining the set of mappings currently associated with a process address space, including the virtual address ranges and virtual memory page protections.
Reference: [10] <author> D. Hanson and M. Raghavachari. </author> <title> A machine-independent debugger. </title> <type> Technical Report CS-TR-500-95, </type> <institution> Princeton University, </institution> <month> November </month> <year> 1995. </year>
Reference-contexts: Our goal was to provide a simple but powerful programming interface which can be used in place of the process control layer provided by the operating system. This design idea is very similar to the idea of a machine-dependent `nub' for debugger process control used in the cdb debugger <ref> [10] </ref>. However, as we shall see, our back-end library needs to provide additional functionality beyond a unified interface to the operating system's process control mechanism.
Reference: [11] <author> D. Korn. ksh: </author> <title> An extensible high level language. </title> <booktitle> In Proceedings of the Very High Level Language Symposium (VHLL), </booktitle> <address> Santa Fe, NM, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: We designed rdb to be as modular as possible so that adding new displays for viewing or interpreting program and replay information will be easy. The debugger also has an integrated KornShell <ref> [11] </ref> interface; new debugger features can be implemented or prototyped quickly by adding shell functions.
Reference: [12] <author> J. Mellor-Crummey and T. LeBlanc. </author> <title> A software instruction counter. </title> <booktitle> In Proceedings of the Third ASPLOS, </booktitle> <month> April </month> <year> 1989. </year>
Reference-contexts: Mellor-Crummey and LeBlanc <ref> [12] </ref> demonstrated that instrumentation to implement a software instruction counter (SIC) can be added to a program with minimal performance penalty. A SIC is a counter which is incremented prior to every backwards branch and function call. <p> Mellor-Crummey and LeBlanc's RISC implementation used a decrement and trap-on-underflow instruction on the HP Precision RISC architecture in order to trigger an exception when the appropriate SIC value is reached during replay <ref> [12] </ref>. Unfortunately no instruction exists on the sparc to trap conditionally without testing the condition codes. Thus our instrumentation code would not only have to decrement a register and trap based on the condition codes, it would have to save and restore the condition codes themselves.
Reference: [13] <author> R. Netzer. </author> <type> Personal communication, </type> <month> October </month> <year> 1995. </year>
Reference-contexts: Their work demonstrated that dividing a program's execution into fixed-size time intervals and then adaptively tracing the unique-spanning reads within each interval can be done efficiently, and provides sufficient trace information for incremental replay. Experimental results <ref> [13] </ref> proved that this technique produced only 10-20 kilobytes of trace per second and met the goal of about a factor of two run-time slowdown. They further proved that tracing unique-spanning M reads was sufficient to provide M-bounded replay in the debugger. <p> These observations are the key to producing low trace volume. We next need to build a fast monitoring mechanism to detect which reads need to be traced. 4 2.3 Monitoring Machines In order to facilitate efficient run-time monitoring for unique-spanning reads, Netzer <ref> [13] </ref> proposed the idea of associating a finite-state machine with a small unit of memory, such as a word. <p> As we will see, our state machines provide other information useful for controlling replay that we would like to associate with small units of memory such as words. 2.8 Run-Time Storage Two methods of representing state machines have been considered: two-level bit vectors and flat bit vectors <ref> [13] </ref>. A two-level bit vector is similar to the idea of a virtual memory page table. The topmost bits of an address are used to index into a sparsely-allocated table, which then contains a pointer to a second-level table.
Reference: [14] <author> R. Netzer. </author> <type> Personal communication, </type> <month> May </month> <year> 1996. </year>
Reference-contexts: the address specified by the sum of registers %g6 and %rX and discards the result, will generate a segmentation fault that we can intercept if %rX contains zero, and will effectively act as a nop if %rX contains a value between one and the size of a virtual memory page <ref> [14] </ref>. Our only remaining problem is that the value in the SIC register may eventually exceed the virtual memory page size (either 4K or 8K on typical Solaris sparc systems).
Reference: [15] <author> R. Netzer and M. Shapiro. </author> <title> Efficient fine-grain monitoring and its application to trace-and-replay debugging. </title> <note> Unpublished extended abstract, </note> <month> November </month> <year> 1996. </year>
Reference-contexts: The transitions in Fig. 5 marked with an asterisk indicate traces following system calls. 2.5 Machine Implementation We have developed techniques for writing efficient instrumentation code by implementing our state machines as small-depth logical circuits <ref> [15] </ref>, avoiding the need to index into a transition table. By associating each machine state with a carefully selected binary value, each machine input can perform a transition by applying a simple function to map the integer representing the current state to the integer which represents the desired destination state. <p> Previous prototypes <ref> [15] </ref> have shown that performing replay tracing at the granularity of words approaches our goals for trace output and run-time slowdowns. Monitoring at a finer granularity, such as bytes, increases the amount of instrumentation code because common full-word accesses must perform transitions on multiple state machines.
Reference: [16] <author> R. Netzer and M. Weaver. </author> <title> Optimal tracing and incremental reexecution for debugging long-running programs. </title> <booktitle> In ACM SIGPLAN Conference on Programming Language Design and Implementation, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Although such techniques can be used to improve the performance of dynamic tracing at the page granularity, Netzer and Weaver have shown that even lower overheads and trace rates can be obtained by dynamically detecting and tracing certain classes of memory accesses during program execution <ref> [16] </ref>. <p> Our goal was to produce a prototype with a run-time slowdown of around a factor of two and trace rates which would allow runs of as much as a day in length to be stored on a gigabyte disk. 3 2.2 Unique-Spanning Reads Previous work by Netzer and Weaver <ref> [16] </ref> identified a class of unique-spanning memory accesses which are a minimal set of memory accesses that must be traced in order to effect replay. First, a program's execution is viewed as a linear sequence of time intervals, each of some length T . <p> The most critical is that an expensive action, tracing the current value, must conditionally take place on a particular Read transition. This implies that the run-time instrumentation must perform a conditional test and then possibly output a trace record at each memory load instruction. Furthermore, previous work <ref> [16] </ref> has shown that reads are the most frequent events. Our goal then was to devise a machine which has fast hooks, no conditional tests, and postpones all tracing activity until the end of each interval.
Reference: [17] <author> J. Plank, J. Xu, and R. Netzer. </author> <title> Compressed differences: An algorithm for fast incremental checkpointing. </title> <note> Submitted for publication, </note> <year> 1995, </year> <month> May </month> <year> 1996. </year> <month> 48 </month>
Reference-contexts: Past program states can be recreated from the checkpoints, but this technique traces orders of magnitude more data than necessary. Many techniques for improving incremental checkpoints have been proposed, including recent work by Plank, Xu, and Netzer on compressed differences <ref> [17] </ref>. Although such techniques can be used to improve the performance of dynamic tracing at the page granularity, Netzer and Weaver have shown that even lower overheads and trace rates can be obtained by dynamically detecting and tracing certain classes of memory accesses during program execution [16].
Reference: [18] <author> M. Powell, S. Kleiman, S. Barton, D. Shah, D. Stein, and M. Weeks. </author> <title> SunOS multi-thread architecture. </title> <booktitle> In Proceedings of the Winter 1991 USENIX Conference, </booktitle> <address> Dallas, TX, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: To meet this goal, the rdb run-time engine provides facilities for the instrumentation library to communicate with the back-end via a separate agent thread which lives inside of the target process. The agent is implemented as a separate light-weight process <ref> [18] </ref> (LWP) in the user process, and is conceptually based on the agent LWP support provided by the Solaris 2.6 /proc filesystem 3 .
Reference: [19] <author> M. Shapiro. </author> <title> Tracing of user programs for incremental replay. </title> <type> Unpublished senior thesis, </type> <month> April </month> <year> 1996. </year>
Reference-contexts: Providing bounded-time replay of any interval and supporting short interval lengths, on the order of 10 or 20 seconds, are necessary for the debugging tool to be practical and useful. Previous work <ref> [19] </ref> has focused on developing state machines for efficiently detecting unique-spanning 0 reads. <p> A two-state machine for detecting unique-spanning 0 reads which also handles system calls is shown in Fig. 2. The start state is denoted with a bold circle. This machine was the starting point for our work in designing a fast machine for replay tracing <ref> [19] </ref>. Before examining the evolution of the more complex machines, we revisit our simple example interval in Fig. 3, this time showing the state of the monitoring machines for the words at addresses A and B after each event. <p> We developed the idea of using the copy-on-write virtual memory facility provided by the operating system to perform efficient, automatic buffering of values that we need to trace, but are overwritten prior to the end of the interval <ref> [19] </ref>. Prior to the execution of each interval, we execute the fork (2) system call to create a copy of the user process. <p> These out-of-order traces may complicate replay. We considered monitoring machines for each of these approaches in <ref> [19] </ref>, and selected a machine using the second method for our initial prototype. This monitoring machine is shown in Fig. 5. This machine includes transitions for full-word and partial-word loads and stores, system calls, and interval boundaries. <p> Although this property is not necessary for implementing the replay algorithm, we had previously shown that this feature can be used to implement flowback debugging queries <ref> [19] </ref>. The idea of flowback debugging is that while working in the debugger, the programmer may observe that a variable has an incorrect value. <p> Register Use %g0 Zero %g1 Volatile (used in PLT) %g2 Temporary for instrumentation %g3 Temporary for instrumentation %g4 Constant value 0x80000000 %g5 Temporary for instrumentation %g6 Constant value 0x80001fff %g7 Software Instruction Counter 4.3 The Stack As discussed in our earlier work <ref> [19] </ref>, the sparc also has special save and restore instructions to manage register windows, or program views of the actual registers provided by the hardware.
Reference: [20] <author> R. Stallman. </author> <title> Debugging with GDB. Cygnus Support, </title> <address> 4.12 edition, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: To this end, we developed a debugger back-end library which allows existing debuggers such as gdb <ref> [20] </ref> to easily incorporate replay functionality and also provides a framework for building a new debugger specifically designed to take advantage of incremental replay.
Reference: [21] <institution> Sun Microsystems, Inc., Mountain View, CA. Linker and Libraries, </institution> <year> 1995. </year>
Reference-contexts: This program is responsible for mapping in all of the shared libraries upon which the user program depends, performing relocations if necessary, calling any initialization functions provided by the shared libraries, and then transferring control to the start routine embedded in the executable <ref> [21] </ref>. This routine constructs the initial stack frame, invokes the init function which calls library and static C++ object initialization functions, and then calls main. <p> Signals are intercepted as part of the framework's signal architecture, described in more detail next. We intercept calls to the exit routine provided by libc by interposing <ref> [21] </ref> our own version of this routine in front of the one exported by libc. <p> Our basic goal was to create a wrapper function for each system call in our instrumentation library, which would then be interposed <ref> [21] </ref> in front of the standard C library system call routines. The wrapper executes the appropriate system call trap, writes a trace record indicating which system call was executed and its return value, and then invokes another routine to perform appropriate machine transitions on affected memory regions.
Reference: [22] <author> U. Vahalia. </author> <title> UNIX Internals: The New Frontiers. </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1996. </year>
Reference-contexts: Instead, the pages are marked as copy-on-write, and the virtual memory system only copies when the parent or child faults on a given page <ref> [22] </ref>. Using this idea, we developed the monitoring machine shown in Fig. 4. By postponing all tracing until interval boundaries, this machine requires much less run-time overhead than the original two-state machine.
Reference: [23] <author> L. Wall and R. Schwartz. </author> <title> Programming Perl. </title> <publisher> O'Reilly and Associates, </publisher> <address> Sebastopol, CA, </address> <year> 1991. </year>
Reference-contexts: Instead, by adding instrumentation at the assembly source level, we work directly with the input assembly source and then just invoke the standard assembler afterward. With these design decisions made, we were able to implement the complete translator utility in just over 2,000 lines of Perl <ref> [23] </ref> code. name = "sample-rule", n instr = $ATTR LOAD f add %g2, 1, %g2 ! Increment %g2 $f0g An example translator rule is shown in Fig. 18. This rule increments a register we have reserved for instrumentation purposes, %g2, prior to each instruction which loads from memory.
Reference: [24] <author> D. Weaver and T. </author> <title> Germond. The SPARC Architecture Manual: Version 9. </title> <publisher> Prentice-Hall, </publisher> <address> New Jersey, </address> <year> 1994. </year> <month> 49 </month>
Reference-contexts: This instruction returns the number of one bits in a given register, and stores the result in another register. The sparc version 9 architecture provides a popc instruction 25 with this functionality <ref> [24] </ref>. Using popc, we map zero to zero, and non-zero to a value between 1 and 64 (the size in bits of a register on an Ultrasparc), thus meeting the requirements of our function. 4.4.2 Exponential Bit Folding Unfortunately not all architectures have a population count instruction.
References-found: 24

