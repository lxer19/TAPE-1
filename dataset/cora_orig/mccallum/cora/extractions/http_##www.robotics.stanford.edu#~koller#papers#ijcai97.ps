URL: http://www.robotics.stanford.edu/~koller/papers/ijcai97.ps
Refering-URL: http://www.robotics.stanford.edu/~koller/papers/ijcai97.html
Root-URL: http://www.robotics.stanford.edu
Email: koller@cs.stanford.edu  avi@cs.stanford.edu  
Title: Learning probabilities for noisy first-order rules  
Author: Daphne Koller Avi Pfeffer 
Affiliation: Stanford University  Stanford University  
Date: August 1997  
Note: In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence (IJCAI-97), Nagoya, Japan,  
Abstract: First-order logic is the traditional basis for knowledge representation languages. However, its applicability to many real-world tasks is limited by its inability to represent uncertainty. Bayesian belief networks, on the other hand, are inadequate for complex KR tasks due to the limited expressivity of the underlying (propositional) language. The need to incorporate uncertainty into an expressive language has led to a resurgence of work on first-order probabilistic logic. This paper addresses one of the main objections to the incorporation of probabilities into the language: Where do the numbers come from? We present an approach that takes a knowledge base in an expressive rule-based first-order language, and learns the probabilistic parameters associated with those rules from data cases. Our approach, which is based on algorithms for learning in traditional Bayesian networks, can handle data cases where many of the relevant aspects of the situation are unobserved. It is also capable of utilizing a rich variety of data cases, including instances with varying causal structure, and even involving a varying number of individuals. These features allow the approach to be used for a wide range of tasks, such as learning genetic propagation models or learning first-order STRIPS planning operators with uncertain effects.
Abstract-found: 1
Intro-found: 1
Reference: [ Boutilier et al., 1996 ] <author> C.E. Boutilier, N. Friedman, M. Gold-szmidt, and D. Koller. </author> <title> Context-specific independence in bayesian networks. </title> <booktitle> In Proc. </booktitle> <address> UAI, </address> <year> 1996. </year>
Reference-contexts: Thus, we restrict attention to decomposable combination rules, ones which can be expressed using a set of separate nodes corresponding to the different influences, which are then combined in another node. Fortunately, all the commonly occuring combination rules (including noisy-or and tree-structured <ref> [ Boutilier et al., 1996 ] </ref> ) generate CPTs with this property. The KBMC algorithm automatically generates the decomposed representation for these combination rules, thereby facilitating learning. This approach can be applied naturally to planning domains. <p> The location is used as a selector to determine which properties are the relevant ones. Computationally, selection rules require the Bayesian network inference algorithm to take advantage of context-specific independence <ref> [ Boutilier et al., 1996 ] </ref> . 3 Learning Our learning task is to take a set of data cases, C, and return a hypothesis H that explains the data C in the best possible way.
Reference: [ Breese, 1992 ] <author> J.S. Breese. </author> <title> Construction of belief and decision networks. </title> <booktitle> Computational Intelligence, </booktitle> <year> 1992. </year>
Reference-contexts: The compactness of such representations allows a probabilistic model to be represented using a small number of parameters, hopefully resulting in faster learning. 2 Knowledge-based model construction Since the idea of constructing belief networks from a first-order probabilistic knowledge base was first proposed <ref> [ Breese, 1992 ] </ref> , several approaches have been developed. Most of these augment logic-programming style rules with uncertainty parameters. In this paper, we largely follow the framework of [ Ngo et al., 1995 ] .
Reference: [ Dean and Wellman, 1991 ] <author> T. Dean and M. Wellman. </author> <title> Planning and Control. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: In recent years, there has been a growing consensus that the underlying assumptions of this representationdeterministic actions, reliable sensors, and (often) complete observabilityare rarely true in practice, particularly in robotics applications. As a consequence, probabilistic representations have recently started to play a role in planning <ref> [ Kushmerick et al., 1993; Dean and Wellman, 1991 ] </ref> . These representations, however, are typically attribute-based, and are therefore limited in their ability to capture general patterns in action models. FOPL would allow for an integration of these two formalisms.
Reference: [ Friedman and Goldszmidt, 1996 ] <author> N. Friedman and M. Goldszmidt. </author> <title> Learning bayesian networks with local structure. </title> <booktitle> In Proc. </booktitle> <address> UAI, </address> <year> 1996. </year>
Reference-contexts: The first-order rules, however, support a significant reduction in the dimensionality of the parameter space via the parameter sharing encoded in the rules. In general, a reduction in the number of parameters tends to speed up convergence. For example, it has recently been shown <ref> [ Friedman and Goldszmidt, 1996 ] </ref> that exploiting context-specific independence in traditional Bayesian networks can speed up the learning process considerably. The learning procedure presented here suffers from two potential problems: local maxima and overfitting.
Reference: [ Halpern, 1990 ] <author> J. Y. Halpern. </author> <title> An analysis of first-order logics of probability. </title> <journal> Artificial Intelligence, </journal> <volume> 46, </volume> <year> 1990. </year>
Reference: [ Heckerman, 1995 ] <author> D. Heckerman. </author> <title> A tutorial on learning with Bayesian networks. </title> <type> Technical Report MSR-TR-95-06, </type> <institution> Microsoft Research, </institution> <year> 1995. </year>
Reference-contexts: The idea of attaching probabilistic parameters to rules leaves unanswered one of the major objections that have been raised about probabilistic representations: the famous where do the numbers come from question. This issue has been addressed satisfactorily for traditional belief networks <ref> [ Lau-ritzen, 1995; Heckerman, 1995 ] </ref> . In this paper, we show how similar techniques can be used to learn the probabilistic parameters of FOPL rules from data. <p> Finally, we have focused on learning the numeric uncertainty parameters of first-order probabilistic rules. We did not address the problem of learning the structure of the rules. In recent years, there has been significant work both on learning the structure of belief networks (see <ref> [ Heckerman, 1995 ] </ref> for a survey) and on inductive logic programming [ Muggleton, 1992 ] learning deterministic first-order rules. It would be very interesting to see whether the techniques developed in these two areas of research can be integrated, allowing us to learn the causal/rule structure of complex uncertain domains.
Reference: [ Kushmerick et al., 1993 ] <author> N. Kushmerick, S. Hanks, and D. Weld. </author> <title> An algorithm for probabilistic least-commitment planning. </title> <booktitle> In Proc. IJCAI, </booktitle> <year> 1993. </year>
Reference-contexts: In recent years, there has been a growing consensus that the underlying assumptions of this representationdeterministic actions, reliable sensors, and (often) complete observabilityare rarely true in practice, particularly in robotics applications. As a consequence, probabilistic representations have recently started to play a role in planning <ref> [ Kushmerick et al., 1993; Dean and Wellman, 1991 ] </ref> . These representations, however, are typically attribute-based, and are therefore limited in their ability to capture general patterns in action models. FOPL would allow for an integration of these two formalisms. <p> The random variables include other properties of the objects (such as whether they are currently wet and therefore harder to grab), and the locations of objects at different times. The knowledge base consists of STRIPS-like rules with uncertainty (as in <ref> [ Kushmerick et al., 1993 ] </ref> ), stipulating the probability that certain postconditions will hold given that the preconditions hold and an action is taken. Our use of the closed world assumption on context predicates fits naturally with the STRIPS assumptions.
Reference: [ Lauritzen and Spiegelhalter, 1988 ] <author> S. L. Lauritzen and D. J. Spiegelhalter. </author> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> B 50(2), </volume> <year> 1988. </year>
Reference-contexts: By contrast, probabilistic parameters are notoriously difficult to elicit from people. The propagation of genetically transmitted properties was a key example in some of the early research into belief networks <ref> [ Lauritzen and Spiegelhalter, 1988 ] </ref> . Given a particular family tree and set of properties being studied, one can construct a traditional propositional belief network in which the probability of each property being passed from each generation to the next is represented.
Reference: [ Lauritzen, 1995 ] <author> S. L. Lauritzen. </author> <title> The EM algorithm for graphical association models with missing data. </title> <journal> Computational Statistics and Data Analysis, </journal> <volume> 19, </volume> <year> 1995. </year>
Reference-contexts: The observations in each data case become evidence in the resulting network. The conditional probability tables in the resulting networks are related to the parameters corresponding to the rules in the knowledge base. We adaptively learn these parameters, using an extension to the standard EM algorithm <ref> [ Lauritzen, 1995 ] </ref> for learning the parameters of a belief network with fixed structure and hidden variables. We extend it to deal with an ensemble of networks of varying structure, and in which the same parameter can appear several times. <p> In the first stage, it constructs a belief network for each data case by mimicking the knowledge based model construction process. In the second stage, it attempts to find the maximum likelihood hypothesis using the EM method (in a manner analogous to its use for learning Bayesian networks <ref> [ Lauritzen, 1995 ] </ref> ). Let C be a particular data case, D C the evidence in the data case, and N C the the belief network constructed for that data case. The learning algorithm begins by building the network for each data case, via back-chaining from the evidence nodes.
Reference: [ McLachlan and Krishnan, 1997 ] <author> G. J. McLachlan and T. Kr-ishnan. </author> <title> The EM Algorithm and Extensions. </title> <publisher> Wiley Inter-science, </publisher> <year> 1997. </year>
Reference-contexts: Each completion is then treated as a fully-observed data case, but one whose weight is its probability. A new set of parameters is then computed as described above, over the set of weighted data cases. The process is now repeated with the new set of parameters. Standard results (see <ref> [ McLachlan and Krishnan, 1997 ] </ref> ) imply that this procedure converges to a set of parameters which is a local maximum in the likelihood space. <p> The fact that the we get the maximum likelihood estimate for our parameters in the fully observable case implies the de sired convergence property <ref> [ McLachlan and Krishnan, 1997 ] </ref> : Theorem 1: The iterative EM procedure described above converges to a set of parameters which induces a local maximum in the likelihood Pr (C).
Reference: [ Muggleton, 1992 ] <author> S. Muggleton. </author> <title> Inductive Logic Programming. </title> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: We did not address the problem of learning the structure of the rules. In recent years, there has been significant work both on learning the structure of belief networks (see [ Heckerman, 1995 ] for a survey) and on inductive logic programming <ref> [ Muggleton, 1992 ] </ref> learning deterministic first-order rules. It would be very interesting to see whether the techniques developed in these two areas of research can be integrated, allowing us to learn the causal/rule structure of complex uncertain domains.
Reference: [ Ngo et al., 1995 ] <author> L. Ngo, P. Haddawy, and J. Helwig. </author> <title> A theoretical framework for context-sensitive temporal probability model construction with application to plan projection. </title> <booktitle> In Proc. </booktitle> <address> UAI, </address> <year> 1995. </year>
Reference-contexts: Most of these augment logic-programming style rules with uncertainty parameters. In this paper, we largely follow the framework of <ref> [ Ngo et al., 1995 ] </ref> . In this approach, a set of Horn rules describes the ways in which first-order predicates influence each other. Because the influence may be uncertain, each rule has a uncertainty parameter associated with it.
Reference: [ Pearl, 1988 ] <author> J. Pearl. </author> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1988. </year>
Reference-contexts: This limitation, which is crucial in many domains (e.g., medical diagnosis), has led over the last decade to the resurgence of probabilistic reasoning in AI. In particular, Bayesian belief networks <ref> [ Pearl, 1988 ] </ref> have been shown to be a principled and useful framework for reasoning in an uncertain domain. However, belief networks do not, by themselves, provide a complete solution for very large-scale knowledge representation tasks. <p> For example, if both a person's parents have a gene, the first rule will fire twice, for the two different values of Q. In such cases, we need a combination rule to indicate how the different possible causes interact. One very common combination rule is noisy-or <ref> [ Pearl, 1988 ] </ref> , which describes a situation in which an effect happens whenever any of its potential causes succeeds in making it happen, and the different causal influences act independently.
Reference: [ Poole, 1993 ] <author> David Poole. </author> <title> Probabilistic horn abduction and bayesian networks. </title> <journal> Artificial Intelligence, </journal> <volume> 64(1), </volume> <year> 1993. </year>
Reference: [ Rabiner and Juang, 1986 ] <author> L. R. Rabiner and B. H. Juang. </author> <title> An introduction to hidden markov models. </title> <journal> IEEE ASSP Magazine, </journal> <year> 1986. </year>
Reference-contexts: Thus, each of the nodes derived from r can be viewed as a separate experiment for the parameters associated with r. Each should therefore make a separate contribution to the count for those parameters. This situation is now analogous to the one that arises in learning Hidden Markov Models <ref> [ Rabiner and Juang, 1986 ] </ref> , where we also have data cases of varying structure and parameter sharing in each data case. Formally, let r be some rule, and be one of its parameters.
Reference: [ Szolovits and Pauker, 1992 ] <author> P. Szolovits and S.P. Pauker. </author> <title> Pedigree analysis for genetic counseling. </title> <booktitle> In Proc. 7th World Congress on Medical Informatics, </booktitle> <year> 1992. </year>
Reference-contexts: However, a new network must be specially constructed for every family tree. Currently, this is either done manually or using a special-purpose procedural program <ref> [ Szolovits and Pauker, 1992 ] </ref> . Using a first order representation, one can capture the general mechanism of gene inheritance using a small number of rules. These can be used to automatically generate an appropriate belief network for any family tree and any set of properties.
References-found: 16

