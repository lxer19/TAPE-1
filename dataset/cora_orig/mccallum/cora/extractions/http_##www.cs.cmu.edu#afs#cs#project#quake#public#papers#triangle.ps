URL: http://www.cs.cmu.edu/afs/cs/project/quake/public/papers/triangle.ps
Refering-URL: http://www.cs.duke.edu/~jeffe/compgeom/code.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: jrs@cs.cmu.edu  
Title: Triangle: Engineering a 2D Quality Mesh Generator and Delaunay Triangulator  
Author: Jonathan Richard Shewchuk 
Address: Pittsburgh, Pennsylvania 15213  
Affiliation: School of Computer Science Carnegie Mellon University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Francis Avnaim, Jean-Daniel Boissonnat, Olivier Dev-illers, Franco P. Preparata, and Mariette Yvinec. </author> <title> Evaluating Signs of Determinants Using Single-Precision Arithmetic. </title> <year> 1995. </year>
Reference-contexts: It is common to hear reports of implementations being slowed by factors of ten or more as a consequence. The goal of improving the speed of correct geometric calculations has received much recent attention <ref> [4, 8, 1] </ref>, but the most promising proposals take integer or rational inputs, often of limited precision. These methods do not appear to be usable if it is convenient or necessary to use ordinary floating-point inputs.
Reference: [2] <author> Marshall Bern and David Eppstein. </author> <title> Mesh Generation and Optimal Triangulation. </title> <editor> Computing in Euclidean Geometry (Ding-Zhu Du and Frank Hwang, editors), </editor> <booktitle> Lecture Notes Series on Computing, </booktitle> <volume> volume 1, </volume> <pages> pages 23-90. </pages> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1992. </year>
Reference-contexts: I assume the reader is familiar with Delaunay triangulations, constrained Delaunay triangulations, and the incremental insertion algorithms for constructing them. Consult the survey by Bern and Eppstein <ref> [2] </ref> for an introduction. There are many Delaunay triangulation algorithms, some of which are surveyed and evaluated by Fortune [7] and Su and Drysdale [18].
Reference: [3] <author> L. Paul Chew. </author> <title> Guaranteed-Quality Mesh Generation for Curved Surfaces. </title> <booktitle> Proceedings of the Ninth Annual Symposium on Computational Geometry, </booktitle> <pages> pages 274-280. </pages> <institution> Association for Computing Machinery, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: It produces meshes with no small angles, using relatively few triangles (though the density of triangles can be increased under user control) and allowing the density of triangles to vary quickly over short distances, as illustrated in Figure 4. (Chew <ref> [3] </ref> independently developed a similar algo 3 while constraining angles. No angles are smaller than 24 ffi . rithm.) This section describes Ruppert's Delaunay refinement algorithm as it is implemented in Triangle.
Reference: [4] <author> Kenneth L. Clarkson. </author> <title> Safe and Effective Determinant Evaluation. </title> <booktitle> 33rd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 387-395. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1992. </year>
Reference-contexts: It is common to hear reports of implementations being slowed by factors of ten or more as a consequence. The goal of improving the speed of correct geometric calculations has received much recent attention <ref> [4, 8, 1] </ref>, but the most promising proposals take integer or rational inputs, often of limited precision. These methods do not appear to be usable if it is convenient or necessary to use ordinary floating-point inputs.
Reference: [5] <author> Rex A. Dwyer. </author> <title> A Faster Divide-and-Conquer Algorithm for Constructing Delaunay Triangulations. </title> <booktitle> Algo-rithmica 2(2) </booktitle> <pages> 137-151, </pages> <year> 1987. </year>
Reference-contexts: Triangle does not use bucketing because it is easily defeated, as discussed in the appendix.) The agreement between my results and those of Su and Drysdale lends support to their ranking of algorithms. An important optimization to the divide-and-conquer algorithm, adapted from Dwyer <ref> [5] </ref>, is to partition the vertices with alternating horizontal and vertical cuts (Lee and Schachter's algorithm uses only vertical cuts). Alternating cuts speed the algorithm and, when exact arithmetic is disabled, reduce its likelihood of failure. One million points can be triangulated correctly in a minute on a fast workstation.
Reference: [6] <author> Steven Fortune. </author> <title> A Sweepline Algorithm for Vorono Diagrams. </title> <journal> Algorithmica 2(2) </journal> <pages> 153-174, </pages> <year> 1987. </year> <title> [7] . Vorono Diagrams and Delaunay Triangulations. </title> <editor> Computing in Euclidean Geometry (Ding-Zhu Du and Frank Hwang, editors), </editor> <booktitle> Lecture Notes Series on Computing, </booktitle> <volume> volume 1, </volume> <pages> pages 193-233. </pages> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1992. </year>
Reference-contexts: Their results indicate a rough parity in speed among the incremental insertion algorithm of Lawson [11], the divide-and-conquer algorithm of Lee and Schachter [12], and the plane-sweep algorithm of Fortune <ref> [6] </ref>; however, the Supported in part by the Natural Sciences and Engineering Research Council of Canada under a 1967 Science and Engineering Scholarship and by the National Science Foundation under Grant ASC-9318163. implementations they study were written by different people.
Reference: [8] <author> Steven Fortune and Christopher J. Van Wyk. </author> <title> Efficient Exact Arithmetic for Computational Geometry. </title> <booktitle> Proceedings of the Ninth Annual Symposium on Computational Geometry, </booktitle> <pages> pages 163-172. </pages> <institution> Association for Computing Machinery, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: It is common to hear reports of implementations being slowed by factors of ten or more as a consequence. The goal of improving the speed of correct geometric calculations has received much recent attention <ref> [4, 8, 1] </ref>, but the most promising proposals take integer or rational inputs, often of limited precision. These methods do not appear to be usable if it is convenient or necessary to use ordinary floating-point inputs. <p> For instance, the adaptive orientation test is slow only if the points being tested are nearly or exactly collinear. The orientation and incircle tests both work by computing the sign of a determinant. Fortune and Van Wyk <ref> [8] </ref> take advantage of the fact that only the sign is needed by using a floating-point filter: the determinant is first evaluated approximately, and only if forward error analysis indicates that the sign of the approximate result cannot be trusted does one use an exact test.
Reference: [9] <author> Leonidas J. Guibas, Donald E. Knuth, and Micha Sharir. </author> <title> Randomized Incremental Construction of Delaunay and Vorono Diagrams. </title> <journal> Algorithmica 7(4) </journal> <pages> 381-413, </pages> <year> 1992. </year> <month> 9 </month>
Reference-contexts: Triangle also checks the previously inserted point, be cause in many practical point sets, any two consecutive points have a high likelihood of being near each other. A more elaborate point location scheme such as that suggested by Guibas, Knuth, and Sharir <ref> [9] </ref> could be used (along with randomization of the insertion order) to obtain an expected O (n log n) triangulation algorithm, but the data structure used for location is likely to take up as much memory as the triangulation itself, and unlikely to surpass the performance of the divide-and-conquer algorithm; hence,
Reference: [10] <author> Leonidas J. Guibas and Jorge Stolfi. </author> <title> Primitives for the Manipulation of General Subdivisions and the Computation of Vorono Diagrams. </title> <journal> ACM Transactions on Graphics 4(2) </journal> <pages> 74-123, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: Should one choose a data structure that uses a record to represent each edge, or one that uses a record to represent each triangle? Triangle was originally written using Guibas and Stolfi's quad-edge data structure <ref> [10] </ref> (without the Flip operator), then rewritten using a triangle-based data structure. <p> Despite the fundamental differences between the data structures, the quad-edge-based and triangle-based implementations of Triangle are both faithful to the Delaunay triangulation algorithms presented by Guibas and Stolfi <ref> [10] </ref> (I did not implement a quad-edge sweepline algorithm), and hence offer a fair comparison of the data structures.
Reference: [11] <author> C. L. Lawson. </author> <title> Software for C 1 Surface Interpolation. Mathematical Software III (John R. Rice, </title> <booktitle> editor), </booktitle> <pages> pages 161-194. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1977. </year>
Reference-contexts: Consult the survey by Bern and Eppstein [2] for an introduction. There are many Delaunay triangulation algorithms, some of which are surveyed and evaluated by Fortune [7] and Su and Drysdale [18]. Their results indicate a rough parity in speed among the incremental insertion algorithm of Lawson <ref> [11] </ref>, the divide-and-conquer algorithm of Lee and Schachter [12], and the plane-sweep algorithm of Fortune [6]; however, the Supported in part by the Natural Sciences and Engineering Research Council of Canada under a 1967 Science and Engineering Scholarship and by the National Science Foundation under Grant ASC-9318163. implementations they study were
Reference: [12] <author> D. T. Lee and B. J. Schachter. </author> <title> Two Algorithms for Constructing a Delaunay Triangulation. </title> <journal> International Journal of Computer and Information Sciences 9(3) </journal> <pages> 219-242, </pages> <year> 1980. </year>
Reference-contexts: There are many Delaunay triangulation algorithms, some of which are surveyed and evaluated by Fortune [7] and Su and Drysdale [18]. Their results indicate a rough parity in speed among the incremental insertion algorithm of Lawson [11], the divide-and-conquer algorithm of Lee and Schachter <ref> [12] </ref>, and the plane-sweep algorithm of Fortune [6]; however, the Supported in part by the Natural Sciences and Engineering Research Council of Canada under a 1967 Science and Engineering Scholarship and by the National Science Foundation under Grant ASC-9318163. implementations they study were written by different people.
Reference: [13] <author> Scott A. Mitchell. </author> <title> Cardinality Bounds for Triangulations with Bounded Minimum Angle. </title> <booktitle> Sixth Canadian Conference on Computational Geometry, </booktitle> <year> 1994. </year>
Reference-contexts: The reasoning behind the result is as follows. Suppose a segment in a conforming triangulation has been split into two subsegments of lengths a and b, as illustrated in Figure 15. Mitchell <ref> [13] </ref> proves that if the triangulation has no angles smaller than , then the ratio b=a has an upper bound of (2 cos ) 180 ffi = . (This bound is tight if 180 ffi = is an integer; 6 Hence any bound on the smallest angle of a triangulation imposes
Reference: [14] <author> Ernst P. M ucke, Isaac Saias, and Binhai Zhu. </author> <title> Fast Randomized Point Location Without Preprocessing in Two-and Three-dimensional Delaunay Triangulations. </title> <booktitle> Proceedings of the Twelfth Annual Symposium on Computational Geometry. Association for Computing Machinery, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: though there are many more boundary edges in the cocircular point set and the splay tree grows to be much larger (containing O (n) boundary edges instead of O ( p Triangle's incremental insertion algorithm for Delaunay triangulation uses the point location method proposed by M ucke, Saias, and Zhu <ref> [14] </ref>.
Reference: [15] <author> Jim Ruppert. </author> <title> A Delaunay Refinement Algorithm for Quality 2-Dimensional Mesh Generation. </title> <journal> Journal of Algorithms 18(3) </journal> <pages> 548-585, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: This eliminates the space advantage of the triangular data structure, but not its time advantage. Triangle uses the longer record only if constraints are needed. 3 Ruppert's Delaunay Refinement Algorithm Ruppert's algorithm for two-dimensional quality mesh generation <ref> [15] </ref> is perhaps the first theoretically guaranteed meshing algorithm to be truly satisfactory in practice. <p> Each segment is inserted by deleting the triangles it overlaps, and retriangulating the regions on each side of the segment. No new vertices are inserted. For reasons explained in Section 3.1, Triangle uses the constrained Delaunay triangulation by default. The third stage of the algorithm, which diverges from Rup-pert <ref> [15] </ref>, is to remove triangles from concavities and holes (Figure 8). <p> In each image, highlighted segments or triangles are about to be split, and highlighted vertices are about to be deleted. Note that the algorithm easily accommodates internal boundaries and holes. The refinement stage is illustrated in Figure 12. Rup-pert <ref> [15] </ref> proves that this procedure halts for an angle constraint of up to 20:7 ffi . In practice, the algorithm generally halts with an angle constraint of 33:8 ffi , but often fails to terminate given an angle constraint of 33:9 ffi . <p> amusing to consider whether the angle constraint can be met if one is allowed an infinite number of triangles.) If some PSLGs do not have quality triangulations, what are the implications for shielding? Triangle implements a variant of shielding known as modified segment splitting using concentric circular shells (see Ruppert <ref> [15] </ref> for details), which is generally effective in practice for PSLGs that have small angles greater than 5 ffi , and often for smaller angles. Shielding is useful even though it cannot solve all problems.
Reference: [16] <author> Jonathan Richard Shewchuk. </author> <title> Robust Adaptive Floating-Point Geometric Predicates. </title> <booktitle> Proceedings of the Twelfth Annual Symposium on Computational Geometry. Association for Computing Machinery, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Triangle's adaptive implementations carry this suggestion to its logical extreme by computing a sequence of successively more accurate approximations to the determinant, stopping only when the accuracy of the sign is assured. To reduce computation time, some of these approximations can reuse previous, less accurate computations. Shewchuk <ref> [16] </ref> presents details of the arbitrary precision arithmetic algorithms and the adaptivity scheme, and provides empirical evidence that multiple-stage adaptivity can significantly improve on two-stage adaptivity when difficult point sets are triangulated. Using the adaptive tests, Triangle computes Delaunay triangulations, constrained Delaunay triangulations, and convex hulls exactly, roundoff error notwithstanding.
Reference: [17] <author> Daniel Dominic Sleator and Robert Endre Tarjan. </author> <title> Self-Adjusting Binary Search Trees. </title> <journal> Journal of the Association for Computing Machinery 32(3) </journal> <pages> 652-686, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: However, bucketing outperforms a heap on small point sets. Triangle's implementation uses a heap as well, and also uses a splay tree <ref> [17] </ref> to store mesh boundary edges, so that an O (n log n) running time is attained, regardless of the distribution of points.
Reference: [18] <author> Peter Su and Robert L. Scot Drysdale. </author> <title> A Comparison of Sequential Delaunay Triangulation Algorithms. </title> <booktitle> Proceedings of the Eleventh Annual Symposium on Computational Geometry, </booktitle> <pages> pages 61-70. </pages> <institution> Association for Computing Machinery, </institution> <month> June </month> <year> 1995. </year> <month> 10 </month>
Reference-contexts: Consult the survey by Bern and Eppstein [2] for an introduction. There are many Delaunay triangulation algorithms, some of which are surveyed and evaluated by Fortune [7] and Su and Drysdale <ref> [18] </ref>. <p> appear in Appendix A.) Table 1 compares the algorithms, including versions that use exact arithmetic (see Section 4) to achieve robustness, and versions that use approximate arithmetic and are hence faster but may fail or produce incorrect output. (The robust and non-robust versions are otherwise identical.) As Su and Drysdale <ref> [18] </ref> also found, the divide-and-conquer algorithm is fastest, with the sweepline algorithm second. The incremental algorithm performs poorly, spending most of its time in point location. (Su and Drysdale produced a better incremental insertion implementation by using bucketing to perform point location, but it still ranks third. <p> A Additional Implementation Notes The sweepline and incremental Delaunay triangulation implementations compared by Su and Drysdale <ref> [18] </ref> each use some variant of uniform bucketing to locate points. Bucketing yields fast implementations on uniform point sets, but is easily defeated; a small, dense cluster of points in a large, sparsely populated region may all fall into a single bucket. <p> Fortune's own implementation, available from Netlib, uses bucketing to perform both these functions; hence, an O (n log n) running time is not guaranteed, and Su and Drysdale <ref> [18] </ref> found that the original implementation exhibits O (n 3=2 ) performance on uniform random point sets. By modifying Fortune's code to use a heap to store events, they obtained O (n log n) running time and better performance on large point sets (having more than 50,000 points).
References-found: 17

