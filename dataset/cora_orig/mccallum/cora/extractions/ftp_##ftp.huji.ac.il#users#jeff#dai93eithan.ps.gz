URL: ftp://ftp.huji.ac.il/users/jeff/dai93eithan.ps.gz
Refering-URL: http://www.cs.huji.ac.il/labs/dai/papers.html
Root-URL: 
Email: tantush@cs.huji.ac.il, jeff@cs.huji.ac.il  
Title: Multi-Agent Planning as the Process of Merging Distributed Sub-plans  
Author: Eithan Ephrati Jeffrey S. Rosenschein 
Address: Jerusalem, Israel  
Affiliation: Computer Science Department Hebrew University,  
Abstract: ABSTRACT: The subject of multi-agent planning has been of continuing concern in Distributed Artificial Intelligence (DAI). In this paper, we suggest an approach to multi-agent planning that contains heuristic elements. Our method makes use of subgoals, and derived sub-plans, to construct a global plan. Agents solve their individual sub-plans, which are then merged into a global plan. The suggested approach reduces overall planning time and derives a plan that approximates the optimal global plan that would have been derived, given those original subgoals.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Chapman. </author> <title> Planning for conjuctive goals. </title> <journal> Artificial Intelligence, </journal> <volume> 32 </volume> <pages> 333-377, </pages> <year> 1987. </year>
Reference-contexts: hM (r (a i ); r (g)); T (g; 2; 7); M (r (a i ); r (d)); T (d; 12; 14); M (14; 10); T (h; 10; 11); M (11; 7); T (g; 7; 11)i). * P (E) denotes the set of "grounded" plans (what Chapman calls "complete" plans <ref> [1] </ref>) that is induced by the set of constraints E. <p> constraints that can be satisfied by invoking at most one operator, given the initial set of constraints E (F 1 ollow (E) = fI j 9op9P [op (P (E)) j= I ]g). 4 Constraints are temporally ordered sets of the domain's predicates associated with the appropriate limitations on their codesignation <ref> [1] </ref>. 5 Similarly F 2 ollow (E) is the set of constraints that can be satisfied by invoking at most two operators simultaneously (by two agents) given E, and F n ollow (E) is the set that can be achieved by n simultaneous actions. * An interface point I (p; fp
Reference: [2] <author> D. Corkill. </author> <title> Hierarchical planning in a distributed environment. </title> <booktitle> In Proceedings of the Sixth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 168-175, </pages> <address> Tokyo, </address> <month> August </month> <year> 1979. </year>
Reference-contexts: 1 Introduction The subject of multi-agent planning has been of continuing concern in Distributed Artificial Intelligence (DAI). Some of the earliest work in the field, such as Smith's Contract Net [14] and Corkill's work on distributing the NOAH planner <ref> [2] </ref>, were directly addressing the question of how to get groups of agents to carry out coordinated, coherent activity.
Reference: [3] <author> T. Dean and M. Boddy. </author> <title> An analysis of time-dependent planning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 49-54, </pages> <address> Saint Paul, Minnesota, </address> <month> August </month> <year> 1988. </year>
Reference-contexts: These constraints can be achieved by M i (r (a i ); r (b)) and M j (r (a j ); r (c)). The bids that a 1 and a 2 give to these actions are respectively [4; 12] and <ref> [6; 3] </ref>. Therefore, a 1 is "assigned" to block b and a 2 is assigned to block c. The constructed plan is hfM 1 (0; 4); M 2 (9; 12)gi yielding a g value of 7 (= 4 + 3) where both agents perform in parallel. <p> The plan is improved due to "re-examination" of the heuristic decisions made so far (within the merging process itself and its preceding phases). Thus, the general algorithm may be considered as an anytime multi-agent planning procedure <ref> [3, 19] </ref>. Figure 4 describes the performance profile of the process (the step function lines). The dotted line describes a "diminishing returns" type decision procedure, to which the process corresponds. As shown, in our case, the performance profile is monotonically nondecreasing, instead of monotonically increasing.
Reference: [4] <author> E. H. Durfee. </author> <title> Coordination of Distributed Problem Solvers. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1988. </year>
Reference-contexts: More recent research on the issue of multi-agent planning includes that of Martial [18, 17], Katz and Rosenschein [10], Durfee <ref> [5, 4, 6] </ref>, and Lansky [12]. The term multi-agent planning has been used to describe both "planning for multiple agents" (where the planning process itself may be centralized), and "planning by multiple agents" (where the planning process is distributed among the agents). <p> These constraints can be achieved by M i (r (a i ); r (b)) and M j (r (a j ); r (c)). The bids that a 1 and a 2 give to these actions are respectively <ref> [4; 12] </ref> and [6; 3]. Therefore, a 1 is "assigned" to block b and a 2 is assigned to block c. The constructed plan is hfM 1 (0; 4); M 2 (9; 12)gi yielding a g value of 7 (= 4 + 3) where both agents perform in parallel.
Reference: [5] <author> E. H. Durfee and V. R. Lesser. </author> <title> Using partial global plans to coordinate distributed problem solvers. </title> <booktitle> Proceedings of the 1987 IJCAI, </booktitle> <pages> pages 875-883, </pages> <year> 1987. </year>
Reference-contexts: More recent research on the issue of multi-agent planning includes that of Martial [18, 17], Katz and Rosenschein [10], Durfee <ref> [5, 4, 6] </ref>, and Lansky [12]. The term multi-agent planning has been used to describe both "planning for multiple agents" (where the planning process itself may be centralized), and "planning by multiple agents" (where the planning process is distributed among the agents).
Reference: [6] <author> E. H. Durfee and V. R. Lesser. </author> <title> Negotiating task decomposition and allocating using partial global plannning. </title> <editor> In A. H. Bond and Les Gasser, editors, </editor> <booktitle> Readings in Distributed Artificial Intelligence, </booktitle> <volume> Vol. II, </volume> <pages> pages 229-243. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, California, </address> <year> 1989. </year>
Reference-contexts: More recent research on the issue of multi-agent planning includes that of Martial [18, 17], Katz and Rosenschein [10], Durfee <ref> [5, 4, 6] </ref>, and Lansky [12]. The term multi-agent planning has been used to describe both "planning for multiple agents" (where the planning process itself may be centralized), and "planning by multiple agents" (where the planning process is distributed among the agents). <p> These constraints can be achieved by M i (r (a i ); r (b)) and M j (r (a j ); r (c)). The bids that a 1 and a 2 give to these actions are respectively [4; 12] and <ref> [6; 3] </ref>. Therefore, a 1 is "assigned" to block b and a 2 is assigned to block c. The constructed plan is hfM 1 (0; 4); M 2 (9; 12)gi yielding a g value of 7 (= 4 + 3) where both agents perform in parallel.
Reference: [7] <author> E. Ephrati and J. S. Rosenschein. </author> <title> Distributed consensus mechanisms for self-interested heterogeneous agents. </title> <booktitle> In First International Conference on Intelligent and Cooperative Information Systems, </booktitle> <address> Rotter-dam, </address> <month> May </month> <year> 1993. </year> <note> To appear. </note>
Reference-contexts: The procedure has the following advantages: (a) alternatives are generated by the entire group dynamically (allowing the procedure to be distributed <ref> [7] </ref>); (b) conflicts and "positive" interactions are addressed within a unified framework. (c) The complexity of the merging process is significantly reduced; First because the branching factor of the search space is strictly constrained by the individual plans' constraints.
Reference: [8] <author> E. Ephrati and J. S. Rosenschein. </author> <title> Multi-agent planning through exploitation of subgoals. </title> <type> Technical report, </type> <institution> Computer Science Department, Hebrew University, Jerusalem, Israel, </institution> <year> 1993. </year> <note> In preparation. </note>
Reference-contexts: In the original example in Section 2.2, two possible coherent instances are found after two iterations of the first step, as shown in Figure 3. The first coherent instance is chosen. The rest of the example is worked out in <ref> [8] </ref>. 5 The Anytime Planning Approach As described in the previous section, the merging process is preceded by two heuristic phases in the algorithm (instantiation of subgoals and binding of soft interface points).
Reference: [9] <author> J. J. </author> <title> Finger. Exploiting Constraints in Design Synthesis. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <address> CA, </address> <year> 1986. </year>
Reference-contexts: is a sequence of operators hop 1 ; : : : ; op m i that ends in some instance, g i , of G i , starting at g 0 i . * Each agent has a cost function (C: OP fi A ) IR) over the domain's operators <ref> [9] </ref>. The cost of a j 's plan c j (p j ) is defined to be P m 2.2 An Example Consider a scenario in the discrete grid sticky blocks world. 2 There are ten blocks (a; : : : ; j) in the world.
Reference: [10] <author> Matthew Katz and Jeffrey S. Rosenschein. </author> <title> Verifying plans for multiple agents. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <note> 1993. To appear. </note>
Reference-contexts: More recent research on the issue of multi-agent planning includes that of Martial [18, 17], Katz and Rosenschein <ref> [10] </ref>, Durfee [5, 4, 6], and Lansky [12]. The term multi-agent planning has been used to describe both "planning for multiple agents" (where the planning process itself may be centralized), and "planning by multiple agents" (where the planning process is distributed among the agents).
Reference: [11] <author> R. E. Korf. </author> <title> Planning as search: A quantitative approach. </title> <journal> Artificial Intelligence, </journal> <volume> 33 </volume> <pages> 65-88, </pages> <year> 1987. </year>
Reference-contexts: The time complexity of the planning problem is then O (b d ) <ref> [11] </ref>. 1 In a multi-agent environment, where each agent is capable of carrying out each of the possible operators (possibly with differing costs), the complexity may be even worse. A centralized planner would need to consider assigning each operator to each agent. <p> Let b i and d i denote respectively the branching factor and depth of the optimal plan that achieves g i (in general b i b n and d i d n ). Then, as shown by Korf <ref> [11] </ref>, if the subgoals are independent or serializable, 1 the central multi-agent planning time complexity can be reduced to P This phenomena can be exploited most naturally in a multi-agent environment.
Reference: [12] <author> A. L. Lansky. </author> <title> Localized search for controlling automated reasoning. </title> <booktitle> In Proceedings of the Workshop on Innovative Approachess to Planning, Scheduling and Control, </booktitle> <pages> pages 115-125, </pages> <address> San Diego, </address> <year> 1990. </year>
Reference-contexts: More recent research on the issue of multi-agent planning includes that of Martial [18, 17], Katz and Rosenschein [10], Durfee [5, 4, 6], and Lansky <ref> [12] </ref>. The term multi-agent planning has been used to describe both "planning for multiple agents" (where the planning process itself may be centralized), and "planning by multiple agents" (where the planning process is distributed among the agents). <p> These constraints can be achieved by M i (r (a i ); r (b)) and M j (r (a j ); r (c)). The bids that a 1 and a 2 give to these actions are respectively <ref> [4; 12] </ref> and [6; 3]. Therefore, a 1 is "assigned" to block b and a 2 is assigned to block c. The constructed plan is hfM 1 (0; 4); M 2 (9; 12)gi yielding a g value of 7 (= 4 + 3) where both agents perform in parallel. <p> Our approach does away with the need for several plans by treating constraints instead of sequences of actions. We also have agents do the "merging" in parallel. Our approach also resembles the GEMPLAN planning system <ref> [12] </ref>. There, the search space is divided into "regions" of activity. Planning in each region is done separately, but an important part of the planning process within a region is the updating of its overlapping regions.
Reference: [13] <author> D. S. Nau, Q. Yang, and J. Hendler. </author> <title> Optimization of multiple-goal plans with limited interaction. </title> <booktitle> In Proceedings of the Workshop on Innovative Approaches to Planning, Scheduling and Control, </booktitle> <pages> pages 160-165, </pages> <address> San Diego, California, </address> <month> November </month> <year> 1990. </year>
Reference-contexts: the following claim: Theorem 2 At any step k of the procedure, i's best strategy is to bid over the induced actions at that step (all operators in P (Ex (A k+ )) according to his true cost. 7 Related Work An approach similar to our own is taken in <ref> [13] </ref> to find an optimal plan. It is shown there how planning for multiple goals can be done by first generating several plans for each subgoal and than merging these plans.
Reference: [14] <author> Reid G. Smith. </author> <title> A Framework for Problem Solving in a Distributed Processing Environment. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1978. </year>
Reference-contexts: 1 Introduction The subject of multi-agent planning has been of continuing concern in Distributed Artificial Intelligence (DAI). Some of the earliest work in the field, such as Smith's Contract Net <ref> [14] </ref> and Corkill's work on distributing the NOAH planner [2], were directly addressing the question of how to get groups of agents to carry out coordinated, coherent activity.
Reference: [15] <author> G. J. Sussman. </author> <title> A Computational Model of Skill Aquisition. </title> <publisher> American Elsevier, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: g 2 = fA (b; 16); A (c; 16); O (b; c; H )g. 5 The lower part of Figure 2 describes the resulting states 5 This is reminiscent of Sussman's Anomaly in the single-agent planning scenario|where the plan to achieve one subgoal obstructs the plan that achieves the other <ref> [15] </ref>. Note that since we demand a coherent instance all blocks 6 that the two corresponding sub-plans would result in, if executed in isolation.
Reference: [16] <author> W. Vickrey. Counterspeculation, </author> <title> auctions and competitive sealed tenders. </title> <journal> Journal of Finanace, </journal> <volume> 16 </volume> <pages> 8-37, </pages> <year> 1961. </year>
Reference-contexts: Fortunately, there do exist solutions to this problem, such that the above plan choice mechanism can be used even when the agents are not necessarily benevolent and honest. By using a variant 13 of the Vickrey Mechanism <ref> [16] </ref>, more commonly known as the "Dutch Auction," it is possible to ensure that all agents will bid honestly. This is done by minor changes to Step 4 of the procedure given in Section 3.2.
Reference: [17] <author> F. von Martial. </author> <title> Multiagent plan relationship. </title> <booktitle> In Proceedings of the Ninth International Workshop on Distributed Artificial Intelligence, </booktitle> <pages> pages 59-72, </pages> <address> Rosario Resort, Eastsound, Washington, </address> <year> 1989. </year>
Reference-contexts: More recent research on the issue of multi-agent planning includes that of Martial <ref> [18, 17] </ref>, Katz and Rosenschein [10], Durfee [5, 4, 6], and Lansky [12]. The term multi-agent planning has been used to describe both "planning for multiple agents" (where the planning process itself may be centralized), and "planning by multiple agents" (where the planning process is distributed among the agents).
Reference: [18] <author> F. von Martial. </author> <title> Coordination of plans in multiagent worlds by taking advantage of the favor relation. </title> <booktitle> In Proceedings of the Tenth International Workshop on Distributed Artificial Intelligence, </booktitle> <address> Bandera, Texas, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: More recent research on the issue of multi-agent planning includes that of Martial <ref> [18, 17] </ref>, Katz and Rosenschein [10], Durfee [5, 4, 6], and Lansky [12]. The term multi-agent planning has been used to describe both "planning for multiple agents" (where the planning process itself may be centralized), and "planning by multiple agents" (where the planning process is distributed among the agents). <p> partial multi-agent plan that has already been constructed. h 0 is the sum of the approximate remaining costs that each agent assigns to his own sub-plan. 4 In general h 0 is an underestimate, since plans will tend to interfere with one another, but due to overlapping constraints ("favor relations" <ref> [18] </ref>, or "positive" interactions) it might sometimes be an overestimate.
Reference: [19] <author> S. Zilberstein and S. J. Russell. </author> <title> Effecient resource-bounded reasoning in AT-RALPH. </title> <booktitle> In Artificial Intelligence Planning Systems: Proceedings of the First International Conference, </booktitle> <pages> pages 260-266, </pages> <address> College Park, Maryland, </address> <month> June </month> <year> 1992. </year> <month> 15 </month>
Reference-contexts: The plan is improved due to "re-examination" of the heuristic decisions made so far (within the merging process itself and its preceding phases). Thus, the general algorithm may be considered as an anytime multi-agent planning procedure <ref> [3, 19] </ref>. Figure 4 describes the performance profile of the process (the step function lines). The dotted line describes a "diminishing returns" type decision procedure, to which the process corresponds. As shown, in our case, the performance profile is monotonically nondecreasing, instead of monotonically increasing.
References-found: 19

