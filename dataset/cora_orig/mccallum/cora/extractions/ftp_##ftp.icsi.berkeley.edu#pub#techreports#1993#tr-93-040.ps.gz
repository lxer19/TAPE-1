URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1993/tr-93-040.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1993.html
Root-URL: http://www.icsi.berkeley.edu
Title: Efficient PRAM Simulation on a Distributed Memory Machine  
Author: Richard M. Karp Michael Luby Friedhelm Meyer auf der Heide 
Note: Research partially supported by NSF operating grant CCR-9016468 and by grant No. 89-00312 from the United States-Israel Binational Science Foundation (BSF), Jerusalem, Israel. Part of work was done during a visit at the International  supported in part by DFG-Forschergruppe "Effiziente Nutzung massiv paralleler Systeme, Teilprojekt 4", and by the Esprit Basic Research Action Nr. 7141 (ALCOM II).  
Date: August 1993  
Address: Berkeley, CA  Germany  Berkeley;  
Affiliation: University of California at Berkeley and International Computer Science Institute,  International Computer Science Institute, Berkeley, CA and UC Berkeley  Heinz Nixdorf Institute and Computer Science Department, University of Paderborn,  Computer Science Institute at  
Pubnum: TR-93-040  
Abstract: We present algorithms for the randomized simulation of a shared memory machine (PRAM) on a Distributed Memory Machine (DMM). In a PRAM, memory conflicts occur only through concurrent access to the same cell, whereas the memory of a DMM is divided into modules, one for each processor, and concurrent accesses to the same module create a conflict. The delay of a simulation is the time needed to simulate a parallel memory access of the PRAM. Any general simulation of an m processor PRAM on a n processor DMM will necessarily have delay at least m=n. A randomized simulation is called time-processor optimal if the delay is O(m=n) with high probability. Using a novel simulation scheme based on hashing we obtain a time-processor optimal simulation with delay O(loglog(n)log fl (n)). The best previous simulations use a simpler scheme based on hashing and have much larger delay: fi(log(n)= loglog(n)) for the simulation of an n processor PRAM on an n processor DMM, and fi(log(n)) in the case where the simulation is time-processor optimal. fl Research partially supported by NSF/DARPA Grant CCR-9005448
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Bast and T. Hagerup. </author> <title> Fast and reliable parallel hashing. </title> <booktitle> In Proc. of the 3rd Ann. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 50-61, </pages> <year> 1991. </year>
Reference-contexts: The structure of these hash functions enables us to analyze the delay in our simulation using a powerful martingale tail estimate that was derived independently in <ref> [1] </ref> and [10]. 2 Computation Models A PRAM consists of processors P 1 ; : : : ; P m and a shared memory with cells U = [p]. The processors work synchronously and have random access to the shared memory cells, each of which can store an integer. <p> RESULT: If jS [ Xj cn then this operation sets SM equal to a parallel hash table storing S [ X; otherwise, the operation returns "failure". 5 The papers <ref> [1] </ref> and [9] give randomized algorithms for realizing a parallel hash table of capacity cn on an n processor PRAM. The inputs and outputs of the operations, as well as the parallel hash table itself, reside in the shared memory of the PRAM. <p> It is not difficult to extend the parallel hash table implementations of <ref> [1] </ref>, [9] so that they work on an n processor DMM with the same performance guarantees as for a PRAM. For the BUILD operation it is assumed that each set S i is presented as an array in module M i . <p> We apply the beautiful tail estimate independently shown in <ref> [1] </ref> and [10] and stated in the following theorem.
Reference: [2] <author> B. Bollobas. </author> <title> Random Graphs. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1985. </year>
Reference-contexts: There is an edge from h 1 (x) to h 2 (x) labeled x for each x 2 S. This graph has the following structural properties. Similar properties are well known for random graphs, (see <ref> [2] </ref>), the proof techniques are very similar. Note that both h 1 and h 2 are (1; p n)-universal on S because of Lemma 5.4. Lemma 6.3 Let H be the graph obtained from G by removing all labels and directions from the edges.
Reference: [3] <author> J. L. Carter and M. N. Wegman. </author> <title> Universal classes of hash functions. </title> <journal> J. Comput. Syst. Sci., </journal> <volume> 18 </volume> <pages> 143-154, </pages> <year> 1979. </year>
Reference-contexts: In [7] and [12] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. The expected contention can be made as small as O (log (n)= loglog (n)), if log (n)-universal hash-functions as introduced in <ref> [3] </ref> are used. These hash functions have evaluation time O (log (n)). Thus these simulations have delay O (log (n)). If a complete interconnection network is assumed then the delay can be reduced. In [11], log (n)= loglog (n)-universal hash functions from [3] are used, yielding delay O (log (n)= loglog <p> (n)), if log (n)-universal hash-functions as introduced in <ref> [3] </ref> are used. These hash functions have evaluation time O (log (n)). Thus these simulations have delay O (log (n)). If a complete interconnection network is assumed then the delay can be reduced. In [11], log (n)= loglog (n)-universal hash functions from [3] are used, yielding delay O (log (n)= loglog (n)). <p> Let H p;n be a family of hash functions mapping U into [n]. In <ref> [3] </ref> the notion of universality for families of hash functions was introduced as a measure of the quality of the family for classical hashing purposes. <p> The first one is the class H d p;n fh : [p] ! [n]g of functions h (x) mod n where h is a polynomial of degree d 1 over ZZ p . H d p;n was introduced by Carter and Wegman in <ref> [3] </ref>. It is a (2; d)-universal class. The second class H n k ;n fh : [n k ] ! [n]g introduced by Siegel in [13] consists of more complicated functions. <p> If h is randomly drawn from H d p;n or H n k ;n then Prob [h is d-perfect on S 0 ] 1 n ` . Proof : The results (a), (b) are obvious from the definition of the classes, (c) and (d) can be found in <ref> [3] </ref> for H d p;n and in [13] for H n k ;n and (e) is shown in [8].
Reference: [4] <author> M. Dietzfelbinger, A. Karlin, K. Mehlhorn, F. Meyer auf der Heide, H. Rohnert, and R. E. Tarjan. </author> <title> Dynamic perfect hashing: upper and lower bounds. </title> <type> Technical Report 77, </type> <institution> Universitat-GH Paderborn, FB Mathematik-Informatik, </institution> <month> Jan. </month> <year> 1991. </year> <title> (Revised version of paper with same title that appeared in Proc. </title> <booktitle> of the 24th IEEE FOCS, </booktitle> <pages> pages 524-531, </pages> <year> 1988), </year> <note> to appear in SIAM J. Comp. </note>
Reference-contexts: Proof : The results (a), (b) are obvious from the definition of the classes, (c) and (d) can be found in [3] for H d p;n and in [13] for H n k ;n and (e) is shown in [8]. The result (g) is shown in <ref> [4] </ref> for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In [5] and [6] a new class of hash functions is introduced. We only present a special case sufficient for our considerations.
Reference: [5] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> How to distribute a hash table in a complete network. </title> <booktitle> In Proc. of the 22nd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 117-127, </pages> <year> 1990. </year> <month> 24 </month>
Reference-contexts: It simulates an n 1+" processor PRAM on an n processor DMM with optimal expected delay O (n " ). In [15] a time-processor optimal simulation of EREW-PRAMs on DMMs is presented with expected delay O (log (n)), using hash functions introduced in [13]. In <ref> [5] </ref> the same result is shown for CRCW-PRAMs, using a new class of hash functions. 1.2 New Results In the present paper we have chosen to assume a complete interconnection network in order to avoid confounding the effects of memory contention with the effects of routing delays, and to make possible <p> Thus, we can distribute the table among the modules so that accesses to it can be performed in constant time. The analysis of our simulation depends on the properties of a particular p n-universal class of hash functions which combines the constructions given in <ref> [5] </ref> and [13]. <p> The result (g) is shown in [4] for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In <ref> [5] </ref> and [6] a new class of hash functions is introduced. We only present a special case sufficient for our considerations. <p> Let h be defined by (f; g; a). Claim 6.1 For all t 2 [T ], Exp [jA t j] d 2 n. Proof : In <ref> [5] </ref> (see Definition 5.5 and Theorem 6.1) the following is shown. Lemma 6.2 Let S U , jSj tn for some t 1. Let h be as above; h splits S into buckets B 1 ; : : : ; B n . <p> Thus, at the end of loop (ii), at most a set X 0 , jX 0 j n 9=10 , have not gotten an answer, i.e., their corresponding read requests are not yet satisfied, with high probability. This is shown in Theorem 6.1. In <ref> [5] </ref>, it is shown that a random h l 2 R d p;n is d-perfect (for a sufficiently large constant D) on a set X 0 of size at most n 9=10 , with high probability.
Reference: [6] <editor> M. Dietzfelbinger and F. Meyer auf der Heide. </editor> <title> A new universal class of hash functions and dynamic hashing in real time. </title> <editor> In M. S. Paterson, editor, </editor> <booktitle> Proceedings of 17th ICALP, </booktitle> <pages> pages 6-19. </pages> <publisher> Springer, </publisher> <year> 1990. </year> <note> Lecture Notes in Computer Science 443. </note>
Reference-contexts: The result (g) is shown in [4] for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In [5] and <ref> [6] </ref> a new class of hash functions is introduced. We only present a special case sufficient for our considerations. <p> Note that a random h can be chosen by a randomized DMM with p n processors in constant time. 7 For R d p;n , <ref> [6] </ref> shows that for any given S U , jSj n 11=10 , a randomly chosen and fixed (f; g) pair will have, with overwhelming probability, distributional properties with respect to how S is mapped by random a that are very similar to the properties that hold if completely random functions <p> The following lemma is implicitly used in <ref> [6] </ref>. It follows directly from Lemma 5.1 e) and f). Lemma 5.2 Let S U , n jSj n 11=10 .
Reference: [7] <author> A. Karlin and E. Upfal. </author> <title> Parallel hashing | an efficient implementation of shared memory. </title> <booktitle> In Proc. of the 18th Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 160-168, </pages> <year> 1986. </year>
Reference-contexts: The papers [14], <ref> [7] </ref>, [11] and [12] present randomized simulations of n processor PRAMs on n processor DMMs. In [7] and [12] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. <p> The papers [14], <ref> [7] </ref>, [11] and [12] present randomized simulations of n processor PRAMs on n processor DMMs. In [7] and [12] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. The expected contention can be made as small as O (log (n)= loglog (n)), if log (n)-universal hash-functions as introduced in [3] are used.
Reference: [8] <author> C. P. Kruskal, L. Rudolph, and M. Snir. </author> <title> A complexity theory of efficient parallel algorithms. </title> <journal> Theoret. Comput. Sci., </journal> <volume> 71 </volume> <pages> 95-132, </pages> <year> 1990. </year>
Reference-contexts: It is easily seen that, in any time-processor optimal simulation that uses a single hash function to distribute the keys, the expected memory contention, and hence the expected delay, must be (log (n)). The first time-processor optimal simulation was published in <ref> [8] </ref>. It simulates an n 1+" processor PRAM on an n processor DMM with optimal expected delay O (n " ). In [15] a time-processor optimal simulation of EREW-PRAMs on DMMs is presented with expected delay O (log (n)), using hash functions introduced in [13]. <p> Proof : The results (a), (b) are obvious from the definition of the classes, (c) and (d) can be found in [3] for H d p;n and in [13] for H n k ;n and (e) is shown in <ref> [8] </ref>. The result (g) is shown in [4] for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In [5] and [6] a new class of hash functions is introduced. We only present a special case sufficient for our considerations.
Reference: [9] <author> Y. Matias and U. Vishkin. </author> <title> Converting high probability into nearly-constant time with applications to parallel hashing. </title> <booktitle> In Proc. of the 23rd Ann. ACM Symp. on Theory of Computing, </booktitle> <pages> pages 307-316, </pages> <year> 1991. </year>
Reference-contexts: RESULT: If jS [ Xj cn then this operation sets SM equal to a parallel hash table storing S [ X; otherwise, the operation returns "failure". 5 The papers [1] and <ref> [9] </ref> give randomized algorithms for realizing a parallel hash table of capacity cn on an n processor PRAM. The inputs and outputs of the operations, as well as the parallel hash table itself, reside in the shared memory of the PRAM. <p> It is not difficult to extend the parallel hash table implementations of [1], <ref> [9] </ref> so that they work on an n processor DMM with the same performance guarantees as for a PRAM. For the BUILD operation it is assumed that each set S i is presented as an array in module M i .
Reference: [10] <author> C. McDiarmid. </author> <title> On the method of bounded differences. </title> <editor> In J. Siemons, editor, </editor> <booktitle> Surveys in Combinatorics, </booktitle> <year> 1989, </year> <pages> pages 148-188. </pages> <publisher> Cambridge University Press, </publisher> <year> 1989. </year> <journal> London Math. Soc. </journal> <note> Lecture Note Series 141. </note>
Reference-contexts: The structure of these hash functions enables us to analyze the delay in our simulation using a powerful martingale tail estimate that was derived independently in [1] and <ref> [10] </ref>. 2 Computation Models A PRAM consists of processors P 1 ; : : : ; P m and a shared memory with cells U = [p]. The processors work synchronously and have random access to the shared memory cells, each of which can store an integer. <p> We apply the beautiful tail estimate independently shown in [1] and <ref> [10] </ref> and stated in the following theorem.
Reference: [11] <author> K. Mehlhorn and U. Vishkin. </author> <title> Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories. </title> <journal> Acta Informatica, </journal> <volume> 21 </volume> <pages> 339-374, </pages> <year> 1984. </year>
Reference-contexts: The papers [14], [7], <ref> [11] </ref> and [12] present randomized simulations of n processor PRAMs on n processor DMMs. In [7] and [12] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. <p> These hash functions have evaluation time O (log (n)). Thus these simulations have delay O (log (n)). If a complete interconnection network is assumed then the delay can be reduced. In <ref> [11] </ref>, log (n)= loglog (n)-universal hash functions from [3] are used, yielding delay O (log (n)= loglog (n)).
Reference: [12] <author> A. G. Ranade. </author> <title> How to emulate shared memory. </title> <booktitle> In Proc. of the 28th IEEE Ann. Symp. on Foundations of Computer Science, </booktitle> <pages> pages 185-194, </pages> <year> 1987. </year>
Reference-contexts: The papers [14], [7], [11] and <ref> [12] </ref> present randomized simulations of n processor PRAMs on n processor DMMs. In [7] and [12] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. <p> The papers [14], [7], [11] and <ref> [12] </ref> present randomized simulations of n processor PRAMs on n processor DMMs. In [7] and [12] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal. The expected contention can be made as small as O (log (n)= loglog (n)), if log (n)-universal hash-functions as introduced in [3] are used.
Reference: [13] <author> A. Siegel. </author> <title> On universal classes of fast high performance hash functions, their time-space tradeoff, and their applications. </title> <booktitle> In Proc. of the 30th IEEE Ann. Symp. on Foundations of Computer Science, </booktitle> <pages> pages 20-25, </pages> <year> 1989. </year> <note> Revised Version. </note>
Reference-contexts: It simulates an n 1+" processor PRAM on an n processor DMM with optimal expected delay O (n " ). In [15] a time-processor optimal simulation of EREW-PRAMs on DMMs is presented with expected delay O (log (n)), using hash functions introduced in <ref> [13] </ref>. <p> Thus, we can distribute the table among the modules so that accesses to it can be performed in constant time. The analysis of our simulation depends on the properties of a particular p n-universal class of hash functions which combines the constructions given in [5] and <ref> [13] </ref>. <p> H d p;n was introduced by Carter and Wegman in [3]. It is a (2; d)-universal class. The second class H n k ;n fh : [n k ] ! [n]g introduced by Siegel in <ref> [13] </ref> consists of more complicated functions. It is the first class with high degree of universality whose functions can be generated fast using little space and have constant evaluation time, if the universe is of size n k for constant k. <p> Proof : The results (a), (b) are obvious from the definition of the classes, (c) and (d) can be found in [3] for H d p;n and in <ref> [13] </ref> for H n k ;n and (e) is shown in [8]. The result (g) is shown in [4] for (; d)-universal classes; thus it applies to both of our classes because of (c) and (d). 2 In [5] and [6] a new class of hash functions is introduced.
Reference: [14] <author> E. Upfal. </author> <title> Efficient schemes for parallel communication. </title> <journal> J. Assoc. Comput. Mach., </journal> <volume> 31(3) </volume> <pages> 507-517, </pages> <year> 1984. </year>
Reference-contexts: The papers <ref> [14] </ref>, [7], [11] and [12] present randomized simulations of n processor PRAMs on n processor DMMs. In [7] and [12] it is shown that, on a butterfly network, expected routing time O (log (n)) can be achieved, which clearly is asymptotically optimal.
Reference: [15] <author> L. G. Valiant. </author> <title> General purpose parallel architectures. </title> <editor> In J. van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, Vol. A: Algorithms and Complexity, chapter 18, </booktitle> <pages> pages 943-971. </pages> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: The first time-processor optimal simulation was published in [8]. It simulates an n 1+" processor PRAM on an n processor DMM with optimal expected delay O (n " ). In <ref> [15] </ref> a time-processor optimal simulation of EREW-PRAMs on DMMs is presented with expected delay O (log (n)), using hash functions introduced in [13]. <p> On the other hand our simulation does not work if we assume the access conflict resolution rule considered in <ref> [15] </ref>, in which, whenever several processors attempt to read or write to the same window, the window remains unchanged and each of the processors involved in the conflict receives a collision message. 3 Urn Models Our PRAM simulations are based on the use of hash functions to distribute data to the
Reference: [16] <author> T. Hagerup. </author> <title> The log-star revolution, </title> <booktitle> Proceedings. STACS 92, </booktitle> <volume> LNCS 577, </volume> <pages> pages 259-280, </pages> <year> 1992. </year>
Reference-contexts: This can be done without increase in the time-processor product, and with a O (log fl (n)) increase for the delay. This is true because of a result from <ref> [16] </ref> where a randomized simulation between the above models is shown which preserves the time-processor product, and has a delay not exceeding O (log fl (n)) with overwhelming probability.
References-found: 16

