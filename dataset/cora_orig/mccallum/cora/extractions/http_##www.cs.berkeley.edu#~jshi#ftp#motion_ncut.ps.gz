URL: http://www.cs.berkeley.edu/~jshi/ftp/motion_ncut.ps.gz
Refering-URL: http://www.cs.berkeley.edu/projects/vision/publications.html
Root-URL: 
Email: fjshi,malikg@cs.berkeley.edu  
Title: Motion Segmentation and Tracking Using Normalized Cuts  
Author: Jianbo Shi and Jitendra Malik 
Address: Berkeley, Berkeley, CA 94720  
Affiliation: Computer Science Division University of California at  
Date: January 1998  
Note: International Conference on Computer Vision,  
Abstract: We propose a motion segmentation algorithm that aims to break a scene into its most prominent moving groups. A weighted graph is constructed on the image sequence by connecting pixels that are in the spatiotemporal neighborhood of each other. At each pixel, we define motion profile vectors which capture the probability distribution of the image velocity. The distance between motion profiles is used to assign a weight on the graph edges. Using normalized cuts we find the most salient partitions of the spatiotempo-ral graph formed by the image sequence. For segmenting long image sequences, we have developed a recursive update procedure that incorporates knowledge of segmentation in previous frames for efficiently finding the group correspondence in the new frame. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. Adelson and J. Bergen. </author> <title> Spatiotemporal energy models for the perception of motion. </title> <journal> J. Opt. Soc. Am., </journal> <volume> 2(2) </volume> <pages> 284-299, </pages> <year> 1985. </year>
Reference-contexts: This will be based on the notion of motion profile. 3 Motion Profile Traditionally, local motion information in an image sequence is represented by optical flow, which can be estimated by using the outputs of spatiotemporal filters <ref> [1, 9, 8] </ref>, or by using differential techniques based the brightness constancy assumption [14]. Although these two techniques differ in the details of their formulation, fundamentally they are equivalent [18].
Reference: [2] <author> P. Anandan. </author> <title> A computational framework and an algorithm for the measurement of vision motion. </title> <journal> Int. J. of Computer Vision, </journal> <volume> 2 </volume> <pages> 283-310, </pages> <year> 1989. </year>
Reference-contexts: There have been various attempts to fix these problems in optical flow computation. Some restrict their algorithms to be run only at the places where velocity can be computed reliably [17], while others impose a smoothness constraint and apply regularization to obtain a smooth looking output <ref> [10, 2, 15, 4] </ref>. Alternatively, one could combine the process of motion measurement with image segmentation as has been done successfully in recent layer based approaches to motion analysis in the EM framework.
Reference: [3] <author> Serge Ayer and Harpreet S. Sawhney. </author> <title> Layered representation of motion video using robust maximum-likelihood estimation of mixture models and MDL encoding. </title> <booktitle> In Int. Conf. Computer Vision, </booktitle> <pages> pages 777-784, </pages> <year> 1995. </year>
Reference-contexts: This idea has evolved through a number of papers <ref> [3, 22, 6, 20, 11, 12] </ref>. Perhaps the cleanest current formulations are based on using the Expectation-Maximization (EM) algorithm [7]. <p> How many models should one initialize and where and what should they be, and how can one ensure a global optimal solution have been reached? A representative approach due to Ayer and Sawhney <ref> [3] </ref> uses the Minimum Description length principle for selecting the number of models. Initialization is done by dividing up the image into a fixed number of tiles; estimating the initial motion parameters in these tiles and then using these as the initial conditions for the EM algorithm.
Reference: [4] <author> M. Black and P. Anandan. </author> <title> Robust dynamic motion estimation over time. </title> <booktitle> In Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 296-302, </pages> <year> 1991. </year>
Reference-contexts: There have been various attempts to fix these problems in optical flow computation. Some restrict their algorithms to be run only at the places where velocity can be computed reliably [17], while others impose a smoothness constraint and apply regularization to obtain a smooth looking output <ref> [10, 2, 15, 4] </ref>. Alternatively, one could combine the process of motion measurement with image segmentation as has been done successfully in recent layer based approaches to motion analysis in the EM framework.
Reference: [5] <author> R. Cipolla and A. Blake. </author> <title> Surface orientation and time to contact from image divergence and deformation. </title> <booktitle> In Second European Conference on Computer Vision, </booktitle> <pages> pages 187-203, </pages> <year> 1992. </year>
Reference-contexts: Such a measure is considerably more robust and could be used for estimating gross measures such as divergence, deformation, rotation which have been shown to be useful variables for visual guidance of locomotion and manipulation <ref> [13, 5] </ref>. Snakes have been used in the computer vision literature [5] previously for this purpose. They are computation-ally efficient but difficult to initialize. The paper is organized as follows. Section 2 briefly explains our grouping algorithm based on the normalized cut graph partitioning criterion. <p> Such a measure is considerably more robust and could be used for estimating gross measures such as divergence, deformation, rotation which have been shown to be useful variables for visual guidance of locomotion and manipulation [13, 5]. Snakes have been used in the computer vision literature <ref> [5] </ref> previously for this purpose. They are computation-ally efficient but difficult to initialize. The paper is organized as follows. Section 2 briefly explains our grouping algorithm based on the normalized cut graph partitioning criterion. This section follows our previous work for static image segmentation described in [16].
Reference: [6] <author> T. Darrell and A. Pentland. </author> <title> Robust estimation of a multi-layered motion representation. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 173-178, </pages> <year> 1991. </year>
Reference-contexts: This idea has evolved through a number of papers <ref> [3, 22, 6, 20, 11, 12] </ref>. Perhaps the cleanest current formulations are based on using the Expectation-Maximization (EM) algorithm [7].
Reference: [7] <author> A.P. Dempster, N.M. Laird, and D.B. Rubin. </author> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, </journal> <volume> 39(B):1-38, </volume> <year> 1977. </year>
Reference-contexts: This idea has evolved through a number of papers [3, 22, 6, 20, 11, 12]. Perhaps the cleanest current formulations are based on using the Expectation-Maximization (EM) algorithm <ref> [7] </ref>. Typically the motion models are 2D parametric models, translational, affine or projective, the E-step is used to solve for the layers given the motions, and the M-step for solving for the motions given the layers.
Reference: [8] <author> D. Fleet and A. Jepson. </author> <title> Computation of component image velocity from local phase information. </title> <journal> Int. J. of Computer Vision, </journal> <volume> 5 </volume> <pages> 77-104, </pages> <year> 1990. </year>
Reference-contexts: This will be based on the notion of motion profile. 3 Motion Profile Traditionally, local motion information in an image sequence is represented by optical flow, which can be estimated by using the outputs of spatiotemporal filters <ref> [1, 9, 8] </ref>, or by using differential techniques based the brightness constancy assumption [14]. Although these two techniques differ in the details of their formulation, fundamentally they are equivalent [18].
Reference: [9] <author> D.J. Heeger. </author> <title> Optical flow using spatiotemporal filters. </title> <journal> Int. J. of Computer Vision, </journal> <volume> 2 </volume> <pages> 181-190, </pages> <year> 1990. </year>
Reference-contexts: This will be based on the notion of motion profile. 3 Motion Profile Traditionally, local motion information in an image sequence is represented by optical flow, which can be estimated by using the outputs of spatiotemporal filters <ref> [1, 9, 8] </ref>, or by using differential techniques based the brightness constancy assumption [14]. Although these two techniques differ in the details of their formulation, fundamentally they are equivalent [18].
Reference: [10] <author> B.K.P. Horn and B.G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: There have been various attempts to fix these problems in optical flow computation. Some restrict their algorithms to be run only at the places where velocity can be computed reliably [17], while others impose a smoothness constraint and apply regularization to obtain a smooth looking output <ref> [10, 2, 15, 4] </ref>. Alternatively, one could combine the process of motion measurement with image segmentation as has been done successfully in recent layer based approaches to motion analysis in the EM framework.
Reference: [11] <author> S. Hsu, P. Anandan, and S. Peleg. </author> <title> Accurate computation of optical flow by using layered motion representation. </title> <booktitle> In 12th International Conference on Pattern Recognition, </booktitle> <pages> pages A:743-746, </pages> <year> 1994. </year>
Reference-contexts: This idea has evolved through a number of papers <ref> [3, 22, 6, 20, 11, 12] </ref>. Perhaps the cleanest current formulations are based on using the Expectation-Maximization (EM) algorithm [7].
Reference: [12] <author> A. Jepson and M. J. Black. </author> <title> Mixture models for optical flow computation. </title> <booktitle> In Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 760-761, </pages> <year> 1993. </year>
Reference-contexts: This idea has evolved through a number of papers <ref> [3, 22, 6, 20, 11, 12] </ref>. Perhaps the cleanest current formulations are based on using the Expectation-Maximization (EM) algorithm [7].
Reference: [13] <author> J.J. Koenderink. </author> <title> Optical flow. </title> <journal> Vision Research, </journal> <volume> 26(1) </volume> <pages> 161-179, </pages> <year> 1986. </year>
Reference-contexts: Such a measure is considerably more robust and could be used for estimating gross measures such as divergence, deformation, rotation which have been shown to be useful variables for visual guidance of locomotion and manipulation <ref> [13, 5] </ref>. Snakes have been used in the computer vision literature [5] previously for this purpose. They are computation-ally efficient but difficult to initialize. The paper is organized as follows. Section 2 briefly explains our grouping algorithm based on the normalized cut graph partitioning criterion.
Reference: [14] <author> B.D. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo vision. </title> <booktitle> Proc. 7th Int. Joint Conf. on Art. Intell., </booktitle> <pages> pages 121-130, </pages> <year> 1981. </year>
Reference-contexts: This will be based on the notion of motion profile. 3 Motion Profile Traditionally, local motion information in an image sequence is represented by optical flow, which can be estimated by using the outputs of spatiotemporal filters [1, 9, 8], or by using differential techniques based the brightness constancy assumption <ref> [14] </ref>. Although these two techniques differ in the details of their formulation, fundamentally they are equivalent [18].
Reference: [15] <author> H. Nagel and W. Enkelmann. </author> <title> An investigation of smoothness constraints for the estimation of displacement vector fields from image sequences. </title> <journal> IEEE Trans. Pattern Anal. Mach. Intell., </journal> <volume> 8 </volume> <pages> 565-593, </pages> <month> Sept. </month> <year> 1986. </year>
Reference-contexts: There have been various attempts to fix these problems in optical flow computation. Some restrict their algorithms to be run only at the places where velocity can be computed reliably [17], while others impose a smoothness constraint and apply regularization to obtain a smooth looking output <ref> [10, 2, 15, 4] </ref>. Alternatively, one could combine the process of motion measurement with image segmentation as has been done successfully in recent layer based approaches to motion analysis in the EM framework.
Reference: [16] <author> J. Shi and J. Malik. </author> <title> Normalized cuts and image segmentation. </title> <booktitle> In Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 731-737, </pages> <year> 1997. </year>
Reference-contexts: This idea can be formalized using a graph partitioning criterion called normalized cut <ref> [16] </ref>. Given a motion sequence, a weighted graph G = (V; E) is constructed by taking each pixel as a node, and connecting nodes that are in a spatiotemporal neighborhood of each other. <p> Once the weighted graph is constructed, the normalized cut criterion is used to recursively partition the graph. As shown in <ref> [16] </ref>, normalized cut is a global measure which reflects both the similarity within the partitions, as well as dissimilarity across the partitions. Furthermore, this criterion can be computed efficiently by solving a generalized eigenvalue system. Successful partition of G gives us spatiotemporal volumes corresponding to different moving objects. <p> They are computation-ally efficient but difficult to initialize. The paper is organized as follows. Section 2 briefly explains our grouping algorithm based on the normalized cut graph partitioning criterion. This section follows our previous work for static image segmentation described in <ref> [16] </ref>. Section 3 describes the motion profile feature vector, and the development of motion segmentation using normalized cuts follows in section 4. Section 5 shows how we can efficiently segment long image sequences. We conclude in section 6. 2 Normalized Cuts In our previous paper [16], we have developed a grouping <p> static image segmentation described in <ref> [16] </ref>. Section 3 describes the motion profile feature vector, and the development of motion segmentation using normalized cuts follows in section 4. Section 5 shows how we can efficiently segment long image sequences. We conclude in section 6. 2 Normalized Cuts In our previous paper [16], we have developed a grouping algorithm based on minimizing a graph partitioning criteria called normalized cut. Let G = (V; E) be a weighted graph. <p> In graph theoretic language, it is called the cut: X w (u; v): (1) Although there are efficient computational algorithm for finding partitions that minimizes the cut value, this criterion favors partitions which have small sizes <ref> [16] </ref>. <p> Furthermore, the subsequent eigenvec-tors are the real valued solutions that form the optimal sub-partition. The normalized cut criterion have been used successfully for segmenting static images based on brightness, color, and texture information <ref> [16] </ref>. To extend it to motion segmentation, we need to first define an appropriate W.
Reference: [17] <author> J. Shi and C. Tomasi. </author> <title> Good features to track. </title> <booktitle> In Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 593-600, </pages> <year> 1994. </year>
Reference-contexts: There have been various attempts to fix these problems in optical flow computation. Some restrict their algorithms to be run only at the places where velocity can be computed reliably <ref> [17] </ref>, while others impose a smoothness constraint and apply regularization to obtain a smooth looking output [10, 2, 15, 4]. Alternatively, one could combine the process of motion measurement with image segmentation as has been done successfully in recent layer based approaches to motion analysis in the EM framework.
Reference: [18] <author> E. P. Simoncelli. </author> <title> Distributed Representation and Analysis of Vision Motion. </title> <type> PhD thesis, </type> <institution> MIT Media Laboratory, </institution> <year> 1993. </year>
Reference-contexts: Although these two techniques differ in the details of their formulation, fundamentally they are equivalent <ref> [18] </ref>. The basic limitations of those techniques are also quite similar one can not determine the image velocity reliably at locations where the intensity profile is flat, such as the image of a featureless wall, or image regions with a one dimensional intensity profile, such as an extended edge.
Reference: [19] <author> P. H. S. Torr and D. W. Murray. </author> <title> Stochastic motion clustering. </title> <booktitle> In Proc. 3rd European Conf. on Computer Vision, </booktitle> <address> Stockholm, pages B:328-337, </address> <year> 1994. </year>
Reference-contexts: When only sparse point correspondences are sought, Torr and Murray <ref> [19] </ref> have developed an alternative approach based on characterizing rigid motions using Fundamental matrices. In our opinion, the principal weakness of the EM approach to layered motion segmentation is in the initialization phase.
Reference: [20] <author> J.Y.A. Wang and E.H. Adelson. </author> <title> Representing moving images with layers. </title> <journal> IEEE Transactions on Image Processing Special Issue: Image Sequence Compression, </journal> <pages> pages 625-638, </pages> <year> 1994. </year>
Reference-contexts: This idea has evolved through a number of papers <ref> [3, 22, 6, 20, 11, 12] </ref>. Perhaps the cleanest current formulations are based on using the Expectation-Maximization (EM) algorithm [7].
Reference: [21] <author> Y. Weiss. </author> <title> Smoothness in layers: Motion segmentation using nonparametric mixture estimation. </title> <booktitle> In Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 520-526, </pages> <year> 1997. </year>
Reference-contexts: The layers that are extracted provide the desired scene segmentation. On the other hand, the assumption that image sequence have to follow a global rigid planar motion is clearly too restrictive, and recently Weiss <ref> [21] </ref> has developed a variation of EM approach that is based on a non-parametric mixture model using a probability distribution over flow fields that favors smooth flow fields.
Reference: [22] <author> Y. Weiss and E.H. Adelson. </author> <title> A unified mixture framework for motion segmentation: Incorporating spatial coherence and estimating the number of models. </title> <booktitle> In Proc. IEEE Conf. Computer Vision and Pattern Recognition, </booktitle> <pages> pages 321-326, </pages> <year> 1996. </year>
Reference-contexts: This idea has evolved through a number of papers <ref> [3, 22, 6, 20, 11, 12] </ref>. Perhaps the cleanest current formulations are based on using the Expectation-Maximization (EM) algorithm [7].
Reference: [23] <author> M. Wertheimer. </author> <title> Laws of organization in perceptual forms. </title> <editor> In W.B. Ellis, editor, </editor> <booktitle> A Sourcebook of Gestalt Psycychol-ogy(Partial translation), </booktitle> <pages> pages 71-88. </pages> <publisher> Harcourt, Brace and Company, </publisher> <year> 1938. </year>
Reference-contexts: 1 Introduction Grouping based on common motion, or what the Gestaltists <ref> [23] </ref> called the factor of "Common Fate", is one of the strongest cues for segmenting an image sequence into separate objects. However, implementing this perceptual capability has proved to be very challenging for computer vision systems.
References-found: 23

