URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94497-S.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: Efficient Address Generation for Block-Cyclic Distributions  
Author: Ken Kennedy Nenad Nedeljkovic Ajay Sethi 
Address: P.O. Box 1892 Houston, TX 77251-1892  
Affiliation: Rice University  
Note: Center for Research on Parallel Computation  Submitted to the 9th ACM International Conference on Supercomputing (ICS '95).  
Date: December, 1994  
Pubnum: CRPC-TR94497-S  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> C. Ancourt, F. Coelho, F. Irigoin, and R. Keryell. </author> <title> A linear algebra framework for static HPF code distribution. </title> <booktitle> In Proceedings of the Fourth Workshop on Compilers for Parallel Computers, </booktitle> <address> Delft, The Netherlands, </address> <month> December </month> <year> 1993. </year>
Reference-contexts: Several efforts to address some of the difficulties in compiling programs with cyclic (k) distribution have been described in the literature. Ancourt et al. use a linear algebra framework for compiling independent loops in HPF <ref> [1] </ref>. Although they can handle arbitrary affine array subscripts, the generated loop bounds and local array subscripts can be quite complex, and thus introduce a significant overhead. Furthermore, the assumption of independent parallelism allows them to enumerate loop iterations in any order, which is, in general, not always possible.
Reference: [2] <author> B. Chapman, P. Mehrotra, and H. Zima. </author> <title> Programming in Vienna Fortran. </title> <journal> Scientific Programming, </journal> <volume> 1(1) </volume> <pages> 31-50, </pages> <month> Fall </month> <year> 1992. </year>
Reference-contexts: However, the message-passing programming model, typically associated with these machines, makes it difficult to take full advantage of parallel computing power. This has resulted in the development of data-parallel languages, such as Fortran D [9], Vienna Fortran <ref> [2] </ref>, and most recently High Performance Fortran (HPF) [7, 13]. These languages provide familiar single address space and data mapping directives that allow the programmer to specify how array data should be distributed across processors.
Reference: [3] <author> S. Chatterjee, J. Gilbert, F. Long, R. Schreiber, and S. Teng. </author> <title> Generating local addresses and communication sets for data-parallel programs. </title> <booktitle> In Proceedings of the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, </booktitle> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Their approach is similar to, and has the same drawback as, the virtual-cyclic scheme mentioned above. The method described by Chatterjee et al. is based on exploiting the repetitive pattern of memory accesses while traversing a regular section of an array with cyclic (k) distribution <ref> [3] </ref>. They show how each processor can generate the correct sequence of its local memory accesses using lookups into a table that has at most k entries, and present a table construction algorithm that takes roughly O (k log k) time. <p> The cycle of offsets induces the cycle in the sequence of local memory gaps, which together with the processor's starting location is sufficient to specify the complete memory access sequence. Chatterjee et al. <ref> [3] </ref> have shown that both the starting location and the table of local memory gaps can be found by solving a set of k linear Diophantine equations fsj pkq = i j km l i km l + k 1g: For each solvable equation (i.e., whenever gcd (s; pk) divides i), <p> Chatterjee et al. have shown that for multidimensional regular array sections (corresponding to array references with independent subscripts), the memory access problem reduces to multiple applications of the algorithm used for the one-dimensional case <ref> [3] </ref>. However, this is not necessarily true if subscripts are dependent, i.e., if two or more subscript positions contain the same loop induction variables. <p> A typical example of a loop with coupled subscripts is shown below. do i = l; u enddo In order to use table lookups for address generation of array references with coupled subscripts, we first show how the method presented by Chatterjee et al. <ref> [3] </ref> can be extended to find the starting location. Let l 1 = s 1 l + c 1 and l 2 = s 2 l + c 2 be the values of the two subscripts in the first loop iteration. <p> (m 1 ; m 2 ) corresponds to the smallest nonnegative integer j which satisfies both of the following two inequalities k 1 m 1 (l 1 + s 1 j) mod p 1 k 1 &lt; k 1 (m 1 + 1); and As shown by Chatterjee et al. <ref> [3] </ref> for the one-dimensional case, finding such a j is equivalent to finding the minimum of the smallest nonnegative solutions of the following set of simultaneous linear Diophantine equations fs 1 j p 1 k 1 q 1 = i 1 j k 1 m 1 l 1 i 1 k <p> The complete algorithm to determine the processor's starting location is shown in Figure 8. Using the same idea as described by Chatterjee et al. <ref> [3] </ref> for the one-dimensional case, the table of memory gaps can be obtained by first sorting the initial sequence of array accesses and then computing the distances Input: Distribution parameters (p 1 ; k 1 ), (p 2 ; k 2 ), loop parameters (l 1 ; s 1 ), (l <p> In this paper we have presented efficient techniques for generating local addresses for array references with arbitrary affine subscripts. We have improved on the previously described table-based address generation scheme <ref> [3] </ref> in two ways. First, we have shown how ideas used to develop our linear-time table construction algorithm [10] can be used to generate local addresses without table lookups, with only insignificant performance degradation.
Reference: [4] <author> T.H. Cormen, C.E. Leiserson, and R.L. Rivest. </author> <title> Introduction to Algorithms. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: Therefore, the S table will have 12, 10, 8 , 6, 4 and 2 as the number of elements skipped for the first elements with offsets 4, 6, 8, 10, 12 and 14 respectively (i.e., S <ref> [4] </ref> = 12, S [6] = 10, and so on). <p> Two separate applications of the extended Euclid algorithm <ref> [4] </ref> determine d 1 ; ff 1 ; fi 1 and d 2 ; ff 2 ; fi 2 . The do i = l i ; u i , s i do k = l k ; u k , s k enddo enddo enddo (a) Original loop.
Reference: [5] <author> M. Gerndt. </author> <title> Automatic Parallelization for Distributed-Memory Multiprocessing Systems. </title> <type> PhD thesis, </type> <institution> University of Bonn, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: A compiler then uses these directives to partition the computation and generate SPMD (Single Program Multiple Data) code to be executed by each processor. Compilation of programs that access arrays with block or cyclic distribution has been studied extensively <ref> [5, 12, 15] </ref>. A more general regular distribution is block-cyclic distribution (cyclic (k) in HPF), in which an array is first divided into blocks of size k, and then these blocks are assigned to processors in a cyclic fashion.
Reference: [6] <author> S.K.S. Gupta, S.D. Kaushik, C.-H. Huang, and P. Sadayappan. </author> <title> On compiling array expressions for efficient execution on distributed-memory machines. </title> <type> Technical Report OSE-CISRC-4/94-TR19, </type> <institution> Department of Computer and Information Science, The Ohio State University, </institution> <month> April </month> <year> 1994. </year>
Reference-contexts: Furthermore, the assumption of independent parallelism allows them to enumerate loop iterations in any order, which is, in general, not always possible. Gupta et al. address the problem of array statements involving block-cyclic distributions <ref> [6] </ref>. In their virtual-cyclic scheme, array elements are accessed in an order different from the order in a sequential program. In the virtual-block scheme array accesses are not reordered, but if the array section stride is larger than the block size, their method effectively reduces to the run-time address resolution. <p> We also compared these two methods with the full run-time generation of local memory addresses and with the virtual-block scheme proposed by Gupta et al. <ref> [6] </ref>. In the run-time resolution each processor executes all the loop iterations, and for each iteration it checks whether it owns the array element that is being assigned to, in which case it computes the local memory address for that array element and performs the assignment. <p> If stride s is not greater than block size k, then all virtual processors own some of the array elements being accessed, i.e., all virtual processors are active <ref> [6] </ref>. <p> Therefore, the S table will have 12, 10, 8 , 6, 4 and 2 as the number of elements skipped for the first elements with offsets 4, 6, 8, 10, 12 and 14 respectively (i.e., S [4] = 12, S <ref> [6] </ref> = 10, and so on).
Reference: [7] <author> High Performance Fortran Forum. </author> <title> High Performance Fortran language specification. </title> <booktitle> Scientific Programming, </booktitle> <address> 2(1-2):1-170, </address> <year> 1993. </year>
Reference-contexts: However, the message-passing programming model, typically associated with these machines, makes it difficult to take full advantage of parallel computing power. This has resulted in the development of data-parallel languages, such as Fortran D [9], Vienna Fortran [2], and most recently High Performance Fortran (HPF) <ref> [7, 13] </ref>. These languages provide familiar single address space and data mapping directives that allow the programmer to specify how array data should be distributed across processors.
Reference: [8] <author> S. Hiranandani, K. Kennedy, J. Mellor-Crummey, and A. Sethi. </author> <title> Compilation techniques for block-cyclic distributions. </title> <booktitle> In Proceedings of the 1994 ACM International Conference on Supercomputing, </booktitle> <address> Manchester, England, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Note that the upper bound computation is simpler because the local upper bound need not be the actual last element accessed by the processor. The procedures for computing the local upper bound (GetU pperBound) and for global to local index conversion (Local) were presented in <ref> [8] </ref>. 10 3.1 Experimental Results In this section we compare the performance of various address generation approaches for array references with MIV subscripts. Figure 6 shows two versions of the SPMD node code corresponding to our canonical loop nest example.
Reference: [9] <author> S. Hiranandani, K. Kennedy, and C.-W. Tseng. </author> <title> Compiling Fortran D for MIMD distributed-memory machines. </title> <journal> Communications of the ACM, </journal> <volume> 35(8) </volume> <pages> 66-80, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: 1 Introduction Distributed-memory machines are widely regarded as the most promising means for high performance computing. However, the message-passing programming model, typically associated with these machines, makes it difficult to take full advantage of parallel computing power. This has resulted in the development of data-parallel languages, such as Fortran D <ref> [9] </ref>, Vienna Fortran [2], and most recently High Performance Fortran (HPF) [7, 13]. These languages provide familiar single address space and data mapping directives that allow the programmer to specify how array data should be distributed across processors.
Reference: [10] <author> K. Kennedy, N. Nedeljkovic, and A. Sethi. </author> <title> A linear-time algorithm for computing the memory access sequence in data-parallel programs. </title> <type> Technical Report CRPC-TR94485-S, </type> <institution> Center for Research on Parallel Computation, Rice University, </institution> <month> October </month> <year> 1994. </year>
Reference-contexts: They show how each processor can generate the correct sequence of its local memory accesses using lookups into a table that has at most k entries, and present a table construction algorithm that takes roughly O (k log k) time. In our previous work <ref> [10] </ref>, we described a linear-time algorithm for constructing the table needed to generate local memory accesses, and presented experimental results to assert the practical efficiency of our method. <p> The complexity of the method described by Chatterjee et al. is O (k log k + min (log s; log p)). We have developed an improved table-construction algorithm that avoids sorting of the initial sequence and achieves O (k + min (log s; log p)) running time <ref> [10] </ref>. Array elements are treated as points in Z 2 with the y-coordinate corresponding to the number of the row to which the array element belongs, and the x-coordinate corresponding to its offset within that row. <p> It has been shown that vectors R and L form a lattice basis for regular section elements, and furthermore that the distance between two consecutive accesses must take one of the three possible values: R, L, or R + L <ref> [10] </ref>. <p> Second, even if this computation has to be done at run time, same tables (or vectors) would typically be reused for multiple array references in the program. And finally, our previous study <ref> [10] </ref> has shown that even for values of k as large as 512, table construction takes less than 1 millisecond, and thus would have no significant impact on results presented here. <p> In this paper we have presented efficient techniques for generating local addresses for array references with arbitrary affine subscripts. We have improved on the previously described table-based address generation scheme [3] in two ways. First, we have shown how ideas used to develop our linear-time table construction algorithm <ref> [10] </ref> can be used to generate local addresses without table lookups, with only insignificant performance degradation. Second, we have extended the table lookup method to references with multiple loop induction variables and coupled array subscripts.
Reference: [11] <author> A. Knies, M. O'Keefe, and T. MacDonald. </author> <title> High Performance Fortran: A practical analysis. </title> <journal> Scientific Programming, </journal> <volume> 3(3) </volume> <pages> 187-199, </pages> <month> Fall </month> <year> 1994. </year>
Reference-contexts: The generality of cyclic (k) distribution poses a challenging problem of address computation for array references. As pointed out by Knies et al., if full address generation were to be performed for each access to an array with cyclic (k) distribution, the resulting overhead would be unacceptable <ref> [11] </ref>. Therefore, there is a strong need for compiler and run-time techniques that would minimize the fl This work was supported in part by ARPA contract DABT63-92-C-0038. and NSF Cooperative Agreement Number CCR-9120008.
Reference: [12] <author> C. Koelbel. </author> <title> Compile-time generation of regular communications patterns. </title> <booktitle> In Proceedings of Supercomputing '91, </booktitle> <pages> pages 101-110, </pages> <address> Albuquerque, NM, </address> <month> November </month> <year> 1991. </year>
Reference-contexts: A compiler then uses these directives to partition the computation and generate SPMD (Single Program Multiple Data) code to be executed by each processor. Compilation of programs that access arrays with block or cyclic distribution has been studied extensively <ref> [5, 12, 15] </ref>. A more general regular distribution is block-cyclic distribution (cyclic (k) in HPF), in which an array is first divided into blocks of size k, and then these blocks are assigned to processors in a cyclic fashion.
Reference: [13] <author> C. Koelbel, D. Loveman, R. Schreiber, G. Steele, Jr., and M. Zosel. </author> <title> The High Performance Fortran Handbook. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1994. </year>
Reference-contexts: However, the message-passing programming model, typically associated with these machines, makes it difficult to take full advantage of parallel computing power. This has resulted in the development of data-parallel languages, such as Fortran D [9], Vienna Fortran [2], and most recently High Performance Fortran (HPF) <ref> [7, 13] </ref>. These languages provide familiar single address space and data mapping directives that allow the programmer to specify how array data should be distributed across processors.
Reference: [14] <author> J. Stichnoth, D. O'Hallaron, and T. Gross. </author> <title> Generating communication for array statements: Design, implementation, and evaluation. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 21(1) </volume> <pages> 150-159, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: In the virtual-block scheme array accesses are not reordered, but if the array section stride is larger than the block size, their method effectively reduces to the run-time address resolution. Stichnoth et al. use intersections of array slices for communication generation <ref> [14] </ref>. Their approach is similar to, and has the same drawback as, the virtual-cyclic scheme mentioned above. The method described by Chatterjee et al. is based on exploiting the repetitive pattern of memory accesses while traversing a regular section of an array with cyclic (k) distribution [3].
Reference: [15] <author> C.-W. Tseng. </author> <title> An Optimizing Fortran D Compiler for MIMD Distributed-Memory Machines. </title> <type> PhD thesis, </type> <institution> Dept. of Computer Science, Rice University, </institution> <month> January </month> <year> 1993. </year> <month> 18 </month>
Reference-contexts: A compiler then uses these directives to partition the computation and generate SPMD (Single Program Multiple Data) code to be executed by each processor. Compilation of programs that access arrays with block or cyclic distribution has been studied extensively <ref> [5, 12, 15] </ref>. A more general regular distribution is block-cyclic distribution (cyclic (k) in HPF), in which an array is first divided into blocks of size k, and then these blocks are assigned to processors in a cyclic fashion. <p> Therefore, we can construct a table such that each entry S [t] contains the number of array elements between the first element accessed by the outer loop iteration first , such that first mod pk = t, and the starting location for processor m. For example, the S <ref> [15] </ref> entry of the table for processor 2 is 10 because offset 15 corresponds to the first element, 111, accessed by the fourth iteration of the outer loop and the starting location for processor 2 is 121; therefore, the number of elements that need to be skipped is 121 111 =
References-found: 15

