URL: http://www.cse.ucsc.edu/~stiliadi/infocom95.ps
Refering-URL: http://www.cse.ucsc.edu/~stiliadi/projects.html
Root-URL: http://www.cse.ucsc.edu
Title: Providing Bandwidth Guarantees in an Input-Buffered Crossbar Switch  
Author: Dimitrios Stiliadis and Anujan Varma 
Address: Santa Cruz, CA 95064  
Affiliation: Computer Engineering Department University of California  
Abstract: In this paper, we introduce and analyze a method for providing bandwidth reservations in an input-buffered non-blocking crossbar switch. The scheme, which we call weighted probabilistic iterative matching (WPIM), is an improvement over probabilistic iterative matching and allows flexible allocation of bandwidth among the switch inputs sharing a common output link in a simple manner. Weighted probabilistic iterative matching allocates the output bandwidth among the inputs based on reservations made during the connection setup phase, and can guarantee that traffic from each input receives its promised share of the bandwidth of the output link. In addition, the algorithm provides isolation between two flows arriving on distinct input links and directed at a common output link; misbehaving flows at one of the inputs do not affect the bandwidth guarantees or delays of traffic from other inputs. Results from simulations show that the scheme is able to maintain probabilistic bandwidth and delay guarantees in the presence of misbehaving traffic. We also derive an analytical upper bound for the average delay under the scheme and validate it by simulation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Zhang, "VirtualClock: </author> <title> a new traffic control algorithm for packet switching networks," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 9, no. 2, </volume> <pages> pp. 101-124, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin [12], generalized processor sharing [13], [14], Virtual-Clock <ref> [1] </ref>, and FIFO+ [3]; with the constraint that the aggregate bandwidth available for these flows is that provided through WPIM.
Reference: [2] <author> A.Demers, S. Keshav, and S.Shenker, </author> <title> "Analysis and simulation of a fair queueing algorithm," </title> <journal> Journal of Internetworking Research and Experience, </journal> <volume> vol. 1, no. 1, </volume> <pages> pp. 3-26, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: This follows from the fact that when all credits are satisfied, the algorithm reduces to simple iterative matching that allocates the bandwidth equally among all inputs requesting access to a given output port. In this sense, the algorithm meets the fairness criteria defined in <ref> [2] </ref>, [15]. When an input-output connection increases its traffic rate, the performance of all others will be equally degraded, but they will still continue to receive at least their reserved bandwidth.
Reference: [3] <author> D. D. Clark, S. Shenker, and L. Zhang, </author> <title> "Supporting real-time applications in an integrated services packet network: Architecture and mechanism," </title> <booktitle> in Proc. ACM SIGCOMM '92, </booktitle> <pages> pp. 14-26, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin [12], generalized processor sharing [13], [14], Virtual-Clock [1], and FIFO+ <ref> [3] </ref>; with the constraint that the aggregate bandwidth available for these flows is that provided through WPIM. Alternatively, schemes for link-by-link flow control of virtual circuits can also limit the bandwidth of individual flows sharing a common link and hence can be used to implement flow-level bandwidth allocation [4], [5].
Reference: [4] <author> H. T. Kung, T. Blackwell, and A. Chapman, </author> <title> "Credit-based flow control for ATM networks: Credit update protocol, adaptive credit allocation, and statistical multiplexing," </title> <booktitle> in Proc. ACM SIGCOMM '94, </booktitle> <pages> pp. 101-113, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Alternatively, schemes for link-by-link flow control of virtual circuits can also limit the bandwidth of individual flows sharing a common link and hence can be used to implement flow-level bandwidth allocation <ref> [4] </ref>, [5]. To implement bandwidth reservations, we divide the time axis into frames with a fixed number of slots per frame. In the context of ATM networks, a slot is equal to the time to transmit one 53-byte cell.
Reference: [5] <author> G. Varghese, C. Ozveren, and R. Simcoe, </author> <title> "Reliable and efficient hop-by-hop flow control," </title> <booktitle> in Proc. ACM SIGCOMM '94, </booktitle> <pages> pp. 89-100, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: Alternatively, schemes for link-by-link flow control of virtual circuits can also limit the bandwidth of individual flows sharing a common link and hence can be used to implement flow-level bandwidth allocation [4], <ref> [5] </ref>. To implement bandwidth reservations, we divide the time axis into frames with a fixed number of slots per frame. In the context of ATM networks, a slot is equal to the time to transmit one 53-byte cell.
Reference: [6] <author> F. A. Tobagi, </author> <title> "Fast packet switch architectures for broadband integrated services digital networks," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 78, no. 1, </volume> <pages> pp. 133-167, </pages> <month> November </month> <year> 1990. </year>
Reference: [7] <author> M. J. Karol, M. G. Hluchyj, and S. P. Morgan, </author> <title> "Input versus output queueing on a space-division packet switch," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 35, no. 12, </volume> <pages> pp. 1347-56, </pages> <month> De-cember </month> <year> 1987. </year>
Reference: [8] <author> Y. S. Yeh, M. G. Hluchyj, and A. S. Acampora, </author> <title> "The knockout switch: A simple, modular architecture for high-performance packet switching," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. SAC-5, no. 8, </volume> <pages> pp. 1274-83, </pages> <month> October </month> <year> 1987. </year>
Reference: [9] <author> T. E. Anderson, S. S. Owicki, J. B. Saxe, and C. P. Thacker, </author> <title> "High speed switch scheduling for local area networks," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 11, no. 4, </volume> <pages> pp. 319-52, </pages> <month> November </month> <year> 1993. </year>
Reference-contexts: The average number of iterations for probabilistic itera-tive matching to yield a maximal matching has been shown to be O (log N ) <ref> [9] </ref>. This is because the number of unresolved requests is reduced by an average of at least 3 4 in each iteration. Starting from a maximum of N 2 unresolved requests, the average number of iterations before the algorithm converges is always less than log N + 4 3 . <p> In this case, the first phase of the algorithm will start with a maximum of N 2 =2 requests and will converge, on the average, in less than log N + 5=6 iterations <ref> [9] </ref>. In the second phase, the N 2 =2 requests that were masked out in the first phase will be activated and the algorithm will again converge in less than log N + 5=6 iterations on the average. <p> This causes the delay to be much higher compared to WPIM at low loads. Also, the maximum bandwidth utilization of statistical matching has been shown to be no more than 72% <ref> [9] </ref>. This causes the switch to saturate at a much lower load than in the case of WPIM, resulting in much higher delays at heavy load.
Reference: [10] <author> R. E. Tarjan, </author> <title> Data Structures and Network Algorithms. </title> <address> Murray Hill NJ: </address> <institution> Bell Laboratories, </institution> <year> 1983. </year>
Reference: [11] <author> R. M. Karp, U. V. Vazirani, and V. V. Vazirani, </author> <title> "An optimal algorithm for on-line bipartite matching," </title> <booktitle> in Proc. 22nd Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pp. 352-358, </pages> <month> May </month> <year> 1990. </year>
Reference: [12] <author> M. Katevenis, S. Sidiropoulos, and C. Courcoubetis, </author> <title> "Weighted round-robin cell multiplexing in a general-purpose ATM switch chip," </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> vol. 9, no. 8, </volume> <pages> pp. 1265-79, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin <ref> [12] </ref>, generalized processor sharing [13], [14], Virtual-Clock [1], and FIFO+ [3]; with the constraint that the aggregate bandwidth available for these flows is that provided through WPIM.
Reference: [13] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow control the single node case," </title> <booktitle> in Proc. INFOCOM '92, </booktitle> <volume> vol. 2, </volume> <pages> pp. 915-924, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin [12], generalized processor sharing <ref> [13] </ref>, [14], Virtual-Clock [1], and FIFO+ [3]; with the constraint that the aggregate bandwidth available for these flows is that provided through WPIM.
Reference: [14] <author> A. K. Parekh and R. G. Gallager, </author> <title> "A generalized processor sharing approach to flow control in integrated services networks: the multiple node case," </title> <booktitle> in Proc. INFOCOM '93, </booktitle> <volume> vol. 2, </volume> <pages> pp. 521-530, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: The second problem, that of allocating bandwidth to individual flows sharing the same input-output connection, can be solved by one of the many scheduling algorithms described in the literature, such as weighted round robin [12], generalized processor sharing [13], <ref> [14] </ref>, Virtual-Clock [1], and FIFO+ [3]; with the constraint that the aggregate bandwidth available for these flows is that provided through WPIM.
Reference: [15] <author> K. K. Ramakrishnan and R. Jain, </author> <title> "A binary feedback scheme for congestion avoidance in computer networks.," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 8, no. 2, </volume> <pages> pp. 158-81, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: This follows from the fact that when all credits are satisfied, the algorithm reduces to simple iterative matching that allocates the bandwidth equally among all inputs requesting access to a given output port. In this sense, the algorithm meets the fairness criteria defined in [2], <ref> [15] </ref>. When an input-output connection increases its traffic rate, the performance of all others will be equally degraded, but they will still continue to receive at least their reserved bandwidth.
Reference: [16] <author> S. Shenker, </author> <title> "Making greed work in networks: A game-theoretic analysis of switch service disciplines," </title> <booktitle> in Proc. ACM SIG-COMM '94, </booktitle> <pages> pp. 47-57, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: In a real network, the traffic may exceed the capacity of the output link, either because of the burstiness of individual flows or because of greedy users. Users may act in a selfish manner by trying to utilize as much of the available bandwidth as possible <ref> [16] </ref>. Higher level protocols such as TCP incorporate mechanisms to utilize the maximum available bandwidth [17]. In addition, some of the input ports of the switch may need to use more than 1=N of the output bandwidth; probabilistic iterative matching can only guarantee them 1=N of the output bandwidth.
Reference: [17] <author> V. Jacobson, </author> <title> "Congestion avoidance and control," </title> <booktitle> in Proc. ACM SIGCOMM '88, </booktitle> <pages> pp. 314-29, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Users may act in a selfish manner by trying to utilize as much of the available bandwidth as possible [16]. Higher level protocols such as TCP incorporate mechanisms to utilize the maximum available bandwidth <ref> [17] </ref>. In addition, some of the input ports of the switch may need to use more than 1=N of the output bandwidth; probabilistic iterative matching can only guarantee them 1=N of the output bandwidth.
References-found: 17

