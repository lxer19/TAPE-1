URL: ftp://ftpipr.ira.uka.de/pub/papers/1994/icarcv94au.ps.gz
Refering-URL: ftp://ftpipr.ira.uka.de/.public_html/papersna.html
Root-URL: 
Email: ude@ira.uka.de dillmann@ira.uka.de  
Title: Ob ject Localization Using Perceptual Organization and Structural Stereopsis  
Author: Ales Ude Holger Brode Rudiger Dillmann 
Address: Kaiserstr. 12, 76128 Karlsruhe, Germany  
Affiliation: Institute for Real-Time Computer Systems and Robotics Faculty of Computer Science, University of Karlsruhe  
Date: November 1994  
Note: In: Proc. Third Int. Conf. Automation, Robotics and Computer Vision, pp. 197-201, Singapore,  
Abstract: In this paper we demonstrate that perceptual organization and structural stereopsis provide a significant computational leverage for the expected object recognition. Object features and groupings are extracted from a CAD model of the object and are guaranteed to be completely visible, up to the edge detection problems, over a wide range of viewing directions. The image processing system limits the search for image groupings to those prototype groupings which have been extracted from the CAD model. The grouping of image features enables an intelligent selection of hypotheses about the matches between the image and the model features while structural stereopsis is used to calculate the 3-D poses of these groupings. This enables not only the rejection of most of the wrong hypotheses by use of 3-D geometric constraints but also an efficient, non-iterative computation of pose candidates which are verified in the next phase of the localization process. A probabilistic quality measure is assigned to each hypothesis in order to verify the most promising ones first. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Ayache. </author> <title> Artificial Vision for Mobile Robots: Stereo Vision and Multisensory Perception. </title> <publisher> MIT Press, </publisher> <address> Cam- bridge, Mass., </address> <year> 1991. </year>
Reference-contexts: Qualitatively, image edges correspond to disconti- nuities in luminance intensities <ref> [1] </ref>. The discontinuities in luminance intensities which can be related to the object arise either because of discontinuities in the object's geometry or because of discontinuities in its reflectance properties. In our system, edges corresponding to these discontinuities are extracted from the object's model automatically. <p> The criteria used to find the correspondences between the groupings detected in the left and right image, respectively, are the type of the groupings, the orientation of the segments generating the groupings and the epipolar constraint <ref> [1] </ref>. Since the image groupings are relatively complex structures, a unique match is normally found. This is an important advantage in comparison with conventional matching procedures which have to deal with multiple matches.
Reference: [2] <author> D. H. Ballard and C. M. Brown. </author> <title> Computer Vision. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N. J., </address> <year> 1982. </year>
Reference-contexts: Each entry of this table corresponds to a class of viewing directions and gives an answer to the question whether an edge is visible or not from a particular viewpoint. Only one bit is needed to store this information. We employ an algorithm proposed by Ballard and Brown <ref> [2] </ref> to construct a set of 320 near-uniformly distributed viewing directions. Hence the dimension of the visibility table is 320 and the memory size needed for its 2 storage is 40 bytes.
Reference: [3] <author> K. L. Boyer and A. C. Kak. </author> <title> Structural stereopsis for 3-D vision. </title> <journal> IEEE Trans. Pattern Anal. Machine Intell., </journal> <volume> 10(2) </volume> <pages> 144-166, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: It has been suggested that in many applications one is better advised to extract a structural description from both views of the scene first. This description can be used in a stereo matching procedure afterwards. Boyer and Kak <ref> [3] </ref> were among the first to propose such an approach. Structural stereopsis is especially valuable in a model-based vision because in this case, one can concentrate on image structures for which there is a high probability that they have been generated by the projected model structures. <p> Assuming that the relations are uncorrelated, the probability that a grouping as a whole has been formed on the basis of a corresponding scene grouping is equal to p = i A good measure of the significance of the grouping is obtained by taking the negative logarithm of this probability <ref> [3] </ref>. Up to the generation of image groupings, both images are treated independently. To compute 3-D poses of the groupings, stereo information must be taken into consideration.
Reference: [4] <author> R. Horaud, F. Veillon, and T. Skordas. </author> <title> Finding geometric and relational structures in an image. </title> <editor> In O. Faugeras, editor, </editor> <booktitle> Computer Vision - ECCV 90; Proc. First Euro- pean Conf. Computer Vision, Antibes, France, </booktitle> <pages> pp. </pages> <address> 374- 384. </address> <publisher> Springer, </publisher> <address> Berlin, Heidelberg, </address> <year> 1990. </year>
Reference-contexts: Image groupings are found by combining image features that share significant relationships. For example, parallelograms are detected by combining two pairs of image segments which share two parallel and four proximity relations. Ho- raud et al. <ref> [4] </ref> have proposed some methods for extracting relational structures from image segments. Since relations forming each grouping cannot be taken in the crisp sense, we must estimate the significance of the detected groupings.
Reference: [5] <author> D. P. Huttenlocher and S. Ullman. </author> <title> Recognizing solid objects by alignment with an image. </title> <journal> Intern. J. Comput. Vis., </journal> <volume> 5(2) </volume> <pages> 195-212, </pages> <year> 1990. </year>
Reference-contexts: Techniques proposed in the literature comprise interpretation tree search, alignment, Hough clustering, geometric hashing and model-based indexing. Many researchers have used range images for this purpose, but the systems which employ intensity imagery are not rare either <ref> [5, 6] </ref>. Although recognition should be easier if 3-D data is directly available, there are some advantages in using intensity images as well. For instance, dense and accurate range images are needed for the 3-D object recognition from range images. <p> Known methods are mostly iterative and require a good starting point [6]. Analytical methods for the pose calculation from 2-D to 3-D correspondences do exist, but they are based on a fix, minimal number of features and do not return a unique solution <ref> [5] </ref>. In order to account for the measurement noise, it is desirable to use more than a minimal number of features for the generation of pose hypotheses. There exist many efficient, analytical methods for the pose calculation from any number of feature correspondences when 3-D to 3-D correspondences are available. <p> A brute force approach would be to match all image edges with all model edges which results in a total number of m n k! hypotheses <ref> [5] </ref>. One can drastically reduce the number of possible hypotheses by considering the relational information contained in the model. According to Gestalt psychologists, parallelism, end-point proximity and collinearity are among the most important relations used in the perceptual organization of images in our real world.
Reference: [6] <author> D. G. Lowe. </author> <title> Three-dimensional object recognition from single two-dimensional images. </title> <journal> Artif. Intell., </journal> <volume> 31:355- 395, </volume> <year> 1987. </year>
Reference-contexts: Techniques proposed in the literature comprise interpretation tree search, alignment, Hough clustering, geometric hashing and model-based indexing. Many researchers have used range images for this purpose, but the systems which employ intensity imagery are not rare either <ref> [5, 6] </ref>. Although recognition should be easier if 3-D data is directly available, there are some advantages in using intensity images as well. For instance, dense and accurate range images are needed for the 3-D object recognition from range images. <p> Object recognition systems which use intensity imagery and invoke pose estimation must tackle the problem of calculating the 3-D object pose from 2-D to 3-D feature correspondences. Known methods are mostly iterative and require a good starting point <ref> [6] </ref>. Analytical methods for the pose calculation from 2-D to 3-D correspondences do exist, but they are based on a fix, minimal number of features and do not return a unique solution [5]. <p> A global structural description of the image is not needed. Perceptual grouping has proved to be a very useful paradigm for deriving relevant relational structures since it allows the system to assign computational resources intelligently <ref> [6, 8] </ref>. In this paper we propose a model-based approach to object recognition and localization based on perceptual grouping, structural stereop- sis and alignment (see Fig. 1). <p> This can be estimated by the frequency of appearance of the relation r in the object model. P (o) denotes the prior probability of the organization o being present among a set of features. We use formulae similar to the ones proposed by Lowe <ref> [6] </ref> to estimate this probability. Image groupings are found by combining image features that share significant relationships. For example, parallelograms are detected by combining two pairs of image segments which share two parallel and four proximity relations.
Reference: [7] <author> D. G. Lowe. </author> <title> Robust model-based motion tracking through the integration of search and estimation. </title> <journal> In- tern. J. Comput. Vis., </journal> <volume> 8(2) </volume> <pages> 113-122, </pages> <year> 1992. </year>
Reference-contexts: The significance of each match is computed based on the probability that a particular edge measurement arose from a model edge rather than from a background edge. Similar formalism is used as in <ref> [7] </ref>. The top-ranked image feature is matched with the projected model feature if its quality measure is significantly better than that of the second-ranked. This prevents the system from choosing ambiguous matches.
Reference: [8] <author> S. Sarkar and K. L. Boyer. </author> <title> Perceptual organization in computer vision: A review and a proposal for a classificatory structure. </title> <journal> IEEE Trans. Syst. Man Cybern., </journal> <volume> 23(2) </volume> <pages> 382-399, </pages> <month> March/April </month> <year> 1993. </year>
Reference-contexts: A global structural description of the image is not needed. Perceptual grouping has proved to be a very useful paradigm for deriving relevant relational structures since it allows the system to assign computational resources intelligently <ref> [6, 8] </ref>. In this paper we propose a model-based approach to object recognition and localization based on perceptual grouping, structural stereop- sis and alignment (see Fig. 1). <p> Using Bayes' rule, we can write for the probability that the relation r exists among two scene features, given that we have found the organization o among the projections of these features <ref> [8] </ref> P (rjo) = P (o) P (ojr) is the probability that we will observe the organization o among two image features given that the corresponding scene features satisfy the relational constraint r.
Reference: [9] <author> A. Ude. </author> <title> Trajectory generation from noisy positions of object features for teaching robot paths. </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <volume> 11(2) </volume> <pages> 113-127, </pages> <month> September </month> <year> 1993. </year>
Reference-contexts: Such images can be acquired only by use of active range sensors. These sensors typically spend a couple of minutes to scan a scene. The main goal of our system is the reconstruction of trajectories of moving objects <ref> [9] </ref>, therefore we prefer to use intensity images. Object recognition systems which use intensity imagery and invoke pose estimation must tackle the problem of calculating the 3-D object pose from 2-D to 3-D feature correspondences. Known methods are mostly iterative and require a good starting point [6].
Reference: [10] <author> Z. Zhang and O. Faugeras. </author> <title> 3D Dynamic Scene Analysis. </title> <publisher> Springer, </publisher> <address> Berlin, Heidelberg, </address> <year> 1992. </year> <month> 5 </month>
Reference-contexts: The computation of pose hypotheses is based on the implicitly given correspondences between the segments contained in the matched groupings. The noniterative method proposed by Zhang and Faugeras <ref> [10] </ref> for the pose calculation from 3-D to 3-D line correspondences is employed for this purpose. 4 Verification Once an initial pose hypothesis has been generated, it has to be checked for global consistency.
References-found: 10

