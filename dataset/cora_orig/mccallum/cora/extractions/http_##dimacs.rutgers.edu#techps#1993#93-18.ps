URL: http://dimacs.rutgers.edu/techps/1993/93-18.ps
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1993.html
Root-URL: http://www.cs.rutgers.edu
Email: e-mail henry@orion.uwaterloo.ca  
Title: CONVEX RELAXATIONS OF 0-1 QUADRATIC PROGRAMMING  
Author: Svatopluk Poljak and Henry Wolkowicz 
Keyword: Key words: quadratic boolean programming, bounds, quadratic programming, trust region subproblems, minmax eigenvalue problems.  
Note: on leave from the Department of Applied Mathematics, Charles University, Mal-ostranske nam. 25, 118 00 Praha 1, Czech Republic This author would like to thank the  their support during his research leave.  
Date: March 1993  
Address: Nankang, Taipei, Taiwan 11529  Waterloo, Ontario N2L 3G1, Canada  
Affiliation: Institute of Mathematics Academia Sinica  University of Waterloo Department of Combinatorics and Optimization  Department of Civil Engineering and Operations Research, Princeton University, for  
Abstract: We consider three parametric relaxations of the 0-1 quadratic programming problem. These relaxations are to: quadratic maximization over simple box constraints, quadratic maximization over the sphere, and the maximum eigenvalue of a bordered matrix. When minimized over the parameter, each of the relaxations provides an upper bound on the original discrete problem. Moreover, these bounds are efficiently computable. Our main result is that, surprisingly, all three bounds are equal. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R.B. BOPPANA. </author> <title> Eigenvalues and graph bisection: An average case analysis. </title> <booktitle> In Proceedings of the 28th Annual Symposium on Computer Science, </booktitle> <pages> pages 280-285. </pages> <publisher> IEEE, </publisher> <year> 1987. </year> <month> 13 </month>
Reference-contexts: This has been done in e.g. [16] for the stable set problem, in Boppana <ref> [1] </ref> for the graph bisection problem, and [5] for the max-cut problem. The quality of the approximation may vary with different combinatorial optimization problems. However, in general, it seems that the nonlinear relaxations provide better bounds more often than the linear ones.
Reference: [2] <author> T.F. COLEMAN. </author> <title> Large-scale numerical optimization: Introduction and overview. </title> <type> Technical report, </type> <institution> Cornell Theory Center, Cornell University, </institution> <address> Ithaca, NY, </address> <year> 1991. </year> <note> To appear in Encyclopedia of Computer Science and Technology, Marcel Decker. </note>
Reference-contexts: In fact, these problems can be solved in polynomial time, see e.g. [15]. Efficient numerical algorithms for these problems are described in e.g. <ref> [2] </ref>. The Lagrangian for (2.3) is L 1 (v; fl) := f 1 (v) + trace fl (Q diag (v)); where fl is a symmetric, positive semidefinite Lagrange multiplier matrix. The Slater constraint qualification holds for (2.3), i.e. there exists v such that Q diag (v) &lt; 0.
Reference: [3] <author> A.R. CONN, N.I.M. GOULD, and P.L. TOINT. LANCELOT: </author> <title> a Fortran package for large-scale nonlinear optimization (Release A), </title> <booktitle> Springer Series in Computational Mathematics. </booktitle> <publisher> Springer Verlag, </publisher> <address> Hei-delberg, Berlin, New York, </address> <year> 1992. </year>
Reference-contexts: However, there is a lot of ongoing research to improve algorithms for all three problems used in our relaxations. Bound B 1 corresponds to applying parametric programming to a quadratic programming problem with simple or box constraints. Efficient algorithms for this problem are given in e.g. <ref> [3] </ref>. These correspond to trust region type algorithms over the box or infinity norm rather than 2-norm. Bound B 2 corresponds to applying parametric programming to trust region subproblems 12 with the 2-norm.
Reference: [4] <author> J.M. DANSKIN. </author> <title> The Theory of Max Min. </title> <publisher> Springer-Verlag, </publisher> <address> New York, NY, </address> <year> 1967. </year>
Reference-contexts: Therefore f 1 (v) is the maximum of a set of linear functions. This implies that f 1 is convex in v. Moreover, compactness and continuity imply that f 1 is finite valued, 4 which further implies that f 1 is continuous and subdifferentiable. In <ref> [4] </ref> (See also pg 26 in [8] or pg 188 in [6].) it is shown that at any point v and any direction z, the directional derivative of f 1 exists and is a support function given by f 0 f1x1;f 1 (v)=q v (x)g The relationship between directional derivative and
Reference: [5] <author> C. DELORME and S. POLJAK. </author> <title> Laplacian eigenvalues and the maximum cut problem. </title> <type> Technical report, </type> <year> 1990. </year> <note> to appear in Math. Programming. </note>
Reference-contexts: One of the possible techniques is to relax problem (P) to a tractable nonlinear continuous problem in order to obtain upper bounds. This approach was used for graph partitioning problems in [7], and the maximum stable set problem in [16]. More recently it has been applied in e.g. <ref> [14, 25, 24, 5] </ref>. In this paper we study three different relaxations which yield three bounds. <p> We have B 2 = min n max (Q diag (u)): (3:9) For Q = L, the Laplacian matrix of a graph, (3.9) provides an upper bound on the max-cut problem , see <ref> [5] </ref>. <p> This has been done in e.g. [16] for the stable set problem, in Boppana [1] for the graph bisection problem, and <ref> [5] </ref> for the max-cut problem. The quality of the approximation may vary with different combinatorial optimization problems. However, in general, it seems that the nonlinear relaxations provide better bounds more often than the linear ones.
Reference: [6] <author> V.F. DEM'JANOV and V.N. MALOZEMOV. </author> <title> On the theory of nonlinear minimax problems. </title> <publisher> John Wiley and Sons, </publisher> <year> 1974. </year>
Reference-contexts: This implies that f 1 is convex in v. Moreover, compactness and continuity imply that f 1 is finite valued, 4 which further implies that f 1 is continuous and subdifferentiable. In [4] (See also pg 26 in [8] or pg 188 in <ref> [6] </ref>.) it is shown that at any point v and any direction z, the directional derivative of f 1 exists and is a support function given by f 0 f1x1;f 1 (v)=q v (x)g The relationship between directional derivative and subdifferential, see (1.2), yields the desired subdifferential formula, i.e. f 0
Reference: [7] <author> W.E. DONATH and A.J. HOFFMAN. </author> <title> Lower bounds for the partitioning of graphs. </title> <journal> IBM J. of Research and Developement, </journal> <volume> 17 </volume> <pages> 420-425, </pages> <year> 1973. </year>
Reference-contexts: Various approaches have been used to solve or approximate 1 or 0,1 programming problems. One of the possible techniques is to relax problem (P) to a tractable nonlinear continuous problem in order to obtain upper bounds. This approach was used for graph partitioning problems in <ref> [7] </ref>, and the maximum stable set problem in [16]. More recently it has been applied in e.g. [14, 25, 24, 5]. In this paper we study three different relaxations which yield three bounds.
Reference: [8] <author> A.V. FIACCO. </author> <title> Introduction to Sensitivity and Stability Analysis in Nonlinear Programming. </title> <publisher> Academic Press, </publisher> <year> 1983. </year>
Reference-contexts: This implies that f 1 is convex in v. Moreover, compactness and continuity imply that f 1 is finite valued, 4 which further implies that f 1 is continuous and subdifferentiable. In [4] (See also pg 26 in <ref> [8] </ref> or pg 188 in [6].) it is shown that at any point v and any direction z, the directional derivative of f 1 exists and is a support function given by f 0 f1x1;f 1 (v)=q v (x)g The relationship between directional derivative and subdifferential, see (1.2), yields the desired
Reference: [9] <author> M.R. GAREY and D.S. JOHNSON. </author> <title> Computers and Intractability: A guide to the theory of NP-completeness. </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: Moreover, 0,1 quadratic programming is equivalent to (P) via the transformation x = 2y e, where y is a (0; 1)vector and e is the vector of ones. These problems have many applications, in particular in combinatorial optimization. However, they are NP-hard, see e.g. <ref> [9] </ref> pg 196, problem GT25, since (P) is equivalent to the max-cut problem. Various approaches have been used to solve or approximate 1 or 0,1 programming problems. One of the possible techniques is to relax problem (P) to a tractable nonlinear continuous problem in order to obtain upper bounds.
Reference: [10] <author> D.M. GAY. </author> <title> Computing optimal locally constrained steps. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 2 </volume> <pages> 186-197, </pages> <year> 1981. </year>
Reference-contexts: These trust region subproblems can be classified into: the easy case if the Hes sian of the Lagrangian (see below) is positive definite; and the hard case otherwise. (For the theory and efficient algorithms, see e.g. <ref> [10, 28, 18] </ref>.) We now present some properties for the bound B 2 . Lemma 3.1 1. B 2 is an upper bound for (P), i.e. fl B 2 : 2. <p> Proof: Fix u with u t e = 0 and set y u so that jjy u jj 2 = n and f 2 (u) = q u (y u ). Then the optimality conditions for (P R 2 u ), see e.g. <ref> [10, 28] </ref>, imply that there exists such that Q diag (u) I 0; 2 (Q diag (u) I)y u = c; (3:4) i.e. the Hessian of the Lagrangian is negative semidefinite and y u is a sta tionary point of the Lagrangian. <p> Efficient algorithms for this problem are given in e.g. [3]. These correspond to trust region type algorithms over the box or infinity norm rather than 2-norm. Bound B 2 corresponds to applying parametric programming to trust region subproblems 12 with the 2-norm. Efficient algorithms are given in <ref> [10, 18] </ref>, where the sub--problems are solved to near optimality in typically 1-2 iterations. There is ongoing recent research to develop more efficient algorithm in particular for large problems. Finally B 3 corresponds to minimizing the maximum eigenvalue. Theory and efficient algorithms for this problem are surveyed in [20].
Reference: [11] <author> P.L. HAMMER and A.A. RUBIN. </author> <title> Some remarks on quadratic programming with 0-1 variables. </title> <journal> R.I.R.O., </journal> <volume> 3 </volume> <pages> 67-79, </pages> <year> 1970. </year>
Reference-contexts: In a weaker form, which corresponds to setting v = max (Q)e, where max denotes the largest eigenvalue, it was proposed by Hammer and Rubin <ref> [11] </ref>. 3 BOUND 2 Optimization Over Sphere Now, for u t e = 0, we again consider the shifted function q u (y) := y t (Q diag (u))y + u t e + c t y; (3:1) and the second relaxed problem (P R 2 jjyjj 2 =n q u
Reference: [12] <author> R. HORN and C. JOHNSON. </author> <title> Matrix Analysis. </title> <publisher> Cambridge University Press, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Then is an eigenvalue of D (t) with eigenvector y, since (Q u I)x = 1 2 c: Moreover, the optimality conditions Q u I 0 implies max (Q u ). Therefore, by the interlacing theorem for eigenvalues, e.g. <ref> [12] </ref>, = max (D (t)): This implies that n + 1 n 1 n + 1 is the largest eigenvalue of the shifted matrix D (t) n + 1 I = Q c diag (u c ); thereby defining the n + 1 dimensional vector u c := n+1 t n+1
Reference: [13] <author> A. P. KAMATH and N. K. KARMARKAR. </author> <title> A continuous method for computing bounds in integer quadratic optimization problems. </title> <journal> Journal of Global Optimization, </journal> <volume> 2(3) </volume> <pages> 229-241, </pages> <year> 1992. </year> <month> 14 </month>
Reference-contexts: Theory and efficient algorithms for this problem are surveyed in [20]. In fact, the theory shows that these algorithms have quadratic convergence properties, which is surprising for possibly nondifferentiable problems. An interior point algorithm to compute B 3 was given in <ref> [13] </ref>. There are several interesting questions that our equivalences raise, e.g. which is the most efficient way to solve the various problems.
Reference: [14] <author> F. K ORNER. </author> <title> A tight bound for the boolean quadratic optimization problem and its use in a branch and bound algorithm. </title> <journal> Optimization, </journal> <volume> 19 </volume> <pages> 711-721, </pages> <year> 1988. </year>
Reference-contexts: One of the possible techniques is to relax problem (P) to a tractable nonlinear continuous problem in order to obtain upper bounds. This approach was used for graph partitioning problems in [7], and the maximum stable set problem in [16]. More recently it has been applied in e.g. <ref> [14, 25, 24, 5] </ref>. In this paper we study three different relaxations which yield three bounds. <p> 1 (v) if and only if the following optimality conditions hold for some fl, see e.g. [17]: 0 2 @f 1 (v) diag (fl) (stationarity) trace fl (Q diag (v)) = 0 (complementary slackness) fl = fl t 0 (multiplier sign): (2:6) Bound B 1 was first considered in Korner <ref> [14] </ref> for constrained problems.
Reference: [15] <author> M.K. KOZLOV, S.P. TARASOV, and L.G. KHACHIYAN. </author> <title> Polynomial solvability of convex quadratic programming. </title> <journal> Soviet Math. Doklady, </journal> <volume> 20 </volume> <pages> 1108-1111, </pages> <year> 1979. </year>
Reference-contexts: Therefore, we can replace q 0 (x) in (P) with a concave function by restricting Q diag (v) 0: We then have a tractable problem to solve. In fact, these problems can be solved in polynomial time, see e.g. <ref> [15] </ref>. Efficient numerical algorithms for these problems are described in e.g. [2]. The Lagrangian for (2.3) is L 1 (v; fl) := f 1 (v) + trace fl (Q diag (v)); where fl is a symmetric, positive semidefinite Lagrange multiplier matrix.
Reference: [16] <author> L. LOVASZ. </author> <title> On the Shannon capacity of a graph. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 25 </volume> <pages> 1-7, </pages> <year> 1979. </year>
Reference-contexts: One of the possible techniques is to relax problem (P) to a tractable nonlinear continuous problem in order to obtain upper bounds. This approach was used for graph partitioning problems in [7], and the maximum stable set problem in <ref> [16] </ref>. More recently it has been applied in e.g. [14, 25, 24, 5]. In this paper we study three different relaxations which yield three bounds. <p> Since the bounds B 1 = B 2 = B 3 are introduced in order to approximate the original discrete problem (P), it is important to study the connection between the original combinatorial problem and its relaxation. This has been done in e.g. <ref> [16] </ref> for the stable set problem, in Boppana [1] for the graph bisection problem, and [5] for the max-cut problem. The quality of the approximation may vary with different combinatorial optimization problems. However, in general, it seems that the nonlinear relaxations provide better bounds more often than the linear ones.
Reference: [17] <author> D.G. LUENBERGER. </author> <title> Optimization by Vector Space Methods. </title> <publisher> John Wiley, </publisher> <year> 1969. </year>
Reference-contexts: The Slater constraint qualification holds for (2.3), i.e. there exists v such that Q diag (v) &lt; 0. Therefore, B 1 = f 1 (v) if and only if the following optimality conditions hold for some fl, see e.g. <ref> [17] </ref>: 0 2 @f 1 (v) diag (fl) (stationarity) trace fl (Q diag (v)) = 0 (complementary slackness) fl = fl t 0 (multiplier sign): (2:6) Bound B 1 was first considered in Korner [14] for constrained problems.
Reference: [18] <author> J.J. MOR E and D.C. SORENSEN. </author> <title> Computing a trust region step. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 4 </volume> <pages> 553-572, </pages> <year> 1983. </year>
Reference-contexts: These trust region subproblems can be classified into: the easy case if the Hes sian of the Lagrangian (see below) is positive definite; and the hard case otherwise. (For the theory and efficient algorithms, see e.g. <ref> [10, 28, 18] </ref>.) We now present some properties for the bound B 2 . Lemma 3.1 1. B 2 is an upper bound for (P), i.e. fl B 2 : 2. <p> Efficient algorithms for this problem are given in e.g. [3]. These correspond to trust region type algorithms over the box or infinity norm rather than 2-norm. Bound B 2 corresponds to applying parametric programming to trust region subproblems 12 with the 2-norm. Efficient algorithms are given in <ref> [10, 18] </ref>, where the sub--problems are solved to near optimality in typically 1-2 iterations. There is ongoing recent research to develop more efficient algorithm in particular for large problems. Finally B 3 corresponds to minimizing the maximum eigenvalue. Theory and efficient algorithms for this problem are surveyed in [20].
Reference: [19] <author> Y. E. NESTEROV and A. S. NEMIROVSKY. </author> <title> Interior Point Polynomial Methods in Convex Programming : Theory and Algorithms. </title> <publisher> SIAM Publications. SIAM, </publisher> <address> Philadelphia, USA, </address> <year> 1993. </year>
Reference-contexts: In each case f (u) is a convex function and L is a convex set. Therefore, finding the bound B can be done in polynomial time, see <ref> [19] </ref>. The relaxations are to: 0 The authors would like to thank DIMACS Center at Rutgers University for their support.
Reference: [20] <author> M.L. OVERTON. </author> <title> Large-scale optimization of eigenvalues. </title> <journal> SIAM J. Optimization, </journal> <volume> 2 </volume> <pages> 88-120, </pages> <year> 1992. </year>
Reference-contexts: The problem (4.3) is equivalent to minimizing the maximum eigenvalue of a matrix. These type of problems are treated in e.g. <ref> [20, 21] </ref>, where efficient algorithms are presented as well as optimality conditions. The above theorem shows that these problems can also be treated using efficient trust region subproblem algorithms. <p> There is ongoing recent research to develop more efficient algorithm in particular for large problems. Finally B 3 corresponds to minimizing the maximum eigenvalue. Theory and efficient algorithms for this problem are surveyed in <ref> [20] </ref>. In fact, the theory shows that these algorithms have quadratic convergence properties, which is surprising for possibly nondifferentiable problems. An interior point algorithm to compute B 3 was given in [13].
Reference: [21] <author> M.L. </author> <title> OVERTON and R.S. WOMERSLEY. On the sum of the largest eigenvalues of a symmetric matrix. </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <volume> 13 </volume> <pages> 41-45, </pages> <year> 1992. </year>
Reference-contexts: The problem (4.3) is equivalent to minimizing the maximum eigenvalue of a matrix. These type of problems are treated in e.g. <ref> [20, 21] </ref>, where efficient algorithms are presented as well as optimality conditions. The above theorem shows that these problems can also be treated using efficient trust region subproblem algorithms.
Reference: [22] <author> S. POLJAK and F. RENDL. </author> <title> Nonlinear relaxations of graph-bisection problems. </title> <type> Technical Report 92-55, </type> <institution> DIMACS, </institution> <year> 1992. </year>
Reference-contexts: From this point of view, the quadratic programming bound B 1 seems to be the most tractable, since it immediately allows adding additional linear constraints. However, one may add certain constraints to the other bounds. For example, in <ref> [22] </ref> an eigenvalue relaxation with additional polyhedral constraints is considered for the graph bisection problem.
Reference: [23] <author> F. RENDL. </author> <title> An inverse parametric eigenvalue approach to trust region problems. </title> <type> Technical report, </type> <institution> Technische Universitat Graz, Graz, Austria, </institution> <year> 1992. </year>
Reference-contexts: stationarity condition for (RP 2 u ), we can substitute (Q u I)x = 1 2 c and see that the objective value f 2 (u) = q u (x) (x t x n) = n 1 2 Similar relations between trust region subproblems and eigenvalue problems are presented in <ref> [30, 23] </ref>. The problem (4.3) is equivalent to minimizing the maximum eigenvalue of a matrix. These type of problems are treated in e.g. [20, 21], where efficient algorithms are presented as well as optimality conditions.
Reference: [24] <author> F. RENDL and H. WOLKOWICZ. </author> <title> A projection technique for partitioning the nodes of a graph. </title> <type> Technical Report CORR 90-20, </type> <institution> University of Waterloo, Waterloo, Canada, </institution> <year> 1990. </year>
Reference-contexts: One of the possible techniques is to relax problem (P) to a tractable nonlinear continuous problem in order to obtain upper bounds. This approach was used for graph partitioning problems in [7], and the maximum stable set problem in [16]. More recently it has been applied in e.g. <ref> [14, 25, 24, 5] </ref>. In this paper we study three different relaxations which yield three bounds.
Reference: [25] <author> F. RENDL and H. WOLKOWICZ. </author> <title> Applications of parametric programming and eigenvalue maximization to the quadratic assignment problem. </title> <journal> Mathematical Programming, </journal> <volume> 53 </volume> <pages> 63-78, </pages> <year> 1992. </year> <month> 15 </month>
Reference-contexts: One of the possible techniques is to relax problem (P) to a tractable nonlinear continuous problem in order to obtain upper bounds. This approach was used for graph partitioning problems in [7], and the maximum stable set problem in [16]. More recently it has been applied in e.g. <ref> [14, 25, 24, 5] </ref>. In this paper we study three different relaxations which yield three bounds.
Reference: [26] <author> R.T. ROCKAFELLAR. </author> <title> Convex Analysis. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ, </address> <year> 1970. </year>
Reference-contexts: t#0 t : The relationship between directional deriva tive and subdifferential is given by f 0 (v; z) = max t z: (1:2) This means that f 0 (v; :) is a positively homogeneous, sublinear functional, and it is the support function of @f (v). (For more details see e.g. <ref> [26] </ref>.) 2 BOUND 1 Convex Quadratic Programming Consider the shifted function q v (x) := x t (Q diag (v))x + v t e + c t x; (2:1) and the relaxed problem (P R 1 1x1 Then a bound for (P) is B 1 := min Qdiag (v)0 f 1 <p> By Caratheodory's Theorem, see e.g. <ref> [26] </ref>, for elements in the convex hull we need only consider k n + 1 optimal solutions y (j) .
Reference: [27] <author> H. SCHRAMM and J. </author> <title> ZOWE. A version of the bundle idea for minimizing a nonsmooth function: Conceptual idea, convergence analysis, numerical results. </title> <journal> SIAM J. Optimization, </journal> <volume> 2 </volume> <pages> 121-152, </pages> <year> 1992. </year>
Reference-contexts: In particular, we see that we can solve min-max eigenvalue problems by applying known trust region subproblem algorithms or even quadratic programming combined with some subdifferential calculus like a bundle trust subgradient approach, see e.g. <ref> [27] </ref>. Another question is to study the performance of the relaxations in the presence of additional constraints. Problem (P) is an unconstrained 1 quadratic programming problem. However, many combinatorial optimization problems naturally lead to constrained 1 quadratic programming problems.
Reference: [28] <author> D.C. SORENSEN. </author> <title> Trust region methods for unconstrained minimization. </title> <editor> In M.J.D. Powell, editor, </editor> <title> Nonlinear Optimization 1981. </title> <publisher> Academic Press, </publisher> <address> London, </address> <year> 1982. </year>
Reference-contexts: These trust region subproblems can be classified into: the easy case if the Hes sian of the Lagrangian (see below) is positive definite; and the hard case otherwise. (For the theory and efficient algorithms, see e.g. <ref> [10, 28, 18] </ref>.) We now present some properties for the bound B 2 . Lemma 3.1 1. B 2 is an upper bound for (P), i.e. fl B 2 : 2. <p> Proof: Fix u with u t e = 0 and set y u so that jjy u jj 2 = n and f 2 (u) = q u (y u ). Then the optimality conditions for (P R 2 u ), see e.g. <ref> [10, 28] </ref>, imply that there exists such that Q diag (u) I 0; 2 (Q diag (u) I)y u = c; (3:4) i.e. the Hessian of the Lagrangian is negative semidefinite and y u is a sta tionary point of the Lagrangian.
Reference: [29] <author> R.J. STERN and H. WOLKOWICZ. </author> <title> Indefinite trust region subprob-lems and nonsymmetric eigenvalue perturbations. </title> <type> Technical Report CORR 92-38, </type> <institution> University of Waterloo, Waterloo, Canada, </institution> <year> 1992. </year>
Reference-contexts: This can also be seen from the fact that there is a dual problem to (P R 2 u ) that minimizes a convex function over an interval, see <ref> [29] </ref>.
Reference: [30] <author> R.J. STERN and H. WOLKOWICZ. </author> <title> Trust region problems and nonsymmetric perturbation theory. </title> <journal> SIAM J. Matrix Analysis and Applications, </journal> <note> 1993. to appear. </note>
Reference-contexts: stationarity condition for (RP 2 u ), we can substitute (Q u I)x = 1 2 c and see that the objective value f 2 (u) = q u (x) (x t x n) = n 1 2 Similar relations between trust region subproblems and eigenvalue problems are presented in <ref> [30, 23] </ref>. The problem (4.3) is equivalent to minimizing the maximum eigenvalue of a matrix. These type of problems are treated in e.g. [20, 21], where efficient algorithms are presented as well as optimality conditions.
Reference: [31] <author> Y. YE. </author> <title> On affine scaling algorithms for nonconvex quadratic program-min. </title> <journal> Mathematical Programming, </journal> <volume> 56 </volume> <pages> 285-300, </pages> <year> 1992. </year> <month> 16 </month>
Reference-contexts: Note that (P R 2 u ) is not linearly constrained. These quadratically constrained problems are called trust region subproblems and are also tractable and can be solved in polynomial time, see <ref> [31] </ref>. This can also be seen from the fact that there is a dual problem to (P R 2 u ) that minimizes a convex function over an interval, see [29].
References-found: 31

