URL: http://www.cis.ohio-state.edu/~rjmiller/Teaching/788dir/papers/zgmhw95.ps
Refering-URL: http://www.cis.ohio-state.edu/~rjmiller/Teaching/788dir/bib.html
Root-URL: 
Email: fzhuge,hector,joachim,widomg@cs.stanford.edu  
Title: View Maintenance in a Warehousing Environment  
Author: Yue Zhuge, Hector Garcia-Molina, Joachim Hammer, Jennifer Widom 
Address: Stanford, CA 94305-2140, USA  
Affiliation: Computer Science Department Stanford University  
Abstract: A warehouse is a repository of integrated information drawn from remote data sources. Since a warehouse effectively implements materialized views, we must maintain the views as the data sources are updated. This view maintenance problem differs from the traditional one in that the view definition and the base data are now decoupled. We show that this de-coupling can result in anomalies if traditional algorithms are applied. We introduce a new algorithm, ECA (for "Eager Compensating Algorithm"), that eliminates the anomalies. ECA is based on previous incremental view maintenance algorithms, but extra "compensating" queries are used to eliminate anomalies. We also introduce two streamlined versions of ECA for special cases of views and updates, and we present an initial performance study that compares ECA to a view recomputation algorithm in terms of messages transmitted, data transferred, and I/O costs. 
Abstract-found: 1
Intro-found: 1
Reference: [BGMS92] <author> Y. Breitbart, H. Garcia-Molina, and A. Silber-schatz. </author> <title> Overview of multidatabase transaction management. </title> <journal> VLDB Journal, </journal> <volume> 1(2) </volume> <pages> 181-239, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: The algorithms in this paper could be viewed as a specialized concurrency control mechanism for a multi-database system. Our algorithms exploit the semantics of the application (relational views) to provide a certain type of consistency without traditional locking. Paper <ref> [BGMS92] </ref> provides a survey of related work. 3 Correctness Our first task is to define what correctness means in an environment where activity at the source is decoupled from the view at the warehouse. We start by defining the notion of events.
Reference: [BLT86] <author> J.A. Blakeley, P.-A. Larson, and F.W. Tompa. </author> <title> Efficiently updating materialized views. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 61-71, </pages> <address> Washington, D.C., </address> <month> June </month> <year> 1986. </year>
Reference-contexts: Although we are using relational algebra, we assume that duplicates are retained in the materialized views. Duplicate retention (or at least a replication count) is essential if deletions are to be handled incrementally <ref> [BLT86, GMS93] </ref>. Note that Warehouse Queries Answers Updates Souce the type of solution we propose here can be extended to other data models and view specification languages. Also, in the examples and in this paper we focus on a single source, and a single view over several base relations. <p> The answer it returns is A 1 = ; since both relations are now empty. 6. The warehouse receives A 1 and replaces the view by MV A 1 = ([1; 3]). (Difference is used here since the update to the base relation was a deletion <ref> [BLT86] </ref>.) 7. Similarly, the source evaluates Q 2 , returns A 2 = ;, and the warehouse replaces the view by MV A 2 = ([1; 3]). <p> These algorithms differ somewhat in the view definitions they handle. For example, <ref> [BLT86] </ref> considers select-project-join (SPJ) views only, while algorithms in [GMS93] handle views defined by any SQL or Datalog expression. Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. <p> Note that although we describe our algorithms for SPJ views, our approach can be applied to adapt any existing centralized view maintenance algorithm to the warehousing environment. In both centralized and distributed systems, there are three general approaches to the timing of view maintenance: immediate update <ref> [BLT86] </ref>, which updates the view after each base relation is updated, deferred update [RK86], which updates the view only when a query is is sued against the view, and periodic update [LHM + 86], which updates the view at periodic intervals. <p> once for each appearance of the relation). 4.1 Signs Our warehouse algorithms will handle two types of updates: insertions and deletions. (Modifications must be treated as deletions followed by insertions, although extensions to our approach could permit modifications to be treated directly.) For convenience, we adopt an approach similar to <ref> [BLT86] </ref> and use signs on tuples: + to denote an inserted or an existing tuple, and to denote a deleted tuple. Tuple signs are propagated through relational operations, as we will illustrate. <p> ECA is an incremental view maintenance algorithm based on the centralized view maintenance algorithm described in <ref> [BLT86] </ref>. ECA anticipates the anomalies that arise due to the decou-pling between base relation updates and view modification, and ECA compensates for the anomalies as needed to ensure correct view maintenance. <p> Before we present ECA and its extensions, we first review the original incremental view maintenance algorithm. 5.1 The Basic Algorithm The view maintenance algorithm described in <ref> [BLT86] </ref> applies incremental changes to a view each time changes are made to relevant base relations. <p> A number of papers, e.g., [BLT86,GB94,TB88], describe conditions when, for a particular view definition and a particular base relation update, the view can be updated without further access to base relations (i.e., the view is autonomously computable, using the terminology of <ref> [BLT86] </ref>). These results can be used to identify which updates ECA L will process locally. For updates that cannot be processed locally, ECA is used (assuming the key condition for ECA K does not hold), with compensating queries whenever necessary.
Reference: [CW91] <author> S. Ceri and J. Widom. </author> <title> Deriving production rules for incremental view maintenance. </title> <booktitle> In Proceedings of the Seventeenth International Conference on Very Large Data Bases, </booktitle> <pages> pages 577-589, </pages> <address> Barcelona, Spain, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in [GMS93] handle views defined by any SQL or Datalog expression. Some algorithms depend on key information to deal with duplicate tuples <ref> [CW91] </ref>, while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems [SF90,SF91,SP89a,SP89b]. All algorithms in these papers are based on timestamp-ing the updated tuples, and the algorithms assume there is only one base table.
Reference: [GB94] <author> Ashish Gupta and J. A. Blakeley. </author> <title> Updating materialized views using the view contents and the update. In unpublished document, </title> <year> 1994. </year>
Reference: [GMS93] <author> A. Gupta, I. Mumick, and V. Subrahmanian. </author> <title> Maintaining views incrementally. </title> <booktitle> In Proceedings of the 1993 ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 157-166, </pages> <address> Washington, D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Although we are using relational algebra, we assume that duplicates are retained in the materialized views. Duplicate retention (or at least a replication count) is essential if deletions are to be handled incrementally <ref> [BLT86, GMS93] </ref>. Note that Warehouse Queries Answers Updates Souce the type of solution we propose here can be extended to other data models and view specification languages. Also, in the examples and in this paper we focus on a single source, and a single view over several base relations. <p> These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in <ref> [GMS93] </ref> handle views defined by any SQL or Datalog expression. Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems [SF90,SF91,SP89a,SP89b]. <p> These algorithms differ somewhat in the view definitions they handle. For example, [BLT86] considers select-project-join (SPJ) views only, while algorithms in <ref> [GMS93] </ref> handle views defined by any SQL or Datalog expression. Some algorithms depend on key information to deal with duplicate tuples [CW91], while others use a counting approach [GMS93]. A series of papers by Segev et al. studies materialized views in distributed systems [SF90,SF91,SP89a,SP89b]. All algorithms in these papers are based on timestamp-ing the updated tuples, and the algorithms assume there is only one base table.
Reference: [Han87] <author> E.N. Hanson. </author> <title> A performance analysis of view materialization strategies. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 440-453, </pages> <year> 1987. </year>
Reference-contexts: Performance studies on these strategies have determined that the efficiency of an approach depends heavily on the structure of the base relations and on update patterns <ref> [Han87] </ref>. We assume immediate update in this paper, but we observe that with little or no modification our algorithms can be applied to deferred and periodic update as well. The algorithms in this paper could be viewed as a specialized concurrency control mechanism for a multi-database system.
Reference: [HD92] <author> J.V. Harrison and S.W. Dietrich. </author> <title> Maintenance of materialized views in a deductive database: An update propagation approach. </title> <booktitle> In Proceedings of the 1992 JICLSP Workshop on Deductive Databases, </booktitle> <pages> pages 56-65, </pages> <year> 1992. </year>
Reference: [IK93] <author> W.H. Inmon and C. Kelley. Rdb/VMS: </author> <title> Developing the Data Warehouse. </title> <publisher> QED Publishing Group, </publisher> <address> Boston, London, Toronto, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Warehousing is an emerging technique for retrieval and integration of data from distributed, autonomous, possibly heterogeneous, information sources. A data warehouse is a repository of integrated information, available for queries and analysis (e.g., decision support, or data mining) <ref> [IK93] </ref>.
Reference: [LHM + 86] <author> B. Lindsay, L.M. Haas, C. Mohan, H. Pira-hesh, and P. Wilms. </author> <title> A snapshot differential refresh algorithm. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <address> Washington, D.C., </address> <month> May </month> <year> 1986. </year>
Reference-contexts: A series of papers by Segev et al. studies materialized views in distributed systems [SF90,SF91,SP89a,SP89b]. All algorithms in these papers are based on timestamp-ing the updated tuples, and the algorithms assume there is only one base table. Other incremental algorithms, such as the "snapshot" procedure in <ref> [LHM + 86] </ref>, also assume timestamping and a single base table. In contrast, our algorithms have no restrictions on the number of base tables, and they require no additional information. <p> In both centralized and distributed systems, there are three general approaches to the timing of view maintenance: immediate update [BLT86], which updates the view after each base relation is updated, deferred update [RK86], which updates the view only when a query is is sued against the view, and periodic update <ref> [LHM + 86] </ref>, which updates the view at periodic intervals. Performance studies on these strategies have determined that the efficiency of an approach depends heavily on the structure of the base relations and on update patterns [Han87].
Reference: [QW91] <author> X. Qian and G. Wiederhold. </author> <title> Incremental recomputation of active relational expressions. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 3(3) </volume> <pages> 337-341, </pages> <month> September </month> <year> 1991. </year>
Reference: [RK86] <author> N. Roussopoulos and H. Kang. </author> <title> Preliminary design of ADMS+-: A workstation-mainframe integrated architecture for database management systems. </title> <booktitle> In Proceedings of the Twelfth International Conference on Very Large Data Bases, </booktitle> <pages> pages 355-364, </pages> <address> Kyoto, Japan, </address> <month> August </month> <year> 1986. </year>
Reference-contexts: In both centralized and distributed systems, there are three general approaches to the timing of view maintenance: immediate update [BLT86], which updates the view after each base relation is updated, deferred update <ref> [RK86] </ref>, which updates the view only when a query is is sued against the view, and periodic update [LHM + 86], which updates the view at periodic intervals.
Reference: [SF90] <author> A. Segev and W. Fang. </author> <title> Currency-based updates to distributed materialized views. </title> <booktitle> In Proceedings of the Sixth International Conference on Data Engineering, </booktitle> <pages> pages 512-520, </pages> <address> Los Alamitos, </address> <month> February </month> <year> 1990. </year>
Reference: [SF91] <author> A. Segev and W. Fang. </author> <title> Optimal update policies for distributed materialized views. </title> <journal> Management Science, </journal> <volume> 37(7) </volume> <pages> 851-70, </pages> <month> July </month> <year> 1991. </year>
Reference: [SI84] <author> O. Shmueli and A. Itai. </author> <title> Maintenance of views. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on Management of Data, </booktitle> <pages> pages 240-255, </pages> <address> Boston, Massachusetts, </address> <month> May </month> <year> 1984. </year>
Reference: [SP89a] <author> A. Segev and J. Park. </author> <title> Maintaining materialized views in distributed databases. </title> <booktitle> In Proceedings of the Fifth International Conference on Data Engineering, </booktitle> <pages> pages 262-70, </pages> <address> Los Ange-les, </address> <month> February </month> <year> 1989. </year>
Reference: [SP89b] <author> A. Segev and J. Park. </author> <title> Updating distributed materialized views. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 1(2) </volume> <pages> 173-184, </pages> <month> June </month> <year> 1989. </year>
Reference: [TB88] <author> F.W. Tompa and J.A. Blakeley. </author> <title> Maintaining materialized views without accessing base data. </title> <journal> Information Systems, </journal> <volume> 13(4) </volume> <pages> 393-406, </pages> <year> 1988. </year>
Reference: [ZGMHW94] <author> Y. Zhuge, H. Garcia-Molina, J. Hammer, and J. Widom. </author> <title> View maintenance in a warehousing environment. </title> <type> Technical report, </type> <institution> Stan-ford University, </institution> <month> October </month> <year> 1994. </year> <note> Available via anonymous ftp from host db.stanford.edu as pub/zhuge/1994/anomaly-full.ps. </note>
Reference-contexts: In Section 7 we conclude and discuss future directions of our work. Additional details|additional examples, proofs, analyses, etc.| that are too lengthy and intricate to be included in the body of the paper are presented in <ref> [ZGMHW94] </ref> (available via anonymous ftp from host db.stanford.edu). 2 Related Research Many incremental view maintenance algorithms have been developed. <p> A number of additional ECA examples are given in <ref> [ZGMHW94] </ref>. Example 4: ECA Consider source relations: r 1 : 1 2 X Y Y Z Let the view definition be V = W (r 1 ./ r 2 ./ r 3 ), and suppose the following events occur. <p> Warehouse receives A 3 = ; COLLECT = ([1],[4])+ ; = ([1],[4]), U QS = ; Warehouse updates view: MV = ; + COLLECT = ([1]; [4]), which is correct. 2 A complete proof showing that the algorithm is strongly consistent is given in <ref> [ZGMHW94] </ref>. Notice, however, that ECA is not complete. Recalling Section 3.1, completeness requires that every source state be reflected in some view state. Clearly some source states may be "missed" by the ECA algorithm while it collects query answers. <p> Details and a sketch for the ECA K correctness proof appear in <ref> [ZGMHW94] </ref>. 5.5 The ECA-Local Algorithm The original ECA uses compensating queries to avoid the anomalies that may occur when queries are sent to the source. <p> Throughout this section, we use the variables listed in Table 1, shown with their default values. The RV algorithm is described informally in Section 1.2; a formal specification is provided in <ref> [ZGMHW94] </ref>. <p> Intuitively, the difference between the best and worst cases of ECA represents the "compensation cost." The calculations for analyzing our algorithms are rather complex and therefore omitted here; the complete derivations can be found in <ref> [ZGMHW94] </ref>. In particular, the expressions derived in [ZGMHW94] for the number of bytes transferred are: B RVBest = SCJ 2 B RVWorst = 3SCJ 2 B ECABest = 3SJ 2 B ECAWorst = 3SJ (J + 1) as a function of the cardinality C. (In all of our graphs, parameters have <p> Intuitively, the difference between the best and worst cases of ECA represents the "compensation cost." The calculations for analyzing our algorithms are rather complex and therefore omitted here; the complete derivations can be found in <ref> [ZGMHW94] </ref>. In particular, the expressions derived in [ZGMHW94] for the number of bytes transferred are: B RVBest = SCJ 2 B RVWorst = 3SCJ 2 B ECABest = 3SJ 2 B ECAWorst = 3SJ (J + 1) as a function of the cardinality C. (In all of our graphs, parameters have the default values of Table 1 unless <p> This result continues to hold over wide ranges of the join selectivity J, except if J is very small (see equations above). One of the reasons ECA appears to perform so well is that we are considering only three updates, so the amount of "compensation work" is limited. In <ref> [ZGMHW94] </ref> we extend our analysis to an arbitrary number k of updates and obtain the following equations: B RVBest = SCJ 2 B RVWorst = kSCJ 2 B ECABest = kSJ 2 B ECAWorst = kSJ 2 + k (k 1)SJ=3 a function of k when C = 100. <p> In particular, B RVWorst is very expensive and always substantially worst than B ECAWorst . 6.3 Performance Based on I/O Estimating the number of I/O's performed at the source is similar to estimating the number of bytes transferred. Details of the estimation are discussed in <ref> [ZGMHW94] </ref>. We consider two extreme scenarios there: when indexing is used and ample memory is available, and when memory is very limited and there are no indexes. Studying these extremes lets us discover the conditions that are most favorable for the algorithms we consider.
References-found: 18

