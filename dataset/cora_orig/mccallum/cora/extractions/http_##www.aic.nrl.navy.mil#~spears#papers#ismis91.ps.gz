URL: http://www.aic.nrl.navy.mil/~spears/papers/ismis91.ps.gz
Refering-URL: http://www.cs.gmu.edu:80/research/gag/pubs.html
Root-URL: 
Title: A STUDY OF CROSSOVER OPERATORS IN GENETIC PROGRAMMING  
Author: William M. Spears and Vic Anand 
Address: Code 5510 Washington, D.C 20375-5000  Cambridge, MA 02139  
Affiliation: Navy Center for Applied Research in AI Naval Research Laboratory,  Massachusetts Institute of Technology  
Abstract: Holland's analysis of the sources of power of genetic algorithms has served as guidance for the applications of genetic algorithms for more than 15 years. The technique of applying a recombination operator (crossover) to a population of individuals is a key to that power. Neverless, there have been a number of contradictory results concerning crossover operators with respect to overall performance. Recently, for example, genetic algorithms were used to design neural network modules and their control circuits. In these studies, a genetic algorithm without crossover outperformed a genetic algorithm with crossover. This report re-examines these studies, and concludes that the results were caused by a small population size. New results are presented that illustrate the effectiveness of crossover when the population size is larger. From a performance view, the results indicate that better neural networks can be evolved in a shorter time if the genetic algorithm uses crossover. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> de Garis, H. </author> <year> (1990a). </year> <title> Genetic Programming: Building Nanobrains with Genetically Programmed Neural Network Modules, </title> <booktitle> Proceedings of the International Joint Conference on Neural Networks, </booktitle> <address> San Diego, CA, </address> <month> June </month> <year> 1990. </year> <title> [2] de Garis, </title> <editor> H. </editor> <year> (1990b). </year> <type> Personal Communication. </type>
Reference-contexts: If a neural network is used to encapsulate a particular behaviour, then genetic algorithms can be used to evolve that behaviour, by evolving a population of neural networks. One particular approach to the evolution of behaviour is described by de Garis <ref> [1] </ref>. In this approach, a GA is used to evolve a population of neural networks. Each NN has a set of adjustable weights and is used to encapsulate some desired behaviour (e.g., walking). <p> Instead of the more traditional NN learning algorithms (e.g., backpropagation) de Garis uses a genetic algorithm to learn a set of good weights. No learning is being done by the neural network itself. This approach is called genetic programming <ref> [1] </ref>. As mentioned above, GAs evolve a population of individuals according to the process of natural selection. During this process, genetic operators create new (child) individuals from highly fit old (parent) individuals. <p> Input neurons are neurons that receive information from the environment. Output neurons provide actions that affect the environment. Hidden neurons can be used to provide arbitrary transformations of the input stimuli. Let us now consider an example from <ref> [1] </ref> that is also used for the experiments described in this report. We will refer to this example as the Walker. In this example, a GenNet is evolved to control a set of stick legs. The behaviour to be learned by the genetic algorithm is that of walking. <p> Given an arbitrary setting of weights in the GenNet, the stick legs will move in a random fashion. However, with the proper weights it is possible for the Gen-Net to control the stick legs in such a way as to perform the behaviour of walking <ref> [1] </ref>. The goal is to learn the appropriate weights. As mentioned earlier, a genetic algorithm is used to learn the weights of the GenNet. This requires a bit string representation of the neural network and a fitness function that quantifies how well the behaviour of walking is achieved. <p> This requires a bit string representation of the neural network and a fitness function that quantifies how well the behaviour of walking is achieved. In genetic programming, each real valued weight is represented by a set number of bits b <ref> [1] </ref>. Since each neuron is connected to all others (including itself), the weights of an n neuron network can be stored in an n by n matrix. Each element of the matrix stores the weight of one connection. <p> Each element of the matrix stores the weight of one connection. Each matrix specifies a GenNet uniquely and can be represented as a bit string in row major order. Each individual of the GA, then, represents the linearized weight matrix <ref> [1] </ref>. If there are n neurons in the network, bn 2 bits are required for each individual. For the stick legs, de Garis represents each weight by 7 bits, resulting in individuals that are 1008 bits long, since there are 12 neurons in the network. <p> The fitness function (used to evaluate each individual described above) should accept each individual in the population and return some quantification of how well the behaviour of walking is being performed by that individual. One straightforward fitness function is to compute the distance traveled by the stick legs <ref> [1] </ref>. Better individuals travel farther (e.g., walk better) and worse individuals travel less far. The goal is to find a set of weights such that the resulting GenNet will produce good walking behaviour. The following sections outline how well genetic programming succeeds in achieving this goal. 4. <p> A larger population allows the space to be sampled more thoroughly, resulting in more accurate statistics. Small populations sample the space less thoroughly, producing results with higher variance. In his experiment with the Walker problem, de Garis reported that a GA without recombination outperformed a GA with recombination <ref> [1] </ref>. This is surprising, since an important key to the power of a genetic algorithm is the recombination operator [3, 4, 6]. A genetic algorithm without recombination should amount to little more than random search.
Reference: [3] <author> De Jong, K. A. and William M. </author> <title> Spears (1990). An Analysis of the Interacting Roles of Population Size and Crossover in Genetic Algorithms, </title> <booktitle> in the International Workshop Parallel Problem Solving from Nature, </booktitle> <institution> University of Dortmund, </institution> <month> Oct. </month> <pages> 1-3, </pages> <year> 1990. </year>
Reference-contexts: Genetic Programming and Crossover Experiments As mentioned earlier, a genetic algorithm evolves a population of individuals according to some fitness function (environment). Theory indicates that the size of the population is crucial to the performance of the genetic algorithm <ref> [3] </ref>. Small populations generally find good solutions quickly, but are often stuck on local optima. Larger populations are less likely to be caught by local optima, but generally take longer to find good solutions. Another way to view a population is as a source of statistics about the environment. <p> In his experiment with the Walker problem, de Garis reported that a GA without recombination outperformed a GA with recombination [1]. This is surprising, since an important key to the power of a genetic algorithm is the recombination operator <ref> [3, 4, 6] </ref>. A genetic algorithm without recombination should amount to little more than random search. However, after examining the program, we noticed that de Garis ran his GA with an extremely small population (20). <p> This explains de Garis's results. The lack of predictable effectiveness is due to the large variance caused by the poor sampling of a small population size. Crossover requires good sampling information in order to be effective <ref> [3] </ref>. However, despite high variance (note the error bars), when averaged over 10 runs, mutation loses. The results with GAC are similar. _______________ Due to computational limitations, de Garis was only able to make one run [2]. Apparently, crossover is hampered by a small population size (i.e., poor sampling). <p> Discussion and Conclusions The interacting roles of population size and crossover are of extreme interest to the genetic algorithm community. Recent theory indicates that crossover is most effective when the sampling is representative of the space being searched <ref> [3] </ref>. This is achieved in a natural manner by using a larger population. Theory would indicate, then, that recombination is more effective with larger populations. Theory also indicates that uniform crossover is extremely useful in those situations where recombination is important (e.g., when the search space is very large).
Reference: [4] <author> De Jong, K. A. </author> <year> (1975). </year> <title> An Analysis of the Behavior of a Class of Genetic Adaptive Systems, </title> <type> Doctoral dissertation, </type> <institution> Dept. Computer and Communication Sciences, University of Michigan, </institution> <address> Ann Arbor. </address>
Reference-contexts: In his experiment with the Walker problem, de Garis reported that a GA without recombination outperformed a GA with recombination [1]. This is surprising, since an important key to the power of a genetic algorithm is the recombination operator <ref> [3, 4, 6] </ref>. A genetic algorithm without recombination should amount to little more than random search. However, after examining the program, we noticed that de Garis ran his GA with an extremely small population (20).
Reference: [5] <author> Grefenstette, J. </author> <year> (1990). </year> <title> Conditions for Implicit Parallelism, </title> <booktitle> Proceedings of the Foundations of Genetic Algorithms Workshop, </booktitle> <address> Bloomington, Indiana, </address> <year> 1990. </year>
Reference-contexts: This indicates a generality to the observations that could not be assumed otherwise. Recent theory has addressed this issue and indicates that GAs are robust with respect to many implementation details <ref> [5] </ref>. This report provides some confirmation of this theory.
Reference: [6] <author> Holland, John H. </author> <year> (1975). </year> <title> Adaptation in Natural and Artificial Systems, </title> <publisher> The University of Michigan Press. </publisher>
Reference-contexts: During this process, genetic operators create new (child) individuals from highly fit old (parent) individuals. Recombination (also referred to as crossover in this report) is one of the genetic operators and is a key to the power of the genetic algorithm <ref> [6] </ref>. In his studies of genetic programming, though, de Garis reports that a genetic algorithm without recombination outperforms a genetic algorithm with recombination. These results motivated us to re-examine genetic programming for two reasons. First, from a theoretical standpoint, we sought to explain what appear to be anomalous findings. <p> Second, from a practical standpoint, we wished to use recombination (as theory suggests) to improve de Garis's results, allowing better behaviour to be learned in less time. 2. Genetic Algorithms The book "Adaptation in Natural and Artificial Systems" <ref> [6] </ref>, lays the groundwork for GAs. A genetic algorithm consists of a population of individuals that reproduce (over many generations) according to their fitness in an environment. Those individuals that are most fit are most likely to survive, mate, and bear children. <p> In his experiment with the Walker problem, de Garis reported that a GA without recombination outperformed a GA with recombination [1]. This is surprising, since an important key to the power of a genetic algorithm is the recombination operator <ref> [3, 4, 6] </ref>. A genetic algorithm without recombination should amount to little more than random search. However, after examining the program, we noticed that de Garis ran his GA with an extremely small population (20). <p> Assuming this hypothesis to be true, we felt that we should be able to explain the reported results. Further - more, we felt that a larger population size would produce a more accurate sampling of the space, allowing recombination to perform as theory indicates <ref> [6] </ref>. From a practical standpoint, this should improve the efficiency of the GA search, resulting in improved performance. To test our hypothesis, we ran two experiments. In an attempt to explain the results reported by de Garis, the first was run with a population of size 20.
Reference: [7] <author> McClelland, James L. and David E. </author> <title> Rumelhart (1988). Explorations in Parallel Distributed Processing, </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference-contexts: Also required is a fitness function that indicates how well a neural network is performing a desired behaviour. These issues are addressed in the next section. 3. Neural Networks and Genetic Programming The class of neural networks (NNs) is a subclass of parallel distributed processing (PDP) models <ref> [7] </ref>. PDP models assume that information processing is a result of interactions between simpler processing elements (e.g., neurons). In genetic programming, the number of neurons is set by the user. This number depends on the behaviour to be learned. <p> The net input to each neuron (propagation rule) is simply the sum of the products of its inputs and their weights. Finally, the output of each neuron is simply its activation, and the activation rule uses the traditional sigmoid function <ref> [7] </ref>. Each genetic programming neural network (called a GenNet by de Garis) consists of a set of input neurons, output neurons, and optional hidden neurons. Input neurons are neurons that receive information from the environment. Output neurons provide actions that affect the environment.
Reference: [8] <author> Spears, William M. and K. A. </author> <title> De Jong (1991). On the Virtues of Uniform Crossover, </title> <booktitle> to appear in the 4th International Conference on Genetic Algorithms, </booktitle> <address> La Jolla, California, </address> <month> July </month> <year> 1991. </year>
Reference-contexts: It simply considers each bit position of the two parents, and swaps the two bits with a probability of 50%. Suppose the first, third, fourth, and ninth bits positions (of the original parents) are swapped. Then the chil dren are: Child 1: 1000101000 Child 2: 1010010010 Spears <ref> [8] </ref> has analyzed the effects of crossover on genetic algorithm performance. In this study it is shown that (with large search spaces) a GA using uniform crossover outperforms a GA using one point crossover, which in turn outperforms a GA using two point crossover. <p> A single experiment compared a GA with and without recombination. The mutation operator was always used, and was the only genetic operator used when the GA did not use recombination. There is one graph for each experiment. Each graph shows four curves, one for a GA without _______________ Spears <ref> [8] </ref> considers uniform crossover with probabilities other than 50%. recombination, and one for a GA with each of the three forms of crossover defined above. The horizontal axis of each graph is a measure of the amount of work done by the GA.
References-found: 7

