URL: http://cslu.cse.ogi.edu/people/hosom/pubs/Ivtta-Etwr98.ps
Refering-URL: http://cslu.cse.ogi.edu/people/hosom/
Root-URL: http://www.cse.ogi.edu
Email: email: cosi@csrf.pd.cnr.it  email: mailto:-hosom,johans,sutton,cole-@cse.ogi.edu  
Title: Connected Digit Recognition Experiments with the OGI Toolkit's Neural Network and HMM-Based Recognizers **Center for
Author: Piero Cosi*, John-Paul Hosom**, Johan Shalkwyk**, Stephen Sutton**, and Ronald A. Cole** 
Web: www: http://www.csrf.pd.cnr.it  www: http://www.cse.ogi.edu/CSLU/  
Address: Via G. Anghinoni, 10 35121 Padova (ITALY),  P.O. Box 91000, Portland Oregon 97291-1000 USA  
Affiliation: *Institute of Phonetics C.N.R.  Oregon Graduate Institute of Science and Technology (OGI)  
Abstract: This paper describes a series of experiments that compare different approaches to training a speaker-independent continuous-speech digit recognizer using the CSLU Toolkit. Comparisons are made between the Hidden Markov Model (HMM) and Neural Network (NN) approaches. In addition, a description of the CSLU Toolkit research environment is given. The CSLU Toolkit is a research and development software environment that provides a powerful and flexible tool for creating and using spoken language systems for telephone and PC applications. In particular, the CSLU-HMM, the CSLU-NN, and the CSLU-FBNN development environments, with which our experiments were implemented, will be described in detail and recognition results will be compared. Our speech corpus is OGI 30K-Numbers, which is a collection of spontaneous ordinal and cardinal numbers, continuous digit strings and isolated digit strings. The utterances were recorded by having a large number of people recite their ZIP code, street address, or other numeric information over the telephone. This corpus represents a very noisy and difficult recognition task. Our best results (98% word recognition, 92% sentence recognition), obtained with the FBNN architecture, suggest the effectiveness of the CSLU Toolkit in building real-life speech recognition systems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Fanty, J. Pochmara and R.A. Cole, </author> <title> An Interactive Environment for Speech Recognition Research, </title> <booktitle> Proc. of ICSLP-92, </booktitle> <address> Banff, Alberta, </address> <month> October </month> <year> 1992, </year> <month> pp.1543-1546. </month>
Reference-contexts: The result of this effort is the CSLU Toolkit, an integrated set of software and documentation that represents the state of the art in tools for research, development, and learning about spoken language systems <ref> [1] </ref>. The CSLU Toolkit is freely available for noncommercial use and may be downloaded from http://cslu.cse.ogi.edu/toolkit. Usually, the development of spoken language systems is a lengthy and expensive process requiring months or even years to design, test, and deploy systems for useful applications. <p> 0.000 0.000 0.000 0.000 0.500 0.500 0.000 0.000 0.000 0.000 0.000 0.000 prototype onestate numstate 4 mixtures 3 transp 0.000 0.500 0.500 0.000 0.000 0.000 define mono &lt;z&gt; &lt;ih&gt; &lt;r&gt; &lt;ow&gt; &lt;w&gt; &lt;ah&gt; &lt;n&gt; &lt;t&gt; &lt;uw&gt; &lt;th&gt; &lt;iy&gt; &lt;f&gt; &lt;aor&gt; &lt;ay&gt; &lt;v&gt; &lt;s&gt; define onestate &lt;sp&gt; tie &lt;sil&gt;.state [2] &lt;sp&gt;.state <ref> [1] </ref> S 0 0.6 0.5 0.6 S 0 0.5 S 2 S 1 Embedded parameter re-estimation, addressing the problem of modeling the interactions between neighboring models (which is not addressed by single model training) is executed, and finally evaluation is performed on the development set.
Reference: [2] <author> R.A. Cole, M. Fanty, M. Noel and T. Lander, </author> <title> Telephone Speech Corpus Development at CSLU Proc. </title> <address> ICSLP-94, Yokohama, Japan, </address> <month> September </month> <year> 1994, </year> <pages> pp. 1815-1818. </pages>
Reference-contexts: In the following sections, a brief description of the Toolkit is given 1 , implementations of a speaker-independent continuous-speech digit recognizer using three different architectures are described, and finally, the recognition results obtained by applying these recognizers to the OGI 30K-Numbers corpus <ref> [2] </ref> are compared. 2. CSLU TOOLKIT The CSLU Toolkit has been developed to support speech-related research and development activities for a wide range of users and uses. <p> CONNECTED DIGIT RECOGNITION EXPERIMENTS For investigating the performance of the CSLU-ASR development environment, three continuous-speech, speaker-independent digit recognizers were trained using each of the three development environments. The recognizers were trained on telephone-band speech using the OGI 30K-Numbers corpus <ref> [2] </ref>, available from http://www.cse.ogi.edu/CSLU/corpora/. The performance of each recognizer was evaluated on a development set and a test set. <p> 1.000 0.000 0.000 0.000 0.000 0.000 0.500 0.500 0.000 0.000 0.000 0.000 0.000 0.000 prototype onestate numstate 4 mixtures 3 transp 0.000 0.500 0.500 0.000 0.000 0.000 define mono &lt;z&gt; &lt;ih&gt; &lt;r&gt; &lt;ow&gt; &lt;w&gt; &lt;ah&gt; &lt;n&gt; &lt;t&gt; &lt;uw&gt; &lt;th&gt; &lt;iy&gt; &lt;f&gt; &lt;aor&gt; &lt;ay&gt; &lt;v&gt; &lt;s&gt; define onestate &lt;sp&gt; tie &lt;sil&gt;.state <ref> [2] </ref> &lt;sp&gt;.state [1] S 0 0.6 0.5 0.6 S 0 0.5 S 2 S 1 Embedded parameter re-estimation, addressing the problem of modeling the interactions between neighboring models (which is not addressed by single model training) is executed, and finally evaluation is performed on the development set.
Reference: [3] <author> J. Schalkwyk, J.H. de Villiers, S. van Vuuren, and P.Vermeulen, Cslush: </author> <title> An Extendible Research Environment, </title> <booktitle> Proc. of Eurospeech 97, </booktitle> <address> Rodhes, </address> <month> September </month> <year> 1997, </year> <pages> pp 689-692. </pages>
Reference-contexts: The architecture of the Toolkit, as shown in Figure 1, has three main components: a set of libraries containing core technology modules specific to speech recognition, speech synthesis and facial animation, an interactive programming shell (CSLUsh <ref> [3] </ref>) and a graphically-based Rapid Application Developer environment (RAD). 2.1 Core Technology Modules The core of the Toolkit consists of a set of modules that implement technology fundamental to all aspects of speech recognition, speech synthesis, and facial animation.
Reference: [4] <author> J.K. Ousterhout, </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addison Wesley, </publisher> <year> 1994. </year>
Reference-contexts: The modules provide a good deal of flexibility since they can be linked directly into a C program or individually loaded into a programming shell as needed. 2.2 CSLUsh: programming shell The main application level of the Toolkit is an interactive Tcl/Tk-based <ref> [4] </ref> programming shell called CSLUsh (pronounced "slush"). CSLUsh incorporates the core technology modules (described in the previous section) with the well-known, freely available and widely ported Tcl/Tk scripting language.
Reference: [5] <author> Y. Yan, M. Fanty and R. Cole, </author> <title> Speech Recognition Using Neural Networks with Forward-Backward Probability Generated Targets Proc. </title> <address> ICASSP-97, Munich, Germany, </address> <month> April </month> <year> 1997, </year> <pages> pp. 3241-3244. </pages>
Reference-contexts: The first environment, CSLU-HMM, is used for developing Hidden Markov Model (HMM) recognizers. The second environment, CSLU-NN, is used to develop neural-network-based (NN) recognizers. The third environment, CSLU-FBNN, is an extension of the CSLU-NN environment that allows training neural-network recognizers with the forward-backward algorithm (FBNN) <ref> [5] </ref>. These three environments are referred to collectively as the CSLU-ASR development environment. They are designed as extensions to the CSLU shell (CSLUsh) and use a wide variety of preexisting modules for distributed computing, speech signal processing, mathematical operations, and various miscellaneous modules to provide a complete recognition development environment. <p> A neural network is used as a state emission probability estimator and the conventional forward-backward algorithm is used for estimating continuous targets for the NN training patterns. The network is not trained on binary target values, but on the probabilities of each category belonging to each frame <ref> [5] </ref>. 4. CONNECTED DIGIT RECOGNITION EXPERIMENTS For investigating the performance of the CSLU-ASR development environment, three continuous-speech, speaker-independent digit recognizers were trained using each of the three development environments. The recognizers were trained on telephone-band speech using the OGI 30K-Numbers corpus [2], available from http://www.cse.ogi.edu/CSLU/corpora/.
Reference: [6] <author> L. Rabiner and B-H Juang, </author> <title> Fundamentals of Speech Recognition, </title> <publisher> Prentice Hall </publisher>
Reference: [7] <author> G.Zavaliagkos, </author> <title> Maximum A Posteriori Adaptation Techniques for Speech Recognition. </title> <type> PhD thesis, </type> <institution> Northeastern University, Boston, Massachusetts, </institution> <month> October </month> <year> 1995. </year>
Reference: [8] <author> C.J.Legetter and P.C.Woodland, </author> <title> Speaker Adaptation of HMM's Using Linear Regression, </title> <type> Tech. Rep. </type> <institution> CUED/F-INGENG/TR.181, Cambridge Results obtained with 16-Gaussian mixtures per state. University Engineering Department, </institution> <address> Cambridge, England, </address> <year> 1994. </year>
Reference: [9] <author> S.J.Young and P.C.Woodland, </author> <title> Tree-based state-tying for high accuracy acoustic modeling, </title> <booktitle> Proc. Human Language Technology Workshop, </booktitle> <pages> pp. 307-312, </pages> <month> March </month> <year> 1994. </year>
Reference: [10] <author> H. Hermansky, </author> <title> Perceptual Linear Predictive (PLP) Analysis of Speech J. </title> <journal> Acoust. Soc. Am., </journal> <volume> Vol. 87, No. 4, </volume> <pages> pp. 1738-1752, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: The broad-context groupings were done based on acoustic-phonetic knowledge. Data Preparation (genfeat.tcl, pickdata.tcl) Model Initialization (hmminit.tcl) Model Training (hmmtrain.tcl) Embedded Training (genmodel.tcl, hmmembed.tcl) Model Selection (hmmsearch.tcl, hmmscore.tcl) Data Preparation (genfeat.tcl, pickdata.tcl) Transcription (hmmscribe.tcl) 4.1.2 Training As a first step in training the neural network, Perceptual Linear Prediction <ref> [10] </ref> (PLP) features (including energy) and Mel-Frequency Cepstrum Coefficients [11] (MFCC) are computed at nonoverlapping 10-msec frames.
Reference: [11] <author> S.B. Davis and P. Mermelstein, </author> <title> "Comparison of Parametric Representations for Monosyllabic Word Recognition in Continuously Spoken Sentences", </title> <journal> IEEE Trans. Acoust.Speech and Signal Processing, </journal> <volume> Vol. ASSP-28, No. 4, </volume> <month> August </month> <year> 1990, </year> <pages> pp. 357-366. </pages>
Reference-contexts: Data Preparation (genfeat.tcl, pickdata.tcl) Model Initialization (hmminit.tcl) Model Training (hmmtrain.tcl) Embedded Training (genmodel.tcl, hmmembed.tcl) Model Selection (hmmsearch.tcl, hmmscore.tcl) Data Preparation (genfeat.tcl, pickdata.tcl) Transcription (hmmscribe.tcl) 4.1.2 Training As a first step in training the neural network, Perceptual Linear Prediction [10] (PLP) features (including energy) and Mel-Frequency Cepstrum Coefficients <ref> [11] </ref> (MFCC) are computed at nonoverlapping 10-msec frames. At each frame, a 130 dimensional vector of PLP+MFCC features is constructed using five surrounding frames; we use 13-PLP+13-MFCC features from frames at -60, - 30, 0, 30, and 60 msec relative to the frame of interest.
References-found: 11

