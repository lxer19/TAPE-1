URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr93/tr93-028.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr93-abstracts.html
Root-URL: http://www.cis.ufl.edu
Title: A DISTRIBUTED, REPLICATED, DATA-BALANCED SEARCH STRUCTURE  
Author: THEODORE JOHNSON ADRIAN COLBROOK 
Address: Gainesville, Fl 32611-2024  Cambridge, MA 02139  
Affiliation: University of Florida, Dept. of CIS  MIT Laboratory for Computer Science  
Abstract: Many concurrent dictionary data structures have been proposed, but usually in the context of shared memory multiprocessors. In this paper, we present an algorithm for a concurrent distributed B-tree that can be implemented on message passing computer systems. Our distributed B-tree (the dB-tree) replicates the interior nodes in order to improve parallelism and reduce message passing. The dB-tree stores some redundant information in its nodes to permit the use of lazy updates to maintain replica coherency. We show how the dB-tree algorithm can be used to build an efficient implementation of a highly parallel, data-balanced distributed dictionary, the dE-tree. Keywords: Concurrent dictionary data structures, Message passing multiprocessor systems, Balanced search trees, B-link trees, Replica coherency. 1. Introduction. We introduce a new balanced search tree algorithm 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Bayer, </author> <title> Symmetric Binary B-trees: Data Structure and Maintenance Algorithms, </title> <journal> Acta Informatica, </journal> <volume> 1 (1972), </volume> <pages> pp. 290-306. </pages>
Reference-contexts: A number of useful computations can be implemented in terms of dictionary abstract data types, including symbol tables, priority queues and pattern matching systems. The B-tree was originally introduced by Bayer <ref> [1] </ref>. The B-tree algorithms for sequential applications were designed to minimize the response time for a single query and the sequential algorithm for a single search operation on a balanced B-tree has logarithmic complexity.
Reference: [2] <author> R. Bayer and M. Schkolnick, </author> <title> Concurrency of operations on B-trees, </title> <journal> Acta Infor-matica, </journal> <volume> 9 (1977), </volume> <pages> pp. 1-21. </pages>
Reference: [3] <author> P. Bernstein, V. Hadzilacos, and N. Goodman, </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Previous Work. Wang and Weihl [45, 49] have proposed that parallel B-trees be stored using Multi-version Memory, a special cache coherence algorithm for linked data structures. Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging <ref> [47, 3] </ref> in transaction systems). Our algorithm permits concurrent updates on replicated nodes (analogous to transition logging [47, 3]). Ellis [12] has proposed algorithms for a distributed hash table. The directories of the table are replicated among several sites, and the data buckets are distributed among several sites. <p> Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging <ref> [47, 3] </ref> in transaction systems). Our algorithm permits concurrent updates on replicated nodes (analogous to transition logging [47, 3]). Ellis [12] has proposed algorithms for a distributed hash table. The directories of the table are replicated among several sites, and the data buckets are distributed among several sites. <p> operations are applied to the data structure, it will eventually evolve into a state such that all replicated copies of the nodes are the same, and their contents are the same as if the set of operations were applied to a single-copy data structure, sequentially in the equivalent serial order <ref> [41, 3] </ref>. Shasha and Goodman [41] describe proof schemas for concurrent search structures (as discussed later).
Reference: [4] <author> A. Biliris, </author> <title> Operation specific locking in B-trees, </title> <booktitle> in Symposiun on the Principles of Database Systems, ACM SIGACT-SIGART-SIGMOD, </booktitle> <year> 1987, </year> <pages> pp. 159-169. </pages>
Reference: [5] <author> R. Bryant and R. Finkel, </author> <title> A stable distributed scheduling algorithm, </title> <booktitle> in Proceedings of the International Conference on Distributed Computing Systems, </booktitle> <year> 1981, </year> <pages> pp. 314-323. </pages>
Reference-contexts: To avoid these problems, information must be propagated reasonably rapidly through the system, but the number of processors that will react quickly to a change in load on a particular processor must be limited. Suitable load propagation mechanisms include probing [6], gradient methods [28], processor pairing <ref> [14, 5] </ref>, drafting algorithms [35] and bidding algorithms [13]. The ultradiffusive algorithms of Lumer and Huberman [29], which uses a hierarchical control structure, are particularly well suited when the number of processors is large. 5. Analysis. The dB-tree algorithm is designed to avoid blocking and permit highly concurrent access.
Reference: [6] <author> C. G. Cassandras, J. F. Kurose, and D. Towsley, </author> <title> Resource contention manage-ment in parallel systems, </title> <institution> radc-tr-89-48, Rome Air Development Center (RADC), </institution> <month> April </month> <year> 1989. </year>
Reference-contexts: To avoid these problems, information must be propagated reasonably rapidly through the system, but the number of processors that will react quickly to a change in load on a particular processor must be limited. Suitable load propagation mechanisms include probing <ref> [6] </ref>, gradient methods [28], processor pairing [14, 5], drafting algorithms [35] and bidding algorithms [13]. The ultradiffusive algorithms of Lumer and Huberman [29], which uses a hierarchical control structure, are particularly well suited when the number of processors is large. 5. Analysis.
Reference: [7] <author> K. Chandy and L. Lamport, </author> <title> Distributed snapshots: Determining global states of distributed systems, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3 (1985), </volume> <pages> pp. 63-75. </pages>
Reference-contexts: While we are recording the nodes in one processor, the state of the nodes might be changing in another. We will use the concept of a consistent snapshot <ref> [7] </ref> to define our global state. The global state corresponds to what we might see if we were to run the snapshot algorithm. If all actions have been completed, and there is a simultaneous global state, then that is the snapshot that we will get.
Reference: [8] <author> A. Colbrook, E. Brewer, C. Dellarocas, and W. Weihl, </author> <title> An algorithm for concurrent search trees, </title> <booktitle> in Proceedings of the 20th International Conference on Parallel Processing, </booktitle> <year> 1991, </year> <pages> pp. </pages> <month> III138-III141. </month>
Reference-contexts: Deitzfelbinger and Meyer auf der Hyde [9] give algorithms for implementing a hash table on a synchronous network. Ranade [38] gives algorithms and performance bounds for implementing a search tree in a synchronous butterfly or mesh network. Colbrook et al. <ref> [8] </ref> have proposed a pipelined distributed B-tree, where each level of the tree is maintained by a different processor. The parallelism that can be obtained from this implementation is limited by the number of levels in the tree, and the distributed tree is not data-balanced.
Reference: [9] <author> M. Dietzfelbinger and F. Meyer auf der Hyde, </author> <title> An optimal parallel dictionary, </title> <booktitle> in Proc. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <year> 1989, </year> <pages> pp. 360-368. </pages>
Reference-contexts: Matsliach and Shmueli [30] propose methods for distributing search structures in a way that has a high space utilization. The authors assume that the index is stored in shared memory, however, and don't address issues of concurrent restructuring. Deitzfelbinger and Meyer auf der Hyde <ref> [9] </ref> give algorithms for implementing a hash table on a synchronous network. Ranade [38] gives algorithms and performance bounds for implementing a search tree in a synchronous butterfly or mesh network.
Reference: [10] <author> K. Donovan, </author> <title> Performance of shared memory in a parallel computer, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 2 (1991), </volume> <pages> pp. 253-256. </pages>
Reference-contexts: The problem with the simple approach is that the processors will not be data-balanced. Even if each insert is equally likely to be directed to each processor, the processor with the most keys will hold considerably more keys than the average <ref> [10] </ref>. Data-balancing is necessary in order to distribute the request load, prevent processors from being required to devote a disproportionate share of their memory resources to the dictionary, and prevent out-of-storage errors when storage is available on other processors.
Reference: [11] <author> C. Ellis, </author> <title> Concurrent search and inserts in 2-3 trees, </title> <journal> Acta Informatica, </journal> <volume> 14 (1980), </volume> <pages> pp. </pages> <month> 63-86. </month> <title> [12] , Distributed data structures: A case study, </title> <journal> IEEE Transactions on Computing, </journal> <volume> C-34 (1985), </volume> <pages> pp. 1178-1185. </pages>
Reference: [13] <author> K. H. et al, </author> <title> A unix-based local computer network with load balancing, </title> <booktitle> IEEE Computer, </booktitle> <year> (1982), </year> <pages> pp. 55-64. </pages>
Reference-contexts: Suitable load propagation mechanisms include probing [6], gradient methods [28], processor pairing [14, 5], drafting algorithms [35] and bidding algorithms <ref> [13] </ref>. The ultradiffusive algorithms of Lumer and Huberman [29], which uses a hierarchical control structure, are particularly well suited when the number of processors is large. 5. Analysis. The dB-tree algorithm is designed to avoid blocking and permit highly concurrent access.
Reference: [14] <author> R. Finkel, M. Solomon, and M. Horowitz, </author> <title> Distributed algorithms for global structuring, </title> <booktitle> in Proceedings of the National Computer Conference, </booktitle> <year> 1979, </year> <pages> pp. 455-460. </pages>
Reference-contexts: To avoid these problems, information must be propagated reasonably rapidly through the system, but the number of processors that will react quickly to a change in load on a particular processor must be limited. Suitable load propagation mechanisms include probing [6], gradient methods [28], processor pairing <ref> [14, 5] </ref>, drafting algorithms [35] and bidding algorithms [13]. The ultradiffusive algorithms of Lumer and Huberman [29], which uses a hierarchical control structure, are particularly well suited when the number of processors is large. 5. Analysis. The dB-tree algorithm is designed to avoid blocking and permit highly concurrent access.
Reference: [15] <author> D. Gifford, </author> <title> Weighted voting for replicated data, </title> <booktitle> in Proceedings of the Seventh Annual ACM Symposium on Operating System Principles, ACM, </booktitle> <year> 1979, </year> <pages> pp. 150-150. </pages>
Reference-contexts: We can achieve the atomic updates by requiring that modifying actions lock every copy of the modified node before performing the update and block all reads and updates on the node, by using one of the well-known algorithms for managing replicated data <ref> [44, 15] </ref>. However, we can maintain our replicated nodes with far less synchronization and overhead. First, observe that it is not necessary to distribute the contents of the node on every modification, it is only necessary to distribute the modification itself.
Reference: [16] <author> K. Gilon and D. Peleg, </author> <title> Compact deterministic distributed dictionaries, </title> <booktitle> in Proceedings of the Tenth Annual ACM Symposium on Principles of Distributed Computing, ACM, </booktitle> <year> 1991, </year> <pages> pp. 81-94. </pages>
Reference-contexts: Yen and Bastani [50] have developed algorithms for implementing a hash table on a SIMD parallel computer, such as a CM2. The authors examine the use of chaining, linear probing, and double hashing to handle bucket overflows. Peleg <ref> [16, 36] </ref> has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. However, the issues of efficiency and concurrent access are not addressed. <p> Ellis' algorithm [12] performs data-balancing whenever a processor runs out of storage. Peleg <ref> [16, 36] </ref> has studied the issue of data-balancing in distributed dictionaries from a complexity point of view, requiring that no processor store more than O (M=N ) keys, where M is the number of keys and N is the number of processors.
Reference: [17] <author> L. Guibas and R. Sedgewick, </author> <title> A dichromatic framework for balanced trees, </title> <booktitle> in Proc. 19th Annual Symposium of Foundations of Computer Science, ACM, </booktitle> <year> 1978, </year> <pages> pp. 8-21. </pages>
Reference-contexts: The second process can then update the node in such a fashion as to cause the first process to lock the wrong node when it eventually acquires the lock. To prevent this kind of process overtaking many algorithms have their operations use lock coupling to block independent operations <ref> [33, 17] </ref>. An operation traverses the tree by obtaining the appropriate lock on the child before releasing the lock it holds on the parent. B-link trees [27, 39, 25] eliminate the need for lock coupling.
Reference: [18] <author> M. Herlihy, </author> <title> A quorum-consensus replication method for abstract data types, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4 (1986), </volume> <pages> pp. 32-53. </pages>
Reference-contexts: Second, the tree is never left in an incorrect state, so that search actions do not need to be blocked. Third, many of the modifying actions commute. Several authors have studied the issue of concurrency control on abstract data types when some operations may commute <ref> [18, 34, 48, 40, 46] </ref>, but in the context of a transaction processing system.
Reference: [19] <author> T. Johnson, </author> <title> The Performance of Concurrent Data Structure Algorithms, </title> <type> PhD thesis, </type> <institution> NYU Dept. of Computer Science, </institution> <year> 1990. </year>
Reference-contexts: This causes data contention as writers block incoming writers and readers, and readers block incoming writers. The contention is severe when it occurs at higher levels in the search tree, particularly at the root (often termed a root bottleneck <ref> [22, 19] </ref>). Similar problems are caused by resource contention. In a shared-memory architecture all of the processes trying to access the same tree node will access the same memory module on the machine. <p> The dB-tree, a Concurrent Distributed B-tree. 2.1. Concurrent B-link tree Algorithms. As a base for our distributed B-tree, we use the concurrent B-link tree [27, 39, 25]. The B-link tree algorithms have been found to have the highest performance among all existing concurrent B-tree algorithms <ref> [22, 19, 43] </ref>. Restructuring operations on B-link trees are performed one node at a time, so that the algorithms can be easily translated to a distributed environment. In a B-link tree, every node contains a pointer to its right neighbor.
Reference: [20] <author> T. Johnson and P. Krishna, </author> <title> Lazy updates in distributed search structures, </title> <booktitle> in SIG-MOD '93, </booktitle> <year> 1993. </year>
Reference-contexts: A lazy action does not need to synchronize with other lazy actions. A semi-synchronous action must synchronize with some, but not all other actions. We classify a synchronous action as one that must be ordered with all other actions, or that requires communication with other nodes. In <ref> [20] </ref>, Johnson and Krishna present a framework for creating and analyzing lazy update algorithms. The framework is used to develop algorithms that can manage a dB-tree node. The algorithm uses lazy insert actions and semi-synchronous half-split actions. <p> We note that a distributed keyset computation is only required to be single copy equivalent in the final state, not in any intermediate state. The issue 19 of single copy equivalence is addressed in <ref> [20] </ref>. A link algorithm is a concurrent data structure that uses linked nodes to allow concurrent actions without locks. If an operation misnavigates due to the action of some other operation, the misnavigated node can recover from the misnavigation by following the link pointers. <p> If the action is routed to a node on the same level as the deleted node, then the action will not be blocked. Further, updates on a node can use non-blocking lazy updates <ref> [20] </ref>, which permit concurrent updates of a node. The performance of the dB-tree depends on many factors.
Reference: [21] <author> T. Johnson and D. Shasha, </author> <title> Utilization of B-trees with inserts, </title> <booktitle> deletes and modifies, in ACM SIGACT/SIGMOD/SIGART Symposium on Principles of Database Systems, </booktitle> <year> 1989, </year> <pages> pp. </pages> <month> 235-246. </month> <title> [22] , A framework for the performance analysis of concurrent B-tree algorithms, </title> <booktitle> in ACM Symp. on Principles of Database Systems, </booktitle> <year> 1990, </year> <pages> pp. 273-287. </pages>
Reference-contexts: If an insert causes a node to become too full, it triggers a half-split action. We allow the implementation to choose the point at which node merges are triggered (for example, merge-at-empty causes little loss in space utilization <ref> [21] </ref>, but greatly simplifies the implementation). 2.3. dB-tree Half-splits and Half-merges. The use of double links requires that splitting a node be carried out in three steps instead of two. The half-split action is shown in Code 6, and is illustrated in Figure 3.
Reference: [23] <author> P. Krishna and T. Johnson, </author> <title> Implementing distributed search structures, </title> <type> Tech. </type> <note> Report UF CIS TR92-032, Availiable at anonymous ftp site cis.ufl.edu, </note> <institution> University of Florida, Dept. of CIS, </institution> <year> 1992. </year>
Reference-contexts: All requests for a link-change on a node are causally related (since they are generated by actions at the neighbor), so a numbering scheme can be used to enforce the ordering <ref> [23] </ref>. link change (local node ! neighbor, boundary value) if the boundary value matches local node's boundary, change the link, obeying the causal ordering acknowledge the link-change Code 9. Link-change action. <p> If P processors store a dE-tree, then at most 2 log (P ) messages must be passed to perform the desired operation. Index restructuring is only required when data balancing is performed, which is relatively rare <ref> [23] </ref>. Thus, the dE-tree is an efficient distributed index in practice. 6. Conclusions. We present a distributed dictionary based on the Blink tree, the dB-tree. The interior nodes of the tree are replicated in order to allow many processors to read the same node and thus increase parallelism.
Reference: [24] <author> Y. Kwong and D. Wood, </author> <title> A new method for concurrency in B-trees, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-8 (1982), </volume> <pages> pp. 211-222. </pages>
Reference: [25] <author> V. Lanin and D. Shasha, </author> <title> A symmetric concurrent B-tree algorithm, </title> <booktitle> in 1986 Fall Joint Computer Conference, </booktitle> <year> 1986, </year> <pages> pp. 380-389. 25 </pages>
Reference-contexts: To prevent this kind of process overtaking many algorithms have their operations use lock coupling to block independent operations [33, 17]. An operation traverses the tree by obtaining the appropriate lock on the child before releasing the lock it holds on the parent. B-link trees <ref> [27, 39, 25] </ref> eliminate the need for lock coupling. If the wrong node is reached at any stage the operation is able to find the correct node. This reduces the number of locks that must be held concurrently and increases throughput. <p> In Section 3 we show how the dE-tree can be built from the dB-tree. Finally, conclusions are drawn in Section 4. 2. The dB-tree, a Concurrent Distributed B-tree. 2.1. Concurrent B-link tree Algorithms. As a base for our distributed B-tree, we use the concurrent B-link tree <ref> [27, 39, 25] </ref>. The B-link tree algorithms have been found to have the highest performance among all existing concurrent B-tree algorithms [22, 19, 43]. Restructuring operations on B-link trees are performed one node at a time, so that the algorithms can be easily translated to a distributed environment. <p> Fig. 1. Half-split operation The B-link tree in a shared memory multiprocessor does not easily support the deletion of nodes. Lehman and Yao [27] recommend that nodes are never deleted. Sagiv [39] describes garbage collection algorithms for under-full nodes. Lanin and Shasha <ref> [25] </ref>, and Wang [45] describe an algorithm that leaves stubs in place of deleted nodes. We show how nodes can safely be removed from the tree due to the explicit naming of shared nodes. 2.2. The dB-tree. Our distributed B-tree algorithm builds on the concurrent B-link algorithms.
Reference: [26] <author> G. Lausen, </author> <title> Integrated concurrency control in shared B-trees, </title> <journal> Computing, </journal> <volume> 33 (1984), </volume> <pages> pp. 13-26. </pages>
Reference: [27] <author> P. Lehman and S. Yao, </author> <title> Efficient locking for concurrent operations on B-trees, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 6 (1981), </volume> <pages> pp. 650-670. </pages>
Reference-contexts: 1. Introduction. We introduce a new balanced search tree algorithm for distributed memory architectures. The search tree uses the B-link tree <ref> [27] </ref> as a base, and distributes ownership of the nodes among the processors that maintain the tree. We also replicate the non-leaf nodes, to improve parallelism. <p> To prevent this kind of process overtaking many algorithms have their operations use lock coupling to block independent operations [33, 17]. An operation traverses the tree by obtaining the appropriate lock on the child before releasing the lock it holds on the parent. B-link trees <ref> [27, 39, 25] </ref> eliminate the need for lock coupling. If the wrong node is reached at any stage the operation is able to find the correct node. This reduces the number of locks that must be held concurrently and increases throughput. <p> In Section 3 we show how the dE-tree can be built from the dB-tree. Finally, conclusions are drawn in Section 4. 2. The dB-tree, a Concurrent Distributed B-tree. 2.1. Concurrent B-link tree Algorithms. As a base for our distributed B-tree, we use the concurrent B-link tree <ref> [27, 39, 25] </ref>. The B-link tree algorithms have been found to have the highest performance among all existing concurrent B-tree algorithms [22, 19, 43]. Restructuring operations on B-link trees are performed one node at a time, so that the algorithms can be easily translated to a distributed environment. <p> Operations can still reach the sibling because of the right pointers and highest field. Fig. 1. Half-split operation The B-link tree in a shared memory multiprocessor does not easily support the deletion of nodes. Lehman and Yao <ref> [27] </ref> recommend that nodes are never deleted. Sagiv [39] describes garbage collection algorithms for under-full nodes. Lanin and Shasha [25], and Wang [45] describe an algorithm that leaves stubs in place of deleted nodes.
Reference: [28] <author> F. Lin and R. Keller, </author> <title> The gradient model load balancing method, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13 (1987), </volume> <pages> pp. 32-38. </pages>
Reference-contexts: To avoid these problems, information must be propagated reasonably rapidly through the system, but the number of processors that will react quickly to a change in load on a particular processor must be limited. Suitable load propagation mechanisms include probing [6], gradient methods <ref> [28] </ref>, processor pairing [14, 5], drafting algorithms [35] and bidding algorithms [13]. The ultradiffusive algorithms of Lumer and Huberman [29], which uses a hierarchical control structure, are particularly well suited when the number of processors is large. 5. Analysis.
Reference: [29] <author> E. Lumer and B. Huberman, </author> <title> Dynamics of resource allocation in distributed systems, </title> <note> preprint (submitted to ieee transactions on smc), </note> <institution> Xerox Palo Alto Research Center, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: Suitable load propagation mechanisms include probing [6], gradient methods [28], processor pairing [14, 5], drafting algorithms [35] and bidding algorithms [13]. The ultradiffusive algorithms of Lumer and Huberman <ref> [29] </ref>, which uses a hierarchical control structure, are particularly well suited when the number of processors is large. 5. Analysis. The dB-tree algorithm is designed to avoid blocking and permit highly concurrent access.
Reference: [30] <author> G. Matsliach and O. Shmueli, </author> <title> An efficient method for distributing search structures, </title> <booktitle> in Symposium on Parallel and Distributed Information Systems, </booktitle> <year> 1991, </year> <pages> pp. 159-166. </pages>
Reference-contexts: Peleg [16, 36] has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. However, the issues of efficiency and concurrent access are not addressed. Matsliach and Shmueli <ref> [30] </ref> propose methods for distributing search structures in a way that has a high space utilization. The authors assume that the index is stored in shared memory, however, and don't address issues of concurrent restructuring.
Reference: [31] <author> R. Miller, </author> <title> Multiple access to B-trees, </title> <booktitle> in Proceedings of the 1978 Conference on Information Sciences and Systems, </booktitle> <institution> Johns Hopkins University, Baltimore, MD, </institution> <year> 1978, </year> <pages> pp. 400-408. </pages>
Reference: [32] <author> C. Mohan and F. Levine, ARIES/IM: </author> <title> An efficient and high concurrency index management method using write-ahead logging, </title> <type> Research Report RJ 6864, </type> <institution> IBM, </institution> <year> 1989. </year>
Reference: [33] <author> Y. Mond and Y. Raz, </author> <title> Concurrency control in B + -trees databases using preparatory operations, </title> <booktitle> in 11th International Conference on Very Large Databases, </booktitle> <address> Stock-holm, </address> <month> Aug. </month> <year> 1985, </year> <pages> pp. 331-334. </pages>
Reference-contexts: The second process can then update the node in such a fashion as to cause the first process to lock the wrong node when it eventually acquires the lock. To prevent this kind of process overtaking many algorithms have their operations use lock coupling to block independent operations <ref> [33, 17] </ref>. An operation traverses the tree by obtaining the appropriate lock on the child before releasing the lock it holds on the parent. B-link trees [27, 39, 25] eliminate the need for lock coupling.
Reference: [34] <author> T. Ng, </author> <title> Using histories to implement atomic objects, </title> <journal> ACM Transactions of Computer Systems, </journal> <volume> 7 (1989), </volume> <pages> pp. 360-393. </pages>
Reference-contexts: Second, the tree is never left in an incorrect state, so that search actions do not need to be blocked. Third, many of the modifying actions commute. Several authors have studied the issue of concurrency control on abstract data types when some operations may commute <ref> [18, 34, 48, 40, 46] </ref>, but in the context of a transaction processing system.
Reference: [35] <author> L. Ni, C. Xu, and T. Genfreau, </author> <title> A distributed drafting algorithm for load balancing, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11 (1985), </volume> <pages> pp. 32-38. </pages>
Reference-contexts: Suitable load propagation mechanisms include probing [6], gradient methods [28], processor pairing [14, 5], drafting algorithms <ref> [35] </ref> and bidding algorithms [13]. The ultradiffusive algorithms of Lumer and Huberman [29], which uses a hierarchical control structure, are particularly well suited when the number of processors is large. 5. Analysis. The dB-tree algorithm is designed to avoid blocking and permit highly concurrent access.
Reference: [36] <author> D. Peleg, </author> <title> Distributed data structures: A complexity oriented view, </title> <booktitle> in Fourth Int'l Workshop on Distributed Algorithms, </booktitle> <address> Bari, Italy, </address> <year> 1990, </year> <pages> pp. 71-89. </pages>
Reference-contexts: Yen and Bastani [50] have developed algorithms for implementing a hash table on a SIMD parallel computer, such as a CM2. The authors examine the use of chaining, linear probing, and double hashing to handle bucket overflows. Peleg <ref> [16, 36] </ref> has proposed several structures for implementing a distributed dictionary. The concern of these papers is the message complexity of access and data balancing. However, the issues of efficiency and concurrent access are not addressed. <p> Ellis' algorithm [12] performs data-balancing whenever a processor runs out of storage. Peleg <ref> [16, 36] </ref> has studied the issue of data-balancing in distributed dictionaries from a complexity point of view, requiring that no processor store more than O (M=N ) keys, where M is the number of keys and N is the number of processors.
Reference: [37] <author> M. Quinn, </author> <title> Designing Efficient Algorithms for Parallel Computers, </title> <publisher> McGraw-Hill, 19787. </publisher>
Reference-contexts: The improvement in the response time that may be achieved by a parallel algorithm for a single search can at best be logarithmic in the number of processors used <ref> [37] </ref>. Therefore, for parallel systems a more important concern is increasing system throughput for a series of search, insertion and deletion operations executing in parallel.
Reference: [38] <author> A. Ranade, </author> <title> Maintaining dynamic ordered sets on processor networks, </title> <booktitle> in Proc. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <year> 1992, </year> <pages> pp. 127-137. </pages>
Reference-contexts: The authors assume that the index is stored in shared memory, however, and don't address issues of concurrent restructuring. Deitzfelbinger and Meyer auf der Hyde [9] give algorithms for implementing a hash table on a synchronous network. Ranade <ref> [38] </ref> gives algorithms and performance bounds for implementing a search tree in a synchronous butterfly or mesh network. Colbrook et al. [8] have proposed a pipelined distributed B-tree, where each level of the tree is maintained by a different processor. <p> Since a processor stores the nodes on the path from the root to a leaf, each processor stores between O (log (P )) and O (P log (P )) internal nodes. Ranade <ref> [38] </ref> gives algorithms for storing a search tree on a synchronous mesh or butterfly network that require O (1) storage overhead per key.
Reference: [39] <author> Y. Sagiv, </author> <title> Concurrent Operations on B-Trees with Overtaking, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 33 (1986), </volume> <pages> pp. 275-296. </pages>
Reference-contexts: To prevent this kind of process overtaking many algorithms have their operations use lock coupling to block independent operations [33, 17]. An operation traverses the tree by obtaining the appropriate lock on the child before releasing the lock it holds on the parent. B-link trees <ref> [27, 39, 25] </ref> eliminate the need for lock coupling. If the wrong node is reached at any stage the operation is able to find the correct node. This reduces the number of locks that must be held concurrently and increases throughput. <p> In Section 3 we show how the dE-tree can be built from the dB-tree. Finally, conclusions are drawn in Section 4. 2. The dB-tree, a Concurrent Distributed B-tree. 2.1. Concurrent B-link tree Algorithms. As a base for our distributed B-tree, we use the concurrent B-link tree <ref> [27, 39, 25] </ref>. The B-link tree algorithms have been found to have the highest performance among all existing concurrent B-tree algorithms [22, 19, 43]. Restructuring operations on B-link trees are performed one node at a time, so that the algorithms can be easily translated to a distributed environment. <p> The B-link tree algorithms use the additional information stored in the nodes to let an operation recover if it misnavigates in the tree due to out-of-date 4 information. The template for the concurrent B-link tree algorithm described by Sa-giv <ref> [39] </ref> is shown as Code 1. Search operations start by placing an R (read) lock on the root and then searching the root to determine the next node to access. The search operation then unlocks the root and places an R lock on the next node. <p> Operations can still reach the sibling because of the right pointers and highest field. Fig. 1. Half-split operation The B-link tree in a shared memory multiprocessor does not easily support the deletion of nodes. Lehman and Yao [27] recommend that nodes are never deleted. Sagiv <ref> [39] </ref> describes garbage collection algorithms for under-full nodes. Lanin and Shasha [25], and Wang [45] describe an algorithm that leaves stubs in place of deleted nodes. We show how nodes can safely be removed from the tree due to the explicit naming of shared nodes. 2.2. The dB-tree. <p> Node-search action. A node search action is used as the basic mechanism for ensuring that an action is performed on the correct node (as in the case of Sagiv's algorithm <ref> [39] </ref>). Thus, node search is written so that it can deliver an action to a non-leaf node.
Reference: [40] <author> P. Schwartz and A. Spector, </author> <title> Synchronizing abstract data types, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2 (1894), </volume> <pages> pp. 223-250. </pages>
Reference-contexts: Second, the tree is never left in an incorrect state, so that search actions do not need to be blocked. Third, many of the modifying actions commute. Several authors have studied the issue of concurrency control on abstract data types when some operations may commute <ref> [18, 34, 48, 40, 46] </ref>, but in the context of a transaction processing system.
Reference: [41] <author> D. Shasha and N. Goodman, </author> <title> Concurrent search structure algorithms, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 13 (1988), </volume> <pages> pp. 53-90. </pages>
Reference-contexts: operations are applied to the data structure, it will eventually evolve into a state such that all replicated copies of the nodes are the same, and their contents are the same as if the set of operations were applied to a single-copy data structure, sequentially in the equivalent serial order <ref> [41, 3] </ref>. Shasha and Goodman [41] describe proof schemas for concurrent search structures (as discussed later). <p> Shasha and Goodman <ref> [41] </ref> describe proof schemas for concurrent search structures (as discussed later). <p> In addition, the algorithm framework accounts for ordered actions, to require that classes of actions are performed on a node in the order in which they are generated. For example, the link-change actions are ordered. 3. Correctness of the Operations. Shasha and Goodman <ref> [41] </ref> provide a framework for proving the correctness of non-replicated concurrent data structures. We make extensive use of their framework in order to discuss operation correctness. An abstract data type consists of a data structure, D, and a set of operations on the data structure. <p> For example, an insert operation adds its key to the search structure state. The first issue that we need to address is the meaning of the state of the search structure. The work that we base this section on <ref> [41] </ref> assumed that the search structure state is globally observable an assumption that applies in the context of a multiprogrammed uniprocessor or a tightly coupled parallel processor. We are interested search structures in an asynchronous distributed system, in which a global time does not exist.
Reference: [42] <author> D. Shasha, V. Lanin, and J. Schmidt, </author> <title> An analytical model for the performance of concurrent B-tree algorithms, NYU Ultracomputer Note 311, </title> <institution> NYU Ultracom-puter lab, </institution> <year> 1987. </year>
Reference-contexts: All concurrent search tree algorithms share the problem of managing contention. Concurrency control is required to ensure that two or more independent processes accessing a B-tree do not interfere with each other. 2 A common approach is to associate a read/write lock with every node in the search tree <ref> [42] </ref>. This causes data contention as writers block incoming writers and readers, and readers block incoming writers. The contention is severe when it occurs at higher levels in the search tree, particularly at the root (often termed a root bottleneck [22, 19]). Similar problems are caused by resource contention.
Reference: [43] <author> V. Srinivasan and M. Carey, </author> <title> Performance of B-tree concurrency control algorithms, </title> <type> Tech. Report Computer Sciences Technical Report 999, </type> <institution> University of Wisconson-Madison, </institution> <year> 1991. </year>
Reference-contexts: The dB-tree, a Concurrent Distributed B-tree. 2.1. Concurrent B-link tree Algorithms. As a base for our distributed B-tree, we use the concurrent B-link tree [27, 39, 25]. The B-link tree algorithms have been found to have the highest performance among all existing concurrent B-tree algorithms <ref> [22, 19, 43] </ref>. Restructuring operations on B-link trees are performed one node at a time, so that the algorithms can be easily translated to a distributed environment. In a B-link tree, every node contains a pointer to its right neighbor.
Reference: [44] <author> R. H. Thomas, </author> <title> A majority consensus approach to concurrency control for multiple copy databases, </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 4 (1979), </volume> <pages> pp. 180-209. </pages>
Reference-contexts: The search tree uses the B-link tree [27] as a base, and distributes ownership of the nodes among the processors that maintain the tree. We also replicate the non-leaf nodes, to improve parallelism. If we apply a read-one, write-all consistency maintenance rule <ref> [44] </ref>, then reading a node becomes cheaper and writing to a node becomes more expensive as we increase the degree of replication. <p> We can achieve the atomic updates by requiring that modifying actions lock every copy of the modified node before performing the update and block all reads and updates on the node, by using one of the well-known algorithms for managing replicated data <ref> [44, 15] </ref>. However, we can maintain our replicated nodes with far less synchronization and overhead. First, observe that it is not necessary to distribute the contents of the node on every modification, it is only necessary to distribute the modification itself.
Reference: [45] <author> P. Wang, </author> <title> An in-depth analysis of concurrent b-tree algorithms, </title> <type> Tech. Report MIT/LCS/TR-496, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1991. </year>
Reference-contexts: Similarly, for message-passing architectures, the processor on which a node resides will receive messages from every processor trying to access the node. Resource contention is again most serious for the higher levels in the search tree. Node replication <ref> [45] </ref> reduces contention but requires a coherence protocol to maintain consistency. The redundant information stored in dB-tree nodes allows the use of lazy update algorithms to maintain consistency. Associated with the contention issue is the problem of process overtaking. <p> If the wrong node is reached at any stage the operation is able to find the correct node. This reduces the number of locks that must be held concurrently and increases throughput. We use the B-link tree as a base for the dB-tree. 1.2. Previous Work. Wang and Weihl <ref> [45, 49] </ref> have proposed that parallel B-trees be stored using Multi-version Memory, a special cache coherence algorithm for linked data structures. Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging [47, 3] in transaction systems). <p> Fig. 1. Half-split operation The B-link tree in a shared memory multiprocessor does not easily support the deletion of nodes. Lehman and Yao [27] recommend that nodes are never deleted. Sagiv [39] describes garbage collection algorithms for under-full nodes. Lanin and Shasha [25], and Wang <ref> [45] </ref> describe an algorithm that leaves stubs in place of deleted nodes. We show how nodes can safely be removed from the tree due to the explicit naming of shared nodes. 2.2. The dB-tree. Our distributed B-tree algorithm builds on the concurrent B-link algorithms.
Reference: [46] <author> W. Weihl, </author> <title> Commutivity-based concurrency control for abstract data types, </title> <journal> IEEE Trans. Computers, </journal> <volume> 37 (1988), </volume> <pages> pp. </pages> <month> 1488-1505. </month> <title> [47] , The impact or recovery on concurrency control, </title> <type> Tech. Report MIT/LCS/TM-382b, </type> <institution> MIT Laboratory for Computer Science, </institution> <year> 1989. </year> <month> 26 </month>
Reference-contexts: Second, the tree is never left in an incorrect state, so that search actions do not need to be blocked. Third, many of the modifying actions commute. Several authors have studied the issue of concurrency control on abstract data types when some operations may commute <ref> [18, 34, 48, 40, 46] </ref>, but in the context of a transaction processing system.
Reference: [48] <author> W. Weihl and B. Liskov, </author> <title> Implementation of resilient, atomic data objects, </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7 (1985), </volume> <pages> pp. 244-269. </pages>
Reference-contexts: Second, the tree is never left in an incorrect state, so that search actions do not need to be blocked. Third, many of the modifying actions commute. Several authors have studied the issue of concurrency control on abstract data types when some operations may commute <ref> [18, 34, 48, 40, 46] </ref>, but in the context of a transaction processing system.
Reference: [49] <author> W. Weihl and P. Wang, </author> <title> Multi-version memory: Software cache management for concurrent B-trees, </title> <booktitle> in Proc. 2nd IEEE Symp. Parallel and Distributed Processing, </booktitle> <year> 1990, </year> <pages> pp. 650-655. </pages>
Reference-contexts: If the wrong node is reached at any stage the operation is able to find the correct node. This reduces the number of locks that must be held concurrently and increases throughput. We use the B-link tree as a base for the dB-tree. 1.2. Previous Work. Wang and Weihl <ref> [45, 49] </ref> have proposed that parallel B-trees be stored using Multi-version Memory, a special cache coherence algorithm for linked data structures. Multi-version Memory permits only a single update to occur on a replicated node at any point in time (analogous to value logging [47, 3] in transaction systems).
Reference: [50] <author> I. Yen and F. Bastani, </author> <title> Hash tables in massively parallel systems, </title> <booktitle> in Int'l Parallel Processing Symposium, </booktitle> <year> 1992, </year> <pages> pp. 660-664. 27 </pages>
Reference-contexts: The distribution of updates can be limited in a 3 distributed B-tree because it is a multilevel index structure. Also, the B-link tree is a very flexible data structure in which more sophisticated operations, such as range queries, can be easily implemented. Yen and Bastani <ref> [50] </ref> have developed algorithms for implementing a hash table on a SIMD parallel computer, such as a CM2. The authors examine the use of chaining, linear probing, and double hashing to handle bucket overflows. Peleg [16, 36] has proposed several structures for implementing a distributed dictionary.
References-found: 47

