URL: http://www.cs.columbia.edu/~thayer/cs-misc-info/tech-reports/ps-files-box/cucs-017-96.ps
Refering-URL: http://www.cs.columbia.edu/~thayer/cs-misc-info/tech-reports/ps-files-box/
Root-URL: http://www.cs.columbia.edu
Title: Concurrency-Oriented Optimization for Low-Power Asynchronous Systems  
Author: Luis A. Plana Steven M. Nowick 
Keyword: Asynchronous Design, Data Hazards, Handshaking, Hazards, Latches, Low Power, Sequencers, Voltage Scaling.  
Note: This is an expanded version of a paper by the same name, appearing in the 1996 International Sym posium on Low Power Electronics and Design [19]. This author was supported by grants from CONICIT and UNEXPO, Venezuela. This author is supported by an NSF CAREER Award MIP-9501880 and by an Alfred P. Sloan Research Fellowship.  
Date: October 1996  
Address: New York, NY 10027  
Affiliation: Department of Computer Science Columbia University  
Pubnum: CUCS-017-96  
Abstract: We introduce new architectural optimizations for asynchronous systems. These optimizations allow application of voltage scaling, to reduce power consumption while maintaining system throughput. In particular, three new asynchronous sequencer designs are introduced, which increase the concurrent activity of the system. We show that existing datapaths will not work correctly at the increased level of concurrency. To insure correct operation, modified latch and multiplexer designs are presented, for both dual-rail and single-rail implementations. The increased concurrency allows the opportunity for substantial system-wide power savings through application of voltage scaling. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bailey and M. Josephs. </author> <title> Sequencer circuits for VLSI programming. </title> <booktitle> In Proc. Working Conf. on Asynchronous Design Methodologies, </booktitle> <pages> pages 82-90. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1995. </year>
Reference-contexts: Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank [14], DCC error corrector [24]. Active research is done in sequencer control also <ref> [22, 25, 1] </ref>. The focus of this paper is on sequential computation. The optimizations introduced in this paper improve the throughput of an asynchronous sequential system by increasing the amount of concurrent activity. A key control element, that has a large impact on concurrency, is the sequencer. <p> Such sequences can be very long. For example, Bailey <ref> [1] </ref> reports that the longest sequence in the asynchronous error decoder circuit for a DCC player [24] consists of 48 processes. Two common operation protocols are used in asynchronous sequencers: sequential and concurrent. * Sequential Protocol. <p> In [10], Martin presents two N-way sequencers. The Tangram N-way sequencer corresponds exactly to a Q-element-based Martin sequencer and it has comparable performance. A D-element based sequencer provides no overall performance improvement. * Josephs/Bailey Counter-Decoder Sequencer. In <ref> [1] </ref>, Bailey and Josephs introduced a centralized sequencer, based in a counter-decoder architecture. The counter centralizes the state of the sequencer, and the decoder distributes the signals to the processes. The circuit is speed-independent and it is currently used in several designs. <p> The implementation has improved initial and inter-process latencies compared to the Tangram tree sequencer. Minor problems are that the circuit is not modular and is designed to work with an even number of processes. * Josephs/Bailey Chain Sequencer. Bailey and Josephs <ref> [1] </ref> also introduced a distributed sequencer built as a linear chain of n modules, each controlling a process. The modules assume fundamental-mode operation [23]. In fundamental mode, no new inputs 9 can arrive until the component has stabilized from a previous input change.
Reference: [2] <author> E. Brunvand. </author> <title> Translating Concurrent Communicating Programs into Asynchronous Circuits. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon University, </institution> <year> 1991. </year>
Reference-contexts: Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently <ref> [21, 10, 2, 16, 28, 15, 25] </ref>. Several methods build asynchronous circuits as networks of communicating modules. Every module is mapped to a circuit element in a library of self-timed modules. Such systems are macromodular , since they are constructed by combining modules into a working system. <p> This type of asynchronous circuit is designed as a network of predefined data and control modules <ref> [2] </ref>. Instead of a global clock signal, communication channels between modules use handshaking to synchronize their operation and data interchange. 2.2.1 Control Signaling Control signaling usually follows a 4-phase handshake protocol [20], which is implemented using request and acknowledge signals. Figure 1 shows two macromodules that communicate with each other.
Reference: [3] <author> A. P. Chandrakasan, M. Potkonjak, R. Mehra, J. Rabaey, and R. W. Brodersen. </author> <title> Optimizing power using transformations. </title> <journal> IEEE Trans. on Computer-Aided Design, </journal> <volume> 14(1) </volume> <pages> 12-31, </pages> <month> January </month> <year> 1995. </year>
Reference-contexts: A wide range of techniques is used to reduce circuit power consumption. These techniques approach low-power operation at different levels of synthesis, including IC technology optimization, low-power circuit design, architecture or structural optimizations, algorithm level optimization and system-wide low power techniques <ref> [4, 3, 13] </ref>. Chandrakasan et al. [4] show that concurrency is a key to architecture-driven optimizations for low-power operation. The increased throughput obtained through concurrent operation allows the reduction of the power supply voltage, i.e., voltage scaling [4, 13, 24]. <p> Unfortunately, voltage scaling has the undesirable effect of reducing the speed of the circuit. Several techniques are used to compensate for this performance penalty. In particular, architecture-driven voltage scaling <ref> [4, 3] </ref> combines architectural optimizations |to increase the concurrent activity and the throughput of the system| with voltage scaling, to reduce the power consumption without affecting the throughput. Our goal is therefore to increase the concurrency, and hence the throughput, of a system.
Reference: [4] <author> A. P. Chandrakasan, S. Sheng, and R. W. Brodersen. </author> <title> Low-power CMOS digital design. </title> <journal> IEEE J. of Solid-State Circuits, </journal> <volume> 27(4) </volume> <pages> 473-484, </pages> <month> April </month> <year> 1992. </year> <month> 32 </month>
Reference-contexts: A wide range of techniques is used to reduce circuit power consumption. These techniques approach low-power operation at different levels of synthesis, including IC technology optimization, low-power circuit design, architecture or structural optimizations, algorithm level optimization and system-wide low power techniques <ref> [4, 3, 13] </ref>. Chandrakasan et al. [4] show that concurrency is a key to architecture-driven optimizations for low-power operation. The increased throughput obtained through concurrent operation allows the reduction of the power supply voltage, i.e., voltage scaling [4, 13, 24]. <p> A wide range of techniques is used to reduce circuit power consumption. These techniques approach low-power operation at different levels of synthesis, including IC technology optimization, low-power circuit design, architecture or structural optimizations, algorithm level optimization and system-wide low power techniques [4, 3, 13]. Chandrakasan et al. <ref> [4] </ref> show that concurrency is a key to architecture-driven optimizations for low-power operation. The increased throughput obtained through concurrent operation allows the reduction of the power supply voltage, i.e., voltage scaling [4, 13, 24]. The focus of this paper is on asynchronous designs for low power. <p> Chandrakasan et al. [4] show that concurrency is a key to architecture-driven optimizations for low-power operation. The increased throughput obtained through concurrent operation allows the reduction of the power supply voltage, i.e., voltage scaling <ref> [4, 13, 24] </ref>. The focus of this paper is on asynchronous designs for low power. In principle, asynchronous systems have the potential for low power operation for two reasons. First, these systems have no global clock; in contrast, clock distribution is a major source of power consumption in synchronous design. <p> The operation of these systems is controlled by basic elements called sequencers. Our strategy is to use architectural optimization to increase the throughput of a sequential system. This increased throughput must be achieved without increasing the switching activity required for a computation (otherwise energy consumption could increase). Voltage scaling <ref> [4, 13, 24] </ref> is then applied, to reduce both power consumption and throughput. The resulting system has no net loss of performance, but a significant reduction in power. In particular, we present the following new contributions. First, we introduce three new designs for asynchronous sequencers. <p> Finally, leakage energy occurs in standby mode, and is caused by substrate currents and by sub-threshold conduction in off transistors. We only consider transition energy because in most CMOS circuits this energy dominates the other two and contributes up to 90% of the total energy <ref> [4] </ref>. In asynchronous systems there is no global clock, so the metric of interest is the total energy of a computation. <p> Energy dissipation can be reduced by reducing the capacitance, the number of transitions, or the supply volt age. Since energy depends quadratically on the supply voltage, supply voltage scaling is 3 an especially attractive scheme for power reduction <ref> [4] </ref>. Unfortunately, voltage scaling has the undesirable effect of reducing the speed of the circuit. Several techniques are used to compensate for this performance penalty. <p> Unfortunately, voltage scaling has the undesirable effect of reducing the speed of the circuit. Several techniques are used to compensate for this performance penalty. In particular, architecture-driven voltage scaling <ref> [4, 3] </ref> combines architectural optimizations |to increase the concurrent activity and the throughput of the system| with voltage scaling, to reduce the power consumption without affecting the throughput. Our goal is therefore to increase the concurrency, and hence the throughput, of a system.
Reference: [5] <author> C. Farnsworth, D. A. Edwards, J. Liu, and S. S. Sikand. </author> <title> A hybrid asynchronous system design environment. </title> <booktitle> In Proc. Working Conf. on Asynchronous Design Methodologies, </booktitle> <pages> pages 91-98. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> May </month> <year> 1995. </year>
Reference-contexts: Farnsworth et. al <ref> [5] </ref> introduced a concurrent 2-way sequencer as part of a FIFO control unit. No N-way extensions were presented. We explored three different tree structures to obtain an N-way sequencer: a left-branching tree, a right-branching tree, and a balanced tree. <p> transitions MODEL Previous Designs Tangram 18N-18 10N-10 SI Martin 18N-18 10N-10 SI Josephs/Bailey Counter-Decoder 15N-6 7N-2 SI Josephs/Bailey Chain 12N+4 8N-2 FM Unger Tree 36N-36 16N-16 FM Farnsworth (Extended N-way) y 14N-14 8N-8 FM New Designs Burst-mode 14N-6 8N-4 FM Optimized 10N+2 6N FM Speed-independent 12N+2 6N+6 SI y In <ref> [5] </ref>, Farnsworth et. al used a concurrent 2-way sequencer. No N-way extensions were presented. We explored three different structures to obtain an N-way sequencer: a left-branching tree, a right-branching tree, and a balanced tree. All extensions lead to the same results. Table 1: Static Characteristics of N-way Sequencers. <p> 5g + R (6N-8)g+NP+(N-1)R Josephs/Bailey Counter-Decoder 2g 4g + R (4N-4)g+NP+(N-1)R Josephs/Bailey Chain 2g 3g + R (3N-2)g+NP+(N-1)R MIN=2g Unger Tree 2 (logN)g MAX=[4 (logN)-2]g (6N-6)g+NP Farnsworth (Extended N-way) y (2N-2)g 2g (4N-4)g+NP New Designs Burst-mode 2g 2g z (2N+2)g+NP Optimized 2g 2g 2Ng+NP Speed-Independent 2g 2g 2Ng+NP y In <ref> [5] </ref>, Farnsworth et. al used a concurrent 2-way sequencer. No N-way extensions were presented. We explored three different structures to obtain an N-way sequencer: a left-branching tree, a right-branching tree, and a balanced tree. The results shown here correspond to our left-branching-tree extension.
Reference: [6] <author> S. Furber. </author> <title> Computing without clocks: Micropipelining the ARM processor. </title> <editor> In G. Birtwistle and A. Davis, editors, </editor> <booktitle> Asynchronous Digital Circuit Design, </booktitle> <pages> pages 211-262. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Second, asynchronous circuits have an inherent automatic power-down operation: modules are activated only when their operations are needed. Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor <ref> [6] </ref>, and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently [21, 10, 2, 16, 28, 15, 25]. Several methods build asynchronous circuits as networks of communicating modules. <p> This timing assumption is called a bundling constraint [21]. 3 Overview Two basic computation structures are used in asynchronous systems: pipelined and sequential. Pipelined computation is usually used in high-performance processors, e.g. AMU-LET2 <ref> [6] </ref>. The design of asynchronous pipeline control is a very active research area [21, 7, 27]. Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank [14], DCC error corrector [24].
Reference: [7] <author> S. B. Furber and P. </author> <title> Day. </title> <journal> Four-phase micropipeline latch control circuits. IEEE Transactions on VLSI Systems, </journal> <volume> 4(2) </volume> <pages> 247-253, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: This timing assumption is called a bundling constraint [21]. 3 Overview Two basic computation structures are used in asynchronous systems: pipelined and sequential. Pipelined computation is usually used in high-performance processors, e.g. AMU-LET2 [6]. The design of asynchronous pipeline control is a very active research area <ref> [21, 7, 27] </ref>. Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank [14], DCC error corrector [24]. Active research is done in sequencer control also [22, 25, 1]. The focus of this paper is on sequential computation.
Reference: [8] <author> M. B. Josephs and A. M. Bailey. </author> <title> Design of sequencer circuits: a case study in SI-algebra. </title> <type> Technical Report SBU-CISM-94-12, </type> <institution> South Bank University, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: The counter centralizes the state of the sequencer, and the decoder distributes the signals to the processes. The circuit is speed-independent and it is currently used in several designs. This sequencer was designed using a formal procedure based on SI-Algebra (see <ref> [8] </ref> for details). The implementation has improved initial and inter-process latencies compared to the Tangram tree sequencer. Minor problems are that the circuit is not modular and is designed to work with an even number of processes. * Josephs/Bailey Chain Sequencer.
Reference: [9] <author> A. Marshall, B. Coates, and P. Siegel. </author> <title> Designing an asynchronous communications chip. </title> <journal> IEEE Design & Test of Computers, </journal> <volume> 11(2) </volume> <pages> 8-21, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: Second, asynchronous circuits have an inherent automatic power-down operation: modules are activated only when their operations are needed. Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip <ref> [9] </ref>, an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently [21, 10, 2, 16, 28, 15, 25]. Several methods build asynchronous circuits as networks of communicating modules.
Reference: [10] <author> A. J. Martin. </author> <title> Programming in VLSI: From communicating processes to delay-insensitive circuits. In C.A.R. Hoare, editor, Developments in Concurrency and Communication, </title> <booktitle> UT Year of Programming Series, </booktitle> <pages> pages 1-64, </pages> <publisher> Addison-Wesley, </publisher> <address> Reading MA, </address> <year> 1990. </year>
Reference-contexts: Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently <ref> [21, 10, 2, 16, 28, 15, 25] </ref>. Several methods build asynchronous circuits as networks of communicating modules. Every module is mapped to a circuit element in a library of self-timed modules. Such systems are macromodular , since they are constructed by combining modules into a working system. <p> This circuit is speed-independent [11], i.e., it operates correctly assuming arbitrary, finite, gate delays. An N-way sequencer consists of SEQ operators connected in a tree structure, as shown in latency and (ii) it has long inter-process latencies (see Section 8, Results). * Martin Sequencers. In <ref> [10] </ref>, Martin presents two N-way sequencers. The Tangram N-way sequencer corresponds exactly to a Q-element-based Martin sequencer and it has comparable performance. A D-element based sequencer provides no overall performance improvement. * Josephs/Bailey Counter-Decoder Sequencer. In [1], Bailey and Josephs introduced a centralized sequencer, based in a counter-decoder architecture.
Reference: [11] <author> R. E. Miller. </author> <title> Sequential Circuits and Machines, volume 2 of Switching Theory. </title> <publisher> John Wiley & Sons, </publisher> <address> New York, </address> <year> 1965. </year>
Reference-contexts: This circuit is speed-independent <ref> [11] </ref>, i.e., it operates correctly assuming arbitrary, finite, gate delays. An N-way sequencer consists of SEQ operators connected in a tree structure, as shown in latency and (ii) it has long inter-process latencies (see Section 8, Results). * Martin Sequencers. In [10], Martin presents two N-way sequencers.
Reference: [12] <author> L. W. Nagel and D. O. Pederson. </author> <title> Simulation program with integrated circuit emphasis (SPICE). </title> <type> Technical Report ERL-M383, </type> <institution> Electronics Research Lab., University of California, Berkeley, </institution> <month> April </month> <year> 1983. </year>
Reference-contexts: Josephs/Bailey chain sequencer + Tangram dual-rail latches OUR DESIGN No Voltage Scaling With Voltage Scaling Optimized concurrent sequencer + modified dual-rail latches Finally, to analyze the combined impact on system power consumption of the new se 29 quencers and the application of voltage scaling, we have simulated results using SPICE <ref> [12] </ref>. We present results on both dual-rail and single-rail sequential systems. In particular, we simulated several versions of a sequencer controlling a 4-stage datapath with identical processes. Simulation results for a dual-rail system are shown in Figure 21.
Reference: [13] <author> L. S. Nielsen, C. Niessen, J. Sparst, and K. van Berkel. </author> <title> Low-power operation using self-timed circuits and adaptive scaling of the supply voltage. </title> <journal> IEEE Transactions on VLSI Systems, </journal> <volume> 2(4) </volume> <pages> 391-397, </pages> <month> December </month> <year> 1994. </year>
Reference-contexts: A wide range of techniques is used to reduce circuit power consumption. These techniques approach low-power operation at different levels of synthesis, including IC technology optimization, low-power circuit design, architecture or structural optimizations, algorithm level optimization and system-wide low power techniques <ref> [4, 3, 13] </ref>. Chandrakasan et al. [4] show that concurrency is a key to architecture-driven optimizations for low-power operation. The increased throughput obtained through concurrent operation allows the reduction of the power supply voltage, i.e., voltage scaling [4, 13, 24]. <p> Chandrakasan et al. [4] show that concurrency is a key to architecture-driven optimizations for low-power operation. The increased throughput obtained through concurrent operation allows the reduction of the power supply voltage, i.e., voltage scaling <ref> [4, 13, 24] </ref>. The focus of this paper is on asynchronous designs for low power. In principle, asynchronous systems have the potential for low power operation for two reasons. First, these systems have no global clock; in contrast, clock distribution is a major source of power consumption in synchronous design. <p> The operation of these systems is controlled by basic elements called sequencers. Our strategy is to use architectural optimization to increase the throughput of a sequential system. This increased throughput must be achieved without increasing the switching activity required for a computation (otherwise energy consumption could increase). Voltage scaling <ref> [4, 13, 24] </ref> is then applied, to reduce both power consumption and throughput. The resulting system has no net loss of performance, but a significant reduction in power. In particular, we present the following new contributions. First, we introduce three new designs for asynchronous sequencers.
Reference: [14] <author> L. S. Nielsen and J. Sparst. </author> <title> A low-power asynchronous data-path for a FIR filter bank. </title> <booktitle> In Proc. International Symposium on Advanced Research in Asynchronous Circuits and Systems, </booktitle> <pages> pages 197-207. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> March </month> <year> 1996. </year>
Reference-contexts: The goal of this paper is to reduce power in asynchronous macromodular systems. Our focus is on non-pipelined (i.e., sequential) systems, which are commonly used in low-power DSP applications with modest performance requirements (see <ref> [14, 24] </ref>). The operation of these systems is controlled by basic elements called sequencers. Our strategy is to use architectural optimization to increase the throughput of a sequential system. This increased throughput must be achieved without increasing the switching activity required for a computation (otherwise energy consumption could increase). <p> Pipelined computation is usually used in high-performance processors, e.g. AMU-LET2 [6]. The design of asynchronous pipeline control is a very active research area [21, 7, 27]. Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank <ref> [14] </ref>, DCC error corrector [24]. Active research is done in sequencer control also [22, 25, 1]. The focus of this paper is on sequential computation. The optimizations introduced in this paper improve the throughput of an asynchronous sequential system by increasing the amount of concurrent activity.
Reference: [15] <author> S. M. Nowick and B. Coates. UCLOCK: </author> <title> Automated design of high-performance asychronous state machines. </title> <booktitle> In Proc. International Conf. Computer Design (ICCD), </booktitle> <pages> pages 434-441. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> October </month> <year> 1994. </year>
Reference-contexts: Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently <ref> [21, 10, 2, 16, 28, 15, 25] </ref>. Several methods build asynchronous circuits as networks of communicating modules. Every module is mapped to a circuit element in a library of self-timed modules. Such systems are macromodular , since they are constructed by combining modules into a working system. <p> The key point is that this sequencer waits until both concurrently operating phases, R i1 and P i , complete before starting the next two overlapped phases, R i and P i+1 , as shown in Figure 5. We synthesized the circuit using an existing burst-mode asynchronous tool, UCLOCK <ref> [15] </ref>, with extensions to incorporate output feedback. The result is a modular design, well suited for distributed control.
Reference: [16] <author> S. M. Nowick and D. L. Dill. </author> <title> Automatic synthesis of locally-clocked asynchronous state machines. </title> <booktitle> In Proc. International Conf. Computer-Aided Design (ICCAD), </booktitle> <pages> pages 318-321. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> November </month> <year> 1991. </year>
Reference-contexts: Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently <ref> [21, 10, 2, 16, 28, 15, 25] </ref>. Several methods build asynchronous circuits as networks of communicating modules. Every module is mapped to a circuit element in a library of self-timed modules. Such systems are macromodular , since they are constructed by combining modules into a working system.
Reference: [17] <author> A. Peeters. </author> <title> Single-Rail Handshake Circuits. </title> <type> PhD thesis, </type> <institution> Eindhoven University of Technology, </institution> <month> June </month> <year> 1996. </year> <month> 33 </month>
Reference-contexts: Complementary signals en and ne are generated by the latch enable circuit. The operation of the datapath depends on the type of sequencer used and on how the delay-matching is done. We now examine two schemes for single-rail datapath operation recently presented by Peeters et al. <ref> [18, 17] </ref>, then introduce our new concurrent approach. 21 6.1.1 Previous Approaches * Conservative Scheme. The conservative scheme uses a sequential controller, such as the Josephs/Bailey counter-decoder sequencer, with the single-rail latch (Figure 17). <p> A scheme that, using a sequential controller, can achieve higher throughput by a novel distribution of the computation throughout the phases of the handshake protocol. In this scheme, called standard true four-phase protocol by Peeters <ref> [17] </ref>, delays are designed to match only half the value of the worst-case delay in the functional blocks. As in the previous scheme, r 1 propagates through DF and becomes the data-valid signal for the output data from F . <p> In fact, the outputs of the combinational circuit F can glitch many times during this period and these glitches will be propagated to every processing stage connected to the latch (see discussion in <ref> [17] </ref>). <p> At the same time, each process uses the simple delay-matching approach of the conservative scheme. This results in essentially the same performance advantage as the fast scheme but without the drawbacks: a latch is transparent only when 4 Peeters <ref> [17] </ref> suggests a low-power true four-phase protocol to reduce the glitch-propagation problem. Essentially, read ports are added to the latches to block the glitches. <p> A new control multiplexer design, shown in Figure 20 (b), allows overlapped requests. In this design, a second request is stalled at the AND gate until the first operation is completed. Control multiplexers have been extended to data multiplexing <ref> [17] </ref>. Similar extensions can be made to our design of Figure 20 (b). (a) (b) 26 8 Results We now show how the increased throughput obtained by the new sequencers combines effectively with the application of voltage scaling to produce significant energy savings of an entire asynchronous system.
Reference: [18] <author> A. Peeters and K. van Berkel. </author> <booktitle> Single-rail handshake circuits. In Proc. Working Conf. on Asynchronous Design Methodologies, </booktitle> <pages> pages 53-62, </pages> <month> May </month> <year> 1995. </year>
Reference-contexts: In CMOS implementations, delays depend heavily on the sizes of transistors and their loading, and also on the final routing and placement of modules, so safety margins are required for correct operation. (see <ref> [18] </ref>). Each latch is normally opaque, and stored data is always readable at its output. A write request (W r ") makes the latch transparent for writing; the subsequent W r # makes the latch opaque, latching the result. <p> Complementary signals en and ne are generated by the latch enable circuit. The operation of the datapath depends on the type of sequencer used and on how the delay-matching is done. We now examine two schemes for single-rail datapath operation recently presented by Peeters et al. <ref> [18, 17] </ref>, then introduce our new concurrent approach. 21 6.1.1 Previous Approaches * Conservative Scheme. The conservative scheme uses a sequential controller, such as the Josephs/Bailey counter-decoder sequencer, with the single-rail latch (Figure 17).
Reference: [19] <author> L. A. Plana and S. M. Nowick. </author> <title> Concurrency-oriented optimization for low-power asynchronous systems. </title> <booktitle> In Proc. International Symposium on Low Power Electronics and Design, </booktitle> <pages> pages 151-156, </pages> <month> August </month> <year> 1996. </year>
Reference: [20] <author> C. L. Seitz. </author> <title> System timing. </title> <editor> In C. A. Mead and L. A. Conway, editors, </editor> <title> Introduction to VLSI Systems, chapter 7. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1980. </year>
Reference-contexts: This type of asynchronous circuit is designed as a network of predefined data and control modules [2]. Instead of a global clock signal, communication channels between modules use handshaking to synchronize their operation and data interchange. 2.2.1 Control Signaling Control signaling usually follows a 4-phase handshake protocol <ref> [20] </ref>, which is implemented using request and acknowledge signals. Figure 1 shows two macromodules that communicate with each other. Initially, processes are idle and both signals are de-asserted. module P asserts r to request module Q to start the processing phase. <p> The rest of the phases, especially the return-to-zero phase, represent dead time from the point of view of computation. 2.2.2 Data Communication When data communication is involved an encoding scheme is used to represent and transmit data. Two encodings are most common <ref> [20] </ref>: dual-rail and single-rail. * Dual-rail Data. Data is encoded using two wires for every data bit. Codes 01 and 10 represent `1' and `0' data values, respectively, and code 00 represents the spacer or idle state.
Reference: [21] <author> I. E. Sutherland. </author> <title> Micropipelines. </title> <journal> Communications of the ACM, </journal> <volume> 32(6) </volume> <pages> 720-738, </pages> <month> June </month> <year> 1989. </year>
Reference-contexts: Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently <ref> [21, 10, 2, 16, 28, 15, 25] </ref>. Several methods build asynchronous circuits as networks of communicating modules. Every module is mapped to a circuit element in a library of self-timed modules. Such systems are macromodular , since they are constructed by combining modules into a working system. <p> This code has good power and area costs, comparable to synchronous implementations. The correct operation of single-rail circuits relies on a local timing assumption: all data wires must be valid and stable before the data-valid signal is asserted. This timing assumption is called a bundling constraint <ref> [21] </ref>. 3 Overview Two basic computation structures are used in asynchronous systems: pipelined and sequential. Pipelined computation is usually used in high-performance processors, e.g. AMU-LET2 [6]. The design of asynchronous pipeline control is a very active research area [21, 7, 27]. <p> This timing assumption is called a bundling constraint [21]. 3 Overview Two basic computation structures are used in asynchronous systems: pipelined and sequential. Pipelined computation is usually used in high-performance processors, e.g. AMU-LET2 [6]. The design of asynchronous pipeline control is a very active research area <ref> [21, 7, 27] </ref>. Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank [14], DCC error corrector [24]. Active research is done in sequencer control also [22, 25, 1]. The focus of this paper is on sequential computation.
Reference: [22] <author> S. H. Unger. </author> <title> A building block approach to unclocked systems. </title> <booktitle> In Proc. Hawaii International Conf. System Sciences, </booktitle> <volume> volume I, </volume> <pages> pages 339-348. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> January </month> <year> 1993. </year>
Reference-contexts: Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank [14], DCC error corrector [24]. Active research is done in sequencer control also <ref> [22, 25, 1] </ref>. The focus of this paper is on sequential computation. The optimizations introduced in this paper improve the throughput of an asynchronous sequential system by increasing the amount of concurrent activity. A key control element, that has a large impact on concurrency, is the sequencer. <p> In addition, some designs also have a long initial latency. 4.1.2 Concurrent Approaches There have been a few attempts to implement concurrent sequencers, but each has limitations. * Unger Tree Sequencer. Unger <ref> [22] </ref> presented a 2-step module that implements a concurrent 2-way sequencer. The 2-step assumes fundamental-mode operation and relies on reasonable timing assumptions. An N-way sequencer is built as a balanced tree of 2-step modules [22]. <p> Unger <ref> [22] </ref> presented a 2-step module that implements a concurrent 2-way sequencer. The 2-step assumes fundamental-mode operation and relies on reasonable timing assumptions. An N-way sequencer is built as a balanced tree of 2-step modules [22].
Reference: [23] <author> Stephen H. Unger. </author> <title> Asynchronous Sequential Switching Circuits. </title> <publisher> Wiley-Interscience, </publisher> <address> New York, </address> <year> 1969. </year>
Reference-contexts: Bailey and Josephs [1] also introduced a distributed sequencer built as a linear chain of n modules, each controlling a process. The modules assume fundamental-mode operation <ref> [23] </ref>. In fundamental mode, no new inputs 9 can arrive until the component has stabilized from a previous input change. This design also has better initial and inter-process latencies than Tangram's.
Reference: [24] <author> K. van Berkel, R. Burgess, J. Kessels, A. Peeters, M. Roncken, and F. Schalij. </author> <title> Asynchronous circuits for low power: A DCC error corrector. </title> <journal> IEEE Design & Test of Computers, </journal> <volume> 11(2) </volume> <pages> 22-32, </pages> <month> Summer </month> <year> 1994. </year>
Reference-contexts: Chandrakasan et al. [4] show that concurrency is a key to architecture-driven optimizations for low-power operation. The increased throughput obtained through concurrent operation allows the reduction of the power supply voltage, i.e., voltage scaling <ref> [4, 13, 24] </ref>. The focus of this paper is on asynchronous designs for low power. In principle, asynchronous systems have the potential for low power operation for two reasons. First, these systems have no global clock; in contrast, clock distribution is a major source of power consumption in synchronous design. <p> Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player <ref> [24] </ref>. A number of asynchronous design methods have been introduced recently [21, 10, 2, 16, 28, 15, 25]. Several methods build asynchronous circuits as networks of communicating modules. Every module is mapped to a circuit element in a library of self-timed modules. <p> Such systems are macromodular , since they are constructed by combining modules into a working system. Macromodular circuits are robust and usually have few timing assump 1 tions. Macromodules are particularly well-suited for methods that approach circuit design as a programming activity. For example, van Berkel et al. <ref> [24, 25] </ref>, have developed a method to automatically design low-power asynchronous circuits from high-level Tangram programs. The programs are compiled, using syntax-directed translation, into handshake circuits, an intermediate-level representation of a circuit as a network of macromodules. The goal of this paper is to reduce power in asynchronous macromodular systems. <p> The goal of this paper is to reduce power in asynchronous macromodular systems. Our focus is on non-pipelined (i.e., sequential) systems, which are commonly used in low-power DSP applications with modest performance requirements (see <ref> [14, 24] </ref>). The operation of these systems is controlled by basic elements called sequencers. Our strategy is to use architectural optimization to increase the throughput of a sequential system. This increased throughput must be achieved without increasing the switching activity required for a computation (otherwise energy consumption could increase). <p> The operation of these systems is controlled by basic elements called sequencers. Our strategy is to use architectural optimization to increase the throughput of a sequential system. This increased throughput must be achieved without increasing the switching activity required for a computation (otherwise energy consumption could increase). Voltage scaling <ref> [4, 13, 24] </ref> is then applied, to reduce both power consumption and throughput. The resulting system has no net loss of performance, but a significant reduction in power. In particular, we present the following new contributions. First, we introduce three new designs for asynchronous sequencers. <p> AMU-LET2 [6]. The design of asynchronous pipeline control is a very active research area [21, 7, 27]. Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank [14], DCC error corrector <ref> [24] </ref>. Active research is done in sequencer control also [22, 25, 1]. The focus of this paper is on sequential computation. The optimizations introduced in this paper improve the throughput of an asynchronous sequential system by increasing the amount of concurrent activity. <p> Such sequences can be very long. For example, Bailey [1] reports that the longest sequence in the asynchronous error decoder circuit for a DCC player <ref> [24] </ref> consists of 48 processes. Two common operation protocols are used in asynchronous sequencers: sequential and concurrent. * Sequential Protocol. Figure 2 (a) shows a sequencer module controlling the operation of four processes (P 1 , P 2 , P 3 , P 4 ).
Reference: [25] <author> K. van Berkel and M. Rem. </author> <title> VLSI programming of asynchronous circuits for low power. </title> <editor> In G. Birtwistle and A. Davis, editors, </editor> <booktitle> Asynchronous Digital Circuit Design, </booktitle> <pages> pages 152-210. </pages> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently <ref> [21, 10, 2, 16, 28, 15, 25] </ref>. Several methods build asynchronous circuits as networks of communicating modules. Every module is mapped to a circuit element in a library of self-timed modules. Such systems are macromodular , since they are constructed by combining modules into a working system. <p> Such systems are macromodular , since they are constructed by combining modules into a working system. Macromodular circuits are robust and usually have few timing assump 1 tions. Macromodules are particularly well-suited for methods that approach circuit design as a programming activity. For example, van Berkel et al. <ref> [24, 25] </ref>, have developed a method to automatically design low-power asynchronous circuits from high-level Tangram programs. The programs are compiled, using syntax-directed translation, into handshake circuits, an intermediate-level representation of a circuit as a network of macromodules. The goal of this paper is to reduce power in asynchronous macromodular systems. <p> Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank [14], DCC error corrector [24]. Active research is done in sequencer control also <ref> [22, 25, 1] </ref>. The focus of this paper is on sequential computation. The optimizations introduced in this paper improve the throughput of an asynchronous sequential system by increasing the amount of concurrent activity. A key control element, that has a large impact on concurrency, is the sequencer. <p> In Tangram, 2-way sequencing is implemented using the SEQ operator <ref> [25] </ref>, shown in Figure 4 (a). The sequencer is activated on its passive port, or channel, S (a passive port is indicated by a small white circle). <p> Data signals return to the idle state to indicate the end of the write request to Z. Z responds by de-asserting a 1 which completes the operation. An existing handshake latch that stores 1 bit of data <ref> [25] </ref> is shown in Figure 13. W 0 and W 1 correspond to the dual-rail write data, and W a is the write acknowledge signal. R r is the read request, and R 0 and R 1 are the dual-rail data outputs. <p> In an n-stage shift register, the R 0 (R 1 ) output of each stage is connected to the W 0 (W 1 ) input of the next stage. A read request to one stage therefore produces a write to the adjacent stage (see <ref> [25] </ref> for details). A sequencer controls each 1-bit shift operation. The sequencer generates a read request (R r ) to each stage in turn, and receives the adjacent write acknowledge (W a ). <p> In this case, the different requests must be multiplexed together. An existing handshake multiplexer for control signals <ref> [25] </ref>, shown in Figure 20 (a), requires mutually-exclusive requests on its two channels. A new control multiplexer design, shown in Figure 20 (b), allows overlapped requests. In this design, a second request is stalled at the AND gate until the first operation is completed.
Reference: [26] <author> Kees van Berkel. </author> <title> Handshake Circuits: an Asynchronous Architecture for VLSI Programming. </title> <publisher> Cambridge University Press, </publisher> <year> 1993. </year>
Reference-contexts: A signal from this module to the previous one (b i ) is added in order to report that the change in a i has been absorbed, allowing further changes in r i to take place. (a) (b) The first process, P 1 , is controlled by a handshake S-element <ref> [26] </ref>, shown in Figure 4 above. Each of the remaining processes is controlled by an M module shown in Figure 11 (b).
Reference: [27] <author> K. Y. Yun, P. A. Beerel, and J. Arceo. </author> <title> High-performance asynchronous pipeline circuits. </title> <booktitle> In Proc. International Symposium on Advanced Research in Asynchronous Circuits and Systems, </booktitle> <pages> pages 17-28. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> March </month> <year> 1996. </year>
Reference-contexts: This timing assumption is called a bundling constraint [21]. 3 Overview Two basic computation structures are used in asynchronous systems: pipelined and sequential. Pipelined computation is usually used in high-performance processors, e.g. AMU-LET2 [6]. The design of asynchronous pipeline control is a very active research area <ref> [21, 7, 27] </ref>. Sequential computation is used in some DSP systems with moderate timing 5 requirements, usually aimed at low-power operation, e.g. FIR filter bank [14], DCC error corrector [24]. Active research is done in sequencer control also [22, 25, 1]. The focus of this paper is on sequential computation.
Reference: [28] <author> K. Y. Yun and D. L. Dill. </author> <title> Automatic synthesis of 3D asynchronous state machines. </title> <booktitle> In Proc. International Conf. Computer-Aided Design (ICCAD), </booktitle> <pages> pages 576-580. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> November </month> <year> 1992. </year> <month> 34 </month>
Reference-contexts: Low-power operation is a major focus of recent asynchronous design, including large-scale, fabricated examples like a low-power infrared communications chip [9], an asynchronous implementation of the ARM microprocessor [6], and an asynchronous error corrector for a DCC player [24]. A number of asynchronous design methods have been introduced recently <ref> [21, 10, 2, 16, 28, 15, 25] </ref>. Several methods build asynchronous circuits as networks of communicating modules. Every module is mapped to a circuit element in a library of self-timed modules. Such systems are macromodular , since they are constructed by combining modules into a working system.
References-found: 28

