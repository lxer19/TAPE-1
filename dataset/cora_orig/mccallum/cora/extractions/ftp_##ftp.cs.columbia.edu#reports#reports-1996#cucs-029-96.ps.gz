URL: ftp://ftp.cs.columbia.edu/reports/reports-1996/cucs-029-96.ps.gz
Refering-URL: http://www.cs.columbia.edu/~library/1996.html
Root-URL: http://www.cs.columbia.edu
Email: paskov@cs.columbia.edu  email: nypav@ubss.com  
Title: New Methodologies for Valuing Derivatives  
Author: SPASSIMIR H. PASKOV 
Note: This research was supported in part by the the National Science Foundation and the Air Force Office of Scientific Research. I am grateful to Goldman Sachs for providing the finance problem. Currently at  
Address: New York, NY 10027  Union Bank of Switzerland, 299 Park Avenue, New York, NY 10171,  
Affiliation: Department of Computer Science Columbia University  
Abstract: This is a slightly modified version of a Columbia University Technical Report which appeared in October 1994. It will appear in "Mathematics of Derivative Securities" edited by S. Pliska and M. Dempster, Isaac Newton Institute, Cambridge, Cambridge University Press, U.K. in May 1996. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Adler, S. J., </author> <title> The Geometry of Random Fields, Wiley Series in Prob. </title> <journal> and Math. Stat., </journal> <year> 1981. </year>
Reference-contexts: We now present the classical Monte Carlo algorithm. For brevity, we refer to it as the Monte Carlo algorithm. Let t 1 ; : : : ; t n be n randomly selected points which are independent and uniformly distributed over D = <ref> [0; 1] </ref> d , the d dimensional unit cube. Consider a function f from the space L 2 (D) of L 2 -integrable functions. The problem is to approximately compute I (f ) = D 6 using function evaluations at randomly chosen points. <p> This concept of effective dimension can be defined rigorously as follows. Let f be a function with domain <ref> [0; 1] </ref> d and let " &gt; 0. <p> This concept of effective dimension can be defined rigorously as follows. Let f be a function with domain [0; 1] d and let " &gt; 0. The effective dimension K (") of f is the smallest integer k 2 <ref> [1; d ] </ref> such that fi fi fi [0;1] k Z f (x)dx fi fi " fi fi Z f (x)dx fi fi : We apply this definition of effective dimension to the ten tranches of the CMO problem. Clearly, the effective dimension is a function of ".
Reference: [2] <author> Antonov, I.A., and Saleev, </author> <title> V.M., An Economic Method of Computing LP t -sequences, </title> <journal> USSR Computational Mathematics and Mathematical Physics, </journal> <volume> 19, </volume> <pages> 252-256, </pages> <year> 1979. </year>
Reference-contexts: For example, k = 3 is 11 in base 2. If v 1 = 0:1 and v 2 = 0:11 then b 1 v 1 b 2 v 2 = 0:1 0:11 = 0:01: Antonov and Saleev <ref> [2] </ref> suggest a shu*ing of the original Sobol sequence which preserves good convergence properties and which can be generated much faster. This version of the Sobol sequence is used here. <p> We checked computationally that the values of the integrals of all tranches are about a10 6 with a 2 <ref> [2; 42] </ref>. Hence by taking " = 0:001 we introduce an absolute error which is on the order of several thousand dollars. We estimate K T (") for " = 0:001, where K T (") denotes the effective dimension of tranche T.
Reference: [3] <author> Bratley, P. and Fox, B.L., </author> <title> Algorithm 659, Implementing Sobol's Quasirandom Sequence Generator, </title> <journal> ACM Trans. Math. Software, </journal> <volume> 14, </volume> <pages> 88-100, </pages> <year> 1988. </year>
Reference: [4] <author> Chelson, P., </author> <title> Quasi-random Techniques for Monte Carlo Methods, </title> <type> PhD Dissertation, </type> <institution> The Claremont Graduate School, </institution> <year> 1976. </year>
Reference-contexts: For the low discrepancy algorithms, the error bound depends on the variation of the integrand, see Section 3. Therefore the error bound will be decreased by reducing of the variation. Reducing the variation of the integrand has not been studied as extensively as reducing the variance. See, however, <ref> [4] </ref>, [17], [20], and [36]. This is a major area for further research. An important advantage of the classical Monte Carlo algorithm and of the deterministic algorithms studied here, is that they can be utilized very generally.
Reference: [5] <author> Fabozzi, F. J., </author> <title> Handbook of Mortgage Backed Securities, </title> <publisher> Probus Publishing Co., </publisher> <year> 1992. </year>
Reference-contexts: The technique of distributing the cash flows transfers the prepayment risk among different tranches. This results in financial instruments with varying characteristics which might be more suitable to the needs and expectations of investors. For more details on CMOs, we refer to <ref> [5] </ref>. We stress that the amount of obtained cash flows will depend upon the future level of interest rates. Our problem is to estimate the expected value of the sum of present values of future cash flows for each of the tranches.
Reference: [6] <editor> Fabozzi, F. J., </editor> <publisher> Fixed Income Mathematics Probus Publishing Co., </publisher> <year> 1988. </year>
Reference: [7] <author> Fox, B.L., </author> <title> Algorithm 647, Implementation and Relative Efficiency of Quasirandom Sequence Generators, </title> <journal> ACM Trans. Math. Software, </journal> <volume> 12, </volume> <pages> 362-376, </pages> <year> 1986. </year>
Reference: [8] <author> Geweke, J., </author> <title> Monte Carlo Simulations and Numerical Integration, to appear in Handbook of Computational Economics edited by H. Amman, </title> <editor> D. Kendrick, and J. Rust, </editor> <publisher> Elsevier, </publisher> <address> Amsterdam, </address> <year> 1996. </year>
Reference: [9] <author> Halton, J.H., </author> <title> On the efficiency of certain quasi-random sequences of points in evaluating multi-dimensional integrals, </title> <journal> Numer. Math., </journal> <volume> 2, </volume> <pages> 84-90, </pages> <year> 1960. </year>
Reference-contexts: (n 1 (log n) (d1)=2 ): (3) Of special interest for numerical integration are infinite low discrepancy sequences fz k g in which the definition of z k does not depend on the specific value of the number of points n. 8 Examples of such infinite sequences are the Halton <ref> [9] </ref> and Sobol [33] sequences. For the reader's convenience, we give a short description of both these sequences later in this section.
Reference: [10] <author> Halton, J.H. and Smith, </author> <title> G.B., Algorithm 247, Radical-inverse quasi-random point sequence, </title> <journal> Commun. ACM, </journal> <volume> 7, </volume> <pages> 701-702, </pages> <year> 1964. </year> <month> 43 </month>
Reference: [11] <author> Halton, J.H., </author> <title> A retrospective and prospective survey of the Monte Carlo method SIAM Review, </title> <type> 12, </type> <year> 1970, </year> <pages> 1-63. </pages>
Reference-contexts: For more details, see for example, <ref> [11] </ref>, [12], [15], and [34]. We now present the classical Monte Carlo algorithm. For brevity, we refer to it as the Monte Carlo algorithm.
Reference: [12] <author> Hammersley, J. and Handscomb, D., </author> <title> Monte Carlo methods, </title> <publisher> Methuen, </publisher> <address> London, </address> <year> 1964. </year>
Reference-contexts: For more details, see for example, [11], <ref> [12] </ref>, [15], and [34]. We now present the classical Monte Carlo algorithm. For brevity, we refer to it as the Monte Carlo algorithm.
Reference: [13] <author> Hoel, P. G., </author> <title> Elementary Statistics, </title> <publisher> John Wiley and Sons, </publisher> <year> 1976. </year>
Reference-contexts: In Section 8, we showed that it is reasonable to assume that m 14; 865; 801. We seek the number of antithetic variables runs, each using 4,000 sample points, which after averaging would give an error ffi with probability . This procedure is widely used in statistical analysis, see <ref> [13] </ref>. That is, let ~ 1 ; ~ 2 ; : : : ; ~ k be the results for k antithetic variables runs each using 4,000 f function evaluations.
Reference: [14] <author> Janse van Rensburg, E. J. and Torrie, G. M., </author> <title> Estimation of multidimensional integrals: Is Monte Carlo the best method? J. </title> <journal> Phys. A.: Math. Gen., </journal> <volume> 26, </volume> <year> 1993, </year> <pages> 943-953. </pages>
Reference-contexts: 1 Introduction High-dimensional integrals are usually solved with Monte Carlo algorithms. Vast sums are spent annually on these algorithms. Theory [21], [43] suggests that low discrepancy algorithms are sometimes superior to Monte Carlo algorithms. However, a number of researchers, <ref> [14] </ref>, [19], [20], report that their numerical tests show that this theoretical advantage decreases with increasing dimension. Furthermore, they report that the theoretical advantage of low discrepancy algorithms disappears for rather modest values of the dimension, say, d 30.
Reference: [15] <author> Kalos, M. H. and Whitlock, P. A., </author> <title> Monte Carlo Methods, Volume I, </title> <publisher> John Wiley and Sons, </publisher> <year> 1986. </year>
Reference-contexts: For more details, see for example, [11], [12], <ref> [15] </ref>, and [34]. We now present the classical Monte Carlo algorithm. For brevity, we refer to it as the Monte Carlo algorithm. <p> In fact, this is the main idea underlying the various variance reduction techniques which are often used in combination with the Monte Carlo algorithm. Examples of variance reduction techniques are importance sampling, control variates, antithetic variables, see for example <ref> [15] </ref>. Antithetic variables will be discussed in Section 7. Let B (L 2 (D)) denote the unit ball of L 2 (D). <p> Therefore by reducing the variance of the integrand the expected error would also decrease. Various variance reduction techniques such as importance sampling, control variates, antithetic variables and others, see for example <ref> [15] </ref>, are often used with the classical Monte Carlo algorithm. For the low discrepancy algorithms, the error bound depends on the variation of the integrand, see Section 3. Therefore the error bound will be decreased by reducing of the variation. <p> Furthermore, the cost of both algorithms is about the same. Since r can be smaller than one for some functions, the antithetic variables variance reduction technique, although simple to use, does not work in general and should be used with care, see also <ref> [15] </ref>. We tested the antithetic variables algorithm for the CMO problem with the ten tranches. Let f T be the integrand for tranche T . We approximately computed (f T ), (g T ), and r T = (f T )=( 2 (g T )) for all tranches T . <p> According to the Central Limit Theorem, see e.g. <ref> [15] </ref>, the distributions of U n (f ) and U n (g) are normal for n ! 1 with the same mean R R D g (x)dx and variances 2 (f )=n and 2 (g)=n, respectively.
Reference: [16] <author> Knuth, D.E., </author> <title> Seminumerical Algorithms, </title> <booktitle> vol. 2 of The Art of Computer Programming, </booktitle> <publisher> Addison Wesley, </publisher> <year> 1981. </year>
Reference-contexts: We mention just three of them here. Even though the rate of convergence is independent of the dimension, it is quite slow. Furthermore, there are fundamental philosophical and practical problems with generating independent random points; instead, pseudorandom numbers are used, see <ref> [16] </ref> and [41]. <p> This version of the Sobol sequence is used here. The sequence of direction numbers v i is generated by a primitive polynomial, see <ref> [16] </ref> and [33], with coefficients in the field Z 2 with elements f0; 1g. Consider, for example, the primitive polynomial P (x) = x n + a 1 x n1 + : : : + a n1 x + 1 of degree n in Z 2 [x].
Reference: [17] <author> Maize, E., </author> <title> Contributions to the theory of error reduction in quasi-Monte Carlo methods, </title> <type> PhD Dissertation, </type> <institution> The Claremont Graduate School, </institution> <year> 1981. </year>
Reference-contexts: For the low discrepancy algorithms, the error bound depends on the variation of the integrand, see Section 3. Therefore the error bound will be decreased by reducing of the variation. Reducing the variation of the integrand has not been studied as extensively as reducing the variance. See, however, [4], <ref> [17] </ref>, [20], and [36]. This is a major area for further research. An important advantage of the classical Monte Carlo algorithm and of the deterministic algorithms studied here, is that they can be utilized very generally.
Reference: [18] <author> Morokoff, W. J. and Caflisch, R. E., </author> <title> Quasi-Random Sequences and their Discrepancies, </title> <journal> SIAM J. Scientific Computing, </journal> <volume> 15, </volume> <pages> 1251-1279, </pages> <year> 1994. </year>
Reference-contexts: We believe that 2 Other low discrepancy sequences also satisfy this property, see [21] 41 this behavior is due to the fact that the Halton points are less uniformly distributed than the Sobol points; especially in high dimensions and sample sizes of 1,000,000 or less, see also <ref> [18] </ref>.
Reference: [19] <author> Morokoff, W. J. and Caflisch, R. E., </author> <title> Quasi-Monte Carlo Integration, </title> <journal> J. Comp. Physics, </journal> <volume> 122, </volume> <pages> 218-230, </pages> <year> 1995. </year>
Reference-contexts: 1 Introduction High-dimensional integrals are usually solved with Monte Carlo algorithms. Vast sums are spent annually on these algorithms. Theory [21], [43] suggests that low discrepancy algorithms are sometimes superior to Monte Carlo algorithms. However, a number of researchers, [14], <ref> [19] </ref>, [20], report that their numerical tests show that this theoretical advantage decreases with increasing dimension. Furthermore, they report that the theoretical advantage of low discrepancy algorithms disappears for rather modest values of the dimension, say, d 30.
Reference: [20] <author> Moskowitz, B. and Caflisch, R. E., </author> <title> Smoothness and Dimension Reduction in Quasi-Monte Carlo Methods, </title> <note> to appear in Math. Comp. Modeling. </note>
Reference-contexts: 1 Introduction High-dimensional integrals are usually solved with Monte Carlo algorithms. Vast sums are spent annually on these algorithms. Theory [21], [43] suggests that low discrepancy algorithms are sometimes superior to Monte Carlo algorithms. However, a number of researchers, [14], [19], <ref> [20] </ref>, report that their numerical tests show that this theoretical advantage decreases with increasing dimension. Furthermore, they report that the theoretical advantage of low discrepancy algorithms disappears for rather modest values of the dimension, say, d 30. <p> Therefore the error bound will be decreased by reducing of the variation. Reducing the variation of the integrand has not been studied as extensively as reducing the variance. See, however, [4], [17], <ref> [20] </ref>, and [36]. This is a major area for further research. An important advantage of the classical Monte Carlo algorithm and of the deterministic algorithms studied here, is that they can be utilized very generally.
Reference: [21] <author> Niederreiter, H., </author> <title> Random Number Generation and Quasi-Monte Carlo Methods, </title> <publisher> CBMS-NSF,63, SIAM, </publisher> <address> Philadelphia, </address> <year> 1992. </year>
Reference-contexts: 1 Introduction High-dimensional integrals are usually solved with Monte Carlo algorithms. Vast sums are spent annually on these algorithms. Theory <ref> [21] </ref>, [43] suggests that low discrepancy algorithms are sometimes superior to Monte Carlo algorithms. However, a number of researchers, [14], [19], [20], report that their numerical tests show that this theoretical advantage decreases with increasing dimension. <p> Nevertheless, the Monte Carlo algorithm has several serious deficiencies, see for example, <ref> [21] </ref> and [36]. We mention just three of them here. Even though the rate of convergence is independent of the dimension, it is quite slow. Furthermore, there are fundamental philosophical and practical problems with generating independent random points; instead, pseudorandom numbers are used, see [16] and [41]. <p> desirable guarantee for problems where highly reliable results are needed. 3 Low Discrepancy Deterministic Algorithms In an attempt to avoid the deficiencies of the Monte Carlo algorithm, many deterministic algorithms have been proposed for computing high dimensional integrals for functions belonging to various subsets of L 2 (D), see e.g. <ref> [21] </ref>, [22], [40], [43], [23], and [37]. One class of such deterministic algorithms is based on low discrepancy sequences. First, we define discrepancy, which is a measure of deviation from uniformity of a sequence of points in D. <p> Then, very briefly, we give the theoretical basis of the low discrepancy sequences to be used as sample points for computing multivariate integrals. For more detailed description and treatment of these results, see <ref> [21] </ref>. For t = [t 1 ; : : : ; t d ] 2 D, define [0; t) = [0; t 1 ) fi fi [0; t d ): Let [0;t) be the characteristic (indicator) function of [0; t). <p> 1 ; : : : ; z n )k 2 kR n (; z 1 ; : : : ; z n )k 1 = O (log n) d ! This is the best upper bound known and it is widely believed that it is sharp for these sequences, see <ref> [21] </ref>. We stress that the constants in the bounds (3) and (4) depend on the dimension d and good estimates of these constants are not known. Bounds with known constants and n independent of d are studied in [42] and [44]. <p> We now state the theoretical bases for the use of low discrepancy sequences as sample points for multivariate integration. Let V (f ) &lt; 1 be the variation of f on D in the sense of Hardy and Krause, see <ref> [21] </ref>, and let fz k g be a low discrepancy sequence. <p> The Koksma-Hlawka inequality guarantees that fi fi fi 1 n X f (z k ) fi fi V (f ) kR n ( ; z 1 ; : : : ; z n )k 1 : (5) Upper bounds in terms of L 2 discrepancy have also been proven, see <ref> [21] </ref>. Therefore, (4) and (5) provide a worst case assurance for the use of low discrepancy sequences as sample points for numerical integration of functions with bounded variation in the sense of Hardy and Krause. <p> Using the identity [0;t) (z k ) = (1t;1] (x k ) and Proposition 2.4 in <ref> [21] </ref>, we conclude that if fz k g is a low discrepancy sequence then fx k g is also a low discrepancy sequence. 3.1 Halton Points We give a short description of the Halton low discrepancy sequence. <p> We believe that our choices of the initial direction numbers contributes to the successful performance of the Sobol points. The Halton algorithm did not perform as well as the Sobol algorithm. We believe that 2 Other low discrepancy sequences also satisfy this property, see <ref> [21] </ref> 41 this behavior is due to the fact that the Halton points are less uniformly distributed than the Sobol points; especially in high dimensions and sample sizes of 1,000,000 or less, see also [18].
Reference: [22] <author> Novak, E., </author> <title> Deterministic and Stochastic Error Bounds in Numerical Analysis, </title> <booktitle> Lecture Notes in Math., </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year>
Reference-contexts: guarantee for problems where highly reliable results are needed. 3 Low Discrepancy Deterministic Algorithms In an attempt to avoid the deficiencies of the Monte Carlo algorithm, many deterministic algorithms have been proposed for computing high dimensional integrals for functions belonging to various subsets of L 2 (D), see e.g. [21], <ref> [22] </ref>, [40], [43], [23], and [37]. One class of such deterministic algorithms is based on low discrepancy sequences. First, we define discrepancy, which is a measure of deviation from uniformity of a sequence of points in D.
Reference: [23] <author> Paskov, S. H., </author> <title> Average Case Complexity of Multivariate Integration for Smooth Functions, </title> <journal> J. Complexity, </journal> <volume> 9, </volume> <pages> 291-312, </pages> <year> 1993. </year>
Reference-contexts: where highly reliable results are needed. 3 Low Discrepancy Deterministic Algorithms In an attempt to avoid the deficiencies of the Monte Carlo algorithm, many deterministic algorithms have been proposed for computing high dimensional integrals for functions belonging to various subsets of L 2 (D), see e.g. [21], [22], [40], [43], <ref> [23] </ref>, and [37]. One class of such deterministic algorithms is based on low discrepancy sequences. First, we define discrepancy, which is a measure of deviation from uniformity of a sequence of points in D.
Reference: [24] <author> Paskov, S. H., </author> <title> Computing High Dimensional Integrals with Applications to Finance, </title> <booktitle> Joint Summer Research Conference on Continuous Algorithms and Complexity, </booktitle> <address> Mount Holyoke College, </address> <month> June, </month> <year> 1994. </year> <month> 44 </month>
Reference-contexts: A January, 1994 article in Scientific American discussed the theoretical issues and reported that "Preliminary results obtained by testing certain finance problems suggest the superiority of the deterministic methods in practice." Further results were reported at a number of conferences including <ref> [24] </ref>, [38], [39]. An "extended abstract" of this paper was published in Fall, 1995 [26]. A slightly different version of this paper appeared as a Columbia University Technical Report in October, 1994. We summarize our main conclusions regarding the evaluation of this CMO.
Reference: [25] <author> Paskov, S. H., </author> <title> Termination Criteria for Linear Problems, </title> <journal> J. Complexity, </journal> <volume> 11, </volume> <pages> 105-137, </pages> <year> 1995. </year>
Reference-contexts: Automatic termination criteria are often used in computational practice. It is of interest to study the relation between the threshold value and the actual error of approximation. See Paskov <ref> [25] </ref> for the approximation of linear operators in the average case setting assuming that arbitrary linear continuous functionals can be computed. It is proved that standard termination criteria work well.
Reference: [26] <author> Paskov, S. H. and Traub, J. F., </author> <title> Faster Valuation of Financial Derivatives, </title> <journal> The Journal of Portfolio Management, </journal> <volume> Vol. 22, No. 1, </volume> <pages> 113-120, </pages> <month> Fall </month> <year> 1995. </year>
Reference-contexts: An "extended abstract" of this paper was published in Fall, 1995 <ref> [26] </ref>. A slightly different version of this paper appeared as a Columbia University Technical Report in October, 1994. We summarize our main conclusions regarding the evaluation of this CMO. The conclusions may be divided into three groups. I.
Reference: [27] <author> Press, W., Teukolsky S., Vetterling, W., and B. Flannery, </author> <title> Numerical Recipes in C, First Edition, </title> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: One of the improvements was developing the table of primitive polynomials and initial direction numbers for dimensions up to 360. The software uses various kinds of random number generators. More specifically, the random number generators ran1 and ran2 from the first edition of Numerical Recipes <ref> [27] </ref>, and RAN1 and RAN2 from the second edition of Numerical Recipes [28] are used because of their wide availability and popularity. All of the above random number generators are based on linear congruential generators with some additional features. For more details on these random number generators we refer to [27] <p> <ref> [27] </ref>, and RAN1 and RAN2 from the second edition of Numerical Recipes [28] are used because of their wide availability and popularity. All of the above random number generators are based on linear congruential generators with some additional features. For more details on these random number generators we refer to [27] and [28]. 4.2 Systems Since workstation clusters and networks provide cost-effective means to perform large-scale computation, we have built and debugged a software system under PVM 3.2 (Parallel Virtual Machine) for computing multivariate integrals. This system runs on a heterogeneous network of machines. <p> This makes automatic termination easier for the Sobol algorithm; see the discussion below; * The Sobol algorithm outperforms the Halton algorithm. namely ran1 from <ref> [27] </ref>, is used to generate four Monte Carlo runs using four randomly chosen initial seeds. The plot again exhibits sensitivity of the Monte Carlo algorithm to the initial seed. <p> Then the speedup of the distributed on a network of workstations software system is also measured for the CMO problem. The CPU time in seconds for simultaneous evaluation of the ten tranches is given in Table 12 for Sobol, Halton, RAN2 from [28], RAN1 from [28], ran1 from <ref> [27] </ref>, and ran2 from [27] generators. The real time in seconds, as should be expected, is slightly higher than the CPU time. It is given in the second column since it is later compared with the real time for the network of workstations to derive the parallel speedup. <p> The CPU time in seconds for simultaneous evaluation of the ten tranches is given in Table 12 for Sobol, Halton, RAN2 from [28], RAN1 from [28], ran1 from <ref> [27] </ref>, and ran2 from [27] generators. The real time in seconds, as should be expected, is slightly higher than the CPU time. It is given in the second column since it is later compared with the real time for the network of workstations to derive the parallel speedup.
Reference: [28] <author> Press, W., Teukolsky S., Vetterling, W., and B. Flannery, </author> <title> Numerical Recipes in C, Second Edition, </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Of course, FINDER can also be used to compute high dimensional integrals on a single workstation. The software system FINDER is available and interested readers should contact the author. A routine for generating Sobol points is given in <ref> [28] </ref>. However, major improvements have been incorporated in FINDER. We emphasize that the results reported in this paper were obtained using FINDER. One of the improvements was developing the table of primitive polynomials and initial direction numbers for dimensions up to 360. <p> One or several multivariate functions defined over the unit cube of up to 360 variables can be integrated simultaneously. The number of variables could be extended as well. A routine for generating Sobol points is given in <ref> [28] </ref>. However, we have made major improvements and we stress that the results reported in this paper were obtained using FINDER and not the routine in [28]. One of the improvements was developing the table of primitive polynomials and initial direction numbers for dimensions up to 360. <p> The number of variables could be extended as well. A routine for generating Sobol points is given in <ref> [28] </ref>. However, we have made major improvements and we stress that the results reported in this paper were obtained using FINDER and not the routine in [28]. One of the improvements was developing the table of primitive polynomials and initial direction numbers for dimensions up to 360. The software uses various kinds of random number generators. <p> The software uses various kinds of random number generators. More specifically, the random number generators ran1 and ran2 from the first edition of Numerical Recipes [27], and RAN1 and RAN2 from the second edition of Numerical Recipes <ref> [28] </ref> are used because of their wide availability and popularity. All of the above random number generators are based on linear congruential generators with some additional features. For more details on these random number generators we refer to [27] and [28]. 4.2 Systems Since workstation clusters and networks provide cost-effective means <p> RAN1 and RAN2 from the second edition of Numerical Recipes <ref> [28] </ref> are used because of their wide availability and popularity. All of the above random number generators are based on linear congruential generators with some additional features. For more details on these random number generators we refer to [27] and [28]. 4.2 Systems Since workstation clusters and networks provide cost-effective means to perform large-scale computation, we have built and debugged a software system under PVM 3.2 (Parallel Virtual Machine) for computing multivariate integrals. This system runs on a heterogeneous network of machines. <p> For the reader's convenience, the results are summarized in a number of graphs. two randomly chosen initial seeds. The pseudorandom generator RAN2 from <ref> [28] </ref> is used to 18 Tranche K T (") A 131 C 212 E 261 H 63 R 338 Table 2: The approximate values of K T (") for " = 0:001 generate random sample points for the Monte Carlo runs. <p> This claim is also supported by the fact that the same effect has been observed for sixteen additional Monte Carlo runs. We assume that is why ran1 has been replaced by a 19 20 different random number generator in <ref> [28] </ref>. Figure 4 is included to show that the results can be affected by the poor performance of the random number generator. Monte Carlo runs using RAN2 from [28]. We stress that the number of sample points on the x-axis is correct only for the deterministic algorithms. <p> We assume that is why ran1 has been replaced by a 19 20 different random number generator in <ref> [28] </ref>. Figure 4 is included to show that the results can be affected by the poor performance of the random number generator. Monte Carlo runs using RAN2 from [28]. We stress that the number of sample points on the x-axis is correct only for the deterministic algorithms. The actual number of sample points for the averaged Monte Carlo graph is twenty times the number of sample points on the x-axis. <p> We thus conclude that to achieve similar performances, we have to take about 20 times more random than deterministic sample points. In Figure 6, an automatic termination criterion is applied to Sobol, Halton, and three 21 using RAN2 22 Monte Carlo runs using RAN2 from <ref> [28] </ref> as the pseudorandom generator. We choose a standard automatic termination criterion. <p> That is why, the spread and the jaggedness of antithetic variables runs in Figure 7 are smaller than the corresponding ones for Monte Carlo runs in Figure 3. antithetic variables runs using RAN2 from <ref> [28] </ref>. We stress that the number of sample points on the x-axis is correct only for the deterministic algorithms. The actual number of sample points for the averaged antithetic variables graph is twenty times the number of sample points on the x-axis. <p> Then the speedup of the distributed on a network of workstations software system is also measured for the CMO problem. The CPU time in seconds for simultaneous evaluation of the ten tranches is given in Table 12 for Sobol, Halton, RAN2 from <ref> [28] </ref>, RAN1 from [28], ran1 from [27], and ran2 from [27] generators. The real time in seconds, as should be expected, is slightly higher than the CPU time. <p> Then the speedup of the distributed on a network of workstations software system is also measured for the CMO problem. The CPU time in seconds for simultaneous evaluation of the ten tranches is given in Table 12 for Sobol, Halton, RAN2 from <ref> [28] </ref>, RAN1 from [28], ran1 from [27], and ran2 from [27] generators. The real time in seconds, as should be expected, is slightly higher than the CPU time.
Reference: [29] <author> Roth, K. F., </author> <title> On irregularities of distribution, </title> <journal> Mathematika, </journal> <volume> 1, </volume> <pages> 73-79, </pages> <year> 1954. </year>
Reference-contexts: R n ( ; z 1 ; : : : ; z n ), i.e., Z R 2 1=2 kR n ( ; z 1 ; : : : ; z n )k 1 = sup jR n (t; z 1 ; : : : ; z n )j: Roth, <ref> [29] </ref> and [30], proves that inf kR n ( ; z 1 ; : : : ; z n )k 2 = fi (n 1 (log n) (d1)=2 ): (3) Of special interest for numerical integration are infinite low discrepancy sequences fz k g in which the definition of z k
Reference: [30] <author> Roth, K. F., </author> <title> On irregularities of distribution, IV, </title> <journal> Acta Arith., </journal> <volume> 37, </volume> <pages> 67-75, </pages> <year> 1980. </year>
Reference-contexts: ( ; z 1 ; : : : ; z n ), i.e., Z R 2 1=2 kR n ( ; z 1 ; : : : ; z n )k 1 = sup jR n (t; z 1 ; : : : ; z n )j: Roth, [29] and <ref> [30] </ref>, proves that inf kR n ( ; z 1 ; : : : ; z n )k 2 = fi (n 1 (log n) (d1)=2 ): (3) Of special interest for numerical integration are infinite low discrepancy sequences fz k g in which the definition of z k does not
Reference: [31] <author> Rust, J., </author> <title> Using randomization to break the curse of dimensionality, </title> <journal> Social Systems Research Institute Working Paper Series, </journal> <volume> No. 9429, </volume> <year> 1994. </year>
Reference: [32] <author> Sarkar, P.K. and Prasad, M. A., </author> <title> A comparative study of pseudo and quasi random sequences for the solution of integral equations, </title> <journal> J. Computational Physics, </journal> <volume> 68, </volume> <pages> 66-88, </pages> <year> 1978. </year>
Reference: [33] <author> Sobol, </author> <title> I.M., On the distribution of points in a cube and the approximate evaluation of integrals, </title> <journal> USSR Computational Mathematics and Mathematical Physics, </journal> <volume> 7, </volume> <pages> 86-112, </pages> <year> 1967. </year>
Reference-contexts: n) (d1)=2 ): (3) Of special interest for numerical integration are infinite low discrepancy sequences fz k g in which the definition of z k does not depend on the specific value of the number of points n. 8 Examples of such infinite sequences are the Halton [9] and Sobol <ref> [33] </ref> sequences. For the reader's convenience, we give a short description of both these sequences later in this section. <p> This version of the Sobol sequence is used here. The sequence of direction numbers v i is generated by a primitive polynomial, see [16] and <ref> [33] </ref>, with coefficients in the field Z 2 with elements f0; 1g. Consider, for example, the primitive polynomial P (x) = x n + a 1 x n1 + : : : + a n1 x + 1 of degree n in Z 2 [x]. <p> The presence of prepayments and rules of distribution to different tranches will distort this monotonicity property. However, this property will be reflected to some extent in the cash flows of the ten tranches. It is a well-known property of the Sobol points 2 , see <ref> [33] </ref>, that the low dimensional components are more uniformly distributed than the high dimensional components. As pointed out by Sobol in [35], the Sobol points will be more efficient for numerical integration of functions for which the influence of the x j -th variable decreases as j increases.
Reference: [34] <author> Sobol, </author> <title> I.M., Numerical Monte Carlo methods (in Russian), </title> <publisher> Izdat "Nauka", </publisher> <address> Moscow, </address> <year> 1973. </year>
Reference-contexts: For more details, see for example, [11], [12], [15], and <ref> [34] </ref>. We now present the classical Monte Carlo algorithm. For brevity, we refer to it as the Monte Carlo algorithm.
Reference: [35] <author> Sobol, </author> <title> I.M., Quadrature formulas for functions of several variables satisfying general Lipschiz condition, </title> <journal> USSR Computational Mathematics and Mathematical Physics, </journal> <volume> 29, </volume> <pages> 935-941, </pages> <year> 1989. </year>
Reference-contexts: It is a well-known property of the Sobol points 2 , see [33], that the low dimensional components are more uniformly distributed than the high dimensional components. As pointed out by Sobol in <ref> [35] </ref>, the Sobol points will be more efficient for numerical integration of functions for which the influence of the x j -th variable decreases as j increases.
Reference: [36] <author> Spanier, J. and Maize, E., </author> <title> Quasi-Random Methods for Estimating Integrals using Relatively Small Samples, </title> <journal> SIAM Review, </journal> <volume> 36, </volume> <pages> 19-44, </pages> <year> 1994. </year>
Reference-contexts: Nevertheless, the Monte Carlo algorithm has several serious deficiencies, see for example, [21] and <ref> [36] </ref>. We mention just three of them here. Even though the rate of convergence is independent of the dimension, it is quite slow. Furthermore, there are fundamental philosophical and practical problems with generating independent random points; instead, pseudorandom numbers are used, see [16] and [41]. <p> Therefore the error bound will be decreased by reducing of the variation. Reducing the variation of the integrand has not been studied as extensively as reducing the variance. See, however, [4], [17], [20], and <ref> [36] </ref>. This is a major area for further research. An important advantage of the classical Monte Carlo algorithm and of the deterministic algorithms studied here, is that they can be utilized very generally.
Reference: [37] <author> Tezuka, Shu, </author> <title> A Generalization of Faure Sequences and its Efficient Implementation, </title> <type> Technical Report, </type> <institution> IBM Research, </institution> <address> Tokyo, </address> <year> 1994. </year> <month> 45 </month>
Reference-contexts: reliable results are needed. 3 Low Discrepancy Deterministic Algorithms In an attempt to avoid the deficiencies of the Monte Carlo algorithm, many deterministic algorithms have been proposed for computing high dimensional integrals for functions belonging to various subsets of L 2 (D), see e.g. [21], [22], [40], [43], [23], and <ref> [37] </ref>. One class of such deterministic algorithms is based on low discrepancy sequences. First, we define discrepancy, which is a measure of deviation from uniformity of a sequence of points in D.
Reference: [38] <author> Traub, J. F., </author> <title> Average Case Computational Complexity of High-Dimensional Integration with Applications to Finance, NSF Symposium on Simulation and Estimation, </title> <institution> Department of Economics, University of California, Berkeley, </institution> <month> August, </month> <year> 1994. </year>
Reference-contexts: A January, 1994 article in Scientific American discussed the theoretical issues and reported that "Preliminary results obtained by testing certain finance problems suggest the superiority of the deterministic methods in practice." Further results were reported at a number of conferences including [24], <ref> [38] </ref>, [39]. An "extended abstract" of this paper was published in Fall, 1995 [26]. A slightly different version of this paper appeared as a Columbia University Technical Report in October, 1994. We summarize our main conclusions regarding the evaluation of this CMO. The conclusions may be divided into three groups.
Reference: [39] <author> Traub, J. F., </author> <title> Solving Hard Problems with Applications to Finance, </title> <booktitle> Thirteenth World Computer Congress, IFIP 94, </booktitle> <address> Hamburg, </address> <month> August, </month> <year> 1994. </year>
Reference-contexts: A January, 1994 article in Scientific American discussed the theoretical issues and reported that "Preliminary results obtained by testing certain finance problems suggest the superiority of the deterministic methods in practice." Further results were reported at a number of conferences including [24], [38], <ref> [39] </ref>. An "extended abstract" of this paper was published in Fall, 1995 [26]. A slightly different version of this paper appeared as a Columbia University Technical Report in October, 1994. We summarize our main conclusions regarding the evaluation of this CMO. The conclusions may be divided into three groups. I.
Reference: [40] <author> Traub, J. F., Wasilkowski, G. W., and Wozniakowski, H., </author> <title> Information-based Complexity, </title> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: for problems where highly reliable results are needed. 3 Low Discrepancy Deterministic Algorithms In an attempt to avoid the deficiencies of the Monte Carlo algorithm, many deterministic algorithms have been proposed for computing high dimensional integrals for functions belonging to various subsets of L 2 (D), see e.g. [21], [22], <ref> [40] </ref>, [43], [23], and [37]. One class of such deterministic algorithms is based on low discrepancy sequences. First, we define discrepancy, which is a measure of deviation from uniformity of a sequence of points in D.
Reference: [41] <author> Traub, J. F. and Wozniakowski, H., </author> <title> The Monte Carlo Algorithm with a Pseudorandom Generator, </title> <journal> Mathematics of Computation, </journal> <volume> 58, </volume> <pages> 323-339, </pages> <year> 1992. </year>
Reference-contexts: We mention just three of them here. Even though the rate of convergence is independent of the dimension, it is quite slow. Furthermore, there are fundamental philosophical and practical problems with generating independent random points; instead, pseudorandom numbers are used, see [16] and <ref> [41] </ref>.
Reference: [42] <author> Wasilkowski, G. W. and Wozniakowski, H., </author> <title> Explicit Cost Bounds of Algorithms for Multivariate Tensor Product Problems, </title> <journal> J. Complexity, </journal> <volume> 11, </volume> <pages> 1-56, </pages> <year> 1995. </year>
Reference-contexts: We stress that the constants in the bounds (3) and (4) depend on the dimension d and good estimates of these constants are not known. Bounds with known constants and n independent of d are studied in <ref> [42] </ref> and [44]. Sequences satisfying the upper bound in (4) are known as low discrepancy sequences or quasi-random sequences. We will refer to them as low discrepancy sequences or deterministic sequences. <p> We checked computationally that the values of the integrals of all tranches are about a10 6 with a 2 <ref> [2; 42] </ref>. Hence by taking " = 0:001 we introduce an absolute error which is on the order of several thousand dollars. We estimate K T (") for " = 0:001, where K T (") denotes the effective dimension of tranche T. <p> uniformly distributed for a small number of points; * Characterize analytic properties of classes of financial derivatives and design new al gorithms tuned to these classes; * Study error reduction techniques for deterministic algorithms; * There are numerous open theoretical problems concerning high dimensional integration and low discrepancy sequences; see <ref> [42] </ref> for some of them. We believe that their solution will aid in the design of better algorithms for finance problems. Acknowledgments An earlier report on this work was presented by Prof. J. Traub at the Bank of England Conference at the Isaac Newton Institute, Cambridge, U.K. in May 1995.
Reference: [43] <author> Wozniakowski, H., </author> <title> Average Case Complexity of Multivariate Integration, </title> <journal> Bull. AMS (New Series), </journal> <volume> 24, </volume> <pages> 185-194, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction High-dimensional integrals are usually solved with Monte Carlo algorithms. Vast sums are spent annually on these algorithms. Theory [21], <ref> [43] </ref> suggests that low discrepancy algorithms are sometimes superior to Monte Carlo algorithms. However, a number of researchers, [14], [19], [20], report that their numerical tests show that this theoretical advantage decreases with increasing dimension. <p> problems where highly reliable results are needed. 3 Low Discrepancy Deterministic Algorithms In an attempt to avoid the deficiencies of the Monte Carlo algorithm, many deterministic algorithms have been proposed for computing high dimensional integrals for functions belonging to various subsets of L 2 (D), see e.g. [21], [22], [40], <ref> [43] </ref>, [23], and [37]. One class of such deterministic algorithms is based on low discrepancy sequences. First, we define discrepancy, which is a measure of deviation from uniformity of a sequence of points in D. <p> We approximate the integral of f from C d by the arithmetic mean of its values at x k , I (f ) = D 1 n X f (x k ); 8f 2 C d : Wozniakowski <ref> [43] </ref> relates the average case error of U n (f ) with the L 2 discrepancy, Z (I (f ) U n (f )) 2 w (df ) = D n (t; z 1 ; : : : ; z n )dt: (6) Thus, (3), (4), and (6) provide an average
Reference: [44] <author> Wozniakowski, H., </author> <title> Tractability and Strong Tractability of Linear Multivariate Problems, </title> <journal> J. Complexity, </journal> <volume> 10, </volume> <pages> 96-128, </pages> <year> 1994. </year> <month> 46 </month>
Reference-contexts: We stress that the constants in the bounds (3) and (4) depend on the dimension d and good estimates of these constants are not known. Bounds with known constants and n independent of d are studied in [42] and <ref> [44] </ref>. Sequences satisfying the upper bound in (4) are known as low discrepancy sequences or quasi-random sequences. We will refer to them as low discrepancy sequences or deterministic sequences.
References-found: 44

