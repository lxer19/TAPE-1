URL: http://www.cs.gatech.edu/gvu/animation/papers/yaleWorkshop.ps.gz
Refering-URL: http://www.cs.gatech.edu/gvu/animation/Areas/publications/publications.html
Root-URL: 
Title: Adapting Behaviors to New Environments, Characters, and Tasks  
Author: Nancy S. Pollard and Jessica K. Hodgins 
Affiliation: College of Computing and Graphics, Visualization and Usability Center  
Abstract: Animated characters and robots are exhibiting increasing levels of competence in complex tasks ranging from locomotion to juggling. One continuing challenge, however, is to develop behaviors that are robust with respect to variation in the environment, the character, and the task. Examples of a behavior (e.g. an individual performing a motion) are a rich source of information, but reliable techniques are needed to adapt examples to new situations. This paper describes how task information can be used to adapt existing examples to changes in the environment or to changes in the character's physical characteristics. Sets of rules for adapting or scaling examples to new situations allow a behavior to be described in a compact way, while also capturing some of the benefits of the information that may be contained in the examples. Results are shown for adapting example grasps to new object geometries and adapting dynamic behaviors to characters with differing physical characteristics. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. G. Atkeson, A. W. Moore, and S. Schaal. </author> <title> Locally weighted learning for control. </title> <journal> Artificial Intelligence Review, </journal> <note> (in press). </note>
Reference-contexts: One approach to this problem is to obtain a set of examples that completely spans the behavior space. In this case, relatively simple functions may be sufficient for interpolating between examples [26] <ref> [1] </ref> [29]. We may not always be able to generate or store a sufficiently large set of examples to obtain good results from simple interpolation functions, however. <p> A large amount of research has been done on memory-based or nonparamet-ric learning techniques [26] that compute a mapping from input data to output data based on a set of stored examples. Atkeson, Moore, and Schaal <ref> [1] </ref> review how memory-based learning has been used for motion control in robotics. In animation, Wiley and Hahn [29] have used interpolation between motion examples to generate reaching motions for an animated character.
Reference: [2] <author> C. G. Atkeson and S. Schaal. </author> <title> Robot learning from demonstration. </title> <booktitle> In International Conference on Machine Learning, </booktitle> <year> 1997. </year>
Reference-contexts: Because of this difficulty, it is important to understand how much information can be extracted from a single example. In previous work, Atkeson and Schaal <ref> [2] </ref> describe learning a pendulum swing-up task for a Sarcos robot arm based on a human demonstration of the same task; they also review related work on imitation learning for automatic robot programming.
Reference: [3] <author> N. A. Bernstein. </author> <title> On dexterity and its development. </title> <editor> In M. L. Latash and M. T. Turvey, editors, </editor> <booktitle> Dexterity and its Development. </booktitle> <publisher> Lawrence Erlbaum Associates, </publisher> <address> New Jersey, </address> <year> 1996. </year>
Reference-contexts: 1 Introduction Bernstein <ref> [3] </ref> describes dexterity as the ability to find a motor solution for any external situation, that is, to adequately solve any emerging motor problem correctly, quickly, rationally, and resourcefully. Dexterity in this sense is needed for autonomous characters or robots that will be placed in unpredictable environments.
Reference: [4] <author> B. M. Blumberg and T. A. Galyean. </author> <title> Multi-level direction of autonomous creatures for real-time virtual environments. </title> <booktitle> In SIGGRAPH 95 Proceedings, Annual Conference Series, </booktitle> <pages> pages 4754. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <month> July </month> <year> 1995. </year>
Reference-contexts: In the area of procedural approaches, Brooks [5] de scribes an architecture for constructing complex, reac-tive behaviors. A similar approach has been used by a number of researchers for creating autonomous animated creatures: Reynolds [24] developed flocking behaviors for groups of animated creatures; Blumberg and Galyean <ref> [4] </ref> describe a virtual creature that can either behave autonomously or be directed by a user; Tu and Ter-zopoulos [27] describe a set of integrated behaviors for artificial fish; and Perlin and Goldberg [20] describe a system for creating actors with distinct personalities that respond to users and to each other
Reference: [5] <author> R. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2(1):1423, </volume> <year> 1986. </year>
Reference-contexts: At a high level, these strategies can be divided into procedural, planning, and example-based approaches. In the area of procedural approaches, Brooks <ref> [5] </ref> de scribes an architecture for constructing complex, reac-tive behaviors.
Reference: [6] <author> A. Bruderlin and T. W. Calvert. </author> <title> Goal-directed, dynamic animation of human walking. </title> <booktitle> In Computer Graphics (SIGGRAPH 89 Proceedings), </booktitle> <volume> volume 23, </volume> <pages> pages 233 242, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Dynamically simulated behaviors for human motion [12] [32] <ref> [6] </ref> may function well over a wide range of user-specified parameters such as running velocity or jumping height, and behaviors such as balancing may be designed to be robust to unexpected disturbances.
Reference: [7] <author> A. Bruderlin and L. Williams. </author> <title> Motion signal processing. </title> <booktitle> In SIGGRAPH 95 Proceedings, Annual Conference Series, </booktitle> <pages> pages 97104. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Atkeson, Moore, and Schaal [1] review how memory-based learning has been used for motion control in robotics. In animation, Wiley and Hahn [29] have used interpolation between motion examples to generate reaching motions for an animated character. Unuma, Anjyo, and Takeuchi [28] and Bruderlin and Williams <ref> [7] </ref> use interpolation in the frequency domain to allow an animator to blend between different sets of experimental motion data to produce walking, running, and gestural motion with different styles. <p> In previous work, Atkeson and Schaal [2] describe learning a pendulum swing-up task for a Sarcos robot arm based on a human demonstration of the same task; they also review related work on imitation learning for automatic robot programming. In animation research, Bruderlin and Williams <ref> [7] </ref>, Witkin and Popovic [31], and Gleicher [10] provide interfaces to allow an animator to alter an example motion by modifying key poses within the motion sequence and specifying other constraints on the motion.
Reference: [8] <author> M. R. Cutkosky and R. D. Howe. </author> <title> Human grasp choice and robot grasp analysis. </title> <editor> In S.T. Venkataraman and T. Ib-erall, editors, </editor> <title> Dextrous Robot Hands. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: This approach could allow a compact representation of a space of grasps based on task and general object shape as seen in grasp taxonomies [19] <ref> [8] </ref>, while providing some guidance as to how the examples will need to be adjusted to fit new situations. <p> In grasping, examples could be used to cover the qualitatively different families of grasps that might be identified in a grasp taxonomy [19] <ref> [8] </ref>, and a force/torque analysis could be used to ensure that grasps can be adapted to changes in geometry for objects within the same family.
Reference: [9] <author> C. Ferrari and J. Canny. </author> <title> Planning optimal grasps. </title> <booktitle> In Proc. IEEE ICRA, </booktitle> <address> Nice, France, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The space of wrenches that can be achieved by a grasp is obtained by placing a limit on the sum of applied contact forces [13] <ref> [9] </ref> [16]. To achieve a grasp with the same quality as the example, a character could try to find points on the surface of a new object that allow it to make contact in a way that exactly matches the example grasp.
Reference: [10] <author> M. Gleicher. </author> <title> Motion editing with spacetime constraints. </title> <booktitle> In Proceedings of the 1997 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 139148, </pages> <address> Providence, RI, </address> <month> April </month> <year> 1997. </year>
Reference-contexts: In animation research, Bruderlin and Williams [7], Witkin and Popovic [31], and Gleicher <ref> [10] </ref> provide interfaces to allow an animator to alter an example motion by modifying key poses within the motion sequence and specifying other constraints on the motion. This paper adds to previous work by showing how task information can be used directly to adapt examples to new situations.
Reference: [11] <author> J. K. Hodgins and N. S. Pollard. </author> <title> Adapting simulated behaviors for new characters. </title> <booktitle> In SIGGRAPH 97 Proceedings, </booktitle> <pages> pages 153162. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <year> 1997. </year>
Reference-contexts: It may require measuring the motion of a number of differently sized actors, or it may require the talents of an experienced behavior designer or animator to create and fine-tune the motion for any new character. To begin to address these problems, Hodgins and Pol-lard <ref> [11] </ref> describe a technique that adapts an example behavior to the physical characteristics of a new character. This technique works by scaling control system parameters based on a dynamic analysis of the two characters. <p> This assumption, along with the requirement that we need coordinated motion (e.g. the arms cannot be swung with a frequency different from the legs) results in the scaling factors shown in the mass scaling column of Figure 3. Further details can be found in <ref> [11] </ref>. This technique has proven to be a good first step to scaling behaviors to new characters, but it is only an approximate scaling technique.
Reference: [12] <author> J. K. Hodgins, W. L. Wooten, D. C. Brogan, and J. F. O'Brien. </author> <title> Animating human athletics. </title> <booktitle> In SIGGRAPH 95 Proceedings, Annual Conference Series, </booktitle> <pages> pages 7178. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Dynamically simulated behaviors for human motion <ref> [12] </ref> [32] [6] may function well over a wide range of user-specified parameters such as running velocity or jumping height, and behaviors such as balancing may be designed to be robust to unexpected disturbances. <p> The goal is to adjust the control system parameters to achieve motion for the new character that has similar dynamic properties to that of the original. The animated behaviors used as examples were the running and cycling behaviors described in <ref> [12] </ref>. The animated motions were computed using dynamic simulation. <p> A description of the graphical and dynamic models and an overview of the control algorithms are given in <ref> [12] </ref>. For running and cycling, we had only a single example of each behavior, and we wanted to adapt the behavior to work for a variety of new characters, as shown in Figure 2.
Reference: [13] <author> D. G. Kirkpatrick, B. Mishra, and C. K. Yap. </author> <title> Quantitative steinitz's theorems with applications to multifin-gered grasping. </title> <booktitle> In Proc. 20th ACM Symposium on Theory of Computing, </booktitle> <address> Baltimore, Maryland, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: The space of wrenches that can be achieved by a grasp is obtained by placing a limit on the sum of applied contact forces <ref> [13] </ref> [9] [16]. To achieve a grasp with the same quality as the example, a character could try to find points on the surface of a new object that allow it to make contact in a way that exactly matches the example grasp.
Reference: [14] <author> Y. Koga, K. Kondo, J. Kuffner, and J. C. Latombe. </author> <title> Planning motions with intentions. </title> <booktitle> In SIGGRAPH 94 Proceedings, Annual Conference Series, </booktitle> <pages> pages 395408. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: An alternative approach to generating robust behaviors involves planning each new action based on the current situation, a set of constraints, and an evaluation function. This approach has been used widely for planning motions for robotics [15], and it has been applied to planning manipulation behaviors for animation <ref> [14] </ref>.
Reference: [15] <author> J. C. Latombe. </author> <title> Robot Motion Planning. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: An alternative approach to generating robust behaviors involves planning each new action based on the current situation, a set of constraints, and an evaluation function. This approach has been used widely for planning motions for robotics <ref> [15] </ref>, and it has been applied to planning manipulation behaviors for animation [14].
Reference: [16] <author> Z. Li and S. Sastry. </author> <title> Optimal grasping by multifingered robot hands. </title> <booktitle> In Proc. IEEE Intl. Conference on Robotics and Automation, </booktitle> <address> Raleigh, North Carolina, </address> <year> 1987. </year>
Reference-contexts: The space of wrenches that can be achieved by a grasp is obtained by placing a limit on the sum of applied contact forces [13] [9] <ref> [16] </ref>. To achieve a grasp with the same quality as the example, a character could try to find points on the surface of a new object that allow it to make contact in a way that exactly matches the example grasp.
Reference: [17] <author> Z. Liu, S. J. Gortler, and M. F. Cohen. </author> <title> Hierarchical spacetime control. </title> <booktitle> In SIGGRAPH 94 Proceedings, Annual Conference Series, </booktitle> <pages> pages 3542. </pages> <publisher> ACM SIG-GRAPH, ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: This approach has been used widely for planning motions for robotics [15], and it has been applied to planning manipulation behaviors for animation [14]. Also in the animation domain, trajectory optimization approaches [30] <ref> [17] </ref> [33] allow an animator to specify constraints on a motion (including key poses such as an initial and final pose) and an evaluation function such as minimum energy, and then compute the motion that minimizes the objective function while meeting the specified constraints.
Reference: [18] <author> T. A. McMahon. Muscles, Reflexes, </author> <title> and Locomotion. </title> <publisher> Princeton University Press, Princeton, </publisher> <year> 1984. </year>
Reference-contexts: This approach results in dynamically similar motion for the two characters, and it is consistent with models that have been explored for scaling properties in families of animals such as primates or ungulates, which may span up to three orders of magnitude in size <ref> [18] </ref>. In general, however, individuals will not be scale models of one another, and a geometric scaling approximation will not be adequate for generating motion for a new character. There are two problems with this approximation: * No single scale factor is adequate.
Reference: [19] <author> J. Napier. </author> <title> The prehensile movements of the human hand. </title> <journal> Journal of Bone and Joint Surgery, </journal> <volume> 38B(4), </volume> <year> 1956. </year>
Reference-contexts: This approach could allow a compact representation of a space of grasps based on task and general object shape as seen in grasp taxonomies <ref> [19] </ref> [8], while providing some guidance as to how the examples will need to be adjusted to fit new situations. <p> In grasping, examples could be used to cover the qualitatively different families of grasps that might be identified in a grasp taxonomy <ref> [19] </ref> [8], and a force/torque analysis could be used to ensure that grasps can be adapted to changes in geometry for objects within the same family.
Reference: [20] <author> K. Perlin and A. Goldberg. Improv: </author> <title> A system for scripting interactive actors in virtual worlds. </title> <booktitle> In SIGGRAPH 96 Proceedings, Annual Conference Series, pages 205216. ACM SIGGRAPH, </booktitle> <publisher> ACM Press, </publisher> <month> July </month> <year> 1996. </year>
Reference-contexts: creating autonomous animated creatures: Reynolds [24] developed flocking behaviors for groups of animated creatures; Blumberg and Galyean [4] describe a virtual creature that can either behave autonomously or be directed by a user; Tu and Ter-zopoulos [27] describe a set of integrated behaviors for artificial fish; and Perlin and Goldberg <ref> [20] </ref> describe a system for creating actors with distinct personalities that respond to users and to each other in a virtual environment.
Reference: [21] <author> N. S. Pollard. </author> <title> Synthesizing grasps from generalized prototypes. </title> <booktitle> In Proc. IEEE Intl. Conference on Robotics and Automation, </booktitle> <address> Minneapolis, Minnesota, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: This robot is performing a very similar task for each object, but the object geometry may change dramatically from one situation to the next. It would be nice to have a compact description of the grasp or set of grasps that can be used to perform this task. Pollard <ref> [21] </ref> [22] presents one method for adapting grasps to new object geometries. This technique assumes that a quality measure can be computed for any grasp. This quality measure is an approximation of the effort required to achieve a specified task. <p> This additional grasp capability can be exchanged for more flexibility in placing contacts on the surface of a new object. Details can be found in Pollard <ref> [21] </ref> [22], and Figure 1 shows an example: * Figure 1A shows an example grasp, a modeled grasp of a cylinder. * Seven contacts are extracted from this grasp, as shown in two views in Figure 1B.
Reference: [22] <author> N. S. Pollard. </author> <title> Parallel algorithms for synthesis of whole-hand grasps. </title> <booktitle> In Proc. IEEE Intl. Conference on Robotics and Automation, </booktitle> <address> Albuquerque, NM, </address> <year> 1997. </year>
Reference-contexts: It would be nice to have a compact description of the grasp or set of grasps that can be used to perform this task. Pollard [21] <ref> [22] </ref> presents one method for adapting grasps to new object geometries. This technique assumes that a quality measure can be computed for any grasp. This quality measure is an approximation of the effort required to achieve a specified task. <p> This additional grasp capability can be exchanged for more flexibility in placing contacts on the surface of a new object. Details can be found in Pollard [21] <ref> [22] </ref>, and Figure 1 shows an example: * Figure 1A shows an example grasp, a modeled grasp of a cylinder. * Seven contacts are extracted from this grasp, as shown in two views in Figure 1B. <p> This procedure guarantees that as long as a grasp contains one contact in each of these seven regions, the resulting grasp is guaranteed to be above some quality threshold. * A search process (described in <ref> [22] </ref>) found that the coordinate frame of the airplane had to be tilted with respect to that of the example cylinder in order to allow the fingers of the hand to wrap around the wings. The same search process selected the hand configuration shown in Figure 1D.
Reference: [23] <author> M. H. Raibert and J. K. Hodgins. </author> <title> Animation of dynamic legged locomotion. </title> <editor> In T. W. Sederberg, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH 91 Proceedings), </booktitle> <volume> volume 25, </volume> <pages> pages 349358, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: If the characters are scale models of each other, then a behavior for the new character can be obtained by scaling control system parameters of the original as described in Raibert and Hodgins <ref> [23] </ref>. Scale factors for a number of common control system parameters are shown in the geometric scaling column of Figure 3.
Reference: [24] <author> C. W. Reynolds. </author> <title> Flocks, herds, and schools: A distributed behavioral model. </title> <booktitle> In Computer Graphics (SIG-GRAPH 87 Proceedings), </booktitle> <volume> volume 21, </volume> <pages> pages 2534, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: At a high level, these strategies can be divided into procedural, planning, and example-based approaches. In the area of procedural approaches, Brooks [5] de scribes an architecture for constructing complex, reac-tive behaviors. A similar approach has been used by a number of researchers for creating autonomous animated creatures: Reynolds <ref> [24] </ref> developed flocking behaviors for groups of animated creatures; Blumberg and Galyean [4] describe a virtual creature that can either behave autonomously or be directed by a user; Tu and Ter-zopoulos [27] describe a set of integrated behaviors for artificial fish; and Perlin and Goldberg [20] describe a system for creating
Reference: [25] <author> S. Schaal, D. Sternad, and C. G. Atkeson. </author> <title> One-handed juggling: A dynamical approach to a rhythmic movement task. Journal of Motor Behavior, </title> <address> 28(2):165183, </address> <year> 1996. </year>
Reference-contexts: Perhaps force and acceleration analyses can be combined to develop better scaling laws for dynamic tasks involving interaction with the environment. There is some evidence that people make use of such scaling laws to achieve different goals. For example, Schaal, Sternad and Atkeson <ref> [25] </ref> suggest that a dynamic scaling relationship can be observed in the paddle motion of subjects asked to paddle-juggle a ball at three different heights. A similar approach could be used to animate tasks such as dribbling, catching, and throwing a basketball.
Reference: [26] <author> C. Stanfill and D. Waltz. </author> <title> Towards memory-based reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29(12):12131228, </volume> <year> 1986. </year>
Reference-contexts: One approach to this problem is to obtain a set of examples that completely spans the behavior space. In this case, relatively simple functions may be sufficient for interpolating between examples <ref> [26] </ref> [1] [29]. We may not always be able to generate or store a sufficiently large set of examples to obtain good results from simple interpolation functions, however. <p> This can be a difficult task for complex, coordinated behaviors such as walking or running. A third approach to generating robust behaviors involves interpolating between or extrapolating from existing examples of a behavior. A large amount of research has been done on memory-based or nonparamet-ric learning techniques <ref> [26] </ref> that compute a mapping from input data to output data based on a set of stored examples. Atkeson, Moore, and Schaal [1] review how memory-based learning has been used for motion control in robotics.
Reference: [27] <author> X. Tu and D. Terzopoulos. </author> <title> Artificial fishes: Physics, locomotion, perception, behavior. </title> <booktitle> In SIGGRAPH 94 Proceedings, Annual Conference Series, </booktitle> <pages> pages 4350. </pages> <publisher> ACM SIGGRAPH, ACM Press, </publisher> <month> July </month> <year> 1994. </year>
Reference-contexts: A similar approach has been used by a number of researchers for creating autonomous animated creatures: Reynolds [24] developed flocking behaviors for groups of animated creatures; Blumberg and Galyean [4] describe a virtual creature that can either behave autonomously or be directed by a user; Tu and Ter-zopoulos <ref> [27] </ref> describe a set of integrated behaviors for artificial fish; and Perlin and Goldberg [20] describe a system for creating actors with distinct personalities that respond to users and to each other in a virtual environment.
Reference: [28] <author> M. Unuma, K. Anjyo, and R. Takeuchi. </author> <title> Fourier principles for emotion-based human figure animation. </title> <booktitle> In SIGGRAPH 95 Proceedings, Annual Conference Series, </booktitle> <pages> pages 9196. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: Atkeson, Moore, and Schaal [1] review how memory-based learning has been used for motion control in robotics. In animation, Wiley and Hahn [29] have used interpolation between motion examples to generate reaching motions for an animated character. Unuma, Anjyo, and Takeuchi <ref> [28] </ref> and Bruderlin and Williams [7] use interpolation in the frequency domain to allow an animator to blend between different sets of experimental motion data to produce walking, running, and gestural motion with different styles.
Reference: [29] <author> D. J. Wiley and J. K. Hahn. </author> <title> Interpolation synthesis for articulated figure motion. </title> <booktitle> In VRAIS '97, </booktitle> <pages> pages 156160, </pages> <address> Albuquerque, New Mexico, </address> <year> 1997. </year>
Reference-contexts: One approach to this problem is to obtain a set of examples that completely spans the behavior space. In this case, relatively simple functions may be sufficient for interpolating between examples [26] [1] <ref> [29] </ref>. We may not always be able to generate or store a sufficiently large set of examples to obtain good results from simple interpolation functions, however. <p> Atkeson, Moore, and Schaal [1] review how memory-based learning has been used for motion control in robotics. In animation, Wiley and Hahn <ref> [29] </ref> have used interpolation between motion examples to generate reaching motions for an animated character.
Reference: [30] <author> A. Witkin and M. Kass. </author> <title> Spacetime constraints. </title> <editor> In J. Dill, editor, </editor> <booktitle> Computer Graphics (SIGGRAPH 88 Proceedings), </booktitle> <volume> volume 22, </volume> <pages> pages 159168, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: This approach has been used widely for planning motions for robotics [15], and it has been applied to planning manipulation behaviors for animation [14]. Also in the animation domain, trajectory optimization approaches <ref> [30] </ref> [17] [33] allow an animator to specify constraints on a motion (including key poses such as an initial and final pose) and an evaluation function such as minimum energy, and then compute the motion that minimizes the objective function while meeting the specified constraints.
Reference: [31] <author> A. Witkin and Z. Popovic. </author> <title> Motion warping. </title> <booktitle> In SIG-GRAPH 95 Proceedings, Annual Conference Series, </booktitle> <pages> pages 105108. </pages> <publisher> ACM SIGGRAPH, Addison Wesley, </publisher> <month> August </month> <year> 1995. </year>
Reference-contexts: In previous work, Atkeson and Schaal [2] describe learning a pendulum swing-up task for a Sarcos robot arm based on a human demonstration of the same task; they also review related work on imitation learning for automatic robot programming. In animation research, Bruderlin and Williams [7], Witkin and Popovic <ref> [31] </ref>, and Gleicher [10] provide interfaces to allow an animator to alter an example motion by modifying key poses within the motion sequence and specifying other constraints on the motion.
Reference: [32] <author> W. L. Wooten. </author> <title> Simulation of Leaping, Tumbling, Landing, and Balancing Humans. </title> <type> PhD thesis, </type> <institution> Georgia Institute of Technology, Department of Computer Science, </institution> <year> 1998. </year>
Reference-contexts: Dynamically simulated behaviors for human motion [12] <ref> [32] </ref> [6] may function well over a wide range of user-specified parameters such as running velocity or jumping height, and behaviors such as balancing may be designed to be robust to unexpected disturbances.
Reference: [33] <author> X. Zhao, D. Tolani, B. Ting, and N. I. Badler. </author> <title> Simulating human movements using optimal control. </title> <booktitle> In Euro-graphics Workshop on Computer Animation and Simulation '96, </booktitle> <pages> pages 109120, </pages> <year> 1996. </year>
Reference-contexts: This approach has been used widely for planning motions for robotics [15], and it has been applied to planning manipulation behaviors for animation [14]. Also in the animation domain, trajectory optimization approaches [30] [17] <ref> [33] </ref> allow an animator to specify constraints on a motion (including key poses such as an initial and final pose) and an evaluation function such as minimum energy, and then compute the motion that minimizes the objective function while meeting the specified constraints.
References-found: 33

