URL: http://www.cs.cmu.edu/~thrun/papers/thrun.ijcai95.ps.gz
Refering-URL: http://www.cs.cmu.edu/~thrun/papers/thrun.ijcai95.html
Root-URL: 
Title: Learning One More Thing  
Author: Sebastian Thrun Tom M. Mitchell 
Note: To appear in: Fourteenth International Joint Conference on Artificial Intelligence to be held in Montreal, Canada, August 20 to 25, 1995, Morgan Kaufmann Publisher  
Address: Romerstr. 164, D-53117 Bonn, Germany  Pittsburgh, PA 15213-3890, USA  
Affiliation: Universitat Bonn Institut fur Informatik III  School of Computer Science Carnegie Mellon University  
Abstract: Most research on machine learning has focused on scenarios in which a learner faces a single, isolated learning task. The lifelong learning framework assumes that the learner encounters a multitude of related learning tasks over its lifetime, providing the opportunity for the transfer of knowledge among these. This paper studies lifelong learning in the context of binary classification. It presents the invariance approach, in which knowledge is transferred via a learned model of the invariances of the domain. Results on learning to recognize objects from color images demonstrate superior generalization capabilities if invariances are learned and used to bias subsequent learning.
Abstract-found: 1
Intro-found: 1
Reference: [ Baxter, 1995 ] <author> J. Baxter. </author> <title> The canonical metric for vector quantization. </title> <note> submitted for publication, </note> <year> 1995. </year>
Reference-contexts: of an inductive learner can be found in [ Utgoff, 1986 ] , [ Ren-dell et al., 1987 ] , [ Suddarth and Kergosien, 1990 ] , [ Moore et al., 1992 ] , [ Sutton, 1992 ] , [ Caruana, 1993 ] , [ Pratt, 1993 ] , and <ref> [ Baxter, 1995 ] </ref> . Table 1 summarizes the problem definitions of the standard and the lifelong supervised learning problem. In lifelong supervised learning, the learner is given a collection Y of support sets, in addition to the training set X and the hypothesis space H. <p> is interpreted as a probability (of the event that i is positive under f fl ), Bayes' rule can be applied Prob (f fl 0 Y (i; i pos ) 1 1 Notice that in this approach, is similar to a distance metric that is obtained from the support sets <ref> [ Moore et al., 1992; Baxter, 1995 ] </ref> . The invariance network generalizes the notion of a distance metric, because the triangle inequality need not hold, and because an instance i pos can provide evidence that i is member of the opposite class (iff (i; i pos ) &lt; 0:5).
Reference: [ Caruana, 1993 ] <author> R. Caruana. </author> <title> Multitask learning: A knowledge-based of source of inductive bias. </title> <editor> In Paul E. Utgoff, editor, </editor> <booktitle> Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 41-48, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Other approaches that use related functions to change the bias of an inductive learner can be found in [ Utgoff, 1986 ] , [ Ren-dell et al., 1987 ] , [ Suddarth and Kergosien, 1990 ] , [ Moore et al., 1992 ] , [ Sutton, 1992 ] , <ref> [ Caruana, 1993 ] </ref> , [ Pratt, 1993 ] , and [ Baxter, 1995 ] . Table 1 summarizes the problem definitions of the standard and the lifelong supervised learning problem. <p> manages to extract useful invari-ance information in this domain, even if these invariances defy simple interpretation. 3.4 Using Support Sets as Hints A related family of methods for the transfer of knowledge across learning tasks are proposed in [ Suddarth and Kergosien, 1990 ] , [ Pratt, 1993 ] , <ref> [ Caruana, 1993 ] </ref> . In a nutshell, these approaches develop improved internal representations by considering multiple functions in F (sequentially, or simultaneously). Following these ideas, we trained a single classification network providing the support data as hints for the development of more appropriate internal representations.
Reference: [ Hild and Waibel, 1993 ] <author> H. Hild and A. Waibel. </author> <title> Multi-speaker/speaker-independent architectures for the multi-state time delay neural network. </title> <booktitle> In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages II 255-258. </pages> <publisher> IEEE, </publisher> <month> April </month> <year> 1993. </year>
Reference-contexts: In speaker-dependent approaches to speech recognition, learning to recognize personal speech is often done by speaker adaptation methods. Speaker adaptation simplifies the learning task by using knowledge learned from other, similar speakers (e.g., see <ref> [ Hild and Waibel, 1993 ] </ref> ).
Reference: [ Lando and Edelman, 1995 ] <author> M. Lando and S. Edelman. </author> <title> Generalizing from a single view in face recognition. </title> <type> Technical report, </type> <institution> Department of Applied Mathematics and Computer Science, The Weizmann Institute of Science, Rehovot 76100, Israel, </institution> <month> January </month> <year> 1995. </year> [ <note> Mitchell and Thrun, 1993 ] T.M. </note> <author> Mitchell and S. Thrun. </author> <title> Explanation-based neural network learning for robot control. </title> <editor> In S. J. Hanson, J. Cowan, and C. L. Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <pages> pages 287-294, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Here X k = fhi; f k (i)ig. Determine: a hypothesis h 2 H that minimizes X Prob (i) jjf fl (i) h (i)jj Table 1: Standard and lifelong supervised learning. Support sets can be useful in a variety of real-world scenarios. For example, in <ref> [ Lando and Edelman, 1995 ] </ref> an approach is proposed that improves the recognition rate of human faces based on knowledge learned by analyzing different views of other, related faces. In speaker-dependent approaches to speech recognition, learning to recognize personal speech is often done by speaker adaptation methods.
Reference: [ Moore et al., 1992 ] <author> A.W. Moore, D.J. Hill, and M.P. Johnson. </author> <title> An Empirical Investigation of Brute Force to choose Features, Smoothers and Function Approximators. </title> <editor> In S. Hanson, S. Judd, and T. Petsche, editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> Volume 3. </volume> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Other approaches that use related functions to change the bias of an inductive learner can be found in [ Utgoff, 1986 ] , [ Ren-dell et al., 1987 ] , [ Suddarth and Kergosien, 1990 ] , <ref> [ Moore et al., 1992 ] </ref> , [ Sutton, 1992 ] , [ Caruana, 1993 ] , [ Pratt, 1993 ] , and [ Baxter, 1995 ] . Table 1 summarizes the problem definitions of the standard and the lifelong supervised learning problem. <p> is interpreted as a probability (of the event that i is positive under f fl ), Bayes' rule can be applied Prob (f fl 0 Y (i; i pos ) 1 1 Notice that in this approach, is similar to a distance metric that is obtained from the support sets <ref> [ Moore et al., 1992; Baxter, 1995 ] </ref> . The invariance network generalizes the notion of a distance metric, because the triangle inequality need not hold, and because an instance i pos can provide evidence that i is member of the opposite class (iff (i; i pos ) &lt; 0:5).
Reference: [ O'Sullivan et al., 1995 ] <author> J. O'Sullivan, T.M. Mitchell, and S. Thrun. </author> <title> Explanation-based neural network learning from mobile robot perception. </title> <editor> In Katsushi Ikeuchi and Manuela Veloso, editors, </editor> <title> Symbolic Visual Learning. </title> <publisher> Oxford University Press, </publisher> <year> 1995. </year>
Reference-contexts: The robustness of EBNN to errors in estimated slopes has been verified empirically in robot navigation [ Mitchell and Thrun, 1993 ] and robot perception <ref> [ O'Sullivan et al., 1995 ] </ref> domains. 3 Example 3.1 The Domain: Object Recognition To illustrate the transfer of knowledge via the invariance network, we collected a database of 700 color camera images of seven different objects (100 images per object), as depicted in Fig. 2 (left columns).
Reference: [ Pratt, 1993 ] <author> L.Y. Pratt. </author> <title> Discriminability-based transfer between neural networks. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: related functions to change the bias of an inductive learner can be found in [ Utgoff, 1986 ] , [ Ren-dell et al., 1987 ] , [ Suddarth and Kergosien, 1990 ] , [ Moore et al., 1992 ] , [ Sutton, 1992 ] , [ Caruana, 1993 ] , <ref> [ Pratt, 1993 ] </ref> , and [ Baxter, 1995 ] . Table 1 summarizes the problem definitions of the standard and the lifelong supervised learning problem. <p> generalization accuracy show that EBNN manages to extract useful invari-ance information in this domain, even if these invariances defy simple interpretation. 3.4 Using Support Sets as Hints A related family of methods for the transfer of knowledge across learning tasks are proposed in [ Suddarth and Kergosien, 1990 ] , <ref> [ Pratt, 1993 ] </ref> , [ Caruana, 1993 ] . In a nutshell, these approaches develop improved internal representations by considering multiple functions in F (sequentially, or simultaneously).
Reference: [ Rendell et al., 1987 ] <author> L. Rendell, R. Seshu, and D. Tcheng. </author> <title> Layered concept-learning and dynamically-variable bias management. </title> <booktitle> In Proceedings of IJCAI-87, </booktitle> <pages> pages 308-314, </pages> <year> 1987. </year>
Reference: [ Simard et al., 1992 ] <author> P. Simard, B. Victorri, Y. LeCun, and J. Denker. </author> <title> Tangent prop a formalism for specifying selected invariances in an adaptive network. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 895-903, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kauf-mann. </publisher>
Reference-contexts: This algorithm is a special case of both the Tangent-Prop algorithm <ref> [ Simard et al., 1992 ] </ref> and the explanation-based neural network learning (EBNN) algorithm [ Mitchell and Thrun, 1993 ] . Here we will refer to it as EBNN. <p> Consequently, instead of fitting training examples of the type hi; f fl (i)i, EBNN fits training examples of the type hi; f fl (i); r i f fl (i)i: Gradient descent can be used to fit training examples of this type, as explained in <ref> [ Simard et al., 1992 ] </ref> . Fig. 1 illustrates the utility of this additional slope information in function fitting. Notice if multiple positive instances are available in X, slopes can be derived from each one.
Reference: [ Suddarth and Kergosien, 1990 ] <author> S.C. Suddarth and Y.L. Kergosien. </author> <title> Rule-injection hints as a means of improving network performance and learning time. </title> <booktitle> In Proceedings of the EURASIP Workshop on Neural Networks, </booktitle> <address> Sesimbra, Portugal, </address> <year> 1990. </year>
Reference-contexts: Other approaches that use related functions to change the bias of an inductive learner can be found in [ Utgoff, 1986 ] , [ Ren-dell et al., 1987 ] , <ref> [ Suddarth and Kergosien, 1990 ] </ref> , [ Moore et al., 1992 ] , [ Sutton, 1992 ] , [ Caruana, 1993 ] , [ Pratt, 1993 ] , and [ Baxter, 1995 ] . Table 1 summarizes the problem definitions of the standard and the lifelong supervised learning problem. <p> The invariance network was trained using the Back-Propagation algorithm 2 After training, the in 2 The classification accuracy of the invariance network was significantly improved using a technique described in <ref> [ Suddarth and Kergosien, 1990 ] </ref> . See [ Thrun and Mitchell, 1994 ] for details. <p> the clear correlation of slope magnitudes and generalization accuracy show that EBNN manages to extract useful invari-ance information in this domain, even if these invariances defy simple interpretation. 3.4 Using Support Sets as Hints A related family of methods for the transfer of knowledge across learning tasks are proposed in <ref> [ Suddarth and Kergosien, 1990 ] </ref> , [ Pratt, 1993 ] , [ Caruana, 1993 ] . In a nutshell, these approaches develop improved internal representations by considering multiple functions in F (sequentially, or simultaneously).
Reference: [ Sutton, 1992 ] <author> R.S. Sutton. </author> <title> Adapting bias by gradient descent: An incremental version of delta-bar-delta. </title> <booktitle> In Proceeding of Tenth National Conference on Artificial Intelligence AAAI-92, </booktitle> <pages> pages 171-176. </pages> <publisher> AAAI, AAAI Press/The MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Other approaches that use related functions to change the bias of an inductive learner can be found in [ Utgoff, 1986 ] , [ Ren-dell et al., 1987 ] , [ Suddarth and Kergosien, 1990 ] , [ Moore et al., 1992 ] , <ref> [ Sutton, 1992 ] </ref> , [ Caruana, 1993 ] , [ Pratt, 1993 ] , and [ Baxter, 1995 ] . Table 1 summarizes the problem definitions of the standard and the lifelong supervised learning problem.
Reference: [ Thrun and Mitchell, 1994 ] <author> S. Thrun and T.M. Mitchell. </author> <title> Learning one more thing. </title> <type> Technical Report CMU-CS-94-184, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA 15213, </address> <year> 1994. </year>
Reference-contexts: The invariance network was trained using the Back-Propagation algorithm 2 After training, the in 2 The classification accuracy of the invariance network was significantly improved using a technique described in [ Suddarth and Kergosien, 1990 ] . See <ref> [ Thrun and Mitchell, 1994 ] </ref> for details. <p> This effectively doubles the number of slopes considered in Eq. (5). The corresponding probabilities 1 (i; i neg ) can also be incorporated into Eq. (4). See <ref> [ Thrun and Mitchell, 1994 ] </ref> for details. The difference between the performance with and without support sets, which is statistically significant at the 95% level, can be assessed in several ways. In terms of residual error, Backpropagation exhibits a misclassification rate that is 60.1% larger than that of EBNN. <p> However, this assumption is not essential for the invariance approach. In principle, invariance functions may be defined for arbitrary, high-dimensional output spaces, given that a notion of difference between output vectors is available, as demonstrated in <ref> [ Thrun and Mitchell, 1994 ] </ref> . In the experiments reported above, all three assumptions were at least approximately fulfilled. We conjecture that the real world offers a variety of tasks where learned invariances can boost generalization.
Reference: [ Thrun and Mitchell, to appear ] <author> S. Thrun and T.M. Mitchell. </author> <title> Lifelong robot learning. </title> <journal> Robotics and Autonomous Systems, </journal> <note> to appear. Also appeared as Technical Report IAI-TR-93-7, </note> <institution> University of Bonn, Dept. of Computer Science III, </institution> <year> 1993. </year>
Reference-contexts: This example illustrates the idea of lifelong learning. In lifelong learning, a collection of related learning problems is encountered over the lifetime of the learner. When learning the n-th task, the learner may employ knowledge gathered in the previous n 1 tasks to improve its performance <ref> [ Thrun and Mitchell, to appear ] </ref> . This paper considers a particular form of lifelong learning in which the learning tasks correspond to learning boolean classifications (concepts), and in which previous experience consists of training examples of other classification functions from the same family F .
Reference: [ Utgoff, 1986 ] <author> P.E. Utgoff. </author> <title> Shift of bias for inductive concept learning. In R.S. </title> <editor> Michalski, J.G. Carbonell, and T.M. Mitchell, editors, </editor> <booktitle> Machine Learning: An Artificial Intelligence Approach, Volume II. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Speaker adaptation simplifies the learning task by using knowledge learned from other, similar speakers (e.g., see [ Hild and Waibel, 1993 ] ). Other approaches that use related functions to change the bias of an inductive learner can be found in <ref> [ Utgoff, 1986 ] </ref> , [ Ren-dell et al., 1987 ] , [ Suddarth and Kergosien, 1990 ] , [ Moore et al., 1992 ] , [ Sutton, 1992 ] , [ Caruana, 1993 ] , [ Pratt, 1993 ] , and [ Baxter, 1995 ] .
References-found: 14

