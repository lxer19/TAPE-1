URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/jpierce/www/publications/HCpaper.ps
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/jpierce/www/publications/publications.html
Root-URL: 
Title: Abstract  
Keyword: CR Categories and Subject Descriptors: I.3.6 [Computer Graphics]: Methodology and Techniques Interaction Techniques; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism Virtual Reality. Additional Keywords: virtual worlds, virtual environments, navigation, selection, manipulation.  
Abstract: This paper presents a set of interaction techniques for use in head-tracked immersive virtual environments. With these techniques, the user interacts with the 2D projections that 3D objects in the scene make on his image plane. The desktop analog is the use of a mouse to interact with objects in a 3D scene based on their projections on the monitor screen. Participants in an immersive environment can use the techniques we discuss for object selection, object manipulation, and user navigation in virtual environments. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. A. Bier, M. Stone, K. Pier, W. Buxton, and T. DeRose. Toolglass and Magic Lenses: </author> <title> The See Through Interface. </title> <booktitle> Proceedings of SIGGRAPH 1993, </booktitle> <pages> pages 73-80, </pages> <year> 1993. </year>
Reference-contexts: Possibilities include showing the object floating to the users hand or having it disappearing in a puff of smoke. We have also considered using this technique in conjunction with portals and mirrors <ref> [1] </ref>. We define a portal as a static or dynamic view into another scene or w orld.
Reference: [2] <author> Richard Bukowski and Carlo Sequin. </author> <title> Object Associations. </title> <booktitle> 1995 Symposium on Interactive 3D Graphics, </booktitle> <pages> pages 131-138., </pages> <year> 1995 </year>
Reference-contexts: Another option is to use object associations <ref> [2] </ref>. Because the 2D image plane displays the same image that a monitor on the desktop would, associations can be implemented as the y would be in desktop applications.
Reference: [3] <author> Scott Fisher, M. McGreevy, J. Humphries, and W. Robinett. </author> <title> Virtual Environment Display System. </title> <booktitle> 1986 Workshop on Interactive 3D Graphics, </booktitle> <pages> pages 77-87, </pages> <year> 1986. </year>
Reference-contexts: The NASA Ames VIEW system <ref> [3] </ref> demonstrated one of the f irst uses of the image plane to interact with a 3D scene while immersed. The VIEW system divided up the image plane into vie ws of different spaces within the virtual en vironment.
Reference: [4] <author> Andrew Forsberg, Kenneth Herndon, and Robert Zeleznik. </author> <title> Aperture Based Selection For Immersive Virtual Environments. </title> <booktitle> Proceedings of UIST 96, </booktitle> <pages> pages 95-96, </pages> <month> November </month> <year> 1996 </year>
Reference-contexts: For example, the user can select an object by touching it with his hand in the image or mo ve it around by pushing its image with his hand. The aperture based selection technique developed by Forsberg et al <ref> [4] </ref> performs the selection task through a hand held aperture. <p> These techniques also pro vide an orientation that can be used to disambiguate the users selection when there are a number of candidate objects with identifiable orientations. As suggested by Forsberg et al <ref> [4] </ref>, the object with the closest matching orientation in the users image plane can be chosen. The user s finger (s) provide this orientation for the Head Crusher , Sticky Finger, and Framing Hands techniques. <p> We place a constraint on the positions of the users hand and selected object in the 2D image so that they remain in the same position relative to each other on the image plane <ref> [4] </ref>. For example, if the user selects a distant b uilding with the Head Crusher technique the constraint will keep the building between the users fingers in the 2D image.
Reference: [5] <author> Michael Gleicher and Andrew Witkin. </author> <title> Through-The-Lens Camera Control. </title> <booktitle> Proceedings of SIGGRAPH 1992, </booktitle> <pages> pages 331-340, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The VIEW system divided up the image plane into vie ws of different spaces within the virtual en vironment. More recently, Michael Gleicher discussed the use of Through-the-Lens controls <ref> [5] </ref> on the desktop to constrain the position of an object on the image plane. Myron Krueger discussed how the VIDEOPLACE system [9] can use the users hands to select and manipulate objects in a 3D scene.
Reference: [6] <author> Ken Hinckley, Randy Pausch, John C. Goble, and Neal F. Kassel. </author> <title> A Survey Of Design Issues In Spatial Input. </title> <booktitle> Proceedings of UIST 94, </booktitle> <pages> pages 213-222, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: We will then present our techniques and discuss some of their advantages and disadvantages, and then close with a discussion of future work. 2 PREVIOUS WORK Physical intersection and laser pointing are tw o of the first techniques that researchers used in virtual en vironments for selection <ref> [6] </ref>. Ph ysical intersection has the dra wback that only objects within reach can be selected.
Reference: [7] <editor> The Kids in the Hall. </editor> <booktitle> Created by The Kids in the Hall comedy troupe. Prod. Lorne Michaels, CBC, </booktitle> <pages> 1988-1994. </pages>
Reference-contexts: the users size up or, equivalently, scaling the size of the en vironment down, the system limits the user to na vigating only to points that can be reached with a single gesture. 3 THE TECHNIQUES The techniques we present ha ve their roots in The Kids in the Hall <ref> [7] </ref>, a comedy show from the late 1980s. This show featured a sketch with a character who w ould pretend to crush peoples heads by positioning his victims head between the inde x finger and thumb of his outstretched hand (see Figure 2).
Reference: [8] <author> David Koller, Mark Mine, and Scott Hudson. </author> <title> Head-Tracked Orbital Viewing: An Interaction Technique For Immersive Virtual Environments. </title> <booktitle> Proceedings of UIST 96, </booktitle> <pages> pages 81-82, </pages> <month> November </month> <year> 1996. </year>
Reference-contexts: We can hold the distance of the user from the object constant to let the user orbit the object. K oller et al <ref> [8] </ref> ha ve implemented orbital viewing and ying techniques that allow a user to quickly move his viewpoint around an object.
Reference: [9] <editor> Myron W. Krueger, Thomas Gionfriddo, and Katrin Hinrichsen. </editor> <booktitle> Proceedings of SIGCHI 85, </booktitle> <pages> pages 35-40, </pages> <month> April </month> <year> 1985. </year>
Reference-contexts: More recently, Michael Gleicher discussed the use of Through-the-Lens controls [5] on the desktop to constrain the position of an object on the image plane. Myron Krueger discussed how the VIDEOPLACE system <ref> [9] </ref> can use the users hands to select and manipulate objects in a 3D scene. The user can interact with objects by changing the position of his hands relative to other objects in the image displayed on a large 2D screen (the image plane).
Reference: [10] <author> Jiandong Liang and Mark Green. JDCAD: </author> <title> A Highly Interactive 3D Modeling System. </title> <journal> Computers and Graphics, </journal> <pages> v18 n4 pages 499-506, </pages> <month> July/August </month> <year> 1994. </year>
Reference-contexts: Laser pointing solv es this problem, but a user can have difficulty selecting small objects at a distance with laser pointing because small hand motions result in large angular displacements for the laser selection spot when the objects pointed at are f ar away. The spotlight technique <ref> [10] </ref> uses a conic selection volume to address this problem.
Reference: [11] <institution> SmartScene TM is a product of MultiGen Inc. </institution> <note> More information on SmartScene TM is available from MultiGens website at http://www.multigen.com/smart.htm. </note>
Reference-contexts: The SmartScene TM system <ref> [11] </ref> includes some inno vative techniques for directed navigation. However, this system requires the user to directly touch his desired destination point in order to navigate to it.
Reference: [12] <author> Randall B. Smith. </author> <title> Experiences With The Alternate Reality Kit: An Example Of The Tension Between Literalism And Magic. </title> <booktitle> CHI+ GI 1987 Proceedings, </booktitle> <pages> pages 311-317, </pages> <year> 1987. </year> <title> an image plane up to f ill his view, a shot of the plane nearly filling his view, and the users new location after the plane has reached the his eye-point. </title>
Reference-contexts: his position after release so that the resized object will occupy the same size and position on his image plane. 6 DISCUSSION To use these image plane techniques, the user must be able to interpret what he sees as both a realistic 3D en vironment and a magical 2D picture <ref> [12] </ref>, and to mo ve freely between these interpretations. We feel that this transition is not nearly as cognitively taxing as it w ould first appear. Prior to implementing these techniques, we observed a user in a virtual environment trying to grab a distant object with his hand.
References-found: 12

