URL: http://www-ccs.cs.umass.edu/~jitu/publications/ms.ps
Refering-URL: http://www-ccs.cs.umass.edu/~jitu/publications.html
Root-URL: 
Title: Preemptive versus Non-Preemptive Processor Allocation Policies: An Empirical Comparison  
Author: Jitendra Padhye 
Keyword: multiprocessor, preemptive scheduling policies, adaptive scheduling policies, message passing architecture, Intel Paragon  
Date: August 31, 1995  
Abstract: When a parallel job arrives at a space-sharing multiprocessor system, a decision has to be made regarding the number and the specific identities of the allocated processors. A preemptive partitioning policy may preempt one or more of the currently running jobs to accommodate the new arrival. A non-preemptive policy may consider the state of the system at arrival time, however, it does not allow preemption of a job once the execution begins. In this paper preemptive and non-preemptive policies are presented and investigated experimentally. The performance of these policies are compared on the Intel Paragon. The workload model is based on matrix multiplication applications commonly found on large systems used for scientific applications. Results are reported for single and multiclass cases. A sensitivity analysis with respect to workload speedup characteristics is presented.
Abstract-found: 1
Intro-found: 1
Reference: [AMV93] <author> R. Agrawal, R.K. Mansharamani, </author> <title> M.K. Vernon, "Response time bounds for paral-lel processor allocation policies," </title> <type> Technical Report # 1152, </type> <institution> Computer Science Dept., Univeristy of Wisconsin, Madison, WI, </institution> <month> June </month> <year> 1993. </year>
Reference: [CMV94] <author> S.-H. Chiang, R.K. Mansharamani, </author> <title> M.K. Vernon, "Use of application characteristics and limited preemption for run-to-completion parallel processor scheduling policies," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1994, </year> <pages> pp. 33-44. </pages>
Reference: [EZL89] <author> D.L. Eager, J. Zahorjan, E.D. Lazowska, </author> <title> "Speedup versus efficiency in parallel sys-tems," </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol 38(3), </volume> <month> March </month> <year> 1989, </year> <pages> pp. 408-423. </pages>
Reference: [DCDP90] <author> K. Dussa, B.M. Carlson, L.W. Dowdy, K.-H. Park, </author> <title> "Dynamic partitioning in a transputer environment," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1990, </year> <pages> pp. 203-213. </pages>
Reference: [GST91] <author> D. Ghosal, G. </author> <title> Serazzi, S.K. Tripathi, "Processor working set and its use in scheduling multiprocessor systems," </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> Vol 17(5), </volume> <month> May </month> <year> 1991, </year> <pages> pp. 443-453. </pages>
Reference: [GTU91] <author> A. Gupta, A. Tucker, S. Urushibara, </author> <title> "The impact of operating system scheduling policies and synchronization methods on the performance of parallel applications," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1991, </year> <pages> pp. 120-132. </pages>
Reference-contexts: Detailed Markovian analysis to verify simulation models is possible only for small systems (i.e. less than 10 processors) [SRSDS94]. For larger systems, simplifying assumptions have to be made, resulting in a loss of accuracy. Experimental studies on preemptive processor partitioning policies have been done mainly for shared memory architectures <ref> [GTU91] </ref>. In this paper, experimental analysis of preemptive processor partitioning policies for a message passing architecture is presented. The primary objective of this study is an empirical analysis and comparison of performance of the preemptive and non- preemptive processor partitioning polices on a message passing architecture.
Reference: [Int93] <author> Intel Corporation, </author> <title> Paragon OSF/1 User's Guide, </title> <year> 1993. </year>
Reference-contexts: The results of the study are presented in Section 3. Section 4 presents conclusions and directions for future work. 2 2 Experimental Setup 2.1 The Intel Paragon This section briefly describes the architecture of the Paragon Supercomputer. A detailed description may be found in <ref> [Int93] </ref>. An Intel Paragon Supercomputer consists of several nodes 1 connected in a mesh configuration. The computer used for this study has 66 nodes connected in a 11 by 6 matrix. Several other nodes are dedicated to special tasks such as disk and network control.
Reference: [Klei75] <author> L. </author> <title> Kleinrock, </title> <journal> Queueing Systems, </journal> <volume> Vol 1, </volume> <publisher> Wiley Interscience, </publisher> <year> 1975. </year>
Reference: [LV90] <author> S.T. </author> <title> Leutenegger, M.K. Vernon, "The performance of multiprogrammed multiprocessor scheduling policies," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1990, </year> <pages> pp. 226-236. </pages>
Reference: [MEB88] <author> S. Majumdar, D.L. Eager, R.B. Bunt, </author> <title> "Scheduling in multiprogrammed parallel sys-tems," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1988, </year> <pages> pp. 104-113. 29 </pages>
Reference: [MEB91] <author> S. Majumdar, D.L. Eager, R.B. Bunt, </author> <title> "Characterization of programs for scheduling in multiprogrammed parallel systems," </title> <journal> Performance Evaluation, </journal> <volume> Vol 13(2), </volume> <year> 1991, </year> <pages> pp. 109-130. </pages>
Reference: [MVZ93] <author> C. McCann, R. Vaswani, and J. Zahorjan, </author> <title> "A dynamic processor allocation policy for multiprogrammed shared memory multiprocessors," </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> Vol 11(2), </volume> <month> February </month> <year> 1993, </year> <pages> pp. 146-178. </pages>
Reference: [MZ94] <author> C. McCann, J. Zahorjan, </author> <title> "Processor allocation policies for message-passing parallel computers," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1994, </year> <pages> pp. 19-32. </pages>
Reference-contexts: In this paper preemptive and non-preemptive space sharing policies are considered. Under preemptive policies, parallel programs can be stopped during execution to allow for resource redistribution according to changing system loads. Time-sharing polices are inherently preemptive in nature. Several space-sharing preemptive policies have also been proposed <ref> [TG89, MZ94] </ref>. Performance analysis of preemptive space sharing scheduling policies has been largely based on simulation studies and Markovian analysis of small systems. For a simulation study to be accurate and realistic, detailed knowledge of various parameters of the system under consideration is necessary. <p> The primary objective of this study is an empirical analysis and comparison of performance of the preemptive and non- preemptive processor partitioning polices on a message passing architecture. To this end, two preemptive processor partitioning policies based on techniques proposed in <ref> [MZ94] </ref> and one non- preemptive robust adaptive policy presented in [RSDSC94] are implemented on the Intel Paragon. Two workload programs are used to compare the behavior of the implemented scheduling policies. One is a synthetic workload program designed to emulate various speedup curves and other characteristics of common scientific applications. <p> Thus, preemptive scheduling policies can adapt quickly adapt to transient changes in the workload flow. The two preemptive processor partitioning policies considered in this study are based on the policies proposed in <ref> [MZ94] </ref>. Both the preemptive scheduling policies are implemented around a standard interface. The interface consists of six reserved message id numbers, two data structures and three library routines that are incorporated into the workload programs. The interface is independent of the workload and the scheduling algorithm involved. <p> The LOSER jobs, on the other hand, have already finished their data redistribution. After receiving the RESTART message, the jobs resume their normal execution. 2.3.1 Equipartitioning Equipartitioning is the most natural and intuitive preemptive scheduling policy. The policy is proposed in <ref> [MZ94] </ref>. The policy tries to equally allocate the available processors among all jobs that are present in the system. On each new arrival or departure, all the currently executing jobs are preempted. <p> A combination of the two above. Preemptions are restricted such that each job is preempted no more than a certain predefined number of times and no more than a certain number of jobs are active at any time. 8 2.3.2 Folding The Folding policy is proposed in <ref> [MZ94] </ref>. The policy, as described in the paper, is rather difficult to implement due to complicated partition movements such as rotation, in which partition sizes of neighboring jobs are compared and depending on the ratio, partition size for some jobs is doubled while it is halved for some others. <p> Also, the results of <ref> [MZ94] </ref> suggest that a long interval between successive rotations leads to better performance. Hence, rather than implementing the policy as described in the paper, a variation is implemented as follows. At each new arrival, the scheduler checks to see if there are any free processors. <p> The workload is capable of of spawning as many tasks as the number of allocated processors <ref> [MZ94] </ref>. When the workload is started on a given partition, the lowest numbered node in the partition is selected as the "co-ordinator". The workload operates in phases. Each phase consists of three subphases, namely, the broadcast communication subphase, the compute subphase and the collect communication subphase.
Reference: [Oust82] <author> J. Ousterhout, </author> <title> "Scheduling techniques for concurrent systems," </title> <booktitle> Proc. 3rd International Conference on Distributed Computing Systems, </booktitle> <year> 1982, </year> <pages> pp. 22-30. </pages>
Reference: [PD89] <author> K.-H. Park, L.W. Dowdy, </author> <title> "Dynamic partitioning of multiprocessor systems," </title> <journal> International Journal of Parallel Programming, </journal> <volume> Vol 18(2), </volume> <year> 1989, </year> <pages> pp. 91-120. </pages>
Reference: [RSDSC94] <author> E. Rosti, E. Smirni, L.W. Dowdy, G. Serazzi, B.M. Carlson, </author> <title> "Robust partitioning policies for multiprocessor systems," </title> <journal> Performance Evaluation, </journal> <volume> Vol 19(2-3), </volume> <month> March </month> <year> 1994, </year> <pages> pp. 141-165. </pages>
Reference-contexts: To this end, two preemptive processor partitioning policies based on techniques proposed in [MZ94] and one non- preemptive robust adaptive policy presented in <ref> [RSDSC94] </ref> are implemented on the Intel Paragon. Two workload programs are used to compare the behavior of the implemented scheduling policies. One is a synthetic workload program designed to emulate various speedup curves and other characteristics of common scientific applications. <p> Although the machine is capable of supporting MIMD (or MPMD) computing models, most applications use the SPMD model for computing. The workloads for this study use the SPMD model. 2.2 Non-Preemptive Policies The Robust Adaptive (RA) scheduling policy is proposed and discussed in <ref> [RSDSC94] </ref>. RA actually represents a suit of scheduling policies rather than a single scheduling algorithm. The version chosen here is representative and has been used in subsequent studies [SRSDS94]. RA is a non-preemptive scheduling policy.
Reference: [SST93] <author> S.K. Setia, </author> <title> M.S. Squillante, S.K. Tripathi, "Processor scheduling in multiprogrammed, distributed memory parallel computers," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1993, </year> <pages> pp. 158170. </pages>
Reference: [Sev89] <author> K.C. Sevcik, </author> <title> "Characterization of parallelism in applications and their use in schedul-ing," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1989, </year> <pages> pp. 171-180. </pages>
Reference: [Sev94] <author> K.C. Sevcik, </author> <title> "Application scheduling and processor allocation in multiprogrammed multiprocessors," </title> <journal> Performance Evaluation, </journal> <volume> Vol 19(2-3), </volume> <month> March </month> <year> 1994, </year> <pages> pp. 107-140. </pages>
Reference: [SRDS93] <author> E. Smirni, E. Rosti, L.W. Dowdy, G. </author> <title> Serazzi, "Evaluation of Multiprocessor Allocation Policies," </title> <type> Tech. Report, </type> <institution> Computer Science Dept., Vanderbilt University, Nashville, TN, </institution> <month> August </month> <year> 1993. </year>
Reference: [TG89] <author> A. Tucker, A. Gupta, </author> <title> "Process control and scheduling issues for multiprogrammed shared-memory multiprocessors," </title> <booktitle> Proc. of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <year> 1989, </year> <pages> pp. 159-166. </pages>
Reference-contexts: In this paper preemptive and non-preemptive space sharing policies are considered. Under preemptive policies, parallel programs can be stopped during execution to allow for resource redistribution according to changing system loads. Time-sharing polices are inherently preemptive in nature. Several space-sharing preemptive policies have also been proposed <ref> [TG89, MZ94] </ref>. Performance analysis of preemptive space sharing scheduling policies has been largely based on simulation studies and Markovian analysis of small systems. For a simulation study to be accurate and realistic, detailed knowledge of various parameters of the system under consideration is necessary.
Reference: [ZM90] <author> J. Zahorjan, C. McCann, </author> <title> "Processor scheduling in shared memory multiprocessors," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1990, </year> <pages> pp. 214-225. </pages>
Reference: [ZB91] <author> S. Zhou, T. Brecht, </author> <title> "Processor pool-based scheduling for large-scale NUMA multipro-cessors," </title> <booktitle> Proc. ACM SIGMETRICS, </booktitle> <year> 1991, </year> <pages> pp. 133-142. </pages>
Reference: [SRSDS94] <author> E. Smirni E. Smirni, E. Rosti, G. Serazzi, L. W. Dowdy, K. C. </author> <title> Sevcik "Performance Gains from Leaving Idle Processors in Multiprocessor Systems" Proc. </title> <booktitle> International Conference on Parallel Processing, </booktitle> <year> 1995. </year> <month> 30 </month>
Reference-contexts: For a heavily used system it is not uncommon to have several parallel jobs waiting to use the multiprocessor. In such cases, performance can be improved by sharing the multiprocessor among all or some of the waiting jobs <ref> [SRSDS94] </ref>. This can be achieved via either space sharing or time sharing. Under space sharing scheduling polices, an incoming job is assigned to a subset of the total available processors. Thus, multiple jobs can be active within the multiprocessor at the same time. <p> For a simulation study to be accurate and realistic, detailed knowledge of various parameters of the system under consideration is necessary. Also, validation of the the simulation models is difficult. Detailed Markovian analysis to verify simulation models is possible only for small systems (i.e. less than 10 processors) <ref> [SRSDS94] </ref>. For larger systems, simplifying assumptions have to be made, resulting in a loss of accuracy. Experimental studies on preemptive processor partitioning policies have been done mainly for shared memory architectures [GTU91]. In this paper, experimental analysis of preemptive processor partitioning policies for a message passing architecture is presented. <p> RA actually represents a suit of scheduling policies rather than a single scheduling algorithm. The version chosen here is representative and has been used in subsequent studies <ref> [SRSDS94] </ref>. RA is a non-preemptive scheduling policy. Once a job is scheduled on a partition, it executes on the same partition without any further interruption from the scheduler until completion. The policy is called an adaptive policy because it adapts to load changes over a period of time.
Reference: [BMSD95] <author> J. Brehm, M. Madhukar, E. Smirni, L. W. Dowdy, </author> <title> "PerPreT A performance pre--diction tool for massively parallel systems," </title> <booktitle> To appear in Int. Conf. on Modelling Techniques and Tools for Computer Performance Evaluation, </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: The other workload program is based on a parallel, preemptable, distributed memory version of a matrix conjugate gradient program. This program is representative of typical scientific workloads and has been used for similar purposes in the past <ref> [BMSD95] </ref>. Both the workload programs interface with the scheduling programs via a set of standardized subroutines. This allows for a fair and uniform comparison of the performance of the scheduling polices under consideration. The rest of the paper is organized as follows. <p> Computation versus communication costs and preemption overheads are easily adjustable. The second workload is based on the Conjugate Gradient method for matrices. The program is a representative example of the scientific workload and has been used for similar purposes in other studies <ref> [BMSD95] </ref>. The 4 This arrival sequence does not necessarily represent the same jobs as in the sequence for the RA or equipartitioning policies. A similar time line has been maintained for easy comparison. 9 10 program is modified to make it capable of running under a preemptive scheduler. <p> The circles indicate the complexity of each stage. The values at the arrows represents the number of data items transmitted. The program consist of several phases in each iteration. A brief explanation of each phase follows. A more detailed description may be found in <ref> [BMSD95] </ref>. * CP1: Distributed computation of a scalar vector product. * CM1: Global collect of a distributed vector using tree topology. * CP2: No computations. * CM2: Global broadcast of the collected vector using tree topology. 13 * CP3: Distributed computation of a matrix vector product. * CM3: Global sum using
Reference: [PICL] <author> G. Geist, M. Heath, B. Peyton, P. Worley, "PICL, </author> <title> A PORTABLE INSTRUMENTED COMMUNICATION LIBRARY, C REFERENCE MANUAL" Oak Ridge National Laboretory. </title> <type> 31 </type>
References-found: 26

