URL: ftp://ftp.eecs.umich.edu/people/huffman/papers/aaai94.ps.Z
Refering-URL: http://ai.eecs.umich.edu/people/laird/airesearch.html
Root-URL: 
Email: huffman@umich.edu  
Title: Learning from highly flexible tutorial instruction  
Author: Scott B. Huffman and John E. Laird 
Note: In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), July 1994,  
Address: 1101 Beal Ave. Ann Arbor, Michigan 48109-2110  Seattle, WA.  
Affiliation: Artificial Intelligence Laboratory The University of Michigan  
Abstract: Situated, interactive tutorial instructions give flexibility in teaching tasks, by allowing communication of a variety of types of knowledge in a variety of situations. To exploit this flexibility, however, an instructable agent must be able to learn different types of knowledge from different instructional interactions. This paper presents an approach to learning from flexible tutorial instruction, called situated explanation, that takes advantage of constraints in different instructional contexts to guide the learning process. This makes it applicable to a wide range of instructional interactions. The theory is implemented in an agent called Instructo-Soar, that learns new tasks and other domain knowledge from natural language instructions. Instructo-Soar meets three key requirements of flexible instructability: it can (A) take any command at each instruction point, (B) handle instructions that apply to either the current situation or a hypothetical one (e.g., conditionals), and (C) learn each type of knowledge it uses (derived from its underlying computational model) from instructions. An earlier version of this paper appeared in Proceedings of the 8th Banff Knowledge Acquisition for Knowledge-Based Systems Workshop (KAW-94), ed. B. Gaines and M. Musen, February 1994. 
Abstract-found: 1
Intro-found: 1
Reference: [Bloom, 1984] <author> B. Bloom. </author> <title> The 2 sigma problem: The search for methods of group instruction as effective as one-to-one tutoring. </title> <editor> Ed. Researcher, </editor> <volume> 13(6) </volume> <pages> 4-16, </pages> <year> 1984. </year>
Reference-contexts: While working on tasks, the student may receive instruction as needed to complete tasks or to understand aspects of the domain or of previous instructions. This situated, interactive form of instruction produces very strong human learning <ref> [Bloom, 1984] </ref>. Thus, although it has received scant attention in AI, tutorial instruction has the potential to be a powerful knowledge source for intelligent agents.
Reference: [DiEugenio, 1993] <author> B. DiEugenio. </author> <title> Understanding NL Instructions: A computational approach to purpose clauses. </title> <type> PhD thesis, </type> <institution> Univ. of Pennsylvania, </institution> <year> 1993. </year>
Reference: [Gruber, 1989] <author> T. Gruber. </author> <title> Automated knowledge acquisition for strategic knowledge. </title> <booktitle> Machine Learning, </booktitle> <address> 4(3-4):293-336, </address> <year> 1989. </year>
Reference: [Huffman and Laird, 1993] <author> S. Huffman and J. Laird. </author> <title> Learning procedures from interactive natural language instructions. </title> <booktitle> In Machine Learning: Proc's. 10th Intl. Conference, </booktitle> <year> 1993. </year>
Reference: [Huffman, 1994] <author> S. Huffman. </author> <title> Instructable Autonomous Agents. </title> <type> PhD thesis, </type> <institution> Univ. of Michi-gan, </institution> <month> January </month> <year> 1994. </year> <month> 11 </month>
Reference-contexts: B. Situation flexibility. The instructor should be free to use instructions that apply to either the current task situation, or some hypothetical situation specified by the instruction. 1 Implicitly situated instructions apply to the current situation (e.g., commands: "Close the door") <ref> [Huffman, 1994] </ref>. Explicitly situated instructions explicitly indicate aspects of a hypothetical situation they apply to (e.g., conditionals: "If the power is low, turn off the machine"). These are especially useful for teaching contingencies that have not come up during ongoing task performance (perhaps rare or dangerous ones). C. Knowledge-type flexibility. <p> Each LAS has learned particular types of knowledge: e.g., opera 1 Human instructors use both of these options. In one protocol, for instance, 119 out of 508 instructions (23%) involved hypothetical situations, with the remainder applying to the current situation when given <ref> [Huffman, 1994] </ref>. 2 Because tutorial instructions provide knowledge for particular situations, they are best for teaching tasks with local control structure (e.g., serial constructive tasks). <p> As an evaluation criterion for instructable agents, we have developed a set of requirements for a "complete tutorable agent" <ref> [Huffman, 1994] </ref>. This paper focuses on three key requirements; there are eleven in all. Instructo-Soar meets seven of the eleven either fully or partially. The unmet requirements provide impetus for further work. First, a complete tutorable agent must deal with instructions in all their linguistic complexity.
Reference: [Kodratoff and Tecuci, 1987] <author> Y. Kodratoff and G. </author> <title> Tecuci. Techniques of design and DISCI--PLE learning apprentice. </title> <journal> Intl. J. Expert Systems, </journal> <volume> 1(1) </volume> <pages> 39-66, </pages> <year> 1987. </year>
Reference-contexts: Local decisions can combine to exhibit global control behavior [Yost and Newell, 1989], but teaching a global method as a sequence of local decisions is difficult. Thus, we focus on learning knowledge for tasks involving local control. 1 tor implementations [Mitchell et al., 1990], goal decomposition rules <ref> [Kodratoff and Tecuci, 1987] </ref>, operational versions of functional goals [Segre, 1987], control knowledge/features [Gru-ber, 1989], heuristic classification knowledge [Wilkins, 1990], etc. Flexible tutorial instruction extends LAS's interaction and learning abilities in a number of ways.
Reference: [Laird et al., 1987] <author> J. Laird, A. Newell, and P. Rosenbloom. </author> <title> Soar: An architecture for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 33(1) </volume> <pages> 1-64, </pages> <year> 1987. </year>
Reference-contexts: We present a learning approach called situated explanation (an extension of EBL) that utilizes the situation an instruction applies to and the larger instructional context to guide the learning process. The approach is implemented in an instructable agent called Instructo-Soar, built within Soar <ref> [Laird et al., 1987] </ref>. Huffman and Laird [1993] described how Instructo-Soar supports (A) command flexibility, learning hierarchies of new tasks, and extending tasks to new situations, given imperative natural language commands like those at the top of (C) knowledge-type flexibility.
Reference: [Laird et al., 1990] <author> J. Laird, M. Hucka, E. Yager, and C. Tuck. </author> <title> Correcting and extending domain knowledge using outside guidance. </title> <booktitle> In Proc. 7th Intl. Conf. on Machine Learning, </booktitle> <year> 1990. </year>
Reference: [Mitchell et al., 1990] <author> T. Mitchell, S. Mahadevan, and L. Steinberg. </author> <title> LEAP: A learning apprentice system for VLSI design. </title> <editor> In Y. Kodratoff and R. Michalski, editors, </editor> <title> Machine learning: An AI approach, Vol. III. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: In this paper, we focus specifically on three crucial requirements of flexible instructability: A. Command flexibility. The instructor should be free to give any appropriate commands to teach a task. Commands should not be limited to only directly performable/observable actions (as in <ref> [Redmond, 1992; Mitchell et al., 1990; Segre, 1987] </ref>), but may request unknown procedures or actions that cannot be performed until after other actions. B. Situation flexibility. <p> Thus, the agent must be able to learn any type of knowledge it uses to perform tasks (control knowledge, knowledge about objects/properties, knowledge of actions' effects, etc.) from instruction. 2 An agent that learns from tutorial instruction is a type of learning apprentice system (LAS) <ref> [Mitchell et al., 1990] </ref>. <p> Local decisions can combine to exhibit global control behavior [Yost and Newell, 1989], but teaching a global method as a sequence of local decisions is difficult. Thus, we focus on learning knowledge for tasks involving local control. 1 tor implementations <ref> [Mitchell et al., 1990] </ref>, goal decomposition rules [Kodratoff and Tecuci, 1987], operational versions of functional goals [Segre, 1987], control knowledge/features [Gru-ber, 1989], heuristic classification knowledge [Wilkins, 1990], etc. Flexible tutorial instruction extends LAS's interaction and learning abilities in a number of ways.
Reference: [Newell et al., 1990] <author> A. Newell, G. Yost, J. Laird, P. Rosenbloom, and E. Altmann. </author> <title> Formulating the problem space computational model. </title> <booktitle> In Proc. 25th Anniversary Symposium, </booktitle> <institution> CMU School of Computer Science, </institution> <year> 1990. </year>
Reference-contexts: We have identified the knowledge types used in our agent by examining its underlying computational model, called the problem space computational model (PSCM) <ref> [Newell et al., 1990; Yost and Newell, 1989] </ref>. The PSCM is a general formulation of the computation in a knowledge-level agent, and many applications have been built within it [Rosenbloom et al., 1993].
Reference: [Porter and Kibler, 1986] <author> B. Porter and D. Kibler. </author> <title> Experimental goal regression: A method for learning problem-solving heuristics. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 249-286, </pages> <year> 1986. </year>
Reference: [Redmond, 1992] <author> M. </author> <title> Redmond. Learning by observing and understanding expert problem solving. </title> <type> PhD thesis, </type> <institution> Georgia Tech, </institution> <year> 1992. </year>
Reference-contexts: In this paper, we focus specifically on three crucial requirements of flexible instructability: A. Command flexibility. The instructor should be free to give any appropriate commands to teach a task. Commands should not be limited to only directly performable/observable actions (as in <ref> [Redmond, 1992; Mitchell et al., 1990; Segre, 1987] </ref>), but may request unknown procedures or actions that cannot be performed until after other actions. B. Situation flexibility.
Reference: [Rosenbloom and Laird, 1986] <author> P. Rosenbloom and J. Laird. </author> <title> Mapping EBG onto Soar. </title> <booktitle> In AAAI-86, </booktitle> <year> 1986. </year>
Reference-contexts: By indicating the features of I, S, and G causally required for success, 5 M K . the explanation allows the agent to learn general knowledge from I (as in standard EBL, realized in our agent by Soar's chunking mechanism <ref> [Rosenbloom and Laird, 1986] </ref>).
Reference: [Rosenbloom et al., 1993] <author> P. Rosenbloom, J. Laird, and A. </author> <title> Newell, </title> <editor> editors. </editor> <booktitle> The Soar Papers: Research on integrated intelligence. </booktitle> <publisher> MIT Press, </publisher> <year> 1993. </year>
Reference-contexts: The PSCM is a general formulation of the computation in a knowledge-level agent, and many applications have been built within it <ref> [Rosenbloom et al., 1993] </ref>. Because its components approximate the knowledge-level, the PSCM is an apt choice for identifying an agent's knowledge types. 4 Soar is a symbol-level implementation of the PSCM.
Reference: [Segre, 1987] <author> A. Segre. </author> <title> A learning apprentice system for mechanical assembly. </title> <booktitle> In IEEE Conf. on AI for Applications, </booktitle> <pages> pages 112-117, </pages> <year> 1987. </year>
Reference-contexts: In this paper, we focus specifically on three crucial requirements of flexible instructability: A. Command flexibility. The instructor should be free to give any appropriate commands to teach a task. Commands should not be limited to only directly performable/observable actions (as in <ref> [Redmond, 1992; Mitchell et al., 1990; Segre, 1987] </ref>), but may request unknown procedures or actions that cannot be performed until after other actions. B. Situation flexibility. <p> Thus, we focus on learning knowledge for tasks involving local control. 1 tor implementations [Mitchell et al., 1990], goal decomposition rules [Kodratoff and Tecuci, 1987], operational versions of functional goals <ref> [Segre, 1987] </ref>, control knowledge/features [Gru-ber, 1989], heuristic classification knowledge [Wilkins, 1990], etc. Flexible tutorial instruction extends LAS's interaction and learning abilities in a number of ways. First, the instructor may specify unknown tasks or tasks with unachieved preconditions at any instruction point (requirement A).
Reference: [VanLehn et al., 1992] <author> K. VanLehn, R. Jones, and M. Chi. </author> <title> A model of the self-explanation effect. </title> <journal> J. of the Learning Sciences, </journal> <volume> 2(1) </volume> <pages> 1-59, </pages> <year> 1992. </year>
Reference-contexts: Or, (O2-O3) it could try to complete the explanation now, by learning the missing knowledge somehow. The missing knowledge could be learned (O2) inductively (e.g. by inducing over the "gap" in the explanation, as in <ref> [VanLehn et al., 1992] </ref> and many others), or, (O3) in an instructable agent's case, through further instruction. Finally, (O4) it could abandon the explanation altogether, and try to induce the desired knowledge instead. Given only an incomplete explanation, it would be difficult to choose which option to follow.
Reference: [VanLehn, 1987] <author> K. VanLehn. </author> <title> Learning one subprocedure per lesson. </title> <journal> Artificial Intelligence, </journal> <volume> 31(1) </volume> <pages> 1-40, </pages> <year> 1987. </year>
Reference: [Wilkins, 1990] <author> D. Wilkins. </author> <title> Knowledge base refinement as improving an incomplete and incorrect domain theory. </title> <editor> In Y. Kodratoff and R. Michalski, editors, </editor> <title> Machine learning: An AI approach, Volume III. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Thus, we focus on learning knowledge for tasks involving local control. 1 tor implementations [Mitchell et al., 1990], goal decomposition rules [Kodratoff and Tecuci, 1987], operational versions of functional goals [Segre, 1987], control knowledge/features [Gru-ber, 1989], heuristic classification knowledge <ref> [Wilkins, 1990] </ref>, etc. Flexible tutorial instruction extends LAS's interaction and learning abilities in a number of ways. First, the instructor may specify unknown tasks or tasks with unachieved preconditions at any instruction point (requirement A).
Reference: [Yost and Newell, 1989] <author> G. Yost and A. Newell. </author> <title> A problem space approach to expert system specification. </title> <booktitle> In IJCAI-89, </booktitle> <year> 1989. </year> <month> 12 </month>
Reference-contexts: Local decisions can combine to exhibit global control behavior <ref> [Yost and Newell, 1989] </ref>, but teaching a global method as a sequence of local decisions is difficult. <p> We have identified the knowledge types used in our agent by examining its underlying computational model, called the problem space computational model (PSCM) <ref> [Newell et al., 1990; Yost and Newell, 1989] </ref>. The PSCM is a general formulation of the computation in a knowledge-level agent, and many applications have been built within it [Rosenbloom et al., 1993].
References-found: 19

