URL: http://www.cs.cmu.edu/~qma/sigmetrics.ps
Refering-URL: http://www.cs.cmu.edu/~qma/Publications.html
Root-URL: 
Email: qma@cs.cmu.edu  kkrama@research.att.com  
Title: Queue Management for Explicit Rate Based Congestion Control  
Author: Qingming Ma K. K. Ramakrishnan 
Address: Pittsburgh, PA 15213, USA  600 Mountain Avenue Murray Hill, NJ 07974, USA  
Affiliation: Computer Science Department Carnegie Mellon University  AT&T Labs. Research  
Abstract: Rate based congestion control has been considered desirable, both to deal with the high bandwidth-delay products of today's high speed networks, and to match the needs of emerging multimedia applications. Explicit rate control achieves low loss because sources transmit smoothly at a rate adjusted through feedback to be within the capacity of the resources in the network. However, large feedback delays, presence of higher priority traffic, and varying transient situations make it difficult to ensure feasibility (i.e., keep the aggregate arrival rate below the bottleneck resource's capacity) while also maintaining high resource utilization. These conditions along with the "fast start" desired by data applications often result in substantial queue buildups. We describe a scheme that manages the queue buildup at a switch even under the most aggressive patterns of sources, in the context of the Explicit Rate option for the Available Bit Rate (ABR) congestion control scheme. A switch observes the buildup of its queue, and uses it to reduce the portion of the link capacity allocated to sources bottlenecked at that link. We use the concept of a "virtual" queue, which tracks the amount of queue that has been "reduced", but has not yet taken effect at the switch. We take advantage of the natural timing of "resource management" (RM) cells transmitted by sources. The scheme is elegant in that it is simple, and we show that it reduces the queue buildup, in some cases, by more than two orders of magnitude and the queue size remains around a desired target. It maintains max-min fairness even when the queue is being drained. The scheme is scalable, and is as responsive as can be expected: within the constraints of the feedback delay. Finally, no changes are needed to the ATM Forum defined source/destination policies. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bolot, J.-C., Udaya Shankar, A., </author> <title> "Analysis of a Fluid Approximation to flow control dynamics", </title> <booktitle> Proc. Infocom '92, </booktitle> <address> Florence, Italy, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: This effect in the oscillation of the queue size has been examined using differential equations by <ref> [1] </ref>. The reduction of the rate of the sources needs to be implemented such that we do not overcorrect and experience underutilization of the link.
Reference: [2] <author> Bertsekas, D., Gallager, R., </author> <title> Data Networks, ch. 6, </title> <publisher> Prentice Hall, </publisher> <address> Englwood Cliffs, N.J., </address> <year> 1992. </year>
Reference-contexts: VCs are classified as being either "satisfied" (in set S) or "bottlenecked". The capacity C of the link is allocated to bottlenecked VCs as: A B = P N jjSjj (1) A global procedure performing the maxmin computation is described in <ref> [2, 4] </ref>. Since we perform an incremental calculation upon the arrival of an RM cell, the A i for V C i is equal to the "demand" seen in the ER field of the RM cell.
Reference: [3] <author> Charny, A., Clark, D.D., Jain R., </author> <title> "Congestion Control With Explicit Rate Indication", </title> <booktitle> Proc. </booktitle> <address> ICC'95, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: With even a small excess in the source rate, it can cause a substantial queue buildup. The ABR service can ensure a particular notion of fairness|max-min fairness [4, 12], which requires a distributed computation <ref> [3] </ref>. An incremental computation that scales with the number of connections is described in [9]. The incremental computation of source rates can potentially result in the rates being infeasible for short intervals (often one round-trip time). <p> Motivated by a desire to keep queues small, RIF is often chosen to be small (we make observations on this "typical" choice later). 2.2 The Switch Allocation Algorithm There are several switch algorithms proposed for computing the rate to be allocated to a VC <ref> [3, 13, 9, 7] </ref>. Switches compute an allocated rate for each VC i, based on its requested rate (value in the ER-field) A i . VCs are classified as being either "satisfied" (in set S) or "bottlenecked".
Reference: [4] <author> Charny A., Ramakrishnan, K.K., and Lauck, A., </author> <title> "Time Scale Analysis and Scalability Issues for Explicit Rate Allocation in ATM Networks" IEEE/ACM Transactions on Networking, </title> <month> August </month> <year> 1996. </year>
Reference-contexts: With even a small excess in the source rate, it can cause a substantial queue buildup. The ABR service can ensure a particular notion of fairness|max-min fairness <ref> [4, 12] </ref>, which requires a distributed computation [3]. An incremental computation that scales with the number of connections is described in [9]. The incremental computation of source rates can potentially result in the rates being infeasible for short intervals (often one round-trip time). <p> One way to ensure feasibility is to force a source being allowed to increase its rate to delay any increase until all other sources have received and implemented their decreases. Thus, the aggregate rate at a given link will never exceed its capacity <ref> [4] </ref>. This method introduces considerable delay to sources when they start up or when they are asked to increase their rate, thus impacting applications (and user--perceived performance) adversely. It also may lead to un-derutilization of resources. <p> The build-up of the queues during this transient period cannot be avoided even by schemes that are extremely conservative in ensuring feasibility. Unlike the scheme proposed in <ref> [4] </ref>, the ATM Forum's ABR service attempts to maintain feasibility and avoid a large queue buildup by picking conservative values for the "increase parameter", RIF and the initial cell rate ICR [14]. We show that even a small ICR and RIF , can still result in substantial queue buildups. <p> VCs are classified as being either "satisfied" (in set S) or "bottlenecked". The capacity C of the link is allocated to bottlenecked VCs as: A B = P N jjSjj (1) A global procedure performing the maxmin computation is described in <ref> [2, 4] </ref>. Since we perform an incremental calculation upon the arrival of an RM cell, the A i for V C i is equal to the "demand" seen in the ER field of the RM cell.
Reference: [5] <author> Clark, D., Shenker, S., Zhang, L., </author> <title> "Supporting real-time applications in an integrated services packet network: architecture and mechanism", </title> <booktitle> Proceedings of ACM Sigcomm '92, </booktitle> <pages> pp., </pages> <month> Sept. </month> <year> 1992. </year>
Reference-contexts: When a cell (let us consider it to be the "marked" arrival) arrives at a non-empty queue subsequent arrivals to different queue can cause additional delay for the marked arrival before it is served. This behavior is similar to that observed in <ref> [5] </ref>. In our situation, the additional delay experienced by RM cells of an existing long VC which already has a reasonable queue at a switch is of concern.
Reference: [6] <author> Jacobson, V., </author> <title> "Congestion Avoidance and Control", </title> <booktitle> Proceedings of of ACM Sigcomm '88, </booktitle> <address> pp.314-329, </address> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: The smooth flow of data packets in response to the arrival of acknowledgements is disturbed in cases where there is ack-compression [16, 15], new flows starting up, or when multiple flows recover from packet loss, and go into slow-start <ref> [6] </ref>. Moreover, allowing the applications to "fast-start", i.e., to transmit as fast as reasonable upon startup, is desirable for many data applications.
Reference: [7] <author> Jain, R., Kalyanaraman, S., Vishwanathan, R., Goyal, R., </author> <title> "A Sample Switch Algorithm", AF-TM 95-0178R1, ATM Forum Traffic Management Working Group, </title> <month> Feb. </month> <year> 1995. </year>
Reference-contexts: Motivated by a desire to keep queues small, RIF is often chosen to be small (we make observations on this "typical" choice later). 2.2 The Switch Allocation Algorithm There are several switch algorithms proposed for computing the rate to be allocated to a VC <ref> [3, 13, 9, 7] </ref>. Switches compute an allocated rate for each VC i, based on its requested rate (value in the ER-field) A i . VCs are classified as being either "satisfied" (in set S) or "bottlenecked". <p> Another alternative is to allocate only a portion of the actual available link capacity to the requesting VCs, and maintaining a reserve for draining the queue <ref> [7] </ref>. Firstly, the capacity available is potentially changing frequently, and even maintaining a reserve does not guarantee feasibility at all times. Secondly, we believe a goal of utilizing all of the available bandwidth is a desirable one, especially when there is little or no queueing in the network. <p> If we decide how much capacity to use based solely on the size of actual queue, it causes under-utilization, oscillations of the queue or takes a very long time to drain the queue because of a very conservative setting of the parameters. This distinguishes our work from <ref> [7] </ref>. The approach we use exploits the fact that all the sources participate in the algorithm that maintains max-min fair rates, so that the aggregate rate remains "feasible" (i.e., does not exceed the capacity of any resource in the network).
Reference: [8] <author> Jain, R., Kalyanaraman, S., Goyal, R., Fahmy, S., Vish-wanathan, R., </author> <title> "ERICA Switch Algorithm: A Complete Description," AF-TM 96-11721, ATM Forum Traffic Management Working Group, </title> <month> August </month> <year> 1996. </year>
Reference-contexts: Related work has been described in the recent past to manage queue build-up <ref> [8] </ref>. In broad terms, most of the techniques suggested achieve a low buffer occupancy by keeping the utilization of the link below the full capacity (e.g., having a target utilization of 95%).
Reference: [9] <author> Kalampoukas, L., Varma A., Ramakrishnan, K.K. </author> <title> "An Efficient Rate Allocation Algorithm for ATM Networks Providing Max-Min Fairness", </title> <booktitle> Proceedings of 6th IFIP International Conf. on High Performance Networking, </booktitle> <address> HPN '95, Palma De Mallorca, Balearic Islands, Spain, </address> <month> Sept. </month> <pages> 11-15, </pages> <year> 1995. </year>
Reference-contexts: With even a small excess in the source rate, it can cause a substantial queue buildup. The ABR service can ensure a particular notion of fairness|max-min fairness [4, 12], which requires a distributed computation [3]. An incremental computation that scales with the number of connections is described in <ref> [9] </ref>. The incremental computation of source rates can potentially result in the rates being infeasible for short intervals (often one round-trip time). Varying feedback delays that result in asynchronous updates to source rates make the control of this period of infeasibility difficult to predict. <p> We seek to maintain the link utilization at the maximum (i.e., 100%), except when we need to reduce the buildup queue. Moreover, we attempt to do this while maintaining exact max-min fairness and the feature of constant-time computation of max-min fairness described in <ref> [9] </ref>. The next section describes the operation of the feedback control mechanism, for both the source and switch policies. Section 3 motivates the problem of queue buildup under a variety of scenarios. <p> Motivated by a desire to keep queues small, RIF is often chosen to be small (we make observations on this "typical" choice later). 2.2 The Switch Allocation Algorithm There are several switch algorithms proposed for computing the rate to be allocated to a VC <ref> [3, 13, 9, 7] </ref>. Switches compute an allocated rate for each VC i, based on its requested rate (value in the ER-field) A i . VCs are classified as being either "satisfied" (in set S) or "bottlenecked".
Reference: [10] <author> P. Mishra., H. </author> <title> Kanakia "A Hop by Hop Rate-based Congestion Control Scheme", </title> <booktitle> Proceedings of ACM SIGCOMM '92 Conference, </booktitle> <year> 1992. </year>
Reference-contexts: In the following sections we propose such a mechanism and show that the queue buildup can be dramatically reduced in all of the scenarios we have observed up to now. The hop-by-hop mechanism in <ref> [10] </ref> adjusts the upstream node's rate in response to queue occupancy information. Its goal is to maintain a target buffer-occupancy (set-point) at each node. <p> buildup, while minimizing link under-utilization, and avoid oscillations in the source rate and the queue size while draining the queue. * Maintain Max-Min Fair share allocation consistently, even during the periods when the queue is being drained. 4.2 Details of the Algorithm We use the concept of a target set-point <ref> [10] </ref> for the queue size at an individual link, above which we begin to perform the function required to reduce the queue. The queue reduction is achieved by modifying the proportion of the link capacity available to be allocated among the competing sources.
Reference: [11] <author> K. K. Ramakrishnan, Raj Jain, </author> <title> "A Binary Feedback Scheme for Congestion Avoidance in Computer Networks with a Connectionless Network Layer", </title> <booktitle> Proceedings of of ACM Sig-comm '88, </booktitle> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: This virtual queue is used to determine how much longer the rate reduction has to be applied. A regeneration cycle for the queue length is similar to that discussed in <ref> [11] </ref>. The start and end points of the regeneration cycle are when the queue transitions the set point, S (and we also start a new cycle when the actual queue exceeds the virtual queue). We reduce the allocated rate on an individual VC basis.
Reference: [12] <author> K.K.Ramakrishnan, Raj Jain, Dah-Ming Chiu. </author> <title> "Congestion Avoidance in Computer Networks With a Connec-tionless Network Layer. Part IV: A Selective Binary Feedback Scheme for General Topologies", </title> <institution> DEC-TR-510, Digital Equipment Corporation, </institution> <year> 1987. </year>
Reference-contexts: With even a small excess in the source rate, it can cause a substantial queue buildup. The ABR service can ensure a particular notion of fairness|max-min fairness <ref> [4, 12] </ref>, which requires a distributed computation [3]. An incremental computation that scales with the number of connections is described in [9]. The incremental computation of source rates can potentially result in the rates being infeasible for short intervals (often one round-trip time). <p> A straightforward computation of the local maxmin fair share (denoted A B ) can be described as follows <ref> [12] </ref>: 1. Initialization: S = ;, j = 0. 2. A j B & i 2 Sg. j+1 P i2S A i )=(N jjSjj). 4. If 9i 62 S, A i &lt; A B then j j + 1; go to step 2. 5.
Reference: [13] <author> L. Roberts, </author> <title> "Enchanced PRCA (Proportional Rate Control Algorithm)", </title> <address> AF-TM 94-0735R1, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Motivated by a desire to keep queues small, RIF is often chosen to be small (we make observations on this "typical" choice later). 2.2 The Switch Allocation Algorithm There are several switch algorithms proposed for computing the rate to be allocated to a VC <ref> [3, 13, 9, 7] </ref>. Switches compute an allocated rate for each VC i, based on its requested rate (value in the ER-field) A i . VCs are classified as being either "satisfied" (in set S) or "bottlenecked".
Reference: [14] <author> Sathaye, S.S., </author> <title> "ATM Forum Traffic Management Specification Version 4.0" (draft), AF-TM 95-0013R10, ATM Forum Traffic Management Working Group, </title> <month> Feb., </month> <year> 1996. </year>
Reference-contexts: Rate based congestion control has been considered desirable to achieve high performance over high speed networks that are characterized by large bandwidth-delay products. Its potential to achieve low loss by maintaining a smooth flow of data with its source rate being adjusted through a feedback mechanism <ref> [14] </ref> allows intermediate systems (switches) to have relatively small buffers while still maintaining high utilizations. In contrast, although window flow control has undergone several refinements to also maintain a smooth even flow of data, there are several conditions during which window flow control results in bursty arrivals into the network. <p> Unlike the scheme proposed in [4], the ATM Forum's ABR service attempts to maintain feasibility and avoid a large queue buildup by picking conservative values for the "increase parameter", RIF and the initial cell rate ICR <ref> [14] </ref>. We show that even a small ICR and RIF , can still result in substantial queue buildups. We first study the queue behavior in detail and show how and to what degree queues can build up. <p> On reaching its destination, the RM cell is returned to the source, which now sets its transmit rate based on the ER-field value in the returned RM cell and a specified policy. 2.1 The Source Algorithm The source policies are a simplified version of <ref> [14] </ref>, where the primary properties of the feedback control loop have been implemented, without incorporating all the issues relating to the boundary and failure cases. Sources maintain a DEMAND (for data sources this may be the outgoing link's rate), used for requesting a rate from the network. <p> The control of the transmission rates is still the same as with the distributed explicit rate control mechanism. An additional attractiveness is that there is no change required to the current specification for the ATM Forum specified source-destination policies <ref> [14] </ref>. 4.1 Design Goals We manage the queue at an intermediate switch instead of at the end system, since this is where the queue is built up. The broad goals that we have for the algorithm to manage queue are the following: * Allow sources to start-up aggressively.
Reference: [15] <author> Wilder, R., Ramakrishnan, K. K., Mankin, A., </author> <title> "Dynamics of Congestion Control and Avoidance of Two-Way Traffic in an OSI Testbed", </title> <journal> ACM Computer Communication Review, </journal> <volume> Vol. 21, </volume> <pages> No.2, </pages> <address> pp.43-58, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The smooth flow of data packets in response to the arrival of acknowledgements is disturbed in cases where there is ack-compression <ref> [16, 15] </ref>, new flows starting up, or when multiple flows recover from packet loss, and go into slow-start [6]. Moreover, allowing the applications to "fast-start", i.e., to transmit as fast as reasonable upon startup, is desirable for many data applications.

References-found: 15

