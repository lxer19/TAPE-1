URL: ftp://ftp.cs.toronto.edu/pub/zoubin/fhmmML.ps.gz
Refering-URL: http://www.cs.utoronto.ca/~zoubin/
Root-URL: 
Title: Machine Learning,  Factorial Hidden Markov Models  
Author: ZOUBIN GHAHRAMANI MICHAEL I. JORDAN Editor: Padhraic Smyth 
Keyword: Hidden Markov models, time series, EM algorithm, graphical models, Bayesian networks, mean field theory  
Address: Toronto, Toronto, ON M5S 3H5, Canada  Cambridge, MA 02139, USA  
Affiliation: Department of Computer Science, University of  Department of Brain Cognitive Sciences, Massachusetts Institute of Technology,  
Note: c 1997 Kluwer Academic Publishers, Boston. Manufactured in The Netherlands.  
Pubnum: 29,  
Email: zoubin@cs.toronto.edu  jordan@psyche.mit.edu  
Date: 245-275 (1997)  
Abstract: Hidden Markov models (HMMs) have proven to be one of the most widely used tools for learning probabilistic models of time series data. In an HMM, information about the past is conveyed through a single discrete variable|the hidden state. We discuss a generalization of HMMs in which this state is factored into multiple state variables and is therefore represented in a distributed manner. We describe an exact algorithm for inferring the posterior probabilities of the hidden state variables given the observations, and relate it to the forward-backward algorithm for HMMs and to algorithms for more general graphical models. Due to the combinatorial nature of the hidden state representation, this exact algorithm is intractable. As in other intractable systems, approximate inference can be carried out using Gibbs sampling or variational methods. Within the variational framework, we present a structured approximation in which the the state variables are decoupled, yielding a tractable algorithm for learning the parameters of the model. Empirical comparisons suggest that these approximations are efficient and provide accurate alternatives to the exact methods. Finally, we use the structured approximation to model Bach's chorales and show that factorial HMMs can capture statistical structure in this data set which an unconstrained HMM cannot. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Baum, L., Petrie, T., Soules, G., & Weiss, N. </author> <year> (1970). </year> <title> A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains. </title> <journal> The Annals of Mathematical Statistics, </journal> <volume> 41, </volume> <pages> 164-171. </pages>
Reference-contexts: GHAHRAMANI AND M.I. JORDAN 3.1. The EM algorithm The parameters of a factorial HMM can be estimated via the expectation maximization (EM) algorithm (Dempster, Laird, & Rubin, 1977), which in the case of classical HMMs is known as the Baum-Welch algorithm <ref> (Baum, Petrie, Soules, & Weiss, 1970) </ref>.
Reference: <author> Bengio, Y., & Frasconi, P. </author> <year> (1995). </year> <title> An input-outputHMM architecture. </title> <editor> In G. Tesauro, D. S. Touret-zky, & T. K. Leen (Eds.), </editor> <booktitle> Advances in neural information processing systems 7, </booktitle> <pages> pp. 427-434. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Cacciatore, T. W., & Nowlan, S. J. </author> <year> (1994). </year> <title> Mixtures of controllers for jump linear and non-linear plants. </title> <editor> In J. D. Cowan, G. Tesauro, & J. Alspector (Eds.), </editor> <booktitle> Advances in neural information processing systems 6, </booktitle> <pages> pp. 719-726. </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Conklin, D., & Witten, I. H. </author> <year> (1995). </year> <title> Multiple viewpoint systems for music prediction. </title> <journal> Journal of New Music Research, </journal> <volume> 24, </volume> <pages> 51-73. </pages>
Reference: <author> Cover, T., & Thomas, J. </author> <year> (1991). </year> <title> Elements of information theory. </title> <address> New York: </address> <publisher> John Wiley. </publisher>
Reference-contexts: The difference between the left-hand side and the right-hand side of this inequality is given by the Kullback-Leibler divergence <ref> (Cover & Thomas, 1991) </ref>: KL (QkP ) = fS t g P (fS t gjfY t g) The complexity of exact inference in the approximation given by Q is determined by its conditional independence relations, not by its parameters.
Reference: <author> Dawid, A. P. </author> <year> (1992). </year> <title> Applications of a general propagation algorithm for probabilistic expert systems. </title> <journal> Statistics and Computing, </journal> <volume> 2, </volume> <pages> 25-36. </pages>
Reference-contexts: This can be achieved via the Viterbi (1967) algorithm, a form of dynamic programming that is very closely related to the forward-backward algorithm and also has analogues in the graphical model literature <ref> (Dawid, 1992) </ref>. The learning problem for probabilistic models consists of two components: learning the structure of the model and learning its parameters. Structure learning is a topic of current research in both the graphical model and machine learning communities (e.g. Heckerman, 1995; Stolcke & Omohundro, 1993).
Reference: <author> Dean, T., & Kanazawa, K. </author> <year> (1989). </year> <title> A model for reasoning about persistence and causation. </title> <booktitle> Computational Intelligence, </booktitle> <pages> 5 , 142-150. </pages>
Reference: <author> Dempster, A., Laird, N., & Rubin, D. </author> <year> (1977). </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society Series B, </journal> <volume> 39, </volume> <pages> 1-38. </pages>
Reference-contexts: Heckerman, 1995; Stolcke & Omohundro, 1993). In the current paper we deal exclusively with the problem of learning the parameters for a given structure. 250 Z. GHAHRAMANI AND M.I. JORDAN 3.1. The EM algorithm The parameters of a factorial HMM can be estimated via the expectation maximization (EM) algorithm <ref> (Dempster, Laird, & Rubin, 1977) </ref>, which in the case of classical HMMs is known as the Baum-Welch algorithm (Baum, Petrie, Soules, & Weiss, 1970).
Reference: <author> Geman, S., Bienenstock, E., & Doursat, R. </author> <year> (1992). </year> <title> Neural networks and the bias/variance dilemma. </title> <journal> Neural Computation, </journal> <volume> 4, </volume> <pages> 1-58. </pages>
Reference: <author> Geman, S., & Geman, D. </author> <year> (1984). </year> <title> Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 6, </volume> <pages> 721-741. </pages>
Reference-contexts: Although there are many possible sampling schemes (for a review see Neal, 1993), here we present one of the simplest|Gibbs sampling <ref> (Geman & Geman, 1984) </ref>. For a given observation sequence fY t g, this procedure starts with a random setting of the hidden states fS t g. <p> Assuming that all probabilities are bounded away from zero, this Markov chain is guaranteed to converge to the 252 Z. GHAHRAMANI AND M.I. JORDAN posterior probabilities of the states given the observations <ref> (Geman & Geman, 1984) </ref>. Thus, after some suitable time, samples from the Markov chain can be taken as approximate samples from the posterior probabilities.
Reference: <author> Ghahramani, Z. </author> <year> (1995). </year> <title> Factorial learning and the EM algorithm. </title> <editor> In G. Tesauro, D. S. Touret-zky, & T. K. Leen (Eds.), </editor> <booktitle> Advances in neural information processing systems 7, </booktitle> <pages> pp. 617-624. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Heckerman, D. (1995.). </author> <title> A tutorial on learning Bayesian networks. </title> <type> (Technical Report MSR-TR-95-06). </type> <institution> Redmond, WA: Microsoft Research. </institution>
Reference: <author> Hinton, G. E., & Sejnowski, T. J. </author> <year> (1986). </year> <title> Learning and relearning in Boltzmann machines. </title> <editor> In D. E. Rumelhart & J. L. McClelland (Eds.), </editor> <booktitle> Parallel distributed processing: Explorations in the microstructure of cognition. Volume 1: Foundations. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: While the Jensen, Lauritzen and Olesen (1990) algorithm can still be used to propagate information exactly in chain graphs, such undirected links cause the normalization constant of the probability distribution|the partition function|to depend on the coupling parameters. As in Boltzmann machines <ref> (Hinton & Sejnowski, 1986) </ref>, both a clamped and an unclamped phase are therefore required for learning, where the goal of the unclamped phase is to compute the derivative of the partition function with respect to the parameters (Neal, 1992). 5.3. <p> Comparisons between these likelihoods are meaningful, whereas to obtain the absolute cost of coding a sequence, it is necessary to specify a discretization level. 10. This is analogous to the fully-connected Boltzmann machine with N units <ref> (Hinton & Sejnowski, 1986) </ref>, in which every binary unit is coupled to every other unit using O (N 2 ) parameters, rather than the O (2 N ) parameters required to specify the complete probability table.
Reference: <author> Hinton, G. E., & Zemel, R. S. </author> <year> (1994). </year> <title> Autoencoders, minimum description length, and Helmholtz free energy. </title> <editor> In J. D. Cowan, G. Tesauro, & J. Alspector (Eds.), </editor> <booktitle> Advances in neural information processing systems 6, </booktitle> <pages> pp. 3-10. </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Jensen, F. V., Lauritzen, S. L., & Olesen, K. G. </author> <year> (1990). </year> <title> Bayesian updating in recursive graphical models by local computations. </title> <journal> Computational Statistical Quarterly, </journal> <volume> 4, </volume> <pages> 269-282. </pages> <note> 274 Z. </note> <author> GHAHRAMANI AND M.I. JORDAN Jordan, M. I., Ghahramani, Z., & Saul, L. K. </author> <year> (1997). </year> <title> Hidden Markov decision trees. </title> <editor> In M. Mozer, M. Jordan, & T. Petsche (Eds.), </editor> <booktitle> Advances in neural information processing systems 9. </booktitle> <address> Cam-bridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: The relation between hidden Markov models and graphical models has recently been reviewed in Smyth, Heckerman and Jordan (1997). Although exact probability propagation algorithms exist for general graphical models <ref> (Jensen, Lauritzen, & Olesen, 1990) </ref>, these algorithms are intractable for densely-connected models such as the ones we consider in this paper. One approach to dealing with this issue is to utilize stochastic sampling methods (Kanazawa et al., 1995).
Reference: <author> Jordan, M. I., & Jacobs, R. </author> <year> (1994). </year> <title> Hierarchical mixtures of experts and the EM algorithm. </title> <journal> Neural Computation, </journal> <volume> 6, </volume> <pages> 181-214. </pages>
Reference-contexts: At the next time step, a similar procedure is used to generate data from the model, except that now each decision in the tree is dependent on the decision taken at that node in the previous time step. Thus, the "hierarchical mixture of experts" architecture <ref> (Jordan & Jacobs, 1994) </ref> is generalized to include Markovian dynamics for the decisions. Hidden Markov decision trees provide a useful starting point for modeling time series with both temporal and spatial structure at multiple resolutions. We explore this generalization of factorial HMMs in Jordan, Ghahramani, and Saul (1997). 6.
Reference: <author> Kanazawa, K., Koller, D., & Russell, S. J. </author> <year> (1995). </year> <title> Stochastic simulation algorithms for dynamic probabilistic networks. </title> <editor> In P. Besnard, , & S. Hanks (Eds.), </editor> <booktitle> Uncertainty in Artificial Intelligence: Proceedings of the Eleventh Conference. </booktitle> <pages> (pp. 346-351). </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Although exact probability propagation algorithms exist for general graphical models (Jensen, Lauritzen, & Olesen, 1990), these algorithms are intractable for densely-connected models such as the ones we consider in this paper. One approach to dealing with this issue is to utilize stochastic sampling methods <ref> (Kanazawa et al., 1995) </ref>. Another approach, which provides the basis for algorithms described in the current paper, is to make use of variational methods (cf. Saul, Jaakkola, & Jordan, 1996).
Reference: <author> Krogh, A., Brown, M., Mian, I. S., Sjolander, K., & Haussler, D. </author> <year> (1994). </year> <title> Hidden Markov models in computational biology: </title> <journal> Applications to protein modeling . Journal of Molecular Biology, </journal> <volume> 235, </volume> <pages> 1501-1531. </pages>
Reference-contexts: to its flexibility and to the simplicity and efficiency of its parameter estimation algorithm, the hidden Markov model (HMM) has emerged as one of the basic statistical tools for modeling discrete time series, finding widespread application in the areas of speech recognition (Rabiner & Juang, 1986) and computational molecular biology <ref> (Krogh, Brown, Mian, Sjolander, & Haussler, 1994) </ref>. An HMM is essentially a mixture model, encoding information about the history of a time series in the value of a single multinomial variable|the hidden state|which can take on one of K discrete values.
Reference: <author> Lauritzen, S. L., & Spiegelhalter, D. J. </author> <year> (1988). </year> <title> Local computations with probabilities on graphical structures and their application to expert systems. </title> <journal> Journal of the Royal Statistical Society B, </journal> <pages> 157-224. </pages>
Reference-contexts: Exact inference Unfortunately, the exact E step for factorial HMMs is computationally intractable. This fact can best be shown by making reference to standard algorithms for prob FACTORIAL HIDDEN MARKOV MODELS 251 abilistic inference in graphical models <ref> (Lauritzen & Spiegelhalter, 1988) </ref>, although it can also be derived readily from direct application of Bayes rule. Consider the computations that are required for calculating posterior probabilities for the factorial HMM shown in Figure 1 (b) within the framework of the Lauritzen and Spiegelhalter algorithm.
Reference: <author> McCullagh, P., & Nelder, J. </author> <year> (1989). </year> <title> Generalized linear models. </title> <publisher> London: Chapman & Hall. </publisher>
Reference-contexts: In general, if the output and transition probabilities are modeled as neural networks, the M step can no longer be solved exactly and a gradient-based generalized EM algorithm must be used. For log-linear models, the M step can be solved using an inner loop of iteratively reweighted least-squares <ref> (McCullagh & Nelder, 1989) </ref>. 5.4. Hidden Markov decision trees An interesting generalization of factorial HMMs results if one conditions on an input X t and orders the M state variables such that S (m) t depends on S (n) 266 Z. GHAHRAMANI AND M.I.
Reference: <author> Meila, M., & Jordan, M. I. </author> <year> (1996). </year> <title> Learning fine motion by Markov mixtures of experts. </title> <editor> In D. S. Touretzky, M. C. Mozer, & M. E. Hasselmo (Eds.), </editor> <booktitle> Advances in neural information processing systems 8, </booktitle> <pages> pp. 1003-1009. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Merz, C. J., & Murphy, P. M. </author> <year> (1996). </year> <note> UCI Repository of machine learning databases [http://www.ics.uci.edu/ mlearn/MLRepository.html]. </note> <institution> Irvine, CA: University of California, Department of Information and Computer Science. </institution>
Reference-contexts: The data set consisted of discrete event sequences encoding the melody lines of J. S. Bach's Chorales, obtained from the UCI Repository for Machine Learning Databases <ref> (Merz & Murphy, 1996) </ref> and originally discussed in Conklin and Wit-ten (1995). Each event in the sequence was represented by six attributes, described in Table 2. Sixty-six chorales, with 40 or more events each, were divided into a training set (30 chorales) and a test set (36 chorales).
Reference: <author> Neal, R. M. </author> <year> (1992). </year> <title> Connectionist learning of belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 56, </volume> <pages> 71-113. </pages>
Reference-contexts: Thus the compactness of the representation would be entirely lost. Standard methods from graphical models suggest approximating such large matrices with "noisy-OR" (Pearl, 1988) or "sigmoid" <ref> (Neal, 1992) </ref> models of interaction. For example, in the softmax model, which generalizes the sigmoid model to D &gt; 2, P (Y t jS (1) (M) t ) is multinomial with mean proportional to 264 Z. GHAHRAMANI AND M.I. JORDAN exp m W (m) S t . <p> As in Boltzmann machines (Hinton & Sejnowski, 1986), both a clamped and an unclamped phase are therefore required for learning, where the goal of the unclamped phase is to compute the derivative of the partition function with respect to the parameters <ref> (Neal, 1992) </ref>. 5.3. Conditioning on inputs Like the hidden Markov model, the factorial HMM provides a model of the unconditional density of the observation sequences.
Reference: <author> Neal, R. M. </author> <year> (1993). </year> <title> Probabilistic inference using Markov chain Monte Carlo methods (Technical Report CRG-TR-93-1). </title> <institution> Toronto, Ontario: University of Toronto, Department of Computer Science. </institution>
Reference-contexts: Inference using Gibbs sampling Rather than computing the exact posterior probabilities, one can approximate them using a Monte Carlo sampling procedure, and thereby avoid the sum over exponentially many state patterns at some cost in accuracy. Although there are many possible sampling schemes <ref> (for a review see Neal, 1993) </ref>, here we present one of the simplest|Gibbs sampling (Geman & Geman, 1984). For a given observation sequence fY t g, this procedure starts with a random setting of the hidden states fS t g.
Reference: <author> Neal, R. M., & Hinton, G. E. </author> <year> (1993). </year> <title> A new view of the EM algorithm that justifies incremental and other variants. </title> <type> Unpublished manuscript, </type> <institution> Department of Computer Science, University of Toronto, </institution> <address> Ontario. </address>
Reference-contexts: Inference using Gibbs sampling Rather than computing the exact posterior probabilities, one can approximate them using a Monte Carlo sampling procedure, and thereby avoid the sum over exponentially many state patterns at some cost in accuracy. Although there are many possible sampling schemes <ref> (for a review see Neal, 1993) </ref>, here we present one of the simplest|Gibbs sampling (Geman & Geman, 1984). For a given observation sequence fY t g, this procedure starts with a random setting of the hidden states fS t g.
Reference: <author> Parisi, G. </author> <year> (1988). </year> <title> Statistical field theory. </title> <address> Redwood City, CA: </address> <publisher> Addison-Wesley. </publisher>
Reference-contexts: under the distribution Q: Q (S t j t ) = k=1 t;k t;k where S (m) K X S t;k = 1: (8) This completely factorized approximation is often used in statistical physics, where it provides the basis for simple yet powerful mean field approximations to statistical mechanical systems <ref> (Parisi, 1988) </ref>. To make the bound as tight as possible we vary separately for each observation sequence so as to minimize the KL divergence.
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic reasoning in intelligent systems: Networks of plausible inference. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Unless otherwise stated, we will assume the Gaussian observation model throughout the paper. The hidden state variables at one time step, although marginally independent, become conditionally dependent given the observation sequence. This can be determined by applying the semantics of directed graphs, in particular the d-separation criterion <ref> (Pearl, 1988) </ref>, to the graphical model in Figure 1 (b). Consider the Gaussian model in equations (4a)-(4b). <p> However, in the case of a factorial HMM, this matrix would have D fiK M entries for each combination of the state variables and observation. Thus the compactness of the representation would be entirely lost. Standard methods from graphical models suggest approximating such large matrices with "noisy-OR" <ref> (Pearl, 1988) </ref> or "sigmoid" (Neal, 1992) models of interaction. For example, in the softmax model, which generalizes the sigmoid model to D &gt; 2, P (Y t jS (1) (M) t ) is multinomial with mean proportional to 264 Z. GHAHRAMANI AND M.I.
Reference: <author> Rabiner, L. R., & Juang, B. H. </author> <year> (1986). </year> <title> An Introduction to hidden Markov models. </title> <journal> IEEE Acoustics, Speech & Signal Processing Magazine, </journal> <volume> 3, </volume> <pages> 4-16. </pages>
Reference-contexts: 1. Introduction Due to its flexibility and to the simplicity and efficiency of its parameter estimation algorithm, the hidden Markov model (HMM) has emerged as one of the basic statistical tools for modeling discrete time series, finding widespread application in the areas of speech recognition <ref> (Rabiner & Juang, 1986) </ref> and computational molecular biology (Krogh, Brown, Mian, Sjolander, & Haussler, 1994). An HMM is essentially a mixture model, encoding information about the history of a time series in the value of a single multinomial variable|the hidden state|which can take on one of K discrete values. <p> In the context of speech recognition, for example, the observations may be acoustic vectors and the goal of inference may be to compute the probability for a particular word or sequence of phonemes (the hidden state). This problem can be solved efficiently via the forward-backward algorithm <ref> (Rabiner & Juang, 1986) </ref>, which can be shown to be a special case of the Jensen, Lauritzen, and Olesen (1990) algorithm for probability propagation in more general graphical models (Smyth et al., 1997).
Reference: <author> Saul, L. K., & Jordan, M. I. </author> <year> (1997). </year> <title> Mixed memory Markov models. </title> <editor> In D. </editor> <address> Madigan , & P. </address>
Reference-contexts: Introducing couplings The architecture for factorial HMMs presented in Section 2 assumes that the underlying Markov chains interact only through the observations. This constraint can be relaxed by introducing couplings between the hidden state variables <ref> (cf. Saul & Jordan, 1997) </ref>.
Reference: <editor> Smyth (Eds.), </editor> <booktitle> Proceedings of the 1997 Conference on Artificial Intelligence and Statistics. </booktitle> <address> Ft. Lauderdale, FL. </address>
Reference-contexts: This problem can be solved efficiently via the forward-backward algorithm (Rabiner & Juang, 1986), which can be shown to be a special case of the Jensen, Lauritzen, and Olesen (1990) algorithm for probability propagation in more general graphical models <ref> (Smyth et al., 1997) </ref>. In some cases, rather than a probability distribution over hidden states it is desirable to infer the single most probable hidden state sequence.
Reference: <author> Saul, L., Jaakkola, T., & Jordan, M. I. </author> <year> (1996). </year> <title> Mean Field Theory for Sigmoid Belief Networks. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 4, </volume> <pages> 61-76. </pages>
Reference-contexts: One approach to dealing with this issue is to utilize stochastic sampling methods (Kanazawa et al., 1995). Another approach, which provides the basis for algorithms described in the current paper, is to make use of variational methods <ref> (cf. Saul, Jaakkola, & Jordan, 1996) </ref>. In the following section we define the probabilistic model for factorial HMMs and in Section 3 we present algorithms for inference and learning.
Reference: <author> Saul, L., & Jordan, M. I. </author> <year> (1995). </year> <title> Boltzmann chains and hidden Markov models. </title> <editor> In G. Tesauro, D. S. Touretzky, & T. K. Leen (Eds.), </editor> <booktitle> Advances in neural information processing systems 7, </booktitle> <pages> pp. 435-442. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Saul, L., & Jordan, M. I. </author> <year> (1996). </year> <title> Exploiting tractable substructures in Intractable networks. </title>
Reference-contexts: One approach to dealing with this issue is to utilize stochastic sampling methods (Kanazawa et al., 1995). Another approach, which provides the basis for algorithms described in the current paper, is to make use of variational methods <ref> (cf. Saul, Jaakkola, & Jordan, 1996) </ref>. In the following section we define the probabilistic model for factorial HMMs and in Section 3 we present algorithms for inference and learning.
Reference: <editor> In D. S. Touretzky, M. C. Mozer, & M. E. Hasselmo (Eds.), </editor> <booktitle> Advances in neural information processing systems 8, </booktitle> <pages> pp. 486-492. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Smyth, P., Heckerman, D., & Jordan, M. I. </author> <year> (1997). </year> <title> Probabilistic independence networks for hidden Markov probability models. </title> <journal> Neural Computation, </journal> <volume> 9, </volume> <pages> 227-269. </pages>
Reference-contexts: This problem can be solved efficiently via the forward-backward algorithm (Rabiner & Juang, 1986), which can be shown to be a special case of the Jensen, Lauritzen, and Olesen (1990) algorithm for probability propagation in more general graphical models <ref> (Smyth et al., 1997) </ref>. In some cases, rather than a probability distribution over hidden states it is desirable to infer the single most probable hidden state sequence.
Reference: <author> Stolcke, A., & Omohundro, S. </author> <year> (1993). </year> <title> Hidden Markov model induction by Bayesian model merging. </title> <editor> In S.J. Hanson, J. D. Cowan, & C. L. Giles (Eds.), </editor> <booktitle> Advances in neural information processing systems 5, </booktitle> <pages> pp. 11-18. </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Tanner, M. A., & Wong, W. H. </author> <year> (1987). </year> <title> The calculation of posterior distributions by data augmentation (with discussion). </title> <journal> Journal of the American Statistical Association, </journal> <volume> 82, </volume> <pages> 528-550. </pages>
Reference-contexts: A more Bayesian treatment of the learning problem, in which the parameters are also considered hidden random variables, can be handled by Gibbs sampling by replacing the "M step" with sampling from the conditional distribution of the parameters given the other hidden variables <ref> (for example, see Tanner and Wong, 1987) </ref>. 5. The first term is replaced by log (m) for t = 1 the second term does not appear for t = T . 6. All samples were used for learning; that is, no samples were discarded at the beginning of the run.
Reference: <author> Viterbi, A. J. </author> <year> (1967). </year> <title> Error bounds for convolutional codes and an asymptotically optimal decoding algorithm. </title> <journal> IEEE Transactions Information Theory, </journal> <volume> IT-13, </volume> <pages> 260-269. </pages>
Reference: <author> Williams, C. K. I., & Hinton, G. E. </author> <year> (1991). </year> <title> Mean field networks that learn to discriminate temporally distorted strings. </title> <editor> In D. Touretzky, J. Elman, T. Sejnowski, & G. Hinton (Eds.), </editor> <title> FACTORIAL HIDDEN MARKOV MODELS 275 Connectionist models: </title> <booktitle> Proceedings of the 1990 summer school (pp. </booktitle> <pages> 18-22). </pages> <address> San Francisco, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: On the other hand, an HMM with a distributed state representation could achieve the same task with 30 binary state 246 Z. GHAHRAMANI AND M.I. JORDAN variables <ref> (Williams & Hinton, 1991) </ref>. This paper addresses the problem of constructing efficient learning algorithms for hidden Markov models with distributed state representations. The need for distributed state representations in HMMs can be motivated in two ways.
Reference: <author> Zemel, R. S. </author> <year> (1993). </year> <title> A minimum description length framework for unsupervised learning. </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, University of Toronto, Toronto, Canada. </institution> <note> Received Date July 10, 1996 Accepted Date January 14, 1997 Final Manuscript Date July 28, </note> <year> 1997 </year>
References-found: 40

