URL: http://www.cs.ucf.edu:80/~vision/PAPERS/flow.ps
Refering-URL: http://www.cs.ucf.edu:80/~vision/tech_papers.html
Root-URL: 
Email: email: ftian, shahg@cs.ucf.edu  
Title: MOTION SEGMENTATION AND ESTIMATION  
Author: Tina Yu Tian and Mubarak Shah 
Address: Orlando, FL 32816  
Affiliation: Computer Vision Lab Computer Science Department University of Central Florida  
Date: November 13-16, 1994.  
Note: To appear in IEEE ICIP-94, Austin, Texas,  
Abstract: In this paper, we apply mean field technique and present a deterministic algorithm to determine the optical flow and motion boundaries. To deal with the problem of large motion, we present an adaptive multigrid approach, which also greatly reduces the computation time. This algorithm is fully parallelizable and iterative. The performance of the proposed method is compared against known algorithms using performance measures proposed by Barron et al [3]. Experimental results indicate that our approach provides good estimates of optical flow and motion boundaries. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Abdelqader and S. Rajala. </author> <title> Motion estimation from noisy image data. </title> <booktitle> In ICASSP'93, </booktitle> <pages> pages 209-212, </pages> <year> 1993. </year>
Reference-contexts: Zhang and Hanauer [14] applied mean field theory to compute displacement field, while we compute optical flow field. Our formulation is different from theirs, and the computation cost is small. Abdelqader and Rajala <ref> [1] </ref> proposed a mean field annealing approach to motion estimation in which only displacement field is involved in the MRF formulation. Our coupled MRF model includes flow field, horizontal and vertical line fields, and motion estimation and segmentation are solved simultaneously.
Reference: [2] <author> P. Anandan. </author> <title> A computational framework and an algorithm for the measurement of visual motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 2 </volume> <pages> 283-310, </pages> <year> 1989. </year>
Reference-contexts: The results for optical flow obtained from Horn and Schunck and our algorithm are shown in Figure 3 (d) and (c), respectively. 3.1. Comparison Barron, Fleet and Beauchemin [3] present a comprehensive evaluation and comparison of existing optical flow methods. Here we compare our method with Anandan's method <ref> [2] </ref>, Horn and Schunck's method [9] and Fleet and Jepson's (a) (b) 2 = 0:71, and fi = 5:0. (a) Frame 1. (b) Frame 2. (c) Optical flow. (d) Motion boundaries. method [4] on the same inputs using the performance measures of Barron et al.
Reference: [3] <author> J.L. Barron, </author> <title> D.J. Fleet, and S.S. Beauchemin. Performance of optical flow techniques. </title> <booktitle> In CVPR'92, </booktitle> <pages> pages 236-242, </pages> <year> 1992. </year>
Reference-contexts: Harris and Koch et al. [7] used the similar formulation, but implemented motion discontinu-ities by analog circuits. Unlike their work, we present a deterministic solution for the MRF motion formulation. The performance of the proposed method is compared against known algorithms using performance measures proposed by Barron et al <ref> [3] </ref>, and it is shown the proposed algorithm outperforms those algorithms. 2. DETERMINING OPTICAL FLOW AND MOTION BOUNDARIES BY MRFS 2.1. <p> The measured displacement is about 1-2 pixels/frame for each toy. The results for optical flow obtained from Horn and Schunck and our algorithm are shown in Figure 3 (d) and (c), respectively. 3.1. Comparison Barron, Fleet and Beauchemin <ref> [3] </ref> present a comprehensive evaluation and comparison of existing optical flow methods. <p> Their program provided quite accurate results with average and standard deviation of error equal to 0:034 o and 0:028 o , respectively, which are very close to (0:07 o , 0:08 o ), the error measurements of Fleet and Jepson's method for their uniform square sequence, as reported in <ref> [3] </ref>.
Reference: [4] <author> D. Fleet and A. Jepson. </author> <title> Computation of component image velocity from local phase information. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5 </volume> <pages> 77-104, </pages> <year> 1990. </year>
Reference-contexts: Here we compare our method with Anandan's method [2], Horn and Schunck's method [9] and Fleet and Jepson's (a) (b) 2 = 0:71, and fi = 5:0. (a) Frame 1. (b) Frame 2. (c) Optical flow. (d) Motion boundaries. method <ref> [4] </ref> on the same inputs using the performance measures of Barron et al. The random-dot synthetic square image sequence is used for quantitative performance comparisons, since textured images are more realistic for the real scenes.
Reference: [5] <author> D. Geiger and F. Girosi. </author> <title> Parallel and deterministic algorithms from mrf's: Surface reconstruction. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 401-412, </pages> <year> 1991. </year>
Reference-contexts: Simulated annealing converges very slowly to the global minimum, ICM gets stuck into a local minimum very easily unless a good initial estimate is provided, and GNC, which is a deterministic simulated annealing, still converges slowly. Mean field technique recently has been shown <ref> [5] </ref> to be more appealing for minimizing the non-convex cost functional, since it converges much faster to the global minimum. In this paper, we apply mean field technique and present a deterministic algorithm to determine the optical flow and motion boundaries. <p> Since the mean field essentially represents the minimum variance Bayesian estimator, it can be used as a measure of field value. A well-known result <ref> [5] </ref> from statistical mechanics and probability theory indicates that all mean values of the sys tem can be obtained from the partition function Z, so we must compute the function Z. <p> The partition function can then be rewritten as Z = fu;vg fiV eff (u;v) where V eff (u; v) = i;j 1 1 2 h v 1 ln [(1 + e i;j )(1 + e i;j )]g: Using the mean field technique <ref> [5] </ref>, we can derive the fol lowing mean field equations for the line processes: d h ij = 1 + e 2 2 k ~ U i;j ~ U i1;j k 2 ) d v ij = 1 + e 2 2 k ~ U i;j ~ U i;j1 k 2
Reference: [6] <author> S. Geman and D. Geman. </author> <title> Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 6 </volume> <pages> 721-741, </pages> <year> 1984. </year>
Reference-contexts: Therefore, the optical flow field ~ U can be modeled as a 2D vector MRF. Moreover, Ge-man and Geman <ref> [6] </ref> introduced another MRF field in the dual lattice, a binary field (the line process), which is composed of the horizontal line process, d h ij , and the vertical line process, d v ij .
Reference: [7] <author> J. Harris, C. Koch, E. Staats, and J. Luo. </author> <title> Analog hardware for detecting discontinuities in early vision. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4 </volume> <pages> 211-223, </pages> <year> 1990. </year>
Reference-contexts: The conventional gradient-based motion estimation approaches impose a global smoothness constraint on the image, which results in inaccurate optical flow estimates near motion boundaries. Some researchers, Poggio et al [12], Konrad and Dubois [11], Heitz and Bouthemy [8], Har-ris and Koch et al <ref> [7] </ref>, introduced line processes and a piecewise smoothness constraint into the regulation formulation to improve the motion estimates. The problem is reduced to minimizing a non-convex cost functional, for which optimization methods can be used, e.g. simulated annealing [11], iterated condition mode (ICM) [8], and graduated non-convexity (GNC) algorithm. <p> The difference between their method and ours is that they did not compute optical flow or displacement field, but approximated the motion of objects by 2D parametric models, then compute the parameters of these models and segmentation. Harris and Koch et al. <ref> [7] </ref> used the similar formulation, but implemented motion discontinu-ities by analog circuits. Unlike their work, we present a deterministic solution for the MRF motion formulation.
Reference: [8] <author> F. Heitz and P. Bouthemy. </author> <title> Multimodal estimation of discontinous optical flow using markov random fields. </title> <journal> In IEEE Trans. on PAMI, </journal> <pages> pages 1217-1232, </pages> <year> 1993. </year>
Reference-contexts: The conventional gradient-based motion estimation approaches impose a global smoothness constraint on the image, which results in inaccurate optical flow estimates near motion boundaries. Some researchers, Poggio et al [12], Konrad and Dubois [11], Heitz and Bouthemy <ref> [8] </ref>, Har-ris and Koch et al [7], introduced line processes and a piecewise smoothness constraint into the regulation formulation to improve the motion estimates. The problem is reduced to minimizing a non-convex cost functional, for which optimization methods can be used, e.g. simulated annealing [11], iterated condition mode (ICM) [8], and <p> Bouthemy <ref> [8] </ref>, Har-ris and Koch et al [7], introduced line processes and a piecewise smoothness constraint into the regulation formulation to improve the motion estimates. The problem is reduced to minimizing a non-convex cost functional, for which optimization methods can be used, e.g. simulated annealing [11], iterated condition mode (ICM) [8], and graduated non-convexity (GNC) algorithm. Simulated annealing converges very slowly to the global minimum, ICM gets stuck into a local minimum very easily unless a good initial estimate is provided, and GNC, which is a deterministic simulated annealing, still converges slowly.
Reference: [9] <author> B.K.P. Horn and G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: The term in the exponential in (1) is based on the brightness constancy equation of Horn and Schunck <ref> [9] </ref>. Another type of error is caused by changes in lighting or reflectance, or the presence of multiple motions, in which case the brightness constancy constraint is not satisfied. <p> Comparison Barron, Fleet and Beauchemin [3] present a comprehensive evaluation and comparison of existing optical flow methods. Here we compare our method with Anandan's method [2], Horn and Schunck's method <ref> [9] </ref> and Fleet and Jepson's (a) (b) 2 = 0:71, and fi = 5:0. (a) Frame 1. (b) Frame 2. (c) Optical flow. (d) Motion boundaries. method [4] on the same inputs using the performance measures of Barron et al.
Reference: [10] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Detecting and tracking multiple moving objects using temporal integration. </title> <booktitle> In ECCV'92, </booktitle> <pages> pages 282-287, </pages> <year> 1992. </year>
Reference-contexts: Abdelqader and Rajala [1] proposed a mean field annealing approach to motion estimation in which only displacement field is involved in the MRF formulation. Our coupled MRF model includes flow field, horizontal and vertical line fields, and motion estimation and segmentation are solved simultaneously. Irani and Peleg <ref> [10] </ref> proposed a method for motion detection and segmentation. The difference between their method and ours is that they did not compute optical flow or displacement field, but approximated the motion of objects by 2D parametric models, then compute the parameters of these models and segmentation.
Reference: [11] <author> J. Konrad and E. Dubois. </author> <title> Bayesian estimation of discontinuous motion in images using simulated annealing. </title> <booktitle> In Conf. Vision Interface, </booktitle> <address> London, Ontario, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: 1. INTRODUCTION Motion segmentation and estimation is the essential first step to solve general structure-from-motion (SFM) problem. The conventional gradient-based motion estimation approaches impose a global smoothness constraint on the image, which results in inaccurate optical flow estimates near motion boundaries. Some researchers, Poggio et al [12], Konrad and Dubois <ref> [11] </ref>, Heitz and Bouthemy [8], Har-ris and Koch et al [7], introduced line processes and a piecewise smoothness constraint into the regulation formulation to improve the motion estimates. The problem is reduced to minimizing a non-convex cost functional, for which optimization methods can be used, e.g. simulated annealing [11], iterated condition <p> and Dubois <ref> [11] </ref>, Heitz and Bouthemy [8], Har-ris and Koch et al [7], introduced line processes and a piecewise smoothness constraint into the regulation formulation to improve the motion estimates. The problem is reduced to minimizing a non-convex cost functional, for which optimization methods can be used, e.g. simulated annealing [11], iterated condition mode (ICM) [8], and graduated non-convexity (GNC) algorithm. Simulated annealing converges very slowly to the global minimum, ICM gets stuck into a local minimum very easily unless a good initial estimate is provided, and GNC, which is a deterministic simulated annealing, still converges slowly.
Reference: [12] <author> T. Poggio, E. Gamble, and J. Little. </author> <title> Parallel integration of vision modules. </title> <journal> Science, </journal> <volume> 242 </volume> <pages> 436-440, </pages> <year> 1988. </year>
Reference-contexts: 1. INTRODUCTION Motion segmentation and estimation is the essential first step to solve general structure-from-motion (SFM) problem. The conventional gradient-based motion estimation approaches impose a global smoothness constraint on the image, which results in inaccurate optical flow estimates near motion boundaries. Some researchers, Poggio et al <ref> [12] </ref>, Konrad and Dubois [11], Heitz and Bouthemy [8], Har-ris and Koch et al [7], introduced line processes and a piecewise smoothness constraint into the regulation formulation to improve the motion estimates.
Reference: [13] <author> J. Vlontzos and D. Geiger. </author> <title> A mrf approach to optical flow estimation. </title> <booktitle> In CVPR'92, </booktitle> <pages> pages 853-856, </pages> <year> 1992. </year>
Reference-contexts: In this paper, we apply mean field technique and present a deterministic algorithm to determine the optical flow and motion boundaries. Recently, Vlontzos and Geiger <ref> [13] </ref> proposed an algorithm for optical flow estimation using mean field technique.
Reference: [14] <author> J. Zhang and J. Hanauer. </author> <title> The mean field theory for image motion estimation. </title> <booktitle> In ICASSP'93, </booktitle> <pages> pages 197-200, </pages> <year> 1993. </year>
Reference-contexts: Our formulation is directly in terms of intensity, avoiding the intermediate step to compute flow by correlation. Zhang and Hanauer <ref> [14] </ref> applied mean field theory to compute displacement field, while we compute optical flow field. Our formulation is different from theirs, and the computation cost is small.
References-found: 14

