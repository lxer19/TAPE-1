URL: http://ftp.eecs.umich.edu/people/peter/ijcai95-nl-learning.ps
Refering-URL: http://ftp.eecs.umich.edu/people/peter/
Root-URL: http://www.eecs.umich.edu
Email: peter@umich.edu  
Title: Implications of an Automatic Lexical Acquisition System  
Author: Peter M. Hastings ()-(voice) ()-(fax) 
Address: 1101 Beal Avenue Ann Arbor, MI 48109  
Affiliation: Artificial Intelligence Lab The University of Michigan  
Abstract: Camille, the Contextual Acquisition Mechanism for Incremental Lexeme LEarning, was implemented as an addition to Lytinen's LINK parser for use in an information extraction task, automatically inferring the meanings of unknown words from context. Unlike many previous lexical acquisition systems, Camille was thoroughly tested within a complex, real-world domain. The implementation of this system produced many lessons which are applicable to language learning in general. This paper describes Camille's implications for evaluation, for knowledge representation, and for cognitive modeling. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Allen, J. </author> <year> 1981. </year> <title> What's necessary to hide?: Modeling action verbs. </title> <booktitle> In Proceedings of the 19 th Annual Meeting of the ACL, </booktitle> <pages> 77-81. </pages>
Reference-contexts: He considered what it would take to represent the verb "hide", and answer reasonable questions about it. Allen's answer involved a temporal logic that could address "notions of belief, intention, and causality." <ref> (Allen 1981, p. 81) </ref> This work takes the same approach as Allen's, in effect rephrasing the previous question as, "In order to meet the functional requirements of the overall task, what does the NLP system need to know?" Instead of requiring the system to answer all possible questions about the consequences
Reference: <author> Behrend, D. </author> <year> 1990. </year> <title> The development of verb concepts: Children's use of verbs to label familiar and novel events. </title> <booktitle> Child Development 61 </booktitle> <pages> 681-696. </pages>
Reference: <author> Brent, M. </author> <year> 1993. </year> <title> From grammar to lexicon: Unsupervised learning of lexical syntax. </title> <note> Computational Linguistics. </note>
Reference: <author> Cardie, C. </author> <year> 1993. </year> <title> A case-based approach to knowledge acquisition for domain-specific sentence analysis. </title> <booktitle> In Proceedings of the 11 th National Conference on Artificial Intelligence, </booktitle> <pages> 798-803. </pages>
Reference: <author> Chinchor, N. </author> <year> 1992. </year> <title> MUC-4 evaluation metrics. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: To reflect the need to reduce the size of the hypothesis set, a system of scores was adapted from the MUC conferences <ref> (Chinchor 1992) </ref>. These measures, Recall and Precision were originally taken from the field of Information Retrieval and are defined as follows: Recall is the number of words which included a correct concept in their hypothesis set divided by the number of possible words which could have received definitions.
Reference: <author> Fernald, A., and Morikawa, H. </author> <year> 1993. </year> <title> Common themes and cultural variations in Japanese and American mothers' speech to infants. </title> <booktitle> Child Development 64 </booktitle> <pages> 637-656. </pages>
Reference: <author> Granger, R. </author> <year> 1977. </year> <title> Foul-up: A program that figures out meanings of words from context. </title> <booktitle> In Proceedings of Fifth International Joint Conference on Artificial Intelligence. </booktitle>
Reference: <author> Hastings, P., and Lytinen, S. </author> <year> 1994a. </year> <title> Objects, actions, nouns, and verbs. </title> <editor> In Ram, A., and Eiselt, K., eds., </editor> <booktitle> Proceedings of the 16 th Annual Conference of the Cognitive Science Society, </booktitle> <pages> 397-402. </pages> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates. </publisher>
Reference-contexts: Cognitive Modeling Camille was not developed as a cognitive model. It does, however, perform a task that humans perform, and it shares some striking similarities with psycholinguistic theories for lexical acquisition, as described in <ref> (Hastings & Lytinen 1994a) </ref>. An unplanned behavior is inherently more interesting that one that was designed into a system, this section describes some of the implications for cognitive modeling that arose out of this research.
Reference: <author> Hastings, P., and Lytinen, S. </author> <year> 1994b. </year> <title> The ups and downs of lexical acquisition. </title> <booktitle> In Proceedings of the 12 th National Conference on Artificial Intelligence, </booktitle> <pages> 754-759. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Introduction As reported in <ref> (Hastings & Lytinen 1994b) </ref> and (Hast-ings 1994), Camille (Contextual Acquisition Mechanism for Incremental Lexical LEarning) implements an algorithm for learning the meanings of words from example sentences without the help of a human trainer. The system was developed to operate on real-world texts as part of an information extraction task. <p> Camille was developed with the goal of leveraging all of the available knowledge for learning word meanings | without requiring additional special-purpose knowledge. The difficulty of this task led to several implications about lexical acquisition in general. A fundamental difference between nouns and verbs was described in <ref> (Hastings & Lytinen 1994b) </ref>. Camille relies on argument structure and examples to enable it to learn word meanings. But nouns and verbs play different roles as far as argument structure is concerned. <p> Thus Camille is forced to make guesses to limit hypothesis sets. As described above and in <ref> (Hastings & Lytinen 1994b) </ref>, different classes of words provide different types of con straints to the system, forcing Camille to infer the most specific consistent concept for a verb's meaning, and the most general for a noun's.
Reference: <author> Hastings, P. </author> <year> 1994. </year> <title> Automatic Acquisition of Word Meaning from Context. </title> <type> Ph.D. Dissertation, </type> <institution> University of Michigan, </institution> <address> Ann Arbor, MI. </address>
Reference: <author> Hobbs, J.; Appelt, D.; Tyson, M.; Bear, J.; and Is-rael, D. </author> <year> 1992. </year> <title> SRI International: Description of the FASTUS system used for MUC-4. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: What is required to successfully perform the information extraction task? In the MUC competitions, systems with greatly varying depths of knowledge representation performed at similar levels of efficiency. Some systems (SRI's FASTUS system <ref> (Hobbs et al. 1992) </ref>, for example) used a simple pattern-matching architecture to process the texts very quickly and rather successfully. They were prone, however, to producing errors in particular situations where a pattern matched a text fragment which was part of a larger context.
Reference: <author> Huttenlocher, J.; Haight, W.; Bryk, A.; Seltzer, M.; and Lyons, T. </author> <year> 1991. </year> <title> Early vocabulary growth: Relation to language input and gender. </title> <booktitle> Developmental Psychology 27(2) </booktitle> <pages> 236-248. </pages>
Reference: <author> Keil, F. </author> <year> 1991. </year> <title> Theories, concepts, and the acquisition of word meaning. </title> <editor> In Byrnes, J. P., and Gelman, S. A., eds., </editor> <booktitle> Perspectives on language and thought: Interrelations in development. </booktitle> <address> Cambridge: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: The general framework consists of an IS-A inheritance hierarchy, a type of representation that is widely used in Artificial Intelligence. Various psychological studies support the existence of hierarchical structures in the brain <ref> (Keil 1991, for example) </ref>. At the lowest level, this representation is clearly not "brain-like". It is highly unlikely that the brain uses such a rule-like arrangement for representing constraints. But the hierarchical structure has advantages that make it a powerful representation scheme for computers and humans.
Reference: <author> Lytinen, S. </author> <year> 1991. </year> <title> A unification-based, integrated natural language processing system. Computers and Mathematics with Applications 23(6-9):403-418. </title>
Reference-contexts: Finally, the paper describes the implications of the system for cognitive modeling, and concludes with a general discussion. Camille As previously mentioned, Camille was implemented as an addition to an information extraction system which was based on Lytinen's LINK parser <ref> (Lytinen 1991) </ref>. This particular task had a strong influence on the design decisions for Camille. It also provided the primary motivation. Because an information extraction system must deal with complex, real-world texts, the system requires huge amounts of linguistic knowledge.
Reference: <author> MacGregor, R. </author> <year> 1990. </year> <title> The evolving technology of classification-based knowledge representation systems. </title> <editor> In Sowa, J., ed., </editor> <booktitle> Principles of Semantic Nets: Explorations in the Representation of Knowledge. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: There have also been statistical approaches which use large corpora but infer little or no information about word meaning (Brent 1993; Zernik 1991, for example). The basic operation of Camille's lexical acquisition mechanism is rather similar to classification systems like Loom <ref> (MacGregor 1990) </ref>. Given a sentence with an unknown word, Camille searches the existing concept hierarchy for a concept which adequately matches the current example. Figure 1 shows a subset of the hierarchy that was used in the terrorism domain of the MUC-3 and MUC-4 conferences (Sundheim 1992).
Reference: <author> Markman, E. </author> <year> 1991. </year> <title> The whole object, taxonomic, and mutual exclusivity assumptions as initial constraints on word meanings. </title> <editor> In Byrnes, J. P., and Gelman, S. A., eds., </editor> <booktitle> Perspectives on language and thought: Interrelations in development. </booktitle> <address> Cambridge: </address> <publisher> Cambridge University Press. </publisher>
Reference-contexts: Psycholinguistics researchers have suggested many methods that children might use to reduce the complexity of the task. One of these is called Mutual Exclusivity <ref> (Markman 1991) </ref>. This theory posits that when children are first learning the meanings of words, they assume that no two words have overlapping meanings. This simplifies their task by eliminating those possible meanings for a new word that they already know a word for.
Reference: <author> Riloff, E. </author> <year> 1993. </year> <title> Automatically constructing a dictionary for information extraction tasks. </title> <booktitle> In Proceedings of the 11 th National Conference on Artificial Intelligence, </booktitle> <pages> 811-816. </pages>
Reference: <author> Salveter, S. </author> <year> 1979. </year> <title> Inferring conceptual graphs. </title> <booktitle> Cognitive Science 3 </booktitle> <pages> 141-166. </pages>
Reference: <author> Sundheim, B. </author> <year> 1992. </year> <title> Overview of the fourth message understanding evaluation and conference. </title> <booktitle> In Proceedings of the Fourth Message Understanding Conference. </booktitle> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann Publishers, Inc. </publisher>
Reference-contexts: Given a sentence with an unknown word, Camille searches the existing concept hierarchy for a concept which adequately matches the current example. Figure 1 shows a subset of the hierarchy that was used in the terrorism domain of the MUC-3 and MUC-4 conferences <ref> (Sundheim 1992) </ref>. Each node shows its name and the semantic constraints on its slot fillers.
Reference: <author> Zernik, U. </author> <year> 1987. </year> <title> How do machine language paradigms fare in language acquisition. </title> <booktitle> In Proceedings of the Fourth International Workshop on Machine Learning. </booktitle> <address> Los Altos, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Zernik, U. </author> <year> 1991. </year> <title> Train1 vs. train2: Tagging word senses in corpus. </title> <editor> In Zernik, U., ed., </editor> <title> Lexical Acquisition: Exploiting On-line Resources to Build a Lexicon. </title> <address> Hillsdale, NJ: </address> <publisher> Lawrence Erlbaum Associates, Inc. </publisher>
References-found: 21

