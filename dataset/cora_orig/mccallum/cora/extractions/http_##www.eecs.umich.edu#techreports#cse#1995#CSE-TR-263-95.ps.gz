URL: http://www.eecs.umich.edu/techreports/cse/1995/CSE-TR-263-95.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse95.html
Root-URL: http://www.eecs.umich.edu
Email: flinear,davidsong@eecs.umich.edu  
Title: Automatic Parallel Program Conversion from Shared-Memory to Message-Passing  
Author: Hsien-Hsin Lee Edward S. Davidson 
Address: Ann Arbor, Michigan 48109  
Affiliation: Advanced Computer Architecture Laboratory Department of Electrical Engineering and Computer Science University of Michigan,  
Abstract: It is an elaborate work to parallelize an application on message-passing machines since there is few good software or compilers supported for dealing with the interprocessor communication. Accordingly, it is inefficient for programmers to understand the communication behavior and explicitly specify them in the code by hand. In this paper, three schemes are presented for alleviating this time-consuming and error-prone task. Scheme A and B are two obvious methods to implement the communication code while the Scheme C is a systematic methodology for generating a functional and efficient message-passing code in an automatic manner. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Eric L. Boyd, Gheith A. Abandah, Hsien-Hsin Lee, and Edward S. Davidson. </author> <title> Modeling computation and communication performance of parallel scientific applications: A case study of the IBM SP2. </title> <type> Technical report, </type> <institution> CSE-TR-236-95, Department of Electrical Engineering and Computer Science, University of Michigan, </institution> <address> Ann Arbor, </address> <year> 1994. </year>
Reference-contexts: Since each processor knows the arrays' partition index domains of all others, thus the receiver end will put their received data into the correct arrays' index range after the communication finishes. The algorithm of our implementation is shown in figure 1. From the experiments suggested in <ref> [1] </ref>, the collective routine, MP BCAST, provided in the MPL message-passing library of the IBM SP2 for broadcasting is used. This routine employs a recursive doubling (binary tree )algorithm. <p> For example, in figure 10 (a), a message is defined as M (s; i; j), where s, i and j stand for the message weight, source 10 processor ID and destination processor ID, respectively. The message weight can be calculated from the formulas of communication latency modeled in <ref> [1] </ref>. Nine messages are scheduled on five processors in the order shown in figure 10 (a). The corresponding schedule and the communication latency are shown in figure 10 (b), the total latency for passing these nine messages is 5700.
Reference: [2] <author> Shih-Hao Hung and Edward S. Davidson. </author> <title> Design of trace-driven simulation tools on the KSR1. Directed Study Report, </title> <institution> University of Michigan, </institution> <year> 1994. </year>
Reference-contexts: During the execution of the instrumented program, a trace is generated for each participating processor. In our experiments, a parallel tracing tool, K-Tracer <ref> [2] </ref>, was developed and used on our host shared-memory machine, the KSR2. In the second phase, these parallel traces are split into several smaller parallel traces based on several disjoint ranges of the address space. This step provides more manageable files and improves the performance in later phases.
Reference: [3] <author> IBM Corporation, Kingston, </author> <title> NY. IBM AIX Parallel Environment Parallel Programming Subroutine Reference, </title> <year> 1994. </year>
Reference-contexts: Regarding exchanging of data between two processors, the IBM Message Passing Library (MPL) <ref> [3] </ref> provides a library routine called MP BSENDRECV which effectively accomplishes a pairwise exchange. Two examples are illustrated in figure 2. At the beginning, each processor p owns a locally updated partial array H (p). Data will be exchanged in each step based on the above description.
Reference: [4] <author> David Kranz, Kirk Johnson, Anant Agarwal, John Kubiatowicz, and Beng-Hong Lim. </author> <title> Integrating message-passing and shared-memory: Early experience. </title> <booktitle> In Proceedings of the Fouth Symposium on Principles and Practices of Parallel Programming, </booktitle> <pages> pages 54-63, </pages> <year> 1993. </year> <month> 15 </month>
Reference-contexts: Distributed shared-memory (DSM) machines are built on top of an underlying message-passing substrate <ref> [4] </ref>. In message-passing multicomputers, the shared data are sent or received by accessing this network (substrate) directly. The messages received from the network are put into buffers which will be accessed later by the processor.
References-found: 4

