URL: http://www.cs.berkeley.edu/~tokuyasu/cs252-3/paper2.ps.gz
Refering-URL: http://www.cs.berkeley.edu/~tokuyasu/
Root-URL: http://www.cs.berkeley.edu
Title: Slow Fourier Transforms on Fast Microprocessors  
Author: Bernd Pfrommer Taku Tokuyasu 
Note: Contents  
Date: February 21, 1996  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Steven W. White, Sudhir Dhawan, POWER2: </author> <title> Next Generation of the RISC System/6000 Family, </title> <institution> http://www.austin.ibm.com/tech/POWER2.2.html#001, Copyright IBM Corporation, </institution> <year> 1994. </year> <note> [2] http://www.austin.ibm.com/software/Apps/essl.html </note>
Reference: [3] <author> D.J.Shippy and T.W. Griffith, </author> <title> POWER2 fixed-point, data cache, and storage control units, </title> <journal> IBM J. Res. Develop., </journal> <volume> 38, 503, </volume> <year> 1994. </year>
Reference: [4] <author> Troy N. Hicks, Richard E. Fry, and Paul E. Harvey, </author> <title> POWER2 Floating-Point Unit: Architecture and Implementation, </title> <institution> http://www.austin.ibm.com/tech/fpu.html, Copyright IBM Corporation, </institution> <year> 1994. </year>
Reference: [5] <author> Steven W. White, Sudhir Dhawan, POWER2: </author> <title> Next Generation of the RISC System/6000 Family, </title> <institution> http://www.austin.ibm.com/tech/POWER2.2.html#001, Copyright IBM Corporation, </institution> <year> 1994. </year>
Reference: [6] <author> John L. Hennessy and David A. Patterson, </author> <title> Computer Architecture: A Quantitative Approach, second edition, </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Francisco, </address> <year> 1996. </year>
Reference-contexts: In addition, the cycle counts when running under the two terminal types can switch roles later in the day. We are presently at a loss to explain this extraordinary behavior. It would be interesting to perform our experiments on a dedicated machine. As noted in Reference <ref> [6] </ref>, clean timing results can often only be obtained after a reboot, for example, and we suspect that we may be in a similar situation. We leave this work to the future.
Reference: [7] <author> E.H. Welbon, C.C. Chan-Nui, D.J. Shippy, and D.A. Hicks, </author> <title> POWER2 Performance Monitor, </title> <institution> http://www.austin.ibm.com/tech/monitor.html, Copyright IBM Corporation, </institution> <year> 1994. </year> <note> [8] http://www.austin.ibm.com/software/Apps/essl.html </note>
Reference-contexts: Five registers are allocated to count events in each of four units, i.e. the ICU, SCU, FXU, and FPU, and two registers are used as a cycle counter and soft error counter. A schematic overview of the monitor hardware <ref> [7] </ref> is given in Figure 3. The five counters allocated to each unit cannot monitor an arbitrary set of events. Instead, each unit has sixteen possible event groupings defined for it.
Reference: [9] <author> P. Hohenberg, W. Kohn, Phs. </author> <month> Rev.136 </month> <year> (1964) </year> <month> B864 </month>
Reference-contexts: Moreover, predictions about the stability of new materials can be made to guide experimental scientists in cases where the experiment is difficult or expensive to perform. We refer the interested reader to references <ref> [9] </ref> and [10], which provide more details on the formalism and its applications. The predictive power of the formalism has led to support by the National Science Foundation.
Reference: [10] <author> W.E. Picket, </author> <note> "Pseudopotential Methods in Condensed Matter Applications", Computer Physics Reports 9, </note> <month> 115-198 </month> <year> (1989) </year>
Reference-contexts: Moreover, predictions about the stability of new materials can be made to guide experimental scientists in cases where the experiment is difficult or expensive to perform. We refer the interested reader to references [9] and <ref> [10] </ref>, which provide more details on the formalism and its applications. The predictive power of the formalism has led to support by the National Science Foundation.
Reference: [11] <author> W. H. Press, S.A. Teukolsky, W.T. Vetterling, and B.P. Flannery, </author> <title> Numerical Recipes, 2nd edition, </title> <publisher> Cambridge University Press, </publisher> <year> 1992 </year>
Reference-contexts: With a fast Fourier transform (FFT) algorithm, the sum can be performed with order N log 2 (N ) operations. It is based on the simple Danielson-Lanczos theorem (see for instance <ref> [11] </ref>). <p> It can be shown <ref> [11] </ref> that if the bitpattern of the index to the datapoints is reversed, and the data is rearranged according to the so-obtained new indices, the bookkeeping of the FFT algorithm is simplified considerably. This memory access intensive rearrangement phase is the first part of the FFT scheme.
Reference: [12] <author> T.N. Hicks, R.E. Fry, P.E. Harvey, IBM J. </author> <title> Res. </title> <journal> Develop. </journal> <volume> 38, 525, </volume> <year> (1994) </year>
Reference-contexts: 11 data [k+i*Nsub+Nsub/2].re=data [k+i*Nsub].re - temp.re; data [k+i*Nsub+Nsub/2].im=data [k+i*Nsub].im - temp.im; data [k+i*Nsub].re += temp.re; data [k+i*Nsub].im += temp.im; It contains a total of 10 floating point operations: * 2 multiply operations * 2 fused multiply-add operations, counting as 4 operations * 4 add operations The Power2 floating point unit <ref> [12] </ref> can perform two fma operations simultaneously, and would take 4 cycles to complete the above sequence of code (not counting the latencies). The fma feature is used only during one cycle. <p> The best slots we could find raised the total cycle count from 12 to 15, resulting in the same slowdown factor of 1.25 as in the case of the two times unrolled loop. The published literature <ref> [12] </ref> does not explain in full detail how the Power2 processor is organized. Especially the renaming scheme is not discussed sufficiently (for whatever reason). Based on the fact that the store queue (figure 8, reference [12]) has 6 stations, we conjecture that those 6 stations get filled, leading to a stall. <p> The published literature <ref> [12] </ref> does not explain in full detail how the Power2 processor is organized. Especially the renaming scheme is not discussed sufficiently (for whatever reason). Based on the fact that the store queue (figure 8, reference [12]) has 6 stations, we conjecture that those 6 stations get filled, leading to a stall. The performance monitor has a register to count the number of cycles the FP store queue is full, and we had many counts there.
Reference: [13] <author> R.C. Agarwal, F.G. Gustavson, M. </author> <title> Zubair, </title> <journal> IBM J. Res. Develop. </journal> <volume> 38, 563, </volume> <year> (1994) </year>
Reference-contexts: Thus from just looking at the specifications of the Power2 architecture, we expect the innermost loop to run at full speed. We will find in section 12 that this is not the case. 10 Assembler versus C programming The IBM ESSL library <ref> [13] </ref> is written in FORTRAN for portability reasons. <p> We relate our idea to the more complicated approach published in the literature [15]. * For our FFT, we find that the benefits of hand-optimizing at the assembly levels are substan tial. This contrasts the approach reported in reference <ref> [13] </ref>. * Two times unrolling is enough for the innermost loop of a radix two FFT is sufficient. * Unrolling more than two times actually decreases the performance, since the overhead for setting up the loop increases.
Reference: [14] <author> R.C. Agarwal, F.G. Gustavson, M. </author> <title> Zubair, </title> <journal> IBM J. Res. Develop. </journal> <volume> 38, 265, </volume> <year> (1994) </year>
Reference-contexts: will depend somewhat on the resolution of the above anomalies. 7 5 Algorithmic Prefetching Assuming that an optimized 1d FFT is provided by the vendor, what can be done to improve the performance of the 3d FFT? The implementors of the IBM ESSL library use the concept of algorithmic prefetching <ref> [14] </ref> for hiding cache effects of linear algebra subroutines. They perform dummy loads on data long before it is being used, to assure that it is in cache when needed. We first thought that this concept could be applied between calls to the 1d FFTs to mask cache latencies.

References-found: 12

