URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS97-02.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: E-mail: yfwang@cs.ucsb.edu  
Title: TRCS 97-02 A New Framework for Image Invariants using Basis Expansion  
Author: Yuan-Fang Wang 
Web: Web: http://www.cs.ucsb.edu/ yfwang  
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: We propose a general framework for computing invariant features from images. The proposed approach is based on a simple concept of basis expansion. It is widely applicable to many popular basis representations, such as wavelets [4, 5, 24, 25], short-time Fourier analysis [15, 30], and splines [2, 6, 33]. Exploiting formulations that use both global and local information about shape and color, the new approach is neither strictly global nor local. It has the advantage of tolerating a certain degree of occlusion (unlike global analysis) and does not require estimating high-order derivatives in computing invariants (unlike local analysis), whence is more robust. Furthermore, it enables a quasi-localized, hierarchical shape analysis which is not possible with other known invariant techniques. Unlike most current research on image invariants which concentrates on either geometry or illumination invariants, the proposed framework is very general and produces invariants which are insensitive to rigid motion, general affine transform, changes of parameterization and scene illumination, and perspective transform.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K. Arbter, W. E. Snyder, H. Burkhardt, and G. Hirzinger. </author> <title> Application of Affine-Invariant Fourier Descriptors to Recognition of 3-D Objects. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 12 </volume> <pages> 640-647, </pages> <year> 1990. </year>
Reference-contexts: Invariant features can be designed based on many different methods and made invariant to rigid motion, general affine transform, scene illumination, occlusion, and projection. For examples, popular image invariants have been designed based on Fourier transform <ref> [1] </ref> and moments [20, 34, 38]. <p> For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint <ref> [1, 14, 20, 32, 34, 38, 41, 43] </ref>, while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3]. <p> For star: m = " 2 4 , t = 1 # , for heart: m = " 0:4 0:2 , t = 0:2 # , and for auto: m = cos (15 o ) sin (15 o ) # " 5 . Here, we use the Harr wavelet: <ref> [1; 1] </ref> T , and, as a result, the coefficient plot shown in the second row in Fig. 6 no longer resembles the shape plot in the first row. However, a similar transform pattern for the shape and coefficient plots should 14 (a) (b) shape descriptors using spline bases. <p> Both star and knot have a "canonical" view which is the head-on view. A 2D perspective image was generated by applying an arbitrary rotation and translation to the shape before perspective projection. For star, the rotation angle was 45 o around an axis <ref> [3; 2; 1] </ref> T and the translation vector was [6; 5; 2] T . For knot, the rotation angle was 55 o around an axis [3; 0; 1] T and the translation vector was [2; 0; 2] T . <p> For star, the rotation angle was 45 o around an axis [3; 2; 1] T and the translation vector was [6; 5; 2] T . For knot, the rotation angle was 55 o around an axis <ref> [3; 0; 1] </ref> T and the translation vector was [2; 0; 2] T . In Figs. 15 and 16, the first row shows the projected 2D shapes and the depth profiles of the control vertices from the particular view point in solid line.
Reference: [2] <author> W. Bohm, G. Farin, and J. Kahmann. </author> <title> A Survey of Curve and Surface Methods in CAGD. </title> <booktitle> Comput. Aided Geometric Des., </booktitle> <pages> pages 1-60, </pages> <year> 1984. </year>
Reference-contexts: Though rational basis functions, such as NURBS, have been widely known in the computer graphics community <ref> [2, 6, 11, 29, 39] </ref>, to the best of our knowledge they have never been used in computer vision before. The remainder of this paper is organized as follows: Sec. 2 presents the framework of image-derived invariants. <p> Hence, the transformed curve can be generated using the transformed wavelet coefficients and the same wavelet bases, instead of transforming the curve point-by-point. This is an observation which is commonly made in the computer graphics community about curves generated by the spline functions and associated control vertices <ref> [2, 6, 33] </ref>. In that sense, u a;b 's function the same way as the control vertices in a spline curve. <p> The projection process can be linearized using a tool which is well-established in computer graphics, but, to the best of our knowledge, has not been introduced into the computer vision community. The particular tool is the rational form of a basis function <ref> [2, 6, 11, 29, 39] </ref>. The most famous such expression is probably NURBS, stands for Non-Uniform Rational B-Spline, which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [21]. NURBS are invariants under perspective transform. <p> Both star and knot have a "canonical" view which is the head-on view. A 2D perspective image was generated by applying an arbitrary rotation and translation to the shape before perspective projection. For star, the rotation angle was 45 o around an axis <ref> [3; 2; 1] </ref> T and the translation vector was [6; 5; 2] T . For knot, the rotation angle was 55 o around an axis [3; 0; 1] T and the translation vector was [2; 0; 2] T . <p> A 2D perspective image was generated by applying an arbitrary rotation and translation to the shape before perspective projection. For star, the rotation angle was 45 o around an axis [3; 2; 1] T and the translation vector was <ref> [6; 5; 2] </ref> T . For knot, the rotation angle was 55 o around an axis [3; 0; 1] T and the translation vector was [2; 0; 2] T . <p> For star, the rotation angle was 45 o around an axis [3; 2; 1] T and the translation vector was [6; 5; 2] T . For knot, the rotation angle was 55 o around an axis [3; 0; 1] T and the translation vector was <ref> [2; 0; 2] </ref> T . In Figs. 15 and 16, the first row shows the projected 2D shapes and the depth profiles of the control vertices from the particular view point in solid line.
Reference: [3] <author> A. M. Bruckstein, R. J. Holt, A. N. Netravali, and T. J. Richardson. </author> <title> Invariant Signatures for Planar Shape Recognition Under Partial Occlusion. </title> <booktitle> In Proc. Int. Conf. Pattern Recognit., </booktitle> <pages> pages 108-112, </pages> <address> The Hague, Netherlands, </address> <year> 1992. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion <ref> [3] </ref>. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length. See [31, 42] for a comprehensive survey of the subject of invariants. <p> Both star and knot have a "canonical" view which is the head-on view. A 2D perspective image was generated by applying an arbitrary rotation and translation to the shape before perspective projection. For star, the rotation angle was 45 o around an axis <ref> [3; 2; 1] </ref> T and the translation vector was [6; 5; 2] T . For knot, the rotation angle was 55 o around an axis [3; 0; 1] T and the translation vector was [2; 0; 2] T . <p> For star, the rotation angle was 45 o around an axis [3; 2; 1] T and the translation vector was [6; 5; 2] T . For knot, the rotation angle was 55 o around an axis <ref> [3; 0; 1] </ref> T and the translation vector was [2; 0; 2] T . In Figs. 15 and 16, the first row shows the projected 2D shapes and the depth profiles of the control vertices from the particular view point in solid line.
Reference: [4] <editor> J. M. Combes, A. Grossman, and Ph. Tchamitchian (Eds.). </editor> <title> Wavelets: Time-Freqency Methods and Phase Space, 2nd ed. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1990. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [4, 5, 6, 24, 25, 30, 33] </ref>. 5.) We introduce the rational basis functions to facilitate the analysis of invariants under perspective transform. <p> A transformed shape is generated by rotating the original shape 31 o counterclockwise, scaling it by a factor of 3 in x and a factor of 2 in y, and finally displacing it by <ref> [20; 4] </ref> T . A random amount of white noise, which can displace a contour point by up to two pixels in any direction, is added to each and every point in the transformed contour. The resulting shape is shown in dashed lines in Fig. 5 (a).
Reference: [5] <author> I. Daubechies. </author> <title> Orthonormal Bases of Compactly Supported Wavelets. </title> <journal> Commun. Pure Appl. Math., </journal> <volume> 41 </volume> <pages> 909-960, </pages> <year> 1988. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [4, 5, 6, 24, 25, 30, 33] </ref>. 5.) We introduce the rational basis functions to facilitate the analysis of invariants under perspective transform. <p> A 2D perspective image was generated by applying an arbitrary rotation and translation to the shape before perspective projection. For star, the rotation angle was 45 o around an axis [3; 2; 1] T and the translation vector was <ref> [6; 5; 2] </ref> T . For knot, the rotation angle was 55 o around an axis [3; 0; 1] T and the translation vector was [2; 0; 2] T .
Reference: [6] <author> C. deBoor. </author> <title> A Practical Guide to Spline. </title> <publisher> Springer-Verlag, </publisher> <address> New York/Berlin, </address> <year> 1978. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [4, 5, 6, 24, 25, 30, 33] </ref>. 5.) We introduce the rational basis functions to facilitate the analysis of invariants under perspective transform. <p> Though rational basis functions, such as NURBS, have been widely known in the computer graphics community <ref> [2, 6, 11, 29, 39] </ref>, to the best of our knowledge they have never been used in computer vision before. The remainder of this paper is organized as follows: Sec. 2 presents the framework of image-derived invariants. <p> Hence, the transformed curve can be generated using the transformed wavelet coefficients and the same wavelet bases, instead of transforming the curve point-by-point. This is an observation which is commonly made in the computer graphics community about curves generated by the spline functions and associated control vertices <ref> [2, 6, 33] </ref>. In that sense, u a;b 's function the same way as the control vertices in a spline curve. <p> The projection process can be linearized using a tool which is well-established in computer graphics, but, to the best of our knowledge, has not been introduced into the computer vision community. The particular tool is the rational form of a basis function <ref> [2, 6, 11, 29, 39] </ref>. The most famous such expression is probably NURBS, stands for Non-Uniform Rational B-Spline, which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [21]. NURBS are invariants under perspective transform. <p> A 2D perspective image was generated by applying an arbitrary rotation and translation to the shape before perspective projection. For star, the rotation angle was 45 o around an axis [3; 2; 1] T and the translation vector was <ref> [6; 5; 2] </ref> T . For knot, the rotation angle was 55 o around an axis [3; 0; 1] T and the translation vector was [2; 0; 2] T .
Reference: [7] <author> S. J. Dickinson, A. Pentland, and A. Rosenfeld. </author> <title> 3-D Shape Recovery Using Distributed Aspect Matching. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 14(2) </volume> <pages> 174-198, </pages> <year> 1992. </year>
Reference-contexts: The need for invariant image descriptors has long been recognized in computer vision [31, 42]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches <ref> [7, 9, 10] </ref>. Hence, it was even argued that object recognition is the search for invariants [42]. Invariant features can be designed based on many different methods and made invariant to rigid motion, general affine transform, scene illumination, occlusion, and projection.
Reference: [8] <author> L. E. Dickson. </author> <title> Algebraic Invariants. </title> <publisher> John-Wiley & Sons, </publisher> <year> 1914. </year>
Reference-contexts: 1 Introduction Image features and shape descriptors that capture the essential traits of an object and are insensitive to environmental changes are ideal for recognition. The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century <ref> [8, 23, 31] </ref>. The need for invariant image descriptors has long been recognized in computer vision [31, 42]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches [7, 9, 10].
Reference: [9] <author> D. Eggert and K. Bowyer. </author> <title> Computing the Perspective Projection Aspect Graph of Solids of Revolution. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 15(2) </volume> <pages> 109-128, </pages> <year> 1993. </year>
Reference-contexts: The need for invariant image descriptors has long been recognized in computer vision [31, 42]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches <ref> [7, 9, 10] </ref>. Hence, it was even argued that object recognition is the search for invariants [42]. Invariant features can be designed based on many different methods and made invariant to rigid motion, general affine transform, scene illumination, occlusion, and projection.
Reference: [10] <author> D. Eggert, K. Bowyer, C. R. Dyer, and H. I. Christensen. </author> <title> The Scale Space Aspect Graph. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 15(11) </volume> <pages> 1114-1130, </pages> <year> 1993. </year>
Reference-contexts: The need for invariant image descriptors has long been recognized in computer vision [31, 42]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches <ref> [7, 9, 10] </ref>. Hence, it was even argued that object recognition is the search for invariants [42]. Invariant features can be designed based on many different methods and made invariant to rigid motion, general affine transform, scene illumination, occlusion, and projection.
Reference: [11] <author> G. Farin. </author> <title> Algorithms for Rational Bezier Curves. </title> <journal> Comput. Aided Des., </journal> <volume> 15(2) </volume> <pages> 73-77, </pages> <month> Mar. </month> <year> 1983. </year>
Reference-contexts: Though rational basis functions, such as NURBS, have been widely known in the computer graphics community <ref> [2, 6, 11, 29, 39] </ref>, to the best of our knowledge they have never been used in computer vision before. The remainder of this paper is organized as follows: Sec. 2 presents the framework of image-derived invariants. <p> The projection process can be linearized using a tool which is well-established in computer graphics, but, to the best of our knowledge, has not been introduced into the computer vision community. The particular tool is the rational form of a basis function <ref> [2, 6, 11, 29, 39] </ref>. The most famous such expression is probably NURBS, stands for Non-Uniform Rational B-Spline, which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [21]. NURBS are invariants under perspective transform.
Reference: [12] <author> J. D. Foley, A. van Dam, S. K. Feiner, and J. F. Hughes. </author> <title> Computer Graphics: </title> <booktitle> Principles and Practice, 2nd ed. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1990. </year>
Reference-contexts: Based on a Lambertian model <ref> [12] </ref>, s (; t) is s (; t) = ( i=1 where n is the number of light sources used to illuminate the scene, l i () the source luminance spectral distribution, N the surface normal, N i the incident direction for source i, (; t) the surface reflectivity, and a
Reference: [13] <author> D. Forsyth. </author> <title> A Novel Algorithm for Color Constancy. </title> <journal> Int. J. Comput. Vision, </journal> <volume> 5 </volume> <pages> 5-36, </pages> <year> 1990. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length.
Reference: [14] <author> D. Forsyth, J. L. Mundy, A. Ziserman, A. Heller C. Coelho, and C. Rothwell. </author> <title> Invariant Descriptors for 3-D Object Recognition and Pose. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 13(10) </volume> <pages> 971-991, </pages> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint <ref> [1, 14, 20, 32, 34, 38, 41, 43] </ref>, while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3].
Reference: [15] <author> D. </author> <title> Gabor. </title> <journal> Theory of Communication. J. Inst. Elec. Eng., </journal> <volume> 93 </volume> <pages> 429-457, </pages> <year> 1946. </year>
Reference: [16] <author> R. Haralick and L. Shapiro. </author> <title> Computer and Robot Vision, Vol. I. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1992. </year>
Reference: [17] <author> G. Healey and A. Jain. </author> <title> Using Physics-Based Invariant Representations for the Recognition of Regions in Multi-spectral Images. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recognit., </journal> <pages> pages 750-755, </pages> <address> San Francisco, CA, </address> <month> Jun. 96. </month>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length. <p> fi fi fi fi [ u a 1 ;b 1 u a 2 ;b 2 u a k ;b k ] [ u a 1 ;b 1 u a 2 ;b 2 u a k ;b k ] T fi fi This derivation is in spirit similar to that of <ref> [17, 19] </ref>. By using a ratio expression, we obtain a much simpler and computationally efficient form of invariants which do not required computing the color correlation matrix and the singular value decomposition of such a matrix [17, 19]. <p> k ] T fi fi This derivation is in spirit similar to that of <ref> [17, 19] </ref>. By using a ratio expression, we obtain a much simpler and computationally efficient form of invariants which do not required computing the color correlation matrix and the singular value decomposition of such a matrix [17, 19]. Perspective Transform Finally, we observe that all the above derivations assume a planar curve under a parallel projection. Perspective foreshortening distortion was not addressed. Allowing perspective transform makes the problem much harder as the transformation is a non-linear process involving a division in computing 2D coordinates.
Reference: [18] <author> G. Healey and D. Slater. </author> <title> Global Color Constancy: Recognition of Objects by Use of Illumniation-Invariant Properties of Color Distributions. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 11(11) </volume> <pages> 3003-3010, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length.
Reference: [19] <author> G. Healey and L. Wang. </author> <title> Illumination-Invariant Recognition of Texture in Color Images. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 12(9) </volume> <pages> 1877-1883, </pages> <month> Sep. </month> <year> 1995. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length. <p> Following a path similar to that adopted by several researchers <ref> [19, 26, 27, 36] </ref>, we assume that surface reflectance functions are modeled as a linear combination of a small number of basis functions s k (), whence, s (; t) = k where s k () denotes the k-th basis function for representing the surface reflectance properties, and ff k (t) <p> fi fi fi fi [ u a 1 ;b 1 u a 2 ;b 2 u a k ;b k ] [ u a 1 ;b 1 u a 2 ;b 2 u a k ;b k ] T fi fi This derivation is in spirit similar to that of <ref> [17, 19] </ref>. By using a ratio expression, we obtain a much simpler and computationally efficient form of invariants which do not required computing the color correlation matrix and the singular value decomposition of such a matrix [17, 19]. <p> k ] T fi fi This derivation is in spirit similar to that of <ref> [17, 19] </ref>. By using a ratio expression, we obtain a much simpler and computationally efficient form of invariants which do not required computing the color correlation matrix and the singular value decomposition of such a matrix [17, 19]. Perspective Transform Finally, we observe that all the above derivations assume a planar curve under a parallel projection. Perspective foreshortening distortion was not addressed. Allowing perspective transform makes the problem much harder as the transformation is a non-linear process involving a division in computing 2D coordinates.
Reference: [20] <author> M. K. Hu. </author> <title> Pattern Recognition by Moment Invariants. </title> <booktitle> Proc. IRE, </booktitle> <address> 49:1428, </address> <year> 1961. </year>
Reference-contexts: Invariant features can be designed based on many different methods and made invariant to rigid motion, general affine transform, scene illumination, occlusion, and projection. For examples, popular image invariants have been designed based on Fourier transform [1] and moments <ref> [20, 34, 38] </ref>. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3]. <p> For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint <ref> [1, 14, 20, 32, 34, 38, 41, 43] </ref>, while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3]. <p> A transformed shape is generated by rotating the original shape 31 o counterclockwise, scaling it by a factor of 3 in x and a factor of 2 in y, and finally displacing it by <ref> [20; 4] </ref> T . A random amount of white noise, which can displace a contour point by up to two pixels in any direction, is added to each and every point in the transformed contour. The resulting shape is shown in dashed lines in Fig. 5 (a).
Reference: [21] <author> IGES. </author> <title> Initial Graphics Exchange Specifications, </title> <type> Ver. </type> <institution> 3.0. Nat. Bur. of Stds., Gaithersburg, MD, </institution> <year> 1986. </year>
Reference-contexts: The particular tool is the rational form of a basis function [2, 6, 11, 29, 39]. The most famous such expression is probably NURBS, stands for Non-Uniform Rational B-Spline, which was adopted as a standard for IGES (Initial Graphics Exchange Specification) <ref> [21] </ref>. NURBS are invariants under perspective transform.
Reference: [22] <author> R. Kondepudy and G. Healey. </author> <title> Use of Invariants for Recognition of Three-Dimensional Color Textures. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 11(11) </volume> <pages> 3037-3049, </pages> <month> Nov. </month> <year> 1994. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length.
Reference: [23] <author> E. P. Lane. </author> <title> Projective Differential Geometry of Curves and Surfaces. </title> <publisher> Univ. of Chicago Press, </publisher> <address> Chicago, IL, </address> <year> 1932. </year>
Reference-contexts: 1 Introduction Image features and shape descriptors that capture the essential traits of an object and are insensitive to environmental changes are ideal for recognition. The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century <ref> [8, 23, 31] </ref>. The need for invariant image descriptors has long been recognized in computer vision [31, 42]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches [7, 9, 10].
Reference: [24] <author> S. G. Mallat. </author> <title> A Theory for Multiresolution Signal Decomposition: The Wavelet Representation. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 11(7) </volume> <pages> 674-693, </pages> <year> 1989. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [4, 5, 6, 24, 25, 30, 33] </ref>. 5.) We introduce the rational basis functions to facilitate the analysis of invariants under perspective transform.
Reference: [25] <author> S. G. Mallat. </author> <title> Multifrequency Channel Decompositions of Images and Wavelet Models. </title> <journal> IEEE Trans. Acoust. Speech Signal Processing, </journal> <volume> 37 </volume> <pages> 2091-2110, </pages> <year> 1989. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [4, 5, 6, 24, 25, 30, 33] </ref>. 5.) We introduce the rational basis functions to facilitate the analysis of invariants under perspective transform.
Reference: [26] <author> L. Maloney. </author> <title> Evaluation of Linear Models of Surface Spectral Refelctance with Small Number of Parameters. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 3 </volume> <pages> 1673-1683, </pages> <year> 1986. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length. <p> Following a path similar to that adopted by several researchers <ref> [19, 26, 27, 36] </ref>, we assume that surface reflectance functions are modeled as a linear combination of a small number of basis functions s k (), whence, s (; t) = k where s k () denotes the k-th basis function for representing the surface reflectance properties, and ff k (t)
Reference: [27] <author> L. Maloney and B. Wandell. </author> <title> Color Constancy: A Method for Recovering Surface Spectral Reflectance. </title> <journal> Opt. Soc. Am. A, </journal> <volume> 3 </volume> <pages> 29-33, </pages> <year> 1986. </year> <month> 26 </month>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length. <p> Following a path similar to that adopted by several researchers <ref> [19, 26, 27, 36] </ref>, we assume that surface reflectance functions are modeled as a linear combination of a small number of basis functions s k (), whence, s (; t) = k where s k () denotes the k-th basis function for representing the surface reflectance properties, and ff k (t)
Reference: [28] <author> J. Michel, N. Nandhakumar, and V. Velten. </author> <title> Thermophysical Algebraic Invariants from Infrared Imagery for Object Recognition. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 19 </volume> <pages> 41-51, </pages> <year> 1987. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length.
Reference: [29] <author> L. Peigl and W. Tiller. </author> <title> Curve and Surface Contructions using Rational B-Splines. </title> <journal> Comput. Aided Des., </journal> <volume> 19(9) </volume> <pages> 485-498, </pages> <year> 1987. </year>
Reference-contexts: Though rational basis functions, such as NURBS, have been widely known in the computer graphics community <ref> [2, 6, 11, 29, 39] </ref>, to the best of our knowledge they have never been used in computer vision before. The remainder of this paper is organized as follows: Sec. 2 presents the framework of image-derived invariants. <p> The projection process can be linearized using a tool which is well-established in computer graphics, but, to the best of our knowledge, has not been introduced into the computer vision community. The particular tool is the rational form of a basis function <ref> [2, 6, 11, 29, 39] </ref>. The most famous such expression is probably NURBS, stands for Non-Uniform Rational B-Spline, which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [21]. NURBS are invariants under perspective transform.
Reference: [30] <author> L. R. Rabiner and D. W. Schafer. </author> <title> Digital Processing of Speech Signals. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1978. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [4, 5, 6, 24, 25, 30, 33] </ref>. 5.) We introduce the rational basis functions to facilitate the analysis of invariants under perspective transform.
Reference: [31] <author> T. H. Reiss. </author> <title> Recognizing Planar Objects Using Invariant Image Features. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1993. </year>
Reference-contexts: 1 Introduction Image features and shape descriptors that capture the essential traits of an object and are insensitive to environmental changes are ideal for recognition. The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century <ref> [8, 23, 31] </ref>. The need for invariant image descriptors has long been recognized in computer vision [31, 42]. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches [7, 9, 10]. <p> The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century [8, 23, 31]. The need for invariant image descriptors has long been recognized in computer vision <ref> [31, 42] </ref>. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches [7, 9, 10]. Hence, it was even argued that object recognition is the search for invariants [42]. <p> Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length. See <ref> [31, 42] </ref> for a comprehensive survey of the subject of invariants. The proposed framework for image-derived invariants builds upon past research on image invariants and basis expansion. <p> For invariants under general affine transform, many forms using ratios, cross ratios, and ratios of ratios have already been derived <ref> [31, 42] </ref>. For example, it is known that the cross ratio of four collinear points are invariant under the affine transform, and the area of the triangle formed by any three u a;b changes linearly in an affine transform (an invariant of weight 1 [31, 42]). <p> of ratios have already been derived <ref> [31, 42] </ref>. For example, it is known that the cross ratio of four collinear points are invariant under the affine transform, and the area of the triangle formed by any three u a;b changes linearly in an affine transform (an invariant of weight 1 [31, 42]).
Reference: [32] <author> E. Rivlin and I. Weiss. </author> <title> Local Invariants for Recognition. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 17(3) </volume> <pages> 226-238, </pages> <month> Mar. </month> <year> 1995. </year>
Reference-contexts: For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint <ref> [1, 14, 20, 32, 34, 38, 41, 43] </ref>, while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3].
Reference: [33] <author> D. F. Rogers and J. A. Adams. </author> <title> Mathematical Elements for Computer Graphics, 2nd Ed. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: We propose to use the framework with wavelet, short-time Fourier analysis, and spline bases, which have been widely used in signal and speech processing, image analysis, computer vision, and computer graphics <ref> [4, 5, 6, 24, 25, 30, 33] </ref>. 5.) We introduce the rational basis functions to facilitate the analysis of invariants under perspective transform. <p> Hence, the transformed curve can be generated using the transformed wavelet coefficients and the same wavelet bases, instead of transforming the curve point-by-point. This is an observation which is commonly made in the computer graphics community about curves generated by the spline functions and associated control vertices <ref> [2, 6, 33] </ref>. In that sense, u a;b 's function the same way as the control vertices in a spline curve. <p> fi fi mu a;b fi fi fi fi fi fi u c;d fi fi : If the second term in Eq. 1 is not zero, but is a constant (e.g., for spline functions, the area under a spline basis integrates to a constant 1 for a uniformly spaced knot vector <ref> [33] </ref>), then invariant expressions can still be derived, albeit in a slightly more complicated form: fi fi fi a;b u 0 u 0 g;h fi fi = fi fi (mu a;b + v) (mu c;d + v) fi fi fi fi fi fi m (u e;f u g;h ) fi fi <p> We will use NURBS to illustrate this invariant property under the perspective transform. In a nutshell, a b-spline function is a polynomial of a finite support. Non-rational b-spline functions of order k (or a polynomial of degree k 1) are generated by the Cox-deBoor recursion formulas <ref> [33] </ref>: N i;1 (t) = 1 if x i t &lt; x i+1 0 otherwise and (t x i )N i;k1 (t) + x i+k x i+1 The values of x i are elements of a knot vector satisfying the relations x i x i+1 . <p> p i R i;k (t) = i x i # X " Z i Z i R i;k (t) ; (8) where R i;k (t) = P : To illustrate, Fig. 2 shows the rational b-spline bases of order four (third-degree polynomial) for an open knot vector [X] = [000012222] <ref> [33] </ref>. By varying the Z coordinates of the associated control vertices, the shape of the bases adapts accordingly. When all the Z's are equal, the rational bases in fact reduce to the non-rational bases as expected. Fig. 3 shows sample b-spline curves using both periodical and open knot vectors [33]. <p> [000012222] <ref> [33] </ref>. By varying the Z coordinates of the associated control vertices, the shape of the bases adapts accordingly. When all the Z's are equal, the rational bases in fact reduce to the non-rational bases as expected. Fig. 3 shows sample b-spline curves using both periodical and open knot vectors [33]. Column (a) in Fig. 3 shows curves generated using non-rational spline bases in space. Columns (b) and (c) show the projections of the 3D curves using two different methods: One is generating points along the 3D curves in Fig. 3 (a), then projecting them one by one. <p> The resulting shape is shown in dashed lines in Fig. 5 (a). We use the second-order b-spline function of a uniform knot vector <ref> [33] </ref> in the basis expansion step. The spline basis is approximated by a vector of length three: [0:1; 1:0; 0:1] T .
Reference: [34] <author> F. A. Sadjadi and E. L. Hall. </author> <title> Three-Dimensional Moment Invariants. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 2 </volume> <pages> 127-136, </pages> <month> Mar. </month> <year> 1980. </year>
Reference-contexts: Invariant features can be designed based on many different methods and made invariant to rigid motion, general affine transform, scene illumination, occlusion, and projection. For examples, popular image invariants have been designed based on Fourier transform [1] and moments <ref> [20, 34, 38] </ref>. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3]. <p> For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint <ref> [1, 14, 20, 32, 34, 38, 41, 43] </ref>, while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3].
Reference: [35] <author> R. Sedgewick. </author> <title> Algorithms, 2nd ed. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference: [36] <author> D. Slater and G. Healey. </author> <title> The Illumination-Invariant Recognition of 3D Objects Using Local Color Invariants. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 18(2) </volume> <pages> 206-210, </pages> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length. <p> Following a path similar to that adopted by several researchers <ref> [19, 26, 27, 36] </ref>, we assume that surface reflectance functions are modeled as a linear combination of a small number of basis functions s k (), whence, s (; t) = k where s k () denotes the k-th basis function for representing the surface reflectance properties, and ff k (t)
Reference: [37] <author> D. Slater and G. Healey. </author> <title> Using a Spectral Reflectance Model for the Illumination-Invariant Recognition of Local Image Structure. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recognit., </journal> <pages> pages 770-775, </pages> <address> San Francisco, CA, </address> <month> Jun. </month> <year> 1996. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length.
Reference: [38] <author> C. H. Teh and R. Chin. </author> <title> On Image Analysis by the Methods of Moments. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 10(4) </volume> <pages> 496-513, </pages> <month> Jul. </month> <year> 1988. </year>
Reference-contexts: Invariant features can be designed based on many different methods and made invariant to rigid motion, general affine transform, scene illumination, occlusion, and projection. For examples, popular image invariants have been designed based on Fourier transform [1] and moments <ref> [20, 34, 38] </ref>. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3]. <p> For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint <ref> [1, 14, 20, 32, 34, 38, 41, 43] </ref>, while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3].
Reference: [39] <author> W. Tiller. </author> <title> Rational B-Splines for Curve and Surface Representation. </title> <journal> IEEE Comput. Graphics & App., </journal> <volume> 3(6) </volume> <pages> 61-69, </pages> <year> 1987. </year>
Reference-contexts: Though rational basis functions, such as NURBS, have been widely known in the computer graphics community <ref> [2, 6, 11, 29, 39] </ref>, to the best of our knowledge they have never been used in computer vision before. The remainder of this paper is organized as follows: Sec. 2 presents the framework of image-derived invariants. <p> The projection process can be linearized using a tool which is well-established in computer graphics, but, to the best of our knowledge, has not been introduced into the computer vision community. The particular tool is the rational form of a basis function <ref> [2, 6, 11, 29, 39] </ref>. The most famous such expression is probably NURBS, stands for Non-Uniform Rational B-Spline, which was adopted as a standard for IGES (Initial Graphics Exchange Specification) [21]. NURBS are invariants under perspective transform.
Reference: [40] <author> L. Wang and G. Healey. </author> <title> Illumination and Geometry Invariant Recognition of Texture in Color Images. </title> <journal> In Proc. IEEE Comput. Soc. Conf. Comput. Vision and Pattern Recognit., </journal> <pages> pages 419-424, </pages> <address> San Francisco, CA, </address> <month> Jun. </month> <year> 1996. </year>
Reference-contexts: Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint [1, 14, 20, 32, 34, 38, 41, 43], while others are immune to changes in illumination <ref> [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40] </ref>, and occlusion [3]. Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length.
Reference: [41] <author> D. Weinshall. </author> <title> Model-Based Invariants for 3-D Vision. </title> <journal> Int. J. Comput. Vision, </journal> <volume> 10(1) </volume> <pages> 27-42, </pages> <year> 1993. </year>
Reference-contexts: For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint <ref> [1, 14, 20, 32, 34, 38, 41, 43] </ref>, while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3].
Reference: [42] <author> I. Weiss. </author> <title> Geometric Invariants and Object Recognition. </title> <journal> Int. J. Comput. Vision, </journal> <volume> 10(3) </volume> <pages> 207-231, </pages> <year> 1993. </year>
Reference-contexts: The search for invariants (e.g., algebraic and projective invariants) is a classical problem in mathematics dating back to the 18th century [8, 23, 31]. The need for invariant image descriptors has long been recognized in computer vision <ref> [31, 42] </ref>. Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches [7, 9, 10]. Hence, it was even argued that object recognition is the search for invariants [42]. <p> Invariant features form a compact, intrinsic description of an object, and can be used to design recognition algorithms that are potentially more efficient than, say, the aspect-based approaches [7, 9, 10]. Hence, it was even argued that object recognition is the search for invariants <ref> [42] </ref>. Invariant features can be designed based on many different methods and made invariant to rigid motion, general affine transform, scene illumination, occlusion, and projection. For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. <p> Invariants can be computed either fl Originally submitted on February 7th, revised on March 21st 1 globally, such is the case in moment invariants, or based on local properties such as curvature and arc length. See <ref> [31, 42] </ref> for a comprehensive survey of the subject of invariants. The proposed framework for image-derived invariants builds upon past research on image invariants and basis expansion. <p> For invariants under general affine transform, many forms using ratios, cross ratios, and ratios of ratios have already been derived <ref> [31, 42] </ref>. For example, it is known that the cross ratio of four collinear points are invariant under the affine transform, and the area of the triangle formed by any three u a;b changes linearly in an affine transform (an invariant of weight 1 [31, 42]). <p> of ratios have already been derived <ref> [31, 42] </ref>. For example, it is known that the cross ratio of four collinear points are invariant under the affine transform, and the area of the triangle formed by any three u a;b changes linearly in an affine transform (an invariant of weight 1 [31, 42]).
Reference: [43] <author> I. Weiss. </author> <title> Noise-Resistant Invariants of Curves. </title> <journal> IEEE Trans. Pattern Analy. Machine Intell., </journal> <volume> 15(9) </volume> <pages> 943-948, </pages> <month> Sep. </month> <year> 1993. </year>
Reference-contexts: For examples, popular image invariants have been designed based on Fourier transform [1] and moments [20, 34, 38]. Many such invariant features are insensitive to changes in geometry induced by motion and change of viewpoint <ref> [1, 14, 20, 32, 34, 38, 41, 43] </ref>, while others are immune to changes in illumination [13, 18, 19, 17, 22, 26, 27, 28, 36, 37, 40], and occlusion [3].
References-found: 43

