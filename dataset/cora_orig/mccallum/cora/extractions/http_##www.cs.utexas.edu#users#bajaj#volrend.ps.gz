URL: http://www.cs.utexas.edu/users/bajaj/volrend.ps.gz
Refering-URL: http://www.cs.utexas.edu/users/bajaj/
Root-URL: http://www.cs.utexas.edu
Title: Efficient Techniques for Volume Rendering of Scalar Fields DATA VISUALIZATION TECHNIQUES,  
Note: Edited by C. Bajaj c 1998 John Wiley Sons Ltd  
Abstract-found: 0
Intro-found: 0
Reference: <institution> 16/2/1998 23:55|PAGE PROOFS for John Wiley & Sons Ltd|book References </institution>
Reference: [ABSS94] <author> V. Anupam, C. Bajaj, D. Schikore, and M. Schikore. </author> <title> Distributed and Collaborative Volume Visualization. </title> <journal> IEEE Computer, </journal> <volume> 27(7):37 - 43, </volume> <year> 1994. </year>
Reference-contexts: Only three reported implementations <ref> [ABSS94] </ref>, [YM95], [WS93] and one recent work [LY96b] are known. Bajaj et. al. [ABSS94] consider both image space and object space partitioning methods for load balancing. The volume rendering calculation programs were tested on a high speed network of Sun workstations. <p> Only three reported implementations <ref> [ABSS94] </ref>, [YM95], [WS93] and one recent work [LY96b] are known. Bajaj et. al. [ABSS94] consider both image space and object space partitioning methods for load balancing. The volume rendering calculation programs were tested on a high speed network of Sun workstations. Wit-tenbrink and Somani's [WS93] method is applicable to affine transformations.
Reference: [AGS95] <author> A. B. Amin, A. Grama, and V. Singh. </author> <title> Fast volume rendering using an efficient, scalable parallel formulation of the shear-warp algorithm. </title> <booktitle> In Proceedings 1995 Parallel Rendering Symposium, </booktitle> <pages> pages 7-14, </pages> <address> Atlanta, GA, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: While waiting, it transforms the next assigned slice. One disadvantage of this implementation is the sorting which is required for each of the slices. The efficient shearing algorithm [LL94] was also parallelized, for a shared-memory architecture (Silicon Graphics Challenge) [Lac95] and on TMC CM-5 <ref> [AGS95] </ref>. In [Lac95], synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events.
Reference: [ASK92] <author> R. Avila, L. M. Sobierajski, and A. E. Kaufman. </author> <title> Towards a comprehensive volume visualization systems. </title> <booktitle> In Proceedings Visualization'92, </booktitle> <pages> pages 13-20, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The object is surrounded by a tightly fit box (or other easy-to-intersect object such as sphere). Rays are intersected with the bounding object and start their actual volume traversal from this intersection point as opposed to starting from the volume boundary. The PARC (Polygon Assisted Ray Casting) approach <ref> [ASK92] </ref> strives to have a better fit by allowing a polyhedral envelope to be constructed around the object (see Figure 2.2b).
Reference: [BFGS86] <author> L. Bergman, H. Fuchs, E. Grant, and S. Spach. </author> <title> Image rendering by adaptive refinement. </title> <journal> Computer Graphics, </journal> <volume> 20(4) </volume> <pages> 29-37, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: Therefore it is observed that it might be the case that we could avoid sending a ray for such obviously identical pixels. The adaptive image supersampling, exploits the pixel-space coherency. It was originally developed for traditional ray-tracing <ref> [BFGS86] </ref> and later adapted to volume rendering [Lev90b]. First, rays are cast from only a subset of the screen pixels (e.g., every other pixel). `Empty pixels' residing between pixels with similar value are assigned an interpolated value. In areas of high image gradient additional rays are cast to resolve ambiguities.
Reference: [CCF94] <author> B. Cabral, N. Cam, and J. Foran. </author> <title> Accelerated volume rendering and tomo-graphic reconstruction using texture mapping hardware. </title> <booktitle> In Proceedings 1994 Symposium on Volume Visualization, </booktitle> <pages> pages 91-98, </pages> <year> 1994. </year>
Reference-contexts: However, these polygon rendering engines seem inherently unsuitable to the task. Recently, some new methods have tapped to this rendering power by either utilizing texture mapping capabilities for rendering splats [Cra95], [LH91], or by exploiting solid texturing capabilities to implement a slicing-based volume rendering <ref> [CCF94] </ref>. The Volume Splatter [YESK95] relies on the notion of fuzzy voxel set which consists of a subset of the volume's voxels. For each voxel in the original volume, we evaluate a transfer function that maps the gradient and the density of the given voxel to an `importance' number. <p> These three dimensional rasters (called 3D texture maps) are mapped on polygons in 3D space using either zero order or first order interpolation. By rendering polygons slicing the volume and perpendicular to the view direction one generates a view of a rectangular volume data set <ref> [CCF94] </ref>. Rendering these polygons from back to front and blending them into the frame buffer generates a correct image of the volume (see Figure 2.5). <p> Some examples of this trend are <ref> [CCF94] </ref>, [Cra95], [LH91], [YSW + 96]. While fastest known parallel implementations achieve close to real-time ( 10 frames per second) on expensive high-end parallel machines [Lac95], the same, or even slightly better performance is achieved on mid-range texture hardware [CCF94]. <p> Some examples of this trend are <ref> [CCF94] </ref>, [Cra95], [LH91], [YSW + 96]. While fastest known parallel implementations achieve close to real-time ( 10 frames per second) on expensive high-end parallel machines [Lac95], the same, or even slightly better performance is achieved on mid-range texture hardware [CCF94].
Reference: [CM92] <author> B. Corrie and P. Mackerras. </author> <title> Parallel volume rendering and data coherence on the Fujitsu AP100. </title> <type> Technical Report TR-CS-92-11, </type> <institution> Department of Computer Science, Australian National University, Canberra, ACT, Australia, </institution> <year> 1992. </year>
Reference-contexts: A dynamic data distribution scheme is used to assign the slices to the various nodes. An efficient incremental transformation method, was used for transforming each slice. Corrie and Mackerras employed the Fujitsu AP1000 MIMD multiprocessor to implement a ray-caster <ref> [CM92] </ref>. A master slave paradigm was used to dynamically distribute square regions of pixels to slave cells. An adaptive distribution scheme is obtained by having the slave cells notify the master when they spend more than their allocated time to render the assigned image.
Reference: [Cra95] <author> R. Crawfis. </author> <title> New techniques for the scientific visualization of three-dimensional multi-variate and vector fields. </title> <type> PhD thesis, </type> <institution> University of California, Davis, </institution> <year> 1995. </year>
Reference-contexts: However, these polygon rendering engines seem inherently unsuitable to the task. Recently, some new methods have tapped to this rendering power by either utilizing texture mapping capabilities for rendering splats <ref> [Cra95] </ref>, [LH91], or by exploiting solid texturing capabilities to implement a slicing-based volume rendering [CCF94]. The Volume Splatter [YESK95] relies on the notion of fuzzy voxel set which consists of a subset of the volume's voxels. <p> Some examples of this trend are [CCF94], <ref> [Cra95] </ref>, [LH91], [YSW + 96]. While fastest known parallel implementations achieve close to real-time ( 10 frames per second) on expensive high-end parallel machines [Lac95], the same, or even slightly better performance is achieved on mid-range texture hardware [CCF94].
Reference: [CS93] <author> D. Cohen and Z. Shefer. </author> <title> Proximity clouds an acceleration technique for 3D grid traversal. </title> <type> Technical Report FC 93-01, </type> <institution> Ben Gurion University of the Negev, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Rays which are cast into the volume encounter either a data voxel, or a voxel containing `uniformity information' which instructs the ray to perform a leap forward that brings it to the first voxel beyond the uniform region <ref> [CS93] </ref>. This approach saves the need to perform a tree search for the appropriate neighbor an operation that is the most time consuming and the major disadvantage in the hierarchical data structure. <p> This flags the need to switch to a more accurate ray traversal algorithm. Encountering later an empty voxel (i.e., unoccupied and not carrying the vicinity flag) can signal a switch back to the rapid traversal of empty space. The proximity-clouds method <ref> [CS93] </ref>, [ZKV92] is based on the extension of this idea even further. Instead of having a one-voxel-deep vicinity cloud this method computes, in a preprocessing stage, for each empty voxel, the distance to the closest occupied voxel. <p> This suggests that the ray can take a n-step leap forward, being assured that there is no object in the skipped span of voxels. The effectiveness of this algorithm is obviously dependent on the ability of the line traversal algorithm to efficiently jump arbitrary number of steps <ref> [CS93] </ref>. 2.3 Parallel and Distributed Architectures The viewing algorithms adopted for parallel implementations are many and varied. Both traditional direct volume rendering methods, namely feed-forward and backward-feed as well as an hybrid approach, was adapted for parallel processors.
Reference: [CU92] <author> G. G. Cameron and P. E. Underill. </author> <title> Rendering volumetric medical image data on a SIMD architecture computer. </title> <booktitle> In Proceedings of Third Eurographics Workshop on Rendering, </booktitle> <pages> pages 135-145, </pages> <address> Bristol, UK, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The master then subdivides the image region further and distributes the new sub-regions to idle cells. To support such a dynamic scheme the volume is replicated among clusters of neighboring cells. The template based viewing method [YK92] has been successfully implemented in <ref> [CU92] </ref>, [SS92] on SIMD machines. Both implementations are very similar. Parallel rays are traced in a lock step fashion by all nodes of the SIMD node. Each node is mapped to a voxel in both implementations. Shading, interpolation and compositing is done by each processor along the ray.
Reference: [DCH88] <author> R. A. Drebin, L. Carpenter, and P. Hanrahan. </author> <title> Volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 65-74, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: One solution is based on transforming each slice from voxel-space to pixel-space using 3D affine transformation (shearing) [Han90], [LL94], [SS91] followed by projection onto the screen in a FTB fashion, and blending with the projection formed by previous slices <ref> [DCH88] </ref>. Westover [Wes90] has introduced another reconstruction technique for forward viewing methods the splatting algorithm. Each voxel, after being transformed into screen space is blurred, based on a 2D lookup table (footprint) that spreads the voxel's energy across multiple pixels. These are then composited with the image array.
Reference: [DH92] <author> J. Danskin and P. Hanrahan. </author> <title> Fast algorithms for volume ray tracing. </title> <booktitle> In Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 91-105, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: Recently, this basic idea was extended to efficiently lower the sampling rate in either areas where only small contributions of opacities are made, or in regions where the volume is homogeneous <ref> [DH92] </ref>. This method efficiently detects regions of low presence or low variation by employing a pyramid of volumes that decode the minimum and maximum voxel value in a small neighborhood, as well as the distance between these measures. <p> One early example of this trend is the shear-warp algorithm that combines the work on shearing-based rendering [Han90], run-length encoding [RGC87], min-max pyramids <ref> [DH92] </ref>, and multi-dimensional summed area tables. * Parallel implementations on state-of-the art distributed shared-memory machines, taking advantage of hardware caches and interleaved dedicated communication processors.
Reference: [FGR85] <author> G. Frieder, D. Gordon, and R. A. Reynolds. </author> <title> Back-to-front display of voxel-based objects. </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 5(1) </volume> <pages> 52-60, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: This avoids the need for a Z-buffer for hidden voxel removal considerations by simply drawing the current voxel on top of previously drawn voxels (`painter's algorithm') or by compositing the current voxel with the screen value [FZY84], <ref> [FGR85] </ref>. The front-to-back (FTB) algorithm is essentially the same as BTF only that now the voxels are traversed in increasing distance order [RGC87]. <p> These methods are: recursive `divide and conquer' [Mea82], pre-calculated tables <ref> [FGR85] </ref>, incremental transformation [MYS92], and shearing-based transforms [Han90]. The first method [Mea82] exploits coherency in voxel space by representing the 3D volume by an octree. <p> In addition, since each octree node has 16/2/1998 23:55|PAGE PROOFS for John Wiley & Sons Ltd|book Volume Rendering 7 eight equally-sized octants, given the transformation of the parent node, the transformation of its sub-octants can be efficiently computed. The table-driven transformation method <ref> [FGR85] </ref> is based on the observation that volume transformation involves the multiplication of the matrix elements with integer values which are always in the range [1 : : : N ], where N is the volume resolution.
Reference: [Fru92] <author> T. Fruhauff. </author> <title> Volume rendering on a multiprocessor architecture with shared memory: A concurrent volume rendering algorithm. </title> <booktitle> In Proceedings of the Third Eurographics Workshop on Scientific Visualization, </booktitle> <address> Pisa, Italy, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Later when each node is finished all these portions are combined to obtain the color. Such a scheme can lead to a load balanced and scalable implementation and the data distribution scheme maps well to the Hypercube interconnection network. Fruhaff's implementation on a multiprocessor Silicon Graphics workstation <ref> [Fru92] </ref> is similar in spirit to Schroeder and Salem's implementation on CM-2. The volume is rotated along the viewing rays and then parallel rays are cast. A dynamic data distribution scheme is used to assign the slices to the various nodes.
Reference: [FZY84] <author> E. J. Farrell, R. Zappulla, and W. C. Yang. </author> <title> Color 3d imaging of normal and pathologic intracranial structures. </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 4(9) </volume> <pages> 5-17, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: This avoids the need for a Z-buffer for hidden voxel removal considerations by simply drawing the current voxel on top of previously drawn voxels (`painter's algorithm') or by compositing the current voxel with the screen value <ref> [FZY84] </ref>, [FGR85]. The front-to-back (FTB) algorithm is essentially the same as BTF only that now the voxels are traversed in increasing distance order [RGC87].
Reference: [GR90] <author> B. Gudmundsson and M. Randen. </author> <title> Incremental generation of projections of CT-volumes. </title> <booktitle> In Proceedings of the First Conference on Visualization in Biomedical Computing, </booktitle> <pages> pages 27-34, </pages> <address> Atlanta, GA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: For each change in the viewing parameters, the C-buffer is transformed accordingly. In the case of rotation the transformed C-buffer goes through a process of eliminating coordinates that possibly became hidden <ref> [GR90] </ref>. The remaining values in the C-buffer serve as an estimate of the point where the new rays should start their volume traversal. Space-leaping The passage of a ray through the volume is two phased.
Reference: [Han90] <author> P. Hanrahan. </author> <title> Three-pass affine transforms for volume rendering. In Proceedings DATA VISUALIZATION TECHNIQUES, Edited by C. Bajaj c fl 1998 John Wiley & Sons Ltd 22 REFERENCES SIGGRAPH '90 Conference, </title> <booktitle> volume 24 of Computer Graphics, </booktitle> <pages> pages 71-78, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: One of the main difficulties in the naive approach described above is the proper signal reconstruction and resampling required when one transforms a discrete set of samples. One solution is based on transforming each slice from voxel-space to pixel-space using 3D affine transformation (shearing) <ref> [Han90] </ref>, [LL94], [SS91] followed by projection onto the screen in a FTB fashion, and blending with the projection formed by previous slices [DCH88]. Westover [Wes90] has introduced another reconstruction technique for forward viewing methods the splatting algorithm. <p> These methods are: recursive `divide and conquer' [Mea82], pre-calculated tables [FGR85], incremental transformation [MYS92], and shearing-based transforms <ref> [Han90] </ref>. The first method [Mea82] exploits coherency in voxel space by representing the 3D volume by an octree. A group of neighboring voxels having the same value (or similar, up to a threshold value) may, under some restrictions, be grouped into a uniform cubic subvolume. <p> The shearing algorithm decomposes the 3D affine transformation into five 1D shearing transformations <ref> [Han90] </ref>. The major advantage of this approach is its ability (using simple averaging techniques) to overcome some of the sampling problems causing the production of low quality images. In addition, this approach replaces the 3D transformation by five 1D transformations which require only one floating-point addition each. <p> These can be tested against each other in runs rather than by comparing individual voxels. This idea was later adopted for expediting the shearing algorithm [LL94]. The shearing algorithm was also optimized [LL94] by devising a factorization that is faster than the original decomposition <ref> [Han90] </ref>. Also, they introduced a data structure for encoding spatial coherence in unclassified volumes (i.e. scalar fields with no precomputed opacity). 2.2.2 Optimizing Image-Space Backward Rendering Backward viewing of volumes, based on casting rays, has three major variations: parallel (orthographic) ray casting, perspective ray casting, and ray tracing. <p> One early example of this trend is the shear-warp algorithm that combines the work on shearing-based rendering <ref> [Han90] </ref>, run-length encoding [RGC87], min-max pyramids [DH92], and multi-dimensional summed area tables. * Parallel implementations on state-of-the art distributed shared-memory machines, taking advantage of hardware caches and interleaved dedicated communication processors.
Reference: [KCY93] <author> A. E. Kaufman, D. Cohen, and R. Yagel. </author> <title> Volumetric graphics. </title> <journal> IEEE Computer, </journal> <volume> 26(7) </volume> <pages> 51-64, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: Rendering and processing does not depend of the object's complexity or type, it depends only on volume resolution. It easily supports operations such as subtraction, addition, collision detection, and deformation. For a complete comparison see <ref> [KCY93] </ref>. Although compute power required for volume rendering is immense, so are the benefits from some potential applications which rely on such capability. One such application is the simulation of surgery on a virtual patient [YSW + 96].
Reference: [KH84] <author> J. T. Kajiya and B. P. V. Herzen. </author> <title> Ray tracing volume densities. </title> <journal> Computer Graphics, </journal> <volume> 18(3) </volume> <pages> 165-174, </pages> <month> July </month> <year> 1984. </year>
Reference-contexts: Alternatively, the volume is sampled at the intersection points of the ray and the voxels' faces, its value is interpolated, and then composited [UK88]. A more precise algorithm uses higher order interpolation to estimate the appropriate value at evenly spaced sample points along the ray <ref> [KH84] </ref>, [Lev88], [Sab88]. Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reflection, shadows, and refraction.
Reference: [Kru90] <author> W. Krueger. </author> <title> The application of transport theory to visualization of 3D scalar data field. </title> <booktitle> In Proceedings Visualization '90, </booktitle> <pages> pages 273-280, </pages> <address> San Francisco, CA, </address> <month> October </month> <year> 1990. </year>
Reference-contexts: These can vary from a simple illumination model (threshold, followed by color lookup, and depth shading) to the most complex illumination (segmentation, followed by multivariate transfer function, followed by multi-scattering illumination model <ref> [Kru90] </ref>, [Max95]). In the following discussion we will assume that the volume has been illuminated already and we are left with the task of rendering the 3D grids of RGBff values. Assume we need to render a volume of size N fi N fi N voxels.
Reference: [KY95] <author> Y. Kurzion and R. Yagel. </author> <title> Volume deformation using Ray Deflectors. </title> <booktitle> In The 6th Eurographics Workshop on Rendering, </booktitle> <pages> pages 33-44, </pages> <address> Dublin, Ireland, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: The first is based on recursively following secondary rays and shadow feelers [YCK92], as in traditional ray tracing. Volume deformation is based on bending the path the rays take, according to the influence of `gravity fields' called deflectors <ref> [KY95] </ref>. The simplest method for implementing resampling performs zero order interpolation to locate the nearest voxel while stepping along the discrete ray representation which is generated by a 3D line algorithm [SSW86]. <p> Rendering these polygons from back to front and blending them into the frame buffer generates a correct image of the volume (see Figure 2.5). In order to use this hardware assisted volume rendering technique for volume deformation <ref> [KY95] </ref>, we must compensate for the main difference between the two mapping techniques: In hardware assisted volume rendering we map a three dimensional raster onto a polygon by interpolating the 3D raster coordinates of the polygon vertices. In other words, the mapping is linear across an entire polygon.
Reference: [Lac95] <author> P. Lacroute. </author> <title> Real-time volume rendering on shared memory multiprocessors using the shear-warp factorization. </title> <booktitle> In Proceedings 1995 Parallel Rendering Symposium, </booktitle> <pages> pages 15-22, </pages> <address> Atlanta, GA, </address> <month> October </month> <year> 1995. </year>
Reference-contexts: While waiting, it transforms the next assigned slice. One disadvantage of this implementation is the sorting which is required for each of the slices. The efficient shearing algorithm [LL94] was also parallelized, for a shared-memory architecture (Silicon Graphics Challenge) <ref> [Lac95] </ref> and on TMC CM-5 [AGS95]. In [Lac95], synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events. <p> While waiting, it transforms the next assigned slice. One disadvantage of this implementation is the sorting which is required for each of the slices. The efficient shearing algorithm [LL94] was also parallelized, for a shared-memory architecture (Silicon Graphics Challenge) <ref> [Lac95] </ref> and on TMC CM-5 [AGS95]. In [Lac95], synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events. <p> Some examples of this trend are [CCF94], [Cra95], [LH91], [YSW + 96]. While fastest known parallel implementations achieve close to real-time ( 10 frames per second) on expensive high-end parallel machines <ref> [Lac95] </ref>, the same, or even slightly better performance is achieved on mid-range texture hardware [CCF94].
Reference: [Lev88] <author> M. Levoy. </author> <title> Display of surfaces from volume data. </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 8(5) </volume> <pages> 29-37, </pages> <month> May </month> <year> 1988. </year> <title> [Lev90a] . Efficient ray tracing of volume data. </title> <journal> ACM Transactions on Graphics, </journal> 9(3):245-261, July 1990. [Lev90b] . Volume rendering by adaptive refinement. The Visual Computer, 6(1):2-7, February 1990. 
Reference-contexts: In contrast to the forward viewing approach, the backward viewing scheme (also called image space method) casts a ray from the eye, through each pixel on the screen, into the volume data, until it intersect an opaque object or accumulates an opaque value through compositing <ref> [Lev88] </ref>, [TT84], [UK88]. Backward viewing is much more powerful than forward viewing since it can be extended to support global illumination and volume deformation. The first is based on recursively following secondary rays and shadow feelers [YCK92], as in traditional ray tracing. <p> Alternatively, the volume is sampled at the intersection points of the ray and the voxels' faces, its value is interpolated, and then composited [UK88]. A more precise algorithm uses higher order interpolation to estimate the appropriate value at evenly spaced sample points along the ray [KH84], <ref> [Lev88] </ref>, [Sab88]. Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reflection, shadows, and refraction.
Reference: [LH91] <author> D. Laur and P. Hanrahan. </author> <title> Hierarchical splatting: A progressive refinement algorithm for volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 285-288, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: These ideas was further explored to allow non-binary surfaces by extracting all voxels that contribute to the final image [YESK95]. Another efficient implementation of the splatting algorithm, called hierarchical splatting <ref> [LH91] </ref> uses a pyramid data structure to hold a multi-resolution representation of the volume. For a volume of N 3 resolution, the pyramid data structure consists of a sequence of log N volumes. <p> However, these polygon rendering engines seem inherently unsuitable to the task. Recently, some new methods have tapped to this rendering power by either utilizing texture mapping capabilities for rendering splats [Cra95], <ref> [LH91] </ref>, or by exploiting solid texturing capabilities to implement a slicing-based volume rendering [CCF94]. The Volume Splatter [YESK95] relies on the notion of fuzzy voxel set which consists of a subset of the volume's voxels. <p> Some examples of this trend are [CCF94], [Cra95], <ref> [LH91] </ref>, [YSW + 96]. While fastest known parallel implementations achieve close to real-time ( 10 frames per second) on expensive high-end parallel machines [Lac95], the same, or even slightly better performance is achieved on mid-range texture hardware [CCF94].
Reference: [LL94] <author> P. Lacroute and M. Levoy. </author> <title> Fast volume rendering using a shear-warp factorization of the viewing transformation. </title> <booktitle> In Proceedings SIGGRAPH '94 Conference, volume 28 of Computer Graphics, </booktitle> <pages> pages 451-458, </pages> <address> Orlando, FL, </address> <month> July 24-29 </month> <year> 1994. </year> <note> ACM SIGGRAPH. </note>
Reference-contexts: One of the main difficulties in the naive approach described above is the proper signal reconstruction and resampling required when one transforms a discrete set of samples. One solution is based on transforming each slice from voxel-space to pixel-space using 3D affine transformation (shearing) [Han90], <ref> [LL94] </ref>, [SS91] followed by projection onto the screen in a FTB fashion, and blending with the projection formed by previous slices [DCH88]. Westover [Wes90] has introduced another reconstruction technique for forward viewing methods the splatting algorithm. <p> The transformation guarantees that a row of voxels always transforms into a row of pixels. These can be tested against each other in runs rather than by comparing individual voxels. This idea was later adopted for expediting the shearing algorithm <ref> [LL94] </ref>. The shearing algorithm was also optimized [LL94] by devising a factorization that is faster than the original decomposition [Han90]. <p> The transformation guarantees that a row of voxels always transforms into a row of pixels. These can be tested against each other in runs rather than by comparing individual voxels. This idea was later adopted for expediting the shearing algorithm <ref> [LL94] </ref>. The shearing algorithm was also optimized [LL94] by devising a factorization that is faster than the original decomposition [Han90]. <p> A graphics processor waits for the a circulating token to reach it before it can send the next slice for rendering. While waiting, it transforms the next assigned slice. One disadvantage of this implementation is the sorting which is required for each of the slices. The efficient shearing algorithm <ref> [LL94] </ref> was also parallelized, for a shared-memory architecture (Silicon Graphics Challenge) [Lac95] and on TMC CM-5 [AGS95]. In [Lac95], synchronization time is minimized by using dynamic load balancing and a task partition that minimizes synchronization events.
Reference: [LY95] <author> A. Law and R. Yagel. Cellflow: </author> <title> A parallel rendering scheme for distributed memory architectures. </title> <booktitle> In Proceedings of International Conference on Parallel and Distributed Processing Techniques and Applications (PDPTA `95), </booktitle> <pages> pages 1-10, </pages> <month> November </month> <year> 1995. </year> <title> [LY96a] . Exploiting spatial, ray, and frame coherency for efficient parallel volume rendering. </title> <booktitle> In GRAPHICON '96, </booktitle> <address> Saint-Petersburg, Russia, </address> <month> July </month> <year> 1996. </year> <title> [LY96b] . Multi-frame thrashless ray casting with advancing ray-front. </title> <booktitle> In Graphics Interface '96, </booktitle> <pages> pages 71-77, </pages> <address> Toronto, Canada, </address> <month> May </month> <year> 1996. </year> <title> [LY96c] . An optimal ray traversal scheme for visualizing colossal medical volumes. </title> <booktitle> Visualization in Biomedical Computing, </booktitle> <month> September </month> <year> 1996. </year>
Reference-contexts: These algorithms are primarily based on efficient utilization of local memory and attempt to hide the latency of locally unavailable objects. The irregularity and unpredictability of the problem at hand makes these features all the more difficult to achieve. Recently, the CellFlow method [LYJ96], <ref> [LY95] </ref>, has been implemented on some distributed shared memory architectures. It is based on exploiting coherency between frames in an animation sequence. <p> Several examples of this trend are already available <ref> [LY95] </ref>, [LY96b], [LY96c]. * Migration of low-end volume rendering application into the PC domain, taking advantage of the recent giagantaic leap in graphics boards for PC. * Increased utilization of existing general purpose, affordable graphics engine with the final disappearance of special purpose volume engines.
Reference: [LYJ96] <author> A. Law, R. Yagel, and D. N. Jayasimha. Voxelflow: </author> <title> A parallel volume rendering method for scientific visualization. </title> <journal> ISCA Journal of Computers & Their Applications, </journal> <month> April </month> <year> 1996. </year>
Reference-contexts: These algorithms are primarily based on efficient utilization of local memory and attempt to hide the latency of locally unavailable objects. The irregularity and unpredictability of the problem at hand makes these features all the more difficult to achieve. Recently, the CellFlow method <ref> [LYJ96] </ref>, [LY95], has been implemented on some distributed shared memory architectures. It is based on exploiting coherency between frames in an animation sequence.
Reference: [Max95] <author> N. Max. </author> <title> Optical models for direct volume rendering. </title> <journal> IEEE Transactions on Visualization & Computer Graphics, </journal> <volume> 1(2) </volume> <pages> 99-108, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: These can vary from a simple illumination model (threshold, followed by color lookup, and depth shading) to the most complex illumination (segmentation, followed by multivariate transfer function, followed by multi-scattering illumination model [Kru90], <ref> [Max95] </ref>). In the following discussion we will assume that the volume has been illuminated already and we are left with the task of rendering the 3D grids of RGBff values. Assume we need to render a volume of size N fi N fi N voxels.
Reference: [Mea82] <author> D. Meagher. </author> <title> Geometric modeling using octree encoding. </title> <journal> Computer Graphics & Image Processing, </journal> <volume> 19(2) </volume> <pages> 129-147, </pages> <month> June </month> <year> 1982. </year>
Reference-contexts: These methods are: recursive `divide and conquer' <ref> [Mea82] </ref>, pre-calculated tables [FGR85], incremental transformation [MYS92], and shearing-based transforms [Han90]. The first method [Mea82] exploits coherency in voxel space by representing the 3D volume by an octree. <p> These methods are: recursive `divide and conquer' <ref> [Mea82] </ref>, pre-calculated tables [FGR85], incremental transformation [MYS92], and shearing-based transforms [Han90]. The first method [Mea82] exploits coherency in voxel space by representing the 3D volume by an octree. A group of neighboring voxels having the same value (or similar, up to a threshold value) may, under some restrictions, be grouped into a uniform cubic subvolume.
Reference: [MPS92] <author> C. Montani, R. Perego, and R. Scopingo. </author> <title> Parallel volume visualization on a hypercube architecture. </title> <booktitle> In Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 9-16, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: To alleviate non-local access the volume is distributed in a round-robin fashion among the nodes. The efficient caching subsystem of the DASH multiprocessor is relied upon to fetch non-local data. Montani et. al.'s implementation of a ray-tracer on the Intel iPSC/2 used a purely static data distribution scheme <ref> [MPS92] </ref>. The scanlines are divided among clusters of processors in an interleaved fashion. The entire volume data is replicated on all clusters with each node of the cluster getting a slab of slices.
Reference: [MYS92] <author> R. Machiraju, R. Yagel, and L. Schwiebert. </author> <title> Parallel algorithms for volume rendering. </title> <type> Technical Report OSU-CISRC-10/92-TR29, </type> <institution> The Ohio State University, Department of Computer and Information Science, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: These methods are: recursive `divide and conquer' [Mea82], pre-calculated tables [FGR85], incremental transformation <ref> [MYS92] </ref>, and shearing-based transforms [Han90]. The first method [Mea82] exploits coherency in voxel space by representing the 3D volume by an octree. A group of neighboring voxels having the same value (or similar, up to a threshold value) may, under some restrictions, be grouped into a uniform cubic subvolume. <p> To employ this approach, all volume elements, including the empty ones, have to be transformed. This approach is therefore more suitable to parallel architecture where it is desired to keep the computation pipeline busy <ref> [MYS92] </ref>.
Reference: [NL92] <author> J. Neih and M. Levoy. </author> <booktitle> Volume rendering on scalable shared memory architecture. In Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 17-24, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: Neih and Levoy's <ref> [NL92] </ref> contribution lies in the development of a hybrid data distribution scheme. The screen is divided into several regions which are again subdivided into tiles. Each node of the DASH multicomputer is assigned a portion of the screen.
Reference: [RGC87] <author> R. A. Reynolds, D. Gordon, and L. S. Chen. </author> <title> A dynamic screen technique for shaded graphic display of slice-represented objects. Computer Vision, </title> <journal> Graphics & Image Processing, </journal> <volume> 38(3) </volume> <pages> 275-298, </pages> <address> June 1987. </address> <publisher> 16/2/1998 23:55|PAGE PROOFS for John Wiley & Sons Ltd|book REFERENCES 23 </publisher>
Reference-contexts: The front-to-back (FTB) algorithm is essentially the same as BTF only that now the voxels are traversed in increasing distance order <ref> [RGC87] </ref>. It should be observed that while in the basic Z-buffer method it is impossible to support the rendition semitransparent materials since voxels are mapped to the screen in arbitrary order. Compositing is based on a computation that simulates the passage of light through several materials. <p> The splats themselves are approximated by polygons which can efficiently be rendered by graphics hardware (see Section 4). It seems that in forward methods voxels need to be transformed and tested against the screen so as to avoid compositing at already opaque pixels. Reynolds et al <ref> [RGC87] </ref> developed the dynamic screen which decodes the screen lines as runlength of non 16/2/1998 23:55|PAGE PROOFS for John Wiley & Sons Ltd|book 8 Yagel opaque pixels. The transformation guarantees that a row of voxels always transforms into a row of pixels. <p> One early example of this trend is the shear-warp algorithm that combines the work on shearing-based rendering [Han90], run-length encoding <ref> [RGC87] </ref>, min-max pyramids [DH92], and multi-dimensional summed area tables. * Parallel implementations on state-of-the art distributed shared-memory machines, taking advantage of hardware caches and interleaved dedicated communication processors.
Reference: [Sab88] <author> P. Sabella. </author> <title> A rendering algorithm for visualizing 3D scalar fields. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 51-58, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: Alternatively, the volume is sampled at the intersection points of the ray and the voxels' faces, its value is interpolated, and then composited [UK88]. A more precise algorithm uses higher order interpolation to estimate the appropriate value at evenly spaced sample points along the ray [KH84], [Lev88], <ref> [Sab88] </ref>. Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reflection, shadows, and refraction. <p> They switch to high cost rays when they encounter a voxel with vicinity flag turned on. regions that can be represented by nodes in a hierarchical data structure <ref> [Sab88] </ref>. An adjusted ray traversal algorithm skips the (uniform) empty space by maneuvering through the hierarchical data structure [Lev90a]. It was also observed that traversing the hierarchical data structure is inefficient compared to the traversal of regular grids. A combination of the advantages of both representations is the uniform buffer.
Reference: [SCK + 93] <author> L. Sobierajski, D. Cohen, A. E. Kaufman, R. Yagel, and D. Acker. </author> <title> A fast display method for volumetric data. </title> <journal> The Visual Computer, </journal> <volume> 10(2) </volume> <pages> 116-124, </pages> <year> 1993. </year>
Reference-contexts: In addition, this approach replaces the 3D transformation by five 1D transformations which require only one floating-point addition each. The splatting algorithm requires extensive filtering and is therefore very time consuming. We have described <ref> [SCK + 93] </ref> a simplified approximation to the splatting method for interactive volume viewing in which only voxels comprising the object's surface are maintained.
Reference: [SS91] <author> P. Schroeder and J. B. Salem. </author> <title> Fast rotation of volume data on data parallel architecture. </title> <booktitle> In Proceedings of Visualization'91, </booktitle> <pages> pages 50-57, </pages> <address> San Diego, CA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: One of the main difficulties in the naive approach described above is the proper signal reconstruction and resampling required when one transforms a discrete set of samples. One solution is based on transforming each slice from voxel-space to pixel-space using 3D affine transformation (shearing) [Han90], [LL94], <ref> [SS91] </ref> followed by projection onto the screen in a FTB fashion, and blending with the projection formed by previous slices [DCH88]. Westover [Wes90] has introduced another reconstruction technique for forward viewing methods the splatting algorithm. <p> In [VFR92] the implementation was conducted on a Maspar MP-1. Beams of voxels are provided to a toroidally connected processors. This implementation relies on the efficient interconnection network of the MP-1 for optimal communications performance. In the other implementation <ref> [SS91] </ref> no efforts were made to perform any explicit distribution or virtualization on the CM-2. Indirect addressing was employed and data exchange was avoided until the composition phase of the algorithm.
Reference: [SS92] <author> P. Schroeder and G. Stoll. </author> <title> Data parallel volume rendering as line drawing. </title> <booktitle> In Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 25-31, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The third phase of the algorithm transforms the projected image from the base-plane to the screen-plane. The regularity and simplicity of this efficient algorithm make it very attractive for hardware implementation [Yag91] and for massively parallel computers such as the CM-2 <ref> [SS92] </ref>. Frame coherency When an animation sequence is generated, in many cases, there is not much difference between successive images. Therefore, much of the work invested to produce one image may be used to expedite the generation of the next image. <p> By converting the three-dimensional view matrix into a series of one-dimensional shears and scales along the orthogonal axis, both Schroeder and Salem <ref> [SS92] </ref> and Vezina et. al., [VFR92] implemented feed-forward rendering on SIMD processors. A one-dimensional shear leads to regular communication along the shear axis and hence the decomposition of the transformation into shears. In [VFR92] the implementation was conducted on a Maspar MP-1. <p> The master then subdivides the image region further and distributes the new sub-regions to idle cells. To support such a dynamic scheme the volume is replicated among clusters of neighboring cells. The template based viewing method [YK92] has been successfully implemented in [CU92], <ref> [SS92] </ref> on SIMD machines. Both implementations are very similar. Parallel rays are traced in a lock step fashion by all nodes of the SIMD node. Each node is mapped to a voxel in both implementations. Shading, interpolation and compositing is done by each processor along the ray.
Reference: [SSW86] <author> D. S. Schlusselberg, K. Smith, and D. J. Woodward. </author> <title> Three-dimensional display of medical image volumes. </title> <booktitle> In Proceedings of NCGA'86 Conference, III, </booktitle> <pages> pages 114-123, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: The simplest method for implementing resampling performs zero order interpolation to locate the nearest voxel while stepping along the discrete ray representation which is generated by a 3D line algorithm <ref> [SSW86] </ref>. Alternatively, the volume is sampled at the intersection points of the ray and the voxels' faces, its value is interpolated, and then composited [UK88]. A more precise algorithm uses higher order interpolation to estimate the appropriate value at evenly spaced sample points along the ray [KH84], [Lev88], [Sab88].
Reference: [TT84] <author> H. K. Tuy and L. T. Tuy. </author> <title> Direct 2-d display of 3-d objects. </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 4(10) </volume> <pages> 29-33, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: In contrast to the forward viewing approach, the backward viewing scheme (also called image space method) casts a ray from the eye, through each pixel on the screen, into the volume data, until it intersect an opaque object or accumulates an opaque value through compositing [Lev88], <ref> [TT84] </ref>, [UK88]. Backward viewing is much more powerful than forward viewing since it can be extended to support global illumination and volume deformation. The first is based on recursively following secondary rays and shadow feelers [YCK92], as in traditional ray tracing.
Reference: [UK88] <author> C. Upson and M. Keeler. V-BUFFER: </author> <title> Visible volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 22(4) </volume> <pages> 59-64, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: In contrast to the forward viewing approach, the backward viewing scheme (also called image space method) casts a ray from the eye, through each pixel on the screen, into the volume data, until it intersect an opaque object or accumulates an opaque value through compositing [Lev88], [TT84], <ref> [UK88] </ref>. Backward viewing is much more powerful than forward viewing since it can be extended to support global illumination and volume deformation. The first is based on recursively following secondary rays and shadow feelers [YCK92], as in traditional ray tracing. <p> Alternatively, the volume is sampled at the intersection points of the ray and the voxels' faces, its value is interpolated, and then composited <ref> [UK88] </ref>. A more precise algorithm uses higher order interpolation to estimate the appropriate value at evenly spaced sample points along the ray [KH84], [Lev88], [Sab88]. Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reflection, shadows, and refraction.
Reference: [VFR92] <author> G. Vezina, P. Fletcher, and P. K. Robertson. </author> <title> Volume rendering on the MasPar MP-1. </title> <booktitle> In Proceedings of 1992 Workshop on Volume Visualization, </booktitle> <pages> pages 3-8, </pages> <address> Boston, MA, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: By converting the three-dimensional view matrix into a series of one-dimensional shears and scales along the orthogonal axis, both Schroeder and Salem [SS92] and Vezina et. al., <ref> [VFR92] </ref> implemented feed-forward rendering on SIMD processors. A one-dimensional shear leads to regular communication along the shear axis and hence the decomposition of the transformation into shears. In [VFR92] the implementation was conducted on a Maspar MP-1. Beams of voxels are provided to a toroidally connected processors. <p> matrix into a series of one-dimensional shears and scales along the orthogonal axis, both Schroeder and Salem [SS92] and Vezina et. al., <ref> [VFR92] </ref> implemented feed-forward rendering on SIMD processors. A one-dimensional shear leads to regular communication along the shear axis and hence the decomposition of the transformation into shears. In [VFR92] the implementation was conducted on a Maspar MP-1. Beams of voxels are provided to a toroidally connected processors. This implementation relies on the efficient interconnection network of the MP-1 for optimal communications performance.
Reference: [vWHVP91] <author> T. van Walsum, A. J. S. Hin, J. Versloot, and F. H. Post. </author> <title> Efficient hybrid rendering of volume data and polygons. </title> <booktitle> In Second Eurographics Workshop on Visualization in Scientific Computing, </booktitle> <address> Delft, Netherlands, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Object-space coherency The extension of the pixel-space coherency to 3D states that there is coherency between voxels in object space. Therefore, it is observed that it should be possible to avoid sampling in 3D regions having uniform or similar values. van Walsum et. al., <ref> [vWHVP91] </ref> have exploited voxel-space coherency. In his method 16/2/1998 23:55|PAGE PROOFS for John Wiley & Sons Ltd|book Volume Rendering 9 the ray starts sampling the volume in low frequency (i.e., large steps between sample points).
Reference: [Wes90] <author> L. Westover. </author> <title> Footprint evaluation for volume rendering. </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 367-376, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: One solution is based on transforming each slice from voxel-space to pixel-space using 3D affine transformation (shearing) [Han90], [LL94], [SS91] followed by projection onto the screen in a FTB fashion, and blending with the projection formed by previous slices [DCH88]. Westover <ref> [Wes90] </ref> has introduced another reconstruction technique for forward viewing methods the splatting algorithm. Each voxel, after being transformed into screen space is blurred, based on a 2D lookup table (footprint) that spreads the voxel's energy across multiple pixels. These are then composited with the image array. <p> Splatting is another reconstruction technique which has gained attention in the parallel volume rendering community. The earliest splatting implementation was conducted on a network of SUNs by Westover <ref> [Wes90] </ref>. Voxels are enumerated in a front-to-back or back-to-front order and a subset of these is sent to N 2 processes which are 16/2/1998 23:55|PAGE PROOFS for John Wiley & Sons Ltd|book Volume Rendering 13 executed on a network of Suns.
Reference: [WS93] <author> C. M. Wittenbrink and A. K. Somani. </author> <title> 2D and 3D optimal image warping. </title> <booktitle> In Proceedings of Seventh International Parallel Processing Symposium, </booktitle> <pages> pages 197-208, </pages> <address> Newport Beach, CA, </address> <month> April </month> <year> 1993. </year>
Reference-contexts: Only three reported implementations [ABSS94], [YM95], <ref> [WS93] </ref> and one recent work [LY96b] are known. Bajaj et. al. [ABSS94] consider both image space and object space partitioning methods for load balancing. The volume rendering calculation programs were tested on a high speed network of Sun workstations. Wit-tenbrink and Somani's [WS93] method is applicable to affine transformations. <p> Only three reported implementations [ABSS94], [YM95], <ref> [WS93] </ref> and one recent work [LY96b] are known. Bajaj et. al. [ABSS94] consider both image space and object space partitioning methods for load balancing. The volume rendering calculation programs were tested on a high speed network of Sun workstations. Wit-tenbrink and Somani's [WS93] method is applicable to affine transformations. They decompose the transformation into a series of shears used to determine the address of a voxel in the transformed space. This address is used for interpolating in object space and obtaining the sample value.
Reference: [Yag91] <author> R. Yagel. </author> <title> Efficient methods for volume graphics. </title> <type> PhD thesis, </type> <institution> SUNY at Stony Brook, Department of Computer Science, </institution> <month> December </month> <year> 1991. </year> <title> [Yag92] . High quality template-based volume viewing. </title> <type> Technical Report OSU-CISRC-10/92-TR28, </type> <institution> The Ohio State University, Department of Computer and Information Science, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: The result of the second phase of the algorithm is a projection of the volume on the base-plane. The third phase of the algorithm transforms the projected image from the base-plane to the screen-plane. The regularity and simplicity of this efficient algorithm make it very attractive for hardware implementation <ref> [Yag91] </ref> and for massively parallel computers such as the CM-2 [SS92]. Frame coherency When an animation sequence is generated, in many cases, there is not much difference between successive images.
Reference: [YCK92] <author> R. Yagel, D. Cohen, and A. E. Kaufman. </author> <title> Discrete ray tracing. </title> <journal> IEEE Computer Graphics & Applications, </journal> <volume> 12(5) </volume> <pages> 19-28, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Backward viewing is much more powerful than forward viewing since it can be extended to support global illumination and volume deformation. The first is based on recursively following secondary rays and shadow feelers <ref> [YCK92] </ref>, as in traditional ray tracing. Volume deformation is based on bending the path the rays take, according to the influence of `gravity fields' called deflectors [KY95]. <p> Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reflection, shadows, and refraction. As an alternative we have developed the 3D raster ray tracer (RRT) <ref> [YCK92] </ref> that recursively considers both primary and secondary rays and thus can create `photorealistic' images. In conventional ray tracing algorithms analytical rays, searching for the closest intersection, are intersected with the object list. <p> Alternatively, ray casting can be implemented to support also perspective viewing. Since ray casting follows only primary rays, it does not directly support the simulation of light phenomena such as reflection, shadows, and refraction. As an alternative we have developed the 3D raster ray tracer (RRT) <ref> [YCK92] </ref> that recursively considers both primary and secondary rays and thus can create `photorealistic' images. <p> A ray that does not hit any object is not traversed at all. It is obvious that the empty space does not have to be sampled it has only to be crossed as fast as possible. Therefore, we have proposed <ref> [YCK92] </ref>, [Yag92] to utilize one fast and crude line algorithm in the empty space (e.g., 3D integer-based 26-connected line algorithm) and another, slower but more accurate (e.g., 6-connected integer or 3D DDA floating point line algorithm), in the vicinity and interior of objects (see Figure 2.2c).
Reference: [YESK95] <author> R. Yagel, D. S. Ebert, J. Scott, and Y. Kurzion. </author> <title> Grouping volume renderers for enhanced visualization in computational fluid dynamics. </title> <journal> IEEE Transactions on Visualization & Computer Graphics, </journal> <volume> 1(2) </volume> <pages> 117-132, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: When the volume remains stationary and unchanged for some short period, the rendering system renders the rest of the points to increase image quality. These ideas was further explored to allow non-binary surfaces by extracting all voxels that contribute to the final image <ref> [YESK95] </ref>. Another efficient implementation of the splatting algorithm, called hierarchical splatting [LH91] uses a pyramid data structure to hold a multi-resolution representation of the volume. For a volume of N 3 resolution, the pyramid data structure consists of a sequence of log N volumes. <p> However, these polygon rendering engines seem inherently unsuitable to the task. Recently, some new methods have tapped to this rendering power by either utilizing texture mapping capabilities for rendering splats [Cra95], [LH91], or by exploiting solid texturing capabilities to implement a slicing-based volume rendering [CCF94]. The Volume Splatter <ref> [YESK95] </ref> relies on the notion of fuzzy voxel set which consists of a subset of the volume's voxels. For each voxel in the original volume, we evaluate a transfer function that maps the gradient and the density of the given voxel to an `importance' number.
Reference: [YK92] <author> R. Yagel and A. E. Kaufman. </author> <title> Template-based volume viewing. </title> <journal> Computer Graphics Forum, </journal> <volume> 11(3) </volume> <pages> 153-157, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: As shown in Therefore, part of the computation needed for trilinear interpolation cab be performed in a preprocessing stage and stored in the template for a later use at rendering time. The template-based method <ref> [YK92] </ref>, [Yag92] utilizes the inter-ray coherency. Observing that, in parallel viewing, all rays have the same form it was realized that there is no need to reactivate the discrete line algorithm for each ray. <p> The master then subdivides the image region further and distributes the new sub-regions to idle cells. To support such a dynamic scheme the volume is replicated among clusters of neighboring cells. The template based viewing method <ref> [YK92] </ref> has been successfully implemented in [CU92], [SS92] on SIMD machines. Both implementations are very similar. Parallel rays are traced in a lock step fashion by all nodes of the SIMD node. Each node is mapped to a voxel in both implementations.
Reference: [YM95] <author> R. Yagel and R. Machiraju. </author> <title> Data parallel volume rendering algorithms. </title> <journal> The Visual Computer, </journal> <volume> 11(6) </volume> <pages> 319-338, </pages> <year> 1995. </year>
Reference-contexts: These processes transform and splat the voxels onto image sheets which are then sent to N compositing processes. Machiraju and Yagel implement a similar splatting algorithm on a IBM Power Visualization System (PVS) <ref> [YM95] </ref>. In this method, shown in Figure 2.3, a computational scheme is utilized which allows very efficient transformations based on incremental vec-torized computation. Also, the volume is statically divided into an ordered set of slabs (of slices). <p> Only three reported implementations [ABSS94], <ref> [YM95] </ref>, [WS93] and one recent work [LY96b] are known. Bajaj et. al. [ABSS94] consider both image space and object space partitioning methods for load balancing. The volume rendering calculation programs were tested on a high speed network of Sun workstations. Wit-tenbrink and Somani's [WS93] method is applicable to affine transformations. <p> This address is used for interpolating in object space and obtaining the sample value. The advantage of this address computation scheme is that communication required for interpolation is nearest neighbor and regular. In the final stages another communication step is required for actually rearranging the transformed volume. In <ref> [YM95] </ref>, a hybrid method was implemented on the IBM Power Visualization System (PVS). The volume data is subdivided into sub-cubes and assigned to different processors. The transformed extents of these sub-cubes are determined in the image space.
Reference: [YNF + 92] <author> T. Yoo, S. Neumann, U. Fuchs, H. Pizer, S. M. Cullip, J. T. Rhoades, and R. Whitaker. </author> <title> Direct visualization of volume data. </title> <journal> Computer Graphics & Applications, </journal> <volume> 12(4) </volume> <pages> 63-71, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: The process is also pipelined and vectorized (in the transformation phase). The images resulting from each processor are composited to yield the final image. In Neumann's implementation on the Pixel Planes 5 architecture <ref> [YNF + 92] </ref> graphics processors transform and shade the voxels, while the rendering processors implement splatting and receive the requisite instruction stream from the graphics processors. Each rendering processor is assigned a subsection of the screen. Only voxels which map to that screen area are sent to this renderer.
Reference: [YS93] <author> R. Yagel and Z. Shi. </author> <title> Accelerating volume animation by space-leaping. </title> <booktitle> In Proceedings of Visualization'93, </booktitle> <pages> pages 62-69, </pages> <address> San Jose, CA, </address> <month> October </month> <year> 1993. </year>
Reference-contexts: Frame coherency When an animation sequence is generated, in many cases, there is not much difference between successive images. Therefore, much of the work invested to produce one image may be used to expedite the generation of the next image. Yagel and Shi <ref> [YS93] </ref> have reported on a method for speeding up the process of volume rendering a sequence of images. It is based on exploiting coherency between consecutive images to shorten the path rays take through the volume.
Reference: [YSW + 96] <author> R. Yagel, D. Stredney, G. J. Wiet, P. Schmalbrock, L. Rosenberg, D. Sessanna, Y. Kurzion, and S. King. </author> <title> Multisensory platform for surgical simulation. </title> <booktitle> In IEEE Virtual Reality Annual International Symposium 1996 - VRAIS'96, </booktitle> <pages> pages 72-78, </pages> <address> Santa Clara, CA, </address> <month> March </month> <year> 1996. </year>
Reference-contexts: For a complete comparison see [KCY93]. Although compute power required for volume rendering is immense, so are the benefits from some potential applications which rely on such capability. One such application is the simulation of surgery on a virtual patient <ref> [YSW + 96] </ref>. The patient is first `digitized' by a medical scanner such as CT, MRI, or Ultrasound. Surgery can then be planned, rehearsed, and redesigned while operating on the digital model in a non-threatening virtual environment. <p> Some examples of this trend are [CCF94], [Cra95], [LH91], <ref> [YSW + 96] </ref>. While fastest known parallel implementations achieve close to real-time ( 10 frames per second) on expensive high-end parallel machines [Lac95], the same, or even slightly better performance is achieved on mid-range texture hardware [CCF94].
Reference: [ZKV92] <author> K. Zuiderveld, A. H. J. Koning, and M. A. Viergever. </author> <title> Acceleration of ray casting using 3D distance transforms. </title> <booktitle> In Proceedings of Visualization in Biomedical Computing, </booktitle> <pages> pages 324-335, </pages> <address> October 1992. </address> <publisher> 16/2/1998 23:55|PAGE PROOFS for John Wiley & Sons Ltd|book </publisher>
Reference-contexts: This flags the need to switch to a more accurate ray traversal algorithm. Encountering later an empty voxel (i.e., unoccupied and not carrying the vicinity flag) can signal a switch back to the rapid traversal of empty space. The proximity-clouds method [CS93], <ref> [ZKV92] </ref> is based on the extension of this idea even further. Instead of having a one-voxel-deep vicinity cloud this method computes, in a preprocessing stage, for each empty voxel, the distance to the closest occupied voxel.
References-found: 53

