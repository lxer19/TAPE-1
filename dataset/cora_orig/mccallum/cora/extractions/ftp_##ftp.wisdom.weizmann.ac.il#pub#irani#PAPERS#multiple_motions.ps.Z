URL: ftp://ftp.wisdom.weizmann.ac.il/pub/irani/PAPERS/multiple_motions.ps.Z
Refering-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/SegmFromMotion.html
Root-URL: http://www.cnl.salk.edu/~wiskott/Bibliographies/SegmFromMotion.html
Title: Computing Occluding and Transparent Motions  
Author: Michal Irani Benny Rousso Shmuel Peleg 
Keyword: Index Terms: motion analysis, transparency, multiple motions, temporal integration, segmentation.  
Note: This research was supported by the Israel Science Foundation. M. Irani and B. Rousso were partially supported by a fellowship from the Leibniz Center.  
Address: 91904 Jerusalem, ISRAEL  
Affiliation: Institute of Computer Science The Hebrew University of Jerusalem  
Abstract: Computing the motions of several moving objects in image sequences involves simultaneous motion analysis and segmentation. This task can become complicated when image motion changes significantly between frames, as with camera vibrations. Such vibrations make tracking in longer sequences harder, as temporal motion constancy can not be assumed. The problem becomes even more difficult in the case of transparent motions. A method is presented for detecting and tracking occluding and transparent moving objects, which uses temporal integration without assuming motion constancy. Each new frame in the sequence is compared to a dynamic internal representation image of the tracked object. The internal representation image is constructed by temporally integrating frames after registration based on the motion computation. The temporal integration maintains sharpness of the tracked object, while blurring objects having other motions. Comparing new frames to the internal representation image causes the motion analysis algorithm to continue tracking the same object in subsequent frames, and to improve the segmentation. 
Abstract-found: 1
Intro-found: 1
Reference: [Adi85] <author> G. Adiv. </author> <title> Determining three-dimensional motion and structure from optical flow generated by several moving objects. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 7(4) </volume> <pages> 384-401, </pages> <month> July </month> <year> 1985. </year>
Reference-contexts: 1 Introduction Motion analysis, such as optical flow [HS81], is often performed on the smallest possible regions, both in the temporal domain and in the spatial domain. Small regions, however, carry little motion information, and such motion computation is therefore inaccurate. Analysis of multiple moving objects based on optical flow <ref> [Adi85] </ref> suffers from this inaccuracy. Increasing the temporal region to more than two frames improves the accuracy of the computed optical flow. Methods for estimating local image velocities with large temporal regions have been introduced using a combined spatio-temporal analysis [FJ90, Hee88, SM90]. <p> Deriving Err (t) (p; q) with respect to the motion parameters and setting to zero yields six linear equations in the six unknowns: a, b, c, d, e, f [BBH + 91, BAHH92]. 3. Moving planar surface (a pseudo projective transformation): 8 parameters <ref> [Adi85, BAHH92] </ref>, p (x; y; t) = a + bx + cy + gx 2 + hxy, q (x; y; t) = d + ex + f y + gxy + hy 2 .
Reference: [BA87] <author> J.R. Bergen and E.H. Adelson. </author> <title> Hierarchical, computationally efficient motion estimation algorithm. </title> <journal> J. Opt. Soc. Am. A., </journal> <volume> 4:35, </volume> <year> 1987. </year>
Reference-contexts: setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Processing the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [BA87, BBH + 91, BBHP92] </ref>. The basic components of this framework are: * Construction of a Gaussian pyramid [Ros84], where the images are represented in multiple resolutions. * Starting at the lowest resolution level: 1.
Reference: [BAHH92] <author> J.R. Bergen, P. Anandan, K.J. Hanna, and R. Hingorani. </author> <title> Hierarchical model-based motion estimation. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages 237-252, </pages> <address> Santa Margarita Ligure, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: In order to minimize Err (t) (p; q), its derivatives with respect to a and d are set to zero. This yields two linear equations in the two unknowns, a and d. Those are the two well-known optical flow equations <ref> [LK81, BAHH92] </ref>, where every small window is assumed to have a single translation. In this translation model, the entire object is assumed to have a single translation. 2. <p> Deriving Err (t) (p; q) with respect to the motion parameters and setting to zero yields six linear equations in the six unknowns: a, b, c, d, e, f <ref> [BBH + 91, BAHH92] </ref>. 3. Moving planar surface (a pseudo projective transformation): 8 parameters [Adi85, BAHH92], p (x; y; t) = a + bx + cy + gx 2 + hxy, q (x; y; t) = d + ex + f y + gxy + hy 2 . <p> Deriving Err (t) (p; q) with respect to the motion parameters and setting to zero yields six linear equations in the six unknowns: a, b, c, d, e, f [BBH + 91, BAHH92]. 3. Moving planar surface (a pseudo projective transformation): 8 parameters <ref> [Adi85, BAHH92] </ref>, p (x; y; t) = a + bx + cy + gx 2 + hxy, q (x; y; t) = d + ex + f y + gxy + hy 2 . <p> The reliability of the motion measure at each pixel is determined by the numerical stability of the two well-known optical flow equations <ref> [LK81, BAHH92] </ref>: " P 2 ) ( I x I y ) P P 2 ) x # " P ( I y I t ) (6) where for each pixel (x; y) the sum is taken over the neighborhood N (x; y).
Reference: [BBH + 91] <author> J.R. Bergen, P.J. Burt, K. Hanna, R. Hingorani, P. Jeanne, and S. Peleg. </author> <title> Dynamic multiple-motion computation. In Y.A. </title> <editor> Feldman and A. Bruckstein, editors, </editor> <booktitle> Artificial Intelligence and Computer Vision: Proceedings of the Israeli Conference, </booktitle> <pages> pages 147-156. </pages> <publisher> Elsevier, </publisher> <year> 1991. </year>
Reference-contexts: The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion. Existing approaches for the analysis of multiple motions can be classified to methods that compute the multiple motions without using segmentation <ref> [BBH + 91, BBHP92, BHK91, DP91, Shi92, SM91] </ref>, and to those that separate the motions by segmentation [MB92, PR90]. <p> Analysis of multiple motions without segmentation has been suggested using the dominant motion approach <ref> [BBH + 91, BHK91] </ref>, which finds the parameters of a single translation in a scene with multiple motions without performing segmentation. The dominant motion approach has also been used to compute two motions from three frames [BBHP92], with the assumption that the motions remain constant in the 3-frame sequence. <p> Deriving Err (t) (p; q) with respect to the motion parameters and setting to zero yields six linear equations in the six unknowns: a, b, c, d, e, f <ref> [BBH + 91, BAHH92] </ref>. 3. Moving planar surface (a pseudo projective transformation): 8 parameters [Adi85, BAHH92], p (x; y; t) = a + bx + cy + gx 2 + hxy, q (x; y; t) = d + ex + f y + gxy + hy 2 . <p> setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Processing the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [BA87, BBH + 91, BBHP92] </ref>. The basic components of this framework are: * Construction of a Gaussian pyramid [Ros84], where the images are represented in multiple resolutions. * Starting at the lowest resolution level: 1.
Reference: [BBHP92] <author> J.R. Bergen, P.J. Burt, R. Hingorani, and S. Peleg. </author> <title> A three-frame algorithm for estimating two-component image motion. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 14 </volume> <pages> 886-895, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion. Existing approaches for the analysis of multiple motions can be classified to methods that compute the multiple motions without using segmentation <ref> [BBH + 91, BBHP92, BHK91, DP91, Shi92, SM91] </ref>, and to those that separate the motions by segmentation [MB92, PR90]. <p> The dominant motion approach has also been used to compute two motions from three frames <ref> [BBHP92] </ref>, with the assumption that the motions remain constant in the 3-frame sequence. The motions are computed between registered frame differences, rather than between the original frames. <p> setting to zero, yields eight linear equations in the eight unknowns: a, b, c, d, e, f , g, h. 2.2 Processing the First Object When the region of support of a single object in the image is known, its motion parameters can be computed using a multiresolution iterative framework <ref> [BA87, BBH + 91, BBHP92] </ref>. The basic components of this framework are: * Construction of a Gaussian pyramid [Ros84], where the images are represented in multiple resolutions. * Starting at the lowest resolution level: 1. <p> For example: moving shadows, spotlights, reflections in water, transparent surfaces moving past one another, etc. In this section, we show how the tracking algorithm presented in Section 3.1 can be used to detect, track and reconstruct objects in the case of transparent motions. Previous analysis of transparency <ref> [BBHP92, DP91, Shi92, SM90, SM91] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [BBHP92, Shi92, SM91] elegantly avoid the segmentation problem. <p> Previous analysis of transparency [BBHP92, DP91, Shi92, SM90, SM91] assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods <ref> [BBHP92, Shi92, SM91] </ref> elegantly avoid the segmentation problem. They require, however, high order derivatives (the order increases with the number of objects), which increases the sensitivity to noisy data. <p> Therefore, we use the values of the absolute difference image as an initial mask for the search of the next dominant object in the temporal integration algorithm from Section 3.1. The tracking algorithm is applied once again to the original image sequence, and not to frame differences as in <ref> [BBHP92] </ref>. Now that the algorithm tracks the second dominant object, the new internal representation image Av 2 (t) restores the second dominant transparent object, and blurs out the other transparent objects, including the first dominant object.
Reference: [BHK91] <author> P.J. Burt, R. Hingorani, and R.J. Kolczynski. </author> <title> Mechanisms for isolating component patterns in the sequential analysis of multiple motion. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 187-193, </pages> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion. Existing approaches for the analysis of multiple motions can be classified to methods that compute the multiple motions without using segmentation <ref> [BBH + 91, BBHP92, BHK91, DP91, Shi92, SM91] </ref>, and to those that separate the motions by segmentation [MB92, PR90]. <p> Analysis of multiple motions without segmentation has been suggested using the dominant motion approach <ref> [BBH + 91, BHK91] </ref>, which finds the parameters of a single translation in a scene with multiple motions without performing segmentation. The dominant motion approach has also been used to compute two motions from three frames [BBHP92], with the assumption that the motions remain constant in the 3-frame sequence. <p> The motion parameters are interpolated to the next resolution level, and are refined by using the higher resolution images. Motion estimation is more difficult when the region of support of an object in the image is not known, which is the common case. It was shown in <ref> [BHK91] </ref> that the motion parameters of a single translating object in the image plane can be recovered accurately by applying the above motion computation framework to the entire region of analysis, using a translation motion model. <p> This can be done even in the presence of other differently moving objects in the region of analysis, and with no prior knowledge of their regions of support. A thorough analysis of hierarchical translation estimation is found in <ref> [BHK91] </ref>. This, however, is rarely true for higher order 2D parametric motion models (e.g. affine, projective, etc), which are much more sensitive to the presence of other moving objects in the region of analysis.
Reference: [DHA88] <author> G.W. Donohoe, D.R. Hush, and N. Ahmed. </author> <title> Change detection for target detection and classification in video sequences. </title> <booktitle> In International Conference on Acoustics Speech and Signal Processing, </booktitle> <pages> pages 1084-1087, </pages> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Each new frame in the sequence is compared to the internal representation image of the tracked object rather than to the previous frame. Similar temporal integration approaches, but which were applied only to stationary background, are described in <ref> [DHA88, KB89] </ref>. 3.1 Tracking the Dominant Object Let fI (t)g denote the image sequence, and let M (t) denote the segmentation mask of the tracked object computed for frame I (t), using the segmentation method described in Section 2.4. Initially, M (0) is the entire region of analysis.
Reference: [DP91] <author> T. Darrell and A. Pentland. </author> <title> Robust estimation of a multi-layered motion representation. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 173-178, </pages> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion. Existing approaches for the analysis of multiple motions can be classified to methods that compute the multiple motions without using segmentation <ref> [BBH + 91, BBHP92, BHK91, DP91, Shi92, SM91] </ref>, and to those that separate the motions by segmentation [MB92, PR90]. <p> It provide an elegant framework to construct motion transparency constraints from conventional single motion constraints, but requires the use of high order derivatives. In another approach, a robust estimation technique for detecting multiple translating objects <ref> [DP91] </ref> has been introduced. It assumes motion constancy over several successive frames in the analyzed sequence. Analysis of multiple motions using segmentation has been suggested [PR90] for the simple case of two planar moving regions of constant depth. <p> For example: moving shadows, spotlights, reflections in water, transparent surfaces moving past one another, etc. In this section, we show how the tracking algorithm presented in Section 3.1 can be used to detect, track and reconstruct objects in the case of transparent motions. Previous analysis of transparency <ref> [BBHP92, DP91, Shi92, SM90, SM91] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [BBHP92, Shi92, SM91] elegantly avoid the segmentation problem.
Reference: [FB92] <author> E. Francois and P. Bouthemy. </author> <title> Multiframe-based identification of mobile components of a scene with a moving camera. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 282-287, </pages> <address> Champaign, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: A more general approach with good experimental results has been presented in a region-based tracking method [MB92]. Kalman filters are used to predict and update the polygonal shape approximation and the 2D motion parameters of the tracked regions. Motion based segmentation <ref> [FB92] </ref>, based on a statistical regularization approach using MRF models, is being used in that approach to initially separate the moving objects.
Reference: [FJ90] <author> D.J. Fleet and A.D. Jepson. </author> <title> Computation of component image velocity from local phase information. </title> <journal> International Journal of Computer Vision, </journal> <volume> 5(1) </volume> <pages> 77-104, </pages> <year> 1990. </year>
Reference-contexts: Analysis of multiple moving objects based on optical flow [Adi85] suffers from this inaccuracy. Increasing the temporal region to more than two frames improves the accuracy of the computed optical flow. Methods for estimating local image velocities with large temporal regions have been introduced using a combined spatio-temporal analysis <ref> [FJ90, Hee88, SM90] </ref>. These methods assume motion constancy in the temporal regions, i.e. motion should remain uniform in the analyzed sequence. The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion.
Reference: [Hee88] <author> D.J. Heeger. </author> <title> Optical flow using spatiotemporal filters. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1 </volume> <pages> 279-302, </pages> <year> 1988. </year>
Reference-contexts: Analysis of multiple moving objects based on optical flow [Adi85] suffers from this inaccuracy. Increasing the temporal region to more than two frames improves the accuracy of the computed optical flow. Methods for estimating local image velocities with large temporal regions have been introduced using a combined spatio-temporal analysis <ref> [FJ90, Hee88, SM90] </ref>. These methods assume motion constancy in the temporal regions, i.e. motion should remain uniform in the analyzed sequence. The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion.
Reference: [HNG84] <author> Y.Z. Hsu, H.-H. Nagel, and G.Rekers. </author> <title> New likelihood test methods for change detection in image sequences. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 26 </volume> <pages> 73-106, </pages> <year> 1984. </year>
Reference-contexts: The segmentation problem reduces therefore to identifying the stationary regions in the registered images. In this implementation, pixels are classified as moving or stationary using simple analysis based on local normalized differences. A more elaborate statistical scheme <ref> [HNG84] </ref> is also possible. A simple grey level difference between the registered images is not sufficient for the classification for two reasons: 6 1. Regions having uniform intensity may be interpreted locally both as moving and as station-ary.
Reference: [HS81] <author> B.K.P. Horn and B.G. Schunck. </author> <title> Determining optical flow. </title> <journal> Artificial Intelligence, </journal> <volume> 17 </volume> <pages> 185-203, </pages> <year> 1981. </year>
Reference-contexts: 1 Introduction Motion analysis, such as optical flow <ref> [HS81] </ref>, is often performed on the smallest possible regions, both in the temporal domain and in the spatial domain. Small regions, however, carry little motion information, and such motion computation is therefore inaccurate. Analysis of multiple moving objects based on optical flow [Adi85] suffers from this inaccuracy. <p> Equations (1) and (2) yield the well-known constraint <ref> [HS81] </ref>: pI x + qI y + I t = 0: (3) We look for a motion (p; q) which minimize the error function at Frame t in the region of analysis R: X (pI x + qI y + I t ) 2 : (4) We perform the error minimization
Reference: [IP91] <author> M. Irani and S. Peleg. </author> <title> Improving resolution by image registration. CVGIP: Graphical Models and Image Processing, </title> <booktitle> 53 </booktitle> <pages> 231-239, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: Other objects can then be tracked. Once good motion estimation and segmentation of a tracked object are obtained, it becomes possible to enhance the object images, like reconstruction of occluded regions and improvement of image resolution <ref> [IP91, IP92] </ref>. 17
Reference: [IP92] <author> M. Irani and S. Peleg. </author> <title> Image sequence enhancement using multiple motions analysis. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <address> Champaign, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: Other objects can then be tracked. Once good motion estimation and segmentation of a tracked object are obtained, it becomes possible to enhance the object images, like reconstruction of occluded regions and improvement of image resolution <ref> [IP91, IP92] </ref>. 17
Reference: [KB89] <author> K.P. Karmann and A.V. Brandt. </author> <title> Moving object recognition using an adaptive background memory. </title> <booktitle> In Proc. 3rd International Workshop on Time-Varying Image Processing and Moving Object Recognition, </booktitle> <pages> pages 289-296, </pages> <address> Florence, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: Each new frame in the sequence is compared to the internal representation image of the tracked object rather than to the previous frame. Similar temporal integration approaches, but which were applied only to stationary background, are described in <ref> [DHA88, KB89] </ref>. 3.1 Tracking the Dominant Object Let fI (t)g denote the image sequence, and let M (t) denote the segmentation mask of the tracked object computed for frame I (t), using the segmentation method described in Section 2.4. Initially, M (0) is the entire region of analysis.
Reference: [LK81] <author> B.D. Lucas and T. Kanade. </author> <title> An iterative image registration technique with an application to stereo vision. </title> <booktitle> In Image Understanding Workshop, </booktitle> <pages> pages 121-130, </pages> <year> 1981. </year>
Reference-contexts: In order to minimize Err (t) (p; q), its derivatives with respect to a and d are set to zero. This yields two linear equations in the two unknowns, a and d. Those are the two well-known optical flow equations <ref> [LK81, BAHH92] </ref>, where every small window is assumed to have a single translation. In this translation model, the entire object is assumed to have a single translation. 2. <p> The reliability of the motion measure at each pixel is determined by the numerical stability of the two well-known optical flow equations <ref> [LK81, BAHH92] </ref>: " P 2 ) ( I x I y ) P P 2 ) x # " P ( I y I t ) (6) where for each pixel (x; y) the sum is taken over the neighborhood N (x; y).
Reference: [MB92] <author> F. Meyer and P. Bouthemy. </author> <title> Region-based tracking in image sequences. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages 476-484, </pages> <address> Santa Margarita Ligure, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Existing approaches for the analysis of multiple motions can be classified to methods that compute the multiple motions without using segmentation [BBH + 91, BBHP92, BHK91, DP91, Shi92, SM91], and to those that separate the motions by segmentation <ref> [MB92, PR90] </ref>. Analysis of multiple motions without segmentation has been suggested using the dominant motion approach [BBH + 91, BHK91], which finds the parameters of a single translation in a scene with multiple motions without performing segmentation. <p> Analysis of multiple motions using segmentation has been suggested [PR90] for the simple case of two planar moving regions of constant depth. A more general approach with good experimental results has been presented in a region-based tracking method <ref> [MB92] </ref>. Kalman filters are used to predict and update the polygonal shape approximation and the 2D motion parameters of the tracked regions. Motion based segmentation [FB92], based on a statistical regularization approach using MRF models, is being used in that approach to initially separate the moving objects.
Reference: [PR90] <author> S. Peleg and H. </author> <title> Rom. Motion based segmentation. </title> <booktitle> In International Conference on Pattern Recognition, </booktitle> <volume> volume 1, </volume> <pages> pages 109-113, </pages> <address> Atlantic City, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Existing approaches for the analysis of multiple motions can be classified to methods that compute the multiple motions without using segmentation [BBH + 91, BBHP92, BHK91, DP91, Shi92, SM91], and to those that separate the motions by segmentation <ref> [MB92, PR90] </ref>. Analysis of multiple motions without segmentation has been suggested using the dominant motion approach [BBH + 91, BHK91], which finds the parameters of a single translation in a scene with multiple motions without performing segmentation. <p> In another approach, a robust estimation technique for detecting multiple translating objects [DP91] has been introduced. It assumes motion constancy over several successive frames in the analyzed sequence. Analysis of multiple motions using segmentation has been suggested <ref> [PR90] </ref> for the simple case of two planar moving regions of constant depth. A more general approach with good experimental results has been presented in a region-based tracking method [MB92].
Reference: [Ros84] <editor> A. Rosenfeld, editor. </editor> <title> Multiresolution Image Processing and Analysis. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year>
Reference-contexts: The basic components of this framework are: * Construction of a Gaussian pyramid <ref> [Ros84] </ref>, where the images are represented in multiple resolutions. * Starting at the lowest resolution level: 1. Motion parameters are estimated by solving the set of linear equations to minimize Err (t) (p; q) (Equation (4)) according to the appropriate motion model (Section 2.1). <p> A simple grey level difference between the registered images is not sufficient for the classification for two reasons: 6 1. Regions having uniform intensity may be interpreted locally both as moving and as station-ary. In order to classify correctly regions having uniform intensity, a multi-resolution scheme <ref> [Ros84] </ref> is used, as in low resolution pyramid levels the uniform regions are small. Classification is first performed on the lowest resolution level and is then interpolated to be used as an initial classification for the next resolution level. Higher resolution information is used to update the initial classification. 2.
Reference: [Shi92] <author> M. Shizawa. </author> <title> On visual ambiguities due to transparency in motion and stereo. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <pages> pages 411-419, </pages> <address> Santa Margarita Ligure, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion. Existing approaches for the analysis of multiple motions can be classified to methods that compute the multiple motions without using segmentation <ref> [BBH + 91, BBHP92, BHK91, DP91, Shi92, SM91] </ref>, and to those that separate the motions by segmentation [MB92, PR90]. <p> The use of frame differences makes it possible to avoid the segmentation problem, but introduces temporal derivatives which increase the order of the derivatives used in this method. Another method for computing multiple motions without segmentation uses the principle of superposition <ref> [Shi92, SM91] </ref>. It provide an elegant framework to construct motion transparency constraints from conventional single motion constraints, but requires the use of high order derivatives. In another approach, a robust estimation technique for detecting multiple translating objects [DP91] has been introduced. <p> For example: moving shadows, spotlights, reflections in water, transparent surfaces moving past one another, etc. In this section, we show how the tracking algorithm presented in Section 3.1 can be used to detect, track and reconstruct objects in the case of transparent motions. Previous analysis of transparency <ref> [BBHP92, DP91, Shi92, SM90, SM91] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [BBHP92, Shi92, SM91] elegantly avoid the segmentation problem. <p> Previous analysis of transparency [BBHP92, DP91, Shi92, SM90, SM91] assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods <ref> [BBHP92, Shi92, SM91] </ref> elegantly avoid the segmentation problem. They require, however, high order derivatives (the order increases with the number of objects), which increases the sensitivity to noisy data.
Reference: [SM90] <author> M. Shizawa and K. Mase. </author> <title> Simultaneous multiple optical flow estimation. </title> <booktitle> In International Conference on Pattern Recognition, </booktitle> <pages> pages 274-278, </pages> <address> Atlantic City, New Jersey, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Analysis of multiple moving objects based on optical flow [Adi85] suffers from this inaccuracy. Increasing the temporal region to more than two frames improves the accuracy of the computed optical flow. Methods for estimating local image velocities with large temporal regions have been introduced using a combined spatio-temporal analysis <ref> [FJ90, Hee88, SM90] </ref>. These methods assume motion constancy in the temporal regions, i.e. motion should remain uniform in the analyzed sequence. The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion. <p> For example: moving shadows, spotlights, reflections in water, transparent surfaces moving past one another, etc. In this section, we show how the tracking algorithm presented in Section 3.1 can be used to detect, track and reconstruct objects in the case of transparent motions. Previous analysis of transparency <ref> [BBHP92, DP91, Shi92, SM90, SM91] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [BBHP92, Shi92, SM91] elegantly avoid the segmentation problem.
Reference: [SM91] <author> M. Shizawa and K. Mase. </author> <title> Principle of superposition: A common computational framework for analysis of multiple motion. </title> <booktitle> In IEEE Workshop on Visual Motion, </booktitle> <pages> pages 164-172, </pages> <address> Princeton, New Jersey, </address> <month> October </month> <year> 1991. </year> <month> 19 </month>
Reference-contexts: The major difficulty in increasing the size of the spatial region of analysis is the possibility that larger regions will include more than a single motion. Existing approaches for the analysis of multiple motions can be classified to methods that compute the multiple motions without using segmentation <ref> [BBH + 91, BBHP92, BHK91, DP91, Shi92, SM91] </ref>, and to those that separate the motions by segmentation [MB92, PR90]. <p> The use of frame differences makes it possible to avoid the segmentation problem, but introduces temporal derivatives which increase the order of the derivatives used in this method. Another method for computing multiple motions without segmentation uses the principle of superposition <ref> [Shi92, SM91] </ref>. It provide an elegant framework to construct motion transparency constraints from conventional single motion constraints, but requires the use of high order derivatives. In another approach, a robust estimation technique for detecting multiple translating objects [DP91] has been introduced. <p> For example: moving shadows, spotlights, reflections in water, transparent surfaces moving past one another, etc. In this section, we show how the tracking algorithm presented in Section 3.1 can be used to detect, track and reconstruct objects in the case of transparent motions. Previous analysis of transparency <ref> [BBHP92, DP91, Shi92, SM90, SM91] </ref> assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods [BBHP92, Shi92, SM91] elegantly avoid the segmentation problem. <p> Previous analysis of transparency [BBHP92, DP91, Shi92, SM90, SM91] assumed constant motion over several successive frames, which excludes most sequences taken from an unstabilized moving camera. Some methods <ref> [BBHP92, Shi92, SM91] </ref> elegantly avoid the segmentation problem. They require, however, high order derivatives (the order increases with the number of objects), which increases the sensitivity to noisy data.
References-found: 23

