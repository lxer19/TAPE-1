URL: ftp://ftp.cse.cuhk.edu.hk/pub/techreports/94/tr-94-2.ps.gz
Refering-URL: ftp://ftp.cs.cuhk.hk/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Efficient Algorithms for Assigning Chain-like Tasks on a Chain-like Network Computer  optimally load balanced optimal schedules.  
Author: Gilbert H. Young and Chi-Lok Chan 
Note: are the  
Date: March 21, 1995  
Affiliation: Computer Science Department The Chinese University of Hong Kong  
Abstract: The optimal allocation of a chain-like task system on a chain-like network computers has been studied in a number of papers [1][2][3][4]. The best known algorithm has a time complexity of O((m 0 n) 2 n) if m n = O( otherwise O(m 0 log m 0 + m 0 (m 0 n)) where m 0 and n denote the number of un-mergeable modules and the number of processors respectively[4]. The space complexity of Hsu's algorithm and Young and Chan's algorithm are O((m 0 n)n) and O(m 0 (m 0 n)) respectively. In this paper, we generalize the decision algorithm discussed in [4] and propose two algorithms for the optimization problem based on the generalized decision test. The first algorithm gives an optimal schedule in O(m 02 ) time. For the second one, the chain-like task system is divided into two categories, dominated and non-dominated task system. A dominated task system can be solved by an asymptotically optimal algorithm in O(m 0 ) time. For a non-dominated task system, the worst case time complexity is O(m 0 n log(m 0 n)). This is asymptotically the best algorithm if m 0 n = !(n). This algorithm has an efficient average case time complexity of O(m 0 log m 0 ) which is better than all existing algorithms except m 0 n = o( log n). The space complexity of our algorithm is O(m 0 ) which is better than that of Young and Chan's or Hsu's algorithm. Furthermore, the optimal schedules obtained by using all these algorithms share a common property that the minimal number of processors is always used so that they p
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Shahid H. Bokhari. </author> <title> "Partitioning Problems in Parallel, Pipelined, </title> <journal> and Distributed Computing". IEEE Transactions on Computers, </journal> <volume> vol 37:pp. </volume> <pages> 48-57, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: 1 Introduction The problem we investigate in this paper is the allocation of a chain-like task system on the chain-like network computers which was first presented by Bokhari <ref> [1] </ref>. A chain-like task system consists of m modules scheduled on n processors. Each module is associated with an execution time and communicates with its neighboring modules with a communication cost. <p> The optimal allocation problem is to find a schedule in which the bottleneck processor has the minimal execution time. This problem is first proposed by Bokhari and he gave an algorithm with time complexity of O (m 3 n) <ref> [1] </ref>. Sheu and Chiang showed that a more general assignment problem can be solved in O (minfm; ngm 2 )[2]. Hsu presented a two phase algorithm [3]. The first phase, merge phase, is used to get an un-mergeable chain like task system with m 0 modules. <p> All of execution times and communication times are positive except that C 0;1 and C m;m+1 equal zero. * Adjacent modules must be assigned to adjacent processors or the same processor, which is called contiguity constraint <ref> [1] </ref>. If adjacent modules are assigned to the same processor, their communication (intra-communication) time is assumed to be zero. * The completion time of a module i,denoted as CM P i , is equal to C i1;i + E i + C i;i+1 .
Reference: [2] <author> J.P. Sheu and Z.F. Chaing. </author> <title> "Efficient allocation of chain-like task on chain-like network computers". </title> <journal> Information Processing Letters, </journal> <volume> vol 36:pp. </volume> <pages> 241-245, </pages> <year> 1990. </year> <month> 13 </month>
Reference: [3] <author> C.C. Hsu. </author> <title> "A Two-phase Approach for the Optimal Assignment of a Chain-like Task on a Chain-like Network Computer". </title> <type> Technical report, </type> <institution> National Taiwan Institute of Technology, </institution> <year> 1993. </year>
Reference-contexts: This problem is first proposed by Bokhari and he gave an algorithm with time complexity of O (m 3 n) [1]. Sheu and Chiang showed that a more general assignment problem can be solved in O (minfm; ngm 2 )[2]. Hsu presented a two phase algorithm <ref> [3] </ref>. The first phase, merge phase, is used to get an un-mergeable chain like task system with m 0 modules. <p> It is analogous to the worst case of quick sort. The average case time complexity is O (m + m 0 log m 0 ) which is better than all existing algorithms except Hsu's one <ref> [3] </ref> when m 0 n = o ( p log n). All optimal schedules obtained by using these two algorithms use the minimal number of processors. The remainder of this paper is organized as follows: section 2 states the problem assumptions and notations used in this paper. <p> F K is the set of all feasible length-K schedules. * An optimal schedule, S ffi , is a feasible schedule with minimal schedule length, K o , ie. 9S ffi 2 F K o * Two modules, t i and t i+1 are un-mergeable <ref> [3] </ref> if C i;i+1 &lt; E i + C i1;i and C i;i+1 &lt; E i+1 + C i+1;i+2 * A chain-like task system is said to be un-mergeable if all pairs of modules are un-mergeable. <p> This is an asymptotically optimal algorithm. In addition, we can get an optimal schedule if the optimal schedule length is known and the resulting optimal schedule uses the minimal number of processors among all optimal schedules. For Hsu's algorithm <ref> [3] </ref>, all processors must always be utilized in any optimal schedule if m 0 n. For obtaining an optimal schedule. Two algorithms are presented. Both of them apply the merge phase of Hsu's algorithm [3] and an un-mergeable chain-like task system with m 0 modules is obtained. <p> For Hsu's algorithm <ref> [3] </ref>, all processors must always be utilized in any optimal schedule if m 0 n. For obtaining an optimal schedule. Two algorithms are presented. Both of them apply the merge phase of Hsu's algorithm [3] and an un-mergeable chain-like task system with m 0 modules is obtained. The first algorithm, Algorithm 2, is a constructive algorithm which has time and space complexities of O (m + m 02 ) and O (m) respectively. <p> For the second algorithm, Algorithm 4, we divide chain-like task systems into two categories, dominated and non-dominated. For a dominated task system, we give an O (m) algorithm for obtaining an optimal schedule. It can be shown that the special case of Hsu's algorithm <ref> [3] </ref>, when m 0 n, is only a sub-class of dominated task system. For a non-dominated task system, we modify the constructive algorithm, Algorithm 2, by using some properties of un-mergeable non-dominated task system. <p> The worst case time complexity is asymptotically better than Young and Chan's one [4] if m 0 n = !(n). The average case time complexity is better than all algorithms except Hsu's one <ref> [3] </ref> when the special case of m 0 n = o ( p log n) occurs.
Reference: [4] <author> Gilbert Young and Chan Chi-Lok. </author> <title> "Scheduling Algorithm for a Chain-like Task System". </title> <booktitle> In "Lecture Notes in Computer Science", volume vol:762, </booktitle> <pages> pages 496-515, </pages> <year> 1993. </year>
Reference-contexts: The decision version, whether there exist a schedule with schedule length no greater than a given constant K , is first presented by Young and Chan <ref> [4] </ref>. The time and space complexities are O (m 0 ). Moreover, they gave an O (m + m 0 log m 0 + m 0 (m 0 n)) algorithm for solving the optimization problem. In this paper, we generalize the decision algorithm presented in [4]. <p> presented by Young and Chan <ref> [4] </ref>. The time and space complexities are O (m 0 ). Moreover, they gave an O (m + m 0 log m 0 + m 0 (m 0 n)) algorithm for solving the optimization problem. In this paper, we generalize the decision algorithm presented in [4]. The time and space complexities remain O (m 0 ). Besides, we propose another approach, a constructive method, to find an optimal schedule in O (m + m 02 ) time. Furthermore, the input chain-like task system is divided into two categories, dominated and non-dominated. <p> This algorithm is asymptotically better than Young and Chan's algorithm <ref> [4] </ref> if m 0 n = !(n). The worst case of this algorithm occurs when two sequences of numbers are nearly monotonic. It is analogous to the worst case of quick sort. <p> L (S) = max i fCP i (S)g The corresponding processor is called bottleneck processor. 2 * A schedule is said to be feasible if it satisfies the contiguity constraint and F is the set of all feasible schedules. A schedule, S, is called a feasible length-K schedule <ref> [4] </ref> if L (S) = max fCP i (S)g K where K is a given constant. <p> Hsu presented an O (m) algorithm to obtain an un-mergeable chain-like task system. 3 Generalized Decision Test By Young and Chan's decision algorithm <ref> [4] </ref>, we can decide whether there exists a feasible length-K schedule, where K is a given constant. In other words, we can check whether K is greater than the optimal schedule length K o . <p> By modifying this algorithm, we can decide whether there exists a feasible schedule with schedule length strictly less than K , or equivalently, check whether a constant K is less than K o . The modified algorithm is identical to Young and Chan's decision algorithm <ref> [4] </ref> except that all "&gt;" symbols (in line 3 and 8) are replaced by "". <p> E i + C i;i+1 C i1;i (14) return `Yes' and S Theorem 1 For m 0 un-mergeable modules scheduled on n processors, Algorithm 1 returns a schedule S with schedule length less than K iff there exists one. 3 Proof: Similar to the proof of the decision algorithm in <ref> [4] </ref>. 2 Theorem 2 For m 0 un-mergeable modules scheduled on n processors and any constant K o , K o is the optimal schedule length iff there exists a feasible length-K o schedule and there does not exists any schedule with schedule length less than K . <p> L (S) =K o and 9=S 0 2 F s.t. L (S 0 ) &lt;K o 2 As a result, we can compare any constant, K with the optimal schedule length, K o by Algorithm 1 and Young and Chan's decision algorithm <ref> [4] </ref>. For the rest of the paper, the following generalized decision test is used for the optimization problem, Young and Chan's decision algorithm [4] Algorithm 1 Result YES YES K &gt;K o NO NO K &lt;K o The generalized decision test has a time and space complexities of O (m 0 <p> o 2 As a result, we can compare any constant, K with the optimal schedule length, K o by Algorithm 1 and Young and Chan's decision algorithm <ref> [4] </ref>. For the rest of the paper, the following generalized decision test is used for the optimization problem, Young and Chan's decision algorithm [4] Algorithm 1 Result YES YES K &gt;K o NO NO K &lt;K o The generalized decision test has a time and space complexities of O (m 0 ). <p> If the optimal schedule length is known, we can obtain the optimal schedule by using the modified Young and Chan's decision algorithm <ref> [4] </ref> (the optimal schedule is a feasible length-K o schedule). In addition, any feasible length-K schedule obtained has the following properties, Lemma 3 By comparing the feasible length-K schedule S return by Young and Chan's decision algorithm [4] and any feasible length-K schedule S 0 , the total number of modules <p> obtain the optimal schedule by using the modified Young and Chan's decision algorithm <ref> [4] </ref> (the optimal schedule is a feasible length-K o schedule). In addition, any feasible length-K schedule obtained has the following properties, Lemma 3 By comparing the feasible length-K schedule S return by Young and Chan's decision algorithm [4] and any feasible length-K schedule S 0 , the total number of modules have been scheduled up to p j (1 j n) of S is no less than that of S 0 , ie. where M (S; j) denotes the total number of modules scheduled on p 1 ; <p> k 1) M (S 0 ; k 1) = n 0 k &gt; n k For S, t n k1 +1 ; : : : ; t n k are scheduled on p k and t n k +1 cannot be scheduled on p k (line 3 in Algorithm 1 <ref> [4] </ref>), ie. CM P n k1 +1n k n k +1 &gt; K k1 +1n 0 k ([4], n k1 n 0 CM P n k1 +1n k +1 ([4], n 0 &gt; K which is contradictory to the fact that S 0 is a feasible length-K schedule. 2 Theorem 4 <p> k1 +1n 0 k (<ref> [4] </ref>, n k1 n 0 CM P n k1 +1n k +1 ([4], n 0 &gt; K which is contradictory to the fact that S 0 is a feasible length-K schedule. 2 Theorem 4 If S is a schedule return from Young and Chan's decision algorithm [4], S is a feasible length-K schedule using the minimal number of processors. 4 Proof: Suppose S uses n fl processors and 9S 0 2 F K such that S 0 uses only n 0 processors with n 0 &lt; n fl , m 0 = M (S 0 ; n <p> Theorem 5 Algorithm 2 returns an optimal schedule. Proof: The optimal schedule length is unique, there exists a schedule with optimal schedule length, K o , and F K o 6= fg. By applying Young and Chan's decision algorithm <ref> [4] </ref> with K = K o , it says 'Yes' and returns a feasible length-K o schedule, S (indeed an optimal schedule). Let p b be the bottleneck processor with the smallest index in S. <p> We are going to prove that Algorithm 2 stops at processor p b . 5 Since K o is the optimal schedule length, F K = fg, 8 K &lt; K o , line 5 is always satisfied (by <ref> [4] </ref>). For the first processor, we can continue to assign more modules until K K o (the first time line 5 fails). This means that Algorithm 2 assigns as many modules as possible until the completion time is no less than K o . <p> L (S) = max fCM P i g; 8S 2 F K o Proof: Part 1: ")" part. It is obvious that each processor has been assigned at least one module (conti guity constraint), by <ref> [4] </ref>, 8S 2 F ; L (S) max On the other hand, if the chain-like task system has a dominated optimal sched ule, then 8S 2 F K o F ; 9x; 1 x m 0 s:t: L (S) = CM P x max 6 By ( 1) and ( 2), <p> The total time and space complexities of Algorithm 3 are O (m 0 ). 5.2 Algorithm for Non-dominated Task System Now, we are going to design an algorithm for a non-dominated task system. By <ref> [4] </ref>, we know that there exists an optimal schedule such that at least one bottleneck processor has been scheduled no greater than m 0 n + 1 modules. <p> Then L (S 0 ) = maxfL; R; CM P x g (x is the index of remaining modules) = maxfL; Rg (Definition of non-dominated task system) &lt; L (S) (By <ref> [4] </ref>) which is contradictory to the fact that S is an optimal schedule. 2 7 In Algorithm 2, we apply the decision test with the current completion time as a feasibility test to check whether this completion time is less than the optimal schedule length. <p> Each module is examined sequentially until the optimal schedule is obtained. By using the monotonic increasing property of the completion time <ref> [4] </ref>, a binary search for each processor can be applied instead of a sequential search. For a non-dominated task system, by Lemma 7, each processor can be scheduled at most m 0 n + 1 modules in any optimal schedule. <p> Proof: If the task system is a dominated task system, line 2 returns an optimal schedule (by lemma 6). If the task system is a non-dominated task system, by Lemma 6 and Lemma 7, CM P 1 &lt; K o CM P 1m 0 n+1 By <ref> [4] </ref> and Lemma 6, the completion time is monotonic increasing so that we can always find an index l such that 1 &lt; l m 0 n + 1 and CM P 1l1 &lt; K o CM P 1l t 1 ; : : : ; t l1 are scheduled on <p> Proof: LB j is updated in two cases only (case 3 or case 4). In case 3, LB j = Y X &gt; LB j1 In case 4, LB j CM P sf (By <ref> [4] </ref>) = X &gt; LB j1 This means that LB j is monotonic non-decreasing with j. <p> The average case time complexity of Algorithm 4 is derived and it equals O (m + m 0 log m 0 ). The worst case time complexity is asymptotically better than Young and Chan's one <ref> [4] </ref> if m 0 n = !(n). The average case time complexity is better than all algorithms except Hsu's one [3] when the special case of m 0 n = o ( p log n) occurs.
Reference: [5] <author> Donald E. Knuth. </author> <title> "The Art of Programming". </title> <publisher> Addison-wesley, </publisher> <year> 1973. </year> <month> 14 </month>
Reference-contexts: Lemma 10 The expected number of occurrences of case 2, case 3, case 4 are O (log n); O (log n); O (1) respectively. Proof: Let P j (x) denotes the probability that x occurs in p j . By <ref> [5] </ref>, the mean and variance of right-to-left maxima are both O (log n), thus P j (case 2 occurs) = P j (R j = min 1ij 1kj 1ij E (case 2 occurs) = P n 2 P j (case 2 occurs) fl 1 E (Number of right-to-left maxima) = O
References-found: 5

