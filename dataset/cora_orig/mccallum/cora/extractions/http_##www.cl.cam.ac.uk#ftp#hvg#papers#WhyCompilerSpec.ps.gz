URL: http://www.cl.cam.ac.uk/ftp/hvg/papers/WhyCompilerSpec.ps.gz
Refering-URL: http://www.cl.cam.ac.uk/Research/HVG/FTP/FTP.html
Root-URL: 
Title: Of What Use is a Verified Compiler Specification?  
Author: Paul Curzon 
Address: New Museums Site Pembroke Street Cambridge CB2 3QG United Kingdom  
Affiliation: University of Cambridge Computer Laboratory  
Date: Number 274  
Pubnum: Technical Report  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Mark Aagaard and Miriam Leeser. </author> <title> Verifying a logic synthesis tool in Nuprl: A case study in software verification. </title> <booktitle> In Proceedings of the 4th Workshop on Computer Aided Verification, </booktitle> <year> 1992. </year>
Reference-contexts: For example, a specification written in a subset of higher-order logic can be identified with an implementation in Standard ML. This was the approach taken by Aagaard and Leeser <ref> [1] </ref>. They verified a higher-order logic specification of a logic synthesis tool using Nuprl. It was also implemented in Standard ML using corresponding definitions. In some cases the definitions required by Nuprl were in a different form to that required by Standard ML. <p> In the following we use the standard bracketed notation for lists. For example, <ref> [1; 2] </ref> is an abbreviation for CONS 1 (CONS 2 []). Suppose we wish to execute APPEND applied to the lists [1; 2] and [3; 4]. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. <p> In the following we use the standard bracketed notation for lists. For example, <ref> [1; 2] </ref> is an abbreviation for CONS 1 (CONS 2 []). Suppose we wish to execute APPEND applied to the lists [1; 2] and [3; 4]. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we <p> Suppose we wish to execute APPEND applied to the lists <ref> [1; 2] </ref> and [3; 4]. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS <p> gives the theorem: ` APPEND <ref> [1; 2] </ref> [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` <p> [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND <ref> [1; 2] </ref> [3; 4] = [1; 2; 3; 4] 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. <p> (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = <ref> [1; 2; 3; 4] </ref> 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. For example, we can obtain a theorem containing variables in place of the numbers. <p> [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = <ref> [1; 2; 3; 4] </ref> 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. For example, we can obtain a theorem containing variables in place of the numbers.
Reference: [2] <author> Richard Boulton, Andrew Gordon, Mike Gordon, John Harrison, John Herbert, and John Van-Tassel. </author> <title> Experience with embedding hardware description languages in HOL. </title> <editor> In V. Stavridou, T. F. Melham, and R. T. Boute, editors, </editor> <booktitle> Theorem Provers in Circuit Design, </booktitle> <pages> pages 129-156. </pages> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: Such semantic embedding has also been used in the field of hardware verification. Subsets of the languages ELLA, VHDL and SILAGE, for which simulators are available, have been semantically embedded in higher-order logic <ref> [2] </ref>. Also when performing a compiler correctness proof, the semantics of the source and target languages must be defined: that is they are semantically embedded in the logic. <p> In the following we use the standard bracketed notation for lists. For example, <ref> [1; 2] </ref> is an abbreviation for CONS 1 (CONS 2 []). Suppose we wish to execute APPEND applied to the lists [1; 2] and [3; 4]. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. <p> In the following we use the standard bracketed notation for lists. For example, <ref> [1; 2] </ref> is an abbreviation for CONS 1 (CONS 2 []). Suppose we wish to execute APPEND applied to the lists [1; 2] and [3; 4]. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we <p> For example, [1; 2] is an abbreviation for CONS 1 (CONS 2 []). Suppose we wish to execute APPEND applied to the lists [1; 2] and [3; 4]. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with <ref> [2] </ref>, [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the <p> Suppose we wish to execute APPEND applied to the lists <ref> [1; 2] </ref> and [3; 4]. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS <p> Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with <ref> [2] </ref>, [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, <p> l1, l2 and h in the second clause of the definition of APPEND are specialised with <ref> [2] </ref>, [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to <p> gives the theorem: ` APPEND <ref> [1; 2] </ref> [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` <p> [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND <ref> [1; 2] </ref> [3; 4] = [1; 2; 3; 4] 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. <p> (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = <ref> [1; 2; 3; 4] </ref> 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. For example, we can obtain a theorem containing variables in place of the numbers. <p> [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = <ref> [1; 2; 3; 4] </ref> 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. For example, we can obtain a theorem containing variables in place of the numbers.
Reference: [3] <author> Robert S. Boyer and Yuan Yu. </author> <title> Automated proofs of object code for a commercial microprocessor. </title> <editor> In D. Kapur, editor, </editor> <booktitle> Proceedings of the 11th International Conference on Automated Deduction, volume 607 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 416-431. </pages> <publisher> Springer-Verlag, </publisher> <year> 1992. </year>
Reference-contexts: The situation is made worse because the object code is machine generated. Understanding why it is expected to be correct, a prerequisite for formal verification, is much harder especially if an optimising compiler is used. This approach was adopted by Boyer and Yu <ref> [3] </ref>. They verified compiled C and Ada code for the MC68020 microprocessor. Their methodology was to compile the source code using an industrial strength compiler and verify the resulting object code. This was done by first writing a second algorithmic version of the program in the Boyer-Moore logic. <p> Next the implementation is shown to satisfy the algorithm. It can then be deduced that the implementation satisfies the abstract specification. This split of the problem is similar to that used by Boyer and Yu to verify machine code programs <ref> [3] </ref>. A similar split has also been used in the verification of protocols [7]. Proving that an algorithm satisfies an abstract specification is simpler than proving that the implementation does. This is because the semantics of the implementation language does not need to be considered in the reasoning. <p> In the following we use the standard bracketed notation for lists. For example, [1; 2] is an abbreviation for CONS 1 (CONS 2 []). Suppose we wish to execute APPEND applied to the lists [1; 2] and <ref> [3; 4] </ref>. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain <p> Suppose we wish to execute APPEND applied to the lists [1; 2] and <ref> [3; 4] </ref>. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS <p> execute APPEND applied to the lists [1; 2] and <ref> [3; 4] </ref>. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we <p> This gives the theorem: ` APPEND [1; 2] <ref> [3; 4] </ref> = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give <p> This gives the theorem: ` APPEND [1; 2] <ref> [3; 4] </ref> = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] <p> theorem: ` APPEND [1; 2] <ref> [3; 4] </ref> = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; <p> 1 (APPEND [2] <ref> [3; 4] </ref>) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = [1; 2; 3; 4] 12 <p> [] <ref> [3; 4] </ref>) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = [1; 2; 3; 4] 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. <p> = CONS 1 (CONS 2 (APPEND [] <ref> [3; 4] </ref>)) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = [1; 2; 3; 4] 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. <p> (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = <ref> [1; 2; 3; 4] </ref> 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. For example, we can obtain a theorem containing variables in place of the numbers. <p> [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = <ref> [1; 2; 3; 4] </ref> 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. For example, we can obtain a theorem containing variables in place of the numbers.
Reference: [4] <author> Bettina Buth, Karl-Heinz Buth, Martin Franzle, Burghard v. Karger, Yassine Lakhneche, Hans Langmaack, and Markus Muller-Olm. </author> <title> Provably correct compiler development and implementation. </title> <booktitle> In Compiler Construction '92, </booktitle> <year> 1992. </year>
Reference-contexts: We suggest that execution by proof provides a secure way of circumventing this problem. It can be used to obtain a low-level implementation of a compiler from a verified compiler specification. This approach is complementary to a method that has been suggested elsewhere <ref> [4] </ref>. By combining the approaches, the probability that the resulting compiler is incorrect can be reduced further. The remainder of this paper is structured as follows. <p> Only their syntax is important. What is required is that the implementation produces syntactically the same program as indicated by the specification. This approach was followed by Chirica and Martin [9], Simpson [37] and Buth et al. <ref> [4] </ref>. It is illustrated in Figure 4. We thus prove the following about the algorithm: ` AbstractCompilerSpec CompilerAlgorithm and about the implementation ` 8p. <p> In the following we use the standard bracketed notation for lists. For example, [1; 2] is an abbreviation for CONS 1 (CONS 2 []). Suppose we wish to execute APPEND applied to the lists [1; 2] and <ref> [3; 4] </ref>. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain <p> Suppose we wish to execute APPEND applied to the lists [1; 2] and <ref> [3; 4] </ref>. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS <p> execute APPEND applied to the lists [1; 2] and <ref> [3; 4] </ref>. Initially, the variables l1, l2 and h in the second clause of the definition of APPEND are specialised with [2], [3;4] and 1, respectively. This gives the theorem: ` APPEND [1; 2] [3; 4] = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we <p> This gives the theorem: ` APPEND [1; 2] <ref> [3; 4] </ref> = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give <p> This gives the theorem: ` APPEND [1; 2] <ref> [3; 4] </ref> = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] <p> theorem: ` APPEND [1; 2] <ref> [3; 4] </ref> = CONS 1 (APPEND [2] [3; 4]) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; <p> 1 (APPEND [2] <ref> [3; 4] </ref>) In a similar way we can also obtain the theorem: ` APPEND [2] [3; 4] = CONS 2 (APPEND [] [3; 4]) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = [1; 2; 3; 4] 12 <p> [] <ref> [3; 4] </ref>) We can use this to rewrite the first theorem giving: ` APPEND [1; 2] [3; 4] = CONS 1 (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = [1; 2; 3; 4] 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. <p> = CONS 1 (CONS 2 (APPEND [] <ref> [3; 4] </ref>)) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = [1; 2; 3; 4] 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. <p> (CONS 2 (APPEND [] [3; 4])) Next, we specialise the first clause of the definition of APPEND with the list [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = <ref> [1; 2; 3; 4] </ref> 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. For example, we can obtain a theorem containing variables in place of the numbers. <p> [3;4] to give the theorem ` APPEND [] [3; 4] = [3;4] Rewriting the previous theorem with this we obtain the desired theorem: ` APPEND [1; 2] [3; 4] = <ref> [1; 2; 3; 4] </ref> 12 This tells us that the result of executing APPEND with these values is the list [1; 2; 3; 4]. We can use the same tool to perform symbolic execution. For example, we can obtain a theorem containing variables in place of the numbers. <p> These approaches entail a significant amount of work. A better solution is available, however. It is possible to bootstrap a secure compiler by implementing it in the source language it compiles. Buth et al. <ref> [4] </ref> suggest compiling the compiler using a possibly insecure compiler that is already available. Even if that compiler has not been verified, a great degree of confidence can still be obtained in the resulting code using a bootstrap self-test. <p> The probability that they produce the same incorrect code is very small. It would require that the bug in the host be such that it implants an identical bug in the target code. An alternative is to use the compiler specification as the first verified compiler. Buth et al. <ref> [4] </ref> suggest manually applying the specification definitions to execute 16 Source Compiler Text Source Compiler Text = Insecure Compiler Object Compiler Object Compiler Text Version 2 Object Compiler Text Version 1 Source Compiler Text Source Compiler Text = Source Compiler Text = Compiler Prototyped from Specification Object Compiler Text Version 1
Reference: [5] <author> Albert John Camilleri. </author> <title> Executing behavioural definitions in higher order logic. </title> <type> Technical Report 140, PhD Thesis, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <month> February </month> <year> 1988. </year> <month> 20 </month>
Reference-contexts: In the field of hardware behavioural specifications, Albert Camilleri showed that specifications in higher-order logic can be automatically translated into the functional programming language HOL ML and so simulated <ref> [5] </ref>. Hall and Windley [21] have adapted this approach to allow microprocessor specifications to be executed. Rajan also uses similar techniques to automatically translate general deterministic higher-order logic specifications into HOL ML code [33].
Reference: [6] <author> Juanito Camilleri. </author> <title> Symbolic compilation and execution of programs by proof: A case study in HOL. </title> <type> Technical Report 240, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <month> December </month> <year> 1991. </year>
Reference-contexts: They can also be used to test the definitions prior to verification and to generate theorems which will be of use when verifying the algorithm. Juanito Camilleri has used this technique very successfully to simulate the definitions of a compiler for an Occam subset <ref> [6] </ref>. Valuable feedback was obtained to help ensure the definitions were correct before verification was attempted. Goossens [18] has also used execution by proof, though to simulate hardware designs and in combination with semantic embedding. The hardware description language picoELLA was semantically embedded in higher-order logic.
Reference: [7] <author> Rachel Cardell-Oliver. </author> <title> Using higher order logic for modelling real-time protocols. </title> <editor> In S. Abramsky and T. S. E. Maibaum, editors, </editor> <booktitle> Proceedings of TAPSOFT'91, Lecture Notes in Computer Science, </booktitle> <pages> pages 259-282. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: It can then be deduced that the implementation satisfies the abstract specification. This split of the problem is similar to that used by Boyer and Yu to verify machine code programs [3]. A similar split has also been used in the verification of protocols <ref> [7] </ref>. Proving that an algorithm satisfies an abstract specification is simpler than proving that the implementation does. This is because the semantics of the implementation language does not need to be considered in the reasoning. Instead we reason about the logical constructs of the algorithm.
Reference: [8] <author> William C. Carter, William H. Joyner, Jr., and Daniel Brand. </author> <title> Microprogram verification considered necessary. </title> <editor> In Saki P. Ghosh and Leonard Y. Liu, editors, </editor> <booktitle> AFIPS Conference Proceedings 1978 National Computer Conference, </booktitle> <volume> volume 47, </volume> <pages> pages 657-664. </pages> <publisher> AFIPS Press, </publisher> <month> June </month> <year> 1978. </year>
Reference-contexts: Verification of bit-level code has typically been based around an operational semantics of the host machine and the use of formal symbolic simulation techniques. MCS was an early system which took this approach. It was used to verify production code for the NASA Standard Spaceborne Computer-2 <ref> [8] </ref>. A hybrid approach using verification condition generation techniques to verify bit-level microprograms has also been suggested [13].
Reference: [9] <author> Laurian M. Chirica and David F. Martin. </author> <title> Towards compiler implementation correctness proofs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 8(2) </volume> <pages> 185-214, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: The majority of compiler correctness work has been concerned only with the correctness of code generators. Exceptions to this include Polak's work [31] and that of Chirica and Martin <ref> [9] </ref> where aspects of compiler front ends are also considered. There has also been isolated work on the formal verification of the front ends of compilers, notably parsers [12, 11, 17]. <p> However, here the semantics of the source and target languages of the compiler do not need to be considered. Only their syntax is important. What is required is that the implementation produces syntactically the same program as indicated by the specification. This approach was followed by Chirica and Martin <ref> [9] </ref>, Simpson [37] and Buth et al. [4]. It is illustrated in Figure 4. We thus prove the following about the algorithm: ` AbstractCompilerSpec CompilerAlgorithm and about the implementation ` 8p.
Reference: [10] <author> D. L. Clutterbuck and B. A. Carre. </author> <title> The verification of low level code. </title> <journal> Software Engineering Journal, </journal> <pages> pages 97-111, </pages> <year> 1988. </year>
Reference-contexts: Lamb also used it in his Intel 8080 Assembly Language Verifier [24]. More recently it has been embodied in the SPADE verification environment. SPADE has been used in the verification of assembly code for the Intel 8080 <ref> [10] </ref>, and also of Z8002 code used in the fuel control unit of the RB211-524G jet engine [29]. Verification of bit-level code has typically been based around an operational semantics of the host machine and the use of formal symbolic simulation techniques.
Reference: [11] <author> Avra Cohn. </author> <title> The correctness of a parsing algorithm in LCF. </title> <type> Technical Report 21, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <year> 1982. </year>
Reference-contexts: Exceptions to this include Polak's work [31] and that of Chirica and Martin [9] where aspects of compiler front ends are also considered. There has also been isolated work on the formal verification of the front ends of compilers, notably parsers <ref> [12, 11, 17] </ref>. The need for a front end can be removed if the abstract syntax used is in a sufficiently readable form. For example, the LISP-like concrete syntax of Piton is also its abstract syntax. Programs are both written and accepted by the verified code generator in this form.
Reference: [12] <author> Avra Cohn and Robin Milner. </author> <title> On using Edinburgh LCF to prove the correctness of a parsing algorithm. </title> <type> Technical Report 20, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <year> 1982. </year>
Reference-contexts: Exceptions to this include Polak's work [31] and that of Chirica and Martin [9] where aspects of compiler front ends are also considered. There has also been isolated work on the formal verification of the front ends of compilers, notably parsers <ref> [12, 11, 17] </ref>. The need for a front end can be removed if the abstract syntax used is in a sufficiently readable form. For example, the LISP-like concrete syntax of Piton is also its abstract syntax. Programs are both written and accepted by the verified code generator in this form.
Reference: [13] <author> Paul Curzon. </author> <title> A structured approach to the verification of low level microcode. </title> <type> Technical Report 215, PhD Thesis, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <month> February </month> <year> 1991. </year>
Reference-contexts: MCS was an early system which took this approach. It was used to verify production code for the NASA Standard Spaceborne Computer-2 [8]. A hybrid approach using verification condition generation techniques to verify bit-level microprograms has also been suggested <ref> [13] </ref>. To retain the advantages of high-level programming, but ensure that the object code itself is validated, the program can be written in a high-level language, and validation of the resulting compiled code performed. This is the normal procedure when testing is the validation method used.
Reference: [14] <author> Paul Curzon. </author> <title> Deriving correctness properties of compiled code. </title> <editor> In L. Claesen and M. Gordon, editors, </editor> <booktitle> Proceedings of the International Workshop on Higher Order Logic Theorem Proving and its Applications. </booktitle> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: Hall and Windley [21] have adapted this approach to allow microprocessor specifications to be executed. Rajan also uses similar techniques to automatically translate general deterministic higher-order logic specifications into HOL ML code [33]. A verified compiling algorithm for a subset of Vista <ref> [14] </ref> is being used as a case study to test this tool [34]. In this approach, the potential sources of insecurity are in the correctness of 10 the translator and the correctness of the implementation of the simulation language.
Reference: [15] <author> Paul Curzon. </author> <title> A verified compiler for a structured assembly language. </title> <booktitle> In Proceedings of the 1991 International Workshop on the HOL Theorem Proving System and its Applications. </booktitle> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: Of course, if the language which is embedded has a complex semantics such as a programming language, the advantages of having a separate algorithmic specification are lost. A more secure approach is to use formal proof to perform the compilation <ref> [15] </ref>. This is done by taking the definitions of the compiler, specialising the appropriate variable with the program to be compiled and performing rewriting until target code is obtained. It can be done automatically using a mechanized proof assistant such as HOL.
Reference: [16] <author> Robert W. Floyd. </author> <title> Assigning meanings to programs. </title> <booktitle> In Proceedings of the Symposium on Applied Mathematics, </booktitle> <volume> volume 19, </volume> <pages> pages 19-32, </pages> <year> 1967. </year>
Reference-contexts: Such systems can be divided into those that perform verification on mnemonic assembly language programs and those which use a bit-representation of the code. 3 The assembly language systems have typically followed Floyd's approach to program verification <ref> [16] </ref> modified to deal with low-level code. They provide a verification condition generation program which embodies the semantics of the assembly language. Maurer [25, 26] used this approach to verify IBM 370 code and code for the Litton C4000 airborne computer.
Reference: [17] <author> P. Gloess. </author> <title> An experiment with the Boyer-Moore theorem prover; a proof of correctness of a simple parser of expressions. </title> <booktitle> In Proceedings of the 5th Conference on Automated Deduction, volume 87 of Lecture Notes in Computer Science, </booktitle> <pages> pages 154-169, </pages> <year> 1980. </year> <month> 21 </month>
Reference-contexts: Exceptions to this include Polak's work [31] and that of Chirica and Martin [9] where aspects of compiler front ends are also considered. There has also been isolated work on the formal verification of the front ends of compilers, notably parsers <ref> [12, 11, 17] </ref>. The need for a front end can be removed if the abstract syntax used is in a sufficiently readable form. For example, the LISP-like concrete syntax of Piton is also its abstract syntax. Programs are both written and accepted by the verified code generator in this form.
Reference: [18] <author> K. G. W. Goossens. </author> <title> Operational semantics based formal symbolic simulation. </title> <editor> In L. Claesen and M. Gordon, editors, </editor> <booktitle> Proceedings of the International Workshop on Higher Order Logic Theorem Proving and its Applications. </booktitle> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: Juanito Camilleri has used this technique very successfully to simulate the definitions of a compiler for an Occam subset [6]. Valuable feedback was obtained to help ensure the definitions were correct before verification was attempted. Goossens <ref> [18] </ref> has also used execution by proof, though to simulate hardware designs and in combination with semantic embedding. The hardware description language picoELLA was semantically embedded in higher-order logic. The LAMBDA theorem prover was then used to execute designs written in picoELLA.
Reference: [19] <author> M. J. C. Gordon and T. F. Melham. </author> <title> Introduction to HOL: A Theorem Proving Environment for Higher-order Logic. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: In particular, we describe a way in which the specification itself can be executed by formal proof. This involves proving a theorem which states that applying the compiling algorithm to a program of interest gives particular object code. Using a mechanized proof assistant such as HOL <ref> [19] </ref>, a theorem like this can be obtained automatically with a high degree of security. Furthermore, the object code in question can be automatically derived as part of the formal proof. Previously this technique has been used to test definitions before using them in a formal proof.
Reference: [20] <author> Michael J. C. Gordon. </author> <title> Mechanizing programming logics in higher order logic. </title> <editor> In G. Birtwistle and P. A. Subrahmanyam, editors, </editor> <booktitle> Current Trends in Hardware Verification and Automated Theorem Proving, </booktitle> <pages> pages 387-439. </pages> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Sufficient proof infrastructure, such as derived inference rules would have to be developed to allow proofs in the embedded language to be naturally performed. Such semantic embedding has been done for several specification languages in HOL, such as linear temporal logic [22], and VDM 11 style specifications <ref> [20] </ref>. Aagaard's work, described above, essentially involved em-bedding Standard ML in Nuprl. Since Standard ML is so similar to higher-order logic little work was needed to define the semantics. Such semantic embedding has also been used in the field of hardware verification.
Reference: [21] <author> Kelly M. Hall and Phillip J. Windley. </author> <title> Simulating microprocessors from formal specifications. </title> <editor> In L. Claesen and M. Gordon, editors, </editor> <booktitle> Proceedings of the International Workshop on Higher Order Logic Theorem Proving and its Applications. </booktitle> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: In the field of hardware behavioural specifications, Albert Camilleri showed that specifications in higher-order logic can be automatically translated into the functional programming language HOL ML and so simulated [5]. Hall and Windley <ref> [21] </ref> have adapted this approach to allow microprocessor specifications to be executed. Rajan also uses similar techniques to automatically translate general deterministic higher-order logic specifications into HOL ML code [33].
Reference: [22] <author> Jeffrey J. Joyce. </author> <title> Totally verified systems: Linking verified software to verified hardware. </title> <editor> In M. Leeser and G. Brown, editors, </editor> <title> Specification, Verification and Synthesis: Mathematical Aspects. </title> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Sufficient proof infrastructure, such as derived inference rules would have to be developed to allow proofs in the embedded language to be naturally performed. Such semantic embedding has been done for several specification languages in HOL, such as linear temporal logic <ref> [22] </ref>, and VDM 11 style specifications [20]. Aagaard's work, described above, essentially involved em-bedding Standard ML in Nuprl. Since Standard ML is so similar to higher-order logic little work was needed to define the semantics. Such semantic embedding has also been used in the field of hardware verification.
Reference: [23] <author> Jeffrey J. Joyce. </author> <title> A verified compiler for a verified microprocessor. </title> <type> Technical Report 167, </type> <institution> University of Cambridge, Computer Laboratory, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: Since then many different techniques have been used. However, there are as yet no formally verified commercially available compilers for real languages. A good overview of the compiler verification literature is given by Joyce <ref> [23] </ref>. Notable work, includes that of Polak [31] on a compiler for a Pascal-like language, and the Piton and Gypsy compilers which form part of Computational Logic's verified stack of system components [28, 38]. The majority of compiler correctness work has been concerned only with the correctness of code generators.
Reference: [24] <author> Paul Arthur Lamb. </author> <title> A verification condition generator for Intel 8080 microprocessor assembly language programs. </title> <type> PhD thesis, </type> <institution> George Washington University, </institution> <year> 1982. </year>
Reference-contexts: They provide a verification condition generation program which embodies the semantics of the assembly language. Maurer [25, 26] used this approach to verify IBM 370 code and code for the Litton C4000 airborne computer. Lamb also used it in his Intel 8080 Assembly Language Verifier <ref> [24] </ref>. More recently it has been embodied in the SPADE verification environment. SPADE has been used in the verification of assembly code for the Intel 8080 [10], and also of Z8002 code used in the fuel control unit of the RB211-524G jet engine [29].
Reference: [25] <author> W. D. Maurer. </author> <title> Proving the correctness of a flight-director program for an airborne minicomputer. </title> <booktitle> In Proceedings of the ACM SIGMINI/SIGPLAN Interface Meeting on Program Systems in the Small Processor Environment, </booktitle> <pages> pages 103-108, </pages> <year> 1976. </year> <note> Appeared as a special issue of SIGPLAN Notice V11(4), </note> <month> April </month> <year> 1976. </year>
Reference-contexts: They provide a verification condition generation program which embodies the semantics of the assembly language. Maurer <ref> [25, 26] </ref> used this approach to verify IBM 370 code and code for the Litton C4000 airborne computer. Lamb also used it in his Intel 8080 Assembly Language Verifier [24]. More recently it has been embodied in the SPADE verification environment.
Reference: [26] <author> W. D. Maurer. </author> <title> An IBM 370 assembly language verifier. </title> <editor> In P. A. Willis, editor, </editor> <booktitle> Proceedings of the 16th Annual Technical Symposium on Systems and Software: Operational Reliability and Performance Assurance, </booktitle> <pages> pages 139-146. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1977. </year>
Reference-contexts: They provide a verification condition generation program which embodies the semantics of the assembly language. Maurer <ref> [25, 26] </ref> used this approach to verify IBM 370 code and code for the Litton C4000 airborne computer. Lamb also used it in his Intel 8080 Assembly Language Verifier [24]. More recently it has been embodied in the SPADE verification environment.
Reference: [27] <author> John McCarthy and James Painter. </author> <title> Correctness of a compiler for arithmetic expressions. </title> <editor> In J. T. Schwartz, editor, </editor> <booktitle> Proceedings of Symposia in Applied Mathematics, volume XIX, </booktitle> <pages> pages 33-41, </pages> <year> 1966. </year>
Reference-contexts: However, in the long term, the use of formally verified compilers will be of more use. There has been interest in formally verifying compilers from the early days of verification technology, the first work being that by McCarthy and Painter <ref> [27] </ref> in 1966. Since then many different techniques have been used. However, there are as yet no formally verified commercially available compilers for real languages. A good overview of the compiler verification literature is given by Joyce [23].
Reference: [28] <author> J. Strother Moore. </author> <title> A mechanically verified language implementation. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 5 </volume> <pages> 461-492, </pages> <year> 1989. </year> <month> 22 </month>
Reference-contexts: A good overview of the compiler verification literature is given by Joyce [23]. Notable work, includes that of Polak [31] on a compiler for a Pascal-like language, and the Piton and Gypsy compilers which form part of Computational Logic's verified stack of system components <ref> [28, 38] </ref>. The majority of compiler correctness work has been concerned only with the correctness of code generators. Exceptions to this include Polak's work [31] and that of Chirica and Martin [9] where aspects of compiler front ends are also considered. <p> When this is so, the algorithm itself can be used as a concrete compiler. The work done at Computational Logic Inc. where the Boyer-Moore logic was used is a case in point <ref> [28, 38] </ref>. The Boyer-Moore logic is a first-order, quantifier-free logic resembling pure Lisp and hence is executable. The Boyer-Moore theorem prover contains an interpreter for the logic which can be used to execute specifications. Thus, verified compiler specifications can be used to do compilation.
Reference: [29] <author> I. M. O'Neill, D. L. Clutterbuck, P. F. Farrow, P. G. Summers, and W. C. Dolman. </author> <title> The formal verification of safety-critical assembly code. </title> <editor> In W. D. Ehrenberger, editor, </editor> <booktitle> Proceedings of the IFAC Symposium on Safety of Computer Control Systems 1988 (Safecomp '88) Safety Related Computers in an Expanding Market, </booktitle> <year> 1988. </year>
Reference-contexts: More recently it has been embodied in the SPADE verification environment. SPADE has been used in the verification of assembly code for the Intel 8080 [10], and also of Z8002 code used in the fuel control unit of the RB211-524G jet engine <ref> [29] </ref>. Verification of bit-level code has typically been based around an operational semantics of the host machine and the use of formal symbolic simulation techniques. MCS was an early system which took this approach. It was used to verify production code for the NASA Standard Spaceborne Computer-2 [8].
Reference: [30] <author> Lawrence Paulson. </author> <title> A higher-order implementation of rewriting. </title> <booktitle> Science of Computer Programming, </booktitle> <volume> 3 </volume> <pages> 119-149, </pages> <year> 1983. </year>
Reference-contexts: The tools used to perform execution of definitions in this way are conversions <ref> [30] </ref>. Given a term in the logic they return a theorem expressing an equality between that term and another. Various tools are available in HOL for creating rewriting conversions for a particular definition and for combining conversions. Thus tools for executing compiler definitions are straightforward to build.
Reference: [31] <author> Wolfgang Polak. </author> <title> Compiler Specification and Verification, </title> <booktitle> volume 124 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Since then many different techniques have been used. However, there are as yet no formally verified commercially available compilers for real languages. A good overview of the compiler verification literature is given by Joyce [23]. Notable work, includes that of Polak <ref> [31] </ref> on a compiler for a Pascal-like language, and the Piton and Gypsy compilers which form part of Computational Logic's verified stack of system components [28, 38]. The majority of compiler correctness work has been concerned only with the correctness of code generators. Exceptions to this include Polak's work [31] and <p> Polak <ref> [31] </ref> on a compiler for a Pascal-like language, and the Piton and Gypsy compilers which form part of Computational Logic's verified stack of system components [28, 38]. The majority of compiler correctness work has been concerned only with the correctness of code generators. Exceptions to this include Polak's work [31] and that of Chirica and Martin [9] where aspects of compiler front ends are also considered. There has also been isolated work on the formal verification of the front ends of compilers, notably parsers [12, 11, 17]. <p> A compiler implementation can be verified against either an algorithm or an abstract specification. Ultimately, we wish to know that an implementation preserves the semantics of the source language. This suggests we should verify it against the abstract specification. This was the approach adopted by Polak <ref> [31] </ref>. However, a simpler alternative is to use a verified algorithm as a refinement step towards obtaining a verified implementation (see Figure 3). The algorithm is first shown to satisfy the abstract specification. Next the implementation is shown to satisfy the algorithm.
Reference: [32] <editor> Terry Pratchett. Mort. </editor> <publisher> Transworld Publishers, </publisher> <year> 1987. </year>
Reference-contexts: These two approaches are complementary. Unfortunately, "million-to-one chances crop up nine times out of ten" <ref> [32] </ref>. Our confidence that the bootstrapping approaches give correct code relies on intuitive arguments that the probabilities of particular events are negligible and that different methods are independent and so will not introduce the same bug.
Reference: [33] <author> Sreeranga Rajan. </author> <title> Executing HOL specifications: Towards an evaluation semantics for classical higher order logic. </title> <editor> In L. Claesen and M. Gordon, editors, </editor> <booktitle> Proceedings of the International Workshop on Higher Order Logic Theorem Proving and its Applications. </booktitle> <publisher> North-Holland, </publisher> <year> 1992. </year>
Reference-contexts: Hall and Windley [21] have adapted this approach to allow microprocessor specifications to be executed. Rajan also uses similar techniques to automatically translate general deterministic higher-order logic specifications into HOL ML code <ref> [33] </ref>. A verified compiling algorithm for a subset of Vista [14] is being used as a case study to test this tool [34]. In this approach, the potential sources of insecurity are in the correctness of 10 the translator and the correctness of the implementation of the simulation language.
Reference: [34] <author> Sreeranga Rajan. </author> <title> Private communication, </title> <year> 1992. </year>
Reference-contexts: Rajan also uses similar techniques to automatically translate general deterministic higher-order logic specifications into HOL ML code [33]. A verified compiling algorithm for a subset of Vista [14] is being used as a case study to test this tool <ref> [34] </ref>. In this approach, the potential sources of insecurity are in the correctness of 10 the translator and the correctness of the implementation of the simulation language. If the implementation language has a close syntactic correspondence with the logic, errors in the translation process can be reduced.
Reference: [35] <author> David Shepherd. </author> <title> Using mathematical logic and formal methods to write correct microcode. </title> <booktitle> In Proceedings of the 20th Annual Workshop on Microprogramming, </booktitle> <year> 1988. </year> <note> Appeared as a special issue of Sigmicro Newsletter, 19(1 and 2), </note> <month> June </month> <year> 1988. </year>
Reference-contexts: However, here it is more difficult as the semantics of the source language are unlikely to be as clean as the pure logic used to describe the algorithm. Shepherd <ref> [35, 36] </ref> adopted an approach similar to this to verify microcode for the IMS T800 floating point Transputer. The intended methodology was to prove correct a high-level Occam implementation of a program then use the Occam transformation system to produce an equivalent microcode version.
Reference: [36] <author> David Shepherd. </author> <title> Verified microcode design. </title> <journal> Microprocessors and Microsystems, </journal> <volume> 40(10) </volume> <pages> 623-630, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: However, here it is more difficult as the semantics of the source language are unlikely to be as clean as the pure logic used to describe the algorithm. Shepherd <ref> [35, 36] </ref> adopted an approach similar to this to verify microcode for the IMS T800 floating point Transputer. The intended methodology was to prove correct a high-level Occam implementation of a program then use the Occam transformation system to produce an equivalent microcode version.
Reference: [37] <author> Todd G. Simpson. </author> <title> Design and verification of IFL: a wide-spectrum intermediate functional language. </title> <type> Technical Report 91/440/24, </type> <institution> University of Calgary, Department of Computer Science, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: Only their syntax is important. What is required is that the implementation produces syntactically the same program as indicated by the specification. This approach was followed by Chirica and Martin [9], Simpson <ref> [37] </ref> and Buth et al. [4]. It is illustrated in Figure 4. We thus prove the following about the algorithm: ` AbstractCompilerSpec CompilerAlgorithm and about the implementation ` 8p.
Reference: [38] <author> William D. Young. </author> <title> A mechanically verified code generator. </title> <journal> Journal of Automated Reasoning, </journal> <volume> 5 </volume> <pages> 493-519, </pages> <year> 1989. </year> <month> 23 </month>
Reference-contexts: A good overview of the compiler verification literature is given by Joyce [23]. Notable work, includes that of Polak [31] on a compiler for a Pascal-like language, and the Piton and Gypsy compilers which form part of Computational Logic's verified stack of system components <ref> [28, 38] </ref>. The majority of compiler correctness work has been concerned only with the correctness of code generators. Exceptions to this include Polak's work [31] and that of Chirica and Martin [9] where aspects of compiler front ends are also considered. <p> When this is so, the algorithm itself can be used as a concrete compiler. The work done at Computational Logic Inc. where the Boyer-Moore logic was used is a case in point <ref> [28, 38] </ref>. The Boyer-Moore logic is a first-order, quantifier-free logic resembling pure Lisp and hence is executable. The Boyer-Moore theorem prover contains an interpreter for the logic which can be used to execute specifications. Thus, verified compiler specifications can be used to do compilation.
References-found: 38

