URL: http://www-cgi.cs.cmu.edu/afs/cs.cmu.edu/project/venari/www/usenix96-kindred-wing.ps
Refering-URL: 
Root-URL: 
Email: fdkindred,wingg@cs.cmu.edu  
Title: Fast, Automatic Checking of Security Protocols  
Author: Darrell Kindred Jeannette M. Wing 
Affiliation: Computer Science Department Carnegie Mellon University  
Abstract: We present a new approach, theory checking, to analyzing and verifying properties of security protocols. In this approach we generate the entire finite theory, T h, of a logic for reasoning about a security protocol; determining whether it satisfies a property, , is thus a simple membership test: 2 T h. Our approach relies on (1) modeling a finite instance of a protocol in the way that the security community naturally, though informally, presents a security protocol, and (2) placing restrictions on a logic's rules of inference to guarantee that our algorithm terminates, generating a finite theory. A novel benefit to our approach is that because of these restrictions we can provide an automatic theory-checker generator. We applied our approach and our theory-checker generator to three different logics for reasoning about authentication and electronic commerce protocols: the Burrows-Abadi-Needham logic of authentication, AUTLOG, and Kailar's accountability logic [4, 8, 6]. For each we verified the desired properties using specialized theory checkers; most checks took less than two minutes, and all less than fifteen. 1 Motivation for our Approach 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. E. Bell and L. J. LaPadula. </author> <title> Secure computer systems: Unified exposition and Multics interpretation. </title> <type> Technical Report ESD-TR-75-306, </type> <institution> The MITRE Corporation, Bedford, </institution> <address> MA, </address> <month> March </month> <year> 1976. </year>
Reference-contexts: Theorem proving, usually machine-assisted, is the more traditional approach to verifying security properties, including a long history of work based on the Bell-LaPadula model <ref> [1] </ref>. As in theorem proving, we manipulate the syntactic representation, i.e., the logic, of the entity we are verifying; by restricting the nature of the logic, however, unlike machine-assisted theorem proving, we enumerate the entire theory rather than (with human assistance) develop lemmas and theorems as needed.
Reference: [2] <author> J. Bentley. </author> <title> Little languages. </title> <journal> Communications of the ACM, </journal> <volume> 29(8):711721, </volume> <year> 1986. </year>
Reference-contexts: Finally, our approach makes it easy to generate specialized checkers automatically. Just as Jon Bentley has argued the need for little languages <ref> [2] </ref>, our tool provides a way to construct little tools for little logics. 6 Summary and Future Directions Our approach was motivated by the need to debug protocols in the security domain. When someone presents a security protocol, there is always an uneasiness on our part.
Reference: [3] <author> R. S. Boyer and J. S. Moore. </author> <title> A Computational Logic. </title> <booktitle> ACM monograph series. </booktitle> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: 1 Motivation for our Approach Past approaches to reasoning about security protocols, e.g., authentication protocols, have relied on either pencil-and-paper proof or machine-assisted proof through the use of interactive theorem provers, e.g., the Boyer-Moore Prover <ref> [3] </ref>, Gypsy [5], HDM [9], Ina This research is sponsored by the Wright Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF, and the Advanced Research Projects Agency (ARPA) under grant number F33615-93-1-1330.
Reference: [4] <author> Michael Burrows, Martin Abadi, and Roger Need-ham. </author> <title> A logic of authentication. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 8(1):1836, </volume> <month> February </month> <year> 1990. </year>
Reference-contexts: Furthermore, each reverse-application of the G-rules will terminate since G-rules are strictly growing, so the algorithm terminates. 3 Examples We used our theory-checker generator to build three theory checkers, encoding three different logics: the well-known BAN logic of authentication <ref> [4] </ref>; AUTLOG [8], an extension of the BAN logic; and Kailar's logic for reasoning about accountability in electronic commerce protocols [6]. We describe each of these encodings below. 3.1 BAN The BAN logic is a natural case to consider; it motivated the original development of our method and tool. <p> be expressed in a simple manner, and it provides rules for interpreting encrypted messages exchanged among the parties (principals) involved in a protocol. 3.1.1 The Logic In encoding the BAN logic and its accompanying sample protocols, we had to make several adjustments and additions to the logic as originally presented <ref> [4] </ref>, to account for rules and assumptions that were missing or implicit. The first eleven correspond directly to constructs in the original logic, and have clear interpretations. <p> The logic restrictions from Section 2 do not permit the use of universal quantifiers, as BAN specifications sometimes do in delegation statements <ref> [4] </ref>: A believes 8K:(S controls (A K However, since none of the BAN rules introduce new keys, we can get the effect of this universal quantification in assumptions by instantiating the statement with each of the keys mentioned in the other assumptions. <p> We could do this automatically as a preprocessing step. It may be possible to extend our method slightly to allow universal quantification at the outermost level. After encoding the rules, we entered each of the four protocols examined in the BAN paper and checked all the properties claimed there <ref> [4] </ref>. (We added most of the extensions above after some verification attempt failed.) 3.1.2 Kerberos Through a sequence of four messages, the Kerberos protocol establishes a shared key for communication between two principals, using a trusted server [12]. <p> The BAN analysis of this protocol starts by constructing a three-message idealized protocol; the idealized protocol ignores message 1 since it is unencrypted. The BAN analysis then goes on to list ten initial assumptions regarding client/server shared keys, trust of the server, and freshness of the timestamps used <ref> [4] </ref>. We express each of these three messages and ten assumptions directly (the conversion is purely syntactic), and add four more assumptions (see Figures 2 and 3). The first extra assumptionthat A must believe its own timestamp to be freshis missing in [4], and the last three are required to satisfy <p> the server, and freshness of the timestamps used <ref> [4] </ref>. We express each of these three messages and ten assumptions directly (the conversion is purely syntactic), and add four more assumptions (see Figures 2 and 3). The first extra assumptionthat A must believe its own timestamp to be freshis missing in [4], and the last three are required to satisfy the distinctness side-conditions. <p> Among the 9 formulas in this difference is believes (A; believes (B; shared key (K ab ; A; B))); (the last of the four results above). This confirms the claim in the original analysis that the three-message protocol does not convince A of B's existence <ref> [4] </ref>.
Reference: [5] <author> D. I. Good, R. L. London, and W. W. Bledsoe. </author> <title> An interactive program verification system. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 1(1):5967, </volume> <year> 1979. </year>
Reference-contexts: 1 Motivation for our Approach Past approaches to reasoning about security protocols, e.g., authentication protocols, have relied on either pencil-and-paper proof or machine-assisted proof through the use of interactive theorem provers, e.g., the Boyer-Moore Prover [3], Gypsy <ref> [5] </ref>, HDM [9], Ina This research is sponsored by the Wright Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF, and the Advanced Research Projects Agency (ARPA) under grant number F33615-93-1-1330.
Reference: [6] <author> Rajashekar Kailar. </author> <title> Accountability in electronic commerce protocols. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 22(5):313328, </volume> <month> May </month> <year> 1996. </year>
Reference-contexts: G-rules are strictly growing, so the algorithm terminates. 3 Examples We used our theory-checker generator to build three theory checkers, encoding three different logics: the well-known BAN logic of authentication [4]; AUTLOG [8], an extension of the BAN logic; and Kailar's logic for reasoning about accountability in electronic commerce protocols <ref> [6] </ref>. We describe each of these encodings below. 3.1 BAN The BAN logic is a natural case to consider; it motivated the original development of our method and tool. This logic is normally applied to authentication protocols. <p> In Section 4 we mention some optimizations we expect to reduce this time. 3.3 Kailar's Accountability Logic More recently, Kailar has proposed a simple logic for reasoning about accountability in electronic commerce protocols <ref> [6] </ref>. The central construct in this logic is P CanProve X which means that principal P can convince anyone in an intended audience sharing a set of assumptions that X holds, without revealing any secrets other than X. <p> We add rewrites expressing the commutativity and associativity of comma, as in the other logics. This encoding does not require any G-rules. We verified the variants of the IBS (NetBill) electronic payment protocol that Kailar analyzes <ref> [6] </ref>. Figure 4 contains an encoding of part of the service provision phase of the asymmetric-key version of this protocol. <p> It will then apply the component-extracting rule to pro duce CanProve (S; Says (E; SignedWith (Price; K 1 s ))) CanProve (S; Says (E; Price)). Finally, it will apply Inf to derive these results, which Kailar gives <ref> [6] </ref>. CanProve (S; Says (E; ReceivedOneServiceItem (E))) CanProve (S; Says (E; AgreesToPrice (E; pr))) It will stop at this point, since no further rule applications can produce new formulas. We verified the rest of Kailar's results for two variants of the IBS protocol and for the SPX Authentication Exchange protocol.
Reference: [7] <author> R. A. Kemmerer and S. T. </author> <title> Eckmann. A User's Manual for the UNISEX System. </title> <institution> Dept. of Computer Science, UCSB, </institution> <year> 1983. </year>
Reference-contexts: Views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of Wright Laboratory or the United States Government. Jo [10], and UNISEX <ref> [7] </ref>. Proofs of properties of these protocols relied on either specialized logics, e.g., Burrows-Abadi-Needham's Logic of Authentication, or an encoding of a specialized logic in the theorem prover's general-purpose logic. These proofs are tedious to do.
Reference: [8] <author> Volker Kessler and Gabriele Wedel. </author> <title> AUTLOGan advanced logic of authentication. </title> <booktitle> In Proc. the Computer Security Foundations Workshop VII, </booktitle> <pages> pages 9099. </pages> <publisher> IEEE Comput. Soc., </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Furthermore, each reverse-application of the G-rules will terminate since G-rules are strictly growing, so the algorithm terminates. 3 Examples We used our theory-checker generator to build three theory checkers, encoding three different logics: the well-known BAN logic of authentication [4]; AUTLOG <ref> [8] </ref>, an extension of the BAN logic; and Kailar's logic for reasoning about accountability in electronic commerce protocols [6]. We describe each of these encodings below. 3.1 BAN The BAN logic is a natural case to consider; it motivated the original development of our method and tool. <p> In fact we must sign the secret data together with a nonce to ensure freshness. After we corrected this, the verifications proceeded as expected. 3.2 AUTLOG AUTLOG is an extension of the BAN logic, proposed by Kessler and Wedel <ref> [8] </ref>. It introduces several concepts, including a simulated eavesdropper for detecting information leaks, and the idea of principals recognizing decrypted messages. Our encoding of AUTLOG uses all the BAN functions, and a few extras: recognizable, mac (for message authentication codes), hash, and recently said.
Reference: [9] <author> K. N. Levitt, L. Robinson, and B. A. Silverberg. </author> <title> The HDM handbook, </title> <type> vols. 13. Technical report, </type> <institution> SRI International, </institution> <address> Menlo Park, California, </address> <year> 1979. </year>
Reference-contexts: 1 Motivation for our Approach Past approaches to reasoning about security protocols, e.g., authentication protocols, have relied on either pencil-and-paper proof or machine-assisted proof through the use of interactive theorem provers, e.g., the Boyer-Moore Prover [3], Gypsy [5], HDM <ref> [9] </ref>, Ina This research is sponsored by the Wright Laboratory, Aeronautical Systems Center, Air Force Materiel Command, USAF, and the Advanced Research Projects Agency (ARPA) under grant number F33615-93-1-1330.
Reference: [10] <author> R. Locasso, J. Scheid, D. V. Schorre, and P. R. Eg-gert. </author> <title> The Ina Jo reference manual. </title> <type> Technical Report TM-(L)-6021/001/000, </type> <institution> System Development Corporation, </institution> <address> Santa Monica, California, </address> <year> 1980. </year>
Reference-contexts: Views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of Wright Laboratory or the United States Government. Jo <ref> [10] </ref>, and UNISEX [7]. Proofs of properties of these protocols relied on either specialized logics, e.g., Burrows-Abadi-Needham's Logic of Authentication, or an encoding of a specialized logic in the theorem prover's general-purpose logic. These proofs are tedious to do.
Reference: [11] <author> G. Lowe. </author> <title> Breaking and fixing the Needham-Schroeder public-key protocol using FDR. </title> <booktitle> In Tools and Algorithms for the Construction and Analysis of Systems, </booktitle> <volume> volume 1055. </volume> <publisher> Springer-Verlag, </publisher> <month> March </month> <year> 1996. </year> <note> Lecture Notes in Computer Science. </note>
Reference-contexts: It has been used successfully in hardware verification and protocol analysis. Most recently, the FDR model checker [17] has been used by Lowe <ref> [11] </ref> to debug and fix the Needham-Schroeder public key protocol and by Roscoe [18] to check noninterference of a simple security hierarchy (high/low). Like model checking, our method relies on the finiteness of the entity being verified; unlike model checking, however, we generate a finite theory, not a finite model.
Reference: [12] <author> S. P. Miller, C. Neuman, J. I. Schiller, and J. H. Saltzer. </author> <title> Kerberos authentication and authorization system, chapter Sect. </title> <publisher> E.2.1. MIT, </publisher> <address> Cambridge, Mas-sachusetts, </address> <month> July </month> <year> 1987. </year>
Reference-contexts: protocols examined in the BAN paper and checked all the properties claimed there [4]. (We added most of the extensions above after some verification attempt failed.) 3.1.2 Kerberos Through a sequence of four messages, the Kerberos protocol establishes a shared key for communication between two principals, using a trusted server <ref> [12] </ref>. The BAN analysis of this protocol starts by constructing a three-message idealized protocol; the idealized protocol ignores message 1 since it is unencrypted. The BAN analysis then goes on to list ten initial assumptions regarding client/server shared keys, trust of the server, and freshness of the timestamps used [4].
Reference: [13] <author> P. Nivela and R. Nieuwenhuis. </author> <title> Saturation of first-order (constrained) clauses with the Saturate system. </title> <booktitle> In Proc. of the Fifth International Conference on Rewriting Techniques and Applications, </booktitle> <pages> pages 436440, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: The idea of computing the closure (or completion) of a theory is used in the theorem proving system SATURATE <ref> [13] </ref>. Our restrictions on the input logic allow us to generate a saturated set of formulas that we find easier to interpret than the sets generated by these more general systems. Finally, our approach makes it easy to generate specialized checkers automatically.
Reference: [14] <author> Sam Owre, John Rushby, Natarajan Shankar, and Friedrich von Henke. </author> <title> Formal verification for fault-tolerant architectures: Prolegomena to the design of PVS. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(2):107125, </volume> <month> February </month> <year> 1995. </year>
Reference-contexts: Moreover, our method is completely automatic and fast. Before building our theory-checker generator, we implemented the BAN logic within the PVS verification system <ref> [14] </ref>, and reproduced the Kerberos protocol proofs with it. The encoding of BAN in PVS was quite natural, but the proofs were tedious, primarily because for each rule application, we had to enter the variable instantia-tions manually since the prover could not guess the right ones.
Reference: [15] <author> Laurence C. Paulson. </author> <title> ML for the Working Programmer. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: This can lead to exponential blowup in the set of valid formulas, though, so it is better to use them only as needed. Since rewrites can be applied to any subformula, we augment a simple unification algorithm by trying rewrites at each recursive step of the unification <ref> [15] </ref>. Plotkin described a similar technique for building equational axioms into the unification process [16]. Since the G-rules and rewrites are applied lazily, the full algorithm does not generate the complete set of valid formulas.
Reference: [16] <author> G. D. Plotkin. </author> <title> Building-in equational theories. </title> <journal> Machine Intelligence, </journal> <volume> 7:7390, </volume> <year> 1972. </year>
Reference-contexts: Since rewrites can be applied to any subformula, we augment a simple unification algorithm by trying rewrites at each recursive step of the unification [15]. Plotkin described a similar technique for building equational axioms into the unification process <ref> [16] </ref>. Since the G-rules and rewrites are applied lazily, the full algorithm does not generate the complete set of valid formulas. Any formula whose formal proof has a rewrite or G-rule as its last step may not appear.
Reference: [17] <editor> A. W. Roscoe. Model-checking CSP. In A. W. Roscoe, editor, </editor> <title> A Classical Mind: Essays in Honour of C. </title> <editor> A. R. Hoare. </editor> <publisher> Prentice-Hall, </publisher> <year> 1994. </year>
Reference-contexts: It has been used successfully in hardware verification and protocol analysis. Most recently, the FDR model checker <ref> [17] </ref> has been used by Lowe [11] to debug and fix the Needham-Schroeder public key protocol and by Roscoe [18] to check noninterference of a simple security hierarchy (high/low).
Reference: [18] <author> A. W. Roscoe. </author> <title> CSP and determinism in security modelling. </title> <booktitle> In Proc. of the 1995 IEEE Symp. on Security and Privacy, </booktitle> <pages> pages 114127, </pages> <year> 1995. </year>
Reference-contexts: It has been used successfully in hardware verification and protocol analysis. Most recently, the FDR model checker [17] has been used by Lowe [11] to debug and fix the Needham-Schroeder public key protocol and by Roscoe <ref> [18] </ref> to check noninterference of a simple security hierarchy (high/low). Like model checking, our method relies on the finiteness of the entity being verified; unlike model checking, however, we generate a finite theory, not a finite model.
References-found: 18

