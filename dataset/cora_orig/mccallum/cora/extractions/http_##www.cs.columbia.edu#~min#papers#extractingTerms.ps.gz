URL: http://www.cs.columbia.edu/~min/papers/extractingTerms.ps.gz
Refering-URL: http://www.cs.columbia.edu/~min/
Root-URL: http://www.cs.columbia.edu
Email: fpascale,ming@cs.columbia.edu  
Title: Extracting Japanese Domain and Technical Terms is Relatively Easy  
Author: Pascale Fung Min-yen Kan Yurie Horita 
Address: New York, NY 10027  
Affiliation: Computer Science Department Columbia University,  
Note: Second International Conference inNew Methods for Language Processing, -NEMLP- Bilkent, Turkey: Sep.1996. pp. 148-159  
Abstract: We argue that the important task of extracting domain and technical terms is much easier in Japanese than is commonly believed, and that technical term extraction should and can be more widely used. We present a method which shows that the implementation of such a tool for Japanese can be remarkably simple due to the regularity and rigidity of morphosyntactic characteristics of Japanese technical terms. Our learning algorithm bootstraps from the tagged output of a Japanese tokenizer/tagger to learn syntactic and morphological properties of technical terms. We show that very simple linguistic patterns are reliable enough to yield high precision technical terms from tagged texts, even for terms which occur only once and are usually overlooked by English technical term extractors. In addition, by incorporating a model for unknown words, we are able to extract correct technical terms from words not properly tagged. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aho, B. Kernighan, and P. Weinberger. </author> <title> The AWK Programming Language. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, USA., </address> <year> 1980. </year>
Reference-contexts: Therefore, we use only the tokenized word output together with their POS tags. The input to our tool consists of the first and fourth column of Figure 2. We tokenize and tag both the Japanese translation of the AWK 2 manual <ref> [1] </ref>, and the Nihon Kezai Shimbun (the NIKKEI corpus) [16]. Part of the tagged AWK text is used for training of syntactic regular expression, and the NIKKEI corpus is used for open testing of our term extractor.
Reference: [2] <author> Sophia Ananiadou. </author> <title> A methodology for automatic term recognition. </title> <booktitle> In Proceedings of COLING-94, </booktitle> <pages> pages 1034-1038, </pages> <year> 1994. </year>
Reference-contexts: For many other languages, much research has been done on tools for automatic extraction of technical terms from large corpora. These languages include English [12, 4], Greek <ref> [2] </ref>, French [3], and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) [8, 4]. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers [12, 2, 3]. <p> These languages include English [12, 4], Greek [2], French [3], and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) [8, 4]. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers <ref> [12, 2, 3] </ref>. The advantages and disadvantages of these two approaches are listed in Figure 1. Lexical approach Morphosyntactic approach More adaptive|the same statistical measure Less robust-prior knowledge can be used over different domain texts. differ for different domains.
Reference: [3] <author> Didier Bourigault. </author> <title> Surface grammatical analysis for the extraction of terminological noun phrases. </title> <booktitle> In Proceedings of COLING 92, </booktitle> <pages> pages 977-981, </pages> <year> 1992. </year>
Reference-contexts: For many other languages, much research has been done on tools for automatic extraction of technical terms from large corpora. These languages include English [12, 4], Greek [2], French <ref> [3] </ref>, and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) [8, 4]. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers [12, 2, 3]. <p> These languages include English [12, 4], Greek [2], French [3], and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) [8, 4]. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers <ref> [12, 2, 3] </ref>. The advantages and disadvantages of these two approaches are listed in Figure 1. Lexical approach Morphosyntactic approach More adaptive|the same statistical measure Less robust-prior knowledge can be used over different domain texts. differ for different domains.
Reference: [4] <author> Ido Dagan and Kenneth W. Church. Termight: </author> <title> Identifying and translating technical terminology. </title> <booktitle> In Proceedings of the 4th Conference on Applied Natural Language Processing, </booktitle> <pages> pages 34-40, </pages> <address> Stuttgart, Germany, </address> <month> October </month> <year> 1994. </year>
Reference-contexts: We show in this paper that the implementation of a Japanese domain and technical term extraction tool is remarkably simple given a Japanese tokenizer/tagger. For many other languages, much research has been done on tools for automatic extraction of technical terms from large corpora. These languages include English <ref> [12, 4] </ref>, Greek [2], French [3], and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) [8, 4]. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers [12, 2, 3]. <p> These languages include English [12, 4], Greek [2], French [3], and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) <ref> [8, 4] </ref>. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers [12, 2, 3]. The advantages and disadvantages of these two approaches are listed in Figure 1.
Reference: [5] <author> Pascale Fung. </author> <title> Compiling bilingual lexicon entries from a non-parallel English-Chinese corpus. </title> <booktitle> In Proceedings of the Third Annual Workshop on Very Large Corpora, </booktitle> <pages> pages 173-183, </pages> <address> Boston, Massachusettes, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Under such circumstances, any recall evaluation would be overly subjective and possibly meaningless. We plan to further evaluate the performance of our term extractor in conjunction with a terminology translation tool we are currently developing <ref> [6, 5, 7] </ref>. This translation tool will match these extracted Japanese technical terms to their English correspondence in a corpus.
Reference: [6] <author> Pascale Fung. </author> <title> A pattern matching method for finding noun and proper noun translations from noisy parallel corpora. </title> <booktitle> In Proceedings of the 33rd Annual Conference of the Association for Computational Linguistics, </booktitle> <pages> pages 236-233, </pages> <address> Boston, Massachusettes, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: Under such circumstances, any recall evaluation would be overly subjective and possibly meaningless. We plan to further evaluate the performance of our term extractor in conjunction with a terminology translation tool we are currently developing <ref> [6, 5, 7] </ref>. This translation tool will match these extracted Japanese technical terms to their English correspondence in a corpus.
Reference: [7] <author> Pascale Fung. </author> <title> Space-frequency analysis for domain word translation. </title> <booktitle> In Proceedings of ICASSP 96, </booktitle> <address> Atlanta, Georgia, </address> <month> May </month> <year> 1996. </year> <note> To appear. </note>
Reference-contexts: Under such circumstances, any recall evaluation would be overly subjective and possibly meaningless. We plan to further evaluate the performance of our term extractor in conjunction with a terminology translation tool we are currently developing <ref> [6, 5, 7] </ref>. This translation tool will match these extracted Japanese technical terms to their English correspondence in a corpus.
Reference: [8] <author> Pascale Fung and Dekai Wu. </author> <title> Statistical augmentation of a Chinese machine-readable dictionary. </title> <booktitle> In Proceedings of the Second Annual Workshop on Very Large Corpora, </booktitle> <pages> pages 69-85, </pages> <address> Kyoto, Japan, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: For many other languages, much research has been done on tools for automatic extraction of technical terms from large corpora. These languages include English [12, 4], Greek [2], French [3], and Chinese <ref> [8] </ref>. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) [8, 4]. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers [12, 2, 3]. The advantages and disadvantages of these two approaches are listed in Figure 1. <p> These languages include English [12, 4], Greek [2], French [3], and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) <ref> [8, 4] </ref>. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers [12, 2, 3]. The advantages and disadvantages of these two approaches are listed in Figure 1. <p> For example, the term H /separation of state & church is an abbreviated term with being the first character of politics, state, the first character of church and the second character of religion, and H is the noun/verb separate, separation. We previously noted in <ref> [8] </ref> that this type of abbreviation increases the amount of unknown words in Chinese to a higher level than that of European languages. In fact, Japanese Kanji terms have equally high degree of abbreviation as Chinese. <p> This can be regarded as a most naive statistical significance measure. We previously used frequency threshold to extract statistically significant Chinese words and terms <ref> [8] </ref>. However, we argue that since technical terms in Japanese have more rigid morphological patterns than their counterparts in other languages, they are more easily distinguishable from non-technical terms. Our tool relies on this fact to extract Japanese technical terms which occur only once in a text.
Reference: [9] <author> Louis Guilbert. La creativite lexicale. Larousse, Paris, </author> <year> 1975. </year>
Reference-contexts: New verbal terms are exclusively Kanji or Katakana verbal nouns with *6 /suru, do. This limitation of new verbs to verbalized nouns seems to be a common phenomenon to many other languages, including English and French <ref> [9] </ref>. Technical terms are usually noun phrases, just like in English. Nouns and noun phrases are usually composed of only one character set, where most common Japanese nouns are in Hiragana, and more specific nouns in Kanji or Katakana.
Reference: [10] <author> Stephanie W. Haas. </author> <title> Covering the vocabulary of technical abstracts using standard and specialized dictionaries. </title> <journal> Journal of Information Science, </journal> <volume> 18 </volume> <pages> 363-373, </pages> <year> 1992. </year>
Reference-contexts: However, they can be intuitively characterized as being highly specific to a domain. They are lexically rigid, i.e. the same term is always used to refer to a domain-specific concept. And they are often new. Published technical dictionaries do not provide enough coverage of these terms <ref> [10] </ref>. One reason for the inadequacy of coverage is that there are many sub-areas in a domain with specialized terminology. Another reason is that in areas such as computer science, new terms are being created constantly and technical dictionaries often fail to be up-to-date.
Reference: [11] <institution> IWNM. Iwa Nami Information Science Dictionary. Iwa Nami Shoten, </institution> <year> 1990. </year> <title> In Japanese. </title>
Reference-contexts: As an example, seeing a multi-character string of Kanjis is analogous to seeing, say, the suffix -tion of a word in English. 5 Learning morphological patterns from technical dictio naries In order to verify our knowledge of Japanese technical terms, we consulted several Japanese technical dictionaries <ref> [14, 11, 17] </ref>. We drew random samples from the dictionaries and computed the distribution of character sets shown in Figure 3. Each column represents the percentage of terms containing that character set or the nominalizer.
Reference: [12] <author> John S. Justeson and Slava M. Katz. </author> <title> Technical terminology: some linguistic properties and an algorithm for identification in text. </title> <booktitle> Natural Language Engineering, </booktitle> <volume> 1 </volume> <pages> 9-27, </pages> <year> 1995. </year>
Reference-contexts: They are important for information retrieval, machine translation, translator-aid and technical manual generation tasks. Professional technical writers, translators and machine translations systems often have difficulties generating or translating domain and technical terms. There is no formal definition of technical terms <ref> [12] </ref>. However, they can be intuitively characterized as being highly specific to a domain. They are lexically rigid, i.e. the same term is always used to refer to a domain-specific concept. And they are often new. Published technical dictionaries do not provide enough coverage of these terms [10]. <p> We show in this paper that the implementation of a Japanese domain and technical term extraction tool is remarkably simple given a Japanese tokenizer/tagger. For many other languages, much research has been done on tools for automatic extraction of technical terms from large corpora. These languages include English <ref> [12, 4] </ref>, Greek [2], French [3], and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) [8, 4]. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers [12, 2, 3]. <p> These languages include English [12, 4], Greek [2], French [3], and Chinese [8]. There are two kinds of main approaches|lexical and morphosyntactic. Lexical approaches use statistical correlation scores between single words (or characters) [8, 4]. Morphosyn-tactic approaches use syntactic and morphological information provided by taggers <ref> [12, 2, 3] </ref>. The advantages and disadvantages of these two approaches are listed in Figure 1. Lexical approach Morphosyntactic approach More adaptive|the same statistical measure Less robust-prior knowledge can be used over different domain texts. differ for different domains. <p> Since (1) it is reported that most technical terms in English are noun phrases <ref> [12] </ref>, and (2) their translations in Japanese are technical terms as well, regardless of their POS tags, we bootstrap the learning process from the Japanese translations of English noun phrases. <p> Eventually we plan to incorporate statistical scores into the unknown word model to improve the performance of our tool. 8 Empirical finding: Rare terms can also found Justeson and Katz <ref> [12] </ref> report that the repetition of noun phrases provide discourse information for technical terms. This can be regarded as a most naive statistical significance measure. We previously used frequency threshold to extract statistically significant Chinese words and terms [8]. <p> However, there is no satisfying way for us to carry out a recall evaluation due to the subjective nature of defining technical terms. In <ref> [12] </ref>, recall was computed for a short paper by asking the author of the paper to manually select what he believes to be technical terms from his own paper, and then evaluating the tool output against his selection.
Reference: [13] <author> Yosiyuki Kobayasi, Takenobu Tokunaga, and Hozumi Tanaka. </author> <title> Analysis of syntactic structures of japanese compound noun. </title> <booktitle> In Proceedings of NLPRS'95, </booktitle> <pages> pages 326-331, </pages> <year> 1995. </year>
Reference-contexts: Perhaps due to such perceived difficulties, much research on Japanese terms has been concentrated on the analysis of some sub-classes such as four character compound nouns <ref> [13] </ref>, rather than a full study of Japanese domain and technical terms. On the other hand, tokenization and tagging of Japanese texts has been greatly facilitated by tools such as JUMAN, which is freely available.
Reference: [14] <author> KYJBJD. </author> <title> Financial Management Dictionary. Financial Study Group Inc., 1975. In Japanese. </title>
Reference-contexts: As an example, seeing a multi-character string of Kanjis is analogous to seeing, say, the suffix -tion of a word in English. 5 Learning morphological patterns from technical dictio naries In order to verify our knowledge of Japanese technical terms, we consulted several Japanese technical dictionaries <ref> [14, 11, 17] </ref>. We drew random samples from the dictionaries and computed the distribution of character sets shown in Figure 3. Each column represents the percentage of terms containing that character set or the nominalizer.
Reference: [15] <author> Yuji Matsumoto and Makoto Nagao. </author> <title> Improvements of japanese morphological analyzer JUMAN. </title> <booktitle> In Proceedings of the International Workshop on Sharable Natural Language Resources, </booktitle> <pages> pages 22-28, </pages> <month> August </month> <year> 1994. </year>
Reference-contexts: This tool, developed by Matsumoto and Nagao <ref> [15] </ref>, uses a set of Japanese Word Construction Grammar and syntactic grammar rules for transition rules, a morpheme dictionary and various grammar dictionaries to tokenize a text into word-segmented, POS tagged format with inflection and phonetic information. Two levels of POS classification are used in the POS dictionary.
Reference: [16] <editor> NIKKEI. Nihon Kezai Shimbun. Nihon Kezai Shimbun, </editor> <publisher> Inc., </publisher> <year> 1994. </year>
Reference-contexts: * p /Nm Numerals word-token phonetics root POS tag POS sub-class usage (2+%7) f`p 1 (1) 1 Gp ('') u`p ? ()3$#8) ? FV`p . (.) , Wp Wp h * R` /Nt Place names A typical JUMAN output is as follows in Figure 2 (taken from Nihon Kezai Shimbun <ref> [16] </ref>): Phonetics are useful in applications such as speech synthesis. The morphological root word differs from the word-token only in cases of verb conjugation, verbalization of nouns, etc. This information is useful when morphological normalization is needed. Japanese technical terms, being mostly noun phrases, have fairly rigid forms. <p> The input to our tool consists of the first and fourth column of Figure 2. We tokenize and tag both the Japanese translation of the AWK 2 manual [1], and the Nihon Kezai Shimbun (the NIKKEI corpus) <ref> [16] </ref>. Part of the tagged AWK text is used for training of syntactic regular expression, and the NIKKEI corpus is used for open testing of our term extractor. There have been various reports on the tokenization and tagging accuracy of JUMAN, ranging from 95% to 100%.
Reference: [17] <author> TKSHS. Statistics Dictionary. Toyo Kezai Shin Ho Sha, </author> <year> 1989. </year> <title> In Japanese. </title>
Reference-contexts: As an example, seeing a multi-character string of Kanjis is analogous to seeing, say, the suffix -tion of a word in English. 5 Learning morphological patterns from technical dictio naries In order to verify our knowledge of Japanese technical terms, we consulted several Japanese technical dictionaries <ref> [14, 11, 17] </ref>. We drew random samples from the dictionaries and computed the distribution of character sets shown in Figure 3. Each column represents the percentage of terms containing that character set or the nominalizer.
References-found: 17

