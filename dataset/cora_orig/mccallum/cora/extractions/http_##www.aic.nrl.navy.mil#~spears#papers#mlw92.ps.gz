URL: http://www.aic.nrl.navy.mil/~spears/papers/mlw92.ps.gz
Refering-URL: http://www.cs.gmu.edu:80/research/gag/pubs.html
Root-URL: 
Email: spears@aic.nrl.navy.mil gordon@aic.nrl.navy.mil  
Title: Is Consistency Harmful?  
Author: William M. Spears Diana F. Gordon 
Address: Washington, D.C. 20375 USA Washington, D.C. 20375 USA  
Affiliation: Naval Research Laboratory Naval Research Laboratory  
Abstract: We examine the issue of consistency from a new perspective. To avoid overfitting the training data, a considerable number of current systems have sacrificed the goal of learning hypotheses that are perfectly consistent with the training instances by setting a new goal of hypothesis simplicity (Occam's razor). Instead of using simplicity as a goal, we have developed a novel approach that addresses consistency directly. In other words, our concept learner has the explicit goal of selecting the most appropriate degree of consistency with the training data. We begin this paper by exploring concept learning with less than perfect consistency. Next, we describe a system that can adapt its degree of consistency in response to feedback about predictive accuracy on test data. Finally, we present the results of initial experiments that begin to address the question of how tightly hypotheses should fit the training data for different problems. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Angluin, D. & Laird, P. </author> <year> (1988). </year> <title> Learning from Noisy Examples. </title> <journal> Machine Learning, </journal> <volume> 2. </volume>
Reference-contexts: Our third direction for future research relates to the results in computational learning theory. Valiant (1984) has introduced the criterion of Probably Approximately Correct (PAC) identification of a target concept. Recently, a number of researchers have considered the computational feasibility of PAC identification in the context of noisy examples <ref> (e.g., Angluin & Laird 1988) </ref>. However, they assume the strategy is to maximize consistency with the training sample. It would be interesting to also explore the computational feasibility of PAC identification assuming a strategy of lower consistency.
Reference: <author> Breiman, L., Friedman, J., Olshen, R., & Stone, C. </author> <year> (1984). </year> <title> Classification and Regression Trees. Belmont: </title> <publisher> Wadsworth. </publisher>
Reference: <author> Buntine, W. </author> <year> (1991). </year> <title> Classifiers: A theoretical and empirical study. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence. </booktitle>
Reference-contexts: This behavior appears similar to that described by Fisher and Schlimmer (1988). 5 RELATED WORK There have been many methods for handling noisy data, such as weighted hypotheses (Schlimmer & Granger 1986), Bayesian approaches <ref> (Buntine 1991) </ref>, multiple version spaces (Mitchell 1978), and tree pruning (Quin-lan 1987; Breiman et al. 1984). The goal of our research is to vary the consistency level to handle noisy data and complex concepts. No previous research has had pre cisely the same goal.
Reference: <author> De Jong, K., Spears, W., & Gordon, D. </author> <year> (1992). </year> <title> Using genetic algorithms for concept learning. </title> <note> To appear in Machine Learning. </note>
Reference-contexts: Exceptions include Breiman et al. (1984) and Michalski (1990). In this paper, we examine one learning algorithm and consider the effects of varying the consistency level. Section 2 describes our concept learner, called the Genetic Algorithm Batch-Incremental Learner (GABIL), that we use in all experiments <ref> (De Jong et al. 1992) </ref>. Section 3 describes a modified version of GABIL that can learn concepts with different levels of consistency. This section also presents experimental results that compare predictive accuracy with different consistency levels on both clean and noisy data and a variety of target concepts.
Reference: <author> Fisher, D. & Schlimmer, D. </author> <year> (1988). </year> <title> Concept Simplification and Prediction Accuracy. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning. </booktitle>
Reference: <author> Michalski, R. </author> <year> (1983). </year> <title> A theory and methodology of inductive learning. </title> <editor> In R. Michalski, J. Car-bonell, & T. Mitchell (Eds.), </editor> <booktitle> Machine learning: An Artificial Intelligence Approach (Vol. 1). </booktitle> <address> Palo Alto: </address> <publisher> Tioga. </publisher>
Reference-contexts: 1 INTRODUCTION Early studies in supervised concept learning made the implicit assumption that the best method for obtaining high predictive accuracy on a test set is to find hypotheses that are perfectly consistent with respect to all examples in a training set <ref> (e.g., Michalski 1983) </ref>. A positive hypothesis (i.e., a hypothesis intended to cover the positive examples) is 100% consistent with respect to a set of examples if it covers all positive examples and no negative examples in the set.
Reference: <author> Michalski, R. </author> <year> (1990). </year> <title> Learning flexible concepts: Fundamental ideas and a method based on two-tiered representation. </title> <editor> In Y. Kodratoff, R. Michalski (Eds.), </editor> <booktitle> Machine learning: An Artificial Intelligence Approach (Vol. </booktitle> <address> 3) San Mateo: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Pruning (Quinlan 1987), which applies to decision trees, can reduce the consistency level because each decision tree branch that is pruned away may contain information to distinguish the classes of instances. After pruning, this information is lost. The removal of hypothesis disjuncts <ref> (Michalski 1990) </ref> is an effective method to increase the simplicity of DNF hypotheses. This method may sacrifice 100% consistency because the removed disjuncts may uniquely cover some of the training examples.
Reference: <author> Mitchell, T. </author> <year> (1978). </year> <title> Version spaces: An approach to concept learning. </title> <type> Ph.D. thesis, </type> <institution> Stanford University, Stanford, </institution> <address> CA. </address>
Reference-contexts: This behavior appears similar to that described by Fisher and Schlimmer (1988). 5 RELATED WORK There have been many methods for handling noisy data, such as weighted hypotheses (Schlimmer & Granger 1986), Bayesian approaches (Buntine 1991), multiple version spaces <ref> (Mitchell 1978) </ref>, and tree pruning (Quin-lan 1987; Breiman et al. 1984). The goal of our research is to vary the consistency level to handle noisy data and complex concepts. No previous research has had pre cisely the same goal.
Reference: <author> Quinlan, J. </author> <year> (1987). </year> <title> Simplifying decision trees. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 27. </volume>
Reference-contexts: The most closely related research investigates the effectiveness of a simplicity bias. This research is related because increased simplicity can result in a reduced consistency level. Simplicity biases have been implemented with two of the most widely used hypothesis representations: decision trees and DNF hypotheses. Pruning <ref> (Quinlan 1987) </ref>, which applies to decision trees, can reduce the consistency level because each decision tree branch that is pruned away may contain information to distinguish the classes of instances. After pruning, this information is lost.
Reference: <author> Schaffer, C. </author> <year> (1991). </year> <title> Overfitting avoidance as bias. </title> <booktitle> In Proceedings of the Workshop on Evaluating and Changing Representation in Machine Learning at IJCAI. </booktitle>
Reference: <author> Schlimmer, J. & Granger, R. </author> <year> (1986). </year> <title> Incremental learning from noisy data. </title> <journal> Machine Learning, </journal> <volume> 1. </volume>
Reference-contexts: Finally, and perhaps most interest ingly, the consistency level usually drops as the number of examples increases. This behavior appears similar to that described by Fisher and Schlimmer (1988). 5 RELATED WORK There have been many methods for handling noisy data, such as weighted hypotheses <ref> (Schlimmer & Granger 1986) </ref>, Bayesian approaches (Buntine 1991), multiple version spaces (Mitchell 1978), and tree pruning (Quin-lan 1987; Breiman et al. 1984). The goal of our research is to vary the consistency level to handle noisy data and complex concepts. No previous research has had pre cisely the same goal.
Reference: <author> Valiant, L. </author> <year> (1984). </year> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27. </volume>
References-found: 12

