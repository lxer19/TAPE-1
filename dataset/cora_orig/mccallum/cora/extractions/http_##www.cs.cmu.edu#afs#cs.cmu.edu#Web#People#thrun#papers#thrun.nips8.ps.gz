URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/thrun.nips8.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/thrun.nips8.html
Root-URL: http://www.cs.cmu.edu
Title: Is Learning The n-th Thing Any Easier Than Learning The First?  
Author: Sebastian Thrun 
Keyword: World Wide Web: http://www.cs.cmu.edu/~thrun  
Address: Pittsburgh, PA 15213-3891  
Affiliation: Computer Science Department Carnegie Mellon University  
Abstract: This paper investigates learning in a lifelong context. Lifelong learning addresses situations in which a learner faces a whole stream of learning tasks. Such scenarios provide the opportunity to transfer knowledge across multiple learning tasks, in order to generalize more accurately from less training data. In this paper, several different approaches to lifelong learning are described, and applied in an object recognition domain. It is shown that across the board, lifelong learning approaches generalize consistently more accurately from less training data, by their ability to transfer knowledge across learning tasks.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. S. Abu-Mostafa. </author> <title> Learning from hints in neural networks. </title> <journal> Journal of Complexity, </journal> <volume> 6 </volume> <pages> 192-198, </pages> <year> 1990. </year>
Reference-contexts: This approach learns a function d : I fi I ! <ref> [0; 1] </ref> which accepts two input patterns, say x and x 0 , and outputs whether x and x 0 are members of the same concept, regardless what the concept is. <p> This approach does not employ the support sets, hence is unable to transfer knowledge across learning tasks. 3.2 Learning With Hints Learning with hints <ref> [1, 4, 6, 16] </ref> constructs a neural network with n output units, one for each function f k (k = 1; 2; : : :; n). This network is then trained to simultaneously minimize the error on both the support sets fX k g and the training set X. <p> EBNN trains an artificial neural network, denoted by h : I ! <ref> [0; 1] </ref>, just like Back-Propagation. However, in addition to the target values given by the training set X, EBNN estimates the slopes (tangents) of the target function f n for each example in X. <p> The third term, the slope r x f n (x), is estimated using the learned distance function d described above. Suppose hx 0 ; y 0 = 1i 2 X is a (positive) training example. Then, the function d x 0 : I ! <ref> [0; 1] </ref> with d x 0 (z) := d (z; x 0 ) maps a single input pattern to [0; 1], and is an approximation to f n . <p> Suppose hx 0 ; y 0 = 1i 2 X is a (positive) training example. Then, the function d x 0 : I ! <ref> [0; 1] </ref> with d x 0 (z) := d (z; x 0 ) maps a single input pattern to [0; 1], and is an approximation to f n . Since d (z; x 0 ) is represented by a neural network and neural networks are differentiable, the gradient @d x 0 (z)=@z is an estimate of the slope of f n at z.
Reference: [2] <author> W.-K. Ahn and W. F. Brewer. </author> <title> Psychological studies of explanation-based learning. </title> <editor> In G. DeJong, editor, </editor> <title> Investigating Explanation-Based Learning. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston/Dordrecht/London, </address> <year> 1993. </year>
Reference-contexts: Psychological studies have shown that humans often employ more than just the training data for generalization. They are often able to generalize correctly even from a single training example <ref> [2, 10] </ref>. One of the key aspects of the learning problem faced by humans, which differs from the vast majority of problems studied in the field of neural network learning, is the fact that humans encounter a whole stream of learning problems over their entire lifetime. <p> In all these domains, it has consistently been found to generalize better from less training data by transferring knowledge from previous learning tasks. The results are also consistent with observations made about human learning <ref> [2, 10] </ref>, namely that previously learned knowledge plays an important role in generalization, particularly when training data is scarce. [18] extends these techniques to situations where most support sets are not related.w However, lifelong learning rests on the assumption that more than a single task is to be learned, and that
Reference: [3] <author> C. A. Atkeson. </author> <title> Using locally weighted regression for robot learning. </title> <booktitle> In Proceedings of the 1991 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 958-962, </pages> <address> Sacramento, CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: Assuming that the learned representation is appropriate for new learning tasks, standard memory-based learning can be applied using this new representation when learning the n-th concept. 2.3 Learning A Distance Function An alternative way for exploiting support sets to improve memory-based learning is to learn a distance function <ref> [3, 9] </ref>. This approach learns a function d : I fi I ! [0; 1] which accepts two input patterns, say x and x 0 , and outputs whether x and x 0 are members of the same concept, regardless what the concept is.
Reference: [4] <author> J. Baxter. </author> <title> Learning internal representations. </title> <booktitle> In Proceedings of the Conference on Computation Learning Theory, </booktitle> <year> 1995. </year>
Reference-contexts: This approach does not employ the support sets, hence is unable to transfer knowledge across learning tasks. 3.2 Learning With Hints Learning with hints <ref> [1, 4, 6, 16] </ref> constructs a neural network with n output units, one for each function f k (k = 1; 2; : : :; n). This network is then trained to simultaneously minimize the error on both the support sets fX k g and the training set X.
Reference: [5] <author> D. Beymer and T. Poggio. </author> <title> Face recognition from one model view. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <year> 1995. </year>
Reference-contexts: Each X k contains training examples that characterize f k . Since this additional data is desired to support learning f n , X k is called a support set for the training set X. An example of the above is the recognition of faces <ref> [5, 7] </ref>. When learning to recognize the n-th person, say f Bob , the learner is given a set of positive and negative example of face images of this person.
Reference: [6] <author> R. Caruana. </author> <title> Multitask learning: A knowledge-based of source of inductive bias. </title> <editor> In P. E. Utgoff, editor, </editor> <booktitle> Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <pages> pages 41-48, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This approach does not employ the support sets, hence is unable to transfer knowledge across learning tasks. 3.2 Learning With Hints Learning with hints <ref> [1, 4, 6, 16] </ref> constructs a neural network with n output units, one for each function f k (k = 1; 2; : : :; n). This network is then trained to simultaneously minimize the error on both the support sets fX k g and the training set X.
Reference: [7] <author> M. Lando and S. Edelman. </author> <title> Generalizing from a single view in face recognition. </title> <type> Technical Report CS-TR 95-02, </type> <institution> Department of Applied Mathematics and Computer Science, The Weizmann Institute of Science, Rehovot 76100, Israel, </institution> <month> January </month> <year> 1995. </year>
Reference-contexts: Each X k contains training examples that characterize f k . Since this additional data is desired to support learning f n , X k is called a support set for the training set X. An example of the above is the recognition of faces <ref> [5, 7] </ref>. When learning to recognize the n-th person, say f Bob , the learner is given a set of positive and negative example of face images of this person.
Reference: [8] <author> T. M. Mitchell and S. Thrun. </author> <title> Explanation-based neural network learning for robot control. </title> <editor> In S. J. Hanson, J. Cowan, and C. L. Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <pages> pages 287-294, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: f k (k = 1; 2; : : : ; n), the support sets provide additional training examples for the internal representation. 3.3 Explanation-Based Neural Network Learning The last method described here uses the explanation-based neural network learning algorithm (EBNN), which was originally proposed in the context of reinforcement learning <ref> [8, 17] </ref>. EBNN trains an artificial neural network, denoted by h : I ! [0; 1], just like Back-Propagation. However, in addition to the target values given by the training set X, EBNN estimates the slopes (tangents) of the target function f n for each example in X.
Reference: [9] <author> A. W. Moore, D. J. Hill, and M. P. Johnson. </author> <title> An Empirical Investigation of Brute Force to choose Features, Smoothers and Function Approximators. </title> <editor> In S. Hanson, S. Judd, and T. Petsche, editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> Volume 3. </volume> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Assuming that the learned representation is appropriate for new learning tasks, standard memory-based learning can be applied using this new representation when learning the n-th concept. 2.3 Learning A Distance Function An alternative way for exploiting support sets to improve memory-based learning is to learn a distance function <ref> [3, 9] </ref>. This approach learns a function d : I fi I ! [0; 1] which accepts two input patterns, say x and x 0 , and outputs whether x and x 0 are members of the same concept, regardless what the concept is.
Reference: [10] <author> Y. Moses, S. Ullman, and S. Edelman. </author> <title> Generalization across changes in illumination and viewing position in upright and inverted faces. </title> <type> Technical Report CS-TR 93-14, </type> <institution> Department of Applied Mathematics and Computer Science, The Weizmann Institute of Science, Rehovot 76100, Israel, </institution> <year> 1993. </year>
Reference-contexts: Psychological studies have shown that humans often employ more than just the training data for generalization. They are often able to generalize correctly even from a single training example <ref> [2, 10] </ref>. One of the key aspects of the learning problem faced by humans, which differs from the vast majority of problems studied in the field of neural network learning, is the fact that humans encounter a whole stream of learning problems over their entire lifetime. <p> In all these domains, it has consistently been found to generalize better from less training data by transferring knowledge from previous learning tasks. The results are also consistent with observations made about human learning <ref> [2, 10] </ref>, namely that previously learned knowledge plays an important role in generalization, particularly when training data is scarce. [18] extends these techniques to situations where most support sets are not related.w However, lifelong learning rests on the assumption that more than a single task is to be learned, and that
Reference: [11] <author> J. O'Sullivan, T. M. Mitchell, and S. Thrun. </author> <title> Explanation-based neural network learning from mobile robot perception. </title> <editor> In K. Ikeuchi and M. Veloso, editors, </editor> <title> Symbolic Visual Learning. </title> <publisher> Oxford University Press, </publisher> <year> 1995. </year>
Reference-contexts: It is consistently found that lifelong learning algorithms generalize significantly more accurately, particularly when training data is scarce. Notice that these results are well in tune with other results obtained by the author. One of the approaches here, EBNN, has extensively been studied in the context of robot perception <ref> [11] </ref>, reinforcement learning for robot control, and chess [17]. In all these domains, it has consistently been found to generalize better from less training data by transferring knowledge from previous learning tasks.
Reference: [12] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing. </booktitle> <volume> Vol. I + II. </volume> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: In our implementation, g is realized by a neural network and trained using the Back-Propagation algorithm <ref> [12] </ref>. Notice that the new representation, g, is obtained through the support sets.
Reference: [13] <author> D. Shepard. </author> <title> A two-dimensional interpolation function for irregularly spaced data. </title> <booktitle> In 23rd National Conference ACM, </booktitle> <pages> pages 517-523, </pages> <year> 1968. </year>
Reference-contexts: It then returns the mean output value 1 K y i of these nearest neighbors. Another commonly used method, which is due to Shepard <ref> [13] </ref>, averages the output values of all training examples but weights each example according to the inverse distance to the query point x. s (x) := @ hx i ;y i i2X jjx x i jj + " A @ hx i ;y i i2X jjx x i jj + "
Reference: [14] <author> P. Simard, B. Victorri, Y. LeCun, and J. Denker. </author> <title> Tangent prop a formalism for specifying selected invariances in an adaptive network. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 895-903, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: More specifically, training examples in EBNN are of the sort hx; f n (x); r x f n (x)i, which are fit using the Tangent-Prop algorithm <ref> [14] </ref>. The input x and target value f n (x) are taken from the training set X. The third term, the slope r x f n (x), is estimated using the learned distance function d described above.
Reference: [15] <author> C. Stanfill and D. Waltz. </author> <title> Towards memory-based reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1213-1228, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: We will first sketch two simple, well-known approaches to memory-based learning, then propose extensions that take the support sets into account. 2.1 Nearest Neighbor and Shepard's Method Probably the most widely used memory-based learning algorithm is K-nearest neighbor (KNN) <ref> [15] </ref>. Suppose x is a query pattern, for which we would like to know the output y.
Reference: [16] <author> S. C. Suddarth and A. Holden. </author> <title> Symbolic neural systems and the use of hints for developing complex systems. </title> <journal> International Journal of Machine Studies, </journal> <volume> 35, </volume> <year> 1991. </year>
Reference-contexts: This approach does not employ the support sets, hence is unable to transfer knowledge across learning tasks. 3.2 Learning With Hints Learning with hints <ref> [1, 4, 6, 16] </ref> constructs a neural network with n output units, one for each function f k (k = 1; 2; : : :; n). This network is then trained to simultaneously minimize the error on both the support sets fX k g and the training set X.
Reference: [17] <author> S. Thrun. </author> <title> Explanation-Based Neural Network Learning: A Lifelong Learning Approach. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1996. </year> <note> to appear. </note>
Reference-contexts: f k (k = 1; 2; : : : ; n), the support sets provide additional training examples for the internal representation. 3.3 Explanation-Based Neural Network Learning The last method described here uses the explanation-based neural network learning algorithm (EBNN), which was originally proposed in the context of reinforcement learning <ref> [8, 17] </ref>. EBNN trains an artificial neural network, denoted by h : I ! [0; 1], just like Back-Propagation. However, in addition to the target values given by the training set X, EBNN estimates the slopes (tangents) of the target function f n for each example in X. <p> EBNN relies on the assumption that d is accurate enough to yield helpful sensitivity information. However, since EBNN fits both training patterns (values) and slopes, misleading slopes can be overridden by training examples. See <ref> [17] </ref> for a more detailed description of EBNN and further references. 4 Experimental Results All approaches were tested using a database of color camera images of different objects (see Fig. 3.3). Each of the object in the database has a distinct color or size. <p> Notice that these results are well in tune with other results obtained by the author. One of the approaches here, EBNN, has extensively been studied in the context of robot perception [11], reinforcement learning for robot control, and chess <ref> [17] </ref>. In all these domains, it has consistently been found to generalize better from less training data by transferring knowledge from previous learning tasks.
Reference: [18] <author> S. Thrun and J. O'Sullivan. </author> <title> Clustering learning tasks and the selective cross-task transfer of knowledge. </title> <type> Technical Report CMU-CS-95-209, </type> <institution> Carnegie Mellon University, School of Computer Science, </institution> <address> Pittsburgh, PA 15213, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: The results are also consistent with observations made about human learning [2, 10], namely that previously learned knowledge plays an important role in generalization, particularly when training data is scarce. <ref> [18] </ref> extends these techniques to situations where most support sets are not related.w However, lifelong learning rests on the assumption that more than a single task is to be learned, and that learning tasks are appropriately related.
References-found: 18

