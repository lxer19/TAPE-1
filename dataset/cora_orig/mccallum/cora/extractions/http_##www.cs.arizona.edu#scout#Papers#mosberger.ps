URL: http://www.cs.arizona.edu/scout/Papers/mosberger.ps
Refering-URL: http://www.cs.arizona.edu/scout/publications.html
Root-URL: http://www.cs.arizona.edu
Title: SCOUT: A PATH-BASED OPERATING SYSTEM  
Author: by David Mosberger 
Degree: A Dissertation Submitted to the Faculty of the DEPARTMENT OF COMPUTER SCIENCE In Partial Fulfillment of the Requirements For the Degree of DOCTOR OF PHILOSOPHY In the Graduate College  
Affiliation: THE UNIVERSITY OF ARIZONA  
Date: 1997  1 9 9 7  
Note: Copyright c David Mosberger  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Mark B. Abbott and Larry L. Peterson. </author> <title> Increasing network throughput by integrating protocol layers. </title> <journal> IEEE Transactions on Networking, </journal> <volume> 1(5):600610, </volume> <month> Octo-ber </month> <year> 1993. </year>
Reference-contexts: The results reported in [85] indicate speedups in the range from 1.12 to 3.61 for the UNIX read system-call compared to the regular HP-UX version. 24 1.4.1.2 Integrated Layer Processing The fundamental observation behind Integrated Layer Processing (ILP) <ref> [16, 1] </ref> is that as a network packet passes through various protocol processing steps, its data may be traversed multiple times. <p> A system that uses ILP collapses all data processing into a single loop. That is, the data is brought into the CPU only once, thus greatly improving the efficiency of the memory system. Indeed, Abbott and Peterson <ref> [1] </ref> report communication bandwidth improvements in the range of 10 to 30% due to ILP. 1.4.1.3 PathIDs PathIDs [56] is a mechanism that allows substituting the implementation of a specific network protocol stack with hand-optimized, vertically integrated code. <p> The path model can trivially support this kind of application since the sequence of modules being traversed is known and fixed for the lifetime of a path. A combination of the language-based ILP approach presented by Abbott and Peterson <ref> [1] </ref> and paths should therefore enable making ILP a truly practical technique. 55 2.4.1.3 PathIDs The PathID approach (see Section 1.4.1.3) consists of a combination of two techniques: a mechanism to efficiently find the path for a network packet and a highly sophisticated partial evaluatornamely a human being. <p> Examples of code, or fast-path optimizations include Synthesis [60], Synthetix [85], PathIDs [56], Protocol Accelerators [107], and integrated layer processing <ref> [16, 1] </ref>. Examples in the second category include processor capacity reserves [64], distributed/migrating threads [19, 37], and Rialto activities [52]. These related works do not attempt to define an explicit and universal path abstraction, but are a source of interesting examples of how paths can be employed. <p> In particular, if n paths exist in the system, it is not guaranteed that the path id is in the range 0::n 1. 76 The stages at the extreme ends of the path are pointed to by end [0] and end <ref> [1] </ref>. For an unextended path, end [0] refers to the stage created first, whereas end [1] refers to the stage created last. <p> in the system, it is not guaranteed that the path id is in the range 0::n 1. 76 The stages at the extreme ends of the path are pointed to by end [0] and end <ref> [1] </ref>. For an unextended path, end [0] refers to the stage created first, whereas end [1] refers to the stage created last. If a path is extended at the end pointed to by end [0], then, once path extension is complete, end [0] will point to the last stage created during extension. The corresponding applies for path extension applied to end [1]. <p> created first, whereas end <ref> [1] </ref> refers to the stage created last. If a path is extended at the end pointed to by end [0], then, once path extension is complete, end [0] will point to the last stage created during extension. The corresponding applies for path extension applied to end [1]. In other words, end [0] and end [1] are guaranteed to point to the stages at the opposing ends of the pathwhich expression points to which end is, in general, difficult to say. <p> If a path is extended at the end pointed to by end [0], then, once path extension is complete, end [0] will point to the last stage created during extension. The corresponding applies for path extension applied to end <ref> [1] </ref>. In other words, end [0] and end [1] are guaranteed to point to the stages at the opposing ends of the pathwhich expression points to which end is, in general, difficult to say. <p> The mapping between the queue index and the function of the queue is given in the following table: expression functions as. . . in direction. . . q [0] source forward (end [0]!end <ref> [1] </ref>) q [1] sink forward (end [0]!end [1]) q [2] source backward (end [1]!end [0]) q [3] sink backward (end [1]!end [0]) To leave the stages flexibility in choosing the implementation for each path queue, only two queue operations are globally defined: one to determine the maximum length of the queue <p> The mapping between the queue index and the function of the queue is given in the following table: expression functions as. . . in direction. . . q [0] source forward (end [0]!end <ref> [1] </ref>) q [1] sink forward (end [0]!end [1]) q [2] source backward (end [1]!end [0]) q [3] sink backward (end [1]!end [0]) To leave the stages flexibility in choosing the implementation for each path queue, only two queue operations are globally defined: one to determine the maximum length of the queue and another <p> The mapping between the queue index and the function of the queue is given in the following table: expression functions as. . . in direction. . . q [0] source forward (end [0]!end <ref> [1] </ref>) q [1] sink forward (end [0]!end [1]) q [2] source backward (end [1]!end [0]) q [3] sink backward (end [1]!end [0]) To leave the stages flexibility in choosing the implementation for each path queue, only two queue operations are globally defined: one to determine the maximum length of the queue and another to determine the current length <p> Expression iface [0] refers to the interface on the side of the stage through which the creation request for this path arrived (see Section 3.3.6). For an unextended path, this is equivalent to the interface in the forward direction of the path. Expression iface <ref> [1] </ref> refers to the other interface in the stage. For an unextended path, this is equivalent to the interface in the backward direction of the path. <p> The prototype for this function is shown below: long pathExtend (Stage s, Attrs a); The first argument, stage s, points to the end of the path that should be extended. If path p is being extended, this must be either p-&gt;end [0] or p-&gt;end <ref> [1] </ref>. If s points to any other stage, path extension will fail. The second argument, attribute set a, is the set of invariants that are true for the path extension operation. <p> pn) f 3 dk = concat (pn, k); 4 n = hashLookup (h, dk); 5 if (!n) f 6 n = new (DemuxNode); 7 n-&gt;numPaths = 0; 8 n-&gt;path = NULL; 9 n-&gt;nextModule = next module in path; 10 hashEnter (h, dk, n); 11 g 12 if (s == s-&gt;path->end <ref> [1] </ref>) 13 n-&gt;path = s-&gt;path; 14 else if (pn) 15 n-&gt;path = pn-&gt;path; 16 ++n-&gt;numPaths; 17 g of the previous demux node with those for the partial key k. <p> TCP/IP RPC [%] [s] [s] <ref> [1] </ref> [1] [%] [s] [s] [1] [1] STD!OUT 114 7.4 5.5 103 0 71 4.6 4.1 66 0 OUT! PIN 70 9.5 14.2 168 0 67 27.3 23.3 341 0 Table 4.6: Comparison of Latency Improvement Table 4.6 lists this percentage for both the TCP/IP and RPC protocol stack in the <p> TCP/IP RPC [%] [s] [s] <ref> [1] </ref> [1] [%] [s] [s] [1] [1] STD!OUT 114 7.4 5.5 103 0 71 4.6 4.1 66 0 OUT! PIN 70 9.5 14.2 168 0 67 27.3 23.3 341 0 Table 4.6: Comparison of Latency Improvement Table 4.6 lists this percentage for both the TCP/IP and RPC protocol stack in the respective <p> TCP/IP RPC [%] [s] [s] <ref> [1] </ref> [1] [%] [s] [s] [1] [1] STD!OUT 114 7.4 5.5 103 0 71 4.6 4.1 66 0 OUT! PIN 70 9.5 14.2 168 0 67 27.3 23.3 341 0 Table 4.6: Comparison of Latency Improvement Table 4.6 lists this percentage for both the TCP/IP and RPC protocol stack in the respective columns labelled I. <p> TCP/IP RPC [%] [s] [s] <ref> [1] </ref> [1] [%] [s] [s] [1] [1] STD!OUT 114 7.4 5.5 103 0 71 4.6 4.1 66 0 OUT! PIN 70 9.5 14.2 168 0 67 27.3 23.3 341 0 Table 4.6: Comparison of Latency Improvement Table 4.6 lists this percentage for both the TCP/IP and RPC protocol stack in the respective columns labelled I.
Reference: [2] <author> Mark Bert Abbott. </author> <title> A Language-Based Approach to Protocol Implementation. </title> <type> PhD thesis, </type> <institution> Department of Computer Science, University of Arizona, </institution> <address> Tucson, AZ 85721, </address> <year> 1993. </year>
Reference-contexts: The systems research community has long harbored an intuitive notion of what a path is. For example, it often refers to the fast path through a system <ref> [85, 73, 2, 112] </ref>, implying that the most commonly executed sequence of instructions have been optimized. <p> In addition to the members shown, the Scout path object contains state that assists the creation, extension and destruction of paths. That state has been omitted since it is not relevant to the discussions presented here. typedef struct Path f long pid; Stage end <ref> [2] </ref>; PathQueue q [4]; struct Attrs attrs; bool realtime; u long prio; g * Path; Every path has a unique integer associated that is called the path id. This id is stored in member pid, and permits accounting resources on a per-path basis. <p> The mapping between the queue index and the function of the queue is given in the following table: expression functions as. . . in direction. . . q [0] source forward (end [0]!end [1]) q [1] sink forward (end [0]!end [1]) q <ref> [2] </ref> source backward (end [1]!end [0]) q [3] sink backward (end [1]!end [0]) To leave the stages flexibility in choosing the implementation for each path queue, only two queue operations are globally defined: one to determine the maximum length of the queue and another to determine the current length of the <p> For this case, all dynamic routing decisions can be avoided. The C structure that implements the stage object in Scout is shown below: typedef struct Stage f Iface iface <ref> [2] </ref>; Path path; Module module; long (*establish)(Stage s, Attrs a); void (*destroy)(Stage s); Stage nextStage; g * Stage; 78 The elements of array iface are pointers to the interfaces in the stage. If such an interface does not exist, the corresponding element is NULL.
Reference: [3] <author> AMD. Am7990: </author> <title> Local Area Network Controller for Ethernet. </title>
Reference-contexts: The mapping between the queue index and the function of the queue is given in the following table: expression functions as. . . in direction. . . q [0] source forward (end [0]!end [1]) q [1] sink forward (end [0]!end [1]) q [2] source backward (end [1]!end [0]) q <ref> [3] </ref> sink backward (end [1]!end [0]) To leave the stages flexibility in choosing the implementation for each path queue, only two queue operations are globally defined: one to determine the maximum length of the queue and another to determine the current length of the queue. <p> While end-to-end latency improvements are certainly respectable, they are nevertheless fractional on the given test system. It is important to keep in mind, however, that modern high-performance network adapters have much lower latency than the LANCE Ethernet adapter present in the DEC 3000 system <ref> [3] </ref>. To put this into perspective, consider that a minimum-sized Ethernet packet is 64 bytes long, to which an 8 byte long preamble is added. At the speed of a 10Mbps Ethernet, transmitting the frame takes 57.6s.
Reference: [4] <author> Ken Arnold and James Gosling. </author> <title> The Java Programming Language. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1996. </year> <note> ISBN 0-201-63455-4. </note>
Reference-contexts: Doing so makes it possible to employ light-weight protection techniques such as software fault-isolation (SFI) or type-safe languages such as Modula-3, Java, or Limbo when protection is all that is desired <ref> [109, 7, 4, 102] </ref>. As appliances are likely to be realized in a single address space, the distinction be 21 tween application and operating system becomes fuzzy. There is nothing wrong with this. <p> In addition to the members shown, the Scout path object contains state that assists the creation, extension and destruction of paths. That state has been omitted since it is not relevant to the discussions presented here. typedef struct Path f long pid; Stage end [2]; PathQueue q <ref> [4] </ref>; struct Attrs attrs; bool realtime; u long prio; g * Path; Every path has a unique integer associated that is called the path id. This id is stored in member pid, and permits accounting resources on a per-path basis.
Reference: [5] <author> Mary L. Bailey, Burra Gopal, Michael A. Pagels, Larry L. Peterson, and Prasenjit Sarkar. PathFinder: </author> <title> A pattern-based packet classifier. </title> <booktitle> In Proceedings of the First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 115 123, </pages> <address> Monterey, CA, 1994. ACM/USENIX. ftp://ftp.cs.arizona.edu/xkernel/Papers/pathfinder.ps. </address>
Reference-contexts: The two classifiers with the best published performance are DPF [30] and PathFinder <ref> [5] </ref>. Unfortunately, the existing implementation of PathFinder is not 64-bit clean and even on 32-bit systems there appear to be problems that prevent it from working reliably. For this reason, the remainder of this discussion is limited to a comparison with DPF. <p> The performance of DPF, a classifier that uses runtime code generation [30] has been reported to be impressive, but unfortunately makes it relatively slow to insert and remove existing filters or, as is the case for version 2.0, provides a language with limited expressiveness. The PathFinder classifier <ref> [5] </ref> also has competitive performance, but it is a rather complex engine which would make it less suitable for appliances with stringent memory requirements. A practical problem common to all but the Scout classifier is that they require writing the classifier predicates in a special language.
Reference: [6] <author> David Banks and Mike Prudence. </author> <title> A high performance network architecture for a PA-RISC workstation. </title> <journal> IEEE Journal on Selected Areas in Communication, </journal> <volume> 11(2):191202, </volume> <month> February </month> <year> 1993. </year>
Reference-contexts: That is, a large fraction of the 578s of the optimized time is due to fixed costs such as time on the wire and sender-side processing. In this light, a 23 percent improvement is very significant. 1.4.1.4 Single-Copy TCP/IP Banks and Prudence <ref> [6] </ref> present what amounts to a vertically integrated networking stack. The stack under consideration was a typical UNIX networking stack consisting of a 25 socket-layer, TCP and IP layers [83, 82], and a network driver layer.
Reference: [7] <author> Brian N. Bershad, Stefan Savage, Przemyslaw Pardyak, Emin Gun Sirer, Marc E. Fiuczynski, David Becker, Craig Chambers, and Susan J. Eggers. </author> <title> Extensibility, safety and performance in the SPIN operating system. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 267284, </pages> <address> Copper Mountain Resort, CO, </address> <month> December </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Doing so makes it possible to employ light-weight protection techniques such as software fault-isolation (SFI) or type-safe languages such as Modula-3, Java, or Limbo when protection is all that is desired <ref> [109, 7, 4, 102] </ref>. As appliances are likely to be realized in a single address space, the distinction be 21 tween application and operating system becomes fuzzy. There is nothing wrong with this. <p> In academia, much of the current OS research focuses on run-time extensibility of operating system kernels. Examples in this area include the Exokernel [32], FLUX [36], SPIN <ref> [7] </ref>, and VINO [92]. In contrast, Scout is targeted at communication-oriented information appliances where the need for dynamic extensibility of kernel software is less of an issue. This is because many appliances are expected to be of relatively static nature.
Reference: [8] <author> Edoardo Biagioni. </author> <title> A structured TCP in standard ML. </title> <booktitle> In Proceedings of SIG-COMM '94 Symposium, </booktitle> <pages> pages 3645, </pages> <address> London, England, </address> <note> August 31stSeptember 2nd 1994. ACM. http://www-cgi.cs.cmu.edu/afs/cs/project/fox/mosaic/papers/sigcomm94.ps. </note>
Reference-contexts: The biggest disadvantage of using C is likely to be found not in convenience-of-use issues, but in suitability for optimization. For example, high level functional languages such as SML are more amenable to aggressive optimization than C <ref> [8] </ref>. But the high level of abstraction that enables these aggressive optimizations is also the reason that makes such languages difficult to compile into code as efficient as C.
Reference: [9] <author> Joel Birnbaum. </author> <title> How the coming digital utility may reshape computing and telecommunications, </title> <month> October </month> <year> 1996. </year> <note> http://www.hpl.hp.com/management/speeches/ieee.htm. 165 </note>
Reference-contexts: Nevertheless, it is not unimaginable that the market penetration of information appliances will reach such a magnitude that, relatively speaking, traditional computer systems may look like niche products. Another aspect that refines the realm of appliances is ease-of-use. To paraphrase Joel Birnbaum <ref> [9] </ref>: just like automobiles, telephones, or television sets, information appliances are more noticeable by their absence than their presence.
Reference: [10] <author> Trevor Blackwell. </author> <title> Speeding up protocols for small messages. </title> <booktitle> In Proceedings of SIGCOMM '96 Symposium, </booktitle> <pages> pages 8595, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year> <note> ACM. http://www.acm.org/sigcomm/sigcomm96/papers/blackwell.html. </note>
Reference-contexts: Path affinity might, for example, make sense in an environment where the cost of bringing a path's code into the caches is high relative to the cost of bringing the data into the caches <ref> [10] </ref>. 101 If the costs are reversed, then letting a thread move a message as far as possible is likely to result in better performance [16].
Reference: [11] <author> R. Braden, D. Clark, and S. Shenker. </author> <title> Integrated Services in the Internet Architecture: an Overview. </title> <booktitle> DARPA, </booktitle> <month> June </month> <year> 1994. </year> <note> http://ds.internic.net/rfc/rfc1633.txt. </note>
Reference-contexts: Hence, a feedback based algorithm is likely too slow to be practical. In effect, this means that automatic control of this parameter requires either distributed paths or a network resource reservation protocol such as RSVP <ref> [11] </ref> (or a combination of both). For these reasons, Scout currently leaves this parameter under user control. 5.2.2 Scheduling To guarantee proper scheduling, two properties must be satisfied. First, the system must always execute the highest-priority runnable path. In other words, priority inversion must be avoided. <p> Distributed paths are particularly important when operating in a wide-area network where network bandwidth and latency are often the limiting factors to overall performance. Distributed paths are likely to be realizable on top of existing Scout paths and corresponding network concepts, such as flows <ref> [11] </ref>. The more interesting questions relate to how path creation should be controlled in a distributed environment. For example, the source and destination machines may want to coordinate the values for certain path invariants (e.g., maximum packet size or throughput may depend on the network connection being used).
Reference: [12] <author> Pei Cao, Edward W. Felten, and Kai Li. </author> <title> Implementation and performance of application-controlled file caching. </title> <booktitle> In Proceedings of the First Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 165177, </pages> <address> Monterey, CA, 1994. ACM/USENIX. ftp://ftp.cs.princeton.edu/pub/people/pc/OSDI94/paper.ps.Z. </address>
Reference-contexts: For example, it might be useful to associate one of the data access patterns identified by Cao et al. <ref> [12] </ref> with each path that traverses the disk subsystem. The access pattern of a path could be used by the modules in the disk subsystem to select an appropriate caching policy. Also, code-optimization tech 161 niques could be used to improve the performance of small reads or writes [85].
Reference: [13] <author> L. Cardelli, J. Donahue, L. Glassman, M. Jordan, B. Kalsow, and G. Nelson. </author> <title> Modula-3 language definition. </title> <journal> SIGPLAN Notices, </journal> <volume> 27(8):1542, </volume> <month> August </month> <year> 1992. </year>
Reference-contexts: Indeed, the techniques developed by these research projects are applicable to Scout insofar that they are orthogonal to the modular structure and path abstraction around which Scout is centered. For example, Scout and its path abstraction could readily be implemented in a type safe language such as Modula-3 <ref> [13] </ref> or it could employ sandboxing [109] to ensure the safe execution of dynamically loaded native-code modules. In industry, there is a wealth of operating systems that are increasingly targeted at network computers (NCs) which could be considered a form of information appliances.
Reference: [14] <author> C. Castelluccia, W. Dabbous, and S. O'Malley. </author> <title> Generating efficient protocol code from an abstract specification. </title> <booktitle> In Proceedings of SIGCOMM '96 Symposium, </booktitle> <pages> pages 6071, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year> <note> http://www.acm.org/sigcomm/sigcomm96/papers/castelluccia.html. </note>
Reference-contexts: It is important, however, to keep in mind that the approach taken in this case study is by no means the only way paths can be exploited to improve execution speed of a system. Dynamic code generation [60], manually crafted vertically integrated code-paths [56, 23], or a language-based approach <ref> [14] </ref> represent a few other possibilities in this spectrum. The case study proposes and analyzes four techniques targeted at improving protocol processing.
Reference: [15] <author> Chran-Ham Chang, Richard Flower, John Forecast, Heather Gray, William R. Hawe, K. K. Ramakrishnan, Ashok P. Nadkarni, Uttam N. Shikarpur, and Kath-leen M. Wilde. </author> <title> High-performance TCP/IP and UDP/IP networking in DEC OSF/1 for Alpha AXP. </title> <journal> Digital Technical Journal, </journal> <volume> 5(1):4461, </volume> <month> Winter </month> <year> 1993. </year>
Reference-contexts: For example, it often refers to the fast path through a system [85, 73, 2, 112], implying that the most commonly executed sequence of instructions have been optimized. As another example, it sometimes talks about optimizing the end-to-end path <ref> [17, 15] </ref> meaning the focus is on the global performance of the system (e.g., from I/O source to sink), rather than on the local performance of a single component.
Reference: [16] <author> David Clark and David Tennenhouse. </author> <title> Architectural considerations for a new generation of protocols. </title> <booktitle> In Proceedings of SIGCOMM '90 Symposium, </booktitle> <pages> pages 200 208, </pages> <address> Philadelphia, PA, </address> <month> September </month> <year> 1990. </year> <note> ACM. </note>
Reference-contexts: The results reported in [85] indicate speedups in the range from 1.12 to 3.61 for the UNIX read system-call compared to the regular HP-UX version. 24 1.4.1.2 Integrated Layer Processing The fundamental observation behind Integrated Layer Processing (ILP) <ref> [16, 1] </ref> is that as a network packet passes through various protocol processing steps, its data may be traversed multiple times. <p> Since video-display is a soft realtime application, proper resource management (in particular proper CPU scheduling) is essential. Using paths and application-level framing 31 <ref> [16] </ref>, the Scout appliance is able to run multiple video streams and non-realtime background loads all without causing unnecessary interference. <p> Examples of code, or fast-path optimizations include Synthesis [60], Synthetix [85], PathIDs [56], Protocol Accelerators [107], and integrated layer processing <ref> [16, 1] </ref>. Examples in the second category include processor capacity reserves [64], distributed/migrating threads [19, 37], and Rialto activities [52]. These related works do not attempt to define an explicit and universal path abstraction, but are a source of interesting examples of how paths can be employed. <p> environment where the cost of bringing a path's code into the caches is high relative to the cost of bringing the data into the caches [10]. 101 If the costs are reversed, then letting a thread move a message as far as possible is likely to result in better performance <ref> [16] </ref>. Rather than based on cache costs, the decision of whether a thread should continue executing in the old path or should move on to the next path may depend on path priority. <p> MPEG expects the compressed video messages to contain an integral number of MPEG macroblocks. The number of macroblocks per message is expected to be small enough so that the message size does not exceed the maximum transmission unit (MTU) of the network link. This kind of application-level framing (ALF) <ref> [16] </ref> ensures that the MPEG decoder does not reach the end of the message in the middle of a complex operation. This simplifies the MPEG decoder, reduces queuing inside video paths, minimizes the number of context switches required to process a message, enables integrated layer processing [16], and enables early load <p> of application-level framing (ALF) <ref> [16] </ref> ensures that the MPEG decoder does not reach the end of the message in the middle of a complex operation. This simplifies the MPEG decoder, reduces queuing inside video paths, minimizes the number of context switches required to process a message, enables integrated layer processing [16], and enables early load shedding, as will be explained later. Another aspect of the module graph that may not be entirely obvious is that STDIO is connected to TERM by three separate arcs.
Reference: [17] <author> David D. Clark. </author> <title> The design philosophy of the DARPA Internet protocols. </title> <booktitle> In Proceedings of SIGCOMM '88 Symposium, </booktitle> <pages> pages 106114, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1988. </year> <note> ACM. </note>
Reference-contexts: For example, it often refers to the fast path through a system [85, 73, 2, 112], implying that the most commonly executed sequence of instructions have been optimized. As another example, it sometimes talks about optimizing the end-to-end path <ref> [17, 15] </ref> meaning the focus is on the global performance of the system (e.g., from I/O source to sink), rather than on the local performance of a single component.
Reference: [18] <author> David D. Clark, Van Jacobson, John Romkey, and Howard Salwen. </author> <title> An analysis of TCP processing overheads. </title> <journal> IEEE Communications Magazine, </journal> <volume> 27(6):2329, </volume> <month> June </month> <year> 1989. </year>
Reference-contexts: The reason for choosing this problem is that optimizing for latency is often considered hard since, in contrast to throughput-oriented optimizations, there is rarely a single dominant latency bottleneck [55, 112]. Instead, to improve latency it is typically necessary to improve protocol processing along the entire path of execution <ref> [18, 51] </ref>. In this sense, the problem is ideally suited to demonstrate some of the potential benefits of Scout paths.
Reference: [19] <author> Raymond K. Clark, E. Douglas Jensen, and Franklin Reynolds. </author> <title> An architectural overview of the Alpha real-time distributed kernel. </title> <booktitle> In Proceedings of the USENIX Workshop on Micro-Kernels and Other Kernel Architectures, </booktitle> <pages> pages 127 146, </pages> <address> Seattle, WA, </address> <month> April </month> <year> 1992. </year> <month> 166 </month>
Reference-contexts: This technique depends on knowing the sequence of modules that will be traversed by a data-item. In addition, it requires a provision for path-specific memory allocators. Both requirements can be accommodated easily in the proposed path model. 4 2.4.2.2 Migrating/Distributed Threads Migrating (distributed) threads <ref> [19, 45, 37] </ref> address the issue of anonymity of processing that often poses problems in modular systems. Typically, when data enters a new module, information on whose behalf the data is being processed is lost. <p> Examples of code, or fast-path optimizations include Synthesis [60], Synthetix [85], PathIDs [56], Protocol Accelerators [107], and integrated layer processing [16, 1]. Examples in the second category include processor capacity reserves [64], distributed/migrating threads <ref> [19, 37] </ref>, and Rialto activities [52]. These related works do not attempt to define an explicit and universal path abstraction, but are a source of interesting examples of how paths can be employed. The work on Synthetix is also interesting in that it introduces the notion of quasi-invariants.
Reference: [20] <author> Doug Cooper. </author> <title> Standard Pascal User Reference Manual. </title> <editor> W. W. </editor> <publisher> Norton & Company, </publisher> <address> New York, NY, </address> <year> 1983. </year> <note> ISBN 0-393-30121-4. </note>
Reference-contexts: Both services are of type ByteStream. As shown in the figure, it is customary in Scout to separate the service name from its type by a colon (a convention adopted from Pascal-like languages <ref> [20] </ref>). Suppose ByteStream represents a bidirectional stream of data bytes. In this case, data sent into the plain service would be run-length encoded and sent out through the compr service. Conversely, data sent into the compr service would be run-length decoded and then passed on through the plain service.
Reference: [21] <author> Fernando J. Corbato, M. Merwin-Daggett, and Robert C. Daley. </author> <title> An experimental time-sharing system. </title> <booktitle> In Proceedings of the AFIPS Spring Joint Computer Conference, </booktitle> <pages> pages 335344, </pages> <month> May </month> <year> 1962. </year>
Reference-contexts: This improved utilization, but unfortunately also increased job completion time. In 1962, the CTSS operating system introduced time-sharing to alleviate this problem <ref> [21] </ref>. Time-sharing made it possible give short jobs higher priority than long-running batch jobs. This preserved the high utilization of batch-processing while greatly reducing the job completion time for short jobs.
Reference: [22] <author> Robert C. Daley and Jack B. Dennis. </author> <title> Virtual memory, processes, and sharing in MULTICS. </title> <journal> Communications of the ACM, </journal> <volume> 11(5):306312, </volume> <month> May </month> <year> 1968. </year>
Reference-contexts: This fundamentally changed how programmers and users perceived computer systems. The evolution of time-sharing systems culminated in the development of MULTICS, a system designed to support hundreds of simultaneous users <ref> [22] </ref>. MULTICS aimed to be everything to everybody and its extant complexity caused repeated and excessive delays. Even though it eventually shipped to a few customers, it was widely considered a commercial failure. Nevertheless, it laid the foundation for much of the operating system research of the coming thirty years.
Reference: [23] <author> Chris Dalton, Greg Watson, David Banks, Costas Calamvokis, Aled Edwards, and John Lumley. </author> <title> Afterburner. </title> <journal> IEEE Network, </journal> <volume> 7(4):3543, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: It is important, however, to keep in mind that the approach taken in this case study is by no means the only way paths can be exploited to improve execution speed of a system. Dynamic code generation [60], manually crafted vertically integrated code-paths <ref> [56, 23] </ref>, or a language-based approach [14] represent a few other possibilities in this spectrum. The case study proposes and analyzes four techniques targeted at improving protocol processing. <p> Towards this end, we collected two additional data sets. The first is a set of instruction traces that cover most of the protocol processing. The second is a set of fine-grained 3 Numbers is this range have been reported in the literature for FDDI and ATM controllers <ref> [23] </ref>. 130 measurements of the execution time of the traced code.
Reference: [24] <author> Martin D. Davis and Elaine J. Weyuker. </author> <title> Computability, Complexity, and Languages. </title> <publisher> Academic Press, </publisher> <address> London, England, </address> <year> 1983. </year> <note> ISBN 0-122-06380-5. </note>
Reference-contexts: The commonality is that in both contexts, the term means that no additional work is created inside a system itself. 50 if any, useful paths would do this. However, the fact that the path model allows for endless looping is analogous to universal (Turing-complete) programming languages <ref> [24] </ref> which must allow for the possibility of infinite looping even though most useful programs terminate in a finite amount of time. 2.3 Summary and Discussion In summary, a path is created by invoking a create operation on a module and specifying a set of invariants.
Reference: [25] <author> Sean Dorward, Rob Pike, Dave Presotto, Dennis Ritchie, Howard Trickey, and Phil Winterbottom. </author> <title> The Inferno operating system. </title> <booktitle> In Forty-Second IEEE Computer Society International Conference Proceedings, </booktitle> <pages> pages 241244, </pages> <address> San Jose, CA, </address> <month> February </month> <year> 1997. </year> <note> http://inferno.lucent.com/inferno/. </note>
Reference-contexts: The biggest issue in doing so is the security issue, not the actual dynamic loading. An alternative to extending the module graph at runtime would be to configure a virtual machine module into the graph that would allow interpreted code to be downloaded and executed inside Scout <ref> [39, 25] </ref>. 3.3 Paths This section describes how paths are realized in Scout. Scout paths closely follow the model presented in Chapter 2. <p> There appear to be three major approaches to supporting NCs: 1. virtual machine based, 2. pared-down general purpose OS, and 3. Internet-extended embedded OS. JavaOS and Inferno use the first approach <ref> [59, 25] </ref>. Both emphasize on the ability to download platform-independent virtual machine code over the network and execute it safely. The issue of supporting virtual machine code is orthogonal to the path abstraction defined by Scout. It is not difficult to add modules to Scout that support such virtual machines.
Reference: [26] <author> P. Druschel, L. L. Peterson, and B. S. Davie. </author> <title> Experiences with a high-speed network adaptor: A software perspective. </title> <booktitle> In Proceedings of SIGCOMM '94 Symposium, </booktitle> <pages> pages 213, </pages> <address> London, England, </address> <note> August 31stSeptember 2nd 1994. ACM. </note>
Reference-contexts: In some cases it may be possible to implement PathIDs using existing networking protocols. For example, ATM has a field containing a virtual circuit identifier (VCI). If VCIs can be allocated on a per-path basis, then they can be used in lieu of an additional PathID field <ref> [26] </ref>. However, PathIDs are not a general path-abstraction like the one defined by Scout. For example, they do not provide a means to generate optimized code paths automatically [56].
Reference: [27] <author> Peter Druschel, Mark B. Abbott, Michael A. Pagels, and Larry L. Peterson. </author> <title> Network subsystem design. </title> <journal> IEEE Network, </journal> <volume> 7(4):817, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: As a final example, it sometimes distinguishes between a system's control path and its data path, with the former being more relevant to latency and the latter more concerned with throughput <ref> [27, 84] </ref>. But the wide-spread use of this term has so far not been translated into a well-defined abstraction that could serve as a foundation of system design.
Reference: [28] <author> Peter Druschel and Gaurav Banga. </author> <title> Lazy receiver processing (LRP): A network subsystem architecture for server systems. </title> <booktitle> In Proceedings of the Second Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 261275, </pages> <address> Seattle, WA, </address> <month> October </month> <year> 1996. </year> <note> ACM/USENIX. http://www.cs.rice.edu/CS/Systems/LRP/osdi96.ps. </note>
Reference-contexts: Clearly, avoiding priority inversion can have significant benefits. Nevertheless, this is not to say that paths are the only way to solve this particular problem. For example, both lazy receiver processing <ref> [28] </ref> and avoiding receive livelock [68] can have similar benefits.
Reference: [29] <author> Peter Druschel and Larry L. Peterson. Fbufs: </author> <title> A high-bandwidth cross-domain transfer facility. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 189202, </pages> <address> Asheville, NC, </address> <month> December </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: The defined path model therefore is ideally suited for this kind of code-related optimizations. 2.4.2 Resource Management The second kind of benefits that the path model affords is related to improved resource management. A discussion of three applications that exploit this follows. 56 2.4.2.1 Fbufs Fbufs <ref> [29] </ref> are a path-oriented buffer management mechanism designed to efficiently move data across multiple modules that are in different protection domains. This technique depends on knowing the sequence of modules that will be traversed by a data-item. In addition, it requires a provision for path-specific memory allocators.
Reference: [30] <author> Dawson Engler and M. Frans Kaashoek. DPF: </author> <title> Fast, flexible message demulti-plexing using dynamic code generation. </title> <booktitle> In Proceedings of SIGCOMM '96 Symposium, </booktitle> <pages> pages 5359, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year> <note> ACM. http://www.acm.org/sigcomm/sigcomm96/papers/engler.html. 167 </note>
Reference-contexts: The two classifiers with the best published performance are DPF <ref> [30] </ref> and PathFinder [5]. Unfortunately, the existing implementation of PathFinder is not 64-bit clean and even on 32-bit systems there appear to be problems that prevent it from working reliably. For this reason, the remainder of this discussion is limited to a comparison with DPF. <p> For this reason, the remainder of this discussion is limited to a comparison with DPF. The available DPF implementation is version 2.0 beta, which is a re-implementation of the version presented in <ref> [30] </ref>. The measurements for this comparison were performed in a user-level test environment running on Linux on an AlphaStation 600/333. This machine uses a 21164 Alpha chip running at 333MHz. All measurements were done with warm caches. <p> Of the many packet classifiers and packet filters that have been proposed in the past, none fit the re 109 quirements of Scout perfectly. For example, interpreted packet filters are generally not fast enough [113, 61]. The performance of DPF, a classifier that uses runtime code generation <ref> [30] </ref> has been reported to be impressive, but unfortunately makes it relatively slow to insert and remove existing filters or, as is the case for version 2.0, provides a language with limited expressiveness.
Reference: [31] <author> Dawson R. Engler. </author> <title> VCODE: a retargetable, extensible, very fast dynamic code generation system. </title> <booktitle> In Proceedings of SIGPLAN '96 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 160170, </pages> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year> <note> ACM. http://www.pdos.lcs.mit.edu/engler/pldi96-abstract.html. </note>
Reference-contexts: This was measured by counting the number of bytes by which the size of test program increases when linking in one or the other classifier. In the DPF case, this includes the size of the vcode dynamic code generator, which accounts for about 74KB of the reported size <ref> [31] </ref>. The next four rows lists various performance aspects. The row labelled Lookup active path lists the time required to classify a TCP/IP packet.
Reference: [32] <author> Dawson R. Engler, Frans Kaashoek, and James O'Toole Jr. Exokernel: </author> <title> An operating system architecture for application-level resource management. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 251266, </pages> <address> Copper Mountain Resort, CO, </address> <month> December </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: In academia, much of the current OS research focuses on run-time extensibility of operating system kernels. Examples in this area include the Exokernel <ref> [32] </ref>, FLUX [36], SPIN [7], and VINO [92]. In contrast, Scout is targeted at communication-oriented information appliances where the need for dynamic extensibility of kernel software is less of an issue. This is because many appliances are expected to be of relatively static nature.
Reference: [33] <author> M. C. </author> <title> Er. Optimizing procedure calls and returns. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 13(10):921939, </volume> <month> October </month> <year> 1983. </year>
Reference-contexts: Ideally, in a calling sequence that is nested N deep, the amount of stack space used would be just the maximum frame size among the active functions instead of the sum of the frame sizes. This last call optimization is an old technique (e.g., <ref> [33] </ref>) that is popular with compilers for functional languages, but not for imperative languages such as C. The main problem with imperative languages is that it is difficult to decide whether or not a callee has access to a caller's stack frame.
Reference: [34] <author> Alan Eustace. </author> <type> Personal communication, </type> <month> October </month> <year> 1994. </year>
Reference-contexts: When executing code sequentially from the b-cache, the CPU can sustain an execution rate of 8 instructions per 13 cycles <ref> [34] </ref>. Unless noted otherwise, all software was implemented in a prototype version of Scout that was derived from the x-kernel [49]. The module graph consists of the networking subsystem and measurement code only.
Reference: [35] <author> R. Fielding, J. Gettys, J. Mogul, H. Frystyk, and T. Berners-Lee. </author> <title> Hypertext Transfer ProtocolHTTP/1.1. </title> <institution> Network Working Group, </institution> <month> January </month> <year> 1997. </year> <note> http://ds.internic.net/rfc/rfc2068.txt. </note>
Reference-contexts: In essence, this approach attempts to leverage existing application software, whereas Scout attempts to define a new paradigm that is inherently well-suited for the needs of communication-oriented devices. 108 The third approach involves adapting existing embedded operating systems to support communication through the addition of Internet protocols such as HTTP <ref> [35] </ref>, TCP, and IP. Examples in this class include OS-9, pSOS+, QNX, and VxWorks [48]. Such systems often have hard realtime support and are relatively small and modular. They also are compute-focused, so support for path-like abstractions is missing.
Reference: [36] <author> Bryan Ford, Mike Hibler, Jay Lepreau, Patrick Tullmann, Godmar Back, and Stephen Clawson. </author> <title> Microkernels meet recursive virtual machines. </title> <booktitle> In Proceedings of the Second Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 137151, </pages> <address> Seattle, WA, </address> <month> October </month> <year> 1996. </year> <note> ACM/USENIX. ftp://mancos.cs.utah.edu/papers/fluke-rvm-abs.html. </note>
Reference-contexts: In academia, much of the current OS research focuses on run-time extensibility of operating system kernels. Examples in this area include the Exokernel [32], FLUX <ref> [36] </ref>, SPIN [7], and VINO [92]. In contrast, Scout is targeted at communication-oriented information appliances where the need for dynamic extensibility of kernel software is less of an issue. This is because many appliances are expected to be of relatively static nature. <p> The desire to support at least a certain level of fate isolation makes it difficult to use fair share based schedulers such as the one presented in [70]. At the same time, hierarchical schedulers such as the ones presented in <ref> [36, 41] </ref> are not of much help since realtime scheduling by its very nature is not hierarchical (time is absolute). On the positive side, it should be possible to exploit the relatively simple linear structure of paths to improve scheduling decisions.
Reference: [37] <author> Bryan Ford and Jay Lepreau. </author> <title> Evolving Mach 3.0 to a migrating thread model. </title> <booktitle> In 1994 Winter USENIX Conference Proceedings, </booktitle> <pages> pages 97114, </pages> <address> San Francisco, CA, </address> <month> January </month> <year> 1994. </year>
Reference-contexts: This technique depends on knowing the sequence of modules that will be traversed by a data-item. In addition, it requires a provision for path-specific memory allocators. Both requirements can be accommodated easily in the proposed path model. 4 2.4.2.2 Migrating/Distributed Threads Migrating (distributed) threads <ref> [19, 45, 37] </ref> address the issue of anonymity of processing that often poses problems in modular systems. Typically, when data enters a new module, information on whose behalf the data is being processed is lost. <p> Examples of code, or fast-path optimizations include Synthesis [60], Synthetix [85], PathIDs [56], Protocol Accelerators [107], and integrated layer processing [16, 1]. Examples in the second category include processor capacity reserves [64], distributed/migrating threads <ref> [19, 37] </ref>, and Rialto activities [52]. These related works do not attempt to define an explicit and universal path abstraction, but are a source of interesting examples of how paths can be employed. The work on Synthetix is also interesting in that it introduces the notion of quasi-invariants.
Reference: [38] <author> Adele Goldberg and Alan Kay. </author> <title> Smalltalk-72 instruction manual. </title> <type> Technical Report SSL 76-6, </type> <institution> Learning Research Group, Xerox Palo Alto Research Center, </institution> <year> 1976. </year>
Reference-contexts: This is simple, but does not provide any way to deliver data to the interface. Thus, all useful interfaces are expanded versions of this primitive interface. That is, Scout uses single inheritance for interfaces <ref> [38] </ref>. For example, the interface that 79 is commonly used to pass a message (a sequence of data bytes) to an interface is called AioIface (asynchronous I/O interface).
Reference: [39] <author> James Gosling, Frank Yellin, </author> <title> and the Java Team. The Java Application Programming Interface. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1996. </year> <note> ISBN 0-201-63455-4. </note>
Reference-contexts: The biggest issue in doing so is the security issue, not the actual dynamic loading. An alternative to extending the module graph at runtime would be to configure a virtual machine module into the graph that would allow interpreted code to be downloaded and executed inside Scout <ref> [39, 25] </ref>. 3.3 Paths This section describes how paths are realized in Scout. Scout paths closely follow the model presented in Chapter 2.
Reference: [40] <author> Andreas Gotti. </author> <title> The Da CaPo communication system. </title> <type> Technical report, </type> <institution> Swiss Federal Institute of Technology, </institution> <address> Zurich, Switzerland, </address> <month> June </month> <year> 1994. </year> <note> http://www.tik.ee.ethz.ch/dacapo/. </note>
Reference-contexts: Neither do they attempt to optimize the code along a path. It is also the case that UNIX pipes are more coarse-grain and unidirectional. The system that is, at least terminology-wise, close to the proposed path model is Da CaPo <ref> [40] </ref>. Da CaPo stands for dynamic configuration of protocols and defines an infrastructure for building multimedia protocols. It has an explicit notion of paths, but there are important differences to our proposed path model at all levels.
Reference: [41] <author> Pawan Goyal, Xingang Guo, and Harrick M. Vin. </author> <title> A hierarchical CPU scheduler for multimedia operating systems. </title> <booktitle> In Proceedings of the Second Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 107121, </pages> <address> Seattle, WA, Oc-tober 1996. ACM/USENIX. http://www.cs.utexas.edu/users/pawang/Postscript/cpu.camera.ps. 168 </address>
Reference-contexts: The desire to support at least a certain level of fate isolation makes it difficult to use fair share based schedulers such as the one presented in [70]. At the same time, hierarchical schedulers such as the ones presented in <ref> [36, 41] </ref> are not of much help since realtime scheduling by its very nature is not hierarchical (time is absolute). On the positive side, it should be possible to exploit the relatively simple linear structure of paths to improve scheduling decisions.
Reference: [42] <author> The Open Group. </author> <title> The Single UNIX Specification. </title> <address> Witney, England, </address> <note> second edition, February 1997. http://www.rdg.opengroup.org/pubs/catalog/t912.htm. </note>
Reference-contexts: In general, the path abstraction often significantly affects the logic with which objects are created and destroyed, meaning that cleanly integrating such changes in a system not designed for paths is likely to be difficult. UNIX STREAMS <ref> [42] </ref> are superficially similar to Scout paths. A STREAM essentially consists of a sequence of modules that is terminated by a STREAM head at the top (beneath the user/kernel boundary) and by a STREAM end at the bottom (device-driver level).
Reference: [43] <author> Rajiv Gupta and Chi-Hung Chi. </author> <title> Improving instruction cache behavior by reducing cache pollution. </title> <booktitle> In Proceedings Supercomputing '90, </booktitle> <pages> pages 8291, </pages> <address> New York, NY, </address> <month> November </month> <year> 1990. </year> <note> IEEE. </note>
Reference-contexts: This hypothesis is corroborated by the fact that we have not found a single instance where aligning function entry-points or similar gap-introducing techniques would have improved end-to-end latency. Note that this is in stark contrast with the findings published in <ref> [43] </ref>, where i-cache optimization focused on functions with a very high degree of locality. So it may be that micro-positioning suffers because of the memory bandwidth wasted on loading gaps. Third, the DEC 3000/600 workstations used in the experiments employ a large second-level cache.
Reference: [44] <author> A. N. Habermann, Lawrence Flon, and Lee Cooprider. </author> <title> Modularization and hierarchy in a family of operating systems. </title> <journal> Communications of the ACM, </journal> <volume> 19(5):266 272, </volume> <month> May </month> <year> 1976. </year>
Reference-contexts: From early work on layered operating systems and networking architectures <ref> [44, 114] </ref>, to more recent advances in stackable systems [88, 49, 46, 108], modularity has played a central role in managing complexity, isolating failure, and enhancing configurability. Clearly, it is not something that can be discarded lightly.
Reference: [45] <author> Graham Hamilton and Panos Kougiouris. </author> <title> The Spring nucleus: a microkernel for objects. </title> <booktitle> In 1993 Summer USENIX Conference Proceedings, </booktitle> <pages> pages 147159, </pages> <address> Cincinnati, OH, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: This technique depends on knowing the sequence of modules that will be traversed by a data-item. In addition, it requires a provision for path-specific memory allocators. Both requirements can be accommodated easily in the proposed path model. 4 2.4.2.2 Migrating/Distributed Threads Migrating (distributed) threads <ref> [19, 45, 37] </ref> address the issue of anonymity of processing that often poses problems in modular systems. Typically, when data enters a new module, information on whose behalf the data is being processed is lost.
Reference: [46] <author> John S. Heidemann and Gerald J. Popek. </author> <title> File-system development with stackable layers. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 12(1):5889, </volume> <month> February </month> <year> 1994. </year>
Reference-contexts: From early work on layered operating systems and networking architectures [44, 114], to more recent advances in stackable systems <ref> [88, 49, 46, 108] </ref>, modularity has played a central role in managing complexity, isolating failure, and enhancing configurability. Clearly, it is not something that can be discarded lightly. So the question is whether it is possible to avoid the disadvantages of modularity without giving up on its strengths.
Reference: [47] <author> R. R. Heisch. </author> <title> Trace-directed program restructuring for AIX executables. </title> <journal> IBM Journal of Research and Development, </journal> <volume> 38(9):595603, </volume> <month> September </month> <year> 1994. </year>
Reference-contexts: Such outlined code could, for example, be moved to the end of the function or to the end of the program where it does not interfere with any frequently executed code. Outlining is sometimes used with profile-based optimizers <ref> [47, 77] </ref>. With profile information, outlining can be automated relatively easily. However, for the purpose of experimentation, it is more appropriate to use a language based approach that gives full and direct control to the programmer.
Reference: [48] <author> Dan Hildebrand. </author> <title> An architectural overview of QNX. </title> <booktitle> In Proceedings of the USENIX Workshop on Micro-Kernels and Other Kernel Architectures, </booktitle> <pages> pages 113 126, </pages> <address> Seattle, WA, </address> <month> April </month> <year> 1992. </year>
Reference-contexts: Examples in this class include OS-9, pSOS+, QNX, and VxWorks <ref> [48] </ref>. Such systems often have hard realtime support and are relatively small and modular. They also are compute-focused, so support for path-like abstractions is missing. In essence, this means that realtime support is limited to the process abstraction and does not extend to the I/O subsystems.
Reference: [49] <author> Norman C. Hutchinson and Larry L. Peterson. </author> <title> The x-kernel: An architecture for implementing network protocols. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1):6476, </volume> <month> January </month> <year> 1991. </year>
Reference-contexts: From early work on layered operating systems and networking architectures [44, 114], to more recent advances in stackable systems <ref> [88, 49, 46, 108] </ref>, modularity has played a central role in managing complexity, isolating failure, and enhancing configurability. Clearly, it is not something that can be discarded lightly. So the question is whether it is possible to avoid the disadvantages of modularity without giving up on its strengths. <p> At a higher level, Da CaPo focuses completely on automatically selecting appropriate protocol functionality; performance and resource management appear to be lesser issues to Da CaPo. CORDS is a communication subsystem by the Open Group (formerly Open Software Foundation) that is based on the x-kernel <ref> [49] </ref>. It employs a path abstraction that is based on early work that lead to the path model proposed here. As such, paths as presented in [105] are limited in several ways. First, they are applicable in the communication subsystem only. <p> On the other hand, if a module modifies all data passing through ite.g., by complementing itthen the partial classifier would 3 This is indeed a common restriction. For example, while the x-kernel <ref> [49] </ref> does not explicitly enforce such a restriction, it is unable to guarantee proper demultiplexing if a connection exists with an active key in a layer beneath a layer that uses a passive key. 96 have to do the same. <p> Owing to the efficiency with which threads can typically move from one path on to another, even a system with many short paths is likely to perform comparably to or better than traditional systems that avoid per-layer context switching, such as the x-kernel or UNIX <ref> [49, 89] </ref>. Furthermore, an approach using independent threads does not prevent building a system in which threads have path affinity. <p> This is typically achieved either through a feedback mechanism (such as TCP flow-control) or a load shedding mechanism (such as dropping messages). 3.6 Related Work Several aspects of Scout bear similarities to the x-kernel and indeed often are refinements that derive from experiences gained with it <ref> [49] </ref>. An interesting question is whether it would have been possible to add the path abstraction to the x-kernel. The CORDS system effectively did that with a limited form of paths [105]. In this sense, it is possible. <p> When executing code sequentially from the b-cache, the CPU can sustain an execution rate of 8 instructions per 13 cycles [34]. Unless noted otherwise, all software was implemented in a prototype version of Scout that was derived from the x-kernel <ref> [49] </ref>. The module graph consists of the networking subsystem and measurement code only. The resulting Scout system is so small that it fits entirely into the b-cache and, unless forced (as in some of the tests), there are no b-cache conflicts.
Reference: [50] <author> Van Jacobson. </author> <title> Congestion avoidance and control. </title> <booktitle> In Proceedings of SIG-COMM '88 Symposium, </booktitle> <pages> pages 314329, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1988. </year> <note> ACM. </note>
Reference-contexts: This discussion implies that in order to properly size the input queue, it is necessary to know the relationship between the average roundtrip time and the average processing time per packet. The roundtrip time can be estimated, for example, with the algorithm typically used for TCP <ref> [50] </ref>. For example, in the protocol stack of NetTV, MFLOW could implement this by putting a timestamp in its packet header and making available this measured roundtrip time by maintaining a well-known path attribute (e.g., AVG RTT), giving the measured average roundtrip time in micro-seconds.
Reference: [51] <author> Van Jacobson. </author> <title> A high performance TCP/IP implementation. Presentation at the NRI Gigabit TCP Workshop, </title> <month> March 18th19th </month> <year> 1993. </year>
Reference-contexts: The reason for choosing this problem is that optimizing for latency is often considered hard since, in contrast to throughput-oriented optimizations, there is rarely a single dominant latency bottleneck [55, 112]. Instead, to improve latency it is typically necessary to improve protocol processing along the entire path of execution <ref> [18, 51] </ref>. In this sense, the problem is ideally suited to demonstrate some of the potential benefits of Scout paths.
Reference: [52] <author> M. Jones, P. Leach, R. Draves, and J. Barrera. </author> <title> Support for user-centric modular real-time resource management in the Rialto operating system. </title> <booktitle> In Proceedings of the 5th International Workshop on Network and Operating System Support for Digital Audio and Video, </booktitle> <pages> pages 5566, </pages> <address> Durham, NH, </address> <month> April </month> <year> 1995. </year> <note> ACM. http://hulk.bu.edu/nossdav95/papers/Michael Jones.ps. </note>
Reference-contexts: Examples of code, or fast-path optimizations include Synthesis [60], Synthetix [85], PathIDs [56], Protocol Accelerators [107], and integrated layer processing [16, 1]. Examples in the second category include processor capacity reserves [64], distributed/migrating threads [19, 37], and Rialto activities <ref> [52] </ref>. These related works do not attempt to define an explicit and universal path abstraction, but are a source of interesting examples of how paths can be employed. The work on Synthetix is also interesting in that it introduces the notion of quasi-invariants.
Reference: [53] <author> Michael Jones, Daniela Rosu, and Marcel-Catalin Rosu. </author> <title> CPU reservations & time constraints: Efficient, predictable scheduling of independent activities. </title> <booktitle> In Proceedings of the Sixteenth ACM Symposium on Operating System Principles, </booktitle> <address> Saint Malo, France, </address> <month> October </month> <year> 1997. </year> <note> ACM. To appear. 169 </note>
Reference-contexts: Finding an appropriate soft realtime scheduler is difficult because, unlike many hard realtime schedulers, it must be fairly general. For example, it cannot assume that synchronization constraints within a task are trivial or negligible. Non-trivial synchronization makes it difficult to employ planning-based approaches, such as the one presented in <ref> [53] </ref>. On the other hand, if a user is committed to a certain realtime task, then it probably would not be acceptable if starting another unrelated task, which may not even be a realtime task, would cause the realtime task to start to misbehave.
Reference: [54] <author> JTC1/SC29. </author> <title> MPEG II Video. Number CD 13818-2 in Information Technology Generic Coding of moving pictures and associated audio information Part 2: Video. </title> <address> ISO/IEC, </address> <year> 1996. </year>
Reference-contexts: With this improved understanding, it is possible to enumerate the scenarios in which the technique might be employed beneficially. Chapter 5 introduces a demonstration appliance consisting of a networked TV that displays MPEG-encoded video streams <ref> [54, 67] </ref> through a windowing system on a graphics frame-buffer. This appliance emphasizes the resource management aspects of paths. In contrast to the networking study, almost all execution time is spent in the MPEG decoder, hence the fact that modular code does not provide the best possible code-path hardly matters. <p> La Rochefoucauld This chapter serves two purposes. First, it provides a concrete example for building a simple, yet fully functional Scout appliance. The appliance presented is a network-attached TV that can display MPEG encoded video <ref> [54, 67] </ref>. Second, this chapter demonstrates path-derived resource management benefits. To emphasize resource managementas opposed to the path-code related benefits described in the previous chapterit is best to choose an appliance that spends most of its CPU time in just one or a few modules.
Reference: [55] <author> Jonathan Kay and Joseph Pasquale. </author> <title> The importance of non-data touching processing overheads in TCP/IP. </title> <booktitle> In Proceedings of SIGCOMM '93 Symposium, </booktitle> <pages> pages 259268, </pages> <address> San Fransico, CA, </address> <month> October </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: Specifically, it is targeted at reducing protocol processing latency. The reason for choosing this problem is that optimizing for latency is often considered hard since, in contrast to throughput-oriented optimizations, there is rarely a single dominant latency bottleneck <ref> [55, 112] </ref>. Instead, to improve latency it is typically necessary to improve protocol processing along the entire path of execution [18, 51]. In this sense, the problem is ideally suited to demonstrate some of the potential benefits of Scout paths.
Reference: [56] <author> Jonathan Simon Kay. </author> <title> Path IDs: A Mechanism for Reducing Network Software Latency. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> San Diego, </address> <year> 1995. </year> <note> http://www-csl.ucsd.edu/CSL/pubs/phd/jkay.thesis.ps. </note>
Reference-contexts: That is, the data is brought into the CPU only once, thus greatly improving the efficiency of the memory system. Indeed, Abbott and Peterson [1] report communication bandwidth improvements in the range of 10 to 30% due to ILP. 1.4.1.3 PathIDs PathIDs <ref> [56] </ref> is a mechanism that allows substituting the implementation of a specific network protocol stack with hand-optimized, vertically integrated code. The mechanism essentially involves inserting an additional network header right above the link-layer. <p> In addition to the above mentioned work, there is a wealth of research on mechanisms that offer point-solutions to the more general problem of exploiting paths, both as a code optimization and resource management framework. Examples of code, or fast-path optimizations include Synthesis [60], Synthetix [85], PathIDs <ref> [56] </ref>, Protocol Accelerators [107], and integrated layer processing [16, 1]. Examples in the second category include processor capacity reserves [64], distributed/migrating threads [19, 37], and Rialto activities [52]. <p> Of course, a solution that would be better still (as far as Scout is concerned) would be to modify the header of the lowest layer protocol to include a field that can store the path id <ref> [56] </ref>. That way, demultiplexing could be reduced to a simple table lookup. However, since Scout needs to be able to interoperate with existing networking infrastructure, this is not always an option. The factoring of demultiplexing decisions is best explained with an example. <p> For this reason, STREAMS are typically very wide in the Scout sense. For example, a STREAM may represent a stack of networking protocols, but it could not (easily) represent an individual TCP connection. Like Scout, the work presented by Kay supports the construction of optimized code paths <ref> [56] </ref>. Its approach is to introduce the notion of PathIDs, which are integer numbers 106 stored in the lowest-layer header of a networking subsystem. These identifiers are allocated on a per-path basis and therefore allow to quickly identify the code-path that should be used to process an incoming packet. <p> If VCIs can be allocated on a per-path basis, then they can be used in lieu of an additional PathID field [26]. However, PathIDs are not a general path-abstraction like the one defined by Scout. For example, they do not provide a means to generate optimized code paths automatically <ref> [56] </ref>. Manually written code is likely to result in good performance, but it is also time consuming to generate and difficult to maintain such vertically integrated code. <p> It is important, however, to keep in mind that the approach taken in this case study is by no means the only way paths can be exploited to improve execution speed of a system. Dynamic code generation [60], manually crafted vertically integrated code-paths <ref> [56, 23] </ref>, or a language-based approach [14] represent a few other possibilities in this spectrum. The case study proposes and analyzes four techniques targeted at improving protocol processing. <p> That is, this version uses all techniques, and is expected to achieve the best performance. Note that all versions except STD use path specific code. Thus, it is necessary to lookup the appropriate path for incoming packets either by using PathIDs <ref> [56] </ref> or a packet classifier (such as the one presented in Section 3.4.1).
Reference: [57] <author> Brian W. Kernighan and Dennis M. Ritchie. </author> <title> Programmieren in C. </title> <publisher> Carl Hanser Verlag, </publisher> <address> Munchen, Germany, </address> <note> german edition, 1983. ISBN 3-446-13878-1. </note>
Reference-contexts: For a comprehensive and detailed description of the various programming interfaces, the reader is referred to the Scout manual [101]. 3.1 Overview Scout is an operating system designed for information appliances such as set-top boxes, or file- and web-servers. It is implemented in C <ref> [57] </ref>, founded on a modular structure and built around the path abstraction which makes it suitable for the communication-oriented nature of appliances. The current system supports both best-effort and soft re-altime scheduling.
Reference: [58] <author> C. L. Liu and J. W. Layland. </author> <title> Scheduling algorithms for multiprogramming in a hard-real-time environment. </title> <journal> Journal of the ACM, </journal> <volume> 1(20):4661, </volume> <month> January </month> <year> 1973. </year>
Reference-contexts: Two scheduling policies are supported and a higher-level round-robin scheduler allocates percentages of CPU time to each. 4 The minimum CPU share that each policy gets is determined by a compile-time parameter. The two policies supported are (1) fixed-priority round-robin and (2) earliest-deadline first (EDF) <ref> [58] </ref>. The reason for implementing the EDF policy is that for many soft realtime applications, it is most natural to express a path's priority in terms of a deadline. This will be discussed in more detail in Chapter 5. <p> The default Scout scheduler is a fixed-priority, round-robin scheduler. Since video is periodic, it seems reasonable to use rate-monotonic (RM) scheduling for MPEG paths <ref> [58] </ref>. With this approach, priorities are assigned in increasing order of frame rate and non-realtime paths are given priorities below those of any realtime path.
Reference: [59] <author> Peter Madany, Susan Keohan, Douglas Kramer, and Tom Saulpaugh. </author> <title> JavaOS: A standalone Java environment. </title> <address> http://www.javasoft.com/products/javaos/javaos.white.html. </address>
Reference-contexts: There appear to be three major approaches to supporting NCs: 1. virtual machine based, 2. pared-down general purpose OS, and 3. Internet-extended embedded OS. JavaOS and Inferno use the first approach <ref> [59, 25] </ref>. Both emphasize on the ability to download platform-independent virtual machine code over the network and execute it safely. The issue of supporting virtual machine code is orthogonal to the path abstraction defined by Scout. It is not difficult to add modules to Scout that support such virtual machines.
Reference: [60] <author> Henry Massalin. </author> <title> Synthesis: An Efficient Implementation of Fundamental Operating System Services. </title> <type> PhD thesis, </type> <institution> Columbia University, </institution> <address> New York, NY 10027, </address> <month> September </month> <year> 1992. </year>
Reference-contexts: There are many examples of this in the literature, of which we now discuss a few. 1.4.1.1 Code Synthesis Code synthesis, also known as run-time code-generation, has been used in the Synthesis kernel to optimize code across module boundaries <ref> [86, 60] </ref>. The two main-techniques involved factoring invariants and collapsing layers, which are forms of partial evaluation. In extreme cases, such as reading a single byte from a memory pseudo-device (/dev/mem in UNIX), these techniques achieved order-of-magnitude improvements compared to regular UNIX kernels [89]. <p> In addition to the above mentioned work, there is a wealth of research on mechanisms that offer point-solutions to the more general problem of exploiting paths, both as a code optimization and resource management framework. Examples of code, or fast-path optimizations include Synthesis <ref> [60] </ref>, Synthetix [85], PathIDs [56], Protocol Accelerators [107], and integrated layer processing [16, 1]. Examples in the second category include processor capacity reserves [64], distributed/migrating threads [19, 37], and Rialto activities [52]. <p> It is important, however, to keep in mind that the approach taken in this case study is by no means the only way paths can be exploited to improve execution speed of a system. Dynamic code generation <ref> [60] </ref>, manually crafted vertically integrated code-paths [56, 23], or a language-based approach [14] represent a few other possibilities in this spectrum. The case study proposes and analyzes four techniques targeted at improving protocol processing. <p> For example, if cloning is delayed until a TCP/IP path is established, most connection state will remain constant and can be used to partially evaluate the cloned function. This achieves similar benefits as code synthesis <ref> [60] </ref>. Just like inlining, cloning is at odds with locality of reference. Cloning at connection creation time will lead to one cloned copy per connection, while cloning at module graph creation time requires only one copy per protocol stack.
Reference: [61] <author> Steven McCanne and Van Jacobson. </author> <title> The BSD packet filter: A new architecture for user-level packet capture. </title> <booktitle> In 1993 Winter USENIX Conference Proceedings, </booktitle> <pages> pages 259269, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1993. </year> <month> ftp://ftp.ee.lbl.gov/papers/bpf-usenix93.ps.Z. </month>
Reference-contexts: Of the many packet classifiers and packet filters that have been proposed in the past, none fit the re 109 quirements of Scout perfectly. For example, interpreted packet filters are generally not fast enough <ref> [113, 61] </ref>. The performance of DPF, a classifier that uses runtime code generation [30] has been reported to be impressive, but unfortunately makes it relatively slow to insert and remove existing filters or, as is the case for version 2.0, provides a language with limited expressiveness.
Reference: [62] <author> Scott McFarling. </author> <title> Program optimization for instruction caches. </title> <booktitle> In Third Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 183191, </pages> <address> Boston, MA, </address> <month> April </month> <year> 1989. </year> <note> ACM. </note>
Reference-contexts: The idea was that, ideally, it should be possible to avoid all i-cache conflicts along a critical path of execution. With a direct-mapped i-cache, the starting address of a function determines exactly which i-cache blocks it is going to occupy <ref> [62] </ref>. Consequently, by choosing appropriate addresses, it is possible to optimize i-cache behavior for the se 120 quence of functions in a given path. The cost is that this fine-grained control of function-placement occasionally makes it necessary to introduce gaps between two consecutive functions.
Reference: [63] <author> Larry McVoy and Carl Staelin. lmbench: </author> <title> Portable tools for performance analysis. </title> <booktitle> In Proceedings of the USENIX 1996 Annual Technical Conference, </booktitle> <pages> pages 120133, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: This is because non-blocking loads enable overlapping (hiding) memory accesses with useful computation. The memory system interface is 128 bits wide and the lmbench <ref> [63] </ref> suite reports a memory access latency of 2, 10, and 48 cycles for a d-cache, 112 b-cache, and main-memory access, respectively. When executing code sequentially from the b-cache, the CPU can sustain an execution rate of 8 instructions per 13 cycles [34].
Reference: [64] <author> C. W. Mercer, S. Savage, and H. Tokuda. </author> <title> Processor capacity reserves: An abstraction for managing processor usage. </title> <booktitle> In Proceedings of the Fourth Workshop on Workstation Operating Systems (WWOS-IV), </booktitle> <pages> pages 129134, </pages> <address> Napa, CA, Octo-ber 1993. </address> <publisher> IEEE. </publisher>
Reference-contexts: Examples of code, or fast-path optimizations include Synthesis [60], Synthetix [85], PathIDs [56], Protocol Accelerators [107], and integrated layer processing [16, 1]. Examples in the second category include processor capacity reserves <ref> [64] </ref>, distributed/migrating threads [19, 37], and Rialto activities [52]. These related works do not attempt to define an explicit and universal path abstraction, but are a source of interesting examples of how paths can be employed.
Reference: [65] <author> R. Metcalf and D. Boggs. </author> <title> Ethernet: Distributed packet switching for local computer networks. </title> <journal> Communications of the ACM, </journal> <volume> 19(7):395403, </volume> <month> July </month> <year> 1976. </year> <month> 170 </month>
Reference-contexts: The most notable area where this is the case is for the networking subsystem. Networking protocols typically require hierarchical demultiplexing for arriving network packets. For example, when a network packet arrives at an Ethernet adapter <ref> [65] </ref>, the Ethernet type field needs to be looked up to determine whether the packet happens to be, e.g., an IP packet or an ARP packet. <p> The initial paths for NetTV are shown in Figure 5.2. As the figure shows, module STDIO creates three paths 141 Module: Description: TULIP Device driver for DECchip 21040 Ethernet chip. ETH Device-independent part of Ethernet protocol processing <ref> [65] </ref>. ARP The Ethernet Address Resolution Protocol [79]. IP The Internet Protocol [82]. ICMP The Internet Control Message Protocol [81]. UDP The User Datagram Protocol [80]. SHELL The command shell. It receives commands such as requests to display a new video and creates appropriate paths in response.
Reference: [66] <author> Bertrand Meyer. </author> <title> Introduction to the Theory of Programming Languages. </title> <publisher> Pren-tice-Hall, Inc., </publisher> <address> Hertfordshire, England, </address> <year> 1990. </year> <note> ISBN 0-13-498510-9. </note>
Reference-contexts: An advantage of paths is that the sequence of partial functions is known and fixed once the path has been created. Using a semicolon (;) as the functional infix operator denoting function composition <ref> [66] </ref>, the path processing function g can be expressed as: g = g FDDI ; g IP ; g UDP ; g MFLOW ; g MPEG ; g WiMP ; g DISPLAY This concisely demonstrates one of the fundamental benefits of paths: they make it possible to express g independent of
Reference: [67] <author> Joan L. Mitchell, William B. Pennebaker, Chad E. Fogg, and Didier J. Legall. </author> <title> MPEG Video Compression Standard. </title> <publisher> Chapman Hall, </publisher> <address> New York, NY, </address> <year> 1996. </year> <note> ISBN 0-412-08771-5. </note>
Reference-contexts: With this improved understanding, it is possible to enumerate the scenarios in which the technique might be employed beneficially. Chapter 5 introduces a demonstration appliance consisting of a networked TV that displays MPEG-encoded video streams <ref> [54, 67] </ref> through a windowing system on a graphics frame-buffer. This appliance emphasizes the resource management aspects of paths. In contrast to the networking study, almost all execution time is spent in the MPEG decoder, hence the fact that modular code does not provide the best possible code-path hardly matters. <p> La Rochefoucauld This chapter serves two purposes. First, it provides a concrete example for building a simple, yet fully functional Scout appliance. The appliance presented is a network-attached TV that can display MPEG encoded video <ref> [54, 67] </ref>. Second, this chapter demonstrates path-derived resource management benefits. To emphasize resource managementas opposed to the path-code related benefits described in the previous chapterit is best to choose an appliance that spends most of its CPU time in just one or a few modules.
Reference: [68] <author> Jeffrey C. Mogul and K. K. Ramakrishnan. </author> <title> Eliminating receive livelock in an interrupt-driven kernel. </title> <booktitle> In 1996 Winter USENIX Conference Proceedings, </booktitle> <pages> pages 99112, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1996. </year> <note> http://www.usenix.org/publications/library/proceedings/sd96/mogul.html. </note>
Reference-contexts: Clearly, avoiding priority inversion can have significant benefits. Nevertheless, this is not to say that paths are the only way to solve this particular problem. For example, both lazy receiver processing [28] and avoiding receive livelock <ref> [68] </ref> can have similar benefits.
Reference: [69] <author> Gordon E. Moore. </author> <title> Cramming more components onto integrated circuits. </title> <journal> Electronics Magazine, </journal> <volume> 38(8):114117, </volume> <month> April </month> <year> 1965. </year>
Reference-contexts: Based on SPECint95 reports, system performance has doubled in the past seven years roughly once every twenty months [96]. In 1965, Moore predicted that the transistor density of semiconductor chips would double roughly every twelve to eighteen months and his prediction has largely held true ever since <ref> [90, 69] </ref>. 1 To put this in perspective, the first microprocessor, the Intel 4004, was implemented using only 2,300 transistors in a 16-pin package. Twenty-seven years later, the DEC Alpha 21264 contains about 15.2 million transistors in a single 588-pin PGA package.
Reference: [70] <author> Jason Nieh and Monica S. Lam. </author> <title> The design, implementation & evaluation of SMART: A scheduler for multimedia applications. </title> <booktitle> In Proceedings of the Sixteenth ACM Symposium on Operating System Principles, </booktitle> <address> Saint Malo, France, </address> <month> Oc-tober </month> <year> 1997. </year> <note> ACM. To appear. </note>
Reference-contexts: The desire to support at least a certain level of fate isolation makes it difficult to use fair share based schedulers such as the one presented in <ref> [70] </ref>. At the same time, hierarchical schedulers such as the ones presented in [36, 41] are not of much help since realtime scheduling by its very nature is not hierarchical (time is absolute).
Reference: [71] <author> NIST. </author> <booktitle> Research and Development for the National Information Infrastructure: Technical Challenges. </booktitle> <publisher> NIST, </publisher> <address> Gaithersburg, MD, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: As a matter of fact, a NIST report on the National Information Infrastructure (NII) rejected the term computer on the grounds that it puts too much emphasis on computation <ref> [71] </ref>. The report suggested the term information appliances be used instead for systems that support communication, information storage, and user interactions. Intuitively, appliances are small, special-purpose, and often mobile devices such as remote controls, personal information managers, network-attached disks, cameras, displays, set-top boxes, embedded web-servers, and dedicated file-servers.
Reference: [72] <author> Sean W. O'Malley and Larry L. Peterson. </author> <title> A dynamic network architecture. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(2):110143, </volume> <month> May </month> <year> 1992. </year>
Reference-contexts: TCP/IP was chosen primarily because its ubiquitous nature facilitates comparison with other work on latency-oriented optimizations. Due to their roots in BSD UNIX, the TCP/IP modules are relatively coarse-grained. In contrast, the RPC stack exemplifies the x-kernel paradigm that encourages decomposing networking functionality into many small modules <ref> [72] </ref>. The module configurations for the two protocol stacks are shown in Figure 4.1. The left hand side shows the TCP/IP stack. At the top is TCPTEST, a simple, ping-pong style test program. <p> At the top is module XRPCTEST, which is the RPC-equivalent of the ping-pong test implemented by TCPTEST. Modules MSEL-ECT, VCHAN, CHAN, BID and BLAST in combination provide the RPC semantics. A detailed description of the protocols these modules implement can be found in <ref> [72] </ref>. The modules below BLAST are identical to the modules of the same name in the TCP/IP stack. 4.1.3 Base Case To determine whether the base case is sound, the Scout prototype version of the TCP/IP stack is compared with the version implemented by DEC UNIX v3.2c.
Reference: [73] <author> Hilarie Orman, Sean O'Malley, Edwin Menze, Larry Peterson, and Richard Schroeppel. </author> <title> A fast and general implementation of Mach IPC in a network. </title> <booktitle> In Proceedings of the Third Mach Symposium, </booktitle> <pages> pages 7588, </pages> <address> Santa Fe, NM, </address> <month> April </month> <year> 1993. </year> <booktitle> USENIX. </booktitle>
Reference-contexts: The systems research community has long harbored an intuitive notion of what a path is. For example, it often refers to the fast path through a system <ref> [85, 73, 2, 112] </ref>, implying that the most commonly executed sequence of instructions have been optimized.
Reference: [74] <author> Ketan Patel, Brian C. Smith, and Lawrence A. Rowe. </author> <title> Performance of a software MPEG video decoder. </title> <booktitle> In Proceedings of the Multimedia '93 Conference, </booktitle> <pages> pages 7582, </pages> <address> Anaheim, CA, </address> <month> June </month> <year> 1993. </year> <note> ACM. ftp://mm-ftp.cs.berkeley.edu/pub/multimedia/mpeg/play/. </note>
Reference-contexts: Along with the maximum frame rates, it also lists the length of the video in num 146 ber of frames. All measurements were performed on a first-generation 21064A Alpha running at 300MHz. The Scout and Linux MPEG-decoder were derived from the same code base <ref> [74] </ref>, so the only significant difference between the two systems is that Linux requires a context switch to move a video frame from the MPEG decoder process to the windowing system (X11).
Reference: [75] <author> Karin Petersen, Mike J. Spreitzer, Douglas B. Terry, Marvin M. Theimer, and Alan J. Demers. </author> <title> Flexible update propagation for weakly consistent replication. </title> <booktitle> In Proceedings of the Sixteenth ACM Symposium on Operating System Principles, </booktitle> <address> Saint Malo, France, </address> <month> October </month> <year> 1997. </year> <note> ACM. To appear. </note>
Reference-contexts: Handling intermittent connectivity typically requires support from higher-level and often application-specific software <ref> [75] </ref>, but studying such appliances should also provide interesting insights on the path architecture.
Reference: [76] <author> Larry L. Peterson and Bruce S. Davie. </author> <title> Computer Networks: A Systems Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc., </publisher> <address> San Francisco, CA, </address> <year> 1996. </year> <note> ISBN 1-55860-368-9. 171 </note>
Reference-contexts: The hosts and routers are connected by point-to-point links. How does a pair of hosts, say host 1 and 3, communicate in such a network? If we assume a datagram-oriented network <ref> [100, 76] </ref>, such as the Internet, then host 1 would prepare a message, append the network address of host 3 to the message, and then inject this datagram into the network by sending it to router 1.
Reference: [77] <author> K. Pettis and R. C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> In Proceedings of SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 1627, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year> <note> ACM. </note>
Reference-contexts: Such outlined code could, for example, be moved to the end of the function or to the end of the program where it does not interfere with any frequently executed code. Outlining is sometimes used with profile-based optimizers <ref> [47, 77] </ref>. With profile information, outlining can be automated relatively easily. However, for the purpose of experimentation, it is more appropriate to use a language based approach that gives full and direct control to the programmer. <p> This layout strategy is so simple that it can be computed easily at runtimethe only dynamic information required is the order in which the functions are invoked. In essence, computing a bipartite layout consists of applying the well-known closest-is-best strategy to the library and path partition individually <ref> [77] </ref>. Establishing the performance advantage of the bipartite layout relative to the micro-positioning approach is difficult since small changes to the heuristics of the latter approach resulted in large performance variations.
Reference: [78] <author> Rob Pike, Bart Locanthi, and John Reiser. </author> <title> Hardware/software trade-offs for bitmap graphics on the Blit. </title> <journal> SoftwarePractice and Experience, </journal> <volume> 15(2):131151, </volume> <month> February </month> <year> 1985. </year>
Reference-contexts: Supports sending of messages (sequence of data bytes). framebuf Frame buffer. Provides access to the raw frame buffer and allows registering callbacks that are invoked at the beginning of every vertical synchronization blanking period. winmgr Window manager. Supports bitblt <ref> [78] </ref>, text rendering, and similar graphics primitives. ns Naming-service. Supports lookup and reverse-lookup of arbitrary fixed-size name/value pairs. Table 5.2: Description of NetTV Interfaces 142 to TERMone each for stdin, stdout, and stderr.
Reference: [79] <author> D. Plummer. </author> <title> Ethernet Address Resolution Protocolorconverting network protocol addresses to 48-bit Ethernet address for transmission on Ethernet hardware. </title> <booktitle> DARPA, </booktitle> <month> November </month> <year> 1982. </year> <note> http://ds.internic.net/rfc/rfc826.txt. </note>
Reference-contexts: The row labelled Lookup active path lists the time required to classify a TCP/IP packet. To provide for a realistic environment, the classification was performed with three filters installed: one for the TCP/IP packets being looked up and one each for ARP and ICMP packets <ref> [79, 81] </ref>. The table shows that DPF is about 25% faster than the Scout classifier. This may sound like a large difference, but it corresponds to 62 CPU cycles which is marginal compared to the 98 cost of fielding an interrupt, which can easily be several hundred cycles. <p> The initial paths for NetTV are shown in Figure 5.2. As the figure shows, module STDIO creates three paths 141 Module: Description: TULIP Device driver for DECchip 21040 Ethernet chip. ETH Device-independent part of Ethernet protocol processing [65]. ARP The Ethernet Address Resolution Protocol <ref> [79] </ref>. IP The Internet Protocol [82]. ICMP The Internet Control Message Protocol [81]. UDP The User Datagram Protocol [80]. SHELL The command shell. It receives commands such as requests to display a new video and creates appropriate paths in response. MFLOW Multimedia-oriented flowcontrol protocol.
Reference: [80] <author> Jon Postel. </author> <title> User Datagram Protocol. </title> <booktitle> DARPA, </booktitle> <month> August </month> <year> 1980. </year> <note> http://ds.internic.net/rfc/rfc768.txt. </note>
Reference-contexts: ETH Device-independent part of Ethernet protocol processing [65]. ARP The Ethernet Address Resolution Protocol [79]. IP The Internet Protocol [82]. ICMP The Internet Control Message Protocol [81]. UDP The User Datagram Protocol <ref> [80] </ref>. SHELL The command shell. It receives commands such as requests to display a new video and creates appropriate paths in response. MFLOW Multimedia-oriented flowcontrol protocol. MPEG Implements the MPEG video decompression algorithm. TGA Device driver for DECchip 21030 based frame buffers. KBD Device driver for IBM PC-AT keyboard interface.
Reference: [81] <author> Jon Postel. </author> <title> Internet Control Message Protocol. </title> <booktitle> DARPA, </booktitle> <month> September </month> <year> 1981. </year> <note> http://ds.internic.net/rfc/rfc792.txt. </note>
Reference-contexts: The row labelled Lookup active path lists the time required to classify a TCP/IP packet. To provide for a realistic environment, the classification was performed with three filters installed: one for the TCP/IP packets being looked up and one each for ARP and ICMP packets <ref> [79, 81] </ref>. The table shows that DPF is about 25% faster than the Scout classifier. This may sound like a large difference, but it corresponds to 62 CPU cycles which is marginal compared to the 98 cost of fielding an interrupt, which can easily be several hundred cycles. <p> As the figure shows, module STDIO creates three paths 141 Module: Description: TULIP Device driver for DECchip 21040 Ethernet chip. ETH Device-independent part of Ethernet protocol processing [65]. ARP The Ethernet Address Resolution Protocol [79]. IP The Internet Protocol [82]. ICMP The Internet Control Message Protocol <ref> [81] </ref>. UDP The User Datagram Protocol [80]. SHELL The command shell. It receives commands such as requests to display a new video and creates appropriate paths in response. MFLOW Multimedia-oriented flowcontrol protocol. MPEG Implements the MPEG video decompression algorithm. TGA Device driver for DECchip 21030 based frame buffers.
Reference: [82] <author> Jon Postel. </author> <title> Internet Protocol. </title> <booktitle> DARPA, </booktitle> <month> September </month> <year> 1981. </year> <note> http://ds.internic.net/rfc/rfc791.txt. </note>
Reference-contexts: In this light, a 23 percent improvement is very significant. 1.4.1.4 Single-Copy TCP/IP Banks and Prudence [6] present what amounts to a vertically integrated networking stack. The stack under consideration was a typical UNIX networking stack consisting of a 25 socket-layer, TCP and IP layers <ref> [83, 82] </ref>, and a network driver layer. The vertical integration ensured that both on the outgoing and incoming side, network data is copied only once. <p> The module configurations for the two protocol stacks are shown in Figure 4.1. The left hand side shows the TCP/IP stack. At the top is TCPTEST, a simple, ping-pong style test program. Below are TCP and IP which are the Scout modules for of the corresponding Internet protocols <ref> [83, 82] </ref>. The TCP implementation is based on BSD UNIX source code so, apart from interface changes and differences in connection setup and tear-down, they are identical. Module VNET routes outgoing messages to the appropriate network adapter. <p> The initial paths for NetTV are shown in Figure 5.2. As the figure shows, module STDIO creates three paths 141 Module: Description: TULIP Device driver for DECchip 21040 Ethernet chip. ETH Device-independent part of Ethernet protocol processing [65]. ARP The Ethernet Address Resolution Protocol [79]. IP The Internet Protocol <ref> [82] </ref>. ICMP The Internet Control Message Protocol [81]. UDP The User Datagram Protocol [80]. SHELL The command shell. It receives commands such as requests to display a new video and creates appropriate paths in response. MFLOW Multimedia-oriented flowcontrol protocol. MPEG Implements the MPEG video decompression algorithm.
Reference: [83] <author> Jon Postel. </author> <title> Transmission Control Protocol. </title> <booktitle> DARPA, </booktitle> <month> September </month> <year> 1981. </year> <note> http://ds.internic.net/rfc/rfc793.txt. </note>
Reference-contexts: In this light, a 23 percent improvement is very significant. 1.4.1.4 Single-Copy TCP/IP Banks and Prudence [6] present what amounts to a vertically integrated networking stack. The stack under consideration was a typical UNIX networking stack consisting of a 25 socket-layer, TCP and IP layers <ref> [83, 82] </ref>, and a network driver layer. The vertical integration ensured that both on the outgoing and incoming side, network data is copied only once. <p> The module configurations for the two protocol stacks are shown in Figure 4.1. The left hand side shows the TCP/IP stack. At the top is TCPTEST, a simple, ping-pong style test program. Below are TCP and IP which are the Scout modules for of the corresponding Internet protocols <ref> [83, 82] </ref>. The TCP implementation is based on BSD UNIX source code so, apart from interface changes and differences in connection setup and tear-down, they are identical. Module VNET routes outgoing messages to the appropriate network adapter.
Reference: [84] <author> Todd A. Proebsting and Scott A. Watterson. </author> <title> Filter fusion. </title> <booktitle> In Proceedings of the 23rd Symposium on Principles of Programming Languages, </booktitle> <pages> pages 119130, </pages> <address> St. Petersburg Beach, FL, </address> <month> January </month> <year> 1996. </year> <note> ACM. </note>
Reference-contexts: As a final example, it sometimes distinguishes between a system's control path and its data path, with the former being more relevant to latency and the latter more concerned with throughput <ref> [27, 84] </ref>. But the wide-spread use of this term has so far not been translated into a well-defined abstraction that could serve as a foundation of system design.
Reference: [85] <author> Calton Pu, Tito Autrey, Andrew Black, Charles Consel, Crispin Cowan, Jon In-ouye, Lakshmi Kethana, Jonathan Walpole, and Ke Zhang. </author> <title> Optimistic incremental specialization: Streamlining a commercial operating system. </title> <booktitle> In Proceedings of the Fifteenth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 314324, </pages> <address> Copper Mountain Resort, CO, </address> <month> December </month> <year> 1995. </year> <note> ACM. </note>
Reference-contexts: Similar techniques were applied in a later project called Syn-thetix. While less aggressive, it was more practical in that it applied code synthesis to an existing commercial operating system, namely HP-UX. The results reported in <ref> [85] </ref> indicate speedups in the range from 1.12 to 3.61 for the UNIX read system-call compared to the regular HP-UX version. 24 1.4.1.2 Integrated Layer Processing The fundamental observation behind Integrated Layer Processing (ILP) [16, 1] is that as a network packet passes through various protocol processing steps, its data may <p> The systems research community has long harbored an intuitive notion of what a path is. For example, it often refers to the fast path through a system <ref> [85, 73, 2, 112] </ref>, implying that the most commonly executed sequence of instructions have been optimized. <p> In addition to the above mentioned work, there is a wealth of research on mechanisms that offer point-solutions to the more general problem of exploiting paths, both as a code optimization and resource management framework. Examples of code, or fast-path optimizations include Synthesis [60], Synthetix <ref> [85] </ref>, PathIDs [56], Protocol Accelerators [107], and integrated layer processing [16, 1]. Examples in the second category include processor capacity reserves [64], distributed/migrating threads [19, 37], and Rialto activities [52]. <p> The access pattern of a path could be used by the modules in the disk subsystem to select an appropriate caching policy. Also, code-optimization tech 161 niques could be used to improve the performance of small reads or writes <ref> [85] </ref>. As a final example, paths through the disk subsystem could prove useful in scheduling disk accesses in a manner that will ensure a certain level of quality-of-service for the path.
Reference: [86] <author> Calton Pu, Henry Massalin, and John Ioannidis. </author> <title> The Synthesis kernel. </title> <booktitle> Computing Systems, </booktitle> <address> 1(1):1132, </address> <month> Winter </month> <year> 1988. </year>
Reference-contexts: There are many examples of this in the literature, of which we now discuss a few. 1.4.1.1 Code Synthesis Code synthesis, also known as run-time code-generation, has been used in the Synthesis kernel to optimize code across module boundaries <ref> [86, 60] </ref>. The two main-techniques involved factoring invariants and collapsing layers, which are forms of partial evaluation. In extreme cases, such as reading a single byte from a memory pseudo-device (/dev/mem in UNIX), these techniques achieved order-of-magnitude improvements compared to regular UNIX kernels [89]. <p> A few specific examples follow below. 2.4.1.1 Code Synthesis Pu et al. propose a runtime code synthesis technique that involves collapsing layers to avoid the overhead that is typically caused by crossing module or layer boundaries <ref> [86] </ref>. The technique allows further optimization of the collapsed code through factoring of invariants and elimination of data copying. For this technique to be applicable, it is necessary to know the invariants that are true for the code-path through the system that is to be optimized.
Reference: [87] <author> David D. Redell, Yogen K. Dalal, Thomas R. Horsley, Hugh C. Lauer, William C. Lynch, Paul R. McJones, Hal G. Murray, and Stephen C. Purcell. </author> <title> Pilot: an operating system for a personal computer. </title> <journal> Communications of the ACM, </journal> <volume> 23(2):8192, </volume> <month> February </month> <year> 1980. </year>
Reference-contexts: But this does not mean that the path model could not be applied to systems with multiple protection domains. 57 2.5 Related Work At the surface, paths are similar to UNIX pipes [89] and Pilot streams <ref> [87] </ref>. While all three have in common a linear sequence of components (processes in UNIX, Mesa modules in Pilot, modules in the path model), neither pipes nor streams provide any global context to the individual components. Neither do they attempt to optimize the code along a path.
Reference: [88] <author> D. M. Ritchie. </author> <title> A stream input-output system. </title> <journal> AT&T Bell Laboratories Technical Journal, </journal> <volume> 63(8):311324, </volume> <month> October </month> <year> 1984. </year> <month> 172 </month>
Reference-contexts: From early work on layered operating systems and networking architectures [44, 114], to more recent advances in stackable systems <ref> [88, 49, 46, 108] </ref>, modularity has played a central role in managing complexity, isolating failure, and enhancing configurability. Clearly, it is not something that can be discarded lightly. So the question is whether it is possible to avoid the disadvantages of modularity without giving up on its strengths.
Reference: [89] <author> D. M. Ritchie and K. Thompson. </author> <title> The UNIX time-sharing system. </title> <journal> Communications of the ACM, </journal> <volume> 17(7):365375, </volume> <month> July </month> <year> 1974. </year>
Reference-contexts: The two main-techniques involved factoring invariants and collapsing layers, which are forms of partial evaluation. In extreme cases, such as reading a single byte from a memory pseudo-device (/dev/mem in UNIX), these techniques achieved order-of-magnitude improvements compared to regular UNIX kernels <ref> [89] </ref>. Similar techniques were applied in a later project called Syn-thetix. While less aggressive, it was more practical in that it applied code synthesis to an existing commercial operating system, namely HP-UX. <p> But this does not mean that the path model could not be applied to systems with multiple protection domains. 57 2.5 Related Work At the surface, paths are similar to UNIX pipes <ref> [89] </ref> and Pilot streams [87]. While all three have in common a linear sequence of components (processes in UNIX, Mesa modules in Pilot, modules in the path model), neither pipes nor streams provide any global context to the individual components. <p> Owing to the efficiency with which threads can typically move from one path on to another, even a system with many short paths is likely to perform comparably to or better than traditional systems that avoid per-layer context switching, such as the x-kernel or UNIX <ref> [49, 89] </ref>. Furthermore, an approach using independent threads does not prevent building a system in which threads have path affinity.
Reference: [90] <author> Robert R. Schaller. Moore's law: </author> <title> past, present, and future. </title> <journal> IEEE SPECTRUM, </journal> <pages> pages 5359, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Based on SPECint95 reports, system performance has doubled in the past seven years roughly once every twenty months [96]. In 1965, Moore predicted that the transistor density of semiconductor chips would double roughly every twelve to eighteen months and his prediction has largely held true ever since <ref> [90, 69] </ref>. 1 To put this in perspective, the first microprocessor, the Intel 4004, was implemented using only 2,300 transistors in a 16-pin package. Twenty-seven years later, the DEC Alpha 21264 contains about 15.2 million transistors in a single 588-pin PGA package.
Reference: [91] <author> Robert Sedgewick. </author> <title> Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <note> second edition, 1988. ISBN 0-201-06673-4. </note>
Reference-contexts: The exact meaning of this type will be discussed later in this chapter. For now, it is sufficient to know that each service has a name and type associated with it. An example module is shown in Figure 3.2. The big box represents a run-length compression filter <ref> [91] </ref>. The two nested boxes represent services: plain provides access to the plain, uncompressed data and compr provides access to the run-length compressed 64 data. Both services are of type ByteStream.
Reference: [92] <author> M. Seltzer, Y. Endo, C. Small, and K. Smith. </author> <title> Dealing with disaster: Surviving misbehaved kernel extensions. </title> <booktitle> In Proceedings of the Second Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pages 213227, </pages> <address> Seattle, WA, </address> <month> October </month> <year> 1996. </year> <note> ACM/USENIX. http://www.eecs.harvard.edu/vino/vino/osdi-96/. </note>
Reference-contexts: In academia, much of the current OS research focuses on run-time extensibility of operating system kernels. Examples in this area include the Exokernel [32], FLUX [36], SPIN [7], and VINO <ref> [92] </ref>. In contrast, Scout is targeted at communication-oriented information appliances where the need for dynamic extensibility of kernel software is less of an issue. This is because many appliances are expected to be of relatively static nature.
Reference: [93] <author> Richard L. </author> <title> Sites, editor. Alpha Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <address> Burlington, Massachusetts, </address> <year> 1996. </year> <month> ftp://ftp.digital.com/pub/Digital/info/semiconductor/literature/alphahb2.pdf. </month>
Reference-contexts: These workstations use a first-generation 21064 Alpha CPU running at 175MHz <ref> [93] </ref>. The CPU is a 64-bit wide, super-scalar design that can issue up to two instructions per cycle. Though the peak issue rate is two, there are few dual-issue opportunities in the pure integer code that is typical for systems code. <p> The necessary data was collected by instrumenting both kernels with a tracing facility that can acquire instruction traces of pristine, working code. 1 Execution times were measured separately using the cycle counter register provided by the Alpha architecture <ref> [93] </ref>. This register allows measuring time intervals on the order of a few seconds in duration with a resolution of a single CPU cycle (approximately 5.7ns for the 175MHz CPU that was used in the tests). In combination, the traces and execution times enable a detailed comparison of processing overhead.
Reference: [94] <editor> IEEE Computer Society. </editor> <title> IEEE Guide to the POSIX Open System Environment. </title> <publisher> IEEE Press, </publisher> <month> November </month> <year> 1995. </year> <note> ISBN 1-55937-531-0. </note>
Reference-contexts: Indeed, as the system is developed, informal arguments are presented as to why and how it could be extended to more complex environments. With the above considerations in mind, it should be no surprise that conformance with standard programming interfaces, such as POSIX <ref> [94] </ref>, is not a primary goal of Scout. An understanding of how existing interfaces support or interfere with the needs of a communication-oriented system could be useful, but is a secondary issue. In contrast to the internal programming interfaces, the external communication protocols are considered a given.
Reference: [95] <author> Oliver Spatschek and Larry Peterson. Escort: </author> <title> Securing Scout paths. </title> <booktitle> In Proceedings of the 1997 IEEE Symposium on Security and Privacy, </booktitle> <pages> page 206, </pages> <address> Oak-land, CA, </address> <month> May </month> <year> 1997. </year>
Reference-contexts: Ideally, paths directly connect modules representing device pairs, so the number of domain crossings for moving data from a source device to sink device would be two, just as is the case with a traditional, monolithic kernel based system <ref> [95] </ref>. 3.4 Demultiplexing So far, we have not discussed the issue of how the appropriate path is found for a given message. In many cases, this is trivial. For example, a path is often used like a file descriptor, a window handle, or a socket descriptor. <p> The latter would require adding mechanisms to Scout to enforce the safety of paths, such as hardware protection domains or sand-boxing <ref> [95] </ref>. 164
Reference: [96] <author> SPEC. </author> <title> SPEC newsletter. </title> <address> Manassas, VA. http://www.specbench.org/osg/cpu95/results/cpu95.html. </address>
Reference-contexts: Sail out to sea and do new things. Admiral Grace Hopper, Computer Pioneer Computer systems are continuing to evolve at a rapid pace. Based on SPECint95 reports, system performance has doubled in the past seven years roughly once every twenty months <ref> [96] </ref>.
Reference: [97] <institution> SPEC. SPEC newsletter. Manassas, VA, </institution> <month> June </month> <year> 1995. </year> <note> http://www.specbench.org/osg/sfs93/results/res9506/. </note>
Reference-contexts: Even though UNIX uses a monolithic kernel, it is relatively modular in that it has well-defined kernel-internal interfaces that make it easy to add new file systems, network protocols, or device drivers. 23 F540 <ref> [97] </ref> AlphaServer 2000 [98] SPECnfs A93 2,230 ops/sec @ 7.7ms 404 ops/sec @ 7.6ms CPU 275MHz 21064A Alpha 275 MHz 21064 Alpha Number of CPUs 1 2 Second-level cache 2MB 4MB Other cache 8MB NVRAM Prestoserve Memory 256MB 1024MB Number of disks 14 25 Table 1.1: SPECnfs Results and System Configurations
Reference: [98] <institution> SPEC. </institution> <note> SPEC newsletter. Manassas, VA, Second Quarter 1996. http://www.specbench.org/osg/sfs93/results/res96q2/. </note>
Reference-contexts: Even though UNIX uses a monolithic kernel, it is relatively modular in that it has well-defined kernel-internal interfaces that make it easy to add new file systems, network protocols, or device drivers. 23 F540 [97] AlphaServer 2000 <ref> [98] </ref> SPECnfs A93 2,230 ops/sec @ 7.7ms 404 ops/sec @ 7.6ms CPU 275MHz 21064A Alpha 275 MHz 21064 Alpha Number of CPUs 1 2 Second-level cache 2MB 4MB Other cache 8MB NVRAM Prestoserve Memory 256MB 1024MB Number of disks 14 25 Table 1.1: SPECnfs Results and System Configurations 1.4.1 Potential For
Reference: [99] <author> Richard M. Stallman. </author> <title> Using and Porting GNU CC, </title> <note> 1992. http://www.delorie.com/gnu/docs/gcc-2.7.2.2/gcc toc.html. </note>
Reference-contexts: The resulting Scout system is so small that it fits entirely into the b-cache and, unless forced (as in some of the tests), there are no b-cache conflicts. All code was compiled using a version of gcc 2.6.0 <ref> [99] </ref> that was modified as necessary to support some of the techniques. 4.1.2 Test Cases As the goal of this study is to test a set of latency improving techniques on protocol stacks that are representative of networking code in general, two protocol stacks are analyzed that differ greatly in design
Reference: [100] <author> Andrew S. Tanenbaum. </author> <title> Computer Networks. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Eaglewood Cliffs, NJ, </address> <note> second edition, 1988. ISBN 0-13-166836-6. </note>
Reference-contexts: The hosts and routers are connected by point-to-point links. How does a pair of hosts, say host 1 and 3, communicate in such a network? If we assume a datagram-oriented network <ref> [100, 76] </ref>, such as the Internet, then host 1 would prepare a message, append the network address of host 3 to the message, and then inject this datagram into the network by sending it to router 1.
Reference: [101] <author> The Scout Team. </author> <title> Scout Programmer's Manual. </title> <institution> Department of Computer Science, University of Arizona, </institution> <address> Tucson, AZ, </address> <year> 1996. </year>
Reference-contexts: The goal of this chapter is to motivate and discuss architectural issues of Scout that are interesting and novel. For a comprehensive and detailed description of the various programming interfaces, the reader is referred to the Scout manual <ref> [101] </ref>. 3.1 Overview Scout is an operating system designed for information appliances such as set-top boxes, or file- and web-servers. It is implemented in C [57], founded on a modular structure and built around the path abstraction which makes it suitable for the communication-oriented nature of appliances.
Reference: [102] <editor> Lucent Technologies. </editor> <booktitle> The Limbo programming language, </booktitle> <year> 1997. </year> <note> http://inferno.lucent.com/inferno/limbo.html. 173 </note>
Reference-contexts: Doing so makes it possible to employ light-weight protection techniques such as software fault-isolation (SFI) or type-safe languages such as Modula-3, Java, or Limbo when protection is all that is desired <ref> [109, 7, 4, 102] </ref>. As appliances are likely to be realized in a single address space, the distinction be 21 tween application and operating system becomes fuzzy. There is nothing wrong with this.
Reference: [103] <author> D. L. Tennenhouse and D. J. Wetherall. </author> <title> Towards an Active Network architecture. </title> <journal> Computer Communication Review, </journal> <volume> 26(2), </volume> <year> 1996. </year> <note> http://www.tns.lcs.mit.edu/publications/ccr96.html. </note>
Reference-contexts: A few examples are discussed next. * IP router: An IP router supporting different quality-of-service on a per-flow basis can exploit paths to ensure proper resource management for each flow. * Active network node: Using Scout to implement nodes in an active network <ref> [103] </ref> allows efficient forwarding of passive packets, yet flexible processing of active packets. <p> Thus, new networking protocols may be needed to support exchanging such meta-path information. An interesting observation is that Scout paths and the virtual circuits they are modeled after appear to be on a course of convergence. Research in active networks <ref> [103] </ref> effectively makes it, at least theoretically, possible to build network routers that perform processing as complex as that in Scout modules.
Reference: [104] <author> Chandramohan A. Thekkath and Henry M. Levy. </author> <title> Limits to low-latency communication on high-speed networks. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 11(2):179203, </volume> <month> May </month> <year> 1993. </year>
Reference-contexts: The LANCE overhead of 47.4s is consistent with the 51s figure reported elsewhere for the same controller in an older generation workstation <ref> [104] </ref>.
Reference: [105] <author> F. Travostino, E. Menze, and F. Reynolds. </author> <title> Paths: Programming with system resources in support of real-time distributed applications. </title> <booktitle> In Proceedings of the 1996 IEEE Workshop on Object-Oriented Real-Time Dependable Systems, </booktitle> <pages> pages 3645, </pages> <address> Laguna Beach, CA, </address> <month> February </month> <year> 1996. </year> <note> IEEE. http://www.osf.org/travos/WORDS96/words96.frame.ps. </note>
Reference-contexts: CORDS is a communication subsystem by the Open Group (formerly Open Software Foundation) that is based on the x-kernel [49]. It employs a path abstraction that is based on early work that lead to the path model proposed here. As such, paths as presented in <ref> [105] </ref> are limited in several ways. First, they are applicable in the communication subsystem only. Second, they do not admit path-oriented code optimizations as discussed in Section 2.4.1. Third, they do not admit paths that are shorter than anticipated or desired. <p> An interesting question is whether it would have been possible to add the path abstraction to the x-kernel. The CORDS system effectively did that with a limited form of paths <ref> [105] </ref>. In this sense, it is possible. However, a problem with adding paths to existing systems is that oftentimes existing 105 abstractions conflict, or at least interfere, with paths. For example, in the case of the x-kernel, there are session objects that serve the role of communication end-points.
Reference: [106] <author> Stephen A. Uhler. </author> <title> MGRa window system for UNIX. </title> <booktitle> In Proceedings of the Fourth Computer Graphics Workshop, </booktitle> <pages> page 106, </pages> <address> Cambridge, MA, </address> <month> October </month> <year> 1987. </year> <note> USENIX. Abstract only. </note>
Reference-contexts: MFLOW Multimedia-oriented flowcontrol protocol. MPEG Implements the MPEG video decompression algorithm. TGA Device driver for DECchip 21030 based frame buffers. KBD Device driver for IBM PC-AT keyboard interface. MOUSE Implements IBM PS/2 mouse protocol. WiMP Window manager with paths: MGR <ref> [106] </ref> derived window manager that supports paths. TERM Terminal emulator. STDIO Translates between C-style stdio streams and Scout paths. This is used for tasks that are not performance critical, such as error logging. Table 5.1: Description of NetTV Modules Interface: Description: aio Asynchronous I/O.
Reference: [107] <author> Robbert van Renesse. </author> <title> Masking the overhead of protocol layering. </title> <booktitle> In Proceedings of SIGCOMM '96 Symposium, </booktitle> <pages> pages 96104, </pages> <address> Stanford, CA, </address> <month> August </month> <year> 1996. </year> <note> ACM. http://www.acm.org/sigcomm/sigcomm96/papers/vanrenesse.html. </note>
Reference-contexts: Examples of code, or fast-path optimizations include Synthesis [60], Synthetix [85], PathIDs [56], Protocol Accelerators <ref> [107] </ref>, and integrated layer processing [16, 1]. Examples in the second category include processor capacity reserves [64], distributed/migrating threads [19, 37], and Rialto activities [52].
Reference: [108] <author> Robbert van Renesse, Ken Birman, Roy Friedman, Mark Hayden, and David Karr. </author> <title> A framework for protocol composition in Horus. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 8089, </pages> <address> Ot-tawa, Canada, </address> <month> August </month> <year> 1995. </year>
Reference-contexts: From early work on layered operating systems and networking architectures [44, 114], to more recent advances in stackable systems <ref> [88, 49, 46, 108] </ref>, modularity has played a central role in managing complexity, isolating failure, and enhancing configurability. Clearly, it is not something that can be discarded lightly. So the question is whether it is possible to avoid the disadvantages of modularity without giving up on its strengths.
Reference: [109] <author> Robert Wahbe, Steven Lucco, Tom Anderson, and Susan Graham. </author> <title> Efficient software-based fault isolation. </title> <booktitle> In Proceedings of the Fourteenth ACM Symposium on Operating System Principles, pages 203216, </booktitle> <address> Asheville, NC, </address> <month> December </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: Doing so makes it possible to employ light-weight protection techniques such as software fault-isolation (SFI) or type-safe languages such as Modula-3, Java, or Limbo when protection is all that is desired <ref> [109, 7, 4, 102] </ref>. As appliances are likely to be realized in a single address space, the distinction be 21 tween application and operating system becomes fuzzy. There is nothing wrong with this. <p> The row labelled Trust assumed shows that the Scout classifier assumes the partial de-mux functions are trusted. To supported untrusted demux functions, Scout would have to employ software fault-isolation <ref> [109] </ref> to sandbox the possibly malicious code. In contrast, the simple DPF filter are provably safe and hence can be supplied by untrusted users. The third row, labelled Static size of code and data compares the static size of the code and data sections required by the two classifiers. <p> For example, Scout and its path abstraction could readily be implemented in a type safe language such as Modula-3 [13] or it could employ sandboxing <ref> [109] </ref> to ensure the safe execution of dynamically loaded native-code modules. In industry, there is a wealth of operating systems that are increasingly targeted at network computers (NCs) which could be considered a form of information appliances.
Reference: [110] <author> Brent B. Welch. </author> <title> The Sprite remote procedure call system. </title> <type> Technical Report UCB/CSD 86/302, </type> <institution> Computer Science Division, EECS Department, University of California, Berkeley, </institution> <month> June </month> <year> 1986. </year> <note> http://sunsite.Berkeley.EDU/NCSTRL/. </note>
Reference-contexts: Module ETH implements the device-independent Ethernet protocol processing and module LANCE implements the driver for the Ethernet adapter present in the DEC 3000 machine. The right hand side of Figure 4.1 shows the RPC stack. It implements a remote procedure call facility similar to Sprite RPC <ref> [110] </ref>. As the figure shows, the RPC stack is 113 considerably taller than the one for TCP/IP. At the top is module XRPCTEST, which is the RPC-equivalent of the ping-pong test implemented by TCPTEST. Modules MSEL-ECT, VCHAN, CHAN, BID and BLAST in combination provide the RPC semantics.
Reference: [111] <author> Mark Wittle and Bruce E. Keith. LADDIS: </author> <title> The next generation in NFS file server benchmarking. </title> <booktitle> In 1993 Summer USENIX Conference Proceedings, </booktitle> <pages> pages 111 128, </pages> <address> Cincinnati, OH, </address> <year> 1993. </year> <note> http://www.specbench.org/osg/sfs93/doc/WhitePaper.ps. 174 </note>
Reference-contexts: For example, Network Appliance manufactures what can be reasonably considered vertically integrated file servers, whereas Digital Equipment is manufacturing relatively modular, UNIX based servers. 2 By comparing the SPEC file server benchmark <ref> [111] </ref> results for one file server from each company, we can provide at least one data-point that directly quantifies the cost of modularity. A price/performance ratio would be easiest to interpret, but prices for computer systems are notoriously volatile and pricing strategies also vary greatly between different companies.
Reference: [112] <author> Alec Wolman, Geoff Voelker, and Chandramohan A. Thekkath. </author> <title> Latency analysis of TCP on an ATM network. </title> <booktitle> In 1994 Winter USENIX Conference Proceedings, </booktitle> <pages> pages 167179, </pages> <address> San Fransisco, CA, </address> <year> 1994. </year>
Reference-contexts: The systems research community has long harbored an intuitive notion of what a path is. For example, it often refers to the fast path through a system <ref> [85, 73, 2, 112] </ref>, implying that the most commonly executed sequence of instructions have been optimized. <p> Specifically, it is targeted at reducing protocol processing latency. The reason for choosing this problem is that optimizing for latency is often considered hard since, in contrast to throughput-oriented optimizations, there is rarely a single dominant latency bottleneck <ref> [55, 112] </ref>. Instead, to improve latency it is typically necessary to improve protocol processing along the entire path of execution [18, 51]. In this sense, the problem is ideally suited to demonstrate some of the potential benefits of Scout paths.
Reference: [113] <author> Masanobu Yuhara, Brian N. Bershad, Chris Maeda, and J. Eliot B. Moss. </author> <title> Efficient packet demultiplexing for multiple endpoints and large messages. </title> <booktitle> In 1994 Winter USENIX Conference Proceedings, </booktitle> <pages> pages 153165, </pages> <address> San Fransico, CA, </address> <year> 1994. </year>
Reference-contexts: Of the many packet classifiers and packet filters that have been proposed in the past, none fit the re 109 quirements of Scout perfectly. For example, interpreted packet filters are generally not fast enough <ref> [113, 61] </ref>. The performance of DPF, a classifier that uses runtime code generation [30] has been reported to be impressive, but unfortunately makes it relatively slow to insert and remove existing filters or, as is the case for version 2.0, provides a language with limited expressiveness.
Reference: [114] <author> Hubert Zimmermann. </author> <title> OSI reference modelthe ISO model of architecture for open systems interconnection. </title> <journal> IEEE Transactions on Communications, </journal> <volume> COM-28(4):425432, </volume> <month> April </month> <year> 1980. </year>
Reference-contexts: From early work on layered operating systems and networking architectures <ref> [44, 114] </ref>, to more recent advances in stackable systems [88, 49, 46, 108], modularity has played a central role in managing complexity, isolating failure, and enhancing configurability. Clearly, it is not something that can be discarded lightly.
References-found: 114

