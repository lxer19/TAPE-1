URL: http://www.cs.ucsb.edu/~schmittm/DA.ps
Refering-URL: http://www.cs.ucsb.edu/~schmittm/res.html
Root-URL: http://www.cs.ucsb.edu
Title: Analytic Performance Prediction of Scientific Computing Applications with  
Author: d d d d d d d d ASAP Diplomarbeit Michael Schmitt 
Affiliation: Technische Universitat Munchen Institut fur Informatik  Lehrstuhl fur Rechnertechnik und Rechnerorganisation  
Abstract-found: 0
Intro-found: 0
Reference: [1] <author> R. Ammar and B. Qin. </author> <title> An Aproach to Derive the Time Cost of Sequential Computations. </title> <journal> In Journal of System Software, </journal> <volume> Vol. 10, No. 3, </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 42 CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 43 graph traversal algorithm was developed at the BRC by Howard Sholl, Reda Ammar and Bin Qin. A detailed description and proof of correctness can be found in <ref> [1] </ref>, [2], [24] and [29]. <p> MEMSFV], MEMSIV, Times [MEMSFV, Plus [END, Times [-1, START]]], Times [Plus [ASGSIV, MEMSFV, MEMSIV, MULSFC], Plus [END, Times [-1, START]]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSFV, Times [3, MEMSIV], MULSFV, Times [3, ARRF [TCE]]]], CALL [TCE], Times [15, Plus [END, Times [-1, START]], LOOP [TCE]], Times [Plus <ref> [1, END, Times [-1, START] </ref>], LOOP [TCE]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSIV, Times [3, MEMSIV], ARRF [TCE], FCT [TCE], AMAX1FUN [TCE], PRMF [TCE], PRMG [TCE]]], INITSUB [TCE], Times [FLAG, Plus [END, Times [-1, START]], Plus [MEMSIV, CALL [TCE], PRMF [TCE], UPDATESUB [TCE]]]]; MAINPRG [FlowPars] := START, END,
Reference: [2] <author> R. Ammar and B. Qin. </author> <title> A Technique to Derive Detailed Time Cost of Parallel Computations. </title> <type> Technical Report, </type> <institution> CSE/CARC-TR-87-30, Computer Science and Engineering Department, University of Con-necticut, Storrs, CT, </institution> <year> 1987. </year>
Reference-contexts: CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 42 CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 43 graph traversal algorithm was developed at the BRC by Howard Sholl, Reda Ammar and Bin Qin. A detailed description and proof of correctness can be found in [1], <ref> [2] </ref>, [24] and [29]. A short description of the algorithm is given here: * Each computation is traversed by its Linked Node list 11 . * The outgoing edges of each node are checked for being independent. * For each independent edge, the corresponding cycle in the graph is sought. <p> OF ASAP 49 (******************************************************* *** Library Package for source file EXAMPLE.F *** *******************************************************) (*** Add EXAMPLE to $ContextPath ***) BeginPackage ["EXAMPLE"]; EndPackage []; (*** Add MAINPRG to $ContextPath ***) BeginPackage ["MAINPRG"]; EndPackage []; (*** Define TCEs, refed comps and flow params for MAINPRG ***) MAINPRG [TCE] ^:= Plus [ASGSIV, Times <ref> [2, MEMSFV] </ref>, MEMSIV, Times [MEMSFV, Plus [END, Times [-1, START]]], Times [Plus [ASGSIV, MEMSFV, MEMSIV, MULSFC], Plus [END, Times [-1, START]]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSFV, Times [3, MEMSIV], MULSFV, Times [3, ARRF [TCE]]]], CALL [TCE], Times [15, Plus [END, Times [-1, START]], LOOP [TCE]], Times [Plus
Reference: [3] <author> ANSI. </author> <title> Programming Language FORTRAN, </title> <type> X3.9-1978. </type> <institution> American Standards Institute, </institution> <address> New York, NY, </address> <year> 1978. </year>
Reference-contexts: Moniot [20] which refers to Appendix F of the ANSI-Standard <ref> [3] </ref>. The grammar covers syntactically the whole standard and allows additionally do while and enddo CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 35 statements. The actions of the parser generate the Computation Flow Graph (CFG) which is depicted in section 4.4. <p> EndPackage []; (*** Define TCEs, refed comps and flow params for MAINPRG ***) MAINPRG [TCE] ^:= Plus [ASGSIV, Times [2, MEMSFV], MEMSIV, Times [MEMSFV, Plus [END, Times [-1, START]]], Times [Plus [ASGSIV, MEMSFV, MEMSIV, MULSFC], Plus [END, Times [-1, START]]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSFV, Times <ref> [3, MEMSIV] </ref>, MULSFV, Times [3, ARRF [TCE]]]], CALL [TCE], Times [15, Plus [END, Times [-1, START]], LOOP [TCE]], Times [Plus [1, END, Times [-1, START]], LOOP [TCE]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSIV, Times [3, MEMSIV], ARRF [TCE], FCT [TCE], AMAX1FUN [TCE], PRMF [TCE], PRMG [TCE]]], INITSUB [TCE], <p> TCEs, refed comps and flow params for MAINPRG ***) MAINPRG [TCE] ^:= Plus [ASGSIV, Times [2, MEMSFV], MEMSIV, Times [MEMSFV, Plus [END, Times [-1, START]]], Times [Plus [ASGSIV, MEMSFV, MEMSIV, MULSFC], Plus [END, Times [-1, START]]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSFV, Times [3, MEMSIV], MULSFV, Times <ref> [3, ARRF [TCE] </ref>]]], CALL [TCE], Times [15, Plus [END, Times [-1, START]], LOOP [TCE]], Times [Plus [1, END, Times [-1, START]], LOOP [TCE]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSIV, Times [3, MEMSIV], ARRF [TCE], FCT [TCE], AMAX1FUN [TCE], PRMF [TCE], PRMG [TCE]]], INITSUB [TCE], Times [FLAG, Plus [END, <p> Times [-1, START]]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSFV, Times <ref> [3, MEMSIV] </ref>, MULSFV, Times [3, ARRF [TCE]]]], CALL [TCE], Times [15, Plus [END, Times [-1, START]], LOOP [TCE]], Times [Plus [1, END, Times [-1, START]], LOOP [TCE]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSIV, Times [3, MEMSIV], ARRF [TCE], FCT [TCE], AMAX1FUN [TCE], PRMF [TCE], PRMG [TCE]]], INITSUB [TCE], Times [FLAG, Plus [END, Times [-1, START]], Plus [MEMSIV, CALL [TCE], PRMF [TCE], UPDATESUB [TCE]]]]; MAINPRG [FlowPars] := START, END, FLAG -; MAINPRG [RefedComps] := Hold [- INITSUB [TCE], UPDATESUB [TCE], AMAX1FUN [TCE] -]; Protect [MAINPRG]; (***
Reference: [4] <author> V. Balasundaram, G. Fox, K. Kennedy and U. Kremer. </author> <title> A Static Performance Estimator to Guide Data Partitioning Decisions. </title> <booktitle> In 3rd ACM SIGPLAN Symposium on Principles and Practice in Parallel Programming (POPP), </booktitle> <address> Williamsburg, VA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: The term training set was first introduced by V. Balasundaram et al. <ref> [4] </ref> to describe a set of micro benchmarks. These compute execution times for single instructions or sequences of instructions corresponding to operations such as high-level language primitives or communication delays. Parameter sensitivity studies imply a different concept.
Reference: [5] <author> T. Bingman. </author> <title> Analytic Performance Prediction of Software Systems. </title> <institution> Master of Science Thesis. Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1996. </year>
Reference-contexts: After starting with source code instrumentation and the Fortran77 parser we depict the Computation Flow Graph (CFG), Flow Balancing and Time Cost Expression (TCE) Derivation. After a brief description of the HLL primitive identification system and the Mathematica post-processing components of Asap which were implemented by Thomas Bingman <ref> [5] </ref>, we finally consider restrictions and inherent limitations of Asap. The chapter is guided by a hypothetical user session, pointing out all necessary steps from instrumenting the source code files to the post-processing of the derived time cost expressions. Chapter 5 contains the experimental validation of Asap. <p> Edges of the graph depict the control flow of the program. The CFG together with the CFG generator are described in detail in section 4.4. 2 The description of the C parser is not part of this thesis. It can be found in <ref> [5] </ref>. CHAPTER 3. CONCEPTS OF ASAP 22 A complicated Flow Balancing technique has to be applied to derive each actual flow on the graph after the single-pass parsing. This technique is discussed in section 4.5. <p> Thomas Bingman developed the C parser which I do not describe here, the HLL primitive identification system and the Mathematica components which I present briefly for the sake of completeness. Further information on these parts are found in Thomas Bingman's Master's Thesis <ref> [5] </ref>. The Fortran77 parser was developed by myself. All other parts were mainly designed by me, but co-developed by both of us. The adjacent sections each describe functional parts of a user session with Asap in chronological order. Following the preliminary Source Code Instrumentation, we introduce the Fortran77 Parsing process. <p> CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 51 the named primitive set cannot be simplified. A more detailed description of Pat is found in <ref> [5] </ref>. 4.7.2 The Masnm System Masnm was developed by Matthias Schumann as part of his own completely Fortran77-based APNM (Abstract Parallel Numerical Machine) performance prediction environment. Masnm measures 179 computation-related 15 primitives which involve the integer, real, double precision, complex and logical data types and all intrinsic functions. <p> It was mainly designed and implemented by Thomas Bingman as described in <ref> [5] </ref>. As yet, this part of Asap consists of a set of Mathematica utility functions that are called from the Mathematica notebook user interface and take the TCE database and the HLL primitive database as input data. <p> A rewritten Masnm system using the Asap-specific data structures and routines from the Pat system is likely the best choice. CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 55 * Restrictions of the Fortran77 parser are mentioned in section 4.3. * Restrictions of the C parser are mentioned in <ref> [5] </ref>. However, since Asap is still an ongoing research project with sufficient funding, these restrictions can be overcome in the future versions (see chapter 6). <p> system and the target programs are compiled using HP's native compiler f77 with optimization level +O0 which enables smart register assignment and constant folding 2 . 1 The validation of the C component of Asap was done by Thomas Bingman on Pentium-based PCs and SUN SPARCstations and is described in <ref> [5] </ref>). 2 Pat is compiled with GNU's gcc at default optimization level (comparable to the +O0 level of f77). CHAPTER 5.
Reference: [6] <author> T. Bingman, B. MacKay, M. Schmitt and M. Havira. Asap: </author> <title> A Tool for Analytic Performance Prediction of Software Systems. </title> <booktitle> To be presented at ISCA 9th International Conference on Computer Applications in Industry and Engineering (CAINE 96), </booktitle> <address> Orlando, FL, </address> <month> Dec </month> <year> 1996. </year>
Reference-contexts: MOTIVATION 3 its symbolical output in a Mathematica 2 -based format which can be utilized by post-processing modules and higher-level tools. An introductory presentation of Asap is given in <ref> [6] </ref>. The research of Thomas Bingman was funded by a research grant of Pandrol Jack-son Technologies, Inc., my research was part of the SEMPA (Software Engineering Methods for Parallel Scientific Applications) project, funded by the bmb+f 3 (Bundesministerium fur Bildung, Wissenschaft, Forschung und Technologie).
Reference: [7] <author> A. Bucherl. </author> <title> Performance Analysis of C/LINDA for Shared Memory Systems. </title> <institution> Master of Science Thesis, Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1995. </year>
Reference-contexts: In 1992 Tcas was extended by Brian Semprebon [26] and Rudi Hackenberg [12] to analyze most of the pre-ANSI C language and in 1994 a further extension carried out by Alois Bucherl <ref> [7] </ref> took place to support C/LINDA. During its lifetime, Tcas was oriented towards shared memory architectures by supporting the typical FORK/JOIN and LOCK/UNLOCK constructs. Tcas supported both the analytic CFG graph model and the simulation as a system model analysis technique.
Reference: [8] <author> M. Peric and G. Scheurer. </author> <title> Cast A Finite Volume Method for Predicting Two-Dimensional Flow and Heat Transfer Phenomena. </title> <institution> Gesellschaft fur Reaktorsicherheit mbH, GRS-Technische Notiz SRR-89-01, </institution> <month> Sep </month> <year> 1989. </year> <note> BIBLIOGRAPHY 66 </note>
Reference-contexts: Cast was developed at the LSTM (Lehrstuhl fur Stromungsmechanik) at the Universitat Erlangen by Milovan Peric and Georg Scheuerer and provides a finite volume method for predicting two-dimensional flow and heat transfer phenomena. Further informations on its functionality and handling are found in <ref> [8] </ref>. The basis for measurement and prediction is one time step of the computation without input and output routines. Due to the size of Cast (over 2000 lines of code were instrumented) we cannot give a detailed look into the process of its usage in the validation procedure.
Reference: [9] <author> J. Cohen. </author> <title> Computer-Assisted Microanalyis of Programs. </title> <journal> In Communications of the ACM, </journal> <volume> 25(10) </volume> <pages> 725-733, </pages> <month> October </month> <year> 1982. </year>
Reference-contexts: Interactive parsing is not much different, as it prompts the user to input the dynamic workload parameters. Intelligent parsing denotes several techniques, such as simple guessing, finite-difference equations over Markov models or expert systems that are to be performed during the parsing process. J. Cohen <ref> [9] </ref> reviews these in detail. Execution profiling delivers a very exact parameter identification, because it obtains its values with the help of software and/or hardware monitors during the execution CHAPTER 2. CONCEPTS OF PERFORMANCE PREDICTION 17 of an instrumented version of the concerning program. L.R.
Reference: [10] <author> T. Fahringer. </author> <title> Automatic Performance Prediction for Parallel Programs on Massively Parallel Computers. </title> <type> Ph.D. Thesis, </type> <institution> Department of Software Technology and Parallel Systems, University of Vienna, Austria, </institution> <year> 1993. </year>
Reference-contexts: Knuth in 1972 [14] the field has evolved in various directions. Different performance prediction application areas have led to different methodologies and design decisions. A huge body of literature has been written on this subject. We refer to Matthias Schu-mann's Ph.D. Thesis [25] and to T. Fahringer's Ph.D.Thesis <ref> [10] </ref> as overviews of contemporary systems. In this chapter we clarify our terminology and describe basic characteristics of performance prediction. Subsequently we state the major requirements that a performance prediction methodology should meet to some extent.
Reference: [11] <author> J. Gray. </author> <title> Mastering Mathematica. AP Professional, </title> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: Ted and Mathematica do not communicate in any other way, since Ted provides its output in the workload database which is read afterwards by the post-processing and analysis utilities. Information about Mathematica in general and MathLink in particular can be found in <ref> [11] </ref> and [19]. The machine database is generated with Pat (HLL Primitive Analysis Tool) developed by Thomas Bingman for identifying C primitives and partly with Masnm (Machine Analyzer of the Abstract Sequential Numeric Machine) developed by Matthias Schumann for identifying Fortran77 primitives. <p> The use of these functions requires a certain proficiency with the Mathematica environment. Comprehensive guides for applying and programming with Mathematica can be found in <ref> [11] </ref> and [18]. A user session for our example program is shown in figure 4.8. The notebook output cells are only shown for the TCEs and for the graph. After loading the script StartUp.m, we have access to the TCE database, the primitive database and all Asap post-processing functions.
Reference: [12] <author> R. Hackenberg. </author> <title> Performance Measurements and Modeling in A Shared Memory Architecture. </title> <institution> Master of Science Thesis, Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1992. </year>
Reference-contexts: At this time Tcas was able to analyze programs written in the Pascal subset CL which made it a tool with design phase orientation, as no compilers exist for this hypothetical Pascal dialect. In 1992 Tcas was extended by Brian Semprebon [26] and Rudi Hackenberg <ref> [12] </ref> to analyze most of the pre-ANSI C language and in 1994 a further extension carried out by Alois Bucherl [7] took place to support C/LINDA. During its lifetime, Tcas was oriented towards shared memory architectures by supporting the typical FORK/JOIN and LOCK/UNLOCK constructs.
Reference: [13] <editor> U. Herzog and R. Klar. Leistungsbewertung von Parallelrechnersyste-men. In K. Waldschmidt, editor, Parallelrechner: Architekturen, Sys-teme, Werkzeuge, </editor> <volume> chapter 12, </volume> <pages> pages 471-516, </pages> <address> B.G. </address> <publisher> Teubner Verlag, Stuttgart, </publisher> <year> 1995. </year>
Reference-contexts: This includes model construction, model integration and model analysis. A general performance prediction concept for system modeling, as proposed by U. Herzog and R. Klar <ref> [13] </ref>, is the the modular approach comprising of the following three models: * Machine model The machine model consists of static and dynamic machine parameters. Static machine parameters describe the structural representation of the target machine.
Reference: [14] <author> D.E. Knuth. </author> <title> Mathematical Analysis of Algorithms. </title> <booktitle> In Proceedings of the 1971 IFIP Congress, </booktitle> <publisher> Elsevier Science, </publisher> <address> New York, NY, </address> <year> 1972. </year>
Reference-contexts: Appendix C shows the validation procedure with the small relax program. Chapter 2 Concepts of Performance Prediction 2.1 Introduction Since the introduction of performance prediction by D.E. Knuth in 1972 <ref> [14] </ref> the field has evolved in various directions. Different performance prediction application areas have led to different methodologies and design decisions. A huge body of literature has been written on this subject. We refer to Matthias Schu-mann's Ph.D. Thesis [25] and to T. <p> []; (*** Add MAINPRG to $ContextPath ***) BeginPackage ["MAINPRG"]; EndPackage []; (*** Define TCEs, refed comps and flow params for MAINPRG ***) MAINPRG [TCE] ^:= Plus [ASGSIV, Times [2, MEMSFV], MEMSIV, Times [MEMSFV, Plus [END, Times [-1, START]]], Times [Plus [ASGSIV, MEMSFV, MEMSIV, MULSFC], Plus [END, Times [-1, START]]], Times <ref> [14, Plus [END, Times [-1, START] </ref>], Plus [ASGSFV, Times [3, MEMSIV], MULSFV, Times [3, ARRF [TCE]]]], CALL [TCE], Times [15, Plus [END, Times [-1, START]], LOOP [TCE]], Times [Plus [1, END, Times [-1, START]], LOOP [TCE]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSIV, Times [3, MEMSIV], ARRF [TCE], FCT <p> START]]], Times [Plus [ASGSIV, MEMSFV, MEMSIV, MULSFC], Plus [END, Times [-1, START]]], Times <ref> [14, Plus [END, Times [-1, START] </ref>], Plus [ASGSFV, Times [3, MEMSIV], MULSFV, Times [3, ARRF [TCE]]]], CALL [TCE], Times [15, Plus [END, Times [-1, START]], LOOP [TCE]], Times [Plus [1, END, Times [-1, START]], LOOP [TCE]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSIV, Times [3, MEMSIV], ARRF [TCE], FCT [TCE], AMAX1FUN [TCE], PRMF [TCE], PRMG [TCE]]], INITSUB [TCE], Times [FLAG, Plus [END, Times [-1, START]], Plus [MEMSIV, CALL [TCE], PRMF [TCE], UPDATESUB [TCE]]]]; MAINPRG [FlowPars] := START, END, FLAG -; MAINPRG [RefedComps] := Hold [- INITSUB
Reference: [15] <author> J. Levine, T. Mason and D. Brown, </author> <title> Lex & Yacc, </title> <publisher> O'Reilley & Associates, Inc., </publisher> <address> Sebastopol, CA, </address> <year> 1995. </year>
Reference-contexts: This will be described in detail in sections 4.4 and 4.5. 4.3 Fortran77 Scanning and Parsing The Fortran77 Scanner and Parser work in a flex/bison environment <ref> [15] </ref> and are inspired by the free software "Fortran Program Checker" by Robert K. Moniot [20] which refers to Appendix F of the ANSI-Standard [3]. The grammar covers syntactically the whole standard and allows additionally do while and enddo CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 35 statements. <p> for MAINPRG ***) MAINPRG [TCE] ^:= Plus [ASGSIV, Times [2, MEMSFV], MEMSIV, Times [MEMSFV, Plus [END, Times [-1, START]]], Times [Plus [ASGSIV, MEMSFV, MEMSIV, MULSFC], Plus [END, Times [-1, START]]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSFV, Times [3, MEMSIV], MULSFV, Times [3, ARRF [TCE]]]], CALL [TCE], Times <ref> [15, Plus [END, Times [-1, START] </ref>], LOOP [TCE]], Times [Plus [1, END, Times [-1, START]], LOOP [TCE]], Times [14, Plus [END, Times [-1, START]], Plus [ASGSIV, Times [3, MEMSIV], ARRF [TCE], FCT [TCE], AMAX1FUN [TCE], PRMF [TCE], PRMG [TCE]]], INITSUB [TCE], Times [FLAG, Plus [END, Times [-1, START]], Plus [MEMSIV, CALL
Reference: [16] <author> B. MacKay. </author> <title> Hierarchical Modeling For Parallel and Distributed Software Applications. </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1996. </year>
Reference-contexts: The design and implementation of Asap affected by its planned incorporation into a hierarchical performance prediction system which is currently developed by Brian MacKay at the BRC (we refer to <ref> [16] </ref>, [17]) form the main part of this thesis. Chapter 2 outlines the terminology, characteristics and basic properties of the field of performance prediction. A classification framework for performance prediction methodologies which was developed at the Lehrstuhl fur Rechnertechnik und Rechnerorganisation, Technische Universitat Munchen (LRR-TUM) is described. <p> the ANSI standard with possible extensions to C++, parallel C dialects, Fortran 90 or HPF (High Performance Fortran). 3.6 Asap as Part of a Hierarchical Methodology A general performance prediction environment for parallel and distributed multiprocessing systems is currently being developed by Brian MacKay as part of his Ph.D. dissertation <ref> [16] </ref> at the BRC. It is based on the HMF (Hierarchical Modeling Framework) methodology. The HMF can be described as a set of models which correspond to the different design abstractions present in software development. The abstractions are denoted as layers in the hierarchical tree-like structure. <p> The system is platform, compiler and source-language-independent and therefore does not require complex porting efforts. Currently, Asap only supports the prediction of sequential programs. Its planned incorporation into the Hierarchical Modeling Framework (HMF) tool set of Brian MacKay <ref> [16] </ref> will enable the analysis of parallel programs. 61 CHAPTER 6. CONCLUSION AND FUTURE RESEARCH 62 6.3 Future Research Up to now one man-year of design and implementation work were constituted for Asap's realization. We optimistically consider the project to be still in a early stage of its life cycle.
Reference: [17] <author> B. MacKay, H. Sholl and R. Ammar. </author> <title> An Overview of Hierarchical Modeling for Parallel/Distributed Software Applications. </title> <booktitle> In ISCA 9th International Conference on Parallel and Distributed Computing Systems (PDCS 96), </booktitle> <address> Dijon, France, </address> <month> Sep </month> <year> 1996. </year>
Reference-contexts: The design and implementation of Asap affected by its planned incorporation into a hierarchical performance prediction system which is currently developed by Brian MacKay at the BRC (we refer to [16], <ref> [17] </ref>) form the main part of this thesis. Chapter 2 outlines the terminology, characteristics and basic properties of the field of performance prediction. A classification framework for performance prediction methodologies which was developed at the Lehrstuhl fur Rechnertechnik und Rechnerorganisation, Technische Universitat Munchen (LRR-TUM) is described. <p> Summarized, as the top of the hierarchical tree structure of HMF the Application Layer provides comprehensive performance metrics of the whole stem, such as utilization of critical resources and overall response time. Further information about the HMF model can be found in <ref> [17] </ref>. Asap clearly provides the functionality required by the lowest layer the Operation Layer as a HLL primitive identification system is part of it. So far, Asap is able to model the computational parts of the Module Layer.
Reference: [18] <author> R. Maeder. </author> <title> Programming in Mathematica. </title> <publisher> Addison-Wesley, </publisher> <address> New York, NY, </address> <year> 1990. </year>
Reference-contexts: The use of these functions requires a certain proficiency with the Mathematica environment. Comprehensive guides for applying and programming with Mathematica can be found in [11] and <ref> [18] </ref>. A user session for our example program is shown in figure 4.8. The notebook output cells are only shown for the TCEs and for the graph. After loading the script StartUp.m, we have access to the TCE database, the primitive database and all Asap post-processing functions.
Reference: [19] <institution> MathLink Reference Guide, </institution> <note> Mathematica Version 2.2, </note> <institution> Wolfram Research, Inc., </institution> <year> 1993. </year> <note> Available from http://www.wri.com/mathsource/. </note>
Reference-contexts: Ted and Mathematica do not communicate in any other way, since Ted provides its output in the workload database which is read afterwards by the post-processing and analysis utilities. Information about Mathematica in general and MathLink in particular can be found in [11] and <ref> [19] </ref>. The machine database is generated with Pat (HLL Primitive Analysis Tool) developed by Thomas Bingman for identifying C primitives and partly with Masnm (Machine Analyzer of the Abstract Sequential Numeric Machine) developed by Matthias Schumann for identifying Fortran77 primitives.
Reference: [20] <author> R.K. Moniot. FTNCHECK. </author> <title> Source code available from the Netlib Repository at http://www.netlib.org. </title>
Reference-contexts: This will be described in detail in sections 4.4 and 4.5. 4.3 Fortran77 Scanning and Parsing The Fortran77 Scanner and Parser work in a flex/bison environment [15] and are inspired by the free software "Fortran Program Checker" by Robert K. Moniot <ref> [20] </ref> which refers to Appendix F of the ANSI-Standard [3]. The grammar covers syntactically the whole standard and allows additionally do while and enddo CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 35 statements. The actions of the parser generate the Computation Flow Graph (CFG) which is depicted in section 4.4.
Reference: [21] <author> L.R. </author> <title> Power. Design and Use of a Program Execution Profiler. </title> <journal> In IBM Systems Journal, </journal> <volume> 23(3) </volume> <pages> 271-294, </pages> <year> 1983. </year> <note> BIBLIOGRAPHY 67 </note>
Reference-contexts: J. Cohen [9] reviews these in detail. Execution profiling delivers a very exact parameter identification, because it obtains its values with the help of software and/or hardware monitors during the execution CHAPTER 2. CONCEPTS OF PERFORMANCE PREDICTION 17 of an instrumented version of the concerning program. L.R. Power <ref> [21] </ref> explains execution profiling techniques thoroughly. * Management modeling The management model is kept very simple in most methodologies.
Reference: [22] <author> B. Qin. </author> <title> Performance Analysis of Parallel Computations. </title> <type> Ph.D. Dissertation, </type> <institution> Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1987. </year>
Reference-contexts: The system model analysis technique is graph analysis as mentioned before. 3.5 History Asap actually evolved from Tcas (Time Cost Analysis System) developed by Bin Qin in 1987 as his Ph.D. dissertation <ref> [22] </ref> at the BRC. At this time Tcas was able to analyze programs written in the Pascal subset CL which made it a tool with design phase orientation, as no compilers exist for this hypothetical Pascal dialect.
Reference: [23] <author> B. Qin, C. Pe and C. Xu. </author> <title> The Design of the Time Cost Analysis System. </title> <institution> Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1988. </year>
Reference-contexts: The simulation mode was necessary to predict shared memory programs incorporating LOCK/UNLOCK constructs, since a solely analytic graph-based technique is not capable of predicting the time cost of queuing for a shared variable operation. Further information on the original Tcas system are found in <ref> [23] </ref> and [28]. Additionally, various projects were performed to include cache performance, i.e. memory hierarchy, communication costs and more advanced machine parameter identification techniques into the prediction system.
Reference: [24] <author> B. Qin, H. Sholl and R. Ammar. </author> <title> Micro Time Cost Analysis of Parallel Computations. </title> <journal> In IEEE Transactions on Computers, </journal> <month> May </month> <year> 1991. </year>
Reference-contexts: CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 42 CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 43 graph traversal algorithm was developed at the BRC by Howard Sholl, Reda Ammar and Bin Qin. A detailed description and proof of correctness can be found in [1], [2], <ref> [24] </ref> and [29]. A short description of the algorithm is given here: * Each computation is traversed by its Linked Node list 11 . * The outgoing edges of each node are checked for being independent. * For each independent edge, the corresponding cycle in the graph is sought.
Reference: [25] <author> M. Schumann. </author> <title> Efficient Performance Prediction for Parallel Programs. </title> <type> PhD Thesis, </type> <institution> Lehrstuhl fur Rechnertechnik und Rechnerorganisation, Technische Universitat Munchen, </institution> <year> 1996. </year>
Reference-contexts: Knuth in 1972 [14] the field has evolved in various directions. Different performance prediction application areas have led to different methodologies and design decisions. A huge body of literature has been written on this subject. We refer to Matthias Schu-mann's Ph.D. Thesis <ref> [25] </ref> and to T. Fahringer's Ph.D.Thesis [10] as overviews of contemporary systems. In this chapter we clarify our terminology and describe basic characteristics of performance prediction. Subsequently we state the major requirements that a performance prediction methodology should meet to some extent. <p> Subsequently we state the major requirements that a performance prediction methodology should meet to some extent. In the remainder of this chapter we illustrate a classification system for performance prediction methodologies, developed at LRR-TUM by Matthias Schumann <ref> [25] </ref>. 2.2 Terms and Properties The description of the following terms utilize the terminology found in [25]: * Target machine A target machine is an architecture for which the prediction is applied. We do not consider parallel or distributed systems in the main part of this work. 5 CHAPTER 2. <p> In the remainder of this chapter we illustrate a classification system for performance prediction methodologies, developed at LRR-TUM by Matthias Schumann <ref> [25] </ref>. 2.2 Terms and Properties The description of the following terms utilize the terminology found in [25]: * Target machine A target machine is an architecture for which the prediction is applied. We do not consider parallel or distributed systems in the main part of this work. 5 CHAPTER 2. <p> to be applied to Asap and in order to be able to compare it to other current work in the field. 2.4 Classification Framework To conclude this chapter we present a classification framework for performance prediction methodologies that was developed by Matthias Schumann as part of his dissertation at LRR-TUM <ref> [25] </ref> 2 . Schumann introduces characteristics based on orthogonal design alternatives for the methodology. The characteristics are assigned certain specific values and grouped as either environmental characteristics or model-related characteristics. <p> CHAPTER 3. CONCEPTS OF ASAP 24 3.4 Classification A classification of the Asap system as a performance prediction methodology after the framework developed by Matthias Schumann <ref> [25] </ref> is presented in table 3.1 3 . 3 Note that only Asap and not the whole planned hierarchical system is classified here. CHAPTER 3. <p> This approach is used for array address calculation, subroutine/function parameters and memory references. Intrinsic functions are measured by computing an average time cost over a typical range of input parameters to the function. A more detailed description of Masnm is found in <ref> [25] </ref>. 4.7.3 The Incorporation of Both Systems into Asap Since the identification of machine parameters has not been part of my original work, I tried to make use of both systems for the experimental evaluation of the Fortran77 part of Asap (see chapter 5).
Reference: [26] <author> B. Semprebon. </author> <title> Performance Prediction of Shared-Memory Systems. </title> <institution> Master of Science Thesis, Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1992. </year>
Reference-contexts: At this time Tcas was able to analyze programs written in the Pascal subset CL which made it a tool with design phase orientation, as no compilers exist for this hypothetical Pascal dialect. In 1992 Tcas was extended by Brian Semprebon <ref> [26] </ref> and Rudi Hackenberg [12] to analyze most of the pre-ANSI C language and in 1994 a further extension carried out by Alois Bucherl [7] took place to support C/LINDA. During its lifetime, Tcas was oriented towards shared memory architectures by supporting the typical FORK/JOIN and LOCK/UNLOCK constructs.
Reference: [27] <author> H. Sholl and T. Booth. </author> <title> Software Performance Modeling Using Computation Structures. </title> <journal> In IEEE Transactions on Software Engineering, </journal> <month> December </month> <year> 1975. </year>
Reference-contexts: The CFG is part of the Computation Structure Model developed at the BRC in UConn by Howard A. Sholl and Taylor Booth <ref> [27] </ref>. In its original form it incorporated the control flow graph of a computation besides and a data flow graph. It has already been used in Asap's predecessor, the Tcas system [28] and other projects at the University of Connecticut.
Reference: [28] <author> H. Sholl, R. Ammar and B. Qin. TCAS: </author> <title> a Time Cost Analysis System for Parallel Computations. </title> <type> Technical Report CSE/CARC-TR-87-48, </type> <institution> Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, </institution> <year> 1987. </year>
Reference-contexts: The simulation mode was necessary to predict shared memory programs incorporating LOCK/UNLOCK constructs, since a solely analytic graph-based technique is not capable of predicting the time cost of queuing for a shared variable operation. Further information on the original Tcas system are found in [23] and <ref> [28] </ref>. Additionally, various projects were performed to include cache performance, i.e. memory hierarchy, communication costs and more advanced machine parameter identification techniques into the prediction system. <p> Sholl and Taylor Booth [27]. In its original form it incorporated the control flow graph of a computation besides and a data flow graph. It has already been used in Asap's predecessor, the Tcas system <ref> [28] </ref> and other projects at the University of Connecticut. The CFG in Asap differs slightly from its prior versions 4 . The CFG consists of nodes which are ordered sequentially by unidirectional edges. Nodes can have multiple incoming and multiple outgoing edges.
Reference: [29] <author> H. Sholl and B. Qin. </author> <title> A Modified Compuation Structure Model to Predict the Time Cost of Parallel Computations. </title> <booktitle> In Proceedings of the International Computer Science Conference, </booktitle> <address> Hongkong, </address> <month> December </month> <year> 1988. </year>
Reference-contexts: CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 42 CHAPTER 4. DESIGN AND IMPLEMENTATION OF ASAP 43 graph traversal algorithm was developed at the BRC by Howard Sholl, Reda Ammar and Bin Qin. A detailed description and proof of correctness can be found in [1], [2], [24] and <ref> [29] </ref>. A short description of the algorithm is given here: * Each computation is traversed by its Linked Node list 11 . * The outgoing edges of each node are checked for being independent. * For each independent edge, the corresponding cycle in the graph is sought.
References-found: 29

