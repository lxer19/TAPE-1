URL: http://www.cs.utah.edu/~cs686/Previous/s96/sw_ft_dsm.ps
Refering-URL: http://www.cs.utah.edu/~cs686/Previous/s96/
Root-URL: 
Title: A Recoverable Distributed Shared Memory Integrating Coherence and Recoverability  
Author: Anne-Marie Kermarrec, Gilbert Cabillic, Alain Gefflaut, Christine Morin, Isabelle Puaut N 
Note: PROGRAMME 1  
Date: Janvier 1995  
Affiliation: INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE  
Abstract-found: 0
Intro-found: 1
Reference: [Ban^atre et al. 91] <author> M. Ban^atre, G. Muller, B. Rochat, and P. Sanchez. </author> <title> Design Decisions for the FTM: A General Purpose Fault Tolerant Machine. </title> <booktitle> In 21st International Symposium on Fault-Tolerant Computing Systems, </booktitle> <address> Montreal, Canada, </address> <month> June </month> <year> 1991. </year>
Reference-contexts: Many proposed stable storage implementations use, either specific hardware devices such as stable memories which are quite expensive, or more conventionnal devices such as disks which are not very efficient and which limit the scalability of the architecture. <ref> [Ban^atre et al. 91, Ban^atre et al. 93, Bernstein 88] </ref>. Unlike these cases, our approach does not require any specific hardware. Instead, the stable storage needed for recovery data is implemented by using the replication mechanisms provided by the standard memories of a DSM.
Reference: [Ban^atre et al. 93] <author> M. Ban^atre, A. Ge*aut, P. Joubert, P.A. Lee, and C. Morin. </author> <title> An Architecture For Tolerating Processor Failures In Shared-Memory Multiprocessors. </title> <note> Research report 1965, INRIA, </note> <month> March </month> <year> 1993. </year>
Reference-contexts: Most recoverable DSM assume the presence of a stable storage device to ensure the stability of recovery data. These stable storages are usually implemented with specific hardware devices such as stable memories <ref> [Ban^atre et al. 93] </ref>, or more conventional devices such as disks. The first solution is efficient but too expensive, especially for large scale systems, whereas the second one is cheap but may rapidly limit the system scalability. <p> For parallel applications, consistent checkpointing is however much more complicated than in a sequential environment since it must take into account the interactions between the processes. Different strategies have already been proposed to ensure that the set of process'checkpoint always form a consistent recovery state <ref> [Ban^atre et al. 93, Janakiraman & Tamir 94] </ref>. In this paper, we adopt a global coordinated checkpoint. The major benefit of this strategy is the simplicity of the algorithm and the fact that it provides a straighforward approach to take a complete recovery line at once. <p> Many proposed stable storage implementations use, either specific hardware devices such as stable memories which are quite expensive, or more conventionnal devices such as disks which are not very efficient and which limit the scalability of the architecture. <ref> [Ban^atre et al. 91, Ban^atre et al. 93, Bernstein 88] </ref>. Unlike these cases, our approach does not require any specific hardware. Instead, the stable storage needed for recovery data is implemented by using the replication mechanisms provided by the standard memories of a DSM.
Reference: [Bernstein 88] <author> P.A. Bernstein. </author> <title> Sequoia: A Fault Tolerant Tightly Coupled Multiprocessor for Transaction Processing. </title> <journal> IEEE Computer, </journal> <note> 1988. INRIA </note>
Reference-contexts: Persistency ensures that recovery data are always accessible by fault-free processors even in spite of a failure. It is usually ensured by replicating recovery data on two failure independant storages <ref> [Bernstein 88] </ref>. Atomic update of recovery data allows to tolerate a failure even during the establishement of a recovery point. It can be physically implemented by a two-phase commit protocol based on data replication. <p> Many proposed stable storage implementations use, either specific hardware devices such as stable memories which are quite expensive, or more conventionnal devices such as disks which are not very efficient and which limit the scalability of the architecture. <ref> [Ban^atre et al. 91, Ban^atre et al. 93, Bernstein 88] </ref>. Unlike these cases, our approach does not require any specific hardware. Instead, the stable storage needed for recovery data is implemented by using the replication mechanisms provided by the standard memories of a DSM.
References-found: 3

