URL: http://e9.ius.cs.cmu.edu:8000/~parag/research/papers/alvinn_tech_rep/alvinn_tech_rep.ps.gz
Refering-URL: http://e9.ius.cs.cmu.edu:8000/~parag/research/publications.html
Root-URL: http://www.cs.cmu.edu
Title: Automated Highway System  
Author: H. Batavia Dean A. Pomerleau Charles E. Thorpe Consortium 
Date: 9 October 1996  
Note: Parag  CMU-RI-TR-96-31 This research was partially supported under a National Science Foundation Graduate Fellowship, the National Highway Traffic Safety Administration (NHTSA) under contract no. DTNH22-93-C-07023, and by USDOT under Cooperative Agreement Number DTFH61-94-X-00001 as part of the National  
Address: Pittsburgh, Pennsylvania 15213-3890  
Affiliation: Robotics Institute Carnegie Mellon University  
Abstract: ALVINN (Autonomous Land Vehicle in a Neural Net) is a Backpropagation trained neural network which is capable of autonomously steering a vehicle in road and highway environments. Although ALVINN is fairly robust, one of the problems with it has been the time it takes to train. As the vehicle is capable of on-line learning, the driver has to drive the car for about 2 minutes before the network is capable of autonomous operation. One reason for this is the use of Backprop. In this report, we describe the original ALVINN system, and then look at three alternative training methods - Quickprop, Cascade Correlation, and Cascade 2. We then run a series of trials using Quickprop, Cascade Correlation and Cascade2, and compare them to a BackProp baseline. Finally, a hidden unit analysis is performed to determine what the network is learning. Applying Advanced Learning Algorithms to ALVINN 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dean Pomerleau, </author> <title> "Neural Network Vision for Robot Driving", Robot Learning, </title> <editor> Ed. J. Connell, S. Mahadevan, </editor> <publisher> Kluwer Publishing, </publisher> <year> 1993. </year>
Reference-contexts: 1. Introduction ALVINN <ref> [1] </ref> (Autonomous Land Vehicle in a Neural Net) is a backprop based neural architecture which has been used to successfully drive a car along a highway at highway speeds. The input to ALVINN is a 30x32 image taken by a camera connected to a digitizer. <p> We also used a 200 element artificially generated balanced training set, along with a similarly balanced 50 element cross validation set. After training, a final evaluation is done with an independent 50 element test set. A complete explanation is given in <ref> [1] </ref>. page 6 4. Learning Algorithms Four different learning algorithms were chosen for investigation: backprop (as a baseline), quickprop, Cascade Correlation, and Cascade II. The next four sections will introduce the algorithms and explain the basic ideas behind their implementations. For a thorough explanation of each method, see [1][6][7][8]. 4.1. <p> It has been suggested [Scott Fahlman, personal communication] that these two algorithms may perform better given a single unit output representation. Therefore, rather than having a 20 unit gaussian output, the network would have a 1 unit linear output, indicating steering direction. It has been shown in <ref> [1] </ref> that a single unit output does not perform as well as a distributed output. What is interesting to note is the obvious effect that the past few years have had on computation speed. The original ALVINN took anywhere from 2 to 3 minutes to train, under similar circumstances. <p> As both one and two lane roads are used in the training set, features should be present which are generic enough to handle both types of roads. A hidden unit analysis of the backprop network is already given in <ref> [1] </ref>, and these results are similar to the ones described below. The original weight diagrams are given in Figures 1-4. Structure is visible, but hard to detect. Therefore, the weight diagrams are modified slightly.
Reference: [2] <author> Dean Pomerleau, RALPH: </author> <title> Rapidly Adapting Lateral Position Handler, </title> <booktitle> IEEE Symposium on Intelligent Vehicles, </booktitle> <year> 1995. </year>
Reference-contexts: The motivation for looking at this is to see whether it is viable to return to actively using ALVINN as a supplement to the RALPH (Rapid Adaptive Lateral Position Handler) <ref> [2] </ref> lane tracking system on Navlab 5. One of the main reasons ALVINN was replaced was the long learning time when dealing with new road conditions, coupled with the requirement of driver intervention during that period.
Reference: [3] <author> Mark Rosenblum and Larry Davis, </author> <title> The Use of a Radial Basis Function Network for Visual Autonomous Road Following, </title> <type> UMD Tech Report CAR-TR-666, </type> <year> 1993 </year>
Reference-contexts: Previous Work There has not been a lot of work in improving ALVINNs training time, although there has been work on improving the robustness and accuracy of ALVINN. Radial Basis Functions (RBFs) have been applied to the ALVINN problem <ref> [3] </ref> with success, but no mention of training time was given. ELVIS (Eigenvectors for Land Vehicle Image System) [4] attempted to discover why ALVINN works. It learned the eigenvectors of an input image and corresponding steering direction using principle components analysis.
Reference: [4] <author> John Hancock and Charles Thorpe, ELVIS: </author> <title> Eigenvectors for Land Vehicle Image System, </title> <type> CMU Tech Report CMU-RI-TR-94-43, </type> <month> December </month> <year> 1994. </year>
Reference-contexts: Radial Basis Functions (RBFs) have been applied to the ALVINN problem [3] with success, but no mention of training time was given. ELVIS (Eigenvectors for Land Vehicle Image System) <ref> [4] </ref> attempted to discover why ALVINN works. It learned the eigenvectors of an input image and corresponding steering direction using principle components analysis. New images were projected into this eigenspace to generate a steering output.
Reference: [5] <author> Todd Jochem, Dean Pomerleau and Chuck Thorpe, MANIAC: </author> <title> A Next Generation Neurally Based Autonomous Road Follower, </title> <booktitle> Proceedings of the International Conference on Intelligent Autonomous Systems: </booktitle> <address> IAS-3," </address> <month> February </month> <year> 1993 </year>
Reference-contexts: New images were projected into this eigenspace to generate a steering output. ELVIS worked nearly as well as ALVINN, demonstrating that a neural network wasnt necessary for this particular task. The MANIAC (Multiple ALVINN Networks in Autonomous Control) <ref> [5] </ref> system improved the robustness of ALVINN by using an architecture which combined the hidden unit outputs of multiple ALVINN networks trained for different road types.
Reference: [6] <author> S. Fahlman and C. Lebiere, </author> <title> "The Cascade-Correlation Learning Architecture," </title> <type> CMU Tech Report CMU-CS-90-100, </type> <month> February </month> <year> 1990. </year>
Reference-contexts: Neither of the above two parameters are very sensitive. For most problems, there is a fairly large range of values which work well. 4.3. Cascade-Correlation Cascade-Correlation (Cascor) is another algorithm developed by Scott Fahlman <ref> [6] </ref>. Cascor was developed to address two problems with backprop: step size, and the moving target problem. The step size problem is the same as discussed in Sec. 3.2.
Reference: [7] <author> S. Fahlman, </author> <title> "An Empirical Study of Learning Speed in Back-Propagation Networks," </title> <type> CMU Tech Report CMU-CS-88-162, </type> <month> June </month> <year> 1988. </year>
Reference-contexts: This is not always optimal, as it may be possible to take much larger steps, which would improve overall learning speed. Methods like momentum and learning rate schedules are some heuristics people have tried to achieve this effect. Scott Fahlmans Quickprop <ref> [7] </ref> takes a different approach. <p> Backprop was second in time and performance, with cascade2 3rd in time but last in performance. Cascor was the opposite, being 3rd in performance, but fourth in time. These results were a surprise. Fahlman <ref> [7] </ref> notes up to a 10x speedup (in epochs) between quickprop and backprop for a 10-5-10 complemented encoder. However, the backprop we used was considerably tweaked to provide the best performance.
Reference: [8] <author> K. Knight, </author> <title> "A Gentle Introduction to Subsymbolic Computation: Connectionism for the A.I. </title> <type> Researcher," CMU Tech Report CMU-CS-89-150, </type> <month> May </month> <year> 1989. </year>
Reference: [9] <author> P. Bakker and J. Wiles, </author> <title> An Animated Study of Learning Dynamics in the 14-2-14 Encoder, </title> <type> U. </type> <institution> of Queensland Tech Report 93-284, </institution> <month> November </month> <year> 1993 </year>
Reference: [10] <author> R. Wallace, A. Stentz, C. Thorpe, H. Moravec, W. Whittaker, T. Kanade, </author> <title> First Results in Robot Road Following, </title> <booktitle> Proceedings of Int. Joint Conf. on Artificial Intelligence, </booktitle> <year> 1985 </year>
Reference-contexts: The network, however, has to be able to deal with situations like this. Therefore, a geometric transform is applied to each captured pattern, adding rotation and translation. A pure pursuit model <ref> [10] </ref> is used to generate the correct steering direction for these artificial patterns. If the required turn is outside the range the network can represent, it is not inserted into the pattern buffer.
Reference: [11] <author> Maybeck, </author> <title> P.S., The Kalman Filter: An Introduction to Concepts, Stochastic Models, Estimation, </title> <journal> and Control, </journal> <volume> Vol. 1, </volume> <pages> 3-16, </pages> <year> 1979 </year>
Reference-contexts: Although RALPH does a very good job of lane-keeping, the above experiments show that it may be feasible to augment RALPH with a newer, faster version of ALVINN. An extended Kalman filter <ref> [11] </ref> or other sensor fusion technique could be used to merge the results of the two processes, as both RALPH and ALVINN can provide the confidence measures required by sensor fusion algorithms.
References-found: 11

