URL: http://www.eecs.umich.edu/techreports/cse/1995/CSE-TR-274-95.ps.gz
Refering-URL: http://www.eecs.umich.edu/home/techreports/cse95.html
Root-URL: http://www.eecs.umich.edu
Email: e-mail:fmathur, aprakashg@eecs.umich.edu  
Title: A Protocol Composition-Based Approach to QoS Control in Collaboration Systems 1  
Author: Amit G. Mathur and Atul Prakash 
Address: Ann Arbor, MI 48109-2122.  
Affiliation: Department of Electrical Engineering and Computer Science University of Michigan  
Abstract: This paper considers the problem of meeting the QoS requirements of media-streams in collaboration systems for use over wide-area networks. The QoS parameters considered, latency, jitter, packet-loss, and asynchrony, are specified and controlled on an end-to-end basis. A QoS control protocol for controlling these parameters is described. The protocol is based on a novel protocol composition-based approach. The basic idea of the approach is to modularize the protocol such that each module controls a single QoS parameter. Further each module is assigned a priority. These modules can then be composed in a number of ways, resulting in a variety of priority assignments to the QoS parameters, thus allowing for more flexible QoS control. The performance of the protocol is evaluated through experiments. The experiments illustrate how the protocol composition approach is able to successfully enforce a priority amongst the QoS parameters, allowing the parameters to be traded-off in an appropriate manner. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> L. Aguilar, J. J. Garcia-Luna-Aceves, D. Moran, E. J. Craighill, and R. Brungart. </author> <title> Architecture for a Multimedia Teleconferencing System. </title> <booktitle> In Proc. of the ACM Sigcomm Symposium, </booktitle> <pages> pages 126-136, </pages> <month> 19 Aug. </month> <year> 1986. </year>
Reference-contexts: Synchronous collaboration, on the other hand, allows collaboration on a common task at the same time [25]. Some of the tasks for which synchronous collaboration has been found very useful include group design, editing, brain-storming, and data visualization. MCS <ref> [1] </ref>, Rapport [2], Etherphone [21], and MMConf [5] are examples of systems that permit such a form of collaboration.
Reference: [2] <author> S. R. Ahuja, J. R. Ensor, and D. N. Horn. </author> <title> The Rapport Multimedia Conferencing System. </title> <booktitle> In Proc. of the Conf. on Office Information Systems, </booktitle> <pages> pages 1-8, </pages> <address> Palo Alto, CA, </address> <month> Mar. </month> <year> 1988. </year>
Reference-contexts: Synchronous collaboration, on the other hand, allows collaboration on a common task at the same time [25]. Some of the tasks for which synchronous collaboration has been found very useful include group design, editing, brain-storming, and data visualization. MCS [1], Rapport <ref> [2] </ref>, Etherphone [21], and MMConf [5] are examples of systems that permit such a form of collaboration. Recently a number of systems such as wb, vat, nevot, nv, ivs, and vic, to name a few, have been used with a great deal of success for collaboration over the Internet [4].
Reference: [3] <author> J. Bolot. </author> <title> End-to-End Packet Delay and Loss Behavior in the Internet. </title> <booktitle> In Proc. of the ACM Sigcomm Symposium, </booktitle> <pages> pages 289-298, </pages> <address> Ithaca, NY, </address> <month> Sept. </month> <year> 1993. </year>
Reference-contexts: The audio and pointer-event packets generated at the source window, were transported over the network, and delivered to the application at the receiver. The packets were subject to network load conditions similar to those observed on the Internet <ref> [3, 20, 23] </ref>. In particular, spikes and sustained variations in network delays, were introduced in both the audio and pointer-event streams (see Figs. 12 and 13).
Reference: [4] <author> S. Casner and S. Deering. </author> <title> First IETF Internet Audiocast. </title> <journal> ACM Sigcomm Computer Communication Review, </journal> <volume> 22(3) </volume> <pages> 92-97, </pages> <month> July </month> <year> 1992. </year>
Reference-contexts: Recently a number of systems such as wb, vat, nevot, nv, ivs, and vic, to name a few, have been used with a great deal of success for collaboration over the Internet <ref> [4] </ref>.
Reference: [5] <author> T. Crowler, P. Milazzo, E. Baka, H. Forsdick, and R. Tomlinson. MMConf: </author> <title> An Infrastructure for Building Shared Multimedia Applications. </title> <booktitle> In Proc. of the 3rd. Conf. on Computer Supported Cooperative Work, </booktitle> <pages> pages 329-342, </pages> <address> Los Angeles, CA, </address> <month> Oct. </month> <year> 1990. </year>
Reference-contexts: Synchronous collaboration, on the other hand, allows collaboration on a common task at the same time [25]. Some of the tasks for which synchronous collaboration has been found very useful include group design, editing, brain-storming, and data visualization. MCS [1], Rapport [2], Etherphone [21], and MMConf <ref> [5] </ref> are examples of systems that permit such a form of collaboration. Recently a number of systems such as wb, vat, nevot, nv, ivs, and vic, to name a few, have been used with a great deal of success for collaboration over the Internet [4].
Reference: [6] <author> L. Delgrossi, C. Halstrick, D. Hehmann, R. G. Herrtwich, O. Krone, J. Sandvoss, and C. Vogt. </author> <title> Media Scaling for Audiovisual Communication with the Heidelberg Transport System. </title> <booktitle> In Proc. of ACM Multimedia 93, </booktitle> <pages> pages 99-104, </pages> <address> Anaheim, CA, </address> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Of Michigan. 1 quality of a collaboration session by five parameters: latency, jitter, packet-loss, asynchrony, and bit--rate. We consider the first four of these parameters in this paper, viz., latency, jitter, packet-loss, and asynchrony. Bit-rate control has been addressed by other researchers (see for e.g., <ref> [6, 7] </ref>) and can be integrated with this work.
Reference: [7] <author> A. Eleftheriadis, S. Pejhan, and D. Anastassiou. </author> <title> Algorithms and Performance Evaluation of the Xphone Multimedia Communication System. </title> <booktitle> In Proc. of ACM Multimedia 93, </booktitle> <pages> pages 311-320, </pages> <address> Anaheim, CA, </address> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: Of Michigan. 1 quality of a collaboration session by five parameters: latency, jitter, packet-loss, asynchrony, and bit--rate. We consider the first four of these parameters in this paper, viz., latency, jitter, packet-loss, and asynchrony. Bit-rate control has been addressed by other researchers (see for e.g., <ref> [6, 7] </ref>) and can be integrated with this work. <p> The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in <ref> [7, 13, 22] </ref>. In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in [8, 24, 22], and these can be adapted to our approach.
Reference: [8] <author> J. Escobar, D. Deutsch, and C. Partridge. </author> <title> Flow Synchronization Protocol. </title> <booktitle> In Proc. IEEE Globecom, </booktitle> <pages> pages 1381-1387, </pages> <year> 1992. </year>
Reference-contexts: However, we are not aware of its use for QoS control. The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. <ref> [8, 13, 20, 22, 11, 24] </ref>). The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. <p> Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in <ref> [8, 24, 22] </ref>, and these can be adapted to our approach. Work on playing back stored media-streams in synchronism (e.g., [14, 19, 11]) are also also related to our work.
Reference: [9] <author> N. C. Hutchinson and L. L. Peterson. </author> <title> The x-Kernel: An architecture for implementing network protocols. </title> <journal> IEEE Trans. on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 64-76, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: It was originally proposed for use with communication protocols such as TCP/IP and RPC in the x-Kernel system <ref> [9] </ref>. It was later used to compose group communication protocols in in the Consul system [17] and recently in the Horus System [26]. However, we are not aware of its use for QoS control.
Reference: [10] <author> E. A. Isaacs and J. C. Tang. </author> <title> What Video Can and Cannot do for Collaboration: A Case Study. </title> <booktitle> In Proc. of ACM Multimedia 93, </booktitle> <address> Anaheim, CA, </address> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: The audio that we are considering is primarily conversational audio. The video that we are considering is used for displaying images of participants and other interesting events <ref> [10] </ref>. The audio manager and video manager modules in each client are responsible for transmitting and receiving audio and video packets, and for controlling the record and playback of audio and video respectively. In addition to the above, a collaboration system needs to maintain certain meta-information about each active session.
Reference: [11] <author> Y. Ishibashi and S. Tasaka. </author> <title> A Synchronization Mechanism for Continuous Media in Multimedia Communications. </title> <booktitle> In Proc. IEEE Infocom 95, </booktitle> <address> Boston, MA, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: However, we are not aware of its use for QoS control. The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. <ref> [8, 13, 20, 22, 11, 24] </ref>). The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. <p> In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in [8, 24, 22], and these can be adapted to our approach. Work on playing back stored media-streams in synchronism (e.g., <ref> [14, 19, 11] </ref>) are also also related to our work. However, since latency is not as much of a concern as in collaboration systems, i.e., stored media-stream playback can tolerate higher latencies, solutions tend to be different.
Reference: [12] <author> V. Jacobson. </author> <title> Congestion Avoidance and Control. </title> <booktitle> In Proc. of the ACM Sigcomm Symposium, </booktitle> <pages> pages 314-329, </pages> <address> Stanford, CA, </address> <month> Aug. </month> <year> 1988. </year>
Reference-contexts: The function compute latcy nw (Fig. 7) does the main work of computing spurt latcy x nw . A running average and variance of the network delay is maintained and these are used to compute spurt latcy x nw in a manner similar to the approach used in <ref> [12, 20] </ref>. In Fig. 7, the function filter computes the average of the network delay (denoted d (x;i) avg ), as a weighted sum of the network delay of the current packet (denoted d (x;i) avg ) and the previous value of the running average (d (x;i1) avg ).
Reference: [13] <author> K. Jeffay, D. L. Stone, and F. D. Smith. </author> <title> Transport and Display Mechanisms for Multimedia Conferencing Across Packet-Switched Networks. </title> <journal> Computer Networks and ISDN Systems, </journal> <volume> 26(10) </volume> <pages> 1281-1304, </pages> <month> July </month> <year> 1994. </year>
Reference-contexts: However, we are not aware of its use for QoS control. The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. <ref> [8, 13, 20, 22, 11, 24] </ref>). The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. <p> The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in <ref> [7, 13, 22] </ref>. In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in [8, 24, 22], and these can be adapted to our approach.
Reference: [14] <author> T. D. C. Little and A. Ghafoor. </author> <title> Synchronization and Storage Models for Multimedia Objects. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 8(3) </volume> <pages> 413-427, </pages> <month> Apr. </month> <year> 1990. </year>
Reference-contexts: In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in [8, 24, 22], and these can be adapted to our approach. Work on playing back stored media-streams in synchronism (e.g., <ref> [14, 19, 11] </ref>) are also also related to our work. However, since latency is not as much of a concern as in collaboration systems, i.e., stored media-stream playback can tolerate higher latencies, solutions tend to be different.
Reference: [15] <author> A. G. Mathur and A. Prakash. </author> <title> Protocols for Integrated Audio and Shared Windows in Collaborative Systems. </title> <booktitle> In Proc. of ACM Multimedia 94, </booktitle> <pages> pages 381-388, </pages> <address> San Francisco, CA, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: A key difference between audio/window-event and audio/video synchronization is the notion of persistent asynchrony <ref> [15] </ref>. Audio and video are continuous media, and if they ever fall out of synchronism due to varying network delays, they will remain out of synchronism unless the synchronization protocol attempts to delay one of the streams or drop packets from one of the streams. <p> This was done to avoid increasing latencies in response to transient asynchronies. In order to determine persistence, we required that the number of pointer-event packets over the monitoring interval be larger than some minimum amount (defined in an application-specific manner) <ref> [15] </ref>. The QoS control modules were composed as shown in Fig. 11. The Packet-Loss module has the highest priority, followed by the Latency-Max module, the Asychrony module, the Latency-Min module, and finally the Jitter module. Results of the experiments are reported in Figs. 12 to 17. <p> The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. [8, 13, 20, 22, 11, 24]). The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in <ref> [15] </ref>. Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in [8, 24, 22], and these can be adapted to our approach.
Reference: [16] <author> D. L. Mills. </author> <title> Internet Time Synchronization: The Network Time Protocol. </title> <journal> IEEE Trans. on Comm., </journal> <volume> 39(10), </volume> <month> Oct. </month> <year> 1991. </year>
Reference-contexts: Note that the source, where packets are generated, and the destination, where they are played back, can be on different machines, with different clocks. We assume that these clocks are kept approximately synchronized through the use of protocols such as NTP <ref> [16] </ref>. The clock skew is denoted by *. We can now formally define latency, jitter, and asynchrony (packet-loss is straightforward and needs no further elaboration). 3.1.1 Latency Latency measures the elapsed time from packet generation to playback.
Reference: [17] <author> S. Mishra, L. L. Peterson, and R. D. Schlichting. </author> <title> Consul: A Communication Substrate for Fault-Tolerant Distributed Programs. </title> <journal> Distributed Systems Engineeering Journal, </journal> <volume> 1(2) </volume> <pages> 87-103, </pages> <month> Dec. </month> <year> 1993. </year> <month> 20 </month>
Reference-contexts: It was originally proposed for use with communication protocols such as TCP/IP and RPC in the x-Kernel system [9]. It was later used to compose group communication protocols in in the Consul system <ref> [17] </ref> and recently in the Horus System [26]. However, we are not aware of its use for QoS control. The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. [8, 13, 20, 22, 11, 24]).
Reference: [18] <author> A. Prakash and H. Shim. DistView: </author> <title> Support for Building Efficient Collaborative Applications using Replicated Objects. </title> <booktitle> In Proc. of the 5th. Conf. on Computer Supported Cooperative Work, </booktitle> <pages> pages 153-164, </pages> <address> Chapel-Hill, NC, </address> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: A shared window typically consists of interface objects, i.e., the objects that make up the user interface, and application objects, i.e., objects that are part of the underlying application <ref> [18] </ref>. Interface objects include windows, buttons, scrollbars, menus, and pointers, whereas application objects include a document being edited, the state of a whiteboard, and images of interest such as X-ray, ultrasound, or upper atmospheric radar images.
Reference: [19] <author> S. Ramanathan and P. V. Rangan. </author> <title> Adaptive Feedback Techniques for Synchronized Multimedia Retrieval over Integrated Networks. </title> <journal> IEEE/ACM Trans. on Networking, </journal> <volume> 1(2) </volume> <pages> 246-260, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in [8, 24, 22], and these can be adapted to our approach. Work on playing back stored media-streams in synchronism (e.g., <ref> [14, 19, 11] </ref>) are also also related to our work. However, since latency is not as much of a concern as in collaboration systems, i.e., stored media-stream playback can tolerate higher latencies, solutions tend to be different.
Reference: [20] <author> R. Ramjee, J. Kurose, D. Towsley, and H. Schulzrinne. </author> <title> Adaptive Playout Mechanisms for Packetized Audio Applications in Wide-Area Networks. </title> <booktitle> In Proc. IEEE Infocom, </booktitle> <address> Toronto, Canada, </address> <year> 1994. </year>
Reference-contexts: The function compute latcy nw (Fig. 7) does the main work of computing spurt latcy x nw . A running average and variance of the network delay is maintained and these are used to compute spurt latcy x nw in a manner similar to the approach used in <ref> [12, 20] </ref>. In Fig. 7, the function filter computes the average of the network delay (denoted d (x;i) avg ), as a weighted sum of the network delay of the current packet (denoted d (x;i) avg ) and the previous value of the running average (d (x;i1) avg ). <p> The audio and pointer-event packets generated at the source window, were transported over the network, and delivered to the application at the receiver. The packets were subject to network load conditions similar to those observed on the Internet <ref> [3, 20, 23] </ref>. In particular, spikes and sustained variations in network delays, were introduced in both the audio and pointer-event streams (see Figs. 12 and 13). <p> However, we are not aware of its use for QoS control. The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. <ref> [8, 13, 20, 22, 11, 24] </ref>). The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered.
Reference: [21] <author> P. V. Rangan and D. C. Swinehart. </author> <title> Software Architecture for Integration of Video Services in the Etherphone System. </title> <journal> IEEE Journal on Selected Areas in Communications, </journal> <volume> 9(9) </volume> <pages> 1395-1404, </pages> <month> Dec. </month> <year> 1991. </year>
Reference-contexts: Synchronous collaboration, on the other hand, allows collaboration on a common task at the same time [25]. Some of the tasks for which synchronous collaboration has been found very useful include group design, editing, brain-storming, and data visualization. MCS [1], Rapport [2], Etherphone <ref> [21] </ref>, and MMConf [5] are examples of systems that permit such a form of collaboration. Recently a number of systems such as wb, vat, nevot, nv, ivs, and vic, to name a few, have been used with a great deal of success for collaboration over the Internet [4].
Reference: [22] <author> K. Rothermel and T. Helbig. </author> <title> An Adaptive Stream Synchronisation Protocol. </title> <booktitle> In Proc. 5th. Intl. Workshop on Networking and Operating System Support for Digital Audio and Video, </booktitle> <address> Durham, NH, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: However, we are not aware of its use for QoS control. The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. <ref> [8, 13, 20, 22, 11, 24] </ref>). The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. <p> The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in <ref> [7, 13, 22] </ref>. In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in [8, 24, 22], and these can be adapted to our approach. <p> Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in <ref> [8, 24, 22] </ref>, and these can be adapted to our approach. Work on playing back stored media-streams in synchronism (e.g., [14, 19, 11]) are also also related to our work.
Reference: [23] <author> D. Sanghi, A. K. Agrawala, O. Gudmundsson, and B. Jain. </author> <title> Experimental Assessment of End-to-End Behavior on Internet. </title> <booktitle> In Proc. IEEE Infocom, </booktitle> <pages> pages 124-131, </pages> <address> San Francisco, CA, </address> <month> March </month> <year> 1993. </year>
Reference-contexts: The audio and pointer-event packets generated at the source window, were transported over the network, and delivered to the application at the receiver. The packets were subject to network load conditions similar to those observed on the Internet <ref> [3, 20, 23] </ref>. In particular, spikes and sustained variations in network delays, were introduced in both the audio and pointer-event streams (see Figs. 12 and 13).
Reference: [24] <author> N. Shivakumar, C.J. Sreenan, B. Narendran, and P. Agrawal. </author> <title> The Concord Algorithm for Synchronization of Networked Multimedia Streams. </title> <booktitle> In Proc. IEEE Intl. Conf. on Multimedia, </booktitle> <address> Washington, D.C., </address> <year> 1995. </year>
Reference-contexts: However, we are not aware of its use for QoS control. The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. <ref> [8, 13, 20, 22, 11, 24] </ref>). The need for synchronizing audio with actions in shared windows and a formalization of this synchronization was reported in [15]. Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. <p> Audio and video synchronization was considered in [7, 13, 22]. In the current version of the protocol, synchronization between pairs of streams is considered. Approaches to synchronizing multiple streams were described in <ref> [8, 24, 22] </ref>, and these can be adapted to our approach. Work on playing back stored media-streams in synchronism (e.g., [14, 19, 11]) are also also related to our work.
Reference: [25] <author> M. Stefik, G. Foster, D. G. Bobrow, K. Kahn, S. Lanning, and L. Suchman. </author> <title> Beyond the Chalkboard: Computer Support for Collaboration and Problem Solving in Meetings. </title> <journal> Comm. of the ACM, </journal> <volume> 30(1) </volume> <pages> 32-47, </pages> <month> Jan. </month> <year> 1987. </year>
Reference-contexts: Email, web browsers such as Mosaic and Netscape, and workflow technologies are examples of systems that support asynchronous collaboration. Synchronous collaboration, on the other hand, allows collaboration on a common task at the same time <ref> [25] </ref>. Some of the tasks for which synchronous collaboration has been found very useful include group design, editing, brain-storming, and data visualization. MCS [1], Rapport [2], Etherphone [21], and MMConf [5] are examples of systems that permit such a form of collaboration.
Reference: [26] <author> R. van Renesse, T. M. Hickey, and K. P. Birman. </author> <title> Design and Performance of Horus: A Lightweight Group Communications System. </title> <type> Technical Report TR94-1442, </type> <institution> Computer Science Dept., Cornell University, </institution> <month> Aug. </month> <year> 1994. </year> <month> 21 </month>
Reference-contexts: It was originally proposed for use with communication protocols such as TCP/IP and RPC in the x-Kernel system [9]. It was later used to compose group communication protocols in in the Consul system [17] and recently in the Horus System <ref> [26] </ref>. However, we are not aware of its use for QoS control. The QoS parameters considered here are essentially similar to those considered by others in the field (e.g. [8, 13, 20, 22, 11, 24]).
References-found: 26

