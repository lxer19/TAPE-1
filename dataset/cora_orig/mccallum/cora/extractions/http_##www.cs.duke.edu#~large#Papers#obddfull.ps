URL: http://www.cs.duke.edu/~large/Papers/obddfull.ps
Refering-URL: http://www.cs.duke.edu/~large/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: The I/O-Complexity of Ordered Binary-Decision Diagram Manipulation  
Author: Lars Arge 
Keyword: I/O-efficient algorithms.  
Date: August 1996  
Address: Aarhus, Denmark  
Affiliation: BRICS Department of Computer Science University of Aarhus  
Abstract: Ordered Binary-Decision Diagrams (OBDD) are the state-of-the-art data structure for boolean function manipulation and there exist several software packages for OBDD manipulation. OBDDs have been successfully used to solve problems in e.g. digital-systems design, verification and testing, in mathematical logic, concurrent system design and in artificial intelligence. The OBDDs used in many of these applications quickly get larger than the avaliable main memory and it becomes essential to consider the problem of minimizing the Input/Output (I/O) communication. In this paper we analyze why existing OBDD manipulation algorithms perform poorly in an I/O environment and develop new 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Aggarwal and J. S. Vitter. </author> <title> The Input/Output complexity of sorting and related problems. </title> <journal> Communications of the ACM, </journal> <volume> 31(9) </volume> <pages> 1116-1127, </pages> <year> 1988. </year>
Reference-contexts: In this paper we analyze why existing OBDD manipulation algorithms perform poorly in an I/O environment and develop new I/O-efficient algorithms. 1.1 I/O Model and Previous Results We will be working in the parallel disk model <ref> [1, 31] </ref> which models the I/O system of many existing workstations. <p> will use the term scanning to describe the fundamental primitive of reading (or writing) all items in a set stored contiguously in external memory by reading (or writing) the blocks of the set in a sequential manner. 2 Early work on external-memory algorithms concentrated on sorting and permutation re-lated problems <ref> [1, 11, 20, 21, 30, 31] </ref>. More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems [10]. <p> Finally, it is demonstrated in [9, 29] that the results obtained in the mentioned papers are not only of theoretical but also of great practical interest. While N=DB is the number of I/Os needed to read all the input, 1 Aggarwal and Vitter <ref> [1] </ref> proved that fi ( N DB log M=B B ) = fi (sort (N )) 2 is the number of I/Os needed to sort N elements. <p> As mentioned in the introduction, Aggarwal and Vitter <ref> [1] </ref> proved a lower bound on the number of I/Os needed to permute N elements. <p> in the model discussed in the introduction, as an I/O reading or writing a portion of two tracks can be simulated with a constant number of I/Os respecting track boundaries. 2.3.2 Pebble I/O Lower Bound on the Reduce Operation In [10] the following generalization of the permutation lower bound from <ref> [1] </ref> is proved: Lemma 1 Let A be an algorithm capable of performing (N !) ff N c different permutations on an input of size N , where 0 &lt; ff 1 and c are constant. Then at least one of these permutations requires fi (perm (N )) I/Os. <p> At the same time we merge the elements with L1 in order to "transfer" the labels of the children to the relevant vertices in L1. Then we proceed like Bryant [7]; we sort the vertices according to the labels of the children (with an I/O optimal sorting algorithm <ref> [1, 31] </ref>), and use the reduction rules to assign new labels. Then we sort the vertices back into their original order, merge the resulting list with L2, and insert the appropriate elements (vertices with a child on level i) in the priority queue|just like after assigning labels to the sinks.
Reference: [2] <author> A. V. Aho, J. E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: In order to analyze their I/O behavior, we in this section sketch the basic algorithm and the different variations of it. The basic reduce algorithm closely follows an algorithm for testing whether two trees are isomorphic <ref> [2] </ref>. The algorithm processes the vertices levelwise from the sinks up to the root, and tries to use the two reduction rules discussed previously on each vertex. <p> The implementations reported in [5, 6, 22, 23] all use this general idea. From a theoretical point of view the table uses a lot of space, namely O (n jGj 2 ), but using "lazy initialization" <ref> [2] </ref> the running time of the algorithm can be kept at O (jGj), as that is the number of entries in the table which is actually used.
Reference: [3] <author> L. Arge. </author> <title> The buffer tree: A new technique for optimal I/O-algorithms. </title> <booktitle> In Proc. Workshop on Algorithms and Data Structures, </booktitle> <volume> LNCS 955, </volume> <pages> pages 334-345, </pages> <year> 1995. </year>
Reference-contexts: Also worth noticing in this context is [18] that addresses the problem of storing graphs in a paging environment, but not the problem of performing computation on them, and <ref> [3] </ref> where a number of external (batched) dynamic data structures are developed. Finally, it is demonstrated in [9, 29] that the results obtained in the mentioned papers are not only of theoretical but also of great practical interest. <p> Our solution to this problem is simple|when a vertex is given a label we "inform" all its immediate predecessors about it in a "lazy" way using an external priority queue developed in <ref> [3] </ref>. On this priority queue we can do a sequence of N insert and deletemin operations in O (sort (N )) I/Os in total. <p> Scanning through N elements can easily be done in O (N=DB) I/Os in the parallel disk model and as already mentioned we can also sort optimally in the model. Furthermore, it is proved in <ref> [3] </ref> that the priority queue can also take full advantage of parallel disks. Both the sorting algorithms and the priority queue on parallel disks work under the (non-restrictive in practice) assumption that 4DB M M 1=2+fi for some 0 &lt; fi &lt; 1=2.
Reference: [4] <author> L. Arge, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory algorithms for processing line segments in geographic information systems. </title> <booktitle> In Proc. Annual European Symposium on Algorithms, </booktitle> <volume> LNCS 979, </volume> <pages> pages 295-310, </pages> <year> 1995. </year> <note> A full version is to appear in special issue of Algorithmica. </note>
Reference-contexts: More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry <ref> [4, 14] </ref> and graph problems [10].
Reference: [5] <author> P. Ashar and M. Cheong. </author> <title> Efficient breadth-first manipulation of binary decision diagrams. </title> <booktitle> In Proc. IEEE International Conference on CAD, </booktitle> <year> 1994. </year>
Reference-contexts: Ordered Binary-Decision Diagrams (OBDDs) [7, 8] are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from all of the above mentioned areas. There exist implementations of OBDD software packages for a number of sequential and parallel machines <ref> [5, 6, 22, 23] </ref>. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> There exist implementations of OBDD software packages for a number of sequential and parallel machines [5, 6, 22, 23]. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. In <ref> [5] </ref> for example, OBDDs of Gigabyte size are manipulated in order to verify logic circuit designs, and researchers in this area would like to be able to manipulate fl An extended abstract version of this paper was presented at the Sixth International Symposium on Algorithms and Computation (ISAAC'95). y This work <p> Very recently however, researchers have instead begun to consider I/O issues arising when the OBDDs get larger than the available internal memory, and experimental results show that very large runtime speedups can be achieved with algorithms that try to minimize the access to external memory as much as possible <ref> [5, 23] </ref>. These speedups can be achieved because of the extremely large access time of external storage medias, such as disks, compared to the access time of internal memory. <p> In [22] a breadth first traversal algorithm with the same time bound is given. Even though the I/O system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [5, 6, 7, 8, 23] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O were developed. <p> This makes the previously developed breadth first algorithm [22] work in a levelwise manner. Implementing the algorithms they obtained runtime speedups of several hundreds compared to an implementation using depth first algorithms. Very recently Ashar and Cheong <ref> [5] </ref> showed how to develop levelwise algorithms without introducing extra vertices, and conducted experiments which showed that on large OBDDs their algorithms outperform all other known algorithms. As the general idea (levelwise algorithms) are the same in [22] and [5], we will only consider the latter paper here. <p> Very recently Ashar and Cheong <ref> [5] </ref> showed how to develop levelwise algorithms without introducing extra vertices, and conducted experiments which showed that on large OBDDs their algorithms outperform all other known algorithms. As the general idea (levelwise algorithms) are the same in [22] and [5], we will only consider the latter paper here. Finally, it should be mentioned that Klar-lund and Rauhe in [16] report significant runtime improvements when working on OBDDs fitting in internal memory and using algorithms taking advantage of the blocked transport of data between cache and main memory. <p> Finally, it should be mentioned that Klar-lund and Rauhe in [16] report significant runtime improvements when working on OBDDs fitting in internal memory and using algorithms taking advantage of the blocked transport of data between cache and main memory. In the algorithms in <ref> [5] </ref> no explicit I/O control is used. Instead the algorithms use a virtual memory space and the I/O operations are done implicitly by the operation system. <p> We believe that the developed algorithms could be of enormous practical value, as the constants in the asymptotic I/O bounds are all small. As mentioned in <ref> [5] </ref> large runtime improvements open up the possibility of creating OBDDs for verifying very large portions of chips, something considered impossible until now. The rest of the paper is organized with a section for each of the OBDD manipulation algorithms. <p> When processing a vertex a lookup is made in the table to see if an isomorphic vertex has already been labeled. If not the vertex is given a new unique label and inserted in the table. The implementations reported in <ref> [5, 6, 22, 23] </ref> all use this general idea. <p> In general an algorithm which scans through the OBDD and distribute the vertices to one of n lists will perform well in practice. As we will discuss below this is precisely the idea used in the algorithm by Ashar and Cheong <ref> [5] </ref>. So let us then assume that we have produced the index lists (and thus a level blocking of 7 4 65 7 9 the OBDD) in a acceptable number of I/Os, and analyze how the different variations of the basic algorithm then perform. <p> This process continues, and it is easy to realize that we do an I/O every time we visit a vertex. Similar examples can be given for depth first and breadth first blockings. The above problem is also realized in <ref> [5] </ref>, and in order to avoid some of the randomness in the memory access the algorithm presented there visits the children in level order. This is accomplished by scanning through the vertices, distributing each of them to two of n lists according to the index (level) of their children. <p> It is difficult to say how many I/Os the basic algorithm uses on this task, as a number of different sorting algorithms could be used and as some of them might actually perform reasonably in an I/O environment. It is however easy to realize that the (hash) table approaches <ref> [5, 8] </ref> perform poorly on large OBDDs, as there is no regular pattern in the access to the table. Also the bucket approach used in [26] performs 8 poorly because of the random pattern in which the (large number of) buckets are accessed. <p> To summarize, all known algorithms use (jGj) I/Os in the worst case to reduce an OBDD of size jGj. As mentioned, this number could be very large compared to the linear or the sorting I/O bounds. There are several reasons why the algorithm in <ref> [5] </ref> still performs so relatively well in practice. We believe that the main reason is that the OBDDs used in the experiments in [5], even though they are large, still are small enough to allow one level of the OBDD to fit in internal memory. <p> As mentioned, this number could be very large compared to the linear or the sorting I/O bounds. There are several reasons why the algorithm in <ref> [5] </ref> still performs so relatively well in practice. We believe that the main reason is that the OBDDs used in the experiments in [5], even though they are large, still are small enough to allow one level of the OBDD to fit in internal memory. This, together with the intuitively correct levelwise blocking and access to the table, results in the large runtime speedups compared to other algorithms. <p> Lemma 4 Reducing a breadth first or depth first blocked OBDD with jGj vertices requires (perm jGj)) pebble I/Os in the worst case. Recall that the OBDDs in <ref> [5] </ref> are level blocked. It is easy to repeat the above proof for a level blocked OBDD and thus Lemma 4 also holds for such blockings. <p> This leads to a breadth first traversal of the involved OBDDs. Also this algorithm uses dynamic programming and runs in O (jG 1 j jG 2 j) time. As previously discussed, I/O issues are then taken into account in <ref> [5] </ref> and an O (jG 1 j jG 2 j) time algorithm working in a levelwise manner is developed. As in the case of the reduce algorithm it is assumed that the OBDDs are stored levelwise and the general idea is then to work as levelwise as possible on them. <p> The advantage of this modified algorithm is that redundant vertices, which would be removed in the following reduction step, is not created and thus space is saved. The algorithms not working in a depth first manner <ref> [5, 22, 23] </ref> cannot perform the reduction as an integrated part of the apply algorithm. 3.2 The I/O-Behavior of Apply Algorithms Like we in Section 2.2 analyzed the existing reduce algorithms in the parallel disk model, we will now analyze the different apply algorithms in the model. <p> end up making a page fault for almost every of the jRj vertices in the new OBDD. 19 a) b) B B B DFS G 2 After illustrating why the breadth first and depth first algorithms perform poorly, let us shortly consider the algorithm especially designed with I/O in mind <ref> [5] </ref>. Recall that this algorithm maintains a request queue for each level of the OBDDs, which also functions as the dynamic programming table divided into levels, and that it processes one level of requests in the order of the levels of the requests issued as a consequence of them. <p> Another important reason is the previously mentioned fact that in practical examples n is much smaller than M=B, which means that a block from each of the n queues fits in internal memory. However, we believe that one major reason for the experimental success in <ref> [5] </ref> is that the OBDDs in the experiments roughly are of the size of the internal memory of the machines used. <p> of the OBDDs actually fits in internal memory, which again explains the good performance because the worst case behavior precisely occurs when one level does not fit in internal memory. 3.3 I/O-Efficient Apply Algorithm The main idea in our new apply algorithm is to do the computation levelwise as in <ref> [5] </ref>, but use a priority queue to control the recursion. Using a priority queue we do not need a queue for each level as in [5]. Furthermore, we do not check for duplicates when new requests are issued, but when they are about to be computed. <p> not fit in internal memory. 3.3 I/O-Efficient Apply Algorithm The main idea in our new apply algorithm is to do the computation levelwise as in <ref> [5] </ref>, but use a priority queue to control the recursion. Using a priority queue we do not need a queue for each level as in [5]. Furthermore, we do not check for duplicates when new requests are issued, but when they are about to be computed. Recall that the main problem with the previous levelwise algorithm precisely is the random lookups in the queues/tables when these checks are made.
Reference: [6] <author> S. K. Brace, R. L. Rudell, and R. E. Bryant. </author> <title> Efficient implementation of a BDD package. </title> <booktitle> In Proc. ACM/IEEE Design Automation Conference, </booktitle> <year> 1990. </year>
Reference-contexts: Ordered Binary-Decision Diagrams (OBDDs) [7, 8] are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from all of the above mentioned areas. There exist implementations of OBDD software packages for a number of sequential and parallel machines <ref> [5, 6, 22, 23] </ref>. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. Until recently most research, both theoretical and practical, has concentrated on finding small OBDD representations of boolean functions appearing in specific problems <ref> [6, 8, 17, 24] </ref>, or on finding alternative succinct representations while maintaining the efficient manipulation algorithms [13]. <p> In [22] a breadth first traversal algorithm with the same time bound is given. Even though the I/O system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [5, 6, 7, 8, 23] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O were developed. <p> When processing a vertex a lookup is made in the table to see if an isomorphic vertex has already been labeled. If not the vertex is given a new unique label and inserted in the table. The implementations reported in <ref> [5, 6, 22, 23] </ref> all use this general idea.
Reference: [7] <author> R. Bryant. </author> <title> Graph-based algorithms for boolean function manipulation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-35(8), </volume> <year> 1986. </year>
Reference-contexts: The efficiency of such solutions depends on the data structures used to represent the boolean functions, and on the algorithms used to manipulate these data structures. Ordered Binary-Decision Diagrams (OBDDs) <ref> [7, 8] </ref> are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from all of the above mentioned areas. There exist implementations of OBDD software packages for a number of sequential and parallel machines [5, 6, 22, 23]. <p> All edges are directed downwards. In <ref> [7] </ref> Bryant proved that for a given variable ordering and a given boolean function there is (up to isomorphism) exactly one OBDD|called the reduced OBDD|of minimal size. <p> The OBDDs in Figure 1 are both reduced. Bryant <ref> [7] </ref> gave an algorithm for reducing an OBDD G with jGj vertices in O (jGj log jGj) time. Later algorithms running in O (jGj) time have been developed [8, 26]. <p> From a computational point of view the fundamental operations are therefore the reduce operation and the apply operation, as we shall call the operation which computes the reduced OBDD for the function obtained by combining two other functions by a binary operator. In <ref> [7] </ref> an O (jG 1 j jG 2 j) time algorithm for using the apply operation on two OBDDs of size jG 1 j and jG 2 j is developed. This algorithm relies on a depth first traversal algorithm. <p> In [22] a breadth first traversal algorithm with the same time bound is given. Even though the I/O system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [5, 6, 7, 8, 23] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O were developed. <p> The reduction algorithm comes in three variants (disregarding I/O issues for now), and the main difference between them is the way they decide if reduction rule R2 can be used on a given vertex. When processing vertices with index i Bryant's original algorithm <ref> [7] </ref> sorts the vertices according to the labels of their children such that vertices which should have assigned the same label end up next to each other in the sorted sequence. <p> Vertices that end up in the same bucket is then assigned the same label. The algorithm runs in O (jGj) time. 2.2 The I/O behavior of Reduce Algorithms The basic reduce algorithm by Bryant <ref> [7] </ref> starts by doing a depth first traversal of the OBDD in order to collect the vertices in lists according to their indices (levels). <p> At the same time we merge the elements with L1 in order to "transfer" the labels of the children to the relevant vertices in L1. Then we proceed like Bryant <ref> [7] </ref>; we sort the vertices according to the labels of the children (with an I/O optimal sorting algorithm [1, 31]), and use the reduction rules to assign new labels. <p> Here f j x i =b denotes the function obtained from f when the argument x i is replaced by the boolean constant b. Using this formula Bryant's algorithm <ref> [7] </ref> works as follows: Consider two functions f 1 and f 2 represented by OBDDs with roots v 1 and v 2 . First, suppose both v 1 and v 2 are sinks. <p> Otherwise, the algorithm continues as described above and adds the root vertex to the table. It is straightforward to realize that Bryant's algorithm runs in O (jG 1 j jG 2 j) time (the size of the dynamic programming table). Note that it is proved in <ref> [7] </ref> that there actually exist reduced OBDDs representing functions f 1 and f 2 such that the size of f 1 f 2 is fi (jG 1 j jG 2 j). Due to the recursive structure Bryant's algorithm works in a depth first manner on the involved OBDDs. <p> In the following jRj will be the size of the un-reduced OBDD resulting from a use of the apply algorithm on two OBDDs of size jG 1 j and jG 2 j, respectively. We first analyze why the depth first <ref> [7] </ref> and breadth first [22] algorithms perform so poorly in an I/O-environment, and then we take a closer look at the algorithms developed with I/O in mind. <p> This results in an overall use of (jRj) I/Os, that is, O (jG 1 jjG 2 j) I/Os in the worst case. It is equally easy to realize that breadth first and level blockings are just as bad for the depth first algorithm <ref> [7] </ref>, and depth first and level blockings just as bad for the breadth first algorithm [22]. So let us assume that the OBDDs are blocked in some "good" way with respect to the used traversal scheme. <p> Still the algorithms perform poorly because of the lack of locality of reference in the lookups in the dynamic programming table. To illustrate this we take a closer look at the depth first algorithm <ref> [7] </ref> assuming that the OBDDs are depth first blocked. Again, if we do not assume anything about the blocking of the dynamic programming table, it is easy to realize that in the worst case every access to the table results in a page fault.
Reference: [8] <author> R. Bryant. </author> <title> Symbolic boolean manipulation with ordered binary-decision diagrams. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(3), </volume> <year> 1992. </year>
Reference-contexts: 1 Introduction Many problems in digital-systems design, verification and testing, mathematical logic, concurrent system design and artificial intelligence can be expressed and solved in terms of boolean functions <ref> [8] </ref>. The efficiency of such solutions depends on the data structures used to represent the boolean functions, and on the algorithms used to manipulate these data structures. <p> The efficiency of such solutions depends on the data structures used to represent the boolean functions, and on the algorithms used to manipulate these data structures. Ordered Binary-Decision Diagrams (OBDDs) <ref> [7, 8] </ref> are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from all of the above mentioned areas. There exist implementations of OBDD software packages for a number of sequential and parallel machines [5, 6, 22, 23]. <p> In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. Until recently most research, both theoretical and practical, has concentrated on finding small OBDD representations of boolean functions appearing in specific problems <ref> [6, 8, 17, 24] </ref>, or on finding alternative succinct representations while maintaining the efficient manipulation algorithms [13]. <p> The OBDDs in Figure 1 are both reduced. Bryant [7] gave an algorithm for reducing an OBDD G with jGj vertices in O (jGj log jGj) time. Later algorithms running in O (jGj) time have been developed <ref> [8, 26] </ref>. <p> In [22] a breadth first traversal algorithm with the same time bound is given. Even though the I/O system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [5, 6, 7, 8, 23] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O were developed. <p> The time complexity of the algorithm is dominated by the time used to sort the vertices, such that the algorithm runs in time O (jGj log jGj). Later, Bryant <ref> [8] </ref> gave an algorithm which instead of sorting the vertices maintain a (hash) table with an entry for each unique vertex seen so far. When processing a vertex a lookup is made in the table to see if an isomorphic vertex has already been labeled. <p> It is difficult to say how many I/Os the basic algorithm uses on this task, as a number of different sorting algorithms could be used and as some of them might actually perform reasonably in an I/O environment. It is however easy to realize that the (hash) table approaches <ref> [5, 8] </ref> perform poorly on large OBDDs, as there is no regular pattern in the access to the table. Also the bucket approach used in [26] performs 8 poorly because of the random pattern in which the (large number of) buckets are accessed. <p> In order to obtain a canonical OBDD all the presented algorithms run the reduce algorithm after constructing a new OBDD with the apply operation. It should be noted that Bryant in <ref> [8] </ref> has modified his depth first algorithm such that the reduction is performed as an integrated part of the apply algorithm. The algorithm simply tries to use the reduction rules after returning from the two recursive calls.
Reference: [9] <author> Y.-J. Chiang. </author> <title> Experiments on the practical I/O efficiency of geometric algorithms: Distribution sweep vs. plane sweep. </title> <booktitle> In Proc. Workshop on Algorithms and Data Structures, </booktitle> <volume> LNCS 955, </volume> <pages> pages 346-357, </pages> <year> 1995. </year>
Reference-contexts: Also worth noticing in this context is [18] that addresses the problem of storing graphs in a paging environment, but not the problem of performing computation on them, and [3] where a number of external (batched) dynamic data structures are developed. Finally, it is demonstrated in <ref> [9, 29] </ref> that the results obtained in the mentioned papers are not only of theoretical but also of great practical interest.
Reference: [10] <author> Y.-J. Chiang, M. T. Goodrich, E. F. Grove, R. Tamassia, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory graph algorithms. </title> <booktitle> In Proc. ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 139-149, </pages> <year> 1995. </year>
Reference-contexts: More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems <ref> [10] </ref>. Other related papers are [27] and [12] that address the problem of computing the transitive closure of a graph under some restrictions on the size of the graph, and propose a framework for studying memory management problems for maintaining connectivity information and paths on graphs, respectively. <p> Later the results have been extended to the general model [20, 19, 30, 31]. In <ref> [10] </ref> it was shown that the permutation lower bound also applies to a large number of fundamental graph problems. <p> However, lower bounds proved in the pebble model also hold in the model discussed in the introduction, as an I/O reading or writing a portion of two tracks can be simulated with a constant number of I/Os respecting track boundaries. 2.3.2 Pebble I/O Lower Bound on the Reduce Operation In <ref> [10] </ref> the following generalization of the permutation lower bound from [1] is proved: Lemma 1 Let A be an algorithm capable of performing (N !) ff N c different permutations on an input of size N , where 0 &lt; ff 1 and c are constant. <p> Then at least one of these permutations requires fi (perm (N )) I/Os. Using this lemma an (perm (N )) lower bound can be shown on the number of I/Os needed to solve the proximate neighbors problem <ref> [10] </ref>. The proximate neighbors problem is 10 defined as follows: Initially, we have N elements in external memory, each with a key that is a positive integer k N=2. Exactly two elements have each possible value of k. <p> Exactly two elements have each possible value of k. The problem is to permute the elements such that, for every k, both elements with k are in the same block. In <ref> [10] </ref> the proximate neighbors problem is used to prove lower bounds on a number of important graph problems. We define a variant of the proximate neighbors problem called the split proximate neighbors problem (SPN).
Reference: [11] <author> T. H. Cormen. </author> <title> Virtual Memory for Data Parallel Computing. </title> <type> PhD thesis, </type> <institution> Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, </institution> <year> 1992. </year>
Reference-contexts: will use the term scanning to describe the fundamental primitive of reading (or writing) all items in a set stored contiguously in external memory by reading (or writing) the blocks of the set in a sequential manner. 2 Early work on external-memory algorithms concentrated on sorting and permutation re-lated problems <ref> [1, 11, 20, 21, 30, 31] </ref>. More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems [10].
Reference: [12] <author> E. Feuerstein and A. Marchetti-Spaccamela. </author> <title> Memory paging for connectivity and path problems in graphs. </title> <booktitle> In Proc. Int. Symp. on Algorithms and Computation, </booktitle> <year> 1993. </year> <month> 23 </month>
Reference-contexts: More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems [10]. Other related papers are [27] and <ref> [12] </ref> that address the problem of computing the transitive closure of a graph under some restrictions on the size of the graph, and propose a framework for studying memory management problems for maintaining connectivity information and paths on graphs, respectively.
Reference: [13] <author> J. Gergov and C. Meinel. </author> <title> Frontiers of feasible and probabilistic feasible boolean manip-ulation with branching programs. </title> <booktitle> In Symposium on Theoretical Aspects of Computer Science, LNCS 665, </booktitle> <year> 1993. </year>
Reference-contexts: Until recently most research, both theoretical and practical, has concentrated on finding small OBDD representations of boolean functions appearing in specific problems [6, 8, 17, 24], or on finding alternative succinct representations while maintaining the efficient manipulation algorithms <ref> [13] </ref>. The limit on the size of the problem instances one has been able to solve in practice has generally been determined by the ability to find representations that fit in internal memory of the machine used to solve the problem.
Reference: [14] <author> M. T. Goodrich, J.-J. Tsay, D. E. Vengroff, and J. S. Vitter. </author> <title> External-memory computational geometry. </title> <booktitle> In Proc. IEEE Symp. on Foundations of Comp. Sci., </booktitle> <pages> pages 714-723, </pages> <year> 1993. </year>
Reference-contexts: More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry <ref> [4, 14] </ref> and graph problems [10].
Reference: [15] <author> J. W. Hong and H. T. Kung. </author> <title> I/O complexity: The red-blue pebble game. </title> <booktitle> In Proc. ACM Symp. on Theory of Computation, </booktitle> <pages> pages 326-333, </pages> <year> 1981. </year>
Reference-contexts: This result is then used to prove an I/O lower bound on the reduce operation. We prove the lower bound for a number of specific blockings. 2.3.1 The (M; B)-Blocked Red-Blue Pebble Game In <ref> [15] </ref> Hung and Kung defined a red-blue pebble game played on directed acyclic graphs in order to define I/O-complexity. In their game there were no notion of blocks.
Reference: [16] <author> N. Klarlund and T. Rauhe. </author> <title> BDD algorithms and cache misses. </title> <type> Technical Report RS-96-26, BRICS, </type> <institution> University of Aarhus, </institution> <year> 1996. </year>
Reference-contexts: As the general idea (levelwise algorithms) are the same in [22] and [5], we will only consider the latter paper here. Finally, it should be mentioned that Klar-lund and Rauhe in <ref> [16] </ref> report significant runtime improvements when working on OBDDs fitting in internal memory and using algorithms taking advantage of the blocked transport of data between cache and main memory. In the algorithms in [5] no explicit I/O control is used.
Reference: [17] <author> S. Malik, A. R. Wang, R. K. Brayton, and A. Sangiovanni-Vincentelli. </author> <title> Logic verification using binary decision diagrams in a logic synthesis environment. </title> <booktitle> In Proc. IEEE International Conference on CAD, </booktitle> <year> 1988. </year>
Reference-contexts: In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. Until recently most research, both theoretical and practical, has concentrated on finding small OBDD representations of boolean functions appearing in specific problems <ref> [6, 8, 17, 24] </ref>, or on finding alternative succinct representations while maintaining the efficient manipulation algorithms [13]. <p> Note that an OBDD representing a boolean function of n variables can be of size 2 n , and that different variable orderings lead to representations of different size. There exist several algorithms (using heuristics) for choosing a variable ordering that minimizes the OBDD representation of a given function <ref> [17, 24] </ref>. 1 We refer to N=DB as the linear number of I/Os. 2 For simplicity we write sort (N) and perm (N), suppressing M; B and D. 3 6 44 2 2 10 1 3 5 2 3 left children are 0-successors and the right 1-successors.
Reference: [18] <author> M. H. Nodine, M. T. Goodrich, and J. S. Vitter. </author> <title> Blocking for external graph searching. </title> <journal> Algorithmica, </journal> <volume> 16(2) </volume> <pages> 181-214, </pages> <year> 1996. </year>
Reference-contexts: Also worth noticing in this context is <ref> [18] </ref> that addresses the problem of storing graphs in a paging environment, but not the problem of performing computation on them, and [3] where a number of external (batched) dynamic data structures are developed.
Reference: [19] <author> M. H. Nodine and J. S. Vitter. </author> <title> Large-scale sorting in parallel memories. </title> <booktitle> In Proc. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 29-39, </pages> <year> 1991. </year>
Reference-contexts: Later the results have been extended to the general model <ref> [20, 19, 30, 31] </ref>. In [10] it was shown that the permutation lower bound also applies to a large number of fundamental graph problems.
Reference: [20] <author> M. H. Nodine and J. S. Vitter. </author> <title> Deterministic distribution sort in shared and distributed memory multiprocessors. </title> <booktitle> In Proc. ACM Symp. on Parallel Algorithms and Architectures, </booktitle> <pages> pages 120-129, </pages> <year> 1993. </year>
Reference-contexts: will use the term scanning to describe the fundamental primitive of reading (or writing) all items in a set stored contiguously in external memory by reading (or writing) the blocks of the set in a sequential manner. 2 Early work on external-memory algorithms concentrated on sorting and permutation re-lated problems <ref> [1, 11, 20, 21, 30, 31] </ref>. More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems [10]. <p> Later the results have been extended to the general model <ref> [20, 19, 30, 31] </ref>. In [10] it was shown that the permutation lower bound also applies to a large number of fundamental graph problems.
Reference: [21] <author> M. H. Nodine and J. S. Vitter. </author> <title> Paradigms for optimal sorting with multiple disks. </title> <booktitle> In Proc. of the 26th Hawaii Int. Conf. on Systems Sciences, </booktitle> <year> 1993. </year>
Reference-contexts: will use the term scanning to describe the fundamental primitive of reading (or writing) all items in a set stored contiguously in external memory by reading (or writing) the blocks of the set in a sequential manner. 2 Early work on external-memory algorithms concentrated on sorting and permutation re-lated problems <ref> [1, 11, 20, 21, 30, 31] </ref>. More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems [10].
Reference: [22] <author> H. Ochi, N. Ishiura, and S. Yajima. </author> <title> Breadth-first manipulation of sbdd of boolean functions for vector processing. </title> <booktitle> In Proc. ACM/IEEE Design Automation Conference, </booktitle> <year> 1991. </year>
Reference-contexts: Ordered Binary-Decision Diagrams (OBDDs) [7, 8] are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from all of the above mentioned areas. There exist implementations of OBDD software packages for a number of sequential and parallel machines <ref> [5, 6, 22, 23] </ref>. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> In [7] an O (jG 1 j jG 2 j) time algorithm for using the apply operation on two OBDDs of size jG 1 j and jG 2 j is developed. This algorithm relies on a depth first traversal algorithm. In <ref> [22] </ref> a breadth first traversal algorithm with the same time bound is given. <p> All known reduce algorithms work in a levelwise manner. 4 OBDD definition) such that the index of successive vertices on any path in an OBDD differs by exactly one. This makes the previously developed breadth first algorithm <ref> [22] </ref> work in a levelwise manner. Implementing the algorithms they obtained runtime speedups of several hundreds compared to an implementation using depth first algorithms. <p> Very recently Ashar and Cheong [5] showed how to develop levelwise algorithms without introducing extra vertices, and conducted experiments which showed that on large OBDDs their algorithms outperform all other known algorithms. As the general idea (levelwise algorithms) are the same in <ref> [22] </ref> and [5], we will only consider the latter paper here. Finally, it should be mentioned that Klar-lund and Rauhe in [16] report significant runtime improvements when working on OBDDs fitting in internal memory and using algorithms taking advantage of the blocked transport of data between cache and main memory. <p> When processing a vertex a lookup is made in the table to see if an isomorphic vertex has already been labeled. If not the vertex is given a new unique label and inserted in the table. The implementations reported in <ref> [5, 6, 22, 23] </ref> all use this general idea. <p> Due to the recursive structure Bryant's algorithm works in a depth first manner on the involved OBDDs. In <ref> [22] </ref> an algorithm algorithm working in a breadth first manner is developed in order to perform OBDD manipulation efficiently on a CRAY-type supercomputer. <p> The advantage of this modified algorithm is that redundant vertices, which would be removed in the following reduction step, is not created and thus space is saved. The algorithms not working in a depth first manner <ref> [5, 22, 23] </ref> cannot perform the reduction as an integrated part of the apply algorithm. 3.2 The I/O-Behavior of Apply Algorithms Like we in Section 2.2 analyzed the existing reduce algorithms in the parallel disk model, we will now analyze the different apply algorithms in the model. <p> In the following jRj will be the size of the un-reduced OBDD resulting from a use of the apply algorithm on two OBDDs of size jG 1 j and jG 2 j, respectively. We first analyze why the depth first [7] and breadth first <ref> [22] </ref> algorithms perform so poorly in an I/O-environment, and then we take a closer look at the algorithms developed with I/O in mind. <p> It is equally easy to realize that breadth first and level blockings are just as bad for the depth first algorithm [7], and depth first and level blockings just as bad for the breadth first algorithm <ref> [22] </ref>. So let us assume that the OBDDs are blocked in some "good" way with respect to the used traversal scheme. Still the algorithms perform poorly because of the lack of locality of reference in the lookups in the dynamic programming table.
Reference: [23] <author> H. Ochi, K. Yasuoka, and S. Yajima. </author> <title> Breadth-first manipulation of very large binary-decision diagrams. </title> <booktitle> In Proc. IEEE International Conference on CAD, </booktitle> <year> 1993. </year>
Reference-contexts: Ordered Binary-Decision Diagrams (OBDDs) [7, 8] are the state-of-the-art data structure for boolean function manipulation and they have been successfully used to solve problems from all of the above mentioned areas. There exist implementations of OBDD software packages for a number of sequential and parallel machines <ref> [5, 6, 22, 23] </ref>. Even though there exist very different sized OBDD representations of the same boolean function, OBDDs in real applications tend to be very large. <p> Very recently however, researchers have instead begun to consider I/O issues arising when the OBDDs get larger than the available internal memory, and experimental results show that very large runtime speedups can be achieved with algorithms that try to minimize the access to external memory as much as possible <ref> [5, 23] </ref>. These speedups can be achieved because of the extremely large access time of external storage medias, such as disks, compared to the access time of internal memory. <p> In [22] a breadth first traversal algorithm with the same time bound is given. Even though the I/O system (the size of the internal memory) seems to be the primary limitation on the size of the OBDD problems one is able to solve practically today <ref> [5, 6, 7, 8, 23] </ref>, it was only very recently that OBDD manipulation algorithms especially designed to minimize I/O were developed. <p> In <ref> [23] </ref> Ochi, Yasuoka and Yajima realized that the traditional depth first and breadth first apply algorithms do not perform well when the OBDDs are too large to fit in internal memory, and they developed alternative algorithms working in a levelwise manner. 3 These algorithms were obtained by adding extra vertices to <p> When processing a vertex a lookup is made in the table to see if an isomorphic vertex has already been labeled. If not the vertex is given a new unique label and inserted in the table. The implementations reported in <ref> [5, 6, 22, 23] </ref> all use this general idea. <p> This effectively means that the dynamic programming table and the request queues are "merged" into one structure. Finally, much like the way the reduce algorithm in <ref> [23] </ref> obtains the new labels of the children of a vertex in level order, the requests on a given level are handled in sorted order according to the levels 18 of the requests issued as a consequence of them. <p> The advantage of this modified algorithm is that redundant vertices, which would be removed in the following reduction step, is not created and thus space is saved. The algorithms not working in a depth first manner <ref> [5, 22, 23] </ref> cannot perform the reduction as an integrated part of the apply algorithm. 3.2 The I/O-Behavior of Apply Algorithms Like we in Section 2.2 analyzed the existing reduce algorithms in the parallel disk model, we will now analyze the different apply algorithms in the model.
Reference: [24] <author> R. Rudell. </author> <title> Dynamic variable ordering for ordered binary decision diagrams. </title> <booktitle> In Proc. IEEE International Conference on CAD, </booktitle> <year> 1993. </year>
Reference-contexts: In such cases the Input/Output (I/O) communication becomes the bottleneck in the computation. Until recently most research, both theoretical and practical, has concentrated on finding small OBDD representations of boolean functions appearing in specific problems <ref> [6, 8, 17, 24] </ref>, or on finding alternative succinct representations while maintaining the efficient manipulation algorithms [13]. <p> Note that an OBDD representing a boolean function of n variables can be of size 2 n , and that different variable orderings lead to representations of different size. There exist several algorithms (using heuristics) for choosing a variable ordering that minimizes the OBDD representation of a given function <ref> [17, 24] </ref>. 1 We refer to N=DB as the linear number of I/Os. 2 For simplicity we write sort (N) and perm (N), suppressing M; B and D. 3 6 44 2 2 10 1 3 5 2 3 left children are 0-successors and the right 1-successors.
Reference: [25] <author> C. Ruemmler and J. Wilkes. </author> <title> An introduction to disk drive modeling. </title> <journal> IEEE Computer, </journal> <volume> 27(3) </volume> <pages> 17-28, </pages> <year> 1994. </year>
Reference-contexts: This will however just increase the significance of the I/O bottleneck since the development of disk technology lacks behind developments in CPU technology. At present, technological advances are increasing CPU speed at an annual rate of 40-60% while disk transfer rates are only increasing by 7-10% annually <ref> [25] </ref>. In this paper we analyze why existing OBDD manipulation algorithms perform poorly in an I/O environment and develop new I/O-efficient algorithms. 1.1 I/O Model and Previous Results We will be working in the parallel disk model [1, 31] which models the I/O system of many existing workstations.
Reference: [26] <author> D. Sieling and I. Wegener. </author> <title> Reduction of obdds in linear time. </title> <journal> Information Processing Letters, </journal> <volume> 48, </volume> <year> 1993. </year>
Reference-contexts: The OBDDs in Figure 1 are both reduced. Bryant [7] gave an algorithm for reducing an OBDD G with jGj vertices in O (jGj log jGj) time. Later algorithms running in O (jGj) time have been developed <ref> [8, 26] </ref>. <p> Finally, the algorithm by Sieling and Wegener <ref> [26] </ref> also sorts the vertices with a given index according to the labels of the children, but uses the bounded size of the label domain to do so with two phases of the well-known bucket sort algorithm. <p> It is however easy to realize that the (hash) table approaches [5, 8] perform poorly on large OBDDs, as there is no regular pattern in the access to the table. Also the bucket approach used in <ref> [26] </ref> performs 8 poorly because of the random pattern in which the (large number of) buckets are accessed. To summarize, all known algorithms use (jGj) I/Os in the worst case to reduce an OBDD of size jGj.
Reference: [27] <author> J. D. Ullman and M. Yannakakis. </author> <title> The input/output complexity of transitive closure. </title> <journal> Annals of Mathematics and Artificial Intellegence, </journal> <volume> 3 </volume> <pages> 331-360, </pages> <year> 1991. </year>
Reference-contexts: More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems [10]. Other related papers are <ref> [27] </ref> and [12] that address the problem of computing the transitive closure of a graph under some restrictions on the size of the graph, and propose a framework for studying memory management problems for maintaining connectivity information and paths on graphs, respectively.
Reference: [28] <author> D. E. Vengroff. </author> <title> A transparent parallel I/O environment. </title> <booktitle> In Proc. 1994 DAGS Symposium on Parallel Computation, </booktitle> <year> 1994. </year> <month> 24 </month>
Reference-contexts: We hope in the future to be able to implement the priority queue data structure in the Transparent Parallel I/O Environment (TPIE) developed by Vengroff <ref> [28] </ref> in order to verify this.
Reference: [29] <author> D. E. Vengroff and J. S. Vitter. </author> <title> I/O-efficient scientific computation using TPIE. </title> <booktitle> In Proc. IEEE Symp. on Parallel and Distributed Computing, </booktitle> <year> 1995. </year> <note> Appears also as Duke University Dept. of Computer Science technical report CS-1995-18. </note>
Reference-contexts: Also worth noticing in this context is [18] that addresses the problem of storing graphs in a paging environment, but not the problem of performing computation on them, and [3] where a number of external (batched) dynamic data structures are developed. Finally, it is demonstrated in <ref> [9, 29] </ref> that the results obtained in the mentioned papers are not only of theoretical but also of great practical interest. <p> As the constants in the I/O bounds on the priority queue operations are all small, the constants in the bounds of the developed OBDD manipulation algorithms are also small. Also it is demonstrated in <ref> [29] </ref> that the overhead required to explicitly manage I/O can be made very small, and therefore we believe that our algorithms could lead to large runtime speedups on existing workstations.
Reference: [30] <author> J. S. Vitter. </author> <title> Efficient memory access in large-scale computation (invited paper). </title> <booktitle> In Symposium on Theoretical Aspects of Computer Science, </booktitle> <volume> LNCS 480, </volume> <pages> pages 26-41, </pages> <year> 1991. </year>
Reference-contexts: will use the term scanning to describe the fundamental primitive of reading (or writing) all items in a set stored contiguously in external memory by reading (or writing) the blocks of the set in a sequential manner. 2 Early work on external-memory algorithms concentrated on sorting and permutation re-lated problems <ref> [1, 11, 20, 21, 30, 31] </ref>. More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems [10]. <p> Later the results have been extended to the general model <ref> [20, 19, 30, 31] </ref>. In [10] it was shown that the permutation lower bound also applies to a large number of fundamental graph problems.
Reference: [31] <author> J. S. Vitter and E. A. M. Shriver. </author> <title> Algorithms for parallel memory, I: Two-level memories. </title> <journal> Algorithmica, </journal> <volume> 12(2-3):110-147, </volume> <year> 1994. </year> <month> 25 </month>
Reference-contexts: In this paper we analyze why existing OBDD manipulation algorithms perform poorly in an I/O environment and develop new I/O-efficient algorithms. 1.1 I/O Model and Previous Results We will be working in the parallel disk model <ref> [1, 31] </ref> which models the I/O system of many existing workstations. <p> will use the term scanning to describe the fundamental primitive of reading (or writing) all items in a set stored contiguously in external memory by reading (or writing) the blocks of the set in a sequential manner. 2 Early work on external-memory algorithms concentrated on sorting and permutation re-lated problems <ref> [1, 11, 20, 21, 30, 31] </ref>. More recently researchers have designed external-memory algorithms for a number of problems in different areas. Most notably I/O-efficient algorithms have been developed for a large number of computational geometry [4, 14] and graph problems [10]. <p> Later the results have been extended to the general model <ref> [20, 19, 30, 31] </ref>. In [10] it was shown that the permutation lower bound also applies to a large number of fundamental graph problems. <p> At the same time we merge the elements with L1 in order to "transfer" the labels of the children to the relevant vertices in L1. Then we proceed like Bryant [7]; we sort the vertices according to the labels of the children (with an I/O optimal sorting algorithm <ref> [1, 31] </ref>), and use the reduction rules to assign new labels. Then we sort the vertices back into their original order, merge the resulting list with L2, and insert the appropriate elements (vertices with a child on level i) in the priority queue|just like after assigning labels to the sinks.
References-found: 31

