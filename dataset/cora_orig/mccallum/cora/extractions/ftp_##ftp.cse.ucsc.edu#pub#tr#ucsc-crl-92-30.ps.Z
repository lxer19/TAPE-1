URL: ftp://ftp.cse.ucsc.edu/pub/tr/ucsc-crl-92-30.ps.Z
Refering-URL: http://www.cse.ucsc.edu/~golding/vita.html
Root-URL: http://www.cse.ucsc.edu
Title: The Performance of Weak-consistency Replication Protocols  
Author: Richard A. Golding Darrell D. E. Long 
Address: Santa Cruz, CA 95064  
Affiliation: Concurrent Systems Laboratory Computer and Information Sciences University of California, Santa Cruz  
Date: July 6, 1992  
Pubnum: UCSC-CRL-92-30  
Abstract: Weak-consistency replication protocols can be used to build wide-area services that are scalable, fault-tolerant, and useful for mobile computer systems. We have developed the timestamped anti-entropy protocol, which provides reliable eventual delivery with a variety of message orderings. Pairs of replicas periodically exchange update messages; in this way updates eventually propagate to all replicas. In this paper we present a detailed analysis of the fault tolerance and the consistency provided by this protocol. The protocol is extremely robust in the face of site and network failure, and it scales well to large numbers of replicas. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. S. Quarterman and J. C. Hoskins, </author> <title> Notable computer networks, </title> <journal> Communications of the ACM, </journal> <volume> vol. 29, </volume> <pages> pp. 932-71, </pages> <month> October </month> <year> 1986. </year> <month> 14 </month>
Reference-contexts: Instead, updates are first delivered to one site, then propagated asynchronously to others. The value a server returns to a client read request depends on whether that server has observed the update yet. Eventually, every server will observe the update. Several existing information systems, such as Usenet <ref> [1] </ref> and the Xerox Grapevine system [2], use similar techniques. Delayed propagation means that clients do not wait for updates to reach distant sites, and the fault-tolerance of the replicated data cannot be compromised by clients that misbehave.
Reference: [2] <author> M. D. Schroeder, A. D. Birrell, and R. M. Needham, </author> <title> Experience with Grapevine: the growth of a distributed system, </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> vol. 2, </volume> <pages> pp. 3-23, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: The value a server returns to a client read request depends on whether that server has observed the update yet. Eventually, every server will observe the update. Several existing information systems, such as Usenet [1] and the Xerox Grapevine system <ref> [2] </ref>, use similar techniques. Delayed propagation means that clients do not wait for updates to reach distant sites, and the fault-tolerance of the replicated data cannot be compromised by clients that misbehave. <p> In particular, there is a non-zero probability that two processes have received all the same messages, and all processes are 3 guaranteed to agree in finite but unbounded time if no further messages are sent. Grapevine <ref> [2] </ref> was one of the first wide-area systems to use weak consistency. In that system, replicated data was first updated at one site, then the results were propagated to other sites in the background. Updates were propagated three ways.
Reference: [3] <author> R. A. Golding, </author> <title> Accessing replicated data in a large-scale distributed system, </title> <type> Master's thesis, </type> <institution> Computer and Information Sciences Board, University of California at Santa Cruz, </institution> <month> June </month> <year> 1991. </year> <note> Published as Tech. Rep. UCSC-CRL-91-18. </note>
Reference-contexts: For example, two hosts on an Ethernet can exchange a pair of datagrams in a few milliseconds, while two hosts on the same continent may require 50-200 milliseconds. Hosts on different continents can require even longer. Packet loss rates of 40% are common, and can go much higher <ref> [3] </ref>. The Internet has many single points of failure, and at any given time it is usually partitioned into several non-communicating networks. This is a difficult environment for building distributed applications. The application must also handle the vast number of users that can access a widely-available service.
Reference: [4] <author> D. D. E. Long, J. L. Carroll, and C. J. Park, </author> <title> A study of the reliability of Internet sites, </title> <booktitle> in Proceedings of 10th IEEE Symposium on Reliable Distributed Systems, </booktitle> <pages> pp. 177-86, </pages> <month> September </month> <year> 1991. </year>
Reference-contexts: This is a difficult environment for building distributed applications. The application must also handle the vast number of users that can access a widely-available service. The Internet now includes more than 900 000 hosts <ref> [4] </ref>; the potential user base is in the millions, and these numbers are expected to increase rapidly. The archie anonymous FTP location service reported on the order of 10 000 queries per day (0.12 queries per second) using two servers in November 1991 [5].
Reference: [5] <author> A. Emtage and P. Deutsch, </author> <title> archie an electronic directory service for the Internet, </title> <booktitle> in Proceedings of Winter 1992 Usenix Conference, </booktitle> <pages> pp. 93-110, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: The archie anonymous FTP location service reported on the order of 10 000 queries per day (0.12 queries per second) using two servers in November 1991 <ref> [5] </ref>. Services used by a wider audience would observe load several orders of magnitude greater. We expect to find services in 1 the near future processing several hundred queries per second, a greater load than can be handled by single computer systems or individual network links.
Reference: [6] <author> J. J. Kistler and M. Satyanarayanan, </author> <title> Disconnected operation in the Coda file system, </title> <booktitle> in Proceedings of 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. 213-25, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: This is an especially difficult expectation to meet on portable systems, where the system may be disconnected from the network for a long time or may be semi-connected by an expensive low-bandwidth connection. Several researchers are investigating file systems that can tolerate disconnection <ref> [6, 7] </ref>. We assume that server processes have access to pseudo-stable storage such as magnetic disk that will not be affected by a system crash. Sites also have loosely synchronized clocks.
Reference: [7] <author> R. Alonso, D. Barbar a, and L. L. Cova, </author> <title> Using stashing to increase node autonomy in distributed file systems, </title> <booktitle> in Proceedings of 9th IEEE Symposium on Reliable Distributed Systems, </booktitle> <month> October </month> <year> 1990. </year>
Reference-contexts: This is an especially difficult expectation to meet on portable systems, where the system may be disconnected from the network for a long time or may be semi-connected by an expensive low-bandwidth connection. Several researchers are investigating file systems that can tolerate disconnection <ref> [6, 7] </ref>. We assume that server processes have access to pseudo-stable storage such as magnetic disk that will not be affected by a system crash. Sites also have loosely synchronized clocks.
Reference: [8] <author> L. Lamport, </author> <title> Time, clocks, and the ordering of events in a distributed system, </title> <journal> Communications of the ACM, </journal> <volume> vol. 21, no. 7, </volume> <pages> pp. 558-65, </pages> <year> 1978. </year>
Reference-contexts: A total ordering means that all processes will see the same messages in the same order, though that order will not necessarily be the order messages were sent. Causal ordering implies that any messages with a potential causal relation will be delivered in the same order at all replicas <ref> [8, 9] </ref>. Messages with no causal relation can be delivered in different orders at different processes. A bound inconsistency ordering ensures that the database at one site never differs from the correct global value by more than a constant [10, 11]. <p> As mentioned earlier, many different message delivery orders are possible. A total ordering is strongest, and ensures that all replicas will process all updates in the same order. This can be done by delivering messages in the order of their timestamps. When site clocks follow Lamport's happens-before condition <ref> [8] </ref>, this order will respect causality as well. A message can be delivered at a replica when the summary vector has no timestamps less than the message timestamp. FIFO channel ordering results when messages from each replica are sorted by timestamp.
Reference: [9] <author> R. Ladin, B. Liskov, and L. Shrira, </author> <title> Lazy replication: exploiting the semantics of distributed services, </title> <journal> Operating Systems Review, </journal> <volume> vol. 25, </volume> <pages> pp. 49-55, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: A total ordering means that all processes will see the same messages in the same order, though that order will not necessarily be the order messages were sent. Causal ordering implies that any messages with a potential causal relation will be delivered in the same order at all replicas <ref> [8, 9] </ref>. Messages with no causal relation can be delivered in different orders at different processes. A bound inconsistency ordering ensures that the database at one site never differs from the correct global value by more than a constant [10, 11].
Reference: [10] <author> C. Pu and A. Leff, </author> <title> Replica control in distributed systems: an asynchronous approach, </title> <type> Tech. Rep. </type> <institution> CUCS-053-090, Department of Computer Science, Columbia University, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: Messages with no causal relation can be delivered in different orders at different processes. A bound inconsistency ordering ensures that the database at one site never differs from the correct global value by more than a constant <ref> [10, 11] </ref>. Weaker orderings include a per-process or FIFO channel ordering, where the messages from any particular process are delivered in order, but the streams of messages from different processes may be interleaved arbitrarily.
Reference: [11] <author> D. Barbar a and H. Garcia-Molina, </author> <title> The case for controlled inconsistency in replicated data, </title> <booktitle> in Proceedings of the Workshop on the Management of Replicated Data, </booktitle> <pages> pp. 35-8, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: Messages with no causal relation can be delivered in different orders at different processes. A bound inconsistency ordering ensures that the database at one site never differs from the correct global value by more than a constant <ref> [10, 11] </ref>. Weaker orderings include a per-process or FIFO channel ordering, where the messages from any particular process are delivered in order, but the streams of messages from different processes may be interleaved arbitrarily.
Reference: [12] <author> J. Turek and D. Shasha, </author> <title> The many faces of consensus in distributed systems, </title> <journal> IEEE Computer, </journal> <volume> vol. 25, </volume> <pages> pp. 8-17, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The communication protocol can deliver messages synchronously, within a bounded time, or eventually in a finite but unbounded time. Strong consistency requirements are impossible to meet in the most general cases. For example, if there are no bounds on message delivery time it is not possible to guarantee consistency <ref> [12] </ref>. Further, if processes can fail in arbitrary ways, providing reliable delivery is equivalent to Byzantine Agreement. For most applications the Internet can be treated as an unreliable, bounded, broadcast (as opposed to strict point-to-point) network.
Reference: [13] <author> R. A. Golding, </author> <title> The timestamped anti-entropy weak-consistency group communication protocol, </title> <type> Tech. Rep. </type> <institution> UCSC-CRL-92-29, Computer and Information Sciences Board, University of California at Santa Cruz, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: Finally, pairs of sites would periodically exchange all known updates in an anti-entropy session until they were mutually consistent. Of the three methods, only anti-entropy guaranteed delivery to all sites. 2.2 Timestamped anti-entropy We have developed a new group communication protocol that provides reliable, eventual delivery, called timestamped anti-entropy <ref> [13] </ref>. Since the protocol is fault tolerant, messages will be delivered to every process in the group even if processes temporarily fail or are disconnected from the network. We have also developed a related group membership mechanism that handles adding and removing processes from the replica group [14].
Reference: [14] <author> R. A. Golding and K. Taylor, </author> <title> Group membership in the epidemic style, </title> <type> Tech. Rep. </type> <institution> UCSC-CRL-92-13, Computer and Information Sciences Board, University of California at Santa Cruz, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Since the protocol is fault tolerant, messages will be delivered to every process in the group even if processes temporarily fail or are disconnected from the network. We have also developed a related group membership mechanism that handles adding and removing processes from the replica group <ref> [14] </ref>. The tradeoffs are that the protocol may have to delay message delivery (it is a blocking protocol), that replicas must maintain logs on disk that are not compromised by failure and recovery, and that timestamp information must be appended to every message.
Reference: [15] <author> D. Agrawal and A. Malpani, </author> <title> Efficient dissemination of information in computer networks, </title> <journal> Computer Journal, </journal> <volume> vol. 34, </volume> <pages> pp. 534-41, </pages> <month> December </month> <year> 1991. </year>
Reference-contexts: This alternate protocol was discovered independently by Agrawal and Malpani <ref> [15] </ref>. 4 The session ends with an exchange of acknowledgment messages. If any step of the exchange fails, either process can abort the session. At the end of a successful session, both processes have received the same set of messages.
Reference: [16] <author> A. Demers, D. Greene, C. Hauser, W. Irish, J. Larson, S. Shenker, H. Sturgis, D. Swinehart, and D. Terry, </author> <title> Epidemic algorithms for replicated database maintenance, </title> <journal> Operating Systems Review, </journal> <volume> vol. 22, </volume> <pages> pp. 8-32, </pages> <month> January </month> <year> 1988. </year>
Reference-contexts: Distance-biased partner selection attempts to avoid long-distance communication as much as possible by weighting the chances of randomly selecting a partner based on its distance. Distance biasing was studied as an optimization for Grapevine <ref> [16] </ref>.
Reference: [17] <author> P. Mockapetris, </author> <title> Domain names concepts and facilities, </title> <type> Tech. Rep. RFC 1034, </type> <institution> ARPA Network Working Group, </institution> <month> November </month> <year> 1987. </year>
Reference-contexts: Many wide-area services have extremely low update rates; some services write new entries and never change them. A low update rate means that anti-entropy has a better chance of propagating an update before another update enters the system. In the Domain Name Service <ref> [17] </ref>, a host name or address rarely changes more than once every few months. In other databases new entries are added, corrected quickly, then remain stable. We expect the update rate for a single database entry to be about a thousand times lower than the anti-entropy rate.
Reference: [18] <author> N. Alon, A. Barak, and U. Manber, </author> <title> On disseminating information reliably without broadcasting, </title> <booktitle> in Proceedings of 7th International Conference on Distributed Computing Systems, </booktitle> <pages> pp. 74-81, </pages> <year> 1987. </year> <month> 15 </month>
Reference-contexts: We are encouraged by the performance of the distance-biased partner selection policy. Similar policies can be used in the Internet to encourage traffic between nearby sites and to avoid saturating long-distance links. The random policy appears to be within a constant factor of optimal <ref> [18] </ref>. We are investigating its optimality, as well as several other selection policies. Acknowledgments John Wilkes, of the Concurrent Systems Project at Hewlett-Packard Laboratories, and Kim Taylor, of UC Santa Cruz, assisted the initial development of these protocols.
References-found: 18

