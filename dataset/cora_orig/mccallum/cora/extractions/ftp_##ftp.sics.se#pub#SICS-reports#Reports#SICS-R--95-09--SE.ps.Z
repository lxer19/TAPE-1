URL: ftp://ftp.sics.se/pub/SICS-reports/Reports/SICS-R--95-09--SE.ps.Z
Refering-URL: http://www.sics.se/libindex.html
Root-URL: 
Title: Best Probability of Activation and Performance Comparisons for Several Designs of Sparse Distributed Memory  
Author: Jan Kristoferson 
Keyword: Sparse Distributed Memory, Probability of Activation, Performance  
Note: Contents  
Address: Box 1263, S164 28 KISTA, SWEDEN  
Affiliation: RWCP 1 Neuro SICS 2 Laboratory  
Email: Email: janke@sics.se  
Phone: Phone +46 8 752 15 00 Fax +46 8 751 72 30  
Date: November 30, 1995  
Abstract: Report R95:09 ISRN : SICS-R-95/09-SE ISSN : 0283-3638 Abstract The optimal probability of activation and the corresponding performance is studied for three designs of Sparse Distributed Memory, namely, Kanerva's original design, Jaeckel's selected-coordinates design and Karlsson's modifi - cation of Jaeckel's design. We will assume that the hard locations (in Karlsson's case, the masks), the storage addresses and the stored data are randomly chosen, and we will consider different levels of random noise in the reading address. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Kanerva, </author> <title> Pentti Sparse Distributed Memory and Related Models. In Associative Neural Memories. Theory and Implementation. Edited by Mohamad H. </title> <publisher> Hassoun. Oxford University Press. </publisher> <year> 1993. </year>
Reference-contexts: 1. Introduction We will look at Kanerva's original design of Sparse Distributed Memory, Jaeckel's design, and a modification of Jaeckel's design invented by Roland Karlsson at SICS, having great implementation advantages for simulations on a sequential computer. For a general discussion of these different designs see Kanerva <ref> [1] </ref>, Jaeckel [2], and Karlsson [3]. The performance of the different designs will be studied assuming that 1. the hard locations in the memory, the data and the addresses for storing data are randomly chosen, 2. the reading procedure is the standard one (used in [1] and [2]; better performance can <p> these different designs see Kanerva <ref> [1] </ref>, Jaeckel [2], and Karlsson [3]. The performance of the different designs will be studied assuming that 1. the hard locations in the memory, the data and the addresses for storing data are randomly chosen, 2. the reading procedure is the standard one (used in [1] and [2]; better performance can be achieved with other reading procedu res, being investigated in Sjdin [4]), 3. the reading address may be disturbed (i.e., it may contain noise). In particular, we will consider the question of determining the optimal probability p of activation. <p> In particular, we will consider the question of determining the optimal probability p of activation. For his original design of the memory, Kanerva <ref> [1] </ref> derived a formula for the optimal p, when reading at the exact address. We will see how the optimal p changes when looking at the other designs, and when the reading address is disturbed. We will also calculate performance for optimal p . <p> Observe that p = 2 -N , k=0 R N ) for Kanerva's design and p = 2 -K for the other two designs. 3. The error probability and the signal-to-noise ratio The material in this section is well-known from <ref> [1] </ref> and [2]. Define the stochastic variables L t = the number of hard locations activated by both Y and X t , t = 0, 1, . . . , T.
Reference: [2] <author> Jaeckel, Louis A. </author> <title> An Alternative Design for a Sparse Distributed Memory. </title> <type> RIACS Technical Report 89.28. </type> <institution> NASA Ames Research Center, </institution> <year> 1989. </year>
Reference-contexts: 1. Introduction We will look at Kanerva's original design of Sparse Distributed Memory, Jaeckel's design, and a modification of Jaeckel's design invented by Roland Karlsson at SICS, having great implementation advantages for simulations on a sequential computer. For a general discussion of these different designs see Kanerva [1], Jaeckel <ref> [2] </ref>, and Karlsson [3]. The performance of the different designs will be studied assuming that 1. the hard locations in the memory, the data and the addresses for storing data are randomly chosen, 2. the reading procedure is the standard one (used in [1] and [2]; better performance can be achieved <p> designs see Kanerva [1], Jaeckel <ref> [2] </ref>, and Karlsson [3]. The performance of the different designs will be studied assuming that 1. the hard locations in the memory, the data and the addresses for storing data are randomly chosen, 2. the reading procedure is the standard one (used in [1] and [2]; better performance can be achieved with other reading procedu res, being investigated in Sjdin [4]), 3. the reading address may be disturbed (i.e., it may contain noise). In particular, we will consider the question of determining the optimal probability p of activation. <p> Observe that p = 2 -N , k=0 R N ) for Kanerva's design and p = 2 -K for the other two designs. 3. The error probability and the signal-to-noise ratio The material in this section is well-known from [1] and <ref> [2] </ref>. Define the stochastic variables L t = the number of hard locations activated by both Y and X t , t = 0, 1, . . . , T. <p> We use the value M = 1,000,000 in accordance with Jaeckel's examples in <ref> [2] </ref>. (This is somewhat improper for Karlsson's design, 1,000,000 not containing high enough powers of 2, but for a comparative study it is quite all right.) Below we give a few comments on the results: Table 1. <p> The figures in the second and third rows give about the same relation between the capacity of Jaeckel's and Kanerva's design for intermediate values of e as Jaeckel claimed in <ref> [2] </ref> (where he used nonoptimal probabilities of activation). 8. Summary and conclusions We have studied the performance of three different designs of Sparse Distributed Memory, namely, Kanerva's original one, Jaeckel's selected-coordinates design, and a modification of Jaeckel's design invented by 13 Karlsson.
Reference: [3] <author> Karlsson, </author> <title> Roland A Fast Activation Mechanism for the Kanerva SDM Memory. </title> <booktitle> In the Proceedings of the '95 RWC Symposium, </booktitle> <pages> pages 6970, </pages> <address> Tokyo, </address> <year> 1995. </year>
Reference-contexts: For a general discussion of these different designs see Kanerva [1], Jaeckel [2], and Karlsson <ref> [3] </ref>. <p> Discussion of the randomness assumptions for hard locations, storage addresses etc. All calculations so far were based upon the assumptions 14 of maximal randomness in section 2. The relevance of these assumptions depends on the application, of course. For instance, Karlsson (cf. <ref> [3] </ref>) has studied some examples where some of the problems discussed below appeared very clearly. Now, imagine any situation with given hard locations, storage addresses, data, and distribution of noise in the reading addresses. Let us first look at Kanerva's model.
Reference: [4] <author> Sjdin, </author> <title> Gunnar Improving the Capacity and Capabilities of SDM. </title> <note> 1995. To be published. </note>
Reference-contexts: will be studied assuming that 1. the hard locations in the memory, the data and the addresses for storing data are randomly chosen, 2. the reading procedure is the standard one (used in [1] and [2]; better performance can be achieved with other reading procedu res, being investigated in Sjdin <ref> [4] </ref>), 3. the reading address may be disturbed (i.e., it may contain noise). In particular, we will consider the question of determining the optimal probability p of activation. For his original design of the memory, Kanerva [1] derived a formula for the optimal p, when reading at the exact address. <p> It is then pretty obvious that for a randomly chosen location h, it is still true that the two events h is activated by Y and h is activated by X t are independent, each having probability p. According to Keeler <ref> [4] </ref> and Chou [5] this approximation will give a slight underestimate of the variance of the noise, hence a slight underestimate of the error probability. For not too small values of N the approximation will be good enough, though. <p> The result was a slight improvement of performance. It is obvious that performance will deteriorate if the storage addresses are too clustered, e.g., if many addresses coincide on a large subset of the coordinates. An indication of how this problem could be handled is given in Sjdin <ref> [4] </ref>. Another problem could arise if the data are too clustered, depending on our use of the standard-type reading with threshold 0 for Z. How to find better thresholds (for all data positions) is discussed in Sjdin [4]. <p> An indication of how this problem could be handled is given in Sjdin <ref> [4] </ref>. Another problem could arise if the data are too clustered, depending on our use of the standard-type reading with threshold 0 for Z. How to find better thresholds (for all data positions) is discussed in Sjdin [4]. Finally, if the disturbance of the reading address is unevenly distributed over the coordinates, we could think of some way of lowering the importance of the coordinates that are disturbed the most. 7. Numerical calculations A program in C was written and run on a SUN Sparc 5 workstation.
Reference: [5] <author> Keeler, James D. </author> <title> Comparison Between Kanerva's SDM and Hopfield-type Neural Networks. </title> <journal> Cognitive Science 12: </journal> <volume> 299329, </volume> <year> 1988. </year>
Reference-contexts: It is then pretty obvious that for a randomly chosen location h, it is still true that the two events h is activated by Y and h is activated by X t are independent, each having probability p. According to Keeler [4] and Chou <ref> [5] </ref> this approximation will give a slight underestimate of the variance of the noise, hence a slight underestimate of the error probability. For not too small values of N the approximation will be good enough, though. These statements were verified by running a C-program for simulations of the SDM.

References-found: 5

