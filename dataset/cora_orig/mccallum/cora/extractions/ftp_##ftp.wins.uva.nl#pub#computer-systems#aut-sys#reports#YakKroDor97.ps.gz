URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/YakKroDor97.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: yakali@fwi.uva.nl  
Title: Vision-Based 6-dof Robot End-effector Positioning Using Neural Networks  
Author: Huseyin Hakan Yakal, Ben Krose and Leo Dorst 
Address: Kruislaan 403, 1098 SJ, Amsterdam, The Netherlands.  
Affiliation: Faculty of Mathematics and Computer Science, University of Amsterdam  
Note: Dutch Foundations for Neural Networks (SNN) Laboratory, Real World Computing Partnership  
Abstract: 1. Abstract 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Espiau, F. Chaumette, and P. Rives. </author> <title> A new approach to visual servoing in robotics. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(3) </volume> <pages> 313-326, </pages> <year> 1992. </year>
Reference-contexts: two types of visuosensory-based robot control approaches: visual servoing which deals with the dynamic response of a robotic systems and visual positioning deals with the inverse kinematics of a robotic systems. 3.1 Visual Servoing of Robot End-effector Camera f World Domain Target in X c Robot X tc This approach <ref> [20, 13, 1, 5, 14] </ref> uses the Jacobian which relates small changes in the feature domain to small changes in the actuator domain. Both the trajectory which specified by using the Jacobian and the desired set point are defined in the image domain. <p> In general, the image of a scene contains more features than the dof of the problem. There are different approaches to solve this problem such as the diagonal dominance measure suggested by Weiss [20]. This method can also be used for determining which feature controls which joint. Others <ref> [13, 1, 5, 14, 2] </ref> used points as the visual features. From the mathematical point of view, a minimum of three points is required. However, multiple solutions exist for three points [6]. This can be resolved either by Newton Gradient search method [2] or using more points.
Reference: [2] <author> J.T. Feddema, C.S.G. Lee, and O.R. Mitchell. </author> <title> Automatic selection of image features for visual servoing of robot manipulator. </title> <booktitle> In IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 832-837, </pages> <address> Scottsdale, Arizona, </address> <year> 1989. </year>
Reference-contexts: In general, the image of a scene contains more features than the dof of the problem. There are different approaches to solve this problem such as the diagonal dominance measure suggested by Weiss [20]. This method can also be used for determining which feature controls which joint. Others <ref> [13, 1, 5, 14, 2] </ref> used points as the visual features. From the mathematical point of view, a minimum of three points is required. However, multiple solutions exist for three points [6]. This can be resolved either by Newton Gradient search method [2] or using more points. <p> Others [13, 1, 5, 14, 2] used points as the visual features. From the mathematical point of view, a minimum of three points is required. However, multiple solutions exist for three points [6]. This can be resolved either by Newton Gradient search method <ref> [2] </ref> or using more points. Using points as the visual features requires point correspondence between the target and the feature points. This correspondence needs to be established externally by a user initially, and then it can be maintained by keeping track of the points.
Reference: [3] <author> A. Guez and Z. Ahmad. </author> <title> Solution to the inverse kinematics problem in robotics by neural networks. </title> <booktitle> In Proc. of Int. Conf. on Neural Networks, </booktitle> <year> 1988. </year>
Reference-contexts: Since feed-forward neural networks can learn any single valued mapping without the detailed analysis of the (robotic) system, the visual positioning of the robot end-effector is an ideal problem for neural networks <ref> [3, 4, 10, 12, 19, 21] </ref>. The mapping from the feature domain to the actuator domain will be represented by a feed-forward neural network. The only condition is that it has to be a single-valued mapping. Let f and be the changes in the feature and the actuator domains, respectively.
Reference: [4] <author> H. Hashimoto, T. Kubota, M. Kuduo, and F. Harashima. </author> <title> Self-organizing visual servo system based on neural networks. </title> <journal> IEEE Cotrol Systems, </journal> <pages> pages 31-36, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Since feed-forward neural networks can learn any single valued mapping without the detailed analysis of the (robotic) system, the visual positioning of the robot end-effector is an ideal problem for neural networks <ref> [3, 4, 10, 12, 19, 21] </ref>. The mapping from the feature domain to the actuator domain will be represented by a feed-forward neural network. The only condition is that it has to be a single-valued mapping. Let f and be the changes in the feature and the actuator domains, respectively.
Reference: [5] <author> K. Hashimoto, T. Kimoto, T. Ebine, and H. Kimura. </author> <title> Manipulator control with image-based visual servo. </title> <booktitle> In IEEE Int. Conf. on Robotics and Automation, </booktitle> <pages> pages 2267-2272, </pages> <address> Sacramento, California, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: two types of visuosensory-based robot control approaches: visual servoing which deals with the dynamic response of a robotic systems and visual positioning deals with the inverse kinematics of a robotic systems. 3.1 Visual Servoing of Robot End-effector Camera f World Domain Target in X c Robot X tc This approach <ref> [20, 13, 1, 5, 14] </ref> uses the Jacobian which relates small changes in the feature domain to small changes in the actuator domain. Both the trajectory which specified by using the Jacobian and the desired set point are defined in the image domain. <p> In general, the image of a scene contains more features than the dof of the problem. There are different approaches to solve this problem such as the diagonal dominance measure suggested by Weiss [20]. This method can also be used for determining which feature controls which joint. Others <ref> [13, 1, 5, 14, 2] </ref> used points as the visual features. From the mathematical point of view, a minimum of three points is required. However, multiple solutions exist for three points [6]. This can be resolved either by Newton Gradient search method [2] or using more points.
Reference: [6] <author> B.K.P Horn. </author> <title> Robot Vision. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Mas-sachusetts, </address> <year> 1986. </year>
Reference-contexts: This method can also be used for determining which feature controls which joint. Others [13, 1, 5, 14, 2] used points as the visual features. From the mathematical point of view, a minimum of three points is required. However, multiple solutions exist for three points <ref> [6] </ref>. This can be resolved either by Newton Gradient search method [2] or using more points. Using points as the visual features requires point correspondence between the target and the feature points. <p> L 34 5 3 1 Determination of the camera position parameters with respect to an external coordinate system is well known exterior orientation problem in photogrammetry and stereo vision literature <ref> [6] </ref>. By considering only the planar white polygon targets on black background and their binary images, we translate the problem to selection of a set of points which define the polygon or the target.
Reference: [7] <author> Ming-Kuei Hu. </author> <title> Visual pattern recognition by moment invariants. </title> <journal> IRE Transactions on Information Theory, </journal> <volume> 50 </volume> <pages> 179-187, </pages> <year> 1962. </year>
Reference-contexts: We will use moments as the visual features and for 6-dof positioning problem, 6 independent moments are needed (refer to <ref> [7, 16, 22, 11] </ref> for more information).
Reference: [8] <author> Y. Hung, P.-S. Yeh, and D. Harwood. </author> <title> Passive ranging to known planar point sets. </title> <type> Tech. Rep. </type> <institution> CAR-TR-65, CS-TR-1408, Center for Automation Research, </institution> <month> June </month> <year> 1984. </year>
Reference-contexts: It has been shown that three points gives up to 8 solutions to this problem. 4 points on a plane (non three of which are collinear) gives a unique solution to the exterior orientation problem <ref> [8] </ref>. The problem with point based approach is that it requires explicit point correspondence initially. This can be avoided by organizing the points to form a concave polygon (Fig. 2a).
Reference: [9] <author> B.J.A. Krose, M.J. van der Korst, and F.C.A. Groen. </author> <title> Learning strategies for a vision based neural controller for a robot arm. </title> <editor> In O. Kaynak, editor, </editor> <booktitle> IEEE International Workshop on Intelligent Motion Control, </booktitle> <pages> pages 199-203, </pages> <address> Bogazi~ci University, _ Istanbul, </address> <month> Aug. </month> <year> 1990. </year> <note> IEEE. </note>
Reference-contexts: A set of visual features linear in world coordinates would eliminate the the need for the current feature state f in this equation <ref> [9] </ref>. Next we consider the mapping from joint domain () to the world domain (X c ). As in the previous case, this is also a nonlinear mapping, and X c depends on the initial actuator state .
Reference: [10] <author> L. Li and H. Ogmen. </author> <title> Visually guided motor control: Adaptive sensorimotor mapping with on-line visual-error correction. </title> <booktitle> In World Congress on Neural Networks-San Diego, </booktitle> <pages> pages II.127-134, </pages> <year> 1994. </year>
Reference-contexts: Since feed-forward neural networks can learn any single valued mapping without the detailed analysis of the (robotic) system, the visual positioning of the robot end-effector is an ideal problem for neural networks <ref> [3, 4, 10, 12, 19, 21] </ref>. The mapping from the feature domain to the actuator domain will be represented by a feed-forward neural network. The only condition is that it has to be a single-valued mapping. Let f and be the changes in the feature and the actuator domains, respectively.
Reference: [11] <author> Ken-ichi Kanatani. </author> <title> Detecting the motion of a planar surface by line and surface integrals. Computer Vision, </title> <journal> Graphics, and Image Processing, </journal> <volume> 29 </volume> <pages> 13-22, </pages> <year> 1985. </year>
Reference-contexts: We will use moments as the visual features and for 6-dof positioning problem, 6 independent moments are needed (refer to <ref> [7, 16, 22, 11] </ref> for more information).
Reference: [12] <author> W. T. Miller. </author> <title> Real-time application of neural networks for sensor-based control of robots with vision. </title> <journal> IEEE Trans. on Systems, Man, and Cybernetics, </journal> <volume> 19(4) </volume> <pages> 825-831, </pages> <year> 1989. </year>
Reference-contexts: Since feed-forward neural networks can learn any single valued mapping without the detailed analysis of the (robotic) system, the visual positioning of the robot end-effector is an ideal problem for neural networks <ref> [3, 4, 10, 12, 19, 21] </ref>. The mapping from the feature domain to the actuator domain will be represented by a feed-forward neural network. The only condition is that it has to be a single-valued mapping. Let f and be the changes in the feature and the actuator domains, respectively.
Reference: [13] <author> N.P. Papanikolopoilos, P.K. Khosla, and T. Kanade. </author> <title> Visual tracking of a moving target by a camera mounted on a robot: Combination of control and vision. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 9(1) </volume> <pages> 14-35, </pages> <year> 1993. </year>
Reference-contexts: two types of visuosensory-based robot control approaches: visual servoing which deals with the dynamic response of a robotic systems and visual positioning deals with the inverse kinematics of a robotic systems. 3.1 Visual Servoing of Robot End-effector Camera f World Domain Target in X c Robot X tc This approach <ref> [20, 13, 1, 5, 14] </ref> uses the Jacobian which relates small changes in the feature domain to small changes in the actuator domain. Both the trajectory which specified by using the Jacobian and the desired set point are defined in the image domain. <p> In general, the image of a scene contains more features than the dof of the problem. There are different approaches to solve this problem such as the diagonal dominance measure suggested by Weiss [20]. This method can also be used for determining which feature controls which joint. Others <ref> [13, 1, 5, 14, 2] </ref> used points as the visual features. From the mathematical point of view, a minimum of three points is required. However, multiple solutions exist for three points [6]. This can be resolved either by Newton Gradient search method [2] or using more points.
Reference: [14] <author> V. Sundareswaran, P. Bouthemy, and F. Chaumette. </author> <title> Visual servoing using dynamic image parameters. </title> <type> Technical Report RR-2336, </type> <institution> INRIA, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: two types of visuosensory-based robot control approaches: visual servoing which deals with the dynamic response of a robotic systems and visual positioning deals with the inverse kinematics of a robotic systems. 3.1 Visual Servoing of Robot End-effector Camera f World Domain Target in X c Robot X tc This approach <ref> [20, 13, 1, 5, 14] </ref> uses the Jacobian which relates small changes in the feature domain to small changes in the actuator domain. Both the trajectory which specified by using the Jacobian and the desired set point are defined in the image domain. <p> In general, the image of a scene contains more features than the dof of the problem. There are different approaches to solve this problem such as the diagonal dominance measure suggested by Weiss [20]. This method can also be used for determining which feature controls which joint. Others <ref> [13, 1, 5, 14, 2] </ref> used points as the visual features. From the mathematical point of view, a minimum of three points is required. However, multiple solutions exist for three points [6]. This can be resolved either by Newton Gradient search method [2] or using more points.
Reference: [15] <author> V. Vysvniauskas, F. C. Groen, and B. J. A. Krt:se. </author> <title> The optimal number of learning samples and hidden units in function approximation witha feedforward network. </title> <type> Technical Report CS-93-15, </type> <institution> Dept. of Computer Systems, University of Amsterdam, </institution> <address> Amsterdam, The Netherlands, </address> <year> 1993. </year>
Reference-contexts: It has been shown <ref> [15] </ref> that the optimum number of hidden units in a feed-forward neural network can be selected to achieve desired precision over a given set of learning samples.
Reference: [16] <author> C.-H. Teh and R. T. Chin. </author> <title> On image analysis by the methods of moments. </title> <journal> IEEE Transactions on PAMI, </journal> <volume> 10(4) </volume> <pages> 496-513, </pages> <year> 1988. </year>
Reference-contexts: We will use moments as the visual features and for 6-dof positioning problem, 6 independent moments are needed (refer to <ref> [7, 16, 22, 11] </ref> for more information).
Reference: [17] <author> Carme Torras. </author> <title> Robot neurocontrol: An overview. </title> <address> ICANN,Paris, </address> <month> December </month> <year> 1995. </year>
Reference: [18] <author> P. van der Smagt. Simderella: </author> <title> a robot simulator for neuro-controller design. </title> <journal> Neurocomputing, </journal> <volume> 6(2) </volume> <pages> 281-285, </pages> <year> 1994. </year>
Reference-contexts: As a result, redundant samples are discarded. Joint Min Max Joint Min Max 1 -30.0 30.0 4 -30.0 30.0 3 80.0 160.0 6 -30.0 30.0 Table 1: Joint limits of the robot. 6.3 Simulation Setup The simulation program <ref> [18, 19] </ref> is written in C and is composed of three modules: * connel is the control module and can communicate with both the robot and the neural network modules. * lummel is the neural network module which simulates the neural network, stores samples received from connel and generates new commands
Reference: [19] <author> P. van der Smagt. </author> <title> Visual Robot Arm Guidance using Neural Networks. </title> <type> PhD thesis, </type> <institution> Dept of Computer Systems, University of Amsterdam, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: Since feed-forward neural networks can learn any single valued mapping without the detailed analysis of the (robotic) system, the visual positioning of the robot end-effector is an ideal problem for neural networks <ref> [3, 4, 10, 12, 19, 21] </ref>. The mapping from the feature domain to the actuator domain will be represented by a feed-forward neural network. The only condition is that it has to be a single-valued mapping. Let f and be the changes in the feature and the actuator domains, respectively. <p> It has been shown [15] that the optimum number of hidden units in a feed-forward neural network can be selected to achieve desired precision over a given set of learning samples. Using this with the conjugate gradient method <ref> [19] </ref> improves the training time required for a feed-forward neural network to represent a mapping with a certain accuracy. <p> Since feed-forward neural networks minimize summed squared error over a given learning samples, the regions with higher learning sample concentration will be approximated better compared to the regions with lower learning sample concentration. This problem can be solved by controling the distribution of the samples using a binning technique <ref> [19] </ref>. 4. Target with a unique feature vector from any relative position The first condition for achieving the positioning task is that the mapping from the relative position X tc to the features f has to be a single-valued function. <p> The feed-forward neural networks minimizes summed squared error over the given learning samples. For a good representation, these samples should be distributed uniformly in the input space of the neural network. This can be achieved by using a binning technique <ref> [19] </ref> which divides each input dimension of the neural network into smaller parts, creating a hypercube with the same dimensionality as the input space. Hence the input values of a learning sample uniquely determines into which bin it will be placed in. <p> Since 1 is independent of its current state, it is omitted from the input. This is the only model knowledge about the robot that is used through out these simulations. The network has 50 hidden units with sigmoidal activation and 6 linear output units. Training of the network <ref> [19] </ref> is done using a conjugate-gradient optimization method with Powell restarts. The training time allowed for the neural network is adjusted with the number of learning samples such that almost the same number of optimization steps are taken for the available learning sample. <p> As a result, redundant samples are discarded. Joint Min Max Joint Min Max 1 -30.0 30.0 4 -30.0 30.0 3 80.0 160.0 6 -30.0 30.0 Table 1: Joint limits of the robot. 6.3 Simulation Setup The simulation program <ref> [18, 19] </ref> is written in C and is composed of three modules: * connel is the control module and can communicate with both the robot and the neural network modules. * lummel is the neural network module which simulates the neural network, stores samples received from connel and generates new commands
Reference: [20] <author> L.E. Weiss, A.C. Sanderson, and C. P. Neuman. </author> <title> Dynamic sensor-based control of robots with visual feedback. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-3(5):404-417, </volume> <year> 1987. </year>
Reference-contexts: two types of visuosensory-based robot control approaches: visual servoing which deals with the dynamic response of a robotic systems and visual positioning deals with the inverse kinematics of a robotic systems. 3.1 Visual Servoing of Robot End-effector Camera f World Domain Target in X c Robot X tc This approach <ref> [20, 13, 1, 5, 14] </ref> uses the Jacobian which relates small changes in the feature domain to small changes in the actuator domain. Both the trajectory which specified by using the Jacobian and the desired set point are defined in the image domain. <p> Obtaining such a matrix with above mentioned conditions involves the proper selection of the visual features. In general, the image of a scene contains more features than the dof of the problem. There are different approaches to solve this problem such as the diagonal dominance measure suggested by Weiss <ref> [20] </ref>. This method can also be used for determining which feature controls which joint. Others [13, 1, 5, 14, 2] used points as the visual features. From the mathematical point of view, a minimum of three points is required. However, multiple solutions exist for three points [6].
Reference: [21] <author> G. Wells, C. Venaille, and C. Torras. </author> <title> Vision-based robot positioning using neural networks. </title> <note> Submitted for publication, </note> <month> June </month> <year> 1995. </year>
Reference-contexts: Since feed-forward neural networks can learn any single valued mapping without the detailed analysis of the (robotic) system, the visual positioning of the robot end-effector is an ideal problem for neural networks <ref> [3, 4, 10, 12, 19, 21] </ref>. The mapping from the feature domain to the actuator domain will be represented by a feed-forward neural network. The only condition is that it has to be a single-valued mapping. Let f and be the changes in the feature and the actuator domains, respectively.
Reference: [22] <author> H. H. Yakal, L. Dorst, and B. Krose. </author> <title> Characterizing perspective transformations by independent moment-based image features. </title> <type> Technical report, </type> <institution> RWCP Novel Functions SNN Laboratory, Dept. of Computer Systems, University of Amsterdam, </institution> <address> Amsterdam, The Netherlands, </address> <year> 1996. </year> <note> In preperation. 8 </note>
Reference-contexts: We will use moments as the visual features and for 6-dof positioning problem, 6 independent moments are needed (refer to <ref> [7, 16, 22, 11] </ref> for more information).
References-found: 22

