URL: ftp://ftp.cs.virginia.edu/pub/techreports/CS-97-02.ps.Z
Refering-URL: ftp://ftp.cs.virginia.edu/pub/techreports/README.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: ffrench|alp4gg@cs.virginia.edu  eschulma@nrao.edu  
Title: Automating the Construction of Authority Files in Digital Libraries: A Case Study  
Author: James C. French Allison L. Powell Eric Schulman 
Address: Charlottesville, Virginia 22903  520 Edgemont Road Charlottesville, VA 22903-2475  
Affiliation: Department of Computer Science University of Virginia  National Radio Astronomy Observatory  
Abstract: Technical Report No. CS-97-02 January 14, 1997 Abstract The issue of quality control has become increasingly important as more online databases are integrated into digital libraries. This can have a dramatic effect on the search effectiveness of an online system. Authority work, the need to discover and reconcile variant forms of strings in bibliographic entries, will become more difficult. Spelling variants, misspellings, translation and transliteration differences all increase the difficulty of retrieving information. This paper is a case study of our efforts to create an authority file for authors' institutional affiliations in the Astrophysics Data System. The techniques surveyed here for the detection and categorization of variant forms have broader applicability and may be used in authority work for other bibliographic fields.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. A. </author> <title> Abt. </title> <journal> Institutional Productivities. Publications of the Astronomical Society of the Pacific, </journal> <volume> 105 </volume> <pages> 794-798, </pages> <year> 1993. </year>
Reference-contexts: The astronomy community collects statistics about publication in that field, tracking changes in measures such as paper length, general productivity and institutional productivity. Traditionally, 2 such statistics have been gathered by hand on a necessarily small subset of available documents (e.g. <ref> [1, 15] </ref>). We have been collaborating with astronomers interested in automatically gathering this information using the ADS database as the data source [11, 12]. Automatically gathering statistics about these electronic documents has allowed a much larger fraction of documents to be considered | it has also presented new challenges.
Reference: [2] <author> A. Accomazzi, G. Eichhorn, M. J. Kurtz, C. S. Grant, and S. S. Murray. </author> <title> The ADS Article Service Data Holdings and Access Method. </title> <editor> In G. Hunt and H. Payne, editors, </editor> <booktitle> Astronomical Data Analysis Software and Systems VI, A.S.P. Conference Series, </booktitle> <year> 1997. </year> <note> in press. </note>
Reference: [3] <author> L. Auld. </author> <title> Authority Control: An Eighty-Year Review. Library Resources & Technical Services, </title> <booktitle> 26 </booktitle> <pages> 319-330, </pages> <year> 1982. </year>
Reference-contexts: In recent years there has also been an increasing emphasis on data quality in online databases [10]. One aspect of improving data quality is detecting variant names for unique entities in the database. This is called authority work <ref> [3] </ref> and results in the creation of authority files that maintain the correspondence between all the allowable forms for strings in a particular bibliographic field, say, author or journal name. In this paper we look at techniques to aid in detecting variant forms of strings in bibliographic databases. <p> More concretely, we are trying to automate this authority control mechanism to achieve a transparent facility having the characteristics described by Auld <ref> [3] </ref>. A bibliographic record, together with all variant forms of each associated heading, would be entered into the system. The computer would establish linkages between the preferred forms of headings and the bibliographic record.
Reference: [4] <author> C. L. Borgman and S. L. Siegfried. </author> <title> Getty's Synoname and its Cousins: A Survey of Applications of Personal Name-Matching Algorithms. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 43(7) </volume> <pages> 459-476, </pages> <year> 1992. </year>
Reference-contexts: Others have considered similar problems with variant forms in bibliographic fields, for example, author names [13] and titles [17]. Borgman <ref> [4] </ref> surveys many other name-matching algorithms. This data cleanup effort will allow us to expand the scope of the statistics-gathering effort. It will also make it possible for the ADS to provide services that are currently infeasible.
Reference: [5] <author> J. R. Davis. </author> <title> Creating a Networked Computer Science Technical Report Library. </title> <journal> D-Lib Magazine, </journal> <month> Sept. </month> <year> 1995. </year>
Reference: [6] <author> J. C. French, A. L. Powell, and E. Schulman. </author> <title> Applications of Approximate Word Matching in Information Retrieval. </title> <type> Technical Report CS-97-01, </type> <institution> Department of Computer Science, University of Virginia, </institution> <month> January </month> <year> 1997. </year>
Reference-contexts: We will show that using the alternate representations of the affiliation string is helpful, but it does not allow fine control over the types of errors allowed. In a companion paper <ref> [6] </ref>, we describe a new approach | approximate word matching | which finds a minimum distance matching between the words in string1 and string2. We have performed experiments on a small subset of the collection using this new approach. The results are reported in [6]. <p> In a companion paper <ref> [6] </ref>, we describe a new approach | approximate word matching | which finds a minimum distance matching between the words in string1 and string2. We have performed experiments on a small subset of the collection using this new approach. The results are reported in [6]. Experiments using the full collection are forthcoming. 4 Results 4.1 Experiments First, raw affiliations were extracted from the affiliation fields of the records in the ADS database. Lexical cleanup was then performed. These results are shown in Table 1. <p> However, it is apparent from Table 5 that we have reached a point of diminishing returns using our current methodology. The next step is to perform comparisons between strings on a word-by-word basis as described in <ref> [6] </ref>. This presents a number of interesting questions, the most important of which is determining an appropriate distance measure. We propose that it should contain components of total edit distance and individual edit distances between words. Note that individual between-word edit distances must be below some threshold. <p> The methods are effective and efficient enough to be used in production environments. In the study reported here, we extracted 20,168 unique affiliation strings from our sample of 146,000 records. Preliminary results from the application of approximate word matching <ref> [6] </ref> show that we are able to further reduce these to 8,928 strings by using extremely conservative thresholds. Although we do not yet have a quantative measure of the misclassification rate, our qualatative assessment is that the results are excellent.
Reference: [7] <author> P. A. V. Hall and G. R. Dowling. </author> <title> Approximate String Matching. </title> <journal> Computing Surveys, </journal> <volume> 12(4) </volume> <pages> 381-402, </pages> <month> Dec. </month> <year> 1980. </year> <month> 14 </month>
Reference-contexts: We chose to use an edit distance as a domain independent way to measure the difference between two strings. The edit distance [9, 16] is the number of insertions, deletions, transpositions and substitutions required to turn string1 into string2. Edit distance has traditionally been used in approximate string matching <ref> [7] </ref>, spelling error detection and correction [8], and more recently has been shown to be more effective than Soundex for phonetic string matching [18]. We used the edit distance algorithm presented by Hall and Dowling [7] as implemented by Zobel and Dart [18]. <p> Edit distance has traditionally been used in approximate string matching <ref> [7] </ref>, spelling error detection and correction [8], and more recently has been shown to be more effective than Soundex for phonetic string matching [18]. We used the edit distance algorithm presented by Hall and Dowling [7] as implemented by Zobel and Dart [18]. For each round of experiments, we computed an edit distance cost matrix which contained the distances between all affiliation strings in the current set. These distances were used to form affiliation clusters based on a fixed or variable edit distance threshold.
Reference: [8] <author> K. Kukich. </author> <title> Techniques for Automatically Correcting Words in Text. </title> <journal> Computing Surveys, </journal> <volume> 24(4) </volume> <pages> 377-440, </pages> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: The edit distance [9, 16] is the number of insertions, deletions, transpositions and substitutions required to turn string1 into string2. Edit distance has traditionally been used in approximate string matching [7], spelling error detection and correction <ref> [8] </ref>, and more recently has been shown to be more effective than Soundex for phonetic string matching [18]. We used the edit distance algorithm presented by Hall and Dowling [7] as implemented by Zobel and Dart [18].
Reference: [9] <author> R. Lowrance and R. A. Wagner. </author> <title> An Extension of the String-to-String Correction Problem. </title> <journal> Journal of the ACM, </journal> <volume> 22(2) </volume> <pages> 177-183, </pages> <month> Apr. </month> <year> 1975. </year>
Reference-contexts: These inconsistencies could not be handled easily by lexical approaches. We chose to use an edit distance as a domain independent way to measure the difference between two strings. The edit distance <ref> [9, 16] </ref> is the number of insertions, deletions, transpositions and substitutions required to turn string1 into string2.
Reference: [10] <author> E. T. O'Neill and D. Vizine-Goetz. </author> <title> Quality Control in Online Databases. </title> <journal> Annual Review of Information Science and Technology, </journal> <volume> 23 </volume> <pages> 125-156, </pages> <year> 1988. </year>
Reference-contexts: There will be increasing reliance on automated techniques to aid information providers as they seek to reach this goal. In recent years there has also been an increasing emphasis on data quality in online databases <ref> [10] </ref>. One aspect of improving data quality is detecting variant names for unique entities in the database.
Reference: [11] <author> E. Schulman, J. C. French, A. L. Powell, S. S. Murray, G. Eichhorn, and M. J. Kurtz. </author> <title> The Sociology of Astronomical Publication Using ADS and ADAMS. </title> <editor> In G. Hunt and H. Payne, editors, </editor> <booktitle> Astronomical Data Analysis Software and Systems VI, A.S.P. Conference Series, </booktitle> <year> 1997. </year> <note> in press. </note>
Reference-contexts: Traditionally, 2 such statistics have been gathered by hand on a necessarily small subset of available documents (e.g. [1, 15]). We have been collaborating with astronomers interested in automatically gathering this information using the ADS database as the data source <ref> [11, 12] </ref>. Automatically gathering statistics about these electronic documents has allowed a much larger fraction of documents to be considered | it has also presented new challenges.
Reference: [12] <author> E. Schulman, A. L. Powell, J. C. French, G. Eichhorn, M. J. Kurtz, and S. S. Murray. </author> <title> Using the ADS Database to Study Trends in Astronomical Publication. </title> <journal> In Bulletin of the American Astronomical Society, </journal> <volume> volume 4, </volume> <year> 1996. </year>
Reference-contexts: Traditionally, 2 such statistics have been gathered by hand on a necessarily small subset of available documents (e.g. [1, 15]). We have been collaborating with astronomers interested in automatically gathering this information using the ADS database as the data source <ref> [11, 12] </ref>. Automatically gathering statistics about these electronic documents has allowed a much larger fraction of documents to be considered | it has also presented new challenges.
Reference: [13] <author> S. L. Siegfried and J. Bernstein. Synoname: </author> <title> The Getty's New Approach to Pattern Matching for Personal Names. </title> <journal> Computers and the Humanities, </journal> <volume> 25(4) </volume> <pages> 211-226, </pages> <year> 1991. </year>
Reference-contexts: Others have considered similar problems with variant forms in bibliographic fields, for example, author names <ref> [13] </ref> and titles [17]. Borgman [4] surveys many other name-matching algorithms. This data cleanup effort will allow us to expand the scope of the statistics-gathering effort. It will also make it possible for the ADS to provide services that are currently infeasible.
Reference: [14] <author> A. G. Taylor. </author> <title> Authority Files in Online Catalogs: An Investigation of Their Value. </title> <journal> Cataloging & Classification Quarterly, </journal> <volume> 4(3) </volume> <pages> 1-17, </pages> <year> 1984. </year>
Reference-contexts: In this paper we look at techniques to aid in detecting variant forms of strings in bibliographic databases. Taylor <ref> [14] </ref> elucidates two principles of authority control. The first is that all variants of a name will be brought together under a single form so that once users find that form, they will be confident fl This work supported in part by Dept. of Energy Grant no.
Reference: [15] <author> V. Trimble. </author> <title> Postwar growth in the length of astronomical and other scientific papers. </title> <journal> Publications of the Astronomical Society of the Pacific, </journal> <volume> 96 </volume> <pages> 1007-1016, </pages> <year> 1984. </year>
Reference-contexts: The astronomy community collects statistics about publication in that field, tracking changes in measures such as paper length, general productivity and institutional productivity. Traditionally, 2 such statistics have been gathered by hand on a necessarily small subset of available documents (e.g. <ref> [1, 15] </ref>). We have been collaborating with astronomers interested in automatically gathering this information using the ADS database as the data source [11, 12]. Automatically gathering statistics about these electronic documents has allowed a much larger fraction of documents to be considered | it has also presented new challenges.
Reference: [16] <author> R. A. Wagner and M. J. Fischer. </author> <title> The String-to-String Correction Problem. </title> <journal> Journal of the ACM, </journal> <volume> 21(1) </volume> <pages> 168-173, </pages> <month> Jan. </month> <year> 1974. </year>
Reference-contexts: These inconsistencies could not be handled easily by lexical approaches. We chose to use an edit distance as a domain independent way to measure the difference between two strings. The edit distance <ref> [9, 16] </ref> is the number of insertions, deletions, transpositions and substitutions required to turn string1 into string2.
Reference: [17] <author> M. E. Williams and L. Lannom. </author> <title> Lack of Standardization of the Journal Title Data Element in Databases. </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 32(3) </volume> <pages> 229-233, </pages> <month> May </month> <year> 1981. </year>
Reference-contexts: Others have considered similar problems with variant forms in bibliographic fields, for example, author names [13] and titles <ref> [17] </ref>. Borgman [4] surveys many other name-matching algorithms. This data cleanup effort will allow us to expand the scope of the statistics-gathering effort. It will also make it possible for the ADS to provide services that are currently infeasible.
Reference: [18] <author> J. Zobel and P. </author> <title> Dart. Phonetic String Matching: Lessons from Information Retrieval. </title> <booktitle> In Proc. 19th Inter. Conf. on Research and Development in Information Retrieval (SIGIR'96), </booktitle> <pages> pages 166-172, </pages> <month> Aug. </month> <year> 1996. </year> <month> 15 </month>
Reference-contexts: Edit distance has traditionally been used in approximate string matching [7], spelling error detection and correction [8], and more recently has been shown to be more effective than Soundex for phonetic string matching <ref> [18] </ref>. We used the edit distance algorithm presented by Hall and Dowling [7] as implemented by Zobel and Dart [18]. For each round of experiments, we computed an edit distance cost matrix which contained the distances between all affiliation strings in the current set. <p> has traditionally been used in approximate string matching [7], spelling error detection and correction [8], and more recently has been shown to be more effective than Soundex for phonetic string matching <ref> [18] </ref>. We used the edit distance algorithm presented by Hall and Dowling [7] as implemented by Zobel and Dart [18]. For each round of experiments, we computed an edit distance cost matrix which contained the distances between all affiliation strings in the current set. These distances were used to form affiliation clusters based on a fixed or variable edit distance threshold.
References-found: 18

