URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1247/CS-TR-94-1247.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-94-1247/
Root-URL: http://www.cs.wisc.edu
Email: mirong@cs.wisc.edu  
Title: Towards Automated Performance Tuning For Complex Workloads  
Author: Kurt P. Browny Manish Mehtaz Michael J. Careyy Miron Livnyz fbrown, mmehta, carey, 
Address: San Jose, CA  Wisconsin, Madison, WI  
Affiliation: yIBM Almaden Research Center,  zComputer Sciences Department, University of  
Abstract: In this paper we explore the problem of automatically adjusting DBMS multiprogramming levels and memory allocations in order to achieve a set of per-class response time goals for a complex multiclass workload. We start by describing the phenomena that make this a very challenging problem, the foremost of which is the interdependence between classes that results from their competition for shared resources. We then describe M&M, a feedback-based algorithm for simultaneously determining the MPL and memory settings for each class independently, and we evaluate the algorithm's effectiveness using a detailed simulation model. We show that our algorithm can successfully achieve response times that are within a few percent of the goals for mixed workloads consisting of short transactions and longer-running ad hoc join queries.
Abstract-found: 1
Intro-found: 1
Reference: [Brown 92] <author> K. Brown, M. Carey, D. Dewitt, M. Mehta, J. Naughton, </author> <title> "Resource Allocation and Scheduling for Mixed Database Workloads," </title> <type> Computer Sciences Technical Report #1095, </type> <institution> Department of Computer Sciences, University of Wisconsin, Madison, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: 1 Introduction As database management systems continue to increase in function and to expand into new application areas, the diversity of database workloads is increasing as well. In addition to the classic relational DBMS "problem workload" consisting of short transactions running concurrently with long decision support queries <ref> [Pirahesh 90, Brown 92, DeWitt 92] </ref>, we can expect to see workloads comprising an even wider range of resource demands and execution times in the future.
Reference: [Brown 93a] <author> K. Brown, M. Carey, M. Livny, </author> <title> "Managing Memory to Meet Multiclass Workload Response Time Goals," </title> <booktitle> Proc. 19th Int'l VLDB Conf, </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Each of these could be driven by performance objectives. Recently, techniques have been proposed for goal-oriented transaction routing [Ferg 93] and goal-oriented buffer management <ref> [Brown 93a] </ref>. fl This work was partially supported by the IBM Corporation through a Research Initiation Grant. 1 However, a complete solution to the problem of automatically satisfying multiclass performance goals must employ more than one mechanism; each class can have different resource consumption patterns, so the most effective knob for <p> An objective of minimizing the maximum performance index means that the algorithms do not have to maintain specific response times very accurately. Rather, they need only determine the correct relative response times when comparing between different routing possibilities. Another approach to achieving per-class performance goals, called fragment fencing <ref> [Brown 93a] </ref>, uses disk buffer allocation to explicitly manage buffer hit rates. Fragment fencing maintains per-class statistics on database reference frequencies and observed hit rates, and uses them to determine a minimum number of memory resident pages for each "fragment" of the database. <p> The success of this process is dependent on the feedback controller, whose job is to translate observations into the knob adjustments that will eventually achieve the goal. It is much easier to develop good controllers for feedback mechanisms that adjust a single knob (such as those in <ref> [Brown 93a] </ref> and [Mehta 93]), as the search space is one dimensional; the only decision required is whether to turn the knob "up" or "down." We have two knobs, however, and are thus faced with a two-dimensional search space. <p> is empty, no pool increases are allowed, and the no-goal class is forced to execute at its minimum memory requirement (using memory from the set-aside area). 4.1 Feedback Mechanism M&M's feedback mechanism is largely based on the feedback mechanism of the fragment fencing algorithm, which is described in detail in <ref> [Brown 93a] </ref>. We will give a brief overview of M&M's feedback mechanism here, primarily 6 The actual size of the set-aside area is workload dependent. For example, each disk buffer transaction might require one or two pages and each working storage transaction might require 20-30 pages. <p> Queries from working storage classes are allocated their minimum memory requirements during warmup, and transactions from disk buffer classes compete freely for any remaining physical memory. 4.2 Disk Buffer Class Controller M&M adopts the fragment fencing algorithm <ref> [Brown 93a] </ref> to control the memory knob for disk buffer classes. Fragment fencing uses observed response times and hit rates for each class to set a minimum number of pages that must remain memory resident for each database fragment 7 referenced by a class; these minimums are called target residencies. <p> We then described M&M, a feedback-based algorithm for determining the MPL and memory settings for each class independently. M&M builds on the fragment fencing algorithm <ref> [Brown 93a] </ref> for managing disk buffer classes, adding new mechanisms for controlling working storage classes; these include a heuristic-based controller for determining MPL and memory allocations and an admission delay mechanism that allows M&M to set non-integral MPL limits.
Reference: [Brown 93b] <author> K. Brown, M. Carey, M. Livny, </author> <title> "Towards an Autopilot in the DBMS Performance Cockpit," </title> <booktitle> Proc. 5th Int'l High Performance Transaction Processing Workshop, Asilomar, </booktitle> <address> CA, </address> <month> Sept </month> <year> 1993. </year>
Reference-contexts: Conversely, even though two classes have similar performance objectives, they may have very different resource demands. Controlling the performance for such a workload by manually adjusting low-level DBMS performance "knobs" will become increasingly impractical, as has been argued previously <ref> [Nikolaou 92, Brown 93b, Selinger 93, Weikum 93] </ref>. Ideally, a DBMS should be able to accept performance goals for each class as inputs, and should dynamically adjust its own low-level performance knobs using the goals as a guide. <p> Finally, we discuss future work and summarize our conclusions in Section 7. 2 Related Work The case for goal-oriented resource management has been argued for distributed computing systems in general [Nikolaou 92] and for database management systems in particular <ref> [Brown 93b] </ref>. The COMFORT project at ETH Zurich is also directed toward the automation of DBMS performance tuning, and is described in [Weikum 93].
Reference: [DeWitt 84] <author> D. DeWitt et al, </author> <title> "Implementation Techniques for Main Memory Database Systems," </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <address> Boston, MA, </address> <month> June </month> <year> 1984. </year>
Reference-contexts: The configuration consists of a single 25 MIP processor, 8 MB of memory, and five 1 GB disks. 4 The workload consists of three classes: "queries," "transactions," and "big queries." The query class represents a consumer of working storage memory. It consists of binary hybrid hash join queries <ref> [DeWitt 84] </ref> whose performance is related to the amount of memory allocated 4 This configuration is scaled up in later experiments. 7 for their join hash tables. <p> The "query" class models a working storage class with longer execution times (tens of seconds or minutes). The individual queries consist of binary joins of two randomly chosen query files (see Table 2). We use the hybrid hash join algorithm <ref> [DeWitt 84] </ref> because it is generally accepted as a good ad hoc join method. Allocating the maximum amount of memory to a join query will allow it to execute with the minimum number of I/Os, i.e. with a single scan of each relation.
Reference: [DeWitt 90] <author> D. DeWitt et al, </author> <title> "The Gamma Database Machine Project," </title> <journal> IEEE Trans. on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March </month> <year> 1990. </year>
Reference-contexts: The software-related parameters in Table 4 are based on instruction counts taken from the Gamma parallel database system prototype <ref> [DeWitt 90] </ref>, and the disk characteristics approximate those of the Fujitsu Model M2266 disk drive, as stated earlier. 6 Experiments and Results In this section, we use our simulation model to examine how well M&M can achieve a variety of goals for several variations of a simulated multiclass workload.
Reference: [DeWitt 92] <author> D. DeWitt and J. Gray, </author> <title> "Parallel Database Systems: The Future of High Performance Database Processing," </title> <journal> CACM, </journal> <volume> 35(6), </volume> <month> June, </month> <year> 1992. </year>
Reference-contexts: 1 Introduction As database management systems continue to increase in function and to expand into new application areas, the diversity of database workloads is increasing as well. In addition to the classic relational DBMS "problem workload" consisting of short transactions running concurrently with long decision support queries <ref> [Pirahesh 90, Brown 92, DeWitt 92] </ref>, we can expect to see workloads comprising an even wider range of resource demands and execution times in the future.
Reference: [Ferg 93] <author> D. Ferguson, C. Nikolaou, L. Geargiadis, </author> <title> "Goal Oriented, Adaptive Transaction Routing for High Performance Transaction Processing Systems," </title> <booktitle> Proc. 2nd Int'l Conf. on Parallel and Distributed Systems, </booktitle> <address> San Diego CA, </address> <month> Jan </month> <year> 1993. </year>
Reference-contexts: Each of these could be driven by performance objectives. Recently, techniques have been proposed for goal-oriented transaction routing <ref> [Ferg 93] </ref> and goal-oriented buffer management [Brown 93a]. fl This work was partially supported by the IBM Corporation through a Research Initiation Grant. 1 However, a complete solution to the problem of automatically satisfying multiclass performance goals must employ more than one mechanism; each class can have different resource consumption patterns, <p> The remainder of this section reviews the few published techniques for automatically achieving per-class performance goals in a database or operating system environment. Two predictive algorithms for goal-oriented transaction routing in distributed transaction processing systems are described in <ref> [Ferg 93] </ref>. These two algorithms attempt to predict the effect of a routing decision on the response times of each class. <p> While it does not specifically accept response time goals, the adaptive memory allocation and MPL adjustment algorithm described in [Mehta 93] is also of interest because its objective of maximizing fairness is very close to the objective of the goal-oriented transaction routing algorithms described in <ref> [Ferg 93] </ref>. The adaptive algorithm computes a performance metric for each class which is the ratio of the observed response time to the best possible response time (as obtained by running single queries of that class alone in the system). <p> <ref> [Ferg 93] </ref>. The adaptive algorithm computes a performance metric for each class which is the ratio of the observed response time to the best possible response time (as obtained by running single queries of that class alone in the system). This measure is very similar to the performance index of [Ferg 93]. Fairness is then defined as the absence of variance in this metric across all classes, so the adaptive algorithm's objective of maximizing fairness is similar to minimizing the maximum performance index.
Reference: [IBM 93] <institution> IBM Corporation, </institution> <note> MVS/ESA Version 4.3 Initialization and Tuning Guide GC28-1643, </note> <institution> IBM Corporation, </institution> <address> Pough-keepsie NY, </address> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: IBM's MVS operating system has long provided mechanisms for achieving per-class performance goals <ref> [Lorin 81, 3 Pierce 83, IBM 93] </ref>. MVS performance goal specification is much more complicated than simply indicating the desired response times for each class, but the net effect is still the same.
Reference: [Lorin 81] <author> H. Lorin and H. Deitel, </author> <title> Operating Systems (chapter 9: Resource Management), </title> <publisher> Addison Wesley, </publisher> <address> Reading MA, </address> <year> 1981. </year>
Reference-contexts: IBM's MVS operating system has long provided mechanisms for achieving per-class performance goals <ref> [Lorin 81, 3 Pierce 83, IBM 93] </ref>. MVS performance goal specification is much more complicated than simply indicating the desired response times for each class, but the net effect is still the same.
Reference: [Mehta 93] <author> M. Mehta and D. DeWitt, </author> <title> "Dynamic Memory Allocation for Multiple-Query Workloads," </title> <booktitle> Proc. 19 Int'l VLDB Conf., </booktitle> <address> Dublin, Ireland, </address> <month> Aug </month> <year> 1993. </year>
Reference-contexts: A limitation of this algorithm is that it cannot satisfy goals for classes which have low buffer hit rates (e.g. sequential scans of infrequently accessed files). While it does not specifically accept response time goals, the adaptive memory allocation and MPL adjustment algorithm described in <ref> [Mehta 93] </ref> is also of interest because its objective of maximizing fairness is very close to the objective of the goal-oriented transaction routing algorithms described in [Ferg 93]. <p> MVS performance goal specification is much more complicated than simply indicating the desired response times for each class, but the net effect is still the same. Much like the adaptive algorithm of <ref> [Mehta 93] </ref>, the System Resources Manager (SRM) component of MVS uses a set of heuristics to guide a feedback mechanism that determines MPLs and working set sizes for each class. <p> It is much easier to develop good controllers for feedback mechanisms that adjust a single knob (such as those in [Brown 93a] and <ref> [Mehta 93] </ref>), as the search space is one dimensional; the only decision required is whether to turn the knob "up" or "down." We have two knobs, however, and are thus faced with a two-dimensional search space.
Reference: [Nikolaou 92] <author> C. Nikolaou, D. Ferguson, P. Constantopoulos, </author> <title> "Towards Goal Oriented Resource Management," </title> <institution> IBM Research Report RC17919, </institution> <month> April </month> <year> 1992. </year>
Reference-contexts: Conversely, even though two classes have similar performance objectives, they may have very different resource demands. Controlling the performance for such a workload by manually adjusting low-level DBMS performance "knobs" will become increasingly impractical, as has been argued previously <ref> [Nikolaou 92, Brown 93b, Selinger 93, Weikum 93] </ref>. Ideally, a DBMS should be able to accept performance goals for each class as inputs, and should dynamically adjust its own low-level performance knobs using the goals as a guide. <p> Finally, we discuss future work and summarize our conclusions in Section 7. 2 Related Work The case for goal-oriented resource management has been argued for distributed computing systems in general <ref> [Nikolaou 92] </ref> and for database management systems in particular [Brown 93b]. The COMFORT project at ETH Zurich is also directed toward the automation of DBMS performance tuning, and is described in [Weikum 93]. <p> We will assume throughout this paper that the system is configured such that it is possible to satisfy the goals for all classes in steady state. In other words, the system does not operate in "degraded mode" <ref> [Nikolaou 92] </ref> except possibly for transient periods. This "non-degraded mode" assumption is important because it allows us to avoid situations in which the algorithm must decide which class (or classes) should be sacrificed so that others may meet their goals.
Reference: [Pang 93a] <author> H. Pang, M. Carey, M. Livny, </author> <title> "Partially Preemptible Hash Joins," </title> <booktitle> Proc. ACM SIGMOD '93 Conf., </booktitle> <address> Washington D.C., </address> <month> May </month> <year> 1993. </year>
Reference-contexts: Beyond these enhancements, our future work will integrate M&M with goal-oriented processor and disk scheduling mechanisms and will exploit memory adaptive query processing techniques (such as the preemptible hash join and sorting methods of <ref> [Pang 93a, Pang 93b] </ref>). Finally, we would like to explore other approaches to specifying goals for low throughput classes.
Reference: [Pang 93b] <author> H. Pang, M. Carey, M. Livny, </author> <title> "Memory Adaptive External Sorts and Sort-Merge Joins," </title> <booktitle> Proc. 19 Int'l VLDB Conf., </booktitle> <address> Dublin, Ireland, </address> <month> Aug </month> <year> 1993. </year>
Reference-contexts: Beyond these enhancements, our future work will integrate M&M with goal-oriented processor and disk scheduling mechanisms and will exploit memory adaptive query processing techniques (such as the preemptible hash join and sorting methods of <ref> [Pang 93a, Pang 93b] </ref>). Finally, we would like to explore other approaches to specifying goals for low throughput classes.
Reference: [Patel 93] <author> J. Patel, M. Carey, M. Vernon, </author> <title> "Accurate Modeling of the Hybrid Hash Join Algorithm," </title> <booktitle> Proc. ACM SIGMETRICS '94, </booktitle> <address> Nashville, TN, </address> <month> May </month> <year> 1994, </year> <note> to appear. </note>
Reference-contexts: Techniques from queuing theory could be applied to account for these delays, but predicting such delays even for a single hash join running alone on a centralized DBMS turns out to be non-trivial due to complexities such as caching disk controllers and intra-operator concurrency <ref> [Patel 93] </ref>.
Reference: [Pierce 83] <author> B. Pierce, </author> <title> "The Most Misunderstood Parts of the SRM," </title> <booktitle> Proc. SHARE 61 (IBM users group), </booktitle> <address> New York NY, </address> <month> Aug </month> <year> 1983. </year>
Reference: [Pirahesh 90] <author> H. Pirahesh, et al, </author> <title> "Parallelism in Relational Database Systems: </title> <booktitle> Architectural Issues and Design Approaches," IEEE 2nd Int'l Symposium on Databases in Parallel and Distributed Systems, </booktitle> <address> Dublin, Ireland, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: 1 Introduction As database management systems continue to increase in function and to expand into new application areas, the diversity of database workloads is increasing as well. In addition to the classic relational DBMS "problem workload" consisting of short transactions running concurrently with long decision support queries <ref> [Pirahesh 90, Brown 92, DeWitt 92] </ref>, we can expect to see workloads comprising an even wider range of resource demands and execution times in the future.
Reference: [Selinger 93] <author> P. Selinger, </author> <title> "Predictions and Challenges for Database Systems in the Year 2000," </title> <booktitle> Proc. 19th Int'l VLDB Conf, </booktitle> <address> Dublin, Ireland, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Conversely, even though two classes have similar performance objectives, they may have very different resource demands. Controlling the performance for such a workload by manually adjusting low-level DBMS performance "knobs" will become increasingly impractical, as has been argued previously <ref> [Nikolaou 92, Brown 93b, Selinger 93, Weikum 93] </ref>. Ideally, a DBMS should be able to accept performance goals for each class as inputs, and should dynamically adjust its own low-level performance knobs using the goals as a guide.
Reference: [Weikum 93] <author> G. Weikum et al, </author> <title> "The COMFORT Project Project Synopsis," </title> <booktitle> Proc. 2nd Int'l Conf. on Parallel and Distributed Information Systems, </booktitle> <address> San Diego CA, </address> <month> Jan </month> <year> 1993. </year>
Reference-contexts: Conversely, even though two classes have similar performance objectives, they may have very different resource demands. Controlling the performance for such a workload by manually adjusting low-level DBMS performance "knobs" will become increasingly impractical, as has been argued previously <ref> [Nikolaou 92, Brown 93b, Selinger 93, Weikum 93] </ref>. Ideally, a DBMS should be able to accept performance goals for each class as inputs, and should dynamically adjust its own low-level performance knobs using the goals as a guide. <p> The COMFORT project at ETH Zurich is also directed toward the automation of DBMS performance tuning, and is described in <ref> [Weikum 93] </ref>. While these position papers describe the motivation for goal-driven systems, very little has been published to date on actual mechanisms for achieving per-class performance goals in a DBMS.
Reference: [Yu 93] <author> P. Yu and D. Cornell, </author> <title> "Buffer Management Based on Return on Consumption in a Multi-Query Environment," </title> <journal> VLDB Journal, </journal> <volume> 2(1), </volume> <month> Jan </month> <year> 1993. </year> <month> 26 </month>
Reference-contexts: In this region of operation, the reduction in MPL queuing provided by a higher MPL outweighs the penalty of a reduced memory allocation per query. These observations support the conclusions of Cornell and Yu <ref> [Yu 93] </ref>, who showed that the best query performance is obtained when queries are allocated either their minimum or maximum memory requirements. Our algorithm will exploit the Cornell and Yu results, as will be explained in Section 4. <p> For small available memory amounts, the best response time 12 is obtained with high MPLs and a per-query memory allocation close to the minimum requirement. These results confirm the memory allocation heuristic derived by Cornell and Yu <ref> [Yu 93] </ref>, which states that the best return on consumption is obtained by allocating only the minimum or the maximum memory requirement of any individual query. Return on consumption is a measure of response time improvement versus the space-time cost of memory.
References-found: 19

