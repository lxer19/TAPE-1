URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P432.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/abstracts/abstracts94.htm
Root-URL: http://www.mcs.anl.gov
Title: PARADIGMS AND STRATEGIES FOR SCIENTIFIC COMPUTING ON DISTRIBUTED MEMORY CONCURRENT COMPUTERS  
Author: Ian T. Foster David W. Walker P. O. David W. Walker P. O. 
Affiliation: Mathematics and Computer Science Argonne National Laboratory  Mathematical Sciences Section Oak Ridge National Laboratory  Oak Ridge National Laboratory  
Address: La Jolla, CA,  Argonne, IL 60439-4844  Box 2008, Bldg. 6012 Oak Ridge, TN 37831-6367  Box 2008 Oak Ridge, TN 37831-6367  
Note: In Proceedings of the High Performance Computing 1994 Conference,  Published by the Society for Computer Simulation, San Diego, CA.  Corresponding author:  (office)  
Email: walker@msr.epm.ornl.gov (email)  
Phone: (615) 574-7401  (615) 574-0680 (fax)  
Date: April 11-15, 1994.  
Abstract-found: 0
Intro-found: 1
Reference: <author> Bal, H. E. </author> <year> 1990. </year> <title> Programming Distributed Systems. </title> <publisher> Silicon Press, </publisher> <address> New Jersey. </address>
Reference-contexts: The work described here is directed at investigating and furthering this trend. Other approaches to parallel programming have been reviewed by Bal <ref> (Bal 1990) </ref>. Coordination languages represent an important alternative to the SL+EMP approach. These are specialized languages for specifying concurrency, communication, and synchronization, and examples include Occam, Strand, PCN, and Fortran M. Fortran M provides a set of extensions to Fortran 77 to support modular message passing programs.
Reference: <author> Bal, H. E.; Kaashoek, M. F.; and Tanenbaum, A. S. </author> <year> 1992. </year> <title> "Orca: A Language for Parallel Programming of Distributed Systems." </title> <journal> IEEE Trans. Software Engineering 18, </journal> <volume> no. 3 </volume> <pages> 190-205. </pages>
Reference-contexts: A pro cess encapsulates common data, subprocesses, and internal communication channels. The use of Fortran M is illustrated for the PIC algorithm in Section 4. Another type of alternative approach involves software support for shared memory, such as the shared virtual memory (Li and Hudak 1989) and shared object <ref> (Bal et al. 1992) </ref> paradigms. Orca provides quite general support for shared objects, while MetaMP (Otto 1991, Otto 1994) provides for globally indexed arrays and certain types of weakly coherent shared data objects. The use of Orca in the PIC algorithm is outlined in Section 5.
Reference: <author> Birdsall, C. K. and Langdon, A. B. </author> <year> 1985. </year> <title> Plasma Physics Via Computer Simulation. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY. </address>
Reference-contexts: Sequential languages with data parallel extensions, such as Fortran-D, Vienna Fortran, and High Performance Fortran, make use of directives for specifying data distribution, and computation is performed using the "owner computes" rule. 3. PARTICLE-IN-CELL APPLICATION The particle-in-cell (PIC) method is commonly used for simulating the evolution of plasmas <ref> (Birdsall and Langdon 1985, Hockney and Eastwood 1988) </ref>. The charged particles making up a plasma move under the influence of the electromagnetic fields that they generate, together with any external fields that may be present.
Reference: <author> Culler, D. E.; Dusseau, A.; Goldstein, S. C.; Krishna-murthy, A.; Lumetta, S.; von Eicken, T.; and Yelick, K. </author> <year> 1993. </year> <title> "Parallel Programming in Split-C." </title> <booktitle> In Proceedings of Supercomputing '93 (Portland, </booktitle> <address> OR, </address> <month> Nov. </month> <pages> 15-19). </pages> <publisher> IEEE Computer Soc. Press, Los Alamitos, CA, </publisher> <pages> 262-273. </pages>
Reference: <author> Foster, I. T. and Chandy, K. M.. </author> <year> 1992. </year> <title> "Fortran M: A Language for Modular Parallel Programming." </title> <type> Technical Report, </type> <institution> Argonne National Laboratory. </institution>
Reference: <author> Foster, I. T.; Olson, R.; and Tuecke, S. </author> <year> 1993. </year> <title> "Programming in Fortran M." </title> <type> Technical Report, </type> <institution> Argonne National Laboratory. </institution>
Reference: <author> Hockney, R. W. and Eastwood, J. W. </author> <year> 1988. </year> <title> Computer Simulation Using Particles. Adam Hilger, </title> <address> Bristol, Eng-land. </address>
Reference: <author> Li, K. and Hudak, P. </author> <year> 1989. </year> <title> "Memory Coherence in Shared Virtual Memory Systems." </title> <journal> ACM Trans. Computers Systems 7, </journal> <volume> no. 4 (Nov.): </volume> <pages> 321-359. </pages> <publisher> MPI. </publisher> <year> 1993. </year> <title> "Document for a Standard Message-Passing Interface." </title> <type> Technical Report CS-93-214, </type> <institution> Department of Computer Science, University of Tennessee, Knoxville, TN. </institution>
Reference-contexts: A pro cess encapsulates common data, subprocesses, and internal communication channels. The use of Fortran M is illustrated for the PIC algorithm in Section 4. Another type of alternative approach involves software support for shared memory, such as the shared virtual memory <ref> (Li and Hudak 1989) </ref> and shared object (Bal et al. 1992) paradigms. Orca provides quite general support for shared objects, while MetaMP (Otto 1991, Otto 1994) provides for globally indexed arrays and certain types of weakly coherent shared data objects.
Reference: <author> Otto, S. W. </author> <year> 1991. </year> <title> "MetaMP: A Higher Level Abstraction for Message Passing Programming." </title> <type> Technical Report CS/E 91-003, </type> <institution> Department of Computer Science and Engineering, Oregon Graduate Institute. </institution>
Reference-contexts: Another type of alternative approach involves software support for shared memory, such as the shared virtual memory (Li and Hudak 1989) and shared object (Bal et al. 1992) paradigms. Orca provides quite general support for shared objects, while MetaMP <ref> (Otto 1991, Otto 1994) </ref> provides for globally indexed arrays and certain types of weakly coherent shared data objects. The use of Orca in the PIC algorithm is outlined in Section 5.
Reference: <author> Otto, S. W. </author> <year> 1994. </year> <title> "Parallel Array Classes and Lightweight Sharing Mechanisms." </title> <journal> Scientific Computing 2, </journal> <volume> no. 4, </volume> <pages> 203-216. </pages> <note> Parallel Computing. 1994. Special Issue on Message Passing. </note>
Reference: <author> Walker, D. W. </author> <year> 1990. </year> <title> "Characterizing the Parallel Performance of a Large Scale, Particle-in-Cell Plasma Simulation Code." </title> <journal> Concurrency: Practice and Experience 2, </journal> <volume> no. </volume> <month> 4 (Dec.): </month> <pages> 257-288. </pages>
Reference-contexts: The update for each particle is independent of all others. There are two basic approaches to parallelizing PIC applications <ref> (Walker 1990, Walker 1991) </ref>. In the first, both the computational grid and the particles are spatially decomposed into processes, and only data lying along process boundaries needs to be moved between processes.
Reference: <author> Walker, D. W. </author> <year> 1991. </year> <title> "Particle-in-Cell Simulations on the Connection Machine." </title> <booktitle> Computing Systems in Engineering 2, </booktitle> <volume> no. 2/3: </volume> <pages> 307-319. </pages>
Reference: <author> Walker, D. W. </author> <year> 1994. </year> <title> "The Design of a Standard Message Passing Interface for Distributed Memory Concurrent Computers." </title> <booktitle> Parallel Computing 20, </booktitle> <volume> no. </volume> <month> 4 (April): 657--673. </month>
References-found: 13

