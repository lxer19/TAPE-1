URL: ftp://ftp.cis.ufl.edu/cis/tech-reports/tr94/tr94-005.ps
Refering-URL: http://www.cis.ufl.edu/tech-reports/tech-reports/tr94-abstracts.html
Root-URL: http://www.cis.ufl.edu
Title: A Combined Unifrontal/Multifrontal Method for Unsymmetric Sparse Matrices  
Author: Timothy A. Davis 
Date: June 1994  
Note: Tech. Report TR-94-005; Proc. Fifth SIAM Conf. on Applied Linear Algebra,  
Abstract: In the multifrontal method, each frontal matrix must hold all of its pivot rows and columns at one time. Moving data between frontal matrices is costly, but the method can handle arbitrary fill-reducing orderings. In the unifrontal method, pivot rows and columns are shifted out of the frontal matrix as the factorization proceeds. Data movement is simpler, but higher fill-in can result. We consider a hybrid unifrontal/multifrontal algorithm. Fill-reducing orderings can still be applied, but data movement is reduced by allowing pivot rows and columns to be shifted into and out of each frontal matrix (just as in the unifrontal method). Performance results on a Cray YMP supercomputer are presented.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. R. Amestoy and I. S. Duff, </author> <title> Vectorization of a multiprocessor multifrontal code, </title> <journal> Int. J. Supercomputer Appl., </journal> <volume> 3 (1989), </volume> <pages> pp. 41-59. </pages>
Reference-contexts: It is inherently sequential (except for the fine-grain parallelism available within the single frontal matrix). The unifrontal method efficiently factorizes a band matrix of bandwidth b with a single (b + 1)-by-(b + 1) frontal matrix. The multifrontal method <ref> [1, 2, 3, 6, 10] </ref> avoids the adverse fill-in properties of the unifrontal method by treating different subgraphs of the matrix with different frontal matrices. It works well for graphs with an overall irregular structure, but with structured subgraphs.
Reference: [2] <author> T. A. Davis, </author> <title> Users' guide to the unsymmetric-pattern multifrontal package (UMFPACK), </title> <type> Tech. Rep. </type> <institution> TR-93-020, CIS Dept., Univ. of Florida, </institution> <address> Gainesville, FL, </address> <year> 1993. </year>
Reference-contexts: It is inherently sequential (except for the fine-grain parallelism available within the single frontal matrix). The unifrontal method efficiently factorizes a band matrix of bandwidth b with a single (b + 1)-by-(b + 1) frontal matrix. The multifrontal method <ref> [1, 2, 3, 6, 10] </ref> avoids the adverse fill-in properties of the unifrontal method by treating different subgraphs of the matrix with different frontal matrices. It works well for graphs with an overall irregular structure, but with structured subgraphs. <p> The undesirable ordering methods required for unifrontal methods are avoided. The combined method factorizes a band matrix of bandwidth b with a single (b + k)-by-(b + k) frontal matrix (and thus no assembly operations between frontal matrices), using rank-k updates. We use UMFPACK <ref> [2, 3] </ref> as a starting point for the combined method, although the approach can be applied to any multifrontal algorithm.
Reference: [3] <author> T. A. Davis and I. S. Duff, </author> <title> An unsymmetric-pattern multifrontal method for sparse LU factorization, </title> <type> Tech. Rep. </type> <institution> TR-93-018, CIS Dept., Univ. of Florida, </institution> <address> Gainesville, FL, </address> <year> 1993. </year>
Reference-contexts: It is inherently sequential (except for the fine-grain parallelism available within the single frontal matrix). The unifrontal method efficiently factorizes a band matrix of bandwidth b with a single (b + 1)-by-(b + 1) frontal matrix. The multifrontal method <ref> [1, 2, 3, 6, 10] </ref> avoids the adverse fill-in properties of the unifrontal method by treating different subgraphs of the matrix with different frontal matrices. It works well for graphs with an overall irregular structure, but with structured subgraphs. <p> The undesirable ordering methods required for unifrontal methods are avoided. The combined method factorizes a band matrix of bandwidth b with a single (b + k)-by-(b + k) frontal matrix (and thus no assembly operations between frontal matrices), using rank-k updates. We use UMFPACK <ref> [2, 3] </ref> as a starting point for the combined method, although the approach can be applied to any multifrontal algorithm. <p> The arrows denote how these matrices grow as new pivots are added. When pivots are removed from the working array in Figure 1 (b), the contribution block does not need to be repositioned. 3 Performance The test collection consists of the 86 matrices used in <ref> [3] </ref>. Each method has a number of user-selectable parameters; these are varied for each matrix, and the fastest time thus obtained is used as the run time for that method and that matrix.
Reference: [4] <author> J. J. Dongarra, J. Du Croz, S. Hammarling, and I. S. Duff, </author> <title> A set of level-3 basic linear algebra subprograms, </title> <journal> ACM Trans. Math. Softw., </journal> <volume> 16 (1990), </volume> <pages> pp. 1-17. </pages>
Reference-contexts: Pivots are not shifted into or out of the frontal matrix. More than one pivot within a frontal matrix is desirable, as this allows the use of a dense matrix-multiply in the innermost loop (the Level-3 BLAS <ref> [4] </ref>). Once the factorization of the active frontal matrix is complete, the remaining contribution block is assembled (added) into a subsequent frontal matrix.
Reference: [5] <author> I. S. Duff, </author> <title> Design features of a frontal code for solving sparse unsymmetric linear systems out-of-core, </title> <journal> SIAM J. Sci. Statis. Comput., </journal> <volume> 5 (1984), </volume> <pages> pp. 270-280. </pages>
Reference-contexts: 1 Unifrontal and Multifrontal methods In the unifrontal method <ref> [5, 11] </ref>, the entire matrix is factorized within a single frontal matrix. Rows and columns of the active submatrix are shifted into the frontal matrix, and pivot rows and columns are shifted out and stored in the LU factors.
Reference: [6] <author> I. S. Duff and J. K. Reid, </author> <title> The multifrontal solution of unsymmetric sets of linear equations, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 5 (1984), </volume> <pages> pp. 633-641. </pages>
Reference-contexts: It is inherently sequential (except for the fine-grain parallelism available within the single frontal matrix). The unifrontal method efficiently factorizes a band matrix of bandwidth b with a single (b + 1)-by-(b + 1) frontal matrix. The multifrontal method <ref> [1, 2, 3, 6, 10] </ref> avoids the adverse fill-in properties of the unifrontal method by treating different subgraphs of the matrix with different frontal matrices. It works well for graphs with an overall irregular structure, but with structured subgraphs.
Reference: [7] <author> A. George and J. W. H. Liu, </author> <title> Computer Solution of Large Sparse Positive Definite Systems, </title> <address> Englewood Cliffs, New Jersey: </address> <publisher> Prentice-Hall, </publisher> <year> 1981. </year>
Reference-contexts: Rows and columns of the active submatrix are shifted into the frontal matrix, and pivot rows and columns are shifted out and stored in the LU factors. In the context of the elimination graph model <ref> [7] </ref>, subsequent pivot nodes are selected only within the single clique. Pivot nodes are dropped from the clique as they are factorized. The method works well for envelope-limited matrices. The overhead is low: no assembly operations are needed between frontal matrices, and a degree update phase is not required.
Reference: [8] <author> S. Hadfield and T. A. Davis, </author> <title> Analysis of potential parallel implementations of the unsymmetric-pattern multifrontal method for sparse LU factorization, </title> <type> Tech. Rep. </type> <institution> TR-92-017, CIS Dept., Univ. of Florida, </institution> <address> Gainesville, FL, </address> <month> June </month> <year> 1992. </year>
Reference-contexts: In addition, MUPS is a parallel code. It is being compared with strictly sequential codes in this paper, running on only a single processor. The theoretically-achievable parallelism in MUPS and UMFPACK is similar <ref> [8] </ref>, and good results have been obtained in a preliminary parallel, distributed-memory factor-only phase of UMFPACK. A parallel analysis+factorize version of UMFPACK or the combined method is not yet developed. D2 is faster than the combined method for 23 matrices, mostly of which are small or extremely sparse.
Reference: [9] <author> J. W. H. Liu, </author> <title> The role of elimination trees in sparse factorization, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 11 (1990), </volume> <pages> pp. </pages> <month> 134-172. </month> <title> [10] , The multifrontal method for sparse matrix solution: </title> <journal> theory and practice, SIAM Review, </journal> <volume> 34 (1992), </volume> <pages> pp. 82-109. </pages>
Reference-contexts: CIS tech reports available via anonymous ftp to ftp.cis.ufl.edu:cis/tech-reports. 1 2 Davis matrices are related by an assembly tree, which is typically identical to the elimination tree <ref> [9] </ref> if each frontal matrix contains only one pivot each. In the unsymmetric-pattern multifrontal method, the tree is replaced with a dag, and a contribution block may be assembled into more than one subsequent frontal matrix.
Reference: [11] <author> S. E. Zitney and M. A. Stadtherr, </author> <title> Supercomputing strategies for the design and analysis of complex separation systems, </title> <institution> Ind. Eng. Chem. Res., </institution> <month> 32 </month> <year> (1993), </year> <pages> pp. 604-612. </pages>
Reference-contexts: 1 Unifrontal and Multifrontal methods In the unifrontal method <ref> [5, 11] </ref>, the entire matrix is factorized within a single frontal matrix. Rows and columns of the active submatrix are shifted into the frontal matrix, and pivot rows and columns are shifted out and stored in the LU factors. <p> D2 is faster than the combined method for 23 matrices, mostly of which are small or extremely sparse. The D2 algorithm is faster for the four small chemical engineering matrices (from the Harwell/Boeing collection), but much slower for the larger matrices in the same domain (from <ref> [11] </ref>). The MA28 algorithm has similar behavior as the D2 algorithm: it is faster than the combined method for 18 matrices, in similar domains as the D2 algorithm. 4 Conclusions We have demonstrated how the advantages of the unifrontal and multifrontal methods can be combined.
References-found: 10

