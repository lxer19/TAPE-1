URL: http://www.eecs.umich.edu/~optimus/dissertation.ps
Refering-URL: http://www.eecs.umich.edu/~optimus/
Root-URL: http://www.cs.umich.edu
Title: Randomized Algorithms and Global Optimization for Optimal and Robust Control  
Author: by Albert Yoon Professor James S. Freudenberg Kumar Hebbale, Staff 
Degree: A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy  Doctoral Committee: Professor Pramod P. Khargonekar, Chair  Professor Vijay Nair  
Address: Motors R&D Center  
Date: 1998  
Affiliation: (Electrical Engineering Systems) in The University of Michigan  Research Engineer, General  
Abstract-found: 0
Intro-found: 1
Reference: <institution> 109 BIBLIOGRAPHY </institution>
Reference: [1] <author> M. Ali, A. Torn, and S. Viitanen, </author> <title> "Stochastic global optimization: Problem classes and solution techniques," </title> <type> Technical Report 37, </type> <institution> Turku Centre for Computer Science, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: There are several collections of problems [22, 56, 58] that have been compiled 33 which feature different difficulties such as nondifferentiability or a large number of local minima. In <ref> [1] </ref>, an attempt is also made at classifying these problems into classifications of difficulty. An easy problem would be those that have few local minima which have large basins of attraction. Even a few runs of a multistart algorithm would suffice. <p> The hypercube can be shrunk and translated so that all the vertices have coordinates that are 0 or 1. Then the coordinates can be interpreted as the binary representation of an integer. For example, the vertex <ref> [1; 1; 0; 1; 0; 0; 1; 1] </ref> would be converted to 211. This reduces that problem to being one-dimensional. An example is shown below in Figure 5.6a when a 16 fi 16 problem is reduced to one dimension. <p> This reduces that problem to being one-dimensional. An example is shown below in Figure 5.6a when a 16 fi 16 problem is reduced to one dimension. Likewise, the coordinates can also be interpreted as a the binary representation of a pair of coordinates. In this case, the vertex <ref> [1; 1; 0; 1; 0; 0; 1; 1] </ref> would be converted to (13; 3).
Reference: [2] <author> M. Ali, A. Torn, and S. Viitanen, </author> <title> "A numerical comparison of some modified controlled random search algorithms," </title> <type> Technical Report 98, </type> <institution> Turku Centre for Computer Science, </institution> <month> March </month> <year> 1997. </year>
Reference-contexts: The focus of this work is on randomized algorithms as opposed to deterministic algorithms for optimization. The rationale for this focus is that randomized algorithms have been shown to have some desirable properties <ref> [2, 30] </ref> over deterministic algorithms that will be useful to us. * Heuristic vs. Analytic: Most of the algorithms given here are heuristic. The use of heuristic, randomized algorithms may be somewhat unsettling due to the lack of theoretical guarantees of computational complexity or performance. <p> Variations on the pure random search such as partitioning or shrinking the input space are made to improve its efficiency. A third algorithm is the controlled random search (CRS) which has many variants. The version used in this study is from <ref> [2] </ref>. By using information from a group of points in X, the CRS determines where the next samples should be made. Finally, the Shu*ed Complex Evolution (SCE) approach of [19] which uses elements of the CRS and partitioned random search techniques is implemented and tested. <p> The first step is to generate a group of random points over the entire search space. In general, the strategy is to replace the worst points of the group with better points through a selected operation. The Nelder-Mead simplex method may be considered as one form of CRS. In <ref> [2] </ref>, a numerical comparison of several CRS algorithms is presented and a new CRS algorithm is introduced. In light of the positive results of the algorithm presented in [2], it is used in this study. * Controlled Random Search Inputs: N , ffi , tolerance Initialization: Uniformly generate a group, A <p> The Nelder-Mead simplex method may be considered as one form of CRS. In <ref> [2] </ref>, a numerical comparison of several CRS algorithms is presented and a new CRS algorithm is introduced. In light of the positive results of the algorithm presented in [2], it is used in this study. * Controlled Random Search Inputs: N , ffi , tolerance Initialization: Uniformly generate a group, A of N points and evaluate them. <p> Step 4 is a dedicated local search about the current best point. The number of points, N , in A is user-defined and a value of 10 (n + 1) is suggested. Several numerical studies have been done on this version of the CRS by the authors of <ref> [2] </ref>. The results are compared with other algorithms that the authors had devised, as well as simulated annealing. There are several problems which are considered, such as minimization of some benchmark problems such as Shekel, fitting parameters for maximum likelihood estimation, and minimization of a many-body potential function. <p> Only the crude random search and ARS I are guaranteed to converge in probability to the global optimum as the number of function evaluations tends to infinity. On the other hand, ARS II is not even guaranteed to converge to a local optimum. In <ref> [2] </ref>, it is stated that the CRS algorithm is totally heuristic and lacks theoretical convergence properties. According to Subrahmanyam in [59], convergence theorems for the Nelder-Mead algorithm alone are practically nonexistent even though the algorithm has was presented in 1965. <p> Tests for the efficiency of the algorithms have mainly been done through the use of numerical experiments. In <ref> [2] </ref>, the proposed CRS algorithm is compared with other CRS algorithms on a set of benchmark problems using numerical experiments. In [44], they are used to compare the Nelder-Mead algorithm with other direct methods and in [45] they are used to propose modifications to the algorithm to improve its efficiency. <p> The following methods, which are described in detail in Chapter 2 are investigated here: 1. Multi-start of Rosenbrock's method [8] 2. Crude and adaptive random search [30] 3. Adaptive partitioned random search [60] 61 4. Controlled random search <ref> [2] </ref> and shu*ed complex evolution [19] It is very difficult to establish theoretical properties of all but the simplest of these algorithms. Therefore, the efficacy of the algorithms is evaluated on several robust stability analysis problems with real-valued uncertainties for this investigation.
Reference: [3] <author> M. Ali, C.Storey, and A. Torn, </author> <title> "Application of some recent stochastic global optimization algorithms to practical problems," </title> <type> Technical Report 47, </type> <institution> Turku Center for Computer Science, </institution> <month> October </month> <year> 1996. </year>
Reference-contexts: Also, except in [52], only local minimization is considered. Having said this, we propose a randomized algorithms approach to solve the nonlinear optimization problem. To our knowledge, such an approach has not been studied extensively for optimal control. Indeed, Torn in <ref> [3] </ref> says: "Solving nonlinear optimal control problems with multiple minima by global optimization in general has never been addressed either by control engineers or by the global optimization community." Our aim is to show that a randomized algorithms approach for this problem has potential due to its simplicity of implementation, effectiveness <p> The success demonstrated in this example is encouraging but it would be interesting to see how they perform on other optimal control problems. Some possible examples are orbit transfer problems [9] or chemical reactor processes <ref> [3] </ref>. There are two issues that need to be addressed further: * Parameterization: If the control inputs are complex, many parameters may be needed to describe it. In the transmission problem, not too many parameters were needed to describe the ramp-like control inputs.
Reference: [4] <author> V. Balakrishnan, S. Balemi, and S. Boyd, </author> <title> "Computation of the Minimum Stability Degree of Parameter-dependent Linear Systems by a Branch and Bound Algorithm," </title> <booktitle> in Proceedings of 1st IFAC Symposium on Design Methods of Control Systems, </booktitle> <pages> pp. 133-138, </pages> <address> Zurich, Switzerland, </address> <month> September </month> <year> 1991. </year>
Reference-contexts: Deterministic branch and bound techniques have been applied to the real robust stability analysis problem in [42] and also to a related problem of finding the minimum stability degree in <ref> [4] </ref>. While branch and bound provides both upper and lower bounds on the size of the smallest destabilizing perturbation, they also require a sweep over a one dimensional parameter such as frequency.
Reference: [5] <author> B. R. Barmish and C. M. Lagoa, </author> <title> "The uniform distribution: a rigorous justification for its use in robustness analysis," </title> <booktitle> in Proceedings of the 35th IEEE International Conference on Decision and Control, </booktitle> <pages> pp. 3418-3423, </pages> <address> Kobe, Japan, </address> <year> 1996. </year>
Reference-contexts: There are some results in the literature <ref> [5, 30, 48, 61] </ref> which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. There are several issues that require better understanding. One is whether certain optimization algorithms are better suited for robust stability than others. <p> However, there are no such widely accepted benchmark problems, at least at this time. There are some results in the literature <ref> [5, 30, 48, 61] </ref>, which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. Genetic algorithms for robust stability analysis have been investigated in 60 [36, 68].
Reference: [6] <author> B. Barmish, P. Khargonekar, Z. Shi, and R. Tempo, </author> <title> "Robustness margin need not be a continuous function of the problem data," </title> <journal> System & Control Letters, </journal> <volume> vol. 15, </volume> <pages> pp. 91-98, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: Another related problem that could occur in other examples is that can be a discontinuous function of frequency <ref> [6] </ref> and so how fine the grid is is an important issue. Some preliminary results for larger problems have also been generated. <p> Instead of resorting to the traditional means of computing the upper and lower bounds of , which can provide very poor bounds, the problem is posed as a global minimization problem and randomized algorithms are used to solve the problem <ref> [6] </ref>. In the case where the system M is dynamic, (i.e. M = (A; B; C)) the approach taken here has the advantage that a frequency sweep does not have to be done to compute (or more accurately, its inverse).
Reference: [7] <author> R. Battiti, </author> <title> Modern Heuristic Search Methods, </title> <booktitle> chapter 4, </booktitle> <pages> pp. 61-83, </pages> <publisher> John Wiley & Sons Ltd., </publisher> <year> 1996. </year>
Reference-contexts: The tabu search tries to use more past data to improve future searches, which the DARS presently does not do, and may provide better results. In particular, the reactive tabu search <ref> [7] </ref>, uses function evaluations to guide future searches by storing information in memory and also adaptively tuning the algorithm parameters. For the general problem the effect of different cost formulations of the robust sta 96 bility analysis problem as a global optimization problem was shown to be an interesting issue.
Reference: [8] <author> M. Bazaraa, H. Sherali, and C. M. Shetty, </author> <title> Nonlinear Programming Theory and Algorithms, </title> <publisher> Wiley & Sons, Inc., </publisher> <address> New York, </address> <note> second edition, </note> <year> 1993. </year>
Reference-contexts: The first algorithm is a multistart version of Rosenbrock's line search method. There are several line search methods such as Zangwill's [67] and Hooke and Jeeve's <ref> [8] </ref> but they are not examined here. Apart from selecting the initial conditions randomly, the algorithm is purely deterministic. Next, we consider perhaps the simplest class of randomized algorithms, containing the pure random search and variants there of. <p> For a minimization problem all of these algorithms place an upper bound on J (x fl ). 2.3.1 Line Searches and Random Multistart There are many line search methods for solving optimization problems. The algorithm of Rosenbrock <ref> [8] </ref> is presented here as an example. It is deterministic and also differs from the random searches in that it moves only a single point; the random algorithms attempt to move a group of points. <p> k Let S j = S j and d j = d j for each j, let y 1 = x k+1 , let k = k + 1, let j = 1, and go to step 1. 17 Rosenbrock's algorithm is attractive because, unlike say Hooke and Jeeve's algorithm <ref> [8] </ref> which always cycles through the coordinate directions for its line search, it changes its set of orthogonal line search directions to suit the cost function. Numerical experiments have shown this algorithm to be more efficient than those that do not adapt its line search directions. <p> Three trials are performed for each algorithm and the best shifts obtained from each are recorded in Table 4.1. The average number of function calls and times for each algorithm are also given. For further comparison, Rosenbrock's line search technique <ref> [8] </ref> is used to try to find the solution, although it is inherently a local optimization technique. It is used three times with different initial starting points. The results of the best of the three trials is recorded in Table 4.1. <p> Since robust control problems often lead to nondifferentiable optimization problems, direct methods will have broader applicability. The following methods, which are described in detail in Chapter 2 are investigated here: 1. Multi-start of Rosenbrock's method <ref> [8] </ref> 2. Crude and adaptive random search [30] 3. Adaptive partitioned random search [60] 61 4. Controlled random search [2] and shu*ed complex evolution [19] It is very difficult to establish theoretical properties of all but the simplest of these algorithms.
Reference: [9] <author> J. T. Betts, </author> <title> "Issues in the direct transcription of optimal control problems to sparse nonlinear programs," in Computational Optimal Control, </title> <editor> R. Bulirsch and D. Kraft, </editor> <booktitle> editors, </booktitle> <pages> pp. 3-17, </pages> <publisher> Birkhauser Verlag, </publisher> <year> 1994. </year>
Reference-contexts: A common strategy is to convert the optimal control problem into a nonlinear programming problem and then use a nonlinear optimization algorithm which is local in nature. Work in <ref> [9, 52, 63] </ref> show examples of this approach. However, except for [52], which is a multistart algorithm, these techniques are focused on local optimization and do not address the possibility of finding a local minimum instead of the global one. <p> Conclusions and a brief discussion of the techniques and results are presented in Section 4.4. Present approaches to computational optimal control involve converting the optimal control problem into a nonlinear programming problem and using nonlinear optimization solution techniques. Several examples are the direct transcription approach, summarized in <ref> [9] </ref>, and the control and state trajectory approximation approaches in [52] and [63]. These approaches are more or less deterministic except possibly in the way the initial conditions are selected. In the direct transcription approach in [9], the differential equations are dis-cretized and used as constraints in the nonlinear programming problem. <p> Several examples are the direct transcription approach, summarized in <ref> [9] </ref>, and the control and state trajectory approximation approaches in [52] and [63]. These approaches are more or less deterministic except possibly in the way the initial conditions are selected. In the direct transcription approach in [9], the differential equations are dis-cretized and used as constraints in the nonlinear programming problem. The optimization routine then finds the values of the states and control inputs at those time instances which minimize the cost function and satisfy the constraints. <p> The success demonstrated in this example is encouraging but it would be interesting to see how they perform on other optimal control problems. Some possible examples are orbit transfer problems <ref> [9] </ref> or chemical reactor processes [3]. There are two issues that need to be addressed further: * Parameterization: If the control inputs are complex, many parameters may be needed to describe it. In the transmission problem, not too many parameters were needed to describe the ramp-like control inputs.
Reference: [10] <author> B.K.Powell, </author> <title> "A dynamic model for automotive engine control analysis," </title> <booktitle> in Proceedings of the IEEE International Conference on Decision and Control, </booktitle> <pages> pp. 120-126, </pages> <year> 1979. </year>
Reference-contexts: The simulation parameter data are listed in Appendix A. 3.3.1 Engine The engine is a complex, highly nonlinear mechanism to model. However, several simplified models that capture the engine's dynamics exist. Both [18] and <ref> [10] </ref> represent early dynamic engine models for control purposes. Even now, engine models are based on the model found in [18] such as that in [38].
Reference: [11] <author> R. Braatz, P. Young, J. Doyle, and M. Morari, </author> <title> "Computational complexity of calculation," </title> <booktitle> in Proceedings of the American Control Conference, </booktitle> <pages> pp. 1682-1683, </pages> <address> San Francisco, California, </address> <year> 1993. </year> <month> 110 </month>
Reference-contexts: Several results have shown that except for a very specific class problems for which analytic results such as Kharitonov's Theorem exist, such problems are NP-hard <ref> [11, 40] </ref>. Therefore the difficulty in the analysis are inherent in the problem and not due to a lack of cleverness on the part of control researchers. Due to these results on computational complexity, an alternative approach to the robust stability problem seems useful. <p> This appears to be even more so for the case of real parameter uncertainty. Results on computational complexity <ref> [11, 40] </ref> of robust stability analysis provide strong support for such conclusions. The fundamental underlying reason appears to be the fact that these problems typically involve nonconvex optimization having many local minima. It is only in very special cases that one has neat analytical solutions. <p> Experience has shown that these bounds can be arbitrarily conservative and recently, it has been proven that solving these problems is NP hard <ref> [11] </ref>. Therefore a reasonable course of action is to move our focus towards efficient means of coming to an approximate solution and reduce the conservatism of the bounds. <p> Since M and are real and the ffi are not repeated, it can be shown [41] that the solution of (5.11) is on a vertex of B. The solution of this problem is known to be NP hard <ref> [11] </ref> and so one usually resorts to computing upper and lower bounds on with algorithms that have polynomial complexity.
Reference: [12] <author> A. Bryson and Y. Ho, </author> <title> Applied optimal control : optimization, estimation, and control, </title> <publisher> Hemisphere Pub. Corp., </publisher> <year> 1975. </year>
Reference-contexts: The goal of determining properly coordinated clutch control inputs can be posed as an open-loop optimal control problem. Optimal control of nonlinear systems has traditionally been handled by Pontryagin's 4 Maximum Principle or the Hamilton-Jacobi-Bellman equations <ref> [12, 35] </ref>. However, these methods apply only to very simple problems and the model of the powertrain is complex enough that it needs to be dealt with using computational open-loop optimal control techniques.
Reference: [13] <author> R. Byrd, E. Eskow, A. Hoek, R. Schnabel, C. Shao, and Z. Zou, </author> <title> "Global optimization methods for protein folding problems," </title> <booktitle> in DIMACS Series in Discrete Mathematics and Theoretical Computer Science, </booktitle> <volume> volume 23, </volume> <pages> pp. 29-39, </pages> <publisher> American Mathematical Society, </publisher> <address> Providence, Rhode Island, </address> <year> 1996. </year>
Reference-contexts: This interest has spawned many efforts towards developing global optimization techniques. In science and engineering, such problems arise in: structural design [27], chemical process scheduling [57], circuit design [58], and protein folding <ref> [13] </ref> among others. Even the financial arena is interested in optimization for problems such as determining optimal trading policies. A collection of reported applications of global optimization can be found in [46] and a good summary of global optimization techniques can be found in [50, 62].
Reference: [14] <author> T.-S. Chiang and Y. Chow, </author> <title> "On the convergence rate of annealing processes," </title> <journal> SIAM Journal on Control and Optimization, </journal> <volume> vol. 26, no. 6, </volume> <pages> pp. 1455-1470, </pages> <year> 1988. </year>
Reference-contexts: Consider a combinatorial optimization problem. When the cooling schedule of the simulated annealing is sufficiently slow, statements can be made about its asymptotic convergence. However, these results are meaningless since it turns out that multistart local searches [21] and random searches <ref> [14] </ref> have better asymptotic convergence to the global minimum. In fact, simulated annealing would typically search more points than there are in the entire search space [49]. With a faster cooling schedule, simulated annealing is more practical but then the asymptotic results do not apply.
Reference: [15] <author> D. Cho, </author> <title> Nonlinear Control Methods for Autmotive Powertrain Systems, </title> <type> PhD thesis, </type> <institution> Massachusetts Institute of Technology Department of Mechanical Engineering, </institution> <year> 1987. </year>
Reference-contexts: For this investigation we present a dynamic model for a clutch-to-clutch shifting automatic transmission. The modeling process starts off by establishing the static and dynamic equations that describe the subsystems of the power-train. Our models are obtained by combining results from the published literature <ref> [15] </ref>, 35 [16], [31]. For most of the components, the models are obtained through derivation from first principles while for others, fairly well established empirical models are used. After this, the subsystems are all connected to form the complete powertrain model. <p> commanded by an onboard microprocessor. 3.3 Physical Model A low order model is desirable to simplify the controller synthesis process but at the same time it must be complex enough that it captures the relevant dynamics of the powertrain. 37 Past work done on modeling powertrains can be found in <ref> [15] </ref>, [16], and [31]. The powertrain model used in this work is slightly simpler than those found in the cited references. The frequency range of interest is from about 0-20 Hz and high frequency effects such as transmission noise and gear backlash are not modeled.
Reference: [16] <author> D. Cho and J. Hedrick, </author> <title> "Automotive powertrain modeling for control," </title> <journal> Transactions of the ASME, </journal> <volume> vol. 111, </volume> <pages> pp. 568-576, </pages> <year> 1989. </year>
Reference-contexts: For this investigation we present a dynamic model for a clutch-to-clutch shifting automatic transmission. The modeling process starts off by establishing the static and dynamic equations that describe the subsystems of the power-train. Our models are obtained by combining results from the published literature [15], 35 <ref> [16] </ref>, [31]. For most of the components, the models are obtained through derivation from first principles while for others, fairly well established empirical models are used. After this, the subsystems are all connected to form the complete powertrain model. <p> by an onboard microprocessor. 3.3 Physical Model A low order model is desirable to simplify the controller synthesis process but at the same time it must be complex enough that it captures the relevant dynamics of the powertrain. 37 Past work done on modeling powertrains can be found in [15], <ref> [16] </ref>, and [31]. The powertrain model used in this work is slightly simpler than those found in the cited references. The frequency range of interest is from about 0-20 Hz and high frequency effects such as transmission noise and gear backlash are not modeled. <p> In a more complex model, the clutch slip for any clutch that is engaged would be zero. However, the transmission model would then have to be a collection of different models which are switched when the transmission does from one mode to another. In <ref> [16] </ref>, different models are provided for the transmission for first gear, second gear, and for the torque and inertia phases of the torque transient during the shift from first to second gear.
Reference: [17] <author> R. R. E. de Gaston and M. G. Safonov, </author> <title> "Exact calculation of the multiloop stability margin," </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> vol. 33, </volume> <pages> pp. 156-171, </pages> <year> 1988. </year>
Reference-contexts: (Re ((A + BC))) (5.2) where (X) is the set of eigenvalues of X, then fl opt = inf (kk 1 : (M; ) is unstable) = inf (kk 1 : (M; ) 0): Solving this problem would typically be handled by the real structured singular value (real ) theory <ref> [17, 65] </ref>. However, real analysis and synthesis problems are very difficult and one usually resorts to computing upper and lower bounds on the quantities of interest such as fl opt .
Reference: [18] <author> D. Dobner, </author> <title> "Dynamic engine models for control development, part i: Nonlinear and linear model formulation," </title> <journal> International Journal of Vehicle Design, </journal> <volume> vol. SP4, </volume> , <year> 1982. </year>
Reference-contexts: The simulation parameter data are listed in Appendix A. 3.3.1 Engine The engine is a complex, highly nonlinear mechanism to model. However, several simplified models that capture the engine's dynamics exist. Both <ref> [18] </ref> and [10] represent early dynamic engine models for control purposes. Even now, engine models are based on the model found in [18] such as that in [38]. <p> However, several simplified models that capture the engine's dynamics exist. Both <ref> [18] </ref> and [10] represent early dynamic engine models for control purposes. Even now, engine models are based on the model found in [18] such as that in [38]. The model used here is further simplified and incorporates a steady state map T e (! e ; ff) with throttle angle, ff, and engine speed, ! e , as inputs and engine torque, T e , as the output.
Reference: [19] <author> Q. Duan, S. Sorooshian, and V. Gupta, </author> <title> "Effective and efficient global optimization for conceptual rainfall-runoff models," </title> <journal> Water Resources Research, </journal> <volume> vol. 28, no. 4, </volume> <pages> pp. 1015-1031, </pages> <year> 1992. </year>
Reference-contexts: The version used in this study is from [2]. By using information from a group of points in X, the CRS determines where the next samples should be made. Finally, the Shu*ed Complex Evolution (SCE) approach of <ref> [19] </ref> which uses elements of the CRS and partitioned random search techniques is implemented and tested. For a minimization problem all of these algorithms place an upper bound on J (x fl ). 2.3.1 Line Searches and Random Multistart There are many line search methods for solving optimization problems. <p> In particular, their version of the CRS algorithm performed very well. Simulated annealing usually found solutions of high quality but required at least an order of magnitude more computational effort. 2.3.5 Shu*ed Complex Evolution (SCE) The so-called Shu*ed Complex Evolution (SCE) approach of <ref> [19] </ref> combines ideas of APRS and CRS. The APRS part of the algorithm separates the group of points into several partitions and for a certain period of time the partitions are treated independently (until the points are shu*ed). <p> A simplex step is interpreted as an evolutionary step of a population while shu*ing is interpreted as communication and 26 cooperation between populations. The procedure can be found in <ref> [19] </ref> and is outlined below. * Shu*ing Inputs: s (such that s n + 1 where n is the dimension of the input space), p, * Initialization: Evaluate the cost function at sp points x 1 ; x 2 ; : : : ; x sp where s is the number <p> In this way, all points in the complex have a chance to participate in evolution, but it is the better points that will participate more often. Finally, randomness can enter when an infeasible point is picked due to reflection or contraction. In <ref> [19] </ref> it is suggested that a point randomly chosen from the smallest hypercube that contains the complex replace the infeasible one. The parameters of this approach are s, p, c reflect , c contract , ff, and fi. <p> The following methods, which are described in detail in Chapter 2 are investigated here: 1. Multi-start of Rosenbrock's method [8] 2. Crude and adaptive random search [30] 3. Adaptive partitioned random search [60] 61 4. Controlled random search [2] and shu*ed complex evolution <ref> [19] </ref> It is very difficult to establish theoretical properties of all but the simplest of these algorithms. Therefore, the efficacy of the algorithms is evaluated on several robust stability analysis problems with real-valued uncertainties for this investigation.
Reference: [20] <author> Q. Duan, S. Sorooshian, and V. Gupta, </author> <title> "Optimal use of the SCE-UA global optimization method for calibrating watershed models," </title> <journal> Journal of Hydrology, </journal> <volume> vol. 158, </volume> <pages> pp. 265-284, </pages> <year> 1994. </year>
Reference-contexts: A higher fi may also increase robustness at the expense of decreased efficiency while a higher ff may decrease robustness since more worst-point replacements occur before a new simplex is chosen from the complex. The relationships between these parameters and 28 29 robustness and efficiency are examined in <ref> [20] </ref> and are based on numerical experiments. The authors of this algorithm intended to use it to calibrate conceptual rainfall-runoff models. These models were to predict stream flows caused by precipitation. This problem is known to have many local minima and so this global optimization algorithm was developed. <p> The rest of the parameter values chosen were ff = 1, fi = 2n + 1 and s = 2n + 1 in accordance with the values recommended in <ref> [20] </ref>.
Reference: [21] <author> A. Ferreira and J. Zerovnik, </author> <title> "Bounding the probability of success of stochastic methods for global optimization," </title> <journal> Computers and Mathematics with Applications, </journal> <volume> vol. 25, no. </volume> <pages> 10-11, pp. 1-8, </pages> <year> 1993. </year>
Reference-contexts: Consider a combinatorial optimization problem. When the cooling schedule of the simulated annealing is sufficiently slow, statements can be made about its asymptotic convergence. However, these results are meaningless since it turns out that multistart local searches <ref> [21] </ref> and random searches [14] have better asymptotic convergence to the global minimum. In fact, simulated annealing would typically search more points than there are in the entire search space [49]. With a faster cooling schedule, simulated annealing is more practical but then the asymptotic results do not apply.
Reference: [22] <author> C. Floudas and P. Pardalos, </author> <title> A Collection of Test Problems for Constrained Global Optimization Algorithms, </title> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: As work on global optimization techniques continue to develop, the need to compare their effectiveness, generality, and efficiency is becoming greater in the global optimization community. There are several collections of problems <ref> [22, 56, 58] </ref> that have been compiled 33 which feature different difficulties such as nondifferentiability or a large number of local minima. In [1], an attempt is also made at classifying these problems into classifications of difficulty.
Reference: [23] <author> B. Francis, </author> <title> A Course in H 1 Control Theory, </title> <publisher> Springer-Verlag, </publisher> <year> 1986. </year>
Reference-contexts: In control theory, a problem is frequently posed in terms of an optimization problem where the design or analysis specifications are met when an optimizing solution is found. Classic examples of optimal controller synthesis techniques are LQR [37], LQG [37], and H 1 <ref> [23] </ref>. If y = Hu, where H is a transfer function, then minimizing the H 2 norm of H minimizes the two norm y when u is an impulse.
Reference: [24] <author> M. Fu and R. Barmish, </author> <title> "Maximal unidirectional perturbation bounds for stability of polynomials and matrices," </title> <journal> Systems & Control Letters, </journal> <volume> vol. 11, </volume> <pages> pp. 173-179, </pages> <year> 1988. </year>
Reference-contexts: We presented two different global optimization formulations for the underlying robust stability analysis problem. One was relatively quick to evaluate but was also very "rough", containing many local 7 minima. The other was based on an analytical result derived by Fu and Barmish <ref> [24] </ref> and was observed likely to have fewer local minima. The drawback of this is that the cost function was also more expensive to evaluate. The formulation of the optimal problem was determined to be a significant factor in the performance of the algorithms. <p> The formulation of the analysis problems is not unique and different formulations may significantly affect the performance of the global optimization algorithms that are applied to the problem. One of these formulations utilizes a result on maximal unidirectional perturbation bounds due to Fu and Barmish <ref> [24] </ref>. For global optimization, attention is restricted to direct methods, where "direct" refers to methods that use only the value of the objective function but no derivative or any other analytical information. Since robust control problems often lead to nondifferentiable optimization problems, direct methods will have broader applicability. <p> For the first problem, several of the algorithms are applied to a 15th degree polynomial example from [30] where the real coefficients vary over a hyper-rectangle. By Kharitonov's Theorem, a well defined computation exists <ref> [24] </ref> for getting the solution against which the results of the randomized algorithms can be compared. The second example comes from [54] and represents a linearized model of the closed-loop system of a bank-to-turn, air-to-air missile with a linear H 1 controller. <p> Consider all perturbations such that kk 1 is unity, and for M = (A; B; C) and ~ 2 R define A = A + ~BC. Fu and Barmish <ref> [24] </ref> provide an analytic expression for the smallest j~j such that A = A 0 + ~A 1 is unstable, where A 0 2 R nfin is stable. Using it, we can define the unidirectional perturbation-based cost function. <p> Unlike the previous example, the unidirectional perturbation-based cost cannot be computed analytically using the expression in <ref> [24] </ref> due to the size of this problem. Even one attempt to evaluate the cost function results in an out of memory error.
Reference: [25] <author> N. Hattori, T. Oshidari, K. Takatori, K. Iwanaga, K. Sugano, and S. Umebayashi, </author> <title> "A new five-speed nissan automatic transmission," </title> <note> in SAE Paper 900551, </note> <year> 1990. </year>
Reference-contexts: Such a shift is called a double transition shift and has been studied as a means of allowing even more compact transmission designs or for the implementation of five-speed automatic transmissions <ref> [25, 28] </ref>. In further studies, this model can be used to design controls for a double transition shift.
Reference: [26] <author> K. Hebbale, </author> <title> "Mathematical modeling of the x2f powertrain," </title> <type> Technical Report PW-210, </type> <institution> General Motors Research, </institution> <year> 1990. </year>
Reference-contexts: For this study, it is a sufficiently accurate representation. Figure 3.3 shows a comparison in the frequency responses of the model and the physical actuator and shows good agreement in the 5 20Hz range <ref> [26] </ref>.
Reference: [27] <author> D. Heglund, Z. Zabinsky, M. Tuttle, D. Graesser, G. Kim, and C. Swanson, </author> <title> "Optimization in preliminary structural design," </title> <booktitle> in Proceedings of the 15th Annual IIE Aerospace & Defense Division Conference, </booktitle> <address> Seattle, Washington, </address> <month> February </month> <year> 1992. </year> <month> 111 </month>
Reference-contexts: This interest has spawned many efforts towards developing global optimization techniques. In science and engineering, such problems arise in: structural design <ref> [27] </ref>, chemical process scheduling [57], circuit design [58], and protein folding [13] among others. Even the financial arena is interested in optimization for problems such as determining optimal trading policies.
Reference: [28] <author> Y. Hojo, K. Iwatsuki, H. Oba, and K. Ishikawa, </author> <title> "Toyota five-speed automatic trans-mission with application of modern control theory," </title> <note> in SAE Paper 920610, </note> <year> 1992. </year>
Reference-contexts: Such a shift is called a double transition shift and has been studied as a means of allowing even more compact transmission designs or for the implementation of five-speed automatic transmissions <ref> [25, 28] </ref>. In further studies, this model can be used to design controls for a double transition shift.
Reference: [29] <author> L. Khachiyan, </author> <title> "A polynomial algorithm in linear programming," </title> <journal> Soviet Mathematics Doklady, </journal> <volume> vol. 20, </volume> <pages> pp. 191-194, </pages> <year> 1979. </year>
Reference-contexts: The simplex is not guaranteed to do well and examples can be constructed where the worst case computational effort is exponential in the problem size. In 1979, Khachiyan <ref> [29] </ref> developed the ellipsoidal algorithm which is known to solve linear programming problems in polynomial time. However, the simplex 32 algorithm has, through the use of computational trials, demonstrated clearly that it is more efficient even when the problem size is in the tens of thousands.
Reference: [30] <author> P. Khargonekar and A. Tikku, </author> <title> "Randomized algorithms for robust control analysis and synthesis have polynomial complexity," </title> <booktitle> in Proceedings of the 35th IEEE International Conference on Decision and Control, </booktitle> <pages> pp. 3470-3475, </pages> <address> Kobe, Japan, </address> <year> 1996. </year>
Reference-contexts: There are some results in the literature <ref> [5, 30, 48, 61] </ref> which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. There are several issues that require better understanding. One is whether certain optimization algorithms are better suited for robust stability than others. <p> The focus of this work is on randomized algorithms as opposed to deterministic algorithms for optimization. The rationale for this focus is that randomized algorithms have been shown to have some desirable properties <ref> [2, 30] </ref> over deterministic algorithms that will be useful to us. * Heuristic vs. Analytic: Most of the algorithms given here are heuristic. The use of heuristic, randomized algorithms may be somewhat unsettling due to the lack of theoretical guarantees of computational complexity or performance. <p> As such, they are very flexible and simpler to implement. The trade-offs for this can be a loss of efficiency or a lack of guarantees that a deterministic algorithm can provide. Another reason for our interest in randomized algorithms comes from the following result <ref> [30] </ref>. Theorem 1 Consider a minimization problem with input parameter space X R n and measurable cost function J : X ! R. <p> The price that is paid for this robustness is poor efficiency. Many more function evaluations are likely necessary to arrive at a solution of the same quality as one that is found by a more directed technique. Two random search methods used in <ref> [30] </ref> and a third method which was proposed in [64] are grouped in this section. The first algorithm is the crude random search and simply samples from X a designated number of times and records the sample that provides the lowest cost. <p> However, there are no such widely accepted benchmark problems, at least at this time. There are some results in the literature <ref> [5, 30, 48, 61] </ref>, which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. Genetic algorithms for robust stability analysis have been investigated in 60 [36, 68]. <p> There are some results in the literature [5, 30, 48, 61], which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. Genetic algorithms for robust stability analysis have been investigated in 60 [36, 68]. In <ref> [30] </ref>, it was shown that even simple random search has potentially attractive com-putational complexity properties. <p> Since robust control problems often lead to nondifferentiable optimization problems, direct methods will have broader applicability. The following methods, which are described in detail in Chapter 2 are investigated here: 1. Multi-start of Rosenbrock's method [8] 2. Crude and adaptive random search <ref> [30] </ref> 3. Adaptive partitioned random search [60] 61 4. Controlled random search [2] and shu*ed complex evolution [19] It is very difficult to establish theoretical properties of all but the simplest of these algorithms. <p> The first three examples take a fairly general problem set up putting the nominal system M = (A; B; C) in feedback with an uncertainty block, of real uncertainties. For the first problem, several of the algorithms are applied to a 15th degree polynomial example from <ref> [30] </ref> where the real coefficients vary over a hyper-rectangle. By Kharitonov's Theorem, a well defined computation exists [24] for getting the solution against which the results of the randomized algorithms can be compared. <p> The third problem is of the same type as the second but much larger. It is a 55 state, 20 uncertain real parameters multivariable robust stability analysis problem which was investigated in <ref> [30] </ref>. The final problem is a very particular type of the real robust stability analysis problem which comes from [68]. Due to the assumptions that have been placed on the problem, it can be approached by both continuous or combinatorial optimization techniques. <p> The APRS algorithm contains both C and MATLAB code and so flops could not be counted. This also renders execution time potentially unsuitable for comparison purposes. For interest, however, execution times are mentioned along with the number of function evaluations. 5.1.4 Kharitonov Example This example comes from <ref> [30] </ref>. It is a 15th degree stable polynomial, p 0 = s 15 + P 14 with real coefficients. <p> Although the increase in the number of flops for the unidirectional perturbation-based cost function is about two orders of magnitude, the increase in time is only about one order higher. 76 5.1.6 Medium-sized Real Example The LTI system, M , obtained from <ref> [30] </ref> is stable and contains 55 states and 20 inputs and outputs, i.e., the number of real parameters is 20. Unlike the previous example, the unidirectional perturbation-based cost cannot be computed analytically using the expression in [24] due to the size of this problem. <p> The versatility of the direct, randomized algorithms allows them to approach a wide range of control problems. For example, they can be used for tuning parameter gains. Another potential application is reduced order controller design. The latter problem is presented briefly in <ref> [30] </ref> where a reduced order controller is found using a randomized algorithm and that is significantly better than one found by a Hankel model reduction on the full order controller. Some preliminary work has also been done on doing multiobjective optimal controller design with promising results.
Reference: [31] <author> Y. Kim, J. Yang, and J. Lee, </author> <title> "A study on the transient characteristics of automatic transmission with detailed dynamic modeling," </title> <note> in SAE Paper 941014, </note> <year> 1994. </year>
Reference-contexts: For this investigation we present a dynamic model for a clutch-to-clutch shifting automatic transmission. The modeling process starts off by establishing the static and dynamic equations that describe the subsystems of the power-train. Our models are obtained by combining results from the published literature [15], 35 [16], <ref> [31] </ref>. For most of the components, the models are obtained through derivation from first principles while for others, fairly well established empirical models are used. After this, the subsystems are all connected to form the complete powertrain model. <p> onboard microprocessor. 3.3 Physical Model A low order model is desirable to simplify the controller synthesis process but at the same time it must be complex enough that it captures the relevant dynamics of the powertrain. 37 Past work done on modeling powertrains can be found in [15], [16], and <ref> [31] </ref>. The powertrain model used in this work is slightly simpler than those found in the cited references. The frequency range of interest is from about 0-20 Hz and high frequency effects such as transmission noise and gear backlash are not modeled.
Reference: [32] <author> A. Kotwicki, </author> <title> "Dynamic models for torque converter equipped vehicles," </title> <note> in SAE Paper 820393, </note> <year> 1982. </year>
Reference-contexts: It provides damping to the vehicle from the engine and provides torque multiplication which prevents stalling and also aids vehicle acceleration. The operation of the torque converter model is modeled by the Kotwicki model <ref> [32] </ref>. It is a static, empirically derived quadratic fit relating the engine 38 (or pump) and turbine speeds to the pump and turbine torques.
Reference: [33] <author> J. Lagarias, J. Reeds, M. Wright, and P. Wright, </author> <title> "Convergence properties of the nelder-mead simplex algorithm in low dimensions," </title> <type> Technical Report 96-4-07, </type> <institution> Lucent Technologies, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: In [2], it is stated that the CRS algorithm is totally heuristic and lacks theoretical convergence properties. According to Subrahmanyam in [59], convergence theorems for the Nelder-Mead algorithm alone are practically nonexistent even though the algorithm has was presented in 1965. Some very recent work in <ref> [33] </ref> has proven the convergence of the algorithm for strictly convex functions in one dimension and shown the difficulty of finding proofs in higher dimensions. Given this, it is unlikely that any theoretical convergence results for the SCE algorithm exist.
Reference: [34] <author> E. Lawler, J. Lenstra, A. Kan, and D.B.Shmoys, </author> <title> The Traveling Salesman: A Guided Tour of Combinatorial Optimization, </title> <publisher> John Wiley & Sons, </publisher> <year> 1985. </year>
Reference-contexts: If upper and lower bounds are available, then branch and bound can be a very effective deterministic algorithm. Along with branch and bound there are many other methods which are exact; that is, they guarantee finding the optimal solution <ref> [34, 43] </ref>. However, the computational complexity of these algorithms is usually exponential. 30 2.4.1 Discrete Adaptive Random Search (DARS) The DARS is a simple modification of the ARS II algorithm. In effect, it is a local search technique which considers a larger neighborhood than a simple local search.
Reference: [35] <author> F. Lewis, </author> <title> Optimal Control, </title> <publisher> Wiley, </publisher> <year> 1986. </year>
Reference-contexts: The goal of determining properly coordinated clutch control inputs can be posed as an open-loop optimal control problem. Optimal control of nonlinear systems has traditionally been handled by Pontryagin's 4 Maximum Principle or the Hamilton-Jacobi-Bellman equations <ref> [12, 35] </ref>. However, these methods apply only to very simple problems and the model of the powertrain is complex enough that it needs to be dealt with using computational open-loop optimal control techniques.
Reference: [36] <author> C. Marrison and R. Stengel, </author> <title> "The use of random search and genetic algorithms to optimize stochastic robustness functions," </title> <booktitle> in Proceedings of American Control Conference, </booktitle> <pages> pp. 1484-1489, </pages> <address> Baltimore, Maryland, </address> <year> 1994. </year>
Reference-contexts: There are some results in the literature [5, 30, 48, 61], which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. Genetic algorithms for robust stability analysis have been investigated in 60 <ref> [36, 68] </ref>. In [30], it was shown that even simple random search has potentially attractive com-putational complexity properties.
Reference: [37] <author> B. A. J. Moore, </author> <title> Optimal Control: Linear Quadratic Methods, </title> <publisher> Prentice Hall, </publisher> <year> 1990. </year>
Reference-contexts: In control theory, a problem is frequently posed in terms of an optimization problem where the design or analysis specifications are met when an optimizing solution is found. Classic examples of optimal controller synthesis techniques are LQR <ref> [37] </ref>, LQG [37], and H 1 [23]. If y = Hu, where H is a transfer function, then minimizing the H 2 norm of H minimizes the two norm y when u is an impulse. <p> In control theory, a problem is frequently posed in terms of an optimization problem where the design or analysis specifications are met when an optimizing solution is found. Classic examples of optimal controller synthesis techniques are LQR <ref> [37] </ref>, LQG [37], and H 1 [23]. If y = Hu, where H is a transfer function, then minimizing the H 2 norm of H minimizes the two norm y when u is an impulse.
Reference: [38] <author> J. Moskwa and J. Hedrick, </author> <title> "Modeling and validation of automotive engines for control algorithm development," </title> <journal> Transactions of the ASME, </journal> <volume> vol. 114, </volume> <pages> pp. 278-285, </pages> <year> 1992. </year>
Reference-contexts: However, several simplified models that capture the engine's dynamics exist. Both [18] and [10] represent early dynamic engine models for control purposes. Even now, engine models are based on the model found in [18] such as that in <ref> [38] </ref>. The model used here is further simplified and incorporates a steady state map T e (! e ; ff) with throttle angle, ff, and engine speed, ! e , as inputs and engine torque, T e , as the output.
Reference: [39] <author> J. A. Nelder and R. Mead, </author> <title> "A simplex method for function minimization," </title> <journal> Computer Journal, </journal> <volume> vol. 7, </volume> <pages> pp. 308-313, </pages> <year> 1965. </year>
Reference-contexts: The APRS part of the algorithm separates the group of points into several partitions and for a certain period of time the partitions are treated independently (until the points are shu*ed). The CRS part of the algorithm uses the Nelder-Mead <ref> [39] </ref> simplex algorithm to replace the worst points in each of the partitions. A simplex is a set of points in the input space which don't all lie in a subspace of lower dimension than the input space.
Reference: [40] <author> A. Nemirovskii, </author> <title> "Several NP-hard problems arising in robust stability analysis," </title> <journal> Math. of Control, Signals, and Systems, </journal> <volume> vol. 6, </volume> <pages> pp. 99-105, </pages> <year> 1993. </year>
Reference-contexts: Several results have shown that except for a very specific class problems for which analytic results such as Kharitonov's Theorem exist, such problems are NP-hard <ref> [11, 40] </ref>. Therefore the difficulty in the analysis are inherent in the problem and not due to a lack of cleverness on the part of control researchers. Due to these results on computational complexity, an alternative approach to the robust stability problem seems useful. <p> This appears to be even more so for the case of real parameter uncertainty. Results on computational complexity <ref> [11, 40] </ref> of robust stability analysis provide strong support for such conclusions. The fundamental underlying reason appears to be the fact that these problems typically involve nonconvex optimization having many local minima. It is only in very special cases that one has neat analytical solutions.
Reference: [41] <author> M. P. Newlin, </author> <title> Model Validation, Control, and Computation, </title> <type> PhD thesis, </type> <institution> California Institute of Technology, </institution> <year> 1996. </year>
Reference-contexts: Since M and are real and the ffi are not repeated, it can be shown <ref> [41] </ref> that the solution of (5.11) is on a vertex of B. The solution of this problem is known to be NP hard [11] and so one usually resorts to computing upper and lower bounds on with algorithms that have polynomial complexity.
Reference: [42] <author> M. P. Newlin and P. M. Young, </author> <title> "Mixed problems and branch and bound techniques," </title> <booktitle> in Proceedings of the 31st IEEE International Conference on Decision and Control, </booktitle> <pages> pp. 3175-3180, </pages> <address> Tucson, Arizona, </address> <year> 1992. </year>
Reference-contexts: A high quality lower bound on the solution would provide confidence in the quality of the upper bound solutions (and vice versa). In contrast, a branch and bound technique has been investigated in <ref> [42] </ref> using upper and lower bounds to compute . Then again, the branch and bound algorithm would have to be applied at each frequency. Our formulation is advantageous since it does not require a frequency grid. <p> As stated in Chapter 5, one drawback of the optimization methods in this study is that 102 only upper bounds on the solution are obtained. Deterministic branch and bound techniques have been applied to the real robust stability analysis problem in <ref> [42] </ref> and also to a related problem of finding the minimum stability degree in [4]. While branch and bound provides both upper and lower bounds on the size of the smallest destabilizing perturbation, they also require a sweep over a one dimensional parameter such as frequency. <p> While branch and bound provides both upper and lower bounds on the size of the smallest destabilizing perturbation, they also require a sweep over a one dimensional parameter such as frequency. The branch and bound work in <ref> [42] </ref> ignores the frequency sweep and concentrates on finding the upper and lower bounds of at a particular frequency, usually chosen to be close to the dominant modes of the nominal system. A special class of real problems was presented in [68].
Reference: [43] <author> C. D. Papadimitrou and K. Steiglitz, </author> <title> Combinatorial Optimization: Algorithms and Complexity, </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: If upper and lower bounds are available, then branch and bound can be a very effective deterministic algorithm. Along with branch and bound there are many other methods which are exact; that is, they guarantee finding the optimal solution <ref> [34, 43] </ref>. However, the computational complexity of these algorithms is usually exponential. 30 2.4.1 Discrete Adaptive Random Search (DARS) The DARS is a simple modification of the ARS II algorithm. In effect, it is a local search technique which considers a larger neighborhood than a simple local search.
Reference: [44] <author> J. M. Parkinson and D. Hutchinson, </author> <title> "A consideration of nongradient algorithms for the unconstrained optimization of function of high dimensionality," in Numerical Methods for Nonlinear Optimization, </title> <editor> F. A. Lootsma, </editor> <booktitle> editor, </booktitle> <pages> pp. 99-113, </pages> <publisher> Academic Press, </publisher> <year> 1972. </year> <month> 112 </month>
Reference-contexts: Tests for the efficiency of the algorithms have mainly been done through the use of numerical experiments. In [2], the proposed CRS algorithm is compared with other CRS algorithms on a set of benchmark problems using numerical experiments. In <ref> [44] </ref>, they are used to compare the Nelder-Mead algorithm with other direct methods and in [45] they are used to propose modifications to the algorithm to improve its efficiency. Interestingly enough, several studies have provided different conclusions.
Reference: [45] <author> J. M. Parkinson and D. Hutchinson, </author> <title> "An investigation into the efficiency of variants of the simplex method," in Numerical Methods for Nonlinear Optimization, </title> <editor> F. A. Lootsma, </editor> <booktitle> editor, </booktitle> <pages> pp. 115-136, </pages> <publisher> Academic Press, </publisher> <year> 1972. </year>
Reference-contexts: In [2], the proposed CRS algorithm is compared with other CRS algorithms on a set of benchmark problems using numerical experiments. In [44], they are used to compare the Nelder-Mead algorithm with other direct methods and in <ref> [45] </ref> they are used to propose modifications to the algorithm to improve its efficiency. Interestingly enough, several studies have provided different conclusions.
Reference: [46] <author> J. Pinter, </author> <title> Global Optimization in Action, </title> <publisher> Kluwer, </publisher> <year> 1996. </year>
Reference-contexts: Even the financial arena is interested in optimization for problems such as determining optimal trading policies. A collection of reported applications of global optimization can be found in <ref> [46] </ref> and a good summary of global optimization techniques can be found in [50, 62]. In this chapter, the global optimization problem is formulated and the challenges involved are listed. Possible challenges include nondifferentiability of the cost function, number of local minima, and problem size.
Reference: [47] <author> M. J. D. Powell, </author> <title> "An efficient method for finding the minimum of a function of several variables without calculating derivatives," </title> <journal> Computer Journal, </journal> <volume> vol. 7, </volume> <pages> pp. 155-162, </pages> <year> 1964. </year>
Reference-contexts: Interestingly enough, several studies have provided different conclusions. Some claim that the simplex method is inefficient and suffer when the dimension of the input space is high while others claim that it is competitive with other methods such as that of Powell <ref> [47] </ref> especially in higher dimensions. Schwefel in [56] has performed a comprehensive numerical study involving many algorithms on a large number of different problems. His results tend to show that the simplex algorithm is very inefficient, especially as it comes close to a solution.
Reference: [48] <author> L. Ray and R. Stengel, </author> <title> "Stochastic robustness of linear time-invariant control systems," </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> vol. 36, </volume> <pages> pp. 82-87, </pages> <year> 1991. </year>
Reference-contexts: There are some results in the literature <ref> [5, 30, 48, 61] </ref> which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. There are several issues that require better understanding. One is whether certain optimization algorithms are better suited for robust stability than others. <p> However, there are no such widely accepted benchmark problems, at least at this time. There are some results in the literature <ref> [5, 30, 48, 61] </ref>, which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. Genetic algorithms for robust stability analysis have been investigated in 60 [36, 68].
Reference: [49] <author> C. R. Reeves, </author> <title> Modern heuristic techniques for combinatorial problems, </title> <publisher> Halsted Press, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: While many algorithms exist for combinatorial optimization problems, only one simple random search, the DARS, is presented here. Genetic algorithms, simulated annealing, and TABU search are some well known examples of heuristic algorithms that have been used for combinatorial optimization <ref> [49] </ref>. If upper and lower bounds are available, then branch and bound can be a very effective deterministic algorithm. Along with branch and bound there are many other methods which are exact; that is, they guarantee finding the optimal solution [34, 43]. <p> complex algorithms may incorporate some memory to prevent computational effort being wasted on already evaluated points and also to provide information about whether the random search should be diversified or intensified. 2.5 Theoretical Results and Heuristics The use of heuristics to solve global optimization problems appears to be gaining approval <ref> [49] </ref>. <p> However, these results are meaningless since it turns out that multistart local searches [21] and random searches [14] have better asymptotic convergence to the global minimum. In fact, simulated annealing would typically search more points than there are in the entire search space <ref> [49] </ref>. With a faster cooling schedule, simulated annealing is more practical but then the asymptotic results do not apply. Another case for heuristics is that their ease of implementation allows more complicated problems to be considered. <p> There is a large body of literature available for solving combinatorial optimization problems that can be tapped for future research. Several examples of heuristic, randomized and deterministic approaches such as genetic algorithms, simulated annealing, and tabu search are presented in <ref> [49] </ref>. Though the first two have already been examined in [68], perhaps a more thorough application of those algorithms would yield better results. The tabu search tries to use more past data to improve future searches, which the DARS presently does not do, and may provide better results.
Reference: [50] <author> H. Reiner, </author> <title> Global Optimization: Deterministic Approaches, </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1996. </year>
Reference-contexts: Even the financial arena is interested in optimization for problems such as determining optimal trading policies. A collection of reported applications of global optimization can be found in [46] and a good summary of global optimization techniques can be found in <ref> [50, 62] </ref>. In this chapter, the global optimization problem is formulated and the challenges involved are listed. Possible challenges include nondifferentiability of the cost function, number of local minima, and problem size. These obstacles can render the task of finding the best solution very difficult. <p> Deterministic Methods Along with being direct methods, all the algorithms except the line search are randomized algorithms. However, a large number of deterministic global optimization algorithms exist <ref> [50] </ref>. The drawback with deterministic approaches, in general, is that they are more complicated to use in a general situation. Although a branch and bound algorithm provides guarantees on performance and a way to evaluate the quality of a solution, it also requires global information about the problem. <p> An extensive presentation of deterministic global optimization algorithms can be found in <ref> [50] </ref>. In contrast, a randomized algorithm is usually designed to treat the cost function as a blackbox and assume little about its structure. As such, they are very flexible and simpler to implement.
Reference: [51] <author> H. E. Romeijn and R. L. Smith, </author> <title> "Simulated annealing for global optimization," </title> <journal> Journal of Global Optimization, </journal> <volume> vol. 5, </volume> , <year> 1994. </year>
Reference-contexts: If the new point is better than the initial one, then it replaces it. Otherwise, another direction and step length are generated randomly to find a new point. This process is continued until a global minimum is found. Work in [66] and <ref> [51] </ref> present the "Hit and Run" and "Hide and Seek" random line searches. The latter is a simulated annealing technique.
Reference: [52] <author> O. Rosen and R. Luus, </author> <title> "Global optimization approach to nonlinear optimal control," </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> vol. 73, no. 3, </volume> <pages> pp. 547-562, </pages> <year> 1992. </year>
Reference-contexts: A common strategy is to convert the optimal control problem into a nonlinear programming problem and then use a nonlinear optimization algorithm which is local in nature. Work in <ref> [9, 52, 63] </ref> show examples of this approach. However, except for [52], which is a multistart algorithm, these techniques are focused on local optimization and do not address the possibility of finding a local minimum instead of the global one. <p> A common strategy is to convert the optimal control problem into a nonlinear programming problem and then use a nonlinear optimization algorithm which is local in nature. Work in [9, 52, 63] show examples of this approach. However, except for <ref> [52] </ref>, which is a multistart algorithm, these techniques are focused on local optimization and do not address the possibility of finding a local minimum instead of the global one. <p> Present approaches to computational optimal control involve converting the optimal control problem into a nonlinear programming problem and using nonlinear optimization solution techniques. Several examples are the direct transcription approach, summarized in [9], and the control and state trajectory approximation approaches in <ref> [52] </ref> and [63]. These approaches are more or less deterministic except possibly in the way the initial conditions are selected. In the direct transcription approach in [9], the differential equations are dis-cretized and used as constraints in the nonlinear programming problem. <p> All of these methods have usually relied on gradient or even Hessian information of the cost function. Also, except in <ref> [52] </ref>, only local minimization is considered. Having said this, we propose a randomized algorithms approach to solve the nonlinear optimization problem. To our knowledge, such an approach has not been studied extensively for optimal control. <p> For example, in the transmission problem, each ramp could be split into two ramps when a relatively good, coarse control input is found. Then the control input can be fine tuned. This approach is presented in <ref> [52] </ref> and appears to have promise. Also important is the way the control inputs are parameterized. The knowledge that a typical clutch control input is ramp-like and monotonically increasing or decreasing is important.
Reference: [53] <author> J. Sacks, S. Schiller, and W. Welch, </author> <title> "Designs for computer experiments," </title> <journal> Technomet-rics, </journal> <volume> vol. 31, </volume> <pages> pp. 41-47, </pages> <year> 1989. </year>
Reference-contexts: We have applied this approach to this problem with limited success [64]. The two different surrogate model forms that were tried were linear regressors with quadratic terms and the kriging approach proposed by <ref> [53] </ref>. The difficulty with this approach is that in our problem the dimension of the input parameter space is quite high at 16 and so constructing an accurate surrogate model is difficult. <p> Also, if the surrogate model parameters (as opposed to the input parameters) are solved by nonlinear regression techniques, then apart from the optimal control problem at hand, a non-trivial optimization problem must be solved to obtain those parameters. The kriging approach in <ref> [53] </ref> uses maximum likelihood estimation (MLE) to solve for the surrogate model parameters and in this problem took several hours to compute. However, more feasible surrogate modeling techniques may exist and remains a future line of research for open-loop optimal control problems. <p> If a loss of accuracy is permissible and the number of parameters is not too high, then surrogate modeling <ref> [53] </ref> may be feasible. In this approach, a number of simulations are run and then the input-output data that is collected is used to compute an interpolator, or surrogate model, which then predicts the results of ensuing simulations and presumably uses comparatively little computational effort.
Reference: [54] <author> C. Schumacher and P. Khargonekar, </author> <title> "A comparison of missle autopilot designs using H 1 control with gain scheduling and nonlinear dynamic inversion," </title> <booktitle> in Proceedings of the American Control Conference, </booktitle> <pages> pp. 2759-2763, </pages> <address> Albuquerque, New Mexico, </address> <year> 1997. </year>
Reference-contexts: By Kharitonov's Theorem, a well defined computation exists [24] for getting the solution against which the results of the randomized algorithms can be compared. The second example comes from <ref> [54] </ref> and represents a linearized model of the closed-loop system of a bank-to-turn, air-to-air missile with a linear H 1 controller. The size of the problem is small enough that two different formulations of the problem can be investigated. <p> The apparent simplicity of this problem may not be surprising since analytic means exist to solve this problem, but the approach taken 68 is quite different. The next problems are more complex. 5.1.5 Real Missile Controller Example The LTI system, M , comes from <ref> [54] </ref> and represents the closed-loop linearized model of a bank-to-turn, air-to-air missile and a H 1 controller. It is stable and has 7 states and 13 inputs and outputs.
Reference: [55] <author> L. Schwab, </author> <title> "Development of a shift quality metric for an automatic transmission," </title> <note> in SAE Paper 941009, </note> <year> 1994. </year>
Reference-contexts: The cost function has the parameters of the clutch controls as its inputs. 4.1.1 Formulation of Cost Function Shift quality is not easy to define or measure as it has a highly subjective component. One paper <ref> [55] </ref> that deals with a metric for shift quality bases its metric on the subjective evaluation of a shift given by a number of passengers when several conditions are varied.
Reference: [56] <author> H. Schwefel, </author> <title> Evolution and Optimum Seeking, </title> <publisher> Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Interestingly enough, several studies have provided different conclusions. Some claim that the simplex method is inefficient and suffer when the dimension of the input space is high while others claim that it is competitive with other methods such as that of Powell [47] especially in higher dimensions. Schwefel in <ref> [56] </ref> has performed a comprehensive numerical study involving many algorithms on a large number of different problems. His results tend to show that the simplex algorithm is very inefficient, especially as it comes close to a solution. <p> As work on global optimization techniques continue to develop, the need to compare their effectiveness, generality, and efficiency is becoming greater in the global optimization community. There are several collections of problems <ref> [22, 56, 58] </ref> that have been compiled 33 which feature different difficulties such as nondifferentiability or a large number of local minima. In [1], an attempt is also made at classifying these problems into classifications of difficulty.
Reference: [57] <author> W. Song, Z. Zabinsky, and R. Storch, </author> <title> "An algorithm for scheduling a chemical processing tank line," </title> <journal> Production Planning and Control, </journal> <volume> vol. 4, no. 4, </volume> <pages> pp. 323-332, </pages> <year> 1993. </year>
Reference-contexts: This interest has spawned many efforts towards developing global optimization techniques. In science and engineering, such problems arise in: structural design [27], chemical process scheduling <ref> [57] </ref>, circuit design [58], and protein folding [13] among others. Even the financial arena is interested in optimization for problems such as determining optimal trading policies.
Reference: [58] <author> B. E. Stuckman, </author> <title> "A global search method for optimizing nonlinear systems," </title> <journal> IEEE Transactions on Systems, Man, and Cybernetics, </journal> <volume> vol. 18, no. 6, </volume> <pages> pp. 965-977, </pages> <month> Novem-ber/December </month> <year> 1988. </year>
Reference-contexts: This interest has spawned many efforts towards developing global optimization techniques. In science and engineering, such problems arise in: structural design [27], chemical process scheduling [57], circuit design <ref> [58] </ref>, and protein folding [13] among others. Even the financial arena is interested in optimization for problems such as determining optimal trading policies. A collection of reported applications of global optimization can be found in [46] and a good summary of global optimization techniques can be found in [50, 62]. <p> As work on global optimization techniques continue to develop, the need to compare their effectiveness, generality, and efficiency is becoming greater in the global optimization community. There are several collections of problems <ref> [22, 56, 58] </ref> that have been compiled 33 which feature different difficulties such as nondifferentiability or a large number of local minima. In [1], an attempt is also made at classifying these problems into classifications of difficulty.
Reference: [59] <author> M. B. Subrahmanyam, </author> <title> "An extension of the simplex method to constrained nonlinear optimization," </title> <journal> Journal of Optimization Theory and Applications, </journal> <volume> vol. 62, no. 2, </volume> <pages> pp. 311-319, </pages> <year> 1989. </year>
Reference-contexts: On the other hand, ARS II is not even guaranteed to converge to a local optimum. In [2], it is stated that the CRS algorithm is totally heuristic and lacks theoretical convergence properties. According to Subrahmanyam in <ref> [59] </ref>, convergence theorems for the Nelder-Mead algorithm alone are practically nonexistent even though the algorithm has was presented in 1965. Some very recent work in [33] has proven the convergence of the algorithm for strictly convex functions in one dimension and shown the difficulty of finding proofs in higher dimensions.
Reference: [60] <author> Z. B. Tang, </author> <title> "Adaptive partitioned random search to global optimization," </title> <journal> IEEE Transactions on Automatic Control, </journal> <volume> vol. 39, no. 11, </volume> <pages> pp. 2235-2244, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: The version of APRS presented here is from <ref> [60] </ref>. In this approach, the goal of finding the subregion with greatest expectation of containing the minimizer is abandoned and replaced with the goal of finding the partition that provides the greatest expected decrease from the current best estimate of the minimum. <p> Therefore, a partition that contains both very good and very bad points will still be seen as promising. Partitions with lower promising indexes are partitioned further while the remaining, inferior ones are lumped into one partition called the surrounding region. The algorithm of <ref> [60] </ref> for finding a global maximum in a rectangular input space is given below. * Adaptive Partitioned Random Search (APRS) Inputs: p 0 , p, p index , best p , ff, tolerance Initialize: Partition the input space into p 0 smaller regions. Let j = 1. <p> However, a typical optimization problem may have an input parameter space that is constrained to be non-rectangular. In this case, one simple remedy is to fit the feasible space into a rectangular one and assign a very high cost to any point that is not feasible. In <ref> [60] </ref>, the APRS algorithm is tested on several "benchmark" problems in global optimization such as the Goldstein-Price and Shekel functions. The APRS algorithm was compared with the crude random search on the example problems and was found to be orders of magnitude more efficient. <p> Since robust control problems often lead to nondifferentiable optimization problems, direct methods will have broader applicability. The following methods, which are described in detail in Chapter 2 are investigated here: 1. Multi-start of Rosenbrock's method [8] 2. Crude and adaptive random search [30] 3. Adaptive partitioned random search <ref> [60] </ref> 61 4. Controlled random search [2] and shu*ed complex evolution [19] It is very difficult to establish theoretical properties of all but the simplest of these algorithms. Therefore, the efficacy of the algorithms is evaluated on several robust stability analysis problems with real-valued uncertainties for this investigation.
Reference: [61] <author> R. Tempo, E. W. Bai, and F. Dabbene, </author> <title> "Probabilistic robustness analysis: explicit bounds for the minimum number of samples," </title> <booktitle> in Proceedings of the 35th IEEE International Conference on Decision and Control, </booktitle> <pages> pp. 3424-3428, </pages> <address> Kobe, Japan, </address> <year> 1996. </year>
Reference-contexts: There are some results in the literature <ref> [5, 30, 48, 61] </ref> which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. There are several issues that require better understanding. One is whether certain optimization algorithms are better suited for robust stability than others. <p> However, there are no such widely accepted benchmark problems, at least at this time. There are some results in the literature <ref> [5, 30, 48, 61] </ref>, which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. Genetic algorithms for robust stability analysis have been investigated in 60 [36, 68].
Reference: [62] <author> A. Torn, </author> <title> Global Optimization, </title> <publisher> Springer-Verlag, </publisher> <year> 1989. </year> <month> 113 </month>
Reference-contexts: Even the financial arena is interested in optimization for problems such as determining optimal trading policies. A collection of reported applications of global optimization can be found in [46] and a good summary of global optimization techniques can be found in <ref> [50, 62] </ref>. In this chapter, the global optimization problem is formulated and the challenges involved are listed. Possible challenges include nondifferentiability of the cost function, number of local minima, and problem size. These obstacles can render the task of finding the best solution very difficult.
Reference: [63] <author> J. Vlassenbroeck, </author> <title> "A chebyshev polynomial method for optimal control with state constraints," </title> <journal> Automatica, </journal> <volume> vol. 24, no. 4, </volume> <pages> pp. 499-505, </pages> <year> 1988. </year>
Reference-contexts: A common strategy is to convert the optimal control problem into a nonlinear programming problem and then use a nonlinear optimization algorithm which is local in nature. Work in <ref> [9, 52, 63] </ref> show examples of this approach. However, except for [52], which is a multistart algorithm, these techniques are focused on local optimization and do not address the possibility of finding a local minimum instead of the global one. <p> Present approaches to computational optimal control involve converting the optimal control problem into a nonlinear programming problem and using nonlinear optimization solution techniques. Several examples are the direct transcription approach, summarized in [9], and the control and state trajectory approximation approaches in [52] and <ref> [63] </ref>. These approaches are more or less deterministic except possibly in the way the initial conditions are selected. In the direct transcription approach in [9], the differential equations are dis-cretized and used as constraints in the nonlinear programming problem.
Reference: [64] <author> A. Yoon, P. Khargonekar, and K. Hebbale, </author> <title> "Design of computer experiments for open-loop control and robustness analysis of clutch-to-clutch shifts in automatic transmissions," </title> <booktitle> in Proceedings of the American Control Conference, </booktitle> <pages> pp. 3359-3364, </pages> <address> Albu-querque, New Mexico, </address> <year> 1997. </year>
Reference-contexts: Many more function evaluations are likely necessary to arrive at a solution of the same quality as one that is found by a more directed technique. Two random search methods used in [30] and a third method which was proposed in <ref> [64] </ref> are grouped in this section. The first algorithm is the crude random search and simply samples from X a designated number of times and records the sample that provides the lowest cost. <p> If sufficiently accurate surrogate models can be constructed, then they can be used in the optimization procedure in place of the simulation model. We have applied this approach to this problem with limited success <ref> [64] </ref>. The two different surrogate model forms that were tried were linear regressors with quadratic terms and the kriging approach proposed by [53].
Reference: [65] <author> P. M. Young, M. P. Newlin, and J. C. Doyle, </author> <title> "Let's get real," </title> <journal> ASME, Dynamic Systems and Control Division (Publication) DSC, </journal> <volume> vol. 43, </volume> <pages> pp. 5-12, </pages> <year> 1992. </year>
Reference-contexts: (Re ((A + BC))) (5.2) where (X) is the set of eigenvalues of X, then fl opt = inf (kk 1 : (M; ) is unstable) = inf (kk 1 : (M; ) 0): Solving this problem would typically be handled by the real structured singular value (real ) theory <ref> [17, 65] </ref>. However, real analysis and synthesis problems are very difficult and one usually resorts to computing upper and lower bounds on the quantities of interest such as fl opt .
Reference: [66] <author> Z. B. Zabinsky, R. L. Smith, J. F. McDonald, H. E. Romeijn, and D. E. Kaufman, </author> <title> "Improving hit-and-run for global optimization," </title> <journal> Journal of Global Optimization, </journal> <volume> vol. 3, </volume> <pages> pp. 171-192, </pages> <year> 1993. </year>
Reference-contexts: If the new point is better than the initial one, then it replaces it. Otherwise, another direction and step length are generated randomly to find a new point. This process is continued until a global minimum is found. Work in <ref> [66] </ref> and [51] present the "Hit and Run" and "Hide and Seek" random line searches. The latter is a simulated annealing technique.
Reference: [67] <author> W. Zangwill, </author> <title> "Minimizing a function without calculating derivatives," </title> <journal> Computer Journal, </journal> <volume> vol. 10, </volume> <pages> pp. 293-296, </pages> <year> 1967. </year>
Reference-contexts: The first algorithm is a multistart version of Rosenbrock's line search method. There are several line search methods such as Zangwill's <ref> [67] </ref> and Hooke and Jeeve's [8] but they are not examined here. Apart from selecting the initial conditions randomly, the algorithm is purely deterministic. Next, we consider perhaps the simplest class of randomized algorithms, containing the pure random search and variants there of.
Reference: [68] <author> X. Zhu, Y. Huang, and J. Doyle, </author> <title> "Genetic algorithms and simulated annealing for robustness analysis," </title> <booktitle> in Proceedings of the American Control Conference, </booktitle> <pages> pp. 3756-3760, </pages> <address> Albuquerque, New Mexico, </address> <year> 1997. </year> <month> 114 </month>
Reference-contexts: advantage of each of the cost functions, a "hybrid" algorithm which uses both of them is used and is observed to find the best solutions consistently. * We demonstrated that even a simple randomized algorithm can provide good results for a particular class of robust stability analysis problem presented in <ref> [68] </ref>. Results in [68] seemed to indicate that simulated annealing and genetic algorithms were inferior to those obtained by their (deterministic) branch and bound algorithm. <p> of the cost functions, a "hybrid" algorithm which uses both of them is used and is observed to find the best solutions consistently. * We demonstrated that even a simple randomized algorithm can provide good results for a particular class of robust stability analysis problem presented in <ref> [68] </ref>. Results in [68] seemed to indicate that simulated annealing and genetic algorithms were inferior to those obtained by their (deterministic) branch and bound algorithm. We applied a couple of the continuous optimization algorithms as well as a simple, randomized, combinatorial optimization algorithm that was developed in this study for this problem. <p> The latter algorithm obtained solutions that were often as good as or better than those found by the branch and bound algorithm used in <ref> [68] </ref> within reasonable amounts of time. <p> One is a general setting where the nominal system, M , is given by the matrix triplet (A; B; C). For this problem, two different formulations of the robust stability analysis problem as global optimization problems are investigated. The second setting is a very particular one presented in <ref> [68] </ref>. In this case, the nominal "system", M , is static and is an element of R nfin . The value of can be found by maximizing a certain function in the closed, n-dimensional unit hypercube. <p> This allows the optimization problem to be approached as a continuous or discrete optimization problem. This problem is presented in <ref> [68] </ref> as being one of the simplest possible setups of the real robust stability analysis problem. <p> There are some results in the literature [5, 30, 48, 61], which indicate that randomized algorithms may provide tractable approaches to the problems of robust stability analysis and performance. Genetic algorithms for robust stability analysis have been investigated in 60 <ref> [36, 68] </ref>. In [30], it was shown that even simple random search has potentially attractive com-putational complexity properties. <p> It is a 55 state, 20 uncertain real parameters multivariable robust stability analysis problem which was investigated in [30]. The final problem is a very particular type of the real robust stability analysis problem which comes from <ref> [68] </ref>. Due to the assumptions that have been placed on the problem, it can be approached by both continuous or combinatorial optimization techniques. Unlike the first problem, the solution to the other three problems cannot be found analytically. <p> This line of attack may lead to new algorithms for robust stability analysis that combine the best features of both types of algorithms. 89 5.2 "Special" Robust Stability Analysis Problem This section is focused on a very particular computation problem considered in <ref> [68] </ref>. In that paper, genetic algorithms and simulated annealing were the randomized algorithms proposed for the computation. The results seemed to indicate that they are not very effective for the type and size of problems considered there. <p> The computational performance of some of these algorithms was encouraging even for large (as measured by the state dimension or the number of uncertain parameters) size problems. These results have provided sufficient motivation for considering the problem in <ref> [68] </ref> and seeing if the randomized algorithms presented in Chapter 2 provided effective tools for the special computation problem posed therein. It turns out that the special computation problem can not be easily posed as a robust stability analysis problem. <p> The main aim of this section is to present some numerical results to assess the effectiveness of these randomized algorithms. For the numerical studies, exactly the same numerical examples as those considered in <ref> [68] </ref> are used. Along with each example, the solution found by their branch and bound algorithm is also provided. The availability of results generated by the branch and bound algorithms allows comparisons between a deterministic algorithm and several randomized algorithms. <p> For example, for 64 fi 64 size problems, our algorithms take, on average, a little over 4 hours on a 200 MHz Pentium Pro personal computer. As stated above, the problem that is considered in this paper is the simple computation problem presented in <ref> [68] </ref>. Consider the feedback system (M; ) containing a matrix M 2 90 R nfin and the perturbation shown in Figure 5.1. The perturbations are unknown, but are assumed to have a known structure. <p> The NP hardness of this problem along with the conservatism of the bounds motivates us to focus on efficient means of coming to approximate solutions and reducing the conservatism of the bounds. In <ref> [68] </ref>, a branch and bound method is used to tighten these upper and lower bounds. <p> this study and so for a particular M , the cost function is J () = r (M ) such that 2 B: (5.12) 5.2.1 Results The results of each of the randomized algorithms are presented here and compared to the results found by the branch and bound algorithm of <ref> [68] </ref>. A discussion of the performance of each of the algorithms is also provided in this section. 5.2.2 Problem Data and Method of Comparison The problem data comes from the authors of [68] and makes some comparison of results possible. <p> randomized algorithms are presented here and compared to the results found by the branch and bound algorithm of <ref> [68] </ref>. A discussion of the performance of each of the algorithms is also provided in this section. 5.2.2 Problem Data and Method of Comparison The problem data comes from the authors of [68] and makes some comparison of results possible. There is a total of 250 problems with 50 matrices each of sizes 4 fi 4; 8 fi 8; 16 fi 16; 32 fi 32; and 64 fi 64. <p> At the same time, the randomized algorithms are compared with the results of the 92 branch and bound algorithm. While the branch and bound algorithm in <ref> [68] </ref> was not readily available to us, the results of the algorithm for each problem were provided. <p> In the tables of results below, we let &lt;, =, and &gt; refer to the number of times out of 50 that the randomized algorithm finds an answer that is respectively less than, equal to, or greater than the lower bound found by the branch and bound algorithm of <ref> [68] </ref>. These numbers alone do not necessarily indicate superiority or inferiority of the randomized algorithms to the branch and bound algorithm since information of the computational effort in flops or computation time to arrive at the answers for the branch and bound algorithm is not available. <p> However, the results provided here are intended to demonstrate that randomized algorithms are a viable approach to the problem, in contrast to the conclusions of <ref> [68] </ref> concerning genetic algorithms and simulated annealing. All trials were run on a DELL 200 M Hz Pentium Pro machine. 5.2.3 Interior Versus Vertex Searches As mentioned previously, two types of randomized algorithm are studied: the interior point search and the vertex search. <p> However, the structure of the problem in this paper is such that the solution lies on a vertex of the search space. As such, a vertex search can be done to increase the speed at which good solutions can be found. In <ref> [68] </ref>, genetic algorithms and simulated annealing are used to perform a vertex search. <p> A comparison between interior and vertex random searches was done as well as a comparison between the vertex search and the results of the branch and bound algorithm of <ref> [68] </ref>. As expected, the vertex random search is more efficient than the interior point random search. <p> Several examples of heuristic, randomized and deterministic approaches such as genetic algorithms, simulated annealing, and tabu search are presented in [49]. Though the first two have already been examined in <ref> [68] </ref>, perhaps a more thorough application of those algorithms would yield better results. The tabu search tries to use more past data to improve future searches, which the DARS presently does not do, and may provide better results. <p> The branch and bound work in [42] ignores the frequency sweep and concentrates on finding the upper and lower bounds of at a particular frequency, usually chosen to be close to the dominant modes of the nominal system. A special class of real problems was presented in <ref> [68] </ref>. The nominal system, M , is static in this case and so a frequency sweep is not required. A set of 250 matrices were tested ranging from 4 fi 4 to 64 fi 64 in size. In [68], the performance of several randomized algorithms, namely genetic algorithms and simulated annealing, <p> A special class of real problems was presented in <ref> [68] </ref>. The nominal system, M , is static in this case and so a frequency sweep is not required. A set of 250 matrices were tested ranging from 4 fi 4 to 64 fi 64 in size. In [68], the performance of several randomized algorithms, namely genetic algorithms and simulated annealing, were compared with branch and bound. The results appeared to indicate that branch and bound is a superior algorithm to those two randomized algorithms.
References-found: 69

