URL: http://www.research.microsoft.com/~jckrumm/Papers/CVPR97/final.ps
Refering-URL: http://www.research.microsoft.com/~jckrumm/
Root-URL: http://www.research.microsoft.com
Email: jckrumm@sandia.gov  
Title: Object Detection with Vector Quantized Binary Features  
Author: John Krumm 
Address: Albuquerque, NM 87185  
Affiliation: Intelligent Systems Robotics Center Sandia National Laboratories  
Date: June 1997  
Note: IEEE Conference on Computer Vision and Pattern Recognition, San Juan, Puerto Rico,  
Abstract: This paper presents a new algorithm for detecting objects in images, one of the fundamental tasks of computer vision. The algorithm extends the representational efficiency of eigenimage methods to binary features, which are less sensitive to illumination changes than gray-level values normally used with eigenimages. Binary features (square subtemplates) are automatically chosen on each training image. Using features rather than whole templates makes the algorithm more robust to background clutter and partial occlusions. Instead of representing the features with real-valued eigenvector principle components, we use binary vector quantization to avoid floating point computations. The object is detected in the image using a simple geometric hash table and Hough transform. On a test of 1000 images, the algorithm works on 99.3%. We present a theoretical analysis of the algorithm in terms of the receiver operating characteristic, which consists of the probabilities of detection and false alarm. We verify this analysis with the results of our 1000-image test, and we use the analysis as a principled way to select some of the algorithms important operating parameters. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Gray, Robert M., </author> <title> Vector Quantization, </title> <journal> IEEE ASSP Magazine, </journal> <month> April </month> <year> 1984, </year> <pages> pp. 4-29. </pages>
Reference: [2] <author> Grimson, W. Eric L. and Huttenlocher, Daniel P. </author> <title> On the Sensitivity of the Hough Transform for Object Recognition, </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 12(3), </volume> <month> March </month> <year> 1990, </year> <pages> pp. 255-274. </pages>
Reference: [3] <author> Huttenlocher, Daniel .P., Lilien, Ryan H., and Olson, Clark F. </author> , <title> Object Recognition Using Subspace Methods, </title> <booktitle> Proceedings of the Fourth European Conference on Computer Vision, </booktitle> <year> 1996, </year> <pages> pp. 536-45. </pages>
Reference: [4] <author> Krumm, John C., </author> <title> Eigenfeatures for Planar Pose Measurement of Partially Occluded Objects, </title> <booktitle> Proceedings of the IEEE Computer Vision and Pattern Recognition Conference, </booktitle> <month> June </month> <year> 1996, </year> <pages> pp. 55-60. </pages>
Reference-contexts: If we set ( ) 2 0 2b Dq = . pixels, then b = 7 gives Dq = 116. o We set Dq = 1 0. , giving n m = 360 . 3. Encoding Binary Features The recent work in subspace methods for object recognition [[3], <ref> [4] </ref>, 6-[8], [10]], as well as the standard principle component analysis of pattern recognition, can be thought of as applications of data compression. A set of high-dimensional training vectors are projected into a lower-dimensional space to serve as efficient models of the items in the training set.
Reference: [5] <author> Lamdan, Yehezkel and Wolfson, Haim J., </author> <title> Geometric Hashing: A General and Efficient Model-Based Recognition Scheme, </title> <booktitle> Proceedings of the Second International Conference on Computer Vision, </booktitle> <month> December </month> <year> 1988, </year> <pages> pp. 238-249. </pages>
Reference: [6] <author> Murase, Hiroshi and Nayar, Shree K., </author> <title> Visual Learning and Recognition of 3D Objects from Appearance, </title> <journal> International Journal of Computer Vision, </journal> <volume> 14(1), </volume> <year> 1995, </year> <pages> pp. 5-24. </pages>
Reference: [7] <author> Murase, Hiroshi and Nayar, Shree K., </author> <title> Image Spotting of 3D Objects using Parametric Eigenspace Representation, </title> <booktitle> 9 th Scandinavian Conference on Image Analysis, </booktitle> <month> June </month> <year> 1995, </year> <pages> 325-332. </pages>
Reference: [8] <author> Ohba, Kohtaro and Ikeuchi, Katsushi, </author> <title> Recognition of the Multi Specularity Objects using the Eigen-Window, </title> <institution> Carnegie Mellon University School of Computer Science Technical Report CMU-CS-96-105, </institution> <month> February </month> <year> 1996. </year>
Reference: [9] <author> Shi, Jianbo and Tomasi, </author> <title> Carlo, Good Features to Track, </title> <booktitle> Proceedings of the IEEE Computer Vision and Pattern Recognition Conference, </booktitle> <month> June </month> <year> 1994, </year> <pages> pp. 593-600. </pages>
Reference: [10] <author> Turk, Matthew and Pentland, Alex, </author> <title> Eigenfaces for Recognition, </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1), </volume> <year> 1991, </year> <pages> 71-86. </pages>
Reference-contexts: Encoding Binary Features The recent work in subspace methods for object recognition [[3], [4], 6-[8], <ref> [10] </ref>], as well as the standard principle component analysis of pattern recognition, can be thought of as applications of data compression. A set of high-dimensional training vectors are projected into a lower-dimensional space to serve as efficient models of the items in the training set.

References-found: 10

