URL: http://www.cs.dartmouth.edu/~cliff/papers/RingScheduling.ps.Z
Refering-URL: http://www.cs.dartmouth.edu/~cliff/papers/
Root-URL: http://www.cs.dartmouth.edu
Email: email: perry@cs.dartmouth.edu  email: karger@theory.lcs.mit.edu  email: cliff@cs.dartmouth.edu  email: wein@mem.poly.edu  
Title: Distributed Job Scheduling in Rings  
Author: Perry Fizzano David Karger Clifford Stein Joel Wein 
Note: Research partially supported by NSF grant CCR-9308701, a Walter Burke Research Initiation Award and a Dartmouth College Research Initiation Award.  yResearch supported by a Hertz Foundation Graduate Fellowship and by NSF Young Investigator Award CCR-9357849, with matching funds from IBM, Schlumberger Foundation, Shell Foundation and Xerox Corporation.  zResearch partially supported by NSF grant CCR-9308701, a Walter Burke Research Initiation Award and a Dartmouth College Research Initiation Award.  xResearch partially supported by NSF grant CCR-9211494 and a grant from the New York State Science and Technology Foundation, Center for Advanced Technology in Telecommunications. Part of this work was done while the author was visiting DIMACS.  
Affiliation: Dartmouth College Department of Computer Science  MIT Laboratory for Computer Science  Dartmouth College Department of Computer Science  Polytechnic University Department of Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Ravindra K. Ahuja, Thomas L. Magnanti, and James B. Orlin. </author> <title> Network Flows. </title> <publisher> Prentice Hall, </publisher> <year> 1993. </year>
Reference-contexts: A well-known method for solving maximum cardinality bipartite matching uses maximum flow. Connect a source, s, to each vertex in V and connect each vertex in W to a sink, t. The edges between V and W are as described above. Finally, give every edge unit capacity. (see <ref> [1] </ref> for details). This leads to an algorithm that is very simple to understand and code but unfortunately it could require nmT space which is far too large for the large instances in Table 6. We refer to this procedure as First-opt.
Reference: [2] <author> W. Aiello, B. Awerbuch, B. Maggs, and S. Rao. </author> <title> Approximate load balancing on dynamic and asynchronous networks. </title> <booktitle> In Proceedings of the 25th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 632-641, </pages> <year> 1993. </year>
Reference-contexts: If algorithm A always yields a schedule of length no more than L (I) + O (1) we call A a -approximation algorithm. Note that this problem is related to, but different from, load balancing, which is another common problem 5 in parallel and distributed systems (see <ref> [2, 9] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [3] <author> F. Allen, M. Burke, P. Charles, R. Cytron, and J. Ferrante. </author> <title> An overview of the ptran analysis system for multiprocessing. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 5 </volume> <pages> 617-640, </pages> <year> 1988. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop paral-lelization <ref> [3, 12, 13, 19] </ref> or in the use of a parallel system to process batches of transactions or independent sequential programs. We restrict our attention to the ring, which is an important network in both theory and practice.
Reference: [4] <author> H. Attiya, M. Snir, and M. Warmuth. </author> <title> Computing on an anonymous ring. </title> <journal> Journal of the ACM, </journal> <volume> 35(4) </volume> <pages> 845-875, </pages> <year> 1988. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [4, 6, 10, 16, 17, 21, 22] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [14, 20, 23, 24].
Reference: [5] <author> B. Awerbuch, S. Kutten, and D. Peleg. </author> <title> Competetive distributed job scheduling. </title> <booktitle> In Proceedings of the 24th Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 571-580, </pages> <year> 1992. </year>
Reference-contexts: In addition, much of the scheduling literature assumes global control of task allocation. Our algorithm has low control overhead, accounts for communication constraints and does not require global control. We know of only one paper which fully addresses the latter two issues: that of Awerbuch, Kutten and Peleg <ref> [5] </ref>, who study the problem of distributed dynamic job scheduling in general networks. Due to the generality of the setting, their algorithms provide performance guarantees that are polylogarithmic in the problem size. <p> We require each job to be processed on exactly one processor without preemption. In one unit of time, we assume that each processor can receive some jobs from each neighbor, send some jobs to each neighbor, and process one unit of work; this is the model of <ref> [5] </ref>, and their assumptions are supported by current technology [7, 24]. If a processor sends a job to a neighbor at time t, the neighbor receives the job at time t + 1. <p> An interesting open problem is whether simple, small-constant approximation algorithms which require no centralized control exist for the other networks, such as the mesh. As stated earlier, Awerbuch et al. 23 <ref> [5] </ref> give a distributed algorithm for job scheduling in general networks. When applied to the mesh their algorithm is a constant-approximation algorithm.
Reference: [6] <author> L. Bhuyan, D. Ghosal, and Q. Yang. </author> <title> Approximate analysis of single and multiple ring networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38 </volume> <pages> 1027-1040, </pages> <year> 1989. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [4, 6, 10, 16, 17, 21, 22] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [14, 20, 23, 24].
Reference: [7] <author> H. Choi and A. Esfahanian. </author> <title> A message routing strategy for multicomputer systems. </title> <journal> Networks, </journal> <volume> 22 </volume> <pages> 627-646, </pages> <year> 1992. </year>
Reference-contexts: In one unit of time, we assume that each processor can receive some jobs from each neighbor, send some jobs to each neighbor, and process one unit of work; this is the model of [5], and their assumptions are supported by current technology <ref> [7, 24] </ref>. If a processor sends a job to a neighbor at time t, the neighbor receives the job at time t + 1. We assume that the job granularity is large enough so that the time for simple control operations, such as simple arithmetic, is negligible.
Reference: [8] <author> X. Deng, H. Liu, J. Long, and B. Xiao. </author> <title> Deterministic load balancing in computer networks. </title> <booktitle> In Proceedings of 2nd IEEE Symposium on Parallel and Distributed Processing, </booktitle> <year> 1990. </year>
Reference-contexts: Other papers have included communication cost in basic scheduling models, and, while not applicable to our problem, are related to our work in spirit. Deng et al. <ref> [8] </ref> were the first to study the parallel machine scheduling problem in a network. They give a number of centralized algorithms, in addition to several distributed algorithms for special cases and models. <p> For each instance, we computed the length of the optimum centralized schedule (a centralized scheduler is given global knowledge of the system). It was previously known how to compute the optimum schedule length for an instance with unit size jobs <ref> [8] </ref> [11]. The former of these two approaches [8] formulated the problem as a minimum cost flow problem. Their algorithm is difficult to implement because it requires the use of a very wide range of costs. <p> For each instance, we computed the length of the optimum centralized schedule (a centralized scheduler is given global knowledge of the system). It was previously known how to compute the optimum schedule length for an instance with unit size jobs <ref> [8] </ref> [11]. The former of these two approaches [8] formulated the problem as a minimum cost flow problem. Their algorithm is difficult to implement because it requires the use of a very wide range of costs. For instance, an instance with a thousand machines would require that the costs range from 1 to 100 1000 . <p> We developed a different approach. It is a polynomial time algorithm that uses less than m 3 space and it only requires code for maximum flow. This approach made the problem more tractable than the algorithm of Deng et al. <ref> [8] </ref> and easier to code than Hoppe and Tardos' algorithm [11]. The algorithm we implemented is a polynomial time algorithm that works for general graphs with infinite capacity links.
Reference: [9] <author> M. Herlihy, B. Lim, and N. Shavit. </author> <title> Low contention load-balancing on large-scale multiprocessors. </title> <booktitle> In Proceedings of the 4th ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 219-227, </pages> <year> 1992. </year>
Reference-contexts: If algorithm A always yields a schedule of length no more than L (I) + O (1) we call A a -approximation algorithm. Note that this problem is related to, but different from, load balancing, which is another common problem 5 in parallel and distributed systems (see <ref> [2, 9] </ref>). In the load balancing problem one is given a set of tasks or tokens and must distribute the tasks so that each processor in the system has approximately the same number.
Reference: [10] <author> Y. Hong and T. Payne. </author> <title> Parallel sorting in a ring network of processors. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 38:458 - 464, </volume> <year> 1989. </year> <month> 28 </month>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [4, 6, 10, 16, 17, 21, 22] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [14, 20, 23, 24].
Reference: [11] <author> B. Hoppe and E. Tardos. </author> <title> The quickest transhipment problem. </title> <booktitle> In Proceedings of the 6th ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <year> 1995. </year>
Reference-contexts: Phillips, Stein and Wein [18] improved on their results by giving a centralized off-line 2-approximation algorithm for a very general form of the problem, as well as hardness-to-approximate results and approximation algorithms for different optimality criteria. Hoppe and 4 Tardos <ref> [11] </ref> give a polynomial time algorithm for general networks and unit size jobs. Their algorithm is the first polynomial time algorithm that produces optimal length schedules in networks with finite capacity. The rest of this paper is organized as follows. In Section 2 we precisely define the problem. <p> For each instance, we computed the length of the optimum centralized schedule (a centralized scheduler is given global knowledge of the system). It was previously known how to compute the optimum schedule length for an instance with unit size jobs [8] <ref> [11] </ref>. The former of these two approaches [8] formulated the problem as a minimum cost flow problem. Their algorithm is difficult to implement because it requires the use of a very wide range of costs. <p> For instance, an instance with a thousand machines would require that the costs range from 1 to 100 1000 . Even if we shifted the values so that the largest value is representable then the smallest value is too small to be represented. The latter of the approaches <ref> [11] </ref> requires using a polynomial time procedure for convex function minimization as a subroutine [25]. We developed a different approach. It is a polynomial time algorithm that uses less than m 3 space and it only requires code for maximum flow. <p> It is a polynomial time algorithm that uses less than m 3 space and it only requires code for maximum flow. This approach made the problem more tractable than the algorithm of Deng et al. [8] and easier to code than Hoppe and Tardos' algorithm <ref> [11] </ref>. The algorithm we implemented is a polynomial time algorithm that works for general graphs with infinite capacity links. We begin by describing a variation of this algorithm and then discuss the necessary refinements to make it run in polynomial time.
Reference: [12] <author> S. Flynn Hummel and E. Schonberg. </author> <title> Low-overhead scheduling of nested parallelism. </title> <journal> IBM Journal of Research and Development, </journal> 35(5/6):743-765, 1991. 
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop paral-lelization <ref> [3, 12, 13, 19] </ref> or in the use of a parallel system to process batches of transactions or independent sequential programs. We restrict our attention to the ring, which is an important network in both theory and practice.
Reference: [13] <author> S. Flynn Hummel, E. Schonberg, and L. E. Flynn. </author> <title> Factoring: A practical and robust method for scheduling parallel loops. </title> <journal> Comm. of the ACM, </journal> <volume> 35(8) </volume> <pages> 90-101, </pages> <year> 1992. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop paral-lelization <ref> [3, 12, 13, 19] </ref> or in the use of a parallel system to process batches of transactions or independent sequential programs. We restrict our attention to the ring, which is an important network in both theory and practice.
Reference: [14] <author> D. Hutchinson. </author> <title> Local Area Network Architectures. </title> <publisher> Addison-Wesley, </publisher> <year> 1988. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [14, 20, 23, 24] </ref>. The element of our model which most differentiates it from previous scheduling models is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network.
Reference: [15] <author> E.L. Lawler, J.K. Lenstra, A.H.G. Rinooy Kan, </author> <title> and D.B. Shmoys. Sequencing and scheduling: Algorithms and complexity. In S.C. Graves, </title> <editor> A.H.G. Rinnooy Kan, and P.H. Zipkin, editors, </editor> <booktitle> Handbooks in Operations Research and Management Science, </booktitle> <volume> Vol 4., </volume> <booktitle> Logistics of Production and Inventory, </booktitle> <pages> pages 445-522. </pages> <publisher> North-Holland, </publisher> <year> 1993. </year>
Reference-contexts: We also report on an experimental study of our algorithm, which suggests better performance than does our worst-case analysis as well as give a lower bound on the performance of any 3 distributed algorithm for this problem. There is a wealth of literature on parallel machine scheduling (see <ref> [15] </ref> for some examples) but almost all of it fails to capture the full complexity of many real scheduling problems. Many of the proposed algorithms have significant control overhead, and almost all of the literature ignores the communication constraints imposed by an underlying network architecture.
Reference: [16] <author> F. T. Leighton. </author> <title> An Introduction to Parallel Algorithms and Architectures. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [4, 6, 10, 16, 17, 21, 22] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [14, 20, 23, 24].
Reference: [17] <author> Y. Mansour and L. Schulman. </author> <title> Sorting on a ring of processors. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 622-630, </pages> <year> 1990. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [4, 6, 10, 16, 17, 21, 22] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [14, 20, 23, 24].
Reference: [18] <author> C. A. Phillips, C. Stein, and J. Wein. </author> <title> Task scheduling in networks. </title> <booktitle> In Proceedings of the 4th Scandinavian Workshop on Algorithm Theory, </booktitle> <month> July </month> <year> 1994. </year>
Reference-contexts: Deng et al. [8] were the first to study the parallel machine scheduling problem in a network. They give a number of centralized algorithms, in addition to several distributed algorithms for special cases and models. Phillips, Stein and Wein <ref> [18] </ref> improved on their results by giving a centralized off-line 2-approximation algorithm for a very general form of the problem, as well as hardness-to-approximate results and approximation algorithms for different optimality criteria. Hoppe and 4 Tardos [11] give a polynomial time algorithm for general networks and unit size jobs.
Reference: [19] <author> C. Polychronopoulos and D. Kuck. </author> <title> Guided self-scheduling: A practical scheduling scheme for parallel computers. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 12 </volume> <pages> 1425-1439, </pages> <year> 1987. </year>
Reference-contexts: Simply put, the problem is to assign each of a set of independent tasks to processors in the system so as to finish the processing of the tasks as quickly as possible. Job scheduling arises frequently in parallel computing, for example in algorithms for automatic loop paral-lelization <ref> [3, 12, 13, 19] </ref> or in the use of a parallel system to process batches of transactions or independent sequential programs. We restrict our attention to the ring, which is an important network in both theory and practice.
Reference: [20] <author> J. Rothnie. </author> <title> Kendall square research introduction to the ksr1. </title> <booktitle> In Dartmouth Institute for Advanced Graduate Studies in Parallel Computation, </booktitle> <pages> pages 200-210, </pages> <year> 1992. </year> <month> 29 </month>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [14, 20, 23, 24] </ref>. The element of our model which most differentiates it from previous scheduling models is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network.
Reference: [21] <author> W. Sung and S. Mitra. </author> <title> Multiprocessor implementation of recursive least squares algorithms using a parallel block processing method. </title> <booktitle> In IEEE International Symposium on Circuits and Systems, </booktitle> <pages> pages 2939-2942, </pages> <year> 1991. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [4, 6, 10, 16, 17, 21, 22] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [14, 20, 23, 24].
Reference: [22] <author> W. Sung, S. Mitra, and K. Kum. </author> <title> Mapping locally recursive sfgs upon a multiprocessor system in a ring network. </title> <booktitle> In Proceedings of the International Conference on Application Specific Array Processors, </booktitle> <pages> pages 560-573, </pages> <year> 1992. </year>
Reference-contexts: We restrict our attention to the ring, which is an important network in both theory and practice. From a theoretical perspective, the ring is a basic network structure, and much work has been done on developing and analyzing algorithms for it <ref> [4, 6, 10, 16, 17, 21, 22] </ref>. In practice the ring is either the basis of or an essential component of many parallel and distributed architectures [14, 20, 23, 24].
Reference: [23] <author> A.S. Tanenbaum. </author> <title> Computer Networks. </title> <publisher> Prentice Hall, </publisher> <year> 1989. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [14, 20, 23, 24] </ref>. The element of our model which most differentiates it from previous scheduling models is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network.
Reference: [24] <author> Gerard Tel. </author> <title> Introduction to Distributed Algorithms. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, U.K., </address> <year> 1994. </year>
Reference-contexts: In practice the ring is either the basis of or an essential component of many parallel and distributed architectures <ref> [14, 20, 23, 24] </ref>. The element of our model which most differentiates it from previous scheduling models is that task migration from one processor to another takes time proportional to the distance between those two processors in the communications network. <p> In one unit of time, we assume that each processor can receive some jobs from each neighbor, send some jobs to each neighbor, and process one unit of work; this is the model of [5], and their assumptions are supported by current technology <ref> [7, 24] </ref>. If a processor sends a job to a neighbor at time t, the neighbor receives the job at time t + 1. We assume that the job granularity is large enough so that the time for simple control operations, such as simple arithmetic, is negligible.

References-found: 24

