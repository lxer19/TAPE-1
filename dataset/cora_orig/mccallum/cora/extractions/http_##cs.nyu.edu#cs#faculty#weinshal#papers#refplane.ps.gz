URL: http://cs.nyu.edu/cs/faculty/weinshal/papers/refplane.ps.gz
Refering-URL: http://cs.nyu.edu/cs/faculty/weinshal/papers.html
Root-URL: http://www.cs.nyu.edu
Email: irani@wisdom.weizmann.ac.il  anandan@microsoft.com  daphna@cs.huji.ac.il  
Title: From Reference Frames to Reference Planes: Multi-View Parallax Geometry and Applications  
Author: Micahl Irani P. Anandan Daphna Weinshall 
Keyword: Multi-point multi-view geometry, uncalibrated images, new view synthesis, duality of cameras and scene points, plane+parallax, trilinearity.  
Address: Rehovot, Israel  One Microsoft Way Redmond, WA 98052  91904 Jerusalem, Israel  
Affiliation: Dept. of Appl. Math and CS The Weizmann Inst. of Sci.  Microsoft Research  Inst. of Computer Sci. Hebrew University  
Abstract: This paper presents a new framework for analyzing the geometry of multiple 3D scene points from multiple uncalibrated images, based on decomposing the projection of these points on the images into two stages: (i) the projection of the scene points onto a (real or virtual) physical reference planar surface in the scene; this creates a virtual "image" on the reference plane, and (ii) the re-projection of the virtual image onto the actual image plane of the camera. The positions of the virtual image points are directly related to the 3D locations of the scene points and the camera centers relative to the reference plane alone. All dependency on the internal camera calibration parameters and the orientation of the camera are folded into homographies relating each image plane to the reference plane. Bi-linear and tri-linear constraints involving multiple points and views are given a concrete physical interpretation in terms of geometric relations on the physical reference plane. In particular, the possible dualities in the relations between scene points and camera centers are shown to have simple and symmetric mathematical forms. These relations are directly related to physical points such as the epipole and the dual-epipole. In contrast to the plane+parallax (p+p) representation, which also uses a reference plane, the approach described here removes the dependency on a reference image plane and extends the analysis to multiple views. This leads to simpler geometric relations and complete symmetry in multi-point multi-view duality. The simple and intuitive expressions derived in the reference-plane based formulation lead to useful applications in 3D scene analysis. In particular, simpler tri-focal constraints are derived that lead to simple methods for New View Synthesis. Moreover, the separation and compact packing of the unknown camera calibration and orientation into the 2D projection transformation (a homography) allows also partial reconstruction using partial calibration information. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Avidan and A. Shashua. </author> <title> Novel view synthesis in tensor space. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 1034-1040, </pages> <address> San-Juan, </address> <month> June </month> <year> 1997. </year>
Reference: [2] <author> S. Carlsson. </author> <title> Duality of reconstruction and positioning from projective views. In Workshop on Representations of Visual Scenes, </title> <booktitle> 1995. In Proc. Fifth European Conference of Computer Vision, Freiburg, </booktitle> <volume> 6/98 13 </volume>
Reference-contexts: Alternatively, given a projective coordinate system specified by 5 basis points, the set of constraints directly relating the projective coordinates of the camera centers to the image measurements (in 2D projective coordinates) and their dual constraints relating to the projective coordinates of the 3D scene points have also been derived <ref> [2, 20] </ref>. Alternatively, multiple uncalibrated images can be handled using the "plane + parallax" (P+P) approach, which analyzes the parallax displacements of a point between two views relative to a (real or virtual) physical planar surface in the scene [16, 12, 11]. <p> red) and dual-epipolar lines (shown in blue) that arise when considering two points in two views. 3 Duality on the Reference Plane In this section, we derive a set of dual relations on the reference-plane by switching the roles of camera centers and scene points as was previously done in <ref> [2, 20] </ref>. Consider two points P i and P j and one camera center C t . Consider the intersection of the rays P i P j , P i C t and P j C t with the reference plane (see Figure 2a). <p> The duality of the bilinear constraint has been previously explored - e.g., Carlsson <ref> [2] </ref> and Weinshall, et al.[20] derive dual bilinear and trilinear relations in terms of the projective coordinate representations of the scene points, camera centers, and image points. Here, however, we derive these relations in the context of the reference plane images, and provide physical meaning to the dual relations.
Reference: [3] <author> H.S.M Coxeter, </author> <title> editor. Projective Geometry. </title> <publisher> Springer Verlag, </publisher> <year> 1987. </year>
Reference-contexts: Note that this figure on the plane (Figure 4a) is known as the "complete quadrilateral" and plays a central role in plane projective geometry <ref> [3] </ref>. Given the three cameras, every point in the scene forms a triangle (e.g., with vertices p it ; p is and p ir . Different points (e.g., indexed i; j; etc.) will form different triangles, all of which share the same tri-focal line (see Figure 4b). <p> In fact, this is because of the complete symmetry between scene points and camera centers in our representation. 3 It is known in plane-projective geometry that if two triangles are perspective from a line they are also perspective from a point <ref> [3] </ref> this is the converse of the Desargues' Theorem. Given the two triangles corresponding to i and j as in Figure 4b, then the point of perspectivity is in fact the dual-epipole p ij . In Proc.
Reference: [4] <author> O.D. Faugeras. </author> <title> What can be seen in three dimensions with an uncalibrated stereo rig? In European Conference on Computer Vision, </title> <address> pages 563-578, Santa Margarita Ligure, </address> <month> May </month> <year> 1992. </year>
Reference-contexts: Fifth European Conference of Computer Vision, Freiburg, 6/98 2 If the calibration of the cameras is unavailable, then it is known that reconstruction is still possible from two views, but only up to a 3D projective transformation <ref> [4] </ref>. In this case the epipolar constraint still holds, but the Essential Matrix is replaced by the "Fundamental Matrix", which also incorporates the unknown camera calibration information. The 3D scene points, the camera centers and their image positions are represented in 3D and 2D projective spaces (using homogeneous projective coordinates).
Reference: [5] <author> O.D. Faugeras and B. Mourrain. </author> <title> On the geometry and algebra of the point and line correspondences between n images. </title> <booktitle> In International Conference on Computer Vision, </booktitle> <pages> pages 951-956, </pages> <address> Cambridge, MA, </address> <month> June </month> <year> 1995. </year>
Reference-contexts: In this case, the reference frame reconstruction may either be a reference camera coordinate frame [8], or as defined by a set of 5 basis points in the 3D world [14]. A complete set of constraints relating the image positions of multiple points in multiple views have been derived <ref> [5, 15] </ref>. <p> The 6 points on lie on 4 lines forming a "complete quadrilateral". 4 Three View Geometry on the Reference Plane In this section we extend our treatment to three views. <ref> [5] </ref> shows that there are no additional independent constraints that can be derived in more than three views. In this section we present a geometric interpretation of the three-view constraints in terms of physical quantities on the reference plane . <p> We derive the algebraic three-view constraints and show that they have a very simple mathematical form. We will also show that the tensor-representation of these constraints in the reference-plane has a very simple mathematical form when compared to the tensors in the standard formulations <ref> [15, 7, 5] </ref>. 4.1 Geometric Observations camera center is labeled as C r , and the two new epipoles as p rt and p sr 2 . <p> There are, however, two cases in which the three epipolar lines collapse into a single line (and hence, their intersection is not unique). These are the same situations noted in <ref> [5, 15] </ref>, but here we examine it in the context of the reference-plane images. The first is the case when the three camera centers are collinear (see Figure 5) in this case the three epipoles collapse into a single point (denoted as e in Figure 5). <p> Also, as in [17] the relationships in Equation 10 are valid for any line passing through p is and any other line passing through p ir . In other words, Equation 10 captures the same point-line-line relationship described in [17] and <ref> [5] </ref>. In Proc. Fifth European Conference of Computer Vision, Freiburg, 6/98 9 (a) (b) 3 points + 1 camera center. (b) the quadrilateral formed by 2 points + 2 cameras. <p> This is in contrast to the general form of the trifocal tensor for example, the trilinear tensor in [15] also depends on the homographies due to the plane between the different cameras and the tensor described in <ref> [5] </ref> which depends on the camera projection matrices. As in the case of the Fundamental Matrix F in our formulation, the epipoles are explicit within the Tensor T , whereas in the general formulation, the tensor is implicitly related to the epipole.
Reference: [6] <author> Olivier Faugeras. </author> <title> Three-Dimensional Computer Vision AGeometric Viewpoint. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: Given two calibrated cameras, their relative orientations can be determined by applying the epipolar constraint to the observed image points, and the 3D structure of the scene can be recovered relative to the coordinate frame of a reference camera (referred to here as the reference frame-e.g., see <ref> [13, 6] </ref>). This is done by using the epipolar constraint and recovering the "Essential Matrix" E which depends on the rotation R and translation T between the two cameras.
Reference: [7] <author> Richard Hartley. </author> <title> Lines and poins in three views a unified approach. </title> <booktitle> In DARPA Image Understanding Workshop Proceedings, </booktitle> <year> 1994. </year>
Reference-contexts: We derive the algebraic three-view constraints and show that they have a very simple mathematical form. We will also show that the tensor-representation of these constraints in the reference-plane has a very simple mathematical form when compared to the tensors in the standard formulations <ref> [15, 7, 5] </ref>. 4.1 Geometric Observations camera center is labeled as C r , and the two new epipoles as p rt and p sr 2 .
Reference: [8] <author> Richard Hartley. </author> <title> Euclidean Reconstruction from Uncalibrated Views. In Applications of Invariance in Computer Vision, </title> <editor> J.L. Mundy, D. Forsyth, and A. Zisserman (Eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The 3D scene points, the camera centers and their image positions are represented in 3D and 2D projective spaces (using homogeneous projective coordinates). In this case, the reference frame reconstruction may either be a reference camera coordinate frame <ref> [8] </ref>, or as defined by a set of 5 basis points in the 3D world [14]. A complete set of constraints relating the image positions of multiple points in multiple views have been derived [5, 15].
Reference: [9] <author> M. Irani and P. Anandan. </author> <title> Parallax geometry of pairs of points for 3d scene analysis. </title> <booktitle> In European Conference on Computer Vision, </booktitle> <address> Cambridge, UK, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: On the reference plane the multi-point multi-view geometry is simple and intuitive. These relations are directly related to physical points on the reference plane such as the epipole and the dual-epipole <ref> [9] </ref>. We identify these points, and also two new entities called the tri-focal line and the dual trifocal-line which are analogous to the epipole and the dual-epipole when considering three-view and three-point geometries on the reference plane. The relations between entities such as epipoles and dual-epipoles have concrete geometrical meaning. <p> Here, however, we derive these relations in the context of the reference plane images, and provide physical meaning to the dual relations. Also, Irani and Anandan <ref> [9] </ref> pointed out the dual epipole in the context of the plane+parallax representation. In that case, since the projection on a camera image plane ("reference frame") is included in the formulation, there exists an asymmetry in the various constraints and their dual constraints. <p> The farther a scene point is from the planar surface (rug), the larger its residual misalignment. We refer to these as planar-parallax displacements (see <ref> [11, 12, 9] </ref>). Note that the plane-stabilized sequence is in fact a 2D re-projection of the corresponding "virtual images" on the reference plane onto the reference image plane, t (See Figure 1.b). <p> Fifth European Conference of Computer Vision, Freiburg, 6/98 12 [12]). Note that after plane stabilization, the flow field between the two images reduces to a radial epipolar field centered at the epipole (see Equation (3); see also <ref> [11, 12, 9] </ref>). The cancellation of the plane homogra-phy removes all effects of camera rotation and changes in calibration. This allows to compute the flow field between a plane-stabilized image pair more reliably than general flow, as it is constrained to satisfy a global epipolar constraint.
Reference: [10] <author> M. Irani, B. Rousso, and S. Peleg. </author> <title> Computing occluding and transparent motions. </title> <journal> International Journal of Computer Vision, </journal> <volume> 12(1) </volume> <pages> 5-16, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: The corresponding 2D projective transformation is computed automatically, without any prior or additional information, using a 2D registration technique described in <ref> [10] </ref>. This method locks onto a dominant 2D parametric transformation between a pair of images, even in the presence of moving objects or other outliers (such as the toys, in our case). For more details see [10]. In Proc. <p> automatically, without any prior or additional information, using a 2D registration technique described in <ref> [10] </ref>. This method locks onto a dominant 2D parametric transformation between a pair of images, even in the presence of moving objects or other outliers (such as the toys, in our case). For more details see [10]. In Proc. Fifth European Conference of Computer Vision, Freiburg, 6/98 11 (a) (b) (a) and (b) show two images taken by a hand-held camera. The camera translated and rotated between the two views.
Reference: [11] <author> M. Irani, B. Rousso, and P. peleg. </author> <title> Recovery of ego-motion using region alignment. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 19(3) </volume> <pages> 268-272, </pages> <month> March </month> <year> 1997. </year>
Reference-contexts: Alternatively, multiple uncalibrated images can be handled using the "plane + parallax" (P+P) approach, which analyzes the parallax displacements of a point between two views relative to a (real or virtual) physical planar surface in the scene <ref> [16, 12, 11] </ref>. The magnitude of the parallax displacement is called the "relative-affine structure" in [16]. [12] shows that this quantity depends both on the "Height" H of P from and its depth Z relative to the reference camera. <p> The farther a scene point is from the planar surface (rug), the larger its residual misalignment. We refer to these as planar-parallax displacements (see <ref> [11, 12, 9] </ref>). Note that the plane-stabilized sequence is in fact a 2D re-projection of the corresponding "virtual images" on the reference plane onto the reference image plane, t (See Figure 1.b). <p> Fifth European Conference of Computer Vision, Freiburg, 6/98 12 [12]). Note that after plane stabilization, the flow field between the two images reduces to a radial epipolar field centered at the epipole (see Equation (3); see also <ref> [11, 12, 9] </ref>). The cancellation of the plane homogra-phy removes all effects of camera rotation and changes in calibration. This allows to compute the flow field between a plane-stabilized image pair more reliably than general flow, as it is constrained to satisfy a global epipolar constraint. <p> The foregoing outline for a reconstruction method assumes that the correspondences of each point across the multiple-views can be estimated. This involves computing the parallax flow-field (s), and the epipole (s)- these can be done in the same manner as described in <ref> [11, 12] </ref>. It is worth noting, however, the removal of the planar homography allows the parallax computation to be more robust and accurate [11, 12]. <p> This involves computing the parallax flow-field (s), and the epipole (s)- these can be done in the same manner as described in <ref> [11, 12] </ref>. It is worth noting, however, the removal of the planar homography allows the parallax computation to be more robust and accurate [11, 12].
Reference: [12] <author> R. Kumar, P. Anandan, and K. Hanna. </author> <title> Direct recovery of shape from multiple views: a parallax based approach. </title> <booktitle> In Proc 12th ICPR, </booktitle> <year> 1994. </year>
Reference-contexts: Alternatively, multiple uncalibrated images can be handled using the "plane + parallax" (P+P) approach, which analyzes the parallax displacements of a point between two views relative to a (real or virtual) physical planar surface in the scene <ref> [16, 12, 11] </ref>. The magnitude of the parallax displacement is called the "relative-affine structure" in [16]. [12] shows that this quantity depends both on the "Height" H of P from and its depth Z relative to the reference camera. <p> The magnitude of the parallax displacement is called the "relative-affine structure" in [16]. <ref> [12] </ref> shows that this quantity depends both on the "Height" H of P from and its depth Z relative to the reference camera. <p> The farther a scene point is from the planar surface (rug), the larger its residual misalignment. We refer to these as planar-parallax displacements (see <ref> [11, 12, 9] </ref>). Note that the plane-stabilized sequence is in fact a 2D re-projection of the corresponding "virtual images" on the reference plane onto the reference image plane, t (See Figure 1.b). <p> Similarly T Z tr for the third camera r. H s and H r are as before (i.e., heights relative to ). Step II: Dense flow is estimated between the two plane-stabilized images (using the method described in In Proc. Fifth European Conference of Computer Vision, Freiburg, 6/98 12 <ref> [12] </ref>). Note that after plane stabilization, the flow field between the two images reduces to a radial epipolar field centered at the epipole (see Equation (3); see also [11, 12, 9]). The cancellation of the plane homogra-phy removes all effects of camera rotation and changes in calibration. <p> Fifth European Conference of Computer Vision, Freiburg, 6/98 12 [12]). Note that after plane stabilization, the flow field between the two images reduces to a radial epipolar field centered at the epipole (see Equation (3); see also <ref> [11, 12, 9] </ref>). The cancellation of the plane homogra-phy removes all effects of camera rotation and changes in calibration. This allows to compute the flow field between a plane-stabilized image pair more reliably than general flow, as it is constrained to satisfy a global epipolar constraint. <p> The foregoing outline for a reconstruction method assumes that the correspondences of each point across the multiple-views can be estimated. This involves computing the parallax flow-field (s), and the epipole (s)- these can be done in the same manner as described in <ref> [11, 12] </ref>. It is worth noting, however, the removal of the planar homography allows the parallax computation to be more robust and accurate [11, 12]. <p> This involves computing the parallax flow-field (s), and the epipole (s)- these can be done in the same manner as described in <ref> [11, 12] </ref>. It is worth noting, however, the removal of the planar homography allows the parallax computation to be more robust and accurate [11, 12].
Reference: [13] <author> H.C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <year> 1981. </year>
Reference-contexts: Given two calibrated cameras, their relative orientations can be determined by applying the epipolar constraint to the observed image points, and the 3D structure of the scene can be recovered relative to the coordinate frame of a reference camera (referred to here as the reference frame-e.g., see <ref> [13, 6] </ref>). This is done by using the epipolar constraint and recovering the "Essential Matrix" E which depends on the rotation R and translation T between the two cameras.
Reference: [14] <author> R. Mohr. </author> <title> Accurate Projective Reconstruction In Applications of Invariance in Computer Vision, </title> <editor> J.L. Mundy, D. Forsyth, and A. Zisserman, (Eds.), </editor> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: In this case, the reference frame reconstruction may either be a reference camera coordinate frame [8], or as defined by a set of 5 basis points in the 3D world <ref> [14] </ref>. A complete set of constraints relating the image positions of multiple points in multiple views have been derived [5, 15].
Reference: [15] <author> A. Shashua. </author> <title> Algebraic functions for recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 17 </volume> <pages> 779-789, </pages> <year> 1995. </year>
Reference-contexts: In this case, the reference frame reconstruction may either be a reference camera coordinate frame [8], or as defined by a set of 5 basis points in the 3D world [14]. A complete set of constraints relating the image positions of multiple points in multiple views have been derived <ref> [5, 15] </ref>. <p> Since the relative-affine-structure measure is relative to both the reference frame (through Z) and the reference plane (through H), we refer to the P+P framework also as the reference-frame + reference-plane formulation. Using the P+P formulation, <ref> [15] </ref> derived "tri-linear" constraints involving image positions of a point in three uncalibrated views. <p> We derive the algebraic three-view constraints and show that they have a very simple mathematical form. We will also show that the tensor-representation of these constraints in the reference-plane has a very simple mathematical form when compared to the tensors in the standard formulations <ref> [15, 7, 5] </ref>. 4.1 Geometric Observations camera center is labeled as C r , and the two new epipoles as p rt and p sr 2 . <p> There are, however, two cases in which the three epipolar lines collapse into a single line (and hence, their intersection is not unique). These are the same situations noted in <ref> [5, 15] </ref>, but here we examine it in the context of the reference-plane images. The first is the case when the three camera centers are collinear (see Figure 5) in this case the three epipoles collapse into a single point (denoted as e in Figure 5). <p> )(x is x ts ) (y is y it )(x ir x rt ) = rst (x ir x it )(y is y ts ) Note that these three view constraints are actually only bilinear in the image locations of the scene point (as opposed to the trilinear constraints in <ref> [15] </ref>)). This is because by considering the projection of the points on the reference plane itself, we eliminate the homographies induced between the views (which appear in [16]). <p> Note that the elements of T rst depend on the two epipoles p rt and p ts and rst . This is in contrast to the general form of the trifocal tensor for example, the trilinear tensor in <ref> [15] </ref> also depends on the homographies due to the plane between the different cameras and the tensor described in [5] which depends on the camera projection matrices.
Reference: [16] <author> A. Shashua and N. Navab. </author> <title> Relative affine structure: Theory and application to 3d reconstruction from perspective views. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <pages> pages 483-489, </pages> <address> Seattle, Wa., </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Alternatively, multiple uncalibrated images can be handled using the "plane + parallax" (P+P) approach, which analyzes the parallax displacements of a point between two views relative to a (real or virtual) physical planar surface in the scene <ref> [16, 12, 11] </ref>. The magnitude of the parallax displacement is called the "relative-affine structure" in [16]. [12] shows that this quantity depends both on the "Height" H of P from and its depth Z relative to the reference camera. <p> The magnitude of the parallax displacement is called the "relative-affine structure" in <ref> [16] </ref>. [12] shows that this quantity depends both on the "Height" H of P from and its depth Z relative to the reference camera. <p> This is because by considering the projection of the points on the reference plane itself, we eliminate the homographies induced between the views (which appear in <ref> [16] </ref>).
Reference: [17] <author> A. Shashua and P. </author> <title> Ananadan Trilinear Constraints revisited: generalized trilinear constraints and the tensor brightness constraint. </title> <address> IUW, </address> <month> Feb. </month> <year> 1996. </year>
Reference-contexts: This is because by considering the projection of the points on the reference plane itself, we eliminate the homographies induced between the views (which appear in [16]). The trilinear forms given in Equation 9 can be unified into a single tensor equation in a manner analogous to <ref> [17] </ref>: where s = 1 0 x is 0 1 y ir and ff; fi = 1; 2 indicate the row indices of s and r (e.g., s 1 = [1 0 x is ]) 4 . <p> T rst is 3 fi 3 fi 3 tensor (T rst ) abc = ((p rt ) b ffi ac rst (p ts ) c ffi ab ) 4 Note that as in <ref> [17] </ref>, s 1 is the vertical line on passing through p is and s 2 is the horizontal line on passing through p is . Similarly r 1 and r 2 are the vertical and horizontal lines on passing through p ir . Also, as in [17] the relationships in Equation <p> Note that as in <ref> [17] </ref>, s 1 is the vertical line on passing through p is and s 2 is the horizontal line on passing through p is . Similarly r 1 and r 2 are the vertical and horizontal lines on passing through p ir . Also, as in [17] the relationships in Equation 10 are valid for any line passing through p is and any other line passing through p ir . In other words, Equation 10 captures the same point-line-line relationship described in [17] and [5]. In Proc. <p> Also, as in <ref> [17] </ref> the relationships in Equation 10 are valid for any line passing through p is and any other line passing through p ir . In other words, Equation 10 captures the same point-line-line relationship described in [17] and [5]. In Proc. Fifth European Conference of Computer Vision, Freiburg, 6/98 9 (a) (b) 3 points + 1 camera center. (b) the quadrilateral formed by 2 points + 2 cameras.
Reference: [18] <author> P.H.S. Torr. </author> <title> Motion Segmentation and Outlier Detection. </title> <type> PhD Thesis: Report No. </type> <institution> OUEL 1987/93, Univ. of Oxford, UK, </institution> <year> 1993. </year>
Reference-contexts: Also, when the scene is "flat", the F matrix estimation is unstable, whereas the planar homography can be reliably recovered <ref> [18] </ref>. In this paper, we remove the dependency on the reference frame of the analysis of multi-point multi-view geometry.
Reference: [19] <author> M. Spetsakis and J. Aloimonos. </author> <title> A unified theory of structure from motion. </title> <booktitle> DARPA Image Understanding Workshop, </booktitle> <address> pp.271-283, Pittsburgh, PA, </address> <year> 1990 </year> . 
Reference-contexts: This is done by using the epipolar constraint and recovering the "Essential Matrix" E which depends on the rotation R and translation T between the two cameras. Constraints directly involving the image positions of a point in three calibrated views of a point have also been derived <ref> [19] </ref>. fl MI and DW are supported in part by DARPA through ARL Contract DAAL01-97-K-0101. This research was done while DW was on sabbatical at NECI Princeton. 1 In Proc.
Reference: [20] <author> D. Weinshall, M.Werman, and A. Shashua. </author> <title> Shape descriptors: Bilinear, trilinear and quadlinear relations for multi-point geometry, and linear projective reconstruction algorithms. In Workshop on Representations of Visual Scenes, </title> <year> 1995. </year>
Reference-contexts: Alternatively, given a projective coordinate system specified by 5 basis points, the set of constraints directly relating the projective coordinates of the camera centers to the image measurements (in 2D projective coordinates) and their dual constraints relating to the projective coordinates of the 3D scene points have also been derived <ref> [2, 20] </ref>. Alternatively, multiple uncalibrated images can be handled using the "plane + parallax" (P+P) approach, which analyzes the parallax displacements of a point between two views relative to a (real or virtual) physical planar surface in the scene [16, 12, 11]. <p> red) and dual-epipolar lines (shown in blue) that arise when considering two points in two views. 3 Duality on the Reference Plane In this section, we derive a set of dual relations on the reference-plane by switching the roles of camera centers and scene points as was previously done in <ref> [2, 20] </ref>. Consider two points P i and P j and one camera center C t . Consider the intersection of the rays P i P j , P i C t and P j C t with the reference plane (see Figure 2a).
References-found: 20

