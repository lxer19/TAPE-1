URL: http://american.cs.ucdavis.edu/publications/ISCA.91a.ps
Refering-URL: http://american.cs.ucdavis.edu/ArchLabPersonnel/Farrens/PubList.html
Root-URL: http://www.cs.ucdavis.edu
Email: (arp@tosca.colorado.edu)  
Title: d d Strategies for Achieving Improved Processor Throughput  
Author: Matthew K. Farrens Andrew R. Pleszkun 
Address: Davis, CA 95616  (farrens@cs.ucdavis.edu) Boulder, CO 80309-0425  
Affiliation: Computer Science Division Department of Electrical and University of California, Davis Computer Engineering  University of Colorado-Boulder  
Abstract: Deeply pipelined processors have relatively low issue rates due to dependencies between instructions. In this paper we examine the possibility of interleaving a second stream of instructions into the pipeline, which would issue instructions during the cycles the first stream was unable to. Such an interleaving has the potential to significantly increase the throughput of a processor without seriously imparing the execution of either process. We propose a dynamic interleaving of at most 2 instructions streams, which share the the pipelined functional units of a machine. To support the interleaving of 2 instruction streams a number of interleaving policies are described and discused. Finally, the amount of improvement in processor throughput is evaluated by simulating the interleaving policies for several machine variants. 
Abstract-found: 1
Intro-found: 1
Reference: [AlGo90] <author> G. S. Almasi and A. Gottlieb, </author> <title> Highly Parallel Computing, </title> <publisher> Benjamin/Cummings Publishing Co. Inc., </publisher> <pages> pp. 425-429, </pages> <year> 1990. </year>
Reference-contexts: This allowed 10 different I/O processes to be in execution simultaneously. The concept of multiple processes sharing a pipelined functional unit appears again, in a slightly different form, in the Denelcor HEP architecture 1 <ref> [Smit81, AlGo90, HwBr84] </ref>. Here, an 8-stage execution pipeline is multiplexed across a set of user processes, instead of I/O processes.
Reference: [CRAY82] <author> CRAY-1 Computers, </author> <title> Hardware Reference Manual, </title> <institution> Chippewa Falls, WI, Cray Research Inc., </institution> <year> 1982. </year>
Reference: [HwBr84] <author> K. Hwang and F. Briggs, </author> <title> Computer Architecture and Parallel Processing, </title> <publisher> McGraw-Hill Book Co., </publisher> <pages> pp. 669-684, </pages> <year> 1984. </year>
Reference-contexts: This allowed 10 different I/O processes to be in execution simultaneously. The concept of multiple processes sharing a pipelined functional unit appears again, in a slightly different form, in the Denelcor HEP architecture 1 <ref> [Smit81, AlGo90, HwBr84] </ref>. Here, an 8-stage execution pipeline is multiplexed across a set of user processes, instead of I/O processes.
Reference: [JoWa89] <author> N. P. Jouppi and D. W. </author> <title> Wall ``Available Instruction-Level Parallelism for Superscalar and Superpipelined Machines,'' </title> <booktitle> Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pp. </pages> <month> 272-282 April </month> <year> 1989. </year>
Reference-contexts: Another approach to decreasing T T is to use a "superscalar" design (which supports the issue of more than one instruction per clock). However, as pointed out by Jouppi and Wall <ref> [JoWa89] </ref>, the same dependencies between instructions that affect pipelined machines also affect superscalar machines. According to their study, machines with a high degree of pipelining provide virtually identical performance to machines that are superscalar to the same degree.
Reference: [KaDa79] <author> W. J. Kaminsky and E. S. Davidson, </author> <title> ``Developing a Multiple-Instruction-Stream Single-Chip Processor,'' </title> <booktitle> Computer, </booktitle> <pages> pp. 66-76, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: Once the a memory request is satisfied, the process is placed back into the pool of processes waiting on the execution pipeline. While the HEP multiplexed the execution pipeline in the context of a supercomputer, a similar approach was suggested by Kaminsky and Davidson <ref> [KaDa79] </ref> in the context of a single-chip processor. They argued that the main cost of supporting multiple processes is the need to duplicate the registers that store the state of a process.
Reference: [McMa84] <author> F. H. McMahon, </author> <title> ``LLNL FORTRAN KERNELS: </title> <type> MFLOPS,'' </type> <institution> Lawrence Livermore Laboratories, Livermore, </institution> <address> CA, </address> <month> March </month> <year> 1984. </year>
Reference-contexts: Basic Machine Model For our studies we used a modified CRAY-1 simulator developed at the University of Wisconsin [PaSm83]. The benchmark programs were the original 14 Lawrence Livermore Loops <ref> [McMa84] </ref>. Instruction traces were generated for each of the benchmark programs and then used to drive the simulations. No modifications to the code were performed; the code used is that produced by the Cray Fortran Compiler.
Reference: [PaSm83] <author> N. Pang and J. E. Smith, </author> <title> CRAY-1 Simulation Tools, </title> <type> Tech. Report ECE-83-11, </type> <institution> University of Wisconsin-Madison, </institution> <month> Dec. </month> <year> 1983. </year> <title> [PlSo88] ``The Performance Potential of Multiple Functional Unit Processors,'' </title> <booktitle> Proceedings of the 15th Annual Symposium on Computer Architecture, </booktitle> <pages> pp. 37-44, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: Basic Machine Model For our studies we used a modified CRAY-1 simulator developed at the University of Wisconsin <ref> [PaSm83] </ref>. The benchmark programs were the original 14 Lawrence Livermore Loops [McMa84]. Instruction traces were generated for each of the benchmark programs and then used to drive the simulations. No modifications to the code were performed; the code used is that produced by the Cray Fortran Compiler.
Reference: [Russ78] <author> R. M. Russel, </author> <title> ``The CRAY-1 Computer System,'' </title> <journal> Communications of the ACM, </journal> <volume> vol. 21, no. 1, </volume> <pages> pp. 63-72, </pages> <month> January </month> <year> 1978. </year>
Reference: [Smit81] <author> B. J. Smith, </author> <title> ``Architecture and Applications of the HEP Multiprocessor Computer System,'' </title> <booktitle> SPIE Real Time Signal Processing IV, </booktitle> <volume> Vol. 298, </volume> <pages> pp. 241-248, </pages> <month> Aug. </month> <year> 1981. </year>
Reference-contexts: This allowed 10 different I/O processes to be in execution simultaneously. The concept of multiple processes sharing a pipelined functional unit appears again, in a slightly different form, in the Denelcor HEP architecture 1 <ref> [Smit81, AlGo90, HwBr84] </ref>. Here, an 8-stage execution pipeline is multiplexed across a set of user processes, instead of I/O processes.
Reference: [Thor70] <author> J. E. Thornton, </author> <title> Design of a Computer The Control Data 6600, </title> <editor> Scott, Foresman and Co,. </editor> <year> 1970. </year>
Reference-contexts: Background The basis for this idea can be traced back to the I/O unit of the CDC 6600 <ref> [Thor70] </ref>. Because of the slow speed of I/O devices, the CDC 6600 I/O unit was configured as a set of 10 independent peripheral processors sharing a 10-stage pipelined central hardware core.
References-found: 10

