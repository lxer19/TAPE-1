URL: http://www.informatik.uni-hildesheim.de:80/~sirene/publ/PfPf_92MedNetIOS.ps.gz
Refering-URL: http://www.informatik.uni-hildesheim.de:80/~sirene/lit/sirene.lit.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Phone: 883735, Fax: +495121 860475  
Title: Advances in Medical Informatics, Technical Aspects of Data Protection in Health Care Informatics social parameters
Author: J. Noothoven van Goor and J. P. Christensen Andreas Pfitzmann, Birgit Pfitzmann 
Address: fr Informatik, Universitt Hildesheim,  Phone:+495121  
Affiliation: Institut  of Germany  
Date: 1992  
Note: (Eds.), IOS Press,  Postfach 101363, W-3200 Hildesheim, F. R.  0 Overview networks 1 in detail 1), and then measures against them 2). Since informatical systems used in medicine can be of quite different (technical and social) characteristics, these chapters deal with any kind of informatical systems. Of course, not all problems are posed, and not all some technical and  from 3, and sketch which security measures should therefore be taken. independently of the construction of specific systems.  
Abstract: Data protection comprises availability and data integrity as well as data confidentiality and privacy. We first consider security problems and their causes, and then measures against them. Finally, we recommend actions which should be taken independently of the construction of specific systems. Our main subject is distributed systems and medical networks: At present, most applications of informatics (computer science) in health care are standalone ones, such as databases or 3-D imaging systems. In the future, however, there will be more and more distributed systems. For example, for administrative purposes, lots of PCs in a hospital could be interconnected by a local area network, or PCs at private doctors could communicate with computers at insurances via a public network. For direct medical purposes, there are proposals to use video conferences to consult external experts during operations, or to monitor patients in their homes. The use of chipcards as carriers of emergency data is a distributed system, too. For security, distributed systems bring about new dangers, but also new possibilities for security measures. Dangers mainly result from the fact that the new systems are more complex, there are more interdependences, and more people have access to at least some part of the system than before. Possibilities are offered, e.g., because more complicated security measures can be performed by computers, and data We first consider the security problems in health care informatics, especially medical measures are applicable, in every system. In 3, for the case of networks, we therefore list To show how the material from the previous sections can be applied, in 4, we present several examples: We classify some specific medical networks according to the parameters In 5, we give some resulting recommendations for actions which should be taken * This paper is a revision of "A. Pfitzmann, B. Pfitzmann: Security in Medical Networks; presented at: Handling Health Data in the Future - AIM Working Conference on Data Protection and Confidentiality in Health Informatics; March 19-21, 1990, Brussels (Commission of the European Communities)". 1 Network is used as a synonym for "communication network", i.e. a technical system which allows a can be put out of reach of someone or some fault by suitable physical distribution.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. Denning: </author> <title> Cryptography and Data Security; Addison-Wesley, Reading 1982; Repr. with corrections, </title> <month> Jan. </month> <year> 1983. </year>
Reference-contexts: We do not claim that networks are the most interesting part of the problem of handling health data, since most of their problems can be solved by standard methods for network security. In particular, we recommend readers to consider problems of statistical databases in more detail <ref> [1] </ref> Chapter 6, [2], [3], [4]. <p> C1.2 Unintentional human errors. C1.2.1 Design or implementation errors. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 370 C1.2.2 Errors during the operation of the system. In contrast to physical failures, human errors are often not statistically independent. C2 Attacks 2 <ref> [1] </ref>, [7]. C2.1 Outsider attacks (i.e. by people who should play no role in the system, such as eavesdroppers). C2.2 Insider attacks (i.e. by people who play a role in the system). <p> C2.2.1 Insiders during the design or implementation of the system (i.e. designers or implementors of the system itself, designers or implementors of the tools used, and so on, since they might design or implement the system wrong, e.g., implant a universal Trojan Horse 3 <ref> [1] </ref>, [2]). C2.2.2 Insiders during the operation of the system. C2.2.2.1 Users. C2.2.2.2 Operators, security managers. C2.2.2.3 Maintenance personnel; in particular, system program mers. In most cases, the causes with higher numbers are more malignant. <p> Other cryptographic systems are, e.g., systems for authentication (such as the GMR Signature Scheme) and identification (such as the FiatShamir Identification Scheme). <ref> [1] </ref> provides a good introduction to cryptography, [11] gives an overview of modern cryptography. For more details, see, e.g., the CRYPTO and EUROCRYPT conference series of the IACR; the proceedings are usually published by Springer-Verlag, Berlin. A. Pfitzmann, B. <p> A particularly doubtful case of these are systems where the algorithms are kept secret. R4.2 Cryptographic systems of medium security, i.e. those which are not supported by theory, but have been thoroughly and publicly investigated for a long time, e.g., DES <ref> [1] </ref>, [8], [9]. R4.3 Cryptographic systems like RSA [10], [1], [8] which have been thoroughly investigated and look like being supported by mathematical theory, i.e. like being of class R4.4, although this cannot be proved (yet). <p> R4.2 Cryptographic systems of medium security, i.e. those which are not supported by theory, but have been thoroughly and publicly investigated for a long time, e.g., DES <ref> [1] </ref>, [8], [9]. R4.3 Cryptographic systems like RSA [10], [1], [8] which have been thoroughly investigated and look like being supported by mathematical theory, i.e. like being of class R4.4, although this cannot be proved (yet). <p> Signature schemes and cryptographically strong identification schemes offer the advantage that t contains no (useful) information about a. Thus A can use the same pair (a, t) for all possible recipients t, i.e. the key distribution problem becomes relatively simple. For a general introduction to authentication, see <ref> [1] </ref>, [8], [11], [12]. There are also new signature schemes which are as secure against forgery as the GMR Signature Scheme, but where, if a forgery should nevertheless occur, this can unconditionally be proved (with very high probability) [47], [36]. <p> A hybrid cryptosystem combines both types: a public key system is used to exchange a key of a private key cryptosystem. Concrete cryptosystems are mentioned in the text. For a general introduction to encryption, see [29], <ref> [1] </ref>, [8], [11]. 9 In a communication network where users A and B are connected via intermediate nodes, encryption can be used in two ways: One is end-to-end encryption, i.e. A encrypts and B decrypts and no intermediate node can read the A. Pfitzmann, B. <p> Disadvantage: the secret key exchange problem, if there are many potential pairs of communication partners. Systems of two security classes are important: M3.2.1.1 Vernam-cipher = onetime pad: the only unconditionally secure cryptosystem, but the keys are extremely long [26]. M3.2.1.2 Systems of medium security like DES 10 <ref> [1] </ref>, [8]: not crypto graphically strong, but publicly known and well investigated. <p> Speed of hardware implementations (one chip) at present 200 kbit/s, software implementations 1 kbit/s. M3.2.2.1 There are cryptographically strong cryptosystems, but definitely not against active attacks (i.e. if the owner of the key deciphers some messages chosen by the attacker) [28]. M3.2.2.2 RSA [10], [8], <ref> [1] </ref>: not cryptographically strong, but well investigated, and in some versions seemingly secure against active attacks, too. M3.2.3 Hybrid cryptosystems combine the easy key exchange of public key cryptosystems with the speed of private key cryptosystems. <p> The advantage is that encrypted data can be sent permanently over the link, i.e. garbage is encrypted if there is nothing real to be sent. Hence an outsider cannot even distinguish whether real messages are sent, i.e. cannot obtain any traffic data. Both modes are discussed in detail in <ref> [1] </ref>, [29].
Reference: [2] <author> D. Denning: </author> <title> Commutative Filters for Reducing Inference Threats in Multilevel Database Systems; Proc. </title> <booktitle> 1985 IEEE Symp. on Security and Privacy, </booktitle> <month> April </month> <year> 1985, </year> <title> Oakland, </title> <publisher> Computer Society, </publisher> <pages> 134-146. </pages>
Reference-contexts: We do not claim that networks are the most interesting part of the problem of handling health data, since most of their problems can be solved by standard methods for network security. In particular, we recommend readers to consider problems of statistical databases in more detail [1] Chapter 6, <ref> [2] </ref>, [3], [4]. <p> C2.2.1 Insiders during the design or implementation of the system (i.e. designers or implementors of the system itself, designers or implementors of the tools used, and so on, since they might design or implement the system wrong, e.g., implant a universal Trojan Horse 3 [1], <ref> [2] </ref>). C2.2.2 Insiders during the operation of the system. C2.2.2.1 Users. C2.2.2.2 Operators, security managers. C2.2.2.3 Maintenance personnel; in particular, system program mers. In most cases, the causes with higher numbers are more malignant.
Reference: [3] <author> D. E. Denning, J. Schlrer: </author> <title> Inference Controls for Statistical Databases; Computer 16/7 (1983) 69-82. </title>
Reference-contexts: In particular, we recommend readers to consider problems of statistical databases in more detail [1] Chapter 6, [2], <ref> [3] </ref>, [4].
Reference: [4] <author> K. Dittrich, J. </author> <month> Schlrer: </month> <institution> Anonymisierung von Forschungsdaten und Identifikation anonymer Datenstze; Datenschutz und Datensicherung DuD /1 (1987) 30-38. </institution>
Reference-contexts: In particular, we recommend readers to consider problems of statistical databases in more detail [1] Chapter 6, [2], [3], <ref> [4] </ref>.
Reference: [5] <author> D. Chaum: </author> <title> Security without Identification: Transaction Systems to make Big Brother Obsolete; Communications of the ACM 28/10 (1985) 1030-1044. </title>
Reference-contexts: In particular, we recommend readers to consider problems of statistical databases in more detail [1] Chapter 6, [2], [3], [4]. We also think a very interesting question is whether sensitive data can be reduced considerably by use of CHAUM's credential mechanism <ref> [5] </ref>. 1 Security problems in informatical systems, especially networks, in general Many problems and solutions are similar for informatical systems for quite different purposes and with quite different technical parameters. <p> M3.6.1 If data from different sources must be put together for some purposes, special pseudonyms can be used. M3.6.2 A new and very promising idea to avoid identification, even if authorization by a third party is necessary, is CHAUM's credential mechanism 12 <ref> [5] </ref>, [30]. <p> The mechanism also ensures that credentials can only be transferred between the different pseudonyms of one customer. Credentials can be implemented using the RSA-signature scheme [10]; for details see <ref> [5] </ref>, [55]. A typical application of CHAUM's credentials are anonymous payments [5], [32], [33]. A. Pfitzmann, B. <p> The mechanism also ensures that credentials can only be transferred between the different pseudonyms of one customer. Credentials can be implemented using the RSA-signature scheme [10]; for details see <ref> [5] </ref>, [55]. A typical application of CHAUM's credentials are anonymous payments [5], [32], [33]. A. Pfitzmann, B. <p> If a distributed database is used, a central MIX 11 , owned by the database organizers, can be used to yield the same effect. If anonymity is indeed offered, and if answers are not free, an anonymous payment system 14 must be used [31], <ref> [5] </ref>, [32], [33]. <p> Strong anonymous payment system can be implemented using CHAUM's credential mechanism [31], <ref> [5] </ref>, [32], [33]. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 382 Timing requirements: rather critical (real time, but not as fast as most purely technical processes). <p> A4 It must be prevented that nobody is responsible for computers. Since not only specifically designed hard and software will be used in medical systems, there must be commercial products complying with measure M2.14. A5 The most promising tool to avoid unnecessary sensitive personal data is CHAUM's credential mechanism <ref> [5] </ref>. How it can be used to maintain security against fraud, but to avoid detailed medical records, e.g., in insurances, should be investigated by an interdisciplinary team. A. Pfitzmann, B.
Reference: [6] <author> T. Anderson, P. A. Lee: </author> <title> Fault Tolerance - Principles and Practice; 2nd rev. ed., </title> <journal> Dependable Computing and Fault-Tolerant Systems Vol. </journal> <volume> 3, </volume> <publisher> Springer-Verlag, </publisher> <address> Wien 1990. </address>
Reference-contexts: For example, if measures to ensure privacy are implemented on a computer, and if this computer or the implementation are not correct, privacy can be lost. 1.2 Possible causes of problems The possible causes, like the problems, are similar for most problems in informatics. C1 Faults <ref> [6] </ref>. C1.1 "Physical" failures (like outside electrical disturbances or inside wearing-out of the material). They usually follow simple statistical distributions, and faults in physically independent systems usually occur statistically independently. C1.2 Unintentional human errors. C1.2.1 Design or implementation errors. A. Pfitzmann, B. <p> the operation of the system, anyway.) Some problems remain, e.g.: Common physical weaknesses (since measures against them are too expensive, such as shielding of everything or renunciation of miniaturization). 5 Of course, there exist quite a lot of fault tolerance measures, in particular as parts of measures M1.1, M1.2, M2.1. <ref> [6] </ref> provides a good introduction to fault tolerance. For more details, see, e.g., the FTCS conference series of the IEEE computer society. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 373 Weaknesses in the overall system design, such as overlooked dependencies between system parts. <p> M2.3 Plausibility tests on higher layers of the system (application dependent) <ref> [6] </ref>. This is the only measure which also helps against wrong commands by authorized users (but it does not detect "plausible" faults). Parts of this measure can be carried out automatically, but parts must be carried out by the people who would be affected by an incorrectness.
Reference: [7] <author> A. Pfitzmann, M. Waidner: </author> <title> Networks without user observability - design options; Eurocrypt '85, </title> <publisher> LNCS 219, Springer-Verlag, </publisher> <address> Berlin 1986, </address> <note> 245-253; revised version in: Computers & Security 6/2 (1987) 158-166. </note>
Reference-contexts: C1.2 Unintentional human errors. C1.2.1 Design or implementation errors. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 370 C1.2.2 Errors during the operation of the system. In contrast to physical failures, human errors are often not statistically independent. C2 Attacks 2 [1], <ref> [7] </ref>. C2.1 Outsider attacks (i.e. by people who should play no role in the system, such as eavesdroppers). C2.2 Insider attacks (i.e. by people who play a role in the system). <p> It could conceivably be used by patients to prove that they are insured in a certain insurance without showing their insurance numbers, or to ensure that patients transfer their medical records to a cancer register, but without telling [50], <ref> [7] </ref>, [53], [54]. 1 2 Assume a number of organizations and customers and a number of standard credentials. Each customer C uses a different pseudonym with each organization.
Reference: [8] <author> D. W. Davies, W. L. Price: </author> <title> Security for Computer Networks; (2nd ed.) </title> <publisher> John Wiley, </publisher> <address> New York 1989. </address>
Reference-contexts: A particularly doubtful case of these are systems where the algorithms are kept secret. R4.2 Cryptographic systems of medium security, i.e. those which are not supported by theory, but have been thoroughly and publicly investigated for a long time, e.g., DES [1], <ref> [8] </ref>, [9]. R4.3 Cryptographic systems like RSA [10], [1], [8] which have been thoroughly investigated and look like being supported by mathematical theory, i.e. like being of class R4.4, although this cannot be proved (yet). <p> R4.2 Cryptographic systems of medium security, i.e. those which are not supported by theory, but have been thoroughly and publicly investigated for a long time, e.g., DES [1], <ref> [8] </ref>, [9]. R4.3 Cryptographic systems like RSA [10], [1], [8] which have been thoroughly investigated and look like being supported by mathematical theory, i.e. like being of class R4.4, although this cannot be proved (yet). <p> Signature schemes and cryptographically strong identification schemes offer the advantage that t contains no (useful) information about a. Thus A can use the same pair (a, t) for all possible recipients t, i.e. the key distribution problem becomes relatively simple. For a general introduction to authentication, see [1], <ref> [8] </ref>, [11], [12]. There are also new signature schemes which are as secure against forgery as the GMR Signature Scheme, but where, if a forgery should nevertheless occur, this can unconditionally be proved (with very high probability) [47], [36]. <p> M2.5 Identification of authorized users by PINs, passwords etc. <ref> [8] </ref>. Some additional measures are necessary: A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 375 M2.5.1 One problem is to prevent an attacker from trying all PINs or passwords, at least if they are not much longer than PINs nowadays. <p> The same holds if the security of the user depends on an answer of the device: In this case the device must also have a (small) display. M2.6 Identification of authorized users by biometrics; e.g., recognizing authorized users by their fingerprints <ref> [8] </ref> Chapters 7.4 - 7.12. M2.7 Logical separation by secure operating systems. <p> A hybrid cryptosystem combines both types: a public key system is used to exchange a key of a private key cryptosystem. Concrete cryptosystems are mentioned in the text. For a general introduction to encryption, see [29], [1], <ref> [8] </ref>, [11]. 9 In a communication network where users A and B are connected via intermediate nodes, encryption can be used in two ways: One is end-to-end encryption, i.e. A encrypts and B decrypts and no intermediate node can read the A. Pfitzmann, B. <p> Disadvantage: the secret key exchange problem, if there are many potential pairs of communication partners. Systems of two security classes are important: M3.2.1.1 Vernam-cipher = onetime pad: the only unconditionally secure cryptosystem, but the keys are extremely long [26]. M3.2.1.2 Systems of medium security like DES 10 [1], <ref> [8] </ref>: not crypto graphically strong, but publicly known and well investigated. <p> Speed of hardware implementations (one chip) at present 200 kbit/s, software implementations 1 kbit/s. M3.2.2.1 There are cryptographically strong cryptosystems, but definitely not against active attacks (i.e. if the owner of the key deciphers some messages chosen by the attacker) [28]. M3.2.2.2 RSA [10], <ref> [8] </ref>, [1]: not cryptographically strong, but well investigated, and in some versions seemingly secure against active attacks, too. M3.2.3 Hybrid cryptosystems combine the easy key exchange of public key cryptosystems with the speed of private key cryptosystems.
Reference: [9] <author> A. Pfitzmann, R. Amann: </author> <title> Efficient Software Implementations of (Generalized) DES; Proc. </title> <booktitle> SECURICOM 90, 8th Worldwide Congress on Computer and Communications Security and Protection, </booktitle> <address> March 13-16, 1990, Paris. </address>
Reference-contexts: A particularly doubtful case of these are systems where the algorithms are kept secret. R4.2 Cryptographic systems of medium security, i.e. those which are not supported by theory, but have been thoroughly and publicly investigated for a long time, e.g., DES [1], [8], <ref> [9] </ref>. R4.3 Cryptographic systems like RSA [10], [1], [8] which have been thoroughly investigated and look like being supported by mathematical theory, i.e. like being of class R4.4, although this cannot be proved (yet). <p> At present, they are more efficient than any public key crypto systems. (Speed: hardware implementations (one chip): 32 Mbit/s; software implementations on MC68000, 8 MHz: 100 kbit/s, on MC68030, 25 MHz: 800 kbit/s <ref> [9] </ref>, [27].) Less secure cryptosystems are unimportant, since the efficiency of DES-like cryptosystems suffices for almost every application. Cryptographically strong private key cryptosystems have no advantages (as far as efficiency is concerned) over public key cryptosystems. M3.2.2 Public key cryptosystems. <p> Both modes are discussed in detail in [1], [29]. In many cases, they should be combined. 1 0 The key space of DES itself is too small, but there are equally efficient variants which seem more secure, e.g., G-DES <ref> [9] </ref>. 1 1 Networks without user observability keep traffic data secret from attackers in intermediate nodes in the network, and keep communication partners anonymous from each other. Apart from networks based on physical security techniques, there are two basic techniques, MIXes [37] and DC-networks [38].
Reference: [10] <author> R. L. Rivest, A. Shamir, L. Adleman: </author> <title> A Method for Obtaining Digital Signatures and Public-Key Cryptosystems; Communications of the ACM 21/2 (1978) 120-126, </title> <note> reprinted: 26/1 (1983) 96-99. </note>
Reference-contexts: A particularly doubtful case of these are systems where the algorithms are kept secret. R4.2 Cryptographic systems of medium security, i.e. those which are not supported by theory, but have been thoroughly and publicly investigated for a long time, e.g., DES [1], [8], [9]. R4.3 Cryptographic systems like RSA <ref> [10] </ref>, [1], [8] which have been thoroughly investigated and look like being supported by mathematical theory, i.e. like being of class R4.4, although this cannot be proved (yet). <p> More efficient, and thus more applicable, are cryptographically secure identification schemes like the FiatShamir Scheme [40]. The first cryptographically strong (R4.4) signature scheme, the GMR Signature Scheme, was presented in [12]. It is nearly as efficient as the less secure RSA-System <ref> [10] </ref>. Both types of authentication schemes need pairs of keys (or algorithms) (a, t) privately chosen by the sender A, where t is given to B. a is used to authenticate a message, t is used to test the authentication of a message. <p> Speed of hardware implementations (one chip) at present 200 kbit/s, software implementations 1 kbit/s. M3.2.2.1 There are cryptographically strong cryptosystems, but definitely not against active attacks (i.e. if the owner of the key deciphers some messages chosen by the attacker) [28]. M3.2.2.2 RSA <ref> [10] </ref>, [8], [1]: not cryptographically strong, but well investigated, and in some versions seemingly secure against active attacks, too. M3.2.3 Hybrid cryptosystems combine the easy key exchange of public key cryptosystems with the speed of private key cryptosystems. <p> The mechanism also ensures that credentials can only be transferred between the different pseudonyms of one customer. Credentials can be implemented using the RSA-signature scheme <ref> [10] </ref>; for details see [5], [55]. A typical application of CHAUM's credentials are anonymous payments [5], [32], [33]. A. Pfitzmann, B.
Reference: [11] <author> G. Brassard: </author> <title> Modern Cryptology - A Tutorial; LNCS 325, </title> <publisher> Springer-Verlag, </publisher> <address> Berlin 1988. </address>
Reference-contexts: Other cryptographic systems are, e.g., systems for authentication (such as the GMR Signature Scheme) and identification (such as the FiatShamir Identification Scheme). [1] provides a good introduction to cryptography, <ref> [11] </ref> gives an overview of modern cryptography. For more details, see, e.g., the CRYPTO and EUROCRYPT conference series of the IACR; the proceedings are usually published by Springer-Verlag, Berlin. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 372 research community. <p> R4.3 Cryptographic systems like RSA [10], [1], [8] which have been thoroughly investigated and look like being supported by mathematical theory, i.e. like being of class R4.4, although this cannot be proved (yet). R4.4 'Cryptographically strong' systems <ref> [11] </ref>, [12], i.e. those whose breaking has been proved to be at least as hard as some well-known old and hard mathematical problem, such as the factorization of natural numbers. R5 Trust in the correctness of designs and implementations. <p> Signature schemes and cryptographically strong identification schemes offer the advantage that t contains no (useful) information about a. Thus A can use the same pair (a, t) for all possible recipients t, i.e. the key distribution problem becomes relatively simple. For a general introduction to authentication, see [1], [8], <ref> [11] </ref>, [12]. There are also new signature schemes which are as secure against forgery as the GMR Signature Scheme, but where, if a forgery should nevertheless occur, this can unconditionally be proved (with very high probability) [47], [36]. <p> A hybrid cryptosystem combines both types: a public key system is used to exchange a key of a private key cryptosystem. Concrete cryptosystems are mentioned in the text. For a general introduction to encryption, see [29], [1], [8], <ref> [11] </ref>. 9 In a communication network where users A and B are connected via intermediate nodes, encryption can be used in two ways: One is end-to-end encryption, i.e. A encrypts and B decrypts and no intermediate node can read the A. Pfitzmann, B.
Reference: [12] <author> S. Goldwasser, S. Micali, R. L. Rivest: </author> <title> A Digital Signature Scheme Secure Against Adaptive Chosen-Message Attacks; SIAM J. </title> <institution> Comput. </institution> <month> 17/2 </month> <year> (1988) </year> <month> 281-308. </month>
Reference-contexts: R4.3 Cryptographic systems like RSA [10], [1], [8] which have been thoroughly investigated and look like being supported by mathematical theory, i.e. like being of class R4.4, although this cannot be proved (yet). R4.4 'Cryptographically strong' systems [11], <ref> [12] </ref>, i.e. those whose breaking has been proved to be at least as hard as some well-known old and hard mathematical problem, such as the factorization of natural numbers. R5 Trust in the correctness of designs and implementations. <p> More efficient, and thus more applicable, are cryptographically secure identification schemes like the FiatShamir Scheme [40]. The first cryptographically strong (R4.4) signature scheme, the GMR Signature Scheme, was presented in <ref> [12] </ref>. It is nearly as efficient as the less secure RSA-System [10]. <p> Thus A can use the same pair (a, t) for all possible recipients t, i.e. the key distribution problem becomes relatively simple. For a general introduction to authentication, see [1], [8], [11], <ref> [12] </ref>. There are also new signature schemes which are as secure against forgery as the GMR Signature Scheme, but where, if a forgery should nevertheless occur, this can unconditionally be proved (with very high probability) [47], [36].
Reference: [13] <institution> Department of Defense Standard: Department of Defense Trusted Computer System Evaluation Criteria; December 1985, DOD 5200.28-STD, </institution> <address> Library Nr. S225,711. </address>
Reference-contexts: users of one computer, nobody can read or change data without permission by their owner, or according to another security policy. (See, e.g., IEEE Computer 16/7 (1983) and the Series of the Proceedings of the IEEE Symposia on Security and Privacy.) However, even the best specified ones, class A1 in <ref> [13] </ref>, [14], are not appropriate for computers dealing with really sensitive data, cf. M2.11. M2.8 Auditing, i.e. storing who accessed which system part. Auditing presupposes that users can be identified. <p> M2.11 Reduction of covert channels 3 ; e.g. [18], [19], [20]. (A bandwidth of "only" 0.1 bit/s per covert channel seems to be the practical limit the military aims at for the future <ref> [13] </ref> p. 81. For channels whose existence is known, exactly 0 is attainable on A. Pfitzmann, B.
Reference: [14] <institution> German Information Security Agency: </institution> <note> ITSecurity Criteria; 1st version; Kln, Bundesanzeiger 1989. </note>
Reference-contexts: of one computer, nobody can read or change data without permission by their owner, or according to another security policy. (See, e.g., IEEE Computer 16/7 (1983) and the Series of the Proceedings of the IEEE Symposia on Security and Privacy.) However, even the best specified ones, class A1 in [13], <ref> [14] </ref>, are not appropriate for computers dealing with really sensitive data, cf. M2.11. M2.8 Auditing, i.e. storing who accessed which system part. Auditing presupposes that users can be identified.
Reference: [15] <author> C. A. R. </author> <title> Hoare: </title> <booktitle> The Mathematics of Programming; 5th Foundations of Software Technology and Theoretical Computer Science, </booktitle> <publisher> LNCS 206, Springer-Verlag, </publisher> <address> Heidelberg 1985, </address> <pages> 1-18. </pages>
Reference-contexts: Unfortunately, none of the following measures is perfect. M2.9 Verification (i.e. formal proof that an implementation satisfies the demands of a specification) <ref> [15] </ref>, [16]. On principle, verification of the top level specification is impossible. (There, only validation and/or diverse specification can help [17], cf. M2.10 and M2.12.) Another problem is that such a proof is usually longer than the implementation which it is to prove.
Reference: [16] <author> L. Lamport: </author> <title> A Simple Approach to Specifying Concurrent Systems; Communications of the ACM 32/1 (1989) 32-45. </title>
Reference-contexts: Unfortunately, none of the following measures is perfect. M2.9 Verification (i.e. formal proof that an implementation satisfies the demands of a specification) [15], <ref> [16] </ref>. On principle, verification of the top level specification is impossible. (There, only validation and/or diverse specification can help [17], cf. M2.10 and M2.12.) Another problem is that such a proof is usually longer than the implementation which it is to prove.
Reference: [17] <author> P. G. Neumann: </author> <title> Flaws in Specifications and What to Do About Them; Fifth Intern. </title> <booktitle> Workshop on Software Specification and Design; May 1989, Pittsburgh, Pennsylvania; Software Engineering Notes 14/3 (1989) xi-xv. </booktitle>
Reference-contexts: Unfortunately, none of the following measures is perfect. M2.9 Verification (i.e. formal proof that an implementation satisfies the demands of a specification) [15], [16]. On principle, verification of the top level specification is impossible. (There, only validation and/or diverse specification can help <ref> [17] </ref>, cf. M2.10 and M2.12.) Another problem is that such a proof is usually longer than the implementation which it is to prove. Hence it may be incorrect, too. (And if verification is carried out automatically, the verification tools, in their turn, may be incorrect.) M2.10 Extensive validation, i.e. testing.
Reference: [18] <author> K. Loepere: </author> <title> The Covert Channel Limiter Revisited; Operating Systems Review 23/2 (1989) 39-44. </title>
Reference-contexts: These are the socalled passive attacks, such as sending data by a covert channel 3 . There, the system behaves according to its specification; it just exploits the freedom which the specification left to the designer in an undesirable way. M2.11 Reduction of covert channels 3 ; e.g. <ref> [18] </ref>, [19], [20]. (A bandwidth of "only" 0.1 bit/s per covert channel seems to be the practical limit the military aims at for the future [13] p. 81. For channels whose existence is known, exactly 0 is attainable on A. Pfitzmann, B.
Reference: [19] <author> C. Tsai, V. D. Gligor, C. Sekar Chandersekaran: </author> <title> A Formal Method for the Identification of Covert Storage Channels in Source Code; Proc. </title> <booktitle> 1987 IEEE Symp. on Security and Privacy, </booktitle> <month> April 27-29, </month> <year> 1987, </year> <pages> Oakland, 74-84. </pages>
Reference-contexts: These are the socalled passive attacks, such as sending data by a covert channel 3 . There, the system behaves according to its specification; it just exploits the freedom which the specification left to the designer in an undesirable way. M2.11 Reduction of covert channels 3 ; e.g. [18], <ref> [19] </ref>, [20]. (A bandwidth of "only" 0.1 bit/s per covert channel seems to be the practical limit the military aims at for the future [13] p. 81. For channels whose existence is known, exactly 0 is attainable on A. Pfitzmann, B.
Reference: [20] <author> C. Tsai, V. D. Gligor: </author> <title> A Bandwidth Computation Model for Covert Storage Channels and its Applications; 1988 IEEE Symposium on Security and Privacy, </title> <publisher> IEEE Computer Society Press, </publisher> <address> Washington 1988, </address> <pages> 108-121. </pages>
Reference-contexts: There, the system behaves according to its specification; it just exploits the freedom which the specification left to the designer in an undesirable way. M2.11 Reduction of covert channels 3 ; e.g. [18], [19], <ref> [20] </ref>. (A bandwidth of "only" 0.1 bit/s per covert channel seems to be the practical limit the military aims at for the future [13] p. 81. For channels whose existence is known, exactly 0 is attainable on A. Pfitzmann, B.
Reference: [21] <author> W. </author> <month> Clesle: </month> <institution> Schutz auch vor Herstellern und Betreibern von Informationssystemen; Diplomarbeit, Institut fr Rechnerentwurf und Fehlertoleranz, Universitt Karlsruhe, </institution> <month> June </month> <year> 1988. </year>
Reference-contexts: For channels whose existence is known, exactly 0 is attainable on A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 376 reasonable assumptions, but at considerable expense <ref> [21] </ref>.) M2.12 Diverse design [22], [23] (in accordance with the decentralization of the system; in particular, if M1.1 is also applied). This is no help against 'typical' design faults, i.e. types of faults which are likely to be made even by completely independent designers, in particular, programmers. <p> Starting from a few widely accepted physical assumptions, the expected services of a computer system or a network must be deducible from the statements of the designers. This, and that only professionals take part in the design process, must be checked. This checking can largely be automatized. In <ref> [21] </ref>, this is elaborated a bit further: For error and attack diagno sis, it is reasonable that even technical entities, such as compilers, sign their output. 2.3 Measures to ensure privacy (P3) 2.3.1 Confidentiality of message contents (P3.1) These measures are mostly designed for networks, but several of them are also
Reference: [22] <author> A. Avizienis, J. Kelly: </author> <title> Fault Tolerance by Design Diversity: Concepts and Experiments; Computer 17/8 (1984) 67-80. </title>
Reference-contexts: For channels whose existence is known, exactly 0 is attainable on A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 376 reasonable assumptions, but at considerable expense [21].) M2.12 Diverse design <ref> [22] </ref>, [23] (in accordance with the decentralization of the system; in particular, if M1.1 is also applied). This is no help against 'typical' design faults, i.e. types of faults which are likely to be made even by completely independent designers, in particular, programmers.
Reference: [23] <author> J. C. Knight, N. G. Leveson: </author> <title> A Reply to the Criticisms of the Knight & Leveson Experiment; Software Engineering Notes 15/1 (1990) 24-35. </title>
Reference-contexts: For channels whose existence is known, exactly 0 is attainable on A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 376 reasonable assumptions, but at considerable expense [21].) M2.12 Diverse design [22], <ref> [23] </ref> (in accordance with the decentralization of the system; in particular, if M1.1 is also applied). This is no help against 'typical' design faults, i.e. types of faults which are likely to be made even by completely independent designers, in particular, programmers.
Reference: [24] <author> J. Horgan: </author> <note> Thwarting the information thieves; IEEE spectrum 22/7 (1985) 30-41. </note>
Reference-contexts: M3.1 Physical security measures against wiretappers: These are only possible in few systems (in-house), otherwise they are too expensive or impossible. Note that optical fibers, too, can be tapped, although not quite as easily as copper cables and radio transmission <ref> [24] </ref> p. 36, [25] p. 108. M3.2 End-to-end encryption 8,9 : 8 Encryption enables A to conceal a message M in a way such that only B can read M.
Reference: [25] <author> H. J. Highland: </author> <title> Random Bits&Bytes; The Charade of Computer Security; Computers & Security 6/2 (1987) 108-109. </title>
Reference-contexts: M3.1 Physical security measures against wiretappers: These are only possible in few systems (in-house), otherwise they are too expensive or impossible. Note that optical fibers, too, can be tapped, although not quite as easily as copper cables and radio transmission [24] p. 36, <ref> [25] </ref> p. 108. M3.2 End-to-end encryption 8,9 : 8 Encryption enables A to conceal a message M in a way such that only B can read M.
Reference: [26] <author> C. E. Shannon: </author> <title> Communication Theory of Secrecy Systems; The Bell System Technical Journal 28/4 (1949) 656-715. </title> <editor> A. Pfitzmann, B. Pfitzmann: </editor> <booktitle> Technical Aspects of Data Protection in Health Care Informatics 386 </booktitle>
Reference-contexts: Disadvantage: the secret key exchange problem, if there are many potential pairs of communication partners. Systems of two security classes are important: M3.2.1.1 Vernam-cipher = onetime pad: the only unconditionally secure cryptosystem, but the keys are extremely long <ref> [26] </ref>. M3.2.1.2 Systems of medium security like DES 10 [1], [8]: not crypto graphically strong, but publicly known and well investigated.
Reference: [27] <author> A. Pfitzmann, R. Amann: </author> <title> More Efficient Software Implementations of (Generalized) DES; Interner Bericht 18/90, </title> <institution> Fakultt fr Informatik, Universitt Karlsruhe 1990. </institution>
Reference-contexts: At present, they are more efficient than any public key crypto systems. (Speed: hardware implementations (one chip): 32 Mbit/s; software implementations on MC68000, 8 MHz: 100 kbit/s, on MC68030, 25 MHz: 800 kbit/s [9], <ref> [27] </ref>.) Less secure cryptosystems are unimportant, since the efficiency of DES-like cryptosystems suffices for almost every application. Cryptographically strong private key cryptosystems have no advantages (as far as efficiency is concerned) over public key cryptosystems. M3.2.2 Public key cryptosystems.
Reference: [28] <author> M. Blum, S. Goldwasser: </author> <title> An Efficient Probabilistic Public-Key Encryption Scheme Which Hides All Partial Information; Crypto '84, </title> <publisher> LNCS 196, Springer-Verlag, </publisher> <address> Berlin 1985, </address> <pages> 289-299. </pages>
Reference-contexts: On principle, public key cryptosystems cannot be unconditionally secure. Speed of hardware implementations (one chip) at present 200 kbit/s, software implementations 1 kbit/s. M3.2.2.1 There are cryptographically strong cryptosystems, but definitely not against active attacks (i.e. if the owner of the key deciphers some messages chosen by the attacker) <ref> [28] </ref>. M3.2.2.2 RSA [10], [8], [1]: not cryptographically strong, but well investigated, and in some versions seemingly secure against active attacks, too. M3.2.3 Hybrid cryptosystems combine the easy key exchange of public key cryptosystems with the speed of private key cryptosystems.
Reference: [29] <author> V. L. Voydock, S. T. Kent: </author> <title> Security Mechanisms in High-Level Network Protocols; ACM Computing Surveys 15/2 (1983) 135-171. </title>
Reference-contexts: A hybrid cryptosystem combines both types: a public key system is used to exchange a key of a private key cryptosystem. Concrete cryptosystems are mentioned in the text. For a general introduction to encryption, see <ref> [29] </ref>, [1], [8], [11]. 9 In a communication network where users A and B are connected via intermediate nodes, encryption can be used in two ways: One is end-to-end encryption, i.e. A encrypts and B decrypts and no intermediate node can read the A. Pfitzmann, B. <p> With all kinds of cryptosystems, secret keys must usually be chosen by one of the communication partners and must not be shown to any third party. 2.3.2 Confidentiality of traffic data M3.3 Link-by-link encryption 9 (usually using a private key cryptosystem) keeps all traffic data secret from wiretappers <ref> [29] </ref>. M3.4 Networks without user observability 11 : They can keep most traffic data secret from messages which A sends to B. The other is link-by-link encryption, where the traffic between any two adjacent nodes is encrypted by the sending node and decrypted by the receiving node. <p> Hence an outsider cannot even distinguish whether real messages are sent, i.e. cannot obtain any traffic data. Both modes are discussed in detail in [1], <ref> [29] </ref>.
Reference: [30] <author> D. Chaum, H. van Antwerpen: </author> <title> Undeniable Signatures; Crypto '89, </title> <publisher> LNCS 435, Springer-Verlag, </publisher> <address> Heidelberg 1990, </address> <pages> 212-216. </pages>
Reference-contexts: M3.6.1 If data from different sources must be put together for some purposes, special pseudonyms can be used. M3.6.2 A new and very promising idea to avoid identification, even if authorization by a third party is necessary, is CHAUM's credential mechanism 12 [5], <ref> [30] </ref>. <p> Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 379 under which pseudonym, or that someone does not have a certain disease, without the medical record containing that person's name. (These measures would need some research work.) M3.6.3 Another new idea is CHAUM's socalled 'undeniable signatures' 13 <ref> [30] </ref>, which might better be called 'signatures which cannot be shown round'. They can be used if data become more sensitive by the fact that they are signed.
Reference: [31] <author> H. Brk, A. Pfitzmann: </author> <title> Digital Payment Systems Enabling Security and Unobservability; Computers & Security 8/5 (1989) 399-416. </title>
Reference-contexts: If a distributed database is used, a central MIX 11 , owned by the database organizers, can be used to yield the same effect. If anonymity is indeed offered, and if answers are not free, an anonymous payment system 14 must be used <ref> [31] </ref>, [5], [32], [33]. <p> Strong anonymous payment system can be implemented using CHAUM's credential mechanism <ref> [31] </ref>, [5], [32], [33]. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 382 Timing requirements: rather critical (real time, but not as fast as most purely technical processes).
Reference: [32] <author> D. Chaum: </author> <title> Privacy Protected Payments Unconditional Payer and/or Payee Untraceability; SMART CARD 2000: The Future of IC Cards; Laxenburg (Austria), </title> <publisher> 19.-20.10.1987, North-Holland, </publisher> <address> Amsterdam 1989, </address> <pages> 69-93. </pages>
Reference-contexts: The mechanism also ensures that credentials can only be transferred between the different pseudonyms of one customer. Credentials can be implemented using the RSA-signature scheme [10]; for details see [5], [55]. A typical application of CHAUM's credentials are anonymous payments [5], <ref> [32] </ref>, [33]. A. Pfitzmann, B. <p> If a distributed database is used, a central MIX 11 , owned by the database organizers, can be used to yield the same effect. If anonymity is indeed offered, and if answers are not free, an anonymous payment system 14 must be used [31], [5], <ref> [32] </ref>, [33]. <p> Strong anonymous payment system can be implemented using CHAUM's credential mechanism [31], [5], <ref> [32] </ref>, [33]. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 382 Timing requirements: rather critical (real time, but not as fast as most purely technical processes).
Reference: [33] <author> B. Pfitzmann, M. Waidner, A. Pfitzmann: </author> <note> Rechtssicherheit trotz Anonymitt in offenen digitalen Systemen; Computer und Recht 3/10,11,12 (1987) 712-717, 796-803, 898-904; revised version in: Datenschutz und Datensicherung DuD 14/5,6 (1990) 243-253, 305-315. </note>
Reference-contexts: The mechanism also ensures that credentials can only be transferred between the different pseudonyms of one customer. Credentials can be implemented using the RSA-signature scheme [10]; for details see [5], [55]. A typical application of CHAUM's credentials are anonymous payments [5], [32], <ref> [33] </ref>. A. Pfitzmann, B. <p> If a distributed database is used, a central MIX 11 , owned by the database organizers, can be used to yield the same effect. If anonymity is indeed offered, and if answers are not free, an anonymous payment system 14 must be used [31], [5], [32], <ref> [33] </ref>. The value exchange protocol (which ensures that the database obtains the money if and only if the user obtains the answer [34], [35]) can be quite simple, since the database is not anonymous [33] p. 803. 4.2 Video transmission during operations Problems posed: P1 Complete failure: critical, if one completely <p> if answers are not free, an anonymous payment system 14 must be used [31], [5], [32], <ref> [33] </ref>. The value exchange protocol (which ensures that the database obtains the money if and only if the user obtains the answer [34], [35]) can be quite simple, since the database is not anonymous [33] p. 803. 4.2 Video transmission during operations Problems posed: P1 Complete failure: critical, if one completely relies on an external expert watching the operation. <p> Strong anonymous payment system can be implemented using CHAUM's credential mechanism [31], [5], [32], <ref> [33] </ref>. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 382 Timing requirements: rather critical (real time, but not as fast as most purely technical processes).
Reference: [34] <author> H. Brk, A. Pfitzmann: </author> <title> Value Transfer Systems Enabling Security and Unobservability; Interner Bericht 2/87, </title> <institution> Fakultt fr Informatik, Universitt Karlsruhe 1987. </institution>
Reference-contexts: If anonymity is indeed offered, and if answers are not free, an anonymous payment system 14 must be used [31], [5], [32], [33]. The value exchange protocol (which ensures that the database obtains the money if and only if the user obtains the answer <ref> [34] </ref>, [35]) can be quite simple, since the database is not anonymous [33] p. 803. 4.2 Video transmission during operations Problems posed: P1 Complete failure: critical, if one completely relies on an external expert watching the operation.
Reference: [35] <author> H. Brk, A. Pfitzmann: </author> <title> Value Exchange Systems Enabling Security and Unobservability; Computers & Security 9/8 (1990) 715-721. </title>
Reference-contexts: If anonymity is indeed offered, and if answers are not free, an anonymous payment system 14 must be used [31], [5], [32], [33]. The value exchange protocol (which ensures that the database obtains the money if and only if the user obtains the answer [34], <ref> [35] </ref>) can be quite simple, since the database is not anonymous [33] p. 803. 4.2 Video transmission during operations Problems posed: P1 Complete failure: critical, if one completely relies on an external expert watching the operation.
Reference: [36] <author> G. Bleumer, B. Pfitzmann, M. Waidner: </author> <title> A Remark on a Signature Scheme where Forgery can be Proved; Eurocrypt '90, </title> <publisher> LNCS 473, Springer-Verlag, </publisher> <address> Berlin 1991, </address> <pages> 441-445. </pages>
Reference-contexts: For a general introduction to authentication, see [1], [8], [11], [12]. There are also new signature schemes which are as secure against forgery as the GMR Signature Scheme, but where, if a forgery should nevertheless occur, this can unconditionally be proved (with very high probability) [47], <ref> [36] </ref>. Thus, there is never any doubt about whether signatures are correct, and the system can be stopped, or security parameters increased, if forgeries occur. Unfortunately, these socalled failstop signatures are, so far, less efficient than conventional signature schemes in most cases.
Reference: [37] <author> D. Chaum: </author> <title> Untraceable Electronic Mail, Return Addresses, </title> <booktitle> and Digital Pseudonyms; Communications of the ACM 24/2 (1981) 84-88. </booktitle>
Reference-contexts: Apart from networks based on physical security techniques, there are two basic techniques, MIXes <ref> [37] </ref> and DC-networks [38]. In general, MIXes are less secure, but more efficient than DC-networks. Details about necessary additions to make the basic concepts secure and about efficient implementations can be found in [46], [45], [48], [49], A. Pfitzmann, B.
Reference: [38] <author> D. Chaum: </author> <title> The Dining Cryptographers Problem: </title> <note> Unconditional Sender and Recipient Untraceability; Journal of Cryptology 1/1 (1988) 65-75. </note>
Reference-contexts: Apart from networks based on physical security techniques, there are two basic techniques, MIXes [37] and DC-networks <ref> [38] </ref>. In general, MIXes are less secure, but more efficient than DC-networks. Details about necessary additions to make the basic concepts secure and about efficient implementations can be found in [46], [45], [48], [49], A. Pfitzmann, B.
Reference: [39] <author> D. Chaum, S. Roijakkers: </author> <title> Unconditionally Secure Digital Signatures; Crypto '90, </title> <month> August </month> <year> 1990, </year> <pages> Abstracts, 209-217. </pages>
Reference-contexts: Unfortunately, these socalled failstop signatures are, so far, less efficient than conventional signature schemes in most cases. Recently, even unconditionally secure digital signatures have been invented <ref> [39] </ref>. There, the key distribution is a complicated protocol, and for many cases they are even less efficient than failstop signatures. Thus the feasability of these new schemes depends on the application. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 374 applied.
Reference: [40] <author> A. Fiat, A. Shamir: </author> <title> How to Prove Yourself: Practical Solutions to Identification and Signature Problems; Crypto '86, </title> <publisher> LNCS 263, Springer-Verlag, </publisher> <address> Berlin 1987, </address> <pages> 186-194. </pages>
Reference-contexts: There are unconditionally secure identification schemes, called authentication codes, but for most applications they need too long privately exchanged keys [51]. More efficient, and thus more applicable, are cryptographically secure identification schemes like the FiatShamir Scheme <ref> [40] </ref>. The first cryptographically strong (R4.4) signature scheme, the GMR Signature Scheme, was presented in [12]. It is nearly as efficient as the less secure RSA-System [10].
Reference: [41] <author> R. G. Gallager: </author> <title> Information Theory and Reliable Communication; John Wiley, </title> <address> New York 1968. </address>
Reference-contexts: If this modification is caused by a physical fault, it can, with high probability, be detected (tolerated) by an error-detecting (correcting) code. In opposite to authentication techniques, error-detecting (correcting) codes need nothing like a secret key. <ref> [41] </ref>, [44] provide good introductions to coding theory. 7 Authentication enables the receiver B of a message M to verify that the message was created by a specific sender A, even if an attacker tries to fool B. A scheme which implements exactly this specification is called an identification scheme.
Reference: [42] <author> B. W. Lampson: </author> <note> A Note on the Confinement Problem; Communications of the ACM 16/10 (1973) 613-615. </note>
Reference-contexts: For example, a Trojan Horse might send secret information (upon which the program operates) to its creator via a covert channel. This is a channel whose usage is not controlled, or whose existence is not even known, such as the exact timing of outputs (cf., e.g., <ref> [42] </ref>, [43]). While a normal Trojan Horse carries out a task fixed by its creator during the design or implementation, a universal Trojan Horse can repeatedly receive and execute instructions by its users during the operation of the system. A. Pfitzmann, B.
Reference: [43] <author> K. Loepere: </author> <title> Resolving Covert Channels Within a B2 Class Secure System; Operating Systems Review 19/3 (1985) 9-28. </title>
Reference-contexts: For example, a Trojan Horse might send secret information (upon which the program operates) to its creator via a covert channel. This is a channel whose usage is not controlled, or whose existence is not even known, such as the exact timing of outputs (cf., e.g., [42], <ref> [43] </ref>). While a normal Trojan Horse carries out a task fixed by its creator during the design or implementation, a universal Trojan Horse can repeatedly receive and execute instructions by its users during the operation of the system. A. Pfitzmann, B.
Reference: [44] <author> R. J. </author> <title> McEliece: The Theory of Information and Coding; A Mathematical Framework for Communication; Encyclopedia of Mathematics and its Applications, </title> <editor> Gian-Carlo Rota (ed.), </editor> <volume> Vol. 3, </volume> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <note> Second printing, with revisions, </note> <year> 1979. </year>
Reference-contexts: If this modification is caused by a physical fault, it can, with high probability, be detected (tolerated) by an error-detecting (correcting) code. In opposite to authentication techniques, error-detecting (correcting) codes need nothing like a secret key. [41], <ref> [44] </ref> provide good introductions to coding theory. 7 Authentication enables the receiver B of a message M to verify that the message was created by a specific sender A, even if an attacker tries to fool B. A scheme which implements exactly this specification is called an identification scheme.
Reference: [45] <author> A. Pfitzmann: </author> <title> How to implement ISDNs without user observability - Some remarks; Fakultt fr Informatik, </title> <note> Universitt Karlsruhe, Interner Bericht 14/85. </note>
Reference-contexts: Apart from networks based on physical security techniques, there are two basic techniques, MIXes [37] and DC-networks [38]. In general, MIXes are less secure, but more efficient than DC-networks. Details about necessary additions to make the basic concepts secure and about efficient implementations can be found in [46], <ref> [45] </ref>, [48], [49], A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 378 attackers in intermediate nodes in the network, and can keep communication partners anonymous from each other.
Reference: [46] <author> A. </author> <title> Pfitzmann: </title> <publisher> Diensteintegrierende Kommunikationsnetze mit teilnehmerberprfbarem Datenschutz; IFB 234, Springer-Verlag, </publisher> <address> Heidelberg 1990. </address>
Reference-contexts: Apart from networks based on physical security techniques, there are two basic techniques, MIXes [37] and DC-networks [38]. In general, MIXes are less secure, but more efficient than DC-networks. Details about necessary additions to make the basic concepts secure and about efficient implementations can be found in <ref> [46] </ref>, [45], [48], [49], A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 378 attackers in intermediate nodes in the network, and can keep communication partners anonymous from each other.
Reference: [47] <author> B. </author> <title> Pfitzmann: </title> <booktitle> Failstop Signatures; Principles and Applications; Proc. Compsec '91, 8th world conference on computer security, audit and control, </booktitle> <publisher> Elsevier, Oxford 1991, </publisher> <pages> 125-134. </pages>
Reference-contexts: For a general introduction to authentication, see [1], [8], [11], [12]. There are also new signature schemes which are as secure against forgery as the GMR Signature Scheme, but where, if a forgery should nevertheless occur, this can unconditionally be proved (with very high probability) <ref> [47] </ref>, [36]. Thus, there is never any doubt about whether signatures are correct, and the system can be stopped, or security parameters increased, if forgeries occur. Unfortunately, these socalled failstop signatures are, so far, less efficient than conventional signature schemes in most cases.
Reference: [48] <author> A. Pfitzmann, B. Pfitzmann, M. Waidner: </author> <note> Datenschutz garantierende offene Kommunikationsnetze; Informatik-Spektrum 11/3 (1988) 118-142. </note>
Reference-contexts: Apart from networks based on physical security techniques, there are two basic techniques, MIXes [37] and DC-networks [38]. In general, MIXes are less secure, but more efficient than DC-networks. Details about necessary additions to make the basic concepts secure and about efficient implementations can be found in [46], [45], <ref> [48] </ref>, [49], A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 378 attackers in intermediate nodes in the network, and can keep communication partners anonymous from each other.
Reference: [49] <author> A. Pfitzmann, B. Pfitzmann, M. </author> <type> Waidner: </type> <institution> Telefon-MIXe: Schutz der Vermittlungsdaten fr zwei 64-kbit/s-Duplexkanle ber den (264+16)-kbit/s-Teilnehmeranschlu; Datenschutz und Datensicherung DuD /12 (1989) 605-622. </institution>
Reference-contexts: In general, MIXes are less secure, but more efficient than DC-networks. Details about necessary additions to make the basic concepts secure and about efficient implementations can be found in [46], [45], [48], <ref> [49] </ref>, A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 378 attackers in intermediate nodes in the network, and can keep communication partners anonymous from each other.
Reference: [50] <author> A. Pfitzmann, B. Pfitzmann, M. Waidner: </author> <title> ISDN-MIXes Untraceable Communication with Very Small Bandwidth Overhead; Proc. </title> <booktitle> Kommunikation in verteilten Systemen, IFB 267, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Heidelberg 1991, </address> <note> 451-463; slightly extended version in: Proc. </note> <institution> IFIP/Sec'91, </institution> <address> Brighton, England, May 1991, </address> <publisher> Elsevier Science Publisher. </publisher>
Reference-contexts: It could conceivably be used by patients to prove that they are insured in a certain insurance without showing their insurance numbers, or to ensure that patients transfer their medical records to a cancer register, but without telling <ref> [50] </ref>, [7], [53], [54]. 1 2 Assume a number of organizations and customers and a number of standard credentials. Each customer C uses a different pseudonym with each organization.
Reference: [51] <author> G. J. Simmons: </author> <booktitle> A Survey of Information Authentication; Proceedings of the IEEE 76/5 (1988) 603-620. </booktitle>
Reference-contexts: A scheme which, additionally, enables B to prove to any third party C that message M was created by A is called a (digital) signature scheme. There are unconditionally secure identification schemes, called authentication codes, but for most applications they need too long privately exchanged keys <ref> [51] </ref>. More efficient, and thus more applicable, are cryptographically secure identification schemes like the FiatShamir Scheme [40]. The first cryptographically strong (R4.4) signature scheme, the GMR Signature Scheme, was presented in [12]. It is nearly as efficient as the less secure RSA-System [10].
Reference: [52] <author> A. S. Tanenbaum: </author> <title> Computer Networks; 2nd ed., </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs 1988. </address>
Reference-contexts: 1 Network is used as a synonym for "communication network", i.e. a technical system which allows a number of devices ("intelligent" computers, "stupid" phones) to exchange messages. We consider all components of a network, the hardware (lines, switching centers, user terminals) and the software which organizes the message transmission. <ref> [52] </ref> provides a good introduction to the technical aspects of networks. A. Pfitzmann, B. Pfitzmann: Technical Aspects of Data Protection in Health Care Informatics 369 The focus on networks results from our own research.
Reference: [53] <author> M. Waidner: </author> <title> Unconditional Sender and Recipient Untraceability in spite of Active Attacks; Eurocrypt '89, </title> <publisher> LNCS 434, Springer-Verlag, </publisher> <address> Berlin 1990, </address> <pages> 302-319. </pages>
Reference-contexts: It could conceivably be used by patients to prove that they are insured in a certain insurance without showing their insurance numbers, or to ensure that patients transfer their medical records to a cancer register, but without telling [50], [7], <ref> [53] </ref>, [54]. 1 2 Assume a number of organizations and customers and a number of standard credentials. Each customer C uses a different pseudonym with each organization.
Reference: [54] <author> M. Waidner, B. Pfitzmann: </author> <title> Unconditional Sender and Recipient Untraceability in spite of Active Attacks Some Remarks; Fakultt fr Informatik, </title> <address> Universitt Karlsruhe, Interner Bericht 5/89, </address> <month> March </month> <year> 1989. </year>
Reference-contexts: It could conceivably be used by patients to prove that they are insured in a certain insurance without showing their insurance numbers, or to ensure that patients transfer their medical records to a cancer register, but without telling [50], [7], [53], <ref> [54] </ref>. 1 2 Assume a number of organizations and customers and a number of standard credentials. Each customer C uses a different pseudonym with each organization.
Reference: [55] <author> D. Chaum: </author> <title> Showing credentials without identification: Transferring signatures between unconditionally unlinkable pseudonyms; Intern. </title> <booktitle> Conf. on Cryptology, </booktitle> <address> Sydney, Australia, </address> <month> January </month> <year> 1990, </year> <title> AUSCRYPT '90, </title> <publisher> LNCS 453, Springer-Verlag, </publisher> <address> Berlin 1990, </address> <pages> 246-264. </pages>
Reference-contexts: The mechanism also ensures that credentials can only be transferred between the different pseudonyms of one customer. Credentials can be implemented using the RSA-signature scheme [10]; for details see [5], <ref> [55] </ref>. A typical application of CHAUM's credentials are anonymous payments [5], [32], [33]. A. Pfitzmann, B.
References-found: 55

