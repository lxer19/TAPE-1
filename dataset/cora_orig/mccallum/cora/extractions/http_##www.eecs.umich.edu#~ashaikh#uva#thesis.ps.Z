URL: http://www.eecs.umich.edu/~ashaikh/uva/thesis.ps.Z
Refering-URL: http://www.eecs.umich.edu/~ashaikh/uva/
Root-URL: http://www.cs.umich.edu
Title: Design of Input and Output Modules for a Safety-Critical Wayside Train Control System  
Author: Anees A. Shaikh 
Degree: A Thesis Presented to the faculty of the  In Partial Fulfillment of the requirements for the Degree Master of Science in Electrical Engineering by  
Date: August 1994  
Affiliation: School of Engineering and Applied Science University of Virginia  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T.G. Fisher, </author> <title> Are Programmable Controllers Suitable for Emergency Shutdown Sys tems?, </title> <journal> ISA Transactions, </journal> <volume> Vol. 29, No. 2, </volume> <year> 1990, </year> <pages> pp. 1-11. </pages>
Reference-contexts: Often such systems require that the processing element, along with the rest of the system, have a numerical probability of operat ing safely, sometimes for periods exceeding 10 5 years <ref> [1] </ref>, [2], [3], [4], [5]. The Next Generation Architecture is a study of the design and implementation of a safety-critical distributed computing platform for real-time automatic train control. The overall goal of this architecture design is to maximize dependability metrics including safety, availability, performance, maintainability, and reliability. <p> Output devices often use triacs to control the state of the field devices. In many applications the safe state is for outputs to be turned off (or de-energized) or to maintain the last state in the event of a fault. When triacs fail, however, they often fail turned on <ref> [1] </ref>. To protect against such failures several manufacturers introduced output modules that make triacs fail-safe. One of these is the Allen-Bradley Protected Output Module. This module incorporates specialized circuitry that detects a shorted triac and forces the output off. Another example is the Texas Instruments Redundant Output Module. <p> Maintaining the ow of cooling water to prevent overheating in a nuclear power plant is an example in which the exibility afforded by a parallel connection is desirable <ref> [1] </ref>. Input interface device failures typically include broken wires, broken switches, or contacts that fail to close. These types of failures should cause a PLC system to fail safely. The fail-safe state of input devices must be carefully considered, similar to that of output devices. <p> For emergency shut-down systems, Fisher recommends fault-tolerant configurations with redundant PLCs, watchdog timers, and redundant input and output modules. Single PLCs, he adds, are not suitable for safety-critical systems even if equipped with external watchdog timers and fail-safe outputs <ref> [1] </ref>. Despite the recommendation to use redundant systems, Fisher does not address the issues of voter dependability or input congruence. Turner et. al. offer an overview of fail-safe design for microprocessor-based systems used in transit applications including railway, commercial and military avionics, and spaceborne applications [4]. <p> In all cases, however, the probability of unsafe failure must be limited to 10 -9 per hour of operation, or a mean time between unsafe failures (MTBUF) of 1 billion hours <ref> [1] </ref>. In spacecraft applications, microprocessor-based controllers handle booster control and spacecraft control. Booster controllers provide guidance during launch and must operate correctly without interruption for five to ten minutes. <p> Fault recovery is handled by local modules or by some central test and repair unit. The suitability of microprocessors for spacecraft control is still unknown, however. The radiation and electromagnetic fields in space may prove harmful to the new generation of smaller, more sensitive devices <ref> [1] </ref>. Regardless of the application, creating a safety-critical architecture requires a general sequence of steps, briey described below [1]: definition of safety requirements and hazards that must be handled safely choice of an acceptable MTBUF for the application detailed specification of the system, including safety features and methods for validation candidate <p> The suitability of microprocessors for spacecraft control is still unknown, however. The radiation and electromagnetic fields in space may prove harmful to the new generation of smaller, more sensitive devices <ref> [1] </ref>. Regardless of the application, creating a safety-critical architecture requires a general sequence of steps, briey described below [1]: definition of safety requirements and hazards that must be handled safely choice of an acceptable MTBUF for the application detailed specification of the system, including safety features and methods for validation candidate design safety evaluation to show that the system meets the required MTBUF software validation testing system maintenance 27
Reference: [2] <author> L. Bodsberg and P. Hokstad, </author> <title> Balancing Reliability Requirements for Field Devices and Control Logic Modules in Safety Systems, </title> <booktitle> Proceedings of the IFAC/IFIP/EWICS/ SRE Symposium on Safety, Security and Reliability of Computer Based Systems (SAFECOMP 91), </booktitle> <address> Trondheim, Norway, </address> <month> October 30, </month> <year> 1991, </year> <pages> pp. 89-94. </pages>
Reference-contexts: Often such systems require that the processing element, along with the rest of the system, have a numerical probability of operat ing safely, sometimes for periods exceeding 10 5 years [1], <ref> [2] </ref>, [3], [4], [5]. The Next Generation Architecture is a study of the design and implementation of a safety-critical distributed computing platform for real-time automatic train control. The overall goal of this architecture design is to maximize dependability metrics including safety, availability, performance, maintainability, and reliability. <p> This allows basic system requirements to be defined first, followed by more specific safety requirement for individual modules based on the tasks they perform <ref> [2] </ref>. A more specific design approach, including requirements definition, is proposed by a research team from the Charles Stark Draper Laboratory (CSDL). They stress that the primary way to define requirements for ultrareliable systems is to provide a quantitative measure of the maximum acceptable failure probability. <p> Errors in the software are not explicitly handled in the architecture and proving software correctness is an exceedingly difficult validation problem. An argument against the use of high redundancy in ultrareliable systems is given in a paper by Bodsberg and Hokstad <ref> [2] </ref>. They claim that physical replication of hardware modules provides only moderate gains in reliability. This is because the effectiveness of hardware redundancy depends on the nature of faults in the system. <p> These tend to be correlated faults that cause redundant hardware modules to fail in the same way <ref> [2] </ref>. <p> As far as processor configuration, the study concludes that duplex processors with one-out-of-two voting and self-test is optimal in applications where the cost of false trips is low or medium <ref> [2] </ref>. Although this study provides some useful comparisons of hardware redundancy configurations, it does not address the issue of input congruency and the Byzantine Generals problem. <p> The output of each of the modules is then voted upon before the data value is sent to the processor. In general safety is optimized when redundant sensors are used and their signals are distributed to different input modules. Voting at the input modules, then, is not necessary <ref> [2] </ref>. The configurations shown in Figure 5.2, however, do have voting at the input modules to Two example configurations are shown in which input modules are designed to vote on sensor values before processing.
Reference: [3] <author> J. Paques, </author> <title> Basic Safety Rules for Using Programmable Controllers, </title> <journal> ISA Transactions, </journal> <volume> Vol. 29, No. 2, </volume> <year> 1990, </year> <pages> pp. 17-22. </pages>
Reference-contexts: Often such systems require that the processing element, along with the rest of the system, have a numerical probability of operat ing safely, sometimes for periods exceeding 10 5 years [1], [2], <ref> [3] </ref>, [4], [5]. The Next Generation Architecture is a study of the design and implementation of a safety-critical distributed computing platform for real-time automatic train control. The overall goal of this architecture design is to maximize dependability metrics including safety, availability, performance, maintainability, and reliability. <p> Paques offers a set of prioritized safety rules that should be applied when using programmable devices in safety systems. He assumes that the system is controlled by a simplex programmable logic controller (PLC). Eight basic measures are considered minimum precautions in PLC-controlled systems <ref> [3] </ref>. <p> Some form of redundancy (with perhaps two-out-of-three voting) must be used. Even with the additional redundancy some minimum of hardwired (or vital Class I) safety devices is necessary <ref> [3] </ref>. 23 Fisher takes a similar view on the use of PLC devices in fail-safe applications. Standard, off-the-shelf hardware is inherently unsafe, he claims, because of the potential for unknown and uncountable internal PLC failures.
Reference: [4] <author> D.B. Turner, R.D. Burns, and H. Hecht, </author> <title> Designing Micro-Based Systems for Fail-Safe Travel, </title> <journal> IEEE Spectrum, </journal> <volume> Vol. 24, </volume> <month> February </month> <year> 1987, </year> <pages> pp. 58-63. </pages>
Reference-contexts: Often such systems require that the processing element, along with the rest of the system, have a numerical probability of operat ing safely, sometimes for periods exceeding 10 5 years [1], [2], [3], <ref> [4] </ref>, [5]. The Next Generation Architecture is a study of the design and implementation of a safety-critical distributed computing platform for real-time automatic train control. The overall goal of this architecture design is to maximize dependability metrics including safety, availability, performance, maintainability, and reliability. <p> Despite the recommendation to use redundant systems, Fisher does not address the issues of voter dependability or input congruence. Turner et. al. offer an overview of fail-safe design for microprocessor-based systems used in transit applications including railway, commercial and military avionics, and spaceborne applications <ref> [4] </ref>. Safety architectures in these applications always include redundancy but in contrast to the discussion above, the redundancy may take several forms. Additional hardware, calculations or processing, information, time, or control actuation, are examples of different types of redundancy. <p> Finally, fault-detection time is a critical parameter. In a duplex system, for example, protection is lost if the second controller fails before a fault in the first is detected and handled. The necessary fault detection time is a function of the system architecture, application dynamics, and acceptable risk <ref> [4] </ref>. As mentioned above, the major safety-critical applications examined by Turner et. al. include railway, aircraft, and spacecraft control. Appropriate definitions of safety along with requirements for the railway application were discussed in detail in Chapter 2.
Reference: [5] <author> D.B. Rutherford, </author> <title> What Do You Mean -- Its Fail-Safe?, 1990 Rapid Transit Conference, </title> <publisher> American Public Transit Association, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Often such systems require that the processing element, along with the rest of the system, have a numerical probability of operat ing safely, sometimes for periods exceeding 10 5 years [1], [2], [3], [4], <ref> [5] </ref>. The Next Generation Architecture is a study of the design and implementation of a safety-critical distributed computing platform for real-time automatic train control. The overall goal of this architecture design is to maximize dependability metrics including safety, availability, performance, maintainability, and reliability. <p> Rutherford, however, provides an overview of some alternative methods for achieving safety in the specific area of ATC systems <ref> [5] </ref>. Hardware redundancy is identified as one option to ensure safety. The pitfalls associated with hardware redundancy are also discussed. Software errors are a primary concern in hardware redundant systems. Errors may cause erroneous outputs or the negation of some important test in all modules. <p> The numerical values tend to be very large and are constructed by combining values representing the critical constituents of a permissive output. As with other single processor systems, the verification of correct numerical value must be assured by some external device <ref> [5] </ref>. Numerical assurance is basically an information redundancy technique where code-words for permissive outputs are generated by the processor and must be correct for operation to continue.
Reference: [6] <author> A.K. Ghosh, </author> <title> A Distributed Parallel Processing System for Wayside and Carborne Train Control, M.S.E.E. </title> <type> Thesis, </type> <institution> University of Virginia, Charlottesville, Virginia, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: In any configuration the architecture should incorporate global safety assurance (GSA) techniques to ensure input-to-output safety of the system, along with local assurance in the various subsystem modules to ensure that faults are contained within them <ref> [6] </ref>. Meeting the overall goals described above requires several iterations of the design, perhaps including different system configurations and varied GSA techniques. At each iteration the candidate architecture is evaluated based on such criteria as achievable safety, analyzability, complexity, implementation feasibility, and cost. <p> A train inertial position system (TIPS) senses such parameters as velocity and acceleration, and with a known starting position, determines train positions. In addition, beacons along the railway provide trains with absolute reference information so that they may correct any errors <ref> [6] </ref>. Control functions governing speed regulation, position calculation, and braking may be described with state variable equations in matrix form. Just as with Boolean operations for the wayside ATP, the carborne functions are appropriate for implementation on a microprocessor [6]. <p> with absolute reference information so that they may correct any errors <ref> [6] </ref>. Control functions governing speed regulation, position calculation, and braking may be described with state variable equations in matrix form. Just as with Boolean operations for the wayside ATP, the carborne functions are appropriate for implementation on a microprocessor [6]. The Next Generation Architecture with its safety assurance techniques provides a computing platform that supports fail-stop and fault-tolerant operations necessary for car-borne and wayside ATP functions. <p> This implies that fail-stop applications (such as the wayside ATP) and fault-tolerant applications (carborne ATP) could be implemented on the same architecture with simplex or hardware-redundant configurations. A software executive that supports multiprocessing also facilitates exibility by easily allowing redundant building block schemes <ref> [6] </ref>. Another characteristic of system exibility is the ability to use different types of processors in the architecture with minimal modifications. Simplicity in design is a desirable characteristic of the architecture that facilitates analysis of dependability metrics. <p> Railway controllers are often exposed to strong electromagnetic fields, noise, vibration, extreme temperatures, and lightning. The system should be designed with consideration of these effects. Reliance on COTS hardware or simplex configurations help to make the system more cost-effective, which is important if the technology is to be commercialized <ref> [6] </ref>. 2.2.3 Quantitative Requirements The purpose of quantitative evaluation is to assign numerical values to dependability attributes so that candidate designs may be directly compared. Typically each characteristic, or metric, is expressed as a probability and analyzed to arrive at an upper or lower bound. <p> Steady state availability is generally calculated by taking the ratio of MTTF to MTBF [10]. Availability requirements for railway applications are between 99.99% and 99.999% which translates roughly to about 10 to 30 minutes of downtime per year <ref> [6] </ref>. Aside from the dependability metrics mentioned above, the Next Generation Architecture must meet demanding performance-related requirements. The real-time nature of the application requires that the wayside ATP complete its operations every 1.5 seconds and the carborne ATP on the order of tens of milliseconds. <p> Each of the nodes is analogous to a fault containment region. The voting clusters themselves may be arranged as simplex, duplex, or N-modular redundant configurations depending on the degree of fault-tolerance required <ref> [6] </ref>, [24]. 4.2 Communications Facilities in a Distributed ATC System The high-speed serial network plays an important role in the system, both in meeting the performance requirements and in providing fault-tolerance characteristics. <p> The input and output modules are geographically distributed along the network and generally will outnumber the required wayside ATP processing sites. Wireless transmission through gateways allows the carborne ATP systems to communicate data such as velocity or identification to the wayside units <ref> [6] </ref>, [24]. 4.3 Safety-Critical Software Executive As discussed in Section 3.1, the use of software in a safety critical systems is problematic. Eradicating a complex software system of all bugs is virtually impossible and it is also extremely difficult to quantify the probability that software is error-free [13]. <p> The safety assurance method detects errors in the information domain. This implies the need for frequent exing of system components to reduce the fault latency time. That is, the time for a fault to manifest itself as an information error should kept to a minimum <ref> [6] </ref>. 59 Concurrent verification implies that errors are detected concurrently with system operation and verification is performed on the control algorithm. This is important because the actual workings of the hardware, or computing platform, are not of concern.
Reference: [7] <author> D.R. </author> <title> Disk, A Unique Application of a Microprocessor to Vital Controls, </title> <booktitle> Proceedings of International Conference on Railway Safety Control and Automation, </booktitle> <year> 1984, </year> <pages> pp. 97 104. </pages>
Reference-contexts: The manufacture, operation, and maintenance of fail-safe relays is based on standards instituted by several international railroad and transit organizations. The railway industry has long depended on fail-safe relays and considers their safety level beyond question <ref> [7] </ref>. The move to a microprocessor-based implementation of interlocking functions was driven by the expense of manufacturing, testing, and calibrating the relays. Also, a single wayside unit requires large and costly enclosures with multiple equipment racks [7]. <p> industry has long depended on fail-safe relays and considers their safety level beyond question <ref> [7] </ref>. The move to a microprocessor-based implementation of interlocking functions was driven by the expense of manufacturing, testing, and calibrating the relays. Also, a single wayside unit requires large and costly enclosures with multiple equipment racks [7]. Processors at the wayside ATP sites are responsible for safe switching and signaling at each track junction, along with communicating information to the carborne ATP. The carborne system handles functions such as overspeed detection and braking. <p> Most of the architectures examined limit their application to interlocking functions used at the wayside ATP. D.R. Disk describes the origin and development of Union Switch and Signals MICROLOK product, a simplex microprocessor-based interlocking system <ref> [7] </ref>. The basic requirements for MICROLOK are that it process data and evaluate Boolean interlocking expressions, determine that it has full control of the output circuits, and has a failsafe method to disconnect power from the outputs quickly if a failure occurs. <p> The drawback to this diverse software approach is the extensive testing necessary to validate the executive. Some of the methods used to validate the system are fault tree analysis, reliability and maintainability analysis, fail-safe testing, and failure modes, effects, and criticality analysis <ref> [7] </ref>. Another approach to providing safety in an microprocessor-based interlocking system is presented by D. Rutherford. The techniques used in the system appear in the General Railway Signal Companys Vital Processor Interlocking (VPI). As with the MICROLOK system, the VPI is based around a general purpose Boolean processor. <p> The input module senses data that the processing elements use to execute the control algorithm. In the wayside ATP system some examples of the data sensed are <ref> [7] </ref>, [28], [29]: track circuit occupancy 65 switch point contacts or switch states signal relay contacts or signal states signal lamp filament integrity track integrity highway grade crossing warning states high water, high wind, and rock slide warning signal states temperature defect indicators including high or wide load, dragging equipment, hot <p> In addition, the set of outputs is often partitioned into a vital and non-vital set. Signals controlling railway switches or braking, for example, are considered vital, while some panel indications may be non-vital. In the wayside ATP output signals may include <ref> [7] </ref>, [28]: signal mechanism drive signal lamp drive switch control traffic and track circuit control bridge control on movable bridges railway grade crossings highway grade crossing warning controls switch heaters for melting snow Wayside control outputs are as varied as sensor inputs. <p> DeLong. Formal documentation of these efforts is not available. 93 sor-based system was set up alongside a traditional relay-based system which was actually driving the switches and signals. This allowed an easy comparison of the control outputs generated by each system to ensure that they were equivalent <ref> [7] </ref>. The relay-driven system in this example is the oracle. The plant model compares the oracle results against the outputs received from the control system and indicates any discrepancies. The outputs are then applied to the physical plant and train, switch, and signal positions are updated.
Reference: [8] <author> Volume II - Technical Specifications, </author> <title> Metro Green Line Contract Documents, Contract No. </title> <institution> R23-T07-H1100, Los Angeles County Transportation Commission, </institution> <month> February 20, </month> <year> 1991. </year>
Reference-contexts: This may involve receiving and decoding speed limit information from the wayside ATP or accurately determining the vehicle speed to provide overspeed detection. In some applications, such as driverless trains in public transit systems, the carborne ATP may also control propulsion, heading, opening doors, and emergency braking <ref> [8] </ref>. <p> These requirements are comparable to the requirements for other transit applications, including commercial avionics systems. A system MTBHE of 10 5 years translates to a one in 10,000 probability of unsafe failure in the first ten years of operation, assuming a constant failure rate <ref> [8] </ref>, [12]. System reliability is a measure of the probability that the system will operate correctly over some time interval. <p> The MTBF, for example, is the sum of MTTR and MTTF [10]. Table 2.1 gives some examples of numerical reliability and maintainability requirements appropriate for ATC applications. Table 2.1 Quantitative Reliability and Maintainability Requirements ATP System Metric Specification (hours), <ref> [8] </ref> Carborne MTBSF 3,500 (9,000 for multiple vehicles) MTBF 2,000 MTTR 1 Wayside MTBSF 38,000 MTBF 1,000 MTTR 1 15 Availability measures the amount of time the system is available to perform its functions correctly.
Reference: [9] <author> H. Kirrmann, </author> <title> Train Control Systems, </title> <journal> IEEE Micro, </journal> <volume> Vol. 10 , No. 4, </volume> <month> August </month> <year> 1990, </year> <pages> pp. 79 80. </pages>
Reference-contexts: Each train must maintain its own position and convey this information to other trains. Rather than concerning itself with segments of track, the train considers intertrain spacing and actual stopping distance through what is called a braking parabola <ref> [9] </ref>. A train inertial position system (TIPS) senses such parameters as velocity and acceleration, and with a known starting position, determines train positions. In addition, beacons along the railway provide trains with absolute reference information so that they may correct any errors [6].
Reference: [10] <author> B.W. Johnson, </author> <title> Design and Analysis of Fault-Tolerant Digital Systems, </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: Flexibility of the design and transparency of fault-tolerance techniques to the end-user are examples of common qualitative measures. Quantitative evaluation techniques provide specific numbers that may be used to compare designs. Common quantitative measures are dependability metrics such as reliability, maintainability, and availability <ref> [10] </ref>. 2.2.1 Safety in Automatic Train Control Systems The definition of system safety is the probability that the system will either behave correctly or fail in a safe manner [10]. The definition of safe failure, however, varies widely in safety-critical applications. <p> Common quantitative measures are dependability metrics such as reliability, maintainability, and availability <ref> [10] </ref>. 2.2.1 Safety in Automatic Train Control Systems The definition of system safety is the probability that the system will either behave correctly or fail in a safe manner [10]. The definition of safe failure, however, varies widely in safety-critical applications. Even in the railway application, what is called a safe failure depends on the portion of the ATC system being discussed. Defining safety also requires consideration of the consequences of various failures. <p> In using COTS hardware, however, the issue of qualified components must also be considered. Qualified hardware in the aircraft industry, for example, is five to ten year-old technology to ensure the removal of design aws and to prove the hardware has a proven reliability and safety record <ref> [10] </ref>. Users of a system typically do not wish to be concerned with the techniques used to achieve fault-tolerance. Transparency of such techniques as information or hardware 13 redundancy is important to make the system convenient to the end-user. <p> Transparency of such techniques as information or hardware 13 redundancy is important to make the system convenient to the end-user. If the users application or programming is affected by redundancy techniques, then inclusion of fault-tolerance is a burden <ref> [10] </ref>. Other desirable properties of the system are resilience to harsh environments and cost-effectiveness. Railway controllers are often exposed to strong electromagnetic fields, noise, vibration, extreme temperatures, and lightning. The system should be designed with consideration of these effects. <p> More precisely, it is defined as the conditional probability 14 that a system will perform correctly over time interval [t 0 , t], given that it was performing correctly at time t 0 <ref> [10] </ref>. The primary reliability measurements used in train applications are mean time between failures (MTBF) and mean time between service failures (MTBSF). The difference between these two is that MTBSF relates to a failure causing disruption of ATC service while MTBF relates simply to any failure requiring repair. <p> The primary measure of maintainability is mean time to repair (MTTR). The MTTR is used with MTTF or MTTSF to calculate time between failures. The MTBF, for example, is the sum of MTTR and MTTF <ref> [10] </ref>. Table 2.1 gives some examples of numerical reliability and maintainability requirements appropriate for ATC applications. <p> It is defined as the probability that a system is operating correctly at some instance of time, t. Steady state availability is generally calculated by taking the ratio of MTTF to MTBF <ref> [10] </ref>. Availability requirements for railway applications are between 99.99% and 99.999% which translates roughly to about 10 to 30 minutes of downtime per year [6]. Aside from the dependability metrics mentioned above, the Next Generation Architecture must meet demanding performance-related requirements. <p> One measure of the systems ability to meet its performance goals is performability, defined as the probability that the system is performing at, or above, some level L at time t <ref> [10] </ref>. 2.3 Chapter Summary This chapter presented the different functions expected in a computer-based ATC system. They are partitioned into the wayside ATP, responsible primarily for switch and signal interlocking control, and the carborne ATP, responsible for such functions as over-speed assurance and emergency braking. <p> They claim that physical replication of hardware modules provides only moderate gains in reliability. This is because the effectiveness of hardware redundancy depends on the nature of faults in the system. Faults generally have four different causes which include the following <ref> [10] </ref>: specification mistakes which might include incorrect algorithms or hardware and software specifications implementation mistakes due to poor design, poor component selection, or software coding errors component defects including random device defects, manufacturing imperfec tions, and component wear-out external disturbances such as radiation, electromagnetic interference, or envi ronmental extremes While hardware <p> This process is shown in Equation 6.2 <ref> [10] </ref>. (6.2) In Equation 6.2 u (X) is the message polynomial and v (x) is the resulting codeword polynomial. Modulo-2 addition is employed from the third to the last step of the procedure and the codeword polynomial may be represented by the binary vector shown. <p> The resulting code polynomial is v (X) = X n-k u (X) + rm (X). The steps to show the validity of this proce dure are given in Equation 6.3 <ref> [10] </ref>. (6.3) 3 v X ( ) u X ( ) g X ( ) 1 X X + + 1 X X + + = = 3 2 4 3 4 6 1 X X 1010001 ( )=+ += n k g x ( ) rm X ( ) -+= <p> A common approach is the use of a linear feedback shift register comprised of memory elements and modulo-2 adders (exclusive-OR gates). This requires that each bit of the message be shifted in one at a time in a sequential fashion <ref> [10] </ref>. An alternative approach uses an array of modulo-2 adders to perform matrix operations that are equivalent to the polynomial operations described here. This method is described later in this chapter. <p> In a Berger check scheme, the j checkbits represent the complement of the number of ones in the information word. The value of j is determined by (6.4) where k is the number of information bits <ref> [10] </ref>. An alternate way to compute the Berger check symbol is to use the binary representation of the result when the number of ones is subtracted from k. <p> The general definition of fault coverage is the systems ability to detect, locate, contain, and recover from faults that occur in the system. The fault coverage is sometimes broken down into separate values for fault detection coverage, fault location coverage, fault containment coverage, and fault recovery coverage <ref> [10] </ref>. In this discussion, however, fault coverage refers to fault detection coverage which simply measures the ability of a system to detect faults. Since the prototype safety assurance scheme is developed based on protection of information used by the control algorithm, it is more appropriate, however, to discuss error coverage. <p> Repair is not modeled here so once the system enters a failed state it remains there with probability 1. This Markov model may be converted to a continuous-time model and solved with Laplace transforms to produce (7.1) where S (t) is the safety of the system at time t <ref> [10] </ref>. The (1 - C) term may also be thought of as the probability of undetected error, or the fraction of errors not detected by the system. A safety model may be constructed with a Markov model having operational, failed safe, and failed unsafe states. <p> Estimates for the failure rate are commonly available in the United States Department of Defense MIL-HDBK-217 standard. This handbook provides a model for the failure rates for electronic components through experimental data collected via failure analysis <ref> [10] </ref>. Several methods of analysis are recognized and accepted as means of proving the safety of an ATC system [11]. Each has its own limitation as far as applicability and level of completeness in regard to microprocessor-based systems. <p> Furthermore it is assumed 122 that the modules functionality remains unchanged (an AND gate still performs the correct operation) and that the faults are permanent <ref> [10] </ref>. Other fault models exist which account for stuck-open faults due to broken lines or transistor stuck-at faults which descend to a lower level of abstraction. The logical stuck-at model is adopted for this work due to its simplicity and relative effectiveness.
Reference: [11] <institution> Safety System Validation with Regard to Cross-Acceptance of Signalling Systems by the Railways, </institution> <note> Report No. 1, Institution of Railway Signal Engineers, International Tech nical Committee, January 14, </note> <year> 1992. </year>
Reference-contexts: Furthermore, stopping trains on any failure is a severe detriment to the reliability and availability of the system <ref> [11] </ref>. Depending on the application technology, stopping trains in the carborne ATP may or may not be an acceptable fail-safe response. In non-magnetic applications, stopping the ATP system and the trains may handle most failures. <p> Since it is generally impractical to analyze all of the failure modes in digital hardware, use of Class II hardware requires an analysis of the probability that its failure will produce an unsafe effect <ref> [11] </ref>. Class III hardware is defined as hardware used only for non-vital functions. Class III hardware does not affect safe implementation of vital functions [12]. Software used in processor-based ATC systems is also classified into vital and non-vital portions. Vital software is software required to implement some vital function. <p> The railway industry, in recognition of this impracticality, does not require a complete fault characterization of digital ATC systems; instead it requires a valid and comprehensive analysis of the system that assigns a probability of safe operation to the overall system <ref> [11] </ref>. 2.2.2 Qualitative Requirements Although safety is the guiding principle in the design of ATC systems, other qualitative features are desirable to meet system goals. An important feature of the Next Generation Architecture is a modular, building block approach. <p> This handbook provides a model for the failure rates for electronic components through experimental data collected via failure analysis [10]. Several methods of analysis are recognized and accepted as means of proving the safety of an ATC system <ref> [11] </ref>. Each has its own limitation as far as applicability and level of completeness in regard to microprocessor-based systems. The first of these is the failure modes, effect and criticality analysis (FMECA). <p> In the case of combinations of failures leading to unsafe conditions, it must be shown that the first failure is detected early enough to negate the effect of the second assuming they do not occur simultaneously <ref> [11] </ref>. The obvious problem is the enumeration of all of the failure modes in a complex digital design. This is generally considered an unbounded problem where a microprocessor is concerned. <p> The intermediate events form the nodes of the fault tree. Combinations of intermediate events are combined logically with AND and OR operations. This requires consideration of combination faults, similar to the FMECA <ref> [11] </ref>. Coverage is estimated by assigning a probability to the unsafe top events by combining the probability of intermediate events leading to the top event. Fault trees also rely on the ability to identify and enumerate all unsafe conditions in the system.
Reference: [12] <author> D.B. Rutherford, </author> <title> What Do You Mean -- Its Fail-Safe? Part II, 1990 Rapid Transit Con ference, </title> <publisher> American Public Transit Association, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: The FMEA method is a pass/fail classification; the circuit under test either meets FMEA requirements or it does not. Examples of Class I hardware include vital current threshold detectors, vital signaling relays, and four-terminal capacitors <ref> [12] </ref>. Class II hardware is described as non-vital hardware used to perform vital functions. This includes elements of a computer platform such as the microprocessor, memory, and address decoding logic. <p> This includes elements of a computer platform such as the microprocessor, memory, and address decoding logic. Failures of Class II hardware might compromise system safety, but such hardware is generally not analyzable to the extent of Class I hardware <ref> [12] </ref>. The faults leading to failures in integrated digital circuits may be innumerable and 11 impossible to analyze. <p> Class III hardware is defined as hardware used only for non-vital functions. Class III hardware does not affect safe implementation of vital functions <ref> [12] </ref>. Software used in processor-based ATC systems is also classified into vital and non-vital portions. Vital software is software required to implement some vital function. Non-vital software has no effect on vital functions under normal operation. <p> These requirements are comparable to the requirements for other transit applications, including commercial avionics systems. A system MTBHE of 10 5 years translates to a one in 10,000 probability of unsafe failure in the first ten years of operation, assuming a constant failure rate [8], <ref> [12] </ref>. System reliability is a measure of the probability that the system will operate correctly over some time interval.
Reference: [13] <author> R.W. Butler and G.B. Finelli, </author> <title> The Infeasibility of Quantifying the Reliability of Life Critical Real-Time Software, </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> vol. 19, No. 1, </volume> <month> January </month> <year> 1993, </year> <pages> pp. 3-12. </pages>
Reference-contexts: Demonstration of absolute software correctness for non-trivial programs is considered a practical impossibility. Vital software, therefore, must be shown to achieve an acceptably low probability of error causing an unsafe failure. Even this task is considered formidable and indeed infeasible by some members of the software engineering community <ref> [13] </ref>. It is a well established fact that hardware and software systems invariably fail. Unfortunately, it is often impossible to characterize all of the faults that cause these failures. <p> Eradicating a complex software system of all bugs is virtually impossible and it is also extremely difficult to quantify the probability that software is error-free <ref> [13] </ref>. In a microprocessor-based system, however, software is unavoidable.
Reference: [14] <author> J.H. Lala, R.E. Harper, </author> <title> and L.S. Alger, A Design Approach for Ultrareliable Real-Time Systems, </title> <journal> IEEE Computer, </journal> <volume> Vol. 24, No. 5, </volume> <month> May </month> <year> 1991, </year> <pages> pp. 12-22. 142 </pages>
Reference-contexts: CSDL defines an FCR (or channel) to include a processor and its associated memory, 18 input and output interfaces, and interface to other channels. Enforcing the FCR requirements allows the argument that random hardware failures in FCRs are independent events, which make the analysis of failure probability feasible <ref> [14] </ref>. FCRs may be able to contain faults but the data errors that occur as a result of a fault can propagate outside the region. To protect against this CSDL proposes the method of voting planes throughout the system to mask errors between stages. <p> The problem with thresholds, however, is that they are a function of the process and may change during operation. In addition, accurate calculation of fault-coverage for a given threshold is extremely difficult. Exact consensus, in contrast, allows application of formal methods and analytical validation <ref> [14] </ref>. <p> They have applied this philosophy to the design of a fault-tolerant computing platform for aerospace applications, called the Advanced Information Processing System (AIPS) <ref> [14] </ref>. While the CSDL philosophy provides a good example of a well-defined approach to designing ultrareliable systems it does not address some important issues. The redundancy management services in the architecture, for example, are provided by software building blocks.
Reference: [15] <author> L. Lamport, R. Shostak, and M. Pease, </author> <title> The Byzantine Generals Problem, </title> <journal> ACM Trans actions on Programming Languages and Systems, </journal> <volume> Vol. 4, No. 3, </volume> <month> July </month> <year> 1982, </year> <pages> pp. 382 401. </pages>
Reference-contexts: Input congruency is necessary for exact consensus while input validity is necessary for correct outputs. The conditions for input congruency are identified in a theory called the Byzantine Generals problem. This theory, first developed by Lamport, Shostak, and Pease <ref> [15] </ref>, applies to redundant computer systems in which faulty components may provide conict-ing data to other elements of the system. <p> The traitors correspond to faulty processors while the loyal generals correspond to non-faulty processors. Messengers are communications links between processors. Byzantine fault resilience is achieved in the presence of f arbitrary faults by meeting the following conditions <ref> [15] </ref>: system has a minimum of 3f + 1 FCRs FCRs are interconnected through 2f + 1 disjoint paths inputs are exchanged between FCRs f + 1 times FCRs are synchronized to provide a bounded time skew Thus, a system that can tolerate one arbitrary fault must have four cross-strapped FCRs
Reference: [16] <author> D.A. Rennels, A. Avizienis, and M., </author> <title> A Study of Standard Building Blocks for the Design of Fault-Tolerant Distributed Computer Systems, </title> <booktitle> Proceedings of Eighth International Symposium on Fault-Tolerant Computing, </booktitle> <address> Toulouse, France, </address> <month> June </month> <year> 1978, </year> <pages> pp. 144-149. </pages>
Reference-contexts: The idea of using standard building blocks to construct fault-tolerant systems is certainly not new. Rennels et. al. introduce a set of four building blocks that can be used with off-the-shelf hardware including processors and memories <ref> [16] </ref>. The memory interface (MI-BB), bus interface (BI-BB), input and output (IO-BB), and core (C-BB) circuits comprise the four basic building blocks. The basic architectural unit is the self-checking computer module (SCCM) which is able to detect internal faults concurrently during normal operation. <p> The building block approach allows a system designer to adjust the level of redundancy to suit the criticality of the application. In addition, this particular approach has the advantage of allowing the use of field-tested off-the-shelf processors and software <ref> [16] </ref>. MAFT (Multicomputer Architecture for Fault-Tolerance) is an example which was designed with the goals of high performance and reliability by logically and physically partitioning the system overhead tasks and the applications tasks.
Reference: [17] <author> C.J. Walter, R.M. Kieckhafer, and R.M. Finn, MAFT: </author> <title> A Multicomputer Architecture for Fault-Tolerance in Real-Time Control Systems, </title> <booktitle> IEEE Real-Time Systems Sympo sium, </booktitle> <month> December </month> <year> 1985, </year> <pages> pp. 133-140. </pages>
Reference-contexts: The system achieves fault-tolerance by assuring that system functions are observable, globally verified, self 31 testable, and employ Byzantine agreement among critical parameters <ref> [17] </ref>. The computer system must meet the typical ight control requirement of a 10 -10 failure probability over a ten hour mission. In addition, the system designers had to handle errors in both hardware and software, or prove that the hardware and software were free of any design errors. <p> The system is highly exible, allowing N-way voting and task replication with distributed synchronization and Byzantine agreement algorithms. Finally, the system supports graceful restoration and degradation and global enabling and disabling of tasks to facilitate distributed processing <ref> [17] </ref>. The Software Implemented Fault Tolerance (SIFT) system uses programs rather than hardware to achieve its goal of probability of failure less then 10 -9 per hour for a ten hour ight mission. <p> The primary disadvantage of SIFT is that much of the systems processing power is consumed by the overhead involved in task scheduling and fault-tolerance functions. This leaves significantly less processing capability for use by the application program <ref> [17] </ref>. Another example of a fault-tolerant control system for critical aerospace applica tions is FTMP (Fault-Tolerant Multiprocessor) which was designed for a failure rate of 10 - failures per hour on a ten-hour ight mission.
Reference: [18] <editor> J.H. Wensley, et. al., SIFT: </editor> <title> Design and Analysis of a Fault-Tolerant Computer for Air craft Control, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 66, No. 10, </volume> <month> October </month> <year> 1978, </year> <pages> pp. 1240 1255. </pages>
Reference-contexts: Another important concept employed in SIFT is the disregard for low-level faults. Only the resulting data corruption or errors are of interest. The primary feature, however, is that all error detection and correction, diagnosis, reconfiguration, and isolation is performed by software routines <ref> [18] </ref>. Computations in SIFT are performed by main processing modules which consist of a processor and its associated memory. Input and output functions are carried out by special input and output processors and their associated memories. <p> SIFTs primary advantage is that it allows the use of off-the-shelf hardware in the processor modules. In addition, any change to the application or to the fault-tolerance techniques is easy to implement because only a software change is required <ref> [18] </ref>. The primary disadvantage of SIFT is that much of the systems processing power is consumed by the overhead involved in task scheduling and fault-tolerance functions. This leaves significantly less processing capability for use by the application program [17].
Reference: [19] <author> A.L. Hopkins, T.B. Smith, and J.H. Lala, </author> <title> FTMP - A Highly Reliable Fault-Tolerant Mul tiprocessor for Aircraft, </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> Vol. 66, No. 10, </volume> <month> October </month> <year> 1978, </year> <pages> pp. 1221-1239. </pages>
Reference-contexts: The FTMP conducts all information processing and transmission in triplicate so that voters in each separate node can correct errors. In addition, each node, or module, may be reassigned or retired in any combination <ref> [19] </ref>. The overall structure of FTMP consists of an arbitrary number of these modules which include processors with local cache memories connected to any number of memory modules via a triply redundant serial bus. The processor and memory modules are placed in groups of three to perform redundant functions.
Reference: [20] <author> T. Markas and N. Kanopoulos, </author> <title> A Bus-Monitor Unit for Fault-Tolerant System Configu rations, </title> <booktitle> Microprocessing and Microprogamming 30, </booktitle> <year> 1990, </year> <pages> pp. 521-528. </pages>
Reference-contexts: It is claimed that the implementation cost of the bus monitor is significantly lower than for other systems while still retaining high reliability <ref> [20] </ref>. The bus monitor is intended primarily for use in standard processor-memory configurations where most faults are assumed to manifest themselves as errors on the address bus, data bus, or a memory-related control line. <p> The DCVS signals are also collected and evaluated by a bus monitor error detection unit. If the bus monitor has a fault, a failure handler may disconnect the monitor and instruct a standby unit to take over <ref> [20] </ref>. The primary advantage of the bus monitor is that it is a single simple unit that can function as a redundancy manager to detect, isolate, and recover from faults. The relative simplicity of the design makes it feasible for a single chip solution, thus driving the costs down.
Reference: [21] <author> D.B. Rutherford, </author> <title> Fail-Safe Microprocessor Interlocking -- An Application of Numeri cally Integrated Safety Assurance Logic, </title> <booktitle> Proceedings of Institution of Railway Sig nal Engineers, </booktitle> <address> London, </address> <month> September </month> <year> 1983. </year>
Reference-contexts: Rutherford. The techniques used in the system appear in the General Railway Signal Companys Vital Processor Interlocking (VPI). As with the MICROLOK system, the VPI is based around a general purpose Boolean processor. It vitally evaluates logic expressions by encoding and checking the terms of each expression <ref> [21] </ref>. Solid-state circuits are used to vitally sense input states and set output states which control switches, signals, relays, and line circuits. <p> The philosophy of the VPI system is called numerically integrated safety assurance logic (NISAL). The codewords are not generated in parallel with data processing; they are integrated directly into the data itself so that any data corruption will affect the codeword <ref> [21] </ref>. A fail-safe microprocessor-based system based on partitioning and diverse redundancy is currently in use in a station near Nanjing, China. The system consists of a basic interlocking system and a separate safety assurance system, implemented diversely. <p> Some would argue that information used by the control algorithm, if encoded, is protected in digital hardware with this probability (assuming vital hardware is used at input and output interfaces) <ref> [21] </ref>. Although this is extremely convenient, it requires some assumptions about the nature of errors arising in the system.
Reference: [22] <author> Y. Min, Y. Zhou, Z. Li, and C. Ye, </author> <title> A Fail-Safe Microprocessor-Based System for Inter locking on Railways, </title> <booktitle> Proceedings of the Annual Reliability and Maintainability Sym posium, </booktitle> <year> 1994, </year> <pages> pp. 415-420. </pages>
Reference-contexts: Fault tree analysis is used to analyze the fail-safety which is evaluated at a behavioral level for 30 critical conditions. The system is also equipped to deliver a variety of error reports and logs to provide maintainability <ref> [22] </ref>. The basic philosophy of the system is the separation of the interlocking system and safety assurance system. The designers claim that such a partitioning allows a exible configuration and gains four orders of magnitude in safety for this system. <p> From this analysis, the designers claim a safety improvement of four orders of magnitude by using the separate SAS <ref> [22] </ref>. Although the designers make many assumptions in analyzing the system, it has operated continuously for over 61,000 hours without any failure or switchover to a cold standby BIS.
Reference: [23] <author> V. Chandra and M.R. Verma, </author> <title> A Fail-Safe Interlocking System for Railways, </title> <journal> IEEE Design &Test of Computers, </journal> <volume> Vol. 8, </volume> <month> March </month> <year> 1991, </year> <pages> pp. 58-66. </pages>
Reference-contexts: The FIRM architecture, developed for use on Indian Railways, implements only those functions critical to system safety at a high safety standard. Routine functions which do not affect the safety are not designed to the same safety standard <ref> [23] </ref>. The basic FIRM architecture consists of a pair of processing modules operating in a duplex mode with one or more pairs standing by. A sequence controller module (SQC) supplies power to the active pair of processors as long as no fault is detected. <p> The module ID is a hardwired value that the processor accesses during its self-check to ensure that it is connected to the global bus and that its addressing circuitry is functional. The data-loop-test verifies the health of the data bus. Finally, the module circuit performs the appropriate function <ref> [23] </ref>. 49 The FIRM architecture employs a design approach which identifies different levels of safety for each function of the system. The implementation technique used to carry out each function then depends on its assigned safety level.
Reference: [24] <author> A. K. Ghosh, et. al., </author> <title> A Distributed Safety-Critical System for Real-Time Train Control, </title> <type> pre-publication draft, </type> <institution> Center for Semicustom Integrated Systems, University of Vir ginia, </institution> <month> July </month> <year> 1994. </year>
Reference-contexts: Input modules sense vital field data such as switch position or track occupancy and 52 deliver it to the processors either locally or over the serial network. Output modules receive vital control outputs from the processors and set actuators or signals to their calculated states <ref> [24] </ref>. The architecture provides the capability for multiprocessing over the parallel bus by forming a node with multiple processors in the same card cage. <p> Each of the nodes is analogous to a fault containment region. The voting clusters themselves may be arranged as simplex, duplex, or N-modular redundant configurations depending on the degree of fault-tolerance required [6], <ref> [24] </ref>. 4.2 Communications Facilities in a Distributed ATC System The high-speed serial network plays an important role in the system, both in meeting the performance requirements and in providing fault-tolerance characteristics. <p> The input and output modules are geographically distributed along the network and generally will outnumber the required wayside ATP processing sites. Wireless transmission through gateways allows the carborne ATP systems to communicate data such as velocity or identification to the wayside units [6], <ref> [24] </ref>. 4.3 Safety-Critical Software Executive As discussed in Section 3.1, the use of software in a safety critical systems is problematic. Eradicating a complex software system of all bugs is virtually impossible and it is also extremely difficult to quantify the probability that software is error-free [13]. <p> Any software system imposes certain guidelines on the hardware on which it is executed. The design constraints on the system must be adhered to for the software to function properly. Some design constraints on the Next Generation Architecture are listed below <ref> [24] </ref>, [26]: hardware interrupts other than a single clock signal are disallowed no suspendible or preemptible tasks are allowed except diagnostics error handling is the only permitted software-based exception use of a frame-based system scheduling paradigm static resource allocation use of a safe Ada subset The operation of the software executive <p> If the processor is constrained to operate in this predetermined manner, it is possible for the algorithm checker to ensure that correct, uncorrupted operands were used at the correct times and that calculations were made without error <ref> [24] </ref>. The safety assurance method adopts a code-based approach for detecting errors that arise in all portions of the system, including input modules, communications channels, processing elements, and output modules. <p> If the checker is implemented in semicustom circuits this assumption has more merit than the case where another processor serves as the checker. Since the processors are executing completely different algorithms, however, the probability of near-coincident failure is considered remote <ref> [24] </ref>. 4.5 Chapter Summary This chapter has presented an overview of the Next Generation Architecture developed to meet the requirements for the ATC application described in Chapter 2.
Reference: [25] <author> S. Heath, </author> <title> Multiprocessing with VMEbus, </title> <journal> Electronics & Wireless World, </journal> <volume> Vol. 93, </volume> <month> November </month> <year> 1987, </year> <pages> pp. 1106-1109. </pages>
Reference-contexts: These processors may use functions such as atomic test-and-set operations in conjunction with read-modify-write bus cycles to provide a message passing system so that processors working on the same task may communicate <ref> [25] </ref>. If hardware redundancy is desired for high reliability applications, processors and nodes may be configured as voting clusters. One processor from each of three nodes, for example, would form a triple modular redundant (TMR) system.
Reference: [26] <author> D.T. Lamb, </author> <title> A Dependable Computing Platform: A Software Executive for Real-Time Safety-Critical Control, M.S.E.E. </title> <type> Thesis, </type> <institution> University of Virginia, Charlottesville, Vir ginia, </institution> <month> May </month> <year> 1994. </year>
Reference-contexts: The overriding design goal in developing the executive, therefore, is simplicity. In addition to being easier to develop, simple systems facilitate performance of some sort of validation. General requirements for the software executive in the Next Generation Architecture include the following <ref> [26] </ref>: execution of all tasks in a safe and deterministic fashion communication with input and output modules to read sensor values and deliver actuator outputs management and mediation of resource allocation where exclusive access is required scheduling and handling of system diagnostic tasks distribution of tasks among possibly heterogeneous processors and <p> The standards promote predictable compiler behavior and consistency and Ada is the only 56 language whose conformity to standards is monitored and approved. Finally, mature, validated compilers are available for Ada from several commercial vendors <ref> [26] </ref>. Despite its suitability for real-time safety-critical systems, the use of Ada alone does not guarantee correct operation. Any software system imposes certain guidelines on the hardware on which it is executed. The design constraints on the system must be adhered to for the software to function properly. <p> Any software system imposes certain guidelines on the hardware on which it is executed. The design constraints on the system must be adhered to for the software to function properly. Some design constraints on the Next Generation Architecture are listed below [24], <ref> [26] </ref>: hardware interrupts other than a single clock signal are disallowed no suspendible or preemptible tasks are allowed except diagnostics error handling is the only permitted software-based exception use of a frame-based system scheduling paradigm static resource allocation use of a safe Ada subset The operation of the software executive follows <p> The executive activates system tasks including output writing, input polling, and control equation execution, at fixed, periodic time intervals. It is designed around a frame-based timing specification where a system cycle is considered a major frame which is in turn made up of several minor frames <ref> [26] </ref>. Minor frames correspond to input-output cycles, the basic unit of system processing around which the executive is designed. All outputs are delivered to output modules at the beginning of a minor frame. <p> Task P4 may consist of non-critical diagnostic routines that are variable in length. These are the only tasks that may be interrupted <ref> [26] </ref>. more or less than the four minor frames shown. Also the number of tasks executed during each minor frame will vary with the ATC application. The main idea is that the major frame, or system cycle, is the repetitive execution of a set of tasks. <p> The main idea is that the major frame, or system cycle, is the repetitive execution of a set of tasks. A minor frame, or input and output cycle, is the writing of outputs, reading of inputs, and evaluation the control algorithm <ref> [26] </ref>. 4.4 Global Safety Assurance Concepts The term global safety assurance refers to a complete input-to-output check of the ATC system in which all aspects of the system are considered. <p> The workstation serves as the development platform for all programs including the safety-critical real-time executive, watchdog checker emulator, and input and output module emulator. Software development for the executive is done on the workstation using a vali 91 dated Ada compiler and run-time system from Tartan, Incorporated <ref> [26] </ref>. The watchdog and input and output emulators are programmed using a 68000 processor family cross-development C compiler from Sierra Systems. Evaluation of the prototype is achieved through data collected on the host workstation. <p> It essentially serves as the engine for the overall control system. The basic frame-based timing specification is implemented with each task executed at a fixed, predetermined frequency. In addition, the executive is implemented in Ada using such guidelines as static memory allocation and static distribution of tasks <ref> [26] </ref>. <p> The prototype executive uses its on-board real-time clock to assure that all tasks are completed in their allotted time. If all tasks are not finished by the time the executive receives the next timing interrupt from the processor PCB, the executive indicates that a frame overrun has occurred <ref> [26] </ref>. In an actual system a violation of the static cycle would indicate failure to meet the real-time deadline and would result in a safe shutdown. <p> The distributed processing tasks handle communication of input and output codewords over the FDDI network and will be included in the next version of the executive. Also diagnostic and other non-critical tasks have not yet been identified for inclusion in the executive <ref> [26] </ref>. 6.2.4 Software Emulation of the Watchdog Checker The watchdog checker is intended to be a dedicated hardware unit that concurrently checks the execution of the executive processor after each operation it performs. <p> Despite this fact, it is assumed that an actual hardware input or output module would perform much better. Neither of these modules are intended to be implemented in software on a processor. They Table 8.1 Timing Data for Estimating Prototype Performance Minor Frame Task Performance application equation evaluation <ref> [26] </ref> 170 ms results array generation [26] 60 ms watchdog checker processing [34] 690 ms input module encoding 29 ms output module decoding and checking 29 ms plant input and output transfer &gt; 30 ms (variable) overall frame rate 1 s 137 will most likely appear on separate PCBs that include <p> Neither of these modules are intended to be implemented in software on a processor. They Table 8.1 Timing Data for Estimating Prototype Performance Minor Frame Task Performance application equation evaluation <ref> [26] </ref> 170 ms results array generation [26] 60 ms watchdog checker processing [34] 690 ms input module encoding 29 ms output module decoding and checking 29 ms plant input and output transfer &gt; 30 ms (variable) overall frame rate 1 s 137 will most likely appear on separate PCBs that include vital interfacing and possibly encoding circuits.
Reference: [27] <author> P.J. Perrone and B.W. Johnson, </author> <title> System Level Error Modeling for Information Systems, </title> <type> Technical Report 931101.0, </type> <institution> Center for Semicuston Integrated Systems, University of Virginia, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: The code-based approach is chosen to facilitate analysis of the probability of undetected errors, which is very important to quantifying the safety of the system. Different types of information are encoded with data to allow checking of six general classes of errors, including <ref> [27] </ref>: noisy data symbol errors, including random, burst, and unidirectional errors data symbol reference errors in which the incorrect operand is referenced and used in an operation instruction control symbol selection errors where the incorrect operation is specified data symbol manipulation errors where an operation is performed incorrectly excessive timing error <p> The design of this circuit is not presented in this thesis. The decision on which checks are necessary is based on the adopted error model <ref> [27] </ref>. <p> As discussed in Section 4.4, the watchdog is responsible for checking codeword validity, data identification, and timestamp information to detect errors in classes dictated by a given error model <ref> [27] </ref>. The prototype version of the architecture implements the watchdog in software using the C language. The primary reasons for developing a software emulator were that it could be done far more rapidly than a hardware module and that a software program is much more easily modified, if necessary.
Reference: [28] <editor> D.C. Coll, et. al., </editor> <title> The Communications System Architecture of the North American Advanced Train Control System, </title> <journal> IEEE Transactions on Vehicular Technology, </journal> <volume> Vol. 39, No. 3, </volume> <month> August </month> <year> 1990, </year> <pages> pp. 244-255. 143 </pages>
Reference-contexts: The input module senses data that the processing elements use to execute the control algorithm. In the wayside ATP system some examples of the data sensed are [7], <ref> [28] </ref>, [29]: track circuit occupancy 65 switch point contacts or switch states signal relay contacts or signal states signal lamp filament integrity track integrity highway grade crossing warning states high water, high wind, and rock slide warning signal states temperature defect indicators including high or wide load, dragging equipment, hot wheels, <p> Input modules in the carborne ATP generally require more advanced sensor interfaces than in the wayside ATP. Some typical data in forthcoming carborne ATP applications such as the North American Advanced Train Control System (ATCS) are <ref> [28] </ref>: train speed throttle position brake settings acceleration train position locomotive health As trains progress the carborne ATP must determine train location using axle-mounted odometers and checks using data obtained from transponders buried in the roadbed. <p> The 66 control algorithm uses speed and location data to calculate appropriate limits on speed, acceleration, and other location-dependent restrictions <ref> [28] </ref>. Here the input modules must be designed to interface with data that is not expressed as simple logic-1 or logic-0 values. Maglev trains require still more sophisticated sensors where, again, data must pass through A/D converters. <p> In addition, the set of outputs is often partitioned into a vital and non-vital set. Signals controlling railway switches or braking, for example, are considered vital, while some panel indications may be non-vital. In the wayside ATP output signals may include [7], <ref> [28] </ref>: signal mechanism drive signal lamp drive switch control traffic and track circuit control bridge control on movable bridges railway grade crossings highway grade crossing warning controls switch heaters for melting snow Wayside control outputs are as varied as sensor inputs.
Reference: [29] <author> R.G. Ayers, </author> <title> Selection of a Forward Error Correcting Code for the Data Communication Radio Link of the Advanced Train Control System, </title> <journal> IEEE Transactions on Vehicular Technology, </journal> <volume> Vol. 38, No. 4, </volume> <month> November </month> <year> 1989, </year> <pages> pp. 247-254. </pages>
Reference-contexts: The input module senses data that the processing elements use to execute the control algorithm. In the wayside ATP system some examples of the data sensed are [7], [28], <ref> [29] </ref>: track circuit occupancy 65 switch point contacts or switch states signal relay contacts or signal states signal lamp filament integrity track integrity highway grade crossing warning states high water, high wind, and rock slide warning signal states temperature defect indicators including high or wide load, dragging equipment, hot wheels, broken
Reference: [30] <author> I. Boldea, et. al., </author> <title> Field Tests on a MAGLEV with Passive Guideway Linear Inductor Motor Transportation System, </title> <journal> IEEE Transactions on Vehicular Technolgy, </journal> <volume> Vol. 37, No. 4, </volume> <month> November </month> <year> 1988, </year> <pages> pp. 213-219. </pages>
Reference-contexts: Maglev trains require still more sophisticated sensors where, again, data must pass through A/D converters. Examples of measured quantities in the levitation system of a linear induction motor system are <ref> [30] </ref>: relative airgap using an air-core coil vertical absolute acceleration using an inertial device attached to the frame of the vehicle motor airgap ux derivative In addition to sensing field data, input modules are also often required to interface with other similar units, perhaps over a serial cable. <p> Future applications, however, include driverless trains in which the carborne ATP is required to control all aspects of the system including speed and acceleration, routine and emergency braking, and perhaps door and lighting control. Maglev applications require the output module to control and correct levitation and propulsion circuits <ref> [30] </ref>. 5.2.2 Output Module Safety Assurance Functions As with the input module, the output module is crucial to providing the safety for which the system is designed. Any global assurance scheme depends to some extent on output modules to serve as a final barrier to the delivery of unsafe outputs.
Reference: [31] <editor> Standard Input PCB, sheet 88A, </editor> <title> drawing no. 451441, Standard Circuit Diagrams of Plug In Printed Circuit Boards, Union Switch and Signal, </title> <publisher> Inc. </publisher>
Reference-contexts: The schematic models contain no hierarchy; that is they are not top-down designs. They were developed to resemble as closely as possible the at hard-copy schematics of the circuit boards provided by Union Switch and Signal, Inc. <ref> [31] </ref>, [32]. Although alternate organizations of the schematic model were possible and perhaps preferable, the close resemblance of the model to the hard-copy schematic allowed easy visual validation of the model.
Reference: [32] <editor> Standard Relay Driver PCB, sheet 86B, </editor> <title> drawing no. 451441, Standard Circuit Diagrams of Plug-In Printed Circuit Boards, Union Switch and Signal, </title> <publisher> Inc. </publisher>
Reference-contexts: The schematic models contain no hierarchy; that is they are not top-down designs. They were developed to resemble as closely as possible the at hard-copy schematics of the circuit boards provided by Union Switch and Signal, Inc. [31], <ref> [32] </ref>. Although alternate organizations of the schematic model were possible and perhaps preferable, the close resemblance of the model to the hard-copy schematic allowed easy visual validation of the model.
Reference: [33] <editor> D.J. Mitchell, et. al., </editor> <title> Examination of the MICROLOK Interlocking System, </title> <type> Final Report, </type> <institution> Battelle, Columbus, Ohio, </institution> <month> October 20, </month> <year> 1989. </year>
Reference-contexts: More specifically, there should be no voltage across pins 1 and 2 of optocoupler IC20 if there is no voltage at the input terminals. Another requirement is that the circuit should not prevent other hardware from detecting a permissive condition at the input terminals <ref> [33] </ref>. Although analog vital circuitry is not in the scope of this thesis, it is discussed here as an example of a safety assurance feature found in the input modules of most ATC systems. In safety assurance methods that use voting at the sensors, several configurations are possible. <p> Although a single double failure situation was identified that could cause an undetectable incorrect output, the two failures must occur simultaneously. All other failure combinations are detectable using command feedback along 74 with software diagnostics in this system <ref> [33] </ref>. The safe non-permissive output will vary with the particular output device. For this relay driver, the safe output is a voltage insufficient to drive a relay connected to the output terminals. In a lamp driver circuit, the safe output would be a signal forcing the signal aspect to red.
Reference: [34] <author> P.J. Perrone, </author> <title> Global Safety Assurance: Concepts and Application to Train Control Sys tems, M.S.E.E. </title> <type> Thesis, </type> <institution> University of Virginia, Charlottesville, Virginia, </institution> <note> to be pub lished January 1995. </note>
Reference-contexts: Making these decisions requires consideration of issues such as desired safety level, exibility, ease of implementation, and impact on system performance. The purpose of this section is to briey describe some details of the safety assurance method as implemented for the prototype <ref> [34] </ref>. Recall that information in the system is encoded to protect it against errors arising due to noisy channel effects. The code adopted for this purpose is a member of the family of binary cyclic codes which are linear block codes [34]. <p> the safety assurance method as implemented for the prototype <ref> [34] </ref>. Recall that information in the system is encoded to protect it against errors arising due to noisy channel effects. The code adopted for this purpose is a member of the family of binary cyclic codes which are linear block codes [34]. The discussion here is limited to the binary alphabet but cyclic codes are defined over other alphabets. Binary block encoders take a message of k bits and produce a codeword of n bits. Block codes are generally referred to as (n, k) codes. <p> Both of these codes are separable and are reduced in size through a process called shortening <ref> [34] </ref>. This is done by forcing the leading l message bits to be zero, and then deleting these positions from the systematic-form codewords, reducing both the number of message bits and the overall block length. <p> The watchdog checker uses a slightly modified set of these equations to check that the processor executing the control algorithm is performing all logical operations correctly <ref> [34] </ref>. Since k = 6 for the 32-bit information values, the remaining 10 bits in the 16-bit field reserved for the Berger check symbol are padded with zeros [34]. The last information field is the 7-bit timestamp. <p> a slightly modified set of these equations to check that the processor executing the control algorithm is performing all logical operations correctly <ref> [34] </ref>. Since k = 6 for the 32-bit information values, the remaining 10 bits in the 16-bit field reserved for the Berger check symbol are padded with zeros [34]. The last information field is the 7-bit timestamp. <p> The identification in particular is spread over the eight words so that each machine word associated with a codeword has part of an identification embedded in it <ref> [34] </ref>. 6.2 A Software-Based Prototype for the Next Generation Architecture The first version of the Next Generation Architecture is a single-node embedded wayside ATP system. <p> The watchdog checker emulator behaves as much as possible like a hardware equivalent within the limitation of performance. That is, some concession is made as far as attempting to parallel the hardware operation in order to improve performance <ref> [34] </ref>. It behaves as a passive device in the system except that instead of retrieving results from the executive processor-memory bus, it relies on the executive to deliver a results array each input-output cycle. The results array contains all operand and operation information necessary to perform the checking. <p> The executive keeps a list of error injection records which contain the following information <ref> [34] </ref>: cycle number on which to activate the error (0, 1, 2, or 3) on which of the 8,496 operations to activate the error an error type field which dictates how to corrupt the operand operand field indicating which of the three operands in an equation to corrupt variable name of <p> Neither of these modules are intended to be implemented in software on a processor. They Table 8.1 Timing Data for Estimating Prototype Performance Minor Frame Task Performance application equation evaluation [26] 170 ms results array generation [26] 60 ms watchdog checker processing <ref> [34] </ref> 690 ms input module encoding 29 ms output module decoding and checking 29 ms plant input and output transfer &gt; 30 ms (variable) overall frame rate 1 s 137 will most likely appear on separate PCBs that include vital interfacing and possibly encoding circuits.
Reference: [35] <author> S.G. Wilson, </author> <title> Digital Modulation and Coding, pre-publication manuscript, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1994. </year>
Reference-contexts: This means that if fewer than d min bit errors occur in transmission, the error pattern will be detectable. If d min or greater bit errors occur the error pattern may still be detectable but it is not certain <ref> [35] </ref>. In addition, cyclic codes are able to detect multiple adjacent errors as long as they affect no more than n - k bits. This parameter is called the burst error detection capability of the code. <p> For this application, however, it is sufficient to examine the syndrome to check whether or not it is zero. As with the encoding procedure, the division for decoding may be implemented in a linear feedback shift register <ref> [35] </ref>. There is also the alternative matrix operation that will achieve the same result, as described later in this chapter. The safety assurance method relies heavily on a family of cyclic codes called BCH codes, named for their discoverers Bose, Ray-Chaudhuri, and Hocquenghem. <p> The safety assurance method relies heavily on a family of cyclic codes called BCH codes, named for their discoverers Bose, Ray-Chaudhuri, and Hocquenghem. These codes have several desirable properties that make them popular in many applications. Some of these include <ref> [35] </ref>: availability of many block lengths and code distances recognition as the most powerful moderate block length codes existence of elegant mathematical structure and decoding algorithms The primary codes used in the prototype are the (127, 85) and the (255, 115) BCH codes with d min of 13 and 43 respectively. <p> In essence shortening transforms an (n, k) code into an (n - l, k - l) code. It can be shown that shortening the code does not reduce d min ; in fact with enough shortening, d min will eventu 85 ally increase <ref> [35] </ref>. The (127,85) code is shortened to (97,55) with l = 30 and the (255,115) code is shortened to (159,19) with l = 96. These two codes are referred to as dynamic and static codes in the safety assurance methodology. <p> When a 1 x k message vector is multiplied by G in systematic form, the leading k bits of the resulting codeword are precisely the message and the remaining n - k bits are the parity check bits. An example for a (7,4) code is shown in Equation 6.9 <ref> [35] </ref>. (6.9) Note that the resulting codeword has the data itself in its most significant four bit positions. The result is formed by adding the rows of the generator matrix that correspond to the ones in the message. <p> Equation 6.11 holds true for all valid codewords, v i , in the code set. The relation between a systematic generator matrix and its corresponding parity check matrix is shown in Equation 6.12 <ref> [35] </ref>. (6.12) By constructing the transposed parity check matrix and then applying Equation 6.11 it is possible to check each received codeword. An all-zeros syndrome vector indicates that the received codeword is valid. This process of generating the syndrome involves the same matrix multiplication operation as the encoding.
Reference: [36] <author> J. Lo, S. Thanawastien, and T.R.N. Rao, </author> <title> Concurrent Error Detection in Arithmetic and Logical Operations Using Berger Codes, </title> <booktitle> Proceedings of the Ninth Symposium on Computer Arithmetic, </booktitle> <month> September </month> <year> 1989, </year> <pages> pp. 233-240. </pages>
Reference-contexts: This prediction is made by examining the check bits of the operands and applying prediction rules. Although the wayside application is limited to logical operations, Berger check prediction is applicable to arithmetic operations as well. Prediction rules for the three basic logical operations are <ref> [36] </ref> . (6.5) In this notation X c denotes the Berger check symbol for X and similarly for Y and Z. The watchdog checker uses a slightly modified set of these equations to check that the processor executing the control algorithm is performing all logical operations correctly [34].
Reference: [37] <institution> The VMEbus Specification, published by VMEbus International Trade Association, Scottsdale, Arizona, </institution> <year> 1987. </year>
Reference-contexts: In addition a modules slot position also defines its priority since the bus grant signal is daisy-chained. Interrupts are supported on seven interrupt request lines and the bus may have multiple interrupt handlers so that processors executing different tasks may handle different types of interrupts <ref> [37] </ref>. The primary reasons for choosing the VMEbus standard are its maturity and the wide variety of COTS hardware available. A multitude of COTS processing modules, network interfaces, and development tools currently exist for the VMEbus.
Reference: [38] <author> HK68/V4F Users Manual, </author> <title> Revision C, </title> <institution> Heurikon Corporation, Madison, Wisconsin, </institution> <year> 1991. </year>
Reference-contexts: Its memory facilities include 2 megabytes (MB) of parity-checking RAM, 8 kilobytes (KB) of electrically erasable programmable read-only memory (EEPROM), and space for a 1 MB programmable read-only memory (PROM) chip <ref> [38] </ref>. Interfacing and development is done through a PROM monitor which provides an environment for downloading and executing programs. The PROM monitor communicates via one of the serial interfaces to a host terminal.
Reference: [39] <author> M.J. Conway, et. al., </author> <note> The SUIT Version 2.3 Reference Manual, </note> <institution> Department of Com puter Science, University of Virginia, </institution> <year> 1992. </year>
Reference-contexts: It provides a view of train movement, switch position, and signal aspect throughout the operation of the system. 92 Science <ref> [39] </ref>. The application consists of three trains, represented by colored blocks, trav eling on two track loops 1 .
Reference: [40] <author> ANSI/IEEE Std. </author> <title> 1076-1993 IEEE Standard VHDL Language Reference Manual, </title> <publisher> pub lished by the IEEE, </publisher> <address> New York, New York, </address> <month> June 6, </month> <year> 1994. </year>
Reference-contexts: Recognized as a standard by the United States Department of Defense, ANSI, and the IEEE, VHDL is a formal notation for describing electronic designs <ref> [40] </ref>. It is based on the Ada programming language, also adopted by the Department of Defense. Since many tools exist which can read VHDL descriptions, it is useful for all phases of design, synthesis, testing, and analysis of digital hardware.
Reference: [41] <institution> FPGA Data Book and Design Guide, Actel Corporation, Sunnyvale, California, </institution> <year> 1994. </year>
Reference-contexts: An example of an FPGA family is the ACT 1 family from Actel Corporation, with a capacity of 1,200 to 2,000 gates. Each logic module in an ACT 1 FPGA incurs a maximum delay of approximately 4.5 nanoseconds (ns) <ref> [41] </ref>.
Reference: [42] <author> H. Choi and K.S. Trivedi, </author> <title> Conditional MTTF and its Computation in Markov Reliability Models, </title> <booktitle> Proceedings of the Annual Reliability and Maintainability Symposium, </booktitle> <year> 1993, </year> <pages> pp. 56-63. </pages>
Reference-contexts: For this simple simplex model the MTBHE is calculated as shown in Equation 7.2 <ref> [42] </ref>. (7.2) It is apparent that the safety of the system depends directly on the error detection coverage. The primary problem in designing and analyzing microprocessor-based safety-critical systems is to design for high error detection coverage and prove that the coverage requirement is met.
Reference: [43] <author> D.T. Smith, </author> <title> A Malicious Fault List Generation Algorithm for the Evaluation of System Coverage, </title> <type> Ph.D. </type> <institution> Disstertation, University of Virginia, Charlottesville, Virginia, </institution> <month> August </month> <year> 1993. </year>
Reference-contexts: For a safety-critical system, however, a statistical sample on the order of 10 6 fault injection experiments is necessary to provide the desired confidence on the coverage estimate. The hardware injection methods developed thus far do not meet these requirements <ref> [43] </ref>. Software fault injection is used to inject faults into the data or control ow of the program executing the application. This method requires the assumption that all hardware or software faults will manifest themselves as errors in data or control ow. <p> Simulation models may allow the relatively rapid performance and analysis of large numbers of fault injection experiments. Depending on the level of abstraction employed, simulation models may provide observability of all parts of the system and also the selective injection of faults that will exercise the safety assurance features <ref> [43] </ref>. 121 7.2 An Application of Simulation-Based Fault Injection for the Evaluation of Input and Output Modules This section describes a study done to evaluate the fault detection and fault han dling of the MICROLOK controller developed and produced by Union Switch and Sig nal, Incorporated.
Reference: [44] <author> T.A. Delong, </author> <title> Performance and Safety Analysis of a Microprocessor-Based Embedded Control System Using VHDL, M.S.E.E. </title> <type> Thesis, </type> <institution> University of Virginia, Charlottes ville, Virginia, </institution> <month> January </month> <year> 1994. </year> <month> 144 </month>
Reference-contexts: A very useful feature of the model is its ability to execute the actual application program allowing faults to be injected in the model while it is running actual MICROLOK code <ref> [44] </ref>. The second model used in the safety evaluation is a gate-level model of the input and output subsystems.
Reference: [45] <author> J. Rabel, </author> <title> Use of 6821 Programmable Interface Adapter in MICROLOK, company docu mentation, Union Switch and Signal, </title> <publisher> Inc., </publisher> <address> March 6, </address> <year> 1992. </year>
Reference-contexts: It is this sequence plus some variations that is used as stimulus in the simulation. The normal operation input set was developed and verified in accordance with Union Switch and Signal, Inc. internal documentation on the workings of the MICROLOK system <ref> [45] </ref>. The significance of using input sequences from normal board operation is that it reduces the amount of time and input combinations necessary for simulation. For exam ple, no invalid input sequences are used. The boards program address, which is dependent on its location in the backplane, remains constant.
Reference: [46] <author> A.A. Shaikh and B.W. Johnson, </author> <title> MICROLOK Input/Output Hardware Fault Dictio nary, </title> <type> Technical Report 940201.0, </type> <institution> Center for Semicustom Integrated Systems, Uni versity of Virginia, </institution> <month> February </month> <year> 1994. </year>
Reference-contexts: This is because from an information viewpoint many fault modes may look identical. The final result, then, was a collapsed list of fault injection experiments for use in the VHDL model. The input PCB required 27 different types of fault injections while the output PCB required 36 <ref> [46] </ref>. The fault simulations produced results that fall into one of seven general categories. Some faults produce results that fall into two categories. A fault may, for example, produce one kind of result on one channel and something different on another channel. The fault behavior categories are described below.
Reference: [47] <author> M.A. Marouf and A.D. Friedman, </author> <title> Design of Self-Checking Checkers for Berger Codes, </title> <booktitle> Proceedings of Eighth International Symposium on Fault-Tolerant Computing, </booktitle> <address> Tou louse, France, </address> <month> June </month> <year> 1978, </year> <pages> pp. 179-184. 145 </pages>
Reference-contexts: It is a very simple state machine which uses a read or write sig 113 nal as its event-triggering signal. An 8-bit ones counter using full and half adders is designed for producing the Berger check symbol <ref> [47] </ref>. The outputs of the 8-bit counters may be combined with a ripple carry adder circuit to produce a 16-bit or 32-bit ones counter. VHDL descriptions for the dynamic code encoder, dynamic decoder, static code decoder, timestamp generator, and 8-bit ones counter appear in Appendix C.
References-found: 47

