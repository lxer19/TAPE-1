URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1187/CS-TR-93-1187.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1187/
Root-URL: http://www.cs.wisc.edu
Email: (mansha@cs.wisc.edu) (vernon@cs.wisc.edu)  
Title: Approximate Analysis of Parallel Processor Allocation Policies  
Author: Rajesh K. Mansharamani and Mary K. Vernon 
Date: November 29, 1993  
Address: 1210 West Dayton Street Madison, WI 53706.  
Affiliation: Computer Sciences Department University of Wisconsin  
Abstract: The complexity of parallel applications and parallel processor scheduling policies makes both exact analysis and simulation difficult, if not intractable, for large systems. In this paper we propose a new approach to performance modeling of multiprogrammed processor scheduling policies, that of interpolation approximations. We first define a workload model that contains parameters for the essential properties of parallel applications with respect to scheduling discipline performance, yet lends itself to mathematical analysis. Key features of the workload model include general distribution of total job processing time, general distribution of available job parallelism, and a simple characterization of parallelism overheads. We then show that one can find specific values of the system parameters for which the parallel system under a given scheduling policy reduces to a queueing system with a known (closed-form) solution. Finally, interpolation between the points with known solutions is used to arrive at mean response time estimates that hold over the entire system parameter space. The interpolation approximations readily yield insight into policy behavior and are easy to evaluate for systems with hundreds of processors. We illustrate the approach by developing and validating models of three scheduling policies, under the assumptions of linear job execution rates and independence between job parallelism and processing time. We discuss several insights and results obtained from the analysis of the three policies under the assumed workloads. One result clarifies and generalizes observations in two previous simulation studies of how policy performance varies with the coefficient of variation in job processing requirement. Another result of the interpolation models yields new insight into how policy performance varies with job parallelism. We also comment on the generalizations of these insights for workloads with less restrictive assumptions. fl This research was partially supported by the National Science Foundation under grants CCR-9024144 and CDA-9024618.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Bricker, M. Litzkow, and M. Livny. </author> <title> Condor Technical Summary. </title> <type> TR 1069, </type> <institution> Computer Sciences Dept., Univ. of Wisconsin-Madison, </institution> <month> January </month> <year> 1992. </year>
Reference-contexts: Comparing the results for C D = 5 we note that the performance of both the FCFS approximations degrades with C D . However, most of the data points are still within an 5 Many simulation experiments were run on the Condor distributed system <ref> [1] </ref>. 22 (a) P=20,100 (b) P=500,1000 acceptable range of error, i.e., within 5% to 35% error for the interpolation on p and within 35% for the interpolation on N .
Reference: [2] <author> D. Burman, and D. Smith. </author> <title> Approximate Analysis of a Queueing Model with Bursty Traffic. </title> <journal> Bell System Tech. Jnl. </journal> <volume> 62 (1983), </volume> <pages> 1433-1453. </pages>
Reference-contexts: 1.) Burman and Smith perform a linear interpolation between light and heavy traffic limits of the ratio of the mean delay in a single server FCFS queue with non-homogeneous Poisson arrivals to the mean delay in an M/G/1 FCFS queue with the same mean arrival rate and service time distribution <ref> [2] </ref>. In [3] they use a similar approach to obtain estimates for the mean delay in single server 4 and multiple server FCFS queues (sequential jobs) with more general arrival processes.
Reference: [3] <author> D. Burman, and D. Smith. </author> <title> An Asymptotic Analysis of a Queueing System with Markov-Modulated Arrivals. </title> <journal> Operations Research 34, </journal> <volume> 1 (1986), </volume> <pages> 105-119. </pages>
Reference-contexts: In <ref> [3] </ref> they use a similar approach to obtain estimates for the mean delay in single server 4 and multiple server FCFS queues (sequential jobs) with more general arrival processes.
Reference: [4] <author> G. Cosmetatos. </author> <title> Some Approximate Equilibrium Results for the Multi-Server Queue (M/G/r). </title> <journal> Operational Research Quarterly 27, </journal> <volume> 3 (1976), </volume> <pages> 615-620. </pages>
Reference-contexts: Cosmetatos interpolates between the mean waiting time in an M/D/c queue and in an M/M/c queue to obtain an approximation for the mean waiting time in an M/G/c queue when the coefficient of variation in service time C X 1 <ref> [4] </ref>.
Reference: [5] <author> K. Fendick, and W. Whitt. </author> <title> Measurements and Approximations to Describe the Offered Traffic and Predict the Average Workload in a Single-Server Queue. </title> <booktitle> Proc. of the IEEE 77, </booktitle> <month> 1 (Jan. </month> <year> 1989), </year> <pages> 171-194. </pages>
Reference-contexts: Fleming and Simon derive interpolation approximations for response time distributions in several single server queues, based on a similar approach [7]. Whitt [47], Fendick and Whitt <ref> [5] </ref> interpolate between light and heavy traffic limits to obtain approximations for a measure they call mean steady-state workload (or virtual waiting time) in a GI/G/1 queue and in general single server queues without independence conditions.
Reference: [6] <author> P. Fleming. </author> <title> An Approximate Analysis of Sojourn Times in the M/G/1 Queue with Round-Robin Service Discipline. </title> <institution> AT&T Bell Labs. Tech. </institution> <address> Jnl. 63, 8 (Oct. </address> <year> 1984), </year> <pages> 1521-1535. </pages>
Reference-contexts: Fleming interpolates between light and heavy traffic limits of the moments of the waiting time distribution in an M/G/1 Round Robin queue <ref> [6] </ref>. Simon and Willie estimate response time characteristics in priority queueing networks using interpolation approximations based on simulation and heavy traffic limits [37].
Reference: [7] <author> P. Fleming, and B. Simon. </author> <title> Interpolation Approximations of Sojourn Time Distributions. </title> <journal> Operations Research 39, </journal> <volume> 2 (1991), </volume> <pages> 251-260. </pages>
Reference-contexts: Fleming and Simon derive interpolation approximations for response time distributions in several single server queues, based on a similar approach <ref> [7] </ref>. Whitt [47], Fendick and Whitt [5] interpolate between light and heavy traffic limits to obtain approximations for a measure they call mean steady-state workload (or virtual waiting time) in a GI/G/1 queue and in general single server queues without independence conditions.
Reference: [8] <author> E. Gelenbe, D. Ghoshal, and S. Tripathi. </author> <title> Analysis of Processor Allocation in Large Multiprocessor Systems. </title> <booktitle> Proc. of the Interntl. Conf. on the Performance of Distributed Systems and Integrated Comm. Networks, </booktitle> <address> Kyoto, Japan, </address> <month> Sept. </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Thus, the particular assumptions in previous analytic models potentially limit the applicability of the results, as well as the ability to study policy behavior. The model in <ref> [8] </ref> allows general job processing requirement, but to apply their analysis one needs to know the probability that a job is allocated a given number of processors as a function of job type and system utilization. These probabilities may be difficult to obtain for many scheduling policies.
Reference: [9] <author> D. Ghosal, G. Serazzi, and S. Tripathi. </author> <title> The Processor Working Set and Its Use in Scheduling Multiprocessor Systems. </title> <journal> IEEE Trans. on Software Engg. </journal> <volume> 17, </volume> <month> 5 (May </month> <year> 1991), </year> <pages> 443-453. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation <ref> [9, 17, 18, 24, 50] </ref>, and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood.
Reference: [10] <author> A. Gupta, A. Tucker, and L. Stevens. </author> <title> Making Effective Use of Shared Memory Multiprocessors: The Process Control Approach. </title> <type> Tech. Report, </type> <institution> Computer Sciences Dept., Stanford University, </institution> <month> July </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement <ref> [10, 23, 44, 46] </ref>, simulation [9, 17, 18, 24, 50], and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> An example of such a policy is the default CM-5 scheduler for jobs that fit in the memory of a single partition. Previous studies have shown that variants of the EQ policy have high performance under a variety of workloads <ref> [44, 17, 23, 10, 16, 35, 24] </ref>. Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism [18, 16]. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. <p> Allocation of processing power for the above example is (27.5, 25, 27.5, 10, 10). Reallocation of power can occur on job arrivals, job departures, and changes in a job's available parallelism. Partitioning of processing power can be spatial, temporal, or some combination of the two <ref> [44, 17, 23, 10, 16] </ref>. The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature [17, 16, 35, 24]. (iii) PSAPF: Preemptive Smallest Available Parallelism First.
Reference: [11] <author> F. Kelly. </author> <title> Reversibility and Stochastic Networks. </title> <publisher> John Wiley & Sons, </publisher> <year> 1979. </year>
Reference-contexts: We use the approximate expressions given by (1) and (2) for the reductions in section 4.2. 12 4.1.2 The Symmetric Queue Kelly defines a queue to be symmetric if it operates in the following manner <ref> [11] </ref>. (i) The service requirement of a job is a random variable whose distribution may depend upon the class of the job. (ii) A total service effort is supplied at the rate (j), where j is the total number of jobs in the queue. (iii) A proportion ff (l; j) of <p> Note that and ff are parameters of the symmetric queue. Theorems 3.8 and 3.10 of <ref> [11] </ref> state that for a stationary symmetric queue with a Poisson arrival process with rate and an arbitrary distribution of job service time, S, the steady state probability of i jobs in the queue is given by i = Q i ; i = 0; 1; 2; : : : (3) <p> We tested the validity of the EQ approximation (6) using the exact expression from the symmetric queue reduction <ref> [11] </ref>, and found the relative errors to be typically less than 2%.
Reference: [12] <author> L. Kleinrock. </author> <title> Queueing Systems, Vol I: Theory. </title> <publisher> John Wiley & Sons, </publisher> <address> New York 1975. </address>
Reference: [13] <author> L. Kleinrock. </author> <title> Queueing Systems, </title> <booktitle> Vol II: Computer Applications. </booktitle> <publisher> John Wiley & Sons, </publisher> <address> New York 1976. </address>
Reference: [14] <editor> S. Lavenberg (Ed). </editor> <booktitle> Computer Performance Modeling Handbook. </booktitle> <publisher> Academic Press, </publisher> <address> New York 1983. </address>
Reference-contexts: Exact estimates for R F CF S (N = k) were obtained using matrix-geometric analysis [29, 26, 38]. For the estimates obtained by simulation almost all had 95% confidence intervals with less than 5% half-widths <ref> [14] </ref>.
Reference: [15] <author> S. </author> <title> Leutenegger. Issues in Multiprogrammed Multiprocessor Sharing. </title> <type> Ph.D. Thesis, Tech. Report #954, </type> <institution> Computer Sciences Dept., Univ. of Wisconsin-Madison, </institution> <month> Aug. </month> <year> 1990 </year>
Reference-contexts: The bounded-geometric distribution <ref> [17, 15] </ref>, is specified by N = &lt; P; with probability P max ; min (G; P ); with probability 1 P max ; where G = Geometric (p). In the validations we ensured coverage of extreme values of C N and N which served as stress tests. <p> p EQ versus p EQ to E [1=N ] for fixed N and C N D = P = 100 (a) Workloads W 3 and W 4 (b) ^ R p EQ versus p EQ to N for fixed E [1=N ] D = P = 100 previous simulation study <ref> [15] </ref> for a different distribution of N . D = P = 100, C D = 5, = 0:9 7.2 Policy Comparison We now focus on a quantitative comparison of EQ against FCFS and PSAPF under the assumption of no correlation between D and N , and linear execution rates.
Reference: [16] <author> S. Leutenegger, and R. Nelson. </author> <title> Analysis of Spatial and Temporal Scheduling Policies for Semi-Static and Dynamic Multiprocessor Environments. </title> <institution> Research Report - IBM T.J. Watson Research Center, Yorktown Heights, </institution> <month> Aug. </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Third, all but one of the previous analytic models either assume exponential distributions of job service time [19, 35], or assume independent and identically distributed (i.i.d.) task execution times (implying a specific degree of correlation between total job demand and the number of tasks in a job) <ref> [16, 25, 27, 28, 34, 42] </ref>. Regarding the former assumption, experience from uniprocessor systems suggests that relative policy performance can be highly sensitive to the (second moment of) job service demand distribution, and that total job demand can have significantly higher variability than the exponential [33, 43]. <p> An example of such a policy is the default CM-5 scheduler for jobs that fit in the memory of a single partition. Previous studies have shown that variants of the EQ policy have high performance under a variety of workloads <ref> [44, 17, 23, 10, 16, 35, 24] </ref>. Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism [18, 16]. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. <p> Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism <ref> [18, 16] </ref>. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. Each of the policies is defined in the context of a global or central job queue. <p> For example, if there are five jobs in a 100-processor system and the available parallelism per job is (50, 25, 100, 10, 10), then the allocation of processing power is (50, 25, 25, 0, 0). This policy has been studied under different workload assumptions in previous literature <ref> [28, 18, 25, 17, 42, 16] </ref>. (ii) EQ: The dynamic EQuiallocation policy allocates an equal fraction of processing power to each job in the system unless a job has smaller available parallelism than the equiallocation value, in which case each such job is allocated as many processors as its available parallelism, <p> Allocation of processing power for the above example is (27.5, 25, 27.5, 10, 10). Reallocation of power can occur on job arrivals, job departures, and changes in a job's available parallelism. Partitioning of processing power can be spatial, temporal, or some combination of the two <ref> [44, 17, 23, 10, 16] </ref>. The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature [17, 16, 35, 24]. (iii) PSAPF: Preemptive Smallest Available Parallelism First. <p> The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature <ref> [17, 16, 35, 24] </ref>. (iii) PSAPF: Preemptive Smallest Available Parallelism First. The central job queue is a preemptive queue that is ordered in ascending order of available job parallelism. Jobs with the same available parallelism are served in first-come-first-serve order. <p> Processor allocation to jobs can change upon job arrivals, job departures, and changes in job parallelism. This policy was proposed in [18] and also studied in <ref> [16, 17] </ref> under specific workloads. 3 Model A goal of this work is to develop a system model that is broadly applicable, characterizes the essential features of parallel workloads with a small number of parameters, and is easy to analyze.
Reference: [17] <author> S. Leutenegger, and M. Vernon. </author> <title> The Performance of Multiprogrammed Multiprocessor Scheduling Policies. </title> <booktitle> Proc. of the ACM SIGMETRICS Conf. on Measurement & Modeling of Computer Systems 18, </booktitle> <month> 1 (May </month> <year> 1990), </year> <pages> 226-236. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation <ref> [9, 17, 18, 24, 50] </ref>, and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> An example of such a policy is the default CM-5 scheduler for jobs that fit in the memory of a single partition. Previous studies have shown that variants of the EQ policy have high performance under a variety of workloads <ref> [44, 17, 23, 10, 16, 35, 24] </ref>. Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism [18, 16]. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. <p> For example, if there are five jobs in a 100-processor system and the available parallelism per job is (50, 25, 100, 10, 10), then the allocation of processing power is (50, 25, 25, 0, 0). This policy has been studied under different workload assumptions in previous literature <ref> [28, 18, 25, 17, 42, 16] </ref>. (ii) EQ: The dynamic EQuiallocation policy allocates an equal fraction of processing power to each job in the system unless a job has smaller available parallelism than the equiallocation value, in which case each such job is allocated as many processors as its available parallelism, <p> Allocation of processing power for the above example is (27.5, 25, 27.5, 10, 10). Reallocation of power can occur on job arrivals, job departures, and changes in a job's available parallelism. Partitioning of processing power can be spatial, temporal, or some combination of the two <ref> [44, 17, 23, 10, 16] </ref>. The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature [17, 16, 35, 24]. (iii) PSAPF: Preemptive Smallest Available Parallelism First. <p> The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature <ref> [17, 16, 35, 24] </ref>. (iii) PSAPF: Preemptive Smallest Available Parallelism First. The central job queue is a preemptive queue that is ordered in ascending order of available job parallelism. Jobs with the same available parallelism are served in first-come-first-serve order. <p> Processor allocation to jobs can change upon job arrivals, job departures, and changes in job parallelism. This policy was proposed in [18] and also studied in <ref> [16, 17] </ref> under specific workloads. 3 Model A goal of this work is to develop a system model that is broadly applicable, characterizes the essential features of parallel workloads with a small number of parameters, and is easy to analyze. <p> The bounded-geometric distribution <ref> [17, 15] </ref>, is specified by N = &lt; P; with probability P max ; min (G; P ); with probability 1 P max ; where G = Geometric (p). In the validations we ensured coverage of extreme values of C N and N which served as stress tests. <p> However, there are specific cases where FCFS and PSAPF can be expected to have similar performance (e.g., exponential job demands and high system utilization), and a previous simulation study <ref> [17] </ref> has shown that for specific distributions of D and N , PSAPF is not significantly better than FCFS when D and N are independent and when C D 5. <p> In particular, the approximations for R EQ are independent of C D . This result generalizes the observation in a previous simulation study <ref> [17] </ref>, which showed that for specific distributions of D and N , R EQ is independent of C D . The mean response time estimates of FCFS and PSAPF (equations (13), (15), (18) and (20)) depend not only on D but also on C D . <p> The mean response time estimates of FCFS and PSAPF (equations (13), (15), (18) and (20)) depend not only on D but also on C D . In particular, these response time estimates increase linearly in C 2 D . Two previous simulation studies <ref> [18, 17] </ref> have shown that for specific distributions of demand and parallelism R F CF S and R P SAP F increase with C D ; however, they did not show the (approximate) linear dependence on C 2 For workloads with sublinear execution rates and/or correlation between D and N , <p> A previous simulation study <ref> [17] </ref> showed similar policy comparison results for a hyperexponential distribution for D and specific distributions of N . <p> The functional dependence of policy performance on E [1=N ] is a new observation. The results for the C D parameter clarify and generalize results from previous work <ref> [17] </ref>, and show that relative policy performance is sensitive to job demand distribution. For example, the EQ policy outperforms FCFS and PSAPF when C D is greater than 1, whereas FCFS and PSAPF outperform EQ when C D &lt; 1.
Reference: [18] <author> S. Majumdar, D. Eager, and R. Bunt. </author> <title> Scheduling in Multiprogrammed Parallel Systems. </title> <booktitle> Proc. of the ACM SIGMETRICS Conf. on Measurement & Modeling of Computer Systems 16, </booktitle> <month> 1 (May </month> <year> 1988), </year> <pages> 104-113. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation <ref> [9, 17, 18, 24, 50] </ref>, and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Previous studies have shown that variants of the EQ policy have high performance under a variety of workloads [44, 17, 23, 10, 16, 35, 24]. Finally, we examine the PSAPF policy proposed in <ref> [18] </ref> because of its potential for high performance for workloads where job processing time is correlated with parallelism [18, 16]. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. <p> Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism <ref> [18, 16] </ref>. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. Each of the policies is defined in the context of a global or central job queue. <p> For example, if there are five jobs in a 100-processor system and the available parallelism per job is (50, 25, 100, 10, 10), then the allocation of processing power is (50, 25, 25, 0, 0). This policy has been studied under different workload assumptions in previous literature <ref> [28, 18, 25, 17, 42, 16] </ref>. (ii) EQ: The dynamic EQuiallocation policy allocates an equal fraction of processing power to each job in the system unless a job has smaller available parallelism than the equiallocation value, in which case each such job is allocated as many processors as its available parallelism, <p> Processor allocation to jobs can change upon job arrivals, job departures, and changes in job parallelism. This policy was proposed in <ref> [18] </ref> and also studied in [16, 17] under specific workloads. 3 Model A goal of this work is to develop a system model that is broadly applicable, characterizes the essential features of parallel workloads with a small number of parameters, and is easy to analyze. <p> The mean response time estimates of FCFS and PSAPF (equations (13), (15), (18) and (20)) depend not only on D but also on C D . In particular, these response time estimates increase linearly in C 2 D . Two previous simulation studies <ref> [18, 17] </ref> have shown that for specific distributions of demand and parallelism R F CF S and R P SAP F increase with C D ; however, they did not show the (approximate) linear dependence on C 2 For workloads with sublinear execution rates and/or correlation between D and N ,
Reference: [19] <author> S. Majumdar, D. Eager, and R. Bunt. </author> <title> Characterisation of programs for scheduling in multiprogrammed parallel systems. </title> <booktitle> Performance Evaluation 13 (1991), </booktitle> <pages> 109-130. 40 </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Second, the sets of simultaneous equations typically grow superlinearly in the number of processors thus limiting their solution to small system sizes, such as 20 or fewer processors. Third, all but one of the previous analytic models either assume exponential distributions of job service time <ref> [19, 35] </ref>, or assume independent and identically distributed (i.i.d.) task execution times (implying a specific degree of correlation between total job demand and the number of tasks in a job) [16, 25, 27, 28, 34, 42].
Reference: [20] <author> R. Mansharamani. </author> <title> Efficient Analysis of Parallel Processor Scheduling Policies. </title> <type> Ph.D. Thesis, </type> <institution> Computer Sciences Department, University of Wisconsin, Madison, WI, </institution> <month> November </month> <year> 1993. </year>
Reference-contexts: It can be shown that for a fixed value of N , the bounded-geometric distribution with lowest C N has P max = 0:0 and the bounded-geometric distribution with highest C N has p = 1 <ref> [20] </ref>. Thus, the first group of three are low C N workloads, the last group are high C N workloads, and the middle group are workloads with intermediate C N .
Reference: [21] <author> R. Mansharamani, and M. Vernon. </author> <title> Performance Analysis of the EQuipartitioning Parallel Processor Allocation Policy. </title> <note> In preparation. </note>
Reference-contexts: For the sake of space, we define the workload model for the case of no correlation between a job's available parallelism and processing requirement. Simple extensions that allow full correlation and arbitrary correlation are also possible <ref> [21] </ref>. The model lends itself to mathematical analysis, yet allows for broad applicability of the results and provides the basis for a fairly complete understanding of policy performance. The approach we propose for obtaining mean job response time equations is that of interpolation approximations. <p> These assumptions include general distribution of total job processing requirement, linear job execution rates, and no correlation between job demand and job parallelism. The approach can be applied to cases of sublinear execution rates and correlated workloads <ref> [21] </ref>, but focusing on the more restrictive assumptions simplifies the exposition of the technique, which is the primary purpose of this paper. The interpolation approximation approach has previously been applied to multiserver and fork-join queues. <p> All but one previous study have assumed specific distributions of demand and/or parallelism. Furthermore, there is a fairly simple extension to the above model to allow controlled correlation between job demand and available parallelism <ref> [21] </ref>. However, as stated in section 1 this is beyond the scope of this paper. <p> We comment in section 7 on how the key parallelism parameters obtained by assuming linear execution rates generalize to the case of sublinear job execution rates. We have also derived reductions and interpolation approximations for mean response time under sublinear execution rates <ref> [21] </ref>. 3.3 Notation Table 1 provides a summary of the notation for the system and workload model defined above.
Reference: [22] <author> R. Mansharamani, and M. Vernon. </author> <title> Comparison of Processor Allocation Policies for Parallel Systems. </title> <note> In preparation. </note>
Reference-contexts: In concluding this section we note that another possible way to improve on the interpolation approximations for PSAPF is to consider modifying the interpolation on p to account for the priority given to jobs with smaller parallelism <ref> [22] </ref>. <p> This intuition is born out by extensions to the interpolation approximations for these workloads <ref> [22] </ref>. 7.1.2 Functional Dependence on Parallelism Measures of workload parallelism include N and E [1=N ]. While N captures the average available parallelism of jobs, E [1=N ] captures the mean execution time of jobs (since E [1=N ] = S=D).
Reference: [23] <author> C. McCann, R. Vaswani, and J. Zahorjan. </author> <title> A Dynamic Processor Allocation Policy for Multiprogrammed, Shared Memory Multiprocessors. </title> <journal> ACM Transactions on Computer Systems 11, </journal> <month> 2 (May </month> <year> 1993), </year> <pages> 146-178. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement <ref> [10, 23, 44, 46] </ref>, simulation [9, 17, 18, 24, 50], and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> An example of such a policy is the default CM-5 scheduler for jobs that fit in the memory of a single partition. Previous studies have shown that variants of the EQ policy have high performance under a variety of workloads <ref> [44, 17, 23, 10, 16, 35, 24] </ref>. Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism [18, 16]. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. <p> Allocation of processing power for the above example is (27.5, 25, 27.5, 10, 10). Reallocation of power can occur on job arrivals, job departures, and changes in a job's available parallelism. Partitioning of processing power can be spatial, temporal, or some combination of the two <ref> [44, 17, 23, 10, 16] </ref>. The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature [17, 16, 35, 24]. (iii) PSAPF: Preemptive Smallest Available Parallelism First.
Reference: [24] <author> V. Naik, S. Setia and M. Squillante. </author> <title> Scheduling of Large Scientific Applications on Distributed Memory Multiprocessor Systems. </title> <type> Research Report RC 18621, </type> <institution> IBM T. J. Watson Research Center, Yorktown Heights, </institution> <month> Jan. </month> <year> 1993. </year> <booktitle> Proc. of the 6th SIAM Conf. on Parallel Processing for Scientific Computation. </booktitle>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation <ref> [9, 17, 18, 24, 50] </ref>, and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> An example of such a policy is the default CM-5 scheduler for jobs that fit in the memory of a single partition. Previous studies have shown that variants of the EQ policy have high performance under a variety of workloads <ref> [44, 17, 23, 10, 16, 35, 24] </ref>. Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism [18, 16]. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. <p> The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature <ref> [17, 16, 35, 24] </ref>. (iii) PSAPF: Preemptive Smallest Available Parallelism First. The central job queue is a preemptive queue that is ordered in ascending order of available job parallelism. Jobs with the same available parallelism are served in first-come-first-serve order.
Reference: [25] <author> R. Nelson. </author> <title> A Performance Evaluation of a General Parallel Processing Model. </title> <booktitle> Proc. of the ACM SIG-METRICS Conf. on Measurement & Modeling of Computer Systems 18, </booktitle> <month> 1 (May </month> <year> 1990), </year> <pages> 13-26 </pages> . 
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Third, all but one of the previous analytic models either assume exponential distributions of job service time [19, 35], or assume independent and identically distributed (i.i.d.) task execution times (implying a specific degree of correlation between total job demand and the number of tasks in a job) <ref> [16, 25, 27, 28, 34, 42] </ref>. Regarding the former assumption, experience from uniprocessor systems suggests that relative policy performance can be highly sensitive to the (second moment of) job service demand distribution, and that total job demand can have significantly higher variability than the exponential [33, 43]. <p> For example, if there are five jobs in a 100-processor system and the available parallelism per job is (50, 25, 100, 10, 10), then the allocation of processing power is (50, 25, 25, 0, 0). This policy has been studied under different workload assumptions in previous literature <ref> [28, 18, 25, 17, 42, 16] </ref>. (ii) EQ: The dynamic EQuiallocation policy allocates an equal fraction of processing power to each job in the system unless a job has smaller available parallelism than the equiallocation value, in which case each such job is allocated as many processors as its available parallelism,
Reference: [26] <author> R. Nelson. </author> <title> Matrix Geometric Solutions in Markov Models A Mathematical Tutorial. </title> <institution> Research Report - IBM T.J. Watson Research Center, Yorktown Heights, </institution> <month> Apr </month> <year> 1991. </year>
Reference-contexts: Exact estimates for R EQ (N = k) were obtained by reducing the system to a symmetric queue (see Proposition 4.2). Exact estimates for R F CF S (N = k) were obtained using matrix-geometric analysis <ref> [29, 26, 38] </ref>. For the estimates obtained by simulation almost all had 95% confidence intervals with less than 5% half-widths [14].
Reference: [27] <author> R. Nelson, and D. Towsley. </author> <title> A Performance Evaluation of Several Priority Policies for Parallel Processing Systems. </title> <type> COINS Tech. Report 91-32, </type> <institution> Computer and Info. Sciences, Univ. of Mass.-Amherst, </institution> <month> May </month> <year> 1991. </year> <note> (To appear in JACM.) </note>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Third, all but one of the previous analytic models either assume exponential distributions of job service time [19, 35], or assume independent and identically distributed (i.i.d.) task execution times (implying a specific degree of correlation between total job demand and the number of tasks in a job) <ref> [16, 25, 27, 28, 34, 42] </ref>. Regarding the former assumption, experience from uniprocessor systems suggests that relative policy performance can be highly sensitive to the (second moment of) job service demand distribution, and that total job demand can have significantly higher variability than the exponential [33, 43].
Reference: [28] <author> R. Nelson, D. Towsley, and A. Tantawi. </author> <title> Performance Analysis of Parallel Processing Systems. </title> <journal> IEEE Trans. on Software Engg., </journal> <month> April </month> <year> 1988, </year> <pages> 532-540. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Third, all but one of the previous analytic models either assume exponential distributions of job service time [19, 35], or assume independent and identically distributed (i.i.d.) task execution times (implying a specific degree of correlation between total job demand and the number of tasks in a job) <ref> [16, 25, 27, 28, 34, 42] </ref>. Regarding the former assumption, experience from uniprocessor systems suggests that relative policy performance can be highly sensitive to the (second moment of) job service demand distribution, and that total job demand can have significantly higher variability than the exponential [33, 43]. <p> For example, if there are five jobs in a 100-processor system and the available parallelism per job is (50, 25, 100, 10, 10), then the allocation of processing power is (50, 25, 25, 0, 0). This policy has been studied under different workload assumptions in previous literature <ref> [28, 18, 25, 17, 42, 16] </ref>. (ii) EQ: The dynamic EQuiallocation policy allocates an equal fraction of processing power to each job in the system unless a job has smaller available parallelism than the equiallocation value, in which case each such job is allocated as many processors as its available parallelism,
Reference: [29] <author> M. Neuts. </author> <title> Matrix-Geometric Solutions in Stochastic Models: An Algorithmic Approach. </title> <publisher> The John Hopkins University Press, </publisher> <year> 1981. </year>
Reference-contexts: Exact estimates for R EQ (N = k) were obtained by reducing the system to a symmetric queue (see Proposition 4.2). Exact estimates for R F CF S (N = k) were obtained using matrix-geometric analysis <ref> [29, 26, 38] </ref>. For the estimates obtained by simulation almost all had 95% confidence intervals with less than 5% half-widths [14].
Reference: [30] <author> M. Reiman, and B. Simon. </author> <title> An Interpolation Approximation for Queueing Systems with Poisson Input. </title> <journal> Operations Research 36, </journal> <volume> 3 (1988), </volume> <pages> 454-469. </pages>
Reference-contexts: Fleming interpolates between light and heavy traffic limits of the moments of the waiting time distribution in an M/G/1 Round Robin queue [6]. Simon and Willie estimate response time characteristics in priority queueing networks using interpolation approximations based on simulation and heavy traffic limits [37]. Reiman and Simon <ref> [30] </ref>, and Reiman et al. [31] provide interpolation approximations for the moments of response time and queue lengths in a variety of single server queueing systems using light and heavy traffic limits as well as derivatives of the computed measure at light traffic.
Reference: [31] <author> M. Reiman, B. Simon, and S. Willie. Simterpolation: </author> <title> A Simulation Based Interpolation Approximation for Queueing Systems. </title> <journal> Operations Research 40, </journal> <volume> 4 (1992), </volume> <pages> 706-723. </pages>
Reference-contexts: Simon and Willie estimate response time characteristics in priority queueing networks using interpolation approximations based on simulation and heavy traffic limits [37]. Reiman and Simon [30], and Reiman et al. <ref> [31] </ref> provide interpolation approximations for the moments of response time and queue lengths in a variety of single server queueing systems using light and heavy traffic limits as well as derivatives of the computed measure at light traffic.
Reference: [32] <author> H. Sakasegawa. </author> <title> An Approximation Formula L q : = ff fi =(1 ). Annals of the Institute of Statistical Mathematics 29, </title> <booktitle> 1 (1977), </booktitle> <pages> 67-75. </pages>
Reference-contexts: Server utilization is given by = x=c, c being the number of servers. There is no known exact solution of the mean response time of the M/G/c (FCFS) queue. As a result there have been a number of approximations for R M=G=c in the literature <ref> [32, 39, 40, 48, 49] </ref>. <p> There is no known exact solution of the mean response time of the M/G/c (FCFS) queue. As a result there have been a number of approximations for R M=G=c in the literature [32, 39, 40, 48, 49]. Of particular interest to us is the simple approximation proposed in <ref> [32] </ref> for the mean number in a GI/G/c queue, which leads to the following approximate formula for R M=G=c : R M=G=c x + p x ) : (1) Note that this approximation is exact for c = 1 and c = 1. <p> It is also exact for c = 1 and very accurate as shown by validations in <ref> [32] </ref> for the M/M/c queue.
Reference: [33] <author> C. Sauer, and K. M. Chandy. </author> <title> Computer System Performance Modeling. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1981. </year>
Reference-contexts: Regarding the former assumption, experience from uniprocessor systems suggests that relative policy performance can be highly sensitive to the (second moment of) job service demand distribution, and that total job demand can have significantly higher variability than the exponential <ref> [33, 43] </ref>. Relative scheduling policy performance for parallel systems may also be sensitive to the degree of correlation between available job parallelism and total job service requirement. <p> Using this approximation and the fact that R M=G=c P S = R M=M=c <ref> [33] </ref>, one can derive the following approximation: R M=G=c P S x + p (1 ) We note that this approximation has a much simpler form than the exact expression for mean response time in the M=G=c P S queue. <p> D , 2 fEQ; F CF S; P SAP F g From figure 14 we note that for C D &gt;> 1 the performance of FCFS and PSAPF is considerably worse than that of EQ. Since general purpose computer system workloads typically have high C D <ref> [33, 43] </ref> this result is relevant to practical systems. 7 Furthermore, the results show that relative policy performance can be strongly influenced by C D , indicating that it is important to interpret the results of scheduling policy performance comparisons in the context of the assumed distribution (s) of job demand.
Reference: [34] <author> S. Setia, M. Squillante, and S. Tripathi. </author> <title> Processor Scheduling on Multiprogrammed, </title> <booktitle> Distributed Memory Parallel Systems. Proc. of the ACM SIGMETRICS Conf. on Measurement & Modeling of Computer Systems 21, </booktitle> <month> 1 (May </month> <year> 1993), </year> <pages> 158-170. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Third, all but one of the previous analytic models either assume exponential distributions of job service time [19, 35], or assume independent and identically distributed (i.i.d.) task execution times (implying a specific degree of correlation between total job demand and the number of tasks in a job) <ref> [16, 25, 27, 28, 34, 42] </ref>. Regarding the former assumption, experience from uniprocessor systems suggests that relative policy performance can be highly sensitive to the (second moment of) job service demand distribution, and that total job demand can have significantly higher variability than the exponential [33, 43].
Reference: [35] <author> S. Setia, and S. Tripathi. </author> <title> An Analysis of Several Processor Partitioning Policies for Parallel Computers. </title> <type> Tech. Report CS-TR-2684, </type> <institution> Univ. of Maryland, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Second, the sets of simultaneous equations typically grow superlinearly in the number of processors thus limiting their solution to small system sizes, such as 20 or fewer processors. Third, all but one of the previous analytic models either assume exponential distributions of job service time <ref> [19, 35] </ref>, or assume independent and identically distributed (i.i.d.) task execution times (implying a specific degree of correlation between total job demand and the number of tasks in a job) [16, 25, 27, 28, 34, 42]. <p> An example of such a policy is the default CM-5 scheduler for jobs that fit in the memory of a single partition. Previous studies have shown that variants of the EQ policy have high performance under a variety of workloads <ref> [44, 17, 23, 10, 16, 35, 24] </ref>. Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism [18, 16]. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. <p> The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature <ref> [17, 16, 35, 24] </ref>. (iii) PSAPF: Preemptive Smallest Available Parallelism First. The central job queue is a preemptive queue that is ordered in ascending order of available job parallelism. Jobs with the same available parallelism are served in first-come-first-serve order.
Reference: [36] <author> S. Setia, and S. Tripathi. </author> <title> A Comparative Analysis of Static Processor Partitioning Policies for Parallel Computers. </title> <booktitle> Proc. of the Interntl. Workshop on Modeling, Analysis and Simulation of Computer and Telecomm. Systems (MASCOTS'93), </booktitle> <month> January </month> <year> 1993. </year> <month> 41 </month>
Reference: [37] <author> B. Simon, and S. Willie. </author> <title> Estimation of Response Time Characteristics in Priority Queueing Networks via an Interpolation Methodology based on Simulation and Heavy Traffic Limits. </title> <booktitle> Computer Science and Statistics: Proc. of the 18th Symposium on the Interface, American Statistical Association, </booktitle> <year> 1986, </year> <pages> 251-256. </pages>
Reference-contexts: Fleming interpolates between light and heavy traffic limits of the moments of the waiting time distribution in an M/G/1 Round Robin queue [6]. Simon and Willie estimate response time characteristics in priority queueing networks using interpolation approximations based on simulation and heavy traffic limits <ref> [37] </ref>. Reiman and Simon [30], and Reiman et al. [31] provide interpolation approximations for the moments of response time and queue lengths in a variety of single server queueing systems using light and heavy traffic limits as well as derivatives of the computed measure at light traffic.
Reference: [38] <author> M. Squillante. </author> <title> MAGIC: A Computer Performance Modeling Tool Based on Matrix-Geometric Techniques. </title> <booktitle> Proc. of the 5 th Interntl. Conf. on Modelling Techniques and Tools for Computer Performance Evaluation, </booktitle> <month> Feb. </month> <year> 1991. </year>
Reference-contexts: Exact estimates for R EQ (N = k) were obtained by reducing the system to a symmetric queue (see Proposition 4.2). Exact estimates for R F CF S (N = k) were obtained using matrix-geometric analysis <ref> [29, 26, 38] </ref>. For the estimates obtained by simulation almost all had 95% confidence intervals with less than 5% half-widths [14].
Reference: [39] <author> D. </author> <title> Stoyan. Comparison Methods for Queues and Other Stochastic Models. </title> <publisher> Wiley 1983. </publisher>
Reference-contexts: Server utilization is given by = x=c, c being the number of servers. There is no known exact solution of the mean response time of the M/G/c (FCFS) queue. As a result there have been a number of approximations for R M=G=c in the literature <ref> [32, 39, 40, 48, 49] </ref>.
Reference: [40] <author> Y. Takahashi. </author> <title> An Approximation Formula for the Mean Waiting Time of a M/G/c Queue. </title> <journal> Jnl. of the Operations Research Society of Japan 20, </journal> <volume> 3 (1977), </volume> <pages> 150-163. </pages>
Reference-contexts: Server utilization is given by = x=c, c being the number of servers. There is no known exact solution of the mean response time of the M/G/c (FCFS) queue. As a result there have been a number of approximations for R M=G=c in the literature <ref> [32, 39, 40, 48, 49] </ref>.
Reference: [41] <author> Thinking Machines Corporation. </author> <title> The Connection Machine CM-5 Technical Summary. </title> <address> Cambridge, Mas-sachusetts, </address> <month> October </month> <year> 1991. </year>
Reference: [42] <author> D. Towsley, C. Rommel, and J. Stankovic. </author> <title> Analysis of Fork-Join Program Response Times on Multiprocessors. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <month> July </month> <year> 1990, </year> <pages> 286-303. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation [9, 17, 18, 24, 50], and analytic modeling methods <ref> [8, 16, 19, 25, 27, 28, 34, 35, 42] </ref>. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> Third, all but one of the previous analytic models either assume exponential distributions of job service time [19, 35], or assume independent and identically distributed (i.i.d.) task execution times (implying a specific degree of correlation between total job demand and the number of tasks in a job) <ref> [16, 25, 27, 28, 34, 42] </ref>. Regarding the former assumption, experience from uniprocessor systems suggests that relative policy performance can be highly sensitive to the (second moment of) job service demand distribution, and that total job demand can have significantly higher variability than the exponential [33, 43]. <p> The FCFS policy is very simple and has been shown to have high performance for specific workloads <ref> [42] </ref>. The EQ policy is an idealization of the class of scheduling policies that allocate an equal fraction of processing power to each job in the system, subject to the constraint that a job is never allocated more processors than its available parallelism. <p> For example, if there are five jobs in a 100-processor system and the available parallelism per job is (50, 25, 100, 10, 10), then the allocation of processing power is (50, 25, 25, 0, 0). This policy has been studied under different workload assumptions in previous literature <ref> [28, 18, 25, 17, 42, 16] </ref>. (ii) EQ: The dynamic EQuiallocation policy allocates an equal fraction of processing power to each job in the system unless a job has smaller available parallelism than the equiallocation value, in which case each such job is allocated as many processors as its available parallelism,
Reference: [43] <author> K. Trivedi. </author> <title> Probability and Statistics, with Reliability, Queueing and Computer Science Applications. </title> <publisher> Prentice-Hall, </publisher> <year> 1982, </year> <pages> pp. 130. </pages>
Reference-contexts: Regarding the former assumption, experience from uniprocessor systems suggests that relative policy performance can be highly sensitive to the (second moment of) job service demand distribution, and that total job demand can have significantly higher variability than the exponential <ref> [33, 43] </ref>. Relative scheduling policy performance for parallel systems may also be sensitive to the degree of correlation between available job parallelism and total job service requirement. <p> D , 2 fEQ; F CF S; P SAP F g From figure 14 we note that for C D &gt;> 1 the performance of FCFS and PSAPF is considerably worse than that of EQ. Since general purpose computer system workloads typically have high C D <ref> [33, 43] </ref> this result is relevant to practical systems. 7 Furthermore, the results show that relative policy performance can be strongly influenced by C D , indicating that it is important to interpret the results of scheduling policy performance comparisons in the context of the assumed distribution (s) of job demand.
Reference: [44] <author> A. Tucker and A. Gupta. </author> <title> Process Control and Scheduling Issues for Multiprogrammed Shared-Memory Multiprocessors. </title> <booktitle> Proc. of the 12th ACM Symp. on Operating System Principles, </booktitle> <month> Dec. </month> <year> 1989, </year> <pages> 159-166. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement <ref> [10, 23, 44, 46] </ref>, simulation [9, 17, 18, 24, 50], and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood. <p> An example of such a policy is the default CM-5 scheduler for jobs that fit in the memory of a single partition. Previous studies have shown that variants of the EQ policy have high performance under a variety of workloads <ref> [44, 17, 23, 10, 16, 35, 24] </ref>. Finally, we examine the PSAPF policy proposed in [18] because of its potential for high performance for workloads where job processing time is correlated with parallelism [18, 16]. Furthermore, this policy allows us to illustrate an interesting aspect of the interpolation approximation approach. <p> Allocation of processing power for the above example is (27.5, 25, 27.5, 10, 10). Reallocation of power can occur on job arrivals, job departures, and changes in a job's available parallelism. Partitioning of processing power can be spatial, temporal, or some combination of the two <ref> [44, 17, 23, 10, 16] </ref>. The analysis in this paper holds for any of these cases. Both simulation and analytic models for the EQ policy, based on various workload assumptions, have appeared in the previous literature [17, 16, 35, 24]. (iii) PSAPF: Preemptive Smallest Available Parallelism First.
Reference: [45] <author> S. Varma, and A. Makowski. </author> <title> Interpolation Approximations for Symmetric Fork-Join Queues. </title> <note> To appear in Proceedings of Performance'93. </note>
Reference-contexts: Whitt [47], Fendick and Whitt [5] interpolate between light and heavy traffic limits to obtain approximations for a measure they call mean steady-state workload (or virtual waiting time) in a GI/G/1 queue and in general single server queues without independence conditions. Varma and Makowski <ref> [45] </ref> propose interpolation approximations for the mean response times of a symmetric fork-join queue with general inter-arrival and service time distributions.
Reference: [46] <author> R. Vaswani and J. Zahorjan. </author> <title> The Implications of Cache Affinity on Processor Scheduling for Multipro-grammed, Shared Memory Multiprocessors. </title> <booktitle> Proc. of the 13th ACM Symposium on Operating System Principles, </booktitle> <month> October </month> <year> 1991, </year> <pages> 26-40. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement <ref> [10, 23, 44, 46] </ref>, simulation [9, 17, 18, 24, 50], and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood.
Reference: [47] <author> W. Whitt. </author> <title> An Interpolation Approximation for the Mean Workload in a GI/G/1 Queue. </title> <journal> Operations Research 37, </journal> <volume> 6 (1989), </volume> <pages> 936-952. </pages>
Reference-contexts: Fleming and Simon derive interpolation approximations for response time distributions in several single server queues, based on a similar approach [7]. Whitt <ref> [47] </ref>, Fendick and Whitt [5] interpolate between light and heavy traffic limits to obtain approximations for a measure they call mean steady-state workload (or virtual waiting time) in a GI/G/1 queue and in general single server queues without independence conditions.
Reference: [48] <author> R. Wolff. </author> <title> Stochastic Modeling and the Theory of Queues. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1989. </year>
Reference-contexts: Server utilization is given by = x=c, c being the number of servers. There is no known exact solution of the mean response time of the M/G/c (FCFS) queue. As a result there have been a number of approximations for R M=G=c in the literature <ref> [32, 39, 40, 48, 49] </ref>.
Reference: [49] <author> D. Yao. </author> <title> Refining the Diffusion Approximation for the M/G/m Queue. </title> <booktitle> Operations Research 33 (1985), </booktitle> <pages> 1266-1277. </pages>
Reference-contexts: Server utilization is given by = x=c, c being the number of servers. There is no known exact solution of the mean response time of the M/G/c (FCFS) queue. As a result there have been a number of approximations for R M=G=c in the literature <ref> [32, 39, 40, 48, 49] </ref>.
Reference: [50] <author> J. Zahorjan, and C. McCann. </author> <title> Processor Scheduling in Shared Memory Multiprocessors. </title> <booktitle> Proc. of the ACM SIGMETRICS Conf. on Measurement & Modeling of Computer Systems 18, </booktitle> <month> 1 (May </month> <year> 1990), </year> <pages> 214-225. </pages>
Reference-contexts: 1 Introduction The algorithm for scheduling jobs on the processors of a multiprogrammed parallel computer can have a significant impact on system performance. Parallel processor scheduling disciplines have been studied using system measurement [10, 23, 44, 46], simulation <ref> [9, 17, 18, 24, 50] </ref>, and analytic modeling methods [8, 16, 19, 25, 27, 28, 34, 35, 42]. While these studies have yielded various specific insights, the general performance characteristics of parallel scheduling policies still remains poorly understood.
References-found: 50

