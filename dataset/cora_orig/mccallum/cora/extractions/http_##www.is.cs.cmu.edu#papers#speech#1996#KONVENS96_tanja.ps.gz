URL: http://www.is.cs.cmu.edu/papers/speech/1996/KONVENS96_tanja.ps.gz
Refering-URL: http://www.is.cs.cmu.edu/ISL.speech.publications.html
Root-URL: 
Title: Automatische Identifizierung spontan gesprochener Sprachen mit neuronalen Netzen automatische Identifikation von Sprachen (LID) ist ein
Author: Tanja Schultz 
Note: Die  von 86% erreicht.  
Address: 76128 Karlsruhe  
Affiliation: und Hagen Soltau Interactive Systems Labs, ILKD Universitat Karlsruhe,  
Abstract: building multilingual speech recognition and translation systems. In this paper we present a front-end module to identify one out of four languages German, English, Spanisch and Japanese for use in spontaneous speech-to-speech translation systems like JANUS. We compare two different approaches to classify the speech data, on the one hand we used the maximum likelihood method on the other hand neuronal networks. It can be shown, that neuronal nets leads to better results which is overall 86% for the four language test. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T.J. </author> <title> Hazen und V.W. Zue: Automatic Language Identification using a Segment-based Approach in: </title> <booktitle> Proc. Eurospeech, S. </booktitle> <pages> 1303-1306, </pages> <address> Berlin 1993. </address>
Reference-contexts: In den meisten Forschungsarbeiten wird bisher ausschlielich akustisch-phonetisches Wissen auf der Grundlage von Einheiten wie Phonemen [9], [2] oder Phonemklassen [3] herangezogen. Einige Autoren fugen phonologisches Wissen in Form von Phonembigrammen [2] oder - trigrammen <ref> [1] </ref> hinzu. Die meisten Untersuchungen beschranken sich allerdings auf den Einsatz von phonembasierten Wissen, da der Rechenbedarf und der Aufwand fur die Erstellung dieser Wissensquellen niedrig ist. Prosodische Wis-sensquellen werden bisher nur in sehr wenigen Arbeiten eingesetzt und erzielen keine signifikante Verbesserung der Identifizierungsleistung [1]. <p> von Phonembigrammen [2] oder - trigrammen <ref> [1] </ref> hinzu. Die meisten Untersuchungen beschranken sich allerdings auf den Einsatz von phonembasierten Wissen, da der Rechenbedarf und der Aufwand fur die Erstellung dieser Wissensquellen niedrig ist. Prosodische Wis-sensquellen werden bisher nur in sehr wenigen Arbeiten eingesetzt und erzielen keine signifikante Verbesserung der Identifizierungsleistung [1]. Wird die Identi-fikation von Sprachen als "`Vorverarbeitung"' zur Erkennung und Ubersetzung von Sprache betrieben, wie es bei multilingualen Ubersetzungssystemen der Fall ist, kann die Information der erkannten Sequenz weiterverwendet werden. <p> Diejenige Sprache, deren Erkenner den besten Score fur die Testauerung ermittelt hat, wird als die gesprochene Sprache identifiziert. Die parallele Architektur wird von einem Groteil der Forscher verwendet (vgl. [2], <ref> [1] </ref>, [8]). Die integrale Architektur hat den Nachteil, da mit zunehmender Zahl der zu identifizierender Sprachen die Anzahl der zu integrierenden sprachenspezifischen Einheiten steigt. Dadurch wird erstens die Klassifizierung wegen wachsender Ambiguitaten schwieriger, zweitens steigt die Berechnungsdauer der Algorith-men an.
Reference: [2] <author> L.F. Lamel und J. Gauvain: </author> <title> Identifying Non-linguistic Speech Features in: </title> <booktitle> Proc. Eurospeech, S. </booktitle> <pages> 23-30, </pages> <address> Berlin 1993. </address>
Reference-contexts: Die eigentlich erkannte Sequenz wird als Information zur Identifikation dabei nicht betrachtet, wichtig ist nur die Sprache in der die Sequenz vorliegt. In den meisten Forschungsarbeiten wird bisher ausschlielich akustisch-phonetisches Wissen auf der Grundlage von Einheiten wie Phonemen [9], <ref> [2] </ref> oder Phonemklassen [3] herangezogen. Einige Autoren fugen phonologisches Wissen in Form von Phonembigrammen [2] oder - trigrammen [1] hinzu. Die meisten Untersuchungen beschranken sich allerdings auf den Einsatz von phonembasierten Wissen, da der Rechenbedarf und der Aufwand fur die Erstellung dieser Wissensquellen niedrig ist. <p> In den meisten Forschungsarbeiten wird bisher ausschlielich akustisch-phonetisches Wissen auf der Grundlage von Einheiten wie Phonemen [9], <ref> [2] </ref> oder Phonemklassen [3] herangezogen. Einige Autoren fugen phonologisches Wissen in Form von Phonembigrammen [2] oder - trigrammen [1] hinzu. Die meisten Untersuchungen beschranken sich allerdings auf den Einsatz von phonembasierten Wissen, da der Rechenbedarf und der Aufwand fur die Erstellung dieser Wissensquellen niedrig ist. Prosodische Wis-sensquellen werden bisher nur in sehr wenigen Arbeiten eingesetzt und erzielen keine signifikante Verbesserung der Identifizierungsleistung [1]. <p> Bei der Identi-fizierung laufen diese Spracherkenner parallel und erzeugen beim Dekodieren der unbekannten Testauerung fur jede Sprache eine Bewertung (Score). Diejenige Sprache, deren Erkenner den besten Score fur die Testauerung ermittelt hat, wird als die gesprochene Sprache identifiziert. Die parallele Architektur wird von einem Groteil der Forscher verwendet (vgl. <ref> [2] </ref>, [1], [8]). Die integrale Architektur hat den Nachteil, da mit zunehmender Zahl der zu identifizierender Sprachen die Anzahl der zu integrierenden sprachenspezifischen Einheiten steigt. Dadurch wird erstens die Klassifizierung wegen wachsender Ambiguitaten schwieriger, zweitens steigt die Berechnungsdauer der Algorith-men an.
Reference: [3] <author> Y. Muthusamy, K. Berkling, T. Arai, R.A. Cole und E. Barnard: </author> <title> Comparison of Approaches to Automatic Language Identification using Telephone Speech in: </title> <booktitle> Proc. Eurospeech, S. </booktitle> <pages> 130 7-1310, </pages> <address> Berlin 1993. </address>
Reference-contexts: Die eigentlich erkannte Sequenz wird als Information zur Identifikation dabei nicht betrachtet, wichtig ist nur die Sprache in der die Sequenz vorliegt. In den meisten Forschungsarbeiten wird bisher ausschlielich akustisch-phonetisches Wissen auf der Grundlage von Einheiten wie Phonemen [9], [2] oder Phonemklassen <ref> [3] </ref> herangezogen. Einige Autoren fugen phonologisches Wissen in Form von Phonembigrammen [2] oder - trigrammen [1] hinzu. Die meisten Untersuchungen beschranken sich allerdings auf den Einsatz von phonembasierten Wissen, da der Rechenbedarf und der Aufwand fur die Erstellung dieser Wissensquellen niedrig ist. <p> Bei der integralen Architek tur wird ein einziger globaler Spracherkenner fur alle zu identifizierenden Ref-erenzsprachen trainiert. In diesem Modell sind alle sprachenspezifischen Eigen-heiten integriert und konkurrieren beim Dekodieren der Testauerung miteinan-der (vgl. <ref> [3] </ref>). Bei der parallelen Architektur wird fur jede zu unterscheidende Referenzsprache ein eigenstandiger Spracherkenner trainiert. Bei der Identi-fizierung laufen diese Spracherkenner parallel und erzeugen beim Dekodieren der unbekannten Testauerung fur jede Sprache eine Bewertung (Score).
Reference: [4] <author> Y.K. Muthusamy, R.A. </author> <title> Cole und B.T. Oshika: The OGI multi-language telephone speech corpus in: </title> <booktitle> Proc. ICSLP, </booktitle> <address> Banff 1992. </address>
Reference-contexts: Erst seit in jungster Zeit Spracherkennungssysteme auf der Basis groer Wortschatze fur viele verschiedenen Fremdsprachen entwickelt werden, erwacht das Interesse an LID erneut. Die Erstellung multilingualer Datenbasen wie etwa der OGI-Korpus <ref> [4] </ref> und die Datenbasis SST ermoglicht es nun, ver schiedene Forschungsansatze miteinander zu vergleichen.
Reference: [5] <author> Y.K. Muthusamy, N. Jain und R.A. Cole: </author> <title> Perceptual Benchmarks for Automatic Language Identification in: </title> <booktitle> Proc. ICASSP, S. </booktitle> <pages> 333-336, </pages> <address> Adelaide 1994. </address>
Reference-contexts: In einer Studie von Muthusamy et. al. <ref> [5] </ref> in der eine aus 10 Sprachen identi-fiziert werden sollte, gaben die Versuchspersonen an, da sie eine Kombination 2 von "`Phonem"'- und "`Wordspotting"', sowie die phonetischen und prosodis--chen Merkmale einer Sprache zur Identifizierung verwenden.
Reference: [6] <author> T. Schultz, I. Rogina und A. Waibel: </author> <title> Experiments with LVCSR based Language Identification. </title> <booktitle> Proceedings of the SRS, S. </booktitle> <pages> 89-94, </pages> <address> Baltimore 1995. </address>
Reference-contexts: Unsere fruhere Exper-imente haben gezeigt, da durch die Integration wortbasierter Lexika und Grammatiken in Form von statistischen Language Modellen eine wesentliche Verbesserung der Sprachenidentifizierungsleistung erreicht werden kann <ref> [6] </ref>, [7]. 3 Die multilinguale Datenbasis SST Zur Entwicklung des hier beschriebenen Identifizierungssystems wird die mul-tilinguale Datenbasis SST (Spontaneous Scheduling Task) spontan gesproch-ener Dialoge verwendet. Dieser multilinguale Korpus enthalt Terminabsprachen zwischen zwei Gesprachspartnern in den Sprachen Deutsch, Englisch, Spanisch und Japanisch.
Reference: [7] <author> T. Schultz, I. Rogina und A. Waibel: </author> <title> LVCSR-based Language Identification. </title> <booktitle> in: Proc. ICASSP, S. </booktitle> <pages> 781-784, </pages> <booktitle> volume 2, </booktitle> <address> Atlanta 1996. </address>
Reference-contexts: Unsere fruhere Exper-imente haben gezeigt, da durch die Integration wortbasierter Lexika und Grammatiken in Form von statistischen Language Modellen eine wesentliche Verbesserung der Sprachenidentifizierungsleistung erreicht werden kann [6], <ref> [7] </ref>. 3 Die multilinguale Datenbasis SST Zur Entwicklung des hier beschriebenen Identifizierungssystems wird die mul-tilinguale Datenbasis SST (Spontaneous Scheduling Task) spontan gesproch-ener Dialoge verwendet. Dieser multilinguale Korpus enthalt Terminabsprachen zwischen zwei Gesprachspartnern in den Sprachen Deutsch, Englisch, Spanisch und Japanisch.
Reference: [8] <author> M.A. Zissman: </author> <title> Automatic Language Identification using Gaussian Mixtures and Hidden Markov Models in: </title> <booktitle> Proc. ICASSP, S. </booktitle> <pages> 309-402, </pages> <booktitle> volume 2, </booktitle> <address> Minneapolis 1993. </address>
Reference-contexts: Diejenige Sprache, deren Erkenner den besten Score fur die Testauerung ermittelt hat, wird als die gesprochene Sprache identifiziert. Die parallele Architektur wird von einem Groteil der Forscher verwendet (vgl. [2], [1], <ref> [8] </ref>). Die integrale Architektur hat den Nachteil, da mit zunehmender Zahl der zu identifizierender Sprachen die Anzahl der zu integrierenden sprachenspezifischen Einheiten steigt. Dadurch wird erstens die Klassifizierung wegen wachsender Ambiguitaten schwieriger, zweitens steigt die Berechnungsdauer der Algorith-men an. <p> Daran sieht man, da bei der parallelen Architektur auf eine Normierung der Erkennerscores nicht verzichtet werden kann. Zissman schlug in <ref> [8] </ref> eine Normierung vor, bei der vom aktuell berechneten Score eines Erken-ners der Mittelwert aller von diesem Erkenner errechneten Scores abgezogen wird. Diese Normierung fuhrt in unseren Experimenten beim W-3LM System zu Verbesserungen.
Reference: [9] <author> M.A. Zissman und E. Singer: </author> <title> Automatic Language Identification of Telephone Speech Messages using Phoneme Recognition and N-gram Modeling in: </title> <booktitle> Proc. ICASSP, S. </booktitle> <volume> 305-308, volume 1, </volume> <booktitle> Adelaide 1994. </booktitle> <pages> 10 </pages>
Reference-contexts: Die eigentlich erkannte Sequenz wird als Information zur Identifikation dabei nicht betrachtet, wichtig ist nur die Sprache in der die Sequenz vorliegt. In den meisten Forschungsarbeiten wird bisher ausschlielich akustisch-phonetisches Wissen auf der Grundlage von Einheiten wie Phonemen <ref> [9] </ref>, [2] oder Phonemklassen [3] herangezogen. Einige Autoren fugen phonologisches Wissen in Form von Phonembigrammen [2] oder - trigrammen [1] hinzu. Die meisten Untersuchungen beschranken sich allerdings auf den Einsatz von phonembasierten Wissen, da der Rechenbedarf und der Aufwand fur die Erstellung dieser Wissensquellen niedrig ist.
References-found: 9

