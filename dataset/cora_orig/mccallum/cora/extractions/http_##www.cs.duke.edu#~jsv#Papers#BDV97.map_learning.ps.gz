URL: http://www.cs.duke.edu/~jsv/Papers/BDV97.map_learning.ps.gz
Refering-URL: http://www.cs.duke.edu/~jsv/Papers/catalog/node53.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: kbasye@black.clarku.edu  tld@cs.brown.edu  jsv@cs.duke.edu  
Phone: 2  3  
Title: Coping With Uncertainty in Map Learning  
Author: Kenneth Basye Thomas Dean Jeffrey Scott Vitter 
Keyword: Running head: Map Learning Keywords: Inference Learning Maps Graphs Uncertainty Noise  
Note: This work was supported in part by a National Science Foundation Presidential Young Investigator Award CCR-8846714 with matching funds from IBM, by National Science Foundation research grant CCR-8403613, and by ONR grant N00014-83-K-0146, ARPA Order No. 4786.  
Address: Worcester, MA 01610  Providence, RI 02912  Durham, NC, 27708  
Affiliation: 1 Department of Mathematics and Computer Science Clark University,  Department of Computer Science Brown University,  Department of Computer Science Duke University,  
Abstract: fl This work was supported in part by a National Science Foundation Presidential Young Investigator Award IRI-8957601 with matching funds from IBM, and by the Advanced Research Projects Agency of the Department of Defense and was monitored by the Air Force Office of Scientific Research under Contract No. F49620-88-C-0132. 
Abstract-found: 1
Intro-found: 1
Reference: [ Aleliunas et al., 1979 ] <author> Romas Aleliunas, Richard M. Karp, Richard J. Lipton, Laszlo Lo-vasz, and Charles Rackoff. </author> <title> Random walks, universal traversal sequences, and the complexity of maze problems. </title> <booktitle> In Proceedings of the 20th Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 218-223, </pages> <year> 1979. </year>
Reference-contexts: Other properties may include regularity or bounded degree. In what follows, we will always assume that the graphs induced are connected and undirected; any other properties will be explicitly noted. Following <ref> [ Aleliunas et al., 1979 ] </ref> , a graph model consists of a graph, G = (V; E), a set L of labels, and a labeling, : fV fi Eg ! L, where we may assume that L has a null element ? which is the label of any pair (v <p> Proof: We rely on a result due to Aleliunas, et al. <ref> [ Aleliunas et al., 1979 ] </ref> that establishes that the expected number of steps for an unbiased random walk to traverse every undirected edge in E is less than or equal to 2djV j (jV j 1).
Reference: [ Basye and Dean, 1989 ] <author> Kenneth Basye and Thomas Dean. </author> <title> Map learning with indistinguishable locations. </title> <booktitle> In Proceedings of the 1989 Workshop on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 7-13, </pages> <year> 1989. </year>
Reference-contexts: In this case, the graph can be reliably navigated by the same agent that did the map learning. We note that the purpose of either certainty requirement is to allow the robot to filter out paths reported by sensors that aren't really in the graph. In <ref> [ Basye and Dean, 1989 ] </ref> , we treat the problem of map learning given a probabilistic oracle which, for any given traversal, provides an answer to the question "was that traversal free of error" which is correct with probability greater than 1 2 .
Reference: [ Brooks, 1984 ] <author> Rodney A. Brooks. </author> <title> Aspects of mobile robot visual map making. </title> <editor> In H. Hana-fusa and H. Inoue, editors, </editor> <booktitle> Second International Symposium on Robotics Research, </booktitle> <pages> pages 325-331, </pages> <address> Cambridge, Massachusetts, 1984. </address> <publisher> MIT Press. </publisher>
Reference: [ Davis, 1986 ] <author> Ernest Davis. </author> <title> Representing and Acquiring Geographic Knowledge. </title> <publisher> Morgan-Kaufmann, </publisher> <address> Los Altos, California, </address> <year> 1986. </year>
Reference: [ Dean, 1988 ] <author> Thomas Dean. </author> <title> On the complexity of integrating spatial measurements. </title> <booktitle> In Proceedings of the SPIE Conference on Advances in Intelligent Robotic Systems. SPIE, </booktitle> <year> 1988. </year>
Reference-contexts: In this paper, we explore a number of problems involved in constructing useful maps from measurements taken with sensors subject to known errors. In previous work <ref> [ Dean, 1988 ] </ref> , we have looked at various optimization problems related to constructing maps (e.g., construct the most accurate map consistent with a set of measurements). Even in cases involving only a single dimension, such optimization problems can turn out to be NP-hard [ Yemini, 1979 ] .
Reference: [ Dudek et al., 1988 ] <author> Gregory Dudek, Michael Jenkins, Evangelos Milios, and David Wilkes. </author> <title> Robotic exploration as graph construction. </title> <type> Technical Report RBCV-TR-88-23, </type> <institution> University of Toronto, </institution> <year> 1988. </year>
Reference-contexts: Another way around this restriction is to allow the exploring agent to drop pebbles or beacons to remember where it has been <ref> [ Dudek et al., 1988 ] </ref> . We can make map learning somewhat easier and more realistic by assuming that the robot can do more work or take more time to get better measurements.
Reference: [ Durrant-Whyte, 1988 ] <author> Hugh F. Durrant-Whyte. </author> <title> Integration, Coordination and Control of Multi-Sensor Robot Systems. </title> <publisher> Kluwer, </publisher> <address> Boston, Massachusetts, </address> <year> 1988. </year>
Reference: [ Graham et al., 1994 ] <author> Ronald L. Graham, Donald E. Knuth, and Patashnik Oren. </author> <title> Concrete Mathematics. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, 2nd edition, </address> <year> 1994. </year>
Reference-contexts: Proof: This is a variation on the Coupon Collector's problem (see <ref> [ Graham et al., 1994 ] </ref> ). We consider only the traversals resulting from leaving the vertex, thus each visit to the vertex results in the traversal of one edge chosen at random. <p> (see <ref> [ Graham et al., 1994 ] </ref> ). We consider only the traversals resulting from leaving the vertex, thus each visit to the vertex results in the traversal of one edge chosen at random. The expected number of visits required for traversing all edges at least once is shown in [ Graham et al., 1994 ] to be dH d &lt; d ln d + d, where H d is the value of the harmonic function at d.
Reference: [ Hoeffding, 1963 ] <author> W. Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58 </volume> <pages> 13-30, </pages> <year> 1963. </year>
Reference-contexts: The quantity count (P ) is a Bernoulli distributed random variable corresponding to n trials, each with probability fl true of success; it has mean nfl true and standard deviation (nfl true (1 fl true )) 1=2 . By Hoeffding's inequality <ref> [ Hoeffding, 1963 ] </ref> we have Pr (error on P ) = Pr (count (P ) nfl true n (fl true t )) e 2n (fl true t ) 2 : Substituting fl true t ff k1 (ff 1 2 ) ff cr1 (ff 1 2 ), we find that Pr
Reference: [ Kuipers and Byun, 1988 ] <author> Benjamin J. Kuipers and Yung-Tai Byun. </author> <title> A robust, qualitative method for robot spatial reasoning. </title> <booktitle> In Proceedings AAAI-88, </booktitle> <pages> pages 774-779. </pages> <publisher> AAAI, </publisher> <year> 1988. </year>
Reference-contexts: In this paper, we are concerned with strategies which, with high probability, provide local certainty. Most existing map-learning schemes exploit this sort of certainty in one way or another (see Section 4). The rehearsal strategies of Kuipers <ref> [ Kuipers and Byun, 1988 ] </ref> are one example of how a robot might plan to eliminate uncertainty. Once we have a method for eliminating uncertainty, the problem then reduces to one of planning out and executing the necessary experiments to extract certain information about the environment. <p> In this section, we consider three related approaches. Kuipers defines the notion of "place" in terms of a set of related visual events [ Kuipers, 1978 ] . This notion provides a basis for inducing graphs from measurements. In Kuipers' framework <ref> [ Kuipers and Byun, 1988 ] </ref> , locations are arranged in an unrestricted planar graph.
Reference: [ Kuipers, 1978 ] <author> Benjamin Kuipers. </author> <title> Modeling spatial knowledge. </title> <journal> Cognitive Science, </journal> <volume> 2 </volume> <pages> 129-153, </pages> <year> 1978. </year>
Reference-contexts: In this section, we consider three related approaches. Kuipers defines the notion of "place" in terms of a set of related visual events <ref> [ Kuipers, 1978 ] </ref> . This notion provides a basis for inducing graphs from measurements. In Kuipers' framework [ Kuipers and Byun, 1988 ] , locations are arranged in an unrestricted planar graph.
Reference: [ Levitt et al., 1987 ] <author> Tod S. Levitt, Daryl T. Lawton, David M. Chelberg, and Philip C. Nelson. </author> <title> Qualitative landmark-based path planning and following. </title> <booktitle> In Proceedings AAAI-87, </booktitle> <pages> pages 689-694. </pages> <publisher> AAAI, </publisher> <year> 1987. </year>
Reference-contexts: Given a procedure that is guaranteed to uniquely identify a location if it succeeds, and succeeds with high probability, we can show that a Kuipers-style map can be reliably probably almost always usefully learned using an analysis similar to that of Section 3. Levitt et al <ref> [ Levitt et al., 1987 ] </ref> describe an approach to spatial reasoning that avoids 29 multiplicative error by introducing local coordinate systems based on landmarks. Land--marks correspond to environmental features that can be acquired and, more importantly, reacquired in exploring the environment.
Reference: [ McDermott and Davis, 1982 ] <author> Drew V. McDermott and Ernest Davis. </author> <title> Planning routes through uncertain territory. </title> <journal> Artificial Intelligence, </journal> <volume> 22 </volume> <pages> 107-156, </pages> <year> 1982. </year>
Reference: [ Moravec and Elfes, 1985 ] <author> H. P. Moravec and A. Elfes. </author> <title> High resolution maps from wide angle sonar. </title> <booktitle> In IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 138-145, </pages> <year> 1985. </year>
Reference: [ Rivest and Sloan, 1994 ] <author> Ronald L. Rivest and Robert Sloan. </author> <title> A formal model of hierarchical concept learning. </title> <journal> Information and Computation, </journal> <volume> 114(1) </volume> <pages> 88-114, </pages> <year> 1994. </year>
Reference-contexts: We have found, however, that some existing models for learning are applicable to map learning. In particular, we consider forms of probabilistic learning such as probably approximately correct learning [ Valiant, 1984 ] and reliable and probably almost always useful learning <ref> [ Rivest and Sloan, 1994 ] </ref> in which the robot gathers information to ensure that it nearly always (with probability 1 ffi) can provide a probably good or guaranteed perfect path from one location to another. <p> The above approach to map learning was inspired by Rivest's model of learning <ref> [ Rivest and Sloan, 1994 ] </ref> , in which complex problems are broken down into simple subproblems that can be learned independently.
Reference: [ Smith and Cheeseman, 1986 ] <author> Randall Smith and Peter Cheeseman. </author> <title> On the representation and estimation of spatial uncertainty. </title> <journal> The International Journal of Robotics Research, </journal> <volume> 5 </volume> <pages> 56-68, </pages> <year> 1986. </year>
Reference: [ Valiant, 1984 ] <author> L. G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Communications of the ACM, </journal> <volume> 27 </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference-contexts: We have found, however, that some existing models for learning are applicable to map learning. In particular, we consider forms of probabilistic learning such as probably approximately correct learning <ref> [ Valiant, 1984 ] </ref> and reliable and probably almost always useful learning [ Rivest and Sloan, 1994 ] in which the robot gathers information to ensure that it nearly always (with probability 1 ffi) can provide a probably good or guaranteed perfect path from one location to another.
Reference: [ Yemini, 1979 ] <author> Yechiam Yemini. </author> <title> Some theoretical aspects of position-location problems. </title> <booktitle> In Proceedings of the 20th Symposium on the Foundations of Computer Science, </booktitle> <pages> pages 1-7, </pages> <year> 1979. </year>
Reference-contexts: In previous work [ Dean, 1988 ] , we have looked at various optimization problems related to constructing maps (e.g., construct the most accurate map consistent with a set of measurements). Even in cases involving only a single dimension, such optimization problems can turn out to be NP-hard <ref> [ Yemini, 1979 ] </ref> . In this paper, rather than look at problems that involve doing the best with what you have, we consider problems that involve going out and getting what you need to generate useful representations.
References-found: 18

