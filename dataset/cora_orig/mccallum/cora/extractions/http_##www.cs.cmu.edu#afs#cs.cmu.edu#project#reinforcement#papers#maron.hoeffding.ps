URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/reinforcement/papers/maron.hoeffding.ps
Refering-URL: http://www.cs.cmu.edu/~awm/papers.html
Root-URL: 
Email: oded@ai.mit.edu  awm@ai.mit.edu  
Title: Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation  
Author: Oded Maron Andrew W. Moore 
Address: NE43-755, 545 Tech. Sq. Cambridge, MA 02139  NE43-752, 545 Tech. Sq. Cambridge, MA 02139  
Affiliation: MIT AI Lab  MIT AI Lab  
Abstract: Selecting a good model of a set of input points by cross validation is a computationally intensive process, especially if the number of possible models or the number of training points is high. Techniques such as gradient descent are helpful in searching through the space of models, but problems such as local minima, and more importantly, lack of a distance metric between various models reduce the applicability of these search methods. Hoeffding Races is a technique for finding a good model for the data by quickly discarding bad models, and concentrating the computational effort at differentiating between the better ones. This paper focuses on the special case of leave-one-out cross validation applied to memory-based learning algorithms, but we also argue that it is applicable to any class of model selection problems. 
Abstract-found: 1
Intro-found: 1
Reference: [ Atkeson and Reinkensmeyer, 1989 ] <author> C. G. Atkeson and D. J. Reinkensmeyer. </author> <title> Using associative content-addressable 6 tial learning boxes vs number of queries to find a good model for the ROBOT problem. The bottom line shows performance by the Hoeffd ing Race algorithm, and the top line by brute force . memories to control robots. </title> <editor> In W. T. Miller, R. S. Sutton, and P. J. Werbos, editors, </editor> <title> Neural Networks for Control. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference: [ Breiman et al., 1984 ] <author> L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. </author> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <year> 1984. </year>
Reference: [ Greiner and Jurisica, 1992 ] <author> R. Greiner and I. Jurisica. </author> <title> A statistical approach to solving the EBL utility problem. </title> <booktitle> In Proceedings of the Tenth International conference on Artificial Intelligence (AAAI-92). </booktitle> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: For a discussion of how to generate various memory-based models, see [ Moore et al., 1992 ] . 2 Hoeffding Races The algorithm was inspired by ideas from [ Haussler, 1992 ] and [ Kaelbling, 1990 ] and a similar idea appears in <ref> [ Greiner and Jurisica, 1992 ] </ref> . It derives its name from Hoeffding's formula [ Hoeffding, 1963 ] , which concerns our confidence in the sample mean of n independently drawn points x 1 ; :::; x n .
Reference: [ Haussler, 1992 ] <author> D. Haussler. </author> <title> Decision theoretic generalizations of the pac model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100 </volume> <pages> 78-150, </pages> <year> 1992. </year>
Reference-contexts: For a discussion of how to generate various memory-based models, see [ Moore et al., 1992 ] . 2 Hoeffding Races The algorithm was inspired by ideas from <ref> [ Haussler, 1992 ] </ref> and [ Kaelbling, 1990 ] and a similar idea appears in [ Greiner and Jurisica, 1992 ] .
Reference: [ Hoeffding, 1963 ] <author> Wassily Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 58 </volume> <pages> 13-30, </pages> <year> 1963. </year>
Reference-contexts: It derives its name from Hoeffding's formula <ref> [ Hoeffding, 1963 ] </ref> , which concerns our confidence in the sample mean of n independently drawn points x 1 ; :::; x n .
Reference: [ Kaelbling, 1990 ] <author> L. P. Kaelbling. </author> <title> Learning in Embedded Systems. </title> <type> PhD. Thesis; Technical Report No. </type> <institution> TR-90-04, Stanford University, Department of Computer Science, </institution> <month> June </month> <year> 1990. </year>
Reference-contexts: For a discussion of how to generate various memory-based models, see [ Moore et al., 1992 ] . 2 Hoeffding Races The algorithm was inspired by ideas from [ Haussler, 1992 ] and <ref> [ Kaelbling, 1990 ] </ref> and a similar idea appears in [ Greiner and Jurisica, 1992 ] . It derives its name from Hoeffding's formula [ Hoeffding, 1963 ] , which concerns our confidence in the sample mean of n independently drawn points x 1 ; :::; x n .
Reference: [ Moore et al., 1992 ] <author> A. W. Moore, D. J. Hill, and M. P. Johnson. </author> <title> An empirical investigation of brute force to choose features, smoothers and function approximators. </title> <editor> In S. Hanson, S. Judd, and T. Petsche, editors, </editor> <booktitle> Computational Learning Theory and Natural Learning Systems, </booktitle> <volume> Volume 3. </volume> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: Finding the leave-one-out cross validation error at a point is cheap as making a prediction: simply "cover up" that point in memory, then predict its value using the current model. For a discussion of how to generate various memory-based models, see <ref> [ Moore et al., 1992 ] </ref> . 2 Hoeffding Races The algorithm was inspired by ideas from [ Haussler, 1992 ] and [ Kaelbling, 1990 ] and a similar idea appears in [ Greiner and Jurisica, 1992 ] .
Reference: [ Moore, 1992 ] <author> A. W. Moore. </author> <title> Fast, robust adaptive control by learning only forward models. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4. </booktitle> <publisher> Morgan Kaufmann, </publisher> <month> April </month> <year> 1992. </year>
Reference-contexts: This is taken from the Building Energy Predictor Shootout. POWER Market data for electricity generation pricing period class for the new United Kingdom Power Market. POOL The visually perceived mapping from pool table configurations to shot out come for two-ball collisions <ref> [ Moore, 1992 ] </ref> . DISCONT An artificially constructed set of points with many discontinuities. Local models should outperform global ones. Table 1: Test problems good learning boxes, and eliminating the bad ones.
Reference: [ Pollard, 1984 ] <author> David Pollard. </author> <title> Convergence of Stochastic Processes. </title> <publisher> Springer-Verlag, </publisher> <year> 1984. </year> <month> 7 </month>
Reference: [ Schaal and Atkeson, 1993 ] <author> S. Schaal and C. G. Atkeson. </author> <title> Open loop stable control strategies for robot juggling. </title> <booktitle> In Proceedings of IEEE conference on Robotics and Automation, </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: The intervals get smaller as more points are tested, thereby "racing" the 4 Problem Description ROBOT 10 input attributes, 5 outputs. Given an initial and a final description of a robot arm, learn the control needed in order to make the robot perform devil-sticking <ref> [ Schaal and Atkeson, 1993 ] </ref> . PROTEIN 3 inputs, output is a classification into one of three classes. This is the famous protein secondary structure database, with some preprocessing [ Zhang et al., 1992 ] . ENERGY Given solar radiation sensing, predict the cooling load for a building.
Reference: [ Stanfill and Waltz, 1986 ] <author> C. Stanfill and D. Waltz. </author> <title> Towards memory-based reasoning. </title> <journal> Communications of the ACM, </journal> <volume> 29(12) </volume> <pages> 1213-1228, </pages> <month> December </month> <year> 1986. </year>
Reference: [ Wahba and Wold, 1975 ] <author> G. Wahba and S. </author> <title> Wold. A completely automatic french curve: Fitting spline functions by cross-validation. </title> <journal> Communications in Statistics, </journal> <volume> 4(1), </volume> <year> 1975. </year>
Reference-contexts: Presentation Preference: oral. Category: Algorithms and Architectures | Learning Algorithms. 1 model, or smoothness. In this paper, this criterion will be prediction accuracy. Let us examine two common ways of measuring accuracy : using a test set and leave-one-out cross validation <ref> [ Wahba and Wold, 1975 ] </ref> . * The test set method arbitrarily divides the data into a training set and a test set. The learner is trained on the training set, and is then queried with just the input vectors of the test set.
Reference: [ Zhang et al., 1992 ] <author> X. Zhang, J.P. Mesirov, and D.L. Waltz. </author> <title> Hybrid system for protein secondary structure prediction. </title> <journal> Journal of Molecular Biology, </journal> <volume> 225 </volume> <pages> 1049-1063, </pages> <year> 1992. </year> <month> 8 </month>
Reference-contexts: PROTEIN 3 inputs, output is a classification into one of three classes. This is the famous protein secondary structure database, with some preprocessing <ref> [ Zhang et al., 1992 ] </ref> . ENERGY Given solar radiation sensing, predict the cooling load for a building. This is taken from the Building Energy Predictor Shootout. POWER Market data for electricity generation pricing period class for the new United Kingdom Power Market.
References-found: 13

