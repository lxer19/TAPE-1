URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/mu.ps
Refering-URL: http://www.csc.ncsu.edu/faculty/mpsingh/papers/mas/
Root-URL: http://www.csc.ncsu.edu
Email: singh@ncsu.edu  
Title: Applying the Mu-Calculus in Planning and Reasoning about Action  
Author: Munindar P. Singh 
Address: Box 7534  Raleigh, NC 27695-7534, USA  
Affiliation: Department of Computer Science  North Carolina State University  
Abstract: Planning algorithms have traditionally been geared toward achievement goals in single-agent environments. Such algorithms essentially produce plans to reach one of a specified set of states. More general approaches for planning based on temporal logic (TL) are emerging. Current approaches tend to use linear TL, and can handle sets of sequences of states. However, they assume deterministic actions with all changes effected solely by one agent. By contrast, we use a branching model of time that can express concurrent actions by multiple agents and the environment, leading to nondeterministic effects of an agent's actions. For this reason, we view plans not as sequences of actions, but as decision graphs describing the agent's actions in different situations. Thus, although we consider single-agent decision graphs, our approach is better suited to multiagent systems. We also consider an expressive formalism, which allows a wider variety of goals, including achievement and maintenance goals. Achievement corresponds to traditional planning, but maintenance is more powerful than traditional maintenance goals, and may require nonterminating plans. To formalize decision graphs requires a means to "alternate" the agent's and the environment's choices. From logics of program, we introduce the propositional mu-calculus, which has operators for least and greatest fixpoints. We give a semantics, a fixpoint characterization, and an algorithm to compute decision graphs. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Fahiem Bacchus and Froduald Kabanza. </author> <title> Planning for temporally extended goals. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 1215-1222, </pages> <year> 1996. </year>
Reference-contexts: For instance, dynamic logic was introduced into the AI and logics of program communities at about the same time. The applicability of temporal 1 logic techniques in planning is well recognized and is studied by several researchers, for example, Bacchus & Kabanza <ref> [1] </ref>. Planning and reasoning about action are widely regarded as among the key components of intelligent agency, and are ideal targets for the application of formal techniques. This paper studies these subjects in an abstract setting. <p> Traditionally, planners have considered tasks that correspond to simple goals of achievement, which are satisfied when a desired state is reached. However, it is now recognized that temporally extended goals are often necessary, for example, see Bacchus & Kabanza <ref> [1] </ref>. These goals are satisfied when a desired sequence of states is achieved. Although achievement goals are usually considered, we can also allow maintenance goals. <p> The present approach shows how algorithms can be derived from the semantics of those operators. Bacchus & Kabanza define goals as sequences of states, and develop an algorithm to produce plans that satisfy such goals <ref> [1] </ref>. The heart of their approach is a progression algorithm, which given formulae for a state, derives formulae for the next state. This assumes that actions are deterministic, and changes to the environment are brought about solely by the agent (p. 1217).
Reference: [2] <author> Chitta Baral. </author> <title> Reasoning about actions: Non-deterministic effects, constraints, and qualification. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 2017-2023, </pages> <year> 1995. </year>
Reference-contexts: The problem of modeling concurrent events and their effects was also considered in an abstract setting by Georgeff, who developed an approach based on persistence and causality [13]. More recent approaches, for example, by Baral <ref> [2] </ref> and Thielscher [28], seek to characterize the effects of actions in different circumstances. Complexity. The complexity of the above approach has not been carefully studied. It relies on having a finite set of moments to explore.
Reference: [3] <author> Nuel Belnap and Michael Perloff. </author> <title> Seeing to it that: A canonical form for agen-tives. </title> <journal> Theoria, </journal> <volume> 54(3) </volume> <pages> 175-199, </pages> <year> 1988. </year>
Reference-contexts: This basic idea is common in theories of know-how (to achieve a condition), for example, see Singh [26] and seeing-to-it-that, for example, see Belnap & Perloff <ref> [3] </ref> and Chellas [7]. However, existing theories tend to focus exclusively on achieving a condition, rather than maintaining one, or achieving and then maintaining a condition. <p> In contrast, the second class is situated and considers the ability as manifest in the opportunities of the given situation. Here, the ability and opportunity go hand-in-hand, and an agent cannot have one without the other. This class is exemplified by Belnap & Perloff <ref> [3] </ref>, Chellas [7], and Singh [26]. Our present approach is in the latter category. This facilitates reading the figures and examples below: what you see is what you get! 3.1 Achievement Intuitively, an agent knows how to achieve a condition if he can knowingly force it to become true. <p> Georgeff proposed process models to represent how the actions were selected by different agents. He also suggested the use of model-based as opposed to axiomatic techniques for reasoning about the relationships among process models. Singh [26] and Belnap & Perloff <ref> [3] </ref> define operators, but do not develop algorithms to compute them. The present approach shows how algorithms can be derived from the semantics of those operators. Bacchus & Kabanza define goals as sequences of states, and develop an algorithm to produce plans that satisfy such goals [1].
Reference: [4] <author> Girish Bhat and Rance Cleaveland. </author> <title> Efficient model checking via the equational mu-calculus. </title> <booktitle> In Proceedings of the 11th International Symposium on Logic in Computer Science, </booktitle> <pages> pages 304-312, </pages> <year> 1996. </year> <month> 21 </month>
Reference-contexts: Fixpoints are well-suited to describing important concepts from planning. An expanding body of research exists to construct efficient tools for the mu-calculus and TL, which can be marshaled for planning. Recent examples include Bhat & Cleaveland <ref> [4] </ref>, Clarke et al. [8], and Holzmann [14].
Reference: [5] <author> Susanne Biundo and Werner Stephan. </author> <title> Modeling planning domains systemati-cally. </title> <booktitle> In Proceedings of the European Conference on Artificial Intelligence, </booktitle> <pages> pages 599-603, </pages> <year> 1996. </year>
Reference-contexts: We believe it could be fruitfully combined with our approach. 20 Another use of TL in planning involves modeling actions as procedural programs in the style of Algol, for instance, and using conventional TL techniques for proving properties about them. Biundo & Stephan <ref> [5] </ref> and Lukaszewicz & Madalinska-Bugaj [17] develop such approaches. Singh introduced the mu-calculus for reasoning about action and developed a model-checking approach [25].
Reference: [6] <author> Mark A. Brown. </author> <title> Action and ability. </title> <journal> Journal of Philosophical Logic, </journal> <volume> 19 </volume> <pages> 95-114, </pages> <year> 1990. </year>
Reference-contexts: Broadly put, there are two main classes of approaches to know-how, discussed at length in [27]. One class follows traditional philosophical intuitions in separating ability from opportunity, for example, Brown <ref> [6] </ref> and van der Hoek et al. [29]. This class of approaches preserves the natural language meaning of knowing how to do something even if one cannot actually do it. However, this naturalness comes at the price of defining know-how based on counterfactual situations.
Reference: [7] <author> Brian F. Chellas. </author> <title> Time and modality in the logic of agency. </title> <journal> Studia Logica, </journal> 51(3/4):485-517, 1992. 
Reference-contexts: This basic idea is common in theories of know-how (to achieve a condition), for example, see Singh [26] and seeing-to-it-that, for example, see Belnap & Perloff [3] and Chellas <ref> [7] </ref>. However, existing theories tend to focus exclusively on achieving a condition, rather than maintaining one, or achieving and then maintaining a condition. <p> Finally, Section 5 derives a fixpoint characterization of maintenance and outlines an algorithm to compute maintenance plans. Throughout, we relate our approach to one for achievement. 2 The Technical Framework The framework described below combines time and nondeterministic actions; it is related to the frameworks of Chellas <ref> [7] </ref>, Rao & Georgeff [21], and Singh [26]. We consider discrete time with concurrent, unit-length atomic actions. As a consequence, there is a finite number of actions between any pair of connected moments. moment defines a unique possible state of the world. <p> In contrast, the second class is situated and considers the ability as manifest in the opportunities of the given situation. Here, the ability and opportunity go hand-in-hand, and an agent cannot have one without the other. This class is exemplified by Belnap & Perloff [3], Chellas <ref> [7] </ref>, and Singh [26]. Our present approach is in the latter category. This facilitates reading the figures and examples below: what you see is what you get! 3.1 Achievement Intuitively, an agent knows how to achieve a condition if he can knowingly force it to become true.
Reference: [8] <author> E. Clarke, O. Grumberg, and D. </author> <title> Long. Model checking. </title> <booktitle> In Proceedings of the International Summer School on Deductive Program Design, </booktitle> <pages> pages 428-439, </pages> <year> 1990. </year>
Reference-contexts: The latter approach, which we adapt,has proved particularly effective in program verification <ref> [8] </ref>. We discuss maintenance at length and then show how achievement can be similarly handled. Given a model, describing moments and actions among them, and a formula, describing a goal, we compute the set of moments at which the formula holds. <p> Fixpoints are well-suited to describing important concepts from planning. An expanding body of research exists to construct efficient tools for the mu-calculus and TL, which can be marshaled for planning. Recent examples include Bhat & Cleaveland [4], Clarke et al. <ref> [8] </ref>, and Holzmann [14].
Reference: [9] <author> Giuseppe De Giacomo and Xiao Jun Chen. </author> <title> Reasoning about nondeterministic and concurrent actions: A process algebra approach. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 658-663, </pages> <year> 1996. </year>
Reference-contexts: Biundo & Stephan [5] and Lukaszewicz & Madalinska-Bugaj [17] develop such approaches. Singh introduced the mu-calculus for reasoning about action and developed a model-checking approach [25]. Independently, De Giacomo & Chen <ref> [9] </ref> give a mu-calculus characterization of plans, which however is based on a process algebra reminiscent of Milner's CCS [19], rather than an explicit branching-time logic as in the present approach. Both of the above approaches assume a fully specified model, instead of constructing one incrementally as here. Future Directions.
Reference: [10] <author> Dietmar Dengler. </author> <title> Customized plans transmitted by flexible refinement. </title> <booktitle> In Proceedings of the European Conference on Artificial Intelligence, </booktitle> <pages> pages 609-613, </pages> <year> 1996. </year>
Reference-contexts: This approach also involves depth-first search, but focuses exclusively on achievement goals. Dengler also uses TL to go beyond traditional achievement planners, but he focuses on enhancing the interactivity of the planner with a human user <ref> [10] </ref>. This approach is quite sophisticated in considering the stepwise refinement of plans, although the underlying framework is linear.
Reference: [11] <author> E. Allen Emerson. </author> <title> Temporal and modal logic. </title> <editor> In Jan van Leeuwen, editor, </editor> <booktitle> Handbook of Theoretical Computer Science, </booktitle> <volume> volume B, </volume> <pages> pages 995-1072. </pages> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1990. </year>
Reference-contexts: Previous TL approaches assume that all changes in the environment are caused by the agent through deterministic actions. We propose a relaxed approach that allows concurrent actions by different agents. This leads naturally to a model of time that allows multiple future paths from each moment <ref> [11] </ref>. Plans in such a model cannot be sequences of actions, but must be decision trees or graphs that describe the agent's actions under different situations. Branching TLs include path quantifiers, which allow us to make assertions about all or some of the paths. <p> This logical 2 alternation cannot be readily captured in TLs, because different parties have to choose alternating actions. For example, if a goal like AGEFp (in the notation of CTL <ref> [11] </ref>, and formally defined below) is considered, then it is not clear what is being planned by the agent and what arises due to environmental effects. <p> A benefit of our approach is that the nature of the goal is itself expressed in the object language. Thus goals can be nested, for example, "achieve a state where the agent can maintain a condition." We choose a formal language related to CTL fl and dynamic logic <ref> [11] </ref> as popularized in the AI community by, among others, Rao & Georgeff [21] and Singh [26]. Another option would be the situation calculus, whose recent versions even allow concurrency, nondeterminism, and even continuity, for example, see Miller [18] and Reiter [23]. <p> Hence, the partial order of temporal precedence may be represented as having cycles: this representation saves repetition in computation. 2.1 Syntax ACTL fl ("A" for actions), our formal language, enhances CTL fl , a branching-time logic <ref> [11] </ref>. ACT L fl is an auxiliary definition and includes the "path-formulae." Below, is a set of atomic propositional symbols and X is a set of agent symbols. <p> Maintenance is not the formal dual of know-how to achieve p. Since maintenance resembles traditional safety properties, one might wonder if it is a dual of the corresponding achievement, that is, liveness, concept <ref> [11] </ref>. But it is not so. Just because an agent does not know how to achieve :p does not entail that other agents do not know how to achieve :p. Thus if the other agents exercise their know-how, the given agent is unable to maintain p.
Reference: [12] <author> Michael P. Georgeff. </author> <title> A theory of action for multiagent planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 121-125, </pages> <year> 1984. </year>
Reference-contexts: We mention only some selected works relating TL and planning. (TL approaches to be distinguished from temporal reasoning in general, which all planners must perform to some degree.) One of the first applications of classical techniques in planning was identified by Georgeff <ref> [12] </ref>. Georgeff proposed process models to represent how the actions were selected by different agents. He also suggested the use of model-based as opposed to axiomatic techniques for reasoning about the relationships among process models. <p> We have taken some early steps in formalizing plans for multiagent environments. Much of our technical development considers the plans of a single agent, but by allowing branching and nondeterminism, it enables planning in multiagent environments. In this way, it is similar in style to <ref> [12, 13] </ref>. We leave it to future research to formalize ideas from cooperative planning to the same level of detail as carried out above. Acknowledgments The author benefited greatly from some early discussions with Allen Emerson, and from meticulous comments by the anonymous reviewers.
Reference: [13] <author> Michael P. Georgeff. </author> <title> The representation of events in multi-agent domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 70-75, </pages> <year> 1986. </year>
Reference-contexts: The problem of modeling concurrent events and their effects was also considered in an abstract setting by Georgeff, who developed an approach based on persistence and causality <ref> [13] </ref>. More recent approaches, for example, by Baral [2] and Thielscher [28], seek to characterize the effects of actions in different circumstances. Complexity. The complexity of the above approach has not been carefully studied. It relies on having a finite set of moments to explore. <p> We have taken some early steps in formalizing plans for multiagent environments. Much of our technical development considers the plans of a single agent, but by allowing branching and nondeterminism, it enables planning in multiagent environments. In this way, it is similar in style to <ref> [12, 13] </ref>. We leave it to future research to formalize ideas from cooperative planning to the same level of detail as carried out above. Acknowledgments The author benefited greatly from some early discussions with Allen Emerson, and from meticulous comments by the anonymous reviewers.
Reference: [14] <author> Gerard J. Holzmann. </author> <title> The model checker SPIN. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 23(5) </volume> <pages> 279-296, </pages> <month> May </month> <year> 1997. </year>
Reference-contexts: Fixpoints are well-suited to describing important concepts from planning. An expanding body of research exists to construct efficient tools for the mu-calculus and TL, which can be marshaled for planning. Recent examples include Bhat & Cleaveland [4], Clarke et al. [8], and Holzmann <ref> [14] </ref>. Our approach is orthogonal to how one determines the formulae true in each state in the post-image of an action, but one can assume a theory of actions with fully specified effects for this purpose, such as that of Schubert [24], with some enhancements to allow nondeterminism.
Reference: [15] <author> David Kinny and Michael P. Georgeff. </author> <title> Modelling and design of multi-agent systems. In Intelligent Agents III: Agent Theories, Architectures, </title> <booktitle> and Languages, </booktitle> <pages> pages 1-20, </pages> <year> 1997. </year>
Reference-contexts: The idea of maintenance also emerges in implemented planning systems, which from the time of Waldinger [30] have considered maintenance as a key functionality in constructing effective plans, especially when more than one goal must be brought about. Maintenance features also in the dMARS system <ref> [15] </ref>. It is therefore quite interesting that maintenance has not received corresponding attention in the formal reasoning about action community. Consequently, implemented systems usually handle maintenance in a seat-of-the-pants manner. Previous TL approaches assume that all changes in the environment are caused by the agent through deterministic actions.
Reference: [16] <author> Dexter Kozen. </author> <title> Results on the propositional -calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 27 </volume> <pages> 333-354, </pages> <year> 1983. </year>
Reference-contexts: Approach. However, this effect is obtained by specifying the desired behavior in terms of the propositional mu-calculus, or the mu-calculus, for short <ref> [16] </ref>. The mu-calculus includes operators to specify the greatest and least fixpoints of expressions. It leads to a succinct formulation of achievement and maintenance goals. Algorithms to compute mu-calculus expressions exist, and can be adapted for planning. The mu-calculus is a generalization of temporal and dynamic logics.
Reference: [17] <author> Witold Lukaszewicz and Ewa Madalinska-Bugaj. </author> <title> Reasoning about action and change using Dijkstra's semantics for programming languages: Preliminary report. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1950-1955, </pages> <year> 1995. </year>
Reference-contexts: We believe it could be fruitfully combined with our approach. 20 Another use of TL in planning involves modeling actions as procedural programs in the style of Algol, for instance, and using conventional TL techniques for proving properties about them. Biundo & Stephan [5] and Lukaszewicz & Madalinska-Bugaj <ref> [17] </ref> develop such approaches. Singh introduced the mu-calculus for reasoning about action and developed a model-checking approach [25].
Reference: [18] <author> Rob Miller. </author> <title> A case study in reasoning about actions and continuous change. </title> <booktitle> In Proceedings of the European Conference on Artificial Intelligence, </booktitle> <pages> pages 624-628, </pages> <year> 1996. </year>
Reference-contexts: Another option would be the situation calculus, whose recent versions even allow concurrency, nondeterminism, and even continuity, for example, see Miller <ref> [18] </ref> and Reiter [23]. However, we would need additional extensions to these approaches to allow path quantifiers and operators for fixpoints as in our approach. Although fixpoint calculations are commonly used implicitly in the interpreters of the logic programming languages, explicit fixpoint calculations as developed here are less common there.
Reference: [19] <author> Robin Milner. </author> <title> Communication and Concurrency. </title> <booktitle> Prentice-Hall International, </booktitle> <address> Hemel Hempstead, UK, </address> <year> 1989. </year> <month> 22 </month>
Reference-contexts: Singh introduced the mu-calculus for reasoning about action and developed a model-checking approach [25]. Independently, De Giacomo & Chen [9] give a mu-calculus characterization of plans, which however is based on a process algebra reminiscent of Milner's CCS <ref> [19] </ref>, rather than an explicit branching-time logic as in the present approach. Both of the above approaches assume a fully specified model, instead of constructing one incrementally as here. Future Directions.
Reference: [20] <author> Cyril Pain-Barre. DEDAL: </author> <title> A deductive and algorithmic planning system. </title> <booktitle> In Proceedings of the European Conference on Artificial Intelligence, </booktitle> <pages> pages 629-633, </pages> <year> 1996. </year>
Reference-contexts: In a fundamental sense, we capture intuitions similar to temporal progression, but extend them to branching, nondeterministic models. Bacchus & Kabanza allow metric goals, which we believe can be added to our approach as well. Pain-Barre <ref> [20] </ref> combines heuristic planning with a deductive approach to world changes due to actions. This approach also involves depth-first search, but focuses exclusively on achievement goals.
Reference: [21] <author> Anand S. Rao and Michael P. Georgeff. </author> <title> Asymmetry thesis and side-effect problems in linear-time and branching-time intention logics. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), </booktitle> <pages> pages 498-504, </pages> <year> 1991. </year>
Reference-contexts: Thus goals can be nested, for example, "achieve a state where the agent can maintain a condition." We choose a formal language related to CTL fl and dynamic logic [11] as popularized in the AI community by, among others, Rao & Georgeff <ref> [21] </ref> and Singh [26]. Another option would be the situation calculus, whose recent versions even allow concurrency, nondeterminism, and even continuity, for example, see Miller [18] and Reiter [23]. However, we would need additional extensions to these approaches to allow path quantifiers and operators for fixpoints as in our approach. <p> Throughout, we relate our approach to one for achievement. 2 The Technical Framework The framework described below combines time and nondeterministic actions; it is related to the frameworks of Chellas [7], Rao & Georgeff <ref> [21] </ref>, and Singh [26]. We consider discrete time with concurrent, unit-length atomic actions. As a consequence, there is a finite number of actions between any pair of connected moments. moment defines a unique possible state of the world. The term state is used informally in the literature.
Reference: [22] <author> Anand S. Rao and Michael J. Wooldridge, </author> <title> editors. Foundations and Theories of Rational Agency. Applied Logic Series. </title> <publisher> Kluwer, </publisher> <address> Dordrecht, </address> <year> 1998. </year>
Reference: [23] <author> Raymond Reiter. </author> <title> Natural actions, concurrency and continuous time in the situation calculus. </title> <booktitle> In Proceedings of the Third Symposium on Logical Formalizations of Commonsense Reasoning, </booktitle> <year> 1996. </year>
Reference-contexts: Another option would be the situation calculus, whose recent versions even allow concurrency, nondeterminism, and even continuity, for example, see Miller [18] and Reiter <ref> [23] </ref>. However, we would need additional extensions to these approaches to allow path quantifiers and operators for fixpoints as in our approach. Although fixpoint calculations are commonly used implicitly in the interpreters of the logic programming languages, explicit fixpoint calculations as developed here are less common there. Organization.
Reference: [24] <author> Lenhart Schubert. </author> <title> Monotonic solution of the frame problem in the situation calculus: An efficient method for worlds with fully specified actions. </title> <editor> In Henry E. Kyburg, Ron Loui, and Greg Carlson, editors, </editor> <booktitle> Knowledge Representation and Defeasible Reasoning, </booktitle> <pages> pages 23-67. </pages> <publisher> Kluwer, </publisher> <year> 1990. </year>
Reference-contexts: Our approach is orthogonal to how one determines the formulae true in each state in the post-image of an action, but one can assume a theory of actions with fully specified effects for this purpose, such as that of Schubert <ref> [24] </ref>, with some enhancements to allow nondeterminism. The problem of modeling concurrent events and their effects was also considered in an abstract setting by Georgeff, who developed an approach based on persistence and causality [13].
Reference: [25] <author> Munindar P. Singh. </author> <title> Maintenance and prevention: Formalization and fixpoint characterization. </title> <booktitle> In Proceedings of the ECAI Workshop on Logic and Change, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Biundo & Stephan [5] and Lukaszewicz & Madalinska-Bugaj [17] develop such approaches. Singh introduced the mu-calculus for reasoning about action and developed a model-checking approach <ref> [25] </ref>. Independently, De Giacomo & Chen [9] give a mu-calculus characterization of plans, which however is based on a process algebra reminiscent of Milner's CCS [19], rather than an explicit branching-time logic as in the present approach.
Reference: [26] <author> Munindar P. Singh. </author> <title> Multiagent Systems: A Theoretical Framework for Intentions, Know-How, and Communications. </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg, </address> <year> 1994. </year>
Reference-contexts: Maintenance goals are important, because an agent may not only need to achieve different states, but also to maintain safety conditions and, equivalently, to prevent harmful conditions. This basic idea is common in theories of know-how (to achieve a condition), for example, see Singh <ref> [26] </ref> and seeing-to-it-that, for example, see Belnap & Perloff [3] and Chellas [7]. However, existing theories tend to focus exclusively on achieving a condition, rather than maintaining one, or achieving and then maintaining a condition. <p> Thus goals can be nested, for example, "achieve a state where the agent can maintain a condition." We choose a formal language related to CTL fl and dynamic logic [11] as popularized in the AI community by, among others, Rao & Georgeff [21] and Singh <ref> [26] </ref>. Another option would be the situation calculus, whose recent versions even allow concurrency, nondeterminism, and even continuity, for example, see Miller [18] and Reiter [23]. However, we would need additional extensions to these approaches to allow path quantifiers and operators for fixpoints as in our approach. <p> Throughout, we relate our approach to one for achievement. 2 The Technical Framework The framework described below combines time and nondeterministic actions; it is related to the frameworks of Chellas [7], Rao & Georgeff [21], and Singh <ref> [26] </ref>. We consider discrete time with concurrent, unit-length atomic actions. As a consequence, there is a finite number of actions between any pair of connected moments. moment defines a unique possible state of the world. The term state is used informally in the literature. <p> The state of the world that holds at a moment is identified by the atomic propositions that hold there. We require moments with the same world states to have isomorphic future fragments. This corresponds to the constraint of weak determinism, motivated in <ref> [26] </ref>. It means that although the individual actions are nondeterministic, the set of possible actions and outcomes depends on the given state. If, in addition, two moments have the same knowledge for all the agents, we can treat them as a single moment for representational efficiency. <p> In contrast, the second class is situated and considers the ability as manifest in the opportunities of the given situation. Here, the ability and opportunity go hand-in-hand, and an agent cannot have one without the other. This class is exemplified by Belnap & Perloff [3], Chellas [7], and Singh <ref> [26] </ref>. Our present approach is in the latter category. This facilitates reading the figures and examples below: what you see is what you get! 3.1 Achievement Intuitively, an agent knows how to achieve a condition if he can knowingly force it to become true. <p> The above characterization reflects the intuition of the formal definition of maintenance. Its conjuncts reflect the cases of the definition of maintenance intensions using which maintenance was formalized above. 4.4 Achievement We now introduce the semantics for know-how with slight modifications from <ref> [26] </ref>. An agent achieves p over an empty tree if he knows that p holds currently. He achieves p over a single action, a, if he knows that he can perform a in the given state and p holds along any branch where a ends. <p> Georgeff proposed process models to represent how the actions were selected by different agents. He also suggested the use of model-based as opposed to axiomatic techniques for reasoning about the relationships among process models. Singh <ref> [26] </ref> and Belnap & Perloff [3] define operators, but do not develop algorithms to compute them. The present approach shows how algorithms can be derived from the semantics of those operators.
Reference: [27] <author> Munindar P. Singh. Know-how. </author> <note> In [22]. </note> <year> 1998. </year>
Reference-contexts: Other agents and the environment can be thought of as being implicit in the nondeterminism of the given agent's actions. Broadly put, there are two main classes of approaches to know-how, discussed at length in <ref> [27] </ref>. One class follows traditional philosophical intuitions in separating ability from opportunity, for example, Brown [6] and van der Hoek et al. [29]. This class of approaches preserves the natural language meaning of knowing how to do something even if one cannot actually do it.
Reference: [28] <author> Michael Thielscher. </author> <title> The logic of dynamic systems. </title> <booktitle> In Proceedings of the International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1956-1962, </pages> <year> 1995. </year>
Reference-contexts: The problem of modeling concurrent events and their effects was also considered in an abstract setting by Georgeff, who developed an approach based on persistence and causality [13]. More recent approaches, for example, by Baral [2] and Thielscher <ref> [28] </ref>, seek to characterize the effects of actions in different circumstances. Complexity. The complexity of the above approach has not been carefully studied. It relies on having a finite set of moments to explore.
Reference: [29] <author> Wiebe van der Hoek, Bernd van Linder, and John-Jules Ch. Meyer. </author> <title> A logic of capabilities. </title> <type> TR IR-330, </type> <institution> Vrije Universiteit, </institution> <address> Amsterdam, </address> <year> 1993. </year>
Reference-contexts: Broadly put, there are two main classes of approaches to know-how, discussed at length in [27]. One class follows traditional philosophical intuitions in separating ability from opportunity, for example, Brown [6] and van der Hoek et al. <ref> [29] </ref>. This class of approaches preserves the natural language meaning of knowing how to do something even if one cannot actually do it. However, this naturalness comes at the price of defining know-how based on counterfactual situations.
Reference: [30] <author> Richard Waldinger. </author> <title> Achieving several goals simultaneously. </title> <editor> In Bonnie L. Webber and Nils J. Nilsson, editors, </editor> <booktitle> Readings in Artificial Intelligence, </booktitle> <pages> pages 250-271. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1981. </year> <month> 23 </month>
Reference-contexts: However, existing theories tend to focus exclusively on achieving a condition, rather than maintaining one, or achieving and then maintaining a condition. The idea of maintenance also emerges in implemented planning systems, which from the time of Waldinger <ref> [30] </ref> have considered maintenance as a key functionality in constructing effective plans, especially when more than one goal must be brought about. Maintenance features also in the dMARS system [15]. It is therefore quite interesting that maintenance has not received corresponding attention in the formal reasoning about action community.
References-found: 30

