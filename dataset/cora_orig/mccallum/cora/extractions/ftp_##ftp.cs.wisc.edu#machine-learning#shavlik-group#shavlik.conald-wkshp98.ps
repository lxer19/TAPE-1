URL: ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/shavlik.conald-wkshp98.ps
Refering-URL: http://www.cs.wisc.edu/~shavlik/abstracts/shavlik.conald-wkshp98.ps.abstract.html
Root-URL: 
Email: fshavlik, eliassig@cs.wisc.edu  
Title: Building Intelligent Agents for Web-Based Tasks: A Theory-Refinement Approach  
Author: Jude Shavlik and Tina Eliassi-Rad 
Web: http://www.cs.wisc.edu/~fshavlik, eliassig  
Address: 1210 W. Dayton Street Madison, Wisconsin 53706  
Affiliation: University of Wisconsin-Madison  
Date: June 1998.  
Note: Appears in the Proceedings of the CONALD Workshop on Learning from Text and the Web,  
Abstract: We present and evaluate an infrastructure with which to rapidly and easily build intelligent software agents for Web-based tasks. Our design is centered around two basic functions: ScoreThis-Link and ScoreThisPage. If given highly accurate such functions, standard heuristic search would lead to efficient retrieval of useful information. Our approach allows users to tailor our system's behavior by providing approximate advice about the above functions. This advice is mapped into neural network implementations of the two functions. Subsequent reinforcements from the Web (e.g., dead links) and any ratings of retrieved pages that the user wishes to provide are, respectively, used to refine the link- and page-scoring functions. Hence, our agent architecture provides an appealing middle ground between nonadaptive "agent" programming languages and systems that solely learn user preferences from the user's ratings of pages. We present a case study where we provide some simple advice and specialize our general-purpose system into a "home-page finder". An empirical study demonstrates that our approach leads to a more effective home-page finder than that of a leading commercial Web search engine. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Joachims, T.; Freitag, D.; and Mitchell, T. </author> <year> 1997. </year> <title> Web-watcher: A tour guide for the World Wide Web. </title> <booktitle> In Proc. IJCAI-97. </booktitle>
Reference-contexts: Table 4: Empirical Results System % Found Mean Rank Wawa with BP 80% 1:2 Ahoy! 74% 1:5 Wawa without BP 70% 1:3 H'Bot person search 66% 12:0 HotBot general 44% 15:4 Related Work Like Wawa, Syskill and Webert (Pazzani, Muramatsu, & Billsus 1996), and WebWatcher <ref> (Joachims, Freitag, & Mitchell 1997) </ref> are Web agents that use machine learning techniques. They, respectively, use a Bayesian classifier and an RL-TFIDF hybrid to learn.
Reference: <author> Maclin, R., and Shavlik, J. </author> <year> 1996. </year> <title> Creating advice-taking reinforcement learners. </title> <booktitle> Machine Learning 22 </booktitle> <pages> 251-281. </pages>
Reference-contexts: These functions, respectively, guide the system's wandering within the Web and judge the value of the pages encountered. The user mainly programs these two functions by providing what we call advice, which is basically, rules-of-thumb for guiding Wawa's wandering and for specifying how it scores pages. Following <ref> (Maclin & Shavlik 1996) </ref>, we call our programming language an advice language, as this name emphasizes that the underlying system does not blindly follow the user-provided instructions, but instead refines this advice based on the system's experiences. <p> Observing the system's behavior is likely to invoke thoughts of good additional instructions. Wawa can accept new advice and augment its neural networks at any time. It simply adds to a network additional hidden units that represent the compiled advice, a technique whose effectiveness was demonstrated <ref> (Maclin & Shavlik 1996) </ref> on several tasks. Providing additional hints can rapidly and drastically improve the performance of Wawa, provided the advice is relevant. (In this paper's experiments we do not evaluate incremental provision of advice, though (Maclin & Shavlik 1996) have done so on their testbeds. <p> hidden units that represent the compiled advice, a technique whose effectiveness was demonstrated <ref> (Maclin & Shavlik 1996) </ref> on several tasks. Providing additional hints can rapidly and drastically improve the performance of Wawa, provided the advice is relevant. (In this paper's experiments we do not evaluate incremental provision of advice, though (Maclin & Shavlik 1996) have done so on their testbeds. They also showed that their algorithm is robust when given "bad" advice, quickly learning to ignore it.) Although more tedious, the user can also rate pages as a mechanism for providing training examples for use by BP.
Reference: <author> Miller, G. </author> <year> 1995. </year> <title> WordNet: A lexical database for English. </title> <journal> Communications of the ACM 38 </journal> <pages> 39-41. </pages>
Reference-contexts: Finally, we plan to continue to expand our advice language and to build into Wawa the ability to use information about synonyms (e.g., WordNet <ref> (Miller 1995) </ref>) and other knowledge about text. We would also like to add the capability of automatically creating plausible training examples by observing the actions made by users during their ordinary use of Wawa.
Reference: <author> Ourston, D., and Mooney, R. </author> <year> 1994. </year> <title> Theory refinement: Combining analytical and empirical methods. </title> <journal> Artif. Intel. </journal> <volume> 66 </volume> <pages> 273-309. </pages>
Reference: <author> Pazzani, M., and Kibler, D. </author> <year> 1992. </year> <title> The utility of knowledge in inductive learning. </title> <booktitle> Machine Learning 9 </booktitle> <pages> 57-94. </pages>
Reference: <author> Pazzani, M.; Muramatsu, J.; and Billsus, D. </author> <year> 1996. </year> <title> Identifying interesting web sites. </title> <booktitle> In Proc. AAAI-96. </booktitle>
Reference-contexts: This can be useful when the user is unable to articulate why the system is misscoring pages and links, but is able to provide better scores. This standard learning-from-labeled-examples methodology has been previously investigated by other researchers, e.g., <ref> (Pazzani, Muramatsu, & Billsus 1996) </ref>, and we will not further discuss this aspect of Wawa in this article. We do conjecture, though, that most of the improvement to Wawa's neural networks, especially to ScorePage, will result from users providing advice. <p> Table 4: Empirical Results System % Found Mean Rank Wawa with BP 80% 1:2 Ahoy! 74% 1:5 Wawa without BP 70% 1:3 H'Bot person search 66% 12:0 HotBot general 44% 15:4 Related Work Like Wawa, Syskill and Webert <ref> (Pazzani, Muramatsu, & Billsus 1996) </ref>, and WebWatcher (Joachims, Freitag, & Mitchell 1997) are Web agents that use machine learning techniques. They, respectively, use a Bayesian classifier and an RL-TFIDF hybrid to learn.
Reference: <author> Rumelhart, D.; Hinton, G.; and Williams, R. </author> <year> 1986. </year> <title> Learning representations by back-propagating errors. </title> <booktitle> Nature 323 </booktitle> <pages> 533-536. </pages>
Reference: <author> Salton, G. </author> <year> 1991. </year> <title> Developments in automatic text retrieval. </title> <booktitle> Science 253 </booktitle> <pages> 974-979. </pages>
Reference-contexts: Following our description of the basic features, we briefly discuss the more complicated language constructs created from the basic ones. Extracting Features from Web Pages. A standard representation of text used in information retrieval is the vector-space model <ref> (Salton 1991) </ref> (or the bag-of-words representation). The left side of Fig. 1 illustrates this representation. Basically, word order is lost and all that is used is a vector that records the words present on the page, usually scaled according to the number of occurrences and other properties (e.g., TFIDF (Salton 1991)). <p> model <ref> (Salton 1991) </ref> (or the bag-of-words representation). The left side of Fig. 1 illustrates this representation. Basically, word order is lost and all that is used is a vector that records the words present on the page, usually scaled according to the number of occurrences and other properties (e.g., TFIDF (Salton 1991)). Typically, information retrieval systems also discard common ("stop") words and "stem" all words to their root form (e.g., "walked" and "walking" both become "walk") (Salton 1991). Doing so greatly reduces the dimensionality of the problem. Wawa performs these two preprocessing steps. <p> is a vector that records the words present on the page, usually scaled according to the number of occurrences and other properties (e.g., TFIDF <ref> (Salton 1991) </ref>). Typically, information retrieval systems also discard common ("stop") words and "stem" all words to their root form (e.g., "walked" and "walking" both become "walk") (Salton 1991). Doing so greatly reduces the dimensionality of the problem. Wawa performs these two preprocessing steps. Instead of solely using the bag-of-words model, we use a richer representation that preserves some word-order information.
Reference: <author> Sejnowski, T., and Rosenberg, C. </author> <year> 1987. </year> <title> Parallel networks that learn to pronounce English text. </title> <booktitle> Complex Systems 1 </booktitle> <pages> 145-168. </pages>
Reference-contexts: Empirical support for these claims is a topic of experiments in progress. Wawa's use of neural networks means we need a mechanism for processing arbitrarily long Web pages with fixed-sized input vectors. We borrow an idea from NETtalk <ref> (Sejnowski & Rosenberg 1987) </ref>, though our basic unit is a word rather than an (alphabetic) letter as in NETtalk. Wawa slides a fixed-sized window across a page, and most of the features we use to represent a page are defined with respect to the current center of this window.
Reference: <author> Shakes, J.; Langheinrich, M.; and Etzioni, O. </author> <year> 1997. </year> <title> Dynamic reference sifting: A case study in the home-page domain. </title> <booktitle> In Proc. of the Sixth International World Wide Web Conference, </booktitle> <pages> 189-200. </pages>
Reference-contexts: Experiments This section presents a case study that illustrates the effectiveness and ease of creating a specialized agent on top of the general-purpose Wawa system for a Web-based task. We chose a task already in the literature: creating a home-page finder <ref> (Shakes, Langheinrich, & Etzioni 1997) </ref>. Their Ahoy! system uses a technique called Dynamic Reference Sifting, which filters the output of several Web indices and generates new guesses for urls' when no promising candidates are found. <p> We compare the performance of Wawa with the performances of Ahoy! and HotBot, a search engine not used by Wawa and the one that performed best in the home-page experiments of <ref> (Shakes, Langheinrich, & Etzioni 1997) </ref>. We provided the names in our test-set to Ahoy! via its Web interface. We ran HotBot under two different conditions. The first setting performs a specialized HotBot search for people; we use the name given on Aha's page for these queries.
Reference: <author> Shavlik, J., and Eliassi-Rad, T. </author> <year> 1998. </year> <title> Intelligent agents for Web-based tasks: An advice-taking approach. </title> <booktitle> In AAAI/ICML Workshop on Learning for Text Categorization. </booktitle>
Reference-contexts: Any differences between the "before" and "after" estimates constitute a temporal difference (Sutton 1988) error that can be used by backpropagation (BP)(Rumelhart, Hinton, & Williams 1986) to improve the ScoreLink neural network (see <ref> (Shavlik & Eliassi-Rad 1998) </ref> for further details). In addition to the above system-internal method of automatically creating training examples, the user can improve the ScorePage and ScoreLink neural networks in two ways. One, the user can provide additional advice.
Reference: <author> Sutton, R. </author> <year> 1988. </year> <title> Learning to predict by the methods of temporal differences. </title> <booktitle> Machine Learning 3 </booktitle> <pages> 9-44. </pages>
Reference-contexts: After fetching and analyzing the text, the system will have a better estimate of the page's value to the user. Any differences between the "before" and "after" estimates constitute a temporal difference <ref> (Sutton 1988) </ref> error that can be used by backpropagation (BP)(Rumelhart, Hinton, & Williams 1986) to improve the ScoreLink neural network (see (Shavlik & Eliassi-Rad 1998) for further details).
Reference: <author> Towell, G., and Shavlik, J. </author> <year> 1994. </year> <booktitle> Knowledge-based artificial neural networks. Artif. Intel. </booktitle> <volume> 70 </volume> <pages> 119-165. </pages>
Reference-contexts: This is accomplished using a variant of the Kbann algorithm <ref> (Towell & Shavlik 1994) </ref>. Rule 1 in Table 3 compiles to five positions (apostrophe-s is treated as a separate word) in the sliding window, along with the constraint that the insideT itle predicate be true (i.e., have an activation value of 1).
References-found: 13

