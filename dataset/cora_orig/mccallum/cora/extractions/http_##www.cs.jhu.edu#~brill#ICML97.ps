URL: http://www.cs.jhu.edu/~brill/ICML97.ps
Refering-URL: http://www.cs.jhu.edu/~brill/acadpubs.html
Root-URL: http://www.cs.jhu.edu
Email: flidia, brillg@cs.jhu.edu  
Title: Automatic Rule Acquisition for Spelling Correction  
Author: Lidia Mangu and Eric Brill 
Address: Baltimore, MD 21218  
Affiliation: Computer Science Dept. Johns Hopkins University  
Abstract: This paper describes a new approach to automatically learning linguistic knowledge for spelling correction. A major feature of this approach is the fact that the acquired knowledge is captured in a small set of easily understood rules, as opposed to a large set of opaque features and weights. A perspicuous representation is advantageous in order to best exploit human intuition to understand and improve upon the acquired knowledge of the system.
Abstract-found: 1
Intro-found: 1
Reference: <author> Atwell, E. and Elliott, S. </author> <year> (1987). </year> <title> Dealing with ill-formed English text. In The Computational Analysis of English: A Corpus-Based Approach. </title> <editor> R. Garside, </editor> <publisher> G. </publisher>
Reference: <editor> Leach, G. Sampson, Ed. </editor> <publisher> Longman, Inc. </publisher> <address> New York. </address>
Reference: <author> Brill, E. </author> <year> (1993). </year> <title> Automatic grammar induction and parsing free text: a transformation-based approach. </title> <booktitle> In Proceedings of 31st Meeting of the Association of Computational Linguistics, </booktitle> <address> Columbus, OH. </address>
Reference-contexts: Because of this, we investigated whether using the output of a tagger instead of the set of allowable tags for each word in the sentence being processed could improve our results. The training set was run through a publicly available part-of-speech tagger <ref> (Brill, 1993) </ref>.
Reference: <author> Brill, E. </author> <year> (1995). </year> <title> Transformation-Based Error-Driven Learning and Natural Language. A Case Study in Part of Speech Tagging. </title> <booktitle> Computational Linguistics,21(4):543-565. </booktitle>
Reference-contexts: In actuality, there may be an extremely large set of potential transformations, and applying and scoring each would be infeasible. Instead, we can do the equivalent to this in a very efficient way by using a data-driven algorithm <ref> (Brill, 1995) </ref>. The result of learning is an ordered list of transformations. To apply the learned transformations to new text, that text is first processed by the baseline predictor. Then each rule is applied, in order, everywhere it can be applied. <p> Second, for a fixed set of features, transformation lists are more powerful than decision trees in what they can learn <ref> (Brill, 1995) </ref>. Finally, unlike both decision trees and decision lists, a rule in the list is able to correct mistakes made by applying previous rules. 3.1 Transformation-Based Learning for Spelling Correction We next describe how to build a transformation-based system for spelling correction.
Reference: <author> Church, K. W. and Gale, W. A. </author> <year> (1991). </year> <title> Probability scoring for spelling correction. </title> <journal> In Stat. Comp. </journal> <volume> 1., </volume> <pages> 93-103. </pages>
Reference: <author> Flexner S. B., </author> <title> editor (1983). Random House Unabridged Dictionary. Random House, </title> <address> New York. </address> <note> Second edition. </note>
Reference-contexts: fdoes/did/can/shouldg not accept. 4 Experiments For their experiments (Golding, 1995; Golding and Schabes, 1996; Golding and Roth, 1996) used the 1 million word Brown corpus (Kucera and Francis, 1967) and collections of confusion sets which were selected from the list of "Words Commonly Confused" in the back of Random House <ref> (Flexner, 1983) </ref> on the basis of occurring frequently in the Brown corpus and representing a variety of types of errors. We ran the experiments using the same corpus, and a subset of their collection of confusion sets which is present in all the three papers mentioned above.
Reference: <author> Gale, W. A. and Church K. W. </author> <year> (1990). </year> <title> Estimation Procedures for language context: Poor estimates are worse than none. </title> <booktitle> In Proceedings of Compstat-90 (Dubrovnik, </booktitle> <address> Yugoslavia), 69-74. New York: </address> <publisher> Springer-Verlag. </publisher>
Reference: <author> Gale, W., Church, K. and Yarowsky, D. </author> <year> (1995). </year> <title> Discrimination decisions for 100,000 dimensional spaces. </title> <journal> Annals of Operations Research, </journal> <volume> 55, </volume> <pages> 323-344. </pages>
Reference: <author> Golding, A. </author> <year> (1995). </year> <title> A Bayesian hybrid method for context-sensitive spelling correction. </title> <booktitle> In Proceedings of the Third Workshop on Very Large Corpora, </booktitle> <pages> 39-53. </pages> <address> Boston, MA. </address>
Reference-contexts: Rather than attempting to detect and correct all errors, this approach attempts to choose between commonly confused words (such as than vs. then). The first efforts within this framework for spelling correction include Bayesian classifiers and decision lists (Gale, Church, and Yarowsky, 1995; Yarowsky, 1994; Golding, 1995). In <ref> (Golding , 1995) </ref> decision lists are first used to choose the proper word from a confusion set. <p> It was determined that better results can be obtained when evidence is combined in a more powerful way, by taking into consideration not just the strongest piece of evidence but all the available evi dence. <ref> (Golding, 1995) </ref> ran the same experiments with Bayesian classifiers, and achieved a small improvement over decision lists. In (Golding and Schabes, 1996) an extension is made to the Bayesian classifier, where a part of speech tagger is first used to tag the text.
Reference: <author> Golding, A. and Schabes, Y. </author> <year> (1996). </year> <title> Combining Trigram-based and Feature-based Methods for Context-Sensitive Spelling Correction. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 71-78. </pages> <address> Santa Cruz, CA. </address>
Reference-contexts: In <ref> (Golding and Schabes, 1996) </ref> an extension is made to the Bayesian classifier, where a part of speech tagger is first used to tag the text. <p> When words do not differ in part of speech, the original Bayesian classifier is used. This resulted in an improvement over the original Bayesian classifier. One of the most successful methods for this problem is a Winnow-based method <ref> (Golding and Roth, 1996) </ref>, a multiplicative weight-updating algorithm which achieves a good accuracy by being able to handle a large number of features. This method also learns a large set of features with corresponding weights. <p> All these made possible a fair direct comparison with the previous methods. The results for Bayes, TriBayes and Winnow methods which occur in the tables below are taken from <ref> (Golding and Schabes, 1996) </ref> and (Golding and Roth, 1996). <p> All these made possible a fair direct comparison with the previous methods. The results for Bayes, TriBayes and Winnow methods which occur in the tables below are taken from (Golding and Schabes, 1996) and <ref> (Golding and Roth, 1996) </ref>. <p> This is the same set of features used in both the Bayesian spelling corrector <ref> (Golding and Schabes, 1996) </ref> and Winnow-based method (Gold-ing and Roth, 1996). In addition, the annotation used for the training and the test set was the same, namely, each word is tagged with the set of all possible part of speech tags. <p> Bayes TriBayes Winnow RuleS AA 86.94 88.38 93.69 88.73 RuleS &gt; RuleS &lt; RuleS = Bayes 7 5 2 TriBayes 4 6 4 Winnow 1 13 0 4.2 Using a Part of Speech Tagger In <ref> (Golding and Schabes, 1996) </ref>, it was shown that using a part of speech tagger to provide the proper tags for words in the sentence resulted in an improvement in performance over using a Bayesian classifier without disambiguating the tags.
Reference: <author> Golding, A. and Roth, D. </author> <year> (1996). </year> <title> Applying Winnow to Context-Sensitive Spelling Correction. </title> <booktitle> In Machine Learning: Proceedings of the 13th International Conference, </booktitle> <pages> 182-190. </pages> <address> San Francisco, CA. </address>
Reference-contexts: In <ref> (Golding and Schabes, 1996) </ref> an extension is made to the Bayesian classifier, where a part of speech tagger is first used to tag the text. <p> When words do not differ in part of speech, the original Bayesian classifier is used. This resulted in an improvement over the original Bayesian classifier. One of the most successful methods for this problem is a Winnow-based method <ref> (Golding and Roth, 1996) </ref>, a multiplicative weight-updating algorithm which achieves a good accuracy by being able to handle a large number of features. This method also learns a large set of features with corresponding weights. <p> All these made possible a fair direct comparison with the previous methods. The results for Bayes, TriBayes and Winnow methods which occur in the tables below are taken from <ref> (Golding and Schabes, 1996) </ref> and (Golding and Roth, 1996). <p> All these made possible a fair direct comparison with the previous methods. The results for Bayes, TriBayes and Winnow methods which occur in the tables below are taken from (Golding and Schabes, 1996) and <ref> (Golding and Roth, 1996) </ref>. <p> This is the same set of features used in both the Bayesian spelling corrector <ref> (Golding and Schabes, 1996) </ref> and Winnow-based method (Gold-ing and Roth, 1996). In addition, the annotation used for the training and the test set was the same, namely, each word is tagged with the set of all possible part of speech tags. <p> Bayes TriBayes Winnow RuleS AA 86.94 88.38 93.69 88.73 RuleS &gt; RuleS &lt; RuleS = Bayes 7 5 2 TriBayes 4 6 4 Winnow 1 13 0 4.2 Using a Part of Speech Tagger In <ref> (Golding and Schabes, 1996) </ref>, it was shown that using a part of speech tagger to provide the proper tags for words in the sentence resulted in an improvement in performance over using a Bayesian classifier without disambiguating the tags.
Reference: <author> Kukich, K. </author> <year> (1991). </year> <title> Automatic spelling correction: Detection, correction and context-dependent techniques. </title> <type> Technical report, </type> <institution> Bellcore, Morristown, </institution> <address> NJ 07960. </address> <note> Draft. </note>
Reference-contexts: Studies have shown that errors of this type account for anywhere from 25% to 50% of word-based errors in a text, depending on the application <ref> (Kukich, 1991) </ref>. Such errors seem to require both syntactic and semantic information from the surrounding context in order to perform accurate correction. For example, in the sentence: I am just a human begin/being. we know the correct word is being because the preceding word is human.
Reference: <author> Kucera, H. and Francis, W. N. </author> <year> (1967). </year> <title> Computational Analysis of Present-Day American English. </title> <publisher> Brown University Press, </publisher> <address> Providence, RI. </address>
Reference-contexts: He fdoes/did/can/shouldg not accept. 4 Experiments For their experiments (Golding, 1995; Golding and Schabes, 1996; Golding and Roth, 1996) used the 1 million word Brown corpus <ref> (Kucera and Francis, 1967) </ref> and collections of confusion sets which were selected from the list of "Words Commonly Confused" in the back of Random House (Flexner, 1983) on the basis of occurring frequently in the Brown corpus and representing a variety of types of errors.

References-found: 13

