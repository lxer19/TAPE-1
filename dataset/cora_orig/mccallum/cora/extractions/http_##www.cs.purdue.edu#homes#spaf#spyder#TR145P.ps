URL: http://www.cs.purdue.edu/homes/spaf/spyder/TR145P.ps
Refering-URL: http://www.cs.purdue.edu/homes/spaf/students.html
Root-URL: http://www.cs.purdue.edu
Title: SOFTWARE DEBUGGING WITH DYNAMIC INSTRUMENTATION AND TEST-BASED KNOWLEDGE  
Author: by Hsin Pan 
Degree: A Thesis Submitted to the Faculty of  In Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy  
Date: August 1993  
Affiliation: Purdue University  
Abstract-found: 0
Intro-found: 1
Reference: <institution> 125 BIBLIOGRAPHY </institution>
Reference: [AC73] <author> W. Amory and J.A. Clapp. </author> <title> A Software Error Classification Methodology, </title> <journal> MTR-2648, </journal> <volume> Vol. </volume> <pages> VII. </pages> <institution> Mitre Corp., Bedford, Massachusetts, </institution> <month> 30 June </month> <year> 1973. </year> <note> (Also published as RADC-TR-74-324, Vol. VII). </note>
Reference-contexts: An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3. ANALYSIS OF A NEW DEBUGGING APPROACH Most studies of fault analysis <ref> [Knu89, BP84, OW84, Bow80, Lip79, AC73, JSCD83, SPL + 85] </ref> classify faults collected from long-term projects. However, no further studies have been conducted based on the categorized information. We believe that there is value to debugging research in such analysis.
Reference: [ADH + 89] <author> H. Agrawal, R. A. DeMillo, B. Hathaway, W. Hsu, W. Hsu, E. W. Krauser, R. J. Martin, A. P. Mathur, and E. H. Spafford. </author> <title> Design of mutant operators for the C programming language. </title> <type> Technical Report SERC-TR-41-P, </type> <institution> Software Engineering Research Center, Purdue University, West Lafayette, Indiana, </institution> <month> March </month> <year> 1989. </year>
Reference-contexts: In Table 5.1, mutant operators of the MOTHRA [CDK + 89, KO91] testing tool for FORTRAN 77 are listed. Mutant operators for C have been reported in <ref> [ADH + 89] </ref>, and are a 1 Readers are referred to [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] for details of program mutation. 47 Table 5.1 Mutant operators used by MOTHRA for FORTRAN 77.
Reference: [ADS91a] <author> H. Agrawal, R. A. DeMillo, and E. H. Spafford. </author> <title> Dynamic slicing in the presence of unconstrained pointers. </title> <booktitle> In Proceedings of the 1991 Symposium on Software Testing, Analysis, and Verification (TAV4), </booktitle> <pages> pages 60-73, </pages> <address> Victoria, British Columbia, Canada, </address> <month> October 8-10 </month> <year> 1991. </year>
Reference-contexts: This dissertation focuses on the second task, reducing the search domain for faults, referred to as fault localization. To assist users in conducting the first and last tasks, two techniques Dynamic Program Slicing <ref> [ADS91a, AH90] </ref> and Execution Backtracking [ADS91b, AS88] were developed by Agrawal, DeMillo, and Spafford. A prototype debugging tool, SPYDER [ADS91a, ADS91b, AS88, Agr91], has been constructed with those techniques. <p> To assist users in conducting the first and last tasks, two techniques Dynamic Program Slicing [ADS91a, AH90] and Execution Backtracking [ADS91b, AS88] were developed by Agrawal, DeMillo, and Spafford. A prototype debugging tool, SPYDER <ref> [ADS91a, ADS91b, AS88, Agr91] </ref>, has been constructed with those techniques. <p> Some of the heuristics were integrated into SPYDER to demonstrate the feasibility and usefulness of our approach. developing powerful debugging tools is suggested as a result of this study. 1 An informal definition of Dynamic Program Slicing is described in Chapter 3.3. See <ref> [AH90, ADS91a, Agr91] </ref> for the formal definition. 2 Program mutation has been studied for over a decade. <p> Dynamic program slicing for pointers based on the same approach has been implemented in the prototype debugging tool SPYDER <ref> [ADS91a, ADS91b, Agr91] </ref>. Prior the work reported here, dynamic program slicing had not been systematically applied to fault localization, although in Agrawal's dissertation [Agr91] he briefly alluded to the idea of combining dynamic program slices and data slices for fault localization. <p> Although each heuristic does not provide a general solution and is only suitable for some specific situations, the overall debugging power from uniting these heuristics is expected to surpass that of currently used debugging tools. 3.3 Expanded Dynamic Program Slicing In this section, we enhance Dynamic Program Slicing <ref> [AH90, ADS91a, Agr91] </ref>, which was chosen as our basic instrument, to handle certain types of faulty statements. <p> This is done by taking the transitive closure of the enclosing predicates starting with the given location. The set of all predicates that belong to this closure forms the dynamic control slice. Thus 1 Readers are referred to <ref> [AH90, ADS91a, Agr91] </ref> for the formal definition. 22 a dynamic program slice with respect to a given variable, location, and test case is the closure of all the data and control slices with regard to all expressions and locations in its constituent dynamic data and control slices. <p> We therefore develop two comparison methods to evaluate the effectiveness of the proposed heuristics of Chapter 4 and the Critical Slicing of Chapter 5.1. 6.1 SPYDER: A Prototype Debugger In order to support the new debugging paradigm proposed in Figure 1.1 of Chapter 1.2, a prototype debugging tool, SPYDER <ref> [ADS91a, ADS91b, AS88, Agr91] </ref>, has been constructed to perform the slicing and backtracking functions. Features of SPYDER are briefly summarized here. Readers are referred to [Agr91] for details of the implementation and functions of SPYDER.
Reference: [ADS91b] <author> H. Agrawal, R. A. DeMillo, and E. H. Spafford. </author> <title> An execution backtracking approach to program debugging. </title> <journal> IEEE Software, </journal> <volume> 8(3) </volume> <pages> 21-26, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: This dissertation focuses on the second task, reducing the search domain for faults, referred to as fault localization. To assist users in conducting the first and last tasks, two techniques Dynamic Program Slicing [ADS91a, AH90] and Execution Backtracking <ref> [ADS91b, AS88] </ref> were developed by Agrawal, DeMillo, and Spafford. A prototype debugging tool, SPYDER [ADS91a, ADS91b, AS88, Agr91], has been constructed with those techniques. <p> To assist users in conducting the first and last tasks, two techniques Dynamic Program Slicing [ADS91a, AH90] and Execution Backtracking [ADS91b, AS88] were developed by Agrawal, DeMillo, and Spafford. A prototype debugging tool, SPYDER <ref> [ADS91a, ADS91b, AS88, Agr91] </ref>, has been constructed with those techniques. <p> EXDAMS [Bal69], for example, is an interactive debugging tool equipped with this technique. The major problem with implementing backtracking is the consumption of large amounts of space for storing the execution history and program states. Agrawal, DeMillo, and Spafford <ref> [ADS91b] </ref> proposed a structured backtracking approach to implement execution backtracking without storing the whole execution history. Their approach saves the latest value of variables changed in a statement and only allows backtracking to the program state prior to a complete statement. <p> Dynamic program slicing for pointers based on the same approach has been implemented in the prototype debugging tool SPYDER <ref> [ADS91a, ADS91b, Agr91] </ref>. Prior the work reported here, dynamic program slicing had not been systematically applied to fault localization, although in Agrawal's dissertation [Agr91] he briefly alluded to the idea of combining dynamic program slices and data slices for fault localization. <p> We therefore develop two comparison methods to evaluate the effectiveness of the proposed heuristics of Chapter 4 and the Critical Slicing of Chapter 5.1. 6.1 SPYDER: A Prototype Debugger In order to support the new debugging paradigm proposed in Figure 1.1 of Chapter 1.2, a prototype debugging tool, SPYDER <ref> [ADS91a, ADS91b, AS88, Agr91] </ref>, has been constructed to perform the slicing and backtracking functions. Features of SPYDER are briefly summarized here. Readers are referred to [Agr91] for details of the implementation and functions of SPYDER.
Reference: [ADS93] <author> H. Agrawal, R. A. DeMillo, and E. H. Spafford. </author> <title> Debugging with dynamic slicing and backtracking. </title> <journal> Software Practice and Experience, </journal> <volume> 23(6) </volume> <pages> 589-616, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: An informal definition of Dynamic Program Slicing mentioned in <ref> [ADS93] </ref> is quoted and summarized as follows. 1 There are two major components to constructing a dynamic program slice: the dynamic data slice and the dynamic control slice.
Reference: [AFC91] <author> Keijiro Araki, Zengo Furukawa, and Jingde Cheng. </author> <title> A general framework for debugging. </title> <journal> IEEE Software, </journal> <volume> 8(3) </volume> <pages> 14-20, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: After the search domain is reduced to a few statement blocks (DD-paths), no further suggestion is provided for locating bugs. 2.6 Summary Araki, Furukawa and Cheng summarized the debugging steps conducted by experienced programmers and proposed a debugging process model as a general framework. <ref> [AFC91] </ref> They also pointed out that debugging tools must support each stage in the debugging process: hypothesis verification, hypothesis-set modification, and hypothesis selection. However, they did not describe what kinds of facilities and functions will be used to support each stage.
Reference: [Agr91] <author> Hiralal Agrawal. </author> <title> Towards Automatic Debugging of Computer Programs. </title> <type> PhD thesis, </type> <institution> Purdue University, West Lafayette, Indiana, </institution> <month> August </month> <year> 1991. </year> <note> (Also released as Technical Report SERC-TR-103-P, </note> <institution> Software Engineering Research Center, Purdue University, West Lafayette, Indiana, </institution> <month> September </month> <year> 1991). </year>
Reference-contexts: To assist users in conducting the first and last tasks, two techniques Dynamic Program Slicing [ADS91a, AH90] and Execution Backtracking [ADS91b, AS88] were developed by Agrawal, DeMillo, and Spafford. A prototype debugging tool, SPYDER <ref> [ADS91a, ADS91b, AS88, Agr91] </ref>, has been constructed with those techniques. <p> Some of the heuristics were integrated into SPYDER to demonstrate the feasibility and usefulness of our approach. developing powerful debugging tools is suggested as a result of this study. 1 An informal definition of Dynamic Program Slicing is described in Chapter 3.3. See <ref> [AH90, ADS91a, Agr91] </ref> for the formal definition. 2 Program mutation has been studied for over a decade. <p> Dynamic program slicing for pointers based on the same approach has been implemented in the prototype debugging tool SPYDER <ref> [ADS91a, ADS91b, Agr91] </ref>. Prior the work reported here, dynamic program slicing had not been systematically applied to fault localization, although in Agrawal's dissertation [Agr91] he briefly alluded to the idea of combining dynamic program slices and data slices for fault localization. <p> Dynamic program slicing for pointers based on the same approach has been implemented in the prototype debugging tool SPYDER [ADS91a, ADS91b, Agr91]. Prior the work reported here, dynamic program slicing had not been systematically applied to fault localization, although in Agrawal's dissertation <ref> [Agr91] </ref> he briefly alluded to the idea of combining dynamic program slices and data slices for fault localization. <p> Although each heuristic does not provide a general solution and is only suitable for some specific situations, the overall debugging power from uniting these heuristics is expected to surpass that of currently used debugging tools. 3.3 Expanded Dynamic Program Slicing In this section, we enhance Dynamic Program Slicing <ref> [AH90, ADS91a, Agr91] </ref>, which was chosen as our basic instrument, to handle certain types of faulty statements. <p> This is done by taking the transitive closure of the enclosing predicates starting with the given location. The set of all predicates that belong to this closure forms the dynamic control slice. Thus 1 Readers are referred to <ref> [AH90, ADS91a, Agr91] </ref> for the formal definition. 22 a dynamic program slice with respect to a given variable, location, and test case is the closure of all the data and control slices with regard to all expressions and locations in its constituent dynamic data and control slices. <p> We therefore develop two comparison methods to evaluate the effectiveness of the proposed heuristics of Chapter 4 and the Critical Slicing of Chapter 5.1. 6.1 SPYDER: A Prototype Debugger In order to support the new debugging paradigm proposed in Figure 1.1 of Chapter 1.2, a prototype debugging tool, SPYDER <ref> [ADS91a, ADS91b, AS88, Agr91] </ref>, has been constructed to perform the slicing and backtracking functions. Features of SPYDER are briefly summarized here. Readers are referred to [Agr91] for details of the implementation and functions of SPYDER. <p> Features of SPYDER are briefly summarized here. Readers are referred to <ref> [Agr91] </ref> for details of the implementation and functions of SPYDER. Heuristics in Chapter 4 and the Expanded Dynamic Program Slicing in Chapter 3.3 are integrated into SPYDER to enhance the capability of fault localization in the proposed 81 82 Table 6.1 Software components of SPYDER. <p> Figure 6.1 provides a snapshot of the SPYDER interface during a debugging session with the heuristics window. 6.1.1 Screen of SPYDER The main window of SPYDER (i.e., the left window in Figure 6.1) is divided into five parts from top to bottom as follows. <ref> [Agr91] </ref> * File Label: contains the name of the source file currently displayed in Source Panel. * Source Panel: displays the source code being debugged along with line numbers. <p> GNU tools are chosen because they are available for delivery and support full ANSI C. Modification of gcc as well as gdb is illustrated in <ref> [Agr91] </ref>. While integrating heuristics into SPYDER, we have to choose the basic unit to be counted executable statements or nodes (vertices) in a program dependency graph for the inclusion and influence frequency. <p> However, each of the following statements is counted as one executable statement: if (expression), for (expression; expression; expression;), while (expression), switch (expression), and case constant-expression. The nodes (vertices) in a program dependency graph as defined in <ref> [Agr91] </ref> correspond to simple statements and predicates where a simple statement is defined as a statement with one memory modification (e.g., an assignment statement a = b + c;). The for (expression; expression; expression;) will be represented by three vertices (one for each expression).
Reference: [AH90] <author> H. Agrawal and J. R. Horgan. </author> <title> Dynamic program slicing. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 246-256, </pages> <address> White Plains, New York, </address> <month> June </month> <year> 1990. </year> <journal> (ACM SIGPLAN Notices, </journal> <volume> 25(6), </volume> <month> June </month> <year> 1990). </year>
Reference-contexts: This dissertation focuses on the second task, reducing the search domain for faults, referred to as fault localization. To assist users in conducting the first and last tasks, two techniques Dynamic Program Slicing <ref> [ADS91a, AH90] </ref> and Execution Backtracking [ADS91b, AS88] were developed by Agrawal, DeMillo, and Spafford. A prototype debugging tool, SPYDER [ADS91a, ADS91b, AS88, Agr91], has been constructed with those techniques. <p> Some of the heuristics were integrated into SPYDER to demonstrate the feasibility and usefulness of our approach. developing powerful debugging tools is suggested as a result of this study. 1 An informal definition of Dynamic Program Slicing is described in Chapter 3.3. See <ref> [AH90, ADS91a, Agr91] </ref> for the formal definition. 2 Program mutation has been studied for over a decade. <p> However, if we want to know the exact influence on the particular value of V at the end of the second iteration, K-L slicing cannot give the information because of the existence of S 1 in this situation. 14 Agrawal and Horgan <ref> [AH90] </ref> claimed the usefulness of a dynamic slice lies not [only] in the fact that one can execute it, but in the fact that it isolates only those statements that [actually] affected a particular value observed at a particular location. <p> The idea of these heuristics helped us develop our proposed fault localization strategies. The main restriction of their heuristics is that only execution paths that are a special case of dynamic program slicing <ref> [AH90] </ref> are examined. <p> Although each heuristic does not provide a general solution and is only suitable for some specific situations, the overall debugging power from uniting these heuristics is expected to surpass that of currently used debugging tools. 3.3 Expanded Dynamic Program Slicing In this section, we enhance Dynamic Program Slicing <ref> [AH90, ADS91a, Agr91] </ref>, which was chosen as our basic instrument, to handle certain types of faulty statements. <p> This is done by taking the transitive closure of the enclosing predicates starting with the given location. The set of all predicates that belong to this closure forms the dynamic control slice. Thus 1 Readers are referred to <ref> [AH90, ADS91a, Agr91] </ref> for the formal definition. 22 a dynamic program slice with respect to a given variable, location, and test case is the closure of all the data and control slices with regard to all expressions and locations in its constituent dynamic data and control slices.
Reference: [AL80] <author> Anne Adam and Jean-Pierre Laurent. LAURA, </author> <title> a system to debug student programs. </title> <journal> Artificial Intelligence, </journal> <volume> 15(1,2):75-122, </volume> <month> November </month> <year> 1980. </year> <month> 126 </month>
Reference-contexts: Otherwise, the corresponding specification for a complete program is too complicated to be described. The major limitation of this system is the variety of the programming schemas in the knowledge base. Only a few typical schemas can be representeded well. 11 Laura <ref> [AL80] </ref> uses a straightforward approach to debug students' programs. The specification of a program given to the system by teachers is the correct program model. The system compares programs written by students with the correct model. Programs for comparison are transformed into internal representation forms flow graphs.
Reference: [AM86] <author> Evan Adams and Steven S. Muchnick. Dbxtool: </author> <title> A window-based symbolic debugger for Sun workstations. </title> <journal> Software-Practice and Experience, </journal> <volume> 16(7) </volume> <pages> 653-669, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: Their approach saves the latest value of variables changed in a statement and only allows backtracking to the program state prior to a complete statement. The idea of a user-friendly interface has been built into some debugging tools such as Dbxtool <ref> [AM86] </ref>. Windows and a mouse are used to handle the selections in debugging processes instead of the traditional command-driven approach which accepts typed commands only.
Reference: [ANS83] <author> ANSI/IEEE. </author> <title> IEEE Standard Glossary of Software Enginnering Terminology. </title> <publisher> IEEE Std 729-1983. IEEE, </publisher> <address> New York, </address> <year> 1983. </year>
Reference-contexts: In <ref> [ANS83] </ref>, errors are defined as inappropriate actions committed by a programmer or designer. Faults or bugs are the manifestations and results of errors during the coding of a program.
Reference: [AS88] <author> H. Agrawal and E. H. Spafford. </author> <title> An execution backtracking approach to program debugging. </title> <booktitle> In Proceedings of the 6th Pacific Northwest Software Quality Conference, </booktitle> <pages> pages 283-299, </pages> <address> Portland, Oregon, </address> <month> September 19-20 </month> <year> 1988. </year>
Reference-contexts: This dissertation focuses on the second task, reducing the search domain for faults, referred to as fault localization. To assist users in conducting the first and last tasks, two techniques Dynamic Program Slicing [ADS91a, AH90] and Execution Backtracking <ref> [ADS91b, AS88] </ref> were developed by Agrawal, DeMillo, and Spafford. A prototype debugging tool, SPYDER [ADS91a, ADS91b, AS88, Agr91], has been constructed with those techniques. <p> To assist users in conducting the first and last tasks, two techniques Dynamic Program Slicing [ADS91a, AH90] and Execution Backtracking [ADS91b, AS88] were developed by Agrawal, DeMillo, and Spafford. A prototype debugging tool, SPYDER <ref> [ADS91a, ADS91b, AS88, Agr91] </ref>, has been constructed with those techniques. <p> We therefore develop two comparison methods to evaluate the effectiveness of the proposed heuristics of Chapter 4 and the Critical Slicing of Chapter 5.1. 6.1 SPYDER: A Prototype Debugger In order to support the new debugging paradigm proposed in Figure 1.1 of Chapter 1.2, a prototype debugging tool, SPYDER <ref> [ADS91a, ADS91b, AS88, Agr91] </ref>, has been constructed to perform the slicing and backtracking functions. Features of SPYDER are briefly summarized here. Readers are referred to [Agr91] for details of the implementation and functions of SPYDER.
Reference: [AS89] <author> H. Agrawal and E. H. Spafford. </author> <title> A bibliography on debugging and backtracking. </title> <journal> ACM Software Engineering Notes, </journal> <volume> 14(2) </volume> <pages> 49-56, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Conventional debugging tools (e.g., ADB and DBX [Dun86]) are command-driven symbolic debugging tools and tend to be stand-alone. Many fault localization strategies used in current well-known debugging tools (e.g., setting break-points and tracing) were developed in the 1960s and have changed little. <ref> [AS89] </ref> These debugging tools do not locate faults efficiently. Users have to discover by themselves information useful for debugging.
Reference: [Bal69] <author> R. M. Balzer. </author> <title> EXDAMS: Extendible debugging and monitoring system. </title> <booktitle> In AFIPS Proceedings, Spring Joint Computer Conference, </booktitle> <volume> vol. 34, </volume> <pages> pages 567-580, </pages> <address> Montvale, New Jersey, 1969. </address> <publisher> AFIPS Press. </publisher>
Reference-contexts: In the above implementations, system states to be rolled back for later analysis must be set at the beginning. However, from the software debugging standpoint, execution backtracking should be able to gradually backtrack program execution from any break-point under the control of users. EXDAMS <ref> [Bal69] </ref>, for example, is an interactive debugging tool equipped with this technique. The major problem with implementing backtracking is the consumption of large amounts of space for storing the execution history and program states.
Reference: [BDLS80] <author> T. A. Budd, R. A. DeMillo, R. J. Lipton, and F. G. Sayward. </author> <title> Theoretical and empirical studies of using program mutation to test the functional correctness of programs. </title> <booktitle> In Proceedings of the 7th ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 220-233, </pages> <address> Las Vegas, </address> <month> January </month> <year> 1980. </year>
Reference-contexts: See [AH90, ADS91a, Agr91] for the formal definition. 2 Program mutation has been studied for over a decade. It is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. and is described in Chapter 5. 5 1.3 Contributions The principal contribution of this dissertation is a new debugging paradigm for enhancing the process of fault localization by reducing the search domain. <p> Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83], and fault-based testing <ref> [DLS78, Bud80, BDLS80, How82, Mor90] </ref>. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing. These two methods are superior to the first one as indicated in [HL91]. <p> For data flow testing, this condition only ensures that the define part of a selected def-use pair criteria is reached. 3 Program mutation has been studied for over a decade and is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. It will not be discussed in detail here. <p> In Table 5.1, mutant operators of the MOTHRA [CDK + 89, KO91] testing tool for FORTRAN 77 are listed. Mutant operators for C have been reported in [ADH + 89], and are a 1 Readers are referred to <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref> for details of program mutation. 47 Table 5.1 Mutant operators used by MOTHRA for FORTRAN 77.
Reference: [Bea83] <author> Bert Beander. </author> <title> VAX DEBUG: An interactive, symbolic, multilingual debugger. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on High-Level Debugging, </booktitle> <pages> pages 173-179, </pages> <address> Pacific Grove, California, </address> <month> March </month> <year> 1983. </year> <journal> (ACM Software Engineering Notes, 8(4), August 1983; ACM SIGPLAN Notices, </journal> <volume> 18(8), </volume> <month> August </month> <year> 1983). </year>
Reference-contexts: not only the basic facility, setting break-points, but also some of the following capabilities: displaying values of variables, tracing preset trace-points during execution, continuing execution of the program from a break-point, executing single steps from a break-point, modifying program states such as value of variables, and reexecuting a program (e.g., <ref> [Kat79, MB79, Bea83, Dun86] </ref>). These utilities can be employed by users to investigate a faulty program 8 interactively. First, users can set break-points in the program. Then, the execution of the program will be suspended at these break-points.
Reference: [BEL75] <author> R. S. Boyer, E. Elspas, and K. N. Levitt. </author> <title> SELECT a system for testing and debugging programs by symbolic execution. </title> <booktitle> In Proceedings of International Conference on Reliable Software, </booktitle> <pages> pages 234-245, </pages> <year> 1975. </year> <journal> (ACM SIGPLAN Notices, </journal> <volume> 10(6), </volume> <month> June </month> <year> 1990). </year>
Reference: [Boe81] <author> B. W. Boehm. </author> <title> Software Enginnering Economics. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Engle-wood Cliffs, New Jersey, </address> <year> 1981. </year>
Reference: [Bow80] <author> John B. Bowen. </author> <title> Standard error classification to support software reliability assessment. </title> <booktitle> In AFIPS Proceedings of 1980 National Computer Conference, </booktitle> <volume> Vol. 49, </volume> <pages> pages 697-705, </pages> <address> Anaheim, CA, </address> <month> May 19-22 </month> <year> 1980. </year>
Reference-contexts: An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3. ANALYSIS OF A NEW DEBUGGING APPROACH Most studies of fault analysis <ref> [Knu89, BP84, OW84, Bow80, Lip79, AC73, JSCD83, SPL + 85] </ref> classify faults collected from long-term projects. However, no further studies have been conducted based on the categorized information. We believe that there is value to debugging research in such analysis.
Reference: [BP84] <author> Victor R. Basili and Barry T. Perricone. </author> <title> Software errors and complexity: An empirical investigation. </title> <journal> Communications of the ACM, </journal> <volume> 27(1) </volume> <pages> 42-52, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3. ANALYSIS OF A NEW DEBUGGING APPROACH Most studies of fault analysis <ref> [Knu89, BP84, OW84, Bow80, Lip79, AC73, JSCD83, SPL + 85] </ref> classify faults collected from long-term projects. However, no further studies have been conducted based on the categorized information. We believe that there is value to debugging research in such analysis.
Reference: [Bra70] <author> Gordon H. Bradley. </author> <title> Algorithm and bound for the greatest common divisor of n integers. </title> <journal> Communications of the ACM, </journal> <volume> 13(7) </volume> <pages> 433-436, </pages> <month> July </month> <year> 1970. </year> <month> 127 </month>
Reference: [Bud80] <author> T. A. Budd. </author> <title> Mutation Analysis of Program Test Data. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, Connecticut, </address> <year> 1980. </year>
Reference-contexts: See [AH90, ADS91a, Agr91] for the formal definition. 2 Program mutation has been studied for over a decade. It is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. and is described in Chapter 5. 5 1.3 Contributions The principal contribution of this dissertation is a new debugging paradigm for enhancing the process of fault localization by reducing the search domain. <p> Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83], and fault-based testing <ref> [DLS78, Bud80, BDLS80, How82, Mor90] </ref>. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing. These two methods are superior to the first one as indicated in [HL91]. <p> For data flow testing, this condition only ensures that the define part of a selected def-use pair criteria is reached. 3 Program mutation has been studied for over a decade and is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. It will not be discussed in detail here. <p> In Table 5.1, mutant operators of the MOTHRA [CDK + 89, KO91] testing tool for FORTRAN 77 are listed. Mutant operators for C have been reported in [ADH + 89], and are a 1 Readers are referred to <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref> for details of program mutation. 47 Table 5.1 Mutant operators used by MOTHRA for FORTRAN 77.
Reference: [CC87] <author> James S. Collofello and Larry Cousins. </author> <title> Towards automatic software fault location through decision-to-decision path analysis. </title> <booktitle> In AFIPS Proceedings of 1987 National Computer Conference, </booktitle> <pages> pages 539-544, </pages> <address> Chicago, Illinois, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: Korel and Laski proposed an algorithm based on the hypothesis-and-test cycle and the above knowledge to localize faults interactively.[KL91] Only a subset of Pascal is supported, and limited program errors are considered in STAD and PELAS. Collofello and Cousins <ref> [CC87] </ref> proposed a set of heuristics to locate suspicious statement blocks after a thorough test. A program is first partitioned into many decision-to-decision paths (DD-paths), which are composite statements existing between predicates. <p> Detailed results of our experiment are presented in Chapter 6.2.3. Heuristics and experiments according to relational (decision-to-decision) path analysis on execution paths were studied by Collofello and Cousins <ref> [CC87] </ref>. A few of their approaches are similar to ours, such as the concept behind Heuristic 13, the most useful one among theirs.
Reference: [CDK + 89] <author> B. J. Choi, R. A. DeMillo, E. W. Krauser, R. J. Martin, A. P. Mathur, A. J. Offutt, H. Pan, and E. H. Spafford. </author> <title> The Mothra tool set. </title> <booktitle> In Proceedings of the 22nd Annual Hawaii International Conference on Systems Sciences, </booktitle> <pages> pages 275-284, </pages> <address> Kona, Hawaii, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: See [AH90, ADS91a, Agr91] for the formal definition. 2 Program mutation has been studied for over a decade. It is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. and is described in Chapter 5. 5 1.3 Contributions The principal contribution of this dissertation is a new debugging paradigm for enhancing the process of fault localization by reducing the search domain. <p> For data flow testing, this condition only ensures that the define part of a selected def-use pair criteria is reached. 3 Program mutation has been studied for over a decade and is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. It will not be discussed in detail here. <p> If P is correct, the test set is evidence to assure the correctness of P . On the other hand, if P is not correct, the faults will be manifested by test data generated for killing some simple mutants. In Table 5.1, mutant operators of the MOTHRA <ref> [CDK + 89, KO91] </ref> testing tool for FORTRAN 77 are listed. <p> In Table 5.1, mutant operators of the MOTHRA [CDK + 89, KO91] testing tool for FORTRAN 77 are listed. Mutant operators for C have been reported in [ADH + 89], and are a 1 Readers are referred to <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref> for details of program mutation. 47 Table 5.1 Mutant operators used by MOTHRA for FORTRAN 77.
Reference: [Cho90] <author> Byoungju Choi. </author> <title> Software Testing Using High Performance Computers. </title> <type> PhD thesis, </type> <institution> Purdue University, West Lafayette, Indiana, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Thus, we can obtain critical slices automatically while killing sdl mutants in the testing phase with minor instrumentation. In this case, the cost of constructing critical slices is not a concern at all. Moreover, the research to perform program mutation in an efficient manner has been conducted. <ref> [Cho90, Kra91] </ref> With that support, the critical slices can be efficiently constructed during mutation-based testing. 5.1.2.3 Effectiveness To study the effectiveness of Critical Slicing (CS), we are interested in the reduction rate among the size of critical slices, corresponding expanded dynamic program slices, and the original program.
Reference: [CHT79] <author> Thomas E. Cheatham, Glenn H. Holloway, and Judy A. Townley. </author> <title> Symbolic evaluation and the analysis of programs. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-5(4):402-417, </volume> <month> July </month> <year> 1979. </year>
Reference-contexts: Clark and Richardson [CR83] were the first to suggest certain testing strategies and classified failure types can be used for debugging purposes. Only one example was given to describe their idea. No further detailed study was conducted. They described how certain test data selection strategies based on symbolic evaluation <ref> [How77, CHT79, CR81] </ref> can help the debugging process. Typical error types classified by them include: erroneous reference to an input value; erroneous processing of special input values; erroneous processing of typical/atypical values; erroneous loop processing (e.g., never terminated, never executed); and erroneous production of special/typical/atypical output values.
Reference: [CPRZ89] <author> Lori A. Clarke, Andy Podgurski, Debra J. Richardson, and Steven J. Zeil. </author> <title> A formal evaluation of data flow path selection criteria. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-15(11):1318-1332, </volume> <month> November </month> <year> 1989. </year>
Reference-contexts: And yet, the error-revealing criteria are the if and only if condition to reveal the fault. Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing <ref> [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83] </ref>, and fault-based testing [DLS78, Bud80, BDLS80, How82, Mor90]. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing.
Reference: [CR81] <author> Lori A. Clarke and Debra J. Richardson. </author> <title> Symbolic evaluation methods implementations and applications. </title> <editor> In B. Chandrasekaran and S. Radicchi, editors, </editor> <booktitle> Computer Program Testing, </booktitle> <pages> pages 65-102. </pages> <publisher> North-Holland Publishing Co., </publisher> <year> 1981. </year>
Reference-contexts: Clark and Richardson [CR83] were the first to suggest certain testing strategies and classified failure types can be used for debugging purposes. Only one example was given to describe their idea. No further detailed study was conducted. They described how certain test data selection strategies based on symbolic evaluation <ref> [How77, CHT79, CR81] </ref> can help the debugging process. Typical error types classified by them include: erroneous reference to an input value; erroneous processing of special input values; erroneous processing of typical/atypical values; erroneous loop processing (e.g., never terminated, never executed); and erroneous production of special/typical/atypical output values.
Reference: [CR83] <author> Lori A. Clarke and Debra J. Richardson. </author> <title> The application of error-sensitive testing strategies to debugging. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on High-Level Debugging, </booktitle> <pages> pages 45-52, </pages> <address> Pacific Grove, California, </address> <month> March </month> <year> 1983. </year> <journal> (ACM Software Engineering Notes, 8(4), August 1983; ACM SIGPLAN Notices, </journal> <volume> 18(8), </volume> <month> August </month> <year> 1983). </year>
Reference-contexts: An interesting result is suggested by Osterweil's research: debugging 15 is probably best supported by a mix of static and dynamic capabilities, just as is the case for testing and verification. This points out a valuable direction for building new debugging tools. Clark and Richardson <ref> [CR83] </ref> were the first to suggest certain testing strategies and classified failure types can be used for debugging purposes. Only one example was given to describe their idea. No further detailed study was conducted.
Reference: [DE88] <author> Mireille Ducasse and Anna-Maria Emde. </author> <title> A review of automated debugging systems: Knowledge, strategies, and techniques. </title> <booktitle> In Proceedings of the 10th International Conference on Software Engineering, </booktitle> <pages> pages 162-171, </pages> <address> Singapore, </address> <month> April </month> <year> 1988. </year>
Reference-contexts: systems for program debugging have been developed based on this approach since the early 1980s.<ref> [DE88, Sev87] </ref> Knowledge of both the classified faults and the nature of program behavior is usually required in this approach. However, the knowledge required for real world programs is too complicated. The prototype systems mentioned in [DE88, Sev87] can only handle restricted fault classes and very simple programs. A few representative debugging tools using knowledge-based approaches are reviewed in this section. PUDSY (Program Understanding and Debugging SYstem) [Luk80] analyzes a program before starting the process of debugging.
Reference: [Deu79] <author> M. Deutsch. </author> <title> Verification and validation. </title> <editor> In R. W. Jensen and C. C. Tonies, editors, </editor> <booktitle> Software Engineering, </booktitle> <pages> pages 329-408. </pages> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1979. </year>
Reference: [DGK + 88] <author> R. A. DeMillo, D. Guindi, K. N. King, W. M. McCracken, and A. J. Offutt. </author> <title> An extended overview of the Mothra software testing environment. </title> <booktitle> In Proceedings of the Second Workshop on Software Testing, Verification and Analysis, </booktitle> <pages> pages 142-151, </pages> <address> Banff, Canada, </address> <month> July </month> <year> 1988. </year> <month> 128 </month>
Reference-contexts: See [AH90, ADS91a, Agr91] for the formal definition. 2 Program mutation has been studied for over a decade. It is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. and is described in Chapter 5. 5 1.3 Contributions The principal contribution of this dissertation is a new debugging paradigm for enhancing the process of fault localization by reducing the search domain. <p> For data flow testing, this condition only ensures that the define part of a selected def-use pair criteria is reached. 3 Program mutation has been studied for over a decade and is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. It will not be discussed in detail here. <p> In Table 5.1, mutant operators of the MOTHRA [CDK + 89, KO91] testing tool for FORTRAN 77 are listed. Mutant operators for C have been reported in [ADH + 89], and are a 1 Readers are referred to <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref> for details of program mutation. 47 Table 5.1 Mutant operators used by MOTHRA for FORTRAN 77.
Reference: [DLS78] <author> R. A. DeMillo, R. J. Lipton, and F. G. Sayward. </author> <title> Hints on test data selection: Help for the practicing programmer. </title> <journal> Computer, </journal> <volume> 11(4) </volume> <pages> 34-43, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: See [AH90, ADS91a, Agr91] for the formal definition. 2 Program mutation has been studied for over a decade. It is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. and is described in Chapter 5. 5 1.3 Contributions The principal contribution of this dissertation is a new debugging paradigm for enhancing the process of fault localization by reducing the search domain. <p> Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83], and fault-based testing <ref> [DLS78, Bud80, BDLS80, How82, Mor90] </ref>. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing. These two methods are superior to the first one as indicated in [HL91]. <p> For data flow testing, this condition only ensures that the define part of a selected def-use pair criteria is reached. 3 Program mutation has been studied for over a decade and is well documented in the literature <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref>. It will not be discussed in detail here. <p> In Table 5.1, mutant operators of the MOTHRA [CDK + 89, KO91] testing tool for FORTRAN 77 are listed. Mutant operators for C have been reported in [ADH + 89], and are a 1 Readers are referred to <ref> [CDK + 89, DGK + 88, BDLS80, Bud80, DLS78] </ref> for details of program mutation. 47 Table 5.1 Mutant operators used by MOTHRA for FORTRAN 77. <p> This extreme situation is unlikely to provide useful information for debugging purposes. We therefore focus on the control dependency variation made by predicate statements. In program mutation, all hidden paths <ref> [DLS78] </ref> implicit in a compound predicate will be tested. The compound predicate is unfolded into a series of simple predicates that all paths are exercised in mutation-based testing. For simplicity, we assume that all compound predicates have been unfolded.
Reference: [DO91] <author> R. A. DeMillo and A. J. Offutt. </author> <title> Constraint-based automatic test data generation. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-17(9):900-910, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: These two methods are superior to the first one as indicated in [HL91]. To examine the way error-indicating criteria are satisfied and the corresponding error-revealing test cases cause program failure, we employ three characteristics addressed in Constraint Based Testing <ref> [DO91, Off88] </ref>, interpreted as follows for our analysis: Reachability: The code specified by the criteria must be included in the program execution flow after applying a given error-revealing test case. <p> The three characteristics for killing mutants have been studied in the constraint-based testing <ref> [Off88, DO91] </ref> and are summarized here. * Reachability: The mutated statement on line S in the mutant program M , S M , is executed by a given test case. * Necessity: The program state of M immediately following the execution of S M is different from the program state of
Reference: [Dun86] <author> Kevin J. Dunlap. </author> <title> Debugging with DBX. In UNIX Programmers Manual, </title> <type> Supplementary Documents 1, </type> <institution> 4.3 Berkeley Software Distribution. Computer Science Division, University of California, Berkeley, California, </institution> <month> April </month> <year> 1986. </year>
Reference-contexts: Although testing and debugging are closely related, none of the existing debugging tools attempt to interface with testing tools. Conventional debugging tools (e.g., ADB and DBX <ref> [Dun86] </ref>) are command-driven symbolic debugging tools and tend to be stand-alone. Many fault localization strategies used in current well-known debugging tools (e.g., setting break-points and tracing) were developed in the 1960s and have changed little. [AS89] These debugging tools do not locate faults efficiently. <p> One debugging technique setting break-points by users has been the main facility of many debugging tools for both low-level and high-level languages since the early 1960s (e.g., DDT [SW65] and FLIT [SD60] for assembly languages, and DBX <ref> [Dun86] </ref> for C). In order to avoid dealing with machine codes as well as scattering print statements in a program, interactive symbolic debugging tools were developed. <p> not only the basic facility, setting break-points, but also some of the following capabilities: displaying values of variables, tracing preset trace-points during execution, continuing execution of the program from a break-point, executing single steps from a break-point, modifying program states such as value of variables, and reexecuting a program (e.g., <ref> [Kat79, MB79, Bea83, Dun86] </ref>). These utilities can be employed by users to investigate a faulty program 8 interactively. First, users can set break-points in the program. Then, the execution of the program will be suspended at these break-points.
Reference: [Fer87] <author> G. Ferrand. </author> <title> Error diagnosis in logic programming, an adaptation of E. Y. Shapiro's method. </title> <journal> Journal of Logic Programming, </journal> <volume> 4(3) </volume> <pages> 177-198, </pages> <month> September </month> <year> 1987. </year>
Reference: [FGKS91] <author> Peter Fritzson, Tibor Gyimothy, Mariam Kamkar, and Nahid Shahmehri. </author> <title> Generalized algorithmic debugging and testing. </title> <booktitle> In Proceedings of the ACM SIG-PLAN'91 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 317-326, </pages> <address> Toronto, Canada, </address> <month> June 26-28 </month> <year> 1991. </year>
Reference-contexts: The primary limitation of applying this approach to programs written in structured languages such as Pascal is that it can only point out the procedure containing bugs. Other debugging tools are needed to debug the faulty procedure. A similar result can be found in <ref> [FGKS91] </ref>. 10 2.3 Knowledge-Based Approaches This approach attempts to automate the debugging process by using the techniques of artificial intelligence and knowledge engineering.
Reference: [FW88] <author> Phyllis G. Frankl and Elaine J. Weyuker. </author> <title> An applicable family of data flow testing criteria. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-14(10):1483-1498, </volume> <month> October </month> <year> 1988. </year>
Reference-contexts: And yet, the error-revealing criteria are the if and only if condition to reveal the fault. Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing <ref> [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83] </ref>, and fault-based testing [DLS78, Bud80, BDLS80, How82, Mor90]. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing.
Reference: [FW91] <author> Phyllis G. Frankl and Stewart N. Weiss. </author> <title> An experimental comparison of the effectiveness of the all-uses and all-edges adequacy criteria. </title> <booktitle> In Proceedings of the 1991 Symposium on Software Testing, Analysis and Verification (TAV4), </booktitle> <pages> pages 154-164, </pages> <address> Victoria, British Columbia, Canada, </address> <month> October 8-10 </month> <year> 1991. </year>
Reference: [GD74] <author> John D. Gould and Paul Drongowski. </author> <title> An exploratory study of computer program debugging. </title> <booktitle> Human Factors, </booktitle> <volume> 16(3) </volume> <pages> 258-277, </pages> <month> May-June </month> <year> 1974. </year>
Reference-contexts: However, these criteria have not been fully met by existing debugging tools. 1.1 Problems in Locating Faults Two major steps involved in the debugging process are locating and then correcting faults. Myers [Mye79] pointed out that the fault-locating aspect represents 95% of the debugging effort. Several studies <ref> [GD74, Gou75, Ves85, Mye79, MM83, ST83] </ref>, including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process.
Reference: [Gel78] <author> M. Geller. </author> <title> Test data as an aid in proving program correctness. </title> <journal> Communications of the ACM, </journal> <volume> 21(5) </volume> <pages> 368-375, </pages> <month> May </month> <year> 1978. </year>
Reference: [GG75] <author> J. B. Goodenough and S. L. Gerhart. </author> <title> Towards a theory of test data selection. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-1(2):156-173, </volume> <month> June </month> <year> 1975. </year>
Reference: [Gou75] <author> John D. Gould. </author> <title> Some psychological evidence on how people debug computer programs. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 7(2) </volume> <pages> 151-182, </pages> <month> March </month> <year> 1975. </year>
Reference-contexts: However, these criteria have not been fully met by existing debugging tools. 1.1 Problems in Locating Faults Two major steps involved in the debugging process are locating and then correcting faults. Myers [Mye79] pointed out that the fault-locating aspect represents 95% of the debugging effort. Several studies <ref> [GD74, Gou75, Ves85, Mye79, MM83, ST83] </ref>, including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process.
Reference: [Gus78] <author> F. Gustavson. </author> <title> Remark on algorithm 408. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 4:295, </volume> <year> 1978. </year> <month> 129 </month>
Reference: [Har83] <author> Mehdi T. Harandi. </author> <title> Knowledge-based program debugging: A heuristic model. </title> <booktitle> In Softfair Proceedings: A Conference on Software Development Tools, Techniques, and Alternatives, </booktitle> <pages> pages 282-288, </pages> <address> Los Alamitos, California, </address> <month> July </month> <year> 1983. </year> <note> IEEE CS Press. </note>
Reference-contexts: Then, the faults are reported in terms of the prototype schema (similar to the programming plans in PROUST) rather than the buggy code. Unfortunately, only a limited class of programs and faults are implemented in this system. Harandi <ref> [Har83] </ref> presented a heuristic model for knowledge-based program debugging. The system aims to debug compile-time errors and certain run-time errors. It is assumed that most of the debugging knowledge of experienced programmers can be encoded as heuristic rules in the form of situation-action pairs.
Reference: [HL91] <author> J. R. Horgan and S. </author> <title> London. Data flow coverage and the C language. </title> <booktitle> In Proceedings of the 1991 Symposium on Software Testing, Analysis, and Verification (TAV4), </booktitle> <pages> pages 87-97, </pages> <address> Victoria, British Columbia, Canada, </address> <month> October 8-10 </month> <year> 1991. </year>
Reference-contexts: And yet, the error-revealing criteria are the if and only if condition to reveal the fault. Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing <ref> [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83] </ref>, and fault-based testing [DLS78, Bud80, BDLS80, How82, Mor90]. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing. <p> For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing. These two methods are superior to the first one as indicated in <ref> [HL91] </ref>. <p> Columns 4 to 7 are obtained from a data flow coverage testing tool ATAC (Automatic Test Analysis for C programs) <ref> [HL91] </ref>, developed at Bellcore. 1 The programs are described in Appendix C. 91 Column blocks (#Bl) represents the number of code fragments not containing control flow branching.
Reference: [Hoa61] <author> C. Hoare. </author> <title> Algorithm 65: FIND. </title> <journal> Communications of the ACM, </journal> <volume> 4(1):321, </volume> <month> April </month> <year> 1961. </year>
Reference: [How77] <author> William E. Howden. </author> <title> Symbolic testing and the DISSECT symbolic evaluation system. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-3(4):266-278, </volume> <month> July </month> <year> 1977. </year>
Reference-contexts: Clark and Richardson [CR83] were the first to suggest certain testing strategies and classified failure types can be used for debugging purposes. Only one example was given to describe their idea. No further detailed study was conducted. They described how certain test data selection strategies based on symbolic evaluation <ref> [How77, CHT79, CR81] </ref> can help the debugging process. Typical error types classified by them include: erroneous reference to an input value; erroneous processing of special input values; erroneous processing of typical/atypical values; erroneous loop processing (e.g., never terminated, never executed); and erroneous production of special/typical/atypical output values.
Reference: [How82] <author> William E. Howden. </author> <title> Weak mutation testing and completeness of test sets. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-8(4):371-379, </volume> <month> July </month> <year> 1982. </year>
Reference-contexts: Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83], and fault-based testing <ref> [DLS78, Bud80, BDLS80, How82, Mor90] </ref>. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing. These two methods are superior to the first one as indicated in [HL91].
Reference: [HR83] <author> T. Haerder and A. Reuter. </author> <title> Principles of transaction-oriented database recovery. </title> <journal> ACM Computing Surveys, </journal> <volume> 15(4) </volume> <pages> 287-317, </pages> <month> December </month> <year> 1983. </year>
Reference-contexts: These drawbacks increase the difficulty of debugging. Another debugging technique keeps track of execution history for backtracking. The concept of execution backtracking has been implemented in database systems (e.g., rollback recovery for system failure <ref> [Ver78, HR83] </ref>) and in fault-tolerant software systems (e.g., the recovery-block technique [Ran75]). In the above implementations, system states to be rolled back for later analysis must be set at the beginning.
Reference: [HRB90] <author> Susan Horwitz, Thomas Reps, and David Binkeley. </author> <title> Interprocedural slicing using dependence graphs. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(1) </volume> <pages> 26-60, </pages> <month> January </month> <year> 1990. </year> <booktitle> (A preliminary version appeared in the Proceedings of the ACM SIGPLAN '88 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 35-46, </pages> <address> Atlanta, Georgia, </address> <month> June 22-24, </month> <year> 1988. </year> <journal> ACM SIGPLAN Notices, </journal> <volume> 23(7), </volume> <month> July </month> <year> 1988). </year>
Reference-contexts: The location parameter of suspicious dynamic slices is often set to the end of program execution, and Dyn (P; v; l; t) is presented as Dyn (P; v; $; t). Furthermore, we employ the forward dynamic slice <ref> [HRB90] </ref> to observe the propagation of the local effect after the execution of the original statement and the mutated statement on line S (S P and S M ).
Reference: [HT90] <author> Dick Hamlet and Ross Taylor. </author> <title> Partition analysis does not inspire confidence. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-16(12):1402-1411, </volume> <month> Decem-ber </month> <year> 1990. </year> <title> (An early version presented at Proceedings of the Second Workshop on Software Testing, Analysis, </title> <booktitle> and Verification (TAV2), </booktitle> <pages> pages 206-215, </pages> <address> Banff, Canada, </address> <month> July </month> <year> 1988). </year>
Reference-contexts: A set of error-revealing test cases is an indispensable resource for debugging. On the other hand, not every non-error-revealing test case is useful. Partition analysis on the input domain helps us identify the subdomains associated with program failures. <ref> [WO80, RC85, HT90, WJ91] </ref> After a thorough test, users can partition the input domain of P based on the specification of P and the results from testing.
Reference: [Joh83] <author> Mark Scott Johnson, </author> <title> editor. </title> <booktitle> Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on High-Level Debugging, </booktitle> <address> Pacific Grove, California, </address> <month> March </month> <year> 1983. </year> <journal> (ACM Software Engineering Notes, 8(4), August 1983; ACM SIGPLAN Notices, </journal> <volume> 18(8), </volume> <month> August </month> <year> 1983). </year>
Reference: [JS84] <author> W. Lewis Johnson and Elliot Soloway. </author> <title> Intention-based diagnosis of programming errors. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, AAAI-84, </booktitle> <pages> pages 162-168, </pages> <address> Austin, Texas, </address> <month> August 6-10 </month> <year> 1984. </year> <journal> American Association of Artificial Intelligence. </journal>
Reference-contexts: Programs for comparison are transformed into internal representation forms flow graphs. Then, the flow graphs are systematically compared by Laura to automatically locate bugs. Because of the limitation of flow graphs to representing complicated programs, this system is designed for tutorial purposes in classrooms. PROUST <ref> [JS84, JS85] </ref> is an intention-based diagnosis system to help novice programmers learn how to write correct programs. It does online analysis and understanding of Pascal programs in order to identify nonsyntactic bugs. PROUST takes a program and a description of the program's intentions as input.
Reference: [JS85] <author> W. Lewis Johnson and Elliot Soloway. </author> <title> PROUST: Knowledge-based program understanding. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11(3):267-275, </volume> <month> March </month> <year> 1985. </year> <month> 130 </month>
Reference-contexts: Programs for comparison are transformed into internal representation forms flow graphs. Then, the flow graphs are systematically compared by Laura to automatically locate bugs. Because of the limitation of flow graphs to representing complicated programs, this system is designed for tutorial purposes in classrooms. PROUST <ref> [JS84, JS85] </ref> is an intention-based diagnosis system to help novice programmers learn how to write correct programs. It does online analysis and understanding of Pascal programs in order to identify nonsyntactic bugs. PROUST takes a program and a description of the program's intentions as input.
Reference: [JSCD83] <author> W. Lewis Johnson, Elliot Soloway, Benjamin Cutler, and Steven Draper. </author> <title> Bug catalogue: I. </title> <type> Technical Report YaleU/CSD/RR #286, </type> <institution> Department of Computer Science, Yale University, </institution> <address> New Haven, Connecticut, </address> <month> October </month> <year> 1983. </year>
Reference-contexts: An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3. ANALYSIS OF A NEW DEBUGGING APPROACH Most studies of fault analysis <ref> [Knu89, BP84, OW84, Bow80, Lip79, AC73, JSCD83, SPL + 85] </ref> classify faults collected from long-term projects. However, no further studies have been conducted based on the categorized information. We believe that there is value to debugging research in such analysis.
Reference: [Kat79] <author> H. Katsoff. SDB: </author> <title> A symbolic debugger. In UNIX Programmers Manual. </title> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, New Jersey, </address> <year> 1979. </year>
Reference-contexts: not only the basic facility, setting break-points, but also some of the following capabilities: displaying values of variables, tracing preset trace-points during execution, continuing execution of the program from a break-point, executing single steps from a break-point, modifying program states such as value of variables, and reexecuting a program (e.g., <ref> [Kat79, MB79, Bea83, Dun86] </ref>). These utilities can be employed by users to investigate a faulty program 8 interactively. First, users can set break-points in the program. Then, the execution of the program will be suspended at these break-points.
Reference: [KL88a] <author> Bogdan Korel and Janusz Laski. </author> <title> Dynamic program slicing. </title> <journal> Information Processing Letters, </journal> <volume> 29(3) </volume> <pages> 155-163, </pages> <month> October 26 </month> <year> 1988. </year>
Reference-contexts: The static program slicing approach cannot resolve runtime ambiguities, thus highlights many spurious statements with no influence on the incorrect results. In this case, the faulty statements cannot be effectively identified. Korel and Laski <ref> [KL88a, KL90] </ref> extended Weiser's static program slicing to dynamic program slicing (K-L slicing). K-L slicing defines an executable subset of an original program that computes the same function for given variables and inputs.
Reference: [KL88b] <author> Bogdan Korel and Janusz Laski. </author> <title> STAD a system for testing and debugging: User perspective. </title> <booktitle> In Proceedings of the Second Workshop on Software Testing, Analysis, and Verification, </booktitle> <pages> pages 13-20, </pages> <address> Banff, Canada, </address> <month> July </month> <year> 1988. </year>
Reference-contexts: If an error in a program is detected after selected test data are applied to the program, we can know the potential type of the error and then locate the bugs through the attributes of the test data and the erroneous results. STAD (System for Testing And Debugging) <ref> [KL88b, Las90, Kor86] </ref> is the first tool to integrate debugging with testing. Nevertheless, its testing and debugging parts do not share much information together except for implementation purposes (e.g., they share the results of data flow analysis).
Reference: [KL90] <author> Bogdan Korel and Janusz Laski. </author> <title> Dynamic slicing of computer programs. </title> <journal> The Journal of Systems and Software, </journal> <volume> 13(3) </volume> <pages> 187-195, </pages> <month> November </month> <year> 1990. </year>
Reference-contexts: The static program slicing approach cannot resolve runtime ambiguities, thus highlights many spurious statements with no influence on the incorrect results. In this case, the faulty statements cannot be effectively identified. Korel and Laski <ref> [KL88a, KL90] </ref> extended Weiser's static program slicing to dynamic program slicing (K-L slicing). K-L slicing defines an executable subset of an original program that computes the same function for given variables and inputs.
Reference: [KL91] <author> Bogdan Korel and Janusz Laski. </author> <title> Algorithmic software fault localization. </title> <booktitle> In Proceedings of the Twenty-Fourth Annual Hawaii International Conference on System Sciences, </booktitle> <pages> pages 246-252, </pages> <address> Hawaii, </address> <month> January </month> <year> 1991. </year>
Reference: [Knu89] <author> D. E. Knuth. </author> <title> The errors of T E X. </title> <journal> Software Practice and Experience, </journal> <volume> 19(7) </volume> <pages> 607-685, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3. ANALYSIS OF A NEW DEBUGGING APPROACH Most studies of fault analysis <ref> [Knu89, BP84, OW84, Bow80, Lip79, AC73, JSCD83, SPL + 85] </ref> classify faults collected from long-term projects. However, no further studies have been conducted based on the categorized information. We believe that there is value to debugging research in such analysis.
Reference: [KO91] <author> K. N. King and A. Jefferson Offutt. </author> <title> A fortran language system for mutation-based software testing. </title> <journal> Software Practice and Experience, </journal> <volume> 21(7) </volume> <pages> 685-718, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: If P is correct, the test set is evidence to assure the correctness of P . On the other hand, if P is not correct, the faults will be manifested by test data generated for killing some simple mutants. In Table 5.1, mutant operators of the MOTHRA <ref> [CDK + 89, KO91] </ref> testing tool for FORTRAN 77 are listed.
Reference: [Kor86] <author> Bogdan Korel. </author> <title> Dependence-Based Modeling in the Automation of Error Localization in Computer Programs. </title> <type> PhD thesis, </type> <institution> Oakland University, Rochester, Michigan, </institution> <year> 1986. </year>
Reference-contexts: If an error in a program is detected after selected test data are applied to the program, we can know the potential type of the error and then locate the bugs through the attributes of the test data and the erroneous results. STAD (System for Testing And Debugging) <ref> [KL88b, Las90, Kor86] </ref> is the first tool to integrate debugging with testing. Nevertheless, its testing and debugging parts do not share much information together except for implementation purposes (e.g., they share the results of data flow analysis).
Reference: [Kor88] <author> Bogdan Korel. </author> <title> PELAS program error-locating assistant system. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-14(9):1253-1260, </volume> <month> September </month> <year> 1988. </year>
Reference-contexts: Then, all hypotheses in the set are verified by users at preset break-points while reexecuting the program. The main goal of fault localization in the debugging session of STAD is to help users focus on the possible erroneous region, rather than precisely locating faults. PELAS (Program Error-Locating Assistant System) <ref> [Kor88] </ref> is an implementation of the debugging part of STAD. Korel and Laski proposed an algorithm based on the hypothesis-and-test cycle and the above knowledge to localize faults interactively.[KL91] Only a subset of Pascal is supported, and limited program errors are considered in STAD and PELAS. <p> We say the if-statement at Statement 5 has type PE1. Statement 6 is in the scope of the predicate 2 This definition is different from the potential influence defined by Korel <ref> [Kor88] </ref>.
Reference: [Kra91] <author> Edward W. Krauser, Jr. </author> <title> Compiler-Integrated Software Testing. </title> <type> PhD thesis, </type> <institution> Purdue University, West Lafayette, Indiana, </institution> <month> December </month> <year> 1991. </year> <note> (Also released as Technical Report SERC-TR-118-P, </note> <institution> Software Engineering Research Center, Purdue University, West Lafayette, Indiana, </institution> <month> July </month> <year> 1992). </year>
Reference-contexts: Thus, we can obtain critical slices automatically while killing sdl mutants in the testing phase with minor instrumentation. In this case, the cost of constructing critical slices is not a concern at all. Moreover, the research to perform program mutation in an efficient manner has been conducted. <ref> [Cho90, Kra91] </ref> With that support, the critical slices can be efficiently constructed during mutation-based testing. 5.1.2.3 Effectiveness To study the effectiveness of Critical Slicing (CS), we are interested in the reduction rate among the size of critical slices, corresponding expanded dynamic program slices, and the original program. <p> If a mutant changes the variable reference, then the whole dependency graph could be changed. An efficient way to construct, save, and retrieve the dependency graph (static and especially the dynamic) of mutants is needed to reduce the overload. The compiler integrated testing to support program mutation <ref> [Kra91] </ref> is a possible avenue of research to resolve the problem. 7.5 Future Work In this section, new directions of this research are discussed. 7.5.1 Fault Guessing Heuristics The reduced search domain suggested by the proposed fault localization techniques can be immediately used as the working scope to locate faults.
Reference: [Las90] <author> Janusz Laski. </author> <title> Data flow testing in STAD. </title> <journal> The Journal of Systems and Software, </journal> <volume> 12(1) </volume> <pages> 3-14, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: If an error in a program is detected after selected test data are applied to the program, we can know the potential type of the error and then locate the bugs through the attributes of the test data and the erroneous results. STAD (System for Testing And Debugging) <ref> [KL88b, Las90, Kor86] </ref> is the first tool to integrate debugging with testing. Nevertheless, its testing and debugging parts do not share much information together except for implementation purposes (e.g., they share the results of data flow analysis).
Reference: [Lau79] <author> Soren Lauesen. </author> <title> Debugging techniques. </title> <journal> Software-Practice and Experience, </journal> <volume> 9(1) </volume> <pages> 51-63, </pages> <month> January </month> <year> 1979. </year>
Reference: [Lip79] <author> Myron Lipow. </author> <title> Prediction of software failures. </title> <journal> The Journal of Systems and Software, </journal> <volume> 1(1) </volume> <pages> 71-75, </pages> <year> 1979. </year> <month> 131 </month>
Reference-contexts: An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3. ANALYSIS OF A NEW DEBUGGING APPROACH Most studies of fault analysis <ref> [Knu89, BP84, OW84, Bow80, Lip79, AC73, JSCD83, SPL + 85] </ref> classify faults collected from long-term projects. However, no further studies have been conducted based on the categorized information. We believe that there is value to debugging research in such analysis. <p> Then, a set of tested programs that are faulty and have been previously referred to in the software testing community is illustrated. Features of these programs vary in fault types and locations that match previous studies of fault categories and frequencies in major projects <ref> [Lip79] </ref> that indicate 26% logic faults, 18% data handling faults, 9% computational faults, : : :, etc. Although the sample space of tested programs is not large, we try to balance the features of our samples according to previous studies.
Reference: [LK83] <author> Janusz Laski and Bogdan Korel. </author> <title> A data flow oriented program testing strategy. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-9(3):347-354, </volume> <month> May </month> <year> 1983. </year>
Reference-contexts: And yet, the error-revealing criteria are the if and only if condition to reveal the fault. Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing <ref> [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83] </ref>, and fault-based testing [DLS78, Bud80, BDLS80, How82, Mor90]. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing.
Reference: [Luk80] <author> F. J. Lukey. </author> <title> Understanding and debugging programs. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 12(2) </volume> <pages> 189-202, </pages> <month> February </month> <year> 1980. </year>
Reference-contexts: However, the knowledge required for real world programs is too complicated. The prototype systems mentioned in [DE88, Sev87] can only handle restricted fault classes and very simple programs. A few representative debugging tools using knowledge-based approaches are reviewed in this section. PUDSY (Program Understanding and Debugging SYstem) <ref> [Luk80] </ref> analyzes a program before starting the process of debugging. Inputs to PUDSY are a program and a specification of the program. A knowledge base is maintained for the first phase analyzing and understanding a program.
Reference: [LW87] <author> James R. Lyle and Mark Weiser. </author> <title> Automatic program bug location by program slicing. </title> <booktitle> In Proceedings of the 2nd International Conference on Computers and Applications, </booktitle> <pages> pages 877-883, </pages> <address> Beijing, PRC, </address> <month> June </month> <year> 1987. </year>
Reference-contexts: Thus, the search domain for faults is reduced from the entire program to the program slice. Focus <ref> [LW87] </ref> is an automatic debugging tool based on static program slicing to locate bugs. It attempts to combine program slices with test cases to find the suspicious region containing faults, which is assumed to be a subset of a program slice.
Reference: [Lyl84] <author> James R. Lyle. </author> <title> Evaluating Variations on Program Slicing for Debugging. </title> <type> PhD thesis, </type> <institution> University of Maryland, College Park, Maryland, </institution> <month> December </month> <year> 1984. </year>
Reference: [MB79] <author> J. F. Maranzano and S. R. Bourne. </author> <title> A tutorial introduction to ADB. In UNIX Programmers Manual. </title> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, New Jersey, </address> <year> 1979. </year>
Reference-contexts: not only the basic facility, setting break-points, but also some of the following capabilities: displaying values of variables, tracing preset trace-points during execution, continuing execution of the program from a break-point, executing single steps from a break-point, modifying program states such as value of variables, and reexecuting a program (e.g., <ref> [Kat79, MB79, Bea83, Dun86] </ref>). These utilities can be employed by users to investigate a faulty program 8 interactively. First, users can set break-points in the program. Then, the execution of the program will be suspended at these break-points.
Reference: [McN71] <author> J. M. McNamee. </author> <title> Algorithm 408: A sparse matrix package (part I) [f4]. </title> <journal> Communications of the ACM, </journal> <volume> 14(4) </volume> <pages> 265-273, </pages> <month> April </month> <year> 1971. </year>
Reference: [MM83] <author> J. Martin and C. McClure. </author> <title> Software Maintenance The Problem and Its Solution. </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1983. </year>
Reference-contexts: However, these criteria have not been fully met by existing debugging tools. 1.1 Problems in Locating Faults Two major steps involved in the debugging process are locating and then correcting faults. Myers [Mye79] pointed out that the fault-locating aspect represents 95% of the debugging effort. Several studies <ref> [GD74, Gou75, Ves85, Mye79, MM83, ST83] </ref>, including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process. <p> Several studies [GD74, Gou75, Ves85, Mye79, MM83, ST83], including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process. Different strategies for locating faults would therefore affect the performance of debugging. [SCML79] A representative paragraph from Martin <ref> [MM83] </ref> states: Traditionally, programmers have spent too much time looking for errors in the wrong places. Myers [Mye78] found that programmers focused their attention on normal processing at the expense of considering special processing situations and invalid inputs.
Reference: [Mor90] <author> Larry J. Morell. </author> <title> A theory of fault-based testing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-16(8):844-857, </volume> <month> August </month> <year> 1990. </year>
Reference-contexts: Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83], and fault-based testing <ref> [DLS78, Bud80, BDLS80, How82, Mor90] </ref>. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing. These two methods are superior to the first one as indicated in [HL91].
Reference: [Mur85] <author> William R. Murray. </author> <title> Heuristic and formal methods in automatic program debugging. </title> <booktitle> In Proceedings of the 9th International Joint Conference on Artificial Intelligence, IJCAI-85, </booktitle> <pages> pages 15-19, </pages> <address> Los Angeles, California, </address> <month> August </month> <year> 1985. </year>
Reference-contexts: Diagnosis of the problem and suggestions for correcting the faults are reported to novices. However, if there are no proper programming plans to synthesize the given goal (intention), bugs are reported even if the code of the given program is correct. This problem becomes serious with complicated programs. TALUS <ref> [Mur85, Mur86b, Mur86a] </ref> employs an approach similar to PROUST's, but uses a theorem prover to do the transformation from programming plans to codes. This method partially solves the problem of restricted programming plans in PROUST. However, TALUS can only handle small LISP programs.
Reference: [Mur86a] <author> William R. Murray. </author> <title> Automatic Program Debugging for Intelligent Tutoring Systems. </title> <type> PhD thesis, </type> <institution> The University of Texas at Austin, Austin, Texas, </institution> <month> June </month> <year> 1986. </year> <note> (Also released as Technical Report AI TR 86-27, </note> <institution> AI Laboratory, The University of Texas at Austin, Austin, Texas, </institution> <month> June </month> <year> 1986). </year>
Reference-contexts: Diagnosis of the problem and suggestions for correcting the faults are reported to novices. However, if there are no proper programming plans to synthesize the given goal (intention), bugs are reported even if the code of the given program is correct. This problem becomes serious with complicated programs. TALUS <ref> [Mur85, Mur86b, Mur86a] </ref> employs an approach similar to PROUST's, but uses a theorem prover to do the transformation from programming plans to codes. This method partially solves the problem of restricted programming plans in PROUST. However, TALUS can only handle small LISP programs.
Reference: [Mur86b] <author> William R. Murray. TALUS: </author> <title> Automatic program debugging for intelligent tutoring systems. </title> <type> Technical Report AI TR 86-32, </type> <institution> AI Laboratory, The University of Texas at Austin, Austin, Texas, </institution> <month> August </month> <year> 1986. </year>
Reference-contexts: Diagnosis of the problem and suggestions for correcting the faults are reported to novices. However, if there are no proper programming plans to synthesize the given goal (intention), bugs are reported even if the code of the given program is correct. This problem becomes serious with complicated programs. TALUS <ref> [Mur85, Mur86b, Mur86a] </ref> employs an approach similar to PROUST's, but uses a theorem prover to do the transformation from programming plans to codes. This method partially solves the problem of restricted programming plans in PROUST. However, TALUS can only handle small LISP programs.
Reference: [Mye78] <author> Glenford J. Myers. </author> <title> A controlled experiment in program testing and code walk-through/inspections. </title> <journal> Communications of the ACM, </journal> <volume> 21(9) </volume> <pages> 760-768, </pages> <month> September </month> <year> 1978. </year>
Reference-contexts: Different strategies for locating faults would therefore affect the performance of debugging. [SCML79] A representative paragraph from Martin [MM83] states: Traditionally, programmers have spent too much time looking for errors in the wrong places. Myers <ref> [Mye78] </ref> found that programmers focused their attention on normal processing at the expense of considering special processing situations and invalid inputs. Weinberg [Wei71] found that programmers have difficulty finding errors because their conjectures become prematurely fixed, blinding them to other possibilities.
Reference: [Mye79] <author> Glenford J. Myers. </author> <title> The Art of Software Testing. </title> <publisher> John Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: However, these criteria have not been fully met by existing debugging tools. 1.1 Problems in Locating Faults Two major steps involved in the debugging process are locating and then correcting faults. Myers <ref> [Mye79] </ref> pointed out that the fault-locating aspect represents 95% of the debugging effort. Several studies [GD74, Gou75, Ves85, Mye79, MM83, ST83], including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process. <p> However, these criteria have not been fully met by existing debugging tools. 1.1 Problems in Locating Faults Two major steps involved in the debugging process are locating and then correcting faults. Myers [Mye79] pointed out that the fault-locating aspect represents 95% of the debugging effort. Several studies <ref> [GD74, Gou75, Ves85, Mye79, MM83, ST83] </ref>, including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process.
Reference: [Nau69] <author> P. Naur. </author> <title> Programming by action clusters. </title> <journal> BIT, </journal> <volume> 9 </volume> <pages> 250-258, </pages> <year> 1969. </year> <month> 132 </month>
Reference: [Nta88] <author> Simeon C. Ntafos. </author> <title> A comparison of some structural testing strategies. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-14(6):868-874, </volume> <month> June </month> <year> 1988. </year>
Reference-contexts: And yet, the error-revealing criteria are the if and only if condition to reveal the fault. Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing <ref> [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83] </ref>, and fault-based testing [DLS78, Bud80, BDLS80, How82, Mor90]. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing.
Reference: [Off88] <author> A. J. Offutt. </author> <title> Automatic Test Data Generation. </title> <type> PhD thesis, </type> <institution> Department of Information and Computer Science, Georgia Institute of Technology, Atlanta, Georgia, </institution> <year> 1988. </year>
Reference-contexts: These two methods are superior to the first one as indicated in [HL91]. To examine the way error-indicating criteria are satisfied and the corresponding error-revealing test cases cause program failure, we employ three characteristics addressed in Constraint Based Testing <ref> [DO91, Off88] </ref>, interpreted as follows for our analysis: Reachability: The code specified by the criteria must be included in the program execution flow after applying a given error-revealing test case. <p> The three characteristics for killing mutants have been studied in the constraint-based testing <ref> [Off88, DO91] </ref> and are summarized here. * Reachability: The mutated statement on line S in the mutant program M , S M , is executed by a given test case. * Necessity: The program state of M immediately following the execution of S M is different from the program state of
Reference: [Ost84] <author> Leon Osterweil. </author> <title> Integrating the testing, analysis, and debugging of programs. </title> <editor> In H. L. Hausen, editor, </editor> <booktitle> Software Validation, </booktitle> <pages> pages 73-102. </pages> <publisher> Elsevier Science Publishers B. V., North-Holland, </publisher> <year> 1984. </year>
Reference-contexts: Even if they are integrated in one tool, strengthening the capability of this tool to detect and to locate faults needs to be seriously studied. This section will focus on the possibility of using the information derived from existing testing methodologies for debugging purposes. Osterweil <ref> [Ost84] </ref> attempted to integrate testing, analysis, and debugging, but gave no solid conclusion about how to transform information between testing and debugging to benefit each other.
Reference: [OW84] <author> Thomas J. Ostrand and Elaine J. Weyuker. </author> <title> Collecting and categorizing software error data in an industrial environment. </title> <journal> The Journal of Systems and Software, </journal> <volume> 4(4) </volume> <pages> 289-300, </pages> <month> November </month> <year> 1984. </year>
Reference-contexts: An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3. ANALYSIS OF A NEW DEBUGGING APPROACH Most studies of fault analysis <ref> [Knu89, BP84, OW84, Bow80, Lip79, AC73, JSCD83, SPL + 85] </ref> classify faults collected from long-term projects. However, no further studies have been conducted based on the categorized information. We believe that there is value to debugging research in such analysis.
Reference: [Pan91] <author> Hsin Pan. </author> <title> Debugging with dynamic instrumentation and test-based knowledge. </title> <type> Technical Report SERC-TR-105-P, </type> <institution> Software Engineering Research Center, Purdue University, West Lafayette, Indiana, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: We believe that there is value to debugging research in such analysis. In order to observe and analyze program failures, dynamic instrumentation capable of doing (dynamic) program dependency analysis is chosen as a basic facility of the new debugging approach. <ref> [Pan91] </ref> Dynamic Program Slicing can determine statements actually affecting program failures so that the search domain for faults will be reduced.
Reference: [PC90] <author> Andy Podgurski and Lori A. Clarke. </author> <title> A formal model of program dependences and its implications for software testing, debugging, and maintenance. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-16(9):965-979, </volume> <month> September </month> <year> 1990. </year>
Reference-contexts: And yet, the error-revealing criteria are the if and only if condition to reveal the fault. Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing <ref> [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83] </ref>, and fault-based testing [DLS78, Bud80, BDLS80, How82, Mor90]. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing.
Reference: [Per86] <author> L. M. Pereira. </author> <title> Rational debugging in logic programming. </title> <booktitle> In Proceedings of the 3rd Logic Programming Conference, </booktitle> <pages> pages 203-210, </pages> <address> London, England, </address> <month> July </month> <year> 1986. </year>
Reference: [Pre87] <author> Roger S. Pressman. </author> <title> Software Enginnering: A Practitioner's Approach. </title> <publisher> McGraw-Hill, Inc., </publisher> <address> New York, </address> <note> second edition, </note> <year> 1987. </year>
Reference: [PS93] <author> Hsin Pan and Eugene. H. Spafford. </author> <title> Fault localization methods for software debugging. </title> <journal> Journal of Computer and Software Engineering, </journal> <note> 1993. (to appear. A preliminary version appeared in Proceedings of the 10th Pacific Northwest Software Quality Conference, pages 192-209, </note> <institution> Portland, Oregon, </institution> <month> October 19-21 </month> <year> 1992). </year>
Reference-contexts: We thus chose to implement the heuristics based on the nodes in a program dependency graph to avoid confusion. However, the interpretation of experimental results based on executable statements addressed in <ref> [PS93] </ref> is similar to those based on the vertices in a program dependency graph addressed in the next section. 6.2 An Experiment We conducted a simple experiment to confirm the effectiveness and feasibility of the proposed heuristics. Results of coverage and effectiveness analysis are presented. <p> = the rank of the critical level # of ranked levels (6.5) general threshold = # of vertices (stmts) within and below the critical level # of vertices (stmts) in a selected heuristic (6.6) A similar experiment based on executable statements in Equations 6.1 and 6.2 has been reported in <ref> [PS93] </ref>. For Critical Slicing as described in Chapter 5.1, the size of a critical slice with respect to a test case is compared with the size of the original program, the size of the corresponding expanded dynamic program slice, and the size of the corresponding exact dynamic program slice.
Reference: [Ran75] <author> Brian Randell. </author> <title> System structure for software fault tolerance. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-1(2):220-232, </volume> <month> June </month> <year> 1975. </year>
Reference-contexts: These drawbacks increase the difficulty of debugging. Another debugging technique keeps track of execution history for backtracking. The concept of execution backtracking has been implemented in database systems (e.g., rollback recovery for system failure [Ver78, HR83]) and in fault-tolerant software systems (e.g., the recovery-block technique <ref> [Ran75] </ref>). In the above implementations, system states to be rolled back for later analysis must be set at the beginning. However, from the software debugging standpoint, execution backtracking should be able to gradually backtrack program execution from any break-point under the control of users.
Reference: [RC85] <author> Debra J. Richardson and Lori A. Clarke. </author> <title> Partition analysis: A method combining testing and verification. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11(12):1477-1490, </volume> <month> December </month> <year> 1985. </year> <booktitle> (An early version presented at Proceedings of the 5th International Conference on Software Engineering, </booktitle> <pages> pages 244-253, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1981). </year> <month> 133 </month>
Reference-contexts: A set of error-revealing test cases is an indispensable resource for debugging. On the other hand, not every non-error-revealing test case is useful. Partition analysis on the input domain helps us identify the subdomains associated with program failures. <ref> [WO80, RC85, HT90, WJ91] </ref> After a thorough test, users can partition the input domain of P based on the specification of P and the results from testing.
Reference: [Ren82] <author> Scott Renner. </author> <title> Location of logical errors on Pascal programs with an appendix on implementation problems in Waterloo PROLOG/C. </title> <type> Technical Report UIUCDCS-F-82-896, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, </institution> <month> April </month> <year> 1982. </year> <note> (Also with No. UIUC-ENG 82 1710). </note>
Reference: [RHC76] <author> C. V. Ramamoorthy, S. F. Ho, and W. T. Chen. </author> <title> On the automated generation of program test data. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-2(4):293-300, </volume> <month> December </month> <year> 1976. </year>
Reference: [RW85] <author> Sandra Rapps and Elaine J. Weyuker. </author> <title> Selecting software test data using data flow information. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-11(4):367-375, </volume> <month> April </month> <year> 1985. </year>
Reference-contexts: And yet, the error-revealing criteria are the if and only if condition to reveal the fault. Therefore, the error-indicating-criteria can be identified during the testing phase and used as indicators for debugging. Three white box testing methodologies were examined in our study. They are structural coverage, data flow testing <ref> [PC90, HL91, CPRZ89, Nta88, FW88, RW85, LK83] </ref>, and fault-based testing [DLS78, Bud80, BDLS80, How82, Mor90]. For the last two methods, we choose c-use and p-use criteria in data flow testing as well as program mutation 3 in fault-based testing.
Reference: [Sch71] <author> Jacob T. Schwartz. </author> <title> An overview of bugs. </title> <editor> In Randall Rustin, editor, </editor> <booktitle> Debugging Techniques in Large Systems, </booktitle> <pages> pages 1-16. </pages> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, New Jersey, </address> <year> 1971. </year>
Reference: [SCML79] <author> Sylvia B. Sheppard, Bill Curtis, Phil Milliman, and Tom Love. </author> <title> Modern coding practices and programmer performance. </title> <journal> Computer, </journal> <volume> 12(12) </volume> <pages> 41-49, </pages> <month> December </month> <year> 1979. </year>
Reference-contexts: Several studies [GD74, Gou75, Ves85, Mye79, MM83, ST83], including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process. Different strategies for locating faults would therefore affect the performance of debugging. <ref> [SCML79] </ref> A representative paragraph from Martin [MM83] states: Traditionally, programmers have spent too much time looking for errors in the wrong places. Myers [Mye78] found that programmers focused their attention on normal processing at the expense of considering special processing situations and invalid inputs.
Reference: [SD60] <author> T. G. Stockham and J. B. Dennis. FLIT: </author> <title> Flexowriter interrogation tape: A symbolic utility for TX-O. </title> <type> Memo 5001-23, </type> <institution> Department of Electrical Engineering, Massachusetts Institute of Technology, Cambridge, Massachusetts, </institution> <month> July </month> <year> 1960. </year>
Reference-contexts: One debugging technique setting break-points by users has been the main facility of many debugging tools for both low-level and high-level languages since the early 1960s (e.g., DDT [SW65] and FLIT <ref> [SD60] </ref> for assembly languages, and DBX [Dun86] for C). In order to avoid dealing with machine codes as well as scattering print statements in a program, interactive symbolic debugging tools were developed.
Reference: [Sev87] <author> Rudolph E. Seviora. </author> <title> Knowledge-based program debugging systems. </title> <journal> IEEE Software, </journal> <volume> 4(3) </volume> <pages> 20-32, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: systems for program debugging have been developed based on this approach since the early 1980s.<ref> [DE88, Sev87] </ref> Knowledge of both the classified faults and the nature of program behavior is usually required in this approach. However, the knowledge required for real world programs is too complicated. The prototype systems mentioned in [DE88, Sev87] can only handle restricted fault classes and very simple programs. A few representative debugging tools using knowledge-based approaches are reviewed in this section. PUDSY (Program Understanding and Debugging SYstem) [Luk80] analyzes a program before starting the process of debugging. <p> This method partially solves the problem of restricted programming plans in PROUST. However, TALUS can only handle small LISP programs. Generally speaking, the above systems, classified as program-analysis techniques <ref> [Sev87] </ref>, can only handle relatively small programs because they have to fully understand and statically analyze the programs to be debugged. The necessity of detailed understanding of programs prevents these techniques from being applied to practical programs.
Reference: [Sha83] <author> Ehud Y. Shapiro. </author> <title> Algorithmic Program Debugging. </title> <publisher> The MIT Press, </publisher> <address> Cam-bridge, Massachusetts, </address> <year> 1983. </year> <type> (PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, Con-necticut, </address> <year> 1982). </year>
Reference-contexts: Being able to display information (e.g., program execution flow, break-points, and program states) simultaneously makes the debugging process more convenient and efficient. 9 2.2 Algorithmic Approaches Shapiro <ref> [Sha83] </ref> proposed an interactive fault diagnosis algorithm, the Divide-and-Query algorithm, for debugging. The algorithm will recursively search a computation tree that represents the target program until bugs are located and fixed.
Reference: [SPL + 85] <author> James C. Spohrer, Edgar Pope, Michael Lipman, Warren Sack, Scott Freiman, David Littman, Lewis Johnson, and Elliot Soloway. </author> <title> Bug catalogue: II, III, IV. </title> <type> Technical Report YaleU/CSD/RR #386, </type> <institution> Department of Computer Science, Yale University, </institution> <address> New Haven, Connecticut, </address> <month> May </month> <year> 1985. </year>
Reference-contexts: An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3. ANALYSIS OF A NEW DEBUGGING APPROACH Most studies of fault analysis <ref> [Knu89, BP84, OW84, Bow80, Lip79, AC73, JSCD83, SPL + 85] </ref> classify faults collected from long-term projects. However, no further studies have been conducted based on the categorized information. We believe that there is value to debugging research in such analysis.
Reference: [ST83] <author> Robert L. Sedlmeyer and William B. Thompson. </author> <title> Knowledge-based fault localization in debugging. </title> <booktitle> In Proceedings of the ACM SIGSOFT/SIGPLAN Software Engineering Symposium on High-Level Debugging, </booktitle> <pages> pages 25-31, </pages> <address> Pacific Grove, California, </address> <month> March </month> <year> 1983. </year> <journal> (ACM Software Engineering Notes, 8(4), August 1983; ACM SIGPLAN Notices, </journal> <volume> 18(8), </volume> <month> August </month> <year> 1983). </year>
Reference-contexts: However, these criteria have not been fully met by existing debugging tools. 1.1 Problems in Locating Faults Two major steps involved in the debugging process are locating and then correcting faults. Myers [Mye79] pointed out that the fault-locating aspect represents 95% of the debugging effort. Several studies <ref> [GD74, Gou75, Ves85, Mye79, MM83, ST83] </ref>, including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process. <p> The necessity of detailed understanding of programs prevents these techniques from being applied to practical programs. Instead of statically analyzing the entire program, FALOSY (FAult LOcalization SYstem) <ref> [ST83] </ref> emphasizes fault localization by comparing the actual output with the expected 12 output. Automatic fault location is performed by analyzing output discrepancies with the help of prestored fault cause-effect knowledge. Two major resources are maintained in the knowledge base.
Reference: [Sta89] <author> Richard M. Stallman. </author> <title> GDB Manual, third edition, GDB version 3.4. Free Software Foundation, </title> <address> Cambridge, Massachusetts, </address> <month> October </month> <year> 1989. </year> <month> 134 </month>
Reference-contexts: SPYDER is built into the GNU C compiler gcc [Sta90] and the GNU source-level debugger gdb <ref> [Sta89] </ref>. Instead of writing a new compiler and debugger, modifying an existing compiler and debugger is preferred because our goal is to show the feasibility of new approaches in a prototype. GNU tools are chosen because they are available for delivery and support full ANSI C.
Reference: [Sta90] <author> Richard M. Stallman. </author> <title> Using and Porting GNU CC, version 1.37. Free Software Foundation, </title> <address> Cambridge, Massachusetts, </address> <month> January </month> <year> 1990. </year>
Reference-contexts: The purpose of fault localization is achieved by employing these heuristics to obtain different reduced search domains. 85 6.1.3 Implementation Features The development environment of SPYDER is on a Sun SPARCstation 1 running SunOS-4.1.1. SPYDER is built into the GNU C compiler gcc <ref> [Sta90] </ref> and the GNU source-level debugger gdb [Sta89]. Instead of writing a new compiler and debugger, modifying an existing compiler and debugger is preferred because our goal is to show the feasibility of new approaches in a prototype.
Reference: [Sto67] <author> T. G. Stockham. </author> <title> Reports on the working conference on on-line debugging. </title> <journal> Communications of the ACM, </journal> <volume> 10(9) </volume> <pages> 590-592, </pages> <month> September </month> <year> 1967. </year>
Reference-contexts: The most popular debugging techniques employed by commonly used debugging tools (e.g., DBX), setting break-points by users and tracing, were introduced around the early 1960s. <ref> [Sto67] </ref> From the history of the development of fault localization, we find that techniques in some prototype systems work only for programs with restricted structure and solve only limited problems. An efficient debugging paradigm that deals with a broader scope of faults is needed. 18 3.
Reference: [SW65] <author> R. Saunders and R. Wagner. </author> <title> On-line debugging systems. </title> <booktitle> In Proceedings of IFIP Congress, </booktitle> <pages> pages 545-546, </pages> <year> 1965. </year>
Reference-contexts: One debugging technique setting break-points by users has been the main facility of many debugging tools for both low-level and high-level languages since the early 1960s (e.g., DDT <ref> [SW65] </ref> and FLIT [SD60] for assembly languages, and DBX [Dun86] for C). In order to avoid dealing with machine codes as well as scattering print statements in a program, interactive symbolic debugging tools were developed.
Reference: [Tra79] <author> M. Tratner. </author> <title> A fundamental approach to debugging. </title> <journal> Software-Practice and Experience, </journal> <volume> 9(2) </volume> <pages> 97-99, </pages> <month> February </month> <year> 1979. </year>
Reference: [TRC93] <author> Margaret C. Thompson, Debra J. Richardson, and Lori A. Clarke. </author> <title> Information flow transfer in the RELAY model. </title> <booktitle> In Proceedings of the International Symposium on Software Testing and Analysis (ISSTA'93), </booktitle> <pages> pages 182-192, </pages> <address> Cambridge, Massachusetts, </address> <month> June 28-30 </month> <year> 1993. </year>
Reference-contexts: Analysis of necessity helps us examine the cause of local effects. Then the sufficiency feature demonstrates how the local effect affects the program results. Information flow transfer among statements as mentioned in <ref> [TRC93] </ref> provides a similar approach to analyze the propagation of local effects. At each step, we explore the reasons causing program failures and try to discover relationships between the three characteristics and possible faults. As mentioned in Chapter 3.2, the debugging process tries to collect valuable information for locating faults.
Reference: [Ver78] <author> Joost S. M. Verhofstad. </author> <title> Recovery techniques for database systems. </title> <journal> ACM Computing Surveys, </journal> <volume> 10(2) </volume> <pages> 167-195, </pages> <month> June </month> <year> 1978. </year>
Reference-contexts: These drawbacks increase the difficulty of debugging. Another debugging technique keeps track of execution history for backtracking. The concept of execution backtracking has been implemented in database systems (e.g., rollback recovery for system failure <ref> [Ver78, HR83] </ref>) and in fault-tolerant software systems (e.g., the recovery-block technique [Ran75]). In the above implementations, system states to be rolled back for later analysis must be set at the beginning.
Reference: [Ves85] <author> Iris Vessey. </author> <title> Expertise in debugging computer programs: A process analysis. </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> 23(5) </volume> <pages> 459-494, </pages> <month> November </month> <year> 1985. </year>
Reference-contexts: However, these criteria have not been fully met by existing debugging tools. 1.1 Problems in Locating Faults Two major steps involved in the debugging process are locating and then correcting faults. Myers [Mye79] pointed out that the fault-locating aspect represents 95% of the debugging effort. Several studies <ref> [GD74, Gou75, Ves85, Mye79, MM83, ST83] </ref>, including behavioral research, suggest that locating faults is the most difficult and important task in the debugging process.
Reference: [Vir91] <author> Chonchanok Viravan. </author> <title> Fault investigation and trial. </title> <type> Technical Report SERC-TR-104-P, </type> <institution> Software Engineering Research Center, Purdue University, West Lafayette, Indiana, </institution> <month> September </month> <year> 1991. </year>
Reference-contexts: After a reduced search domain for faults is presented by our proposed heuristics, further analysis is needed to identify whether faulty statements are in the highlighted suspicious region. Ongoing research will provide automated decision support to do verification. <ref> [Vir91] </ref> 45 4.3 Summary We have presented a set of heuristics based on dynamic slices with respect to relevant test cases that are obtained from a thorough test. Analysis of relationships between the proposed heuristics was also examined, and a family tree was obtained as a result.
Reference: [Wei71] <author> G. Weinberg. </author> <title> Psychology of Computer Programming. </title> <publisher> Van Nostrand Reinhold Company, </publisher> <address> New York, </address> <year> 1971. </year>
Reference-contexts: Myers [Mye78] found that programmers focused their attention on normal processing at the expense of considering special processing situations and invalid inputs. Weinberg <ref> [Wei71] </ref> found that programmers have difficulty finding errors because their conjectures become prematurely fixed, blinding them to other possibilities. Knowing what types of errors are likely to occur and where they are likely to occur in the program can avoid these problems and greatly simplify the debugging process.
Reference: [Wei82] <author> Mark Weiser. </author> <title> Programmers use slices when debugging. </title> <journal> Communications of the ACM, </journal> <volume> 25(7) </volume> <pages> 446-452, </pages> <month> July </month> <year> 1982. </year>
Reference-contexts: Then, the corresponding actions of the rules are invoked. Because compilation errors can easily be fixed by experienced programmers using the error messages provided by the compiler, this system is mainly used for tutoring purposes. 2.4 Program Slicing Approach Program slicing was proposed by Weiser <ref> [Wei82, Wei84] </ref> as another approach for debugging. Weiser's program slicing (also called static slicing) decomposes a program by statically analyzing data-flow and control-flow of the program. <p> From now on, we use DPS to represent the approach of Dynamic Program Slicing and refer to it as exact dynamic program slicing. Also, the static program slice proposed by Weiser <ref> [Wei82, Wei84] </ref> is represented as SPS, which is associated with a variable-location pair (v, l). During the process of debugging, all statements making contribution to the erroneous variables that contain unexpected values are candidates for investigation.
Reference: [Wei84] <author> Mark Weiser. </author> <title> Program slicing. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-10(4):352-357, </volume> <month> July </month> <year> 1984. </year>
Reference-contexts: Then, the corresponding actions of the rules are invoked. Because compilation errors can easily be fixed by experienced programmers using the error messages provided by the compiler, this system is mainly used for tutoring purposes. 2.4 Program Slicing Approach Program slicing was proposed by Weiser <ref> [Wei82, Wei84] </ref> as another approach for debugging. Weiser's program slicing (also called static slicing) decomposes a program by statically analyzing data-flow and control-flow of the program. <p> From now on, we use DPS to represent the approach of Dynamic Program Slicing and refer to it as exact dynamic program slicing. Also, the static program slice proposed by Weiser <ref> [Wei82, Wei84] </ref> is represented as SPS, which is associated with a variable-location pair (v, l). During the process of debugging, all statements making contribution to the erroneous variables that contain unexpected values are candidates for investigation.
Reference: [WJ91] <author> Elaine J. Weyunker and Bingchiang Jeng. </author> <title> Analyzing partition testing strategies. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-17(7):703-711, </volume> <month> July </month> <year> 1991. </year> <booktitle> (An early version presented at Proceedings of the ACM SIGSOFT '89 Third Symposium on Software Testing, Analysis, and Verification (TAV3), </booktitle> <pages> pages 38-47, </pages> <address> Key West, Florida, </address> <month> December </month> <year> 1989). </year>
Reference-contexts: A set of error-revealing test cases is an indispensable resource for debugging. On the other hand, not every non-error-revealing test case is useful. Partition analysis on the input domain helps us identify the subdomains associated with program failures. <ref> [WO80, RC85, HT90, WJ91] </ref> After a thorough test, users can partition the input domain of P based on the specification of P and the results from testing.
Reference: [WL86] <author> Mark Weiser and Jim Lyle. </author> <title> Experiments on slicing-based debugging aids. </title> <editor> In Elliot Soloway and Sitharama Iyengar, editors, </editor> <booktitle> Empirical Studies of Programmers, </booktitle> <pages> pages 187-197. </pages> <publisher> Ablex Publishing Corp., </publisher> <address> Norwood, New Jersey, </address> <year> 1986. </year> <title> (Presented at the First Workshop on Empirical Studies of Programmers, </title> <address> Washington DC, June 5-6 1986.). </address> <month> 135 </month>
Reference: [WO80] <author> E. J. Weyuker and T. J. </author> <title> Ostrand. Theories of program testing and the application of revealing subdomains. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-6(3):236-246, </volume> <month> May </month> <year> 1980. </year> <note> APPENDICES 136 </note>
Reference-contexts: A set of error-revealing test cases is an indispensable resource for debugging. On the other hand, not every non-error-revealing test case is useful. Partition analysis on the input domain helps us identify the subdomains associated with program failures. <ref> [WO80, RC85, HT90, WJ91] </ref> After a thorough test, users can partition the input domain of P based on the specification of P and the results from testing. <p> We thus define the following features of testing criteria from the standpoint of debugging. Definition 3.7 If the execution of every test case that satisfies a selected testing criterion always causes program failure, then the testing criterion is called an error-revealing criterion. <ref> [WO80] </ref> 2 29 In other words, it is guaranteed that any test case satisfying an error-revealing testing criterion causes program failure. Only error-revealing test cases can satisfy this criterion. This is the strongest condition for finding criteria revealing faults.
References-found: 120

