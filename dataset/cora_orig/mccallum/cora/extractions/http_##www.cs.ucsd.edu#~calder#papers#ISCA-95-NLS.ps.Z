URL: http://www.cs.ucsd.edu/~calder/papers/ISCA-95-NLS.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~calder/papers.html
Root-URL: http://www.cs.ucsd.edu
Email: fcalder,grunwaldg@cs.colorado.edu  
Phone: 430,  
Title: Next Cache Line and Set Prediction  
Author: Brad Calder and Dirk Grunwald 
Keyword: Instruction fetch prediction, Branch prediction, Branch target buffers  
Address: Campus Box  Boulder, CO 80309-0430 USA  
Affiliation: Department of Computer Science,  University of Colorado,  
Abstract: Accurate instruction fetch and branch prediction is increasingly important on today's wide-issue architectures. Fetch prediction is the process of determining the next instruction to request from the memory subsystem. Branch prediction is the process of predicting the likely out-come of branch instructions. Several researchers have proposed very effective fetch and branch prediction mechanisms including branch target buffers (BTB) that store the target addresses of taken branches. An alternative approach fetches the instruction following a branch by using an index into the cache instead of a branch target address. We call such an index a next cache line and set (NLS) predictor. A NLS predictor is a pointer into the instruction cache, indicating the target instruction of a branch. In this paper we examine the use of NLS predictors for efficient and accurate fetch and branch prediction. Previous studies associated each NLS predictor with a cache line and provided only one-bit conditional branch predictors. Our study examines the use of NLS predictors with highly accurate two-level correlated conditional branch architectures. We examine the performance of de-coupling the NLS predictors from the cache line and storing them in a separate tag-less memory buffer. Our results show that the decoupled architecture performs better than associating the NLS predictors with the cache line, that the NLS architecture benefits from reduced cache miss rates, and it is particularly effective for programs containing many branches. We also provide an in-depth comparison between the NLS and BTB architectures, showing that the NLS architecture is a competitive alternative to the BTB design. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brian Bray and M.J. Flynn. </author> <title> Strategies for branch target buffers. </title> <booktitle> In 24th Annual International Symposium and Workshop on Microprogramming, </booktitle> <pages> pages 42-49. </pages> <publisher> ACM, </publisher> <year> 1991. </year>
Reference-contexts: Branch target buffers (BTB) have been used as a mechanism for branch and instruction fetch prediction, effectively predicting the behavior of a branch <ref> [1, 7, 10, 13, 15, 21] </ref>. The Intel Pentium is an example of a modern architecture using BTBs it has a 256-entry BTB organized as a four-way associative cache. Only branches that are `taken' are entered into the BTB. <p> The primary difference, besides eliminating the tag, is that the BTB encodes the full address, while the NLS encodes only the instruction cache line and set, allowing for larger NLS-tables. Bray and Flynn <ref> [1] </ref> described a design similar to the NLS-cache that associated branch target addresses with each cache line. As in our study, they found approximately one entry per four instructions provided the most cost effective design.
Reference: [2] <author> Brad Calder and Dirk Grunwald. </author> <title> Fast & accurate instruction fetch and branch prediction. </title> <booktitle> In 21st Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 2-11. </pages> <publisher> ACM, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: An alternative BTB architecture is the decoupled design, where the branch prediction information is not associated with the BTB and is used for all conditional branches, including those not recorded in the BTB. In an earlier study <ref> [2] </ref>, we found that decoupled designs performed better than coupled designs. This allows conditional branches that do not hit in the BTB to use dynamic prediction. The PowerPC 604 is an example of an architecture using a decoupled design [16]. <p> In this model, we store only taken branches in the BTB, since previous studies have shown this to be more effective <ref> [2, 13] </ref>. If a branch is not taken while it is in the BTB, we leave the branch (target address) in the BTB until it is removed due to the LRU replacement policy, since we might need the taken target address again in the near future. <p> If the instruction set encoding does not contain such a distinguishing bit in the instruction, that information can be stored in the instruction cache or an instruction type prediction table, as described in <ref> [2] </ref>. Encoding this information in the instruction improves the fetch accuracy for the NLS architecture, since non-branch instructions fetch the fall-through address while branch instructions use NLS predictors.
Reference: [3] <author> Peter Yan-Tek Hsu. </author> <title> Designing the TFP microprocessor. </title> <journal> IEEE Micro, </journal> <volume> 14(2) </volume> <pages> 23-33, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: By comparison, we only update the NLS predictor when taken branches are encountered to obtain improved branch prediction accuracy when using a decoupled PHT. Variations on the NLS-cache design can be found in recent microprocessor architectures. The TFP microprocessor (MIPS R8000) <ref> [3] </ref> has a 1024 entry NLS-cache architecture similar to the design proposed by Johnson. It has one NLS predictor for every four instructions, and a one-bit branch predictor coupled with each NLS predictor. <p> This should be considered when comparing the performance of the direct mapped BTB and NLS architecture to the associative BTB architectures since the cycle limitation of the instruction fetch may effect the entire machine. In <ref> [3] </ref>, the designers of the TFP (MIPS R8000) microprocessor stated: We evaluated several well-known branch prediction algorithms for layout size, speed, and prediction accuracy.
Reference: [4] <author> Wen-mei W. Hwu and Pohua P. Chang. </author> <title> Achieving high instruction cache performance with an optimizing compiler. </title> <booktitle> In 16th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 242-251. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: The BTB architecture will not benefit from the lower cache miss rate, and the there is no change in the BEP for varying cache configurations. Whole-program restructuring <ref> [8, 4, 14] </ref> is one technique that can be used to reduce the instruction cache miss rate at no additional architectural cost.
Reference: [5] <author> Mike Johnson. </author> <title> Superscalar Microprocessor Design. Innovative Technology. </title> <publisher> Prentice-Hall. Inc., </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1991. </year>
Reference-contexts: In this paper we examine an alternative to the BTB called next cache line and set (NLS) prediction. A NLS predictor is a pointer into the instruction cache indicating the target instruction of a taken branch. Johnson <ref> [5] </ref> proposed a similar design using cache indices to predict the next instruction fetch. We propose an alternate organization that improves fetch prediction accuracy. In this paper we examine two varieties of the NLS architecture. <p> Bray and Flynn [1] described a design similar to the NLS-cache that associated branch target addresses with each cache line. As in our study, they found approximately one entry per four instructions provided the most cost effective design. Johnson <ref> [5] </ref>, suggested the idea of using cache successor indices as in the NLS-cache architecture for instruction fetch and branch prediction. His architecture associated the cache indices with each cache line as the NLS-cache architecture does. <p> In contrast, an increase in cache size has no effect on the size of the BTB. 8 Conclusions In this paper we have presented two alternative NLS architectures, the NLS-cache and NLS-table. Our results show that decoupling the NLS predictors from the instruction cache (NLS-table) performs better than Johnson's <ref> [5] </ref> approach of associating the NLS predictors with the cache line (NLS-cache). We found the NLS-cache is not a scalable design, because the number of NLS predictors increases linearly with the cache size.
Reference: [6] <author> David R. Kaeli and Philip G. Emma. </author> <title> Branch history table prediction of moving target branches due to subroutine returns. </title> <booktitle> In 18th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 34-42. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: In Figure 1 the next instruction fetch address is concurrently offered to: the instruction cache, the BTB, and the PHT. The address is also used to compute the fall-through instruction's address. A 32-entry return address stack <ref> [6] </ref> predicts return instructions, and conditional branches are predicted using the pattern history table organization described by McFarling [9]. <p> When simulating the NLS-table architecture, we simulated NLS-table sizes with 512, 1024 and 2048 NLS predictors. For the BTB architecture, we simulated 128-entry and 256-entry BTB organizations with direct mapped, 2-way and 4-way associativity with LRU replacement. Both the BTB and NLS architectures used a 32-entry return stack <ref> [6] </ref> to predict procedure returns and a two-level correlated 4096-entry pattern history table for conditional branches. The accuracy of the pattern history table is the same for both the BTB and NLS architectures.
Reference: [7] <author> Johnny K. F. Lee and Alan Jay Smith. </author> <title> Branch prediction strategies and branch target buffer design. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 6-22, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: Branch target buffers (BTB) have been used as a mechanism for branch and instruction fetch prediction, effectively predicting the behavior of a branch <ref> [1, 7, 10, 13, 15, 21] </ref>. The Intel Pentium is an example of a modern architecture using BTBs it has a 256-entry BTB organized as a four-way associative cache. Only branches that are `taken' are entered into the BTB. <p> If a branch address appears in the BTB and the branch is predicted as taken, the stored address is used to fetch future instructions, otherwise the fall-through address is used. For each BTB entry, the Pentium uses a two-bit saturating counter to predict the direction of a conditional branch <ref> [7] </ref>. In this BTB architecture, the branch prediction information (the two-bit counter), is associated or coupled with the BTB entry. Thus, the dynamic prediction can only be used for branches in the BTB, and branches that miss in the BTB must use less accurate static prediction.
Reference: [8] <author> Scott McFarling. </author> <title> Program optimization for instruction caches. </title> <booktitle> In Proceedingsof the 3rd Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 183-191. </pages> <publisher> ACM, </publisher> <year> 1988. </year>
Reference-contexts: The BTB architecture will not benefit from the lower cache miss rate, and the there is no change in the BEP for varying cache configurations. Whole-program restructuring <ref> [8, 4, 14] </ref> is one technique that can be used to reduce the instruction cache miss rate at no additional architectural cost.
Reference: [9] <author> Scott McFarling. </author> <title> Combining branch predictors. </title> <address> TN 36, DEC-WRL, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: The shift register is used as an index into the PHT, much as the program counter is used for a direct-mapped PHT. This provides contextual information and correlation about particular patterns of branches. Recently, McFarling <ref> [9] </ref> showed that combining branch history with the branch's address was more effective. His method used the exclusive-or of the global history register and the branch address as the index into the PHT. <p> The NLS and BTB architectures we study in this paper use a decoupled design with a separate PHT to predict the direction of conditional branches. For both of the architectures, we use McFarling's form of the two-level PHT <ref> [9] </ref>. In the next two sections we first describe the BTB architecture and then our alternative NLS architecture. 3 A BTB-based Instruction Fetch Architecture PHT branch prediction and instruction fetch architecture we simulated. <p> The address is also used to compute the fall-through instruction's address. A 32-entry return address stack [6] predicts return instructions, and conditional branches are predicted using the pattern history table organization described by McFarling <ref> [9] </ref>. This is the degenerate prediction architecture using two-level correlated branch prediction for conditional branches and a return stack for return instructions. scheme of Pan et al [12], where we XOR the global history register with the program counter and use this to index into a 4096 entry (1KByte) PHT.
Reference: [10] <author> Scott McFarling and John Hennessy. </author> <title> Reducing the cost of branches. </title> <booktitle> In 13th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 396-403. </pages> <publisher> ACM, </publisher> <year> 1986. </year>
Reference-contexts: Branch target buffers (BTB) have been used as a mechanism for branch and instruction fetch prediction, effectively predicting the behavior of a branch <ref> [1, 7, 10, 13, 15, 21] </ref>. The Intel Pentium is an example of a modern architecture using BTBs it has a 256-entry BTB organized as a four-way associative cache. Only branches that are `taken' are entered into the BTB.
Reference: [11] <author> Johannes M. Mulder, Nhon T. Quach, and Michael J. Flynn. </author> <title> An area model for on-chip memories and its application. </title> <journal> IEEE Journal of Solid-State Circuits, </journal> <volume> 26(2) </volume> <pages> 98-105, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: In order to evaluate the area implementation costs of the NLS and BTB architectures, we used the register bit equivalent (RBE) model for on-chip memories proposed by Mulder et al <ref> [11] </ref>, where one RBE equals the area of a bit storage cell. BTB architectures using Mulder et al's on-chip memory area model.
Reference: [12] <author> S.-T. Pan, K. So, and J. T. Rahmeh. </author> <title> Improving the accuracy of dynamic branch prediction using branch correlation. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 76-84, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: The PowerPC 604 has a 64-entry fully associative BTB that holds the target address of the most recently taken branches, and uses a separate 512 entry pattern history table (PHT) to predict the direction for conditional branches. There are several different PHT variations. Pan et al. <ref> [12] </ref> and Yeh and Patt [20, 22] investigated branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of a branch. The simplest example is the degenerate method of Pan et al.[12]. <p> This is the degenerate prediction architecture using two-level correlated branch prediction for conditional branches and a return stack for return instructions. scheme of Pan et al <ref> [12] </ref>, where we XOR the global history register with the program counter and use this to index into a 4096 entry (1KByte) PHT. In this model, we store only taken branches in the BTB, since previous studies have shown this to be more effective [2, 13].
Reference: [13] <author> Chris Perleberg and Alan Jay Smith. </author> <title> Branch target buffer design and optimization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(4) </volume> <pages> 396-412, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Branch target buffers (BTB) have been used as a mechanism for branch and instruction fetch prediction, effectively predicting the behavior of a branch <ref> [1, 7, 10, 13, 15, 21] </ref>. The Intel Pentium is an example of a modern architecture using BTBs it has a 256-entry BTB organized as a four-way associative cache. Only branches that are `taken' are entered into the BTB. <p> In this model, we store only taken branches in the BTB, since previous studies have shown this to be more effective <ref> [2, 13] </ref>. If a branch is not taken while it is in the BTB, we leave the branch (target address) in the BTB until it is removed due to the LRU replacement policy, since we might need the taken target address again in the near future.
Reference: [14] <author> Karl Pettis and Robert C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> In Proceedings of the ACM SIGPLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 16-27. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: The BTB architecture will not benefit from the lower cache miss rate, and the there is no change in the BEP for varying cache configurations. Whole-program restructuring <ref> [8, 4, 14] </ref> is one technique that can be used to reduce the instruction cache miss rate at no additional architectural cost.
Reference: [15] <author> J. E. Smith. </author> <title> A study of branch prediction strategies. </title> <booktitle> In 8th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 135-148. </pages> <publisher> ACM, </publisher> <year> 1981. </year>
Reference-contexts: Branch target buffers (BTB) have been used as a mechanism for branch and instruction fetch prediction, effectively predicting the behavior of a branch <ref> [1, 7, 10, 13, 15, 21] </ref>. The Intel Pentium is an example of a modern architecture using BTBs it has a 256-entry BTB organized as a four-way associative cache. Only branches that are `taken' are entered into the BTB.
Reference: [16] <author> S. Peter Song, Marvin Denman, and Joe Chang. </author> <title> The PowerPC 604 RISC microprocessor. </title> <journal> IEEE Micro, </journal> <volume> 14(5) </volume> <pages> 8-17, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: In an earlier study [2], we found that decoupled designs performed better than coupled designs. This allows conditional branches that do not hit in the BTB to use dynamic prediction. The PowerPC 604 is an example of an architecture using a decoupled design <ref> [16] </ref>. The PowerPC 604 has a 64-entry fully associative BTB that holds the target address of the most recently taken branches, and uses a separate 512 entry pattern history table (PHT) to predict the direction for conditional branches. There are several different PHT variations.
Reference: [17] <author> Amitabh Srivastava and Alan Eustace. </author> <title> ATOM: A system for building customized program analysis tools. </title> <booktitle> In 1994 Programming Language Design and Implementation, </booktitle> <pages> pages 196-205. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: We picked three of the programs (gcc, cfront and groff) because they have high instruction cache miss rates, execute a lot of branches, and the branches are hard to predict. We used ATOM <ref> [17] </ref> to instrument the programs. Due to the structure of ATOM, we did not need to record traces and could trace very long-running programs. The programs were compiled on a DEC 3000-400 using either the DEC FORTRAN, C, or C++ compiler. All programs were compiled with standard optimization (-O).
Reference: [18] <author> Simon C. Steely and David J. Sager. </author> <title> Next line prediction apparatus for a pipelined computer system. </title> <type> US. Patent #5,283,873, </type> <month> Feb. </month> <year> 1994. </year>
Reference-contexts: Instead of using one-bit prediction as in the TFP, the UltraSPARC uses a 2-bit dynamic conditional branch predictor for every two instructions in the instruction cache. The NLS-table design uses an independent table of next line and set predictors. This basic design was recently patented by Steely and Sager <ref> [18] </ref>. However, they have not published any performance comparisons, and the patented design only addresses direct mapped caches, while our design addresses both direct mapped and associative caches. Furthermore, the patented architecture uses a single "computed goto" register to store the destination of indirect jumps. <p> By comparison, we use the NLS predictor to provide the predicted cache index for all branch destinations other than fall-through branches and return instructions. Although we developed our NLS architecture independently, there are several similarities as well as other differences; see <ref> [18] </ref> for more details. 6.3 Performance of the BTB Architecture programs simulated in this paper. The 1024 entry NLS-table has better performance than the similar costing 128 entry BTB, even when the BTB has a high degree of associativity.
Reference: [19] <author> Steven J. E. Wilton and Norman P. Jouppi. </author> <title> An enhanced access and cycle time model for on-chip caches. </title> <type> WRL Report 93/5, </type> <institution> DEC Western Research Lab, </institution> <year> 1993. </year>
Reference-contexts: Figure 6 shows the estimated access time, in nanoseconds, for a 128 entry BTB and 256 entry BTB with direct mapped, two, and four way associativity. These estimates were derived using the CACTI timing model of Wilton and Jouppi <ref> [19] </ref>. 6 architecture for direct mapped and 4-way associativity instruction caches of size 8K, 16K and 32K, and for a 128 entry and 256 entry BTB. more important than the absolute values for a particular processor technology.
Reference: [20] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> Alternative implementations of two-level adaptive branch predictions. </title> <booktitle> In 19th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 124-134, </pages> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: There are several different PHT variations. Pan et al. [12] and Yeh and Patt <ref> [20, 22] </ref> investigated branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of a branch. The simplest example is the degenerate method of Pan et al.[12].
Reference: [21] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comprehensive instruction fetch mechanism for a processor supporting speculative execution. </title> <booktitle> In 25th Annual International Symposium on Microarchi-tecture, </booktitle> <pages> pages 129-139, </pages> <address> Portland, Or, </address> <month> December </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: Branch target buffers (BTB) have been used as a mechanism for branch and instruction fetch prediction, effectively predicting the behavior of a branch <ref> [1, 7, 10, 13, 15, 21] </ref>. The Intel Pentium is an example of a modern architecture using BTBs it has a 256-entry BTB organized as a four-way associative cache. Only branches that are `taken' are entered into the BTB. <p> We also record the percentage of misfetched branches (%MfB), and the percentage of mispredicted branches (%MpB). Note that a mispredicted branch is never counted as a misfetched branch and visa versa. It is often difficult to understand how each of these metrics influence processor performance. Yeh & Patt <ref> [21] </ref> defined the branch execution penalty to be: BEP = %MfB fi misfetch penalty + %MpB fi misprediction penalty 100 The BEP reflects the average penalty suffered by a branch due to misfetch and mispredict penalties. With a BEP of 0:5, the average branch incurs a half-cycle execution penalty.
Reference: [22] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comparison of dynamic branch predictors that use two levels of branch history. </title> <booktitle> In 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 257-266, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <journal> ACM. </journal> <volume> 10 </volume>
Reference-contexts: There are several different PHT variations. Pan et al. [12] and Yeh and Patt <ref> [20, 22] </ref> investigated branch-correlation or two-level branch prediction mechanisms. Although there are a number of variants, these mechanisms generally combine the history of several recent branches to predict the outcome of a branch. The simplest example is the degenerate method of Pan et al.[12].
References-found: 22

