URL: http://www.cs.umn.edu/Users/dept/users/kumar/mlevel_hgraph.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Email: shekharg@cs.umn.edu  
Title: Multilevel Hypergraph Partitioning: Applications in VLSI Domain  
Author: George Karypis, Rajat Aggarwal, Vipin Kumar, and Shashi Shekhar fkarypis, rajat, kumar, 
Note: Last updated on April 25, 1997 at 6:01pm  
Address: Minneapolis, MN 55455  
Affiliation: University of Minnesota, Department of Computer Science,  
Abstract: A short version of this paper appears in the 34th Design Automation Conference Abstract In this paper, we present a new hypergraph partitioning algorithm that is based on the multilevel paradigm. In the multilevel paradigm, a sequence of successively coarser hypergraphs is constructed. A bisection of the smallest hyper-graph is computed and it is used to obtain a bisection of the original hypergraph by successively projecting and refining the bisection to the next level finer hypergraph. We have developed new hypergraph coarsening strategies within the multilevel framework. We evaluate the performance both in terms of the size of the hyperedge cut on the bisection as well as run time on a number of VLSI circuits. Our experiments show that our multilevel hypergraph partitioning algorithm produces high quality partitioning in relatively small amount of time. The quality of the partitionings produced by our scheme are on the average 6% to 23% better than those produced by other state-of-the-art schemes. Furthermore, our partitioning algorithm is significantly faster, often requiring 4 to 10 times less time than that required by the other schemes. Our multilevel hypergraph partitioning algorithm scales very well for large hypergraphs. Hypergraphs with over 100,000 vertices can be bisected in a few minutes on today's workstations. Also, on the large hypergraphs, our scheme outperforms other schemes (in hyperedge cut) quite consistently with larger margins (9% to 30%). 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Alpert, L. Hagen, and A. Kahng. </author> <title> A hybrid multilevel/genetic approach for circuit partitioning. </title> <type> Technical report, </type> <institution> Computer Science Department, UCLA, </institution> <address> Los Angeles, CA, </address> <year> 1996. </year>
Reference-contexts: G 4 is the coarsest graph. the hypergraph is first converted into a graph (by replacing each hyperedge by a set of regular edges), then METIS [18] can be used to compute a partitioning of this graph. This technique was investigated by Alpert and Khang <ref> [1] </ref>. They converted hypergraphs to graphs by simply replacing each hyperedge by a clique, and then dropped many edges from each clique randomly. They used METIS to compute a partitioning of each such random graph and selected the best of these partitionings. <p> Furthermore, the hyperedge to clique conversion destroys the natural sparsity of the hypergraph, significantly increasing the run-time of the partitioning algorithm. Alpert and Khang <ref> [1] </ref> solved this problem by dropping many edges of the 4 partitioning with weight of hyperedges cut down =1, and (d) an example partitioning with weight of hyperedges cut down= 4/3 clique randomly. But this makes the graph representation even less accurate. <p> Our experiments show that our multilevel hypergraph partitioning algorithm produces high quality partitioning in relatively small amount of time. The quality of the partitionings produced by our scheme are on the average 6% to 23% better that those produced by other state-of-the-art schemes <ref> [1, 7, 8, 26, 24] </ref>. The difference 5 in quality over other schemes become even greater for larger hypergraphs. Furthermore, our partitioning algorithm is significantly faster, often requiring 4 to 10 times less time than that required by the other schemes. <p> Comparing the results in Table 2 with those in Table 7, we see that the overall performance of any of these three schemes is, on the average, better than any of the previously known state-of-the-art algorithms <ref> [1, 7, 8, 26] </ref> for hyper-graph partitioning. This demonstrates the power and robustness of the multilevel paradigm for hypergraph partitioning. However, looking at the individual problems, we see that performance of the three schemes differs significantly on some of the problems. <p> Table 7 shows the size of the hyperedge cut produced by our algorithms (hMETIS) and those reported by various previously developed hypergraph bisection algorithms. In particular, Table 7 contains results for the following algorithms: PROP [7], CDIP-LA3 f and CLIP-PROP f [8], PARABOLI [26], GFM [23], GMetis <ref> [1] </ref>, and Optimized KLFM (scheme by Hauck and Borriello [14]). Note that for certain circuits, there are missing results for some of the algorithms. This is because no results were reported for these circuits. <p> Note that hypergraph based multilevel scheme as presented in this paper significantly outperforms the graph based multilevel scheme GMetis <ref> [1] </ref> that used METIS [18] to compute bisections of graph approximations of hypergraph. The reasons for this performance difference are as follows.
Reference: [2] <author> Charles J. Alpert and Andrew B. Kahng. </author> <title> Recent directions in netlist partitioning. Integration, </title> <journal> the VLSI Journal, </journal> <volume> 19(1-2):1-81, </volume> <year> 1995. </year>
Reference-contexts: 1 Introduction Hypergraph partitioning is an important problem and has extensive application to many areas, including VLSI design <ref> [2] </ref>, efficient storage of large databases on disks [30], and data mining [25]. The problem is to partition the vertices of a hypergraph in k roughly equal parts, such that the number of hyperedges connecting vertices in different parts is minimized. <p> However, because of the importance of the problem in many application areas, many heuristic algorithms have been developed. The survey by Alpert and Khang <ref> [2] </ref> provides a detailed description and comparison of various such schemes.
Reference: [3] <institution> ACM/SIGDA benchmark suite. </institution> <note> Available on the WWW at http://vlsicad.cs.ucla.edu/cheese/benchmarks.html. </note>
Reference-contexts: The difference 5 in quality over other schemes become even greater for larger hypergraphs. Furthermore, our partitioning algorithm is significantly faster, often requiring 4 to 10 times less time than that required by the other schemes. For many circuits in the well known ACM/SIGDA benchmark set <ref> [3] </ref>, our scheme is able to find better partitionings than those reported in the literature for any other hypergraph partitioning algorithm. 1.3 Scope and Outline The multilevel hypergraph bisection scheme, described in this paper, can be used for k-way hypergraph partitioning. <p> obtained by HER refinement can be substantially improved by a round of FM refinement. 3 Experimental Results We experimentally evaluated the quality of the bisections produced by our multilevel hypergraph partitioning algorithm on a large number of hypergraphs that are part of the widely used ACM/SIGDA circuit partitioning benchmark suite <ref> [3] </ref>. The characteristics of these hypergraphs are shown in Table 1. We performed all our experiments on an SGI Challenge that has MIPS R10000 processors running at 200Mhz, and all reported run-times are in seconds. All the reported partitioning results were obtained by forcing a 45-55 balance condition.
Reference: [4] <author> C. Berge. </author> <title> Graphs and Hypergraphs. </title> <publisher> American Elsevier, </publisher> <address> New york, </address> <year> 1976. </year>
Reference-contexts: Formally, a hypergraph H D .V ; E h / is defined as a set of vertices V and a set of hyperedges E h , where each hyperedge is a subset of the vertex set V <ref> [4] </ref>. During the course of VLSI circuit design and synthesis, it is quite important to be able to divide the system specification into clusters so that the inter-cluster connections are minimized.
Reference: [5] <author> T. Bui and C. Jones. </author> <title> A heuristic for reducing fill in sparse matrix factorization. </title> <booktitle> In 6th SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <pages> pages 445-452, </pages> <year> 1993. </year>
Reference-contexts: But the overall performance of such a scheme depends upon the quality of the coarsening method. In many schemes, the projected partition is further improved using the FM refinement scheme [32]. Recently a new class of multilevel partitioning techniques was developed <ref> [5, 15, 14, 6] </ref>, in which a sequence of successively smaller (coarser) graphs is constructed. A bisection of the smallest graph is computed. <p> Second, the refined partitioning projected to the next level serves as an excellent initial partitioning for the KL or FM refinement algorithms. This paradigm was independently studied by Bui and Jones <ref> [5] </ref> in the context of computing fill reducing matrix reordering, by Hendrickson and Leland [15] in the context of finite element grid partitioning, and by Hauck and Borriello [14](called Optimized KLFM) and by Cong and Smith [6] for hypergraph partitioning.
Reference: [6] <author> J. Cong and M. L. Smith. </author> <title> A parallel bottom-up clustering algorithm with applications to circuit partitioning in vlsi design. </title> <booktitle> In Proc. ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 755-760, </pages> <year> 1993. </year>
Reference-contexts: But the overall performance of such a scheme depends upon the quality of the coarsening method. In many schemes, the projected partition is further improved using the FM refinement scheme [32]. Recently a new class of multilevel partitioning techniques was developed <ref> [5, 15, 14, 6] </ref>, in which a sequence of successively smaller (coarser) graphs is constructed. A bisection of the smallest graph is computed. <p> This paradigm was independently studied by Bui and Jones [5] in the context of computing fill reducing matrix reordering, by Hendrickson and Leland [15] in the context of finite element grid partitioning, and by Hauck and Borriello [14](called Optimized KLFM) and by Cong and Smith <ref> [6] </ref> for hypergraph partitioning. Karypis and Kumar extensively studied this paradigm in [18, 17] for partitioning of graphs. They presented new graph coarsening schemes for which even a good bisection of the coarsest graph is a pretty good bisection of the original graph.
Reference: [7] <author> S. Dutt and W. Deng. </author> <title> A probability-based approach to VLSI circuit partitioning. </title> <booktitle> In ACM/IEEE Design Automation Conference, </booktitle> <year> 1996. </year>
Reference-contexts: Third, a hyperedge that has more than one vertices on both sides of the partition line does not influence the computation of the gain of vertices contained in it, making the gain computation quite inexact <ref> [7] </ref>. Hence, these algorithms have been extended in a number of ways [21, 27, 7, 8]. Krishnamurthy [21] tried to introduce intelligence in the tie breaking process from among the many possible moves with the same high gain. <p> Third, a hyperedge that has more than one vertices on both sides of the partition line does not influence the computation of the gain of vertices contained in it, making the gain computation quite inexact [7]. Hence, these algorithms have been extended in a number of ways <ref> [21, 27, 7, 8] </ref>. Krishnamurthy [21] tried to introduce intelligence in the tie breaking process from among the many possible moves with the same high gain. He used a Look Ahead (LA r ) algorithm which looks ahead upto r -level of gains before making moves. <p> Krishnamurthy [21] tried to introduce intelligence in the tie breaking process from among the many possible moves with the same high gain. He used a Look Ahead (LA r ) algorithm which looks ahead upto r -level of gains before making moves. PROP <ref> [7] </ref>, introduced by Dutt and Deng, used a probabilistic gain computation model for deciding the vertices that needs to move across the partition line. <p> Their results show that reasonably good partitionings can be obtained in a reasonable amount of time for a variety of benchmark problems. In particular, the performance of their resulting scheme (called GMetis) is comparable to other state-of-the art schemes such as PARABOLI [26], PROP <ref> [7] </ref>, and the multilevel hypergraph partitioner from Hauck and Borriello [14]. <p> Our experiments show that our multilevel hypergraph partitioning algorithm produces high quality partitioning in relatively small amount of time. The quality of the partitionings produced by our scheme are on the average 6% to 23% better that those produced by other state-of-the-art schemes <ref> [1, 7, 8, 26, 24] </ref>. The difference 5 in quality over other schemes become even greater for larger hypergraphs. Furthermore, our partitioning algorithm is significantly faster, often requiring 4 to 10 times less time than that required by the other schemes. <p> Comparing the results in Table 2 with those in Table 7, we see that the overall performance of any of these three schemes is, on the average, better than any of the previously known state-of-the-art algorithms <ref> [1, 7, 8, 26] </ref> for hyper-graph partitioning. This demonstrates the power and robustness of the multilevel paradigm for hypergraph partitioning. However, looking at the individual problems, we see that performance of the three schemes differs significantly on some of the problems. <p> Table 7 shows the size of the hyperedge cut produced by our algorithms (hMETIS) and those reported by various previously developed hypergraph bisection algorithms. In particular, Table 7 contains results for the following algorithms: PROP <ref> [7] </ref>, CDIP-LA3 f and CLIP-PROP f [8], PARABOLI [26], GFM [23], GMetis [1], and Optimized KLFM (scheme by Hauck and Borriello [14]). Note that for certain circuits, there are missing results for some of the algorithms. This is because no results were reported for these circuits. <p> Results for the multilevel hypergraph partitioning presented in Table 5 use FM or its simplifications for refinement in the uncoarsening phase. New powerful variants of the FM refinement schemes have been developed recently by Dutt et al., <ref> [7, 8] </ref>. It will be instructive to include such a refinement scheme during the uncoarsening phase to see if it makes the multi-level scheme more robust.
Reference: [8] <author> S. Dutt and W. Deng. </author> <title> VLSI circuit partitioning by cluster-removal using iterative improvement techniques. </title> <booktitle> In Proc. Physical Design Workshop, </booktitle> <year> 1996. </year> <month> 22 </month>
Reference-contexts: Third, a hyperedge that has more than one vertices on both sides of the partition line does not influence the computation of the gain of vertices contained in it, making the gain computation quite inexact [7]. Hence, these algorithms have been extended in a number of ways <ref> [21, 27, 7, 8] </ref>. Krishnamurthy [21] tried to introduce intelligence in the tie breaking process from among the many possible moves with the same high gain. He used a Look Ahead (LA r ) algorithm which looks ahead upto r -level of gains before making moves. <p> These schemes tend to enhance the performance of the basic KL/FM refinement algorithms, at the expense of increased run time. Dutt and Deng <ref> [8] </ref> proposed two new methods, namely CLIP and CDIP, for computing gains of hyperedges that contain more than one node on either side of the partition boundary. <p> Our experiments show that our multilevel hypergraph partitioning algorithm produces high quality partitioning in relatively small amount of time. The quality of the partitionings produced by our scheme are on the average 6% to 23% better that those produced by other state-of-the-art schemes <ref> [1, 7, 8, 26, 24] </ref>. The difference 5 in quality over other schemes become even greater for larger hypergraphs. Furthermore, our partitioning algorithm is significantly faster, often requiring 4 to 10 times less time than that required by the other schemes. <p> Comparing the results in Table 2 with those in Table 7, we see that the overall performance of any of these three schemes is, on the average, better than any of the previously known state-of-the-art algorithms <ref> [1, 7, 8, 26] </ref> for hyper-graph partitioning. This demonstrates the power and robustness of the multilevel paradigm for hypergraph partitioning. However, looking at the individual problems, we see that performance of the three schemes differs significantly on some of the problems. <p> Table 7 shows the size of the hyperedge cut produced by our algorithms (hMETIS) and those reported by various previously developed hypergraph bisection algorithms. In particular, Table 7 contains results for the following algorithms: PROP [7], CDIP-LA3 f and CLIP-PROP f <ref> [8] </ref>, PARABOLI [26], GFM [23], GMetis [1], and Optimized KLFM (scheme by Hauck and Borriello [14]). Note that for certain circuits, there are missing results for some of the algorithms. This is because no results were reported for these circuits. <p> Results for the multilevel hypergraph partitioning presented in Table 5 use FM or its simplifications for refinement in the uncoarsening phase. New powerful variants of the FM refinement schemes have been developed recently by Dutt et al., <ref> [7, 8] </ref>. It will be instructive to include such a refinement scheme during the uncoarsening phase to see if it makes the multi-level scheme more robust.
Reference: [9] <author> T. Bui et al. </author> <title> Improving the performance of the kernighan-lin and simulated annealing graph bisection algorithm. </title> <booktitle> In Proc. ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 775-778, </pages> <year> 1989. </year>
Reference-contexts: CDIP in conjunction with LA 3 and CLIP in conjunction with PROP are two schemes that have shown the best results in their experiments. Another class of hypergraph partitioning algorithms <ref> [9, 13, 12, 32] </ref> is of two-phase algorithms. In the first phase, they coarsen the hypergraph to form a small hypergraph and use the FM algorithm to bisect the small hypergraph.
Reference: [10] <author> C. M. Fiduccia and R. M. Mattheyses. </author> <title> A linear time heuristic for improving network partitions. </title> <booktitle> In In Proc. 19th IEEE Design Automation Conference, </booktitle> <pages> pages 175-181, </pages> <year> 1982. </year>
Reference-contexts: These algorithms often use the Schweikert-Kernighan [28] (an extension of Kernighan-Lin (KL) [20] for hypergraphs), or the faster Fiduccia-Mattheyses (FM) <ref> [10] </ref> refinement heuristic to iteratively improve the quality of the partition. In all of these methods (sometimes also called KLFM schemes), a vertex is moved (or a vertex-pair is swapped) if it results in the greatest reduction in the edge-cuts, which is also called the gain for moving the vertex. <p> In addition to that, hypergraph coarsening also helps in successively reducing the size of the hyperedges. That is, after several levels of coarsening, large hyperedges are contracted to hyperedges connecting just a few vertices. This is particularly helpful, since refinement heuristics based on the Kernighan-Lin algorithm <ref> [20, 28, 10] </ref> are very effective in refining small hyperedges but are quite ineffective in refining hyperedges with a large number of vertices belonging to different partitions. <p> Since the next level finer hypergraph has more degrees of freedom, such refinement algorithms tend to improve the quality. We have implemented two different partitioning refinement algorithms. The first is the FM algorithm <ref> [10] </ref> which repeatedly moves vertices between partitions in order to improve the cut. The second algorithm, called HER, moves groups of vertices between partitions so that an entire hyperedge is removed from the cut. These algorithms are further described in the remaining of this section. <p> The second algorithm, called HER, moves groups of vertices between partitions so that an entire hyperedge is removed from the cut. These algorithms are further described in the remaining of this section. Fiduccia-Mattheyses (FM) The partitioning refinement algorithm by Fiduccia and Mattheyses <ref> [10] </ref> is iterative in nature. <p> Now, this becomes the initial partitioning for the next pass of the algorithm. With the use of appropriate data-structures, the complexity of each pass of the FM algorithm is O.jE h j/ <ref> [10] </ref>. For refinement in the context of multilevel schemes, the initial partitioning obtained from the next level coarser graph, is actually a very good partition. For this reason we can make a number of optimizations to the original FM algorithm.
Reference: [11] <author> Michael R. Garey and David S. Johnson. </author> <title> Computers and Instractability: A Guide to the Theory of NP-Completeness. </title> <publisher> W.H Freeman, </publisher> <address> San Francisco, CA, </address> <year> 1979. </year>
Reference-contexts: However, because of the importance of the problem in many application areas, many heuristic algorithms have been developed. The survey by Alpert and Khang [2] provides a detailed description and comparison of various such schemes. In a widely used class of iterative 1 Graph partitioning is an NP-complete problem <ref> [11] </ref>, which is a special case of hypergraph partitioning 2 refinement partitioning algorithms, an initial bisection is computed (often obtained randomly) and then the partition is refined by repeatedly moving vertices between the two parts to reduce the hyperedge-cut.
Reference: [12] <author> Charles J. Alpert Lars W. Hagen and Andrew B. Kahng. </author> <title> A general framework for vertex orderings, with applications to netlist clustering. </title> <note> to appear in IEEE Transactions on VLSI. </note>
Reference-contexts: CDIP in conjunction with LA 3 and CLIP in conjunction with PROP are two schemes that have shown the best results in their experiments. Another class of hypergraph partitioning algorithms <ref> [9, 13, 12, 32] </ref> is of two-phase algorithms. In the first phase, they coarsen the hypergraph to form a small hypergraph and use the FM algorithm to bisect the small hypergraph.
Reference: [13] <author> Lars Hagen and Andrew Kahng. </author> <title> A new approach to effective circuit clustering. </title> <booktitle> In Proceedings of IEEE International Conference on Computer Aided Design, </booktitle> <pages> pages 422-427, </pages> <year> 1992. </year>
Reference-contexts: CDIP in conjunction with LA 3 and CLIP in conjunction with PROP are two schemes that have shown the best results in their experiments. Another class of hypergraph partitioning algorithms <ref> [9, 13, 12, 32] </ref> is of two-phase algorithms. In the first phase, they coarsen the hypergraph to form a small hypergraph and use the FM algorithm to bisect the small hypergraph.
Reference: [14] <author> S. Hauck and G. Borriello. </author> <title> An evaluation of bipartitioning technique. </title> <booktitle> In Proc. Chapel Hill Conference on Advanced Research in VLSI, </booktitle> <year> 1995. </year>
Reference-contexts: But the overall performance of such a scheme depends upon the quality of the coarsening method. In many schemes, the projected partition is further improved using the FM refinement scheme [32]. Recently a new class of multilevel partitioning techniques was developed <ref> [5, 15, 14, 6] </ref>, in which a sequence of successively smaller (coarser) graphs is constructed. A bisection of the smallest graph is computed. <p> In particular, the performance of their resulting scheme (called GMetis) is comparable to other state-of-the art schemes such as PARABOLI [26], PROP [7], and the multilevel hypergraph partitioner from Hauck and Borriello <ref> [14] </ref>. The conversion of a hypergraph into a graph by replacing each hyperedge by a clique does not result in an equivalent representation, since high quality partitionings of the resulting graph do not necessarily lead to high quality partition-ings of the hypergraph. This is illustrated in Figure 3. <p> But this makes the graph representation even less accurate. A better approach is to develop coarsening and refinement schemes that operates directly on the hypergraph. Note that the multilevel scheme by Hauck and Borriello <ref> [14] </ref> operates directly on hypergraphs, and thus is able to perform accurate refinement during the uncoarsen-ing phase. However, all coarsening scheme studied in [14] are edge-oriented, i.e., they only merge pairs of nodes to construct coarser graphs. <p> A better approach is to develop coarsening and refinement schemes that operates directly on the hypergraph. Note that the multilevel scheme by Hauck and Borriello <ref> [14] </ref> operates directly on hypergraphs, and thus is able to perform accurate refinement during the uncoarsen-ing phase. However, all coarsening scheme studied in [14] are edge-oriented, i.e., they only merge pairs of nodes to construct coarser graphs. <p> In particular, Table 7 contains results for the following algorithms: PROP [7], CDIP-LA3 f and CLIP-PROP f [8], PARABOLI [26], GFM [23], GMetis [1], and Optimized KLFM (scheme by Hauck and Borriello <ref> [14] </ref>). Note that for certain circuits, there are missing results for some of the algorithms. This is because no results were reported for these circuits. The column labeled Best shows the minimum cut obtained for each circuit by any of the earlier algorithms. <p> The power of hMETIS over GMetis is much more visible on the largest benchmark golem3 on which even the best of 100 different runs produced a cut that is 50% worse than 10 runs of hMETIS-FM 20vV . hMETIS also significantly outperforms Optimized KLFM <ref> [14] </ref> by Hauck and Borriello. The main reason behind this is the new hyperedge coarsening schemes used in hMETIS. Even though they used powerful refinement schemes (FM with LA 3 [21]), hMETIS outperforms Optimized KLFM.
Reference: [15] <author> Bruce Hendrickson and Robert Leland. </author> <title> A multilevel algorithm for partitioning graphs. </title> <type> Technical Report SAND93-1301, </type> <institution> Sandia National Laboratories, </institution> <year> 1993. </year>
Reference-contexts: But the overall performance of such a scheme depends upon the quality of the coarsening method. In many schemes, the projected partition is further improved using the FM refinement scheme [32]. Recently a new class of multilevel partitioning techniques was developed <ref> [5, 15, 14, 6] </ref>, in which a sequence of successively smaller (coarser) graphs is constructed. A bisection of the smallest graph is computed. <p> Second, the refined partitioning projected to the next level serves as an excellent initial partitioning for the KL or FM refinement algorithms. This paradigm was independently studied by Bui and Jones [5] in the context of computing fill reducing matrix reordering, by Hendrickson and Leland <ref> [15] </ref> in the context of finite element grid partitioning, and by Hauck and Borriello [14](called Optimized KLFM) and by Cong and Smith [6] for hypergraph partitioning. Karypis and Kumar extensively studied this paradigm in [18, 17] for partitioning of graphs.
Reference: [16] <author> E. Ihler, D. Wagner, and F. Wagner. </author> <title> Modeling hypergraphs by graphs with the same mincut properties. </title> <journal> Information Processing Letters, </journal> <volume> 45(4), </volume> <month> March </month> <year> 1993. </year>
Reference-contexts: The fundamental problem associated with replacing a hyperedge by its clique, is that there exists no scheme to assign weight to the edges of the clique that can correctly capture the cost of cutting this hyperedge <ref> [16] </ref>. This hinders the partitioning refinement algorithm since vertices are moved between partitions depending on the reduction in the number of edges they cut in the converted graph, whereas the real objective is to minimize the number of hyperedges that are cut in the original hypergraph.
Reference: [17] <author> G. Karypis and V. Kumar. </author> <title> A fast and high quality multilevel scheme for partitioning irregular graphs. </title> <type> Technical Report TR 95-035, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel serial.ps. A short version appears in Intl. Conf. on Parallel Processing 1995. </note>
Reference-contexts: Karypis and Kumar extensively studied this paradigm in <ref> [18, 17] </ref> for partitioning of graphs. They presented new graph coarsening schemes for which even a good bisection of the coarsest graph is a pretty good bisection of the original graph. This makes the overall multilevel paradigm even more robust. <p> However, for HEC, region growing outperforms random partitioning by 0.6%. These results show that there is no significant difference between the two initial partitioning algorithms, and either one performs reasonably good. These results are consistent with those for multilevel graph partitioning of regular graphs <ref> [17] </ref>. In either case, the initial partitioning of a highly compressed graph has little effect on the overall quality of the final partition. The reasons are two-fold. First, the coarsening process reduces the number of exposed hyperedges in the coarsest hypergraph substantially.
Reference: [18] <author> G. Karypis and V. Kumar. METIS: </author> <title> Unstructured graph partitioning and sparse matrix ordering system. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Available on the WWW at URL http://www.cs.umn.edu/karypis/metis/metis.html. </note>
Reference-contexts: Karypis and Kumar extensively studied this paradigm in <ref> [18, 17] </ref> for partitioning of graphs. They presented new graph coarsening schemes for which even a good bisection of the coarsest graph is a pretty good bisection of the original graph. This makes the overall multilevel paradigm even more robust. <p> This makes the overall multilevel paradigm even more robust. Furthermore, it allows the use of simplified variants of KL and FM refinement schemes during the uncoarsening phase, which significantly speeds up the refinement without compromising the overall quality. METIS <ref> [18] </ref>, a multilevel graph partitioning algorithm based upon this work, routinely finds substantially better bisections and is often two orders of magnitude faster than the hitherto state-of-the-art spectral-based bisection techniques for graphs. The improved coarsening schemes of METIS work only for graphs, and are not directly applicable to hypergraphs. <p> G 4 is the coarsest graph. the hypergraph is first converted into a graph (by replacing each hyperedge by a set of regular edges), then METIS <ref> [18] </ref> can be used to compute a partitioning of this graph. This technique was investigated by Alpert and Khang [1]. They converted hypergraphs to graphs by simply replacing each hyperedge by a clique, and then dropped many edges from each clique randomly. <p> Note that hypergraph based multilevel scheme as presented in this paper significantly outperforms the graph based multilevel scheme GMetis [1] that used METIS <ref> [18] </ref> to compute bisections of graph approximations of hypergraph. The reasons for this performance difference are as follows. First hypergraph based coarsening cause much greater reduction of the exposed hyperedge-weight of the coarsest level hypergraph, and thus provides much better initial partitions than those obtained with edge-based coarsening.
Reference: [19] <author> G. Karypis and V. Kumar. </author> <title> Multilevel k-way partitioning scheme for irregular graphs. </title> <type> Technical Report TR 95-064, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1995. </year> <note> Also available on WWW at URL http://www.cs.umn.edu/karypis/papers/mlevel kway.ps. </note>
Reference-contexts: We implemented two different algorithms. The first algorithm simply creates a balanced random bisection, whereas, the second algorithm starts from a randomly selected vertex and grows a region around it in a breadth-first fashion <ref> [19] </ref> until half of the vertices are in this region. Then the vertices belonging to the grown region are assigned to the first part and the rest of the vertices are assigned to the second part.
Reference: [20] <author> B. W. Kernighan and S. Lin. </author> <title> An efficient heuristic procedure for partitioning graphs. </title> <journal> The Bell System Technical Journal, </journal> <year> 1970. </year>
Reference-contexts: These algorithms often use the Schweikert-Kernighan [28] (an extension of Kernighan-Lin (KL) <ref> [20] </ref> for hypergraphs), or the faster Fiduccia-Mattheyses (FM) [10] refinement heuristic to iteratively improve the quality of the partition. <p> In addition to that, hypergraph coarsening also helps in successively reducing the size of the hyperedges. That is, after several levels of coarsening, large hyperedges are contracted to hyperedges connecting just a few vertices. This is particularly helpful, since refinement heuristics based on the Kernighan-Lin algorithm <ref> [20, 28, 10] </ref> are very effective in refining small hyperedges but are quite ineffective in refining hyperedges with a large number of vertices belonging to different partitions.
Reference: [21] <author> B. Krishnamurthy. </author> <title> An improved min-cut algorithm for partitioning VLSI networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33, </volume> <month> May </month> <year> 1984. </year>
Reference-contexts: For example, it may be better to move a vertex with smaller gain, as it may allow many good moves later. Second, if many vertices have the same gain, then the method offers no insight on which of these vertices to move <ref> [21] </ref>. Third, a hyperedge that has more than one vertices on both sides of the partition line does not influence the computation of the gain of vertices contained in it, making the gain computation quite inexact [7]. <p> Third, a hyperedge that has more than one vertices on both sides of the partition line does not influence the computation of the gain of vertices contained in it, making the gain computation quite inexact [7]. Hence, these algorithms have been extended in a number of ways <ref> [21, 27, 7, 8] </ref>. Krishnamurthy [21] tried to introduce intelligence in the tie breaking process from among the many possible moves with the same high gain. He used a Look Ahead (LA r ) algorithm which looks ahead upto r -level of gains before making moves. <p> Hence, these algorithms have been extended in a number of ways [21, 27, 7, 8]. Krishnamurthy <ref> [21] </ref> tried to introduce intelligence in the tie breaking process from among the many possible moves with the same high gain. He used a Look Ahead (LA r ) algorithm which looks ahead upto r -level of gains before making moves. <p> The main reason behind this is the new hyperedge coarsening schemes used in hMETIS. Even though they used powerful refinement schemes (FM with LA 3 <ref> [21] </ref>), hMETIS outperforms Optimized KLFM. It may be possible to improve the quality of the bisection produced by this algorithm in many ways. Further research may identify better coarsening schemes that are suitable for a wider class of hypergraphs.
Reference: [22] <author> T. Lengauer. </author> <title> Combinatorial Optimization: Networks and Matroids. </title> <publisher> Holt, Rinehart, and Winston, </publisher> <address> Boston, MA, </address> <year> 1976. </year>
Reference-contexts: This is illustrated in Figure 3. Figure 3 (a) shows the original hyperedge and Figure 3 (b) shows the graph obtained after replacing the hyperedge by its clique. The standard hyperedge to edge conversion <ref> [22] </ref> assigns a uniform weight of 1=.jej 1/ to each edge in the clique, where jej is the size of the hyperedge. Thus, in our example, each edge is assigned a weight of 1=3. <p> This edge coarsening scheme is similar in nature to the schemes that treat the hypergraph as a graph by replacing each hyperedge with its clique representation <ref> [22] </ref>. However, this hypergraph to graph conversion is done implicitly during matching without forming the actual graph, as described below.
Reference: [23] <author> J. Li, J. Lillis, and C. Cheng. </author> <title> Linear decomposition algorithm for vlsi design applications. </title> <booktitle> In IEEE Intl. Conf. Computer-Aided Design, </booktitle> <pages> pages 223-228, </pages> <year> 1995. </year>
Reference-contexts: Table 7 shows the size of the hyperedge cut produced by our algorithms (hMETIS) and those reported by various previously developed hypergraph bisection algorithms. In particular, Table 7 contains results for the following algorithms: PROP [7], CDIP-LA3 f and CLIP-PROP f [8], PARABOLI [26], GFM <ref> [23] </ref>, GMetis [1], and Optimized KLFM (scheme by Hauck and Borriello [14]). Note that for certain circuits, there are missing results for some of the algorithms. This is because no results were reported for these circuits.
Reference: [24] <author> J. Li, J. Lillis, and C. K. Cheng. </author> <title> Linear decomposition algorithm for VLSI design applications. </title> <booktitle> In Proceedings IEEE Intl. Conf. Computer Aided Design, </booktitle> <pages> pages 223-228, </pages> <year> 1995. </year>
Reference-contexts: Our experiments show that our multilevel hypergraph partitioning algorithm produces high quality partitioning in relatively small amount of time. The quality of the partitionings produced by our scheme are on the average 6% to 23% better that those produced by other state-of-the-art schemes <ref> [1, 7, 8, 26, 24] </ref>. The difference 5 in quality over other schemes become even greater for larger hypergraphs. Furthermore, our partitioning algorithm is significantly faster, often requiring 4 to 10 times less time than that required by the other schemes.
Reference: [25] <author> B. Mobasher, N. Jain, E.H. Han, and J. Srivastava. </author> <title> Web mining: Pattern discovery from world wide web transactions. </title> <type> Technical Report TR-96-050, </type> <institution> Department of Computer Science, University of Minnesota, Minneapolis, </institution> <year> 1996. </year>
Reference-contexts: 1 Introduction Hypergraph partitioning is an important problem and has extensive application to many areas, including VLSI design [2], efficient storage of large databases on disks [30], and data mining <ref> [25] </ref>. The problem is to partition the vertices of a hypergraph in k roughly equal parts, such that the number of hyperedges connecting vertices in different parts is minimized. A hypergraph is a generalization of a graph, where the set of edges is replaced by a set of hyperedges.
Reference: [26] <author> B. M. Riess, K. Doll, and F. M. Johannes. </author> <title> Partitioning very large circuits using analytical placement techniques. </title> <booktitle> In Proceedings ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 646-651, </pages> <year> 1994. </year> <month> 23 </month>
Reference-contexts: Their results show that reasonably good partitionings can be obtained in a reasonable amount of time for a variety of benchmark problems. In particular, the performance of their resulting scheme (called GMetis) is comparable to other state-of-the art schemes such as PARABOLI <ref> [26] </ref>, PROP [7], and the multilevel hypergraph partitioner from Hauck and Borriello [14]. <p> Our experiments show that our multilevel hypergraph partitioning algorithm produces high quality partitioning in relatively small amount of time. The quality of the partitionings produced by our scheme are on the average 6% to 23% better that those produced by other state-of-the-art schemes <ref> [1, 7, 8, 26, 24] </ref>. The difference 5 in quality over other schemes become even greater for larger hypergraphs. Furthermore, our partitioning algorithm is significantly faster, often requiring 4 to 10 times less time than that required by the other schemes. <p> Comparing the results in Table 2 with those in Table 7, we see that the overall performance of any of these three schemes is, on the average, better than any of the previously known state-of-the-art algorithms <ref> [1, 7, 8, 26] </ref> for hyper-graph partitioning. This demonstrates the power and robustness of the multilevel paradigm for hypergraph partitioning. However, looking at the individual problems, we see that performance of the three schemes differs significantly on some of the problems. <p> Table 7 shows the size of the hyperedge cut produced by our algorithms (hMETIS) and those reported by various previously developed hypergraph bisection algorithms. In particular, Table 7 contains results for the following algorithms: PROP [7], CDIP-LA3 f and CLIP-PROP f [8], PARABOLI <ref> [26] </ref>, GFM [23], GMetis [1], and Optimized KLFM (scheme by Hauck and Borriello [14]). Note that for certain circuits, there are missing results for some of the algorithms. This is because no results were reported for these circuits.
Reference: [27] <author> Y. Saab. </author> <title> A fast and robust network bisection algorithm. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 44(7) </volume> <pages> 903-913, </pages> <year> 1995. </year>
Reference-contexts: Third, a hyperedge that has more than one vertices on both sides of the partition line does not influence the computation of the gain of vertices contained in it, making the gain computation quite inexact [7]. Hence, these algorithms have been extended in a number of ways <ref> [21, 27, 7, 8] </ref>. Krishnamurthy [21] tried to introduce intelligence in the tie breaking process from among the many possible moves with the same high gain. He used a Look Ahead (LA r ) algorithm which looks ahead upto r -level of gains before making moves.
Reference: [28] <author> D. G. Schweikert and B. W. Kernighan. </author> <title> A proper model for the partitioning of electrical circuits. </title> <booktitle> In Proc. ACM/IEEE Design Automation Conference, </booktitle> <pages> pages 57-62, </pages> <year> 1972. </year>
Reference-contexts: These algorithms often use the Schweikert-Kernighan <ref> [28] </ref> (an extension of Kernighan-Lin (KL) [20] for hypergraphs), or the faster Fiduccia-Mattheyses (FM) [10] refinement heuristic to iteratively improve the quality of the partition. <p> In addition to that, hypergraph coarsening also helps in successively reducing the size of the hyperedges. That is, after several levels of coarsening, large hyperedges are contracted to hyperedges connecting just a few vertices. This is particularly helpful, since refinement heuristics based on the Kernighan-Lin algorithm <ref> [20, 28, 10] </ref> are very effective in refining small hyperedges but are quite ineffective in refining hyperedges with a large number of vertices belonging to different partitions.
Reference: [29] <author> S. Shekhar and R. Aggarwal. </author> <title> Clustering roadmaps for routing: A hypergraph approach. </title> <type> Technical report, </type> <institution> Department of Computer Science, University of Minnesota, </institution> <year> 1997. </year>
Reference-contexts: Other applications include clustering as well as the partitioning of the roadmap database for routing applications <ref> [29] </ref> and declustering data in parallel databases [30]. 1.1 Related Work The problem of computing an optimal bisection of a hypergraph is NP-complete 1 . However, because of the importance of the problem in many application areas, many heuristic algorithms have been developed.
Reference: [30] <author> S. Shekhar and D. R. Liu. </author> <title> Partitioning similarity graphs: A framework for declustering problmes. </title> <type> Technical Report TR 94-18, </type> <institution> University of Minnesota, Department of Computer Science, Minneapolis, MN, </institution> <year> 1994. </year> <note> Accepted in Information Systems Journal. </note>
Reference-contexts: 1 Introduction Hypergraph partitioning is an important problem and has extensive application to many areas, including VLSI design [2], efficient storage of large databases on disks <ref> [30] </ref>, and data mining [25]. The problem is to partition the vertices of a hypergraph in k roughly equal parts, such that the number of hyperedges connecting vertices in different parts is minimized. <p> Other applications include clustering as well as the partitioning of the roadmap database for routing applications [29] and declustering data in parallel databases <ref> [30] </ref>. 1.1 Related Work The problem of computing an optimal bisection of a hypergraph is NP-complete 1 . However, because of the importance of the problem in many application areas, many heuristic algorithms have been developed.
Reference: [31] <author> S. Shekhar and D. R. Liu. CCAM: </author> <title> A connectivity-clustered access method for networks and network computations. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <note> to appear. </note>
Reference-contexts: This significantly improves the performance of database operations when disk access time is the bottleneck. By clustering related information we can minimize the number of disk accesses. Graph partitioning is an effective method for database clustering <ref> [31] </ref> but the performance can be further improved by using hypergraph partitioning. In particular, the database is modeled as hypergraph, in which the various items stored in the database (i.e., records) represent the vertices, and records that are accessed together by single queries are connected via hyperedges.
Reference: [32] <author> H. Shin and C. Kim. </author> <title> A simple yet effective technique for partitioning. </title> <journal> IEEE Transactions on VLSI Systems, </journal> <volume> 1(3), </volume> <year> 1993. </year>
Reference-contexts: CDIP in conjunction with LA 3 and CLIP in conjunction with PROP are two schemes that have shown the best results in their experiments. Another class of hypergraph partitioning algorithms <ref> [9, 13, 12, 32] </ref> is of two-phase algorithms. In the first phase, they coarsen the hypergraph to form a small hypergraph and use the FM algorithm to bisect the small hypergraph. <p> Since FM refinement is done only on the small coarse hypergraph, this step is usually fast. But the overall performance of such a scheme depends upon the quality of the coarsening method. In many schemes, the projected partition is further improved using the FM refinement scheme <ref> [32] </ref>. Recently a new class of multilevel partitioning techniques was developed [5, 15, 14, 6], in which a sequence of successively smaller (coarser) graphs is constructed. A bisection of the smallest graph is computed.
Reference: [33] <author> Horst D. Simon and Shang-Hua Teng. </author> <title> How good is recursive bisection? Technical Report RNR-93-012, NAS Systems Division, </title> <booktitle> Moffet Field, </booktitle> <address> CA, </address> <year> 1993. </year> <month> 24 </month>
Reference-contexts: After log k phases, hypergraph H is partitioned into k parts. Thus, the problem of performing a k-way partitioning can be solved by performing a sequence of 2-way partitionings or bisections. Even though this scheme does not necessarily lead to optimal partitionings <ref> [33] </ref>, it is used extensively due to its simplicity. The rest of this paper is organized as follows. Section 2 describes the different algorithms used in the three phases of our multilevel hypergraph partitioning algorithm. A comprehensive experimental evaluation of these algorithms is provided in Section 3.
References-found: 33

