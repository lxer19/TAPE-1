URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/thrun.tr-rule-extraction.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/thrun/papers/full.html
Root-URL: http://www.cs.cmu.edu
Email: E-mail: thrun@cs.uni-bonn.de thrun@cmu.edu  
Phone: Phone: +49-228-550-260 FAX: +49-228-550-382  
Title: Extracting Provably Correct Rules from Artificial Neural Networks  
Author: Sebastian B. Thrun 
Keyword: machine learning, artificial neural networks, rule extraction, validity interval analysis, symbolic and subsymbolic representations  
Address: Romerstr. 164, D-5300 Bonn 1, Germany  
Affiliation: University of Bonn Dept. of Computer Science III  
Abstract: Although connectionist learning procedures have been applied successfully to a variety of real-world scenarios, artificial neural networks have often been criticized for exhibiting a low degree of comprehensibility. Mechanisms that automatically compile neural networks into symbolic rules offer a promising perspective to overcome this practical shortcoming of neural network representations. This paper describes an approach to neural network rule extraction based on Validity Interval Analysis (VI-Analysis). VI-Analysis is a generic tool for extracting symbolic knowledge from Backpropagation-style artificial neural networks. It does this by propagating whole intervals of activations through the network in both the forward and backward directions. In the context of rule extraction, these intervals are used to prove or disprove the correctness of conjectured rules. We describe techniques for generating and testing rule hypotheses, and demonstrate these using some simple classification tasks including the MONK's benchmark problems. Rules extracted by VI-Analysis are provably correct. No assumptions are made about the topology of the network at hand, as well as the procedure employed for training the network. 
Abstract-found: 1
Intro-found: 1
Reference: [ Craven and Shavlik, 1993 ] <author> Mark W. Craven and Jude W. Shavlik. </author> <title> Learning symbolic rules using artificial neural networks. </title> <editor> In Paul E. Utgoff, editor, </editor> <booktitle> Proceedings of the Tenth International Conference on Machine Learning, </booktitle> <address> San Mateo, CA, </address> <year> 1993. </year> <note> Morgan Kaufmann. to appear. </note>
Reference-contexts: Once the network is trained in this manner, dependencies are sparse, and the mapping to a set of rules is straightforward. A second neural network training scheme is described by Craven and Shavlik <ref> [ Craven and Shavlik, 1993 ] </ref> . In their rule extraction algorithm, a weight regularization term is applied during training which aims at grouping weight values into discrete classes. Discrete weights facilitate the extraction of certain types of symbolic rules (namely m-of-n rules) from trained networks.
Reference: [ DeJong and Mooney, 1986 ] <author> Gerald DeJong and Raymond Mooney. </author> <title> Explanation-based learning: An alternative view. </title> <journal> Machine Learning, </journal> <volume> 1(2) </volume> <pages> 145-176, </pages> <year> 1986. </year>
Reference-contexts: Hence the resulting preimage generalizes the training instance in the input space. It is worth mentioning that VI-Analysis bears some resemblance to symbolic explanation-based learning techniques (EBL) <ref> [ DeJong and Mooney, 1986 ] </ref> , [ Mitchell et al., 1986 ] . In symbolic EBL, weakest preconditions are extracted by observing and analyzing a chain of symbolic rule inferences. These weakest preconditions generalize single training instances in the feature space.
Reference: [ Elman, 1988 ] <author> Jeffrey L. Elman. </author> <title> Finding structure in time. </title> <type> Technical Report CRL Technical Report 8801, </type> <institution> Center for Research in Language, University of California, </institution> <address> San Diego, </address> <year> 1988. </year>
Reference-contexts: As described below, VI-Analysis can be extended to piecewise monotonic transfer functions, which includes for example Radial-Basis functions [ Moody and Darken, 1989 ] . 2. No training requirements. Since VI-Analysis analyses trained networks, the rule 11 See for example [ Jordan, 1986 ] , <ref> [ Elman, 1988 ] </ref> , and [ Williams and Zipser, 1989 ] for literature on recurrent networks). Extracting Provably Correct Rules from Artificial Neural Networks 31 extraction mechanism described in this paper does not require any special training procedure. Consequently, VI-Analysis is applicable to a variety of networks.
Reference: [ Fu, 1989 ] <author> Li-Min Fu. </author> <title> Integration of neural heuristics into knowledge-based inference. </title> <journal> Connection Science, </journal> <volume> 1(3) </volume> <pages> 325-339, </pages> <year> 1989. </year>
Reference-contexts: These rules correspond directly to the links and units in the network. Consequently, the technique benefits if the networks at hand are only sparsely connected. In their approach, initial domain knowledge is employed for pre-structuring the networks. Similar methods have been proposed by Fu <ref> [ Fu, 1989 ] </ref> , and Mahoney and Mooney [ Mahoney and Mooney, 1993 ] , [ Mahoney and Mooney, 1992 ] .
Reference: [ Giles and Omlin, 1993 ] <author> C. Lee Giles and Christian W. Omlin. </author> <title> Rule refinement with recurrent neural networks. </title> <booktitle> In Proceedings of the IEEE International Conference on Neural Network, </booktitle> <pages> pages 801-806, </pages> <address> San Francisco, CA, </address> <month> March </month> <year> 1993. </year> <institution> IEEE Neural Network Council. </institution>
Reference-contexts: Similar methods have been proposed by Fu [ Fu, 1989 ] , and Mahoney and Mooney [ Mahoney and Mooney, 1993 ] , [ Mahoney and Mooney, 1992 ] . Tresp and Hollatz [ Tresp and Hollatz, 1993 ] and Giles and Omlin <ref> [ Giles and Omlin, 1993 ] </ref> describe rule extraction methods for a restrictive class of network architectures with specific transfer functions. Tresp and Hollatz's method is restricted to single-layer networks with Gaussian activation functions. In the case of [ Giles and Omlin, 1993 ] , the networks are higher-order recurrent networks <p> and Hollatz [ Tresp and Hollatz, 1993 ] and Giles and Omlin <ref> [ Giles and Omlin, 1993 ] </ref> describe rule extraction methods for a restrictive class of network architectures with specific transfer functions. Tresp and Hollatz's method is restricted to single-layer networks with Gaussian activation functions. In the case of [ Giles and Omlin, 1993 ] , the networks are higher-order recurrent networks which are trained to approximate finite state automata. <p> To give a simple example, the rule the output is always smaller than the input can not be verified by VI-Analysis, since linear constraints may not applied across several layers. VI-Analysis also excludes higher-order rules 12 , as studied for example by Giles and Omlin <ref> [ Giles and Omlin, 1993 ] </ref> . If such rules are to be verified, non-linear optimization techniques must replace the Simplex algorithm. We conclude that we have partially met our goal of a powerful rule language. More general rule languages are clearly desirable.
Reference: [ Goh and Wong, 1993 ] <author> T. G. Goh and Francis Wong. </author> <title> Semantic extraction using neural network modelling ans sensitivity analysis. </title> <note> To be found in the neurprose archive (anonymous ftp from archive.cis.ohio-state.edu:pub/neuroprose/thgoh.sense.ps.Z), </note> <year> 1993. </year>
Reference-contexts: Like VI-Analysis, sensitivity analysis analyses the network as a whole. An approach to rule extraction based on sensitivity analysis has been proposed by Goh and Wong <ref> [ Goh and Wong, 1993 ] </ref> . Sensitivity analysis, however, yields only approximately correct rules. 10 It should be noted that some of the rule extraction mechanisms listed above have not been designed with the same objectives as the method proposed in this paper.
Reference: [ Goldberg, 1989 ] <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: For example, one could start with identifying irrelevant features by removing whole input interval constraints. If the total volume of the rule is to be maximized, parallel search techniques such as Genetic Algorithms [ Holland, 1984 ] , <ref> [ Goldberg, 1989 ] </ref> become applicable. At a first glance, the genetic string could encode the current setting of validity intervals, and the performance measure to be maximized may be the volume covered by these intervals, or a similar function.
Reference: [ Holland, 1984 ] <author> John H. Holland. </author> <title> Genetic algorithms and adaptation. </title> <booktitle> In Proceedings of Ill-Defined Systems, </booktitle> <address> England, </address> <year> 1984. </year>
Reference-contexts: There are a wide variety of more efficient strategies to grow input intervals in real-values domains. For example, one could start with identifying irrelevant features by removing whole input interval constraints. If the total volume of the rule is to be maximized, parallel search techniques such as Genetic Algorithms <ref> [ Holland, 1984 ] </ref> , [ Goldberg, 1989 ] become applicable. At a first glance, the genetic string could encode the current setting of validity intervals, and the performance measure to be maximized may be the volume covered by these intervals, or a similar function.
Reference: [ Jabri et al., 1992 ] <author> M. Jabri, S. Pickard, P. Leong, Z. Chi, B. Flower, and Y. Xie. </author> <title> ANN based classification for heart defibrillators. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 637-644, </pages> <address> San Mateo, CA, </address> <year> 1992. </year> <title> Morgan Kaufmann. Extracting Provably Correct Rules from Artificial Neural Networks 35 </title>
Reference-contexts: Moreover, symbolic rules allow for interfacing with various knowledge-based systems, such 1 See [ Sejnowski and Rosenberg, 1986 ] , [ Waibel, 1989 ] , [ Pomerleau, 1989 ] , [ LeCun et al., 1990 ] , <ref> [ Jabri et al., 1992 ] </ref> , and [ Tesauro, 1992 ] for few out of many examples. 2 The primary focus of this paper will be on Backpropagation-style networks which have learned some classification task. <p> Examples include speech recognition [ Waibel, 1989 ] , speech synthesis [ Sejnowski and Rosenberg, 1986 ] , robot navigation [ Pomerleau, 1989 ] , handwritten digit recognition [ LeCun et al., 1990 ] , medical diagnostics <ref> [ Jabri et al., 1992 ] </ref> , and game playing [ Tesauro, 1992 ] . Unlike rule extraction mechanisms which require a special training routine, VI-Analysis is generally applicable to a broad variety of artificial neural networks, including those listed above. 3. Correctness.
Reference: [ Jordan, 1986 ] <author> Michael I. Jordan. </author> <title> Serial order: A parallel distributed processing approach. </title> <type> Technical Report ICS Report 8604, </type> <institution> Institute for Cognitive Science, University of Califor-nia, </institution> <year> 1986. </year>
Reference-contexts: As described below, VI-Analysis can be extended to piecewise monotonic transfer functions, which includes for example Radial-Basis functions [ Moody and Darken, 1989 ] . 2. No training requirements. Since VI-Analysis analyses trained networks, the rule 11 See for example <ref> [ Jordan, 1986 ] </ref> , [ Elman, 1988 ] , and [ Williams and Zipser, 1989 ] for literature on recurrent networks). Extracting Provably Correct Rules from Artificial Neural Networks 31 extraction mechanism described in this paper does not require any special training procedure.
Reference: [ Karmarkar, 1984 ] <author> N. Karmarkar. </author> <title> A new polynomial-time algorithm for linear programming. </title> <journal> Combinatorica, </journal> <volume> 4 </volume> <pages> 373-395, </pages> <year> 1984. </year>
Reference-contexts: Although this algorithm is known to take worst-case exponential time in the number of variables (i.e. units in a layer), we did not yet observe this algorithm to be slow in practice. It should be noted that there exist more complex algorithms for linear programming which are worst-case polynomial <ref> [ Karmarkar, 1984 ] </ref> . 7 Thus far, we have described the refinement procedure for the units connected to a single weight layer. VI-Analysis iteratively refines all intervals in the network.
Reference: [ LeCun et al., 1990 ] <author> Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hub-bard, and L. D. Jackel. </author> <title> Backpropagation applied to handwritten zip code recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 541-551, </pages> <year> 1990. </year>
Reference-contexts: Such rules can usually be much better interpreted by humans and are thus easier to understand. Moreover, symbolic rules allow for interfacing with various knowledge-based systems, such 1 See [ Sejnowski and Rosenberg, 1986 ] , [ Waibel, 1989 ] , [ Pomerleau, 1989 ] , <ref> [ LeCun et al., 1990 ] </ref> , [ Jabri et al., 1992 ] , and [ Tesauro, 1992 ] for few out of many examples. 2 The primary focus of this paper will be on Backpropagation-style networks which have learned some classification task. <p> Examples include speech recognition [ Waibel, 1989 ] , speech synthesis [ Sejnowski and Rosenberg, 1986 ] , robot navigation [ Pomerleau, 1989 ] , handwritten digit recognition <ref> [ LeCun et al., 1990 ] </ref> , medical diagnostics [ Jabri et al., 1992 ] , and game playing [ Tesauro, 1992 ] .
Reference: [ Mahoney and Mooney, 1992 ] <author> J. Jeffrey Mahoney and Raymond J. Mooney. </author> <title> Combining symbolic and neural learning to revise probabilistic theories. </title> <booktitle> In Proceedings of the 1992 Machine Learning Workshop on Integrated Learning in Real Domains, </booktitle> <address> Aberdeen Scotland, </address> <month> July </month> <year> 1992. </year>
Reference-contexts: Consequently, the technique benefits if the networks at hand are only sparsely connected. In their approach, initial domain knowledge is employed for pre-structuring the networks. Similar methods have been proposed by Fu [ Fu, 1989 ] , and Mahoney and Mooney [ Mahoney and Mooney, 1993 ] , <ref> [ Mahoney and Mooney, 1992 ] </ref> . Tresp and Hollatz [ Tresp and Hollatz, 1993 ] and Giles and Omlin [ Giles and Omlin, 1993 ] describe rule extraction methods for a restrictive class of network architectures with specific transfer functions.
Reference: [ Mahoney and Mooney, 1993 ] <author> J. Jeffrey Mahoney and Raymond J. Mooney. </author> <title> Combining neural and symbolic learning to revise probabilistic rule bases. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> San Mateo, CA, </address> <year> 1993. </year> <note> Morgan Kaufmann. (to appear). </note>
Reference-contexts: Consequently, the technique benefits if the networks at hand are only sparsely connected. In their approach, initial domain knowledge is employed for pre-structuring the networks. Similar methods have been proposed by Fu [ Fu, 1989 ] , and Mahoney and Mooney <ref> [ Mahoney and Mooney, 1993 ] </ref> , [ Mahoney and Mooney, 1992 ] . Tresp and Hollatz [ Tresp and Hollatz, 1993 ] and Giles and Omlin [ Giles and Omlin, 1993 ] describe rule extraction methods for a restrictive class of network architectures with specific transfer functions.
Reference: [ McMillan et al., 1992 ] <author> Clayton McMillan, Michael C. Mozer, and Paul Smolensky. </author> <title> Rule induction through integrated symbolic and subsymbolic processing. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 969-976, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Moreover, the rules found by VI-Analysis are provably correct, making VI-Analysis a promising candidate for larger networks with multiple hidden layers. Other rule extraction mechanisms rely on special training procedure that are applied during network training. For example, McMillan [ McMillan, 1992 ] , <ref> [ McMillan et al., 1992 ] </ref> describes a system in which the task of rule extraction is simplified by imposing regularization constraints on the network during training. Once the network is trained in this manner, dependencies are sparse, and the mapping to a set of rules is straightforward.
Reference: [ McMillan, 1992 ] <author> Clayton McMillan. </author> <title> Rule Induction in a Neural Network through Integrated Symbolic and Subsymbolic Processing. </title> <type> PhD thesis, </type> <institution> University of Colorado, Department of Computer Science, Boulder, </institution> <year> 1992. </year>
Reference-contexts: Moreover, the rules found by VI-Analysis are provably correct, making VI-Analysis a promising candidate for larger networks with multiple hidden layers. Other rule extraction mechanisms rely on special training procedure that are applied during network training. For example, McMillan <ref> [ McMillan, 1992 ] </ref> , [ McMillan et al., 1992 ] describes a system in which the task of rule extraction is simplified by imposing regularization constraints on the network during training.
Reference: [ Mitchell et al., 1986 ] <author> Tom M. Mitchell, Rich Keller, and Smadar Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: Hence the resulting preimage generalizes the training instance in the input space. It is worth mentioning that VI-Analysis bears some resemblance to symbolic explanation-based learning techniques (EBL) [ DeJong and Mooney, 1986 ] , <ref> [ Mitchell et al., 1986 ] </ref> . In symbolic EBL, weakest preconditions are extracted by observing and analyzing a chain of symbolic rule inferences. These weakest preconditions generalize single training instances in the feature space.
Reference: [ Moody and Darken, 1989 ] <author> John Moody and Chris Darken. </author> <title> Fast learning in networks of locally-tuned processing units. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 281-294, </pages> <year> 1989. </year> <title> Extracting Provably Correct Rules from Artificial Neural Networks 36 </title>
Reference-contexts: As described below, VI-Analysis can be extended to piecewise monotonic transfer functions, which includes for example Radial-Basis functions <ref> [ Moody and Darken, 1989 ] </ref> . 2. No training requirements. Since VI-Analysis analyses trained networks, the rule 11 See for example [ Jordan, 1986 ] , [ Elman, 1988 ] , and [ Williams and Zipser, 1989 ] for literature on recurrent networks).
Reference: [ Pomerleau, 1989 ] <author> D. A. Pomerleau. ALVINN: </author> <title> an autonomous land vehicle in a neural network. </title> <type> Technical Report CMU-CS-89-107, </type> <institution> Computer Science Dept. Carnegie Mellon University, </institution> <address> Pittsburgh PA, </address> <year> 1989. </year>
Reference-contexts: Such rules can usually be much better interpreted by humans and are thus easier to understand. Moreover, symbolic rules allow for interfacing with various knowledge-based systems, such 1 See [ Sejnowski and Rosenberg, 1986 ] , [ Waibel, 1989 ] , <ref> [ Pomerleau, 1989 ] </ref> , [ LeCun et al., 1990 ] , [ Jabri et al., 1992 ] , and [ Tesauro, 1992 ] for few out of many examples. 2 The primary focus of this paper will be on Backpropagation-style networks which have learned some classification task. <p> For example, many neural network applications that have proven to be successful in practice have not been trained to facilitate the extraction of rules. Examples include speech recognition [ Waibel, 1989 ] , speech synthesis [ Sejnowski and Rosenberg, 1986 ] , robot navigation <ref> [ Pomerleau, 1989 ] </ref> , handwritten digit recognition [ LeCun et al., 1990 ] , medical diagnostics [ Jabri et al., 1992 ] , and game playing [ Tesauro, 1992 ] .
Reference: [ Quinlan, 1986 ] <author> J. Ross Quinlan. </author> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106, </pages> <year> 1986. </year>
Reference-contexts: At a first glance, the genetic string could encode the current setting of validity intervals, and the performance measure to be maximized may be the volume covered by these intervals, or a similar function. As Tom Dietterich [personal communication] pointed out, symbolic learning algorithms such as decision tree learning <ref> [ Quinlan, 1986 ] </ref> may be used to generate rule hypotheses as well. Symbolic learning procedures directly generate sets of rules which approximate the set of training instances.
Reference: [ Rumelhart et al., 1986 ] <author> David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing. </booktitle> <volume> Vol. I + II. </volume> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: To date, the most common way to characterize the result of neural network learning is statistical in nature. Supervised training procedures, such as the Backpropagation algorithm <ref> [ Rumelhart et al., 1986 ] </ref> , approximate an unknown target function by iteratively minimizing the output error based on a finite set of pre-classified training instances. <p> VI-Analysis on a simple example, namely a network realizing the boolean function AND, is followed by a general description of the refinement procedure in VI-Analysis. 2.1 Notation The following rules of activation propagation for artificial neural networks may be found in the literature on the Backpropagation training algorithm, see e.g. <ref> [ Rumelhart et al., 1986 ] </ref> . Activation values are denoted by x i , where i refers to the index of the unit in the network. 4 By activation pattern we mean a vector of activations generated by the standard forward propagation equations given below. <p> These parameters are adapted during Backpropagation learning <ref> [ Rumelhart et al., 1986 ] </ref> in order to fit a set of training examples. i denotes the transfer function (squashing function), which usually is given by i (net i ) = 1 + e net i with 1 i (x i ) = ln 1 1 Since VI-Analysis applies to
Reference: [ Sejnowski and Rosenberg, 1986 ] <author> T. J. Sejnowski and C. R. Rosenberg. Nettalk: </author> <title> A parallel network that learns to read aloud. </title> <type> Technical Report JHU/EECS-86/01, </type> <institution> John Hopkins University, </institution> <year> 1986. </year>
Reference-contexts: Symbolic learning procedures seek to generate small sets of sparse rules that fit the observed training data. Such rules can usually be much better interpreted by humans and are thus easier to understand. Moreover, symbolic rules allow for interfacing with various knowledge-based systems, such 1 See <ref> [ Sejnowski and Rosenberg, 1986 ] </ref> , [ Waibel, 1989 ] , [ Pomerleau, 1989 ] , [ LeCun et al., 1990 ] , [ Jabri et al., 1992 ] , and [ Tesauro, 1992 ] for few out of many examples. 2 The primary focus of this paper will be <p> Consequently, VI-Analysis is applicable to a variety of networks. For example, many neural network applications that have proven to be successful in practice have not been trained to facilitate the extraction of rules. Examples include speech recognition [ Waibel, 1989 ] , speech synthesis <ref> [ Sejnowski and Rosenberg, 1986 ] </ref> , robot navigation [ Pomerleau, 1989 ] , handwritten digit recognition [ LeCun et al., 1990 ] , medical diagnostics [ Jabri et al., 1992 ] , and game playing [ Tesauro, 1992 ] .
Reference: [ Tesauro, 1992 ] <author> Gerald J. Tesauro. </author> <title> Practical issues in temporal difference learning. </title> <journal> Machine Learning Journal, </journal> <volume> 8, </volume> <year> 1992. </year>
Reference-contexts: Moreover, symbolic rules allow for interfacing with various knowledge-based systems, such 1 See [ Sejnowski and Rosenberg, 1986 ] , [ Waibel, 1989 ] , [ Pomerleau, 1989 ] , [ LeCun et al., 1990 ] , [ Jabri et al., 1992 ] , and <ref> [ Tesauro, 1992 ] </ref> for few out of many examples. 2 The primary focus of this paper will be on Backpropagation-style networks which have learned some classification task. Extracting Provably Correct Rules from Artificial Neural Networks 3 as expert systems or intelligent databases. <p> Examples include speech recognition [ Waibel, 1989 ] , speech synthesis [ Sejnowski and Rosenberg, 1986 ] , robot navigation [ Pomerleau, 1989 ] , handwritten digit recognition [ LeCun et al., 1990 ] , medical diagnostics [ Jabri et al., 1992 ] , and game playing <ref> [ Tesauro, 1992 ] </ref> . Unlike rule extraction mechanisms which require a special training routine, VI-Analysis is generally applicable to a broad variety of artificial neural networks, including those listed above. 3. Correctness.
Reference: [ Thrun and Linden, 1990 ] <author> S. Thrun and A. Linden. </author> <title> Inversion in time. </title> <booktitle> In Proceedings of the EURASIP Workshop on Neural Networks, </booktitle> <address> Sesimbra, Portugal, </address> <month> Feb </month> <year> 1990. </year> <month> EURASIP. </month>
Reference-contexts: This technique is based on a generic tool for analyzing dependencies within neural networks, called Validity Interval Analysis (VI-Analysis or VIA) <ref> [ Thrun and Linden, 1990 ] </ref> . VI-Analysis iteratively analyzes the input-output functionality of an artificial neural network by propagating sets of intervals through the network. The basic notion of VI-Analysis is presented in Section 2, followed in Section 3 by a demonstration using the simple boolean function XOR. <p> Figure 7 displays the results. Each row summarizes a single experiment, and each diagram shows the refinement of validity intervals over time. Each of the five columns corresponds to a particular unit in the network. 7 In an earlier paper <ref> [ Thrun and Linden, 1990 ] </ref> we proposed a more straightforward algorithm which works much faster by sacrificing some solutions to the interval refinement problem.
Reference: [ Thrun et al., 1991 ] <author> Sebastian B. Thrun, Jerzy Bala, Eric Bloedorn, Ivan Bratko, Bojan Cestnik, John Cheng, Kenneth De Jong, Saso Dzeroski, Douglas Fisher, Scott E. Fahlman, Rainer Hamann, Kenneth Kaufman, Stefan Keller, Igor Kononenko, Juergen Kreuziger, Ryszard S. Michalski, Tom Mitchell, Peter Pachowicz, Yoram Reich, Haleh Vafaie, Walter Van de Welde, Walter Wenzel, Janusz Wnek, and Jianping Zhang. </author> <title> The MONK's problems a performance comparison of different learning algorithms. </title> <type> Technical Report CMU-CS-91-197, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: The three MONK's problems constitute a set of benchmark problems for inductive machine learning algorithms <ref> [ Thrun et al., 1991 ] </ref> .
Reference: [ Towell and Shavlik, 1992 ] <author> Geoffrey Towell and Jude W. Shavlik. </author> <title> Interpretation of artificial neural networks: Mapping knowledge-based neural networks into rules. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 977-984, </pages> <address> San Mateo, CA, 1992. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Unlike the technique proposed in this paper, most of the approaches seek to assign semantic concepts to the individual hidden and output units of a network. Often they translate each hidden unit into a separate rule. For example, Towell and Shavlik [ Towell, 1991 ] , <ref> [ Towell and Shavlik, 1992 ] </ref> describe a method which analyzes the weights and biases of a neural network in order to translate the network step-by-step into a set of rules with equivalent structure. <p> Discrete weights facilitate the extraction of certain types of symbolic rules (namely m-of-n rules) from trained networks. Note that the weight regularization term replaces the need for initial knowledge, as reported in [ Towell, 1991 ] and <ref> [ Towell and Shavlik, 1992 ] </ref> . In both of these extraction schemes the effectiveness of the rule extraction mechanism, as well as the degree of correctness of the extracted rules, relies crucially on the particular training procedure invoked.
Reference: [ Towell, 1991 ] <author> Geoffrey Towell. </author> <title> Symbolic Knowledge and Neural Networks: Insertion, Refinement and Extraction. </title> <type> PhD thesis, </type> <institution> University of Wisconsin-Madison, </institution> <year> 1991. </year> <title> Extracting Provably Correct Rules from Artificial Neural Networks 37 </title>
Reference-contexts: Unlike the technique proposed in this paper, most of the approaches seek to assign semantic concepts to the individual hidden and output units of a network. Often they translate each hidden unit into a separate rule. For example, Towell and Shavlik <ref> [ Towell, 1991 ] </ref> , [ Towell and Shavlik, 1992 ] describe a method which analyzes the weights and biases of a neural network in order to translate the network step-by-step into a set of rules with equivalent structure. <p> Discrete weights facilitate the extraction of certain types of symbolic rules (namely m-of-n rules) from trained networks. Note that the weight regularization term replaces the need for initial knowledge, as reported in <ref> [ Towell, 1991 ] </ref> and [ Towell and Shavlik, 1992 ] . In both of these extraction schemes the effectiveness of the rule extraction mechanism, as well as the degree of correctness of the extracted rules, relies crucially on the particular training procedure invoked.
Reference: [ Tresp and Hollatz, 1993 ] <author> Volker Tresp and Jurgen Hollatz. </author> <title> Network structuring and training using rule-based knowledge. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <address> San Mateo, CA, </address> <year> 1993. </year> <note> Morgan Kaufmann. (to appear). </note>
Reference-contexts: In their approach, initial domain knowledge is employed for pre-structuring the networks. Similar methods have been proposed by Fu [ Fu, 1989 ] , and Mahoney and Mooney [ Mahoney and Mooney, 1993 ] , [ Mahoney and Mooney, 1992 ] . Tresp and Hollatz <ref> [ Tresp and Hollatz, 1993 ] </ref> and Giles and Omlin [ Giles and Omlin, 1993 ] describe rule extraction methods for a restrictive class of network architectures with specific transfer functions. Tresp and Hollatz's method is restricted to single-layer networks with Gaussian activation functions.
Reference: [ Waibel, 1989 ] <author> A. H. Waibel. </author> <title> Modular construction of time-delay neural networks for speech recognition. </title> <journal> Neural Computation, </journal> <volume> 1 </volume> <pages> 39-46, </pages> <year> 1989. </year>
Reference-contexts: Such rules can usually be much better interpreted by humans and are thus easier to understand. Moreover, symbolic rules allow for interfacing with various knowledge-based systems, such 1 See [ Sejnowski and Rosenberg, 1986 ] , <ref> [ Waibel, 1989 ] </ref> , [ Pomerleau, 1989 ] , [ LeCun et al., 1990 ] , [ Jabri et al., 1992 ] , and [ Tesauro, 1992 ] for few out of many examples. 2 The primary focus of this paper will be on Backpropagation-style networks which have learned some <p> Consequently, VI-Analysis is applicable to a variety of networks. For example, many neural network applications that have proven to be successful in practice have not been trained to facilitate the extraction of rules. Examples include speech recognition <ref> [ Waibel, 1989 ] </ref> , speech synthesis [ Sejnowski and Rosenberg, 1986 ] , robot navigation [ Pomerleau, 1989 ] , handwritten digit recognition [ LeCun et al., 1990 ] , medical diagnostics [ Jabri et al., 1992 ] , and game playing [ Tesauro, 1992 ] .
Reference: [ Williams and Zipser, 1989 ] <author> R. J. Williams and D. Zipser. </author> <title> A learning algorithm for continually running fully recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 1(2) </volume> <pages> 270-280, </pages> <year> 1989. </year> <note> also appeared as: Technical Report ICS Report 8805, </note> <institution> Institute for Cognitive Science, University of California, </institution> <address> San Diego, CA, </address> <year> 1988. </year>
Reference-contexts: No training requirements. Since VI-Analysis analyses trained networks, the rule 11 See for example [ Jordan, 1986 ] , [ Elman, 1988 ] , and <ref> [ Williams and Zipser, 1989 ] </ref> for literature on recurrent networks). Extracting Provably Correct Rules from Artificial Neural Networks 31 extraction mechanism described in this paper does not require any special training procedure. Consequently, VI-Analysis is applicable to a variety of networks.
Reference: [ Wnek et al., 1990 ] <author> J. Wnek, J. Sarma, A. Wahab, and R. Michalski. </author> <title> Comparison learning paradigms via diagrammatic visualization: A case study in single concept learning using symbolic, neural net and genetic algorithm methods. </title> <type> Technical report, </type> <institution> George Mason University, Computer Science Department, </institution> <year> 1990. </year>
Reference-contexts: The three MONK's problems constitute a set of benchmark problems for inductive machine learning algorithms [ Thrun et al., 1991 ] . They are discrete classification problems defined in an artificial robot domain, in which robots are described by six different attributes, adopted from <ref> [ Wnek et al., 1990 ] </ref> : x 1 : head shape 2 round, square, octagon x 2 : body shape 2 round, square, octagon x 3 : is smiling 2 yes, no x 4 : holding 2 sword, balloon, flag x 5 : jacket color 2 red, yellow, green, blue
References-found: 31

