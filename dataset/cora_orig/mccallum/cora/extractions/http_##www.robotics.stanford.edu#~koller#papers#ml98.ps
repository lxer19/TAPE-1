URL: http://www.robotics.stanford.edu/~koller/papers/ml98.ps
Refering-URL: http://www.robotics.stanford.edu/~koller/papers/ml98.html
Root-URL: http://www.robotics.stanford.edu
Email: koller@cs.stanford.edu  raya@cs.stanford.edu  
Title: Using learning for approximation in stochastic processes  
Author: Daphne Koller Raya Fratkina 
Address: Stanford, CA 94305-9010  Stanford, CA 94305-9010  
Affiliation: Computer Science Dept. Stanford University  Computer Science Dept. Stanford University  
Abstract: To monitor or control a stochastic dynamic system, we need to reason about its current state. Exact inference for this task requires that we maintain a complete joint probability distribution over the possible states, an impossible requirement for most processes. Stochastic simulation algorithms provide an alternative solution by approximating the distribution at time t via a (relatively small) set of samples. The time t samples are used as the basis for generating the samples at time t + 1. However, since only existing samples are used as the basis for the next sampling phase, new parts of the space are never explored. We propose an approach whereby we try to generalize from the time t samples to unsampled regions of the state space. Thus, these samples are used as data for learning a distribution over the states at time t, which is then used to generate the time t+1 samples. We examine different representations for a distribution, including density trees, Bayesian networks, and tree-structured Bayesian networks, and evaluate their appropriateness to the task. The machine learning perspective allows us to examine issues such as the tradeoffs of using more complex models, and to utilize important techniques such as regularization and priors. We validate the performance of our algorithm on both artificial and real domains, and show significant improvement in ac curacy over the existing approach.
Abstract-found: 1
Intro-found: 1
Reference: [Ast65] <author> K. J. Astrom. </author> <title> Optimal control of Markov decision processes with incomplete state estimation. </title> <journal> J. Math. Anal. Applic., </journal> <volume> 10:174205, </volume> <year> 1965. </year>
Reference-contexts: Such a distribution is called a belief state; in a Marko-vian process, it provides a concise summary of all of our past observations, and suffices both for predicting the future trajectory of the system as well as for making optimal decisions about our actions <ref> [Ast65] </ref>. Unfortunately, even systems whose evolution model is compactly represented rarely admit a compact representation of the belief state and an effective update process. Consider, for example, a stochastic system represented as a dynamic Bayesian network (DBN) [DK89].
Reference: [BD97] <author> S. Baluja and S. Davies. </author> <title> Using optimal dependency-trees for combinatorial optimization: Learning the structure of the search space. </title> <booktitle> In Proc. ICML, </booktitle> <year> 1997. </year>
Reference-contexts: We have shown that this idea can significantly improve the quality of our tracking for a given allocation of computational resources. We note that a related idea <ref> [BD97] </ref> has been proposed in the domain of combinatorial optimization algorithms, and has proved very effective.
Reference: [BK98] <author> X. Boyen and D. Koller. </author> <title> Tractable inference for complex stochastic processes. </title> <booktitle> In Proc. </booktitle> <address> UAI, </address> <year> 1998. </year> <note> To appear. </note>
Reference-contexts: Exact inference algorithms for BNs have analogues for inference in DBNs [Kja92]. Unfortunately, in most cases, these algorithms also end up maintaining a belief statea distribution over most or all of the variables in a time slice. Furthermore, it can be shown <ref> [BK98] </ref> that the belief state rarely has any structure that may support a compact representation. Thus, exact inference algorithms are forced to maintain a fully explicit joint distribution over an exponen (a) (b) (c) (c) The WATER 2TBN. tially large state space, making them impractical for most complex systems. <p> A similar problem arises when we attempt to monitor a process with complex continuous dynamics. Here also, an explicit representation of the belief state is infeasible. This limitation has led to work on approximate inference algorithms for complex stochastic processes <ref> [GJ96, BK98, KKR95, IB96] </ref>. Of the approaches proposed, stochastic simulation algorithms are conceptually simplest and make the fewest assumptions about the structure of the process. The survival of the fittest (SOF) algorithm [KKR95] has been applied with success to large discrete DBNs [FHKR95]. <p> Bayesian networks. Given our overall problem, a Bayesian network representation for our distribution seems particularly appropriate. After all, our process is represented as a DBN, and is therefore highly structured. While it is known that conditional independences are not maintained in the belief states <ref> [BK98] </ref>, it is reasonable to assume that some of the random variables in a time slice are 1 If we view SOF as doing a process akin to bootstrapping by sampling from its own samples, our extension is akin to smoothed bootstrapping [Sil86]. only weakly correlated with each other, and perhaps <p> Thus, our algorithm allows us to deal with domains in which exact inference is intractable. Another option is to use non-stochastic approximate inference algorithms <ref> [GJ96, BK98] </ref>. The approach of [GJ96] is not really intended for real-time monitoring, and is probably too computationally expensive to be used in that role. It also applies only to a fairly narrow class of stochastic models. <p> Another option is to use non-stochastic approximate inference algorithms [GJ96, BK98]. The approach of [GJ96] is not really intended for real-time monitoring, and is probably too computationally expensive to be used in that role. It also applies only to a fairly narrow class of stochastic models. The algorithm of <ref> [BK98] </ref> is more comparable to ours; essentially, it avoids the sampling step, directly propagating a time t approximate belief state to a time t + 1 approximate belief state. For certain types of processes, this approach probably dominates ours, as it avoids the additional variance introduced by the sampling phase.
Reference: [CAL94] <author> D. Cohn, L. Atlas, and R. Ladner. </author> <title> Improving generalization with active learning. </title> <booktitle> Machine Learning, </booktitle> <address> 15(2):201221, </address> <year> 1994. </year>
Reference-contexts: Luckily, as we are generating our own data, we can generate as many samples as we need; that is, we can perform a simple type of active learning <ref> [CAL94] </ref>. We then introduce a Dirichlet prior over the parameters of our distribution in order to deal with the problem of numerical overfitting, a particularly serious problem when we have a sparse sample for a very large space. <p> Furthermore, the accuracy maintained by the variable-samples algorithm for likely and unlikely runs is essentially the same; thus, in a way, the algorithm generates as many samples as it needs to maintain a certain level of performance. We can view this ability as a type of active learning <ref> [CAL94] </ref>, where the learning algorithm has the ability to ask for more data cases when necessary. In our context, the active learning paradigm is particularly appropriate, as the algorithm is generating its own data cases. Our next improvement relates to another problem with the SOF algorithm.
Reference: [CHG95] <author> D.M. Chickering, D. Heckerman, and D. Geiger. </author> <title> Learning Bayesian networks: Search methods and experimental results. </title> <booktitle> In Proc. AI & Stats, </booktitle> <pages> pages 112 128, </pages> <year> 1995. </year>
Reference-contexts: Unfortunately, learning of BN structure is a hard problem. Theoretically, even the problem of learning the optimal structure where each node is restricted to have at most k parents is NP-hard for any k &gt; 1 <ref> [CHG95] </ref>. Pragmatically, the algorithms for this learning task are expensive, performing a greedy search, with multiple restarts, over the combinatorial (and superexponential) space of BN structures. One option is to restrict our search to tree-structured BNsones where each node has at most one parent.
Reference: [CL68] <author> C.K. Chow and C.N. Liu. </author> <title> Approximating discrete probability distributions with dependence trees. </title> <journal> IEEE Transaction on Information Theory, </journal> <volume> IT-14:462467, </volume> <year> 1968. </year>
Reference-contexts: Pragmatically, the algorithms for this learning task are expensive, performing a greedy search, with multiple restarts, over the combinatorial (and superexponential) space of BN structures. One option is to restrict our search to tree-structured BNsones where each node has at most one parent. Chow and Liu <ref> [CL68] </ref> present a simple (quadratic time) algorithm for finding the tree-structured BN whose distribution is closestin terms of relative entropyto the one in our data. The intuition is that, in a tree-structured BN, the edges should correspond to the strongest correlations.
Reference: [CS95] <author> P. Cheeseman and J. Stutz. </author> <title> Bayesian classification (AutoClass): Theory and results. </title> <editor> In U. Fayyad et al., editor, </editor> <booktitle> Advances in Knowledge Discovery and Data Mining. </booktitle> <publisher> AAAI Press, </publisher> <year> 1995. </year>
Reference-contexts: One possibility is to combine Bayesian networks and density trees; there are several ways of doing so, which we are currently investigating. We are also considering the use of other (computationally more expensive) representations of a density, e.g., as a mixture model where the mixture components have independent features <ref> [CS95] </ref>. It is interesting to also compare our approach to other types of algorithms for inference in stochastic processes. As we have shown, the number of samples generated by our algorithm is significantly lower than the number of states in the explicit representation of the belief state.
Reference: [CT91] <author> T. Cover and J. Thomas. </author> <title> Elements of Information Theory. </title> <publisher> Wiley, </publisher> <year> 1991. </year>
Reference-contexts: This problem is reflected clearly if we measure the distance between our approximation and the exact distribution using relative entropy <ref> [CT91] </ref>, for many reasons the most appropriate distance measure for this type of situation. For an exact distribution and an approximate one over the same space , the relative entropy D (k ) is defined as !2 (!) log ((!)= (!)). <p> The intuition is that, in a tree-structured BN, the edges should correspond to the strongest correlations. Thus, the algorithm introduces a direct connection between the variables whose mutual information <ref> [CT91] </ref> is largest.
Reference: [Deg86] <author> M.H. </author> <title> Degroot. Probability and statistics. </title> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: An appropriate prior for multinomial distributions such as this is the Dirichlet distribution. We omit the formal definition of the Dirichlet prior, referring the reader to <ref> [Deg86] </ref>. Intuitively, it is defined using a set of hyperparameters ff x i , each representing imaginary samples observed for the state x i .
Reference: [DK89] <author> T. Dean and K. </author> <title> Kanazawa. A model for reasoning about persistence and causation. </title> <journal> Comp. Int., </journal> <volume> 5(3), </volume> <year> 1989. </year>
Reference-contexts: Unfortunately, even systems whose evolution model is compactly represented rarely admit a compact representation of the belief state and an effective update process. Consider, for example, a stochastic system represented as a dynamic Bayesian network (DBN) <ref> [DK89] </ref>. A DBN partitions the evolution of the process into time slices, each of which represents a snapshot of the state of the system at one point in time.
Reference: [DL97] <author> P. Dagum and M. Luby. </author> <title> An optimal approximation algorithm for Baysian inference. </title> <journal> Artificial Intelligence, </journal> <volume> 93(12):127, </volume> <year> 1997. </year>
Reference-contexts: Thus, if the total weight of our N samples is low, then we have not really sampled a significant portion of the probability mass. Indeed, as argued by Dagum and Luby <ref> [DL97] </ref>, the actual number of effective samples is their total weight. Thus, we modify the algorithm to guarantee that our estimation is based on a fixed weight rather than a fixed number of samples. Our results for this improvement, applied to the simple CAPITAL network, are shown in Figure 3.
Reference: [FHKR95] <author> J. Forbes, T. Huang, K. Kanazawa, and S.J. Russell. </author> <title> The BATmobile: Towards a Bayesian automated taxi. </title> <booktitle> In Proc. IJCAI, </booktitle> <pages> pages 18781885, </pages> <year> 1995. </year>
Reference-contexts: The evolution model of the systemthe distribution over states at time t + 1 given the state at time tis represented in a network fragment such as the one in Figure 1 (a) (appropriately annotated with probabilities). DBNs have been used for a variety of applications, including freeway surveillance <ref> [FHKR95] </ref>, monitoring complex factories [JKOP89], and more. Exact inference algorithms for BNs have analogues for inference in DBNs [Kja92]. Unfortunately, in most cases, these algorithms also end up maintaining a belief statea distribution over most or all of the variables in a time slice. <p> Of the approaches proposed, stochastic simulation algorithms are conceptually simplest and make the fewest assumptions about the structure of the process. The survival of the fittest (SOF) algorithm [KKR95] has been applied with success to large discrete DBNs <ref> [FHKR95] </ref>. The same algorithm (independently discovered by [IB96]) has been applied to the continuous problem of tracking object motion in cluttered visual scenes.
Reference: [GJ96] <author> Z. Ghahramani and M.I. Jordan. </author> <title> Factorial hidden Markov models. </title> <booktitle> In NIPS 8, </booktitle> <year> 1996. </year>
Reference-contexts: A similar problem arises when we attempt to monitor a process with complex continuous dynamics. Here also, an explicit representation of the belief state is infeasible. This limitation has led to work on approximate inference algorithms for complex stochastic processes <ref> [GJ96, BK98, KKR95, IB96] </ref>. Of the approaches proposed, stochastic simulation algorithms are conceptually simplest and make the fewest assumptions about the structure of the process. The survival of the fittest (SOF) algorithm [KKR95] has been applied with success to large discrete DBNs [FHKR95]. <p> Thus, our algorithm allows us to deal with domains in which exact inference is intractable. Another option is to use non-stochastic approximate inference algorithms <ref> [GJ96, BK98] </ref>. The approach of [GJ96] is not really intended for real-time monitoring, and is probably too computationally expensive to be used in that role. It also applies only to a fairly narrow class of stochastic models. <p> Thus, our algorithm allows us to deal with domains in which exact inference is intractable. Another option is to use non-stochastic approximate inference algorithms [GJ96, BK98]. The approach of <ref> [GJ96] </ref> is not really intended for real-time monitoring, and is probably too computationally expensive to be used in that role. It also applies only to a fairly narrow class of stochastic models.
Reference: [Hec95] <author> D. Heckerman. </author> <title> A tutorial on learning with Bayesian networks. </title> <type> Technical Report MSR-TR-95-06, </type> <institution> Mi-crosoft Research, </institution> <year> 1995. </year>
Reference-contexts: There has been a substantial amount of recent work on learning Bayesian networks from data (see <ref> [Hec95] </ref> for a survey). The simplest option is to fix the structure of the Bayesian network and to use our data to fill in the parameters for it. This process can be accomplished very efficiently, by a simple traversal over our data.
Reference: [IB96] <author> M. Isard and A. Blake. </author> <title> Contour tracking by stochastic propagation of conditional density. </title> <booktitle> In Proc. ECCV, </booktitle> <volume> volume 1, </volume> <pages> pages 343356, </pages> <year> 1996. </year>
Reference-contexts: A similar problem arises when we attempt to monitor a process with complex continuous dynamics. Here also, an explicit representation of the belief state is infeasible. This limitation has led to work on approximate inference algorithms for complex stochastic processes <ref> [GJ96, BK98, KKR95, IB96] </ref>. Of the approaches proposed, stochastic simulation algorithms are conceptually simplest and make the fewest assumptions about the structure of the process. The survival of the fittest (SOF) algorithm [KKR95] has been applied with success to large discrete DBNs [FHKR95]. <p> Of the approaches proposed, stochastic simulation algorithms are conceptually simplest and make the fewest assumptions about the structure of the process. The survival of the fittest (SOF) algorithm [KKR95] has been applied with success to large discrete DBNs [FHKR95]. The same algorithm (independently discovered by <ref> [IB96] </ref>) has been applied to the continuous problem of tracking object motion in cluttered visual scenes. <p> Despite its simplicity and low computational cost, the SOF algorithm performs very well; as shown in [KKR95], its error seems to remain bounded indefinitely over time. As shown in <ref> [IB96] </ref>, this algorithm can also deal with complex continuous processes much more successfully than standard techniques. In this paper, we use machine learning techniques to improve the behavior of the SOF algorithm, with the goal of applying it to real-world complex domains. <p> By contrast, we note that our ideas are not specific to DBNs. The only use we made of the DBN model is as a representation from which we can generate random samples. We believe that our ideas apply to a much wider range of processes. Indeed, Isard and Blake <ref> [IB96] </ref> have obtained impressive results by using a stochastic sampling algorithm identical to simple SOF for the task of monitoring object motion in cluttered scenes. Here, the process is described using fairly complex continuous dynamics, that do not permit any exact inference algorithm.
Reference: [JKOP89] <author> F.V. Jensen, U. Kjrulff, K.G. Olesen, and J. Ped-ersen. </author> <title> An expert system for control of waste water treatment a pilot project. </title> <type> Technical report, </type> <note> Judex Datasystemer A/S, </note> <institution> Aalborg, Denmark, </institution> <year> 1989. </year>
Reference-contexts: DBNs have been used for a variety of applications, including freeway surveillance [FHKR95], monitoring complex factories <ref> [JKOP89] </ref>, and more. Exact inference algorithms for BNs have analogues for inference in DBNs [Kja92]. Unfortunately, in most cases, these algorithms also end up maintaining a belief statea distribution over most or all of the variables in a time slice. <p> to multidimensional histogram techniques; however, the tree structure allows variable-sized bins, and therefore greater flexibility in matching the number of parameters to the com plexity of the distribution. 5 Experimental results To provide a more realistic comparison, we tested the different variants of our algorithm on the practical WATER DBN <ref> [JKOP89] </ref>, used for monitoring the biological processes of a water purification plant. (Comparable results were obtained for the CAPITAL network.) The WATER DBN had a substantially larger state space, with 27,648 possible values taken by the (non-evidence) variables. The structure of the WATER network is shown in Figure 1 (c).
Reference: [Kja92] <author> U. Kjaerulff. </author> <title> A computational scheme for reasoning in dynamic probabilistic networks. </title> <booktitle> In Proc. UAI, </booktitle> <pages> pages 121129, </pages> <year> 1992. </year>
Reference-contexts: DBNs have been used for a variety of applications, including freeway surveillance [FHKR95], monitoring complex factories [JKOP89], and more. Exact inference algorithms for BNs have analogues for inference in DBNs <ref> [Kja92] </ref>. Unfortunately, in most cases, these algorithms also end up maintaining a belief statea distribution over most or all of the variables in a time slice. Furthermore, it can be shown [BK98] that the belief state rarely has any structure that may support a compact representation.
Reference: [KKR95] <author> K. Kanazawa, D. Koller, and S.J. Russell. </author> <title> Stochastic simulation algorithms for dynamic probabilistic networks. </title> <booktitle> In Proc. UAI, </booktitle> <pages> pages 346351, </pages> <year> 1995. </year>
Reference-contexts: A similar problem arises when we attempt to monitor a process with complex continuous dynamics. Here also, an explicit representation of the belief state is infeasible. This limitation has led to work on approximate inference algorithms for complex stochastic processes <ref> [GJ96, BK98, KKR95, IB96] </ref>. Of the approaches proposed, stochastic simulation algorithms are conceptually simplest and make the fewest assumptions about the structure of the process. The survival of the fittest (SOF) algorithm [KKR95] has been applied with success to large discrete DBNs [FHKR95]. <p> This limitation has led to work on approximate inference algorithms for complex stochastic processes [GJ96, BK98, KKR95, IB96]. Of the approaches proposed, stochastic simulation algorithms are conceptually simplest and make the fewest assumptions about the structure of the process. The survival of the fittest (SOF) algorithm <ref> [KKR95] </ref> has been applied with success to large discrete DBNs [FHKR95]. The same algorithm (independently discovered by [IB96]) has been applied to the continuous problem of tracking object motion in cluttered visual scenes. <p> A sample at time t is propagated to time t + 1 by a random process based on the dynamics of the system. In a naive generalization of [SP89], each time t sample is propagated forward to time t + 1. However, as shown by <ref> [KKR95] </ref>, this approach results in extremely poor performance, with the error of the approximation diverging rapidly as t grows. They propose an approach where samples are propagated preferentially: those whose weight is higher are more likely to be propagated, while the lower weight ones tend to be killed off. <p> The resulting trajectories are weighted based on how well they fit the new evidence at time t + 1, and the process continues. Despite its simplicity and low computational cost, the SOF algorithm performs very well; as shown in <ref> [KKR95] </ref>, its error seems to remain bounded indefinitely over time. As shown in [IB96], this algorithm can also deal with complex continuous processes much more successfully than standard techniques. <p> At each time slice t, each of the samples is propagated to the next time slice using the LW algorithm, and its weight is adjusted according to how well it reflects the new observations. Unfortunately, as observed by <ref> [KKR95] </ref>, this approach works very poorly for most DBNs. Intuitively, the process by which samples are randomly generated is oblivious to the evidence, which only affects the weight assigned to the samples. Therefore, the samples represent random trajectories through the system, most of which are completely irrelevant. <p> Intuitively, the process by which samples are randomly generated is oblivious to the evidence, which only affects the weight assigned to the samples. Therefore, the samples represent random trajectories through the system, most of which are completely irrelevant. As a consequence, as shown in <ref> [KKR95] </ref>, the accuracy of LW diverges extremely quickly over time. The survival of the fittest algorithm of [KKR95] addresses this problem by preferentially selecting which samples to propagate according to how likely they are, i.e., their weight relative to other samples. <p> Therefore, the samples represent random trajectories through the system, most of which are completely irrelevant. As a consequence, as shown in <ref> [KKR95] </ref>, the accuracy of LW diverges extremely quickly over time. The survival of the fittest algorithm of [KKR95] addresses this problem by preferentially selecting which samples to propagate according to how likely they are, i.e., their weight relative to other samples. Technically, each sample x (t) [j] is associated with a weight w (t) [j].
Reference: [Sco92] <author> D.W. Scott. </author> <title> Multivariate Density Estimation: Theory, Practice, and Visualization. </title> <publisher> Wiley, </publisher> <year> 1992. </year>
Reference-contexts: This task is precisely a density estimation task (a type of unsupervised learning), where the set of sampled states are the training data. 1 As in any learning task, we must first define the hypothesis space. Essentially, our representations above fall into the category of nonparametric density estimators <ref> [Sco92] </ref>. (Roughly speaking, they are a discrete form of Parzen window.) As applied in our setting, these density estimators have no bias (and high variance); thus, they are incapable of generalizing from the training data to the rest of the space. <p> We note that our notion of a density tree draws upon the literature of semiparametric density estimation techniques for continuous densities <ref> [Sco92] </ref>.
Reference: [Sil86] <author> B.W. Silverman. </author> <title> Density estimation for statistics and data analysis. </title> <publisher> Chapman & Hall, </publisher> <year> 1986. </year>
Reference-contexts: independences are not maintained in the belief states [BK98], it is reasonable to assume that some of the random variables in a time slice are 1 If we view SOF as doing a process akin to bootstrapping by sampling from its own samples, our extension is akin to smoothed bootstrapping <ref> [Sil86] </ref>. only weakly correlated with each other, and perhaps even weaker when conditioned on a third variable. There has been a substantial amount of recent work on learning Bayesian networks from data (see [Hec95] for a survey).
Reference: [SP89] <author> R. D. Shachter and M. A. Peot. </author> <title> Simulation approaches to general probabilistic inference on belief networks. </title> <booktitle> In Proc. </booktitle> <address> UAI, </address> <year> 1989. </year>
Reference-contexts: The same algorithm (independently discovered by [IB96]) has been applied to the continuous problem of tracking object motion in cluttered visual scenes. The algorithm, which builds on stochastic simulation algorithms for standard BNs <ref> [SP89] </ref>, is as follows: For each time slice, we maintain a (small) set of weighted samples; a sample is one possible state of the system at that time, while its weight is some measure of how likely it is. <p> This set of weighted samples is, in effect, a very sparse estimate of the belief state at time t. A sample at time t is propagated to time t + 1 by a random process based on the dynamics of the system. In a naive generalization of <ref> [SP89] </ref>, each time t sample is propagated forward to time t + 1. However, as shown by [KKR95], this approach results in extremely poor performance, with the error of the approximation diverging rapidly as t grows.
References-found: 21

