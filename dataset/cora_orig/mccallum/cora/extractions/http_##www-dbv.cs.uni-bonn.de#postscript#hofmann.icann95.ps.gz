URL: http://www-dbv.cs.uni-bonn.de/postscript/hofmann.icann95.ps.gz
Refering-URL: 
Root-URL: 
Title: Hierarchical Pairwise Data Clustering by Mean-Field Annealing  
Author: Thomas Hofmann Joachim M. Buhmann Rheinische Friedrich-Wilhelms-Universitat 
Address: D-53117 Bonn, Germany  
Affiliation: Institut fur Informatik III, Romerstrae 164  
Abstract: Partitioning a data set and extracting hidden structure arises in different application areas of pattern recognition, data analysis and image processing. We formulate data clustering for data characterized by pairwise dissimilarity values as an assignment problem with an objective function to be minimized. An extension to tree-structured clustering is proposed which allows a hierarchical grouping of data. Deterministic annealing algorithms are derived for uncon strained and tree-structured pairwise clustering.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Buhmann and T. Hofmann. </author> <title> A maximum entropy approach to pairwise data clustering. </title> <booktitle> In Proceedings of the ICPR'94, </booktitle> <volume> volume II, </volume> <pages> pages 207-212. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1994. </year>
Reference-contexts: The algorithm which is derived in this paper belongs to the class of deterministic annealing algorithms, a deterministic variant of the well-known simulated annealing [3]. Deterministic annealing algorithms have been successfully applied to vector quantization [5, 2], pairwise data clustering <ref> [1] </ref> and other optimization problems in pattern recognition and image processing. Deterministic annealing algorithms favor parallel implementations and are scalable with respect to the quality/complexity tradeoff. The paper is organized as follows. In Section 2 we give a general outline how to derive deterministic annealing algorithms for assignment problems. <p> Euclidian distances D ik = kx i x k k 2 , Eq. (2) simplifies to the widely used objective function for vector quantization: H K (M ; X ) = -=1 i=1 M i-kx i y -k 2 , prototypes y being defined accord ing to the centroid condition <ref> [1] </ref>.
Reference: [2] <author> J. M. Buhmann and H. Kuhnel. </author> <title> Vector quantization with complexity costs. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 39(4) </volume> <pages> 1133-1145, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: The algorithm which is derived in this paper belongs to the class of deterministic annealing algorithms, a deterministic variant of the well-known simulated annealing [3]. Deterministic annealing algorithms have been successfully applied to vector quantization <ref> [5, 2] </ref>, pairwise data clustering [1] and other optimization problems in pattern recognition and image processing. Deterministic annealing algorithms favor parallel implementations and are scalable with respect to the quality/complexity tradeoff. The paper is organized as follows.
Reference: [3] <author> S. Kirkpatrick, </author> <title> C.D. Gelatt, and M.P. Vecchi. Optimization by simulated annealing. </title> <journal> Science, </journal> <volume> 220 </volume> <pages> 671-680, </pages> <year> 1983. </year>
Reference-contexts: P Mi-= 1; 8i in the clustering case, to enforce a unique and complete assignment. The algorithm which is derived in this paper belongs to the class of deterministic annealing algorithms, a deterministic variant of the well-known simulated annealing <ref> [3] </ref>. Deterministic annealing algorithms have been successfully applied to vector quantization [5, 2], pairwise data clustering [1] and other optimization problems in pattern recognition and image processing. Deterministic annealing algorithms favor parallel implementations and are scalable with respect to the quality/complexity tradeoff. The paper is organized as follows. <p> If the hM i-i are calculated by stochastic sampling we are performing simulated annealing <ref> [3] </ref>, if they are determined analytically this is called deterministic annealing. Often the Gibbs distribution is not separable and it cannot be written as a product of statistically independent assignment variables, since the sufficient statistics is unknown. In this case, the calculation of expectation values is intractable.
Reference: [4] <author> D. Miller and K. Rose. </author> <title> A non-greedy approach to tree-structured clustering. </title> <journal> Pattern Recognition Letters, </journal> <volume> 15(7) </volume> <pages> 683-690, </pages> <year> 1994. </year>
Reference-contexts: Therefore an extension of pairwise data clustering to tree-structured grouping, as proposed in this paper, is highly desirable. For the vector quantization problem a tree-structured clustering algorithm has recently been proposed by Miller et al. <ref> [4] </ref>. Data clustering is a special case of combinatorial optimization problems known as assignment problems. The solution space M of an assignment problem is conveniently represented by Boolean assignment variables M i- 2 f0; 1g, indicating whether or not item i is assigned to group -. <p> For fl=fi ! 1 the structural constraints are strictly enforced, while for fl=fi ! 0 the prior vanishes completely. In the fi = fl case costs at inner and leaf nodes are equally weighted. fl can also be used to control the fuzziness in the leaf layer <ref> [4] </ref>. As in the case of unconstrained clustering we calculate P mf by a fix point method and increase the inverse temperatures fi and fl, starting the next iteration with the solution found at the preceeding temperature level.
Reference: [5] <author> K. Rose, E. Gurewitz, and G. Fox. </author> <title> Vector quantization by deterministic annealing. </title> <journal> IEEE transactions on Information Theory, </journal> <volume> 38(4) </volume> <pages> 1249-1257, </pages> <year> 1992. </year>
Reference-contexts: The algorithm which is derived in this paper belongs to the class of deterministic annealing algorithms, a deterministic variant of the well-known simulated annealing [3]. Deterministic annealing algorithms have been successfully applied to vector quantization <ref> [5, 2] </ref>, pairwise data clustering [1] and other optimization problems in pattern recognition and image processing. Deterministic annealing algorithms favor parallel implementations and are scalable with respect to the quality/complexity tradeoff. The paper is organized as follows. <p> To derive the tree structure in an unsupervised fashion we splitted clusters at phase transitions <ref> [5] </ref>, growing the tree dynamically with decreasing temperature.
References-found: 5

