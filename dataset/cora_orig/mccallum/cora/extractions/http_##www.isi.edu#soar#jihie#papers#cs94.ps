URL: http://www.isi.edu/soar/jihie/papers/cs94.ps
Refering-URL: http://www.isi.edu/soar/jihie/chunking.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Learning High Utility Rules by Incorporating Search Control  Guidance Committee  
Author: Jihie Kim Dr. Paul S. Rosenbloom(Chairperson) Dr. Shankar A. Rajamoney Dr. Kenneth Y. Goldberg Dr. Craig A. Knoblock Dr. Stephen J. Read(Outside Member) 
Degree: Ph.D. Dissertation Proposal submitted by  
Date: February 1994  
Affiliation: Dept. of Computer Science Artificial Intelligence University of Southern California  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Acharya and M. Tambe. </author> <title> Collection-oriented match : Scaling up the data in production systems. </title> <type> Technical Report CMU-CS-92-218, </type> <institution> Computer Science Department, Carnegie Mellon University, </institution> <year> 1992. </year>
Reference-contexts: A combination of the two techniques will be implemented and evaluated empirically over a variety of tasks. 6.2 Collection-oriented match and dead-variable elimination In collection-oriented match <ref> [1] </ref>, a set of working memory elements, instead of an individual working memory element, is the unit of matching. Thus, tuples of sets instead of simple tuples are used for generating the partial instantiations. Figure 24 shows an example. <p> For a production with K conditions, the savings are O (N K ). In addition to space savings, there are also corresponding speedups in execution time. The analysis performed in <ref> [1] </ref> shows that the tasks which have large productions with large collections matching with each condition and little fragmentation achieves large time and space improvement.
Reference: [2] <author> F. Barachini and G. Verteneul. </author> <title> The challenge of real-time process control for production systems. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 705-709, </pages> <year> 1988. </year>
Reference-contexts: This results in the match time being linear in the number of conditions. Although this restriction has been successfully applied to a number of systems <ref> [2, 5, 3] </ref> and has obtained significant time savings as a result, there are still some outstanding problems.
Reference: [3] <author> J. Bouaud and P. Zweigenbaum. </author> <title> A reconstruction of conceptual graphs on top of a production system. </title> <booktitle> In Proceedings of the 7th Annual Workshop on Conceptual Graphs, </booktitle> <year> 1992. </year>
Reference-contexts: This results in the match time being linear in the number of conditions. Although this restriction has been successfully applied to a number of systems <ref> [2, 5, 3] </ref> and has obtained significant time savings as a result, there are still some outstanding problems.
Reference: [4] <author> B. Carlson, J. Weinberg, and D. Fisher. </author> <title> Search control, utility, and concept induction. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 85-91, </pages> <year> 1990. </year>
Reference-contexts: The term utility problem has also come to be used for a variety of other issues and phenomena such as accuracy and completeness of empirical learning systems, in which the learning intends to achieve a better classification, but not necessarily speed-up <ref> [13, 23, 14, 4] </ref>. However, this proposal concentrates upon the utility problem in speed-up learning. Many speed-up learning systems acquire new knowledge in the form of control rules 1 . The utility problem for these systems is mainly concerned with the cost of using these learned rules.
Reference: [5] <author> W. W. Cohen. </author> <title> Learning approximate control rules of high utilty. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 268-276, </pages> <year> 1990. </year>
Reference-contexts: This results in the match time being linear in the number of conditions. Although this restriction has been successfully applied to a number of systems <ref> [2, 5, 3] </ref> and has obtained significant time savings as a result, there are still some outstanding problems.
Reference: [6] <author> B. Doorenbos, M. Tambe, and A. </author> <title> Newell. </title> <booktitle> Learning 10,000 chunks: What's it like out there? In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 830-836, </pages> <year> 1992. </year>
Reference-contexts: The first issue is the expensive chunk problem 2 [34], in which individual learned rules are so expensive to match that the system suffers a slow down from learning [20, 30, 7, 28, 29]. The second issue is the average growth effect <ref> [6] </ref>, in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. This research focuses on the expensive chunk problem in EBL a representative form of speed-up learning.
Reference: [7] <author> O. Etzioni. </author> <title> Why prodigy/ebl works. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 916-922, </pages> <year> 1990. </year>
Reference-contexts: The research on this problem has focused on two key issues. The first issue is the expensive chunk problem 2 [34], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [20, 30, 7, 28, 29] </ref>. The second issue is the average growth effect [6], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> There has been approaches which statically analyze search structure or problem space structure before problem solving. Taylor and Korf [36] developed a technique to detect duplicate operator sequences from a small bread-first search to control the redundancy in the problem solving. STATIC <ref> [7] </ref> employed a depth-first search for non-recursive problem space structure subgraph, and extracts control rules from the non-recursive subgraphs it find. These approaches does not utilize dynamic aspect of problem solving, and thus have potential disadvantages than EBL [24].
Reference: [8] <author> O. Etzioni. </author> <title> An asymptotic analysis of speedup learning. </title> <booktitle> In Proceedings of the Ninth International Workshop on Machine Learning, </booktitle> <pages> pages 135-142, </pages> <year> 1992. </year>
Reference-contexts: Macro-operator learning suffers the overhead of increasingthe branching factor of a problem solver's search. Etzioni <ref> [8] </ref> has claimed that acquiring macro-operators is guaranteed to slow down a problem solver unless the macros modify the search-space structure so that sufficient search-depth reduction accompanies branching-factor increase, everywhere. However, this research is not concerning about this problem. 2 Chunk means any learned rule.
Reference: [9] <author> R. Fikes, P. Hart, and N. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference-contexts: Third, systems can evaluate the utility of learned knowledge and keep only the useful ones [20]. However, the utility evaluation of the candidate rules may become a part of the utility problem 1 Another form of learned knowledge in speed-up learning is macro-operators <ref> [9, 17] </ref>, which are compositions of original operators. Macro-operator learning suffers the overhead of increasingthe branching factor of a problem solver's search.
Reference: [10] <author> C. L. Forgy. </author> <title> Rete: A fast algorithm for the many pattern/many object pattern match problem. </title> <journal> Artificial Intelligence, </journal> <volume> 19(1) </volume> <pages> 17-37, </pages> <year> 1982. </year>
Reference-contexts: All three versions use an efficient implementation of RETE <ref> [10] </ref> as match algorithm. 4.1 Grid task Table 1 shows the average CPU time per problem for the three versions, averaged across seven different problems in the Grid Task, both before and after learning.
Reference: [11] <author> J. Gratch and G. Dejong. Composer: </author> <title> A probabilistic solution to the utility problem in speedup learning. </title> <booktitle> In Proceedings of the Tenth National Conference on Aritificial Intelligence, </booktitle> <pages> pages 235-240, </pages> <year> 1992. </year>
Reference-contexts: The utility analysis in PALO is expected performance based on the test cases from a fixed distribution. This is similar to the approach taken in Composer <ref> [11] </ref> which adds a control rule to the system only if it shows incremental utility. The incremental utility is evaluated by expected problem solving cost in a sequence of problems.
Reference: [12] <author> R. Greiner and I. Jurisica. </author> <title> A statistical approach to solving the ebl utility problem. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> pages 241-248, </pages> <year> 1992. </year>
Reference-contexts: These originated in Minton [20]'s utility evaluation, where PRODIGY/EBL 28 measures the utility in terms of savings and cost of a rule, and rules are deactivated if their utility becomes negative. Greiner and Jurisica <ref> [12] </ref> proposed an algorithm called PALO that navigates through the space of performance elements, and selects a new performance element which is strictly better than the current performance element to reach the one that is essentially local optimal.
Reference: [13] <author> L. B. Holder. </author> <title> The general utilty problem in machine learning. </title> <booktitle> In Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pages 402-410, </pages> <year> 1990. </year> <month> 36 </month>
Reference-contexts: The term utility problem has also come to be used for a variety of other issues and phenomena such as accuracy and completeness of empirical learning systems, in which the learning intends to achieve a better classification, but not necessarily speed-up <ref> [13, 23, 14, 4] </ref>. However, this proposal concentrates upon the utility problem in speed-up learning. Many speed-up learning systems acquire new knowledge in the form of control rules 1 . The utility problem for these systems is mainly concerned with the cost of using these learned rules.
Reference: [14] <author> L. B. Holder. </author> <title> Empirical analysis of the general utility problem in machine learning. </title> <booktitle> In Proceedings of the Ninth International Workshop on Machine Learning, </booktitle> <pages> pages 249-254, </pages> <year> 1992. </year>
Reference-contexts: The term utility problem has also come to be used for a variety of other issues and phenomena such as accuracy and completeness of empirical learning systems, in which the learning intends to achieve a better classification, but not necessarily speed-up <ref> [13, 23, 14, 4] </ref>. However, this proposal concentrates upon the utility problem in speed-up learning. Many speed-up learning systems acquire new knowledge in the form of control rules 1 . The utility problem for these systems is mainly concerned with the cost of using these learned rules.
Reference: [15] <author> C. A. Knoblock J. G. Carbonell and S. Minton. </author> <title> Prodigy: An integrated architecture for planning and learning. </title> <editor> In K. Vanlehn, editor, </editor> <booktitle> Architecture for Intelligence: The 22nd Carnegie Mellon Symposium on Cognition. </booktitle> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, NJ, </address> <year> 1991. </year>
Reference-contexts: Although the investigation is based on chunking in Soar, it should be applicable to most of the problem solving systems which use control rules and have 33 EBL as a learning paradigm, including Prodigy <ref> [15] </ref>. Expected contributions of this research are: 1. Solving the expensive chunk problem without restricting the expressiveness The prior strong solution to the expensive chunk problem depends on restricting expressiveness, and showed several weaknesses. Controlled chunking is proposed as a weak solution.
Reference: [16] <author> J. E. Laird, C. B. Congdon, E. Altmann, and R. Doorenbos. </author> <note> Soar User's Manual: Version 6, 1 edition, </note> <year> 1993. </year>
Reference-contexts: A preference specifies the relative or absolute worth of a value of a given object and an attribute <ref> [16] </ref>. Figure 10 briefly describes the semantics of the major preferences. Rules in Soar propose changes to working memory through preferences, but do not actually make the changes.
Reference: [17] <author> J. E. Laird, P. S. Rosenbloom, and A. Newell. </author> <title> Chunking in soar: The anatomy of a general learning mechanism. </title> <journal> Machine Learning, </journal> <volume> 1, </volume> <year> 1985. </year>
Reference-contexts: Third, systems can evaluate the utility of learned knowledge and keep only the useful ones [20]. However, the utility evaluation of the candidate rules may become a part of the utility problem 1 Another form of learned knowledge in speed-up learning is macro-operators <ref> [9, 17] </ref>, which are compositions of original operators. Macro-operator learning suffers the overhead of increasingthe branching factor of a problem solver's search.
Reference: [18] <author> J. E. Laird, P. S. Rosenbloom, and A. Newell. </author> <title> Overgeneralization during knowledge compilation in soar. </title> <booktitle> In Proceedings of the Workshop on Knowledge Compilation, </booktitle> <pages> pages 46-57, </pages> <year> 1986. </year>
Reference-contexts: When a new rule is acquired from a trace of the problem solving, often the control rules are not included in learning (i.e., in the explanation). For example, PRODIGY/EBL [21] and Soar <ref> [18, 26] </ref> two problem solvers that learn search-control rules by a variant of EBL ignore a large part of the search-control rules in learning to increase the generality of the learned rules. (The details of how they increase the generality are in section 3.) The most critical consequence of this omission <p> It sometimes requires a large number of rules for the same knowledge which could be expressed by a single rule. This research pursues the following three goals. First, to flesh out the design and implement controlled chunking. I have chosen to use Soar for the implementation, where Soar <ref> [18, 26] </ref> 4 In real world situations, cpu time after learning for critical (active) period should be less than cpu time before learning. <p> For example, TacAir-Soar [32] suffers a temporary catastrophic slowdown due to expensive chunks, which very negatively impact overall performance. 4 is an integrated architecture that combines general problem solving abilities with a chunking mechanism that is a form of EBL <ref> [18, 26] </ref>. Second, to analyze and compare controlled chunking with the prior work (especially the one which is a strong solution) in terms of speed of the system and generality of the rules.
Reference: [19] <author> S. Markovitch and P. D. Scott. </author> <title> Information filtering : Selection mechanism in learning systems. </title> <journal> Machine Learning, </journal> <volume> 10(2) </volume> <pages> 113-151, </pages> <year> 1993. </year>
Reference-contexts: This is similar to the approach taken in Composer [11] which adds a control rule to the system only if it shows incremental utility. The incremental utility is evaluated by expected problem solving cost in a sequence of problems. The information filtering model <ref> [19] </ref> proposes a more general framework of selective learning, and defines various methods for eliminating harmful knowledge from the learning system. Selection processes, called filters, may be inserted to remove such knowledge. The filters include selective experience, selective attention, selective acquisition, selective retention, and selective utilization.
Reference: [20] <author> S. Minton. </author> <title> Quantitative results concerning the utility of explanation-based learning. </title> <booktitle> In Proceedings of the Seventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 564-569, </pages> <year> 1988. </year>
Reference-contexts: One of the ways of achieving efficiency is gradual improvement in performance by learning. For example, the explanation-based learning (EBL) systems adjust their behavior on the basis of their experience in order to reduce the amount of time to solve similar problems. However, Minton <ref> [20] </ref> has identified that in some EBL systems the cost of learned knowledge often overwhelms its benefit. This phenomenon is called the utility problem, and it has turned out to be pervasive in many learning systems which are intended to speed up the problem solving. <p> The research on this problem has focused on two key issues. The first issue is the expensive chunk problem 2 [34], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [20, 30, 7, 28, 29] </ref>. The second issue is the average growth effect [6], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> This research focuses on the expensive chunk problem in EBL a representative form of speed-up learning. The prior work in this area has taken four approaches. (The details are in section 5.) First, a system can restructure the learned rules to reduce the match cost of the rules <ref> [20] </ref>. Although this approach is useful for producing cheaper rules, it is incomplete in the sense that it cannot extract all the sources of the expensive chunk problem. Also, in the case where the transformation time is not bounded, it would become another source of utility problem. <p> This approach doesn't completely solve the expensive chunk problem either, because not all expensive chunks arise from these structures. Third, systems can evaluate the utility of learned knowledge and keep only the useful ones <ref> [20] </ref>. However, the utility evaluation of the candidate rules may become a part of the utility problem 1 Another form of learned knowledge in speed-up learning is macro-operators [9, 17], which are compositions of original operators. Macro-operator learning suffers the overhead of increasingthe branching factor of a problem solver's search. <p> A partial instantiation, also called a token, of a rule is a consistent binding of variables in a subset of the conditions. Match time per token is known to be approximately constant <ref> [33, 20] </ref>. Figure 5-(b-c) show two different unique-attribute encodings. Given an object attribute, only one value is assigned. Figure 5-(d) shows a chunk encoding conforming to Figure 5-(b). <p> Some approaches have restructured the learned rules to semantically equivalent ones to reduce the match cost of the rules. Partial evaluation in PROLEARN [25] simplifies the learned rules by exploiting domain constraints. COMPRESSOR <ref> [20] </ref> in Prodigy simplifies rules or combines multiple rules to find less expensive descriptions, by employing domain knowledge, partial evaluation, reordering, and logical equivalences.
Reference: [21] <author> S. Minton. </author> <type> Personal communication. </type> <year> 1993. </year>
Reference-contexts: When a new rule is acquired from a trace of the problem solving, often the control rules are not included in learning (i.e., in the explanation). For example, PRODIGY/EBL <ref> [21] </ref> and Soar [18, 26] two problem solvers that learn search-control rules by a variant of EBL ignore a large part of the search-control rules in learning to increase the generality of the learned rules. (The details of how they increase the generality are in section 3.) The most critical consequence <p> Search-control rules, as distinguished from task definition rules, suggest the relative worth of the proposed values. Although search-control rules affect the problem solving, they are missing in the explanation. This omission, which turns out to also be the approach taken in PRODIGY/EBL <ref> [21] </ref>, is intended to increase the generality of the learned rules while not affecting their correctness. Reducing the number of conditions by leaving out search control rules means less restriction on the test of applicability of the rules, and thus implies increased generality.
Reference: [22] <author> T. M. Mitchell, R. M. Keller, and S. T. Kedar-Cabelli. </author> <title> Explanation-based generalization a unifying view. </title> <journal> Machine Learning, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: Figure 7 shows the input and the output of EBL as specified in <ref> [22] </ref>. EBL explains (proves) why an example is an instance of a goal concept. It then extracts a sufficient condition (for an instance being an element of the concept) that satisfies the given operationality criterion. In the process of explaining, EBL constructs a structure called the explanation structure.
Reference: [23] <author> M. Pazzani and D. Kibler. </author> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning, </journal> <volume> 9(1) </volume> <pages> 57-94, </pages> <year> 1992. </year>
Reference-contexts: The term utility problem has also come to be used for a variety of other issues and phenomena such as accuracy and completeness of empirical learning systems, in which the learning intends to achieve a better classification, but not necessarily speed-up <ref> [13, 23, 14, 4] </ref>. However, this proposal concentrates upon the utility problem in speed-up learning. Many speed-up learning systems acquire new knowledge in the form of control rules 1 . The utility problem for these systems is mainly concerned with the cost of using these learned rules.
Reference: [24] <author> M. A. Perez and O. Etzioni. </author> <title> Dynamic: A new role for training examples in ebl. </title> <booktitle> In Proceedings of the Ninth International Workshop in Machine Learning, </booktitle> <pages> pages 367-372, </pages> <year> 1992. </year>
Reference-contexts: STATIC [7] employed a depth-first search for non-recursive problem space structure subgraph, and extracts control rules from the non-recursive subgraphs it find. These approaches does not utilize dynamic aspect of problem solving, and thus have potential disadvantages than EBL <ref> [24] </ref>. Although DYNAMIC [24] has provided an intermediate solution by introducing problem distribution sensitivity to STATIC, these approaches still handle limited structures in problem-space search. <p> STATIC [7] employed a depth-first search for non-recursive problem space structure subgraph, and extracts control rules from the non-recursive subgraphs it find. These approaches does not utilize dynamic aspect of problem solving, and thus have potential disadvantages than EBL <ref> [24] </ref>. Although DYNAMIC [24] has provided an intermediate solution by introducing problem distribution sensitivity to STATIC, these approaches still handle limited structures in problem-space search.
Reference: [25] <author> A. E. Prieditis and J. Mostow. Prolearn: </author> <title> Towards a prolog interpreter that learns. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <pages> pages 494-498, </pages> <year> 1987. </year>
Reference-contexts: Some approaches have restructured the learned rules to semantically equivalent ones to reduce the match cost of the rules. Partial evaluation in PROLEARN <ref> [25] </ref> simplifies the learned rules by exploiting domain constraints. COMPRESSOR [20] in Prodigy simplifies rules or combines multiple rules to find less expensive descriptions, by employing domain knowledge, partial evaluation, reordering, and logical equivalences.
Reference: [26] <author> P. S. Rosenbloom, J. E. Laird, A. Newell, and R. McCarl. </author> <title> A preliminary analysis of the soar architecture as a basis for general intelligence. </title> <journal> Artificial Intelligence, </journal> <volume> 47(1-3):289-325, </volume> <year> 1991. </year>
Reference-contexts: When a new rule is acquired from a trace of the problem solving, often the control rules are not included in learning (i.e., in the explanation). For example, PRODIGY/EBL [21] and Soar <ref> [18, 26] </ref> two problem solvers that learn search-control rules by a variant of EBL ignore a large part of the search-control rules in learning to increase the generality of the learned rules. (The details of how they increase the generality are in section 3.) The most critical consequence of this omission <p> It sometimes requires a large number of rules for the same knowledge which could be expressed by a single rule. This research pursues the following three goals. First, to flesh out the design and implement controlled chunking. I have chosen to use Soar for the implementation, where Soar <ref> [18, 26] </ref> 4 In real world situations, cpu time after learning for critical (active) period should be less than cpu time before learning. <p> For example, TacAir-Soar [32] suffers a temporary catastrophic slowdown due to expensive chunks, which very negatively impact overall performance. 4 is an integrated architecture that combines general problem solving abilities with a chunking mechanism that is a form of EBL <ref> [18, 26] </ref>. Second, to analyze and compare controlled chunking with the prior work (especially the one which is a strong solution) in terms of speed of the system and generality of the rules. <p> Although it may be difficult to completely eliminate the exponential match, some approaches may eliminate unnecessary search in the match, and provide an intermediate level solution. This proposal investigates controlled chunking in the context of Soar. Learning in Soar, called chunking, is a variant of EBL <ref> [26] </ref>, and also suffers from the expensive chunk problem [30]. Although the work is presented in terms of chunking in Soar, the approach should be applicable to most of the problem solving systems which use control rules and have EBL as a learning paradigm. <p> Because of the particular way in which learning and problem solving are integrated together in Soar, there is a small difference between these two structures. However, the mapping of EBL to chunking is close enough that it is safe to say that chunking is a form of EBL <ref> [26] </ref>. Each square represents a WME (corresponding to a fact in EBL) and each circle represents a rule. Connections between rules and WMEs represent instantiations of the rules. The chunking mechanism creates a new rule by unfolding the rule chain linked in the marked subgraph.
Reference: [27] <author> Jude W. Shavlik. </author> <title> Aquiring recursive and iterative concepts with explanation-based learning. </title> <journal> Machine Learning, </journal> <volume> 5 </volume> <pages> 39-70, </pages> <year> 1990. </year>
Reference-contexts: Also, in the case where the transformation time is not bounded, it would become another source of utility problem. Second, an approach is taken to preserve iterative or recursive search structures, which are difficult to be acquired efficiently in EBL, in the learned rules <ref> [27, 28] </ref>. This approach doesn't completely solve the expensive chunk problem either, because not all expensive chunks arise from these structures. Third, systems can evaluate the utility of learned knowledge and keep only the useful ones [20]. <p> In Shell and Carbonell's work [28], they employ iterative constructs in learned macro-operators to capture the iterative paths found during problem-space search. These iterative macro-operators are then used in a way that guarantees that they take the same path followed in the problem space. Shavlik <ref> [27] </ref> and Subramanian and Feldman [29] learn recursive and iterative concepts by generalizing the explanation structure. These approaches are close to controlled chunking in that the search paths are reflected in the learned rules.
Reference: [28] <author> P. Shell and J. Carbonell. </author> <title> Empirical and analytical performance of iterative operators. </title> <booktitle> In The 13th Annual Conference of The Cognitive Science Society, </booktitle> <pages> pages 898-902. </pages> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1991. </year> <month> 37 </month>
Reference-contexts: The research on this problem has focused on two key issues. The first issue is the expensive chunk problem 2 [34], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [20, 30, 7, 28, 29] </ref>. The second issue is the average growth effect [6], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> Also, in the case where the transformation time is not bounded, it would become another source of utility problem. Second, an approach is taken to preserve iterative or recursive search structures, which are difficult to be acquired efficiently in EBL, in the learned rules <ref> [27, 28] </ref>. This approach doesn't completely solve the expensive chunk problem either, because not all expensive chunks arise from these structures. Third, systems can evaluate the utility of learned knowledge and keep only the useful ones [20]. <p> The objective of controlled chunking is to learn cheap enough rules in the beginning, so that the system does not have to restructure them afterwards. Some other approaches have preserved the search structure in the learned knowledge. In Shell and Carbonell's work <ref> [28] </ref>, they employ iterative constructs in learned macro-operators to capture the iterative paths found during problem-space search. These iterative macro-operators are then used in a way that guarantees that they take the same path followed in the problem space.
Reference: [29] <author> D. Subramanian and R. Feldman. </author> <title> The utility of ebl in recursive domain theories. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 942-949, </pages> <year> 1990. </year>
Reference-contexts: The research on this problem has focused on two key issues. The first issue is the expensive chunk problem 2 [34], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [20, 30, 7, 28, 29] </ref>. The second issue is the average growth effect [6], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> These iterative macro-operators are then used in a way that guarantees that they take the same path followed in the problem space. Shavlik [27] and Subramanian and Feldman <ref> [29] </ref> learn recursive and iterative concepts by generalizing the explanation structure. These approaches are close to controlled chunking in that the search paths are reflected in the learned rules. These approaches also do not completely solve the expensive chunk problem because not all expensive chunks arise from these structures.
Reference: [30] <author> M. Tambe. </author> <title> Eliminating combinatorics from production match. </title> <type> PhD thesis, </type> <institution> Carnegie-Mellon University, </institution> <year> 1991. </year>
Reference-contexts: The research on this problem has focused on two key issues. The first issue is the expensive chunk problem 2 [34], in which individual learned rules are so expensive to match that the system suffers a slow down from learning <ref> [20, 30, 7, 28, 29] </ref>. The second issue is the average growth effect [6], in which the interactions across the rules slow down the system, even if none of the rules individually are all that expensive. <p> Also the system may waste a lot of energy to learn and evaluate the knowledge when a large part of the learned rules turn out to be useless. Finally, there has been a technique for restricting the expressiveness of the rules to bound the match cost of the rules <ref> [30] </ref>. However, this also has several weaknesses. The restriction reduces the expressibility of the rules, and encoding tasks by the restriction thus sometimes requires a large number of rules. Also, the learned rules may become very specific. <p> This proposal investigates controlled chunking in the context of Soar. Learning in Soar, called chunking, is a variant of EBL [26], and also suffers from the expensive chunk problem <ref> [30] </ref>. Although the work is presented in terms of chunking in Soar, the approach should be applicable to most of the problem solving systems which use control rules and have EBL as a learning paradigm. The next section reviews the strong solution, which happens to be developed in Soar. <p> Figure 5-(a) shows an unrestricted (multi-attribute 5 ) encoding. The attribute block of object S1 is not a unique attribute because it has three distinct values. Tambe <ref> [30] </ref> has shown that these multi-attribute representations often cause combinatorial match via an exponential number of partial instantiations of rules, and has proposed the unique-attribute restriction to eliminate the exponentials. <p> In particular, the encoding radically increases the number of rules used in specifying some tasks, and may also require many more rules to be learned to achieve the same level of generality as was previously attainable by a small number of rules <ref> [30] </ref>.
Reference: [31] <author> M. Tambe and A. Acharya. </author> <title> Toward optimal k-search. Talk given at the Twelfth Soar Workshop, </title> <address> Los Angeles, CA, </address> <year> 1993. </year>
Reference-contexts: At the point of instantiating the second condition, the system can ignore the bindings of variable &lt;b&gt;. &lt;b&gt; doesn't constrain later conditions (the second condition is the last condition), and nor the action. We call these variables dead variables and ignoring them while matching is called dead-variable elimination <ref> [31] </ref>. Once we know that there is any consistent binding, that is enough, and the system doesn't have to keep the actual values of the dead variables. 32 &lt;b&gt;. The number of instantiations is reduced from sixteen (Figure 26-(a)) to nine.
Reference: [32] <author> M. Tambe, R. M. Jones, J. E. Laird, and P. S. Rosenbloom. </author> <title> Building believable agents for simulation environments. </title> <editor> In J. Bates, editor, </editor> <booktitle> Working Notes of the AAAI Spring Symposium on Believable Agents, </booktitle> <address> Stanford, CA, </address> <year> 1994. </year> <note> AAAI. Accepted. </note>
Reference-contexts: First, to flesh out the design and implement controlled chunking. I have chosen to use Soar for the implementation, where Soar [18, 26] 4 In real world situations, cpu time after learning for critical (active) period should be less than cpu time before learning. For example, TacAir-Soar <ref> [32] </ref> suffers a temporary catastrophic slowdown due to expensive chunks, which very negatively impact overall performance. 4 is an integrated architecture that combines general problem solving abilities with a chunking mechanism that is a form of EBL [18, 26].
Reference: [33] <author> M. Tambe, D. Kalp, A. Gupta, C. L. Forgy, B. G. Milnes, and A. Newell. Soar/psm-e: </author> <title> Investigating match parallelism in a learning production system. </title> <booktitle> In Proceedings of the ACM/SIGPLAN Symposium on Parallel Programming: Experience with applications, languages, and systems, </booktitle> <pages> pages 146-160, </pages> <year> 1988. </year>
Reference-contexts: A partial instantiation, also called a token, of a rule is a consistent binding of variables in a subset of the conditions. Match time per token is known to be approximately constant <ref> [33, 20] </ref>. Figure 5-(b-c) show two different unique-attribute encodings. Given an object attribute, only one value is assigned. Figure 5-(d) shows a chunk encoding conforming to Figure 5-(b).
Reference: [34] <author> M. Tambe, A. Newell, and P. S. Rosenbloom. </author> <title> The problem of expensive chunks and its solution by restricting expressiveness. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 299-348, </pages> <year> 1990. </year>
Reference-contexts: The utility problem for these systems is mainly concerned with the cost of using these learned rules. The research on this problem has focused on two key issues. The first issue is the expensive chunk problem 2 <ref> [34] </ref>, in which individual learned rules are so expensive to match that the system suffers a slow down from learning [20, 30, 7, 28, 29]. <p> Consider an example from the Grid task a task known to suffer from the expensive chunk problem <ref> [34] </ref> as shown in Figure 2. Each problem in the Grid task is to find a path between two points in two dimensional space. The given problem is to go from point F to point P, a path of length four. <p> the same generality in that they describe the same grid path followed by the lookahead search to reach the desired point, and nothing more than that. 22 23 4.2 Eight-puzzle task Table 2 compares the three methods on the Eight-puzzle task (Figure 20) another task known to produce expensive chunks <ref> [34] </ref>. In the multi-attribute representation, a state points to nine bindings (using attribute ^ binding), each of which connects a cell from the static 3x3 structure of the board to a tile.
Reference: [35] <author> M. Tambe and P. S. Rosenbloom. </author> <title> On the masking effect. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 526-533, </pages> <year> 1993. </year>
Reference-contexts: This didn't occur in the previous experiments, but it could happen in other domains. The effect of unexpected alternatives during performance time will be analyzed and a solution will be provided. 10 This is also related with the masking effect <ref> [35] </ref>, where the learned knowledge masks the original-problem solving knowledge, and thus system can produce low quality solutions. 27 5 Related Work There has been a lot of work on the expensive chunk problem in EBL.
Reference: [36] <author> L. A. Taylor and R. E. Korf. </author> <title> Pruning duplicate node in depth-first search. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 756-761, </pages> <year> 1993. </year> <month> 38 </month>
Reference-contexts: There has been approaches which statically analyze search structure or problem space structure before problem solving. Taylor and Korf <ref> [36] </ref> developed a technique to detect duplicate operator sequences from a small bread-first search to control the redundancy in the problem solving. STATIC [7] employed a depth-first search for non-recursive problem space structure subgraph, and extracts control rules from the non-recursive subgraphs it find.
References-found: 36

