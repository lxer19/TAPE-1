URL: http://www.cs.umr.edu/techreports/93-19.ps
Refering-URL: http://www.cs.umr.edu/techreports/
Root-URL: 
Title: Asynchronous Parallel Schemes: A Survey  
Author: Eric Jui-Lin Lu Michael G. Hilgers Bruce McMillin 
Address: Rolla, Missouri 65401  
Affiliation: Department of Computer Science University of Missouri-Rolla  
Date: November 1993 CSC 93-19  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> D. P. Bertsekas and J. N. Tsitsiklis, </author> <title> Parallel and Distributed Computation: Numerical Methods. </title> <publisher> Prentice-Hall, Inc., </publisher> <year> 1989. </year>
Reference-contexts: The parallel algorithms of this type are called synchronous parallel algorithms. Let x i (t) be the value of x i residing in the memory of the ith processor at time t. A synchronous iterative execution of Equation (1.2), as defined in <ref> [1, 2] </ref>, can be described mathematically by the formula x i (t + 1) = f i (x 1 (t); : : : ; x n (t)); if t 2 T i x i (t); otherwise: (2.1) where t is an integer-valued variable used to index different iterations, not necessarily representing <p> As indicated in [13], the computation model is similar to the models presented by Chazan and Miranker [7], Miellou [8, 9], and Baudet [12]. This model has been further refined by Bertsekas and Tsitsiklis in <ref> [1, 2] </ref>. The asynchronous model in [1, 2] is defined as x i (t + 1) = f i (x 1 (t i n (t))); 8t 2 T i ; (6.1) where t i j (t) are times satisfying 0 t i Note that, unlike the chaotic iteration [7, 8, 9] <p> As indicated in [13], the computation model is similar to the models presented by Chazan and Miranker [7], Miellou [8, 9], and Baudet [12]. This model has been further refined by Bertsekas and Tsitsiklis in <ref> [1, 2] </ref>. The asynchronous model in [1, 2] is defined as x i (t + 1) = f i (x 1 (t i n (t))); 8t 2 T i ; (6.1) where t i j (t) are times satisfying 0 t i Note that, unlike the chaotic iteration [7, 8, 9] and the asynchronous iterative schemes [12] <p> if x x 0 , then F (x) F (x 0 ), and also F (x) x for all x; x 0 2 S n , and (b) the synchronous iteration corresponding to F and starting with x (0) ~ converges to ~. 8 Summary According to the definitions in <ref> [1, 2] </ref>, the models proposed in [7, 8, 9, 16] are partial asynchronous algorithms. On the other hand, the models proposed in [12, 15, 14, 6] are totally asynchronous algorithms. <p> Note that if A is negative, then the above proposition may be not true because (A) (jAj). Even when (A) &lt; 1, it is possible that (jAj) 1. An example can be seen in pages 435-437 <ref> [1] </ref>. 8.1 Pros and Cons From the previous discussions, we can now summarize the potential advantages that may be gained from asynchronous execution: * Reduction of the synchronization penalty. <p> This, in general, will accelerate the convergence. Though the asynchronous algorithms have several advantages over the synchronous algorithms, it has some drawbacks: * Due to the chaotic ordering, the asynchronous iteration could be divergent even if the corresponding synchronous (or sequential) iteration converges. One example can be found in <ref> [1] </ref> at page 438. 16 * The analysis of convergence, convergence rate, and stability is often difficult even if the convergence of the asynchronous iteration can be established. * An asynchronous algorithm may have converged (within a desired accuracy) but the algorithm does not terminate because no processor is aware of
Reference: [2] <author> D. P. Bertsekas and J. N. Tsitsiklis, </author> <title> "Some aspects of parallel and distributed iterative algorithms a survey," </title> <journal> Automatica, </journal> <volume> vol. 27, no. 1, </volume> <pages> pp. 3-21, </pages> <year> 1991. </year>
Reference-contexts: The parallel algorithms of this type are called synchronous parallel algorithms. Let x i (t) be the value of x i residing in the memory of the ith processor at time t. A synchronous iterative execution of Equation (1.2), as defined in <ref> [1, 2] </ref>, can be described mathematically by the formula x i (t + 1) = f i (x 1 (t); : : : ; x n (t)); if t 2 T i x i (t); otherwise: (2.1) where t is an integer-valued variable used to index different iterations, not necessarily representing <p> As indicated in [13], the computation model is similar to the models presented by Chazan and Miranker [7], Miellou [8, 9], and Baudet [12]. This model has been further refined by Bertsekas and Tsitsiklis in <ref> [1, 2] </ref>. The asynchronous model in [1, 2] is defined as x i (t + 1) = f i (x 1 (t i n (t))); 8t 2 T i ; (6.1) where t i j (t) are times satisfying 0 t i Note that, unlike the chaotic iteration [7, 8, 9] <p> As indicated in [13], the computation model is similar to the models presented by Chazan and Miranker [7], Miellou [8, 9], and Baudet [12]. This model has been further refined by Bertsekas and Tsitsiklis in <ref> [1, 2] </ref>. The asynchronous model in [1, 2] is defined as x i (t + 1) = f i (x 1 (t i n (t))); 8t 2 T i ; (6.1) where t i j (t) are times satisfying 0 t i Note that, unlike the chaotic iteration [7, 8, 9] and the asynchronous iterative schemes [12] <p> if x x 0 , then F (x) F (x 0 ), and also F (x) x for all x; x 0 2 S n , and (b) the synchronous iteration corresponding to F and starting with x (0) ~ converges to ~. 8 Summary According to the definitions in <ref> [1, 2] </ref>, the models proposed in [7, 8, 9, 16] are partial asynchronous algorithms. On the other hand, the models proposed in [12, 15, 14, 6] are totally asynchronous algorithms. <p> Bertsekas and Tsitsiklis showed that, for solving system of linear equations, partial asynchronous algorithm converges geometrically <ref> [2] </ref>. It is interesting to know the convergence rate for totally asynchronous algorithm and, if possible, how to optimize the convergence rate. There have been some works done in solving systems of non-linear equations asynchronously.
Reference: [3] <author> D. P. Bertsekas and D. A. Castanon, </author> <title> "Parallel synchronous and asynchronous implementations of the auction algorithm," </title> <journal> Parallel Computing, </journal> <volume> vol. 17, </volume> <pages> pp. 707-732, </pages> <year> 1991. </year>
Reference-contexts: The developed results have been applied to a wide variety of iterative algorithms to solve problems such as dynamic programming, shortest path problems, network flow problems, unsupervised pattern clustering, consistent labeling, and artificial neural networks <ref> [3, 4, 5, 6] </ref>. The purpose of this paper is to survey the existing asynchronous schemes and their sufficient conditions for the convergence. Although this survey is by no mean complete, it gives readers a fairly good overview of work from the past three decades.
Reference: [4] <author> E. M. Chajakis and S. A. Zenios, </author> <title> "Synchronous and asynchronous implementations of relaxation algorithms for nonlinear network optimization," </title> <journal> Parallel Computing, </journal> <volume> vol. 17, </volume> <pages> pp. 873-894, </pages> <year> 1991. </year>
Reference-contexts: The developed results have been applied to a wide variety of iterative algorithms to solve problems such as dynamic programming, shortest path problems, network flow problems, unsupervised pattern clustering, consistent labeling, and artificial neural networks <ref> [3, 4, 5, 6] </ref>. The purpose of this paper is to survey the existing asynchronous schemes and their sufficient conditions for the convergence. Although this survey is by no mean complete, it gives readers a fairly good overview of work from the past three decades.
Reference: [5] <author> P. Tseng, D. P. Bertsekas, and J. N. Tsitsiklis, </author> <title> "Partially asynchronous, parallel algorithms for network flow and other problems," </title> <journal> SIAM Journal of Control and Optimization, </journal> <volume> vol. 28, </volume> <pages> pp. 678-710, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The developed results have been applied to a wide variety of iterative algorithms to solve problems such as dynamic programming, shortest path problems, network flow problems, unsupervised pattern clustering, consistent labeling, and artificial neural networks <ref> [3, 4, 5, 6] </ref>. The purpose of this paper is to survey the existing asynchronous schemes and their sufficient conditions for the convergence. Although this survey is by no mean complete, it gives readers a fairly good overview of work from the past three decades.
Reference: [6] <author> A. Uresin and M. Dubois, </author> <title> "Parallel asynchrnous algorithms for discrete data," </title> <journal> Journal of ACM, </journal> <volume> vol. 37, </volume> <pages> pp. 588-606, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: The developed results have been applied to a wide variety of iterative algorithms to solve problems such as dynamic programming, shortest path problems, network flow problems, unsupervised pattern clustering, consistent labeling, and artificial neural networks <ref> [3, 4, 5, 6] </ref>. The purpose of this paper is to survey the existing asynchronous schemes and their sufficient conditions for the convergence. Although this survey is by no mean complete, it gives readers a fairly good overview of work from the past three decades. <p> However, many relaxation techniques involve the manipulation of symbolic or discrete-valued data. To solve the problems of discrete-valued data asynchronously, Uresin and Dubois, in 1986, proposed their generalized asynchronous scheme. In <ref> [15, 14, 6] </ref>, they showed that, if the mapping is contractive, a generalized asynchronous relaxation converges to a unique fixed point in an arbitrary 13 set, finite or infinite, countable or not. <p> On the other hand, the models proposed in <ref> [12, 15, 14, 6] </ref> are totally asynchronous algorithms. It is well known that (A) &lt; 1 is a necessary and sufficient condition for a system of linear equations, F (x) = Ax + b, to converge sequentially (or synchronously).
Reference: [7] <author> D. Chazan and W. Miranker, </author> <title> "Chaotic relaxation," </title> <journal> Linear Algebra and Its Applications, </journal> <volume> vol. 2, </volume> <pages> pp. 199-222, </pages> <year> 1969. </year>
Reference-contexts: defined on X by the formula, d (x; y) = kx yk: As proved in [10], both (R; j j) and (R n ; k k) are complete metric spaces and Banach spaces. 4 Chaotic Iteration The idea of a chaotic iteration was introduced by Chazan and Miranker in 1969 <ref> [7] </ref>. The proposed model is used to solve systems of linear equations of the form Ax = b (4.1) where A, an n fi n matrix where a i;j 2 R, is symmetric and positive definite, and x; b 2 R n . <p> (j + 1) 1 2 0 0 x 1 (2) = x 1 (1) x 2 (2) = f 2 (x 1 (0); x 2 (0)) 3 2 2 2 x 1 (4) = x 1 (3) x 2 (4) = f 2 (x 1 (2); x 2 (2)) In <ref> [7] </ref>, Chazan and Miranker showed that Theorem 4.1 Let (F; I) be a chaotic iteration scheme. The sequence of iterates x (j) generated by (F; I) converges to the solution of Equation (4.2) if and only if (jBj) &lt; 1. <p> It has been proved in part (a) that F is contracting on R n . Thus, F is contracting in x fl 2 R n for the vector norm . fl 5 Asynchronous Iterative Scheme Motivated by <ref> [7, 8, 9] </ref>, Baudet proposed an asynchronous iterative scheme [12] in 1978. <p> As indicated in [13], the computation model is similar to the models presented by Chazan and Miranker <ref> [7] </ref>, Miellou [8, 9], and Baudet [12]. This model has been further refined by Bertsekas and Tsitsiklis in [1, 2]. <p> The asynchronous model in [1, 2] is defined as x i (t + 1) = f i (x 1 (t i n (t))); 8t 2 T i ; (6.1) where t i j (t) are times satisfying 0 t i Note that, unlike the chaotic iteration <ref> [7, 8, 9] </ref> and the asynchronous iterative schemes [12] which all processors have the same set of ft j (t)g for j 2 f1; : : : ; ng, the asynchronous model allows each processor i has its own set of ft i j (t)g. <p> F (x) F (x 0 ), and also F (x) x for all x; x 0 2 S n , and (b) the synchronous iteration corresponding to F and starting with x (0) ~ converges to ~. 8 Summary According to the definitions in [1, 2], the models proposed in <ref> [7, 8, 9, 16] </ref> are partial asynchronous algorithms. On the other hand, the models proposed in [12, 15, 14, 6] are totally asynchronous algorithms.
Reference: [8] <author> J. C. Miellou, </author> <title> "Iterations chaotiques a retards, etudes de la convergence dans le cas d'espaces partiellement or donnes," </title> <booktitle> CRAS, serie A t.278, </booktitle> <pages> pp. 957-960, </pages> <year> 1974. </year>
Reference-contexts: The chaotic iteration with ! is denoted as (F ! ; I). Theorem 4.2 The scheme (F ! ; I) converges for all I on assumptions of Definition 4.1 when (jBj) &lt; 1, and 0 &lt; ! &lt; 2=(1 + (jBj)). In <ref> [8, 9] </ref>, Miellou extended the chaotic iteration scheme. The extensions include (1) more than one component of x (j) can be updated at each instant of j, and (2) the operator F can be non-linear. <p> It has been proved in part (a) that F is contracting on R n . Thus, F is contracting in x fl 2 R n for the vector norm . fl 5 Asynchronous Iterative Scheme Motivated by <ref> [7, 8, 9] </ref>, Baudet proposed an asynchronous iterative scheme [12] in 1978. <p> As indicated in [13], the computation model is similar to the models presented by Chazan and Miranker [7], Miellou <ref> [8, 9] </ref>, and Baudet [12]. This model has been further refined by Bertsekas and Tsitsiklis in [1, 2]. <p> The asynchronous model in [1, 2] is defined as x i (t + 1) = f i (x 1 (t i n (t))); 8t 2 T i ; (6.1) where t i j (t) are times satisfying 0 t i Note that, unlike the chaotic iteration <ref> [7, 8, 9] </ref> and the asynchronous iterative schemes [12] which all processors have the same set of ft j (t)g for j 2 f1; : : : ; ng, the asynchronous model allows each processor i has its own set of ft i j (t)g. <p> F (x) F (x 0 ), and also F (x) x for all x; x 0 2 S n , and (b) the synchronous iteration corresponding to F and starting with x (0) ~ converges to ~. 8 Summary According to the definitions in [1, 2], the models proposed in <ref> [7, 8, 9, 16] </ref> are partial asynchronous algorithms. On the other hand, the models proposed in [12, 15, 14, 6] are totally asynchronous algorithms.
Reference: [9] <author> J. C. Miellou, </author> <title> "Algorithmes de relaxation chaotique a retards," </title> <booktitle> RAIRO-R1, </booktitle> <pages> pp. 55-82, </pages> <year> 1975. </year>
Reference-contexts: The chaotic iteration with ! is denoted as (F ! ; I). Theorem 4.2 The scheme (F ! ; I) converges for all I on assumptions of Definition 4.1 when (jBj) &lt; 1, and 0 &lt; ! &lt; 2=(1 + (jBj)). In <ref> [8, 9] </ref>, Miellou extended the chaotic iteration scheme. The extensions include (1) more than one component of x (j) can be updated at each instant of j, and (2) the operator F can be non-linear. <p> Let x; y 2 R n . Then, (F (x)F (y)) = jB (xy)j jBjjxyj = jBj (xy); 8x; y 2 R n : Since jBj is non-negative and (jBj) &lt; 1, then, see <ref> [9] </ref>, kF (x) F (y)k ! 1 ffkx yk ! 1 where ff &lt; 1. Let d (x; y) = kx yk ! 1 . By Banach's fixed point theorem, F has a unique fixed point x fl 2 R n . <p> It has been proved in part (a) that F is contracting on R n . Thus, F is contracting in x fl 2 R n for the vector norm . fl 5 Asynchronous Iterative Scheme Motivated by <ref> [7, 8, 9] </ref>, Baudet proposed an asynchronous iterative scheme [12] in 1978. <p> As indicated in [13], the computation model is similar to the models presented by Chazan and Miranker [7], Miellou <ref> [8, 9] </ref>, and Baudet [12]. This model has been further refined by Bertsekas and Tsitsiklis in [1, 2]. <p> The asynchronous model in [1, 2] is defined as x i (t + 1) = f i (x 1 (t i n (t))); 8t 2 T i ; (6.1) where t i j (t) are times satisfying 0 t i Note that, unlike the chaotic iteration <ref> [7, 8, 9] </ref> and the asynchronous iterative schemes [12] which all processors have the same set of ft j (t)g for j 2 f1; : : : ; ng, the asynchronous model allows each processor i has its own set of ft i j (t)g. <p> F (x) F (x 0 ), and also F (x) x for all x; x 0 2 S n , and (b) the synchronous iteration corresponding to F and starting with x (0) ~ converges to ~. 8 Summary According to the definitions in [1, 2], the models proposed in <ref> [7, 8, 9, 16] </ref> are partial asynchronous algorithms. On the other hand, the models proposed in [12, 15, 14, 6] are totally asynchronous algorithms. <p> However, is it possible that asynchronous algorithm converges slower than synchronous one? Also, in the synchronous algorithm shown in Figure 6, will asynchronous algorithm run at least as fast as synchronous one? Miellou obtained the asymptotic rate of convergence for the chaotic iterative scheme <ref> [9] </ref>. Bertsekas and Tsitsiklis showed that, for solving system of linear equations, partial asynchronous algorithm converges geometrically [2]. It is interesting to know the convergence rate for totally asynchronous algorithm and, if possible, how to optimize the convergence rate.
Reference: [10] <author> F. H. Croom, </author> <title> Principles of Topology. </title> <publisher> Saunders College Publishing, </publisher> <year> 1989. </year>
Reference-contexts: has a unique fixed point in X. 4 Definition 3.4 A normed space X with the norm k k is called a Banach space if X is a complete metric space for the metric d defined on X by the formula, d (x; y) = kx yk: As proved in <ref> [10] </ref>, both (R; j j) and (R n ; k k) are complete metric spaces and Banach spaces. 4 Chaotic Iteration The idea of a chaotic iteration was introduced by Chazan and Miranker in 1969 [7]. <p> unique fixed point x fl . (b) F is contracting in x fl for the vector norm . [Proof:] Since (R n ; k k ! 1 ), where kxk ! i=1;::: ;n x i j; ! i &gt; 0 is a weighted maximum norm, is a complete metric space <ref> [10] </ref>, it is sufficient to show that F is contracting on R n with respect to k k ! 1 to prove (a). Let x; y 2 R n .
Reference: [11] <author> R. L. Burden and J. D. Faires, </author> <title> Numerical Analysis. </title> <publisher> PWS-KENT Publishing Company, </publisher> <editor> fourth ed., </editor> <year> 1989. </year> <month> 22 </month>
Reference: [12] <author> G. M. Baudet, </author> <title> "Asynchronous iterative methods for multiprocessors," </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> vol. 25, </volume> <pages> pp. 226-244, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: It has been proved in part (a) that F is contracting on R n . Thus, F is contracting in x fl 2 R n for the vector norm . fl 5 Asynchronous Iterative Scheme Motivated by [7, 8, 9], Baudet proposed an asynchronous iterative scheme <ref> [12] </ref> in 1978. Unlike the chaotic iteration scheme which does not allow use of the values which was produced by an update s or more step earlier, the asyn chronous iterative scheme has no restriction on the choice of the antecedent values used in the evaluation of an iterate. <p> As indicated in [13], the computation model is similar to the models presented by Chazan and Miranker [7], Miellou [8, 9], and Baudet <ref> [12] </ref>. This model has been further refined by Bertsekas and Tsitsiklis in [1, 2]. <p> [1, 2] is defined as x i (t + 1) = f i (x 1 (t i n (t))); 8t 2 T i ; (6.1) where t i j (t) are times satisfying 0 t i Note that, unlike the chaotic iteration [7, 8, 9] and the asynchronous iterative schemes <ref> [12] </ref> which all processors have the same set of ft j (t)g for j 2 f1; : : : ; ng, the asynchronous model allows each processor i has its own set of ft i j (t)g. <p> On the other hand, the models proposed in <ref> [12, 15, 14, 6] </ref> are totally asynchronous algorithms. It is well known that (A) &lt; 1 is a necessary and sufficient condition for a system of linear equations, F (x) = Ax + b, to converge sequentially (or synchronously).
Reference: [13] <author> D. P. Bertsekas, </author> <title> "Distributed asynchronous computation of fixed points," </title> <journal> Mathematical Programming, </journal> <volume> vol. 27, </volume> <pages> pp. 107-120, </pages> <year> 1983. </year>
Reference-contexts: Thus, the condition required for Equation (5.1) to converge is stronger than the one required by Miellou's model. 6 Asynchronous Fixed Point Algorithms In 1983, Bertsekas proposed an algorithmic model for distributed computation of fixed points. As indicated in <ref> [13] </ref>, the computation model is similar to the models presented by Chazan and Miranker [7], Miellou [8, 9], and Baudet [12]. This model has been further refined by Bertsekas and Tsitsiklis in [1, 2].
Reference: [14] <author> A. Uresin and M. Dubois, </author> <title> "Sufficient conditions for the convergence of asynchronous iterations," </title> <journal> Parallel Computing, </journal> <volume> vol. 10, </volume> <pages> pp. 83-92, </pages> <year> 1989. </year>
Reference-contexts: The key idea behind Theorem 6.1 is that eventually x (t) enters and stays in the set X (k); furthermore, it eventually moves into the next set X (k + 1). But will the following situation, as illustrated in <ref> [14] </ref>, happen? [Example] Suppose that D is defined by the following inequali ties in R 2 : 0 x 1 2; 0 x 2 x 1 ; and let the value of the function at the point (2; 2) be (1; 1), i.e., F (2; 2) = (1; 1): If the <p> However, many relaxation techniques involve the manipulation of symbolic or discrete-valued data. To solve the problems of discrete-valued data asynchronously, Uresin and Dubois, in 1986, proposed their generalized asynchronous scheme. In <ref> [15, 14, 6] </ref>, they showed that, if the mapping is contractive, a generalized asynchronous relaxation converges to a unique fixed point in an arbitrary 13 set, finite or infinite, countable or not. <p> On the other hand, the models proposed in <ref> [12, 15, 14, 6] </ref> are totally asynchronous algorithms. It is well known that (A) &lt; 1 is a necessary and sufficient condition for a system of linear equations, F (x) = Ax + b, to converge sequentially (or synchronously).
Reference: [15] <author> A. Uresin and M. Dubois, </author> <title> "Generalized asynchronous iterations," </title> <booktitle> in Proceedings of the Conference on Algorithms and Hardware for Parallel Processing, </booktitle> <pages> pp. 272-278, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: However, many relaxation techniques involve the manipulation of symbolic or discrete-valued data. To solve the problems of discrete-valued data asynchronously, Uresin and Dubois, in 1986, proposed their generalized asynchronous scheme. In <ref> [15, 14, 6] </ref>, they showed that, if the mapping is contractive, a generalized asynchronous relaxation converges to a unique fixed point in an arbitrary 13 set, finite or infinite, countable or not. <p> On the other hand, the models proposed in <ref> [12, 15, 14, 6] </ref> are totally asynchronous algorithms. It is well known that (A) &lt; 1 is a necessary and sufficient condition for a system of linear equations, F (x) = Ax + b, to converge sequentially (or synchronously).
Reference: [16] <author> D. Mitra, </author> <title> "Asynchronous relaxations for the numerical solution of differential equations by parallel processors," </title> <journal> SIAM Journal on Scientific and Statistical Computing, </journal> <volume> vol. 8, </volume> <pages> pp. </pages> <address> s43-s58, </address> <month> January </month> <year> 1987. </year>
Reference-contexts: F (x) F (x 0 ), and also F (x) x for all x; x 0 2 S n , and (b) the synchronous iteration corresponding to F and starting with x (0) ~ converges to ~. 8 Summary According to the definitions in [1, 2], the models proposed in <ref> [7, 8, 9, 16] </ref> are partial asynchronous algorithms. On the other hand, the models proposed in [12, 15, 14, 6] are totally asynchronous algorithms.
Reference: [17] <author> F. Mattern, </author> <title> "Virtual tiem and global states of distributed systems," </title> <booktitle> in Procedings of International Workshop on Parallel and Distributed Algorithms, </booktitle> <pages> pp. 215-226, </pages> <month> Oct. </month> <year> 1988. </year>
Reference-contexts: This may break the assumptions made for partial asynchronous algorithms. Though the stated situation may be solved by employing vector clock and rollback <ref> [17, 18] </ref>, the overhead is too huge to make asynchronous parallel algorithms be attractive. * Processors may converge to some point which is not the solution. For example, to solve Equation (8.1), assume the initial value is x (0) = (1; 2).
Reference: [18] <author> C. Fidge, </author> <title> "Logical time in distributed computing systems," </title> <booktitle> Computer, </booktitle> <pages> pp. 28-33, </pages> <month> Aug. </month> <year> 1991. </year> <month> 23 </month>
Reference-contexts: This may break the assumptions made for partial asynchronous algorithms. Though the stated situation may be solved by employing vector clock and rollback <ref> [17, 18] </ref>, the overhead is too huge to make asynchronous parallel algorithms be attractive. * Processors may converge to some point which is not the solution. For example, to solve Equation (8.1), assume the initial value is x (0) = (1; 2).
References-found: 18

