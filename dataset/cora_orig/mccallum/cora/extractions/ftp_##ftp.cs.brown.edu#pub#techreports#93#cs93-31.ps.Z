URL: ftp://ftp.cs.brown.edu/pub/techreports/93/cs93-31.ps.Z
Refering-URL: http://www.cs.brown.edu/publications/techreports/reports/CS-93-31.html
Root-URL: http://www.cs.brown.edu/
Abstract-found: 0
Intro-found: 1
Reference: [ Andreassen et al., 1991 ] <author> Andreassen, S.A.; Benn, J.J.; Hovorks, R.; Olesen, K. G.; and Carson, R. </author> <title> E 1991. A probabilistic approach to glucose prediction and insulin dose adjustment: Description of metabolic model and pilot evaluation study. </title> <type> Unpublished draft. </type>
Reference: [ Breese, 1989 ] <author> Breese, J.S. </author> <year> 1989. </year> <title> Construction of belief and decision networks. </title> <type> Technical Memorandum 30, </type> <institution> Rockwell Palo Alto Laboratory, 444 High Street, </institution> <address> Palo Alto, California 94301. </address>
Reference-contexts: These approaches involved determining the network structure, supplying prior and conditional probabilities, adding or retracting evidence and repeating the inference algorithm for each change in the evidence. The complexity and size of networks for domains such as Natural Language Understanding motivated work on the dynamic construction of belief networks <ref> [ Breese, 1989, Charniak and Goldman, 1989 ] </ref> .
Reference: [ Charniak and Goldman, 1989 ] <author> Charniak, Eugene and Goldman, Robert 1989. </author> <title> Plan recognition in stories and in life. </title> <booktitle> In Proc. of the Fifth Workshop on Uncertainty in Artificial Intelligence. </booktitle> <pages> 54-60. </pages>
Reference-contexts: These approaches involved determining the network structure, supplying prior and conditional probabilities, adding or retracting evidence and repeating the inference algorithm for each change in the evidence. The complexity and size of networks for domains such as Natural Language Understanding motivated work on the dynamic construction of belief networks <ref> [ Breese, 1989, Charniak and Goldman, 1989 ] </ref> .
Reference: [ Cooper, 1990 ] <author> Cooper, </author> <title> G.F. 1990. The computational complexity of probabilistic inference using bayesian belief networks. </title> <booktitle> Artificial Intelligence 42 </booktitle> <pages> 393-405. </pages>
Reference-contexts: Fig. 1.1. Generic Structure for a typical Dynamic Belief Network. In general, the complexity of inference for highly multiply-connected networks is NP-hard <ref> [ Cooper, 1990 ] </ref> . Cooper [ Cooper, 1990 ] suggests that the complexity problem should be tackled by designing efficient special-case, average-case and approximation algorithms, rather than searching for a general, efficient exact inference algorithm. <p> Fig. 1.1. Generic Structure for a typical Dynamic Belief Network. In general, the complexity of inference for highly multiply-connected networks is NP-hard <ref> [ Cooper, 1990 ] </ref> . Cooper [ Cooper, 1990 ] suggests that the complexity problem should be tackled by designing efficient special-case, average-case and approximation algorithms, rather than searching for a general, efficient exact inference algorithm.
Reference: [ Dagum et al., 1992 ] <author> Dagum, P.; Galper, A.; and Horvitz, E. </author> <year> 1992. </year> <title> Dynamic network models for forecasting. </title> <booktitle> In Proceedings of the 8th Conference on Uncertainty in Artificial Intelligence. </booktitle>
Reference: [ Dean and Kanazawa, 1989 ] <author> Dean, Thomas and Kanazawa, </author> <title> Keiji 1989. A model for reasoning about persistence and causation. </title> <booktitle> Computational Intelligence 5 </booktitle> <pages> 142-150. </pages>
Reference-contexts: The complexity and size of networks for domains such as Natural Language Understanding motivated work on the dynamic construction of belief networks [ Breese, 1989, Charniak and Goldman, 1989 ] . More recently, Dynamic Belief Networks (DBNs) (also called Temporal Probabilistic Networks <ref> [ Dean and Kanazawa, 1989, Dean et al., 1990 ] </ref> , and Dynamic Causal Probabilistic Networks [ Kjrulff, 1992 ] ) have been of interest as modelling tools for environments that change over time [ Kjrulff, 1992, Dagum et al., 1992, Dean and Wellman, 1991, Andreassen et al., 1991, Nicholson, 1992
Reference: [ Dean and Wellman, 1991 ] <author> Dean, Thomas and Wellman, Michael P. </author> <year> 1991. </year> <title> Planning and control. </title> <publisher> Morgan Kaufman Publishers, </publisher> <address> San Mateo, Ca. </address>
Reference-contexts: There is no p-time 3 3 Pruning Pruning decisions follow from the topological structure, and the current belief and assumptions of the network. Therefore pruning can be implemented by domain independent meta-reasoning, which result in the reproduction of domain specific methods such as those by Dean et al. <ref> [ Dean and Wellman, 1991, pp.330-334 ] </ref> among others. The aim of pruning is to reduce the state space of the network, and, in particular, to reduce the complexity of the inference algorithm, by getting rid of redundant or irrelevant information about the world. <p> This method of node removal is very general; both Kjrulff's model reduction [ Kjrulff, 1992 ] and the network reduction described in <ref> [ Dean and Wellman, 1991 ] </ref> , based on work by Shachter [ Shachter, 1986 ] , fall within the same framework. Example of exact pruning Our experimental domain is that of robot vehicle monitoring.
Reference: [ Dean et al., 1990 ] <author> Dean, Thomas; Kanazawa, Keiji; and Shewchuk, </author> <title> John 1990. Prediction, observation, and estimation in planning and control. </title> <booktitle> In Proceedings of the Fifth IEEE International Symposium on Intelligent Control. </booktitle> <pages> 645-650. </pages>
Reference-contexts: The complexity and size of networks for domains such as Natural Language Understanding motivated work on the dynamic construction of belief networks [ Breese, 1989, Charniak and Goldman, 1989 ] . More recently, Dynamic Belief Networks (DBNs) (also called Temporal Probabilistic Networks <ref> [ Dean and Kanazawa, 1989, Dean et al., 1990 ] </ref> , and Dynamic Causal Probabilistic Networks [ Kjrulff, 1992 ] ) have been of interest as modelling tools for environments that change over time [ Kjrulff, 1992, Dagum et al., 1992, Dean and Wellman, 1991, Andreassen et al., 1991, Nicholson, 1992
Reference: [ Henrion, 1988 ] <author> Henrion, M. </author> <year> 1988. </year> <title> Propagating uncertainty in bayesian networks by logic sampling. </title> <editor> In Lemmer, J. and Kanal, L., editors 1988, </editor> <booktitle> Uncertainty in Artificial Intelligence Vol 2. </booktitle> <publisher> North Holland, Amsterdam. </publisher> <pages> 149-163. 11 </pages>
Reference: [ Horvitz et al., 1989 ] <author> Horvitz, E.J.; Suermondt, H.J.; and Cooper, </author> <title> G.F. 1989. Bounded conditioning: Flex--ible inference for decisions under scarce resources. </title> <booktitle> In Proc. of the Fifth Workshop on Uncertainty in Artificial Intelligence. </booktitle> <pages> 182-193. </pages>
Reference: [ Kanazawa, 1992 ] <author> Kanazawa, </author> <title> Keiji 1992. Probability, Time, and Action. </title> <type> Ph.D. Dissertation, </type> <institution> Brown University, Providence, RI. </institution>
Reference-contexts: Kanazawa <ref> [ Kanazawa, 1992 ] </ref> proposed the following join-tree cost to assess the computational expense of evaluating a probabilistic network. <p> Fig. 2.1. Run time for (a) creating the join-tree, (b) join-tree inference, vs. Join-tree Cost. The plots for the join-tree cost show a nearly linear relationship between run time and join-tree cost. This is empirical support of Kanazawa's theoretical result <ref> [ Kanazawa, 1992 ] </ref> , that the join-tree cost is a good measure of the cost of running the Jensen inference algorithm.
Reference: [ Kjrulff, 1990 ] <author> Kjrulff, U. </author> <year> 1990. </year> <title> Graph triangulation | algorithms giving small total state space. </title> <type> Technical Report R 90-09, </type> <institution> University of Aalborg, Denmark. </institution>
Reference-contexts: Kjrulff <ref> [ Kjrulff, 1990 ] </ref> uses a process based on simulated annealing to choose the order in which to eliminate nodes.
Reference: [ Kjrulff, 1992 ] <author> Kjrulff, U. </author> <year> 1992. </year> <title> A computational scheme for reasoning in dynamic probabilistic networks. </title> <booktitle> In Proceedings of the 8th Conference on Uncertainty in Artificial Intelligence. </booktitle>
Reference-contexts: More recently, Dynamic Belief Networks (DBNs) (also called Temporal Probabilistic Networks [ Dean and Kanazawa, 1989, Dean et al., 1990 ] , and Dynamic Causal Probabilistic Networks <ref> [ Kjrulff, 1992 ] </ref> ) have been of interest as modelling tools for environments that change over time [ Kjrulff, 1992, Dagum et al., 1992, Dean and Wellman, 1991, Andreassen et al., 1991, Nicholson, 1992 ] . <p> This method of node removal is very general; both Kjrulff's model reduction <ref> [ Kjrulff, 1992 ] </ref> and the network reduction described in [ Dean and Wellman, 1991 ] , based on work by Shachter [ Shachter, 1986 ] , fall within the same framework. Example of exact pruning Our experimental domain is that of robot vehicle monitoring.
Reference: [ Levitt et al., 1989 ] <author> Levitt, T.S.; Agosta, J. M.; and Binford, </author> <title> T.O. 1989. Model-based influence diagrams for machine vision. </title> <booktitle> In Proc. of the Fifth Workshop on Uncertainty in Artificial Intelligence. </booktitle> <pages> 233-244. </pages>
Reference-contexts: 1 Introduction Belief Networks [ Pearl, 1988 ] , which integrate a mechanism for inference under uncertainty with a secure Bayesian foundation, were initially applied to fairly static domains, where the nodes and arcs do not change over time <ref> [ Spiegelhalter et al., 1989, Levitt et al., 1989 ] </ref> . These approaches involved determining the network structure, supplying prior and conditional probabilities, adding or retracting evidence and repeating the inference algorithm for each change in the evidence.
Reference: [ Nicholson and Brady, 1992a ] <author> Nicholson, A. E. and Brady, J. M. </author> <year> 1992a. </year> <title> The data association problem when monitoring robot vehicles using dynamic belief networks. </title> <booktitle> In Proc. of the 10th European Conf. on Artificial Intelligence (ECAI-92). </booktitle>
Reference: [ Nicholson and Brady, 1992b ] <author> Nicholson, A. E. and Brady, J. M. </author> <year> 1992b. </year> <title> Sensor validation using dynamic belief networks. </title> <booktitle> In Proceedings of the 8th Conference on Uncertainty in Artificial Intelligence. </booktitle>
Reference-contexts: If the network internally models uncertainty about the data, the network will not necessarily infer a contradiction. For example, in our monitoring domain, the DBN infers that a sensor is defective and this is in fact used for sensor validation <ref> [ Nicholson and Brady, 1992b ] </ref> . We therefore require a measure of the likelihood of new evidence. For the monitoring domain, we want to capture the intuition that it is more likely an earlier assumption was incorrect than that all the sensors are malfunctioning.
Reference: [ Nicholson, 1992 ] <author> Nicholson, A. E. </author> <year> 1992. </year> <title> Monitoring Discrete Environments using Dynamic Belief Networks. </title> <type> Ph.D. Dissertation, </type> <institution> Dept. of Engineering Sciences, Oxford University. </institution>
Reference-contexts: In Section 3 we describe a simplified version of the network which is sufficient to provide illustrative examples; the experimental results were obtained using the complete and considerably more complex network model described in detail in <ref> [ Nicholson, 1992 ] </ref> . The network structure for our domain, which is typical of many dynamic applications, is highly multiply connected. This means that the standard, comparatively efficient inference algorithms for poly-trees are not applicable; intuitively, special techniques must be used to ensure that evidence is not counted twice. <p> shows the join-tree cost plotted against the run time for creating the join-tree and the run time for inference on the join tree respectively; these graphs use about 700 data points from running the Jensen inference algorithm on different combinations of structures, extension to the model, and domain parameters (see <ref> [ Nicholson, 1992 ] </ref> for details). The results obtained were limited by the available computing resources. There is the usual trade-off between space and time; the Jensen algorithm runs comparatively quickly, but it takes up a lot of space. <p> In <ref> [ Nicholson, 1992 ] </ref> a detailed analysis of the network complexity for alternative network structures is described in terms of the domain parameters. In general the complexity for all the alternative structures is exponential both in the number of objects being monitored, and the number of regions. <p> We therefore require a measure of the likelihood of new evidence. For the monitoring domain, we want to capture the intuition that it is more likely an earlier assumption was incorrect than that all the sensors are malfunctioning. In <ref> [ Nicholson, 1992 ] </ref> a method is described for determining the difference between predicted and observed beliefs within the network. However, the real problem with this method is that the prediction is based on the assumption set. <p> We require some measure of the probability that the observations would have occurred without setting the assumptions. This remains an open research question. General dynamic network construction algorithm We can now outline a general dynamic network construction algorithm, an updated version of that given in <ref> [ Nicholson, 1992 ] </ref> , currently unimplemented, which includes both using thresholds for making assumptions, and pruning. 1. Expand DBN 2. Add data evidence 3. Run inference algorithm 4.
Reference: [ Pearl, 1988 ] <author> Pearl, </author> <title> Judea 1988. Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, Ca. </address>
Reference-contexts: 1 Introduction Belief Networks <ref> [ Pearl, 1988 ] </ref> , which integrate a mechanism for inference under uncertainty with a secure Bayesian foundation, were initially applied to fairly static domains, where the nodes and arcs do not change over time [ Spiegelhalter et al., 1989, Levitt et al., 1989 ] . <p> This means that the standard, comparatively efficient inference algorithms for poly-trees are not applicable; intuitively, special techniques must be used to ensure that evidence is not counted twice. Various exact inference algorithms for this have been described, which fall broadly into two classes: conditioning and clustering <ref> [ Pearl, 1988 ] </ref> .
Reference: [ Shachter and Peot, 1989 ] <author> Shachter, R. and Peot, M. </author> <year> 1989. </year> <title> Simulation approaches to general probabilistic inference on belief networks. </title> <booktitle> In Proc. of the Fifth Workshop on Uncertainty in Artificial Intelligence. </booktitle> <pages> 311-318. </pages>
Reference: [ Shachter, 1986 ] <author> Shachter, R.D. </author> <year> 1986. </year> <title> Evaluating influence diagrams. </title> <journal> Operations Research 34 </journal> <pages> 871-882. </pages>
Reference-contexts: This method of node removal is very general; both Kjrulff's model reduction [ Kjrulff, 1992 ] and the network reduction described in [ Dean and Wellman, 1991 ] , based on work by Shachter <ref> [ Shachter, 1986 ] </ref> , fall within the same framework. Example of exact pruning Our experimental domain is that of robot vehicle monitoring. The environment (a laboratory in which a robot vehicle roams) is divided into regions by the light beam sensors.
Reference: [ Shwe and Cooper, 1990 ] <author> Shwe, M. and Cooper, G. </author> <year> 1990. </year> <title> An empirical analysis of likelihood-weighting simulation on a large, multiply connected belief network. </title> <booktitle> In Proceedings of the Sixth Workshop on Uncertainty in Artificial Intelligence. </booktitle> <pages> 498-508. </pages>
Reference: [ Spiegelhalter et al., 1989 ] <author> Spiegelhalter, D.; Franklin, R.; and Bull, K. </author> <year> 1989. </year> <title> Assessment criticism and improvement of imprecise subject probabilities for a medical expert system. </title> <booktitle> In Proc. of the Fifth Workshop on Uncertainty in Artificial Intelligence. </booktitle> <pages> 335-342. </pages>
Reference-contexts: 1 Introduction Belief Networks [ Pearl, 1988 ] , which integrate a mechanism for inference under uncertainty with a secure Bayesian foundation, were initially applied to fairly static domains, where the nodes and arcs do not change over time <ref> [ Spiegelhalter et al., 1989, Levitt et al., 1989 ] </ref> . These approaches involved determining the network structure, supplying prior and conditional probabilities, adding or retracting evidence and repeating the inference algorithm for each change in the evidence.
Reference: [ Srinivas and Breese, 1989 ] <author> Srinivas, Sampath and Breese, </author> <title> Jack 1989. Ideal: Influence diagram evaluation and analysis in lisp. </title> <type> Technical Report Technical Memorandum No. 23, </type> <institution> Rockwell International Science Center. </institution> <month> 12 </month>
Reference-contexts: Various exact inference algorithms for this have been described, which fall broadly into two classes: conditioning and clustering [ Pearl, 1988 ] . Our experimental results were obtained with an implementation of the DBN using the Jensen version of the Laurtizen-Spiegelhalter clustering algorithm provided by the IDEAL <ref> [ Srinivas and Breese, 1989 ] </ref> , currently the best algorithm available. 1 As further motivation for the techniques we will present for reducing DBN inference complexity, we consider in more detail the performance of this algorithm for our domain.
References-found: 23

