URL: http://www.cs.umn.edu/Users/dept/users/kumar/conc_heap.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/kumar/
Root-URL: http://www.cs.umn.edu
Title: Concurrent Access of Priority Queues  
Author: V. Nageshwara Rao and Vipin Kumar 
Keyword: Index Terms: concurrent data structures, priority queues, insertions, deletions, branch-and-bound, speedup.  
Address: Austin, Texas 78712  
Affiliation: Department of Computer Sciences, University of Texas at Austin,  
Abstract: The heap is an important data structure used as a priority queue in a wide variety of parallel algorithms (e.g., multiprocessor scheduling, branch-and-bound). In these algorithms, contention for the shared heap limits the obtainable speedup. This paper presents an approach to allow concurrent insertions and deletions on the heap in a shared-memory multiprocessor. The scheme also retains the strict priority ordering of the serial-access heap algorithms; i.e., a delete operation returns the best key of all keys that have been inserted or are being inserted at the time delete is started. Our experimental results on the BBN Butterfly parallel processor demonstrate that the use of the concurrent-heap algorithms in parallel branch-and-bound improves its performance substantially. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, John E. Hopcroft, and J. D. Ullman. </author> <title> The Design and Analysis of Computer Algorithms. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1974. </year>
Reference-contexts: Section 6 discusses ways to improve the basic scheme to further reduce the overheads. A comparison with related work is presented in Section 7. Section 8 contains concluding remarks. 2 Serial Access Heap algorithms 2.1 Preliminaries A heap <ref> [1, 7] </ref> is a complete binary tree of depth d, with the property that the value of the key at any node is less than the value of the keys at its children (if they exist). 1 Before presenting the concurrent update scheme, we briefly describe the sequential implementation of the
Reference: [2] <author> M. J. Atallah and S. R. Kosaraju. </author> <title> A generalized dictionary machine for VLSI. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34, No. 2 </volume> <pages> 151-155, </pages> <year> 1985. </year>
Reference-contexts: Since our concurrent-access heap scheme has the same degree of concurrency as others and has smaller overhead, it is better than other concurrent schemes for manipulating a strict priority queue. A number of VLSI dictionary machines <ref> [?, 19, 2] </ref> use O (M ) processors and allow O (log M ) operations to proceed in parallel. Leiserson's hardware priority queue [10] provides O (1) access time at the expense of O (M ) processors.
Reference: [3] <author> Jit Biswas and James C. Browne. </author> <title> Simultaneous update of priority structures. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 124-131, </pages> <year> 1987. </year>
Reference-contexts: In the ordinary serial heap algorithms, deletes manipulate the heap level by level going from top to bottom, while inserts manipulate it from bottom to top. Hence many deletions (or many insertions) can be executed in parallel by using a simple window locking scheme <ref> [3] </ref> or software pipelining [13, 14]. But inserts and deletes cannot be active together, as they proceed in opposite directions and hence can deadlock. Biswas and Browne [3] present a scheme to handle this problem. <p> Hence many deletions (or many insertions) can be executed in parallel by using a simple window locking scheme <ref> [3] </ref> or software pipelining [13, 14]. But inserts and deletes cannot be active together, as they proceed in opposite directions and hence can deadlock. Biswas and Browne [3] present a scheme to handle this problem. But their scheme incurs substantial overhead, and performs worse than the serial-access heap unless the heap size M is very large. <p> We can associate two different locks for these two steps. 7 Related Research In <ref> [3] </ref>, Biswas and Browne present a scheme, called CHEAP, that allows insertions and deletions to proceed in parallel. In their scheme, an insert or delete operation is decomposed into a sequence of update steps at different levels of a heap. <p> This approach is not able to perform better than the serial access scheme except for very large heaps due to the overheads associated with scheduling window updates through the server queue. Unlike the scheme in <ref> [3] </ref>, our scheme does not require special server processors to update the heap. Also the number of locks needed for each operation are much smaller in our scheme.
Reference: [4] <author> William J. Dally. </author> <title> A VLSI Architecture for Concurrent Data Structures. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston, MA, </address> <year> 1987. </year>
Reference-contexts: Performance results of this scheme are not yet available. A number of concurrent-access schemes have been developed for manipulating dictionaries that are represented as balanced trees [6, 11], B-trees [5], and the balanced cube <ref> [4] </ref>. Most of these concurrent schemes allow O (log M ) operations (delete the smallest key, delete a key, insert a key, search for key, etc.) to be done simultaneously. A major exception is the balanced cube which permits O (M ) search, insert and delete operations to done concurrently.
Reference: [5] <author> Carla S. Ellis. </author> <title> Concurrent search and insertion in 2-3 trees. </title> <journal> Acta Informatica, </journal> <volume> 14 </volume> <pages> 63-86, </pages> <year> 1980. </year>
Reference-contexts: Performance results of this scheme are not yet available. A number of concurrent-access schemes have been developed for manipulating dictionaries that are represented as balanced trees [6, 11], B-trees <ref> [5] </ref>, and the balanced cube [4]. Most of these concurrent schemes allow O (log M ) operations (delete the smallest key, delete a key, insert a key, search for key, etc.) to be done simultaneously.
Reference: [6] <author> Carla S. Ellis. </author> <title> Concurrent search and insertion in avl trees. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-29 No 9 </volume> <pages> 811-817, </pages> <month> Sept </month> <year> 1980. </year>
Reference-contexts: Performance results of this scheme are not yet available. A number of concurrent-access schemes have been developed for manipulating dictionaries that are represented as balanced trees <ref> [6, 11] </ref>, B-trees [5], and the balanced cube [4]. Most of these concurrent schemes allow O (log M ) operations (delete the smallest key, delete a key, insert a key, search for key, etc.) to be done simultaneously.
Reference: [7] <author> Ellis Horowitz and Sartaj Sahni. </author> <title> Fundamentals of Computer Algorithms. </title> <publisher> Computer Science Press, </publisher> <address> Rockville, MD, </address> <year> 1978. </year>
Reference-contexts: Section 6 discusses ways to improve the basic scheme to further reduce the overheads. A comparison with related work is presented in Section 7. Section 8 contains concluding remarks. 2 Serial Access Heap algorithms 2.1 Preliminaries A heap <ref> [1, 7] </ref> is a complete binary tree of depth d, with the property that the value of the key at any node is less than the value of the keys at its children (if they exist). 1 Before presenting the concurrent update scheme, we briefly describe the sequential implementation of the <p> performs better than the serial-access heap, and the speedup improvement factor grows as O (log M ). * Case II: Random Inserts If the keys of randomly distributed values are inserted into a heap, then the number of iterations of the heapification loop executed in insert b is very small <ref> [7] </ref>. Hence, L in T s access = T s r + L fl T s w is very small (&lt;2) even for very large heaps.
Reference: [8] <author> S.-R. Huang and Larry S. Davis. </author> <title> A tight upper bound for the speedup of parallel best-first branch-and-bound algorithms. </title> <type> Technical report, </type> <institution> Center for Automation Research, University of Maryland, College Park, MD, </institution> <year> 1987. </year> <month> 18 </month>
Reference-contexts: This serial-access scheme limits the number of processors that can be used to speed up the problem. If T think is the mean think time and T access is the mean access time, then clearly the maximum speedup achievable is (T access + T think )=T access (see <ref> [8] </ref>). T think is a characteristic of the problem being solved. T access depends on the priority structure being used. For the heap, T access is O (log M ), where M is the size of the heap. <p> Fig. 4 shows the speedup curves for T think = 10ms. ****** Figure 4 comes here **** Case III: Parallel Branch-and-Bound To test the performance of the concurrent-heap scheme in a more realistic situation, we incorporated it in a parallel branch-and-bound algorithm for solving the traveling salesman problem <ref> [18, 12, 8] </ref>. In this parallel algorithm, in each access-think cycle, each processor removes a least cost node from the heap, generates two successors, computes their costs, and inserts them both on the heap.
Reference: [9] <author> Vipin Kumar, K. Ramesh, and V. Nageshwara Rao. </author> <title> Parallel best-first search of state-space graphs: A summary of results. </title> <booktitle> In Proceedings of the 1988 National Conference on Artificial Intelligence, </booktitle> <pages> pages 122-126, </pages> <month> August </month> <year> 1988. </year>
Reference-contexts: To allow greater concurrency, it seems necessary to relax the strictness of the priority queue. In <ref> [9] </ref>, we present several "distributed" formulations of priority queue that permit O (M ) concurrency, and test their effectiveness in parallel branch-and-bound. Acknowledgements: We would like to thank Jit Biswas for many useful discussions concerning CHEAP, and Dan Miranker for comments on an earlier draft of this paper.
Reference: [10] <author> Charles E. Leiserson. </author> <title> Area-Efficient VLSI Computation. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1983. </year>
Reference-contexts: A number of VLSI dictionary machines [?, 19, 2] use O (M ) processors and allow O (log M ) operations to proceed in parallel. Leiserson's hardware priority queue <ref> [10] </ref> provides O (1) access time at the expense of O (M ) processors. As discussed in the previous section, with the help of O (log M ) service processors, our concurrent-access scheme can also provide O (1) access time.
Reference: [11] <author> U. Manber and R.E. Ladner. </author> <title> Concurrency control in a dynamic search structure. </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 9, 3 </volume> <pages> 439-455, </pages> <year> 1984. </year>
Reference-contexts: Performance results of this scheme are not yet available. A number of concurrent-access schemes have been developed for manipulating dictionaries that are represented as balanced trees <ref> [6, 11] </ref>, B-trees [5], and the balanced cube [4]. Most of these concurrent schemes allow O (log M ) operations (delete the smallest key, delete a key, insert a key, search for key, etc.) to be done simultaneously.
Reference: [12] <author> Joseph Mohan. </author> <title> Experience with two parallel programs solving the traveling salesman problem. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 191-193, </pages> <year> 1983. </year>
Reference-contexts: Fig. 4 shows the speedup curves for T think = 10ms. ****** Figure 4 comes here **** Case III: Parallel Branch-and-Bound To test the performance of the concurrent-heap scheme in a more realistic situation, we incorporated it in a parallel branch-and-bound algorithm for solving the traveling salesman problem <ref> [18, 12, 8] </ref>. In this parallel algorithm, in each access-think cycle, each processor removes a least cost node from the heap, generates two successors, computes their costs, and inserts them both on the heap.
Reference: [13] <author> Michael J. Quinn. </author> <title> Designing Efficient Algorithms for Parallel Computers. </title> <publisher> McGraw-Hill, </publisher> <address> New York, NY, </address> <year> 1987. </year>
Reference-contexts: In the ordinary serial heap algorithms, deletes manipulate the heap level by level going from top to bottom, while inserts manipulate it from bottom to top. Hence many deletions (or many insertions) can be executed in parallel by using a simple window locking scheme [3] or software pipelining <ref> [13, 14] </ref>. But inserts and deletes cannot be active together, as they proceed in opposite directions and hence can deadlock. Biswas and Browne [3] present a scheme to handle this problem.
Reference: [14] <author> Michael J. Quinn and Narsingh Deo. </author> <title> Data structures for the efficient solution of graph theoretic problems on tightly-coupled MIMD computers. </title> <booktitle> In Proceedings of International Conference on Parallel Processing, </booktitle> <pages> pages 431-438, </pages> <year> 1984. </year>
Reference-contexts: In the ordinary serial heap algorithms, deletes manipulate the heap level by level going from top to bottom, while inserts manipulate it from bottom to top. Hence many deletions (or many insertions) can be executed in parallel by using a simple window locking scheme [3] or software pipelining <ref> [13, 14] </ref>. But inserts and deletes cannot be active together, as they proceed in opposite directions and hence can deadlock. Biswas and Browne [3] present a scheme to handle this problem.
Reference: [15] <author> Michael J. Quinn and Narsingh Deo. </author> <title> Parallel graph algorithms. </title> <journal> ACM Computing Surveys, </journal> <volume> 16,No 3 </volume> <pages> 319-348, </pages> <month> September </month> <year> 1984. </year>
Reference-contexts: 1 Introduction The heap is an important data structure used as a priority queue in a wide variety of parallel algorithms (e.g., multiprocessor scheduling, graph search <ref> [15] </ref>, branch-and-bound [18, fl This work was supported by Army Research Office grant # DAAG29-84-K-0060 to the Artificial Intelligence Laboratory, and Office of Naval Research Grant N00014-86-K-0763 to the computer science department at the University of Texas at Austin. y Arpanet: kumar@cs.utexas.edu 1 12, 8, 16]) on shared-memory multiprocessors.
Reference: [16] <author> Michael J. Quinn and Narsingh Deo. </author> <title> An upper bound for the speedup of parallel branch-and-bound algorithms. </title> <type> Technical report, </type> <institution> Purdue University, </institution> <address> Pullman, Washington, </address> <year> 1984. </year>
Reference: [17] <author> V. Nageshwara Rao and V. Kumar. </author> <title> Concurrent access of priority queues. </title> <type> Technical Report TR88-06, </type> <institution> Computer Science Department, University of Texas at Austin, </institution> <year> 1988. </year>
Reference-contexts: At the beginning of the nth iteration of insert t, the value of i is the same as the value of I if its n 1 left most bits are set to zero. See <ref> [17] </ref> for a proof of correctness of the insert t algorithm. 6 Status code Meaning PRESENT A key exists at the node. PENDING An insertion is in progress which will ultimately insert a key at the node WANTED A deleter is waiting for the key. <p> This ensures that concurrent deletes or inserts proceeding in the same path progress in strict queue order without any interference. Since the locking sequence is in the strict increasing order of node indices, there are no deadlocks. See <ref> [17] </ref> for a proof of correctness of the concurrent-heap scheme. 4 Theoretical Analysis of Performance In this section we present a discussion of expected improvement in speedup due to the new concurrent-heap algorithms.
Reference: [18] <author> V. Nageshwara Rao, V. Kumar, and K. Ramesh. </author> <title> Parallel heuristic search on a shared memory multiprocessor. </title> <type> Technical Report AI TR87-45, </type> <institution> University of Texas at Austin, </institution> <year> 1987. </year>
Reference-contexts: concurrent (random) inserts and deletes are performed simultaneously, then the concurrent heap could still perform better overall if the average access time for serial inserts and deletes is larger than the average root locking time in concurrent heap operations. * Case III: Biased Inserts In many parallel algorithms (e.g., branch-and-bound <ref> [18] </ref>), each newly inserted key tends to be nearly as good as the best key already available in the heap. In this case, T s access = T s r + L fl T s w , where L log M . <p> Fig. 4 shows the speedup curves for T think = 10ms. ****** Figure 4 comes here **** Case III: Parallel Branch-and-Bound To test the performance of the concurrent-heap scheme in a more realistic situation, we incorporated it in a parallel branch-and-bound algorithm for solving the traveling salesman problem <ref> [18, 12, 8] </ref>. In this parallel algorithm, in each access-think cycle, each processor removes a least cost node from the heap, generates two successors, computes their costs, and inserts them both on the heap.

References-found: 18

