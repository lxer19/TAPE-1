URL: http://louis.hunter.cuny.edu/faculty/epstein/papers/MM.ps
Refering-URL: http://www.ai.univie.ac.at/~juffi/lig/lig-bib.html
Root-URL: 
Title: Role of Memory and Concepts in Learning  
Author: SUSAN L. EPSTEIN 
Keyword: Key words. Representation, cognitive architecture, concepts, machine learning, game playing.  
Address: New York  
Affiliation: Department of Computer Science Hunter College and The Graduate School of The City University of  
Note: The  
Abstract: This paper appeared in 1992 in Minds and Machines, 2 : 239-265. Abstract. The extent to which concepts, memory, and planning are necessary to the simulation of intelligent behavior is a fundamental philosophical issue in Artificial Intelligence. An active and productive segment of the AI community has taken the position that multiple low-level agents, properly organized, can account for high-level behavior. Empirical research on these questions with fully operational systems has been restricted to mobile robots that do simple tasks. This paper recounts experiments with Hoyle, a system in a cerebral, rather than a physical, domain. The program learns to perform well and quickly, often outpacing its human creators at two-person, perfect information board games. Hoyle demonstrates that a surprising amount of intelligent behavior can be treated as if it were situation-determined, that often planning is unnecessary, and that the memory required to support this learning is minimal. Concepts, however, are crucial to this reactive programs ability to learn and perform. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Amarel, S. </author> <year> (1968), </year> <title> On Representations of Problems of Reasoning about Actions, </title> <address> in D. </address>
Reference-contexts: In its thirty-odd years, AI has studied several ways to improve weak methods with domain knowledge. A good description of a problem (representation) can simplify and clarify its solution, as DENDRALs did (Lindsay et al., 1980). A perfect representation actually makes solution trivial, i.e., search-free <ref> (e.g., Amarel, 1968) </ref>. Without a perfect representation, domain knowledge can guide the exploration of alternative solutions (search control) as MYCINs did (Shortliffe, 1976).
Reference: <editor> Michie, ed., </editor> <booktitle> Machine Intelligence 3, </booktitle> <publisher> Edinburgh: Edinburgh University Press, </publisher> <pages> pp. 131-171. </pages>
Reference: <author> Anantharaman, T., Campbell, M. S., and Hsu, F.-h. </author> <year> (1990), </year> <title> Singular Extensions: Adding Selectivity to Brute-Force Searching, </title> <booktitle> Artificial Intelligence 43, </booktitle> <pages> pp. 99-110. </pages>
Reference: <author> Baerends, G. P. </author> <year> (1976), </year> <title> The Functional Organization of Behavior, </title> <booktitle> Animal Behavior 24, </booktitle> <pages> pp. 726-735. </pages>
Reference: <author> Bell, R. C. </author> <year> (1969), </year> <title> Board and Table Games from Many Civilizations, </title> <publisher> London: Oxford University Press. </publisher>
Reference: <author> Berliner, H., and Ebeling, C. </author> <year> (1989), </year> <title> Pattern Knowledge and Search: The SUPREM Architecture, </title> <booktitle> Artificial Intelligence 38, </booktitle> <pages> pp. 161-198. </pages>
Reference: <author> Blakeslee, S. </author> <year> (1991), </year> <title> Brain Yields New Clues on its Organization for Language, </title> <address> New York: The New York Times, </address> <month> September, </month> <note> 10, p.C1. </note>
Reference-contexts: If people have The Role of Memory and Concepts in Learning Page 7 preassembled low-level agents, the paucity, redundancy, and flexibility of human mental hardware suggests that the combination of those components to perform more elaborate tasks is learned, not innate <ref> (Blakeslee, 1991) </ref>. Some reactive systems have already learned their own control strategy. Robots with a subsumption architecture have successfully learned to coordinate six individual leg-controllers to walk like an insect, and to coordinate lower-level behaviors to push boxes against a wall (Maes, 1990; Mahadevan and Connell, 1991).
Reference: <author> Brooks, R. A. </author> <year> (1991), </year> <title> Intelligence without Representation, </title> <booktitle> Artificial Intelligence 47, </booktitle> <pages> pp. 139-160. </pages>
Reference: <author> Campbell, M. S. </author> <year> (1988), </year> <title> Chunking as an Abstraction Mechanism, </title> <type> Ph.D. Thesis, </type> <institution> Carnegie Mellon. </institution>
Reference-contexts: When in doubt, Hoyle may choose at random from some subset of the legal moves its Advisors find attractive. Thus the program structures its own nondeterministic learning environment, and averages are necessary to report its performance. 18. This is more closely related to the phenomenon of chunking <ref> (e.g., Campbell, 1988) </ref>. 19. Admittedly, the allocation of the difficult tasks to the system designer in some way begs the philosophical question as to what an ultimate general intelligence might be. The more modest goal targeted here, as previously stated, is only the simulation of a skilled expert.
Reference: <author> Cobb, H. G., and Grefenstette, J. J. </author> <year> (1991), </year> <title> Learning the Persistence of Actions in Reactive Control Rules, </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> pp. 293-297. </pages>
Reference: <author> Connell, J. </author> <year> (1990), </year> <title> Minimalist Mobile Robotics: A Colony-style Architecture for an Artificial Creature, </title> <address> New York: </address> <publisher> Academic Press. </publisher>
Reference: <author> DAndrade, R. G. </author> <year> (1990), </year> <title> Some Propositions about the Relations between Culture and Human Cognition, </title> <editor> in J. W. Stigler, R. A. Shweder and G. Herdt, ed., </editor> <booktitle> Cultural Psychology: Essays on Comparative Human Development, Cambridge: Cambridge The Role of Memory and Concepts in Learning Page 39 University Press, </booktitle> <pages> pp. 65-129. </pages>
Reference-contexts: There is ample evidence that concepts are both learned and culturally determined, and that people prefer them to logical reasoning for any but the simplest examples (DAndrade, 1991). In any culture, those judged experts are those who give more modal responses, i.e., agree most with commonly held regularities <ref> (DAndrade, 1990) </ref>. Thus an expert learns compiled knowledge, categories, scripts, and principles, and knows when and how to apply them. 11 Given those regularities, learning and problem solving with them may not be trivial, but it should be easier and require less memory.
Reference: <author> DAndrade, R. G. </author> <year> (1991), </year> <title> Culturally Based Reasoning, </title> <editor> in A. Gellatly and D. Rogers, ed., </editor> <title> Cognition and Social Worlds, </title> <publisher> Oxford: Clarendon Press, </publisher> <editor> Epstein, S. L. </editor> <year> (1990a), </year> <title> Learning Plans for Competitive Domains, </title> <booktitle> Proceedings of the Seventh International Conference on Machine Learning, </booktitle> <pages> pp. 190-197. </pages>
Reference-contexts: There is ample evidence that concepts are both learned and culturally determined, and that people prefer them to logical reasoning for any but the simplest examples <ref> (DAndrade, 1991) </ref>. In any culture, those judged experts are those who give more modal responses, i.e., agree most with commonly held regularities (DAndrade, 1990).
Reference: <author> Epstein, S. L. </author> <year> (1990b), </year> <title> Learning to Control a Blackboard System for Game Playing, </title> <booktitle> Proceedings of the AAAI Workshop on Blackboard Systems. </booktitle>
Reference-contexts: Control learning is beyond the scope of this paper, however. See <ref> (Epstein, 1990b) </ref> for further details. 13. This is a version of Brooks suppression and inhibition mechanisms. 14. Note that there may be more than one optimal next move and each such move is stored as an appropriate reaction.
Reference: <author> Epstein, S. L. </author> <year> (1991), </year> <title> Learning under a Weak Theory, </title> <institution> Department of Computer Science, Hunter College. </institution>
Reference-contexts: This section describes an artifact in that direction: Hoyle, a program that learns to play two-person, perfect information board games. Hoyle is based upon FORR, a general architecture for a learning and problem solving expert, one that postulates and capitalizes upon regularities <ref> (Epstein, 1991) </ref>. As a result, Hoyle explicitly identifies different kinds of concepts, learns instances of them, and capitalizes upon those instances.
Reference: <author> Epstein, S. L. </author> <year> (1992), </year> <title> Hard Questions about Easy Tasks - Issues from Learning to Play Games, in Computational Learning Theory and Natural Learning Systems: Constraints and Prospects, </title> <address> Cambridge, MA: </address> <publisher> MIT Press. To appear. </publisher>
Reference-contexts: Hoyles expert model is either a very good human player or a hand-crafted program that offers a broad variety of independent, tournament-level competition. (See <ref> (Epstein, 1992) </ref> for additional details.) Blackboard knowledge is a temporary repository for remembered, sensed, and calculated information. Information flow on the blackboard is monitored by the move selector, which produces the final move decision.
Reference: <author> Esfahany, K.H. </author> <year> (1992), </year> <note> in preparation. </note>
Reference-contexts: Most intelligent people would learn to play such a simple game perfectly after that much experience; N-N/Tree does not. Pattern recognition plus search can fail to learn this simple game in a realistic environment. Esfahanys classifier system, Dooze, 9 also learns to play games on a three-by-three board <ref> (Esfahany, 1992) </ref>. Like N-N/Tree, a Dooze pattern lists all nine positions on a three-by The Role of Memory and Concepts in Learning Page 10 three board. Each classifier is a rule of the form when position i is empty and the others have the following content, move to position i.
Reference: <author> Flax, M. G., Gelfand, J. J., Lane, S. H. and Handelman, D. A. </author> <year> (1990), </year> <title> Integrating Neural Network and Tree Search Approaches to Produce an AutoSupervised System that Learns to Play Games. </title> <booktitle> In Proceedings of The Aerospace Applications of Artificial Intelligence Conference, </booktitle> <editor> Goodman, N. </editor> <year> (1973), </year> <title> Fact, Fiction, and Forecast, Indianapolis, IN: </title> <publisher> Bobbs-Merrill. </publisher>
Reference-contexts: Pure pattern recognition seems insufficient for learning even this simple game in a noise-free environment. Gelfand has had similar results with N-N/Tree, a program that uses temporal differences and a neural net to learn values for nine-position patterns that describe games on a three-by-three board <ref> (Flax et al., 1990) </ref>. N-N/Tree is also permitted a 3-ply search. It plays against a programmed expert that may err as often as 5% of the time. After 1000 tic-tac-toe training contests, N-N/Tree still loses 8% of its contests.
Reference: <author> Hsu, G.-T., and Simmons, R. </author> <year> (1991), </year> <title> Learning Footfall Evaluation for a Walking Robot, </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> pp. 303-307. </pages>
Reference: <author> Kirsh, D. </author> <year> (1991), </year> <title> Today, </title> <booktitle> the Earwig, Tomorrow Man?, Artificial Intelligence 47, </booktitle> <pages> pp. 161-184. </pages>
Reference: <author> Laird, J. E., Rosenbloom, P. S., and Newell, A. </author> <year> (1987), </year> <title> SOAR: An Architecture for General Intelligence, </title> <booktitle> Artificial Intelligence 33, </booktitle> <pages> pp. 1-64. </pages>
Reference: <author> Lenat, D. B. </author> <year> (1976), </year> <title> AM: An Artificial Intelligence Approach to Discovery in The Role of Memory and Concepts in Learning Page 40 Mathematics, </title> <type> Ph.D. Thesis, </type> <institution> Department of Computer Science, Stanford University. </institution>
Reference: <author> Levinson, R., </author> <year> (1991), </year> <type> Personal communication. </type>
Reference-contexts: Learning only control, while adequate, may require more memory than a machine can offer. Levinson and Snyder have constructed Morph, a program that learns patterns to play chess <ref> (Levinson and Snyder, 1991) </ref>. They describe Morph as a search-free and purely syntactic game player, i.e., one that reacts only to patterns, without planning or reasoning. A pattern in their system is a labeled graph that describes how selected markers and positions on the board relate to each other. <p> Levinson has indicated that Morphs methods can be applied to any game once an appropriate pattern language is constructed. 10 Morphs approach was tested on tic-tac-toe; the program learned to play perfectly after approximately 250 contests and retained approximately 50 patterns to do so <ref> (Levinson, 1991) </ref>. The difference in learning rate and storage requirements between this program and Dooze highlights a possible learning tradeoff between memory size and number of training experiences required to learn.
Reference: <author> Levinson, R., and Snyder, R. </author> <year> (1991), </year> <title> Adaptive Pattern-Oriented Chess, </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> pp. 85-89. </pages>
Reference-contexts: Learning only control, while adequate, may require more memory than a machine can offer. Levinson and Snyder have constructed Morph, a program that learns patterns to play chess <ref> (Levinson and Snyder, 1991) </ref>. They describe Morph as a search-free and purely syntactic game player, i.e., one that reacts only to patterns, without planning or reasoning. A pattern in their system is a labeled graph that describes how selected markers and positions on the board relate to each other. <p> Levinson has indicated that Morphs methods can be applied to any game once an appropriate pattern language is constructed. 10 Morphs approach was tested on tic-tac-toe; the program learned to play perfectly after approximately 250 contests and retained approximately 50 patterns to do so <ref> (Levinson, 1991) </ref>. The difference in learning rate and storage requirements between this program and Dooze highlights a possible learning tradeoff between memory size and number of training experiences required to learn.
Reference: <author> Lindsay, R. K., Buchanan, B. G., Feigenbaum, E. A., and Lederberg, J. </author> <year> (1980), </year> <title> Applications of Artificial Intelligence for Organic Chemistry: The Dendral Project, </title> <address> New York: </address> <publisher> McGraw-Hill. </publisher>
Reference-contexts: In its thirty-odd years, AI has studied several ways to improve weak methods with domain knowledge. A good description of a problem (representation) can simplify and clarify its solution, as DENDRALs did <ref> (Lindsay et al., 1980) </ref>. A perfect representation actually makes solution trivial, i.e., search-free (e.g., Amarel, 1968). Without a perfect representation, domain knowledge can guide the exploration of alternative solutions (search control) as MYCINs did (Shortliffe, 1976).
Reference: <author> Maes, P., and Brooks, R. A. </author> <year> (1990), </year> <title> Learning to Coordinate Behaviors, </title> <booktitle> Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pp. 796-802. </pages>
Reference: <author> Mahadevan, S., and Connell, J. </author> <year> (1991), </year> <title> Scaling Reinforcement Learning to Robotics by Exploiting the Subsumption Architecture, </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> pp. 328-332. </pages>
Reference: <editor> Michie, D. </editor> <booktitle> 1986. On Machine Intelligence. Second edition. </booktitle> <publisher> Ellis Horwood Ltd. </publisher> <editor> check Minsky, M. </editor> <booktitle> (1986), The Society of Mind, </booktitle> <address> New York: </address> <publisher> Simon & Schuster. </publisher>
Reference-contexts: This will be a slow task, however, bounded from above only by the size of the search space, adjusted for symmetry. Michies experiments with MENACE, his matchbox tic-tac-toe machine indicate that a set of 300-odd expert moves can be learned in about 150 contests to simulate perfect play <ref> (Michie, 1986) </ref>. From his description it is estimated that Hoyle, after the same number of contests, would play as well when it learned approximately 300 expert moves and 100 significant states, for a total memory requirement of roughly 400 storage positions.
Reference: <author> Minton, S. </author> <year> (1988), </year> <title> Learning Search Control Knowledge - An Explanation-Based Approach, </title> <address> Boston: </address> <publisher> Kluwer Academic. </publisher>
Reference: <author> Mitchell, T., Allen, J., Chalasani, P., Cheng, J., Etzioni, O., Ringuette, M. N., and Schlimmer, J. C. </author> <year> (1990), </year> <title> Theo: A Framework for Self-Improving Systems, in K. </title>
Reference: <editor> Vanlehn, ed., </editor> <booktitle> Architectures for Intelligence, </booktitle> <address> Boston: </address> <publisher> Erlbaum, </publisher> <editor> Newell, A., Shaw, J. C., and Simon, H. A. </editor> <year> (1963), </year> <title> Empirical Explorations with the Logic Theory Machine: A Case Study in Heuristics, </title> <editor> in E. A. </editor> <booktitle> Feigenbaum and J. </booktitle>
Reference: <editor> Feldman, ed., </editor> <booktitle> Computers and Thought, </booktitle> <address> New York: </address> <publisher> McGraw-Hill, </publisher> <editor> Nilsson, N. J. </editor> <booktitle> (1980), Principles of Artificial Intelligence, </booktitle> <address> Palo Alto: </address> <publisher> Tioga Publishing. </publisher>
Reference: <author> Painter, J. </author> <year> (1992), </year> <title> Pattern Recognition for Decision Making in a Competitive Environment, </title> <type> Masters Thesis, </type> <institution> Department of Computer Science, Hunter College of the City University of New York. </institution> <note> The Role of Memory and Concepts in Learning Page 41 Pierce, </note> <author> D. </author> <year> (1991), </year> <title> Learning a Set of Primitive Actions with an Uninterpreted Sensorimotor Apparatus, </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> pp. 338-342. </pages>
Reference: <author> Ring, M. </author> <year> (1991), </year> <title> Incremental Development of Complex Behaviors through Automatic Construction of Sensory-motor Hierarchies, </title> <booktitle> Proceedings of the Eighth International Machine Learning Workshop, </booktitle> <pages> pp. 343-347. </pages>
Reference: <author> Sacerdoti, E. D. </author> <year> (1974), </year> <title> Planning in a Hierarchy of Abstraction Spaces, </title> <booktitle> Artificial Intelligence 5, </booktitle> <pages> pp. 115-135. </pages>
Reference: <author> Schank, R., and Abelson, R. </author> <year> (1977), </year> <title> Scripts, Plans, Goals, and Understanding: An Inquiry into Human Knowledge Structures, </title> <address> Hillsdale, NJ: </address> <publisher> Erlbaum. </publisher>
Reference-contexts: The occasional unhappy surprise when this assumption fails testifies to the existence of the category and its associated expectations. Regularities about what is expected of an experience and those who participate in it are recorded as scripts <ref> (Schank and Abelson, 1977) </ref>. For example, people learn that there is a partially ordered set of expectations for everyones behavior in a restaurant. A visit to any restaurant is a walk through that script. Jokes about waiters may be funny because they violate that script.
Reference: <author> Shortliffe, E. H. </author> <year> (1976), </year> <title> Computer-Based Medical Consultations: MYCIN, </title> <address> New York: </address> <publisher> Elsevier. </publisher>
Reference-contexts: A perfect representation actually makes solution trivial, i.e., search-free (e.g., Amarel, 1968). Without a perfect representation, domain knowledge can guide the exploration of alternative solutions (search control) as MYCINs did <ref> (Shortliffe, 1976) </ref>. Domain knowledge can also indicate which ideas are particularly relevant to the problems solution and which are not (focus of attention), as ABSTRIPS and AM did (Sacerdoti, 1974; Lenat, 1976). It is not always possible, however, for people to identify key domain knowledge precisely for an implementation.
Reference: <author> Tinbergen, N. </author> <year> (1951), </year> <title> The Study of Instinct, </title> <publisher> Oxford: Oxford University Press. </publisher>
Reference: <author> Wierzbicka, A. </author> <year> (1985), </year> <title> Lexicography and Conceptual Analysis, </title> <address> Ann Arbor, MI: </address> <publisher> Karoma Publishers. </publisher>
Reference-contexts: The agents are supposed to determine behavior, of course, but there ought to be a more memory-efficient and elegant construction for them. Each of the four programs described here senses 7 and reacts to recognized patterns without deliberating upon their meaning, i.e., their conceptual structure <ref> (Wierzbicka, 1985) </ref>. The programs are introduced in increasing order of the amount of knowledge about game playing that they somehow The Role of Memory and Concepts in Learning Page 9 incorporate into their control rules and/or their learning algorithms. <p> For example, one may know how to ride a bicycle without deliberation, but teaching another person to ride usually requires self-observation on some fresh bicycle-riding experience. People store some regularities as categories, sets of objects with common features <ref> (Wierzbicka, 1985) </ref>. For example, people learn about chairs and that a chair usually has a back which supports weight. Every chair, physical or hypothetical, is an instance of the category, with specifically noted values for some of its features.
Reference: <author> Zaslavsky, C. </author> <year> (1982), </year> <title> Tic Tac Toe and Other Three-in-a-Row Games, from Ancient Egypt to the Modern Computer, </title> <publisher> Crowell. </publisher>
References-found: 40

