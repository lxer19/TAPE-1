URL: ftp://ftp.cs.helsinki.fi/pub/Reports/by_Author/Elomaa_Tapio/Learning_Decision_Trees_for_Mapping_the_Local_Environment_in_Mobile_Robot_Navigation.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/robot-learning.html
Root-URL: 
Email: i.p.sillitoe@lut.ac.uk  elomaa@cs.helsinki.fi  
Title: Learning Decision Trees for Mapping the Local Environment in Mobile Robot Navigation  
Author: Ian Sillitoe Tapio Elomaa P. O. Box (Teollisuuskatu ) 
Address: Loughborough, Leicestershire, LE11 3TU, U.K.  Helsinki, Finland  
Affiliation: Department of Electronic and Electrical Engineering Loughborough University of Technology  Department of Computer Science  University of  
Pubnum: FIN-00014  
Abstract: This paper describes the use of the C4.5 decision tree learning algorithm in the design of a classifier for a new approach to the mapping of a mobile robot's local environment. The decision tree uses the features from the echoes of an ultrasonic array mounted on the robot to classify the contours of its local environment. The contours are classified into a finite number of two dimensional shapes to form a primitive map which is to be used for navigation. The nature of the problem, noise and the practical timing constraints, distinguishes it from those typically used in machine learning applications and highlights some of the advantages of decision tree learning in robotic applications.
Abstract-found: 1
Intro-found: 1
Reference: <author> Atlas, L. et al. </author> <year> (1990). </year> <title> Performance comparisons between backpropagation networks and classification trees on three real-world applications. </title> <editor> In D. Touretzky (ed.), </editor> <booktitle> Advances in Neural Information Processing Systems 2 (pp. </booktitle> <pages> 622-629). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Barshan, B. and Kuc, R. </author> <year> (1992). </year> <title> A bat-like sonar system for obstacle localization. </title> <journal> IEEE Transactions on Systems, Man and Cybernetics 22: </journal> <pages> 636-646. </pages>
Reference-contexts: Much attention has been placed upon the accurate determination of the beginning of the received pulse, since this plays an important role in maximising the accuracy of such a system <ref> (Barshan and Kuc, 1992) </ref>. These approaches essentially give a spot reading; i.e., they return the distance to a given spot on the object. <p> Thus, this system is similar in its physical arrangement to the 'Bat Sonar' system <ref> (Barshan and Kuc, 1992) </ref>, which used time of flight to identify the position of objects within its working volume.
Reference: <author> Craven, M. and Shavlik, J. </author> <year> (1993). </year> <title> Learning to represent codons: a challenge problem for constructive induction. </title> <booktitle> In Proc. Thirteenth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 1319-1324). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Dietterich, T., Hild, H., and Bakiri, G. </author> <year> (1990). </year> <title> A comparative study of ID3 and backpropagation for English text-to-speech mapping. </title> <editor> In B. Porter and R. Mooney (eds.), </editor> <booktitle> Machine Learning: Proceedings of the Seventh International Conference (pp. </booktitle> <pages> 24-31). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fisher, D. and McKusick, K. </author> <year> (1989). </year> <title> An empirical comparison of ID3 and back-propagation. </title> <booktitle> In Proc. Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 788-793). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Fisher, D., McKusick, K., Mooney, R., Shavlik, J., and Towell, G. </author> <year> (1989). </year> <title> Processing issues in comparisons of symbolic and connectionist learning systems. </title> <booktitle> In Proc. Sixth International Workshop on Machine Learning (pp. </booktitle> <pages> 169-173). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Hickling, R. and Marin, S.P. </author> <year> (1986). </year> <title> The use of ultrasonics for gauging and proximity sensing in air. </title> <journal> The Journal of the Acoustical Society of America 79: </journal> <pages> 1151-1160. </pages>
Reference: <author> Kira, K. and Rendell, L. </author> <year> (1992). </year> <title> A practical approach to feature selection. </title> <editor> In D. Sleeman and P. Edwards (eds.), </editor> <booktitle> Machine Learning: Proceedings of the Ninth International Workshop (pp. </booktitle> <pages> 249-256). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Automatically producing decision trees that minimise the average cost of instance classification in cases where the evaluation of a feature has a natural cost has also been studied (Nunez, 1988; Tan and Schlimmer, 1990). Rather than trying these approaches or some separate feature selection technique <ref> (e.g., Kira and Rendell, 1992) </ref>, we chose to use Quinlan's (1993) C4.5 and manual picking out of the final features in order to retain full control over this crucial process.
Reference: <author> Kuc, R. and Bozma, </author> <title> O . (1991). Building a sonar map in a specular environment using a single mobile sensor. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence 13: </journal> <pages> 1260-1269. </pages>
Reference-contexts: In order to allow a time-of-flight ultrasonic system to produce a more detailed map of the surface of the object the sensor spot must be moved across the object. This can be done in either of two ways: mechanically, where the sensor is moved relative to the object <ref> (Kuc and Bozma, 1991) </ref>, or through the use of a phased array technique, whereby the relative phase of a number of transmitters is altered so that the combined wave front is shifted. The mechanical procedure requires that the sensor is moved and reading taken many times during a single scan.
Reference: <author> Mooney, R., Shavlik, J., Towell, G., and Gove, A. </author> <year> (1989). </year> <title> An experimental comparison of symbolic and connectionist learning algorithms. </title> <booktitle> In Proc. Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 775-780). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Nunez, M. </author> <year> (1988). </year> <title> Economic induction: a case study. </title>
Reference: <editor> In D. Sleeman (ed.), </editor> <booktitle> Proc. Third European Working Session on Learning (pp. </booktitle> <pages> 139-145). </pages> <address> London: </address> <publisher> Pitman. </publisher>
Reference: <author> Pagallo, G. and Haussler, D. </author> <year> (1990). </year> <title> Boolean feature discovery in empirical learning. </title> <booktitle> Machine Learning 5: </booktitle> <pages> 71-99. </pages>
Reference-contexts: Subsequent comparative studies (e.g., Thrun et al., 1991) have stressed the connectionist approach's additional advantage of being able to construct, if not express, new (sub-symbolic) features from the primitive ones. This property is lacking from the basic symbolic approaches, even though specific algorithms with feature construction capabilities now exist <ref> (see e.g., Pagallo and Haussler, 1990) </ref>. However, a recent study by Craven and Shavlik (1993) demonstrates that even back-propagation fails in constructing quite simple new features. In connectionist approaches it is often difficult to determine the relative significance of individual features and the use to which they are put.
Reference: <author> Quinlan, R. </author> <year> (1993). </year> <title> C4.5: Programs for Machine Learning. </title> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: We report some of our preliminary experiences on using the C4.5 algorithm <ref> (Quinlan, 1993) </ref> to construct decision tree classifiers from feature vectors recorded for example objects exposed to the sensor system.
Reference: <author> Shavlik, J., Mooney, R., and Towell, G. </author> <year> (1991). </year> <title> Symbolic and neural learning algorithms: An experimental comparison. </title> <booktitle> Machine Learning 6: </booktitle> <pages> 111-143. </pages>
Reference: <author> Tan, M. and Schlimmer, J. </author> <year> (1990). </year> <title> Two case studies in cost-sensitive concept acquisition. </title> <booktitle> In Proc. Eighth National Conference on Artificial Intelligence (pp. </booktitle> <pages> 854-860). </pages> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Thrun, S. et al. </author> <year> (1991). </year> <title> The MONK's problems a performance comparison of different learning algorithms. </title> <type> Report CMU-CS-91-197. </type> <institution> School of Computer Science, Carnegie Mellon University. </institution>
Reference-contexts: The symbolic approach turns out to be superior in training time, while in classification both approaches are equally efficient. Moreover, neural networks typically require much more examples than decision trees before converging. Subsequent comparative studies <ref> (e.g., Thrun et al., 1991) </ref> have stressed the connectionist approach's additional advantage of being able to construct, if not express, new (sub-symbolic) features from the primitive ones.
Reference: <author> Watanabe, S. and Yoneyama, M. </author> <year> (1992). </year> <title> An ultrasonic visual sensor for three-dimensional object recognition using neural networks. </title> <journal> IEEE Transactions on Robotics and Automation 8: </journal> <pages> 240-249. </pages>
Reference: <author> Weiss, S. and Kapouleas, I. </author> <year> (1989). </year> <title> An empirical comparison of pattern recognition, neural nets, and machine learning classification methods. </title> <booktitle> In Proc. Eleventh International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 781-787). </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann. </publisher>
References-found: 19

