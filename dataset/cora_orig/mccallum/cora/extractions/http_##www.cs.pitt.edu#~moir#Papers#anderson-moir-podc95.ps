URL: http://www.cs.pitt.edu/~moir/Papers/anderson-moir-podc95.ps
Refering-URL: http://www.cs.pitt.edu/~moir/papers.html
Root-URL: 
Title: Universal Constructions for Multi-Object Operations (Extended Abstract)  
Author: James H. Anderson and Mark Moir 
Address: Chapel Hill, NC 27599-3175  
Affiliation: Department of Computer Science, University of North Carolina,  
Abstract: We present wait-free and lock-free universal constructions that allow operations to access multiple objects atomically. Such constructions provide functionality similar to nested critical sections in conventional, lock-based systems. In such a system, two critical sections might be nested, for example, to swap the contents of two shared buffers. Using our constructions, such a transfer can be done in a wait-free or a lock-free manner. Our universal constructions are based upon multiword synchronization primitives. In the first part of the paper, we present wait-free implementations of such primitives from one-word primitives. These implementations allow processes that access disjoint words to execute in parallel. Previous implementations of multi-word primitives either overly restrict parallelism, or provide only lock-free execution. We also present several implementations involving one-word universal primitives that allow our constructions to be applied with greater flexibility. In particular, we present time-optimal, wait-free implementations of Load-Linked and Store-Conditional from Read and Compare-And-Swap, and vice versa, and implementations that eliminate the need to deal with spurious Store-Conditional failures. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Anderson and M. Moir, </author> <title> "Universal Constructions for Large Objects", </title> <booktitle> submitted to Ninth International Workshop on Distributed Algorithms, </booktitle> <month> September </month> <year> 1995. </year>
Reference-contexts: Because p does not use any of the N most recently selected tags, it follows that p performs at least N successful SC operations before reusing v. Thus, p must have read A [q] in the last N operations, and therefore does not reuse tag v. In <ref> [1] </ref>, we show how the new tag can be selected in constant time. Thus, we have the following theorem. <p> =fl Initialize AM row to reflect operation fl= 10: for i := 1 to numobjs do AM [p][obj [i]] := op od; 11: bit := :OBJ [obj <ref> [1] </ref>]&gt;bit [p]; =fl Compute termination bit fl= 12: ANC [p]:func; ANC [p]:par; ANC [p]:bit; ANC [p]:first := func; par ; bit ; obj [1]; =fl Announce operation fl= 13: while (OBJ [obj [1]]&gt;bit [p] = bit) _ (OBJ [obj [1]]&gt;bit [p] = bit ) do =fl Operation is not done yet fl= repeat 14: for i := 1 to M do if AM [p][i] 6= none then old [i] := LL (&OBJ [i]) fi <p> Operation is not done yet fl= repeat 14: for i := 1 to M do if AM [p][i] 6= none then old [i] := LL (&OBJ [i]) fi od; =fl Load pointers in closure fl= 15: proc; tclist; same; k; fail := fg; fg; true; 1; false; 16: TC (obj <ref> [1] </ref>); =fl Recompute transitive closure fl= 17: for each i 2 tclist do if AM [p][i] = none then AM [p][i] := help; same := false fi od 18: until same; =fl Repeatedly compute transitive closure until no more is added fl= 19: for each i 2 tclist do =fl Make <p> [h] := h + 1; i else cover := false fi fi od; 28: if cover ^ VL (&ANC [j]:first) then func (new; objl ; par ); new [first]&gt;bit [j]] := :new [first]&gt;bit [j] fi od; fi =fl Try to make local copies current fl= 29: if MWSC ((&OBJ [word <ref> [1] </ref>]; :::; &OBJ [word [k 1]]); (new [word [1]]; :::; new [word [k 1]])) then 30: for i := 1 to k 1 do new [word [i]] := old [word [i]] od; exit while =fl Reclaim old copies fl= od; fi 31: ANC [p]:first := 0; 32: for k := 1 <p> := false fi fi od; 28: if cover ^ VL (&ANC [j]:first) then func (new; objl ; par ); new [first]&gt;bit [j]] := :new [first]&gt;bit [j] fi od; fi =fl Try to make local copies current fl= 29: if MWSC ((&OBJ [word <ref> [1] </ref>]; :::; &OBJ [word [k 1]]); (new [word [1]]; :::; new [word [k 1]])) then 30: for i := 1 to k 1 do new [word [i]] := old [word [i]] od; exit while =fl Reclaim old copies fl= od; fi 31: ANC [p]:first := 0; 32: for k := 1 to numobjs do retval [k] := OBJ [obj
Reference: [2] <author> G. Barnes, </author> <title> "A Method for Implementing Lock-Free Shared Data Structures", </title> <booktitle> Proceedings of the Fifth Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1993, </year> <pages> pp. 261-270. </pages>
Reference-contexts: By a straightforward generalization of the one-word case, MWCAS can in turn be used to implement LL, VL, and MWSC (see Table 1). The problem of implementing such multi-word primitives has been considered previously by Barnes <ref> [2] </ref>, by Israeli and Rappoport [7], and by Shavit and Touitou [8]. However, the implementations presented in these papers are only lock-free. A process in our implementation attempts to "lock", in a wait-free manner, each of the words that it accesses. <p> LL, VL, and SC operations are used to ensure that each stage of each operation is executed exactly once. Techniques similar to this one have been used previously <ref> [2, 7, 8] </ref>. However, these implementations are only lock-free, not wait-free, so operations are not guaranteed to complete. We employ a technique that allows a process to detect concurrent operations with which it potentially interferes, and to help complete such operations.
Reference: [3] <author> B. Bershad, </author> <title> "Practical Considerations for Non-Blocking Concurrent Objects", </title> <booktitle> Proceedings of the 13th international Conference on Distributed Computing Systems, </booktitle> <month> May </month> <year> 1993, </year> <pages> pp. pages 264-274. </pages>
Reference-contexts: The performance benefits of allowing CAS operations to fail early were first recognized by Bershad in his work on operating system-based implementations of CAS <ref> [3] </ref>. In the last major section of the paper, Section 4, we use the primitives developed previously to obtain both lock-free and wait-free universal constructions of multi-object operations.
Reference: [4] <author> M. Herlihy, </author> <title> "Wait-Free Synchronization", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 13, No. 1, </volume> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: 1 Introduction This paper extends recent research on universal wait-free and lock-free constructions of shared objects <ref> [4, 5] </ref>. Such constructions are based upon strong primitives such as Compare-And-Swap (CAS ) or Load-Linked (LL) and Store-Conditional (SC ), and can be used to implement any object in a wait-free or a lock-free manner.
Reference: [5] <author> M. Herlihy, </author> <title> "A Methodology for Implementing Highly Concurrent Data Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 5, </volume> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: 1 Introduction This paper extends recent research on universal wait-free and lock-free constructions of shared objects <ref> [4, 5] </ref>. Such constructions are based upon strong primitives such as Compare-And-Swap (CAS ) or Load-Linked (LL) and Store-Conditional (SC ), and can be used to implement any object in a wait-free or a lock-free manner. <p> Both constructions are based upon LL, VL, and MWSC, and are obtained by adapting the universal constructions based upon LL and SC presented by Herlihy in <ref> [5] </ref>. As in the implementation of MWCAS , the major problem that arises in our wait-free construction is that of ensuring good parallelism in the face of transitive conflicts. <p> A straightforward generalization of the construction in Figure 1 implements LL, MWSC , and VL using Read and MWCAS . Details are deferred to the full paper. Herlihy's universal construction <ref> [5] </ref> can be used to implement any shared object using LL and SC . In particular, MWCAS can be implemented using Herlihy's construction by treating all M words as one object. However, this approach suffers from two drawbacks. <p> We then present a wait-free construction for multi-object operations in more detail. Both constructions use LL, VL, and MWSC . The lock-free construction is a generalization of Her-lihy's single-object, lock-free construction <ref> [5] </ref>. A pointer to each object affected by a multi-object operation is loaded using LL. A local copy of each object is made, and the multi-object operation is applied to the copies. Finally, a MWSC operation is used to attempt to "install" the new versions of the affected objects. <p> The loop at lines 13 to 30 is repeated until the test at line 13 fails, indicating that p's operation has been successfully completed. This test is performed twice to avoid a race condition similar to the one described by Herlihy in <ref> [5] </ref>. Inside this outer loop, p detects operations that conflict with its own and attempts to perform these operations along with its own by making local copies of the affected objects, applying the operations to the local copies, and finally using MWSC to "install" the new versions of the objects. <p> All other terms in the time complexity are dominated by these terms. Thus, the construction in asymptotic time complexity as Herlihy's construction <ref> [5] </ref> for the single-object case (that is, when M = 1). In fact, it can be shown that even when M &gt; 1, if no multi-object operations conflict with a single-object operation, then that operation is completed in O (N ) time.
Reference: [6] <author> M. Herlihy and J. Wing, </author> <title> "Linearizability: A Correctness Condition for Concurrent Objects", </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 12, No. 3, </volume> <year> 1990, </year> <pages> pp. 463-492. </pages>
Reference: [7] <author> A. Israeli and L. Rappoport, </author> <title> "Disjoint-Access-Parallel Implementations of Strong Shared Memory Primitives", </title> <booktitle> Proceedings of the 13th Annual ACM Symposium on Principles of Distributed Computing , August 1994, </booktitle> <pages> pp. 151-160. </pages>
Reference-contexts: Our implementations of these primitives are time-optimal, requiring constant time per operation. The best previous wait-free implementation of LL, SC , and VL, recently presented by Israeli and Rappoport in <ref> [7] </ref>, requires O (N ) time per operation. It also requires N -bit shared variables, which severely limits its usefulness in practice. (Israeli and Rappoport did not present similar constructions for CAS .) Our implementations of multi-word universal primitives are given in Section 3. <p> The use of such constructions would also limit parallelism: processes performing operations involving disjoint sets of words could not execute in parallel. The importance of parallelism in this context was first noted by Israeli and Rappoport <ref> [7] </ref>. The main result of Section 3 is a wait-free implementation of MWCAS from LL, SC , and VL. By a straightforward generalization of the one-word case, MWCAS can in turn be used to implement LL, VL, and MWSC (see Table 1). <p> By a straightforward generalization of the one-word case, MWCAS can in turn be used to implement LL, VL, and MWSC (see Table 1). The problem of implementing such multi-word primitives has been considered previously by Barnes [2], by Israeli and Rappoport <ref> [7] </ref>, and by Shavit and Touitou [8]. However, the implementations presented in these papers are only lock-free. A process in our implementation attempts to "lock", in a wait-free manner, each of the words that it accesses. A similar (albeit only lock-free) approach is used in [7] and [8]. <p> [2], by Israeli and Rappoport <ref> [7] </ref>, and by Shavit and Touitou [8]. However, the implementations presented in these papers are only lock-free. A process in our implementation attempts to "lock", in a wait-free manner, each of the words that it accesses. A similar (albeit only lock-free) approach is used in [7] and [8]. The main problem encountered in obtaining a wait-free implementation of MWCAS is that of efficiently "helping" conflicting operations | such helping is cen 2 The SC operation terminates in O (1) time after the most recent spurious FSC. <p> LL, VL, and SC operations are used to ensure that each stage of each operation is executed exactly once. Techniques similar to this one have been used previously <ref> [2, 7, 8] </ref>. However, these implementations are only lock-free, not wait-free, so operations are not guaranteed to complete. We employ a technique that allows a process to detect concurrent operations with which it potentially interferes, and to help complete such operations.
Reference: [8] <author> N. Shavit and D. Touitou, </author> <title> "Software Transactional Memory", </title> <booktitle> these proceedings. </booktitle>
Reference-contexts: By a straightforward generalization of the one-word case, MWCAS can in turn be used to implement LL, VL, and MWSC (see Table 1). The problem of implementing such multi-word primitives has been considered previously by Barnes [2], by Israeli and Rappoport [7], and by Shavit and Touitou <ref> [8] </ref>. However, the implementations presented in these papers are only lock-free. A process in our implementation attempts to "lock", in a wait-free manner, each of the words that it accesses. A similar (albeit only lock-free) approach is used in [7] and [8]. <p> Israeli and Rappoport [7], and by Shavit and Touitou <ref> [8] </ref>. However, the implementations presented in these papers are only lock-free. A process in our implementation attempts to "lock", in a wait-free manner, each of the words that it accesses. A similar (albeit only lock-free) approach is used in [7] and [8]. The main problem encountered in obtaining a wait-free implementation of MWCAS is that of efficiently "helping" conflicting operations | such helping is cen 2 The SC operation terminates in O (1) time after the most recent spurious FSC. See Section 2 for details. tral to most wait-free universal constructions. <p> LL, VL, and SC operations are used to ensure that each stage of each operation is executed exactly once. Techniques similar to this one have been used previously <ref> [2, 7, 8] </ref>. However, these implementations are only lock-free, not wait-free, so operations are not guaranteed to complete. We employ a technique that allows a process to detect concurrent operations with which it potentially interferes, and to help complete such operations.
References-found: 8

