URL: ftp://dimacs.rutgers.edu/pub/dimacs/TechnicalReports/TechReports/1995/95-37.ps.gz
Refering-URL: http://dimacs.rutgers.edu/TechnicalReports/1995.html
Root-URL: http://www.cs.rutgers.edu
Title: Improved Approximation Guarantees for Packing and Covering Integer Programs 1  
Author: by Aravind Srinivasan ; 
Address: Lower Kent Ridge Road Singapore 119260 Republic of Singapore  
Affiliation: Department of Information Systems and Computer Science National University of Singapore  
Abstract: DIMACS Technical Report 95-37 September 1995 DIMACS is a partnership of Rutgers University, Princeton University, AT&T Research, Bellcore, and Bell Laboratories. DIMACS is an NSF Science and Technology Center, funded under contract STC-91-19999; and also receives support from the New Jersey Commission on Science and Technology. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. Aharoni, P. Erd-os, and N. Linial. </author> <title> Optima of dual integer linear programs. </title> <journal> Combinatorica, </journal> <volume> 8 </volume> <pages> 13-20, </pages> <year> 1988. </year>
Reference-contexts: For a (column) vector v, let v T denote its transpose, and v i stand for its ith component. We first define the packing and covering integer programs. Definition 1 Given A 2 <ref> [0; 1] </ref> nfim , b 2 [1; 1) n and c 2 [0; 1] m with max j c j = 1, a packing (resp. covering) integer program PIP (resp. CIP) seeks to maximize (resp. minimize) c T x subject to x 2 Z m + and Ax b (resp. <p> For a (column) vector v, let v T denote its transpose, and v i stand for its ith component. We first define the packing and covering integer programs. Definition 1 Given A 2 [0; 1] nfim , b 2 <ref> [1; 1) n and c 2 [0; 1] </ref> m with max j c j = 1, a packing (resp. covering) integer program PIP (resp. CIP) seeks to maximize (resp. minimize) c T x subject to x 2 Z m + and Ax b (resp. Ax b). <p> For a (column) vector v, let v T denote its transpose, and v i stand for its ith component. We first define the packing and covering integer programs. Definition 1 Given A 2 <ref> [0; 1] </ref> nfim , b 2 [1; 1) n and c 2 [0; 1] m with max j c j = 1, a packing (resp. covering) integer program PIP (resp. CIP) seeks to maximize (resp. minimize) c T x subject to x 2 Z m + and Ax b (resp. Ax b). <p> Though randomized rounding is a unifying idea to derive good approximation algorithms, there are better approximation bounds for specific key problems such as set cover (Johnson [13], Lovasz [14], Chvatal [6]), hypergraph matching (Aharoni, Erd-os & Linial <ref> [1] </ref>) and file-sharing in distributed networks (Naor & Roth [17]), each derived through different means. <p> Thus we get, in a unified way, improved bounds on the integrality gap maxf (c T z)=y fl ; y fl =(c T z)g and hence, improved approximation algorithms for all PIPs and CIPs. In particular, we improve on the above-mentioned results of <ref> [13, 14, 1, 17] </ref>; our bound is incomparable with that of [6]. 1.3 Approximation bounds achieved Our best improvements are for PIPs. <p> For PIPs, the standard analysis of randomized rounding guarantees integral solutions of value t 1 = (y fl =n 1=B ) and 5 t 2 = (y fl =n 1=(B+1) ) respectively, if A 2 <ref> [0; 1] </ref> nfim and A 2 f0; 1g nfim . <p> Usual hypergraph matching has B = 1, and is a well-known NP-hard problem. To our knowledge, the only known good bound for this problem, apart from the standard analysis of randomized rounding, was provided by the work of <ref> [1] </ref>, which focused on the special case of unweighted edges. The methods of [1] can be used to show that if f is the minimum size of an edge in the hypergraph, then there exists an integral matching of value at least (y fl ) 2 B 2 n While this <p> To our knowledge, the only known good bound for this problem, apart from the standard analysis of randomized rounding, was provided by the work of <ref> [1] </ref>, which focused on the special case of unweighted edges. The methods of [1] can be used to show that if f is the minimum size of an edge in the hypergraph, then there exists an integral matching of value at least (y fl ) 2 B 2 n While this matches our result to within a constant factor for B = 1, note <p> Theorem 1 presents these tail bounds; see, e.g., Motwani & Raghavan [16] for the proofs. Theorem 1 Let X 1 ; X 2 ; : : : ; X ` be independent r.v.s, each taking values in <ref> [0; 1] </ref>, with R = P ` i=1 X i and E [R] = . <p> Theorem 2 Given a finite set N = fa 1 ; a 2 ; : : :; a ` g and some p = (p 1 ; p 2 ; : : : ; p ` ) 2 <ref> [0; 1] </ref> ` , suppose we pick a random Y N by placing each a i in Y independently, with probability p i . <p> For our purposes, we focus on the case of independent binary r.v.s. Let X 1 ; X 2 ; : : :; X ` 2 f0; 1g be independent r.v.s with P r (X i = 1) = p i , for some p 2 <ref> [0; 1] </ref> ` . Suppose, for some implicitly defined L f0; 1g ` , that P r (X (`) 2 L) &lt; 1: How do we find some v 2 f0; 1g ` L? Theorem 3 now presents the idea of pessimistic estimators applied to the method of conditional probabilities. <p> See [19] for a detailed discussion and proof. Notation 1 8q 2 <ref> [0; 1] </ref> ` 8i 2 f0g [[`] 8w 2 f0; 1g i : and for any j 2 f0; 1g, define wj 2 f0; 1g i+1 Returning to the X i s, p and L, we define Definition 3 A function U : [0; 1] ` ! &lt; + is a <p> Notation 1 8q 2 <ref> [0; 1] </ref> ` 8i 2 f0g [[`] 8w 2 f0; 1g i : and for any j 2 f0; 1g, define wj 2 f0; 1g i+1 Returning to the X i s, p and L, we define Definition 3 A function U : [0; 1] ` ! &lt; + is a pessimistic estimator w.r.t. (X 1 ; : : : ; X ` ) and L if: (2) 8i 2 f0g [ [`] 8w 2 f0; 1g , (a) U (u (i; w; p)) P r (X (`) 2 LjX (i) = w), and <p> Suppose the graph G = (V; E) is a line on the N vertices 1; 2; : : :; N , and that each vertex independently picks a random bit for itself with the bit being one with probability q, for some q 2 <ref> [0; 1] </ref>. Let p N be the probability that no two adjacent vertices choose the bit "1".
Reference: [2] <author> N. Alon, J. H. Spencer, and P. Erd-os. </author> <title> The Probabilistic Method. </title> <publisher> Wiley-Interscience Series, John Wiley & Sons, Inc., </publisher> <address> New York, </address> <year> 1992. </year> <month> 22 </month>
Reference-contexts: r ( i=1 n _ E i ) + P r (E n+1 ) 1 ( i=1 which is always as good as, and most often much better than, (1). (For a detailed study of the FKG inequality, see, e.g., Graham [11] and Chapter 6 of Alon, Spencer & Erd-os <ref> [2] </ref>.) It is not hard to verify such a property for CIPs also. <p> We next present Theorem 2, a special case of the powerful FKG inequality [10, 22]; for a proof, see, e.g., the proof of Theorem 3.2 in Chapter 6 of <ref> [2] </ref>. <p> The precise reasons for such a correlation are spelled out in Section 1.2. It is a challenging open question to use the structure of correlations in more complicated scenarios; one such problem is the set discrepancy problem <ref> [23, 2] </ref>. <p> come up with a function : A ! f1; 1g, such that the discrepancy disc ( ) : is "small", where (S i ) = j2S i While randomized rounding and the method of conditional probabilities can be used to produce a with discrepancy O ( p n log n) <ref> [23, 2] </ref>, a classical nonconstructive result of Spencer shows the existence of a with disc ( ) = O ( p [24]. This is best possible, and it is an important open problem to make this constructive.
Reference: [3] <author> M. Bellare, S. Goldwasser, C. Lund, and A. Russell. </author> <title> Efficient probabilis-tically checkable proofs and applications to approximation. </title> <booktitle> In Proc. ACM Symposium on Theory of Computing, </booktitle> <pages> pages 294-304, </pages> <year> 1993. </year>
Reference-contexts: For set cover, we tighten the constants in (4) to derive an ln (n=y fl ) + O (ln ln (n=y fl )) + O (1) approximation bound. The work of Lund & Yannakakis [15] and Bellare, Gold-wasser, Lund & Russell <ref> [3] </ref> shows a constant a &gt; 0 such that approximating this problem to within a ln n is likely to take super-polynomial time.
Reference: [4] <author> D. Bertsimas and R. Vohra. </author> <title> Linear programming relaxations, approximation algorithms and randomization; a unified view of covering problems. </title> <type> Technical Report OR 285-94, </type> <institution> Massachusetts Institute of Technology, </institution> <year> 1994. </year>
Reference-contexts: Our bound is incomparable with theirs, but for any given A, c, and the unit vector b=jjbjj 2 pointing in the direction of b, our bound is always better if B is more than a certain threshold thresh (A; b; c). See Bertsimas & Vohra <ref> [4] </ref> for a detailed study of approximating CIPs; our work improves on all of their randomized rounding bounds except for their weighted CIPs (wherein it is not the case that c i = 1 for all i) for which our bounds are incomparable with theirs. <p> Furthermore, it would be very interesting to study the correlations involved in other relaxation approaches such as semi-definite programming relaxations. Finally, as we had seen before, our bounds are incomparable with known results for some weighted CIPs, e.g., those considered in <ref> [6, 4] </ref>. It would be interesting if our method could be extended to include these results also. Acknowledgements We thank Moni Naor, Babu Narayanan and David Shmoys for their valuable comments. Thanks in particular to Prabhakar Raghavan for his insightful suggestions and pointers to the literature.
Reference: [5] <author> H. Chernoff. </author> <title> A measure of asymptotic efficiency for tests of a hypothesis based on the sum of observations. </title> <journal> Annals of Mathematical Statistics, </journal> <volume> 23 </volume> <pages> 493-509, </pages> <year> 1952. </year>
Reference-contexts: The reader might even consider skipping the proofs of most of the rest of the lemmas, for the first reading. We first recall the Chernoff-Hoeffding (CH) bounds, for the tail probabilities of sums of bounded independent r.v.s <ref> [5, 12] </ref>. Theorem 1 presents these tail bounds; see, e.g., Motwani & Raghavan [16] for the proofs.
Reference: [6] <author> V. Chvatal. </author> <title> A greedy heuristic for the set covering problem. </title> <journal> Mathematics of Operations Research, </journal> <volume> 4 </volume> <pages> 233-235, </pages> <year> 1979. </year>
Reference-contexts: Though randomized rounding is a unifying idea to derive good approximation algorithms, there are better approximation bounds for specific key problems such as set cover (Johnson [13], Lovasz [14], Chvatal <ref> [6] </ref>), hypergraph matching (Aharoni, Erd-os & Linial [1]) and file-sharing in distributed networks (Naor & Roth [17]), each derived through different means. <p> In particular, we improve on the above-mentioned results of [13, 14, 1, 17]; our bound is incomparable with that of <ref> [6] </ref>. 1.3 Approximation bounds achieved Our best improvements are for PIPs. <p> However, this problem is important enough to study approximations parametrized by other parameters of A; b and c, that are always as good as and often much better than, fi (log n); for instance, the work of <ref> [13, 14, 6] </ref> shows a ln d + O (1) approximation bound, where d is the maximum column sum in A-note that d n. Also since there is a trivial solution of size n for any set cover instance, n=y fl is a simple upper bound on the approximation ratio. <p> Furthermore, it would be very interesting to study the correlations involved in other relaxation approaches such as semi-definite programming relaxations. Finally, as we had seen before, our bounds are incomparable with known results for some weighted CIPs, e.g., those considered in <ref> [6, 4] </ref>. It would be interesting if our method could be extended to include these results also. Acknowledgements We thank Moni Naor, Babu Narayanan and David Shmoys for their valuable comments. Thanks in particular to Prabhakar Raghavan for his insightful suggestions and pointers to the literature.
Reference: [7] <author> P. Crescenzi and V. Kann. </author> <title> A compendium of NP optimization problems. </title> <type> Technical Report SI/RR-95/02, </type> <institution> Department of Computer Science, University of Rome "La Sapienza", </institution> <year> 1995. </year>
Reference-contexts: Similar ideas hold for CIPs-the fractions fx fl i g are scaled up by some ff &gt; 1 here. Similar approximation bounds are derived through different methods by Plotkin, Shmoys & Tardos [18]. See Raghavan [20] for a survey of randomized rounding, and Crescenzi & Kann <ref> [7] </ref> for a comprehensive collection of results on NP-optimization problems.
Reference: [8] <author> G. Dobson. </author> <title> Worst-case analysis of greedy heuristics for integer programming with nonnegative data. </title> <journal> Mathematics of Operations Research, </journal> <volume> 7 </volume> <pages> 515-531, </pages> <year> 1982. </year>
Reference-contexts: For covering, we prove an 1 + O (maxfln (nB=y fl )=B; p integrality gap, and derive the corresponding deterministic polynomial-time ap proximation algorithm. This improves on the 1 + O (maxf (ln n)=B; p bound given by the standard analysis of randomized rounding. Also, Dobson <ref> [8] </ref> and Fisher & Wolsey [9] bound the performance of a natural greedy algorithm for CIPs in terms of the optimal integral solution.
Reference: [9] <author> M. L. Fisher and L. A. Wolsey. </author> <title> On the greedy heuristic for continuous covering and packing problems. </title> <journal> SIAM J. on Algebraic and Discrete Methods, </journal> <volume> 3 </volume> <pages> 584-591, </pages> <year> 1982. </year>
Reference-contexts: This improves on the 1 + O (maxf (ln n)=B; p bound given by the standard analysis of randomized rounding. Also, Dobson [8] and Fisher & Wolsey <ref> [9] </ref> bound the performance of a natural greedy algorithm for CIPs in terms of the optimal integral solution.
Reference: [10] <author> C. M. Fortuin, J. Ginibre, and P. N. Kasteleyn. </author> <title> Correlational inequalities for partially ordered sets. </title> <journal> Communications of Mathematical Physics, </journal> <volume> 22 </volume> <pages> 89-103, </pages> <year> 1971. </year>
Reference-contexts: We present an elementary property of all these IPs-positive correlation-and use the FKG inequality (Fortuin, Kasteleyn & Ginibre <ref> [10] </ref>, Sarkar [22]) to derive an improved analysis of randomized rounding on them. <p> We next present Theorem 2, a special case of the powerful FKG inequality <ref> [10, 22] </ref>; for a proof, see, e.g., the proof of Theorem 3.2 in Chapter 6 of [2].
Reference: [11] <author> R. L. Graham. </author> <title> Application of the FKG Inequality and its Relatives. </title> <editor> In A. Bachem, M. Grotschel and B. Korte Ed., </editor> <booktitle> Mathematical Programming: The State of the Art, </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1983. </year>
Reference-contexts: Thus, P r ( i=1 n _ E i ) + P r (E n+1 ) 1 ( i=1 which is always as good as, and most often much better than, (1). (For a detailed study of the FKG inequality, see, e.g., Graham <ref> [11] </ref> and Chapter 6 of Alon, Spencer & Erd-os [2].) It is not hard to verify such a property for CIPs also.
Reference: [12] <author> W. Hoeffding. </author> <title> Probability inequalities for sums of bounded random variables. </title> <journal> American Statistical Association Journal, </journal> <volume> 58 </volume> <pages> 13-30, </pages> <year> 1963. </year>
Reference-contexts: The reader might even consider skipping the proofs of most of the rest of the lemmas, for the first reading. We first recall the Chernoff-Hoeffding (CH) bounds, for the tail probabilities of sums of bounded independent r.v.s <ref> [5, 12] </ref>. Theorem 1 presents these tail bounds; see, e.g., Motwani & Raghavan [16] for the proofs.
Reference: [13] <author> D. S. Johnson. </author> <title> Approximation algorithms for combinatorial problems. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 9 </volume> <pages> 256-278, </pages> <year> 1974. </year>
Reference-contexts: See Raghavan [20] for a survey of randomized rounding, and Crescenzi & Kann [7] for a comprehensive collection of results on NP-optimization problems. Though randomized rounding is a unifying idea to derive good approximation algorithms, there are better approximation bounds for specific key problems such as set cover (Johnson <ref> [13] </ref>, Lovasz [14], Chvatal [6]), hypergraph matching (Aharoni, Erd-os & Linial [1]) and file-sharing in distributed networks (Naor & Roth [17]), each derived through different means. <p> Thus we get, in a unified way, improved bounds on the integrality gap maxf (c T z)=y fl ; y fl =(c T z)g and hence, improved approximation algorithms for all PIPs and CIPs. In particular, we improve on the above-mentioned results of <ref> [13, 14, 1, 17] </ref>; our bound is incomparable with that of [6]. 1.3 Approximation bounds achieved Our best improvements are for PIPs. <p> However, this problem is important enough to study approximations parametrized by other parameters of A; b and c, that are always as good as and often much better than, fi (log n); for instance, the work of <ref> [13, 14, 6] </ref> shows a ln d + O (1) approximation bound, where d is the maximum column sum in A-note that d n. Also since there is a trivial solution of size n for any set cover instance, n=y fl is a simple upper bound on the approximation ratio.
Reference: [14] <author> L. Lovasz. </author> <title> On the ratio of optimal integral and fractional covers. </title> <journal> Discrete Mathematics, </journal> <volume> 13 </volume> <pages> 383-390, </pages> <year> 1975. </year>
Reference-contexts: Though randomized rounding is a unifying idea to derive good approximation algorithms, there are better approximation bounds for specific key problems such as set cover (Johnson [13], Lovasz <ref> [14] </ref>, Chvatal [6]), hypergraph matching (Aharoni, Erd-os & Linial [1]) and file-sharing in distributed networks (Naor & Roth [17]), each derived through different means. <p> Thus we get, in a unified way, improved bounds on the integrality gap maxf (c T z)=y fl ; y fl =(c T z)g and hence, improved approximation algorithms for all PIPs and CIPs. In particular, we improve on the above-mentioned results of <ref> [13, 14, 1, 17] </ref>; our bound is incomparable with that of [6]. 1.3 Approximation bounds achieved Our best improvements are for PIPs. <p> This method also gives Turan's classical theorem on independent sets in graphs [25] to within a constant factor. An important packing problem where A 2 f0; 1g nfim is simple B-matching in hypergraphs <ref> [14] </ref>: given a hypergraph with non-negative edge weights, finding a maximum weight collection of edges such that no vertex occurs in more than B of them. Usual hypergraph matching has B = 1, and is a well-known NP-hard problem. <p> However, this problem is important enough to study approximations parametrized by other parameters of A; b and c, that are always as good as and often much better than, fi (log n); for instance, the work of <ref> [13, 14, 6] </ref> shows a ln d + O (1) approximation bound, where d is the maximum column sum in A-note that d n. Also since there is a trivial solution of size n for any set cover instance, n=y fl is a simple upper bound on the approximation ratio.
Reference: [15] <author> C. Lund and M. Yannakakis. </author> <title> On the hardness of approximating minimization problems. </title> <journal> Journal of the ACM, </journal> <volume> 41 </volume> <pages> 960-981, </pages> <year> 1994. </year>
Reference-contexts: For set cover, we tighten the constants in (4) to derive an ln (n=y fl ) + O (ln ln (n=y fl )) + O (1) approximation bound. The work of Lund & Yannakakis <ref> [15] </ref> and Bellare, Gold-wasser, Lund & Russell [3] shows a constant a &gt; 0 such that approximating this problem to within a ln n is likely to take super-polynomial time.
Reference: [16] <author> R. Motwani and P. Raghavan. </author> <title> Randomized Algorithms. </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year> <month> 23 </month>
Reference-contexts: We first recall the Chernoff-Hoeffding (CH) bounds, for the tail probabilities of sums of bounded independent r.v.s [5, 12]. Theorem 1 presents these tail bounds; see, e.g., Motwani & Raghavan <ref> [16] </ref> for the proofs. Theorem 1 Let X 1 ; X 2 ; : : : ; X ` be independent r.v.s, each taking values in [0; 1], with R = P ` i=1 X i and E [R] = .
Reference: [17] <author> M. Naor and R. M. Roth. </author> <title> Optimal file sharing in distributed networks. </title> <journal> SIAM Journal on Computing, </journal> <volume> 24 </volume> <pages> 158-183, </pages> <year> 1995. </year>
Reference-contexts: Though randomized rounding is a unifying idea to derive good approximation algorithms, there are better approximation bounds for specific key problems such as set cover (Johnson [13], Lovasz [14], Chvatal [6]), hypergraph matching (Aharoni, Erd-os & Linial [1]) and file-sharing in distributed networks (Naor & Roth <ref> [17] </ref>), each derived through different means. One reason for this slack stems from bounding P r ( W n+1 P n+1 i=1 P r (E i ): to quote Raghavan [19], Throughout, we naively (?) sum the probabilities of all bad events-although these bad events are surely correlated. <p> Thus we get, in a unified way, improved bounds on the integrality gap maxf (c T z)=y fl ; y fl =(c T z)g and hence, improved approximation algorithms for all PIPs and CIPs. In particular, we improve on the above-mentioned results of <ref> [13, 14, 1, 17] </ref>; our bound is incomparable with that of [6]. 1.3 Approximation bounds achieved Our best improvements are for PIPs. <p> This is also a key subproblem in sharing files in a distributed system <ref> [17] </ref>; under the assumption that G is undirected and letting be its maximum degree, an 1 + O (maxfln ()=B; p approximation bound is presented in [17], improving on the standard analysis of randomized rounding. <p> This is also a key subproblem in sharing files in a distributed system <ref> [17] </ref>; under the assumption that G is undirected and letting be its maximum degree, an 1 + O (maxfln ()=B; p approximation bound is presented in [17], improving on the standard analysis of randomized rounding. Bound (4) improves further on this; in particular, even if G is directed with maximum in-degree , (4) shows that the Naor-Roth bound holds. <p> For the case where G is undirected with maximum degree , an approximation bound of 1 + O (maxfln ()=B; p is presented in <ref> [17] </ref>, improving on the 1 + O (maxfln (n)=B; p bound given by the standard analysis of randomized rounding. <p> In addition to its independent interest, the above problem is a crucial sub-problem in the following file-sharing problem in distributed networks <ref> [17] </ref>. <p> every node can recover F by examining the contents of its neighbor's memories; the aim is to minimize the total amount of memory used. (Note that solving the above domination problem is not sufficient for this task.) An approximation bound of 1 + O (maxfln ()=B; p is presented in <ref> [17] </ref> for this problem.
Reference: [18] <author> S. A. Plotkin, D. B. Shmoys, and E. Tardos. </author> <title> Fast approximation algorithms for fractional packing and covering problems. </title> <booktitle> In Proc. IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 495-504, </pages> <year> 1991. </year> <note> To appear in Mathematics of Operations Research. </note>
Reference-contexts: Similar ideas hold for CIPs-the fractions fx fl i g are scaled up by some ff &gt; 1 here. Similar approximation bounds are derived through different methods by Plotkin, Shmoys & Tardos <ref> [18] </ref>. See Raghavan [20] for a survey of randomized rounding, and Crescenzi & Kann [7] for a comprehensive collection of results on NP-optimization problems.
Reference: [19] <author> P. Raghavan. </author> <title> Probabilistic construction of deterministic algorithms: approximating packing integer programs. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 37 </volume> <pages> 130-143, </pages> <year> 1988. </year>
Reference-contexts: This gives us an (fffi)-approximation z with nonzero probability, which is also made deterministic by Raghavan, using pessimistic estimators <ref> [19] </ref>. Similar ideas hold for CIPs-the fractions fx fl i g are scaled up by some ff &gt; 1 here. Similar approximation bounds are derived through different methods by Plotkin, Shmoys & Tardos [18]. <p> One reason for this slack stems from bounding P r ( W n+1 P n+1 i=1 P r (E i ): to quote Raghavan <ref> [19] </ref>, Throughout, we naively (?) sum the probabilities of all bad events-although these bad events are surely correlated. <p> The problem in arriving at a good pessimistic estimator is that while the previous estimator P n+1 i=1 P r (E i ) (i.e., the one used in <ref> [19] </ref> and in related papers) is upper-bounded by E [Z] (for some random variable Z) on applying the CH bounds, such a fact does not seem to hold here. Nevertheless, the structure of CIPs/PIPs-in particular, the two simple properties itemized above-help in providing a good pessimistic estimator. <p> Then, P r p ( i=1 s Y P r p (F i ); and P r p ( i=1 s Y P r p (G i ): 2 Finally, we recall the notion of pessimistic estimators <ref> [19] </ref>. For our purposes, we focus on the case of independent binary r.v.s. Let X 1 ; X 2 ; : : :; X ` 2 f0; 1g be independent r.v.s with P r (X i = 1) = p i , for some p 2 [0; 1] ` . <p> Suppose, for some implicitly defined L f0; 1g ` , that P r (X (`) 2 L) &lt; 1: How do we find some v 2 f0; 1g ` L? Theorem 3 now presents the idea of pessimistic estimators applied to the method of conditional probabilities. See <ref> [19] </ref> for a detailed discussion and proof. <p> 2 f0; 1g , (a) U (u (i; w; p)) P r (X (`) 2 LjX (i) = w), and (b) if i ` 1, then U (u (i; w; p)) is at least minfU (u (i + 1; w0; p)); U (u (i + 1; w1; p))g: Theorem 3 <ref> [19] </ref> Let an efficiently computable U be a pessimistic estimator w.r.t. (X 1 ; : : : ; X ` ) and L.
Reference: [20] <author> P. Raghavan. </author> <title> Randomized approximation algorithms in combinatorial optimization. </title> <booktitle> In Proc. FST & TCS Conference, </booktitle> <pages> pages 300-317, </pages> <year> 1994. </year> <booktitle> Lecture Notes in Computer Science 880, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin. </address>
Reference-contexts: Similar ideas hold for CIPs-the fractions fx fl i g are scaled up by some ff &gt; 1 here. Similar approximation bounds are derived through different methods by Plotkin, Shmoys & Tardos [18]. See Raghavan <ref> [20] </ref> for a survey of randomized rounding, and Crescenzi & Kann [7] for a comprehensive collection of results on NP-optimization problems.
Reference: [21] <author> P. Raghavan and C. D. Thompson. </author> <title> Randomized rounding: a technique for provably good algorithms and algorithmic proofs. </title> <journal> Combinatorica, </journal> <volume> 7 </volume> <pages> 365-374, </pages> <year> 1987. </year>
Reference-contexts: 1 Introduction Several important NP-hard combinatorial optimization problems such as basic problems on graphs and hypergraphs, can be posed as packing/covering integer programs; the randomized rounding technique of Raghavan & Thompson is a powerful tool to approximate them well <ref> [21] </ref>. We present an elementary property of all these IPs-positive correlation-and use the FKG inequality (Fortuin, Kasteleyn & Ginibre [10], Sarkar [22]) to derive an improved analysis of randomized rounding on them. <p> However, it is known that such "thresholding" methods are of limited applicability. A key technique to approximate a class of integer programming problems via a new rounding method-randomized rounding-was proposed in <ref> [21] </ref>. Given a positive real v, the idea is to look at its fractional part as a probability-round v to bvc + 1 with probability v bvc, and round v to bvc with probability 1 v + bvc. <p> This is formalized in <ref> [21] </ref> as follows. As seen above, an important observation is that E [z i ] = x 0 i .
Reference: [22] <author> T. K. Sarkar. </author> <title> Some lower bounds of reliability. </title> <type> Technical Report 124, </type> <institution> Department of Operations Research and Statistics, Stanford University, </institution> <year> 1969. </year>
Reference-contexts: We present an elementary property of all these IPs-positive correlation-and use the FKG inequality (Fortuin, Kasteleyn & Ginibre [10], Sarkar <ref> [22] </ref>) to derive an improved analysis of randomized rounding on them. <p> We next present Theorem 2, a special case of the powerful FKG inequality <ref> [10, 22] </ref>; for a proof, see, e.g., the proof of Theorem 3.2 in Chapter 6 of [2].
Reference: [23] <author> J. H. Spencer. </author> <title> Ten Lectures on the Probabilistic Method. </title> <publisher> SIAM, </publisher> <address> Philadel-phia, </address> <year> 1987. </year>
Reference-contexts: The precise reasons for such a correlation are spelled out in Section 1.2. It is a challenging open question to use the structure of correlations in more complicated scenarios; one such problem is the set discrepancy problem <ref> [23, 2] </ref>. <p> come up with a function : A ! f1; 1g, such that the discrepancy disc ( ) : is "small", where (S i ) = j2S i While randomized rounding and the method of conditional probabilities can be used to produce a with discrepancy O ( p n log n) <ref> [23, 2] </ref>, a classical nonconstructive result of Spencer shows the existence of a with disc ( ) = O ( p [24]. This is best possible, and it is an important open problem to make this constructive.
Reference: [24] <author> J. H. Spencer. </author> <title> Six standard deviations suffice. </title> <journal> Transactions of the American Mathematical Society, </journal> <volume> 289 </volume> <pages> 679-706, </pages> <year> 1985. </year>
Reference-contexts: (S i ) = j2S i While randomized rounding and the method of conditional probabilities can be used to produce a with discrepancy O ( p n log n) [23, 2], a classical nonconstructive result of Spencer shows the existence of a with disc ( ) = O ( p <ref> [24] </ref>. This is best possible, and it is an important open problem to make this constructive.
Reference: [25] <author> P. Turan. </author> <title> On an extremal problem in graph theory. </title> <journal> Matematicko Fizicki Lapok, </journal> <volume> 48 </volume> <pages> 436-452, </pages> <year> 1941. </year> <note> (See, for instance, pages 81 and 82 in N. </note> <author> Alon, J. H. Spencer and P. Erd-os, </author> <title> The Probabilistic Method, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1992.) </year> <month> 24 </month>
Reference-contexts: This method also gives Turan's classical theorem on independent sets in graphs <ref> [25] </ref> to within a constant factor. An important packing problem where A 2 f0; 1g nfim is simple B-matching in hypergraphs [14]: given a hypergraph with non-negative edge weights, finding a maximum weight collection of edges such that no vertex occurs in more than B of them. <p> Though we do not get improved approximation algorithms for this problem, a few observations on this important problem are relevant, as we shall see shortly. Turan's classical theorem <ref> [25] </ref> shows that G always has an independent set of size at least jV j 2 =(2jEj + jV j); such a set can also be found in polynomial time.
References-found: 25

