URL: http://www.cs.berkeley.edu/~kozyraki/project/cs252/paper.ps
Refering-URL: http://www.cs.berkeley.edu/~kozyraki/project/cs252/
Root-URL: 
Email: fkozyraki,helenjwg@cs.berkeley.edu  
Title: Evaluation and Comparison of Existing Cache Designs Implemented as an IRAM  
Author: Christoforos E. Kozyrakis and Helen J. Wang 
Affiliation: University of California at Berkeley Computer Science Division  
Abstract: The increasing processor-memory speed gap has become a performance limitation for current microprocessors. The integration of processor and memory in a single DRAM chip has been proposed in order to overcome this problem. Such an architecture will provide high memory bandwidth and low memory latency, but may have to compensate for slower logic. In this paper, we use a study of program's execution time and an analytical model in order to evaluate the potential performance of IRAM architectures as a function of process parameters, such as the speed of logic and memory access in a DRAM chip. For memory intensive applications, IRAM is faster than conventional implementations, even when logic is 1.5 times slower compared to microprocessor processes. Maximum speedup achieved varies between 1.3 and 1.9. For CPU intensive applications, almost no logic slowdown is necessary for IRAM to achieve comparable performance. We compare the IRAM implementations of simple and a complex processor/cache architecture and find that the first performs comparably and, for some applications, even better than the first one. Finally, we discover that the IRAM implementation of a simple architecture can be 1.5 to 2.8 times faster than the conventional implementation of a complex one. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <institution> Galileo project. http://www.cs.wisc.edu/ galileo/. Computer Science Department, University of Wisconin - Madison. </institution>
Reference-contexts: Several attempts to integrate processor and memory have been made in order to design building blocks for parallel computers. Some of the systems in this category are the J-Machine [15], MOSAIC-C, Exe-cube [21] and the M-Machine [16]. Finally, the Galileo project <ref> [1] </ref> at the University of Wisconsin and PPRAM project [2] at Kyushu University are also exploring various issues in processor-memory integration. 7 Future Work In terms of this specific study, it would be interesting to repeat the same analysis for some additional applications, like a database server or more floating point
Reference: [2] <institution> PPRAM project. http://kasuga.csce.kyushu-u.ac.jp/ ppram/. Computer Science Division, Kyushu Univeristy, </institution> <address> Japan. </address>
Reference-contexts: Some of the systems in this category are the J-Machine [15], MOSAIC-C, Exe-cube [21] and the M-Machine [16]. Finally, the Galileo project [1] at the University of Wisconsin and PPRAM project <ref> [2] </ref> at Kyushu University are also exploring various issues in processor-memory integration. 7 Future Work In terms of this specific study, it would be interesting to repeat the same analysis for some additional applications, like a database server or more floating point programs for example.
Reference: [3] <editor> SPEC95 CPU Benchmarks. </editor> <address> http://www.specbench.org/osg/cpu95/. </address>
Reference-contexts: By adding these two components, time in processor and time in on-chip DRAM, we can estimate the IRAM execution time as a function of two variables : the logic and DRAM slowdown in a DRAM process. 3.2 Benchmarks and Applications used for the evaluation. SPEC95 <ref> [3] </ref> is the current accepted standard metric of uniprocessor performance. We use the eight integer programs (SPECint95) from this suite. These benchmarks are considered to be CPU intensive and to put very little pressure on the memory hierarchy.
Reference: [4] <author> DECchip 21064-AA Microprocessor Hardware Reference Manual, </author> <year> 1992. </year> <month> 13 </month>
Reference-contexts: This paper addresses this issue by comparing the expected performance of an IRAM implementation of a simple architecture to that of a complex one. We use two existing processor architectures, the 21064 Alpha <ref> [4] </ref>, a simple dual-issue in-order processor, and the Pentium Pro [9], a complex triple-issue out-of-order speculative processor, to estimate the performance of an IRAM implementation of similar organizations. <p> The effect on the total run time of the pro grams is negligible. In addition, it is much faster and easier to use compared to simulator development. Alpha 21064 has two programmable 16-bit hardware counters <ref> [4] </ref> that allow us to monitor various events in the processor and the memory hierarchy like: cycles, issues, non-issues, pipeline stall cycles, memory misses, mispredictions, instruction types etc. The data collection is based on interrupt handling upon counter overflow.
Reference: [5] <editor> Pentium Pro Family Developer's Manual, </editor> <booktitle> Vol--ume 3: Operating System Writer's Manual, </booktitle> <year> 1996. </year>
Reference-contexts: The data collection is based on interrupt handling upon counter overflow. Pentium Pro has two programmable 40-bit hardware counters that can measure a vast number of events related to the processor, memory hierarchy or bus system <ref> [5] </ref>. Data collection is done by reading the actual counter values 3 . Using the hardware counter involved developing or porting the corresponding device drivers, access tools and result processing tools under DEC OSF1 V3.0 for Alpha, and BSD/OS V2.1 for Pentium Pro.
Reference: [6] <editor> Y. Aimoto et al. A 7.68 GIPS, </editor> <booktitle> 3.84 GB/s 1W Parallel Image-Processing RAM Integrating a 16 Mb DRAM and 128 Processors. In Digest of Technical Papers, 1996 IEEE International Solid-State Circuits Conference, </booktitle> <pages> pages 372-373, 476, </pages> <address> San Francisco, CA, </address> <month> February </month> <year> 1996. </year>
Reference: [7] <author> A. Arpaci-Dusseau et al. </author> <title> High-performance sorting on networks of workstations. </title> <year> 1996. </year>
Reference-contexts: In addition, it is doubtful if they efficiently represent all possible workloads on a current processor. In order to compensate for that and increase the validity of our work, we use three additional applications: sort <ref> [7] </ref>, which is representative of the databases field, where operations are performed on large collections of data; mpeg encode [28], which is a characteristic multimedia application, and finally linpack, that represents programs for scientific computations.
Reference: [8] <author> D. Bhandarkar and D. Clark. </author> <title> Measuring VAX 8800 Performance with Historogram Hardware Monitor. </title> <booktitle> In Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 301-310, </pages> <year> 1984. </year>
Reference: [9] <author> D. Bhandarkar and J. Ding. </author> <title> Performance characterization of the Pentium Pro processor. </title> <booktitle> In Proceedings of the Third International Symposium on High-Performance Computer Architecture (to appear), </booktitle> <month> February </month> <year> 1997. </year>
Reference-contexts: This paper addresses this issue by comparing the expected performance of an IRAM implementation of a simple architecture to that of a complex one. We use two existing processor architectures, the 21064 Alpha [4], a simple dual-issue in-order processor, and the Pentium Pro <ref> [9] </ref>, a complex triple-issue out-of-order speculative processor, to estimate the performance of an IRAM implementation of similar organizations. <p> considering the fact that the capacity of DRAM increases by 60% year and that the 256Mbit and 1Gbit DRAM generations have already been demonstrated. 3 Methodology To evaluate the expected performance of IRAM, we use two existing processor/cache architectures : the DEC 21064 Alpha [11] and the Intel Pentium Pro <ref> [9] </ref>. The main features of the two processors are summarized in figure 2. <p> So, one can view our results as a lower bound or worst case prediction of the performance of IRAM. Analytical models are difficult to develop for the case of out-of-order and speculative architectures, like the one of Pentium Pro, due to the extended parallelism <ref> [9] </ref>. In order to avoid not including parallelism in our study, we use optimistic delays for all operations in Pentium Pro (e.g. the cost of a first-level cache miss).
Reference: [10] <author> W. Bowman, N. Cardwell, and C. Cromer. </author> <title> IRAM System Simulation, </title> <year> 1996. </year>
Reference-contexts: Its goal is to present performance trends, identify the effect of specific issues on performance and estimate the value of speedup that can be expect from IRAM for specific application groups. Detailed simulations of IRAM architectures using the SimOs [27] environment, that are currently performed by Bowman et.al. <ref> [10] </ref>, present results that accurately match those stated in this paper. In addition, our model only uses the low memory advantage of IRAM in order to evaluate the potential performance gains.
Reference: [11] <author> Z. Cvetanovic and D. Bhandarkar. </author> <title> Characterization of ALPHA AXP performance using TP and SPEC woarkloads. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 60-70, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Nevertheless, this is feasible even with currently available commercial DRAM technology. A 64Mbit DRAM chip, designed in a 0:4m CMOS process, can be 186mm 2 big [22]. The original Alpha 21064, designed in a 0:75m CMOS process occupies 234mm 2 <ref> [11] </ref>. Scaling Alpha to the 0:4m CMOS process, reduces its size roughly to 66mm 2 . Therefore, we can implement the processor in the DRAM chip and still have one third of the die size available for DRAM memory. <p> the feasibility of the design, especially considering the fact that the capacity of DRAM increases by 60% year and that the 256Mbit and 1Gbit DRAM generations have already been demonstrated. 3 Methodology To evaluate the expected performance of IRAM, we use two existing processor/cache architectures : the DEC 21064 Alpha <ref> [11] </ref> and the Intel Pentium Pro [9]. The main features of the two processors are summarized in figure 2.
Reference: [12] <author> Z. Cvetanovic and D. Bhandarkar. </author> <title> Performance characterization of the Alpha 21164 microprocessor using TP and SPEC workloads. </title> <booktitle> In Proceedings of the Second International Symposium on High-Performance Computer Architecture, </booktitle> <pages> pages 270-280, </pages> <address> San Jose, CA, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: Yet, the results of this approach are disappointing for several categories of applications like databases or CAD programs, where most of the execution time is spent in the memory hierarchy <ref> [12] </ref>. In addition, it is doubtful if this solution will be able to feed future superscalar and speculative processors with data at low latencies. An alternative approach is to integrate the processor and the main memory in a single chip. This idea is known as Intelligent RAM (IRAM) [24][25].
Reference: [13] <author> M. Deering and S. Schlapp. FBRAM: </author> <title> a new form of memory optimized for 3D graphics. </title> <booktitle> In Proceedings of the SIGGRAPH 94 Conference, </booktitle> <pages> pages 167-74, </pages> <month> July </month> <year> 1994. </year>
Reference: [14] <author> C. Noakes et.al. </author> <title> Instruction Level Profiling of the RS/6000. </title> <booktitle> In Proceedings of the 18st Annual International Symposiu m on Computer Architecture, </booktitle> <pages> pages 180-189, </pages> <month> May </month> <year> 1991. </year>
Reference: [15] <author> M. Noakes et.al. </author> <title> The J-Machine multicomputer: an architectural evaluation. </title> <booktitle> In Proceedings of the 20st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 224-235, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Integration of processor and memory has also been used for graphics accelerators and image-processing devices [13][6]. Several attempts to integrate processor and memory have been made in order to design building blocks for parallel computers. Some of the systems in this category are the J-Machine <ref> [15] </ref>, MOSAIC-C, Exe-cube [21] and the M-Machine [16].
Reference: [16] <editor> M. Fillo et al. </editor> <booktitle> The M-Machine multicomputer. In Proceedings of the 28th Annual International Symposium on Microarchitecture, </booktitle> <pages> pages 146-156, </pages> <address> Ann Arbor, MI, </address> <month> November </month> <year> 1995. </year>
Reference-contexts: Several attempts to integrate processor and memory have been made in order to design building blocks for parallel computers. Some of the systems in this category are the J-Machine [15], MOSAIC-C, Exe-cube [21] and the M-Machine <ref> [16] </ref>.
Reference: [17] <author> R. Fromm et al. </author> <title> The Energy Efficiency of IRAM Architectures. </title> <booktitle> paper submitted to the 23rd International Symposium on Computer Architecture, </booktitle> <month> May </month> <year> 1996. </year>
Reference-contexts: Consequently, the DRAM slowdown factor is less than one. 2 Comparing bits per area for DRAM and SRAM reveals that DRAM is 16 to 32 time denser <ref> [17] </ref>. into account many issues like the logic density in a DRAM processes, but do point the feasibility of the design, especially considering the fact that the capacity of DRAM increases by 60% year and that the 256Mbit and 1Gbit DRAM generations have already been demonstrated. 3 Methodology To evaluate the
Reference: [18] <author> G. Giacalone et al. </author> <title> A 1 MB, 100 MHz integrated L2 cache memory with 128b interface and ECC protection. </title> <booktitle> In Digest of Technical Papers, 1996 IEEE International Solid-State Circuits Conference, </booktitle> <pages> pages 370-371, </pages> <address> San Francisco, CA, </address> <month> Febru-ary </month> <year> 1996. </year>
Reference-contexts: Saulsbury et.al. [29] evaluated the performance of a single-scalar SPARC CPU, implemented in a 256Mbit DRAM, using sense-amps as caches. They found that, for optimistic process parameters, they get comparable performance for integer programs and and half performance for floating-point programs. Giacalone et.al. <ref> [18] </ref> presented an chip that implements second-level cache with DRAM. Integration of processor and memory has also been used for graphics accelerators and image-processing devices [13][6]. Several attempts to integrate processor and memory have been made in order to design building blocks for parallel computers.
Reference: [19] <author> J. Hennessy and D. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers, Inc, </publisher> <address> San Francisco, CA, </address> <year> 1996. </year>
Reference-contexts: Logic processes, developed for microprocessor design, provide fast transistors and many layers of metal in order to accelerate logic and communication within a chip. The speed of microprocessors has been improving by 60% per year for over a decade <ref> [19] </ref>. On the other hand, DRAM processes, used for production of memory chips, are optimized for high memory density and low cost. While DRAM capacity has been increasing at an exponential rate, its latency has improved by 10% within the same ten years.
Reference: [20] <author> M. Horiguchi et al. </author> <title> An experimental 220MHz 1 Gb DRAM. </title> <booktitle> In Proceedings of the IEEE International Solid-State Circuits Conference, </booktitle> <volume> volume 38, </volume> <pages> pages 252-253, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: This idea is known as Intelligent RAM (IRAM) [24][25]. Since the largest portion of an IRAM die will be dedicated to memory, it is logical to fabricate such a chip in a DRAM process. The upcoming 256 Mbit and 1 Gbit DRAM generations <ref> [20] </ref> [22] have enough capacity both for a processor core and enough memory for whole programs and data sets to fit on chip.
Reference: [21] <author> P. Kogge. </author> <title> EXECUBE ANew Architecture for Scaleable MPPS. </title> <booktitle> In Proceedings of the 1994 International Conference on Parallel Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 77-84, </pages> <address> Raleigh, NC, </address> <month> August </month> <year> 1994. </year>
Reference-contexts: Integration of processor and memory has also been used for graphics accelerators and image-processing devices [13][6]. Several attempts to integrate processor and memory have been made in order to design building blocks for parallel computers. Some of the systems in this category are the J-Machine [15], MOSAIC-C, Exe-cube <ref> [21] </ref> and the M-Machine [16].
Reference: [22] <author> H. Koike et al. </author> <title> A 30ns 64Mb DRAM with built-in self-test and repair function. </title> <booktitle> In Digest of Technical Papers, 1996 IEEE International Solid-State Circuits Conference, </booktitle> <pages> pages 150-151, 270, </pages> <address> San Francisco, CA, </address> <month> February </month> <year> 1996. </year>
Reference-contexts: This idea is known as Intelligent RAM (IRAM) [24][25]. Since the largest portion of an IRAM die will be dedicated to memory, it is logical to fabricate such a chip in a DRAM process. The upcoming 256 Mbit and 1 Gbit DRAM generations [20] <ref> [22] </ref> have enough capacity both for a processor core and enough memory for whole programs and data sets to fit on chip. <p> 8KB (DM) 8KB (4 way SA) L2 cache 256KB (off-chip) 256KB (off-chip) Memory Latency (L1/L2/DRAM) 22.5ns/52.5ns/277.5ns 15ns/35ns/285ns Transistors 1.7M 5.5M Die Size 234 mm 2 306 mm 2 Technology 0:75m CMOS 0:35m BiCMOS SPECint92 74.7 320 SPECfp92 112.5 283 have already demonstrated that such low memory access times are achievable <ref> [22] </ref>. In order to quantify the effect and importance of each factor, we estimate the expected performance of IRAM architectures for the regions of values 1 presented in figure 1. The structure of an IRAM architecture is also under research for the moment. <p> It may seem that it is hard to fit all these components in a single chip. Nevertheless, this is feasible even with currently available commercial DRAM technology. A 64Mbit DRAM chip, designed in a 0:4m CMOS process, can be 186mm 2 big <ref> [22] </ref>. The original Alpha 21064, designed in a 0:75m CMOS process occupies 234mm 2 [11]. Scaling Alpha to the 0:4m CMOS process, reduces its size roughly to 66mm 2 .
Reference: [23] <author> L. McVoy and C. Staelin. lmbench: </author> <title> Portable tools for performance analysis. </title> <booktitle> In Proceedings of the USENIX 1996 Annual Technical Conference, </booktitle> <month> January </month> <year> 1996. </year>
Reference-contexts: A variation of sort that has a larger working set and a study of the importance of the cost of off-chip accesses in IRAM is presented later on. We avoid using microbenchmarks like lmbench, STREAM etc <ref> [23] </ref>. Such benchmarks do not represent any real application or workload. They are especially developed to stress a particular part of the system and measure its behavior and performance.
Reference: [24] <author> D. Patterson, T. Anderson, and K. Yelick. </author> <title> A Case for Intelligent DRAM: </title> <booktitle> IRAM. In HotChips VIII, </booktitle> <pages> pages 75-93, </pages> <address> Stanford, CA, </address> <year> 1996. </year>
Reference: [25] <author> D. Patterson et al. </author> <title> Intelligent ram (IRAM): Chips that remember and compute. </title> <booktitle> In To appear in 1997 IEEE International Solid-State Circuits Conference, </booktitle> <address> San Francisco, CA, </address> <month> February </month> <year> 1997. </year>
Reference-contexts: SRAM on a DRAM chip is expected to be 1.1 to 1.3 times slower compared compared to a logic process. Finally, DRAM, or main memory, access time will dramatically improve due to the elimination of off-chip buses and memory controllers <ref> [25] </ref>. The expected benefit is a speedup between 5 and 10.
Reference: [26] <author> Steven A. </author> <title> Przybylski. </title> <publisher> New DRAM Technologies: </publisher>
Reference-contexts: This can result to a slower CPU core for IRAM compared to that 1 Optimistic Slowdown Factor Pessimistic Slowdown Factor Logic 1.0 2.0 SRAM 1.1 1.3 DRAM 0.1 0.2 in a conventional processor <ref> [26] </ref>. The logic slowdown can significantly affect the performance of IRAM and even completely cancel the speedup gained by accelerating memory accesses. The first contribution of this work is to estimate effect of the logic slowdown and the memory access speedup on the expected performance of IRAM.
References-found: 26

