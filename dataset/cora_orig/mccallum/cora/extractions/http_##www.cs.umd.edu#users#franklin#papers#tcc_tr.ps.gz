URL: http://www.cs.umd.edu/users/franklin/papers/tcc_tr.ps.gz
Refering-URL: http://www.cs.umd.edu/projects/dimsum/papers/
Root-URL: 
Title: Transactional Client-Server Cache Consistency: Alternatives and Performance  
Author: Michael J. Franklin Michael J. Carey Miron Livny 
Date: 1995  
Note: September  
Affiliation: University of Maryland IBM Almaden Research Center University of Wisconsin  
Abstract: University of Maryland College Park Technical Report CS-TR-3511 and UMIACS TR 95-84 Abstract Client-server database systems based on a page server model can exploit client memory resources by caching copies of pages across transaction boundaries. Caching reduces the need to obtain data from servers or other sites on the network. In order to ensure that such caching does not result in the violation of transaction semantics, a cache consistency maintenance algorithm is required. Many such algorithms have been proposed in the literature and, as all provide the same functionality, performance is a primary concern in choosing among them. In this paper we provide a taxonomy that describes the design space for transactional cache consistency maintenance algorithms and show how proposed algorithms relate to one another. We then investigate the performance of six of these algorithms, and use these results to examine the tradeoffs inherent in the design choices identified in the taxonomy. The insight gained in this manner is then used to reflect upon the characteristics of other algorithms that have been proposed. The results show that the interactions among dimensions of the design space can impact performance in many ways, and that classifications of algorithms as simply "pessimistic" or "optimistic" do not accurately characterize the similarities and differences among the many possible cache consistency algorithms.
Abstract-found: 1
Intro-found: 1
Reference: [Adya95] <author> Adya, A., Gruber, R., Liskov, B., Maheshwari, U., </author> <title> "Efficient Optimistic Concurrency Control Using Loosely Synchronized Clocks" Proceedings of the ACM SIGMOD International Conference on the Management of Data, </title> <address> San Jose, CA, </address> <month> June, </month> <year> 1995. </year>
Reference-contexts: In contrast, inter-transaction data caching raises the need for a cache consistency protocol to ensure that applications always see a consistent (serializable) view of the database. Cache consistency protocols for client-server database systems have been the subject of much study over the past five years <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. Many algorithms have been proposed; these algorithms differ along numerous dimensions such as their level of optimism versus pessimism, their use of invalidation or propagation (i.e., write-invalidate or write-broadcast [Arch86]) for updated data items, and their interaction with transaction management. <p> As a result, there is a wide range of options for the design of such algorithms. This section provides a taxonomy of transactional cache consistency algorithms that encompasses the major algorithms that have appeared in the literature, including <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. All of these algorithms provide one-copy serializability and are applicable to page server DBMSs (although some were originally proposed for object servers). The taxonomy is shown in two parts in Figures 2 and 3. The figures show where proposed algorithms fit in the taxonomy. <p> Of course, the use of avoidance obviates any possible need for detection, so there is no augmentation in the opposite direction within the taxonomy. 3.2 Detection-based Algorithms A number of detection-based algorithms (shown in Figure 2) have been proposed and studied in the literature <ref> [Kim90, Wilk90, Care91a, Wang91, Adya95] </ref>. The main argument for the detection-based approach is simplicity. Because their consistency actions involve only a single client and the server, the detection-based approaches allow the cache management software on the clients to be greatly simplified compared to the ROWA approach. <p> Two approaches to reducing the potential for aborts in optimistic techniques have been proposed. One is to simply treat "hot spot" data differently, e.g., by switching to a more pessimistic protocol for such data (e.g., <ref> [Adya95] </ref>). The details of such adaptive algorithms have not yet been published, however. The other approach is to borrow techniques from the avoidance-based (ROWA) algorithms on the other side of the taxonomy to reduce the amount of stale data that resides in client caches. <p> More recently, an optimistic algorithm with notifications has been proposed for the Thor system at MIT <ref> [Adya95] </ref>. This algorithm, called Adaptive Optimistic Concurrency Control (AOCC), is similar to the Cache Locks algorithm; it also includes support for transactions that access data from multiple servers (which is beyond the scope of both [Wilk90] and this paper). <p> Rather than using lock modes to represent invalid cached copies, AOCC maintains an invalid set for each client in order to keep track of which copies of the data items cached at a client have been made invalid. As described in <ref> [Adya95] </ref>, AOCC uses a combination of invalidation and propagation for Remote Update Actions. As in Cache Locks, notifications are piggybacked on messages sent to clients, and such notifications invalidate cached copies. <p> For this reason, both Cache Locks and AOCC use the more optimistic approach of deferring such checks until transaction commit time. As shown in <ref> [Adya95] </ref>, such optimism, combined with piggybacking of notifications, can significantly reduce the number of messages required for consistency checking; of course, this comes at the expense of a possible rise in transaction aborts.
Reference: [Agar88] <author> Agarawal, A., Simoni, R., Hennessy, J., Horowitz, M., </author> <title> "An Evaluation of Directory Schemes for Cache Coherence", </title> <booktitle> Proceedings of the 15th International Symposium on Computer Architecture, </booktitle> <address> Honolulu, </address> <month> June, </month> <year> 1988. </year>
Reference-contexts: Reliance on broadcast is not a viable option in a page server DBMS environment, however, due to cost and scalability issues. As a result, a "directory-based" approach <ref> [Agar88] </ref> must be used. As discussed in Section 2.3, the server is the focal point for all transaction management functions and is responsible for providing clients with requested data; as a result, the avoidance-based algorithms covered here all maintain a directory of client page copies at the server. <p> These systems differ along all four of the dimensions listed above. For example, database systems support serializable transactions, while the consistency requirements for multiprocessors are at the level of individual memory accesses. Nevertheless, the basic consistency mechanisms, such as write-broadcast and write-invalidate [Arch86], or directories of cached copies (e.g., <ref> [Agar88] </ref>), are similar. Client caching has been used in distributed file systems since some of the earliest work in the area (e.g., DFS [Stur80]). Many distributed file systems that support some form of client caching have been proposed and built.
Reference: [Alsb76] <author> Alsberg, P., Day, J., </author> <title> "Principles for Resilient Sharing of Distributed Resources", </title> <booktitle> Proceedings of the 2nd International Conference on Software Engineering, IEEE, </booktitle> <address> San Francisco, </address> <year> 1976. </year> <month> 35 </month>
Reference-contexts: Server-based 2PL schemes are derived from the primary copy approach to replicated data management <ref> [Alsb76, Ston79] </ref>. Before a transaction is allowed to commit, it must first access a specially designated copy (i.e., the primary copy) of each data item that it reads or writes.
Reference: [Amsa95] <author> Amsaleg, L., Franklin, M., Gruber, O., </author> <title> "Efficient Incremental Garbage Collection for Client--Server Object Database Systems", </title> <booktitle> Proc. of the 21st International Conference on Very Large Data Bases, </booktitle> <address> Zurich, Switzerland, </address> <month> September, </month> <year> 1995. </year>
Reference-contexts: single process with the client DBMS code. 3 Furthermore, our experience with the client-server EXODUS system [Fran92c, Exod93] has shown that a page server design provides additional advantages, such as the ability to use standard recovery algorithms (e.g., ARIES [Moha92]), and the ability to add efficient, server-based garbage collection algorithms <ref> [Amsa95] </ref>. For these reasons, the work in this paper is focused on page server architectures. It should be noted however, that many of the algorithms and results are also applicable to object servers.
Reference: [Arch86] <author> Archibald, J., Baer, J., </author> <title> "Cache Coherence Protocols: Evaluation Using a Multiprocessor Simulation Model", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 4(4), </volume> <month> November, </month> <year> 1986. </year>
Reference-contexts: Many algorithms have been proposed; these algorithms differ along numerous dimensions such as their level of optimism versus pessimism, their use of invalidation or propagation (i.e., write-invalidate or write-broadcast <ref> [Arch86] </ref>) for updated data items, and their interaction with transaction management. While the papers mentioned previously have all provided comparisons of two or more proposed algorithms, there has been little published work on systematically exploring the large design space for client-server cache consistency algorithms. <p> A dynamic algorithm can chose between invalidation and propagation heuristically in order to optimize performance for varying workloads. The concepts of propagation and invalidation are analogous to the notions of write-broadcast and write-invalidate (respectively) found in multiprocessor cache consistency algorithms <ref> [Arch86] </ref>. 3.3 Avoidance-based Algorithms Avoidance-based algorithms form the other half of our taxonomy of transactional cache consistency maintenance algorithms. The avoidance-based side of the taxonomy is shown in Figure 3. <p> Much of the early work in cache consistency maintenance was done in the context of shared-memory 33 multiprocessors. A number of early protocols for such systems were studied in <ref> [Arch86] </ref>; a more recent survey appears in [Sten90]. These systems differ along all four of the dimensions listed above. For example, database systems support serializable transactions, while the consistency requirements for multiprocessors are at the level of individual memory accesses. Nevertheless, the basic consistency mechanisms, such as write-broadcast and write-invalidate [Arch86], <p> <ref> [Arch86] </ref>; a more recent survey appears in [Sten90]. These systems differ along all four of the dimensions listed above. For example, database systems support serializable transactions, while the consistency requirements for multiprocessors are at the level of individual memory accesses. Nevertheless, the basic consistency mechanisms, such as write-broadcast and write-invalidate [Arch86], or directories of cached copies (e.g., [Agar88]), are similar. Client caching has been used in distributed file systems since some of the earliest work in the area (e.g., DFS [Stur80]). Many distributed file systems that support some form of client caching have been proposed and built.
Reference: [Bake91] <author> Baker, M., Hartman, J., Kuper, M., Shirriff, K., Ousterhout, J., </author> <title> "Measurements of a Distributed File System", </title> <booktitle> Proceedings of the 13th International Symposium on Operating System Principles, </booktitle> <address> Pacific Grove, CA, </address> <month> October, </month> <year> 1991. </year>
Reference-contexts: As with page server DBMSs, these systems use client caching to improve performance and scalability. However, they support much less stringent notions of correctness in terms of both concurrency and failure semantics. Furthermore, distributed file systems are typically designed for workloads in which read-write sharing is rare (e.g., <ref> [Bake91] </ref>). Caching is often done at a fairly coarse granularity, such as entire files or large portions of files. Finally, Distributed Shared Memory (DSM) systems [Li89, Nitz91] provide the abstraction of a shared virtual memory address space that spans the nodes of a distributed system.
Reference: [Bern87] <author> Bernstein, P., Hadzilacos, V., Goodman, N., </author> <title> Concurrency Control and Recovery in Database Systems, </title> <publisher> Addison-Wesley, </publisher> <year> 1987. </year>
Reference-contexts: Because (as described in the following section) client caching is essentially a form of dynamic data replication, correctness criteria for managing replicated data are applicable in this environment. The extension of serializability to replicated data is called one-copy serializabil-ity <ref> [Bern87] </ref>. A one-copy serializable execution of transactions on a replicated database is equivalent to some serial execution of those transactions on a non-replicated database. <p> Some consistency algorithms allow multiple transactions to simultaneously access different values of the same page, provided that serializability is not violated, essentially yielding a dynamic form of multiversion concurrency control <ref> [Bern87] </ref>. 4 As described in Section 2.3, the use of second-class replication allows the server to unilaterally eliminate any unreachable copies from the protocol so that transaction processing can continue. 10 notification hints, and remote update action. 3.2.1 Validity Check Initiation The coarsest level of differentiation for the detection-based half of
Reference: [Bhid88] <author> Bhide, A., Stonebraker, M., </author> <title> "An Analysis of Three Transaction Processing Architectures," </title> <booktitle> Proceedings of the 14th International Conference on Very Large Data Bases, </booktitle> <address> Los Angeles, </address> <month> August, </month> <year> 1988. </year>
Reference-contexts: One such class of systems is shared-disk (or data sharing) parallel database systems, which consist of multiple nodes with private processors and memory that share a common disk pool <ref> [Bhid88] </ref>. While similar in some respects to the client-server database systems addressed in this study, they differ in three significant ways.
Reference: [Butt91] <author> Butterworth, P., Otis, A., Stien, J., </author> <title> "The GemStone Object Database System", </title> <journal> Communications of the ACM, </journal> <volume> 34(10), </volume> <month> October, </month> <year> 1991. </year>
Reference-contexts: Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS [Fran92c, Exod93], SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone <ref> [Butt91] </ref>, O2 [Deux91], ObjectStore [Lamb91], Ontos [Onto92], Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the volume of data requested by clients.
Reference: [Care91a] <author> Carey, M., Franklin, M., Livny, M., Shekita, E., </author> <title> "Data Caching Tradeoffs in Client-Server DBMS Architectures", </title> <booktitle> Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> Denver, </address> <month> June, </month> <year> 1991. </year>
Reference-contexts: In contrast, inter-transaction data caching raises the need for a cache consistency protocol to ensure that applications always see a consistent (serializable) view of the database. Cache consistency protocols for client-server database systems have been the subject of much study over the past five years <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. Many algorithms have been proposed; these algorithms differ along numerous dimensions such as their level of optimism versus pessimism, their use of invalidation or propagation (i.e., write-invalidate or write-broadcast [Arch86]) for updated data items, and their interaction with transaction management. <p> As a result, there is a wide range of options for the design of such algorithms. This section provides a taxonomy of transactional cache consistency algorithms that encompasses the major algorithms that have appeared in the literature, including <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. All of these algorithms provide one-copy serializability and are applicable to page server DBMSs (although some were originally proposed for object servers). The taxonomy is shown in two parts in Figures 2 and 3. The figures show where proposed algorithms fit in the taxonomy. <p> Of course, the use of avoidance obviates any possible need for detection, so there is no augmentation in the opposite direction within the taxonomy. 3.2 Detection-based Algorithms A number of detection-based algorithms (shown in Figure 2) have been proposed and studied in the literature <ref> [Kim90, Wilk90, Care91a, Wang91, Adya95] </ref>. The main argument for the detection-based approach is simplicity. Because their consistency actions involve only a single client and the server, the detection-based approaches allow the cache management software on the clients to be greatly simplified compared to the ROWA approach. <p> In this section, we examine the performance implications of a number of the choices identified in the taxonomy. To date, our work has focused primarily on algorithms from the avoidance-based half of the taxonomy <ref> [Care91a, Fran92a] </ref>. In this section, we consolidate the results of those studies and re-examine their conclusions in the context of the design choices identified in the taxonomy. We first describe six candidate algorithms from three different algorithm families. <p> Finally, although this section focuses on results from a limited set of experiments, it should be emphasized that we have run numerous experiments with a variety of different parameter settings and workloads. Many of these experiments are described in <ref> [Care91a, Fran92a, Fran93a] </ref>. 4.3.1 The PRIVATE Workload We first examine performance results for the PRIVATE workload. As described in Section 4.2.2, PRIVATE has a high degree of locality per client, and it has no read-write or write-write data sharing. <p> To reduce the possibility of stale data access, the no-wait algorithm was extended in [Wang91] with a propagation-based notification hint scheme. The performance of this algorithm, called No-Wait Locking with Notifications, was then examined. The results of that study showed (as we did in <ref> [Care91a] </ref>) that the cost of propagations typically outweighs their potential benefits. <p> The original dynamic algorithm (O2PL-Dynamic) was introduced in <ref> [Care91a] </ref>. This algorithm used a simple heuristic that would initially 32 propagate an update to a remotely cached page copy, switching to invalidation the next time if the propa-gation went unused. An improved heuristic (called O2PL-NewDynamic), which initially favors invalidation over propagation, was described and studied in [Fran92a, Fran93a].
Reference: [Care91b] <author> Carey, M. and Livny, M., </author> <title> "Conflict Detection Tradeoffs for Replicated Data", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 16(4), </volume> <month> December, </month> <year> 1991. </year>
Reference-contexts: An algorithm similar to CB-R was also studied in [Wang91]. 4.1.3 Optimistic Two-Phase Locking (O2PL) The third family of caching algorithms that we have studied is Optimistic Two-phase Locking (O2PL). The O2PL algorithms are derived from a concurrency control protocol that was originally developed for replicated distributed databases <ref> [Care91b] </ref>. The O2PL algorithms are avoidance-based, but they are more "optimistic" than Callback Locking because they defer write intention declaration until the end of a transaction's execution phase. We have developed and analyzed several O2PL variants that differ in their implementation of remote update actions. <p> client does not affect the page's LRU status at that site. 10 Note that deadlocks involving consistency actions can be resolved early, rather than waiting for periodic detection, as any conflict detected between two consistency actions or between a consistency action and an update will ultimately result in a deadlock <ref> [Care91b] </ref>. 19 transactions never have the opportunity to access stale data. The S2PL algorithms are detection-based, whereas the CBL and O2PL algorithms are all avoidance-based. Among these algorithms, comparing the performance of C2PL and CB-A can provide the clearest insights into this tradeoff.
Reference: [Care93] <author> Carey, M., DeWitt, D., Naughton, J., </author> <title> "The 007 Benchmark", </title> <booktitle> Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> Washington, D.C., </address> <month> May, </month> <year> 1993. </year>
Reference-contexts: Workloads that demonstrate these performance advantages include the 001 (or "Sun") engineering database benchmark [Catt92] and the more recent 007 benchmark <ref> [Care93] </ref>.
Reference: [Care94a] <author> Carey, M., DeWitt, D., Franklin, M., Hall, N., McAuliffe, M., Naughton, J., Schuh, D., Solomon, M., Tan, C., Tsatalos, O., White, S., Zwilling, M.. </author> <booktitle> "Shoring up Persistent Applications" Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> Minneapolis, MN, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Workloads that demonstrate these performance advantages include the 001 (or "Sun") engineering database benchmark [Catt92] and the more recent 007 benchmark [Care93]. Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS [Fran92c, Exod93], SHORE <ref> [Care94a] </ref>, and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore [Lamb91], Ontos [Onto92], Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the volume of data
Reference: [Care94b] <author> Carey, M., Franklin, M., Zaharioudakis, M., </author> <title> "Fine-grained Locking in Page Server Database Systems", </title> <booktitle> Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> Minneapolis, MN, </address> <month> June, </month> <year> 1994. </year>
Reference-contexts: The tradeoffs between page servers and object servers have been studied for the single user case in [DeWi90], and more recently for the multi-user case in <ref> [Care94b, Chu94] </ref>. In the single user case, page servers were shown to offer communication savings given effective clustering. The multi-user work showed how to efficiently support fine-grained (e.g., object-level) sharing within a page server context. 1 The process boundaries described here are typical, but not strictly required. <p> An algorithm that could dynamically adjust the granularity at which locking and coherency were managed for a shared-disk DBMS was introduced in [Josh91]. This approach was later extended for use in page server environments in <ref> [Care94b] </ref>. 5.2.2 Non-Database Environments Of course, cache consistency issues arise in other types of distributed and/or parallel systems as well, such as multi-processor architectures, distributed file systems, and distributed shared memory systems. <p> Issues that arise when clients are allowed to obtain data from each other (in addition to servers) were studied in [Fran92b]. More recently, callback-style approaches have been extended to support multiple granularities of concurrency control and cache consistency maintenance <ref> [Care94b, Chu94] </ref>. Current trends in client-server database systems raise additional challenges that must be addressed as well.
Reference: [Catt91] <author> Cattell, R., </author> <title> Object Data Management, </title> <publisher> Addison Wesley, </publisher> <address> Reading, MA, </address> <year> 1991. </year>
Reference-contexts: While there is currently no definitive understanding of page server DBMS workloads, it is generally assumed that such workloads have lower levels of conflict than more traditional DBMS workloads, such as transaction processing <ref> [Catt91] </ref>. In a transactional caching environment, however, the notion of conflict must take into account not only concurrent data sharing, but also sequential sharing. Sequential sharing arises when transactions that do not run concurrently access the same data.
Reference: [Catt92] <author> Cattell, R., Skeen, J., </author> <title> "Object Operations Benchmark", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17,1, </volume> <month> March, </month> <year> 1992. </year>
Reference-contexts: Second, data-shipping o*oads much of the DBMS function from the server to the client workstations, thereby allowing the DBMS to exploit the plentiful and relatively inexpensive resources of the workstations. Workloads that demonstrate these performance advantages include the 001 (or "Sun") engineering database benchmark <ref> [Catt92] </ref> and the more recent 007 benchmark [Care93].
Reference: [Chu94] <author> Chu, S., Winslett, M., </author> <title> "Minipage Locking Support for Page-Server Database Management Systems", </title> <booktitle> Proc. 3rd Intl. Conference on Information and Knowledge Management, </booktitle> <address> Gaithersburg, MD, </address> <month> November, </month> <year> 1994. </year>
Reference-contexts: The tradeoffs between page servers and object servers have been studied for the single user case in [DeWi90], and more recently for the multi-user case in <ref> [Care94b, Chu94] </ref>. In the single user case, page servers were shown to offer communication savings given effective clustering. The multi-user work showed how to efficiently support fine-grained (e.g., object-level) sharing within a page server context. 1 The process boundaries described here are typical, but not strictly required. <p> Issues that arise when clients are allowed to obtain data from each other (in addition to servers) were studied in [Fran92b]. More recently, callback-style approaches have been extended to support multiple granularities of concurrency control and cache consistency maintenance <ref> [Care94b, Chu94] </ref>. Current trends in client-server database systems raise additional challenges that must be addressed as well.
Reference: [Dan90a] <author> Dan, A., Dias, D., Yu, P., </author> <title> "The Effect of Skewed Data Access on Buffer Hits and Data Contention in a Data Sharing Environment", </title> <booktitle> Proceedings of the 16th International Conference on Very Large Data Bases, </booktitle> <address> Brisbane, Australia, </address> <month> August, </month> <year> 1990. </year>
Reference-contexts: One of their earlier papers examined cache consistency protocols that were integrated with the global lock manager of a shared-disk system [Dias87]. Later work has addressed the impact of data skew and contention for a range of possible algorithms <ref> [Dan90a, Dan90b] </ref>, the interaction between private and shared buffering [Dan91] (similar to the interactions between client buffers and the server buffer), and extensions to callback-style algorithms [Dan92]. Other related work in this area includes the work of Mohan and Narang [Moha91], Rahm [Rahm93], and Lomet [Lome94].
Reference: [Dan90b] <author> Dan, A., Yu, P., </author> <title> "Performance Comparisons of Buffer Coherency Policies", </title> <institution> IBM Research Report RC16361, </institution> <month> November, </month> <year> 1990. </year>
Reference-contexts: One of their earlier papers examined cache consistency protocols that were integrated with the global lock manager of a shared-disk system [Dias87]. Later work has addressed the impact of data skew and contention for a range of possible algorithms <ref> [Dan90a, Dan90b] </ref>, the interaction between private and shared buffering [Dan91] (similar to the interactions between client buffers and the server buffer), and extensions to callback-style algorithms [Dan92]. Other related work in this area includes the work of Mohan and Narang [Moha91], Rahm [Rahm93], and Lomet [Lome94].
Reference: [Dan91] <author> Dan, A., Dias, D., Yu, P., </author> <title> "Analytical Modelling of a Hierarchical Buffer for a Data Sharing Environment", </title> <booktitle> Proceedings of the ACM SIGMETRICS Conference on Measurement and Modelling of Computer Systems, </booktitle> <address> San Diego, </address> <month> May, </month> <year> 1991. </year> <month> 36 </month>
Reference-contexts: One of their earlier papers examined cache consistency protocols that were integrated with the global lock manager of a shared-disk system [Dias87]. Later work has addressed the impact of data skew and contention for a range of possible algorithms [Dan90a, Dan90b], the interaction between private and shared buffering <ref> [Dan91] </ref> (similar to the interactions between client buffers and the server buffer), and extensions to callback-style algorithms [Dan92]. Other related work in this area includes the work of Mohan and Narang [Moha91], Rahm [Rahm93], and Lomet [Lome94].
Reference: [Dan92] <author> Dan, A., Yu, P., </author> <title> "Performance Analysis of Coherency Control Policies through Lock Retention", </title> <booktitle> Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> San Diego, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: Later work has addressed the impact of data skew and contention for a range of possible algorithms [Dan90a, Dan90b], the interaction between private and shared buffering [Dan91] (similar to the interactions between client buffers and the server buffer), and extensions to callback-style algorithms <ref> [Dan92] </ref>. Other related work in this area includes the work of Mohan and Narang [Moha91], Rahm [Rahm93], and Lomet [Lome94]. An algorithm that could dynamically adjust the granularity at which locking and coherency were managed for a shared-disk DBMS was introduced in [Josh91].
Reference: [Davi85] <author> Davidson, S., Garcia-Molina, H., Skeen, D., </author> <title> "Consistency in Partitioned Networks", </title> <journal> ACM Computing Surveys, </journal> <volume> 17(3), </volume> <month> September, </month> <year> 1985. </year>
Reference-contexts: It is well known that replication can reduce data availability for updates in the presence of certain failures (e.g., network partition) in a distributed environment <ref> [Davi85] </ref>. Second-class ownership allows consistency to be preserved without sacrificing availability. Second-class ownership refers to the fact that the cached copies of pages are not considered to be the equals of the actual data pages, which are kept at the server 2 .
Reference: [Deux91] <editor> O. Deux et al., </editor> <title> "The O2 System", </title> <journal> Communications of the ACM, </journal> <volume> 34(10), </volume> <month> October, </month> <year> 1991. </year>
Reference-contexts: Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS [Fran92c, Exod93], SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 <ref> [Deux91] </ref>, ObjectStore [Lamb91], Ontos [Onto92], Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the volume of data requested by clients.
Reference: [DeWi90] <author> DeWitt, D., Futtersack, P., Maier, D., Velez, F., </author> <title> "A Study of Three Alternative Workstation-Server Architectures for Object-Oriented Database Systems", </title> <booktitle> Proceedings of the 16th International Conference on Very Large Data Bases, </booktitle> <address> Brisbane, Australia, </address> <month> August, </month> <year> 1990. </year>
Reference-contexts: The tradeoffs between page servers and object servers have been studied for the single user case in <ref> [DeWi90] </ref>, and more recently for the multi-user case in [Care94b, Chu94]. In the single user case, page servers were shown to offer communication savings given effective clustering.
Reference: [Dias87] <author> Dias, D., Iyer, B., Robinson, J., Yu., P., </author> <title> "Design and Analysis of Integrated Concurrency-Controls", </title> <booktitle> Proceedings of the 13th International Conference on Very Large Data Bases, </booktitle> <address> Brighton, England, </address> <year> 1987. </year>
Reference-contexts: A number of papers on shared-disk caching performance have been written by a group at IBM York-town. One of their earlier papers examined cache consistency protocols that were integrated with the global lock manager of a shared-disk system <ref> [Dias87] </ref>. Later work has addressed the impact of data skew and contention for a range of possible algorithms [Dan90a, Dan90b], the interaction between private and shared buffering [Dan91] (similar to the interactions between client buffers and the server buffer), and extensions to callback-style algorithms [Dan92].
Reference: [Exod93] <author> EXODUS Project Group, </author> <title> "EXODUS Storage Manager Architectural Overview", EXODUS Project Document, </title> <institution> Computer Sciences Department, University of Wisconsin-Madison, </institution> <note> (available by ftp from ftp.cs.wisc.edu), </note> <year> 1993. </year>
Reference-contexts: Workloads that demonstrate these performance advantages include the 001 (or "Sun") engineering database benchmark [Catt92] and the more recent 007 benchmark [Care93]. Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS <ref> [Fran92c, Exod93] </ref>, SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore [Lamb91], Ontos [Onto92], Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the <p> For example, in EXODUS, applications are linked into a single process with the client DBMS code. 3 Furthermore, our experience with the client-server EXODUS system <ref> [Fran92c, Exod93] </ref> has shown that a page server design provides additional advantages, such as the ability to use standard recovery algorithms (e.g., ARIES [Moha92]), and the ability to add efficient, server-based garbage collection algorithms [Amsa95]. For these reasons, the work in this paper is focused on page server architectures. <p> For example, using detection, the system software can be structured such that clients do not ever have to receive asynchronous messages from the server. The EXODUS storage manager <ref> [Exod93] </ref> chose a detection-based approach largely for this reason. Also, servers can be made responsible for maintaining consistency information, thus relieving clients of that burden. The disadvantage of detection-based approaches, however, is a greater dependency on the server, which can result in additional overhead. <p> C2PL is one of the simplest algorithms that supports inter-transaction caching, and therefore, algorithms similar to C2PL have been implemented in several systems, including the ORION-1SX prototype [Kim90] and the EXODUS storage manager <ref> [Exod93] </ref>. An algorithm similar to C2PL has also been studied in [Wang91]. For comparison purposes, the performance study also includes results for an algorithm called Basic 2PL (B2PL) that allows only intra-transaction caching.
Reference: [Fran92a] <author> Franklin, M., Carey, </author> <title> M.,"Client-Server Caching Revisited", </title> <booktitle> in Proceedings of the International Workshop on Distributed Object Management, </booktitle> <address> Edmonton, Canada, </address> <month> August, </month> <year> 1992, </year> <note> (Published as Distributed Object Management, </note> <editor> Ozsu, Dayal, Vaduriez, eds., </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1994). </year>
Reference-contexts: In contrast, inter-transaction data caching raises the need for a cache consistency protocol to ensure that applications always see a consistent (serializable) view of the database. Cache consistency protocols for client-server database systems have been the subject of much study over the past five years <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. Many algorithms have been proposed; these algorithms differ along numerous dimensions such as their level of optimism versus pessimism, their use of invalidation or propagation (i.e., write-invalidate or write-broadcast [Arch86]) for updated data items, and their interaction with transaction management. <p> As a result, there is a wide range of options for the design of such algorithms. This section provides a taxonomy of transactional cache consistency algorithms that encompasses the major algorithms that have appeared in the literature, including <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. All of these algorithms provide one-copy serializability and are applicable to page server DBMSs (although some were originally proposed for object servers). The taxonomy is shown in two parts in Figures 2 and 3. The figures show where proposed algorithms fit in the taxonomy. <p> In this section, we examine the performance implications of a number of the choices identified in the taxonomy. To date, our work has focused primarily on algorithms from the avoidance-based half of the taxonomy <ref> [Care91a, Fran92a] </ref>. In this section, we consolidate the results of those studies and re-examine their conclusions in the context of the design choices identified in the taxonomy. We first describe six candidate algorithms from three different algorithm families. <p> Finally, although this section focuses on results from a limited set of experiments, it should be emphasized that we have run numerous experiments with a variety of different parameter settings and workloads. Many of these experiments are described in <ref> [Care91a, Fran92a, Fran93a] </ref>. 4.3.1 The PRIVATE Workload We first examine performance results for the PRIVATE workload. As described in Section 4.2.2, PRIVATE has a high degree of locality per client, and it has no read-write or write-write data sharing. <p> Interestingly, despite this difference, O2PL-I obtains roughly 10% higher throughput than CB-A (see Figure 9). This is because the cost of aborts in this experiment is rather low due to cache hits that occur when aborted transactions run again. However, as shown in <ref> [Fran92a, Fran93a] </ref>, the high abort rate of O2PL-I can cause it to have significantly worse performance than CB-R if data contention is increased further. <p> If sharing is present, then deferring declarations can save messages. However, if sharing increases to the point were data contention arises, deferring declarations can lead to significantly higher abort rates; transaction aborts can result in higher resource utilization due to lost work <ref> [Fran92a, Fran93a] </ref>, though this effect did not significantly hurt throughput in the workloads examined here. Whether or not aborts impact overall throughput, a high abort rate may be intolerable for users in some highly-interactive applications. <p> This algorithm used a simple heuristic that would initially 32 propagate an update to a remotely cached page copy, switching to invalidation the next time if the propa-gation went unused. An improved heuristic (called O2PL-NewDynamic), which initially favors invalidation over propagation, was described and studied in <ref> [Fran92a, Fran93a] </ref>.
Reference: [Fran92b] <author> Franklin, M. Carey, M., and Livny, M., </author> <title> "Global Memory Management in Client-Server DBMS Architectures", </title> <booktitle> Proceedings of the 18th International Conference on Very Large Data Bases, </booktitle> <address> Vancouver, B.C., Canada, </address> <month> August, </month> <year> 1992. </year>
Reference-contexts: The work reported here has been extended in several ways. The extension of these techniques to client disk caching was investigated in [Fran93b]. Issues that arise when clients are allowed to obtain data from each other (in addition to servers) were studied in <ref> [Fran92b] </ref>. More recently, callback-style approaches have been extended to support multiple granularities of concurrency control and cache consistency maintenance [Care94b, Chu94]. Current trends in client-server database systems raise additional challenges that must be addressed as well.
Reference: [Fran92c] <author> Franklin, M., Zwilling, M., Tan, C., Carey, M., DeWitt, D., </author> <title> "Crash Recovery in Client-Server EXODUS", </title> <booktitle> Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> San Diego, </address> <month> June, </month> <year> 1992. </year>
Reference-contexts: Workloads that demonstrate these performance advantages include the 001 (or "Sun") engineering database benchmark [Catt92] and the more recent 007 benchmark [Care93]. Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS <ref> [Fran92c, Exod93] </ref>, SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore [Lamb91], Ontos [Onto92], Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the <p> For example, in EXODUS, applications are linked into a single process with the client DBMS code. 3 Furthermore, our experience with the client-server EXODUS system <ref> [Fran92c, Exod93] </ref> has shown that a page server design provides additional advantages, such as the ability to use standard recovery algorithms (e.g., ARIES [Moha92]), and the ability to add efficient, server-based garbage collection algorithms [Amsa95]. For these reasons, the work in this paper is focused on page server architectures.
Reference: [Fran93a] <author> Franklin, M., </author> <title> Caching and Memory Mangement in Client-Server Databse Systems, </title> <type> Ph.D. Thesis, </type> <institution> Dept. of Computer Science, University of Wisconsin, </institution> <month> July, </month> <year> 1993. </year>
Reference-contexts: In contrast, inter-transaction data caching raises the need for a cache consistency protocol to ensure that applications always see a consistent (serializable) view of the database. Cache consistency protocols for client-server database systems have been the subject of much study over the past five years <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. Many algorithms have been proposed; these algorithms differ along numerous dimensions such as their level of optimism versus pessimism, their use of invalidation or propagation (i.e., write-invalidate or write-broadcast [Arch86]) for updated data items, and their interaction with transaction management. <p> As a result, there is a wide range of options for the design of such algorithms. This section provides a taxonomy of transactional cache consistency algorithms that encompasses the major algorithms that have appeared in the literature, including <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. All of these algorithms provide one-copy serializability and are applicable to page server DBMSs (although some were originally proposed for object servers). The taxonomy is shown in two parts in Figures 2 and 3. The figures show where proposed algorithms fit in the taxonomy. <p> While these algorithms differ in many ways, they all stem from the fundamental observation that because cached data is dynamically replicated data, techniques originally devised for managing replicated data can be adapted to manage cached copies. In the following, we briefly describe each of these three algorithm families (see <ref> [Fran93a] </ref> for a more detailed description) and then identify pairs of algorithms that can be used to isolate the impact of a number of the design choices described in Section 3. 4.1.1 Server-Based Two-Phase Locking (S2PL) Server-based two-phase locking algorithms are detection-based algorithms that validate cached pages synchronously on a transaction's <p> Finally, although this section focuses on results from a limited set of experiments, it should be emphasized that we have run numerous experiments with a variety of different parameter settings and workloads. Many of these experiments are described in <ref> [Care91a, Fran92a, Fran93a] </ref>. 4.3.1 The PRIVATE Workload We first examine performance results for the PRIVATE workload. As described in Section 4.2.2, PRIVATE has a high degree of locality per client, and it has no read-write or write-write data sharing. <p> Interestingly, despite this difference, O2PL-I obtains roughly 10% higher throughput than CB-A (see Figure 9). This is because the cost of aborts in this experiment is rather low due to cache hits that occur when aborted transactions run again. However, as shown in <ref> [Fran92a, Fran93a] </ref>, the high abort rate of O2PL-I can cause it to have significantly worse performance than CB-R if data contention is increased further. <p> If sharing is present, then deferring declarations can save messages. However, if sharing increases to the point were data contention arises, deferring declarations can lead to significantly higher abort rates; transaction aborts can result in higher resource utilization due to lost work <ref> [Fran92a, Fran93a] </ref>, though this effect did not significantly hurt throughput in the workloads examined here. Whether or not aborts impact overall throughput, a high abort rate may be intolerable for users in some highly-interactive applications. <p> This algorithm used a simple heuristic that would initially 32 propagate an update to a remotely cached page copy, switching to invalidation the next time if the propa-gation went unused. An improved heuristic (called O2PL-NewDynamic), which initially favors invalidation over propagation, was described and studied in <ref> [Fran92a, Fran93a] </ref>.
Reference: [Fran93b] <author> Franklin, M. Carey, M., and Livny, M., </author> <title> "Local Disk Caching in Client-Server Database Systems", </title> <booktitle> Proceedings of the 19th International Conference on Very Large Data Bases, </booktitle> <address> Dublin, Ireland, </address> <month> August, </month> <year> 1993. </year>
Reference-contexts: Thus, it is technically possible to avoid sending a copy of dirty page back to the server until the write permission on the page is downgraded or the page is dropped <ref> [Fran93b] </ref>. Callback-style algorithms originated in the operating systems community for maintaining cache consistency in distributed file systems such as Andrew [Howa88] and Sprite [Nels88], both of which provide weaker forms of consistency than that required by database systems. <p> In the absence of a dynamic approach or detailed information about client access patterns, invalidation is clearly the safest choice for most situations. The work reported here has been extended in several ways. The extension of these techniques to client disk caching was investigated in <ref> [Fran93b] </ref>. Issues that arise when clients are allowed to obtain data from each other (in addition to servers) were studied in [Fran92b]. More recently, callback-style approaches have been extended to support multiple granularities of concurrency control and cache consistency maintenance [Care94b, Chu94].
Reference: [Good83] <author> Goodman, J., </author> <title> "Using Cache Memory to Reduce Processor Memory Traffic", </title> <booktitle> Proceedings of the 10th International Symposium on Computer Architecture, </booktitle> <address> Stockholm, Sweden, </address> <month> June, </month> <year> 1983. </year>
Reference-contexts: In order to satisfy the "write all" requirement of the ROWA paradigm, it must be possible to locate all copies of a given page. One way to accomplish this is through the use of broadcast, as in the snooping protocols used in caching algorithms for small-scale multiprocessors <ref> [Good83] </ref>. Reliance on broadcast is not a viable option in a page server DBMS environment, however, due to cost and scalability issues. As a result, a "directory-based" approach [Agar88] must be used.
Reference: [Gray93] <author> Gray, J., Reuter, A., </author> <title> Transaction Processing: Concepts and Techniques, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1993. </year>
Reference-contexts: Workstation-server database systems must be capable of providing the same level of transaction support as more traditional database architectures (i.e., the ACID properties <ref> [Gray93] </ref>), including serializability. Because (as described in the following section) client caching is essentially a form of dynamic data replication, correctness criteria for managing replicated data are applicable in this environment. The extension of serializability to replicated data is called one-copy serializabil-ity [Bern87]. <p> Since every transaction starts with an empty 7 Data pages are typically tagged with such numbers, called Log Sequence Numbers (LSNs), in systems that use the Write Ahead-Logging protocol for crash recovery <ref> [Gray93] </ref>. 16 buffer pool, no page copies ever need to be validated with the server.
Reference: [Henn90] <author> Hennesy, J., Patterson, D., </author> <title> Computer Architecture, A Quantitative Approach, </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA., </address> <year> 1990. </year>
Reference-contexts: The utilization of client resources can also enhance performance predictability. As Hennessy and Pat-terson state: "The attraction of a personal computer is that you don't have to share it with anyone. This means response time is predictable, unlike timesharing systems." <ref> [Henn90] </ref>. This is only true, however, to the extent that access to shared resources can be avoided. For example, if data must be obtained from a remote server, then the time required to respond to a user request will vary depending on the load on the server and the network.
Reference: [Howa88] <author> Howard, J., Kazar, M., Menees, S., Nichols, D., Satyanarayanan, M., Sidebotham, R., West, M., </author> <title> "Scale and Performance in a Distributed File System", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1), </volume> <month> February, </month> <year> 1988. </year>
Reference-contexts: Callback-style algorithms originated in the operating systems community for maintaining cache consistency in distributed file systems such as Andrew <ref> [Howa88] </ref> and Sprite [Nels88], both of which provide weaker forms of consistency than that required by database systems. More recently, a Callback Locking algorithm that provides transaction serializability has been employed in the ObjectStore OODBMS [Lamb91]. <p> Client caching has been used in distributed file systems since some of the earliest work in the area (e.g., DFS [Stur80]). Many distributed file systems that support some form of client caching have been proposed and built. These include Andrew <ref> [Howa88] </ref> and Sprite [Nels88], which both used callback-style algorithms. A survey of distributed file systems can be found in [Levy90]. As with page server DBMSs, these systems use client caching to improve performance and scalability.
Reference: [Josh91] <author> Joshi, A., </author> <title> "Adaptive Locking Strategies in a Multi-Node Data Sharing System", </title> <booktitle> Proceedings of the 17th International Conference on Very Large Data Bases, </booktitle> <address> Barcelona, </address> <year> 1991. </year>
Reference-contexts: Other related work in this area includes the work of Mohan and Narang [Moha91], Rahm [Rahm93], and Lomet [Lome94]. An algorithm that could dynamically adjust the granularity at which locking and coherency were managed for a shared-disk DBMS was introduced in <ref> [Josh91] </ref>. This approach was later extended for use in page server environments in [Care94b]. 5.2.2 Non-Database Environments Of course, cache consistency issues arise in other types of distributed and/or parallel systems as well, such as multi-processor architectures, distributed file systems, and distributed shared memory systems.
Reference: [Kim90] <author> Kim, W., Garza, J., Ballou, N., Woelk, D., </author> <title> "The Architecture of the ORION Next-Generation Database System," </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 2(1), </volume> <month> March, </month> <year> 1990. </year> <month> 37 </month>
Reference-contexts: Workloads that demonstrate these performance advantages include the 001 (or "Sun") engineering database benchmark [Catt92] and the more recent 007 benchmark [Care93]. Examples of data-shipping systems include include research prototypes such as ORION <ref> [Kim90] </ref>, EXODUS [Fran92c, Exod93], SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore [Lamb91], Ontos [Onto92], Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due <p> Of course, the use of avoidance obviates any possible need for detection, so there is no augmentation in the opposite direction within the taxonomy. 3.2 Detection-based Algorithms A number of detection-based algorithms (shown in Figure 2) have been proposed and studied in the literature <ref> [Kim90, Wilk90, Care91a, Wang91, Adya95] </ref>. The main argument for the detection-based approach is simplicity. Because their consistency actions involve only a single client and the server, the detection-based approaches allow the cache management software on the clients to be greatly simplified compared to the ROWA approach. <p> Deadlocks are detected through a centralized scheme at the server, and are resolved by aborting the youngest transaction involved in the deadlock. C2PL is one of the simplest algorithms that supports inter-transaction caching, and therefore, algorithms similar to C2PL have been implemented in several systems, including the ORION-1SX prototype <ref> [Kim90] </ref> and the EXODUS storage manager [Exod93]. An algorithm similar to C2PL has also been studied in [Wang91]. For comparison purposes, the performance study also includes results for an algorithm called Basic 2PL (B2PL) that allows only intra-transaction caching.
Reference: [Kist91] <author> Kistler, J., Satyanarayanan, M., </author> <title> "Disconnected Operation in the Coda File System", </title> <booktitle> Proceedings of the 13th International Symposium on Operating System Principles, </booktitle> <address> Pacific Grove, CA, </address> <month> October </month> <year> 1991. </year>
Reference-contexts: The challenge in designing cache 2 The term "second-class ownership" is derived from a similar concept called "second-class replication" used in the CODA distributed file system <ref> [Kist91] </ref>. The two notions are similar in that a distinction is made between the "worth" of different types of copies.
Reference: [Lamb91] <author> Lamb, C., Landis, G., Orenstein, J., Weinreb, D., </author> <title> "The ObjectStore Database System", </title> <journal> Communications of the ACM, </journal> <volume> 34(10), </volume> <month> October, </month> <year> 1991. </year>
Reference-contexts: Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS [Fran92c, Exod93], SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore <ref> [Lamb91] </ref>, Ontos [Onto92], Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the volume of data requested by clients. <p> More recently, a Callback Locking algorithm that provides transaction serializability has been employed in the ObjectStore OODBMS <ref> [Lamb91] </ref>. An algorithm similar to CB-R was also studied in [Wang91]. 4.1.3 Optimistic Two-Phase Locking (O2PL) The third family of caching algorithms that we have studied is Optimistic Two-phase Locking (O2PL). The O2PL algorithms are derived from a concurrency control protocol that was originally developed for replicated distributed databases [Care91b].
Reference: [Levy90] <author> Levy, E., Silbershatz, A., </author> <title> "Distributed File Systems: Concepts and Examples", </title> <journal> ACM Computing Surveys, </journal> <volume> 22(4), </volume> <month> December, </month> <year> 1990. </year>
Reference-contexts: Many distributed file systems that support some form of client caching have been proposed and built. These include Andrew [Howa88] and Sprite [Nels88], which both used callback-style algorithms. A survey of distributed file systems can be found in <ref> [Levy90] </ref>. As with page server DBMSs, these systems use client caching to improve performance and scalability. However, they support much less stringent notions of correctness in terms of both concurrency and failure semantics. Furthermore, distributed file systems are typically designed for workloads in which read-write sharing is rare (e.g., [Bake91]).
Reference: [Li89] <author> Li, K., Hudak, P., </author> <title> "Memory Coherence in Shared Virtual Memory Systems", </title> <journal> ACM Transactions on Computer Systems,7(4) November, </journal> <year> 1989. </year>
Reference-contexts: Furthermore, distributed file systems are typically designed for workloads in which read-write sharing is rare (e.g., [Bake91]). Caching is often done at a fairly coarse granularity, such as entire files or large portions of files. Finally, Distributed Shared Memory (DSM) systems <ref> [Li89, Nitz91] </ref> provide the abstraction of a shared virtual memory address space that spans the nodes of a distributed system. DSM implementations allow multiple readers to access the same page, so DSM systems must deal with the problems raised by dynamic replication.
Reference: [Lisk92] <author> Liskov, B., Day, M., Shrira, L., </author> <title> "Distributed Object Management in Thor", </title> <booktitle> Proceedings of the International Workshop on Distributed Object Management, </booktitle> <address> Edmonton, Canada, </address> <month> August, </month> <year> 1992, </year> <note> (Published as Distributed Object Management, </note> <editor> Ozsu, Dayal, Vaduriez, eds., </editor> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1994). </year>
Reference-contexts: Workloads that demonstrate these performance advantages include the 001 (or "Sun") engineering database benchmark [Catt92] and the more recent 007 benchmark [Care93]. Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS [Fran92c, Exod93], SHORE [Care94a], and THOR <ref> [Lisk92] </ref>, as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore [Lamb91], Ontos [Onto92], Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the volume of data requested by clients.
Reference: [Livn90] <author> Livny, M., </author> <note> DeNet User's Guide, Version 1.5, </note> <institution> Computer Sciences Dept., University of Wisconsin-Madison, </institution> <year> 1990. </year>
Reference-contexts: Comparing the performance of O2PL-I and O2PL-P, which differ only in this respect, will help to isolate the tradeoffs between these two options. 4.2 A Client-Server Performance Model 4.2.1 The System Model event simulation language <ref> [Livn90] </ref>. It consists of components that model diskless client workstations and a server machine (with disks) that are connected over a simple network.
Reference: [Lome94] <author> Lomet, D., </author> <title> "Private Locking and Distributed Cache Management", </title> <booktitle> Proc. of the 3rd Intl. Conference on Parallel and Distributed Information Systems, </booktitle> <address> Austin, TX, </address> <month> September, </month> <year> 1994. </year>
Reference-contexts: Other related work in this area includes the work of Mohan and Narang [Moha91], Rahm [Rahm93], and Lomet <ref> [Lome94] </ref>. An algorithm that could dynamically adjust the granularity at which locking and coherency were managed for a shared-disk DBMS was introduced in [Josh91].
Reference: [Moha91] <author> Mohan, C., Narang, I., </author> <title> "Recovery and Coherency Control Protocols for Fast Intersystem Page Transfer and Fine-Granularity Locking in a Shared Disks Transaction Environment", </title> <booktitle> Proceedings of the 17th International Conference on Very Large Data Bases, </booktitle> <address> Barcelona, Spain, </address> <month> September, </month> <year> 1991. </year>
Reference-contexts: Other related work in this area includes the work of Mohan and Narang <ref> [Moha91] </ref>, Rahm [Rahm93], and Lomet [Lome94]. An algorithm that could dynamically adjust the granularity at which locking and coherency were managed for a shared-disk DBMS was introduced in [Josh91].
Reference: [Moha92] <author> Mohan, C., Haderle, D. Lindsay, B., Pirahesh, H., Schwarz, P., </author> <title> "ARIES: A Transaction Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 17(1), </volume> <month> March, </month> <year> 1992. </year>
Reference-contexts: For example, in EXODUS, applications are linked into a single process with the client DBMS code. 3 Furthermore, our experience with the client-server EXODUS system [Fran92c, Exod93] has shown that a page server design provides additional advantages, such as the ability to use standard recovery algorithms (e.g., ARIES <ref> [Moha92] </ref>), and the ability to add efficient, server-based garbage collection algorithms [Amsa95]. For these reasons, the work in this paper is focused on page server architectures. It should be noted however, that many of the algorithms and results are also applicable to object servers.
Reference: [Nels88] <author> Nelson, M., Welch, B., Ousterhout, J., </author> <title> "Caching in the Sprite Network File System", </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1), </volume> <month> February, </month> <year> 1988. </year>
Reference-contexts: Callback-style algorithms originated in the operating systems community for maintaining cache consistency in distributed file systems such as Andrew [Howa88] and Sprite <ref> [Nels88] </ref>, both of which provide weaker forms of consistency than that required by database systems. More recently, a Callback Locking algorithm that provides transaction serializability has been employed in the ObjectStore OODBMS [Lamb91]. <p> Client caching has been used in distributed file systems since some of the earliest work in the area (e.g., DFS [Stur80]). Many distributed file systems that support some form of client caching have been proposed and built. These include Andrew [Howa88] and Sprite <ref> [Nels88] </ref>, which both used callback-style algorithms. A survey of distributed file systems can be found in [Levy90]. As with page server DBMSs, these systems use client caching to improve performance and scalability. However, they support much less stringent notions of correctness in terms of both concurrency and failure semantics.
Reference: [Nitz91] <author> Nitzberg, B., Lo, V., </author> <title> "Distributed Shared Memory: A Survey of Issues and Algorithms", </title> <journal> IEEE Computer, </journal> <volume> 24(8), </volume> <month> August, </month> <year> 1991. </year>
Reference-contexts: Furthermore, distributed file systems are typically designed for workloads in which read-write sharing is rare (e.g., [Bake91]). Caching is often done at a fairly coarse granularity, such as entire files or large portions of files. Finally, Distributed Shared Memory (DSM) systems <ref> [Li89, Nitz91] </ref> provide the abstraction of a shared virtual memory address space that spans the nodes of a distributed system. DSM implementations allow multiple readers to access the same page, so DSM systems must deal with the problems raised by dynamic replication.
Reference: [Obje91] <institution> Objectivity Inc., </institution> <note> Objectivity/DB Documentation Vol. 1, </note> <year> 1991. </year>
Reference-contexts: Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS [Fran92c, Exod93], SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore [Lamb91], Ontos [Onto92], Objectivity <ref> [Obje91] </ref>, and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the volume of data requested by clients.
Reference: [Onto92] <author> ONTOS Inc., </author> <title> ONTOS DB 2.2 Reference Manual, </title> <year> 1992. </year>
Reference-contexts: Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS [Fran92c, Exod93], SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore [Lamb91], Ontos <ref> [Onto92] </ref>, Objectivity [Obje91], and Versant [Vers91]. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the volume of data requested by clients.
Reference: [Rahm91] <author> Rahm, E., </author> <title> "Concurrency and Coherency Control in Database Sharing Systems", </title> <type> Technical Report 3/91, </type> <institution> Computer Science Dept., University of Kaiserslautern, Germany, </institution> <month> November </month> <year> 1991. </year>
Reference-contexts: A different, and possibly more intuitive approach is to divide the taxonomy along the lines of concurrency control and replicated data management, as has been done for algorithms in the shared disks environment <ref> [Rahm91] </ref>. Because the two concepts are so closely inter-related, however, dividing a taxonomy at the highest level along these lines can result in substantial duplication of mechanism within the taxonomy, hurting its descriptive effectiveness.
Reference: [Rahm93] <author> Rahm, E., </author> <title> "Emperical Performance Evaluation of Concurrency and Coherency Control Protocols for Database Sharing Systems", </title> <journal> ACM Transactions on Database Systems, </journal> <volume> 18,2, </volume> <month> June, </month> <year> 1993. </year>
Reference-contexts: Other related work in this area includes the work of Mohan and Narang [Moha91], Rahm <ref> [Rahm93] </ref>, and Lomet [Lome94]. An algorithm that could dynamically adjust the granularity at which locking and coherency were managed for a shared-disk DBMS was introduced in [Josh91].
Reference: [Rama92] <author> Ramakrishnan, K., Biswas, P., Karedla, R., </author> <title> "Analysis of File I/O Traces in Commercial Computing Environments", </title> <booktitle> Proceedings of the ACM SIGMETRICS and Performance '92 Conference, </booktitle> <month> May, </month> <year> 1992. </year>
Reference-contexts: Sequential sharing arises when transactions that do not run concurrently access the same data. Because caching strives to retain data at a site even after a transaction has completed, the cache consistency maintenance algorithm must also deal effectively with this type of sharing. Recent studies of file system workloads <ref> [Rama92, Sand92] </ref> indicate that sequential sharing may, in fact, be quite common in the types of situations in which page servers are intended to be used. If this is the case, then the naive use of optimistic techniques could result in unacceptably high abort rates.
Reference: [Sand92] <author> Sandhu, H., Zhou, S., </author> <title> "Cluster-Based File Replication in Large-Scale Distributed Systems", </title> <booktitle> Proceedings of the ACM SIGMETRICS and Performance '92 Conference, </booktitle> <month> May, </month> <year> 1992. </year>
Reference-contexts: Sequential sharing arises when transactions that do not run concurrently access the same data. Because caching strives to retain data at a site even after a transaction has completed, the cache consistency maintenance algorithm must also deal effectively with this type of sharing. Recent studies of file system workloads <ref> [Rama92, Sand92] </ref> indicate that sequential sharing may, in fact, be quite common in the types of situations in which page servers are intended to be used. If this is the case, then the naive use of optimistic techniques could result in unacceptably high abort rates.
Reference: [Sten90] <author> Stenstrom, P., </author> <title> "A Survey of Cache Coherence Schemes for Multiprocessors", </title> <journal> IEEE Computer, </journal> <volume> 23(6), </volume> <month> June, </month> <year> 1990. </year>
Reference-contexts: Much of the early work in cache consistency maintenance was done in the context of shared-memory 33 multiprocessors. A number of early protocols for such systems were studied in [Arch86]; a more recent survey appears in <ref> [Sten90] </ref>. These systems differ along all four of the dimensions listed above. For example, database systems support serializable transactions, while the consistency requirements for multiprocessors are at the level of individual memory accesses.
Reference: [Ston79] <author> Stonebraker, M., </author> <title> "Concurrency Control and Consistency of Multiple Copies of Data in Distributed INGRES", </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-5(3), </volume> <month> May, </month> <year> 1979. </year> <month> 38 </month>
Reference-contexts: This is in contrast to static replication schemes, in which the replication of data is determined as part of the physical database design process (e.g., <ref> [Ston79] </ref>). It is well known that replication can reduce data availability for updates in the presence of certain failures (e.g., network partition) in a distributed environment [Davi85]. Second-class ownership allows consistency to be preserved without sacrificing availability. <p> Server-based 2PL schemes are derived from the primary copy approach to replicated data management <ref> [Alsb76, Ston79] </ref>. Before a transaction is allowed to commit, it must first access a specially designated copy (i.e., the primary copy) of each data item that it reads or writes.
Reference: [Stur80] <author> Sturgis, H., Mitchell, J., Israel, J., </author> <title> "Issues in the Design and use of a Distributed File System", </title> <journal> Operating Systems Review, </journal> <volume> 14(3), </volume> <month> July, </month> <year> 1980. </year>
Reference-contexts: Nevertheless, the basic consistency mechanisms, such as write-broadcast and write-invalidate [Arch86], or directories of cached copies (e.g., [Agar88]), are similar. Client caching has been used in distributed file systems since some of the earliest work in the area (e.g., DFS <ref> [Stur80] </ref>). Many distributed file systems that support some form of client caching have been proposed and built. These include Andrew [Howa88] and Sprite [Nels88], which both used callback-style algorithms. A survey of distributed file systems can be found in [Levy90].
Reference: [Vers91] <author> Versant Object Technology, </author> <title> VERSANT System Reference Manual, Release 1.6, </title> <address> Menlo Park, CA, </address> <year> 1991. </year>
Reference-contexts: Examples of data-shipping systems include include research prototypes such as ORION [Kim90], EXODUS [Fran92c, Exod93], SHORE [Care94a], and THOR [Lisk92], as well as commercial products such as GemStone [Butt91], O2 [Deux91], ObjectStore [Lamb91], Ontos [Onto92], Objectivity [Obje91], and Versant <ref> [Vers91] </ref>. 1.2 Client Caching A potential weakness of the data-shipping approach is its susceptibility to network and/or server bottlenecks that can arise due to the volume of data requested by clients.
Reference: [Wang91] <author> Wang, Y., Rowe, L., </author> <title> "Cache Consistency and Concurrency Control in a Client/Server DBMS Architecture", </title> <booktitle> Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> Denver, </address> <month> June, </month> <year> 1991 </year>
Reference-contexts: In contrast, inter-transaction data caching raises the need for a cache consistency protocol to ensure that applications always see a consistent (serializable) view of the database. Cache consistency protocols for client-server database systems have been the subject of much study over the past five years <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. Many algorithms have been proposed; these algorithms differ along numerous dimensions such as their level of optimism versus pessimism, their use of invalidation or propagation (i.e., write-invalidate or write-broadcast [Arch86]) for updated data items, and their interaction with transaction management. <p> As a result, there is a wide range of options for the design of such algorithms. This section provides a taxonomy of transactional cache consistency algorithms that encompasses the major algorithms that have appeared in the literature, including <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. All of these algorithms provide one-copy serializability and are applicable to page server DBMSs (although some were originally proposed for object servers). The taxonomy is shown in two parts in Figures 2 and 3. The figures show where proposed algorithms fit in the taxonomy. <p> Of course, the use of avoidance obviates any possible need for detection, so there is no augmentation in the opposite direction within the taxonomy. 3.2 Detection-based Algorithms A number of detection-based algorithms (shown in Figure 2) have been proposed and studied in the literature <ref> [Kim90, Wilk90, Care91a, Wang91, Adya95] </ref>. The main argument for the detection-based approach is simplicity. Because their consistency actions involve only a single client and the server, the detection-based approaches allow the cache management software on the clients to be greatly simplified compared to the ROWA approach. <p> C2PL is one of the simplest algorithms that supports inter-transaction caching, and therefore, algorithms similar to C2PL have been implemented in several systems, including the ORION-1SX prototype [Kim90] and the EXODUS storage manager [Exod93]. An algorithm similar to C2PL has also been studied in <ref> [Wang91] </ref>. For comparison purposes, the performance study also includes results for an algorithm called Basic 2PL (B2PL) that allows only intra-transaction caching. B2PL works similarly to C2PL, except that under B2PL, the client's buffer pool is purged upon transaction termination. <p> More recently, a Callback Locking algorithm that provides transaction serializability has been employed in the ObjectStore OODBMS [Lamb91]. An algorithm similar to CB-R was also studied in <ref> [Wang91] </ref>. 4.1.3 Optimistic Two-Phase Locking (O2PL) The third family of caching algorithms that we have studied is Optimistic Two-phase Locking (O2PL). The O2PL algorithms are derived from a concurrency control protocol that was originally developed for replicated distributed databases [Care91b]. <p> This effect was not detected in [Wilk90] because that study used a probabilistic cache model that assumed that cache hit probabilities were independent of cache size. 5.1.3 No-wait Locking No-wait locking algorithms were studied in <ref> [Wang91] </ref>. No-wait algorithms are detection-based algorithms that try to hide the latency of validations at the server by performing validity checking asynchronously. As with all detection-based algorithms, transactions must abort if they are found to have accessed stale data. <p> As stated in Section 4.1.4, asynchrony does not reduce the total work required, and thus, will not improve performance in a highly utilized system (e.g., if the server is a bottleneck). The performance results of <ref> [Wang91] </ref> showed that an algorithm similar to CB-R typically performed as well as or better than no-wait Locking. To reduce the possibility of stale data access, the no-wait algorithm was extended in [Wang91] with a propagation-based notification hint scheme. <p> The performance results of <ref> [Wang91] </ref> showed that an algorithm similar to CB-R typically performed as well as or better than no-wait Locking. To reduce the possibility of stale data access, the no-wait algorithm was extended in [Wang91] with a propagation-based notification hint scheme. The performance of this algorithm, called No-Wait Locking with Notifications, was then examined. The results of that study showed (as we did in [Care91a]) that the cost of propagations typically outweighs their potential benefits. <p> The results of that study showed (as we did in [Care91a]) that the cost of propagations typically outweighs their potential benefits. An invalidation-based notification scheme could avoid this problem, but such a scheme was not studied in <ref> [Wang91] </ref>. 5.1.4 Dynamic Optimistic Two-Phase Locking The two remaining algorithms shown in the taxonomy of Figures 2 and 3 are variants of O2PL that choose dynamically between invalidation and propagation on a page-by-page basis. The original dynamic algorithm (O2PL-Dynamic) was introduced in [Care91a].
Reference: [Wilk90] <author> Wilkinson, W., Neimat, M., </author> <title> "Maintaining Consistency of Client Cached Data", </title> <booktitle> Proceedings of the 16th International Conference on Very Large Data Bases, </booktitle> <address> Brisbane, Australia, </address> <month> August, </month> <year> 1990. </year> <month> 39 </month>
Reference-contexts: In contrast, inter-transaction data caching raises the need for a cache consistency protocol to ensure that applications always see a consistent (serializable) view of the database. Cache consistency protocols for client-server database systems have been the subject of much study over the past five years <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. Many algorithms have been proposed; these algorithms differ along numerous dimensions such as their level of optimism versus pessimism, their use of invalidation or propagation (i.e., write-invalidate or write-broadcast [Arch86]) for updated data items, and their interaction with transaction management. <p> As a result, there is a wide range of options for the design of such algorithms. This section provides a taxonomy of transactional cache consistency algorithms that encompasses the major algorithms that have appeared in the literature, including <ref> [Wilk90, Care91a, Wang91, Fran92a, Fran93a, Adya95] </ref>. All of these algorithms provide one-copy serializability and are applicable to page server DBMSs (although some were originally proposed for object servers). The taxonomy is shown in two parts in Figures 2 and 3. The figures show where proposed algorithms fit in the taxonomy. <p> Of course, the use of avoidance obviates any possible need for detection, so there is no augmentation in the opposite direction within the taxonomy. 3.2 Detection-based Algorithms A number of detection-based algorithms (shown in Figure 2) have been proposed and studied in the literature <ref> [Kim90, Wilk90, Care91a, Wang91, Adya95] </ref>. The main argument for the detection-based approach is simplicity. Because their consistency actions involve only a single client and the server, the detection-based approaches allow the cache management software on the clients to be greatly simplified compared to the ROWA approach. <p> We then briefly discuss related work in other domains. 5.1 Other Proposed Algorithms 5.1.1 Optimistic Detection-Based Algorithms The first published paper to analyze transactional cache consistency algorithms for client-server OODBMSs was <ref> [Wilk90] </ref>. In that paper, two algorithms were proposed and studied. One algorithm, called Cache Locks, is a detection-based algorithm that defers validation of transactions until commit time. Special lock modes and long-running "envelope transactions" are used to determine when transactions have accessed stale data. <p> This algorithm, called Adaptive Optimistic Concurrency Control (AOCC), is similar to the Cache Locks algorithm; it also includes support for transactions that access data from multiple servers (which is beyond the scope of both <ref> [Wilk90] </ref> and this paper). Rather than using lock modes to represent invalid cached copies, AOCC maintains an invalid set for each client in order to keep track of which copies of the data items cached at a client have been made invalid. <p> as long as the aborted transactions are restarted immediately and tend to access the same items as they did in their previous incarnation (s); otherwise, inefficiencies that were identified for propagation in Section 4.3 may be incurred by this approach as well. 5.1.2 Notify Locks The second algorithm proposed in <ref> [Wilk90] </ref>, Notify Locks, is an avoidance-based algorithm. It is similar to the O2PL-P algorithm described previously in that it defers Write Intention Declaration until the end of transaction execution and uses propagation for remote update actions. <p> The performance tradeoffs between the wait and preempt policies, however, have not been addressed in this study. Of course, because Notify Locks uses propagation, it is clearly subject to the performance problems that we saw for O2PL-P. This effect was not detected in <ref> [Wilk90] </ref> because that study used a probabilistic cache model that assumed that cache hit probabilities were independent of cache size. 5.1.3 No-wait Locking No-wait locking algorithms were studied in [Wang91].
References-found: 60

