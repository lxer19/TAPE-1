URL: ftp://ftp.ai.mit.edu/pub/users/joanna/agents.ps
Refering-URL: http://www.ai.mit.edu/people/joanna/joanna.html
Root-URL: 
Email: Joanna.Bryson@ed.ac.uk  
Title: Agent Architecture as Object Oriented Design  
Author: Joanna Bryson and Brendan McGonigle 
Address: Edinburgh EH8 9JZ, UK  
Affiliation: Laboratory for Cognitive Neuroscience and Intelligent Systems, Edinburgh University  
Abstract: Improving the development of agent intelligence requires improving the mechanisms of that development. This paper explores the application of an established software methodology, object-oriented design, to agent development in two ways. We present a distributed agent architecture, Edmund, and describe first its own object-oriented structure. Then we relate the methodology for developing agent behaviors under Edmund. We explain how this methodology exploits key aspects of object-oriented design, particularly the development of the class hierarchy, as a prototype for agent design.
Abstract-found: 1
Intro-found: 1
Reference: 1. <editor> Special issue: </editor> <booktitle> Software architectures for hardware agents, </booktitle> <year> 1997. </year>
Reference-contexts: The scripting facility also allows for easily switching elements between competences and drives. Our work has more in common with the multi-layered architectures that are currently dominating mobile robotics <ref> [1] </ref>, such as [12, 15, 3]. However, we place more intelligence and learning in what corresponds to the lower, reactive level in these systems.
Reference: 2. <author> J. S. Albus. </author> <title> The NIST real-time control system (RCS): an approach to intelligent systems research. </title> <journal> Journal of Experimental & Theoretical Artificial Intelligence, </journal> <volume> 9(2/3), </volume> <year> 1997. </year>
Reference-contexts: Edmund's control is discussed in the architecture section below. The second problem area we address is the need for specialized, modularized learning. In BBAI, learning tends to be either nonexistent, as in strictly reactive systems [4], or fairly homogeneous, with each behavior having a generic learning capability <ref> [28, 2] </ref>. Often it is monolithic, as in systems that employ reinforcement learning, genetic algorithms, or neural networks to supervise control.
Reference: 3. <author> R. P. Bonasso, R. J. Firby, E. Gat, D. Kortenkamp, D. P. Miller, and M. G. Slack. </author> <title> Experiences with an architecture for intelligent, reactive agents. </title> <journal> Journal of Experimental & Theoretical Artificial Intelligence, </journal> <volume> 9(2/3):237256, </volume> <year> 1997. </year>
Reference-contexts: Edmund is the result of an attempt to scale the behavior-based artificial intelligence (BBAI) approach to building intelligent systems without resorting to hybrid symbolic / reactive architectures such as 3T <ref> [3] </ref> or PRS [13]. During development, Edmund has evolved commonalities with these architectures which we review briefly Section 6. It addresses three problem areas in BBAI, the first being control structure. Strict parallelism provides insufficient bias for action selection and goal persistence. <p> The scripting facility also allows for easily switching elements between competences and drives. Our work has more in common with the multi-layered architectures that are currently dominating mobile robotics [1], such as <ref> [12, 15, 3] </ref>. However, we place more intelligence and learning in what corresponds to the lower, reactive level in these systems. We take the lesson from biology that learning and memory are a part of perception [6, 23], and from Brooks that perception and action must be tightly linked.
Reference: 4. <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> RA-2:1423, </volume> <month> April </month> <year> 1986. </year>
Reference-contexts: Animal intelligence appears to provide sequencing primitives for both representation and action [23, 31]. At the same time, rigidly connected structures as in Brooks' subsumption architecture <ref> [4] </ref> or even as constructed by Firby's RAPs [10] overly constrain behavioral flexibility. Subsumption architecture fixes goal prioritization in a linear order. RAPs constructs tree structures not suited to the continuous, non-terminating processes of life-like agents; processes including language [11]. <p> Edmund's control is discussed in the architecture section below. The second problem area we address is the need for specialized, modularized learning. In BBAI, learning tends to be either nonexistent, as in strictly reactive systems <ref> [4] </ref>, or fairly homogeneous, with each behavior having a generic learning capability [28, 2]. Often it is monolithic, as in systems that employ reinforcement learning, genetic algorithms, or neural networks to supervise control. <p> On the other hand, a perceptual routine for watching for landmarks was successfully moved into walk since it was only needed in the context of motion, and could rely on perceptual memory if it was called less frequently. 6 Discussion: Related and Future Work In describing his subsumption architecture, Brooks <ref> [4] </ref> states that development must begin from the bottom up, with each layer being fully tested before the next is added, so that at every level one is only debugging that level and its interface to the working sublayers.
Reference: 5. <author> Joanna Bryson. </author> <title> The reactive accompanist: Adaptation and behavior decomposition in a music system. </title> <editor> In Luc Steels, editor, </editor> <booktitle> The Biology and Technology of Intelligent Autonomous Agents. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1995. </year>
Reference-contexts: Too many things may be scheduled per second with no direct indication they are failing to execute. This is to some extent an artifact of the reactive nature of the system we expect some events and behaviors to arrest the attention of the agent. 2 Bryson <ref> [5] </ref> has suggested earlier that adaptivity requirements serve as good indicators for be havior decomposition. An initial schedule for Edmund can be computed with the help of simple bench--marking, facilities for which are built into the control program.
Reference: 6. <author> Niel R. Carlson. </author> <title> Physiology of Behavior. </title> <publisher> Allyn and Bacon, </publisher> <address> Boston, 5 edition, </address> <year> 1994. </year>
Reference-contexts: Vertebrate brains have specialization both by organs and regions within organs for storing relevant state, whether that state is fairly transient computations of perceptual or motor information or longer term skills and information <ref> [6] </ref>. BBAI systems with specialized learning or state elements (such as [21, 16]) have been successful, but no principled system for supporting multiple state elements with varying representations has been developed. Edmund addresses this with object-oriented behavior libraries, described in Section 4 below. <p> For example areas of the forebrain such as the amygdala operate on separate channels of sensor input and can interrupt cortical activity by providing independent activation, while elements of the hindbrain maintain metabolic event scheduling independent of cortical sensing and activation <ref> [6] </ref>. The perpetuation of activation and its chaining through competences as described above is related to the problems of binding and attention, issues which are receiving a great deal of attention in neuroscience at the moment. See for example [33, 29]. <p> However, we place more intelligence and learning in what corresponds to the lower, reactive level in these systems. We take the lesson from biology that learning and memory are a part of perception <ref> [6, 23] </ref>, and from Brooks that perception and action must be tightly linked. We are currently reviewing better established architectures. If we can model the essential elements of our approach in a system that provides better tools for development and analysis, we feel we should exploit these programming benefits. <p> Many areas of animal brains, both cortical and subcortical, fuse information from multiple senses. In fact, very few animal behaviors are independent of sensory context. Pitch detection, time sense, and intentional learning and recall all show strong context dependency <ref> [6] </ref>. Encapsulation violations in the object library amount to methods or even functions calling for information from multiple classes. OOD methodologies address the problems of interdependencies by limiting and documenting the points of interface. These OOD methodologies have been directly transferable to ENRL.
Reference: 7. <author> David Chapman. </author> <title> Penguins can make cake. </title> <journal> AI Magazine, </journal> <volume> 10(4):5160, </volume> <year> 1989. </year>
Reference-contexts: So far two libraries have been constructed, one for using visual routines theory in a blocks world simulating (as in <ref> [34, 7] </ref>), and the other for a Nomad 200 mobile robot. This paper focuses on Edmund's Nomad Robot Library (ENRL), which is the more recent work. The Edmund architecture's only interface to its libraries are function pointers that are passed to its primitives on loading.
Reference: 8. <author> Daniel C. Dennett and Marcel Kinsbourne. </author> <title> Time and the observer: The where and when of consciousness in the brain. </title> <journal> Brain and Behavioral Sciences, </journal> <volume> 15:183247, </volume> <year> 1992. </year>
Reference-contexts: Nevertheless, as mentioned in Section 2, behavior library elements are designed to represent different areas of a modular (but not fully encapsulated) memory structure like the brain. This corresponds roughly to Dennett and Kinsbourne's <ref> [8] </ref> multiple drafts hypothesis of awareness . There is no single continuous stream or record Fig. 4. <p> Sonar values are based on a perceptual memory of previous values and rates of change sudden changes may not be believed for nearly half a second, then they just as suddenly replace the old value in the perceptual memory. This approach is consistent with human perception <ref> [8] </ref>. Bumps require a quite different, more persistent form of perceptual memory since, in order to be useful, they need to influence behavior by being avoided for some time, possibly even a minute, after impact.
Reference: 9. <author> Mark d'Inverno, David Kinny, Michael Luck, and Michael Wooldridge. </author> <title> A formal specification of dMARS. </title> <booktitle> In this volume. </booktitle>
Reference-contexts: We are currently reviewing better established architectures. If we can model the essential elements of our approach in a system that provides better tools for development and analysis, we feel we should exploit these programming benefits. One obvious can didate is PRS, discussed extensively in this volume (for example <ref> [9, 17] </ref>). However, there would be a problem with implementation at the level of perception and belief. Edmund's beliefs consist of what is currently reported by its senses, combined with its perceptual memory and built-in biases.
Reference: 10. <author> James Firby. </author> <title> An investigation into reactive planning in complex domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence (AAAI), </booktitle> <pages> pages 202207, </pages> <year> 1987. </year>
Reference-contexts: Animal intelligence appears to provide sequencing primitives for both representation and action [23, 31]. At the same time, rigidly connected structures as in Brooks' subsumption architecture [4] or even as constructed by Firby's RAPs <ref> [10] </ref> overly constrain behavioral flexibility. Subsumption architecture fixes goal prioritization in a linear order. RAPs constructs tree structures not suited to the continuous, non-terminating processes of life-like agents; processes including language [11]. Edmund's architecture addresses the selection bias problem by providing structures for both parallel and sequential control components.
Reference: 11. <author> James Firby. </author> <type> Personal communication, </type> <year> 1995. </year>
Reference-contexts: Subsumption architecture fixes goal prioritization in a linear order. RAPs constructs tree structures not suited to the continuous, non-terminating processes of life-like agents; processes including language <ref> [11] </ref>. Edmund's architecture addresses the selection bias problem by providing structures for both parallel and sequential control components. It addresses the flexibility issue by providing a parallel reactive drive structure, each element of which allows for chaining or looping sub-structures. Edmund's control is discussed in the architecture section below.
Reference: 12. <author> Erann Gat. </author> <title> Reliable Goal-Directed Reactive Control of Autonomous Mobile Robots. </title> <type> PhD thesis, </type> <institution> Virginia Polytechnic Institute and State University, </institution> <year> 1991. </year>
Reference-contexts: The scripting facility also allows for easily switching elements between competences and drives. Our work has more in common with the multi-layered architectures that are currently dominating mobile robotics [1], such as <ref> [12, 15, 3] </ref>. However, we place more intelligence and learning in what corresponds to the lower, reactive level in these systems. We take the lesson from biology that learning and memory are a part of perception [6, 23], and from Brooks that perception and action must be tightly linked.
Reference: 13. <author> M. P. Georgeff and A. L. Lansky. </author> <title> Reactive reasoning and planning. </title> <booktitle> In Proceedings of the Sixth National Conference on Artificial Intelligence (AAAI-87), </booktitle> <pages> pages 677682, </pages> <year> 1987. </year>
Reference-contexts: Edmund is the result of an attempt to scale the behavior-based artificial intelligence (BBAI) approach to building intelligent systems without resorting to hybrid symbolic / reactive architectures such as 3T [3] or PRS <ref> [13] </ref>. During development, Edmund has evolved commonalities with these architectures which we review briefly Section 6. It addresses three problem areas in BBAI, the first being control structure. Strict parallelism provides insufficient bias for action selection and goal persistence.
Reference: 14. <author> David W. Glasspool. </author> <title> Competitive queuing and the articulatory loop. </title> <editor> In J. Levy, D. Bairaktaris, J. Bullinaria, and P. Cairns, editors, </editor> <title> Connectionist Models of Memory and Language. </title> <publisher> UCL Press, </publisher> <year> 1995. </year>
Reference-contexts: Competences are not directly supported, but could exist as sets skills that are collectively stimulated to varying degrees in a particular context, similar to priming in spreading activation networks [24]. Similar action selection mechanisms have been postulated by <ref> [14] </ref>. Drives allow the simulation of parallel activity in non-cortical parts of the brain.
Reference: 15. <author> Henry H. Hexmoor. </author> <title> Representing and Learning Routine Activities. </title> <type> PhD thesis, </type> <institution> State Uni--versity of New York at Buffalo, </institution> <month> December </month> <year> 1995. </year>
Reference-contexts: The scripting facility also allows for easily switching elements between competences and drives. Our work has more in common with the multi-layered architectures that are currently dominating mobile robotics [1], such as <ref> [12, 15, 3] </ref>. However, we place more intelligence and learning in what corresponds to the lower, reactive level in these systems. We take the lesson from biology that learning and memory are a part of perception [6, 23], and from Brooks that perception and action must be tightly linked.
Reference: 16. <author> Ian Horswill. </author> <title> Visual architecture and cognitive architecture. </title> <journal> Journal of Experimental & Theoretical Artificial Intelligence, </journal> <volume> 9(2/3):277293, </volume> <year> 1997. </year>
Reference-contexts: Vertebrate brains have specialization both by organs and regions within organs for storing relevant state, whether that state is fairly transient computations of perceptual or motor information or longer term skills and information [6]. BBAI systems with specialized learning or state elements (such as <ref> [21, 16] </ref>) have been successful, but no principled system for supporting multiple state elements with varying representations has been developed. Edmund addresses this with object-oriented behavior libraries, described in Section 4 below. Finally, a crucial element to scaling is programmability.
Reference: 17. <author> Jaeho Lee and Edmund Durfee. </author> <title> On explicit plan languages for coordinating multiagent plan execution. </title> <booktitle> In this volume. </booktitle>
Reference-contexts: We are currently reviewing better established architectures. If we can model the essential elements of our approach in a system that provides better tools for development and analysis, we feel we should exploit these programming benefits. One obvious can didate is PRS, discussed extensively in this volume (for example <ref> [9, 17] </ref>). However, there would be a problem with implementation at the level of perception and belief. Edmund's beliefs consist of what is currently reported by its senses, combined with its perceptual memory and built-in biases. <p> Certainly Edmund's scripts can be described in formal languages such as Robot Schemes (RS) [19] or Structured Circuit Semantics (SCS) <ref> [17] </ref>. <p> Edmund might then also more easily plug in to multi-agent coordination systems such described in <ref> [17, 30] </ref>. The perception of having a flexible or inevitable action currently blessed by a coordinator [30] could be worked into the action selection routines.
Reference: 18. <author> Peter J. Livesey. </author> <title> Evolutionary Processes, volume 1 of Learning and Emotion: A Biological Synthesis. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <address> Hillsdale, NJ, </address> <year> 1986. </year>
Reference-contexts: Although we consider this a good working principle, in our experience it is not easy to determine that layers are either fully or correctly implemented before other layers that need them have been added. Certainly evolution does not leave primitive brain organs completely untouched, but reuses them creatively <ref> [18] </ref>. Unlike Brooks, we do not expect layers will necessarily be fully or correctly implemented before moving to the next one. If as the project progresses problems are discovered in early levels, earlier scripts exercising only those levels can be used to test that redevelopment does not damage earlier behavior.
Reference: 19. <author> Damion M. Lyons. </author> <title> Representing and analyzing action plans as networks of concurrent processes. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 9(3), </volume> <month> June </month> <year> 1993. </year>
Reference-contexts: Certainly Edmund's scripts can be described in formal languages such as Robot Schemes (RS) <ref> [19] </ref> or Structured Circuit Semantics (SCS) [17].
Reference: 20. <editor> Pattie Maes. </editor> <title> How to do the right thing. </title> <journal> A.I. </journal> <volume> Memo 1180, </volume> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <year> 1989. </year>
Reference-contexts: It addresses three problem areas in BBAI, the first being control structure. Strict parallelism provides insufficient bias for action selection and goal persistence. Tyrrell demonstrates that this is particularly true in non-hierarchical machines such as Maes <ref> [20] </ref>, but suggests it is even a problem with his own hierarchy-based spreading activation approach [32]. Animal intelligence appears to provide sequencing primitives for both representation and action [23, 31].
Reference: 21. <editor> Maja J. Mataric. </editor> <title> Integration of representation into goal-driven behavior-based robots. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 8(3):304312, </volume> <month> June </month> <year> 1992. </year>
Reference-contexts: Vertebrate brains have specialization both by organs and regions within organs for storing relevant state, whether that state is fairly transient computations of perceptual or motor information or longer term skills and information [6]. BBAI systems with specialized learning or state elements (such as <ref> [21, 16] </ref>) have been successful, but no principled system for supporting multiple state elements with varying representations has been developed. Edmund addresses this with object-oriented behavior libraries, described in Section 4 below. Finally, a crucial element to scaling is programmability.
Reference: 22. <author> Brendan McGonigle. </author> <title> Incrementing intelligent systems by design. </title> <editor> In Jean-Arcady Meyer and Stuart Wilson, editors, </editor> <booktitle> From Animals to Animats, </booktitle> <pages> pages 478485, </pages> <address> Cambridge, MA, 1991. </address> <publisher> MIT Press. </publisher>
Reference-contexts: Our laboratory operates on the hypothesis that the most likely way to replicate the natural phenomena of intelligence is through careful design <ref> [22] </ref>. This implies that building on and expanding design methodologies is a necessary component of research into artificial intelligence. This paper describes one of the architectures, Edmund, under development in our laboratory as a platform for cognitive modeling.
Reference: 23. <author> Brendan McGonigle and Margaret Chalmers. </author> <title> The ontology of order. In Les Smith, editor, Piaget: A Critical Assessment. </title> <publisher> Routledge, </publisher> <year> 1996. </year>
Reference-contexts: Tyrrell demonstrates that this is particularly true in non-hierarchical machines such as Maes [20], but suggests it is even a problem with his own hierarchy-based spreading activation approach [32]. Animal intelligence appears to provide sequencing primitives for both representation and action <ref> [23, 31] </ref>. At the same time, rigidly connected structures as in Brooks' subsumption architecture [4] or even as constructed by Firby's RAPs [10] overly constrain behavioral flexibility. Subsumption architecture fixes goal prioritization in a linear order. <p> However, we place more intelligence and learning in what corresponds to the lower, reactive level in these systems. We take the lesson from biology that learning and memory are a part of perception <ref> [6, 23] </ref>, and from Brooks that perception and action must be tightly linked. We are currently reviewing better established architectures. If we can model the essential elements of our approach in a system that provides better tools for development and analysis, we feel we should exploit these programming benefits.
Reference: 24. <author> J. H. Neely. </author> <title> Semantic priming effects in visual word recognition: A selective review of current findings and theories. </title> <editor> In D. Besner and G. W. Humphreys, editors, </editor> <title> Basic Processes in Reading: Visual Word Recognition, chapter 9. </title> <publisher> Lawrence Erlbaum Associates, </publisher> <year> 1991. </year>
Reference-contexts: Behavior sequences are supported in the natural intelligence literature as described in Section 2. Competences are not directly supported, but could exist as sets skills that are collectively stimulated to varying degrees in a particular context, similar to priming in spreading activation networks <ref> [24] </ref>. Similar action selection mechanisms have been postulated by [14]. Drives allow the simulation of parallel activity in non-cortical parts of the brain.
Reference: 25. <author> Nils Nilsson. </author> <title> Shakey the robot. </title> <type> Technical note 323, </type> <institution> SRI International, </institution> <address> Menlo Park, Califor-nia, </address> <month> April </month> <year> 1984. </year>
Reference-contexts: Action sequences provide persistence and reduce the combinatorics of action selection by encoding skills in a canonical way. During execution they maintaining state specifying which element of a skill is currently being executed, and thus which element should be next. Competences are essentially reactive plans, much like triangle tables <ref> [25] </ref>. Drives are similar to competences but may have several elements in some state of execution at the same time, they provide scheduling and priority between parallel tasks for the robot. Like action sequences, competences and drives maintain attentional state while the program is executing.
Reference: 26. <author> Nils Nilsson. </author> <title> Teleo-reactive programs for agent control. </title> <journal> Journal of Artificial Intelligence Research, </journal> <volume> 1:139158, </volume> <year> 1994. </year>
Reference-contexts: To borrow the formalism of SCS, an action sequence is simply a list of atomic actions (where Senses combined with their test are considered to be primitive actions, as are Acts) and a competence could be expressed as a do first. (Competences are also very similar to Nilsson's Teleo-Reactive programs <ref> [26] </ref>.) Although the primitive actions change behavior slightly over time because of their learning, all of these systems have to be robust to unreliable behavior in actions, so these languages might still be used to assist in checking competences for internal cycles or deadlocks.
Reference: 27. <author> Van Parunak, John Sauter, and Steve Clark. </author> <title> Specification and design of industrial synthetic ecosystems. </title> <booktitle> In this volume. </booktitle>
Reference-contexts: The methodology we recommend is iterative, similar to that of OOD. One of the main principles of OOD is rapid prototyping. The design process is first boot-strapped by a combination of analysis and intuition. The process described in <ref> [27] </ref> for multi-agent systems would be adaptable for both object-oriented systems and to some extent Edmund. Once an initial decomposition has been reached, the class hierarchy is evolved as the classes of objects are developed and tested.
Reference: 28. <author> Miles Pebody. </author> <title> Learning and adaptivity: Enhancing reactive behaviour architectures in real-world interaction systems. </title> <editor> In F. Moran, A. Moreno, J.J. Merelo, and P. Chacon, editors, </editor> <booktitle> Advances in Artificial Life (Third European Conference on Artificial Life), </booktitle> <pages> pages 679690, </pages> <address> Berlin, Germany, 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Edmund's control is discussed in the architecture section below. The second problem area we address is the need for specialized, modularized learning. In BBAI, learning tends to be either nonexistent, as in strictly reactive systems [4], or fairly homogeneous, with each behavior having a generic learning capability <ref> [28, 2] </ref>. Often it is monolithic, as in systems that employ reinforcement learning, genetic algorithms, or neural networks to supervise control.
Reference: 29. <author> W. A. Phillips and W. Singer. </author> <title> In search of common cortical foundations. Brain and Behavioral Sciences, </title> <publisher> forthcoming. </publisher>
Reference-contexts: The perpetuation of activation and its chaining through competences as described above is related to the problems of binding and attention, issues which are receiving a great deal of attention in neuroscience at the moment. See for example <ref> [33, 29] </ref>. Direction For moving and detecting motion-relevant information, knows current and preferred directions. Instances correspond to faces of the robot. PMem Perceptual Memory, a short list of recent combined sensor readings. The main source of sensing. No significant instances. Bump Provide information about local invisible obstacles.
Reference: 30. <author> Munindar Singh. </author> <title> A customizable coordination service for autonomous agents. </title> <booktitle> In this volume. </booktitle>
Reference-contexts: Edmund might then also more easily plug in to multi-agent coordination systems such described in <ref> [17, 30] </ref>. The perception of having a flexible or inevitable action currently blessed by a coordinator [30] could be worked into the action selection routines. <p> Edmund might then also more easily plug in to multi-agent coordination systems such described in [17, 30]. The perception of having a flexible or inevitable action currently blessed by a coordinator <ref> [30] </ref> could be worked into the action selection routines. There is a similar imprecise mapping of PRS back into Edmund, which may be useful if only insofar as the development of PRS agents might also exploit this sort of iterative design.
Reference: 31. <author> Jun Tanji. </author> <title> Involvement of motor areas in the medial frontal cortex of primates in temporal sequencing of multiple movements. </title> <editor> In R. Caminiti, K-P Hoffmann, F. Lacquaniti, and J. Altman, editors, </editor> <title> Vision and Movement: </title> <booktitle> Mechanisms in the Cerebral Cortex, </booktitle> <volume> volume 2, </volume> <pages> pages 126133. </pages> <booktitle> Human Frontier Science Program, </booktitle> <address> Strasbourg, </address> <year> 1996. </year>
Reference-contexts: Tyrrell demonstrates that this is particularly true in non-hierarchical machines such as Maes [20], but suggests it is even a problem with his own hierarchy-based spreading activation approach [32]. Animal intelligence appears to provide sequencing primitives for both representation and action <ref> [23, 31] </ref>. At the same time, rigidly connected structures as in Brooks' subsumption architecture [4] or even as constructed by Firby's RAPs [10] overly constrain behavioral flexibility. Subsumption architecture fixes goal prioritization in a linear order.
Reference: 32. <author> Toby Tyrrell. </author> <title> Computational Mechanisms for Action Selection. </title> <type> PhD thesis, </type> <institution> University of Edinburgh, 1993. Centre for Cognitive Science. </institution>
Reference-contexts: Strict parallelism provides insufficient bias for action selection and goal persistence. Tyrrell demonstrates that this is particularly true in non-hierarchical machines such as Maes [20], but suggests it is even a problem with his own hierarchy-based spreading activation approach <ref> [32] </ref>. Animal intelligence appears to provide sequencing primitives for both representation and action [23, 31]. At the same time, rigidly connected structures as in Brooks' subsumption architecture [4] or even as constructed by Firby's RAPs [10] overly constrain behavioral flexibility. Subsumption architecture fixes goal prioritization in a linear order.
Reference: 33. <author> Christoph von der Malsburg. </author> <title> Binding in models of perception and brain function. Current Opinion in Neurobiology, </title> <address> 5:520526, </address> <year> 1995. </year>
Reference-contexts: The perpetuation of activation and its chaining through competences as described above is related to the problems of binding and attention, issues which are receiving a great deal of attention in neuroscience at the moment. See for example <ref> [33, 29] </ref>. Direction For moving and detecting motion-relevant information, knows current and preferred directions. Instances correspond to faces of the robot. PMem Perceptual Memory, a short list of recent combined sensor readings. The main source of sensing. No significant instances. Bump Provide information about local invisible obstacles.
Reference: 34. <author> Steven D. Whitehead. </author> <title> Reinforcement learning for the adaptive control of perception and action. </title> <type> Technical Report 406, </type> <institution> University of Rochester Computer Science, </institution> <month> Feb </month> <year> 1992. </year>
Reference-contexts: So far two libraries have been constructed, one for using visual routines theory in a blocks world simulating (as in <ref> [34, 7] </ref>), and the other for a Nomad 200 mobile robot. This paper focuses on Edmund's Nomad Robot Library (ENRL), which is the more recent work. The Edmund architecture's only interface to its libraries are function pointers that are passed to its primitives on loading.
Reference: 35. <author> Matthew Wilson and Bruce McNaughton. </author> <title> Reactivation of hippocampal ensemble memories during sleep. </title> <booktitle> Science, </booktitle> <address> 261:12271232, </address> <month> 29 July </month> <year> 1994. </year>
Reference-contexts: This suggests that the robot should engage in phased periods of activity, for example switching between sense-intensive work like exploration and compute-intensive work like map learning. This strategy is found in most mammals (e.g. <ref> [35] </ref>), and is facilitated by the Edmund drive system. We are developing a navigation system based on this for the robot have modeled such behavior in simulation. Correcting scheduling problems can also be done incrementally; switching elements between competences and drives can also occur at the control script level.
Reference: 36. <author> Michael Wooldridge and Nicholas R. Jennings. </author> <title> Intelligent agents: </title> <journal> Theory and practice. Knowledge Engineering Review, </journal> <volume> 10(2), </volume> <year> 1995. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Similarly, a methodology is a tool that provides rules for decomposing a problem into manageable sections. Methodology is particularly important in the design of reactive systems, because the reactive approach to intelligent agent research depends entirely on the hand-coding of the agent's behavior <ref> [36] </ref>. Our laboratory operates on the hypothesis that the most likely way to replicate the natural phenomena of intelligence is through careful design [22]. This implies that building on and expanding design methodologies is a necessary component of research into artificial intelligence.
References-found: 36

