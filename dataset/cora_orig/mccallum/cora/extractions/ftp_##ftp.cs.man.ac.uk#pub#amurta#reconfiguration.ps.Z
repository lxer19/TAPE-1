URL: ftp://ftp.cs.man.ac.uk/pub/amurta/reconfiguration.ps.Z
Refering-URL: http://www.cs.man.ac.uk/aig/staff/alan/research/publications.html
Root-URL: http://www.cs.man.ac.uk
Title: Support for Network-Wide Synchronous Communication via the Active Reconfiguration of Transputer Links  
Author: Alan MURTA 
Address: Oxford Road, Manchester, M13 9PL, United Kingdom  
Affiliation: Department of Computer Science, University of Manchester  
Abstract: The occam programming model allows the specification of an arbitrary number of parallel processes, which mutually interact via message passing on synchronous communication channels. Whereas collections of oc-cam processes can be readily mapped onto single transputers, connective limitations can become a problem when the processes are distributed over a network of first-generation transputers. Two problems can occur. Firstly, the number of channels which must enter or leave a given transputer node may exceed the channel carrying capacity of that node's communication links. Secondly, there may be a requirement for channel communication between processes which are located on nodes which are not directly connected by a transputer link. A traditional remedy to this problem is to make use of a software messaging "harness" in which extra processes are used to perform channel-to-link multiplexing and message forwarding activities. This adds complexity to the program, and may result in a loss of synchronisation in remote inter-process communications. This paper describes an alternative solution the active reconfiguration of transputer link connections under program control, which effectively allows direct channel communication between all processes in the network. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Inmos Limited. </author> <title> The T9000 Transputer Products Overview Manual. </title> <booktitle> 1991. </booktitle> <volume> Number 72 TRN 228 00. </volume>
Reference-contexts: 1. Introduction The forthcoming release of a new family of transputer devices represents a significant advance in parallel systems technology <ref> [1] </ref>. The virtual channel multiplexing and wormhole routing of the T9000 and C104 devices offer sophisticated support for distributed inter-process communications. <p> value would be to use a conditional (IF) construct, rather than using a guarded ALT. [no.of.alt.entries] BOOL active : -- initialised FALSE SEQ to.bus.writer [local.alt.id] ! alt.request from.bus.reader [local.alt.id] ? alt.index ; port active [alt.index] := TRUE ALT active [0] & input.on.link [port] ? clause.0.data ... use received data active <ref> [1] </ref> & input.on.link [port] ? clause.1.data ... use received data ... remaining ALT clauses active [alt.index] := FALSE The local.alt.id index value is used in a similar way to the local.ch.id value in the simple channel request protocol. This informs the bus writer which local ALT is making the request.
Reference: [2] <author> J.E. Boillat et al. </author> <title> An analysis and reconfiguration tool for mapping parallel programs onto transputer networks. </title> <editor> In T. Muntean, editor, </editor> <booktitle> Proceedings of the 7th Occam Users Group, </booktitle> <month> September </month> <year> 1987. </year>
Reference-contexts: The allocation of processes to processors is therefore a non-trivial problem. This has provided the motivation for many recent research projects which have considered the automation of various aspects of this task <ref> [2, 3, 4] </ref>. 2.1. The problems of limited node connectivity Many potential difficulties in the task of mapping occam programs onto networks arise from the limited connectivity of each transputer node.
Reference: [3] <author> F.C.M. Lau and K.M. Shea. </author> <title> Mapping a process network onto a processor network. </title> <editor> In C. Askew, editor, </editor> <booktitle> Proceedings of the 9th Occam Users Group, </booktitle> <pages> pages 91-100. </pages> <publisher> IOS Amsterdam, </publisher> <month> September </month> <year> 1988. </year>
Reference-contexts: The allocation of processes to processors is therefore a non-trivial problem. This has provided the motivation for many recent research projects which have considered the automation of various aspects of this task <ref> [2, 3, 4] </ref>. 2.1. The problems of limited node connectivity Many potential difficulties in the task of mapping occam programs onto networks arise from the limited connectivity of each transputer node.
Reference: [4] <author> A.D. Murta. </author> <title> Tools for the automated configuration of a transputer network. </title> <type> Master's thesis, </type> <institution> Department of Computer Science, University of Manchester, </institution> <month> October </month> <year> 1987. </year>
Reference-contexts: The allocation of processes to processors is therefore a non-trivial problem. This has provided the motivation for many recent research projects which have considered the automation of various aspects of this task <ref> [2, 3, 4] </ref>. 2.1. The problems of limited node connectivity Many potential difficulties in the task of mapping occam programs onto networks arise from the limited connectivity of each transputer node.
Reference: [5] <author> A.E. Knowles and T. Kantchev. </author> <title> Message passing in a transputer system. </title> <journal> Microprocessors and Microsystems, </journal> <volume> 13(2), </volume> <month> March </month> <year> 1989. </year>
Reference-contexts: Program complexity A considerable amount of programming effort may be required in the development of a message forwarding harness for a distributed occam program. To remedy this, a number of harness process libraries have been made available in an attempt to simplify the development of transputer based applications <ref> [5, 6] </ref>. The task of modifying an existing application for use within a general purpose communication harness may also be a time consuming exercise, however. The use of a communication harness can also increase the number of concurrently executing processes within an application.
Reference: [6] <author> D. </author> <title> Prior. </title> <journal> Communication harnesses. Edinburgh Concurrent Supercomputer Newsletter, </journal> (8):5-8, July 1989. 
Reference-contexts: Program complexity A considerable amount of programming effort may be required in the development of a message forwarding harness for a distributed occam program. To remedy this, a number of harness process libraries have been made available in an attempt to simplify the development of transputer based applications <ref> [5, 6] </ref>. The task of modifying an existing application for use within a general purpose communication harness may also be a time consuming exercise, however. The use of a communication harness can also increase the number of concurrently executing processes within an application.
Reference: [7] <author> M. Shumway. </author> <title> Deadlock-free packet networks. </title> <booktitle> In Proceedings of the Second Conference of the North American Transputer Users Group, </booktitle> <pages> pages 139-178, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: This lack of information may allow the issue of messages when the intended receiver is not ready to accept incoming communications, which can result in congestion as the limited buffering within the harness fills with undelivered messages. This phenomenon may eventually lead to system deadlock <ref> [7] </ref>. With care, protocols may be devised (in which acknowledgement tokens are returned along the message forwarding path) in order to prevent the issue of multiple messages to unreceptive destinations. Such techniques provide a limited form of syn-chronisation between parallel processes.
Reference: [8] <author> M. Debbage, M. Hill and D. Nicole. </author> <title> A general purpose parallel programming environment. </title> <editor> In J. Edwards, editor, </editor> <booktitle> Proceedings of the 14th World occam and Transputer Users Group, </booktitle> <pages> pages 123-132. </pages> <publisher> IOS Amsterdam, </publisher> <month> September </month> <year> 1991. </year>
Reference-contexts: Although it is possible to design harnesses which support network-wide synchronous communications <ref> [8] </ref> and which are guaranteed to be deadlock free [9, 10], the solutions may impose restrictions on the network topology, or severely degrade overall system performance. 2.3.3.
Reference: [9] <author> W. Dally and C. Seitz. </author> <title> Deadlock-free message routing in multiprocessor interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <month> May </month> <year> 1987. </year>
Reference-contexts: Although it is possible to design harnesses which support network-wide synchronous communications [8] and which are guaranteed to be deadlock free <ref> [9, 10] </ref>, the solutions may impose restrictions on the network topology, or severely degrade overall system performance. 2.3.3.
Reference: [10] <author> A.W. Roscoe. </author> <title> Routing messages through networks: an exercise in deadlock avoidance. </title> <editor> In T. Muntean, editor, </editor> <booktitle> Proceedings of the 7th Occam Users Group, </booktitle> <month> September </month> <year> 1987. </year>
Reference-contexts: Although it is possible to design harnesses which support network-wide synchronous communications [8] and which are guaranteed to be deadlock free <ref> [9, 10] </ref>, the solutions may impose restrictions on the network topology, or severely degrade overall system performance. 2.3.3.
Reference: [11] <author> U. De Carlini and U. Villano. </author> <title> A simple algorithm for clock synchronisation in transputer networks. </title> <journal> Software Practice and Experience, </journal> <volume> 18(4), </volume> <month> April </month> <year> 1988. </year>
Reference-contexts: Experimental results have shown that clock updates must occur every five to ten seconds in order to keep timers within a few tens of microseconds of each other <ref> [11] </ref>. The lack of fully synchronous communications across message forwarding systems can make the maintenance of an accurate global time standard difficult to achieve. Existing solutions use numerical methods in an attempt to minimise the errors which can accumulate when clock synchronisation messages are forwarded through a transputer network.
Reference: [12] <author> G. Stewart. </author> <title> IMS C004 Communication Switch. Inmos Limited, </title> <year> 1986. </year>
Reference-contexts: A novel approach: run-time link reconfiguration A flexible method of building multiple transputer systems is to connect the links via programmable link switching devices, such as the Inmos C004 <ref> [12] </ref>. Link connections passing through the C004 may be installed or broken by applying a command protocol to the switch control port. This allows the configuration of transputer network topologies to be manipulated under software control.
Reference: [13] <author> N.T. Son. </author> <title> Run-time system reconfiguration on the T-Rack. ParSiFal internal document PSF/PCL/WP6/88/3, </title> <institution> Polytechnic of Central London, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: Transputer links may even be disconnected and reconnected in a different network topology, although this may disrupt applications which were not expecting this to happen! It has been suggested that this ability could be used to allow the coarse grain (phased) reconfiguration of transputer networks <ref> [13] </ref>. Under this scheme, different parts of a computation are executed using a network topology which is suited to the current task (a tree structure for initial data broadcasting, and a mesh topology for the calculation phases, for example).
Reference: [14] <author> J.M. Garcia and J. Duato. </author> <title> An advanced environment for programming transputer networks with dynamic reconfiguration. </title> <booktitle> In Proc. Int. Conf. on Parallel Computing and Transputer Applications, </booktitle> <pages> pages 601-610. </pages> <publisher> IOS Press / CINME, </publisher> <month> September </month> <year> 1992. </year>
Reference-contexts: As application processes may not use links without the receipt of an acknowledgement from the controller, any number of processes may safely share link ports on a given transputer. Other parties known to be active in this research area are groups based in Albacete, Spain <ref> [14] </ref> and Lyon, France [15], although neither of these projects are directly concerned with the investigation of general-purpose reconfiguration systems of the kind described here. 2.4.1.
Reference: [15] <author> J.M. Adamo. </author> <title> Virtualising a dynamically reconfigurable machine: From phase-reconfigurable to SPMD programming. In A.F. </title> <editor> Clark, editor, </editor> <booktitle> University of Essex / Parsys Reconfiguration Workshop, </booktitle> <month> August </month> <year> 1992. </year>
Reference-contexts: As application processes may not use links without the receipt of an acknowledgement from the controller, any number of processes may safely share link ports on a given transputer. Other parties known to be active in this research area are groups based in Albacete, Spain [14] and Lyon, France <ref> [15] </ref>, although neither of these projects are directly concerned with the investigation of general-purpose reconfiguration systems of the kind described here. 2.4.1. Benefits The use of run-time link reconfiguration to implement network-wide process communications has the following advantages over static harness based schemes. * Direct channel communications.
Reference: [16] <author> D.L. </author> <title> McBurney and M.R. Sleep. Transputer based experiments with the ZAPP architecture. </title> <booktitle> In PARLE Conference Proceedings, Lecture Notes in Computer Science 258. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: Existing load balancing schemes usually base their o*oading strategy on strictly local (four-neighbourhood) state information <ref> [16] </ref>. * Design considerations. There is no need to specify in advance which links are to be used for particular inter-node channel communications, as the allocation of link resources is handled at run-time by the link control software.
Reference: [17] <author> P.C. Capon, J.R. Gurd and A.E. Knowles. ParSiFal: </author> <title> a parallel simulation facility. </title> <booktitle> IEE Colloquium Digest 1986/91, </booktitle> <pages> pages 2/1-2/3, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: The ParSiFal T-Rack This section briefly describes the hardware platform on which the run-time link reconfiguration system described here was implemented the ParSiFal T-Rack <ref> [17] </ref>. The T-Rack system was one of the first medium-scale transputer machines to be built, being constructed at the University of Manchester as part of the Alvey sponsored ParSiFal project.
Reference: [18] <author> G. Hill. </author> <title> Designs and applications for the IMS C004. </title> <type> Technical Note 19, Inmos Limited, </type> <month> September </month> <year> 1988. </year>
Reference-contexts: A single link connection between application transputers therefore requires a path to be installed through both switch cards, to support bidirectional communication. Twelve C004 devices are used within each card; these are connected in a 3 fi 4 array, as described in <ref> [18] </ref>. Sixty-four of these inputs and outputs connect with the T-Rack application transputers, the remainder may be used for external connections to other T-Racks for example. The switch control transputer provides byte streams to install or remove individual connections within each card.
Reference: [19] <author> P. Jones and A.D. Murta. </author> <title> Support for occam channels via dynamic switching in multi-transputer machines. </title> <editor> In C. Askew, editor, </editor> <booktitle> Proceedings of the 9th Occam Users Group, </booktitle> <pages> pages 101-112. </pages> <publisher> IOS Amsterdam, </publisher> <month> September </month> <year> 1988. </year>
Reference-contexts: A prototype link reconfiguration system A run-time link reconfiguration system has been implemented on the T-Rack, which allows user code running on the application transputers to request switched link resources for inter-node communication. This work is an extension of earlier investigations into reconfigurability reported in <ref> [19] </ref> and [20]. In this implementation, switched link allocation is handled centrally by a link controller process running on the T-Rack control transputer.
Reference: [20] <author> P. Jones and A.D. Murta. </author> <title> Practical experience of run-time link reconfiguration in a multi-transputer machine. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 1(2) </volume> <pages> 171-190, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: A prototype link reconfiguration system A run-time link reconfiguration system has been implemented on the T-Rack, which allows user code running on the application transputers to request switched link resources for inter-node communication. This work is an extension of earlier investigations into reconfigurability reported in [19] and <ref> [20] </ref>. In this implementation, switched link allocation is handled centrally by a link controller process running on the T-Rack control transputer.
Reference: [21] <author> M. Aspnas and T.E. Malen. </author> <title> Transputer benchmark tests. Technical Report, </title> <journal> Ser. A, </journal> <volume> No. 97, </volume> <year> 1989, </year> <institution> Abo Akademi, Finland, </institution> <month> November </month> <year> 1989. </year>
Reference-contexts: Number of Bodies 64 transputers (traditional harness) 64 transputers (link switching) 80 60 40 20 Efficiency = T 64-procs T 1-proc % 100 message forwarding implementation is at an advantage, as the hard-wired link communication bandwidth is approximately twice that of a switched link passing through a three-stage C004 network <ref> [21] </ref>. A better test would have been to configure a ring network using the switched links.
References-found: 21

