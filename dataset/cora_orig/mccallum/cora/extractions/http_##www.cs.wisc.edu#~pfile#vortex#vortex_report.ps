URL: http://www.cs.wisc.edu/~pfile/vortex/vortex_report.ps
Refering-URL: http://www.cs.wisc.edu/~pfile/vortex/vortex.html
Root-URL: 
Email: pfile@cs.wisc.edu, wwt@cs.wisc.edu  
Title: Typhoon-Zero Implementation: The Vortex Module  
Author: Robert W. Pfile 
Date: August 31, 1995  
Address: Wisconsin Madison  
Affiliation: Wisconsin Wind Tunnel Project Computer Sciences Department University of  
Abstract-found: 0
Intro-found: 0
Reference: [Alt95] <author> Altera. </author> <title> Altera 1995 Data Book. </title> <publisher> Altera Corporation, </publisher> <month> March </month> <year> 1995. </year>
Reference-contexts: Finally, we looked at Altera's FLEX8000-series FPGAs <ref> [Alt95] </ref>. This family of parts is SRAM-based, and features high pin counts (up to 208 user I/O pins,) fast clock to Q times for I/O cell flip flops (near 1nS,) high density (up to 1500 flip-flops total,) and can support up to 10 independently-tristatable groups of bidirectional I/O pins.
Reference: [FW95] <author> Babak Falsafi and David A. Wood. </author> <title> When does dedicated protocol processing make sense? Submitted for publication, </title> <month> April </month> <year> 1995. </year>
Reference-contexts: Furthermore, Solaris threads are not necessarily bound to processors, so what we logically consider to be the protocol processor can be either physical processor. Finally, we need not dedicate one of the processors exclusively to protocol handling, instead using both to run compute threads <ref> [FW95] </ref>. In this case access control must be enforced on both processors. For these reasons, we enforce access control unconditionally on both processors. Since Vortex snoops only coherent transactions, the protocol thread can manipulate Tempest memory via uncacheable aliases which do not generate coherent transactions.
Reference: [Kel91] <author> Edmund G. Kelley, et. al. </author> <title> SPARC T M MBus Interface Specification. Sun Microsystems, </title> <publisher> Inc., </publisher> <month> March </month> <year> 1991. </year> <note> Revision 1.2. </note>
Reference-contexts: Finally, we describe our verification process, major problems in the design flow, and the future for this project. Source code and schematics are presented in the appendices. 4 The SPARC Mbus The SPARC Mbus <ref> [Kel91] </ref> is a synchronous processor-memory bus which supports shared-memory multiprocessing. It consists of a 64-bit multiplexed address/data bus and 22 control signals, all driven at TTL levels. Control signals are asserted low, but addresses and data are asserted high.
Reference: [KR95] <author> Mohammed A. S. Khalid and Jonathan Rose. </author> <title> The Effect of Fixed I/O Pin Positioning on The Routability and Speed of FPGAs. </title> <type> Technical Report CSRI-325, </type> <institution> Computer Systems Research Institute, University of Toronto, Toronto, Canada M5S 1A1, </institution> <month> May </month> <year> 1995. </year>
Reference-contexts: Since groups of adjacent I/O cells are connected only to particular FastTracks, preassigned pin constraints can affect routeability of the design, especially those designs with high logic and pin utilization <ref> [KR95] </ref>.
Reference: [PP84] <author> Mark S. Papamarcos and Janak H. Patel. </author> <title> A low-overhead coherence solution for multiprocessors with private cache memories. </title> <booktitle> In Proceedings of the 11th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 348-354, </pages> <year> 1984. </year>
Reference-contexts: Cache blocks are 32 bytes in size and are tagged with the following states: Exclusive Clean, Shared Clean, Invalid, Exclusive Modified and Shared Modified in accordance with the MOESI cache coherence protocol <ref> [PP84] </ref>. When a processor cache is allowed to share memory with other processor caches, it manipulates memory using one of 4 Coherent transactions: Coherent Read (afterward referred to herein as CR), Coherent Invalidate (CI), Coherent Read and Invalidate (CRI) and Coherent Write and Invalidate (CWI).
Reference: [RLW94] <author> Steven K. Reinhardt, James R. Larus, and David A. Wood. Tempest and Typhoon: </author> <title> User-level shared memory. </title> <booktitle> In Proceedings of the 21st Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 325-337, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: : : : : : : : 9 5 Vortex Mbus actions for fine-grain access control : : : : : : : : : : : : : : : : : : : : : : : 11 iv 1 Background 1.1 Tempest The Tempest parallel programming interface <ref> [RLW94] </ref> provides an abstraction upon which shared memory and message passing codes can be built on a variety of parallel computers. <p> These mechanisms can be implemented in a variety of ways, ranging from all-software systems (such as Blizzard-S on the Wisconsin COW [SFL + 94]), to partially hardware assisted implementations (such as Blizzard-E on the CM-5), to high performance all-hardware implementations such as Typhoon <ref> [RLW94] </ref>. 1.2 Fine-Grain Access Control The key mechanism behind Tempest is fine-grain access control, which allows arbitrary user-level protocol code to be associated with small (on the order of cache-block sized) blocks of memory. Tempest specifies fine-grain access control by associating tags with aligned, power-of-two-sized blocks of memory. <p> Typhoon's performance is largely due to the tight integration between fine-grain access control, protocol processing, and the network interface. Simulations show that user-level global cache coherence protocols running on Typhoon perform comparably (within 30%) to that of an all-hardware scheme <ref> [RLW94] </ref>. 1.4 Typhoon-Zero and Vortex In order to prove the feasibility of our ideas, we would like to implement a Typhoon system.
Reference: [SFL + 94] <author> Ioannis Schoinas, Babak Falsafi, Alvin R. Lebeck, Steven K. Reinhardt, James R. Larus, and David A. Wood. </author> <title> Fine-grain access control for distributed shared memory. </title> <booktitle> In Proceedings of the Sixth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS VI), </booktitle> <pages> pages 297-307, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: These are: fine-grain access control, virtual memory management, efficient (low overhead) messaging, and bulk node-to-node data transfers. These mechanisms can be implemented in a variety of ways, ranging from all-software systems (such as Blizzard-S on the Wisconsin COW <ref> [SFL + 94] </ref>), to partially hardware assisted implementations (such as Blizzard-E on the CM-5), to high performance all-hardware implementations such as Typhoon [RLW94]. 1.2 Fine-Grain Access Control The key mechanism behind Tempest is fine-grain access control, which allows arbitrary user-level protocol code to be associated with small (on the order of
Reference: [Sun93] <author> Sun Microsystems, Inc. </author> <title> MBus Module Design Guide. Sun Microsystems, </title> <publisher> Inc., </publisher> <month> May </month> <year> 1993. </year> <note> Version 2.1. </note>
Reference-contexts: Because of the chaotic pin assignments on the FPGAs (described in Section 12.2.2), the manhattan (x-y) lengths of several control and bus signals violate both the overall trace and stub trace length constraints <ref> [Sun93] </ref>. To minimize the routed length of these signals, the Mbus pins were routed by hand, and although many do violate the specification, no timing problems have been observed. <p> This is probably due to the reasons given at the end of Section 7.5; the Mbus we are running on is superior to the specification. 10.3 Signal Termination Mbus Clock signals are terminated with HSMS-2822 series schottky barrier diodes per the module design guide <ref> [Sun93] </ref>. Due to transmission line effects and the fast edge rates (&lt; 1nS) of the Altera FPGAs, signals longer than 3 inches on the Vortex board are susceptible to overshoot, undershoot and ringing.
Reference: [TM91] <author> Donald E. Thomas and Philip Moorby. </author> <title> The Verilog Hardware Description Language. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: Lastly, timing issues related to the partitioning and intra-FPGA routing are considered. All implementation was done using Verilog <ref> [TM91] </ref>, a hardware description language. 9.1 Slave The slave handles all incoming Mbus requests to address spaces that Vortex services. As shown in Figure 15, it consists of decoding logic, an interface to the master logic, an FSM and output logic.
Reference: [Tos94] <author> Toshiba. </author> <title> Toshiba 1994 Static Ram Data Book. Toshiba America Electronic Components, </title> <publisher> Inc., </publisher> <year> 1994. </year>
Reference-contexts: To simplify the hardware, the Tempest block size supported directly by Vortex is the same as the Mbus cache block size, 32 bytes. Therefore, the tag store is 8Mbit, organized as 4M x 2bits, and is implemented with two 25nS 4Mbit x 1 Toshiba TC551402J SRAMS <ref> [Tos94] </ref>. Vortex monitors every transaction on the Mbus. The tag address is determined (see Section 9.4), and driven into the SRAM.
Reference: [Tri94] <author> TriQuint. </author> <title> TriQuint 1994 Clock Products Data Book. TriQuint Semiconductor, </title> <publisher> Inc., </publisher> <year> 1994. </year>
Reference-contexts: To this end, the clock circuitry on the Vortex board is overengineered. Figure 14 schematically depicts our final clocking scheme. For the PLLs, we selected the TriQuint GA1088 <ref> [Tri94] </ref> clock buffer, which includes adjustable outputs. The early clock generated by the first GA1088 is not directly used to clock the FPGA flip-flops; instead another dedicated input is used for the actual clock.
Reference: [vECGS92] <author> Thorsten von Eicken, David E. Culler, Seth Copen Goldstein, and Klaus Erik Schauser. </author> <title> Active messages: a mechanism for integrating communication and computation. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 256-266, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: For instance, it would be desirable to support invalidate (downgrade) & send as a Vortex primitive mechanism, or to directly support Active Messages <ref> [vECGS92] </ref> by extracting the message handler PC from the message and including it in the handlerPC CCR. At the very least, however, we would like to integrate the message handler dispatch method with the block fault handler dispatch method in some way.
References-found: 12

