URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1994/ahpcrc-94-27.ps
Refering-URL: http://www.cs.umn.edu/Users/dept/users/saad/reports/1994/
Root-URL: http://www.cs.umn.edu
Title: Distributed ILU(0) and SOR Preconditioners for Unstructured Sparse Linear Systems  
Author: S. Ma and Y. Saad 
Keyword: Key words: Preconditioning; Distributed ILU(0); point SOR preconditioner; Block SOR; Parallel preconditioners.  
Address: 4-192 EE/CSci Building, 200 Union Street S.E., Minneapolis, MN 55455  
Affiliation: University of Minnesota, Computer Science Department,  
Note: AMS (MOS) Subject Classification: 65F10. Work supported by ARPA under grant number NIST 60NANB2D1272, by NSF under grant number NSF/CCR-9214116, and by AHPCRC (University of Minnesota) under Army Research Office grant number DAAL03-89-C-0038.  
Date: February 23, 1998  
Abstract: There are two common ways of implementing ILU or (S)SOR preconditioned Krylov subspace methods on parallel computers. The first resorts to multicoloring of the adjacency graph and often results in a parallelism of order N, where N is the dimension of the matrix. This strategy sometimes suffers from the deterioration of the rate of convergence. The second technique exploits the intrinsic parallelism available in the original forward and backward solutions. This approach does not suffer from the deterioration of the convergence rate since the resulting algorithm is mathematically equivalent to the original one. On the other hand, the maximum parallelism is limited by the length of the wavefronts which are often nonuniform. In this paper we consider the implementation of these two approaches on distributed memory computers and compare their performance on the CM-5. We have found that for the problems tested ILU(0) with multicoloring outperforms the other alternatives. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. C. Anderson and Y. Saad. </author> <title> Solving sparse triangular systems on parallel computers. </title> <journal> International Journal of High Speed Computing, </journal> <volume> 1 </volume> <pages> 73-96, </pages> <year> 1989. </year>
Reference-contexts: The wavefront technique (or level scheduling) consists of finding this reordering by a pass through the adjacency graph. The new ordering is then explicitly or implicitly exploited. This technique would work equally well for three dimensional problems as well as two dimensional problems. For further details see, for example, <ref> [1, 10] </ref> and the references therein. 3 Distributed ILU (0) and SOR preconditioners In this section we will describe parallel variants of the Block Successive Over-Relaxation (BSOR) and ILU (0) preconditioners for distributed memory environments.
Reference: [2] <institution> The connection machine cm-5 technical summary. </institution> <type> Technical report, </type> <institution> Thinking Machine Corporation, Cambridge, Massachusetts, </institution> <year> 1992. </year>
Reference-contexts: Comparing the communication speed of 5-20 Mbytes/sec with that of about five Mflops/sec of each SPARC microprocessor chip, it is apparent that communication can easily overshadow the performance of the arithmetic of a typical sparse matrix algorithm. For additional details on the architecture of the CM-5 see <ref> [2] </ref>. For details on the performance of the CM-5 for sparse matrix computations, see [9].
Reference: [3] <author> H. C. Elman. </author> <title> Iterative Methods for Large Sparse Nonsymmetric Systems of Linear Equations. </title> <type> PhD thesis, </type> <institution> Yale University, Computer Science Dept., </institution> <address> New Haven, CT., </address> <year> 1982. </year>
Reference-contexts: The problem is discretized using 5-point centered finite differences. This class of problems was described by Elman <ref> [3] </ref>.
Reference: [4] <author> C. C. Jay Kuo and T. F. Chan. </author> <title> Two-color Fourier analysis of iterative algorithms for elliptic problems via red/black ordering. </title> <journal> SIAM J. Scient. Stat. Comput., </journal> <volume> 11 </volume> <pages> 767-793, </pages> <year> 1990. </year>
Reference-contexts: For the model problem, SSOR and the preconditioned-CG with the Red/Black ordering have a worse convergence rate than with the natural ordering, while SOR has the same convergence rate if the optimal ! is used. The following table, see e.g., <ref> [4] </ref>, shows the rates of convergence for the SOR, SSOR, and ILU (0) preconditioned CG methods with natural and red/black ordering for the 5-point Laplacian matrix, when the optimal ! is used.
Reference: [5] <author> M. T. Jones and P. E. Plassmann. </author> <title> Parallel iterative solution of sparse linear systems using ordering from graph coloring heuristics. </title> <type> Technical Report MCS-P198-1290, </type> <institution> Argonne National Lab., Argonne, IL, </institution> <year> 1990. </year>
Reference-contexts: The resulting reduced system is often well-conditioned and this approach works quite well for symmetric problems. This `two-coloring' often referred to as a red-black or checkerboard ordering, can be generalized to arbitrary sparse matrices by using heuristic graph-coloring and independent set order-ings, see, e.g., <ref> [12, 6, 5] </ref>. However, a well-known drawback of this approach is that the resulting convergence of the preconditioned Krylov subspace technique, is often poorer than with the original ordering. An alternative means of parallelizing standard preconditioners, is to use an approach known in the literature as level-scheduling or wavefront technique.
Reference: [6] <author> R. Leuze. </author> <title> Independent set orderings for parallel matrix factorizations by Gaussian elimination. </title> <journal> Parallel Computing, </journal> <volume> 10 </volume> <pages> 177-191, </pages> <year> 1989. </year> <month> 14 </month>
Reference-contexts: The resulting reduced system is often well-conditioned and this approach works quite well for symmetric problems. This `two-coloring' often referred to as a red-black or checkerboard ordering, can be generalized to arbitrary sparse matrices by using heuristic graph-coloring and independent set order-ings, see, e.g., <ref> [12, 6, 5] </ref>. However, a well-known drawback of this approach is that the resulting convergence of the preconditioned Krylov subspace technique, is often poorer than with the original ordering. An alternative means of parallelizing standard preconditioners, is to use an approach known in the literature as level-scheduling or wavefront technique.
Reference: [7] <author> J. A. Meijerink and H. A. van der Vorst. </author> <title> An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix. </title> <journal> Math. Comp., </journal> <volume> 31(137) </volume> <pages> 148-162, </pages> <year> 1977. </year>
Reference-contexts: For both ILU and SOR, we can use multicoloring or level-scheduling at the macro-level, to extract parallelism. Here, by macro-level we mean the level of parallelism corresponding to the processors, or blocks, or subdomains in the domain decomposition framework. 3.1 Distributed ILU (0) In the ILU (0) factorization <ref> [7] </ref> the LU factors have the same nonzero patterns as the original matrix A, so that in distributed mode the references of the entries belonging to the external processors in the ILU (0) factorization are identical with those of the matrix-vector product operation with the matrix A.
Reference: [8] <author> D. O'Leary. </author> <title> Ordering schemes for parallel processing of certain mesh problems. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 5 </volume> <pages> 620-632, </pages> <year> 1984. </year>
Reference-contexts: O ( p Red/Black Ordering O (h) O (h 2 ) O (h) Table 1: Rate of convergence as a function of the mesh-size h, when reordering is used For the nine-point Laplacian with properly selected ! the convergence rate of SOR remains the same as with the natural ordering <ref> [8] </ref>. O'Leary [8] considered several other ordering schemes for the 9-point Laplacian and has shown that the convergence rate of SOR iteration is not worse than that of the natural ordering. From this viewpoint, SOR has a slight advantage over SSOR in the presence of reordering via multi-coloring. <p> p Red/Black Ordering O (h) O (h 2 ) O (h) Table 1: Rate of convergence as a function of the mesh-size h, when reordering is used For the nine-point Laplacian with properly selected ! the convergence rate of SOR remains the same as with the natural ordering <ref> [8] </ref>. O'Leary [8] considered several other ordering schemes for the 9-point Laplacian and has shown that the convergence rate of SOR iteration is not worse than that of the natural ordering. From this viewpoint, SOR has a slight advantage over SSOR in the presence of reordering via multi-coloring.
Reference: [9] <author> S. Petiton, Y. Saad, K. Wu, and W. Ferng. </author> <title> Basic sparse matrix computations on the cm-5. </title> <journal> Internat. J. of Modern Physics, </journal> <volume> 4 </volume> <pages> 65-83, </pages> <year> 1993. </year>
Reference-contexts: For additional details on the architecture of the CM-5 see [2]. For details on the performance of the CM-5 for sparse matrix computations, see <ref> [9] </ref>. The numerical experiments described in this section have been performed in SPMD (Single Program Multiple Data) mode, using CMMD, the CM-5 message-passing library. 4.2 Test problems We take as model problems linear systems that arise from the discretizations of elliptic partial differential equation on a square domain.
Reference: [10] <author> Y. Saad. </author> <title> Krylov subspace methods on supercomputers. </title> <journal> SIAM J. Scient. Stat. Com-put., </journal> <volume> 10 </volume> <pages> 1200-1232, </pages> <year> 1989. </year>
Reference-contexts: The wavefront technique (or level scheduling) consists of finding this reordering by a pass through the adjacency graph. The new ordering is then explicitly or implicitly exploited. This technique would work equally well for three dimensional problems as well as two dimensional problems. For further details see, for example, <ref> [1, 10] </ref> and the references therein. 3 Distributed ILU (0) and SOR preconditioners In this section we will describe parallel variants of the Block Successive Over-Relaxation (BSOR) and ILU (0) preconditioners for distributed memory environments.
Reference: [11] <author> Y. Saad. SPARSKIT: </author> <title> A basic tool kit for sparse matrix computations. </title> <type> Technical Report 90-20, </type> <institution> Research Institute for Advanced Computer Science, NASA Ames Research Center, Moffet Field, </institution> <address> CA, </address> <year> 1990. </year>
Reference-contexts: To store the local matrix we separate it into two parts, a part which acts on the local nodes and a second which acts on the remote nodes. Currently all matrices are stored in the general row-sparse oriented format (CSR format, see <ref> [11] </ref>). The local matrix is stored using the local ordering. The first nloc rows of the (aloc; jaloc; ialoc) data structure for the CSR format reference the interior nodes only. The last nbdy rows reference interface nodes located in the neighboring processors. <p> The number of colors required to multicolor the graph associated with this problem is four. 4.3 Results The matrices were stored in CSR (Compressed Sparse Row) format <ref> [11] </ref> while the ILU factors were stored in the MSR format. In order to avoid deadlocks the adjacency processor list was sorted in ascending order. The parameter ! was set to 1.0 for the BSOR and point-SSOR methods.
Reference: [12] <author> Y. Saad. ILUM: </author> <title> a parallel multi-elimination ILU preconditioner for general sparse matrices. </title> <type> Technical Report 92-241, </type> <institution> University of Minnesota, Army High Performance Computing Research Center, Minneapolis, Minnesota, </institution> <year> 1992. </year> <note> submitted, under revision. </note>
Reference-contexts: The resulting reduced system is often well-conditioned and this approach works quite well for symmetric problems. This `two-coloring' often referred to as a red-black or checkerboard ordering, can be generalized to arbitrary sparse matrices by using heuristic graph-coloring and independent set order-ings, see, e.g., <ref> [12, 6, 5] </ref>. However, a well-known drawback of this approach is that the resulting convergence of the preconditioned Krylov subspace technique, is often poorer than with the original ordering. An alternative means of parallelizing standard preconditioners, is to use an approach known in the literature as level-scheduling or wavefront technique.
Reference: [13] <author> Y. Saad. ILUT: </author> <title> a dual threshold incomplete ILU factorization. </title> <type> Technical Report 92-38, </type> <institution> Minnesota Supercomputer Institute, University of Minnesota, Minneapolis, </institution> <year> 1992. </year> <note> to appear, SISSC. </note>
Reference-contexts: BSOR (l) stands for the Block SOR algorithm described in the previous section, iterated l times for higher accuracy [17]. The vector units were not used for our experiments. For the BSOR method the diagonal blocks were inverted iteratively by GMRES preconditioned with ILU T (4), preconditioning <ref> [13] </ref>. In these inner solves the solution is iterated until the initial residual is reduced by a factor of * = 10 3 .
Reference: [14] <author> Y. Saad. </author> <title> Krylov subspace methods in distributed computing environments. </title> <type> Technical Report 92-126, </type> <institution> Army High Performance Computing Research Center, Minneapolis, MN, </institution> <year> 1992. </year>
Reference-contexts: In this paper we will examine these two broad options and compare them on some model problems on a CM-5 parallel computer. The methods which we consider are designed for general sparse irregularly structured matrices. We exploit the data structures and general approach of distributed sparse matrices described in <ref> [14, 16] </ref>. The underlying assumption we make is that we have a linear system which is row-wise distributed among a number of processors and we would like to implement a 2 distributed preconditioned Krylov subspace method to solve such a system.
Reference: [15] <author> Y. Saad. </author> <title> A flexible inner-outer preconditioned GMRES algorithm. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 14 </volume> <pages> 461-469, </pages> <year> 1993. </year>
Reference-contexts: In order to avoid deadlocks the adjacency processor list was sorted in ascending order. The parameter ! was set to 1.0 for the BSOR and point-SSOR methods. FGMRES, the flexible variant of GMRES <ref> [15, 18] </ref> was used as the outer accelerator. With this option, the preconditioner is allowed to vary at each GM-RES step, as is the case when the preconditioner is defined through an iterative scheme.
Reference: [16] <author> Y. Saad. </author> <title> Data structures and algorithms for domain decomposition and distributed sparse matrix computations. </title> <type> Technical Report 94|, </type> <institution> Army High Performance Computing Research Center, Minneapolis,MN, </institution> <year> 1994. </year>
Reference-contexts: In this paper we will examine these two broad options and compare them on some model problems on a CM-5 parallel computer. The methods which we consider are designed for general sparse irregularly structured matrices. We exploit the data structures and general approach of distributed sparse matrices described in <ref> [14, 16] </ref>. The underlying assumption we make is that we have a linear system which is row-wise distributed among a number of processors and we would like to implement a 2 distributed preconditioned Krylov subspace method to solve such a system. <p> The terms blocks and processors will often be used interchangeably in what follows. In our implementation, we use the general data structure for distributed matrix computations developed in <ref> [16] </ref>. This data-structure handles the general situation where A is irregularly structured. A key feature of the data structure is the separation of the boundary points from the interior points for efficient interprocessor communication. This is illustrated in Figure 2.
Reference: [17] <author> Y. Saad. </author> <title> Highly parallel preconditioners for general sparse matrices. </title> <editor> In G. Golub, M. Luskin, and A. Greenbaum, editors, </editor> <title> Recent Advances in Iterative Methods, </title> <journal> IMA volumes in Mathematics and its Applications, </journal> <volume> volume 60, </volume> <pages> pages 165-199. </pages> <publisher> Springer Verlag, </publisher> <year> 1994. </year>
Reference-contexts: We set fl = 50; fi = 1; * = 0:1; ff = 15, so that the resulting matrices for problem 1 and 2 are nonsymmetric. BSOR (l) stands for the Block SOR algorithm described in the previous section, iterated l times for higher accuracy <ref> [17] </ref>. The vector units were not used for our experiments. For the BSOR method the diagonal blocks were inverted iteratively by GMRES preconditioned with ILU T (4), preconditioning [13]. <p> In these inner solves the solution is iterated until the initial residual is reduced by a factor of * = 10 3 . To obtain the multi-color ordering, we used a simple greedy heuristic described in the literature, see for example, <ref> [17] </ref>. 10 nprocs = 32 nprocs = 128 nprocs = 256 nprocs = 512 cpu/iter MC-BSOR (1) 8.9/22 4.9/38 4.4/44 6.9/60 MC-BSOR (2) 12.2/15 4.5/20 4.6/27 8.7/43 SSOR-Wavefront 6.1/145 5.3/227 6.2/155 8.4/150 DISTILU (0)-Wavefront 4.1/120 3.5/105 4.7/119 6.2/122 DISTILU (0)-Multicol 3.1/119 2.3/102 3.2/122 5.3/138 Table 2: Problem 1 with FDM, fl
Reference: [18] <author> Y. Saad and M. H. Schultz. </author> <title> GMRES: a generalized minimal residual algorithm for solving nonsymmetric linear systems. </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <volume> 7 </volume> <pages> 856-869, </pages> <year> 1986. </year>
Reference-contexts: In order to avoid deadlocks the adjacency processor list was sorted in ascending order. The parameter ! was set to 1.0 for the BSOR and point-SSOR methods. FGMRES, the flexible variant of GMRES <ref> [15, 18] </ref> was used as the outer accelerator. With this option, the preconditioner is allowed to vary at each GM-RES step, as is the case when the preconditioner is defined through an iterative scheme.
References-found: 18

