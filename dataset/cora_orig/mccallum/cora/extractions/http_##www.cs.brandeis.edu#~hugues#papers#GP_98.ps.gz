URL: http://www.cs.brandeis.edu/~hugues/papers/GP_98.ps.gz
Refering-URL: http://www.demo.cs.brandeis.edu/coev_CA/
Root-URL: http://www.cs.brandeis.edu
Email: hugues@cs.brandeis.edu  pollack@cs.brandeis.edu  
Title: Coevolving the "Ideal" Trainer: Application to the Discovery of Cellular Automata Rules  
Author: Hugues Juille Jordan B. Pollack 
Address: Waltham, Massachusetts 02254-9110, USA  Waltham, Massachusetts 02254-9110, USA  
Affiliation: Computer Science Department Brandeis University  Computer Science Department Brandeis University  
Abstract: Coevolution provides a framework to implement search heuristics that are more elaborate than those driving the exploration of the state space in canonical evolutionary systems. However, some drawbacks have also to be overcome in order to ensure continuous progress on the long term. This paper presents the concept of coevolutionary learning and introduces a search procedure which successfully addresses the underlying impediments in coevolutionary search. The application of this algorithm to the discovery of cellular automata rules for a classification task is described. This work resulted in a significant improvement over previously known best rules for this task.
Abstract-found: 1
Intro-found: 1
Reference: <author> Andre, David, Forrest H. Bennett III and John R. </author> <title> Koza (1996). Evolution of intricate long-distance communication signals in cellular automata using genetic programming. </title> <booktitle> In: Proceedings of the Fifth Artificial Life Conference. </booktitle> <pages> pp. 16-18. </pages>
Reference-contexts: This work resulted in an analysis of some of the complex behaviors exhibited by CAs using "particles". The GKL and Das rules are human-written while the Andre-Bennett-Koza (ABK) rule has been discovered using the Genetic Programming paradigm <ref> (Andre et al. 1996) </ref>. For the c = 1=2 task, it is believed that the rules that perform reasonably well have a density close to 0:5 and, indeed, the GKL rule has density 0:5 exactly. An intuitive argument to support this hypothesis is presented in (Mitchell et al. 1993). <p> This information is useful for the understanding of the experimental analysis presented in the following sections. In the research literature, initial work performed by (Das et al. 1994, Mitchell et al. 1994) has been followed by <ref> (Andre et al. 1996) </ref> whose rule improved the case N = 149 but doesn't generalize as well as the GKL or the Das rule. (Sipper 1994) evolved rules for nonhomogeneous CA for which each cell has its own independent version of a rule. (Paredis 1997) describes a GKL rule for 0 <p> It might be possible to evolve even better rules with a larger population size. However, with our current implementation, a run takes about one week on a workstation for 5000 generations and a population size of 1000. As a comparison, <ref> (Andre et al. 1996) </ref> used a population of size 51; 200.
Reference: <author> Capcarrere, M. S., M. Sipper and M. </author> <title> Tomassini (1996). Two-state, r=1 cellular automaton that classifies density. </title> <journal> Physical Review Letters 77(24), </journal> <pages> 4969-4971. </pages>
Reference-contexts: (Sipper 1994) evolved rules for nonhomogeneous CA for which each cell has its own independent version of a rule. (Paredis 1997) describes a GKL rule for 0 2 [0:0; 1:0]. coevolutionary approach to search the space of rules and shows the difficulty of coevolving consistently two populations towards continuous improvement. <ref> (Capcarrere et al. 1996) </ref> also reports that by changing the specification of the convergence pattern of the CA from all 0 0 s or all 1 0 s to a pattern in which a block of at least two consecutive 1 0 s exists if and only if 0 &gt; 1=2
Reference: <author> Cliff, Dave and Geoffrey F. </author> <title> Miller (1995). Tracking the red queen: Measurements of adaptive progress in co-evolutionary simulations. </title> <booktitle> In: The Third Euro-pean Conference on Artificial Life. </booktitle> <publisher> Springer-Verlag. </publisher> <pages> pp. 200-218. </pages> <note> LNCS 929. </note>
Reference-contexts: Pursuer/evader games have also been used as a test problem for research in coevolution. In particular, Cliff and Miller <ref> (Cliff and Miller 1995, Cliff and Miller 1996) </ref> developed several tools to track progress and detect loss of traits resulting from the Red Queen effect. Sims' block-creatures (Sims 1994) and Reynolds' experiments with the game of tag (Reynolds 1994) are also two successful applications of competitive evolution.
Reference: <author> Cliff, Dave and Geoffrey F. </author> <title> Miller (1996). Co-evolution of pursuit and evasion ii: Simulation methods and results. </title> <booktitle> In: Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior (Pattie Maes, </booktitle> <editor> Maja J. Mataric, Jean-Arcady Meyer, Jordan Pollack and Stewart W. Wilson, Eds.). </editor> <publisher> MIT Press. </publisher> <address> Cambridge, Massachusetts. </address> <pages> pp. 506-515. </pages>
Reference: <author> Das, Rajarshi, Melanie Mitchell and James P. </author> <month> Crutch-field </month> <year> (1994). </year> <title> A genetic algorithm discovers particle-based computation in cellular automata. In: Parallel Problem Solving from Nature III, </title> <publisher> LNCS 866. Springer-Verlag. </publisher> <pages> pp. 344-353. </pages>
Reference-contexts: The Gacs-Kurdyumov-Levin (GKL) rule was designed in 1978 for a different goal than the c = 1=2 task (Mitchell et al. 1994). However, for a while it provided the best known performance. (Mitchell et al. 1994) and <ref> (Das et al. 1994) </ref> used Genetic Algorithms (GAs) to explore the space of rules. This work resulted in an analysis of some of the complex behaviors exhibited by CAs using "particles". <p> This information is useful for the understanding of the experimental analysis presented in the following sections. In the research literature, initial work performed by <ref> (Das et al. 1994, Mitchell et al. 1994) </ref> has been followed by (Andre et al. 1996) whose rule improved the case N = 149 but doesn't generalize as well as the GKL or the Das rule. (Sipper 1994) evolved rules for nonhomogeneous CA for which each cell has its own independent <p> In their work, the training environment was composed of a fixed training set constructed from a uniform sampling from the space of all ICs (thus, the distribution for the density of ICs in the training set is binomial, centered on 1=2). In experiments described in <ref> (Das et al. 1994, Mitchell et al. 1994) </ref>, the learning environment is composed of a set of ICs sampled at each generation according to a uniform distribution over 0 2 [0:0; 1:0].
Reference: <author> Hillis, W. </author> <title> Daniel (1992). Co-evolving parasites improve simulated evolution as an optimization procedure. </title> <editor> In: Artificial Life II (Chris Langton et al., Eds.). </editor> <publisher> Addison Wesley. </publisher> <pages> pp. 313-324. </pages>
Reference-contexts: Any slight alteration of an individual in one species results in no improvement or a smaller performance. In the research literature, Hillis' work marked an important step by showing that coevolution can be used to improve search performance <ref> (Hillis 1992) </ref>. In his work, a population of sorters (the hosts) coevolve with input vec tors (the parasites). The goal of sorters is to construct se-quences of comparator-swaps that sort the input vectors that are proposed by the parasites while parasites search for input vectors that are difficult to sort.
Reference: <author> Husbands, </author> <title> Phil (1994). Distributed coevolutionary genetic algorithms for multi-criteria and multi-constraint optimisation. </title> <booktitle> In: Proceedings of Evolutionary computing, AISB Workshop Selected Papers (T. </booktitle> <editor> Fogarty, Ed.). </editor> <publisher> Springer-Verlag. </publisher> <pages> pp. 150-165. </pages> <note> LNCS 865. </note>
Reference-contexts: This work has been followed by others using both competitive and cooperative models of coevolution. For instance, Husbands implemented a model similar to Hillis' to address a generalized version of the job-shop scheduling problem <ref> (Husbands 1994) </ref>. Paredis (Paredis 1996) used competition between a population of solutions and a population of problems as a search strategy for applications in inductive learning (Paredis 1994b) and constraint satisfaction problems (Paredis 1994a). Pursuer/evader games have also been used as a test problem for research in coevolution.
Reference: <author> Juille, Hugues and Jordan B. </author> <title> Pollack (1996). Co-evolving intertwined spirals. </title> <booktitle> In: Proceedings of the Fifth Annual Conference on Evolutionary Programming. </booktitle> <publisher> MIT Press. </publisher> <pages> pp. 461-468. </pages>
Reference-contexts: The definition for the weight of rules is similar. The benefit of resource sharing in the context of search has already been discussed in <ref> (Juille and Pollack 1996) </ref>. The definition of the ICs' fitness has been extended with a new component, namely E (R i ; (IC j )). <p> By providing a methodology in which individuals are evaluated in a changing environment, more elaborate heuristics can be implemented for search. In the system presented in this paper, the principal underlying heuristic introduces a pressure towards adaptability. In previous work <ref> (Juille and Pollack 1996) </ref>, coevolution was used as a niching technique to implement a coverage-based heuristic. Acknowledgment The authors gratefully thank Melanie Mitchell for her help and useful discussions. David Andre made helpful comments on a preliminary version of this paper.
Reference: <author> Land, Mark and Richard K. </author> <title> Belew (1995). No perfect two-state cellular automata for density classification exists. </title> <journal> Physical Review Letters 74(25), </journal> <pages> 1548-1550. </pages>
Reference-contexts: The task c = 1=2 is known to be difficult. In particular, it has been proven that no rule exists that will result in the CA relaxing to the correct state for all possible ICs <ref> (Land and Belew 1995) </ref>. Indeed, the density is (2) which scores 86:0% for N = 149. White squares represent cells in state 0 while black squares correspond to cells in state 1.
Reference: <author> Mitchell, Melanie, James P. Crutchfield and Peter T. </author> <title> Hraber (1994). Evolving cellular automata to perform computations: Mechanisms and impediments. </title> <journal> Physica D 75, </journal> <pages> 361-391. </pages>
Reference-contexts: This is a density classification task, for which one wants the state of the cells of the CA to relax to all 0's or 1's depending on the density of the initial configuration (IC) of the CA, within a maximum of M time steps. Following <ref> (Mitchell et al. 1994) </ref>, c denotes the threshold for the classification task (here, c = 1=2), denotes the density of 1's in a configuration and o denotes the density of 1's in the initial configuration. <p> Table 1 describes the performance for that task for different published rules and different values of N . The Gacs-Kurdyumov-Levin (GKL) rule was designed in 1978 for a different goal than the c = 1=2 task <ref> (Mitchell et al. 1994) </ref>. However, for a while it provided the best known performance. (Mitchell et al. 1994) and (Das et al. 1994) used Genetic Algorithms (GAs) to explore the space of rules. This work resulted in an analysis of some of the complex behaviors exhibited by CAs using "particles". <p> The Gacs-Kurdyumov-Levin (GKL) rule was designed in 1978 for a different goal than the c = 1=2 task <ref> (Mitchell et al. 1994) </ref>. However, for a while it provided the best known performance. (Mitchell et al. 1994) and (Das et al. 1994) used Genetic Algorithms (GAs) to explore the space of rules. This work resulted in an analysis of some of the complex behaviors exhibited by CAs using "particles". <p> This information is useful for the understanding of the experimental analysis presented in the following sections. In the research literature, initial work performed by <ref> (Das et al. 1994, Mitchell et al. 1994) </ref> has been followed by (Andre et al. 1996) whose rule improved the case N = 149 but doesn't generalize as well as the GKL or the Das rule. (Sipper 1994) evolved rules for nonhomogeneous CA for which each cell has its own independent <p> In a first set of experiments composed of about 20 runs, the population size for rules and ICs was 400. The implementation to search the space of rules is similar to the one described in <ref> (Mitchell et al. 1994) </ref>. Each rule is coded on a binary string of length 2 2flr+1 = 128. One-point crossover is used with a 2% bit mutation probability. The population of rules is initialized according to a uniform distribution over [0:0; 1:0] for the density. <p> In their work, the training environment was composed of a fixed training set constructed from a uniform sampling from the space of all ICs (thus, the distribution for the density of ICs in the training set is binomial, centered on 1=2). In experiments described in <ref> (Das et al. 1994, Mitchell et al. 1994) </ref>, the learning environment is composed of a set of ICs sampled at each generation according to a uniform distribution over 0 2 [0:0; 1:0].
Reference: <author> Mitchell, Melanie, Peter T. Hraber and James P. </author> <month> Crutch-field </month> <year> (1993). </year> <title> Revisiting the edge of chaos: Evolving cellular automata to perform computations. </title> <booktitle> Complex Systems 7, </booktitle> <pages> 89-130. </pages>
Reference-contexts: For the c = 1=2 task, it is believed that the rules that perform reasonably well have a density close to 0:5 and, indeed, the GKL rule has density 0:5 exactly. An intuitive argument to support this hypothesis is presented in <ref> (Mitchell et al. 1993) </ref>. It is also believed that the most difficult ICs are those with density close to 0:5 (since only a little modification can make them switch from 0 &lt; 1=2 to 0 &gt; 1=2, and vice versa).
Reference: <author> Moriarty, David Eric (1997). </author> <title> Symbiotic Evolution of Neural Networks in Sequential Decision Tasks. </title> <type> PhD thesis. </type> <institution> University of Texas at Austin, USA. </institution>
Reference-contexts: Cooperative models of coevolution have also been implemented. Such models have been used for function optimization (Potter and De Jong 1994) and for the design of control systems (Potter et al. 1995). Another application is the search of a space of problem decompositions to construct modular solutions <ref> (Potter 1997, Moriarty 1997) </ref>. Following a different track, Paredis (Paredis 1995) designed a model exploiting a symbiotic relationship to coevolve solutions and their representation. In this paper, we introduce a framework which addresses the impediments related to coevolution just discussed and which does result in continuous improvement.
Reference: <author> Paredis, </author> <month> Jan </month> <year> (1994a). </year> <title> Co-evolutionary constraint satisfaction. In: Parallel Problem Solving from Nature - PPSN III, </title> <publisher> LNCS 866. Springer-Verlag. </publisher> <pages> pp. 46-55. </pages>
Reference-contexts: Paredis (Paredis 1996) used competition between a population of solutions and a population of problems as a search strategy for applications in inductive learning (Paredis 1994b) and constraint satisfaction problems <ref> (Paredis 1994a) </ref>. Pursuer/evader games have also been used as a test problem for research in coevolution. In particular, Cliff and Miller (Cliff and Miller 1995, Cliff and Miller 1996) developed several tools to track progress and detect loss of traits resulting from the Red Queen effect.
Reference: <author> Paredis, </author> <month> Jan </month> <year> (1994b). </year> <title> Steps towards co-evolutionary classification neural networks. </title> <booktitle> In: Artificial Life IV (Brooks and Maes, </booktitle> <editor> Eds.). </editor> <publisher> MIT Press. </publisher> <pages> pp. 102-108. </pages>
Reference-contexts: For instance, Husbands implemented a model similar to Hillis' to address a generalized version of the job-shop scheduling problem (Husbands 1994). Paredis (Paredis 1996) used competition between a population of solutions and a population of problems as a search strategy for applications in inductive learning <ref> (Paredis 1994b) </ref> and constraint satisfaction problems (Paredis 1994a). Pursuer/evader games have also been used as a test problem for research in coevolution.
Reference: <author> Paredis, </author> <month> Jan </month> <year> (1995). </year> <title> The symbiotic evolution of solutions and their representations. </title> <booktitle> In: Proceedings of the Sixth International Conference on Genetic Algorithms (Larry J. </booktitle> <editor> Eshelman, Ed.). </editor> <publisher> Morgan Kauf-mann. </publisher> <pages> pp. 359-365. </pages>
Reference-contexts: Such models have been used for function optimization (Potter and De Jong 1994) and for the design of control systems (Potter et al. 1995). Another application is the search of a space of problem decompositions to construct modular solutions (Potter 1997, Moriarty 1997). Following a different track, Paredis <ref> (Paredis 1995) </ref> designed a model exploiting a symbiotic relationship to coevolve solutions and their representation. In this paper, we introduce a framework which addresses the impediments related to coevolution just discussed and which does result in continuous improvement.
Reference: <author> Paredis, </author> <month> Jan </month> <year> (1996). </year> <title> Coevolutionary computation. </title> <journal> Artificial Life. </journal> <note> To appear. </note>
Reference-contexts: This work has been followed by others using both competitive and cooperative models of coevolution. For instance, Husbands implemented a model similar to Hillis' to address a generalized version of the job-shop scheduling problem (Husbands 1994). Paredis <ref> (Paredis 1996) </ref> used competition between a population of solutions and a population of problems as a search strategy for applications in inductive learning (Paredis 1994b) and constraint satisfaction problems (Paredis 1994a). Pursuer/evader games have also been used as a test problem for research in coevolution.
Reference: <author> Paredis, </author> <month> Jan </month> <year> (1997). </year> <title> Coevolving cellular automata: Be aware of the red queen!. </title> <booktitle> In: Proceedings of the Seventh International Conference on Genetic Algorithms (Thomas Back, </booktitle> <address> Ed.). </address> <publisher> Morgan Kaufmann. </publisher> <pages> pp. 393-400. </pages>
Reference-contexts: et al. 1994) has been followed by (Andre et al. 1996) whose rule improved the case N = 149 but doesn't generalize as well as the GKL or the Das rule. (Sipper 1994) evolved rules for nonhomogeneous CA for which each cell has its own independent version of a rule. <ref> (Paredis 1997) </ref> describes a GKL rule for 0 2 [0:0; 1:0]. coevolutionary approach to search the space of rules and shows the difficulty of coevolving consistently two populations towards continuous improvement. (Capcarrere et al. 1996) also reports that by changing the specification of the convergence pattern of the CA from all
Reference: <author> Potter, Mitchell A. </author> <year> (1997). </year> <title> The Design and Analysis of a Computational Model of Cooperative Coevolution. </title> <type> PhD thesis. </type> <institution> George Mason University, Fairfax, Vir-ginia. </institution>
Reference-contexts: Cooperative models of coevolution have also been implemented. Such models have been used for function optimization (Potter and De Jong 1994) and for the design of control systems (Potter et al. 1995). Another application is the search of a space of problem decompositions to construct modular solutions <ref> (Potter 1997, Moriarty 1997) </ref>. Following a different track, Paredis (Paredis 1995) designed a model exploiting a symbiotic relationship to coevolve solutions and their representation. In this paper, we introduce a framework which addresses the impediments related to coevolution just discussed and which does result in continuous improvement.
Reference: <author> Potter, Mitchell A. and Kenneth A. </author> <title> De Jong (1994). A cooperative coevolutionary approach to function optimization. In: Parallel Problem Solving from Nature - PPSN III, </title> <publisher> LNCS 866. Springer-Verlag. </publisher> <pages> pp. 249-257. </pages>
Reference-contexts: In a theoretical analysis (Rosin and Belew 1996), Rosin and Belew described a coevolutionary environment and proved it allows the discovery of perfect game strategies. Cooperative models of coevolution have also been implemented. Such models have been used for function optimization <ref> (Potter and De Jong 1994) </ref> and for the design of control systems (Potter et al. 1995). Another application is the search of a space of problem decompositions to construct modular solutions (Potter 1997, Moriarty 1997).
Reference: <author> Potter, Mitchell A., Kenneth A. </author> <title> De Jong and John J. </title>
Reference: <editor> Grefenstette (1995). </editor> <title> A coevolutionary approach to learning sequential decision rules. </title> <booktitle> In: Proceedings of the Sixth International Conference on Genetic Algorithms (Larry J. </booktitle> <editor> Eshelman, Ed.). </editor> <publisher> Morgan Kauff-mann. </publisher> <address> San Mateo, California. </address> <pages> pp. 366-372. </pages>
Reference: <author> Reynolds, Craig W. </author> <year> (1994). </year> <title> Competition, coevolution, and the game of tag. </title> <booktitle> In: Artificial Life IV (Brooks and Maes, </booktitle> <editor> Eds.). </editor> <publisher> MIT Press. </publisher>
Reference-contexts: In particular, Cliff and Miller (Cliff and Miller 1995, Cliff and Miller 1996) developed several tools to track progress and detect loss of traits resulting from the Red Queen effect. Sims' block-creatures (Sims 1994) and Reynolds' experiments with the game of tag <ref> (Reynolds 1994) </ref> are also two successful applications of competitive evolution. Rosin's work on coevolutionary learning (Rosin 1997) addresses the different issues related to competitive evolution in the context of adversarial problems (e.g., game strategies).
Reference: <author> Rosin, Christopher D. and Richard K. </author> <title> Belew (1996). A competitive approach to game learning. </title> <booktitle> In: Proceedings of the Ninth Annual ACM Conference on Computational Learning Theory. </booktitle>
Reference-contexts: The goal of this work is to define a framework for coevolutionary search that results in continuous progress on the long term. In a theoretical analysis <ref> (Rosin and Belew 1996) </ref>, Rosin and Belew described a coevolutionary environment and proved it allows the discovery of perfect game strategies. Cooperative models of coevolution have also been implemented.
Reference: <author> Rosin, Christopher Darrell (1997). </author> <title> Coevolutionary Search Among Adversaries. </title> <type> PhD thesis. </type> <institution> University of California, </institution> <address> San Diego. </address>
Reference-contexts: Sims' block-creatures (Sims 1994) and Reynolds' experiments with the game of tag (Reynolds 1994) are also two successful applications of competitive evolution. Rosin's work on coevolutionary learning <ref> (Rosin 1997) </ref> addresses the different issues related to competitive evolution in the context of adversarial problems (e.g., game strategies). The goal of this work is to define a framework for coevolutionary search that results in continuous progress on the long term. <p> In the future, our goal is to eliminate some of those explicit components by introducing some heuristics that automatically identify problems that are appropriate for the current set of learners while preventing the Red Queen effect. The work of Rosin <ref> (Rosin 1997) </ref> already describes some methods to address this issue. 2.2 Discussion As stated previously, the coevolutionary learning framework introduces a pressure towards adaptability.
Reference: <author> Schmidhuber, </author> <title> Jurgen (1995). Discovering solutions with low kolmogorov complexity and high generalization capability. </title> <booktitle> In: Machine Learning: Proceedings of the twelfth International Conference (A. </booktitle> <editor> Prieditis amd S. Russell, Ed.). </editor> <publisher> Morgan Kaufmann. </publisher> <pages> pp. 188-196. </pages>
Reference-contexts: The main difficulty is to setup a coevolutionary framework that implements this heuristic accurately and efficiently. The idea of introducing a pressure towards adaptability as the central heuristic for search is not new. Schmidhuber <ref> (Schmidhuber 1995) </ref> proposed the Incremental Self-Improvement system in which adaptability is the measure that is optimized.
Reference: <author> Sims, </author> <title> Karl (1994). Evolving 3d morphology and behavior by competition. </title> <booktitle> In: Artificial Life IV (Brooks and Maes, </booktitle> <editor> Eds.). </editor> <publisher> MIT Press. </publisher> <pages> pp. 28-39. </pages>
Reference-contexts: Pursuer/evader games have also been used as a test problem for research in coevolution. In particular, Cliff and Miller (Cliff and Miller 1995, Cliff and Miller 1996) developed several tools to track progress and detect loss of traits resulting from the Red Queen effect. Sims' block-creatures <ref> (Sims 1994) </ref> and Reynolds' experiments with the game of tag (Reynolds 1994) are also two successful applications of competitive evolution. Rosin's work on coevolutionary learning (Rosin 1997) addresses the different issues related to competitive evolution in the context of adversarial problems (e.g., game strategies).
Reference: <author> Sipper, </author> <title> Moshe (1994). Coevolving non-uniform cellular automata to perform computations. </title> <journal> Physica D 92, </journal> <pages> 193-208. </pages>
Reference-contexts: In the research literature, initial work performed by (Das et al. 1994, Mitchell et al. 1994) has been followed by (Andre et al. 1996) whose rule improved the case N = 149 but doesn't generalize as well as the GKL or the Das rule. <ref> (Sipper 1994) </ref> evolved rules for nonhomogeneous CA for which each cell has its own independent version of a rule. (Paredis 1997) describes a GKL rule for 0 2 [0:0; 1:0]. coevolutionary approach to search the space of rules and shows the difficulty of coevolving consistently two populations towards continuous improvement. (Capcarrere
References-found: 27

