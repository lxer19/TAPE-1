URL: ftp://ftp.cc.gatech.edu/pub/coc/tech_reports/1993/GIT-CC-93-71.ps.Z
Refering-URL: http://www.cs.gatech.edu/tech_reports/index.93.html
Root-URL: 
Email: (kaushik/panesar/fujimoto/schwan@cc.gatech.edu)  
Title: PORTS: A Parallel, Optimistic, Real-Time Simulator  
Author: Kaushik Ghosh, Kiran Panesar, Richard M. Fujimoto and Karsten Schwan 
Date: December 7, 1993  
Pubnum: GIT-CC-93/71  
Abstract: This paper describes issues concerning the design of an optimistic parallel discrete event simulation system that executes in environments that impose real-time constraints on the simulator's execution. Two key problems must be addressed by such a system. First, the timing characteristics of the parallel simulator must be sufficiently predictable to allow one to guarantee that real-time deadlines for completing simulation computations will be met. Second, the optimistic computation must be able to interact with its surrounding environment with as little latency as possible, necessitating rapid commitment of I/O operations. To address the first question, we show that optimistic simulators that never send incorrect messages (sometimes called "aggressive-no-risk" simulators) provide sufficient predictability to allow traditional schedulability analysis techniques commonly used in real-time systems to be applied. We show that incremental state saving techniques introduce sufficient unpredictability that they are not well-suited for real-time environments. We observe that the traditional "lowest timestamp first" scheduling policy used in many optimistic parallel simulation systems is an optimal (in the real-time sense) scheduling algorithm when event timestamps and real-time deadlines are the same. Finally, to address the question of rapid commitment of I/O operations, we utilize a continuous GVT computation scheme for shared-memory multiprocessors where a new value of GVT is computed after processing each event in the simulation. These ideas are incorporated in a parallel, optimistic, real-time simulation system called PORTS. Initial performance measurements of the shared-memory based PORTS system executing on a Kendall Square Research multiprocessor are presented. Initial performance results are encouraging, demonstrating that PORTS achieves performance approaching that of a conventional Time Warp system under several test cases. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. L. Bagrodia and C.-C Shen. </author> <title> Midas: Integrated design and simulation of distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(10) </volume> <pages> 1042-1058, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: These approaches detect synchronization errors (out-of-order execution of events) at runtime, and recover using a rollback mechanism. The focus of our work is in optimistic real-time simulation. This is in contrast to prior work by Bagrodia and Shen that used conservative simulation methods <ref> [26, 1] </ref>. Further, we explicitly consider deadlines on simulation events, and their real-time schedulability analysis, unlike the work described in [31]. Optimistic real-time simulation is challenging because it is difficult to determine in advance what rollbacks will occur.
Reference: [2] <author> Steven Bellenot. </author> <title> Global virtual time algorithms. Distributed Simulation. </title> <booktitle> Proceedings of the SCS Mul ticonference, </booktitle> <year> 1990. </year>
Reference-contexts: We present such an algorithm next. Several algorithms have been proposed in the literature for computing GVT. Software-based GVT schemes either synchronize all processors and take a global snapshot, or compute GVT concurrently with the simulation (e.g., see <ref> [24, 2, 19, 18] </ref>). Schemes utilizing a global snapshot entail an unacceptable amount of overhead for our purposes because we require GVT to be performed very frequently, possibly as often as after each event.
Reference: [3] <author> David L. Black. </author> <title> Scheduling and resource management techniques for multiprocessors. </title> <address> (CMU-CS-90 152), </address> <month> July </month> <year> 1990. </year>
Reference-contexts: The slot list is updated after the reschedule. There are two interrupts associated with each slot: at the `leading edge' of the slot, the processor is handed off <ref> [3] </ref> to the thread that will run that particular event, while at the trailing edge of the slot, the processor is handed off to the `dispatcher thread 7 , which later hands the processor off to a particular event at the next `leading edge' of a slot.
Reference: [4] <author> Ben Blake and Karsten Schwan. </author> <title> Experimental evaluation of a real-time scheduler for a multiprocessor system. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 17(1) </volume> <pages> 34-44, </pages> <month> Jan. </month> <year> 1991. </year>
Reference-contexts: Thus, events are bound to processors. Further, because deadlines and execution times are associated with events, it suffices to perform schedulability analyses on a per-processor basis (rather than following some kind of drafting or bidding <ref> [28, 4] </ref> approach). We follow the ED (earliest deadline first) algorithm for scheduling, which has been proven to be optimal for uniprocessor systems. A slot list is used to perform this schedulability analysis.
Reference: [5] <author> R. Brown. </author> <title> Calendar queues: A fast O(1) priority queue implementation for the simulation event set problem. </title> <journal> Communications of the ACM, </journal> <volume> 31(10) </volume> <pages> 1220-1227, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: We assume the `interrupt processing' takes negligible time; thus, we do not consider queue insertion time. The model can be easily extended to include such overheads, provided they require at most constant time. Hashing schemes such as the calendar queue <ref> [5] </ref> provide possible approaches for achieving constant time queue insertions.
Reference: [6] <author> Houssine Chetto and Maryline Chetto. </author> <title> Some results of the earliest deadline scheduling algorithm. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 1261-1269, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: It is well known that the earliest deadline (ED) first scheduling policy is optimal in keeping real-time deadlines on a single processor <ref> [7, 6] </ref>. Here, we have assumed that the deadline for an event is identical to its timestamp, so the ED scheduling algorithm is identical to the lowest timestamp first (LTF) event scheduling algorithm that is commonly used in optimistic simulators.
Reference: [7] <author> Michael L. Dertouzos and Aloysius K. Mok. </author> <title> Multiprocessor on-line scheduling of hard-real-time tasks. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(12) </volume> <pages> 1497-1506, </pages> <month> December </month> <year> 1989. </year> <month> 17 </month>
Reference-contexts: It is well known that the earliest deadline (ED) first scheduling policy is optimal in keeping real-time deadlines on a single processor <ref> [7, 6] </ref>. Here, we have assumed that the deadline for an event is identical to its timestamp, so the ED scheduling algorithm is identical to the lowest timestamp first (LTF) event scheduling algorithm that is commonly used in optimistic simulators.
Reference: [8] <author> P. M. Dickens and P. F. Reynolds, Jr. </author> <title> SRADS with local rollback. </title> <booktitle> Proceedings of the SCS Multiconfer ence on Distributed Simulation, </booktitle> <volume> 22(1) </volume> <pages> 161-164, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: This idea of delaying message sends until the sending event commits is not new; Reynolds refers to optimistic simulators that do not send false messages as aggressive, no-risk (ANR) simulations [17], and at least two synchronization mechanisms, the SRADS <ref> [8] </ref> and SPEEDES [31] protocols, utilize this approach. However, to our knowledge, the relationship between ANR simulation protocols and guaranteeing deadlines for optimistic real-time simulations has not been previously reported. The following lemma proves that ANR simulations have the NFT property.
Reference: [9] <author> M. Ebling, M. DiLorento, M. Presley, F. Wieland, and D. R. Jefferson. </author> <title> An ant foraging model imple mented on the Time Warp Operating System. </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 21(2) </volume> <pages> 21-26, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Parallel execution offers a promising approach toward achieving high performance, but introduces non-trivial problems in ensuring that the computation is properly synchronized. Optimistic (aggressive) simulations offer a promising approach to achieving high performance, and have been observed to be very effective in speeding up simulations of many applications <ref> [9, 32, 23, 10, 11] </ref>. These approaches detect synchronization errors (out-of-order execution of events) at runtime, and recover using a rollback mechanism. The focus of our work is in optimistic real-time simulation. This is in contrast to prior work by Bagrodia and Shen that used conservative simulation methods [26, 1].
Reference: [10] <author> R. M. Fujimoto. </author> <title> Time Warp on a shared memory multiprocessor. </title> <journal> Transactions of the Society for Computer Simulation, </journal> <volume> 6(3) </volume> <pages> 211-239, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: Parallel execution offers a promising approach toward achieving high performance, but introduces non-trivial problems in ensuring that the computation is properly synchronized. Optimistic (aggressive) simulations offer a promising approach to achieving high performance, and have been observed to be very effective in speeding up simulations of many applications <ref> [9, 32, 23, 10, 11] </ref>. These approaches detect synchronization errors (out-of-order execution of events) at runtime, and recover using a rollback mechanism. The focus of our work is in optimistic real-time simulation. This is in contrast to prior work by Bagrodia and Shen that used conservative simulation methods [26, 1]. <p> As stated earlier, at most t units of time are required to send each antimessage. Cancellation of an unprocessed event just requires that the event be discarded from the event list. We assume that this operation requires a negligible amount of time 2 . Direct cancellation strategies <ref> [10, 11] </ref> avoid the time for searching for the event to be cancelled, and justify this assumption. <p> If the arriving event can be run to completion without violating the deadline of any existing event, it is accepted; otherwise, the event is rejected, and a negative acknowledgement is sent to the sender LP 6 . Thus, in our optimistic simulator which uses direct-cancellation <ref> [10, 11] </ref> on a shared-memory multiprocessor (a KSR-1 machine), the receiving processor is interrupted after the sender has put the arriving message into the receiver's message list. The slot list is updated after the reschedule. <p> The goal of the PORTS system is to achieve performance comparable to Time Warp while guaranteeing that real-time deadlines will be met. We use the Phold model [11] as the application to evaluate performance. We enhanced the shared memory implementation of Time Warp described in <ref> [10] </ref> by the continuous GVT and ANR protocols.
Reference: [11] <author> R. M. Fujimoto. </author> <title> Performance of Time Warp under synthetic workloads. </title> <booktitle> Proceedings of the SCS Multi conference on Distributed Simulation, </booktitle> <volume> 22(1) </volume> <pages> 23-28, </pages> <month> January </month> <year> 1990. </year>
Reference-contexts: Parallel execution offers a promising approach toward achieving high performance, but introduces non-trivial problems in ensuring that the computation is properly synchronized. Optimistic (aggressive) simulations offer a promising approach to achieving high performance, and have been observed to be very effective in speeding up simulations of many applications <ref> [9, 32, 23, 10, 11] </ref>. These approaches detect synchronization errors (out-of-order execution of events) at runtime, and recover using a rollback mechanism. The focus of our work is in optimistic real-time simulation. This is in contrast to prior work by Bagrodia and Shen that used conservative simulation methods [26, 1]. <p> As stated earlier, at most t units of time are required to send each antimessage. Cancellation of an unprocessed event just requires that the event be discarded from the event list. We assume that this operation requires a negligible amount of time 2 . Direct cancellation strategies <ref> [10, 11] </ref> avoid the time for searching for the event to be cancelled, and justify this assumption. <p> If the arriving event can be run to completion without violating the deadline of any existing event, it is accepted; otherwise, the event is rejected, and a negative acknowledgement is sent to the sender LP 6 . Thus, in our optimistic simulator which uses direct-cancellation <ref> [10, 11] </ref> on a shared-memory multiprocessor (a KSR-1 machine), the receiving processor is interrupted after the sender has put the arriving message into the receiver's message list. The slot list is updated after the reschedule. <p> The goal of the PORTS system is to achieve performance comparable to Time Warp while guaranteeing that real-time deadlines will be met. We use the Phold model <ref> [11] </ref> as the application to evaluate performance. We enhanced the shared memory implementation of Time Warp described in [10] by the continuous GVT and ANR protocols.
Reference: [12] <author> Kaushik Ghosh, Richard M. Fujimoto, and Karsten Schwan. </author> <title> Time warp simulation in time constrained systems. </title> <address> (GIT-CC-92/46), </address> <month> October </month> <year> 1992. </year>
Reference-contexts: The execution time of each event is inflated to allow time for rollback computations to be performed, should that become necessary <ref> [12] </ref>. In addition to analyzing the schedulability of event computations, any real-time system must also devise a schedule that indicates when the scheduled events will be executed (this schedule is usually used in the schedulability analysis as well) so that no deadlines are violated.
Reference: [13] <author> Kaushik Ghosh, Richard M. Fujimoto, and Karsten Schwan. </author> <title> A testbed for optimistic execution of real-time simulations. </title> <booktitle> IEEE Workshop on Parallel and Distributed Real-Time Systems, </booktitle> <month> April </month> <year> 1993. </year>
Reference-contexts: The above lemma proves that ANR simulation protocols do not suffer from this problem. Schedulability analysis 3 can be performed on the real-time simulator if * the events conform to NFT (guaranteed for ANR protocols), * a Lazy-Cancellation-like strategy was used to undo erroneous computation (see <ref> [14, 13] </ref> for details), and * the event execution time is inflated by an amount restore state + save state for the purposes of schedulability analysis. The execution time of each event is inflated to allow time for rollback computations to be performed, should that become necessary [12].
Reference: [14] <author> Kaushik Ghosh, Richard M. Fujimoto, and Karsten Schwan. </author> <title> Time warp simulation in time constrained systems. </title> <booktitle> Proceedings of the 7th Workshop on Parallel and Distributed Sim ulation (PADS), </booktitle> <month> May </month> <year> 1993. </year>
Reference-contexts: Optimistic real-time simulation is challenging because it is difficult to determine in advance what rollbacks will occur. This makes the predictability of the computation, and thus one's ability to guarantee that deadlines will be met, unclear. In <ref> [14] </ref> it was shown that Time Warp [16], the most well known optimistic protocol, cannot guarantee deadlines because of the unpredictability of rollbacks for general simulation problems. Thus, Time Warp is poorly suited for real-time simulations. <p> We assume that this operation requires a negligible amount of time 2 . Direct cancellation strategies [10, 11] avoid the time for searching for the event to be cancelled, and justify this assumption. In <ref> [14] </ref>, a restricted class of optimistic simulations is defined as follows: if an incorrect computation (one that will be later rolled back) produces an (incorrect) event E i;T it must be the case that the correct computation also produces an event E i;T with the same timestamp, but possibly different message <p> Events with false timestamps might be produced, and premature execution of events may have to be rolled back. False events have to be cancelled, and premature execution has to be undone by restoration of state and sending antimessages for falsely-scheduled messages. In <ref> [14] </ref> it is shown that these overheads might require unbounded amounts of time, thus severely restricting the use of Time Warp in real-time simulation. Specifically, a result that was proven in [14] is: If there is no constraint on the number of false events that may be created between any two <p> In <ref> [14] </ref> it is shown that these overheads might require unbounded amounts of time, thus severely restricting the use of Time Warp in real-time simulation. Specifically, a result that was proven in [14] is: If there is no constraint on the number of false events that may be created between any two successive true events on an LP, and the per-event overheads of Time Warp (saving and restoring state, sending antimessages) are non-zero, Time Warp cannot guarantee that any set of events can <p> For instance, queueing network simulations are non-NFT. Thus, rather than restricting the range of applications that can be executed on the real-time simulator, as was done in <ref> [14] </ref>, we take another approach. Message sends are not executed until it can be guaranteed that the generated message is a true (correct) message, thereby eliminating all false messages. <p> no event in an ANR simulation that violates NFT. 2 The significance of the above lemma lies in the fact that NFT simulations have sufficient predictability to enable one to determine whether or not an event computation is schedulable, i.e., can be scheduled for execution without later violating real-time constraints <ref> [14] </ref>. Non-schedulable computations must be rejected because if they were allowed to execute, the system would be at risk of violating one or more deadlines. More will be said about rejected computations later. <p> The above lemma proves that ANR simulation protocols do not suffer from this problem. Schedulability analysis 3 can be performed on the real-time simulator if * the events conform to NFT (guaranteed for ANR protocols), * a Lazy-Cancellation-like strategy was used to undo erroneous computation (see <ref> [14, 13] </ref> for details), and * the event execution time is inflated by an amount restore state + save state for the purposes of schedulability analysis. The execution time of each event is inflated to allow time for rollback computations to be performed, should that become necessary [12].
Reference: [15] <author> W. T.-Y. Hsu and P.-C. Yew. </author> <title> An effective synchronization network for hot-spot accesses. </title> <journal> ACM Trans actions on Comuter Systems, </journal> <volume> 10(3) </volume> <pages> 167-189, </pages> <month> August </month> <year> 1992. </year>
Reference-contexts: We present a software implementation for shared-memory multiprocessors. To compute GVT, we maintain a tournament tree, not unlike the hardware reduction networks or algorithms such as that described in <ref> [15] </ref> with processors at the leaves. Each node of the tree has a timestamp associated with it. The timestamp of a node signifies the minimum of the local virtual times of the processors at the leaves in that node's subtree. The value at the root node is the GVT.
Reference: [16] <author> D. R. Jefferson. </author> <title> Virtual time. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 7(3):404 425, </volume> <month> July </month> <year> 1985. </year>
Reference-contexts: Optimistic real-time simulation is challenging because it is difficult to determine in advance what rollbacks will occur. This makes the predictability of the computation, and thus one's ability to guarantee that deadlines will be met, unclear. In [14] it was shown that Time Warp <ref> [16] </ref>, the most well known optimistic protocol, cannot guarantee deadlines because of the unpredictability of rollbacks for general simulation problems. Thus, Time Warp is poorly suited for real-time simulations. This work also defined a class of simulations where Time Warp using lazy cancellation is able to guarantee deadlines.
Reference: [17] <author> Paul F. Reynolds Jr. </author> <title> A spectrum of options for parallel simulation. </title> <booktitle> In Proceedings of the 1988 Winter Simulation Conference, </booktitle> <pages> pages 325-332, </pages> <year> 1988. </year> <month> 18 </month>
Reference-contexts: With this protocol, there is no need for antimessages because message sends are never rolled back. This idea of delaying message sends until the sending event commits is not new; Reynolds refers to optimistic simulators that do not send false messages as aggressive, no-risk (ANR) simulations <ref> [17] </ref>, and at least two synchronization mechanisms, the SRADS [8] and SPEEDES [31] protocols, utilize this approach. However, to our knowledge, the relationship between ANR simulation protocols and guaranteeing deadlines for optimistic real-time simulations has not been previously reported. The following lemma proves that ANR simulations have the NFT property.
Reference: [18] <author> Yi-Bing Lin and Edward D. Laszowska. </author> <title> Determining the global virtual time in a distributed simulation. </title> <booktitle> International Conference on Parallel Processing, </booktitle> <address> III:201-209, </address> <year> 1990. </year>
Reference-contexts: We present such an algorithm next. Several algorithms have been proposed in the literature for computing GVT. Software-based GVT schemes either synchronize all processors and take a global snapshot, or compute GVT concurrently with the simulation (e.g., see <ref> [24, 2, 19, 18] </ref>). Schemes utilizing a global snapshot entail an unacceptable amount of overhead for our purposes because we require GVT to be performed very frequently, possibly as often as after each event. <p> All unacknowledged messages on the processor are searched for the minimum timestamp. The LVT value is then propagated up the GVT tree as far as possible. Finally, all the received messages are acknowledged. As outlined in <ref> [18] </ref> there are two potential problems in any GVT algorithm, unacknowledged messages and the simultaneous update problem. Our algorithm prevents both these race conditions by explicitly acknowledging messages. The sender is responsible for including unacknowledged messages into the GVT computation, until an acknowledge is received.
Reference: [19] <author> Friedemann Mattern. </author> <title> Efficient algorithms for distributed snapshots and global virtual time approxima tion. </title> <type> Draft, </type> <year> 1992. </year>
Reference-contexts: We present such an algorithm next. Several algorithms have been proposed in the literature for computing GVT. Software-based GVT schemes either synchronize all processors and take a global snapshot, or compute GVT concurrently with the simulation (e.g., see <ref> [24, 2, 19, 18] </ref>). Schemes utilizing a global snapshot entail an unacceptable amount of overhead for our purposes because we require GVT to be performed very frequently, possibly as often as after each event.
Reference: [20] <author> Bodhisattwa Mukherjee, Greg Eisenhauer, and Kaushik Ghosh. </author> <title> A machine independent interface for lightweight threads. </title> <booktitle> Submitted to OS Review of the ACM Special Interest Group in Operating Systems. </booktitle>
Reference-contexts: Keeping them distinct ensures generality, and is useful in rolling back to the `middle of' an event, as stated later. 8 We use the same thread for dispatching other threads and performing schedulability analyses. 11 <ref> [25, 20] </ref> was modified to perform these operations. Just as unused memory for events is reclaimed during fossil collection in conventional implementations of Time Warp, we reclaim space used by saved versions of stack and slots, which correspond to times earlier than GVT. The slot list can be optimized.
Reference: [21] <author> C. Pancerella. </author> <title> Improving the efficiency of a framework for parallel simulations. </title> <booktitle> In 6 th Workshop on Parallel and Distributed Simulation, </booktitle> <volume> volume 24, </volume> <pages> pages 22-32. </pages> <booktitle> SCS Simulation Series, </booktitle> <month> January </month> <year> 1992. </year>
Reference-contexts: We require a continuous GVT computation scheme where results from prior GVT computations (e.g., the local minimum computed by a processor) are reused on the next GVT computation. Hardware solutions such as those described in <ref> [22, 21] </ref> provide a good solution to this problem, but such hardware is currently not available for most computing platforms. We present a software implementation for shared-memory multiprocessors.
Reference: [22] <author> Jr. Paul F. Reynolds, Carmen M. Pancerella, and Sudhir Srinivasan. </author> <title> Design and performance analysis of hardware support for parallel simulations. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 18(4) </volume> <pages> 435-453, </pages> <month> Aug. </month> <year> 1993. </year>
Reference-contexts: We require a continuous GVT computation scheme where results from prior GVT computations (e.g., the local minimum computed by a processor) are reused on the next GVT computation. Hardware solutions such as those described in <ref> [22, 21] </ref> provide a good solution to this problem, but such hardware is currently not available for most computing platforms. We present a software implementation for shared-memory multiprocessors.
Reference: [23] <author> M. Presley, M. Ebling, F. Wieland, and D. R. Jefferson. </author> <title> Benchmarking the Time Warp Operating System with a computer network simulation. </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 21(2) </volume> <pages> 8-13, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Parallel execution offers a promising approach toward achieving high performance, but introduces non-trivial problems in ensuring that the computation is properly synchronized. Optimistic (aggressive) simulations offer a promising approach to achieving high performance, and have been observed to be very effective in speeding up simulations of many applications <ref> [9, 32, 23, 10, 11] </ref>. These approaches detect synchronization errors (out-of-order execution of events) at runtime, and recover using a rollback mechanism. The focus of our work is in optimistic real-time simulation. This is in contrast to prior work by Bagrodia and Shen that used conservative simulation methods [26, 1].
Reference: [24] <author> B. Samadi. </author> <title> Distributed simulation, algorithms and performance analysis. </title> <type> Ph. D. Thesis, </type> <institution> University of California, </institution> <address> Los Angeles, </address> <year> 1985. </year>
Reference-contexts: We present such an algorithm next. Several algorithms have been proposed in the literature for computing GVT. Software-based GVT schemes either synchronize all processors and take a global snapshot, or compute GVT concurrently with the simulation (e.g., see <ref> [24, 2, 19, 18] </ref>). Schemes utilizing a global snapshot entail an unacceptable amount of overhead for our purposes because we require GVT to be performed very frequently, possibly as often as after each event.
Reference: [25] <author> Karsten Schwan, Harold Forbes, Ahmed Gheith, Bodhisattwa Mukherjee, and Yiannis Samiotakis. </author> <title> A cthread library for multiprocessors. </title> <address> (GIT-ICS-91/02), </address> <month> January </month> <year> 1991. </year>
Reference-contexts: Keeping them distinct ensures generality, and is useful in rolling back to the `middle of' an event, as stated later. 8 We use the same thread for dispatching other threads and performing schedulability analyses. 11 <ref> [25, 20] </ref> was modified to perform these operations. Just as unused memory for events is reclaimed during fossil collection in conventional implementations of Time Warp, we reclaim space used by saved versions of stack and slots, which correspond to times earlier than GVT. The slot list can be optimized.
Reference: [26] <author> C.-C. Shen and R. Bagrodia. </author> <title> Pips: An integrated approach to the design of real-time systems. </title> <booktitle> Pro ceedings of the 8th IEEE Workshop on Real-Time Operating Systems and Software, </booktitle> <pages> pages 42-46, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: These approaches detect synchronization errors (out-of-order execution of events) at runtime, and recover using a rollback mechanism. The focus of our work is in optimistic real-time simulation. This is in contrast to prior work by Bagrodia and Shen that used conservative simulation methods <ref> [26, 1] </ref>. Further, we explicitly consider deadlines on simulation events, and their real-time schedulability analysis, unlike the work described in [31]. Optimistic real-time simulation is challenging because it is difficult to determine in advance what rollbacks will occur.
Reference: [27] <author> Wei-Kuan Shih and Jane W. S. Liu. </author> <title> On-line scheduling of imprecise computations to minimize error. </title> <booktitle> In Proceedings of IEEE Real-Time Systems Symposium, </booktitle> <year> 1992. </year>
Reference-contexts: However, E 4 requires 1 unit of time to execute, and therefore misses its deadline. 6 We assume that there is some `higher-level' software that takes care of such situations. One way to handle these situations is the use of primary and secondary versions of algorithms <ref> [27] </ref>: essentially, reverting to `coarser' models of simulation. 7 These threads may be the same in certain implementations.
Reference: [28] <author> John A. Stankovic. </author> <title> Stability and distributed algorithms. </title> <journal> IEEE Transactions on Software Engineering, </journal> <pages> pages 1141-1152, </pages> <month> Oct. </month> <year> 1985. </year>
Reference-contexts: Thus, events are bound to processors. Further, because deadlines and execution times are associated with events, it suffices to perform schedulability analyses on a per-processor basis (rather than following some kind of drafting or bidding <ref> [28, 4] </ref> approach). We follow the ED (earliest deadline first) algorithm for scheduling, which has been proven to be optimal for uniprocessor systems. A slot list is used to perform this schedulability analysis.
Reference: [29] <author> John A. Stankovic and Krithi Ramamritham. </author> <title> Editorial: What is predictability for real-time systems? Real-Time Systems, </title> <booktitle> 2(4) </booktitle> <pages> 247-254, </pages> <month> November </month> <year> 1991. </year>
Reference-contexts: The real-time scheduler has to ensure that recovery does not take inordinately long. Also, predictability plays a major role in real-time simulations: there should not be large variances between the execution time of a primitive when it is performed several times <ref> [29] </ref>. Essential problems associated with using optimistic schemes such as Time Warp for real-time simulation include the following: * predictability of execution with respect to real-time, * fast commitment of operations, and * state saving and restoration overheads.
Reference: [30] <author> Jeff S. Steinman. </author> <title> Incremental state saving in SPEEDES using C++, unpublished document. </title>
Reference-contexts: SPEEDES, for instance, performs an optimization to improve the efficiency of state saving. In this incremental state-saving mechanism (called the Delta Exchange in SPEEDES <ref> [30] </ref>), state saving is performed after each event; however, instead of saving the whole state associated with that event (i.e., the complete set of state variables that the event might update), SPEEDES `saves' only the bytes that the event had actually updated.
Reference: [31] <author> Jeff S. Steinman. SPEEDES: </author> <title> A multiple-synchronization environment for parallel discrete-event simu lation. </title> <booktitle> In International Journal in Computer Simulation, </booktitle> <pages> pages 251-286, </pages> <year> 1992. </year>
Reference-contexts: The focus of our work is in optimistic real-time simulation. This is in contrast to prior work by Bagrodia and Shen that used conservative simulation methods [26, 1]. Further, we explicitly consider deadlines on simulation events, and their real-time schedulability analysis, unlike the work described in <ref> [31] </ref>. Optimistic real-time simulation is challenging because it is difficult to determine in advance what rollbacks will occur. This makes the predictability of the computation, and thus one's ability to guarantee that deadlines will be met, unclear. <p> This idea of delaying message sends until the sending event commits is not new; Reynolds refers to optimistic simulators that do not send false messages as aggressive, no-risk (ANR) simulations [17], and at least two synchronization mechanisms, the SRADS [8] and SPEEDES <ref> [31] </ref> protocols, utilize this approach. However, to our knowledge, the relationship between ANR simulation protocols and guaranteeing deadlines for optimistic real-time simulations has not been previously reported. The following lemma proves that ANR simulations have the NFT property.
Reference: [32] <author> F. Wieland, L. Hawley, A. Feinberg, M. DiLorento, L. Blume, P. Reiher, B. Beckman, P. Hontalas, S. Bellenot, and D. R. Jefferson. </author> <title> Distributed combat simulation and Time Warp: The model and its performance. </title> <booktitle> Proceedings of the SCS Multiconference on Distributed Simulation, </booktitle> <volume> 21(2) </volume> <pages> 14-20, </pages> <month> March </month> <year> 1989. </year>
Reference-contexts: Parallel execution offers a promising approach toward achieving high performance, but introduces non-trivial problems in ensuring that the computation is properly synchronized. Optimistic (aggressive) simulations offer a promising approach to achieving high performance, and have been observed to be very effective in speeding up simulations of many applications <ref> [9, 32, 23, 10, 11] </ref>. These approaches detect synchronization errors (out-of-order execution of events) at runtime, and recover using a rollback mechanism. The focus of our work is in optimistic real-time simulation. This is in contrast to prior work by Bagrodia and Shen that used conservative simulation methods [26, 1].
Reference: [33] <author> Hongyi Zhou. </author> <title> Task Scheduling and Synchronization for Multiprocessor Real-Time Systems. </title> <type> PhD thesis, </type> <institution> College of Computing, Georgia Institute of Technology, </institution> <address> Atlanta, GA, </address> <month> April </month> <year> 1992. </year> <month> 19 </month>
Reference-contexts: The hash table provides a better starting point for the traversal than would be otherwise obtained. This achieves much the same effect as the `slot-merging' technique used in <ref> [33] </ref>, and becomes especially important if there are a lot of slots in the system. Figure 4 provides an example to explain the hashing technique. Suppose that there are events with deadlines as shown in Figure 4.
References-found: 33

