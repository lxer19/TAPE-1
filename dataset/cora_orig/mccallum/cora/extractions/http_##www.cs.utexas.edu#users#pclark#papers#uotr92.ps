URL: http://www.cs.utexas.edu/users/pclark/papers/uotr92.ps
Refering-URL: http://www.cs.utexas.edu/users/pclark/papers/uotr92.abs.html
Root-URL: 
Email: fpclark,stang@csi.uottawa.ca  
Title: Domain Theories using Abstract Background Knowledge  
Author: Peter Clark and Stan Matwin 
Address: Ontario, CANADA K1N 6N5  
Affiliation: Ottawa Machine Learning Group Computer Science, University of Ottawa  
Note: Learning  
Abstract: Tech Report TR-92-95, Dept CS, Univ. Ottawa, Canada, (1992) http://www.cs.utexas.edu/users/pclark/papers/uotr92.ps Abstract Substantial machine learning research has addressed the task of learning new knowledge given a (possibly incomplete or incorrect) domain theory, but leaves open the question of where such domain theories originate from in the first place. In this paper we address the problem of constructing a domain theory itself from more general, abstract knowledge which may be available. The basis of our method is to first assume a structure of the target domain theory, and second to view background knowledge as constraints on components of that structure. This enables a focusing of search during learning, and also produces a domain theory which is explainable with respect to the background knowledge. We present a general framework for this task and describe learning algorithms which can be employed, and then apply a particular instance of it to the domain of economics. In this application domain, the background knowledge is a qualitative model expressing plausible economic relationships, examples are sets of numeric economic data, and the learning task is to induce a domain theory for predicting the future movement of economic parameters from this qualitative background knowledge and data. We evaluate the value of this approach, and finally speculate on ways this method could be extended.
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Derek Sleeman and Peter Edwards, editors. </editor> <booktitle> Proc. Ninth Int. Machine Learning Conference, </booktitle> <address> Ca, 1992. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: 1 Introduction Machine learning research is now heavily focussed on knowledge-intensive learning methods (eg. <ref> [1] </ref>), an essential step in the field's development. An important advance has been the development of systems which will learn given an initial (possibly incomplete or incorrect) domain theory (eg. ML-Smart [2], Focl [3], Forte [4], Either [5]).
Reference: [2] <author> Francesco Bergadano and Attilio Giordana. </author> <title> A knowledge-intensive approach to concept induction. </title> <editor> In John Laird, editor, </editor> <booktitle> ML-88 (Proc. Fifth Int. Machine Learning Conference), </booktitle> <pages> pages 305-317, </pages> <address> Ca, 1988. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: 1 Introduction Machine learning research is now heavily focussed on knowledge-intensive learning methods (eg. [1]), an essential step in the field's development. An important advance has been the development of systems which will learn given an initial (possibly incomplete or incorrect) domain theory (eg. ML-Smart <ref> [2] </ref>, Focl [3], Forte [4], Either [5]). Despite this, the issue of how such domain theories can be learned in the first place remains a difficult open problem. Although there have been significant recent advances in inductive learning technology, in particular in Inductive Logic Programming (eg. <p> In early EBL work (eg. [19]) it was assumed that the domain theory included precise definitions of non-operational terms; in other words, there was a `bridge' given spanning the gap between non-operational and operational expressions. More recent work on integrating EBL and similarity-based learning (SBL) (eg. <ref> [2, 3] </ref>) has looked at relaxing the assumption that non-operational terms will have correct definitions. The systems ML-SMART and FOCL both consider the case where there may be disjunctive and possibly erroneous definitions of terms.
Reference: [3] <author> Michael Pazzani and Dennis Kibler. </author> <title> The utility of knowledge in inductive learning. </title> <journal> Machine Learning Journal, </journal> <note> 1992. (To appear). </note>
Reference-contexts: 1 Introduction Machine learning research is now heavily focussed on knowledge-intensive learning methods (eg. [1]), an essential step in the field's development. An important advance has been the development of systems which will learn given an initial (possibly incomplete or incorrect) domain theory (eg. ML-Smart [2], Focl <ref> [3] </ref>, Forte [4], Either [5]). Despite this, the issue of how such domain theories can be learned in the first place remains a difficult open problem. Although there have been significant recent advances in inductive learning technology, in particular in Inductive Logic Programming (eg. <p> In early EBL work (eg. [19]) it was assumed that the domain theory included precise definitions of non-operational terms; in other words, there was a `bridge' given spanning the gap between non-operational and operational expressions. More recent work on integrating EBL and similarity-based learning (SBL) (eg. <ref> [2, 3] </ref>) has looked at relaxing the assumption that non-operational terms will have correct definitions. The systems ML-SMART and FOCL both consider the case where there may be disjunctive and possibly erroneous definitions of terms.
Reference: [4] <author> Bradley L. Richards and Raymond J. Mooney. </author> <title> First-order theory revision. </title> <booktitle> In ML-91 (Proc. Eighth Int. Machine Learning Workshop), </booktitle> <pages> pages 447-451, </pages> <address> Ca, 1991. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: 1 Introduction Machine learning research is now heavily focussed on knowledge-intensive learning methods (eg. [1]), an essential step in the field's development. An important advance has been the development of systems which will learn given an initial (possibly incomplete or incorrect) domain theory (eg. ML-Smart [2], Focl [3], Forte <ref> [4] </ref>, Either [5]). Despite this, the issue of how such domain theories can be learned in the first place remains a difficult open problem. Although there have been significant recent advances in inductive learning technology, in particular in Inductive Logic Programming (eg. <p> Here, it is assumed a domain theory is available but may contain errors. The learning task is to remove these errors, typically using examples to guide learning (eg. Either [5], Forte <ref> [4] </ref>, Krust [18]). Our work shares some aspects of these systems, but differs in that we do not assume a `nearly correct' theory but instead assume more abstract knowledge.
Reference: [5] <author> Raymond J. Mooney and Dick Ourston. </author> <title> Constructive induction in theory refinement. </title> <booktitle> In ML-91 (Proc. Eighth Int. Machine Learning Workshop), </booktitle> <pages> pages 178-182, </pages> <address> Ca, 1991. </address> <publisher> Kaufmann. </publisher> <pages> 17 </pages>
Reference-contexts: An important advance has been the development of systems which will learn given an initial (possibly incomplete or incorrect) domain theory (eg. ML-Smart [2], Focl [3], Forte [4], Either <ref> [5] </ref>). Despite this, the issue of how such domain theories can be learned in the first place remains a difficult open problem. Although there have been significant recent advances in inductive learning technology, in particular in Inductive Logic Programming (eg. <p> Here, it is assumed a domain theory is available but may contain errors. The learning task is to remove these errors, typically using examples to guide learning (eg. Either <ref> [5] </ref>, Forte [4], Krust [18]). Our work shares some aspects of these systems, but differs in that we do not assume a `nearly correct' theory but instead assume more abstract knowledge.
Reference: [6] <author> S. Muggleton and C. Feng. </author> <title> Efficient induction of logic programs. </title> <booktitle> In First International Conference on Algorithmic Learning Theory, </booktitle> <pages> pages 369-381, </pages> <address> Tokyo, Japan, </address> <year> 1990. </year> <journal> Japanese Society for Artificial Intellligence. </journal>
Reference-contexts: ML-Smart [2], Focl [3], Forte [4], Either [5]). Despite this, the issue of how such domain theories can be learned in the first place remains a difficult open problem. Although there have been significant recent advances in inductive learning technology, in particular in Inductive Logic Programming (eg. Golem <ref> [6] </ref>, Foil [7]), it is still well-recognised that to learn all but the simplest domain theories some other form of background knowledge is required to constrain search.
Reference: [7] <author> J. R. Quinlan. </author> <title> Learning logical definitions from relations. </title> <journal> Machine Learning, </journal> <volume> 5(3) </volume> <pages> 239-266, </pages> <month> Aug </month> <year> 1990. </year>
Reference-contexts: Despite this, the issue of how such domain theories can be learned in the first place remains a difficult open problem. Although there have been significant recent advances in inductive learning technology, in particular in Inductive Logic Programming (eg. Golem [6], Foil <ref> [7] </ref>), it is still well-recognised that to learn all but the simplest domain theories some other form of background knowledge is required to constrain search.
Reference: [8] <author> James C. Lester and Bruce W. Porter. </author> <title> Generating context-sensitive explanations in interactive knowledge-based systems. </title> <type> Tech. Report AI-91-160, </type> <institution> Univ. Austin at Texas, TX, </institution> <year> 1991. </year>
Reference-contexts: We thus view an idealised domain theory as task-specific, coherent 1 1 loosely meaning internally consistent: A formal definition of coherence is difficult to capture, eg. see <ref> [8] </ref> and related papers for discussion. 1 and non-redundant (avoids details irrelevant to the task). In contrast, background knowledge may be over-general (for the performance task), ambiguous and contain more inconsistencies.
Reference: [9] <author> Anne v.d.L. Gardner. </author> <title> The design of a legal analysis program. </title> <booktitle> In AAAI-83, </booktitle> <pages> pages 114-118, </pages> <year> 1983. </year>
Reference-contexts: Here a language gap exists between the terminology of the background knowledge and of the examples' descriptions, with no clear mapping between the two. This problem is a recurring one in learning (eg. <ref> [9, 10] </ref>). We apply our framework by assuming a `two-layered' structure for the target domain theory, in which the top layer comprises of qualitative prediction rules extracted from the model and the bottom layer defines a mapping between the qualitative terms and quantitive data, thus spanning this gap.
Reference: [10] <author> Bruce W. Porter, Ray Bareiss, and Robert C. Holte. </author> <title> Concept learning and heuristic classification in weak-theory domains. </title> <journal> Artificial Intelligence, </journal> <volume> 45 </volume> <pages> 229-263, </pages> <year> 1990. </year>
Reference-contexts: Here a language gap exists between the terminology of the background knowledge and of the examples' descriptions, with no clear mapping between the two. This problem is a recurring one in learning (eg. <ref> [9, 10] </ref>). We apply our framework by assuming a `two-layered' structure for the target domain theory, in which the top layer comprises of qualitative prediction rules extracted from the model and the bottom layer defines a mapping between the qualitative terms and quantitive data, thus spanning this gap.
Reference: [11] <author> Ranan B. Banerji. </author> <title> Learning theoretical terms. </title> <editor> In Stephen Muggleton, editor, </editor> <booktitle> Inductive Logic Programming. </booktitle> <year> 1992. </year>
Reference-contexts: ! T k (3) where F i 2 F are literals whose truth value on examples is known and G i 2 G are other literals with known definitions (eg. arithmetic tests). 3 The T i can be described as ill-defined `theoretical' terms, and the F i as `observational' terms <ref> [11] </ref>, the two-layer structure distinguishing between these two vocabularies of background knowledge and observation. We call a clause of type (2) a rule, and a clause of type (3) a definition.
Reference: [12] <author> J. R. Quinlan, P. J. Compton, K. A. Horn, and L. Lazarus. </author> <title> Inductive knowledge acquisition: a case study. </title> <booktitle> In Applications of Expert Systems, </booktitle> <pages> pages 157-173. </pages> <publisher> Addison-Wesley, </publisher> <address> Wokingham, UK, </address> <year> 1987. </year>
Reference-contexts: In this section we review work related to this goal. 3.1 Theory Construction Systems In the simplest case, propositional rule learning systems (eg. C4.5 <ref> [12] </ref>, CN2 [13]) can be seen as learning very simple `domain theories' for a classification task, using no background knowledge. The limited expressiveness of these systems' rule languages, and the labour-intensive task of choosing a suitable representation of examples, are well-known limitations which more recent work has sought to overcome.
Reference: [13] <author> Peter Clark and Robin Boswell. </author> <title> Rule induction with CN2: Some recent improvements. </title> <editor> In Yves Kodratoff, editor, </editor> <booktitle> Machine Learning - EWSL-91, </booktitle> <pages> pages 151-163, </pages> <address> Berlin, 1991. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: In this section we review work related to this goal. 3.1 Theory Construction Systems In the simplest case, propositional rule learning systems (eg. C4.5 [12], CN2 <ref> [13] </ref>) can be seen as learning very simple `domain theories' for a classification task, using no background knowledge. The limited expressiveness of these systems' rule languages, and the labour-intensive task of choosing a suitable representation of examples, are well-known limitations which more recent work has sought to overcome. <p> Economic parameters are affected by a potentially unbounded list of factors (eg. politics, general elections, international conflict), making the data appear noisy to any algorithm which cannot represent these factors. Even running a highly predictive induction algorithm (CN2 <ref> [24, 13] </ref>), an average prediction accuracy of only 57.2% could be achieved (compared with the default accuracy of 50.4% 6 ). The rule language of this algorithm is relatively unconstrained, in that an arbitrary number of different numeric tests can be used to construct the rule set.
Reference: [14] <author> Christopher J. Matheus. </author> <title> Feature Construction: An Analytic Framework and An Application to Decision Trees. </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1990. </year>
Reference-contexts: However, the space of intermediate terms which can be introduced is potentially huge and can itself be intractable to adequately explore. Even with simple domains (eg. tic-tac-toe) search can take considerable time (eg. <ref> [14, 15] </ref>). Recent research in inductive logic programming (ILP) has also sought to learn domain theories in more expressive languages (in particular Horn clause languages).
Reference: [15] <author> Jerzy W. Bala, Ryszard S. Michalski, and Janusz Wnek. </author> <title> The principle axes method for constructive induction. </title> <editor> In Derek Sleeman and Peter Edwards, editors, </editor> <booktitle> Proc. Ninth Int. Machine Learning Conference (ML-92), </booktitle> <pages> pages 20-29, </pages> <address> CA, </address> <year> 1992. </year> <title> Kaufmann. (and personal communication). </title>
Reference-contexts: However, the space of intermediate terms which can be introduced is potentially huge and can itself be intractable to adequately explore. Even with simple domains (eg. tic-tac-toe) search can take considerable time (eg. <ref> [14, 15] </ref>). Recent research in inductive logic programming (ILP) has also sought to learn domain theories in more expressive languages (in particular Horn clause languages).
Reference: [16] <author> L. de Raedt and M. Bruynooghe. </author> <title> Constructive induction by analogy: A method to learn how to learn? In Proc. </title> <booktitle> 4th European Machine Learning Conference (EWSL-89), </booktitle> <pages> pages 189-200, </pages> <address> London, 1989. </address> <publisher> Pitman. </publisher>
Reference-contexts: Addressing this problem has been an important thrust of the research. Several ingenious methods have been developed, including techniques such as determinacy constraints ([6, 7]), mode and type declarations, and rule schemas (eg. in CIA <ref> [16] </ref>) 2 . In addition, allowing users to specify `background predicates' which can be included in the domain theory obviates (or at least reduces) the requirement for CI capabilities, a huge benefit for learning.
Reference: [17] <author> David Aha. </author> <title> Relating relational learning algorithms. </title> <editor> In Stephen Muggleton, editor, </editor> <booktitle> Inductive Logic Programming. </booktitle> <year> 1992. </year>
Reference-contexts: As a result, we must account for global repercussions of local operationalisation choices on the rest of the theory. This complicates the evaluation of operationalisation decisions, and presents a credit assignment problem. 2 An excellent overview of this field is given in <ref> [17] </ref>. 6 Parameter Details Units gnp Gross National Product % increase (1 year) sales Retail sales % increase (1 year) unemp Unemployment % inflatn Consumer prices % increase (1 year) wages Wages/earnings % increase (1 year) stocks Stock price indices % increase (1 year) money Money supply (broad) % increase (1
Reference: [18] <author> Susan Craw and Derek Sleeman. </author> <title> The flexibility of speculative refinement. </title> <booktitle> In ML91 (Proc. Eigth Int. Machine Learning Workshop), </booktitle> <pages> pages 28-32, </pages> <address> Ca, 1991. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: Here, it is assumed a domain theory is available but may contain errors. The learning task is to remove these errors, typically using examples to guide learning (eg. Either [5], Forte [4], Krust <ref> [18] </ref>). Our work shares some aspects of these systems, but differs in that we do not assume a `nearly correct' theory but instead assume more abstract knowledge.
Reference: [19] <author> T. M. Mitchell, R. M. Keller, and S. T. Kedar-Cabelli. </author> <title> Explanation-based generalization: A unifying view. </title> <journal> Machine Learning Journal, </journal> <volume> 1(1) </volume> <pages> 47-80, </pages> <year> 1986. </year>
Reference-contexts: We can view this as a process of specialising background knowledge, or, in EBL terms, of operationalising the non-operational, abstract knowledge available. In early EBL work (eg. <ref> [19] </ref>) it was assumed that the domain theory included precise definitions of non-operational terms; in other words, there was a `bridge' given spanning the gap between non-operational and operational expressions.
Reference: [20] <author> Igor Mozetic. </author> <title> The role of abstractions in learning qualitative models. </title> <editor> In P. Langley, editor, </editor> <booktitle> Proc. 4th International Workshop on Machine Learning, </booktitle> <address> CA, 1987. </address> <publisher> Kaufmann. </publisher>
Reference-contexts: Interest rates (bank prime lending) % ca bal Current account balance % increase (1 year) exchange Trade-weighted exchange rate % increase (1 year) Table 1: The ten economic parameters used. 3.3.2 Refinement of Abstract Models Our work is also closely related to work on qualitative model refinement (eg. by Mozetic <ref> [20] </ref>) in which an abstract model is repeatedly instantiated until a fully specified model is completed.
Reference: [21] <author> Kenneth D. Forbus. </author> <title> Qualitative process theory. </title> <journal> Artificial Intelligence, </journal> <volume> 24 </volume> <pages> 85-168, </pages> <year> 1984. </year>
Reference-contexts: Each parameter has an associated numeric value (for a given country and year), but in the model we use just two qualitative values, high or low. As in Qualitative Process Theory <ref> [21] </ref>, we label the arcs Q+ to denote a positive influence and Q- a negative influence.
Reference: [22] <author> James C. Spohrer and Christopher K. Riesbeck. </author> <title> Reasoning-driven memory modification in the economics domain. </title> <type> Technical Report YALEU/DCS/RR-308, </type> <institution> Yale University, </institution> <month> May </month> <year> 1984. </year>
Reference-contexts: The model we use is depicted in Figure 2, constructed manually by the authors in the style of Charniak's economic model <ref> [22] </ref>. Boxed items are the 10 measurable parameters P , described in Table 1. Unboxed items are the unmeasurable parameters Q, which are not included in rules extracted from the model but can be used for explanation purposes. The algorithm for extracting rules is given in Appendix A.
Reference: [23] <author> Gerald DeJong. </author> <title> Explanation-based learning with plausible inferencing. </title> <booktitle> In Proc. 4th European Machine Learning Conference (EWSL-89), </booktitle> <pages> pages 1-10, </pages> <address> London, 1989. </address> <publisher> Pitman. </publisher>
Reference-contexts: Unboxed items are the unmeasurable parameters Q, which are not included in rules extracted from the model but can be used for explanation purposes. The algorithm for extracting rules is given in Appendix A. The idea of extracting plausible rules from a QM is similar to DeJong's Plausible EBL <ref> [23] </ref>.
Reference: [24] <author> Peter Clark and Tim Niblett. </author> <title> The CN2 induction algorithm. </title> <journal> Machine Learning Journal, </journal> <volume> 3(4) </volume> <pages> 261-283, </pages> <year> 1989. </year>
Reference-contexts: Economic parameters are affected by a potentially unbounded list of factors (eg. politics, general elections, international conflict), making the data appear noisy to any algorithm which cannot represent these factors. Even running a highly predictive induction algorithm (CN2 <ref> [24, 13] </ref>), an average prediction accuracy of only 57.2% could be achieved (compared with the default accuracy of 50.4% 6 ). The rule language of this algorithm is relatively unconstrained, in that an arbitrary number of different numeric tests can be used to construct the rule set.
Reference: [25] <author> Jill Houston, </author> <year> 1992. </year> <title> (Senior consultant, Intelligent Terminals Ltd., </title> <type> Personal communication). 18 </type>
Reference-contexts: The effort normally involved in this task is reported to be typically of the order of months per application <ref> [25] </ref>, so any assistance which can be provided is potentially valuable. In addition, as illustrated in Section 6.1, use of domain knowledge can substantially reduce the size of the search space involved allowing more focussed search to be conducted.
References-found: 25

