URL: http://www.tns.lcs.mit.edu/~djw/library/sigcomm96/mathis.ps.gz
Refering-URL: http://www.tns.lcs.mit.edu/~djw/library/sigcomm96/program.html
Root-URL: 
Email: &lt;mathis@psc.edu&gt; &lt;mahdavi@psc.edu&gt;  
Title: Forward Acknowledgment: Refining TCP Congestion Control  
Author: Matthew Mathis and Jamshid Mahdavi 
Affiliation: Pittsburgh Supercomputing Center  
Abstract: We have developed a Forward Acknowledgment (FACK) congestion control algorithm which addresses many of the performance problems recently observed in the Internet. The FACK algorithm is based on first principles of congestion control and is designed to be used with the proposed TCP SACK option. By decoupling congestion control from other algorithms such as data recovery, it attains more precise control over the data flow in the network. We introduce two additional algorithms to improve the behavior in specific situations. Through simulations we compare FACK to both Reno and Reno with SACK. Finally, we consider the potential performance and impact of FACK in the Internet. 
Abstract-found: 1
Intro-found: 1
Reference: [Bal96] <author> Hari Balakrishnan, </author> <month> March </month> <year> 1996. </year> <note> Presentation to the IETF TCP-LW working group. </note>
Reference-contexts: At the time recovery begins, cwnd+wintrim is slightly less than awnd. After one 16 We are aware of one research group working with a TCP implementation which includes a solution to this problem similar to ours <ref> [Bal96] </ref>. round trip of recovery, wintrim is reduced to zero. While wintrim is non-zero, it acts to smooth the data evenly over one round trip, so that exactly cwnd bytes of data are outstanding at the end of this round trip.
Reference: [BOP94] <author> Lawrence S. Brakmo, Sean W. O'Malley, and Larry L. Peterson. </author> <title> TCP Vegas: New Techniques for COngestion Detection and Avoidance. </title> <booktitle> Proceedings of ACM SIGCOMM '94, </booktitle> <month> August </month> <year> 1994. </year>
Reference-contexts: Other researchers are currently studying congestion control issues in TCP. The research community is very interested in the potential of TCP Vegas <ref> [BOP94, DLY95] </ref>. Through the use of delay measurements, TCP Vegas attempts to eliminate the periodic self-induced segment losses caused in Reno TCP. The Vegas Congestion Avoidance Mechanism (CAM) algorithm modifies the "linear increase" phase of congestion avoidance. In another recent study, Hoe investigates congestion control issues during Slow-start [Hoe95, Hoe96]. <p> The transport and internet layers must work together to improve the behavior of the Internet under high load. Other current research into TCP congestion is largely independent of FACK. The Congestion Avoidance Mechanism (CAM) of TCP Vegas <ref> [BOP94, DLY95] </ref> attempts to avoid unnecessary inflation of the congestion window through delay sensing techniques. Hoe has done extensive work in analyzing the effects of congestion during Slow-start [Hoe95, Hoe96], where there can be significant performance problems.
Reference: [Bra89] <author> R. Braden. </author> <title> Requirements for Internet Hosts Communication Layers, </title> <month> October </month> <year> 1989. </year> <title> Request for Comments 1122. </title>
Reference-contexts: Finally, we summarize our findings. 2 Congestion Control 2.1 Ideal Principles In 1988, Van Jacobson published the paper that has become the standard for TCP congestion control algorithms 1 This idea has been proposed before [CLZ87], but it has not been implemented for TCP. <ref> [Jac88, Bra89] </ref>. We do not modify any of the algorithms described in that paper. Rather, FACK extends these congestion control algorithms to TCP's recovery interval.
Reference: [CLZ87] <author> D. D. Clark, M. L. Lambert, and L. Zhang. NETBLT: </author> <title> a high throughput transport protocol. </title> <journal> Computer Communications Review, </journal> <volume> 17(5) </volume> <pages> 353-359, </pages> <year> 1987. </year>
Reference-contexts: In section 7 we discuss future research directions for this work. Finally, we summarize our findings. 2 Congestion Control 2.1 Ideal Principles In 1988, Van Jacobson published the paper that has become the standard for TCP congestion control algorithms 1 This idea has been proposed before <ref> [CLZ87] </ref>, but it has not been implemented for TCP. [Jac88, Bra89]. We do not modify any of the algorithms described in that paper. Rather, FACK extends these congestion control algorithms to TCP's recovery interval.
Reference: [DJ91] <author> Peter B. Danzig and Sugih Jamin. </author> <title> tc plib: A library of TCP/IP traffic characteristics. </title> <type> Technical Report TR-SYS-91-01, </type> <institution> USC Networking and Distributed Systems Laboratory, </institution> <month> October </month> <year> 1991. </year> <note> Obtain via: ftp://catarina.usc.edu/pub/jamin/tcplib. </note>
Reference-contexts: Finally, we would like to acknowledge our management at PSC for encouraging our research activities on TCP performance. 21 In our experiments, we did not take advantage of the capabilities of tcplib <ref> [DJ91] </ref>, which models some of these complexities.
Reference: [DLY95] <author> Peter B. Danzig, Zhen Liu, and Limim Yan. </author> <title> An Evaluation of TCP Vegas by Live Emulation. </title> <booktitle> ACM SIGMetrics '95, </booktitle> <year> 1995. </year>
Reference-contexts: Other researchers are currently studying congestion control issues in TCP. The research community is very interested in the potential of TCP Vegas <ref> [BOP94, DLY95] </ref>. Through the use of delay measurements, TCP Vegas attempts to eliminate the periodic self-induced segment losses caused in Reno TCP. The Vegas Congestion Avoidance Mechanism (CAM) algorithm modifies the "linear increase" phase of congestion avoidance. In another recent study, Hoe investigates congestion control issues during Slow-start [Hoe95, Hoe96]. <p> The transport and internet layers must work together to improve the behavior of the Internet under high load. Other current research into TCP congestion is largely independent of FACK. The Congestion Avoidance Mechanism (CAM) of TCP Vegas <ref> [BOP94, DLY95] </ref> attempts to avoid unnecessary inflation of the congestion window through delay sensing techniques. Hoe has done extensive work in analyzing the effects of congestion during Slow-start [Hoe95, Hoe96], where there can be significant performance problems.
Reference: [FF96] <author> Kevin Fall and Sally Floyd. </author> <title> Compar isons of Tahoe, Reno and Sack TCP, </title> <month> May </month> <year> 1996. </year> <note> Submitted to CCR, Obtain via ftp://ftp.ee.lbl.gov/papers/sacks v2.ps.Z. </note>
Reference-contexts: In some cases, Reno may incorrectly reinvoke Fast Retransmit and Fast Recovery. Floyd and Hoe have observed that strengthening Reno's test for the end of recovery improves its behavior in a number of situations <ref> [FF96, Hoe95] </ref>. 2.4 FACK Design Goals Under single segment losses, Reno implements the ideal congestion control principles set forth above. <p> following behavior in roughly 13% of the traces he collected at major Internet exchange points: 18 Reno+SACK performs as well as FACK in this situation. ...a fast retransmit followed by a retransmit timeout, with the additional condition that the packet retransmitted after the retransmit timeout had not been previously retransmitted... <ref> [FF96] </ref> It is most likely that this behavior is the result of minor congestion episodes which cause multiple packet loss in one round trip.
Reference: [FJ91] <author> Sally Floyd and Van Jacobson. </author> <title> Traffic Phase Effects in Packet-Switched Gateways. </title> <journal> Computer Communications Review, </journal> <volume> 21(2), </volume> <month> April </month> <year> 1991. </year>
Reference-contexts: Under other conditions, the congestion window is increased linearly by one maximum segment size (MSS) per round trip on the network. The stability of this linear increase and multiplicative decrease algorithm has been demonstrated in many investigations since its publication in 1988 <ref> [ZSC91, FJ91, Mog92, FJ92, FJ93] </ref>. "Slow-start" is the algorithm which TCP uses to reach the equilibrium state when cwnd is less than a threshold, ssthresh. Ssthresh attempts to dynamically estimate the correct window size for the connection.
Reference: [FJ92] <author> Sally Floyd and Van Jacobson. </author> <title> On Traffic Phase Effects in Packet-Switched Gateways. </title> <journal> Inter-networking: Research and Experience, </journal> <volume> 3(3) </volume> <pages> 115-156, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Under other conditions, the congestion window is increased linearly by one maximum segment size (MSS) per round trip on the network. The stability of this linear increase and multiplicative decrease algorithm has been demonstrated in many investigations since its publication in 1988 <ref> [ZSC91, FJ91, Mog92, FJ92, FJ93] </ref>. "Slow-start" is the algorithm which TCP uses to reach the equilibrium state when cwnd is less than a threshold, ssthresh. Ssthresh attempts to dynamically estimate the correct window size for the connection.
Reference: [FJ93] <author> Sally Floyd and Van Jacobson. </author> <title> Random Early Detection Gateways for Congestion Avoidance. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <month> August </month> <year> 1993. </year>
Reference-contexts: Under other conditions, the congestion window is increased linearly by one maximum segment size (MSS) per round trip on the network. The stability of this linear increase and multiplicative decrease algorithm has been demonstrated in many investigations since its publication in 1988 <ref> [ZSC91, FJ91, Mog92, FJ92, FJ93] </ref>. "Slow-start" is the algorithm which TCP uses to reach the equilibrium state when cwnd is less than a threshold, ssthresh. Ssthresh attempts to dynamically estimate the correct window size for the connection. <p> The production Internet still lacks adequate attention to issues of congestion and congestion detection. Many routers are incapable of providing full bandwidthfidelay buffering and do not signal the onset of congestion through mechanisms such as Random Early Detection (RED) <ref> [FJ93] </ref>. Although the FACK algorithm is designed to help in times of congestion, it is not a substitute for these signals at the Internet layer. The transport and internet layers must work together to improve the behavior of the Internet under high load.
Reference: [Flo92] <author> Sally Floyd, </author> <month> February </month> <year> 1992. </year> <note> Private Communi cation. </note>
Reference-contexts: However, SACK is generally viewed as a method to address data recovery; it has not been widely investigated to address congestion control issues. Floyd pointed out that multiple segment losses can cause Reno TCP to lose its Self-clock, resulting in a retransmission timeout <ref> [Flo95, Flo92] </ref>. These timeouts can cause a substantial performance degradation. During the timeout interval, no data is sent. In addition, the timeout is followed by a period of Slow-start. This sequence of events underutilizes the network over several round-trip times, which results in a significant performance reduction on long-delay links.
Reference: [Flo95] <author> Sally Floyd. </author> <title> TCP and Successive Fast Retransmits, </title> <month> February </month> <year> 1995. </year> <note> Obtain via ftp://ftp.ee.lbl.gov/papers/fastretrans.ps. </note>
Reference-contexts: However, SACK is generally viewed as a method to address data recovery; it has not been widely investigated to address congestion control issues. Floyd pointed out that multiple segment losses can cause Reno TCP to lose its Self-clock, resulting in a retransmission timeout <ref> [Flo95, Flo92] </ref>. These timeouts can cause a substantial performance degradation. During the timeout interval, no data is sent. In addition, the timeout is followed by a period of Slow-start. This sequence of events underutilizes the network over several round-trip times, which results in a significant performance reduction on long-delay links. <p> Under single segment losses, Fast Retransmit and Fast Recovery preserve TCP's Self-clock and enable it to keep the network full while recovering from one lost segment. If there are multiple lost segments, Reno is unlikely to fully recover, resulting in a timeout and subsequent Slow-start <ref> [Flo95] </ref>. 2.3 SACK TCP Behavior The new TCP SACK option [MMFR96] is progressing through the IETF standards track. It is a slight modification to the original SACK option described in RFC1072 [JB88]. <p> These variables are defined in the TCP standard [Pos81]. 4 This fixes a problem in Reno which has been pointed out by Hoe [Hoe95] and Floyd <ref> [Flo95] </ref>. In some cases, Reno may incorrectly reinvoke Fast Retransmit and Fast Recovery.
Reference: [Hoe95] <author> Janey C. Hoe. </author> <title> Startup Dynamics of TCP's Con gestion Control and Avoidance Schemes. </title> <type> Mas-ter's thesis, </type> <institution> Massachusetts Institute of Technology, </institution> <month> June </month> <year> 1995. </year>
Reference-contexts: Through the use of delay measurements, TCP Vegas attempts to eliminate the periodic self-induced segment losses caused in Reno TCP. The Vegas Congestion Avoidance Mechanism (CAM) algorithm modifies the "linear increase" phase of congestion avoidance. In another recent study, Hoe investigates congestion control issues during Slow-start <ref> [Hoe95, Hoe96] </ref>. Because our work is focused primarily on improving congestion control during recovery (the "expo-nential decrease" phase of congestion avoidance), it is compatible with these efforts. It is our expectation that each of these efforts can eventually be incorporated into TCP in order to incrementally improve performance. <p> These variables are defined in the TCP standard [Pos81]. 4 This fixes a problem in Reno which has been pointed out by Hoe <ref> [Hoe95] </ref> and Floyd [Flo95]. In some cases, Reno may incorrectly reinvoke Fast Retransmit and Fast Recovery. <p> In some cases, Reno may incorrectly reinvoke Fast Retransmit and Fast Recovery. Floyd and Hoe have observed that strengthening Reno's test for the end of recovery improves its behavior in a number of situations <ref> [FF96, Hoe95] </ref>. 2.4 FACK Design Goals Under single segment losses, Reno implements the ideal congestion control principles set forth above. <p> The sender then resumes transmission of data. This typically results in a full window of data being transmitted in one half of a round trip time, resulting in uneven transmission of data for this and subsequent round trips. Solutions to this problem have been suggested <ref> [Hoe95, Jac95] </ref>, but have not yet been deployed. 16 The recommended solution for this problem is to smooth the transmission of data over one RTT by slowly reducing cwnd, rather than instantly halving it. <p> Other current research into TCP congestion is largely independent of FACK. The Congestion Avoidance Mechanism (CAM) of TCP Vegas [BOP94, DLY95] attempts to avoid unnecessary inflation of the congestion window through delay sensing techniques. Hoe has done extensive work in analyzing the effects of congestion during Slow-start <ref> [Hoe95, Hoe96] </ref>, where there can be significant performance problems. The implementation of SACK and/or FACK may reduce the gravity of these problems, but will not eliminate them. Both of these efforts address different aspects of the TCP congestion control problem.
Reference: [Hoe96] <author> Janey C. Hoe. </author> <title> Improving the Start-up Behavior of a Congestion Control Scheme for TCP. </title> <booktitle> Proceedings of ACM SIGCOMM '96, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Through the use of delay measurements, TCP Vegas attempts to eliminate the periodic self-induced segment losses caused in Reno TCP. The Vegas Congestion Avoidance Mechanism (CAM) algorithm modifies the "linear increase" phase of congestion avoidance. In another recent study, Hoe investigates congestion control issues during Slow-start <ref> [Hoe95, Hoe96] </ref>. Because our work is focused primarily on improving congestion control during recovery (the "expo-nential decrease" phase of congestion avoidance), it is compatible with these efforts. It is our expectation that each of these efforts can eventually be incorporated into TCP in order to incrementally improve performance. <p> Other current research into TCP congestion is largely independent of FACK. The Congestion Avoidance Mechanism (CAM) of TCP Vegas [BOP94, DLY95] attempts to avoid unnecessary inflation of the congestion window through delay sensing techniques. Hoe has done extensive work in analyzing the effects of congestion during Slow-start <ref> [Hoe95, Hoe96] </ref>, where there can be significant performance problems. The implementation of SACK and/or FACK may reduce the gravity of these problems, but will not eliminate them. Both of these efforts address different aspects of the TCP congestion control problem.
Reference: [ipp96] <institution> Charter of the Benchmarking Working Group (BMWG) of the IETF, </institution> <year> 1996. </year> <note> Obtain via: http://www.ietf.cnri.reston.va.us/html.charters/ bmwg-charter.html. </note>
Reference-contexts: When a SACK 5 The observation that Reno inaccurately assesses the network state arose as a part of ongoing research aimed at developing tools for benchmarking the production Internet <ref> [ipp96] </ref>. Our efforts focused on a tool called "TReno" for Traceroute-Reno [Mat95, Mat96], which is an evolution of an earlier tool "Windowed Ping" [Mat94]. TReno attempts to measure the available network headroom by emulating Reno TCP over a traceroute-like UDP stream.
Reference: [Jac88] <author> Van Jacobson. </author> <title> Congestion Avoidance and Con trol. </title> <booktitle> Proceedings of ACM SIGCOMM '88, </booktitle> <month> August </month> <year> 1988. </year>
Reference-contexts: Finally, we summarize our findings. 2 Congestion Control 2.1 Ideal Principles In 1988, Van Jacobson published the paper that has become the standard for TCP congestion control algorithms 1 This idea has been proposed before [CLZ87], but it has not been implemented for TCP. <ref> [Jac88, Bra89] </ref>. We do not modify any of the algorithms described in that paper. Rather, FACK extends these congestion control algorithms to TCP's recovery interval.
Reference: [Jac90] <author> Van L. Jacobson. </author> <title> Fast Retransmit. Message to the end2end-interest mailing list, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: Both Fast Retransmit and Fast Recovery [Ste96] rely on counting "duplicate ACKs" - TCP acknowledgments sent by the data receiver in response to each additional received segment following some missing data. Fast Retransmit and Fast Recovery <ref> [Jac90, Ste94] </ref> are algorithms intended to preserve Self-clock during recovery from a lost segment. Fast Retransmit uses duplicate ACKs to detect the loss of a segment. When three duplicate ACKs are detected, TCP assumes that a segment has been lost and retransmits it.
Reference: [Jac95] <author> Van Jacobson, </author> <month> July </month> <year> 1995. </year> <note> Private Communica tion. </note>
Reference-contexts: The sender then resumes transmission of data. This typically results in a full window of data being transmitted in one half of a round trip time, resulting in uneven transmission of data for this and subsequent round trips. Solutions to this problem have been suggested <ref> [Hoe95, Jac95] </ref>, but have not yet been deployed. 16 The recommended solution for this problem is to smooth the transmission of data over one RTT by slowly reducing cwnd, rather than instantly halving it.
Reference: [JB88] <author> V. Jacobson and R. Braden. </author> <title> TCP extensions for long-delay paths, </title> <month> October </month> <year> 1988. </year> <title> Request for Comments 1072. </title>
Reference-contexts: Anecdotal evidence suggests that TCP experiences lower than expected performance in a number of situations in the Internet [tcp95]. The common perception is that these weaknesses are a consequence of the failure to deploy a standard Selective Acknowledgment (SACK) <ref> [JB88] </ref> in any of today's TCP implementations. However, SACK is generally viewed as a method to address data recovery; it has not been widely investigated to address congestion control issues. <p> It is a slight modification to the original SACK option described in RFC1072 <ref> [JB88] </ref>. When the receiver holds non-contiguous data, it sends duplicate ACKs bearing SACK options to inform the sender which segments have been correctly received.
Reference: [JBB92] <author> V. Jacobson, R. Braden, and D. </author> <title> Borman. TCP Extensions for High Performance, </title> <month> May </month> <year> 1992. </year> <title> Request for Comments 1323. </title>
Reference-contexts: We have been moderately successful at deriving closed-form mathematical models for FACK TCP performance in some topologies and believe that this technique deserves further exploration. The new state variable snd:f ack might also be used to strengthen Round Trip Time Measurements (RTTM) and Protection Against Wrapped Sequence (PAWS) algorithms <ref> [JBB92] </ref> during recovery. The FACK algorithm was first implemented in TReno, an Internet performance metric [Mat96]. Tools to measure Internet performance should track the evolution of TCP [Mat]. The production Internet still lacks adequate attention to issues of congestion and congestion detection.
Reference: [Kar95] <author> Phil Karn, </author> <month> December </month> <year> 1995. </year> <note> Private Communi cation. </note>
Reference-contexts: Our investigation of the differences between TReno and Reno behaviors led us to discover FACK's underlying principles. 6 In principle, the FACK algorithm could also be implemented by utilizing the information provided by the receiver through other mechanisms, such as TCP Timestamp option, to determine the rightmost segment received <ref> [Kar95] </ref>. This would allow the benefits of improved congestion control during recovery to be immediately realized in existing TCP implementations.
Reference: [Mat] <author> Matthew Mathis. </author> <title> Internet Performance and IP Provider Metrics information page. </title> <address> http://www.psc.edu/~mathis/ippm/. </address>
Reference-contexts: The FACK algorithm was first implemented in TReno, an Internet performance metric [Mat96]. Tools to measure Internet performance should track the evolution of TCP <ref> [Mat] </ref>. The production Internet still lacks adequate attention to issues of congestion and congestion detection. Many routers are incapable of providing full bandwidthfidelay buffering and do not signal the onset of congestion through mechanisms such as Random Early Detection (RED) [FJ93].
Reference: [Mat94] <author> Matthew B. Mathis. </author> <title> Windowed Ping: An IP Layer Performance Diagnostic. </title> <booktitle> In Proceedings of INET'94/JENC5, volume 2, </booktitle> <address> Prague, Czech Republic, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: Our efforts focused on a tool called "TReno" for Traceroute-Reno [Mat95, Mat96], which is an evolution of an earlier tool "Windowed Ping" <ref> [Mat94] </ref>. TReno attempts to measure the available network headroom by emulating Reno TCP over a traceroute-like UDP stream. Although based on Reno congestion control, TReno was observed to exhibit significantly different behavior largely due to its precise picture of the congestion state of the network.
Reference: [Mat95] <author> Matthew Mathis. </author> <title> Source code for the TReno package, </title> <note> 1995. Obtain via: ftp://ftp.psc.edu/pub/net tools/treno.shar. </note>
Reference-contexts: When a SACK 5 The observation that Reno inaccurately assesses the network state arose as a part of ongoing research aimed at developing tools for benchmarking the production Internet [ipp96]. Our efforts focused on a tool called "TReno" for Traceroute-Reno <ref> [Mat95, Mat96] </ref>, which is an evolution of an earlier tool "Windowed Ping" [Mat94]. TReno attempts to measure the available network headroom by emulating Reno TCP over a traceroute-like UDP stream.
Reference: [Mat96] <author> Matthew Mathis. </author> <title> Diagnosing Internet Conges tion with a Transport Layer Performance Tool. </title> <booktitle> In Proceedings of INET'96, </booktitle> <address> Montreal, Quebec, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: When a SACK 5 The observation that Reno inaccurately assesses the network state arose as a part of ongoing research aimed at developing tools for benchmarking the production Internet [ipp96]. Our efforts focused on a tool called "TReno" for Traceroute-Reno <ref> [Mat95, Mat96] </ref>, which is an evolution of an earlier tool "Windowed Ping" [Mat94]. TReno attempts to measure the available network headroom by emulating Reno TCP over a traceroute-like UDP stream. <p> The new state variable snd:f ack might also be used to strengthen Round Trip Time Measurements (RTTM) and Protection Against Wrapped Sequence (PAWS) algorithms [JBB92] during recovery. The FACK algorithm was first implemented in TReno, an Internet performance metric <ref> [Mat96] </ref>. Tools to measure Internet performance should track the evolution of TCP [Mat]. The production Internet still lacks adequate attention to issues of congestion and congestion detection.
Reference: [MF] <author> S. McCanne and S. Floyd. </author> <title> ns-LBNL Net work Simulator. Obtain via: </title> <address> http://www-nrg.ee.lbl.gov/ns/. </address>
Reference-contexts: We introduce another algorithm, Overdamping, which estimates the correct window more conservatively following losses as a result of Slow-start. Finally, we introduce a Rampdown algorithm to smooth data transmission during the recovery period. 4.1 Simulation Environment We tested these new algorithms by implementing them under the LBNL simulator "ns" <ref> [MF] </ref>, where we added the necessary new congestion control algorithms. 10 The simulator includes models of Tahoe, Reno, and Reno+SACK. We added a FACK sender to the simulator, but were able to use the existing SACK TCP receiver without modification.
Reference: [MMFR96] <author> Matthew Mathis, Jamshid Mahdavi, Sally Floyd, and Allyn Romanow. </author> <title> TCP Selective Acknowledgement Options, </title> <month> May </month> <year> 1996. </year> <title> Internet Draft ("work in progress") draft-ietf-tcplw-sack-02.txt, </title> <journal> Expires: </journal> <volume> 29/7/96. </volume>
Reference-contexts: NCR-9415552. We have developed a new algorithm to improve TCP congestion control during recovery. This algorithm, called Forward Acknowledgment or FACK, works in conjunction with the proposed TCP SACK option <ref> [MMFR96] </ref>. The existence of the SACK option alone greatly improves the robustness of TCP following congestion. SACK will help TCP to survive multiple segment losses within a single window without incurring a retransmission timeout. SACK can also glean additional information about congestion state, leading to improved TCP behavior during recovery. <p> If there are multiple lost segments, Reno is unlikely to fully recover, resulting in a timeout and subsequent Slow-start [Flo95]. 2.3 SACK TCP Behavior The new TCP SACK option <ref> [MMFR96] </ref> is progressing through the IETF standards track. It is a slight modification to the original SACK option described in RFC1072 [JB88]. When the receiver holds non-contiguous data, it sends duplicate ACKs bearing SACK options to inform the sender which segments have been correctly received.
Reference: [Mog92] <author> Jeff C. Mogul. </author> <title> Observing TCP Dynamics in Real Networks. </title> <booktitle> Proceedings of ACM SIGCOMM '92, </booktitle> <pages> pages 305-317, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Under other conditions, the congestion window is increased linearly by one maximum segment size (MSS) per round trip on the network. The stability of this linear increase and multiplicative decrease algorithm has been demonstrated in many investigations since its publication in 1988 <ref> [ZSC91, FJ91, Mog92, FJ92, FJ93] </ref>. "Slow-start" is the algorithm which TCP uses to reach the equilibrium state when cwnd is less than a threshold, ssthresh. Ssthresh attempts to dynamically estimate the correct window size for the connection.
Reference: [Pos81] <author> J. Postel. </author> <title> Transmission Control Protocol, </title> <month> September </month> <year> 1981. </year> <title> Request for Comments 793. </title>
Reference-contexts: These variables are defined in the TCP standard <ref> [Pos81] </ref>. 4 This fixes a problem in Reno which has been pointed out by Hoe [Hoe95] and Floyd [Flo95]. In some cases, Reno may incorrectly reinvoke Fast Retransmit and Fast Recovery.
Reference: [Ste94] <author> W. </author> <title> Stevens. </title> <journal> TCP/IP Illustrated, </journal> <volume> volume 1. </volume> <publisher> Addison-Wesley, </publisher> <address> Reading MA, </address> <year> 1994. </year>
Reference-contexts: Once ssthresh is reached, TCP passes into the Congestion Avoidance regime. Ssthresh is set to half of the current value of cwnd when the sender detects congestion or undergoes a retransmission timeout. 2.2 Reno TCP Behavior Reno TCP is currently the de facto standard implementation of TCP <ref> [Ste94] </ref>. Reno implements Slow-start and Congestion Avoidance in the manner described above. It includes the Fast Retransmit algorithm from Tahoe TCP and adds one new algorithm: Fast Recovery. <p> Both Fast Retransmit and Fast Recovery [Ste96] rely on counting "duplicate ACKs" - TCP acknowledgments sent by the data receiver in response to each additional received segment following some missing data. Fast Retransmit and Fast Recovery <ref> [Jac90, Ste94] </ref> are algorithms intended to preserve Self-clock during recovery from a lost segment. Fast Retransmit uses duplicate ACKs to detect the loss of a segment. When three duplicate ACKs are detected, TCP assumes that a segment has been lost and retransmits it.
Reference: [Ste96] <author> W. Richard Stevens. </author> <title> TCP Slow Start, Conges tion Avoidance, Fast Retransmit, and Fast Recovery Algorithms, </title> <month> March </month> <year> 1996. </year> <title> Currently an Internet Draft: </title> <publisher> draft-stevens-tcpca-spec-01.txt. </publisher>
Reference-contexts: Reno implements Slow-start and Congestion Avoidance in the manner described above. It includes the Fast Retransmit algorithm from Tahoe TCP and adds one new algorithm: Fast Recovery. Both Fast Retransmit and Fast Recovery <ref> [Ste96] </ref> rely on counting "duplicate ACKs" - TCP acknowledgments sent by the data receiver in response to each additional received segment following some missing data. Fast Retransmit and Fast Recovery [Jac90, Ste94] are algorithms intended to preserve Self-clock during recovery from a lost segment.
Reference: [tcp95] <institution> Minutes of the tcpfix meeting at the 34th IETF, in Dallas TX, </institution> <month> December </month> <year> 1995. </year> <note> Obtain via: http://www.ietf.cnri.reston.va.us/proceedings/ 95dec/tsv/tcplw.html. </note>
Reference-contexts: 1 Introduction The evolution of the Internet has pushed TCP to new limits over a wide variety of IP infrastructures. Anecdotal evidence suggests that TCP experiences lower than expected performance in a number of situations in the Internet <ref> [tcp95] </ref>. The common perception is that these weaknesses are a consequence of the failure to deploy a standard Selective Acknowledgment (SACK) [JB88] in any of today's TCP implementations.
Reference: [ZSC91] <author> Lixia Zhang, Scott Shenker, and David D. Clark. </author> <title> Observations on the Dynamics of a Congestion Control Algorithm: The Effects of Two-Way Traffic. </title> <booktitle> Proceedings of ACM SIGCOMM '91, </booktitle> <pages> pages 133-148, </pages> <year> 1991. </year>
Reference-contexts: Under other conditions, the congestion window is increased linearly by one maximum segment size (MSS) per round trip on the network. The stability of this linear increase and multiplicative decrease algorithm has been demonstrated in many investigations since its publication in 1988 <ref> [ZSC91, FJ91, Mog92, FJ92, FJ93] </ref>. "Slow-start" is the algorithm which TCP uses to reach the equilibrium state when cwnd is less than a threshold, ssthresh. Ssthresh attempts to dynamically estimate the correct window size for the connection. <p> Note that with only 7% load on the reverse path, Reno leaves almost 50% idle capacity on the forward path. This reflects the combined effects of ACK compression <ref> [ZSC91] </ref>, drop-tail routers and the high penalty of retransmit timeouts. Note that this example uses a 20 packet queue length, which is more than sufficient buffering for this network. In this trace we slightly reduced the buffering from figure 11, to accent interesting detail.
References-found: 33

