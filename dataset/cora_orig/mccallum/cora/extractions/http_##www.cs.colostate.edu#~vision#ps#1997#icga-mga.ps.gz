URL: http://www.cs.colostate.edu/~vision/ps/1997/icga-mga.ps.gz
Refering-URL: http://www.cs.colostate.edu/~vision/html/publications.html
Root-URL: 
Email: gravesc@cs.colostate.edu  
Phone: (303) 491-5373  
Title: Messy Genetic Algorithms for Subset Feature Selection  
Author: D. Whitley, J. R. Beveridge, C. Guerra-Salcedo, C. Graves whitley, ross, guerra, 
Keyword: messy genetic algorithms, subset feature selection, computer vision  
Address: Fort Collins, Colorado 80523 USA  
Affiliation: Department of Computer Science Colorado State University  
Abstract: Subset Feature Selection problems can have several attributes which may make Messy Genetic Algorithms an appropriate optimization method. First, competitive solutions may often use only a small percentage of the total available features; this can not only offer an advantage to Messy Genetic Algorithms, it may also cause problems for other types of evolutionary algorithms. Second, the evaluation of small blocks of features is naturally decomposable. Thus, there is no difficulty evaluating underspecified strings. We apply variants of the Messy Genetic Algorithm to a application in computer vision with very good results. We also apply variants of the Fast Messy Genetic Algorithm to synthethic test problems.
Abstract-found: 1
Intro-found: 1
Reference: [Bala et al., 1995] <author> Bala, J., Jong, K. D., Huang, J., Vafaie, H., and Wechsler, H. </author> <year> (1995). </year> <title> Hybrid Learning Using Genetic Algorithms and Decision Trees for Pattern Classification. </title> <booktitle> In 14th Int. Joint Conf. on Artificial Intelligence (IJCAI). </booktitle>
Reference: [Beveridge, 1993] <author> Beveridge, J. R. </author> <year> (1993). </year> <title> Local Search Algorithms for Geometric Obejct Recognition: Optimal Correspondence and Pose. </title> <type> PhD thesis, </type> <institution> University of Massachuesetts at Amherst. </institution>
Reference-contexts: Dr. Beveridge's work on object recognition shows local search in the form of bit-climbing algorithms to be a powerful tool for finding optimal matches between features on 3D geometric object models and features in 2D images <ref> [Beveridge, 1993, Beveridge and Riseman, 1995] </ref>. These algorithms excel on problems involving poor quality image data and cluttered scenes. Here problems involving 2D object models such as shown in Figure 1 will be considered. <p> The filled in squares in Figure 1 correspond to 1s in this bit string encoding. An objective function is defined over the correspondence space which the best match c fl minimizes: E (c fl ) E (c) 8c 2 C (1) The match error E, described in <ref> [Beveridge, 1993] </ref>, includes two terms: a fit error and an omission er ror. Whenever E is evaluated for a correspondence c, the best global 2D similarity transformation from object model to data is computed. <p> This is a great advantage for local search operating on the neighborhood of single bit changes. The details of this incremental update procedure are explained in <ref> [Beveridge, 1993] </ref>, page 83.
Reference: [Beveridge and Riseman, 1995] <author> Beveridge, J. R. and Riseman, E. M. </author> <year> (1995). </year> <title> Optimal Geometric Model Matching Under Full 3D Perspective. Computer Vision and Image Understanding, </title> <note> 61(3):351 - 364. (short version in IEEE Second CAD-Based Vision Workshop). </note>
Reference-contexts: Dr. Beveridge's work on object recognition shows local search in the form of bit-climbing algorithms to be a powerful tool for finding optimal matches between features on 3D geometric object models and features in 2D images <ref> [Beveridge, 1993, Beveridge and Riseman, 1995] </ref>. These algorithms excel on problems involving poor quality image data and cluttered scenes. Here problems involving 2D object models such as shown in Figure 1 will be considered.
Reference: [Beveridge et al., 1995] <author> Beveridge, J. R., Riseman, E. M., and Graves, C. </author> <year> (1995). </year> <title> Demonstrating polynomial run-time growth for local search matching. </title> <booktitle> In Proceedings: International Symposium on Computer Vision, </booktitle> <pages> pages 533 - 538, </pages> <address> Coral Gables, Florida. </address> <publisher> IEEE PAMI TC, IEEE Computer Society Press. </publisher>
Reference-contexts: This dataset and local search results are available through our website: http://www.cs.colostate.edu/~vision. (a) model instances. Previously [Whitley et al., 1995], the CHC and Genitor algorithms have been shown to perform poorly on this data. In contrast, this dataset is readily solved using different bit-climbing algorithms <ref> [Beveridge et al., 1995] </ref>. By hybridizing Gen-itor with the bit-climbing algorithm results compara ble to those obtained using local search have been obtained. Here the Messy Genetic Algorithm described above performs is shown to perform much better than the random starts local search algorithm.
Reference: [Brill et al., 1992] <author> Brill, F., Brown, D., and Martin, W. </author> <year> (1992). </year> <title> Fast genetic selection of features for neural network classifiers. </title> <journal> IEEE Trans. on Neural Networks, </journal> <volume> 3(2) </volume> <pages> 324-328. </pages>
Reference: [Burns et al., 1986] <author> Burns, J. B., Hanson, A. R., and Riseman, E. M. </author> <year> (1986). </year> <title> Extracting straight lines. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> PAMI-8(4):425 - 456. </volume>
Reference-contexts: In contrast, for the harder 24 problems the Messy Genetic Algorithm runs 9:4 times faster. In other words, for the problems taking thousands of seconds to solve using local search, the Messy Genetic Algorithm is dropping run-times by an order of magnitude. (a) (b) Burns line segments <ref> [Burns et al., 1986] </ref>, c) building model, d) best match. from a real image. For this problem, there are 4 model line segments, 443 data line segments, generating 1; 772 possible pairs of segments.
Reference: [Deb and Goldberg, 1993] <author> Deb, K. and Goldberg, D. </author> <year> (1993). </year> <title> Analyzing Deception in Trap Functions. </title> <editor> In Whitley, L. D., editor, </editor> <volume> FOGA - 2, </volume> <pages> pages 93-108. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: [Deb and Goldberg, 1991] <author> Deb, K. and Goldberg, D. E. </author> <year> (1991). </year> <title> mga in c: A messy genetic algorithm in c. </title> <type> Technical report, </type> <institution> Department of General Engineering University of Illinois at Urbana-Champaign. </institution>
Reference: [Eshelman, 1991] <author> Eshelman, L. </author> <year> (1991). </year> <title> The CHC Adaptive Search Algorithm. How to Have Safe Search When Engaging in Nontraditional Genetic Recombination. </title> <editor> In Rawlins, G., editor, </editor> <booktitle> FOGA -1, </booktitle> <pages> pages 265-283. </pages> <publisher> Morgan Kaufmann. </publisher>
Reference: [Goldberg et al., 1989] <author> Goldberg, D., Korb, B., and Deb, K. </author> <year> (1989). </year> <title> Messy Genetic Algorithms: Motivation, Analysis, and First Results. </title> <journal> Complex Systems, </journal> <volume> 4 </volume> <pages> 415-444. </pages>
Reference: [Goldberg et al., 1992] <author> Goldberg, D. E., Deb, K., and Clark, J. H. </author> <year> (1992). </year> <title> Genetic algorithms, noise, and the sizing of populations. </title> <journal> Complex Systems. </journal>
Reference: [Goldberg et al., 1993] <author> Goldberg, D. E., Deb, K., Kar gupta, H., and Harik, G. </author> <year> (1993). </year> <title> Rapid, accurate optimization of difficult problems using fast messy genetic algorithms. </title> <editor> In Forrest, S., editor, </editor> <booktitle> Proc. of the 5th Int'l. Conf. on GAs, </booktitle> <pages> pages 56-64. </pages> <publisher> Morgan Kauffman. </publisher>
Reference: [Grimson, 1990] <author> Grimson, W. E. L. </author> <year> (1990). </year> <title> Object Recognition by Computer: The Role of Geometric Constraints. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA. </address>
Reference: [Kargupta, 1995] <author> Kargupta, H. </author> <year> (1995). </year> <title> SEARCH, Polynomial Complexity, And The Fast Messy Genetic Algorithm. </title> <type> PhD thesis, </type> <institution> Department of Computer Science University of Illinois at Urbana Cham-paign. </institution> <note> [Kelly D. </note> <author> Crawford and Schoenefeld, 1997] Kelly D. Crawford, Cory J. Hoelting, R. L. W. and Schoenefeld, D. A. </author> <year> (1997). </year> <title> A study of fixed-length subset recombination. </title> <editor> In Belew, R. and Vose, M., editors, </editor> <address> FOGA - 4. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: [Radcliffe and George, 1993] <author> Radcliffe, N. J. and George, F. A. W. </author> <year> (1993). </year> <title> A study in set recombination. </title> <editor> In Forrest, S., editor, </editor> <booktitle> Proc. of the 5th Int'l. Conf. on GAs, </booktitle> <pages> pages 23-30. </pages> <publisher> Morgan Kauffman. </publisher>
Reference: [Whitley et al., 1995] <author> Whitley, D., Beveridge, R., Graves, C., and Mathias, K. </author> <year> (1995). </year> <title> Test driving three 1995 genetic algorithms: New test functions and geometric matching. </title> <journal> Journal of Heuristics, </journal> <volume> 1(1):77 - 104. </volume>
Reference-contexts: Hence solutions tend to be "sparse" with the majority of bits being set to zero; this causes serious problems for algorithms such as CHC <ref> [Whitley et al., 1995] </ref>. The second example in this paper applies variants of the Fast Messy Genetic Algorithm (FMGA) to synthetic subset selection problems previously studied by Radcliffe and George (1993) and Crawford et al. (1997). as well as deceptive trap functions (Deb and Goldberg 1993). <p> In the another 24 problems, 0, 1, 2 and 3 additional more highly corrupted model instances are added: Figure 2b. This dataset and local search results are available through our website: http://www.cs.colostate.edu/~vision. (a) model instances. Previously <ref> [Whitley et al., 1995] </ref>, the CHC and Genitor algorithms have been shown to perform poorly on this data. In contrast, this dataset is readily solved using different bit-climbing algorithms [Beveridge et al., 1995].
References-found: 16

