URL: http://www.cs.ucsb.edu/~tzekwan/paper/content.ps
Refering-URL: http://www.cs.ucsb.edu/~tzekwan/
Root-URL: http://www.cs.ucsb.edu
Title: Design and Implementation of a System to Support Integration of Autonomous Database Systems  
Author: Tze Kwan Lau 
Degree: A thesis submitted in partial satisfaction of the requirements for the degree of Master of Science in Computer Science by  Committee in charge: Professor Jianwen Su, Chair Professor Oscar Ibarra Professor Amr El Abbadi  
Date: December 1998  
Affiliation: UNIVERSITY of CALIFORNIA Santa Barbara  
Abstract-found: 0
Intro-found: 1
Reference: [AHV95] <author> S. Abiteboul, R. Hull, and V. Vianu. </author> <title> Foundations of Databases. </title> <publisher> Addison-Wesley Publishing Company, Inc, </publisher> <year> 1995. </year>
Reference-contexts: For convenience we assume throughout this paper that the variables in r i (y i ) part are always distinct since equalities can be pushed into the formula '. The answer to Q is defined in the standard format <ref> [AHV95] </ref> and it is shown in the following example. <p> The bound/free condition of a relation R (x; y) is denoted by the expression R bf if the first coordinate x is bound and the second coordinate y is free. The superscript 'bf ' is called an adornment <ref> [AHV95] </ref> which we have applied in our subgoal ordering algorithm. 3 Century21 locates at http://www.century21.com 25 The general algorithm for adorning a rule, given an adornment for the head (ans) and an ordering of the rule body (relations) [AHV95], is as follows: (1) All occurrences of each bound variable in the <p> The superscript 'bf ' is called an adornment <ref> [AHV95] </ref> which we have applied in our subgoal ordering algorithm. 3 Century21 locates at http://www.century21.com 25 The general algorithm for adorning a rule, given an adornment for the head (ans) and an ordering of the rule body (relations) [AHV95], is as follows: (1) All occurrences of each bound variable in the rule head are bound, (2) all occurrences of constants are bound, and (3) if a variable x occurs in the rule body, then all occurrences of x in subse quent literals are bound.
Reference: [AKS96] <author> Y. Arens, C. Knoblock, and W. Shen. </author> <title> Query reformulation for dynamic information integration. </title> <journal> Journal of Intelligent Information Systems, </journal> <year> 1996. </year>
Reference-contexts: The update of mediators may lead to significant changes. Information agents from the AI community use another approach. Information agents are systems that provide a uniform query interface (conjunctive query) with an integrated database schema to multiple information sources and merge the results (e.g. <ref> [AKS96, GMPQ + 97, GKD97, SAB + 95] </ref>). The system determines which information sources are relevant to the query by using descriptions of the sources available to the system. In some cases, the agent rewrites (conjunctive) queries with (conjunctive) views [LMSS95, RSU95, KW96]. <p> Our primary goal here is to develop a data integration framework for the efficient evaluation of queries over multiple autonomous data sources (databases). Our ideas are inspired by those of the agent-based systems, i.e. to the use of Information Manifold [LRO96a] and SIMS <ref> [AKS96] </ref>. In our framework, we assume the existence of a global database schema [LRO96a, LRO96b, AKS96, KW96, GKD97]. We introduce the content of data sources as "source description catalogs" or "SDCs". <p> Our ideas are inspired by those of the agent-based systems, i.e. to the use of Information Manifold [LRO96a] and SIMS [AKS96]. In our framework, we assume the existence of a global database schema <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref>. We introduce the content of data sources as "source description catalogs" or "SDCs". SDCs represent the contents of each data source as a set of constraint tuples over the global schema; each of these tuple indicates possible contributions from the source. <p> When the evaluation path is completed, all resulting tuples are sent to a "result collector" of the query. 4.1 Partial Evaluation The evaluation strategy developed in [CDLS97] and in this thesis differs from those mediator-based strategies [GMPQ + 97, RS97] or agent-based ones <ref> [LRO96a, LRO96b, AKS96, KW96] </ref>. In those cases, the mediator or agent plays a greater role: it not only decomposes the query into subqueries (e.g., subgoals) and sends them to data sources, but also needs to perform further manipulations on the results from the sources to produce the final answer. <p> However, the bidding process in Mariposa processes the input query into a collection of subqueries and each subquery are posted for data sources to bid. 57 6.2 Information Agents Information agents <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref> are systems that provide a uniform query interface to multiple information sources. In such a system, a user requests for an inquiry and the system determines which information sources are relevant to the query user descriptions for the sources available to the system.
Reference: [BJM87] <author> A. Brodsky, J. Jaffar, and M. J. Maher. </author> <title> Towards practical constraint databases. </title> <booktitle> In Proc. Int. Conf. on Very Large Data Bases, </booktitle> <pages> pages 567-580, </pages> <year> 1987. </year>
Reference-contexts: We can build indexes on the attributes of SDCs and apply efficient join algorithms for constraint relations such as the ones described in <ref> [BJM87, ZSI98] </ref>. With the use of the meta data retrieve from every SDC, we can efficiently tighten the intervals of all variables by using the topological order T G = (x t1 ; :::; x tn ) obtained from Section 3.2.
Reference: [CDLS97] <author> X. Cheng, G. Dong, T. K. Lau, and J. Su. </author> <title> Data Integration by Describing Sources with Constraint Databases, 1997. </title> <type> Technical Documentation. </type>
Reference-contexts: The limitations of these approaches are further exposed with the advances of the World Wide Web in which new online information sources increase rapidly while old information sources are constantly eliminated or becoming temporarily unavailable due to network/system outages. In this thesis we describe a data integration framework in <ref> [CDLS97] </ref>. Our primary goal here is to develop a data integration framework for the efficient evaluation of queries over multiple autonomous data sources (databases). Our ideas are inspired by those of the agent-based systems, i.e. to the use of Information Manifold [LRO96a] and SIMS [AKS96]. <p> More detailed terminology will be discussed in the following chapters. 2.1 Database Schema and Conjunctive Queries In our framework <ref> [CDLS97] </ref>, we have used a well known class of queries, namely, conjunctive queries, for our modeling of autonomous data sources. We assume the existence of a set of attribute names and a set of domains as int, string and real such that each attribute is associated with a domain. <p> An SDC is actually a "constraint relation" in the sense of [KKR95] over dense [KG94, GS95] or discrete order domains. In <ref> [CDLS97] </ref>, we have the following definitions. Let &gt; and ? be two new symbols that are not in the given domains. The descriptive values (d-values) of A : t , where A is an attribute name and t a domain, are defined as follows. 1. <p> Intuitively, this d-tuple indicates what information is available at the data source located at ff. A source description catalog (SDC) <ref> [CDLS97] </ref> of the relation R, denoted by C r , is a finite set of d-tuples of R. <p> After the evaluation, the wrapper then transforms the result in a proper format, and sends the result set to the next destination for partial evaluation or to the result collector for result collection (to be explained in Section 2.5). 2.4 Plan Generator In the framework <ref> [CDLS97] </ref>, user query are input in a form of conjunctive query, Q : ans (x) r 1 (y 1 ); :::; r k (y k ); '. The Plan Generator of our framework accepts the conjunctive query and starts on the process of query plan generation. <p> Finally, an evaluation plan which includes a set of evaluation path, and path envelopes will be generated for partial evaluation. 3.1 Primates of Canonical Representation To describe the algorithm for locating data sources, we define some notations and operations in <ref> [CDLS97] </ref> about intervals. (A constant c in an unordered domain like string is viewed as an interval [c; c].) Let 1; +1 be two special symbols such that 1 &lt; c &lt; +1 for all other constants c. <p> From the matrix ij , we find that x 4 &lt; x 2 but variables x 2 and x 4 are not directly related in the given condition formula. 19 Intervals for Variables To obtain the intervals of a canonical representation <ref> [CDLS97] </ref>, we set the initial bounds L i = ( 1 and U i = +1 ) for each 1 i n. <p> (or "c x i "), let L i = maxfL i ; ( c g (resp. maxfL i ; [ c g); if it is "x i &lt; c" (or "x i c"), let U i = minfU i ; c )g (resp. minfU i ; c ]g); Different from <ref> [CDLS97] </ref>, we further propagate lower bounds upwards and upper bounds downwards by following the topological order T G = (x t1 ; :::; x tn ) obtained at the generation of matrix under the following rules: 1. <p> &lt; ? ? &gt; &gt; = ? ? ? ? ? &gt; = 7 7 7 1 C C A 3.3 Locating Sources by Constraint Query Evaluation After constructing the canonical representation of the input query, we are now ready to describe the extraction of the site sequences derived from <ref> [CDLS97] </ref>. Let Q : ans (x) r 1 (y 1 ); :::; r k (y k ); ' be a valid conjunctive query passed the satisfiability check in Section 3.2 which contains essential variables x 1 ; : : : ; x n . <p> It takes only two traversals (one in topological order and one in inverse-topological order of nodes) to find the tightest boundings of all variables and the cost is in linear time [GSW96] and improves the algorithm in <ref> [CDLS97] </ref>. Let A 1 ; : : : ; A n be the corresponding attributes of the essential variables x 1 ; : : : ; x n in Q. <p> I 3 = f (4:5; 7:5)g Since all I i 's have been altered, we set B = fx 1 ; x 2 ; x 3 ; x 4 ; x 5 g. 3.4 Evaluation Path Generation In this section we consider the generation of efficient query evaluation plans in <ref> [CDLS97] </ref>. The main task is to set the ordering of data sources in order to reduce the sizes of temporary results. <p> A different orderings of relation would yield different adornments. In general, we permit different orderings of relations for different adornments of a given rule head. The subgoal ordering problem here <ref> [CDLS97] </ref> is different from the traditional central or distributed processing environment, since the systems are autonomous and indexing (information) is generally not available. <p> The subgoal ordering algorithm, which is the same as in <ref> [CDLS97] </ref>, derives an ordering f , the schemas of temporary relations s i (1 i k), and sets of bound variables b i (1 i k) for subgoals (so that selection conditions can be constructed during evaluation). 26 Algorithm 2: Subgoal Ordering Step 1: Let g = fr 1 ; : <p> ; : : : ; t ` are all d-tuples in SDCs that are satisfiable with Q, the evaluation plan for Q is a set of evaluation paths fp t 1 ; :::; p t ` g. 28 We conclude our discussion on plan generation with the following properties from <ref> [CDLS97] </ref>. <p> When the evaluation path is completed, all resulting tuples are sent to a "result collector" of the query. 4.1 Partial Evaluation The evaluation strategy developed in <ref> [CDLS97] </ref> and in this thesis differs from those mediator-based strategies [GMPQ + 97, RS97] or agent-based ones [LRO96a, LRO96b, AKS96, KW96]. <p> If ff is the last source, s 0 is sent to ff a . The algorithm on partial evaluation at a data source, which is the same as in <ref> [CDLS97] </ref> is given below. <p> After E is evaluated, the result s 2 is sent to ff a since ff C21 is the last source on the path t. The following theorem presented in <ref> [CDLS97] </ref> states the correctness of the query evaluation algorithm. Theorem 4.1 For each conjunctive query Q, the answer obtained by our evaluation methods is always the same as the definite answer of Q. Clearly the algorithm always produces tuples in the definite answer. <p> In the framework, we illustrate the use of constraint tuples for source description, and the novel feature of sending partially evaluated queries between data sources mentioned in <ref> [CDLS97] </ref>. Our framework provides a flexible and scalable system for processing queries to multiple information sources. We have covered several aspects through out the thesis: plan generation, path optimization, and partial evaluation. <p> improvement in the implementation, the prototype clearly demonstrates that the approaches of our data integration framework can be extended to support a large database network. 61 7.1 Future Work Since there are many interesting problems related to query optimization, future work will focus on extending the optimization capabilities described in <ref> [CDLS97] </ref>. For example, new strategies for minimizing the number of paths and reducing duplicates among different paths remain to be investigated. In fact, the current SDC model in [CDLS97] does not contain enough information for further optimization. It will be interesting to extend the model towards query optimization. <p> Work Since there are many interesting problems related to query optimization, future work will focus on extending the optimization capabilities described in <ref> [CDLS97] </ref>. For example, new strategies for minimizing the number of paths and reducing duplicates among different paths remain to be investigated. In fact, the current SDC model in [CDLS97] does not contain enough information for further optimization. It will be interesting to extend the model towards query optimization. In addition, the updates and maintenance of SDCs can be one of the important issues. 62
Reference: [DL97] <author> O. M. Duschka and A. Y. Levy. </author> <title> Recursive plans for information gathering. </title> <booktitle> In Proc. Int. Joint Conf. on Artificial Intelligence, </booktitle> <year> 1997. </year>
Reference: [DLI96] <institution> Digital library initiative. IEEE Computer, </institution> <month> May </month> <year> 1996. </year>
Reference-contexts: Most of the time, information sources are put to work together in a loosely coupled setting, and sometimes they cause problems on maintain consistency [LMR90, SL90, LSK95, Ull97, Hul97]. Applications like digital libraries <ref> [DLI96] </ref> and electronic commerce [EC96, EC97] are applications that typically work with a collection of autonomous data sources. There are two of the fundamental issues in developing such data integration applications: (1) managing semantic heterogeneity (schema integration) and (2) efficiently evaluating queries that are often distributed in nature (query optimization).
Reference: [EC96] <institution> Electronic commerce and the internet. Comm. of ACM, </institution> <month> June </month> <year> 1996. </year>
Reference-contexts: Most of the time, information sources are put to work together in a loosely coupled setting, and sometimes they cause problems on maintain consistency [LMR90, SL90, LSK95, Ull97, Hul97]. Applications like digital libraries [DLI96] and electronic commerce <ref> [EC96, EC97] </ref> are applications that typically work with a collection of autonomous data sources. There are two of the fundamental issues in developing such data integration applications: (1) managing semantic heterogeneity (schema integration) and (2) efficiently evaluating queries that are often distributed in nature (query optimization).
Reference: [EC97] <institution> Electronic commerce. IEEE Computer, </institution> <month> May </month> <year> 1997. </year>
Reference-contexts: Most of the time, information sources are put to work together in a loosely coupled setting, and sometimes they cause problems on maintain consistency [LMR90, SL90, LSK95, Ull97, Hul97]. Applications like digital libraries [DLI96] and electronic commerce <ref> [EC96, EC97] </ref> are applications that typically work with a collection of autonomous data sources. There are two of the fundamental issues in developing such data integration applications: (1) managing semantic heterogeneity (schema integration) and (2) efficiently evaluating queries that are often distributed in nature (query optimization).
Reference: [FS97] <author> M. Foweler and K. Scott. </author> <title> UML Distilled Applying the Standard Object Modeling Language. </title> <address> Addision-Wesley, </address> <year> 1997. </year> <month> 63 </month>
Reference-contexts: In the following subsections, we provide a brief overview of the component objects and their behavior of each module. Class diagram for each module is composed with UML <ref> [FS97] </ref> object model notation.
Reference: [GKD97] <author> M. R. Genesereth, A. M. Keller, and O. M. Duschka. Infomaster: </author> <title> An information integration system. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <pages> pages 539-542, </pages> <year> 1997. </year>
Reference-contexts: The update of mediators may lead to significant changes. Information agents from the AI community use another approach. Information agents are systems that provide a uniform query interface (conjunctive query) with an integrated database schema to multiple information sources and merge the results (e.g. <ref> [AKS96, GMPQ + 97, GKD97, SAB + 95] </ref>). The system determines which information sources are relevant to the query by using descriptions of the sources available to the system. In some cases, the agent rewrites (conjunctive) queries with (conjunctive) views [LMSS95, RSU95, KW96]. <p> Our ideas are inspired by those of the agent-based systems, i.e. to the use of Information Manifold [LRO96a] and SIMS [AKS96]. In our framework, we assume the existence of a global database schema <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref>. We introduce the content of data sources as "source description catalogs" or "SDCs". SDCs represent the contents of each data source as a set of constraint tuples over the global schema; each of these tuple indicates possible contributions from the source. <p> However, the bidding process in Mariposa processes the input query into a collection of subqueries and each subquery are posted for data sources to bid. 57 6.2 Information Agents Information agents <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref> are systems that provide a uniform query interface to multiple information sources. In such a system, a user requests for an inquiry and the system determines which information sources are relevant to the query user descriptions for the sources available to the system.
Reference: [GMPQ + 97] <author> H. Garcia-Molina, Y. Papakonstantinou, D. Quass, A. Rajara-man, Y. Sagiv, J. Ullmand, V. Vassalos, and J. Widom. </author> <title> The TSIMMIS approach to mediation: Data models and languages. </title> <journal> Journal of Intelligent Information Systems, </journal> <year> 1997. </year>
Reference-contexts: The update of mediators may lead to significant changes. Information agents from the AI community use another approach. Information agents are systems that provide a uniform query interface (conjunctive query) with an integrated database schema to multiple information sources and merge the results (e.g. <ref> [AKS96, GMPQ + 97, GKD97, SAB + 95] </ref>). The system determines which information sources are relevant to the query by using descriptions of the sources available to the system. In some cases, the agent rewrites (conjunctive) queries with (conjunctive) views [LMSS95, RSU95, KW96]. <p> Then we know that all tuples from ff n must satisfy either t 1 or t 2 . 2.3 Wrapper In the context of data integration, each data source needs to have a wrapper <ref> [Wie92, GMPQ + 97, RS97, SAB + 95] </ref> so that both the information content as well as the query capabilities can be offered. Our SDCs can clearly be viewed as descriptions of the query processing capabilities of wrappers (e.g. [GMPQ + 97]) where each service has an associated "wrapper". <p> Our SDCs can clearly be viewed as descriptions of the query processing capabilities of wrappers (e.g. <ref> [GMPQ + 97] </ref>) where each service has an associated "wrapper". Every associated wrapper responds to convert its data into a commonly understood format and semantics. The wrapper also functions as a translator between the outside 2 Site School Match is located at http://schoolmatch.com 10 world and its local database. <p> When the evaluation path is completed, all resulting tuples are sent to a "result collector" of the query. 4.1 Partial Evaluation The evaluation strategy developed in [CDLS97] and in this thesis differs from those mediator-based strategies <ref> [GMPQ + 97, RS97] </ref> or agent-based ones [LRO96a, LRO96b, AKS96, KW96].
Reference: [GS95] <author> S. Grumbach and J. Su. </author> <title> Dense order constraint databases. </title> <booktitle> In Proc. ACM Symp. on Principles of Database Systems, </booktitle> <address> San Jose, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: An SDC is actually a "constraint relation" in the sense of [KKR95] over dense <ref> [KG94, GS95] </ref> or discrete order domains. In [CDLS97], we have the following definitions. Let &gt; and ? be two new symbols that are not in the given domains.
Reference: [GSW96] <author> S. Guo, W. Sun, and M. A. Weiss. </author> <title> Solving satisfiability and implication problems in database systems. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 21(2) </volume> <pages> 270-293, </pages> <month> June </month> <year> 1996. </year>
Reference-contexts: We start on the query consistency checking and the construction of the intervals in the canonical representation by using a similar algorithm described in <ref> [GSW96] </ref>. The canonical form not only represents the conjunctive formula ', but also extends the constraint requirements from one variable to other related variables. The satisfiability test and the intervals in the canonical from can be done within linear time in the length of the formula. <p> The satisfiability test and the intervals in the canonical from can be done within linear time in the length of the formula. However, for queries that involve inequality, the complexity is increased to NP-hard <ref> [GSW96] </ref>. Consider the conjunctive formula ' of the following form : x i f=; ; &lt; gx j ^ : : : ^ x i f=; ; &lt;gx k . <p> It takes only two traversals (one in topological order and one in inverse-topological order of nodes) to find the tightest boundings of all variables and the cost is in linear time <ref> [GSW96] </ref> and improves the algorithm in [CDLS97]. Let A 1 ; : : : ; A n be the corresponding attributes of the essential variables x 1 ; : : : ; x n in Q.
Reference: [HGMW + 95] <author> J. Hammer, H. Garcia-Molina, J. Widom, W. Labio, and Y. Zhuge. </author> <title> The stanford data warehousing project. </title> <journal> IEEE Data Engineering Bulletin, </journal> <volume> 18(2), </volume> <month> 6 </month> <year> 1995. </year>
Reference-contexts: Among different approaches for data integration approaches, data warehousing integrates relevant data sources into a repository that can be fully materialized <ref> [HGMW + 95] </ref>, fully virtual, or a combination [HZ96].
Reference: [Hul97] <author> R. Hull. </author> <title> Managing semantic heterogeneity in databases: A theoretical perspective. </title> <booktitle> In Proc. ACM Symp. on Principles of Database Systems, </booktitle> <year> 1997. </year>
Reference-contexts: Most of the time, information sources are put to work together in a loosely coupled setting, and sometimes they cause problems on maintain consistency <ref> [LMR90, SL90, LSK95, Ull97, Hul97] </ref>. Applications like digital libraries [DLI96] and electronic commerce [EC96, EC97] are applications that typically work with a collection of autonomous data sources.
Reference: [HZ96] <author> R. Hull and G. Zhou. </author> <title> A framework for supporting data integration using the materialized and virtual approaches. </title> <booktitle> In Proc. ACM SIGMOD Int. Conf. on Management of Data, </booktitle> <year> 1996. </year>
Reference-contexts: Among different approaches for data integration approaches, data warehousing integrates relevant data sources into a repository that can be fully materialized [HGMW + 95], fully virtual, or a combination <ref> [HZ96] </ref>. Queries are formulated against the integrated schema at the data warehouse and are evaluated either locally at the data warehouse when it is fully materialized or decomposed into subqueries that are evaluated at the sources when some or all of the data are not materialized.
Reference: [KG94] <author> P. C. Kanellakis and D. Q. Goldin. </author> <title> Constraint programming and database query languages. </title> <booktitle> In Proc. 2nd Conference on Theoretical Aspects of Computer Software (TACS), volume 789 of Lecture notes in computer science. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1994. </year>
Reference-contexts: An SDC is actually a "constraint relation" in the sense of [KKR95] over dense <ref> [KG94, GS95] </ref> or discrete order domains. In [CDLS97], we have the following definitions. Let &gt; and ? be two new symbols that are not in the given domains.
Reference: [KKR95] <author> P. Kanellakis, G. Kuper, and P. Revesz. </author> <title> Constraint query languages. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 51(1) </volume> <pages> 26-52, </pages> <year> 1995. </year> <note> (An extended abstract appeard in Proc. PODS '90). 64 </note>
Reference-contexts: An SDC is actually a "constraint relation" in the sense of <ref> [KKR95] </ref> over dense [KG94, GS95] or discrete order domains. In [CDLS97], we have the following definitions. Let &gt; and ? be two new symbols that are not in the given domains.
Reference: [KW96] <author> C. Kwok and D. S. Weld. </author> <title> Planning to gather information. </title> <booktitle> In Proc. AAAI, </booktitle> <year> 1996. </year>
Reference-contexts: The system determines which information sources are relevant to the query by using descriptions of the sources available to the system. In some cases, the agent rewrites (conjunctive) queries with (conjunctive) views <ref> [LMSS95, RSU95, KW96] </ref>. This makes the introduction of new sources simplier than the two approaches discussed earlier. However, the inherent difficulties of query rewriting using views (a NP-complete problem) prevents efficient implementation of information agents. <p> Our ideas are inspired by those of the agent-based systems, i.e. to the use of Information Manifold [LRO96a] and SIMS [AKS96]. In our framework, we assume the existence of a global database schema <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref>. We introduce the content of data sources as "source description catalogs" or "SDCs". SDCs represent the contents of each data source as a set of constraint tuples over the global schema; each of these tuple indicates possible contributions from the source. <p> When the evaluation path is completed, all resulting tuples are sent to a "result collector" of the query. 4.1 Partial Evaluation The evaluation strategy developed in [CDLS97] and in this thesis differs from those mediator-based strategies [GMPQ + 97, RS97] or agent-based ones <ref> [LRO96a, LRO96b, AKS96, KW96] </ref>. In those cases, the mediator or agent plays a greater role: it not only decomposes the query into subqueries (e.g., subgoals) and sends them to data sources, but also needs to perform further manipulations on the results from the sources to produce the final answer. <p> However, the bidding process in Mariposa processes the input query into a collection of subqueries and each subquery are posted for data sources to bid. 57 6.2 Information Agents Information agents <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref> are systems that provide a uniform query interface to multiple information sources. In such a system, a user requests for an inquiry and the system determines which information sources are relevant to the query user descriptions for the sources available to the system.
Reference: [Lev96] <author> A. Y. Levy. </author> <title> Obtaining complete answers from incomplete databases. </title> <booktitle> In Proc. Int. Conf. on Very Large Data Bases, </booktitle> <year> 1996. </year>
Reference: [LMR90] <author> W. Litwin, L. Mark, and N. Roussopoulos. </author> <title> Interoperability of multiple autonomous databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 22(3) </volume> <pages> 267-293, </pages> <year> 1990. </year>
Reference-contexts: Most of the time, information sources are put to work together in a loosely coupled setting, and sometimes they cause problems on maintain consistency <ref> [LMR90, SL90, LSK95, Ull97, Hul97] </ref>. Applications like digital libraries [DLI96] and electronic commerce [EC96, EC97] are applications that typically work with a collection of autonomous data sources.
Reference: [LMSS95] <author> A. Y. Levy, A. O. Mendelzon, Y. Sagiv, and D. Srivastava. </author> <title> Answering queries using views. </title> <booktitle> In Proc. ACM Symp. on Principles of Database Systems, </booktitle> <pages> pages 95-104, </pages> <year> 1995. </year>
Reference-contexts: The system determines which information sources are relevant to the query by using descriptions of the sources available to the system. In some cases, the agent rewrites (conjunctive) queries with (conjunctive) views <ref> [LMSS95, RSU95, KW96] </ref>. This makes the introduction of new sources simplier than the two approaches discussed earlier. However, the inherent difficulties of query rewriting using views (a NP-complete problem) prevents efficient implementation of information agents.
Reference: [LRO96a] <author> A. Levy, A. Rajaraman, and J. J. Ordille. </author> <title> Querying heterogeneous information sources using source descriptions. </title> <booktitle> In Proc. National Conf. on Artifical Intelligence, </booktitle> <year> 1996. </year>
Reference-contexts: Our primary goal here is to develop a data integration framework for the efficient evaluation of queries over multiple autonomous data sources (databases). Our ideas are inspired by those of the agent-based systems, i.e. to the use of Information Manifold <ref> [LRO96a] </ref> and SIMS [AKS96]. In our framework, we assume the existence of a global database schema [LRO96a, LRO96b, AKS96, KW96, GKD97]. We introduce the content of data sources as "source description catalogs" or "SDCs". <p> Our ideas are inspired by those of the agent-based systems, i.e. to the use of Information Manifold [LRO96a] and SIMS [AKS96]. In our framework, we assume the existence of a global database schema <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref>. We introduce the content of data sources as "source description catalogs" or "SDCs". SDCs represent the contents of each data source as a set of constraint tuples over the global schema; each of these tuple indicates possible contributions from the source. <p> When the evaluation path is completed, all resulting tuples are sent to a "result collector" of the query. 4.1 Partial Evaluation The evaluation strategy developed in [CDLS97] and in this thesis differs from those mediator-based strategies [GMPQ + 97, RS97] or agent-based ones <ref> [LRO96a, LRO96b, AKS96, KW96] </ref>. In those cases, the mediator or agent plays a greater role: it not only decomposes the query into subqueries (e.g., subgoals) and sends them to data sources, but also needs to perform further manipulations on the results from the sources to produce the final answer. <p> However, the bidding process in Mariposa processes the input query into a collection of subqueries and each subquery are posted for data sources to bid. 57 6.2 Information Agents Information agents <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref> are systems that provide a uniform query interface to multiple information sources. In such a system, a user requests for an inquiry and the system determines which information sources are relevant to the query user descriptions for the sources available to the system. <p> The domain model in SIMS has a similar approach to the SDC describes in this thesis. 58 Information Manifold The Information Manifold system <ref> [LRO96a] </ref> provides uniform access to multiple structured information sources on the World Wide Web (e.g. form-based sources, databases ). The system answers queries that require the combination of information from multiple sources.
Reference: [LRO96b] <author> A. Y. Levy, A. Rajaraman, and J. J. Ordille. </author> <title> Query answering algorithms for information agents. </title> <booktitle> In Proceedings of the 13th National Conference on Artificial Intelligence, </booktitle> <year> 1996. </year>
Reference-contexts: Our ideas are inspired by those of the agent-based systems, i.e. to the use of Information Manifold [LRO96a] and SIMS [AKS96]. In our framework, we assume the existence of a global database schema <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref>. We introduce the content of data sources as "source description catalogs" or "SDCs". SDCs represent the contents of each data source as a set of constraint tuples over the global schema; each of these tuple indicates possible contributions from the source. <p> When the evaluation path is completed, all resulting tuples are sent to a "result collector" of the query. 4.1 Partial Evaluation The evaluation strategy developed in [CDLS97] and in this thesis differs from those mediator-based strategies [GMPQ + 97, RS97] or agent-based ones <ref> [LRO96a, LRO96b, AKS96, KW96] </ref>. In those cases, the mediator or agent plays a greater role: it not only decomposes the query into subqueries (e.g., subgoals) and sends them to data sources, but also needs to perform further manipulations on the results from the sources to produce the final answer. <p> However, the bidding process in Mariposa processes the input query into a collection of subqueries and each subquery are posted for data sources to bid. 57 6.2 Information Agents Information agents <ref> [LRO96a, LRO96b, AKS96, KW96, GKD97] </ref> are systems that provide a uniform query interface to multiple information sources. In such a system, a user requests for an inquiry and the system determines which information sources are relevant to the query user descriptions for the sources available to the system.
Reference: [LSK95] <author> A. Levy, D. Srivastava, and T. Kirk. </author> <title> Data model and query evaluation in global information systems. </title> <journal> Journal of Intelligent Information Systems, </journal> <year> 1995. </year>
Reference-contexts: Most of the time, information sources are put to work together in a loosely coupled setting, and sometimes they cause problems on maintain consistency <ref> [LMR90, SL90, LSK95, Ull97, Hul97] </ref>. Applications like digital libraries [DLI96] and electronic commerce [EC96, EC97] are applications that typically work with a collection of autonomous data sources.
Reference: [Mot89] <author> A. Motro. </author> <title> Integrity = validity + completeness. </title> <journal> ACM Trans. on Database Systems, </journal> <volume> 14(4) </volume> <pages> 480-502, </pages> <month> December </month> <year> 1989. </year>
Reference: [RS97] <author> M. T. Roth and P. Schwarz. </author> <title> Don't scrap it, wrap it! a wrapper architecture for legacy data sources. </title> <booktitle> In Proc. Int. Conf. on Very Large Data Bases, </booktitle> <year> 1997. </year>
Reference-contexts: Then we know that all tuples from ff n must satisfy either t 1 or t 2 . 2.3 Wrapper In the context of data integration, each data source needs to have a wrapper <ref> [Wie92, GMPQ + 97, RS97, SAB + 95] </ref> so that both the information content as well as the query capabilities can be offered. Our SDCs can clearly be viewed as descriptions of the query processing capabilities of wrappers (e.g. [GMPQ + 97]) where each service has an associated "wrapper". <p> When the evaluation path is completed, all resulting tuples are sent to a "result collector" of the query. 4.1 Partial Evaluation The evaluation strategy developed in [CDLS97] and in this thesis differs from those mediator-based strategies <ref> [GMPQ + 97, RS97] </ref> or agent-based ones [LRO96a, LRO96b, AKS96, KW96].
Reference: [RSU95] <author> A. Rajaraman, Y. Sagiv, and J. D. Ullman. </author> <title> Answering queries using templates with binding patterns. </title> <booktitle> In Proc. ACM Symp. on Principles of Database Systems, </booktitle> <pages> pages 105-112, </pages> <year> 1995. </year> <month> 65 </month>
Reference-contexts: The system determines which information sources are relevant to the query by using descriptions of the sources available to the system. In some cases, the agent rewrites (conjunctive) queries with (conjunctive) views <ref> [LMSS95, RSU95, KW96] </ref>. This makes the introduction of new sources simplier than the two approaches discussed earlier. However, the inherent difficulties of query rewriting using views (a NP-complete problem) prevents efficient implementation of information agents.
Reference: [SAB + 95] <author> V. S. Subrahmanian, S. Adali, A. Brink, R. Emery, J. J. Lu, A. Rajput, T. J. Rogers, R. Ross, and C. Ward. </author> <title> Hermes: Heterogeneous reasoning and mediator system. </title> <type> Technical report, </type> <institution> University of Maryland, </institution> <year> 1995. </year>
Reference-contexts: The update of mediators may lead to significant changes. Information agents from the AI community use another approach. Information agents are systems that provide a uniform query interface (conjunctive query) with an integrated database schema to multiple information sources and merge the results (e.g. <ref> [AKS96, GMPQ + 97, GKD97, SAB + 95] </ref>). The system determines which information sources are relevant to the query by using descriptions of the sources available to the system. In some cases, the agent rewrites (conjunctive) queries with (conjunctive) views [LMSS95, RSU95, KW96]. <p> Then we know that all tuples from ff n must satisfy either t 1 or t 2 . 2.3 Wrapper In the context of data integration, each data source needs to have a wrapper <ref> [Wie92, GMPQ + 97, RS97, SAB + 95] </ref> so that both the information content as well as the query capabilities can be offered. Our SDCs can clearly be viewed as descriptions of the query processing capabilities of wrappers (e.g. [GMPQ + 97]) where each service has an associated "wrapper".
Reference: [SAL + 96] <author> M. Stonebraker, P. M. Aoki, W. Litwin, A. Pfeffer, A. Sah, J. Sidell, C. Staelin, and A. Yu. Mariposa: </author> <title> a wide-area distributed database system. </title> <journal> VLDB Journal, </journal> <volume> 5(1) </volume> <pages> 48-63, </pages> <month> Jan </month> <year> 1996. </year>
Reference-contexts: For each evaluation path, the query moves from one source to another sequentially to perform partial evaluation. The distributed evaluation approach is similar to but different from Mariposa <ref> [SAL + 96] </ref> where query evaluation is based on decomposing a query into subqueries which are then posted for data sources to bid. Moreover, we demonstrate the capabilities of our framework by implementing a RealEstate property search engine system. <p> The framework in this thesis are related to several previous and current research projects. In this chapter, we review some approaches from different works and compare them with our data integration framework. 6.1 Mariposa The Mariposa distributed database management system <ref> [SAL + 96] </ref> is an ongoing research project at the University of California at Berkeley. The goal of the Mariposa project is to design a WAN distributed databases system. All Mariposa clients and server have an account with a network bank.
Reference: [SDK + 94] <author> M. Stonebraker, R. Devine, M. Kornacker, W. Litwin, A. Pfeffer, and C. Staelin. </author> <title> An economic paradigm for query processing and data migration in mariposa. </title> <booktitle> In Proc. Int. Conf. on Parallel and Distributed Information, </booktitle> <year> 1994. </year>
Reference: [SL90] <author> A. P. Sheth and J. A. Larson. </author> <title> Federated database systems for managing distributed, heterogeneous, and autonomous databases. </title> <journal> ACM Computing Surveys, </journal> <volume> 22(3), </volume> <month> 9 </month> <year> 1990. </year>
Reference-contexts: Most of the time, information sources are put to work together in a loosely coupled setting, and sometimes they cause problems on maintain consistency <ref> [LMR90, SL90, LSK95, Ull97, Hul97] </ref>. Applications like digital libraries [DLI96] and electronic commerce [EC96, EC97] are applications that typically work with a collection of autonomous data sources.
Reference: [Ull97] <author> J. D. Ullman. </author> <title> Information integration using logical views. </title> <booktitle> In Proc. Int. Conf. on Database Theory, </booktitle> <pages> pages 19-40, </pages> <year> 1997. </year>
Reference-contexts: Most of the time, information sources are put to work together in a loosely coupled setting, and sometimes they cause problems on maintain consistency <ref> [LMR90, SL90, LSK95, Ull97, Hul97] </ref>. Applications like digital libraries [DLI96] and electronic commerce [EC96, EC97] are applications that typically work with a collection of autonomous data sources.
Reference: [Wie92] <author> G. Wiederhold. </author> <title> Mediators in the architecture of future information systems. </title> <journal> IEEE Computer, </journal> <volume> 25(3) </volume> <pages> 38-49, </pages> <month> mar </month> <year> 1992. </year>
Reference-contexts: Then we know that all tuples from ff n must satisfy either t 1 or t 2 . 2.3 Wrapper In the context of data integration, each data source needs to have a wrapper <ref> [Wie92, GMPQ + 97, RS97, SAB + 95] </ref> so that both the information content as well as the query capabilities can be offered. Our SDCs can clearly be viewed as descriptions of the query processing capabilities of wrappers (e.g. [GMPQ + 97]) where each service has an associated "wrapper".
Reference: [ZSI98] <author> H. Zhu, J. Su, and O. H. Ibarra. </author> <title> Efficient evaluation of linear constraint queries with interval b-trees. </title> <note> In preparation, </note> <year> 1998. </year>
Reference-contexts: We can build indexes on the attributes of SDCs and apply efficient join algorithms for constraint relations such as the ones described in <ref> [BJM87, ZSI98] </ref>. With the use of the meta data retrieve from every SDC, we can efficiently tighten the intervals of all variables by using the topological order T G = (x t1 ; :::; x tn ) obtained from Section 3.2.
References-found: 35

