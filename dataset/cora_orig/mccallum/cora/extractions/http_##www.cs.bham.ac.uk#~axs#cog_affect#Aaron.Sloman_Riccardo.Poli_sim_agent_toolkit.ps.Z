URL: http://www.cs.bham.ac.uk/~axs/cog_affect/Aaron.Sloman_Riccardo.Poli_sim_agent_toolkit.ps.Z
Refering-URL: http://www.cs.bham.ac.uk/~axs/cog_affect/sim_agent.html
Root-URL: 
Email: fA.Sloman,R.Polig@cs.bham.ac.uk  
Title: SIM AGENT: A toolkit for exploring agent designs  
Author: Aaron Sloman and Riccardo Poli 
Address: Birmingham, B15 2TT United Kingdom  
Affiliation: School of Computer Science The University of Birmingham  
Abstract: SIM AGENT is a toolkit that arose out of a project concerned with designing an architecture for an autonomous agent with human-like capabilities. Analysis of requirements showed a need to combine a wide variety of richly interacting mechanisms, including independent asynchronous sources of motivation and the ability to reflect on which motives to adopt, when to achieve them, how to achieve them, and so on. These internal `management' (and meta-management) processes involve a certain amount of parallelism, but resource limits imply the need for explicit control of attention. Such control problems can lead to emotional and other characteristically human affective states. In order to explore these ideas, we needed a toolkit to facilitate experiments with various architectures in various environments, including other agents. The paper outlines requirements and summarises the main design features of a Pop-11 toolkit supporting both rule-based and `sub-symbolic' mechanisms. Some experiments including hybrid architectures and genetic algorithms are summarised.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> J.A.D.W. Anderson, </author> <title> editor. POP-11 Comes of Age: The Advancement of an AI Programming Language. </title> <publisher> Ellis Horwood, </publisher> <address> Chichester, </address> <year> 1989. </year>
Reference-contexts: A simple object has no parts that are objects managed by the scheduler but may nevertheless have a complex internal architecture, involving several interacting subsystems. e.g. an intelligent agent. 2 The SIM AGENT toolkit The toolkit is implemented in Poplog Pop-11 <ref> [1] </ref>, using our Poprulebase [27] library, and the Objectclass package designed by Steve Knight at Hewlett Packard Laboratories, which extends Pop-11 with CLOS-like object oriented facilities, including classes, inheritance and generic methods that can be redefined for specific user-defined classes of objects or agents.
Reference: 2. <author> J. Bates. </author> <title> The role of emotion in believable agents. </title> <journal> Communications of the ACM, </journal> <volume> 37(7) </volume> <pages> 122-125, </pages> <year> 1994. </year>
Reference-contexts: This requires an architecture combining a wide variety of types of mechanisms. Like the OZ project <ref> [3, 2] </ref> we are initially interested in `broad and shallow' architectures, combining many sorts of capabilities, where each capability is initially implemented in a shallow fashion. Deeper, more complete, implementations will follow. <p> Rather, the main focus was (and still often is) on some sub-mechanism, or mechanisms, e.g. vision, language processing, planning, learning, etc. There is now growing interest in agent architectures, and increasingly ambitious attempts to design complete agents, whether physical robots or software agents (e.g. <ref> [2, 7, 10] </ref>. However, the motivational systems are generally very primitive. There are some attempts to describe complete human-like architectures (e.g. [14]) but implementations are usually lacking, partly because of the enormous complexity of the task (as Minsky comments in [17]). <p> Bates et al. <ref> [3, 2] </ref> attempt to implement `broad and shallow' systems based on rules of a type that might emerge from the architecture (Fig. 1) that we are considering.
Reference: 3. <author> J. Bates, A. B. Loyall, and W. S. Reilly. </author> <title> Broad agents. </title> <booktitle> In Paper presented at AAAI spring symposium on integrated intelligent architectures, </booktitle> <year> 1991. </year> <note> (Available in SIGART BULLETIN, 2(4), </note> <month> Aug. </month> <year> 1991, </year> <pages> pp. 38-40). </pages>
Reference-contexts: This requires an architecture combining a wide variety of types of mechanisms. Like the OZ project <ref> [3, 2] </ref> we are initially interested in `broad and shallow' architectures, combining many sorts of capabilities, where each capability is initially implemented in a shallow fashion. Deeper, more complete, implementations will follow. <p> Bates et al. <ref> [3, 2] </ref> attempt to implement `broad and shallow' systems based on rules of a type that might emerge from the architecture (Fig. 1) that we are considering.
Reference: 4. <author> L.P. Beaudoin. </author> <title> Goal processing in autonomous agents. </title> <type> PhD thesis, </type> <institution> School of Computer Science, The University of Birmingham, </institution> <year> 1994. </year>
Reference-contexts: Figure 1 depicts approximately the type of architecture we have been exploring (described incrementally in <ref> [28, 19, 21, 5, 4, 25, 11] </ref>). At present we are primarily concerned with performance in simulated time, not real time. <p> Towards an Intelligent Agent Architecture before selection. The latter (which need not involve conscious processing) are resource-limited and may sometimes require both attention filters to protect them from disturbance and meta-management processes to regulate and direct them. This requires some sort of self-monitoring. (See <ref> [4, 11] </ref>). Reflexes (learnt or innate) bypass `normal' processing. The diagram should not be taken to imply any sharp division between processes concerned with perception or action and other cognitive processes [20]. <p> The internal `management' (and meta-management) processes involve a certain amount of (asynchronous) parallelism, but we wanted to show how resource limits restricting parallelism in high level processes can lead to emotional and other characteristically human states involving partial loss of control of attention and thought processes <ref> [18, 21, 22, 4, 11] </ref>. This requires an architecture combining a wide variety of types of mechanisms. Like the OZ project [3, 2] we are initially interested in `broad and shallow' architectures, combining many sorts of capabilities, where each capability is initially implemented in a shallow fashion.
Reference: 5. <author> L.P. Beaudoin and A. Sloman. </author> <title> A study of motive processing and attention. </title> <editor> In A.Sloman, D.Hogg, G.Humphreys, D. Partridge, and A. Ramsay, editors, </editor> <booktitle> Prospects for Artificial Intelligence, </booktitle> <pages> pages 229-238. </pages> <publisher> IOS Press, </publisher> <address> Amsterdam, </address> <year> 1993. </year>
Reference-contexts: Figure 1 depicts approximately the type of architecture we have been exploring (described incrementally in <ref> [28, 19, 21, 5, 4, 25, 11] </ref>). At present we are primarily concerned with performance in simulated time, not real time.
Reference: 6. <author> R. A. Brooks. </author> <title> Intelligence without representation. </title> <journal> Artificial Intelligence, </journal> <volume> 47 </volume> <pages> 139-159, </pages> <year> 1991. </year>
Reference-contexts: `real' robot equipment is used, and as a result such work often oversimplifies some aspects of the task because of the difficulty of other aspects. (It is possible to hide `toy' problems under a pile of expensive equipment.) There are some attempts to design and implement more complete architectures (e.g. <ref> [9, 6, 17] </ref>) though these projects are still at a relatively early stage, and those involving complete physical robots include only a small subset of the motive management processes that interest us.
Reference: 7. <author> M.P. Georgeff. </author> <title> Agents and their plans, </title> <booktitle> 1995. Invited lecture Proc 14th Int. Joint Conf. on AI. </booktitle>
Reference-contexts: Rather, the main focus was (and still often is) on some sub-mechanism, or mechanisms, e.g. vision, language processing, planning, learning, etc. There is now growing interest in agent architectures, and increasingly ambitious attempts to design complete agents, whether physical robots or software agents (e.g. <ref> [2, 7, 10] </ref>. However, the motivational systems are generally very primitive. There are some attempts to describe complete human-like architectures (e.g. [14]) but implementations are usually lacking, partly because of the enormous complexity of the task (as Minsky comments in [17]).
Reference: 8. <author> David E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization, and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: As in the previous example, we used a top-up approach, i.e. starting with agents having a high-level symbolic architecture only partially specified and some high-level functions, like perception, communication and motor control, already available (top) and using optimisation techniques like Genetic Algorithms (GAs) <ref> [8] </ref> to complete the design (up). The scenario is very simple: there is a flat 2-D world inhabited by two agents, a blind agent and a lazy one.
Reference: 9. <author> B. Hayes-Roth. </author> <title> Intelligent control. </title> <journal> Artificial Intelligence, </journal> <volume> 59 </volume> <pages> 213-220, </pages> <year> 1993. </year>
Reference-contexts: `real' robot equipment is used, and as a result such work often oversimplifies some aspects of the task because of the difficulty of other aspects. (It is possible to hide `toy' problems under a pile of expensive equipment.) There are some attempts to design and implement more complete architectures (e.g. <ref> [9, 6, 17] </ref>) though these projects are still at a relatively early stage, and those involving complete physical robots include only a small subset of the motive management processes that interest us.
Reference: 10. <author> B. Hayes-Roth. </author> <title> Agents on stage: </title> <booktitle> Advancing the state of the art of ai. In Proc 14th Int. Joint Conf. on AI, </booktitle> <pages> pages 967-971, </pages> <address> Montreal, </address> <year> 1995. </year>
Reference-contexts: Rather, the main focus was (and still often is) on some sub-mechanism, or mechanisms, e.g. vision, language processing, planning, learning, etc. There is now growing interest in agent architectures, and increasingly ambitious attempts to design complete agents, whether physical robots or software agents (e.g. <ref> [2, 7, 10] </ref>. However, the motivational systems are generally very primitive. There are some attempts to describe complete human-like architectures (e.g. [14]) but implementations are usually lacking, partly because of the enormous complexity of the task (as Minsky comments in [17]).
Reference: 11. <author> A. Sloman I.P. Wright and L.P. Beaudoin. </author> <title> Towards a design-based analysis of emotional episodes, </title> <note> 1996(to appear). Available at URL ftp://ftp.cs.bham.ac.uk/pub/groups/cog affect in the file Wright Sloman Beaudoin grief.ps.Z. </note>
Reference-contexts: Figure 1 depicts approximately the type of architecture we have been exploring (described incrementally in <ref> [28, 19, 21, 5, 4, 25, 11] </ref>). At present we are primarily concerned with performance in simulated time, not real time. <p> Towards an Intelligent Agent Architecture before selection. The latter (which need not involve conscious processing) are resource-limited and may sometimes require both attention filters to protect them from disturbance and meta-management processes to regulate and direct them. This requires some sort of self-monitoring. (See <ref> [4, 11] </ref>). Reflexes (learnt or innate) bypass `normal' processing. The diagram should not be taken to imply any sharp division between processes concerned with perception or action and other cognitive processes [20]. <p> The internal `management' (and meta-management) processes involve a certain amount of (asynchronous) parallelism, but we wanted to show how resource limits restricting parallelism in high level processes can lead to emotional and other characteristically human states involving partial loss of control of attention and thought processes <ref> [18, 21, 22, 4, 11] </ref>. This requires an architecture combining a wide variety of types of mechanisms. Like the OZ project [3, 2] we are initially interested in `broad and shallow' architectures, combining many sorts of capabilities, where each capability is initially implemented in a shallow fashion.
Reference: 12. <institution> The KQML project is described in URL http://www.cs.umbc.edu/kqml. This WEB page also contains pointers to information on other languages, protocols, and agent frameworks, including AKL, Agent0, toolTalk, CORBA, etc. </institution>
Reference-contexts: The use of new Pop-11 macros or syntax words allows translation from another representation into the format used by Poprule-base, and this could be applied to ontologies created by others, e.g. in the KQML/KIF libraries <ref> [12] </ref>.
Reference: 13. <author> P. Maes. </author> <title> Modeling adaptive autonomous agents. </title> <journal> Artificial Life, </journal> <volume> 1(1) </volume> <pages> 135-162, </pages> <year> 1994. </year>
Reference-contexts: Conditions may include variables whose values (e.g. sensor values contrast <ref> [13] </ref>) are passed to the filter. This allows a single rule to perform a task that would otherwise require a complex set of `AND' and `OR' conditions.
Reference: 14. <author> M. L. Minsky. </author> <title> The Society of Mind. </title> <publisher> William Heinemann Ltd., </publisher> <address> London, </address> <year> 1987. </year>
Reference-contexts: There is now growing interest in agent architectures, and increasingly ambitious attempts to design complete agents, whether physical robots or software agents (e.g. [2, 7, 10]. However, the motivational systems are generally very primitive. There are some attempts to describe complete human-like architectures (e.g. <ref> [14] </ref>) but implementations are usually lacking, partly because of the enormous complexity of the task (as Minsky comments in [17]).
Reference: 15. <author> A. Newell. </author> <title> Unified Theories of Cognition. </title> <publisher> Harvard University Press, </publisher> <year> 1990. </year>
Reference-contexts: Thus different rulesets might be concerned with: interpreting low-level sensory data, reasoning, generating motivators in response to new beliefs, assessing the importance of motivators, planning, meta-management, etc. Rules can switch between databases, push them onto a stack, restore them, etc., as in SOAR <ref> [15] </ref>. Rules can also transfer control to a new ruleset. Rulesets may be stacked then restored. Each ruleset corresponds to a sub-mechanism or `context' in the agent.
Reference: 16. <author> R. Poli and M. Brayshaw. </author> <title> A hybrid trainable rule-based system. </title> <type> Technical Report CSRP-95-3, </type> <institution> School of Computer Science, The University of Birmingham, </institution> <month> March </month> <year> 1995. </year>
Reference-contexts: If `sub-symbolic' mechanisms are required, they can be invoked by appropriate rules, e.g. using FILTER conditions and SELECT actions, described in Appendix B (see also <ref> [16, 26] </ref>). The rules can also invoke Pop-11, and Pop-11 can invoke other Poplog languages or libraries, e.g. Prolog, theorem provers, planners. <p> Appendix B: Support for `hybrid' mechanisms in Poprulebase We have implemented and extended ideas from <ref> [16] </ref>, allowing a rule to contain a complex `filter' which operates simultaneously on a set of conditions, not all of which need be satisfied. The simplest format is: [FILTER BFP C1 C2 ... <p> This allows a single rule to perform a task that would otherwise require a complex set of `AND' and `OR' conditions. In some cases, the VFP or BFP in a filter condition may invoke a trainable neural net, programmed by being given examples ( <ref> [16] </ref>). The `select' action has the following format: [SELECT ?var A1 A2 ... Am] where var is a variable containing a vector of length m, derived from a VFP in one of the `filter' conditions of the rule.
Reference: 17. <author> D. Riecken(ed). </author> <title> Intelligent agents, 1994. </title> <journal> Special Issue of Communications of the ACM, </journal> <month> 37,7 July </month> <year> 1994. </year>
Reference-contexts: However, the motivational systems are generally very primitive. There are some attempts to describe complete human-like architectures (e.g. [14]) but implementations are usually lacking, partly because of the enormous complexity of the task (as Minsky comments in <ref> [17] </ref>). <p> `real' robot equipment is used, and as a result such work often oversimplifies some aspects of the task because of the difficulty of other aspects. (It is possible to hide `toy' problems under a pile of expensive equipment.) There are some attempts to design and implement more complete architectures (e.g. <ref> [9, 6, 17] </ref>) though these projects are still at a relatively early stage, and those involving complete physical robots include only a small subset of the motive management processes that interest us.
Reference: 18. <author> H. A. Simon. </author> <title> Motivational and emotional controls of cognition'. Reprinted in Models of Thought, </title> <publisher> Yale University Press, </publisher> <pages> 29-38, </pages> <year> 1979. </year>
Reference-contexts: The internal `management' (and meta-management) processes involve a certain amount of (asynchronous) parallelism, but we wanted to show how resource limits restricting parallelism in high level processes can lead to emotional and other characteristically human states involving partial loss of control of attention and thought processes <ref> [18, 21, 22, 4, 11] </ref>. This requires an architecture combining a wide variety of types of mechanisms. Like the OZ project [3, 2] we are initially interested in `broad and shallow' architectures, combining many sorts of capabilities, where each capability is initially implemented in a shallow fashion.
Reference: 19. <author> A. Sloman. </author> <title> Motives mechanisms and emotions'. </title> <journal> Emotion and Cognition, </journal> <volume> 1(3) </volume> <pages> 217-234, </pages> <year> 1987. </year> <note> Reprinted in M.A. </note> <editor> Boden (ed), </editor> <booktitle> The Philosophy of Artificial Intelligence, `Oxford Readings in Philosophy' Series, </booktitle> <publisher> Oxford University Press, </publisher> <pages> 231-247, </pages> <year> 1990. </year>
Reference-contexts: Figure 1 depicts approximately the type of architecture we have been exploring (described incrementally in <ref> [28, 19, 21, 5, 4, 25, 11] </ref>). At present we are primarily concerned with performance in simulated time, not real time.
Reference: 20. <author> A. Sloman. </author> <title> On designing a visual system (towards a gibsonian computational model of vision). </title> <journal> Journal of Experimental and Theoretical AI, </journal> <volume> 1(4) </volume> <pages> 289-337, </pages> <year> 1989. </year>
Reference-contexts: This requires some sort of self-monitoring. (See [4, 11]). Reflexes (learnt or innate) bypass `normal' processing. The diagram should not be taken to imply any sharp division between processes concerned with perception or action and other cognitive processes <ref> [20] </ref>.
Reference: 21. <author> A. Sloman. </author> <title> Prolegomena to a theory of communication and affect. </title> <editor> In A. Ortony, J. Slack, and O. Stock, editors, </editor> <booktitle> Communication from an Artificial Intelligence Perspective: Theoretical and Applied Issues, </booktitle> <pages> pages 229-260. </pages> <publisher> Springer, </publisher> <address> Heidelberg, Germany, </address> <year> 1992. </year>
Reference-contexts: Figure 1 depicts approximately the type of architecture we have been exploring (described incrementally in <ref> [28, 19, 21, 5, 4, 25, 11] </ref>). At present we are primarily concerned with performance in simulated time, not real time. <p> The internal `management' (and meta-management) processes involve a certain amount of (asynchronous) parallelism, but we wanted to show how resource limits restricting parallelism in high level processes can lead to emotional and other characteristically human states involving partial loss of control of attention and thought processes <ref> [18, 21, 22, 4, 11] </ref>. This requires an architecture combining a wide variety of types of mechanisms. Like the OZ project [3, 2] we are initially interested in `broad and shallow' architectures, combining many sorts of capabilities, where each capability is initially implemented in a shallow fashion.
Reference: 22. <author> A. Sloman. </author> <title> The mind as a control system. </title> <editor> In C. Hookway and D. Peterson, editors, </editor> <booktitle> Philosophy and the Cognitive Sciences, </booktitle> <pages> pages 69-110. </pages> <publisher> Cambridge University Press, </publisher> <year> 1993. </year>
Reference-contexts: The internal `management' (and meta-management) processes involve a certain amount of (asynchronous) parallelism, but we wanted to show how resource limits restricting parallelism in high level processes can lead to emotional and other characteristically human states involving partial loss of control of attention and thought processes <ref> [18, 21, 22, 4, 11] </ref>. This requires an architecture combining a wide variety of types of mechanisms. Like the OZ project [3, 2] we are initially interested in `broad and shallow' architectures, combining many sorts of capabilities, where each capability is initially implemented in a shallow fashion.
Reference: 23. <author> A. Sloman. </author> <title> Prospects for ai as the general science of intelligence. </title> <editor> In A.Sloman, D.Hogg, G.Humphreys, D. Partridge, and A. Ramsay, editors, </editor> <booktitle> Prospects for Artificial Intelligence, </booktitle> <pages> pages 1-10. </pages> <publisher> IOS Press, </publisher> <address> Amsterdam, </address> <year> 1993. </year>
Reference-contexts: We also wished to support evolutionary experiments, as described in Section 3.2. A generic toolkit is needed to support the exploration of alternative designs <ref> [23, 25] </ref>. We needed a toolkit providing the following features: Minimal ontological commitment: i.e. many kinds of objects with very different ar chitectures should be supported. External behaviour: which is detectable by or which affects other objects or agents, e.g. movement and communication. <p> We therefore provide a framework within which alternative architectures can easily be constructed and their capabilities explored and evaluated. Part of the task is to devise good evaluation criteria <ref> [23, 25] </ref>, e.g. performance criteria and cognitive modelling criteria. 5 Conclusion Our toolkit is very general, but not so general as to be completely useless: a frequent consequence of generality.
Reference: 24. <author> A. Sloman. </author> <title> Explorations in design space. </title> <booktitle> In Proceedings 11th European Conference on AI, </booktitle> <address> Amsterdam, </address> <year> 1994. </year>
Reference-contexts: Some of the active objects merely obey physical laws, whereas others, which we call agents take in and manipulate information and vary their behaviour as a result of processing information. The division between agents and non-agents is not very sharp <ref> [24, 25] </ref>. We are specially interested in agents that generate their own motivators. These are autonomous. Passive objects are objects which do not change their state spontaneously. Examples might be walls, ditches, ladders, roads.
Reference: 25. <author> A. Sloman. </author> <title> Exploring design space and niche space. </title> <booktitle> In Proceedings 5th Scandinavian Conference on AI, </booktitle> <address> Trondheim, 1995. </address> <publisher> IOS Press. </publisher>
Reference-contexts: Figure 1 depicts approximately the type of architecture we have been exploring (described incrementally in <ref> [28, 19, 21, 5, 4, 25, 11] </ref>). At present we are primarily concerned with performance in simulated time, not real time. <p> We also wished to support evolutionary experiments, as described in Section 3.2. A generic toolkit is needed to support the exploration of alternative designs <ref> [23, 25] </ref>. We needed a toolkit providing the following features: Minimal ontological commitment: i.e. many kinds of objects with very different ar chitectures should be supported. External behaviour: which is detectable by or which affects other objects or agents, e.g. movement and communication. <p> Some of the active objects merely obey physical laws, whereas others, which we call agents take in and manipulate information and vary their behaviour as a result of processing information. The division between agents and non-agents is not very sharp <ref> [24, 25] </ref>. We are specially interested in agents that generate their own motivators. These are autonomous. Passive objects are objects which do not change their state spontaneously. Examples might be walls, ditches, ladders, roads. <p> We therefore provide a framework within which alternative architectures can easily be constructed and their capabilities explored and evaluated. Part of the task is to devise good evaluation criteria <ref> [23, 25] </ref>, e.g. performance criteria and cognitive modelling criteria. 5 Conclusion Our toolkit is very general, but not so general as to be completely useless: a frequent consequence of generality.
Reference: 26. <author> A. Sloman. </author> <title> Filtering of rules in lib poprulebase, </title> <note> 1995. Available at URL ftp://ftp.cs.bham.ac.uk/pub/dist/poplog/prb/help/pop filter. </note>
Reference-contexts: If `sub-symbolic' mechanisms are required, they can be invoked by appropriate rules, e.g. using FILTER conditions and SELECT actions, described in Appendix B (see also <ref> [16, 26] </ref>). The rules can also invoke Pop-11, and Pop-11 can invoke other Poplog languages or libraries, e.g. Prolog, theorem provers, planners.
Reference: 27. <author> A. Sloman. </author> <note> Poprulebase help file, 1995. Available at URL ftp://ftp.cs.bham.ac.uk/pub/dist/poplog/prb/help/poprulebase. </note>
Reference-contexts: A simple object has no parts that are objects managed by the scheduler but may nevertheless have a complex internal architecture, involving several interacting subsystems. e.g. an intelligent agent. 2 The SIM AGENT toolkit The toolkit is implemented in Poplog Pop-11 [1], using our Poprulebase <ref> [27] </ref> library, and the Objectclass package designed by Steve Knight at Hewlett Packard Laboratories, which extends Pop-11 with CLOS-like object oriented facilities, including classes, inheritance and generic methods that can be redefined for specific user-defined classes of objects or agents. <p> The toolkit allows users to explore different forms of internal processing, but provides special support for agents whose internal processing can be implemented using interacting collections of condition-action rules, communicating concurrently via a collection of databases, including rules that invoke non-symbolic `low level' mechanisms. This uses Poprulebase <ref> [27] </ref>, a forward-chaining production system which provides many of the features associated with conventional rule interpreters as well as the ability to drop into Pop-11 where appropriate. In particular: Each agent class has an associated collection of rulesets.
Reference: 28. <author> A. Sloman and M. Croucher. </author> <title> Why robots will have emotions. </title> <booktitle> In Proc 7th Int. Joint Conf. on AI, </booktitle> <address> Vancouver, </address> <year> 1981. </year>
Reference-contexts: Figure 1 depicts approximately the type of architecture we have been exploring (described incrementally in <ref> [28, 19, 21, 5, 4, 25, 11] </ref>). At present we are primarily concerned with performance in simulated time, not real time.
Reference: 29. <author> I.P. Wright. </author> <title> A summary of the attention and affect project, 1994. Available at URL ftp://ftp.cs.bham.ac.uk/pub/groups/cog affect in the file Ian.Wright Project Summary.ps.Z. This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: Increases in processor power and the use of multi-processor hosts will compensate further. 6 Acknowledgements The work reported in this paper arises out of collaborative research involving Luc Beau-doin, Darryl Davis, Glyn Humphreys, Ian Wright, and other members of the Cognition and Affect project at the University of Birmingham <ref> [29] </ref>. Jeremy Baxter and Richard Hepplewhite (at DRA Malvern) are users of the toolkit and made several suggestions for improvement. This research is funded by the Renaissance Trust, the UK Joint Council initiative in HCI and Cognitive Science, and DRA Malvern.
References-found: 29

