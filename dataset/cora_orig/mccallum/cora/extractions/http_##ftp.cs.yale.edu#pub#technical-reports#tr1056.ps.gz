URL: http://ftp.cs.yale.edu/pub/technical-reports/tr1056.ps.gz
Refering-URL: http://ftp.cs.yale.edu/pub/technical-reports/
Root-URL: http://www.cs.yale.edu
Title: Dynamic Fault Diagnosis  
Author: William Hurwood 
Date: December 1994  
Affiliation: Yale University Department of Computer Science  
Pubnum: YALEU/DCS/TR-1056  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Richard Beigel, William Hurwood, and Nabil Kahale. </author> <title> Fault diagnosis in a flash. </title> <type> Technical Report 1051, </type> <institution> Yale University, </institution> <year> 1994. </year>
Reference-contexts: This model was used in [6, 8, 2, 7, 3] in which the upper bound on the number of rounds of testing as a function of n was eventually reduced from a linear bound, through logarithmic and doubly-logarithmic bounds to a large constant bound. Recent work in <ref> [1] </ref> has reduced the upper bound to 10 rounds. [1] also shows that at least 5 rounds are needed to carry out complete diagnosis in the most general case. In this paper we will consider a natural extension of this model. <p> Recent work in <ref> [1] </ref> has reduced the upper bound to 10 rounds. [1] also shows that at least 5 rounds are needed to carry out complete diagnosis in the most general case. In this paper we will consider a natural extension of this model. We will remove the requirement that every processor have a fixed status throughout the testing procedure.
Reference: [2] <author> Richard Beigel, S. Rao Kosaraju, and Gregory F. Sullivan. </author> <title> Locating faults in a constant number of testing rounds. </title> <booktitle> In Proceedings of the 1st Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <pages> pages 189-198, </pages> <year> 1989. </year>
Reference-contexts: Nakajima [10] introduced adaptive tests, where the tests performed in later rounds were chosen after considering the results of the earlier rounds. This naturally led to asking how many rounds of adaptive tests are needed to carry out a complete diagnosis. This model was used in <ref> [6, 8, 2, 7, 3] </ref> in which the upper bound on the number of rounds of testing as a function of n was eventually reduced from a linear bound, through logarithmic and doubly-logarithmic bounds to a large constant bound.
Reference: [3] <author> Richard Beigel, Grigorii Margulis, and Daniel A. Spielman. </author> <title> Fault diagnosis in a small constant number of parallel testing rounds. </title> <booktitle> In Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, </booktitle> <year> 1993. </year>
Reference-contexts: Nakajima [10] introduced adaptive tests, where the tests performed in later rounds were chosen after considering the results of the earlier rounds. This naturally led to asking how many rounds of adaptive tests are needed to carry out a complete diagnosis. This model was used in <ref> [6, 8, 2, 7, 3] </ref> in which the upper bound on the number of rounds of testing as a function of n was eventually reduced from a linear bound, through logarithmic and doubly-logarithmic bounds to a large constant bound.
Reference: [4] <author> Ronald P. Bianchini, Jr. and Richard Buskens. </author> <title> An adaptive distributed system level-diagnosis algorithm and its implementation. </title> <booktitle> In Proceedings of 21st Int. Symp. on Fault Tolerant Computing, </booktitle> <pages> pages 222-229, </pages> <year> 1991. </year> <month> 13 </month>
Reference-contexts: This problem has led to the development of system level fault diagnosis. Each of n atomic processing units is assumed to be able to test every other unit. But when a faulty unit carries out a test the result is unreliable. Such testing protocols have been usefully implemented <ref> [5, 4] </ref>. Preparata, Metze and Chien first proposed a fault diagnosis model in [11]. They suggested viewing the system as a graph with the processors as nodes and tests as edges. <p> In this paper we will consider a natural extension of this model. We will remove the requirement that every processor have a fixed status throughout the testing procedure. Such dynamic models have been considered before <ref> [9, 5, 4] </ref>. In these papers the authors presented self-stabilizing distributed algorithms: if the processors stopped changing status then the remaining good processors would eventually discover the status of all the processors in the system. We will consider a different model, the ongoing fault diagnosis model defined in Section 2.
Reference: [5] <author> Ronald P. Bianchini, Jr., K. Goodwin, and D. S. Nydick. </author> <title> Practical application and implementation of distributed system-level diagnosis theory. </title> <booktitle> In Proceedings of 20th Int. Symp. on Fault Tolerant Computing, </booktitle> <pages> pages 332-339, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: This problem has led to the development of system level fault diagnosis. Each of n atomic processing units is assumed to be able to test every other unit. But when a faulty unit carries out a test the result is unreliable. Such testing protocols have been usefully implemented <ref> [5, 4] </ref>. Preparata, Metze and Chien first proposed a fault diagnosis model in [11]. They suggested viewing the system as a graph with the processors as nodes and tests as edges. <p> In this paper we will consider a natural extension of this model. We will remove the requirement that every processor have a fixed status throughout the testing procedure. Such dynamic models have been considered before <ref> [9, 5, 4] </ref>. In these papers the authors presented self-stabilizing distributed algorithms: if the processors stopped changing status then the remaining good processors would eventually discover the status of all the processors in the system. We will consider a different model, the ongoing fault diagnosis model defined in Section 2.
Reference: [6] <author> S. Louis Hakimi and Kazuo Nakajima. </author> <title> On adaptive system diagnosis. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33(3):234-240, </volume> <month> March </month> <year> 1984. </year>
Reference-contexts: Nakajima [10] introduced adaptive tests, where the tests performed in later rounds were chosen after considering the results of the earlier rounds. This naturally led to asking how many rounds of adaptive tests are needed to carry out a complete diagnosis. This model was used in <ref> [6, 8, 2, 7, 3] </ref> in which the upper bound on the number of rounds of testing as a function of n was eventually reduced from a linear bound, through logarithmic and doubly-logarithmic bounds to a large constant bound.
Reference: [7] <author> S. Louis Hakimi, M. Otsuka, Edward F. Schmeichel, and Gregory F. Sullivan. </author> <title> A parallel fault identification algorithm. </title> <journal> Journal of Algorithms, </journal> <volume> 11 </volume> <pages> 231-241, </pages> <year> 1990. </year>
Reference-contexts: Nakajima [10] introduced adaptive tests, where the tests performed in later rounds were chosen after considering the results of the earlier rounds. This naturally led to asking how many rounds of adaptive tests are needed to carry out a complete diagnosis. This model was used in <ref> [6, 8, 2, 7, 3] </ref> in which the upper bound on the number of rounds of testing as a function of n was eventually reduced from a linear bound, through logarithmic and doubly-logarithmic bounds to a large constant bound.
Reference: [8] <author> S. Louis Hakimi and Edward F. Schmeichel. </author> <title> An adaptive algorithm for system level diagnosis. </title> <journal> Journal of Algorithms, </journal> <volume> 5 </volume> <pages> 526-530, </pages> <year> 1984. </year>
Reference-contexts: Nakajima [10] introduced adaptive tests, where the tests performed in later rounds were chosen after considering the results of the earlier rounds. This naturally led to asking how many rounds of adaptive tests are needed to carry out a complete diagnosis. This model was used in <ref> [6, 8, 2, 7, 3] </ref> in which the upper bound on the number of rounds of testing as a function of n was eventually reduced from a linear bound, through logarithmic and doubly-logarithmic bounds to a large constant bound.
Reference: [9] <author> S. H. Hosseini, Jon G. Kuhl, and Sudhakar M. Reddy. </author> <title> A diagnosis algorithm for distributed computing systems with dynamic failure and repair. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-33(3):223-233, </volume> <month> March </month> <year> 1984. </year>
Reference-contexts: In this paper we will consider a natural extension of this model. We will remove the requirement that every processor have a fixed status throughout the testing procedure. Such dynamic models have been considered before <ref> [9, 5, 4] </ref>. In these papers the authors presented self-stabilizing distributed algorithms: if the processors stopped changing status then the remaining good processors would eventually discover the status of all the processors in the system. We will consider a different model, the ongoing fault diagnosis model defined in Section 2.
Reference: [10] <author> Kazuo Nakajima. </author> <title> A new approach to system diagnosis. </title> <booktitle> In Proc. 19th Annu. Allerton Conf. Commun. Contr. and Comput., </booktitle> <pages> pages 697-706, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: Such testing protocols have been usefully implemented [5, 4]. Preparata, Metze and Chien first proposed a fault diagnosis model in [11]. They suggested viewing the system as a graph with the processors as nodes and tests as edges. Nakajima <ref> [10] </ref> introduced adaptive tests, where the tests performed in later rounds were chosen after considering the results of the earlier rounds. This naturally led to asking how many rounds of adaptive tests are needed to carry out a complete diagnosis.
Reference: [11] <author> Franco Preparata, Gernot Metze, and Robert Chien. </author> <title> On the connection assignment problem of diagnosable systems. </title> <journal> IEEE Transactions on Electronic Computers, </journal> <volume> EC-16(6):848-853, </volume> <month> December </month> <year> 1967. </year> <month> 14 </month>
Reference-contexts: Each of n atomic processing units is assumed to be able to test every other unit. But when a faulty unit carries out a test the result is unreliable. Such testing protocols have been usefully implemented [5, 4]. Preparata, Metze and Chien first proposed a fault diagnosis model in <ref> [11] </ref>. They suggested viewing the system as a graph with the processors as nodes and tests as edges. Nakajima [10] introduced adaptive tests, where the tests performed in later rounds were chosen after considering the results of the earlier rounds.
References-found: 11

