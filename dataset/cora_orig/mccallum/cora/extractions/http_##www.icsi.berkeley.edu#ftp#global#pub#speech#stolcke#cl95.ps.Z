URL: http://www.icsi.berkeley.edu/ftp/global/pub/speech/stolcke/cl95.ps.Z
Refering-URL: http://www.icsi.berkeley.edu/ftp/global/pub/speech/stolcke/
Root-URL: http://www.icsi.berkeley.edu
Title: An Efficient Probabilistic Context-Free Parsing Algorithm that Computes Prefix Probabilities  
Author: Andreas Stolcke 
Affiliation: University of California at Berkeley and International Computer Science Institute  
Abstract: We describe an extension of Earley's parser for stochastic context-free grammars that computes the following quantities given a stochastic context-free grammar and an input string: a) probabilities of successive prefixes being generated by the grammar; b) probabilities of substrings being generated by the nonterminals, including the entire string being generated by the grammar; c) most likely (Viterbi) parse of the string; d) posterior expected number of applications of each grammar production, as required for reestimating rule probabilities. Probabilities (a) and (b) are computed incrementally in a single left-to-right pass over the input. Our algorithm compares favorably to standard bottom-up parsing methods for SCFGs in that it works efficiently on sparse grammars by making use of Earley's top-down control structure. It can process any context-free rule format without conversion to some normal form, and combines computations for (a) through (d) in a single algorithm. Finally, the algorithm has simple extensions for processing partially bracketed inputs, and for finding partial parses and their likelihoods on ungrammatical inputs. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Alfred V. Aho and Jeffrey D. Ullman. </author> <year> 1972. </year> <title> The Theory of Parsing, Translation, and Compiling. Volume1: Parsing. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J. </address>
Reference: <author> Lalit R. Bahl, Frederick Jelinek, </author> <title> and Robert L. </title>
Reference: <author> Mercer. </author> <year> 1983. </year> <title> A maximum likelihood approach to continuous speech recognition. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 5(2) </volume> <pages> 179-190. </pages>
Reference: <author> James K. Baker. </author> <year> 1979. </year> <title> Trainable grammars for speech recognition. </title> <editor> In Jared J. Wolf and Dennis H. Klatt, editors, </editor> <booktitle> Speech Communication Papers for the 97th Meeting of the Acoustical Society of America, </booktitle> <pages> pages 547-550, </pages> <publisher> MIT, </publisher> <address> Cambridge, Mass. </address>
Reference: <author> Leonard E. Baum, Ted Petrie, George Soules, and Norman Weiss. </author> <year> 1970. </year> <title> A maximization technique occuring in the statistical analysis of probabilistic functions in Markov chains. </title> <journal> The Annals of Mathematical Statistics, </journal> <volume> 41(1) </volume> <pages> 164-171. </pages>
Reference: <author> Taylor L. Booth and Richard A. Thompson. </author> <year> 1973. </year> <title> Applying probability measures to abstract languages. </title> <journal> IEEE Transactions on Computers, C-22(5):442-450. </journal>
Reference: <author> Ted Briscoe and John Carroll. </author> <year> 1993. </year> <title> Generalized probabilistic LR parsing of natural language (corpora) with unification-based grammars. </title> <journal> Computational Linguistics, </journal> <volume> 19(1) </volume> <pages> 25-59. </pages>
Reference: <author> F. Casacuberta and E. Vidal. </author> <year> 1988. </year> <title> A parsing algorithm for weighted grammars and substring recognition. </title> <editor> In Gabriel Fer-rat e, Theo Pavlidis, Alberto Sanfeliu, and Horst Bunke, editors, </editor> <title> Syntactic and Structural Pattern Recognition, </title> <booktitle> volume F45 of NATO ASI Series, </booktitle> <pages> pages 51-67. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin. </address>
Reference: <author> Anna Corazza, Renato De Mori, Roberto Gret-ter, and Giorgio Satta. </author> <year> 1991. </year> <title> Computation of probabilities for an island-driven parser. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9) </volume> <pages> 936-950. </pages>
Reference: <author> A. P. Dempster, N. M. Laird, and D. B. Rubin. </author> <year> 1977. </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, Series B, </journal> <volume> 34 </volume> <month> 1-38. </month> <title> References References Jay Earley. 1970. An efficient context-free parsing algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 6(8) </volume> <pages> 451-455. </pages>
Reference-contexts: :Y ) as well as T 0 = Viterbi-parse (i : j Y ! -:) Adjoin T 0 to T as the right-most child at the root, and return T . 5.2 Rule probability estimation The rule probabilities in a SCFG can be iteratively estimated using the EM (Expectation-Maximization) algorithm <ref> (Dempster et al., 1977) </ref>.
Reference: <author> T. Fujisaki, F. Jelinek, J. Cocke, E. Black, and T. Nishino. </author> <year> 1991. </year> <title> A probabilistic parsing method for sentence disambiguation. </title> <editor> In Masaru Tomita, editor, </editor> <booktitle> Current Issues in Parsing Technology, chapter 10, </booktitle> <pages> pages 139-152. </pages> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston. </address>
Reference: <author> Susan L. Graham, Michael A. Harrison, and Walter L. Ruzzo. </author> <year> 1980. </year> <title> An improved context-free recognizer. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 2(3) </volume> <pages> 415-462. </pages>
Reference: <author> Frederick Jelinek and John D. Lafferty. </author> <year> 1991. </year> <title> Computation of the probability of initial substring generation by stochastic context-free grammars. </title> <journal> Computational Linguistics, </journal> <volume> 17(3) </volume> <pages> 315-323. </pages>
Reference: <author> Frederick Jelinek, John D. Lafferty, and Robert L. Mercer. </author> <year> 1992. </year> <title> Basic methods of probabilistic context free grammars. </title> <editor> In Pietro Laface and Renato De Mori, editors, </editor> <booktitle> Speech Recognition and Understanding. Recent Advances, Trends, and Applications, volume F75 of NATO ASI Series, </booktitle> <pages> pages 345-360. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin. </address> <booktitle> Proceedings of the NATO Advanced Study Institute, </booktitle> <address> Cetraro, Italy, </address> <month> July </month> <year> 1990. </year>
Reference: <author> Frederick Jelinek. </author> <year> 1985. </year> <title> Markov source modeling of text generation. </title> <editor> In J. K. Skwirzyn-ski, editor, </editor> <booktitle> The Impact of Processing Techniques on Communications, volume E91 of NATO ASI Series, </booktitle> <pages> pages 569-598. </pages> <publisher> Nijhoff, </publisher> <address> Dordrecht. </address> <booktitle> Proceedings of the NATO Advanced Study Institute, </booktitle> <address> Bonas, France, </address> <year> 1983. </year>
Reference: <author> Mark A. Jones and Jason M. Eisner. </author> <year> 1992. </year> <title> A probabilistic parser and its applications. </title> <booktitle> In AAAI Workshop on Statistically-Based NLP Techniques, </booktitle> <pages> pages 20-27, </pages> <address> San Jose, CA. </address>
Reference: <author> Daniel Jurafsky, Chuck Wooters, Gary Tajch-man, Jonathan Segal, Andreas Stolcke, Eric Fosler, and Nelson Morgan. </author> <year> 1994. </year> <title> The Berkeley Restaurant Project. </title> <booktitle> In Proceedings International Conference on Spoken Language Processing, </booktitle> <volume> volume 4, </volume> <pages> pages 2139-2142, </pages> <address> Yokohama. </address>
Reference: <author> Daniel Jurafsky, Chuck Wooters, Jonathan Se-gal, Andreas Stolcke, Eric Fosler, Gary Tajchman, and Nelson Morgan. </author> <year> 1995. </year> <title> Using a stochastic context-free grammar as a language model for speech recognition. </title> <booktitle> In Proceedings IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <pages> pages 189-192. </pages>
Reference: <author> Julian Kupiec. </author> <year> 1992. </year> <title> Hidden Markov estimation for unrestricted stochastic context-free grammars. </title> <booktitle> In Proceedings IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> pages 177-180, </pages> <address> San Francisco. </address>
Reference: <author> K. Lari and S. J. Young. </author> <year> 1990. </year> <title> The estimation of stochastic context-free grammars using the Inside-Outside algorithm. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 4 </volume> <pages> 35-56. </pages>
Reference-contexts: Unfortunately, it seems that in the case of unconstrained SCFG estimation local maxima present a very real problem, and make success dependent on chance and initial conditions <ref> (Lari and Young, 1990) </ref>. Pereira and Schabes (1992) showed that partially bracketed input samples can alleviate the problem in certain cases. The bracketing information constrains the parse of the inputs, and therefore the parameter estimates, steering it clear from some of the suboptimal solutions that could otherwise be found.
Reference: <author> K. Lari and S. J. Young. </author> <year> 1991. </year> <title> Applications of stochastic context-free grammars using the Inside-Outside algorithm. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 5 </volume> <pages> 237-257. </pages>
Reference: <author> David M. Magerman and Mitchell P. Mar-cus. </author> <year> 1991. </year> <title> Pearl: A probabilistic chart parser. </title> <booktitle> In Proceedings of the 2nd International Workshop on Parsing Technologies, </booktitle> <pages> pages 193-199, </pages> <address> Cancun, Mexico. </address>
Reference: <author> David M. Magerman and Carl Weir. </author> <year> 1992. </year> <title> Efficiency, robustness and accuracy in Picky chart parsing. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 40-47, </pages> <institution> University of Delaware, Newark, Delaware. </institution>
Reference: <author> Sei-ichi Nakagawa. </author> <year> 1987. </year> <title> Spoken sentence recognition by time-synchronous parsing algorithm of context-free grammar. </title> <booktitle> In Proceedings IEEE Conference on Acoustics, Speech and Signal Processing, </booktitle> <volume> volume 2, </volume> <pages> pages 829-832, </pages> <address> Dallas, Texas. </address>
Reference: <author> Hermann Ney. </author> <year> 1992. </year> <title> Stochastic grammars and pattern recognition. </title> <editor> In Pietro Laface and Renato De Mori, editors, </editor> <booktitle> Speech Recognition and Understanding. Recent Advances, Trends, and Applications, volume F75 of NATO ASI Series, </booktitle> <pages> pages 319-344. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin. </address> <booktitle> Proceedings of the NATO Advanced Study Institute, </booktitle> <address> Ce-traro, Italy, </address> <month> July </month> <year> 1990. </year> <title> Annedore P aseler. 1988. Modification of Ear-ley's algorithm for speech recognition. </title> <editor> In H. Niemann, M. Lang, and G. Sagerer, editors, </editor> <booktitle> Recent Advances in Speech Understanding and Dialog Systems, volume F46 of NATO ASI Series, </booktitle> <pages> pages 466-472. </pages> <publisher> Springer Verlag, </publisher> <address> Berlin. </address> <booktitle> Proceedings of the NATO Advanced Study Institute, </booktitle> <address> Bad Windsheim, Germany, </address> <month> July </month> <year> 1987. </year>
Reference: <author> Fernando Pereira and Yves Schabes. </author> <year> 1992. </year> <title> Inside-outside reestimation from partially bracketed corpora. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 128-135, </pages> <institution> University of Delaware, Newark, Delaware. </institution>
Reference: <author> Fernando C. N. Pereira and Stuart M. Shieber. </author> <year> 1987. </year> <title> Prolog and Natural-Language Analysis. </title> <booktitle> Number 10 in CSLI Lecture Notes 35 Computational Linguistics Volume 21, Number 2 Series. Center for the Study of Language and Information, </booktitle> <address> Stanford, CA. </address>
Reference: <author> L. R. Rabiner and B. H. Juang. </author> <year> 1986. </year> <title> An introduction to hidden Markov models. </title> <journal> IEEE ASSP Magazine, </journal> <volume> 3(1) </volume> <pages> 4-16. </pages>
Reference-contexts: This can be accomplished by attaching two probabilistic quantities to each Earley state, as follows. The terminology is derived from analogous or similar quantities commonly used in the literature on Hidden Markov Models (HMMs) <ref> (Rabiner and Juang, 1986) </ref> and in Baker (1979). <p> Both the definition of Viterbi parse, and its computation are straightforward generalizations of the corresponding notion for Hidden Markov Models <ref> (Rabiner and Juang, 1986) </ref>, where one computes the Viterbi path (state sequence) through an HMM. Precisely the same approach can be used in the Earley parser, using the fact that each derivation corresponds to a path. The standard computational technique for Viterbi parses is applicable here.
Reference: <author> Yves Schabes. </author> <year> 1991. </year> <title> An inside-outside algorithm for estimating the parameters of a hidden stochastic context-free grammar based on Earley's algorithm. Unpublished mss. </title> <booktitle> Presented at the Second Workshop on Mathematics of Language, </booktitle> <address> Tarritown, N.Y., </address> <month> May </month> <year> 1991. </year>
Reference: <author> Andreas Stolcke and Jonathan Segal. </author> <year> 1994. </year> <title> Precise n-gram probabilities from stochastic context-free grammars. </title> <booktitle> In Proceedings of the 31th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 74-79, </pages> <address> New Mexico State University, Las Cruces, NM. </address>
Reference: <author> Andreas Stolcke. </author> <year> 1993. </year> <title> An efficient probabilistic context-free parsing algorithm that computes prefix probabilities. </title> <type> Technical Report TR-93-065, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA. </address> <month> Revised November </month> <year> 1994. </year>
Reference: <author> Masaru Tomita. </author> <year> 1986. </year> <title> Efficient Parsing for Natural Language. </title> <publisher> Kluwer Academic Publishers, </publisher> <address> Boston. </address>
Reference: <author> J. H. Wright. </author> <year> 1990. </year> <title> LR parsing of probabilistic grammars with input uncertainty for speech recognition. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 4 </volume> <pages> 297-323. 36 </pages>
Reference-contexts: Generalized LR parsing is an extension that allows parallel tracking of multiple state transitions and stack actions by using a graph-structured stack (Tomita, 1986). Probabilistic LR parsing <ref> (Wright, 1990) </ref> is based on LR items augmented with certain conditional probabilities.
References-found: 33

