URL: http://www.cs.colostate.edu/~ftppub/TechReports/1997/tr97-108.ps.Z
Refering-URL: http://www.cs.colostate.edu/~ftppub/
Root-URL: 
Email: annavara@eecs.umich.edu najjar@cs.colostate.edu  roh@mcs.anl.gov  
Phone: Phone: (970) 491-5792 Fax: (970) 491-2466  
Title: Experimental Evaluation of Blocking and Non-Blocking Multithreaded Code Execution  
Author: Murali Annavaram Walid A. Najjar Lucas Roh 
Web: WWW: http://www.cs.colostate.edu  
Address: Ann Arbor, MI 48105 Fort Collins, CO 80523  Argonne, IL 60439  Fort Collins, CO 80523-1873  
Affiliation: Computer Science  Dept. of EECS Dept. of Computer Science University of Michigan Colorado State University  Mathematics and Computer Science Division Argonne National Laboratory  Computer Science Department Colorado State University  
Pubnum: Technical Report  Technical Report CS-97-108  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> A. Agarwal, J. Hennessy, and M. Horowitz. </author> <title> Cache performance of operating systems and multiprogramming. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 6 </volume> <pages> 393-431, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: The details of various issues in cache designs are treated in [18]. Several designs have tried to combine the advantages of direct-mapped caches with those of set-associative caches, these designs include the victim-cache [21], MRU cache [38], hash-rehash cache <ref> [1] </ref>, and half-half cache [42]. In general, these schemes split the cache into two parts: one is direct mapped, while the other is set associative. The idea is to simultaneously send the desired address to both parts of the cache and to assume that the direct-mapped portion contains the data.
Reference: [2] <author> R. Alverson, D. Callahan, D. Cummings, B. Koblenz, A. Portfield, and B. Smith. </author> <title> The Tera computer system. </title> <booktitle> In Int. Conf. on Supercomputing, </booktitle> <pages> pages 1-6. </pages> <publisher> ACM Press, </publisher> <year> 1990. </year>
Reference-contexts: In designs closer to the von Neumann model, threads tend to become larger, and data structure locality can be better exploited. Examples of these designs include HEP [37], Tera MTA <ref> [2] </ref>, J-Machine [10], and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC [30], *T [31], EM-4 [36] and the EARTH project [19]. <p> In [41] Tekkath and Eggers show that a minimal amount of contention misses occur due to inter thread communication. Therefore thread co-placement strategies designed to enhance inter-thread locality and reduce cache misses have minimal effects. Among the proposed multithreaded architectures that are being developed, the Tera MTA <ref> [2] </ref> does not have a cache memory. The M-Machine [14] does not have a proper data cache but uses the local memory to cache remote data. This caching mechanism is also supported in the local TLB providing hardware support for the coherence mechanism at the block level (8 word granularity).
Reference: [3] <author> B. S. Ang, Arvind, and D. Chiou. </author> <title> StarT the Next Generation: Integrating Global Caches and Dataflow Architecture. </title> <type> Technical Report 354, LCS, </type> <institution> MIT, </institution> <month> August </month> <year> 1994. </year>
Reference-contexts: Frames are of variable size and contiguously allocated in the virtual address space. The size of a frame is determined based on the maximum number of data values associated with the code-block. The frame model is used in several multithreaded machines (e.g., TAM [8], StarT-NG <ref> [3] </ref>, and the EM-4 and EM-X [24]). When an instance of a particular code-block is invoked, a frame is first allocated in a given processor's frame store. All the tokens generated for that code-block instance are stored in that frame. <p> The M-Machine [14] does not have a proper data cache but uses the local memory to cache remote data. This caching mechanism is also supported in the local TLB providing hardware support for the coherence mechanism at the block level (8 word granularity). The *T-NG <ref> [3] </ref> uses coherent caches for global shared memory. It also retains the message passing ability of the *T machine. The coherency is implemented by using a directory based coherency scheme.
Reference: [4] <author> G.D. Benson and R.A. Olson. </author> <title> A portable run-time for the SR concurrent programming language. </title> <booktitle> In Proc. Workshop on Run-Time Systems for Parallel Programming, </booktitle> <year> 1997. </year>
Reference: [5] <author> D. C. Cann. </author> <title> Compilation techniques for high performance applicative computation. </title> <type> Technical Report CS-89-108, </type> <institution> Colorado State University, </institution> <year> 1989. </year>
Reference-contexts: Phase 1: The first phase of the code generation is the same for both the blocking and the non blocking models. This phase involves compiling the Sisal programs to an intermediate format, called IF2, using the OSC <ref> [5] </ref> compiler. IF2 is a block structured, acyclic data 3 dependence graph that allows operations that explicitly allocate and manipulate memory in a machine independent way. IF2 also makes certain assumptions about the allocation of data structures.
Reference: [6] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Implementation and performance of munin. </title> <booktitle> In Proc. of 13th ACM Symp. on Operating Systems, </booktitle> <pages> pages 152-164, </pages> <month> October </month> <year> 1991. </year>
Reference: [7] <author> D. E. Culler. </author> <title> Managing parallelism and resources in scientific dataflow program. </title> <type> PhD thesis, </type> <institution> MIT, </institution> <month> June </month> <year> 1989. </year>
Reference-contexts: Cache designs in a dataflow model is discussed in [39] for DFM-II [40]. This model is designed for a fine-grained dataflow machine and must therefore take into account the explosion of parallelism that is typical in these machines <ref> [7] </ref>. The model is evaluated by using a relatively small set of hand-coded benchmarks. The caching mechanism attempts to preserve the working set of the program in the cache. Compulsory misses form most of the misses in the caches for multithreaded architectures.
Reference: [8] <author> D. E. Culler, A. Sah, K. E. Schauser, T. von Eicken, and J. Wawrzynek. </author> <title> Fine-grain parallelism with minimal hardware support: A compiler-controlled threaded abstract machine. </title> <booktitle> In Proc. Int. Conf. on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 164-175, </pages> <year> 1991. </year>
Reference-contexts: Examples are Monsoon [32, 33], P-RISC [30], *T [31], EM-4 [36] and the EARTH project [19]. The Hybrid Architecture (IHA), proposed by Iannucci [20] extends the von Neumann model with dataflow features to perform synchronizations. The Threaded Abstract Machine (TAM) <ref> [8] </ref> is a software implemented multithreaded model that has been ported to a number of platforms, such as the TMC CM-5 and the Cray T3D. <p> Frames are of variable size and contiguously allocated in the virtual address space. The size of a frame is determined based on the maximum number of data values associated with the code-block. The frame model is used in several multithreaded machines (e.g., TAM <ref> [8] </ref>, StarT-NG [3], and the EM-4 and EM-X [24]). When an instance of a particular code-block is invoked, a frame is first allocated in a given processor's frame store. All the tokens generated for that code-block instance are stored in that frame.
Reference: [9] <author> D. E. Culler, K. E. Schauser, and T. von Eicken. </author> <title> Two fundamental limits on dataflow multiprocessing. </title> <editor> In Cosnard, Ebcioglu, and Gaudiot, editors, </editor> <booktitle> Proc. IFIP WG 10.3 Conf. on Architecture and Compilation Techniques for Medium and Fine Grain Parallelism, </booktitle> <address> Orlando, FL, 1993. </address> <publisher> North-Holland. </publisher>
Reference-contexts: The slope is higher than that of the non blocking model. Since the miss rates are higher for the blocking model, the miss penalties affect the execution time more severely than the non blocking model. 6 Related Work Culler et al. <ref> [9] </ref> demonstrates that the performance of the storage hierarchy to an extent limits the amount of multithreading within a processor, thus limiting the latency that can be tolerated.
Reference: [10] <author> W. J. Dally, J. Fiske, J. Keen, R. Lethin, M. Noakes, P. Nuth, R. Davison, and G. Fyler. </author> <title> The message-driven processor: A multicomputer processing node with efficient mechanisms. </title> <journal> IEEE Micro, </journal> <volume> 12(2) </volume> <pages> 23-39, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: In designs closer to the von Neumann model, threads tend to become larger, and data structure locality can be better exploited. Examples of these designs include HEP [37], Tera MTA [2], J-Machine <ref> [10] </ref>, and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC [30], *T [31], EM-4 [36] and the EARTH project [19].
Reference: [11] <author> D.L. Eager and J. Zahorjan. Chores: </author> <title> Enhanced run-time support for shared memory parallel computing. </title> <journal> ACM Trans. on Computer Systems, </journal> <volume> 11(1) </volume> <pages> 1-32, </pages> <month> February </month> <year> 1993. </year>
Reference: [12] <author> D.R. Engler, G.R. Andrews, and D.K. Lowenthal. Filaments: </author> <title> Efficient support for fine-grain parallelism. </title> <type> Technical Report TR 93-13, </type> <institution> Dept. of Computer Science, University of Arizona, </institution> <month> April </month> <year> 1993. </year>
Reference: [13] <author> E. Felton and D. McNamee. </author> <title> Improving the performance of message-passing applications by multithreading. </title> <booktitle> In Scalable High-Performance Computing Conf., </booktitle> <pages> pages 84-89, </pages> <month> April </month> <year> 1992. </year>
Reference: [14] <author> M. Fillo, S. W. Keckler, W. J. Dally, N. P. Carter, A. Chang, Y. Gurevich, and W. S Lee. </author> <title> The m-machine multicomputer. </title> <booktitle> In Proc. Int. Symp. on Microarchitecture, </booktitle> <month> November </month> <year> 1995. </year>
Reference-contexts: In designs closer to the von Neumann model, threads tend to become larger, and data structure locality can be better exploited. Examples of these designs include HEP [37], Tera MTA [2], J-Machine [10], and M-Machine <ref> [14] </ref>. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC [30], *T [31], EM-4 [36] and the EARTH project [19]. <p> Therefore thread co-placement strategies designed to enhance inter-thread locality and reduce cache misses have minimal effects. Among the proposed multithreaded architectures that are being developed, the Tera MTA [2] does not have a cache memory. The M-Machine <ref> [14] </ref> does not have a proper data cache but uses the local memory to cache remote data. This caching mechanism is also supported in the local TLB providing hardware support for the coherence mechanism at the block level (8 word granularity).
Reference: [15] <author> I. Foster, C. Kesselman, and S. Tuecke. </author> <title> The Nexus approach to integrating multithreading and communication. </title> <journal> J. of Parallel and Distributed Computing, </journal> (37):70-82, 1996. 
Reference: [16] <author> V.W. Freeh, D.K. Lowenthal, and G.R. Andrews. </author> <title> Distributed Filaments: Efficient fine-grain parallelism on a cluster of workstations. </title> <type> Technical Report TR 94-11, </type> <institution> Dept. of Computer Science, University of Arizona, </institution> <year> 1993. </year>
Reference: [17] <author> M. Haines, D. Cronk, and P. Mehrotra. </author> <title> On the design of Chant: A talking threads package. </title> <booktitle> In Supercomputing, </booktitle> <pages> pages 350-359, </pages> <address> Washington, D.C., </address> <month> November </month> <year> 1994. </year>
Reference: [18] <author> J. L. Hennessy and D. A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <year> 1990. </year> <month> 21 </month>
Reference-contexts: Because the processor speeds have been improving at a much faster rate than the memory speeds in the past decade, the design of on-chip caches has become more crucial. The details of various issues in cache designs are treated in <ref> [18] </ref>. Several designs have tried to combine the advantages of direct-mapped caches with those of set-associative caches, these designs include the victim-cache [21], MRU cache [38], hash-rehash cache [1], and half-half cache [42].
Reference: [19] <author> H. Hum, O. Macquelin, K. Theobald, X. Tian, G. Gao, P. Cupryk, N. Elmassri, L. Hendren, A. Jimenez, S. Krishnan, A. Marquez, S. Merali, S. Nemawarkar, P. Panangaden, X. Xue, and Y. Zhu. </author> <title> A design study of the EARTH multiprocessor. </title> <booktitle> In Proc. Int. Conf. on Parallel Architectures and Compilation Techniques, </booktitle> <year> 1995. </year>
Reference-contexts: Examples of these designs include HEP [37], Tera MTA [2], J-Machine [10], and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC [30], *T [31], EM-4 [36] and the EARTH project <ref> [19] </ref>. The Hybrid Architecture (IHA), proposed by Iannucci [20] extends the von Neumann model with dataflow features to perform synchronizations. The Threaded Abstract Machine (TAM) [8] is a software implemented multithreaded model that has been ported to a number of platforms, such as the TMC CM-5 and the Cray T3D.
Reference: [20] <author> R. A. </author> <title> Iannucci. Toward A Dataflow/Von Neumann Hybrid Architecture. </title> <booktitle> In Proc. 15thInt. Symp. on Computer Architecture, </booktitle> <pages> pages 131-140, </pages> <year> 1988. </year>
Reference-contexts: In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC [30], *T [31], EM-4 [36] and the EARTH project [19]. The Hybrid Architecture (IHA), proposed by Iannucci <ref> [20] </ref> extends the von Neumann model with dataflow features to perform synchronizations. The Threaded Abstract Machine (TAM) [8] is a software implemented multithreaded model that has been ported to a number of platforms, such as the TMC CM-5 and the Cray T3D.
Reference: [21] <author> N. P. Jouppi. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers. </title> <booktitle> In Int. Symp. on Computer Architecture, </booktitle> <pages> pages pp. 364-373, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: The details of various issues in cache designs are treated in [18]. Several designs have tried to combine the advantages of direct-mapped caches with those of set-associative caches, these designs include the victim-cache <ref> [21] </ref>, MRU cache [38], hash-rehash cache [1], and half-half cache [42]. In general, these schemes split the cache into two parts: one is direct mapped, while the other is set associative.
Reference: [22] <author> K. M. Kavi, A. R. Hurson, P. Patadia, E. Abraham, and P. Shanmugam. </author> <title> Design of cache memories for multi-threaded dataflow architecture. </title> <booktitle> In Int. Symp. on Computer Architecture, </booktitle> <pages> pages 253-264, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The caching mechanism attempts to preserve the working set of the program in the cache. Compulsory misses form most of the misses in the caches for multithreaded architectures. Hence, the techniques to reduce the compulsory miss penalty give significant performance benefits. Kavi et al. <ref> [22] </ref> use a cache with a frame based storage (called SuperBlocks) in a dataflow execution model. Their mechanism uses a Cold Store bit to identify compulsory misses and avoid bringing in the cache block.
Reference: [23] <author> D. Keppel. </author> <title> Tools and techniques for building fast portable threads packages. </title> <type> Technical Report UWCSE 93-05-06, </type> <institution> University of Washington, </institution> <year> 1993. </year>
Reference: [24] <author> Y. Kodama, H. Sakane, M. Sato, H. Yamana, S. Sakai, and Y. Yamaguchi. </author> <title> The EM-X parallel computer: Architecture and basic performance. </title> <booktitle> In Int. Symp. on Computer Architecture, </booktitle> <pages> pages 14-23, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: The size of a frame is determined based on the maximum number of data values associated with the code-block. The frame model is used in several multithreaded machines (e.g., TAM [8], StarT-NG [3], and the EM-4 and EM-X <ref> [24] </ref>). When an instance of a particular code-block is invoked, a frame is first allocated in a given processor's frame store. All the tokens generated for that code-block instance are stored in that frame.
Reference: [25] <author> J. Kramer, J. Magee, M. Sloman, N. Duley, S.C. Cheung, S. Crane, and K. Twindle. </author> <title> An introduction to distributed programming in REX. </title> <booktitle> In Proc. of ESPRIT-91, </booktitle> <pages> pages 207-222, </pages> <address> Brussels, </address> <month> November </month> <year> 1991. </year>
Reference: [26] <author> J. McGraw, S. Skedzielewski, S. Allan, R. Oldehoeft, J. Glauert, C. Kirkham, B. Noyce, and R. Thomas. </author> <title> SISAL: Streams and Iteration in a Single Assignment Language: reference manual version 1.2. Manual M-146, </title> <type> Rev. 1, </type> <institution> Lawrence Livermore National Laboratory, Livermore, </institution> <address> CA, </address> <month> March </month> <year> 1985. </year>
Reference-contexts: This section describes the code generation strategy and the execution models. 2.1 Code Generation The source language used for the multithreaded code generation is Sisal <ref> [26] </ref>, a pure, first order, functional programming language. The functional nature of the language allows the compiler to easily extract parallelism at any granularity and generate code that takes the advantage of multiple threads of execution.
Reference: [27] <author> F. Mueller. </author> <title> A library implementation of POSIX threads under UNIX. </title> <booktitle> In Winter USENIX, </booktitle> <pages> pages 29-41, </pages> <address> San Diego, CA, </address> <month> January </month> <year> 1993. </year>
Reference: [28] <author> Frank Mueller. </author> <title> Distributed shared memory threads: </title> <booktitle> DSM-Threads. In Proc. Workshop on Run-Time Systems for Parallel Programming, </booktitle> <year> 1997. </year>
Reference: [29] <author> B. Mukherjee, G. Eisenhauer, and K. Ghosh. </author> <title> A machine independent interface for lightweight threads. </title> <type> Technical Report CIT-CC-93/53, </type> <institution> College of Computing, Georgia Institutre of Technology, </institution> <year> 1993. </year>
Reference: [30] <author> R. S. Nikhil and Arvind. </author> <title> Can dataflow subsume von Neumann computing? In Proc. </title> <booktitle> 16thInt. Symp. on Computer Architecture, </booktitle> <pages> pages 262-272, </pages> <year> 1989. </year> <note> Also: CSG Memo 292, </note> <institution> MIT Laboratory for Computer Science 545 Technology Square, </institution> <address> Cambridge, MA 02139, USA. </address>
Reference-contexts: Examples of these designs include HEP [37], Tera MTA [2], J-Machine [10], and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC <ref> [30] </ref>, *T [31], EM-4 [36] and the EARTH project [19]. The Hybrid Architecture (IHA), proposed by Iannucci [20] extends the von Neumann model with dataflow features to perform synchronizations.
Reference: [31] <author> R. S. Nikhil, G. M. Papadopoulos, and Arvind. </author> <title> *T: A multithreaded massively parallel architecture. </title> <booktitle> In Proc. 19thInt. Symp. on Computer Architecture, </booktitle> <pages> pages 156-167, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Examples of these designs include HEP [37], Tera MTA [2], J-Machine [10], and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC [30], *T <ref> [31] </ref>, EM-4 [36] and the EARTH project [19]. The Hybrid Architecture (IHA), proposed by Iannucci [20] extends the von Neumann model with dataflow features to perform synchronizations.
Reference: [32] <author> G. M. Papadopoulos. </author> <title> Implementation of a General-Purpose Dataflow Multiprocessor. </title> <type> Technical Report TR-432, </type> <institution> MIT Laboratory for Computer Science, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: Examples of these designs include HEP [37], Tera MTA [2], J-Machine [10], and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon <ref> [32, 33] </ref>, P-RISC [30], *T [31], EM-4 [36] and the EARTH project [19]. The Hybrid Architecture (IHA), proposed by Iannucci [20] extends the von Neumann model with dataflow features to perform synchronizations.
Reference: [33] <author> G. M. Papadopoulos and D. E. Culler. Monsoon: </author> <title> An explicit token-store architecture. </title> <booktitle> In Proc. 17thInt. Symp. on Computer Architecture, </booktitle> <pages> pages 82-91, </pages> <month> June </month> <year> 1990. </year>
Reference-contexts: Examples of these designs include HEP [37], Tera MTA [2], J-Machine [10], and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon <ref> [32, 33] </ref>, P-RISC [30], *T [31], EM-4 [36] and the EARTH project [19]. The Hybrid Architecture (IHA), proposed by Iannucci [20] extends the von Neumann model with dataflow features to perform synchronizations.
Reference: [34] <author> L. Roh, W. A. Najjar, B. Shankar, and A. P. W. Bohm. </author> <title> An evaluation of optimized threaded code generation. </title> <booktitle> In Proc. Int. Conf. on Parallel Architectures and Compilation Techniques, </booktitle> <address> Montreal, Canada, </address> <year> 1994. </year>
Reference-contexts: The compilation process converts the Sisal programs into two intermediate forms: MIDC-2 for the non blocking model and MIDC-3 for the blocking one. Both are derived from the Machine Independent Dataflow Code (MIDC) <ref> [34] </ref>. MIDC is a graph structured intermediate format: The nodes of the graph correspond to the von Neumann sequence of instructions and the edges represent the transfer of data between the nodes. It has been used to generate the executable code for other multithreaded machines (e.g., Monsoon and EM-4).
Reference: [35] <author> Lucas Roh and Walid Najjar. </author> <title> Design of storage hierarchy in multithreaded architectures. </title> <booktitle> In Proc. Int. Symp. on Microarchitecture, </booktitle> <pages> pages 271-278, </pages> <month> November </month> <year> 1995. </year>
Reference-contexts: The storage mechanism for the non blocking threads is the framelet model. A framelet is a fixed-sized unit of storage that is associated with each thread instance; it includes a synchronization slot for that thread instance. This model has been described in detail in <ref> [35] </ref>. Simulation results have shown that over 99% of all thread instances can be accommodated with a framelet size of 128 bytes. A chain of framelets, with indirect references, is set up for those threads that have a larger input set. <p> The advantage of framelet model is that one can design special storage schemes that take advantage of the inter thread and intra thread locality and achieve a cache miss rate close to 1% <ref> [35] </ref>. 3 Experimental Evaluation and Analysis This section presents the results of executing multithreaded code in the blocking and non blocking models. In this section we assume an ideal storage hierarchy in which the requested data is always available in the cache. <p> Kavi et al. [22] use a cache with a frame based storage (called SuperBlocks) in a dataflow execution model. Their mechanism uses a Cold Store bit to identify compulsory misses and avoid bringing in the cache block. In <ref> [35] </ref> it is shown that by using certain simple hardware support, the cache performance can be increased by an order of magnitude. Some blocks of the cache are reserved for satisfying the compulsory misses. This scheme, called reserve block scheme, reduces the miss penalty on compulsory misses.
Reference: [36] <author> S. Sakai, Y. Yamaguchi, K. Hiraki, Y. Kodama, and T. Yuba. </author> <title> An architecture of a data-flow single chip processor. </title> <booktitle> In Proc. 16thInt. Symp. on Computer Architecture, </booktitle> <pages> pages 46-53, </pages> <month> May </month> <year> 1989. </year>
Reference-contexts: Examples of these designs include HEP [37], Tera MTA [2], J-Machine [10], and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC [30], *T [31], EM-4 <ref> [36] </ref> and the EARTH project [19]. The Hybrid Architecture (IHA), proposed by Iannucci [20] extends the von Neumann model with dataflow features to perform synchronizations.
Reference: [37] <author> B. J. Smith. </author> <title> Architecture and Applications of the HEP Multiprocessor Computer System. </title> <booktitle> SPIE (Real Time Signal Processing), </booktitle> <volume> 298 </volume> <pages> 241-248, </pages> <year> 1981. </year>
Reference-contexts: In designs closer to the von Neumann model, threads tend to become larger, and data structure locality can be better exploited. Examples of these designs include HEP <ref> [37] </ref>, Tera MTA [2], J-Machine [10], and M-Machine [14]. In designs closer to the dataflow model, latencies are better tolerated, and parallelism is more easily exploited. Examples are Monsoon [32, 33], P-RISC [30], *T [31], EM-4 [36] and the EARTH project [19].
Reference: [38] <author> K. So and R. N. Rechtschaffen. </author> <title> Cache operations by MRU-Change. </title> <booktitle> Intl. Conf. on Computer Design, </booktitle> <pages> pages pp. 584-586, </pages> <month> October </month> <year> 1986. </year>
Reference-contexts: The details of various issues in cache designs are treated in [18]. Several designs have tried to combine the advantages of direct-mapped caches with those of set-associative caches, these designs include the victim-cache [21], MRU cache <ref> [38] </ref>, hash-rehash cache [1], and half-half cache [42]. In general, these schemes split the cache into two parts: one is direct mapped, while the other is set associative.
Reference: [39] <author> M. Takesu. </author> <title> Cache memories for data flow machines. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 41(6) </volume> <pages> 677-687, </pages> <month> June </month> <year> 1992. </year> <month> 22 </month>
Reference-contexts: Scoreboarding is a sequential bottleneck that can reduce the performance. Research on storage hierarchy design for multithreaded architectures is ongoing. Most of the research efforts are on incorporating caches into multithreaded executions and measuring their effectiveness. Cache designs in a dataflow model is discussed in <ref> [39] </ref> for DFM-II [40]. This model is designed for a fine-grained dataflow machine and must therefore take into account the explosion of parallelism that is typical in these machines [7]. The model is evaluated by using a relatively small set of hand-coded benchmarks.
Reference: [40] <author> M. Takesue. </author> <title> A unified resource management and execution control mechanism for data flow machine. </title> <booktitle> In Int. Ann. Symp. on Computer Architecture, </booktitle> <pages> pages 90-97. </pages> <publisher> ACM, </publisher> <year> 1987. </year>
Reference-contexts: Scoreboarding is a sequential bottleneck that can reduce the performance. Research on storage hierarchy design for multithreaded architectures is ongoing. Most of the research efforts are on incorporating caches into multithreaded executions and measuring their effectiveness. Cache designs in a dataflow model is discussed in [39] for DFM-II <ref> [40] </ref>. This model is designed for a fine-grained dataflow machine and must therefore take into account the explosion of parallelism that is typical in these machines [7]. The model is evaluated by using a relatively small set of hand-coded benchmarks.
Reference: [41] <author> R. Thekkath and S. J. Eggers. </author> <title> Impact of sharing-based thread placement on multithreaded architectures. </title> <booktitle> In Proc. 21thInt. Symp. on Computer Architecture, </booktitle> <pages> pages 176-186, </pages> <address> Chicago, Illinois, </address> <year> 1994. </year>
Reference-contexts: In [35] it is shown that by using certain simple hardware support, the cache performance can be increased by an order of magnitude. Some blocks of the cache are reserved for satisfying the compulsory misses. This scheme, called reserve block scheme, reduces the miss penalty on compulsory misses. In <ref> [41] </ref> Tekkath and Eggers show that a minimal amount of contention misses occur due to inter thread communication. Therefore thread co-placement strategies designed to enhance inter-thread locality and reduce cache misses have minimal effects.
Reference: [42] <author> K. B. Theobald, H. H. Hum, and G. R. Gao. </author> <title> A design framework for hybrid-access caches. </title> <booktitle> In Int. Symposium on High-Performance Computer Architecture, </booktitle> <pages> pages pp. 144-153, </pages> <month> January </month> <year> 1995. </year> <month> 23 </month>
Reference-contexts: The details of various issues in cache designs are treated in [18]. Several designs have tried to combine the advantages of direct-mapped caches with those of set-associative caches, these designs include the victim-cache [21], MRU cache [38], hash-rehash cache [1], and half-half cache <ref> [42] </ref>. In general, these schemes split the cache into two parts: one is direct mapped, while the other is set associative. The idea is to simultaneously send the desired address to both parts of the cache and to assume that the direct-mapped portion contains the data.
References-found: 42

