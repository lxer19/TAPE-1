URL: ftp://ftp.cse.ucsc.edu/pub/rna/techreport.ps.Z
Refering-URL: http://www.cse.ucsc.edu/research/compbio/scfg.html
Root-URL: http://www.cse.ucsc.edu
Title: Stochastic Context-Free Grammars for Modeling RNA  
Author: Yasubumi Sakakibara Michael Brown Rebecca C. Underwood I. Saira Mian David Haussler 
Keyword: Stochastic Context-Free Grammar, RNA, Transfer RNA, Multiple Sequence Alignments, Database Searching.  
Address: Santa Cruz, CA 95064, USA.  
Affiliation: Computer and Information Sciences Sinsheimer Laboratories University of California,  
Pubnum: UCSC-CRL-93-16  
Email: email: haussler@cse.ucsc.edu  
Date: June 8, 1993  
Abstract: Stochastic context-free grammars (SCFGs) are applied to the problems of folding, aligning and modeling families of homologous RNA sequences. These models capture the common primary and secondary structure of the sequences with a context-free grammar, much like those used to define the syntax of programming languages. SCFGs generalize the hidden Markov models used in related work on protein and DNA sequences. The novel aspect of this work is that the SCFGs developed here are learned automatically from initially unaligned and unfolded training sequences. To do this, a new generalization of the forward-backward algorithm, commonly used to train hidden Markov models, is introduced. This algorithm is based on tree grammars, and is more efficient than the inside-outside algorithm, which was previously proposed to train SCFGs. This method is tested on the family of transfer RNA (tRNA) sequences. The results show that the model is able to reliably discriminate tRNA sequences from other RNA sequences of similar length, that it can reliably determine the secondary structure of new tRNA sequences, and that it can produce accurate multiple alignments of large collections of tRNA sequences. The model is also extended to handle introns present in tRNA genes. 
Abstract-found: 1
Intro-found: 1
Reference: [AU72] <author> Alfred V. Aho and Jeffrey D. Ullman. </author> <title> The Theory of Parsing, Translation and Compiling, Vol. I: Parsing. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1972. </year>
Reference-contexts: Methods Efficiently computing this quantity, Prob (s j G), presents a problem because the number of possible parse trees for s is exponential in the length of the sequence. However, a dynamic programming technique analogous to the Cocke-Kasami-Young or Early methods <ref> [AU72] </ref> for non-stochastic CFGs can accomplish this task efficiently (in time proportional to the cube of the length of s). We define the negative logarithm of the probability of a sequence given by the grammar, i.e., log (Prob (s j G)), as the negative log likelihood (NLL)-score of the sequence.
Reference: [Bak79] <author> J. K. Baker. </author> <title> Trainable grammars for speech recognition. </title> <booktitle> Speech Communication Papers for the 97th Meeting of the Acoustical Society of America, </booktitle> <pages> pages 547-550, </pages> <year> 1979. </year>
Reference-contexts: A stochastic grammar assigns a probability to each string it derives. Stochastic regular grammars are exactly equivalent to HMMs. This provides an alternate way of examining HMMs and suggests an interesting generalization from HMMs to stochastic context-free grammars (SCFGs) <ref> [Bak79] </ref>. In this paper, we pursue a stochastic model of the family of transfer RNAs (tRNAs) by using a SCFG that is similar to our previous protein HMMs [KBM + 92] but which additionally incorporates base pairing information. <p> To do this, we introduce a new generalization of the forward-backward algorithm, commonly used to train HMMs. Our algorithm is based on tree grammars, and is more efficient than the inside-outside algorithm [LY90], a computationally expensive generalization of the forward-backward algorithm developed by J. K. Baker to train SCFGs <ref> [Bak79] </ref>. Thus we derive two grammars: the alignment grammar, directly derived from an existing multiple alignment of tRNAs, and the trained grammar, deduced by our training algorithm from a training set of tRNA sequences. <p> This algorithm is more efficient than the inside-outside algorithm, which was previously proposed to train SCFGs. The inside-outside algorithm <ref> [LY90, Bak79] </ref> is an Expectation Maximization (EM) algorithm to reestimate the parameters (i.e., the probabilities of productions) in a SCFG.
Reference: [BCHM93] <author> P. Baldi, Y. Chauvin, T. Hunkapiller, and M. A. McClure. </author> <title> Hidden Markov models in molecular biology: new algorithms and applications. </title> <editor> In Hanson, Cowan, and Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <pages> pages 747-754, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kauffmann Publishers. </publisher>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing of new approaches to problems in computational biology such as Hidden Markov Models (HMMs) <ref> [Rab89, HKMS93, KBM + 92, BCHM93, CS92] </ref>. In this paper, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple alignment, and prediction of the secondary structure of RNA families.
Reference: [BHK + 93] <author> M. P. Brown, R. Hughey, A. Krogh, I. S. Mian, K. Sjolander, and D. Haussler. </author> <title> Using Dirichlet mixture priors to derive hidden Markov models for protein families. </title> <booktitle> Proc. of workshop on AI in Molecular Biology, </booktitle> <address> Wash. D.C., </address> <month> July </month> <year> 1993. </year> <note> to appear. </note>
Reference-contexts: Essentially, this is done by counting the occurrences of each letter in a column. However, our method uses Dirichlet mixture density priors for interpreting this count data to avoid statistical problems that arise when not enough count data are available. Details of this general method are described in <ref> [BHK + 93] </ref>. 2. Methods 7 EM training algorithm In order to estimate the parameters of a SCFG from unaligned training RNA sequences, we introduce a new method for training SCFGs that is a generalization of the forward-backward algorithm, commonly used to train HMMs.
Reference: [CS92] <author> L. R. Cardon and G. D. Stormo. </author> <title> Expectation maximization algorithm for identifying protein-binding sites with variable lengths from unaligned DNA fragments. </title> <journal> Journ Mol Biol, </journal> <volume> 223 </volume> <pages> 159-170, </pages> <year> 1992. </year>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing of new approaches to problems in computational biology such as Hidden Markov Models (HMMs) <ref> [Rab89, HKMS93, KBM + 92, BCHM93, CS92] </ref>. In this paper, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple alignment, and prediction of the secondary structure of RNA families.
Reference: [ER91] <author> J. Engelfriet and G. Rozenberg. </author> <title> Graph grammars based on node rewriting: and introduction to NLC graph grammars. </title> <editor> In E. Ehrig, H.J. Kreowski, and G. Rozenberg, editors, </editor> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> volume 532, </volume> <pages> pages 12-23. </pages> <publisher> Springer-Verlag, </publisher> <year> 1991. </year>
Reference-contexts: To go beyond this to the tertiary structure would require still more general methods. One possibility would be to consider stochastic graph grammars (see e.g. <ref> [ER91] </ref>) in hopes of obtaining a more general model of the interactions present in the molecule beyond the primary structure.
Reference: [Fu82] <author> K.S. Fu. </author> <title> Syntactic pattern recognition and applications. </title> <publisher> Prentice-Hall, </publisher> <year> 1982. </year>
Reference-contexts: This progression is similar to the path taken by the late King Sun Fu and his colleagues in their development of the field of syntactic pattern recognition <ref> [Fu82] </ref>. To go beyond this to the tertiary structure would require still more general methods. One possibility would be to consider stochastic graph grammars (see e.g. [ER91]) in hopes of obtaining a more general model of the interactions present in the molecule beyond the primary structure.
Reference: [GPH + 92] <author> R. R. Gutell, A. Power, G. Z. Hertz, E. J. Putz, and G. D. Stormo. </author> <title> Identifying constraints on the higher-order structure of RNA: continued development and application of comparative sequence analysis methods. </title> <journal> Nucleic Acids Research, </journal> <volume> 20 </volume> <pages> 5785-5795, </pages> <year> 1992. </year> <note> 18 References </note>
Reference-contexts: Then, by studying multiple alignments produced by this grammar, we might be able to use methods for finding correlations between columns in this multiple alignment, such as those in <ref> [GPH + 92, Lap92, KB93] </ref>, to discover some of the base paring structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [HKMS93] <author> D. Haussler, A. Krogh, I. S. Mian, and K. Sjolander. </author> <title> Protein modeling using hidden Markov models: Analysis of globins. </title> <booktitle> In Proceedings of the Hawaii International Conference on System Sciences, </booktitle> <address> Los Alamitos, CA, 1993. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing of new approaches to problems in computational biology such as Hidden Markov Models (HMMs) <ref> [Rab89, HKMS93, KBM + 92, BCHM93, CS92] </ref>. In this paper, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple alignment, and prediction of the secondary structure of RNA families. <p> In this paper, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple alignment, and prediction of the secondary structure of RNA families. This approach is highly related to our previous work on modeling protein families with HMMs <ref> [HKMS93, KBM + 92] </ref>. RNA is mostly involved in the biological machinery that expresses the genetic information from DNA to protein. Information is encoded in RNA by the linear arrangement of the four different constituent nucleotides (the primary structure). <p> Essentially, our method builds a statistical model during the process of multiple alignment and folding analysis, rather than leaving this as a separate task to be done after the alignment and folding are completed. In our previous studies <ref> [HKMS93, KBM + 92] </ref>, this approach has been successfully applied to modeling protein families with HMMs. Although in principle HMMs could be used for RNA, we strongly suspect that the more general statistical models described below will be required to obtain useful results.
Reference: [JOP89] <author> B. D. James, G. J. Olsen, and N. R. </author> <title> Pace. Phylogenetic comparative analysis of RNA secondary structure. </title> <booktitle> Methods in Enzymology, </booktitle> <volume> 180 </volume> <pages> 227-239, </pages> <year> 1989. </year>
Reference-contexts: Currently, there are two principal methods for predicting the secondary structure of RNA. Phylogenetic analysis for homologous RNA molecules relies upon alignment and subsequent folding of several sequences into similar structures (reviewed in <ref> [JOP89, WGGN83] </ref>). In contrast, energy minimization is dependent upon thermodynamic parameters and computer algorithms to evaluate the optimal and suboptimal free energy folding of an RNA species (reviewed in [JTZ90, ZS84]). Our method of multiple alignment and folding differs quite markedly from the conventional techniques.
Reference: [JTZ90] <author> J. A. Jaeger, D. H. Turner, and M. Zuker. </author> <title> Predicting optimal and suboptimal secondary structure for RNA. </title> <booktitle> Methods in Enzymology, </booktitle> <volume> 183 </volume> <pages> 281-306, </pages> <year> 1990. </year>
Reference-contexts: Phylogenetic analysis for homologous RNA molecules relies upon alignment and subsequent folding of several sequences into similar structures (reviewed in [JOP89, WGGN83]). In contrast, energy minimization is dependent upon thermodynamic parameters and computer algorithms to evaluate the optimal and suboptimal free energy folding of an RNA species (reviewed in <ref> [JTZ90, ZS84] </ref>). Our method of multiple alignment and folding differs quite markedly from the conventional techniques. Essentially, our method builds a statistical model during the process of multiple alignment and folding analysis, rather than leaving this as a separate task to be done after the alignment and folding are completed.
Reference: [KB93] <author> Tod Klinger and Douglas Brutlag. </author> <type> Unpublished manuscript, </type> <year> 1993. </year>
Reference-contexts: Then, by studying multiple alignments produced by this grammar, we might be able to use methods for finding correlations between columns in this multiple alignment, such as those in <ref> [GPH + 92, Lap92, KB93] </ref>, to discover some of the base paring structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [KBM + 92] <author> A. Krogh, M. Brown, I. S. Mian, K. Sjolander, and D. Haussler. </author> <title> Hidden Markov models in computational biology: Applications to protein modeling. </title> <note> Submitted to J. Mol. Bio., </note> <month> December </month> <year> 1992. </year>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing of new approaches to problems in computational biology such as Hidden Markov Models (HMMs) <ref> [Rab89, HKMS93, KBM + 92, BCHM93, CS92] </ref>. In this paper, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple alignment, and prediction of the secondary structure of RNA families. <p> In this paper, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple alignment, and prediction of the secondary structure of RNA families. This approach is highly related to our previous work on modeling protein families with HMMs <ref> [HKMS93, KBM + 92] </ref>. RNA is mostly involved in the biological machinery that expresses the genetic information from DNA to protein. Information is encoded in RNA by the linear arrangement of the four different constituent nucleotides (the primary structure). <p> Essentially, our method builds a statistical model during the process of multiple alignment and folding analysis, rather than leaving this as a separate task to be done after the alignment and folding are completed. In our previous studies <ref> [HKMS93, KBM + 92] </ref>, this approach has been successfully applied to modeling protein families with HMMs. Although in principle HMMs could be used for RNA, we strongly suspect that the more general statistical models described below will be required to obtain useful results. <p> This provides an alternate way of examining HMMs and suggests an interesting generalization from HMMs to stochastic context-free grammars (SCFGs) [Bak79]. In this paper, we pursue a stochastic model of the family of transfer RNAs (tRNAs) by using a SCFG that is similar to our previous protein HMMs <ref> [KBM + 92] </ref> but which additionally incorporates base pairing information. A SCFG that forms a statistical model of tRNA sequences can be built in much the same way as our construction of an HMM representing a statistical model of the globin protein family. <p> A parse tree represents the syntactic structure of an RNA sequence given by the grammar, and hence reflects the actual 2. Methods 5 physical secondary structure. Figure 2.2 shows the derivation arranged in a parse tree reflecting the physical secondary structure. As in the HMM of <ref> [KBM + 92] </ref>, we distinguish two different types of nonterminals: match nonter-minals and insert nonterminals. The match nonterminals in a grammar correspond to important structural positions in an RNA or columns in a multiple alignment with few - (gap) characters. These constitute the main line of the grammar. <p> We calculated a regularizer from the multiple alignment of tRNA sequences and added it to the counts used for reestimating the probabilities of productions of the grammar in each iteration of training. Similar methods are described in <ref> [KBM + 92] </ref>. 10 3. Results 2.5 Iterative usage of the training algorithm Since our EM training algorithm uses folded RNA as training examples, rather than unfolded ones, the base pairs in each training sequence need to be identified before the EM iteration begins. <p> The run-time was around 10 CPU minutes on a Sun Sparcstation. During this process, only the probabilities of the productions were reestimated and no nonterminals or productions were added or deleted (unlike "model surgery" in <ref> [KBM + 92] </ref>). Our future work will focus on developing some method that can automatically select a good structure and a good length of the grammar while training. 3.1 Data The experiments used data from three sources: 1. <p> This raw NLL-score depends too much on the length of test sequence to be used directly to decide whether a sequence belongs to the family modeled by the grammar. However, this problem can be overcome by normalizing the NLL-score appropriately. Details are described in <ref> [KBM + 92] </ref>. Essentially, we calculate the difference between the NLL-score of a sequence and the average NLL-score of a typical non-tRNA sequence of the same length, measured in standard deviations. This number is called the Z-score for the sequence. <p> As described in Section 2.5, we could then try to gradually extend the grammar to account for the structure of the training sequences. We might do this by starting with a regular grammar that represents an HMM like those used to model protein families in our previous work <ref> [KBM + 92] </ref>. Then, by studying multiple alignments produced by this grammar, we might be able to use methods for finding correlations between columns in this multiple alignment, such as those in [GPH + 92, Lap92, KB93], to discover some of the base paring structure in tRNA.
Reference: [Lap92] <author> Allan Lapedes. </author> <title> Private communication, </title> <year> 1992. </year>
Reference-contexts: Then, by studying multiple alignments produced by this grammar, we might be able to use methods for finding correlations between columns in this multiple alignment, such as those in <ref> [GPH + 92, Lap92, KB93] </ref>, to discover some of the base paring structure in tRNA. Having done this, it would be straightforward to modify the grammar to account for this base pairing, and then iterate this process until no new structure is found.
Reference: [LY90] <author> K. Lari and S. J. Young. </author> <title> The estimation of stochastic context-free grammars using the inside-outside algorithm. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 4 </volume> <pages> 35-56, </pages> <year> 1990. </year>
Reference-contexts: To do this, we introduce a new generalization of the forward-backward algorithm, commonly used to train HMMs. Our algorithm is based on tree grammars, and is more efficient than the inside-outside algorithm <ref> [LY90] </ref>, a computationally expensive generalization of the forward-backward algorithm developed by J. K. Baker to train SCFGs [Bak79]. <p> This algorithm is more efficient than the inside-outside algorithm, which was previously proposed to train SCFGs. The inside-outside algorithm <ref> [LY90, Bak79] </ref> is an Expectation Maximization (EM) algorithm to reestimate the parameters (i.e., the probabilities of productions) in a SCFG.
Reference: [OOL + 92] <author> G. J. Olsen, R. Overbeek, N. Larsen, T. L. Marshand M. J. McCaughey, M. A. Maciuke-nas, W. M. Kuan, T. J. Macke, Y. Xing, and C. R. Woese. </author> <title> The ribosomal database project. </title> <journal> Nucleic Acids Research, </journal> <volume> 20 </volume> <pages> 2199-200, </pages> <year> 1992. </year>
Reference-contexts: Of these 1477 tRNA sequence descriptions, we selected randomly 500 as training examples for deriving a grammar to model intron-free tRNA and used the rest as test data. 2. The Ribosomal Database Project's (RDP) <ref> [OOL + 92] </ref> aligned, folded large subunit ribosomal RNA data file LSU.aln provided primary source of non-tRNA sequences.
Reference: [PG93] <author> E. M. Phizicky and C. L. </author> <title> Greer. Pre-tRNA splicing: variation on a theme or exception to the rule? Trends in Biochemical Sciences, </title> <booktitle> 18 </booktitle> <pages> 31-34, </pages> <year> 1993. </year>
Reference-contexts: This means that when we search databank files of genomic sequences, the sequence of the tRNA may be interrupted by non-tRNA coding nucleotides. The grammar needs to be extended to handle this situation. Introns are normally present in the anticodon stem loop (reviewed in <ref> [PG93] </ref>). We make the assumption that an intron (of whatever type) will be present in the anticodon loop and more specifically within or on either side of the anticodon itself, i.e., we consider a total of five possible positions for introns. An extremely useful advantage of SCFGs is their modularity.
Reference: [Rab89] <author> L. R. Rabiner. </author> <title> A tutorial on hidden Markov models and selected applications in speech recognition. </title> <journal> Proc IEEE, </journal> <volume> 77(2) </volume> <pages> 257-286, </pages> <year> 1989. </year>
Reference-contexts: Rapid generation of sequence data in recent years thus provides abundant opportunities for developing of new approaches to problems in computational biology such as Hidden Markov Models (HMMs) <ref> [Rab89, HKMS93, KBM + 92, BCHM93, CS92] </ref>. In this paper, we apply stochastic context-free grammars (SCFGs) to the problems of statistical modeling, database searching, multiple alignment, and prediction of the secondary structure of RNA families. <p> To obtain the most likely parse tree for the sequence s, we calculate max parse trees d Prob (S 0 d The dynamic programming procedure to do this resembles the Viterbi algorithm for HMMs <ref> [Rab89] </ref>.
Reference: [Sak92] <author> Yasubumi Sakakibara. </author> <title> Efficient learning of context-free grammars from positive structural examples. </title> <journal> Information and Computation, </journal> <volume> 97 </volume> <pages> 23-60, </pages> <year> 1992. </year>
Reference-contexts: The new algorithm also tends to converge faster because each training example is much more informative. which can be broken into two parts such as t=3 (middle) and tn3 (right). To avoid unnecessary complexity, we describe this new algorithm in terms of CFGs instead of tree-grammars <ref> [TW68, Sak92] </ref>. A tree is a rooted, directed, connected acyclic finite graph in which the direct successors of any node are linearly ordered from left to right. The predecessor of a node 8 2.
Reference: [San85] <author> David Sankoff. </author> <title> Simultaneous solution of the RNA folding, alignment and protosequence problems. </title> <journal> SIAM J. Appl. Math., </journal> <volume> 45 </volume> <pages> 810-825, </pages> <year> 1985. </year>
Reference-contexts: Thus, the elucidation of common folding patterns among two or more sequences may indicate the pertinent regions to be aligned and vice versa <ref> [San85] </ref>. Currently, there are two principal methods for predicting the secondary structure of RNA. Phylogenetic analysis for homologous RNA molecules relies upon alignment and subsequent folding of several sequences into similar structures (reviewed in [JOP89, WGGN83]).
Reference: [Sea92] <author> David B. </author> <title> Searls. The linguistics of DNA. </title> <journal> American Scientist, </journal> <volume> 80 </volume> <pages> 579-591, </pages> <month> November-December </month> <year> 1992. </year>
Reference-contexts: Such base pairs constitute so-called biological palindromes in the genome. We have found a way to generalize HMMs to model most of these interactions seen in RNA. The essence of the idea can be expressed most clearly in terms of formal language theory. As in the work of Searls <ref> [Sea92] </ref>, we can view the strings of characters representing pieces of DNA, RNA and protein as sentences derived from a formal grammar. <p> As is beautifully described by Searls, it is precisely these additional types of production that are needed to describe the base pairing structure in RNA 1 <ref> [Sea92] </ref>. In particular, the productions of the forms S ! A S U, S ! U S A, S ! G S C, and S ! C S G describe the structure in RNA due to Watson-Crick base pairing. <p> An example CFG that generates a particular set of RNA sequences is shown in Figure 2.1. We will use it to describe CFGs. See Searls <ref> [Sea92] </ref> for a more comprehensive explanation. A formal grammar is a set of productions (rewriting rules) that are used to generate a set of strings, that is, a language. The productions are applied iteratively to generate a string, a process called derivation. <p> We can also use this procedure to obtain our multiple alignments: the grammar aligns each sequence by finding the most likely parse tree, after which the mutual alignment of the sequences among themselves is determined. 2.3 Estimating SCFGs from sequences Searls <ref> [Sea92] </ref> argues the benefits of using context-free grammars as models for RNA folding, but does not discuss methods for estimating the grammar from training sequences. One purpose of this paper is to provide an effective method for estimating a SCFG to model a family of RNA sequences.
Reference: [SZ90] <author> Bruce A. Shapiro and Kaizhong Zhang. </author> <title> Comparing multiple RNA secondary structures using tree comparisons. </title> <journal> CABIOS, </journal> <volume> 6(4) </volume> <pages> 309-318, </pages> <year> 1990. </year>
Reference-contexts: This new algorithm we have developed is based on the theory of stochastic tree-grammars. As the name suggests, tree-grammars are used to derive labeled trees instead of strings. Labeled trees can be used to represent the secondary structure of RNA quite easily <ref> [SZ90] </ref> (see Figure 2.2). When working with a tree-grammar for RNA, one is explicitly working with the secondary structure of the molecule.
Reference: [TW68] <author> J. W. Thatcher and J. B. Wright. </author> <title> Generalized finite automata theory with an application to a decision problem of second-order logic. </title> <journal> Mathematical Systems Theory, </journal> <volume> 2 </volume> <pages> 57-81, </pages> <year> 1968. </year>
Reference-contexts: The new algorithm also tends to converge faster because each training example is much more informative. which can be broken into two parts such as t=3 (middle) and tn3 (right). To avoid unnecessary complexity, we describe this new algorithm in terms of CFGs instead of tree-grammars <ref> [TW68, Sak92] </ref>. A tree is a rooted, directed, connected acyclic finite graph in which the direct successors of any node are linearly ordered from left to right. The predecessor of a node 8 2.
Reference: [Wat89] <author> M. S. Waterman. </author> <title> Sequence alignments. </title> <editor> In M S Waterman, editor, </editor> <title> Mathematical Methods for DNA Sequences. </title> <publisher> CRC Press, </publisher> <year> 1989. </year>
Reference-contexts: Comparative analyses of two or more protein or nucleic acid sequences have been used widely in the detection and evaluation of biological similarities and evolutionary relationships. Several methods of producing these multiple sequence alignments have been developed, most based on dynamic programming techniques (see for example <ref> [Wat89] </ref>). However, when RNA sequences are to be aligned, both the primary and secondary structure need to be taken into consideration since the generation of a multiple sequence alignment and an analysis of folding are not mutually exclusive exercises.
Reference: [WGGN83] <author> C. R. Woese, R. R. Gutell, R. Gupta, and H. F. Noller. </author> <title> Detailed analysis of the higher-order structure of 16s-like ribosomal ribonucleic acids. </title> <journal> Microbiology Reviews, </journal> <volume> 47(4) </volume> <pages> 621-669, </pages> <year> 1983. </year>
Reference-contexts: Currently, there are two principal methods for predicting the secondary structure of RNA. Phylogenetic analysis for homologous RNA molecules relies upon alignment and subsequent folding of several sequences into similar structures (reviewed in <ref> [JOP89, WGGN83] </ref>). In contrast, energy minimization is dependent upon thermodynamic parameters and computer algorithms to evaluate the optimal and suboptimal free energy folding of an RNA species (reviewed in [JTZ90, ZS84]). Our method of multiple alignment and folding differs quite markedly from the conventional techniques.
Reference: [WGN93] <author> Bryn Weiser, Robin Gutell, and Harry Noller. XRNA: </author> <title> an X-windows environment RNA editing/display package. </title> <type> Unpublished manuscript, </type> <month> January </month> <year> 1993. </year>
Reference-contexts: Thus, this approach shows some promise in identifying introns and finding the correct secondary structure for tRNA sequences with introns. 3.6 Displaying folded RNA sequences: XRNA XRNA is a suite of programs providing, among other functions, graphic manipulation and labeling of previously determined RNA secondary structures <ref> [WGN93] </ref>. Using simple filters, we were able to transform the secondary structure predicted by our grammar into XRNA format. 16 4.
Reference: [ZS84] <author> Michael Zuker and David Sankoff. </author> <title> RNA secondary structures and their prediction. </title> <journal> Bull. Math. Biol., </journal> <volume> 46 </volume> <pages> 591-621, </pages> <year> 1984. </year> <title> A. </title> <type> Appendix 19 </type>
Reference-contexts: Phylogenetic analysis for homologous RNA molecules relies upon alignment and subsequent folding of several sequences into similar structures (reviewed in [JOP89, WGGN83]). In contrast, energy minimization is dependent upon thermodynamic parameters and computer algorithms to evaluate the optimal and suboptimal free energy folding of an RNA species (reviewed in <ref> [JTZ90, ZS84] </ref>). Our method of multiple alignment and folding differs quite markedly from the conventional techniques. Essentially, our method builds a statistical model during the process of multiple alignment and folding analysis, rather than leaving this as a separate task to be done after the alignment and folding are completed.
References-found: 27

