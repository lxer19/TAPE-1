URL: ftp://ftp.imag.fr/pub/MAI/santia.ps.gz
Refering-URL: http://www-lmc.imag.fr/MAI/cours.fr.html
Root-URL: http://www.imag.fr
Email: bernard.ycart@imag.fr  
Title: Algorithmes markoviens  
Author: B. Ycart 
Date: Diciembre 1997  
Address: BP 53, 38041 Grenoble Cedex 09  Chile  
Affiliation: LMC/IMAG,  Departamento de Ingenieria Matematica Universidad de  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> D.J. Aldous. </author> <title> On the Markov chain simulation method for uniform combinatorial distributions and simulated annealing. </title> <journal> Probab. Eng. and Inf. Sciences, </journal> <volume> 1 </volume> <pages> 33-46, </pages> <year> 1987. </year>
Reference-contexts: En d'autres termes, nous supposerons que tout vecteur constitue d'appels successifs de Random est une realisation d'un vecteur de variables aleatoires independantes et de m^eme loi, uniforme sur l'intervalle <ref> [0; 1] </ref>. En dehors des generateurs livres avec tous les compilateurs courants, plusieurs excellents generateurs sont disponibles sous des formes diverses, en particulier le generateur ULTRA de Marsaglia et Zaman [57, 58]. En pratique une cha^ine de Markov est simulee de maniere iterative comme le dit la definition 2.1. <p> Supposons par exemple que la loi (p ij ) j2E soit simulee par inversion. Notons 6 * U n le n-eme appel de Random. * l'application de E fi <ref> [0; 1] </ref> dans E qui au couple (i; u) associe l'inverse de la fonction de repartition de la loi (p ij ) j2E , evalue en u. L'algorithme calcule bien X n+1 = (X n ; U n ) : Ceci a une portee plutot theorique. <p> 1; : : : ; d : L'ensemble E est naturellement muni d'une structure de graphe G = (E; A), pour laquelle deux sommets j et i sont voisins si et seulement si ils different en une coor-donnee et une seule. fj; ig 2 A () i=1 Soit fi 2 <ref> [0; 1] </ref> un reel fixe. <p> Si on revient a la cha^ine de matrice de transition P , son equilibre est donc atteint bien avant que toutes les coordonnees de la configuration de depart aient ete modifiees, ne serait-ce qu'une fois. 3.1.4 Denombrement par cha^ine de Markov Ce qui suit s'inspire de Aldous <ref> [1, 2] </ref> (voir aussi [62, 74]). <p> Nous traduisons cette approximation par la proposition suivante (d'autres formulations seraient envisageables). Proposition 5.1 Pour tout h &gt; 0, definissons l'operateur h par h f (j) = h 2 X d Soit ' une application deux fois contin^ument differentiable de IR d dans <ref> [0; 1] </ref>. Fixons i 2 F et considerons la loi de probabilite P h sur E h = f0; 1g hZZ d definie par P h = i j Soit f la fonction indicatrice de la valeur i en x.
Reference: [2] <author> D.J. Aldous. </author> <title> Approximate counting via Markov chains. </title> <journal> Statistical Science, </journal> <volume> 8(1) </volume> <pages> 16-19, </pages> <year> 1993. </year>
Reference-contexts: Si on revient a la cha^ine de matrice de transition P , son equilibre est donc atteint bien avant que toutes les coordonnees de la configuration de depart aient ete modifiees, ne serait-ce qu'une fois. 3.1.4 Denombrement par cha^ine de Markov Ce qui suit s'inspire de Aldous <ref> [1, 2] </ref> (voir aussi [62, 74]).
Reference: [3] <author> R. Azencott. </author> <title> Simulated annealing. </title> <type> Seminaire Bourbaki, 697 </type> <pages> 161-175, </pages> <year> 1988. </year>
Reference-contexts: Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [3, 9, 26] </ref>. 3.2.1 Mesures de Gibbs Definition 3.3 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [4] <author> F. Baccelli, G. Cohen, G. Olsder, and J.P. Quadrat. </author> <title> Synchronization and Linearity: an algebra for discrete event systems. </title> <publisher> Wiley, </publisher> <address> Chichester, </address> <year> 1992. </year>
Reference-contexts: des taux que peu de coordonnees seront non nulles simultanement pendant une forte proportion du temps, alors la simulation de la cha^ine incluse redevient competitive. 4.2.3 Reseaux de Petri Les reseaux de Petri markoviens peuvent ^etre vus comme le modele markovien le plus general pour des files d'attente synchronisees (voir <ref> [4, 14] </ref>). Un reseau de Petri se compose d'un nombre fini de N places (ou sites) et d'un ensemble fini de T transitions. Chaque place n peut contenir un nombre entier i n de marques (aussi appelees jetons ou charges).
Reference: [5] <author> T. </author> <title> Back. Evolutionary algorithms in theory and practice. </title> <publisher> Oxford University Press, Oxford, </publisher> <year> 1996. </year>
Reference-contexts: Nous avons surtout utilise Saloff-Coste [73]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [5, 16, 37, 40, 59, 60, 81] </ref>). La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante [68, 70, 72, 71, 78, 80, 82]. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [5, 40, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [17, 18, 19] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [35].
Reference: [6] <author> A.T. Barucha-Reid. </author> <title> Elements of the theory of Markov processes and their Applications. </title> <publisher> McGraw-Hill, </publisher> <address> London, </address> <year> 1960. </year>
Reference-contexts: Les livres de Bouleau [11], Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. Un point de vue plus applique est celui de Barucha-Reid <ref> [6] </ref> et Karlin et Taylor [42, 43]. C inlar [22] est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [34]. <p> de la fonction (de y) p (s; x; t; y). 24 3 Exploration markovienne 3.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [6, 15, 22, 32, 42, 46] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 56 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [6, 42, 43, 15, 22, 33, 12] </ref>). La presentation que nous proposons ici n'est pas classique. <p> C'est un des avantages de la cha^ine harmonisee par rapport a la cha^ine incluse pour ce qui est de la simulation. Exemple : File M/M/1. La file M/M/1 (voir par exemple <ref> [6, 43, 78, 79] </ref>) est le processus de naissance et de mort sur IN dont les taux de transition sont ij = si i 0 ; j = i + 1 ; = 0 dans tous les autres cas : 68 Pour la simulation par la cha^ine incluse, on aura p
Reference: [7] <author> M. Beguin, L. Gray, and B. Ycart. </author> <title> The load transfer model. </title> <journal> A para^itre Ann. Appl. Probab., </journal> <year> 1998. </year>
Reference-contexts: si elle ne correspond pas aux "vraies" valeurs (l'hypothese d'independance des sites est bien s^ur fausse en general), fournit neanmoins de nombreux renseignements sur le phenomene, et dans certains cas une approximation de bonne qualite : voir [31] pour des exemples d'applications a des equilibres en dynamique des populations, et <ref> [7] </ref> pour un cas de bonne adequation avec les resultats de simulations. Pour exposer cette technique, nous allons nous placer dans le cadre de systemes de particules ou chaque site prend ses valeurs dans un ensemble fini quelconque F .
Reference: [8] <author> M.A. Berger. </author> <title> An introduction to probability and stochastic processes. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: Les notions de probabilites qui seront utilisees ici sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [15] ou Feller [32, 33]. Les livres de Bouleau [11], Snell [75] et Berger <ref> [8] </ref> font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor [42, 43]. C inlar [22] est particulierement clair.
Reference: [9] <author> D. Bertsimas and J. Tsitsiklis. </author> <title> Simulated annealing. </title> <journal> Statistical Science, </journal> <volume> 8 </volume> <pages> 10-15, </pages> <year> 1993. </year>
Reference-contexts: Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [3, 9, 26] </ref>. 3.2.1 Mesures de Gibbs Definition 3.3 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [10] <author> N. Biggs. </author> <title> Algebraic Graph Theory. </title> <publisher> Cambridge University Press, </publisher> <year> 1973. </year>
Reference-contexts: La cha^ine de Markov de matrice de transition P s'appelle marche aleatoire symetrique sur le graphe G. La matrice P est, a une transformation pres, ce que les combinatoriciens nomment le laplacien du graphe G (voir <ref> [10] </ref>). Cet exemple est a rapprocher de la proposition 2.4. Il existe une analogie etroite entre les cha^ines de Markov symetriques et les reseaux electriques (voir [27]). Les etats de E sont vus comme les sommets d'un reseau, relies par des lignes electriques.
Reference: [11] <author> N. Bouleau. Probabilites de l'ingenieur, </author> <title> variables aleatoires et simulation. </title> <address> Her-mann, Paris, </address> <year> 1985. </year>
Reference-contexts: Les notions de probabilites qui seront utilisees ici sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [15] ou Feller [32, 33]. Les livres de Bouleau <ref> [11] </ref>, Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor [42, 43]. <p> Il est naturel de se demander s'il existe des cha^ines de Markov non simulables. Il n'en existe pas si E est denombrable, ou si E = IR d , muni de sa tribu de boreliens. On n'en rencontrera donc jamais en pratique (voir Bouleau <ref> [11] </ref> p. 208-211 et p. 225). Exemple : Marches aleatoires sur IR d . 5 Soit (U n ); n 2 IN une suite de variables aleatoires independantes et de m^eme loi sur IR d .
Reference: [12] <author> N. Bouleau. </author> <title> Processus stochastiques et applications. </title> <publisher> Hermann, </publisher> <address> Paris, </address> <year> 1988. </year>
Reference-contexts: processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (2.3) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [55, 12, 41, 50] </ref>). <p> C'est ce semi-groupe qui decrit la dynamique d'evolution inherente a l'equation dX (t) = (X (t))dt + oe (X (t))dW t : La propriete essentielle est la troisieme. Elle decoule du caractere markovien et de l'homogeneite (voir par exemple <ref> [12] </ref>). Sous les hypotheses du theoreme de Hille-Yoshida, tout semi-groupe admet un gene-rateur qui, formellement, est sa derivee logarithmique. Dans le cas du semi-groupe associe a un processus de diffusion, ce generateur est l'operateur A du paragraphe precedent. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 56 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [6, 42, 43, 15, 22, 33, 12] </ref>). La presentation que nous proposons ici n'est pas classique. <p> L'hypothese que les (x) sont minores par une constante strictement positive assure que la suite T n des instants de saut du processus tend presque s^urement vers l'infini. Dans le cas particulier ou la fonction est constante, cette suite forme un processus de Poisson homogene d'intensite (voir <ref> [15, 22, 33, 12] </ref>). Un taux (x) nul correspondrait a une duree de sejour infinie dans l'etat x, qui serait alors qualifie d'etat absorbant. Comme pour la definition algorithmique des cha^ines de Markov 2.1, il est legitime de se demander quel est le degre de generalite de la definition 4.1.
Reference: [13] <author> N. Bouleau and D. Lepingle. </author> <title> Numerical methods for stochastic processes. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle <ref> [13] </ref>. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay [77]. Les methodes MCMC (Monte-Carlo Markov Chain) sont traitees en particulier par Duflo [29, 30] et Robert [66, 67]. <p> Nous ne les aborderons pas (voir [50] p. 511-527). 18 2.3.3 Problemes de Dirichlet C'est la generalisation du probleme (2.1) que nous considerons ici. La presentation que nous en faisons est celle de [41] p. 364-365 (voir aussi <ref> [13] </ref> p. 237). Les notations sont celles des paragraphes precedents. Supposons que les applications et oe ne dependent pas de t (cas homogene). L'application va de IR d dans IR d , oe va de IR d dans M dfid 0 (IR).
Reference: [14] <author> G.W. Brams. Reseaux de Petri: </author> <title> theorie et pratique. </title> <publisher> Masson, </publisher> <address> Paris, </address> <year> 1983. </year>
Reference-contexts: des taux que peu de coordonnees seront non nulles simultanement pendant une forte proportion du temps, alors la simulation de la cha^ine incluse redevient competitive. 4.2.3 Reseaux de Petri Les reseaux de Petri markoviens peuvent ^etre vus comme le modele markovien le plus general pour des files d'attente synchronisees (voir <ref> [4, 14] </ref>). Un reseau de Petri se compose d'un nombre fini de N places (ou sites) et d'un ensemble fini de T transitions. Chaque place n peut contenir un nombre entier i n de marques (aussi appelees jetons ou charges).
Reference: [15] <author> L. Breiman. </author> <title> Probability. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1968. </year>
Reference-contexts: Les notions de probabilites qui seront utilisees ici sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman <ref> [15] </ref> ou Feller [32, 33]. Les livres de Bouleau [11], Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. <p> Discuter des differentes definitions et caracterisations du mouvement brownien sortirait du cadre de ce cours. Nous renvoyons pour cela au cours aux tres nombreuses references de la litterature, en particulier <ref> [15, 41] </ref>. <p> de la fonction (de y) p (s; x; t; y). 24 3 Exploration markovienne 3.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [6, 15, 22, 32, 42, 46] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 56 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [6, 42, 43, 15, 22, 33, 12] </ref>). La presentation que nous proposons ici n'est pas classique. <p> L'hypothese que les (x) sont minores par une constante strictement positive assure que la suite T n des instants de saut du processus tend presque s^urement vers l'infini. Dans le cas particulier ou la fonction est constante, cette suite forme un processus de Poisson homogene d'intensite (voir <ref> [15, 22, 33, 12] </ref>). Un taux (x) nul correspondrait a une duree de sejour infinie dans l'etat x, qui serait alors qualifie d'etat absorbant. Comme pour la definition algorithmique des cha^ines de Markov 2.1, il est legitime de se demander quel est le degre de generalite de la definition 4.1.
Reference: [16] <author> R. Cairoli and R.C. Dalang. </author> <title> Sequential stochastic optimization. </title> <publisher> Wiley, </publisher> <address> New-York, </address> <year> 1996. </year>
Reference-contexts: Nous avons surtout utilise Saloff-Coste [73]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [5, 16, 37, 40, 59, 60, 81] </ref>). La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante [68, 70, 72, 71, 78, 80, 82].
Reference: [17] <author> R. </author> <type> Cerf. </type> <institution> Une theorie asymptotique des algorithmes genetiques. These, Universite Montpellier II, </institution> <year> 1994. </year> <month> 101 </month>
Reference-contexts: L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [5, 40, 37, 59, 60]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [17, 18, 19] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [35]. <p> dependant des autres parametres de l'algorithme ainsi que de la fonction f, telle que pour m &gt; m fl , lim max ) = 1 : La demonstration est assez technique et il nous est impossible d'en donner un apercu significatif dans le cadre restreint de ce cours : voir <ref> [17] </ref> p. 27 et p. 72. La valeur critique m fl y est decrite en fonction de a; b; c; et f de maniere relativement precise, mais malheureusement elle n'est pas calculable en pratique.
Reference: [18] <author> R. Cerf. </author> <title> The dynamics of mutation-selection algorithms with large population sizes. </title> <journal> Ann. Inst. H. Poincare, Probab. Stat., </journal> <volume> 32(4) </volume> <pages> 455-508, </pages> <year> 1996. </year>
Reference-contexts: L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [5, 40, 37, 59, 60]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [17, 18, 19] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [35].
Reference: [19] <author> R. Cerf. </author> <title> A new genetic algorithm. </title> <journal> Ann. Appl. Probab., </journal> <volume> 6(3) </volume> <pages> 778-817, </pages> <year> 1996. </year>
Reference-contexts: L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir [5, 40, 37, 59, 60]). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf <ref> [17, 18, 19] </ref> qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [35].
Reference: [20] <author> M.F. Chen. </author> <title> From Markov chains to non-equilibrium particle systems. </title> <publisher> World Scientific, </publisher> <address> Singapore, </address> <year> 1992. </year>
Reference-contexts: Pour les systemes de particules interactives, nos references de base sont Liggett [56] et Durrett [31]. Un point de vue original est celui de Chen <ref> [20] </ref>. La convergence des systemes de particules renormalises est traitee dans [31, 20], la reference de base etant Spohn [76]. Un panorama complet du sujet, et de ses relations avec la resolution de certaines equations aux derivees partielles, est donne dans l'ouvrage collectif [38]. <p> Pour les systemes de particules interactives, nos references de base sont Liggett [56] et Durrett [31]. Un point de vue original est celui de Chen [20]. La convergence des systemes de particules renormalises est traitee dans <ref> [31, 20] </ref>, la reference de base etant Spohn [76]. Un panorama complet du sujet, et de ses relations avec la resolution de certaines equations aux derivees partielles, est donne dans l'ouvrage collectif [38].
Reference: [21] <author> K.L. Chung. </author> <title> Markov chains with stationary transition probabilities. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1960. </year>
Reference-contexts: Les livres de Bouleau [11], Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung <ref> [21] </ref> et Kemeny et Snell [46]. Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor [42, 43]. C inlar [22] est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [34]. <p> Dans le cas de variables independantes, nous disposons pour cela du theoreme central limite pour en deduire des intervalles de confiance. Un theoreme central limite est vrai pour la suite (f (X n )) (voir <ref> [21] </ref> p. 94). Mais la variance asymptotique, qui determine l'amplitude des intervalles de confiance, n'est pas V ar p [f ]. Elle est en general impossible a calculer, et peut ^etre tres grande.
Reference: [22] <author> E. C inlar. </author> <title> Introduction to stochastic processes. </title> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor [42, 43]. C inlar <ref> [22] </ref> est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [34]. <p> Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple <ref> [22, 44] </ref>. Pour les systemes de particules interactives, nos references de base sont Liggett [56] et Durrett [31]. Un point de vue original est celui de Chen [20]. La convergence des systemes de particules renormalises est traitee dans [31, 20], la reference de base etant Spohn [76]. <p> de la fonction (de y) p (s; x; t; y). 24 3 Exploration markovienne 3.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [6, 15, 22, 32, 42, 46] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo. <p> Ces proprietes du spectre des matrices de transition reversibles sont des cas particuliers de proprietes plus generales que l'on deduit classiquement du theoreme de Perron-Frobenius (voir par exemple <ref> [22] </ref>). L'hypothese de reversibilite permet d'en donner une demonstration elementaire. Demonstration : Comme DP D 1 est symetrique, ses valeurs propres sont toutes reelles, et ce sont celles de P . Les valeurs propres de I DP D 1 et de I +DP D 1 sont positives ou nulles. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 56 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [6, 42, 43, 15, 22, 33, 12] </ref>). La presentation que nous proposons ici n'est pas classique. <p> L'hypothese que les (x) sont minores par une constante strictement positive assure que la suite T n des instants de saut du processus tend presque s^urement vers l'infini. Dans le cas particulier ou la fonction est constante, cette suite forme un processus de Poisson homogene d'intensite (voir <ref> [15, 22, 33, 12] </ref>). Un taux (x) nul correspondrait a une duree de sejour infinie dans l'etat x, qui serait alors qualifie d'etat absorbant. Comme pour la definition algorithmique des cha^ines de Markov 2.1, il est legitime de se demander quel est le degre de generalite de la definition 4.1. <p> Sur un espace d'etats denombrable, la plupart des processus de Markov d'inter^et pratique peuvent s'ecrire comme des versions temporisees de cha^ines de Markov (voir ci-dessous 4.1.4 et C inlar <ref> [22] </ref>). 4.1.3 Taux de transition et generateur Nous supposons desormais que l'espace d'etats E = fi; j; : : :g est fini. <p> de matrice de transition P = I + ou i i j6=i La definition de la cha^ine harmonisee s'etend de maniere evidente a des processus de Markov sur des ensembles infinis denombrables, pourvu que sup X ij &lt; 1 : On parle alors de processus harmonisable, ou processus uniformisable (voir <ref> [22, 44] </ref>). On peut voir la simulation de la cha^ine harmonisee comme une extension de la methode de rejet. Dans la version temporisee, la suite des instants de saut forme un processus de Poisson homogene d'intensite .
Reference: [23] <author> Y. Colin de Verdiere, Y. Pan, and B. Ycart. </author> <title> Singular limits of Schrodinger operators and Markov processes. </title> <address> Soumis, </address> <year> 1997. </year>
Reference-contexts: Colin de Verdiere et Y. Pan <ref> [23] </ref>.
Reference: [24] <author> A. De Masi, P. Ferrari, and J. Lebowitz. </author> <title> Reaction diffusion equations for interacting particle systems. </title> <journal> J. Stat. Phys., </journal> <volume> 44 </volume> <pages> 589-644, </pages> <year> 1986. </year>
Reference-contexts: Le resultat precis est le suivant, il est d^u a De Masi, Ferrari et Lebowitz <ref> [24] </ref> (voir aussi [31] p. 171-179).
Reference: [25] <author> L. Devroye. </author> <title> Non-uniform random variate generation. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb [39], Morgan [61], Rubinstein [69], Ripley [64], Kleijnen [48, 49]. Le plus complet sur le sujet est le livre de Devroye <ref> [25] </ref>. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay [77]. <p> Il existe plusieurs algorithmes efficaces pour la simulation de la loi normale N (0; 1) (voir Devroye <ref> [25] </ref>). Si X suit la loi N (0; 1), alors p ffitX suit la loi N (0; ffit). Il est important de bien comprendre le lien entre d'une part la discretisation du laplacien et la marche aleatoire symetrique, d'autre part le laplacien et le mouvement brownien. <p> En ce qui concerne la fonction Normale, qui retourne d 0 variables aleatoires independantes de loi N (0; 1), elle peut ^etre programmee en util-isant l'algorithme polaire qui retourne des couples de variables independantes (voir <ref> [25] </ref>). Dans ce cas, il faudra prendre garde a utiliser successivement les deux variables aleatoires retournees par cet algorithme. Ceci ne pose pas de probleme si d 0 est pair, mais peut conduire a doubler les instructions dans la boucle principale (simuler deux pas consecutifs) si d 0 est impair. <p> x 11 IR La fonction de repartition correspondante est F X (x) = P rob [X x] = (1 e x ) 11 IR + (x) : L'esperance et la variance valent respectivement IE [X] = 1 De nombreux algorithmes ont ete proposes pour la simulation des lois exponentielles (voir <ref> [25] </ref>). Nous retiendrons le plus simple, qui est l'algorithme d'inversion. X log (Random)= : Si X suit la loi E (1) alors X= suit la loi E (). En pratique, X represente une duree, typiquement le temps d'attente d'un evenement ou une duree de vie.
Reference: [26] <author> P. Diaconis and L. Saloff-Coste. </author> <title> What do we know about the Metropolis algorithm ? J. </title> <institution> Comp. Syst. Sci., </institution> <note> To appear. </note>
Reference-contexts: la litterature de nombreuses majorations, qui expriment en substance la m^eme idee de convergence a vitesse exponentielle vers la mesure d'equilibre, que ce soit dans le cas reversible ou dans le cas general, pour des cha^ines a temps discret ou a temps continu (voir Saloff-Coste [73] ou Diaconis et Saloff-Coste <ref> [26] </ref>). Voici une des plus simples. Proposition 3.5 Soit p une mesure de probabilite strictement positive sur E et P une matrice de transition irreductible aperiodique et p-reversible. <p> Malheureusement, on ne conna^it pas en general la valeur de ff. On est alors amene a en donner des majora-tions, et de nombreuses techniques ont ete inventees pour cela. Nous ne developperons pas cet aspect, pour lequel nous renvoyons a <ref> [73, 26] </ref>. Au vu de la proposition 3.6, il para^it naturel d'estimer IE p [f ] par une moyenne des valeurs prises par f sur une trajectoire de la cha^ine, suivie suffisamment longtemps. Ceci est justifie par le theoreme suivant. <p> Ces algorithmes ont ete testes sur tous les problemes d'optimisation celebres, et appliques dans de nombreux contextes. Une importante litterature s'est developpee autour de leurs performances et des resultats theoriques permettant de les justifier. Ce qui suit s'inspire de <ref> [3, 9, 26] </ref>. 3.2.1 Mesures de Gibbs Definition 3.3 Soit E un ensemble fini et p = (p i ) i2E une loi de probabilite strictement positive sur E.
Reference: [27] <author> P. Doyle and J. Snell. </author> <title> Random walks and electric networks. </title> <editor> M. A. A., </editor> <address> Washington, </address> <year> 1984. </year>
Reference-contexts: La matrice P est, a une transformation pres, ce que les combinatoriciens nomment le laplacien du graphe G (voir [10]). Cet exemple est a rapprocher de la proposition 2.4. Il existe une analogie etroite entre les cha^ines de Markov symetriques et les reseaux electriques (voir <ref> [27] </ref>). Les etats de E sont vus comme les sommets d'un reseau, relies par des lignes electriques. L'analogue de la probabilite de transition p ij est la conduc tance (inverse de la resistance) de la ligne reliant i a j.
Reference: [28] <author> E.J. Dudewicz and T.G. Ralley. </author> <title> The handbook of random number generation and testing with TESTRAND computer code. </title> <publisher> American Sciences Press Inc., </publisher> <address> Colum-bus., </address> <year> 1981. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [51] et Dudewicz et Ralley <ref> [28] </ref>. L'article de Ripley [65] est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb [39], Morgan [61], Rubinstein [69], Ripley [64], Kleijnen [48, 49].
Reference: [29] <author> M. Duflo. Methodes recursives aleatoires. Masson, Paris, </author> <year> 1990. </year>
Reference-contexts: Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay [77]. Les methodes MCMC (Monte-Carlo Markov Chain) sont traitees en particulier par Duflo <ref> [29, 30] </ref> et Robert [66, 67]. L'etude de la vitesse de convergence des cha^ines de Markov a donne lieu a une intense activite de publication ces dix dernieres annees. Nous avons surtout utilise Saloff-Coste [73].
Reference: [30] <author> M. Duflo. </author> <title> Algorithmes stochastiques. Mathematiques et applications 23. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference-contexts: Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay [77]. Les methodes MCMC (Monte-Carlo Markov Chain) sont traitees en particulier par Duflo <ref> [29, 30] </ref> et Robert [66, 67]. L'etude de la vitesse de convergence des cha^ines de Markov a donne lieu a une intense activite de publication ces dix dernieres annees. Nous avons surtout utilise Saloff-Coste [73].
Reference: [31] <author> R.T. Durrett. </author> <title> Ten lectures on particle systems. </title> <editor> In Ecole d'ete de probabilite de Saint-Flour XXIII (P. Bernard ed.), </editor> <title> L.N. </title> <journal> in Math. </journal> <volume> 1608, </volume> <pages> pages 97-201. </pages> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44]. Pour les systemes de particules interactives, nos references de base sont Liggett [56] et Durrett <ref> [31] </ref>. Un point de vue original est celui de Chen [20]. La convergence des systemes de particules renormalises est traitee dans [31, 20], la reference de base etant Spohn [76]. <p> Pour les systemes de particules interactives, nos references de base sont Liggett [56] et Durrett [31]. Un point de vue original est celui de Chen [20]. La convergence des systemes de particules renormalises est traitee dans <ref> [31, 20] </ref>, la reference de base etant Spohn [76]. Un panorama complet du sujet, et de ses relations avec la resolution de certaines equations aux derivees partielles, est donne dans l'ouvrage collectif [38]. <p> faire Si (X (5) &gt; 0 et X (6) &gt; 0) alors X (5) X (5) 1 finSi finSelon t t + 1 Jusqu'a (arr^et de la simulation) t t= 4.2.4 Systemes de particules interactives Nos deux references generales sur les systemes de particules interactives sont Liggett [56] et Durrett <ref> [31] </ref>. Il n'y a pas de difference mathematique entre un reseau de Petri markovien et un systeme de particules sur un ensemble fini de sites. Ce sont deux points de vue de modelisation assez differents, et les deux theories se sont developpees de maniere largement independante. <p> La solution de ces equations, si elle ne correspond pas aux "vraies" valeurs (l'hypothese d'independance des sites est bien s^ur fausse en general), fournit neanmoins de nombreux renseignements sur le phenomene, et dans certains cas une approximation de bonne qualite : voir <ref> [31] </ref> pour des exemples d'applications a des equilibres en dynamique des populations, et [7] pour un cas de bonne adequation avec les resultats de simulations. <p> V 0 = fy 2 ZZ d t.q. kyk rg : Jusqu'ici, nous n'avions parle que de systemes de particules a espaces d'etats finis. Ici l'espace d'etats devient E = F ZZ d , qui est non denombrable. Nous renvoyons a <ref> [56, 31] </ref> pour les questions theoriques de definition, d'existence et d'approximation des systemes infinis de particules. Nous considerons des systemes dits de spin, au sens ou la configuration courante ne peut ^etre modifiee qu'en un site au plus. <p> Le resultat precis est le suivant, il est d^u a De Masi, Ferrari et Lebowitz [24] (voir aussi <ref> [31] </ref> p. 171-179). <p> Neanmoins, le theoreme 5.1 concretise une coherence entre modelisation determi-niste (macroscopique) et modelisation stochastique (microscopique), tout a fait analogue a celle que nous avons deja soulignee dans 2.3.1. Nous illustrerons cette coherence sur un modele predateur-proie, tire de <ref> [31] </ref> p. 112. Exemple : Modele predateur-proie Dans ce modele, l'ocean est quadrille par les points de ZZ 3 , muni de sa structure de graphe naturelle, pour laquelle chaque site a 6 voisins.
Reference: [32] <author> W. Feller. </author> <title> An introduction to probability theory and its applications, volume I. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1968. </year>
Reference-contexts: Les notions de probabilites qui seront utilisees ici sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [15] ou Feller <ref> [32, 33] </ref>. Les livres de Bouleau [11], Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. <p> de la fonction (de y) p (s; x; t; y). 24 3 Exploration markovienne 3.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [6, 15, 22, 32, 42, 46] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo.
Reference: [33] <author> W. Feller. </author> <title> An introduction to probability theory and its applications, volume II. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1971. </year>
Reference-contexts: Les notions de probabilites qui seront utilisees ici sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [15] ou Feller <ref> [32, 33] </ref>. Les livres de Bouleau [11], Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 56 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [6, 42, 43, 15, 22, 33, 12] </ref>). La presentation que nous proposons ici n'est pas classique. <p> L'hypothese que les (x) sont minores par une constante strictement positive assure que la suite T n des instants de saut du processus tend presque s^urement vers l'infini. Dans le cas particulier ou la fonction est constante, cette suite forme un processus de Poisson homogene d'intensite (voir <ref> [15, 22, 33, 12] </ref>). Un taux (x) nul correspondrait a une duree de sejour infinie dans l'etat x, qui serait alors qualifie d'etat absorbant. Comme pour la definition algorithmique des cha^ines de Markov 2.1, il est legitime de se demander quel est le degre de generalite de la definition 4.1. <p> Sur K iterations, l'echelle de temps aura ete incrementee de la somme de K variables exponentielles independantes. Bien que ces variables ne soient pas de m^eme loi, le theoreme central limite s'applique dans ce cas (voir Feller <ref> [33] </ref> p. 262). On pourra donc remplacer l'incrementation totale sur les K pas de temps par une variable aleatoire suivant une loi normale de m^eme moyenne et de m^eme variance.
Reference: [34] <author> G.S. Fishman. </author> <title> Monte Carlo concepts algorithms and applications. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1996. </year> <month> 102 </month>
Reference-contexts: Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor [42, 43]. C inlar [22] est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman <ref> [34] </ref>. La construction des generateurs pseudo-aleatoires, ou comment programmer efficacement une fonction Random, est un probleme que nous considererons arbitrairement comme resolu par Marsaglia et Zaman [57, 58], bien qu'une litterature importante continue a se developper sur la question.
Reference: [35] <author> M.I. Freidlin and A.D. Wentzell. </author> <title> Random perturbations of dynamical systems. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1984. </year>
Reference-contexts: Toute valeur propre ` (") est donc d'ordre " h ou h h fl . Les plus petites d'entre elles sont d'ordre " h fl exactement, ce qui justifie la proposition 3.9. Cette description est classiquement deduite de la theorie de Freidlin et Wentzell <ref> [35] </ref>. Nous ne donnerons pas une demonstration complete de la proposi tion 3.10, mais simplement une idee de justification algebrique. <p> Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [17, 18, 19] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell <ref> [35] </ref>. Nous suivons sa presentation sans rentrer dans les details mathematiques, qui sont tres techniques. 3.3.1 Version classique Les algorithmes genetiques s'inspirent des mecanismes de la selection naturelle, comme le recuit simule s'inspire de principes physiques. La fonction a optimiser est ici l'adaptation et c'est son maximum que l'on recherche.
Reference: [36] <author> E. Gelenbe and G. Pujolle. </author> <title> Introduction aux reseaux de files d'attente. </title> <publisher> Eyrolles, </publisher> <address> Paris, </address> <year> 1985. </year>
Reference-contexts: La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [36, 45, 68, 70, 79] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [37] <author> D. Goldberg. </author> <title> Genetic algorithms in search, optimization and machine learning. </title> <publisher> Addison-Wesley, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: Nous avons surtout utilise Saloff-Coste [73]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [5, 16, 37, 40, 59, 60, 81] </ref>). La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante [68, 70, 72, 71, 78, 80, 82]. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [5, 40, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [17, 18, 19] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [35].
Reference: [38] <author> C. Graham, T.G. Kurtz, S. Meleard, P.E. Protter, M. Pulvirenti, and D. Talay. </author> <title> Probabilistic Models for Nonlinear Partial Differential Equations. </title> <editor> L. N. </editor> <publisher> in Math. 1627 Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference-contexts: La convergence des systemes de particules renormalises est traitee dans [31, 20], la reference de base etant Spohn [76]. Un panorama complet du sujet, et de ses relations avec la resolution de certaines equations aux derivees partielles, est donne dans l'ouvrage collectif <ref> [38] </ref>. <p> Nous ne developperons ce lien que pour certaines de ses consequences numeriques. Encore ne traiterons-nous pas la question de la convergence des methodes proposees (voir par exemple Talay <ref> [38] </ref> p. 148-196). Les quelques exemples que nous donnons ici ne constituent qu'une introduction a un sujet en plein developpement. Les generalisations consistent a introduire un certain degre de dependance entre les differentes trajectoires simulees Nous les aborderons dans la derniere partie. <p> Notre reference generale sera ici l'ouvrage collectif <ref> [38] </ref>, et en particulier les contributions de Meleard p. 42-95 et Pulvirenti p. 96-126 (voir aussi [52]). Nous nous contenterons de degager quelques idees generales sur la propagation du chaos et la resolution de certaines equations aux derivees partielles non lineaires par des methodes stochastiques. Nous renvoyons a [38] et aux <p> l'ouvrage collectif <ref> [38] </ref>, et en particulier les contributions de Meleard p. 42-95 et Pulvirenti p. 96-126 (voir aussi [52]). Nous nous contenterons de degager quelques idees generales sur la propagation du chaos et la resolution de certaines equations aux derivees partielles non lineaires par des methodes stochastiques. Nous renvoyons a [38] et aux nombreuses references de cet ouvrage pour le traitement mathematique, qui est d'un niveau souvent tres superieur a celui de ces notes. <p> Il s'agit en general d'un ensemble de N processus de diffusion, (fX i (t) ; t 0g) iN dont chacun interagit de maniere symetrique avec tous les autres, les interactions individuelles restant faibles. Nous precisons ce cadre a l'aide de l'exemple introductif de Pulvirenti, <ref> [38] </ref> p. 97. Exemple : Soit K une application de IR d dans IR d , de classe C 1 . <p> La mesure empirique N (t) converge vers une mesure deterministe, par la loi des grands nombres. De ces deux proprietes, on concoit que la premiere entra^ine la seconde. Elles sont en fait equivalentes pour des lois echangeables, au sens du theoreme suivant (voir par exemple Meleard <ref> [38] </ref> p. 66). <p> Nous ne donnerons pas les conditions d'existence et d'unicite de la solution de (5.18) (voir <ref> [38] </ref> p. 46). L'algorithme de simulation approchee de cette solution est tout a fait naturel. <p> Ce systeme verifie la propriete de propagation du chaos, et pour des conditions initiales independantes, sa mesure empirique N (t) converge vers la solution de (5.21). Plutot que de detailler le resultat theorique de convergence, pour lequel nous renvoyons a Meleard <ref> [38] </ref>, p. 54-63, nous donnerons un algorithme de simulation, melangeant les techniques des paragraphes 2.3.2 et 4.2.4. L'algorithme que nous proposons n'est evidemment pas le seul possible. Il nous semble plus rapide que celui de Meleard [38] p. 63. L'idee est cependant analogue. <p> que de detailler le resultat theorique de convergence, pour lequel nous renvoyons a Meleard <ref> [38] </ref>, p. 54-63, nous donnerons un algorithme de simulation, melangeant les techniques des paragraphes 2.3.2 et 4.2.4. L'algorithme que nous proposons n'est evidemment pas le seul possible. Il nous semble plus rapide que celui de Meleard [38] p. 63. L'idee est cependant analogue. Elle con-siste a simuler le vecteur des N diffusions, en lui superposant un processus de sauts, simule par la technique generale de la cha^ine harmonisee.
Reference: [39] <author> J.M. </author> <title> Hammersley and Handscomb D.C. Monte-Carlo methods. </title> <publisher> Methuen, </publisher> <address> London, </address> <year> 1964. </year>
Reference-contexts: L'article de Ripley [65] est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb <ref> [39] </ref>, Morgan [61], Rubinstein [69], Ripley [64], Kleijnen [48, 49]. Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13].
Reference: [40] <author> J.H. Holland. </author> <title> Adaptation in natural and artificial systems. </title> <publisher> The University of Michigan Press, </publisher> <address> Ann Arbor, </address> <year> 1975. </year>
Reference-contexts: Nous avons surtout utilise Saloff-Coste [73]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [5, 16, 37, 40, 59, 60, 81] </ref>). La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante [68, 70, 72, 71, 78, 80, 82]. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [5, 40, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [17, 18, 19] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [35].
Reference: [41] <author> I. Karatzas and S.E. Shreve. </author> <title> Brownian motion and stochastic calculus. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Discuter des differentes definitions et caracterisations du mouvement brownien sortirait du cadre de ce cours. Nous renvoyons pour cela au cours aux tres nombreuses references de la litterature, en particulier <ref> [15, 41] </ref>. <p> processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (2.3) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [55, 12, 41, 50] </ref>). <p> Nous ne les aborderons pas (voir [50] p. 511-527). 18 2.3.3 Problemes de Dirichlet C'est la generalisation du probleme (2.1) que nous considerons ici. La presentation que nous en faisons est celle de <ref> [41] </ref> p. 364-365 (voir aussi [13] p. 237). Les notations sont celles des paragraphes precedents. Supposons que les applications et oe ne dependent pas de t (cas homogene). L'application va de IR d dans IR d , oe va de IR d dans M dfid 0 (IR). <p> Ce qui suit est tire de Karatzas et Shreve <ref> [41] </ref> p. 366-369. Soient et oe deux fonctions de IR + fi IR d dans IR d et M dfid (IR) respectivement. <p> sous lesquelles les affirmations qui vont suivre sont vraies portent sur * la regularite des fonctions et oe, ainsi que des fonctions a et c du probleme (2.12) ci-dessous, * la croissance lineaire ou polynomiale de ces m^emes fonctions, * l'ellipticite uniforme des operateurs A t . (Se reporter a <ref> [41] </ref> pour les enonces precis). On note fX (t) ; t 0g le processus de diffusion, solution du probleme de Cauchy (2.2). Si et oe sont suffisamment regulieres, alors le processus fX (t) ; t 0g admet un noyau de transition, note p (s; x; t; y).
Reference: [42] <author> S. Karlin. </author> <title> A first course in stochastic processes. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1966. </year>
Reference-contexts: Les livres de Bouleau [11], Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor <ref> [42, 43] </ref>. C inlar [22] est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [34]. <p> de la fonction (de y) p (s; x; t; y). 24 3 Exploration markovienne 3.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [6, 15, 22, 32, 42, 46] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 56 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [6, 42, 43, 15, 22, 33, 12] </ref>). La presentation que nous proposons ici n'est pas classique. <p> Ces N echelles de temps sont independantes. La 73 superposition de N echelles de temps independantes est encore un processus de Poisson homogene, d'intensite (1) + + (N) (voir <ref> [42] </ref> p. 226). Cette intensite est l'horloge interne du processus fZ t ; t 0g. Quand le processus fZ t g entre dans l'etat (i 1 ; : : : ; i N ), le temps avant le prochain saut est donc exponentiel de parametre (1) + + (N) .
Reference: [43] <author> S. Karlin and H.M. Taylor. </author> <title> A second course in stochastic processes. </title> <publisher> Academic Press, </publisher> <address> San Diego, </address> <year> 1981. </year>
Reference-contexts: Les livres de Bouleau [11], Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor <ref> [42, 43] </ref>. C inlar [22] est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [34]. <p> 2 [i] F [i] F 2 [i] somme EF somme EF + EF [i] finPour n n+1 Jusqu'a (n Palier) Jusqu'a (arr^et de la simulation) 56 4 Cha^ines a temps continu Les cha^ines de Markov a temps continu, ou processus markoviens de saut, sont traitees dans de nombreux manuels (voir <ref> [6, 42, 43, 15, 22, 33, 12] </ref>). La presentation que nous proposons ici n'est pas classique. <p> C'est un des avantages de la cha^ine harmonisee par rapport a la cha^ine incluse pour ce qui est de la simulation. Exemple : File M/M/1. La file M/M/1 (voir par exemple <ref> [6, 43, 78, 79] </ref>) est le processus de naissance et de mort sur IN dont les taux de transition sont ij = si i 0 ; j = i + 1 ; = 0 dans tous les autres cas : 68 Pour la simulation par la cha^ine incluse, on aura p
Reference: [44] <author> J. Keilson. </author> <title> Markov chain models rarity and exponentiality. </title> <booktitle> Applied Mathematical Sciences 28. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1979. </year>
Reference-contexts: Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple <ref> [22, 44] </ref>. Pour les systemes de particules interactives, nos references de base sont Liggett [56] et Durrett [31]. Un point de vue original est celui de Chen [20]. La convergence des systemes de particules renormalises est traitee dans [31, 20], la reference de base etant Spohn [76]. <p> de matrice de transition P = I + ou i i j6=i La definition de la cha^ine harmonisee s'etend de maniere evidente a des processus de Markov sur des ensembles infinis denombrables, pourvu que sup X ij &lt; 1 : On parle alors de processus harmonisable, ou processus uniformisable (voir <ref> [22, 44] </ref>). On peut voir la simulation de la cha^ine harmonisee comme une extension de la methode de rejet. Dans la version temporisee, la suite des instants de saut forme un processus de Poisson homogene d'intensite .
Reference: [45] <author> F.P. Kelly. </author> <title> Reversibility and Stochastic Networks. </title> <publisher> Wiley, </publisher> <address> London, </address> <year> 1979. </year>
Reference-contexts: On dit que p est une mesure reversible pour la cha^ine de Markov de matrice de transition P , ou que la matrice P est p-reversible, si p i p ij = p j p ji ; 8i; j 2 E : (3.1) Le livre de Kelly <ref> [45] </ref> est une bonne reference generale sur la reversibilite et ses applications. La relation (3.1) s'appelle condition de bilan detaille. Observons tout d'abord qu'une mesure reversible est necessairement stationnaire. <p> L'analogue de la probabilite de transition p ij est la conduc tance (inverse de la resistance) de la ligne reliant i a j. Des criteres pour verifier si une matrice de transition donnee admet ou non une mesure reversible ont ete donnes par Kolmogorov (voir <ref> [45] </ref>). Nous nous interesserons plutot ici a la construction d'une matrice de transition p-reversible, quand p est une mesure donnee. Voici une methode generale. <p> La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [36, 45, 68, 70, 79] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [46] <author> J.G. Kemeny and J.L. Snell. </author> <title> Finite Markov chains. </title> <publisher> Van Nostrand, Princeton, </publisher> <year> 1960. </year>
Reference-contexts: Les livres de Bouleau [11], Snell [75] et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell <ref> [46] </ref>. Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor [42, 43]. C inlar [22] est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [34]. <p> de la fonction (de y) p (s; x; t; y). 24 3 Exploration markovienne 3.1 Comportement asymptotique Les resultats decrivant la classification des etats d'une cha^ine de Markov sur un ensemble fini, ses mesures stationnaires, la convergence vers ces mesures, sont extr^emement classiques et se retrouvent dans de nombreux manuels <ref> [6, 15, 22, 32, 42, 46] </ref>. Nous avons choisi ici de nous limiter aux cha^ines de Markov a temps discret reversibles, puisque ce sont elles que l'on rencontre dans la plupart des methodes markoviennes de Monte-Carlo. <p> Ce sont en quelque sorte les boutons de reglage de l'algorithme. La cha^ine de Markov (X T n ) est irreductible et aperiodique. Elle converge donc en loi vers une mesure stationnaire unique p T (voir par exemple <ref> [46] </ref>). On souhaite verifier 52 que lorsque T tend vers 0, cette mesure stationnaire se concentre sur les populations optimales. Contrairement au cas du recuit simule, ce n'est pas toujours vrai.
Reference: [47] <author> W.J. Kennedy and J.E. </author> <title> Gentle. Statistical computing. </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, </address> <year> 1980. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [51] et Dudewicz et Ralley [28]. L'article de Ripley [65] est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle <ref> [47] </ref>, Hammersley et Handscomb [39], Morgan [61], Rubinstein [69], Ripley [64], Kleijnen [48, 49]. Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13].
Reference: [48] <author> J.P.C. Kleijnen. </author> <title> Statistical techniques in simulation, Part I. </title> <publisher> Marcel Dekker, Inc., </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: L'article de Ripley [65] est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb [39], Morgan [61], Rubinstein [69], Ripley [64], Kleijnen <ref> [48, 49] </ref>. Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay [77].
Reference: [49] <author> J.P.C. Kleijnen and W. Van Groenendaal. </author> <title> Simulation, a statistical perspective. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: L'article de Ripley [65] est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb [39], Morgan [61], Rubinstein [69], Ripley [64], Kleijnen <ref> [48, 49] </ref>. Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay [77].
Reference: [50] <author> P.E. Kloeden and E. Platen. </author> <title> Numerical solution of stochastic differential equations. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1992. </year>
Reference-contexts: Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen <ref> [50] </ref> est la reference indispensable. Pour une introduction, voir Talay [77]. Les methodes MCMC (Monte-Carlo Markov Chain) sont traitees en particulier par Duflo [29, 30] et Robert [66, 67]. <p> Sur cette coherence entre modelisation deterministe et aleatoire, problemes differentiels et simulation de proces-sus de diffusion, on pourra se reporter a la troisieme partie de Kloeden et Platen <ref> [50] </ref> ainsi qu'a Talay [77] et aux autres articles du m^eme ouvrage. Le rapport entre le mouvement brownien et le laplacien se generalise aux processus de diffusion. Cela fournit le principe de methodes de Monte-Carlo pour la resolution de nombreux problemes differentiels. <p> Nous en donnerons plusieurs exemples dans les paragraphes suivants. Nous examinons tout d'abord la simulation des processus de diffusion. 15 2.3.2 Simulation des processus de diffusion La reference generale sur le sujet est le livre de Kloeden et Platen <ref> [50] </ref>. Nous ne presentons ici que la methode la plus simple, qui est la generalisation aux processus de diffusion de la methode d'Euler pour les solutions d'equations differentielles ordinaires. <p> processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (2.3) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [55, 12, 41, 50] </ref>). <p> Ceci ne pose pas de probleme si d 0 est pair, mais peut conduire a doubler les instructions dans la boucle principale (simuler deux pas consecutifs) si d 0 est impair. Il existe de nombreuses autres methodes pour simuler les processus de diffusion (voir Kloeden et Platen <ref> [50] </ref>). La methode d'Euler-Maruyama, si elle est la moins precise de toutes, presente l'avantage d'^etre la plus naturelle, la plus facile a programmer, et la plus rapide a l'execution. <p> Dans le cas deterministe, la methode d'Euler est connue pour "cumuler les erreurs" (au sens ou l'ecart entre la solution exacte et son approximation numerique augmente avec le temps). C'est aussi le cas pour la version stochastique. Le probleme de la stabilite numerique est aborde dans <ref> [50] </ref> p. 331-337. Des techniques de reduction de variance appropriees aux methodes de Monte-Carlo utilisant ce type de simulation ont ete proposees. Nous ne les aborderons pas (voir [50] p. 511-527). 18 2.3.3 Problemes de Dirichlet C'est la generalisation du probleme (2.1) que nous considerons ici. <p> C'est aussi le cas pour la version stochastique. Le probleme de la stabilite numerique est aborde dans <ref> [50] </ref> p. 331-337. Des techniques de reduction de variance appropriees aux methodes de Monte-Carlo utilisant ce type de simulation ont ete proposees. Nous ne les aborderons pas (voir [50] p. 511-527). 18 2.3.3 Problemes de Dirichlet C'est la generalisation du probleme (2.1) que nous considerons ici. La presentation que nous en faisons est celle de [41] p. 364-365 (voir aussi [13] p. 237). Les notations sont celles des paragraphes precedents.
Reference: [51] <author> D.E. Knuth. </author> <booktitle> The art of computer programming, volume 2, seminumerical algorithms. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, </address> <year> 1981. </year> <month> 103 </month>
Reference-contexts: La construction des generateurs pseudo-aleatoires, ou comment programmer efficacement une fonction Random, est un probleme que nous considererons arbitrairement comme resolu par Marsaglia et Zaman [57, 58], bien qu'une litterature importante continue a se developper sur la question. Deux references de base sont les livres de Knuth <ref> [51] </ref> et Dudewicz et Ralley [28]. L'article de Ripley [65] est une bonne introduction.
Reference: [52] <author> B. Lapeyre, E. Pardoux, and R. Sentis. </author> <title> Methodes de Monte-Carlo pour les equations de transport et de diffusion. Mathematiques et applications 29. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1997. </year>
Reference-contexts: Un panorama complet du sujet, et de ses relations avec la resolution de certaines equations aux derivees partielles, est donne dans l'ouvrage collectif [38]. On pourra aussi se reporter a l'ouvrage recent de Lapeyre, Pardoux et Sentis <ref> [52] </ref>. 3 4 2 Methodes markoviennes a temps fini 2.1 Simulation des cha^ines de Markov 2.1.1 Definition algorithmique Une cha^ine de Markov est classiquement definie comme une suite de variables aleatoires pour laquelle la meilleure prediction que l'on puisse faire pour l'etape n+1 si on conna^it toutes les valeurs anterieures est <p> Notre reference generale sera ici l'ouvrage collectif [38], et en particulier les contributions de Meleard p. 42-95 et Pulvirenti p. 96-126 (voir aussi <ref> [52] </ref>). Nous nous contenterons de degager quelques idees generales sur la propagation du chaos et la resolution de certaines equations aux derivees partielles non lineaires par des methodes stochastiques.
Reference: [53] <author> P. J. Laurent. </author> <title> Les methodes de Monte-Carlo. </title> <institution> Universite Joseph Fourier, Grenoble, </institution> <year> 1966. </year>
Reference-contexts: Les quelques exemples que nous donnons ici ne constituent qu'une introduction a un sujet en plein developpement. Les generalisations consistent a introduire un certain degre de dependance entre les differentes trajectoires simulees Nous les aborderons dans la derniere partie. Nous commencons par un exemple, tire de <ref> [53] </ref>. 2.3.1 Exemple Appliquons la methode du paragraphe 2.2.2 a la discretisation d'un probleme de Dirich-let simple. Soit D le carre unite ouvert, @D son bord.
Reference: [54] <author> E.L. Lawler, J.K. Lensra, A.H.G. Rinnooy Kan, </author> <title> and D.B. Shmoys. The traveling salesman problem. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: En general plusieurs choix sont possibles et on pourra opter pour une structure de voisinage qui permette une exploration plus rapide de l'espace si cela n'alourdit pas trop l'algorithme. A titre d'exemple, nous traitons ci-dessous un des problemes les plus celebres de l'optimisation combinatoire (voir <ref> [54, 63] </ref>). Exemple : Le probleme du voyageur de commerce [54, 63]. <p> A titre d'exemple, nous traitons ci-dessous un des problemes les plus celebres de l'optimisation combinatoire (voir <ref> [54, 63] </ref>). Exemple : Le probleme du voyageur de commerce [54, 63].
Reference: [55] <author> A. Le Breton. Calcul stochastique. Cours de DEA UJF, </author> <year> 1996. </year>
Reference-contexts: processus stochastique fX (t) ; t 2 [0; T ]g, a trajectoires continues, verifiant pour tout t 2 [0; T ], X (t) = X 0 + 0 Z t oe (t; X (t))dW t ; (2.3) ou la seconde integrale est une integrale stochastique au sens de It^o (voir <ref> [55, 12, 41, 50] </ref>).
Reference: [56] <author> T.M. Liggett. </author> <title> Interacting Particle Systems. </title> <publisher> Springer, </publisher> <address> New York, </address> <year> 1985. </year>
Reference-contexts: Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44]. Pour les systemes de particules interactives, nos references de base sont Liggett <ref> [56] </ref> et Durrett [31]. Un point de vue original est celui de Chen [20]. La convergence des systemes de particules renormalises est traitee dans [31, 20], la reference de base etant Spohn [76]. <p> type = fl faire Si (X (5) &gt; 0 et X (6) &gt; 0) alors X (5) X (5) 1 finSi finSelon t t + 1 Jusqu'a (arr^et de la simulation) t t= 4.2.4 Systemes de particules interactives Nos deux references generales sur les systemes de particules interactives sont Liggett <ref> [56] </ref> et Durrett [31]. Il n'y a pas de difference mathematique entre un reseau de Petri markovien et un systeme de particules sur un ensemble fini de sites. Ce sont deux points de vue de modelisation assez differents, et les deux theories se sont developpees de maniere largement independante. <p> V 0 = fy 2 ZZ d t.q. kyk rg : Jusqu'ici, nous n'avions parle que de systemes de particules a espaces d'etats finis. Ici l'espace d'etats devient E = F ZZ d , qui est non denombrable. Nous renvoyons a <ref> [56, 31] </ref> pour les questions theoriques de definition, d'existence et d'approximation des systemes infinis de particules. Nous considerons des systemes dits de spin, au sens ou la configuration courante ne peut ^etre modifiee qu'en un site au plus. <p> C'est une formule analogue qui definit le generateur dans le cas d'un systeme infini de particules. f (j) = x2ZZ X c i (x; j)(f (j i ou f designe une fonction de E dans IR. Nous renvoyons a Liggett <ref> [56] </ref> pour les conditions precises sous lesquelles la formule (5.2) definit effectivement un generateur de Markov, et pour la definition du domaine de cet operateur.
Reference: [57] <author> G. Marsaglia and A. Zaman. </author> <title> Toward a universal random number generator. </title> <journal> Stat. Prob. Lett., </journal> <volume> 8 </volume> <pages> 35-39, </pages> <year> 1990. </year>
Reference-contexts: C inlar [22] est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [34]. La construction des generateurs pseudo-aleatoires, ou comment programmer efficacement une fonction Random, est un probleme que nous considererons arbitrairement comme resolu par Marsaglia et Zaman <ref> [57, 58] </ref>, bien qu'une litterature importante continue a se developper sur la question. Deux references de base sont les livres de Knuth [51] et Dudewicz et Ralley [28]. L'article de Ripley [65] est une bonne introduction. <p> En dehors des generateurs livres avec tous les compilateurs courants, plusieurs excellents generateurs sont disponibles sous des formes diverses, en particulier le generateur ULTRA de Marsaglia et Zaman <ref> [57, 58] </ref>. En pratique une cha^ine de Markov est simulee de maniere iterative comme le dit la definition 2.1. Une initialisation dans E est d'abord choisie (aleatoire ou pas). Puis chaque nouveau pas est simule selon une loi de probabilite dependant du point atteint precedemment.
Reference: [58] <author> G. Marsaglia and A. Zaman. </author> <title> A new class of random number generators. </title> <journal> Ann. Appl. Probab., </journal> <volume> 1 </volume> <pages> 462-480, </pages> <year> 1991. </year>
Reference-contexts: C inlar [22] est particulierement clair. La reference recente la plus complete pour l'utilisation du hasard sur ordinateur est le livre de Fishman [34]. La construction des generateurs pseudo-aleatoires, ou comment programmer efficacement une fonction Random, est un probleme que nous considererons arbitrairement comme resolu par Marsaglia et Zaman <ref> [57, 58] </ref>, bien qu'une litterature importante continue a se developper sur la question. Deux references de base sont les livres de Knuth [51] et Dudewicz et Ralley [28]. L'article de Ripley [65] est une bonne introduction. <p> En dehors des generateurs livres avec tous les compilateurs courants, plusieurs excellents generateurs sont disponibles sous des formes diverses, en particulier le generateur ULTRA de Marsaglia et Zaman <ref> [57, 58] </ref>. En pratique une cha^ine de Markov est simulee de maniere iterative comme le dit la definition 2.1. Une initialisation dans E est d'abord choisie (aleatoire ou pas). Puis chaque nouveau pas est simule selon une loi de probabilite dependant du point atteint precedemment.
Reference: [59] <author> Z. Michalewicz. </author> <title> Genetic algorithms + Data structures = Evolution programs, </title> <publisher> 3rd ed. Springer, </publisher> <address> New-York, </address> <year> 1996. </year>
Reference-contexts: Nous avons surtout utilise Saloff-Coste [73]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [5, 16, 37, 40, 59, 60, 81] </ref>). La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante [68, 70, 72, 71, 78, 80, 82]. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [5, 40, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [17, 18, 19] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [35].
Reference: [60] <author> M. Mitchell. </author> <title> An introduction to genetic algorithms. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1996. </year>
Reference-contexts: Nous avons surtout utilise Saloff-Coste [73]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [5, 16, 37, 40, 59, 60, 81] </ref>). La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante [68, 70, 72, 71, 78, 80, 82]. <p> L'analogie avec la theorie de l'evolution constitue un attrait psychologique important de ces algorithmes, sur lesquels une litterature extr^emement etendue s'est developpee en peu de temps (voir <ref> [5, 40, 37, 59, 60] </ref>). Les resultats mathematiques rigoureux sont encore rares. C'est R. Cerf [17, 18, 19] qui dans sa these a le premier developpe une theorie asymptotique fondee sur la theorie des perturbations de Freidlin et Wentzell [35].
Reference: [61] <author> B.J.T. Morgan. </author> <title> Elements of simulation. </title> <publisher> Chapman and Hall, </publisher> <address> London, </address> <year> 1984. </year>
Reference-contexts: L'article de Ripley [65] est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb [39], Morgan <ref> [61] </ref>, Rubinstein [69], Ripley [64], Kleijnen [48, 49]. Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable.
Reference: [62] <author> R. Motwani and P. Raghavan. </author> <title> Randomized algorithms. </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year>
Reference-contexts: on revient a la cha^ine de matrice de transition P , son equilibre est donc atteint bien avant que toutes les coordonnees de la configuration de depart aient ete modifiees, ne serait-ce qu'une fois. 3.1.4 Denombrement par cha^ine de Markov Ce qui suit s'inspire de Aldous [1, 2] (voir aussi <ref> [62, 74] </ref>).
Reference: [63] <author> G. Reinelt. </author> <title> The traveling salesman: computational solutions for TSP applications. </title> <editor> L. N. </editor> <booktitle> in Computer Science 840. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: En general plusieurs choix sont possibles et on pourra opter pour une structure de voisinage qui permette une exploration plus rapide de l'espace si cela n'alourdit pas trop l'algorithme. A titre d'exemple, nous traitons ci-dessous un des problemes les plus celebres de l'optimisation combinatoire (voir <ref> [54, 63] </ref>). Exemple : Le probleme du voyageur de commerce [54, 63]. <p> A titre d'exemple, nous traitons ci-dessous un des problemes les plus celebres de l'optimisation combinatoire (voir <ref> [54, 63] </ref>). Exemple : Le probleme du voyageur de commerce [54, 63].
Reference: [64] <author> B.D. Ripley. </author> <title> Stochastic simulation. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: L'article de Ripley [65] est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb [39], Morgan [61], Rubinstein [69], Ripley <ref> [64] </ref>, Kleijnen [48, 49]. Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable.
Reference: [65] <author> B.D. Ripley. </author> <title> Thoughts on pseudorandom numbers. </title> <journal> J. Comput. Appl. Math., </journal> <volume> 31 </volume> <pages> 153-163, </pages> <year> 1990. </year>
Reference-contexts: Deux references de base sont les livres de Knuth [51] et Dudewicz et Ralley [28]. L'article de Ripley <ref> [65] </ref> est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb [39], Morgan [61], Rubinstein [69], Ripley [64], Kleijnen [48, 49].
Reference: [66] <editor> C.P. Robert. L'Analyse Statistique Bayesienne. Economica, </editor> <address> Paris, </address> <year> 1992. </year>
Reference-contexts: Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay [77]. Les methodes MCMC (Monte-Carlo Markov Chain) sont traitees en particulier par Duflo [29, 30] et Robert <ref> [66, 67] </ref>. L'etude de la vitesse de convergence des cha^ines de Markov a donne lieu a une intense activite de publication ces dix dernieres annees. Nous avons surtout utilise Saloff-Coste [73].
Reference: [67] <editor> C.P. Robert. Methodes de Monte-Carlo par cha^ines de Markov. Economica, </editor> <address> Paris, </address> <year> 1996. </year>
Reference-contexts: Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay [77]. Les methodes MCMC (Monte-Carlo Markov Chain) sont traitees en particulier par Duflo [29, 30] et Robert <ref> [66, 67] </ref>. L'etude de la vitesse de convergence des cha^ines de Markov a donne lieu a une intense activite de publication ces dix dernieres annees. Nous avons surtout utilise Saloff-Coste [73].
Reference: [68] <author> T.G. Robertazzi. </author> <title> Computer networks and systems: queuing theory and performance evaluation. </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990. </year>
Reference-contexts: La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante <ref> [68, 70, 72, 71, 78, 80, 82] </ref>. Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44]. <p> La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [36, 45, 68, 70, 79] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [69] <author> R.Y. Rubinstein. </author> <title> Simulation and the Monte-Carlo method. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1981. </year>
Reference-contexts: L'article de Ripley [65] est une bonne introduction. La simulation des lois de probabilite fait l'objet au moins d'un chapitre dans de tres nombreux manuels comme ceux de Kennedy et Gentle [47], Hammersley et Handscomb [39], Morgan [61], Rubinstein <ref> [69] </ref>, Ripley [64], Kleijnen [48, 49]. Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. <p> Il est m^eme possible de calculer toute la matrice (I A) 1 . Des variantes de cet algorithme ont ete proposees qui n'utilisent qu'une seule trajectoire, suivie suffisamment longtemps (voir Rubinstein <ref> [69] </ref> p. 158-169). Comme on l'aura constate, on dispose d'une grande latitude pour choisir la loi initiale ainsi que les probabilites de transition.
Reference: [70] <author> R.Y. Rubinstein. </author> <title> Monte-Carlo optimization, simulation and sensitivity of queuing networks. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante <ref> [68, 70, 72, 71, 78, 80, 82] </ref>. Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44]. <p> La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [36, 45, 68, 70, 79] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [71] <author> R.Y. Rubinstein and B. Melamed. </author> <title> Efficient simulation and Monte-Carlo methods. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1997. </year>
Reference-contexts: La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante <ref> [68, 70, 72, 71, 78, 80, 82] </ref>. Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44].
Reference: [72] <author> R.Y. Rubinstein and A. Shapiro. </author> <title> Discrete event systems: sensitivity analysis and stochastic optimization by the score function method. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1993. </year>
Reference-contexts: La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante <ref> [68, 70, 72, 71, 78, 80, 82] </ref>. Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44].
Reference: [73] <author> L. Saloff-Coste. </author> <title> Lectures on finite Markov chains. </title> <institution> Notes de Cours, Ecole d'ete de probabilites de Saint-Flour, a para^itre, </institution> <year> 1996. </year>
Reference-contexts: Les methodes MCMC (Monte-Carlo Markov Chain) sont traitees en particulier par Duflo [29, 30] et Robert [66, 67]. L'etude de la vitesse de convergence des cha^ines de Markov a donne lieu a une intense activite de publication ces dix dernieres annees. Nous avons surtout utilise Saloff-Coste <ref> [73] </ref>. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple [5, 16, 37, 40, 59, 60, 81]). <p> Il existe dans la litterature de nombreuses majorations, qui expriment en substance la m^eme idee de convergence a vitesse exponentielle vers la mesure d'equilibre, que ce soit dans le cas reversible ou dans le cas general, pour des cha^ines a temps discret ou a temps continu (voir Saloff-Coste <ref> [73] </ref> ou Diaconis et Saloff-Coste [26]). Voici une des plus simples. Proposition 3.5 Soit p une mesure de probabilite strictement positive sur E et P une matrice de transition irreductible aperiodique et p-reversible. <p> Malheureusement, on ne conna^it pas en general la valeur de ff. On est alors amene a en donner des majora-tions, et de nombreuses techniques ont ete inventees pour cela. Nous ne developperons pas cet aspect, pour lequel nous renvoyons a <ref> [73, 26] </ref>. Au vu de la proposition 3.6, il para^it naturel d'estimer IE p [f ] par une moyenne des valeurs prises par f sur une trajectoire de la cha^ine, suivie suffisamment longtemps. Ceci est justifie par le theoreme suivant.
Reference: [74] <author> A. Sinclair. </author> <title> Algorithms for random generation and counting: a Markov chain approach. </title> <publisher> Birkhauser, </publisher> <address> Boston, </address> <year> 1993. </year>
Reference-contexts: on revient a la cha^ine de matrice de transition P , son equilibre est donc atteint bien avant que toutes les coordonnees de la configuration de depart aient ete modifiees, ne serait-ce qu'une fois. 3.1.4 Denombrement par cha^ine de Markov Ce qui suit s'inspire de Aldous [1, 2] (voir aussi <ref> [62, 74] </ref>).
Reference: [75] <author> J.L. Snell. </author> <title> Introduction to probability. Random House, </title> <address> New York, </address> <year> 1988. </year>
Reference-contexts: Les notions de probabilites qui seront utilisees ici sont tout a fait elementaires et se retrouvent dans la plupart des manuels comme ceux de Breiman [15] ou Feller [32, 33]. Les livres de Bouleau [11], Snell <ref> [75] </ref> et Berger [8] font une part importante a la simulation. Sur les cha^ines de Markov, les references de base restent Chung [21] et Kemeny et Snell [46]. Un point de vue plus applique est celui de Barucha-Reid [6] et Karlin et Taylor [42, 43].
Reference: [76] <author> H. Spohn. </author> <title> Large scale dynamics of interacting particles. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: Pour les systemes de particules interactives, nos references de base sont Liggett [56] et Durrett [31]. Un point de vue original est celui de Chen [20]. La convergence des systemes de particules renormalises est traitee dans [31, 20], la reference de base etant Spohn <ref> [76] </ref>. Un panorama complet du sujet, et de ses relations avec la resolution de certaines equations aux derivees partielles, est donne dans l'ouvrage collectif [38].
Reference: [77] <author> D. Talay. </author> <title> Simulation and numerical analysis of stochastic differential systems: a review. </title> <editor> In P. Kree and W. Wedig, editors, </editor> <booktitle> Probabilistic Methods in Applied Physics, volume 451 of L. N. in Physics, chapter 3, </booktitle> <pages> pages 54-96. </pages> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Le plus complet sur le sujet est le livre de Devroye [25]. Plusieurs livres traitent de la simulation des processus, parmi lesquels celui de Bouleau et Lepingle [13]. Pour les processus de diffusion Kloeden et Platen [50] est la reference indispensable. Pour une introduction, voir Talay <ref> [77] </ref>. Les methodes MCMC (Monte-Carlo Markov Chain) sont traitees en particulier par Duflo [29, 30] et Robert [66, 67]. L'etude de la vitesse de convergence des cha^ines de Markov a donne lieu a une intense activite de publication ces dix dernieres annees. Nous avons surtout utilise Saloff-Coste [73]. <p> Sur cette coherence entre modelisation deterministe et aleatoire, problemes differentiels et simulation de proces-sus de diffusion, on pourra se reporter a la troisieme partie de Kloeden et Platen [50] ainsi qu'a Talay <ref> [77] </ref> et aux autres articles du m^eme ouvrage. Le rapport entre le mouvement brownien et le laplacien se generalise aux processus de diffusion. Cela fournit le principe de methodes de Monte-Carlo pour la resolution de nombreux problemes differentiels. Nous en donnerons plusieurs exemples dans les paragraphes suivants.
Reference: [78] <author> K.S. Trivedi. </author> <title> Probability and Statistics with Reliability, Queuing and Computer Science Applications. </title> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1982. </year>
Reference-contexts: La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante <ref> [68, 70, 72, 71, 78, 80, 82] </ref>. Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44]. <p> C'est un des avantages de la cha^ine harmonisee par rapport a la cha^ine incluse pour ce qui est de la simulation. Exemple : File M/M/1. La file M/M/1 (voir par exemple <ref> [6, 43, 78, 79] </ref>) est le processus de naissance et de mort sur IN dont les taux de transition sont ij = si i 0 ; j = i + 1 ; = 0 dans tous les autres cas : 68 Pour la simulation par la cha^ine incluse, on aura p
Reference: [79] <author> J. Walrand. </author> <title> Introduction to Queuing Networks. </title> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: C'est un des avantages de la cha^ine harmonisee par rapport a la cha^ine incluse pour ce qui est de la simulation. Exemple : File M/M/1. La file M/M/1 (voir par exemple <ref> [6, 43, 78, 79] </ref>) est le processus de naissance et de mort sur IN dont les taux de transition sont ij = si i 0 ; j = i + 1 ; = 0 dans tous les autres cas : 68 Pour la simulation par la cha^ine incluse, on aura p <p> La simulation des sauts de la cha^ine harmonisee sera decomposee en deux etapes successives au moins. 4.2.2 Reseaux de Jackson Les reseaux de Jackson sont les reseaux de files d'attente les plus simples. Leur solution stationnaire s'exprime sous forme produit, et peut donc ^etre calculee explicitement ou numeriquement (voir <ref> [36, 45, 68, 70, 79] </ref>). Il ne s'agit donc pas dans ce cas de preconiser la simulation comme alternative a l'etude mathematique ou numerique.
Reference: [80] <author> K. Watkins. </author> <title> Discrete event simulation in C. </title> <publisher> McGraw-Hill, </publisher> <address> London, </address> <year> 1993. </year>
Reference-contexts: La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante <ref> [68, 70, 72, 71, 78, 80, 82] </ref>. Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44].
Reference: [81] <author> G. Winkler. </author> <title> Image analysis, random fields and dynamic Monte-Carlo methods. </title> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1995. </year>
Reference-contexts: Nous avons surtout utilise Saloff-Coste [73]. Il existe de nombreuses references sur les algorithmes d'optimisation stochastique, et en particulier le recuit simule, les algorithmes genetiques et leurs applications (voir par exemple <ref> [5, 16, 37, 40, 59, 60, 81] </ref>). La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante [68, 70, 72, 71, 78, 80, 82].
Reference: [82] <author> R.W. Wolff. </author> <title> Stochastic Modelling and the Theory of Queues. </title> <publisher> Prentice-Hall, </publisher> <address> En-glewood Cliff, </address> <year> 1989. </year> <month> 105 </month>
Reference-contexts: La simulation des reseaux de files d'attente, reseaux de Petri et autres systemes a evenements discrets rev^et une importance pratique suffisamment grande pour avoir suscite une litterature importante <ref> [68, 70, 72, 71, 78, 80, 82] </ref>. Les algorithmes presentes 2 ici ne sont pas classiques, m^eme si la notion d'harmonisation sur laquelle ils sont bases est traitee dans plusieurs manuels, par exemple [22, 44].
References-found: 82

