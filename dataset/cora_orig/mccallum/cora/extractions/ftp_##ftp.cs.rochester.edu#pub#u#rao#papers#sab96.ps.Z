URL: ftp://ftp.cs.rochester.edu/pub/u/rao/papers/sab96.ps.Z
Refering-URL: http://www.cs.rochester.edu/u/rao/papers.html
Root-URL: 
Email: frao,fuentesg@cs.rochester.edu  
Title: Learning Navigational Behaviors using a Predictive Sparse Distributed Memory  
Author: Rajesh P.N. Rao and Olac Fuentes 
Address: Rochester, NY 14627  
Affiliation: Department of Computer Science University of Rochester  
Abstract: We describe a general framework for the acquisition of perception-based navigational behaviors in autonomous mobile robots. A self-organizing sparse distributed memory equivalent to a three-layered neural network is used to learn the desired transfer function mapping sensory input into motor commands. The memory is initially trained by teleoperating the robot on a small number of paths within a given domain of interest. During training, the vectors in the sensory space as well as the motor space are continually adapted using a form of competitive learning to yield basis vectors aimed at efficiently spanning the sensorimotor space. After training, the robot navigates from arbitrary locations to a desired goal location using motor output vectors computed by a saliency-based weighted averaging scheme. The pervasive problem of perceptual aliasing in non-Markov environments is handled by allowing both current as well as the set of immediately preceding perceptual inputs to predict the motor output vector for the current time instant. Simulation results obtained for a mobile robot, equipped with simple photoreceptors and infrared receivers, navigating within an enclosed obstacle-ridden arena indicate that the method performs successfully in a variety of navigational tasks, some of which exhibit substantial perceptual aliasing.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> James S. Albus. </author> <title> A theory of cerebellar functions. </title> <journal> Math. Biosci., </journal> <volume> 10 </volume> <pages> 25-61, </pages> <year> 1971. </year>
Reference-contexts: distinguishes our approach from previous neural network approaches based on training procedures such as back propagation [29]. * Biological Plausibility: The structure of the memory bears some striking similarities to the organization of the mammalian cerebellum (and therefore to the cerebellar model of Marr [21] and the CMAC of Albus <ref> [1] </ref>). 2 It is therefore plausible that biological structures and learning processes similar in spirit to those proposed herein may underlie goal-directed perception-based navigation in animals.
Reference: [2] <author> M. Asada, E. Uchibe, S. Noda, S. Tawaratsumida, and K. Hosoda. </author> <title> Coordination of multiple behaviors acquired by a vision-based reinforcement learning. </title> <booktitle> In Proceedings of the 1994 IEEE/RSJ International Conference on Intelligent Robots an Systems, </booktitle> <pages> pages 917-924, </pages> <address> Munich, Germany, </address> <year> 1994. </year>
Reference-contexts: A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning <ref> [2, 13, 20] </ref>, hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [3] <author> R.D. Beer and J.C. Gallagher. </author> <title> Evolving dynamical neural networks for adaptive behavior. </title> <booktitle> Adaptive Behavior, </booktitle> <volume> 1 </volume> <pages> 91-122, </pages> <year> 1992. </year>
Reference-contexts: The second problem has been addressed by endowing robots with the ability to autonomously learn behaviors either from experimentation and dynamic interaction with their environment or via teleoperation. A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming <ref> [3, 6, 18] </ref>, reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [4] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2(1) </volume> <pages> 14-22, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: The first problem is addressed by Brooks <ref> [4] </ref>, who proposes a hierarchical behavior-based decomposition of control architectures. Such behavior-based robot architectures have been shown to accomplish a wide variety of tasks in an efficient manner [7, 19]. <p> Such an approach, while being intuitively appealing, faces the difficult problem of robot localization i.e. establishing reliable correspondences between noisy sensor readings and geometrical map information in order to estimate current map position. In addition, the global map inherits many of the undesirable properties of centralized representations that Brooks <ref> [4] </ref> identifies in traditional robot controllers. An alternative behavior-based approach to navigation is proposed by Mataric [22] (see also [8, 17]). This method avoids the problems involved in creating and maintaining global representations by utilizing only local information as provided by landmarks along a navigational path.
Reference: [5] <author> Lonnie Chrisman. </author> <title> Reinforcement learning with perceptual aliasing. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <year> 1992. </year>
Reference-contexts: By using past sensory inputs to provide the necessary context for disambiguating potentially similar perceptions, we alleviate the well-known problem of perceptual aliasing <ref> [5, 38] </ref> in non-Markov environments. We provide simulation results for a mobile robot, equipped with simple photoreceptors and infrared receivers, navigating within an enclosed obstacle-ridden arena. <p> In general environments, however, a Markovian assumption is often inappropriate, and any method that relies on such an assumption suffers from the problem of perceptual aliasing <ref> [5, 38] </ref>. 4.1 Perceptual Aliasing Perceptual aliasing, a term coined in [38], refers to the situation wherein two or more identical perceptual inputs require different responses from an autonomous system.
Reference: [6] <author> Dave Cliff, Philip Husbands, and Inman Harvey. </author> <title> Evolving visually guided robots. </title> <editor> In J. A. Meyer, H. Roitblat, and S. Wilson, editors, </editor> <booktitle> From Animals to Animats 2: Proceedings of the Second International Conference on the Simulation of Adaptive Behavior, </booktitle> <pages> pages 374-383. </pages> <address> Cam-bridge, MA: </address> <publisher> MIT Press, </publisher> <month> December </month> <year> 1992. </year>
Reference-contexts: The second problem has been addressed by endowing robots with the ability to autonomously learn behaviors either from experimentation and dynamic interaction with their environment or via teleoperation. A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming <ref> [3, 6, 18] </ref>, reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [7] <author> Jonathan H. Connell. </author> <title> Minimalist mobile robotics : A colony-style architecture for an artificial creature. </title> <publisher> Academic Press, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: The first problem is addressed by Brooks [4], who proposes a hierarchical behavior-based decomposition of control architectures. Such behavior-based robot architectures have been shown to accomplish a wide variety of tasks in an efficient manner <ref> [7, 19] </ref>. The second problem has been addressed by endowing robots with the ability to autonomously learn behaviors either from experimentation and dynamic interaction with their environment or via teleoperation.
Reference: [8] <author> P.G.R. de Bourcier. </author> <title> Animate navigation using visual landmarks. </title> <booktitle> Cognitive Science Research Papers 277, </booktitle> <institution> University of Sussex at Brighton, </institution> <month> May </month> <year> 1993. </year>
Reference-contexts: In addition, the global map inherits many of the undesirable properties of centralized representations that Brooks [4] identifies in traditional robot controllers. An alternative behavior-based approach to navigation is proposed by Mataric [22] (see also <ref> [8, 17] </ref>). This method avoids the problems involved in creating and maintaining global representations by utilizing only local information as provided by landmarks along a navigational path.
Reference: [9] <author> A. Elfes. </author> <title> Sonar-based real-world mapping and navigation. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 3 </volume> <pages> 249-265, </pages> <year> 1987. </year>
Reference-contexts: In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment <ref> [9] </ref>. Such an approach, while being intuitively appealing, faces the difficult problem of robot localization i.e. establishing reliable correspondences between noisy sensor readings and geometrical map information in order to estimate current map position.
Reference: [10] <author> Olac Fuentes, Rajesh P. N. Rao, and Michael Van Wie. </author> <title> Hierarchical learning of reactive behaviors in an autonomous mobile robot. </title> <booktitle> In Proceedings of the IEEE International Conf. on Systems, Man, and Cybernetics, </booktitle> <year> 1995. </year>
Reference-contexts: A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning [2, 13, 20], hill-climbing routines <ref> [10, 27] </ref>, and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9]. <p> each of the four cases of navigational behaviors shown in the diagram. (b) The mobile robot that inspired the simulations in the experiments. (c) The robot in its environment. (c) Robot control architecture: the collision detection and obstacle avoidance routines were autonomously learned on-line by the robot as described in <ref> [10] </ref>. I denotes inhibition of the current behavior by a lower-level behavior. * Navigation: During the autonomous navigation phase (Figure 2 (b)), the current perception yields a set of actions a t ; a t+1 ; : : : ; a t+k . <p> This robot was previously used for on-line learning of a hierarchical set of behaviors <ref> [10] </ref> but the slow processing speed of the on-board microcontroller unfortunately limited its use in the present endeavor; we therefore evaluated the feasibility of the algorithms presented in this paper by using a simulation of the robot instead.
Reference: [11] <author> G.E. Hinton, J.L. McClelland, and D.E. Rumelhart. </author> <title> Distributed representations. </title> <booktitle> In Parallel Distributed Processing: Explorations in the Microstructure of Cognition, </booktitle> <volume> volume 1. </volume> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year>
Reference-contexts: The learning rule allows the memory to autonomously form its own set of basis functions for describing the current sensorimotor space. * Distributed Storage: Inputs to the memory are distributed across a number of locations, thereby inheriting the well-known advantages of a distributed representation <ref> [11] </ref> such as generalization to previously unknown inputs and resis tance to faults in memory and internal noise. * Motor Prediction based on Past Perceptual History: The problem of perceptual aliasing is alleviated by employing past perceptions to predict and influence current motor output.
Reference: [12] <author> U.D. Joglekar. </author> <title> Learning to read aloud: A neural network approach using sparse distributed memory. </title> <type> Technical Report 89.27, </type> <institution> Research Institute for Advanced Computer Science, NASA Ames Research Center, </institution> <year> 1989. </year>
Reference-contexts: Sparse distributed memories have previously been used for a wide variety of tasks such as object recognition [34], face recognition [33], speech recognition [31], speech synthesis <ref> [12] </ref>, and weather prediction [36]. The present work shows that with suitable modifications, such memories can be used for learning useful navigational behaviors in mobile robots as well.
Reference: [13] <author> Leslie P. Kaelbling. </author> <title> Learning in embedded systems. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1993. </year>
Reference-contexts: A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning <ref> [2, 13, 20] </ref>, hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [14] <author> P. Kanerva. </author> <title> Sparse Distributed Memory. </title> <address> Cambridge, MA: </address> <publisher> Bradford Books, </publisher> <year> 1988. </year>
Reference-contexts: In this section, we address problems (a) and (b) by using only a sparse subset of the perceptual address space. This naturally leads to a memory known as sparse distributed memory (SDM) that was originally proposed by Kanerva <ref> [14] </ref>. <p> second problem of generalization in novel scenarios in the next section where we propose a modified form of SDM that uses competitive learning to adapt its sensorimotor space and radial interpolation to compute motor output vectors. 2.1 Kanerva's Model Sparse distributed memory (SDM) (Figure 1) was first proposed by Kanerva <ref> [14] </ref> as a model of human long-term memory. It is based on the crucial observation that if concepts or objects of interest are represented by high-dimensional vectors, they can benefit from the very favorable matching properties caused by the inherent tendency toward orthogonality in high-dimensional spaces. <p> The motor action for the current time instant t is then determined by a weighted average of the actions recommended by the current as well as past perceptions upto time t k. This solution shares some similarities with Kanerva's k-fold memory for storage and retrieval of sequences <ref> [14] </ref>; however, all the weaknesses inherent in Kanerva's original model (Section 2.2) still apply to the k-fold memories, thus preventing their direct application in countering the aliasing problem. 4.2 Using Past Perceptions for Motor Prediction The informal solution for perceptual aliasing sketched in the previous section can be formalized as follows.
Reference: [15] <author> Pentti Kanerva. </author> <title> Sparse distributed memory and related models. </title> <editor> In Mohamad H. Hassoun, editor, </editor> <booktitle> Associative Neural Memories, </booktitle> <pages> pages 50-76. </pages> <address> New York: </address> <publisher> Oxford University Press, </publisher> <year> 1993. </year>
Reference-contexts: Note that the addition step in (2) above is essentially a Heb-bian learning rule. The statistically reconstructed data vector d 0 should be the same as the original data vector provided the capacity of the SDM <ref> [15] </ref> has not been exceeded. The intuitive reason for this is as follows: When storing a data vector d using an p-dimensional address vector r, each of the selected locations receives one copy of the data. <p> This biases the sum vector in the direction of d and hence, d is output with high probability. A more rigorous argument based on signal-to-noise ratio analysis can be found in <ref> [15] </ref>. 2.2 Limitations of Kanerva's Model The model of sparse distributed memory as originally proposed by Kanerva has several weaknesses that prevent its direct use in memory-based navigation: * Both the address and data vectors are required to be binary in the standard model of the SDM. <p> Ongoing work involves implementing the learning method on a recently acquired wheelchair robot and designing learning procedures for on-line adaptation of some of the free parameters in the current method such as the length of the perceptual history window and the fidelity fl i for combining 2 See <ref> [15, 35] </ref> for more details. intersection of the training paths at various points which gives rise to perceptual aliasing. (b), (c) and (d) show that the predictive memory is able to circumvent aliasing effects and follow the path to its goal destination by using past sensory information as a contextual aid
Reference: [16] <author> Ben J. A. Krose and Marc Eecen. </author> <title> A self-organizing rep-resentation of sensor space for mobile robot navigation. </title> <booktitle> In IEEE/RSJ/GI International Conference on Intelligent Robots an Systems, </booktitle> <pages> pages 9-14, </pages> <year> 1994. </year>
Reference-contexts: A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps <ref> [16, 24, 35] </ref>. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [17] <author> Benjamin J. Kuipers and Yung-Tai Byun. </author> <title> A robust, quali-tiative approach to a spatial learning mobile robot. </title> <booktitle> In SPIE Cambridge Symposium on Optical and Optoelec-tronic Engineering: Advances in Intelligent Robotics Systems, </booktitle> <month> November </month> <year> 1988. </year>
Reference-contexts: In addition, the global map inherits many of the undesirable properties of centralized representations that Brooks [4] identifies in traditional robot controllers. An alternative behavior-based approach to navigation is proposed by Mataric [22] (see also <ref> [8, 17] </ref>). This method avoids the problems involved in creating and maintaining global representations by utilizing only local information as provided by landmarks along a navigational path.
Reference: [18] <author> M. A. Lewis, A. H. Fagg, and A. Solidum. </author> <title> Genetic programming approach to the construction of a neural network for control of a walking robot. </title> <booktitle> In Proceedings of the 1992 IEEE International Conference on Robotics and Automation, </booktitle> <address> Nice, France, </address> <year> 1992. </year>
Reference-contexts: The second problem has been addressed by endowing robots with the ability to autonomously learn behaviors either from experimentation and dynamic interaction with their environment or via teleoperation. A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming <ref> [3, 6, 18] </ref>, reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [19] <author> Pattie Maes and Rodney A. Brooks. </author> <title> Learning to coordinate behaviors. </title> <booktitle> In Proceedings of AAAI-90, </booktitle> <pages> pages 796-802, </pages> <year> 1990. </year>
Reference-contexts: The first problem is addressed by Brooks [4], who proposes a hierarchical behavior-based decomposition of control architectures. Such behavior-based robot architectures have been shown to accomplish a wide variety of tasks in an efficient manner <ref> [7, 19] </ref>. The second problem has been addressed by endowing robots with the ability to autonomously learn behaviors either from experimentation and dynamic interaction with their environment or via teleoperation.
Reference: [20] <author> Sridhar Mahadevan and Jonathan Connell. </author> <title> Scaling reinforcement learning to robotics by exploiting the sub-sumption architecture. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <year> 1991. </year>
Reference-contexts: A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning <ref> [2, 13, 20] </ref>, hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [21] <author> David Marr. </author> <title> A theory of cerebellar cortex. </title> <journal> J. Physiol. (London), </journal> <volume> 202 </volume> <pages> 437-470, </pages> <year> 1969. </year>
Reference-contexts: method to non-Markov sensorimotor environments and distinguishes our approach from previous neural network approaches based on training procedures such as back propagation [29]. * Biological Plausibility: The structure of the memory bears some striking similarities to the organization of the mammalian cerebellum (and therefore to the cerebellar model of Marr <ref> [21] </ref> and the CMAC of Albus [1]). 2 It is therefore plausible that biological structures and learning processes similar in spirit to those proposed herein may underlie goal-directed perception-based navigation in animals.
Reference: [22] <editor> Maja Mataric. </editor> <title> Integration of representation into goal-driven behavior-based robot. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 8(3) </volume> <pages> 304-312, </pages> <year> 1992. </year>
Reference-contexts: In addition, the global map inherits many of the undesirable properties of centralized representations that Brooks [4] identifies in traditional robot controllers. An alternative behavior-based approach to navigation is proposed by Mataric <ref> [22] </ref> (see also [8, 17]). This method avoids the problems involved in creating and maintaining global representations by utilizing only local information as provided by landmarks along a navigational path.
Reference: [23] <author> James T. McIlwain. </author> <title> Distributed spatial coding in the superior colliculus: A review. </title> <journal> Visual Neuroscience, </journal> <volume> 6 </volume> <pages> 3-13, </pages> <year> 1991. </year>
Reference-contexts: The above scheme is inspired by recent neurophysiological evidence <ref> [23] </ref> that the superior colliculus, a multilayered neuronal structure in the brain stem that is known to play a crucial role in the generation of saccadic eye move ments, in fact employs a population averaging scheme similar to the one above to compute saccadic motor vectors. 1 4 Predictive Sensorimotor Memory
Reference: [24] <author> Ulrich Nehmzow and Tim Smithers. </author> <title> Mapbuilding using self-organizing networks in Really Useful Robots. </title> <editor> In J.-A. Meyer and S. W. Wilson, editors, </editor> <booktitle> From Animals to Animats 1: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 152-159. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1991. </year>
Reference-contexts: A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps <ref> [16, 24, 35] </ref>. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [25] <author> Randal. C. Nelson. </author> <title> Visual homing using an associative memory. </title> <journal> Biological Cybernetics, </journal> <volume> 65 </volume> <pages> 281-291, </pages> <year> 1991. </year>
Reference-contexts: exhibit substantial perceptual aliasing. 2 Sparse Distributed Memory One possible method for memory-based navigation is to use an associative memory in the form of a look-up table that associates a large set of perception vectors from different locations with corresponding set of actions required to navigate to a desired location <ref> [25] </ref>.
Reference: [26] <author> Steven J. Nowlan. </author> <title> Maximum likelihood competitive learning. </title> <booktitle> In Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 574-582. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: This corresponds to randomly initializing the input-hidden weight vectors w i (1 i m). 3.2 Competitive Learning of Sensorimotor Basis Functions Given an input perception vector p and an associated motor vector m during the training phase, we self-organize the address/data space using a soft competitive learning rule <ref> [26, 40] </ref>: 1. Calculate the Euclidean distances d j = kw t j pk between w t j and the input perception vector p. 2. <p> memory locations and avoids the curse of dimensionality problem by intelligently sampling the high-dimensional sensorimotor space using competitive learning (see below). * Competitive Learning of Sensorimotor Basis Functions: The contents of the sparse memory are self-organized using a form of competitive learning that can be related to maximum likelihood estimation <ref> [26] </ref>.
Reference: [27] <author> David Pierce and Benjamin Kuipers. </author> <title> Learning hill-climbing functions as a strategy for generating behaviors in a mobile robot. </title> <booktitle> In From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, </booktitle> <pages> pages 327-336, </pages> <year> 1991. </year>
Reference-contexts: A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning [2, 13, 20], hill-climbing routines <ref> [10, 27] </ref>, and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [28] <author> T. Poggio and F. Girosi. </author> <title> Networks for approximation and learning. </title> <journal> Proc. IEEE, </journal> <volume> 78 </volume> <pages> 1481-1497, </pages> <year> 1990. </year>
Reference-contexts: ith component of the reconstructed output vector o (in other words, the output of the output unit i) is given by: o i = j=1 The saliency-based weighted averaging above is a form of normalized radial interpolation that is similar to the output operation of radial basis function (RBF) networks <ref> [28] </ref>: the closer the current perception is to a given sensory basis vector, the more salient that memory location and the more the weight assigned to the motor vector associated with that basis vector.
Reference: [29] <author> D.A. Pomerleau. ALVINN: </author> <title> An autonomous land vehicle in a neural network. </title> <editor> In D.S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems, </booktitle> <volume> volume 1, </volume> <pages> pages 305-313. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, </address> <year> 1989. </year>
Reference-contexts: The second problem has been addressed by endowing robots with the ability to autonomously learn behaviors either from experimentation and dynamic interaction with their environment or via teleoperation. A number of learning algorithms have been used for this purpose including neural networks <ref> [29, 30, 37] </ref>, evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9]. <p> This extends the application of the method to non-Markov sensorimotor environments and distinguishes our approach from previous neural network approaches based on training procedures such as back propagation <ref> [29] </ref>. * Biological Plausibility: The structure of the memory bears some striking similarities to the organization of the mammalian cerebellum (and therefore to the cerebellar model of Marr [21] and the CMAC of Albus [1]). 2 It is therefore plausible that biological structures and learning processes similar in spirit to those
Reference: [30] <author> D.A. Pomerleau. </author> <title> Efficient training of artificial neural networks for autonomous navigation. </title> <journal> Neural Computation, </journal> <volume> 3(1) </volume> <pages> 88-97, </pages> <month> Spring </month> <year> 1991. </year>
Reference-contexts: The second problem has been addressed by endowing robots with the ability to autonomously learn behaviors either from experimentation and dynamic interaction with their environment or via teleoperation. A number of learning algorithms have been used for this purpose including neural networks <ref> [29, 30, 37] </ref>, evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [31] <author> R.W. Prager and F. Fallside. </author> <title> The modified Kanerva model for automatic speech recognition. </title> <booktitle> Computer Speech and Language, </booktitle> <volume> 3(1) </volume> <pages> 61-81, </pages> <year> 1989. </year>
Reference-contexts: Sparse distributed memories have previously been used for a wide variety of tasks such as object recognition [34], face recognition [33], speech recognition <ref> [31] </ref>, speech synthesis [12], and weather prediction [36]. The present work shows that with suitable modifications, such memories can be used for learning useful navigational behaviors in mobile robots as well.
Reference: [32] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> Learning sac-cadic eye movements using multiscale spatial filters. </title> <editor> In G. Tesauro, D.S. Touretzky, and T.K. Leen, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 7, </booktitle> <pages> pages 893-900. </pages> <address> Cambridge, MA: </address> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: The effects of aliasing can be reduced to some extent by incorporating additional sensory information that suffice to disambiguate between any two given 1 We refer the interested reader to an earlier paper <ref> [32] </ref> for a closely related method for visuomotor learning of saccadic eye movements for a robot head. the motor memories which are indexed by the current perception (left), the previous one (middle), and the perception before the previous one (right).
Reference: [33] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> Natural basis functions and topographic memory for face recognition. </title> <booktitle> In Proc. of IJCAI, </booktitle> <pages> pages 10-17, </pages> <year> 1995. </year>
Reference-contexts: Sparse distributed memories have previously been used for a wide variety of tasks such as object recognition [34], face recognition <ref> [33] </ref>, speech recognition [31], speech synthesis [12], and weather prediction [36]. The present work shows that with suitable modifications, such memories can be used for learning useful navigational behaviors in mobile robots as well.
Reference: [34] <author> Rajesh P.N. Rao and Dana H. Ballard. </author> <title> Object indexing using an iconic sparse distributed memory. </title> <booktitle> In Proceedings of the International Conference on Computer Vision (ICCV), </booktitle> <pages> pages 24-31, </pages> <year> 1995. </year>
Reference-contexts: Sparse distributed memories have previously been used for a wide variety of tasks such as object recognition <ref> [34] </ref>, face recognition [33], speech recognition [31], speech synthesis [12], and weather prediction [36]. The present work shows that with suitable modifications, such memories can be used for learning useful navigational behaviors in mobile robots as well.
Reference: [35] <author> Rajesh P.N. Rao and Olac Fuentes. </author> <title> Perceptual homing by an autonomous mobile robot using sparse self-organizing sensory-motor maps. </title> <booktitle> In Proceedings of World Congress on Neural Networks (WCNN), </booktitle> <pages> pages II380-II383, </pages> <year> 1995. </year>
Reference-contexts: A number of learning algorithms have been used for this purpose including neural networks [29, 30, 37], evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps <ref> [16, 24, 35] </ref>. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9]. <p> generation of saccadic eye move ments, in fact employs a population averaging scheme similar to the one above to compute saccadic motor vectors. 1 4 Predictive Sensorimotor Memory The self-organizing SDM described in the preceding section has been shown to be useful for perceptual homing by an autonomous mobile robot <ref> [35] </ref>. However, it is not hard to see that the above method is limited to only those navigational behaviors that can be modeled by Markov processes: the current motor output is dependent solely on the current perception and past inputs are treated as irrelevant for determining current action. <p> Ongoing work involves implementing the learning method on a recently acquired wheelchair robot and designing learning procedures for on-line adaptation of some of the free parameters in the current method such as the length of the perceptual history window and the fidelity fl i for combining 2 See <ref> [15, 35] </ref> for more details. intersection of the training paths at various points which gives rise to perceptual aliasing. (b), (c) and (d) show that the predictive memory is able to circumvent aliasing effects and follow the path to its goal destination by using past sensory information as a contextual aid
Reference: [36] <author> David Rogers. </author> <title> Predicting weather using a genetic memory: A combination of Kanerva's sparse distributed memory and Holland's genetic algorithms. </title> <editor> In D. S. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 455-464. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Sparse distributed memories have previously been used for a wide variety of tasks such as object recognition [34], face recognition [33], speech recognition [31], speech synthesis [12], and weather prediction <ref> [36] </ref>. The present work shows that with suitable modifications, such memories can be used for learning useful navigational behaviors in mobile robots as well.
Reference: [37] <author> Jun Tani and Naohiro Fukumura. </author> <title> Learning goal-directed sensory-based navigation of a mobile robot. </title> <booktitle> Neural Networks, </booktitle> <volume> 7(3) </volume> <pages> 553-563, </pages> <year> 1994. </year>
Reference-contexts: The second problem has been addressed by endowing robots with the ability to autonomously learn behaviors either from experimentation and dynamic interaction with their environment or via teleoperation. A number of learning algorithms have been used for this purpose including neural networks <ref> [29, 30, 37] </ref>, evolutionary algorithms/genetic programming [3, 6, 18], reinforcement learning [2, 13, 20], hill-climbing routines [10, 27], and self-organizing maps [16, 24, 35]. In the context of robot navigation, a popular approach has been the construction and use of global maps of the environment [9].
Reference: [38] <author> Steven D. Whitehead and Dana H. Ballard. </author> <title> Learning to perceive and act by trial and error. </title> <journal> Machine Learning, </journal> <volume> 7(1) </volume> <pages> 45-83, </pages> <year> 1991. </year> <type> (Also Tech. Report # 331, </type> <institution> Department of Computer Science, University of Rochester, 1990.). </institution>
Reference-contexts: By using past sensory inputs to provide the necessary context for disambiguating potentially similar perceptions, we alleviate the well-known problem of perceptual aliasing <ref> [5, 38] </ref> in non-Markov environments. We provide simulation results for a mobile robot, equipped with simple photoreceptors and infrared receivers, navigating within an enclosed obstacle-ridden arena. <p> In general environments, however, a Markovian assumption is often inappropriate, and any method that relies on such an assumption suffers from the problem of perceptual aliasing <ref> [5, 38] </ref>. 4.1 Perceptual Aliasing Perceptual aliasing, a term coined in [38], refers to the situation wherein two or more identical perceptual inputs require different responses from an autonomous system. <p> In general environments, however, a Markovian assumption is often inappropriate, and any method that relies on such an assumption suffers from the problem of perceptual aliasing [5, 38]. 4.1 Perceptual Aliasing Perceptual aliasing, a term coined in <ref> [38] </ref>, refers to the situation wherein two or more identical perceptual inputs require different responses from an autonomous system. A number of factors such as limited sensing capability, noisy sensory inputs, and restricted resolution in addition to inherent local ambiguity in typical environments contribute towards exac erbating perceptual aliasing. <p> The current estimate of motor output a t is computed by averaging over the motor action vectors for the current time instant t predicted by current and past perceptual inputs. situations <ref> [38, 39] </ref>. However, these methods still rely only on current percepts and thus, are unable to overcome aliasing in non-Markov environments.
Reference: [39] <author> Lambert Wixson. </author> <title> Scaling reinforcement learning techniques via modularity. </title> <booktitle> In Proceedings of the Eighth International Workshop on Machine Learning, </booktitle> <pages> pages 368-372. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The current estimate of motor output a t is computed by averaging over the motor action vectors for the current time instant t predicted by current and past perceptual inputs. situations <ref> [38, 39] </ref>. However, these methods still rely only on current percepts and thus, are unable to overcome aliasing in non-Markov environments.
Reference: [40] <author> E. Yair, K. Zeger, and A. Gersho. </author> <title> Competitive learning and soft competition for vector quantizer design. </title> <journal> IEEE Trans. Signal Processing, </journal> <volume> 40(2) </volume> <pages> 294-309, </pages> <year> 1992. </year>
Reference-contexts: This corresponds to randomly initializing the input-hidden weight vectors w i (1 i m). 3.2 Competitive Learning of Sensorimotor Basis Functions Given an input perception vector p and an associated motor vector m during the training phase, we self-organize the address/data space using a soft competitive learning rule <ref> [26, 40] </ref>: 1. Calculate the Euclidean distances d j = kw t j pk between w t j and the input perception vector p. 2.
References-found: 40

