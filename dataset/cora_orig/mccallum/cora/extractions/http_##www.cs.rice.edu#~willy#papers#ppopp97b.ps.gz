URL: http://www.cs.rice.edu/~willy/papers/ppopp97b.ps.gz
Refering-URL: http://www.cs.rice.edu/~willy/TreadMarks/papers.html
Root-URL: 
Email: willyg@cs.rice.edu  
Title: Tradeoffs Between False Sharing and Aggregation in Software Distributed Shared Memory  
Author: Cristiana Amza Alan Cox Karthick Rajamani and Willy Zwaenepoel 
Address: famza, alc, karthick,  
Affiliation: Department of Computer Science Department of Electrical and Computer Engineering Rice University  
Abstract: Software Distributed Shared Memory (DSM) systems based on virtual memory techniques traditionally use the hardware page as the consistency unit. The large size of the hardware page is considered to be a performance bottleneck because of the implied false sharing overheads. Instead, we show that in the presence of a relaxed consistency model and a multiple writer protocol, a large consistency unit is generally not detrimental to performance. We study the tradeoffs between false sharing and aggregation effects when using large consistency units. In this context, this paper makes three separate contributions: 1. We document the cost of false sharing in terms of extra messages and extra data being communicated. We 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Amza, A.L. Cox, S. Dwarkadas, P. Keleher, H. Lu, R. Rajamony, W. Yu, and W. Zwaenepoel. </author> <title> Tread-Marks: Shared memory computing on networks of workstations. </title> <journal> IEEE Computer, </journal> <volume> 29(2) </volume> <pages> 18-28, </pages> <month> February </month> <year> 1996. </year>
Reference-contexts: Today, it is generally accepted that the ill effects of false sharing can be reduced, but not entirely eliminated, using a relaxed memory consistency model and a multiple writer protocol <ref> [1, 3, 9, 13] </ref>. Despite this, the conventional wisdom remains that the overhead of false sharing, as well as fine-grained true sharing, in page-based consistency protocols is the primary factor limiting the performance of software DSM. <p> In a software DSM that uses lazy release consistency (LRC) [13] and multiple writer protocols [3], such as Tread-Marks <ref> [1] </ref>, false sharing can have two harmful effects: it can cause extra messages to be sent, and it can cause additional data to be sent on messages that also carry truly shared data. We refer to these as useless messages and useless data. <p> Our platform is a 100Mbps switched Ethernet connecting 8 166Mhz Pentium machines. We use the TreadMarks software DSM <ref> [1] </ref> as the basis for our experiments. TreadMarks implements a lazy release consistent memory model [13]. It uses virtual memory page faults to detect access misses, and twinning and diffing to record modifications to a page and to implement a multiple writer protocol [3].
Reference: [2] <author> D. Bailey, J. Barton, T. Lasinski, and H. Simon. </author> <title> The NAS parallel benchmarks. </title> <type> Technical Report 103863, </type> <institution> NASA, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: For all applications and data sets, the dynamic aggregation algorithm performs nearly as well as the best static page size. Our application suite consists of eight programs. Barnes and Water are from the SPLASH benchmark suite [17]; 3D-FFT is from the NAS benchmark suite <ref> [2] </ref>; Ilink is a widely used genetic linkage analysis program [5]; Shallow is a benchmark developed at NCAR [16]; and Modified Gramm-Schmidt (MGS), Jacobi, and Traveling Salesman Problem (TSP) are simple computational kernels. Our platform is a 100Mbps switched Ethernet connecting 8 166Mhz Pentium machines. <p> The time to acquire a lock varies from 374 to 574 microseconds. The time for an eight processor barrier is 861 microseconds. The time to obtain a diff varies from 579 to 1,746 microseconds. 5.2 Applications We used eight applications in this study: Barnes and Water [17], 3D-FFT <ref> [2] </ref>, Ilink [5], Shallow [16], Modified Gramm-Schmidt (MGS), Jacobi, and Traveling Salesman Problem (TSP). Table 1 includes for each application, the data set sizes used, the sequential execution time, and the speedup on 8 processors using the hardware page size as the consistency unit.
Reference: [3] <author> J.B. Carter, J.K. Bennett, and W. Zwaenepoel. </author> <title> Techniques for reducing consistency-related information in distributed shared memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 13(3) </volume> <pages> 205-243, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: Today, it is generally accepted that the ill effects of false sharing can be reduced, but not entirely eliminated, using a relaxed memory consistency model and a multiple writer protocol <ref> [1, 3, 9, 13] </ref>. Despite this, the conventional wisdom remains that the overhead of false sharing, as well as fine-grained true sharing, in page-based consistency protocols is the primary factor limiting the performance of software DSM. <p> Despite this, the conventional wisdom remains that the overhead of false sharing, as well as fine-grained true sharing, in page-based consistency protocols is the primary factor limiting the performance of software DSM. In a software DSM that uses lazy release consistency (LRC) [13] and multiple writer protocols <ref> [3] </ref>, such as Tread-Marks [1], false sharing can have two harmful effects: it can cause extra messages to be sent, and it can cause additional data to be sent on messages that also carry truly shared data. We refer to these as useless messages and useless data. <p> We use the TreadMarks software DSM [1] as the basis for our experiments. TreadMarks implements a lazy release consistent memory model [13]. It uses virtual memory page faults to detect access misses, and twinning and diffing to record modifications to a page and to implement a multiple writer protocol <ref> [3] </ref>. The rest of this paper is organized as follows. Section 2 discusses the effects of false sharing when the consistency unit is a virtual memory page. <p> Access to an invalidated page causes a page fault, which in turn causes page fault request messages to be sent out to all of the processors that wrote the page concurrently before the synchronization. In multiple writer protocols <ref> [3] </ref>, write detection is done by twinning, and diffing. On the first write to a shared page, an identical copy of the page (a twin) is made. The twin is then compared with the modified copy of the page to generate a diff, a record of modifications to the page.
Reference: [4] <author> C. Dubnicki and T. LeBlanc. </author> <title> Adjustable block size coherent caches. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 170-180, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: They too noticed that different applications gave their best performances for different cache block sizes. They traced the source for this variation to the different sharing patterns among the applications. Dubnicki and LeBlanc <ref> [4] </ref> proposed a scheme to reduce the impact on performance due to a mismatch between the cache block size and the sharing patterns exhibited by a given application. They adjusted the size of the cache block according to recent reference patterns.
Reference: [5] <author> S. Dwarkadas, A.A. Schaffer, R.W. Cottingham Jr., A.L. Cox, P. Keleher, and W. Zwaenepoel. </author> <title> Paral-lelization of general linkage analysis problems. </title> <booktitle> Human Heredity, </booktitle> <volume> 44 </volume> <pages> 127-141, </pages> <year> 1994. </year>
Reference-contexts: Our application suite consists of eight programs. Barnes and Water are from the SPLASH benchmark suite [17]; 3D-FFT is from the NAS benchmark suite [2]; Ilink is a widely used genetic linkage analysis program <ref> [5] </ref>; Shallow is a benchmark developed at NCAR [16]; and Modified Gramm-Schmidt (MGS), Jacobi, and Traveling Salesman Problem (TSP) are simple computational kernels. Our platform is a 100Mbps switched Ethernet connecting 8 166Mhz Pentium machines. We use the TreadMarks software DSM [1] as the basis for our experiments. <p> The time for an eight processor barrier is 861 microseconds. The time to obtain a diff varies from 579 to 1,746 microseconds. 5.2 Applications We used eight applications in this study: Barnes and Water [17], 3D-FFT [2], Ilink <ref> [5] </ref>, Shallow [16], Modified Gramm-Schmidt (MGS), Jacobi, and Traveling Salesman Problem (TSP). Table 1 includes for each application, the data set sizes used, the sequential execution time, and the speedup on 8 processors using the hardware page size as the consistency unit.
Reference: [6] <author> S.J. Eggers and R.H. Katz. </author> <title> A characterization of sharing in parallel programs and its application to coherency protocol evaluation. </title> <booktitle> In Proceedings of the 15th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 373-383, </pages> <month> May </month> <year> 1988. </year>
Reference-contexts: Jeremiassen presents compile-time techniques to analyze the sharing behavior of explicitly parallel programs [12]. His analysis determines which data structures may be susceptible to false sharing. Heuristics are then applied to determine if it is profitable to pad the data structures. Eggers and Katz <ref> [6, 7] </ref> showed that the performance of coherent caches for bus-based shared memory multiprocessors depends on the relationship between the cache block size, the granularity of sharing, and the locality exhibited by a program. They showed that the optimal cache block size varies for different sets of applications.
Reference: [7] <author> S.J. Eggers and R.H. Katz. </author> <title> The effect of sharing on the cache and bus performance of parallel programs. </title> <booktitle> In Proceedings of the 3rd Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 257-270, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: Jeremiassen presents compile-time techniques to analyze the sharing behavior of explicitly parallel programs [12]. His analysis determines which data structures may be susceptible to false sharing. Heuristics are then applied to determine if it is profitable to pad the data structures. Eggers and Katz <ref> [6, 7] </ref> showed that the performance of coherent caches for bus-based shared memory multiprocessors depends on the relationship between the cache block size, the granularity of sharing, and the locality exhibited by a program. They showed that the optimal cache block size varies for different sets of applications.
Reference: [8] <author> G.A. Geist and V.S. Sunderam. </author> <title> Network-based concurrent computing on the PVM system. </title> <journal> Concurrency: Practice and Experience, </journal> <pages> pages 293-311, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: They only consider consistency units up to the size of the virtual memory page, while we study consistency units that are a multiple of the page size. Lu et al. [15] analyzed the performance differences between message passing programs, using Parallel Virtual Machine (PVM) <ref> [8] </ref>, and DSM programs, using TreadMarks.
Reference: [9] <author> K. Gharachorloo, D. Lenoski, J. Laudon, P. Gibbons, A. Gupta, and J. Hennessy. </author> <title> Memory consistency and event ordering in scalable shared-memory multiprocessors. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 15-26, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Today, it is generally accepted that the ill effects of false sharing can be reduced, but not entirely eliminated, using a relaxed memory consistency model and a multiple writer protocol <ref> [1, 3, 9, 13] </ref>. Despite this, the conventional wisdom remains that the overhead of false sharing, as well as fine-grained true sharing, in page-based consistency protocols is the primary factor limiting the performance of software DSM. <p> Section 5 discusses our performance measurements. Section 6 discusses related work. Section 7 provides our conclusions. 2 False Sharing Effects The discussion of false sharing in this paper concerns page-based software DSM systems that use lazy release consistency (LRC) and multiple writer protocols, such as Tread-Marks. With release consistency <ref> [9, 13] </ref>, the modifications of processor p become visible to processor q only after q synchronizes with p. If an invalidate protocol is used, modifications cause a page to be invalidated after the synchronization.
Reference: [10] <author> J.R. Goodman. </author> <title> Coherency for multiprocessor virtual address caches. </title> <booktitle> In Proceedings of the 2nd Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 72-81, </pages> <month> October </month> <year> 1987. </year>
Reference-contexts: They adjusted the size of the cache block according to recent reference patterns. They found that the adjustable cache-block-size implementation did better than the best fixed-size implementations for most of the programs in their suite. In an earlier study <ref> [10] </ref>, Goodman also evaluated the effect of the size of the consistency units on the behavior of a virtual address cache. Zhou et al. [20] discuss the relationship between relaxed consistency and coherence granularity in DSM systems.
Reference: [11] <author> E. Granston and H. Wijshoff. </author> <title> Managing pages in shared virtual memory systems: Getting the compiler into the game. </title> <booktitle> In Proceedings of the 1993 ACM International Conference on Supercomputing, </booktitle> <month> July </month> <year> 1993. </year>
Reference-contexts: The Midway DSM system [19] supports the entry consistency model, which requires the programmer to associate each shared datum explicitly with a synchronization variable. False sharing can be entirely avoided, because the consistency unit is precisely the shared data. Granston and Wijshoff <ref> [11] </ref> present compile-time techniques for a parallelizing Fortran compiler that transforms loops in order to reduce false sharing. Jeremiassen presents compile-time techniques to analyze the sharing behavior of explicitly parallel programs [12]. His analysis determines which data structures may be susceptible to false sharing.
Reference: [12] <author> T.E. Jeremiassen and S. Eggers. </author> <title> Reducing false sharing on shared memory multiprocessors through compile time data transformations. </title> <booktitle> In Proceedings of the 5th Symposium on the Principles and Practice of Parallel Programming, </booktitle> <month> July </month> <year> 1995. </year>
Reference-contexts: False sharing can be entirely avoided, because the consistency unit is precisely the shared data. Granston and Wijshoff [11] present compile-time techniques for a parallelizing Fortran compiler that transforms loops in order to reduce false sharing. Jeremiassen presents compile-time techniques to analyze the sharing behavior of explicitly parallel programs <ref> [12] </ref>. His analysis determines which data structures may be susceptible to false sharing. Heuristics are then applied to determine if it is profitable to pad the data structures.
Reference: [13] <author> P. Keleher, A. L. Cox, and W. Zwaenepoel. </author> <title> Lazy release consistency for software distributed shared memory. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 13-21, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: Today, it is generally accepted that the ill effects of false sharing can be reduced, but not entirely eliminated, using a relaxed memory consistency model and a multiple writer protocol <ref> [1, 3, 9, 13] </ref>. Despite this, the conventional wisdom remains that the overhead of false sharing, as well as fine-grained true sharing, in page-based consistency protocols is the primary factor limiting the performance of software DSM. <p> Despite this, the conventional wisdom remains that the overhead of false sharing, as well as fine-grained true sharing, in page-based consistency protocols is the primary factor limiting the performance of software DSM. In a software DSM that uses lazy release consistency (LRC) <ref> [13] </ref> and multiple writer protocols [3], such as Tread-Marks [1], false sharing can have two harmful effects: it can cause extra messages to be sent, and it can cause additional data to be sent on messages that also carry truly shared data. <p> Our platform is a 100Mbps switched Ethernet connecting 8 166Mhz Pentium machines. We use the TreadMarks software DSM [1] as the basis for our experiments. TreadMarks implements a lazy release consistent memory model <ref> [13] </ref>. It uses virtual memory page faults to detect access misses, and twinning and diffing to record modifications to a page and to implement a multiple writer protocol [3]. The rest of this paper is organized as follows. <p> Section 5 discusses our performance measurements. Section 6 discusses related work. Section 7 provides our conclusions. 2 False Sharing Effects The discussion of false sharing in this paper concerns page-based software DSM systems that use lazy release consistency (LRC) and multiple writer protocols, such as Tread-Marks. With release consistency <ref> [9, 13] </ref>, the modifications of processor p become visible to processor q only after q synchronizes with p. If an invalidate protocol is used, modifications cause a page to be invalidated after the synchronization.
Reference: [14] <author> K. Li and P. Hudak. </author> <title> Memory coherence in shared virtual memory systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 7(4) </volume> <pages> 321-359, </pages> <month> November </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Since Li and Hudak's seminal work <ref> [14] </ref> on software distributed shared memory (DSM) in 1985, the "Battle Against False Sharing" has been a dominant, if not the dominant, theme of research in this area.
Reference: [15] <author> H. Lu, S. Dwarkadas, A.L. Cox, and W. Zwaenepoel. </author> <title> Quantifying the performance differences between PVM and TreadMarks. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <month> June </month> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: This diff contains the entire page, although p 2 will only read the top half. The bottom half of the page sent in the diff is useless data. Previous research <ref> [15] </ref> has studied the extra communication in software DSM induced by false sharing. We argue that the study of false sharing, in isolation, is not a very good indicator of the effect of false sharing on program performance. <p> They only consider consistency units up to the size of the virtual memory page, while we study consistency units that are a multiple of the page size. Lu et al. <ref> [15] </ref> analyzed the performance differences between message passing programs, using Parallel Virtual Machine (PVM) [8], and DSM programs, using TreadMarks.
Reference: [16] <author> R. Sadourny. </author> <title> The dynamics of finite-difference models of the shallow-water equations. </title> <journal> Journal of Atmospheric Sciences, </journal> <volume> 32(4), </volume> <month> April </month> <year> 1975. </year>
Reference-contexts: Our application suite consists of eight programs. Barnes and Water are from the SPLASH benchmark suite [17]; 3D-FFT is from the NAS benchmark suite [2]; Ilink is a widely used genetic linkage analysis program [5]; Shallow is a benchmark developed at NCAR <ref> [16] </ref>; and Modified Gramm-Schmidt (MGS), Jacobi, and Traveling Salesman Problem (TSP) are simple computational kernels. Our platform is a 100Mbps switched Ethernet connecting 8 166Mhz Pentium machines. We use the TreadMarks software DSM [1] as the basis for our experiments. TreadMarks implements a lazy release consistent memory model [13]. <p> The time for an eight processor barrier is 861 microseconds. The time to obtain a diff varies from 579 to 1,746 microseconds. 5.2 Applications We used eight applications in this study: Barnes and Water [17], 3D-FFT [2], Ilink [5], Shallow <ref> [16] </ref>, Modified Gramm-Schmidt (MGS), Jacobi, and Traveling Salesman Problem (TSP). Table 1 includes for each application, the data set sizes used, the sequential execution time, and the speedup on 8 processors using the hardware page size as the consistency unit.
Reference: [17] <author> J.P. Singh, W.-D. Weber, and A. Gupta. </author> <title> SPLASH: Stanford parallel applications for shared-memory. </title> <journal> Computer Architecture News, </journal> <volume> 20(1) </volume> <pages> 2-12, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: We found this cost to be small relative to the gains achieved. For all applications and data sets, the dynamic aggregation algorithm performs nearly as well as the best static page size. Our application suite consists of eight programs. Barnes and Water are from the SPLASH benchmark suite <ref> [17] </ref>; 3D-FFT is from the NAS benchmark suite [2]; Ilink is a widely used genetic linkage analysis program [5]; Shallow is a benchmark developed at NCAR [16]; and Modified Gramm-Schmidt (MGS), Jacobi, and Traveling Salesman Problem (TSP) are simple computational kernels. <p> The time to acquire a lock varies from 374 to 574 microseconds. The time for an eight processor barrier is 861 microseconds. The time to obtain a diff varies from 579 to 1,746 microseconds. 5.2 Applications We used eight applications in this study: Barnes and Water <ref> [17] </ref>, 3D-FFT [2], Ilink [5], Shallow [16], Modified Gramm-Schmidt (MGS), Jacobi, and Traveling Salesman Problem (TSP). Table 1 includes for each application, the data set sizes used, the sequential execution time, and the speedup on 8 processors using the hardware page size as the consistency unit.
Reference: [18] <author> W.-D. Weber and A. Gupta. </author> <title> Analysis of cache invalidation patterns in multiprocessors. </title> <booktitle> In Proceedings of the 3rd Symposium on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 243-256, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: They showed that the optimal cache block size varies for different sets of applications. Gupta and Weber <ref> [18] </ref> examined the effect of cache block size on the number and size of invalidations in a directory-based cache-coherent multiprocessor system. They too noticed that different applications gave their best performances for different cache block sizes.
Reference: [19] <author> M.J. Zekauskas, </author> <title> W.A. Sawdon, and B.N. Bershad. Software write detection for distributed shared memory. </title> <booktitle> In Proceedings of the First USENIX Symposium on Operating System Design and Implementation, </booktitle> <pages> pages 87-100, </pages> <month> November </month> <year> 1994. </year>
Reference-contexts: Overall, the combination results in a slight decrease in performance. For larger data sets, false sharing subsides, and aggregation causes performance to improve. 6 Related Work There are both compile-time and run-time schemes to eliminate false sharing. The Midway DSM system <ref> [19] </ref> supports the entry consistency model, which requires the programmer to associate each shared datum explicitly with a synchronization variable. False sharing can be entirely avoided, because the consistency unit is precisely the shared data.
Reference: [20] <author> Y. Zhou, L. Iftode, K. Li, J.P. Singh, B.R. Toonen, I. Schoinas, M.D. Hill, and D.A. Wood. </author> <title> Relaxed consistency and coherence granularity in DSM systems: A performance evaluation. </title> <booktitle> In Proceedings of the 6th Symposium on the Principles and Practice of Parallel Programming, </booktitle> <month> jun </month> <year> 1997. </year> <note> To appear. </note>
Reference-contexts: In an earlier study [10], Goodman also evaluated the effect of the size of the consistency units on the behavior of a virtual address cache. Zhou et al. <ref> [20] </ref> discuss the relationship between relaxed consistency and coherence granularity in DSM systems. They conclude that sequential consistency with small consistency units and lazy release consistency with larger consistency units perform comparably for the applications used in the study.
References-found: 20

