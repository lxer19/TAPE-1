URL: http://www.cs.purdue.edu/homes/sunil/syllabi/lsi2.ps
Refering-URL: http://www.cs.purdue.edu/homes/sunil/syllabi/CS690D_Fall98.html
Root-URL: http://www.cs.purdue.edu
Title: Using Linear Algebra for Intelligent Information Retrieval  
Author: Michael W. Berry Susan T. Dumais 
Date: December 1994  
Affiliation: Computer Science Department  
Pubnum: CS-94-270  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> N. J. Belkin and W. B. Croft, </author> <title> Information filtering and information retrieval: Two sides of the same coin?, </title> <journal> Communications of the ACM, </journal> <volume> 35 (1992), </volume> <pages> pp. 29-38. </pages>
Reference-contexts: Information Filtering. Information filtering is a problem that is closely related to information retrieval <ref> [1] </ref>. In information filtering applications, a user has a relatively stable long-term interest or profile, and new documents are constantly received and matched against this standing interest.
Reference: [2] <author> M. W. Berry, </author> <title> Large scale singular value computations, </title> <journal> International Journal of Supercomputer Applications, </journal> <volume> 6 (1992), </volume> <pages> pp. 13-49. </pages>
Reference-contexts: In general, the cost of computing the SVD of a sparse matrix [3] can be generally expressed as I fi cost (G T Gx) + trp fi cost (Gx); where I is the number of iterations required by a Lanczos-type procedure <ref> [2] </ref> to approximate the eigensystem of G T G and trp is the number of accepted singular triplets (i.e. singular values and corresponding left and right singular vectors).
Reference: [3] <author> M. W. Berry et al., SVDPACKC: </author> <title> Version 1.0 User's Guide, </title> <type> Tech. Rep. </type> <institution> CS-93-194, University of Tennessee, Knoxville, TN, </institution> <month> October </month> <year> 1993. </year>
Reference-contexts: SVD-updating exploits the previous singular values and singular vectors of the original term-documents matrix A as an alternative to recomputing the SVD of ~ A in Equation (9). In general, the cost of computing the SVD of a sparse matrix <ref> [3] </ref> can be generally expressed as I fi cost (G T Gx) + trp fi cost (Gx); where I is the number of iterations required by a Lanczos-type procedure [2] to approximate the eigensystem of G T G and trp is the number of accepted singular triplets (i.e. singular values and <p> Instead, a sample 3 of about 70; 000 documents and 90; 000 terms was used. Such term by document matrices (A) are quite sparse, containing only :001-:002% non-zero entries. Computing A 200 , i.e. the 200-largest singular values and corresponding singular vectors, by a single-vector Lanczos algorithm <ref> [3] </ref> required about 18 hours of CPU time on a SUN SPARCstation 10 workstation. Documents not in the original LSI analysis were folded-in as previously described in Section 3.3. That is, the vector for a document is located at the weighted vector sum of its constituent term vectors. <p> Using Linear Algebra for Intelligent Information Retrieval 21 The computation of A k for the large sparse TREC matrices A was accomplished without difficulty (numerical or convergence problems) using sophisticated implementations of the Lanczos algorithm from SVDPACKC <ref> [3] </ref>. However, the computational and memory requirements posed by the TREC collection greatly motivated the development of the SVD-updating procedures discussed in Section 4. 5.4. Novel Applications. Because LSI is a completely automatic method, it is widely applicable to new collections of texts (including to different languages, as described below).
Reference: [4] <author> S. Deerwester, S. Dumais, G. Furnas, T. Landauer, and R. Harshman, </author> <title> Indexing by latent semantic analysis, </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41 (1990), </volume> <pages> pp. 391-407. </pages>
Reference-contexts: For several information science test collections, the average precision using LSI ranged from comparable to to 30% better than that obtained using standard keyword vector methods. See <ref> [4, 12, 6] </ref> for details of these evaluations. The LSI method performs best relative to standard vector methods when the queries and relevant documents do not share many words, and at high levels of recall. Term Weighting. <p> Choosing the Number of Factors. Choosing the number of dimensions (k) for A k shown in Figure 1 is an interesting problem. While a reduction in k can remove much of the noise, keeping too few dimensions or factors may loose important information. As discussed in <ref> [4] </ref> using a test database of medical abstracts, LSI performance 2 can improve considerably after 10 or 20 dimensions, peaks between 70 and 100 dimensions, and then begins to diminish slowly.
Reference: [5] <author> J. J. Dongarra and E. Grosse, </author> <title> Distribution of mathematical software via electronic mail, </title> <journal> Communications of the ACM, </journal> <volume> 30 (1987), </volume> <pages> pp. 403-407. </pages>
Reference-contexts: Similarly, an entire document is usually the text object of interest, but smaller, more topically coherent units of text (e.g., paragraphs, sections) could be represented as well. For example, LSI has been incorporated as a fuzzy search option in NETLIB <ref> [5] </ref> for retrieving algorithms, code descriptions, and short articles from the NA-Digest electronic newsletter. Regardless of how the original descriptor-object matrix is derived, a reduced-dimension approximation can be computed. The important idea in LSI is to go beyond the original descriptors to more reliable statistically derived indexing dimensions.
Reference: [6] <author> S. T. Dumais, </author> <title> Improving the retrieval of information from external sources, Behavior Research Methods, Instruments, </title> & <journal> Computers, </journal> <volume> 23 (1991), </volume> <pages> pp. </pages> <month> 229-236. </month> <title> [7] , LSI meets TREC: A status report., </title> <booktitle> in The First Text REtrieval Conference (TREC1), </booktitle> <editor> D. Harman, ed., </editor> <month> March </month> <year> 1993, </year> <pages> pp. 137-152. </pages> <booktitle> National Institute of Standards and Technology Special Publication 500-207. [8] , Latent Semantic Indexing (LSI) and TREC-2., in The Second Text REtrieval Conference (TREC2), </booktitle> <editor> D. Harman, ed., </editor> <month> March </month> <year> 1994, </year> <pages> pp. 105-116. </pages> <institution> National Institute of Standards and Technology Special Publication 500-215. </institution>
Reference-contexts: For several information science test collections, the average precision using LSI ranged from comparable to to 30% better than that obtained using standard keyword vector methods. See <ref> [4, 12, 6] </ref> for details of these evaluations. The LSI method performs best relative to standard vector methods when the queries and relevant documents do not share many words, and at high levels of recall. Term Weighting. <p> It is also possible to transform the term's frequency in the document; such a transformation is called a local weighting, and is applied to each cell in the matrix. The performance for several weighting schemes have been compared in <ref> [6] </ref>. A transformed matrix is automatically computed, the truncated SVD shown in Figure 1 is computed, and performance is evaluated. A log transformation of the local cell entries combined with a global entropy weight for terms is the most effective term-weighting scheme. <p> Replacing the users' query with the first relevant document improves performance by an average of 33% and replacing it with the average of the first three relevant documents improves performance by an average of 67% (see <ref> [6] </ref> for details). Relevance feedback provides sizeable and consistent retrieval advantages. One way of thinking about the success of these methods is that many words (those from relevant documents) augment the initial query which is usually quite impoverished.
Reference: [9] <author> S. T. Dumais and J. Nielsen, </author> <title> Automating the assignment of submitted manuscripts to reviewers, </title> <booktitle> in SIGIR'92: Proceedings of the 15th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, </booktitle> <editor> N. Belkin, P. Ingwersen, and A. M. Pejtersen, eds., </editor> <address> Copenhagen, Denmark, June 1992, </address> <publisher> ACM Press, </publisher> <pages> pp. 233-244. </pages>
Reference-contexts: In one application [12], known as the Bellcore Advisor, a system was developed to find local experts relevant to users' queries. A query was matched to the nearest documents and project descriptions and the authors organization was returned as the most relevant internal group. In another application <ref> [9] </ref>, LSI was used to automate the assignment of reviewers to submitted conference papers. Several hundred reviewers were described by means of texts they had written, and this formed the basis of the LSI analysis. Hundreds of submitted papers were represented by their abstracts, and matched to the closest reviewers.
Reference: [10] <author> P. W. Foltz, </author> <title> Using Latent Semantic Indexing for information filtering, </title> <booktitle> in Proceedings of the ACM Conference on Office Information Systems (COIS), </booktitle> <year> 1990, </year> <pages> pp. 40-47. </pages>
Reference-contexts: Each new document is matched against the vector and if it is similar enough to the interest vector it is recommended to the user. Learning methods like relevance feedback can be used to improve the representation of interest vectors over time. Foltz <ref> [10] </ref> compared LSI and keyword vector methods for filtering Netnews articles, and found 12%- 23% advantages for LSI. Dumais and Foltz in [11] compared several different methods for representing users interests for filtering technical memoranda.
Reference: [11] <author> P. W. Foltz and S. T. Dumais, </author> <title> Personalized information delivery: An analysis of information filtering methods, </title> <journal> Communications of the ACM, </journal> <volume> 35 (1992), </volume> <pages> pp. 51-60. </pages>
Reference-contexts: Learning methods like relevance feedback can be used to improve the representation of interest vectors over time. Foltz [10] compared LSI and keyword vector methods for filtering Netnews articles, and found 12%- 23% advantages for LSI. Dumais and Foltz in <ref> [11] </ref> compared several different methods for representing users interests for filtering technical memoranda. The most effective method used vectors derived from known relevant documents (like relevance feedback) combined with LSI matching. TREC.
Reference: [12] <author> G. W. Furnas, S. Deerwester, S. T. Dumais, T. K. Landauer, R. A. Harshman, L. A. Streeter, and K. E. Lochbaum, </author> <title> Information retrieval using a singular value decomposition model of latent semantic structure, </title> <booktitle> in Proceedings of SIGIR, </booktitle> <year> 1988, </year> <pages> pp. 465-480. </pages>
Reference-contexts: For several information science test collections, the average precision using LSI ranged from comparable to to 30% better than that obtained using standard keyword vector methods. See <ref> [4, 12, 6] </ref> for details of these evaluations. The LSI method performs best relative to standard vector methods when the queries and relevant documents do not share many words, and at high levels of recall. Term Weighting. <p> Matching People Instead of Documents. In a couple of applications, LSI has been used to return the best matching people instead of documents. In these applications, people were represented by articles they had written. In one application <ref> [12] </ref>, known as the Bellcore Advisor, a system was developed to find local experts relevant to users' queries. A query was matched to the nearest documents and project descriptions and the authors organization was returned as the most relevant internal group.
Reference: [13] <author> S. I. Gallant, </author> <title> A practical approach for representing contexts and for performing word sense disambiguation using neural networks, </title> <booktitle> Neural Computation, 3 (1991), </booktitle> <pages> pp. 293-309. </pages>
Reference-contexts: Related Work. A number of other researchers are using related linear algebra methods for information retrieval and classification work. Schutze [26] and Gallant <ref> [13] </ref> have used SVD and related dimension reduction ideas for word sense disambiguation and information retrieval work. Hull [16] and Yang and Chute [28] have used LSI/SVD as the first step in conjunction with statistical classification (e.g. discriminant analysis).
Reference: [14] <author> G. Golub and C. V. Loan, </author> <title> Matrix Computations, </title> <address> Johns-Hopkins, Baltimore, </address> <note> second ed., </note> <year> 1989. </year>
Reference: [15] <author> G. Golub and C. Reinsch, </author> <title> Handbook for automatic computation II, linear algebra, </title> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1971. </year>
Reference: [16] <author> D. Hull, </author> <title> Improving text retrieval for the routing problem using Latent Semantic Indexing, </title> <booktitle> in Proceedings of the Seventeenth Annual International ACM-SIGIR Conference, </booktitle> <year> 1994, </year> <pages> pp. 282-291. </pages>
Reference-contexts: Related Work. A number of other researchers are using related linear algebra methods for information retrieval and classification work. Schutze [26] and Gallant [13] have used SVD and related dimension reduction ideas for word sense disambiguation and information retrieval work. Hull <ref> [16] </ref> and Yang and Chute [28] have used LSI/SVD as the first step in conjunction with statistical classification (e.g. discriminant analysis). Using the LSI-derived dimensions effectively reduces the number of predictor variables for classification.
Reference: [17] <author> Y. Kane-Esrig, L. Streeter, S. T. Dumais, W. Keese, and G. Casella, </author> <title> The relevance density method for multi-topic queries in information retrieval, </title> <booktitle> in Proceedings of the 23rd Symposium on the Interface, </booktitle> <editor> E. Keramidas, ed., </editor> <year> 1991, </year> <pages> pp. 407-410. </pages>
Reference-contexts: Queries can be either terms (as in most information retrieval applications), documents or combinations of the two (as in relevance feedback). Queries can even be represented as multiple points of interest <ref> [17] </ref>. Similarly, the objects returned to the user are typically documents, but there is no reason that similar terms could not be returned.
Reference: [18] <author> K. Kukich, </author> <title> A comparison of some novel and traditional lexical distance metrics for for spelling correction, </title> <booktitle> in Proceedings of INNC-90-Paris, </booktitle> <year> 1990, </year> <pages> pp. 309-313. </pages>
Reference-contexts: Even though the error rates were 8:8% at the word level, information retrieval performance using LSI was not disrupted (compared with the same uncorrupted texts). Kukich <ref> [18] </ref> used LSI for a related problem, spelling correction. In this application, the rows were unigrams and bigrams and the columns were correctly spelled words.
Reference: [19] <author> T. K. Landauer and S. T. Dumais, </author> <title> Latent Semantic Analysis and the measurement of knowledge, </title> <booktitle> in Proceedings of the First Educational Testing Service Conference on Applications of Natural Language Processing in Assessment and Education, </booktitle> <year> 1994. </year> <note> To appear. </note>
Reference-contexts: The method has shown almost as good results for retrieving English abstracts and Japanese Kanji ideographs, and for multilingual translations (English and Greek) of the Bible [29]. Modeling Human Memory. Landauer and Dumais <ref> [19] </ref> have recently used LSI spaces to model some of the associative relationships observed in human memory. They were interested in term-term similarities.
Reference: [20] <author> T. K. Landauer and M. L. Littman, </author> <title> Fully automatic cross-language document retrieval using latent semantic indexing, </title> <booktitle> in Proceedings of the Sixth Annual Conference of the UW Centre for the New Oxford English Dictionary and Text Research, UW Centre for the New OED and Text Research, </booktitle> <address> Waterloo Ontario, </address> <year> 1990, </year> <pages> pp. 31-38. </pages> <note> 24 Berry and Dumais </note>
Reference-contexts: In addition, it can be used for cross-language retrieval documents are in several languages and user queries (again in several languages) can match documents in any language. What is required for cross-language applications is a common space in which words from many languages are represented. Landauer and Littman in <ref> [20] </ref> described one method for creating such an LSI space. The original term-document matrix is formed using a collection of abstracts that have versions in more than one language (French and English, in their experiments). Each abstract is treated as the combination of its French English versions.
Reference: [21] <author> L. Mirsky, </author> <title> Symmetric gage functions and unitarilly invariant norms, Q. </title> <journal> J. Math, </journal> <volume> 11 (1960), </volume> <pages> pp. 50-59. </pages>
Reference: [22] <author> J. Nielsen, V. L. Phillips, and S. T. Dumais, </author> <title> Retrieving imperfectly recognized handwritten notes, </title> <booktitle> Behaviour and Information Technology, </booktitle> <year> (1994). </year> <note> Submitted. </note>
Reference-contexts: If these correctly spelled context words also occur in documents which contained a correctly spelled version of Dumais, then Dumais will probably be near Duniais in the k-dimensional space determined by A k (see Equation 2 or Figure 1). Nielsen et al. in <ref> [22] </ref> used LSI to index a small collection of abstracts input by a commercially available pen machine in its standard recognizer mode. Even though the error rates were 8:8% at the word level, information retrieval performance using LSI was not disrupted (compared with the same uncorrupted texts).
Reference: [23] <author> G. W. O'Brien, </author> <title> Information Management Tools for Updating an SVD-Encoded Indexing Scheme, </title> <type> Master's thesis, </type> <institution> The University of Knoxville, Tennessee, Knoxville, TN, </institution> <year> 1994. </year>
Reference-contexts: A different cosine threshold, of course, could have been used so that a larger or smaller set of documents would be returned. The cosine is merely used to rank-order documents and its explicit value is not always an adequate measure of relevance <ref> [23, 29] </ref>. 3.2. Comparison with Lexical Matching. In this example, LSI has been applied using two factors, i.e. A 2 is used to approximate the original 16fi 17 term-document matrix. <p> Updating methods which can approximate the SVD of the larger term-document matrix ~ A become attractive in the presence of memory or time constraints. As discussed in <ref> [23] </ref>, the the accuracy of SVD-updating approaches can be easily compared to that obtained when the SVD of ~ A is explicitly computed. Suppose the titles from Table 5 are combined with those of Table 2 in order to create a new 16 fi 20 term-document matrix ~ A. <p> The three steps required to perform a complete SVD-update involve adding new documents, adding new terms, and correction for changes in term weightings. The order of these steps, however, need not follow the ordering presented in this section (see <ref> [23] </ref>). 4.1. Overview. Let D denote the p new document vectors to process, then D is an mfip sparse matrix since most terms (as was the case with the original term-document matrix A) do not occur in each document. <p> be an m fi j matrix comprised of rows of zeros or rows of the j-th order identity matrix, I j , and let Z j be an n fi j matrix whose columns specify the actual differences between old and new weights for each of the j terms (see <ref> [23] </ref> for examples). Computing the SVD of the following rank-j update to A k defines the correction step. W = A k + Y j Z T 4.2. SVD-Updating Procedures. The mathematical computations required in each phase of the SVD-updating process are detailed in this section. <p> Using the complexities in Table 7 the required number of floating-point operations (or flops) for each method can be compared for varying numbers of added documents or terms. As shown in <ref> [23] </ref> for a condensed encyclopedia test case, the computational advantages of one scheme over another depends the values of the variables listed in Table 6. <p> The trade-off in computational complexity and loss of orthogonality in the coordinate axes for updating databases using LSI poses interesting future research. Though the SVD-updating process is considerably more expensive <ref> [23] </ref> than folding-in, the true lower-rank approximation to the true term-document matrix A defined by Figure 1 is maintained.
Reference: [24] <author> G. Salton, </author> <title> Automatic Information Organization and Retrieval, </title> <publisher> McGraw Hill, </publisher> <address> New York, </address> <year> 1968. </year>
Reference-contexts: Average precision across several levels of recall can then be used as a summary measure of performance. Results were obtained for LSI and compared against published or computed results for other retrieval techniques, notably the standard keyword vector method in SMART <ref> [24] </ref>. For several information science test collections, the average precision using LSI ranged from comparable to to 30% better than that obtained using standard keyword vector methods. See [4, 12, 6] for details of these evaluations.
Reference: [25] <author> G. Salton and C. Buckley, </author> <title> Improving retrieval performance by relevance feedback, </title> <journal> Journal of the American Society for Information Science, </journal> <volume> 41 (1990), </volume> <pages> pp. 288-297. </pages>
Reference-contexts: Relevance Feedback. The idea behind relevance feedback is quite simple. Users are very unlikely to be able to specify their information needs adequately, especially on the first try. In interactive retrieval situations, it is possible to take advantage of user feedback about relevant and non-relevant documents <ref> [25] </ref>. Systems can use information about which documents are relevant in many ways. Typically the weight given to terms occurring in relevant documents is increased and the weight of terms occurring in non-relevant documents is decreased.
Reference: [26] <author> H. Schutze, </author> <title> Dimensions of meaning, </title> <booktitle> in Proceedings of Supercomputing'92, </booktitle> <year> 1992, </year> <pages> pp. 787-796. </pages>
Reference-contexts: Related Work. A number of other researchers are using related linear algebra methods for information retrieval and classification work. Schutze <ref> [26] </ref> and Gallant [13] have used SVD and related dimension reduction ideas for word sense disambiguation and information retrieval work. Hull [16] and Yang and Chute [28] have used LSI/SVD as the first step in conjunction with statistical classification (e.g. discriminant analysis).
Reference: [27] <author> C. Wu, M. Berry, S. Shivakumar, and J. McLarty, </author> <title> Neural networks for full-scale protein sequence classification: Sequence encoding with singular value decomposition, </title> <booktitle> Machine Learning, </booktitle> <year> (1994). </year> <note> To appear. </note>
Reference-contexts: Hull [16] and Yang and Chute [28] have used LSI/SVD as the first step in conjunction with statistical classification (e.g. discriminant analysis). Using the LSI-derived dimensions effectively reduces the number of predictor variables for classification. Wu et al. in <ref> [27] </ref> also used LSI/SVD to reduce Using Linear Algebra for Intelligent Information Retrieval 23 the training set dimension for a neural network protein classification system used in human genome research. 6. Acknowledgements.
Reference: [28] <author> Y. Yang and C. G. Chute, </author> <title> An application of least squares fit mapping to text information retrieval, </title> <booktitle> in Proceedings of the Sixteenth Annual International ACM-SIGIR Conference, </booktitle> <year> 1993, </year> <pages> pp. 281-290. </pages>
Reference-contexts: Related Work. A number of other researchers are using related linear algebra methods for information retrieval and classification work. Schutze [26] and Gallant [13] have used SVD and related dimension reduction ideas for word sense disambiguation and information retrieval work. Hull [16] and Yang and Chute <ref> [28] </ref> have used LSI/SVD as the first step in conjunction with statistical classification (e.g. discriminant analysis). Using the LSI-derived dimensions effectively reduces the number of predictor variables for classification.
Reference: [29] <author> P. G. Young, </author> <title> Cross-Language Information Retrieval Using Latent Semantic Indexing, </title> <type> Master's thesis, </type> <institution> The University of Knoxville, Tennessee, Knoxville, TN, </institution> <year> 1994. </year>
Reference-contexts: A different cosine threshold, of course, could have been used so that a larger or smaller set of documents would be returned. The cosine is merely used to rank-order documents and its explicit value is not always an adequate measure of relevance <ref> [23, 29] </ref>. 3.2. Comparison with Lexical Matching. In this example, LSI has been applied using two factors, i.e. A 2 is used to approximate the original 16fi 17 term-document matrix. <p> The method has shown almost as good results for retrieving English abstracts and Japanese Kanji ideographs, and for multilingual translations (English and Greek) of the Bible <ref> [29] </ref>. Modeling Human Memory. Landauer and Dumais [19] have recently used LSI spaces to model some of the associative relationships observed in human memory. They were interested in term-term similarities.
References-found: 27

