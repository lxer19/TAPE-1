URL: http://www.cis.ohio-state.edu/~clam/papers/jpdc-submit.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~clam/
Root-URL: http://www.cis.ohio-state.edu
Title: Optimal Algorithms for All-to-All Personalized Communication on Rings and Two Dimensional Tori for two dimensional
Author: Chi Chung Lam C.-H. Huang P. Sadayappan 
Note: and  
Address: Columbus, OH 43210  
Affiliation: Dept. of Computer Information Science The Ohio State University  
Abstract: All-to-all personalized communication is a basic communication operation in a parallel computing environment. In this operation, each processor sends a distinct message to every other processor. It is used in several parallel computing applications, such as the fast Fourier transform. This paper presents new algorithms to perform the all-to-all personalized communication on ring and torus-structured networks of p processors, where and for rings, and 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Gupta, S. Hawkinson, and B. Baxter. </author> <title> A Binary Interleaved Algorithm for Complete Exchange on a Mesh Architecture. </title> <type> Technical Report, </type> <institution> Intel Corporation, </institution> <year> 1994. </year>
Reference-contexts: Each processor sends different messages to different processors. This operation is used in parallel fast Fourier transform, matrix transpose, and some parallel database join operations [4]. The problem of all-to-all personalized communication on hypercubes and meshes has been studied extensively <ref> [1, 2, 3, 6] </ref>. But the number of algorithms for rings and tori are relatively few. One straightforward algorithm given in [4] for a ring of p processors completes the operation in a total time of .
Reference: [2] <author> N. S. Sundar, D. N. Jayasimha, D. K. Panda, and P. Sadayappan. </author> <title> Complete Exchange in 2D Meshes. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <pages> pages 406-413, </pages> <year> 1994. </year>
Reference-contexts: Each processor sends different messages to different processors. This operation is used in parallel fast Fourier transform, matrix transpose, and some parallel database join operations [4]. The problem of all-to-all personalized communication on hypercubes and meshes has been studied extensively <ref> [1, 2, 3, 6] </ref>. But the number of algorithms for rings and tori are relatively few. One straightforward algorithm given in [4] for a ring of p processors completes the operation in a total time of . <p> The algorithm proposed here is faster than the one in [5] Table 3: Comparison of Algorithms for All-to-All Personalized Communication Topology Algorithm Type Transmission Time Start-up Time 2D Mesh Scott [3] Direct 2D Mesh Bokhari & Berryman [6] Indirect 2D Mesh Sundar, et-al. <ref> [2] </ref> Indirect 2D Torus Tseng, et-al. [5] Indirect 2D Torus This Paper Direct t s mt w t s + 4 1 - p pt s 4 1 - p pmt w 1 - p p 4+( ) mt w 2 1 - p pmt w 8 19 The above inequality
Reference: [3] <author> D. Scott. </author> <title> Efficient All-to-All Communication Patterns in Hypercube and Mesh Topologies. </title> <booktitle> In IEEE Distributed Memory Conference, </booktitle> <pages> pages 398-403, </pages> <year> 1991. </year>
Reference-contexts: Each processor sends different messages to different processors. This operation is used in parallel fast Fourier transform, matrix transpose, and some parallel database join operations [4]. The problem of all-to-all personalized communication on hypercubes and meshes has been studied extensively <ref> [1, 2, 3, 6] </ref>. But the number of algorithms for rings and tori are relatively few. One straightforward algorithm given in [4] for a ring of p processors completes the operation in a total time of . <p> Then, a time unit used in this paper corresponds to . Table 3 compares the start-up time and transmission time of the algorithms in this paper and some other algorithms proposed for meshes and tori. Among the mesh algorithms listed in Table 3, Scotts algorithm <ref> [3] </ref> is most efficient in terms of transmission time. But it is still twice slower than the torus algorithm in this paper although both algorithms are direct. This factor of two in the relative efficiency is due to the intrinsic limitations of a mesh. <p> Furthermore, their algorithm requires some additional time to rearrange the messages between phases. The algorithm proposed here is faster than the one in [5] Table 3: Comparison of Algorithms for All-to-All Personalized Communication Topology Algorithm Type Transmission Time Start-up Time 2D Mesh Scott <ref> [3] </ref> Direct 2D Mesh Bokhari & Berryman [6] Indirect 2D Mesh Sundar, et-al. [2] Indirect 2D Torus Tseng, et-al. [5] Indirect 2D Torus This Paper Direct t s mt w t s + 4 1 - p pt s 4 1 - p pmt w 1 - p p 4+( )
Reference: [4] <author> V. Kumar, A. Grama, A. Gupta, and G. Karypis. </author> <title> Introduction to Parallel Computing: Design and Analysis of Algorithms. </title> <address> RedWood City, CA: Benjamin/Cummings, </address> <year> 1994. </year>
Reference-contexts: Each processor sends different messages to different processors. This operation is used in parallel fast Fourier transform, matrix transpose, and some parallel database join operations <ref> [4] </ref>. The problem of all-to-all personalized communication on hypercubes and meshes has been studied extensively [1, 2, 3, 6]. But the number of algorithms for rings and tori are relatively few. One straightforward algorithm given in [4] for a ring of p processors completes the operation in a total time of <p> used in parallel fast Fourier transform, matrix transpose, and some parallel database join operations <ref> [4] </ref>. The problem of all-to-all personalized communication on hypercubes and meshes has been studied extensively [1, 2, 3, 6]. But the number of algorithms for rings and tori are relatively few. One straightforward algorithm given in [4] for a ring of p processors completes the operation in a total time of . In the first step of that algorithm, each processor sends half of its messages in a packet in one direction and the remaining half in the other direction.
Reference: [5] <author> Y.-C. Tseng, S. Gupta, and D. Panda. </author> <title> An Efficient Scheme for Complete Exchange in 2D Tori In Proceedings of 9th International Parallel Processing Symposium, </title> <address> pages 532-536, </address> <year> 1995. </year>
Reference-contexts: Upon receiving the packets, each processor extracts the messages meant for it and forwards the remainder to the next processor in the direction of the messages. The process is repeated until all messages have reached their destination processors. The diagonal propagation algorithm proposed in <ref> [5] </ref> works on two dimensional tori of size . In each of the first two steps, every node sends half of all its messages to the furthest node in the same column or row. The algorithm then proceeds recursively by halving the message distances in each iteration. <p> Since meshes have no wrap-around connections, message distances become larger compared to those for equal-sized tori and the bottle neck region near the center of meshes is hard to avoid. The algorithm proposed by Tseng, Gupta, and Panda <ref> [5] </ref> is based on the indirect model. In contrast with the torus algorithm in this paper, their algorithm saves some start-up time as it packs and sends messages in large packets. <p> Furthermore, their algorithm requires some additional time to rearrange the messages between phases. The algorithm proposed here is faster than the one in <ref> [5] </ref> Table 3: Comparison of Algorithms for All-to-All Personalized Communication Topology Algorithm Type Transmission Time Start-up Time 2D Mesh Scott [3] Direct 2D Mesh Bokhari & Berryman [6] Indirect 2D Mesh Sundar, et-al. [2] Indirect 2D Torus Tseng, et-al. [5] Indirect 2D Torus This Paper Direct t s mt w t <p> The algorithm proposed here is faster than the one in <ref> [5] </ref> Table 3: Comparison of Algorithms for All-to-All Personalized Communication Topology Algorithm Type Transmission Time Start-up Time 2D Mesh Scott [3] Direct 2D Mesh Bokhari & Berryman [6] Indirect 2D Mesh Sundar, et-al. [2] Indirect 2D Torus Tseng, et-al. [5] Indirect 2D Torus This Paper Direct t s mt w t s + 4 1 - p pt s 4 1 - p pmt w 1 - p p 4+( ) mt w 2 1 - p pmt w 8 19 The above inequality holds whenever: Thus, the algorithm proposed
Reference: [6] <author> S. H. Bokhari, H. Berryman. </author> <title> Complete Exchange on a Circuit Switched Mesh. </title> <booktitle> In Scalable High Performance Computing Conference, </booktitle> <pages> pages 300-306, </pages> <address> 1992. 1 -p p 4+( ) mt w 2 1 -p pmt w 1 -p pt s +&gt; t w mt w t s &gt; </address>
Reference-contexts: Each processor sends different messages to different processors. This operation is used in parallel fast Fourier transform, matrix transpose, and some parallel database join operations [4]. The problem of all-to-all personalized communication on hypercubes and meshes has been studied extensively <ref> [1, 2, 3, 6] </ref>. But the number of algorithms for rings and tori are relatively few. One straightforward algorithm given in [4] for a ring of p processors completes the operation in a total time of . <p> The algorithm proposed here is faster than the one in [5] Table 3: Comparison of Algorithms for All-to-All Personalized Communication Topology Algorithm Type Transmission Time Start-up Time 2D Mesh Scott [3] Direct 2D Mesh Bokhari & Berryman <ref> [6] </ref> Indirect 2D Mesh Sundar, et-al. [2] Indirect 2D Torus Tseng, et-al. [5] Indirect 2D Torus This Paper Direct t s mt w t s + 4 1 - p pt s 4 1 - p pmt w 1 - p p 4+( ) mt w 2 1 - p pmt
References-found: 6

