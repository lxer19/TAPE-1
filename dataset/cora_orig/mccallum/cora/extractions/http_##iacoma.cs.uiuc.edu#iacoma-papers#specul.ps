URL: http://iacoma.cs.uiuc.edu/iacoma-papers/specul.ps
Refering-URL: http://iacoma.cs.uiuc.edu/papers.html
Root-URL: http://www.cs.uiuc.edu
Email: venkat,torrella@cs.uiuc.edu  
Title: Executing Sequential Binaries on a Clustered Multithreaded Architecture with Speculation Support 1  
Author: Venkata Krishnan and Josep Torrellas 
Keyword: superscalar, chip multiprocessors, simultaneous multithreading, speculation, binary annotation  
Web: http://iacoma.cs.uiuc.edu/iacoma/  
Address: IL 61801  
Affiliation: Department of Computer Science University of Illinois at Urbana-Champaign,  
Abstract: With the conventional superscalar approach of exploiting ILP from a single flow of control giving diminishing returns, integrating multiple processing units on a die seems to be a promising approach. However, in these architectures, the resources are partitioned such that a thread is allocated exclusively to a processor. This risks wasting resources when a thread stalls due to hazards. While simultaneous multithreading (SMT) addresses this problem with complete resource sharing, its centralized structure may impact the clock frequency. An intuitive solution is a hybrid of the two architectures, namely, a clustered SMT architecture, where the chip has several independent processing units, with each unit having the capability to perform simultaneous multithreading. In this paper, we describe a software-hardware approach that enables speculative execution of a sequential binary on a clustered SMT architecture. The software support includes a compiler that can identify threads from sequential binaries. The hardware includes support for inter-thread register synchronization and memory disambiguation. We evaluate the resulting clustered SMT architecture and show that it is more cost effective than a centralized SMT and architectures where all the resources have a fixed assignment. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> P. Dubey, K. O'Brien, K. O'Brien, and C. Barton. </author> <title> Single-program speculative multithreading (SPSM) architecture: Compiler-assisted fine-grained multithreading. </title> <booktitle> In Proceedings of the IFIP WG 10.3 Working Conference on Parallel Architectures and Compilation Techniques, PACT '95, </booktitle> <pages> pages 109-121, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: Since identifying fully independent threads statically is quite difficult, a good approach is for the compiler to identify threads in a speculative fashion at compile time <ref> [1, 10] </ref> and for the hardware to assist at run-time to honor dependences [6, 8]. It has been shown that this speculative approach has good potential [9]. A large number of applications are available only in their binary form. <p> Processor Number Threads per Max. IPC per Number of FUs per Type of Processors Processor [Chip] Processor [Chip] Processor [Chip] (int/ld-st/fp) Conventional Superscalar 1 1 <ref> [1] </ref> 8 [8] 8/4/4 [8/4/4] Centralized SM T 1 4 [4] 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 [2] 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment
Reference: [2] <author> M. Franklin and G. Sohi. ARB: </author> <title> A hardware mechanism for dynamic memory disambiguation. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 45(5) </volume> <pages> 552-571, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: To enable a thread to acquire the correct register value during its execution, we propose a special scoreboard that we call the Synchronizing Scoreboard (Section 2.2.1). To support memory disambiguation, we use the Memory Disambiguation Table, whose functionality is similar to the ARB <ref> [2] </ref>, together with private write buffers for each thread (Section 2.2.2). For the hardware to work, each thread maintains its status in the form of a bit-mask (called T hreadM ask) in a special register. <p> IPC per Number of FUs per Type of Processors Processor [Chip] Processor [Chip] Processor [Chip] (int/ld-st/fp) Conventional Superscalar 1 1 [1] 8 [8] 8/4/4 [8/4/4] Centralized SM T 1 4 [4] 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 <ref> [2] </ref> 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment is built upon the MINT [12] execution-driven simulation environment.
Reference: [3] <author> V. Krishnan and J. Torrellas. </author> <title> Efficient use of processing transistors for larger on-chip storage: Multithreading. In Workshop on Mixing Logic and DRAM: Chips that Compute and Remember, </title> <month> June </month> <year> 1997. </year>
Reference-contexts: If, in a given cycle, a thread is not using a resource, that resource can typically be utilized by another thread. Evaluation of this architecture running multiprogrammed and parallel workloads <ref> [3, 4, 11] </ref> 1 This work was supported in part by the National Science Foundation under grants NSF Young Investigator Award MIP-9457436, ASC-9612099 and MIP-9619351, DARPA Contract DABT63-95-C-0097, NASA Contract NAG-1-613, and gifts from IBM and Intel. has shown significant speedups.
Reference: [4] <author> J. Lo, S. Eggers, J. Emer, H. Levy, R. Stamm, and D. Tullsen. </author> <title> Converting thread-level parallelism into instruction-level parallelism via simultaneous mul-tithreading. </title> <journal> ACM Transactions on Computer Systems, </journal> <pages> pages 322-354, </pages> <month> August </month> <year> 1997. </year>
Reference-contexts: If, in a given cycle, a thread is not using a resource, that resource can typically be utilized by another thread. Evaluation of this architecture running multiprogrammed and parallel workloads <ref> [3, 4, 11] </ref> 1 This work was supported in part by the National Science Foundation under grants NSF Young Investigator Award MIP-9457436, ASC-9612099 and MIP-9619351, DARPA Contract DABT63-95-C-0097, NASA Contract NAG-1-613, and gifts from IBM and Intel. has shown significant speedups. <p> Processor Number Threads per Max. IPC per Number of FUs per Type of Processors Processor [Chip] Processor [Chip] Processor [Chip] (int/ld-st/fp) Conventional Superscalar 1 1 [1] 8 [8] 8/4/4 [8/4/4] Centralized SM T 1 4 <ref> [4] </ref> 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 [2] 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment is built upon the MINT [12] execution-driven simulation environment. <p> Processor Number Threads per Max. IPC per Number of FUs per Type of Processors Processor [Chip] Processor [Chip] Processor [Chip] (int/ld-st/fp) Conventional Superscalar 1 1 [1] 8 [8] 8/4/4 [8/4/4] Centralized SM T 1 4 <ref> [4] </ref> 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 [2] 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment is built upon the MINT [12] execution-driven simulation environment.
Reference: [5] <author> K. Olukotun, B. Nayfeh, L. Hammond, K. Wilson, and K. Chang. </author> <title> The case for a single-chip multiprocessor. </title> <booktitle> In 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 2-11, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: 1 Introduction With wire delays dominating the cycle time of future microprocessors, alternatives to the conventional superscalar design are being actively investigated. One promising approach is to integrate multiple processing units on a single die <ref> [5] </ref>. This allows multiple control flows (also called threads) in the application to be executed concurrently. Unfortunately, by assigning a thread exclusively to a processor [5, 8, 10], we run the risk of wasting resources. <p> One promising approach is to integrate multiple processing units on a single die [5]. This allows multiple control flows (also called threads) in the application to be executed concurrently. Unfortunately, by assigning a thread exclusively to a processor <ref> [5, 8, 10] </ref>, we run the risk of wasting resources. Indeed, when a thread cannot execute due to a hazard, the resources of its processor are typically wasted. We term this type of architecture the fixed assignment (FA) architecture.
Reference: [6] <author> J. Oplinger, D. Heine, S.-W. Liao, B. Nayfeh, M. Lam, and K. Olukotun. </author> <title> Software and hardware for exploiting speculative parallelism with a multiprocessor. </title> <type> Technical Report CSL-TR-97-715, </type> <institution> Computer Systems Laboratory, Stanford University, </institution> <month> February </month> <year> 1997. </year>
Reference-contexts: Since identifying fully independent threads statically is quite difficult, a good approach is for the compiler to identify threads in a speculative fashion at compile time [1, 10] and for the hardware to assist at run-time to honor dependences <ref> [6, 8] </ref>. It has been shown that this speculative approach has good potential [9]. A large number of applications are available only in their binary form. As a result, this approach needs to be used at the binary level too.
Reference: [7] <author> S. Palacharla, N. Jouppi, and J. Smith. </author> <title> Complexity-effective superscalar processors. </title> <booktitle> In 24th International Symposium on Computer Architecture, </booktitle> <pages> pages 206-218, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: However, a drawback of this approach is that it may inherit the complexity of existing su-perscalars. In fact, with the delays in the register bypass network dictating the cycle time of future high-issue processors <ref> [7] </ref>, a fully centralized SMT processor is likely to have a slower clock. An intuitive alternative is a hybrid of the FA and the centralized SMT approaches, namely a clustered SMT architecture. <p> So the complexity of this phase is less than that of the wakeup and selection delay for a 32-instruction associative window in a dynamic superscalar processor. Thus, this doesn't affect the cycle time of the centralized architecture as much as the bypass delay <ref> [7] </ref>. To alleviate the bypass problem, we partition the SMT processor into 2 clusters of 4-issue SMT processing units. Each processing unit supports 2 threads and has its own fetch unit that can fetch 4 instructions/cycle in a round robin fashion. <p> In terms of delay, the synchronizing scoreboard can be thought of as a renaming table of 32 entries. Using the model provided by <ref> [7] </ref> for an 8-issue processor with 0.18 technology, the estimated delay for the synchronizing scoreboard would be around 500ps, while the estimated delay for the bypass network is over 1000ps. <p> Therefore, the complexity of their bypass networks is likely to be similar for a given implementation. Since we follow <ref> [7] </ref> in assuming that the delay in the bypass network is the most dominant one, both processors should have approximately the same clock cycle time. ijpeg and eqntott , both processors have similar performance, while for the remaining, floating-point applications, the SMT processor is better than the dynamic superscalar. <p> The clock cycle time in these two architectures and in the clustered SMT is comparable. The reason is that the bypass networks in the three architectures are too small to determine the cycle time <ref> [7] </ref>. Instead, the cycle time is determined by the synchronizing scoreboard, which is the same for the three architectures. architectures. In the floating point applications, performance is decided by the thread parallelism.
Reference: [8] <author> G. Sohi, S. Breach, and T. Vijayakumar. </author> <title> Multiscalar processors. </title> <booktitle> In 22nd International Symposium on Computer Architecture, </booktitle> <pages> pages 414-425, </pages> <month> June </month> <year> 1995. </year>
Reference-contexts: One promising approach is to integrate multiple processing units on a single die [5]. This allows multiple control flows (also called threads) in the application to be executed concurrently. Unfortunately, by assigning a thread exclusively to a processor <ref> [5, 8, 10] </ref>, we run the risk of wasting resources. Indeed, when a thread cannot execute due to a hazard, the resources of its processor are typically wasted. We term this type of architecture the fixed assignment (FA) architecture. <p> Since identifying fully independent threads statically is quite difficult, a good approach is for the compiler to identify threads in a speculative fashion at compile time [1, 10] and for the hardware to assist at run-time to honor dependences <ref> [6, 8] </ref>. It has been shown that this speculative approach has good potential [9]. A large number of applications are available only in their binary form. As a result, this approach needs to be used at the binary level too. <p> The steps involved in the annotation process are illustrated in Figure 1. The approach we use is similar to that of Multi-scalar <ref> [8] </ref> except that we operate on the binary instead of the source program. First, we identify inner loop iterations and annotate their initiation and termination points. Then, we need to identify the register level dependences between these threads. <p> Processor Number Threads per Max. IPC per Number of FUs per Type of Processors Processor [Chip] Processor [Chip] Processor [Chip] (int/ld-st/fp) Conventional Superscalar 1 1 [1] 8 <ref> [8] </ref> 8/4/4 [8/4/4] Centralized SM T 1 4 [4] 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 [2] 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment is built <p> Processor Number Threads per Max. IPC per Number of FUs per Type of Processors Processor [Chip] Processor [Chip] Processor [Chip] (int/ld-st/fp) Conventional Superscalar 1 1 [1] 8 <ref> [8] </ref> 8/4/4 [8/4/4] Centralized SM T 1 4 [4] 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 [2] 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment is built upon the MINT [12] execution-driven simulation environment. <p> Processor Number Threads per Max. IPC per Number of FUs per Type of Processors Processor [Chip] Processor [Chip] Processor [Chip] (int/ld-st/fp) Conventional Superscalar 1 1 [1] 8 <ref> [8] </ref> 8/4/4 [8/4/4] Centralized SM T 1 4 [4] 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 [2] 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment is built upon the MINT [12] execution-driven simulation environment. <p> Number of FUs per Type of Processors Processor [Chip] Processor [Chip] Processor [Chip] (int/ld-st/fp) Conventional Superscalar 1 1 [1] 8 <ref> [8] </ref> 8/4/4 [8/4/4] Centralized SM T 1 4 [4] 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 [2] 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment is built upon the MINT [12] execution-driven simulation environment.
Reference: [9] <author> J. Steffan and T. Mowry. </author> <title> The potential for thread-level data speculation in tightly-coupled multiprocessors. </title> <type> Technical Report CSRI-TR-350, </type> <institution> Computer Systems Research Institute, University of Toronto, </institution> <month> February </month> <year> 1997. </year>
Reference-contexts: It has been shown that this speculative approach has good potential <ref> [9] </ref>. A large number of applications are available only in their binary form. As a result, this approach needs to be used at the binary level too.
Reference: [10] <author> J. Tsai and P. Yew. </author> <title> The superthreaded architecture: Thread pipelining with run-time data dependence checking and control speculation. </title> <booktitle> In Proceedings of International Conference on Parallel Architectures and Compilation Techniques (PACT '96), </booktitle> <pages> pages 35-46, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: One promising approach is to integrate multiple processing units on a single die [5]. This allows multiple control flows (also called threads) in the application to be executed concurrently. Unfortunately, by assigning a thread exclusively to a processor <ref> [5, 8, 10] </ref>, we run the risk of wasting resources. Indeed, when a thread cannot execute due to a hazard, the resources of its processor are typically wasted. We term this type of architecture the fixed assignment (FA) architecture. <p> Since identifying fully independent threads statically is quite difficult, a good approach is for the compiler to identify threads in a speculative fashion at compile time <ref> [1, 10] </ref> and for the hardware to assist at run-time to honor dependences [6, 8]. It has been shown that this speculative approach has good potential [9]. A large number of applications are available only in their binary form.
Reference: [11] <author> D. Tullsen, S. Eggers, J. Emer, H. Levy, J. Lo, and R. Stamm. </author> <title> Exploiting choice: Instruction fetch and issue on an implementable simultaneous multithreading processor. </title> <booktitle> In 23rd International Symposium on Computer Architecture, </booktitle> <pages> pages 191-202, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: We term this type of architecture the fixed assignment (FA) architecture. To utilize the resources better, we can design a more centralized architecture where threads can share all the resources. This is the approach taken by the basic Simultaneous Multi-threading (SMT) <ref> [11] </ref>. In this scheme, the processor can support multiple threads such that, in a given cycle, instructions from different threads can be issued. If, in a given cycle, a thread is not using a resource, that resource can typically be utilized by another thread. <p> If, in a given cycle, a thread is not using a resource, that resource can typically be utilized by another thread. Evaluation of this architecture running multiprogrammed and parallel workloads <ref> [3, 4, 11] </ref> 1 This work was supported in part by the National Science Foundation under grants NSF Young Investigator Award MIP-9457436, ASC-9612099 and MIP-9619351, DARPA Contract DABT63-95-C-0097, NASA Contract NAG-1-613, and gifts from IBM and Intel. has shown significant speedups. <p> In this architecture, the chip has several independent processing units, with each unit having the capability to perform simultaneous multithreading. Given that the effort to enhance a conventional dynamic superscalar to perform simultaneous multithreading is small <ref> [11] </ref>, a low-issue SMT processor is feasible. Also, a clustered SMT architecture is a simple design as it involves replicating several low-issue SMT processors on a die. However, it might be argued that this separation of processing units would restrict the sharing of resources.
Reference: [12] <author> J. Veenstra and R. Fowler. MINT: </author> <title> A front end for efficient simulation of shared-memory multiprocessors. </title> <booktitle> In Proceedings of the Second International Workshop on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS'94), </booktitle> <pages> pages 201-207, </pages> <month> January </month> <year> 1994. </year>
Reference-contexts: SM T 1 4 [4] 8 [8] 8/4/4 [8/4/4] Clustered SM T 2 2 [4] 4 [8] 4/2/2 [8/4/4] F A 2 2 1 [2] 4 [8] 4/2/2 [8/4/4] Table 4: Description of the different types of architectures evaluated. 3.3 Simulation Approach Our simulation environment is built upon the MINT <ref> [12] </ref> execution-driven simulation environment. We use binaries generated on the SGI PowerChallenge for 3 integer benchmarks (compress, ijpeg and eqntott ) and 4 floating point benchmarks (swim, tomcatv , hydro2d and su2cor ). All are from the SPEC95 suite except eqntott , which is from SPEC92.
References-found: 12

