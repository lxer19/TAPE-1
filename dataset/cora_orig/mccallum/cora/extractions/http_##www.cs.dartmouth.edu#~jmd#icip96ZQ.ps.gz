URL: http://www.cs.dartmouth.edu/~jmd/icip96ZQ.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~jmd/
Root-URL: http://www.cs.dartmouth.edu
Email: fzhangq, jmdg@cs.dartmouth.edu  
Title: ENTROPY-BASED PATTERN MATCHING FOR DOCUMENT IMAGE COMPRESSION  
Author: Qin Zhang and John M. Danskin 
Address: Hanover, NH 03755, USA  
Affiliation: 6211 Sudikoff Laboratory Department of Computer Science Dartmouth College  
Abstract: In this paper, we introduce a pattern matching algorithm used in document image compression. This pattern matching algorithm uses the cross entropy between two patterns as the criterion for a match. We use a physical model which is based on the finite resolution of the scanner (spatial sampling error) to estimate the probability values used in cross entropy calculation. Experimental results show this pattern matching algorithm compares favorably to previous algorithms. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Ascher, R.N. and Nagy, </author> <title> "A means for achieving a high degree of compaction on scan-digitized printed text," </title> <journal> IEEE Transactions on Computers, </journal> <volume> c-23(11):1174-1179, </volume> <year> 1974. </year>
Reference-contexts: Traditional methods of facsimile data compression based on run-length coding fail to provide good performance. On the other hand, document image compression based on pattern matching is a method particularly effective for text pages. It was originally proposed in <ref> [1] </ref> and further studied in [4],[3],and [6]. Document image compression based on pattern matching works in this way: patterns, connected blobs of ink, which are expected to be characters, are extracted from the image to be compressed. These patterns are compared to previously transmitted patterns.
Reference: [2] <author> Inglis,S. and I.H.Witten, </author> <title> "Compression-based template matching," </title> <booktitle> Proc. IEEE Data Compression Conference, </booktitle> <address> pp.106-115, </address> <publisher> IEEE Computer Society Press, Los Alamitos, </publisher> <address> CA, </address> <year> 1994. </year>
Reference-contexts: The success of the compression depends on the accuracy of pattern matching. A number of pattern matching algorithms were proposed in [4], [5], and <ref> [2] </ref>. The existing algorithms fall into two main types, depend ing on whether global or local criteria are employed in obtaining the matching decision. * One algorithm based on global criteria is Combined Symbol Matching (CSM). <p> These rules are heuristic and do not have a firm theoretical basis. Most of the rules are not scalable. * Inglis and Witten proposed a compression-based pattern matching scheme (CTM) in <ref> [2] </ref>. CTM produces better results than previous pattern matching methods. However, the context-based compression model used by CTM is not a close approximation of the true cross-entropy between pairs of patterns.
Reference: [3] <author> Mohiuddin, K.M, </author> <title> "Lossless binary image compression based on pattern matching," </title> <booktitle> Proc. International Conference on Computers, System and Signal Processing, </booktitle> <address> pp.447-451, </address> <year> 1984. </year>
Reference-contexts: The tendency for scanning noise to be concentrated at the edges of symbols was previously reported in <ref> [3] </ref>. Assuming that the scanner's spatial sampling rate is the only source of error, we can estimate an edge pixel's corresponding probability value in the probability map. Figures 1 and 2 illustrate the one dimensional case.
Reference: [4] <author> Holt, M.J.J. and C.S.Xydeas, </author> <title> "Recent developments in image data compression for digital facsimile," </title> <type> ICL Technical Jounal, </type> <pages> pp. 123-146, </pages> <year> 1986. </year>
Reference-contexts: The success of the compression depends on the accuracy of pattern matching. A number of pattern matching algorithms were proposed in <ref> [4] </ref>, [5], and [2]. The existing algorithms fall into two main types, depend ing on whether global or local criteria are employed in obtaining the matching decision. * One algorithm based on global criteria is Combined Symbol Matching (CSM).
Reference: [5] <author> Holt, M.J., </author> <title> "A fast binary template matching algorithm for document image data compression," </title> <booktitle> Proc. 4th International Conference on Pattern Recognition, </booktitle> <address> Cambridge, England, </address> <pages> pp. 230-239. </pages> <address> Berlin, </address> <publisher> Springer-Verlag, </publisher> <year> 1988. </year>
Reference-contexts: The success of the compression depends on the accuracy of pattern matching. A number of pattern matching algorithms were proposed in [4], <ref> [5] </ref>, and [2]. The existing algorithms fall into two main types, depend ing on whether global or local criteria are employed in obtaining the matching decision. * One algorithm based on global criteria is Combined Symbol Matching (CSM). <p> These algorithms tend to have high rejection rate if the threshold function is set to eliminate matching errors. * In other algorithms, such as the Pattern Matching and Substitution (PMS) and Combined Size Independent Strategy (CSIS), the matching decision is based on local criteria <ref> [5] </ref>. For example, CSIS looks for four error pixels clustered in a square, and rejects a match if such pattern is found. These rules are heuristic and do not have a firm theoretical basis.
Reference: [6] <author> Witten, I.H., Bell, T.C., Emberson,H., and S. Inglis, </author> <title> "Textual image compression: two-stage lossy/lossless encoding of textual images," </title> <booktitle> Proceedings of the IEEE, v. </booktitle> <volume> 86, No. 6, </volume> <pages> pp. 878-888, </pages> <year> 1994. </year>
Reference-contexts: Traditional methods of facsimile data compression based on run-length coding fail to provide good performance. On the other hand, document image compression based on pattern matching is a method particularly effective for text pages. It was originally proposed in [1] and further studied in [4],[3],and <ref> [6] </ref>. Document image compression based on pattern matching works in this way: patterns, connected blobs of ink, which are expected to be characters, are extracted from the image to be compressed. These patterns are compared to previously transmitted patterns.
Reference: [7] <author> Witten, I.H., Moffat, Alistair, and I. C. Bell, </author> <title> "Managing Gigabytes: compressing and indexing documents and images," </title> <publisher> Van Nostrand Reinhold, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: We have implemented EPM and tested it on a set of document images. We used some components of MG to build our system <ref> [7] </ref>. Our document image set contains three high quality scanned-in document pages with a total of 8935 patterns. Two of the pages are from the CCITT test image set. The other page is scanned at 300dpi, contains 25 lines of identical text, each line of text has 63 symbols.
References-found: 7

