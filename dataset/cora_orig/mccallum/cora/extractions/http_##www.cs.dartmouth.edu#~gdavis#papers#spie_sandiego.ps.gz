URL: http://www.cs.dartmouth.edu/~gdavis/papers/spie_sandiego.ps.gz
Refering-URL: http://www.cs.dartmouth.edu/~gdavis/
Root-URL: http://www.cs.dartmouth.edu
Email: Email: geoff.davis@dartmouth.edu  
Title: Adaptive self-quantization of wavelet subtrees: A wavelet-based theory of fractal image compression  
Author: Geoffrey Davis 
Keyword: image compression, fractal compression, wavelets, vector quantization, collage theorem  
Address: Hall  College, Hanover, NH 03755  
Affiliation: Department of Mathematics, Bradley  Dartmouth  
Abstract: Fractal image compression was one of the earliest compression schemes to take advantage of image redundancy in scale. The theory of iterated function systems motivates a broad class of fractal schemes but does not give much guidance for implementation. Fractal compression schemes do not fit into the standard transform coder paradigm and have proven difficult to analyze. We introduce a wavelet-based framework for analyzing fractal block coders which simplifies these schemes considerably. Using this framework we find that fractal block coders are Haar wavelet subtree quantization schemes, and we thereby place fractal schemes in the context of conventional transform coders. We show that the central mechanism of fractal schemes is an extrapolation of fine-scale Haar wavelet coefficients from coarse-scale coefficients. We use this insight to derive a wavelet-based analog of fractal compression, the self-quantization of subtrees (SQS) scheme. We obtain a simple SQS decoder convergence proof and a fast SQS decoding algorithm which simplify and generalize existing fractal compression results. We describe an adaptive SQS compression scheme which outperforms the best fractal schemes in the literature by roughly 1 dB in PSNR across a broad range of compression ratios and which has performance comparable to some of the best conventional wavelet subtree quantization schemes. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Antonini, M. Barlaud, P. Mathieu, and I. Daubechies, </author> <title> "Image coding using wavelet transform," </title> <journal> IEEE Trans. Image Processing, </journal> <volume> Vol. 1, No. 2, </volume> <pages> 205-221. </pages>
Reference-contexts: Such artifacts yield poor subjective image quality since the human visual system is especially sensitive to horizontal and vertical lines. We replace the Haar basis with a biorthogonal spline basis designed for image compression (the spline variant with less dissimilar lengths) from <ref> [1] </ref> and use the same disjoint domain pool as with the Haar SQS scheme. There is a substantial improvement in perceived image quality over the Haar SQS scheme. In particular, blocking artifacts, a hallmark of fractal block coding schemes, have been completely eliminated.
Reference: [2] <author> M.F. Barnsley and A. Jacquin, </author> <title> "Application of recurrent iterated function systems to images." </title> <booktitle> Proc. SPIE, </booktitle> <volume> vol. 1001, </volume> <pages> pp. 122-131, </pages> <year> 1988. </year>
Reference-contexts: In section 5 we describe an adaptive self-quantized subtree compression scheme which is a generalization of a wavelet compression scheme of [17], and in section 6 we present the results of this compression scheme. 2 FRACTAL IMAGE COMPRESSION Fractal image compression techniques, introduced by Barnsley and Jacquin <ref> [2] </ref>, have proved very successful for compressing images at low bitrates. An overview of these techniques can be found in [8]. The motivation for fractal image compression is that many basic features in images are invariant under rescaling. <p> Features of a particular scale constitute a detail space of a multiresolution analysis [14]. Fractal decoding can be seen as a cascading of information from coarse wavelet coefficients to fine. Fractal compression has been motivated by the theory of iterated function systems <ref> [2] </ref>, which involves the construction of a strictly contractive map from the image to itself. However, the scale-extending maps described above are not in general contractive in any of the l p norms. It is the flow from coarse to fine and not the contractivity of the map which matters.
Reference: [3] <author> Z. Baharav, D. Malah, and E. Karnin, </author> <title> "Hierarchical interpretation of fractal image coding and its application to fast decoding," </title> <booktitle> in Proc. Digital Signal Processing Conference, </booktitle> <address> Cyprus, </address> <month> July </month> <year> 1993. </year>
Reference-contexts: In the case of the the Haar basis this set corresponds to the set of domain blocks which share boundaries with range blocks. This particular restricted domain pool has been studied for fractal block coders in [13] and <ref> [3] </ref>. The theorem below generalizes their results, extends them into the general wavelet framework, and gives new insight into why their results hold. Theorem 4.1 (Reconstruction Theorem).
Reference: [4] <author> T. Bell, J. G. Cleary, and I. H. Witten, </author> <title> Text Compression, </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1990. </year>
Reference: [5] <author> G. Davis, </author> <title> "Self-Quantization of Wavelet Subtrees," </title> <booktitle> in Proc. SPIE Wavelet Applications II, </booktitle> <address> Orlando, </address> <month> April </month> <year> 1995, </year> <journal> Vol. </journal> <volume> 2491, </volume> <pages> pp. 141-152. </pages>
Reference-contexts: We note that while it is possible to bound the l 2 quantization error in the decoded image in terms of this l 2 error, minimizing this l 2 error is not an optimal selection criterion. An improved criterion is described in an earlier work <ref> [5] </ref>. <p> Each time we apply the map M we obtain the wavelet coefficients at the next finer scale, so by induction the result is proved. A more detailed version of this proof may be found in <ref> [5] </ref>. 2 When we use the disjoint domain pool described above, the matrix G from (6) has a very simple form. The rows of G corresponding to the scaling functions are all zero since we have transferred all the scaling function information to the coefficients in H. <p> Our convergence proof shows that images are reconstructed from the stored self-similarity relation by cascading information from coarse to fine scales. This suggests that the decoding process will be more sensitive to errors in coarser scales than fine. In <ref> [5] </ref> we examine a weighted l 2 error metric which we use to select which domain subtree to use for quantization. Our convergence proof also gives insight into the mechanism underlying fractal interpolation or super-resolution of images. Each iteration of our decoding process generates a new level of wavelet coefficients.
Reference: [6] <author> Y. Fisher, B. Jacobs, and R. Boss, </author> <title> "Fractal Image Compression Using Iterated Transforms," in Image and Text Compression, </title> <editor> J. Storer (ed), </editor> <publisher> Kluwer Academic, </publisher> <pages> 35-61, </pages> <year> 1992. </year>
Reference-contexts: Encoding in these wavelet schemes, as well as in JPEG, follows a standard, well-understood paradigm. First an invertible transform is performed on an image; then the transform coefficients are quantized, entropy-coded, and stored. Fractal image compression <ref> [9, 6] </ref> also takes advantage of redundancy in scale, but its operating principles are very different from those of transform coders. Fractal compression is related to vector quantization, but it uses a self-referential vector codebook, drawn from the image itself, rather than a fixed codebook. <p> Compressed images are stored by storing this map and recovered by iteratively applying the map to find its fixed point. We now describe a simple fractal image compression scheme based on those in [9] and <ref> [6] </ref>. Let I be a 2 N fi 2 N pixel image, and let B J K;L I be the 2 J fi 2 J subblock of I with lower left hand corner at (2 J K; 2 J L). <p> It can be shown that this process converges pointwise when the scaling factors jg j &lt; 1 [8]. Numerical experiments show that this upper bound is not a necessary condition for convergence, and that the use of larger bounds on the scaling factors can yield improved compression results <ref> [6] </ref>. 3 FRACTAL COMPRESSION IN THE WAVELET DOMAIN 3.1 The Discrete Wavelet Transform Wavelets are a natural tool for analyzing fractal compression since wavelet bases possess the same type of dyadic similarity which fractal compression exploits.
Reference: [7] <author> Y. Fisher and S. Menlove, </author> <title> "Fractal Encoding with HV Partitions", in Y. Fisher, Fractal Compression: Theory and Application to Digital Images, </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: The performance of fractal block coders is substantially improved by enlarging the domain pool. The third line from the bottom of Figure 6, 'Fractal HV Tree', shows the PSNR for a fractal block encoding of rectangular range blocks using rectangular domain blocks <ref> [7] </ref>. The use of rectangular blocks introduces an additional degree of freedom in the construction of the domain pool and gives increased flexibility to the partitioning of the image. The reconstructed images in [7] show the coding to be of high quality. <p> Tree', shows the PSNR for a fractal block encoding of rectangular range blocks using rectangular domain blocks <ref> [7] </ref>. The use of rectangular blocks introduces an additional degree of freedom in the construction of the domain pool and gives increased flexibility to the partitioning of the image. The reconstructed images in [7] show the coding to be of high quality. In fact, the authors claim that their algorithm gives the best results of any fractal block coder in the literature. The enlarged domain pool results in high computational complexity for coding, however.
Reference: [8] <author> Y. Fisher, </author> <title> Fractal Compression: Theory and Application to Digital Images, </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1994. </year>
Reference-contexts: An overview of these techniques can be found in <ref> [8] </ref>. The motivation for fractal image compression is that many basic features in images are invariant under rescaling. Constant regions in images are invariant under local averaging and subsampling, as are straight edges. Fractal compression takes advantage of this redundancy by using coarse-scale image features to quantize fine-scale features. <p> We recover the image iteratively from this stored information. We start with an arbitrary image I 0 , and we compute I n = GI n1 +H. It can be shown that this process converges pointwise when the scaling factors jg j &lt; 1 <ref> [8] </ref>. <p> This bound on the g 's is not a necessary condition for convergence. Indeed, the sum in the denominator in general considerably larger than 2 DR , so for the Haar basis this is a weaker result than can be obtained for subblock methods via pointwise methods <ref> [8] </ref>. The bound does show that we can decode our wavelet encoding via an iterative algorithm for some range of scale factors. <p> The lowest line in Figure 6, 'Fractal Quadtree', is from the quadtree block coder listed in <ref> [8] </ref> using a disjoint domain pool as described in section 4.1 constructed from domain blocks of size 8 fi 8 up to 128 fi 128. (We note that quadtree schemes perform much better for larger domain pools; the point is to illustrate that our SQS scheme makes more effective use of
Reference: [9] <author> A. Jacquin, </author> <title> "Fractal image coding based on a theory of iterated contractive image transformations," </title> <booktitle> Proc. SPIE Visual Comm. and Image Proc., </booktitle> <pages> pp. 227-239, </pages> <year> 1990. </year>
Reference-contexts: Encoding in these wavelet schemes, as well as in JPEG, follows a standard, well-understood paradigm. First an invertible transform is performed on an image; then the transform coefficients are quantized, entropy-coded, and stored. Fractal image compression <ref> [9, 6] </ref> also takes advantage of redundancy in scale, but its operating principles are very different from those of transform coders. Fractal compression is related to vector quantization, but it uses a self-referential vector codebook, drawn from the image itself, rather than a fixed codebook. <p> Compressed images are stored by storing this map and recovered by iteratively applying the map to find its fixed point. We now describe a simple fractal image compression scheme based on those in <ref> [9] </ref> and [6]. Let I be a 2 N fi 2 N pixel image, and let B J K;L I be the 2 J fi 2 J subblock of I with lower left hand corner at (2 J K; 2 J L). <p> The goal of the compression scheme is to approximate each range block with a block from a codebook constructed from domain blocks B D 2 D K;2 D L I; with (K; L) 2 D where D &gt; R and D is a set called the domain pool. In <ref> [9] </ref> the codebook is constructed from all unit translates of the domain blocks, so the domain pool D = f (K; L) : 2 D K; 2 D L 2 Z and 0 K; L &lt; 2 ND g is an collection of overlapping subblocks.
Reference: [10] <author> B. Jawerth and W. Sweldens, </author> <title> "An overview of wavelet based multiresolution analyses," </title> <journal> SIAM Review, </journal> <volume> 36:3, </volume> <pages> 377-412, </pages> <year> 1994. </year>
Reference-contexts: We first establish some notation. For simplicity we will consider orthogonal wavelets only; it is straightforward to generalize the results to the biorthogonal case. Let (x) and (x) be an orthogonal wavelet and its associated scaling function (see <ref> [10] </ref> and [14] for an overview of wavelets). The scaling function together with a set of dyadic rescalings and integral translations of (x) form a basis of L 2 (R).
Reference: [11] <author> A. S. Lewis and G. Knowles, </author> <title> "Image compression using the 2-D wavelet transform," </title> <journal> IEEE Transactions on Image Processing, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 244-250, </pages> <month> April </month> <year> 1992. </year>
Reference: [12] <author> L. M. Lundheim, </author> <title> Fractal Signal Modelling for Source Coding. </title> <type> Ph.D. thesis, </type> <institution> The Norwegian Institute of Technology, </institution> <month> November </month> <year> 1992. </year>
Reference: [13] <author> G. </author> <title> ien L 2 -Optimal Attractor Image Coding with Fast Decoder Convergence. </title> <type> Ph.D. thesis, </type> <institution> The Norwegian Institute of Technology, </institution> <month> November </month> <year> 1992. </year>
Reference-contexts: In the case of the the Haar basis this set corresponds to the set of domain blocks which share boundaries with range blocks. This particular restricted domain pool has been studied for fractal block coders in <ref> [13] </ref> and [3]. The theorem below generalizes their results, extends them into the general wavelet framework, and gives new insight into why their results hold. Theorem 4.1 (Reconstruction Theorem).
Reference: [14] <author> S. Mallat, </author> <title> "A theory for multiresolution signal decomposition: the wavelet representation," </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> Vol. 11, No. 7, </volume> <pages> 674-693, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: We generalize this modified coder to the self-quantization of subtrees scheme. Our analysis of the decoder shows that the central component of fractal coding schemes is an extrapolation of fine-scale information from coarse-scale. Here scale is in the sense of the detail spaces of a multiresolution analyses <ref> [14] </ref>. Fractal decoding is thus a cascading of information from coarse scales to fine. We see that the convergence problems which affect conventional fractal compression schemes are due to dependencies of fine-scale coefficients on finer-scale ones. <p> We first establish some notation. For simplicity we will consider orthogonal wavelets only; it is straightforward to generalize the results to the biorthogonal case. Let (x) and (x) be an orthogonal wavelet and its associated scaling function (see [10] and <ref> [14] </ref> for an overview of wavelets). The scaling function together with a set of dyadic rescalings and integral translations of (x) form a basis of L 2 (R). <p> The above theorem shows we can make this notion of scale rigorous with a particular class of domain pools. Features of a particular scale constitute a detail space of a multiresolution analysis <ref> [14] </ref>. Fractal decoding can be seen as a cascading of information from coarse wavelet coefficients to fine. Fractal compression has been motivated by the theory of iterated function systems [2], which involves the construction of a strictly contractive map from the image to itself.
Reference: [15] <author> J. Shapiro, </author> <title> "Embedded Image Coding Using Zerotrees of Wavelet Coefficients," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> Vol. 41, No. 12, </volume> <pages> pp. 3445-3462. </pages>
Reference-contexts: 1 INTRODUCTION Lossy image compression schemes such as JPEG achieve most of their data reduction by eliminating spatial redundancy within images. Recent wavelet-based techniques which have achieved particularly high quality rate-distortion results have done so by taking advantage of additional redundancy in scale <ref> [15, 17] </ref>. Encoding in these wavelet schemes, as well as in JPEG, follows a standard, well-understood paradigm. First an invertible transform is performed on an image; then the transform coefficients are quantized, entropy-coded, and stored. <p> In our experiments SQS-compressed images have PSNR's of roughly 1 dB higher than the best existing fractal compression schemes over a broad range of compression ratios. The overall performance of our SQS coder is comparable to that of Shapiro's embedded zerotree wavelet coder <ref> [15] </ref>. SQS decoding is fast, requiring O (N ) operations for an N -pixel images, unlike the asymptotically converging standard fractal decoders. The balance of the paper is organized as follows. In the next section we give an overview of fractal block coding schemes. <p> Similar predictions are possible for this hybrid wavelet/SQS coder but have not been used here. We see that the performance of this hybrid coder is comparable to that of Shapiro's embedded wavelet zerotree encoder <ref> [15] </ref>. 7 ACKNOWLEDGMENTS This work was supported in part by DARPA as administered by the AFOSR under contract DOD F4960-93-1-0567.
Reference: [16] <author> Y. Shoham and A. Gersho, </author> <title> "Efficient Bit Allocation for an Arbitrary Set of Quantizers," </title> <journal> IEEE Trans. Acoustics, Speech, and Signal Processing, </journal> <volume> Vol. 36, </volume> <pages> pp. 1445-1453, </pages> <month> September </month> <year> 1988. </year>
Reference-contexts: We initiate the algorithm with a fixed and an S such that the entire tree is scalar-quantized. The algorithm proceeds iteratively in two stages. First, given S and , we find an optimal allocation of quantizer resolutions q using a Lagrangian algorithm <ref> [16] </ref> (we assume uniformly spaced quantization). We next perform an optimization step on our decision tree.
Reference: [17] <author> Z. Xiong, K. Ramchandran, and M. Orchard. </author> <title> "Joint Optimization of Scalar and Tree-structured Quantization of Wavelet Image Decompositions," </title> <booktitle> Proceedings of the 27th Annual Asilomar Conference on Signals, Systems, and Computers, </booktitle> <address> Pacific Grove, CA, </address> <month> November </month> <year> 1993. </year>
Reference-contexts: 1 INTRODUCTION Lossy image compression schemes such as JPEG achieve most of their data reduction by eliminating spatial redundancy within images. Recent wavelet-based techniques which have achieved particularly high quality rate-distortion results have done so by taking advantage of additional redundancy in scale <ref> [15, 17] </ref>. Encoding in these wavelet schemes, as well as in JPEG, follows a standard, well-understood paradigm. First an invertible transform is performed on an image; then the transform coefficients are quantized, entropy-coded, and stored. <p> We see that the convergence problems which affect conventional fractal compression schemes are due to dependencies of fine-scale coefficients on finer-scale ones. In section 5 we describe an adaptive self-quantized subtree compression scheme which is a generalization of a wavelet compression scheme of <ref> [17] </ref>, and in section 6 we present the results of this compression scheme. 2 FRACTAL IMAGE COMPRESSION Fractal image compression techniques, introduced by Barnsley and Jacquin [2], have proved very successful for compressing images at low bitrates. An overview of these techniques can be found in [8]. <p> of fractal compression possesses a structure very similar to a number of recently introduced hierarchical wavelet coders [15]<ref> [17] </ref>[11]. The basic problem is to quantize a tree of wavelet coefficients using some combination of subtree quantization and scalar quantization. In addition the resolution of the scalar quantizers must be adaptively allocated. [17] describes an algorithm which optimally allocates bits between a set of scalar quantizers and subtree quantizers, and we use a slightly modified version of this algorithm for our experiments. We sketch the algorithm and our modifications here and refer the reader to [17] for details. <p> the scalar quantizers must be adaptively allocated. <ref> [17] </ref> describes an algorithm which optimally allocates bits between a set of scalar quantizers and subtree quantizers, and we use a slightly modified version of this algorithm for our experiments. We sketch the algorithm and our modifications here and refer the reader to [17] for details. The set of wavelet coefficients to be quantized forms a tree T ; each leaf of the tree contains the triple of wavelet coefficients &lt; I; j !;k;l &gt; for ! 2 . Each node and its descendents constitute a wavelet subtree. <p> This increased flexibility yields improved coding for subtrees which are not well-represented by self-quantization. The improvement in performance is offset slightly by the increased cost of storing the decision tree for the compressed image. We note that <ref> [17] </ref> obtains some savings in the cost of storing the decision tree by predicting decisions conditioned on the values of the parent wavelet coefficients. Similar predictions are possible for this hybrid wavelet/SQS coder but have not been used here.
References-found: 17

