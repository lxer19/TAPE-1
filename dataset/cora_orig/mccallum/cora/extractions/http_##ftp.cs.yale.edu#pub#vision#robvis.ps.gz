URL: http://ftp.cs.yale.edu/pub/vision/robvis.ps.gz
Refering-URL: http://ftp.cs.yale.edu/pub/vision/
Root-URL: http://www.cs.yale.edu
Email: kentoy@microsoft.com fhager,doddsg@cs.yale.edu  
Title: State-Based Vision for Prohibition of Robot Action  
Author: Kentaro Toyama Gregory D. Hager Zachary Dodds 
Address: Redmond, WA 98052 New Haven, CT 06520  
Affiliation: Vision Technology Group Department of Computer Science Microsoft Research Yale University  
Abstract: Robust sensing is a crucial ingredient for robust robotics. This paper considers an architecture called Incremental Focus of Attention (IFA) for real-time robot vision that robustly recovers from failures to track a target object. IFA is a state-based architecture for combining different tracking algorithms into a single system that is cognizant of its own degree of success. The states of an IFA system are used to issue action prohibitions, in which certain robot actions are suppressed when sensory information required to perform the actions is unavailable. Action prohibition is an intuitive way to integrate robust, failure-cognizant vision systems with almost any type of robot planning scheme. We present three examples of robot tasks with IFA and action prohibition, where the robots implement a range of planning paradigms, from reactive agents to more centrally controlled planners. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Birchfield and C. Tomasi. </author> <title> Elliptical head tracking using intensity gradients and color histograms. </title> <booktitle> In Proc. Computer Vision and Patt. </booktitle> <address> Recog., </address> <year> 1998. </year>
Reference-contexts: Although there are several face tracking systems described in the literature <ref> [1, 4, 8] </ref>, few are able to consistently maintain track of a single, specified individual given occlusions, distraction by other people in view, illumination changes, and so forth. The underlying IFA system consists of seven different algorithms which can be broadly classified into three types.
Reference: [2] <author> R. A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Trans. Robot. and Autom., </journal> <volume> 1(1) </volume> <pages> 24-30, </pages> <month> March </month> <year> 1986. </year>
Reference-contexts: Perhaps the most similar in conception is the sub-sumption architecture, in which hardware modules organized in layers inhibit execution of modules below them <ref> [2] </ref>. In fact, IFA was inspired by the robustness of subsumption robots [9], and it shares similar structure. There is a major difference, however: subsump-tion emphasizes complete perception-action modules whereas the action prohibition concept is free of bias toward any single robot planning paradigm.
Reference: [3] <author> R. Burridge, A. Rizzi, and D. Koditschek. </author> <title> Sequential composition of dynamically dexterous robot behaviors. </title> <journal> Int'l J. Robot. Res., </journal> <note> 1998. To appear. </note>
Reference-contexts: In addition, we view adaptive control as a reactive, low-level form of robot control. Action prohibition can apply to higher level planners equally well. One interesting example of adaptive control is sequential composition, in which different control algorithms are applied based on the phase of an observed object <ref> [3] </ref>. This work is complementary to ours. Where we focus on the robustness of vision, sequential composition assumes that input from vision is assured and focuses instead on robust control architectures.
Reference: [4] <author> M. Collobert, R. Feraud, G. Le Tourneur, O. Bernier, J. E. Viallet, Y Mahieux, and D. Col-lobert. </author> <title> LISTEN: A system for locating and tracking individual speakers. </title> <booktitle> In Proc. Int'l Conf. on Autom. Face and Gesture Recog., </booktitle> <pages> pages 283-288, </pages> <year> 1996. </year>
Reference-contexts: Although there are several face tracking systems described in the literature <ref> [1, 4, 8] </ref>, few are able to consistently maintain track of a single, specified individual given occlusions, distraction by other people in view, illumination changes, and so forth. The underlying IFA system consists of seven different algorithms which can be broadly classified into three types.
Reference: [5] <author> W. Feiten, G. D. Hager, J. Bauer, B. Magnussen, and K. Toyama. </author> <title> Modeling and control for mobile manipulation in everyday environments. </title> <booktitle> In Proceedings of the 8th International Symposium on Robotics Research, </booktitle> <year> 1997. </year>
Reference-contexts: In order to successfully accomplish this task when doors are closed, doorknobs in the environment must be identified and tracked prior to grasping of the doorknob. We have implemented the vision module for this subtask, for a mobile robot platform used in the Siemens robotics lab <ref> [5] </ref>. The IFA system consists of several search layers and one additional layer at the top which tracks doorknobs as an edge-based polygon. The vision system was implemented on a Sun Sparc 20 equipped with a K2T-V300 digitizer and Sony single-CCD color camera. <p> The vision system was implemented on a Sun Sparc 20 equipped with a K2T-V300 digitizer and Sony single-CCD color camera. Figure 4 shows doorknob search at different layers. For more information on the details of the layers, see <ref> [5] </ref>. The relevant robot actions are simply (A) standstill, and (B) servoing toward the doorknob. The obvious action prohibition is to suppress (B) when the IFA system is not in the sole track state. Again, the behavior of the robot during the doorknob homing subtask is as expected.
Reference: [6] <author> G. Hager and P.N. Belhumeur. </author> <title> Occlusion insensitive tracking of image regions with changes in geometry and illumination. </title> <type> Technical Report DCS-TR-1122, </type> <institution> Yale University, </institution> <year> 1996. </year>
Reference-contexts: Listing these in ascending layer order, we have (1) search algorithms which find those regions of the image exhibiting motion and skin color, (2) fast tracking algorithms for tracking face position based on color, and (3) slow tracking algorithms for tracking face position precisely based on templates (based on <ref> [6] </ref>. During tracking, (2) takes over when (3) is too slow to track (layers in (3) are still necessary to insure that the proper target is being tracked). <p> In order to perform these functions, the IFA system uses three layers: (1) color- and motion-based centroid tracking, (2) approximately vertical edge tracking [7], and (3) correlation-based region tracking <ref> [6] </ref>. The nature of the task precludes any absolute ordering of actions by preference. Instead, robot actions are determined by how much of the task has already been accomplished information which is updated by a central planning module.
Reference: [7] <author> G. Hager and K. Toyama. XVision: </author> <title> A portable substrate for real-time vision applications. </title> <booktitle> In Proc. ECCV, </booktitle> <volume> volume 2, </volume> <pages> pages 507-512, </pages> <address> Cam-bridge, UK, </address> <year> 1996. </year>
Reference-contexts: In order to perform these functions, the IFA system uses three layers: (1) color- and motion-based centroid tracking, (2) approximately vertical edge tracking <ref> [7] </ref>, and (3) correlation-based region tracking [6]. The nature of the task precludes any absolute ordering of actions by preference. Instead, robot actions are determined by how much of the task has already been accomplished information which is updated by a central planning module.
Reference: [8] <author> N. Oliver, A. Pentland, and F. Berard. LAFTER: </author> <title> Lips and face real-time tracker. </title> <booktitle> In Proc. Computer Vision and Patt. Recog., </booktitle> <pages> pages 123-130, </pages> <year> 1997. </year>
Reference-contexts: Although there are several face tracking systems described in the literature <ref> [1, 4, 8] </ref>, few are able to consistently maintain track of a single, specified individual given occlusions, distraction by other people in view, illumination changes, and so forth. The underlying IFA system consists of seven different algorithms which can be broadly classified into three types.
Reference: [9] <author> K. Toyama and G. Hager. </author> <title> Incremental Focus of Attention for robust visual tracking. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 189-195, </pages> <year> 1996. </year>
Reference-contexts: Perhaps the most similar in conception is the sub-sumption architecture, in which hardware modules organized in layers inhibit execution of modules below them [2]. In fact, IFA was inspired by the robustness of subsumption robots <ref> [9] </ref>, and it shares similar structure. There is a major difference, however: subsump-tion emphasizes complete perception-action modules whereas the action prohibition concept is free of bias toward any single robot planning paradigm. Consequently, action prohibition can be laid on top of an existing system, whether reactive or centrally controlled.
Reference: [10] <author> K. Toyama and G. Hager. </author> <title> If at first you don't succeed... </title> <booktitle> In Proc. AAAI, </booktitle> <pages> pages 3-9, </pages> <address> Providence, RI, </address> <year> 1997. </year>
Reference-contexts: The framework makes vision post-failure ro bust, or efficient at recovering from non-catastrophic failures <ref> [10] </ref>. Of course, for the robotics and automation community, robust vision is simply one of many requirements for reliable robotics. One lesson that transfers from efforts in real-time vision is that post-failure robustness is as crucial for real-world operation as the ability to avoid failure in the first place.
Reference: [11] <author> K. Watanabe. </author> <title> Adaptive Estimation and Control. </title> <publisher> Prentice Hall, </publisher> <year> 1992. </year>
Reference-contexts: Consequently, action prohibition can be laid on top of an existing system, whether reactive or centrally controlled. Adaptive control considers dynamic adjustment of different control algorithms based on observed state <ref> [11] </ref>. These adjustments are not strictly prohibitions on actions, however, as they are modifications of operating parameters. In addition, we view adaptive control as a reactive, low-level form of robot control. Action prohibition can apply to higher level planners equally well.
References-found: 11

