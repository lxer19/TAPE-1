URL: http://www.cs.tamu.edu/research/robotics/Skubic/Papers/icra97.ps.gz
Refering-URL: http://www.cs.tamu.edu/research/robotics/Skubic/Papers/marge_bib.html
Root-URL: http://www.cs.tamu.edu
Title: Learning Force Sensory Patterns and Skills from Human Demonstration  
Author: Marjorie Skubic and Richard A. Volz 
Address: College Station, TX 77843-3112  
Affiliation: Department of Computer Science Texas A&M University  
Abstract: The motivation behind this work is to transfer force-based assembly skills to robots by using human demonstration. For this purpose, we model the skills as a sequence of contact formations (which describe how a workpiece touches its environment) and desired transitions between contact formations. In this paper, we present a method of identifying single-ended contact formations from force sensor patterns. Instead of using geometric models of the workpieces, fuzzy logic is used to learn and model the patterns in the force signals. Membership functions are generated automatically from training data and then used by the fuzzy classifier. This classification scheme is used to learn desired sequences of contact formations which comprise a force-based skill. Experimental results are presented which use the technique to extract skill information from human demonstration data. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> H. Asada and H. Izumi. </author> <title> Automatic program generation from teaching data for the hybrid control of robots. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 5(2) </volume> <pages> 166-173, </pages> <month> April </month> <year> 1989. </year>
Reference-contexts: In this way, the learning process can be simplified and the learned program should be more robust to discrepancies in position and orientation. The utility of this approach has been demonstrated by Asada et al in <ref> [1] </ref>. However, the method used to identify the discrete contact states required a geometric model of the workpieces [6], a burden we would like to avoid in robot programming by demonstration. McCarragher et al have used the discrete event approach to assembly, incorporating system dynamics and qualitative reasoning [11].
Reference: [2] <author> N. Delson and H. West. </author> <title> Robot programming by human demonstration: Adaptation and inconsistency in constrained motion. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 30-36, </pages> <address> Minneapolis, MN, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: While not yet coupled with vision, force signals have been incorporated into programming by demonstration systems, in order to learn compliant task strategies for assembly operations. Early work is presented by Hirzinger and Landzettel in [7]. More recent work includes that of Delson and West <ref> [2] </ref>. In contrast, we are not attempting to learn an entire task fl This work has been supported by NSF under grants CDA-9115123, CDA-9422123, and EID-9017249 and by the State of Texas under TATP grants 999903-267 and 999903-095. trajectory. Rather we will focus on learning low-level force-based skills.
Reference: [3] <author> R.S. Desai and R.A. Volz. </author> <title> Identification and verification of termination conditions in fine motion in presence of sensor errors and geometric uncertainties. </title> <booktitle> In Proceedings of the 1989 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 800-807, </pages> <address> Scottsdale, AZ, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: An approach to assembly operations which we believe can be combined with robot programming by demonstration is to model the assembly task as a sequence of discrete states, representing the contact formations (i.e., contact state) <ref> [3] </ref> between workpieces. In this way, the learning process can be simplified and the learned program should be more robust to discrepancies in position and orientation. The utility of this approach has been demonstrated by Asada et al in [1]. <p> In Section 2, the sensory patterns of single-ended contact formations will be discussed. Section 3 will describe the algorithm for identifying SECF's. Section 4 will present experimental results and discussion. Conclusions will be given in Section 5. 2 Sensory Patterns of Single-Ended Contact Formations The contact formation <ref> [3] </ref> provides a qualitative description of how 2 or more objects make contact with each other (e.g., edge 1 of the grasped object touches side B of the environment). As such, the possible contact formations depend on the relative size and shapes of the objects, reflecting the geometric relationship.
Reference: [4] <author> N.I. Durlach and A.S. Mavor, </author> <title> editors. Virtual Reality: Scientific and Technological Challenges. </title> <publisher> National Academy Press, </publisher> <year> 1995. </year>
Reference-contexts: This has the effect of eliminating undesired human-generated actions. Human factors studies have shown that the bandwidth for human limb motion is at most 5 Hz for internally generated trajectories and around 10 Hz for reflex actions <ref> [4] </ref>. In these experiments, we have filtered out transitory states occurring faster than 15 Hz. Sequence 1 The second sequence consisted of 6 steps as follows: no contact, edge 9, side C, edge 9, no contact, and bottom. Force and moment profiles are shown in Figures 8 and 9.
Reference: [5] <author> K. Hara and R. Yokogawa. </author> <title> Recognition of state in peg-in-hole by fuzzy schema. </title> <journal> Journal of Advanced Automation Technology, </journal> <volume> 4(3) </volume> <pages> 134-139, </pages> <year> 1992. </year>
Reference-contexts: We will utilize previous work [12], which is based on a quasi-static contact condition. We extend the approach to now consider the dynamic system and illustrate how a sequence of SECF's can be extracted. Similar to the strategy used by Hara and Yoko--gawa <ref> [5] </ref>, our method uses fuzzy logic to model and recognize the sensory patterns and also resolve ambiguities. In addition to its pattern recognition strengths, fuzzy logic provides a linguistic interface to the human demonstrator, which allows us to assign a meaningful and recognizeable name to each membership class.
Reference: [6] <author> S. Hirai and H. Asada. </author> <title> A model-based approach to the recognition of assembly process states using the theory of polyhedral convex cones. </title> <booktitle> In Proceedings of the 1990 Japan USA Symposium on Flexible Automation, </booktitle> <pages> pages 809-816, </pages> <address> Kyoto, Japan, </address> <year> 1990. </year>
Reference-contexts: The utility of this approach has been demonstrated by Asada et al in [1]. However, the method used to identify the discrete contact states required a geometric model of the workpieces <ref> [6] </ref>, a burden we would like to avoid in robot programming by demonstration. McCarragher et al have used the discrete event approach to assembly, incorporating system dynamics and qualitative reasoning [11]. In [8], FFT's are used to identify contact states; however, this approach cannot easily be run in real-time. <p> The set of force and moment vectors that comprise all possible vectors for a given SECF form a cone, which reflects the motion constraints existing between the grasped object and its environment. A theoretical discussion is provided by Hirai and Asada in <ref> [6] </ref>. Figures 1 and 2 show example force and moment patterns for several measurements on 2 SECF's. This data was collected using the small, plastic block, shown in Figure 3, in contact with a flat surface.
Reference: [7] <author> G. Hirzinger and K. Landzettel. </author> <title> Sensory feedback structures for robots with supervised learning. </title> <booktitle> In Proceedings of the 1985 IEEE International Conference on Robotics and Automation, </booktitle> <pages> pages 627-635, </pages> <address> St. Louis, MO, </address> <month> March </month> <year> 1985. </year>
Reference-contexts: Capabilities of such vision systems could be expanded with the use of force-based skills. While not yet coupled with vision, force signals have been incorporated into programming by demonstration systems, in order to learn compliant task strategies for assembly operations. Early work is presented by Hirzinger and Landzettel in <ref> [7] </ref>. More recent work includes that of Delson and West [2]. In contrast, we are not attempting to learn an entire task fl This work has been supported by NSF under grants CDA-9115123, CDA-9422123, and EID-9017249 and by the State of Texas under TATP grants 999903-267 and 999903-095. trajectory.
Reference: [8] <author> G.E. Hovland and B.J. McCarragher. </author> <title> Frequency-domain force measurements for discrete event contact recognition. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 2, </volume> <pages> pages 1166-1171, </pages> <address> Min-neapolis, MN, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: However, the method used to identify the discrete contact states required a geometric model of the workpieces [6], a burden we would like to avoid in robot programming by demonstration. McCarragher et al have used the discrete event approach to assembly, incorporating system dynamics and qualitative reasoning [11]. In <ref> [8] </ref>, FFT's are used to identify contact states; however, this approach cannot easily be run in real-time. In [9], Hidden Markov Models are used to model skills, which include the contact states and discretized velocity commands representing the transitions between contact states.
Reference: [9] <author> G.E. Hovland, P. Sikka, and B.J. McCarragher. </author> <title> Skill acquisition from human demonstration using a hidden markov model. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 3, </volume> <pages> pages 2706-2711, </pages> <address> Minneapolis, MN, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: McCarragher et al have used the discrete event approach to assembly, incorporating system dynamics and qualitative reasoning [11]. In [8], FFT's are used to identify contact states; however, this approach cannot easily be run in real-time. In <ref> [9] </ref>, Hidden Markov Models are used to model skills, which include the contact states and discretized velocity commands representing the transitions between contact states. This provides a 2-step approach to mapping forces to velocity commands.
Reference: [10] <author> S.B. Kang and K. </author> <title> Ikeuchi. Toward automatic robot instruction from perception- temporal segmentation of tasks from human hand motion. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 11(5) </volume> <pages> 670-681, </pages> <month> October </month> <year> 1995. </year>
Reference-contexts: Several such programming systems have been proposed and developed. Vision-based systems have been used to observe and extract an assembly plan from human demonstrators (e.g., <ref> [10] </ref>). While useful for observing high-level task information, vision has so far has not proven adequate for observing intricate assembly operations. Capabilities of such vision systems could be expanded with the use of force-based skills.
Reference: [11] <author> B. J. McCarragher. </author> <title> Force sensing from human demonstration using a hybrid dynamical model and qualitative reasoning. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 557-563, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: However, the method used to identify the discrete contact states required a geometric model of the workpieces [6], a burden we would like to avoid in robot programming by demonstration. McCarragher et al have used the discrete event approach to assembly, incorporating system dynamics and qualitative reasoning <ref> [11] </ref>. In [8], FFT's are used to identify contact states; however, this approach cannot easily be run in real-time. In [9], Hidden Markov Models are used to model skills, which include the contact states and discretized velocity commands representing the transitions between contact states. <p> For efficiency, the classifier should be run only when the contact condition changes. This is analogous to the force event defined by McCarragher <ref> [11] </ref>, which is a gain or loss of contact resulting in a new contact formation. The force event is observed as a significant change in force.
Reference: [12] <author> M. Skubic and R.A. Volz. </author> <title> Identifying contact formations from sensory patterns and its applicability to robot programming by demonstration. </title> <booktitle> In Proceedings of the 1996 IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 458-464, </pages> <address> Osaka, Japan, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: We introduce the concept of a single-ended contact formation (SECF) and present a fast sensor-based algorithm for identifying SECF's. We will utilize previous work <ref> [12] </ref>, which is based on a quasi-static contact condition. We extend the approach to now consider the dynamic system and illustrate how a sequence of SECF's can be extracted. <p> In this case, the Hamacher product is used in its reduced form <ref> [12] </ref>. The combination of the 7 feature membership functions is interpreted as the possibility (i.e., a fuzzy number in [0,1]) of this sensor data set being in the specified class. In the classification process, possibility values are calculated for each class; the highest possibility number represents the identified CF class.
References-found: 12

