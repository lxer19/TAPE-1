URL: http://www.icsi.berkeley.edu/~luby/PAPERS/anaerr.ps
Refering-URL: http://www.icsi.berkeley.edu/~luby/
Root-URL: http://www.icsi.berkeley.edu
Email: E-mail: luby@icsi.berkeley.edu.  E-mail: michaelm@pa.dec.com.  E-mail: amin@icsi.berkeley.edu.  E-mail: spielman@math.mit.edu.  
Title: Analysis of Low Density Codes and Improved Designs Using Irregular Graphs  
Author: Michael G. Luby Michael Mitzenmacher M. Amin Shokrollahi Daniel A. Spielman 
Web: NCR-9416101.  
Note: Parts of this research were done while still at the Digital Equipment Corporation Systems Research Center, Palo Alto, CA. Research partially supported by NSF operating grant  Research supported by a Habilitationsstipendium of the Deutsche Forschungs-gemeinschaft, Grant Sh 57/1-1.  
Address: Berkeley, CA.  Palo Alto, CA.  
Affiliation: International Computer Science Institute,  Digital Equipment Corporation, Systems Research Center,  International Computer Science Institute Berkeley, and Insti-tut fur Informatik der Universitat Bonn, Germany.  Department of Mathematics, M.I.T.  
Abstract: In [6], Gallager introduces a family of codes based on sparse bipartite graphs, which he calls low-density parity-check codes. He suggests a natural decoding algorithm for these codes, and proves a good bound on the fraction of errors that can be corrected. As the codes that Gal-lager builds are derived from regular graphs, we refer to them as regular codes. Following the general approach introduced in [7] for the design and analysis of erasure codes, we consider error-correcting codes based on random irregular bipartite graphs, which we call irregular codes. We introduce tools based on linear programming for designing linear time irregular codes with better error-correcting capabilities than possible with regular codes. For example, the decoding algorithm for the rate 1/2 regular codes of Gallager can provably correct up to 5.17% errors asymptotically, whereas we have found irregular codes for which our decoding algorithm can provably correct up to 6.27% errors asymptotically. We include the results of simulations demonstrating the effectiveness of our codes on systems of reasonable size. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Berrou, A Glavieux, and P. Thitimajshima, </author> <title> "Near Shannon Limit Error-Correcting Coding and Decoding: </title> <booktitle> Turbo-Codes", Proceedings of IEEE International Communications Conference, </booktitle> <year> 1993. </year>
Reference-contexts: Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes [2, 6, 11, 12, 17] and is strongly related to the highly successful turbo codes <ref> [1, 3, 10, 5] </ref>. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9]. We believe our analysis here provides an important step towards analyzing codes based on belief propagation techniques.
Reference: [2] <author> J.-F. Cheng and R. J. </author> <title> McEliece, "Some High-Rate Near Capacity Codecs for the Gaussian Channel", </title> <booktitle> 34th Allerton Conference on Communications, Control and Computing. </booktitle>
Reference-contexts: Additionally, the bound on the probability of error we derive using this methodology improves upon the bound derived by Gallager for the regular graphs he explicitly constructed. Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes <ref> [2, 6, 11, 12, 17] </ref> and is strongly related to the highly successful turbo codes [1, 3, 10, 5]. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9].
Reference: [3] <author> D. Divsalar and F. Pollara, </author> <title> "On the Design of Turbo Codes", </title> <type> JPL TDA Progress Report 42-123. </type>
Reference-contexts: Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes [2, 6, 11, 12, 17] and is strongly related to the highly successful turbo codes <ref> [1, 3, 10, 5] </ref>. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9]. We believe our analysis here provides an important step towards analyzing codes based on belief propagation techniques.
Reference: [4] <author> G. D. Forney, Jr. </author> <title> "The Forward-Backward Algorithm", </title> <booktitle> Proceedings of the 34th Allerton Conference on Communications, Control and Computing, </booktitle> <year> 1996, </year> <pages> pp. 432-446. </pages>
Reference-contexts: We note that Gallager also proposes a belief propagation type decoding algorithm, which uses a more complicated state; for more details, see for example <ref> [4, 9, 11, 17] </ref>. In the following we refer to the nodes on the left and right sides of a bipartite graph as its message nodes and check nodes respectively.
Reference: [5] <author> B. J. Frey and F. R. Kschischang, </author> <title> "Probability Propagation and Iterative Decoding", </title> <booktitle> Proceedings of the 34th Allerton Conference on Communications, Control and Computing, </booktitle> <year> 1996. </year>
Reference-contexts: Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes [2, 6, 11, 12, 17] and is strongly related to the highly successful turbo codes <ref> [1, 3, 10, 5] </ref>. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9]. We believe our analysis here provides an important step towards analyzing codes based on belief propagation techniques.
Reference: [6] <author> R. G. Gallager, </author> <title> Low-Density Parity-Check Codes, </title> <publisher> MIT Press, </publisher> <year> 1963. </year>
Reference-contexts: 1 Introduction In <ref> [6] </ref>, Gallager introduces a family of codes based on sparse bipartite graphs, which he calls low-density parity-check codes. As the codes that Gallager builds are derived from regular graphs, we refer to them as regular codes. <p> Additionally, the bound on the probability of error we derive using this methodology improves upon the bound derived by Gallager for the regular graphs he explicitly constructed. Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes <ref> [2, 6, 11, 12, 17] </ref> and is strongly related to the highly successful turbo codes [1, 3, 10, 5]. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9]. <p> In Section 4, we discuss some simulation results that show the effectiveness of our analysis for designing practical codes. We conclude with a discussion of open problems. 2 Regular Codes 2.1 Analyzing Regular Codes We first review the codes developed by Gallager and his analysis <ref> [6] </ref>. Later we explain how his analysis combined with the argument from [8] shows that his suggested decoding algorithm corrects all but an arbitrarily small constant fraction of the nodes with high probability for random regular codes. <p> To circumvent this problem Gallager designs regular graphs with no small cycles <ref> [6] </ref>. To circumvent this problem in random graphs, we make a small change in the structure of the graph, similar to that in [7]. Suppose that we use the previous analysis to correct all but at most n message bits with high probability.
Reference: [7] <author> M. Luby, M. Mitzenmacher, M. A. Shokrollahi, D. A. Spielman, and V. Stemann, </author> <title> "Practical Loss-Resilient Codes", </title> <booktitle> Proc. 29 th Symp. on Theory of Computing, </booktitle> <year> 1997, </year> <pages> pp. 150-159. </pages>
Reference-contexts: Instead, he constructs explicit graphs of large girth to which his analysis does apply. The main contribution of this paper is the design and analysis of low-density parity-check codes based on irregular graphs. This work follows the general approach introduced in <ref> [7] </ref> for the design and analysis of erasure codes. There it is shown that using irregular graphs yields codes with much better performance than regular graphs. In accordance with [7], we consider error-correcting codes based on random irregular bipartite graphs, which we call irregular codes. <p> This work follows the general approach introduced in <ref> [7] </ref> for the design and analysis of erasure codes. There it is shown that using irregular graphs yields codes with much better performance than regular graphs. In accordance with [7], we consider error-correcting codes based on random irregular bipartite graphs, which we call irregular codes. We develop tools based on linear programming for designing linear time encodable and decodable irregular codes with better error-correcting capabilities than regular codes. <p> An alternative approach is to allow the nodes on the right to represent bits rather than restrictions, and then use a cascading series of bipartite graphs, as described for example in [16] or <ref> [7] </ref>. In this situation, we know inductively the correct value of the check nodes in each layer when we correct the message nodes, and the check nodes are the exclusive-or of their incident message nodes. <p> The analysis that we provide in this case works for either of the two approaches given above, as we may inductively focus on just one layer in the context of cascading series of graphs <ref> [16, 7] </ref>. We call the linear codes that are obtained by either of the above constructions regular codes. Consider a regular random graph with the message nodes having degree d ` and the check nodes having degree d r . With probability p a message node receives the wrong bit. <p> To circumvent this problem Gallager designs regular graphs with no small cycles [6]. To circumvent this problem in random graphs, we make a small change in the structure of the graph, similar to that in <ref> [7] </ref>. Suppose that we use the previous analysis to correct all but at most n message bits with high probability. <p> Following the notation used in <ref> [7] </ref>, for an irregular bipartite graph we say that an edge has degree i on the left (right) if its left (right) hand neighbor has degree i.
Reference: [8] <author> M. Luby, M. Mitzenmacher, and M. A. Shokrollahi, </author> <title> "Analysis of Random Processes via And-Or Trees", </title> <booktitle> Proc. 9 th Symp. on Discrete Algorithms, </booktitle> <year> 1998. </year>
Reference-contexts: However, the analysis used by Gallager does not directly apply to randomly chosen graphs. Thus, to analyze the performance of the irregular codes, we develop an analysis that applies to randomly chosen graphs. Using techniques from <ref> [8] </ref> for studying random processes, we can calculate for a random regular graph the fraction of erroneous bits for which Gallager's original algorithm can correct all but an arbitrarily small constant fraction of the errors. <p> We conclude with a discussion of open problems. 2 Regular Codes 2.1 Analyzing Regular Codes We first review the codes developed by Gallager and his analysis [6]. Later we explain how his analysis combined with the argument from <ref> [8] </ref> shows that his suggested decoding algorithm corrects all but an arbitrarily small constant fraction of the nodes with high probability for random regular codes. <p> It follows simply from a similar argument in <ref> [8] </ref> that the recursive description given by equation (4) is correct with high probability over any constant number of rounds.
Reference: [9] <author> M. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. A. Spielman, </author> <title> "Improved Low Density Parity Check Codes Using Irregular Graphs and Belief Propagation", </title> <note> submitted to the 1998 International Symposium on Information Theory. </note>
Reference-contexts: In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes <ref> [9] </ref>. We believe our analysis here provides an important step towards analyzing codes based on belief propagation techniques. The paper proceeds as follows: in Section 2.1, we present a description of regular codes and analyze Gal-lager's decoding scheme. <p> We note that Gallager also proposes a belief propagation type decoding algorithm, which uses a more complicated state; for more details, see for example <ref> [4, 9, 11, 17] </ref>. In the following we refer to the nodes on the left and right sides of a bipartite graph as its message nodes and check nodes respectively. <p> In contrast, we note that using varying degrees for the check nodes is advantageous when using a more complicated decoding algorithm based on belief propagation <ref> [9] </ref>. Using the linear programming technique, we have considered graphs where the nodes on the left side may have varying degrees and the nodes on the right side all have the same degree. In other words, we have found good codes by considering vectors with just one nonzero entry.
Reference: [10] <author> D. J. C. MacKay, R, J. McEliece, and J.-F. Cheng, </author> <title> "Turbo Coding as an Instance of Pearl's 'Belief Propagation' Algorithm", </title> <journal> to appear in IEEE Journal on Selected Areas in Communication. </journal>
Reference-contexts: Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes [2, 6, 11, 12, 17] and is strongly related to the highly successful turbo codes <ref> [1, 3, 10, 5] </ref>. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9]. We believe our analysis here provides an important step towards analyzing codes based on belief propagation techniques.
Reference: [11] <author> D. J. C. MacKay and R. M. Neal, </author> <title> "Good Error Correcting Codes Based on Very Sparse Matrices", </title> <note> available from http://wol.ra.phy.cam.ac.uk/mackay. </note>
Reference-contexts: Additionally, the bound on the probability of error we derive using this methodology improves upon the bound derived by Gallager for the regular graphs he explicitly constructed. Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes <ref> [2, 6, 11, 12, 17] </ref> and is strongly related to the highly successful turbo codes [1, 3, 10, 5]. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9]. <p> We note that Gallager also proposes a belief propagation type decoding algorithm, which uses a more complicated state; for more details, see for example <ref> [4, 9, 11, 17] </ref>. In the following we refer to the nodes on the left and right sides of a bipartite graph as its message nodes and check nodes respectively. <p> No effort was made to test graphs or weed out potentially bad ones, and hence we expect that our results would be slightly better if several random graphs were tested and the best ones chosen. Following the ideas of [15] and <ref> [11] </ref>, when necessary we remove double edges from our graphs. 4.1 Some Experiments We first describe experiments on codes of rate 1=2 with 16,000 message bits and 8,000 check bits. In Figure 3, we describe the performance of Code 14 and Code 22 that we introduced in subsection 3.4. <p> We now consider Code 10' and Code 14' introduced in subsection 3.4. The experiments were run on 16,000 message bits and 8,000 check bits for 2,000 trials. In our experiments, we remove both double edges and some small cycles, as suggested in <ref> [11] </ref>. Recall that the appropriate value of p fl is approximately 0:0578 for Code 10' and 0:0627 for Code 14'. These codes again perform near what our analysis suggests, and they significantly outperform previous similar codes with similar decoding schemes, including regular codes.
Reference: [12] <author> D. J. C. MacKay and R. M. Neal, </author> <title> "Near Shannon Limit Performance of Low Density Parity Check Codes", </title> <note> to appear in Electronic Letters. </note>
Reference-contexts: Additionally, the bound on the probability of error we derive using this methodology improves upon the bound derived by Gallager for the regular graphs he explicitly constructed. Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes <ref> [2, 6, 11, 12, 17] </ref> and is strongly related to the highly successful turbo codes [1, 3, 10, 5]. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9].
Reference: [13] <author> R. Motwani and P. Raghavan, </author> <title> Randomized Algorithms, </title> <publisher> Cambridge University Press, </publisher> <year> 1995. </year>
Reference-contexts: For sufficiently large n the value fl=n is less than *=4. Now by exposing the edges one by one using an edge exposure martingale and applying Azuma's inequality <ref> [13, Section 4.4] </ref> we see that the fraction of edges with non-tree neighborhoods is greater than *=2 with probability at most exp (c*n). Now let Z i be the expected number of edges set to pass incorrect messages after i rounds.
Reference: [14] <author> J. Pearl, </author> <title> Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, </title> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1988. </year>
Reference-contexts: This analysis easily extends to the irregular codes that we introduce. Additionally, the bound on the probability of error we derive using this methodology improves upon the bound derived by Gallager for the regular graphs he explicitly constructed. Gallager's decoding algorithm is a simplification of "belief propagation" <ref> [14] </ref>. Belief propagation has been extensively tested with Gallager's low-density parity-check codes [2, 6, 11, 12, 17] and is strongly related to the highly successful turbo codes [1, 3, 10, 5].
Reference: [15] <author> M. Sipser, D. A. Spielman, </author> <title> "Expander Codes", </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 42(6), </volume> <month> November </month> <year> 1996, </year> <pages> pp. 1710-1722. </pages>
Reference-contexts: Once the number of erroneous bits is reduced to this level, we switch from Gallager's algorithm to one used by Spielman and Sipser in <ref> [15] </ref>, and prove that this new hybrid method successfully finishes the decoding with high probability. This analysis easily extends to the irregular codes that we introduce. <p> The analysis, however, is not sufficient to show that the decoding process completes successfully. In this section, we show how to finish the decoding process with high probability once the number of errors is sufficiently small using slightly different algorithms. Our work utilizes the expander-based arguments in <ref> [15, 16] </ref>. We first define what we require in terms of the bipartite graph represented by the code being a good expander. <p> Following the notation of <ref> [15] </ref>, we call a message node corrupt if it differs from its correct value, and we call a check node satisfied (respectively unsatisfied) if its value is (is not) the sum of the values of its adjacent message nodes. The work of [15] shows that if the underlying bipartite graph of <p> Following the notation of <ref> [15] </ref>, we call a message node corrupt if it differs from its correct value, and we call a check node satisfied (respectively unsatisfied) if its value is (is not) the sum of the values of its adjacent message nodes. The work of [15] shows that if the underlying bipartite graph of a code has sufficient expansion for sets of size up to ffn, then both of the following algorithms can correct any set of ffn=2 errors: Sequential decoding: if there is a message node that has more satisfied than unsatisfied neighbors, flip the <p> We call upon the results of <ref> [15] </ref> to show that once we use hard decision decoding to correct all but some arbitrarily small fraction of the message nodes, we can finish the process. The next lemma follows from Theorems 10 and 11 of [15]. <p> We call upon the results of <ref> [15] </ref> to show that once we use hard decision decoding to correct all but some arbitrarily small fraction of the message nodes, we can finish the process. The next lemma follows from Theorems 10 and 11 of [15]. Lemma 1 Let ff &gt; 0 and fi &gt; 3=4 + * for some fixed * &gt; 0. Let B be an (ff; fi) expander. Then the sequential and parallel decoding algorithms correct up to ffn=2 errors. <p> Suppose that B is an irregular bipartite (ff; fi) expander, and that d is the maximum degree on a left node of B. Then the sequential decoding algorithm corrects up to ffn=2d errors in linear time. Proof : We follow Theorem 10 of <ref> [15] </ref>. We show that the number of unsatisfied check nodes decreases after each step in the sequential algorithm. Let V be the set of corrupt message nodes, with jV j = v and jffi (V )j = dv. <p> Recall that 0:0517 is the best value of p fl that is possible using regular graphs for rate 1/2 codes. 4 Experimental Results We include preliminary experimental results for new codes we have found using the linear programming approach. Our experimental design is similar to that of <ref> [15] </ref>, whose results can be compared with ours. We describe a few important details of our experiments and implementations. In our implementation, we simply run Gallager's decoding technique until it finishes, or until a pre-specified number of rounds pass without success. <p> No effort was made to test graphs or weed out potentially bad ones, and hence we expect that our results would be slightly better if several random graphs were tested and the best ones chosen. Following the ideas of <ref> [15] </ref> and [11], when necessary we remove double edges from our graphs. 4.1 Some Experiments We first describe experiments on codes of rate 1=2 with 16,000 message bits and 8,000 check bits. <p> Further experiments with larger block lengths demonstrate that performance improves with the number of bits in the message, as one would expect. These codes therefore perform better than the codes based on regular graphs presented in <ref> [15] </ref>, albeit at the expense of a greater (but still linear) running time. They also perform much better than regular codes.
Reference: [16] <author> D. A. Spielman, </author> <title> "Linear Time Encodable and Decodable Error-Correcting Codes", </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 42(6), </volume> <month> November </month> <year> 1996, </year> <pages> pp. 1723-1731. </pages>
Reference-contexts: An alternative approach is to allow the nodes on the right to represent bits rather than restrictions, and then use a cascading series of bipartite graphs, as described for example in <ref> [16] </ref> or [7]. In this situation, we know inductively the correct value of the check nodes in each layer when we correct the message nodes, and the check nodes are the exclusive-or of their incident message nodes. <p> The analysis that we provide in this case works for either of the two approaches given above, as we may inductively focus on just one layer in the context of cascading series of graphs <ref> [16, 7] </ref>. We call the linear codes that are obtained by either of the above constructions regular codes. Consider a regular random graph with the message nodes having degree d ` and the check nodes having degree d r . With probability p a message node receives the wrong bit. <p> The analysis, however, is not sufficient to show that the decoding process completes successfully. In this section, we show how to finish the decoding process with high probability once the number of errors is sufficiently small using slightly different algorithms. Our work utilizes the expander-based arguments in <ref> [15, 16] </ref>. We first define what we require in terms of the bipartite graph represented by the code being a good expander.
Reference: [17] <author> N. Wiberg, </author> <title> "Codes and decoding on general graphs" Ph.D. </title> <type> dissertation, </type> <institution> Dept. Elec. Eng, U. Linkoping, Sweeden, </institution> <month> April </month> <year> 1996. </year>
Reference-contexts: Additionally, the bound on the probability of error we derive using this methodology improves upon the bound derived by Gallager for the regular graphs he explicitly constructed. Gallager's decoding algorithm is a simplification of "belief propagation" [14]. Belief propagation has been extensively tested with Gallager's low-density parity-check codes <ref> [2, 6, 11, 12, 17] </ref> and is strongly related to the highly successful turbo codes [1, 3, 10, 5]. In a separate work, we describe empirical tests on irregular codes using a full belief propagation algorithm and demonstrate irregular codes with better performance than regular codes [9]. <p> We note that Gallager also proposes a belief propagation type decoding algorithm, which uses a more complicated state; for more details, see for example <ref> [4, 9, 11, 17] </ref>. In the following we refer to the nodes on the left and right sides of a bipartite graph as its message nodes and check nodes respectively.
References-found: 17

