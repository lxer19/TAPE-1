URL: http://www.eecis.udel.edu:80/~kalluri/papers/kalluri-thesis.ps
Refering-URL: http://www.eecis.udel.edu:80/~kalluri/
Root-URL: http://www.cis.udel.edu
Title: NONLINEAR ADAPTIVE ALGORITHMS FOR ROBUST SIGNAL PROCESSING AND COMMUNICATIONS IN IMPULSIVE ENVIRONMENTS  
Author: by Sudhakar Kalluri 
Degree: A dissertation submitted to the Faculty of the University of Delaware in partial fulfillment of the requirements for the degree of Doctor of Philosophy in Electrical Engineering  c 1998 Sudhakar Kalluri All Rights Reserved  
Date: Fall 1998  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> E. J. Wegman and J. G. Smith, eds., </author> <title> Statistical Signal Processing. </title> <address> New York: </address> <publisher> Marcel Dekker, </publisher> <year> 1984. </year>
Reference-contexts: As a result of this assumption, linear estimators have pervaded the statistical signal processing literature, since they are the optimal estimators in a Gaussian environment. There are, however, many phenomena occurring in practice that are decidedly non-Gaussian <ref> [1, 2] </ref>. For instance, a large number of physical processes have been found to be impulsive in nature, with sharp spikes or occasional outliers present in the data. <p> to demonstrate the fixed point iterations of Section 4.2, a single input vector of length N = 9 was generated, with the N samples chosen to be independent 49 w = [0:70; 0:36; 0:94; 0:22; 0:39; 0:04; 0:26; 0:60; 0:02], linearity param eter K = 0:03. and uniformly distributed over <ref> [0; 1] </ref>. The weight vector was also generated randomly, with the weights following a uniform distribution over [0; 1]. The linearity parameter was chosen to be K = 0:03. Fig. 4.4 shows the weighted myriad objective function Q () of (4.4) for this example. <p> 9 was generated, with the N samples chosen to be independent 49 w = [0:70; 0:36; 0:94; 0:22; 0:39; 0:04; 0:26; 0:60; 0:02], linearity param eter K = 0:03. and uniformly distributed over <ref> [0; 1] </ref>. The weight vector was also generated randomly, with the weights following a uniform distribution over [0; 1]. The linearity parameter was chosen to be K = 0:03. Fig. 4.4 shows the weighted myriad objective function Q () of (4.4) for this example. <p> Example 2: In this example, the speed and accuracy of Algorithms I and II are investigated by filtering a long input signal using several window sizes N and different values of the linearity parameter K. The input signal consisted of 5000 randomly generated samples following a uniform distribution over <ref> [0; 1] </ref>. The window sizes used were N = 5; 7; 9; 11; 13 and 15. For each N , the N filter weights were generated randomly, again following the uniform distribution over [0; 1]. <p> The input signal consisted of 5000 randomly generated samples following a uniform distribution over <ref> [0; 1] </ref>. The window sizes used were N = 5; 7; 9; 11; 13 and 15. For each N , the N filter weights were generated randomly, again following the uniform distribution over [0; 1]. The same weight vector was used 52 to filter the input signal with several values of K, varying from K = 0:05 to K = 1:0 in steps of 0:05.
Reference: [2] <author> E. J. Wegman, S. C. Schwartz, and J. B. Thomas, eds., </author> <title> Topics in Non-Gaussian Signal Processing. </title> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1989. </year>
Reference-contexts: As a result of this assumption, linear estimators have pervaded the statistical signal processing literature, since they are the optimal estimators in a Gaussian environment. There are, however, many phenomena occurring in practice that are decidedly non-Gaussian <ref> [1, 2] </ref>. For instance, a large number of physical processes have been found to be impulsive in nature, with sharp spikes or occasional outliers present in the data.
Reference: [3] <author> D. Middleton, </author> <title> "Man-made noise in urban environments and transportation systems," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. COM-21, </volume> <pages> pp. 1232-1241, </pages> <month> Nov. </month> <year> 1973. </year>
Reference-contexts: Examples of impulsive signals include atmospheric noise in radio links, ocean acoustic signals, switching transients in telephone channels, multiple access interference in wireless communication systems, and many kinds of human-made noise <ref> [3, 4, 5, 6, 7] </ref>. Such processes are more accurately modeled by distributions with probability density functions having heavier tails than those of the Gaussian density function. The 1 performance of traditional linear signal processing, optimized under the Gaussian model, can deteriorate rapidly in an impulsive environment.
Reference: [4] <author> D. Middleton, </author> <title> "Statistical-physical models of electromagnetic interference," </title> <journal> IEEE Transactions on Electromagnetic Compatibility, </journal> <volume> vol. EMC-19, no. 3, </volume> <pages> pp. 106-127, </pages> <year> 1977. </year>
Reference-contexts: Examples of impulsive signals include atmospheric noise in radio links, ocean acoustic signals, switching transients in telephone channels, multiple access interference in wireless communication systems, and many kinds of human-made noise <ref> [3, 4, 5, 6, 7] </ref>. Such processes are more accurately modeled by distributions with probability density functions having heavier tails than those of the Gaussian density function. The 1 performance of traditional linear signal processing, optimized under the Gaussian model, can deteriorate rapidly in an impulsive environment.
Reference: [5] <author> M. P. Shinde and S. N. Gupta, </author> <title> "Signal detection in the presence of atmospheric noise in tropics," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. COM-22, </volume> <month> Aug. </month> <year> 1974. </year>
Reference-contexts: Examples of impulsive signals include atmospheric noise in radio links, ocean acoustic signals, switching transients in telephone channels, multiple access interference in wireless communication systems, and many kinds of human-made noise <ref> [3, 4, 5, 6, 7] </ref>. Such processes are more accurately modeled by distributions with probability density functions having heavier tails than those of the Gaussian density function. The 1 performance of traditional linear signal processing, optimized under the Gaussian model, can deteriorate rapidly in an impulsive environment.
Reference: [6] <author> B. Stuck and B. Kleiner, </author> <title> "A statistical analysis of telephone noise," </title> <journal> Bell Systems Technical Journal, </journal> <volume> vol. 53, </volume> <pages> pp. 1263-1320, </pages> <month> Sept. </month> <year> 1974. </year>
Reference-contexts: Examples of impulsive signals include atmospheric noise in radio links, ocean acoustic signals, switching transients in telephone channels, multiple access interference in wireless communication systems, and many kinds of human-made noise <ref> [3, 4, 5, 6, 7] </ref>. Such processes are more accurately modeled by distributions with probability density functions having heavier tails than those of the Gaussian density function. The 1 performance of traditional linear signal processing, optimized under the Gaussian model, can deteriorate rapidly in an impulsive environment.
Reference: [7] <author> J. Ilow, </author> <title> Signal Processing in Alpha-Stable Noise Environments: Noise Modeling, Detection and Estimation. </title> <type> PhD thesis, </type> <institution> University of Toronto, Canada, </institution> <month> Dec. </month> <year> 1995. </year>
Reference-contexts: Examples of impulsive signals include atmospheric noise in radio links, ocean acoustic signals, switching transients in telephone channels, multiple access interference in wireless communication systems, and many kinds of human-made noise <ref> [3, 4, 5, 6, 7] </ref>. Such processes are more accurately modeled by distributions with probability density functions having heavier tails than those of the Gaussian density function. The 1 performance of traditional linear signal processing, optimized under the Gaussian model, can deteriorate rapidly in an impulsive environment. <p> For example, ff-stable distributions have been used to model multiple access interference in radio networks where the independent interfering sources are modeled as a Poisson field in space and the superposition of the interfering electromagnetic waves follows an ff-stable distribution <ref> [7, 26] </ref>. <p> Weighted median smoothers, and other nonlinear smoothers based on order statistics [12, 14], are derived from the heavy-tailed Laplacian noise model, and are extensively used in robust image processing applications. Weighted Myriad Smoothers [27, 28, 29, 36] have been developed based on the so-called ff-stable distributions <ref> [7, 22] </ref>, which are more heavy-tailed than the Gaussian and Laplacian distributions, while including the Gaussian distribution as a special limiting case. Weighted myriad smoothers include as a special case the weighted mean smoother, which is a normalized linear FIR filter with non-negative weights summing to unity.
Reference: [8] <author> P. J. Huber, </author> <title> Robust Statistics. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1981. </year>
Reference-contexts: The presence of outliers can be viewed as arising from an uncertainty regarding the assumed model, with the outlier in a set of observations often modeled using a different distribution from that of the remaining "normal" samples. Most of these methods are based on the theory of robust statistics <ref> [8, 9] </ref>. Robust signal processing techniques [10] are designed to have good performance under nominal conditions and still be adequate when the signal and noise statistics deviate from the nominal model. <p> The class of M -estimators, developed in the theory of robust statistics <ref> [8, 9] </ref>, has been a cornerstone in the development of robust processing techniques [10]. Maximum-Likelihood location estimates form a special type of M -estimators, based on the assumption of independent and identically distributed (i.i.d) observations following a known common probability distribution. <p> In the following, we first develop the general class of M -smoothers, before introducing the specific case of weighted myriad smoothers. 2.1 M -estimators and M -smoothers The class of M -estimators (Maximum-Likelihood type estimators) of location, developed in the theory of robust statistics <ref> [8] </ref>, has been of fundamental importance in the development of robust signal processing techniques [10]. <p> [x (1) ; x (N) ] in (b) is not restrictive since, even if the initial value 0 is chosen outside [x (1) ; x (N) ], (4.17) shows that m ; m &gt; 0 will all lie within this interval. (iii) This theorem exploits parts of Section 7.8 of <ref> [8] </ref>, which deals with the computation of regression M -estimates. Corollary 4.1 The sequence fQ m g converges: Q m # Q fl 4 = inf (fQ m g 1 Proof: It is evident from the theorem that Q m+1 Q m . <p> This leads to negligible updates. Thus, the algorithm is robust to outliers and also allows the weights to settle down. It is interesting to note that the function (u; ~) is related to the influence function of the myriad estimator (see <ref> [8, 9] </ref> for discussions on the influence function of an M -estimator). <p> This completes the proof of Theorem 4.1. 131 Remark Parts of our proof use ideas from Section 7.8 of <ref> [8] </ref> on the computation of joint regression M -estimates of location and scale. As promised earlier, we now verify that the functions C i () of (A.4) satisfy the condition (i) of (A.5): C i (v) (v) 8 v.
Reference: [9] <author> F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel, </author> <title> Robust Statistics: The Approach Based on Influence Functions. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1986. </year>
Reference-contexts: The presence of outliers can be viewed as arising from an uncertainty regarding the assumed model, with the outlier in a set of observations often modeled using a different distribution from that of the remaining "normal" samples. Most of these methods are based on the theory of robust statistics <ref> [8, 9] </ref>. Robust signal processing techniques [10] are designed to have good performance under nominal conditions and still be adequate when the signal and noise statistics deviate from the nominal model. <p> The class of M -estimators, developed in the theory of robust statistics <ref> [8, 9] </ref>, has been a cornerstone in the development of robust processing techniques [10]. Maximum-Likelihood location estimates form a special type of M -estimators, based on the assumption of independent and identically distributed (i.i.d) observations following a known common probability distribution. <p> This leads to negligible updates. Thus, the algorithm is robust to outliers and also allows the weights to settle down. It is interesting to note that the function (u; ~) is related to the influence function of the myriad estimator (see <ref> [8, 9] </ref> for discussions on the influence function of an M -estimator).
Reference: [10] <author> S. A. Kassam and H. V. </author> <title> Poor, "Robust techniques for signal processing," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 73, </volume> <month> Mar. </month> <year> 1985. </year>
Reference-contexts: Most of these methods are based on the theory of robust statistics [8, 9]. Robust signal processing techniques <ref> [10] </ref> are designed to have good performance under nominal conditions and still be adequate when the signal and noise statistics deviate from the nominal model. <p> The class of M -estimators, developed in the theory of robust statistics [8, 9], has been a cornerstone in the development of robust processing techniques <ref> [10] </ref>. Maximum-Likelihood location estimates form a special type of M -estimators, based on the assumption of independent and identically distributed (i.i.d) observations following a known common probability distribution. <p> class of M -smoothers, before introducing the specific case of weighted myriad smoothers. 2.1 M -estimators and M -smoothers The class of M -estimators (Maximum-Likelihood type estimators) of location, developed in the theory of robust statistics [8], has been of fundamental importance in the development of robust signal processing techniques <ref> [10] </ref>. Given a set of observations (input samples) fx i g N i=1 , an M -estimate of their common location is given by ^ = arg min N X (x i ); (2.1) where () is called the cost function of the M -estimator.
Reference: [11] <author> D. R. K. Brownrigg, </author> <title> "The weighted median filter," </title> <journal> Commun. Assoc. Comput. Mach., </journal> <volume> vol. 27, </volume> <month> Aug. </month> <year> 1984. </year> <month> 142 </month>
Reference-contexts: Robust signal processing techniques [10] are designed to have good performance under nominal conditions and still be adequate when the signal and noise statistics deviate from the nominal model. In the area of image processing, Weighted Median Smoothers <ref> [11, 12] </ref>, along with other filters based on order statistics [13], have been widely used due to their ability to reject outliers while preserving edges and fine detail in images [14, 15].
Reference: [12] <author> L. Yin, R. Yang, M. Gabbouj, and Y. Neuvo, </author> <title> "Weighted median filters: A tutorial," </title> <journal> IEEE Transactions on Circuits and Systems-II, </journal> <volume> vol. 43, </volume> <month> Mar. </month> <year> 1996. </year>
Reference-contexts: Robust signal processing techniques [10] are designed to have good performance under nominal conditions and still be adequate when the signal and noise statistics deviate from the nominal model. In the area of image processing, Weighted Median Smoothers <ref> [11, 12] </ref>, along with other filters based on order statistics [13], have been widely used due to their ability to reject outliers while preserving edges and fine detail in images [14, 15]. <p> Included in this class of estimators are the linear, weighted median and the recently proposed weighted myriad smoother families. Weighted median smoothers, and other nonlinear smoothers based on order statistics <ref> [12, 14] </ref>, are derived from the heavy-tailed Laplacian noise model, and are extensively used in robust image processing applications.
Reference: [13] <author> H. A. David, </author> <title> Order statistics. </title> <address> New York: </address> <publisher> Wiley Interscience, </publisher> <year> 1982. </year>
Reference-contexts: Robust signal processing techniques [10] are designed to have good performance under nominal conditions and still be adequate when the signal and noise statistics deviate from the nominal model. In the area of image processing, Weighted Median Smoothers [11, 12], along with other filters based on order statistics <ref> [13] </ref>, have been widely used due to their ability to reject outliers while preserving edges and fine detail in images [14, 15]. These nonlinear filters are optimal under the Laplacian noise model, whose density function is heavier-tailed than the Gaussian density and, therefore, more suited to model outliers.
Reference: [14] <author> I. Pitas and A. Venetsanopoulos, </author> <title> "Order statistics in digital image processing," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 80, </volume> <month> Dec. </month> <year> 1992. </year>
Reference-contexts: In the area of image processing, Weighted Median Smoothers [11, 12], along with other filters based on order statistics [13], have been widely used due to their ability to reject outliers while preserving edges and fine detail in images <ref> [14, 15] </ref>. These nonlinear filters are optimal under the Laplacian noise model, whose density function is heavier-tailed than the Gaussian density and, therefore, more suited to model outliers. <p> Included in this class of estimators are the linear, weighted median and the recently proposed weighted myriad smoother families. Weighted median smoothers, and other nonlinear smoothers based on order statistics <ref> [12, 14] </ref>, are derived from the heavy-tailed Laplacian noise model, and are extensively used in robust image processing applications.
Reference: [15] <author> Y.-T. Kim and G. R. Arce, </author> <title> "Permutation filter lattices: A general order-statistic filtering framework," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 42, </volume> <month> Sept. </month> <year> 1994. </year>
Reference-contexts: In the area of image processing, Weighted Median Smoothers [11, 12], along with other filters based on order statistics [13], have been widely used due to their ability to reject outliers while preserving edges and fine detail in images <ref> [14, 15] </ref>. These nonlinear filters are optimal under the Laplacian noise model, whose density function is heavier-tailed than the Gaussian density and, therefore, more suited to model outliers. <p> Included in this class are linear filters, Ll filters based on order statistics [17, 18], permutation filters (which are generalizations of both linear and order statistic filters) <ref> [15] </ref>, and Volterra filters [50], among others.
Reference: [16] <author> J. Astola and Y. Neuvo, </author> <title> "Matched median filtering," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 40, </volume> <month> Apr. </month> <year> 1992. </year>
Reference-contexts: These nonlinear filters are optimal under the Laplacian noise model, whose density function is heavier-tailed than the Gaussian density and, therefore, more suited to model outliers. However, they have found limited use in communications <ref> [16] </ref> and their applications have been mainly confined to the field of robust image processing, largely because they are constrained to be selection filters (the filter output is always, by definition, one of the input samples).
Reference: [17] <author> F. Palmieri and C. G. Boncelet, Jr., </author> <title> "Ll filters Anew class of order statistic filters," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 37, </volume> <month> May </month> <year> 1989. </year>
Reference-contexts: Although hybrid techniques combining linear and median filtering have been developed <ref> [17, 18, 19, 20] </ref>, they tend to be ad hoc in nature and prohibitively complex. Further, unlike the Gaussian model which is justified by its occurrence in practice, the Laplacian distribution rarely arises 2 as the natural model for a real-world phenomenon. <p> Included in this class are linear filters, Ll filters based on order statistics <ref> [17, 18] </ref>, permutation filters (which are generalizations of both linear and order statistic filters) [15], and Volterra filters [50], among others.
Reference: [18] <author> P. Ghandi and S. A. Kassam, </author> <title> "Design and performance of combination filters," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 39, </volume> <month> July </month> <year> 1991. </year>
Reference-contexts: Although hybrid techniques combining linear and median filtering have been developed <ref> [17, 18, 19, 20] </ref>, they tend to be ad hoc in nature and prohibitively complex. Further, unlike the Gaussian model which is justified by its occurrence in practice, the Laplacian distribution rarely arises 2 as the natural model for a real-world phenomenon. <p> Included in this class are linear filters, Ll filters based on order statistics <ref> [17, 18] </ref>, permutation filters (which are generalizations of both linear and order statistic filters) [15], and Volterra filters [50], among others.
Reference: [19] <author> P. Heinonen and Y. Neuvo, </author> <title> "FIR-median hybrid filters," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 35, </volume> <month> June </month> <year> 1987. </year>
Reference-contexts: Although hybrid techniques combining linear and median filtering have been developed <ref> [17, 18, 19, 20] </ref>, they tend to be ad hoc in nature and prohibitively complex. Further, unlike the Gaussian model which is justified by its occurrence in practice, the Laplacian distribution rarely arises 2 as the natural model for a real-world phenomenon.
Reference: [20] <author> L. Yin and Y. Neuvo, </author> <title> "Fast adaptation and performance characteristics of FIR-WOS hybrid filters," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. 42, </volume> <month> July </month> <year> 1994. </year>
Reference-contexts: Although hybrid techniques combining linear and median filtering have been developed <ref> [17, 18, 19, 20] </ref>, they tend to be ad hoc in nature and prohibitively complex. Further, unlike the Gaussian model which is justified by its occurrence in practice, the Laplacian distribution rarely arises 2 as the natural model for a real-world phenomenon. <p> The adaptation of the weighted median smoother utilized an adaptive weighted order statistic (WOS) algorithm from <ref> [20] </ref>.
Reference: [21] <author> M. Shao and C. L. Nikias, </author> <title> "Signal processing with fractional lower order moments: Stable processes and their applications," </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> vol. 81, </volume> <month> July </month> <year> 1993. </year>
Reference-contexts: There is, therefore, a strong need to develop robust techniques based on practically occurring noise models, with widespread applications in signal processing and communications. In recent years, there has been considerable interest in signal processing based on ff-stable distributions, which have been shown to accurately model impulsive noise processes <ref> [21, 22, 23, 24, 25] </ref>. These distributions have a parameter ff (0 &lt; ff 2), called the characteristic exponent, which controls the heaviness of their tails; a smaller ff signifies a heavier-tailed distribution. For 0 &lt; ff &lt; 2, ff-stable random variables have infinite variance.
Reference: [22] <author> C. L. Nikias and M. Shao, </author> <title> Signal Processing with Alpha-Stable Distributions and Applications. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1995. </year>
Reference-contexts: There is, therefore, a strong need to develop robust techniques based on practically occurring noise models, with widespread applications in signal processing and communications. In recent years, there has been considerable interest in signal processing based on ff-stable distributions, which have been shown to accurately model impulsive noise processes <ref> [21, 22, 23, 24, 25] </ref>. These distributions have a parameter ff (0 &lt; ff 2), called the characteristic exponent, which controls the heaviness of their tails; a smaller ff signifies a heavier-tailed distribution. For 0 &lt; ff &lt; 2, ff-stable random variables have infinite variance. <p> The Gaussian and Cauchy distributions are the only symmetric ff-stable distributions having closed-form expressions for their density functions. The use of the ff-stable distribution as a statistical model is justified theoretically by two properties <ref> [22] </ref>. The first is the stability property: the sum of two independent stable random variables with the same characteristic exponent is also stable with the same characteristic exponent. <p> Weighted median smoothers, and other nonlinear smoothers based on order statistics [12, 14], are derived from the heavy-tailed Laplacian noise model, and are extensively used in robust image processing applications. Weighted Myriad Smoothers [27, 28, 29, 36] have been developed based on the so-called ff-stable distributions <ref> [7, 22] </ref>, which are more heavy-tailed than the Gaussian and Laplacian distributions, while including the Gaussian distribution as a special limiting case. Weighted myriad smoothers include as a special case the weighted mean smoother, which is a normalized linear FIR filter with non-negative weights summing to unity. <p> As mentioned in Section 2.1, myriad filters are motivated by the properties of ff-stable distributions <ref> [22] </ref>, of which the Gaussian distribution (ff = 2) and the Cauchy distribution (ff = 1) are special cases. <p> The desired signal d (n), also shown in the figure, is the sinusoid at the highest frequency, f 2 . The additive noise process v (n) was chosen to have a zero-mean symmetric ff-stable distribution <ref> [22] </ref> with a characteristic exponent ff = 1:6 and a dispersion fl = 0:02. Fig. 7.2 shows the additive ff-stable noise signal v (n) used in our simulations.
Reference: [23] <author> G. Samorodnitsky and M. S. Taqqu, </author> <title> Stable Non-Gaussian Random Processes. </title> <address> New York: </address> <publisher> Chapman & Hall, </publisher> <year> 1994. </year>
Reference-contexts: There is, therefore, a strong need to develop robust techniques based on practically occurring noise models, with widespread applications in signal processing and communications. In recent years, there has been considerable interest in signal processing based on ff-stable distributions, which have been shown to accurately model impulsive noise processes <ref> [21, 22, 23, 24, 25] </ref>. These distributions have a parameter ff (0 &lt; ff 2), called the characteristic exponent, which controls the heaviness of their tails; a smaller ff signifies a heavier-tailed distribution. For 0 &lt; ff &lt; 2, ff-stable random variables have infinite variance.
Reference: [24] <author> P. Tsakalides and C. L. Nikias, </author> <title> "Maximum likelihood localization of sources in noise modeled as a stable process," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 43, </volume> <month> Nov. </month> <year> 1995. </year>
Reference-contexts: There is, therefore, a strong need to develop robust techniques based on practically occurring noise models, with widespread applications in signal processing and communications. In recent years, there has been considerable interest in signal processing based on ff-stable distributions, which have been shown to accurately model impulsive noise processes <ref> [21, 22, 23, 24, 25] </ref>. These distributions have a parameter ff (0 &lt; ff 2), called the characteristic exponent, which controls the heaviness of their tails; a smaller ff signifies a heavier-tailed distribution. For 0 &lt; ff &lt; 2, ff-stable random variables have infinite variance.
Reference: [25] <author> G. A. Tsihrintzis and C. L. Nikias, </author> <title> "Performance of optimum and suboptimum receivers in the presence of impulsive noise modeled as an alpha- stable process," </title> <journal> IEEE Transactions on Communications, </journal> <volume> vol. 43, </volume> <month> Apr. </month> <year> 1995. </year> <month> 143 </month>
Reference-contexts: There is, therefore, a strong need to develop robust techniques based on practically occurring noise models, with widespread applications in signal processing and communications. In recent years, there has been considerable interest in signal processing based on ff-stable distributions, which have been shown to accurately model impulsive noise processes <ref> [21, 22, 23, 24, 25] </ref>. These distributions have a parameter ff (0 &lt; ff 2), called the characteristic exponent, which controls the heaviness of their tails; a smaller ff signifies a heavier-tailed distribution. For 0 &lt; ff &lt; 2, ff-stable random variables have infinite variance.
Reference: [26] <author> E. S. Sousa, </author> <title> "Performance of a spread spectrum packet radio network link in a Poisson field of interferers," </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> vol. 38, </volume> <pages> pp. 1743-1754, </pages> <month> Nov. </month> <year> 1992. </year>
Reference-contexts: For example, ff-stable distributions have been used to model multiple access interference in radio networks where the independent interfering sources are modeled as a Poisson field in space and the superposition of the interfering electromagnetic waves follows an ff-stable distribution <ref> [7, 26] </ref>.
Reference: [27] <author> J. G. Gonzalez and G. R. Arce, </author> <title> "Weighted myriad filters: A robust filtering framework derived from ff-stable distributions," </title> <booktitle> in Proc. of the 1996 IEEE ICASSP, </booktitle> <address> (Atlanta, GA), </address> <year> 1996. </year>
Reference-contexts: of ff-stable distributions are that they include the Gaussian distribution as the special limiting case of ff = 2, while possessing heavier density tails than the Gaussian and the Laplacian distributions. 3 Weighted Myriad Smoothers have been proposed recently as a class of robust, nonlinear filters based on ff-stable distributions <ref> [27, 28, 29] </ref>. These filters have been derived as extensions of the sample myriad, defined as the Maximum-Likelihood estimate of the location parameter of the Cauchy distribution (an ff-stable distribution with ff = 1) [28, 30]. <p> The fundamental M -estimator that generates the weighted myriad smoother family is the sample myriad, which is the Maximum-Likelihood estimator of location for the Cauchy distribution. For a complete treatment of weighted myriad smoothers and their applications, see <ref> [27, 31, 28, 29, 33, 36, 32] </ref>. It should be noted that in all the previously published work on myriad estimators, the weighted myriad smoother has been referred to as the weighted myriad filter. <p> Weighted median smoothers, and other nonlinear smoothers based on order statistics [12, 14], are derived from the heavy-tailed Laplacian noise model, and are extensively used in robust image processing applications. Weighted Myriad Smoothers <ref> [27, 28, 29, 36] </ref> have been developed based on the so-called ff-stable distributions [7, 22], which are more heavy-tailed than the Gaussian and Laplacian distributions, while including the Gaussian distribution as a special limiting case. <p> Using the Gaussian and Laplacian density functions in Maximum-Likelihood location estimation, we obtain the cost functions for the sample mean and the sample median as (u) = u 2 and (u) = juj, respectively. The sample myriad <ref> [30, 27, 28, 29] </ref> is defined using the Cauchy density function, which is the only symmetric ff-stable density function (other than the Gaussian) that is expressible in closed-form. <p> The cost function thus obtained is (u) = log (K 2 + u 2 ), where the robustness of the estimator is controlled by the so-called tuning parameter or linearity parameter K <ref> [27, 28, 29] </ref>. Table 2.1 shows the cost functions and the corresponding estimator outputs for the linear (mean), median and myriad smoother families. The first three rows describe the sample mean, median and 12 myriad estimators.
Reference: [28] <author> J. G. Gonzalez and G. R. Arce, </author> <title> "Weighted myriad filters: A powerful framework for efficient filtering in impulsive environments," </title> <journal> IEEE Transactions on Signal Processing. </journal> <note> Manuscript in review. </note>
Reference-contexts: of ff-stable distributions are that they include the Gaussian distribution as the special limiting case of ff = 2, while possessing heavier density tails than the Gaussian and the Laplacian distributions. 3 Weighted Myriad Smoothers have been proposed recently as a class of robust, nonlinear filters based on ff-stable distributions <ref> [27, 28, 29] </ref>. These filters have been derived as extensions of the sample myriad, defined as the Maximum-Likelihood estimate of the location parameter of the Cauchy distribution (an ff-stable distribution with ff = 1) [28, 30]. <p> These filters have been derived as extensions of the sample myriad, defined as the Maximum-Likelihood estimate of the location parameter of the Cauchy distribution (an ff-stable distribution with ff = 1) <ref> [28, 30] </ref>. Weighted myriad smoothers include as a special limiting case the weighted mean smoother (a normalized linear FIR filter with non-negative weights summing to unity). <p> Myriad smoothers have been shown to be optimal for a large class of distributions, including ff-stable distributions and generalized t distributions, that serve as practical models of impulsive noise <ref> [28, 29] </ref>. They have been successfully employed in several applications in robust communications and image processing [31, 32, 33]. <p> The fundamental M -estimator that generates the weighted myriad smoother family is the sample myriad, which is the Maximum-Likelihood estimator of location for the Cauchy distribution. For a complete treatment of weighted myriad smoothers and their applications, see <ref> [27, 31, 28, 29, 33, 36, 32] </ref>. It should be noted that in all the previously published work on myriad estimators, the weighted myriad smoother has been referred to as the weighted myriad filter. <p> Weighted median smoothers, and other nonlinear smoothers based on order statistics [12, 14], are derived from the heavy-tailed Laplacian noise model, and are extensively used in robust image processing applications. Weighted Myriad Smoothers <ref> [27, 28, 29, 36] </ref> have been developed based on the so-called ff-stable distributions [7, 22], which are more heavy-tailed than the Gaussian and Laplacian distributions, while including the Gaussian distribution as a special limiting case. <p> Using the Gaussian and Laplacian density functions in Maximum-Likelihood location estimation, we obtain the cost functions for the sample mean and the sample median as (u) = u 2 and (u) = juj, respectively. The sample myriad <ref> [30, 27, 28, 29] </ref> is defined using the Cauchy density function, which is the only symmetric ff-stable density function (other than the Gaussian) that is expressible in closed-form. <p> The cost function thus obtained is (u) = log (K 2 + u 2 ), where the robustness of the estimator is controlled by the so-called tuning parameter or linearity parameter K <ref> [27, 28, 29] </ref>. Table 2.1 shows the cost functions and the corresponding estimator outputs for the linear (mean), median and myriad smoother families. The first three rows describe the sample mean, median and 12 myriad estimators. <p> However, the myriad in fact turns out to be the optimal estimator of the location of ff-stable distributions for the triplet ff = (0; 1; 2) <ref> [28, 29] </ref>. Consider now a set of N independent and identically distributed (i.i.d.) random variables fX i g N i=1 , each following a Cauchy distribution with location parameter and scaling factor K &gt; 0. <p> It is interesting to note that the sample myriad includes the sample mean as the special limiting case when K ! 1 <ref> [28] </ref>: lim ^ K = i=1 2.3 The Weighted Myriad Smoother As mentioned in Section 2.1, the sample myriad can be generalized to the weighted myriad smoother by assigning non-negative weights to the input samples (observations); the weights reflect the varying levels of "reliability".
Reference: [29] <author> J. G. Gonzalez, </author> <title> Robust Techniques for Wireless Communications in NonGaus-sian Environments. </title> <type> PhD thesis, </type> <institution> Department of Electrical and Computer Engineering, University of Delaware, Newark, Delaware, U.S.A., </institution> <month> Dec. </month> <year> 1997. </year>
Reference-contexts: of ff-stable distributions are that they include the Gaussian distribution as the special limiting case of ff = 2, while possessing heavier density tails than the Gaussian and the Laplacian distributions. 3 Weighted Myriad Smoothers have been proposed recently as a class of robust, nonlinear filters based on ff-stable distributions <ref> [27, 28, 29] </ref>. These filters have been derived as extensions of the sample myriad, defined as the Maximum-Likelihood estimate of the location parameter of the Cauchy distribution (an ff-stable distribution with ff = 1) [28, 30]. <p> Myriad smoothers have been shown to be optimal for a large class of distributions, including ff-stable distributions and generalized t distributions, that serve as practical models of impulsive noise <ref> [28, 29] </ref>. They have been successfully employed in several applications in robust communications and image processing [31, 32, 33]. <p> The fundamental M -estimator that generates the weighted myriad smoother family is the sample myriad, which is the Maximum-Likelihood estimator of location for the Cauchy distribution. For a complete treatment of weighted myriad smoothers and their applications, see <ref> [27, 31, 28, 29, 33, 36, 32] </ref>. It should be noted that in all the previously published work on myriad estimators, the weighted myriad smoother has been referred to as the weighted myriad filter. <p> Weighted median smoothers, and other nonlinear smoothers based on order statistics [12, 14], are derived from the heavy-tailed Laplacian noise model, and are extensively used in robust image processing applications. Weighted Myriad Smoothers <ref> [27, 28, 29, 36] </ref> have been developed based on the so-called ff-stable distributions [7, 22], which are more heavy-tailed than the Gaussian and Laplacian distributions, while including the Gaussian distribution as a special limiting case. <p> Using the Gaussian and Laplacian density functions in Maximum-Likelihood location estimation, we obtain the cost functions for the sample mean and the sample median as (u) = u 2 and (u) = juj, respectively. The sample myriad <ref> [30, 27, 28, 29] </ref> is defined using the Cauchy density function, which is the only symmetric ff-stable density function (other than the Gaussian) that is expressible in closed-form. <p> The cost function thus obtained is (u) = log (K 2 + u 2 ), where the robustness of the estimator is controlled by the so-called tuning parameter or linearity parameter K <ref> [27, 28, 29] </ref>. Table 2.1 shows the cost functions and the corresponding estimator outputs for the linear (mean), median and myriad smoother families. The first three rows describe the sample mean, median and 12 myriad estimators. <p> However, the myriad in fact turns out to be the optimal estimator of the location of ff-stable distributions for the triplet ff = (0; 1; 2) <ref> [28, 29] </ref>. Consider now a set of N independent and identically distributed (i.i.d.) random variables fX i g N i=1 , each following a Cauchy distribution with location parameter and scaling factor K &gt; 0.
Reference: [30] <author> S. Ambike and D. Hatzinakos, </author> <title> "A new filter for highly impulsive ff-stable noise," </title> <booktitle> in Proc. of the 1995 Int. Workshop on Nonlinear Signal and Image Processing, </booktitle> <address> (Halkidiki, Greece), </address> <year> 1995. </year>
Reference-contexts: These filters have been derived as extensions of the sample myriad, defined as the Maximum-Likelihood estimate of the location parameter of the Cauchy distribution (an ff-stable distribution with ff = 1) <ref> [28, 30] </ref>. Weighted myriad smoothers include as a special limiting case the weighted mean smoother (a normalized linear FIR filter with non-negative weights summing to unity). <p> Using the Gaussian and Laplacian density functions in Maximum-Likelihood location estimation, we obtain the cost functions for the sample mean and the sample median as (u) = u 2 and (u) = juj, respectively. The sample myriad <ref> [30, 27, 28, 29] </ref> is defined using the Cauchy density function, which is the only symmetric ff-stable density function (other than the Gaussian) that is expressible in closed-form.
Reference: [31] <author> J. G. Gonzalez, D. W. Griffith, and G. R. Arce, </author> <title> "Matched myriad filtering for robust communications," </title> <booktitle> in Proc. of the 1996 CISS, </booktitle> <address> (Princeton, NJ), </address> <year> 1996. </year>
Reference-contexts: Myriad smoothers have been shown to be optimal for a large class of distributions, including ff-stable distributions and generalized t distributions, that serve as practical models of impulsive noise [28, 29]. They have been successfully employed in several applications in robust communications and image processing <ref> [31, 32, 33] </ref>. Weighted mean, median and myriad smoothers are all special cases of the class of weighted M -estimators of location (with non-negative weights), which we shall also refer to as the class of M -smoothers, for reasons that will be evident later in this section. <p> The fundamental M -estimator that generates the weighted myriad smoother family is the sample myriad, which is the Maximum-Likelihood estimator of location for the Cauchy distribution. For a complete treatment of weighted myriad smoothers and their applications, see <ref> [27, 31, 28, 29, 33, 36, 32] </ref>. It should be noted that in all the previously published work on myriad estimators, the weighted myriad smoother has been referred to as the weighted myriad filter. <p> Weighted myriad smoothers include as a special case the weighted mean smoother, which is a normalized linear FIR filter with non-negative weights summing to unity. These smoothers have been successfully utilized in several applications in robust communications and image processing <ref> [31, 32, 33] </ref>. The fundamental M -estimators that generate the linear, weighted median and weighted myriad smoother families are the sample mean, sample median and sample myriad, respectively.
Reference: [32] <author> P. Zurbach, J. G. Gonzalez, and G. R. Arce, </author> <title> "Weighted myriad filters for image processing," </title> <booktitle> in Proc. of the 1996 IEEE Int. Symp. on Circuits and Systems, </booktitle> <address> (Atlanta, GA), </address> <year> 1996. </year>
Reference-contexts: Myriad smoothers have been shown to be optimal for a large class of distributions, including ff-stable distributions and generalized t distributions, that serve as practical models of impulsive noise [28, 29]. They have been successfully employed in several applications in robust communications and image processing <ref> [31, 32, 33] </ref>. Weighted mean, median and myriad smoothers are all special cases of the class of weighted M -estimators of location (with non-negative weights), which we shall also refer to as the class of M -smoothers, for reasons that will be evident later in this section. <p> The fundamental M -estimator that generates the weighted myriad smoother family is the sample myriad, which is the Maximum-Likelihood estimator of location for the Cauchy distribution. For a complete treatment of weighted myriad smoothers and their applications, see <ref> [27, 31, 28, 29, 33, 36, 32] </ref>. It should be noted that in all the previously published work on myriad estimators, the weighted myriad smoother has been referred to as the weighted myriad filter. <p> Weighted myriad smoothers include as a special case the weighted mean smoother, which is a normalized linear FIR filter with non-negative weights summing to unity. These smoothers have been successfully utilized in several applications in robust communications and image processing <ref> [31, 32, 33] </ref>. The fundamental M -estimators that generate the linear, weighted median and weighted myriad smoother families are the sample mean, sample median and sample myriad, respectively.
Reference: [33] <author> S. Kalluri and G. R. Arce, </author> <title> "Adaptive weighted myriad filter algorithms for robust signal processing in ff-stable noise environments," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 46, </volume> <pages> pp. 322-334, </pages> <month> Feb. </month> <year> 1998. </year>
Reference-contexts: Myriad smoothers have been shown to be optimal for a large class of distributions, including ff-stable distributions and generalized t distributions, that serve as practical models of impulsive noise [28, 29]. They have been successfully employed in several applications in robust communications and image processing <ref> [31, 32, 33] </ref>. Weighted mean, median and myriad smoothers are all special cases of the class of weighted M -estimators of location (with non-negative weights), which we shall also refer to as the class of M -smoothers, for reasons that will be evident later in this section. <p> class of Nonlinear Normalized Adaptive Filtering Algorithms with fast convergence, that are applicable to a wide variety of nonlinear filters. 7 The material presented in this dissertation is the compilation of three years of research work that has so far resulted in the publication or submission of four journal articles <ref> [33, 36, 37, 38] </ref>, three conference articles [39, 40, 41] and one technical report [42]. Except for the background material on weighted myriad smoothers in Chapter 2, this dissertation contains purely original work. <p> The fundamental M -estimator that generates the weighted myriad smoother family is the sample myriad, which is the Maximum-Likelihood estimator of location for the Cauchy distribution. For a complete treatment of weighted myriad smoothers and their applications, see <ref> [27, 31, 28, 29, 33, 36, 32] </ref>. It should be noted that in all the previously published work on myriad estimators, the weighted myriad smoother has been referred to as the weighted myriad filter. <p> Weighted myriad smoothers include as a special case the weighted mean smoother, which is a normalized linear FIR filter with non-negative weights summing to unity. These smoothers have been successfully utilized in several applications in robust communications and image processing <ref> [31, 32, 33] </ref>. The fundamental M -estimators that generate the linear, weighted median and weighted myriad smoother families are the sample mean, sample median and sample myriad, respectively. <p> myriad smoother, the outputs of all these filters can be computed efficiently using the algorithms of this chapter. 57 Chapter 5 OPTIMIZATION OF WEIGHTED MYRIAD SMOOTHERS In this chapter, necessary conditions are obtained for optimality of the parameters of the Weighted Myriad Smoother under the mean absolute error (MAE) criterion <ref> [33, 40] </ref>. Stochastic gradient-based adaptive algorithms are then derived for the optimization of the filter weights. Although we focus on the MAE optimization criterion, our solutions are applicable to the mean squared error (MSE) criterion with trivial modifications.
Reference: [34] <author> S. Haykin, </author> <title> Adaptive Filter Theory. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1996. </year>
Reference-contexts: In applications where the signal statistics are unknown or insufficient, or when the signals are non-stationary, adaptive signal processing algorithms have been 6 used with great advantage <ref> [34, 35] </ref>. Motivated by the need for low-complexity tech-niques for filter optimization, we focus in this dissertation on the development of nonlinear adaptive algorithms for the optimization of the different types of myriad filters. <p> i (n) is given from (5.10) as @J (n) = E sgn (y (n) d (n)) @w i ) Since the lack of knowledge of the signal statistics precludes the evaluation of the statistical expectation in (5.32), we use instantaneous estimates for the gradient just as in the LMS algorithm <ref> [35, 34] </ref>. To this end, removing the expectation operator in (5.32) and substituting into (5.30), we have w i (n + 1) = P 0 w i (n) sgn (e (n)) @w i # where e (n) = y (n) d (n) is the error at the nth iteration. <p> Computer simulations of these algorithms are presented for two specific nonlinear filter structures: Volterra Filters and Myriad Filters. 7.1 Motivation The Least Mean Square (LMS) algorithm <ref> [34] </ref> is widely used for adapting the weights of a linear FIR filter that minimizes the mean square error (MSE) between the filter output and a desired signal. <p> In an envi ronment of unknown or time-varying signal statistics, the standard LMS algorithm 102 <ref> [34] </ref> continually attempts to minimize the MSE by updating the weight vector, at each time instant n, as w (n + 1) = w (n) e (n) x (n); (7.1) where &gt; 0 is the so-called step-size of the update. <p> The computational simplicity of the LMS algorithm has made it an attractive choice for several applications in linear signal processing, including noise cancellation, channel equalization, adaptive control, and system identification <ref> [34] </ref>. However, it suffers from a slow rate of convergence. Further, its implementation requires the choice of an appropriate value for the step-size which affects the stability, steady-state MSE and convergence speed of the algorithm. The stability (convergence) of the LMS algorithm has been extensively studied in the literature [34]. <p> identification <ref> [34] </ref>. However, it suffers from a slow rate of convergence. Further, its implementation requires the choice of an appropriate value for the step-size which affects the stability, steady-state MSE and convergence speed of the algorithm. The stability (convergence) of the LMS algorithm has been extensively studied in the literature [34]. The stability region for mean-square convergence of the LMS algorithm is given by 0 &lt; &lt; (2 = trace (R)) [34], where R = Efx (n)x T (n)g is the correlation matrix of the input vector x (n). <p> The stability (convergence) of the LMS algorithm has been extensively studied in the literature <ref> [34] </ref>. The stability region for mean-square convergence of the LMS algorithm is given by 0 &lt; &lt; (2 = trace (R)) [34], where R = Efx (n)x T (n)g is the correlation matrix of the input vector x (n). When the input signal statistics are unknown or the environment is nonstationary, it is difficult to choose a step-size that is guaranteed to lie within the stability region. <p> When the input signal statistics are unknown or the environment is nonstationary, it is difficult to choose a step-size that is guaranteed to lie within the stability region. The so-called Normalized LMS (NLMS) algorithm <ref> [34] </ref> addresses the problem of step-size design by choosing a time-varying step-size (n) in (7.1) such that the next-step MSE, J n+1 4 = Efe 2 (n + 1)g, is minimized at each iteration. <p> After incorporating an auxiliary step-size ~ &gt; 0, the NLMS algorithm is written as w (n + 1) = w (n) kx (n)k The theoretical bounds on the stability of the NLMS algorithm are given by 0 &lt; ~ &lt; 2 <ref> [34] </ref>. A significant advantage here is that, unlike the LMS step-size of (7.1), the auxiliary step-size ~ is dimensionless and the stability region for ~ is in dependent of the signal statistics. This allows for an easier step-size design with 103 guaranteed stability (convergence) of the algorithm. <p> Therefore, it is reasonable to expect the stability region for ~ to be the same as in the linear case, where it is 0 &lt; ~ &lt; 2 <ref> [34] </ref>. This turned out to be true in our simulations for the case of the second order Volterra filter (see Section 7.5). 7.4.2 Myriad Filters As a second example of nonlinear NLMS-type adaptive filtering, we consider a special type of weighted myriad filter, defined in Section 3.2.1.
Reference: [35] <author> B. Widrow and S. D. Stearns, </author> <title> Adaptive Signal Processing. </title> <address> Englewood Cliffs, NJ: </address> <publisher> Prentice Hall, </publisher> <year> 1985. </year>
Reference-contexts: In applications where the signal statistics are unknown or insufficient, or when the signals are non-stationary, adaptive signal processing algorithms have been 6 used with great advantage <ref> [34, 35] </ref>. Motivated by the need for low-complexity tech-niques for filter optimization, we focus in this dissertation on the development of nonlinear adaptive algorithms for the optimization of the different types of myriad filters. <p> i (n) is given from (5.10) as @J (n) = E sgn (y (n) d (n)) @w i ) Since the lack of knowledge of the signal statistics precludes the evaluation of the statistical expectation in (5.32), we use instantaneous estimates for the gradient just as in the LMS algorithm <ref> [35, 34] </ref>. To this end, removing the expectation operator in (5.32) and substituting into (5.30), we have w i (n + 1) = P 0 w i (n) sgn (e (n)) @w i # where e (n) = y (n) d (n) is the error at the nth iteration.
Reference: [36] <author> S. Kalluri and G. R. Arce, </author> <title> "Fast algorithms for weighted myriad computation by fixed point search," </title> <journal> IEEE Transactions on Signal Processing. </journal> <note> Manuscript in review. </note>
Reference-contexts: class of Nonlinear Normalized Adaptive Filtering Algorithms with fast convergence, that are applicable to a wide variety of nonlinear filters. 7 The material presented in this dissertation is the compilation of three years of research work that has so far resulted in the publication or submission of four journal articles <ref> [33, 36, 37, 38] </ref>, three conference articles [39, 40, 41] and one technical report [42]. Except for the background material on weighted myriad smoothers in Chapter 2, this dissertation contains purely original work. <p> The fundamental M -estimator that generates the weighted myriad smoother family is the sample myriad, which is the Maximum-Likelihood estimator of location for the Cauchy distribution. For a complete treatment of weighted myriad smoothers and their applications, see <ref> [27, 31, 28, 29, 33, 36, 32] </ref>. It should be noted that in all the previously published work on myriad estimators, the weighted myriad smoother has been referred to as the weighted myriad filter. <p> Weighted median smoothers, and other nonlinear smoothers based on order statistics [12, 14], are derived from the heavy-tailed Laplacian noise model, and are extensively used in robust image processing applications. Weighted Myriad Smoothers <ref> [27, 28, 29, 36] </ref> have been developed based on the so-called ff-stable distributions [7, 22], which are more heavy-tailed than the Gaussian and Laplacian distributions, while including the Gaussian distribution as a special limiting case. <p> We propose an iterative algorithm to compute these fixed points. We then develop fast algorithms, incorporating these fixed point iterations, for the computation of the weighted myriad <ref> [36, 42] </ref>. It is shown through a numerical example that these algorithms achieve a high degree of accuracy in approximating the weighted myriad, at a relatively low cost of computation.
Reference: [37] <author> S. Kalluri and G. R. Arce, </author> <title> "Robust frequency-selective filtering using weighted myriad filters admitting real-valued weights," </title> <journal> IEEE Transactions on Signal Processing. </journal> <note> Submitted for publication. 144 </note>
Reference-contexts: class of Nonlinear Normalized Adaptive Filtering Algorithms with fast convergence, that are applicable to a wide variety of nonlinear filters. 7 The material presented in this dissertation is the compilation of three years of research work that has so far resulted in the publication or submission of four journal articles <ref> [33, 36, 37, 38] </ref>, three conference articles [39, 40, 41] and one technical report [42]. Except for the background material on weighted myriad smoothers in Chapter 2, this dissertation contains purely original work. <p> By appropriately scaling (multiplying) the weighted myriad filter output, we further extend this structure 20 to yield the so-called Scaled Weighted Myriad Filters, which include the traditional linear FIR filter (with unnormalized real-valued weights) as a special case <ref> [37] </ref>. 3.1 M -filters Before we can extend the general class of M -smoothers, it is useful to examine the special cases of the weighted mean and median smoothers. <p> We derive necessary conditions for the optimality of these filter structures under the mean square error (MSE) criterion, and develop stochastic gradient-based (LMS-type) nonlinear adaptive algorithms for the optimization of the filter parameters <ref> [37] </ref>.
Reference: [38] <author> S. Kalluri and G. R. Arce, </author> <title> "A general class of nonlinear normalized adaptive filtering algorithms," </title> <journal> IEEE Transactions on Signal Processing. </journal> <note> Manuscript in review. </note>
Reference-contexts: class of Nonlinear Normalized Adaptive Filtering Algorithms with fast convergence, that are applicable to a wide variety of nonlinear filters. 7 The material presented in this dissertation is the compilation of three years of research work that has so far resulted in the publication or submission of four journal articles <ref> [33, 36, 37, 38] </ref>, three conference articles [39, 40, 41] and one technical report [42]. Except for the background material on weighted myriad smoothers in Chapter 2, this dissertation contains purely original work. <p> The design of the step-size is crucial to the performance of any adaptive algorithm since this parameter affects the stability, convergence speed and final mean square error (MSE) of the algorithm. In this chapter, we develop a class of so-called Normalized LMS-type algorithms <ref> [38, 41] </ref> which provide for an automatic step-size choice, possess superior convergence properties, and are applicable to a wide variety of nonlinear filters. <p> In this chapter, we generalize the NLMS algorithm of (7.2) by deriving a class of nonlinear Normalized LMS-type (NLMS-type) algorithms <ref> [41, 38] </ref> that are applicable to a wide variety of nonlinear filter structures. Consider now the case of an arbitrary nonlinear filter whose output is given by y y (w; x).
Reference: [39] <author> S. Kalluri and G. R. Arce, </author> <title> "Adaptive weighted myriad filter optimization for robust signal processing," </title> <booktitle> in Proc. of the 1996 CISS, </booktitle> <address> (Princeton, NJ), </address> <year> 1996. </year>
Reference-contexts: with fast convergence, that are applicable to a wide variety of nonlinear filters. 7 The material presented in this dissertation is the compilation of three years of research work that has so far resulted in the publication or submission of four journal articles [33, 36, 37, 38], three conference articles <ref> [39, 40, 41] </ref> and one technical report [42]. Except for the background material on weighted myriad smoothers in Chapter 2, this dissertation contains purely original work. The organization of this dissertation is as follows: Chapter 2 reviews the weighted myriad smoother, which is derived based on ff-stable distributions.
Reference: [40] <author> S. Kalluri and G. R. Arce, </author> <title> "Adaptive algorithms for weighted myriad filter optimization," </title> <booktitle> in Proc. of the 1997 IEEE ICASSP, </booktitle> <address> (Munich, Germany), </address> <year> 1997. </year>
Reference-contexts: with fast convergence, that are applicable to a wide variety of nonlinear filters. 7 The material presented in this dissertation is the compilation of three years of research work that has so far resulted in the publication or submission of four journal articles [33, 36, 37, 38], three conference articles <ref> [39, 40, 41] </ref> and one technical report [42]. Except for the background material on weighted myriad smoothers in Chapter 2, this dissertation contains purely original work. The organization of this dissertation is as follows: Chapter 2 reviews the weighted myriad smoother, which is derived based on ff-stable distributions. <p> myriad smoother, the outputs of all these filters can be computed efficiently using the algorithms of this chapter. 57 Chapter 5 OPTIMIZATION OF WEIGHTED MYRIAD SMOOTHERS In this chapter, necessary conditions are obtained for optimality of the parameters of the Weighted Myriad Smoother under the mean absolute error (MAE) criterion <ref> [33, 40] </ref>. Stochastic gradient-based adaptive algorithms are then derived for the optimization of the filter weights. Although we focus on the MAE optimization criterion, our solutions are applicable to the mean squared error (MSE) criterion with trivial modifications.
Reference: [41] <author> S. Kalluri and G. R. Arce, </author> <title> "A general class of nonlinear normalized LMS-type adaptive algorithms," </title> <booktitle> in Proc. of the 1998 CISS, </booktitle> <address> (Princeton, NJ), </address> <month> Mar. </month> <year> 1998. </year>
Reference-contexts: with fast convergence, that are applicable to a wide variety of nonlinear filters. 7 The material presented in this dissertation is the compilation of three years of research work that has so far resulted in the publication or submission of four journal articles [33, 36, 37, 38], three conference articles <ref> [39, 40, 41] </ref> and one technical report [42]. Except for the background material on weighted myriad smoothers in Chapter 2, this dissertation contains purely original work. The organization of this dissertation is as follows: Chapter 2 reviews the weighted myriad smoother, which is derived based on ff-stable distributions. <p> The design of the step-size is crucial to the performance of any adaptive algorithm since this parameter affects the stability, convergence speed and final mean square error (MSE) of the algorithm. In this chapter, we develop a class of so-called Normalized LMS-type algorithms <ref> [38, 41] </ref> which provide for an automatic step-size choice, possess superior convergence properties, and are applicable to a wide variety of nonlinear filters. <p> In this chapter, we generalize the NLMS algorithm of (7.2) by deriving a class of nonlinear Normalized LMS-type (NLMS-type) algorithms <ref> [41, 38] </ref> that are applicable to a wide variety of nonlinear filter structures. Consider now the case of an arbitrary nonlinear filter whose output is given by y y (w; x).
Reference: [42] <author> S. Kalluri and G. R. Arce, </author> <title> "Approximate weighted myriad computation by fixed point search," </title> <type> Tech. Rep. </type> <institution> 96-12-2, Department of Electrical Engineering, University of Delaware, </institution> <year> 1996. </year>
Reference-contexts: a wide variety of nonlinear filters. 7 The material presented in this dissertation is the compilation of three years of research work that has so far resulted in the publication or submission of four journal articles [33, 36, 37, 38], three conference articles [39, 40, 41] and one technical report <ref> [42] </ref>. Except for the background material on weighted myriad smoothers in Chapter 2, this dissertation contains purely original work. The organization of this dissertation is as follows: Chapter 2 reviews the weighted myriad smoother, which is derived based on ff-stable distributions. <p> We propose an iterative algorithm to compute these fixed points. We then develop fast algorithms, incorporating these fixed point iterations, for the computation of the weighted myriad <ref> [36, 42] </ref>. It is shown through a numerical example that these algorithms achieve a high degree of accuracy in approximating the weighted myriad, at a relatively low cost of computation.
Reference: [43] <author> G. R. Arce, </author> <title> "A general weighted median filter structure admitting real-valued weights," </title> <journal> IEEE Transactions on Signal Processing. </journal> <note> To appear. </note>
Reference-contexts: There is a need to extend this into a filter structure that is analogous to the unconstrained linear FIR filter with real-valued weights. Recently, the weighted median smoother has been successfully generalized to yield a weighted median filter structure that admits real-valued weights <ref> [43, 44] </ref>. In this chapter, we use a similar approach to extend the class of M -smoothers defined in Section 2.1, leading to the more general class of M -filters that allow for real-valued weights. <p> Following the above approach, the weighted median smoother was recently extended to a class of weighted median filters with real-valued weights <ref> [43] </ref>. Thus, referring to Table 2.1, and by analogy to (3.4), the output of a weighted median filter with weights fw i 2 Rg N i=1 was written in [43] as (w; x) = median (jw i j sgn (w i )x i )j N i=1 jw i j jsgn (w <p> Following the above approach, the weighted median smoother was recently extended to a class of weighted median filters with real-valued weights <ref> [43] </ref>. Thus, referring to Table 2.1, and by analogy to (3.4), the output of a weighted median filter with weights fw i 2 Rg N i=1 was written in [43] as (w; x) = median (jw i j sgn (w i )x i )j N i=1 jw i j jsgn (w i )x i j: (3.5) However, it was subsequently found in [44] that a more general definition of the weighted median filter was possible. <p> This special case is derived by analogy with the weighted mean filter of (3.4) and the special weighted median filter of (3.5), proposed in <ref> [43] </ref>.
Reference: [44] <author> J. L. Paredes and G. R. Arce, </author> <title> "Stack filters, stack smoothers, and mirrored threshold decomposition," </title> <journal> IEEE Transactions on Signal Processing. </journal> <note> Manuscript in review. </note>
Reference-contexts: There is a need to extend this into a filter structure that is analogous to the unconstrained linear FIR filter with real-valued weights. Recently, the weighted median smoother has been successfully generalized to yield a weighted median filter structure that admits real-valued weights <ref> [43, 44] </ref>. In this chapter, we use a similar approach to extend the class of M -smoothers defined in Section 2.1, leading to the more general class of M -filters that allow for real-valued weights. <p> output of a weighted median filter with weights fw i 2 Rg N i=1 was written in [43] as (w; x) = median (jw i j sgn (w i )x i )j N i=1 jw i j jsgn (w i )x i j: (3.5) However, it was subsequently found in <ref> [44] </ref> that a more general definition of the weighted median filter was possible. Notice in (3.5) that if a particular weight w i is negative, the corresponding modified sample is sgn (w i )x i = x i , which is the mirror sample of x i . <p> Thus, since h i 0, we have the equivalence h i x i = jh i j sgn (h i )x i = jh i j (x i ). This concept of double weighting emerges naturally in <ref> [44] </ref> through the analysis of the so-called stack filters with real-valued weights (weighted median filters are a special case of stack filters). Thus, given the sets of weights fw i 0g N i=1 and fh i 0g N i=1 , the weighted median filter output [44] is defined as = median <p> double weighting emerges naturally in <ref> [44] </ref> through the analysis of the so-called stack filters with real-valued weights (weighted median filters are a special case of stack filters). Thus, given the sets of weights fw i 0g N i=1 and fh i 0g N i=1 , the weighted median filter output [44] is defined as = median (w i x i ; jh i j (x i ))j N i=1 = median (hw i ; h i i x i )j N where the notation hw i ; h i i reflects the double weight assigned to the sample x i . <p> This conversion into a single weight, due to the superposition property of linear filters, does not occur for the weighted median filter <ref> [44] </ref>, and cannot be expected for the more general class of M -filters to be developed in the following. Using the aforementioned ideas, the extension of the general class of M - smoothers to allow for real-valued weights can be achieved in a straightforward manner as follows.
Reference: [45] <author> D. G. Luenberger, </author> <title> Optimization by Vector Space Methods. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1969. </year>
Reference-contexts: We propose the following fixed point iteration algorithm to compute these fixed points: m+1 = T ( m ) = i=1 N X h i ( m ) In the classical literature, this is also called the method of successive approximation for the solution of the equation = T () <ref> [45] </ref>. <p> This does not guarantee that Q ( m+1 ) Q ( m ); however, it is shown in Section 4.2.2 that (4.19) does in fact decrease Q () at each iteration. We can contrast the recursion of (4.17) with the update in Newton's method <ref> [45] </ref> for the solution of the equation Q 0 () = 0: 0 4 Q 0 ( m ) ; (4.20) which is interpreted by considering the tangent of Q 0 () at = m : Z () 4 Q 0 ( m ) + Q 00 ( m ) ( <p> at which the tangent Z () crosses the axis: Q 0 ( 0 m+1 ) Z ( 0 Although Newton's method can have fast (quadratic) convergence, the major disadvantage of this method is that it may converge only if the initial value 0 is sufficiently close to the solution fl <ref> [45] </ref>. Thus, only local convergence is guaranteed.
Reference: [46] <author> B. T. Smith et al., </author> <title> Matrix Eigensystem Routines | EISPACK Guide, </title> <booktitle> vol. 6 of Lecture Notes in Computer Science. </booktitle> <address> New York: </address> <publisher> Springer-Verlag, </publisher> <year> 1976. </year>
Reference-contexts: The complexity of the exact algorithm is typically dominated by the term -(2N 1) involving root finding; for example, the EISPACK routines <ref> [46] </ref> 48 Table 4.1: Complexities of weighted myriad algorithms (window size N , L fixed point iterations); -(m) is the complexity in finding the roots of a polynomial of degree m, and varies with the particular polynomial root finding method used.
Reference: [47] <author> M. Lang and B. Frenzel, </author> <title> "Polynomial root finding," </title> <journal> IEEE Signal Processing Letters, </journal> <volume> vol. 1, </volume> <month> Oct. </month> <year> 1994. </year>
Reference-contexts: The exact computation of the weighted myriad requires finding the roots of the derivative, P 0 (), of the polynomial objective function P () (see Proposition 4.1). These roots are found using the polynomial root finding (PRF) method described in <ref> [47] </ref>, which is apparently superior in speed and accuracy to the best previously-known root finding methods. <p> For our example, as the figure shows, Q () has 4 local minima and 3 local maxima, and the input samples range from the smallest x (1) = 0:13 to the largest x (N) = 0:99. The 4 local minima, computed using the polynomial root finding (PRF) method of <ref> [47] </ref>, are at 0:17, 0:27, 0:38 and 0:93, with the exact weighted myriad being ^ PRF = 0:93. <p> The same weight vector was used 52 to filter the input signal with several values of K, varying from K = 0:05 to K = 1:0 in steps of 0:05. Three algorithms were used for the filtering: the exact computation algorithm using polynomial root finding <ref> [47] </ref>, Algorithm I, and Algorithm II. The fixed point search algorithms I and II were implemented for iterations ranging from L = 0 to L = 5. All the computations were performed in C on a Sun Ultra2 Enterprise workstation (SUN4U/170 Ultra-2/1170).
Reference: [48] <author> T. A. C. M. Claasen and W. F. G. Mecklenbrauker, </author> <title> "Comparison of the convergence of two algorithms for adaptive FIR digital filters," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. ASSP-29, </volume> <month> June </month> <year> 1981. </year>
Reference-contexts: a very simple update that is computationally comparable to 67 the update in the LMS algorithm or its variant, the LMAD (least mean absolute deviation) algorithm (also called the sign algorithm (SA)), which is written as w i (n+ 1) = w i (n) sgn (e (n)) x i (n) <ref> [48] </ref>. In our simulations, the simplified algorithm of (5.37) converged significantly faster than the algorithm of (5.34). <p> For the linear filter, the following least mean absolute deviation (LMAD) algorithm, also called the sign algorithm (SA) <ref> [48] </ref>, was used: w i (n+1) = w i (n)sgn (e (n))x i (n); i = 1; 2; : : : ; N; where we use the notation of Section 5.5. The adaptation of the weighted median smoother utilized an adaptive weighted order statistic (WOS) algorithm from [20].
Reference: [49] <author> M. Rupp, </author> <title> "The behavior of LMS and NLMS algorithms in the presence of spherically invariant processes," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 41, </volume> <pages> pp. 1149-1160, </pages> <month> Mar. </month> <year> 1993. </year>
Reference-contexts: This allows for an easier step-size design with 103 guaranteed stability (convergence) of the algorithm. Further, the NLMS algorithm has a potentially faster convergence than the LMS algorithm <ref> [49] </ref>. The NLMS algorithm can also be alternatively interpreted as a modification of the LMS algorithm of (7.1), where the update term is divided (normalized) by the squared-norm kx (n)k 2 so that the update stays bounded even when the input vector x (n) becomes large in magnitude.
Reference: [50] <author> M. Schetzen, </author> <title> The Volterra and Wiener Theories of Nonlinear Systems. </title> <address> New York: </address> <publisher> Wiley, </publisher> <year> 1980. </year> <month> 145 </month>
Reference-contexts: Included in this class are linear filters, Ll filters based on order statistics [17, 18], permutation filters (which are generalizations of both linear and order statistic filters) [15], and Volterra filters <ref> [50] </ref>, among others.
Reference: [51] <author> T. Koh and E. J. </author> <title> Powers, "Second-order Volterra filtering and its application to nonlinear system identification," </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> vol. ASSP-33, </volume> <pages> pp. 1445-1455, </pages> <month> Dec. </month> <year> 1985. </year>
Reference-contexts: Consider now the special case of the Volterra filter, which has found wide-spread use in nonlinear signal processing <ref> [51, 52] </ref>.
Reference: [52] <author> V. J. Mathews, </author> <title> "Adaptive polynomial filters," </title> <journal> Signal Processing Magazine, </journal> <volume> vol. 8, </volume> <pages> pp. 10-26, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: Consider now the special case of the Volterra filter, which has found wide-spread use in nonlinear signal processing <ref> [51, 52] </ref>.
Reference: [53] <author> C. B. Papadias and D. T. M. Slock, </author> <title> "Normalized sliding window constant modulus and decision-directed algorithms: A link between blind equalization and classical adaptive filtering," </title> <journal> IEEE Transactions on Signal Processing, </journal> <volume> vol. 45, </volume> <pages> pp. 231-235, </pages> <month> Jan. </month> <year> 1997. </year> <month> 146 </month>
Reference-contexts: In the context of the so-called constant modulus algorithms for blind linear equalization, methods have been developed by which any classical (linear) adaptive filtering algorithm can be transformed into a corresponding blind algorithm <ref> [53] </ref>.
References-found: 53

