URL: ftp://ftp.cs.caltech.edu/tr/cs-tr-97-18.ps.Z
Refering-URL: ftp://ftp.cs.caltech.edu/tr/INDEX.html
Root-URL: http://www.cs.caltech.edu
Title: Compiler Techniques for Loosely-Coupled Multi-Cluster Architectures  
Author: Bryan Chow 
Degree: In Partial Fulfillment of the Requirements for the Degree of Master of Science  
Date: June 17, 1996  
Address: Pasadena, California 91125  
Affiliation: Scalable Concurrent Programming Laboratory California Institute of Technology  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. Adam, K. M. Chandy and J. R. Dickson, </author> <title> A comparison of list schedules for parallel processing systems, </title> <journal> CACM, </journal> <month> 17:12 </month> <year> (1974), </year> <pages> 685-690. </pages>
Reference-contexts: List scheduling works well when the communication cost is zero, as in most VLIW machines. Graham [9] showed that in such cases any list scheduler will be within 50% of optimum, and Adam, Chandy and Dickson <ref> [1] </ref> showed experimentally that the critical path list scheduling heuristic is within 5% of the optimum 90% of the time. However, when the communication cost is nonzero, the performance of list scheduling degrades significantly. List scheduling is a one-stage method.
Reference: [2] <author> Aho, Alfred V., Jeffery D. Ullman, </author> <title> Principles of Compiler Design Addison-Wesley Publishing Company, </title> <address> Reading, Mass., </address> <year> 1977. </year>
Reference: [3] <author> S.T. Barnard and H.D. Simon, </author> <title> A Fast Multilevel Implementation of Recursive Spectral Bisection for Partitioning Unstructured Problems, </title> <booktitle> Proc. Sixth SIAM Conf. on Parallel Processing for Scientific Computing, </booktitle> <publisher> SIAM, </publisher> <year> 1993. </year>
Reference: [4] <author> Gary R. Beck, David W. L. Yen and Thomas L. Anderson, </author> <title> The Cydra 5 Minisupercom-puter: </title> <booktitle> Architecture and Implementation The Journal of Supercomputing, </booktitle> <year> 1993. </year>
Reference-contexts: These operations execute in parallel and in lock-step. It is the responsibility of the compiler to ensure that there are no dependencies between operations. There have been a number of commercial VLIW implementations [15] <ref> [4] </ref>. Unfortunately, the classic VLIW approach has its disadvantages. The increasing disparity between clock cycle and memory latency limits the performance of VLIW, since each time a single functional unit stalls, the whole machine stalls.
Reference: [5] <author> Robert P. Colwell, Robert P. Nix, John J. O'Donnell, David B. Papworth and Paul K. Rod-man. </author> <title> A VLIW Architecture for a Trace Scheduling Compiler IEEE Transactions on Computers, </title> <type> 37-8, </type> <month> August </month> <year> 1988. </year>
Reference: [6] <author> William Dally J., Stephen W. Keckler, Nick Carter, Andrew Chang, Marco Fillo, and Whay S. Lee, </author> <booktitle> M-Machine Architecture v1.0 Massachusetts Institute of Technology, Artificial Intelligence Laboratory Concurrent VLSI Architecture Memo, </booktitle> <volume> Number 58, </volume> <month> January </month> <year> 1994. </year>
Reference-contexts: This exercise has isolated some of the central issues and allowed an analysis to a preliminary implementation of multi-cluster scheduling. It has also resulted in changes to the architectural design. 10 CHAPTER 1. INTRODUCTION Chapter 2 Compiler Philosophy 2.1 M-Machine Architecture The M-Machine <ref> [6] </ref> is a massively parallel computer being designed at the Massachusetts Institute of Technology. It consists of a collection of nodes connected by a 3-D mesh network.
Reference: [7] <author> John R. Ellis, Bulldog: </author> <title> A Compiler for VLIW Architectures MIT Press, </title> <year> 1986. </year>
Reference: [8] <author> Joseph A. Fisher, </author> <title> Trace scheduling: A technique for global microcode compaction IEEE Transactions on Computers, </title> <address> C-30(8):478-490, </address> <month> July </month> <year> 1981. </year>
Reference-contexts: The traces are then scheduled onto functional units by the list scheduler, which receives information on the target architecture from the machine model and generates code. The disambiguator performs memory-reference analysis. 2.4 Trace Scheduling Trace scheduling <ref> [8] </ref> is an algorithm that allows instruction scheduling beyond basic blocks, so that more operations can be considered for scheduling and hence provide a greater amount of parallelism. It allows loops, conditional expressions, and straight stretches of code to be handled in a consistent and uniform manner.
Reference: [9] <author> R. L. Graham, </author> <title> Bounds for certain multiprocessing anomalies, </title> <journal> Bell System Technical Journal, </journal> <volume> 45 (1966), </volume> <pages> 1563-1581. </pages>
Reference-contexts: Another reason is that the list scheduler, which is responsible for scheduling operations onto clusters, was not designed for large discrepancies in the latencies between different functional units. List scheduling works well when the communication cost is zero, as in most VLIW machines. Graham <ref> [9] </ref> showed that in such cases any list scheduler will be within 50% of optimum, and Adam, Chandy and Dickson [1] showed experimentally that the critical path list scheduling heuristic is within 5% of the optimum 90% of the time.
Reference: [10] <author> M. Gumpta and P. Banerjee, </author> <title> Demonstration of automatic data partitioning techniques for parallelizing compilers on multicomputers. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 179-193, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Yang [22, 23, 24], SarkarSARKAR89, and Kim and Brown [13] have conducted extensive research on the partitioning of computational graphs. The work on automatic parallelization, optimizations, interprocedural analysis, and partitioning techniques for parallelizing compilers by Lam [14], Hall [11], Gupta <ref> [10] </ref> and others are relevant when compiling for loosely-coupled clusters.
Reference: [11] <author> M. W. Hall, B. R. Murphy, and S. P. Amarasinghe, </author> <title> Interprocedural parallelization analysis: A case study. </title> <booktitle> Proceedings of the Seventh SIAM Conference on Parallel Processing for Scientific Computing, </booktitle> <address> San Francisco, </address> <month> Feb </month> <year> 1995. </year> <note> 43 44 BIBLIOGRAPHY </note>
Reference-contexts: However, many research topics are relevant to compiling for loosely-coupled clusters. Yang [22, 23, 24], SarkarSARKAR89, and Kim and Brown [13] have conducted extensive research on the partitioning of computational graphs. The work on automatic parallelization, optimizations, interprocedural analysis, and partitioning techniques for parallelizing compilers by Lam [14], Hall <ref> [11] </ref>, Gupta [10] and others are relevant when compiling for loosely-coupled clusters.
Reference: [12] <author> Hudak, David E. </author> <title> Compiling parallel loops for high performance computers: partitioning, data assignment, </title> <booktitle> and remapping The Kluwer international series in engineering and computer science, </booktitle> <year> 1993. </year>
Reference: [13] <author> Kim, S. J. and Browne, J. C. </author> <title> A general approaach to mapping of parallel computation upon multiprocessor architectures, </title> <booktitle> International Conference on Parallel Processing, </booktitle> <volume> vol 3, </volume> <year> 1988, </year> <pages> pp. 1-8. </pages>
Reference-contexts: A good partition is one which results in a low execution time. There are many DAG partitioning algorithms in the literature, such as Sarkar's [18] algorithm and Kim and Browne's linear clustering algorithm <ref> [13] </ref>. The algorithm is based on Yang and Gerasoulis' Dominant Sequence Clustering (DSC) algorithm [24] for unbounded number of processors. The DSC algorithm combines the best features of several algorithms, and typically gets better partitions than Sarkar's or Kim and Browne's algorithms, and also run in less time. <p> However, many research topics are relevant to compiling for loosely-coupled clusters. Yang [22, 23, 24], SarkarSARKAR89, and Kim and Brown <ref> [13] </ref> have conducted extensive research on the partitioning of computational graphs. The work on automatic parallelization, optimizations, interprocedural analysis, and partitioning techniques for parallelizing compilers by Lam [14], Hall [11], Gupta [10] and others are relevant when compiling for loosely-coupled clusters.
Reference: [14] <author> J.Anderson and M. Lam. </author> <title> Global optimizations for parallelism and locality on scalable parallel machines., </title> <booktitle> Proceedings of the SIGPLAN '93 Conference on Programming Language Design and Implementation, </booktitle> <address> Albuquerque, NM, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: However, many research topics are relevant to compiling for loosely-coupled clusters. Yang [22, 23, 24], SarkarSARKAR89, and Kim and Brown [13] have conducted extensive research on the partitioning of computational graphs. The work on automatic parallelization, optimizations, interprocedural analysis, and partitioning techniques for parallelizing compilers by Lam <ref> [14] </ref>, Hall [11], Gupta [10] and others are relevant when compiling for loosely-coupled clusters.
Reference: [15] <author> P. G. Lowney, S. G. Freudenberger, T. J. Karzes, W. D. Lichtenstein, R. P. Nix, J. S. O'Donnell and J. C. Ruttenberg. </author> <title> The Multiflow Trace Scheduling Compiler The Journal of Supercomputing, </title> <year> 1993. </year>
Reference-contexts: These operations execute in parallel and in lock-step. It is the responsibility of the compiler to ensure that there are no dependencies between operations. There have been a number of commercial VLIW implementations <ref> [15] </ref> [4]. Unfortunately, the classic VLIW approach has its disadvantages. The increasing disparity between clock cycle and memory latency limits the performance of VLIW, since each time a single functional unit stalls, the whole machine stalls. <p> We can pack many loosely coupled functional units on a chip and hide latency better than other methods such as VLIW. 2.3 Multiflow Trace Scheduling Compiler The compiler used for the M-Machine is the Multiflow Trace Scheduling Compiler <ref> [15] </ref>, which was designed to exploit instruction-level parallelism for traditional VLIW architectures. tran source code and converts it into a high-level intermediate representation called IL-1. Traditional code optimizations such as loop unrolling, constant folding and common subex-pression elimination are applied to this intermediate representation. <p> done by making a copy of the instructions that will be executed if the side entrance is taken, and moving the side entrance to join at a later point in the schedule as shown in the figure. 2.5 Differences between the M-Machine and TRACE VLIW Computer The Multiflow TRACE computers <ref> [15] </ref>, for which the compiler was originally designed, all share a common set of features. The differences between the M-Machine and TRACE that are signif 2.5. DIFFERENCES BETWEEN THE M-MACHINE AND TRACE VLIW COMPUTER 15 16 CHAPTER 2.
Reference: [16] <author> D. Maskit and S. Taylor. </author> <title> A Message-Driven Programming System for Fine-Grain Multi-computers. </title> <journal> Software: Practice and Experience, </journal> <volume> 24(10) </volume> <pages> 953-980, </pages> <year> 1994. </year>
Reference: [17] <author> S. Keckler, </author> <title> A Coupled Multi-ALU Processing Node for a Highly Parallel Computer Massachusetts Institute of Technology, </title> <type> Artificial Intelligence Technical Report 1355, </type> <month> September </month> <year> 1992. </year>
Reference-contexts: Introduction 1.1 Motivation Recent advances in semiconductor technology have made it possible to have multiple execution units reside on a single chip <ref> [17] </ref>. These multiple execution units can be used to execute individual machine operations in parallel (instruction-level parallelism). However, it is an open question as to how to best organize the units in order to exploit instruction-level parallelism. <p> INTRODUCTION all functional units execute in lockstep. B) A loosely-coupled architecture with an instruction pointer for each cluster. 1.2 Compilation Issues for Loosely-Coupled Clusters Keckler <ref> [17] </ref> has shown that loosely-coupled clusters provide better latency hiding and functional unit utilization than a classic VLIW architecture, especially when memory latencies can be variable. <p> This algorithm is currently not implemented in the compiler and details are currently under investigation. 40 CHAPTER 5. PROPOSED MULTI-CLUSTER SCHEDULING ALGORITHM Chapter 6 Conclusion 6.1 Summary Loosely-coupled clusters have been shown to have the potential to exploit instruction-level parallelism while maintining high function unit utilization <ref> [17] </ref>. A compiler that generates code for loosely-coupled clusters has been implemented on top of the Multiflow Trace Scheduling Compiler. The performance of this compiler has been evaluated by compiling and executing benchmarking programs on the M-Machine simulator.
Reference: [18] <author> Sarkar, Vivek. </author> <title> Partitioning and Scheduling Parallel Programs for Multiprocessors, </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: For example, a memory load instruction requires a few integer operation to set the address, followed by a memory operation. A good partition is one which results in a low execution time. There are many DAG partitioning algorithms in the literature, such as Sarkar's <ref> [18] </ref> algorithm and Kim and Browne's linear clustering algorithm [13]. The algorithm is based on Yang and Gerasoulis' Dominant Sequence Clustering (DSC) algorithm [24] for unbounded number of processors.
Reference: [19] <author> R. Van Driessche and D. Roose. </author> <title> An Improved Spectral Bisection Algorithm and Its Application to Dynamic Load Balancing. </title> <journal> Parallel Computing, </journal> <volume> 21 </volume> <pages> 29-48, </pages> <year> 1995. </year>
Reference: [20] <author> R. Williams. </author> <title> Performance of Dynamic Load balancing Algorithms for Unstructured Mesh Calculations. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 3 </volume> <pages> 457-481, </pages> <year> 1991. </year>
Reference: [21] <author> Wolfe, Michael Joseph. </author> <title> High Performance Compilers for Parallel Computing, </title> <publisher> Addison-Wesley, </publisher> <year> 1995. </year>
Reference: [22] <author> T. Yang and A. Gerasoulis, </author> <title> List scheduling with and without communication delays, </title> <institution> Rut-gers University, Department of Computer Science, </institution> <year> 1992. </year>
Reference-contexts: This is straightforward, but has not yet been added to the compiler. 6.3 Related Work Loose coupling is a new architecture, and there have not been any available implementations of it: the M-Machine will be the first. However, many research topics are relevant to compiling for loosely-coupled clusters. Yang <ref> [22, 23, 24] </ref>, SarkarSARKAR89, and Kim and Brown [13] have conducted extensive research on the partitioning of computational graphs. The work on automatic parallelization, optimizations, interprocedural analysis, and partitioning techniques for parallelizing compilers by Lam [14], Hall [11], Gupta [10] and others are relevant when compiling for loosely-coupled clusters.
Reference: [23] <author> T. Yang and A. Gerasoulis, </author> <title> PYRROS: Static scheduling and code generation for message passing multiprocessors, </title> <booktitle> Proc. of 6th ACM International Conference on Supercomputing, </booktitle> <address> Washington D.C., </address> <month> July </month> <year> 1992, </year> <pages> pp. 428-437 </pages>
Reference-contexts: We also define the priority of a node as tlevel (n) + blevel (n). The algorithm is given in Figure5.3. The above algorithm assumes an unbounded number of processors. Yang also described a simple but effective cluster merging algorithm which was implemented in the PYRROS <ref> [23] </ref> par 1 The Multiflow compiler is more general and keeps track of operations using resource request lists. <p> This is straightforward, but has not yet been added to the compiler. 6.3 Related Work Loose coupling is a new architecture, and there have not been any available implementations of it: the M-Machine will be the first. However, many research topics are relevant to compiling for loosely-coupled clusters. Yang <ref> [22, 23, 24] </ref>, SarkarSARKAR89, and Kim and Brown [13] have conducted extensive research on the partitioning of computational graphs. The work on automatic parallelization, optimizations, interprocedural analysis, and partitioning techniques for parallelizing compilers by Lam [14], Hall [11], Gupta [10] and others are relevant when compiling for loosely-coupled clusters.
Reference: [24] <author> Tao Yang and Apostolos Gerasoulis, </author> <title> DSC: Scheduling parallel tasks on an unbounded number of processors, </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> Vol. 5, No. 9, </volume> <pages> 951-967, </pages> <year> 1994. </year>
Reference-contexts: A good partition is one which results in a low execution time. There are many DAG partitioning algorithms in the literature, such as Sarkar's [18] algorithm and Kim and Browne's linear clustering algorithm [13]. The algorithm is based on Yang and Gerasoulis' Dominant Sequence Clustering (DSC) algorithm <ref> [24] </ref> for unbounded number of processors. The DSC algorithm combines the best features of several algorithms, and typically gets better partitions than Sarkar's or Kim and Browne's algorithms, and also run in less time. <p> In the DSC algorithm, the DS is identified at each step and the nodes along the DS are placed in the same cluster. An outline of the DSC algorithm is given below. A more detailed description of the algorithm can be found in <ref> [24] </ref>. A DAG is defined by G = (V, E, C, T) where V is the set of nodes, E is the set of edges, C is the set of communication costs (in cycles), and T is the set of node costs. <p> This is straightforward, but has not yet been added to the compiler. 6.3 Related Work Loose coupling is a new architecture, and there have not been any available implementations of it: the M-Machine will be the first. However, many research topics are relevant to compiling for loosely-coupled clusters. Yang <ref> [22, 23, 24] </ref>, SarkarSARKAR89, and Kim and Brown [13] have conducted extensive research on the partitioning of computational graphs. The work on automatic parallelization, optimizations, interprocedural analysis, and partitioning techniques for parallelizing compilers by Lam [14], Hall [11], Gupta [10] and others are relevant when compiling for loosely-coupled clusters.
References-found: 24

