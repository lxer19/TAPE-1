URL: http://ai.eecs.umich.edu/people/jmvidal/papers/icmas98/icmas98l.ps
Refering-URL: http://ai.eecs.umich.edu/people/jmvidal/jmvidal.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: jmvidal@umich.edu  
Title: The Moving Target Function Problem in Multi-Agent Learning  
Author: Jose M. Vidal and Edmund H. Durfee 
Address: 1101 Beal Avenue, Ann Arbor, MI 48109-2110  
Affiliation: Artificial Intelligence Laboratory, University of Michigan  
Note: Proceedings of the Third International Conference on Multi-Agent Systems, 1998. Paris, France.  
Abstract: We describe a framework that can be used to model and predict the behavior of MASs with learning agents. It uses a difference equation for calculating the progression of an agent's error in its decision function, thereby telling us how the agent is expected to fare in the MAS. The equation relies on parameters which capture the agents' learning abilities (such as its change rate, learning rate and retention rate) as well as relevant aspects of the MAS (such as the impact that agents have on each other). We validate the framework with experimental results using reinforcement learning agents in a market system, as well as by other experimental results gathered from the AI literature. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Claus and C. Boutilier. </author> <title> The dynamics of reinforcement learning in cooperative multiagent systems. </title> <booktitle> In Pro 7 ceedings of Workshop on Multiagent Learning. </booktitle> <publisher> AAAI Press, </publisher> <year> 1997. </year> <note> http://www.cs.ubc.ca/spider/cebly/ Papers/multirl.ps. </note>
Reference-contexts: (a) Experiment PSfrag replacements ff j = :1 ff j = :9 l j = :04 time error (b) Theory PSfrag replacements l i final error CLRI theory S&T's experiment (a) Original Experiment PSfrag replacements l i final error CLRI theory S&T's experiment (b) Theory and Experiment Claus and Boutelier <ref> [1] </ref>, and believe that we can do the same for some of the experiments in Sen et. al. [5], and Ishida [4] (see http://ai.eecs.umich. edu/people/jmvidal/papers/icmas98l.ps for details on how these reproductions were achieved). 10. Summary We have presented a framework for studying the behavior of MASs composed of learning agents.
Reference: [2] <author> P. R. Cohen, A. Cheyer, M. Wang, and C. S. Baeg. </author> <title> An open agent architecture. </title> <booktitle> In Proceedings of the AAAI Spring Symposium on Software Agents, </booktitle> <pages> pages 18. </pages> <publisher> AAAI, </publisher> <year> 1994. </year>
Reference-contexts: 1. Introduction The analysis of multi-agent systems (MASs) composed of learning agents is an important problem because of the steady increase in the number of open MASs <ref> [2] </ref> [3] which allow for the use of learning agents. Up to now, most of the research in this area has consisted of experiments where multitudes of learning agents are placed in a MAS, then different learning/game parameters are varied, and the results are gathered and analyzed.
Reference: [3] <author> E. H. Durfee, D. L. Kiskis, and W. P. </author> <title> Birmingham. The agent architecture of the University of Michigan Digital Library. </title> <booktitle> IEE Proceedings on Software Engineering, </booktitle> <volume> 144(1):61 71, </volume> <year> 1997. </year>
Reference-contexts: 1. Introduction The analysis of multi-agent systems (MASs) composed of learning agents is an important problem because of the steady increase in the number of open MASs [2] <ref> [3] </ref> which allow for the use of learning agents. Up to now, most of the research in this area has consisted of experiments where multitudes of learning agents are placed in a MAS, then different learning/game parameters are varied, and the results are gathered and analyzed.
Reference: [4] <author> T. Ishida. </author> <title> Real-Time Search for Learnnig Autonomous Agents. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1997. </year>
Reference-contexts: replacements l i final error CLRI theory S&T's experiment (a) Original Experiment PSfrag replacements l i final error CLRI theory S&T's experiment (b) Theory and Experiment Claus and Boutelier [1], and believe that we can do the same for some of the experiments in Sen et. al. [5], and Ishida <ref> [4] </ref> (see http://ai.eecs.umich. edu/people/jmvidal/papers/icmas98l.ps for details on how these reproductions were achieved). 10. Summary We have presented a framework for studying the behavior of MASs composed of learning agents. We believe that this framework captures the most important parameters that describe the agents' learning and the system's rules of encounter.
Reference: [5] <author> S. Sen, M. Sekaran, and J. Hale. </author> <title> Learning to coordinate without sharing information. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <year> 1994. </year>
Reference-contexts: (b) Theory PSfrag replacements l i final error CLRI theory S&T's experiment (a) Original Experiment PSfrag replacements l i final error CLRI theory S&T's experiment (b) Theory and Experiment Claus and Boutelier [1], and believe that we can do the same for some of the experiments in Sen et. al. <ref> [5] </ref>, and Ishida [4] (see http://ai.eecs.umich. edu/people/jmvidal/papers/icmas98l.ps for details on how these reproductions were achieved). 10. Summary We have presented a framework for studying the behavior of MASs composed of learning agents.
Reference: [6] <author> Y. Shoham and M. Tennenholtz. </author> <title> On the emergence of social conventions: modeling, analysis, and simulations. </title> <journal> Artificial Intelligence, </journal> <volume> 94(1):139166, </volume> <year> 1997. </year>
Reference-contexts: Application to Results from the Literature We have also used our theory to reproduce experimental results from the literature. For example, Figure 5 (a) shows experimental results from Shoham and Tennenholtz <ref> [6] </ref>. They show how the percentage of agents reaching a convention decreases as the delay between applications of the learning algorithm increases.

References-found: 6

