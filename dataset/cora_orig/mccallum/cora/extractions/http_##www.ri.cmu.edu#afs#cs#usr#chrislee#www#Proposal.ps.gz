URL: http://www.ri.cmu.edu/afs/cs/usr/chrislee/www/Proposal.ps.gz
Refering-URL: http://www.ri.cmu.edu/afs/cs/usr/chrislee/www/research.html
Root-URL: 
Title: Transferring Human Skills to Robots via Task Demonstrations in Virtual Environments  
Author: Christopher Lee Pradeep Khosla, Karun Shimoga (CMU), Rajeev Sharma 
Degree: Thesis Proposal  Committee: Yangsheng Xu (advisor),  
Date: June 4, 1997  
Affiliation: Robotics PhD Program Carnegie Mellon University  (Penn State)  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> Proceedings of 1993 IEEE/RSJ International Conference on Intelligent Robots and Systems, </institution> <address> Yokohama, Japan, </address> <month> July </month> <year> 1993. </year> <note> IEEE. </note>
Reference: [2] <institution> Proceedings of IEEE Virtual Reality Annual International Symposium. IEEE, </institution> <month> September </month> <year> 1993. </year>
Reference: [3] <institution> Proceedings of the 1994 IEEE International Conference on Robotics and Automation. IEEE, </institution> <month> May </month> <year> 1994. </year>
Reference: [4] <institution> Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE Computer Society Press, </institution> <month> September </month> <year> 1994. </year>
Reference: [5] <institution> Proceedings of the 1995 IEEE International Conference on Robotics and Automation. IEEE, </institution> <month> May </month> <year> 1995. </year>
Reference: [6] <institution> Proceedings of the 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE Computer Society Press, </institution> <month> August </month> <year> 1995. </year>
Reference: [7] <institution> Proceedings of IEEE Virtual Reality Annual International Symposium. IEEE, </institution> <year> 1996. </year>
Reference: [8] <institution> Proceedings of the 1996 IEEE International Conference on Robotics and Automation. IEEE, </institution> <month> April </month> <year> 1996. </year>
Reference: [9] <author> H. Abelson et al. </author> <title> Revised 4 report on the algorithmic language Scheme. </title> <booktitle> ACM Lisp Pointers IV, </booktitle> <volume> 4(3), </volume> <month> July-September </month> <year> 1991. </year>
Reference-contexts: To solve this problem, we have built a portable, extendible library which implements a virtual machine called the "Robot Scheme Kernel" (RSK). RSK provides a set of virtual machine instructions and library functions which can be used for implementing the Scheme programming language <ref> [9] </ref>, but uses an approach to memory management based on reference-counting which avoids most of the problems of using a garbage-collected language in a real-time system [26].
Reference: [10] <author> F. Arai, M. Tanimoto, T. Fukuda, K. Shimojima, H. Matsuura, and M. Ne goro. </author> <title> Distributed virtual environment for intravascular tele-surgery using multimedia telecommunication. </title> <booktitle> In Proceedings of IEEE Virtual Reality Annual International Symposium [7], </booktitle> <pages> pages 79-85, 267. </pages>
Reference-contexts: Shimoga [81, 82] analyzes requirements for force feedback and touch feedback in haptic interfaces, and surveys current systems in terms of these requirements. Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are <ref> [35, 21, 20, 76, 25, 10] </ref>. The work of Hirzinger's group is extended in [16] to include development of skills for force control using the PHANToM force feedback device to interact with a virtual environment.
Reference: [11] <author> C. Archibald and E. Petriu. </author> <title> Skills-oriented robot programming. </title> <editor> In F.C.A. Groen, S. Hirose, and C.E. Thorpe, editors, </editor> <booktitle> Proceedings of the International Conference on Intelligent Autonomous Systems IAS-3, </booktitle> <pages> pages 104-15, </pages> <address> Pittsburgh, PA, 1993. </address> <publisher> IOS Press. </publisher> <address> 41 42 BIBLIOGRAPHY </address>
Reference-contexts: use the terms "sensory-motor primitives", "prim-itive operations", "elementary operations", "basic operations", and "human control strategy." Sussman [85] is an early work on computer problem solving which uses the word "skill" to mean "the unwritten knowledge derived from practice which ties the written knowledge together, making it usable." Archibald and Petriu <ref> [11] </ref> describe the "Skills-Oriented Robot Programming" concept (SKORP) for simple composition of task-based programs on the factory floor from pre-developed robot skills. Deno et al. [24] present a method for formulation of control primitives for robot systems in terms of a dynamical systems based description language.
Reference: [12] <author> H. Asada and S. Liu. </author> <title> Transfer of human skills to neural net robot con trollers. </title> <booktitle> In Proceedings. 1991 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 3, </volume> <pages> pages 2442-8. </pages> <publisher> IEEE Comput. Soc. Press, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: Schmajuk [79] discusses how animal behavior and learning may be used as a model for development of systems for robotic task performance based on neural networks. Asada and Liu <ref> [12, 60] </ref> present results of transferring human skills to a robot for a deburring task. They use a neural network, trained from human performance data, to perform online adaptation of the stiffness coefficient of a conventional controller for deburring. <p> The skill transfer literature related to preprocessing of training data focusses primarily on evaluation and filtering of human performance data, and some work has also been done on selection of input signals from a high-dimensional set of training data. Asada and Liu <ref> [12] </ref> propose eliminating inconsistencies in human performance by using Lipschitz's condition as a smoothness criterion. Kaiser et al. [44] identify several kinds of intrinsic non-optimalities of human performance data, and build task-independent measures of performance quality based upon this analysis.
Reference: [13] <author> David Baraff. </author> <title> Interactive simulation of solid rigid bodies. </title> <journal> IEEE Computer Graphics and Applications, </journal> <volume> 15(3) </volume> <pages> 63-75, </pages> <year> 1995. </year>
Reference-contexts: Kinematics for things such as the hand of the human in the virtual environment will be calculated by the graphics engine of the computer used for the simulation. Dynamics for the simulation will either be written by hand or calculated by a preexisting package such as Coriolis, by Baraff <ref> [13] </ref>. 2.1.2 Interaction The performer interacts with the simulation via sensory feedback devices and input devices. These interaction devices must sufficiently immerse the performer in the virtual environment that skilled performance of simulated tasks becomes as natural as possible.
Reference: [14] <author> C. Baroglio, A. Giordana, M. Kaiser, N. Nuttin, and R. Piola. </author> <title> Learning controllers for industrial robots. </title> <booktitle> Machine Learning, </booktitle> <address> 23(2-3):221-49, </address> <month> May-June </month> <year> 1996. </year>
Reference-contexts: In [40], Kaiser discusses the use of time-delay neural networks for control of robots, and Giordana et al. [31] compare the use of time delay neural networks verses adaptive fuzzy controllers for generating nonlinear controllers from human demonstration data. Baroglio et al. <ref> [14] </ref> extends this work by comparing the use of radial basis function neural networks and fuzzy controllers for human to robot skill transfer and reinforcement learning. In [28], Friedrich et al. present a system for learning robot programs through classification of human teleoperation data. <p> Online adaptation is especially necessary for controllers trained for input to output mappings between raw sensor and actuator domains, where differences in environmental and robot parameters can greatly effect the quality of skill performance. This kind of skill refinement is used by Giordana and Baroglio et al. <ref> [31, 14] </ref>. Kaiser and Dillmann [43] use reinforcement-learning method of Gullapalli et al. [34] for refinement of skills for peg-in-hole insertion and opening a door. Asada and Lui's work [60] uses a model-based skill refinement strategy for improving the performance of their deburring skill.
Reference: [15] <author> C.M. Bishop. </author> <title> Neural Networks for Pattern Recognition. </title> <publisher> Oxford University Press, </publisher> <address> New York, </address> <year> 1995. </year>
Reference-contexts: Train intelligent controller as a mapping between the lower-dimensional representations of the inputs and outputs. Use the controller to perform control within the lower-dimensional task representation. 22 CHAPTER 2. BUILDING SKILLS pings using a multi-layer perceptron which can compute a non-linear principal component analysis <ref> [53, 15] </ref>. 2.4.2 Training an intelligent controller Training the intelligent controller itself is not the focus of the proposed research. Instead, we will use and compare methods resulting from previous and current research in training intelligent controllers, such as the work of Nechyba [70, 69].
Reference: [16] <author> B. Brunner, K. Arbter, G. Hirzinger, and R. Koeppe. </author> <title> Programming robots via learning by showing in a virtual environment. In Virtual Reality World '95, </title> <publisher> Stuttgart, </publisher> <month> February </month> <year> 1995. </year>
Reference-contexts: Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are [35, 21, 20, 76, 25, 10]. The work of Hirzinger's group is extended in <ref> [16] </ref> to include development of skills for force control using the PHANToM force feedback device to interact with a virtual environment. Koeppe and Hirzinger [48] apply this approach to teaching compliant motions for use in assembly operations.
Reference: [17] <author> M. Buss and H. Hashimoto. </author> <title> Information and power flow during skill ac quisition for the intelligent assisting system-IAS. </title> <booktitle> In Proceedings of 1993 IEEE/RSJ International Conference on Intelligent Robots and Systems [1], </booktitle> <pages> pages 25-32. </pages>
Reference-contexts: This result is extended in [50] to involve a "task-oriented virtual tool", and in [49] to allow for scaled telemanipulation. The "Intelligent Assisting System" described by Buss and Hashimoto <ref> [17] </ref> is an interactive manipulation aid for assisting a human in haptic teleopera-tion.
Reference: [18] <author> M. Buss and H. Hashimoto. </author> <title> Hand manipulation skill learning for the in telligent cooperative manipulation system. </title> <booktitle> In Proceedings of International Conference on Intelligent Autonomous Systems, </booktitle> <pages> pages 279-86, </pages> <address> Karlsruhe, Germany, </address> <month> March </month> <year> 1995. </year>
Reference-contexts: They demonstrate multi-finger haptic interaction with a simulated environment [54, 55], and develop a system for learning dextrous human skills using a record of hand trajectory and a human-to-robot grasp mapping function [19], and a neural-network <ref> [18] </ref>. 2 1.3.7 Comparison with previous work Although the proposed research is related to a large amount of previous work, it is different in important ways.
Reference: [19] <author> Martin Buss and Hideki Hashimoto. </author> <title> Hand manipulation skill modeling for the intelligent cooperative manipulation system-icms. </title> <booktitle> In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems [4], </booktitle> <pages> pages 1234-41. </pages>
Reference-contexts: They demonstrate multi-finger haptic interaction with a simulated environment [54, 55], and develop a system for learning dextrous human skills using a record of hand trajectory and a human-to-robot grasp mapping function <ref> [19] </ref>, and a neural-network [18]. 2 1.3.7 Comparison with previous work Although the proposed research is related to a large amount of previous work, it is different in important ways.
Reference: [20] <editor> J.E. Colgate, M.A. Peshkin, and W. Wannasuphoprasit. Nonholonomic haptic display. </editor> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 539-44. </pages>
Reference-contexts: Shimoga [81, 82] analyzes requirements for force feedback and touch feedback in haptic interfaces, and surveys current systems in terms of these requirements. Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are <ref> [35, 21, 20, 76, 25, 10] </ref>. The work of Hirzinger's group is extended in [16] to include development of skills for force control using the PHANToM force feedback device to interact with a virtual environment.
Reference: [21] <author> J.E. Colgate, M.C. Stanley, and J.M. Brown. </author> <title> Issues in the haptic display of tool use. </title> <booktitle> In Proceedings of the 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems [6], </booktitle> <pages> pages 140-5. </pages>
Reference-contexts: Shimoga [81, 82] analyzes requirements for force feedback and touch feedback in haptic interfaces, and surveys current systems in terms of these requirements. Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are <ref> [35, 21, 20, 76, 25, 10] </ref>. The work of Hirzinger's group is extended in [16] to include development of skills for force control using the PHANToM force feedback device to interact with a virtual environment.
Reference: [22] <author> N. Delson and H. West. </author> <title> Robot programming by human demonstra tion: Subtask compliance controller identification. </title> <booktitle> In Proceedings of 1993 IEEE/RSJ International Conference on Intelligent Robots and Systems [1], </booktitle> <pages> pages 33-41. </pages>
Reference-contexts: In <ref> [22, 23] </ref>, Delson and West describe a version of programming by human demonstration where a human demonstrates skills using an end-effector similar to that which the robot will use.
Reference: [23] <author> N. Delson and H. West. </author> <title> Robot programming by human demonstration: adaptation and inconsistancy in constrained motion. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 30-36. BIBLIOGRAPHY 43 </pages>
Reference-contexts: In <ref> [22, 23] </ref>, Delson and West describe a version of programming by human demonstration where a human demonstrates skills using an end-effector similar to that which the robot will use.
Reference: [24] <author> D.C. Deno, R.M. Murray, K.S.J. Pister, and S.S. Sastry. </author> <title> Control primitives for robot systems. </title> <booktitle> In Proceedings 1990 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 3, </volume> <pages> pages 1866-71, </pages> <address> Cincinnati, OH, USA, May 1990. </address> <publisher> IEEE Comput. Soc. Press. </publisher>
Reference-contexts: Deno et al. <ref> [24] </ref> present a method for formulation of control primitives for robot systems in terms of a dynamical systems based description language. In [61], McCarragher describes the process of assembly as a discrete event system based on contact-based task-primitives.
Reference: [25] <author> Lionel Fabini, Grigore Burdea, and Daniel Gomez. </author> <title> Human interface using the Rutgers Master II force feedback interface. </title> <booktitle> In Proceedings of IEEE Virtual Reality Annual International Symposium [7], </booktitle> <pages> pages 54-59. </pages>
Reference-contexts: Shimoga [81, 82] analyzes requirements for force feedback and touch feedback in haptic interfaces, and surveys current systems in terms of these requirements. Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are <ref> [35, 21, 20, 76, 25, 10] </ref>. The work of Hirzinger's group is extended in [16] to include development of skills for force control using the PHANToM force feedback device to interact with a virtual environment.
Reference: [26] <author> Daniel Friedman and David Wise. </author> <title> Reference counting can manage the circular invironments of mutual recursion. </title> <journal> Information Processing Letters, </journal> <volume> 8(1) </volume> <pages> 41-45, </pages> <month> Janary </month> <year> 1979. </year>
Reference-contexts: RSK provides a set of virtual machine instructions and library functions which can be used for implementing the Scheme programming language [9], but uses an approach to memory management based on reference-counting which avoids most of the problems of using a garbage-collected language in a real-time system <ref> [26] </ref>. RSK uses messages both for communication with other subsystems within the robot such as the continuous subsystem of the proposed task-execution framework, and for flow-control via an approach we call "Message-Based Evaluation" (MBE).
Reference: [27] <author> H. Friedrich and M. Kaiser. </author> <title> What can robots learn from humans? In IFAC Workshop on Human-Oriented Design of Advanced Robotic Systems, </title> <year> 1995. </year>
Reference-contexts: One of their main points is that the robot's control system architecture should be designed from the ground up with learning capabilities in mind (in contrast to traditional, hierarchical architectures). In <ref> [46, 27] </ref>, Friedrich and Kaiser outline an interactive framework for training robot controllers from human demonstration data.
Reference: [28] <author> H. Friedrich, S. Munch, R. Dillmann, S. Bocionek, and M. Sassin. </author> <title> Robot programming by demonstration (RPD): supporting the induction by human interaction. </title> <booktitle> Machine Learning, </booktitle> <address> 23(2-3):163-89, </address> <month> May-June </month> <year> 1996. </year>
Reference-contexts: Baroglio et al. [14] extends this work by comparing the use of radial basis function neural networks and fuzzy controllers for human to robot skill transfer and reinforcement learning. In <ref> [28] </ref>, Friedrich et al. present a system for learning robot programs through classification of human teleoperation data. Human performance is segmented and classified into "Basic Operations" (BOs), which are recognized using Time Delay Neural Networks. Sequences of BOs can 1.3. EXISTING WORK 5 then be optimized and generalized.
Reference: [29] <author> O. Fuentes and R.C. Nelson. </author> <title> Learning dextrous manipulation skills using multisensory information. </title> <booktitle> In 1996 IEEE/SICE RSJ International Conference on Multisensor Fusion and Integration for Intelligent Systems, </booktitle> <pages> pages 342-8, </pages> <address> Washington, DC, USA, </address> <month> December </month> <year> 1996. </year> <note> IEEE. </note>
Reference-contexts: Reinforcement learning is used to train a robot to perform an open loop throwing motion, and a simple simulation of the throwing task is used to reduce the number of actual throws performed by the robot during its training. In <ref> [29, 30] </ref>, Fuentes and Nelson use a virtual tool model to reduce the dimensionality of the search space used for learning dextrous manipulation skills using a Utah/MIT hand. They use an associative memory algorithm for reinforcement learning of the dextrous skill.
Reference: [30] <author> O. Fuentes and R.C. Nelson. </author> <title> The virtual tool approach to dextrous tele manipulation. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 1700-5. </pages>
Reference-contexts: Reinforcement learning is used to train a robot to perform an open loop throwing motion, and a simple simulation of the throwing task is used to reduce the number of actual throws performed by the robot during its training. In <ref> [29, 30] </ref>, Fuentes and Nelson use a virtual tool model to reduce the dimensionality of the search space used for learning dextrous manipulation skills using a Utah/MIT hand. They use an associative memory algorithm for reinforcement learning of the dextrous skill.
Reference: [31] <author> A. Giordana, M. Kaiser, and M. Nuttin. </author> <title> On the reduction of costs for robot controller synthesis. </title> <booktitle> In International Symposium on Intelligent Robotic Systems (IRS '94), </booktitle> <address> Grenoble, France, </address> <year> 1994. </year>
Reference-contexts: They also demonstrate human-to-human skill transfer using the neural network as an intermediary teacher. In [40], Kaiser discusses the use of time-delay neural networks for control of robots, and Giordana et al. <ref> [31] </ref> compare the use of time delay neural networks verses adaptive fuzzy controllers for generating nonlinear controllers from human demonstration data. Baroglio et al. [14] extends this work by comparing the use of radial basis function neural networks and fuzzy controllers for human to robot skill transfer and reinforcement learning. <p> Online adaptation is especially necessary for controllers trained for input to output mappings between raw sensor and actuator domains, where differences in environmental and robot parameters can greatly effect the quality of skill performance. This kind of skill refinement is used by Giordana and Baroglio et al. <ref> [31, 14] </ref>. Kaiser and Dillmann [43] use reinforcement-learning method of Gullapalli et al. [34] for refinement of skills for peg-in-hole insertion and opening a door. Asada and Lui's work [60] uses a model-based skill refinement strategy for improving the performance of their deburring skill.
Reference: [32] <author> G. Grudic and P. Lawrence. </author> <title> Human-to-robot skill transfer using the SPORE approximation. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 2962-7. </pages>
Reference-contexts: Inconsistency of human performance in Cartesian and force domains over multiple demonstrations is used to generate compliance specifications for subtasks within a task. Grudic and Lawrence, in <ref> [32, 33] </ref>, propose a framework for programming robot tasks through teleoperation. They specify that humans demonstrate task performance through teleoperation using the same information as feedback that will be available to the robot for its performance.
Reference: [33] <author> G.Z. Grudic and P.D. Lawrence. </author> <title> Human-to-robot skill transfer via tele operation. </title> <booktitle> In 1995 IEEE International Conference on Systems, Man and Cybernetics, </booktitle> <volume> volume 3, </volume> <pages> pages 2109-14. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1995. </year>
Reference-contexts: Inconsistency of human performance in Cartesian and force domains over multiple demonstrations is used to generate compliance specifications for subtasks within a task. Grudic and Lawrence, in <ref> [32, 33] </ref>, propose a framework for programming robot tasks through teleoperation. They specify that humans demonstrate task performance through teleoperation using the same information as feedback that will be available to the robot for its performance.
Reference: [34] <author> V. Gullapalli, J.A. Franklin, and H. Benbrahim. </author> <title> Acquiring robot skills via reinforcement learning. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 14(1) </volume> <pages> 13-24, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: INTRODUCTION means. Examples of reinforcement learning for building robot skills include the work of Gullapalli et al., Schneider and Gans, and Fuentes and Nelson. Gullapalli et al. <ref> [34] </ref> use a direct associative reinforcement learning (i.e. not based on a process model) method, based on a multi-layer neural network trained by a stochastic real-valued learning algorithm, to learn and perform peg-in-hole and ball balancing tasks. Their implementations are specific to the current robot and its environment. <p> This kind of skill refinement is used by Giordana and Baroglio et al. [31, 14]. Kaiser and Dillmann [43] use reinforcement-learning method of Gullapalli et al. <ref> [34] </ref> for refinement of skills for peg-in-hole insertion and opening a door. Asada and Lui's work [60] uses a model-based skill refinement strategy for improving the performance of their deburring skill.
Reference: [35] <author> V. Hayward. </author> <title> Toward a seven axis haptic device. </title> <booktitle> In Proceedings of the 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems [6], </booktitle> <pages> pages 133-9. 44 BIBLIOGRAPHY </pages>
Reference-contexts: Shimoga [81, 82] analyzes requirements for force feedback and touch feedback in haptic interfaces, and surveys current systems in terms of these requirements. Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are <ref> [35, 21, 20, 76, 25, 10] </ref>. The work of Hirzinger's group is extended in [16] to include development of skills for force control using the PHANToM force feedback device to interact with a virtual environment.
Reference: [36] <author> S. Hirai, H. Noguchi, and K. Iwata. </author> <title> Human-demonstration based ap proach to the recognition of process state transitions in insertion of de-formable tubes. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 2006-11. </pages>
Reference-contexts: Some work related to this includes the analysis of qualitative state transitions in deformable tube insertion in Hirai et al. <ref> [36] </ref>, and the failure detection method of Narendra [67]. Work is also being done by Hovland and McCarragher on using HMMs as a process monitor.
Reference: [37] <author> Gerd Hirzinger, Bernhard Brunner, Johannes Dietrich, and Johan Heindl. </author> <title> Sensor-based space robotics-ROTEX and its telerobotic features. </title> <journal> IEEE Transactions on robotics and automation, </journal> <volume> 9(5) </volume> <pages> 649-63, </pages> <month> October </month> <year> 1993. </year>
Reference-contexts: A symbolic task-level representation of the demonstrated task is generated by their system, and transferred to a robot which then executes the task, re-planning steps where necessary. In the ROTEX experiment, Hirzinger et al. <ref> [37] </ref> demonstrated task-level programming in a virtual environment for teleoperation of a robot system on the space shuttle Columbia. Human teleoperators specified robot operations in a virtual environment simulation of the robot workplace.
Reference: [38] <author> G. Hovland, P. Sikka, and B.J. McCarragher. </author> <title> Skill aquisition from human demonstration using a hidden Markov model. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 2706-11. </pages>
Reference-contexts: Xu and Yang [86, 87] show how to train an HMM using human performance data to find a "most likely" performance for a given task, and demonstrate their approach by training the space robot (SM) 2 to perform an ORU replacement task. Hovland et al. <ref> [38] </ref> present a HMM-based approach to transferring human assembly skills to robots whereby an assembly skill is represented by a hybrid dynamic system where a discrete event controller models the skill at the task level.
Reference: [39] <author> I.T. Jollife. </author> <title> Principal Component Analysis. </title> <publisher> Springer Verlag, </publisher> <address> New York, </address> <year> 1986. </year>
Reference-contexts: Mapping the inputs and outputs to lower-dimensional spaces extracts the important features of the low-level skill. We will investigate the use of at least two methods for this feature extraction: the Karhunen-Loeve transformation (principal component analysis) <ref> [39] </ref>, and auto-associative neural-network map 2.4. BUILDING THE LOW-LEVEL SKILL MAPPING 21 Train input-to-input mapping through lower-dimensional subspace. Train output-to-output mapping through lower-dimensional subspace. Train intelligent controller as a mapping between the lower-dimensional representations of the inputs and outputs.
Reference: [40] <author> M. Kaiser. </author> <title> Time-delay neural networks for control. </title> <booktitle> In Proceedings of IFAC Symposium on Robot Control 1994, </booktitle> <volume> volume 2, </volume> <pages> pages 851-6, </pages> <address> Oxford, UK, 1995. </address> <publisher> Elsevier Science. </publisher>
Reference-contexts: In [70, 69], Nechyba and Xu use a cascade correlation neural network architecture, trained by node-decoupled extended Kalman filtering, to learn skill mappings from human performance data. They also demonstrate human-to-human skill transfer using the neural network as an intermediary teacher. In <ref> [40] </ref>, Kaiser discusses the use of time-delay neural networks for control of robots, and Giordana et al. [31] compare the use of time delay neural networks verses adaptive fuzzy controllers for generating nonlinear controllers from human demonstration data.
Reference: [41] <author> M. Kaiser, L. Camarinha-Matos, A. Giordana, V. Klingspor, J. del R. Millan, M. Nuttin, and R. </author> <title> Suarez. Robot learning|three case studies in robotics and machine learning. </title> <booktitle> In Proceedings of the IVAR '94, </booktitle> <address> Leuven, Belgium, </address> <year> 1994. </year>
Reference-contexts: Fuzzy logic control, reinforcement learning, and table-look-up with local interpolation are other common methods. 4 CHAPTER 1. INTRODUCTION Frameworks for skill acquisition Some papers on the overall process of skill acquisition from human demonstration has been written by Dillmann's group at the University of Karlsruhe. <ref> [41] </ref> is a large, useful summary of work in learning for robotic applications, with discussions of the use of learning for compliant motion, machining, and navigation.
Reference: [42] <author> M. Kaiser and R. Dillmann. </author> <title> Hierarchical learning of efficient skill appli cation for autonomous robots. </title> <booktitle> In International Symposium on Intelligent Robotics Systems, </booktitle> <address> Pisa, Italy, </address> <year> 1995. </year>
Reference-contexts: In [46, 27], Friedrich and Kaiser outline an interactive framework for training robot controllers from human demonstration data. This is a proposed extension of their previous work on task-level skill transfer to include learning of low-level skills (as "elementary operations") and the conditions for their use within task execution. <ref> [42] </ref> shows how this can be used to discretize continuous perception and action spaces of a robot so that higher-level systems can plan actions within a reduced planning space.
Reference: [43] <author> M. Kaiser and R. Dillmann. </author> <title> Building elementary robot skills from human demonstration. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 2700-5. </pages>
Reference-contexts: This kind of skill refinement is used by Giordana and Baroglio et al. [31, 14]. Kaiser and Dillmann <ref> [43] </ref> use reinforcement-learning method of Gullapalli et al. [34] for refinement of skills for peg-in-hole insertion and opening a door. Asada and Lui's work [60] uses a model-based skill refinement strategy for improving the performance of their deburring skill.
Reference: [44] <author> M. Kaiser, H. Friedrich, and R. Dillmann. </author> <title> Obtaining good performance from a bad teacher. </title> <booktitle> In International Conference on Machine Learning, Workshop on Programming by Demonstration, </booktitle> <address> Tahoe City, California, </address> <year> 1995. </year>
Reference-contexts: Asada and Liu [12] propose eliminating inconsistencies in human performance by using Lipschitz's condition as a smoothness criterion. Kaiser et al. <ref> [44] </ref> identify several kinds of intrinsic non-optimalities of human performance data, and build task-independent measures of performance quality based upon this analysis. They use preprocessing to eliminate some performance non-optimalities before training, and use reinforcement learning for performance tuning after training to deal with other kinds of non-optimalities. <p> Other kinds of intrinsic features which we might want to take into account for rating a performance include unnecessary motions, unnecessary actions, and unmotivated actions <ref> [44] </ref>.
Reference: [45] <author> M. Kaiser, R. Buckingham H. Friedrich, K. Khodabandehloo, and S. Tom linson. </author> <title> Towards a general measure of skill for learning robots. </title> <booktitle> In ICML-96 Workshop on Learning Robots, </booktitle> <address> Bari, Italy, </address> <year> 1996. </year>
Reference-contexts: In [71], Nechyba and Xu demonstrate the use of an HMM-based model determining similarities of task performances, which may be used for validating the consistency between a trained controller's performances and the task demonstration data of its human teacher. Kaiser et al. <ref> [45] </ref> contrast the concept of skilled robots from the normal concept of robots which carry out complex skilled tasks.
Reference: [46] <author> M. Kaiser, U. Rembold, and R. Dillmann. </author> <title> A framework for the generation of robot controllers from examples. </title> <booktitle> In Proceedings of IFAC International Conference on CAD/CAM: Robotics and Factories of the Future, </booktitle> <pages> pages 818-23, </pages> <address> Kanata, Ont., Canada, 1994. </address> <publisher> OCRI Publications. BIBLIOGRAPHY 45 </publisher>
Reference-contexts: One of their main points is that the robot's control system architecture should be designed from the ground up with learning capabilities in mind (in contrast to traditional, hierarchical architectures). In <ref> [46, 27] </ref>, Friedrich and Kaiser outline an interactive framework for training robot controllers from human demonstration data.
Reference: [47] <author> M. Kaiser, A. Retey, and R. Dillmann. </author> <title> Designing neural networks for adaptive control. </title> <booktitle> In Proceedings of 1995 34th IEEE Conference on Decision and Control, </booktitle> <volume> volume 2, </volume> <pages> pages 1833-9, </pages> <address> New Orleans, LA, </address> <month> December </month> <year> 1995. </year> <note> IEEE. </note>
Reference-contexts: Human performance is segmented and classified into "Basic Operations" (BOs), which are recognized using Time Delay Neural Networks. Sequences of BOs can 1.3. EXISTING WORK 5 then be optimized and generalized. In <ref> [47] </ref>, Kaiser et al. give general conclusions and recommendations for designing neural networks for adaptive control. Based on the kind of task, availability of a priori knowledge, task representation, and environment, they recommend an architecture and adaptation strategy.
Reference: [48] <author> R. Koeppe and G. Hirzinger. </author> <title> Learning compliant motions by task demonstration in virtual environments. </title> <booktitle> In Fourth International Symposium on Experimental Robotics, ISER'95, Lecture notes in control and information sciences, </booktitle> <address> Stanford, CA, June-July 1995. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: The work of Hirzinger's group is extended in [16] to include development of skills for force control using the PHANToM force feedback device to interact with a virtual environment. Koeppe and Hirzinger <ref> [48] </ref> apply this approach to teaching compliant motions for use in assembly operations. In this work, they use neural networks pre-structured to represent fuzzy rule-based knowledge to learn compliant motions from human task demonstrations in a simulated environment.
Reference: [49] <author> K. Kosuge, T. Itoh, T. Fukuda, and M. Otsuka. </author> <title> Scaled telemanipulation system using semi-autonomous task-oriented virtual tool. </title> <booktitle> In Proceedings of the 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems [6], </booktitle> <pages> pages 124-9. </pages>
Reference-contexts: Dynamics of the haptic interface and the slave robot are compensated for so that the human's skill performance feels like direct performance of the task in the real world. This result is extended in [50] to involve a "task-oriented virtual tool", and in <ref> [49] </ref> to allow for scaled telemanipulation. The "Intelligent Assisting System" described by Buss and Hashimoto [17] is an interactive manipulation aid for assisting a human in haptic teleopera-tion.
Reference: [50] <author> K. Kosuge, T. Itoh, T. Fukuda, and M. Otsuka. </author> <title> Tele-manipulation sys tem based on task-oriented virtual tool. </title> <booktitle> In Proceedings of the 1995 IEEE International Conference on Robotics and Automation [5], </booktitle> <pages> pages 351-6. </pages>
Reference-contexts: Their algorithm is used to find 12 input sensors for use in training the neural network model, selected from a set of hundreds of available sensor signals. In Kosuge et al. <ref> [50] </ref>, the "task-oriented virtual tool" concept is used to reduce the dimension of training data for a dextrous manipulation skill by focussing on a low-dimensional tool-based performance representation rather than a high-dimensional hand-based representation. 1.3.6 Virtual reality Task-level demonstration Several groups have started to work on skill transfer using virtual environments <p> Dynamics of the haptic interface and the slave robot are compensated for so that the human's skill performance feels like direct performance of the task in the real world. This result is extended in <ref> [50] </ref> to involve a "task-oriented virtual tool", and in [49] to allow for scaled telemanipulation. The "Intelligent Assisting System" described by Buss and Hashimoto [17] is an interactive manipulation aid for assisting a human in haptic teleopera-tion.
Reference: [51] <author> K. Kosuge, K. Takeo, and T. Fukuda. </author> <title> Unified approach for teleoperation of virtual and real environment-manipulation based on reference dynamics. </title> <booktitle> In Proceedings of the 1995 IEEE International Conference on Robotics and Automation [5], </booktitle> <pages> pages 938-43. </pages>
Reference-contexts: Both visual and haptic feedback are provided to the human during task demonstration, and a only single demonstration was used for teaching, but transfer of the skill to the robot system was not performed. Kosuge et al. <ref> [52, 51] </ref> propose a teleoperation scheme in which the operator interacts with a simulation of the remote environment through a haptic interface, a manipulation skill is extracted, and then sent to a remote manipulator for execution.
Reference: [52] <author> K. Kosuge, K. Takeo, T. Fukuda, T. Sugiura, A. Sakai, and K. Yamada. </author> <title> Unified approach for teleoperation of virtual and real environment for skill based teleoperation. </title> <booktitle> In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems [4], </booktitle> <pages> pages 1242-7. </pages>
Reference-contexts: Both visual and haptic feedback are provided to the human during task demonstration, and a only single demonstration was used for teaching, but transfer of the skill to the robot system was not performed. Kosuge et al. <ref> [52, 51] </ref> propose a teleoperation scheme in which the operator interacts with a simulation of the remote environment through a haptic interface, a manipulation skill is extracted, and then sent to a remote manipulator for execution.
Reference: [53] <author> M.A. Kramer. </author> <title> Nonlinear principal component analysis using autoassocia tive neural networks. </title> <journal> AIChe Journal, </journal> <volume> 37(2) </volume> <pages> 233-243, </pages> <year> 1991. </year>
Reference-contexts: Train intelligent controller as a mapping between the lower-dimensional representations of the inputs and outputs. Use the controller to perform control within the lower-dimensional task representation. 22 CHAPTER 2. BUILDING SKILLS pings using a multi-layer perceptron which can compute a non-linear principal component analysis <ref> [53, 15] </ref>. 2.4.2 Training an intelligent controller Training the intelligent controller itself is not the focus of the proposed research. Instead, we will use and compare methods resulting from previous and current research in training intelligent controllers, such as the work of Nechyba [70, 69].
Reference: [54] <author> Y. Kunii and H. Hashimoto. </author> <title> Dynamic force simulator for multifinger force display. </title> <journal> IEEE Transactions on Industrial Electronics, </journal> <volume> 34(1) </volume> <pages> 74-80, </pages> <month> Febru-ary </month> <year> 1996. </year>
Reference-contexts: The "Intelligent Assisting System" described by Buss and Hashimoto [17] is an interactive manipulation aid for assisting a human in haptic teleopera-tion. They demonstrate multi-finger haptic interaction with a simulated environment <ref> [54, 55] </ref>, and develop a system for learning dextrous human skills using a record of hand trajectory and a human-to-robot grasp mapping function [19], and a neural-network [18]. 2 1.3.7 Comparison with previous work Although the proposed research is related to a large amount of previous work, it is different in
Reference: [55] <author> Y. Kunii and H. Hashimoto. </author> <title> Virtual environment for haptic interface in robotic network system. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 545-9. </pages>
Reference-contexts: The "Intelligent Assisting System" described by Buss and Hashimoto [17] is an interactive manipulation aid for assisting a human in haptic teleopera-tion. They demonstrate multi-finger haptic interaction with a simulated environment <ref> [54, 55] </ref>, and develop a system for learning dextrous human skills using a record of hand trajectory and a human-to-robot grasp mapping function [19], and a neural-network [18]. 2 1.3.7 Comparison with previous work Although the proposed research is related to a large amount of previous work, it is different in
Reference: [56] <author> Christopher Lee and Yangsheng Xu. </author> <title> (DM) 2 : A modular solution for robotic lunar missions. </title> <journal> International Journal of Space Technology, </journal> <volume> 16(1) </volume> <pages> 49-58, </pages> <year> 1996. </year>
Reference-contexts: The basic robot control infrastructure for controlling (SM) 2 is built upon the work done for (DM) 2 <ref> [56] </ref>, where the high-level control code is replaced by Chilli. This system has undergone initial testing, and will be enhanced with modules for implementing the low-level control system of the proposed task-execution framework. 5.2 Planned research Table 5.1 outlines the current completion status of the proposed work.
Reference: [57] <author> Sukhan Lee and J. Chen. </author> <title> Skill learning from observations. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Robotics and Automation [3], </booktitle> <pages> pages 3245-50. 46 BIBLIOGRAPHY </pages>
Reference-contexts: Skill acquisition by other methods Several groups of researchers have used or developed strategies for transferring human skills to robots using methods other than neural-networks. Sukhan Lee and Chen <ref> [57] </ref> propose viewing skills as a set of feasible state transitions, and representing skills as regions in an "augmented state space," which is a space of current and next states during control.
Reference: [58] <author> Sukhan Lee and Judy Chen. </author> <title> Robot skill discovery based on observed data. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 2694-9. </pages>
Reference-contexts: By labelling regions of the augmented state space through performing globally competitive clustering and locally cooperative interpolation of data from human task performances, they form a rule-based skill representation which may be used for task-planning as well as skill execution. <ref> [58] </ref> extends this work by providing a planning algorithm for use with generated skill representations, and demonstrates its use for non-holonomic motion planning and skill-learning through robot teleoperation.
Reference: [59] <author> Sukhan Lee and Shunichi Shimoji. </author> <title> Machine acquisition of skills by neural networks. </title> <booktitle> In International Joint Conference on Neural Networks, </booktitle> <volume> volume 2, </volume> <pages> pages 781-8. </pages> <publisher> IEEE, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: Asada and Liu [12, 60] present results of transferring human skills to a robot for a deburring task. They use a neural network, trained from human performance data, to perform online adaptation of the stiffness coefficient of a conventional controller for deburring. Sukhan Lee and Shimoji <ref> [59] </ref> propose a neural network architecture called the Hierarchically Self-Organizing Learning Network, for learning skill mappings for robots. Pomerleau [77] transferred human road following skills to an automated driving system using a single hidden-layer neural network which mapped coarsely sampled video images to steering outputs.
Reference: [60] <author> S. Liu and H. Asada. </author> <title> Teaching and learning of deburring robots using neural networks. </title> <booktitle> In Proceedings of 1993 IEEE/RSJ International Conference on Intelligent Robots and Systems [1], </booktitle> <pages> pages 339-45. </pages>
Reference-contexts: Schmajuk [79] discusses how animal behavior and learning may be used as a model for development of systems for robotic task performance based on neural networks. Asada and Liu <ref> [12, 60] </ref> present results of transferring human skills to a robot for a deburring task. They use a neural network, trained from human performance data, to perform online adaptation of the stiffness coefficient of a conventional controller for deburring. <p> This kind of skill refinement is used by Giordana and Baroglio et al. [31, 14]. Kaiser and Dillmann [43] use reinforcement-learning method of Gullapalli et al. [34] for refinement of skills for peg-in-hole insertion and opening a door. Asada and Lui's work <ref> [60] </ref> uses a model-based skill refinement strategy for improving the performance of their deburring skill.
Reference: [61] <author> B.J. McCarragher. </author> <title> Task primitives for the discrete event modeling and control of 6-DOF assembly tasks. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 12(2) </volume> <pages> 280-9, </pages> <month> April </month> <year> 1996. </year>
Reference-contexts: Deno et al. [24] present a method for formulation of control primitives for robot systems in terms of a dynamical systems based description language. In <ref> [61] </ref>, McCarragher describes the process of assembly as a discrete event system based on contact-based task-primitives.
Reference: [62] <author> T.W. III Miller, R.S. Sutton, and P.J. Werbos, </author> <title> editors. Neural networks for control. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1990. </year>
Reference-contexts: The use of artificial neural networks is one of the most prevalent methods for robot control and skill acquisition <ref> [68, 62, 78] </ref>. Fuzzy logic control, reinforcement learning, and table-look-up with local interpolation are other common methods. 4 CHAPTER 1.
Reference: [63] <author> P.A. Millman, M. Stanley, and J.E. Colgate. </author> <title> Design of a high performance haptic interface to virtual environments. </title> <booktitle> In Proceedings of IEEE Virtual Reality Annual International Symposium [2], </booktitle> <pages> pages 216-22. </pages>
Reference: [64] <author> J. Daniel Morrow. </author> <title> Sensorimotor primitives for programming robotic as sembly skills. </title> <type> PhD thesis, </type> <institution> Robotics Institute, Carnegie Mellon University, </institution> <year> 1997. </year>
Reference-contexts: In [61], McCarragher describes the process of assembly as a discrete event system based on contact-based task-primitives. Dan Morrow [66, 65] describes "sensorimotor" primitives which can be combined to perform robot tasks, and in his thesis <ref> [64] </ref> describes how an interactive CAD environment can be used to automatically generate a finite state machine description of tasks composed from a library of these primitives. 1.3.2 Skill acquisition Work on skill acquisition for robots falls largely within the field of intelligent control, which builds control ability by learning from
Reference: [65] <author> J.D. Morrow and P.K. Khosla. </author> <title> Sensorimotor primitives for robotic assem bly skills. </title> <booktitle> In Proceedings of the 1995 IEEE International Conference on Robotics and Automation [5], </booktitle> <pages> pages 1894-9. </pages>
Reference-contexts: Deno et al. [24] present a method for formulation of control primitives for robot systems in terms of a dynamical systems based description language. In [61], McCarragher describes the process of assembly as a discrete event system based on contact-based task-primitives. Dan Morrow <ref> [66, 65] </ref> describes "sensorimotor" primitives which can be combined to perform robot tasks, and in his thesis [64] describes how an interactive CAD environment can be used to automatically generate a finite state machine description of tasks composed from a library of these primitives. 1.3.2 Skill acquisition Work on skill acquisition
Reference: [66] <author> J.D. Morrow, B.J. Nelson, and P.K. Khosla. </author> <title> Vision and force driven sen sorimotor primitives for robotic assembly skills. </title> <booktitle> In Proceedings of the 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems [6], </booktitle> <pages> pages 234-40. </pages>
Reference-contexts: Deno et al. [24] present a method for formulation of control primitives for robot systems in terms of a dynamical systems based description language. In [61], McCarragher describes the process of assembly as a discrete event system based on contact-based task-primitives. Dan Morrow <ref> [66, 65] </ref> describes "sensorimotor" primitives which can be combined to perform robot tasks, and in his thesis [64] describes how an interactive CAD environment can be used to automatically generate a finite state machine description of tasks composed from a library of these primitives. 1.3.2 Skill acquisition Work on skill acquisition
Reference: [67] <author> K.S. Narendra and S. Mukhopadhyay. </author> <title> Intelligent control using neural net works. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 12(2) </volume> <pages> 11-18, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: Some work related to this includes the analysis of qualitative state transitions in deformable tube insertion in Hirai et al. [36], and the failure detection method of Narendra <ref> [67] </ref>. Work is also being done by Hovland and McCarragher on using HMMs as a process monitor.
Reference: [68] <author> Kumpati S. Narendra. </author> <title> Neural networks for control theory and practice. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 84(10) </volume> <pages> 1385-406, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The use of artificial neural networks is one of the most prevalent methods for robot control and skill acquisition <ref> [68, 62, 78] </ref>. Fuzzy logic control, reinforcement learning, and table-look-up with local interpolation are other common methods. 4 CHAPTER 1.
Reference: [69] <author> M. Nechyba and Y. Xu. </author> <title> Cascade neural networks with node-decoupled extended kalman filtering. </title> <booktitle> In Proc. IEEE Int. Symp. on Computational Intelligence in Robotics and Automation, </booktitle> <address> Monterey, CA, </address> <month> July </month> <year> 1997. </year> <note> to be published. </note>
Reference-contexts: Pomerleau [77] transferred human road following skills to an automated driving system using a single hidden-layer neural network which mapped coarsely sampled video images to steering outputs. In <ref> [70, 69] </ref>, Nechyba and Xu use a cascade correlation neural network architecture, trained by node-decoupled extended Kalman filtering, to learn skill mappings from human performance data. They also demonstrate human-to-human skill transfer using the neural network as an intermediary teacher. <p> Instead, we will use and compare methods resulting from previous and current research in training intelligent controllers, such as the work of Nechyba <ref> [70, 69] </ref>. Because task-skills will be broken into sets of individual low-level skills, we expect that training each low-level skill will be less demanding than for other methods of skill learning, and that a number of training methods will thus be acceptable for our use. <p> RESEARCH PLAN 5.1.3 Training neural networks The intelligent controller technology used so far in this work is a neural network. The first practical results are from training networks using the error backpropagation algorithm, but some work using the cascade correlation neural network trained with Nechyba's node-decoupled extended-Kalman algorithm <ref> [69] </ref> is also being conducted. 5.1.4 Simulation code Simulation code has been written which allows neural networks trained by our system to be used for demonstrating both the approach and grasping phases of the catching skill.
Reference: [70] <author> M.C. Nechyba and Yangsheng Xu. </author> <title> Human skill transfer: neural networks as learners and teachers. </title> <booktitle> In Proceedings of the 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems [6], </booktitle> <pages> pages 314-19. BIBLIOGRAPHY 47 </pages>
Reference-contexts: Pomerleau [77] transferred human road following skills to an automated driving system using a single hidden-layer neural network which mapped coarsely sampled video images to steering outputs. In <ref> [70, 69] </ref>, Nechyba and Xu use a cascade correlation neural network architecture, trained by node-decoupled extended Kalman filtering, to learn skill mappings from human performance data. They also demonstrate human-to-human skill transfer using the neural network as an intermediary teacher. <p> Instead, we will use and compare methods resulting from previous and current research in training intelligent controllers, such as the work of Nechyba <ref> [70, 69] </ref>. Because task-skills will be broken into sets of individual low-level skills, we expect that training each low-level skill will be less demanding than for other methods of skill learning, and that a number of training methods will thus be acceptable for our use.
Reference: [71] <author> M.C. Nechyba and Yangsheng Xu. </author> <title> Stochastic similarity for validating hu man control strategy models. </title> <booktitle> In Proceedings of the 1997 IEEE International Conference on Robotics and Automation, </booktitle> <volume> volume 1, </volume> <pages> pages 278-83, </pages> <address> Albuquerque, NM, </address> <month> April </month> <year> 1997. </year> <note> IEEE. </note>
Reference-contexts: In most cases in the literature, this evaluation is made using extrinsic, task-specific performance metrics. However, comparisons of the performances of learned controllers with the data used to train them, and metrics of intrinsic, task-independent performance qualities are also used. In <ref> [71] </ref>, Nechyba and Xu demonstrate the use of an HMM-based model determining similarities of task performances, which may be used for validating the consistency between a trained controller's performances and the task demonstration data of its human teacher. <p> RELIABILITY 25 are necessarily different in some senses, that the basic structure of their performances are similar. We thus propose to use a measure developed by Nechyba and Xu <ref> [71] </ref> to check the fidelity of learned skills with respect to the human performances used to develop them.
Reference: [72] <author> Jackie Neider, Tom Davis, and Mason Woo. </author> <title> OpenGL Programming Guide: The Official Guide to Learning OpenGL, Release 1. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <address> Reading, MA, </address> <year> 1993. </year>
Reference-contexts: These interaction devices must sufficiently immerse the performer in the virtual environment that skilled performance of simulated tasks becomes as natural as possible. Currently, the sensory feedback provided to the performer is a set of multiple views of the virtual environment rendered with OpenGL <ref> [72] </ref> and displayed on a computer monitor. A Cyberglove with a Polhemus sensor for tracking the performer's hand motions in space are used as input devices. <p> The input device is a Cyberglove with a Polhemus position sensor, and the feedback to the performer is a set of views of the virtual environment rendered on the monitor of a workstation. The scenes are rendered in real-time using the OpenGL <ref> [72] </ref> graphics programming interface. The current simulation is very simple: the ball moves with a constant velocity along a trajectory, and the simulation is terminated either when the ball contacts the palm of the performer's virtual hand, or when the ball touches more than one finger-segment of the virtual hand.
Reference: [73] <author> H. Ogata and T. Takahashi. </author> <title> A geometric approach to task understand ing and playback: compact and robust task description for complex environments. </title> <booktitle> In Proceedings of the 1994 IEEE International Conference on Robotics and Automation [3], </booktitle> <pages> pages 848-54. </pages>
Reference-contexts: Some of this work is for task-level programming-by-demonstration. In <ref> [74, 73] </ref>, Ogata and Takahashi present a system whereby a human operator demonstrates a task in a virtual environment. A symbolic task-level representation of the demonstrated task is generated by their system, and transferred to a robot which then executes the task, re-planning steps where necessary.
Reference: [74] <author> H. Ogata and T. Takahashi. </author> <title> Robotic assembly operation teaching in a virtual environment. </title> <journal> IEEE Transactions on Robotics and Automation, </journal> <volume> 10(3) </volume> <pages> 391-9, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: Some of this work is for task-level programming-by-demonstration. In <ref> [74, 73] </ref>, Ogata and Takahashi present a system whereby a human operator demonstrates a task in a virtual environment. A symbolic task-level representation of the demonstrated task is generated by their system, and transferred to a robot which then executes the task, re-planning steps where necessary.
Reference: [75] <author> C.C. Peck and A.P. Dhawan. </author> <title> SSME parameter model input selection us ing genetic algorithms. </title> <journal> IEEE Transactions on Aerospace and Electronic Systems, </journal> <volume> 32(1) </volume> <pages> 199-212, </pages> <month> January </month> <year> 1996. </year>
Reference-contexts: They use preprocessing to eliminate some performance non-optimalities before training, and use reinforcement learning for performance tuning after training to deal with other kinds of non-optimalities. Peck and Dhawan <ref> [75] </ref> show how a genetic algorithm may be used to search for a set of inputs to use for modelling a complex system with a neural network, and demonstrate their approach in the generation of a dynamic model of the Space Shuttle Main Engines.
Reference: [76] <author> M.A. Peshkin, J.E. Colgate, and C. Moore. </author> <title> Passive robots and haptic displays based on nonholonimic elements. </title> <booktitle> In Proceedings of the 1996 IEEE International Conference on Robotics and Automation [8], </booktitle> <pages> pages 551-6. </pages>
Reference-contexts: Shimoga [81, 82] analyzes requirements for force feedback and touch feedback in haptic interfaces, and surveys current systems in terms of these requirements. Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are <ref> [35, 21, 20, 76, 25, 10] </ref>. The work of Hirzinger's group is extended in [16] to include development of skills for force control using the PHANToM force feedback device to interact with a virtual environment.
Reference: [77] <author> Dean A. Pomerleau. </author> <title> Neural Network Perception for Mobile Robot Guidance. </title> <type> PhD thesis, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <year> 1992. </year>
Reference-contexts: They use a neural network, trained from human performance data, to perform online adaptation of the stiffness coefficient of a conventional controller for deburring. Sukhan Lee and Shimoji [59] propose a neural network architecture called the Hierarchically Self-Organizing Learning Network, for learning skill mappings for robots. Pomerleau <ref> [77] </ref> transferred human road following skills to an automated driving system using a single hidden-layer neural network which mapped coarsely sampled video images to steering outputs.
Reference: [78] <author> M.A. Sartori and P.J. Antsaklis. </author> <title> Implementations of learning control sys tems using neural networks. </title> <journal> IEEE Control Systems Magazine, </journal> <volume> 2 </volume> <pages> 49-57, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: The use of artificial neural networks is one of the most prevalent methods for robot control and skill acquisition <ref> [68, 62, 78] </ref>. Fuzzy logic control, reinforcement learning, and table-look-up with local interpolation are other common methods. 4 CHAPTER 1.
Reference: [79] <author> Nestor A. Schmajuk. </author> <title> The psychology of robots. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 84(10) </volume> <pages> 1553-61, </pages> <month> October </month> <year> 1996. </year>
Reference-contexts: The framework is designed to allow for learning new skills and automated refinement of skills over the lifetime of the robot through experimentation. Skill acquisition using neural networks A large number of techniques for transferring skills to robots using neural networks are currently being developed. Schmajuk <ref> [79] </ref> discusses how animal behavior and learning may be used as a model for development of systems for robotic task performance based on neural networks. Asada and Liu [12, 60] present results of transferring human skills to a robot for a deburring task.
Reference: [80] <author> J.G. Schneider and R.F. Gans. </author> <title> Efficient search for robot skill learning: simulation and reality. </title> <booktitle> In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems [4], </booktitle> <pages> pages 1256-63. </pages>
Reference-contexts: Their implementations are specific to the current robot and its environment. Schneider and Gans <ref> [80] </ref> represent robot skill as a table lookup with interpolation, and present skill development as a search through a high-dimensional action space.
Reference: [81] <author> K.B. Shimoga. </author> <title> A survey of perceptual feedback issues in dexterous telema nipulation. i. finger force feedback. </title> <booktitle> In Proceedings of IEEE Virtual Reality Annual International Symposium [2], </booktitle> <pages> pages 263-70. </pages>
Reference-contexts: INTRODUCTION Compliant motion skills Most of the current work in transferring human skills to robots via virtual environments involves acquiring compliant motion skills through haptic interfaces. Shimoga <ref> [81, 82] </ref> analyzes requirements for force feedback and touch feedback in haptic interfaces, and surveys current systems in terms of these requirements. Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are [35, 21, 20, 76, 25, 10].
Reference: [82] <author> K.B. Shimoga. </author> <title> A survey of perceptual feedback issues in dexterous telema nipulation. ii. finger touch feedback. </title> <booktitle> In Proceedings of IEEE Virtual Reality Annual International Symposium [2], </booktitle> <pages> pages 271-9. 48 BIBLIOGRAPHY </pages>
Reference-contexts: INTRODUCTION Compliant motion skills Most of the current work in transferring human skills to robots via virtual environments involves acquiring compliant motion skills through haptic interfaces. Shimoga <ref> [81, 82] </ref> analyzes requirements for force feedback and touch feedback in haptic interfaces, and surveys current systems in terms of these requirements. Some papers on haptic interfaces, particularly for teleoperation with force-feedback, that have been published since this survey are [35, 21, 20, 76, 25, 10].
Reference: [83] <author> D. Stewart, R. Volpe, and P. Khosla. </author> <title> Integration of real-time software modules for reconfigurable sensor-based control systems. </title> <booktitle> In Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems, </booktitle> <pages> pages 325-332, </pages> <year> 1992. </year>
Reference-contexts: The implementation of the continuous subsystem in a robot architecture will actually be a set of tasks within the robot's operating system which repeat computations at some fixed frequency. In our particular robot systems which run the Chimera operating system <ref> [83, 84] </ref>, the continuous subsystem will consist of a set of Chimera SBS-modules communicating through a triple-buffered state-variable table. SBS-modules run in separate threads, cycle at independent frequencies, and can be allocated at runtime to any of the processors on the system without modification.
Reference: [84] <author> D. Stewart, R. Volpe, and P. Khosla. </author> <title> Design of dynamically reconfigurable real-time software using port-based objects. </title> <type> Technical Report CMU-RI-TR-93-11, </type> <institution> Department of Electrical and Computer Engineering, Carnegie Mellon University, Carnegie Mellon University, </institution> <month> July </month> <year> 1993. </year>
Reference-contexts: The implementation of the continuous subsystem in a robot architecture will actually be a set of tasks within the robot's operating system which repeat computations at some fixed frequency. In our particular robot systems which run the Chimera operating system <ref> [83, 84] </ref>, the continuous subsystem will consist of a set of Chimera SBS-modules communicating through a triple-buffered state-variable table. SBS-modules run in separate threads, cycle at independent frequencies, and can be allocated at runtime to any of the processors on the system without modification.
Reference: [85] <author> Gerald Sussman. </author> <title> A computer model of skill aquisition. </title> <booktitle> Number 1 in Artifi cial intelligence series. </booktitle> <publisher> American Elsevier Publishing Company, </publisher> <address> New York, </address> <year> 1975. </year>
Reference-contexts: learning and refinement of robot skills, and virtual reality for skill transfer. 1.3.1 Skill-oriented programming We will use the term "low-level" skill in roughly the same way that authors of works in the literature use the terms "sensory-motor primitives", "prim-itive operations", "elementary operations", "basic operations", and "human control strategy." Sussman <ref> [85] </ref> is an early work on computer problem solving which uses the word "skill" to mean "the unwritten knowledge derived from practice which ties the written knowledge together, making it usable." Archibald and Petriu [11] describe the "Skills-Oriented Robot Programming" concept (SKORP) for simple composition of task-based programs on the factory
Reference: [86] <author> Yangsheng Xu and Jie Yang. </author> <title> Towards human-robot coordination: skill modeling and transferring via hidden Markov model. </title> <booktitle> In Proceedings of the 1995 IEEE International Conference on Robotics and Automation [5], </booktitle> <pages> pages 1906-11. </pages>
Reference-contexts: A few researchers are investigating hidden Markov models (HMMs), as a means of representing human skills. Xu and Yang <ref> [86, 87] </ref> show how to train an HMM using human performance data to find a "most likely" performance for a given task, and demonstrate their approach by training the space robot (SM) 2 to perform an ORU replacement task.

References-found: 86

