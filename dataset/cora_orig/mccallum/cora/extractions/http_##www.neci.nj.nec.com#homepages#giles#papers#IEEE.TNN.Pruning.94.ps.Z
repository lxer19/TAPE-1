URL: http://www.neci.nj.nec.com/homepages/giles/papers/IEEE.TNN.Pruning.94.ps.Z
Refering-URL: http://www.neci.nj.nec.com/homepages/giles/html/CLG_pub.html
Root-URL: 
Title: Pruning Recurrent Neural Networks for Improved Generalization Performance  
Author: C. Lee Giles a;b Christian W. Omlin a;c 
Address: 4 Independence Way, Princeton, NJ 08540  College Park, MD 20742  Troy, NY 12180  
Affiliation: a NEC Research Institute,  b UMIACS, U. of Maryland,  c Computer Science, Rensselaer Polytechnic Institute,  
Abstract: Determining the architecture of a neural network is an important issue for any learning task. For recurrent neural networks no general methods exist that permit the estimation of the number of layers of hidden neurons, the size of layers or the number of weights. We present a simple pruning heuristic which significantly improves the generalization performance of trained recurrent networks. We illustrate this heuristic by training a fully recurrent neural network on positive and negative strings of a regular grammar. We also show that if rules are extracted from networks trained to recognize these strings, that rules extracted after pruning are more consistent with the rules to be learned. This performance improvement is obtained by pruning and retraining the networks. Simulations are shown for training and pruning a recurrent neural net on strings generated by two regular grammars, a randomly-generated 10-state grammar and an 8-state triple parity grammar. Further simulations indicate that this pruning method can gives generalization performance superior to that obtained by training with weight decay.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Cleeremans, D. Servan-Schreiber, and J. L. McClelland, </author> <title> "Finite state automata and simple recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 1, no. 3, </volume> <pages> pp. 372-381, </pages> <year> 1989. </year>
Reference-contexts: Copyright IEEE. 1 2 PRUNING A RECURRENT NETWORK To test our pruning heuristic, we incrementally trained discrete-time, fully recurrent temporally-driven neural networks with second-order weights W ijk to learn regular languages <ref> [1, 4, 13, 15] </ref>. <p> For more details see [4]. The heuristic used for extracting rules from recurrent networks in the form of deterministic finite-state automata (DFA's) is described in detail in [4]. Different approaches are discussed in <ref> [1, 15] </ref>. The quality of the extracted rules has been discussed in [5]. The algorithm used to extract a finite-state automaton from a network is based on the observation that the outputs of the recurrent state neurons of a trained network tend to cluster. <p> Otherwise, the current network state corresponds to a rejecting DFA state. The problem of DFA extraction is thus reduced to identifying clusters in the output space <ref> [0; 1] </ref> N of all state neurons. We use a dynamical state space exploration which identifies the DFA states and at the same time avoids exploration of the entire space which is computationally not feasible.
Reference: [2] <author> Y. L. Cun, J. S. Denker, and S. A. Solla, </author> <title> "Optimal brain damage," </title> <booktitle> in Advances in Neural Information Processing Systems 2 (D. </booktitle> <editor> Touretzky, ed.), </editor> <address> (San Mateo, CA), </address> <pages> pp. 598-605, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference: [3] <author> P. Frasconi, M. Gori, M. Maggini, and G. </author> <title> Soda, "A unified approach for integrating explicit knowledge and learning by example in recurrent networks," </title> <booktitle> in Proceedings of the International Joint Conference on Neural Networks, </booktitle> <volume> vol. 1, </volume> <editor> p. </editor> <volume> 811, </volume> <publisher> IEEE 91CH3049-4, </publisher> <year> 1991. </year>
Reference-contexts: But the 10-state random DFA should have had a 4 state recurrent network. However, that did not occur; training failed to converge. It would be interesting to see if knowledge inserted into the network before or during training <ref> [3, 6, 14] </ref> aids or impedes the pruning process.
Reference: [4] <author> C. L. Giles, C. B. Miller, D. Chen, H. H. Chen, G. Z. Sun, and Y. C. Lee, </author> <title> "Learning and extracting finite state automata with second-order recurrent neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 4, no. 3, </volume> <editor> p. </editor> <volume> 380, </volume> <year> 1992. </year>
Reference-contexts: Copyright IEEE. 1 2 PRUNING A RECURRENT NETWORK To test our pruning heuristic, we incrementally trained discrete-time, fully recurrent temporally-driven neural networks with second-order weights W ijk to learn regular languages <ref> [1, 4, 13, 15] </ref>. <p> The output is the activation of one of the state neurons S 0 inspected at the end of a temporal sequence. The weights W ijk were updated according to a second-order form of the real-time recurrent learning (RTRL) algorithm for recurrent neural networks ([16]). For more details see <ref> [4] </ref>. The heuristic used for extracting rules from recurrent networks in the form of deterministic finite-state automata (DFA's) is described in detail in [4]. Different approaches are discussed in [1, 15]. The quality of the extracted rules has been discussed in [5]. <p> For more details see <ref> [4] </ref>. The heuristic used for extracting rules from recurrent networks in the form of deterministic finite-state automata (DFA's) is described in detail in [4]. Different approaches are discussed in [1, 15]. The quality of the extracted rules has been discussed in [5]. The algorithm used to extract a finite-state automaton from a network is based on the observation that the outputs of the recurrent state neurons of a trained network tend to cluster. <p> It consists of the first 500 positive and 500 negative example strings in alphabetical order with alternating positive and negative strings. Since this a second-order modification of RTRL, training occurs at the end of each presented string. An incremental training method discussed in <ref> [4] </ref> was used for the string presentation. The initial training set consisted of 30 strings. This training set was successfully learned and a small number of incorrectly classified strings were then added to the original set. The process was repeated until all strings in the training set were correctly classified.
Reference: [5] <author> C. L. Giles and C. W. Omlin, </author> <title> "Extraction, insertion and refinement of symbolic rules in dynamically-driven recurrent neural networks," </title> <journal> Connection Science, </journal> <volume> vol. 5, no. 3,4, </volume> <pages> pp. 307-337. </pages> <booktitle> Special Issue on Architectures for Integrating Symbolic and Neural Processes. </booktitle> <pages> 7 </pages>
Reference-contexts: For more details see [4]. The heuristic used for extracting rules from recurrent networks in the form of deterministic finite-state automata (DFA's) is described in detail in [4]. Different approaches are discussed in [1, 15]. The quality of the extracted rules has been discussed in <ref> [5] </ref>. The algorithm used to extract a finite-state automaton from a network is based on the observation that the outputs of the recurrent state neurons of a trained network tend to cluster. <p> The extracted DFA's generalization performance is impressive with only 0.41% of all test strings misclassified, thus outperforming the trained network (this is often the case, see for example <ref> [5] </ref>). After pruning the first state neuron of the network, the retraining time was negligible (7 epochs), indicating that the pruned state neuron did not contribute significantly to the internal representation of the learned DFA.
Reference: [6] <author> C. L. Giles and C. W. Omlin, </author> <title> "Inserting rules into recurrent neural networks," in Neural Networks for Signal Processing II, </title> <booktitle> Proceedings of The 1992 IEEE Workshop (S. </booktitle> <editor> Kung, F. Fallside, J. A. Sorenson, and C. Kamm, </editor> <booktitle> eds.), </booktitle> <pages> pp. 13-22, </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: But the 10-state random DFA should have had a 4 state recurrent network. However, that did not occur; training failed to converge. It would be interesting to see if knowledge inserted into the network before or during training <ref> [3, 6, 14] </ref> aids or impedes the pruning process.
Reference: [7] <author> B. Hassibi and D. G. Stork, </author> <title> "Second order derivatives for network pruning: Optimal brain surgeon," </title> <booktitle> in Advances in Neural Information Processing Systems 5 (S. </booktitle> <editor> Hanson, J. Cowan, and C. Giles, eds.), </editor> <address> (San Mateo, CA), </address> <note> Morgan Kaufmann Publishers, 1993 to be published. </note>
Reference: [8] <author> G. E. Hinton, </author> <title> "Learning translation invariant recognition in a massively parallel network," </title> <booktitle> in PARLE: Parallel Architectures and Languages Europe, </booktitle> <pages> pp. 1-13, </pages> <address> Berlin: </address> <publisher> Springer Verlag, </publisher> <year> 1987. </year> <note> Lecture Notes in Computer Science. </note>
Reference: [9] <author> J. E. Hopcroft and J. D. Ullman, </author> <title> Introduction to Automata Theory, </title> <booktitle> Languages, and Computation. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <year> 1979. </year>
Reference: [10] <author> A. Krogh and J. A. Hertz, </author> <title> "A simple weight decay can improve generalization," </title> <booktitle> in Advances in Neural Information Processing Systems 4 (J. </booktitle> <editor> Moody, S. Hanson, and R. Lippmann, eds.), </editor> <address> (San Mateo, CA), </address> <pages> pp. 950-957, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1992. </year>
Reference: [11] <author> C. W. Omlin and C. L. Giles, </author> <title> "Extraction of rules from discrete-time recurrent neural networks," </title> <type> Tech. Rep. 92-23, </type> <institution> Computer Science Department - Rensselaer Polytechnic Institute, </institution> <address> Troy, NY 12180, </address> <year> 1992. </year>
Reference-contexts: Many different DFA extracted thus collapse into equivalence classes. Several minimized DFA's may be consistent with the training set. Thus, it becomes necessary to select among the candidate DFA's the one model which best approximates the unknown source grammar. Based on simulation results in <ref> [11] </ref>, we choose the consistent minimized DFA which was extracted with the smallest quantization level q as the best model. As it turns out, the best model is also always the DFA with shortest description length (number of states). <p> As it turns out, the best model is also always the DFA with shortest description length (number of states). The specific issues of the extraction algorithm and quality of the extracted rules are discussed in <ref> [11, 12] </ref>. Our goal is to train networks of small size with improved generalization performance and also to improve the quality of the extracted rules. We start by training a large network for a known regular grammar and apply our network pruning and retraining strategy to the trained network.
Reference: [12] <author> C. W. Omlin, C. L. Giles, and C. B. Miller, </author> <title> "Heuristics for the extraction of rules from discrete-time recurrent neural networks," </title> <booktitle> in Proceedings International Joint Conference on Neural Networks 1992, </booktitle> <volume> vol. I, </volume> <pages> pp. 33-38, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: As it turns out, the best model is also always the DFA with shortest description length (number of states). The specific issues of the extraction algorithm and quality of the extracted rules are discussed in <ref> [11, 12] </ref>. Our goal is to train networks of small size with improved generalization performance and also to improve the quality of the extracted rules. We start by training a large network for a known regular grammar and apply our network pruning and retraining strategy to the trained network.
Reference: [13] <author> J. B. Pollack, </author> <title> "The induction of dynamical recognizers," </title> <journal> Machine Learning, </journal> <volume> vol. 7, </volume> <pages> pp. 227-252, </pages> <year> 1991. </year>
Reference-contexts: Copyright IEEE. 1 2 PRUNING A RECURRENT NETWORK To test our pruning heuristic, we incrementally trained discrete-time, fully recurrent temporally-driven neural networks with second-order weights W ijk to learn regular languages <ref> [1, 4, 13, 15] </ref>.
Reference: [14] <author> J. W. Shavlik, </author> <title> "A framework of combining symbolic and neural learning," </title> <type> Tech. Rep. TR 1123, </type> <institution> Computer Sciences Dept., Computer Sciences Dept, U of Wisconson - Madison, </institution> <year> 1992. </year>
Reference-contexts: But the 10-state random DFA should have had a 4 state recurrent network. However, that did not occur; training failed to converge. It would be interesting to see if knowledge inserted into the network before or during training <ref> [3, 6, 14] </ref> aids or impedes the pruning process.
Reference: [15] <author> R. L. Watrous and G. M. Kuhn, </author> <title> "Induction of finite-state languages using second-order recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 4, no. 3, </volume> <editor> p. </editor> <volume> 406, </volume> <year> 1992. </year>
Reference-contexts: Copyright IEEE. 1 2 PRUNING A RECURRENT NETWORK To test our pruning heuristic, we incrementally trained discrete-time, fully recurrent temporally-driven neural networks with second-order weights W ijk to learn regular languages <ref> [1, 4, 13, 15] </ref>. <p> For more details see [4]. The heuristic used for extracting rules from recurrent networks in the form of deterministic finite-state automata (DFA's) is described in detail in [4]. Different approaches are discussed in <ref> [1, 15] </ref>. The quality of the extracted rules has been discussed in [5]. The algorithm used to extract a finite-state automaton from a network is based on the observation that the outputs of the recurrent state neurons of a trained network tend to cluster.
Reference: [16] <author> R. J. Williams and D. Zipser, </author> <title> "A learning algorithm for continually running fully recurrent neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 1, </volume> <pages> pp. 270-280, </pages> <year> 1989. </year>
Reference: [17] <author> Z. Zeng, R. M. Goodman, and P. Smyth, </author> <title> "Learning finite state machines with self-clustering recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 5, no. 6, </volume> <pages> pp. 976-990, </pages> <year> 1993. </year> <month> 8 </month>
References-found: 17

