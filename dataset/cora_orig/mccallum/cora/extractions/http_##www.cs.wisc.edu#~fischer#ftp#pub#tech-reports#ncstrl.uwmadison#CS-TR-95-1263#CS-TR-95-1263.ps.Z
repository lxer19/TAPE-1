URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-95-1263/CS-TR-95-1263.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-95-1263/
Root-URL: http://www.cs.wisc.edu
Title: A Convergence Theorem for Chaotic Asynchronous Relaxation  
Author: John C. Strikwerday 
Keyword: chaotic relaxation, asynchronous relaxation, parallel computing.  
Note: AMS(MOS) classifications: 65F10  
Affiliation: Computer Sciences Department University of Wisconsin-Madison  
Abstract: We present a convergence result for chaotic asynchronous relaxation that is a modification of the result of Chazan and Miranker. The modification is a restriction to the case of global memory or fast communication. The extra restriction is that each update is based on a prior state of the system, rather than based on prior sub-states of the system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. Baudet, </author> <title> Asynchronous iterative methods for multiprocessors, </title> <journal> J. ACM, </journal> <volume> 25 (1978), </volume> <pages> pp. 225-244. </pages>
Reference-contexts: Proof of Theorem 2.2. The proof that the condition (jBj) &lt; 1 implies that the restricted processes will converge follows from the theorem of Chazan and Miranker. However, we include it here for completeness. The proof of the following lemma is due to Baudet <ref> [1] </ref>. Lemma 3.1. The condition (jBj) &lt; 1 implies that there is a value ff with 0 &lt; ff &lt; 1 and a vector ~p with positive components such that jBj~p ff~p: Proof.
Reference: [2] <author> D.P. Bertsekas and J.N. Tsitsiklis, </author> <title> Parallel and Distributed Computing, Numerical Methods, </title> <publisher> Prentice-Hall, Inc., </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1989. </year>
Reference-contexts: Of interest here are cases where there is no particular pattern to the order of the updates. Bertsekas and Tsitsiklis <ref> [2, page 435] </ref> consider a seemly more general form of asynchronous relaxation in which the function u () takes sets as values. <p> For the general chaotic relaxation as defined here, Chazan and Miranker have proved the following stability theorem. (See also Bertsekas and Tsitsiklis <ref> [2] </ref> for a proof.) Theorem 2.1. A necessary and sufficient condition for the chaotic iteration to converge for all update functions and shift functions satisfying Conditions 1 and 2 is the condition (jBj) &lt; 1: An interesting feature of the definition of Chazan and Miranker is the extreme generality allowed. <p> The shift function is independent of m: Here we are interested in considering a modification of the processes allowed by Chazan and Miranker by considering the Condition 3 along with Conditions 1 and 2. In the notation of Bertsekas and Tsitsiklis <ref> [2] </ref> this condition is that t i j (t) is independent of j: Our main result is the following theorem. Theorem 2.2.
Reference: [3] <author> D.P. Bertsekas and J.N. Tsitsiklis, </author> <title> Some aspects of parallel and distributed algorithms a survey, </title> <journal> Automatica, </journal> <volume> 27 (1991), </volume> <pages> pp. 3-21. </pages>
Reference-contexts: The shift function is bounded, that is, there is an integer s such that 0 s (-; m) &lt; s: For the initial steps to be well defined, we require s (-; m) -; as well. Condition 1 is obviously necessary for the process to converge, and Bertsekas <ref> [3] </ref> has an example of a non-converging process in the case that Condition 2 fails to hold. For the general chaotic relaxation as defined here, Chazan and Miranker have proved the following stability theorem. (See also Bertsekas and Tsitsiklis [2] for a proof.) Theorem 2.1.
Reference: [4] <author> R. Bru, L. Elsner, and M. Neumann, </author> <title> Models of parallel chaotic iteration methods, </title> <journal> Lin. Alg. Appl., </journal> <volume> 103 (1988), </volume> <pages> pp. 175-192. </pages>
Reference-contexts: Much of the paper [5] deals with the special case of periodic relaxation, in which there is a well-define order to the process of updating. Much of the work that has followed that of Chazan and Miranker extends the analysis of periodic relaxation, see, for example, <ref> [4] </ref> and [6]. At the end of [5] Chazan and Miranker prove an interesting very general theorem on convergence for chaotic iteration.
Reference: [5] <author> D. Chazan and W. Miranker, </author> <title> Chaotic relaxation, </title> <journal> Lin. Alg. Appl., </journal> <volume> 2 (1969), </volume> <pages> pp. 199-222. </pages>
Reference-contexts: 1. Introduction. In their seminal paper <ref> [5] </ref> Chazan and Miranker studied chaotic relaxation, now usually called asynchronous relaxation, for the solution of linear systems. In chaotic relaxation the order in which components of the solution are updated is arbitrary and the past values of components that are used in the updates are also selected arbitrarily. <p> The model of Chazan and Miranker is an extreme model in that many real systems place more restrictions on the process than Chazan and Miranker do. Much of the paper <ref> [5] </ref> deals with the special case of periodic relaxation, in which there is a well-define order to the process of updating. Much of the work that has followed that of Chazan and Miranker extends the analysis of periodic relaxation, see, for example, [4] and [6]. At the end of [5] Chazan <p> paper <ref> [5] </ref> deals with the special case of periodic relaxation, in which there is a well-define order to the process of updating. Much of the work that has followed that of Chazan and Miranker extends the analysis of periodic relaxation, see, for example, [4] and [6]. At the end of [5] Chazan and Miranker prove an interesting very general theorem on convergence for chaotic iteration. In this paper we present, we believe, the first theorem y This work was supported in part by the National Science Foundation under grant DMS-9208049 that modifies their general theorem for chaotic relaxation. <p> sufficient condition for the chaotic iteration to converge for all update functions and shift functions satisfying Conditions 1, 2, and 3 is the condition (jBj) &lt; 1: The proof of this result does not follow from the proof of Chazan and Miranker because the construction of the non-converging sequence in <ref> [5] </ref> depends heavily on the function s (; ) depending on the component of the vector. In fact, the construction of the non-converging sequence for the restricted case of Theorem 2.2 is more involved than in the general case of Theorem 2.1. 3. Proof of Theorem 2.2. <p> A interesting topic for further study would be the analysis of systems that are less chaotic than the general system of Chazan and Miranker <ref> [5] </ref>, but allow for behavior that is not deterministic. The situation in which there is some constraint on older data not being available once newer data is available, see (2.2), appears to be much more difficult than the case studied here.
Reference: [6] <author> J.D.P. Donnelly, </author> <title> Periodic chaotic relaxation, </title> <journal> Lin. Alg. Appl., </journal> <volume> 4 (1971), </volume> <pages> pp. 117-128. </pages>
Reference-contexts: Much of the paper [5] deals with the special case of periodic relaxation, in which there is a well-define order to the process of updating. Much of the work that has followed that of Chazan and Miranker extends the analysis of periodic relaxation, see, for example, [4] and <ref> [6] </ref>. At the end of [5] Chazan and Miranker prove an interesting very general theorem on convergence for chaotic iteration.
Reference: [7] <author> F.R. Gantmacher, </author> <title> The Theory of Matrices, </title> <publisher> Chelsea Publishing Co., </publisher> <address> New York, </address> <year> 1959. </year> <month> 9 </month>
Reference-contexts: Lemma 3.1. The condition (jBj) &lt; 1 implies that there is a value ff with 0 &lt; ff &lt; 1 and a vector ~p with positive components such that jBj~p ff~p: Proof. Suppose first that jb `;m j &gt; 0 for all components of jBj: Then by Perron's Theorem <ref> [7, vol. 2, page 53] </ref> on positive matrices, the largest eigenvalue of jBj is simple and the eigenvector has positive values. If ~p is this eigenvector and ff is the eigenvalue then jBj~p = ff~p; and the theorem is proved in this special case.
References-found: 7

