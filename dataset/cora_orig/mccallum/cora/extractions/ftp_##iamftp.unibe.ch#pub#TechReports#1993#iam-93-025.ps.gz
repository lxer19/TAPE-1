URL: ftp://iamftp.unibe.ch/pub/TechReports/1993/iam-93-025.ps.gz
Refering-URL: 
Root-URL: 
Title: A Fast Algorithm for Finding the Nearest Neighbor of a Word in a Dictionary  
Author: Horst Bunke 
Date: November 1993  
Pubnum: IAM-93-025  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Pavlidis, T. and Mori, S.: </author> <title> Optical Character Recognition, </title> <journal> Special Issue of Proceedings of the IEEE, </journal> <volume> Vol. 80, No. 7, </volume> <month> July </month> <year> 1992, </year> <pages> 1027-1209 </pages>
Reference: [2] <author> O'Gorman, L. and Kasturi, R.: </author> <title> Document Image Analysis Systems, </title> <journal> Special Issue of IEEE Computer, </journal> <volume> Vol. 25, No. 7, </volume> <month> July </month> <year> 1992 </year> <month> 13 </month>
Reference: [3] <author> Kasturi, R. and O'Gorman, L.: </author> <title> Document Image Analysis Techniques, </title> <journal> Special Issue of Machine Vision and Application, </journal> <volume> Vol. 5, No. 3, </volume> <publisher> Springer Verlag, </publisher> <month> Summer </month> <year> 1992 </year>
Reference: [4] <author> Baird, H., Bunke, H. and Yamamoto, K.(eds.): </author> <title> Structured Document Image Analysis, </title> <publisher> Springer Verlag, </publisher> <year> 1992 </year>
Reference: [5] <author> Elliman, D.G. and Lancaster, </author> <title> I.T.: A Review of Segmentation and Contextual Analysis Techniques for Text Recognition, </title> <journal> Pattern Recognition, </journal> <volume> Vol. 23, No. 3/4, </volume> <year> 1990, </year> <pages> 337-346 </pages>
Reference-contexts: In order to improve the overall performance of an automatic reading device, nevertheless, the application of post-processing techniques using contextual information is considered very useful. A recent survey of contextual postprocessing methods has been given in <ref> [5] </ref>. For an earlier collection of papers addressing the same problem domain see [6]. There are different categories of contextual postprocessing methods. One class of methods is based on n-gram statistics [7,8]. Such methods rely on transition probabilities between consecutive letters of a word.
Reference: [6] <author> Srihari, S.N.(ed.): </author> <title> Computer Text Recognition and Error Correction, Tutorial, </title> <publisher> IEEE Computer Society Press, </publisher> <address> Silver Spring, MD, </address> <year> 1985 </year>
Reference-contexts: In order to improve the overall performance of an automatic reading device, nevertheless, the application of post-processing techniques using contextual information is considered very useful. A recent survey of contextual postprocessing methods has been given in [5]. For an earlier collection of papers addressing the same problem domain see <ref> [6] </ref>. There are different categories of contextual postprocessing methods. One class of methods is based on n-gram statistics [7,8]. Such methods rely on transition probabilities between consecutive letters of a word.
Reference: [7] <author> Riseman, E.M. and Hanson, </author> <title> A.R.: A Contextual Postprocessing System for Error Correction Using Binary n-Grams, </title> <journal> IEEE Trans. on Computers, </journal> <volume> Vol. C-23, </volume> <month> May </month> <year> 1974, </year> <pages> 480-493 </pages>
Reference: [8] <author> Hull, J.J. and Srihari, </author> <title> S.N.: Experiments in Text Recognition with Binary n-Gram and Viterbi Algorithms, </title> <journal> IEEE Trans. PAMI, </journal> <volume> Vol. PAMI-4, </volume> <month> Sept </month> <year> 1982, </year> <pages> 520-530 </pages>
Reference: [9] <author> Downtown, A.C. and Tregido, R.W.S.: </author> <title> The Use of a Trie Structured Dictionary as a Contextual Aid to Recognition of Handwritten British Postal Addresses, </title> <booktitle> Proc. 1st ICDAR, </booktitle> <address> Saint-Malo, France, </address> <year> 1991, </year> <pages> 542-550 </pages>
Reference: [10] <author> Leroux, M., Salome, J.C. and Badard, J.: </author> <title> Recognition of Cursive Words in a Small Lexicon, </title> <booktitle> Proc. 1st ICDAR, </booktitle> <address> Saint-Malo, France, </address> <year> 1991, </year> <pages> 774-782 </pages>
Reference: [11] <author> Wagner, R.A. and Fischer, M.J.: </author> <title> The String-to-String Correction Problem, </title> <journal> Journal of the ACM, </journal> <volume> Vol. 21, No. 1, </volume> <year> 1974, </year> <pages> 168-173 </pages>
Reference-contexts: The string edit, or generalized Levenshtein distance of two strings of symbols corresponds to the minimum cost sequence of elementary edit operations that make the two strings identical. The classical reference for edit distance computation of two words is the Wagner & Fischer algorithm <ref> [11] </ref>. This algorithm is based on dynamic programming. It has a time complexity of O (n m) where n and m are the lengths of the two strings under comparison. Improving the time complexity of the Wagner & Fischer algorithm has been a major subject of research for many years. <p> Then some preselection technique is indispensible in order to quickly determine a small set of potential candidate words from the dictionary [18]. In this paper a new algorithm for string edit distance computation is proposed. It is based on the classical approach <ref> [11] </ref>. However, while in [11] the two strings to be compared may be given online, our algorithm assumes that one of the two strings to be compared is a dictionary entry that is known a priori. <p> Then some preselection technique is indispensible in order to quickly determine a small set of potential candidate words from the dictionary [18]. In this paper a new algorithm for string edit distance computation is proposed. It is based on the classical approach <ref> [11] </ref>. However, while in [11] the two strings to be compared may be given online, our algorithm assumes that one of the two strings to be compared is a dictionary entry that is known a priori. <p> edit operations is defined by c (E) = i=1 Now, the edit distance of strings A and B is defined by d (A; B) = minfc (E)jB is derivable from A via Eg: An algorithm for computing the string edit distance d (A; B) was given by Wagner & Fischer <ref> [11] </ref>. This algorithm plays a fundamental role for the method described in this paper. It will be called basic algorithm in the rest of this paper. Next, we give a brief review of this algorithm. <p> For the interior elements, the following recursion formula is used D (i; j) = minfD (i1; j1)+c (a i ! b j ); D (i1; j)+c (a i ! *); D (i; j1)+c (* ! b j )g: (1) It was shown that d (A; B) = D (n; m) <ref> [11] </ref>. The basic algorithm uses O (n m) time and space. <p> It is known that for the cost function c (a ! b) = 2; c (a ! *) = c (* ! a) = 1; a 6= b the edit distance of two strings is identical with the longest common subsequence <ref> [11] </ref>. A case analysis similar to the one provided in Lemma 3.1 reveals that under this cost function the difference between two successive elements in the edit matrix is either 1 or -1.
Reference: [12] <author> Masek, W.J. and Paterson, </author> <title> M.S.: A Faster Algorithm for Comparing String-Edit Distances, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> Vol. 20, No. 1, </volume> <year> 1980, </year> <pages> 18-31 </pages>
Reference-contexts: A potential limitation of the method, however, is its space complexity, which is exponential in the length of the dictionary words. Throughout this paper we have considered only the cost function (2). However, it has been shown in <ref> [12] </ref> that under the condition of sparseness of the cost function there is always only a finite number of possible differences between two successive elements in a row or column of an edit matrix. Consequently, all results of the present paper can be easily extended to this case.
Reference: [13] <author> Ukkonen, E.: </author> <title> Algorithms for Approximate String Matching, </title> <journal> Inform. and Control, </journal> <volume> Vol. 64, </volume> <year> 1985, </year> <pages> 100-118 </pages>
Reference: [14] <author> Hall, P.A.V. and Dowling, </author> <title> G.R.: Approximate String Matching, </title> <journal> ACM Comp. Surveys, </journal> <volume> Vol. 12, No. 4, </volume> <year> 1980, </year> <pages> 381-401 </pages>
Reference-contexts: Improving the time complexity of the Wagner & Fischer algorithm has been a major subject of research for many years. Two algorithm with a better assymptotical time complexity have been published [12,13]. A general discussion of string edit distance including various applications is contained in <ref> [14] </ref>. For a resent survey see [15]. Stochastic versions of string matching and their applications to the correction of distorted words have been described in [16,17]. One of the apparent problems in the application of string 2 edit distance to the correction of OCR-output is the high computational complexity.
Reference: [15] <author> Bunke, H.: </author> <title> Recent Advances in String Matching, in Bunke, H.(ed.): Advances in Structural and Syntactic Pattern Recognition, </title> <publisher> World Scientific Publ. Co., </publisher> <address> Singapore, </address> <year> 1993, </year> <note> to appear </note>
Reference-contexts: Two algorithm with a better assymptotical time complexity have been published [12,13]. A general discussion of string edit distance including various applications is contained in [14]. For a resent survey see <ref> [15] </ref>. Stochastic versions of string matching and their applications to the correction of distorted words have been described in [16,17]. One of the apparent problems in the application of string 2 edit distance to the correction of OCR-output is the high computational complexity.
Reference: [16] <author> Kashyap, R.L. and Oommen, B.J.: </author> <title> Spelling Correction Using Probabilistic Methods, </title> <journal> Pattern Recognition Letters 2, </journal> <year> 1984, </year> <pages> 147-154 14 </pages>
Reference: [17] <author> Bozinovic, R. and Srihari, </author> <title> S.N.: A String Correction Algorithm for Cursive Script Recognition, </title> <journal> IEEE Trans. PAMI, </journal> <volume> Vol. PAMI-4, </volume> <year> 1982, </year> <pages> 655-663 </pages>
Reference: [18] <author> Takahashi, H. Itoh, N., Amano, T. and Yamashita, A.: </author> <title> A Spelling Correction Method and its Application to an OCR System, </title> <journal> Pattern Recognition, </journal> <volume> Vol. 23, No. 3/4, </volume> <year> 1990, </year> <pages> 363-377 </pages>
Reference-contexts: This problem is particularly serious if the underlying dictionary is large. Then some preselection technique is indispensible in order to quickly determine a small set of potential candidate words from the dictionary <ref> [18] </ref>. In this paper a new algorithm for string edit distance computation is proposed. It is based on the classical approach [11].
Reference: [19] <author> Ha Minh, T. and Bunke. H.: </author> <title> Very Fast Recognition of Giro Check Form, </title> <booktitle> Proc. SPIE Conf. 1906 on Character Recognition Technologies, </booktitle> <address> San Jose, CA, </address> <year> 1993, </year> <note> to appear </note>
Reference-contexts: In this paper we describe the new algorithm and prove its correctness. Also, we analyze its computational complexity. Potential applications are beyond the scope of this paper. However, the practical use of the algorithm in the context of a system for reading check forms <ref> [19] </ref> is currently under investigation. The rest of this paper is organized in the following way. Section 2 introduces the basic terminology and briefly reviews the Wagner & Fischer algorithm. Then, some fundamental definitions and basic properties will be given in section 3.
Reference: [20] <author> Hopcroft, J.E. and Ullman, J.D.: </author> <title> Introduction to Automata Theory, Languages, and Computation, </title> <publisher> Addison Wesley Publ. Co., </publisher> <year> 1979 </year> <month> 15 </month>
Reference-contexts: In this Lemma, the function ffi : QfiV ! Q has been extended to ffi : QfiV fl ! Q in the standard fashion; see, for example, chapter 2 of <ref> [20] </ref>. Proof of Lemma 4.4: The proof is by induction on the length of B. For B = * we have ffi (I; *) = I = (1; 1; : : : ; 1).
References-found: 20

