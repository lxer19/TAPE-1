URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/dpetrou/www/papers/freebsd_lottery_writeup98.ps
Refering-URL: http://www.ri.cmu.edu/afs/cs.cmu.edu/user/dpetrou/www/research.html
Root-URL: 
Email: dpetrou@cs.cmu.edu, jwm@csua.berkeley.edu  
Title: Proportional-Share Scheduling: Implementation and Evaluation in a Widely-Deployed Operating System  
Author: David Petrou and John Milford 
Note: Draft 12/20/1997. Send feedback to the authors.  
Abstract: This paper explores the feasibility of using lottery scheduling, a proportional-share resource management algorithm, to schedule processes under the FreeBSD operating system. Proportional-share scheduling enables flexible control over relative process execution rates and processor load insulation among groups of processes. We show that a straight implementation of lottery scheduling performs worse than the standard FreeBSD scheduler. This initial result prompted us to extend lottery scheduling. Except for one test we run, our resulting system performs within one percent of the FreeBSD scheduler. We describe our design, evaluate our implementation, and relate our experience in deploying our lottery scheduler on production machines. 
Abstract-found: 1
Intro-found: 1
Reference: [4.4BSD 1994] <institution> The 4.4BSD source code, </institution> <year> 1994. </year> <note> See ftp://- ftp.cdrom.com/pub/bsd-sources. </note>
Reference-contexts: Following, we contrast the characteristics and goals of the FreeBSD scheduler with the lottery scheduler. 2.1 Scheduling in FreeBSD FreeBSD [Lehey 1996, FreeBSD 1997] is a UNIX [Ritchie & Thompson 1974] operating system for the Intel 80386 platform based on UC Berkeley's 4.4BSD-Lite <ref> [4.4BSD 1994, McKusick et al. 1996] </ref> release. FreeBSD's scheduler is a typical example of decay usage priority scheduling also used in System V and Mach with 100 ms time slices. The scheduler is implemented with a multilevel feedback queue. Processes with equal priority are placed onto the same queue.
Reference: [Birrell 1989] <author> Birrell, A. D. </author> <title> An introduction to programming with threads. </title> <type> Technical Report 35, </type> <institution> Digital Equipment Corporation Systems Research Center, </institution> <address> Palo Alto, CA, </address> <month> January </month> <year> 1989. </year>
Reference-contexts: This chance exists, but it is not common, since we only force a context switch when the event-receiving process has used less CPU that the running process, making it probable that it earns more effective tickets than the preempted processes. 3.2 Kernel Priorities Priority inversion <ref> [Lampson & Redell 1980, Birrell 1989, Hauser et al. 1993] </ref> is a well-documented problem in concurrent systems. Consider the following situation. A low priority process acquires a non-preemptable kernel resource such as a lock.
Reference: [FreeBSD 1997] <institution> The FreeBSD Operating System, </institution> <year> 1997. </year> <note> See http://www.freebsd.org/. </note>
Reference-contexts: In some contexts, schedulers must ensure that processes meet real-time deadlines, although we are not concerned with such systems here. Following, we contrast the characteristics and goals of the FreeBSD scheduler with the lottery scheduler. 2.1 Scheduling in FreeBSD FreeBSD <ref> [Lehey 1996, FreeBSD 1997] </ref> is a UNIX [Ritchie & Thompson 1974] operating system for the Intel 80386 platform based on UC Berkeley's 4.4BSD-Lite [4.4BSD 1994, McKusick et al. 1996] release.
Reference: [Goldberg et al. 1996] <author> Goldberg, I., Wagner, D., Thomas, R., and Brewer, E. A. </author> <title> A secure environment for untrusted helper applications: Confining the wily hacker. </title> <booktitle> In Proceedings of the 1996 USENIX Security Symposium, </booktitle> <year> 1996. </year>
Reference-contexts: From a security perspective, proportional-share process scheduling enables users to carefully restrict the CPU consumption rate of untrusted binaries such as Java applications, or trusted binaries that use untrusted data such as WWW helper applications <ref> [Goldberg et al. 1996] </ref>. We have demonstrated the utility of proportional-share scheduling with respect to individual processes. Now we generalize and consider allocating proportions of processor time to individual users. In a timesharing system, users own processes which compete for, among other resources, CPU time.
Reference: [Hauser et al. 1993] <author> Hauser, C., Jacobi, C., Theimer, M., Welch, B., and Weiser, M. </author> <title> Using threads in interactive systems: A case study. </title> <booktitle> In Proceedings of the 14th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. 94-105, </pages> <month> December 5-8 </month> <year> 1993. </year>
Reference-contexts: This chance exists, but it is not common, since we only force a context switch when the event-receiving process has used less CPU that the running process, making it probable that it earns more effective tickets than the preempted processes. 3.2 Kernel Priorities Priority inversion <ref> [Lampson & Redell 1980, Birrell 1989, Hauser et al. 1993] </ref> is a well-documented problem in concurrent systems. Consider the following situation. A low priority process acquires a non-preemptable kernel resource such as a lock. <p> more as it doesn't have a chance to use its pages before they are evicted. [Waldspurger & Weihl 1994] explains that proportional-share resource management can be applied across diverse resources but does not provide an algorithm or policy by which an entire system can be scheduled toward optimal system performance. <ref> [Hauser et al. 1993, Nieh et al. 1994] </ref> suggest that adjusting priorities (tickets) toward higher-level scheduling goals is very difficult or intractable. We find the pursuit of more intelligent systemwide resource schedulers 10 an exciting research question.
Reference: [Hellerstein 1993] <author> Hellerstein, J. L. </author> <title> Achieving Service Rate Objectives with Decay Usage Scheduling. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 19(8) </volume> <pages> 813-825, </pages> <month> August </month> <year> 1993. </year>
Reference: [Int 1996] <author> Intel. </author> <title> Pentium Pro Family Developer's Manual, </title> <booktitle> volume 2, </booktitle> <year> 1996. </year>
Reference-contexts: We use the the cycle counter instruction RDTSC (Read Time-Stamp Counter) which increments a counter every clock cycle <ref> [Int 1996] </ref> to obtain accurate measurements. As we ran our tests on a 200 MHz machine, divide "cycles" by 200 to obtain microseconds. (out of at least 1000 measurements) to perform a context switch via the cpu switch () function while varying the number of runnable processes.
Reference: [Jolitz & Jolitz 1996] <author> Jolitz, W. F. and Jolitz, L. G. </author> <title> Source Code Secrets: The Basic Kernel, volume 1. Peer-to-Peer Communications, </title> <publisher> Inc., </publisher> <year> 1996. </year>
Reference-contexts: In the FreeBSD scheduler, processes are assigned kernel priorities when they block waiting for a kernel resource. These kernel priorities are higher than priorities held by userlevel processes and are ordered in importance. Kernel priorities exist to enable processes to release high-demand resources quickly <ref> [Vahalia 1996, Jolitz & Jolitz 1996, McKu-sick et al. 1996] </ref>. The solution to priority inversion described in [Wald-spurger & Weihl 1996] is for processes that are blocked on a resource to temporarily transfer their tickets to the process that holds the resource 2 .
Reference: [Lampson & Redell 1980] <author> Lampson, B. W. and Redell, D. D. </author> <title> Experiences with Processes and Monitors in Mesa. </title> <journal> Communications of the ACM, </journal> <volume> 23(2) </volume> <pages> 105-117, </pages> <month> Febru-ary </month> <year> 1980. </year>
Reference-contexts: This chance exists, but it is not common, since we only force a context switch when the event-receiving process has used less CPU that the running process, making it probable that it earns more effective tickets than the preempted processes. 3.2 Kernel Priorities Priority inversion <ref> [Lampson & Redell 1980, Birrell 1989, Hauser et al. 1993] </ref> is a well-documented problem in concurrent systems. Consider the following situation. A low priority process acquires a non-preemptable kernel resource such as a lock.
Reference: [Lampson 1984] <author> Lampson, B. W. </author> <title> Hints for Computer System Design. </title> <journal> IEEE Software, </journal> <volume> 1(1) </volume> <pages> 11-28, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: Apparently for performance considerations, this function violates the good programming practice that functions should "do one thing well." 5 <ref> [Lampson 1984] </ref> We modified cpu switch () to decouple the scheduling decision from the scheduling mechanism. Specifically, we rearrange some of the assembly code and make calls to a C function called lott choose next runner ().
Reference: [Lehey 1996] <author> Lehey, G. </author> <title> The Complete FreeBSD. </title> <publisher> Walnut Creek, </publisher> <month> September </month> <year> 1996. </year>
Reference-contexts: In some contexts, schedulers must ensure that processes meet real-time deadlines, although we are not concerned with such systems here. Following, we contrast the characteristics and goals of the FreeBSD scheduler with the lottery scheduler. 2.1 Scheduling in FreeBSD FreeBSD <ref> [Lehey 1996, FreeBSD 1997] </ref> is a UNIX [Ritchie & Thompson 1974] operating system for the Intel 80386 platform based on UC Berkeley's 4.4BSD-Lite [4.4BSD 1994, McKusick et al. 1996] release.
Reference: [Massalin & Pu 1989] <author> Massalin, H. and Pu, C. </author> <title> Threads and input/output in the synthesis kernel. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating System Principles, </booktitle> <volume> volume 23, </volume> <pages> pp. 191-201, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: Any lottery scheduling implementation with compensation tickets and currencies will be more computationally expensive than the FreeBSD scheduler. As our goal was to achieve comparable performance to FreeBSD, we expended much effort in optimizing our implementation. Motivated by <ref> [Massalin & Pu 1989] </ref> we factor invariants, defer work, use many inline functions, and aggressively cache computed values. The heart of the lottery scheduling algorithm is in lott - choose next runner ().
Reference: [McKusick et al. 1996] <author> McKusick, M. K., Bostic, K., Karels, M. J., and Quarterman, J. S. </author> <title> The Design and Implementation of the 4.4BSD Operating System. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <year> 1996. </year>
Reference-contexts: Following, we contrast the characteristics and goals of the FreeBSD scheduler with the lottery scheduler. 2.1 Scheduling in FreeBSD FreeBSD [Lehey 1996, FreeBSD 1997] is a UNIX [Ritchie & Thompson 1974] operating system for the Intel 80386 platform based on UC Berkeley's 4.4BSD-Lite <ref> [4.4BSD 1994, McKusick et al. 1996] </ref> release. FreeBSD's scheduler is a typical example of decay usage priority scheduling also used in System V and Mach with 100 ms time slices. The scheduler is implemented with a multilevel feedback queue. Processes with equal priority are placed onto the same queue.
Reference: [Nieh et al. 1994] <author> Nieh, J., Hanko, J. G., Northcutt, J. D., and Wall, G. A. </author> <title> SVR4 UNIX scheduler unacceptable for multimedia applications. </title> <booktitle> Lecture Notes in Computer Science, </booktitle> <volume> 846, </volume> <year> 1994. </year>
Reference-contexts: more as it doesn't have a chance to use its pages before they are evicted. [Waldspurger & Weihl 1994] explains that proportional-share resource management can be applied across diverse resources but does not provide an algorithm or policy by which an entire system can be scheduled toward optimal system performance. <ref> [Hauser et al. 1993, Nieh et al. 1994] </ref> suggest that adjusting priorities (tickets) toward higher-level scheduling goals is very difficult or intractable. We find the pursuit of more intelligent systemwide resource schedulers 10 an exciting research question.
Reference: [Parnas 1972] <author> Parnas, D. L. </author> <title> On the criteria to be used in decomposing systems into modules. </title> <journal> Communications of the ACM, </journal> <volume> 15(12) </volume> <pages> 1053-1058, </pages> <month> December </month> <year> 1972. </year>
Reference-contexts: We 5 The opaque structure of this function is the reason for, in our opinion, it remaining largely unmodified from the earliest version of the code that we found. <ref> [Parnas 1972] </ref> explains that systems should be decomposed based on "difficult design decisions or design decisions which are likely to change." We find the poor modulariza-tion of the FreeBSD scheduler unfortunate, as it impedes scheduler experimentation. 4 then multiply this value by the number of tickets that the process holds to
Reference: [Patterson et al. 1995] <author> Patterson, R. H., Gibson, G. A., Gint-ing, E., Stodolsky, D., and Zelenka, J. </author> <title> Informed prefetching and caching. </title> <booktitle> In Proceedings of the 15th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pp. 79-95, </pages> <month> December 3-6 </month> <year> 1995. </year>
Reference-contexts: We find the pursuit of more intelligent systemwide resource schedulers 10 an exciting research question. We envision a framework by which a process registers its scheduling goals and the operating system schedules system resources to the process based on ticket-like objects. A cost-benefit analysis such as in <ref> [Patterson et al. 1995] </ref> considers the types of resources requested and how other processes may be affected by having those resources revoked. 8 Conclusion We began this work with the goal of discovering why lottery scheduling, and by extension proportional-share scheduling, is not a standard part of modern operating systems.
Reference: [rc564 1997] <author> Project RC5, </author> <year> 1997. </year> <note> See http://www.distributed.- net/rc5/. </note>
Reference-contexts: Our poor results are presented in figure 5. Table 2 presents the data in these figures numerically. We now consider throughput of batch processes. Our test application is rc564 <ref> [rc564 1997] </ref>, a program that tries to find the solution to RSA's 64-bit secret-key challenge. To exacerbate the affect of our added overhead while running rc564, we also run a varying number of interactive processes.
Reference: [Ritchie & Thompson 1974] <author> Ritchie, D. M. and Thompson, K. </author> <title> The UNIX time-sharing system. </title> <journal> Communications of the ACM, </journal> <volume> 17(7) </volume> <pages> 365-375, </pages> <month> July </month> <year> 1974. </year>
Reference-contexts: In some contexts, schedulers must ensure that processes meet real-time deadlines, although we are not concerned with such systems here. Following, we contrast the characteristics and goals of the FreeBSD scheduler with the lottery scheduler. 2.1 Scheduling in FreeBSD FreeBSD [Lehey 1996, FreeBSD 1997] is a UNIX <ref> [Ritchie & Thompson 1974] </ref> operating system for the Intel 80386 platform based on UC Berkeley's 4.4BSD-Lite [4.4BSD 1994, McKusick et al. 1996] release. FreeBSD's scheduler is a typical example of decay usage priority scheduling also used in System V and Mach with 100 ms time slices.
Reference: [Shneiderman 1992] <author> Shneiderman, B. </author> <title> Designing the User Interface: Strategies for Effective Human-Computer Interaction. </title> <publisher> Addison-Wesley Publishing Co., </publisher> <address> Reading, MA, </address> <note> second edition, </note> <year> 1992. </year>
Reference-contexts: While we run interactive, we also run a CPU-bound process in the background. Again, we use the RDTSC cycle count instruction. We keep in mind that the minimum latency that humans can discern varies between 50-150 ms depending on the individual <ref> [Shneiderman 1992] </ref>. Figure 3 measures response time under the FreeBSD scheduler as a baseline. Due to the way timeouts are handled in FreeBSD, processes cannot sleep on a timer event for less than 20 ms. Figure 4 shows the same experiment under the lottery scheduler. We achieve very similar results.
Reference: [Vahalia 1996] <author> Vahalia, U. </author> <title> UNIX Internals: The New Frontiers. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ 07632, USA, </address> <year> 1996. </year>
Reference-contexts: In the FreeBSD scheduler, processes are assigned kernel priorities when they block waiting for a kernel resource. These kernel priorities are higher than priorities held by userlevel processes and are ordered in importance. Kernel priorities exist to enable processes to release high-demand resources quickly <ref> [Vahalia 1996, Jolitz & Jolitz 1996, McKu-sick et al. 1996] </ref>. The solution to priority inversion described in [Wald-spurger & Weihl 1996] is for processes that are blocked on a resource to temporarily transfer their tickets to the process that holds the resource 2 .
Reference: [Waldspurger & Weihl 1994] <author> Waldspurger, C. A. and Weihl, W. E. </author> <title> Lottery Scheduling: Flexible Proportional-Share Resource Mangement. </title> <booktitle> In Proceedings of the 1st USENIX Symposium on Operating Systems Design and Implementation, </booktitle> <pages> pp. 1-11, </pages> <month> November 14-17 </month> <year> 1994. </year>
Reference-contexts: 1 Introduction This paper explores the feasibility of proportional-share resource management in a modern and well-understood operating system. Specifically, we employ lottery scheduling <ref> [Waldspurger & Weihl 1994] </ref> to allocate processor time in FreeBSD 2.2.5R. We describe and evaluate our implementation, a hybrid of the FreeBSD scheduler and lottery scheduling, and relate our experiences in using this sched-uler on production machines. <p> processes, which generally block for a long period of time after using a small fraction of their quanta, are very likely to be chosen to run during the next scheduling decision after they wake up. 3 Design The preceding section described our first lottery scheduling implementation following the description in <ref> [Waldspurger & Weihl 1994] </ref>. With this implementation we were able to 2 control the relative execution rates of CPU-bound programs and insulate user workloads. In other areas the scheduler performed worse than the FreeBSD scheduler. <p> Unfortunately, this may simply cause the large process to page even more as it doesn't have a chance to use its pages before they are evicted. <ref> [Waldspurger & Weihl 1994] </ref> explains that proportional-share resource management can be applied across diverse resources but does not provide an algorithm or policy by which an entire system can be scheduled toward optimal system performance. [Hauser et al. 1993, Nieh et al. 1994] suggest that adjusting priorities (tickets) toward higher-level scheduling <p> Our initial implementation followed <ref> [Waldspurger & Weihl 1994] </ref> and enabled control over process execution rates and processor load insulation at the cost of system responsiveness. After examining the FreeBSD scheduler, we decided to apply both abbreviated quanta and kernel priorities to our lottery scheduler.
Reference: [Waldspurger & Weihl 1996] <author> Waldspurger, C. A. and Weihl, W. E. </author> <title> An objectoriented framework for modular resource management. </title> <booktitle> In Fifth Workshop on Object-Orientation in Operating Systems (IWOOOS '96), </booktitle> <month> October, </month> <year> 1996. </year> <institution> Seattle, WA, </institution> <year> 1996. </year>
Reference: [Waldspurger 1995] <author> Waldspurger, C. A. </author> <title> Lottery and Stride Scheduling: Flexible Proportional-Share Resource Management. </title> <type> PhD dissertation, </type> <institution> Massachusetts Institute of Technology, </institution> <month> September </month> <year> 1995. </year>
Reference-contexts: Now we demonstrate the features that we have gained by replacing FreeBSD's decay usage scheduler with lottery scheduling. These are simple measurements and we refer the reader to <ref> [Waldspurger 1995] </ref> for an extensive analysis of lottery scheduling. We demonstrate the ease at which a user can control the execution rate of his programs in figure 9. This figure shows three processes assigned tickets in a 3:2:1 ratio.
Reference: [xoopic 1997] <institution> XOOPIC Plasma Simulation Program, </institution> <year> 1997. </year> <note> See http://ptsg.eecs.berkeley.edu/xoopic/xoopic.html. 12 </note>
Reference-contexts: We determine that load insulation works on our deployed code by looking at the output of the UNIX top utility while two users run the CPU-bound processes xoopic and rc564. xoopic <ref> [xoopic 1997] </ref> is a particle-in-cell plasma simulation that calculates particle positions and velocities by discretiz-ing Maxwell's equations in time and space on a 2-D mesh. Tables 4 and 5 show the results.
References-found: 24

