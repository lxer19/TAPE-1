URL: http://www.eecs.umich.edu/~qstout/pap/IF97.ps
Refering-URL: http://www.eecs.umich.edu/~qstout/papers.html
Root-URL: http://www.cs.umich.edu
Title: A Parallel Program for 3-Arm Bandits  
Author: Janis Hardwick Robert Oehmke Quentin F. Stout 
Keyword: and phrases: multi-arm bandit problem, parallel computing, dynamic programming, adaptive allocation, sequential, clinical trial, high-performance computing, load balancing, recursive equations  
Address: Ann Arbor, Michigan 48109 USA  
Affiliation: Statistics Dept. EECS Dept. EECS Dept. University of Michigan  
Note: In Computing Science and Statistics 29 (1997), pp. 390-395.  
Abstract: We describe a new parallel program for optimizing and analyzing 3-arm Bernoulli bandit problems. Previous researchers had considered this problem computationally intractable, and we know of no previous exact optimizations of 3-arm bandit problems. Despite this, our program is able to solve problems of size 100 or more. We describe the techniques used to achieve this, and indicate various extensions of the program that enable it to solve a wide range of related problems. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Armitage, P. </author> <year> (1985), </year> <title> "The search for optimality in clinical trials", </title> <journal> Int. Statist. Rev. </journal> <volume> 53, </volume> <pages> pp. 15-24. </pages>
Reference-contexts: One reason for this is that many statisticians are unfamiliar with sequential designs, which are analytically and computationally more complex than fixed designs. For example, some typical comments concerning bandit models are "the computation involved is prohibitive except for trivially small horizons" <ref> [1] </ref> and "In theory the optimal strategies can always be found by dynamic programming but the computation required is prohibitive" [13].
Reference: [2] <author> Berry, D.A. and Eick, S.G. </author> <year> (1995), </year> <title> "Adaptive assignment versus balanced randomization in clinical trials | a decision-analysis", Stat. </title> <booktitle> in Medicine 14, </booktitle> <pages> pp. 231-246. </pages>
Reference-contexts: It is our understanding that, prior to our work, the largest 2-armed bandit problem that had been solved utilized a Cray 2 supercomputer around 1987 <ref> [2] </ref>. Using the Cray 2, Barry and Eick were able to handle a sample size of n = 200. In early 1991, we began working on improving algorithms for 2-armed bandits. <p> To do this typically requires repeated reevaluation of the design, and this ultimately becomes the most time-consuming part of the entire computational process. Prior to our introduction of forward induction, each such evaluation was evaluated via back ward induction (see, for example, <ref> [2] </ref>). For the 3-arm bandit, this would require fi (n 6 ) time. With forward induction [8], there is still a preprocessing step that requires fi (n 6 ) time and space, using only the space for the decision array and the space originally used to store V .
Reference: [3] <author> Berry, D.A. and Fristedt, B. </author> <year> (1985), </year> <title> Bandit Problems: Sequential Allocation of Experiments, </title> <publisher> Chap-man and Hall. </publisher>
Reference-contexts: They arise, for example, in the design of ethical clinical trials in which we wish to minimize failures that occur during the trial. In the fixed horizon version of a bandit problem, the goal is to minimize the total losses after n observations, where n is the horizon. See <ref> [3] </ref> for an in-depth discussion of bandit problems. In certain situations, bandit models can be dramatically superior to standard clinical trial models (and other statistical allocation problems) in which all sampling decisions have been made in advance.
Reference: [4] <author> Betensky, R. A. </author> <year> (1996), </year> <title> "An O'Brien-Fleming sequential trial for comparing three treatments", </title> <journal> Annals of Statistics 24 1765-1791. </journal>
Reference-contexts: Problems requiring solutions to 3-arm bandits have been considered intractable and we know of no prior work addressing exact, optimal solutions for fully sequential 3-arm problems. There has been asymptotic and ad hoc work on the topic of sequentially selecting among three populations (see for example <ref> [4] </ref> and [5]). The only exactly optimal solution that we know of for a 3-arm problem was carried out by Palmer in 1993 [11].
Reference: [5] <author> Coad, D. S. </author> <year> (1993), </year> <title> "Sequential allocation involving several treatments", Adaptive Designs (B. </title> <editor> Rosen-berger & N. Flournoy, ed.'s), </editor> <booktitle> Institute Math. Stat. Lec. Notes 25, </booktitle> <pages> pp. 95-109. </pages>
Reference-contexts: Problems requiring solutions to 3-arm bandits have been considered intractable and we know of no prior work addressing exact, optimal solutions for fully sequential 3-arm problems. There has been asymptotic and ad hoc work on the topic of sequentially selecting among three populations (see for example [4] and <ref> [5] </ref>). The only exactly optimal solution that we know of for a 3-arm problem was carried out by Palmer in 1993 [11]. Palmer optimized a 3-arm knock-out tournament in which one does vector-at-a-time sampling until 1 arm can be eliminated, and then does vector-at-a-time on the remaining 2 arms.
Reference: [6] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1993), </year> <title> "Exact computational analyses for adaptive designs", Adaptive Designs (B. </title> <editor> Rosenberger & N. Flournoy, ed.'s), </editor> <booktitle> Institute Math. Stat. Lec. Notes 25, </booktitle> <pages> pp. 223-237. </pages>
Reference-contexts: Our goals were to write parallel code that is efficient, portable, maintainable, and flexible. With these issues, of course, we wanted to maintain the efficiencies that had previously been exploited for 2-arm bandit-like problems (see <ref> [6] </ref>). The new parallel code is written in Fortran 77, with MPI for the message-passing among processors. While we were extending to 3 arms, and parallelizing the code, our major new computational issues were: 1. Space reduction (useful for both serial and parallel execution) 2. <p> It is simple to verify that since each of the inner loops is increasing, an array entry for a specific m values is overwritten (by the corresponding entry for m 1) after all reads of the value corresponding to m have occurred (see <ref> [6] </ref> for a further discussion of this point). This is a well-known space compression technique for bandit problems. The next observation is that only a corner of the 5-dimensional array is used, since we have the constraint that s3+f 3+s2+ f2 +s1+f 1 n.
Reference: [7] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1996), </year> <title> "Optimal allocation for estimating the mean of a bivariate polynomial", Sequential Analysis 15 71-90. </title>
Reference-contexts: The adaptive nature of the bandit model can significantly reduce costs or fatalities without sacrificing statistical objectives such as maximizing the probability of determining the best treatment. Adaptive, bandit-like statistical designs can also be used for estimation problems and many other objectives <ref> [7] </ref>, again with the possibility of dramatic savings. However, despite all of these advantages, experimental designs based on bandit models are almost never used. One reason for this is that many statisticians are unfamiliar with sequential designs, which are analytically and computationally more complex than fixed designs.
Reference: [8] <author> Hardwick, J. and Stout, Q.F. </author> <year> (1997), </year> <title> "Forward induction for evaluating sequential allocation procedures", </title> <note> to appear in SIAM J. Scientific and Statistical Computing. </note>
Reference-contexts: Fortunately, the decision array is written to once, and in later analyses is only read once. This is because nearly all analyses can be accomplished via forward induction <ref> [8] </ref>, which, after a single preprocessing pass through the decision array, reduces each evaluation to a computation over the final states. <p> Prior to our introduction of forward induction, each such evaluation was evaluated via back ward induction (see, for example, [2]). For the 3-arm bandit, this would require fi (n 6 ) time. With forward induction <ref> [8] </ref>, there is still a preprocessing step that requires fi (n 6 ) time and space, using only the space for the decision array and the space originally used to store V .
Reference: [9] <author> Jones, P. </author> <year> (1992), </year> <title> "Multiobjective Bayesian Ban--dits", Bayesian Statistics 4: </title> <booktitle> Proc. 4 th Valencia Int'l Meeting, </booktitle> <pages> pp. 689-695. </pages>
Reference-contexts: For 2-armed bandits, a typical example is Jones <ref> [9] </ref>, who solved a problem of size n = 25, and noted the difficulties of solving larger problems. Kulkarni and Kulkarni also noted that the computation required for 2-armed bandits make it "impractical to compute the decision even for moderate values of n 50" [10].
Reference: [10] <author> Kulkarni, R. and Kulkarni, V. </author> <year> (1987), </year> <title> "Optimal Bayes procedures for selecting the better of two Bernoulli populations", </title> <journal> J. Statistical Planning and Inference 15, </journal> <pages> pp. 311-330. </pages>
Reference-contexts: Kulkarni and Kulkarni also noted that the computation required for 2-armed bandits make it "impractical to compute the decision even for moderate values of n 50" <ref> [10] </ref>. It is our understanding that, prior to our work, the largest 2-armed bandit problem that had been solved utilized a Cray 2 supercomputer around 1987 [2]. Using the Cray 2, Barry and Eick were able to handle a sample size of n = 200.
Reference: [11] <author> Palmer, C. </author> <year> (1993), </year> <title> "Selecting the best of k treatments", Adaptive Designs (B. </title> <editor> Rosenberger & N. Flournoy, ed.'s), </editor> <booktitle> Institute Math. Stat. Lec. Notes 25, </booktitle> <pages> pp. 110-123. </pages>
Reference-contexts: There has been asymptotic and ad hoc work on the topic of sequentially selecting among three populations (see for example [4] and [5]). The only exactly optimal solution that we know of for a 3-arm problem was carried out by Palmer in 1993 <ref> [11] </ref>. Palmer optimized a 3-arm knock-out tournament in which one does vector-at-a-time sampling until 1 arm can be eliminated, and then does vector-at-a-time on the remaining 2 arms. This is not a bandit problem since the allocation strategy is partially fixed.
Reference: [12] <author> Simon, R. </author> <year> (1977), </year> <title> "Adaptive treatment assignment methods and clinical trials", </title> <type> Biometrics 33, </type> <pages> pp. 743-744. </pages>
Reference: [13] <author> Wang, Y.-G. </author> <year> (1991), </year> <title> "Sequential allocation in clinical trials", </title> <journal> Comm. in Statistics: Theory and Methods 20, </journal> <pages> pp. 791-805. </pages>
Reference-contexts: For example, some typical comments concerning bandit models are "the computation involved is prohibitive except for trivially small horizons" [1] and "In theory the optimal strategies can always be found by dynamic programming but the computation required is prohibitive" <ref> [13] </ref>. One of the main long-term goals of our project is to show that this is no longer true. 1.1 Previous Work Most previous work on exact optimizations of bandit designs for statistical models has concentrated on very small sample sizes, and on either 1-arm or 2-arm bandits.
References-found: 13

