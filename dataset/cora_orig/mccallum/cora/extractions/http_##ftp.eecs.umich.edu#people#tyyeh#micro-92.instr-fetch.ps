URL: http://ftp.eecs.umich.edu/people/tyyeh/micro-92.instr-fetch.ps
Refering-URL: http://ftp.eecs.umich.edu/people/tyyeh/
Root-URL: http://www.eecs.umich.edu
Title: A Comprehensive Instruction Fetch Mechanism for a Processor Supporting Speculative Execution  
Author: Tse-Yu Yeh and Yale N. Patt 
Address: Ann Arbor, Michigan 48109-2122  
Affiliation: Portland, Oregon.  Department of Electrical Engineering and Computer Science The University of Michigan  
Date: 129 139, December 1 4, 1992,  
Note: The 25th Annual International Symposium on Microarchitecture pp.  
Abstract: A superscalar processor supporting speculative execution requires an instruction fetch mechanism that can provide instruction fetch addresses as nearly correct as possible and as soon as possible in order to reduce the likelihood of throwing away speculative work. In this paper we propose a comprehensive instruction fetch mechanism to satisfy that need. Implementation issues are identified, possible solutions and designs for resolving those issues are simulated, and the results of these simulations are presented. A metric for measuring the average penalty of executing a branch instruction is introduced and used to evaluate the performance of our instruction fetch mechanism. We achieve an average performance of 4.19 IPC on the original SPEC benchmarks in a machine which can execute five instructions ideally by using the proposed mechanism. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> T-Y Yeh and Y.N. Patt, </author> <title> "Two-Level Adaptive Branch Prediction," </title> <booktitle> The 24th ACM/IEEE International Symposium and Workshop on Microarchitecture , (Nov. </booktitle> <year> 1991), </year> <pages> pp. 51-61. </pages>
Reference-contexts: Decreased latency means the newly directed instruction stream can begin execution faster. In this paper we propose a comprehensive instruction fetch mechanism for a superscalar processor supporting speculative execution. It consists of a conditional branch predictor, the Two-Level Adaptive Branch Predictor <ref> [1, 2, 3] </ref>, a cache for storing branch target addresses, a return address stack for storing the return addresses of subroutine calls, and a pipeline which can generate one predicted instruction fetch ad dress each cycle. <p> The prediction mechanisms for these four classes of branches and the comprehensive design of the instruction fetch mechanism to handle them are described below. 2.1 Conditional Branch Prediction We chose to use the Two-Level Adaptive branch predictor <ref> [1, 2, 3] </ref> and a branch target buffer for conditional branch predictions. The Two-Level Adaptive branch predictor achieves substantially higher accuracy in predicting branch paths than other dynamic conditional branch prediction schemes. The branch target buffer reduces the delay in providing instruction fetch addresses.
Reference: [2] <author> T-Y Yeh and Y.N. Patt, </author> <title> "Two-Level Adaptive Branch Prediction," </title> <type> Technical Report CSE-TR-117-91, </type> <institution> Computer Science and Engineering Division, Department of EECS, The University of Michigan, </institution> <month> (Nov. </month> <year> 1991). </year>
Reference-contexts: Decreased latency means the newly directed instruction stream can begin execution faster. In this paper we propose a comprehensive instruction fetch mechanism for a superscalar processor supporting speculative execution. It consists of a conditional branch predictor, the Two-Level Adaptive Branch Predictor <ref> [1, 2, 3] </ref>, a cache for storing branch target addresses, a return address stack for storing the return addresses of subroutine calls, and a pipeline which can generate one predicted instruction fetch ad dress each cycle. <p> The prediction mechanisms for these four classes of branches and the comprehensive design of the instruction fetch mechanism to handle them are described below. 2.1 Conditional Branch Prediction We chose to use the Two-Level Adaptive branch predictor <ref> [1, 2, 3] </ref> and a branch target buffer for conditional branch predictions. The Two-Level Adaptive branch predictor achieves substantially higher accuracy in predicting branch paths than other dynamic conditional branch prediction schemes. The branch target buffer reduces the delay in providing instruction fetch addresses.
Reference: [3] <author> T-Y Yeh and Y.N. Patt, </author> <title> "Alternative Implemenations of Two-Level Adaptive Branch Prediction," </title> <booktitle> Proceedings of the 19th Internations Symposium on Computer Architecture, </booktitle> <month> (May </month> <year> 1992), </year> <pages> pp. 124-134. </pages>
Reference-contexts: Decreased latency means the newly directed instruction stream can begin execution faster. In this paper we propose a comprehensive instruction fetch mechanism for a superscalar processor supporting speculative execution. It consists of a conditional branch predictor, the Two-Level Adaptive Branch Predictor <ref> [1, 2, 3] </ref>, a cache for storing branch target addresses, a return address stack for storing the return addresses of subroutine calls, and a pipeline which can generate one predicted instruction fetch ad dress each cycle. <p> Section four discusses the simulation models and traces used in this study. Section five reports the simulation results and our analysis. Section six contains some concluding remarks. 2 Instruction Fetch Mechanism Design Approximately 20 percent of dynamic instructions are branch instructions as shown in the trace analysis in <ref> [3] </ref>. Since multiple instructions are issued each cycle, it is likely that at least one branch is issued ev ery cycle in a wide-issue machine. Most branches can not be resolved as soon as they are fetched. <p> The prediction mechanisms for these four classes of branches and the comprehensive design of the instruction fetch mechanism to handle them are described below. 2.1 Conditional Branch Prediction We chose to use the Two-Level Adaptive branch predictor <ref> [1, 2, 3] </ref> and a branch target buffer for conditional branch predictions. The Two-Level Adaptive branch predictor achieves substantially higher accuracy in predicting branch paths than other dynamic conditional branch prediction schemes. The branch target buffer reduces the delay in providing instruction fetch addresses. <p> If the branch is an indirect branch, its target address is not available until the source register value is calculated. Speculative updates of branch history with predictions were suggested in <ref> [3] </ref> to provide the Two-Level Adaptive conditional branch predictor the most-recent Ain Update Cycle Phase T1 T2 T3 T4 i i+1 i+2 I-Cache BHTRead BHT Update BHR PHTRead PHTUpdate Ain Access Dout Ain Access Dout Ain Access Dout ADDRi Ain Access Dout ADDRi+1INSTi INSTi+1 ADDRi ADDRi+1 BHRi Prdi BHRi+1 Prdi+1 BHT <p> Pattern table updates, on the other hand, are delayed until the branch results become ready. We simulate the update delay in this study to show that the delay has negligible effect on performance. In addition, lookahead prediction is also suggested in <ref> [3] </ref> to make predicting a branch in one cycle possible. An extra prediction bit in the branch target buffer entry is used to store the prefetched prediction from the pattern history table by using the speculatively-updated branch history. Therefore, the prediction for the next execution requires only one table access. <p> N asa7 is not included because it takes too long to capture the branch behavior of all seven kernels. The work load is the same as used in <ref> [3] </ref>. The profiling of the benchmarks is done by using a separate training data set from the one used in testing. The number of static branches in the trace when each program is executed with the test data set is listed in Table 2. <p> For the P Ag mechanism, the 12-bit per-address Two-level Adaptive conditional predictor achieves 97 percent average conditional branch prediction accuracy over the nine original SPEC benchmarks with the least hardware cost among the variations of Two-level Adaptive branch predictors. The detailed study was presented in <ref> [3] </ref>. Since there are more taken than not taken branches according to our simulation results, a history register in the branch history table is initialized to all 1's when an entry is allocated. <p> The delivered machine performance is translated from the branch execution penalties shown in Figure 8 and the branch probability in each program by using Equation 5. The IIPC is set to five, because the average basic block size is five instructions in our traces <ref> [3] </ref> and our issue mechanism is limited to issue at most one basic block per cycle.
Reference: [4] <author> M. Butler, T-Y Yeh, Y.N. Patt, M. Alsup, H. Scales, and M. Shebanow, </author> <title> "Instruction Level Parallelism is Greater Than Two," </title> <booktitle> Proceedings of the 18th International Symposium on Computer Architecture, </booktitle> <month> (May. </month> <year> 1991), </year> <pages> pp. 276-286. </pages>
Reference: [5] <author> D.R. Kaeli and P.G. Emma, </author> <title> "Branch History Table Prediction of Moving Target Branches Due to Subroutine Returns" , Proceedings of the 18th International Symposium on Computer Architecture, </title> <month> (May </month> <year> 1991), </year> <pages> pp. 34-42. </pages>
Reference: [6] <author> Motorola Inc., </author> <title> "M88100 User's Manual," </title> <address> Phoenix, Ari-zona, (March 13, </address> <year> 1989). </year>
Reference: [7] <author> W.W. Hwu, T.M.Conte, and P.P.Chang, </author> <title> "Comparing Software and Hardware Schemes for Reducing the Cost of Branches," </title> <booktitle> Proceedings of the 16th International Symposium on Computer Architecture, </booktitle> <month> (May </month> <year> 1989). </year>
Reference-contexts: Machines using a static branch predictor without a branch target buffer must wait for the target address to be generated if the branch is predicted taken but not if the branch is predicted not taken. Trace scheduling [17] and Superblock scheduling <ref> [7] </ref> can reduce this delay by rearranging the instructions so that the fall-through path is the more likely branch path. The percentage of taken conditional branches can be reduced from 62 percent to approximately 50 percent by using trace scheduling.
Reference: [8] <author> N.P. Jouppi and D. Wall, </author> <title> "Available Instruction-Level Parallelism for Superscalar and Superpipelined Machines," </title> <booktitle> Proceedings of the Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> (April </month> <year> 1989), </year> <pages> pp. 272-282. </pages>
Reference: [9] <author> D.J. Lilja, </author> <title> "Reducing the Branch Penalty in Pipelined Processors," </title> <booktitle> IEEE Computer, </booktitle> <month> (July </month> <year> 1988), </year> <month> pp.47-55. </month>
Reference: [10] <author> W.W. Hwu and Y.N. Patt, </author> <title> "Checkpoint Repair for Out-of-order Execution Machines," </title> <journal> IEEE Transactions on Computers, </journal> <month> (December </month> <year> 1987), </year> <month> pp.1496-1514. </month>
Reference: [11] <author> P.G. Emma and E.S. Davidson, </author> <title> "Characterization of Branch and Data Dependencies in Programs for Evaluating Pipeline Performance" , IEEE Transactions on Computers, </title> <month> (July </month> <year> 1987), </year> <month> pp.859-876. </month>
Reference: [12] <author> J.A. DeRosa and H.M. Levy, </author> <title> "An Evaluation of Branch Architectures," </title> <booktitle> Proceedings of the 14th International Symposium on Computer Architecture, </booktitle> <month> (June </month> <year> 1987), </year> <month> pp.10-16. </month>
Reference: [13] <author> D.R. Ditzel and H.R. McLellan, </author> <title> "Branch Folding in the CRISP Microprocessor: Reducing Branch Delay to Zero," </title> <booktitle> Proceedings of the 14th International Symposium on Computer Architecture, </booktitle> <month> (June </month> <year> 1987), </year> <month> pp.2-9. </month>
Reference: [14] <author> S. McFarling and J. Hennessy, </author> <title> "Reducing the Cost of Branches," </title> <booktitle> Proceedings of the 13th International Symposium on Computer Architecture, </booktitle> <year> (1986), </year> <month> pp.396-403. </month>
Reference: [15] <author> J. Lee and A.J. Smith, </author> <title> "Branch Prediction Strategies and Branch Target Buffer Design," </title> <booktitle> IEEE Computer, </booktitle> <month> (January </month> <year> 1984), </year> <month> pp.6-22. </month>
Reference: [16] <author> T.R. Gross and J. Hennessy, </author> <title> "Optimizing Delayed Branches," </title> <booktitle> Proceedings of the 15th Annual Workshop on Microprogramming, </booktitle> <month> (Oct. </month> <year> 1982), </year> <month> pp.114-120. </month>
Reference: [17] <author> J. Fisher, </author> <title> "Trace Scheduling: A Technique for Global Microcode Compaction," </title> <journal> IEEE Transactions on Computer, </journal> <month> (July </month> <year> 1981), </year> <note> C-30, pp.478-490. </note>
Reference-contexts: Machines using a static branch predictor without a branch target buffer must wait for the target address to be generated if the branch is predicted taken but not if the branch is predicted not taken. Trace scheduling <ref> [17] </ref> and Superblock scheduling [7] can reduce this delay by rearranging the instructions so that the fall-through path is the more likely branch path. The percentage of taken conditional branches can be reduced from 62 percent to approximately 50 percent by using trace scheduling.
Reference: [18] <author> J.E. Smith, </author> <title> "A Study of Branch Prediction Strategies," </title> <booktitle> Proceedings of the 8th International Symposium on Computer Architecture, </booktitle> <month> (May. </month> <year> 1981), </year> <month> pp.135-148. </month>
Reference-contexts: Its structure is shown in Figure 1. The combined BTB stores address and prediction information of conditional branches, unconditional branches, and returns. The J S uses a combined 512-entry BTB, J. Smith's 2-bit up-down saturating counter scheme <ref> [18] </ref> for conditional branch prediction, and a 32-entry RAS. P ROF is an example of instruction fetch mechanisms which use static conditional branch predictors requiring no hardware support. The target addresses of taken conditional branches and immediate unconditional branches are not available until they are calculated from the decoded instructions.
References-found: 18

