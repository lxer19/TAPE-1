URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3533/3533.ps.Z
Refering-URL: http://www.cs.umd.edu/TRs/TR.html
Root-URL: 
Title: The Triangular Matrices of Gaussian Elimination and Related Decompositions  
Author: G. W. Stewart 
Date: October, 1995  
Affiliation: University of Maryland College Park Institute for Advanced Computer Studies TR-95-91 Department of Computer Science  
Pubnum: TR-3533  
Abstract: It has become a commonplace that triangular systems are solved to higher accuracy than their condition would warrant. This observation is not true in general, and counterexamples are easy to construct. However, it is often true of the triangular matrices from pivoted LU or QR decompositions. It is shown that this fact is closely connected with the rank-revealing character of these decompositions. fl This report is available by anonymous ftp from thales.cs.umd.edu in the directory pub/reports. y Department of Computer Science and Institute for Advanced Computer Studies, University of Maryland, College Park, MD 20742. This work was supported in part by the National Science Foundation under grant CCR 95503126. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> G. H. Golub. </author> <title> Numerical methods for solving least squares problems. </title> <journal> Nu-merische Mathematik, </journal> <volume> 7 </volume> <pages> 206-216, </pages> <year> 1965. </year>
Reference-contexts: Thus the R factor from a pivoted QR factorization is another source of triangular systems that tend to be solved accurately. These results possibly explain an observation of Golub on the use of Householder transformations to solve least squares problems <ref> [1] </ref>. He noted that column pivoting slightly improved the accuracy of the computed solutions. From the point of view taken here, pivoting would make the R more rank revealing and hence the QR equations for the least squares solution would be solved more accurately.
Reference: [2] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> Johns Hopkins University Press, </publisher> <address> Baltimore, Maryland, 2nd edition, </address> <year> 1989. </year>
Reference-contexts: The paper concludes with a brief recapitulation. In the following, k k denotes the 2-norm. We will make free use of the properties of the singular value decomposition. For details see <ref> [2, 4, 6] </ref>. 2. Lower bounds for singular values The purpose of this section is to show that a triangular matrix whose principal minors reveal their rank becomes well conditioned when its rows are equilibrated.
Reference: [3] <author> N. J. Higham. </author> <title> Accuracy and Stability of Numerical Algorithms. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1995. </year> <note> To appear. </note>
Reference-contexts: The matrix L is well conditioned. The first of these consequences implies that systems involving U will be solved accurately, since the best bounds on the accuracy of the solution do not depend on row scaling <ref> [3] </ref>. The second implies ipso facto that systems involving L will be solved accurately. It might be objected that we have traded one mystery for another | the other being that Gaussian elimination tends to be rank revealing. The proper response is that it is not very mysterious.
Reference: [4] <author> R. A. Horn and C. R. Johnson. </author> <title> Topics in Matrix Analysis. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1991. </year> <title> The Triangular Matrices of Gaussian Elimination 11 </title>
Reference-contexts: The paper concludes with a brief recapitulation. In the following, k k denotes the 2-norm. We will make free use of the properties of the singular value decomposition. For details see <ref> [2, 4, 6] </ref>. 2. Lower bounds for singular values The purpose of this section is to show that a triangular matrix whose principal minors reveal their rank becomes well conditioned when its rows are equilibrated.
Reference: [5] <author> G. W. Stewart. </author> <title> The efficient generation of random orthogonal matrices with an application to condition estimators. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 17 </volume> <pages> 403-404, </pages> <year> 1980. </year>
Reference-contexts: Since the bound is nearly attained, we observe a small singular value in D 1 U . The numbers in the second column come from the R factor in a pivoted QR decomposition of the U in column one. Such a decomposition is generally an excellent rank revealer <ref> [5] </ref>, and indeed we observe that the bounds and the smallest singular value are near one. We will discuss the experiments of the third and fourth columns after we apply our results to Gaussian elimination. <p> The pivoting insures that r 2 j X r 2 The pivoted QR decomposition is known empirically to reveal the rank of A in the following sense <ref> [5] </ref>. If A k denotes the matrix consisting of the first k columns of A, then r kk is an approximation to the smallest singular value of A k .
Reference: [6] <author> G. W. Stewart and J.-G. Sun. </author> <title> Matrix Perturbation Theory. </title> <publisher> Academic Press, </publisher> <address> Boston, </address> <year> 1990. </year>
Reference-contexts: The paper concludes with a brief recapitulation. In the following, k k denotes the 2-norm. We will make free use of the properties of the singular value decomposition. For details see <ref> [2, 4, 6] </ref>. 2. Lower bounds for singular values The purpose of this section is to show that a triangular matrix whose principal minors reveal their rank becomes well conditioned when its rows are equilibrated.
Reference: [7] <author> G. W. Stwart. </author> <title> On sublinear convergence. </title> <type> Technical Report CS-TR-3534 UMIACS-TR-95-92, </type> <institution> University of Maryland, Department of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: values of the lower bounds for k when fi k is held 6 The Triangular Matrices of Gaussian Elimination constant. fi 5 2:4e1 5:0e2 5:0e3 100 5:0e2 1:0e2 1:0e3 In fact it can be shown that in the limit the iterates approach fi= p general theory of sublinear convergence see <ref> [7] </ref>.) The price we pay for these slowly decreasing bounds is the requirement that U satisfy a strong rank-revealing condition. The diagonals of U must not just approximate the corresponding singular values of U but instead must approximate the smallest singular value of the corresponding leading principal submatrix.
Reference: [8] <author> G. W. Stwart. </author> <title> On the perturbation of LU and Cholesky factors. </title> <type> Technical Report CS-TR-3535 UMIACS-TR-95-93, </type> <institution> University of Maryland, Department of Computer Science, </institution> <year> 1995. </year>
Reference-contexts: These results have implications for the perturbation theory of the LU decomposition. Let A + E have the LU decomposition (L + F L )(U + F U ) and let S be an arbitrary nonsingular diagonal matrix. The author has shown <ref> [8] </ref> that for any absolute norm k k kF U k (L)(SU ) kAk The Triangular Matrices of Gaussian Elimination 9 where as usual (X) = kXkkX 1 k.
Reference: [9] <author> L. N. Trefethen and R. S. Schreiber. </author> <title> Average-case stability of Gaussian elimination. </title> <journal> SIAM Journal on Matrix Analysis and Applications, </journal> <volume> 11 </volume> <pages> 335-360, </pages> <year> 1990. </year>
Reference-contexts: Gaussian elimination In applying our results to Gaussian elimination, we will have to make use of some empirical facts about the growth of elements in course of the algorithm. For experiments and analyses concerning this important topic, see the paper by Trefethen and Schreiber <ref> [9] </ref>. Let the matrix A of order n be decomposed by Gaussian elimination with pivoting, so that P T AQ = LDU; where P and Q are permutation matrices, L is a unit lower triangular matrix, and U is unit upper triangular. <p> The fact | critical to our analysis | that L and U are of modest size is guaranteed for complete pivoting, but for partial pivoting what inhibits growth of the elements of U is imperfectly understood <ref> [9] </ref>. For the pivoted QR and Cholesky factorizations we need no auxiliary hypothesis about the sizes of the triangular factor. All we need to believe is that the factorizations reveal rank. Perhaps the most unusual feature of the analysis is the nature of the recursion (2.5).
Reference: [10] <author> J. H. Wilkinson. </author> <title> Error analysis of direct methods of matrix inversion. </title> <journal> Journal of the ACM, </journal> <volume> 8 </volume> <pages> 281-330, </pages> <year> 1961. </year>
Reference-contexts: 1. Introduction In 1961 J. H. Wilkinson <ref> [10] </ref> published a ground-breaking error analysis of Gaussian elimination. In the course of the paper he observed that triangular systems are frequently solved more accurately than their condition would warrant. In support of this observation he offered some examples and suggestive analyses, but no general theorems.
References-found: 10

