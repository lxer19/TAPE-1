URL: ftp://www.cs.rutgers.edu/pub/technical-reports/dcs-tr-332.ps.Z
Refering-URL: http://www.cs.rutgers.edu/pub/technical-reports/
Root-URL: 
Email: E-mail: liberato@cs.rutgers.edu.  E-mail: farach@cs.rutgers.edu.  E-mail: uli@cs.rutgers.edu.  
Phone: 3  4  
Title: Hardness and Algorithms for Local Register Allocation  
Author: Vincenzo Liberatore Martin Farach Ulrich Kremer 
Web: URL: http://www.cs.rutgers.edu/~liberato/.  URL: http://www.cs.rutgers.edu/~farach/.  URL: http://www.cs.rutgers.edu/~uli/.  
Address: New Brunswick, NJ 08903.  New Brunswick, NJ 08903  700 Mountain Avenue, Murray Hill, NJ 07974.  New Brunswick, NJ 08903.  
Affiliation: Department of Computer Science, Hill Center, Rutgers University,  Department of Computer Science, Hill Center, Rutgers University,  and Information Sciences Research Center, Bell Labs,  Department of Computer Science, Hill Center, Rutgers University,  
Note: 1 Research partly supported by NSF Career Development Award CCR-9501942, NATO Grant CRG 960215, NSF/NIH Grant BIR 94-12594-03-CONF and an Alfred P. Sloan Research Fellowship. 2  
Date: July 18, 1997  
Abstract-found: 0
Intro-found: 1
Reference: [AMO93] <author> Ravindra K. Ahuja, Thomas L. Magnanti, and James B. Orlin. </author> <title> Network Flows. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliff, NJ, </address> <year> 1993. </year>
Reference-contexts: Value ranges extend over intervals of the basic block. 2 Matrices with the consecutive ones property are totally unimodular and correspond to network flow problems. Therefore, those matrices define problems that can be solved efficiently and that always yield an integral solution <ref> [AMO93] </ref>. The total unimodularity of N implies that the constraints that the y ik 's be binary can be substituted with the much weaker continuous constraints 0 y ik 1 (i = 1; 2; : : :; M and k = 1; 2; : : :; K (i)). <p> Since N constitutes a large fraction of constraints, the initial linear relaxation of (1) can be efficiently solved as a network flow problem with side constraints <ref> [AMO93] </ref>. Finally, we expect the running time of the branch-and-bound algorithm to decrease as N increases. Indeed, more basic blocks can be scheduled without spilling as N increases.
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Then, the compiler executes a hierarchical register allocation pass. In both compilers, register allocation remains an independent pass and a good register allocator results in good compiled code. Register allocators of the past often operated under a schedule of instruction that strived to achieve minimum register sufficiency <ref> [ASU86, SU70] </ref>. Consequently, the register allocator was helped by the instruction scheduling to achieve minimum spill cost. When register allocation operates under a compromise ILP/register-pressure scheduling, the allocator cannot rely any longer on the scheduling to produce an easy problem. Today's register allocators face critical problems that never appeared before. <p> We will denote with L the set of pseudo-registers alive at the end of the basic block. The set L can be determined by live-variable analysis or we can simply assume that L = V <ref> [ASU86] </ref>. Our theoretical results hold for both choices of L. Our model of local register allocation is more realistic than that in previous papers. First, previous works counted each load and store as a unit of cost.
Reference: [BCT94] <author> Preston Briggs, Keith D. Cooper, and Linda Torczon. </author> <title> Improvements to graph color ing register allocation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 16(3) </volume> <pages> 428-455, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: Once a compromise instruction scheduling has been fixed, the register allocator proper is invoked to obtain a good allocation under the given schedule. For example, in the MIPSpro compiler [RGSL96], the instruction scheduling is followed by the invocation of the Chaitin-Briggs algorithm <ref> [BCT94] </ref>. Another example is the ACAPS compilers [NG93] that performs a scheduling phase to find a time-optimal scheduling with minimal buffer allocation. Then, the compiler executes a hierarchical register allocation pass. In both compilers, register allocation remains an independent pass and a good register allocator results in good compiled code. <p> Our cost model is similar to that in <ref> [BCT94] </ref> and allows us to keep track of simple rematerializations. In this paper, floating point operations are assumed to cost as much as integer ones. However, the cost model can be modified to include different operation costs. The augmented cost model enjoys most of the theoretical properties described below [FL97].
Reference: [Bel66] <author> L. A. Belady. </author> <title> A study of replacement algorithms for a virtual storage computer. </title> <journal> IBM Systems Journal, </journal> <volume> 5(2) </volume> <pages> 78-101, </pages> <year> 1966. </year>
Reference-contexts: The oldest is probably Furthest-First (FF): if no register is empty, evict the pseudo-register that is requested furthest in the future <ref> [Bel66] </ref>. FF is not necessarily optimum | compare figure 2 with figure 1. Unlike FF, the optimum LRA keeps into account both distance to the next reference and eviction costs. FF and other heuristics are discussed in section 5. <p> In the next section, we will compare the optimum with the heuristics. 5 Heuristics We experimented with three heuristics. Each heuristic specifies which pseudo-register is to be evicted if no empty register is available. Furthest-First (FF) evict a pseudo-register that is used furthest in the future <ref> [Bel66] </ref>. Clean-First (CF) evict a clean pseudo-register that is used furthest in the future.
Reference: [FH92] <author> Christopher W. Fraser and David R. Hanson. </author> <title> Simple register spilling in a retargetable compiler. </title> <journal> Software | Practice and Experience, </journal> <volume> 22(1) </volume> <pages> 85-99, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: We did not find in the literature any explicit mention of the running time of FF or CF, nor any reference to a careful implementation of those heuristics. However, we did find an implementation of FF with enough details to establish that no refined data structure is used <ref> [FH92] </ref>. We implemented CFF with binary heaps. The code is somewhat longer than that in the previous straightforward implementation of FF, but CFF is roughly eight times faster on SPEC benchmarks. <p> We now specify the tie-breaking rule for FF that has been implemented in an existing compiler: break ties by evicting the pseudo-register that occupies the lowest number register <ref> [FH92] </ref>. The heuristic adopting this rule will be denoted as FFi, or, when no confusion can arise, simply as FF. 5.1 Worst-Case Analysis We will examine the worst-case performance of the heuristics under the following stringent non-compulsory load cost model. <p> general, it can be shown that CFF is never 4 times worse than the optimum even if we account only for non-compulsory loads and stores [FL97]. 5.2 Implementation Issues A current implementations of FF searches for a register to evict by repeatedly scanning the register file and the basic block <ref> [FH92] </ref>. Henceforth, we will assume that FF uses this strategy. We propose an implementation of CFF with a priority queue.
Reference: [FL88] <author> Charles N. Fischer and Richard J. LeBlanc, Jr. </author> <title> Crafting a Compiler. </title> <editor> Ben jamin/Cummings, </editor> <address> Menlo Park, CA, </address> <year> 1988. </year>
Reference-contexts: Furthest-First (FF) evict a pseudo-register that is used furthest in the future [Bel66]. Clean-First (CF) evict a clean pseudo-register that is used furthest in the future. If no clean pseudo-register exists, evict a dirty pseudo-register that is requested furthest in the future <ref> [FL88] </ref>. 3 CPLEX is a trademark of CPLEX Optimization, Inc. 10 Conservative-Furthest-First (CFF) determine the set S of pseudo-registers that are requested furthest in the future. Evict a clean pseudo-register in S. If all pseudo-register in S are dirty, evict an element of S arbitrarily.
Reference: [FL97] <author> Martin Farach and Vincenzo Liberatore. </author> <title> On local register allocation. </title> <type> Technical Report TR97-33, </type> <institution> DIMACS, </institution> <year> 1997. </year>
Reference-contexts: In this paper, floating point operations are assumed to cost as much as integer ones. However, the cost model can be modified to include different operation costs. The augmented cost model enjoys most of the theoretical properties described below <ref> [FL97] </ref>. The set S = fclean; dirtyg is the set of register states, which are explained as follows. Suppose that a pseudo-register i is in the actual register h. <p> Proof Sketch. The reduction is from set cover. The involved argument is found in <ref> [FL97] </ref>. 2 3 Experimental Setup We performed experiments with ILOC, the Intermediate Language for Optimizing Compilers developed at Rice University 1 . We used several ILOC routines from the fmm and SPEC benchmarks. <p> No allocation can improve on these compulsory loads once the initial register contents are given. The non-compulsory spill cost of CFF is never 4 times worse than the optimum <ref> [FL97] </ref>. By contrast, we will now show that neither FF nor CF have a performance guarantee in the worst case. First, consider CF. Construct a reference sequence block that fills all the register but one with dirty variables. <p> CFF is similar to FF, but it breaks ties carefully. In this example, CFF does not pay any non-compulsory cost. In general, it can be shown that CFF is never 4 times worse than the optimum even if we account only for non-compulsory loads and stores <ref> [FL97] </ref>. 5.2 Implementation Issues A current implementations of FF searches for a register to evict by repeatedly scanning the register file and the basic block [FH92]. Henceforth, we will assume that FF uses this strategy. We propose an implementation of CFF with a priority queue.
Reference: [HFG89] <author> Wei-Chung Hsu, Charles N. Fischer, and James R. Goodman. </author> <title> On the minimization of load/stores in local register allocation. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(10) </volume> <pages> 1252-1260, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Therefore, it reflects actual performance issues better than register sufficiency and graph coloring. It is then no surprise that local register allocation has retained its fundamental role over the years. A compelling case for local register allocation is made in the paper by Hsu, Fischer, and Goodman <ref> [HFG89] </ref>. Local register allocation has been extensively studied, but it was not quite well understood yet. Two major problems in local register allocation were open before this paper: the intrinsic complexity of the problem, and the quality and the speed of the heuristics. <p> Pitfall: The exact optimum for local register allocation is very hard to obtain even with a small register file. Previous to this paper, the only known algorithm was based on dynamic programming and failed to terminate even with only four registers due to exponential memory requirements <ref> [HFG89] </ref>. In this paper, we present a new integer programming formulation and a new branch-and-bound algorithm. The branch-and-bound algorithm takes only a polynomial amount of space, never ran out of space on our benchmarks, and always reported an optimum solution. <p> worst-case performance guarantee, the quality of the allocation is close to the optimum on common benchmarks. - CFF is implemented to run roughly two to eleven times faster than other heuristics on SPEC benchmarks. 2 Local Register Allocation Our model for local register allocation follows mostly Hsu, Fischer, and Goodman <ref> [HFG89] </ref> and it is consistent with other previous works [HKMW66, Ken72, Luc67]. The model is based on architectures with general purpose registers. Our model extends previous formulations and reflects more realistically actual architectures and instruction sets. <p> The previous optimum algorithm was based on dynamic programming <ref> [HKMW66, Luc67, HFG89] </ref>, took an exponential amount of space in the worst case, and failed to terminate on a few benchmarks due to the lack of memory space. The branch-and-bound algorithm is space-efficient.
Reference: [HGAM93] <author> Laurie J. Hendren, Guang R. Gao, Erik R. Altman, and Chandrika Mukerji. </author> <title> A register allocation framework based on hierarchical cyclic interval graphs. </title> <type> ACAPS Technical Memo 33, </type> <institution> McGill University, </institution> <month> February </month> <year> 1993. </year> <month> 13 </month>
Reference-contexts: Local register allocation precedes global allocation in the FORTRAN IV compiler for a HITAC-5020 [Nak67] and in the Fortran H compiler for the IBM System/360 [LM69]. At the other chronological extreme, the ACAPS hierarchical allocator extends a local allocation into a global allocation <ref> [HGAM93] </ref>. 1 Local register allocation has been a crucial task for optimizing compilers for more than two decades and, in the classification of [HP96], for at least two computer generations. The objective of local register allocation is to minimize the total traffic between the register file and the memory system.
Reference: [HKMW66] <author> L. P. Horwitz, R. M. Karp, R. E. Miller, and S. Winograd. </author> <title> Index register allocation. </title> <journal> Journal of the Association for Computing Machinery, </journal> <volume> 13(1) </volume> <pages> 43-61, </pages> <month> January </month> <year> 1966. </year>
Reference-contexts: close to the optimum on common benchmarks. - CFF is implemented to run roughly two to eleven times faster than other heuristics on SPEC benchmarks. 2 Local Register Allocation Our model for local register allocation follows mostly Hsu, Fischer, and Goodman [HFG89] and it is consistent with other previous works <ref> [HKMW66, Ken72, Luc67] </ref>. The model is based on architectures with general purpose registers. Our model extends previous formulations and reflects more realistically actual architectures and instruction sets. Let V = f1; 2; : : :; M g be a set of pseudo-registers. Pseudo-registers will contain temporary variables and constants. <p> The previous optimum algorithm was based on dynamic programming <ref> [HKMW66, Luc67, HFG89] </ref>, took an exponential amount of space in the worst case, and failed to terminate on a few benchmarks due to the lack of memory space. The branch-and-bound algorithm is space-efficient.
Reference: [HP96] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <note> second edition, </note> <year> 1996. </year>
Reference-contexts: At the other chronological extreme, the ACAPS hierarchical allocator extends a local allocation into a global allocation [HGAM93]. 1 Local register allocation has been a crucial task for optimizing compilers for more than two decades and, in the classification of <ref> [HP96] </ref>, for at least two computer generations. The objective of local register allocation is to minimize the total traffic between the register file and the memory system. Therefore, it reflects actual performance issues better than register sufficiency and graph coloring. <p> The dynamic weighted instruction count is given by P basic block B (number of times B was executed) fi (weighted instruction count for B). The experimental results are given in the following tables for N = 16; 32; 64, which are representative cases of today's register file sizes <ref> [HP96] </ref>. The time is the time taken by the heuristics to run in seconds. It does not include the time to read the input file nor the time to perform live range analysis. The cost is the total weighted dynamic instruction count in thousands.
Reference: [Ken72] <author> Ken Kennedy. </author> <title> Index register allocation in straight line code and simple loops. </title> <editor> In Randall Rustin, editor, </editor> <booktitle> Design and Optimization of Compilers, </booktitle> <pages> pages 51-63. </pages> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1972. </year>
Reference-contexts: close to the optimum on common benchmarks. - CFF is implemented to run roughly two to eleven times faster than other heuristics on SPEC benchmarks. 2 Local Register Allocation Our model for local register allocation follows mostly Hsu, Fischer, and Goodman [HFG89] and it is consistent with other previous works <ref> [HKMW66, Ken72, Luc67] </ref>. The model is based on architectures with general purpose registers. Our model extends previous formulations and reflects more realistically actual architectures and instruction sets. Let V = f1; 2; : : :; M g be a set of pseudo-registers. Pseudo-registers will contain temporary variables and constants.
Reference: [Kre98] <author> Ulrich Kremer. </author> <title> Optimal and near-optimal solution for hard compilation problems. </title> <note> Parallel Processing Letters, 1998. To appear. </note>
Reference-contexts: The algorithm is slower than some heuristics, but it returns the best possible local allocation. The optimum algorithm is used in this paper as a local allocator and as a definite point of comparison for faster heuristics. Several other applications of optimum algorithms are discussed for example in <ref> [Kre98] </ref>. 4.1 Integer Programming Formulation The first time a dirty pseudo-register i is evicted, it has to be stored. If i is subsequently reloaded and evicted, i is clean and no store has to be inserted again.
Reference: [LM69] <author> Edward S. Lowry and C. W. Medlock. </author> <title> Object code optimization. </title> <journal> Communications of the ACM, </journal> <volume> 12(1) </volume> <pages> 13-22, </pages> <month> January </month> <year> 1969. </year>
Reference-contexts: Fallacy: Local register allocation is well understood. Local register allocation has been emphasized in several compilers over the decades. Local register allocation precedes global allocation in the FORTRAN IV compiler for a HITAC-5020 [Nak67] and in the Fortran H compiler for the IBM System/360 <ref> [LM69] </ref>. At the other chronological extreme, the ACAPS hierarchical allocator extends a local allocation into a global allocation [HGAM93]. 1 Local register allocation has been a crucial task for optimizing compilers for more than two decades and, in the classification of [HP96], for at least two computer generations.
Reference: [Luc67] <author> F. Luccio. </author> <title> A comment on index register allocation. </title> <journal> Communications of the ACM, </journal> <volume> 10(9) </volume> <pages> 572-574, </pages> <month> September </month> <year> 1967. </year>
Reference-contexts: close to the optimum on common benchmarks. - CFF is implemented to run roughly two to eleven times faster than other heuristics on SPEC benchmarks. 2 Local Register Allocation Our model for local register allocation follows mostly Hsu, Fischer, and Goodman [HFG89] and it is consistent with other previous works <ref> [HKMW66, Ken72, Luc67] </ref>. The model is based on architectures with general purpose registers. Our model extends previous formulations and reflects more realistically actual architectures and instruction sets. Let V = f1; 2; : : :; M g be a set of pseudo-registers. Pseudo-registers will contain temporary variables and constants. <p> The previous optimum algorithm was based on dynamic programming <ref> [HKMW66, Luc67, HFG89] </ref>, took an exponential amount of space in the worst case, and failed to terminate on a few benchmarks due to the lack of memory space. The branch-and-bound algorithm is space-efficient.
Reference: [Nak67] <author> Ikuo Nakata. </author> <title> On compiling algorithms for arithmetic expressions. </title> <journal> Communications of the ACM, </journal> <volume> 10(8) </volume> <pages> 492-494, </pages> <month> August </month> <year> 1967. </year>
Reference-contexts: Today's register allocators face critical problems that never appeared before. Fallacy: Local register allocation is well understood. Local register allocation has been emphasized in several compilers over the decades. Local register allocation precedes global allocation in the FORTRAN IV compiler for a HITAC-5020 <ref> [Nak67] </ref> and in the Fortran H compiler for the IBM System/360 [LM69].
Reference: [NG93] <author> Qi Ning and Guang R. Gao. </author> <title> A novel framework of register allocation for software pipelining. </title> <booktitle> In Proceedings of the Twentieth Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 29-42, </pages> <month> January </month> <year> 1993. </year>
Reference-contexts: Once a compromise instruction scheduling has been fixed, the register allocator proper is invoked to obtain a good allocation under the given schedule. For example, in the MIPSpro compiler [RGSL96], the instruction scheduling is followed by the invocation of the Chaitin-Briggs algorithm [BCT94]. Another example is the ACAPS compilers <ref> [NG93] </ref> that performs a scheduling phase to find a time-optimal scheduling with minimal buffer allocation. Then, the compiler executes a hierarchical register allocation pass. In both compilers, register allocation remains an independent pass and a good register allocator results in good compiled code.
Reference: [Ram96] <author> Rajeev Raman. </author> <title> Priority queues: Small, monotone and trans-dichotomous. </title> <booktitle> In Proc. ESA '96, number 1136 in Lecture Notes in Computer Science, </booktitle> <pages> pages 121-137, </pages> <year> 1996. </year>
Reference-contexts: Recently, a new priority queue has been proposed with O (1) expected time per operation <ref> [Ram96] </ref>, but it is not clear yet if that data structure is also efficient in practice, so we did not use it. The algorithm CFF is depicted in figure 6.
Reference: [RGSL96] <author> John Ruttenberg, G. R. Gao, A. Stoutchinin, and W. Lichtenstein. </author> <title> Software pipelin ing showdown: Optimal vs. heuristics methods in production compilers. </title> <booktitle> In Proc. SIGPLAN '96 Conf. on Programming Language Design and Implementation, </booktitle> <pages> pages 1-11, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Once a compromise instruction scheduling has been fixed, the register allocator proper is invoked to obtain a good allocation under the given schedule. For example, in the MIPSpro compiler <ref> [RGSL96] </ref>, the instruction scheduling is followed by the invocation of the Chaitin-Briggs algorithm [BCT94]. Another example is the ACAPS compilers [NG93] that performs a scheduling phase to find a time-optimal scheduling with minimal buffer allocation. Then, the compiler executes a hierarchical register allocation pass.

References-found: 19

