URL: ftp://ftp.eecs.umich.edu/groups/os_arch/isca95.ps.Z
Refering-URL: http://www.eecs.umich.edu/UMichMP/NT/papers.html
Root-URL: http://www.cs.umich.edu
Title: Abstract  
Keyword: Key words: code bloat, address traces, caches, instruction fetching.  
Abstract: Previous research has shown that the SPEC benchmarks achieve low miss ratios in relatively small instruction caches. This paper presents evidence that current software-development practices produce applications that exhibit substantially higher instruction-cache miss ratios than do the SPEC benchmarks. To represent these trends, we have assembled a collection of applications, called the Instruction Benchmark Suite (IBS), that provides a better test of instruction-cache performance. We discuss the rationale behind the design of IBS and characterize its behavior relative to the SPEC benchmark suite. Our analysis is based on trace-driven and trap-driven simulations and takes into full account both the application and operating-system components of the workloads. This paper then reexamines a collection of previously-proposed hardware mechanisms for improving instruction-fetch performance in the context of the IBS workloads. We study the impact of cache organization, transfer bandwidth, prefetching, and pipelined memory systems on machines that rely on the use of relatively small primary instruction caches to facilitate increased clock rates. We find that, although of little use for SPEC, the right combination of these techniques substantially benefits IBS. Even so, under IBS, a stubborn lower bound on the instruction-fetch CPI remains as an obstacle to improving overall processor performance. 
Abstract-found: 1
Intro-found: 1
Reference: [Accetta86] <author> Accetta, M., Baron, R., Golub, D., Rashid, R., Teva-nian, A. and Young, M. </author> <title> Mach: A new kernel foundation for UNIX development, </title> <booktitle> In the Summer 1986 USENIX Conference. </booktitle>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, including Windows NT [Custer93], Mach 3.0 <ref> [Accetta86] </ref>, and others [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92], have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Alexander85] <author> Alexander, C. A., Keshlear, W. M. and Briggs, F. </author> <title> Translation buffer performance in a UNIX environment. </title> <booktitle> Computer Architecture News 13 (5): </booktitle> <pages> 2-14, </pages> <year> 1985. </year>
Reference: [Alexander86] <author> Alexander, C., Keshlear, W., Cooper, F. and Briggs, F. </author> <title> Cache memory performance in a UNIX environment. </title> <booktitle> Computer Architecture News 14: </booktitle> <pages> 14-70, </pages> <year> 1986. </year>
Reference: [Agarwal88] <author> Agarwal, A., Hennessy, J. and Horowitz, M. </author> <title> Cache performance of operating system and multiprogramming work-loads. </title> <journal> ACM Transactions on Computer Systems 6 (Number 4): </journal> <pages> 393-431, </pages> <year> 1988. </year>
Reference: [Baer87] <author> Baer, J.-L. and Wang, W.-H. </author> <title> Architectural choices for multi-level cache hierarchies. </title> <booktitle> In the 16th International Conference on Parallel Processing: </booktitle> <pages> 258-261, </pages> <year> 1987. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Baer88] <author> Baer, J.-L. and Wang, W.-H. </author> <title> On the inclusion properties for multi-level cache hierarchies. </title> <booktitle> In the 15th ISCA, Honolulu, Hawaii, </booktitle> <pages> 73-80, </pages> <year> 1988. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Bershad94] <author> Bershad, B., Lee, D., Romer, T. and Chen, B. </author> <title> Avoiding conict misses dynamically in large direct-mapped caches, </title> <booktitle> In the 6th ASPLOS, </booktitle> <address> San Jose, CA, 158-170, </address> <year> 1994. </year>
Reference-contexts: During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks. 3 and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses <ref> [Bray90, Kessler92, Bershad94] </ref>. Most previous studies of workloads with a significant operating system component have tended to consider simple memory systems. Most of the effort in these studies went into the collection of complete address traces that include multi-task and operating system references. <p> The plots also show that small amounts of associativity reduce variability by avoiding conict misses before they happen. This suggests that on-chip, associative L2 caches offer an attractive alternative to the recently-proposed cache miss lookaside (CML) buffers <ref> [Bershad94] </ref>, which detect and remove conict misses only after they begin to affect performance. A final advantage of associativity is that it allows designers to more easily add cache memory in increments smaller than a power of two.
Reference: [Bomberger92] <author> Bomberger, A., Hardy, N., Frantz, A. P., Landau, C. R., Frantz, W. S., Shapiro, J. S. and Hardy, A. C. </author> <booktitle> The KeyKOS Nanokernel Architecture, In the USENIX Micro-Kernels and Other Kernel Architectures Workshop, </booktitle> <address> Seattle, WA, 95-112, </address> <year> 1992. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, including Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref>, have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Borg90] <author> Borg, A., Kessler, R. and Wall, D. </author> <title> Generation and analysis of very long address traces, </title> <booktitle> In the 17th ISCA, </booktitle> <address> Seattle, WA, </address> <year> 1990. </year>
Reference: [Bray90] <author> Bray, B., Lynch, W. and Flynn, M. J. </author> <title> Page allocation to reduce access time of physical caches. </title> <institution> Stanford University, Computer Systems Laboratory. CSL-TR-90-454. </institution> <year> 1990. </year>
Reference-contexts: During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks. 3 and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses <ref> [Bray90, Kessler92, Bershad94] </ref>. Most previous studies of workloads with a significant operating system component have tended to consider simple memory systems. Most of the effort in these studies went into the collection of complete address traces that include multi-task and operating system references.
Reference: [Brunner91] <author> Brunner, R. A. </author> <title> VAX Architecture Reference Manual. </title> <publisher> Digital Press, </publisher> <year> 1991. </year>
Reference-contexts: As a result, the primary caches in processors that have targeted fast cycle times (100+ MHz) usually have low associativity and are limited in size to 4-16KB [MReport94, MReport95]. The net effect of these trends is that primary caches have exhibited little growth during the past 10 years <ref> [Brunner91] </ref>. This results in code bloat having a larger relative impact on the instruction cache than on other parts of the system. When CPU performance is reported in terms of SPECmarks [SPEC91], the effects of code bloat on system performance in an actual work environment are not revealed.
Reference: [Budd91] <author> Budd, T. </author> <title> An Introduction to Object-Oriented Programming. </title> <publisher> Addison-Wesley Publishing IBSN 0-201-54709-0, </publisher> <year> 1991. </year>
Reference-contexts: Windows NT also separates its different API servers (Win32, OS/2, POSIX, etc.) into independent modules or subsystems that are loaded into the system only as needed [Custer93]. The benefits of object-oriented and modular code are well-recognized <ref> [Budd91] </ref>, but because they incur a variety of overheads, these techniques come with a cost. The IBS benchmark suite represents these costs in two ways.
Reference: [Calder94] <author> Calder, B., Grunwald, D. and Zorn, B. </author> <title> Quantifying behavioral differences between C and C++ programs. </title> <institution> The Department of Computer Science, University of Colorado. CU-CS-698-94. </institution> <year> 1994. </year>
Reference-contexts: This assertion is supported by the recent work of Calder et al. who have performed a more detailed study of 10 C and 10 C++ programs in <ref> [Calder94] </ref>.
Reference: [Chen93] <author> Chen, B. and Bershad, B. </author> <title> The impact of operating system structure on memory system performance, </title> <booktitle> In the 14th Symposium on Operating System Principles, </booktitle> <year> 1993. </year>
Reference: [Chen94] <author> Chen, B. </author> <title> Memory behavior of an X11 window system, </title> <booktitle> In the USENIX Winter 1994 Technical Conference, </booktitle> <year> 1994. </year>
Reference: [Cheriton84] <author> Cheriton, D. R. </author> <title> The V kernel: A software base for distributed systems. </title> <booktitle> IEEE Software 1 (2): </booktitle> <pages> 19-42, </pages> <year> 1984. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, including Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref>, have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Clark83] <author> Clark, D. </author> <title> Cache performance in the VAX-11/780. </title> <journal> ACM Transactions on Computer Systems 1: </journal> <pages> 24-37, </pages> <year> 1983. </year>
Reference: [Clark85] <author> Clark, D. W. and Emer, J. S. </author> <title> Performance of the VAX-11/780 translation buffer: </title> <booktitle> Simulation and measurement. ACM Transactions on Computer Systems 3 (1): </booktitle> <pages> 31-62, </pages> <year> 1985. </year>
Reference: [Clark88] <author> Clark, D. W., Bannon, P. J. and Keller, J. B. </author> <title> Measuring VAX 8800 Performance with a Histogram Hardware Monitor, </title> <booktitle> In the 15th ISCA, Honolulu, Hawaii, </booktitle> <pages> 176-185, </pages> <year> 1988. </year>
Reference: [Cmelik94] <author> Cmelik, B. and Keppel, D. Shade: </author> <title> A fast instruction-set simulator for execution profiling, </title> <booktitle> In SIGMETRICS, </booktitle> <address> Nashville, TN, </address> <publisher> ACM, </publisher> <pages> 128-137, </pages> <year> 1994. </year>
Reference-contexts: For example, DEC implements ABI emulation by statically translating VAX and MIPS binaries into Alpha binaries [Sites92]. Apple uses a similar strategy to dynamically translate 68040 binaries to the PowerPC architecture [Koch94]. Several other examples of ABI emulators are given in <ref> [Cmelik94] </ref>. ABI emulation causes code bloat because several host instructions are usually required to emulate a single source instruction. An emulation environment typically also includes a large amount of additional execution state, such as translated instruction blocks or jump tables that lead to frequent indirect jumps [Cmelik94]. <p> emulators are given in <ref> [Cmelik94] </ref>. ABI emulation causes code bloat because several host instructions are usually required to emulate a single source instruction. An emulation environment typically also includes a large amount of additional execution state, such as translated instruction blocks or jump tables that lead to frequent indirect jumps [Cmelik94]. We are currently looking for an ABI emulation workload to include in the IBS. Maintainability As it grows in size and complexity, application and system software becomes increasingly difficult to maintain.
Reference: [Custer93] <author> Custer, H. </author> <title> Inside Windows NT. </title> <address> Redmond, WA, </address> <publisher> Microsoft Press, </publisher> <year> 1993. </year>
Reference-contexts: Two different software techniques that increase application portability are API emulation and ABI emulation. Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, including Windows NT <ref> [Custer93] </ref>, Mach 3.0 [Accetta86], and others [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92], have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application. <p> To help manage this complexity, software developers rely on techniques such as object-oriented programming and the restructuring of code into independent and interchangeable modules. For example, the Windows NT Executive bases all of its system abstractions, such as processes, threads and files on an object-oriented model <ref> [Custer93] </ref>. Windows NT also separates its different API servers (Win32, OS/2, POSIX, etc.) into independent modules or subsystems that are loaded into the system only as needed [Custer93]. <p> For example, the Windows NT Executive bases all of its system abstractions, such as processes, threads and files on an object-oriented model <ref> [Custer93] </ref>. Windows NT also separates its different API servers (Win32, OS/2, POSIX, etc.) into independent modules or subsystems that are loaded into the system only as needed [Custer93]. The benefits of object-oriented and modular code are well-recognized [Budd91], but because they incur a variety of overheads, these techniques come with a cost. The IBS benchmark suite represents these costs in two ways.
Reference: [Cvetanovic94] <author> Cvetanovic, Z. and Bhandarkar, D. </author> <title> Characterization of Alpha AXP performance using TP and SPEC Workloads, </title> <booktitle> In the 21st ISCA, </booktitle> <address> Chicago, Ill., </address> <year> 1994. </year>
Reference: [Emer84] <author> Emer, J. and Clark, D. </author> <title> A characterization of processor performance in the VAX-11/780, </title> <booktitle> In the 11th ISCA, </booktitle> <address> Ann Arbor, MI, 301-309, </address> <year> 1984. </year>
Reference-contexts: Tapeworm simulates cache performance while running alongside the system in the OS kernel, enabling us to conduct multiple experimental trials for each workload and cache configuration. We adopt a simple performance model based on cycles-per-instruction (CPI) that focuses on instruction-fetching performance <ref> [Emer84, Hennessey90, Smith92] </ref>: where CPI instr is the performance lost to instruction-cache misses and CPI other is determined by the instruction-issue rate and all Benchmark Execution Time (%) Components of CPI User OS I-cache (CPI instr ) D-cache (CPI data ) Write (CPI write ) IBS (Mach 3.0) 62% 38% 0.36
Reference: [Farrens89] <author> Farrens, M. and Pleszkun, A. </author> <title> Improving performance of small on-chip instruction caches, </title> <booktitle> In the 16th ISCA, </booktitle> <pages> 234-241, </pages> <year> 1989. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92, Pierce95] </ref>, pipelining [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Flanagan93] <author> Flanagan, J. K., Nelson, B. E. and Archibald, J. K. </author> <title> The inaccuracy of trace-driven simulation using incomplete trace data. </title> <institution> Brigham Young University. </institution> <year> 1993. </year>
Reference: [Gee93] <author> Gee, J., Hill, M., Pnevmatikatos, D. and Smith, A. J. </author> <title> Cache Performance of the SPEC92 Benchmark Suite. </title> <journal> IEEE Micro (August): </journal> <pages> 17-27, </pages> <year> 1993. </year>
Reference-contexts: under Components of Memory CPI. 2 Related Work In recent years, much of the architecture research community has settled on using the SPEC benchmark suite as a measure of uniprocessor system performance 1 and considerable effort has been expended by commercial computer manufacturers to tune system performance on these workloads <ref> [Gee93] </ref>. Despite its popularity for evaluating a wide range of architectural structures, SPEC warns against the use of the SPEC89 or SPEC92 benchmarks for testing memory or I/O performance [SPEC93]. <p> In particular, the SPEC benchmark suite is not a good test of instruction-cache performance, a point made most persuasively by Gee et al., who have shown through exhaustive simulation that most of the SPEC benchmarks fit easily into relatively small I-caches over a range of associativities and line sizes <ref> [Gee93] </ref>. One reason that the SPEC benchmarks exhibit such good I-cache performance is due to their infrequent invocation of operating system services. <p> L2 contribution is determined by simulating an L2 cache backed by main memory. Some of our comparisons with the SPEC92 benchmarks are based on miss ratios reported by Gee et al. in <ref> [Gee93] </ref>. Because Gee et al. performed their study on the same machine type (MIPS-based DECstations) and with the same type of compiler used in this study, meaningful comparisons can be made. <p> For the purposes of comparison, the average MPI for the IBS workloads running under Ultrix 3.1 and the SPEC92 benchmarks running under Ultrix 4.1 are also given. The SPEC92 results are based on miss ratios reported by Gee et al. in <ref> [Gee93] </ref>. Workload components include the user application task (s), the Mach 3.0 kernel, and the BSD and X display servers. The relative importance of each of these Workload Components is given as a fraction of total execution time.
Reference: [Happel92] <author> Happel, L. P. and Jayasumana, A. P. </author> <title> Performance of a RISC machine with two-level caches. </title> <booktitle> IEE Proceedings-E 139 (3): </booktitle> <pages> 221-229, </pages> <year> 1992. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Hennessy90] <author> Hennessy, J. L. and Patterson, D. A. </author> <title> Computer Architecture A Quantitative Approach. </title> <address> San Mateo, </address> <publisher> Morgan Kauf-mann, </publisher> <year> 1990. </year>
Reference-contexts: These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92, Pierce95], pipelining [Jouppi90, Olukotun92, Palcharla94] and bypassing <ref> [Hennessy90] </ref>. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. When a cache is physically-indexed 1.
Reference: [Hill87] <author> Hill, M. </author> <title> Aspects of cache memory and instruction buffer performance. </title> <institution> The University of California at Berkeley. </institution> <year> 1987. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92, Pierce95] </ref>, pipelining [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. <p> Following the Three-Cs model of cache performance <ref> [Hill87] </ref>, this graph is a stacked-bar chart that breaks the cause of misses into three components: capacity, conict and compulsory misses. 1 Capacity misses are removed by larger caches and conict misses are removed by higher degrees of cache associativity. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Huck93] <author> Huck, J. and Hays, J. </author> <title> Architectural support for translation table management in large address space machines, </title> <booktitle> In the 20th ISCA, </booktitle> <address> San Diego, CA, 39-50, </address> <year> 1993. </year>
Reference: [Hwu89] <author> Hwu, W.-m. and Chang, P. </author> <title> Achieving high instruction cache performance with an optimizing compiler, </title> <booktitle> In the 16th ISCA, Jerusalem, Isreal, </booktitle> <pages> 242-251, </pages> <year> 1989. </year>
Reference-contexts: There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis <ref> [Hwu89, McFarling89, Torrellas95] </ref>. When a cache is physically-indexed 1.
Reference: [Jouppi90] <author> Jouppi, N. </author> <title> Improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers, </title> <booktitle> In the 17th ISCA, </booktitle> <address> Seattle, WA, 364-373, </address> <year> 1990. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92, Pierce95], pipelining <ref> [Jouppi90, Olukotun92, Palcharla94] </ref> and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. When a cache is physically-indexed 1. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references. <p> During cycles where the processor hits in the cache, the memory pipeline is kept busy with sequential prefetch requests. 2 These prefetches are not placed directly into the cache; instead, they are stored in a special memory, called a stream buffer <ref> [Jouppi90] </ref>. We model the stream buffer as a fully-associative, dual-ported memory that can store N prefetched lines (see Table 8) and that can be accessed in parallel with the cache.
Reference: [Jouppi94] <author> Jouppi, N. and Wilton, S. </author> <title> Tradeoffs in two-level on-chip caching, </title> <booktitle> In the 21st ISCA, </booktitle> <address> Chicago, IL, 34-45, </address> <year> 1994. </year>
Reference-contexts: However, technology trends have resulted in more complex trade-offs in the case of TLBs and caches. Although continued advancements in integrated-circuit densities make it possible to allocate more die area to on-chip cache structures, reductions in cycle times constrain the maximum size and associativity of primary on-chip caches <ref> [Jouppi94] </ref>. These constraints follow from simple physical arguments that show that increasing cache size and associativity increases access times [Olukutun92, Wada92, Wilton94]. <p> Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. <p> recover some of the performance lost to bloated code. 5 Instruction Fetch Support for IBS The IBS workloads require significantly larger I-caches to achieve the same miss rates as the SPEC benchmarks, but cycle-time constraints prevent level-1 (L1) caches from providing the size and/or associativity necessary to deliver good performance <ref> [Jouppi94] </ref>. However, integration levels have reached a point where small L1 caches can be supported by a variety of on-chip structures that reduce the L1 miss penalty. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Koch94] <author> Koch, P. </author> <title> Emulating the 68040 in the PowerPC Macintosh, In Microprocessor Forum, </title> <address> San Francisco, CA, </address> <year> 1994. </year>
Reference-contexts: ABI emulation is sometimes used to ease the transition from an older processor architecture to a newer one. For example, DEC implements ABI emulation by statically translating VAX and MIPS binaries into Alpha binaries [Sites92]. Apple uses a similar strategy to dynamically translate 68040 binaries to the PowerPC architecture <ref> [Koch94] </ref>. Several other examples of ABI emulators are given in [Cmelik94]. ABI emulation causes code bloat because several host instructions are usually required to emulate a single source instruction.
Reference: [Kessler91] <author> Kessler, R. </author> <title> Analysis of multi-megabyte secondary CPU cache memories. </title> <institution> University of Wisconsin-Madison. </institution> <year> 1991. </year> <month> 12 </month>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references. <p> reported on the y-axis in terms of one standard deviation of CPI instr . 0.00 0.02 0.04 CPI instr (std dev) 0.01 0.03 0.05 instr (std dev) 0.01 0.03 0.05 instr (std dev) 0.01 0.03 0.05 instr (std dev) performance caused by random OS page-mapping effects in a physically-indexed cache <ref> [Kessler91, Sites88] </ref>. Variability occurs because different page mappings cause different patterns of con-ict misses from run to run of a workload. Figure 5 shows that the amount of variability is a function of the workload, cache size and associativity.
Reference: [Kessler92] <author> Kessler, R. and Hill, M. </author> <title> Page placement algorithms for large real-indexed caches. </title> <journal> ACM Transactions on Computer Systems 10 (4): </journal> <pages> 338-359, </pages> <year> 1992. </year>
Reference-contexts: During the past three ISCAs, over two thirds of the papers dealing with uniprocessor architecture issues used the SPEC benchmarks. 3 and larger than the page size, operating systems can implement page-allocation algorithms that more evenly distribute pages in the cache to help prevent conict misses <ref> [Bray90, Kessler92, Bershad94] </ref>. Most previous studies of workloads with a significant operating system component have tended to consider simple memory systems. Most of the effort in these studies went into the collection of complete address traces that include multi-task and operating system references.
Reference: [Malan91] <author> Malan, G., Rashid, R., Golub, D. and Baron, R. </author> <title> DOS as a Mach 3.0 application, </title> <booktitle> In the USENIX Mach Symposium, </booktitle> <pages> 27-40, </pages> <year> 1991. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, including Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref>, have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Maynard94] <author> Maynard, A. M., Donnelly, C. and Olszewski, B. </author> <title> Contrasting characteristics and cache performance of technical and multi-user commercial workloads, </title> <booktitle> In the 6th ASPLOS, </booktitle> <address> San Jose, CA, 145-156, </address> <year> 1994. </year>
Reference: [McFarling89] <author> McFarling, S. </author> <title> Program optimization for instruction caches, </title> <booktitle> In the 3rd ASPLOS, </booktitle> <address> Boston, MA, 183-191, </address> <year> 1989. </year>
Reference-contexts: There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis <ref> [Hwu89, McFarling89, Torrellas95] </ref>. When a cache is physically-indexed 1.
Reference: [Mogul91] <author> Mogul, J. C. and Borg, A. </author> <title> The effect of context switches on cache performance, </title> <booktitle> In the 4th ASPLOS, </booktitle> <address> Santa Clara, CA, 75-84, </address> <year> 1991. </year>
Reference: [MReport92-95] <institution> Microprocessor Report. Sebastopol, CA, MicroDesign Resources, </institution> <year> 1992, 1993, 1994 </year> <month> and </month> <year> 1995. </year>
Reference: [Mulder91] <author> Mulder, J., Quach, N. and Flynn, M. </author> <title> An area model for on-chip memories and its application. </title> <journal> IEEE Journal of Solid-State Circuits 26 (2): </journal> <pages> 98-106, </pages> <year> 1991. </year>
Reference-contexts: First, increasing the line size decreases the size of the cache tags. Second, the reduction in area reduces the cache access time. The Mulder area model predicts a 10% reduction in area when moving from a 16-byte to a 64-byte line (8-KB, direct-mapped cache) <ref> [Mulder91] </ref>, while the Wilton and Jouppi timing model shows a 6% decrease in access time [Wilton94]. The incremental improvements due to increasing bandwidth begin to diminish for rates greater than 16 bytes/cycle.
Reference: [Nagle92] <author> Nagle, D., Uhlig, R., Mudge, T., </author> <title> Monster: a tool for analyzing the interaction between operating systems and architectures. </title> <institution> CSE-TR147-92. University of Michigan, </institution> <year> 1992. </year>
Reference-contexts: Our analysis of IBS uses two different and complementary methods: trace-driven and trap-driven simulation. For trace-driven simulation, we gathered address traces, complete with all user and operating system references, by using Monster, a hardware logic analyzer connected to the CPU pins of a DECstation 3100 <ref> [Nagle92] </ref>. Because the caches on this machine are implemented off chip, all memory references were captured using this technique. Long, continuous traces were obtained by stalling the DECstation while unloading the trace buffer in the logic analyzer whenever it became full.
Reference: [Nagle93] <author> Nagle, D., Uhlig, R., Stanley, T., Sechrest, S., Mudge, T. and Brown, R. </author> <title> Design tradeoffs for software-managed TLBs. </title> <booktitle> In the 20th ISCA, </booktitle> <address> San Diego, CA, 27-38, </address> <month> May </month> <year> 1993. </year>
Reference: [Nagle94] <author> Nagle, D., Uhlig, R., Mudge, T. and Sechrest, S. </author> <title> Optimal allocation of on-chip memory for multiple-API operating systems, </title> <booktitle> In the 21st ISCA, </booktitle> <address> Chicago, IL, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: The ability to change cache sizes in smaller increments also helps to more optimally allocate chip die-area among various on-chip memory-system structures (I-cache, D-cache, TLB) <ref> [Nagle94] </ref>. 5.2 Tuning the L1-L2 Interface For both configurations, a 64-KB 8-way, set-associative L2 cache contributes less than one third to the total CPI instr , making the 8-KB L1 I-cache the performance bottleneck (see Figure 4).
Reference: [Olukotun91] <author> Olukotun, O. A., Mudge, T. N. and Brown, R. B. </author> <title> Implementing a cache for a high-performance GaAs microprocessor, </title> <booktitle> In the 18th ISCA, </booktitle> <address> Toronto, Canada, 138-147, </address> <year> 1991. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Olukotun92] <author> Olukotun, K., Mudge, T. and Brown, R. </author> <title> Performance optimization of pipelined primary caches, </title> <booktitle> In The 19th ISCA, </booktitle> <address> Gold Coast, Australia, 181-190, </address> <year> 1992. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92, Pierce95], pipelining <ref> [Jouppi90, Olukotun92, Palcharla94] </ref> and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. When a cache is physically-indexed 1. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Ousterhout94] <author> Ousterhout, J. K. </author> <title> Tcl and the Tk Toolkit. </title> <publisher> Addi-son-Wesley Publishing Company, </publisher> <year> 1994. </year>
Reference-contexts: Tasks (Virtual Address Spaces) Mach Ports (Inter-process Communication and RPC) Service A Core IBS User Task tk Xlib BSD API Emulation X Window Manager server, a window manager and a set of application-linked libraries that implement the core X calls and higher-level graphical objects such as the tk widget set <ref> [Ousterhout94] </ref>. The use of any X application implies that all of these layers of code will be activated, increasing instruction path lengths over workloads with simple textual user interfaces.
Reference: [Palcharla94] <author> Palcharla, S. and Kessler, R. E. </author> <title> Evaluating stream buffers as a secondary cache replacement, </title> <booktitle> In the 21st ISCA, </booktitle> <address> Chi-cago, IL, 24-33, </address> <year> 1994. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching [Farrens89, Hill87, Smith78, Smith92, Pierce95], pipelining <ref> [Jouppi90, Olukotun92, Palcharla94] </ref> and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. When a cache is physically-indexed 1.
Reference: [Patel92] <author> Patel, K., Smith, B. C. and Rowe, L. A. </author> <title> Performance of a Software MPEG Video Decoder. </title> <institution> University of California, Ber-keley. </institution> <year> 1992. </year>
Reference-contexts: Table 2 summarizes the benchmarks and operating systems in the IBS workload suite. The IBS workloads are mainly programs that we actually use in our day-to-day work Workload Description mpeg_play mpeg_play (version 2.0) from the Berkeley Plateau Research Group. Displays 85 frames from a com pressed video file <ref> [Patel92] </ref>. jpeg_play The xloadimage (version 3.0) program written by Jim Frost. Displays two JPEG images. gs Ghostscript (version 2.4.1) distributed by the Free Software Foundation.
Reference: [Pierce95] <author> Pierce, J., </author> <title> Cache Behavior in the Presence of Speculative Execution-The Benefits of Misprediction, </title> <type> Ph.D. Thesis, </type> <institution> The University of Michigan, </institution> <year> 1995. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92, Pierce95] </ref>, pipelining [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. <p> Further, Pierce has shown that even if the prefetching is on the not-taken path of a branch, these wrong-path prefetched instructions are frequently used soon enough after the prefetch that they benefit from being cached <ref> [Pierce95] </ref>. This comparison also shows how subtle differences in cache and prefetch policies can inuence performance, underscoring the point that there are numerous tradeoffs with respect to bandwidth, latency, line size, prefetching, bypassing and pipelining in the memory hierarchy. Summary of Optimizations economy system.
Reference: [Przybylski89] <author> Przybylski, S., Horowitz, M. and Hennessy, J. </author> <title> Characteristics of performance-optimal multi-level cache hierarchies, </title> <booktitle> In the 16th ISCA, Jerusalem, Israel, </booktitle> <pages> 114-121, </pages> <year> 1989. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Przybylski90] <author> Przybylski, S. </author> <title> The performance impact of block sizes and fetching strategies, </title> <booktitle> In the 16th ISCA, </booktitle> <address> Seattle, WA, 160-169, </address> <year> 1990. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. <p> Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth <ref> [Przybylski90] </ref>, prefetching [Farrens89, Hill87, Smith78, Smith92, Pierce95], pipelining [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95].
Reference: [Rozier92] <author> Rozier, M., Abrossimov, V., Armand, F., Boule, I., Gien, M., Guillemont, M., Herrman, F., Kaise, C., Langlois, S., Leonard, P. and Neuhauser, W. </author> <title> Overview of the Chorus distributed operating system, In the Micro-kernels and Other Kernel Architectures Workshop, </title> <address> Seattle, WA, </address> <publisher> USENIX, </publisher> <pages> 39-69, </pages> <year> 1992. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, including Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref>, have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Scheier86] <author> Scheier, R. and Gettys, J. </author> <title> The X window system. </title> <journal> ACM Transactions on Graphics 5 (2): </journal> <pages> 79-109, </pages> <year> 1986. </year>
Reference-contexts: Such features are usually implemented with the help of multiple layers of system software that comprise a window system. The dominant window system in UNIX-based workstations is X11 <ref> [Scheier86] </ref>, which includes an X display Workload Misses per 100 Instructions (MPI) Workload Components (% of Execution Time) Suite OS Application User Kernel BSD X IBS Mach 3.0 mpeg_play 4.28 40% 23% 30% 7% jpeg_play 2.39 67% 13% 17% 3% gs 5.15 47% 34% 10% 9% verilog 5.28 75% 14% 11%
Reference: [Short88] <author> Short, R. and Levy, H. </author> <title> A simulation study of two-level caches, </title> <booktitle> In the 15th ISCA, Honolulu, Hawaii, </booktitle> <pages> 81-88, </pages> <year> 1988. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Sites88] <author> Sites, R. L. and Agarwal, A. </author> <title> Multiprocessor cache analysis with ATUM, </title> <booktitle> In the 15th ISCA, Honolulu, Hawaii, </booktitle> <pages> 186-195, </pages> <year> 1988. </year>
Reference-contexts: reported on the y-axis in terms of one standard deviation of CPI instr . 0.00 0.02 0.04 CPI instr (std dev) 0.01 0.03 0.05 instr (std dev) 0.01 0.03 0.05 instr (std dev) 0.01 0.03 0.05 instr (std dev) performance caused by random OS page-mapping effects in a physically-indexed cache <ref> [Kessler91, Sites88] </ref>. Variability occurs because different page mappings cause different patterns of con-ict misses from run to run of a workload. Figure 5 shows that the amount of variability is a function of the workload, cache size and associativity.
Reference: [Sites92] <author> Sites, R., Chernoff, A., Kirk, M., Marks, M. and Robin-son, S. </author> <title> Binary translation. </title> <journal> Digital Technical Journal 4 (4): </journal> <pages> 137-152, </pages> <year> 1992. </year>
Reference-contexts: ABI emulation is sometimes used to ease the transition from an older processor architecture to a newer one. For example, DEC implements ABI emulation by statically translating VAX and MIPS binaries into Alpha binaries <ref> [Sites92] </ref>. Apple uses a similar strategy to dynamically translate 68040 binaries to the PowerPC architecture [Koch94]. Several other examples of ABI emulators are given in [Cmelik94]. ABI emulation causes code bloat because several host instructions are usually required to emulate a single source instruction.
Reference: [Smith78] <author> Smith, A. J. </author> <title> Sequential program prefetching in memory hierarchies. </title> <booktitle> IEEE Computer 11 (12): </booktitle> <pages> 7-21, </pages> <year> 1978. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92, Pierce95] </ref>, pipelining [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. <p> After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references.
Reference: [Smith82] <author> Smith, A. J. </author> <title> Cache Memories. </title> <booktitle> Computing Surveys 14 (3): </booktitle> <pages> 473-530, </pages> <year> 1982. </year>
Reference-contexts: After arriving at an optimized L2 design, we consider how bandwidth, prefetching, bypassing and pipelining the L1-L2 interface can further improve performance. Throughout this section, we draw on the work of numerous researchers who have explored various instruction-fetching techniques, including multi-level caching, prefetching and pipelined-memory systems <ref> [Farrens89, Hill87, Kessler91, Jouppi90, Jouppi94, Olukotun92, Przybylski,89, Smith78, Smith82] </ref>. This work uses IBS to compare and evaluate these various architectural mechanisms under a more challenging workload. Throughout this analysis, we only consider instruction references. <p> Table 6 shows that for small line sizes, prefetching can significantly improve performance. The table also shows a result previously noted by Smith <ref> [Smith82] </ref>: prefetching over multiple small lines yields better performance than implementing a cache with longer lines. For example, the cache with the 64-byte line has a CPI instr of 0.297, while the cache with the 16-byte line and 3 prefetched lines has a lower CPI instr of 0.260.
Reference: [Smith85] <author> Smith, A. J. </author> <title> Cache evaluation and the impact on workload choice, </title> <booktitle> In the 12th ISCA, </booktitle> <address> Boston, MA, 64-73, </address> <year> 1985. </year>
Reference-contexts: 1 Introduction It has long been recognized that the best selection of memory-system parameters, such as cache size, associativity and line size, is highly dependent on the workload that a machine is expected to support <ref> [Smith85] </ref>. Because application and operating system code continually evolves to incorporate new functions, and because memory technologies are constantly changing in capability and cost, it follows that memory-system parameters must be continually re-evaluated to achieve the best possible performance.
Reference: [Smith92] <author> Smith, J. E. and Hsu, W.-C. </author> <title> Prefetching in supercomputer instruction caches, </title> <booktitle> In Supercomputing 92, </booktitle> <pages> 588-597, </pages> <year> 1992. </year>
Reference-contexts: Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory. These methods include the tuning of cache line sizes and bandwidth [Przybylski90], prefetching <ref> [Farrens89, Hill87, Smith78, Smith92, Pierce95] </ref>, pipelining [Jouppi90, Olukotun92, Palcharla94] and bypassing [Hennessy90]. There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis [Hwu89, McFarling89, Torrellas95]. <p> Tapeworm simulates cache performance while running alongside the system in the OS kernel, enabling us to conduct multiple experimental trials for each workload and cache configuration. We adopt a simple performance model based on cycles-per-instruction (CPI) that focuses on instruction-fetching performance <ref> [Emer84, Hennessey90, Smith92] </ref>: where CPI instr is the performance lost to instruction-cache misses and CPI other is determined by the instruction-issue rate and all Benchmark Execution Time (%) Components of CPI User OS I-cache (CPI instr ) D-cache (CPI data ) Write (CPI write ) IBS (Mach 3.0) 62% 38% 0.36
Reference: [SPEC91] <author> SPEC. </author> <title> The SPEC Benchmark Suite. </title> <journal> SPEC Newsletter. </journal> <volume> 3: </volume> <pages> 3-4, </pages> <year> 1991. </year>
Reference-contexts: This results in code bloat having a larger relative impact on the instruction cache than on other parts of the system. When CPU performance is reported in terms of SPECmarks <ref> [SPEC91] </ref>, the effects of code bloat on system performance in an actual work environment are not revealed. Although the SPEC benchmarks are periodically upgraded (SPEC89, SPEC92 and the To appear in the 22nd International Symposium on Computer Architecture, Santa Magherita Ligure, Italy, June, 1995.
Reference: [SPEC93] <author> SPEC. </author> <title> SPEC: A five year retrospective. </title> <booktitle> The SPEC Newsletter 5 (4): </booktitle> <pages> 1-4, </pages> <year> 1993. </year>
Reference-contexts: Despite its popularity for evaluating a wide range of architectural structures, SPEC warns against the use of the SPEC89 or SPEC92 benchmarks for testing memory or I/O performance <ref> [SPEC93] </ref>.
Reference: [Taylor90] <author> Taylor, G., Davies, P. and Farmwald, M. </author> <title> The TLB slice - A low-cost high-speed address translation mechanism, </title> <booktitle> In the 17th ISCA, </booktitle> <address> Seattle, WA, 355-363, </address> <year> 1990. </year>
Reference: [Torrellas92] <author> Torrellas, J., Gupta, A. and Hennessy, J. </author> <title> Characterizing the caching and synchronization performance of multiprocessor operating system, </title> <booktitle> In the 5th ASPLOS, </booktitle> <address> Boston, MA, 162-174, </address> <year> 1992. </year>
Reference: [Torrellas95] <author> Torrellas, J., Xia, C. and Daigle, R. </author> <title> Optimizing instruction cache performance for operating system intensive workloads, </title> <booktitle> In the 21st International Symposium on High-Performance Computer Architecture (HPCA), </booktitle> <address> Raleigh, North Carolina, </address> <note> to appear, </note> <year> 1995. </year>
Reference-contexts: There are also software-based methods for improving I-cache performance. Compilers can reduce conict misses by carefully placing procedures in memory with the assistance of execution-profile information and through call-graph analysis <ref> [Hwu89, McFarling89, Torrellas95] </ref>. When a cache is physically-indexed 1.
Reference: [Touma92] <author> Touma, W. R. </author> <title> The Dynamics of the Computer Industry. </title> <institution> University of Texas at Austin. </institution> <year> 1993. </year>
Reference-contexts: Improvements in memory technology have offset some of these trends. For example, main-memory DRAMs have quadrupled in size roughly every 2 to 3 years and their price has dropped steadily from about $800 per megabyte in 1986 to a current price of about $40 per megabyte <ref> [Touma92] </ref>. Magnetic disk drives have exhibited similar improvements in capacity and reduction in cost [Touma92]. However, technology trends have resulted in more complex trade-offs in the case of TLBs and caches. <p> For example, main-memory DRAMs have quadrupled in size roughly every 2 to 3 years and their price has dropped steadily from about $800 per megabyte in 1986 to a current price of about $40 per megabyte <ref> [Touma92] </ref>. Magnetic disk drives have exhibited similar improvements in capacity and reduction in cost [Touma92]. However, technology trends have resulted in more complex trade-offs in the case of TLBs and caches. Although continued advancements in integrated-circuit densities make it possible to allocate more die area to on-chip cache structures, reductions in cycle times constrain the maximum size and associativity of primary on-chip caches [Jouppi94].
Reference: [Uhlig94] <author> Uhlig, R., Nagle, D., Sechrest, S. and Mudge, T. </author> <title> Trap-driven simulation with Tapeworm II. </title> <booktitle> In the 6th ASPLOS, </booktitle> <address> San Jose, CA, 132-144, </address> <year> 1994. </year>
Reference-contexts: To add an additional degree of confidence to our measurements and to take into account inherent variations in performance due to operating system effects, we use a trap-driven simulator called Tapeworm II <ref> [Uhlig94, Uhlig95] </ref>. Tapeworm simulates cache performance while running alongside the system in the OS kernel, enabling us to conduct multiple experimental trials for each workload and cache configuration.
Reference: [Uhlig95] <author> Uhlig, R. </author> <title> Trap-driven Memory Simulation, </title> <type> Ph.D. Thesis, </type> <institution> The University of Michigan, </institution> <year> 1995. </year>
Reference-contexts: To add an additional degree of confidence to our measurements and to take into account inherent variations in performance due to operating system effects, we use a trap-driven simulator called Tapeworm II <ref> [Uhlig94, Uhlig95] </ref>. Tapeworm simulates cache performance while running alongside the system in the OS kernel, enabling us to conduct multiple experimental trials for each workload and cache configuration.
Reference: [Wada92] <author> Wada, T., Rajan, S. and Przybylski, S. </author> <title> An analytical access time model for on-chip cache memories. </title> <journal> IEEE Journal of Solid-State Circuits 27 (8): </journal> <pages> 1147-1156, </pages> <year> 1992. </year>
Reference-contexts: These constraints follow from simple physical arguments that show that increasing cache size and associativity increases access times <ref> [Olukutun92, Wada92, Wilton94] </ref>. As a result, the primary caches in processors that have targeted fast cycle times (100+ MHz) usually have low associativity and are limited in size to 4-16KB [MReport94, MReport95].
Reference: [Wang89] <author> Wang, W.-H., Baer, J.-L. and Levy, H. </author> <title> Organization and performance of a two-level virtual-real cache hierarchy, </title> <booktitle> In the 16th ISCA, Jerusalem, Israel, </booktitle> <pages> 140-148, </pages> <year> 1989. </year>
Reference-contexts: Several hardware-based methods have been proposed to reduce the penalty of misses in small, direct-mapped primary I-caches. The most straightforward is to add a second level of cache, either on or off chip, to reduce time-consuming references to main memory <ref> [Short88, Baer87, Baer88, Przybylski89, Przybylski90, Happel92, Kessler91, Olukotun91, Jouppi94, Wang89] </ref>. Other methods focus on optimizing the interface from the primary I-cache to the next level in the memory hierarchy, whether it be a second-level cache, or main memory.
Reference: [Wiecek92] <author> Wiecek, C. A., Kaler, C. G., Fiorelli, S., Davenport, W. C. and Chen, R. C. </author> <title> A Model and Prototype of VMS Using the Mach 3.0 Kernel, </title> <booktitle> In the USENIX Micro-kernels and Other Kernel Architectures Workshop, </booktitle> <address> Seattle, WA, 187-203, </address> <year> 1992. </year>
Reference-contexts: Porting an application to a different operating system requires that it be rewritten to use the application-procedure interfaces or APIs of the new host OS. To simplify this process, some operating systems, including Windows NT [Custer93], Mach 3.0 [Accetta86], and others <ref> [Bomberger92, Cheriton84, Malan91, Rozier92, Wiecek92] </ref>, have been designed to emulate multiple APIs. Overhead due to API emulation is represented in IBS through the use of a 4.3 BSD emulation library that is dynamically linked into the address space of each user application.
Reference: [Wilton94] <author> Wilton, S. and Jouppi, N. </author> <title> An enhanced access and cycle time model for on-chip caches. </title> <institution> DEC Western Research Lab. </institution> <type> Technical Report 93/5. </type> <year> 1994. </year>
Reference-contexts: These constraints follow from simple physical arguments that show that increasing cache size and associativity increases access times <ref> [Olukutun92, Wada92, Wilton94] </ref>. As a result, the primary caches in processors that have targeted fast cycle times (100+ MHz) usually have low associativity and are limited in size to 4-16KB [MReport94, MReport95]. <p> This would increase the L1 contribution to CPI instr from 0.34 to 0.38. It is also possible that the increase would be small enough so as not to impact the latency. Przybylski [Przybylski88] and Wilton <ref> [Wilton94] </ref> present detailed models that accurately account for these effects. 4 8 16 32 64 128 256 512 1K 4 8 16 32 64 128 256 512 1K verilog 4 8 16 32 64 128 256 512 1K I-cache Size (KB) espresso 1-way 2-way 4 8 16 32 64 128 256 <p> Second, the reduction in area reduces the cache access time. The Mulder area model predicts a 10% reduction in area when moving from a 16-byte to a 64-byte line (8-KB, direct-mapped cache) [Mulder91], while the Wilton and Jouppi timing model shows a 6% decrease in access time <ref> [Wilton94] </ref>. The incremental improvements due to increasing bandwidth begin to diminish for rates greater than 16 bytes/cycle. Moreover, building large cache busses (&gt; 128 bits) can consume a significant amount of chip area and possibly impact the overall cache size.
References-found: 74

