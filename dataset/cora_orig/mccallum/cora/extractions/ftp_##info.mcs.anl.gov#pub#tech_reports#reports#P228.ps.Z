URL: ftp://info.mcs.anl.gov/pub/tech_reports/reports/P228.ps.Z
Refering-URL: http://www.mcs.anl.gov/publications/preprints.htm
Root-URL: http://www.mcs.anl.gov
Title: ACHIEVING LOGARITHMIC GROWTH OF TEMPORAL AND SPATIAL COMPLEXITY IN REVERSE AUTOMATIC DIFFERENTIATION  
Author: ANDREAS GRIEWANK 
Keyword: KEY WORDS: Gradient, Adjoint, Complexity, Checkpointing, Recursion  
Address: Argonne, Illinois 60439  
Affiliation: Mathematics and Computer Science Division, Argonne National Laboratory,  
Note: Copyright information to be inserted by the Publishers  
Abstract: In its basic form the reverse mode of automatic differentiation yields gradient vectors at a small multiple of the computational work needed to evaluate the underlying scalar function. The practical applicability of this temporal complexity result, due originally to Linnainmaa, seemed to be severely limited by the fact that the memory requirement of the basic implementation is proportional to the run time, T , of the original evaluation program. It is shown here that, by a recursive scheme related to the multilevel differentiation approach of Volin and Ostrovskii, the growth in both temporal and spatial complexity can be limited to a fixed multiple of log(T ). Other compromises between the run time and memory requirement are possible, so that the reverse mode becomes applicable to computational problems of virtually any size. 
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> F. L. Bauer, </author> <title> Computational graphs and rounding errors. </title> <journal> SINUM, </journal> <volume> Vol. 11, No. 1 (1974), </volume> <pages> pp. 87-96. </pages>
Reference-contexts: For the sake of completeness we may formalize the concept of a computer program P as follows. Let P be a numbered set of m instructions each of which consists of two components: a procedure f 2 L and a mapping from S to the counter range <ref> [1; : : : ; m] </ref>. The second component lets every instruction nominate its successor, possibly as a function of flags and counters in the state space. Thus we allow for loops and conditional jumps rather than restricting ourselves to straight-line code. <p> The resulting ratio h = 20 M can obviously be arbitrarily large. In general, h can be thought of as the height of the computational graph <ref> [1] </ref>, with R representing its width and T the area (i.e., the total number of nodes). This visualization of the situation is utilized in Fig. 1.
Reference: 2. <author> C. H. Bennett, </author> <title> Logical Reversability of Computation, </title> <journal> IBM Journal of Research and Development, </journal> <volume> Vol. 17 (1973), </volume> <pages> pp. 525-532. </pages>
Reference-contexts: In accounting for computational costs, we will try to be as realistic and system independent as possible. The problem we are addressing is closely related to that of logical program reversability, which has attracted some interest in theoretical computer science. Bennett <ref> [2] </ref> conjectured already in 1973 that a logarithmic growth in the spatial complexity might be achievable. The technique advocated here could also be useful for debugging purposes, where previous states need to be reconstructed by some form of running the program backward. The paper is organized as follows.
Reference: 3. <author> Yu. G. Evtushenko, </author> <title> Automatic differentiation viewed, in: Automatic Differentiation of Algorithm: Theory, Implementation, and Application, </title> <editor> A. Griewwank and G. F. Corliss, eds., </editor> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1991. </year> <title> LOGARITHMIC REVERSE DIFFERENTIATION 21 </title>
Reference-contexts: In control theory it is well known that these gradients can be obtained with low temporal complexity by integrating the linear co-state equation backward in time. The close relation between this well-established technique and reverse automatic differentiation was analyzed in Evtushenko's contribution to the proceedings <ref> [3] </ref> of the first SIAM Workshop on the Automatic Differentiation of Algorithms. The same volume contains several papers by leading researchers from Meteorology and Oceanography, where adjoint models are in regular use.
Reference: 4. <author> A. Griewank, </author> <title> On automatic differentiation, in: Mathematical Programming: Recent Developments and Applications, </title> <editor> ed. M. Iri and K. Tanabe, </editor> <publisher> Kluwer Academic Publishers, </publisher> <address> Tokyo, </address> <pages> pp. 83-108, </pages> <year> 1989. </year>
Reference-contexts: Hence there is only one vector-matrix product associated with each elementary function, so that the effort for evaluating F and yF 0 should be comparable <ref> [4] </ref>. Provided that the f i are sufficiently simple, this is indeed the case in terms of the usual operations counts. <p> If the library L consists solely of binary arithmetic operations and univariate system functions, one can show that, under reasonable conditions on the computer system in use, the scaled identity matrix D = 5 I is large enough <ref> [4] </ref>. For the sake of completeness we may formalize the concept of a computer program P as follows.
Reference: 5. <author> A. Griewank, D. Juedes, and J. Srinivasan, ADOL-C, </author> <title> a package for the automatic differentiation of algorithms written in C/C++, </title> <type> Preprint MCS-180-1190, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Illinois, </institution> <year> 1990. </year> <note> To appear in TOMS. </note>
Reference-contexts: This spatial complexity is usually proportional to the temporal complexity of the original evaluation program and may therefore be quite large. Current implementations of the reverse mode <ref> [5] </ref> typically store 15-20 bytes per arithmetic operation, which may require 30 megabytes of storage for each minute evaluation time on a Sun 3. <p> Currently, this information cannot be obtained any other way. 8 IMPLEMENTATION QUESTIONS AND DISCUSSION The logarithmic complexity growth of the recursive method described and analyzed in this paper has been verified by an experimental implementation. For this purpose our C++ package ADOL-C <ref> [5] </ref> was modified using the forking and piping facilities of UNIX System V. The tree of calls to treeverse was implemented as a tree of processes with each child being spawned by a fork, which generates a full duplicate of the parent's environment.
Reference: 6. <author> M. Iri, T. Tsuchiya, and M. Hoshi, </author> <title> Automatic computation of partial derivatives and rounding error estimates with applications to large-scale systems of nonlinear equations, </title> <journal> Journal of Computational and Applied Mathematics, </journal> <volume> 24 (1988), </volume> <pages> pp. 365-392. </pages>
Reference: 7. <author> S. Linnainmaa, </author> <title> Taylor expansion of the accumulated rounding error, </title> <journal> BIT, </journal> <volume> 16 (1976), </volume> <pages> pp. 146-160. </pages>
Reference: 8. <author> B. Speelpenning, </author> <title> "Compiling Fast Partial Derivatives of Functions Given by Algorithms," </title> <type> Ph.D. dissertation, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, </institution> <year> 1980. </year>
Reference-contexts: Even though the individual Jacobians f 0 i are likely to be extremely sparse, Speelpenning fl This work was supported by the Applied Mathematical Sciences subprogram of the Office of Energy Research, U.S. Department of Energy, under Contract W-31-109-Eng-38. 1 2 A. GRIEWANK <ref> [8] </ref> and others have observed that multiplying them together from right to left (i.e., for i = 0; 1; 2; : : :; n 1) may be much less efficient than multiplying them from left to right, especially when n r &lt;< n d .
Reference: 9. <author> Yu. M. Volin and G. M. Ostrovskii, </author> <title> Automatic computation of derivatives with the use of the multilevel differentiation technique, </title> <journal> Computers and Mathematics with Applications, </journal> <volume> Vol. 11, No. 11 (1985), </volume> <pages> pp. 1099-1114. </pages>
Reference-contexts: Volin and Ostrovskii <ref> [9] </ref> suggested recursively treating procedures as programs with their own work space and evaluating their adjoints by performing forward and reverse sweeps within these subprograms. <p> In this case we need only save and restore that subspace at the beginning and end of the call to treeverse, repectively. In this way our recursive formalism can be modified to include Volin and Ostrovskii's multilevel differentiation approach <ref> [9] </ref>. However, in this paper we assume that the simplicity and convenience of taking snapshots of the whole state space outweigh the savings in storage that might be achieved by a more localized approach.
References-found: 9

