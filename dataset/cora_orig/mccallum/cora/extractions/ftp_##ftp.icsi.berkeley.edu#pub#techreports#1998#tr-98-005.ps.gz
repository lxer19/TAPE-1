URL: ftp://ftp.icsi.berkeley.edu/pub/techreports/1998/tr-98-005.ps.gz
Refering-URL: http://www.icsi.berkeley.edu/techreports/1998.html
Root-URL: http://www.icsi.berkeley.edu
Email: byers@cs.berkeley.edu  
Title: A Digital Fountain Approach to Reliable Distribution of Bulk Data  
Author: John W. Byers Michael Luby Michael Mitzenmacher Ashutosh Rege 
Keyword: digital fountain, reliable data distribution, bulk distribution, on demand download, erasure codes, forward-error correcting (FEC), IP multicast, broadcast, lossy channels, heterogeneous conditions.  
Note: Research supported in part by National Science Foundation operating grant NCR-9416101. Contact author:  Research supported in part by National Science Foundation operating grant NCR-9416101.  Research supported in part by National Science Foundation operating grant NCR-9416101.  
Affiliation: UC Berkeley and International Computer Science Institute, Berkeley, California.  International Computer Science Institute, Berkeley, California.  Digital Systems Research Center, Palo Alto, California. International Computer Science Institute, Berkeley, California.  
Date: February 13, 1998  
Abstract: The proliferation of applications that must reliably distribute bulk data to a large number of autonomous clients motivates the design of new multicast and broadcast protocols. We describe an ideal, fully scalable protocol for these applications that we call a digital fountain. A digital fountain allows any number of heterogeneous clients to acquire bulk data with optimal efficiency at times of their choosing. Moreover, no feedback channels are needed to ensure reliable delivery, even in the face of high loss rates. We develop a protocol that closely approximates a digital fountain using a new class of erasure codes that are orders of magnitude faster than standard erasure codes. We provide performance measurements that demonstrate the feasibility of our approach and discuss the design, implementation and performance of an experimental system. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. Acharya, M. Franklin, S. Zdonik, </author> <title> "Dissemination-Based Data Delivery Using Broadcast Disks," </title> <journal> IEEE Personal Communications, </journal> <month> December </month> <year> 1995, </year> <pages> pp. 50-60. </pages>
Reference-contexts: To avoid confusion, we always refer to the codes we consider as erasure codes. 2 the use of a data carousel or broadcast disk approach can ensure full reliability <ref> [1] </ref>. In a data carousel approach, the source repeatedly loops through transmission of all data packets. Receivers may join the stream at any time, then listen until they receive all distinct packets comprising the transmission.
Reference: [2] <author> J. Blomer, M. Kalfane, M. Karpinski, R. Karp, M. Luby, D. Zuckerman, </author> <title> "An XOR-Based Erasure-Resilient Coding Scheme," </title> <type> ICSI Technical Report No. </type> <institution> TR-95-048, </institution> <month> August </month> <year> 1995. </year>
Reference-contexts: Tornado codes with standard codes that have been previously proposed for network applications [4, 14, 16, 17, 18, 19]. The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy <ref> [2] </ref> are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. Both Tornado A and Tornado B codes were designed using some of the principles described in [8] and [9].
Reference: [3] <author> S. Floyd, V. Jacobson, C. G. Liu, S. McCanne, L. Zhang, </author> <title> "A Reliable Multicast Framework for Light-Weight Sessions and Application Level Framing." </title> <booktitle> In ACM SIGCOMM '95, </booktitle> <pages> pp. 342-356, </pages> <month> August </month> <year> 1995. </year>
Reference-contexts: More sophisticated solutions which address these limitations by using techniques such as local repair, polling, or the use of a hierarchy have been proposed <ref> [3, 7, 10, 11, 21] </ref>, but these solutions as yet appear inadequate. Moreover, whereas retransmission-based solutions are at best unscalable and inefficient on terrestrial networks, they are unworkable on satellite networks, where the back channel typically has high latency and limited capacity, if it is available at all.
Reference: [4] <author> J. </author> <title> Gemmell, "ECRSM Erasure Correcting Scalable Reliable Multicast," </title> <institution> Microsoft Research Technical Report MS-TR-97-20, </institution> <month> June </month> <year> 1997. </year>
Reference-contexts: The problems with solutions based on retransmission have led many researchers to consider applying Forward Error Correction based on erasure codes 1 to reliable multicast <ref> [4, 12, 13, 14, 16, 17, 18, 19] </ref>. <p> Tornado codes with standard codes that have been previously proposed for network applications <ref> [4, 14, 16, 17, 18, 19] </ref>. The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively.
Reference: [5] <author> C. Huitema, </author> <title> "The Case for Packet Level FEC." </title> <booktitle> In Proc. of IFIP 5th Int'l Workshop on Protocols for High Speed Networks, </booktitle> <institution> Sophia Antipolis, France, </institution> <month> October </month> <year> 1996. </year>
Reference-contexts: Their work, and the work of many other authors, focus on erasure codes based on Reed-Solomon codes <ref> [5, 11, 12, 13, 16, 17, 18] </ref>. The limitation of these codes is that encoding and decoding times are slow, effectively limiting k to small values for practical applications. Hence, their solution involves breaking the source data into smaller blocks of packets and encoding over these blocks.
Reference: [6] <author> V. Jacobson, "pathchar", </author> <note> http://www-nrg.ee.lbl.gov/pathchar. </note>
Reference-contexts: The server and clients were on three different subnets, located at Berkeley, CMU and Cornell. There were 16 hops on the path from Berkeley to CMU, and the bottleneck bandwidth (obtained by using mtrace and pathchar <ref> [6] </ref>) was 8 Mb/s with an RTT of 60 ms. There were 17 hops on the path from Berkeley to Cornell, and the bottleneck bandwidth was 9.3 Mb/s with an RTT of 87 ms. Base layer bandwidth was set at rates ranging from 64 Kb/sec to 512 Kb/sec.
Reference: [7] <author> J. C. Lin, S. Paul, "RMTP: </author> <title> A Reliable Multicast Transport Protocol." </title> <booktitle> In IEEE INFOCOM '96, </booktitle> <pages> pp. 1414-1424, </pages> <month> March </month> <year> 1996. </year>
Reference-contexts: More sophisticated solutions which address these limitations by using techniques such as local repair, polling, or the use of a hierarchy have been proposed <ref> [3, 7, 10, 11, 21] </ref>, but these solutions as yet appear inadequate. Moreover, whereas retransmission-based solutions are at best unscalable and inefficient on terrestrial networks, they are unworkable on satellite networks, where the back channel typically has high latency and limited capacity, if it is available at all.
Reference: [8] <author> M. Luby, M. Mitzenmacher, A. Shokrollahi, D. Spielman, V. Stemann, </author> <title> "Practical Loss-Resilient Codes." </title> <booktitle> In Proceedings of the 29 th ACM Symposium on Theory of Computing, </booktitle> <year> 1997. </year>
Reference-contexts: The structure of the bipartite random graphs must be specially chosen to guarantee both rapid encoding and decoding and the erasure property described below. A detailed, technical description of these codes is provided in <ref> [8] </ref> and [9]. Tornado codes have the following erasure property: to reconstruct the source data, it suffices to recover slightly more than k of the n packets stored in the graph. <p> The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. Both Tornado A and Tornado B codes were designed using some of the principles described in <ref> [8] </ref> and [9]. The implementations were not carefully optimized, so their running times could be improved by constant factors. All experiments were benchmarked on a Sun 167 MHz UltraSPARC 1 with 64 megabytes of RAM running Solaris 2.5.1. All runs are with packet length P = 1KB.
Reference: [9] <author> M. Luby, M. Mitzenmacher, A. Shokrollahi, </author> <title> "Analysis of Random Processes via And-Or Tree Evaluation." </title> <booktitle> In Proceedings of the 9 th Annual ACM-SIAM Symposium on Discrete Algorithms, </booktitle> <month> January </month> <year> 1998. </year>
Reference-contexts: The structure of the bipartite random graphs must be specially chosen to guarantee both rapid encoding and decoding and the erasure property described below. A detailed, technical description of these codes is provided in [8] and <ref> [9] </ref>. Tornado codes have the following erasure property: to reconstruct the source data, it suffices to recover slightly more than k of the n packets stored in the graph. <p> The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. Both Tornado A and Tornado B codes were designed using some of the principles described in [8] and <ref> [9] </ref>. The implementations were not carefully optimized, so their running times could be improved by constant factors. All experiments were benchmarked on a Sun 167 MHz UltraSPARC 1 with 64 megabytes of RAM running Solaris 2.5.1. All runs are with packet length P = 1KB.
Reference: [10] <author> S. McCanne, V. Jacobson, and M. Vetterli, </author> <title> "Receiver-driven Layered Multicast." </title> <booktitle> In Proc. of ACM SIGCOMM '96, </booktitle> <pages> pp. 117-130, </pages> <year> 1996. </year>
Reference-contexts: More sophisticated solutions which address these limitations by using techniques such as local repair, polling, or the use of a hierarchy have been proposed <ref> [3, 7, 10, 11, 21] </ref>, but these solutions as yet appear inadequate. Moreover, whereas retransmission-based solutions are at best unscalable and inefficient on terrestrial networks, they are unworkable on satellite networks, where the back channel typically has high latency and limited capacity, if it is available at all. <p> Receiver heterogeneity and varying rates of network congestion motivate the need for distribution protocols which can support a variety of end-to-end bandwidth and packet loss rates. 7.1.1 Layering Across Multiple Multicast Groups The approach we take follows the lead of other authors who advocate layered multicast <ref> [10, 13, 19] </ref>. The main idea underlying this approach is to enable the source to transmit data across multiple multicast groups, thereby allowing the receiver to subscribe to an appropriate subset of these layers.
Reference: [11] <author> C. K. Miller, </author> <title> "Reliable Multicast Protocols: A Practical View." </title> <booktitle> In Proc. of the 22nd Annual Conference on Local Computer Networks (LCN '97), </booktitle> <year> 1997. </year>
Reference-contexts: More sophisticated solutions which address these limitations by using techniques such as local repair, polling, or the use of a hierarchy have been proposed <ref> [3, 7, 10, 11, 21] </ref>, but these solutions as yet appear inadequate. Moreover, whereas retransmission-based solutions are at best unscalable and inefficient on terrestrial networks, they are unworkable on satellite networks, where the back channel typically has high latency and limited capacity, if it is available at all. <p> Their work, and the work of many other authors, focus on erasure codes based on Reed-Solomon codes <ref> [5, 11, 12, 13, 16, 17, 18] </ref>. The limitation of these codes is that encoding and decoding times are slow, effectively limiting k to small values for practical applications. Hence, their solution involves breaking the source data into smaller blocks of packets and encoding over these blocks.
Reference: [12] <author> J. Nonnenmacher and E. W. Biersack, </author> <title> "Reliable Multicast: Where to Use Forward Error Correction." </title> <booktitle> In Proc. of IFIP 5th Int'l Workshop on Protocols for High Speed Networks, </booktitle> <pages> pp. 134-148, </pages> <institution> Sophia Antipolis, </institution> <address> France, October 1996. </address> <publisher> Chapman and Hall. </publisher>
Reference-contexts: The problems with solutions based on retransmission have led many researchers to consider applying Forward Error Correction based on erasure codes 1 to reliable multicast <ref> [4, 12, 13, 14, 16, 17, 18, 19] </ref>. <p> Their work, and the work of many other authors, focus on erasure codes based on Reed-Solomon codes <ref> [5, 11, 12, 13, 16, 17, 18] </ref>. The limitation of these codes is that encoding and decoding times are slow, effectively limiting k to small values for practical applications. Hence, their solution involves breaking the source data into smaller blocks of packets and encoding over these blocks.
Reference: [13] <author> J. </author> <title> Nonnenmacher and E.W. Biersack, "Asynchronous Multicast Push: AMP." </title> <booktitle> In Proc. of International Conference on Computer Communications, </booktitle> <address> Cannes, France, </address> <month> November </month> <year> 1997. </year>
Reference-contexts: The problems with solutions based on retransmission have led many researchers to consider applying Forward Error Correction based on erasure codes 1 to reliable multicast <ref> [4, 12, 13, 14, 16, 17, 18, 19] </ref>. <p> Their work, and the work of many other authors, focus on erasure codes based on Reed-Solomon codes <ref> [5, 11, 12, 13, 16, 17, 18] </ref>. The limitation of these codes is that encoding and decoding times are slow, effectively limiting k to small values for practical applications. Hence, their solution involves breaking the source data into smaller blocks of packets and encoding over these blocks. <p> This limits the extent to which an erasure code can achieve the properties of a digital fountain. An obvious way to approximate a digital fountain also proposed by other researchers (e.g., <ref> [13, 16, 17, 19] </ref>) is to set n to be a multiple of k, and repeatedly cycle through and send the n encoding packets. Then, the client is guaranteed to be able to recover the original file as long as k distinct packets are received. <p> Receiver heterogeneity and varying rates of network congestion motivate the need for distribution protocols which can support a variety of end-to-end bandwidth and packet loss rates. 7.1.1 Layering Across Multiple Multicast Groups The approach we take follows the lead of other authors who advocate layered multicast <ref> [10, 13, 19] </ref>. The main idea underlying this approach is to enable the source to transmit data across multiple multicast groups, thereby allowing the receiver to subscribe to an appropriate subset of these layers.
Reference: [14] <author> J. Nonnenmacher, E. W. Biersack, and D. Towsley, </author> <title> "Parity-Based Loss Recovery for Reliable Multicast Transmission." </title> <booktitle> In Proc. of ACM SIGCOMM '97, </booktitle> <year> 1997. </year>
Reference-contexts: The problems with solutions based on retransmission have led many researchers to consider applying Forward Error Correction based on erasure codes 1 to reliable multicast <ref> [4, 12, 13, 14, 16, 17, 18, 19] </ref>. <p> In principle, this idea can greatly reduce the number of retransmissions, as a single retransmission of redundant data can potentially benefit many receivers simultaneously. The recent work of Nonnenmacher, Biersack and Towsley <ref> [14] </ref> defines a hybrid approach to reliable multicast, coupling requests for retransmission with transmission of redundant codewords, and quantifies the benefits of this approach in practice. Their work, and the work of many other authors, focus on erasure codes based on Reed-Solomon codes [5, 11, 12, 13, 16, 17, 18]. <p> Standard erasure codes also require somewhat complex finite field operations, further increasing their encoding and decoding times. As a result, standard erasure codes can only be applied in practice when k and ` are small. (Values used in <ref> [14, 17, 19, 18] </ref> have k and ` ranging from 8 to 256). In contrast, Tornado codes have encoding and decoding times that are proportional to (k + `) ln (1=*)P , where * is the reception overhead. <p> Tornado codes with standard codes that have been previously proposed for network applications <ref> [4, 14, 16, 17, 18, 19] </ref>. The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. <p> But another approach, described in the introduction, is the method of interleaving suggested in <ref> [14, 16, 17, 18] </ref>. Interleaved codes are constructed as follows: Suppose K + L encoding packets are to be produced from K file packets. Partition the K file packets into blocks of length k, so that there are B = K=k blocks in total. <p> The results we give can be interpolated to provide intuition for performance at intermediate rates of loss. For channels with very low loss rates, such as the 1% loss rates studied in <ref> [14] </ref>, use of interleaved codes is probably acceptable, even though Tornado codes perform equally well. receivers using interleaved codes with block sizes of 20 and 50, respectively. The average case is represented by the leftmost points in each graph, corresponding to the single receiver case.
Reference: [15] <author> M. O. Rabin, </author> <title> "Efficient Dispersal of Information for Security, Load Balancing, and Fault Tolerance." </title> <journal> In Journal of the ACM, </journal> <volume> Volume 38, </volume> <pages> pp. 335-348, </pages> <year> 1989. </year>
Reference-contexts: Those packets which experience congestion are delayed, but the destination can recover the data once a sufficient number of packets arrive, irrespective of the paths they took. This application dates back to the seminal information dispersal work of Rabin <ref> [15] </ref> who suggested using standard erasure codes. We expect Tornado codes will lead to improved practical dispersity routing schemes. Another application for which the Tornado code approximation might be useful arises in the context of mirrored data.
Reference: [16] <author> L. </author> <title> Rizzo, "Effective Erasure Codes for Reliable Computer Communication Protocols." </title> <booktitle> In Computer Communication Review, </booktitle> <month> April </month> <year> 1997. </year>
Reference-contexts: The problems with solutions based on retransmission have led many researchers to consider applying Forward Error Correction based on erasure codes 1 to reliable multicast <ref> [4, 12, 13, 14, 16, 17, 18, 19] </ref>. <p> Their work, and the work of many other authors, focus on erasure codes based on Reed-Solomon codes <ref> [5, 11, 12, 13, 16, 17, 18] </ref>. The limitation of these codes is that encoding and decoding times are slow, effectively limiting k to small values for practical applications. Hence, their solution involves breaking the source data into smaller blocks of packets and encoding over these blocks. <p> This limits the extent to which an erasure code can achieve the properties of a digital fountain. An obvious way to approximate a digital fountain also proposed by other researchers (e.g., <ref> [13, 16, 17, 19] </ref>) is to set n to be a multiple of k, and repeatedly cycle through and send the n encoding packets. Then, the client is guaranteed to be able to recover the original file as long as k distinct packets are received. <p> Tornado codes with standard codes that have been previously proposed for network applications <ref> [4, 14, 16, 17, 18, 19] </ref>. The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. <p> Tornado codes with standard codes that have been previously proposed for network applications [4, 14, 16, 17, 18, 19]. The erasure codes listed in Tables 2 and 3 as Vandermonde <ref> [16] </ref> and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. Both Tornado A and Tornado B codes were designed using some of the principles described in [8] and [9]. <p> But another approach, described in the introduction, is the method of interleaving suggested in <ref> [14, 16, 17, 18] </ref>. Interleaved codes are constructed as follows: Suppose K + L encoding packets are to be produced from K file packets. Partition the K file packets into blocks of length k, so that there are B = K=k blocks in total.
Reference: [17] <author> L. Rizzo and L. Vicisano, </author> <title> "A Reliable Multicast data Distribution Protocol Based on Software FEC Techniques." </title> <booktitle> In Proc. of HPCS '97, </booktitle> <address> Greece, </address> <month> June </month> <year> 1997. </year> <month> 19 </month>
Reference-contexts: The problems with solutions based on retransmission have led many researchers to consider applying Forward Error Correction based on erasure codes 1 to reliable multicast <ref> [4, 12, 13, 14, 16, 17, 18, 19] </ref>. <p> Their work, and the work of many other authors, focus on erasure codes based on Reed-Solomon codes <ref> [5, 11, 12, 13, 16, 17, 18] </ref>. The limitation of these codes is that encoding and decoding times are slow, effectively limiting k to small values for practical applications. Hence, their solution involves breaking the source data into smaller blocks of packets and encoding over these blocks. <p> Receivers may join the stream at any time, then listen until they receive all distinct packets comprising the transmission. Clearly, the reception overhead at a receiver, measured in terms of unnecessary receptions, can be extremely high using this approach. As shown in <ref> [17, 18] </ref>, adding redundant codewords to the carousel can dramatically reduce reception overhead. Using Reed-Solomon codes, these papers advocate adding a fixed amount of redundancy to blocks of the transmission. <p> This limits the extent to which an erasure code can achieve the properties of a digital fountain. An obvious way to approximate a digital fountain also proposed by other researchers (e.g., <ref> [13, 16, 17, 19] </ref>) is to set n to be a multiple of k, and repeatedly cycle through and send the n encoding packets. Then, the client is guaranteed to be able to recover the original file as long as k distinct packets are received. <p> Standard erasure codes also require somewhat complex finite field operations, further increasing their encoding and decoding times. As a result, standard erasure codes can only be applied in practice when k and ` are small. (Values used in <ref> [14, 17, 19, 18] </ref> have k and ` ranging from 8 to 256). In contrast, Tornado codes have encoding and decoding times that are proportional to (k + `) ln (1=*)P , where * is the reception overhead. <p> Tornado codes with standard codes that have been previously proposed for network applications <ref> [4, 14, 16, 17, 18, 19] </ref>. The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. <p> But another approach, described in the introduction, is the method of interleaving suggested in <ref> [14, 16, 17, 18] </ref>. Interleaved codes are constructed as follows: Suppose K + L encoding packets are to be produced from K file packets. Partition the K file packets into blocks of length k, so that there are B = K=k blocks in total. <p> Of course, use of a large stretch factor provides more flexibility, but slows decoding time and increases the space requirements for decoding. 3 For these reasons, we typically choose a stretch factor c = 2 as compared to c = 8 used in <ref> [17, 18] </ref>.
Reference: [18] <author> E. Schooler and J. </author> <title> Gemmell, "Using multicast FEC to solve the midnight madness problem," </title> <institution> Microsoft Research Technical Report MS-TR-97-25, </institution> <month> September </month> <year> 1997. </year>
Reference-contexts: 1 Introduction Software companies that plan to efficiently disseminate new software over the Internet to millions of users simultaneously will require multicast or broadcast transmission <ref> [18] </ref>. These transmissions must be fully reliable, have low network overhead, and support vast numbers of receivers with heterogeneous characteristics. Other activities which have similar requirements include distribution of video and financial information, database replication, and popular web site access. <p> The problems with solutions based on retransmission have led many researchers to consider applying Forward Error Correction based on erasure codes 1 to reliable multicast <ref> [4, 12, 13, 14, 16, 17, 18, 19] </ref>. <p> Their work, and the work of many other authors, focus on erasure codes based on Reed-Solomon codes <ref> [5, 11, 12, 13, 16, 17, 18] </ref>. The limitation of these codes is that encoding and decoding times are slow, effectively limiting k to small values for practical applications. Hence, their solution involves breaking the source data into smaller blocks of packets and encoding over these blocks. <p> Receivers may join the stream at any time, then listen until they receive all distinct packets comprising the transmission. Clearly, the reception overhead at a receiver, measured in terms of unnecessary receptions, can be extremely high using this approach. As shown in <ref> [17, 18] </ref>, adding redundant codewords to the carousel can dramatically reduce reception overhead. Using Reed-Solomon codes, these papers advocate adding a fixed amount of redundancy to blocks of the transmission. <p> Standard erasure codes also require somewhat complex finite field operations, further increasing their encoding and decoding times. As a result, standard erasure codes can only be applied in practice when k and ` are small. (Values used in <ref> [14, 17, 19, 18] </ref> have k and ` ranging from 8 to 256). In contrast, Tornado codes have encoding and decoding times that are proportional to (k + `) ln (1=*)P , where * is the reception overhead. <p> Tornado codes with standard codes that have been previously proposed for network applications <ref> [4, 14, 16, 17, 18, 19] </ref>. The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. <p> But another approach, described in the introduction, is the method of interleaving suggested in <ref> [14, 16, 17, 18] </ref>. Interleaved codes are constructed as follows: Suppose K + L encoding packets are to be produced from K file packets. Partition the K file packets into blocks of length k, so that there are B = K=k blocks in total. <p> Of course, use of a large stretch factor provides more flexibility, but slows decoding time and increases the space requirements for decoding. 3 For these reasons, we typically choose a stretch factor c = 2 as compared to c = 8 used in <ref> [17, 18] </ref>.
Reference: [19] <author> L. Vicisano, L. Rizzo, and J. Crowcroft. </author> <title> "TCP-like congestion control for layered multicast data transfer." </title> <note> To appear in INFOCOM '98. </note>
Reference-contexts: The problems with solutions based on retransmission have led many researchers to consider applying Forward Error Correction based on erasure codes 1 to reliable multicast <ref> [4, 12, 13, 14, 16, 17, 18, 19] </ref>. <p> The performance of the prototype bears out the simulation results, and it also demonstrates the interoperability of this work with the layered multicast techniques of <ref> [19] </ref>. We conclude with additional research directions for the digital fountain approach. 2 Requirements for an Ideal Protocol We recall an example application in which millions of clients want to download a new release of software over the course of several days. <p> This limits the extent to which an erasure code can achieve the properties of a digital fountain. An obvious way to approximate a digital fountain also proposed by other researchers (e.g., <ref> [13, 16, 17, 19] </ref>) is to set n to be a multiple of k, and repeatedly cycle through and send the n encoding packets. Then, the client is guaranteed to be able to recover the original file as long as k distinct packets are received. <p> Standard erasure codes also require somewhat complex finite field operations, further increasing their encoding and decoding times. As a result, standard erasure codes can only be applied in practice when k and ` are small. (Values used in <ref> [14, 17, 19, 18] </ref> have k and ` ranging from 8 to 256). In contrast, Tornado codes have encoding and decoding times that are proportional to (k + `) ln (1=*)P , where * is the reception overhead. <p> Tornado codes with standard codes that have been previously proposed for network applications <ref> [4, 14, 16, 17, 18, 19] </ref>. The erasure codes listed in Tables 2 and 3 as Vandermonde [16] and Cauchy [2] are standard implementations of Reed-Solomon erasure codes, based on Vandermonde matrices and Cauchy matrices, respectively. <p> Receiver heterogeneity and varying rates of network congestion motivate the need for distribution protocols which can support a variety of end-to-end bandwidth and packet loss rates. 7.1.1 Layering Across Multiple Multicast Groups The approach we take follows the lead of other authors who advocate layered multicast <ref> [10, 13, 19] </ref>. The main idea underlying this approach is to enable the source to transmit data across multiple multicast groups, thereby allowing the receiver to subscribe to an appropriate subset of these layers. <p> Thus, a receiver at subscription level i would receive bandwidth proportional to 2B i , for i 1. The protocol we use is based on the scheme described in <ref> [19] </ref> which proposes the following two novel ideas, summarized here briefly: * Congestion control is achieved by the use of synchronization points (SP's) which are specially marked packets in the stream.
Reference: [20] <author> M. Yajnik, J. Kurose, and D. Towsley, </author> <title> "Packet Loss Correlation in the MBone Multicast Network." </title> <booktitle> In Proceedings of IEEE Global Internet '96, </booktitle> <address> London, </address> <month> November </month> <year> 1996. </year>
Reference-contexts: This effect is completely avoided by using Tornado codes. 6.4 Trace Data To study the effects of real loss patterns, we perform a similar comparison using publicly available MBone trace data collected by Yajnik, Kurose, and Towsley <ref> [20] </ref>. Over a period of several months, clients from across the US and abroad subscribed to MBone broadcasts each of roughly an hour in length and reported which packets they received. Clients experienced loss rates ranging from less than 1% to over 30% over the course of these broadcasts.
Reference: [21] <author> R. Yavatkar, J. Griffoen and M. Sudan, </author> <title> "A Reliable Dissemination Protocol for Interactive Collaborative Applications." </title> <booktitle> In Proceedings of ACM Multimedia '95, </booktitle> <address> San Francisco, </address> <year> 1995, </year> <pages> pp. 333-344. </pages>
Reference-contexts: More sophisticated solutions which address these limitations by using techniques such as local repair, polling, or the use of a hierarchy have been proposed <ref> [3, 7, 10, 11, 21] </ref>, but these solutions as yet appear inadequate. Moreover, whereas retransmission-based solutions are at best unscalable and inefficient on terrestrial networks, they are unworkable on satellite networks, where the back channel typically has high latency and limited capacity, if it is available at all.
References-found: 21

