URL: http://larch-www.lcs.mit.edu:8001/~mtv/mit-lcs-tr-598.ps
Refering-URL: http://www.sds.lcs.mit.edu/spd/pub/index.html
Root-URL: 
Title: Exploiting Specifications to Improve Program Performance  
Author: Mark T. Vandevoorde 
Note: c flMassachusetts Institute of Technology, 1994  
Abstract: This report is a revised copy of the author's thesis, submitted to the Department of Electrical Engineering and Computer Science on May 28, 1993 in partial fulfillment of the requirements for the degree of Doctor of Philosophy, at the Massachusetts Institute of Technology. The author's current address is: MIT Lab for Computer Science, 545 Technology Square, Cambridge, Ma 02139. Internet: mtv@lcs.mit.edu 
Abstract-found: 1
Intro-found: 1
Reference: [1] <editor> Samson Abramsky and Chris Hankin, editors. </editor> <title> Abstract Interpretation of Declarative Languages. </title> <publisher> Ellis Horwood Limited, </publisher> <year> 1987. </year>
Reference-contexts: T e contains the formula Env d (`b') = true, but T d does not (unless the branch is always taken). In T e , e is analogous to the "collecting state" of edge e in the framework of abstract interpretation <ref> [1, 11] </ref>. The collecting state of an edge denotes the set of program states that can occur at the edge. <p> For each edge in a flow graph, the proof rules define an LSL theory that constrains the possible values of program states that can arise at the edge. The set of possible program state values corresponds to the "collecting state" in the literature on abstract interpretation <ref> [1, 11] </ref>. <p> Each data type must ensure that outside its implementation, locations of the type are never aliased to locations of other types. This makes it easier to perform optimizations. For example, consider the code a: array [monomer] := : : : p: polymer := : : : a <ref> [1] </ref> := p.left m := p.left If this code is outside the implementation of polymer, it is easy to prove that it is safe to eliminate the second call to get left: the result depends only on the value stored in polymerLoc p, and the only location modified by the code
Reference: [2] <author> Alfred Aho, Ravi Sethi, and Jeffrey Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <year> 1986. </year>
Reference-contexts: 1 The compiler may replace a [i] by x or, if x is assigned between the occurrences of a [i], by a temporary variable introduced by the compiler. 1 If the two occurrences of a [i] lie in different basic blocks, this optimization is sometimes called global common subexpression elimination <ref> [2] </ref>. 49 While common subexpressions are often syntactically identical, as in the example above, they may be syntactically different, as in the code fragment x := a+b z := y+a Here, y+a can be replaced by x if, as is the case in Speckle, assignment to one identifier cannot change the <p> Without unreduced, the rule above could not be ordered from left to right. Note that the axiom unreduced (s) = s must not be used; otherwise, LP would normalize away all occurrences of unreduced and order the rewrite rule in the opposite direction. 4 As defined in <ref> [2] </ref>, d immediately dominates e if d 6= e and d dominates e and no other dominator of e is dominated by d.
Reference: [3] <author> J. P. Banning. </author> <title> An efficient way to find the side effects of procedure calls and the aliases of variables. </title> <booktitle> In Proceedings of the 1979 Conference on Principles of Programming Languages, </booktitle> <pages> pages 29-41. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1979. </year>
Reference-contexts: Much work on alias analysis has been restricted to languages that do not allow pointers <ref> [3, 10] </ref> or that restrict pointers to at most one level of indirection [43]. Some exceptions are [7, 29, 33], which use interprocedural analysis.
Reference: [4] <author> Michel Bidoit. Pluss, </author> <title> un langage pour le developpement de specifications algebriques modulaires. </title> <type> PhD thesis, </type> <institution> Universite Paris-Sud, Orsay, </institution> <month> May </month> <year> 1989. </year> <note> These d'Etat. </note>
Reference-contexts: ANNA [40] provides a similar mechanism for both pre- and postconditions. Speckle differs in that it distinguishes partial specifications from full specifications. This distinction is used to prevent the compiler from performing unsound optimizations. The idea of writing specifications incrementally has also been studied for algebraic specifications. In <ref> [4, 5] </ref>, Bidoit distinguishes between "achieved" and "draft" specifications|a draft specification is analogous to a partial specification. His focus is on how to combine the theories of achieved and draft specifications in a modular fashion. The specification language is independent of any programming language.
Reference: [5] <author> Michel Bidoit. </author> <title> Development of modular specifications by stepwise refinements using the PLUSS specification language. </title> <booktitle> In Proc. of the IMA Unified Computation Laboratory Conference, Stirling, </booktitle> <address> Scotland, </address> <month> July </month> <year> 1990, </year> <pages> pages 171-192. </pages> <publisher> Oxford University Press, </publisher> <year> 1992. </year>
Reference-contexts: ANNA [40] provides a similar mechanism for both pre- and postconditions. Speckle differs in that it distinguishes partial specifications from full specifications. This distinction is used to prevent the compiler from performing unsound optimizations. The idea of writing specifications incrementally has also been studied for algebraic specifications. In <ref> [4, 5] </ref>, Bidoit distinguishes between "achieved" and "draft" specifications|a draft specification is analogous to a partial specification. His focus is on how to combine the theories of achieved and draft specifications in a modular fashion. The specification language is independent of any programming language.
Reference: [6] <author> W. W. Bledsoe and M. Tyson. </author> <title> The UT Interactive Prover. </title> <type> ATP 17, </type> <institution> University of Texas Mathematics Dept., </institution> <month> May </month> <year> 1975. </year>
Reference-contexts: Gypsy is a programming environment for verified software, so programs typically contain entry, exit, and other assertions. McHugh's 81 compiler generated optimization conjectures that, when discharged by the UT Interactive Prover <ref> [6] </ref>, resulted in the elimination of code supporting exceptions|i.e., a broad category of runtime checks. McHugh does not describe strategies used to prove the conjectures.
Reference: [7] <author> David R. Chase, Mark Wegman, and F. Kenneth Zadeck. </author> <title> Analysis of pointers and structures. </title> <booktitle> In Proceedings of the 1990 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 296-310. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year>
Reference-contexts: Much work on alias analysis has been restricted to languages that do not allow pointers [3, 10] or that restrict pointers to at most one level of indirection [43]. Some exceptions are <ref> [7, 29, 33] </ref>, which use interprocedural analysis. The alias analysis techniques in [7, 29, 33] annotate each edge in a FG with a summary graph approximating the data structures at that point in the program. <p> Much work on alias analysis has been restricted to languages that do not allow pointers [3, 10] or that restrict pointers to at most one level of indirection [43]. Some exceptions are <ref> [7, 29, 33] </ref>, which use interprocedural analysis. The alias analysis techniques in [7, 29, 33] annotate each edge in a FG with a summary graph approximating the data structures at that point in the program.
Reference: [8] <author> Jolly Chen. </author> <title> The Larch/Generic interface language. S. B. </title> <type> Thesis, </type> <institution> Department of Electrical Engineering and Computer Science, M.I.T., </institution> <month> May </month> <year> 1989. </year> <month> 133 </month>
Reference-contexts: This is useful in specifying iterators such as int$from to, which yields a subrange of integers in ascending order. 2.4 Related Work Larch/Speckle has many features in common with other interface languages, e.g., Larch/CLU [52], Larch/C [22], and Larch/C++ [34], as well as features in common with generic interface languages <ref> [8, 24, 35, 53] </ref>. Larch/Speckle is unique in that, as explained in Chapter 7, Larch/Speckle supports partial specifications. Because Speckle is based on CLU, Larch/Speckle is most like Larch/CLU.
Reference: [9] <author> John Cocke and Jacob T. Schwartz. </author> <title> Programming Languages and Their Compilers: Preliminary Notes. </title> <institution> Courant Institute of Mathematical Sciences, </institution> <address> New York University, </address> <year> 1970. </year>
Reference-contexts: Furthermore, the assertion New (p2) implies that p2 is not an alias for p. Since change cycle modifies only p2, p is not modified, so the values of p.left and p.right are unchanged. 4.5 Related Work 4.5.1 Conventional Techniques Conventional optimization techniques, e.g. <ref> [9, 12, 42, 46, 50] </ref>, all use some form of symbolic evaluation based on the semantics of the programming language. For example, value numbering [9], one of the earliest techniques, can eliminate primitive expressions such as sums and products. <p> For example, value numbering <ref> [9] </ref>, one of the earliest techniques, can eliminate primitive expressions such as sums and products.
Reference: [10] <author> Keith D. Cooper. </author> <title> Analyzing aliases of reference formal parameters. </title> <booktitle> In Proceedings of the 1985 Conference on Principles of Programming Languages, </booktitle> <pages> pages 281-290. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1985. </year>
Reference-contexts: Much work on alias analysis has been restricted to languages that do not allow pointers <ref> [3, 10] </ref> or that restrict pointers to at most one level of indirection [43]. Some exceptions are [7, 29, 33], which use interprocedural analysis.
Reference: [11] <author> Patrick Cousot and Radhia Cousot. </author> <title> Abstract Interpretation: A unified lattice model for static analysis of programs by construction or approximation of fixpoints. </title> <booktitle> In Proceedings of the 1977 Conference on Principles of Programming Languages. ACM, </booktitle> <year> 1977. </year>
Reference-contexts: T e contains the formula Env d (`b') = true, but T d does not (unless the branch is always taken). In T e , e is analogous to the "collecting state" of edge e in the framework of abstract interpretation <ref> [1, 11] </ref>. The collecting state of an edge denotes the set of program states that can occur at the edge. <p> For each edge in a flow graph, the proof rules define an LSL theory that constrains the possible values of program states that can arise at the edge. The set of possible program state values corresponds to the "collecting state" in the literature on abstract interpretation <ref> [1, 11] </ref>.
Reference: [12] <author> J. Ferrante, K. J. Ottenstein, and J. D. Warren. </author> <title> The program dependence graph and its use in optimization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 9(3) </volume> <pages> 319-349, </pages> <month> July </month> <year> 1987. </year>
Reference-contexts: Furthermore, the assertion New (p2) implies that p2 is not an alias for p. Since change cycle modifies only p2, p is not modified, so the values of p.left and p.right are unchanged. 4.5 Related Work 4.5.1 Conventional Techniques Conventional optimization techniques, e.g. <ref> [9, 12, 42, 46, 50] </ref>, all use some form of symbolic evaluation based on the semantics of the programming language. For example, value numbering [9], one of the earliest techniques, can eliminate primitive expressions such as sums and products.
Reference: [13] <author> Robert W. Floyd. </author> <title> Assigning meanings to programs. </title> <booktitle> In Proceedings of Symposia in Applied Mathematics, </booktitle> <volume> volume 19, </volume> <pages> pages 19-31. </pages> <publisher> American Mathematical Society, </publisher> <year> 1967. </year>
Reference-contexts: However, in a language with exceptions, it is awkward 35 to use Hoare rules for the same reason that it is awkward to give Hoare rules for statements like break and continue. Therefore, I use Floyd's approach <ref> [13] </ref> and define proof rules for Speckle programs that have been converted into control flow graphs (FGs). These rules represent a (partial) semantics for Speckle. A program is an implementation of a procedure. <p> The flow graph for the code is shown in Fig. 3.1. 3.4 Summary and Related Work The proof rules for programs are a form of Hoare rules [26] for programs that are formalized as flow graphs, as in <ref> [13] </ref>, rather than parse trees. The proof rules rely on data type specifications to define the program state (see Chapter 2), and on procedure specifications to describe the effect of procedure calls.
Reference: [14] <author> Stefan M. Freudenberger, Jacob T. Schwartz, and Micha Sharir. </author> <title> Experience with the SETL optimizer. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(1) </volume> <pages> 26-45, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: His focus is on how to combine the theories of achieved and draft specifications in a modular fashion. The specification language is independent of any programming language. The SETL compiler uses types to reason about reachability <ref> [14] </ref>. The compiler relies on definitions of containment and reachability for primitive types to identify when the source of a copy operation would always become garbage, obviating the need for the copy. SETL does not support data abstraction explicitly, so there is no use for contains clauses.
Reference: [15] <author> S. J. Garland, J. V. Guttag, and J. J. Horning. </author> <title> Debugging Larch Shared Language specifications. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 16(9) </volume> <pages> 1044-1075, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: The implies section lists formulas that should follow from the axioms using the normal inference rules of predicate logic. Implications are a source of redundant information that can be used to detect inconsistencies and omissions in specifications <ref> [15] </ref>. In Speckle, implications are used as additional information for proving that an optimization is safe. The semantics of LSL defines a theory|an infinite set of formulas|for a trait.
Reference: [16] <author> S.J. Garland and J.V. Guttag. </author> <title> A guide to LP, The Larch Prover. </title> <type> TR 82, </type> <institution> DEC Systems Research Center, </institution> <address> Palo Alto, CA, </address> <month> December </month> <year> 1991. </year>
Reference-contexts: CLU has static typing, so there is no need to optimize away runtime type checks. CLU has side effects and pointers, 1 so the compiler must handle aliasing. I chose Larch because of the tools available for checking and reasoning about Larch specifications <ref> [16] </ref> and because there were already techniques for specifying CLU programs using Larch [52]. I implemented a prototype Speckle compiler that incorporates parts of a general-purpose theorem-prover, LP [16], to identify opportunities to perform optimizations. <p> I chose Larch because of the tools available for checking and reasoning about Larch specifications <ref> [16] </ref> and because there were already techniques for specifying CLU programs using Larch [52]. I implemented a prototype Speckle compiler that incorporates parts of a general-purpose theorem-prover, LP [16], to identify opportunities to perform optimizations. The compiler recognizes three kinds of conventional optimizations: common subexpression elimination, 2 moving code out of loops, and dead code elimination. It also identifies opportunities to use SPIs. 1.2.1 Design Goals Several key ideas drove the design of Speckle. <p> Euclid and FX are more general than Larch/Speckle because they allow programs to use multiple collections or regions of data of a single type. I chose to use Larch because it came with both a theorem-prover for reasoning about Larch specifications (LP <ref> [16] </ref>) and techniques for 33 specifying CLU programs using Larch [52]. However, there are many generic specification languages other than Larch that could also be used as the basis for program optimization. Perhaps the language most similar to Larch is VDM [27, 28]. <p> v), t)) ensuring s' = s ^ extend2 = proc (s: substitution, v: variable, t: term) requires v =2 vars (apply (unbind (s, v), t)) modifies s ensures s' = bind (s ^ , v, t) code fragment in Fig. 5.3, which is taken from the source code of LP <ref> [16] </ref>, a theorem-prover. Because the call to lookup signals missing only when k is not defined in t, and because the call to value$create () modifies nothing, k cannot be defined in t when store is called. Fig. 5.4 contains another example of the conflict between generality and efficiency. <p> To explore these issues and to test the ideas of the previous chapters, I constructed a prototype Speckle compiler, PSC. The inference engine of PSC is a stripped-down, automated version of the interactive theorem-prover LP (version 2.2a) <ref> [16, 22] </ref>. LP is particularly well-suited for Speckle because it was designed to work with LSL and because it fails quickly when trying to prove a difficult conjecture rather than attempting expensive proof strategies. This is important because most conjectures PSC tries to prove are false.
Reference: [17] <author> Stephen J. Garland, John V. Guttag, and James J. Horning. </author> <title> Debugging Larch Shared Language specifications. </title> <type> Report 60, </type> <institution> DEC Systems Research Center, </institution> <address> Palo Alto, CA, </address> <month> July 4, </month> <year> 1990. </year>
Reference-contexts: only edges that dominate e, or 2. a term that doesn't contain any program state symbols. (This case can be viewed as a special case of (1).) LP uses a simplification ordering to choose whether to convert an equation a = b into a ! b or b ! a <ref> [17] </ref>. To encourage LP to rewrite terms towards the entering edge, PSC imposes the dominates partial order onto LP's simplification ordering. If e 1 dominates e 2 , PSC makes the term 1 simpler than 2 in the simplification ordering.
Reference: [18] <author> Steven M. </author> <title> German. Verifying the absence of common runtime errors in computer programs. </title> <type> Technical Report CS-81-866, </type> <institution> Stanford, </institution> <month> June </month> <year> 1981. </year>
Reference-contexts: To make such specifications useful to a compiler, one would first have to develop an interface language that relates the semantics of Z to that of the programming language. Another approach in developing specification languages is to design them for particular programming languages. German <ref> [18] </ref> uses a language tailored for Pascal, and McHugh [41] uses one tailored for Gypsy, a derivative of Pascal. Neither of these languages supports data abstraction as well as CLU. <p> This requires proving properties sufficient to eliminate runtime checks in array references, numeric operations, assignments from supertypes to subtypes, etc. The language does not have pointers, so the problem of aliasing is simpler than in Speckle. Sites simulates his technique manually on several examples. In <ref> [18] </ref>, German develops a tool for verifying the absence of runtime errors, such as arithmetic overflow and invalid array indices.
Reference: [19] <editor> David Gries. </editor> <booktitle> The Science of Programming. </booktitle> <publisher> Springer-Verlag, </publisher> <year> 1981. </year>
Reference-contexts: Although the proof rules could be used to verify that the preconditions are satisfied, this has been extensively studied by others, e.g. <ref> [19, 26, 39] </ref>, and is not a part of my research. 3.2 Programs as Annotated Control Flow Graphs Hoare rules are a standard way of defining proof rules for programs in terms of their structure [26].
Reference: [20] <author> Rajiv Gupta. </author> <title> A fresh look at optimizing array bound checking. </title> <booktitle> In Proceedings of the 1990 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 272-282. </pages> <publisher> ACM, </publisher> <month> June </month> <year> 1990. </year> <month> 134 </month>
Reference-contexts: To get theses optimizations, the author of remove duplicates did not have to write any specifications. Instead, the compiler used the specifications of the procedures and data types used in remove duplicates. On the surface, many of the array optimizations seem similar to those in <ref> [20] </ref>. However, there is a significant difference. In [20], the compiler relies on the semantics of arrays as defined by the programming language. The technique does not work for optimizations of user-defined data types, e.g., sets. <p> Instead, the compiler used the specifications of the procedures and data types used in remove duplicates. On the surface, many of the array optimizations seem similar to those in <ref> [20] </ref>. However, there is a significant difference. In [20], the compiler relies on the semantics of arrays as defined by the programming language. The technique does not work for optimizations of user-defined data types, e.g., sets. <p> McHugh's 81 compiler generated optimization conjectures that, when discharged by the UT Interactive Prover [6], resulted in the elimination of code supporting exceptions|i.e., a broad category of runtime checks. McHugh does not describe strategies used to prove the conjectures. In <ref> [20] </ref>, Gupta reduces the overhead of array bounds checks by eliminating redundant checks that occur in code fragments such as "a [i] := a [i]+1" and by moving checks out of loops. The strategy used relies on the programming language semantics of arrays and does not extend to user-defined types.
Reference: [21] <author> J. V. Guttag, J. J. Horning, and J. M. Wing. </author> <title> The Larch Family of Specification Languages. </title> <journal> IEEE Software, </journal> <volume> 2(5) </volume> <pages> 24-36, </pages> <year> 1985. </year>
Reference-contexts: The programming language portion is mostly a subset of CLU [36], and the specification language portion is based on Larch <ref> [21, 22] </ref>. CLU has several features that make it an appropriate starting point for Speckle. CLU supports both procedural and data abstraction, which are the primary ways to simplify reasoning about programs. CLU has static typing, so there is no need to optimize away runtime type checks.
Reference: [22] <author> J. V. Guttag, J. J. Horning, with S. J. Garland, K. D. Jones, A. Modet, and J. M. Wing. </author> <title> Larch: Languages and Tools for Formal Specification. Texts and Monographs in Computer Science. </title> <publisher> Springer-Verlag, </publisher> <year> 1993. </year>
Reference-contexts: The programming language portion is mostly a subset of CLU [36], and the specification language portion is based on Larch <ref> [21, 22] </ref>. CLU has several features that make it an appropriate starting point for Speckle. CLU supports both procedural and data abstraction, which are the primary ways to simplify reasoning about programs. CLU has static typing, so there is no need to optimize away runtime type checks. <p> LSL is used to define useful functions in a fragment of multisorted first-order predicate logic. The glue between a programming language and LSL is the interface tier, which provides an interface language for each programming language, e.g., Larch/CLU [52], Larch/C <ref> [22] </ref>, Larch/C++ [34], etc. Each interface language formalizes the notion of a program state and provides a syntax and semantics for specifying procedure interfaces and data abstractions. * A procedure specification is a predicate on pre- and post-states. <p> This is useful in specifying iterators such as int$from to, which yields a subrange of integers in ascending order. 2.4 Related Work Larch/Speckle has many features in common with other interface languages, e.g., Larch/CLU [52], Larch/C <ref> [22] </ref>, and Larch/C++ [34], as well as features in common with generic interface languages [8, 24, 35, 53]. Larch/Speckle is unique in that, as explained in Chapter 7, Larch/Speckle supports partial specifications. Because Speckle is based on CLU, Larch/Speckle is most like Larch/CLU. <p> To explore these issues and to test the ideas of the previous chapters, I constructed a prototype Speckle compiler, PSC. The inference engine of PSC is a stripped-down, automated version of the interactive theorem-prover LP (version 2.2a) <ref> [16, 22] </ref>. LP is particularly well-suited for Speckle because it was designed to work with LSL and because it fails quickly when trying to prove a difficult conjecture rather than attempting expensive proof strategies. This is important because most conjectures PSC tries to prove are false.
Reference: [23] <author> John V. Guttag, James J. Horning, and Andres Modet. </author> <title> Report on the Larch Shared Language: Version 2.3. </title> <type> Report 58, </type> <institution> DEC Systems Research Center, </institution> <address> Palo Alto, CA, </address> <month> April 14, </month> <year> 1990. </year>
Reference-contexts: Thus, program states are more abstract than if they were defined using only the sorts corresponding to primitive types. 2.1.1 The Larch Shared Language The semantics of LSL is defined precisely in <ref> [23] </ref>. This section is just an informal synopsis of LSL features that are relevant to Speckle. LSL specifications are written in units called traits. Fig. 2.1 is an example of a trait for sets. A trait begins with a name followed by sort parameters, if any.
Reference: [24] <author> David Hinman. </author> <title> On the design of Larch interface languages. </title> <type> Master's thesis, </type> <institution> Department of Electrical Engineering and Computer Science, M.I.T., </institution> <month> January </month> <year> 1987. </year>
Reference-contexts: This is useful in specifying iterators such as int$from to, which yields a subrange of integers in ascending order. 2.4 Related Work Larch/Speckle has many features in common with other interface languages, e.g., Larch/CLU [52], Larch/C [22], and Larch/C++ [34], as well as features in common with generic interface languages <ref> [8, 24, 35, 53] </ref>. Larch/Speckle is unique in that, as explained in Chapter 7, Larch/Speckle supports partial specifications. Because Speckle is based on CLU, Larch/Speckle is most like Larch/CLU.
Reference: [25] <author> Andy Hisgen. </author> <title> Optimization of User-Defined Abstract Data Types: </title>
Reference-contexts: Related work is discussed throughout the thesis. To my knowledge, only Hisgen has previously examined the idea of letting programmers define optimizations in an imperative language <ref> [25] </ref>. Other closely related works are discussed in Chapters 4 and 5. 20 Chapter 2 Larch/Speckle This chapter describes most of the Larch/Speckle specification language| it omits only the features for partial specifications, which are described in Chapter 7. <p> In <ref> [25] </ref>, Hisgen presents an unimplemented design of a strategy based on transformation rules rather than specifications. The source language is a derivative of ADA. To define an optimization, an implementor describes transformations to be performed by the compiler. <p> For example, in <ref> [25] </ref>, a procedure header may contain a formal postcondition, but the full postcondition need not be written formally. ANNA [40] provides a similar mechanism for both pre- and postconditions. Speckle differs in that it distinguishes partial specifications from full specifications. <p> SPIs also improve modularity, since the programmer can add or remove a specialized implementation and let the compiler worry about updating client code. User-defined optimizations like SPIs were previously studied in <ref> [25] </ref>. Because the approach there was based on transformation rules rather than specifications, it lacked modularity. Furthermore, this thesis appears to be novel in that it addresses the problem of propagating optimizations across levels of data abstraction. * Partial Specifications. Partial specifications allow users to write specifications incrementally.
References-found: 25

