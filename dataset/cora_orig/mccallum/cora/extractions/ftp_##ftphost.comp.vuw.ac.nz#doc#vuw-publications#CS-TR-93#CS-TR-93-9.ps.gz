URL: ftp://ftphost.comp.vuw.ac.nz/doc/vuw-publications/CS-TR-93/CS-TR-93-9.ps.gz
Refering-URL: http://www.comp.vuw.ac.nz/~jones/publications/publications_3.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: Internet: Tech.Reports@comp.vuw.ac.nz  
Title: The Lfl Parsing Algorithm  
Phone: Tel: +64 4 471 5328  
Author: Eric K. Jones and Linton M. Miller 
Address: PO Box 600 Wellington New Zealand  
Affiliation: VICTORIA UNIVERSITY OF WELLINGTON VUW Department of Computer Science  
Abstract: Technical Report CS-TR-93/9 December 1993 Abstract This report describes a new algorithm for table-driven parsing with arbitrary context-free grammars. The algorithm provides a framework in which a variety of parser control strategies can be freely specified: bottom-up strategies, top-down strategies, and strategies that strike a balance between the two. The algorithm thus combines the flexibility of chart parsing with the low overhead of table-driven approaches, and should find ready application to natural language processing. Publishing Information A shorter version of this report has been accepted for the 17th Annual Computer Science Conference to be held in Christchurch, New Zealand, January 1994. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Alfred V. Aho and Jeffrey D. Ullman. </author> <title> The Theory of Parsing, Translation, and Compiling. </title> <publisher> Prentice-Hall, </publisher> <year> 1972. </year>
Reference-contexts: The parser next carries out the eager reduction e1-2 and creates a new forest node S from NP 1 and VP, and a new stack vertex with state determined from ACTION [0, S] = fg1g. The entry ACTION <ref> [1, EAG ] </ref> is blank, so we do nothing further at this vertex (third diagram of figure 4). No unprocessed reductions remain for the current word (the), so the parser finally performs the shift action s9, shifting the onto the stack. <p> Having completed the VP node, the parser next performs a second completing reduction, this time by rule 1, which indicates that the S is also complete. A single stack top remains, with state 1 (bottom diagram of figure 5). As ACTION <ref> [1, $] </ref> = faccg, the parse succeeds. S is the root of the resulting parse tree. 3.2 Local Ambiguity Packing The example described above does not involve the problem of local ambiguity packing. <p> More generally, any context-free grammar can be easily transformed into a grammar in Chomsky Normal Form that generates the same language <ref> [1] </ref>. Billot and Lang [3] describe an optimal packing strategy for arbitrary context-free grammars similar to this transformation procedure, which could be easily incorporated into our current algorithm. Whichever packing strategy is chosen, eager reduction makes local ambiguity packing difficult to implement.
Reference: [2] <author> Alfred V. Aho and Jeffrey D. Ullman. </author> <title> Principles of Compiler Design. </title> <publisher> Addison-Wesley, </publisher> <year> 1977. </year>
Reference-contexts: Existing parsers exhibit a tradeoff between efficiency and flexibility of control. Chart parsers encode their dynamic state as a large set of edges [8] or items <ref> [2] </ref> in a data structure called a chart. Maintaining these edges requires a high constant-factor overhead at each stage of the parse. By contrast, table-driven approaches such as GLR parsing perform much of this computation off line, when the parse table is constructed. <p> A new forest node NP 1 is 4 John saw also created for the new vertex, with a single child, the node N 1 (bottom diagram of figure 3). At this new vertex, ACTION <ref> [2, V] </ref> = fs6g, so we shift the verb saw onto the stack, creating a new stack node with state 6. The following word is the, with lexical category Det. ACTION [6, Det] = fe4-1, s9g (top diagram of figure 4). <p> This state is determined using the parse table entry ACTION <ref> [2, VP] </ref> = fg7g. We draw the parse tree for VP with dashed and dotted lines to indicate that the the 5 $ $ the parse of the VP is not yet complete (second diagram of figure 4).
Reference: [3] <author> Sylvie Billot and Bernard Lang. </author> <title> The structure of shared forests in ambiguous parsing. </title> <booktitle> In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 143-151, </pages> <address> Vancouver, British Columbia, </address> <year> 1989. </year> <booktitle> ACL. </booktitle>
Reference-contexts: The newly created vertex becomes the stack top, so it is drawn as a circle; the original circle is redrawn as a square (middle diagram of figure 3). The next word is saw, whose lexical category is V. ACTION <ref> [3, V] </ref> = fr3g, so we carry out a normal, non-eager reduction by rule 3. The vertex labeled N 1 corresponds to the RHS of rule 3 and is accordingly popped off the stack. <p> More generally, any context-free grammar can be easily transformed into a grammar in Chomsky Normal Form that generates the same language [1]. Billot and Lang <ref> [3] </ref> describe an optimal packing strategy for arbitrary context-free grammars similar to this transformation procedure, which could be easily incorporated into our current algorithm. Whichever packing strategy is chosen, eager reduction makes local ambiguity packing difficult to implement.
Reference: [4] <author> Gerald Gazdar and Chris Mellish. </author> <title> Natural Language Processing in Prolog. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: 1 Introduction Parsers for general context-free grammars have found wide application in natural language processing, because grammars for natural languages are close to context-free <ref> [4] </ref>. To be useful in natural language processing, however, a parsing algorithm must cope well with grammatical ambiguity, as natural language grammars are highly ambiguous.
Reference: [5] <author> P. S. Jacobs, G. R. Krupka, and L. F. Rau. </author> <title> Lexico-semantic pattern matching as a companion to parsing in text understanding. </title> <booktitle> In Proceedings of the Speech and Natural Language Workshop, </booktitle> <pages> pages 337-341, </pages> <address> Pacific Grove, California, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The number of valid syntactic parses of a natural language sentence can be larger than exponential in the length of the sentence [9], and sentences of average length occurring in newspaper stories often admit hundreds of parses <ref> [5] </ref>. Most of the time, however, only one of these many parses is consistent with context and the meanings of the words in the sentence. Systems for natural language understanding must therefore be carefully designed to prune out undesirable partial parses as soon as possible using semantic information.
Reference: [6] <author> Eric K. Jones and Linton M. Miller. </author> <title> Eager GLR parsing. </title> <booktitle> In First Australian Workshop on Natural Language Processing and Information Retrieval, </booktitle> <address> Melbourne, Australia, </address> <month> November </month> <year> 1992. </year>
Reference-contexts: Pure bottom-up parsers are unnecessarily inefficient because they often fail to allow semantic information to be brought to bear as early as practicable in processing to prune unpromising partial parses <ref> [6] </ref>. Pure top-down parsers are likewise inefficient, because they explore syntactic hypotheses that are entirely unsupported by the input. Moreover, certain natural language phenomena such as traces are most efficiently analysed top down, while others such as coordinate conjunctions are best parsed bottom up [13]. <p> At this new vertex, ACTION [2, V] = fs6g, so we shift the verb saw onto the stack, creating a new stack node with state 6. The following word is the, with lexical category Det. ACTION <ref> [6, Det] </ref> = fe4-1, s9g (top diagram of figure 4). <p> This word is shifted onto the stack, making the terminator $ the current word (top diagram of figure 5). Next, the parser reduces Det N 2 at the top of the stack to NP 2 by rule 2. 6 ACTION <ref> [6, NP] </ref> = fg10, c4g, so the new vertex resulting from this reduction has state 10. The combine action also means that forest node NP 2 is combined into the VP created previously during eager reduction by rule 4. <p> We hypothesise that the algorithm will achieve unusually high efficiency because it is table driven but also accommodates parser control strategies that may yield efficiency gains over straight bottom-up or top-down parsing. For example, in <ref> [6] </ref> we advocate a parsing strategy that aims to minimise overall search within a natural language understander by eagerly reducing whenever the reduction is likely to generate semantic preferences that resolve local ambiguities. We are currently conducting experiments to test our hypothesis that strategies such as this can improve performance.
Reference: [7] <author> Ronald M. Kaplan. </author> <title> A general syntactic processor. </title> <editor> In Randall Rustin, editor, </editor> <booktitle> Natural Language Processing, </booktitle> <pages> pages 193-241. </pages> <publisher> Algorithmic Press, </publisher> <year> 1973. </year>
Reference-contexts: Ideally, a parser should be designed to balance top-down and bottom-up processing so as to minimise the total effort of the natural language processing system as a whole. The general framework of chart parsing <ref> [7] </ref> allows users to freely specify a range of parser control strategies and is consequently often the method of choice in real-world applications. Existing parsers exhibit a tradeoff between efficiency and flexibility of control. <p> The parser therefore simply carries out all cascaded reductions that could conceivably be appropriate. To implement this idea, we introduce a dummy symbol EAG. ACTION [st, EAG ] contains the set of cascaded reductions to perform at state st after performing an eager reduction. In our example, ACTION <ref> [7, EAG ] </ref> = fe1-2g. This reduction is eager, even though it involves the complete RHS of rule 1, because there is as yet no complete parse corresponding to the last symbol of its RHS (a VP).
Reference: [8] <author> Martin Kay. </author> <title> Algorithm schemata and data structures in syntactic processing. </title> <editor> In Barbara J. Grosz, Karen S. Jones, and Bonnie L. Webber, editors, </editor> <booktitle> Readings in Natural Language Processing, </booktitle> <pages> pages 35-70. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: Existing parsers exhibit a tradeoff between efficiency and flexibility of control. Chart parsers encode their dynamic state as a large set of edges <ref> [8] </ref> or items [2] in a data structure called a chart. Maintaining these edges requires a high constant-factor overhead at each stage of the parse. By contrast, table-driven approaches such as GLR parsing perform much of this computation off line, when the parse table is constructed.
Reference: [9] <author> Hiroshi Maruyama. </author> <title> Structural disambiguation with constraint propagation. </title> <booktitle> In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 31-38, </pages> <address> Pittsburgh, Pennsylvania, </address> <year> 1990. </year> <booktitle> ACL. </booktitle>
Reference-contexts: To be useful in natural language processing, however, a parsing algorithm must cope well with grammatical ambiguity, as natural language grammars are highly ambiguous. The number of valid syntactic parses of a natural language sentence can be larger than exponential in the length of the sentence <ref> [9] </ref>, and sentences of average length occurring in newspaper stories often admit hundreds of parses [5]. Most of the time, however, only one of these many parses is consistent with context and the meanings of the words in the sentence.
Reference: [10] <author> Linton M. Miller. </author> <title> Flexible table-driven parsing for natural language understanding. </title> <type> Master's thesis, </type> <institution> Victoria University of Wellington, </institution> <year> 1994. </year> <note> (In preparation.) </note>
Reference-contexts: The opposite extreme is to never eagerly reduce, which yields a standard, bottom-up GLR parser. Parser control strategies are specified as an input to the parse table builder. For a given grammar, a different choice of control strategy will yield a different parse table. In <ref> [10] </ref>, we describe an algorithm 1 We assume a basic familiarity with LR parsing. 2 for parse table construction that allows the user to specify a range of control strategies and produces parse tables for each. <p> The combine action also means that forest node NP 2 is combined into the VP created previously during eager reduction by rule 4. The combine action installs NP 2 as the rightmost child of the VP, but leaves the stack unchanged (second diagram of figure 5). ACTION <ref> [10, $] </ref> = fr4g covers the same ground as the eager reduction by rule 4 carried out previously. It is therefore a completing reduction, whose job it is to indicate that the earlier eager reduction is indeed correct.
Reference: [11] <author> Yves Schabes. </author> <title> Polynomial time and space shift-reduce parsing of arbitrary context-free grammars. </title> <booktitle> In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 106-113, </pages> <address> Berkeley, California, </address> <month> June </month> <year> 1991. </year> <booktitle> ACL. </booktitle>
Reference-contexts: Efficiency: Even in the best of circumstances, a parser has to consider large numbers of partial parses, so it must be able to produce these parses efficiently. Table-driven algorithms such as generalised LR (GLR) parsing [14] or the method of Schabes <ref> [11] </ref> are significantly more efficient in practical applications than other approaches such as chart parsing, even though they may have the same worst-case complexity. 2.
Reference: [12] <author> Patrick Shann. </author> <title> Experiments with GLR and chart parsing. </title> <editor> In Masaru Tomita, editor, </editor> <booktitle> Generalized LR Parsing, </booktitle> <pages> pages 17-34. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year>
Reference-contexts: Local ambiguity packing can reduce the amount of stack and parse forest structure created by an exponential factor and has been shown to yield substantial efficiency gains in practice <ref> [12] </ref>. Our current strategy for packing is derived from the approach followed by Tomita [14], which packs different derivations that cover the same input substring by creating a single common parent.
Reference: [13] <author> Sam Steel and Anne N. De Roeck. </author> <title> Bidirectional chart parsing. </title> <editor> In Christopher S. Mellish and John Hallam, editors, </editor> <booktitle> Advances in Artificial Intelligence (Proceedings of AISB-87), </booktitle> <pages> pages 223-235. </pages> <editor> J. </editor> <publisher> Wiley and Son, </publisher> <year> 1987. </year>
Reference-contexts: Pure top-down parsers are likewise inefficient, because they explore syntactic hypotheses that are entirely unsupported by the input. Moreover, certain natural language phenomena such as traces are most efficiently analysed top down, while others such as coordinate conjunctions are best parsed bottom up <ref> [13] </ref>. Ideally, a parser should be designed to balance top-down and bottom-up processing so as to minimise the total effort of the natural language processing system as a whole.
Reference: [14] <author> Masaru Tomita. </author> <title> Efficient Parsing for Natural Language. </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1986. </year>
Reference-contexts: Efficiency: Even in the best of circumstances, a parser has to consider large numbers of partial parses, so it must be able to produce these parses efficiently. Table-driven algorithms such as generalised LR (GLR) parsing <ref> [14] </ref> or the method of Schabes [11] are significantly more efficient in practical applications than other approaches such as chart parsing, even though they may have the same worst-case complexity. 2. <p> Local ambiguity packing can reduce the amount of stack and parse forest structure created by an exponential factor and has been shown to yield substantial efficiency gains in practice [12]. Our current strategy for packing is derived from the approach followed by Tomita <ref> [14] </ref>, which packs different derivations that cover the same input substring by creating a single common parent.
Reference: [15] <author> Masaru Tomita and See-Kiong Ng. </author> <title> The generalized LR parsing algorithm. </title> <editor> In Masaru Tomita, editor, </editor> <booktitle> Generalized LR Parsing, </booktitle> <pages> pages 1-16. </pages> <publisher> Kluwer Academic Publishers, </publisher> <year> 1991. </year> <month> 9 </month>
Reference-contexts: In this case, each reduction corresponds to an alternative parse of the substring headed by the same nonterminal. For a more detailed description of GLR parsing, the reader is referred to <ref> [15] </ref>. 3 Table-Driven Lfl Parsing To implement our table-driven parser with flexible control, we alter a GLR parser to allow it to eagerly reduce a grammar rule before its entire RHS has been seen. The missing elements of the RHS are then combined into the parse as they arrive.
References-found: 15

