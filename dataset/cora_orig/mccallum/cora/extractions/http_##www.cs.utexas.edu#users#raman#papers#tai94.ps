URL: http://www.cs.utexas.edu/users/raman/papers/tai94.ps
Refering-URL: http://www.cs.utexas.edu/users/raman/my-papers.html
Root-URL: 
Email: raman@cs.utexas.edu  
Title: The Figure Understander: A Tool for the Integration of Text and Graphical Input to a
Author: Raman Rajagopalan 
Address: Austin, Texas, 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  
Abstract: This paper describes the Figure Understander, a tool for integrating multimedia input in the form of graphically-drawn diagrams and text to a knowledge base. This tool has been designed to support applications, such as a story or map understanding system, that will benefit from the ability to input a spatial scene compactly through a diagram, but may require additional text to describe the domain properties of objects. Previous solutions to the problem of integrating text and pictorial input have been based on associating spatial images with text objects. The ambiguities associated with these methods are well known. We present an alternate approach which eliminates many of the sources of ambiguity by allowing semantic information to be provided directly within diagram objects. We illustrate the utility of our method through examples from two independent applications. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Crawford and B. Kuipers. </author> <title> Algernon a tractable system for knowledge-representation. </title> <booktitle> In AAAI Spring Symposium on Implemented Knowledge Representation and Reasoning Systems, </booktitle> <address> Palo Alto, CA, </address> <year> 1991. </year>
Reference-contexts: Its output is a knowledge base fragment that contains an integrated description of the information in each form of input. In the current implementation, the Figure Under-stander operates on the Postscript files produced by the Interviews drawing editor, and the Algernon knowledge representation language <ref> [1] </ref> is used to maintain the knowledge base. The techniques described in this paper could be easily adopted to other drawing and CAD/CAM tools. 2.1 Figure Understander Architecture The Figure Understander contains a diagram processing component and a text processing component. Diagram processing always precedes text processing.
Reference: [2] <author> A. Herskovits. </author> <title> Semantics and pragmatics of locative expressions. </title> <journal> Cognitive Science, </journal> <volume> 9(3) </volume> <pages> 341-378, </pages> <year> 1985. </year>
Reference-contexts: For example, we can infer that some object, A, is to the left of another object, B, if the inequality relation (rightmost (A) &lt; leftmost (B)) is satisfied. These definitions represent `ideal meanings', as used by Her-skovits <ref> [2] </ref>. The advantages and limitations of this method, its extensions for reasoning about orientation and for reasoning about translational and rotational motion are described in detail in [5]. 4.5 Annotated Demonstration The previous sections have described the rationale and theory behind the implemented code.
Reference: [3] <author> J. Larkin and H. Simon. </author> <title> Why a diagram is (sometimes) worth 10,000 words. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 65-99, </pages> <year> 1987. </year>
Reference-contexts: sloping line with the word `track'. 5.2 Applicability Of Our Solution Our solution addresses the question "Are there any simpler, but unrestrictive, methods that allow diagrams and text to be used as computer input?" The goal is to take advantage of the power of diagrams for describing the spatial state <ref> [3] </ref> and yet retain the ability to use text-based input to describe other properties of interest. We assume that the users of the Figure Understander will wish to present the input in an ambiguity-free manner. Our solution explores methods for achieving this.
Reference: [4] <author> G. Novak and W. Bulko. </author> <title> Diagrams and text as computer input. </title> <journal> Journal of Visual Languages and Computing, </journal> <volume> 4 </volume> <pages> 161-175, </pages> <year> 1993. </year>
Reference-contexts: The diagram objects are lines, polygons, and circles. The text problem statement uses domain-specific terms, such as `disk' and `track', to describe the same objects. The coreference problem <ref> [4] </ref> is to associate object references in text with the appropriate diagram objects. Human readers can make use of a large "common-sense" knowledge base to quickly visualize the spatial properties of an object mentioned in the text description and identify the appropriate object (s) in a picture. <p> Human readers can make use of a large "common-sense" knowledge base to quickly visualize the spatial properties of an object mentioned in the text description and identify the appropriate object (s) in a picture. Automated solutions can follow the same strategy <ref> [4, 9, 10] </ref> but must face the challenging task of constructing mappings between domain-specific terms and a collection of objects in the input picture. One approach is to use model libraries, such as the model that a `car' is a rectangle with four circles attached to it. <p> from a graphically-drawn diagram and a collection of text sentences into a unified knowledge base description. 5.1 Previous Work The previous work in this area has addressed problems associated with automating the ability to understand text and diagrammatic input intended for human communication, such as understanding problem statements in textbooks <ref> [4] </ref>, or associating objects in photographs with text references in captions [9, 10]. In understanding diagram and text input intended for human use, there can be many hidden assumptions on the background knowledge of the reader that complicate the problem and the solution.
Reference: [5] <author> R. Rajagopalan. </author> <title> A model for integrated spatial and dynamic reasoning about physical systems. </title> <booktitle> In Proc. 12th National Conf. on Artificial Intelligence, </booktitle> <address> Cam-bridge, MA, 1994. </address> <publisher> AAAI/MIT Press. </publisher>
Reference-contexts: Diagram processing always precedes text processing. During diagram processing, the Figure Understander automatically extracts a qualitative description of the spatial state from the diagram. This description includes the position, connectivity, and orientation of individual objects and topological and directional spatial relations between objects <ref> [5] </ref>. Then, any additional domain knowledge provided in the Picture Semantics form is attached to the knowledge base descriptions of the diagram objects. For example, the user can specify that all red objects in the diagram are cars. <p> These definitions represent `ideal meanings', as used by Her-skovits [2]. The advantages and limitations of this method, its extensions for reasoning about orientation and for reasoning about translational and rotational motion are described in detail in <ref> [5] </ref>. 4.5 Annotated Demonstration The previous sections have described the rationale and theory behind the implemented code. The following illustrates the processing of the diagram and text given Figures 4 and 6.
Reference: [6] <author> R. Rajagopalan and B. Kuipers. </author> <title> The figure under-stander: A system for integrating text and diagram input to a knowledge base. </title> <booktitle> In Proc. 7th Intl. Conf. on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems, </booktitle> <address> Austin, TX, </address> <month> June </month> <year> 1994. </year>
Reference-contexts: A thorough description of the forms of input to the problem solver and the internal structures produced by the Figure Under-stander is provided in <ref> [6] </ref>. * Diagram: * Text: The disk is rolling down the track. the textbook problem shown in Figure 1. The diagram and text input to the Figure Under-stander for problem of Figure 1 is given in Figure 2.
Reference: [7] <author> J. Resnick and D. Halliday. </author> <title> Fundamentals of Physics. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, third edition, </address> <year> 1988. </year>
Reference-contexts: You roll a copper disk down the track. Describe the motion of the disk as it rolls from the top of the track to the bottom. and text statement for a Physics problem <ref> [7] </ref>. The diagram objects are lines, polygons, and circles. The text problem statement uses domain-specific terms, such as `disk' and `track', to describe the same objects. The coreference problem [4] is to associate object references in text with the appropriate diagram objects.
Reference: [8] <author> G. Retz-Schmidt. </author> <title> Various views on spatial prepositions. </title> <journal> AI Magazine, </journal> <volume> 9(2) </volume> <pages> 95-105, </pages> <year> 1988. </year>
Reference-contexts: Incidentally, notice that the phrase `my right' uses a deictic frame of reference <ref> [8] </ref> centered around the speaker, and that the phrase `in front of Welch Hall' in sentence 3 of Figure 6 uses an intrinsic frame of reference (the intrinsic front of Welch Hall).
Reference: [9] <author> N. Rowe and E. Guglielmo. </author> <title> Exploiting captions in retrieval of multimedia data. </title> <booktitle> Information Processing and Management, </booktitle> <volume> 29(4) </volume> <pages> 453-461, </pages> <year> 1993. </year>
Reference-contexts: Human readers can make use of a large "common-sense" knowledge base to quickly visualize the spatial properties of an object mentioned in the text description and identify the appropriate object (s) in a picture. Automated solutions can follow the same strategy <ref> [4, 9, 10] </ref> but must face the challenging task of constructing mappings between domain-specific terms and a collection of objects in the input picture. One approach is to use model libraries, such as the model that a `car' is a rectangle with four circles attached to it. <p> a unified knowledge base description. 5.1 Previous Work The previous work in this area has addressed problems associated with automating the ability to understand text and diagrammatic input intended for human communication, such as understanding problem statements in textbooks [4], or associating objects in photographs with text references in captions <ref> [9, 10] </ref>. In understanding diagram and text input intended for human use, there can be many hidden assumptions on the background knowledge of the reader that complicate the problem and the solution.
Reference: [10] <author> R. Srihari and D. T. Burhans. </author> <title> Visual semantics: Extracting visual information from text accompanying pictures. </title> <booktitle> In Proc. 12th National Conf. on Artificial Intelligence, </booktitle> <address> Cambridge, MA, 1994. </address> <publisher> AAAI/MIT Press. </publisher>
Reference-contexts: Human readers can make use of a large "common-sense" knowledge base to quickly visualize the spatial properties of an object mentioned in the text description and identify the appropriate object (s) in a picture. Automated solutions can follow the same strategy <ref> [4, 9, 10] </ref> but must face the challenging task of constructing mappings between domain-specific terms and a collection of objects in the input picture. One approach is to use model libraries, such as the model that a `car' is a rectangle with four circles attached to it. <p> a unified knowledge base description. 5.1 Previous Work The previous work in this area has addressed problems associated with automating the ability to understand text and diagrammatic input intended for human communication, such as understanding problem statements in textbooks [4], or associating objects in photographs with text references in captions <ref> [9, 10] </ref>. In understanding diagram and text input intended for human use, there can be many hidden assumptions on the background knowledge of the reader that complicate the problem and the solution.
References-found: 10

