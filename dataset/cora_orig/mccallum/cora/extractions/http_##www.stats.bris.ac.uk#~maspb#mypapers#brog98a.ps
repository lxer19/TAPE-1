URL: http://www.stats.bris.ac.uk/~maspb/mypapers/brog98a.ps
Refering-URL: http://www.stats.bris.ac.uk/MCMC/pages/list.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: BAYESIAN STATISTICS 6, pp. 000--000  Convergence Assessment for Reversible Jump MCMC Simulations  
Author: J. M. Bernardo, J. O. Berger, A. P. Dawid and A. F. M. Smith (Eds.) STEPHEN P. BROOKS and PAOLO GIUDICI 
Keyword: MARKOV CHAIN MONTE CARLO; GRAPHICAL GAUSSIAN MODELS; RUN-LENGTH DETERMINATION; BAYESIAN INFERENCE.  
Address: Pavia, Italy  
Date: 1998  
Note: Press,  
Affiliation: Oxford University  University of Bristol, UK and University of  
Abstract: SUMMARY In this paper we introduce the problem of assessing convergence of reversible jump MCMC algorithms on the basis of simulation output. We discuss the various direct approaches which could be employed, together with their associated drawbacks. Using the example of fitting a graphical Gaussian model via RJMCMC, we show how the simulation output for models which can be parameterised so that parameters of primary interest retain a coherent interpretation throughout the simulation, can be used to assess convergence. In the context of this example, we extend the work of Gelman and Rubin (1992) and Brooks and Gelman (1998), to provide convergence assessment procedures for graphical model determination problems, but which may be applied to any form of model choice problem and, indeed, MCMC simulations more generally. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Brooks, S. P. </author> <year> (1997). </year> <title> Discussion to Richardson and Green (1997). </title>
Reference: <author> Brooks, S. P. </author> <year> (1998). </year> <title> Markov Chain Monte Carlo Method and its Application. The Statistician 47, </title> <publisher> 69--100. </publisher>
Reference-contexts: We begin with a brief review of the original approach proposed by Gelman and Rubin (1992). 3.1 The Method of Gelman and Rubin The method of Gelman and Rubin (1992) <ref> (subsequently generalised by Brooks and Gelman, 1998) </ref> consists of analysing m independent sequences to form a distributional estimate for what is known about some random variable, given the observations simulated so far. <p> Then, we can split the variation of into various components <ref> (see Brooks and Giudici, 1998 for more details on the decompositions) </ref>: B m = m=1 m W m = M i=1 m=1 k=1 im W c = I i=1 m=1 k=1 im B m W c = i=1 m=1 im and W m W c = IM i=1 m=1 k=1 im
Reference: <author> Brooks, S. P. and Gelman, A. </author> <year> (1998). </year> <title> Alternative Methods for Monitoring Convergence of Iterative Simulations. </title>
Reference-contexts: We begin with a brief review of the original approach proposed by Gelman and Rubin (1992). 3.1 The Method of Gelman and Rubin The method of Gelman and Rubin (1992) <ref> (subsequently generalised by Brooks and Gelman, 1998) </ref> consists of analysing m independent sequences to form a distributional estimate for what is known about some random variable, given the observations simulated so far. <p> Then, we can split the variation of into various components <ref> (see Brooks and Giudici, 1998 for more details on the decompositions) </ref>: B m = m=1 m W m = M i=1 m=1 k=1 im W c = I i=1 m=1 k=1 im B m W c = i=1 m=1 im and W m W c = IM i=1 m=1 k=1 im
Reference: <author> J. </author> <title> Comp. and Graph. </title> <journal> Stat. </journal> <note> (to appear). </note>
Reference: <author> Brooks, S. P. and Giudici, P. </author> <year> (1998). </year> <title> Diagnosing Convergence of Reversible Jump MCMC Algorithms. </title> <type> Tech. Rep., </type> <institution> University of Bristol. </institution>
Reference-contexts: We begin with a brief review of the original approach proposed by Gelman and Rubin (1992). 3.1 The Method of Gelman and Rubin The method of Gelman and Rubin (1992) <ref> (subsequently generalised by Brooks and Gelman, 1998) </ref> consists of analysing m independent sequences to form a distributional estimate for what is known about some random variable, given the observations simulated so far. <p> Then, we can split the variation of into various components <ref> (see Brooks and Giudici, 1998 for more details on the decompositions) </ref>: B m = m=1 m W m = M i=1 m=1 k=1 im W c = I i=1 m=1 k=1 im B m W c = i=1 m=1 im and W m W c = IM i=1 m=1 k=1 im
Reference: <author> Brooks, S. P. and Roberts, G. O. </author> <year> (1998). </year> <title> Diagnosing Convergence of Markov Chain Monte Carlo Algorithms. </title> <type> Tech. Rep., </type> <institution> University of Bristol. </institution>
Reference-contexts: We begin with a brief review of the original approach proposed by Gelman and Rubin (1992). 3.1 The Method of Gelman and Rubin The method of Gelman and Rubin (1992) <ref> (subsequently generalised by Brooks and Gelman, 1998) </ref> consists of analysing m independent sequences to form a distributional estimate for what is known about some random variable, given the observations simulated so far. <p> Then, we can split the variation of into various components <ref> (see Brooks and Giudici, 1998 for more details on the decompositions) </ref>: B m = m=1 m W m = M i=1 m=1 k=1 im W c = I i=1 m=1 k=1 im B m W c = i=1 m=1 im and W m W c = IM i=1 m=1 k=1 im
Reference: <author> Carlin, B. P. and Chib, S. </author> <year> (1995). </year> <title> Bayesian model Choice via Markov Chain Monte Carlo. </title> <journal> J. Roy. Statist. Soc. </journal> <volume> B 57, </volume> <month> 473--484. </month>
Reference: <author> Cowles, M. K. and Carlin, B. P. </author> <year> (1996). </year> <title> Markov Chain Monte Carlo Convergence Diagnostics: A Comparative Review. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 91, </volume> <month> 883--904. </month>
Reference: <author> Dawid, A. P. and Lauritzen, S. L. </author> <year> (1993). </year> <title> Hyper Markov Laws in the Statistical Analysis of Decomposable Graphical Models. </title> <journal> Ann. Statist. </journal> <volume> 21, </volume> <month> 1272--1317. </month>
Reference: <author> Dellaportas, P. and Forster, J. </author> <year> (1996). </year> <title> Markov Chain Monte Carlo Model Determination for Hierarchical and Graphical Log-Linear Models. </title> <type> Tech. Rep., </type> <institution> Athens University of Economics and Business. </institution>
Reference-contexts: Applications of the method include change point problems and factorial experiments (Green, 1995), mixture problems (Richardson and Green, 1997), log-linear models <ref> (Dellaportas and Forster, 1996) </ref> and graphical Gaussian models (Giudici and Green, 1998).
Reference: <author> Gelman, A. and Rubin, D. B. </author> <year> (1992). </year> <title> Inference from Iterative Simulations Using Multiple Sequences. </title> <journal> Statist. Sci. </journal> <volume> 7, </volume> <month> 457--511. </month>
Reference: <author> Giudici, P. and Green, P. J. </author> <year> (1998). </year> <title> Decomposable Graphical Gaussian Model Determination. </title> <type> Tech. Rep., </type> <institution> University of Pavia. </institution>
Reference-contexts: Applications of the method include change point problems and factorial experiments (Green, 1995), mixture problems (Richardson and Green, 1997), log-linear models (Dellaportas and Forster, 1996) and graphical Gaussian models <ref> (Giudici and Green, 1998) </ref>. Simply put, RJMCMC extends the basic Metropolis Hastings algorithm to general state spaces, so that the target distribution becomes a general measure, rather than a density and the Metropolis Hastings proposal density q (x; y) is replaced by a proposal kernel q (x; dy). <p> Then, we can split the variation of into various components <ref> (see Brooks and Giudici, 1998 for more details on the decompositions) </ref>: B m = m=1 m W m = M i=1 m=1 k=1 im W c = I i=1 m=1 k=1 im B m W c = i=1 m=1 im and W m W c = IM i=1 m=1 k=1 im
Reference: <author> Green, P. J. </author> <year> (1995). </year> <title> Reversible Jump MCMC Computation and Bayesian Model Determination. </title> <journal> Biometrika 82, 711--732. </journal>
Reference-contexts: Applications of the method include change point problems and factorial experiments <ref> (Green, 1995) </ref>, mixture problems (Richardson and Green, 1997), log-linear models (Dellaportas and Forster, 1996) and graphical Gaussian models (Giudici and Green, 1998). <p> The move is then accepted with probability ff m (x; y) = min 1; (dy)q m (y; dx) 2 S. P. Brooks and P. Giudici This probability is rigorously defined, subject to a ``dimension-matching'' condition on q m (x; dy) <ref> (Green, 1995) </ref>, that effectively matches the degrees of freedom of joint variation of x and y as the dimension changes with the number of parameters under different models. Green (1995) provides a ``template'' for dimension-changing moves.
Reference: <author> Grenander, U. and Miller, M. I. </author> <year> (1994). </year> <journal> Representations of Knowledge in Complex Systems J. Roy. Statist. Soc. </journal> <volume> B 56, </volume> <month> 549--603. </month>
Reference: <author> Lauritzen, S. L. </author> <year> (1996). </year> <title> Graphical Models Oxford: </title> <publisher> University Press. </publisher>
Reference: <author> Richardson, S. and Green, P. J. </author> <year> (1997). </year> <title> On Bayesian Analysis of Mixtures with an Unknown number of Components. </title> <journal> J. Roy. Statist. Soc. </journal> <volume> B 59, </volume> <month> 731--792. </month> <title> (with discussion). </title>
Reference-contexts: Applications of the method include change point problems and factorial experiments (Green, 1995), mixture problems <ref> (Richardson and Green, 1997) </ref>, log-linear models (Dellaportas and Forster, 1996) and graphical Gaussian models (Giudici and Green, 1998).
Reference: <author> Robert, C. P. and Mengersen, K. L. </author> <year> (1998). </year> <title> MCMC Convergence Diagnostics: A ``Reviewww''. </title> <booktitle> In this volume. </booktitle>
Reference: <author> Whittaker, J. </author> <year> (1990). </year> <title> Graphical Models in Applied Multivariate Statistics Chichester: </title> <publisher> Wiley. </publisher>
Reference-contexts: A conditional independence graph, G = (V; E), describes the association structure of X by means of a graph, specified by the vertex set V and the edge set E. A graphical model is then a family of probability distributions P G which is Markov over G <ref> (see, for instance, Whittaker, 1990, or Lauritzen, 1996) </ref>. A graphical Gaussian model is obtained when only continuous random variables are considered and assuming P G = N (; G ), with G positive definite and such that P G is Markov over G.
References-found: 18

