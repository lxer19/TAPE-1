URL: http://www.cs.toronto.edu/~greiner/PAPERS/missing.ps
Refering-URL: http://www.cs.toronto.edu/~greiner/PAPERS/
Root-URL: 
Email: dale@cs.toronto.edu  greiner@scr.siemens.com  
Title: Learning to Classify Incomplete Examples  
Author: Dale Schuurmans Russell Greiner 
Address: Toronto, ON M5S 1A4  Princeton, NJ 08540  
Affiliation: Department of Computer Science University of Toronto  Siemens Corporate Research  
Abstract: Most research on supervised learning assumes the attributes of training and test examples are completely specified. Real-world data, however, is often incomplete. This paper studies the task of learning to classify incomplete test examples, given incomplete (resp., complete) training data. We first show that the performance task of classifying incomplete examples requires the use of default classification functions which demonstrate nonmonotonic classification behavior. We then extend the standard pac-learning model to allow attribute values to be hidden from the classifier, investigate the robustness of various learning strategies, and study the sample complexity of learning classes of default classification functions from examples.
Abstract-found: 1
Intro-found: 1
Reference: <author> Angluin, D. and Laird, P. </author> <year> (1988). </year> <title> Learning from noisy examples. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 343-370. </pages>
Reference: <author> Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. K. </author> <year> (1989). </year> <title> Learnability and the Vapnik-Chervonenkis dimension. </title> <journal> JACM, </journal> <volume> 36(4) </volume> <pages> 929-965. </pages>
Reference: <author> Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J. </author> <year> (1984). </year> <title> Classification and Regression Trees. </title> <publisher> Wadsworth, </publisher> <address> Belmont, CA. </address>
Reference: <author> Clancey, W. </author> <year> (1985). </year> <title> Heuristic classification. </title> <journal> Artificial Intelligence, </journal> <volume> 27 </volume> <pages> 289-350. </pages>
Reference-contexts: 1 Introduction The central task of most expert systems is classifying objects from some domain of application; i.e., determining whether a particular object belongs to a specified class, given a description of that object <ref> (Clancey, 1985) </ref>.
Reference: <author> Ehrenfeucht, A., Haussler, D., Kearns, M., and Valiant, L. </author> <year> (1988). </year> <title> A general lower bound on the number of examples needed for learning. </title> <booktitle> In Proceedings COLT-88. </booktitle>
Reference: <author> Ghahramani, Z. and Jordan, M. I. </author> <year> (1994). </year> <title> Supervised learning from real and discrete incomplete data. </title> <booktitle> In Proceedings CLNL-93. (This volume). </booktitle>
Reference-contexts: To classify a description x fl , determine the most likely class given x fl 's observed attributes. Popular techniques for representing joint distributions over f0; 1g n include Bayes and Markov nets (Neal, 1992; Pearl, 1988), and Bernoulli mixture models <ref> (Ghahramani and Jordan, 1994) </ref>. These representations provide compact and intuitive representations of mdcs, but they have the drawback that actually determining their classifications can often be com-putationally expensive (Roth, 1993; Pearl, 1988).
Reference: <author> Ginsberg, M., </author> <title> editor (1987). Readings in Nonmonotonic Reasoning. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA. </address>
Reference: <author> Haussler, D. </author> <year> (1992). </year> <title> Decision theoretic generalizations of the PAC model for neural net and other learning applications. </title> <journal> Information and Computation, </journal> <volume> 100 </volume> <pages> 78-150. </pages>
Reference-contexts: Many generalizations of Valiant's framework have been introduced in the learning theory literature, including: learning from noisy concept labels (Angluin and Laird, 1988; Kearns and Li, 1988), learning with attribute noise (Shackelford and Volper, 1988), learning probabilistic concepts (Kearns and Schapire, 1990), and general decision-theoretic learning <ref> (Haussler, 1992) </ref>. However, our task differs from each of these, in that we address a fundamentally different form of classification task. For example, a system that learns with attribute noise will not know which attribute values have been corrupted; by contrast, we know explicitly which values are missing.
Reference: <author> Kearns, M. J. and Li, M. </author> <year> (1988). </year> <title> Learning in the presence of malicious errors. </title> <booktitle> In Proceedings STOC-88. </booktitle>
Reference: <author> Kearns, M. J. and Schapire, R. E. </author> <year> (1990). </year> <title> Efficient distribution-free learning of probabilistic concepts. </title> <booktitle> In Proceedings FOCS-90. </booktitle>
Reference-contexts: Many generalizations of Valiant's framework have been introduced in the learning theory literature, including: learning from noisy concept labels (Angluin and Laird, 1988; Kearns and Li, 1988), learning with attribute noise (Shackelford and Volper, 1988), learning probabilistic concepts <ref> (Kearns and Schapire, 1990) </ref>, and general decision-theoretic learning (Haussler, 1992). However, our task differs from each of these, in that we address a fundamentally different form of classification task. <p> In standard classification models, this domain object x would be passed "as is" to the classifier; here, however, we assume the classifier only sees a degraded version of x in which certain attribute values have been 2 <ref> (Kearns and Schapire, 1990) </ref> consider the problem of learning the probabilistic concept induced by observing a fixed subset of the available attributes.
Reference: <author> Kyburg, H. </author> <year> (1991). </year> <title> Evidential probability. </title> <booktitle> In Proceedings IJCAI-91. </booktitle>
Reference-contexts: There are a number of connections between the problem of learning default concept definitions from examples and related work in AI and philosophy of statistics <ref> (Kyburg, 1991) </ref>; these are explored in detail elsewhere (Schuurmans and Greiner, 1994). 2 Missing-data classifiers We begin by formalizing the performance task of classifying incomplete examples, before going on to the task of learning such classifiers.
Reference: <author> Little, J. A. and Rubin, D. B. </author> <year> (1987). </year> <title> Statistical Analysis with Missing Data. </title> <publisher> Wiley, </publisher> <address> New York. </address>
Reference: <author> Mitchell, T. M. </author> <year> (1980). </year> <title> The need for biases in learning generalizations. </title> <type> Technical Report CBM-TR-117, </type> <institution> Rutgers University. </institution>
Reference-contexts: This points to the necessity of bias: in any successful application, the learning system must be constrained to search a restricted class of appro priate classifiers <ref> (Mitchell, 1980) </ref>. 6 Domain distribution P XC over domain objects + Observation process fi loses information + Observed distribution P X fl C over object descriptions Most empirical learning techniques for mdcs include two components: a technique for representing a bias (here a class of mdcs D = fdg), and a
Reference: <author> Neal, R. M. </author> <year> (1992). </year> <title> Connectionist learning of belief networks. </title> <journal> Artificial Intelligence, </journal> <volume> 56 </volume> <pages> 71-113. </pages>
Reference: <author> Pearl, J. </author> <year> (1988). </year> <title> Probabilistic Reasoning in Intelligent Systems. </title> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA. </address>
Reference: <author> Porter, B. W., Bareiss, R., and Holte, R. C. </author> <year> (1990). </year> <title> Concept learning and heuristic classification in weak-theory domains. </title> <journal> Artificial Intelligence, 45(1-2):229-263. </journal>
Reference-contexts: However, in many real world situations we often have to classify objects given only incomplete descriptions of their attributes. For example, in medical diagnosis applications doctors seldom have access to every potentially relevant fact about a patient <ref> (Porter, Bareiss and Holte, 1990) </ref>. <p> There are clearly a wide number of ways to represent mdcs. In fact, other representations of mdcs are possible; for example based on finding best matches to prototype objects <ref> (Porter, Bareiss and Holte, 1990) </ref> (i.e., case-based reasoning), but these will not be considered here. The choice among these many different representation paradigms is largely a matter of taste and/or convenience, and should be dictated by the application at hand. <p> Aside from pursuing open technical questions, we are beginning to examine many extensions to better cope with real-world learning problems. For example, missing attribute values in medical databases typically provide useful information | namely that the missing attributes are irrelevant to the classification given the known attributes <ref> (Porter, Bareiss and Holte, 1990) </ref> | which could be exploited by a learning system (Rao, Greiner and Hancock, 1994). Notice that fi I is overly restrictive and fi A is too underconstrained to adequately model this situation.
Reference: <author> Quinlan, J. R. </author> <year> (1989). </year> <title> Unknown attribute values in induction. </title> <booktitle> In Proceedings ML-89. </booktitle>
Reference: <author> Rao, R. B., Greiner, R., and Hancock, T. </author> <year> (1994). </year> <title> Exploiting the absence of irrelevant information. </title> <booktitle> In AAAI Fall Symposium on `Relevance', </booktitle> <address> New Orleans. </address>
Reference-contexts: For example, missing attribute values in medical databases typically provide useful information | namely that the missing attributes are irrelevant to the classification given the known attributes (Porter, Bareiss and Holte, 1990) | which could be exploited by a learning system <ref> (Rao, Greiner and Hancock, 1994) </ref>. Notice that fi I is overly restrictive and fi A is too underconstrained to adequately model this situation. We are currently investigating alternative blocking models that (we hope) lead to better empirical learning performance in such domains.
Reference: <author> Reiter, R. </author> <year> (1987). </year> <title> Nonmonotonic reasoning. </title> <booktitle> Annual Review of Computer Science, </booktitle> <volume> 2 </volume> <pages> 147-186. </pages> <note> 13 Rivest, </note> <author> R. and Sloan, R. </author> <year> (1988). </year> <title> Learning complicated concepts reliably and usefully. </title> <booktitle> In Proceedings AAAI-88. </booktitle>
Reference-contexts: Since these default classifications may change in light of further information about a domain object, incomplete-data classifiers are able to exhibit "nonmonotonic classification behavior" <ref> (Reiter, 1987) </ref>. This type of nonmonotonic classification behavior cannot be described in terms of necessary and sufficient conditions, and hence cannot be encoded by a complete data classifier (Schuurmans and Greiner, 1994).
Reference: <author> Roth, D. </author> <year> (1993). </year> <title> On the hardness of approximate reasoning. </title> <booktitle> In Proceedings IJCAI-93. </booktitle>
Reference: <author> Schuurmans, D. and Greiner, R. </author> <year> (1994). </year> <title> Learning default concepts. </title> <booktitle> In Proceedings CSCSI-94. </booktitle>
Reference-contexts: This type of nonmonotonic classification behavior cannot be described in terms of necessary and sufficient conditions, and hence cannot be encoded by a complete data classifier <ref> (Schuurmans and Greiner, 1994) </ref>. The task of learning an accurate incomplete-data classifier from examples raises a number of new issues which have not been addressed by traditional supervised learning research. <p> There are a number of connections between the problem of learning default concept definitions from examples and related work in AI and philosophy of statistics (Kyburg, 1991); these are explored in detail elsewhere <ref> (Schuurmans and Greiner, 1994) </ref>. 2 Missing-data classifiers We begin by formalizing the performance task of classifying incomplete examples, before going on to the task of learning such classifiers. <p> Furthermore, this strategy is still not fully general in the range of mdcs it can represent; for example, jt can only represent mdcs satisfying a certain "inheritance" constraint in the hierarchy of default classifications <ref> (Schuurmans and Greiner, 1994) </ref>. 4 "thing ) :photo, by default"flfl ! 0 "green ^ plant , photo" "plant ) photo, by default" 00 ! 0 01 ! 0 10 ! 0 11 ! 1 The simplest way to conceptualize an mdc is just as a direct mapping from partial descriptions x <p> However, an important observation is that these strategies differ in their fundamental representation capacities. Proposition 1 im jt dr cl (inclusions are strict). There are many unexpected similarities between mdcs and existing nonmonotonic knowledge representation formalisms; see <ref> (Schuurmans and Greiner, 1994) </ref> for more details.
Reference: <author> Shackelford, G. and Volper, D. </author> <year> (1988). </year> <title> Learning k-DNF with noise in the attributes. </title> <booktitle> In Proceedings COLT-88. </booktitle>
Reference-contexts: Many generalizations of Valiant's framework have been introduced in the learning theory literature, including: learning from noisy concept labels (Angluin and Laird, 1988; Kearns and Li, 1988), learning with attribute noise <ref> (Shackelford and Volper, 1988) </ref>, learning probabilistic concepts (Kearns and Schapire, 1990), and general decision-theoretic learning (Haussler, 1992). However, our task differs from each of these, in that we address a fundamentally different form of classification task.
Reference: <author> Valiant, L. G. </author> <year> (1984). </year> <title> A theory of the learnable. </title> <journal> CACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142. </pages>
Reference-contexts: The intent is to uncover a theoretical explanation of the observed empirical phenomena, and provide effective guidance for practice. Overview: We develop a theoretical framework along the lines of Valiant's pac-learning framework for learning complete data classifiers <ref> (Valiant, 1984) </ref>. After introducing the basic classification framework in Section 2, Section 3 then extends Valiant's random example model to incorporate an "attribute blocking process". <p> Related Work: Valiant's pac-learning model <ref> (Valiant, 1984) </ref>, and the subsequent research it inspired (Blumer et al., 1989; Haussler, 1992), has greatly advanced our understanding of learning complete data classifiers from examples. <p> Note that in general a classifier's accuracy depends both on the domain distribution and the blocking process. To formalize the task of learning an accurate mdc from random training examples, as in <ref> (Valiant, 1984) </ref>, we assume training examples are randomly drawn from the example distribution P X fl C along with their correct classifications, from which the learner L must produce a mdc that will be tested on examples drawn from the same example distribution.
Reference: <author> Vapnik, V. N. and Chervonenkis, A. </author> <year> (1971). </year> <title> On the uniform convergence of relative frequencies of events to their probabilities. </title> <journal> Theory of Probability and its Applications, </journal> <volume> 16(2) </volume> <pages> 264-280. </pages>
Reference-contexts: Proposition 5 In context (fi A ; I ): dr is consistent; cl, im, and jt fail. 3 It is sufficient that C have finite Vapnik-Chervonenkis dimension <ref> (Vapnik and Chervonenkis, 1971) </ref> (and satisfy certain (benign) measure theoretic properties that we will not concern ourselves with here); see the next section.
References-found: 24

