URL: http://roger-rabbit.cs.berkeley.edu/papers/1998/149/paper.ps
Refering-URL: http://roger-rabbit.cs.berkeley.edu/papers/1998/149/149.html
Root-URL: http://www.cs.berkeley.edu
Email: fkpatel,roweg@cs.berkeley.edu  
Title: Exploiting Temporal Parallelism For Software-only Video Effects Processing  
Author: Ketan Mayer-Patel Lawrence A. Rowe 
Note: Submission Number: C-144  
Abstract: Internet video is emerging as an important multimedia application area. Although development and use of video applications is increasing, the ability to manipulate and process video is missing within this application area. Current video effects processing solutions are not well matched for the Internet video environment. A software-only solution, however, provides enough flexibility to match the constraints and needs of a particular video application. The key to a software solution is exploiting parallelism. This paper presents the design of a parallel software-only video effects processing system. Preliminary experimental results exploring the use of temporal parallelism are presented. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> V. M. Bove, Jr. and J. A. Watlington. Cheops: </author> <title> A reconfigurable data-flow system for video processing. </title> <journal> IEEE Transactions on Circuits and Systems for Video Processing, </journal> <volume> 5(2) </volume> <pages> 140-149, </pages> <month> April </month> <year> 1995. </year>
Reference-contexts: Conventional television systems cannot vary these quality and delivery parameters. The key to a software solution is exploiting parallelism. Currently, a single processor cannot produce a wide variety of video effects in real-time which is why conventional VPS systems and early research systems (e.g., Cheops <ref> [1] </ref>) use custom-designed hardware. Even as processors become faster, the demand for more complicated effects, larger images, and higher quality will increase. The complexity of video effects processing is arbitrary because the number, size, data rate, and quality of video streams is variable. <p> The Cheops system developed by Bove and Watlington at MIT is composed of interconnected special-purpose hardware components that implement specific functions (e.g., discrete cosine transform (DCT), convolution, etc.) <ref> [1] </ref>. Video effects are implemented by configuring and controlling data flow between these specialized hardware components. This system focused primarily on exploiting temporal and functional parallelism. The IBM Power Visualization System is a parallel processor composed of up to 32 identical processors interconnected by a global bus [4]. <p> Q : priority queue of frames waiting for transmission ordered by their MTS. h : next frame to be sent in Q (i.e., head of Q). ff : latency bias parameter ranged in <ref> [0; 1] </ref>. fi : frame skip tolerance parameter (&gt; 0). l : last frame transmitted. The value M (f ) + offset is the scheduled time for transmitting f .
Reference: [2] <author> D. Chin, J. Passe, F. Bernard, H. Taylor, and S. Knight. </author> <title> The Princeton Engine: A real-time video system simulator. </title> <journal> IEEE Transactions on Consumer Electronics, </journal> <volume> 32(2) </volume> <pages> 285-297, </pages> <year> 1988. </year>
Reference-contexts: It was designed specifically to support the IBM EFX suite of editing, effects, and compression software. The Princeton Engine is a parallel processor composed of up to 2048 custom-designed processing elements which are used to simultaneously operate on an array of data elements (i.e., SIMD) <ref> [2] </ref>. Many other hardware systems have also been developed [6, 7, 11]. The system proposed here differs fundamentally from these systems by not assuming any particular underlying parallel architecture.
Reference: [3] <author> David E. Culler et al. </author> <title> Parallel computing on the Berkeley NOW. </title> <booktitle> 9th Joint Symposium on Parallel Processing, </booktitle> <year> 1997. </year>
Reference-contexts: The most common architecture will be 2 to 100 processors connected by a fast, low latency local area network. The Network of Workstations (NOW) project at U.C. Berkeley provides this type of environment and is the target for our development efforts <ref> [3] </ref>. The last design goal is to support multiple effect-tasks simultaneously. Several IV applications may require effects processing from the system at the same time, or one application may instantiate two or more effects at the same time. The system processing resources must be dynamically allocated.
Reference: [4] <author> D. A. Epstein et al. </author> <title> The IBM POWER Visualization System: A digital post-production suite in a box. </title> <booktitle> 136th SMPTE Technical Conference, </booktitle> <pages> pages 136-198, </pages> <year> 1994. </year>
Reference-contexts: Video effects are implemented by configuring and controlling data flow between these specialized hardware components. This system focused primarily on exploiting temporal and functional parallelism. The IBM Power Visualization System is a parallel processor composed of up to 32 identical processors interconnected by a global bus <ref> [4] </ref>. It was designed specifically to support the IBM EFX suite of editing, effects, and compression software. The Princeton Engine is a parallel processor composed of up to 2048 custom-designed processing elements which are used to simultaneously operate on an array of data elements (i.e., SIMD) [2].
Reference: [5] <author> Sally Floyd, Van Jacobson, Ching-Gung Liu, Steven McCanne, and Lixia Zhang. </author> <title> A reliable multicast framework for light-weight sessions and application level framing. </title> <journal> IEEE/ACM Transactions on Networking, </journal> <month> December </month> <year> 1997. </year>
Reference-contexts: The FX Processor is the execution agent for the subprograms generated by the FX Mapper. The execution environment is implemented on the MASH platform [8]. MASH is a flexible software environment for building distributed continuous media applications. It supports existing Internet protocols including RTP, RTCP, RTSP and SRM <ref> [12, 5, 10] </ref>. 4 Temporal Parallelism Exploring the use of temporal parallelism is a logical starting point for this project for several reasons. First, the processing subgraph for each computational resource is the same.
Reference: [6] <author> T. Ikedo. </author> <title> A scalable high-performance graphics processor: </title> <journal> GVIP. Visual Computer, </journal> <volume> 11(3) </volume> <pages> 121-33, </pages> <year> 1995. </year>
Reference-contexts: The Princeton Engine is a parallel processor composed of up to 2048 custom-designed processing elements which are used to simultaneously operate on an array of data elements (i.e., SIMD) [2]. Many other hardware systems have also been developed <ref> [6, 7, 11] </ref>. The system proposed here differs fundamentally from these systems by not assuming any particular underlying parallel architecture.
Reference: [7] <author> R. M. Lougheed and D. L. McCubbrey. </author> <title> The cyto-computer: a practical pipelined image processor. </title> <booktitle> Conference Proceedings of the 7th Annual Symposium on Computer Architecture, </booktitle> <pages> pages 271-278, </pages> <year> 1980. </year>
Reference-contexts: The Princeton Engine is a parallel processor composed of up to 2048 custom-designed processing elements which are used to simultaneously operate on an array of data elements (i.e., SIMD) [2]. Many other hardware systems have also been developed <ref> [6, 7, 11] </ref>. The system proposed here differs fundamentally from these systems by not assuming any particular underlying parallel architecture.
Reference: [8] <author> Steven McCanne et al. </author> <title> Toward a common infrastructure for multimedia-networking middleware. </title> <booktitle> Proceedings of the 7th Intl. Workshop on Network and Operating Systems Support for Digital Audio and Video (NOSSDAV), </booktitle> <year> 1997. </year>
Reference-contexts: The effect graph primitives are implemented as Dali programs or operations implemented in a general purpose programming language. The FX Processor is the execution agent for the subprograms generated by the FX Mapper. The execution environment is implemented on the MASH platform <ref> [8] </ref>. MASH is a flexible software environment for building distributed continuous media applications. It supports existing Internet protocols including RTP, RTCP, RTSP and SRM [12, 5, 10]. 4 Temporal Parallelism Exploring the use of temporal parallelism is a logical starting point for this project for several reasons.
Reference: [9] <author> G. Millerson. </author> <title> The Technique of Television Production. </title> <publisher> Focal Press, Oxford, </publisher> <address> England, </address> <year> 1990. </year>
Reference-contexts: Live broadcasts of conferences, classes, and other special events require improved production values. Experience from the television, video, and film industries shows that visual effects are an important tool for communicating and maintaining audience interest <ref> [9] </ref>. Titling, for example, is used to identify speakers and topics in a video presentation. Compositing effects that combine two or more video images into one image can be used to present simultaneous views of people or events at different locations or artifacts at varying levels of detail.
Reference: [10] <author> Anup Rao and Rob Lanphier. RTSP: </author> <title> Real Time Streaming Protocol, </title> <month> February </month> <year> 1998. </year> <title> Internet Proposed Standard, </title> <booktitle> work in progress. </booktitle>
Reference-contexts: The FX Processor is the execution agent for the subprograms generated by the FX Mapper. The execution environment is implemented on the MASH platform [8]. MASH is a flexible software environment for building distributed continuous media applications. It supports existing Internet protocols including RTP, RTCP, RTSP and SRM <ref> [12, 5, 10] </ref>. 4 Temporal Parallelism Exploring the use of temporal parallelism is a logical starting point for this project for several reasons. First, the processing subgraph for each computational resource is the same.
Reference: [11] <author> Shigeru Sasaki, Tatsuya Satoh, and Masumi Yoshida. IDATEN: </author> <title> Reconfigurable video-rate image processing system. </title> <journal> FUJITSU Sci. Tech. Journal, </journal> <volume> 23(4) </volume> <pages> 391-400, </pages> <month> December </month> <year> 1987. </year>
Reference-contexts: The Princeton Engine is a parallel processor composed of up to 2048 custom-designed processing elements which are used to simultaneously operate on an array of data elements (i.e., SIMD) [2]. Many other hardware systems have also been developed <ref> [6, 7, 11] </ref>. The system proposed here differs fundamentally from these systems by not assuming any particular underlying parallel architecture.
Reference: [12] <author> Henning Schulzrinne, Stephen Casner, Ron Fred-erick, and Van Jacobson. </author> <title> RFC 1889, RTP: A Transport Protocol for Real-Time Applications, </title> <month> January </month> <year> 1996. </year>
Reference-contexts: This research shares some of the same goals and solutions that we are working toward. Our system is different in that we are taking advantage of representational structure present in compressed video formats, and we are constrained to standard streaming protocols for video on the Internet (i.e., RTP <ref> [12] </ref>). The Resolution Independent Video Language (RIVL) is a high-level language for describing video effects irrespective of format and resolution [15]. The system described here is independent of any specific language for specifying video effects, but RIVL serves as a model for the type of language to be supported. <p> These formats are very similar they use the DCT, quantization, and entropy coding with intra- and inter-frame optimizations. We will capital ize on available compressed domain processing methods wherever possible [14]. RTP is the standard networking protocol used by IV applications <ref> [12] </ref>. This protocol is used for input and output video streams. The third major design goal is to use commodity hardware. The system should operate on any set of networked, general-purpose processors. This goal requires the system to be software-only and portable. <p> The FX Processor is the execution agent for the subprograms generated by the FX Mapper. The execution environment is implemented on the MASH platform [8]. MASH is a flexible software environment for building distributed continuous media applications. It supports existing Internet protocols including RTP, RTCP, RTSP and SRM <ref> [12, 5, 10] </ref>. 4 Temporal Parallelism Exploring the use of temporal parallelism is a logical starting point for this project for several reasons. First, the processing subgraph for each computational resource is the same.
Reference: [13] <author> B. C. Smith. </author> <title> Dali: High-Performance Video Processing Primitives. </title> <institution> Cornell University. </institution> <note> Unpublished work in progress. </note>
Reference-contexts: The system described here is independent of any specific language for specifying video effects, but RIVL serves as a model for the type of language to be supported. Dali is a low-level set of image operators that operate on specific representations of data elements <ref> [13] </ref>. We are using Dali as a target language to express primitive effects processing tasks. 3 System Architecture The overall system architecture is shown in Figure 3. This picture depicts the high bandwidth, low latency network as a cloud.
Reference: [14] <author> B. C. Smith. </author> <title> Implementation techniques for continuous media systems and applications. </title> <type> PhD thesis, </type> <institution> University of California, Berkeley : Computer Science Division, </institution> <year> 1994. </year>
Reference-contexts: Motion-JPEG, H.261/H.263, and MPEG are the most common video formats in use today. These formats are very similar they use the DCT, quantization, and entropy coding with intra- and inter-frame optimizations. We will capital ize on available compressed domain processing methods wherever possible <ref> [14] </ref>. RTP is the standard networking protocol used by IV applications [12]. This protocol is used for input and output video streams. The third major design goal is to use commodity hardware. The system should operate on any set of networked, general-purpose processors.
Reference: [15] <author> J. Swartz and B. C. Smith. RIVL: </author> <title> a Resolution Independent Video Language. </title> <booktitle> Proceedings of the Tcl/Tk Workshop, </booktitle> <pages> pages 235-242, </pages> <year> 1995. </year>
Reference-contexts: The Resolution Independent Video Language (RIVL) is a high-level language for describing video effects irrespective of format and resolution <ref> [15] </ref>. The system described here is independent of any specific language for specifying video effects, but RIVL serves as a model for the type of language to be supported. Dali is a low-level set of image operators that operate on specific representations of data elements [13].
Reference: [16] <author> J.A. Watlington and V.M. Bove, Jr. </author> <title> A system for parallel media processing. </title> <journal> Parallel Computing, </journal> <volume> 23(12) </volume> <pages> 1793-1809, </pages> <month> December </month> <year> 1997. </year>
Reference-contexts: The system proposed here differs fundamentally from these systems by not assuming any particular underlying parallel architecture. More recent work by Bove and Watlington describes a general system for abstractly describing media streams and processing algorithms that can be mapped to a set of networked hardware resources <ref> [16] </ref>. In this system, hardware resources may be special purpose media processors or general-purpose processors. The system is centered around an abstraction for media streams that describes any multi-dimensional array of data elements.
Reference: [17] <author> T. Wong, K. Mayer-Patel, D. Simpson, and L. Rowe. </author> <title> Software-only video production switcher for the Internet MBone. </title> <booktitle> Proceedings of SPIE Multimedia Computing and Networking, </booktitle> <year> 1998. </year>
Reference-contexts: Applications using the system will use the control interface description to manage the effect by generating an appropriate user interface, mapping the controls to a predefined interface (e.g., a software-only video production switcher interface <ref> [17] </ref>), or controlling the effect programmatically 1 . The FX Mapper is analogous to a database query optimizer or a compiler code generator. The FX Mapper determines how the video effect will be paral-lelized. The effect graph produced by the FX Compiler is augmented with temporal and spatial parallelism operators.
References-found: 17

