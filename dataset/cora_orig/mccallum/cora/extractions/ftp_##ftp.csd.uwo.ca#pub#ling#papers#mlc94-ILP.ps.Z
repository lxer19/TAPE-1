URL: ftp://ftp.csd.uwo.ca/pub/ling/papers/mlc94-ILP.ps.Z
Refering-URL: http://www.csd.uwo.ca/faculty/ling/sub-pub.html
Root-URL: 
Email: aha@aic.nrl.navy.mil  lapointe@drev.dnd.ca  ling@csd.uwo.ca  stan@csi.uottawa.ca  
Title: Learning Recursive Relations with Randomly Selected Small Training Sets  
Author: David W. Aha Stephane Lapointe Charles X. Ling Stan Matwin 
Address: Washington, DC 20375 USA  P.O. Box 8800 Courcelette, Quebec G0A 1R0 Canada  Ontario London, Ontario N6A 5B7 Canada  Ottawa, Ontario K1N 6N5 Canada  
Affiliation: Navy AI Center Naval Research Laboratory  DREV  Dept. of Computer Science Univ. of Western  Dept. of Computer Science University of Ottawa  
Abstract: We evaluate CRUSTACEAN, an inductive logic programming algorithm that uses inverse implication to induce recursive clauses from examples. This approach is well suited for learning a class of self-recursive clauses, which commonly appear in logic programs, because it searches for common substructures among the examples. However, little evidence exists that inverse implication approaches perform well when given only randomly selected positive and negative examples. We show that CRUSTACEAN learns recursive relations with higher accuracies than GOLEM, yet with reasonable efficiency. We also demonstrate that increasing the number of randomly selected positive and negative examples increases its accuracy on randomly selected test examples, increases the frequency in which it outputs the target relation, and reduces its number of outputs. We also prove a theorem that defines the class of logic programs for which our approach is complete.
Abstract-found: 1
Intro-found: 1
Reference: <author> Aha, D. W., Lapointe, S., Ling, C. X., & Matwin, S. </author> <year> (1994). </year> <title> Inverting implication with small training sets. </title> <booktitle> In Proceedings of the 1994 European Conference on Machine Learning (pp. </booktitle> <pages> 31-48). </pages> <address> Catania, Italy: </address> <publisher> Springer Verlag. </publisher>
Reference-contexts: 1 MOTIVATION This paper extends our previous work <ref> (Aha, Lapointe, Ling, & Matwin, 1994) </ref>, which introduced an inductive logic programming (ILP) algorithm and its implementation in CRUSTACEAN. <p> The arguments in the head of the recursive clause are determined by computing lggs from the generating term decompositions of the positive examples, where the number of decompositions each example contributes is equal to the depth of its generating terms. See <ref> (Aha, Lapointe, Ling, & Matwin, 1994) </ref> for more details, including a detailed example. 2.2 CONSTRAINTS CRUSTACEAN's complexity is dominated by its search through the space of generating term combinations. <p> These constraints greatly reduce the amount of time required to locate matched lists of generating terms. For example, when tested on the manually-selected inputs <ref> (see Aha, Lapointe, Ling, & Matwin, 1994) </ref> for the ten relations listed in Table 2, these constraints reduced average summed cpu times by 93.2%. <p> Applying these constraints reduces the space of combinations that satisfy Legal match to 1% of its original size (i.e., 143 of 14225). 2.3 COMPLETENESS THEOREM We <ref> (Aha, Lapointe, Ling, & Matwin, 1994) </ref> previously sketched a proof showing that our algorithm is complete for SR (i.e., it induces all least general logic programs of SR that are consistent with the training examples). <p> The hypotheses explored were summarized in Section 1. 1 Our experiments are with the ten relations whose target clauses 1 Initial evidence for Hypotheses 2 and 5 were discussed in <ref> (Aha, Lapointe, Ling, & Matwin, 1994) </ref>. <p> While these (Sun SPARCstation 10, QProlog) runtimes still increase exponentially with the number of positive examples, these constraints allowed for reasonable run-times. We plan to analyze the utility of additional pragmatic constraints. 4 RELATED WORK This paper extends <ref> (Aha, Lapointe, Ling, & Matwin, 1994) </ref> by empirically evaluating several hypotheses using randomly selected inputs and by providing a proof for our theorem. CRUSTACEAN is derived from LOPSTER (Lapointe & Matwin, 1992).
Reference: <author> Cohen, W. </author> <year> (1993). </year> <title> Pac-learning a restricted class of recursive logic programs. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence (pp. </booktitle> <pages> 86-92). </pages> <address> Washington, DC: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Idestam-Almquist, P. </author> <year> (1993). </year> <title> Recursive anti-unification. </title> <booktitle> In Proceedings of the Third International Workshop on Inductive Logic Programming (pp. </booktitle> <pages> 241-254). </pages> <institution> Bled, Slovenia: J. Stefan Institute. </institution>
Reference: <editor> Kodratoff, Y, & Jouannaud, J.-P. </editor> <year> (1984). </year> <title> Synthesizing LISP programs working on the list level of embedding. </title> <editor> In A. Biermann, G. Guiho, & Y. Kodratoff (Eds.) </editor> <year> (1984). </year> <title> Automatic program construction techniques. </title> <address> New York: </address> <publisher> Macmillian Publishing Company. </publisher>
Reference-contexts: CRUSTACEAN is not given this information, and could presumably benefit from it. Our work also relates to previous work on program synthesis from examples <ref> (e.g., Kodratoff & Jouan-naud, 1984) </ref>). This involves transforming an input-output sequence fx i ; F (x i )g into computational traces of the form fp i (x); f i (x)g, where p i (x) is a predicate and is true if x has the same structure as x i .
Reference: <author> Lapointe, S., Ling, X. C., & Matwin, S. </author> <year> (1993). </year> <title> Constructive inductive logic programming. </title> <booktitle> In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence. </booktitle> <address> Chambery, France: </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Lapointe, S., & Matwin, S. </author> <year> (1992). </year> <title> Sub-unification: A tool for efficient induction of recursive programs. </title> <booktitle> In Proceedings of the Ninth International Conference on Machine Learning (pp. </booktitle> <pages> 273-281). </pages> <address> Aberdeen, Scot-land: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Accuracy increases with increasing numbers of negative examples. 4. The percentage of runs in which CRUSTACEAN outputs the target clause increases with more pos itive examples. 5. The number of relations output decreases with in creasing numbers of examples. Our initial reason for developing CRUSTACEAN was to extend LOPSTER <ref> (Lapointe & Matwin, 1992) </ref>, which inputs two examples and outputs a recursive clause. It requires that one of these examples is the base clause of the recursive relation, or that they are different clauses on the same resolution chain. <p> We plan to analyze the utility of additional pragmatic constraints. 4 RELATED WORK This paper extends (Aha, Lapointe, Ling, & Matwin, 1994) by empirically evaluating several hypotheses using randomly selected inputs and by providing a proof for our theorem. CRUSTACEAN is derived from LOPSTER <ref> (Lapointe & Matwin, 1992) </ref>.
Reference: <author> Muggleton, S. </author> <year> (1992). </year> <title> Inverting implication. </title> <booktitle> In Proceedings of the First European Workshop on Inductive Logic Programming. </booktitle> <address> Vienna, Austria: </address> <note> Unpublished. </note>
Reference-contexts: Here we present its proof, which uses the notion of n th powers and roots <ref> (Muggleton, 1992) </ref>. Theorem 1. Given a set of positive examples P and a set of negative examples N , CRUSTACEAN will output every logic program LP=(BC,RC) in SR with the following properties: 1. <p> Since the - subsumption notion of generality is only incomplete for self-recursive clauses (i.e., for expressing generality relations between different powers or roots of a clause) <ref> (Muggleton, 1992) </ref>, no output is more general under -subsumption than any other output, although one may be more general than another under implication. 3 EVALUATION We empirically evaluated CRUSTACEAN's ability to induce target relations when given randomly selected positive and negative examples.
Reference: <author> Muggleton, S., & Feng, C. </author> <year> (1990). </year> <title> Efficient induction of logic programs. </title> <booktitle> Proceedings of the First International Workshop on Algorithmic Learning Theory (pp. </booktitle> <pages> 368-381). </pages> <address> Tokyo, Japan: </address> <publisher> Japanese Society for AI. </publisher>
Reference-contexts: We examine this in Section 3, where we provide evidence that, for a class of recursive clauses, CRUSTACEAN attains higher accuracies than GOLEM <ref> (Muggleton & Feng, 1990) </ref> when given small numbers of training instances. Section 2 briefly reviews CRUSTACEAN, highlights the constraints it uses to attain reasonable efficiency, and includes the proof for our completeness theorem. Section 3 then summarizes our empirical investigations and discusses the results. <p> CRUSTACEAN embodies strong constraints on the target language, as detailed in Section 2.3. Most popular ILP systems can learn larger classes of relations. Therefore, this restriction is only useful if it yields some comparative performance improvement. We compared CRUSTACEAN with GOLEM <ref> (Muggleton & Feng, 1990) </ref>, a popular ILP system. We fixed the number of negative inputs to ten and varied the number of positive examples from between two and five.
Reference: <author> Quinlan, J. R. </author> <year> (1991). </year> <title> Determinate literals in inductive logic programming. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence (pp. </booktitle> <pages> 746-750). </pages> <address> Sydney, Australia: </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: FORCE2's class of learnable theories and techniques are similar to CRUSTACEAN's. It is a model-driven (enumeration) system, while CRUSTACEAN is data-driven. Cohen reported that FORCE2 has faster learning rates than FOIL <ref> (Quinlan, 1991) </ref>, and that its speed scales linearly with the number of examples. FORCE2 inputs, in addition to the examples, knowledge concerning which examples are instantiations of the base clause, an upper bound on the target relation's depth complexity, and a depth bound i (i.e., it outputs ij-determinate logic programs).
References-found: 9

