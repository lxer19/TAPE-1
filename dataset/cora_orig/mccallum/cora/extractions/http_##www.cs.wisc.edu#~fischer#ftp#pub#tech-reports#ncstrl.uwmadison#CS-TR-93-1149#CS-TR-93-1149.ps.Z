URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1149/CS-TR-93-1149.ps.Z
Refering-URL: http://www.cs.wisc.edu/~fischer/ftp/pub/tech-reports/ncstrl.uwmadison/CS-TR-93-1149/
Root-URL: http://www.cs.wisc.edu
Email: Email olvi@cs.wisc.edu, solodov@cs.wisc.edu.  
Title: SERIAL AND PARALLEL BACKPROPAGATION CONVERGENCE VIA NONMONOTONE PERTURBED MINIMIZATION  
Author: O. L. Mangasarian and M. V. Solodov 
Note: This material is based on research supported by Air Force Office of Scientific Research Grant AFOSR-89-0410 and National Science Foundation Grant CCR-9101801.  
Address: Wisconsin, 1210 West Dayton Street, Madi-son, WI 53706, U.S.A.  
Affiliation: Computer Sciences Department, University of  
Date: Revised December 6, 1993  
Abstract: A general convergence theorem is proposed for a family of serial and parallel nonmonotone unconstrained minimization methods with perturbations. A principal application of the theorem is to establish convergence of backpropagation (BP), the classical algorithm for training artificial neural networks. Under certain natural assumptions, such as divergence of the sum of the learning rates and convergence of the sum of their squares, it is shown that every accumulation point of the BP iterates is a stationary point of the error function associated with the given set of training examples. The results presented cover serial and parallel BP, as well as modified BP with a momentum term. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. C. Blaydon, R. L. Kashyap & K. S. Fu: </author> <title> "Applications of the stochastic approximation methods", in Adaptive, Learning, and Pattern Recognition systems, </title> <editor> J. M. Mendel & K. S. Fu (eds), </editor> <publisher> Academic Press, </publisher> <year> 1970. </year>
Reference: [2] <author> Y. C. Cheng: </author> <title> "On the gradient projection method for solving the nonsymmetric linear complementarity problem", </title> <journal> Journal of Optimization Theory and Applications 43, </journal> <year> 1984, </year> <pages> 527-541. </pages>
Reference: [3] <editor> Yu. Ermoliev & R. J.-B. Wets (editors): </editor> <title> "Numerical Techniques for Stochastic Optimization", </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1988. </year> <month> 14 </month>
Reference: [4] <author> W. Finnoff: </author> <title> "Diffusion approximations for the constant learning rate backpropagation algorithm and resistance to local minima", </title> <booktitle> 1992 Conference on Neural Information Processing Systems, </booktitle> <address> Denver, Colorado, </address> <month> November 30-December 3, </month> <year> 1992. </year>
Reference: [5] <author> A. A. Gaivoronski: </author> <title> "Convergence properties of backpropagation for neural networks via theory of stochastic gradient methods. </title> <booktitle> Part 1.", Symposium on Parallel Optimization 3, </booktitle> <address> Madison July 7-9, </address> <year> 1993. </year>
Reference-contexts: (<ref> [5] </ref>,[6],[10],[4],[18]). In [18] by using stochastic approximation ideas ([1],[3]) it is shown that, under certain stochastic assumptions, the sequence of weights generated by BP either diverges or converges almost surely to a point that is a stationary point of the error function. Some stronger stochastic results were recently obtained in [5]. We emphasize that our approach is purely deterministic. In fact, we show that BP can be viewed as an ordinary perturbed gradient-type algorithm for unconstrained optimization (Theorem 3.1). We give a convergence result for serial and parallel online BP as well as the modified BP with a momentum term.
Reference: [6] <author> L. Grippo: </author> <title> "A class of unconstrained minimization methods for neural network training", </title> <booktitle> Symposium on Parallel Optimization 3, </booktitle> <address> Madison July 7-9, </address> <year> 1993. </year>
Reference-contexts: Since the principal result of the 13 theorem deals with accumulation points, boundedness of the iterates is needed in order to ensure the existence of such accumulation points. There are a number of ways to ensure that the sequence of iterates produced by BP be bounded. In <ref> [6] </ref> a regularization term consisting of the squared 2-norm of x is added to the error function so that the modified objective function has bounded level sets.
Reference: [7] <author> J. Hertz, A. Krogh & R. G. Palmer: </author> <title> "Introduction to the Theory of Neural Computation", </title> <publisher> Addison-Wesley, </publisher> <address> Redwood City, California, </address> <year> 1991. </year>
Reference: [8] <author> T. Khanna: </author> <title> "Foundations of Neural Networks", </title> <publisher> Addison-Wesley, </publisher> <address> Reading, Mas-sachusetts, </address> <year> 1989. </year>
Reference: [9] <author> Z.-Q. Luo: </author> <title> "On the convergence of the LMS algorithm with adaptive learning rate for linear feedforward networks", </title> <booktitle> Neural Computation 3, </booktitle> <year> 1991, </year> <pages> 226-245. </pages>
Reference-contexts: We note that under the same assumptions on the learning rate that we use here, the first two conditions of (3.4) below, convergence of the sequence of weights for linear feedforward networks without a hidden layer is established in <ref> [9] </ref>. The paper is organized as follows. In Section 2 we establish the serial and parallel versions of our nonmonotone convergence theorem for unconstrained optimization. We also show that this theorem can be applied to the analysis of a family of optimization methods with perturbed gradients.
Reference: [10] <author> Z.-Q. Luo & P. Tseng: </author> <title> "Analysis of an approximate gradient projection method with applications to the backpropagation algorithm", </title> <booktitle> Symposium on Parallel Optimization 3, </booktitle> <address> Madison July 7-9, </address> <year> 1993. </year>
Reference-contexts: There are a number of ways to ensure that the sequence of iterates produced by BP be bounded. In [6] a regularization term consisting of the squared 2-norm of x is added to the error function so that the modified objective function has bounded level sets. In <ref> [10] </ref> a simple projection onto a box is introduced which ensures that the iterates remain in the box. 4 Concluding Remarks A general theorem for the nonmonotone convergence of a family of unconstrained optimization methods has been presented.
Reference: [11] <author> O. L. Mangasarian: </author> <title> "Mathematical programming in neural networks", </title> <institution> Computer Sciences Department, University of Wisconsin, Madison, </institution> <type> Technical Report # 1129, </type> <note> De-cember 1992. ORSA Journal on Computing, 5(4), 1993, to appear. </note>
Reference: [12] <author> O. L. Mangasarian: </author> <title> "Parallel gradient distribution in unconstrained optimization", </title> <institution> Computer Sciences Department, University of Wisconsin, Madison, </institution> <type> Technical Report # 1145, </type> <month> April </month> <year> 1993. </year> <note> SIAM Journal on Control, submitted. </note>
Reference-contexts: We start with a nonmonotone convergence theorem for unconstrained optimization algorithms (Theorem 2.1 below). This result generalizes the monotone Theorem 2.1 of <ref> [12] </ref> by adding perturbations to the algorithms that result in a nonmonotone sequence of function values. This is a key generalization that allows the proposed theorems to apply to a wider class of algorithms including backpropagation. <p> However, we have chosen to state Theorem 2.1 in a direction - stepsize form because it is easier to implement. See <ref> [12] </ref> for specific instances of directions d i and stepsize i choices without perturbation terms. We now show that Theorem 2.1 can be applied to the analysis of the perturbed gradient-type methods. <p> The proof is complete. Remark 2.2. Under appropriate assumptions, other well known direction choices, such as conjugate and quasi-Newton directions ([15]) can also be perturbed similarly as in Corollary 2.1. Remark 2.3. Similar to <ref> [12] </ref>, a parallel version of Theorem 2.1 can be established where portions of the gradient are distributed among the processors. However, having in mind the analysis of the BP algorithm, we shall instead here concentrate on parallel distribution of the objective function in the form (1.2). <p> Remark 2.4. Theorem 2.2 can be easily generalized so that each processor takes an arbitrary but finite number of steps before any synchronization is made. The changes needed to extend Theorem 2.2 to these asynchronous methods are straightforward, and are thus omitted. See <ref> [12] </ref> for details. Remark 2.5. A similar parallel version can be stated for Theorem 2.1. 8 3 Convergence of the Backpropagation Algorithm We now turn our attention to the classical BP algorithm for training feedforward artificial neural networks with one layer of hidden units ([16],[7],[17],[8]).
Reference: [13] <author> G. P. McCormick & K. Ritter: </author> <title> "Alternate proofs of the convergence properties of the conjugate gradient method", </title> <journal> Journal of Optimization Theory and Applications 13, </journal> <year> 1974, </year> <pages> 497-518. </pages>
Reference: [14] <author> J. M. Ortega: </author> <title> "Numerical Analysis: A Second Course", </title> <publisher> Academic Press, </publisher> <address> New York, New York 1972. </address>
Reference: [15] <author> B. T. Polyak: </author> <title> "Introduction to Optimization", Optimization Software, </title> <publisher> Inc., </publisher> <address> New York, New York 1987. </address>
Reference: [16] <author> D. E. Rumelhart, G. E. Hinton & R. J. Williams: </author> <title> "Learning internal representations by error propagation", in "Parallel Distributed Processing", </title> <editor> D. E. Rumelhart, J. L. McClelland eds., </editor> <publisher> MIT Press, </publisher> <address> Cambridge, </address> <year> 1986, </year> <pages> 318-362. </pages>
Reference: [17] <author> P. K. Simpson: </author> <booktitle> "Artificial Neural Systems", </booktitle> <publisher> Pergamon Press, </publisher> <address> New York, </address> <year> 1990. </year>
Reference: [18] <author> H. White: </author> <title> "Some asymptotic results for learning in single hidden-layer feedforward network models", </title> <journal> Journal of the American Statistical Association, vol.84, </journal> <volume> No. 408, </volume> <year> 1989, </year> <pages> 1003-1013. </pages>
Reference-contexts: Therefore a single iteration of BP may, in fact, increase rather than decrease the objective function f (x) we are trying to minimize. This difficulty makes convergence analysis of BP a challenging problem that has currently attracted interest of many researchers ([5],[6],[10],[4],<ref> [18] </ref>). In [18] by using stochastic approximation ideas ([1],[3]) it is shown that, under certain stochastic assumptions, the sequence of weights generated by BP either diverges or converges almost surely to a point that is a stationary point of the error function. Some stronger stochastic results were recently obtained in [5]. <p> Flowchart of the Parallel BP To the best of our knowledge there are no published deterministic convergence proofs for either the parallel or serial BP algorithm. In <ref> [18] </ref> it is proven that the sequence of weights generated by the serial BP either converges to a point that is almost surely stationary or it diverges. In contrast, our approach is deterministic.
References-found: 18

