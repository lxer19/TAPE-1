URL: ftp://ftp.cs.colorado.edu/users/alw/papers/sigmod94.ps.Z
Refering-URL: http://www.cs.colorado.edu/~alw/RecentPubs.html
Root-URL: http://www.cs.colorado.edu
Title: Partition Selection Policies in Object Database Garbage Collection  
Author: Jonathan E. Cook, Alexander L. Wolf, and Benjamin G. Zorn 
Affiliation: Department of Computer Science  University of Colorado  
Date: May 25-27, 1994  
Address: Minneapolis, MN,  Campus Box 430  Boulder, CO 80309-0430 USA  
Note: From the Proceedings of the 1994 ACM SIGMOD Inter. Conf. on Management of Data,  
Abstract: The automatic reclamation of storage for unreferenced objects is very important in object databases. Existing language system algorithms for automatic storage reclamation have been shown to be inappropriate. In this paper, we investigate methods to improve the performance of algorithms for automatic storage reclamation of object databases. These algorithms are based on a technique called partitioned garbage collection, in which a subset of the entire database is collected independently of the rest. Specifically, we investigate the policy that is used to select what partition in the database should be collected. The policies that we propose and investigate are based on the intuition that the values of overwritten pointers provide good hints about where to find garbage. Using trace-driven simulation, we show that one of our policies requires less I/O to collect more garbage than any existing implementable policy and performs close to a near-optimal policy over a wide range of database sizes and object connectivities. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Henry G. Baker, Jr. </author> <title> List processing in real time on a serial computer. </title> <journal> Comm. of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <month> April </month> <year> 1978. </year>
Reference-contexts: Butler investigates the performance of different persistent storage management algorithms using probabilistic models of program reference and update behavior [3]. For a number of dynamic storage allocation algorithms, she shows the expected I/O costs based on complex formulas. Her results show that the incremental collection proposed by Baker <ref> [1] </ref> provides significant advantages over other traditional primary-memory collection algorithms when applied to object databases. Butler did not consider partitioned collection algorithms. In very recent work, Yong, Naughton, and Yu present a comprehensive evaluation of incremental, reference counting, and partitioned garbage collection algorithms in client/server persistent object stores [25].
Reference: [2] <author> Anders Bjornerstedt. </author> <title> Secondary Storage Garbage Collection for Decentralized Object-Based Systems. </title> <type> PhD thesis, </type> <institution> Stock-holm University, Dept. of Comp. Sys. Sciences, Royal Inst. of Tech. and Stockholm Univ., Kista, Sweden, </institution> <year> 1993. </year> <note> Also appears as Systems Dev. </note> <institution> and AI Lab. </institution> <note> Report No. 77. </note>
Reference-contexts: problem has been studied for three decades by designers of programming language systems in the realm of transient, primary-memory (heap) objects, only recently has a strong interest developed in formulating the storage reclamation techniques that are commensurate with the size, complexity, and stability characteristics of persistent, secondary-memory objects in ODBMSs <ref> [2, 3, 15, 16, 25] </ref>. In fact, it has been shown that the reclamation algorithms developed for programming language systems are, as currently formulated, inappropriate for use on object databases [3, 25]. <p> Although some of the proposed algorithms do act incrementally on subsets of the database <ref> [2, 4, 16, 18] </ref>, the partitioning aspects of those algorithms have been treated secondarily at best. Butler investigates the performance of different persistent storage management algorithms using probabilistic models of program reference and update behavior [3].
Reference: [3] <author> Margaret H. Butler. </author> <title> Storage reclamation in object-oriented database systems. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <pages> pages 410-423, </pages> <address> San Francisco, CA, </address> <year> 1987. </year>
Reference-contexts: problem has been studied for three decades by designers of programming language systems in the realm of transient, primary-memory (heap) objects, only recently has a strong interest developed in formulating the storage reclamation techniques that are commensurate with the size, complexity, and stability characteristics of persistent, secondary-memory objects in ODBMSs <ref> [2, 3, 15, 16, 25] </ref>. In fact, it has been shown that the reclamation algorithms developed for programming language systems are, as currently formulated, inappropriate for use on object databases [3, 25]. <p> In fact, it has been shown that the reclamation algorithms developed for programming language systems are, as currently formulated, inappropriate for use on object databases <ref> [3, 25] </ref>. This paper reports on the design and evaluation of several new storage reclamation algorithms specifically intended for use by ODBMSs. <p> Although some of the proposed algorithms do act incrementally on subsets of the database [2, 4, 16, 18], the partitioning aspects of those algorithms have been treated secondarily at best. Butler investigates the performance of different persistent storage management algorithms using probabilistic models of program reference and update behavior <ref> [3] </ref>. For a number of dynamic storage allocation algorithms, she shows the expected I/O costs based on complex formulas. Her results show that the incremental collection proposed by Baker [1] provides significant advantages over other traditional primary-memory collection algorithms when applied to object databases. <p> The dense edges connect random nodes in the same tree. Object Size. Object sizes are randomly distributed around an average of 100 bytes. The distribution is uniform, with bounds at 50 and 150 bytes. We selected this size after looking at previous work <ref> [3, 7, 25] </ref> and experimenting with a variety of sizes.
Reference: [4] <author> Jack Campin and Malcolm Atkinson. </author> <title> A persistent store garbage collector with statistical facilities. Persistent Programming Reserarch Report 29, </title> <institution> Department of Computing Science, University of Glasgow, </institution> <address> Glasgow, Scotland, </address> <year> 1986. </year>
Reference-contexts: Although some of the proposed algorithms do act incrementally on subsets of the database <ref> [2, 4, 16, 18] </ref>, the partitioning aspects of those algorithms have been treated secondarily at best. Butler investigates the performance of different persistent storage management algorithms using probabilistic models of program reference and update behavior [3].
Reference: [5] <author> Michael J. Carey, David J. DeWitt, and Jeffrey F. Naughton. </author> <title> The OO7 benchmark. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> Washington, DC, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: We do, however, include a few large objects that average 64 kilobytes each. These are always leaf objects and comprise about 20% of the space of all objects, in a manner similar to the document nodes in the OO7 benchmark <ref> [5] </ref>. Object Placement. Each augmented binary tree is created in a breadth-first manner and the database attempts to place a new object near its parent. For an empty partition, then, a new tree would be placed in the database in a strict breadth-first order. Database Size. <p> As an overall observation on the work in this area, we note that there is a general lack of understanding about the time-varying behavior of real object databases. Even existing object database benchmarks, such as OO1 [7] and OO7 <ref> [5] </ref>, focus primarily on the database access patterns and not the time-evolution of the contents of the database. As we have noted, an understanding of algorithms for language system garbage collection evolved from accumulated experience and empirical results about object lifetimes in programs.
Reference: [6] <author> M. Cart and J. Ferrie. </author> <title> Integrating Concurrency Control into an Object-oriented Database System. </title> <booktitle> In Proceedings of the Second International Conference on Extending Database Technology. </booktitle> <publisher> Springer-Verlag, </publisher> <month> March </month> <year> 1989. </year>
Reference-contexts: Three of them are: (1) partition objects based on access patterns (e.g., [19, 22]); (2) partition objects based on the unit of transfer between a server and a client (e.g., [11]); and (3) partition objects to increase locking granularity and thereby decrease overhead (e.g., <ref> [6] </ref>). If the criterion used to partition the object space is essentially a given, then what is the crucial element in the design of an ODBMS garbage collection algorithm? The answer is partition selection, the selection of which partition to examine for garbage during a particular collection.
Reference: [7] <author> R. G. G. Cattell. </author> <title> The Benchmark Handbook for Database and Transaction Processing Systems, </title> <booktitle> chapter 6, </booktitle> <pages> pages 247-281. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1991. </year>
Reference-contexts: The dense edges connect random nodes in the same tree. Object Size. Object sizes are randomly distributed around an average of 100 bytes. The distribution is uniform, with bounds at 50 and 150 bytes. We selected this size after looking at previous work <ref> [3, 7, 25] </ref> and experimenting with a variety of sizes. <p> As an overall observation on the work in this area, we note that there is a general lack of understanding about the time-varying behavior of real object databases. Even existing object database benchmarks, such as OO1 <ref> [7] </ref> and OO7 [5], focus primarily on the database access patterns and not the time-evolution of the contents of the database. As we have noted, an understanding of algorithms for language system garbage collection evolved from accumulated experience and empirical results about object lifetimes in programs.
Reference: [8] <author> H.-T. Chou and D.J. Dewitt. </author> <title> An Evaluation of Buffer Management Strategies for Relational Database Systems. </title> <booktitle> In Proc. of the 11th International Conf. on Very Large Data Bases, </booktitle> <pages> pages 127-141. </pages> <publisher> Morgan Kaufmann, </publisher> <month> August </month> <year> 1985. </year>
Reference-contexts: The primary distinction among our algorithms is the policy by which each selects a partition (i.e., the subset) of the database to examine during a particular activation of the garbage collector. We evaluated the algorithms using trace-driven simulations <ref> [8] </ref> of applications that create, access, and modify objects. Our results show that the partition selection policy can significantly affect application performance and that a new policy we propose has the highest performance of the implementable policies that we considered. <p> This method has been applied effectively in evaluating many kinds of computer systems, including computer architectures [21], programming languages [24], and database systems <ref> [8, 25] </ref>. To evaluate the performance of storage reclamation in ODBMSs, our simulation system simulates the physical and logical structure of the database implementation being measured. Traces of database application events (e.g., object creations, object mutations, etc.) are used to drive the simulations; details appear in [9].
Reference: [9] <author> Jonathan Cook, Alexander Wolf, and Benjamin Zorn. </author> <title> The design of a simulation system for persistent object storage management. </title> <type> Technical Report CU-CS-647-93, </type> <institution> Department of Computer Science, University of Colorado, Boulder, CO, </institution> <month> March </month> <year> 1993. </year>
Reference-contexts: To evaluate the performance of storage reclamation in ODBMSs, our simulation system simulates the physical and logical structure of the database implementation being measured. Traces of database application events (e.g., object creations, object mutations, etc.) are used to drive the simulations; details appear in <ref> [9] </ref>. We use synthetic, probabilistic models of application behavior to generate a test database application. Details of the test database are provided in Section 4.
Reference: [10] <author> Jonathan Cook, Alexander Wolf, and Benjamin Zorn. </author> <title> Partition selection policies in object database garbage collection. </title> <type> Technical Report CU-CS-653-93, </type> <institution> Department of Computer Science, University of Colorado, Boulder, CO, </institution> <note> Revised De-cember 1993. </note>
Reference-contexts: In particular, we discuss some lessons learned from programming-language-system algorithms and clarify the notions of partitioning and partitioned garbage collection. We also briefly discuss related work; a more detailed discussion appears in <ref> [10] </ref>. 371 1.1 Background Useful insights into storage reclamation for ODBMSs can be gained from the programming-language-system experience. <p> We model a single-process application sharing a buffer with the ODBMS, which executes on the same processor. The following list presents the database characteristics and briefly gives reasons behind the choices. A more detailed description appears in <ref> [10] </ref>. 376 Database Structure. The test database is a forest of augmented binary trees of objects, where each tree root is itself a root object of the database.
Reference: [11] <author> D.J. Dewitt, P. Futtersack, D. Maier, and F. Velez. </author> <title> A Study of Three Alternative Workstation-Server Architectures for Object-Oriented Database Systems. </title> <booktitle> In Proceedings of the 16th International Conference on Very Large Data Bases, </booktitle> <pages> pages 107-121. </pages> <publisher> Morgan Kaufmann, </publisher> <month> August </month> <year> 1990. </year>
Reference-contexts: Three of them are: (1) partition objects based on access patterns (e.g., [19, 22]); (2) partition objects based on the unit of transfer between a server and a client (e.g., <ref> [11] </ref>); and (3) partition objects to increase locking granularity and thereby decrease overhead (e.g., [6]).
Reference: [12] <author> Aloke Gupta and W. Kent Fuchs. </author> <title> Garbage collection in a distributed object-oriented system. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 5(2) </volume> <pages> 257-265, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Our collectors do not reclaim these garbage structures, although our future work will investigate this phenomenon in more detail. While there has been some work done in handling distributed cyclic garbage in distributed systems <ref> [12] </ref>, which can be applied to partitioned collection, previous work in partitioned collection has maintained that cross-partition cycles will "probably" not be a problem [23, 25]. We have seen, however, that even small increases in connectivity can produce significant amounts of distributed cyclic garbage due to nepotism.
Reference: [13] <author> Antony L. Hosking, J. Eliot B. Moss, and Darko Stefanovic. </author> <title> A comparative performance evaluation of write barrier implementations. </title> <booktitle> In ACM SIGPLAN 1992 Conference on Object Oriented Programming Systems, Languages and Applications (OOPSLA '92), </booktitle> <pages> pages 92-109, </pages> <address> Vancouver, British Columbia, Canada, </address> <month> October </month> <year> 1992. </year>
Reference-contexts: Language system techniques for maintaining the remembered sets and the write barriers exist and can be applied in the domain of object databases. A number of well-known and effective implementations, including those mentioned in the table, have been evaluated and compared <ref> [13] </ref>. In addition, most object databases already make use of the write barrier for purposes such as concurrency control and recovery.
Reference: [14] <author> W. Kim. </author> <title> Introduction to Object-Oriented Databases. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: The goal of the integration is to support the definition of a richer set of types for data and to support the manipulation of those data using a more powerful, programming-language-like model of computation <ref> [14] </ref>. Two concepts that were extensively developed in the programming language area and that are now profitably employed in ODBMSs are direct support for complex, highly interconnected data and a notion of object identity separate from object value.
Reference: [15] <author> Elliot Kolodner, Barbara Liskov, and William Weihl. </author> <title> Atomic garbage collection: Managing a stable heap. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <pages> pages 15-25, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: problem has been studied for three decades by designers of programming language systems in the realm of transient, primary-memory (heap) objects, only recently has a strong interest developed in formulating the storage reclamation techniques that are commensurate with the size, complexity, and stability characteristics of persistent, secondary-memory objects in ODBMSs <ref> [2, 3, 15, 16, 25] </ref>. In fact, it has been shown that the reclamation algorithms developed for programming language systems are, as currently formulated, inappropriate for use on object databases [3, 25].
Reference: [16] <author> Elliot Kolodner and William Weihl. </author> <title> Atomic incremental garbage collection and recovery for a large stable heap. </title> <booktitle> In Proceedings of the ACM SIGMOD International Conference on the Management of Data, </booktitle> <address> Washington, DC, </address> <month> June </month> <year> 1993. </year>
Reference-contexts: problem has been studied for three decades by designers of programming language systems in the realm of transient, primary-memory (heap) objects, only recently has a strong interest developed in formulating the storage reclamation techniques that are commensurate with the size, complexity, and stability characteristics of persistent, secondary-memory objects in ODBMSs <ref> [2, 3, 15, 16, 25] </ref>. In fact, it has been shown that the reclamation algorithms developed for programming language systems are, as currently formulated, inappropriate for use on object databases [3, 25]. <p> Although some of the proposed algorithms do act incrementally on subsets of the database <ref> [2, 4, 16, 18] </ref>, the partitioning aspects of those algorithms have been treated secondarily at best. Butler investigates the performance of different persistent storage management algorithms using probabilistic models of program reference and update behavior [3].
Reference: [17] <author> Henry Lieberman and Carl Hewitt. </author> <title> A real-time garbage collector based on the lifetimes of objects. </title> <journal> Comm. of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-429, </pages> <month> June </month> <year> 1983. </year>
Reference-contexts: One fundamental insight is that the performance of garbage collection over a large address space is improved if the objects in the address space are partitioned into groups, where storage in each group can be reclaimed independently <ref> [17] </ref>. Thus, only a subset of a potentially huge set of objects needs to be considered at any point by a collector. <p> In the programming language domain, garbage collection algorithms are dominated by those that use object age as the criterion, since empirical data on programs clearly demonstrate that objects of similar age usually exhibit similar lifetimes [20, 26]. Thus, these algorithms are referred to as generational collection algorithms <ref> [17, 23] </ref>. In ODBMSs, no such universal criterion has yet emerged. In fact, a number of different criteria for partitioning an object database| predating the recent interest in garbage collection and hence not designed with garbage collection in mind| have already been built into those systems.
Reference: [18] <author> David C. J. Matthews. </author> <title> Poly manual. </title> <journal> SIGPLAN Notices, </journal> <volume> 20(9), </volume> <month> September </month> <year> 1985. </year>
Reference-contexts: Although some of the proposed algorithms do act incrementally on subsets of the database <ref> [2, 4, 16, 18] </ref>, the partitioning aspects of those algorithms have been treated secondarily at best. Butler investigates the performance of different persistent storage management algorithms using probabilistic models of program reference and update behavior [3].
Reference: [19] <author> K.P. Shannon and R.T. Snodgrass. </author> <title> Semantic Clustering. </title> <booktitle> In Proceedings of the Fourth International Workshop on Persistent Object Systems, </booktitle> <pages> pages 361-374. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: In fact, a number of different criteria for partitioning an object database| predating the recent interest in garbage collection and hence not designed with garbage collection in mind| have already been built into those systems. Three of them are: (1) partition objects based on access patterns (e.g., <ref> [19, 22] </ref>); (2) partition objects based on the unit of transfer between a server and a client (e.g., [11]); and (3) partition objects to increase locking granularity and thereby decrease overhead (e.g., [6]).
Reference: [20] <author> Robert A. Shaw. </author> <title> Empirical Analysis of a Lisp System. </title> <type> PhD thesis, </type> <institution> Stanford University, Stanford, </institution> <address> CA, </address> <month> February </month> <year> 1988. </year> <note> Also appears as tech report CSL-TR-88-351. </note>
Reference-contexts: In the programming language domain, garbage collection algorithms are dominated by those that use object age as the criterion, since empirical data on programs clearly demonstrate that objects of similar age usually exhibit similar lifetimes <ref> [20, 26] </ref>. Thus, these algorithms are referred to as generational collection algorithms [17, 23]. In ODBMSs, no such universal criterion has yet emerged.
Reference: [21] <author> Alan J. Smith. </author> <title> Cache memories. </title> <journal> ACM Computing Surveys, </journal> <volume> 14(3) </volume> <pages> 473-530, </pages> <month> September </month> <year> 1982. </year>
Reference-contexts: Otherwise, when we collect that partition, we will unnecessarily preserve objects pointed to by garbage. 3.2 Performance Evaluation Method We use trace-driven simulation to evaluate alternative partition selection policies. This method has been applied effectively in evaluating many kinds of computer systems, including computer architectures <ref> [21] </ref>, programming languages [24], and database systems [8, 25]. To evaluate the performance of storage reclamation in ODBMSs, our simulation system simulates the physical and logical structure of the database implementation being measured.
Reference: [22] <author> M. M. Tsangaris and J. F. Naughton. </author> <title> A stochastic approach for clustering in object bases. </title> <booktitle> In Proceedings of the SIGMOD Conference on Management of Data, </booktitle> <pages> pages 12-21, </pages> <address> Denver, CO, </address> <month> March </month> <year> 1991. </year>
Reference-contexts: In fact, a number of different criteria for partitioning an object database| predating the recent interest in garbage collection and hence not designed with garbage collection in mind| have already been built into those systems. Three of them are: (1) partition objects based on access patterns (e.g., <ref> [19, 22] </ref>); (2) partition objects based on the unit of transfer between a server and a client (e.g., [11]); and (3) partition objects to increase locking granularity and thereby decrease overhead (e.g., [6]).
Reference: [23] <author> David Ungar. </author> <title> Generation scavenging: A non-disruptive high performance storage reclamation algorithm. </title> <booktitle> In SIGSOFT/SIGPLAN Practical Programming Environments Conference, </booktitle> <pages> pages 157-167, </pages> <month> April </month> <year> 1984. </year>
Reference-contexts: In the programming language domain, garbage collection algorithms are dominated by those that use object age as the criterion, since empirical data on programs clearly demonstrate that objects of similar age usually exhibit similar lifetimes [20, 26]. Thus, these algorithms are referred to as generational collection algorithms <ref> [17, 23] </ref>. In ODBMSs, no such universal criterion has yet emerged. In fact, a number of different criteria for partitioning an object database| predating the recent interest in garbage collection and hence not designed with garbage collection in mind| have already been built into those systems. <p> The only one that deserves further explanation is the policy concerned with maintaining the inter-partition pointers. These pointers are commonly stored in a data structure called the remembered set <ref> [23] </ref>, which records all inter-partition pointers into a partition on a per-partition basis. Each time a write occurs there is a possibility that an inter-partition reference has been created or destroyed. <p> While there has been some work done in handling distributed cyclic garbage in distributed systems [12], which can be applied to partitioned collection, previous work in partitioned collection has maintained that cross-partition cycles will "probably" not be a problem <ref> [23, 25] </ref>. We have seen, however, that even small increases in connectivity can produce significant amounts of distributed cyclic garbage due to nepotism.
Reference: [24] <author> David Ungar and Frank Jackson. </author> <title> An adaptive tenuring policy for generation scavengers. </title> <journal> ACM Trans. on Programming Languages and Systems, </journal> <volume> 14(1) </volume> <pages> 1-27, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: Otherwise, when we collect that partition, we will unnecessarily preserve objects pointed to by garbage. 3.2 Performance Evaluation Method We use trace-driven simulation to evaluate alternative partition selection policies. This method has been applied effectively in evaluating many kinds of computer systems, including computer architectures [21], programming languages <ref> [24] </ref>, and database systems [8, 25]. To evaluate the performance of storage reclamation in ODBMSs, our simulation system simulates the physical and logical structure of the database implementation being measured. <p> Note that inter-partition pointers from dead objects into a partition cause data in a partition to be considered alive (so-called nepotism in generational collectors <ref> [24] </ref>). Thus, as connectivity increases, so does the incidence of nepotism, and as a result, the efficiency of collection decreases. The results in Table 5 show that nepotism plays a part (although not a large one) in reducing the efficiency of collection, even with the near-optimal Oracle policy.
Reference: [25] <author> Voon-Fee Yong, Jeffrey Naughton, and Jie-Bing Yu. </author> <title> Storage reclamation and reorganization in client-server persistent object stores. </title> <booktitle> In Proc. of the 10th International Conference on Data Engineering, </booktitle> <pages> pages 120-131, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: problem has been studied for three decades by designers of programming language systems in the realm of transient, primary-memory (heap) objects, only recently has a strong interest developed in formulating the storage reclamation techniques that are commensurate with the size, complexity, and stability characteristics of persistent, secondary-memory objects in ODBMSs <ref> [2, 3, 15, 16, 25] </ref>. In fact, it has been shown that the reclamation algorithms developed for programming language systems are, as currently formulated, inappropriate for use on object databases [3, 25]. <p> In fact, it has been shown that the reclamation algorithms developed for programming language systems are, as currently formulated, inappropriate for use on object databases <ref> [3, 25] </ref>. This paper reports on the design and evaluation of several new storage reclamation algorithms specifically intended for use by ODBMSs. <p> This paper reports on the design and evaluation of several new storage reclamation algorithms specifically intended for use by ODBMSs. Our designs fall into the class of algorithms know as partitioned garbage collection algorithms <ref> [25] </ref>, in which a subset of the entire database is collected incrementally and independently of the rest. The primary distinction among our algorithms is the policy by which each selects a partition (i.e., the subset) of the database to examine during a particular activation of the garbage collector. <p> Butler did not consider partitioned collection algorithms. In very recent work, Yong, Naughton, and Yu present a comprehensive evaluation of incremental, reference counting, and partitioned garbage collection algorithms in client/server persistent object stores <ref> [25] </ref>. They conclude that an incremental partitioned collection algorithm shows the best performance based on a number of metrics including scalability, reclustering capability, and locality improvement. Our work extends and complements the work of Yong, Naughton, and Yu. <p> This method has been applied effectively in evaluating many kinds of computer systems, including computer architectures [21], programming languages [24], and database systems <ref> [8, 25] </ref>. To evaluate the performance of storage reclamation in ODBMSs, our simulation system simulates the physical and logical structure of the database implementation being measured. Traces of database application events (e.g., object creations, object mutations, etc.) are used to drive the simulations; details appear in [9]. <p> The dense edges connect random nodes in the same tree. Object Size. Object sizes are randomly distributed around an average of 100 bytes. The distribution is uniform, with bounds at 50 and 150 bytes. We selected this size after looking at previous work <ref> [3, 7, 25] </ref> and experimenting with a variety of sizes. <p> While there has been some work done in handling distributed cyclic garbage in distributed systems [12], which can be applied to partitioned collection, previous work in partitioned collection has maintained that cross-partition cycles will "probably" not be a problem <ref> [23, 25] </ref>. We have seen, however, that even small increases in connectivity can produce significant amounts of distributed cyclic garbage due to nepotism.
Reference: [26] <author> Benjamin Zorn. </author> <title> Comparative Performance Evaluation of Garbage Collection Algorithms. </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, Berkeley, </institution> <address> CA, </address> <month> November </month> <year> 1989. </year> <note> Also appears as tech report UCB/CSD 89/544. 382 </note>
Reference-contexts: In the programming language domain, garbage collection algorithms are dominated by those that use object age as the criterion, since empirical data on programs clearly demonstrate that objects of similar age usually exhibit similar lifetimes <ref> [20, 26] </ref>. Thus, these algorithms are referred to as generational collection algorithms [17, 23]. In ODBMSs, no such universal criterion has yet emerged.
References-found: 26

