URL: ftp://cns.brown.edu/nin/papers/cooper.ps.Z
Refering-URL: http://www.math.tau.ac.il/~nin/research.html
Root-URL: 
Title: Objective Function Formulation of the BCM Theory of Visual Cortical Plasticity: Statistical Connections, Stability Conditions  
Author: Nathan Intrator and Leon N Cooper 
Keyword: unsupervised learning, feature extraction, dimensionality reduction.  
Note: In Neural Networks Vol. 5, pp. 3-17, 1992 This work was supported in part by the National Science Foundation, the Office of Naval Research, and the Army Research Office.  
Address: Providence, RI 02912  
Affiliation: Physics Department and Center for Neural Science Brown University  
Abstract: In this paper, we present an objective function formulation of the BCM theory of visual cortical plasticity that permits us to demonstrate the connection between the unsupervised BCM learning procedure and various statistical methods, in particular, that of Projection Pursuit. This formulation provides a general method for stability analysis of the fixed points of the theory and enables us to analyze the behavior and the evolution of the network under various visual rearing conditions. It also allows comparison with many existing unsupervised methods. This model has been shown successful in various applications such as phoneme and 3D object recognition. We thus have the striking and possibly highly significant result that a biological neuron is performing a sophisticated statistical procedure. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Barron, A. R. and Barron, R. L. </author> <year> (1988). </year> <title> Statistical learning networks: A unifying view. </title> <editor> In Wegman, E., editor, </editor> <booktitle> Computing Science and Statistics: Proc. 20th Symp. Interface, </booktitle> <pages> pages 192-203. </pages> <publisher> American Statistical Association, </publisher> <address> Washington, DC. </address>
Reference-contexts: Unsupervised methods however, use local objective functions which may lead to less sensitivity to the number of parameters in the estimation, and therefore have the potential to avoid the curse of dimensionality <ref> (Barron and Barron, 1988) </ref>. For the purpose of pattern classification, it is important to devote our attention to those dimensionality reduction methods that allow discrimination between classes and not faithful representations of the data.
Reference: <author> Bear, M. F. and Cooper, L. N. </author> <year> (1990). </year> <title> Molecular mechanisms for synaptic modification in the visual cortex: Interaction between theory and experiment. </title> <editor> In Gluck, M. and Rumelhart, D., editors, </editor> <booktitle> Neuroscience and Connectionist Theory, </booktitle> <pages> pages 65-94. </pages> <publisher> Lawrence Erlbaum, </publisher> <address> Hillsdale, New Jersey. </address>
Reference: <author> Bear, M. F., Cooper, L. N., and Ebner, F. F. </author> <year> (1987). </year> <title> A physiological basis for a theory of synapse modification. </title> <journal> Science, </journal> <volume> 237 </volume> <pages> 42-48. </pages>
Reference: <author> Bellman, R. E. </author> <year> (1961). </year> <title> Adaptive Control Processes. </title> <publisher> Princeton University Press, </publisher> <address> Princeton, NJ. </address> <note> Intrator and Cooper Objective Function Formulation of the BCM Theory 22 Bienenstock, </note> <author> E. L., Cooper, L. N., and Munro, P. W. </author> <year> (1982). </year> <title> Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex. </title> <journal> Journal Neuroscience, </journal> <volume> 2 </volume> <pages> 32-48. </pages>
Reference-contexts: with synaptic weight vector m i there is a corresponding neuron with weight vector m 0 i that undergoes the same evolution (around the fixed points) subject to a translation ff. 3 Extraction of Optimal Unsupervised Features When a classification of high dimensional vectors is sought, the curse of dimensionality <ref> (Bellman, 1961) </ref> becomes the main factor affecting the classification performance. The curse of dimensionality is due to the inherent sparsity of high dimensional spaces; thus the amount of training data needed to get reasonably low variance estimators becomes ridiculously high.
Reference: <author> Bryan, J. G. </author> <year> (1951). </year> <title> The generalized discriminant function: mathematical foundations and computational routines. </title> <journal> Harvard Educational Review, </journal> <volume> 21 </volume> <pages> 90-95. </pages>
Reference: <author> Clothiaux, E. E., Cooper, L. N., and Bear, M. F. </author> <year> (1991). </year> <title> Synaptic plasticity in visual cortex: Comparison of theory with experiment. </title> <journal> Journal of Neurophysiology, </journal> <volume> 66 </volume> <pages> 1785-1804. </pages>
Reference-contexts: Either form seems consistent with presently available experimental results <ref> (Clothiaux et al., 1991) </ref> but imply quite different underlying physiological mechanisms. The original BCM form requires that a history of activity (likely cell depolarization) be stored and then via a non-linear process produce the modification threshold. The present form of fi M requires that the non-linear process occur first. <p> Computer simulations show that it is possible to achieve a disconnection of the newly closed eye before the newly open eye Intrator and Cooper Objective Function Formulation of the BCM Theory 21 becomes selective <ref> (Clothiaux et al., 1991) </ref>. 6.5 Strabismus From theorem 5.1 we infer that a stable fixed point is such that its projection to one of the inputs is positive, and it is orthogonal to all the other inputs.
Reference: <author> Cooper, L. N., Liberman, F., and Oja, E. </author> <year> (1979). </year> <title> A theory for the acquisition and loss of neurons specificity in visual cortex. </title> <journal> Biological Cybernetics, </journal> <volume> 33 </volume> <pages> 9-28. </pages>
Reference: <author> Cooper, L. N. and Scofield, C. L. </author> <year> (1988). </year> <title> Mean-field theory of a neural network. </title> <booktitle> Proceedings of the National Academy of Science, </booktitle> <volume> 85 </volume> <pages> 1973-1977. </pages>
Reference-contexts: Daniels, 1986; Bear et al., 1987; Bear and Cooper, 1990; Clothiaux et al., 1991). 2.3 Lateral Inhibition Network: Mean Field Theory An extension of the single cell BCM neuron to a lateral inhibition network was presented by (Scofield and Cooper, 1985) and a mean field approximation of this network by <ref> (Cooper and Scofield, 1988) </ref>. <p> The inhibited activity and threshold of the k'th neuron is given by ~c k = c k j6=k M = E [~c 2 This feed-forward network should be contrasted with a lateral inhibition network <ref> (used for example by Cooper and Scofield, 1988) </ref> in which the inhibited activity is given by c k = c k (0) + P relation between these two networks will be discussed in the next section. <p> Thus the mean field approximation of the feed-forward network yields the lateral inhibition mean field result merely by scaling the average inhibition. One result of the mean field approximation <ref> (Cooper and Scofield, 1988) </ref> is that there is a transformation such that m (ff) = m 0 ff (24) and so the gradient with respect to the weights yields two terms _m and _ff. <p> In this situation the analysis of section 5 applies for m (ff) (the mean field network) as well as for m (0). In addition, the argument given in the appendix of <ref> (Cooper and Scofield, 1988) </ref> regarding the non adiabatic case holds here as well.
Reference: <author> Diaconis, P. and Freedman, D. </author> <year> (1984). </year> <title> Asymptotics of graphical projection pursuit. </title> <journal> Annals of Statistics, </journal> <volume> 12 </volume> <pages> 793-815. </pages>
Reference: <author> Duda, R. O. and Hart, P. E. </author> <year> (1973). </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley, </publisher> <address> New York. </address>
Reference: <author> Duffy, F. H., Sonodgrass, S. R., Burchfiel, J. L., and Conway, J. L. </author> <year> (1976). </year> <booktitle> Bicuculline reversal of deprivation amblyopia in the cat. Nature, </booktitle> <volume> 260 </volume> <pages> 256-257. </pages>
Reference-contexts: Moreover, deprived-eye responses in visual cortex may be restored within minutes to hours under some conditions <ref> (Duffy et al., 1976) </ref>, which suggests that synapses deemed functionally disconnected are nonetheless physically present. Therefore, it is reasonable to assume that changes in the functional binocularity may be explained by changes in the efficacy of individual cortical synapses.
Reference: <author> Fisher, R. A. </author> <year> (1936). </year> <title> The use of multiple measurements in taxonomic problems. </title> <journal> Annals of Eugenics, </journal> <volume> 7 </volume> <pages> 179-188. </pages>
Reference: <author> Fregnac, Y. and Imbert, M. </author> <year> (1984). </year> <title> Development of neuronal selectivity in primary visual cortex of cat. </title> <journal> Physiol. Rev, </journal> <volume> 64 </volume> <pages> 325-434. </pages>
Reference: <author> Friedman, J. H. </author> <year> (1987). </year> <title> Exploratory projection pursuit. </title> <journal> Journal of the American Statistical Association, </journal> <volume> 82 </volume> <pages> 249-266. </pages>
Reference-contexts: It also provides a general method for stability analysis of the fixed points of the theory and enables us to analyze the behavior and the evolution of the network under various visual rearing conditions. This new model has some advantages over the original exploratory projection pursuit model <ref> (Friedman, 1987) </ref>. Due to its computational efficiency, it can extract several features in parallel, taking into account the interaction between the different extracted features via a lateral inhibition network.
Reference: <author> Friedman, J. H. and Tukey, J. W. </author> <year> (1974). </year> <title> A projection pursuit algorithm for exploratory data analysis. </title> <journal> IEEE Transactions on Computers, C(23):881-889. </journal>
Reference: <author> Harman, H. H. </author> <year> (1967). </year> <title> Modern Factor Analysis. </title> <publisher> University of Chicago Press, </publisher> <address> Second Edition, Chicago and London. </address>
Reference-contexts: For the purpose of pattern classification, it is important to devote our attention to those dimensionality reduction methods that allow discrimination between classes and not faithful representations of the data. This leaves out the class of methods such as factor analysis <ref> (see review in Harman, 1967) </ref> which tend to combine features that seem to have high correlation. <p> The resulting method concentrates on projections that allow discrimination between clusters and not faithful representation of the data, which is in contrast to principal components analysis, or factor analysis which tend to combine features that have high correlation <ref> (see review in Harman, 1967) </ref>. The method differs from cluster analysis by the fact that it searches for clusters in the low dimensional projection space, thus avoiding the inherent sparsity of the high dimensional space.
Reference: <author> Hinton, G. E. and Nowlan, S. J. </author> <year> (1990). </year> <title> The bootstrap widrow-hoff rule as a cluster-formation algorithm. </title> <journal> Neural Computation, </journal> <volume> 2(3) </volume> <pages> 355-362. </pages>
Reference-contexts: From our earlier discussion it follows that these polynomial moments should be of higher order than two. In some special cases where the data is known in advance to be bi-modal, it is relatively straightforward to define a good projection index <ref> (Hinton and Nowlan, 1990) </ref>, however, when the structure is not known in advance, it is still valid to seek multi-modality in the projected data. by projecting to the y axis, although the variance in the y axis is larger.
Reference: <author> Hubel, D. H. and Wiesel, T. N. </author> <year> (1959). </year> <title> Integrative action in the cat's lateral geniculate body. </title> <journal> J. Physiol, </journal> <volume> 148 </volume> <pages> 574-591. </pages>
Reference: <author> Huber, P. J. </author> <year> (1985). </year> <title> Projection pursuit. (with discussion). </title> <journal> The Annals of Statistics, </journal> <volume> 13 </volume> <pages> 435-475. </pages>
Reference-contexts: Despite the computational attractiveness, projection indices based on polynomial moments are not directly applicable, since they very heavily emphasize departure from normality in the tails of the distribution <ref> (Huber, 1985) </ref>. Friedman (1987) addresses this issue by introducing a nonlinear transformation that compresses the projected data from R to [1; 1] using a normal distribution function. <p> BCM Theory 11 Therefore the total gradient becomes: _m k = @m k M ) 0 (~c k )x] j6=k m ) 0 (~c j )x]g: (11) The lateral inhibition network performs a search of k-dimensional projections together; thus may find a richer structure that a stepwise approach might miss <ref> (e.g. see example 14.1, Huber, 1985) </ref>. 4.4 Some Related Statistical and Computational Issues The proposed method uses low order polynomial moments which are computational efficient, yet it does not suffer from the main draw back of polynomial moments sensitivity to outliers. <p> The projection index contains a single dimensional scaling (see the contribution of Hastie and Tibshirani to the discussion in Jones and Sibson, 1987), therefore, removing the need for a sphering transformation to the data, however, a sphering transformation will result in a type III projection index <ref> (see Huber, 1985) </ref>. The projection index has a natural stochastic gradient descent version which further accelerates the calculation by eliminating the need to calculate the empirical expected value of the gradient.
Reference: <author> Intrator, N. </author> <year> (1990). </year> <title> An averaging result for random differential equations. </title> <type> Technical Report 54, </type> <institution> Center For Neural Science, Brown University. </institution> <note> Intrator and Cooper Objective Function Formulation of the BCM Theory 23 Intrator, </note> <author> N. </author> <year> (1992). </year> <title> Feature extraction using an unsupervised neural network. </title> <journal> Neural Computation, </journal> <volume> 4 </volume> <pages> 98-107. </pages>
Reference-contexts: These assumptions are plausible, since they represent the closest continuous approximation to the usual training algorithms, in which training patterns are presented at random. They are needed for the approximation of the resulting deterministic gradient descent by a stochastic one <ref> (Intrator, 1990) </ref>. For this reason we use a learning rate that has to decay in time so that this approximation is valid. <p> Intrator and Cooper Objective Function Formulation of the BCM Theory 14 5 Analysis of the Fixed Points in High Dimensional Space In appendix A we show using a general result on random differential equations <ref> (Intrator, 1990) </ref> that the solution of the random differential equations remains as close as we like, in the L 2 sense, to the solution of the deterministic equations. We have shown in section 4 that the deterministic equation converges to a local minimum of the risk. <p> A general result which yields this connection is given in <ref> (Intrator, 1990) </ref> and will be discussed in the appendix.
Reference: <author> Intrator, N. and Gold, J. I. </author> <year> (1993). </year> <title> Three-dimensional object recognition of gray level images: The usefulness of distinguishing features. </title> <journal> Neural Computation, </journal> <volume> 5 </volume> <pages> 61-74. </pages>
Reference: <author> Intrator, N., Gold, J. I., Bulthoff, H. H., and Edelman, S. </author> <year> (1991). </year> <title> Three-dimensional object recognition using an unsupervised neural network: Understanding the distinguishing features. </title> <editor> In Feldman, Y. and Bruckstein, A., editors, </editor> <booktitle> Proceedings of the 8th Israeli Conference on AICV, </booktitle> <pages> pages 113-123. </pages> <publisher> Elsevier. </publisher>
Reference-contexts: Feature extraction based on this model have been applied to various real-world problems such as phoneme recognition of a small-speaker database (Intrator, 1992), multi-speaker phoneme recognition from the TIMIT database <ref> (Intrator and Tajchman, 1991) </ref> using the Lyon's cochlear model (Slaney, 1988), and 3D object recognition (Intrator and Gold, 1993; Intrator et al., 1991). We thus have the striking and possibly highly significant result that a biological neuron is performing a sophisticated statistical procedure.
Reference: <author> Intrator, N. and Tajchman, G. </author> <year> (1991). </year> <title> Supervised and unsupervised feature extraction from a cochlear model for speech recognition. </title> <editor> In Juang, B. H., Kung, S. Y., and Kamm, C. A., editors, </editor> <booktitle> Neural Networks for Signal Processing Proceedings of the 1991 IEEE Workshop, </booktitle> <pages> pages 460-469. </pages> <publisher> IEEE Press, </publisher> <address> New York, NY. </address>
Reference-contexts: Feature extraction based on this model have been applied to various real-world problems such as phoneme recognition of a small-speaker database (Intrator, 1992), multi-speaker phoneme recognition from the TIMIT database <ref> (Intrator and Tajchman, 1991) </ref> using the Lyon's cochlear model (Slaney, 1988), and 3D object recognition (Intrator and Gold, 1993; Intrator et al., 1991). We thus have the striking and possibly highly significant result that a biological neuron is performing a sophisticated statistical procedure.
Reference: <author> Jones, M. C. </author> <year> (1983). </year> <title> The projection pursuit algorithm for exploratory data analysis. </title> <type> Unpublished Ph.D. dissertation, </type> <institution> University of Bath, School of Mathematics. </institution>
Reference: <author> Jones, M. C. and Sibson, R. </author> <year> (1987). </year> <title> What is projection pursuit? (with discussion). </title> <journal> J. Roy. Statist. Soc., Ser. A(150):1-36. </journal>
Reference: <author> Kruskal, J. B. </author> <year> (1969). </year> <title> Toward a practical method which helps uncover the structure of the set of multivariate observations by finding the linear transformation which optimizes a new 'index of condensation'. </title> <editor> In Milton, R. C. and Nelder, J. A., editors, </editor> <booktitle> Statistical Computation, </booktitle> <pages> pages 427-440. </pages> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference: <author> Kruskal, J. B. </author> <year> (1972). </year> <title> Linear transformation of multivariate data to reveal clustering. In Shepard, </title> <editor> R. N., Romney, A. K., and Nerlove, S. B., editors, </editor> <title> Multidimensional Scaling: Theory and Application in the Behavioral Sciences, I, </title> <booktitle> Theory, </booktitle> <pages> pages 179-191. </pages> <publisher> Seminar Press, </publisher> <address> New York and London. </address>
Reference: <author> Linsker, R. </author> <year> (1988). </year> <title> Self-organization in a perceptual network. </title> <journal> IEEE. Computer, </journal> <volume> 88 </volume> <pages> 105-117. </pages>
Reference: <author> Miller, K. D., Keller, J., and Stryker, M. P. </author> <year> (1989). </year> <title> Ocular dominance column development: Analysis and simulation. </title> <journal> Science, </journal> <volume> 240 </volume> <pages> 605-615. </pages>
Reference: <author> Mower, G. D., Caplan, C. J., Christen, W. G., and Duffy, F. H. </author> <year> (1985). </year> <title> Dark rearing prolongs physiological but not anatomical plasticity of the cat visual cortex. </title> <journal> J. Comp. Neurol., </journal> <volume> 235 </volume> <pages> 448-466. </pages>
Reference-contexts: The OD shift after MD is the best known, and most intensively studied type of visual cortex plasticity. When MD is initiated late in the critical period (Presson and Gordon, 1982), or after a period of rearing in the dark <ref> (Mower et al., 1985) </ref>, it will induce clear changes in cortical OD without a corresponding anatomic change in the geniculocortical projections.
Reference: <author> Oja, E. </author> <year> (1982). </year> <title> A simplified neuron model as a principal component analyzer. </title> <journal> Math. Biology, </journal> <volume> 15 </volume> <pages> 267-273. </pages>
Reference: <author> Presson, J. and Gordon, B. </author> <year> (1982). </year> <title> The effects of monocular deprivation on the physiology and anatomy of the kitten's visual system. </title> <journal> Soc. Neurosci. Abstracts, 8:5. </journal> <volume> 10. </volume>
Reference-contexts: The OD shift after MD is the best known, and most intensively studied type of visual cortex plasticity. When MD is initiated late in the critical period <ref> (Presson and Gordon, 1982) </ref>, or after a period of rearing in the dark (Mower et al., 1985), it will induce clear changes in cortical OD without a corresponding anatomic change in the geniculocortical projections.
Reference: <author> Saul, A. and Daniels, J. D. </author> <year> (1986). </year> <title> Modeling and simulation I: Introduction and guidelines. </title> <journal> J. of Electrophysiological Techniques, </journal> <volume> 13 </volume> <pages> 95-109. </pages> <note> Intrator and Cooper Objective Function Formulation of the BCM Theory 24 Scofield, </note> <author> C. L. and Cooper, L. N. </author> <year> (1985). </year> <title> Development and properties of neural networks. </title> <journal> Contemp. Phys., </journal> 26:125-145. 
Reference: <author> Sebestyen, G. </author> <year> (1962). </year> <title> Decision Making Processes in Pattern Recognition. </title> <publisher> Macmillan, </publisher> <address> New York. </address>
Reference: <author> Sejnowski, T. J. </author> <year> (1977). </year> <title> Storing covariance with nonlinearly interacting neurons. </title> <journal> Journal of Mathematical Biology, </journal> <volume> 4 </volume> <pages> 303-321. </pages>
Reference: <author> Sherman, S. M. and Spear, P. D. </author> <year> (1982). </year> <title> Organization of visual pathways in normal and visually deprived cats. </title> <journal> Physiol. Rev., </journal> <volume> 62 </volume> <pages> 738-855. </pages>
Reference: <author> Slaney, M. </author> <year> (1988). </year> <title> Lyon's cochlear model. </title> <type> Technical report, </type> <institution> Apple Corporate Library, Cupertino, </institution> <address> CA 95014. </address>
Reference-contexts: Feature extraction based on this model have been applied to various real-world problems such as phoneme recognition of a small-speaker database (Intrator, 1992), multi-speaker phoneme recognition from the TIMIT database (Intrator and Tajchman, 1991) using the Lyon's cochlear model <ref> (Slaney, 1988) </ref>, and 3D object recognition (Intrator and Gold, 1993; Intrator et al., 1991). We thus have the striking and possibly highly significant result that a biological neuron is performing a sophisticated statistical procedure.
Reference: <author> Switzer, P. </author> <year> (1970). </year> <title> Numerical classification. </title> <editor> In Barnett, V., editor, Geostatistics. </editor> <publisher> Plenum Press, </publisher> <address> New York. </address> <publisher> von der Malsburg, </publisher> <address> C. </address> <year> (1973). </year> <title> Self-organization of orientation sensitivity cells in the striate cortex. </title> <journal> Kybernetik, </journal> <volume> 14 </volume> <pages> 85-100. </pages>
Reference: <author> Wiesel, T. N. and Hubel, D. H. </author> <year> (1965). </year> <title> Comparison of the effects of unilateral and bilateral eye closure on cortical unit responses in kittens. </title> <journal> J. Neurophysiol., </journal> <volume> 28 </volume> <pages> 1029-1040. </pages>
Reference-contexts: Second, although 7 days of MD during the second postnatal month leave few neurons in the striate cortex responsive to stimulation of the deprived eye, most cells remain responsive to stimulation through either eye after a comparable period of BD <ref> (Wiesel and Hubel, 1965) </ref>. Thus it is not merely the absence of patterned activity in the deprived geniculate projection that causes the decrease in synaptic efficacy after MD. The result of a reversed suture (RS) experiment is even more striking.
Reference: <author> Yang, X. and Faber, D. S. </author> <year> (1991). </year> <title> Initial synaptic efficacy influences induction and expression of long-term changes in transmission. </title> <booktitle> Proceedings of the National Academy of Science, </booktitle> <volume> 88(10) </volume> <pages> 4299-4303. </pages>
Reference-contexts: The gradient decent procedure is valid, provided that the risk is bounded from below (see Section 5). 2 Some indications of a moving threshold has been already found <ref> (Yang and Faber, 1991) </ref> Intrator and Cooper Objective Function Formulation of the BCM Theory 10 4.3 Extension to a Network with Feed-Forward Inhibition We now define a network with feed-forward inhibition.
References-found: 40

