URL: ftp://prospero.isi.edu/pub/papers/scale.ps.Z
Refering-URL: http://www.isi.edu/isi-technical-reports.html
Root-URL: http://www.isi.edu
Title: Scale in Distributed Systems  
Author: B. Clifford Neuman 
Affiliation: Information Sciences Institute University of Southern California  
Abstract: In recent years, scale has become a factor of increasing importance in the design of distributed systems. The scale of a system has three dimensions: numerical, geographical, and administrative. The numerical dimension consists of the number of users of the system, and the number of objects and services encompassed. The geographical dimension consists of the distance over which the system is scattered. The administrative dimension consists of the number of organizations that exert control over pieces of the system. The three dimensions of scale affect distributed systems in many ways. Among the affected components are naming, authentication, authorization, accounting, communication, the use of remote resources, and the mechanisms by which users view the system. Scale affects reliability: as a system scales numerically, the likelihood that some host will be down increases; as it scales geographically, the likelihood that all hosts can communicate will decrease. Scale also affects performance: its numerical component affects the load on the servers and the amount of communication; its geographic component affects communication latency. Administrative complexity is also affected by scale: administration becomes more difficult as changes become more frequent and as they require the interaction of different administrative entities, possibly with conflicting policies. Finally, scale affects heterogeneity: as the size of a system grows it becomes less likely that all pieces will be identical. This paper looks at scale and how it affects distributed systems. Approaches taken by existing systems are examined and their common aspects highlighted. The limits of scalability in these systems are discussed. A set of principles for scalable systems is presented along with a list of questions to be asked when considering how far a system scales. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> David P. Anderson and Domenico Ferrari. </author> <title> The Dash project: An overview. </title> <type> Technical Report 88/405, </type> <institution> Computer Science Division, Department of Electrical Engineering and Computer Science, University of California at Berkeley, </institution> <month> August </month> <year> 1988. </year>
Reference-contexts: Approaches which might seem reasonable given a low latency connection might not be reasonable across a satellite link. Because they can greatly affect the usability of a system, the underlying communications parameters must not be completely hidden from the application. The Dash system <ref> [1] </ref> does a 11 good job at exposing the communication pa-rameters in an appropriate manner. When a connection is established, it is possible for the application to require that the connection meet certain requirements. If the requirements are not met, an error is returned. <p> Dash is notable for exposing these characteristics by allowing the application to require that the connection meet certain requirements and returning an error if those requirements cannot be met. <ref> [1] </ref> DEC's Global Naming System, developed at at DEC's Systems Research Center, was designed to support naming in large networks spanning multiple organizations.
Reference: [2] <author> Andrew D. Birrell, Butler W. Lamp-son, Roger M. Needham, and Michael D. Schroeder. </author> <title> A global authentication service without global trust. </title> <booktitle> In Proceedings of the IEEE Symposium on Security and Privacy, </booktitle> <pages> pages 223-230, </pages> <month> April </month> <year> 1986. </year>
Reference-contexts: The initial version of Kerberos only supported single-hop cross-realm authentication. This re quired that each realm had to know about every other realm with which it was to communicate. This limitation does not exist in Version 5 of Kerberos, or in DEC's global authentication system <ref> [2] </ref>. With multiple-hop cross-realm authentication, what is known after a client has been authenticated may be as weak as "the local AS claims that a remote AS claims that another AS has authenticated the client as A". <p> DEC's Global Authentication System is notable for the fact that a principal's name is not absolute, but is instead determined by the sequence of authentication servers used to authenticate the principal. <ref> [2, 11, 14] </ref> Grapevine was one of the earliest distributed systems designed to scale to a large network.
Reference: [3] <author> Andrew D. Birrell, Roy Levin, Roger M. Needham, and Michael D. Schroeder. Grapevine: </author> <title> An exercise in distributed computing. </title> <journal> Communications of the ACM, </journal> <volume> 25(4) </volume> <pages> 260-274, </pages> <month> April </month> <year> 1982. </year>
Reference-contexts: Few systems provide for accounting in a distributed manner. 5.1 Authentication Several techniques are used to authenticate users in distributed systems. The simplest, the use of passwords on each host, requires maintenance of a password database on multiple nodes. To make it easier to administer, Grapevine <ref> [3] </ref> supported a central service to verify passwords. Password-based authentication can be cumbersome if the user is required to present a password each time a new service is requested. Unfortunately, letting the workstation remember the users password is risky. <p> It was developed at Xerox PARC to support electronic mail, to provide a name service for the location of network services, and to support simple password-based authentication on a world-wide network connecting Xerox sites. <ref> [3, 27] </ref> The Heterogeneous Computer Systems Project at the University of Washington demonstrated that a single interface could be used to communicate with systems using different underlying protocols and data representations.
Reference: [4] <author> Luis-Felipe Cabrera and Jim Wyllie. </author> <title> QuickSilver distributed file services: An architecture for horizontal growth. </title> <booktitle> In Proceedings of the 2nd IEEE Conference on Computer Workstations, </booktitle> <pages> pages 23-27, </pages> <month> March </month> <year> 1988. </year> <note> Also IBM Research Report RJ 5578, </note> <month> April </month> <year> 1987. </year>
Reference-contexts: Hints don't have to be kept consistent; if out of date, that fact will 18 be detected when the data is used and the en-try can be flushed. Grapevine and QuickSilver <ref> [4] </ref> both use hints. Hints are useful in naming systems if an objects identifier can be stored along with the object itself. The cached data tells where the object can be found, but if the object has moved, that fact will be apparent when the client attempts to retrieve it. <p> The solution is to allow individual users to customize their name space so that they see only the objects that are of interest. This approach is taken in Plan 9 [24], Prospero [20], Tilde [7], and QuickSilver <ref> [4] </ref>. Naming in these systems is often described as user-centered though, with the exception of Prospero, it might better be described as user-exclusive; an object must be added to the user's name space before it can be named. <p> In a system spanning a large, multi-national corporation, such a name space allows users to see only those parts of the system that concern them. <ref> [4] </ref> Sprite, a network operating system developed at Berkeley, was designed for use across a local area network.
Reference: [5] <author> CCITT. </author> <title> Recommendation X.500: The Directory, </title> <month> December </month> <year> 1988. </year>
Reference-contexts: As discussed in Section 6.1, this approach does not scale beyond a local network. In fact, most of the systems that use this approach provide a secondary name resolution mechanism to be used when a broadcast goes unanswered. Distribution in Grapevine, IDNS, and X.500 <ref> [5] </ref> is domain-based. Like the other techniques described, the distribution function in domain-based naming is based on a prefix of the name to be resolved. Names are divided into multiple components. <p> Scalability is addressed in largely the same manner as in the Internet Domain Name Service. <ref> [5] </ref> 25 26
Reference: [6] <author> George A. Champine, Daniel E. Geer Jr., and William N. Ruh. </author> <title> Project athena as a distributed computer system. </title> <journal> IEEE Computer, </journal> <volume> 23(9) </volume> <pages> 40-51, </pages> <month> September </month> <year> 1990. </year>
Reference-contexts: Still looser is coherence at the protocol level: all nodes are required to support a common set of protocols, and these protocols define the interfaces to the subsystems which tie the system together. MIT's Project Athena <ref> [6] </ref> is an example of a system that uses coherence (of the execution abstraction) to deal with heterogeneity. The Heterogeneous Computer Systems Project [21] provides explicit support for heterogeneity. A mechanism is provided that allows the use of a single interface when communicating with nodes that use different underlying protocols. <p> Distributed services provide authentication, naming, filing, printing, mail and administrative functions. Kerberos was developed as part of Project Athena. <ref> [6] </ref> Dash, under development at Berkeley, is a distributed operating system designed for use across large networks exhibiting a range of transmission characteristics.
Reference: [7] <author> Douglas Comer, Ralph E. Droms, and Thomas P. Murtagh. </author> <title> An experimental implementation of the Tilde naming system. </title> <journal> Computing Systems, </journal> <volume> 4(3) </volume> <pages> 487-515, </pages> <month> Fall </month> <year> 1990. </year>
Reference-contexts: The solution is to allow individual users to customize their name space so that they see only the objects that are of interest. This approach is taken in Plan 9 [24], Prospero [20], Tilde <ref> [7] </ref>, and QuickSilver [4]. Naming in these systems is often described as user-centered though, with the exception of Prospero, it might better be described as user-exclusive; an object must be added to the user's name space before it can be named. <p> This ability provides applications with the advantages of a global name space for those file names that should be resolved globally, while allowing parts of the name space to be specified locally for file names which would be better resolved to local files. <ref> [7] </ref> X.500 is an ISO standard describing a distributed directory service that is designed to store information about users, organizations, resources, and similar entities worldwide. Scalability is addressed in largely the same manner as in the Internet Domain Name Service. [5] 25 26
Reference: [8] <author> Robert J. Fowler. </author> <title> Decentralized Object Finding Using Forwarding Addresses. </title> <type> PhD thesis, </type> <institution> University of Washington, Decem-ber 1985. Department of Computer Science technical report 85-12-1. </institution>
Reference-contexts: Since the UIDs are scattered about without any way to find them all, they might continue to exist with incorrect addresses for the objects they reference. A technique often used to solve this problem is forwarding pointers <ref> [8] </ref>. With forwarding pointers, a user attempting to use an old address to access an object is given a new UID containing the new address. A drawback to forwarding pointers is that the chain of links to be followed can become lengthy.
Reference: [9] <author> David K. Gifford. </author> <title> Weighted voting for replicated data. </title> <booktitle> In Proceedings of the 7th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 150-159, </pages> <month> December </month> <year> 1979. </year> <title> Pacific Grove, </title> <address> California. </address>
Reference-contexts: Maintaining a consistent view of replicated data does not require that all replicas are up-to-date. It only requires that the up-to-date information is always visible to the users of the data. In the mechanisms described so far, updates eventually make it to every replica. In quorum-consensus, or voting <ref> [9] </ref>, updates may be sent to a subset replicas. A consistent view is maintained by requiring that all reads are directed to at least one replica that is up-to-date.
Reference: [10] <author> Cary G. Gray and David R. Cheriton. Leases: </author> <title> An efficient fault-tolerant mechanism for distributed file cache consistency. </title> <booktitle> In Proceedings of the 12th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 202-210, </pages> <month> December </month> <year> 1989. </year>
Reference-contexts: By requiring that clients check the validity of files when they reboot (or if contact with the file server has been lost), problems due to lost callbacks can be minimized. Leases <ref> [10] </ref> are similar to callbacks, but there are several important differences. A lease eventually expires, and a server granting a lease guarantees that it will not make a change during the period the lease is valid unless it first gets approval from the lease holder.
Reference: [11] <author> Andy Hisgen, Andrew Birrell, Timothy Mann, Michael Schroeder, and Garret Swart. </author> <title> Availability and consistency tradeoffs in the Echo distributed file system. </title> <booktitle> In Proceedings of the 2nd IEEE Workshop on Workstation Operating Systems, </booktitle> <pages> pages 49-54, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: A final difficulty is that a client might fail during an update, resulting in its receipt by only some of the replicas. In primary-site replication, all updates are directed to a primary replica which then forwards the updates to the others. Updates may be forwarded individually, as in Echo <ref> [11] </ref>, or the whole database might be periodically downloaded by the replicas as in Kerberos [29] and the Berkeley Internet Domain Naming system (BIND) [31], an implementation of IDNS [15]. <p> DEC's Global Authentication System is notable for the fact that a principal's name is not absolute, but is instead determined by the sequence of authentication servers used to authenticate the principal. <ref> [2, 11, 14] </ref> Grapevine was one of the earliest distributed systems designed to scale to a large network.
Reference: [12] <author> John H. Howard, Michael L. Kazar, Sherri G. Menees, David A. Nichols, M. Satyanarayanan, Robert N. Side-botham, and Michael J. West. </author> <title> Scale and performance in a distributed file system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(1) </volume> <pages> 51-81, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: The server knows the most about the request and is in the best position to decide whether it should be allowed. For example, in the Andrew file system <ref> [12] </ref> each directory has an associated list, known as an access control list (ACL), identifying the users authorized to access the files within the directory. When access to a file is requested, the client's name is compared with those in the ACL. <p> An issue of importance when caching files is the size of the chunks to be cached. Most systems cache pieces of files. This is appropriate when only parts of a file are read. Coda [26] and early versions of the Andrew File System <ref> [12] </ref> support whole file caching, in which the entire file is transferred to the client's workstation when opened. Files that are modified are copied back when closed. Files remain cached on the workstation between opens so that a subsequent open does not require the file to be fetched again. <p> For small amounts of data, the cost of doing so is the same as if the information were not cached at all. For larger amounts of data, the check takes significantly less time than transferring the data itself. The Andrew File System <ref> [12] </ref> originally used this form of check-on-use to decide if a locally cached copy of a file could be used. Experience showed that the checks were the primary bottleneck, and that, in the common case, the files were unchanged. For this reason, the next implementation (and subsequently Coda) used callbacks. <p> Its most notable component is the An-drew File System which now ties together file systems at sites distributed across the United States. Coda is a follow-on to Andrew, improving availability, especially in the face of network partitions. <ref> [12, 26] </ref> MIT's Project Athena is a system built from thousands of computers distributed across campus. Distributed services provide authentication, naming, filing, printing, mail and administrative functions.
Reference: [13] <author> Butler W. Lampson. </author> <title> Hints for computer system design. </title> <booktitle> In Proceedings of the 9th ACM Symposium on Operating System Principles, </booktitle> <pages> pages 33-48, </pages> <year> 1983. </year>
Reference-contexts: The hints are broken into groups corresponding to the primary techniques of replication, distribution and caching. When building systems it is important to consider factors other than scalability. An excellent collection of hints on the general design of computer systems is presented by Lampson in <ref> [13] </ref>. 11.1 Replication Replicate important resources. Replication increases availability and allows requests to be spread across multiple servers, thus reducing the load on each. Distribute the replicas. Placing replicas in different parts of the network improves availability during network partitions.
Reference: [14] <author> Butler W. Lampson. </author> <title> Designing a global name service. </title> <booktitle> In Proceedings of the 4th ACM Symposium on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1985. </year>
Reference-contexts: This causes problems for any names which were hardcoded in programs or otherwise specified before the change. DEC's Global Name Service <ref> [14] </ref> addresses this problem by associating a unique number with the root of every independent name space. 6 When a file name is stored, the number for the root of the name space can be stored along with the name. <p> DEC's Global Authentication System is notable for the fact that a principal's name is not absolute, but is instead determined by the sequence of authentication servers used to authenticate the principal. <ref> [2, 11, 14] </ref> Grapevine was one of the earliest distributed systems designed to scale to a large network.
Reference: [15] <author> Paul Mockapetris. </author> <title> Domain names concepts and facilities. DARPA Internet RFC 1034, </title> <month> November </month> <year> 1987. </year> <month> 27 </month>
Reference-contexts: Updates may be forwarded individually, as in Echo [11], or the whole database might be periodically downloaded by the replicas as in Kerberos [29] and the Berkeley Internet Domain Naming system (BIND) [31], an implementation of IDNS <ref> [15] </ref>. The advantage of the primary-site approach is that the ordering of updates is determined by the order in which they are received at the primary site, and updates only require the availability of the primary site. <p> Each organization maintains replicated servers supporting the translation of names for its own part of the name space. <ref> [15, 31] </ref> Kerberos is an encryption-based network authentication system, developed by MIT's Project Athena, which supports authentication of users both locally, and across organizational boundaries. [29] Locus, developed at the UCLA, was designed to run on systems distributed across a local-area network.
Reference: [16] <author> S. J. Mullender and A. S. Tanenbaum. </author> <title> The design of a capability-based distributed operating system. </title> <journal> The Computer Journal, </journal> <volume> 29(4) </volume> <pages> 289-299, </pages> <year> 1986. </year>
Reference-contexts: There is a need for distributed, secure, and scalable accounting mechanism, especially in large systems that cross administrative boundaries. To date, few systems have even considered the problem. The difficulty lies in the inability to trust servers run by unknown individuals or organizations. The bank server <ref> [16] </ref> and accounting based on proxies [19] are among the few approaches that have been described. In Amoeba, accounting is handled by bank servers which maintain accounts on behalf of users and servers. Users transfer money to servers, which then draw upon the balance as resources are used. <p> Objects are referenced by capabilities which include identifiers for the server and object, and access rights for the object. The capabilities provide both a distributed naming and authorization mechanism. <ref> [16, 30] </ref> The Andrew system, developed at Carnegie-Mellon University, runs on thousands of computers distributed across the university campus. Its most notable component is the An-drew File System which now ties together file systems at sites distributed across the United States.
Reference: [17] <author> Roger M. Needham and Michael D. Schroeder. </author> <title> Using encryption for authentication in large networks of computers. </title> <journal> Communication of the ACM, </journal> <volume> 21(12) </volume> <pages> 993-999, </pages> <month> December </month> <year> 1978. </year>
Reference-contexts: Principals (users and servers) must maintain a key for use with every other principal with which they might possibly communicate. This is impractical in large systems. Altogether, (n x m) keys are required where n is the number of users, and m the number of servers. In <ref> [17] </ref> Needham and Schroeder show how the number of keys to be maintained can be reduced through the use of an authentication server (AS). An AS securely generates keys as they are needed and distributes them to the parties wishing to communicate.
Reference: [18] <author> B. Clifford Neuman. </author> <title> Issues of scale in large distributed operating systems. </title> <type> Generals Report, </type> <institution> Department of Computer Science, University of Washington, </institution> <month> May </month> <year> 1988. </year>
Reference: [19] <author> B. Clifford Neuman. </author> <title> Proxy-based authorization and accounting for distributed systems. </title> <type> Technical Report 91-02-01, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <month> March </month> <year> 1991. </year>
Reference-contexts: The difference from capabilities is that these credentials might only be usable by a particular user, or they might require further proof that they were really issued to the user presenting them. Version 5 of Kerberos supports such credentials. Their use is described separately in <ref> [19] </ref>. 5.2.1 Capabilities The approaches discussed so far have been based on an access control list model for authorization. <p> To date, few systems have even considered the problem. The difficulty lies in the inability to trust servers run by unknown individuals or organizations. The bank server [16] and accounting based on proxies <ref> [19] </ref> are among the few approaches that have been described. In Amoeba, accounting is handled by bank servers which maintain accounts on behalf of users and servers. Users transfer money to servers, which then draw upon the balance as resources are used.
Reference: [20] <author> B. Clifford Neuman. </author> <title> The Prospero File System: A global file system based on the Virtual System Model. </title> <booktitle> In Proceedings of the Workshop on File Systems, </booktitle> <month> May </month> <year> 1992. </year>
Reference-contexts: This drawback is solved in Emerald by requiring that each object have a home site and that the forwarding pointer at that site is kept up to date. Another solution is for the client to update the forwarding pointers traversed if subsequent forwarding pointers are encountered. Prospero <ref> [20] </ref> supports UIDs with expiration dates. Its directory service guarantees that the UIDs it maintains are kept up-to-date. <p> The solution is to allow individual users to customize their name space so that they see only the objects that are of interest. This approach is taken in Plan 9 [24], Prospero <ref> [20] </ref>, Tilde [7], and QuickSilver [4]. Naming in these systems is often described as user-centered though, with the exception of Prospero, it might better be described as user-exclusive; an object must be added to the user's name space before it can be named. <p> It supports an object-centered view of the entire system, allowing users to define their own virtual system by specifying the pieces of the global system that are of interest. Prospero's support for closure resolves the problems caused by the use of multiple name spaces. <ref> [20] </ref> QuickSilver, developed at IBM's Almaden Research Center, is notable for its proposed use of a user-centered 3 name space.
Reference: [21] <author> David Notkin, Andrew P. Black, Edward D. Lazowska, Henry M. Levy, Jan Sanislo, and John Zahorjan. </author> <title> Interconnecting heterogeneous computer systems. </title> <journal> Communications of the ACM, </journal> <volume> 31(3) </volume> <pages> 258-273, </pages> <month> March </month> <year> 1988. </year>
Reference-contexts: MIT's Project Athena [6] is an example of a system that uses coherence (of the execution abstraction) to deal with heterogeneity. The Heterogeneous Computer Systems Project <ref> [21] </ref> provides explicit support for heterogeneity. A mechanism is provided that allows the use of a single interface when communicating with nodes that use different underlying protocols. The HCS approach shows that it is possible to support multiple mechanisms in heterogeneous systems. <p> This is important for large systems when it is not practical to dictate the choice of hardware and software across multiple sites, or when the underlying mechanisms have different strengths and weaknesses. <ref> [21] </ref> 24 The Internet Domain Naming System (IDNS) is a distributed name service, running on the Internet, supporting the translation of host names to Internet addresses and mail forwarders.
Reference: [22] <author> John K. Ousterhout, Andrew R. Cheren-son, Frederick Douglis, Michael N. Nelson, and Brent B. Welch. </author> <title> The Sprite network operating system. </title> <journal> Computer, </journal> <volume> 21(2) </volume> <pages> 23-35, </pages> <month> February </month> <year> 1988. </year>
Reference-contexts: A few name servers name individual files. There are a huge number of files and they are often transient in nature. Supporting naming at this level requires support for frequent updates and a massive number of queries. 4 An intermediate approach is used by Sprite <ref> [22] </ref> and a number of other file systems. Groups of objects sharing a common prefix are assigned to servers. The name service maps the prefix to the server, and the remainder of the name is resolved locally by the server on which the object is stored. <p> For domain names it is really the suffix. 15 ent systems. Locus supports a uniform name space by keeping the mount table the same on all systems. In Plan 9, the table is maintained on a per-process basis. Broadcast is used by Sprite <ref> [22] </ref> to identify the server on which a particular file can be found. The client broadcasts a request, and the server with the file replies. The reply includes the prefix for the files maintained by the server. <p> Caching is usually performed by the client, eliminating repeated requests to network services. Caching can also take place on the servers implementing those services. For example, in addition to caching on the workstation, Sprite <ref> [22] </ref> caches blocks in the memory of the file server. Reading a file from the memory cached copy on the file server is often faster than reading it from the client's local disk. <p> Its file system is notable for its use of caching on both the client and the server to improve performance, and for its use of prefix tables to distribute requests to the correct file server. <ref> [22] </ref> The Tilde naming system, developed at Pur-due, supports process-centered 3 naming. This allows one to specify, on a per-process basis, how names will map to pieces of the global system.
Reference: [23] <author> Larry L. Peterson. </author> <title> The Profile naming service. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 6(4) </volume> <pages> 341-364, </pages> <month> November </month> <year> 1988. </year>
Reference-contexts: Names are normally resolved within the name space associated with the object in which the name is found. A few systems have looked at mechanisms for identifying objects that are needed when the object's full name is not known. Profile <ref> [23] </ref> supports attribute-based naming. In attribute-based naming, the user specifies known attributes of an object instead of its name. To be used in place of a name, enough attributes must specified to uniquely identify the object. In order to scale, information must be distributed across multiple name servers. <p> University of Ari-zona, is an attribute-based name service that maps possibly incomplete information about coarse-grained objects on a large network to 3 Perhaps better described as processor user-exclusive since objects must first be added to the user's name space before they can be named. the object (s) matching that information. <ref> [23] </ref> Prospero, developed at the University of Washington, runs on systems distributed across the Internet. It supports an object-centered view of the entire system, allowing users to define their own virtual system by specifying the pieces of the global system that are of interest.
Reference: [24] <author> D. Presotto, R. Pike, K. Thompson, and H. Trickey. </author> <title> Plan 9: A distributed system. </title> <booktitle> In Proceedings of Spring 1991 Eu-rOpen, </booktitle> <month> May </month> <year> 1991. </year>
Reference-contexts: The methods most frequently used are mounts, broadcast and domain-based queries. Sun's Network File System [25], Locus [32], and Plan 9 <ref> [24] </ref> use a mount table to identify the server on which a a named object resides. The system maintains a table mapping name prefixes to servers. When an object is referenced, the name is looked up in the mount table, and the request is forwarded to the appropriate server. <p> The solution is to allow individual users to customize their name space so that they see only the objects that are of interest. This approach is taken in Plan 9 <ref> [24] </ref>, Prospero [20], Tilde [7], and QuickSilver [4]. Naming in these systems is often described as user-centered though, with the exception of Prospero, it might better be described as user-exclusive; an object must be added to the user's name space before it can be named. <p> The NFS server maintains very little information (state) about the clients that use it. [25] Plan 9 from Bell Labs, intended for use by a large corporation, supports a process-centered 3 name space, allowing users to incorporate into their name space those parts of the global system that are useful. <ref> [24] </ref> Profile, developed at the University of Ari-zona, is an attribute-based name service that maps possibly incomplete information about coarse-grained objects on a large network to 3 Perhaps better described as processor user-exclusive since objects must first be added to the user's name space before they can be named. the object
Reference: [25] <author> R. Sandberg, D. Goldberg, S. Kleiman, D. Walsh, and B. Lyon. </author> <title> Design and implementation of the Sun Network File System. </title> <booktitle> In Proceedings of the Summer 1985 Usenix Conference, </booktitle> <pages> pages 119-130, </pages> <month> June </month> <year> 1985. </year>
Reference-contexts: Hierarchical name spaces make the task easier since names with common prefixes are often stored together 2 , but it is still necessary to identify the server maintaining that part of the name space. The methods most frequently used are mounts, broadcast and domain-based queries. Sun's Network File System <ref> [25] </ref>, Locus [32], and Plan 9 [24] use a mount table to identify the server on which a a named object resides. The system maintains a table mapping name prefixes to servers. <p> The NFS server maintains very little information (state) about the clients that use it. <ref> [25] </ref> Plan 9 from Bell Labs, intended for use by a large corporation, supports a process-centered 3 name space, allowing users to incorporate into their name space those parts of the global system that are useful. [24] Profile, developed at the University of Ari-zona, is an attribute-based name service that maps
Reference: [26] <author> Mahadev Satyanarayanan. </author> <title> Scalable, secure, and highly available distributed file access. </title> <journal> IEEE Computer, </journal> <volume> 23(5) </volume> <pages> 9-21, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Mechanisms to maintain the consistency of caches are described in Section 9. An issue of importance when caching files is the size of the chunks to be cached. Most systems cache pieces of files. This is appropriate when only parts of a file are read. Coda <ref> [26] </ref> and early versions of the Andrew File System [12] support whole file caching, in which the entire file is transferred to the client's workstation when opened. Files that are modified are copied back when closed. <p> Its most notable component is the An-drew File System which now ties together file systems at sites distributed across the United States. Coda is a follow-on to Andrew, improving availability, especially in the face of network partitions. <ref> [12, 26] </ref> MIT's Project Athena is a system built from thousands of computers distributed across campus. Distributed services provide authentication, naming, filing, printing, mail and administrative functions.
Reference: [27] <author> Michael D. Schroeder, Andrew D. Birrell, and Roger M. Needham. </author> <title> Experience with Grapevine: The growth of a distributed system. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 2(1) </volume> <pages> 3-23, </pages> <month> February </month> <year> 1984. </year>
Reference-contexts: The name server recursively checks the group for membership by the individual. If necessary, recursive queries can be sent to other name servers. One of the most noticeable bottlenecks in Grapevine was the time required to check membership in large groups, especially when other name servers were involved. <ref> [27] </ref> External information can be made available to a server without the need for it to contact another service. The client can request cryptographically sealed credentials either authorizing its access to a particular object or verifying its membership in a particular group. <p> It was developed at Xerox PARC to support electronic mail, to provide a name service for the location of network services, and to support simple password-based authentication on a world-wide network connecting Xerox sites. <ref> [3, 27] </ref> The Heterogeneous Computer Systems Project at the University of Washington demonstrated that a single interface could be used to communicate with systems using different underlying protocols and data representations.
Reference: [28] <author> M. F. Schwartz. </author> <title> The networked resource discovery project. </title> <booktitle> In Proceedings of the IFIP XI World Congress, </booktitle> <pages> pages 827-832, </pages> <month> August </month> <year> 1989. </year> <note> San Francisco. </note>
Reference-contexts: The key difference is that the links do not necessarily form a hierarchy. Alternative approaches are being examined by the Resource Discovery Project at the University of Colorado. These approaches use information already available over the network. In one approach, resource discovery agents <ref> [28] </ref> collect and share information with other agents scattered across the system. A user wishing to find a resource asks one of these agents, and the agents route queries among themselves, exploiting the semantics of the query to limit the activity that must take place.
Reference: [29] <author> J. G. Steiner, B. C. Neuman, and J. I. Schiller. </author> <title> Kerberos: An authentication service for open network systems. </title> <booktitle> In Proceedings of the Winter 1988 Usenix Conference, </booktitle> <pages> pages 191-201, </pages> <month> February </month> <year> 1988. </year> <note> Dal-las, Texas. </note>
Reference-contexts: An AS securely generates keys as they are needed and distributes them to the parties wishing to communicate. Each party 7 shares a key (or key pair) with the AS. Authentication in Kerberos <ref> [29] </ref> is based on a modified version of the Needham and Schroeder protocol (Figure 1). When a client wishes to communicate with a server it contacts the AS, sending its own name and the name of the server to be contacted (1). <p> In primary-site replication, all updates are directed to a primary replica which then forwards the updates to the others. Updates may be forwarded individually, as in Echo [11], or the whole database might be periodically downloaded by the replicas as in Kerberos <ref> [29] </ref> and the Berkeley Internet Domain Naming system (BIND) [31], an implementation of IDNS [15]. <p> Each organization maintains replicated servers supporting the translation of names for its own part of the name space. [15, 31] Kerberos is an encryption-based network authentication system, developed by MIT's Project Athena, which supports authentication of users both locally, and across organizational boundaries. <ref> [29] </ref> Locus, developed at the UCLA, was designed to run on systems distributed across a local-area network.
Reference: [30] <author> Andrew S. Tanenbaum, Robbert van Re-nesse, Hans van Staveren, Gregory J. Sharp, Sape J. Mullender, Jack Jansen, and Guido van Rossum. </author> <title> Experience with the Amoeba distributed operating system. </title> <journal> Communications of the ACM, </journal> <volume> 33(12) </volume> <pages> 47-63, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: Caching is described in greater detail in Section 9. 4.3 UID-Based Naming Not all distributed systems use a hierarchical name service like those that have been described. Some systems use unique identifiers to name objects. Capability-based systems such as Amoeba <ref> [30] </ref> fall into this category. A capability is a unique identifier that both names and grants access rights for an object. Unique IDs may be thought of as addresses. They usually contain information identifying the server 5 that maintains the object, and an identifier to be interpreted by the server. <p> The advantages of the access control list model are that it leaves the final decision with the server itself, and that it is straightforward to revoke access should that be required. Amoeba <ref> [30] </ref> uses the capability model for authorization. In the capability model, the user maintains the list of the objects for which access is authorized. Each object is represented by a capability which, when presented to a server, grants the bearer access to the ob 9 ject. <p> Local communications in one part of a network is not seen by users in another. When messages are broadcast globally, they are transmitted on all sub-nets, consuming available bandwidth on each. Although global broadcast should be avoided in scalable systems, broadcast need not be ruled out entirely. Amoeba <ref> [30] </ref> uses broadcast on its subnets to improve the performance of local operations. Communications beyond the local subnet uses point-to-point communication. Multicast, a broadcast-like mechanism, can also be used. In multicast, a single message can be sent to a group of servers. <p> Objects are referenced by capabilities which include identifiers for the server and object, and access rights for the object. The capabilities provide both a distributed naming and authorization mechanism. <ref> [16, 30] </ref> The Andrew system, developed at Carnegie-Mellon University, runs on thousands of computers distributed across the university campus. Its most notable component is the An-drew File System which now ties together file systems at sites distributed across the United States.
Reference: [31] <author> Douglas B. Terry, Mark Painter, David W. Riggle, and Songnian Zhou. </author> <title> The Berkeley internet domain server. </title> <booktitle> In Proceedings of the 1984 Usenix Summer Conference, </booktitle> <pages> pages 23-31, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: Updates may be forwarded individually, as in Echo [11], or the whole database might be periodically downloaded by the replicas as in Kerberos [29] and the Berkeley Internet Domain Naming system (BIND) <ref> [31] </ref>, an implementation of IDNS [15]. The advantage of the primary-site approach is that the ordering of updates is determined by the order in which they are received at the primary site, and updates only require the availability of the primary site. <p> Most name servers unable to answer to a query will return the address of the name server sharing the longest prefix in common with the name being resolved. In many cases, that might be the name server for the root. BIND <ref> [31] </ref> may be configured so that a local name server makes queries on behalf of the client and caches the response (and any intermediate responses) for use by other local clients. <p> Each organization maintains replicated servers supporting the translation of names for its own part of the name space. <ref> [15, 31] </ref> Kerberos is an encryption-based network authentication system, developed by MIT's Project Athena, which supports authentication of users both locally, and across organizational boundaries. [29] Locus, developed at the UCLA, was designed to run on systems distributed across a local-area network.
Reference: [32] <author> B. Walker, G. Popek, R. English, C. Kline, and G. Thiel. </author> <title> The Locus distributed operating system. </title> <booktitle> In Proceedings of the 9th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 49-70, </pages> <month> October </month> <year> 1983. </year> <month> 28 </month>
Reference-contexts: The methods most frequently used are mounts, broadcast and domain-based queries. Sun's Network File System [25], Locus <ref> [32] </ref>, and Plan 9 [24] use a mount table to identify the server on which a a named object resides. The system maintains a table mapping name prefixes to servers. <p> Locus is notable as one of the earliest distributed systems to support a uniform view of the file system across all nodes in the system. <ref> [32] </ref> SUN's Network File System supports transparent access to files stored on remote hosts. Files are named independently on each host.
References-found: 32

