URL: http://www.cs.ucsb.edu/~acha/publications/icdcs98-submitted.ps.gz
Refering-URL: http://www.cs.ucsb.edu/~acha/publications/icdcs98-submitted.html
Root-URL: http://www.cs.ucsb.edu
Email: mranga@snad.ncsl.nist.gov, acha@cs.ucsb.edu, saltz@cs.umd.edu  
Title: Adapting to Bandwidth Variations in Wide-Area Data Combination  
Author: M.Ranganathan yx Anurag Acharya zy Joel Saltz 
Address: Gaithersburg, MD  
Affiliation: Department of Computer Science Department of Computer Science University of Maryland, College Park University of California, Santa Barbara National Institute of Standards and Technology,  
Abstract: Efficient data combination over wide-area networks is hard as wide-area networks have large variations in available network bandwidth. In this paper, we examine the utility of changing the location of combination operators as a technique to adapt to variations in wide-area network bandwidth. We try to answer the following questions. First, does relocation of operators provide a significant performance improvement? Second, is on-line relocation useful or does a one-time positioning at start-up time provide most if not all the benefits? If on-line relocation is useful, how frequently should it be done and is global knowledge of network performance required or can local knowledge and local relocation of operators sufficient? Fourth, does the effectiveness of operator relocation depend on the ordering of the combination operations. That is, are certain ways of ordering more amenable to adaptation than others? Finally, how do the results change as the number of data sources changes?
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Acharya, M. Ranganathan, and J. Saltz. Sumatra: </author> <title> A Language for Resource-Aware Mobile Programs, </title> <booktitle> chapter _ Springer Verlag Lecture Notes in Computer Science, </booktitle> <year> 1997. </year> <editor> J. Vitek and C. </editor> <publisher> Tschudin (eds). </publisher>
Reference-contexts: The mobility support can be provided by mobile object systems like Sumatra <ref> [1, 14] </ref>, Aglets [11], Mole [17] or Telescript [18].
Reference: [2] <author> A. Acharya, M. Uysal, R. Bennett, A. Mendelson, M. Beynon, J. Hollingsworth, J. Saltz, and A. Sussman. </author> <title> Tuning the performance of I/O intensive parallel applications. </title> <booktitle> In Proceedings of the 4th Workshop on Input/Output in Parallel and Distributed Systems, </booktitle> <pages> pages 15-27, </pages> <month> May </month> <year> 1996. </year>
Reference-contexts: Corresponding images from all participating servers are composed and a sequence of 180 images is delivered to the client. The composition operations are arranged as a complete binary tree. This application is based on the AVHRR Pathfinder program used by NASA Goddard to process data from the NOAA satellites <ref> [2] </ref>. We implemented a detailed discrete event simulation of the system using CSIM [12]. The simulation models the complete protocol and includes the effects of end-point congestion, message buffering and message startup cost, retrieval of images from disk, image composition and transmission delays.
Reference: [3] <author> L. Amsaleg, M. Franklin, A. Tomasic, and T. Urhan. </author> <title> Scrambling Query Plans to Cope With Unexpected Delays. </title> <booktitle> In Proceedings of the Fourth International Conference on Parallel and Distributed Information Systems, </booktitle> <month> December </month> <year> 1996. </year>
Reference-contexts: Changing the order of combination operations 1 can adapt to transient bandwidth variations between the data sources and the site of a combination operator by delaying the operator till network performance between its location and the corresponding data sources improves. An example of this is query-scrambling <ref> [3] </ref> which tries to hide initial delay in data arrival as well as bursty data rates by reordering relational join operations. <p> The primary technique, similar to the one-shot algorithm proposed in this paper, determines suitable locations for various operators at query startup time. The amount of memory available is assumed to not change for the duration of the query. Amsaleg and Franklin <ref> [3] </ref> have proposed query scrambling to deal with unexpected delays in data arrival in a wide-area environment. The primary technique, once again, is to reorder the query plan. They did not consider relocation of operators. Various scheduling heuristics for task graphs have been proposed [4, 16, 20, 21].
Reference: [4] <author> F. Anger, J. Hwang, and Y. Chow. </author> <title> Scheduling with sufficiently loosely-coupled processors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 9 </volume> <pages> 87-92, </pages> <year> 1990. </year>
Reference-contexts: Amsaleg and Franklin [3] have proposed query scrambling to deal with unexpected delays in data arrival in a wide-area environment. The primary technique, once again, is to reorder the query plan. They did not consider relocation of operators. Various scheduling heuristics for task graphs have been proposed <ref> [4, 16, 20, 21] </ref>. Comparisons of some of these schemes appear in [8, 10]. While the task graph scheduling problem is similar to the problem considered in this paper, it differs in several important ways.
Reference: [5] <author> P. Bodorik, J. Riordan, and J. Pyra. </author> <title> Deciding to correct distributed query processing. </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> 4(3) </volume> <pages> 12-21, </pages> <month> June </month> <year> 1992. </year> <month> 13 </month>
Reference-contexts: Dynamic query optimization has been proposed for dealing with uncertainties in the size of intermediate results and in the availability of memory and other resources. Bodorik et al <ref> [5, 6] </ref> apply critical path analysis and on-line correction of query plans to deal with mispredictions in the size of intermediate results. Their primary technique is to reorder the query plan.
Reference: [6] <author> P. Bodorik and J. Riordon. </author> <title> A threshold mechanism for distributed query processing. </title> <booktitle> In ACM Computer Science Conference, </booktitle> <pages> pages 616-625, </pages> <address> Atlanta, Georgia, </address> <month> Feb. </month> <year> 1988. </year>
Reference-contexts: Dynamic query optimization has been proposed for dealing with uncertainties in the size of intermediate results and in the availability of memory and other resources. Bodorik et al <ref> [5, 6] </ref> apply critical path analysis and on-line correction of query plans to deal with mispredictions in the size of intermediate results. Their primary technique is to reorder the query plan.
Reference: [7] <author> M.-S. Chen, M. Lo, P. S. Yu, and H. C. Young. </author> <title> Using segmented right-deep trees for the exeucution of pipelined hash joins. </title> <booktitle> In 18th International Conference on Very Large Databases, </booktitle> <address> Vancouver, </address> <month> Aug. </month> <year> 1992. </year>
Reference-contexts: Our scheme of partitioning the dataset and processing a set of partitions at a time is similar in spirit to pipelined hash-joins which are used in parallel and distributed databases <ref> [7, 15] </ref>. The advantage of pipelining in both these scenarios is that intermediate results do not have to be stored. For our algorithms, pipelining provides an additional advantage in that it allows individual stages in the pipeline to be relocated after each data partition.
Reference: [8] <author> H. El-Rewini and T. Lewis. </author> <title> Task Scheduling in Parallel and Distributed Systems. </title> <publisher> Prentice Hall, </publisher> <year> 1994. </year>
Reference-contexts: The primary technique, once again, is to reorder the query plan. They did not consider relocation of operators. Various scheduling heuristics for task graphs have been proposed [4, 16, 20, 21]. Comparisons of some of these schemes appear in <ref> [8, 10] </ref>. While the task graph scheduling problem is similar to the problem considered in this paper, it differs in several important ways. First, task heuristics assume that the network speed is constant and is the same for all links.
Reference: [9] <author> M. J. Franklin, B. Jonsson, and D. Kossmann. </author> <title> Performance tradeoffs for client-server query processing. </title> <booktitle> In ACM SIGMOD 96, </booktitle> <address> Montreal, Canada, </address> <month> June </month> <year> 1996. </year>
Reference-contexts: Bodorik et al [5, 6] apply critical path analysis and on-line correction of query plans to deal with mispredictions in the size of intermediate results. Their primary technique is to reorder the query plan. Franklin et al. <ref> [9] </ref> have proposed dynamic query optimization for dealing with uncertainty in the amount and configuration of memory available. The primary technique, similar to the one-shot algorithm proposed in this paper, determines suitable locations for various operators at query startup time.
Reference: [10] <author> A. Gerasoulis and T. Yang. </author> <title> A comparison of clustering heuristics for scheduling DAGs on multiprocessors. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 16(4) </volume> <pages> 276-91, </pages> <month> Dec </month> <year> 1992. </year>
Reference-contexts: The primary technique, once again, is to reorder the query plan. They did not consider relocation of operators. Various scheduling heuristics for task graphs have been proposed [4, 16, 20, 21]. Comparisons of some of these schemes appear in <ref> [8, 10] </ref>. While the task graph scheduling problem is similar to the problem considered in this paper, it differs in several important ways. First, task heuristics assume that the network speed is constant and is the same for all links.
Reference: [11] <author> D. Lange and M. Oshima. </author> <title> Programming Mobile Agents in Java. </title> <booktitle> In progress, </booktitle> <year> 1996. </year>
Reference-contexts: The mobility support can be provided by mobile object systems like Sumatra [1, 14], Aglets <ref> [11] </ref>, Mole [17] or Telescript [18].
Reference: [12] <institution> Mesquite Software. CSIM Simulation Software. </institution> <note> http://www.mesquite.com/. </note>
Reference-contexts: The composition operations are arranged as a complete binary tree. This application is based on the AVHRR Pathfinder program used by NASA Goddard to process data from the NOAA satellites [2]. We implemented a detailed discrete event simulation of the system using CSIM <ref> [12] </ref>. The simulation models the complete protocol and includes the effects of end-point congestion, message buffering and message startup cost, retrieval of images from disk, image composition and transmission delays. The simulation also models high-priority messages, such as barrier messages, which are preferentially processed.
Reference: [13] <author> M. Ranganathan, A. Acharya, and J. Saltz. </author> <title> Distributed resource monitors for mobile objects. </title> <booktitle> In International Workshop on Operating System Support for Object Oriented Systems, </booktitle> <year> 1996. </year>
Reference-contexts: The monitoring support can be provided by user-level distributed network monitoring systems like Komodo <ref> [13] </ref> and the Network Weather Service [19]. Since the placement algorithms run periodically, only on-demand monitoring is needed.
Reference: [14] <author> M. Ranganathan, A. Acharya, S. Sharma, and J. Saltz. </author> <title> Network-aware Mobile Programs. </title> <booktitle> In Proceedings of the USENIX 1997 Annual Technical Conference, </booktitle> <pages> pages 91-104, </pages> <month> Jan </month> <year> 1997. </year>
Reference-contexts: The mobility support can be provided by mobile object systems like Sumatra <ref> [1, 14] </ref>, Aglets [11], Mole [17] or Telescript [18].
Reference: [15] <author> J. Richardson, J. Lu, and K. Mikkilineni. </author> <title> Design and evaluation of parallel pipelined join algorithms. </title> <booktitle> In ACM SIGMOD, </booktitle> <pages> pages 399-409, </pages> <month> May </month> <year> 1987. </year>
Reference-contexts: Our scheme of partitioning the dataset and processing a set of partitions at a time is similar in spirit to pipelined hash-joins which are used in parallel and distributed databases <ref> [7, 15] </ref>. The advantage of pipelining in both these scenarios is that intermediate results do not have to be stored. For our algorithms, pipelining provides an additional advantage in that it allows individual stages in the pipeline to be relocated after each data partition.
Reference: [16] <author> V. Sarkar. </author> <title> Partitioning and Scheduling Parallel Programs for Execution on Multiprocessors. </title> <publisher> MIT Press, </publisher> <year> 1989. </year>
Reference-contexts: Amsaleg and Franklin [3] have proposed query scrambling to deal with unexpected delays in data arrival in a wide-area environment. The primary technique, once again, is to reorder the query plan. They did not consider relocation of operators. Various scheduling heuristics for task graphs have been proposed <ref> [4, 16, 20, 21] </ref>. Comparisons of some of these schemes appear in [8, 10]. While the task graph scheduling problem is similar to the problem considered in this paper, it differs in several important ways.
Reference: [17] <author> M. Strafier, J. Baumann, and F. Hohl. </author> <title> Mole A Java Based Mobile Agent System. </title> <booktitle> In Proceedings of the ECOOP'96 workshop on Mobile Object Systems, </booktitle> <year> 1996. </year>
Reference-contexts: The mobility support can be provided by mobile object systems like Sumatra [1, 14], Aglets [11], Mole <ref> [17] </ref> or Telescript [18].
Reference: [18] <author> J. White. </author> <title> Telescript Technology: </title> <booktitle> Mobile Agents, </booktitle> <year> 1996. </year> <note> http://www.genmagic.com/Telescript /Whitepapers. </note>
Reference-contexts: The mobility support can be provided by mobile object systems like Sumatra [1, 14], Aglets [11], Mole [17] or Telescript <ref> [18] </ref>.
Reference: [19] <author> R. Wolski. </author> <title> Dynamically forecasting network performance using the Network Weather Service. </title> <type> Technical Report TR-CS96-494, </type> <institution> University of California at San Deigo, </institution> <month> Oct </month> <year> 1996. </year>
Reference-contexts: The monitoring support can be provided by user-level distributed network monitoring systems like Komodo [13] and the Network Weather Service <ref> [19] </ref>. Since the placement algorithms run periodically, only on-demand monitoring is needed.
Reference: [20] <author> M. Wu and D. Gajski. Hypertool: </author> <title> A programming aid for message-passing systems. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 1(3) </volume> <pages> 330-43, </pages> <year> 1990. </year>
Reference-contexts: Amsaleg and Franklin [3] have proposed query scrambling to deal with unexpected delays in data arrival in a wide-area environment. The primary technique, once again, is to reorder the query plan. They did not consider relocation of operators. Various scheduling heuristics for task graphs have been proposed <ref> [4, 16, 20, 21] </ref>. Comparisons of some of these schemes appear in [8, 10]. While the task graph scheduling problem is similar to the problem considered in this paper, it differs in several important ways.
Reference: [21] <author> T. Yang and A. Gerasoulis. </author> <title> DSC: Scheduling parallel tasks on an unbounded number of processors. </title> <journal> IEEE Transactions on Parallel and Distributed Systems, </journal> <volume> 5(9) </volume> <pages> 951-67, </pages> <year> 1994. </year> <month> 14 </month>
Reference-contexts: Amsaleg and Franklin [3] have proposed query scrambling to deal with unexpected delays in data arrival in a wide-area environment. The primary technique, once again, is to reorder the query plan. They did not consider relocation of operators. Various scheduling heuristics for task graphs have been proposed <ref> [4, 16, 20, 21] </ref>. Comparisons of some of these schemes appear in [8, 10]. While the task graph scheduling problem is similar to the problem considered in this paper, it differs in several important ways.
References-found: 21

