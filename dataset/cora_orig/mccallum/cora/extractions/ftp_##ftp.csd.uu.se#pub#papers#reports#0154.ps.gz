URL: ftp://ftp.csd.uu.se/pub/papers/reports/0154.ps.gz
Refering-URL: http://www.csd.uu.se/papers/reports.html
Root-URL: 
Email: E-mail: thomasl@csd.uu.se  
Phone: Tel: 46 18 471 10 54  Phone: +4818471 00 00 Fax: +461851 19 25  
Author: Thomas Lindgren 
Keyword: Module Merging: aggressive optimization and code  
Address: Box 311 751 05 Uppsala SWEDEN  Box 311, S-751 05 Uppsala, Sweden  
Affiliation: Computing Science Department Uppsala University  
Note: replacement in highly available systems  
Abstract: UPMAIL Technical Report No. 154 March 11, 1998 ISSN 1100-0686 Abstract In this paper, we propose a method to enable aggressive, interprocedu-ral optimization in a setting where code can be replaced at runtime. Code replacement involves both introducing a new module into the system and deal-locating old code. Code purging deallocates replaced code, which is required in long running systems. Our approach, module merging, is simple and practical: we merge code modules and insert code to check for code replacement at the appropriate points. We show how to preserve the behavior of code purging. The net result is that merged modules preserve the original code replacement behavior, while enabling optimization across code replacement boundaries. We finally show how to perform inlining and dataflow analysis in merged modules.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. Armstrong, R. Virding, C. Wikstrom, M. Williams. </author> <title> Concurrent Programming in Erlang, 2nd ed. </title> <publisher> Prentice-Hall, </publisher> <year> 1996. </year> <month> 10 </month>
Reference-contexts: As code is debugged, upgraded and performance tuned, modules can be merged into new configurations, aggressively reoptimized o*ine and introduced into the running system. While our methods have been developed for the concurrent functional language Erlang <ref> [1] </ref>, a language used at Ericsson to develop products and middleware for high availability telephony and data communications [11], they can be applied to any language with a similar code replacement model. 1.1 Overview Section 2 describes the code replacement model. <p> Section 4 shows how to integrate inlining and dataflow analysis on top of merged modules. Section 5 discusses related work. Section 6 summarizes the paper and indicates future work. 2 Code replacement model Our thread and code replacement models are based on those of Erlang <ref> [1] </ref> with the extra assumption of non-preemptiveness. (This assumption holds for most current Erlang implementations and works well when threads reliably check whether to yield.) 2.1 Thread model Threads are dynamically created lightweight entities that execute functional programs. Threads communicate asynchronously by message passing through mailboxes. <p> If a thread dies, an exit signal is sent to all linked threads. The signal is either caught by the recipient thread or otherwise kills it. 2 2.2 Overview of code replacement Our code replacement model is based on that of Erlang <ref> [1] </ref>, though we describe it in a more general context. The program is divided into a number of code replacement units, each of which may be replaced at runtime. We call each such program unit a module, written m; m 0 ; : : :. <p> Chambers [2] describes how this can be done intelligently, though the method requires extra code space or a dynamic compiler. 5 Related work The code replacement model we have developed is close to that used in Erlang <ref> [1] </ref>; the main difference is that Erlang currently limits the number of instances present in the system at one time to two instances, the old and new versions of the module, and on a call to m : f (: : :) tries to autoload an instance of m if none
Reference: [2] <author> C. Chambers, </author> <title> The Design and Implementation of the SELF-91 Compiler, </title> <type> Ph.D thesis, </type> <institution> Stanford University, </institution> <year> 1992. </year>
Reference-contexts: Application maintenance must 1 be performed in a live system: parts of the application code is replaced while the application executes. A second trend is the move towards program construction using encapsulation. While this helps reuse, rapid development and debugging, it also entails well-known performance problems <ref> [2, 5] </ref>. To implement encapsulation efficiently, modern optimizing compilers perform inlining, interprocedural analysis and interprocedural optimization [3]. Unfortunately, such techniques do not easily generalize to a setting where modules can be replaced at runtime. <p> We suggest that compilers split the control flow to separate reaching definitions appropriately, as shown in the lower part of Figure 4. Chambers <ref> [2] </ref> describes how this can be done intelligently, though the method requires extra code space or a dynamic compiler. 5 Related work The code replacement model we have developed is close to that used in Erlang [1]; the main difference is that Erlang currently limits the number of instances present in
Reference: [3] <author> C. Chambers, J. Dean, D. Grove. </author> <title> Whole-Program Optimization of Object-Oriented Languages. </title> <type> Technical report 96-06-02, </type> <institution> Department of Computer Science and Engineering, University of Washington, </institution> <year> 1996. </year>
Reference-contexts: A second trend is the move towards program construction using encapsulation. While this helps reuse, rapid development and debugging, it also entails well-known performance problems [2, 5]. To implement encapsulation efficiently, modern optimizing compilers perform inlining, interprocedural analysis and interprocedural optimization <ref> [3] </ref>. Unfortunately, such techniques do not easily generalize to a setting where modules can be replaced at runtime. In this paper, we propose the technique of module merging to allow interpro-cedural optimization of code that can be replaced at runtime.
Reference: [4] <author> C. Cowan, T. Autrey, C. Krasic, C. Pu, J. Walpole. </author> <title> Fast Concurrent Dynamic Linking for an Adaptive Operating System. </title> <booktitle> In Proc. International Conference on Configurable Distributed Systems (ICCDS'96), </booktitle> <publisher> IEEE Press, </publisher> <year> 1996. </year>
Reference-contexts: Code loading by multiple threads is 9 serialized. Most published work on systems with code replacement has addressed the question of managing the evolution of code, rather than optimizing the changing code. The closest related work of which we are aware is Synthetix <ref> [4] </ref>. There, procedures are optimistically specialized to take advantage of current system settings, quasi-invariants [10].
Reference: [5] <author> A. Diwan, E. Moss, K. McKinley. </author> <title> Simple and effective analysis of statically-typed object-oriented programs. </title> <booktitle> In Proc. </booktitle> <address> OOPSLA'96, </address> <publisher> ACM Press, </publisher> <year> 1996. </year>
Reference-contexts: Application maintenance must 1 be performed in a live system: parts of the application code is replaced while the application executes. A second trend is the move towards program construction using encapsulation. While this helps reuse, rapid development and debugging, it also entails well-known performance problems <ref> [2, 5] </ref>. To implement encapsulation efficiently, modern optimizing compilers perform inlining, interprocedural analysis and interprocedural optimization [3]. Unfortunately, such techniques do not easily generalize to a setting where modules can be replaced at runtime.
Reference: [6] <author> P. Hedqvist, </author> <title> A Multithreaded Erlang Architecture, M.Sc. </title> <type> thesis, </type> <institution> Computing Science Department, Uppsala University, </institution> <note> to appear. </note>
Reference-contexts: Purging a module m in Erlang means purging the old version of m. A multithreaded Erlang implementation developed at Ericsson by Hedqvist and Rogvall <ref> [6] </ref> handles code replacement with generic threads. Remote calls are handled by looking up the function at call-time. Code loading atomically inserts exported functions in the global lookup table. Code loading by multiple threads is 9 serialized.
Reference: [7] <author> E. Johansson, C. Jonsson, T. Lindgren, J. Bevemyr, H. Millroth. </author> <title> A pragmatic approach to compilation of Erlang. </title> <booktitle> In Proc. PLILP'97, Lecture Notes in Computer Science, </booktitle> <publisher> Springer Verlag, </publisher> <year> 1997. </year>
Reference-contexts: At the same time, optimization across the former module boundaries is now possible, since remote calls in the code have been resolved into (guarded) direct function calls. 6.1 Future work We are at present building a module manager and optimizing compiler based on the principles above and previous work <ref> [7] </ref>. We are also investigating optimizations to the latest checking scheme, and delving into the principles of optimization in systems with code replacement. In particular, code motion in the presence of code replacement appears interesting.
Reference: [8] <author> S. Muchnick. </author> <title> Advanced Compiler Implementation. </title> <publisher> Morgan Kaufmann, </publisher> <year> 1997. </year>
Reference-contexts: Remote calls in the merged module must still be treated as if returning some unknown value. The generated code can be far from optimal. Consider the uppermost part of local call by module merging. Unfortunately, subsequent uses of x are reached <ref> [8, Sec. 8.10-8.11] </ref> by both the local call and the remote call: the result is that nothing is known of the value of x. We suggest that compilers split the control flow to separate reaching definitions appropriately, as shown in the lower part of Figure 4.
Reference: [9] <author> G. Pfister. </author> <title> In Search of Clusters, 2nd edition. </title> <publisher> Prentice-Hall, </publisher> <year> 1998. </year>
Reference-contexts: 1 Introduction As the computer industry moves into the age of ubiquitous networking, servers with extremely high availability become crucial. Such systems are expected to run indefinitely, with downtimes of a few minutes per year <ref> [9, Ch.12] </ref>, yet must install upgrades and bug fixes as they become available. Application maintenance must 1 be performed in a live system: parts of the application code is replaced while the application executes. A second trend is the move towards program construction using encapsulation.
Reference: [10] <author> C. Pu, T. Autrey, A. Black, C. Consel, C. Cowan, J. Inouye, L. Kethana, J. Walpole, K. Zhang. </author> <title> Optimistic incremental specialization: streamlining a commercial operating system. </title> <booktitle> In Proc. 15th ACM Symposium on Operating Systems Principles (SOSP'95), </booktitle> <month> December 3-6, </month> <year> 1995, </year> <institution> Copper Mountain, Colorado. </institution>
Reference-contexts: Most published work on systems with code replacement has addressed the question of managing the evolution of code, rather than optimizing the changing code. The closest related work of which we are aware is Synthetix [4]. There, procedures are optimistically specialized to take advantage of current system settings, quasi-invariants <ref> [10] </ref>. If an invariant is violated by some other process (e.g., a file becomes shared), then the system backs out of the optimized code by directing threads into a waiting area and relinking the code, a process called replugging. <p> The Synthetix group estimates the cost of a repluggable call to 50 clock cycles, while the replugging protocol is estimated to cost 280 cycles. Our latest tests could be seen as an application of the principle of optimistic incremental specialization <ref> [10] </ref>, though as shown above it is a very efficient special case. A cross-module call in a merged module requires a single instruction to implement a remote call (corresponding to a replugging point). Relinking remote calls requires time proportional to the number of calls to the module.
Reference: [11] <author> S. Torstendahl. </author> <title> Open telecom platform. </title> <journal> Ericsson Review, </journal> <volume> no. 1, 1997, vol. 74. 11 -module(ets). </volume> <editor> -export([lookup/2,...]). lookup(-T,Ref-,K) when node(Ref) == node() -&gt; erlang:db_get(-T,Ref-,K); lookup(-T,Ref-,K) -&gt; chk(rpc:block_call(node(Ref), ets, lookup, [-T,Ref-, K])). -module(rpc). -export([block_call/4,...]). </editor> <title> block_call(N,M,F,A) when node() == N -&gt; %% Optimize local call case catch apply(M,F,A) of -'EXIT', </title> <editor> R- -&gt; -badrpc, R-; Other -&gt; Other end; block_call(N,M,F,A) -&gt; rpc_check(server_call(N, rex, </editor> <publisher> rex,-block_call,M,F,A,group_leader()-)). </publisher>
Reference-contexts: While our methods have been developed for the concurrent functional language Erlang [1], a language used at Ericsson to develop products and middleware for high availability telephony and data communications <ref> [11] </ref>, they can be applied to any language with a similar code replacement model. 1.1 Overview Section 2 describes the code replacement model. Section 3 describes how to merge modules into larger units. Section 4 shows how to integrate inlining and dataflow analysis on top of merged modules.
References-found: 11

