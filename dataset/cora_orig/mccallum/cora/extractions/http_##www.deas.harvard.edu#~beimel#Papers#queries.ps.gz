URL: http://www.deas.harvard.edu/~beimel/Papers/queries.ps.gz
Refering-URL: http://www.deas.harvard.edu/~beimel/pub.html
Root-URL: 
Title: The Query Complexity of Finding Local Minima in the Lattice  
Author: Amos Beimel Felix Geller Eyal Kushilevitz 
Address: 40 Oxford st., Cambridge, MA 02138.  Haifa 32000, Israel.  Haifa 32000, Israel.  
Affiliation: Division of Engineering Applied Sciences Harvard University  Computer Science Department Technion  Computer Science Department, Technion  
Abstract: In this paper we study the query complexity of finding local minimum points of a boolean function. This task occurs frequently in exact learning algorithms for many natural classes, such as monotone DNF, O(log n)-term DNF, unate DNF and decision trees. On the negative side, we prove that any (possibly randomized) algorithm that produces a local minimum of a function f chosen from a sufficiently rich concept class, using a membership oracle for f , must ask (n 2 ) membership queries in the worst case. In particular, this lower bound applies to the class of decision trees. A simple algorithm is known that achieves this lower bound. On the positive side, we show that for the class O(log n)-term DNF finding local minimum points requires only fi(n log n) membership queries (and more generally fi(nt) membership queries for t-term DNF with t n). This efficient procedure improves the time and query complexity of known learning algorithms for the class O(log n)-term DNF.
Abstract-found: 1
Intro-found: 1
Reference: [AFP92] <author> D. Angluin, M. Frazier, and L. Pitt. </author> <title> Learning conjunctions of Horn clauses. </title> <booktitle> Machine Learning, </booktitle> <address> 9:147164, </address> <year> 1992. </year>
Reference: [AHK93] <author> D. Angluin, L. Hellerstein, and M. Karpinski. </author> <title> Learning read-once formulas with queries. </title> <journal> J. of the ACM, </journal> <volume> 40:185210, </volume> <year> 1993. </year>
Reference-contexts: Ang87b, AFP92, RS93, Bsh93, BR95, SS96, BCV96, BBB + 96, Bsh97] and many others). In some of the above, and in several related papers (e.g., <ref> [Ang88, GM92, AHK93, Bsh93, AS94, BCGS95, Bsh97, AKST97] </ref>), the following common approach is used: the input space, f0; 1g n , is viewed as a lattice with the natural partial order (i.e., for u; v 2 f0; 1g n if u [i] v [i] for all i then u v).
Reference: [AKST97] <author> D. Angluin, M. Krikis, R. E. Sloan, and G. Turan. </author> <title> Malicious omissions and errors in answers to membership queries. </title> <booktitle> Machine Learning, </booktitle> <address> 28:211255, </address> <year> 1997. </year>
Reference-contexts: Ang87b, AFP92, RS93, Bsh93, BR95, SS96, BCV96, BBB + 96, Bsh97] and many others). In some of the above, and in several related papers (e.g., <ref> [Ang88, GM92, AHK93, Bsh93, AS94, BCGS95, Bsh97, AKST97] </ref>), the following common approach is used: the input space, f0; 1g n , is viewed as a lattice with the natural partial order (i.e., for u; v 2 f0; 1g n if u [i] v [i] for all i then u v).
Reference: [Ang87a] <author> D. Angluin. </author> <title> Learning k-term DNF formulas using queries and counterexamples. </title> <type> Technical Report YALEU/DCS/RR-559, </type> <institution> Department of Computer Science, Yale University, </institution> <year> 1987. </year>
Reference: [Ang87b] <author> D. Angluin. </author> <title> Learning regular sets from queries and counterexamples. Information and Computation, </title> <address> 75:87106, </address> <year> 1987. </year>
Reference: [Ang88] <author> D. Angluin. </author> <title> Queries and concept learning. </title> <booktitle> Machine Learning, </booktitle> <address> 2(4):319342, </address> <year> 1988. </year>
Reference-contexts: 1 Introduction Angluin's model of learning using membership queries and equivalence queries (i.e. the exact learning model) <ref> [Ang88] </ref> attracted a lot of attention. In particular, various concept classes were shown to be learnable in this model (e.g., [Ang87a, fl E-mail: beimel@deas.harvard.edu. http://www.deas.harvard.edu/~beimel. Supported by grants ONR-N00014-96-1-0550 and ARO-DAAL-03-92-G0115. y E-mail: felix@cs.technion.ac.il. z E-mail: eyalk@cs.technion.ac.il. http://www.cs.technion.ac.il/~eyalk. Supported by Technion V.P.R. <p> Ang87b, AFP92, RS93, Bsh93, BR95, SS96, BCV96, BBB + 96, Bsh97] and many others). In some of the above, and in several related papers (e.g., <ref> [Ang88, GM92, AHK93, Bsh93, AS94, BCGS95, Bsh97, AKST97] </ref>), the following common approach is used: the input space, f0; 1g n , is viewed as a lattice with the natural partial order (i.e., for u; v 2 f0; 1g n if u [i] v [i] for all i then u v). <p> For this, the learning algorithm uses a procedure FIND TERM that gets as an input some point w such that f (w) = 1 and searches for a minimal point u such that u w. Angluin <ref> [Ang88] </ref>, considering the case of monotone functions, implemented the procedure FIND TERM using n membership queries as follows: * For 1 i n: If the i-th bit of w is 1 and when flipping this bit to 0 the value of f remains 1 then flip the i-th bit of w <p> Related Work: The query complexity of learning algorithms was the subject of a considerable amount of work. For example, Angluin proved for several classes that polynomial number of membership queries do not suffice for learning (if equivalence queries are not allowed) <ref> [Ang88] </ref>. In [Ang90] Angluin showed the significance of membership queries for efficient learning of classes such as DFA, CFG, DNF and CNF formulae. Maass and Turan [MT89, MT90, MT92] established general lower bounds, relating the query complexity of a concept class to combinatorial parameters of the class. <p> Thus, intuitively, if the algorithm does not go down the lattice from father to son (as is the case in the search procedures of <ref> [Ang88, Bsh93] </ref>), but rather decides to skip at least one level, then the expected number of queries it has to make is (n 2 ).
Reference: [Ang90] <author> D. Angluin. </author> <title> Negative results for equivalence queries. </title> <booktitle> Machine Learning, </booktitle> <address> 5:121150, </address> <year> 1990. </year>
Reference-contexts: Related Work: The query complexity of learning algorithms was the subject of a considerable amount of work. For example, Angluin proved for several classes that polynomial number of membership queries do not suffice for learning (if equivalence queries are not allowed) [Ang88]. In <ref> [Ang90] </ref> Angluin showed the significance of membership queries for efficient learning of classes such as DFA, CFG, DNF and CNF formulae. Maass and Turan [MT89, MT90, MT92] established general lower bounds, relating the query complexity of a concept class to combinatorial parameters of the class.
Reference: [AS94] <author> D. Angluin and D. K. </author> <title> Slonim. Randomly fallible teachers: learning monotone DNF with an incomplete membership oracle. </title> <booktitle> Machine Learning, </booktitle> <address> 14(1):726, </address> <year> 1994. </year>
Reference-contexts: Ang87b, AFP92, RS93, Bsh93, BR95, SS96, BCV96, BBB + 96, Bsh97] and many others). In some of the above, and in several related papers (e.g., <ref> [Ang88, GM92, AHK93, Bsh93, AS94, BCGS95, Bsh97, AKST97] </ref>), the following common approach is used: the input space, f0; 1g n , is viewed as a lattice with the natural partial order (i.e., for u; v 2 f0; 1g n if u [i] v [i] for all i then u v).
Reference: [BBB + 96] <author> A. Beimel, F. Bergadano, N. H. Bshouty, E. Kushilevitz, and S. Varricchio. </author> <title> On the applications of multiplicity automata in learning. </title> <booktitle> In Proc. of 37th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 349358, </pages> <year> 1996. </year>
Reference-contexts: Among the many algorithms for learning this class for t = O (log n) <ref> [BR95, Bsh93, Bsh97, Kus97, BBB + 96] </ref>, the most efficient one is the algorithm of Bshouty [Bsh93] based on his monotone theory.
Reference: [BC92] <author> N. H. Bshouty and R. Cleve. </author> <title> On the exact learning of formulas in parallel. </title> <booktitle> In 33rd Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 513522, </pages> <year> 1992. </year>
Reference-contexts: They gave a combinatorial characterization of the the number of queries required to learn a class by a (possibly non-efficient) algorithm that uses proper equivalence queries and membership queries. Hegedus [Heg95] also gave combinatorial characterization for algorithms that only use membership queries. Bshouty et al. <ref> [BC92, BGHM96] </ref> investigated lower bounds on the number of equivalence queries required for learning, assuming that polynomially many membership queries are available (in addition to the equivalence queries).
Reference: [BCGS95] <author> A. Blum, P. Chalasani, S. Goldman, and D. K. </author> <title> Slonim. Learning with unreliable boundary queries. </title> <booktitle> In Proc. of 8th Annu. ACM Conf. on Comput. Learning Theory, </booktitle> <pages> pages 98107, </pages> <year> 1995. </year>
Reference-contexts: Ang87b, AFP92, RS93, Bsh93, BR95, SS96, BCV96, BBB + 96, Bsh97] and many others). In some of the above, and in several related papers (e.g., <ref> [Ang88, GM92, AHK93, Bsh93, AS94, BCGS95, Bsh97, AKST97] </ref>), the following common approach is used: the input space, f0; 1g n , is viewed as a lattice with the natural partial order (i.e., for u; v 2 f0; 1g n if u [i] v [i] for all i then u v).
Reference: [BCV96] <author> F. Bergadano, D. Catalano, and S. Varricchio. </author> <title> Learning sat-k-DNF formulas from membership queries. </title> <booktitle> In Proc. of 28th Annu. ACM Symp. on the Theory of Computing, </booktitle> <pages> pages 126130, </pages> <year> 1996. </year>
Reference: [BGHM96] <author> N. H. Bshouty, S. A. Goldman, T. R. Hancock, and S. Matar. </author> <title> Asking questions to minimize errors. </title> <journal> J. of Computer and System Sciences, </journal> <volume> 52(2):268286, </volume> <year> 1996. </year>
Reference-contexts: They gave a combinatorial characterization of the the number of queries required to learn a class by a (possibly non-efficient) algorithm that uses proper equivalence queries and membership queries. Hegedus [Heg95] also gave combinatorial characterization for algorithms that only use membership queries. Bshouty et al. <ref> [BC92, BGHM96] </ref> investigated lower bounds on the number of equivalence queries required for learning, assuming that polynomially many membership queries are available (in addition to the equivalence queries).
Reference: [BR95] <author> A. Blum and S. Rudich. </author> <title> Fast learning of k-term DNF formulas with queries. </title> <journal> J. of Computer and System Sciences, </journal> <volume> 51(3):367373, </volume> <year> 1995. </year>
Reference-contexts: Among the many algorithms for learning this class for t = O (log n) <ref> [BR95, Bsh93, Bsh97, Kus97, BBB + 96] </ref>, the most efficient one is the algorithm of Bshouty [Bsh93] based on his monotone theory.
Reference: [Bsh93] <author> N. H. Bshouty. </author> <title> Exact learning via the monotone theory. </title> <booktitle> In Proc. of 34th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 302 311, </pages> <year> 1993. </year> <note> Journal version: Information and Computation, 123(1):146153, </note> <year> 1995. </year>
Reference-contexts: Ang87b, AFP92, RS93, Bsh93, BR95, SS96, BCV96, BBB + 96, Bsh97] and many others). In some of the above, and in several related papers (e.g., <ref> [Ang88, GM92, AHK93, Bsh93, AS94, BCGS95, Bsh97, AKST97] </ref>), the following common approach is used: the input space, f0; 1g n , is viewed as a lattice with the natural partial order (i.e., for u; v 2 f0; 1g n if u [i] v [i] for all i then u v). <p> The last value of w is a minimal point. Bshouty <ref> [Bsh93, Bsh97] </ref> considered non-monotone classes of functions (such as decision trees), and implemented the procedure FIND TERM using O (n 2 ) membership queries as follows: * Do at most n times: Find an index 1 i n such that the i-th bit of w is 1 and when flipping the <p> is a minimal point. (Our procedure is described in detail in Fig. 4.) This efficient implementation of FIND TERM improves the time and query complexity of learning the class O (log n)- term DNF by a factor of O (n= log n) in Bshouty's algorithm based on the monotone theory <ref> [Bsh93] </ref> and in Bshouty's divide and conquer algorithm algorithm [Bsh97]. On the other hand, we prove a matching lower bound of (nt) for finding minimal points for target functions from the class t-term DNF (for every t n). <p> Another remark is that this lower bound is tight up to an additive factor of O (log n) since a simple modification of Bshouty's implementation <ref> [Bsh93] </ref> uses n + O (log n) membership queries to find local minimum points for any boolean function 1 . In the rest of this section we restrict our attention to the sub-class P n . <p> Thus, intuitively, if the algorithm does not go down the lattice from father to son (as is the case in the search procedures of <ref> [Ang88, Bsh93] </ref>), but rather decides to skip at least one level, then the expected number of queries it has to make is (n 2 ). <p> Among the many algorithms for learning this class for t = O (log n) <ref> [BR95, Bsh93, Bsh97, Kus97, BBB + 96] </ref>, the most efficient one is the algorithm of Bshouty [Bsh93] based on his monotone theory. <p> Among the many algorithms for learning this class for t = O (log n) [BR95, Bsh93, Bsh97, Kus97, BBB + 96], the most efficient one is the algorithm of Bshouty <ref> [Bsh93] </ref> based on his monotone theory. The number of equivalence queries in this algorithm for learning a t-term DNF function is O (u t) where u is the size of an (n; t) universal set. <p> Bshouty [Bsh97] presented an alternative algorithm for this class based on the divide and conquer approach. This algorithm, whose running time and query complexity are inferior to the <ref> [Bsh93] </ref> algorithm, calls O (t 2 t n) times the procedure FIND TERM.
Reference: [Bsh97] <author> N. H. Bshouty. </author> <title> Simple learning algorithms using divide and conquer. Computational Complexity, </title> <address> 6:174194, </address> <year> 1997. </year>
Reference-contexts: Ang87b, AFP92, RS93, Bsh93, BR95, SS96, BCV96, BBB + 96, Bsh97] and many others). In some of the above, and in several related papers (e.g., <ref> [Ang88, GM92, AHK93, Bsh93, AS94, BCGS95, Bsh97, AKST97] </ref>), the following common approach is used: the input space, f0; 1g n , is viewed as a lattice with the natural partial order (i.e., for u; v 2 f0; 1g n if u [i] v [i] for all i then u v). <p> The last value of w is a minimal point. Bshouty <ref> [Bsh93, Bsh97] </ref> considered non-monotone classes of functions (such as decision trees), and implemented the procedure FIND TERM using O (n 2 ) membership queries as follows: * Do at most n times: Find an index 1 i n such that the i-th bit of w is 1 and when flipping the <p> detail in Fig. 4.) This efficient implementation of FIND TERM improves the time and query complexity of learning the class O (log n)- term DNF by a factor of O (n= log n) in Bshouty's algorithm based on the monotone theory [Bsh93] and in Bshouty's divide and conquer algorithm algorithm <ref> [Bsh97] </ref>. On the other hand, we prove a matching lower bound of (nt) for finding minimal points for target functions from the class t-term DNF (for every t n). Related Work: The query complexity of learning algorithms was the subject of a considerable amount of work. <p> Among the many algorithms for learning this class for t = O (log n) <ref> [BR95, Bsh93, Bsh97, Kus97, BBB + 96] </ref>, the most efficient one is the algorithm of Bshouty [Bsh93] based on his monotone theory. <p> With our implementation of FIND TERM, we get a deterministic algorithm which uses O (2 t t O (log t) n log n) membership queries, and a randomized algorithm which uses O (t 2 2 t n log n) membership queries. Bshouty <ref> [Bsh97] </ref> presented an alternative algorithm for this class based on the divide and conquer approach. This algorithm, whose running time and query complexity are inferior to the [Bsh93] algorithm, calls O (t 2 t n) times the procedure FIND TERM.
Reference: [CDGK91] <author> M. Clausen, A. Dress, J. Grabmeier, and M. Karpinski. </author> <title> On zero-testing and interpolation of k-sparse multivariate polynomials over finite fields. </title> <booktitle> Theoretical Computer Science, </booktitle> <address> 84(2):151164, </address> <year> 1991. </year>
Reference-contexts: Hegedus [Heg95] also gave combinatorial characterization for algorithms that only use membership queries. Bshouty et al. [BC92, BGHM96] investigated lower bounds on the number of equivalence queries required for learning, assuming that polynomially many membership queries are available (in addition to the equivalence queries). Clausen et al. <ref> [CDGK91] </ref> and Roth and Benedek [RB91] investigate the number of membership queries required to interpolate polynomials over finite fields (without equivalence queries). Organization: In Section 2 we present the definitions and notations that we use throughout the paper.
Reference: [GM92] <author> S. Goldman and H. Mathias. </author> <title> Learning k-term DNF formulas with an incomplete membership oracle. </title> <booktitle> In Proc. of 5th Annu. ACM Workshop on Comput. Learning Theory, </booktitle> <pages> pages 7785, </pages> <year> 1992. </year>
Reference-contexts: Ang87b, AFP92, RS93, Bsh93, BR95, SS96, BCV96, BBB + 96, Bsh97] and many others). In some of the above, and in several related papers (e.g., <ref> [Ang88, GM92, AHK93, Bsh93, AS94, BCGS95, Bsh97, AKST97] </ref>), the following common approach is used: the input space, f0; 1g n , is viewed as a lattice with the natural partial order (i.e., for u; v 2 f0; 1g n if u [i] v [i] for all i then u v).
Reference: [Heg95] <author> T. Hegedus. </author> <title> Generalized teaching dimensions and the query complexity of learning. </title> <booktitle> In Proc. of 8th Annu. ACM Conf. on Comput. Learning Theory, </booktitle> <pages> pages 108117, </pages> <year> 1995. </year>
Reference-contexts: Maass and Turan [MT89, MT90, MT92] established general lower bounds, relating the query complexity of a concept class to combinatorial parameters of the class. This direction was continued by Hegedus <ref> [Heg95] </ref> and by Hellerstein et al. [HPRW96]. They gave a combinatorial characterization of the the number of queries required to learn a class by a (possibly non-efficient) algorithm that uses proper equivalence queries and membership queries. Hegedus [Heg95] also gave combinatorial characterization for algorithms that only use membership queries. <p> This direction was continued by Hegedus <ref> [Heg95] </ref> and by Hellerstein et al. [HPRW96]. They gave a combinatorial characterization of the the number of queries required to learn a class by a (possibly non-efficient) algorithm that uses proper equivalence queries and membership queries. Hegedus [Heg95] also gave combinatorial characterization for algorithms that only use membership queries. Bshouty et al. [BC92, BGHM96] investigated lower bounds on the number of equivalence queries required for learning, assuming that polynomially many membership queries are available (in addition to the equivalence queries).
Reference: [HPRW96] <author> L. Hellerstein, K. Pillaipakkamnatt, V. Ragha-van, and D. Wilkins. </author> <title> How many queries are needed to learn? J. </title> <booktitle> of the ACM, </booktitle> <address> 43(5):840862, </address> <year> 1996. </year>
Reference-contexts: Maass and Turan [MT89, MT90, MT92] established general lower bounds, relating the query complexity of a concept class to combinatorial parameters of the class. This direction was continued by Hegedus [Heg95] and by Hellerstein et al. <ref> [HPRW96] </ref>. They gave a combinatorial characterization of the the number of queries required to learn a class by a (possibly non-efficient) algorithm that uses proper equivalence queries and membership queries. Hegedus [Heg95] also gave combinatorial characterization for algorithms that only use membership queries.
Reference: [Kus97] <author> E. Kushilevitz. </author> <title> A simple algorithm for learning O(log n)-term DNF. </title> <journal> Inform. Process. Lett., </journal> <volume> 61(6):289292, </volume> <year> 1997. </year>
Reference-contexts: Among the many algorithms for learning this class for t = O (log n) <ref> [BR95, Bsh93, Bsh97, Kus97, BBB + 96] </ref>, the most efficient one is the algorithm of Bshouty [Bsh93] based on his monotone theory.
Reference: [MT89] <author> W. Maass and G. Turan. </author> <title> On the complexity of learning from counterexamples. </title> <booktitle> In Proc. of 30th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 262273, </pages> <year> 1989. </year>
Reference-contexts: In [Ang90] Angluin showed the significance of membership queries for efficient learning of classes such as DFA, CFG, DNF and CNF formulae. Maass and Turan <ref> [MT89, MT90, MT92] </ref> established general lower bounds, relating the query complexity of a concept class to combinatorial parameters of the class. This direction was continued by Hegedus [Heg95] and by Hellerstein et al. [HPRW96].
Reference: [MT90] <author> W. Maass and G. Turan. </author> <title> On the complexity of learning from counterexamples and membership queries. </title> <booktitle> In Proc. of 31st Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <volume> volume I, </volume> <pages> pages 203210, </pages> <year> 1990. </year>
Reference-contexts: In [Ang90] Angluin showed the significance of membership queries for efficient learning of classes such as DFA, CFG, DNF and CNF formulae. Maass and Turan <ref> [MT89, MT90, MT92] </ref> established general lower bounds, relating the query complexity of a concept class to combinatorial parameters of the class. This direction was continued by Hegedus [Heg95] and by Hellerstein et al. [HPRW96].
Reference: [MT92] <author> W. Maass and G. Turan. </author> <title> Lower bound methods and separation results for on-line learning models. </title> <booktitle> Machine Learning, </booktitle> <address> 9:107145, </address> <year> 1992. </year>
Reference-contexts: In [Ang90] Angluin showed the significance of membership queries for efficient learning of classes such as DFA, CFG, DNF and CNF formulae. Maass and Turan <ref> [MT89, MT90, MT92] </ref> established general lower bounds, relating the query complexity of a concept class to combinatorial parameters of the class. This direction was continued by Hegedus [Heg95] and by Hellerstein et al. [HPRW96].
Reference: [NSS95] <author> M. Naor, L. J. Schulman, and A. Srinivasan. </author> <title> Splitters and near-optimal derandomization. </title> <booktitle> In Proc. 36th Annu. IEEE Symp. Foundations of Computer Science, </booktitle> <pages> pages 182191, </pages> <year> 1995. </year>
Reference-contexts: In addition, the al-gorithm calls O (u t) times the procedure FIND TERM, and no membership queries are used otherwise. The size of the smallest deterministic construction of an (n; t) universal set known to date <ref> [NSS95] </ref> is 2 t t O (log t) log n, and the smallest known randomized construction has size O (t 2 t log n).
Reference: [RB91] <author> R. M. Roth and G. M. Benedek. </author> <title> Interpolation and approximation of sparse multivariate polynomials over GF (2). </title> <journal> SIAM J. Comput., </journal> <volume> 20(2):291314, </volume> <year> 1991. </year>
Reference-contexts: Bshouty et al. [BC92, BGHM96] investigated lower bounds on the number of equivalence queries required for learning, assuming that polynomially many membership queries are available (in addition to the equivalence queries). Clausen et al. [CDGK91] and Roth and Benedek <ref> [RB91] </ref> investigate the number of membership queries required to interpolate polynomials over finite fields (without equivalence queries). Organization: In Section 2 we present the definitions and notations that we use throughout the paper.
Reference: [RS93] <author> R. L. Rivest and R. E. Schapire. </author> <title> Inference of finite automata using homing sequences. Information and Computation, </title> <address> 103:299347, </address> <year> 1993. </year>
Reference: [SS96] <author> R. E. Schapire and L. M. Sellie. </author> <title> Learning sparse multivariate polynomials over a field with queries and counterexamples. </title> <journal> J. of Computer and System Sciences, </journal> <volume> 52(2):201213, </volume> <year> 1996. </year>
Reference: [Yao83] <author> A. C. Yao. </author> <title> Lower bounds by probabilistic arguments. </title> <booktitle> In Proc. of the 24th Annu. IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 420 428, </pages> <year> 1983. </year>
Reference-contexts: By Markov inequality, algorithm A 1 finds a correct local minimum point with probability at least 1=2 (again, the probability is over the uniform distribution of f 2 P n and over the random choices of A 1 ). We use Yao's principle <ref> [Yao83] </ref> to construct a deterministic algorithm A 2 that succeeds for at least 1=2 of the functions in P n and still has the same properties as A 1 : it uses less than (i 2 + i)=8 queries of weight at most i and less than (i + 1)=4 queries
References-found: 29

