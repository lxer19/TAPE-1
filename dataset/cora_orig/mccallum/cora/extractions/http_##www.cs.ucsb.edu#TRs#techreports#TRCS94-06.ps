URL: http://www.cs.ucsb.edu/TRs/techreports/TRCS94-06.ps
Refering-URL: http://www.cs.ucsb.edu/TRs/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Semantics-based Failure Recovery in Distributed Systems with Optimistic Message Logging  
Author: Hong Va Leong Divyakant Agrawal 
Keyword: message semantics, commutativity, recovery, optimistic message logging, asynchronous checkpointing  
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California  
Abstract: Recovery from failures is important in distributed computing. A common technique to support recovery is asynchronous checkpointing, coupled with optimistic message logging. These schemes have low overheads during failure-free operations and can provide an acceptable degree of fault-tolerance. Central to these protocols is the determination of a maximal consistent global state, which is recoverable. Message semantics is not exploited in most existing recovery protocols to determine the recoverable state. We propose to identify messages that are not influential in the computation through message semantics. These messages can be logically removed from the computation without changing its meaning or result. In this paper, we illustrate with examples how the removal of these messages improves the theoretical maximal consistent global state. Taking semantics into account, recovery protocols are then developed to realize the idea. The semantics in object-oriented databases is adapted to special processes acting as servers for further improvements. This technique can also be applied to ensure a more timely commitment for output in a distributed computation. fl An abridged version of this paper appears in the Proceedings of the 14th International Conference on Distributed Computing Systems as Using Message Semantics to Reduce Rollback in Optimistic Message Logging Recovery Schemes. y This research is supported in part by the NSF under grant number IRI-9117094. 
Abstract-found: 1
Intro-found: 1
Reference: [AL89] <author> Mustaque Ahamad and Luke Lin. </author> <title> Using checkpoints to localize the effects of faults in distributed systems. </title> <booktitle> In Proceedings of the 9th International Conference on Distributed Computing Systems, </booktitle> <pages> pages 2-11. </pages> <publisher> IEEE, </publisher> <year> 1989. </year>
Reference-contexts: The authors considered reducing the checkpoint dependency based on whether a remote procedure call is state-modifying. They forced a checkpoint to be taken when dependency exists to avoid cascading rollback. They also discussed the dependency developed at a shared server process <ref> [AL89] </ref> (among several groups of independent processes with their own recovery protocol) and restricted the rollback effect by propagating checkpoint requests. Their approach can be considered as semi-synchronous checkpointing. During normal operation, checkpointing is asynchronous. When possible harmful dependency is developed, a checkpoint is forced to be taken on demand. <p> We also do not have to roll back processes whose current state interval is part of the maximal recoverable state, whereas [WF92a] has to, since their notion of recoverable state is at the checkpoint level but not the state interval level. Inspired by <ref> [AL89] </ref>, we examine the server processes and apply richer semantics like commutativity as in [LAA93] on the operations they support while retaining asynchronous checkpointing and asynchronous message logging schemes. The identification of insignificant and weakly significant messages improves the recoverable state.
Reference: [BBG83] <author> A. Borg, J. Baumbach, and S. Glazer. </author> <title> A Message System Supporting Fault Tolerance. </title> <booktitle> In Proceedings of the Ninth ACM Symposium on Operating System Principles, </booktitle> <pages> pages 90-99, </pages> <month> October </month> <year> 1983. </year>
Reference-contexts: This is in general very undesirable. In a database environment, a synchronous checkpoint that has little interference on the normal transactions is achievable [SA89] due to the discrete nature of transactions. Asynchronous checkpoints can be taken independently to reduce the interference to the underlying computation in a synchronous checkpoint <ref> [BL88, BBG83, SY85, JZ90] </ref>. These checkpoints are no longer consistent and the recovery scheme must reconstruct a consistent state from this information after a failure. When a computation is forced to be discarded to maintain system consistency, it is said to be rolled back. <p> To ensure progress in asynchronous checkpointing, the system would maintain additional information on the stable storage, such as the set of messages sent or received by a process. This is called message logging and is adopted in various recovery protocols <ref> [BBG83, SY85, JZ90] </ref>. Pessimistic message logging refers to the logging of a message received before being processed [BBG83]. The advantage of this scheme is the absence of cascading rollback, since there always exists a non-decreasing consistent system state constructible from the most recent checkpoints and the logged messages. <p> This is called message logging and is adopted in various recovery protocols [BBG83, SY85, JZ90]. Pessimistic message logging refers to the logging of a message received before being processed <ref> [BBG83] </ref>. The advantage of this scheme is the absence of cascading rollback, since there always exists a non-decreasing consistent system state constructible from the most recent checkpoints and the logged messages. However, the waiting time for a message to be logged before processing can be significant, compared with the computation.
Reference: [BL88] <author> B. Bhargava and S. Lian. </author> <title> Independent Checkpointing and Concurrent Rollback for Recovery in Distributed Systems|An Optimistic Approach. </title> <booktitle> In Proceedings of the Seventh Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 3-12, </pages> <month> October </month> <year> 1988. </year>
Reference-contexts: This is in general very undesirable. In a database environment, a synchronous checkpoint that has little interference on the normal transactions is achievable [SA89] due to the discrete nature of transactions. Asynchronous checkpoints can be taken independently to reduce the interference to the underlying computation in a synchronous checkpoint <ref> [BL88, BBG83, SY85, JZ90] </ref>. These checkpoints are no longer consistent and the recovery scheme must reconstruct a consistent state from this information after a failure. When a computation is forced to be discarded to maintain system consistency, it is said to be rolled back. <p> When a computation is forced to be discarded to maintain system consistency, it is said to be rolled back. The domino effect of cascading rollback can seriously damage the system performance. The protocol by Bhargava and Lian <ref> [BL88] </ref> rolls back processes only when necessary and does not suffer from the domino effect. It is, however, possible to get rolled back to the very beginning.
Reference: [BSS91] <author> Kenneth Birman, Andre Schiper, and Pat Stephenson. </author> <title> Lightweight causal and atomic group multicast. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 9(3) </volume> <pages> 272-314, </pages> <month> August </month> <year> 1991. </year>
Reference-contexts: Delivery of a buffered message may be delayed to facilitate recovery (for example, log the message in pessimistic message logging), or to satisfy integrity constraints (for example, to ensure causal delivery or atomic delivery <ref> [BSS91] </ref>). Messages sent and received by the recovery protocol are not considered as a part of the underlying computation. The distributed computation is modeled after [JZ90]. Each process P i maintains a count for the number of messages delivered to it.
Reference: [CB91] <author> B. Charron-Bost. </author> <title> Concerning the size of logical clocks in distributed systems. </title> <journal> Information Processing Letter, </journal> <volume> 39(1) </volume> <pages> 11-16, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: This value tracks the direct 4 dependency of messages. If we do not use direct dependency, but use transitive dependency instead, we will have to transmit a vector of size n to maintain valid transitive information. In <ref> [CB91] </ref>, there is a proof on the lower bound of tracking transitive information to be a vector of size n. Transitive dependency is computed only when a state interval becomes stable and the maximal recoverable state is updated.
Reference: [CL85] <author> K. Mani Chandy and Leslie Lamport. </author> <title> Distributed snapshots: Determining global states of distributed systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1) </volume> <pages> 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: The simplest recovery scheme is to checkpoint only consistent system states. Chandy and Lamport <ref> [CL85] </ref> proposed the marker algorithm that always collects a set of consistent system states. Koo and Toueg [KT87] used a two-phase scheme. In these synchronous schemes, recovery is merely the restoration of the most recent checkpoint. Synchronous checkpoints are also taken in distributed transaction processing systems for fault-tolerance [FGL82].
Reference: [FGL82] <author> M. J. Fischer, N. D. Griffeth, and N. A. Lynch. </author> <title> Global States of a Distributed System. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-8(3):198-202, </volume> <month> May </month> <year> 1982. </year>
Reference-contexts: Koo and Toueg [KT87] used a two-phase scheme. In these synchronous schemes, recovery is merely the restoration of the most recent checkpoint. Synchronous checkpoints are also taken in distributed transaction processing systems for fault-tolerance <ref> [FGL82] </ref>. Unfortunately, taking a checkpoint synchronously essentially halts the underlying computation for an extended period and consumes significant communication bandwidth. This is in general very undesirable.
Reference: [HW91] <author> M. P. Herlihy and W. E. Weihl. </author> <title> Hybrid Concurrency Control for Abstract Data Types. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 43(1) </volume> <pages> 25-61, </pages> <month> August </month> <year> 1991. </year> <booktitle> Special issue on the 7th Annual ACM SIGACT-SIGMOD Symposium on the Principles of Database Systems, </booktitle> <month> March 21-23, </month> <year> 1988. </year>
Reference-contexts: These special processes deserve our attention since they admit further optimization that is not possible with mere detection of insignificant messages. Lessons learned from the database community in utilizing abstract data types (objects) to improve the level of concurrency in concurrency control protocols <ref> [HW91, Wei89] </ref> enable us to apply such methodologies on objects in general. Servers are objects, as they exhibit the same unique request/response pattern. They serialize concurrent requests by placing them in a queue or a bag, and serve them one by one sequentially.
Reference: [JZ90] <author> D. B. Johnson and W. Zwaenepoel. </author> <title> Recovery in Distributed Systems. </title> <journal> Journal of Algorithms, </journal> <volume> 11(3) </volume> <pages> 462-491, </pages> <month> September </month> <year> 1990. </year> <note> Preliminary version in PODC 1988. </note>
Reference-contexts: This is in general very undesirable. In a database environment, a synchronous checkpoint that has little interference on the normal transactions is achievable [SA89] due to the discrete nature of transactions. Asynchronous checkpoints can be taken independently to reduce the interference to the underlying computation in a synchronous checkpoint <ref> [BL88, BBG83, SY85, JZ90] </ref>. These checkpoints are no longer consistent and the recovery scheme must reconstruct a consistent state from this information after a failure. When a computation is forced to be discarded to maintain system consistency, it is said to be rolled back. <p> To ensure progress in asynchronous checkpointing, the system would maintain additional information on the stable storage, such as the set of messages sent or received by a process. This is called message logging and is adopted in various recovery protocols <ref> [BBG83, SY85, JZ90] </ref>. Pessimistic message logging refers to the logging of a message received before being processed [BBG83]. The advantage of this scheme is the absence of cascading rollback, since there always exists a non-decreasing consistent system state constructible from the most recent checkpoints and the logged messages. <p> The catch is that the recovery protocol becomes more complicated. Strom and Yemini [SY85] were the first to propose such a class of protocols, but their protocol suffers from cascading rollbacks, the number of which could be exponential in the number of processes. Johnson and Zwaenepoel <ref> [JZ90] </ref> developed a formal model and eliminated cascading rollback with a centralized protocol. Sistla and Welch [SW89] subsequently improved over [JZ90] by imposing stronger assumptions and developed fully distributed protocols. Reducing message logging improves the performance of an optimistic scheme. <p> Johnson and Zwaenepoel <ref> [JZ90] </ref> developed a formal model and eliminated cascading rollback with a centralized protocol. Sistla and Welch [SW89] subsequently improved over [JZ90] by imposing stronger assumptions and developed fully distributed protocols. Reducing message logging improves the performance of an optimistic scheme. Wang and Fuchs [WF92a] therefore introduced the notion of non-state messages. <p> Consequently the amount of rollback and recomputation after a failure is reduced. Thus we can achieve comparable performance in the absence of failure, and faster recovery after a failure than Johnson and Zwaenepoel's protocol <ref> [JZ90] </ref>. It is not necessary to log an insignificant message in our scheme, resulting in a small saving in computation. This paper is organized as follows. Section 2 gives a description of the model with some examples. In Section 3, the centralized recovery protocol is briefly described. <p> Messages sent and received by the recovery protocol are not considered as a part of the underlying computation. The distributed computation is modeled after <ref> [JZ90] </ref>. Each process P i maintains a count for the number of messages delivered to it. This count defines a state interval on P i . <p> A global state S is consistent if and only if for all i and j, D S [i; i] D S [j; i] <ref> [JZ90] </ref>. In other words, a global state is consistent when all state intervals in the global state do not depend on any state interval not contained in the global state. A consistent global state S is recoverable if all state intervals ffi i i are stable. <p> In our scheme, recovery is done by restoring a maximal recoverable state, which always exists. 3 A Centralized Recovery Protocol The centralized message logging and recovery protocol is described in <ref> [JZ90] </ref> and is summarized here. Messages delivered are logged asynchronously with respect to processing of the message. Checkpoints are also taken independently and occasionally. As more and more messages are logged and checkpoints are taken, new state intervals become stable. <p> Even worse, as P 2 becomes orphan, m 4 and m 5 also become orphan. As a result, P 3 and P 4 become orphan processes. This mishap is manifested by a cascading rollback in Strom and Yemini's protocol [SY85]. In Johnson and Zwaenepoel's protocol <ref> [JZ90] </ref>, the recoverable state remains unchanged, even as more and more state intervals in P 2 ; P 3 and P 4 become stable. But this can be improved. Suppose P 2 is a shared memory object accepting read and write messages. <p> ii 1 (**) while ctr [t] = 0 do class [t] insig; t t 1 /* for all previous intervals with no message sent */ (**) endif (**) end When state interval k i becomes stable: send the dependency vector to the coordinator The modified recovery protocol is similar to <ref> [JZ90] </ref>. The differences are the maintenance of extra infor 7 mation to facilitate the detection of insignificant messages, the actual identification of these messages after a failure and the logical removal of these messages. <p> It identifies insignificant messages and computes a new state interval. Normal operation when stable state interval k i is received: try to include the stable state interval into the current recoverable state RS to form a better one, as in <ref> [JZ90] </ref> After a failure: begin receive the new stable state intervals from all non-failed processes, and information about insignificant messages form a recoverable state from available stable state intervals determine the reversed message dependency on all messages beyond the current recoverable state perform a topological sort on the above messages foreach <p> Due to the asynchrony of background stable intervals exchange, each process may reach a different recoverable state. This does no harm for the purpose of committing output, since the structure of maximal recoverable system state forms a lattice <ref> [JZ90] </ref>. The current maximal recoverable state dominates the least upper bound of all the local recoverable states computed by the processes. Thus the local version of the recoverable state is good enough to guarantee that no rollback is possible beyond the output commitment point. <p> Cascading rollback is limited by the existence of a nondecreasing maximal recoverable state and also by the number 2 n 1. In the <ref> [JZ90] </ref> protocol, the failure-free overhead is O (1) per application message and the exponential number of recovery messages caused by cascading rollback in the [SY85] protocol manifests itself as a prolonged computation inside the main loop in the computation of the recoverable state by the coordinator. <p> Failure-free protocol message complexity would then be O (a 0 n 2 ). Our protocol is based on <ref> [JZ90] </ref> and has the same message complexity of O (a 0 n), where the factor of a is amortized in the same way over batch size and number of recoverable state computation. <p> In the worst case, the total number of failure-free protocol messages is within a factor of 2 with respect to <ref> [JZ90] </ref>. The size of each protocol message is also doubled. This factor of 2 in the number of messages comes from the 17 reporting of the status of insignificant messages. When the state intervals are reported to the coordinator to be stable, the status of the messages is also reported. <p> We extend the basic <ref> [JZ90] </ref> protocol to encompass the detection of insignificant messages and show how to use this information to improve the recoverable global state, thus reducing the amount of rollback required after a failure. Extending the model to include client-server model leads to the definition of weakly significant messages. <p> During normal operation, checkpointing is asynchronous. When possible harmful dependency is developed, a checkpoint is forced to be taken on demand. This would increase the failure-free overhead. To avoid harmful dependencies, artificial delaying of message delivery is adopted in [WF92b]. Our approach, based on the formal model of <ref> [JZ90] </ref>, for insignificant message detection is completely asynchronous. We also do not have to roll back processes whose current state interval is part of the maximal recoverable state, whereas [WF92a] has to, since their notion of recoverable state is at the checkpoint level but not the state interval level. <p> This will incur more computation overheads even when there is no failure because it is necessary to perform the computation more often. However, the same tradeoff has to be made in all optimistic message logging schemes, including <ref> [SW89, JZ90] </ref>, to commit output. Traditional definitions of consistent global state and recoverable global state have been focused only on the dependency of messages and fail to capture properties of the underlying messages.
Reference: [Kor83] <author> H. F. Korth. </author> <title> Locking primitives in a database system. </title> <journal> Journal of the ACM, </journal> <volume> 30(1) </volume> <pages> 55-79, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: As a comparison purpose, the commutativity relation for the bounded counter object is shown in Table 3, which is stronger than the corresponding right backward commutativity relation. The notion of commutativity when the response of an operation is taken into account is an extension from the original definition in <ref> [Kor83] </ref>. State equivalence and validity of operations are required.
Reference: [KT87] <author> R. Koo and S. Toueg. </author> <title> Checkpointing and Rollback-Recovery for Distributed Systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(1):23-31, </volume> <month> January </month> <year> 1987. </year>
Reference-contexts: The simplest recovery scheme is to checkpoint only consistent system states. Chandy and Lamport [CL85] proposed the marker algorithm that always collects a set of consistent system states. Koo and Toueg <ref> [KT87] </ref> used a two-phase scheme. In these synchronous schemes, recovery is merely the restoration of the most recent checkpoint. Synchronous checkpoints are also taken in distributed transaction processing systems for fault-tolerance [FGL82].
Reference: [LA90] <author> Luke Lin and Mustaque Ahamad. </author> <title> Checkpointing and rollback-recovery in distributed object based systems. </title> <booktitle> In Proceedings of the 20th International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 97-104. </pages> <publisher> IEEE, </publisher> <year> 1990. </year>
Reference-contexts: Extending the model to include client-server model leads to the definition of weakly significant messages. Considering them in the computation further improves the recoverable state. The issue of exploiting message semantics were discussed in <ref> [LA90] </ref>. The authors considered reducing the checkpoint dependency based on whether a remote procedure call is state-modifying. They forced a checkpoint to be taken when dependency exists to avoid cascading rollback.
Reference: [LAA93] <author> H.V. Leong, D. Agrawal, and J.R. Agre. </author> <title> Using message semantics to reduce rollback in the time warp mechanism. </title> <booktitle> In Proceedings of the 7th International Workshop on Distributed Algorithms, </booktitle> <pages> pages 309-323. </pages> <publisher> LNCS, </publisher> <month> September </month> <year> 1993. </year>
Reference-contexts: Note that this definition of right backward commutativity is 13 not symmetric, whereas the usual definition of commutativity (described above) is symmetric. The formal definition can be found in [Wei89] and an alternative definition in <ref> [LAA93] </ref>. <p> Inspired by [AL89], we examine the server processes and apply richer semantics like commutativity as in <ref> [LAA93] </ref> on the operations they support while retaining asynchronous checkpointing and asynchronous message logging schemes. The identification of insignificant and weakly significant messages improves the recoverable state.
Reference: [Lam78] <author> Leslie Lamport. </author> <title> Time, clocks, and the ordering of events in a distributed system. </title> <journal> Communications of the ACM, </journal> <volume> 21(7) </volume> <pages> 558-565, </pages> <month> July </month> <year> 1978. </year>
Reference-contexts: It is clear that message m 3 depends on m 6 , since it is sent in the state interval that m 6 creates. Similarly, message m 1 depends on m 3 . Furthermore, the program order on the delivery events dictates that m 7 happens-before m 8 <ref> [Lam78] </ref>.
Reference: [NT90] <author> G. Neiger and S. Toueg. </author> <title> Automatically increasing the fault-tolerance of distributed algorithms. </title> <journal> Journal of Algorithms, </journal> <volume> 11(3) </volume> <pages> 374-419, </pages> <year> 1990. </year> <month> 19 </month>
Reference-contexts: This complicates the strategies to ensure consistency and integrity of the system when a failure occurs. The fault-tolerance in a computer system that fails by stopping [SS83] can be achieved by a checkpointing mechanism and a recovery mechanism. Neiger and Toueg <ref> [NT90] </ref> showed that all other types of failures can be translated to fail-stop failure with a sufficient amount of redundant resources. A checkpoint is the system states of one or more processes that are stored on stable storage that can survive processor crashes.
Reference: [SA89] <author> S. H. Son and A. K. Agrawala. </author> <title> Distributed Checkpointing for Globally Consistent States of Databases. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 15(10) </volume> <pages> 1157-1167, </pages> <month> October </month> <year> 1989. </year>
Reference-contexts: Unfortunately, taking a checkpoint synchronously essentially halts the underlying computation for an extended period and consumes significant communication bandwidth. This is in general very undesirable. In a database environment, a synchronous checkpoint that has little interference on the normal transactions is achievable <ref> [SA89] </ref> due to the discrete nature of transactions. Asynchronous checkpoints can be taken independently to reduce the interference to the underlying computation in a synchronous checkpoint [BL88, BBG83, SY85, JZ90].
Reference: [SS83] <author> Richard D. Schlichting and Fred B. Schneider. </author> <title> Fail-stop processors: An approach to designing fault-tolerant computing systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 1(3) </volume> <pages> 222-238, </pages> <month> August </month> <year> 1983. </year>
Reference-contexts: Usually the components in a distributed system fail in an independent manner. This complicates the strategies to ensure consistency and integrity of the system when a failure occurs. The fault-tolerance in a computer system that fails by stopping <ref> [SS83] </ref> can be achieved by a checkpointing mechanism and a recovery mechanism. Neiger and Toueg [NT90] showed that all other types of failures can be translated to fail-stop failure with a sufficient amount of redundant resources.
Reference: [SW89] <author> A. P. Sistla and J. L. Welch. </author> <title> Efficient Distributed Recovery Using Message Logging. </title> <booktitle> In Proceedings of the Eighth Annual ACM Symposium on Principles of Distributed Computing, </booktitle> <pages> pages 223-238, </pages> <month> August </month> <year> 1989. </year>
Reference-contexts: Johnson and Zwaenepoel [JZ90] developed a formal model and eliminated cascading rollback with a centralized protocol. Sistla and Welch <ref> [SW89] </ref> subsequently improved over [JZ90] by imposing stronger assumptions and developed fully distributed protocols. Reducing message logging improves the performance of an optimistic scheme. Wang and Fuchs [WF92a] therefore introduced the notion of non-state messages. <p> Then 8 i depends on both 3 j as well as 2 j . This second part of the requirement takes into account non-FIFO messages (which is not allowed in the model of <ref> [SW89] </ref>). Define the dependency vector of k i to be D k i = hd 1 ; d 2 ; :::; d n i such that for all j, k i directly depends on d j j . Every state interval directly depends on itself and d i = k. <p> Assuming computation is much faster than communication, we can concentrate on the message overhead, on both message size and message count. We call the messages of the underlying computation application messages and the messages of the recovery protocol protocol messages. Sistla and Welch <ref> [SW89] </ref> developed distributed recovery protocols based on a more restrictive system model. In particular, they assumed that the message delivery mechanism is reliable and ensures FIFO ordering. Messages are logged asynchronously in the sequential order they are received. <p> This will incur more computation overheads even when there is no failure because it is necessary to perform the computation more often. However, the same tradeoff has to be made in all optimistic message logging schemes, including <ref> [SW89, JZ90] </ref>, to commit output. Traditional definitions of consistent global state and recoverable global state have been focused only on the dependency of messages and fail to capture properties of the underlying messages.
Reference: [SY85] <author> R. Strom and S. Yemini. </author> <title> Optimistic Recovery in Distributed Systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(3) </volume> <pages> 205-226, </pages> <month> August </month> <year> 1985. </year>
Reference-contexts: This is in general very undesirable. In a database environment, a synchronous checkpoint that has little interference on the normal transactions is achievable [SA89] due to the discrete nature of transactions. Asynchronous checkpoints can be taken independently to reduce the interference to the underlying computation in a synchronous checkpoint <ref> [BL88, BBG83, SY85, JZ90] </ref>. These checkpoints are no longer consistent and the recovery scheme must reconstruct a consistent state from this information after a failure. When a computation is forced to be discarded to maintain system consistency, it is said to be rolled back. <p> To ensure progress in asynchronous checkpointing, the system would maintain additional information on the stable storage, such as the set of messages sent or received by a process. This is called message logging and is adopted in various recovery protocols <ref> [BBG83, SY85, JZ90] </ref>. Pessimistic message logging refers to the logging of a message received before being processed [BBG83]. The advantage of this scheme is the absence of cascading rollback, since there always exists a non-decreasing consistent system state constructible from the most recent checkpoints and the logged messages. <p> Optimistic message logging allows messages to be processed independent of when they are logged, in an asynchronous manner. In the absence of failure, the only overhead is the asynchronous logging of messages by a background process. The catch is that the recovery protocol becomes more complicated. Strom and Yemini <ref> [SY85] </ref> were the first to propose such a class of protocols, but their protocol suffers from cascading rollbacks, the number of which could be exponential in the number of processes. Johnson and Zwaenepoel [JZ90] developed a formal model and eliminated cascading rollback with a centralized protocol. <p> Even worse, as P 2 becomes orphan, m 4 and m 5 also become orphan. As a result, P 3 and P 4 become orphan processes. This mishap is manifested by a cascading rollback in Strom and Yemini's protocol <ref> [SY85] </ref>. In Johnson and Zwaenepoel's protocol [JZ90], the recoverable state remains unchanged, even as more and more state intervals in P 2 ; P 3 and P 4 become stable. But this can be improved. Suppose P 2 is a shared memory object accepting read and write messages. <p> The failure-free overhead for the <ref> [SY85] </ref> protocol is O (n) per message. The size of a recovery message is O (1). However, the number of recovery messages is dependent on the execution status, and in the worst case, it is exponential O (2 n ) due to cascading rollback. <p> Cascading rollback is limited by the existence of a nondecreasing maximal recoverable state and also by the number 2 n 1. In the [JZ90] protocol, the failure-free overhead is O (1) per application message and the exponential number of recovery messages caused by cascading rollback in the <ref> [SY85] </ref> protocol manifests itself as a prolonged computation inside the main loop in the computation of the recoverable state by the coordinator. The number of recovery messages, each of constant size, is O (n): n 1 to collect the stable state interval index and n 1 to announce the result.
Reference: [Wei89] <author> William E. Weihl. </author> <title> The impact of recovery on concurrency control. </title> <booktitle> In Proceedings of the 8th ACM Annual Symposium on Principles of Database Systems, </booktitle> <pages> pages 259-269. </pages> <publisher> ACM, </publisher> <year> 1989. </year>
Reference-contexts: These special processes deserve our attention since they admit further optimization that is not possible with mere detection of insignificant messages. Lessons learned from the database community in utilizing abstract data types (objects) to improve the level of concurrency in concurrency control protocols <ref> [HW91, Wei89] </ref> enable us to apply such methodologies on objects in general. Servers are objects, as they exhibit the same unique request/response pattern. They serialize concurrent requests by placing them in a queue or a bag, and serve them one by one sequentially. <p> Commutativity is too strong a requirement in our application in this section. We should opt for a weaker notion that would enable us to do the same kind of improvement. The notion of right backward commutativity <ref> [Wei89] </ref> is particularly useful. Informally, we say that an operation q right commutes backward with another operation p, if whenever q can be executed at the state after p has been executed, it is possible to swap these two operations so that q is executed before p. <p> Furthermore, the final states of execution in either q after p or p after q are identical. Note that this definition of right backward commutativity is 13 not symmetric, whereas the usual definition of commutativity (described above) is symmetric. The formal definition can be found in <ref> [Wei89] </ref> and an alternative definition in [LAA93].
Reference: [WF92a] <author> Yi-Min Wang and W. Kent Fuchs. </author> <title> Optimistic message logging for independent checkpointing in message-passing systems. </title> <booktitle> In Proceedings of the 11th IEEE Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 147-154. </pages> <publisher> IEEE, </publisher> <year> 1992. </year>
Reference-contexts: Johnson and Zwaenepoel [JZ90] developed a formal model and eliminated cascading rollback with a centralized protocol. Sistla and Welch [SW89] subsequently improved over [JZ90] by imposing stronger assumptions and developed fully distributed protocols. Reducing message logging improves the performance of an optimistic scheme. Wang and Fuchs <ref> [WF92a] </ref> therefore introduced the notion of non-state messages. The recoverable state is limited to the most recent set of consistent checkpoints and message logging is used to recover lost messages. <p> Our approach, based on the formal model of [JZ90], for insignificant message detection is completely asynchronous. We also do not have to roll back processes whose current state interval is part of the maximal recoverable state, whereas <ref> [WF92a] </ref> has to, since their notion of recoverable state is at the checkpoint level but not the state interval level.
Reference: [WF92b] <author> Yi-Min Wang and W. Kent Fuchs. </author> <title> Scheduling message processing for reducing rollback propagation. </title> <booktitle> In Proceedings of the 22nd International Symposium on Fault-Tolerant Computing, </booktitle> <pages> pages 204-211. </pages> <publisher> IEEE, </publisher> <year> 1992. </year> <month> 20 </month>
Reference-contexts: Their approach can be considered as semi-synchronous checkpointing. During normal operation, checkpointing is asynchronous. When possible harmful dependency is developed, a checkpoint is forced to be taken on demand. This would increase the failure-free overhead. To avoid harmful dependencies, artificial delaying of message delivery is adopted in <ref> [WF92b] </ref>. Our approach, based on the formal model of [JZ90], for insignificant message detection is completely asynchronous.
References-found: 22

