URL: http://www.cs.nyu.edu/phd_students/wyckoff/charlotte.ps
Refering-URL: http://www.cs.nyu.edu/phd_students/wyckoff/index.html
Root-URL: http://www.cs.nyu.edu
Title: Charlotte: Metacomputing on the Web  
Author: Arash Baratloo Mehmet Karaul Zvi Kedem Peter Wyckoff 
Keyword: Metacomputing, Distributed Computing, Parallel Programming Environments, World Wide Web.  
Date: April 23, 1997  
Address: New York University New York, NY 10012, USA  
Affiliation: Department of Computer Science Courant Institute of Mathematical Sciences  
Abstract: The World Wide Web has the potential of being used as an inexpensive and convenient metacomputing resource. This brings forward new challenges and invalidates many of the assumptions made in offering the same functionality for a network of workstations. We have designed and implemented Charlotte which goes beyond providing a set of features commonly used for a network of workstations: (1) a user can execute a parallel program on a machine she does not have an account on; (2) neither a shared file system nor a copy of the program on the local file system is required; (3) local hardware is protected from programs written by strangers; (4) any machine on the Web can join or leave any running computation, thus utilizing the dynamic resources. Charlotte combines many complementary but isolated research efforts. It comprises a virtual machine model which isolates the program from the execution environment, and a runtime system which realizes this model on the Web. Load balancing and fault masking are provided by the runtime system transparent to the programmer. Charlotte provides distributed shared memory without relying on operating system or compiler support. It is implemented soley in Java without any native code, thus providing the same level of security, heterogeneity, and portability as Java. In this paper, we describe the design and implementation of Charlotte and present initial performance results. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Aumann, Z. Kedem, K. Palem, and M. Rabin. </author> <title> Highly efficient asynchronous execution of large-grained parallel programs. </title> <booktitle> In Proc. of 34th IEEE Annual Symposium on Foundations of Computer Science, </booktitle> <year> 1993. </year>
Reference-contexts: No system currently addresses all or even a majority of these. In this paper, we present a system called Charlotte that addresses these issues. The research leading to our system started as a theoretical work where provable methods for executing parallel computations on abstract asynchronous processors were developed <ref> [12, 1] </ref>. The outline of the virtual machine interface to actual system was proposed in [11]. Theoretical results were then interpreted in the context of networks of workstations in [5]. The above were significantly extended and validated in the Calypso [2] system for homogeneous networks.
Reference: [2] <author> A. Baratloo, P. Dasgupta, and Z. Kedem. Calypso: </author> <title> A novel software system for fault-tolerant parallel processing on distributed platforms. </title> <booktitle> In Proc. of IEEE International Symposium on High-Performance Distributed Computing, </booktitle> <year> 1995. </year>
Reference-contexts: The outline of the virtual machine interface to actual system was proposed in [11]. Theoretical results were then interpreted in the context of networks of workstations in [5]. The above were significantly extended and validated in the Calypso <ref> [2] </ref> system for homogeneous networks. Charlotte builds on these and other complementary research efforts by offering a unified programming and execution environment for the Web. <p> In Charlotte, we achieve both. 5.1 Existing Techniques There have been two approaches to implement DSM at the software level: one relies on virtual memory page protection and the other on a compiler to provide software write detection. Traditional software-based shared memory systems rely on virtual memory page protection <ref> [14, 2, 13] </ref>. Detection of a data access is done by protecting the memory pages and catching the page-fault signal generated by the operating system. A write operation sets a dirty-bit for each page, indicating that the change needs to be propagated.
Reference: [3] <author> R. Blumofe, C. Joerg, B. Kuszmaul, C. Leiserson, K. Randall, A. Shaw, and Y. Zhou. Cilk: </author> <title> An Efficient Multithreaded Runtime System. </title> <booktitle> In Proc. Symposium on Principals and Practice of Parallel Programming, </booktitle> <year> 1995. </year>
Reference-contexts: These factors severely limit their use as an interface to a metacomputing framework on the Web. Another class of systems for distributed computing focuses on providing distributed shared memory (DSM) across loosely-coupled machines. IVY [14] and TreadMarks [13] are representatives of DSM systems. Cilk <ref> [3] </ref> is a comprehensive system providing resource management and fault-tolerance in addition to DSM. However, it makes similar assumptions about the file system and user privileges as message passing 3 systems, which again, limits its applicability to the Web.
Reference: [4] <author> N. Biggs. </author> <title> Interaction models: </title> <institution> Course given at Royal Hollaway College, University of London. Cam-bridge University Press, </institution> <year> 1977. </year>
Reference-contexts: However, Java compilers, due to be released later this year, will provide performance much closer to C. We expect our results to carry over. 10 We chose a scientific application from statistical physicscomputing the 3D Ising model <ref> [4] </ref>. This is a simplified model of magnets on a three dimensional lattice which can be used to describe qualitatively how small systems behave. Computing the Ising model involves an exponential number of independent tasks and very little data movement. We performed three experiments.
Reference: [5] <author> P. Dasgupta, Z. Kedem, and M. Rabin. </author> <title> Parallel processing on networks of workstations: A fault-tolerant, high performance approach. </title> <booktitle> In Proc. of the 15th International Conference on Distributed Computing Systems, </booktitle> <year> 1995. </year>
Reference-contexts: The outline of the virtual machine interface to actual system was proposed in [11]. Theoretical results were then interpreted in the context of networks of workstations in <ref> [5] </ref>. The above were significantly extended and validated in the Calypso [2] system for homogeneous networks. Charlotte builds on these and other complementary research efforts by offering a unified programming and execution environment for the Web.
Reference: [6] <author> D. Dean, E. Felten, and D. Wallach. </author> <title> Java Security: From HotJava to Netscape and Beyond. </title> <booktitle> To appear in Proc. IEEE Symposium on Security and Privacy, </booktitle> <year> 1996. </year>
Reference-contexts: We plan to automate this feature by relying on manager lookup services. 7 Since Charlotte is entirely implemented in Java, it provides the same security guarantees as Java. Java guarantees the protection of local resources from programs. Although there seem to be security holes in the current implementation <ref> [6] </ref>, there are strong indications that this will be solved. Charlotte will transparently take advantage of these improvements.
Reference: [7] <author> Electric Communities. </author> <title> The E Programming language. </title> <note> Available at http://www.communities.com/e/ epl.html. </note>
Reference-contexts: In addition, DSM systems in general, do not work on heterogeneous environments. Recently, with the introduction of Java, another class of systems is becoming available. HORB [17] and the E programming language <ref> [7] </ref> are two such examples. HORB is a distributed Object Oriented system. It extends Java with a well understood programming model, RPC, and persistent objects. Charlotte and HORB are similar in that they both utilize Java in providing heterogeneity, interoperability, and security.
Reference: [8] <author> P. Guedes and M. </author> <title> Castro. </title> <booktitle> Distributed Shared Object Memory . In Proc. of the Fourth Workshop on Workstation Operating Systems (now HotOS), </booktitle> <year> 1993. </year>
Reference-contexts: On the other hand, it requires that the system continuously evolves with the language it is based on. Charlotte's shared memory abstraction is neither operating system nor compiler based. We were introduced to the feasability of object-based shared memory by the work in <ref> [8] </ref>, and to the feasability of software write detection by the work in [19]. However, rather than using a compiler, we chose to realize shared memory abstraction through shared name-space.
Reference: [9] <author> W. Gropp, E. Lusk, and A. Skjellum. </author> <title> Using MPI: Portable Parallel Programming with the Message-Passing-Interface. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: The virtual machine model provides a reliable shared memory machine to the programmer and isolates the program from the execution environment. The run-time system realizes this model on a set of unpredictable, dynamically changing, and faulty machines. 2 Related Work PVM [18] and MPI <ref> [9] </ref> are representatives of message passing systems. They provide portability and good performance, but they are low level. Systems such as CARMI [16] and [10] augment PVM's functionality by providing resource management services.
Reference: [10] <author> J. Ju and Y. Wang. </author> <title> Scheduling PVM Tasks. </title> <booktitle> Operating Systems Review, </booktitle> <month> July </month> <year> 1996. </year>
Reference-contexts: The run-time system realizes this model on a set of unpredictable, dynamically changing, and faulty machines. 2 Related Work PVM [18] and MPI [9] are representatives of message passing systems. They provide portability and good performance, but they are low level. Systems such as CARMI [16] and <ref> [10] </ref> augment PVM's functionality by providing resource management services.
Reference: [11] <author> Z. Kedem and K. Palem. </author> <title> Transformations for the automatic dirivation of resilient parallel programs. </title> <booktitle> In Proc. of IEEE Workshop on Fault-Tolerant Parallel and Distributed Systems, </booktitle> <year> 1992. </year> <month> 12 </month>
Reference-contexts: The research leading to our system started as a theoretical work where provable methods for executing parallel computations on abstract asynchronous processors were developed [12, 1]. The outline of the virtual machine interface to actual system was proposed in <ref> [11] </ref>. Theoretical results were then interpreted in the context of networks of workstations in [5]. The above were significantly extended and validated in the Calypso [2] system for homogeneous networks. Charlotte builds on these and other complementary research efforts by offering a unified programming and execution environment for the Web.
Reference: [12] <author> Z. Kedem, K. Palem, and P. Spirakis. </author> <title> Efficient robust parallel computations. </title> <booktitle> In Proc. of 22nd ACM Symposium on Theory of Computing, </booktitle> <year> 1990. </year>
Reference-contexts: No system currently addresses all or even a majority of these. In this paper, we present a system called Charlotte that addresses these issues. The research leading to our system started as a theoretical work where provable methods for executing parallel computations on abstract asynchronous processors were developed <ref> [12, 1] </ref>. The outline of the virtual machine interface to actual system was proposed in [11]. Theoretical results were then interpreted in the context of networks of workstations in [5]. The above were significantly extended and validated in the Calypso [2] system for homogeneous networks.
Reference: [13] <author> P. Keleher, S. Dwarkadas, A. Cox, and W. Zwaenepoel. TreadMarks: </author> <title> Distributed shared memory on standard workstations and operating systems. </title> <booktitle> In Proc. of the Winter USENIX Conference, </booktitle> <year> 1991. </year>
Reference-contexts: These factors severely limit their use as an interface to a metacomputing framework on the Web. Another class of systems for distributed computing focuses on providing distributed shared memory (DSM) across loosely-coupled machines. IVY [14] and TreadMarks <ref> [13] </ref> are representatives of DSM systems. Cilk [3] is a comprehensive system providing resource management and fault-tolerance in addition to DSM. However, it makes similar assumptions about the file system and user privileges as message passing 3 systems, which again, limits its applicability to the Web. <p> In Charlotte, we achieve both. 5.1 Existing Techniques There have been two approaches to implement DSM at the software level: one relies on virtual memory page protection and the other on a compiler to provide software write detection. Traditional software-based shared memory systems rely on virtual memory page protection <ref> [14, 2, 13] </ref>. Detection of a data access is done by protecting the memory pages and catching the page-fault signal generated by the operating system. A write operation sets a dirty-bit for each page, indicating that the change needs to be propagated.
Reference: [14] <author> K. Li. IVY: </author> <title> A Shared Virtual Memory System for Parallel Computing. </title> <booktitle> In Proc. International Conference on Parallel Processing, </booktitle> <year> 1988. </year>
Reference-contexts: These factors severely limit their use as an interface to a metacomputing framework on the Web. Another class of systems for distributed computing focuses on providing distributed shared memory (DSM) across loosely-coupled machines. IVY <ref> [14] </ref> and TreadMarks [13] are representatives of DSM systems. Cilk [3] is a comprehensive system providing resource management and fault-tolerance in addition to DSM. However, it makes similar assumptions about the file system and user privileges as message passing 3 systems, which again, limits its applicability to the Web. <p> In Charlotte, we achieve both. 5.1 Existing Techniques There have been two approaches to implement DSM at the software level: one relies on virtual memory page protection and the other on a compiler to provide software write detection. Traditional software-based shared memory systems rely on virtual memory page protection <ref> [14, 2, 13] </ref>. Detection of a data access is done by protecting the memory pages and catching the page-fault signal generated by the operating system. A write operation sets a dirty-bit for each page, indicating that the change needs to be propagated.
Reference: [15] <author> D. Mosberger. </author> <title> Memory Consistency Models. </title> <type> Technical Report number TR92/11, </type> <institution> University of Ari-zona, </institution> <year> 1992. </year>
Reference-contexts: Since Java prohibits operator overloading, distributed objects are accessed and modified with explicit function calls ( get () and set ()). The consistency and coherence of the distributed data is maintained by the runtime system. In an attempt to improve performance, many DSM systems have introduced multiple memory-consistency semantics <ref> [15] </ref>. The decision as to which consistency model is best suited for a particular application is left to the programmer. We feel this generally complicates a task the researchers were seeking to simplify. In Charlotte, we provide a single and intuitive memory semantics: Concurrent Read and Exclusive Write (CR&EW).
Reference: [16] <author> J. Pruyne and M. Livny. </author> <title> Parallel Processing on Dynamic Resources with CARMI. </title> <booktitle> In Proc. of the Workshop on Job Scheduling Strategies for Parallel Processing, </booktitle> <year> 1995. </year>
Reference-contexts: The run-time system realizes this model on a set of unpredictable, dynamically changing, and faulty machines. 2 Related Work PVM [18] and MPI [9] are representatives of message passing systems. They provide portability and good performance, but they are low level. Systems such as CARMI <ref> [16] </ref> and [10] augment PVM's functionality by providing resource management services.
Reference: [17] <author> H. Satoshi. </author> <title> The Magic Carpet for Network Computing: </title> <note> HORB Flyer's Guide. Available at http://ring.etl. go.jp/openlab/horb/doc/guide/guide.html. </note>
Reference-contexts: In addition, DSM systems in general, do not work on heterogeneous environments. Recently, with the introduction of Java, another class of systems is becoming available. HORB <ref> [17] </ref> and the E programming language [7] are two such examples. HORB is a distributed Object Oriented system. It extends Java with a well understood programming model, RPC, and persistent objects. Charlotte and HORB are similar in that they both utilize Java in providing heterogeneity, interoperability, and security.
Reference: [18] <author> V. Sunderam, G. Geist, J. Dongarra, and R. Manchek. </author> <title> The PVM concurrent computing system: Evolution, experiences, </title> <booktitle> and trends. Parallel Computing, </booktitle> <year> 1994. </year>
Reference-contexts: The virtual machine model provides a reliable shared memory machine to the programmer and isolates the program from the execution environment. The run-time system realizes this model on a set of unpredictable, dynamically changing, and faulty machines. 2 Related Work PVM <ref> [18] </ref> and MPI [9] are representatives of message passing systems. They provide portability and good performance, but they are low level. Systems such as CARMI [16] and [10] augment PVM's functionality by providing resource management services.
Reference: [19] <author> M. Zekauska, W. Sawdon, and B. Bershad. </author> <title> Software Write Detection for a Distributed Shared Memory. </title> <booktitle> In Proc. of Symposium on OSDI, </booktitle> <year> 1994. </year> <month> 13 </month>
Reference-contexts: Since page size and data format vary across different machines and operating systems, this is not a viable option for a heterogeneous environment such as the Web. Another technique to implement DSM relies on compiler and runtime support <ref> [19] </ref>. A compiler inserts the necessary code to detect and service an access to the shared memory region. This approach has the advantage that the granularity can be controlled, meaning that it alleviates false sharing. <p> Charlotte's shared memory abstraction is neither operating system nor compiler based. We were introduced to the feasability of object-based shared memory by the work in [8], and to the feasability of software write detection by the work in <ref> [19] </ref>. However, rather than using a compiler, we chose to realize shared memory abstraction through shared name-space.
References-found: 19

