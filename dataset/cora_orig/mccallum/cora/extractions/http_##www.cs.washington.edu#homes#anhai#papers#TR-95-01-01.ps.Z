URL: http://www.cs.washington.edu/homes/anhai/papers/TR-95-01-01.ps.Z
Refering-URL: http://www.cs.washington.edu/homes/anhai/anhai-cv.html
Root-URL: 
Title: Decision-Theoretic Refinement Planning: Principles and Application  
Author: AnHai Doan and Peter Haddawy 
Address: PO Box 784 Milwaukee, WI 53201  
Affiliation: Department of Electrical Engineering and Computer Science University of Wisconsin-Milwaukee  
Pubnum: Technical Report TR-95-01-01  
Email: fanhai, haddawyg@cs.uwm.edu  
Phone: 414 229-4955  
Date: February 11, 1995  
Abstract: We present a general theory of action abstraction for reducing the complexity of decision-theoretic planning. We develop projection rules for abstract actions and prove our abstraction techniques to be correct. We present a planning algorithm that uses the abstraction theory to efficiently explore the space of possible plans by eliminating suboptimal classes of plans without explicitly examining all plans in those classes. An instance of the algorithm has been implemented as the drips decision-theoretic refinement planning system. We apply the planner to the problem of selecting the optimal test/treat strategy for managing patients suspected of having deep-vein thrombosis of the lower extremities. We show that drips significantly outperforms a standard branch-and-bound decision tree evaluation algorithm on this domain. fl We would like to thank Charles Kahn for pointing us to the DVT application. This work was partially supported by NSF grant IRI-9207262. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> C. Boutilier and R. Dearden. </author> <title> Using abstractions for decision-theoretic planning with time constraints. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1016-1022, </pages> <address> Seattle, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: Lower and upper probabilities, LP and U P , are functions mapping from 2 into <ref> [0; 1] </ref> such that for any A; B, A " B = ; 1: LP (;) = U P (;) = 0 3: LP (A) + LP ( A) = 1 5: U P (A) + U P (B) U P (A " B) where A denotes the complement of A. <p> The set of all PD-s consistent with LP will be denoted -(LP ). Another one-to-one representation of a lower probability LP is obtained by Mobius transformation, which defines a function m : 2 ! <ref> [0; 1] </ref> such that for LP m (B) = P CB (1) jBCj LP (C), LP can be recovered from m using the formula LP (B) = P CB m (C). The set of PD-s consistent with m is -(m) = -(LP ). <p> Lemma 1 A probability distribution P is consistent with a mass assignment m iff there exists a function g : 2 fi ! <ref> [0; 1] </ref> such that 1: B g (B; b) = P (b) 8b 2 P P 3: g (B; b) 0; f or all B; b 2 A proof of this lemma is presented in [ 2 ] . <p> In a nondeterministic mass assignment m, each focal element is a function E i : ! 2 ; m therefore can be considered as a function from into the set of all deterministic mass assignments. Denote the set of all intervals in <ref> [0; 1] </ref> as I, a deterministic general mass assignment M : 2 ! I assigns to each subset of a (probability) interval in I. M can be understood as a set of mass assignments M = fmjm : 2 ! [0; 1] s:t: 8B m (B) 2 M (B)g. <p> Denote the set of all intervals in <ref> [0; 1] </ref> as I, a deterministic general mass assignment M : 2 ! I assigns to each subset of a (probability) interval in I. M can be understood as a set of mass assignments M = fmjm : 2 ! [0; 1] s:t: 8B m (B) 2 M (B)g. We define -(M ) = S m2M -(m). We shall interpret M as either set or function depending on the context. <p> The following lemma shows how a mass assignment can be manipulated in an analogous manner. It is trivial to generalize the lemma for general mass assignment. Lemma 2 Given m : 2 ! <ref> [0; 1] </ref>, S 2 2 , AS, and a mass assignment m 0 as follows 1: m 0 (B) = m (B) 8B 6= A; B 6= S; B 2 2 3: m 0 (S) = m (S) + m (A) m 0 (A) then we have -(m)-(m 0 ). <p> the set of concrete plans = fp i1 ; p i2 ; ; p ik jp ij 2 ; j = 1; 2; ; kg is the optimal plan set of wrt M pre , U 1 , and project 2 iff 1. there does not exist s; t 2 <ref> [1; k] </ref> such that U min (project 2 (p is ; M pre )) U max (project 2 (p it ; M pre )). 2. for any p l 2 fng there exists p j 2 such that U min (project 2 (p j ; M pre )) &gt; U max <p> If dead is highly relevant to utility and there exist an action conditioned on cost that changes the value of dead, the abstraction can be arbitrarily bad. Questions about abstraction efficiency can best be answered by first developing theories of grouping actions based on their similarities. Boutilier <ref> [ 1 ] </ref> discussed a state abstraction model in the context of Markov process based planning. He first identifies "relevant" attributes, whose changes in value could lead to value changes of domain attributes appearing explicitly in the utility function.
Reference: [2] <author> L. Chrisman. </author> <title> Abstract probabilistic modeling of action. </title> <booktitle> In Proceedings of the First International Conference on Artificial Intelligence Planning Systems, </booktitle> <pages> pages 28-36, </pages> <month> June </month> <year> 1992. </year> <month> 37 </month>
Reference-contexts: with a mass assignment m iff there exists a function g : 2 fi ! [0; 1] such that 1: B g (B; b) = P (b) 8b 2 P P 3: g (B; b) 0; f or all B; b 2 A proof of this lemma is presented in <ref> [ 2 ] </ref> . For each B we define f B (b) = g (B; b) 8b 2 B. Function f B (b) is called an allocation function assigning mass to individual states trapped in B. We can specify a mass assignment by enumerating all its branches. <p> The set V i in the above definition is frequently represented as an interval in D i , eg. f uel [10] = <ref> [2; 4] </ref>, which says that f uel at time point 10 is some value between 2 and 4. <p> In the most extreme case, drips uses only 4.4% as much memory as the branch-and-bound algorithm. 10 Related Work and Discussion Uncertainty Model Most existing probabilistic planning models represent uncertainty with a single probability distribution. Chrisman <ref> [ 2 ] </ref> suggests using a deterministic mass assignment to represent uncertainty in the state of the world and in action effects. His model is therefore non-metric. There have been considerable problems with interpreting probability interval representations and with using them properly.
Reference: [3] <author> T. Dean, L. Pack Kaelbling, J. Kirman, and A. Nicholson. </author> <title> Planning with deadlines in stochastic domains. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> pages 574-579, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: All domains implemented so far in drips has utility functions with the above property. 9 Empirical Results Handling Complex Uncertainty Representation Most existing probabilistic planner represent uncertainty concerning the world and action effects as probability distributions over the set of states <ref> [ 11, 14, 3 ] </ref> . A typical world and action representation, which is taken from [ 11 ] , but is fairly common found in other probabilistic schemes, is shown in Figure 5. Value 1 corresponds to proposition being true, and value 0 to false. <p> It is the only planner that efficiently performs optimal decision-theoretic planning. Other systems either do not reason about utility, e.g. [ 12 ] , or are not guaranteed to return optimal plans without exhaustively enumerating the space of plans <ref> [ 3, 4 ] </ref> . drips is the only decision-theoretic planner that can reason with continuous attributes. Generative planners have difficulty reasoning with continuous quantities and planners based on discrete Markov processes [ 3, 4 ] are limited by that framework to reasoning in finite state spaces. drips can also reason <p> 12 ] , or are not guaranteed to return optimal plans without exhaustively enumerating the space of plans <ref> [ 3, 4 ] </ref> . drips is the only decision-theoretic planner that can reason with continuous attributes. Generative planners have difficulty reasoning with continuous quantities and planners based on discrete Markov processes [ 3, 4 ] are limited by that framework to reasoning in finite state spaces. drips can also reason with metric time actions can have uncertain temporal duration. drips can reason about actions involving observations and actions that change the state of the world in a uniform manner.
Reference: [4] <author> R. Dearden and C. Boutilier. </author> <title> Integrating planning and execution in stochastic domains. </title> <booktitle> In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 162-169, </pages> <address> Seattle, </address> <month> July </month> <year> 1994. </year>
Reference-contexts: The set V i in the above definition is frequently represented as an interval in D i , eg. f uel [10] = <ref> [2; 4] </ref>, which says that f uel at time point 10 is some value between 2 and 4. <p> Indeed, assume (f uel [t] = f fuel;t = f uel [t p ] + 2) and B contains constraint (f uel [t p ] = <ref> [4; 7] </ref>), then since f fuel;t is monoton increasing, the bounds on f uel's values for 26 f fuel;t (B) will be the f fuel;t (b)-s with b-s the minimal and maximal values of f uel in B at t p . <p> It is the only planner that efficiently performs optimal decision-theoretic planning. Other systems either do not reason about utility, e.g. [ 12 ] , or are not guaranteed to return optimal plans without exhaustively enumerating the space of plans <ref> [ 3, 4 ] </ref> . drips is the only decision-theoretic planner that can reason with continuous attributes. Generative planners have difficulty reasoning with continuous quantities and planners based on discrete Markov processes [ 3, 4 ] are limited by that framework to reasoning in finite state spaces. drips can also reason <p> 12 ] , or are not guaranteed to return optimal plans without exhaustively enumerating the space of plans <ref> [ 3, 4 ] </ref> . drips is the only decision-theoretic planner that can reason with continuous attributes. Generative planners have difficulty reasoning with continuous quantities and planners based on discrete Markov processes [ 3, 4 ] are limited by that framework to reasoning in finite state spaces. drips can also reason with metric time actions can have uncertain temporal duration. drips can reason about actions involving observations and actions that change the state of the world in a uniform manner.
Reference: [5] <author> J.Y. Halpern. </author> <title> Two views of belief: Belief as generalized probability and belief as evidence. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 112-119, </pages> <address> Boston, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: His model is therefore non-metric. There have been considerable problems with interpreting probability interval representations and with using them properly. In this report they are to be understood as generalized probability <ref> [ 5 ] </ref> , providing constraints on a set of probability distributions. This semantics of probability interval has been kept clear throughout the report. Abstraction While abstraction has been long a focus in planning, probabilistic abstraction is relatively new and has received much less attention.
Reference: [6] <author> S. Hanks. </author> <title> Practical temporal projection. </title> <booktitle> In Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <pages> pages 158-163, </pages> <address> Boston, </address> <month> July </month> <year> 1990. </year>
Reference-contexts: Doing this explicitly is computationally prohibitive in all but the smallest of domains. This is due to the large space of possible plans that must be searched and to the fact that probabilistic plan evaluation is many magnitudes harder than deterministic plan evaluation <ref> [ 11, 6 ] </ref> . In decision theoretic models, qualitative techniques can be used to filter out classes of obviously bad plans, thus avoiding costly plan evaluation [ 16 ] ; but at some point one must resort quantitative reasoning about expected utility in order to evaluate tradeoffs. <p> We have, therefore, f fuel;t = [4 + 2; 7 + 2] = <ref> [6; 9] </ref>. All functions f il implemented so far in drips have countable changes in mono-tonicity. Figure 2 shows the Driver action and the new general mass assignment M post resulting from projecting Driver on M pre . <p> This semantics of probability interval has been kept clear throughout the report. Abstraction While abstraction has been long a focus in planning, probabilistic abstraction is relatively new and has received much less attention. Hanks <ref> [ 6 ] </ref> suggested action "bundling", which is equivalent to our intra-action abstraction, to reduce the complexity of projection. The BURIDAN planner [ 12 ] implemented a similar bundling technique. The method is limited due to the restrictive uncertainty model.
Reference: [7] <author> S. Hanks, S. Russell, and M. Wellman, </author> <title> editors. </title> <booktitle> AAAI Spring Symposium on Decision-Theoretic Planning, </booktitle> <address> Stanford, </address> <year> 1994. </year>
Reference-contexts: 1 Introduction It has become widely accepted in the AI planning community that planning schemes which strive to solve realistic problems must be able to model uncertainty as well as tradeoffs among goals and the resources consumed in achieving goals. This position has given rise to the decision-theoretic planning paradigm <ref> [ 7 ] </ref> . In the framework of decision-theoretic planning, uncertainty in the state of the world and in the effects of actions are represented with probabilities and the planner's goals, as well as tradeoffs among them, are represented with a utility function over outcomes. <p> Indeed, assume (f uel [t] = f fuel;t = f uel [t p ] + 2) and B contains constraint (f uel [t p ] = <ref> [4; 7] </ref>), then since f fuel;t is monoton increasing, the bounds on f uel's values for 26 f fuel;t (B) will be the f fuel;t (b)-s with b-s the minimal and maximal values of f uel in B at t p .
Reference: [8] <editor> Hillner BE, Philbrick JT, Becker DM. </editor> <title> Optimal management of suspected lower-extremity deep vein thrombosis: an evaluation with cost assessment of 24 management strategies. </title> <journal> Arch Intern Med, </journal> <volume> 152 </volume> <pages> 165-175, </pages> <year> 1992. </year>
Reference-contexts: To evaluate the applicability of drips, we constructed a model for diagnosis and treatment of DVT 3 , based on data from an article that compared 24 different management strategies <ref> [ 8 ] </ref> . To encompass all of the strategies described in the original model, our model incorporated up to four tests, with a maximum of three 7-day waiting periods between tests. <p> We ran drips with several variations of the utility function and in all cases it successfully identified the optimal plan. This was verified by comparison with a decision-tree evaluation algorithm. The results produced by drips differed from those reported in the reference manuscript <ref> [ 8 ] </ref> . In reviewing these results, we discovered that drips had uncovered an error in the original study [ 10 ] . In evaluating this model, drips used abstraction to eliminate 5,551 (89%) of the 6,206 possible management strategies without explicitly evaluating them.
Reference: [9] <author> E. Horvitz. </author> <title> Utility-based abstraction and categorization. </title> <booktitle> In Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence, </booktitle> <pages> pages 128-135, </pages> <year> 1993. </year>
Reference-contexts: We have, therefore, f fuel;t = [4 + 2; 7 + 2] = <ref> [6; 9] </ref>. All functions f il implemented so far in drips have countable changes in mono-tonicity. Figure 2 shows the Driver action and the new general mass assignment M post resulting from projecting Driver on M pre . <p> The correlation value is used determine the weights on these new attributes which are added to the relevant set. The process is continued until all the action descriptions have been examined. These weights can then be used by a clustering algorithm to generate good groupings of action branches. Horvitz <ref> [ 9 ] </ref> also discussed utility based state and action abstraction. In his framework, however, utility is action-based, instead of plan-based.
Reference: [10] <author> CE Kahn, Jr and P Haddawy. </author> <title> Management of suspected lower-extremity deep venous thrombosis (letter). Archives of Internal Medicine, </title> <note> Febru-ary 1995. (to appear). </note>
Reference-contexts: The set V i in the above definition is frequently represented as an interval in D i , eg. f uel <ref> [10] </ref> = [2; 4], which says that f uel at time point 10 is some value between 2 and 4. <p> This was verified by comparison with a decision-tree evaluation algorithm. The results produced by drips differed from those reported in the reference manuscript [ 8 ] . In reviewing these results, we discovered that drips had uncovered an error in the original study <ref> [ 10 ] </ref> . In evaluating this model, drips used abstraction to eliminate 5,551 (89%) of the 6,206 possible management strategies without explicitly evaluating them.
Reference: [11] <author> N. Kushmerick, S. Hanks, and D. Weld. </author> <title> An algorithm for probabilistic planning. </title> <type> Technical Report 93-06-03, </type> <institution> Dept. of Computer Science and Engineering, University of Washington, </institution> <month> June </month> <year> 1993. </year> <note> (To appear in Artificial Intelligence). </note>
Reference-contexts: Doing this explicitly is computationally prohibitive in all but the smallest of domains. This is due to the large space of possible plans that must be searched and to the fact that probabilistic plan evaluation is many magnitudes harder than deterministic plan evaluation <ref> [ 11, 6 ] </ref> . In decision theoretic models, qualitative techniques can be used to filter out classes of obviously bad plans, thus avoiding costly plan evaluation [ 16 ] ; but at some point one must resort quantitative reasoning about expected utility in order to evaluate tradeoffs. <p> All domains implemented so far in drips has utility functions with the above property. 9 Empirical Results Handling Complex Uncertainty Representation Most existing probabilistic planner represent uncertainty concerning the world and action effects as probability distributions over the set of states <ref> [ 11, 14, 3 ] </ref> . A typical world and action representation, which is taken from [ 11 ] , but is fairly common found in other probabilistic schemes, is shown in Figure 5. Value 1 corresponds to proposition being true, and value 0 to false. <p> A typical world and action representation, which is taken from <ref> [ 11 ] </ref> , but is fairly common found in other probabilistic schemes, is shown in Figure 5. Value 1 corresponds to proposition being true, and value 0 to false.
Reference: [12] <author> N. Kushmerick, S. Hanks, and D. Weld. </author> <title> An algorithm for probabilistic least-commitment planning. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence, </booktitle> <pages> pages 1073-1078, </pages> <address> Seattle, </address> <year> 1994. </year>
Reference-contexts: Abstraction While abstraction has been long a focus in planning, probabilistic abstraction is relatively new and has received much less attention. Hanks [ 6 ] suggested action "bundling", which is equivalent to our intra-action abstraction, to reduce the complexity of projection. The BURIDAN planner <ref> [ 12 ] </ref> implemented a similar bundling technique. The method is limited due to the restrictive uncertainty model. The importance of abstracting action sequences, and loops is also discussed [ 13 ] , but we are not aware of any formal theory or concrete application. <p> It is the only planner that efficiently performs optimal decision-theoretic planning. Other systems either do not reason about utility, e.g. <ref> [ 12 ] </ref> , or are not guaranteed to return optimal plans without exhaustively enumerating the space of plans [ 3, 4 ] . drips is the only decision-theoretic planner that can reason with continuous attributes.
Reference: [13] <author> David E. Smith and Mike Williamson. </author> <title> Representation and evaluation of plans with loops. </title> <booktitle> In AAAI Spring Symposium 95 Extending Theories of Actions, </booktitle> <address> Stanford, CA, </address> <year> 1995. </year>
Reference-contexts: The BURIDAN planner [ 12 ] implemented a similar bundling technique. The method is limited due to the restrictive uncertainty model. The importance of abstracting action sequences, and loops is also discussed <ref> [ 13 ] </ref> , but we are not aware of any formal theory or concrete application. To see how other abstraction strategies are possible in our framework, consider the following proposition.
Reference: [14] <author> S. Thiebaux, J. Hertzberg, W. Shoaff, and M. Schneider. </author> <title> A stochastic model of actions and plans for anytime planning under uncertainty. </title> <journal> International Journal of Intelligent Systems, </journal> <note> 1994. To appear. 38 </note>
Reference-contexts: All domains implemented so far in drips has utility functions with the above property. 9 Empirical Results Handling Complex Uncertainty Representation Most existing probabilistic planner represent uncertainty concerning the world and action effects as probability distributions over the set of states <ref> [ 11, 14, 3 ] </ref> . A typical world and action representation, which is taken from [ 11 ] , but is fairly common found in other probabilistic schemes, is shown in Figure 5. Value 1 corresponds to proposition being true, and value 0 to false.
Reference: [15] <author> S. Uckun. </author> <title> Instantiating and monitoring treatment protocols. </title> <booktitle> In Proceed--ings of the Eighteenth Annual Symposium on Computer Applications in Medical Care (SCAMC94), </booktitle> <pages> pages 689-693, </pages> <address> Washington, DC, </address> <month> November </month> <year> 1994. </year>
Reference-contexts: Unlike most Markov process based planners it does not require the state of the world to be observable. Uckun's spin system <ref> [ 15 ] </ref> uses abstraction/decomposition networks for protocol-based treatment planning, plan execution, and execution monitoring. The hierarchical representation of plans is used for controlling execution. Although the hierarchy encodes alternative plans, Uckun does not show how choices are made when alternatives exist.
Reference: [16] <author> M.P. Wellman. </author> <title> Formulation of Tradeoffs in Planning Under Uncertainty. </title> <publisher> Pitman, </publisher> <address> London,UK, </address> <year> 1990. </year> <month> 39 </month>
Reference-contexts: In decision theoretic models, qualitative techniques can be used to filter out classes of obviously bad plans, thus avoiding costly plan evaluation <ref> [ 16 ] </ref> ; but at some point one must resort quantitative reasoning about expected utility in order to evaluate tradeoffs. In large domains we expect that even if qualitative techniques are used as a filter, the remaining space of possible plans will be too large to exhaustively examine. <p> The hierarchical representation of plans is used for controlling execution. Although the hierarchy encodes alternative plans, Uckun does not show how choices are made when alternatives exist. The spin system does not include decision-theoretic measures of uncertainty or plan quality. The SUDO-PLANNER system <ref> [ 16 ] </ref> uses decision-theoretic principles to eliminate classes of suboptimal plans in domains characterized by partially satisfiable goals and actions with uncertain effects. It eliminates only those classes of plans which it can prove are dominated without resorting to reasoning about tradeoffs.
References-found: 16

