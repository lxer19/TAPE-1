URL: http://L2R.cs.uiuc.edu/~danr/Papers/categ.ps.gz
Refering-URL: http://L2R.cs.uiuc.edu/~danr/publications.html
Root-URL: http://www.cs.uiuc.edu
Email: dagan@cs.biu.ac.il  yaelk@wisdom.weizmann.ac.il  danr@wisdom.weizmann.ac.il  
Title: Mistake-Driven Learning in Text Categorization  
Author: Ido Dagan Yael Karov Dan Roth 
Address: Ramat Gan 52900, Israel  Rehovot 76100, Israel  Rehovot 76100, Israel  
Affiliation: Dept. of Math. CS Bar Ilan University  Dept. of Appl. Math. CS Weizmann Institute of Science  Dept. of Appl. Math. CS Weizmann Institute of Science  
Date: 9 Jun 1997  
Note: cmp-lg/9706006  Partly supported by a grant no. 8560195 from the Israeli Ministry of Science. Partly supported by a grant from the Israeli Ministry of Science. Part of this work was done while visiting at Harvard University, supported by ONR grant N00014-96-1-0550.  
Abstract: Learning problems in the text processing domain often map the text to a space whose dimensions are the measured features of the text, e.g., its words. Three characteristic properties of this domain are (a) very high dimensionality, (b) both the learned concepts and the instances reside very sparsely in the feature space, and (c) a high variation in the number of active features in an instance. In this work we study three mistake-driven learning algorithms for a typical task of this nature - text categorization. We argue that these algorithms which categorize documents by learning a linear separator in the feature space have a few properties that make them ideal for this domain. We then show that a quantum leap in performance is achieved when we further modify the algorithms to better address some of the specific characteristics of the domain. In particular, we demonstrate (1) how variation in document length can be tolerated by either normalizing feature weights or by using negative weights, (2) the positive effect of applying a threshold range in training, (3) alternatives in considering feature frequency, and (4) the benefits of discarding features while training. Overall, we present an algorithm, a variation of Littlestone's Winnow, which performs significantly better than any other algorithm tested on this task using a similar feature set. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Apte, C., F. Damerau, and S. Weiss. </author> <year> 1994. </year> <title> Towards language independent automated learning of text categorization models. </title> <booktitle> In Proceedings of ACM-SIGIR Conference on Information Retrieval. </booktitle>
Reference-contexts: In addition, we have tested our final version of the classifier on two common partitions of the complete Reuters collection, and compare the results with those of other works. The two partitions used are those of Lewis (Lewis, 1992) (14704 documents for training, 6746 for testing) and Apte <ref> (Apte, Dam-erau, and Weiss, 1994) </ref> (10645 training, 3672 testing, omitting documents with no topical category). To evaluate performance, the usual measures of recall and precision were used. <p> split BalancedWinnow + 83.3 74.7 Experts unigram (Cohen and Singer, 1996) 64.7 65.6 Neural Network (Wiener, Pedersen, and Weigend, 1995) 77.5 NA Rocchio (Rocchio, 1971) 74.5 66.0 Ripper (Cohen and Singer, 1996) 79.6 71.9 Decision trees (Lewis and Ringuette, 1994) NA 67.0 Bayes (Lewis and Ringuette, 1994) NA 65.0 SWAP <ref> (Apte, Damerau, and Weiss, 1994) </ref> 78.9 NA Table 2: Break-even points comparison. The data is split into training set and test set based on Lewis's split - (Lewis, 1992), 14704 documents for training, 6746 for testing, and Apte's split - (Apte, Damerau, and Weiss, 1994), 10645 training, 3672 testing, omitting documents <p> NA 67.0 Bayes (Lewis and Ringuette, 1994) NA 65.0 SWAP <ref> (Apte, Damerau, and Weiss, 1994) </ref> 78.9 NA Table 2: Break-even points comparison. The data is split into training set and test set based on Lewis's split - (Lewis, 1992), 14704 documents for training, 6746 for testing, and Apte's split - (Apte, Damerau, and Weiss, 1994), 10645 training, 3672 testing, omitting documents with no topical category. now algorithm, which incorporates the -range modification, a square-root of occurrences as the feature strength and the discard features modification (BalancedWinnow + in Table 2). <p> The last two figure are taken from (Lewis and Ringuette, 1994) where they were evaluated only on Lewis's split. The last comparison is with the learning system used by <ref> (Apte, Damerau, and Weiss, 1994) </ref>, SWAP, which was evaluated only on Apte's split. Our results significantly outperform (by at least 2-4%) all results which appear in that table and use the same set of features (based on single words).
Reference: <author> Blum, A. </author> <year> 1992. </year> <title> Learning boolean functions in an infinite attribute space. </title> <journal> Machine Learning, </journal> <volume> 9(4) </volume> <pages> 373-386, </pages> <month> October. </month>
Reference-contexts: The label of the document is denoted by y; y takes the value 1 if the document is relevant to the category and 0 otherwise. Notice, that we care only about the active features in the domain, following <ref> (Blum, 1992) </ref>. The algorithms have three parameters: a threshold , and two update parameters, a promotion parameter ff and a demotion parameter fi.
Reference: <author> Blum, A. </author> <year> 1995. </year> <title> Empirical support for Winnow and weighted-majority based algorithms: results on a calendar scheduling domain. </title> <booktitle> In Proc. 12th International Conference on Machine Learning, </booktitle> <pages> pages 64-72. </pages> <publisher> Mor-gan Kaufmann. </publisher>
Reference: <author> Cesa-Bianchi, N., Y. Freund, D. P. Helmbold, D. Haus-sler, and R. E. Schapire a nd M. K. Warmuth. </author> <year> 1995. </year> <title> How to use expert advice. </title> <address> pages 382-391. </address>
Reference: <author> Cesa-Bianchi, N., Y. Freund, D. P. Helmbold, and M. Warmuth. </author> <year> 1994. </year> <title> On-line prediction and conversion strategies. </title> <booktitle> In Computational Learning Theory: Eurocolt '93, volume New Series Number 53 of The Institute of Mathematics and its Applications Conference Series, </booktitle> <pages> pages 205-216, </pages> <publisher> Oxford. Oxford University Press. </publisher>
Reference: <author> Cohen, W. W. and Y. Singer. </author> <year> 1996. </year> <title> Context-sensitive learning methods for text categorization. </title> <booktitle> In Proc. of the 19th Annual Int. ACM Conference on Research and Development in Information Retrieval. </booktitle>
Reference-contexts: A feature f i may typically represent a word w, a set w 1 ; : : : w k of words <ref> (Cohen and Singer, 1996) </ref> or a phrasal structure (Lewis, 1992; Tzeras and Hartmann, 1993). The strength of the feature f in the document d is denoted by s (f; d). The strength is usually a function of the number of times f appears in d (denoted by n (f; d)). <p> The methods that are most similar to our techniques are the on-line algorithms used in (Lewis et al., 1996) and <ref> (Cohen and Singer, 1996) </ref>. In the first, two algorithms, a multiplicative update and additive update algorithms suggested in (Kivinen and War-muth, 1995a) are evaluated in the text categorization domain, and are shown to perform somewhat better than Rocchio's algorithm. <p> First, there are some important technical differences between the algorithms used. Second, the algorithms we study here are mistake-driven; they update the weight vector only when a mistake is made, and not after every example seen. The Experts algorithm studied in <ref> (Cohen and Singer, 1996) </ref> is very similar to a basic version of the BalancedWinnow algorithm which we study here. The way we treat the negative weights is different, though, and significantly more efficient, especially in sparse domains (see Section 3.1). <p> are other versions of the Winnow algorithm that allow the use of negative features: (1) Littlestone, when introducing the Balanced version, introduced also a simpler version aversion of PositiveWinnow with a duplication of the number of features. (2) A version of the Winnow algorithm with negative features is used in <ref> (Cohen and Singer, 1996) </ref>. In both cases, however, whenever there is a need to update the weights, all the weights are being updated (actually, n out of the 2n). <p> Eventually, we have selected the version of the BalancedWin Algorithm Apte's split Lewis's split BalancedWinnow + 83.3 74.7 Experts unigram <ref> (Cohen and Singer, 1996) </ref> 64.7 65.6 Neural Network (Wiener, Pedersen, and Weigend, 1995) 77.5 NA Rocchio (Rocchio, 1971) 74.5 66.0 Ripper (Cohen and Singer, 1996) 79.6 71.9 Decision trees (Lewis and Ringuette, 1994) NA 67.0 Bayes (Lewis and Ringuette, 1994) NA 65.0 SWAP (Apte, Damerau, and Weiss, 1994) 78.9 NA Table <p> Eventually, we have selected the version of the BalancedWin Algorithm Apte's split Lewis's split BalancedWinnow + 83.3 74.7 Experts unigram <ref> (Cohen and Singer, 1996) </ref> 64.7 65.6 Neural Network (Wiener, Pedersen, and Weigend, 1995) 77.5 NA Rocchio (Rocchio, 1971) 74.5 66.0 Ripper (Cohen and Singer, 1996) 79.6 71.9 Decision trees (Lewis and Ringuette, 1994) NA 67.0 Bayes (Lewis and Ringuette, 1994) NA 65.0 SWAP (Apte, Damerau, and Weiss, 1994) 78.9 NA Table 2: Break-even points comparison. <p> The algorithm was run with iterations, threshold range, feature filtering, and frequency-square-root feature strength. The first two rows in Table 2 compare the performance of BalancedWinnow + with the two algorithms that most resemble our approach, the Experts algorithm from <ref> (Cohen and Singer, 1996) </ref> and a neural network approach presented in (Wiener, Ped-ersen, and Weigend, 1995). (see Section 2.2). Rocchio's algorithm is one of the classical algorithms for this tasks, and it still performs very good compared to newly developed techniques (e.g, (Lewis et al., 1996)). <p> Rocchio's algorithm is one of the classical algorithms for this tasks, and it still performs very good compared to newly developed techniques (e.g, (Lewis et al., 1996)). We also compared with the Ripper algorithm presented in <ref> (Cohen and Singer, 1996) </ref> (we present the best results for this task, with negative tests), a simple decision tree learning system and a Bayesian classifier. The last two figure are taken from (Lewis and Ringuette, 1994) where they were evaluated only on Lewis's split. <p> Our results significantly outperform (by at least 2-4%) all results which appear in that table and use the same set of features (based on single words). Of the results we know of in the literature, only a version of the Experts algorithm of <ref> (Cohen and Singer, 1996) </ref> which uses a richer feature set sparse word trigrams outperforms our result on the Lewis split, with a break-even point of 75.3%, compared with 74.6% for the unigram-based BalancedWinnow + .
Reference: <author> Cortes, Corinna and Vladimir Vapnik. </author> <year> 1995. </year> <title> Support-vector networks. </title> <journal> Machine Learning, </journal> <volume> 20(3) </volume> <pages> 273-297. </pages>
Reference-contexts: In this implementation we do not try to find the optimal t (as is done in <ref> (Cortes and Vapnik, 1995) </ref>, but rather determine it heuristically.
Reference: <author> Duda, R. O. and P. E. Hart. </author> <year> 1973. </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley. </publisher>
Reference-contexts: The additive-update algorithm that we evaluate here, the Perceptron, goes back to (Rosenblatt, 1958). While this algorithm is also known to learn the target linear function when it exists, the bounds given by the Perceptron convergence theorem <ref> (Duda and Hart, 1973) </ref> may be exponential in the optimal mistake bound, even for fairly simple functions (Kivinen and Warmuth, 1995b). We refer to (Kivi-nen and Warmuth, 1995a) for a thorough analysis of multiplicative update algorithms versus additive update algorithms.
Reference: <author> Golding, A. R. and D. Roth. </author> <year> 1996. </year> <title> Applying winnow to context-sensitive spelling correction. </title> <booktitle> In Proc. of the International Conference on Machine Learning. </booktitle>
Reference-contexts: This explains the recent success in using these methods on high dimensional problems <ref> (Golding and Roth, 1996) </ref> and suggests that multiplicative-update algorithms might do well on IR applications, provided that a good set of features is selected.
Reference: <author> Herbster, M. and M. Warmuth. </author> <year> 1995. </year> <title> Tracking the best expert. </title> <booktitle> In Proc. 12th International Conference on Machine Learning, </booktitle> <pages> pages 286-294. </pages> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Kivinen, J. and M. K. Warmuth. </author> <year> 1995a. </year> <title> Exponentiated gradient versus gradient descent for linear predictors. </title> <note> In Proc. of STOC. Tech Report UCSC-CRL-94-16. </note>
Reference-contexts: The methods that are most similar to our techniques are the on-line algorithms used in (Lewis et al., 1996) and (Cohen and Singer, 1996). In the first, two algorithms, a multiplicative update and additive update algorithms suggested in <ref> (Kivinen and War-muth, 1995a) </ref> are evaluated in the text categorization domain, and are shown to perform somewhat better than Rocchio's algorithm. While both these works make use of multiplicative update algorithms, as we do, there are two major differences between those studies and the current one.
Reference: <author> Kivinen, J. and M. K. Warmuth. </author> <year> 1995b. </year> <title> The perceptron algorithm vs. Winnow: linear vs. logarithmic mistake bounds when few input variables are relevant. </title> <booktitle> In Proc. 8th Annu. Conf. on Comput. Learning Theory, </booktitle> <pages> pages 289-296. </pages> <publisher> ACM Press, </publisher> <address> New York, NY. </address>
Reference-contexts: While this algorithm is also known to learn the target linear function when it exists, the bounds given by the Perceptron convergence theorem (Duda and Hart, 1973) may be exponential in the optimal mistake bound, even for fairly simple functions <ref> (Kivinen and Warmuth, 1995b) </ref>. We refer to (Kivi-nen and Warmuth, 1995a) for a thorough analysis of multiplicative update algorithms versus additive update algorithms. In particular, it is shown that the number of mistakes the additive and multiplicative update algorithms make, depend differently on the domain characteristics.
Reference: <author> Lewis, D. </author> <year> 1992. </year> <title> An evaluation of phrasal and clustered representations on a text categorization problem. </title> <booktitle> In Proc. of the 15th Int. ACM-SIGIR Conference on Information Retrieval. </booktitle>
Reference-contexts: They use a more complex representation, a multi-layer network, but this additional expressiveness seems to make training more complicated, without contributing to better results. 2.3 Methodology We evaluate our algorithms on the the Reuters-22173 text collection <ref> (Lewis, 1992) </ref>, one of the most commonly used benchmarks in the literature. For the experiments reported In Sections 3.2 we explore and compare different variations of the al gorithms; we evaluate those on two disjoint pairs of a training set and a test set, both subsets of the Reuters collection. <p> The figures reported are the average results on the two test sets. In addition, we have tested our final version of the classifier on two common partitions of the complete Reuters collection, and compare the results with those of other works. The two partitions used are those of Lewis <ref> (Lewis, 1992) </ref> (14704 documents for training, 6746 for testing) and Apte (Apte, Dam-erau, and Weiss, 1994) (10645 training, 3672 testing, omitting documents with no topical category). To evaluate performance, the usual measures of recall and precision were used. <p> The data is split into training set and test set based on Lewis's split - <ref> (Lewis, 1992) </ref>, 14704 documents for training, 6746 for testing, and Apte's split - (Apte, Damerau, and Weiss, 1994), 10645 training, 3672 testing, omitting documents with no topical category. now algorithm, which incorporates the -range modification, a square-root of occurrences as the feature strength and the discard features modification (BalancedWinnow + in
Reference: <author> Lewis, D. and M. Ringuette. </author> <year> 1994. </year> <title> A comparison of two learning algorithms for text categorization. </title> <booktitle> In Proc. of Symposium on Document Analysis and Information Retrieval. </booktitle>
Reference-contexts: Eventually, we have selected the version of the BalancedWin Algorithm Apte's split Lewis's split BalancedWinnow + 83.3 74.7 Experts unigram (Cohen and Singer, 1996) 64.7 65.6 Neural Network (Wiener, Pedersen, and Weigend, 1995) 77.5 NA Rocchio (Rocchio, 1971) 74.5 66.0 Ripper (Cohen and Singer, 1996) 79.6 71.9 Decision trees <ref> (Lewis and Ringuette, 1994) </ref> NA 67.0 Bayes (Lewis and Ringuette, 1994) NA 65.0 SWAP (Apte, Damerau, and Weiss, 1994) 78.9 NA Table 2: Break-even points comparison. <p> of the BalancedWin Algorithm Apte's split Lewis's split BalancedWinnow + 83.3 74.7 Experts unigram (Cohen and Singer, 1996) 64.7 65.6 Neural Network (Wiener, Pedersen, and Weigend, 1995) 77.5 NA Rocchio (Rocchio, 1971) 74.5 66.0 Ripper (Cohen and Singer, 1996) 79.6 71.9 Decision trees <ref> (Lewis and Ringuette, 1994) </ref> NA 67.0 Bayes (Lewis and Ringuette, 1994) NA 65.0 SWAP (Apte, Damerau, and Weiss, 1994) 78.9 NA Table 2: Break-even points comparison. <p> We also compared with the Ripper algorithm presented in (Cohen and Singer, 1996) (we present the best results for this task, with negative tests), a simple decision tree learning system and a Bayesian classifier. The last two figure are taken from <ref> (Lewis and Ringuette, 1994) </ref> where they were evaluated only on Lewis's split. The last comparison is with the learning system used by (Apte, Damerau, and Weiss, 1994), SWAP, which was evaluated only on Apte's split.
Reference: <author> Lewis, D., R. E. Schapire, J. P. Callan, and R. Papka. </author> <year> 1996. </year> <title> Training algorithms for linear text classifiers. </title> <booktitle> In SIGIR '96: Proc. of the 19th Int. Conference on Research and Development in Information Retrieval, </booktitle> <year> 1996. </year>
Reference-contexts: The methods that are most similar to our techniques are the on-line algorithms used in <ref> (Lewis et al., 1996) </ref> and (Cohen and Singer, 1996). In the first, two algorithms, a multiplicative update and additive update algorithms suggested in (Kivinen and War-muth, 1995a) are evaluated in the text categorization domain, and are shown to perform somewhat better than Rocchio's algorithm. <p> Rocchio's algorithm is one of the classical algorithms for this tasks, and it still performs very good compared to newly developed techniques (e.g, <ref> (Lewis et al., 1996) </ref>). We also compared with the Ripper algorithm presented in (Cohen and Singer, 1996) (we present the best results for this task, with negative tests), a simple decision tree learning system and a Bayesian classifier.
Reference: <author> Littlestone, N. </author> <year> 1988. </year> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318. </pages>
Reference-contexts: Three characteristic properties of this domain are (a) very high dimensionality, (b) both the learned concepts and the instances reside very sparsely in the feature space and, consequently, (c) there is a high variation in the number of active features in an instance. Multiplicative weight-updating algorithms such as Winnow <ref> (Littlestone, 1988) </ref> have been studied extensively in the theoretical learning literature. <p> Notice, that we care only about the active features in the domain, following (Blum, 1992). The algorithms have three parameters: a threshold , and two update parameters, a promotion parameter ff and a demotion parameter fi. Positive Winnow <ref> (Littlestone, 1988) </ref>: The algorithm keeps an n-dimensional weight vector w = (w 1 ; w 2 ; : : : w n ), w i being the weight of the ith feature, which it updates whenever a mistake is made. <p> A single update parameter ff &gt; 0 is used, and a weight is promoted by adding ff to its previous value, and is demoted by subtracting ff from it. In both cases, all other weights maintain the same value. Balanced Winnow <ref> (Littlestone, 1988) </ref>: In this case, the algorithm keeps two weights, w + ; w , for each feature. The overall weight of a feature is the difference between these two weights, thus allowing for negative weights. <p> In the version we use, only weights of active features are being updated; this gives a significant computational advantage when working in a sparse high dimensional space. 3.1 Properties of the Algorithms Winnow and its variations were introduced in Little-stone's seminal paper <ref> (Littlestone, 1988) </ref>; the theoretical behavior of multiplicative weight-updating algorithms for learning linear functions has been studied since then extensively. In particular, Win now has been shown to learn efficiently any linear threshold function (Littlestone, 1988). <p> dimensional space. 3.1 Properties of the Algorithms Winnow and its variations were introduced in Little-stone's seminal paper <ref> (Littlestone, 1988) </ref>; the theoretical behavior of multiplicative weight-updating algorithms for learning linear functions has been studied since then extensively. In particular, Win now has been shown to learn efficiently any linear threshold function (Littlestone, 1988).
Reference: <author> Littlestone, N. </author> <year> 1991. </year> <title> Redundant noisy attributes, attribute errors, and linear threshold learning using Winnow. </title> <booktitle> In Proc. 4th Annu. Workshop on Com-put. Learning Theory, </booktitle> <pages> pages 147-156, </pages> <address> San Mateo, CA. </address> <publisher> Morgan Kaufmann. </publisher>
Reference: <author> Littlestone, N. </author> <year> 1995. </year> <title> Comparing several linear-threshold learning algorithms on tasks involving superfluous attributes. </title> <booktitle> In Proc. 12th International Conference on Machine Learning, </booktitle> <pages> pages 353-361. </pages> <publisher> Morgan Kauf-mann. </publisher>
Reference: <author> Littlestone, N. and M. K. Warmuth. </author> <year> 1994. </year> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261. </pages>
Reference: <author> Rocchio, J. </author> <year> 1971. </year> <title> Relevance feedback information retrieval. </title> <editor> In G. Salton, editor, </editor> <title> The SMART retrieval system experiments in automatic document processing. </title> <publisher> Prentice-Hall, </publisher> <pages> pages 313-323. </pages>
Reference-contexts: Eventually, we have selected the version of the BalancedWin Algorithm Apte's split Lewis's split BalancedWinnow + 83.3 74.7 Experts unigram (Cohen and Singer, 1996) 64.7 65.6 Neural Network (Wiener, Pedersen, and Weigend, 1995) 77.5 NA Rocchio <ref> (Rocchio, 1971) </ref> 74.5 66.0 Ripper (Cohen and Singer, 1996) 79.6 71.9 Decision trees (Lewis and Ringuette, 1994) NA 67.0 Bayes (Lewis and Ringuette, 1994) NA 65.0 SWAP (Apte, Damerau, and Weiss, 1994) 78.9 NA Table 2: Break-even points comparison.
Reference: <author> Rosenblatt, F. </author> <year> 1958. </year> <title> The perceptron: A probabilistic model for information storage and organization in the brain. </title> <journal> Psychological Review, </journal> <volume> 65 </volume> <pages> 386-407. </pages> <publisher> (Reprinted in Neurocomputing (MIT Press, 1988).). </publisher>
Reference-contexts: In both cases, weights of inactive features maintain the same value. Perceptron <ref> (Rosenblatt, 1958) </ref> As in PositiveWinnow, in Perceptron we also keep an n-dimensional weight vector w = (w 1 ; w 2 ; : : : w n ) whose entries correspond to the set of potential features, which is updated whenever a mistake is made. <p> The features used are the "experts" and the learning algorithm can be viewed as an algorithm that learns how to combine the classifications of the different experts in an optimal way. The additive-update algorithm that we evaluate here, the Perceptron, goes back to <ref> (Rosenblatt, 1958) </ref>. While this algorithm is also known to learn the target linear function when it exists, the bounds given by the Perceptron convergence theorem (Duda and Hart, 1973) may be exponential in the optimal mistake bound, even for fairly simple functions (Kivinen and Warmuth, 1995b).
Reference: <author> Salton, G. and C. Buckley. </author> <year> 1983. </year> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill. </publisher>
Reference-contexts: The classical vector space model, which ranks documents using a nonlinear similarity measure (the "cosine correlation") <ref> (Salton and Buckley, 1983) </ref> can also be recast as a linear classification by incorporating length normalization into the weight vector and the document vector features values. <p> This problem has been identified earlier on and attracted a lot of work in the classical work on IR <ref> (Salton and Buckley, 1983) </ref>, as we have indicated in Section 2.2. The treatment described there addresses at the same time at least two different concerns: length variation of documents and feature repetition.
Reference: <author> Tzeras, K. and S. Hartmann. </author> <year> 1993. </year> <title> Automatic indexing based on bayesian inference networks. </title> <booktitle> In Proc. of 16th Int. ACM SIGIR Conference on Research and Development in Information Retrieval. </booktitle>
Reference: <author> Wiener, E., J. Pedersen, and A. Weigend. </author> <year> 1995. </year> <title> A neural network approach to topic spotting. </title> <booktitle> In Symposium on Document Analysis and Information Retrieval. </booktitle>
Reference-contexts: Cohen and Singer experiment also, using the same algorithm, with more complex features (sparse n-grams) and show that, as expected, it yields better results. Our additive update algorithm, Perceptron, is somewhat similar to what is used in <ref> (Wiener, Peder-sen, and Weigend, 1995) </ref>. <p> 1, if the feature is present in the document (active feature) and s (f; d) = 0 otherwise. (2) s (f; d) = n (f; d), where n (f; d) is the number of occurrences of f in d; and (3) s (f; d) = n (f; d) (as in <ref> (Wiener, Pedersen, and Weigend, 1995) </ref>). These three alternatives examine the tradeoff between the positive and negative impacts of assigning a strength in proportion to feature frequency. In most of our experiments, on different data sets, the choice of using p n (f; d) performed best. <p> Eventually, we have selected the version of the BalancedWin Algorithm Apte's split Lewis's split BalancedWinnow + 83.3 74.7 Experts unigram (Cohen and Singer, 1996) 64.7 65.6 Neural Network <ref> (Wiener, Pedersen, and Weigend, 1995) </ref> 77.5 NA Rocchio (Rocchio, 1971) 74.5 66.0 Ripper (Cohen and Singer, 1996) 79.6 71.9 Decision trees (Lewis and Ringuette, 1994) NA 67.0 Bayes (Lewis and Ringuette, 1994) NA 65.0 SWAP (Apte, Damerau, and Weiss, 1994) 78.9 NA Table 2: Break-even points comparison. <p> The first two rows in Table 2 compare the performance of BalancedWinnow + with the two algorithms that most resemble our approach, the Experts algorithm from (Cohen and Singer, 1996) and a neural network approach presented in <ref> (Wiener, Ped-ersen, and Weigend, 1995) </ref>. (see Section 2.2). Rocchio's algorithm is one of the classical algorithms for this tasks, and it still performs very good compared to newly developed techniques (e.g, (Lewis et al., 1996)).
References-found: 24

