URL: http://www.demo.cs.brandeis.edu/papers/jetai.ps.gz
Refering-URL: http://www.demo.cs.brandeis.edu/papers/long.html
Root-URL: http://www.cs.brandeis.edu
Email: kolen-j@cis.ohio-state.edu and pollack@cis.ohio-state.edu  
Title: The Observers Paradox: Apparent Computational Complexity in Physical Systems  
Author: John F. Kolen and Jordan B. Pollack 
Address: Columbus, OH 43210  
Affiliation: Laboratory for Artificial Intelligence Research Department of Computer and Information Sciences The Ohio State University  
Date: August 15, 1993  
Note: To appear Summer 1994 in The Journal of Experimental and Theoretical Artificial Intellignce Running Head: The Observers Paradox  
Abstract-found: 0
Intro-found: 1
Reference: <editor> Aida, S., et al. </editor> <booktitle> (1984) The Science and Praxis of Complexity (Tokyo: </booktitle> <address> United Nations University). </address>
Reference-contexts: The first appeals to the common sense notion that judges the complexity of a system by the number of internal moving parts. Thus, a system is more complex if it has a larger number of unique states induced by the internal mechanisms generating its behavior. Others <ref> (see Aida et al., 1984) </ref> have adopted the term complexion. We specifically use this term to refer to a measure of complexity based upon the number of unique moving parts within a system. The second approach to judging complexity is more subtle.
Reference: <author> Ashby, W. R. </author> <title> (1956) An Introduction to Cybernetics. </title> <publisher> (London: Chapman and Hall). </publisher>
Reference: <author> Bak, P., & Chen, K. </author> <title> (1991) Self-organized criticality, </title> <publisher> Scientific American, </publisher> <pages> 46-53. </pages>
Reference-contexts: At crit-icality, a system displays unbounded dependencies of behavior across space and/or time (Schroeder, 1991). The spread of forest fires at the percolation threshold of tree density (Bak et al., 1990) and sand pile avalanches <ref> (Bak and Chen, 1991) </ref> both produce global dependencies at critical parameters of tree density and pile slope. Even simple systems, such as the iterated logistic function , exhibit criticality for an infinite set of parameter values between zero and four.
Reference: <author> Bak, P., Chen, K., & Creutz, M. </author> <title> (1990) A forest-fire model and some thoughts on turbulence, </title> <journal> Physics Letters, </journal> <volume> 147 </volume> <pages> 297-300. </pages>
Reference-contexts: At crit-icality, a system displays unbounded dependencies of behavior across space and/or time (Schroeder, 1991). The spread of forest fires at the percolation threshold of tree density <ref> (Bak et al., 1990) </ref> and sand pile avalanches (Bak and Chen, 1991) both produce global dependencies at critical parameters of tree density and pile slope. Even simple systems, such as the iterated logistic function , exhibit criticality for an infinite set of parameter values between zero and four.
Reference: <author> Barton, G. E., Jr., Berwick, R. C., and Ristad, E. S. </author> <title> (1987) Computational Complexity and Natural Language (Cambridge, </title> <address> Mass.: </address> <publisher> MIT Press). </publisher>
Reference-contexts: The necessary and sufficient conditions of universal computation in the Physical Symbol System Hypothesis provide no insight into cognitive behavior; rather, it implies that humans can write down behavioral descriptions requiring universal computation to simulate. Even the computational intractability of models of linguistic competence <ref> (e. g., Barton, et al., 1987) </ref> is dependent on a particular symbolization of human behavior, not an underlying mechanical capacity. This highlights the groundless nature of rejections of mathematical models solely on claims of insufficient computational complexity.
Reference: <author> Cage, J. </author> <title> (1969) A Year From Monday: New Lectures and Writings by John Cage. (Middletown, Connecticut. </title> <publisher> Wesleyan University Press). </publisher>
Reference: <author> Chomsky, N. </author> <title> (1965) Aspects of the Theory of Syntax (Cambridge, </title> <address> Mass.: </address> <publisher> MIT Press). </publisher>
Reference: <author> Chomsky, N. </author> <title> (1957) Syntactic Structures (The Hague: </title> <publisher> Mounton & Co.). </publisher>
Reference: <author> Crutchfield, J., & Young, K. </author> <title> (1991) Computation at the onset of chaos. </title> <editor> In W. Zurek (Ed.) </editor> <title> Entropy, Complexity, and the Physics of Information (Reading: </title> <publisher> Addison-Wesely). </publisher>
Reference: <author> Fields, C. </author> <title> (1989) Consequences of nonclassical measurement for the algorithmic description of continuous dynamical systems. </title> <journal> Journal of Experimental and Theoretical Artificial Intelligence, </journal> <volume> 1 </volume> <pages> 171-178. </pages>
Reference: <author> Fodor, J. A., & Pylyshyn, Z. </author> <title> W.(1988) Connectionism and cognitive architecture: A critical analysis. </title> <journal> Cognition, </journal> <volume> 28 </volume> <pages> 3-71. </pages>
Reference-contexts: As such, it is constantly battered both from below (e.g., Grossberg, 1987), on actual biologically plausibility of the mechanisms, and from above <ref> (e.g., Fodor & Pylyshyn, 1988) </ref>, on the adequacy of its mechanisms when faced with normal tasks of high-level cognition requiring structured representations (Pollack, 1988) and generative complexity. Our earlier work tried to address the generative capacity issue raised long ago by Chomsky.
Reference: <author> Grossberg, S. </author> <title> (1987) Competitive learning: From interactive activation to adaptive resonance. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 23-63. </pages>
Reference-contexts: Connectionism seeks to understand how elements of cognition can be based on the physical mechanisms that can be in the brain, without being constrained by the overwhelming detail of neuroscience. As such, it is constantly battered both from below <ref> (e.g., Grossberg, 1987) </ref>, on actual biologically plausibility of the mechanisms, and from above (e.g., Fodor & Pylyshyn, 1988), on the adequacy of its mechanisms when faced with normal tasks of high-level cognition requiring structured representations (Pollack, 1988) and generative complexity.
Reference: <author> Hopcroft, J. E., and Ullman, J. D. </author> <title> (1979) Introduction to Automata Theory, Languages, and Computation (Reading: </title> <publisher> Addison-Wesely). </publisher>
Reference-contexts: In addition, they correlate quite beautifully with families of mechanisms, or automata, operating under memory constraints. Of course, we now know that many other classes are possible by placing different constraints on how the changeable parts interact <ref> (see many of the exercises in Hopcroft and Ullman, 1979) </ref>. We use the term generative class out of respect to the fact that this theory of complexity arose in formal languages (automata) and the questions of what kinds of sentences (behaviors) could be generated. <p> The two symbol discrimination of the variable rotational speed system. x The Observers Paradox 15 guage as a simple corollary to the pumping lemma for regular languages <ref> (Hopcroft and Ullman, 1979) </ref>.
Reference: <author> A. K. Joshi, K. Vijay-shanker, & D. J. Weir, </author> <title> (1989) Convergence of mildly context-sensitive grammar formalisms. </title> <editor> In T. Wasow, P. </editor> <title> Sells (eds) The Processing of Linguistic Structure. The Observers Paradox 19 Cambridge: </title> <publisher> MIT Press. </publisher>
Reference: <author> Langton, C., </author> <title> (1990) Computation at the edge of chaos: Phase transitions and emergent computation, </title> <journal> Physica, 42D:12-37. </journal>
Reference: <author> Newell, A., and Simon, H. A. </author> <title> (1962) GPS--A program that simulates human thought. </title> <editor> In E. </editor> <publisher> A. </publisher>
Reference: <editor> Feigenbaum & J. Feldman (Eds.) </editor> <booktitle> Computers and Thought. </booktitle> <address> (New York: </address> <publisher> McGraw-Hill). </publisher>
Reference: <author> Newell, A., and Simon, H. A. </author> <title> (1976) Computer Science as Empirical Inquiry: Symbols and Search. </title> <journal> Communications of the ACM, 19:3. </journal>
Reference-contexts: context-sensitive model: There are so many difficulties with the notion of linguistic level based on left-to right generation, both in terms of complexity of description and lack of explana tory power, that it seems pointless to pursue this approach any further. 2 Even Newell and Simon's Physical Symbol System Hypothesis <ref> (Newell and Simon, 1976) </ref> identifies recursive computation of a physical symbol system as both a necessary and sufficient condition for the production of intelligent action.
Reference: <author> Pollack, J. B. </author> <title> (1991) The induction of dynamical recognizers, </title> <journal> Machine Learning, </journal> <volume> 7 </volume> <pages> 227-252. </pages>
Reference-contexts: Our earlier work tried to address the generative capacity issue raised long ago by Chomsky. In this work we examined biologically plausible iterative systems and found that a particular con-strual, the dynamical recognizer, resulted in recurrent neural network automata that had finite specifications and yet infinite state spaces <ref> (Pollack, 1991) </ref>. From this observation we hypothesized that yet another mapping might be found between the hierarchy of formal languages and increasingly intricate dynamics of state spaces (implemented by recurrent neural networks).
Reference: <author> Putnam, H. </author> <title> (1988) Representation and Reality (Cambridge, </title> <address> Mass.: </address> <publisher> MIT Press). </publisher>
Reference: <author> Schroeder, M. </author> <title> (1991) Fractals, Chaos, Power Laws (New York: </title> <editor> W. H. </editor> <publisher> Freeman and Company). </publisher>
Reference-contexts: These are shown schematically in Figure 2. Third, Crutchfield and Young proved that the minimal machines needed to describe the behavior of simple dynamical systems when tuned to criticality had an infinite number of states. At crit-icality, a system displays unbounded dependencies of behavior across space and/or time <ref> (Schroeder, 1991) </ref>. The spread of forest fires at the percolation threshold of tree density (Bak et al., 1990) and sand pile avalanches (Bak and Chen, 1991) both produce global dependencies at critical parameters of tree density and pile slope.
Reference: <author> Searle, J. </author> <booktitle> (1990) Is the brain a digital computer? Proceedings and Addresses of the American Philosophical Association, </booktitle> <volume> 64 </volume> <pages> 21-37. </pages>
Reference: <author> Searle, J. </author> <booktitle> (1993) The Rediscovery of the Mind. </booktitle> <address> (Cambridge, Mass.: </address> <publisher> MIT Press). </publisher>
Reference-contexts: Based upon this observation, Searle concludes that causality, blatantly missing from the state transitions in his example, is the key component of cognition <ref> (Searle, 1993) </ref>. Fields (1987), on the other hand, suggests that the arbitrary nature of state labellings is only a problem for classical systems, i.e., systems unaffected by observations of their state.
Reference: <author> Takens, F. </author> <title> (1981) Detecting strange attractors in turbulence. </title> <booktitle> Lecture Notes in Mathematics 898. </booktitle> <address> (Berlin: </address> <publisher> Springer Verlag). </publisher>
Reference: <author> Wolfram, S. </author> <title> (1984) Universality and complexity in cellular automata, </title> <journal> Physica, 10D:1-35. </journal>
References-found: 25

