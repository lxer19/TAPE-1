URL: http://http.cs.berkeley.edu/~asah/papers/other/printed/massalin_diss.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/printed/
Root-URL: http://www.cs.berkeley.edu
Title: Synthesis: An Efficient Implementation of Fundamental Operating System Services  
Author: Henry Massalin 
Degree: Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Graduate School of Arts and Sciences.  
Date: 1992  
Affiliation: Columbia University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid, A. Tevanian, and M. Young. </author> <title> Mach: A New Kernel Foundation for Unix Development. </title> <booktitle> In Proceedings of the 1986 Usenix Conference, </booktitle> <pages> pages 93-112. </pages> <publisher> Usenix Association, </publisher> <year> 1986. </year>
Reference-contexts: when I read about the "Compare-and-Swap" instructions on the 68030 processor, which allows concurrent data structures to be implemented without using locks. 1.3 Synthesis Overview 1.3.1 Kernel Structure The Synthesis kernel is designed to support a real, full-featured operating system with functionality on the level of Unix [28] and Mach <ref> [1] </ref>. It is built out of many small, independent modules called quajects. A quaject is an abstract data type | a collection of code and data with a well-defined interface that performs a specific function. <p> There was no disk activity. 15 extra layers and overhead where there was none before. For example, the Mach operating system offers a wide range of new features, such as threads and flexible virtual memory management, all packaged in a small, modular, easy-to-port kernel <ref> [1] </ref>. But it does not perform very well compared to Sony's Unix. Table 2.2 shows the results of the previous experiment, repeated under Mach on the NeXT machine. Both the NeXT machine and the Sony workstation use the Motorola 68030 processor, and both run at 25MHz. <p> For example, recognizing the need for clean, elegant services, the Mach group at CMU started with the BSD kernel and factored services into user-level tasks, leaving behind a very small kernel of common, central services <ref> [1] </ref>. Taking a different approach, the Plan 9 group at AT&T Bell Laboratories chose to carve the monolithic kernel into three sub-kernels, one for managing files, one for computation, and one for user interfaces [24].
Reference: [2] <author> Sarita V. Adve, Vikram S. Adve, Mark D. Hill, and Mary K. Vernon. </author> <title> Comparison of Hardware and Software Cache Coherence Schemes. </title> <booktitle> In The 18th Annual International Symposium on Computer Architecture, </booktitle> <volume> volume 19, </volume> <pages> pages 298-308, </pages> <year> 1991. </year>
Reference-contexts: Relief may come from advances in the design of multiprocessors. Recent studies show that, for a wide variety of workloads, software-controlled caches are nearly as effective as fully coherent hardware caches and much easier to build, as they require no hardware [23] <ref> [2] </ref>. Further extensions to this idea stem from the observation that full coherency is often not necessary, and that it is beneficial to rely on the compiler to maintain coherency in software only when required [2]. <p> fully coherent hardware caches and much easier to build, as they require no hardware [23] <ref> [2] </ref>. Further extensions to this idea stem from the observation that full coherency is often not necessary, and that it is beneficial to rely on the compiler to maintain coherency in software only when required [2]. This line of thinking leads to cache designs that have the necessary control to efficiently support code-modifying programs. But it is true that the assumption that code is read-only is increasingly common, and that hardware designs are more and more using this assumption.
Reference: [3] <author> T.E. Anderson, B.N. Bershad, E.D. Lazowska, and H.M. Levy. </author> <title> Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism. </title> <booktitle> In Proceedings of the 13th ACM Symposium on Operating Systems Principles, </booktitle> <pages> pages 95-109, </pages> <address> Pacific Grove, CA, </address> <month> October </month> <year> 1991. </year> <note> ACM. </note>
Reference-contexts: Look, for example, at recent advances in thread management. A number of researchers begin with the premise that kernel thread operations are necessarily expensive, and go on to describe the implementation of a user-level threads package [17] [5] [33] <ref> [3] </ref>. Since much of the work is now done at the user-level by subscheduling one or more kernel-supplied threads, they can avoid many kernel invocations and their associated overhead. <p> For example, while Anderson reports order-of-magnitude performance improvement for user-level thread operations on the DEC CVAX multiprocessor compared to the native Topaz kernel threads implementation, the cost of invoking the kernel thread operations had been increased by a factor of 5 over Topaz threads <ref> [3] </ref>. 16 The factor of 5 is significant because, ultimately, programs interact with the outside world through kernel invocations. Increasing the overhead limits the rate at which a program can invoke the kernel and therefore, interact with the outside world.
Reference: [4] <author> James Arleth. </author> <title> A 68010 multiuser development system. </title> <type> Master's thesis, </type> <institution> The Cooper Union for the Advancement of Science and Art, </institution> <address> New York City, </address> <year> 1984. </year>
Reference-contexts: I teamed up with a fellow student, James Arleth, and together we built the precursor of what was later to become an experimental machine known as the Quamachine. It was a two-processor machine based on the 68000 CPU <ref> [4] </ref>, but designed in such a way that it could be split into two independently-operating halves, so we each would have a computer to take with us after we graduated. Jim did most of the hardware design while I concentrated on software.
Reference: [5] <author> Brian N. Bershad, Edward D. Lazowska, Henry M. Levy, and David B. Wagner. </author> <title> An Open Environment for Building Parallel Programming Systems. </title> <booktitle> In Symposium on Parallel Programming: Experience with Applications, Languages and Systems, </booktitle> <pages> pages 1-9, </pages> <address> New Haven, Connecticut (USA), </address> <month> July </month> <year> 1988. </year> <journal> ACM SIGPLAN. </journal>
Reference-contexts: Look, for example, at recent advances in thread management. A number of researchers begin with the premise that kernel thread operations are necessarily expensive, and go on to describe the implementation of a user-level threads package [17] <ref> [5] </ref> [33] [3]. Since much of the work is now done at the user-level by subscheduling one or more kernel-supplied threads, they can avoid many kernel invocations and their associated overhead.
Reference: [6] <author> A. Black, N. Hutchinson, E. Jul, and H. Levy. </author> <title> Object Structure in the Emerald System. </title> <booktitle> In Proceedings of the First Annual Conference on Object-Oriented Programming, Systems, Languages, and Applications, </booktitle> <pages> pages 78-86. </pages> <publisher> ACM, </publisher> <month> September </month> <year> 1986. </year>
Reference-contexts: The Synthesis kernel supports four different types of queues, to optimize for the varying synchronization needs of different combinations of single or multiple producers and consumers (synchronization is discussed in Chapter 5). All four types support the same abstract type <ref> [6] </ref>, defined by two callentry references, Q put and Q get, which put and get elements of the queue. Both these callentry references return synchronously under the normal condition (successful insertion or deletion). Under other conditions, the queue returns through the callbacks.
Reference: [7] <author> D.L. Black. </author> <title> Scheduling Support for Concurrency and Parallelism in the Mach Operating System. </title> <journal> IEEE Computer, </journal> <volume> 23(5) </volume> <pages> 35-43, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Contention occurs when many competing processes all want to access the same lock. Important global data structures are often points of contention. In Mach, for example, a single lock serializes access to the global run-queue <ref> [7] </ref>. This becomes a point of contention if several processors want to access the queue at the same time, as would occur when the scheduler clocks are synchronized. One way to reduce the lock contention in Mach relies on scheduling "hints" from the programmer. <p> An example of code isolation is in the run-queue. Typically a run-queue is protected by semaphores or spin-locks, such as in the Unix and Mach implementations <ref> [7] </ref>. In Synthesis, only code residing in each element can change it, so we separate the run-queue traversal, which is done lock-free, safely and 77 concurrently, from the queue element update, which is done locally by its associated thread. Another example occurs in a single-producer, single-consumer queue.
Reference: [8] <institution> Min-Ih Chen and Kwei-Jay Lin. </institution>
Reference-contexts: This can be particularly problematic for real-time systems where rapid response to urgent events is essential. There are sophisticated solutions for the priority inversion problem <ref> [8] </ref>, but they contribute to make locks more costly and less appealing. A final problem with locks is that they are state. In an environment that allows partial failure | such as parallel and distributed systems | a process can set a lock and then crash.
References-found: 8

