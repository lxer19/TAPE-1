URL: ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1473.ps.Z
Refering-URL: http://www.ai.mit.edu/projects/cbcl/old-course9.520/class-5.html
Root-URL: 
Title: Viewer-Centered Object Recognition in Monkeys  
Author: N.K. Logothetis, J. Pauls and T. Poggio 
Note: Copyright c Massachusetts Institute of Technology, 1994  
Date: 1473 April 1994  95  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY ARTIFICIAL INTELLIGENCE LABORATORY and CENTER FOR BIOLOGICAL AND COMPUTATIONAL LEARNING  
Pubnum: A.I. Memo No.  C.B.C.L. Paper No.  
Abstract: How does the brain recognize three-dimensional objects? An initial step towards the understanding of the neural substrate of visual object recognition can be taken by studying first the nature of object representation, as manifested in behavioral studies with humans or non-human primates. One fundamental question is whether these representations are object or viewer centered. We trained monkeys to recognize computer rendered objects presented from an arbitrarily chosen training view, and subsequently tested their ability to generalize recognition for views generated by mathematically rotating the objects around any arbitrary axis. In agreement with human psychophysical work (Rock and DiVita, 1987, Bulthoff and Edelman, 1992), our results show that recognition at the subordinate level becomes increasingly difficult for the monkey as the stimulus is rotated away from a familiar attitude, and thus provide additional evidence in favor of memorial representations that are viewer-centered. When the animals were trained with as few as three views of the object, 120 o apart, they could often interpolate recognition for all views resulting from rotations around the same axis. The possibility thus exists that even in the case of a viewer-centered recognition system, a small number of stored views may suffice to achieve the view-invariant performance that humans and non-human primates typically achieve when recognizing familiar objects. These results are also in agreement with a recognition model that accomplishes view-invariant performance by storing a limited number of object views or templates together with the capacity to interpolate between the templates (Poggio and Edelman, 1990). In such a model, the units involved in representing a learned view are expected to exhibit a bellshaped tuning curve centered around the learned view, while interpolation is instantiated in the summed activity of the units. This paper describes research done at the M.I.T. Artificial Intelligence Laboratory, at Baylor College of Medicine, and at the Center for Biological and Computational Learning in the Department of Brain and Cognitive Sciences at the Massachusetts Institute of Technology. Nikos K. Logothetis was supported by contract N00014-93-1-0209 of the Office of Naval Research (1992) and the McKnight Endowment Fund for Neuroscience (1993). Tomaso Poggio was supported by Office of Naval Research contracts N00014-92-J-1879 (1992) and N00014-93-J-0385, and by NSF grant ASC-92-17041. Support for the A.I. Laboratory's artificial intelligence research is provided by ARPA contract N00014-91-J-4038. Tomaso Poggio is supported by the Uncas and Helen Whitaker Chair at MIT's Whitaker College. Additional support is provided by the North Atlantic Treaty Organization, ATR Audio and Visual Perception Research Laboratories, and Siemens AG. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> I. Biederman. Recognition-by-components: </author> <title> a theory of human image understanding. </title> <journal> Psychological Review, </journal> <volume> 94 </volume> <month> 115-147 </month> <year> 1987. </year>
Reference-contexts: In contrast, viewer-centered representations model three-dimensional objects as a set of 2D views, or aspects, and recognition consists of matching image features against the views in this set. When tested against human behavior, object-centered representations predict well the view-independent recognition of familiar objects <ref> [1] </ref>. However, psychophysical studies using familiar objects to investigate the processes underlying object constancy, i.e. viewpoint-invariant recognition of objects, can be misleading because a recognition system based on 3D descriptions can not easily be discerned from a viewer centered system exposed to a sufficient number of object views. <p> The largely view independent basic level recognition exhibited by adults may be the result of learning of certain irreducible shapes early in life. Even those theories suggesting that recognition involves the indexing of a limited number of volumetric components <ref> [1] </ref> and the detection of their relationships have to face the problem of learning components that cannot be further decomposed. In other words, we still have to achieve representations of some elementary object forms that transcend the special viewpoint of the observer.
Reference: [2] <author> I. Biederman and E.E. Cooper. </author> <title> Evidence for complete translational and reflectional invariance in visual object priming. </title> <journal> Perception, </journal> <volume> 20 </volume> <month> 585-593 </month> <year> 1991. </year>
Reference-contexts: This behavior was specific to those wire-like objects, for which the zero and 180 o views appeared as mirror-symmetrical images of each other, due to accidental minimal self-occlusion. In this respect, the improvement in performance parallels the reflectional invariance observed in human psychophysical experiments <ref> [2] </ref>. Such reflectional invariance may also partly explain the observation that information about bilateral symmetry simplifies the task of 3D recognition by reducing the number of views required to achieve object constancy [30]. <p> Third, for many wire-like objects the animal's recognition was found to exceed criterion performance for views that resembled "mirror-symmetrical", two-dimensional images of each other, due to accidental lack of self-occlusion. Invariance for reflections has been reported earlier in the literature <ref> [2] </ref>, and it clearly represents a form of generalization. Finally, human subjects that were tested for comparison using the same apparatus exhibited recognition performance very similar to that of the tested monkeys.
Reference: [3] <author> M.L. Braunstein. </author> <title> Motion and texture as sources of slant information. </title> <journal> J. Exp. Psychol., </journal> <volume> 78 </volume> <month> 247-253 </month> <year> 1968. </year>
Reference: [4] <author> H.H. Buelthoff and S. Edelman. </author> <title> Psychophysical support for a two-dimensional view interpolation theory of object recognition. </title> <booktitle> Proceedings of the National Academic of Science of the United States of America, </booktitle> <volume> 89 </volume> <month> 60-64 </month> <year> 1992. </year>
Reference: [5] <author> A.R. Damasio. </author> <title> Category-related recogntion defects as a clue to the neural substrates of knowledge. </title> <booktitle> Trends in Neurosciences, </booktitle> <volume> 13 </volume> <month> 95-99 </month> <year> 1990. </year>
Reference-contexts: Evidence as to the importance of shape for object perception comes also from clinical studies showing that the breakdown of recognition, resulting from circumscribed damage to the human cerebral cortex, is most marked at the subordinate level, at which the greatest shape similarities occur <ref> [5] </ref>. Models of recognition differ in the spatial frame used for shape representation. Current theories using object-centered representations assume either a complete three-dimensional description of an object [28], or a structural description of the image specifying the relationships among viewpoint-invariant volumetric primi tives [1,12].
Reference: [6] <author> S. Edelman and H.H. Buelthoff. </author> <title> Orientation dependence in the recognition of familiar and novel views of 3D objects. </title> <journal> Vision Research, </journal> <volume> 32 </volume> <month> 2385-2400 </month> <year> 1992. </year>
Reference-contexts: The stimuli, examples of which are shown in Figure 1, were similar to those used by Edelman and Bulthoff (1992) <ref> [6] </ref> in human psychophysical experiments. Our aim was to examine whether non-human primates show viewpoint in-variance at the subordinate level of recognition.
Reference: [7] <author> D.M. Green and J.A. Swets. </author> <title> Signal detection theory and psychophysics. </title> <publisher> Krieger, </publisher> <address> New York, </address> <year> 1974. </year>
Reference-contexts: To directly compare the network performance with the psychophysical data described above we used the same wire objects used in our first experiment (Generalization Fields), and applied a decision theoretic analysis on the network's output <ref> [7] </ref>. In Figure 8a the curve f T (X), to the right, represents the distribution of network activities that occur on those occasions, in which the input is a view of the target. <p> The area underneath this curve has been shown to amount to the percentage correct performance of an ideal observer in a two-alternative forced-choice (2AFC) task <ref> [7] </ref> (page 45-47). In this model, performance depends solely on the distance d 0 between the means of the f T (X) and f D (X) distributions, revealing the actual sensitivity of the recognition system. The distance d 0 is determined in standard deviation units.
Reference: [8] <author> P. Jolicoeur, M.A. Gluck, and S.M. Kosslyn. </author> <title> Pictures and Names: </title> <journal> Making the Connection . Cognitive Psychology, </journal> <volume> 16 </volume> <month> 243-275 </month> <year> 1984. </year>
Reference: [9] <author> S.J. Judge, B.J. Richmond, and F.C. Chu. </author> <title> Implantation of magnetic search coils for measurement of eye position: An improved method. </title> <journal> Vision Research, </journal> <volume> 20 </volume> <month> 535-538 </month> <year> 1980. </year>
Reference-contexts: The animals were cared for in 1 accordance with the National Institutes of Health Guide, and the guidelines of the Animal Protocol Review Committee of the Baylor College of Medicine. The animals underwent a surgery for the placement of a head restraint post, and a scleral-search eye coil <ref> [9] </ref> for measuring eye movements. The monkeys were given antibiotics (Tribrissen 30 mg/kg) and analgesics (Tylenol 10 mg/kg) orally one day before the operation.
Reference: [10] <author> N.K. Logothetis, J. Pauls, H.H. Buelthoff, and T. Poggio. </author> <title> Evidence for recognition based on interpolation among 2D views of objects in monkeys. </title> <booktitle> Investigative Ophthalmology and Visual Science Supplement, </booktitle> <month> 34:1132 </month> <year> 1992.(Abstract) </year>
Reference: [11] <author> N.K. Logothetis, J. Pauls, H.H. Buelthoff, and T. Poggio. </author> <title> Responses of Inferotemporal (IT) neurons to Novel Wire-Objects in Monkeys trained in an Object Recognition Task. </title> <publisher> Soc. </publisher> <address> Neurosci. Abstr., </address> <month> 19:27 </month> <year> 1993.(Abstract) </year>
Reference-contexts: In the present simulations we assume that each unit's output is superimposed on Gaussian noise, N (V, 2 u ), the sigma 2 u of which was estimated from single-unit data in the inferotemporal cortex of the macaque monkey <ref> [11] </ref>. The four plots in Figure 7c show the output of each RBF unit when presented with views generated by rotations around the vertical axis. Units U 1 through U 4 are centered on the 0, 60, 120, and 180 degree views of the object respectively.
Reference: [12] <author> D. Marr. </author> <title> Vision. </title> <publisher> Freeman, W.H. </publisher> & <address> Comp., San Francisco, </address> <year> 1982. </year>
Reference: [13] <author> N.A. Maxmillan and C.D. Creelman. </author> <title> Detection Theory: A User's Guide. </title> <publisher> Cabridge University Press, </publisher> <address> New York, </address> <year> 1991. </year>
Reference: [14] <author> D.H. McLain. </author> <title> Drawing contours from arbitrary data points. </title> <journal> The Computer Journal, </journal> <volume> 17 </volume> <month> 318-324 </month> <year> 1974. </year>
Reference-contexts: The small squares show performance for each tested view for 240 presentations. The solid line was obtained by a distance weighted least squares smoothing of the data using the McLain algorithm <ref> [14] </ref>. The small insets show examples of the tested views. The monkey could identify correctly the views of the target around the zero view, while its performance dropped below chance levels for disparities larger than 30 degrees for leftward rotations, and larger than 60 degrees for rightward rotations. <p> The spikes on the YZ plane of the plot show the hit rate for each view generated by rotations around the Y axis. The solid line represents a distance-weighted, least-squares smoothing of the data using the McLain algorithm <ref> [14] </ref>. The results show that interpolation between familiar views may be the only generalization achieved by the monkey's recognition system.
Reference: [15] <author> T. Poggio. </author> <title> A Theory of How the Brain Might Work, </title> <booktitle> in Cold Spring Harbor Symposia on Quantitative Biology, </booktitle> <publisher> Cold Spring Harbor Laboratory Press, </publisher> <pages> pp. </pages> <month> 899-910 </month> <year> 1990. </year>
Reference-contexts: Such an interpolation-based network makes both psychophysical and physiological predictions <ref> [15] </ref> that can be directly tested against behavioral performance and single cell activity. In the experiments described below, we trained monkeys to recognize novel objects presented from one view, and subsequently tested their ability to generalize recognition for views generated by mathematically rotating the objects around arbitrary axes.
Reference: [16] <author> T. Poggio and S. Edelman. </author> <title> A network that learns to recognize three-dimensional objects. </title> <journal> Nature, </journal> <volume> 343 </volume> <month> 263-266 </month> <year> 1990. </year>
Reference-contexts: Yet, recent theoretical work shows that a simple network can achieve viewpoint invariance by interpolating between a small number of stored views <ref> [16] </ref>. Computationally, this network uses a small set of sparse data corresponding to an object's training views to synthesize an approximation to a multivariate function representing the object. <p> an object did not 3 improve for any of the opaque, spheroidal objects used in these experiments. 3.2 Generalization Field: Simulations Poggio and Edelman (1990) described a regularization network capable of performing view-independent recognition of three-dimensional wire-like objects, after initial training with a limited set of views of the objects <ref> [16] </ref>. The set size in their experiments, 80-100 views of an object for the entire viewing sphere, predicts a generalization field of about 30 degrees for any given rotation axis, which is in agreement with human psychophysical work [4,6,18,19], and with the data presented in this paper. its output activity.
Reference: [17] <author> T. Poggio and F. Girosi. </author> <title> Regularization algorithms for learning that are equivalent to multilayer networks . Science, </title> <type> 247 </type> <month> 978-982 </month> <year> 1990. </year>
Reference-contexts: The approximation technique is known by the name of Generalized Radial Basis Functions (GRBFs), and it has been shown to be mathematically equivalent to a multilayer network <ref> [17] </ref>. A special case of such a network is that of the Radial Basis Functions (RBFs) that can be conceived of as "hidden-layer" units, the activity of which is a radial function of the disparity between a novel view and a template stored in the unit's memory.
Reference: [18] <author> I. Rock and J. DiVita. </author> <title> A case of viewer-centered object perception . Cognitive Psychology, </title> <type> 19 </type> <month> 280-293 </month> <year> 1987. </year>
Reference: [19] <author> I. Rock, J. DiVita, and R. Barbeito. </author> <title> The effect on form percption of change of orientation in the third dimension. </title> <journal> Journal of Experimental Psychology: Generl, </journal> <volume> 7 </volume> <month> 719-732 </month> <year> 1981. </year>
Reference: [20] <author> B.J. Rogers and M. Graham. </author> <title> Motion parallax as an independant cue for depth perception. </title> <journal> Perception and Psychophysics, </journal> <volume> 8 </volume> <month> 125-134 </month> <year> 1979. </year>
Reference: [21] <author> B.J. Rogers and M. Graham. </author> <title> Similarities between motion parallax and stereopsis in human depth perception. </title> <journal> Vision Research, </journal> <volume> 27 </volume> <month> 261-270 </month> <year> 1982. </year>
Reference: [22] <author> B.J. Rogers and M. Graham. </author> <title> Anisotropies in the perception of three-dimensional surfaces. </title> <journal> Science, </journal> <volume> 221 </volume> <month> 1409-1411 </month> <year> 1983. </year>
Reference: [23] <author> B.J. Rogers and M. Graham. </author> <title> Motion parallax and the perception of three-dimensional surfaces, in Brain Mechanisms and Spatial Vision, D.J. </title> <editor> Ingle et al., eds., </editor> <publisher> Martinus Nijhoff, </publisher> <address> Dordrecht, </address> <year> 1985. </year>
Reference: [24] <author> E. Rosch. </author> <title> Cognitive Representations of Semantic Categories. </title> <journal> J. Exp. Psy. : General, </journal> <volume> 104 </volume> <month> 192-233 </month> <year> 1975. </year>
Reference: [25] <author> E. Rosch, C.B. Mervis, W.D. Gray, D.M. Johnson, and P. Boyes-Braem. </author> <title> Basic objects in natural categories . Cognitive Psychology, </title> <type> 8 </type> <month> 382-439 </month> <year> 1976. </year>
Reference-contexts: Such categories often relate to each other by means of class inclusion, forming taxonomies. Objects are usually recognized first at a particular level of abstraction, called the basic level <ref> [25] </ref>. For example, a Golden-retriever is more likely to be first perceived as a dog, rather than as a retriever or a mammal. Classifications at the basic level carry the highest amount of information about a category and are usually characterized by distinct shapes [25]. <p> of abstraction, called the basic level <ref> [25] </ref>. For example, a Golden-retriever is more likely to be first perceived as a dog, rather than as a retriever or a mammal. Classifications at the basic level carry the highest amount of information about a category and are usually characterized by distinct shapes [25]. Classifications above the basic level, superordinate categories, are more general, while those below the basic level, subordinate categories, are more specific, sharing a great number of attributes with other subordinate categories, and having to a large extent similar shape (for a thorough discussion of categories see [8,24,25]).
Reference: [26] <author> R.M. Siegel and R.A. Andersen. </author> <title> Perception of three-dimensional structure from motion in monkey and man. </title> <journal> Nature, </journal> <volume> 331 </volume> <month> 259-261 </month> <year> 1988. </year>
Reference-contexts: In fact, psychometric functions showing depth modulation thresholds as a function of spatial frequency of 3D corrugations are very similar for surfaces specified through either disparity or motion parallax cues [21-23]. Furthermore, experiments on monkeys have shown that nonhuman primates, too, possess the ability to see structure from motion <ref> [26] </ref> in random-dot kinematograms. Thus, during the learning phase of each observation period, information about the three-dimensional structure of the target was available to the monkey by virtue of shading, the kinetic depth effect, and minimal self-occlusion.
Reference: [27] <author> M. Tarr and S. Pinker. </author> <title> When does human object recognition use a viewer-centered referenceframe? Psychological Science, </title> <type> 1 </type> <month> 253-256 </month> <year> 1990. </year>
Reference: [28] <author> S. Ullman. </author> <title> Aligning pictorial descriptions: An approach to object recognition. </title> <journal> Cognition, </journal> <volume> 32 </volume> <month> 193-254 </month> <year> 1989. </year>
Reference-contexts: 1 Introduction Most theories of object recognition assume that the visual system stores a representation of an object and that recognition occurs when this stored representation is matched to its corresponding sensory representation generated from the viewed object <ref> [28] </ref>. <p> Models of recognition differ in the spatial frame used for shape representation. Current theories using object-centered representations assume either a complete three-dimensional description of an object <ref> [28] </ref>, or a structural description of the image specifying the relationships among viewpoint-invariant volumetric primi tives [1,12]. In contrast, viewer-centered representations model three-dimensional objects as a set of 2D views, or aspects, and recognition consists of matching image features against the views in this set.
Reference: [29] <author> S. Ullman and R. Basri. </author> <title> Recognition by Linear Combinations of Models. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <month> 992-1005 </month> <year> 1991. </year>
Reference-contexts: Furthermore, unlike schemes based on linear combination of 2D views <ref> [29] </ref>, the non-linear interpolation model predicts recognition of novel views beyond the above measured generalization field to occur for only those views situated between the templates.
Reference: [30] <author> T. Vetter, T. Poggio, and H.H. B lthoff. </author> <title> The importance of symmetry and virtual views in three-dimensional object recognition. </title> <journal> Curr. Biol., </journal> <volume> 4 </volume> <month> 18-23 </month> <year> 1994. </year>
Reference-contexts: In this respect, the improvement in performance parallels the reflectional invariance observed in human psychophysical experiments [2]. Such reflectional invariance may also partly explain the observation that information about bilateral symmetry simplifies the task of 3D recognition by reducing the number of views required to achieve object constancy <ref> [30] </ref>.

References-found: 30

