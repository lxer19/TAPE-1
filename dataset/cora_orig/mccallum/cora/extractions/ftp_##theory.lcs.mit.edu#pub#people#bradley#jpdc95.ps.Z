URL: ftp://theory.lcs.mit.edu/pub/people/bradley/jpdc95.ps.Z
Refering-URL: http://theory.lcs.mit.edu/~supertech/papers.html
Root-URL: 
Title: The Network Architecture of the Connection Machine CM-5  
Author: Charles E. Leiserson,Zahi S. Abuhamdeh,David C. Douglas,Carl R. Feynman,Mahesh N. Ganmukhi, Jeffrey V. Hill,W. Daniel Hillis,Bradley C. Kuszmaul,Margaret A. St. Pierre,David S. Wells, Monica C. Wong-Chan,Shaw-Wen Yang,and Robert Zak 
Date: February 7, 1996  
Address: Cambridge, Massachusetts 02142  
Affiliation: Thinking Machines Corporation  
Abstract: The Connection Machine Model CM-5 Supercomputer is a massively parallel computer system designed to offer performance in the range of 1 teraflops (10 12 floating-point operations per second). The CM-5 obtains its high performance while offering ease of programming, flexibility, and reliability. The machine contains three communication networks: a data network, a control network, and a diagnostic network. This paper describes the organization of these three networks and how they contribute to the design goals of the CM-5. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> IEEE Std 1149.1-1990. </author> <title> IEEE standard test access port and boundary-scan architecture, </title> <year> 1990. </year>
Reference-contexts: Moreover, when these tests fail, they provide specific information on the location and extent of the failure. In the CM-5, design for testablity starts at the chip level. All CM-5 VLSI components support the IEEE 1149.1 testability architecture standard <ref> [1] </ref>, also known as JTAG, for the Joint Test Action Group which originated the standard. 1 At the system level, the CM-5 diagnostic network provides parallel access to all system components from a diagnostic processor.
Reference: [2] <author> G. E. Blelloch. </author> <title> Vector Models for Data-Parallel Computing. </title> <publisher> The MIT Press, </publisher> <year> 1990. </year>
Reference-contexts: To offset this deficiency, the CM-5 also contains a control network, which makes synchronization and multiparty communication primitives competitive with comparable functions on SIMD machines. These primitives include the fast broadcasting of data, barrier synchronization [5, 11, 20], and parallel prefix (scan) operations <ref> [2] </ref>. nodes, each of which contains a 32-megahertz SPARC processor, 32 megabytes of memory, and a 128-megaflops vector-processing unit capable of processing 64-bit floating-point and integer numbers. System administration tasks and serial user tasks are executed by a collection of control processors, which are Sun Microsystems workstation computers. <p> Backward scans are also supported. All basic scan operations use 1-word (32-bit) inputs, but multiple-word scans are supported by a sequence of 1-word scans in a manner similar to multiple-word reductions. An excellent discussion of scans can be found in <ref> [2] </ref>. Early on in the design of the CM-5, we decided to support scans in hardware. Our experience with the CM-2 showed that many high-performance data-parallel algorithms|including both combinatorial and numerical algorithms|make extensive use of scans. <p> When a multiple-source message finally reaches the root, it is sent downward. As it reencounters the internal nodes of the tree, it is replicated or further combined with waiting messages. (A good overview of the implementation of scans can be found in <ref> [2] </ref>.) While a multiple-source packet is waiting for a sibling or a parent, other packets arriving on the same input can be processed. If the newly arriving packet is a single-source packet, it proceeds ahead of the waiting packet, thereby giving priority, for example, to supervisor broadcasts and interrupts.
Reference: [3] <author> W. J. Dally. </author> <title> Wire-efficient VLSI multiprocessor communication networks. </title> <editor> In Paul Losleben, editor, </editor> <booktitle> Proceedings of the 1987 Stanford Conference on Advanced Research in VLSI, </booktitle> <pages> pages 391-415, </pages> <address> Cambridge, MA, 1987. </address> <publisher> The MIT Press. </publisher>
Reference-contexts: Message integrity is checked on every link and through every switch. If a message is found to be corrupted, an error is signaled. Messages snake their way through the switches in a manner similar to cut-through [12] or worm-hole <ref> [3, 4] </ref> routing, and so by the time that a data-network chip has detected an error, the head of the message may have traveled far away. To avoid an avalanche of errors, the complement of a proper CRC is appended to the message.
Reference: [4] <author> W. J. Dally and C. L. Seitz. </author> <title> Deadlock-free message routing in multiprocessor interconnection networks. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-36(5):547-553, </volume> <month> May </month> <year> 1987. </year>
Reference-contexts: Message integrity is checked on every link and through every switch. If a message is found to be corrupted, an error is signaled. Messages snake their way through the switches in a manner similar to cut-through [12] or worm-hole <ref> [3, 4] </ref> routing, and so by the time that a data-network chip has detected an error, the head of the message may have traveled far away. To avoid an avalanche of errors, the complement of a proper CRC is appended to the message.
Reference: [5] <author> F. Darema-Rogers, D. A. George, V. A. Norton, and G. F. Pfister. </author> <title> A single-program-multiple-data computational model for EPEX/FORTRAN. </title> <type> Research Report RC 11552, </type> <institution> Computer Sciences Department, IBM T. J. Watson Research Center, </institution> <address> Yorktown Heights, NY, </address> <month> November </month> <year> 1986. </year>
Reference-contexts: To offset this deficiency, the CM-5 also contains a control network, which makes synchronization and multiparty communication primitives competitive with comparable functions on SIMD machines. These primitives include the fast broadcasting of data, barrier synchronization <ref> [5, 11, 20] </ref>, and parallel prefix (scan) operations [2]. nodes, each of which contains a 32-megahertz SPARC processor, 32 megabytes of memory, and a 128-megaflops vector-processing unit capable of processing 64-bit floating-point and integer numbers.
Reference: [6] <author> M. Dubois and S. Thakkar, </author> <title> editors. Cache Architectures in Tightly Coupled Multiprocessors. </title> <publisher> IEEE Computer Society, </publisher> <month> June </month> <year> 1990. </year> <journal> Special Issue of Computer, </journal> <volume> Volume 23, Number 6. </volume>
Reference-contexts: Each processor in the CM-5 executes its own instructions, providing the flexibility of a typical MIMD machine. And, like many MIMD machines, the CM-5 is a distributed memory machine (as opposed to shared memory machine <ref> [6, 8] </ref>) in which processors communicate among themselves by sending messages [18, 19] through the data network of the machine. A deficiency of typical MIMD machines, especially as compared with their SIMD cousins, however, is that they provide little or no support for coordinating and synchronizing sets of processors.
Reference: [7] <author> M. J. Flynn. </author> <title> Very high speed computing systems. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 54(12) </volume> <pages> 1901-1909, </pages> <month> December </month> <year> 1966. </year>
Reference-contexts: This paper describes the architecture of each of these three networks and the rationale behind them. The CM-5 is a synchronized MIMD machine, which combines the best aspects of SIMD (single instruction stream, multiple data stream) and MIMD (multiple instruction stream, multiple data stream) machines <ref> [7] </ref>. Each processor in the CM-5 executes its own instructions, providing the flexibility of a typical MIMD machine.
Reference: [8] <author> A. Gottlieb, R. Grishman, C. P. Kruskal, K. P. McAuliffe, L. Rudolph, and M. Snir. </author> <title> The NYU Ultracomputer| designing a MIMD, shared-memory parallel machine. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-32(2):175-159, </volume> <month> February </month> <year> 1983. </year>
Reference-contexts: Each processor in the CM-5 executes its own instructions, providing the flexibility of a typical MIMD machine. And, like many MIMD machines, the CM-5 is a distributed memory machine (as opposed to shared memory machine <ref> [6, 8] </ref>) in which processors communicate among themselves by sending messages [18, 19] through the data network of the machine. A deficiency of typical MIMD machines, especially as compared with their SIMD cousins, however, is that they provide little or no support for coordinating and synchronizing sets of processors.
Reference: [9] <author> R. I. Greenberg and C. E. Leiserson. </author> <title> Randomized routing on fat-trees. </title> <booktitle> Advances in Computing Research, </booktitle> <volume> 5 </volume> <pages> 345-374, </pages> <year> 1989. </year>
Reference-contexts: In addition, it helps solve several system problems, including the problem of balancing message loads in the network, the so-called "fetch-deadlock problem," and the problem of timesharing a parallel computer. The basic architecture of the CM-5 data network is a fat-tree <ref> [9, 15] </ref>. Figure 2 shows a binary fat-tree. Unlike a computer scientist's traditional notion of a tree, a fat-tree is more like a real tree in that it gets thicker further from 3 the channel capacities of a fat-tree increase as we ascend from leaves to root. <p> A fat-tree can be adapted to effectively utilize whatever bandwidths make engineering sense in terms of cost and performance. No matter how the bandwidths of the fat-tree are chosen, provably effective routing algorithms exist <ref> [9, 14] </ref> to route messages near-optimally. The underlying architecture and mechanism for addressing is not affected by communication bandwidths: to route a message from one processor to another, the message is sent up the tree to the least common ancestor of the two processors, and then down to the destination.
Reference: [10] <author> R. Gupta. </author> <title> The fuzzy barrier: A mechanism for high speed synchronization of processors. </title> <booktitle> In Third International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 54-63, </pages> <address> Boston, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: One of the two asynchronous OR's is privileged, and the other is nonprivileged. The synchronous OR or any of the various combining operations can be used to implement split-phase barrier synchronization [22]. (In independent work <ref> [10] </ref>, this type of synchronization has been called a fuzzy barrier.) In a split-phase barrier, the barrier is a region of code with an entry and an exit. (If the region is empty, an ordinary 9 word of data, some synchronization bits, and various other flags.
Reference: [11] <author> H. F. Jordan. </author> <title> A multi-microprocessor system for finite element structural analysis. </title> <editor> In A. K. Noor and Jr. McComb, H. G., editors, </editor> <booktitle> Trends in Computerized Structural Analysis and Synthesis, </booktitle> <pages> pages 21-29. </pages> <publisher> Pergamon Press Ltd, </publisher> <year> 1978. </year> <note> Published as a special issue of Computers & Structures, Volume 10, Numbers 1-2. </note>
Reference-contexts: To offset this deficiency, the CM-5 also contains a control network, which makes synchronization and multiparty communication primitives competitive with comparable functions on SIMD machines. These primitives include the fast broadcasting of data, barrier synchronization <ref> [5, 11, 20] </ref>, and parallel prefix (scan) operations [2]. nodes, each of which contains a 32-megahertz SPARC processor, 32 megabytes of memory, and a 128-megaflops vector-processing unit capable of processing 64-bit floating-point and integer numbers.
Reference: [12] <author> P. Kermani and L. Kleinrock. </author> <title> Virtual cut-through: A new computer communication switching technique. </title> <journal> Computer Networks, </journal> <volume> 3 </volume> <pages> 267-286, </pages> <year> 1979. </year> <month> 15 </month>
Reference-contexts: Message integrity is checked on every link and through every switch. If a message is found to be corrupted, an error is signaled. Messages snake their way through the switches in a manner similar to cut-through <ref> [12] </ref> or worm-hole [3, 4] routing, and so by the time that a data-network chip has detected an error, the head of the message may have traveled far away. To avoid an avalanche of errors, the complement of a proper CRC is appended to the message.
Reference: [13] <author> Leonard Kleinrock. </author> <title> Principles and lessons in packet communications. </title> <booktitle> Proceedings of the IEEE, </booktitle> <volume> 66(11) </volume> <pages> 1320-1329, </pages> <month> November </month> <year> 1978. </year>
Reference-contexts: With buffer space proportional to the number of processors in the system, it is possible to construct a "round-trip" protocol that solves the fetch-deadlock problem. The key idea is to program a reservation mechanism <ref> [13] </ref> that ensures that at most a bounded number of messages are outstanding between any two processors at any time. A processor X does not attempt to send a message to another processor Y until Y informs X that it has room to handle the message.
Reference: [14] <author> F. T. Leighton, B. Maggs, and S. Rao. </author> <title> Universal packet routing algorithms. </title> <booktitle> In 29th Annual IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 256-271, </pages> <year> 1988. </year>
Reference-contexts: A fat-tree can be adapted to effectively utilize whatever bandwidths make engineering sense in terms of cost and performance. No matter how the bandwidths of the fat-tree are chosen, provably effective routing algorithms exist <ref> [9, 14] </ref> to route messages near-optimally. The underlying architecture and mechanism for addressing is not affected by communication bandwidths: to route a message from one processor to another, the message is sent up the tree to the least common ancestor of the two processors, and then down to the destination.
Reference: [15] <author> C. E. Leiserson. Fat-trees: </author> <title> Universal networks for hardware-efficient supercomputing. </title> <journal> IEEE Transactions on Computers, </journal> <volume> C-34(10):892-901, </volume> <month> October </month> <year> 1985. </year>
Reference-contexts: In addition, it helps solve several system problems, including the problem of balancing message loads in the network, the so-called "fetch-deadlock problem," and the problem of timesharing a parallel computer. The basic architecture of the CM-5 data network is a fat-tree <ref> [9, 15] </ref>. Figure 2 shows a binary fat-tree. Unlike a computer scientist's traditional notion of a tree, a fat-tree is more like a real tree in that it gets thicker further from 3 the channel capacities of a fat-tree increase as we ascend from leaves to root. <p> Short of this bandwidth restriction, however, any connection of control processors to legal partitions can be implemented using an off-line routing algorithm similar to that in <ref> [15, Theorem 1] </ref>. In summary, the CM-5 control network provides the mechanisms to allow data-parallel code to be executed efficiently, as well as allowing more general kinds of parallel models to be implemented.
Reference: [16] <author> C. E. Leiserson and B. M. Maggs. </author> <title> Communication-efficient parallel algorithms for distributed random-access machines. </title> <journal> Algorithmica, </journal> <volume> 3 </volume> <pages> 53-77, </pages> <year> 1988. </year>
Reference-contexts: Moreover, an accurate estimate of the performance of routing a set of messages through the network can be predicted by using a relatively simple model <ref> [16] </ref>. One determines the load of messages passing through each arm of the fat-tree and divides this value by the available bandwidth. The worst-case such ratio, over all arms of the fat-tree, provides the estimate.
Reference: [17] <author> M. St. Pierre, S.-W. Yang, and D. Cassiday. </author> <title> Functional VLSI design verification methodology for the CM 5 massively parallel supercomputer. </title> <booktitle> In 1992 IEEE International Conference on Computer Design: VLSI in Computers & Processors (ICCD '92), </booktitle> <pages> pages 430-445, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Within two days after the interface chips arrived, we had assembled the networks for a 2-node machine and powered it up, a feat due in large measure to our functional verification methodology <ref> [17] </ref>. That same day, the operating system|which had been developed on a simulator|functioned correctly on the machine. By year's end, we had successfully constructed several small machines, including a 64-node machine, some of which were dedicated to software development.
Reference: [18] <author> C. L. Seitz. </author> <title> The cosmic cube. </title> <journal> Communications of the ACM, </journal> <volume> 28(1) </volume> <pages> 22-23, </pages> <month> January </month> <year> 1985. </year>
Reference-contexts: Each processor in the CM-5 executes its own instructions, providing the flexibility of a typical MIMD machine. And, like many MIMD machines, the CM-5 is a distributed memory machine (as opposed to shared memory machine [6, 8]) in which processors communicate among themselves by sending messages <ref> [18, 19] </ref> through the data network of the machine. A deficiency of typical MIMD machines, especially as compared with their SIMD cousins, however, is that they provide little or no support for coordinating and synchronizing sets of processors.
Reference: [19] <author> C. L. Seitz, W. C. Athas, W. J. Dally, R. Faucette, A. J. Martin, S. Mattisson, C. S. Steele, and W.-K. Su. </author> <title> Message-Passing Concurrent Computers: Their Architecture and Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: Each processor in the CM-5 executes its own instructions, providing the flexibility of a typical MIMD machine. And, like many MIMD machines, the CM-5 is a distributed memory machine (as opposed to shared memory machine [6, 8]) in which processors communicate among themselves by sending messages <ref> [18, 19] </ref> through the data network of the machine. A deficiency of typical MIMD machines, especially as compared with their SIMD cousins, however, is that they provide little or no support for coordinating and synchronizing sets of processors.
Reference: [20] <author> P. Tang and P.-C. Yew. </author> <title> Processor self-scheduling for multiple-nested parallel loops. </title> <editor> In K. Hwang, S. M. Jacobs, and E. E. Swartzlander, editors, </editor> <booktitle> Proceedings of the 1986 International Conference on Parallel Processing, </booktitle> <pages> pages 528-535, </pages> <month> August </month> <year> 1986. </year>
Reference-contexts: To offset this deficiency, the CM-5 also contains a control network, which makes synchronization and multiparty communication primitives competitive with comparable functions on SIMD machines. These primitives include the fast broadcasting of data, barrier synchronization <ref> [5, 11, 20] </ref>, and parallel prefix (scan) operations [2]. nodes, each of which contains a 32-megahertz SPARC processor, 32 megabytes of memory, and a 128-megaflops vector-processing unit capable of processing 64-bit floating-point and integer numbers.
Reference: [21] <institution> Texas Instruments. </institution> <month> SN54ACT8997, </month> <title> SN74ACT8997 Scan Path Linker With 4-bit Identification Bus, </title> <month> April </month> <year> 1990. </year> <title> Product Preview. </title>
Reference-contexts: The clock and control pins are connected in parallel so that these signals can be broadcast to all chips in the chain. Previous designs have focused on reducing the length of very long scan chains by placing scan-controllable bypass elements in the scan chain <ref> [21] </ref>. Unfortunately, testing all the chips in the system still requires serial access to each one. Even with ideally short test times on the order of seconds per device, this method would be unacceptably slow for an entire 16,384-node CM-5 comprising many tens of thousands of devices.
Reference: [22] <institution> Thinking Machines Corporation, </institution> <note> applicant. </note> <author> W. Daniel Hillis, </author> <title> inventor. European Patent Application Serial Number 89 902 461.6, priority date of February 2, 1988, entitled Method and Apparatus For Aligning The Operation Of A Plurality Of Processors. </title> <note> Also International Application Number WO 89/07299 (Published under the Patent Cooperation Treaty), Publication Date 10 August 1989. </note>
Reference-contexts: The transition of an asynchronous OR from 0 to 1 can be used to signal an interrupt. One of the two asynchronous OR's is privileged, and the other is nonprivileged. The synchronous OR or any of the various combining operations can be used to implement split-phase barrier synchronization <ref> [22] </ref>. (In independent work [10], this type of synchronization has been called a fuzzy barrier.) In a split-phase barrier, the barrier is a region of code with an entry and an exit. (If the region is empty, an ordinary 9 word of data, some synchronization bits, and various other flags.
Reference: [23] <institution> Thinking Machines Corporation, </institution> <address> 245 First Street, Cambridge, MA 02154-1264. </address> <booktitle> The Connection Machine CM-5 Technical Summary, </booktitle> <month> October </month> <year> 1991. </year>
Reference-contexts: The paper closes with Section 6, which gives a short history of our development project. Further details about the CM-5 system can be found in the CM-5 Technical Summary <ref> [23] </ref>. The reader should be aware that the performance specifications quoted in this paper apply only to the initial release of the CM-5 system.
Reference: [24] <author> R. Zak and J. Hill. </author> <title> An IEEE 1149.1 compliant testability architecture with internal scan. </title> <booktitle> In 1992 IEEE International Conference on Computer Design: VLSI in Computers & Processors (ICCD '92), </booktitle> <pages> pages 436-443, </pages> <month> October </month> <year> 1992. </year> <month> 16 </month>
Reference-contexts: In the CM-5, we extended the JTAG standard to include full internal scan in all proprietary chips. Details of this design are described in <ref> [24] </ref>. The use of a full internal scan allows software for automatically generating test patterns to generate a set of scan vectors with very high fault coverage. The vectors can be applied through the JTAG interface to test individual chips when they are manufactured and packaged.
References-found: 24

