URL: http://ftp.eecs.umich.edu/people/wellman/psc90.ps.Z
Refering-URL: http://ftp.eecs.umich.edu/people/wellman/
Root-URL: http://www.eecs.umich.edu
Email: doyle@zermatt.lcs.mit.edu  wellman@wrdc.af.mil  
Title: on Innovative Approaches to Planning, Scheduling and Control, Novem- Rational Distributed Reason Maintenance for Planning
Author: ber, , Katia P. Sycara, Jon Doyle Michael P. Wellman 
Address: 545 Technology Square Cambridge, MA 02139  OH 45433  
Affiliation: MIT Laboratory for Computer Science  USAF Wright R&D Center WRDC/TXI Wright-Patterson AFB,  
Note: Reprinted from Proceedings of the DARPA Workshop  editor, San Mateo: Morgan Kaufmann Publishers, pp. 28-36.  
Abstract: Efficiency dictates that plans for large-scale distributed activities be revised incrementally, with parts of plans being revised only if the expected utility of identifying and revising the subplans improve on the expected utility of using the original plan. The problems of identifying and reconsidering the subplans affected by changed circumstances or goals are closely related to the problems of revising beliefs as new or changed information is gained. But the current techniques of reason maintenance| the standard method for belief revision|choose revisions arbitrarily and enforce global notions of consistency and groundedness which may mean reconsidering all beliefs or plan elements at each step. We outline revision methods that revise only those beliefs and plans worth revising, and that tolerate incoherence and ungroundedness when these are judged less detrimental than a costly revision effort. 
Abstract-found: 1
Intro-found: 1
Reference: [ Bond and Glasser, 1988 ] <editor> Alan Bond and Les Glasser, editors. </editor> <booktitle> Readings in Distributed Artificial Intelligence. </booktitle> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1988. </year>
Reference-contexts: Most work on distributed AI has not addressed issues of belief or plan revision, focusing instead on distributing the effort involved in ordinary reasoning and planning <ref> [ Bond and Glasser, 1988 ] </ref> . Very recently, however, some distributed RMSs have been developed. While these represent important first steps, they are not at present suitable bases for rational plan revision.
Reference: [ Bridgeland and Huhns, 1990 ] <author> David Murray Bridge-land and Michael N. Huhns. </author> <title> Distributed truth maintenance. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence. AAAI, </booktitle> <year> 1990. </year>
Reference: [ Brooks, 1986 ] <author> Rodney A. Brooks. </author> <title> A robust layered control system for a mobile robot. </title> <journal> IEEE Journal of Robotics and Automation, </journal> <volume> 2 </volume> <pages> 14-23, </pages> <year> 1986. </year>
Reference: [ Carbonell, 1986 ] <author> Jaime G. Carbonell. </author> <title> Derivational analogy: A theory of reconstructive problem solving and expertise acquisition. </title> <editor> In Ryszard S. Michalski, Jaime G. Carbonell, and Tom M. Mitchell, editors, </editor> <booktitle> Machine Learning 2. </booktitle> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference-contexts: That is, we view reasons as information about past computations or conditions which may be used to reconstruct results in changed circumstances, either exactly or in modified form (as in derivational analogy <ref> [ Carbonell, 1986 ] </ref> or case-based reasoning).
Reference: [ Collins et al., 1989 ] <author> Gregg Collins, Lawrence Birn-baum, and Bruce Krulwich. </author> <title> An adaptive model of decision-making in planning. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 511-516, </pages> <year> 1989. </year>
Reference: [ de Kleer, 1986 ] <author> Johan de Kleer. </author> <title> An assumption-based TMS. </title> <journal> Artificial Intelligence, </journal> <volume> 28 </volume> <pages> 127-162, </pages> <year> 1986. </year>
Reference-contexts: Characterizing the computational costs and performance of the revision process contributes toward solutions to the second problem, development of a contingency planning strategy. Our techniques center on a reason maintenance system or RMS (also known as TMS for "truth maintenance system" <ref> [ de Kleer, 1986; Doyle, 1979 ] </ref> ), redesigned for more rational and flexible control. 2 Rational replanning To replan effectively in crisis situations, replanning must be incremental , so that it modifies only the portions of the plan actually affected by the changes. <p> For example, the system will ordinarily use reasons to construct a single global set of beliefs, as in the original RMS. But for some specific sets of reasons, say those corresponding to a circumscribed problem, the RDRMS may determine all consistent sets of beliefs as in the ATMS <ref> [ de Kleer, 1986 ] </ref> . Alternatively, only some consistent interpretations may be constructed, such as those maximal in some order (as in preferential nonmonotonic logics [ Shoham, 1988 ] ). In general, the aim is to use the recorded reasons to draw as many conclusions as the reasoner needs.
Reference: [ de Kleer et al., 1977 ] <author> Johan de Kleer, Jon Doyle, Guy L. Steele Jr., et al. Amord: </author> <title> Explicit control of reasoning. </title> <booktitle> In Proceedings of the ACM Symposium on Artificial Intelligence and Programming Languages, </booktitle> <pages> pages 116-125, </pages> <year> 1977. </year>
Reference-contexts: This possibility was, in fact, one of the original motivations for reason maintenance systems (see <ref> [ de Kleer et al., 1977 ] </ref> ). 4.1 Rational reason maintenance But the extant architectures for reason maintenance require reassessment. <p> also depend on other facts, such as how hard it was for the reasoner to discover the belief, so we cannot expect the RDRMS to make all such decisions on its own. 6 Comparison with other work Reason maintenance is the standard approach to belief revision, backtracking, and default reasoning <ref> [ de Kleer et al., 1977; Doyle, 1979; Goodwin, 1987 ] </ref> . Morris [ 1988 ] has shown that a standard RMS can support planning and dependency-directed replanning within the classical planning framework.
Reference: [ Dean, 1990 ] <author> Thomas Dean. </author> <title> Decision-theoretic control of inference for time-critical applications. </title> <type> Technical Report CS-90-44, </type> <institution> Department of Computer Science, Brown University, Providence, RI, </institution> <year> 1990. </year>
Reference-contexts: Many of these techniques therefore require some reworking before they can be said to produce rational plans, and the issue of rational control of the planning process is just now beginning to be studied <ref> [ Dean, 1990; Smith, 1988 ] </ref> . Another approach is the "reactive" approach to planning and action, which seeks to avoid execution-time planning by "compiling" all necessary behaviors into directly applicable forms [ Brooks, 1986; Georgeff and Lan-sky, 1987; Rosenschein and Kaelbling, 1986; Schoppers, 1987 ] .
Reference: [ Doyle, 1979 ] <author> Jon Doyle. </author> <title> A truth maintenance system. </title> <journal> Artificial Intelligence, </journal> <volume> 12(2) </volume> <pages> 231-272, </pages> <year> 1979. </year>
Reference-contexts: Characterizing the computational costs and performance of the revision process contributes toward solutions to the second problem, development of a contingency planning strategy. Our techniques center on a reason maintenance system or RMS (also known as TMS for "truth maintenance system" <ref> [ de Kleer, 1986; Doyle, 1979 ] </ref> ), redesigned for more rational and flexible control. 2 Rational replanning To replan effectively in crisis situations, replanning must be incremental , so that it modifies only the portions of the plan actually affected by the changes. <p> also depend on other facts, such as how hard it was for the reasoner to discover the belief, so we cannot expect the RDRMS to make all such decisions on its own. 6 Comparison with other work Reason maintenance is the standard approach to belief revision, backtracking, and default reasoning <ref> [ de Kleer et al., 1977; Doyle, 1979; Goodwin, 1987 ] </ref> . Morris [ 1988 ] has shown that a standard RMS can support planning and dependency-directed replanning within the classical planning framework.
Reference: [ Doyle, 1985 ] <author> Jon Doyle. </author> <title> Reasoned assumptions and Pareto optimality. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 87-90, </pages> <year> 1985. </year>
Reference-contexts: Though the algorithms for determining these sets of conclusions do not involve any explicit rationality calculations, the conclusions drawn by the RMS can be shown to be Pareto optimal sets, that is, rational choices of conclusions when the reasons are interpreted as preferences over states of belief <ref> [ Doyle, 1985 ] </ref> . Viewed this way, default rules or reasons encode compiled preferences, and reason maintenance is an example of an implicitly rational choice mechanism.
Reference: [ Doyle, 1988 ] <author> Jon Doyle. </author> <title> Artificial intelligence and rational self-government. </title> <type> Technical Report CS-88-124, </type> <institution> 8 Carnegie-Mellon University Computer Science De--partment, </institution> <year> 1988. </year>
Reference-contexts: But if we are to achieve the efficiency required for revising large plans, reason maintenance must be redesigned to make these choices rationally whenever possible. Accordingly, we have begun to develop formal foundations for the theory of rational belief revision <ref> [ Doyle, 1988; Doyle, 1990 ] </ref> , and are developing techniques for encoding probabilistic and preferential information within the RMS and methods by which the RMS can use this information to backtrack in a rational manner.
Reference: [ Doyle, 1990 ] <author> Jon Doyle. </author> <title> Rational belief revision. </title> <booktitle> In Proceedings of the Third International Workshop on Nonmonotonic Reasoning, Stanford Sierra Camp, </booktitle> <address> CA, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: But if we are to achieve the efficiency required for revising large plans, reason maintenance must be redesigned to make these choices rationally whenever possible. Accordingly, we have begun to develop formal foundations for the theory of rational belief revision <ref> [ Doyle, 1988; Doyle, 1990 ] </ref> , and are developing techniques for encoding probabilistic and preferential information within the RMS and methods by which the RMS can use this information to backtrack in a rational manner.
Reference: [ Fikes et al., 1972 ] <author> Richard E. Fikes, Peter E. Hart, and Nils J. Nilsson. </author> <title> Learning and executing generalized robot plans. </title> <journal> Artificial Intelligence, </journal> <volume> 3 </volume> <pages> 251-288, </pages> <year> 1972. </year>
Reference-contexts: Most work on generative planning has concentrated on planning from scratch, though the replanning task has been studied off and on over the years <ref> [ Fikes et al., 1972; McDermott, 1978; Wilkins, 1988 ] </ref> with some success. But generative planning has focused|with a few recent exceptions| on planning without probability or utility information.
Reference: [ Fox, 1987 ] <author> Mark S. Fox. </author> <title> Constraint-Directed Search: A Case Study of Job-Shop Scheduling. </title> <publisher> Pitman and Mor-gan Kaufmann, </publisher> <year> 1987. </year>
Reference-contexts: In addition, our assumption of distributed execution authorities and replanners explicitly accounts for the reactive abilities of the distributed execution modules. The constraint-based approach to scheduling <ref> [ Fox, 1987 ] </ref> complements the generative planning approach in many ways, as it does focus on issues of utility and optimization.
Reference: [ Gardenfors, 1988 ] <author> Peter Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1988. </year>
Reference-contexts: This corresponds to the "revision" operation in philosophical treatments of belief revision <ref> [ Gardenfors, 1988 ] </ref> .) Specifically, without explicit instructions, the RDRMS does not propagate changes, does not ensure beliefs are grounded, and does not automatically backtrack to remove inconsistencies. To give some structure to these operations, we define revision instructions relative to the modules of the knowledge base.
Reference: [ Georgeff and Lansky, 1987 ] <author> Michael P. Georgeff and Amy L. Lansky. </author> <title> Reactive reasoning and planning. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> pages 677-682, </pages> <year> 1987. </year>
Reference: [ Goodwin, 1987 ] <author> James W. Goodwin. </author> <title> A theory and system for non-monotonic reasoning. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Science, Linkoping University, Linkoping, Sweden, </institution> <year> 1987. </year> <booktitle> Linkoping Studies in Science and Technology, </booktitle> <volume> No. </volume> <pages> 165. </pages>
Reference-contexts: also depend on other facts, such as how hard it was for the reasoner to discover the belief, so we cannot expect the RDRMS to make all such decisions on its own. 6 Comparison with other work Reason maintenance is the standard approach to belief revision, backtracking, and default reasoning <ref> [ de Kleer et al., 1977; Doyle, 1979; Goodwin, 1987 ] </ref> . Morris [ 1988 ] has shown that a standard RMS can support planning and dependency-directed replanning within the classical planning framework.
Reference: [ Hammond, 1986 ] <author> Kristian Hammond. </author> <title> Case-based Planning: An Integrated Theory of Planning, Learning and Memory. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <year> 1986. </year>
Reference: [ Hewitt, 1986 ] <author> Carl Hewitt. </author> <title> Offices are open systems. </title> <journal> ACM Transactions on Office Information Systems, </journal> <volume> 4 </volume> <pages> 271-287, </pages> <year> 1986. </year>
Reference-contexts: Ordinarily the specialized beliefs corresponding to specific problems or subjects will be represented in modules that are internally consistent, but the RDRMS need not be forced to keep all these modules consistent with each other. In this case, the locally coherent modules can be interpreted as "microtheories" <ref> [ Hewitt, 1986 ] </ref> (related to the idea of "small worlds" in decision theory [ Savage, 1972 ] ). But inconsistency can arise even within a module if too little inference is specified. Another consequence is that the beliefs of the system may not be fully grounded.
Reference: [ Horvitz et al., 1989 ] <author> Eric J. Horvitz, Gregory F. Cooper, and David E. Heckerman. </author> <title> Reflection and action under scarce resources: Theoretical principles and empirical study. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1121-1127, </pages> <year> 1989. </year>
Reference: [ Lansky, 1988 ] <author> Amy L. Lansky. </author> <title> Localized event-based reasoning for multiagent domains. </title> <journal> Computational Intelligence, </journal> <volume> 4 </volume> <pages> 319-340, </pages> <year> 1988. </year>
Reference: [ Mason and Johnson, 1989 ] <author> Cindy L. Mason and Roland R. Johnson. DATMS: </author> <title> A framework for distributed assumption based reasoning. </title> <editor> In Les Gasser and Michael N. Huhns, editors, </editor> <booktitle> Distributed Artificial Intelligence, chapter 13, </booktitle> <pages> pages 293-317. </pages> <publisher> Morgan Kauf-mann, </publisher> <address> San Mateo, CA, </address> <year> 1989. </year>
Reference: [ McDermott, 1978 ] <author> Drew McDermott. </author> <title> Planning and acting. </title> <journal> Cognitive Science, </journal> <volume> 2 </volume> <pages> 71-109, </pages> <year> 1978. </year>
Reference-contexts: Most work on generative planning has concentrated on planning from scratch, though the replanning task has been studied off and on over the years <ref> [ Fikes et al., 1972; McDermott, 1978; Wilkins, 1988 ] </ref> with some success. But generative planning has focused|with a few recent exceptions| on planning without probability or utility information.
Reference: [ Minsky, 1975 ] <author> Marvin Minsky. </author> <title> A framework for representing knowledge. </title> <editor> In Patrick Henry Winston, editor, </editor> <booktitle> The Psychology of Computer Vision, chapter 6, </booktitle> <pages> pages 211-277. </pages> <publisher> McGraw-Hill, </publisher> <year> 1975. </year>
Reference: [ Minton et al., 1989 ] <author> Steven Minton, Jaime Carbonell, Craig Knoblock, et al. </author> <title> Explanation-based learning: A problem-solving perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 40 </volume> <pages> 63-118, </pages> <year> 1989. </year>
Reference: [ Moore, 1985 ] <author> Robert C. Moore. </author> <title> Semantical considerations on nonmonotonic logic. </title> <journal> Artificial Intelligence, </journal> <volume> 25 </volume> <pages> 75-94, </pages> <year> 1985. </year>
Reference: [ Morris, 1988 ] <author> Paul Morris. </author> <title> Truth maintenance-based planning with error recovery. </title> <booktitle> In Proceedings of the Rochester Planning Workshop, </booktitle> <pages> pages 18-19, </pages> <year> 1988. </year> <note> Extended Abstract. </note>
Reference: [ Rich, 1985 ] <author> Charles Rich. </author> <title> The layered architecture of a system for reasoning about programs. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <year> 1985. </year>
Reference-contexts: To enable belief revision, one must encode every bit of information that might change in reasons and tell these reasons to the RMS (cf. <ref> [ Rich, 1985; Vilain, 1985 ] </ref> ). This can present an excessive burden, as manifest by the observation that the RMSs supplied in expert system shells all too often go unused.
Reference: [ Rosenschein and Kaelbling, 1986 ] <author> Stanley J. Rosen-schein and Leslie Pack Kaelbling. </author> <title> The synthesis of digital machines with provable epistemic properties. </title> <editor> In Joseph Y. Halpern, editor, </editor> <booktitle> Theoretical Aspects of Reasoning About Knowledge: Proceedings of the 1986 Conference, </booktitle> <pages> pages 83-98. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1986. </year>
Reference: [ Russell and Wefald, 1989 ] <author> Stuart Russell and Eric We-fald. </author> <booktitle> Principles of metareasoning. In First International Conference on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pages 400-411, </pages> <year> 1989. </year>
Reference: [ Savage, 1972 ] <author> Leonard J. Savage. </author> <title> The Foundations of Statistics. </title> <publisher> Dover Publications, </publisher> <address> New York, </address> <note> second edition, </note> <year> 1972. </year>
Reference-contexts: In this case, the locally coherent modules can be interpreted as "microtheories" [ Hewitt, 1986 ] (related to the idea of "small worlds" in decision theory <ref> [ Savage, 1972 ] </ref> ). But inconsistency can arise even within a module if too little inference is specified. Another consequence is that the beliefs of the system may not be fully grounded.
Reference: [ Schoppers, 1987 ] <author> M. J. Schoppers. </author> <title> Universal plans for reactive robots in unpredictable environments. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 1039-1046, </pages> <year> 1987. </year>
Reference: [ Shoham, 1988 ] <author> Yoav Shoham. </author> <title> Reasoning about Change: Time and Causation from the Standpoint of Artificial Intelligence. </title> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: Alternatively, only some consistent interpretations may be constructed, such as those maximal in some order (as in preferential nonmonotonic logics <ref> [ Shoham, 1988 ] </ref> ). In general, the aim is to use the recorded reasons to draw as many conclusions as the reasoner needs. Similarly, the revisions performed by the RDRMS may be incomplete.
Reference: [ Smith, 1988 ] <author> David E. Smith. </author> <title> A decision theoretic approach to the control of planning search. </title> <type> Technical Report LOGIC-87-11, </type> <institution> Department of Computer Science, Stanford University, </institution> <year> 1988. </year>
Reference-contexts: Many of these techniques therefore require some reworking before they can be said to produce rational plans, and the issue of rational control of the planning process is just now beginning to be studied <ref> [ Dean, 1990; Smith, 1988 ] </ref> . Another approach is the "reactive" approach to planning and action, which seeks to avoid execution-time planning by "compiling" all necessary behaviors into directly applicable forms [ Brooks, 1986; Georgeff and Lan-sky, 1987; Rosenschein and Kaelbling, 1986; Schoppers, 1987 ] .
Reference: [ Vilain, 1985 ] <author> Marc B. Vilain. </author> <title> The restricted language architecture of a hybrid representation system. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 547-551, </pages> <year> 1985. </year>
Reference-contexts: To enable belief revision, one must encode every bit of information that might change in reasons and tell these reasons to the RMS (cf. <ref> [ Rich, 1985; Vilain, 1985 ] </ref> ). This can present an excessive burden, as manifest by the observation that the RMSs supplied in expert system shells all too often go unused.
Reference: [ Wellman, 1987 ] <author> Michael P. Wellman. </author> <title> Dominance and subsumption in constraint-posting planning. </title> <booktitle> In Proceedings of the Tenth International Joint Conference on Artificial Intelligence, </booktitle> <pages> pages 884-890, </pages> <year> 1987. </year>
Reference-contexts: To support rationality in planning, we require that every decision be associated with a reason, of one of the following types: 1. Dominance reasons indicate decision-theoretic arguments that plans violating the constraints are inad missible <ref> [ Wellman, 1987 ] </ref> . 2. Feasibility reasons justify posting constraints because they are required for plan executability. For example, we must enforce preconditions of included actions. 3. Completeness reasons indicate the constraints are required to fill out plans so that they can be interpreted by the execution module.
Reference: [ Wellman, 1990a ] <author> Michael P. Wellman. </author> <title> Formulation of Tradeoffs in Planning Under Uncertainty. </title> <publisher> Pitman and Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: Each of these ways of implementing rationality is best in some circumstances, since compilation is not always possible or worthwhile. Examples of implicitly rational procedures abound in AI under the name of heuristics. For instance, the "status quo optimality" heuristic <ref> [ Wellman, 1990a, Section 6.4.1 ] </ref> constrains the set of possible revisions under the assumption that the current plan is optimal. In particular, the replanner need only respond to the specific changes. <p> This also makes it important that implicitly rational planning procedures indicate the original expectations, preferences, and sub-plans from which they were "compiled." 3 Planning framework Our approach combines a dominance-proving architecture for planning <ref> [ Wellman, 1990a ] </ref> with a reason maintenance facility for replanning. We start from a constraint-posting view of the plan construction process. Plans consist of a set of actions, which can be specified at varying levels of detail. <p> But developing an architecture for reason maintenance and replanning subject to rational control will require significant modification of existing techniques. As mentioned above, we use the RDRMS to extend the dominance-proving architecture for planning with partially satisfiable goals <ref> [ Wellman, 1990a ] </ref> . This decision-theoretic approach fits well with our goal of rational planning.
Reference: [ Wellman, 1990b ] <author> Michael P. Wellman. </author> <title> Fundamental concepts of qualitative probabilistic networks. </title> <journal> Artificial Intelligence, </journal> <year> 1990. </year>
Reference-contexts: In this, we build on techniques for qualitative representation of probabilistic information <ref> [ Wellman, 1990b ] </ref> . But to really make reason maintenance techniques efficient, we must do more than choose rationally among assumptions in backtracking. We must in addition undertake a fundamental reconsideration and redesign of reason maintenance systems to make them much more incremental than extant architectures.
Reference: [ Wilkins, 1988 ] <author> David E. Wilkins. </author> <title> Practical Planning. </title> <publisher> Morgan Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1988. </year> <month> 9 </month>
Reference-contexts: Most work on generative planning has concentrated on planning from scratch, though the replanning task has been studied off and on over the years <ref> [ Fikes et al., 1972; McDermott, 1978; Wilkins, 1988 ] </ref> with some success. But generative planning has focused|with a few recent exceptions| on planning without probability or utility information.
References-found: 39

