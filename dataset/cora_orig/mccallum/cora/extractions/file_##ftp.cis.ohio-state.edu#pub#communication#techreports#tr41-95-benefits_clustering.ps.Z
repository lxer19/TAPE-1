URL: file://ftp.cis.ohio-state.edu/pub/communication/techreports/tr41-95-benefits_clustering.ps.Z
Refering-URL: http://www.cis.ohio-state.edu/~panda/cluster_pub.html
Root-URL: 
Title: Benefits of Processor Clustering in Designing Large Parallel Systems: When and How?  
Abstract: D. Basak, D. K. Panda, and M. Banikazemi Technical Report OSU-CISRC-10/95-TR41 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. Agrawal. </author> <title> Limits on Interconnection Network Performance. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 2(4), </volume> <month> Oct </month> <year> 1991. </year>
Reference-contexts: Figure 2 shows the overall configuration of such a system. 2 Modeling network contention with wormhole routing is not the objective of this paper. Without presenting such details here we refer interested readers to relevant treatises on analytical modeling in <ref> [1, 6, 10] </ref>. 5 3.2 Scaling by using larger processor-clusters while maintaining network topol ogy Large processor clusters can be used to scale systems as shown in Fig. 3. <p> Similarly, packaging constraints like maximum board size, pinout limitations, system bisection size put bounds on the maximum channel width (W max ) and maximum cluster size (c max ) <ref> [1, 5, 20] </ref>. Design under such constraints has been analyzed by us in detail and presented in [4, 5]. It was shown that the design process is sensitive to technological and packaging advancements.
Reference: [2] <author> A. Asthana, H. Jagdish, and B. Mathews. </author> <title> Impact of Advanced VLSI packaging on the design of a large parallel computer. </title> <booktitle> In Proc. of the Int. Conf. on Parallel Processing, </booktitle> <month> Aug </month> <year> 1989. </year>
Reference-contexts: With advancements in VLSI and packaging technologies it has become cost-effective to integrate multiple processing elements into a chip or a board <ref> [2] </ref>. This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors [15, 8]. Similarly, there has been advancements in the area of interconnection technologies leading to networks with wider and faster channels [19] becoming feasible.
Reference: [3] <author> S. Balakrishnan and D. K. Panda. </author> <title> Impact of Multiple Consumption Channels on Wormhole Routed k-ary n-cube Networks. </title> <booktitle> In Proc. of the Int. Parallel Processing Symp., </booktitle> <pages> pages 163-167, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: Other functionalities of the CI may include efficient implementation of various communication, synchronization, and cache-coherence operations [13]. However, such discussion is beyond the scope of this paper. The links connecting a CI to the local router are referred to as injection and consumption channels <ref> [3] </ref>. An injection channel is used to send out (inject) a message into the network. Similarly, a consumption channel is used to receive (consume) an incoming message destined to this cluster. <p> Before being sent out, a message requires software processing at the sender. This is followed by injection of the message into the network via an injection channel <ref> [3] </ref>. The message then traverses across the network to the router associated with the destination cluster where it transferred to the destination processor via a consumption channel. It then incurs a software processing overhead at the destination processor before being ready to be used.
Reference: [4] <author> D. Basak and D. K. Panda. </author> <title> Scalable Architectures with k-ary n-cube cluster-c organization. </title> <booktitle> In Proc. of the Symposium of Parallel and Distributed Processing, </booktitle> <pages> pages 780-787, </pages> <year> 1993. </year> <month> 23 </month>
Reference-contexts: In this section we introduce clustered organizations, indicate that such organizations have potential to support larger systems in a more cost-effective manner, and then discuss some architectural details of such organizations. 3.1 Clustered Organizations Recently, we have introduced a new k-ary n-cube cluster-c organization <ref> [4, 5, 18] </ref> to capture the upcoming trend in building scalable parallel systems. In this organization, the lower level consists of k n clusters of processors. These clusters are interconnected by a higher level direct k-ary n-cube network (also referred to as inter-cluster network). <p> Similarly, packaging constraints like maximum board size, pinout limitations, system bisection size put bounds on the maximum channel width (W max ) and maximum cluster size (c max ) [1, 5, 20]. Design under such constraints has been analyzed by us in detail and presented in <ref> [4, 5] </ref>. It was shown that the design process is sensitive to technological and packaging advancements.
Reference: [5] <author> D. Basak and D. K. Panda. </author> <title> Designing Large Hierarchical Multiprocessor Systems under Pro cessor, Interconnection, </title> <booktitle> and Packaging Advancements. In Proc. of the Int'l Conference on Parallel Processing, </booktitle> <pages> pages I:63-66, </pages> <year> 1994. </year>
Reference-contexts: Other researchers have studied the design problem under very realistic packaging constraints <ref> [14, 5, 20] </ref> and proved that under such conditions clustering becomes more useful. However, these works do not demonstrate the merits of clustering in scaling systems. <p> In this section we introduce clustered organizations, indicate that such organizations have potential to support larger systems in a more cost-effective manner, and then discuss some architectural details of such organizations. 3.1 Clustered Organizations Recently, we have introduced a new k-ary n-cube cluster-c organization <ref> [4, 5, 18] </ref> to capture the upcoming trend in building scalable parallel systems. In this organization, the lower level consists of k n clusters of processors. These clusters are interconnected by a higher level direct k-ary n-cube network (also referred to as inter-cluster network). <p> This leads us to an interesting question: given that either system can be built, which one of these would be more cost-effective and deliver lower average message latency? To compare costs here we use the metric of interconnect wiring costs <ref> [5] </ref>. It has been demonstrated in [20] that such costs in the inter-cluster network constitute a significant fraction of the total system costs. We determine these cost figures for both systems, by first computing the total number of channels in the inter-cluster network (4k (k1)). <p> Similarly, packaging constraints like maximum board size, pinout limitations, system bisection size put bounds on the maximum channel width (W max ) and maximum cluster size (c max ) <ref> [1, 5, 20] </ref>. Design under such constraints has been analyzed by us in detail and presented in [4, 5]. It was shown that the design process is sensitive to technological and packaging advancements. <p> Similarly, packaging constraints like maximum board size, pinout limitations, system bisection size put bounds on the maximum channel width (W max ) and maximum cluster size (c max ) [1, 5, 20]. Design under such constraints has been analyzed by us in detail and presented in <ref> [4, 5] </ref>. It was shown that the design process is sensitive to technological and packaging advancements.
Reference: [6] <author> Y. M. Boura and C. R. Das. </author> <title> Modeling virtual channel flow control in hypercubes. </title> <booktitle> In Proc. of the High-Performance Computer Architecture, </booktitle> <pages> pages 166-175, </pages> <year> 1995. </year>
Reference-contexts: Figure 2 shows the overall configuration of such a system. 2 Modeling network contention with wormhole routing is not the objective of this paper. Without presenting such details here we refer interested readers to relevant treatises on analytical modeling in <ref> [1, 6, 10] </ref>. 5 3.2 Scaling by using larger processor-clusters while maintaining network topol ogy Large processor clusters can be used to scale systems as shown in Fig. 3.
Reference: [7] <author> D. Carlson. </author> <title> The Mesh with a Global Mesh: a Flexible, High-speed Organization for Parallel Computation. </title> <booktitle> In Proc. of the 1 st Int. Conf. on Supercomputer Systems. IEEE Comp. </booktitle> <publisher> Soc. Press, </publisher> <year> 1985. </year>
Reference-contexts: Examples of hierarchical configurations proposed by researchers in the last decade to build scalable systems using processor clusters include cluster of processors with buses and MINs [9], local and global meshes <ref> [7] </ref>, and two-level systems based on hypercube and other network topologies [12, 17]. Other researchers have studied the design problem under very realistic packaging constraints [14, 5, 20] and proved that under such conditions clustering becomes more useful.
Reference: [8] <author> Cray Reasearch Inc. </author> <title> Cray T3D System Architecture Overview, </title> <year> 1993. </year>
Reference-contexts: With advancements in VLSI and packaging technologies it has become cost-effective to integrate multiple processing elements into a chip or a board [2]. This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors <ref> [15, 8] </ref>. Similarly, there has been advancements in the area of interconnection technologies leading to networks with wider and faster channels [19] becoming feasible. These new trends of larger processor-clusters with wider interconnection technology offer potential to provide a more cost-effective scaling of systems while utilizing the communication bandwidth effectively. <p> Other researchers have studied the design problem under very realistic packaging constraints [14, 5, 20] and proved that under such conditions clustering becomes more useful. However, these works do not demonstrate the merits of clustering in scaling systems. Although some recent systems like the Cray-T3D <ref> [8] </ref>, DASH [13] are being built based on the clustering approach, there is no formal study to demonstrate when and how such systems can be scaled using processor clustering. In this paper we demonstrate the potential of clustering in designing balanced and cost-effective systems along two directions. <p> By exploiting the advantages of using larger clusters and wider interconnect technology a system designer can offer more balanced and cost-effective configurations. Such trends can be observed in the design of Cray T3D system <ref> [8] </ref>. The results derived in this paper provide detailed insight into this trend which can be used by system architects to build larger and cost-effective parallel systems under technological constraints. The paper is organized as follows. In Sec. 2 we present the problems encountered while scaling systems to larger sizes. <p> Thus, computing nodes having more than one processor on a single multi-chip module or processor-board are becoming increasingly available. These are also referred to as processor-clusters. Many current parallel systems like the CRAY T3D <ref> [8] </ref>, Intel Paragon [15], and the Stanford DASH [13] are using such clustered organizations to build systems. <p> Each processor in a star cluster is connected to a cluster interface (CI). It is to be noted that star-based cluster organization with c = 2 is used in the Cray-T3D system <ref> [8] </ref>. The CI is connected to the rest of the system through a network router. The main task of the cluster interface is to handle the volume of communication to/from the cluster. Other functionalities of the CI may include efficient implementation of various communication, synchronization, and cache-coherence operations [13].
Reference: [9] <author> D. J. Kuck et al. </author> <title> The Cedar System and an Initial Performance Study. </title> <booktitle> In Proc. of the Int'l Symposium on Computer Architecture, </booktitle> <pages> pages 213-223, </pages> <year> 1993. </year>
Reference-contexts: Examples of hierarchical configurations proposed by researchers in the last decade to build scalable systems using processor clusters include cluster of processors with buses and MINs <ref> [9] </ref>, local and global meshes [7], and two-level systems based on hypercube and other network topologies [12, 17]. Other researchers have studied the design problem under very realistic packaging constraints [14, 5, 20] and proved that under such conditions clustering becomes more useful.
Reference: [10] <author> W. J. Dally. </author> <title> Performance Analysis of k-ary n-cube Interconnection Networks. </title> <journal> IEEE Trans. on Computers, </journal> <volume> 39(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: By scaling the system to a 8x8 configuration while maintaining channel width, the value of nw;p falls by a factor of two to 0.5 messages/sec. However, the overall system throughput in this case remains at = 0:5 messages/sec. By using an analytical model, similar to the one presented in <ref> [10] </ref> to model contention in wormhole routed systems, it can be 4 easily demonstrated that such scaling is achieved with only a marginal increase in average message latency 2 . <p> Figure 2 shows the overall configuration of such a system. 2 Modeling network contention with wormhole routing is not the objective of this paper. Without presenting such details here we refer interested readers to relevant treatises on analytical modeling in <ref> [1, 6, 10] </ref>. 5 3.2 Scaling by using larger processor-clusters while maintaining network topol ogy Large processor clusters can be used to scale systems as shown in Fig. 3. <p> We use these architectural features in our analysis. In this paper we assume the popular wormhole mechanism to route messages in the inter-cluster network. In wormhole routing a message is divided into flits <ref> [10] </ref> which are then pipelined over a path in the network established by the header flit. This offers a low-cost, low-latency, and scalable communication sub-system. The interconnection within a cluster (also referred to as intra-cluster network or intranet) can be chosen as bus/MIN/star network/direct network as shown in Fig. 4. <p> Let us denote the bisection of a network as B. It is the minimum number of network channels to be cut so as to divide the network into two equal halves. For a clustered k-ary n-cube cluster-c system, the bisection of the k-ary n-cube inter-cluster network is derived <ref> [10] </ref> as, 3 B = 2k n1 channels = 2k n1 W bytes (3) assuming a channel width of W bytes. Let the channel cycle time in the network be denoted as t c sec. Thus, W bytes can be sent across a network channel in t c sec.
Reference: [11] <author> W. J. Dally. </author> <title> Virtual-channel flow control. </title> <journal> IEEE Trans. on Parallel and Distributed Systems, </journal> <volume> 3(2) </volume> <pages> 194-205, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: and usually for a given set of system parameters like 3 For toruses this number needs to be adjusted by a factor of two to B = 4k n1 channels due to the presence of wrap-around links. 10 message length, routing adaptivity [16], traffic patterns, and virtual channel flow control <ref> [11] </ref> techniques, it remains almost unchanged with system size [16]. We denote this achievable fractional throughput as nw;p . Later we use accurate simulation modeling of contention to determine such network throughput in presence of contention.
Reference: [12] <author> S. Dandamudi and D. Eager. </author> <title> Hierarchical Interconnection Networks for Multicomputer Sys tems. </title> <journal> IEEE Trans. on Computers, </journal> <volume> C-39(6), </volume> <month> June </month> <year> 1990. </year>
Reference-contexts: Examples of hierarchical configurations proposed by researchers in the last decade to build scalable systems using processor clusters include cluster of processors with buses and MINs [9], local and global meshes [7], and two-level systems based on hypercube and other network topologies <ref> [12, 17] </ref>. Other researchers have studied the design problem under very realistic packaging constraints [14, 5, 20] and proved that under such conditions clustering becomes more useful. However, these works do not demonstrate the merits of clustering in scaling systems.
Reference: [13] <author> D. Lenoski et al. </author> <title> The Stanford DASH Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <year> 1990. </year>
Reference-contexts: Other researchers have studied the design problem under very realistic packaging constraints [14, 5, 20] and proved that under such conditions clustering becomes more useful. However, these works do not demonstrate the merits of clustering in scaling systems. Although some recent systems like the Cray-T3D [8], DASH <ref> [13] </ref> are being built based on the clustering approach, there is no formal study to demonstrate when and how such systems can be scaled using processor clustering. In this paper we demonstrate the potential of clustering in designing balanced and cost-effective systems along two directions. <p> Thus, computing nodes having more than one processor on a single multi-chip module or processor-board are becoming increasingly available. These are also referred to as processor-clusters. Many current parallel systems like the CRAY T3D [8], Intel Paragon [15], and the Stanford DASH <ref> [13] </ref> are using such clustered organizations to build systems. <p> The CI is connected to the rest of the system through a network router. The main task of the cluster interface is to handle the volume of communication to/from the cluster. Other functionalities of the CI may include efficient implementation of various communication, synchronization, and cache-coherence operations <ref> [13] </ref>. However, such discussion is beyond the scope of this paper. The links connecting a CI to the local router are referred to as injection and consumption channels [3]. An injection channel is used to send out (inject) a message into the network.
Reference: [14] <author> W. Hsu and P. C. Yew. </author> <title> The Performance of Hierarchical Systems with wiring constraints. </title> <booktitle> In Proc. of the Int. Conf. on Parallel Processing, </booktitle> <month> Aug </month> <year> 1991. </year>
Reference-contexts: Other researchers have studied the design problem under very realistic packaging constraints <ref> [14, 5, 20] </ref> and proved that under such conditions clustering becomes more useful. However, these works do not demonstrate the merits of clustering in scaling systems.
Reference: [15] <author> Intel Corporation. </author> <title> Paragon XP/S Product Overview, </title> <year> 1991. </year>
Reference-contexts: With advancements in VLSI and packaging technologies it has become cost-effective to integrate multiple processing elements into a chip or a board [2]. This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors <ref> [15, 8] </ref>. Similarly, there has been advancements in the area of interconnection technologies leading to networks with wider and faster channels [19] becoming feasible. These new trends of larger processor-clusters with wider interconnection technology offer potential to provide a more cost-effective scaling of systems while utilizing the communication bandwidth effectively. <p> Thus, computing nodes having more than one processor on a single multi-chip module or processor-board are becoming increasingly available. These are also referred to as processor-clusters. Many current parallel systems like the CRAY T3D [8], Intel Paragon <ref> [15] </ref>, and the Stanford DASH [13] are using such clustered organizations to build systems.
Reference: [16] <author> L. M. Ni and P. K. McKinley. </author> <title> A survey of wormhole routing techniques in direct networks. </title> <journal> IEEE Computer, </journal> <volume> 26 </volume> <pages> 62-76, </pages> <month> Feb </month> <year> 1993. </year>
Reference-contexts: This coupled with the recent trends in routing mechanisms like fast packet switching, virtual-cut through, and wormhole routing <ref> [16] </ref> has led to systems offering very small point-to-point network delay in the range of less than a microsecond. However, in most of these systems the fast communication subsystem remains under-utilized. <p> This fraction represents the utilization of the network and usually for a given set of system parameters like 3 For toruses this number needs to be adjusted by a factor of two to B = 4k n1 channels due to the presence of wrap-around links. 10 message length, routing adaptivity <ref> [16] </ref>, traffic patterns, and virtual channel flow control [11] techniques, it remains almost unchanged with system size [16]. We denote this achievable fractional throughput as nw;p . Later we use accurate simulation modeling of contention to determine such network throughput in presence of contention. <p> like 3 For toruses this number needs to be adjusted by a factor of two to B = 4k n1 channels due to the presence of wrap-around links. 10 message length, routing adaptivity <ref> [16] </ref>, traffic patterns, and virtual channel flow control [11] techniques, it remains almost unchanged with system size [16]. We denote this achievable fractional throughput as nw;p . Later we use accurate simulation modeling of contention to determine such network throughput in presence of contention. Thus, we have: nw;p = B;p r = 4W r=(kcLT c )messages/sec, (7) where r denotes the utilization fraction of the network.
Reference: [17] <author> K. Padmanabhan. </author> <title> Effective Architectures for Data Access in a Shared Memory Hierarchy. </title> <journal> Jour. of Parallel and Distributed Computing, </journal> <volume> 11, </volume> <year> 1991. </year>
Reference-contexts: Examples of hierarchical configurations proposed by researchers in the last decade to build scalable systems using processor clusters include cluster of processors with buses and MINs [9], local and global meshes [7], and two-level systems based on hypercube and other network topologies <ref> [12, 17] </ref>. Other researchers have studied the design problem under very realistic packaging constraints [14, 5, 20] and proved that under such conditions clustering becomes more useful. However, these works do not demonstrate the merits of clustering in scaling systems.
Reference: [18] <author> D. K. Panda and D. Basak. </author> <title> Issues in Designing Scalable Systems with k-ary n-cube cluster c Organization. </title> <booktitle> In Proc. of the First International Workshop on Parallel Processing, India, </booktitle> <pages> pages 5-10, </pages> <year> 1994. </year>
Reference-contexts: In this section we introduce clustered organizations, indicate that such organizations have potential to support larger systems in a more cost-effective manner, and then discuss some architectural details of such organizations. 3.1 Clustered Organizations Recently, we have introduced a new k-ary n-cube cluster-c organization <ref> [4, 5, 18] </ref> to capture the upcoming trend in building scalable parallel systems. In this organization, the lower level consists of k n clusters of processors. These clusters are interconnected by a higher level direct k-ary n-cube network (also referred to as inter-cluster network). <p> This offers a low-cost, low-latency, and scalable communication sub-system. The interconnection within a cluster (also referred to as intra-cluster network or intranet) can be chosen as bus/MIN/star network/direct network as shown in Fig. 4. The merits and demerits of each of these organizations is presented in <ref> [18] </ref>. Although the study presented in this paper can be extended to include other cluster organizations, in this paper we assume clusters to be star-connected as shown in Fig. 2 (d). Each processor in a star cluster is connected to a cluster interface (CI).
Reference: [19] <author> D. A. Patterson. </author> <title> Observations in Massive Parallelism Trends and Predictions for 1995 to 2000. </title> <type> Technical Report 93-87, </type> <institution> DIMACS, </institution> <month> Sept </month> <year> 1993. </year>
Reference-contexts: This is leading to the development of parallel systems using such processor-clusters as building blocks instead of single processors [15, 8]. Similarly, there has been advancements in the area of interconnection technologies leading to networks with wider and faster channels <ref> [19] </ref> becoming feasible. These new trends of larger processor-clusters with wider interconnection technology offer potential to provide a more cost-effective scaling of systems while utilizing the communication bandwidth effectively.
Reference: [20] <author> M. T. Raghunath and A. Ranade. </author> <title> Designing interconnection networks for multi-level packag ing. </title> <booktitle> In Proc. of the Supercomputing, </booktitle> <pages> pages 772-781, </pages> <year> 1993. </year> <month> 24 </month>
Reference-contexts: Other researchers have studied the design problem under very realistic packaging constraints <ref> [14, 5, 20] </ref> and proved that under such conditions clustering becomes more useful. However, these works do not demonstrate the merits of clustering in scaling systems. <p> This leads us to an interesting question: given that either system can be built, which one of these would be more cost-effective and deliver lower average message latency? To compare costs here we use the metric of interconnect wiring costs [5]. It has been demonstrated in <ref> [20] </ref> that such costs in the inter-cluster network constitute a significant fraction of the total system costs. We determine these cost figures for both systems, by first computing the total number of channels in the inter-cluster network (4k (k1)). <p> Similarly, packaging constraints like maximum board size, pinout limitations, system bisection size put bounds on the maximum channel width (W max ) and maximum cluster size (c max ) <ref> [1, 5, 20] </ref>. Design under such constraints has been analyzed by us in detail and presented in [4, 5]. It was shown that the design process is sensitive to technological and packaging advancements.
References-found: 20

