URL: http://theory.lcs.mit.edu/~vaziri/MV-thesis.ps.Z
Refering-URL: http://theory.lcs.mit.edu/~vaziri/thesis.html
Root-URL: 
Title: Proving Correctness of a Controller Algorithm for the RAID Level 5 System  
Author: by Mandana Vaziri-Farahani Nancy A. Lynch Cecil H. Green 
Degree: Submitted to the Department of Electrical Engineering and Computer Science in partial fulfillment of the requirements for the degree of Master of Science in Electrical Engineering and Computer Science at the  All rights reserved. Author  Certified by  Professor of Computer Science and Engineering Thesis Supervisor Accepted by Frederic R. Morgenthaler Chairman, Departmental Committee on Graduate Students  
Date: August 1996  August 9, 1996  
Affiliation: MASSACHUSETTS INSTITUTE OF TECHNOLOGY  c Massachusetts Institute of Technology 1996.  Department of Electrical Engineering and Computer Science  
Abstract-found: 0
Intro-found: 1
Reference: [Bitton88] <author> D. Bitton and J. Gray, </author> <title> "Disk Shadowing," </title> <booktitle> Proceedings of the 14th Conference on Very Large Data Bases, </booktitle> <year> 1988, </year> <pages> pp. 331-338. </pages>
Reference-contexts: To overcome this problem, RAID systems are designed to be fault-tolerant by storing redundant data [Gibson90]. RAID systems are usually 1 or 2 fault tolerant. The redundancy can be an identical copy of each data unit, also known as disk mirroring <ref> [Bitton88, Gray90] </ref>. In this case if the disk containing one copy fails, the controller can use the other copy which is on a separate disk.
Reference: [Cao93] <author> P. Cao, S. B. Lim, S. Venkataraman, and J. Wilkes, </author> <title> "The TickerTAIP parallel RAID architecture," </title> <booktitle> Proceedings of the International Symposium on Computer Architecture, </booktitle> <year> 1993, </year> <pages> pp. 52-63. </pages>
Reference-contexts: When an error is encountered, the state of the system is modified to note which disk has failed, and the operation is retried based on the new state. In this approach, operations are represented as Directed Acyclic Graphs (DAGs), which is an expansion on the representation used in TickerTAIP <ref> [Cao93] </ref>, a distributed implementation of RAID Level 5. Each node in a DAG is an action to be performed on a disk or an action that computes data. DAGs provide a visualization of operations which simplifies reasoning about the ordering of actions.
Reference: [Clarke94] <author> Clarke, E., Grumberg, O., and Long, D. </author> <title> "Model Checking". </title> <booktitle> Proceedings of the International Summer School on Deductive Program Design. Marktoberdorf, </booktitle> <address> Germany, </address> <month> July 26 August 27 </month> <year> 1994. </year>
Reference-contexts: Researchers have proposed that practitioners would use formal methods, if fully automatic tools were available. These tools would have to be easy to learn and to use. One example is the success of model checking in the hardware domain <ref> [Clarke94] </ref>. A model checker takes, as input, the description of a system and a property to verify. Then it generates the state-space of the system and checks it exhaustively. It outputs true if the system satisfies the property, and false otherwise.
Reference: [Courtright94] <author> W. V. Courtright II and G. A. Gibson. </author> <title> "Backward error recovery in redundant disk arrays." </title> <booktitle> Proceedings of the 20th International Conference for the Resource Management and Performance Evaluation of Enterprise Computing Systems (CMG). </booktitle> <month> December 4-9 </month> <year> 1994, </year> <pages> pp. 63-74. </pages>
Reference-contexts: This method requires knowing about the context in which an error occurred and thus involves enumerating a large number of erroneous states. Courtright and Gibson propose a form of backward error-recovery method <ref> [Courtright94] </ref> to allow context-free recovery. Traditional backward error-recovery methods consist of undoing operations and returning the disk array to an error-free state. The disadvantage of these methods is that they are expensive. However, Courtright and Gibson's method is based on retry. <p> Each node in a DAG is an action to be performed on a disk or an action that computes data. DAGs provide a visualization of operations which simplifies reasoning about the ordering of actions. Courtright and Gibson's method to error-recovery <ref> [Courtright94] </ref> has two requirements. First, actions must be idempotent. When a DAG fails, some actions may have been executed and some may have not. The controller then retries the operation with a similar DAG and actions that have already been performed will be performed again. <p> In this thesis, we are concerned with controller algorithms that use Courtright and Gibson's error-recovery method <ref> [Courtright94] </ref> described previously 2 . Although these algorithms employ context-free 3 error recovery, the logics used to select a new DAG are nonetheless complicated. Also these algorithms allow fine interleavings between actions on the disks. As a consequence, these algorithms are difficult to test and to reason about. <p> In a recent work Gibson et al. have used a different controller algorithm for the RAID Level 6 that does not have this problem. This controller algorithm uses roll-away error recovery [Courtright96], rather than Courtright and Gibson's method <ref> [Courtright94] </ref>. 83 Chapter 5 Conclusions Summary We proved the correctness of a controller algorithm for the RAID Level 5 system. We expressed the algorithm and its specification using I/O Automata and proved that the algorithm satisfies its specification by using the proof by simulation technique.
Reference: [Courtright96] <author> William V. </author> <title> Courtright II, "A Transactional Approach to Redundant Disk Array Implementation." </title> <institution> Computer Science Technical Report, 1996, Carnegie Mellon University, </institution> <address> 5000 Forbes Ave., Pittsburgh, PA 15213. </address>
Reference-contexts: A DAG satisfying the second requirement is said to preserve consistency. Although many RAID controller algorithms perform actions that are idempotent, there exists some algorithms for which this is not the case <ref> [Courtright96] </ref>. Also for some architectures, it is impossible to build DAGs that preserves consistency for all operations. <p> In order to provide a context-free error recovery method that would be general enough for all algorithms, Gibson et al. have devised roll-away recovery, which is a hybrid between Cour-tright and Gibson's method described above and more traditional backward error-recovery approaches <ref> [Courtright96] </ref>. In this thesis, we are concerned with controller algorithms that use Courtright and Gibson's error-recovery method [Courtright94] described previously 2 . Although these algorithms employ context-free 3 error recovery, the logics used to select a new DAG are nonetheless complicated. <p> We show extensions of the algorithm in Chapter 4. Finally, Chapter 5 presents a summary of our conclusions. 12 Chapter 2 Algorithm 2.1 Informal Description We now describe a controller algorithm for the RAID level 5 system [Gibson95], that uses Courtright and Gibson's error recovery method <ref> [Courtright96] </ref>. When the controller receives an operation, it chooses a local algorithm based on the state of the disk array and starts executing it. Local algorithms are represented as antecedence graphs. <p> In a recent work Gibson et al. have used a different controller algorithm for the RAID Level 6 that does not have this problem. This controller algorithm uses roll-away error recovery <ref> [Courtright96] </ref>, rather than Courtright and Gibson's method [Courtright94]. 83 Chapter 5 Conclusions Summary We proved the correctness of a controller algorithm for the RAID Level 5 system.
Reference: [Gibson90] <author> Garth Gibson. </author> <title> "Redundant Disk Arrays: Reliable, Parallel Secondary Storage". </title> <type> PhD thesis, </type> <institution> University of California at Berkeley, </institution> <year> 1990. </year> <note> Report UCB/CSD 91/613. </note>
Reference-contexts: This scheme improves the throughput. Secondly, when the number of disks increases in a disk array, the availability of data and the reliability of the disk array, may decrease dramatically [Gibson93]. To overcome this problem, RAID systems are designed to be fault-tolerant by storing redundant data <ref> [Gibson90] </ref>. RAID systems are usually 1 or 2 fault tolerant. The redundancy can be an identical copy of each data unit, also known as disk mirroring [Bitton88, Gray90].
Reference: [Gibson93] <author> G. A. Gibson and D. A. Patterson, </author> <title> "Designing disk arrays for high data reliability", </title> <journal> Journal of Parallel and Distributed Computing. </journal> <pages> 17(1-2), </pages> <year> 1993, </year> <pages> 4-27. 87 </pages>
Reference-contexts: This scheme improves the throughput. Secondly, when the number of disks increases in a disk array, the availability of data and the reliability of the disk array, may decrease dramatically <ref> [Gibson93] </ref>. To overcome this problem, RAID systems are designed to be fault-tolerant by storing redundant data [Gibson90]. RAID systems are usually 1 or 2 fault tolerant. The redundancy can be an identical copy of each data unit, also known as disk mirroring [Bitton88, Gray90].
Reference: [Gibson95] <author> G. Gibson, W. Courtright II, M. Holland, and J. Zelenka, </author> <title> "RAIDframe: Rapid prototyping for disk arrays," </title> <institution> Computer Science Technical Report CMU-CS-95-200, Carnegie Mellon University, </institution> <year> 1995. </year>
Reference-contexts: As a consequence, these algorithms are difficult to test and to reason about. This is why formal methods are useful for proving the correctness of these algorithms. The topic of this thesis is to prove the correctness of a controller algorithm for the RAID Level 5 System <ref> [Gibson95] </ref>, that uses Courtright and Gibson's error recovery method, with the objective of formalizing the general notion of consistency. We describe the algorithm and its specification using the I/O Automaton model [Lynch89]. This model is suitable for specifying components of asynchronous concurrent systems. <p> We used our consistency property to find an error in a DAG for the RAID Level 6 architecture, which appears in <ref> [Gibson95] </ref>. The outline of the thesis is the following. Chapter 2 presents the RAID Level 5 algorithm and its specification. Chapter 3 presents the proof of correctness. We show extensions of the algorithm in Chapter 4. <p> Chapter 3 presents the proof of correctness. We show extensions of the algorithm in Chapter 4. Finally, Chapter 5 presents a summary of our conclusions. 12 Chapter 2 Algorithm 2.1 Informal Description We now describe a controller algorithm for the RAID level 5 system <ref> [Gibson95] </ref>, that uses Courtright and Gibson's error recovery method [Courtright96]. When the controller receives an operation, it chooses a local algorithm based on the state of the disk array and starts executing it. Local algorithms are represented as antecedence graphs. <p> Since the controllers do not share any data, this new composition does not require any special consideration. 4.2 Verifying Controller Algorithms for other RAID Archi tectures In this section, we turn our attention to another RAID architecture: the RAID Level 6 system <ref> [Gibson95] </ref>, which is two-fault tolerant. <p> But this is enough for the purposes of applying the General Consistency property. 82 4.2.3 Error Found in a RAID Level 6 DAG We found an error in the Small-Write graph for RAID Level 6, that appears in <ref> [Gibson95] </ref>. This graph did not satisfy General Consistency and our property helped in finding a counterexample. The graph is shown in Figure 4-3. It consists of reading the disks to be written, reading the old P and Q values, computing the new parities and writing the new data and parities. <p> Disk D 4 is not to be written and its V B is different from its hist at the end of the execution of the graph. Therefore this graph does not satisfy General Consistency. The Small Write graph appears in <ref> [Gibson95] </ref>. It seems to be the case that there does not exist a DAG that performs the Small Write operation, while satisfying the General Consistency property, using Courtright and Gibson's error recovery method.
Reference: [Gray90] <author> G. Gray, B. Horst, and M. Walker, </author> <title> "Parity Striping of Disc Arrays: Low-Cost Reliable Storage with Acceptable Throughput," </title> <booktitle> Proceedings of the Conference on Very Large Scale Data Bases, </booktitle> <year> 1990, </year> <pages> pp. 148-160. </pages>
Reference-contexts: To overcome this problem, RAID systems are designed to be fault-tolerant by storing redundant data [Gibson90]. RAID systems are usually 1 or 2 fault tolerant. The redundancy can be an identical copy of each data unit, also known as disk mirroring <ref> [Bitton88, Gray90] </ref>. In this case if the disk containing one copy fails, the controller can use the other copy which is on a separate disk.
Reference: [Reddy89] <author> A. L. Narasimha Reddy and Prithviraj Banerjee, </author> <title> "An evaluation of multiple-disk I/O systems." </title> <journal> IEEE Transactions on Computers, </journal> <volume> Vol. 38, No. 12, </volume> <month> December </month> <year> 1989, </year> <pages> pp. 1680-1690. </pages>
Reference-contexts: First, the data on the disks can be accessed in parallel which improves the I/O performance. Each file that is stored in the array is decomposed into blocks and placed on several disks. This scheme improves the response time when the user accesses that file <ref> [Kim86, Reddy89, Salem86] </ref>. The controller can also carry out several operations at the same time if the set of disks involved in these operations are non-conflicting. This scheme improves the throughput.
Reference: [Kim86] <author> M. Kim. </author> <title> "Synchronized Disk Interleaving". </title> <journal> IEEE Transactions on Computers 35(11), </journal> <month> November </month> <year> 1986, </year> <pages> pp 978-988. </pages>
Reference-contexts: First, the data on the disks can be accessed in parallel which improves the I/O performance. Each file that is stored in the array is decomposed into blocks and placed on several disks. This scheme improves the response time when the user accesses that file <ref> [Kim86, Reddy89, Salem86] </ref>. The controller can also carry out several operations at the same time if the set of disks involved in these operations are non-conflicting. This scheme improves the throughput.
Reference: [Lamport83] <author> Leslie Lamport. </author> <title> Specifying concurrent program modules. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 5(2) </volume> <pages> 190-222, </pages> <month> April </month> <year> 1983. </year>
Reference-contexts: We prove that the algorithm is correct by showing that it implements its specification, using 2 This method is different from the roll-away error recovery method described in the previous paragraph. 3 Context-free means independent from the context in which an error occurs. 11 the proof by simulation technique <ref> [Lamport83, Lynch87, Lynch95, Lynch96] </ref>. In the course of this proof, we formalize the general notion of consistency, in a way that it can be applied to DAGs of other similar RAID controller algorithms.
Reference: [Lawlor81] <author> F. D. Lawlor. </author> <title> "Efficient Mass Storage Parity Recovery Mechanism", </title> <journal> IBM Technical Disclosure Bulletin 24(2) </journal> <pages> 986-987, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: RAID or Redundant Arrays of Inexpensive Disks were developed in the 1980's to address this need. They were first described at the beginning of the decade <ref> [Lawlor81, Park86] </ref>, and popularized by the work of a group at UC Berkeley [Patterson88, Patterson89]. Abstractly, we can think of a RAID system as being composed of two components: * A disk array, and * A disk array controller.
Reference: [Lynch87] <author> N. Lynch and M. Tuttle. </author> <title> "Hierarchical correctness proofs for distributed algorithms." </title> <type> Technical report MIT/LCS/TR-387, </type> <institution> MIT Laboratory for Computer Science, </institution> <address> Cambridge, MA, </address> <month> April </month> <year> 1987. </year>
Reference-contexts: We prove that the algorithm is correct by showing that it implements its specification, using 2 This method is different from the roll-away error recovery method described in the previous paragraph. 3 Context-free means independent from the context in which an error occurs. 11 the proof by simulation technique <ref> [Lamport83, Lynch87, Lynch95, Lynch96] </ref>. In the course of this proof, we formalize the general notion of consistency, in a way that it can be applied to DAGs of other similar RAID controller algorithms.
Reference: [Lynch89] <author> N. Lynch and M. Tuttle. </author> <title> An Introduction to Input/Output Automata. </title> <journal> CWI-Quaterly, </journal> <volume> 2(3): </volume> <pages> 219-246, </pages> <month> September </month> <year> 1989. </year> <institution> Centrum voor Wiskunde en Informatica, </institution> <address> Amsterdam, The Netherlands. </address>
Reference-contexts: We describe the algorithm and its specification using the I/O Automaton model <ref> [Lynch89] </ref>. This model is suitable for specifying components of asynchronous concurrent systems. Although the algorithm we consider is essentially sequential, the concurrency due to disk failures and actions on the disks, make the I/O Automaton model a suitable model to use.
Reference: [Lynch95] <author> Nancy Lynch and Frits Vaandrager. </author> <title> "Forward and Backward Simulations Part I: </title> <journal> Untimed Systems". Information and Computation, </journal> <volume> 121(2), </volume> <pages> pages 214-233, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: We prove that the algorithm is correct by showing that it implements its specification, using 2 This method is different from the roll-away error recovery method described in the previous paragraph. 3 Context-free means independent from the context in which an error occurs. 11 the proof by simulation technique <ref> [Lamport83, Lynch87, Lynch95, Lynch96] </ref>. In the course of this proof, we formalize the general notion of consistency, in a way that it can be applied to DAGs of other similar RAID controller algorithms.
Reference: [Lynch96] <author> Nancy A. Lynch, </author> <title> "Distributed Algorithms", </title> <publisher> Morgan Kaufmann Publishers, </publisher> <address> San Mateo, CA, </address> <year> 1996. </year> <month> 88 </month>
Reference-contexts: We prove that the algorithm is correct by showing that it implements its specification, using 2 This method is different from the roll-away error recovery method described in the previous paragraph. 3 Context-free means independent from the context in which an error occurs. 11 the proof by simulation technique <ref> [Lamport83, Lynch87, Lynch95, Lynch96] </ref>. In the course of this proof, we formalize the general notion of consistency, in a way that it can be applied to DAGs of other similar RAID controller algorithms.
Reference: [Patterson88] <author> David A. Patterson, Garth A. Gibson, and Randy Katz. </author> <title> "A Case for Re--dundant Arrays of Inexpensive Disks (RAID)". </title> <booktitle> Proceedings SIGMOD International Conference on Data Management, </booktitle> <year> 1988, </year> <pages> pp. 109-116. </pages>
Reference-contexts: RAID or Redundant Arrays of Inexpensive Disks were developed in the 1980's to address this need. They were first described at the beginning of the decade [Lawlor81, Park86], and popularized by the work of a group at UC Berkeley <ref> [Patterson88, Patterson89] </ref>. Abstractly, we can think of a RAID system as being composed of two components: * A disk array, and * A disk array controller. The disk array is a collection of magnetic disks that can be accessed in parallel. <p> In this form of redundancy, lost or damaged data can be recovered by using the backup copy. Another form of redundancy is having a parity block for every group of n blocks, independently stored <ref> [Patterson88] </ref>. The parity block is computed by performing an exclusive or operation on the blocks it covers. Given any set of n 1 blocks, the nth block can be recovered by performing an exclusive or operation on the n 1 blocks. <p> Given any set of n 1 blocks, the nth block can be recovered by performing an exclusive or operation on the n 1 blocks. There are several RAID architectures that are classified as five "levels" <ref> [Patterson88] </ref>. RAID Level 1 employs disk mirroring and thus uses twice as many disks as a non-redundant disk array for the same amount of data. RAID Level 2 provides redundancy by using Hamming codes. Levels 3, 4 and 5 all use parity.
Reference: [Patterson89] <author> David A. Patterson, Peter Chen, Garth Gibson and Randy Katz. </author> <title> Introduction to Redundant Arrays of Inexpensive Disks (RAID). </title> <address> Spring COMPCON'89 San Fransisco, CA, </address> <pages> pp 112-17. </pages> <publisher> IEEE, </publisher> <month> March </month> <year> 1989. </year>
Reference-contexts: RAID or Redundant Arrays of Inexpensive Disks were developed in the 1980's to address this need. They were first described at the beginning of the decade [Lawlor81, Park86], and popularized by the work of a group at UC Berkeley <ref> [Patterson88, Patterson89] </ref>. Abstractly, we can think of a RAID system as being composed of two components: * A disk array, and * A disk array controller. The disk array is a collection of magnetic disks that can be accessed in parallel.
Reference: [Park86] <author> Arvin Park and K. Balasubramanian. </author> <title> "Providing Fault Tolerance in Parallel Secondary Storage Systems". </title> <type> Technical Report CS-TR-057-86. </type> <institution> Department of Computer Science, Princeton University, </institution> <month> November </month> <year> 1986. </year>
Reference-contexts: RAID or Redundant Arrays of Inexpensive Disks were developed in the 1980's to address this need. They were first described at the beginning of the decade <ref> [Lawlor81, Park86] </ref>, and popularized by the work of a group at UC Berkeley [Patterson88, Patterson89]. Abstractly, we can think of a RAID system as being composed of two components: * A disk array, and * A disk array controller.
Reference: [Salem86] <author> K. Salem and H. Garcia-Molina. </author> <title> "Disk Striping". </title> <booktitle> Proceedings of the 2nd International Conference on Data Engineering, </booktitle> <year> 1986, </year> <pages> pp. 336-342. 89 </pages>
Reference-contexts: First, the data on the disks can be accessed in parallel which improves the I/O performance. Each file that is stored in the array is decomposed into blocks and placed on several disks. This scheme improves the response time when the user accesses that file <ref> [Kim86, Reddy89, Salem86] </ref>. The controller can also carry out several operations at the same time if the set of disks involved in these operations are non-conflicting. This scheme improves the throughput.
References-found: 21

