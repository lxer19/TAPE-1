URL: http://cs.nyu.edu/cs/faculty/weinshal/papers/gram-alg.ps.gz
Refering-URL: http://cs.nyu.edu/cs/faculty/weinshal/papers.html
Root-URL: http://www.cs.nyu.edu
Title: Linear and Incremental Acquisition of Invariant Shape Models from Image Sequences  
Author: Daphna Weinshall and Carlo Tomasi 
Keyword: Structure from motion, linear reconstruction, factorization method, affine shape, Euclidean shape, weak perspective, Gramian, affine coordinates.  
Date: 17(5):512-517, May 1995. 1  
Note: IEEE Transactions on Pattern Analysis and Machine Intelligence,  
Abstract: We show how to automatically acquire a Euclidean shape representations of objects from noisy image sequences under weak perspective. The proposed method is linear and incremental, requiring no more than pseudo-inverse. A nonlinear but numerically sound preprocessing stage is added to improve the accuracy of the results even further. Experiments show that attention to noise and computational techniques improve the shape results substantially with respect to previous methods proposed for ideal images. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. C. Bolles, H. H. Baker, and D. H. Marimont. </author> <title> Epipolar-plane image analysis: An approach to determining structure from motion. </title> <journal> International Journal of Computer Vision, </journal> <volume> 1(1) </volume> <pages> 7-55, </pages> <year> 1987. </year>
Reference-contexts: IEEECS Log Number P95063. papers discuss under ideal circumstances. To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, [14, 9] identify the minimum number of points necessary to recover motion and structure from two or three frames, <ref> [1] </ref> recovers depth from many frames when motion is known, [8] considers restricted or partially known motion, [12] solves the complete multiframe problem under orthographic projection, and [5] proposes multiframe solutions under perspective projection.
Reference: [2] <author> W. E. L. Grimson, D. P. Huttenlocher, and D. W. Ja-cobs. </author> <title> A study of affine matching with bounded sensor error. </title> <editor> In G. Sandini, editor, </editor> <booktitle> Computer Vision - ECCV92, </booktitle> <pages> pages 291-306, </pages> <address> Berlin, May 1992. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Automatic acquisition from images avoids the tedious and error prone process of typing three-dimensional coordinates of points on the objects, and makes expensive three-dimensional sensors such as laser rangefind-ers unnecessary. However, model recognition techniques such as geometric hashing have been shown <ref> [2] </ref> to produce false positive matches with even moderate levels of error in the representations or in the images. Consequently, we pay close attention to accuracy and numerical soundness of the algorithms employed, and derive a computationally robust and efficient counterpart to the schemes that previous D.
Reference: [3] <author> B. K. P. Horn, H. M. Hilden, and S. Negahdaripour. </author> <title> Closed-form solution of absolute orientation using or-thonormal matrices. </title> <journal> Journal of the Optical Society of America A, </journal> <volume> 5(7) </volume> <pages> 1127-1135, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: For comparison, we received the 3D coordinates of the points in the first frame as ground truth. We used the algorithm described in <ref> [3] </ref> to compute the optimal similarity transformation between the invariant depth map representation computed by our algorithm (step 5), and the given data in the coordinate system of the first frame.
Reference: [4] <author> B. K. P. Horn. </author> <title> Relative orientation. </title> <journal> International Journal of Computer Vision, </journal> <volume> 4(1) </volume> <pages> 59-78, </pages> <year> 1990. </year>
Reference-contexts: Three results were reported in [10] and copied to Table 1: column "Rot." depth computation with their algorithm, which assumes perspective projection and rotational motion only; column "2-frm" depth computation using the algorithm described in <ref> [4] </ref>, which uses 2-frames only; and column "2-frm, Ave." depth computation using the 2-frames algorithm, where the depth estimates were averages over six pairs of frames. Table 1 summarizes these results, as well as the results using our affine algorithm (column "Aff.
Reference: [5] <author> D. J. Heeger and A. Jepson. </author> <title> Visual perception of three-dimensional motion. </title> <type> Technical Report 124, </type> <institution> MIT Media Laboratory, </institution> <address> Cambridge, Ma, </address> <month> December </month> <year> 1989. </year>
Reference-contexts: For instance, [14, 9] identify the minimum number of points necessary to recover motion and structure from two or three frames, [1] recovers depth from many frames when motion is known, [8] considers restricted or partially known motion, [12] solves the complete multiframe problem under orthographic projection, and <ref> [5] </ref> proposes multiframe solutions under perspective projection. Conceivably, one could use one of these algorithms to determine the complete three-dimensional shape and pose of the object in a Euclidean reference system, and process the results to achieve similarity invariance.
Reference: [6] <author> R. Kumar and A. R. Hanson. </author> <title> Sensitivity of the pose refinement problem to accurate estimation of camera parameters. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 365-369, </pages> <address> Osaka, Japan, 1990. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: The depth values of the points in the first frame ranged from 550 to 700 mms, therefore weak perspective provided a good approximation to this sequence. (See a more detailed description of the sequence in [10] Fig. 5, or <ref> [6] </ref> Fig. 2.) We compared the relative errors of our algorithm to the errors reported in [10]. <p> Moreover, a wide-lens camera was used, causing distortions at the periphery which were not compensated for. (See a more detailed description in [10] Fig. 4, or <ref> [6] </ref> Fig. 3.) Table 2 summarizes the results of our invariant algorithm for the last 8 points.
Reference: [7] <author> J. J. Koenderink and A. J. van Doorn. </author> <title> Affine structure from motion. </title> <journal> Journal of the Optical Society of America, </journal> <volume> 8(2) </volume> <pages> 377-385, </pages> <year> 1991. </year>
Reference-contexts: Specifically, the basis is made by three of the object points themselves, that is, by the vectors from the reference origin to the three points, assumed not to be coplanar with the origin. This basis is no more orthonormal. The new coordinates were called affine in <ref> [7] </ref>. If now the object undergoes some affine transformation, so do the basis points, and the affine coordinates of the N object points do not change. The choice of the three basis points can be important.
Reference: [8] <author> D. T. Lawton. </author> <title> Processing translational motion sequences. </title> <journal> Computer Graphics and Image Processing, </journal> <volume> 22 </volume> <pages> 116-144, </pages> <year> 1983. </year>
Reference-contexts: To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, [14, 9] identify the minimum number of points necessary to recover motion and structure from two or three frames, [1] recovers depth from many frames when motion is known, <ref> [8] </ref> considers restricted or partially known motion, [12] solves the complete multiframe problem under orthographic projection, and [5] proposes multiframe solutions under perspective projection.
Reference: [9] <author> H. C. Longuet-Higgins. </author> <title> A computer algorithm for reconstructing a scene from two projections. </title> <journal> Nature, </journal> <volume> 293 </volume> <pages> 133-135, </pages> <month> September </month> <year> 1981. </year>
Reference-contexts: C. Tomasi is with the Department of Computer Science, Stanford University, Cedar Hall, Stanford, CA 94305; email: tomasi@cs.stanford.edu. IEEECS Log Number P95063. papers discuss under ideal circumstances. To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, <ref> [14, 9] </ref> identify the minimum number of points necessary to recover motion and structure from two or three frames, [1] recovers depth from many frames when motion is known, [8] considers restricted or partially known motion, [12] solves the complete multiframe problem under orthographic projection, and [5] proposes multiframe solutions under
Reference: [10] <author> H. S. Sawhney, J. Oliensis, and A. R. Hanson. </author> <title> Description and reconstruction from image trajectories of rotational motion. </title> <booktitle> In Proceedings of the 3rd International Conference on Computer Vision, </booktitle> <pages> pages 494-498, </pages> <address> Osaka, Japan, 1990. </address> <publisher> IEEE, </publisher> <address> Washington, DC. </address>
Reference-contexts: The depth values of the points in the first frame ranged from 550 to 700 mms, therefore weak perspective provided a good approximation to this sequence. (See a more detailed description of the sequence in <ref> [10] </ref> Fig. 5, or [6] Fig. 2.) We compared the relative errors of our algorithm to the errors reported in [10]. Three results were reported in [10] and copied to Table 1: column "Rot." depth computation with their algorithm, which assumes perspective projection and rotational motion only; column "2-frm" depth computation <p> points in the first frame ranged from 550 to 700 mms, therefore weak perspective provided a good approximation to this sequence. (See a more detailed description of the sequence in <ref> [10] </ref> Fig. 5, or [6] Fig. 2.) We compared the relative errors of our algorithm to the errors reported in [10]. Three results were reported in [10] and copied to Table 1: column "Rot." depth computation with their algorithm, which assumes perspective projection and rotational motion only; column "2-frm" depth computation using the algorithm described in [4], which uses 2-frames only; and column "2-frm, Ave." depth computation using the 2-frames algorithm, <p> from 550 to 700 mms, therefore weak perspective provided a good approximation to this sequence. (See a more detailed description of the sequence in <ref> [10] </ref> Fig. 5, or [6] Fig. 2.) We compared the relative errors of our algorithm to the errors reported in [10]. Three results were reported in [10] and copied to Table 1: column "Rot." depth computation with their algorithm, which assumes perspective projection and rotational motion only; column "2-frm" depth computation using the algorithm described in [4], which uses 2-frames only; and column "2-frm, Ave." depth computation using the 2-frames algorithm, where the depth estimates were averages <p> Moreover, a wide-lens camera was used, causing distortions at the periphery which were not compensated for. (See a more detailed description in <ref> [10] </ref> Fig. 4, or [6] Fig. 3.) Table 2 summarizes the results of our invariant algorithm for the last 8 points. <p> Note, however, that even algorithms which use the perspective projection model do not necessarily perform better with such sequences (compare with the results for a similar sequence reported in <ref> [10] </ref>). In this last sequence, the computation of invariant shape using 8 frames or 16 frames lead to rather similar results for the affine shape matrix and the Gramian matrix. However, in the second case the computed Gramian matrix was not positive-definite, and therefore we could not compute depth.
Reference: [11] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams: a factorization method - 3. detection and tracking of point features. </title> <type> Technical Report CMU-CS-91-132, </type> <institution> Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: In a sequence of images, feature points can be extracted and tracked (see, e.g., <ref> [11] </ref>).
Reference: [12] <author> C. Tomasi and T. Kanade. </author> <title> Shape and motion from image streams under orthography: a factorization method. </title> <journal> International Journal of Computer Vision, </journal> <volume> 9(2) </volume> <pages> 137-154, </pages> <year> 1992. </year>
Reference-contexts: For instance, [14, 9] identify the minimum number of points necessary to recover motion and structure from two or three frames, [1] recovers depth from many frames when motion is known, [8] considers restricted or partially known motion, <ref> [12] </ref> solves the complete multiframe problem under orthographic projection, and [5] proposes multiframe solutions under perspective projection. Conceivably, one could use one of these algorithms to determine the complete three-dimensional shape and pose of the object in a Euclidean reference system, and process the results to achieve similarity invariance.
Reference: [13] <author> S. Ullman and R. Basri. </author> <title> Recognition by linear combinations of models. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 13 </volume> <pages> 992-1006, </pages> <year> 1991. </year>
Reference-contexts: This result is closely related to, but different from, the statement that any image in the sequence is a linear combination of three of its images <ref> [13] </ref>. In this paper, we also show that the optional addition of a nonlinear but numerically sound stage, which selects the 1 B. Boufama, personal communication. <p> The coefficients (A) of the linear combinations are the three-dimensional coordinates of the correspond ing points in space in the affine three-dimensional basis of the points themselves. Notice the analogy and difference between this result and the statement, made in <ref> [13] </ref>, that under weak perspective any image of an object is a linear combination of three of its views. We are saying that any trajectory is a linear combination of three trajectories, while they are saying that any snapshot is a linear combination of three snapshots.
Reference: [14] <author> S. Ullman. </author> <title> The Interpretation of Visual Motion. </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1979. </year>
Reference-contexts: C. Tomasi is with the Department of Computer Science, Stanford University, Cedar Hall, Stanford, CA 94305; email: tomasi@cs.stanford.edu. IEEECS Log Number P95063. papers discuss under ideal circumstances. To be sure, several systems have been proposed for computing depth or shape information from image sequences. For instance, <ref> [14, 9] </ref> identify the minimum number of points necessary to recover motion and structure from two or three frames, [1] recovers depth from many frames when motion is known, [8] considers restricted or partially known motion, [12] solves the complete multiframe problem under orthographic projection, and [5] proposes multiframe solutions under
Reference: [15] <author> D. Weinshall. </author> <title> Model-based invariants for 3D vision. </title> <journal> International Journal on Computer Vision, </journal> <volume> 10(1) </volume> <month> 27-42, </month> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> 17(5):512-517, May 1995. <volume> 8 </volume> 1993. 
Reference-contexts: The recognition process is greatly simplified if the quality of the match can be determined without camera calibration, namely, without having to compute the pose of each candidate object in the reference system of the camera. For this purpose, three-dimensional object representations have been proposed <ref> [15] </ref> that are invariant with respect to similarity transformations, that is, rotations, translations, and isotropic scaling. These are exactly the transformations that occur in the weak perspective projection model, where images are scaled orthographic projections of rotated and translated objects. <p> be computed explicitly in order to compute a Euclidean representation. 3 Review of the Euclidean Repre sentation Starting with Eq. (3) as a multiframe imaging model, we now describe how to define a shape representation that is invariant with respect to similarity transformations, that is, rigid transformations and isotropic scaling <ref> [15] </ref>. Specifically, we work towards similarity invariance in three steps: 1. invariance to translation: we use the centroid of the points as a reference origin in the coordinate system where P is described. We translate ^ W accordingly, obtaining the matrix of centered image measurements W . <p> Of course, we cannot simply list the coordinates of the three basis points in a fixed reference system, since these coordinates would not be invariant with respect to rotation and scaling. Instead, we introduce the Gramian matrix of the three basis points, defined as follows <ref> [15] </ref>: G = 4 i p i p T i p k j p i p T j p k k p i p T k p k 5 : (7) In Section 4.2 we normalize G to make it invariant to scaling.

References-found: 15

