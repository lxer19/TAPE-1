URL: http://www.cs.bu.edu/techreports/97-014-imagedigestion.ps.Z
Refering-URL: http://cs-www.bu.edu/techreports/Home.html
Root-URL: 
Title: Image Digestion and Relevance Feedback in the ImageRover WWW Search Engine  
Author: Leonid Taycher, Marco La Cascia, and Stan Sclaroff 
Address: Boston, MA 02215  
Affiliation: Computer Science Department Boston University  
Note: BU CS TR97-014. To appear in Proc. Visual 1997, San Diego, 12/97.  
Abstract: ImageRover is a search by image content navigation tool for the world wide web. The staggering size of the WWW dictates certain strategies and algorithms for image collection, digestion, indexing, and user interface. This paper describes two key components of the ImageRover strategy: image digestion and relevance feedback. Image digestion occurs during image collection; robots digest the images they find, computing image decompositions and indices, and storing this extracted information in vector form for searches based on image content. Relevance feedback occurs during index search; users can iteratively guide the search through the selection of relevant examples. Im-ageRover employs a novel relevance feedback algorithm to determine the weighted combination of image similarity metrics appropriate for a particular query. ImageRover is available and running on the web site. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> J. R. Smith and S.-F. Chang. Visualseek: </author> <title> a fully automated content-based image query system. </title> <booktitle> In Proc. ACM Multimedia '96, </booktitle> <month> November </month> <year> 1996. </year>
Reference-contexts: One possible solution to this indexing problem is to use a traditional text-based approach. The strategy is to ex tract keywords automatically from HTML documents containing the image, using them as indices for image search. Variations of this approach are employed in Yahoo's Image Surfer, Lycos WebSeek <ref> [1] </ref>. The WebSeer search engine [2] supplements keywords with extracted information about images: grayscale vs. color, graphic vs. photo, image dimensions, file type and size, file date. In addition, their system includes a face detector that counts the number of faces and computes the largest face size.
Reference: [2] <author> C. Frankel, M. Swain, and V. Athitsos. Webseer: </author> <title> An image search engine for the world wide web. </title> <type> Technical Report 96-14, </type> <institution> University of Chicago, </institution> <month> August </month> <year> 1996. </year>
Reference-contexts: The strategy is to ex tract keywords automatically from HTML documents containing the image, using them as indices for image search. Variations of this approach are employed in Yahoo's Image Surfer, Lycos WebSeek [1]. The WebSeer search engine <ref> [2] </ref> supplements keywords with extracted information about images: grayscale vs. color, graphic vs. photo, image dimensions, file type and size, file date. In addition, their system includes a face detector that counts the number of faces and computes the largest face size. <p> Dominant orientation angle d and the orientation strength m at a given pixel are calculated via the follow ing formulae: d = 2 S d = C 2 3 : (11) Orientation histograms are then computed for each level in the pyramid. Each orientation histogram is quantized over <ref> [ 2 ; 2 ] </ref>. In the current implementation, there are 16 histogram bins, thus the number of bins allocated for direction information stored per subimage is 64 (4 levels * 16 bins/ level). Each histogram is then normalized to have unit sum. <p> For this application, a pyramid of four levels was found to be sufficient. For each level in the pyramid, a direction histogram of the harmonic peak magnitudes is then computed. Direction is quantized over <ref> [ 2 , 2 ] </ref>. In the current implementation, there are 16 histogram bins, thus the number of bins allocated for harmonic information stored per subimage is 64 (4 levels * 16 bins/ level). Finally, each histogram is normalized to have unit sum and then circularly smoothed.
Reference: [3] <author> M. Flickner, H. Sawhney, W. Niblack, J. Ashley, Q. Huang, D. Dom, M. Gorkani, J. Hafner, D. Lee, D. Petkovic, D. Steele, and P. Yanker. </author> <title> Query by image and video content: </title> <booktitle> The qbic system. IEEE Computer, </booktitle> <pages> pages 2330, </pages> <month> September </month> <year> 1995. </year>
Reference-contexts: In general, it is difficult for users to directly specify the weighted combination of measures needed for a particular query. This might require understanding the underlying image analysis algorithms. An alternative is to allow users to specify these weightings implicitly via a visual interface known as query by example <ref> [3] </ref>. Users can iteratively refine the search through the selection of more relevant example images. Using this relevance feedback, ImageRover then employs a novel relevance feedback algorithm to determine the weighted combination of image similarity metrics appropriate for the query. <p> Experimental evaluation of ImageRover's indexing strategy has shown approximation cuts indexing time by nearly two orders of magnitude without significant loss in retrieval accuracy [4]. 2.3 User Interface ImageRover employs the query by example paradigm <ref> [3, 8, 9] </ref>. To get the search going, a set of randomly selected images are shown to the user. The user can ask the system for another set of random images, or he/she can mark example relevant images from those presented.
Reference: [4] <author> S. Sclaroff, L. Taycher, and M. La Cascia. Im-agerover: </author> <title> A content-based image browser for the world wide web. </title> <booktitle> In Proc. of IEEE Workshop on Content-based Access of Image and Video Libraries, </booktitle> <month> June </month> <year> 1997. </year>
Reference-contexts: Experiments indicate that our framework can allow a modest fleet of 32 robots to collect and process over one million images monthly. For a detailed description of the ImageRover robot system architecture, readers are referred to <ref> [4] </ref>. As images are gathered, the robot then needs to digest each image, extracting the needed image statistics and decompositions. Each image digestion module processes an input stream of image URLs. <p> Furthermore, the distribution of samples may not be distributed uniformly across all dimensions. As a preliminary step, it is therefore useful to perform a dimensionality reduction via a principal components analysis (PCA) for each of the subvector spaces <ref> [4] </ref>. Using the truncated basis, each original image index subvectors x i undergo the dimensionality reducing transform, producing a reduced vector x i . <p> For each query, a client connects to the server to send the query data and then waits for the resulting k nearest neighbors. The server performs the query and returns the results to the client. To obtain better indexing performance, ImageRover employs an approximation algorithm for k-d search <ref> [7, 5, 4] </ref>. Experimental evaluation of ImageRover's indexing strategy has shown approximation cuts indexing time by nearly two orders of magnitude without significant loss in retrieval accuracy [4]. 2.3 User Interface ImageRover employs the query by example paradigm [3, 8, 9]. <p> To obtain better indexing performance, ImageRover employs an approximation algorithm for k-d search [7, 5, 4]. Experimental evaluation of ImageRover's indexing strategy has shown approximation cuts indexing time by nearly two orders of magnitude without significant loss in retrieval accuracy <ref> [4] </ref>. 2.3 User Interface ImageRover employs the query by example paradigm [3, 8, 9]. To get the search going, a set of randomly selected images are shown to the user.
Reference: [5] <author> D. White and R. Jain. </author> <title> Algorithms and strategies for similarity retrieval. </title> <type> Technical Report VCL-96-101, </type> <institution> University of California, </institution> <address> San Diego, </address> <month> July </month> <year> 1996. </year>
Reference-contexts: Given M modules and N subimages, the image index vector will have n = M fi N subvectors: X = B x 1 x n C The image indexing vectors stored by the robots have rather high dimension. As pointed out by White and Jain <ref> [5] </ref>, the data has intrinsic dimension that is significantly less than this. Furthermore, the distribution of samples may not be distributed uniformly across all dimensions. <p> For each query, a client connects to the server to send the query data and then waits for the resulting k nearest neighbors. The server performs the query and returns the results to the client. To obtain better indexing performance, ImageRover employs an approximation algorithm for k-d search <ref> [7, 5, 4] </ref>. Experimental evaluation of ImageRover's indexing strategy has shown approximation cuts indexing time by nearly two orders of magnitude without significant loss in retrieval accuracy [4]. 2.3 User Interface ImageRover employs the query by example paradigm [3, 8, 9].
Reference: [6] <author> J. H. Friedman, J. H. Bentley, and R. A. Finkel. </author> <title> An algorithm for finding best matches in logarithmic expected time. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 3(3):209226, </volume> <year> 1977. </year>
Reference-contexts: At startup, the server first performs a dimensionality reduction, and then builds an optimized k-d tree <ref> [6] </ref>. Once initialized, the index server runs as a process separate from the database query server, possibly on a different computer. For each query, a client connects to the server to send the query data and then waits for the resulting k nearest neighbors.
Reference: [7] <author> S. Arya, D. M. Mount, N. S. Netanyahu, R. Silver--man, and A. Y. Wu. </author> <title> An optimal algorithm for approximate nearest neighbor seaching in fixed dimensions. </title> <booktitle> In Proc. ACM-SIAM Syposium on Discrete Algorithms, </booktitle> <pages> pages 573582, </pages> <year> 1994. </year>
Reference-contexts: For each query, a client connects to the server to send the query data and then waits for the resulting k nearest neighbors. The server performs the query and returns the results to the client. To obtain better indexing performance, ImageRover employs an approximation algorithm for k-d search <ref> [7, 5, 4] </ref>. Experimental evaluation of ImageRover's indexing strategy has shown approximation cuts indexing time by nearly two orders of magnitude without significant loss in retrieval accuracy [4]. 2.3 User Interface ImageRover employs the query by example paradigm [3, 8, 9].
Reference: [8] <author> A. Gupta. </author> <title> Visual information retrieval technology: A virage perspective. </title> <type> Technical Report Revision 3a, </type> <institution> Virage Inc., </institution> <address> 177 Bovet Road, Suite 540, San Mateo, CA 94403, </address> <year> 1996. </year>
Reference-contexts: Experimental evaluation of ImageRover's indexing strategy has shown approximation cuts indexing time by nearly two orders of magnitude without significant loss in retrieval accuracy [4]. 2.3 User Interface ImageRover employs the query by example paradigm <ref> [3, 8, 9] </ref>. To get the search going, a set of randomly selected images are shown to the user. The user can ask the system for another set of random images, or he/she can mark example relevant images from those presented.
Reference: [9] <author> A. Pentland, R. Picard, and S. Sclaroff. Photo-book: </author> <title> Tools for content-based manipulation of image databases. </title> <journal> International Journal of Computer Vision, </journal> <volume> 18(3):233254, </volume> <month> June </month> <year> 1996. </year>
Reference-contexts: Experimental evaluation of ImageRover's indexing strategy has shown approximation cuts indexing time by nearly two orders of magnitude without significant loss in retrieval accuracy [4]. 2.3 User Interface ImageRover employs the query by example paradigm <ref> [3, 8, 9] </ref>. To get the search going, a set of randomly selected images are shown to the user. The user can ask the system for another set of random images, or he/she can mark example relevant images from those presented.
Reference: [10] <author> F. Liu and R. W. </author> <title> Picard. Periodicity, directionality, and randomness: Wold features for image modeling and retrieval. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 18(7):722733, </volume> <year> 1996. </year>
Reference-contexts: Readers are therefore invited to visit the ImageRover WWW site to try the system: http://www.cs.bu.edu/groups/ivc/ImageRover/. 3 Image Digestion Modules At this writing there are four image analysis submod-ules fully-implemented in our system: a color module, and three texture modules computing the Wold features of periodicity, directionality, and randomness <ref> [10] </ref>. Efforts are underway to expand the system to include face detection and description using eigenfaces [11, 12], and text cue vectors extracted via latent semantic indexing (LSI) [13, 14] on the text surrounding the image in an HTML document. 3.1 Color Color distributions are calculated as follows. <p> In ImageRover, histograms are compared directly via histogram distance, thereby avoiding problems with direct peak extraction and matching. 3.3 Texture Harmonic Structure The distribution of harmonic features is computed as a histogram of the harmonic peak magnitudes extracted from the DFT magnitude image <ref> [10] </ref>. Since it is based on the Fourier spectrum magnitude, this harmonic structure measure offers the useful property of spatial shift-invariance. In practice, each subimage is first converted to grayscale, normalized to zero mean, and its discrete Fourier transform magnitude image is computed. <p> The resulting peak list is then cleaned up by deleting all peaks which do not have corresponding harmonic peaks (peaks of the same angular direction but different frequency). Following <ref> [10] </ref>, a peak is considered harmonic if it is either: 1.) fundamental, i.e., its frequency can be used to linearly express frequencies of other peaks, or 2.) harmonic, i.e., its frequency can be linearly expressed as a combination of frequencies of fundamental peaks. <p> Finally, each histogram is normalized to have unit sum and then circularly smoothed. In the method proposed by Liu and Picard <ref> [10] </ref>, harmonic peaks are matched directly by using an inter-peak distance heuristic. The method proposed here is different, in that a histogram of the harmonic peak magnitudes is computed. Images can then be compared in terms of histogram distance between normalized histograms. <p> In addition, the method offers robustness to changes in scale. 3.4 Texture Randomness The randomness analysis module captures information about the indeterministic component of texture. The image is modeled in terms of the coefficients for a second order symmetric multiresolution simultaneous autoregres-sive (MRSAR) process <ref> [20, 10] </ref>. In the current implementation, color images are converted to grayscale before MR-SAR coefficients are computed.
Reference: [11] <author> A. Pentland, B. Moghaddam, T. Starner, O. Oliyide, and M. Turk. </author> <title> View-based and modular eigenspaces for face recognition. </title> <booktitle> In Proc. CVPR, </booktitle> <pages> pages 8491, </pages> <year> 1994. </year>
Reference-contexts: Efforts are underway to expand the system to include face detection and description using eigenfaces <ref> [11, 12] </ref>, and text cue vectors extracted via latent semantic indexing (LSI) [13, 14] on the text surrounding the image in an HTML document. 3.1 Color Color distributions are calculated as follows.
Reference: [12] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> Journal of Cognitive Neuroscience, </journal> <volume> 3(1):7186, </volume> <year> 1991. </year>
Reference-contexts: Efforts are underway to expand the system to include face detection and description using eigenfaces <ref> [11, 12] </ref>, and text cue vectors extracted via latent semantic indexing (LSI) [13, 14] on the text surrounding the image in an HTML document. 3.1 Color Color distributions are calculated as follows.
Reference: [13] <author> M. W. Berry, S. T. Dumais, and G. W. O'Brien. </author> <title> Low-rank orthogonal decompositions for information retrieval applications. </title> <journal> SIAM Review, </journal> <volume> 37(4):573595, </volume> <year> 1995. </year>
Reference-contexts: Efforts are underway to expand the system to include face detection and description using eigenfaces [11, 12], and text cue vectors extracted via latent semantic indexing (LSI) <ref> [13, 14] </ref> on the text surrounding the image in an HTML document. 3.1 Color Color distributions are calculated as follows. Image color histograms are computed in the CIE L fl u fl v fl color space, which has been shown to correspond closely to the human perception of color [15].
Reference: [14] <author> M. W. Berry and R. D. Fierro. </author> <title> Low-rank orthogonal decompositions for information retrieval applications. Numerical Linear Algebra with Applications, </title> <address> 3(4):301328, </address> <month> April </month> <year> 1996. </year>
Reference-contexts: Efforts are underway to expand the system to include face detection and description using eigenfaces [11, 12], and text cue vectors extracted via latent semantic indexing (LSI) <ref> [13, 14] </ref> on the text surrounding the image in an HTML document. 3.1 Color Color distributions are calculated as follows. Image color histograms are computed in the CIE L fl u fl v fl color space, which has been shown to correspond closely to the human perception of color [15].
Reference: [15] <author> U. Gargi and R. Kasturi. </author> <title> An evaluation of color histogram based methods in video indexing. </title> <booktitle> In Proc. of International Workshop on Image Databases and Multi-media search, </booktitle> <month> August </month> <year> 1996. </year>
Reference-contexts: Image color histograms are computed in the CIE L fl u fl v fl color space, which has been shown to correspond closely to the human perception of color <ref> [15] </ref>.
Reference: [16] <author> J. Hafner, Harpreet Sawney, W. Equitz, M. Flickner, and W. Niblack. </author> <title> Efficient color histogram indexing for quadratic form distance functions. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 1(7):729 736, </volume> <year> 1995. </year>
Reference-contexts: For each of the subimages, the color distribution is then calculated using the histogram method <ref> [16] </ref>. Each histogram quantizes the color space into 64 (4 for each axis) bins. Each histogram is normalized to have unit sum and then blurred. 3.2 Texture Orientation The texture orientation distribution is calculated using steerable pyramids [17, 18].
Reference: [17] <author> W. Freeman and E. H. Adelson. </author> <title> The Design and Use of Steerable Filters. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence, </journal> <volume> 13(9):891906, </volume> <month> September </month> <year> 1991. </year>
Reference-contexts: Each histogram quantizes the color space into 64 (4 for each axis) bins. Each histogram is normalized to have unit sum and then blurred. 3.2 Texture Orientation The texture orientation distribution is calculated using steerable pyramids <ref> [17, 18] </ref>. For this application, a steer able pyramid of four levels was found to be sufficient. If the input image is color, then it is first converted to grayscale before pyramid computation. <p> The separable basis set and interpolation functions for the second derivative of a Gaussian were implemented directly using the nine-tap formulation provided in Appendix H (tables IV and VI) of <ref> [17] </ref>. The resulting basis is comprised of three G 2 filters to steer the second derivative of a Gaussian, and four H 2 filters to steer the Hilbert transform of the second derivative of a Gaussian. <p> the Fourier series for oriented energy E G 2 H 2 as a function of angle : E G 2 H 2 = C 1 + C 2 cos (2) + C 3 sin (2); (9) where the terms C 1 ,C 2 , C 3 are as prescribed in <ref> [17] </ref>, Ap pendix I. Dominant orientation angle d and the orientation strength m at a given pixel are calculated via the follow ing formulae: d = 2 S d = C 2 3 : (11) Orientation histograms are then computed for each level in the pyramid.
Reference: [18] <author> M. Gorkani and R. </author> <title> Picard. Texture orientation for sorting photos at a glance. </title> <booktitle> In Proc. IEEE Conf. on Vision and Pattern Recogntion, </booktitle> <year> 1994. </year>
Reference-contexts: Each histogram quantizes the color space into 64 (4 for each axis) bins. Each histogram is normalized to have unit sum and then blurred. 3.2 Texture Orientation The texture orientation distribution is calculated using steerable pyramids <ref> [17, 18] </ref>. For this application, a steer able pyramid of four levels was found to be sufficient. If the input image is color, then it is first converted to grayscale before pyramid computation. <p> For the implementation described in this paper, all the points with the strength magnitude less than 0.005 were discarded and not counted in the overall direction histogram. The orientation measure employed in ImageRover differs from that proposed by Gorkani and Picard <ref> [18] </ref>. While both systems utilize steerable pyramids to determine orientation strengths at multiple scales, there is a difference in how histograms are compared. In the system of Gorkani and Picard, histogram peaks are first extracted and then image similarity is computed in terms of peak-to-peak distances.
Reference: [19] <author> R. Picard and T. Minka. </author> <title> Vision texture for annotation. Multimedia Systems, </title> <address> 3(3):314, </address> <year> 1995. </year>
Reference-contexts: Each histogram is then normalized to have unit sum. Once computed, the histogram must be circularly blurred to obviate aliasing effects and to allow for fuzzy matching of histograms during image search <ref> [19] </ref>. In practice, there must be a lower bound placed on the accepted orientation strength allowed to contribute to the distribution. For the implementation described in this paper, all the points with the strength magnitude less than 0.005 were discarded and not counted in the overall direction histogram.
Reference: [20] <author> J. Mao and A. K. Jain. </author> <title> Texture classification and segmentation using multiresolution simultaneous au-toregressive models. </title> <journal> Pattern Recognition, </journal> <volume> 25(2):173 188, </volume> <year> 1992. </year>
Reference-contexts: In addition, the method offers robustness to changes in scale. 3.4 Texture Randomness The randomness analysis module captures information about the indeterministic component of texture. The image is modeled in terms of the coefficients for a second order symmetric multiresolution simultaneous autoregres-sive (MRSAR) process <ref> [20, 10] </ref>. In the current implementation, color images are converted to grayscale before MR-SAR coefficients are computed.
Reference: [21] <author> G. Salton and M. J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1989. </year>
Reference-contexts: Furthermore, these features are computed at three resolutions l = f2; 3; 4g, yielding 15 values per subimage. 4 Relevance Feedback Relevance feedback enables the user to iteratively refine a query via the specification of relevant items <ref> [21] </ref>. By including the user in the loop, better search performance can be achieved. Typically, the system returns a set of possible matches, and the user gives feedback by marking items as relevant or not relevant.
Reference: [22] <author> R. O. Duda and P. E. Hart. </author> <title> Pattern Recognition and Scene Analysis. </title> <publisher> John Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: Moreover, if the database is reasonably large, we don't need to recompute this factor when new images are added to the archive. It is difficult to determine in advance which ~ L m distance metric is best suited for a particular similarity detection task <ref> [22] </ref>. Therefore, our system selects the appropriate ~ L m metric each time a query is made, based on relevance feedback from the user.
References-found: 22

