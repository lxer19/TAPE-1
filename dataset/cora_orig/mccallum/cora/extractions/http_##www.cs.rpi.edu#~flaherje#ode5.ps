URL: http://www.cs.rpi.edu/~flaherje/ode5.ps
Refering-URL: http://www.cs.rpi.edu/~flaherje/index6.html
Root-URL: http://www.cs.rpi.edu
Email: f j f (t j j (5.1.2b)  
Title: Chapter 5 Multivalue or Multistep Methods 5.1 Introduction  
Author: k X ff i ni h 
Address: where  
Affiliation: i=0  
Abstract: One-step methods only require information about the solution at one time, say t = t n1 to compute the solution at an advanced time t = t n . After integrating away from the initial point, we have several solution values that can be used to predict the solution at an advanced point. In this Chapter, we use these past solution values to construct "multistep" methods that potentially have fewer function evaluations per time step than one-step methods. To begin, let us define a linear multistep method for the scalar IVP In applying (5.1.2), we assume that approximate solutions y n1 , y n2 , : : : , y nk are known and that we seek to calculate y n (Figure 5.1.1). In particular, y 0 , y 1 , : : : , y k1 must be known in order to start using the method. We'll discuss methods for obtaining these "starting values;" however, for the moment, assume that they are calculated by a one-step method. Some other assumptions and observations concerning (5.1.2) follow. y 0 = f (t; y); t &gt; 0; y(0) = y 0 (5.1.1)
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> U.M. </author> <title> Ascher and L.R. Petzold. Computer Methods for Ordinary Differential Equations and Differential-Algebraic Equations. </title> <publisher> SIAM, </publisher> <address> Philadelphia, </address> <year> 1998. </year>
Reference-contexts: that if p (o ) 2 C 0 [a; b] and q (o ) is integrable and does not change sign on [a; b] then Z b p (o )q (o )do = p (j) a Examining (5.3.4b), reveals that k = k! does not change sign for o 2 <ref> [0; 1] </ref>. Thus, we can use the second mean value theorem with (5.3.7b) and write the local error in the more explicit form d n = (1) k h k+1 y (k+1) (j) 0 o Thus, the error coefficient fl k is also known from, e.g., Table 5.3.1. <p> * k = 4 : Four-step Adams-Bashforth formula y n = y n1 + 24 o n = 720 The coefficients of the Adams-Bashforth methods (5.3.8c) and the local error coeffi cient according to (5.3.9b) are repeated in Table 5.3.2 for k = 1; 2; : : : ; 6 <ref> [1] </ref>. k j = 1 2 3 4 5 6 fl k 2 12 8 720 288 60480 Table 5.3.2: Coefficients of the Adamas-Bashforth method (5.3.8c) and the local error (5.3.9b) for orders one through six [1]. Problems 18 1. <p> repeated in Table 5.3.2 for k = 1; 2; : : : ; 6 <ref> [1] </ref>. k j = 1 2 3 4 5 6 fl k 2 12 8 720 288 60480 Table 5.3.2: Coefficients of the Adamas-Bashforth method (5.3.8c) and the local error (5.3.9b) for orders one through six [1]. Problems 18 1. <p> (5.4.3c) for k = 1; 2; : : : ; 6, in Table 5.4.2. k j = 0 1 2 3 4 5 fl k 2 12 24 720 160 60480 Table 5.4.2: Coefficients of the Adams-Moulton method (5.4.9) and their local error coefficients (5.4.3c) for orders one through six <ref> [1] </ref>. Example 5.4.1. Comparing Tables 5.3.2 and 5.4.2, we see that the error coefficient of the Adams-Moulton method of order k is smaller than that of the Adams-Bashforth method of the same order. Thus, with comparable derivatives, the implicit methods should produce more accuracy than the explicit methods. <p> Backward difference methods and their local discretization errors for k = 1; 2; 3; 4, follow. Backward difference coefficients for k = 1; 2; : : : ; 6, appear in Table 5.5.1 <ref> [1] </ref>. 25 * k = 1 : Backward Euler method y n = y n1 + hf n ; (5.5.6a) h y 00 (): (5.5.6b) * k = 2 : Two-step backward-difference formula ry n + 2 or 1 (4y n1 y n2 + 2hf n ); (5.5.7a) h 2 y <p> 0 ffiff 0 ffiff 1 ffiff 2 ffiff 3 ffiff 4 ffiff 5 ffiff 6 1 1 1 1 -1 3 11 6 11 -18 9 -2 5 137 60 137 -300 300 -200 75 -12 Table 5.5.1: Coefficients of the backward difference method (5.5.5c). for orders one through six <ref> [1] </ref>. Their local error coefficients are 1=(k + 1). 5.6 Convergence, Accuracy, and Stability Having several methods at our disposal, let us now study questions of consistency, convergence, and stability of linear multistep methods (LMMs) of the form (5.1.2) applied to the IVP (5.1.1). <p> The boundary of the region of absolute stability follows by calculating h = oe (e i ) The regions of absolute stability of the Adams-Bashforth, Adams-Moulton, and backward difference methods are illustrated in Figures 2, 3, and 4, respectively <ref> [1] </ref>. Some observations and conclusions follow. 1. The Adams-Moulton methods of orders 1 and 2 are the backward Euler method and the trapezoidal rule. The absolute stability regions of these methods are the exterior of a unit circle centered at (1; 0) and the entire left-half of the h-plane, respectively. <p> The absolute stability regions of these methods are the exterior of a unit circle centered at (1; 0) and the entire left-half of the h-plane, respectively. Neither region is shown in Figure 5.6.2. Ascher and Petzold's <ref> [1] </ref> definition of k differs from ours for Adams-Moulton methods. The regions labeled k = 2 to 4 in Figure 5.6.3 correspond to our k = 3 to 5. 2. Explicit methods always have a finite region of absolute stability. 36 A method is stable inside of its shaded region [1]. <p> <ref> [1] </ref> definition of k differs from ours for Adams-Moulton methods. The regions labeled k = 2 to 4 in Figure 5.6.3 correspond to our k = 3 to 5. 2. Explicit methods always have a finite region of absolute stability. 36 A method is stable inside of its shaded region [1]. method is stable inside of its shaded region [1]. 37 (top) and 4 to 6 (bottom). Methods are stable outside of the shaded regions [1]. 38 3. Implicit methods have a larger region of absolute stability than a corresponding explicit method of the same order. 4. <p> The regions labeled k = 2 to 4 in Figure 5.6.3 correspond to our k = 3 to 5. 2. Explicit methods always have a finite region of absolute stability. 36 A method is stable inside of its shaded region <ref> [1] </ref>. method is stable inside of its shaded region [1]. 37 (top) and 4 to 6 (bottom). Methods are stable outside of the shaded regions [1]. 38 3. Implicit methods have a larger region of absolute stability than a corresponding explicit method of the same order. 4. The absolute stability region typically becomes smaller as order increases. 5. <p> Explicit methods always have a finite region of absolute stability. 36 A method is stable inside of its shaded region <ref> [1] </ref>. method is stable inside of its shaded region [1]. 37 (top) and 4 to 6 (bottom). Methods are stable outside of the shaded regions [1]. 38 3. Implicit methods have a larger region of absolute stability than a corresponding explicit method of the same order. 4. The absolute stability region typically becomes smaller as order increases. 5.
Reference: [2] <author> M. Berzins and R.M. Furzeland. </author> <title> A user's manual for sprint a versatile software package for solving systems of algebraic, ordinary and partial differential equations: Part 1 algebraic and ordinary differential equations. </title> <type> Technical report, </type> <institution> Thornton Research Centre, Shell Research Ltd., </institution> <address> Amsterdam, </address> <year> 1993. </year>
Reference-contexts: We report their results in Figures 5.7.3 and 5.7.4. The codes used for this test follow. 1. LSODE and VODE are the codes described previously with the BDF option set. 2. DEBDF is a driver for LSODE for stiff systems. 3. SPRINT, developed by Berzins and Furzeland <ref> [2] </ref>, contains several multistep methods and solution packages. The one used for the test is a blended multistep method that is A-stable to order four. 4. SECDER and ROBER are multistep codes that won't be described further. 5. LADAMS is LSODE with the Adams methods selected. 6.
Reference: [3] <author> W.E. Boyce and R.C. DiPrima. </author> <title> Elementary Differential Equations and Boundary Value Problems. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, third edition, </address> <year> 1977. </year>
Reference-contexts: Suppose, for example, that i is a root of multiplicity , then the solutions corresponding to i are i : (5.6.8b) Note the similarities between this analysis and that of constant-coefficient ODE <ref> [3] </ref>. Since the exact solution of the test equation (5.6.4) is y (t n ) = ffie hn = ffi (e h ) n ; (5.6.9) the principal root 1 of (5.6.7) must be an approximation of e h .
Reference: [4] <author> K.E. Brenan, S.L Campbell, </author> <title> and L.R. Petzold. Numerical Solution of Initial-Value Problems in Differential-Algebraic Equations. </title> <publisher> North Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference-contexts: DEABM - 22 EPISODE -..-..- 18 LSODE -.-.-.- 17 D02CAF : : : : : : . 19 DOPRI8 9 Table 5.7.1: Legends for Figures 5.7.1 and 5.7.2 and code storage [12]. 5. DASSL, developed by Petzold (cf. <ref> [4] </ref>) is a backward difference code for stiff differential and differential algebraic systems. DASSL addresses differential equations in the implicit form f (t; y; y 0 ) = 0: It can also solve these systems when the Jacobian f y 0 is not invertible.
Reference: [5] <author> P.N. Brown, G.D. Byrne, and A.C. Hindmarsh. Vode: </author> <title> a variable coefficient ode solver. </title> <journal> SIAM J. Sci. Stat. Comput., </journal> <volume> 10 </volume> <pages> 1039-1051, </pages> <year> 1989. </year>
Reference-contexts: Newton's method is used for stiff problems. 3. LSODE is another implementation of the constant-step Adams and BDF methods. It is similar to EPISODE. 4. VODE is a variable step, variable order code based on the variable-step Adams and BDF formulas. It was developed by Brown et al. <ref> [5] </ref> and is an extension of EPISODE. 57 Code Symbol Storage/eqn. DEABM - 22 EPISODE -..-..- 18 LSODE -.-.-.- 17 D02CAF : : : : : : . 19 DOPRI8 9 Table 5.7.1: Legends for Figures 5.7.1 and 5.7.2 and code storage [12]. 5.
Reference: [6] <author> R.L. Burden and J.D. Faires. </author> <title> Numerical Analysis. </title> <address> PWS-Kent, Boston, fifth edition, </address> <year> 1993. </year>
Reference-contexts: Thus, with comparable derivatives, the implicit methods should produce more accuracy than the explicit methods. Let's examine this possibility using the simple example (cf. Burden and Faires <ref> [6] </ref>, Chapter 5) y 0 = y t 2 + 1; 0 &lt; t 2; y (0) = 2 which has the exact solution y (t) = (t + 1) 2 2 Burden and Faires [6] calculate solutions using the fourth order Adams-Bashforth (5.3.13a) and Adams-Moulton (5.4.8a) formulas. <p> Let's examine this possibility using the simple example (cf. Burden and Faires <ref> [6] </ref>, Chapter 5) y 0 = y t 2 + 1; 0 &lt; t 2; y (0) = 2 which has the exact solution y (t) = (t + 1) 2 2 Burden and Faires [6] calculate solutions using the fourth order Adams-Bashforth (5.3.13a) and Adams-Moulton (5.4.8a) formulas. Since this problem is linear, the Adams-Moulton solution may be obtained without iteration. Results with h = 0:2 are shown in 22 Table 5.4.3.
Reference: [7] <author> G.D. Byrne and A.C. Hindmarsh. </author> <title> A polyalgorithm for the numerical solution of ordinary differential equations. </title> <journal> ACM Trans. Math. Software, </journal> <volume> 1 </volume> <pages> 71-96, </pages> <year> 1975. </year>
Reference-contexts: Norms are used for vector systems. 2. EPISODE, developed by Byrne and Hindmarsh <ref> [7] </ref>, is a variable step, variable order implementation of the constant-step Adams and BDF methods using the Nordsieck representation. For nonstiff problems, functional iteration uses a P (EC) strategy. Newton's method is used for stiff problems. 3. LSODE is another implementation of the constant-step Adams and BDF methods.
Reference: [8] <author> G. Dahlquist. </author> <title> A special stability problem for some linear multistep methods. </title> <journal> BIT, </journal> <volume> 3 </volume> <pages> 27-43, </pages> <year> 1963. </year>
Reference-contexts: Unfortunately, A-stability is very difficult to obtain for LMMs. Theorem 5.6.4. (i) No explicit LMM is A-stable, (ii) the order of an A-stable LMM cannot exceed two, and (iii) the second-order A-stable LMM with the smallest error coefficient is the trapezoidal rule. Proof. cf. Dahlquist <ref> [8] </ref>. A different proof of (ii) and (iii) appears in Wanner et al. [17]. This a major negative result of numerical ODEs. No such restriction exists for implicit Runge-Kutta methods and arbitrarily high-order A-stable methods may be constructed.
Reference: [9] <author> J.R. Dormand and P.J. Prince. </author> <title> A family of embedded Runge-Kutta formulae. </title> <journal> J. Comput. Appl. Math., </journal> <volume> 6 </volume> <pages> 19-26, </pages> <year> 1980. </year> <month> 65 </month>
Reference-contexts: Example 5.7.7. Hairer et al. [12], Section III.7, compare several codes on a suite of six non-stiff problems. We report their results in Figures 5.7.1 and 5.7.2. Codes that have not already been identified include DOPRI8, which is the eighth-order Dormand and Prince Runge-Kutta method <ref> [9] </ref>, and D02CAF, which is similar to LSODE and EPISODE, and contained in the NAG library. The six problems used for testing are described in Hairer et al. [12], Section II.10. The legends and storage requirements for each code are given in Table 5.7.1.
Reference: [10] <author> C.W. Gear. </author> <title> Numerical Initial Value Problems in Ordinary Differential Equations. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, </address> <year> 1971. </year>
Reference-contexts: Figure 5.3.1). We'll call (5.3.7a) a k-step method since it uses solution and function values at the k points t n1 , t n2 , : : : , t nk ; however, other terminology is also used <ref> [10] </ref>. From (5.3.7b) we see that the local error of (5.3.7a) is O (h k+1 ). Thus, the order of a k-step Adams-Bashforth method is k. The method (5.3.7) has only one function evaluation per step. <p> Theorem 5.6.1. Satisfaction of the root condition is necessary and sufficient for the stability of a LMM. Proof. The key aspect of the proof have been presented. A more thorough analysis is given in Gear <ref> [10] </ref>, Section 10.1. Example 5.6.2. <p> Dahlquist. Theorem 5.6.3. The necessary and sufficient conditions for a LMM to be convergent are that it be consistent and satisfy the root condition. Proof. Complete proofs of this important theorem are given in Gear <ref> [10] </ref>, Chapter 10, and Henrici [14], Chapter 5. We'll prove that convergence implies stability and consistency. <p> A (ff)-stable, ff 2 [0; =2) if its region of absolute stability contains the infinite wedge W ff = fh j ff &lt; arg (h) &lt; ffg: Re (h ) Re (h )l l a The notion of A (ff)-stability was introduced by Widlund [18] and is discussed in Gear <ref> [10] </ref>, Chapter 11 and Hairer and Wanner [13], Section V.2. An example of the wedge W ff is shown in Figure 5.6.6. A (0 + )-stable methods have regions of absolute stability that contain the negative real axis. A (=2)-stable methods are A-stable. <p> Widlund [18] showed that A (ff)-stable LMMs of orders one through four exist with ff arbitrarily close to =2. Grigorieff and Schroll [11] showed that k-step LMMs of order k also exist for all k (cf. [13], Section V.2). Gear <ref> [10] </ref>, Chapter 11, describes another means of relaxing A-stability by introducing the notion of stiff stability, which combines both stability and accuracy. Definition 5.6.14. <p> Functional iteration is assumed. The formulas would have to be modified for Newton iteration. Our development does not reveal the generality of (5.7.6c) and (5.7.8). Gear <ref> [10] </ref>, Chapters 7 and 9, provides additional details. The final converged iterates are passed to the next step; thus, if convergence occurs after corrector iterations, y n = y n . The representation (5.7.6c) and (5.7.8) may not be best when automatic step and order changes are involved. <p> A simple two-dimensional example is y 0 0 = a 21 y 1 + a 22 y 2 + b 2 : Many of these codes have been incorporated into scientific subroutine libraries. For example, the IVPAG procedure in the IMSL Library is a modification of Gear's <ref> [10] </ref> original Adam's and BDF procedure. The procedures D02PCF and D02EJF, respectively, are variable order, variable step Adams and BDF codes in the NAG Library. Example 5.7.7. Hairer et al. [12], Section III.7, compare several codes on a suite of six non-stiff problems.
Reference: [11] <author> R.D. Grigorieff and J.Schroll. </author> <title> Uber A(alpha)-stable verfahren hoher konsistenzord-nung. </title> <journal> Computing, </journal> <volume> 20 </volume> <pages> 343-350, </pages> <year> 1978. </year>
Reference-contexts: Widlund [18] showed that A (ff)-stable LMMs of orders one through four exist with ff arbitrarily close to =2. Grigorieff and Schroll <ref> [11] </ref> showed that k-step LMMs of order k also exist for all k (cf. [13], Section V.2). Gear [10], Chapter 11, describes another means of relaxing A-stability by introducing the notion of stiff stability, which combines both stability and accuracy. Definition 5.6.14.
Reference: [12] <author> E. Hairer, S.P. Norsett, and G. Wanner. </author> <title> Solving Ordinary Differential Equations I: Nonstiff Problems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <note> second edition, </note> <year> 1993. </year>
Reference-contexts: 1 ; Z 1 2 do = 0 2 5 : Continuing in this manner and using the results in (5.3.7a) yields y n = y n1 + h (1 + 2 5 r 2 + 8 251 r 4 + 288 (5.3.9a) Additional results, given in Hairer et al. <ref> [12] </ref>, Section III.1, are reproduced in Table 5.3.1. j 0 1 2 3 4 5 6 7 8 2 12 8 720 288 60480 17280 3628800 Table 5.3.1: Coefficients fl j for Adams-Bashforth methods ([12], Section III.1). <p> fl fl i , i = 0; 1; : : : ; k 1, according to (5.4.3a), we find y n = y n1 + h (1 2 1 r 2 24 19 r 4 160 20 : : : + fl fl Additional results, given in Hairer et al. <ref> [12] </ref>, Section III.1, are reproduced in Table 5.4.1. j 0 1 2 3 4 5 6 7 8 j 1 1 12 1 720 3 60480 275 3628800 Table 5.4.1: Coefficients fl fl j for implicit Adams methods ([12], Section III.1). <p> Theorem 5.6.2. No k-step LMM satisfying the root condition can have order exceeding k + 1 when k is odd or order k + 2 when k is even. Proof. cf. Hairer et al. <ref> [12] </ref>. The k-step methods of order k + 2 are called optimal-order methods. All roots of ae () are on the unit circle, so they are only weakly stable. Example 5.6.5. <p> It was developed by Brown et al. [5] and is an extension of EPISODE. 57 Code Symbol Storage/eqn. DEABM - 22 EPISODE -..-..- 18 LSODE -.-.-.- 17 D02CAF : : : : : : . 19 DOPRI8 9 Table 5.7.1: Legends for Figures 5.7.1 and 5.7.2 and code storage <ref> [12] </ref>. 5. DASSL, developed by Petzold (cf. [4]) is a backward difference code for stiff differential and differential algebraic systems. <p> For example, the IVPAG procedure in the IMSL Library is a modification of Gear's [10] original Adam's and BDF procedure. The procedures D02PCF and D02EJF, respectively, are variable order, variable step Adams and BDF codes in the NAG Library. Example 5.7.7. Hairer et al. <ref> [12] </ref>, Section III.7, compare several codes on a suite of six non-stiff problems. We report their results in Figures 5.7.1 and 5.7.2. <p> Codes that have not already been identified include DOPRI8, which is the eighth-order Dormand and Prince Runge-Kutta method [9], and D02CAF, which is similar to LSODE and EPISODE, and contained in the NAG library. The six problems used for testing are described in Hairer et al. <ref> [12] </ref>, Section II.10. The legends and storage requirements for each code are given in Table 5.7.1. The Runge-Kutta code DOPRI8 generally uses more function evaluations but less CPU time than the LMM codes. The test problems are fairly simple, but the performance 58 [12]. 60 of the high-order Runge-Kutta method should <p> testing are described in Hairer et al. <ref> [12] </ref>, Section II.10. The legends and storage requirements for each code are given in Table 5.7.1. The Runge-Kutta code DOPRI8 generally uses more function evaluations but less CPU time than the LMM codes. The test problems are fairly simple, but the performance 58 [12]. 60 of the high-order Runge-Kutta method should not be ignored. Conditions, however, could be reversed with more complicated functions. Of the LMM codes, DEABM seems to be the most efficient and EPISODE the least.
Reference: [13] <author> E. Hairer and G. Wanner. </author> <title> Solving Ordinary Differential Equations II: Stiff and Differential Algebraic Problems. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: its region of absolute stability contains the infinite wedge W ff = fh j ff &lt; arg (h) &lt; ffg: Re (h ) Re (h )l l a The notion of A (ff)-stability was introduced by Widlund [18] and is discussed in Gear [10], Chapter 11 and Hairer and Wanner <ref> [13] </ref>, Section V.2. An example of the wedge W ff is shown in Figure 5.6.6. A (0 + )-stable methods have regions of absolute stability that contain the negative real axis. A (=2)-stable methods are A-stable. <p> Widlund [18] showed that A (ff)-stable LMMs of orders one through four exist with ff arbitrarily close to =2. Grigorieff and Schroll [11] showed that k-step LMMs of order k also exist for all k (cf. <ref> [13] </ref>, Section V.2). Gear [10], Chapter 11, describes another means of relaxing A-stability by introducing the notion of stiff stability, which combines both stability and accuracy. Definition 5.6.14. <p> Of the LMM codes, DEABM seems to be the most efficient and EPISODE the least. From Table 5.7.1, we see that DOPPI8 requires about half of the storage per equation as do the LMMs. Of the LMM codes, DEBEAM has the greatest storage cost. Example 5.7.8. Hairer and Wanner <ref> [13] </ref>, Section V.5, compare several codes for a suite of stiff problems. We report their results in Figures 5.7.3 and 5.7.4. The codes used for this test follow. 1. LSODE and VODE are the codes described previously with the BDF option set. 2.
Reference: [14] <author> P. Henrici. </author> <title> Discrete Variable Mehtods in Ordinary Differential Equations. </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1962. </year>
Reference-contexts: Dahlquist. Theorem 5.6.3. The necessary and sufficient conditions for a LMM to be convergent are that it be consistent and satisfy the root condition. Proof. Complete proofs of this important theorem are given in Gear [10], Chapter 10, and Henrici <ref> [14] </ref>, Chapter 5. We'll prove that convergence implies stability and consistency.
Reference: [15] <author> A. </author> <title> Nordsieck. On numerical integration of ordinary differential equations. </title> <journal> Maths. Comp., </journal> <volume> 16 </volume> <pages> 22-49, </pages> <year> 1962. </year>
Reference-contexts: 0 rhy 0 r 2 hy 0 3 7 Using the definition of the backward-difference operators (5.2.15) 2 6 y n n n n 7 5 = 6 4 0 1 0 0 0 1 2 1 7 5 6 4 hy 0 hy 0 hy 0 3 7 Nordsieck <ref> [15] </ref> suggested representing the solution in terms of scaled derivatives at t = t n , i.e., as n ; 2! n ; : : : ; (k 1)! n ] T : (5.7.10) Step size variation is simplified with this representation.
Reference: [16] <editor> L.F. Shampine and M.K. Gordon. </editor> <title> Computer Solution of Ordinary Differential Equations. W.H. </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1975. </year>
Reference-contexts: The coefficients of these formulas are functions of h. The variable step formulas are generally more stable than the uniform step formulas but are less efficient. Some available LMM codes are 1. DEABM is a modification of a code developed by Shampine and Gordon <ref> [16] </ref>. This code implements a variable step size divided difference representation of the Adams formulas. It uses a P ECE strategy and includes order variation. Let's go over the order variation scheme to illustrate the technique.
Reference: [17] <author> G. Wanner, E Hairer, and S.P. Norsett. </author> <title> Order stars and stability theorems. </title> <journal> BIT, </journal> <volume> 18 </volume> <pages> 475-489, </pages> <year> 1978. </year>
Reference-contexts: Theorem 5.6.4. (i) No explicit LMM is A-stable, (ii) the order of an A-stable LMM cannot exceed two, and (iii) the second-order A-stable LMM with the smallest error coefficient is the trapezoidal rule. Proof. cf. Dahlquist [8]. A different proof of (ii) and (iii) appears in Wanner et al. <ref> [17] </ref>. This a major negative result of numerical ODEs. No such restriction exists for implicit Runge-Kutta methods and arbitrarily high-order A-stable methods may be constructed.
Reference: [18] <author> O. Widlund. </author> <title> A note on unconditionally stable linear multistep methods. </title> <journal> BIT, </journal> <volume> 7 </volume> <pages> 65-70, </pages> <year> 1967. </year>
Reference-contexts: A numerical method is A (ff)-stable, ff 2 [0; =2) if its region of absolute stability contains the infinite wedge W ff = fh j ff &lt; arg (h) &lt; ffg: Re (h ) Re (h )l l a The notion of A (ff)-stability was introduced by Widlund <ref> [18] </ref> and is discussed in Gear [10], Chapter 11 and Hairer and Wanner [13], Section V.2. An example of the wedge W ff is shown in Figure 5.6.6. A (0 + )-stable methods have regions of absolute stability that contain the negative real axis. A (=2)-stable methods are A-stable. <p> If we know that all of the eigenvalues of a stiff system lie inside of a certain wedge W ff fl , then an A (ff fl )-stable method can be used without any stability restriction on h. Widlund <ref> [18] </ref> showed that A (ff)-stable LMMs of orders one through four exist with ff arbitrarily close to =2. Grigorieff and Schroll [11] showed that k-step LMMs of order k also exist for all k (cf. [13], Section V.2).
References-found: 18

