URL: ftp://ftp.cs.caltech.edu/tr/cs-tr-96-02.ps.Z
Refering-URL: ftp://ftp.cs.caltech.edu/tr/INDEX.html
Root-URL: http://www.cs.caltech.edu
Title: A Compiler Algorithm for Managing Asynchronous Memory Read Completion 1  
Author: Daniel Maskit 
Date: January 15, 1996  
Affiliation: Scalable Concurrent Programming Laboratory California Institute of Technology  
Abstract: Computers with conventional memory systems have a predictable latency between initiation and completion of a memory read. On such machines it is relatively easy for either the compiler or the processor to guarantee that a load has completed before further references to the loaded register are made. In a machine with a logically shared, but physically distributed, memory, these latencies are not statically predictable. Some existing systems, such as the Cray T3D, deal with this problem by using a hardware mechanism to enforce synchronization on a register which is the target of a remote memory access. The M-Machine currently being designed by the Concurrent VLSI Architecture Group at MIT performs remote memory accesses asynchronously, and allows program execution to continue while the access is outstanding, but does not enforce synchronization in hardware. This architectural simplification, and resulting relaxation of memory completion semantics, poses a challenge to the compiler: how can this simpler memory system be efficiently supported while maintaining program correctness. In particular, what is required to guarantee that there are no conflicts between completion of a memory operation by placing a value into a register, and other uses of the register being written. This paper describes a general solution to this problem, develops an algorithm to implement it, and shows that the algorithm is correct. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dally, W. J., et al., </author> <title> "M-Machine Architecture v1.0," </title> <institution> Massachusetts Institute of Technology, Artificial Intelligence Laboratory, </institution> <note> Concurrent VLSI Architecture Memo 58, </note> <month> February, </month> <year> 1994. </year>
Reference: [2] <author> Ellis, John R., 'Bulldog: </author> <title> A Compiler for VLIW Architectures', </title> <publisher> The MIT Press, </publisher> <address> Cambridge, MA, </address> <year> 1986. </year> <note> [3] , Lowney, </note> <editor> P.G., Freudenberger, Stefan M., et. al., </editor> <title> The Multiflow Trace Scheduling Compiler', </title> <editor> J. </editor> <booktitle> of Supercomputing, </booktitle> <address> v.7(1-2), </address> <year> 1993. </year> <month> 23 </month>
Reference-contexts: The Multiflow compiler being used for the M-Machine work uses a trace scheduling algorithm <ref> [2] </ref>. In terms of the algorithm presented in this paper, the major difference between basic blocks and traces is that, unlike a basic block, a trace can have multiple entry and exit points. <p> Traces are not allowed to contain loop back edges. One important difference between a basic block and a trace is that a trace is allowed to have multiple exit and entry points. An in-depth description of trace scheduling can be found in <ref> [2, 3] </ref>. 6.2 Algorithm Modifications for Trace Scheduling The first change that needs to be made to the algorithm is the structure with which state information is associated. For the basic block algorithm it makes sense to associate this information with each block.
References-found: 2

