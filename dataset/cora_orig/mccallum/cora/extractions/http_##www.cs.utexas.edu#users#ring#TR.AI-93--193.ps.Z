URL: http://www.cs.utexas.edu/users/ring/TR.AI-93--193.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ring/
Root-URL: 
Email: (ring@cs.utexas.edu)  
Title: Sequence Learning with Incremental Higher-Order Neural Networks  
Author: Mark Ring 
Date: January, 1993  93-193  
Address: Austin, Texas 78712  
Affiliation: Department of Computer Sciences University of Texas at Austin  
Pubnum: AI  
Abstract: An incremental, higher-order, non-recurrent neural-network combines two properties found to be useful for sequence learning in neural-networks: higher-order connections and the incremental introduction of new units. The incremental, higher-order neural-network adds higher orders when needed by adding new units that dynamically modify connection weights. The new units modify the weights at the next time-step with information from the previous step. Since a theoretically unlimited number of units can be added to the network, information from the arbitrarily distant past can be brought to bear on each prediction. Temporal tasks can thereby be learned without the use of feedback, in contrast to recurrent neural-networks. Because there are no recurrent connections, training is simple and fast. Experiments have demonstrated speedups of two orders of magnitude over recurrent networks.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jonathan Richard Bachrach. </author> <title> Connectionist Modeling and Control of Finite State Environments. </title> <type> PhD thesis, </type> <institution> Department of Computer and Information Sciences, University of Massachusetts, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: each term is the product of a weight and the output of two units): in i (t + 1) = j k The second-order terms seem to have a notably positive effect on the networks, which have been shown to learn difficult tasks with a small number of training samples <ref> [1, 5, 11] </ref>. The networks are cumbersome, however, having O (n 3 ) weights (where n is the number of neurons), and in order to get good performance, true gradient descent must be done [10, 12], which is also quite cumbersome.
Reference: [2] <author> Axel Cleeremans, David Servan-Schreiber, and James L. McClelland. </author> <title> Finite state automata and simple recurrent networks. </title> <journal> Neural Computation, </journal> <volume> 1(3) </volume> <pages> 372-381, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Traditional first-order, recurrent neural-networks <ref> [2, 3, 9, 10, 12] </ref> can be improved in two notable ways. The first is by adding higher-order connections. The other is by adding units to the network incrementally as learning progresses. Second-order recurrent networks have proven to be very powerful [7]. <p> The results for the recurrent networks are quoted from other sources <ref> [2, 4] </ref>. The mean and/or best performance is shown when available. RTRL is the real-time recurrent learning algorithm [12]. or string, is generated by starting with a B transition and then randomly choosing an arc leading away from the current state until the final state is reached. <p> Note that the current state cannot be determined from the current input alone. An Elman-type recurrent network was able to learn this task after 20,000 string presentations using 15 hidden units <ref> [2] </ref>. (The correctness criteria for the Elman net was slightly more stringent than that described in the previous paragraph.) Recurrent Cascade-Correlation (RCC) was able to learn this task using only two or three hidden units in an average of 25,000 string presentations [4]. <p> Finally, once a bridge across a time-delay is created, it does not generalize to other time-delays. This means that the network would have great difficulty learning the embedded Reber grammar <ref> [2, 4] </ref>, where a variable number of time-steps can occur between the presentation of important information and the moment that the information is eventually used. These four issues are the subject of current research.
Reference: [3] <author> Jeffrey L. Elman. </author> <title> Finding structure in time. </title> <type> CRL Technical Report 8801, </type> <institution> University of California, San Diego, Center for Research in Language, </institution> <month> April </month> <year> 1988. </year>
Reference-contexts: 1 Introduction Traditional first-order, recurrent neural-networks <ref> [2, 3, 9, 10, 12] </ref> can be improved in two notable ways. The first is by adding higher-order connections. The other is by adding units to the network incrementally as learning progresses. Second-order recurrent networks have proven to be very powerful [7].
Reference: [4] <author> Scott E. Fahlman. </author> <title> The recurrent cascade-correlation architecture. </title> <editor> In R. P. Lippmann, J. E. Moody, and D. S. Touretzky, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 3, </booktitle> <pages> pages 190-196, </pages> <address> San Mateo, California, 1991. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: A different method for getting good performance in a recurrent neural-network is to add new units during training in order to minimize error. This is done by Fahlman's Recurrent Cascade Correlation (RCC) algorithm <ref> [4] </ref>. In the RCC network, a pool of units are trained to predict the network's error, and the best is then added as a hidden unit into the network. The new unit's weights are frozen and training for the next unit begins. <p> The results for the recurrent networks are quoted from other sources <ref> [2, 4] </ref>. The mean and/or best performance is shown when available. RTRL is the real-time recurrent learning algorithm [12]. or string, is generated by starting with a B transition and then randomly choosing an arc leading away from the current state until the final state is reached. <p> after 20,000 string presentations using 15 hidden units [2]. (The correctness criteria for the Elman net was slightly more stringent than that described in the previous paragraph.) Recurrent Cascade-Correlation (RCC) was able to learn this task using only two or three hidden units in an average of 25,000 string presentations <ref> [4] </ref>. The incremental, higher-order network was trained on a continuous stream of input: the network was not reset before beginning a new string. Training was considered to be complete only after the network had correctly classified 100 strings in a row. <p> Finally, once a bridge across a time-delay is created, it does not generalize to other time-delays. This means that the network would have great difficulty learning the embedded Reber grammar <ref> [2, 4] </ref>, where a variable number of time-steps can occur between the presentation of important information and the moment that the information is eventually used. These four issues are the subject of current research.
Reference: [5] <author> C. L. Giles, C. B. Miller, D. Chen, G. Z. Sun, H. H. Chen, and Y. C. Lee. </author> <title> Extracting and learning an unknown grammar with recurrent neural networks. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 317-324, </pages> <address> San Mateo, California, 1992. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: each term is the product of a weight and the output of two units): in i (t + 1) = j k The second-order terms seem to have a notably positive effect on the networks, which have been shown to learn difficult tasks with a small number of training samples <ref> [1, 5, 11] </ref>. The networks are cumbersome, however, having O (n 3 ) weights (where n is the number of neurons), and in order to get good performance, true gradient descent must be done [10, 12], which is also quite cumbersome.
Reference: [6] <author> Michael C. Mozer. </author> <title> Induction of multiscale temporal structure. </title> <editor> In John E. Moody, Steven J. Hanson, and Richard P. Lippmann, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 275-282, </pages> <address> San Mateo, California, 1992. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: The parameter settings were: = 0:04; = 0:08; fi = 1:0; * = 0:1 and Bias = 0:0. (The network seemed to perform better with no bias unit.) The network has also been tested on the "variable gap" tasks introduced by Mozer <ref> [6] </ref>, as shown in are alternately presented to the network. Each sequence begins with an X or a Y and is followed by a fixed string of characters with an X or a Y inserted some number of time-steps from the beginning. <p> The length of the gap can be increased in order to create tasks of greater difficulty. Results of the "gap" tasks are given in Table 2. The values for the standard recurrent network and for Mozer's own variation are quoted from Mozer's paper <ref> [6] </ref>. Mozer reported results for gaps up to ten, and he also stated that the network had scaled linearly even up to gaps of 25. The incremental higher-order net was tested on gaps up to 24. The training string was composed of the letters of the alphabet in order. <p> Net Higher-Order Net 2 468 328 4 10 6 9830 992 8 19 10 &gt; 10000 1630 12 27 24 26 49 Table 2: The incremental higher-order network is compared on the "variable gap" task against a standard recurrent network [10] and a network devised specifically for learning long time-delays <ref> [6] </ref>. The comparison values are quoted from Mozer [6], who reported results for gaps up to ten. 10 was considered to have correctly predicted an element in the sequence if the most strongly activated output unit was the unit corresponding to the correct prediction. <p> 6 9830 992 8 19 10 &gt; 10000 1630 12 27 24 26 49 Table 2: The incremental higher-order network is compared on the "variable gap" task against a standard recurrent network [10] and a network devised specifically for learning long time-delays <ref> [6] </ref>. The comparison values are quoted from Mozer [6], who reported results for gaps up to ten. 10 was considered to have correctly predicted an element in the sequence if the most strongly activated output unit was the unit corresponding to the correct prediction.
Reference: [7] <author> Jordan B. Pollack. </author> <title> The induction of dynamical recognizers. </title> <journal> Machine Learning, </journal> <volume> 7 </volume> <pages> 227-252, </pages> <year> 1991. </year>
Reference-contexts: 1 Introduction Traditional first-order, recurrent neural-networks [2, 3, 9, 10, 12] can be improved in two notable ways. The first is by adding higher-order connections. The other is by adding units to the network incrementally as learning progresses. Second-order recurrent networks have proven to be very powerful <ref> [7] </ref>.
Reference: [8] <author> Mark B. </author> <title> Ring. Incremental development of complex behaviors through automatic construction of sensory-motor hierarchies. </title> <editor> In Lawrence A. Birnbaum and Gregg C. Collins, editors, </editor> <booktitle> Machine Learning: Proceedings of the Eighth International Workshop (ML91), </booktitle> <pages> pages 343-347. </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <month> June </month> <year> 1991. </year>
Reference-contexts: The incremental, higher-order network presented here combines advantages of both of these approaches, but it does so in a non-recurrent network. This network (a simplified, continuous version of that introduced in <ref> [8] </ref>), adds higher orders when they are needed by the system to solve its task. This is done by adding new units that dynamically modify connection weights.
Reference: [9] <author> A. J. Robinson and F. Fallside. </author> <title> The utility driven dynamic error propagation network. </title> <type> Technical Report CUED/F-INFENG/TR.1, </type> <institution> Cambridge University Engineering Department, </institution> <year> 1987. </year>
Reference-contexts: 1 Introduction Traditional first-order, recurrent neural-networks <ref> [2, 3, 9, 10, 12] </ref> can be improved in two notable ways. The first is by adding higher-order connections. The other is by adding units to the network incrementally as learning progresses. Second-order recurrent networks have proven to be very powerful [7].
Reference: [10] <author> D. E. Rumelhart, G. E. Hinton, and R. J. Williams. </author> <title> Learning internal representations by error propagation. </title> <editor> In D. E. Rumelhart and J. L. McClelland, editors, </editor> <booktitle> Parallel Distributed Processing: Explorations in the Microstructure of Cognition. V1: Foundations. </booktitle> <publisher> MIT Press, </publisher> <year> 1986. </year>
Reference-contexts: 1 Introduction Traditional first-order, recurrent neural-networks <ref> [2, 3, 9, 10, 12] </ref> can be improved in two notable ways. The first is by adding higher-order connections. The other is by adding units to the network incrementally as learning progresses. Second-order recurrent networks have proven to be very powerful [7]. <p> The networks are cumbersome, however, having O (n 3 ) weights (where n is the number of neurons), and in order to get good performance, true gradient descent must be done <ref> [10, 12] </ref>, which is also quite cumbersome. A different method for getting good performance in a recurrent neural-network is to add new units during training in order to minimize error. This is done by Fahlman's Recurrent Cascade Correlation (RCC) algorithm [4]. <p> by Gap Standard Mozer Incremental Incremental Recurrent Net Net Higher-Order Net Higher-Order Net 2 468 328 4 10 6 9830 992 8 19 10 &gt; 10000 1630 12 27 24 26 49 Table 2: The incremental higher-order network is compared on the "variable gap" task against a standard recurrent network <ref> [10] </ref> and a network devised specifically for learning long time-delays [6].
Reference: [11] <author> Raymond L. Watrous and Gary M. Kuhn. </author> <title> Induction of finite-state languages using second-order recurrent networks. </title> <editor> In J. E. Moody, S. J. Hanson, and R. P. Lippman, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 4, </booktitle> <pages> pages 309-316, </pages> <address> San Mateo, California, 1992. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: each term is the product of a weight and the output of two units): in i (t + 1) = j k The second-order terms seem to have a notably positive effect on the networks, which have been shown to learn difficult tasks with a small number of training samples <ref> [1, 5, 11] </ref>. The networks are cumbersome, however, having O (n 3 ) weights (where n is the number of neurons), and in order to get good performance, true gradient descent must be done [10, 12], which is also quite cumbersome.
Reference: [12] <author> Ronald J. Williams and David Zipser. </author> <title> A learning algorithm for continually running fully recurrent neural networks. </title> <journal> Neural Computation, </journal> <volume> 1(2) </volume> <pages> 270-280, </pages> <year> 1989. </year>
Reference-contexts: 1 Introduction Traditional first-order, recurrent neural-networks <ref> [2, 3, 9, 10, 12] </ref> can be improved in two notable ways. The first is by adding higher-order connections. The other is by adding units to the network incrementally as learning progresses. Second-order recurrent networks have proven to be very powerful [7]. <p> The networks are cumbersome, however, having O (n 3 ) weights (where n is the number of neurons), and in order to get good performance, true gradient descent must be done <ref> [10, 12] </ref>, which is also quite cumbersome. A different method for getting good performance in a recurrent neural-network is to add new units during training in order to minimize error. This is done by Fahlman's Recurrent Cascade Correlation (RCC) algorithm [4]. <p> The results for the recurrent networks are quoted from other sources [2, 4]. The mean and/or best performance is shown when available. RTRL is the real-time recurrent learning algorithm <ref> [12] </ref>. or string, is generated by starting with a B transition and then randomly choosing an arc leading away from the current state until the final state is reached.
Reference: [13] <author> Mike Wynn-Jones. </author> <title> Node splitting: A constructive algorithm for feed-forward neural networks. </title> <journal> Neural Computing and Applications, </journal> <volume> 1(1) </volume> <pages> 17-22, </pages> <year> 1993. </year> <month> 12 </month>
Reference-contexts: A related method for adding new units, but in feed-forward neural-networks, was introduced by Wynne-Jones <ref> [13] </ref>. When a new unit is added, its incoming weights are initially zero. It has no output weights but simply learns to anticipate and reduce the error at each time-step of the weight it modifies.
References-found: 13

