URL: ftp://ftp.cs.colorado.edu/pub/HPSC/LabManualChap5.ps.Z
Refering-URL: http://www.cs.colorado.edu/current/courses/materials.hpsc.html
Root-URL: http://www.cs.colorado.edu
Note: Lab 5 Intel iPSC/2 Performance 1 5.1 Introduction 109  
Abstract: In this chapter you will be concerned with timing some simple operations on the Intel hypercube, the iPSC/2. Before doing the work in this chapter, you should read the book chapter [Jessup 95a] and the handouts [Jessup 95c] and [Jessup 95b]. Some other useful references are the User's Guide [Int 91b] and the Programmers Reference Manual [Int 91a]. The iPSC/2 is an example of a distributed memory, MIMD, parallel computer. It uses message passing for sharing data between processors. You will learn how to use some of the basic communication operations: "send" for sending data from a processor to one or more other processors and "receive" for a processor to receive data from one or more other processors. You will also learn how to use global operations such as "global sum" by which the sum of numbers from different processors is computed in parallel and the result returned to every processor. Timing experiments will show you that the arithmetic operation time is short compared with the time required for operations that require communication between processors, such as send, receive, and global sum. Thus, a high ratio of arithmetic operations to communication operations is required if communication is not to be a bottleneck. The next section begins with a brief explanation of how to use our iPSC/2, and following it we consider three examples that illustrate important features of the iPSC/2 and its programs. After that we time the basic arithmetic 
Abstract-found: 1
Intro-found: 0
Reference: [Int 91a] <institution> Intel Corporation, Beaverton, Oregon. </institution> <month> [Apr </month> <year> 1991]. </year> <title> iPSC/2 and iPSC860 Programmer's Reference Manual. Order number: </title> <type> 311708-004. </type>
Reference-contexts: Before doing the work in this chapter, you should read the book chapter [Jessup 95a] and the handouts [Jessup 95c] and [Jessup 95b]. Some other useful references are the User's Guide [Int 91b] and the Programmers Reference Manual <ref> [Int 91a] </ref>. The iPSC/2 is an example of a distributed memory, MIMD, parallel computer. It uses message passing for sharing data between processors. <p> from Exercise 5.6.2 to create host and node programs for the double-precision saxpy operation: z i = a fi x i + y i ; i = 1; 2; : : :; n: (5.5) For this you need to use the global concatenate operation, GCOLX: see the Programmers Reference Manual <ref> [Int 91a] </ref> or the book chapter [Jessup 95a]. Use this program to time the double-precision saxpy operation on cubes of various sizes. Use the same vector lengths and cube sizes as in the dot product exercise, Exercise 5.6.2.
Reference: [Int 91b] <institution> Intel Corporation, Beaverton, Oregon. </institution> <month> [Apr </month> <year> 1991]. </year> <title> iPSC/2 and iPSC/860 User's Guide. Order number: </title> <type> 311532-007. </type>
Reference-contexts: Before doing the work in this chapter, you should read the book chapter [Jessup 95a] and the handouts [Jessup 95c] and [Jessup 95b]. Some other useful references are the User's Guide <ref> [Int 91b] </ref> and the Programmers Reference Manual [Int 91a]. The iPSC/2 is an example of a distributed memory, MIMD, parallel computer. It uses message passing for sharing data between processors.
Reference: [Jessup 95a] <author> JESSUP, ELIZABETH R. </author> <year> [1995]. </year> <title> Distributed-memory MIMD computing: An introduction. </title> <booktitle> HPSC Course Notes. </booktitle>
Reference-contexts: 5.1 Introduction In this chapter you will be concerned with timing some simple operations on the Intel hypercube, the iPSC/2. Before doing the work in this chapter, you should read the book chapter <ref> [Jessup 95a] </ref> and the handouts [Jessup 95c] and [Jessup 95b]. Some other useful references are the User's Guide [Int 91b] and the Programmers Reference Manual [Int 91a]. The iPSC/2 is an example of a distributed memory, MIMD, parallel computer. It uses message passing for sharing data between processors. <p> Here it is used to take a single number from each node, sum this set of numbers, and return the sum to each node. In this case only node 0 used the final result. Because the global operation executes steps of the summation in parallel, it is relatively efficient <ref> [Jessup 95a] </ref>. The global sum operation can also be used to compute the sum of a set of vectors, one from each node but this feature is not used here. * Even distribution of work over the nodes. <p> They are transmitted as a part of the initial message that is sent to establish the route between the sending node and receiving node <ref> [Jessup 95a] </ref>. <p> and node programs for the double-precision saxpy operation: z i = a fi x i + y i ; i = 1; 2; : : :; n: (5.5) For this you need to use the global concatenate operation, GCOLX: see the Programmers Reference Manual [Int 91a] or the book chapter <ref> [Jessup 95a] </ref>. Use this program to time the double-precision saxpy operation on cubes of various sizes. Use the same vector lengths and cube sizes as in the dot product exercise, Exercise 5.6.2. As before plot the rate ( MFLOPS) as a function of vector length for the various cube sizes.
Reference: [Jessup 95b] <author> JESSUP, ELIZABETH R. </author> <year> [1995]. </year> <note> The secrets to happiness on the iPSC/2! HPSC Course Notes. </note>
Reference-contexts: 5.1 Introduction In this chapter you will be concerned with timing some simple operations on the Intel hypercube, the iPSC/2. Before doing the work in this chapter, you should read the book chapter [Jessup 95a] and the handouts [Jessup 95c] and <ref> [Jessup 95b] </ref>. Some other useful references are the User's Guide [Int 91b] and the Programmers Reference Manual [Int 91a]. The iPSC/2 is an example of a distributed memory, MIMD, parallel computer. It uses message passing for sharing data between processors.
Reference: [Jessup 95c] <author> JESSUP, ELIZABETH R. </author> <year> [1995]. </year> <title> Using the iPSC/2 at CU Boulder. </title> <note> HPSC Course Notes. CUBoulder : HPSC Course Notes </note>
Reference-contexts: 5.1 Introduction In this chapter you will be concerned with timing some simple operations on the Intel hypercube, the iPSC/2. Before doing the work in this chapter, you should read the book chapter [Jessup 95a] and the handouts <ref> [Jessup 95c] </ref> and [Jessup 95b]. Some other useful references are the User's Guide [Int 91b] and the Programmers Reference Manual [Int 91a]. The iPSC/2 is an example of a distributed memory, MIMD, parallel computer. It uses message passing for sharing data between processors.
References-found: 5

