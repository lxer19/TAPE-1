URL: http://www.cs.pitt.edu/~kirk/papers/faultschedule.ps
Refering-URL: http://www.cs.pitt.edu/~kirk/papers/index.html
Root-URL: 
Email: kalyan@cs.pitt.edu  kirk@cs.pitt.edu  
Title: Fault-Tolerant Scheduling  
Author: Bala Kalyanasundaram Kirk R. Pruhs 
Note: Supported in part by NSF under grant CCR-9202158. Supported in part by NSF under grant CCR-9209283.  
Address: Pittsburgh  Pittsburgh  
Affiliation: Computer Science Department University of  Computer Science Department University of  
Abstract: We study fault-tolerant multiprocessor scheduling under the realistic assumption that the occurrence of faults can not be predicted. The goal in these problems is to minimize the delay incurred by the jobs. Since this is an online problem we use competitive analysis to evaluate possible algorithms. For the problems of minimizing the makespan, and minimizing the average completion time (for static release times), we give nonclairvoyant algorithms (both deterministic and randomized) that have provably asymptotically optimal competitive ratios. The main tool used by these algorithms to combat faults is redundancy. We also show that randomization has the same effect as redundancy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> N. Alon and J. H. Spencer, </author> <title> The Probabilistic Method, </title> <publisher> John Wiley & Sons, Inc., </publisher> <year> 1992. </year>
Reference-contexts: Hence by linearity of expectation, E [u (i + 1)] ( 2 ) u (i) : Since u (i+1) is the sum of independent 0/1 valued random variables, the variance of u (i+1) is at most the expected value of u (i + 1) (see <ref> [1] </ref>). <p> j 2` ) n j =2 m8 k big n j j 2 j1 ) n j =2 m8 k j=1 j 2 j1 ) n j =2 1 (3) In the above equation, the first and the second inequality follows since n j k=(2`) and for any j in <ref> [1; `] </ref>, n j m 1. <p> As a consequence, for a 6= b, the covariance Cov [x a ; x b ] 0. For 0=1 random variables x a 's (see <ref> [1] </ref>), Var [ j=1 x j ] E [ j=1 x j ] + a6=b Cov [x a ; x b ] (7) As a consequence, we get Var [ j=1 x j ] E [ j=1 x j ] (8) The product in equation 6 is maximum subject to P
Reference: [2] <author> S. Ben-David, A. Borodin, R. Karp, G. Tardos, and A. Wigderson, </author> <title> "On the Power of Randomization in On-line Algorithms," </title> <journal> Algorithmica, </journal> <volume> 11, </volume> <pages> 2-14, </pages> <year> 1994. </year>
Reference-contexts: We can assume that the optimal value of M was computed by an 1 off-line algorithm with full advance knowledge of all the information about the jobs and the pattern of faults. For randomized algorithms we assume an oblivious adversary <ref> [2] </ref>, that is, the input (length of jobs and where, when and how long fault happens) must be specified in advance, and may not be modified as a result of random events internal to the randomized algorithm. <p> On the other hand, if &gt; m=3, we have that max (2; g (k) ) is in the range <ref> [2; 3] </ref>.
Reference: [3] <author> A. Borodin and R. El-Yaniv, </author> <title> "On Randomization in On-line Computation", </title> <booktitle> Proceedings of IEEE Conference on Computational Complexity, </booktitle> <year> 1996. </year>
Reference-contexts: It is not clear how to formulate an alternative reasonable model that avoids this phenomenon. 2.1.3 Randomized Case Using Yao's technique <ref> [3, 12] </ref>, it suffices to prove the lower bound on the expected competitive ratio of any deterministic algorithm when faults occur according to a fixed probabilistic distribution. We first describe the instance of the input and the probability distribution on the faults. <p> For other cases, OP T is at most the makespan of A. Therefore, E [ makespan of A makespan of OPT ] = (max (log fl m log fl m )). Applying Yao's principle (see <ref> [3] </ref>), it is the case that the competitive ratio (against oblivious adversary) of an online algorithm is not smaller than E [ makespan of A makespan of OPT ]. <p> On the other hand, if &gt; m=3, we have that max (2; g (k) ) is in the range <ref> [2; 3] </ref>.
Reference: [4] <author> T. Cormen, C. Leiserson, and R. Rivest, </author> <title> Introduction to Algorithms, </title> <publisher> MIT Press, </publisher> <year> 1990. </year>
Reference: [5] <author> A. Feldmann, J. Sgall, S. Teng, </author> <title> "Dynamic scheduling on parallel machines", </title> <journal> Theoretical Computer Science, </journal> <volume> 130, </volume> <pages> 49-72, </pages> <year> 1994. </year>
Reference-contexts: We know of no previous theoretical investigations of this kind into fault-tolerant scheduling. Nonclairvoyant scheduling without faults is discussed in <ref> [5, 7, 8, 10] </ref>. In [8] it is shown that with dynamic release times and without faults, a nonclairvoyant deterministic (randomized) algorithm can not be better than (n 1=3 )-competitive ((log n)-competitive), with respect to average completion time, even allowing preemptions.
Reference: [6] <author> R. Graham, E. Lawler, J. Lenstra, and A Rinnooy Kan, </author> <title> "Optimization and approximation in deterministic sequencing and scheduling: a survey", </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 5, 287 - 326, </volume> <year> 1979. </year>
Reference-contexts: 1 Introduction 1.1 Problem Statement The scheduling of tasks in a multiprocessor system has been recognized as an important problem and has been extensively studied (see <ref> [6] </ref> for a survey). In a large multiprocessor system, processor faults are inevitable and fault-tolerance is a significant issue [11]. The vast majority of previous work on scheduling either assumes that there are no faults, or gives minimal analysis.
Reference: [7] <author> T. Matsumoto, </author> <title> "Competitive analysis of the round robin algorithm', </title> <booktitle> International Symposium on Algorithms and Computation, </booktitle> <volume> 71 - 77, </volume> <year> 1992. </year>
Reference-contexts: We know of no previous theoretical investigations of this kind into fault-tolerant scheduling. Nonclairvoyant scheduling without faults is discussed in <ref> [5, 7, 8, 10] </ref>. In [8] it is shown that with dynamic release times and without faults, a nonclairvoyant deterministic (randomized) algorithm can not be better than (n 1=3 )-competitive ((log n)-competitive), with respect to average completion time, even allowing preemptions.
Reference: [8] <author> R. Motwani, S. Phillips, E. Torng, </author> <title> "Non-clairvoyant scheduling", </title> <journal> Theoretical Computer Science, </journal> <volume> 130, </volume> <pages> 17-47, </pages> <year> 1994. </year>
Reference-contexts: be the minimum i such that log (i) 2 x 1, where log (i) 2 is the log function iterated i times. 2 Optimal Competitive Ratios for Identical Processors Makespan Average Completion Time (Static Case) Deterministic Faults Deterministic Randomized and Randomized = 0 fi (1)[10] fi (1) [10] fi (1) <ref> [8] </ref> log ( m log m ; m ; m ) Permanent = *m fi ( log m Permanent &gt; 0 fi (max ( log m ) m )) fi (max (log fl m log fl m m )) fi (max ( Transient The results for no faults come from [10, <p> [8] log ( m log m ; m ; m ) Permanent = *m fi ( log m Permanent &gt; 0 fi (max ( log m ) m )) fi (max (log fl m log fl m m )) fi (max ( Transient The results for no faults come from <ref> [10, 8] </ref>. If one expects that permanent faults are largely independent, then the number of faults is likely to be approximately *m, where the constant * is the probability that a particular processor faults. <p> For no faults, [10] showed a fi (min (log R; log m)) bound on the optimal deterministic competitive ratio, with respect to makespan, in the related processors case. In <ref> [8] </ref> it is implicitly shown that there exists a constant competitive algorithm for minimizing the average completion time in the general related processors case. The result is only explicitly stated for the identical processors case. <p> We know of no previous theoretical investigations of this kind into fault-tolerant scheduling. Nonclairvoyant scheduling without faults is discussed in <ref> [5, 7, 8, 10] </ref>. In [8] it is shown that with dynamic release times and without faults, a nonclairvoyant deterministic (randomized) algorithm can not be better than (n 1=3 )-competitive ((log n)-competitive), with respect to average completion time, even allowing preemptions. <p> We know of no previous theoretical investigations of this kind into fault-tolerant scheduling. Nonclairvoyant scheduling without faults is discussed in [5, 7, 8, 10]. In <ref> [8] </ref> it is shown that with dynamic release times and without faults, a nonclairvoyant deterministic (randomized) algorithm can not be better than (n 1=3 )-competitive ((log n)-competitive), with respect to average completion time, even allowing preemptions.
Reference: [9] <author> D. Sleator, and R. Tarjan, </author> <title> "Amortized efficiency of list update and paging rules", </title> <journal> Communications of the ACM, </journal> <volume> 28, 202 - 208, </volume> <year> 1985. </year>
Reference-contexts: ratio) of a deterministic algorithm for a particular problem and measure M is the supremum over all instances I, of the ratio of the value of M for the schedule produced by the online algorithm given I as input to the optimal value of M for a schedule of I <ref> [9] </ref>. We can assume that the optimal value of M was computed by an 1 off-line algorithm with full advance knowledge of all the information about the jobs and the pattern of faults.
Reference: [10] <author> D. Shmoys, J. Wein, and D. Williamson, </author> <title> "Scheduling parallel machines on-line", </title> <booktitle> Proceedings of IEEE Symposium on Foundations of Computing, </booktitle> <volume> 131 - 140, </volume> <year> 1991. </year>
Reference-contexts: is defined to be the minimum i such that log (i) 2 x 1, where log (i) 2 is the log function iterated i times. 2 Optimal Competitive Ratios for Identical Processors Makespan Average Completion Time (Static Case) Deterministic Faults Deterministic Randomized and Randomized = 0 fi (1)<ref> [10] </ref> fi (1) [10] fi (1) [8] log ( m log m ; m ; m ) Permanent = *m fi ( log m Permanent &gt; 0 fi (max ( log m ) m )) fi (max (log fl m log fl m m )) fi (max ( Transient The results for no faults <p> [8] log ( m log m ; m ; m ) Permanent = *m fi ( log m Permanent &gt; 0 fi (max ( log m ) m )) fi (max (log fl m log fl m m )) fi (max ( Transient The results for no faults come from <ref> [10, 8] </ref>. If one expects that permanent faults are largely independent, then the number of faults is likely to be approximately *m, where the constant * is the probability that a particular processor faults. <p> In the general related processors case, almost all the optimal competitive ratios listed in the table for permanent faults increase by a multiplicative factor of R, where R is the ratio of the speed of the fastest processor to the speed of the slowest processor. For no faults, <ref> [10] </ref> showed a fi (min (log R; log m)) bound on the optimal deterministic competitive ratio, with respect to makespan, in the related processors case. In [8] it is implicitly shown that there exists a constant competitive algorithm for minimizing the average completion time in the general related processors case. <p> We know of no previous theoretical investigations of this kind into fault-tolerant scheduling. Nonclairvoyant scheduling without faults is discussed in <ref> [5, 7, 8, 10] </ref>. In [8] it is shown that with dynamic release times and without faults, a nonclairvoyant deterministic (randomized) algorithm can not be better than (n 1=3 )-competitive ((log n)-competitive), with respect to average completion time, even allowing preemptions. <p> We do so for the ease of analysis, and it is important to observe that the competitive ratio will be off by a factor of at most 2. This doubling idea has been used before, see for example <ref> [10] </ref>. Observe that Geometric Rotary "estimates" the length of a job by running it for a duration of at most 2 i during the ith stage. Based on this estimated length, we calculate a lower bound on the completion time for the o*ine optimal algorithm.
Reference: [11] <editor> J. Vytopil (ed.), </editor> <title> Formal Techniques in Real-time and Fault-tolerant Systems, </title> <publisher> Kluwer Academic Publishers, </publisher> <year> 1993. </year>
Reference-contexts: 1 Introduction 1.1 Problem Statement The scheduling of tasks in a multiprocessor system has been recognized as an important problem and has been extensively studied (see [6] for a survey). In a large multiprocessor system, processor faults are inevitable and fault-tolerance is a significant issue <ref> [11] </ref>. The vast majority of previous work on scheduling either assumes that there are no faults, or gives minimal analysis. In this paper we begin a theoretical investigation of the effect of processor faults on scheduling by considering several standard scheduling problems modified to allow faults. <p> A fault at P j can be classified as either permanent, in which case no more jobs may be run on P j , or transient, in which case P j is inoperative for some finite period of time <ref> [11] </ref>. Note, nonclairvoyant algorithm (a.k.a. online algorithm) detects faults only at the time of their occurrence. <p> We always assume preemption-with-restart. As in most settings where fault-tolerance is an issue, the main tool available to combat faults is redundancy <ref> [11] </ref>. In this setting this generally means running multiple copies of the same job on different processors. 1.2 Results The main results for the case of identical processors and preemption-with-restart are summarized in the table below. <p> This shows that online scheduling algorithms face a much more daunting task when trying to minimize the average completion time of jobs with dynamic release times. For a general survey of fault tolerant scheduling see <ref> [11] </ref>. 2 Makespan 2.1 Lower Bounds We use the following adversary to prove a lower bound on the competitive ratio, with respect to makespan, of any deterministic online algorithm.
Reference: [12] <author> A. Yao, </author> <title> "Probabilistic computations: towards a unified measure of complexity", </title> <booktitle> Proceedings of IEEE Symposium on Foundations of Computing, </booktitle> <volume> 222 - 227, </volume> <year> 1977. </year> <month> 29 </month>
Reference-contexts: It is not clear how to formulate an alternative reasonable model that avoids this phenomenon. 2.1.3 Randomized Case Using Yao's technique <ref> [3, 12] </ref>, it suffices to prove the lower bound on the expected competitive ratio of any deterministic algorithm when faults occur according to a fixed probabilistic distribution. We first describe the instance of the input and the probability distribution on the faults. <p> Theorem 43 With static release times, and related processors, every randomized algorithm is (R m )-competitive with respect to average completion time. 23 Proof: Using Yao's technique <ref> [12] </ref>, it suffices to bound the expected competitive ratio of any deterministic algorithm where the occurrence of fault is selected from some fixed probability distribution. First we assume that m=2. The desired lower bound is (R). There are 3 processors with speed R and m 3 processors with speed 1.
References-found: 12

