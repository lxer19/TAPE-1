URL: ftp://ftp.cs.umd.edu/pub/papers/papers/3383/3383.ps.Z
Refering-URL: http://www.cs.bham.ac.uk/~anp/bibtex/kdd.bib.html
Root-URL: 
Title: FastMap: A Fast Algorithm for Indexing, Data-Mining and Visualization of Traditional and Multimedia Datasets  
Author: Christos Faloutsos King-Ip (David) Lin 
Address: College Park  College Park  
Affiliation: Institute of Systems Research and Dept. of Computer Science Univ. of Maryland,  Dept. of Computer Science Univ. of Maryland,  
Abstract: A very promising idea for fast searching in traditional and multimedia databases is to map objects into points in k-d space, using k feature-extraction functions, provided by a domain expert [Jag91]. Thus, we can subsequently use highly fine-tuned spatial access methods (SAMs), to answer several types of queries, including the `Query By Example' type (which translates to a range query); the `all pairs' query (which translates to a spatial join [BKSS94]); the nearest-neighbor or best-match query, etc. However, designing feature extraction functions can be hard. It is relatively easier for a domain expert to assess the similarity/distance of two objects. Given only the distance information though, it is not obvious how to map objects into points. This is exactly the topic of this paper. We describe a fast algorithm to map objects into points in some k-dimensional space (k is user-defined), such that the dis-similarities are preserved. There are two benefits from this mapping: (a) efficient retrieval, in conjunction with a SAM, as discussed before and (b) visualization and data-mining: the objects can now be plotted as points in 2-d or 3-d space, revealing potential clusters, correlations among attributes and other regularities that data-mining is looking for. We introduce an older method from pattern recognition, namely, Multi-Dimensional Scaling (MDS) [Tor52]; although unsuitable for indexing, we use it as yardstick for our method. Then, we propose a much faster algorithm to solve the problem in hand, while in addition it allows for indexing. Experiments on real and synthetic data indeed show that the proposed algorithm is significantly faster than MDS, (being linear, as opposed to quadratic, on the database size N ), while it manages to preserve distances and the overall structure of the data-set. 
Abstract-found: 1
Intro-found: 1
Reference: [ACF + 93] <author> Manish Arya, William Cody, Christos Faloutsos, Joel Richardson, and Arthur Toga. Qbism: </author> <title> a prototype 3-d medical image database system. </title> <journal> IEEE Data Engineering Bulletin, </journal> <volume> 16(1) </volume> <pages> 38-42, </pages> <month> March </month> <year> 1993. </year>
Reference-contexts: Once the similarity (or dis-similarity) function has been determined, our proposed method can be immediately applied. * Medical databases, where 1-d objects (eg., ECGs), 2-d images (eg., X-rays) and 3-d images (eg., MRI brain scans) <ref> [ACF + 93] </ref> are stored. Ability to retrieve quickly past cases with similar symptoms would be valuable for diagnosis, as well as for medical teaching and research purposes.
Reference: [AFS93] <author> Rakesh Agrawal, Christos Faloutsos, and Arun Swami. </author> <title> Efficient similarity search in sequence databases. </title> <booktitle> In Foundations of Data Organization and Algorithms (FODO) Conference, </booktitle> <address> Evanston, Illinois, </address> <month> October </month> <year> 1993. </year> <note> also available through anonymous ftp, from olympos.cs.umd.edu: ftp/pub/TechReports/fodo.ps. </note>
Reference-contexts: The goal is to aid forecasting, by examining similar patterns that may have appeared in the past. In <ref> [AFS93] </ref> we used the Euclidean distance (sum of squared errors) as the distance function between two time series. * Similarity searching in string databases, as in the case of spelling, typing [Kuk92] and OCR error correction [JSB91].
Reference: [AGM + 90] <author> S.F. Altschul, W. Gish, W. Miller, </author> <title> E.W. Myers, and D.J. Lipman. A basic local alignment search tool. </title> <journal> Journal of Molecular Biology, </journal> <volume> 215(3) </volume> <pages> 403-410, </pages> <year> 1990. </year>
Reference-contexts: Conceptually identical is the case of approximate matching in DNA databases, where there is a large collection of strings from a four-letter alphabet (A,G,C,T); a new string has to be matched against the old strings, to find the best candidates <ref> [AGM + 90] </ref>. In all these applications, the distance is typically the editing distance ie., minimum number of insertions, deletions or substitutions that are needed to transform the first string to the second. * Data mining [AS94], [AIS93] and visualization applications.
Reference: [AIS93] <author> Rakesh Agrawal, Tomasz Imielinski, and Arun Swami. </author> <title> Mining association rules between sets of items in large databases. </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> pages 207-216, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: In all these applications, the distance is typically the editing distance ie., minimum number of insertions, deletions or substitutions that are needed to transform the first string to the second. * Data mining [AS94], <ref> [AIS93] </ref> and visualization applications. For example, given records of patients (with attributes like gender, age, blood-pressure etc.), we would like to help the physician detect any clusters, or correlations among symptoms, demographic data and diseases.
Reference: [AS94] <author> Rakesh Agrawal and Ramakrishnan Srikant. </author> <title> Fast algorithms for mining association rules in large databases. </title> <booktitle> Proc. of VLDB Conf., </booktitle> <pages> pages 487-499, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: In all these applications, the distance is typically the editing distance ie., minimum number of insertions, deletions or substitutions that are needed to transform the first string to the second. * Data mining <ref> [AS94] </ref>, [AIS93] and visualization applications. For example, given records of patients (with attributes like gender, age, blood-pressure etc.), we would like to help the physician detect any clusters, or correlations among symptoms, demographic data and diseases.
Reference: [BK73] <author> W.A. Burkhard and R.M. Keller. </author> <title> Some approaches to best-match file searching. </title> <journal> Comm. of the ACM (CACM), </journal> <volume> 16(4) </volume> <pages> 230-236, </pages> <month> April </month> <year> 1973. </year>
Reference-contexts: There are also retrieval methods for the case where only the triangular inequality holds <ref> [BK73] </ref>, [Sha77], [SW90], [BYCMW94]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query. However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization.
Reference: [BKS93] <author> Thomas Brinkhoff, Hans-Peter Kriegel, and Bernhard Seeger. </author> <title> Efficient processing of spatial joins using r-trees. </title> <booktitle> Proc. of ACM SIGMOD, </booktitle> <pages> pages 237-246, </pages> <month> May </month> <year> 1993. </year>
Reference-contexts: Mapping objects into points has the following two applications. Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins <ref> [BKS93, BKSS94] </ref>, nearest neighbor queries etc.), because several, highly optimized spatial access methods are readily available (R-trees [Gut84], R fl -trees [BKSS90] etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [BKSS90] <author> N. Beckmann, H.-P. Kriegel, R. Schneider, and B. Seeger. </author> <title> The r*-tree: an efficient and robust access method for points and rectangles. </title> <booktitle> ACM SIGMOD, </booktitle> <pages> pages 322-331, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: Such a mapping provides two major benefits: 1. It can accelerate the search time for queries. The reason is that we can employ highly fine-tuned Spatial Access Methods (SAMs), like the R fl -trees <ref> [BKSS90] </ref> and the z-ordering [Ore86]. <p> The most popular methods form three classes: (a) tree-based methods like the R-tree [Gut84], and its variants (R + -tree [SRF87], hB-tree [LS90], P-tree [Jag90a], R fl -tree <ref> [BKSS90] </ref>, Hilbert R-trees [KF94] 6 Symbols Definitions. <p> Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins [BKS93, BKSS94], nearest neighbor queries etc.), because several, highly optimized spatial access methods are readily available (R-trees [Gut84], R fl -trees <ref> [BKSS90] </ref> etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [BKSS94] <author> Thomas Brinkhoff, Hans-Peter Kriegel, Ralf Schneider, and Bernhard Seeger. </author> <title> Multi-step processing of spatial joins. </title> <booktitle> ACM SIGMOD, </booktitle> <pages> pages 197-208, </pages> <month> May </month> <year> 1994. </year>
Reference-contexts: It can accelerate the search time for queries. The reason is that we can employ highly fine-tuned Spatial Access Methods (SAMs), like the R fl -trees [BKSS90] and the z-ordering [Ore86]. These methods provide fast searching for range queries as well as spatial joins <ref> [BKSS94] </ref>. 2. it can help with visualization, clustering and data-mining: Plotting objects as points in k=2 or 3 dimensions can reveal much of the structure of the dataset, such as the existence of major clusters, the general shape of the distribution (linear versus curvilinear versus Gaussian) etc.. <p> Mapping objects into points has the following two applications. Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins <ref> [BKS93, BKSS94] </ref>, nearest neighbor queries etc.), because several, highly optimized spatial access methods are readily available (R-trees [Gut84], R fl -trees [BKSS90] etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [BYCMW94] <author> Ricardo A. Baeza-Yates, Walter Cunto, Udi Manber, and Sun Wu. </author> <title> Proximity matching using fixed queries trees. </title> <editor> In M. Crochemore and D. Gusfield, editors, </editor> <booktitle> 5th Combinatorial Pattern Matching, </booktitle> <volume> LNCS 807, </volume> <pages> pages 198-212. </pages> <publisher> Springer-Verlag, </publisher> <address> Asilomar, CA, </address> <month> June </month> <year> 1994. </year> <month> 22 </month>
Reference-contexts: There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], [SW90], <ref> [BYCMW94] </ref>. All these methods try to exploit the triangular inequality in order to prune the search space on a range query. However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization.
Reference: [CoPES92] <institution> Mathematical Committee on Physical and NSF Engineering Sciences. Grand Challenges: High Performance Computing and Communications. National Science Foundation, </institution> <year> 1992. </year> <booktitle> The FY 1992 U.S. Research and Development Program. </booktitle>
Reference-contexts: This warping makes it difficult to find features that would adequately describe each image (and therefore, map it into a point in feature space). 2 * Time series, with, eg. financial data, such as stock prices, sales numbers etc., or scientific databases, with time series of sensor data, weather <ref> [CoPES92] </ref>, geological, environmental, astrophysics [Vas93] data, etc., In such databases, typical queries would be `find companies whose stock prices move similarly', or `find past days in which the solar magnetic wind showed patterns similar to today's pattern' [Vas93].
Reference: [DH73] <author> R.O. Duda and P.E. Hart. </author> <title> Pattern Classification and Scene Analysis. </title> <publisher> Wiley, </publisher> <address> New York, </address> <year> 1973. </year>
Reference-contexts: The optimal way to map n-dimensional points to k-dimensional points (k n) is the Karhunen-Loeve (`K-L') transform (eg., see <ref> [DH73] </ref>, [Fuk90]).
Reference: [Dum94] <author> Susan T. Dumais. </author> <title> Latent semantic indexing (LSI) and TREC-2. </title> <editor> In D. K. Harman, editor, </editor> <booktitle> The Second Text Retrieval Conference (TREC-2), </booktitle> <pages> pages 105-115, </pages> <address> Gaithersburg, MD, </address> <month> March </month> <year> 1994. </year> <note> NIST. Special Publication 500-215. </note>
Reference-contexts: the K-L transform suffers from two drawbacks: * it can not be applied at all on the `distance' case * even in the `features' case, it may be slow for large databases (N 1) with many attributes (n 1) The latter situation appears, eg., in information retrieval and filtering [FD92], <ref> [Dum94] </ref>, where documents correspond to V -dimensional vectors (V being the vocabulary size of the collection, typically in the tens of thousands).
Reference: [FD92] <author> Peter W. Foltz and Susan T. Dumais. </author> <title> Personalized information delivery: an analysis of information filtering methods. </title> <journal> Comm. of ACM (CACM), </journal> <volume> 35(12) </volume> <pages> 51-60, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: However, the K-L transform suffers from two drawbacks: * it can not be applied at all on the `distance' case * even in the `features' case, it may be slow for large databases (N 1) with many attributes (n 1) The latter situation appears, eg., in information retrieval and filtering <ref> [FD92] </ref>, [Dum94], where documents correspond to V -dimensional vectors (V being the vocabulary size of the collection, typically in the tens of thousands).
Reference: [FR89] <author> C. Faloutsos and S. Roseman. </author> <title> Fractals for secondary key retrieval. </title> <booktitle> Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems (PODS), </booktitle> <pages> pages 247-252, </pages> <month> March </month> <year> 1989. </year> <note> also available as UMIACS-TR-89-47 and CS-TR-2242. </note>
Reference-contexts: fl) the distance function between two objects jj~xjj 2 the length (= L 2 norm) of vector ~x (AB) the length of the line segment AB Table 1: Summary of Symbols and Definitions etc.) (b) methods using linear quadtrees [Gar82] or, equivalently, the z-ordering [Ore86, Ore90], or other space-filling curves <ref> [FR89, Jag90b] </ref> and finally (c) methods that use grid-files [NHS84, HN83]. There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], [SW90], [BYCMW94]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query.
Reference: [Fuk90] <author> Keinosuke Fukunaga. </author> <title> Introduction to Statistical Pattern Recognition. </title> <publisher> Academic Press, </publisher> <year> 1990. </year> <note> 2nd Edition. </note>
Reference-contexts: The optimal way to map n-dimensional points to k-dimensional points (k n) is the Karhunen-Loeve (`K-L') transform (eg., see [DH73], <ref> [Fuk90] </ref>). <p> error, where the error is the distance between each n-d point and its k-d image. transform suggests: If we are allowed only k=1, the best direction to project on is the direction of x 0 ; the next best is y 0 etc. `K-L' is often used in pattern matching <ref> [Fuk90] </ref> to choose the most important features (actually, linear combinations of features), for a given set of vectors. It computes the eigenvectors of the covariance matrix, sorts them in decreasing eigenvalue order, and approximates each data vector with its projections on the first k eigenvectors.
Reference: [Gar82] <author> I. </author> <title> Gargantini. An effective way to represent quadtrees. </title> <journal> Comm. of ACM (CACM), </journal> <volume> 25(12) </volume> <pages> 905-910, </pages> <month> December </month> <year> 1982. </year>
Reference-contexts: space (`features' case only) k dimensionality of `target space' D (fl; fl) the distance function between two objects jj~xjj 2 the length (= L 2 norm) of vector ~x (AB) the length of the line segment AB Table 1: Summary of Symbols and Definitions etc.) (b) methods using linear quadtrees <ref> [Gar82] </ref> or, equivalently, the z-ordering [Ore86, Ore90], or other space-filling curves [FR89, Jag90b] and finally (c) methods that use grid-files [NHS84, HN83]. There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], [SW90], [BYCMW94].
Reference: [Gut84] <author> A. Guttman. R-trees: </author> <title> a dynamic index structure for spatial searching. </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> pages 47-57, </pages> <month> June </month> <year> 1984. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree <ref> [Gut84] </ref>, and its variants (R + -tree [SRF87], hB-tree [LS90], P-tree [Jag90a], R fl -tree [BKSS90], Hilbert R-trees [KF94] 6 Symbols Definitions. <p> Mapping objects into points has the following two applications. Firstly, it can accelerate searching for several types of queries (`query-by-example' or `range' queries, `all pairs' queries or spatial joins [BKS93, BKSS94], nearest neighbor queries etc.), because several, highly optimized spatial access methods are readily available (R-trees <ref> [Gut84] </ref>, R fl -trees [BKSS90] etc.). Secondly, such a mapping is useful for data-mining, cluster analysis and visualization of a high-dimensionality dataset.
Reference: [GV89] <author> G. H. Golub and C. F. Van Loan. </author> <title> Matrix Computations. </title> <publisher> The Johns Hopkins University Press, </publisher> <address> Baltimore, </address> <note> second edition, </note> <year> 1989. </year>
Reference-contexts: It computes the eigenvectors of the covariance matrix, sorts them in decreasing eigenvalue order, and approximates each data vector with its projections on the first k eigenvectors. The operation is closely related to the Singular Value Decomposition (SVD) <ref> [Str80, PFTV88, GV89] </ref> of the object-feature matrix. Appendix A gives our implementation of the K-L transform in Mathematica [Wol91].
Reference: [Har75] <author> John A. Hartigan. </author> <title> Clustering Algorithms. </title> <publisher> John Wiley & Sons, </publisher> <year> 1975. </year>
Reference-contexts: However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization. Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., [Mur83], <ref> [Har75] </ref> for surveys, [NH94] for a recent application in GIS, [SM83] [VR79] for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [HN83] <author> K. Hinrichs and J. Nievergelt. </author> <title> The grid file: a data structure to support proximity queries on spatial objects. </title> <booktitle> Proc. of the WG'83 (Intern. Workshop on Graph Theoretic Concepts in Computer Science), </booktitle> <pages> pages 100-113, </pages> <year> 1983. </year>
Reference-contexts: the length (= L 2 norm) of vector ~x (AB) the length of the line segment AB Table 1: Summary of Symbols and Definitions etc.) (b) methods using linear quadtrees [Gar82] or, equivalently, the z-ordering [Ore86, Ore90], or other space-filling curves [FR89, Jag90b] and finally (c) methods that use grid-files <ref> [NHS84, HN83] </ref>. There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], [SW90], [BYCMW94]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query.
Reference: [Jag90a] <author> H. V. Jagadish. </author> <title> Spatial search with polyhedra. </title> <booktitle> Proc. Sixth IEEE Int'l Conf. on Data Engineering, </booktitle> <month> February </month> <year> 1990. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [Gut84], and its variants (R + -tree [SRF87], hB-tree [LS90], P-tree <ref> [Jag90a] </ref>, R fl -tree [BKSS90], Hilbert R-trees [KF94] 6 Symbols Definitions.
Reference: [Jag90b] <author> H.V. Jagadish. </author> <title> Linear clustering of objects with multiple attributes. </title> <booktitle> ACM SIGMOD Conf., </booktitle> <pages> pages 332-342, </pages> <month> May </month> <year> 1990. </year>
Reference-contexts: fl) the distance function between two objects jj~xjj 2 the length (= L 2 norm) of vector ~x (AB) the length of the line segment AB Table 1: Summary of Symbols and Definitions etc.) (b) methods using linear quadtrees [Gar82] or, equivalently, the z-ordering [Ore86, Ore90], or other space-filling curves <ref> [FR89, Jag90b] </ref> and finally (c) methods that use grid-files [NHS84, HN83]. There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], [SW90], [BYCMW94]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query.
Reference: [Jag91] <author> H.V. Jagadish. </author> <title> A retrieval technique for similar shapes. </title> <booktitle> Proc. ACM SIGMOD Conf., </booktitle> <pages> pages 208-217, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: 1 Introduction The objective of this work is to provide a retrieval and visualization tool for large collections of traditional as well as `exotic' and multimedia datasets. An excellent idea, suggested by Jagadish <ref> [Jag91] </ref>, was to fl This work was partially supported by the National Science Foundation (IRI-8958546 and IRI-9205273), with matching funds from Empress Software Inc. and Thinking Machines Inc. 1 rely on domain experts to derive k feature-extraction functions, thus mapping each object into a point in k-dimensional space. <p> Some of the applications that motivated the present work are listed next. Some distance functions are also described. * Image and, in general, multimedia databases: In a collection of shapes <ref> [Jag91] </ref> we would like to find shapes similar to a give one; in a collection of color images, we would like to find images with similar colors, shapes or texture [NBE + 93]. <p> In an earlier approach for similarity searching in non-traditional/multimedia databases <ref> [Jag91] </ref>, a domain expert was expected to provide feature extraction functions. Thanks to the proposed `FastMap' algorithm, the domain expert need only provide a distance function, from which our algorithm will infer the appropriate features for each object. Mapping objects into points has the following two applications.
Reference: [JSB91] <author> Mark A. Jones, Guy A. Story, and Bruce W. Ballard. </author> <title> Integrating multiple knowledge sources in a bayesian ocr post-processor. </title> <booktitle> In First International Conference on Document Analysis and Recognition, </booktitle> <address> Saint-Malo, France, </address> <month> September </month> <year> 1991. </year> <note> to appear. </note>
Reference-contexts: In [AFS93] we used the Euclidean distance (sum of squared errors) as the distance function between two time series. * Similarity searching in string databases, as in the case of spelling, typing [Kuk92] and OCR error correction <ref> [JSB91] </ref>. There, given a wrong string, we should search a dictionary to find the closest strings to it.
Reference: [KF94] <author> Ibrahim Kamel and Christos Faloutsos. Hilbert r-tree: </author> <title> an improved r-tree using fractals. </title> <booktitle> In Proc. of VLDB Conference,, </booktitle> <pages> pages 500-509, </pages> <address> Santiago, Chile, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [Gut84], and its variants (R + -tree [SRF87], hB-tree [LS90], P-tree [Jag90a], R fl -tree [BKSS90], Hilbert R-trees <ref> [KF94] </ref> 6 Symbols Definitions.
Reference: [Kru64] <author> Joseph B. Kruskal. </author> <title> Nonmetric multidimensional scaling. </title> <journal> Psychometrika, </journal> <volume> 29 </volume> <pages> 1-27, </pages> <year> 1964. </year> <month> 23 </month>
Reference-contexts: The above version of MDS is called metric multidimensional scaling [Tor52], because the distances are given as numbers. Several generalizations and extensions have been proposed to the above basic algorithm: Kruskal [KW78] proposed a method that automatically determines a good value for k; Shepard [She62], and Kruskal <ref> [Kru64] </ref> proposed the non-metric MDS where the distance between items are specified qualitatively; Young [You87] describes the individual difference MDS, which incorporates multiple distance measures, corresponding to different observers' perception of the data's difference.
Reference: [Kuk92] <author> Karen Kukich. </author> <title> Techniques for automatically correcting words in text. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(4) </volume> <pages> 377-440, </pages> <month> December </month> <year> 1992. </year>
Reference-contexts: The goal is to aid forecasting, by examining similar patterns that may have appeared in the past. In [AFS93] we used the Euclidean distance (sum of squared errors) as the distance function between two time series. * Similarity searching in string databases, as in the case of spelling, typing <ref> [Kuk92] </ref> and OCR error correction [JSB91]. There, given a wrong string, we should search a dictionary to find the closest strings to it.
Reference: [KW78] <author> Joseph B. Kruskal and Myron Wish. </author> <title> Multidimensional scaling. </title> <publisher> SAGE publications, </publisher> <address> Beverly Hills, </address> <year> 1978. </year>
Reference-contexts: There are several variations, but the basic method (eg., see <ref> [KW78] </ref>) is described next. Following the `distance' case setting, the method expects (a) a set of N items, (b) their pair-wise (dis)similarities and (c) the desirable dimensionality k. <p> The above version of MDS is called metric multidimensional scaling [Tor52], because the distances are given as numbers. Several generalizations and extensions have been proposed to the above basic algorithm: Kruskal <ref> [KW78] </ref> proposed a method that automatically determines a good value for k; Shepard [She62], and Kruskal [Kru64] proposed the non-metric MDS where the distance between items are specified qualitatively; Young [You87] describes the individual difference MDS, which incorporates multiple distance measures, corresponding to different observers' perception of the data's difference.
Reference: [LS90] <author> David B. Lomet and Betty Salzberg. </author> <title> The hb-tree: a multiattribute indexing method with good guaranteed performance. </title> <journal> ACM TODS, </journal> <volume> 15(4) </volume> <pages> 625-658, </pages> <month> December </month> <year> 1990. </year>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [Gut84], and its variants (R + -tree [SRF87], hB-tree <ref> [LS90] </ref>, P-tree [Jag90a], R fl -tree [BKSS90], Hilbert R-trees [KF94] 6 Symbols Definitions.
Reference: [Mur83] <author> F. Murtagh. </author> <title> A survey of recent advances in hierarchical clustering algorithms. </title> <journal> The Computer Journal, </journal> <volume> 26(4) </volume> <pages> 354-359, </pages> <year> 1983. </year>
Reference-contexts: However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization. Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., <ref> [Mur83] </ref>, [Har75] for surveys, [NH94] for a recent application in GIS, [SM83] [VR79] for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [NBE + 93] <author> Wayne Niblack, Ron Barber, Will Equitz, Myron Flickner, Eduardo Glasman, Dragutin Petkovic, Peter Yanker, Christos Faloutsos, and Gabriel Taubin. </author> <title> The qbic project: Querying images by content using color, texture and shape. </title> <booktitle> SPIE 1993 Intl. Symposium on Electronic Imaging: Science and Technology, Conf. </booktitle> <year> 1908, </year> <title> Storage and Retrieval for Image and Video Databases, </title> <month> February </month> <year> 1993. </year> <note> Also available as IBM Research Report RJ 9203 (81511), </note> <month> Feb. 1, </month> <year> 1993, </year> <institution> Computer Science. </institution>
Reference-contexts: Some distance functions are also described. * Image and, in general, multimedia databases: In a collection of shapes [Jag91] we would like to find shapes similar to a give one; in a collection of color images, we would like to find images with similar colors, shapes or texture <ref> [NBE + 93] </ref>. There we used the Euclidean distance between appropriately selected feature vectors (color attributes, moments of inertia for shape, etc.) Search-by-content is highly desirable in multimedia databases, with audio (voice, music), video etc. [NC91].
Reference: [NC91] <author> A. Desai Narasimhalu and Stavros Christodoulakis. </author> <title> Multimedia information systems: the unfolding of a reality. </title> <journal> IEEE Computer, </journal> <volume> 24(10) </volume> <pages> 6-8, </pages> <month> October </month> <year> 1991. </year>
Reference-contexts: There we used the Euclidean distance between appropriately selected feature vectors (color attributes, moments of inertia for shape, etc.) Search-by-content is highly desirable in multimedia databases, with audio (voice, music), video etc. <ref> [NC91] </ref>. For example, users might want to retrieve, music scores, or video clips that are similar to a target music score or video clip.
Reference: [NH94] <author> Raymond T. Ng and Jiawei Han. </author> <title> Efficient and effective clustering methods for spatial data mining. </title> <booktitle> Proc. of VLDB Conf., </booktitle> <pages> pages 144-155, </pages> <month> September </month> <year> 1994. </year>
Reference-contexts: However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization. Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., [Mur83], [Har75] for surveys, <ref> [NH94] </ref> for a recent application in GIS, [SM83] [VR79] for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [NHS84] <author> J. Nievergelt, H. Hinterberger, and K.C. Sevcik. </author> <title> The grid file: an adaptable, symmetric multikey file structure. </title> <journal> ACM TODS, </journal> <volume> 9(1) </volume> <pages> 38-71, </pages> <month> March </month> <year> 1984. </year>
Reference-contexts: the length (= L 2 norm) of vector ~x (AB) the length of the line segment AB Table 1: Summary of Symbols and Definitions etc.) (b) methods using linear quadtrees [Gar82] or, equivalently, the z-ordering [Ore86, Ore90], or other space-filling curves [FR89, Jag90b] and finally (c) methods that use grid-files <ref> [NHS84, HN83] </ref>. There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], [SW90], [BYCMW94]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query.
Reference: [Ore86] <author> J. Orenstein. </author> <title> Spatial query processing in an object-oriented database system. </title> <booktitle> Proc. ACM SIGMOD, </booktitle> <pages> pages 326-336, </pages> <month> May </month> <year> 1986. </year>
Reference-contexts: Such a mapping provides two major benefits: 1. It can accelerate the search time for queries. The reason is that we can employ highly fine-tuned Spatial Access Methods (SAMs), like the R fl -trees [BKSS90] and the z-ordering <ref> [Ore86] </ref>. <p> dimensionality of `target space' D (fl; fl) the distance function between two objects jj~xjj 2 the length (= L 2 norm) of vector ~x (AB) the length of the line segment AB Table 1: Summary of Symbols and Definitions etc.) (b) methods using linear quadtrees [Gar82] or, equivalently, the z-ordering <ref> [Ore86, Ore90] </ref>, or other space-filling curves [FR89, Jag90b] and finally (c) methods that use grid-files [NHS84, HN83]. There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], [SW90], [BYCMW94].
Reference: [Ore90] <author> J.A. Orenstein. </author> <title> A comparison of spatial query processing techniques for native and parameter spaces. </title> <booktitle> Proc. of ACM SIGMOD Conf., </booktitle> <pages> pages 343-352, </pages> <year> 1990. </year>
Reference-contexts: dimensionality of `target space' D (fl; fl) the distance function between two objects jj~xjj 2 the length (= L 2 norm) of vector ~x (AB) the length of the line segment AB Table 1: Summary of Symbols and Definitions etc.) (b) methods using linear quadtrees [Gar82] or, equivalently, the z-ordering <ref> [Ore86, Ore90] </ref>, or other space-filling curves [FR89, Jag90b] and finally (c) methods that use grid-files [NHS84, HN83]. There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], [SW90], [BYCMW94].
Reference: [Pet80] <author> J.L. Peterson. </author> <title> Computer programs for detecting and correcting spelling errors. </title> <journal> CACM, </journal> <volume> 23(12) </volume> <pages> 676-687, </pages> <month> December </month> <year> 1980. </year>
Reference-contexts: For the English language, we can expect V to range from 2,000 up to and exceeding 100,000 (the vocabulary of every-day English, and the size of a very detailed dictionary, respectively <ref> [Pet80] </ref>). The coordinates of such vectors are called term weights and can be binary ('1' if the term appears in the document; '0' if not) or real-valued, with values increasing with the importance (eg., occurrence frequency) of the term in the document.
Reference: [PFTV88] <author> William H. Press, Brian P. Flannery, Saul A. Teukolsky, and William T. Vetterling. </author> <title> Numerical Recipes in C. </title> <publisher> Cambridge University Press, </publisher> <year> 1988. </year>
Reference-contexts: It computes the eigenvectors of the covariance matrix, sorts them in decreasing eigenvalue order, and approximates each data vector with its projections on the first k eigenvectors. The operation is closely related to the Singular Value Decomposition (SVD) <ref> [Str80, PFTV88, GV89] </ref> of the object-feature matrix. Appendix A gives our implementation of the K-L transform in Mathematica [Wol91].
Reference: [RL92] <author> A. Ravishankar Rao and Jerry Lohse. </author> <title> Identifying high level features of texture perception. </title> <booktitle> In SPIE Conference, </booktitle> <address> San Jose, </address> <month> February </month> <year> 1992. </year>
Reference-contexts: semantic structure analysis of words; perceived personality trait relationships [RSN72], operating on 60 different personality traits and people's perception of what goes together (like `warm' and `trusting'); physics (nuclear gamma-ray spectra pattern recognition, recognizing the different type of spins and their relationships); political science (determining ideological shifts) [You87]; texture analysis <ref> [RL92] </ref>. However, for our applications, MDS suffers from two drawbacks: * It requires O (N 2 ) time, where N is the number of items. Thus, it is impractical for large datasets.
Reference: [RSN72] <author> A. Kimball Romney, Roger N. Shepard, and Sara Beth Nerlove. </author> <title> Multidimensional scaling: </title> <booktitle> Theory and applications in the behavioral sciences : vol II Applications. </booktitle> <publisher> Seminar Press, </publisher> <address> New York, </address> <year> 1972. </year>
Reference-contexts: MDS has been used in numerous, diverse applications, including the following: semantic structure analysis of words; perceived personality trait relationships <ref> [RSN72] </ref>, operating on 60 different personality traits and people's perception of what goes together (like `warm' and `trusting'); physics (nuclear gamma-ray spectra pattern recognition, recognizing the different type of spins and their relationships); political science (determining ideological shifts) [You87]; texture analysis [RL92].
Reference: [Sha77] <author> M. Shapiro. </author> <title> The choice of reference points in best-match file searching. </title> <journal> Comm. of the ACM (CACM), </journal> <volume> 20(5) </volume> <pages> 339-343, </pages> <month> May </month> <year> 1977. </year>
Reference-contexts: There are also retrieval methods for the case where only the triangular inequality holds [BK73], <ref> [Sha77] </ref>, [SW90], [BYCMW94]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query. However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization.
Reference: [She62] <author> R. N. Shepard. </author> <title> The analysis of proximities: Multidimensional scaling with an u nknown distance i and ii. </title> <journal> Psychometrika, </journal> <volume> 27 </volume> <pages> 125-140, 219-246, </pages> <year> 1962. </year> <month> 24 </month>
Reference-contexts: The above version of MDS is called metric multidimensional scaling [Tor52], because the distances are given as numbers. Several generalizations and extensions have been proposed to the above basic algorithm: Kruskal [KW78] proposed a method that automatically determines a good value for k; Shepard <ref> [She62] </ref>, and Kruskal [Kru64] proposed the non-metric MDS where the distance between items are specified qualitatively; Young [You87] describes the individual difference MDS, which incorporates multiple distance measures, corresponding to different observers' perception of the data's difference.
Reference: [SK83] <author> David Sankoff and Joseph B. Kruskal. </author> <title> Time Warps, String Edits and Macromolecules: the Theory and Practice of Sequence Comparisons. </title> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <address> Reading, MA, </address> <year> 1983. </year>
Reference-contexts: It is not clear which the features should be in this case. Similarly, in matching digitized voice excerpts, we typically have to do some time-warping <ref> [SK83] </ref>, which makes it difficult to design feature-extraction functions. Overcoming these difficulties is exactly the motivation behind this work. Generalizing the approach by Jagadish, we try to map objects into k-dimensional points, assuming that a domain expert has only provided us with a distance/dis-similarity function D (fl; fl).
Reference: [SM83] <author> G. Salton and M.J. McGill. </author> <title> Introduction to Modern Information Retrieval. </title> <publisher> McGraw-Hill, </publisher> <year> 1983. </year>
Reference-contexts: Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., [Mur83], [Har75] for surveys, [NH94] for a recent application in GIS, <ref> [SM83] </ref> [VR79] for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well. <p> Here we trace the algorithm on an information retrieval application <ref> [SM83] </ref>. There, documents are represented as vectors in V -dimensional space, where V is the size of the vocabulary of the collection. <p> Consider two documents d 1 and d 2 , with vectors ~u 1 , ~u 2 respectively. The similarity between two documents is typically measured by the cosine similarity of their vectors <ref> [SM83] </ref>: similarity (d 1 ; d 2 ) = ~u 1 ffi ~u 2 (6) where `ffi' stands for the inner product of two vectors and jj fl jj 2 stands for the Euclidean norm of the vector. Clearly the cosine similarity takes values between -1 and 1.
Reference: [SRF87] <author> T. Sellis, N. Roussopoulos, and C. Faloutsos. </author> <title> The r+ tree: a dynamic index for multidimensional objects. </title> <booktitle> In Proc. 13th International Conference on VLDB, </booktitle> <pages> pages 507-518, </pages> <address> England,, </address> <month> September </month> <year> 1987. </year> <note> also available as SRC-TR-87-32, UMIACS-TR-87-3, CS-TR-1795. </note>
Reference-contexts: The most popular methods form three classes: (a) tree-based methods like the R-tree [Gut84], and its variants (R + -tree <ref> [SRF87] </ref>, hB-tree [LS90], P-tree [Jag90a], R fl -tree [BKSS90], Hilbert R-trees [KF94] 6 Symbols Definitions.
Reference: [Str80] <author> Gilbert Strang. </author> <title> Linear Algebra and its Applications. </title> <publisher> Academic Press, </publisher> <year> 1980. </year> <note> 2nd edition. </note>
Reference-contexts: It computes the eigenvectors of the covariance matrix, sorts them in decreasing eigenvalue order, and approximates each data vector with its projections on the first k eigenvectors. The operation is closely related to the Singular Value Decomposition (SVD) <ref> [Str80, PFTV88, GV89] </ref> of the object-feature matrix. Appendix A gives our implementation of the K-L transform in Mathematica [Wol91].
Reference: [SW90] <author> Dennis Shasha and Tsong-Li Wang. </author> <title> New techniques for best-match retrieval. </title> <journal> ACM TOIS, </journal> <volume> 8(2) </volume> <pages> 140-158, </pages> <month> April </month> <year> 1990. </year>
Reference-contexts: There are also retrieval methods for the case where only the triangular inequality holds [BK73], [Sha77], <ref> [SW90] </ref>, [BYCMW94]. All these methods try to exploit the triangular inequality in order to prune the search space on a range query. However, none of them tries to map objects into points in `target space', nor to provide a tool for visualization.
Reference: [TBS90] <author> A.W. Toga, P.K. Banerjee, </author> <title> and E.M. Santori. Warping 3d models for interbrain comparisons. </title> <address> Neurosc. Abs., 16:247, </address> <year> 1990. </year>
Reference-contexts: Notice that the distance functions are complicated, typically requiring some warping of the two images, to make sure that the anatomical structures (eg., bones) are properly aligned, before we consider the differences <ref> [TBS90] </ref>.
Reference: [Tor52] <author> W. S. Torgerson. </author> <title> Multidimensional scaling: I. theory and method. </title> <journal> Psychometrika, </journal> <volume> 17 </volume> <pages> 401-419, </pages> <year> 1952. </year>
Reference-contexts: Intuitively, it treats each pair-wise distance as a `spring' between the two points; then, the algorithm tries to re-arrange the positions of the k-d points to minimize the `stress' of the springs. The above version of MDS is called metric multidimensional scaling <ref> [Tor52] </ref>, because the distances are given as numbers.
Reference: [Vas93] <author> Dimitris Vassiliadis. </author> <title> The input-state space approach to the prediction of auroral geo-magnetic activity from solar wind variables. </title> <booktitle> Int. Workshop on Applications of Artificial Intelligence in Solar Terrestrial Physics, </booktitle> <month> September </month> <year> 1993. </year>
Reference-contexts: it difficult to find features that would adequately describe each image (and therefore, map it into a point in feature space). 2 * Time series, with, eg. financial data, such as stock prices, sales numbers etc., or scientific databases, with time series of sensor data, weather [CoPES92], geological, environmental, astrophysics <ref> [Vas93] </ref> data, etc., In such databases, typical queries would be `find companies whose stock prices move similarly', or `find past days in which the solar magnetic wind showed patterns similar to today's pattern' [Vas93]. <p> sales numbers etc., or scientific databases, with time series of sensor data, weather [CoPES92], geological, environmental, astrophysics <ref> [Vas93] </ref> data, etc., In such databases, typical queries would be `find companies whose stock prices move similarly', or `find past days in which the solar magnetic wind showed patterns similar to today's pattern' [Vas93]. The goal is to aid forecasting, by examining similar patterns that may have appeared in the past.
Reference: [VR79] <author> C.J. Van-Rijsbergen. </author> <title> Information Retrieval. </title> <publisher> Butterworths, </publisher> <address> London, England, </address> <year> 1979. </year> <note> 2nd edition. </note>
Reference-contexts: Finally, our work could be beneficial to research on clustering algorithms, where several approaches have been proposed. See, eg., [Mur83], [Har75] for surveys, [NH94] for a recent application in GIS, [SM83] <ref> [VR79] </ref> for applications in Information Retrieval. 3 Proposed Method In the first part, we describe the proposed algorithm, which achieves a fast mapping of objects into points, so that distances are preserved well.
Reference: [Wol91] <author> Stephen Wolfram. </author> <title> Mathematica. </title> <publisher> Addison Wesley, </publisher> <year> 1991. </year> <note> Second Edition. </note>
Reference-contexts: The operation is closely related to the Singular Value Decomposition (SVD) [Str80, PFTV88, GV89] of the object-feature matrix. Appendix A gives our implementation of the K-L transform in Mathematica <ref> [Wol91] </ref>. <p> Murphy and David W. Aha for maintaining the UC-Irvine Repository of Machine Learning Databases and Domain Theories; Prof. Howard Elman and Doug Oard for help with SVD algorithms. A Karhunen-Loeve Transform This is the code for the K-L transform in Mathematica <ref> [Wol91] </ref> (* given a matrix mat_ with $n$ vectors of $m$ attributes, it creates a matrix with $n$ vectors and their first $k$ most 'important' attributes (ie., the K-L expansions of these $n$ vectors) *) KLexpansion [ mat_, k_:2] := mat .
Reference: [You87] <author> Forrest W. Young. </author> <title> Multidimensional scaling : History, Theory and Applications. </title> <publisher> Lawrence Erlbaum associates, </publisher> <address> Hillsdale, New Jersey, </address> <year> 1987. </year> <month> 25 </month>
Reference-contexts: In section 5 we list the conclusions. 2 Survey Here we present some background information about older attempts to solve the problem. First we discuss the Multidimensional Scaling (MDS) method that has been used in several diverse fields (eg., social sciences, psychology, market research, physics <ref> [You87] </ref>) to solve the `distance' case problem. Then, we present the Karhunen-Loeve transform and the closely related Singular Value Decomposition that has been used for dimensionality reduction (`features' case). <p> Several generalizations and extensions have been proposed to the above basic algorithm: Kruskal [KW78] proposed a method that automatically determines a good value for k; Shepard [She62], and Kruskal [Kru64] proposed the non-metric MDS where the distance between items are specified qualitatively; Young <ref> [You87] </ref> describes the individual difference MDS, which incorporates multiple distance measures, corresponding to different observers' perception of the data's difference. <p> including the following: semantic structure analysis of words; perceived personality trait relationships [RSN72], operating on 60 different personality traits and people's perception of what goes together (like `warm' and `trusting'); physics (nuclear gamma-ray spectra pattern recognition, recognizing the different type of spins and their relationships); political science (determining ideological shifts) <ref> [You87] </ref>; texture analysis [RL92]. However, for our applications, MDS suffers from two drawbacks: * It requires O (N 2 ) time, where N is the number of items. Thus, it is impractical for large datasets.
References-found: 54

