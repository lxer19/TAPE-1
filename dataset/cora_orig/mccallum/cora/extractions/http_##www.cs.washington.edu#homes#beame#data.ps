URL: http://www.cs.washington.edu/homes/beame/data.ps
Refering-URL: http://www.cs.washington.edu/homes/beame/papers.html
Root-URL: 
Title: On Searching Sorted Lists: A Near-Optimal Lower Bound  
Author: Paul Beame Faith Fich 
Date: April 23, 1997  
Address: Box 352350 Seattle, WA USA 98195-2350  Toronto, Ontario CANADA M5S 1A4  
Affiliation: Computer Science and Engineering University of Washington  Computer Science Department University of Toronto  
Abstract: We obtain improved lower bounds for a class of static and dynamic data structure problems that includes several problems of searching sorted lists as special cases. These lower bounds nearly match the upper bounds given by recent striking improvements in searching algorithms given by Fredman and Willard's fusion trees [9] and Andersson's search data structure [5]. Thus they show sharp limitations on the running time improvements obtainable using the unit-cost word-level RAM operations that those algorithms employ.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> M. Ajtai, M. Fredman, and J. Komlos. </author> <title> Hash functions for priority queues. </title> <journal> Information and Control, </journal> <volume> 63 </volume> <pages> 217-225, </pages> <year> 1984. </year>
Reference-contexts: Ajtai, Fredman, and Komlos <ref> [1] </ref> also considered the static problem. They showed that, if n, the size of the universe, is only polynomial in s = jSj then, using a trie, one can store S in O (s) memory cells and answer predecessor queries in constant time in the cell-probe model. <p> Fusion trees and Andersson's search structure also provide solutions to the static predecessor problem. They use O ( p log s) time per query. Unlike the predecessor data structure in <ref> [1] </ref>, these structures use only O (s) memory cells for a given set size s, independent of universe size (provided that elements of the universe fit in individual words of memory.) Miltersen et al. [12] observed that, for certain universe sizes, the lower bound of [13] also gives an ((log s) <p> Our key improvement is that we find a better distribution of inputs on which to consider the data structure's behaviour. 2 Preliminaries In this section, we state two combinatorial results which are important for the lower bound proofs given in the next section. We use the notation <ref> [1; n] </ref> to denote the set of integers f1; : : : ; ng and (a; a 0 ], for a &lt; a 0 , to denote the set of integers fa + 1; : : : ; a 0 g. <p> Definition 3.3: Let Z (n; s) denote the set of strings in ( [ f?g) n containing at most s non? characters. Definition 3.4: The static (L; n; s)-prefix problem is to store an arbitrary string y 2 Z (n; s) so that, for any j 2 <ref> [1; n] </ref>, the query "Is PRE j (y) 2 L?" may be answered. If n 0 n and s 0 s, then any string in Z (n; s) can be viewed as a string in Z (n 0 ; s 0 ) by appending ? n 0 n to it. <p> The simplest probability distribution on the Responder's input that we consider is D (n; s), which is defined as follows: Definition 3.6: An element y = y 1 : : : y n from Z (n; s) is chosen according to D (n; s) by first choosing S <ref> [1; n] </ref> uniformly at random with jSj = s, then, independently for each j 2 S, choosing y j 2 [ f?g uniformly at random, and finally setting y j = ? for j =2 S. <p> That is, each of the n strings in Z (n; s) with exactly i non? characters has probability ni n First we argue that there does not exist a large set of positions A <ref> [1; n] </ref> and a large set of strings B Z (n; s) for which the static (L; n; s)-prefix problem can be solved, for all j 2 A and y 2 B, without communication. We actually consider a slightly more general problem: determining whether x PRE j (y) 2 L. <p> Let n s &gt; 0 and suppose that b 2 (jj + 1) q , ff max (8qb 2 =s; 12b 3 =s), and fi 2 2b+1 . Consider any set of positions A <ref> [1; n] </ref>, with jAj ffn, and any set of strings B Z (n; s), with D (n;s) (B) fi. <p> Say a 0 &lt; &lt; a b 2 . Then j (a i1 ; a i ]j = a i a i1 &gt; ffn=(2b 2 ) for i = 1; : : : ; b 2 . Let S <ref> [1; n] </ref> with jSj = s be chosen uniformly at random. <p> After i rounds, the possible values of the Querier's input in this portion will correspond to an interval <ref> [1; n i ] </ref> of a smaller prefix problem for language L. After i rounds, the Responder's input for this smaller prefix problem will have at most s i elements of and thus be a member of Z (n i ; s i ). <p> Lemma 5: Suppose that L is a regular language accepted by a deterministic finite automaton M with q states. Suppose (b; k; t; n; s) satisfies the integrality condition, b 16, and 2 b 4q. Let x 2 fl , A <ref> [1; n i ] </ref> with jAj ffn i , and B Z (n i ; s i ) with D i (B) fi. <p> Suppose there is a t i round cell-probe communication protocol, using m s k memory cells of b bits, that correctly determines whether xP RE j (y) 2 L for all j 2 A and y 2 B. Then there exist x 0 2 fl , A 0 <ref> [1; n i+1 ] </ref> with jA 0 j ffn i+1 , B 0 Z (n i+1 ; s i+1 ) with D i+1 (B 0 ) fi and a t i 1 round cell-probe communication protocol, using m cells of b bits, that correctly determines whether x 0 P RE j <p> Choose that node v. Fixing a round of communication for each player Since v is ff-dense, there is some message c the Querier may send in the first round such that jA 0 j=n i+1 ff, where A 0 = fj 0 2 <ref> [1; n i+1 ] </ref> j the j 0 -th child of v is coloured cg: Recall that the j 0 -th child of v is coloured c when there is some j 2 A on which the Querier sends message c in the first round and the j-th leaf of T <p> Since (b; k; t; n; s) satisfies the integrality condition, b 16, and 2 b b 2 q+1 4q, we can apply Lemma 5 t times, starting with A = <ref> [1; n] </ref> and B = Z (n; s), to obtain x 2 fl , A 0 [1; n t ] with jA 0 j ffn t , B 0 Z (n t ; s t ) with D t (B 0 ) fi, and a 0 round cell-probe communication protocol such <p> Since (b; k; t; n; s) satisfies the integrality condition, b 16, and 2 b b 2 q+1 4q, we can apply Lemma 5 t times, starting with A = [1; n] and B = Z (n; s), to obtain x 2 fl , A 0 <ref> [1; n t ] </ref> with jA 0 j ffn t , B 0 Z (n t ; s t ) with D t (B 0 ) fi, and a 0 round cell-probe communication protocol such that the protocol correctly determines whether x PRE j (y) 2 L for all j 2 <p> This is a contradiction. 2 Theorem 7: If L is an indecisive regular language, then for any n &gt; 0 there exists s 2 <ref> [1; n] </ref> such that any cell-probe data structure for the static (L; n; s)-prefix problem using s O (1) memory cells of 2 (log n) 1 (1) bits requires time (log log n= log log log n) per query. <p> Proof We show that, for each positive integer k and each positive constant * &lt; 1, there is a constant ffi &gt; 0 so that, for each sufficiently large n, there exists s 2 <ref> [1; n] </ref> such that any cell-probe communication protocol using s k memory cells of 2 (log n) 1* bits requires at least ffi log log n= log log log n rounds to solve the static (L; n; s)-prefix problem.
Reference: [2] <author> Miklos Ajtai. </author> <title> A lower bound for finding predecessors in Yao's cell probe model. </title> <journal> Combinatorica, </journal> <volume> 8 </volume> <pages> 235-247, </pages> <year> 1988. </year>
Reference-contexts: number of memory cells in order for the model to be meaningful; otherwise a precomputed table of answers can be used to solve any given problem with only one access.) A number of authors have considered lower bounds in the cell-probe model for both static and dynamic data structure problems <ref> [18, 2, 8, 13] </ref>. The particular class of problems that we consider includes problems such as both the static and dynamic predecessor and one-dimensional range query problems. <p> They showed that, if n, the size of the universe, is only polynomial in s = jSj then, using a trie, one can store S in O (s) memory cells and answer predecessor queries in constant time in the cell-probe model. In <ref> [2] </ref>, on which many of the techniques of this paper are based, Ajtai showed that, even in the very general cell-probe model, the result of Ajtai, Fredman, and Szemeredi cannot be extended to general S, even if the memory size is permitted to be as large as s O (1) . <p> In terms of the number of elements, s, we improve the bound to ( p nearly matching the O ( p log s) upper bound on augmented RAMs due to Andersson. The basic structure of our argument follows that of <ref> [2] </ref> as expressed by [13]. Our key improvement is that we find a better distribution of inputs on which to consider the data structure's behaviour. 2 Preliminaries In this section, we state two combinatorial results which are important for the lower bound proofs given in the next section. <p> Then Pr [jH " Sj s=4] ( 2=e 3=4 ) s &lt; 2 s=2 : The next result is a small modification and rephrasing of a combinatorial lemma that formed the basis of Ajtai's lower bound argument in <ref> [2] </ref>. Suppose we have a tree T of depth d such that all nodes on the same level have the same number of children.
Reference: [3] <author> A. Andersson, T. Hagerup, S. Nilsson, and R. Raman. </author> <booktitle> Sorting in linear time? In Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 427-436, </pages> <address> Las Vegas, NV, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: Traditionally, the second view is only applied when the number of bits to represent the data is very small in comparison with the number of elements being sorted. More recently, algorithms such as the fusion tree sorting algorithm of Fredman and Willard [9] and subsequent algorithms in <ref> [10, 7, 3] </ref>, have shown that one can obtain significant speed-ups by fully exploiting unit-cost word-level operations and the fact that data elements being sorted need to fit in words of memory. <p> in part by grants from the Natural Sciences and Engineering Research Council and the Information Technology Research Centre of Ontario 1 unit-cost operation, which may be more than one wishes to allow, but Andersson [5], building on an O (n log log n) time sorting algorithm in this model in <ref> [3] </ref>, has shown that even a simpler collection of word-level operations (all of them computable in AC 0 ) permits the O ( p log s) running time and O (s) space as a worst case bound.
Reference: [4] <author> A. Andersson, P. B. Miltersen, S. Riis, and M. </author> <title> Thorup. Static dictionaries on AC 0 RAMs: query time fi( p log n= log log n) is necessary and sufficient. </title> <booktitle> In 37nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 441-450, </pages> <address> Burlington, VT, </address> <month> October </month> <year> 1996. </year> <note> IEEE. </note>
Reference-contexts: One might be inclined to rule out the lower bound based simply on its unusual form. However, as Andersson et al. <ref> [4] </ref> have recently shown the complexity of the simpler static dictionary problem on the more restricted AC 0 RAM model is the same function as in our lower bound. Acknowledgements We are grateful to Peter Bro Miltersen for helpful discussions. 14
Reference: [5] <author> Arne Andersson. </author> <title> Sublogarithmic seaching without multiplications. </title> <booktitle> In 36nd Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 655-665, </pages> <address> Milwaukee, WI, </address> <month> October </month> <year> 1995. </year> <note> IEEE. </note>
Reference-contexts: as a fl Research supported by the National Science Foundation under grant CCR-9303017 y Research supported in part by grants from the Natural Sciences and Engineering Research Council and the Information Technology Research Centre of Ontario 1 unit-cost operation, which may be more than one wishes to allow, but Andersson <ref> [5] </ref>, building on an O (n log log n) time sorting algorithm in this model in [3], has shown that even a simpler collection of word-level operations (all of them computable in AC 0 ) permits the O ( p log s) running time and O (s) space as a worst
Reference: [6] <author> V. Chvatal. </author> <title> Probabilistic methods in graph theory. </title> <journal> Annals of Operations Research, </journal> <volume> 1 </volume> <pages> 171-182, </pages> <year> 1984. </year>
Reference-contexts: The following form of the Chernoff-Hoeffding bound follows easily from the presentation in <ref> [6] </ref>. Proposition 1: Fix H U with jHj jU j and let S U with jSj = s be chosen uniformly at 3 random.
Reference: [7] <author> Frandsen, P. B. Miltersen, and Skyum. </author> <title> Dynamic word problems. </title> <booktitle> In Proceedings 34th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 470-479, </pages> <address> Palo Alto, CA, </address> <month> November </month> <year> 1993. </year> <note> IEEE. </note>
Reference-contexts: Traditionally, the second view is only applied when the number of bits to represent the data is very small in comparison with the number of elements being sorted. More recently, algorithms such as the fusion tree sorting algorithm of Fredman and Willard [9] and subsequent algorithms in <ref> [10, 7, 3] </ref>, have shown that one can obtain significant speed-ups by fully exploiting unit-cost word-level operations and the fact that data elements being sorted need to fit in words of memory.
Reference: [8] <author> M. Fredman and M. Saks. </author> <title> The cell probe complexity of dynamic data structures. </title> <booktitle> In Proceedings of the Twenty First Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 345-354, </pages> <address> Seattle, WA, </address> <month> May </month> <year> 1989. </year>
Reference-contexts: number of memory cells in order for the model to be meaningful; otherwise a precomputed table of answers can be used to solve any given problem with only one access.) A number of authors have considered lower bounds in the cell-probe model for both static and dynamic data structure problems <ref> [18, 2, 8, 13] </ref>. The particular class of problems that we consider includes problems such as both the static and dynamic predecessor and one-dimensional range query problems. <p> The basic idea of the translation is to observe that dynamic algorithms that have small cost per query and do not run for very long can access only a small number of memory cells from a moderate size set of potential memory cells. Using static dictionary techniques from <ref> [8] </ref> one can obtain an efficient solution to the static problem by beginning with string in f?g fl , then inserting the non ? elements needed, one by one, and recording in the dictionary the changes made to the memory.
Reference: [9] <author> M. Fredman and D. Willard. </author> <title> Surpassing the information theoretic bound with fusion trees. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 47(3) </volume> <pages> 424-436, </pages> <year> 1993. </year>
Reference-contexts: Traditionally, the second view is only applied when the number of bits to represent the data is very small in comparison with the number of elements being sorted. More recently, algorithms such as the fusion tree sorting algorithm of Fredman and Willard <ref> [9] </ref> and subsequent algorithms in [10, 7, 3], have shown that one can obtain significant speed-ups by fully exploiting unit-cost word-level operations and the fact that data elements being sorted need to fit in words of memory.
Reference: [10] <author> M. Fredman and D. Willard. </author> <title> Trans-dichotomous algorithms for minimum spanning trees and shortest paths. </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 48(3) </volume> <pages> 533-551, </pages> <year> 1994. </year>
Reference-contexts: Traditionally, the second view is only applied when the number of bits to represent the data is very small in comparison with the number of elements being sorted. More recently, algorithms such as the fusion tree sorting algorithm of Fredman and Willard [9] and subsequent algorithms in <ref> [10, 7, 3] </ref>, have shown that one can obtain significant speed-ups by fully exploiting unit-cost word-level operations and the fact that data elements being sorted need to fit in words of memory.
Reference: [11] <author> Mauricio Karchmer and Avi Wigderson. </author> <title> Monotone circuits for connectivity require super-logarithmic depth. </title> <booktitle> In Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 539-550, </pages> <address> Chicago, IL, </address> <month> May </month> <year> 1988. </year>
Reference-contexts: cell to access and the Responder answers with the contents of that memory cell. (The only restriction is that the same query always receives the same response.) He rephrases most of Ajtai's argument in this form where its similarities with the communication complexity lower bound argument of Karchmer and Wigderson <ref> [11] </ref> become quite apparent. Fusion trees and Andersson's search structure also provide solutions to the static predecessor problem. They use O ( p log s) time per query. <p> Therefore, if there is an algorithm for the static (L; n; s)-prefix problem that uses at most t 1 probes, then there is a cell-probe communication protocol that solves this problem in at most t rounds. The lower bound, in the style of <ref> [11] </ref>, works `top down', maintaining, for each player, a relatively large set of inputs on which the communication is fixed. Unlike [11], we actually have a non-uniform distributions on the Responder's inputs, so our notion of `large' is with respect to these distributions. <p> The lower bound, in the style of <ref> [11] </ref>, works `top down', maintaining, for each player, a relatively large set of inputs on which the communication is fixed. Unlike [11], we actually have a non-uniform distributions on the Responder's inputs, so our notion of `large' is with respect to these distributions. The distributions change (get simpler) as the rounds of the communication proceed. We find the following notation convenient for this.
Reference: [12] <author> P. B. Miltersen, N. Nisan, S. Safra, and A. Wigderson. </author> <title> On data structures and asymmetric communication complexity. </title> <booktitle> In Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 103-111, </pages> <address> Las Vegas, NV, </address> <month> May </month> <year> 1995. </year> <note> Journal version. </note>
Reference-contexts: Unlike the predecessor data structure in [1], these structures use only O (s) memory cells for a given set size s, independent of universe size (provided that elements of the universe fit in individual words of memory.) Miltersen et al. <ref> [12] </ref> observed that, for certain universe sizes, the lower bound of [13] also gives an ((log s) 1=3 ) lower bound on the time to implement any static problem from the class considered in [13] and thus on search data structures, such as fusion trees, with an s O (1) bound
Reference: [13] <author> Peter B. Miltersen. </author> <title> Lower bounds for Union-Split-Find related problems on random access machines. </title> <booktitle> In Proceedings of the Twenty-Sixth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 625-634, </pages> <address> Montreal, Quebec, Canada, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: number of memory cells in order for the model to be meaningful; otherwise a precomputed table of answers can be used to solve any given problem with only one access.) A number of authors have considered lower bounds in the cell-probe model for both static and dynamic data structure problems <ref> [18, 2, 8, 13] </ref>. The particular class of problems that we consider includes problems such as both the static and dynamic predecessor and one-dimensional range query problems. <p> More precisely, he showed that if the size n of the universe U grows more than polynomially in s = jSj, then any cell-probe 2 data structure using s O (1) memory cells requires non-constant time per query. In <ref> [13] </ref>, Miltersen defined a natural class of data structure problems that includes the predecessor and one-dimensional range query problems as special cases and he generalized many of the results above to this class of problems. <p> the predecessor data structure in [1], these structures use only O (s) memory cells for a given set size s, independent of universe size (provided that elements of the universe fit in individual words of memory.) Miltersen et al. [12] observed that, for certain universe sizes, the lower bound of <ref> [13] </ref> also gives an ((log s) 1=3 ) lower bound on the time to implement any static problem from the class considered in [13] and thus on search data structures, such as fusion trees, with an s O (1) bound on the number of memory cells. <p> size (provided that elements of the universe fit in individual words of memory.) Miltersen et al. [12] observed that, for certain universe sizes, the lower bound of <ref> [13] </ref> also gives an ((log s) 1=3 ) lower bound on the time to implement any static problem from the class considered in [13] and thus on search data structures, such as fusion trees, with an s O (1) bound on the number of memory cells. In this paper, we nearly close the gaps between the upper and lower bounds for these data structure problems in the cell-probe model. <p> In terms of the number of elements, s, we improve the bound to ( p nearly matching the O ( p log s) upper bound on augmented RAMs due to Andersson. The basic structure of our argument follows that of [2] as expressed by <ref> [13] </ref>. Our key improvement is that we find a better distribution of inputs on which to consider the data structure's behaviour. 2 Preliminaries In this section, we state two combinatorial results which are important for the lower bound proofs given in the next section. <p> ffi j ff jV d j mffi d1 jV d j, so d1 X ffi ` ff mffi d1 : Thus there is some `, 1 ` d 1, such that ffi ` (ff mffi d1 )=(d 1), as required. 2 3 Lower Bounds for Static Problems As in Miltersen <ref> [13] </ref>, we prove our lower bounds in a general language-theoretic setting. At the end of the section, we show how to obtain the results for the specific data structure problems mentioned in the introduction as corollaries of these lower bounds. <p> Thus the static (L; n 0 ; s 0 )-prefix problem is at least as hard as the static (L; n; s)-prefix problem. 5 We prove a lower bounds on the complexity of the static (L; n; s)-prefix problem using an adversary argument. As discussed in the introduction, Miltersen <ref> [13] </ref> observed that one can phrase a static data structure algorithm in the cell-probe model in terms of a communication protocol between between two players: the Querier, who holds the information about the input to be dealt with, and the Responder, who holds the data structure. <p> O (1) memory cells of (log n) O (1) bits whose time does not depend on n. 4 Lower Bounds for Dynamic Problems The results of this section are really simply translations of the results of the previous section to the dynamic case, using the translation argument given by Miltersen <ref> [13] </ref>. 13 The dynamic (L; n)-prefix problem requires answers to the questions "Is PRE j (x) 2 L?" for x 2 ( [ f?g) n . For this problem, an additional set of update operations on the input string are permitted.
Reference: [14] <author> P. Van Emde Boas, R Kaas, and E. Zijlstra. </author> <title> Design and implementation of an efficient priority queue. </title> <journal> Mathematical Systems Theory, </journal> <volume> 10 </volume> <pages> 99-127, </pages> <year> 1977. </year> <month> 15 </month>
Reference-contexts: Van Emde Boas et al. <ref> [14] </ref> showed that the dynamic version of the predecessor problem (as well as the more general priority queue problem) in a universe of size n may be solved on a RAM at a cost of only O (log log n) time per update.
Reference: [15] <author> D. E. Willard. </author> <title> Log-logarithmic worst case range queries are possible in space fi(n). </title> <journal> Information Processing Letters, </journal> <volume> 17 </volume> <pages> 81-84, </pages> <year> 1983. </year>
Reference-contexts: Van Emde Boas et al. [14] showed that the dynamic version of the predecessor problem (as well as the more general priority queue problem) in a universe of size n may be solved on a RAM at a cost of only O (log log n) time per update. Willard <ref> [15] </ref> extended this result to show that if the set S has size at most s then, in the static version of the predecessor problem, only O (s) memory cells are needed so that each query can be answered in O (log log n) time on a RAM.
Reference: [16] <author> Bing Xiao. </author> <title> New bounds in cell probe model. </title> <type> PhD thesis, </type> <institution> University of California, </institution> <address> San Diego, </address> <year> 1992. </year>
Reference-contexts: A result similar to Corollary 9 was independently shown by Xiao <ref> [16] </ref>. As noted in the introduction, the static predecessor problem for a set S from a universe of size jSj O (1) can be solved in constant time in the cell-probe model using only O (jSj) memory cells.
Reference: [17] <author> A. C. Yao. </author> <title> Some complexity questions related to distributive computing. </title> <booktitle> In Conference Record of the Eleventh Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 209-213, </pages> <address> Atlanta, GA, </address> <month> April-May </month> <year> 1979. </year>
Reference-contexts: One of the other nice contributions of Miltersen's paper is the observation that cell-probe algorithms can be viewed as two-party communication protocols <ref> [17] </ref> between a Querier who holds the input query and a Responder who holds the data structure.
Reference: [18] <author> A. C. Yao. </author> <title> Should tables be sorted? Journal of the ACM, </title> <booktitle> 28 </booktitle> <pages> 615-628, </pages> <month> July </month> <year> 1981. </year> <month> 16 </month>
Reference-contexts: What are the limits to the improvements in running-time obtained using this freedom? One of the most natural and general models for proving lower bounds for data structures problems, and one that is ideally suited for representing word-level operations, is the cell-probe model, introduced by Yao <ref> [18] </ref>. In this model, there is a memory consisting of cells, each of which is capable of storing some fixed number of bits. A cell-probe algorithm is a decision tree with one memory cell accessed at each node. The decision tree branches according to the contents of the cell accessed. <p> number of memory cells in order for the model to be meaningful; otherwise a precomputed table of answers can be used to solve any given problem with only one access.) A number of authors have considered lower bounds in the cell-probe model for both static and dynamic data structure problems <ref> [18, 2, 8, 13] </ref>. The particular class of problems that we consider includes problems such as both the static and dynamic predecessor and one-dimensional range query problems.
References-found: 18

