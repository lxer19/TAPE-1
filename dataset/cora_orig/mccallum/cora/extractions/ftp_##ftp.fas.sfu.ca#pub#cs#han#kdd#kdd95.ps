URL: ftp://ftp.fas.sfu.ca/pub/cs/han/kdd/kdd95.ps
Refering-URL: http://fas.sfu.ca/cs/research/groups/DB/sections/publication/kdd/kdd.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: 16 Exploration of the Power of Attribute-Oriented Induction in Data Mining  
Author: Jiawei Han Yongjian Fu 
Note: 16.1 Introduction The development of the attribute-oriented induction method is motivated by the following observations. First, although certain regularities, such as association rules, can be discovered and expressed at the primitive concept level by interesting data mining  
Affiliation: Simon Fraser University  
Abstract: Attribute-oriented induction is a set-oriented database mining method which generalizes the task-relevant subset of data attribute-by-attribute, compresses it into a generalized relation, and extracts from it the general features of data. In this chapter, the power of attribute-oriented induction is explored for the extraction from relational databases of different kinds of patterns, including characteristic rules, discriminant rules, cluster description rules, and multiple-level association rules. Furthermore, it is shown that the method is efficient, robust, with wide applications, and extensible to knowledge discovery in advanced database systems, including object-oriented, deductive, and spatial database systems. The implementation status of DB-Miner, a system prototype which applies the method, is also reported here. With an upsurge of the application demands and research activities on knowledge discovery in databases (Matheus, Chan and Piatetsky-Shapiro 1993; Piatetsky-Shapiro and Frawley 1991), an attribute-oriented induction method (Cai, Cercone and Han 1991; Han, Cai and Cercone 1993) has been developed as an interesting technique for mining knowledge from data. The method integrates a machine learning paradigm (Michalski 1983), especially learning-from-examples techniques, with database operations, extracts generalized rules from an interesting set of data, and discovers high-level data regularities. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Agrawal, R., Imielinski, T. and Swami, A. </author> <year> 1993. </year> <title> Mining association rules between sets of items in large databases. </title> <booktitle> In Proc. 1993 ACM-SIGMOD Int. Conf. Management of Data, </booktitle> <pages> 207-216, </pages> <address> Washington, D.C.: </address> <publisher> ACM Press. </publisher>
Reference-contexts: Exploration of the Power of Attribute-Oriented Induction in Data Mining 161 16.3.3 Mining multiple-level association rules An association rule represents an association relationship among a set of patterns (values) in a database <ref> (Agrawal, Imielinski and Swami 1993) </ref>. For example, an association rule discovered from a shopping transaction database may disclose that a customer who buys milk will have 90% possibility to buy bread as well. The association relationship can be characterized by support and confidence '.
Reference: <author> Cai, Y., Cercone, N., and Han, J. </author> <year> 1991. </year> <title> Attribute-oriented induction in relational databases. In Knowledge Discovery in Databases, </title> <editor> ed. G. Piatetsky-Shapiro and W. J. Frawley, </editor> <address> 213-228. </address> <publisher> AAAI/MIT Press. </publisher>
Reference-contexts: It is important to determine desired classifying attribute (s) and desired concept level (s) for conceptual clustering in a particular set of data. Attribute-oriented induction can be applied to conceptual clustering as follows <ref> (Han, Cai and Cercone 1991) </ref>. First, the interested set of data is collected by a database query, and the attribute-oriented induction generalizes the set of data to an appropriate high concept level, which results in a generalized relation.
Reference: <author> Cheung, D.W., Fu, A. W.-C. and Han., J. </author> <year> 1994. </year> <title> Knowledge discovery in databases: A rule-based attribute-oriented approach. </title> <booktitle> In Proc. 1994 Int'l Symp. on Methodologies for Intelligent Systems, </booktitle> <pages> 164-173, </pages> <address> Charlotte, </address> <publisher> North Carolina. </publisher>
Reference-contexts: Such a rule can be stored as a part of the concept hierarchy and be used in generalization <ref> (Cheung, Fu and Han 1994) </ref>. 4. Rule-directed knowledge discovery: Certain rules can be used for directing a knowledge discovery process.
Reference: <author> Chu, W. W. and Chiang, K. </author> <year> 1994. </year> <title> Abstraction of high level concepts from numerical values in databases. </title> <booktitle> In Proc. AAAI'94 Workshop on Knowledge Discovery in Databases (KDD'94), </booktitle> <pages> 37-48, </pages> <address> Seattle, WA.: </address> <publisher> AAAI Press. </publisher>
Reference: <author> Dhar, V. and Tuzhilin, A. </author> <year> 1993. </year> <title> Abstract-driving pattern discovery in databases. </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> 5(6): </volume> <pages> 926-938. </pages>
Reference-contexts: Deduction rule-specified concept hierarchy: A rule may also be used to specify concept hierarchies <ref> (Dhar and Tuzhilin 1993) </ref>. For example, a rule which claims that "a student is excellent if (s)he is an undergraduate student with GPA 3.5 or if (s)he is a graduate student with GPA 3.75" defines a portion of the concept hierarchy for the attribute GPA.
Reference: <author> Elmasri, R. and Navathe, S. B. </author> <year> 1994. </year> <title> Fundamentals of Database Systems, 2nd ed. </title> <publisher> Benjamin/Cummings. </publisher>
Reference-contexts: 2% Dairyland milk, there is a 45% possibility that (s)he will buy Wonder whole wheat bread." 16.4.3 Attribute-oriented induction in spatial databases A spatial database system stores, manages and manipulates spatial (i.e., space-related) data and, in most cases, nonspatial data as well for geographic information systems and many other applications <ref> (Elmasri and Navathe 1994) </ref>. Spatial data mining refers to the discovery of interesting relationships between spatial and nonspatial data and/or among spatial data in spatial databases.
Reference: <author> Fisher, D. H. </author> <year> 1987. </year> <title> Knowledge acquisition via incremental conceptual clustering. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 139-172. </pages>
Reference-contexts: The association of count with each disjunct leads naturally to mining approximate rules, for which the conditions with negligible weight can be dropped in generalization and rule formation since a negligible weight implies a minimal influence to the conclusion. Count association facilitates incremental learning <ref> (Fisher 1987) </ref> in large databases as well: when a new tuple is inserted into a database, its concepts (attribute values) are first generalized to the same concept level as those in the generalized relation and then merged naturally into the generalized relation.
Reference: <author> Han, J., Cai, Y., and Cercone, N. </author> <year> 1991. </year> <title> Concept-based data classification in relational databases. </title> <booktitle> In Proc. 1991 AAAI Workshop on Knowledge Discovery in Databases, </booktitle> <pages> 77-94, </pages> <address> Anaheim, CA.: </address> <publisher> AAAI Press Han, </publisher> <editor> J., Cai, Y., and Cercone, N. </editor> <year> 1993. </year> <title> Data-driven discovery of quantitative rules in relational databases. </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> 5 </volume> <pages> 29-40. </pages>
Reference-contexts: It is important to determine desired classifying attribute (s) and desired concept level (s) for conceptual clustering in a particular set of data. Attribute-oriented induction can be applied to conceptual clustering as follows <ref> (Han, Cai and Cercone 1991) </ref>. First, the interested set of data is collected by a database query, and the attribute-oriented induction generalizes the set of data to an appropriate high concept level, which results in a generalized relation.
Reference: <author> Han, J. and Fu, Y. </author> <year> 1994. </year> <title> Dynamic generation and refinement of concept hierarchies for knowledge discovery in databases. </title> <booktitle> In Proc. AAAI'94 Workshop on Knowledge Discovery in Databases (KDD'94, </booktitle> <pages> 157-168, </pages> <address> Seattle, WA.: </address> <publisher> AAAI Press Han, </publisher> <editor> J. and Fu, Y. </editor> <year> 1995. </year> <title> Discovery of multiple-level association rules from large databases. </title> <booktitle> In Proc. 1995 Int. Conf. Very Large Data Bases, </booktitle> <month> 420-431, </month> <title> Zurich, Switzerland. Exploration of the Power of Attribute-Oriented Induction in Data Mining 169 Han, </title> <editor> J., Fu, Y., and Ng, R. </editor> <year> 1994. </year> <title> Cooperative query answering using multiple-layered databases. </title> <booktitle> In Proc. 2nd Int. Conf. Cooperative Information Systems, </booktitle> <pages> 47-58, </pages> <address> Toronto, Canada. </address>
Reference-contexts: a given concept hierarchy may 1 the Natural Sciences and Engineering Research Council of Canada 154 Han & Fu The given and refined concept hierarchies for the attribute "province". not be best suited for a particular learning task, which therefore often needs to be dynamically refined for desired learning results <ref> (Han and Fu 1994) </ref>. Example 16.2 The given concept hierarchy for province (Figure 16.1 (a)), based on the geographic and administrative regions of Canada, may not reflect the characteristics of research grant distribution of Computer Science in Canada. <p> The refinement is performed by identifying and promoting "big" nodes and grouping the small ones while maximally preserving the original shape of the hierarchy (thus the semantic meaning) <ref> (Han and Fu 1994) </ref>. The refined hierarchy for the query of Example 16.1 is described in Figure 16.1 (b). 2 Different concept hierarchies can be constructed on the same attribute based on different viewpoints or preferences. <p> Besides threshold control, one may also allow a user to specify explicitly a level in the hierarchy as the level to be generalized. For mining characteristic rules, the attribute-oriented induction is performed in the following steps <ref> (Han and Fu 1994) </ref>. 1. Initial data collection: The data mining request is transformed into an SQL query and executed to collect the set of data relevant to the data mining task (as an initial relation). 2. <p> Knowledge discovery in object-oriented databases can be performed by first generalizing a set of complex data components into relatively simple generalized concepts and then applying the attribute-oriented induction method to generalize them into a generalized prime relation <ref> (Han, Nishio and Kawano 1994) </ref>. To facilitate generalization of complex data objects, it is important to implement efficiently a set of generalization operators on the components of object-oriented databases, including object identifiers, unstructured and structure values, class composition hierarchies, inherited and derived data, methods, etc., illustrated as follows. 1. <p> Such a rule can be stored as a part of the concept hierarchy and be used in generalization <ref> (Cheung, Fu and Han 1994) </ref>. 4. Rule-directed knowledge discovery: Certain rules can be used for directing a knowledge discovery process. <p> Exploration of the Power of Attribute-Oriented Induction in Data Mining 165 The spatial-dominant generalization first performs generalization on task-relevant spatial data using user/expert-provided spatial data hierarchies (such as geographic regions, etc.), hierarchical spatial data structures (such as R-trees, quad-trees, etc.), or spatial clustering algorithms <ref> (Ng and Han 1994) </ref> to generalize or cluster spatial data, and then generalize the nonspatial data associated with each spatial cluster or partition. <p> Thus it may not be suitable for mining knowledge without generalization or without background knowledge. Knowledge discovered by attribute-oriented induction has interesting applications at querying database knowledge, cooperative query answering, multiple layered database construction, and semantic query optimization, as reported in our previous studies <ref> (Han, Fu and Ng 1994) </ref>. In general, data mining provides a powerful tool for automatic generation and verification of knowledge in the construction of large knowledge-bases. Knowledge discovery represents an important and promising direction in the development of data and knowledge-base systems.
Reference: <author> Han, J., Nishio, S., and Kawano, H. </author> <year> 1994. </year> <title> Knowledge discovery in object-oriented and active databases. In Knowledge Building and Knowledge Sharing, </title> <editor> ed. F. Fuchi and T. </editor> <booktitle> Yokoi, </booktitle> <pages> 221-230. </pages> <publisher> Ohmsha, Ltd. and IOS Press. </publisher>
Reference-contexts: a given concept hierarchy may 1 the Natural Sciences and Engineering Research Council of Canada 154 Han & Fu The given and refined concept hierarchies for the attribute "province". not be best suited for a particular learning task, which therefore often needs to be dynamically refined for desired learning results <ref> (Han and Fu 1994) </ref>. Example 16.2 The given concept hierarchy for province (Figure 16.1 (a)), based on the geographic and administrative regions of Canada, may not reflect the characteristics of research grant distribution of Computer Science in Canada. <p> The refinement is performed by identifying and promoting "big" nodes and grouping the small ones while maximally preserving the original shape of the hierarchy (thus the semantic meaning) <ref> (Han and Fu 1994) </ref>. The refined hierarchy for the query of Example 16.1 is described in Figure 16.1 (b). 2 Different concept hierarchies can be constructed on the same attribute based on different viewpoints or preferences. <p> Besides threshold control, one may also allow a user to specify explicitly a level in the hierarchy as the level to be generalized. For mining characteristic rules, the attribute-oriented induction is performed in the following steps <ref> (Han and Fu 1994) </ref>. 1. Initial data collection: The data mining request is transformed into an SQL query and executed to collect the set of data relevant to the data mining task (as an initial relation). 2. <p> Knowledge discovery in object-oriented databases can be performed by first generalizing a set of complex data components into relatively simple generalized concepts and then applying the attribute-oriented induction method to generalize them into a generalized prime relation <ref> (Han, Nishio and Kawano 1994) </ref>. To facilitate generalization of complex data objects, it is important to implement efficiently a set of generalization operators on the components of object-oriented databases, including object identifiers, unstructured and structure values, class composition hierarchies, inherited and derived data, methods, etc., illustrated as follows. 1. <p> Such a rule can be stored as a part of the concept hierarchy and be used in generalization <ref> (Cheung, Fu and Han 1994) </ref>. 4. Rule-directed knowledge discovery: Certain rules can be used for directing a knowledge discovery process. <p> Exploration of the Power of Attribute-Oriented Induction in Data Mining 165 The spatial-dominant generalization first performs generalization on task-relevant spatial data using user/expert-provided spatial data hierarchies (such as geographic regions, etc.), hierarchical spatial data structures (such as R-trees, quad-trees, etc.), or spatial clustering algorithms <ref> (Ng and Han 1994) </ref> to generalize or cluster spatial data, and then generalize the nonspatial data associated with each spatial cluster or partition. <p> Thus it may not be suitable for mining knowledge without generalization or without background knowledge. Knowledge discovered by attribute-oriented induction has interesting applications at querying database knowledge, cooperative query answering, multiple layered database construction, and semantic query optimization, as reported in our previous studies <ref> (Han, Fu and Ng 1994) </ref>. In general, data mining provides a powerful tool for automatic generation and verification of knowledge in the construction of large knowledge-bases. Knowledge discovery represents an important and promising direction in the development of data and knowledge-base systems.
Reference: <author> Kivinen, J. and Mannila, H. </author> <year> 1994. </year> <title> The power of sampling in knowledge discovery. </title> <booktitle> In Proc. 13th ACM Symp. Principles of Database Systems, </booktitle> <pages> 77-85, </pages> <address> Minneapolis, MN.: </address> <publisher> ACM Press. </publisher>
Reference-contexts: Furthermore, with the association of count information, data sampling <ref> (Kivinen and Mannila 1994) </ref> and parallelism can be explored in knowledge discovery. Attribute 158 Han & Fu amount province total Alberta B.C.
Reference: <author> Matheus, C., Chan, P. K. and Piatetsky-Shapiro, G. </author> <year> 1993. </year> <title> Systems for knowledge discovery in databases. </title> <journal> IEEE Trans. Knowledge and Data Engineering, </journal> <volume> 5(6): </volume> <pages> 903-913. </pages>
Reference: <author> Michalski, R. S. </author> <year> 1983. </year> <title> A theory and methodology of inductive learning. </title> <booktitle> In Machine Learning: An Artificial Intelligence Approach, </booktitle> <volume> Vol. 1, </volume> <editor> ed. Michalski et al., </editor> <address> 83-134. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The method integrates a machine learning paradigm <ref> (Michalski 1983) </ref>, especially learning-from-examples techniques, with database operations, extracts generalized rules from an interesting set of data, and discovers high-level data regularities. The development of the attribute-oriented induction method is motivated by the following observations. <p> and allowing the same tuples appearing in different classes but with weights associated), or integrating with an ID3-like algorithm for further concept classification and compact rule generation. 16.3.2 Mining cluster description rules In a large database, it is often desirable to cluster data according to data semantics (called conceptual clustering <ref> (Michalski and Stepp 1983) </ref>) and associate (description) rules with such clusters. For example, students in a university can be clustered (i.e., classified) based on different attribute (s), including major, age, height, academic performance, etc., however, clustering on one attribute may generate more meaningful and concise descriptions than that on another.
Reference: <author> Michalski, R. S., Carbonell, J. G. and Mitchell, T. M. </author> <year> 1986. </year> <title> Machine Learning, </title> <booktitle> An Artificial Intelligence Approach, </booktitle> <volume> Vol. 2. </volume> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: A simple method is to project on different sets of attributes to extract different generalized feature tables. Example 16.3 shows a prime relation and a feature table for count% in relevance to amount and province. Moreover, many techniques developed in previous studies on machine learning <ref> (Michalski, Carbonell and Mitchell 1986) </ref>, statistics, fuzzy set and rough set theories (Ziarko 1994), etc. can be applied to the evaluation of the importance of different sets of attributes and projection on the appropriate ones. 3. Further generalization of the prime relation.
Reference: <author> Michalski, R. S., Kerschberg, L., Kaufman, K. A. and Ribeiro, J. S. </author> <year> 1992. </year> <title> Mining for knowledge in databases: The INLEN architecture, initial implementation and first results. </title> <journal> J. Int. Info. Systems, </journal> <volume> 1 </volume> <pages> 85-114. </pages>
Reference: <author> Michalski, R. S. and Stepp, R. </author> <year> 1983. </year> <title> Automated construction of classifications: Conceptual clustering versus numerical taxonomy. </title> <journal> IEEE Trans. Pattern Analysis and Machine Intelligence, </journal> <volume> 5 </volume> <pages> 396-410. </pages>
Reference-contexts: The method integrates a machine learning paradigm <ref> (Michalski 1983) </ref>, especially learning-from-examples techniques, with database operations, extracts generalized rules from an interesting set of data, and discovers high-level data regularities. The development of the attribute-oriented induction method is motivated by the following observations. <p> and allowing the same tuples appearing in different classes but with weights associated), or integrating with an ID3-like algorithm for further concept classification and compact rule generation. 16.3.2 Mining cluster description rules In a large database, it is often desirable to cluster data according to data semantics (called conceptual clustering <ref> (Michalski and Stepp 1983) </ref>) and associate (description) rules with such clusters. For example, students in a university can be clustered (i.e., classified) based on different attribute (s), including major, age, height, academic performance, etc., however, clustering on one attribute may generate more meaningful and concise descriptions than that on another.
Reference: <author> Ng, R. and Han, J. </author> <year> 1994. </year> <title> Efficient and effective clustering method for spatial data mining. </title> <booktitle> In Proc. 1994 Int. Conf. Very Large Data Bases, </booktitle> <pages> 144-155, </pages> <address> Santiago, Chile. </address>
Reference-contexts: Exploration of the Power of Attribute-Oriented Induction in Data Mining 153 Example 16.1 The following query, presented in an SQL-like syntax, requests to use the database "NSERC94" <ref> (containing the information about 1994-1995 NSERC 1 research grants) </ref>, and find a characteristic rule from two relations, award and organization, which satisfies the condition specified in the where-clause and in relevance to four attributes: province, amount, percentage (count), percentage (amount), where percentage (x) = x=total x% (the ratio of x versus <p> Such a rule can be stored as a part of the concept hierarchy and be used in generalization <ref> (Cheung, Fu and Han 1994) </ref>. 4. Rule-directed knowledge discovery: Certain rules can be used for directing a knowledge discovery process. <p> Exploration of the Power of Attribute-Oriented Induction in Data Mining 165 The spatial-dominant generalization first performs generalization on task-relevant spatial data using user/expert-provided spatial data hierarchies (such as geographic regions, etc.), hierarchical spatial data structures (such as R-trees, quad-trees, etc.), or spatial clustering algorithms <ref> (Ng and Han 1994) </ref> to generalize or cluster spatial data, and then generalize the nonspatial data associated with each spatial cluster or partition. <p> Thus it may not be suitable for mining knowledge without generalization or without background knowledge. Knowledge discovered by attribute-oriented induction has interesting applications at querying database knowledge, cooperative query answering, multiple layered database construction, and semantic query optimization, as reported in our previous studies <ref> (Han, Fu and Ng 1994) </ref>. In general, data mining provides a powerful tool for automatic generation and verification of knowledge in the construction of large knowledge-bases. Knowledge discovery represents an important and promising direction in the development of data and knowledge-base systems.
Reference: <author> Piatetsky-Shapiro, G. and Frawley, W. J. </author> <year> 1991. </year> <title> Knowledge Discovery in Databases. </title> <publisher> AAAI/MIT Press. </publisher>
Reference: <author> Piatetsky-Shapiro, G. </author> <year> 1991. </year> <title> Discovery, analysis, and presentation of strong rules. In Knowledge Discovery in Databases, </title> <editor> ed. G. Piatetsky-Shapiro and W. J. Frawley, </editor> <address> 229-238. </address> <publisher> AAAI/MIT Press. </publisher>
Reference: <author> Quinlan, J. R. </author> <year> 1992. </year> <title> C4.5: Programs for Machine Learning. </title> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: This method summarizes the major differences of a target class from a contrasting class at a high concept level. Notice that machine learning techniques, such as a decision-tree method like ID3 (Quinlan 1986) and C4.5 <ref> (Quinlan 1992) </ref>, have been used to classify objects and find discriminating behaviors.
Reference: <author> Quinlan, J. R. </author> <year> 1986. </year> <title> Induction of decision trees. </title> <journal> Machine Learning, </journal> <volume> 1 </volume> <pages> 81-106. </pages>
Reference-contexts: This method summarizes the major differences of a target class from a contrasting class at a high concept level. Notice that machine learning techniques, such as a decision-tree method like ID3 <ref> (Quinlan 1986) </ref> and C4.5 (Quinlan 1992), have been used to classify objects and find discriminating behaviors. <p> Examples in ID3 or C4.5 algorithms assume that concepts to be classified are already at a relatively high level, such as "mild" (temperature) and "high" (humidity) <ref> (Quinlan 1986) </ref>, which may not be the cases for the actual data stored in large databases 160 Han & Fu but can be easily achieved by attribute-oriented generalization. <p> An alternative (but of the same spirit) conceptual clustering method is to first perform attribute-oriented induction as described above, and then construct a decision tree from the generalized relation using a method similar to ID3 <ref> (Quinlan 1986) </ref> and associate the corresponding rules with each node in the tree. Exploration of the Power of Attribute-Oriented Induction in Data Mining 161 16.3.3 Mining multiple-level association rules An association rule represents an association relationship among a set of patterns (values) in a database (Agrawal, Imielinski and Swami 1993).
Reference: <author> Shen, W., Mitbander, B., Ong, K. and Zaniolo, C. </author> <year> 1994. </year> <title> Using metaqueries to integrate inductive learning and deductive database technology. </title> <booktitle> In Proc. AAAI'94 Workshop on Knowledge Discovery in Databases (KDD'94), </booktitle> <pages> 335-346, </pages> <address> Seattle, WA.: </address> <publisher> AAAI Press. </publisher> <editor> 170 Han & Fu Uthurusamy, R., Fayyad, U. M. and Spangler, S. </editor> <year> 1991. </year> <title> Learning useful rules from inconclusive data. In Knowledge Discovery in Databases, </title> <editor> ed. G. Piatetsky-Shapiro and W. J. Frawley, </editor> <address> 141-158. </address> <publisher> AAAI/MIT Press. </publisher>
Reference-contexts: Rule-directed knowledge discovery: Certain rules can be used for directing a knowledge discovery process. For example, "A ^ B ! C" can be used as a meta-rule to inform the system to find rules in such a logical form from a large set of data <ref> (Shen et al. 1994) </ref>.
Reference: <author> Ziarko, W. </author> <year> 1994. </year> <title> Rough Sets, Fuzzy Sets and Knowledge Discovery. </title> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Example 16.3 shows a prime relation and a feature table for count% in relevance to amount and province. Moreover, many techniques developed in previous studies on machine learning (Michalski, Carbonell and Mitchell 1986), statistics, fuzzy set and rough set theories <ref> (Ziarko 1994) </ref>, etc. can be applied to the evaluation of the importance of different sets of attributes and projection on the appropriate ones. 3. Further generalization of the prime relation.
Reference: <author> Zytkow J. and Baker, J. </author> <year> 1991. </year> <title> Interactive mining of regularities in databases. In Knowledge Discovery in Databases, </title> <editor> ed. G. Piatetsky-Shapiro and W. J. Frawley, </editor> <address> 31-54. </address> <publisher> AAAI/MIT Press. </publisher>
Reference-contexts: Following different paths corresponds to the way in which different people may learn differently from the same set of examples. The generalized relations can be examined by users or experts interactively to filter out trivial rules and preserve interesting ones <ref> (Zytkow and Baker 1991) </ref>. Therefore, a user-friendly graphical interface is implemented in DBMiner for users to try different alternatives for interactive mining of desired rules. Example 16.3 Following Example 16.1, part of an original relation, award, is shown in Table 16.1. Part of the prime relation is in Table 16.2.
References-found: 24

