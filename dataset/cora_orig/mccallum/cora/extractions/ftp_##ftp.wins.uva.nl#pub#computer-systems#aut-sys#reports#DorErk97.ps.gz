URL: ftp://ftp.wins.uva.nl/pub/computer-systems/aut-sys/reports/DorErk97.ps.gz
Refering-URL: http://www.fwi.uva.nl/research/neuro/publications/publications.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: leo@wins.uva.nl  
Title: Generating effective exploration from a sensor space representation of robot perception  
Author: Leo Dorst, Heleen Erkamp 
Keyword: navigation, exploration, geometric representation, sensor space, distance senors  
Note: Submitted to: AFPAC'97: Algebraic Frames for the Perception-Action Cycle,  
Date: April 14, 1997  September 8-9, 1997.  
Address: Kruislaan 403, NL-1098 SJ Amsterdam, The Netherlands  Kiel, Germany,  
Affiliation: RWCP Novel Functions: SNN Laboratory Amsterdam, Dept. of Mathematics, Computer Science, Physics and Astronomy, University of Amsterdam,  
Abstract: When a mobile robot moves around in an unknown world, without a way of establishing its position, it needs to use its sensor data to navigate. The common approach is to interpret the sensor data to a geometrical model of the environment, and base the navigation and exploration strategies on that model. In this paper, we attempt to generate explorative motions based on the raw sensor data, for the special, idealized case of a robot with exact noise-free distance sensors in a rectangular room. In the space spanned by the sensor values, the environment is represented by subsurface of a dimensionality equal to the number of degrees of freedom of motion. Exploration is: establishing this surface; navigation is: using it to generate goal-directed motions. We show that the approach seems promising in simple cases, but touch on the difficulties in extending it to more realistic situations, arising from the awkward properties of the sensor space subsurface in the general case: discontinuity, self-intersection, and degeneracy. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> B. Donald, J. Jennings, </author> <title> Sensor interpretation and task-directed planning using perceptual equivalence classes, </title> <booktitle> Proc. IEEE 1991 ICRA, </booktitle> <address> Sacramento, CA, </address> <year> 1991, </year> <pages> pp. 190-197. </pages>
Reference-contexts: But recently, some work has been done in seeing how far the robot could get on the basis of sensory data alone, with minimal capabilities. To get the maximum out of this limited data, one needs to use all structure present in it. Donald and Jennings <ref> [1] </ref> have made a formal study of the algebraic structure of the sensory data (it forms a lattice), and especially of the coarseness of the `perceptual equivalence classes' of non-distinguishable locations. Kuipers [5] used a hierarchical model based on sensor values. <p> These we call facets (the surface looks like that of a diamond), each facet can be characterized by the aspect class [W (s 1 ); W (s 2 ); W (s 3 )] (together with the orientation ). The aspect classes are what <ref> [1] </ref> calls the perceptual equivalence classes. Since this term might be applied to boths aspects and facets, we have preferred to distinguish the two by giving them different names in this paper ([1] works mostly in task space and does not need to distinguish the two). 3 Examples of sensor spaces <p> In this paper, we stop at three, to retain the degeneracy in our sensor surface, and to meet the challenge of working with it. If we succeed, we will be able to group sensors at random, since degeneracies will not bother us. Donald and Jennings <ref> [1] </ref> show that the relationship between the various perceptual equivalence classes when switching on or off sensors is algebraically a lattice.
Reference: [2] <author> L. Dorst, I. Mandhyan, K.I. Trovato, </author> <title> The Geometrical Representation of Path Planning Problems, </title> <booktitle> Robotics and Autonomous Systems, </booktitle> <publisher> Elsevier, </publisher> <address> vol.7, </address> <year> 1991, </year> <note> pp.181-195. Available at http://carol.wins.uva.nl/ ~ leo/papers/ias.html </note>
Reference-contexts: 1 Towards minimal world representations for navigation and exploration Robot motion planning has traditionally taken rather involved representations in which to perform its computations: sensor data is made into a geometrical model of the task space, which may subsequently be re-represented in configuration space <ref> [2, 6] </ref>. But recently, some work has been done in seeing how far the robot could get on the basis of sensory data alone, with minimal capabilities. To get the maximum out of this limited data, one needs to use all structure present in it.
Reference: [3] <author> H. Erkamp, </author> <title> A representation in sensor values of an unknown environment through exploration of a mobile robot, </title> <type> Master's Thesis, </type> <institution> University of Amsterdam, </institution> <year> 1996. </year> <note> Available at http://www.fwi.uva.nl/research/neuro/publications/publications.html. </note>
Reference-contexts: That prompted us to a more detailed analysis of the kind of sensor spaces they were dealing with, based on simplified distance sensors in idealized office-like environments. This led to a Master's thesis <ref> [3] </ref>, the companion to this paper. <p> The three points can still be used for computation of ^ a, but the computation of the Jacobian (see section 4.4) will give the wrong result since part of the actual motion in task space does not lead to a change in the corresponding point in sensor space. (In <ref> [3] </ref> and this paper, we check this in postprocessing, but it would be better to resolve this locally and make it lead to a regeneration of the points Q and R. <p> We have chosen in <ref> [3] </ref> to go the closest point s to p in sensor space (this seems to work well enough for our situation, but more search along the line might be needed in general rooms). <p> Furthermore, the graph could be checked for other connections that have never been observed, but that can be inferred from the data gathered. This deduction contains some pitfalls (see <ref> [3] </ref>) which are unsolved, and therefore we do not perform postprocessing at present. 5 Some test results The exploration algorithms were implemented in our robot simulator. <p> We show the graphs found; missing nodes (which did not occur) and missing edges are dashed. For clarity, the boundaries of the aspect classes have been drawn in the figures. The difficult node for a degenerate facet is indicated in grey. Extended results are given in <ref> [3] </ref>. We illustrate some of the findings: * IP-test without Jacobian moves The top pair in figure 8 shows an exploration using the IP-test to determine whether a boundary has been crossed; no exploration of a possible connection between facets is performed, just the neighbor test of eq.(14).
Reference: [4] <author> B.J.A. Krose and M. Eecen, </author> <title> A self-organizing representation of sensor space for mobile robot navigation, </title> <booktitle> in Proceedings of the IEEE/RSJ/GI International Conference on Intelligent Robots and Systems, </booktitle> <pages> pages 9-14. </pages> <note> Published by IEEE, 1994. Available at http://www.fwi.uva.nl/research/neuro/publications/publications.html. </note>
Reference-contexts: Donald and Jennings [1] have made a formal study of the algebraic structure of the sensory data (it forms a lattice), and especially of the coarseness of the `perceptual equivalence classes' of non-distinguishable locations. Kuipers [5] used a hierarchical model based on sensor values. Krose and Eecen <ref> [4] </ref> attempted to impose a Kohonen neural network onto the hypersurface of sensor values induced by the environment of a mobile robot in an office. Estimating the local dimension of the sensory subspace using principal component analysis (a check to find how wild the hypersurface was) gave strange results.
Reference: [5] <author> B. Kuipers, Y. Byun, </author> <title> A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations, </title> <type> TR, </type> <institution> Austin, Texas, </institution> <year> 1990. </year>
Reference-contexts: Donald and Jennings [1] have made a formal study of the algebraic structure of the sensory data (it forms a lattice), and especially of the coarseness of the `perceptual equivalence classes' of non-distinguishable locations. Kuipers <ref> [5] </ref> used a hierarchical model based on sensor values. Krose and Eecen [4] attempted to impose a Kohonen neural network onto the hypersurface of sensor values induced by the environment of a mobile robot in an office.
Reference: [6] <author> J.-C. Latombe, </author> <title> Robot motion planning, </title> <publisher> Kluwer Academic, </publisher> <address> Boston, </address> <year> 1991. </year>
Reference-contexts: 1 Towards minimal world representations for navigation and exploration Robot motion planning has traditionally taken rather involved representations in which to perform its computations: sensor data is made into a geometrical model of the task space, which may subsequently be re-represented in configuration space <ref> [2, 6] </ref>. But recently, some work has been done in seeing how far the robot could get on the basis of sensory data alone, with minimal capabilities. To get the maximum out of this limited data, one needs to use all structure present in it.
Reference: [7] <author> D.F. Stubbs and N.W. Webre, </author> <title> Data structures with abstract data types and Pascal, </title> <publisher> Brooks/Cole Publishing Company, </publisher> <year> 1989 </year> <month> 18 </month>
Reference-contexts: From this one can compute the cone of normal directions to the intersection line of the facets, if required. The graph is implemented as adjacency lists (see <ref> [7] </ref>). The basic exploration algorithm is indicated in figure 7. We discuss the mathematics and details behind each of the steps. 4.1 Notation We need to quantify the faceted sensor surface in the sensor space of the robot.
References-found: 7

