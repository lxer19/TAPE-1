URL: http://www.cs.ucsd.edu/~calder/papers/POPL-94.ps.Z
Refering-URL: http://www.cs.ucsd.edu/~calder/papers.html
Root-URL: http://www.cs.ucsd.edu
Email: (Email:fcalder,grunwaldg@cs.colorado.edu)  
Phone: 430,  
Title: Reducing Indirect Function Call Overhead In C++ Programs  
Author: Brad Calder and Dirk Grunwald 
Keyword: Object oriented programming, optimization, profile-based optimization, customization  
Address: Campus Box  Boulder, CO 80309-0430  
Affiliation: Department of Computer Science,  University of Colorado,  
Abstract: Modern computer architectures increasingly depend on mechanisms that estimate future control flow decisions to increase performance. Mechanisms such as speculative execution and prefetching are becoming standard architectural mechanisms that rely on control flow prediction to prefetch and speculatively execute future instructions. At the same time, computer programmers are increasingly turning to object-oriented languages to increase their productivity. These languages commonly use run time dispatching to implement object polymorphism. Dispatching is usually implemented using an indirect function call, which presents challenges to existing control flow prediction techniques. We have measured the occurrence of indirect function calls in a collection of C++ programs. We show that, although it is more important to predict branches accurately, indirect call prediction is also an important factor in some programs and will grow in importance with the growth of object-oriented programming. We examine the improvement offered by compile-time optimizations and static and dynamic prediction techniques, and demonstrate how compilers can use existing branch prediction mechanisms to improve performance in C++ programs. Using these methods with the programs we examined, the number of instructions between mispredicted breaks in control can be doubled on existing computers. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Robert Alverson, David Callahan, Daniel Cummings, Brian Koblenz, Allan Porterfield, and Burton Smith. </author> <title> The tera computer system. </title> <booktitle> In Proc. 17th Annual Symposium on Computer Architecture, Computer Architecture News, </booktitle> <pages> pages 1-6, </pages> <address> Ams-terdam, Netherlands, </address> <month> June </month> <year> 1990. </year> <note> ACM, ACM. </note>
Reference-contexts: The advantage of these bit-table techniques is that they keep track of very little information per branch site and are very effective in practice. Lastly, some computers use explicit branch target addressregis-ters (BTARs) to specify the branch target <ref> [11, 1] </ref>. This has numerous advantages, because branch instructions are very compact and easily decoded. BTARs can be applied to both conditional branches and function calls, and the instructions loading branch targets can be moved out of loops or optimized in other ways. <p> Furthermore, addresses specified by explicit branch target registers provide additional hints to instruction caches, and those instructions can be prefetched and decoded early. However, most proposed implementations provide only 4-8 BTARs <ref> [1] </ref>. The contents of these registers will probably not be saved across function calls. Thus, instructions manipulating the BTARs must occur early in the instruction stream to effectively use BTARs.
Reference: [2] <author> T. Ball and J. R. Larus. </author> <title> Branch prediction for free. </title> <booktitle> In 1993 SIGPLAN Confernce on Programming Language Design and Implementation. ACM, </booktitle> <month> June </month> <year> 1993. </year>
Reference-contexts: Rather than present a comprehensive overview of the field, we focus on methods related to the techniques we consider in this paper. Some architectures employ static prediction hints using either profile-derived information, information derived from compile time analysis or information about the branch direction or branch op-code <ref> [25, 20, 2] </ref>. Wall [26] found profile-driven static prediction to be reasonably accurate for indirect function calls.
Reference: [3] <author> T. Ball and J.R. Larus. </author> <title> Optimally profiling and tracing programs. </title> <booktitle> In Conference Record of the 19th Annual ACM Symposium on Principles of Programming Languages, </booktitle> <pages> pages 59-70, </pages> <address> Albuquerque, NM, </address> <month> January </month> <year> 1992. </year>
Reference-contexts: Later, we show how profile-based I-call if conversion can use these mechanisms. 3 Experimental Design Our comparison used trace-based simulation. We instrumented a number of C++ programs, listed in Table 1, using a modified version of the QPT <ref> [3] </ref> program tracing tool. We emphasized programs using existing C++ class libraries or that structured the application in a modular, extensible fashion normally associated with object-oriented design. A more extensive comparison between the characteristics of C and C++ programs can be found in [7].
Reference: [4] <author> Michael Burke. </author> <title> An interval-based approach to exhcaustive and incremental interprocedural analysis. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 12(3) </volume> <pages> 341-395, </pages> <month> July </month> <year> 1990. </year>
Reference-contexts: Ryder [24] presented a method for computing the call-graph, or set of functions, that may be called by each call site using dataflow equations. More recent work by Burke <ref> [4] </ref> and Hall [13] has refined this technique. All of this work characterized programs where procedure values may be passed as function parameters. Others, including Hall [13], also examine functional programs.
Reference: [5] <author> Brad Calder and Dirk Grunwald. </author> <title> Branch alignment. </title> <note> Technical Report (In Preperation), </note> <institution> Univ. of Colorado-Boulder, </institution> <year> 1993. </year>
Reference-contexts: These designs use the branch site address as an index into a table of prediction bits. This information can actually be the prediction information for another branch. However, there's at least a 50% chance the prediction information is correct, and this can be improved somewhat <ref> [5] </ref>. The most common variants of table-based designs are 1-bit techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit techniques that yield much better performance for programs with loops [25, 17, 20].
Reference: [6] <author> Brad Calder and Dirk Grunwald. </author> <title> Fast & accurate instruction fetch and branch prediction. </title> <institution> CU-CS xxx, Univ. of Colorado, </institution> <month> October </month> <year> 1993. </year> <note> (In preperation). </note>
Reference-contexts: These control-transfer instructions, conditional branches and I-calls can also cause an instruction misfetch penalty because they must be decoded before the instruction stream knows the instruction type. Thus, the instruction fetch unit may incorrectly fetch the next instruction, rather than the target destination. In another paper <ref> [6] </ref>, we show how these misfetch penalties can be avoided using extra instruction type bits and/or a simple instruction type prediction table, coupled with the techniques discussed in this paper. If we are only considering conditional branches and indirect calls. <p> 94.1 morpher 51.9 85.8 74.0 90.0 85.1 91.3 87.9 91.6 rtsh 71.6 80.2 72.6 80.4 95.0 85.1 130.5 89.1 HM / Avg 60.7 85.0 71.1 86.9 106.5 91.6 125.5 92.9 Table 7: Measurements of breaks that can be predicted using compile-time and static I-call prediction with 2-Bit branch prediction. resources <ref> [6] </ref>. It is likely that our prediction architecture would benefit from a small 2-bit prediction mechanism for indirect function calls. The last prediction mechanism we considered was branch target address registers (BTAR's).
Reference: [7] <author> Brad Calder, Dirk Grunwald, and Benjamin Zorn. </author> <title> Exploiting behavioral differences between C and C++ programs. </title> <note> Technical Report (In Preperation), </note> <institution> Univ. of Colorado-Boulder, </institution> <year> 1993. </year>
Reference-contexts: We measured the behavior of a variety of publicly available C++ programs, collecting information on instruction counts and function calls. This information is also part of a larger study to quantify the differences between C++ and conventional C programs <ref> [7] </ref>. In this study, we show that call prediction is important for many C++ programs and show to what extent static, dynamic and compile-directed methods can reduce indirect function call overhead. We also demonstrate the opportunity for profile-based optimization in the C++ programs we measured. <p> We emphasized programs using existing C++ class libraries or that structured the application in a modular, extensible fashion normally associated with object-oriented design. A more extensive comparison between the characteristics of C and C++ programs can be found in <ref> [7] </ref>. Empirical computer science is a labour-intensive undertaking. The programs were compiled and processed on DECstation 5000's. Three C++ compilers (Gnu G++, DEC C++, AT&T C++ V3.0.2) were required to successfully compile all programs; much of this occurred because the C++ language is not standardized. <p> A C++ programmer, on the other hand, would tend to use inheritance and the object model to provide similar functionality. Thus, it is not surprising that C++ programs tend to have more procedure calls and fewer conditional operations <ref> [7] </ref>. In the remaining tables, we only show the mean NIBB for each program and use the harmonic mean of the NIBB as a summary. We also use the percent of breaks predicted (%BP) to understand how well various techniques predict breaks.
Reference: [8] <author> Craig Chambers and David Ungar. </author> <title> Customization: optimizing compiler technology for SELF, a dynamically-typed object-oriented programming language. </title> <booktitle> In Proceedings of the ACM SIGPLAN '89 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 146-160, </pages> <address> Portland, OR, </address> <month> June </month> <year> 1989. </year>
Reference-contexts: By comparison, there has been considerable work in adaptive runtime systems to reduce the cost of polymorphism in dynamically typed languages. Most recent, and foremost, in these efforts is the work by the SELF project <ref> [8, 9, 14] </ref> on customization of method dispatches and extensive optimization of method lookup. SELF is a dynamicly-typed language, providing a rich set of capabilities not present in statically-typed languages such as C++. However, statically-typed languages such as C++ are very efficient, using a constant-time method dispatch mechanism.
Reference: [9] <author> Craig Chambers and David Ungar. </author> <title> Iterative type analysis and extended message splitting: optimizing dynamically-typed object-oriented programs. </title> <booktitle> In Proceedings of the ACM SIG-PLAN '90 Conference on Programming Language Design and Implementation, </booktitle> <pages> pages 150-164, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: By comparison, there has been considerable work in adaptive runtime systems to reduce the cost of polymorphism in dynamically typed languages. Most recent, and foremost, in these efforts is the work by the SELF project <ref> [8, 9, 14] </ref> on customization of method dispatches and extensive optimization of method lookup. SELF is a dynamicly-typed language, providing a rich set of capabilities not present in statically-typed languages such as C++. However, statically-typed languages such as C++ are very efficient, using a constant-time method dispatch mechanism.
Reference: [10] <author> Jack W. Davidson and Anne M. Holler. Subprogram inlin-ing: </author> <title> A study of its effects on program execution time. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 18(2) </volume> <pages> 89-102, </pages> <month> Febru-ary </month> <year> 1992. </year>
Reference-contexts: Existing branch prediction hardware may be able to improve on strictly profile-based prediction because it can accommodate bursts of calls to a secondary call target. Although inlining functions is useful, it does not always reduce program execution time <ref> [10] </ref>. However, many indirect function calls in C++ tend to be very short, because programmers are more likely to employ proper data encapsulation techniques. We believe automatic inlining will be more useful for C++ than C.
Reference: [11] <author> Jack W. Davidson and D.B. Whalley. </author> <title> Reducing the cost of branches by using registers. </title> <booktitle> In Proceedings of the 17th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 182-191, </pages> <address> Los Alamitos, CA, </address> <month> May </month> <year> 1990. </year>
Reference-contexts: The advantage of these bit-table techniques is that they keep track of very little information per branch site and are very effective in practice. Lastly, some computers use explicit branch target addressregis-ters (BTARs) to specify the branch target <ref> [11, 1] </ref>. This has numerous advantages, because branch instructions are very compact and easily decoded. BTARs can be applied to both conditional branches and function calls, and the instructions loading branch targets can be moved out of loops or optimized in other ways.
Reference: [12] <author> J. A. Fisher and S. M. Freudenberger. </author> <title> Predicting conditional branch directions from previous runs of a program. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 85-95, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: Most function calls specify explicit call targets, and thus most function calls can be trivially predicted. Control flow prediction is just as important in object-oriented programs, but these languages tend to use indirect function calls, where the address of the call target is loaded from memory. Fisher et al <ref> [12] </ref> said indirection function calls : : : are unavoidable breaks in control and there are few compiler or hardware tricks that could allow instruction-level parallelism to advance past them. By accurately predicting the calling address, the processor can reduce instruction stalls and prefetch instructions. <p> Some architectures employ static prediction hints using either profile-derived information, information derived from compile time analysis or information about the branch direction or branch op-code [25, 20, 2]. Wall [26] found profile-driven static prediction to be reasonably accurate for indirect function calls. Fisher and Freudenberger <ref> [12] </ref> found profile-derived static prediction to be effective for conditional branches, but they hypothesize that inter-run variations occurred because prior input did not cover sufficient execution paths, and our results provide support for their hypothesis. <p> In our experience, this usually occurs because the inputs, that were used to establish the profile used to predict the branches and I-calls, did not provide adequate coverage of all the branches and indirect function calls. This problem has been mentioned by others <ref> [26, 12] </ref>, but has not be studied in detail. Table 4 also shows the effectiveness of idealized dynamic prediction techniques. We simulated two infinitely large Branch Target Buffers.
Reference: [13] <author> Mary W. Hall and Ken Kennedy. </author> <title> Efficient call graph analysis. </title> <journal> Letters on Programming Languages and Systems, </journal> <volume> 1(3) </volume> <pages> 227-242, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Ryder [24] presented a method for computing the call-graph, or set of functions, that may be called by each call site using dataflow equations. More recent work by Burke [4] and Hall <ref> [13] </ref> has refined this technique. All of this work characterized programs where procedure values may be passed as function parameters. Others, including Hall [13], also examine functional programs. <p> More recent work by Burke [4] and Hall <ref> [13] </ref> has refined this technique. All of this work characterized programs where procedure values may be passed as function parameters. Others, including Hall [13], also examine functional programs. More recently, Pande and Ryder [22] have shown that inferring the set of call targets for call sites in languages with the C++ type system is a NP-hard problem.
Reference: [14] <author> Urs Holzle, Craig Chambers, and David Unger. </author> <title> Optimizating dynamically-typed object-orientred languages with polymorphic inlines caches. </title> <booktitle> In ECCOP '91 Proc. </booktitle> <publisher> Springer-Verlag, </publisher> <month> July </month> <year> 1991. </year>
Reference-contexts: By comparison, there has been considerable work in adaptive runtime systems to reduce the cost of polymorphism in dynamically typed languages. Most recent, and foremost, in these efforts is the work by the SELF project <ref> [8, 9, 14] </ref> on customization of method dispatches and extensive optimization of method lookup. SELF is a dynamicly-typed language, providing a rich set of capabilities not present in statically-typed languages such as C++. However, statically-typed languages such as C++ are very efficient, using a constant-time method dispatch mechanism. <p> SELF uses an inline cache to speed indirect function calls. The inline cache records the last target address for each call site; when a method is called, the jump target is recovered from the software cache. In <ref> [14] </ref>, Holzle et al found that they could improve performance by converting an inline cache access into a polymorphic inline cache (PIC) lookup. The PIC encodes a data-dependent type check in a stub procedure, dynamically modifying the program; this reduces searching for the appropriate method for a given data type.
Reference: [15] <author> David R. Kaeli and Philip G. Emma. </author> <title> Branch history table prdiction of moving target branches due to subroutine returns. </title> <booktitle> In 18th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 34-42. </pages> <publisher> ACM, </publisher> <month> May </month> <year> 1991. </year>
Reference-contexts: We tracked only breaks in control flow that will cause a long pipeline delay. These breaks are conditional branches and indirect calls. Returns also cause a long pipeline stall, but returns can be accurately predicted by using a return stack <ref> [15] </ref>, and we did not track these. We assume that unconditional branches, procedure calls and assigned gotos are accurately predicted. These control-transfer instructions, conditional branches and I-calls can also cause an instruction misfetch penalty because they must be decoded before the instruction stream knows the instruction type.
Reference: [16] <author> M. S. Lam and R. P. Wilson. </author> <title> Limits of control flow on parallelism. </title> <booktitle> In 19th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 46-57, </pages> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: This increases if the mispredicted target is not in the instruction cache and must be fetched. As systems increasingly rely on speculative execution <ref> [19, 16] </ref>, the importance of control flow prediction will increase. In most programs, conditional branches introduce the main uncertainty in program flow, and architectures use a variety of branch prediction techniques to reduce instruction cache misses and to insure instructions are available for the processor pipeline.
Reference: [17] <author> Johnny K. F. Lee and Alan Jay Smith. </author> <title> Branch prediction strategies and branch target buffer design. </title> <journal> IEEE Computer, </journal> <volume> ??(??):6-22, </volume> <month> January </month> <year> 1984. </year>
Reference-contexts: In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on branch prediction or instruction opcodes. Some architectures use dynamic prediction, either using tables or explicit branch registers. A branch target buffer (BTB) <ref> [17, 23] </ref> is a small cache holding the address of branch sites and the address of branch targets. There are myriad variations on the general idea. Typically, the cache contains from 32 to 512 entries and may be 2 or 4-way associative. <p> The most common variants of table-based designs are 1-bit techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit techniques that yield much better performance for programs with loops <ref> [25, 17, 20] </ref>. The advantage of these bit-table techniques is that they keep track of very little information per branch site and are very effective in practice. Lastly, some computers use explicit branch target addressregis-ters (BTARs) to specify the branch target [11, 1].
Reference: [18] <author> David J. Lilja. </author> <title> Reducing the branch penalty in pipelined processors. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 47-55, </pages> <month> July </month> <year> 1988. </year>
Reference-contexts: dynamic method lookups are not implemented as indirect jump instructions. 2.2 Branch Prediction There are a number of mechanisms to ameliorate the effect of uncertain control flow changes, including static and dynamic branch prediction, branch target buffers, delayed branches, prefetching both targets, early branch resolution, branch bypassing and prepare-to-branch mechanisms <ref> [18] </ref>. Conventional branch prediction studies typically assume there are two possible branch targets for a given branch point, because multi-target branches occur infrequently in most programs. Rather than present a comprehensive overview of the field, we focus on methods related to the techniques we consider in this paper.
Reference: [19] <author> M. S. Lam M. D. Smith, M. Horowitz. </author> <title> Efficient superscalar performance through boosting. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 248-259, </pages> <address> Boston, Mass., Oc-tober 1992. </address> <publisher> ACM. </publisher>
Reference-contexts: This increases if the mispredicted target is not in the instruction cache and must be fetched. As systems increasingly rely on speculative execution <ref> [19, 16] </ref>, the importance of control flow prediction will increase. In most programs, conditional branches introduce the main uncertainty in program flow, and architectures use a variety of branch prediction techniques to reduce instruction cache misses and to insure instructions are available for the processor pipeline.
Reference: [20] <author> Scott McFarling and John Hennessy. </author> <title> Reducing the cost of branches. </title> <booktitle> In 13th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 396-403. </pages> <publisher> ACM, </publisher> <year> 1986. </year>
Reference-contexts: Rather than present a comprehensive overview of the field, we focus on methods related to the techniques we consider in this paper. Some architectures employ static prediction hints using either profile-derived information, information derived from compile time analysis or information about the branch direction or branch op-code <ref> [25, 20, 2] </ref>. Wall [26] found profile-driven static prediction to be reasonably accurate for indirect function calls. <p> The most common variants of table-based designs are 1-bit techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit techniques that yield much better performance for programs with loops <ref> [25, 17, 20] </ref>. The advantage of these bit-table techniques is that they keep track of very little information per branch site and are very effective in practice. Lastly, some computers use explicit branch target addressregis-ters (BTARs) to specify the branch target [11, 1].
Reference: [21] <author> S.-T. Pan, K. So, and J. T. Rahmeh. </author> <title> Improving the accuracy of dynamic branch prediction using branch correlation. </title> <booktitle> In Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 76-84, </pages> <address> Boston, Mass., </address> <month> October </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: We have measured programs with 191 different subroutines called from a single indirect function call. This makes branches easier to predict. Some dynamic branch prediction mechanisms achieve 95%97% prediction accuracy <ref> [21, 27, 29] </ref>. This level of accuracy is needed for super-scalar processors issuing several instructions per cycle [28]. The most relevant prior work was on predicting the destination of indirect function calls with hardware conducted by David Wall [26] while examining limits to instruction level parallelism.
Reference: [22] <author> Hemant D. Pande and Barbera G. Ryder. </author> <title> Static type determination for C++. </title> <type> Technical Report LCSR-TR-197, </type> <institution> Rutgers Univ., </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: Likewise, compilers may choose to inline likely or unique call targets. Inlining I-calls not only reduces the number of function calls, it exposes opportunities for other optimizations such as better register allocation, constant folding, code scheduling and the like. However, type inferencing for C++ programs is an NP-hard problem <ref> [22] </ref>, and will be difficult to integrate into existing compilers, because accurate type inference requires information about the entire type hierarchy. This information is typically not available until programs are linked, implying that type-determination algorithms will require link-time optimization. <p> More recent work by Burke [4] and Hall [13] has refined this technique. All of this work characterized programs where procedure values may be passed as function parameters. Others, including Hall [13], also examine functional programs. More recently, Pande and Ryder <ref> [22] </ref> have shown that inferring the set of call targets for call sites in languages with the C++ type system is a NP-hard problem. In this paper, we seek to minimize pipeline stalls using information concerning the frequency of calling specific call sites. <p> Unless the previous algorithms can determine a unique call target, more information is needed for I-call prediction. However, the results of this study indicates that single call targets occur frequently, and the techniques in e.g., Ryder <ref> [22] </ref> may be very successful in practice. To our knowledge, there has been little work in specifying the probability of specific call targets being called using dataflow techniques. By comparison, there has been considerable work in adaptive runtime systems to reduce the cost of polymorphism in dynamically typed languages. <p> Therefore, it is useful to look at both the NIBB and %BP when comparing prediction techniques across different programs. 4.1 Bounds on Compile-time I-Call Prediction We were interested in determining how well interprocedural dataflow analysis could predict indirect method calls <ref> [22] </ref> and we compared these results to profile-based static prediction methods. Method names in C++ are encoded with a unique type signature.
Reference: [23] <author> Chris Perleberg and Alan Jay Smith. </author> <title> Branch target buffer design and optimization. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(4) </volume> <pages> 396-412, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: In general, profile based prediction techniques outperform compile-time prediction techniques or techniques that use hueristics based on branch prediction or instruction opcodes. Some architectures use dynamic prediction, either using tables or explicit branch registers. A branch target buffer (BTB) <ref> [17, 23] </ref> is a small cache holding the address of branch sites and the address of branch targets. There are myriad variations on the general idea. Typically, the cache contains from 32 to 512 entries and may be 2 or 4-way associative.
Reference: [24] <author> Barbera G. Ryder. </author> <title> Constructing the call graph of a program. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-5(3):216-226, </volume> <month> May </month> <year> 1979. </year>
Reference-contexts: A large body of research exists in dataflow analysis to determine the set of possible call targets for a given call site. Ryder <ref> [24] </ref> presented a method for computing the call-graph, or set of functions, that may be called by each call site using dataflow equations. More recent work by Burke [4] and Hall [13] has refined this technique.
Reference: [25] <author> J. E. Smith. </author> <title> A study of branch prediction strategies. </title> <booktitle> In 8th Annual International Symposium of Computer Architecture. ACM, </booktitle> <year> 1981. </year>
Reference-contexts: Rather than present a comprehensive overview of the field, we focus on methods related to the techniques we consider in this paper. Some architectures employ static prediction hints using either profile-derived information, information derived from compile time analysis or information about the branch direction or branch op-code <ref> [25, 20, 2] </ref>. Wall [26] found profile-driven static prediction to be reasonably accurate for indirect function calls. <p> The most common variants of table-based designs are 1-bit techniques that indicate the direction of the most recent branch mapping to a given prediction bit, and 2-bit techniques that yield much better performance for programs with loops <ref> [25, 17, 20] </ref>. The advantage of these bit-table techniques is that they keep track of very little information per branch site and are very effective in practice. Lastly, some computers use explicit branch target addressregis-ters (BTARs) to specify the branch target [11, 1].
Reference: [26] <author> D. W. Wall. </author> <title> Limits of instruction-level parallelism. </title> <booktitle> In Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <pages> pages 176-188, </pages> <address> Boston, Mass., 1991. </address> <publisher> ACM. </publisher>
Reference-contexts: Some dynamic branch prediction mechanisms achieve 95%97% prediction accuracy [21, 27, 29]. This level of accuracy is needed for super-scalar processors issuing several instructions per cycle [28]. The most relevant prior work was on predicting the destination of indirect function calls with hardware conducted by David Wall <ref> [26] </ref> while examining limits to instruction level parallelism. He states Little work has been done on predicting the destinations of indirect jumps, but it might pay off in instruction-level parallelism. <p> Some architectures employ static prediction hints using either profile-derived information, information derived from compile time analysis or information about the branch direction or branch op-code [25, 20, 2]. Wall <ref> [26] </ref> found profile-driven static prediction to be reasonably accurate for indirect function calls. <p> In our experience, this usually occurs because the inputs, that were used to establish the profile used to predict the branches and I-calls, did not provide adequate coverage of all the branches and indirect function calls. This problem has been mentioned by others <ref> [26, 12] </ref>, but has not be studied in detail. Table 4 also shows the effectiveness of idealized dynamic prediction techniques. We simulated two infinitely large Branch Target Buffers.
Reference: [27] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> Alternative implementations of two-level adaptive branch predictions. </title> <booktitle> In 19th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 124-134, </pages> <address> Gold Coast, Australia, </address> <month> May </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: We have measured programs with 191 different subroutines called from a single indirect function call. This makes branches easier to predict. Some dynamic branch prediction mechanisms achieve 95%97% prediction accuracy <ref> [21, 27, 29] </ref>. This level of accuracy is needed for super-scalar processors issuing several instructions per cycle [28]. The most relevant prior work was on predicting the destination of indirect function calls with hardware conducted by David Wall [26] while examining limits to instruction level parallelism.
Reference: [28] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comprehensive instruction fetch mechanism for a processor supporting speculative execution. </title> <booktitle> In 19th Annual International Symposium on Microarchi-tecture, </booktitle> <pages> pages 129-139, </pages> <address> Portland, Or, </address> <month> December </month> <year> 1992. </year> <note> ACM. </note>
Reference-contexts: We have measured programs with 191 different subroutines called from a single indirect function call. This makes branches easier to predict. Some dynamic branch prediction mechanisms achieve 95%97% prediction accuracy [21, 27, 29]. This level of accuracy is needed for super-scalar processors issuing several instructions per cycle <ref> [28] </ref>. The most relevant prior work was on predicting the destination of indirect function calls with hardware conducted by David Wall [26] while examining limits to instruction level parallelism.
Reference: [29] <author> Tse-Yu Yeh and Yale N. Patt. </author> <title> A comparison of dynamic branch predictors that use two levels of branch history. </title> <booktitle> In 20th Annual International Symposium of Computer Architecture, </booktitle> <pages> pages 257-266, </pages> <address> San Diego, CA, </address> <month> May </month> <year> 1993. </year> <note> ACM. </note>
Reference-contexts: We have measured programs with 191 different subroutines called from a single indirect function call. This makes branches easier to predict. Some dynamic branch prediction mechanisms achieve 95%97% prediction accuracy <ref> [21, 27, 29] </ref>. This level of accuracy is needed for super-scalar processors issuing several instructions per cycle [28]. The most relevant prior work was on predicting the destination of indirect function calls with hardware conducted by David Wall [26] while examining limits to instruction level parallelism.
References-found: 29

