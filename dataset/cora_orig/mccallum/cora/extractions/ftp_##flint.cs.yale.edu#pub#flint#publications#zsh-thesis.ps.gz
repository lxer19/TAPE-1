URL: ftp://flint.cs.yale.edu/pub/flint/publications/zsh-thesis.ps.gz
Refering-URL: http://daffy.cs.yale.edu/users/shao-zhong/papers.html
Root-URL: http://www.cs.yale.edu
Title: COMPILING STANDARD ML FOR EFFICIENT EXECUTION ON MODERN MACHINES  
Author: Zhong Shao 
Degree: A DISSERTATION PRESENTED TO THE FACULTY  IN CANDIDACY FOR THE DEGREE OF DOCTOR OF PHILOSOPHY RECOMMENDED FOR ACCEPTANCE BY THE DEPARTMENT OF COMPUTER SCIENCE  
Date: November 1994  
Affiliation: OF PRINCETON UNIVERSITY  
Abstract-found: 0
Intro-found: 1
Reference: [AAD fl 93] <author> Tom Asprey, Gregory S. Averill, Eric DeLano, Russ Mason, Bill Weiner, and Jeff Yetter. </author> <title> Performance Features of the PA7100 Microprocessor. </title> <journal> IEEE Micro, </journal> <volume> 13(3) </volume> <pages> 22-35, </pages> <month> June </month> <year> 1993. </year>
Reference-contexts: This avoids the write miss, with a 0.687-instruction cost per frame. 7 Cache-control hint: On the HP PA7100, a store instruction can have a cache-control hint specifying that the block will be overwritten before being read; this avoids the read if the write misses <ref> [AAD fl 93] </ref>. But these machines have very large primary caches anyway, so locality can be handled by generational collection.
Reference: [AB93] <author> Michael S. Allen and Michael C. Becker. </author> <booktitle> Multiprocessing Aspects of the Pow-erPC 601. In IEEE COMPCON Spring '93, </booktitle> <pages> pages 117-126. </pages> <publisher> IEEE Computer Society Press, </publisher> <month> February </month> <year> 1993. </year>
Reference-contexts: It is more expensive to implement, since it requires a full tag (not just a valid bit) for each word. Diwan et al. found excellent memory-subsystem performance for SML/NJ on this machine. Cache-line zero instruction: On some machines (e.g., IBM R/S6000 [HHH fl 90] and PowerPC <ref> [AB93] </ref>, Power2, HP PA) a cache line (64 bytes) can be allocated and zeroed with a special instruction.
Reference: [AJ88] <author> Andrew W. Appel and Trevor Jim. </author> <title> Optimizing Closure Environment Representations. </title> <type> Technical Report 168, </type> <institution> Dept. of Computer Science, Princeton University, Princeton, NJ, </institution> <year> 1988. </year>
Reference-contexts: Flat closures do satisfy the SSC rule, but they require that variables be copied many times from one closure to another. Many of the closure strategies described by Appel and Jim <ref> [AJ88] </ref> and most stack-frame implementations also violate SSC, since dead variables remain in the frame until a function returns. CHAPTER 4. <p> Rozas's Lias compiler [Roz84] used closure analysis to choose specialized representations for different kinds of closures; Kranz's Orbit compiler [KKR fl 86, Kra87] uses six different closure allocation strategies for different kinds of functions; Appel and Jim investigated closure-sharing strategies <ref> [AJ88] </ref> and proposed many alternative closure representations. Unfortunately, all these closure analysis techniques violate the "safe for space complexity" rule due to unsafe closure sharing.
Reference: [AJ89] <author> Andrew W. Appel and Trevor Jim. </author> <title> Continuation-Passing, Closure-Passing Style. </title> <booktitle> In Sixteenth ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 293-302, </pages> <address> New York, 1989. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Type correctness must be preserved during all optimizations and transformations. Closure Conversion This phase makes explicit the access to nonlocal variables by converting CPS expressions into closure-passing style (CLO) <ref> [AJ89, App92] </ref>. CLO is almost the same as CPS, except that all functions in CLO do not contain free variables, so they can be translated into machine code directly. <p> Under stack allocation, this is impossible since stack frames normally have shorter lifetimes than heap-allocated closures. * Tail recursive calls|which are often quite troublesome to implement correctly on a stack [Han90]|can be implemented very easily. * All of our closure optimizations can be cleanly represented using continuation-passing and closure-passing style <ref> [AJ89] </ref> as the intermediate language. * Once a closure is created, no later writes are made to it; this makes generational garbage collection and call/cc efficient, and also reduces the need for alias analysis in the compiler (since there are less side-effect operations). * Because all closures are allocated either in <p> The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques [Kra87, AS92, Ste78, Roz84, Han90, Joh85], using a simple and general framework expressed in continuation-passing and closure-passing style <ref> [AJ89, AS92] </ref>. Our new algorithm extensively exploits the use of compile-time control and data flow information to optimize closure allocation strategies and representations. <p> In our previous work [AS92], we outlined this framework and demonstrated that it could reduce allocation and memory traffic. But, we did not have a really good algorithm to exploit the flexibility that callee-save registers provide. Closure creation and use can also be represented using the CPS language itself <ref> [AJ89, KH89] </ref>. We call this closure-passing style (CLO). The main difference between CLO and CPS is that functions in CLO do not contain free variables, so they can be translated directly into machine code. <p> Where there are more than three free variables, some of the callee-save arguments must be heap-allocated records containing several variables each; thus, the CR closure-record appears as J1 in the call on line 19. Previous closure conversion algorithms <ref> [Ste78, KKR fl 86, AJ89] </ref> require memory stores for each continuation function. <p> But it is useful to separate the closure introduction from machine code generation so that the compiler is more modular; this has been done in compilers based on ordinary -calculus (through lambda lifting) [CCM85, Joh85] and on continuation-passing style (using closure-passing style) <ref> [AJ89, KH89] </ref>. Many have tried to make call/cc efficient, but this is very hard to achieve in traditional stack-based schemes. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation. <p> Updating activation records In order to guarantee that only "new" heap frames can be roots for garbage collection, it is necessary to prohibit any writes to frames after they have been allocated. Compilers using continuation-passing style (such as Rabbit [Ste78], Orbit [KKR fl 86], and SML/NJ <ref> [AJ89] </ref>) naturally initialize frames as soon as they are allocated, and then never write to them again. In effect, they save up any changes in registers, then dump everything out all at once.
Reference: [AL91] <author> Andrew W. Appel and Kai Li. </author> <title> Virtual Memory Primitives for User Programs. </title> <booktitle> In Fourth Int'l Conf. on Architectural Support for Programming Languages and Operating Systems (SIGPLAN Notices v. </booktitle> <volume> 26, no. 4), </volume> <pages> pages 96-107. </pages> <publisher> ACM Press, </publisher> <month> April </month> <year> 1991. </year>
Reference-contexts: It is also necessary to check for stack overflow; but since overflow is so rare, this can usually be done at no cost using an inaccessible virtual memory page. Allocating a heap frame is more complicated: 1. Heap overflow must be checked. As explained by Appel and Li <ref> [AL91] </ref>, and contrary to the ideas of Appel [App89], this should not be done by a virtual memory fault: (1) operating-system fault handling is too expensive, (2) heap overflow is unrelated to locality of reference, and (3) the technique is almost impossible on machines without precise interrupts.
Reference: [AM91] <author> Andrew W. Appel and David B. MacQueen. </author> <title> Standard ML of New Jersey. </title> <editor> In Martin Wirsing, editor, </editor> <booktitle> Third Int'l Symp. on Prog. Lang. Implementation and Logic Programming, </booktitle> <pages> pages 1-13, </pages> <address> New York, </address> <month> August </month> <year> 1991. </year> <note> Springer-Verlag. </note>
Reference-contexts: Chapters 3 through 6 constitute the core of this dissertation. Chapter 3 describes the design, implementation, and evaluation of the type-directed compilation technique in the context of the Standard ML of New Jersey compiler <ref> [AM91] </ref>; the new technique allows data objects in SML to use efficient unboxed representations, even with the presence of polymorphic functions. <p> Another important predefined data type in SML (actually, only in SML/NJ <ref> [AM91] </ref>) is the polymorphic option type: datatype 'a option = NONE | SOME of 'a CHAPTER 2. BACKGROUND 16 Structured data type values are decomposed using a powerful pattern matching notation. A pattern is a data template. <p> The above function head2 will return 0 if the argument is an empty list. 2.2.6 First-class continuations An extension in Standard ML of New Jersey (SML/NJ) <ref> [AM91] </ref> is the typed first-class continuation [DHM91], defined as follows: type 'a cont val callcc : ('1a cont -&gt; '1a) -&gt; '1a val throw : 'a cont -&gt; 'a -&gt; 'b Here, cont is an abstract type constructor; "'1a" denotes a weak type variable (also used for typing references) [Mac88]; callcc <p> In order to answer these questions and to gain more experience with type-directed compilation, we have implemented a new type-based middle end and back end for the Standard ML of New Jersey compiler (SML/NJ) <ref> [AM91] </ref>. In this chapter, we describe CHAPTER 3. TYPE-DIRECTED COMPILATION 28 the basic design of our new compiler, identify and solve a number of practical problems involved in the implementation, and then present a detailed performance evaluation of various type-based compilation techniques. <p> In this section, we explain in detail what the standard boxed representations are, and what other more efficient alternatives one can use in type-based compilers. Non-type-based compilers for polymorphic languages, such as the old SML/NJ compiler <ref> [AM91] </ref>, must use the standard boxed representations for all data objects. <p> In a type-based compiler, because we know the types of program variables, we can use much more efficient data representations, depending on how complicated a descriptor we CHAPTER 3. TYPE-DIRECTED COMPILATION 30 want to support at runtime 1 . For example, in the SML/NJ compiler <ref> [App90, Rep93, AM91] </ref>, the descriptor for runtime objects is just a kind tag plus the length of the object; each object may contain tagged/boxed objects, or untagged/unboxed objects, but not both. <p> The overall organization of the new compiler is very similar to the old Standard ML of New Jersey compiler described by Appel and MacQueen <ref> [AM91] </ref>. Compilation of an SML program is grossly divided into CHAPTER 3. <p> The details are described in Section 3.4. Lambda Translation In this phase, the abstract syntax Absyn, annotated with static semantic information, is translated into a strict call-by-value lambda calculus (LEXP) augmented with data constructors, records, and primitive operators. Unlike the un-typed lambda language used in the older SML/NJ compiler <ref> [AM91] </ref>, LEXP is explicitly typed using a simple monomorphic type system (to be described in Section 3.5). The type information in LEXP is converted directly from the static semantic information attached to the Absyn. <p> Assume that and t are translated into LTYs s and t, variable v is then translated into the LEXP expression coerce (s; t)(VAR v). pattern matching: Pattern matches are compiled in the same way as in the old compiler <ref> [AR92, AM91, App92] </ref>. The only difference is that we have to insert coercions around polymorphic data constructor projections (DECON) (see the next item). polymorphic data constructors: Polymorphic data constructors are treated the same as polymorphic variables except that coercions are applied to data constructor injections (CON) and projections (DECON). <p> 1 , u 2 , ..., u n ], suppose the LTY for each u i is t i (i = 1; :::; n), we can represent the record using virtually any layout: * The simplest way is to box every field, with integers tagged and reals boxed (see piler <ref> [AM91, App92] </ref>. <p> Because there is no object identity for records in ML, we can replace all uses of w by v and eliminate all copying operations. This is impossible in the old compiler <ref> [AM91, App92] </ref> where the length information for each record is not known in CPS. 3.6.4 Closure conversion The representations of CPS functions (FIXes) are not exactly as a von Neumann machine would like them, since functions are nested with lexical scope. <p> TYPE-DIRECTED COMPILATION 59 for the Caml Light dialect of ML, and shown that it can result in important speedups on certain benchmarks. The work described in this chapter is a re-implementation of Leroy's techniques in the Standard ML of New Jersey compiler <ref> [AM91] </ref>. Unlike Leroy [Ler92], we concentrate more on practical issues such as how to implement type-directed compilation for the entire SML language (Caml has a much simpler module system than SML), and how to efficiently propagate type information through many rounds of transformations and optimizations. <p> This table shows the proportion of frame allocations that are not in the same block as a non-frame allocation. The results shown are from measurements of ML benchmark programs (see Table 2 in Section 2.4 for details) as compiled by the Standard ML of New Jersey <ref> [AM91] </ref> compiler. Program Limit Checks per Frame Boyer .717 Knuth-B .783 Lexgen .864 Life .456 YACC .631 Simple .665 VLIW .695 Average .687 5.2 Creation To allocate a stack frame, the program must add a constant to the stack pointer. This takes one instruction. <p> The restriction that heaps cannot point to stacks must be counted as a "cost" of using stack-allocated frames. To quantify this cost, we measured two versions of the Standard ML of New Jersey compiler <ref> [AM91, App92] </ref> outfitted with the new closure conversion algorithm described in Chapter 4. The version shown as Ordinary Heap in Table 20, allocates all frames and closures on the heap. <p> We will now demonstrate that heap-allocated frames have adequate locality of reference in a small cache, if the read miss penalty is not too large and the write miss penalty is zero. 5.6.1 Write misses The Standard ML of New Jersey compiler <ref> [AM91] </ref> uses no stack; all frames are allocated on the garbage-collected heap. If any system should have poor cache locality, this is the one. <p> The problem with filter 6 Here is a list of these functions: hd, tl, length, append, rev, map, fold, revfold, app, revapp, nthtail, nth, exists, last, and filter. They are mostly taken from the initial basis of the Standard ML of New Jersey compiler <ref> [AM91] </ref>. CHAPTER 6. UNROLLING LISTS 135 is that even if we know the length parity of its argument, we still do not know the length parity of its result. <p> next section) is that the NUR version of filter is about as fast as the OSR version, even without the specialized CPS version of our analysis. 6.4 Experiments We have implemented the algorithm described in Section 6.2 in an experimental version of the Standard ML of New Jersey compiler (SML/NJ) <ref> [AM91, App92] </ref>. Because the compiler uses continuation-passing style as its intermediate language, the multiple-continuation CHAPTER 6. UNROLLING LISTS 136 approach described in Section 6.3 can be easily added (this has not been done yet).
Reference: [AMT89] <author> Andrew W. Appel, James S. Mattson, and David R. Tarditi. </author> <title> A lexical analyzer generator for Standard ML. Distributed with Standard ML of New Jersey, </title> <month> December </month> <year> 1989. </year>
Reference-contexts: KB-Comp 655 1 1 An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen 1185 5 1 A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi <ref> [AMT89] </ref>, processing the lexical de scription of Standard ML. Life 148 1 1 The game of Life, written by Chris Reade and described in his book [Rea89], running 50 gen erations of a glider gun.
Reference: [App87] <author> Andrew W. Appel. </author> <title> Garbage Collection can be Faster than Stack Allocation. </title> <journal> Information Processing Letter, </journal> <volume> 25(4) </volume> <pages> 275-279, </pages> <year> 1987. </year> <note> BIBLIOGRAPHY 146 </note>
Reference-contexts: Stacks do have a much better write miss ratio, but not a much better read miss ratio. But on many modern machines, the write miss penalty is approximately zero [Jou93, DTM94, Rei94]. 3. The amortized cost of collection can be very low <ref> [App87] </ref> (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. <p> One might think that it would be expensive to allocate, at every procedure call, heap storage that becomes garbage on return. But not necessarily <ref> [App87] </ref>: modern generational garbage-collection algorithms [Ung86] can reclaim dead frames efficiently, as cheap as the one-instruction cost to pop the stack. But there are other costs involved in creating, accessing, and destroying activation records|whether on a heap or a stack.
Reference: [App89] <author> Andrew W. Appel. </author> <title> Simple Generational Garbage Collection and Fast Allocation. </title> <journal> Software|Practice and Experience, </journal> <volume> 19(2) </volume> <pages> 171-183, </pages> <year> 1989. </year>
Reference-contexts: CHAPTER 2. BACKGROUND 25 run as its final performance data (as recommended, for example, by the SPEC benchmark consortium [Sta89]). All compilers mentioned in this dissertation use a simple two-generation copying garbage collector <ref> [App89] </ref>. Available memory is divided into two half-spaces, and allocation occurs at the low end of the upper space (called new space). <p> Allocating a heap frame is more complicated: 1. Heap overflow must be checked. As explained by Appel and Li [AL91], and contrary to the ideas of Appel <ref> [App89] </ref>, this should not be done by a virtual memory fault: (1) operating-system fault handling is too expensive, (2) heap overflow is unrelated to locality of reference, and (3) the technique is almost impossible on machines without precise interrupts. <p> This provides empirical evidence for the claim that sizing the allocation space to fit into cache can improve performance." [Rep93] Unfortunately, the measurements in this chapter were made using the older two-generation collector <ref> [App89] </ref>. Small Caches For small (e.g., primary) caches whose size is less than 100 kbytes, it is impractical to keep the youngest generation in the cache; doing so would cause garbage collections to be too frequent, and this would be expensive. Let us consider locality in a small, primary cache.
Reference: [App90] <author> Andrew W. Appel. </author> <title> A Runtime System. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 3(4) </volume> <pages> 343-380, </pages> <year> 1990. </year>
Reference-contexts: In a type-based compiler, because we know the types of program variables, we can use much more efficient data representations, depending on how complicated a descriptor we CHAPTER 3. TYPE-DIRECTED COMPILATION 30 want to support at runtime 1 . For example, in the SML/NJ compiler <ref> [App90, Rep93, AM91] </ref>, the descriptor for runtime objects is just a kind tag plus the length of the object; each object may contain tagged/boxed objects, or untagged/unboxed objects, but not both. <p> both boxed and unboxed values are still represented as two layers, with each unboxed value being boxed separately (see Figure 4). sml.fp3 This version is completely same as the sml.ffb compiler except three floating-point callee-save registers are used. 8 Unfortunately, the SML/NJ version 1.03z still uses the old runtime system <ref> [App90] </ref>. Memory fetch (or store) of a floating-point number is implemented using two normal (one-word) memory-load (memory-store) instructions. Because of this, the "flat" real vectors we used need not be aligned at the double-word boundary. CHAPTER 3.
Reference: [App92] <author> Andrew W. Appel. </author> <title> Compiling with Continuations. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: used for links and significantly shortens the length of control-dependence and data-dependence chains in operations on lists. 1.2 Outline of this dissertation The development of this dissertation may be easier to follow for readers with some background in Standard ML [Ull93, Har86, MTH90] and basic compilation techniques for functional languages <ref> [App92, Pey87] </ref>. Chapter 2 contains a survey of various functional languages, an introduction to SML (which may be skipped if the reader is familiar with SML notation), and a review of several important aspects in compiling functional languages. <p> In a garbage-collected language, the garbage collector need not use such variables as "roots" of live data. Several implementors have independently discovered that this is really important: if the collector traverses too many dead variables, the memory use of the program can increase by a large factor <ref> [Bak76, Cha88, RW93, App92, Jon92] </ref>. <p> This theorem, examples, and a description of compiler techniques that are "safe for space complexity" are described by Appel <ref> [App92, Chapter 12] </ref>. We can use the example shown in Figure 2 to illustrate this problem. With flat closures, each evaluation of f (: : :)() yields a closure s for h that contains just a few integers u, w, x, CHAPTER 2. <p> All recent versions of SML/NJ have obeyed the "safe for space complexity" (SSC) rule, and users really did notice the improvement. The SSC rule is stated as follows: any local variable binding must be unreachable after its last use within its scope (see Appel <ref> [App92] </ref> for a more formal definition). Assumption: all discussions in this dissertation are based on the assumption that the compiler must satisfy the "safe for space complexity" rule. 2.4 Experimental measurements All measurements in this dissertation are done on a DEC5000/240 workstation with 128 mega-bytes of memory (under Ultrix 4.3). <p> CHAPTER 3. TYPE-DIRECTED COMPILATION 34 CPS optimizations The resulting CPS expression is then fed into many rounds of CPS optimizations <ref> [App92] </ref> such as contraction, eta-reduction, beta-reduction, inlining expansion, loop unrolling, and so on. Type correctness must be preserved during all optimizations and transformations. Closure Conversion This phase makes explicit the access to nonlocal variables by converting CPS expressions into closure-passing style (CLO) [AJ89, App92]. <p> Type correctness must be preserved during all optimizations and transformations. Closure Conversion This phase makes explicit the access to nonlocal variables by converting CPS expressions into closure-passing style (CLO) <ref> [AJ89, App92] </ref>. CLO is almost the same as CPS, except that all functions in CLO do not contain free variables, so they can be translated into machine code directly. <p> function names, lty list denotes the types of these functions, and lexp list denotes the corresponding function definitions; * a SWITCH expression that detects which constant or data constructor (from the (con*lexp) list) was used to build a data type value, and then evaluates the cor responding expression (see Appel <ref> [App92] </ref> for details); CHAPTER 3. <p> Assume that and t are translated into LTYs s and t, variable v is then translated into the LEXP expression coerce (s; t)(VAR v). pattern matching: Pattern matches are compiled in the same way as in the old compiler <ref> [AR92, AM91, App92] </ref>. The only difference is that we have to insert coercions around polymorphic data constructor projections (DECON) (see the next item). polymorphic data constructors: Polymorphic data constructors are treated the same as polymorphic variables except that coercions are applied to data constructor injections (CON) and projections (DECON). <p> The CPS conversion phase not only converts the LEXP expression into continuation-passing style (CPS), but also makes the implementation decisions for records, data constructors, function applications, and switch statements. 6 The resulting CPS expression, annotated with CPS types (CTY), is fed into many rounds of CPS optimization (described by Appel <ref> [App92] </ref>), and then converted into closure-passing style (CLO) by the closure converter. <p> Finally, based on the CLO expression and the CTY information, the compiler does the register allocation and instruction scheduling, and writes out the machine code. 3.6.1 The typed CPS language CPS types "CTY" (defined as the data type cty). As in the old CPS language <ref> [App92] </ref>, the 6 See Appel [App92] for details on how to CPS-convert data constructors and switch statements. CHAPTER 3. TYPE-DIRECTED COMPILATION 49 arguments to a function (or primitive operators) are always values (variables or constants, defined as the data type value). <p> As in the old CPS language <ref> [App92] </ref>, the 6 See Appel [App92] for details on how to CPS-convert data constructors and switch statements. CHAPTER 3. TYPE-DIRECTED COMPILATION 49 arguments to a function (or primitive operators) are always values (variables or constants, defined as the data type value). <p> Notice since the CPS conversion phase has made implementation decisions for records and functions, the CTY is not concerned with the details of RECORDty and ARROWty. 3.6.2 Converting LEXP into CPS The overall structure and algorithm of our CPS conversion phase is almost same as the one described by Appel <ref> [App92] </ref>. The conversion function F takes two arguments: an LEXP expression E and a "continuation" function c of type value ! cexp; and returns a CPS expression as the result. Unlike Appel [App92], during the conversion process, we also gather the LTY information for each LEXP expression, and maintain an LTY <p> overall structure and algorithm of our CPS conversion phase is almost same as the one described by Appel <ref> [App92] </ref>. The conversion function F takes two arguments: an LEXP expression E and a "continuation" function c of type value ! cexp; and returns a CPS expression as the result. Unlike Appel [App92], during the conversion process, we also gather the LTY information for each LEXP expression, and maintain an LTY environment for all CPS variables. <p> 1 , u 2 , ..., u n ], suppose the LTY for each u i is t i (i = 1; :::; n), we can represent the record using virtually any layout: * The simplest way is to box every field, with integers tagged and reals boxed (see piler <ref> [AM91, App92] </ref>. <p> CPS conversion of function definition and application may introduce redundant record creation and selection code. Fortunately, they can be eliminated by the CPS optimization phase <ref> [App92] </ref>. Finally, the primitive coercion operations, WRAP (t,e) and UNWRAP (t,e), are converted into corresponding CPS primitive operations. <p> The only extra work is to copy the CTY information, when a function is being inlined or unrolled; this overhead is minimal since we have such a simple set of CPS types. Besides those described by Appel <ref> [App92] </ref>, two new CPS optimizations are performed: * One is to cancel pairs of "wrapper" and "unwrapper" operations as long as they are of the same kind, that is, between iwrap and iunwrap, fwrap and funwrap, or wrap and unwrap. <p> Because there is no object identity for records in ML, we can replace all uses of w by v and eliminate all copying operations. This is impossible in the old compiler <ref> [AM91, App92] </ref> where the length information for each record is not known in CPS. 3.6.4 Closure conversion The representations of CPS functions (FIXes) are not exactly as a von Neumann machine would like them, since functions are nested with lexical scope. <p> One optimization commonly used in closure conversion is to share closures among several functions. Unfortunately, closure sharing, if not done carefully, is not safe for space complexity <ref> [App92] </ref> (see Section 2.3.3). In our typed CPS back end, the object size information for each CPS variable is known most of the time (from its CTY, except those with type PTRt (NONE)), so we can easily identify whether it is safe to share two closures or not. <p> All of these compilers use the new closure conversion algorithm (described in Chapter 4), and with three general purpose callee-save registers [AS92], and all use tagged 31-bit integer representations. Other aspects of these compilers are close to those described by Appel <ref> [App92] </ref>. sml.nrp This version does not support representation analysis. No type information is propagated into the compiler middle end and back end. All data objects use uniform standard boxed representations. <p> No type information is propagated into the compiler middle end and back end. All data objects use uniform standard boxed representations. All functions take exactly one argument and return one result. sml.fag This is the sml.nrp compiler with the argument flattening optimization turned on <ref> [App92] </ref>. <p> For all other benchmarks, sml.mtd performs about the same as sml.rep. Although there are much larger number of coercions in the lambda language in sml.rep, most these coercions are eliminated by the CPS optimization phase <ref> [App92] </ref> (through eta-reduction, inlining, constant folding, etc.). * Another observation is that the sml.mtd compiler did not make the compilation any faster than sml.rep either. <p> Unlike linked closures, the nesting level of safely linked closures never exceeds two, so they still enjoy very fast variable access time. 4.3 Continuations and closures We will illustrate CPS-conversion (which is not new <ref> [Plo75, Ste78, Kra87, App92] </ref>), and our new closure analysis algorithm, on the example in Figure 16. <p> If y's last use is much earlier than w's or x's, then the record (w; x; y) might not obey the SSC rule. Most closure conversion algorithms <ref> [App92, Kra87, Ste78] </ref> start with a phase to gather the set of raw free variables for each function definition in E. <p> The "lazy display" technique is implemented in all six compilers, but it is used more effectively in compilers that use the new closure conversion algorithm, because of their more extensive use of shared closures. sml.occ This version uses the old closure conversion algorithm <ref> [App92, AS92] </ref>. More specifically, it uses the linked closure representation if it is space safe, otherwise it uses the flat closure representation. Continuation closures are represented using three callee save registers. sml.gp1,sml.gp2,sml.gp3,sml.gp4 These compilers all use the new closure conversion algorithm described in this chapter. <p> Both Chow [Cho88a] and Steele [SS80] observed that dataflow analysis can help decide whether to put variables in caller-save or callee-save registers. We are the first to show how to represent callee-save registers in continuation-passing style <ref> [AS92, App92] </ref> and how to use compile-time variable lifetime information to do a much better job of it. Local variables of different functions with nonoverlapping live ranges can be allocated to the same register or global without any save/restore [GS91, Cho88a]. <p> The restriction that heaps cannot point to stacks must be counted as a "cost" of using stack-allocated frames. To quantify this cost, we measured two versions of the Standard ML of New Jersey compiler <ref> [AM91, App92] </ref> outfitted with the new closure conversion algorithm described in Chapter 4. The version shown as Ordinary Heap in Table 20, allocates all frames and closures on the heap. <p> In effect, they save up any changes in registers, then dump everything out all at once. With good use of callee-save registers <ref> [AS92, App92] </ref> (also see Chapter 4), it is even easier to accumulate any changes in registers and write immutable frames in big chunks. A stack-based compiler could update the topmost frame at any time, and the collector could always scan this frame for roots. <p> ,econs (e 2 ,e 3 )) can be transformed to TAIL2 (e 1 ,e 2 ,e 3 ), which avoids the parity checking and the allocation of the intermediate odd-length list cell. 4 In practice, TAIL1 is a transparent data constructor, thus does not require any extra storage to represent <ref> [Car84a, App92] </ref>. CHAPTER 6. UNROLLING LISTS 126 6.2.2 An introduction to refinement types In this section, we give a brief introduction to the refinement type system used in our translation algorithm (see Section 6.2.3). <p> Here is the filter function: fun filter p = let fun f nil = nil | f (x::r) = if (p x) then x::(f r) else f r in f It turns out that this problem can be easily solved in the continuation-passing style (CPS) framework <ref> [Ste78, App92] </ref>, because we can specialize the return continuation on the length parity of the result, and make it have multiple entry points also. <p> next section) is that the NUR version of filter is about as fast as the OSR version, even without the specialized CPS version of our analysis. 6.4 Experiments We have implemented the algorithm described in Section 6.2 in an experimental version of the Standard ML of New Jersey compiler (SML/NJ) <ref> [AM91, App92] </ref>. Because the compiler uses continuation-passing style as its intermediate language, the multiple-continuation CHAPTER 6. UNROLLING LISTS 136 approach described in Section 6.3 can be easily added (this has not been done yet).
Reference: [App94a] <author> Andrew W. Appel. </author> <title> Emulating Write-Allocate on a No-Write-Allocate Cache. </title> <type> Technical Report CS-TR-459-94, </type> <institution> Princeton University, </institution> <month> June </month> <year> 1994. </year>
Reference-contexts: Garbage-prefetch: On a machine with a no-write-allocate (write-around) cache, write-allocate can be simulated (as long as read misses are nonblocking) by fetching the cache line (with an ordinary read instruction) in advance of the write <ref> [App94a] </ref>. This technique works (providing a modest performance enhancement) on the DEC Alpha 21064 [Dig92], for example. On any of these machines, heap-allocated data should not incur a write-miss penalty. Assumption: Any small cache will have write-allocate and no write-miss latency (or write-allocate can be emulated).
Reference: [App94b] <author> Andrew W. Appel. </author> <title> Loop Headers in -calculus or CPS. Lisp and Symbolic Computation, </title> <note> page (to appear), 1994. Also available as Princeton University Tech Report CS-TR-460-94. </note>
Reference-contexts: This function can be defined in the ordinary way (by fun), and will presumably be invoked by the callee in order to continue the computation. loop-invariant continuation argument of h has been hoisted out of the loop <ref> [App94b] </ref>. <p> CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 89 Hanson [Han90] showed the complexity of implementing tail calls correctly and efficiently on a conventional stack. In our heap-based scheme, the correctness is straightforward because dead frames are automatically reclaimed by the garbage collector; the efficiency is achieved by using the loop-header technique <ref> [App94b] </ref> to hoist the loop-invariant free variables out of the tail recursion, and using the callee-save registers [AS92] to simulate the top reusable stack frames.
Reference: [AR92] <author> William E. Aitken and John H. Reppy. </author> <title> Abstract Value Constructors. </title> <booktitle> In ACM SIGPLAN Workshop on ML and its Applications, </booktitle> <pages> pages 1-11, </pages> <month> June </month> <year> 1992. </year> <note> Longer version available as Cornell Univ. Tech. Report. </note>
Reference-contexts: Assume that and t are translated into LTYs s and t, variable v is then translated into the LEXP expression coerce (s; t)(VAR v). pattern matching: Pattern matches are compiled in the same way as in the old compiler <ref> [AR92, AM91, App92] </ref>. The only difference is that we have to insert coercions around polymorphic data constructor projections (DECON) (see the next item). polymorphic data constructors: Polymorphic data constructors are treated the same as polymorphic variables except that coercions are applied to data constructor injections (CON) and projections (DECON). <p> First we describe a simple syntactic transformation that gets us partway to our goal. A simple way to implement the NUR is to make the compiler interpret the normal "::" constructor abstractly, just as Aitken and Reppy deal with their abstract value constructors <ref> [AR92] </ref>.
Reference: [AS92] <author> Andrew W. Appel and Zhong Shao. </author> <title> Callee-save Registers in Continuation-Passing Style. </title> <journal> Lisp and Symbolic Computation, </journal> <volume> 5(3) </volume> <pages> 191-221, </pages> <year> 1992. </year>
Reference-contexts: Finally, Chapter 7 describes areas for future research and summarizes the results of this dissertation. History The idea of allocating continuation closures in callee-save registers (described in Chapter 4) is first published as Reference <ref> [AS92] </ref>. The new closure conversion algorithm in Chapter 4 is developed recently, and published as Reference [SA94]. The measurement data used in Reference [SA94] is different from one in Chapter 4 because they are using different versions of the SML/NJ compiler. <p> CHAPTER 3. TYPE-DIRECTED COMPILATION 54 The six compilers we use are all simple variations of the Standard ML of New Jersey compiler version 1.03z. All of these compilers use the new closure conversion algorithm (described in Chapter 4), and with three general purpose callee-save registers <ref> [AS92] </ref>, and all use tagged 31-bit integer representations. Other aspects of these compilers are close to those described by Appel [App92]. sml.nrp This version does not support representation analysis. No type information is propagated into the compiler middle end and back end. All data objects use uniform standard boxed representations. <p> Function returns are implemented in the same way, because in CPS, they are represented as calls to continuation functions. A closure can be any combination of registers and memory data structures that gives access to the free variables <ref> [KKR fl 86, AS92] </ref>. The compiler is free to choose a closure representation that minimizes stores (closure creation), fetches (to access free variables), and memory use (reachable data). We have developed a new algorithm for choosing good closure representations. <p> These assumptions do not hold in our algorithm for three reasons: 1. As we will show in Section 4.4, because most parts of continuation closures are allocated in callee-save registers <ref> [AS92] </ref>, the extra memory write and read at each call can often be avoided. With the help of compile-time control and data flow information, the combination of shared closures and callee-save registers can often be comparable to or even better than stack allocation. 2. <p> The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques <ref> [Kra87, AS92, Ste78, Roz84, Han90, Joh85] </ref>, using a simple and general framework expressed in continuation-passing and closure-passing style [AJ89, AS92]. Our new algorithm extensively exploits the use of compile-time control and data flow information to optimize closure allocation strategies and representations. <p> The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques [Kra87, AS92, Ste78, Roz84, Han90, Joh85], using a simple and general framework expressed in continuation-passing and closure-passing style <ref> [AJ89, AS92] </ref>. Our new algorithm extensively exploits the use of compile-time control and data flow information to optimize closure allocation strategies and representations. <p> We did so as follows <ref> [AS92] </ref>: each CPS-converted user function f is passed its ordinary arguments, a continuation function c 0 , and k extra arguments c 1 ; :::; c k . <p> SPACE-EFFICIENT CLOSURE REPRESENTATIONS 69 f must save and restore them. One could also say that the continuation is represented in k + 1 registers (c 0 ; :::; c k ). In our previous work <ref> [AS92] </ref>, we outlined this framework and demonstrated that it could reduce allocation and memory traffic. But, we did not have a really good algorithm to exploit the flexibility that callee-save registers provide. Closure creation and use can also be represented using the CPS language itself [AJ89, KH89]. <p> If f is an escaping continuation function, then S (f ) = k where k is the number of callee-save registers. Because their call sites are not known at compile time, most continuation functions have to use the uniform convention; that is, always use k callee-save registers <ref> [AS92] </ref>. In special cases, some escaping continuation functions can be represented differently; this is discussed in Section 4.5.3. For known functions, since their call sites are known at compile time, their closures (or environments) may be allocated completely in registers. <p> The "lazy display" technique is implemented in all six compilers, but it is used more effectively in compilers that use the new closure conversion algorithm, because of their more extensive use of shared closures. sml.occ This version uses the old closure conversion algorithm <ref> [App92, AS92] </ref>. More specifically, it uses the linked closure representation if it is space safe, otherwise it uses the flat closure representation. Continuation closures are represented using three callee save registers. sml.gp1,sml.gp2,sml.gp3,sml.gp4 These compilers all use the new closure conversion algorithm described in this chapter. <p> In our heap-based scheme, the correctness is straightforward because dead frames are automatically reclaimed by the garbage collector; the efficiency is achieved by using the loop-header technique [App94b] to hoist the loop-invariant free variables out of the tail recursion, and using the callee-save registers <ref> [AS92] </ref> to simulate the top reusable stack frames. Some compilers [Ste78, KKR fl 86, Car84a] perform closure conversion and closure analyses as part of their translation from lambda calculus or continuation-passing style into machine code. <p> Both Chow [Cho88a] and Steele [SS80] observed that dataflow analysis can help decide whether to put variables in caller-save or callee-save registers. We are the first to show how to represent callee-save registers in continuation-passing style <ref> [AS92, App92] </ref> and how to use compile-time variable lifetime information to do a much better job of it. Local variables of different functions with nonoverlapping live ranges can be allocated to the same register or global without any save/restore [GS91, Cho88a]. <p> In effect, they save up any changes in registers, then dump everything out all at once. With good use of callee-save registers <ref> [AS92, App92] </ref> (also see Chapter 4), it is even easier to accumulate any changes in registers and write immutable frames in big chunks. A stack-based compiler could update the topmost frame at any time, and the collector could always scan this frame for roots.
Reference: [AS94] <author> Andrew W. Appel and Zhong Shao. </author> <title> An Empirical and Analytic Study of Stack vs. Heap Cost for Languages with Closures. </title> <type> Technical Report CS-TR-450-94, </type> <institution> Princeton University, Department of Computer Science, Princeton, NJ, </institution> <month> March </month> <year> 1994. </year> <note> To appear in Journal of Functional Programming. </note>
Reference-contexts: The measurement data used in Reference [SA94] is different from one in Chapter 4 because they are using different versions of the SML/NJ compiler. The comparison of stack-based and heap-based closure allocation scheme described in Chapter 5 previously appeared as Reference <ref> [AS94] </ref>. The unrolling lists technique described in Chapter 6 is previously published as Reference [SRA94]. Some of the ideas used in Chapter 3 are evolved from my work on smartest recompilation [SA93, SA92], which is not described in this dissertation.
Reference: [ASU86] <author> Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman. </author> <booktitle> Compilers: Principles, Techniques, and Tools. </booktitle> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1986. </year>
Reference-contexts: that type tags need not be carried around at run time, and operators need not to check the types of their arguments at run time. * SML uses call-by-value evaluation semantics, so SML programs still have understandable control flow to do all conventional data flow and control flow optimiza tions <ref> [ASU86] </ref>. * Unlike pure functional languages such as Haskell [HJet al92], SML is just a mostly functional language. <p> On many other aspects, compiling functional languages can be attacked using the same techniques described in the "Dragon" book <ref> [ASU86] </ref>. This section reviews the basic issues involved in compiling function call and return for functional languages.
Reference: [Aug89] <author> Lennart Augustsson. </author> <title> Garbage collection in the &lt; -; G &gt;-machine. </title> <type> Technical Report PMG memo 73, </type> <institution> Dept. of Computer Sciences, Chalmers University of Technology, Goteborg, Sweden, </institution> <month> December </month> <year> 1989. </year>
Reference-contexts: It is possible to allow dead variables in frames and closures, if the garbage collector knows they are dead. This can be accomplished using special descriptors, which would reduce the "copying and sharing" penalty for stack frames. For example, in the Chalmers Lazy ML compiler <ref> [Aug89] </ref> or the Gallium compiler [Ler92], associated with each return address is a descriptor telling which variables in the caller's frame are live after the return. 4 But this is not sufficient; heap closures still cannot point to stack frames.
Reference: [Bak76] <author> Henry G. Baker. </author> <title> The Buried Binding and Stale Binding Problems of LISP 1.5. </title> <note> unpublished, undistributed paper, </note> <month> June </month> <year> 1976. </year>
Reference-contexts: In a garbage-collected language, the garbage collector need not use such variables as "roots" of live data. Several implementors have independently discovered that this is really important: if the collector traverses too many dead variables, the memory use of the program can increase by a large factor <ref> [Bak76, Cha88, RW93, App92, Jon92] </ref>.
Reference: [Bak78] <author> Henry G. Baker. </author> <title> List Processing in Real Time on a Serial Computer. </title> <journal> Communications of the ACM, </journal> <volume> 21(4) </volume> <pages> 280-294, </pages> <month> April </month> <year> 1978. </year> <note> BIBLIOGRAPHY 147 </note>
Reference-contexts: A depth-first (or breadth-first <ref> [Bak78] </ref>) copying garbage collector helps ensure that most lists are arranged sequentially in storage, so they can take advantage of this encoding.
Reference: [Bar84] <author> H. P. Barendregt. </author> <title> The Lambda Calculus, Its Syntax and Semantics. </title> <publisher> North-Holland, </publisher> <address> Amsterdam, </address> <year> 1984. </year>
Reference-contexts: The lambda calculus is often regarded as the first functional language, and all modern functional languages can be thought of as nontrivial embellishments of the lambda calculus. Interested readers are referred to the excellent book by Barendregt <ref> [Bar84] </ref> for more detailed explanations. CHAPTER 2.
Reference: [BC79] <author> Daniel G. Bobrow and Douglas W. Clark. </author> <title> Compact Encodings of List Structure. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 1(2) </volume> <pages> 267-286, </pages> <month> Oc-tober </month> <year> 1979. </year>
Reference-contexts: With modern superscalar hardware, these dependences are a serious bottleneck. In order to save on storage for links, "cdr-coding" was proposed in the 1970's <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>. <p> of NUR is that our compiler does not have a good dead code detection algorithm, we believe that a more refined implementation can achieve more code sharing and produce much smaller code. 6.5 Related work Cdr-coding techniques were first proposed in the early 70's by researchers at MIT and Xerox <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>.
Reference: [BCKT89] <author> Preston Briggs, Keith D. Cooper, Ken Kennedy, and Linda Torczon. </author> <title> Coloring Heuristics for Register Allocation. </title> <booktitle> In Proc. ACM SIGPLAN '89 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 275-284, </pages> <address> New York, July 1989. </address> <publisher> ACM Press. </publisher>
Reference-contexts: These intermediate variables (e.g., register r) may use up all the available machine registers and cause unnecessary register spilling, but this can always be avoided by selectively keeping limited number of intermediate variables in the "lazy display" (registers). 4.4.6 Remarks Graph-coloring global register allocation and targeting <ref> [Cha82, BCKT89] </ref>, which have been implemented for SML/NJ by Lal George et al [GGR94], accomplishes most control transfers (function calls) (such as line 12 and 13 in Figure 19) without any register-register moves. This allows a more flexible boundary between callee-save and caller-save registers than is normal in most compilers. <p> We achieve this by allocating part of the closures (for known functions and continuations) in both caller-and callee-save registers, and then using the graph-coloring global register allocation and targeting algorithms <ref> [Cha82, BCKT89, GGR94] </ref>. 4.8 Summary Our new closure conversion algorithm is a great success. The closure conversion algorithm itself is faster than our previous algorithm (see Table 15). It makes programs smaller (by an CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 90 average of 19%) and faster (by an average of 14%).
Reference: [BH86] <author> J.E. Barnes and P. Hut. </author> <title> A Hierarchical O(N logN ) Force Calculation Algorithm. </title> <journal> Nature, </journal> <volume> 324(4) </volume> <pages> 446-449, </pages> <month> December </month> <year> 1986. </year>
Reference-contexts: CHAPTER 2. BACKGROUND 24 Table 2: General information about the benchmark programs Program Lines Modules Files Description BHut 1258 9 9 "Barnes-Hut" N-body problem solver <ref> [BH86] </ref>, translated from C into Standard ML by John Reppy. Boyer 919 4 3 Standard theorem-prover benchmark [BM72], translated from the Gabriel benchmark [Gab85]. Sieve 1356 4 5 CML implementation of prime number gener ator written by John Reppy [Rep91].
Reference: [Bjo94] <author> Nikolaj S. </author> <title> Bjorner. Minimial Typing Derivations. </title> <booktitle> In ACM SIGPLAN Workshop on ML and its Applications, </booktitle> <pages> pages 120-126, </pages> <month> June </month> <year> 1994. </year>
Reference-contexts: We have implemented a "minimum typing derivation" phase in our compiler to give all local variables "least" polymorphic types. The derivation is done after the elaboration so that it is only applied to type-correct programs. Our algorithm, which is similar to Bjtrner's algorithm M <ref> [Bjo94] </ref>, does a bottom-up traversal of the abstract syntax Absyn. During the traversal, we mark all variables that are local (e.g., let-bound) or hidden because of signature matching. <p> This version does not use minimum typing derivations (see Section 3.4.3 and Bjtrner <ref> [Bjo94] </ref>). Moreover, all floating point numbers still use boxed representations. <p> Once again, it is not clear how their technique can easily be extended to the SML module language. Our compiler uses a simple minimum typing derivation <ref> [Bjo94] </ref> round in the front end to decrease the degree of polymorphism for all local and hidden functions. This is very easy to extend to the module system. We believe our approach can almost achieve the same result as "formally optimal unboxing" [HJ94].
Reference: [BM72] <author> R. S. Boyer and J Moore. </author> <title> The Sharing of Structure in Theorem-Proving Programs. </title> <editor> In B. Meltzer and D. Michie, editors, </editor> <booktitle> Machine Intelligence 7. </booktitle> <publisher> Edinburgh University Press, </publisher> <year> 1972. </year>
Reference-contexts: CHAPTER 2. BACKGROUND 24 Table 2: General information about the benchmark programs Program Lines Modules Files Description BHut 1258 9 9 "Barnes-Hut" N-body problem solver [BH86], translated from C into Standard ML by John Reppy. Boyer 919 4 3 Standard theorem-prover benchmark <ref> [BM72] </ref>, translated from the Gabriel benchmark [Gab85]. Sieve 1356 4 5 CML implementation of prime number gener ator written by John Reppy [Rep91]. KB-Comp 655 1 1 An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry.
Reference: [Bob75] <author> Daniel G. Bobrow. </author> <title> A note on hash linking. </title> <journal> Communications of the ACM, </journal> <volume> 18(7) </volume> <pages> 413-415, </pages> <month> July </month> <year> 1975. </year>
Reference-contexts: With modern superscalar hardware, these dependences are a serious bottleneck. In order to save on storage for links, "cdr-coding" was proposed in the 1970's <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>. <p> of NUR is that our compiler does not have a good dead code detection algorithm, we believe that a more refined implementation can achieve more code sharing and produce much smaller code. 6.5 Related work Cdr-coding techniques were first proposed in the early 70's by researchers at MIT and Xerox <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>.
Reference: [Car84a] <author> Luca Cardelli. </author> <title> Compiling a functional language. </title> <booktitle> In Proc. of the 1984 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 208-217, </pages> <month> August </month> <year> 1984. </year>
Reference-contexts: Some compilers <ref> [Ste78, KKR fl 86, Car84a] </ref> perform closure conversion and closure analyses as part of their translation from lambda calculus or continuation-passing style into machine code. <p> ,econs (e 2 ,e 3 )) can be transformed to TAIL2 (e 1 ,e 2 ,e 3 ), which avoids the parity checking and the allocation of the intermediate odd-length list cell. 4 In practice, TAIL1 is a transparent data constructor, thus does not require any extra storage to represent <ref> [Car84a, App92] </ref>. CHAPTER 6. UNROLLING LISTS 126 6.2.2 An introduction to refinement types In this section, we give a brief introduction to the refinement type system used in our translation algorithm (see Section 6.2.3).
Reference: [Car84b] <author> Luca Cardelli. </author> <title> A Semantics of Multiple Inheritance. In Semantics of Data Types, </title> <booktitle> International Symposium, </booktitle> <pages> pages 51-68, </pages> <address> Berlin, June 1984. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: A flat closure <ref> [Car84b] </ref> is a record that holds only the free variables needed by the function. For example, the flat closure for h (denoted as H) contains just the code pointer (denoted by h) plus the values for variable u, w, x, y, and z.
Reference: [CCM85] <author> G. Cousineau, P. L. Curien, and M. Mauny. </author> <title> The Categorical Abstract Machine. </title> <editor> In J. P. Jouannaud, editor, </editor> <booktitle> Functional Programming Languages and Computer Architecture, </booktitle> <volume> LNCS Vol 201, </volume> <pages> pages 50-64, </pages> <address> New York, 1985. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: But it is useful to separate the closure introduction from machine code generation so that the compiler is more modular; this has been done in compilers based on ordinary -calculus (through lambda lifting) <ref> [CCM85, Joh85] </ref> and on continuation-passing style (using closure-passing style) [AJ89, KH89]. Many have tried to make call/cc efficient, but this is very hard to achieve in traditional stack-based schemes. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation.
Reference: [CG77] <author> Douglas W. Clark and C. Cordell Green. </author> <title> An Empirical Study of List Structure in Lisp. </title> <journal> Communications of the ACM, </journal> <volume> 20(2) </volume> <pages> 78-87, </pages> <month> February </month> <year> 1977. </year>
Reference-contexts: With modern superscalar hardware, these dependences are a serious bottleneck. In order to save on storage for links, "cdr-coding" was proposed in the 1970's <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>. <p> of NUR is that our compiler does not have a good dead code detection algorithm, we believe that a more refined implementation can achieve more code sharing and produce much smaller code. 6.5 Related work Cdr-coding techniques were first proposed in the early 70's by researchers at MIT and Xerox <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>.
Reference: [Cha82] <author> Gregory J. Chaitin. </author> <title> Register Allocation and Spilling via Graph Coloring. </title> <booktitle> In Symposium on Compiler Construction, </booktitle> <pages> pages 98-105, </pages> <address> New York, </address> <month> June </month> <year> 1982. </year> <journal> ACM Sigplan. </journal> <volume> BIBLIOGRAPHY 148 </volume>
Reference-contexts: These intermediate variables (e.g., register r) may use up all the available machine registers and cause unnecessary register spilling, but this can always be avoided by selectively keeping limited number of intermediate variables in the "lazy display" (registers). 4.4.6 Remarks Graph-coloring global register allocation and targeting <ref> [Cha82, BCKT89] </ref>, which have been implemented for SML/NJ by Lal George et al [GGR94], accomplishes most control transfers (function calls) (such as line 12 and 13 in Figure 19) without any register-register moves. This allows a more flexible boundary between callee-save and caller-save registers than is normal in most compilers. <p> We achieve this by allocating part of the closures (for known functions and continuations) in both caller-and callee-save registers, and then using the graph-coloring global register allocation and targeting algorithms <ref> [Cha82, BCKT89, GGR94] </ref>. 4.8 Summary Our new closure conversion algorithm is a great success. The closure conversion algorithm itself is faster than our previous algorithm (see Table 15). It makes programs smaller (by an CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 90 average of 19%) and faster (by an average of 14%).
Reference: [Cha88] <author> David R. Chase. </author> <title> Safety considerations for storage allocation optimizations. </title> <booktitle> In Proc. ACM SIGPLAN '88 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 1-9, </pages> <address> New York, June 1988. </address> <publisher> ACM Press. </publisher>
Reference-contexts: In a garbage-collected language, the garbage collector need not use such variables as "roots" of live data. Several implementors have independently discovered that this is really important: if the collector traverses too many dead variables, the memory use of the program can increase by a large factor <ref> [Bak76, Cha88, RW93, App92, Jon92] </ref>.
Reference: [Cho88a] <author> Fred C. Chow. </author> <title> Minimizing Register Usage Penalty at Procedure Calls. </title> <booktitle> In Proc. ACM SIGPLAN '88 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 85-94, </pages> <address> New York, June 1988. </address> <publisher> ACM Press. </publisher>
Reference-contexts: This turns to be complicated to implement. Danvy [Dan87] proposed to use a free list of re-usable frames (or "quasi-stack") to support fast call/cc; but his method may incur extra overhead at each function call (or return). Both Chow <ref> [Cho88a] </ref> and Steele [SS80] observed that dataflow analysis can help decide whether to put variables in caller-save or callee-save registers. <p> Local variables of different functions with nonoverlapping live ranges can be allocated to the same register or global without any save/restore <ref> [GS91, Cho88a] </ref>. We achieve this by allocating part of the closures (for known functions and continuations) in both caller-and callee-save registers, and then using the graph-coloring global register allocation and targeting algorithms [Cha82, BCKT89, GGR94]. 4.8 Summary Our new closure conversion algorithm is a great success.
Reference: [CHO88b] <author> William D Clinger, Anne H Hartheimer, and Eric M Ost. </author> <title> Implementation Strategies for Continuations. </title> <booktitle> In 1988 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 124-131, </pages> <address> New York, June 1988. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Many have tried to make call/cc efficient, but this is very hard to achieve in traditional stack-based schemes. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation. Clinger <ref> [CHO88b] </ref> and Hieb [HDB90] presented several mixed stack/heap strategies intended to support call/cc efficiently in the presence of stacks. Their basic idea is to make a "stack chunk" that holds several stack frames; if this fills, it is linked to another chunk allocated from the heap. <p> There have been mixed stack/heap implementations intended to support call/cc efficiently in the presence of stacks <ref> [CHO88b, HDB90] </ref>. The basic idea is to make a "stack chunk" that holds several stack frames; if this fills, it is linked to another chunk allocated from the heap. This turns out to be complicated to implement.
Reference: [CHR78] <author> W. P. Crowley, C. P. Hendrickson, and T. E. Rudy. </author> <title> The SIMPLE Code. </title> <type> Technical Report UCID 17715, </type> <institution> Lawrence Livermore Laboratory, Livermore, </institution> <address> CA, </address> <month> February </month> <year> 1978. </year>
Reference-contexts: Ray 874 5 5 A simple ray tracer written in C by Don Mitchell, translated into Standard ML by John Reppy. Simple 990 2 1 A spherical fluid-dynamics program, developed as a "realistic" FORTRAN benchmark <ref> [CHR78] </ref>, translated into ID [EA87], and then translated into Standard ML by Lal George. VLIW 3658 24 2 A Very-Long-Instruction-Word instruc tion scheduler written by John Danskin. YACC 7432 56 26 A LALR (1) parser generator, implemented by David R. Tarditi [TA90], processing the gram mar of Standard ML.
Reference: [Chu41] <author> Alonzo Church. </author> <title> The Calculi of Lambda Conversion. </title> <publisher> Princeton University Press, </publisher> <year> 1941. </year>
Reference-contexts: core ML language and its polymorphic type system; a more detailed description of Standard ML [MTH90] is presented later in Section 2.2. 2.1.1 Lambda calculus The development of functional languages has been influenced from time to time by many sources, but none is as fundamental as the work of Church <ref> [Chu41] </ref> on the lambda calculus. The lambda calculus is often regarded as the first functional language, and all modern functional languages can be thought of as nontrivial embellishments of the lambda calculus. Interested readers are referred to the excellent book by Barendregt [Bar84] for more detailed explanations. CHAPTER 2.
Reference: [Cla76] <author> Douglas W. Clark. </author> <title> List structure: measurements, algorithms, and encodings. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon Univ., </institution> <address> Pittsburgh, PA, </address> <month> August </month> <year> 1976. </year>
Reference-contexts: With modern superscalar hardware, these dependences are a serious bottleneck. In order to save on storage for links, "cdr-coding" was proposed in the 1970's <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>. <p> of NUR is that our compiler does not have a good dead code detection algorithm, we believe that a more refined implementation can achieve more code sharing and produce much smaller code. 6.5 Related work Cdr-coding techniques were first proposed in the early 70's by researchers at MIT and Xerox <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>.
Reference: [Dan87] <author> Olivier Danvy. </author> <title> Memory Allocation and Higher-Order Functions. </title> <booktitle> In Proceedings of the SIGPLAN'87 Symposium on Interpreters and Interpretive Techniques, </booktitle> <pages> pages 241-252. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1987. </year>
Reference-contexts: Their basic idea is to make a "stack chunk" that holds several stack frames; if this fills, it is linked to another chunk allocated from the heap. This turns to be complicated to implement. Danvy <ref> [Dan87] </ref> proposed to use a free list of re-usable frames (or "quasi-stack") to support fast call/cc; but his method may incur extra overhead at each function call (or return). <p> This turns out to be complicated to implement. Stack chunks require a stack-overflow test on every frame, 14 so creation costs three instructions (add to SP, compare, branch). Danvy <ref> [Dan87] </ref> made a free list of re-usable frames (we call this a "quasi-stack"); these reduce the load on the garbage collector and have good locality; but they are expensive to create and destroy, and require a frame pointer.
Reference: [Deu73] <author> L. P. Deutsch. </author> <title> A Lisp machine with very compact programs. </title> <booktitle> In Proc. 3rd IJACI, </booktitle> <pages> pages 697-703, </pages> <year> 1973. </year>
Reference-contexts: Cdr-coding solves the space-usage problem (and in the MIT version allows random access subscripting of lists [Gre77]), but makes the control-dependence problem even worse, as the cdr-coding tag of each car must be checked. Cdr-coding was popular on microcoded Lisp machines circa 1980 <ref> [WM81, Deu73] </ref>, but it is not an attractive solution on modern machines. Our new "compile-time cdr-coding" method works for statically typed languages such as ML. Our scheme allows a more compact runtime representation for lists, but does not require any runtime encoding at all. <p> CHAPTER 6. UNROLLING LISTS 138 Lisp machines <ref> [WM81, Deu73] </ref> to alleviate the high costs incurred by the runtime encoding bits. Since modern machines tend not to offer these kinds of special hardware support, the runtime cdr-coding technique quickly became obsolete in the 1980's.
Reference: [DG94] <author> Damien Doligez and Georges Gonthier. Re: </author> <title> stack scanning for generational g.c. E-mail message &lt;9403041606.AA07877@lix.polytechnique.fr&gt;, </title> <month> March </month> <year> 1994. </year>
Reference-contexts: In rare cases (very deep one-way recursions) the cost will be higher, but the stack-based systems and heap-based systems will pay approximately the same price. Doligez and Gonthier <ref> [DG94] </ref> have suggested that the collector put a one-bit mark in every live stack frame that it scans; this mark will be ignored by the collector but will be cleared in new frames. This is fine, if there is already some word in every frame that has a free bit.
Reference: [DHM91] <author> Bruce Duba, Robert Harper, and David MacQueen. </author> <title> Typing First-Class Continuations in ML. </title> <booktitle> In Eighteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 163-173, </pages> <address> New York, Jan 1991. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The above function head2 will return 0 if the argument is an empty list. 2.2.6 First-class continuations An extension in Standard ML of New Jersey (SML/NJ) [AM91] is the typed first-class continuation <ref> [DHM91] </ref>, defined as follows: type 'a cont val callcc : ('1a cont -&gt; '1a) -&gt; '1a val throw : 'a cont -&gt; 'a -&gt; 'b Here, cont is an abstract type constructor; "'1a" denotes a weak type variable (also used for typing references) [Mac88]; callcc is used to capture the current <p> such a compiler, it is best to keep the top frame in callee-save registers and not in memory at all. 5.9 First-class continuations The notion of "first class continuations" using the call-with-current-continuation (call/cc) primitive originated in the Scheme language [RC86] and has since been adopted in other systems as well <ref> [DHM91] </ref>. First class continuations are useful for implementing coroutines [Wan80] and concurrency libraries [Rep91]. But call/cc is much harder to implement efficiently if there is a stack. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation.
Reference: [Dig92] <institution> Digital Equipment Corp., Maynard, </institution> <address> MA. </address> <note> DECchip(tm) 21064-AA Microprocessor Hardware Reference Manual, first edition, October 1992. BIBLIOGRAPHY 149 </note>
Reference-contexts: Garbage-prefetch: On a machine with a no-write-allocate (write-around) cache, write-allocate can be simulated (as long as read misses are nonblocking) by fetching the cache line (with an ordinary read instruction) in advance of the write [App94a]. This technique works (providing a modest performance enhancement) on the DEC Alpha 21064 <ref> [Dig92] </ref>, for example. On any of these machines, heap-allocated data should not incur a write-miss penalty. Assumption: Any small cache will have write-allocate and no write-miss latency (or write-allocate can be emulated).
Reference: [DM82] <author> Luis Damas and Robin Milner. </author> <title> Principal type-schemes for functional programs. </title> <booktitle> In Ninth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 207-212, </pages> <address> New York, Jan 1982. </address> <publisher> ACM Press. </publisher>
Reference-contexts: We are particularly concerned with the principal type of e under TE, namely the type t such that if TE ` e : t and TE ` e : t 0 , then gen (TE; t ) t 0 . Damas and Milner <ref> [DM82] </ref> have shown that any expression that has a type in a given environment has a principal type in that environment, which is unique except for choice of bound type-variable names and can be inferred using the well-known type assignment algorithm "W " [DM82]. <p> Damas and Milner <ref> [DM82] </ref> have shown that any expression that has a type in a given environment has a principal type in that environment, which is unique except for choice of bound type-variable names and can be inferred using the well-known type assignment algorithm "W " [DM82]. Standard ML [MTH90] is just core ML extended with constants, pattern matching, data type definitions, references and exceptions, and a sophisticated module system [Mac84]. <p> TYPE-DIRECTED COMPILATION 33 forms. This phase elaborates all program declarations and specifications (e.g., modules, module interfaces, type and value declarations, etc.) into semantic objects according to the static semantics [MTH90]; the types of all program variables are inferred and checked using the ML type inference algorithm <ref> [DM82, MTH90] </ref>. The raw abstract syntax tree is rewritten into a more compact form called abstract syntax (Ab-syn). Each declaration in Absyn is annotated with its corresponding static semantic or type information calculated during elaboration. <p> CHAPTER 3. TYPE-DIRECTED COMPILATION 38 3.4.3 Minimum typing derivation Like the Damas-Milner type assignment algorithm W <ref> [DM82] </ref>, The elaboration phase in our compiler also infers the most general type schemes for all SML programs. As a result, local variables are always assigned the most polymorphic types, even though they are used much less polymorphically.
Reference: [DTM94] <author> Amer Diwan, David Tarditi, and Eliot Moss. </author> <title> Memory subsystem performance of programs using copying garbage collection. </title> <booktitle> In Proc. 21st Annual ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, </booktitle> <pages> pages 1-14. </pages> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: Stacks do have a much better write miss ratio, but not a much better read miss ratio. But on many modern machines, the write miss penalty is approximately zero <ref> [Jou93, DTM94, Rei94] </ref>. 3. The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. <p> If any system should have poor cache locality, this is the one. Diwan, Tarditi, and Moss <ref> [DTM94] </ref> simulated the memory-hierarchy performance of SML/NJ on a DECstation 5000, and found two things: * SML/NJ program executions have an astoundingly high write-miss ratio. * SML/NJ programs are not much delayed by cache misses. <p> Thus, a write miss does not require reading the rest of the written cache line from memory. Subsequent (sequential) writes will fill the rest of the line. One-word cache line: The DECstation 5000 has a cache-line size of one word, but four lines are read on a miss <ref> [DTM94] </ref>. For some applications this is better than subblock placement, but for sequential writes it is equally good. It is more expensive to implement, since it requires a full tag (not just a valid bit) for each word. Diwan et al. found excellent memory-subsystem performance for SML/NJ on this machine. <p> The simulations counted read misses, write misses, and total instruction count of SML programs compiled to the MIPS instruction set. The total instruction count also includes the instructions and cache misses of garbage collection. Diwan et al. <ref> [DTM94] </ref> measured a heap-only ML system; Reinhold [Rei94] measured a stack-frame Scheme system. In order to make a more direct comparison, we measured stack frames vs. heap frames in the same ML system. We simulated only the primary data cache. <p> Stack frames, running in simulated caches of different sizes. We simulated a write-allocate cache with partial fill (the left-hand-side of Figure 25), and also a write-around cache (the right-hand-side of Figure 25). Jouppi [Jou93] simulated both kinds of cache for C programs without garbage collection; Diwan et al. <ref> [DTM94] </ref> simulated both caches for almost purely heap-allocating ML programs. By simulating both caches on stack and heap allocation for the same programs, we can compare more straightforwardly. <p> Jouppi's measurements of C and fortran programs [Jou93] may perhaps be influential. He concludes that write-validate (that is, write-allocate, no-fetch-on-write) is the policy with best performance. This is exactly the policy that we and others <ref> [DTM94, Rei94, SM94] </ref> find best for garbage-collected strict functional programs. On the other hand, as Jouppi points out, write-validate is difficult|though not impossible|to implement on a shared-memory multiprocessor with cache coherence. Such machines require each writable cache line to have a single owner.
Reference: [EA87] <author> K. Ekanadham and Arvind. </author> <title> SIMPLE: An Exercise in Future Scientific Programming. Technical Report Computation Structures Group Memo 273, </title> <publisher> MIT, </publisher> <address> Cambridge, MA, </address> <month> July </month> <year> 1987. </year> <note> Simultaneously published as IBM/T.J. </note> <institution> Watson Research Center Research Report 12686, Yorktown Heights, NY. </institution>
Reference-contexts: Ray 874 5 5 A simple ray tracer written in C by Don Mitchell, translated into Standard ML by John Reppy. Simple 990 2 1 A spherical fluid-dynamics program, developed as a "realistic" FORTRAN benchmark [CHR78], translated into ID <ref> [EA87] </ref>, and then translated into Standard ML by Lal George. VLIW 3658 24 2 A Very-Long-Instruction-Word instruc tion scheduler written by John Danskin. YACC 7432 56 26 A LALR (1) parser generator, implemented by David R. Tarditi [TA90], processing the gram mar of Standard ML.
Reference: [FP91] <author> Tim Freeman and Frank Pfenning. </author> <title> Refinement Types for ML. </title> <booktitle> In Proc. ACM SIGPLAN '91 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 268-277, </pages> <address> New York, July 1991. </address> <publisher> ACM Press. </publisher>
Reference-contexts: We borrow the refinement type inference algorithm of Freeman and Pfenning <ref> [FP91, Fre92] </ref> by introducing a refinement of the list type: the type olist for odd-length lists and the type elist for even-length lists. <p> CHAPTER 6. UNROLLING LISTS 126 6.2.2 An introduction to refinement types In this section, we give a brief introduction to the refinement type system used in our translation algorithm (see Section 6.2.3). Most of the notation and concepts are directly borrowed from Freeman and Pfenning <ref> [FP91, Fre92] </ref>, since our system is just a simplified version of theirs. Basically we refine the list type by introducing elist for even-length lists and olist for odd-length lists. <p> CHAPTER 6. UNROLLING LISTS 127 The operation apprfty of applying a refinement type 1 to another refinement type 2 is defined by rules (A1-A4) in Figure 29. This operation is used extensively by the meta operation applyfun during the translation (see Section 6.2.3). Freeman and Pfenning <ref> [Fre92, FP91] </ref> give an refinement type inference algorithm for typed core-ML. <p> Coercions among representations for even-length lists, odd-length lists, and lists whose length parity is unknown, are quite cheap. The refinement type system used in Section 6.2 is a much simplified version of Freeman and Pfenning's refinement type system <ref> [FP91, Fre92] </ref>. While the underlying framework and type inference algorithm are quite similar, our motivation is rather different. In their system, the refinement type is declared by the programmer, and the refinement type information is used to detect program errors at compile time.
Reference: [Fre92] <institution> Tim Freeman. Carnegie Mellon University, </institution> <type> personal communication, </type> <year> 1992. </year>
Reference-contexts: We borrow the refinement type inference algorithm of Freeman and Pfenning <ref> [FP91, Fre92] </ref> by introducing a refinement of the list type: the type olist for odd-length lists and the type elist for even-length lists. <p> CHAPTER 6. UNROLLING LISTS 126 6.2.2 An introduction to refinement types In this section, we give a brief introduction to the refinement type system used in our translation algorithm (see Section 6.2.3). Most of the notation and concepts are directly borrowed from Freeman and Pfenning <ref> [FP91, Fre92] </ref>, since our system is just a simplified version of theirs. Basically we refine the list type by introducing elist for even-length lists and olist for odd-length lists. <p> CHAPTER 6. UNROLLING LISTS 127 The operation apprfty of applying a refinement type 1 to another refinement type 2 is defined by rules (A1-A4) in Figure 29. This operation is used extensively by the meta operation applyfun during the translation (see Section 6.2.3). Freeman and Pfenning <ref> [Fre92, FP91] </ref> give an refinement type inference algorithm for typed core-ML. <p> Coercions among representations for even-length lists, odd-length lists, and lists whose length parity is unknown, are quite cheap. The refinement type system used in Section 6.2 is a much simplified version of Freeman and Pfenning's refinement type system <ref> [FP91, Fre92] </ref>. While the underlying framework and type inference algorithm are quite similar, our motivation is rather different. In their system, the refinement type is declared by the programmer, and the refinement type information is used to detect program errors at compile time.
Reference: [Fre94] <author> Tim Freeman. </author> <title> Refinement Types for ML. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon Univ., Pittsburgh, Pennsylvania, </institution> <month> March </month> <year> 1994. </year> <month> CMU-CS-94-110. </month>
Reference-contexts: The loop inside DecComp computes the fixed point of the refinement types; this is guaranteed to terminate because there are only finitely many refinement types below any given SRC type (a proof of this is given by Freeman <ref> [Fre94, Chapter 2] </ref>). 5 Since there are no redundant matches, m must have the form fn (x t ) e). CHAPTER 6.
Reference: [FTL94] <author> M. Feeley, M. Turcotte, and G. LaPalme. </author> <title> Using Multilisp for solving constraint satisfaction problems: an application to nucleic acid 3D strucure determination. Lisp and Symbolic Computation, </title> <note> page (to appear), </note> <year> 1994. </year>
Reference-contexts: Tarditi [TA90], processing the gram mar of Standard ML. MBrot 60 1 1 The Mandelbrot curve construction written by John Reppy. Nucleic 3307 1 1 The pseudoknot program that computes the three-dimensional structure of part of a nucleic acid molecule <ref> [FTL94] </ref>, translated from Scheme into Standard ML by Peter Lee. CHAPTER 2. BACKGROUND 25 run as its final performance data (as recommended, for example, by the SPEC benchmark consortium [Sta89]). All compilers mentioned in this dissertation use a simple two-generation copying garbage collector [App89].
Reference: [Gab85] <author> Richard P. Gabriel. </author> <title> Performance and Evaluation of Lisp Systems. </title> <publisher> MIT Press, </publisher> <address> Boston, MA, </address> <year> 1985. </year>
Reference-contexts: CHAPTER 2. BACKGROUND 24 Table 2: General information about the benchmark programs Program Lines Modules Files Description BHut 1258 9 9 "Barnes-Hut" N-body problem solver [BH86], translated from C into Standard ML by John Reppy. Boyer 919 4 3 Standard theorem-prover benchmark [BM72], translated from the Gabriel benchmark <ref> [Gab85] </ref>. Sieve 1356 4 5 CML implementation of prime number gener ator written by John Reppy [Rep91]. KB-Comp 655 1 1 An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen 1185 5 1 A lexical-analyzer generator, implemented by James S.
Reference: [GGR94] <author> Lal George, Florent Guillaume, and John Reppy. </author> <title> A portable and optimizing backend for the SML/NJ compiler. </title> <booktitle> In Proceedings of the 1994 International Conference on Compiler Construction, </booktitle> <pages> pages 83-97. </pages> <publisher> Springer-Verlag, </publisher> <month> April </month> <year> 1994. </year>
Reference-contexts: all the available machine registers and cause unnecessary register spilling, but this can always be avoided by selectively keeping limited number of intermediate variables in the "lazy display" (registers). 4.4.6 Remarks Graph-coloring global register allocation and targeting [Cha82, BCKT89], which have been implemented for SML/NJ by Lal George et al <ref> [GGR94] </ref>, accomplishes most control transfers (function calls) (such as line 12 and 13 in Figure 19) without any register-register moves. This allows a more flexible boundary between callee-save and caller-save registers than is normal in most compilers. <p> We achieve this by allocating part of the closures (for known functions and continuations) in both caller-and callee-save registers, and then using the graph-coloring global register allocation and targeting algorithms <ref> [Cha82, BCKT89, GGR94] </ref>. 4.8 Summary Our new closure conversion algorithm is a great success. The closure conversion algorithm itself is faster than our previous algorithm (see Table 15). It makes programs smaller (by an CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 90 average of 19%) and faster (by an average of 14%).
Reference: [Gre77] <author> R. Greenblatt. </author> <title> LISP Machine Progress Report memo 444. </title> <type> Technical report, </type> <institution> A.I. Lab., M.I.T., </institution> <address> Cambridge, MA, </address> <month> August </month> <year> 1977. </year>
Reference-contexts: With modern superscalar hardware, these dependences are a serious bottleneck. In order to save on storage for links, "cdr-coding" was proposed in the 1970's <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>. <p> A depth-first (or breadth-first [Bak78]) copying garbage collector helps ensure that most lists are arranged sequentially in storage, so they can take advantage of this encoding. Cdr-coding solves the space-usage problem (and in the MIT version allows random access subscripting of lists <ref> [Gre77] </ref>), but makes the control-dependence problem even worse, as the cdr-coding tag of each car must be checked. Cdr-coding was popular on microcoded Lisp machines circa 1980 [WM81, Deu73], but it is not an attractive solution on modern machines. <p> of NUR is that our compiler does not have a good dead code detection algorithm, we believe that a more refined implementation can achieve more code sharing and produce much smaller code. 6.5 Related work Cdr-coding techniques were first proposed in the early 70's by researchers at MIT and Xerox <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>.
Reference: [GS91] <author> Carsten K. Gomard and Peter Sestoft. </author> <title> Globalization and Live Variables. </title> <booktitle> In Proceedings of the 1991 Symposium on Partial Evaluation and Semantics-Based Program Manipulation, </booktitle> <pages> pages 166-177. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1991. </year> <note> BIBLIOGRAPHY 150 </note>
Reference-contexts: Local variables of different functions with nonoverlapping live ranges can be allocated to the same register or global without any save/restore <ref> [GS91, Cho88a] </ref>. We achieve this by allocating part of the closures (for known functions and continuations) in both caller-and callee-save registers, and then using the graph-coloring global register allocation and targeting algorithms [Cha82, BCKT89, GGR94]. 4.8 Summary Our new closure conversion algorithm is a great success.
Reference: [Hal94] <author> Cordelia V. Hall. </author> <title> Using Hindley-Milner Type Inference to Optimize List Representation. </title> <booktitle> In 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 162-172, </pages> <address> New York, June 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: Our static cdr-coding method, on the other hand, exploits compile-time analysis to eliminate most runtime checks; at the same time, it poses no more problem in parallel environments than does ordinary allocation. On the side of statically typed languages, Hall <ref> [Hal94] </ref> has presented a list compaction technique for Haskell [HJet al92]. In her scheme, lists can be represented as the old standard representation (OSR) at one place, and in an optimized representation at another place.
Reference: [Han69] <author> Wilfred J. Hansen. </author> <title> Compact List Representation: Definition, Garbage Collection, and System Implementation. </title> <journal> Communications of the ACM, </journal> <volume> 12(9) </volume> <pages> 499-507, </pages> <month> Sep </month> <year> 1969. </year>
Reference-contexts: With modern superscalar hardware, these dependences are a serious bottleneck. In order to save on storage for links, "cdr-coding" was proposed in the 1970's <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>. <p> of NUR is that our compiler does not have a good dead code detection algorithm, we believe that a more refined implementation can achieve more code sharing and produce much smaller code. 6.5 Related work Cdr-coding techniques were first proposed in the early 70's by researchers at MIT and Xerox <ref> [Han69, Gre77, Cla76, CG77, BC79, Bob75] </ref>.
Reference: [Han80] <author> David R. Hanson. </author> <title> A Portable Storage Management System for the Icon Programming Language. </title> <journal> Software|Practice and Experience, </journal> <volume> 10 </volume> <pages> 489-500, </pages> <year> 1980. </year>
Reference-contexts: 3 However, the cost of reserving these registers should not be charged to heap allocation of frames, because we are assuming that the implementation in question already 2 Actually, SML/NJ does write an explicit descriptor to each frame, for simplicity. 3 Some implementations use a BIBOP (BIg Bag Of Pages <ref> [Han80] </ref>) scheme that allocates each kind of object in a different contiguous space, so that only one g.c.-descriptor is required per space, instead of per object. This requires a free-space pointer and a limit pointer per space. CHAPTER 5. HEAP VS.
Reference: [Han90] <author> Chris Hanson. </author> <title> Efficient Stack Allocation for Tail-Recursive Languages. </title> <booktitle> In 1990 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 106-118, </pages> <address> New York, June 1990. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques <ref> [Kra87, AS92, Ste78, Roz84, Han90, Joh85] </ref>, using a simple and general framework expressed in continuation-passing and closure-passing style [AJ89, AS92]. Our new algorithm extensively exploits the use of compile-time control and data flow information to optimize closure allocation strategies and representations. <p> It may be useful to use more callee-save (and fewer caller-save) registers to optimize this (e.g., to reduce total heap allocation) Our closure scheme handles tail calls very nicely, simply by re-arranging registers. Han-son <ref> [Han90] </ref> shows how complicated things become when it's necessary to re-arrange a stack frame. A source-language function that calls several other functions in sequence would, in previous CPS compilers (including our own), allocate a continuation closure for each call. <p> The closure conversion algorithm described in this chapter combines all of these analyses (except stack allocation) and more, while still satisfying the "safe for space complexity" rule. CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 89 Hanson <ref> [Han90] </ref> showed the complexity of implementing tail calls correctly and efficiently on a conventional stack. <p> In particular, most conventional stack implementations are not safe for space complexity. 2. To preserve space complexity and correctly implement tail recursion, certain activation records require a complicated scheme to determine when they must be popped <ref> [Han90] </ref>. (Or these frames could be heap allocated, even in a stack discipline; but they must be identified by static analysis.) 3. A high-water mark must be maintained to achieve efficiency in the generational col lector. 4.
Reference: [Har86] <author> Robert Harper. </author> <title> Introduction to Standard ML. </title> <type> Technical Report ECS-LFCS-86-14, </type> <institution> Univ. of Edinburgh, Dept. of Computer Science, Edinburgh, EH9 3JZ, </institution> <month> August </month> <year> 1986. </year>
Reference-contexts: and one cdr field, the unrolled list reduces the memory used for links and significantly shortens the length of control-dependence and data-dependence chains in operations on lists. 1.2 Outline of this dissertation The development of this dissertation may be easier to follow for readers with some background in Standard ML <ref> [Ull93, Har86, MTH90] </ref> and basic compilation techniques for functional languages [App92, Pey87]. Chapter 2 contains a survey of various functional languages, an introduction to SML (which may be skipped if the reader is familiar with SML notation), and a review of several important aspects in compiling functional languages. <p> Readers are referred to References <ref> [Har86, Ull93, Pau91] </ref> for a more complete introduction. The formal definition and commentary for SML can be found in References [MTH90, MT91]. 2.2.1 Basic expressions, values, and types SML is an expression language: the traditional statement constructs, such as blocks, conditionals, case statements, and assignment, are packaged as expressions.
Reference: [HDB90] <author> Robert Hieb, R. Kent Dybvig, and Carl Bruggeman. </author> <title> Representing Control in the Presence of First-Class Continuations. </title> <booktitle> In Proc. ACM SIGPLAN '90 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 66-77, </pages> <address> New York, 1990. </address> <publisher> ACM Press. </publisher>
Reference-contexts: makes generational garbage collection and call/cc efficient, and also reduces the need for alias analysis in the compiler (since there are less side-effect operations). * Because all closures are allocated either in the heap or in registers, first class contin uations call/cc are very efficient, requiring no complicated stack hackery <ref> [HDB90] </ref>. CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 63 Our new closure allocation scheme does not use any runtime stack. Instead, all closure environments are either allocated in the heap or in registers. <p> Many have tried to make call/cc efficient, but this is very hard to achieve in traditional stack-based schemes. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation. Clinger [CHO88b] and Hieb <ref> [HDB90] </ref> presented several mixed stack/heap strategies intended to support call/cc efficiently in the presence of stacks. Their basic idea is to make a "stack chunk" that holds several stack frames; if this fills, it is linked to another chunk allocated from the heap. This turns to be complicated to implement. <p> There have been mixed stack/heap implementations intended to support call/cc efficiently in the presence of stacks <ref> [CHO88b, HDB90] </ref>. The basic idea is to make a "stack chunk" that holds several stack frames; if this fills, it is linked to another chunk allocated from the heap. This turns out to be complicated to implement. <p> The simplicity and efficiency of call/cc in a pure heap discipline is a strong motivation for avoiding stacks. 14 "Unfortunately, it has been our experience that memory exceptions are not a tenable means for detecting stack overflow...." <ref> [HDB90] </ref> CHAPTER 5. HEAP VS. STACK 116 5.10 Implementation One reason to avoid stacks is that they are complicated to implement, especially with all the tricks that are necessary to achieve good performance. <p> A high-water mark must be maintained to achieve efficiency in the generational col lector. 4. If call/cc is to be supported, then stack copying or some more complicated technique must be implemented <ref> [HDB90] </ref>. 5. To avoid having a descriptor in each frame, the runtime system must maintain a mapping of return addresses to frame layout descriptors. CHAPTER 5. HEAP VS. STACK 117 6. In a system with multiple threads, each thread must have its own stack.
Reference: [HHH fl 90] <author> William R. Hardell, Dwain A. Hicks, Lawrence C. Howell, Warren E. Maule, Robert Montoye, and David P. Tuttle. </author> <title> Data Cache and Storage Control Units. </title> <booktitle> In IBM RISC System/6000 Technology, </booktitle> <pages> pages 44-50. </pages> <institution> IBM, </institution> <year> 1990. </year>
Reference-contexts: It is more expensive to implement, since it requires a full tag (not just a valid bit) for each word. Diwan et al. found excellent memory-subsystem performance for SML/NJ on this machine. Cache-line zero instruction: On some machines (e.g., IBM R/S6000 <ref> [HHH fl 90] </ref> and PowerPC [AB93], Power2, HP PA) a cache line (64 bytes) can be allocated and zeroed with a special instruction.
Reference: [Hil88] <author> Mark D. Hill. </author> <title> A Case for Direct-Mapped Caches. </title> <journal> IEEE Computer, </journal> <volume> 21(12) </volume> <pages> 25-40, </pages> <month> December </month> <year> 1988. </year>
Reference-contexts: CHAPTER 5. HEAP VS. STACK 104 have direct-mapped caches especially at the first level of the memory hierarchy, so that tag comparison can be overlapped with further computations on the value fetched <ref> [Hil88] </ref>.
Reference: [Hin69] <author> Roger Hindley. </author> <title> The principle type scheme of an object in combinatory logic. </title> <journal> Trans. Amer. Math. Soc., </journal> <volume> 146 </volume> <pages> 29-60, </pages> <year> 1969. </year>
Reference-contexts: j x.e 1 j e 1 e 2 j let x = e 1 in e 2 Here, the let statement is just a syntactic language construct equivalent to [e 1 =x]e 2 ; this additional structure is used to support ML's powerful polymorphic type system, developed independently by Hindley <ref> [Hin69] </ref> and Milner [Mil78].
Reference: [HJ94] <author> Fritz Henglein and Jesper Jorgensen. </author> <title> Formally Optimal Boxing. </title> <booktitle> In Proc. 21st Annual ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, </booktitle> <pages> pages 213-226. </pages> <publisher> ACM Press, </publisher> <year> 1994. </year>
Reference-contexts: The major problem of his technique is that it is not easy to extend to the SML module system. Henglein and Jorgensen <ref> [HJ94] </ref> presents a term-rewriting method that translates a program with many coercions into one that contains "minimum" number of coercions (statically). Once again, it is not clear how their technique can easily be extended to the SML module language. <p> This is very easy to extend to the module system. We believe our approach can almost achieve the same result as "formally optimal unboxing" <ref> [HJ94] </ref>. Actually, we have shown that "wrapper" eliminations do not have much effect on performance in a highly optimizing compiler such as SML/NJ, simply because a simple compile-time contraction can eliminate most of the wrap and unwrap pairs (see Section 3.6.3).
Reference: [HJet al92] <editor> Paul Hudak, Simon Peyton Jones, and Philip Wadler et al. </editor> <title> Report on the Programming Language Haskell, A Non-strict, Purely Functional Language Version 1.2. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(5), </volume> <month> May </month> <year> 1992. </year> <note> BIBLIOGRAPHY 151 </note>
Reference-contexts: run time, and operators need not to check the types of their arguments at run time. * SML uses call-by-value evaluation semantics, so SML programs still have understandable control flow to do all conventional data flow and control flow optimiza tions [ASU86]. * Unlike pure functional languages such as Haskell <ref> [HJet al92] </ref>, SML is just a mostly functional language. <p> We'll explain the details of Standard ML in Section 2.2. 2.1.4 Haskell Haskell is a nonstrict, purely functional programming language developed by Hudak, Peyton Jones, Wadler et al <ref> [HJet al92] </ref>. Core Haskell is very much like the core ML described in the last section; it is a statically typed language with the same Hindley-Milner type system. The main differences between ML and Haskell are as follows: CHAPTER 2. <p> Our static cdr-coding method, on the other hand, exploits compile-time analysis to eliminate most runtime checks; at the same time, it poses no more problem in parallel environments than does ordinary allocation. On the side of statically typed languages, Hall [Hal94] has presented a list compaction technique for Haskell <ref> [HJet al92] </ref>. In her scheme, lists can be represented as the old standard representation (OSR) at one place, and in an optimized representation at another place.
Reference: [HL94] <author> Robert Harper and Mark Lillibridge. </author> <title> A Type-Theoretic Approach to Higher-Order Modules with Sharing. </title> <booktitle> In Twenty-first Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 123-137, </pages> <address> New York, Jan 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: TYPE-DIRECTED COMPILATION 37 if there are substructures) in the original structure, and their new types in the in-stantiation structure. For example, in Figure 9, U is bound to the result of matching structure S against signature SIG. Because signature matching in SML is transparent <ref> [MT91, Ler94, HL94] </ref>, f and p in the instantiation structure U respectively have type (real fl real) ! ((real fl real) fl (real fl real)) and real fl real (see Table 3). <p> These new types and their old types in structure S (shown in Table 3) will be recorded in its thinning function. * Abstraction is treated the same as signature matching. Because matching for abstraction is opaque <ref> [MT91, Ler94, HL94] </ref>, the elaboration phase also records the result signature in addition to the thinning function. For example, in Figure 9, V is an abstraction of structure S on signature SIG.
Reference: [HLPR94] <author> Robert Harper, Peter Lee, Frank Pfenning, and Eugene Rollins. </author> <title> Incremental Recompilation for Standard ML of New Jersey. </title> <booktitle> In ACM SIGPLAN Workshop on ML and its Applications, </booktitle> <month> June </month> <year> 1994. </year>
Reference-contexts: This problem is extremely severe for programs that contain many of the functor applications, and large structure and signature expressions. For example, the top-level linking program for the SML/NJ compilation manager CM <ref> [HLPR94] </ref> contains only 78 lines of source code and 9 functor applications, but many signatures involved (they are externally defined) are extremely large. As a result, its LEXP expression is several orders of magnitude larger than its Absyn form.
Reference: [HM95] <author> Robert Harper and Greg Morrisett. </author> <title> Compiling Polymorphism Using Intensional Type Analysis. </title> <booktitle> In Twenty-second Annual ACM Symp. on Principles of Prog. Languages, page (to appear), </booktitle> <address> New York, Jan 1995. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The type-based compiler described in this paper also uses this approach. The LEXP language described later in Section 3.5.1 has special type called RBOXEDty to express such requirements. * Another approach, described by Harper and Morrisett <ref> [HM95] </ref>, is to represent concrete data types using more efficient representations as shown in Figure 6. When z is being passed to unzip, we also pass a type descriptor to unzip indicating how to extract each car field of z. <p> Peterson [Pet89] presents a way to decide when to use boxed and unboxed representations using data flow analysis. It is not clear how much performance gain we can get from this kind of expensive analysis. Harper and Morrisett <ref> [HM95] </ref> have recently proposed a type-based compilation framework called Compiling with Intensional Type Analysis for the core-ML language. They use a typed lambda calculus with explicit type abstractions and type applications as the intermediate language.
Reference: [Hud89] <author> Paul Hudak. </author> <title> Conception, Evolution, and Application of Functional Programming Languages. </title> <journal> ACM Computing Surveys, </journal> <volume> 21(3) </volume> <pages> 359-411, </pages> <month> September </month> <year> 1989. </year>
Reference-contexts: A more complete survey of the history of functional languages can be found in Hudak <ref> [Hud89] </ref>.
Reference: [Joh85] <author> Thomas Johnsson. </author> <title> Lambda Lifting: Transforming Programs to Recursive Equations. </title> <booktitle> In The Second International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 190-203, </pages> <address> New York, </address> <month> September </month> <year> 1985. </year> <note> Springer-Verlag. </note>
Reference-contexts: The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques <ref> [Kra87, AS92, Ste78, Roz84, Han90, Joh85] </ref>, using a simple and general framework expressed in continuation-passing and closure-passing style [AJ89, AS92]. Our new algorithm extensively exploits the use of compile-time control and data flow information to optimize closure allocation strategies and representations. <p> This is because the lifetime of w and x (also g and y) does not overlap, so they can just share one callee-save register (i.e., J3 and K3, K2 and Q2). 4.5.2 Lambda lifting on known functions Lambda lifting <ref> [Joh85] </ref> is a well-known transformation that rewrites a program into an equivalent one in which no function has free variables. Lambda lifting on known functions essentially corresponds to the special closure allocation strategy that allocates as many free variables in registers as possible. <p> But it is useful to separate the closure introduction from machine code generation so that the compiler is more modular; this has been done in compilers based on ordinary -calculus (through lambda lifting) <ref> [CCM85, Joh85] </ref> and on continuation-passing style (using closure-passing style) [AJ89, KH89]. Many have tried to make call/cc efficient, but this is very hard to achieve in traditional stack-based schemes. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation.
Reference: [Jon92] <author> Mark P. Jones. </author> <title> A theory of qualified types. </title> <booktitle> In The 4th European Symposium on Programming, </booktitle> <pages> pages 287-306, </pages> <address> Berlin, </address> <month> February </month> <year> 1992. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: In a garbage-collected language, the garbage collector need not use such variables as "roots" of live data. Several implementors have independently discovered that this is really important: if the collector traverses too many dead variables, the memory use of the program can increase by a large factor <ref> [Bak76, Cha88, RW93, App92, Jon92] </ref>.
Reference: [Jou93] <author> Norman P. Jouppi. </author> <title> Cache Write Policies and Performance. </title> <booktitle> In Proceedings of the 20th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 191-201. </pages> <publisher> ACM Press, </publisher> <month> May </month> <year> 1993. </year>
Reference-contexts: Stacks do have a much better write miss ratio, but not a much better read miss ratio. But on many modern machines, the write miss penalty is approximately zero <ref> [Jou93, DTM94, Rei94] </ref>. 3. The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. <p> Many modern machines have a zero write-miss penalty, especially for their primary caches <ref> [Jou93] </ref>. Simulating machines with a high write-miss penalty, Diwan et al. found that SML/NJ performs badly, as might be expected. Thus: on machines with a zero write-miss penalty, the average cost per frame of write misses is zero. <p> Indeed, this is not true of all machines: the VAX 11/780, VAX 8800, and Pentium do write-around, bypassing the primary cache on write misses (causing subsequent read misses); and most pre-1993 designs do fetch-on-write, stalling the processor on a write miss <ref> [Jou93] </ref>. In fact, the bad performance of garbage-collected systems on machines with a write-miss penalty is a good reason not to build such machines. Finally, note that a write-miss penalty on large caches is not particularly problematic; as explained above, generational garbage collection solves that problem. <p> Stack frames, running in simulated caches of different sizes. We simulated a write-allocate cache with partial fill (the left-hand-side of Figure 25), and also a write-around cache (the right-hand-side of Figure 25). Jouppi <ref> [Jou93] </ref> simulated both kinds of cache for C programs without garbage collection; Diwan et al. [DTM94] simulated both caches for almost purely heap-allocating ML programs. By simulating both caches on stack and heap allocation for the same programs, we can compare more straightforwardly. <p> Jouppi's measurements of C and fortran programs <ref> [Jou93] </ref> may perhaps be influential. He concludes that write-validate (that is, write-allocate, no-fetch-on-write) is the policy with best performance. This is exactly the policy that we and others [DTM94, Rei94, SM94] find best for garbage-collected strict functional programs.
Reference: [KH89] <author> Richard Kelsey and Paul Hudak. </author> <title> Realistic Compilation by Program Transformation. </title> <booktitle> In Sixteenth ACM Symp. on Principles of Programming Languages, </booktitle> <pages> pages 281-292, </pages> <address> New York, 1989. </address> <publisher> ACM Press. </publisher>
Reference-contexts: In our previous work [AS92], we outlined this framework and demonstrated that it could reduce allocation and memory traffic. But, we did not have a really good algorithm to exploit the flexibility that callee-save registers provide. Closure creation and use can also be represented using the CPS language itself <ref> [AJ89, KH89] </ref>. We call this closure-passing style (CLO). The main difference between CLO and CPS is that functions in CLO do not contain free variables, so they can be translated directly into machine code. <p> But it is useful to separate the closure introduction from machine code generation so that the compiler is more modular; this has been done in compilers based on ordinary -calculus (through lambda lifting) [CCM85, Joh85] and on continuation-passing style (using closure-passing style) <ref> [AJ89, KH89] </ref>. Many have tried to make call/cc efficient, but this is very hard to achieve in traditional stack-based schemes. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation.
Reference: [KKR fl 86] <author> D. Kranz, R. Kelsey, J. Rees, P. Hudak, J. Philbin, and N. Adams. </author> <title> ORBIT: An optimizing compiler for Scheme. </title> <booktitle> SIGPLAN Notices (Proc. Sigplan '86 Symp. on Compiler Construction), </booktitle> <volume> 21(7) </volume> <pages> 219-233, </pages> <month> July </month> <year> 1986. </year>
Reference-contexts: Function returns are implemented in the same way, because in CPS, they are represented as calls to continuation functions. A closure can be any combination of registers and memory data structures that gives access to the free variables <ref> [KKR fl 86, AS92] </ref>. The compiler is free to choose a closure representation that minimizes stores (closure creation), fetches (to access free variables), and memory use (reachable data). We have developed a new algorithm for choosing good closure representations. <p> This problem is solved by adding a closure which makes explicit the access to all nonlocal variables. Kranz <ref> [KKR fl 86, Kra87] </ref> showed that different kinds of functions should use different closure allocation strategies. For example, the closure for a known function (e.g., h in CHAPTER 4. <p> Where there are more than three free variables, some of the callee-save arguments must be heap-allocated records containing several variables each; thus, the CR closure-record appears as J1 in the call on line 19. Previous closure conversion algorithms <ref> [Ste78, KKR fl 86, AJ89] </ref> require memory stores for each continuation function. <p> Rozas's Lias compiler [Roz84] used closure analysis to choose specialized representations for different kinds of closures; Kranz's Orbit compiler <ref> [KKR fl 86, Kra87] </ref> uses six different closure allocation strategies for different kinds of functions; Appel and Jim investigated closure-sharing strategies [AJ88] and proposed many alternative closure representations. Unfortunately, all these closure analysis techniques violate the "safe for space complexity" rule due to unsafe closure sharing. <p> Some compilers <ref> [Ste78, KKR fl 86, Car84a] </ref> perform closure conversion and closure analyses as part of their translation from lambda calculus or continuation-passing style into machine code. <p> Updating activation records In order to guarantee that only "new" heap frames can be roots for garbage collection, it is necessary to prohibit any writes to frames after they have been allocated. Compilers using continuation-passing style (such as Rabbit [Ste78], Orbit <ref> [KKR fl 86] </ref>, and SML/NJ [AJ89]) naturally initialize frames as soon as they are allocated, and then never write to them again. In effect, they save up any changes in registers, then dump everything out all at once.
Reference: [Kra87] <author> David Kranz. </author> <title> ORBIT: An optimizing compiler for Scheme. </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <address> New Haven, CT, </address> <year> 1987. </year>
Reference-contexts: representation analysis. * We show how the type annotations can be simplified in successive phases of the compiler, and how representation analysis can interact with the Continuation-Passing Style used by the SML/NJ compiler's optimizer. * We compare representation analysis with the crude (but effective) known-function parameter specialization implemented by Kranz <ref> [Kra87] </ref>. * Our measurements show that a combination of several type-based optimizations reduces heap allocation by 36%, and improves the already-efficient code generated by the old non-type-based compiler by about 19%. 3.2 Data representations The most important benefit of type-directed compilation is to allow data objects with specialized types to use <p> The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques <ref> [Kra87, AS92, Ste78, Roz84, Han90, Joh85] </ref>, using a simple and general framework expressed in continuation-passing and closure-passing style [AJ89, AS92]. Our new algorithm extensively exploits the use of compile-time control and data flow information to optimize closure allocation strategies and representations. <p> Unlike linked closures, the nesting level of safely linked closures never exceeds two, so they still enjoy very fast variable access time. 4.3 Continuations and closures We will illustrate CPS-conversion (which is not new <ref> [Plo75, Ste78, Kra87, App92] </ref>), and our new closure analysis algorithm, on the example in Figure 16. <p> This problem is solved by adding a closure which makes explicit the access to all nonlocal variables. Kranz <ref> [KKR fl 86, Kra87] </ref> showed that different kinds of functions should use different closure allocation strategies. For example, the closure for a known function (e.g., h in CHAPTER 4. <p> If y's last use is much earlier than w's or x's, then the record (w; x; y) might not obey the SSC rule. Most closure conversion algorithms <ref> [App92, Kra87, Ste78] </ref> start with a phase to gather the set of raw free variables for each function definition in E. <p> Notice that a variable can have different lut and fut numbers inside different function definitions (e.g., a in J and Q). 4.4.3 Closure strategy analysis Closure strategy analysis essentially determines where in the machine to allocate each closure. Unlike previous CPS compilers <ref> [Kra87, Ste78] </ref>, we do not do any escape analysis, 3 because we simply do not use a runtime stack. Our closure strategy analysis only decides how many slots (i.e., registers) each closure is going to use, denoted by S (f ) for each function f . <p> CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 77 4.4.5 Access path for non-local free variables Computing the access path for each non-local free variable v is done by a breadth-first search of v in the whereMap environment. We use the "lazy display" technique <ref> [Kra87] </ref> to keep a cache of access paths, so that loads of common paths can be shared. <p> CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 78 4.5 Case studies A good environment allocation scheme must implement frequently used control structures very efficiently. Many compilers identify special control structures at compile time, and assign each of them a special closure allocation strategy. For example, in Kranz's Orbit compiler <ref> [Kra87] </ref>, all tail recursions are assigned a so-called "stack/loop" strategy, and all general recursions are assigned a "stack/recursion" strategy. <p> Lambda lifting on known functions essentially corresponds to the special closure allocation strategy that allocates as many free variables in registers as possible. But this special strategy does not always generate efficient code <ref> [Kra87] </ref>. For example, in the following program, assume that f is a known function, and p,w,x,y, and z are its free variables. fun f u = (p u, u+w+x+y+z+1) CHAPTER 4. <p> Rozas's Lias compiler [Roz84] used closure analysis to choose specialized representations for different kinds of closures; Kranz's Orbit compiler <ref> [KKR fl 86, Kra87] </ref> uses six different closure allocation strategies for different kinds of functions; Appel and Jim investigated closure-sharing strategies [AJ88] and proposed many alternative closure representations. Unfortunately, all these closure analysis techniques violate the "safe for space complexity" rule due to unsafe closure sharing. <p> Chapter 4 has already described an implementation of such an algorithm, which is not particularly hairy. 2. To avoid having a descriptor in each frame, the runtime system can maintain a mapping of return addresses to frame layout descriptors. Kranz's orbit compiler used this technique <ref> [Kra87] </ref>. Standard ML of New Jersey does not bother, so it does indeed pay the price of a descriptor in each frame. Implementation of Stacks 1. A good closure analysis algorithm must be used to preserve space complexity while still trying to avoid too much copying.
Reference: [Lan64] <author> P. J. Landin. </author> <title> The mechanical evaluation of expressions. </title> <journal> Computer Journal, </journal> <volume> 6(4) </volume> <pages> 308-320, </pages> <year> 1964. </year> <note> BIBLIOGRAPHY 152 </note>
Reference-contexts: Higher-order functions such as g, h, i cannot be implemented just using a LIFO stack because they may be called later even though their environments (i.e., activation records) have been popped off the stack. The usual solution to this problem is to represent functions as closures <ref> [Lan64] </ref>. A function with free variables is said to be open; a closure is a data structure containing both the machine code address of an open function, and bindings for all the non-local variables (i.e., free variables) of that function. The machine-code CHAPTER 2. <p> A flat closure [Car84b] is a record that holds only the free variables needed by the function. For example, the flat closure for h (denoted as H) contains just the code pointer (denoted by h) plus the values for variable u, w, x, y, and z. A linked closure <ref> [Lan64] </ref> is a record that contains the bound variables of the enclosing function, together with a pointer to the enclosing function's closure.
Reference: [Lan65] <author> P. J. Landin. </author> <title> A correspondence between Algol 60 and Church's lambda notation: Part I. </title> <journal> Commnuications of the ACM, </journal> <volume> 8(2) </volume> <pages> 89-101, </pages> <year> 1965. </year>
Reference: [Ler92] <author> Xavier Leroy. </author> <title> Unboxed objects and polymorphic typing. </title> <booktitle> In Nineteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 177-188, </pages> <address> New York, </address> <month> Jan </month> <year> 1992. </year> <note> ACM Press. Longer version available as INRIA Tech Report. </note>
Reference-contexts: If the natural representation of a value does not fit into one word (as with a floating-point number, etc.), a pointer to a heap-allocated object is used instead. This is a source of great inefficiency. Leroy <ref> [Ler92] </ref> has recently presented a representation analysis technique (for core-ML) that does not always require variables be boxed in one word. <p> Representation analysis makes possible many interesting type-based compiler optimizations. But, since no existing compiler has fully implemented representation analysis for the complete SML language, many practical implementation issues are still unclear. For example, while Leroy <ref> [Ler92] </ref> has shown in detail how to insert coercions for core-ML, he does not address the issues in the ML module system, that is, how to insert coercions for functor application and signature matching (see Section 2.2.7). <p> The type information in LEXP is converted directly from the static semantic information attached to the Absyn. Coercion functions (in the same style as Leroy's <ref> [Ler92] </ref>) are inserted at each abstraction and instantiation site to correctly support abstraction and polymorphism. In addition, this phase also inserts the proper implementation of each equality test and assignment operator, and does pattern-match compilation. The details are described in Section 3.5. <p> First, the source program (Absyn) annotated with static semantics is translated into an intermediate lambda language (LEXP) annotated with simple monomorphic types (LTY); all module constructs and polymorphic functions are translated into simple lambda functions and records using Leroy's representation analysis <ref> [Ler92] </ref>. The lambda expression is then converted into continuation-passing style (CPS) annotated with an even simpler CPS types (CTY); this conversion also determines the representation of records and concrete data types, and the argument-passing convention for function calls and returns, based on the LTY information. <p> Leroy's representation analysis technique <ref> [Ler92] </ref> solves this problem by memorizing the actual instantiation of every polymorphic type and then inserting proper coercions later. Our compiler does the same. <p> In order to support coercion of data objects from one representation to another, we define a coerce operation on our lambda language, just like the "wrap" and "unwrap" functions used by Leroy <ref> [Ler92] </ref>. <p> * If one of t 1 and t 2 is RBOXEDty, this requires coercing an arbitrary unboxed object into a pointer (or vice versa); moreover, the object itself must be coerced into standard boxed representation (or vice versa); this coercion is similar to the recursive wrapping operations defined by Leroy <ref> [Ler92] </ref>. <p> The representation analysis technique, first proposed by Leroy <ref> [Ler92] </ref> (for ML-like languages) and Peyton Jones and Launchbury [PL91] (for Haskell-like languages), allows data objects whose types are not polymorphic to use more efficient unboxed representations. Leroy [Ler92] has also implemented representation analysis in his Gallium compiler CHAPTER 3. <p> The representation analysis technique, first proposed by Leroy <ref> [Ler92] </ref> (for ML-like languages) and Peyton Jones and Launchbury [PL91] (for Haskell-like languages), allows data objects whose types are not polymorphic to use more efficient unboxed representations. Leroy [Ler92] has also implemented representation analysis in his Gallium compiler CHAPTER 3. TYPE-DIRECTED COMPILATION 59 for the Caml Light dialect of ML, and shown that it can result in important speedups on certain benchmarks. <p> TYPE-DIRECTED COMPILATION 59 for the Caml Light dialect of ML, and shown that it can result in important speedups on certain benchmarks. The work described in this chapter is a re-implementation of Leroy's techniques in the Standard ML of New Jersey compiler [AM91]. Unlike Leroy <ref> [Ler92] </ref>, we concentrate more on practical issues such as how to implement type-directed compilation for the entire SML language (Caml has a much simpler module system than SML), and how to efficiently propagate type information through many rounds of transformations and optimizations. <p> This can be accomplished using special descriptors, which would reduce the "copying and sharing" penalty for stack frames. For example, in the Chalmers Lazy ML compiler [Aug89] or the Gallium compiler <ref> [Ler92] </ref>, associated with each return address is a descriptor telling which variables in the caller's frame are live after the return. 4 But this is not sufficient; heap closures still cannot point to stack frames. <p> This does not mean that our algorithm cannot be applied to polymorphic languages; polymorphic expressions can be easily translated into a monomor-phically typed intermediate language by using representation analysis, a technique first proposed by Leroy <ref> [Ler92] </ref> and Peyton Jones [PL91]. <p> 0 1 ; 1 ; e 0 2 ; 2 ), which returns a TGT expression and a refinement type, is also defined in Figure 35. 6.2.5 Correctness of the translation The type and semantic correctness of our translation can be proven using a technique similar to that of Leroy <ref> [Ler92] </ref>. Here we only sketch the proof method and state the main theorem. We use ` SRC to denote the type deduction rule for SRC, and ` TGT to denote the refinement type deduction rule for TGT. <p> The heap allocation of intermediate OLIST cons cell is still avoided because of representation analysis (see Chapter 3 and Leroy <ref> [Ler92] </ref>). It is likely, however, that this transformation will only improve performance if the underlying compiler uses representation analysis (see Chapter 3 and Leroy [Ler92]), and is very sophisticated about closure construction and register usage (see Chapter 4). <p> The heap allocation of intermediate OLIST cons cell is still avoided because of representation analysis (see Chapter 3 and Leroy <ref> [Ler92] </ref>). It is likely, however, that this transformation will only improve performance if the underlying compiler uses representation analysis (see Chapter 3 and Leroy [Ler92]), and is very sophisticated about closure construction and register usage (see Chapter 4). Otherwise, the extra cost of closure creations could outweigh the elimination of the cons operations. Note, however, that though there are extra costs of testing for ELIST/OLIST, there are fewer tests for nil. <p> Because the compiler uses continuation-passing style as its intermediate language, the multiple-continuation CHAPTER 6. UNROLLING LISTS 136 approach described in Section 6.3 can be easily added (this has not been done yet). The SML/NJ compiler supports representation analysis (see Chapter 3 and <ref> [Ler92] </ref>), so intermediate odd-length lists are represented by unboxed records, which normally stay in registers; this makes the specialized versions (for even-length and odd-length lists) of the ucons and uproj operations require less memory allocation. <p> In effect, this means that library functions must be explicitly programmed using several different representations, and programs will be improved only if they use the library functions. The idea of using special and more efficient representations for frequently used data objects (through type-based analysis) is originally from Leroy <ref> [Ler92] </ref> and Peyton Jones [PL91]. Both propose a type-based program transformation scheme that allows objects with monomorphic ML types to use special unboxed representations. When an unboxed object interacts with a boxed polymorphic object, appropriate coercions are inserted. But as mentioned by Leroy [Ler92], their representation analysis techniques do not work <p> (through type-based analysis) is originally from Leroy <ref> [Ler92] </ref> and Peyton Jones [PL91]. Both propose a type-based program transformation scheme that allows objects with monomorphic ML types to use special unboxed representations. When an unboxed object interacts with a boxed polymorphic object, appropriate coercions are inserted. But as mentioned by Leroy [Ler92], their representation analysis techniques do not work well with ML's recursive data types, such as the list type. This is because the coercion between the CHAPTER 6. UNROLLING LISTS 139 unboxed and boxed representation for lists is often rather expensive (i.e., has costs proportional to the list length).
Reference: [Ler94] <author> Xavier Leroy. </author> <title> Manifest Types, Modules, and Separate Compilation. </title> <booktitle> In Twenty-first Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 109-122, </pages> <address> New York, Jan 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: TYPE-DIRECTED COMPILATION 37 if there are substructures) in the original structure, and their new types in the in-stantiation structure. For example, in Figure 9, U is bound to the result of matching structure S against signature SIG. Because signature matching in SML is transparent <ref> [MT91, Ler94, HL94] </ref>, f and p in the instantiation structure U respectively have type (real fl real) ! ((real fl real) fl (real fl real)) and real fl real (see Table 3). <p> These new types and their old types in structure S (shown in Table 3) will be recorded in its thinning function. * Abstraction is treated the same as signature matching. Because matching for abstraction is opaque <ref> [MT91, Ler94, HL94] </ref>, the elaboration phase also records the result signature in addition to the thinning function. For example, in Figure 9, V is an abstraction of structure S on signature SIG.
Reference: [LH83] <author> Henry Lieberman and Carl Hewitt. </author> <title> A Real-Time Garbage Collector Based on the Lifetimes of Objects. </title> <journal> Communications of the ACM, </journal> <volume> 26(6) </volume> <pages> 419-29, </pages> <year> 1983. </year>
Reference-contexts: and the LTYs for F and F 0 are respectively s and t, then the LEXP expression for F 0 is f 0 = (coerce (s; t))(f ), and functor application F (S) is translated into APP (f 0 ; c (v)). 5 In order to support generational garbage collection <ref> [LH83, Ung86] </ref>, most compilers must do some bookkeeping at each update so that the pointers from older generation to youngest generation are correctly identified.
Reference: [LH86] <author> Kai Li and Paul Hudak. </author> <title> A New List Compaction Method. </title> <journal> Software Practice and Experience, </journal> <volume> 16(2) </volume> <pages> 145-163, </pages> <month> February </month> <year> 1986. </year>
Reference-contexts: The "static cdr-coding" technique presented in this chapter is a simple compile-time method for doing list compaction. It is attractive for modern machines because it does not require any runtime encoding bits at all. Li and Hudak <ref> [LH86] </ref> proposed a cdr-coding scheme for list compaction under parallel environments. When several lists are being constructed simultaneously from the same heap, the non-contiguous nature of the cells being allocated might eliminate the opportunity for compaction under traditional cdr-coding techniques.
Reference: [Mac84] <author> David B. MacQueen. </author> <title> Modules for Standard ML. </title> <booktitle> In 1984 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 198-207, </pages> <address> New York, </address> <month> August </month> <year> 1984. </year> <note> ACM Press. </note>
Reference-contexts: Standard ML [MTH90] is just core ML extended with constants, pattern matching, data type definitions, references and exceptions, and a sophisticated module system <ref> [Mac84] </ref>. We'll explain the details of Standard ML in Section 2.2. 2.1.4 Haskell Haskell is a nonstrict, purely functional programming language developed by Hudak, Peyton Jones, Wadler et al [HJet al92].
Reference: [Mac88] <author> David B. MacQueen. </author> <title> Weak types. Distributed with Standard ML of New Jersey, </title> <year> 1988. </year>
Reference-contexts: (SML/NJ) [AM91] is the typed first-class continuation [DHM91], defined as follows: type 'a cont val callcc : ('1a cont -&gt; '1a) -&gt; '1a val throw : 'a cont -&gt; 'a -&gt; 'b Here, cont is an abstract type constructor; "'1a" denotes a weak type variable (also used for typing references) <ref> [Mac88] </ref>; callcc is used to capture the current state (representing the "rest of the program"), just like the call-with-current-continuation function in Scheme [RC86]; the captured continuation can be later applied by using the throw function.
Reference: [McC60] <author> John McCarthy. </author> <title> Recursive functions of symbolic expressions and their computation by machine, Part I. </title> <journal> Communications of the ACM, </journal> <volume> 3(4) </volume> <pages> 184-195, </pages> <month> Apirl </month> <year> 1960. </year>
Reference-contexts: Actually, it is shown (by Turing [Tur37]) that those functions computable on Turing machines are exactly those definable functions in the lambda calculus. 2.1.2 Lisp Lisp <ref> [McC60, Ste84] </ref> was the first functional language in the world, developed by John McCarthy in 1950s. Although the core of Lisp is essentially the lambda calculus plus the constants, many new features in Lisp are now commonly used by almost all functional languages.
Reference: [Mil78] <author> Robin Milner. </author> <title> A theory of type polymorphism in programming. </title> <journal> J. Comput. Syst. Sci., </journal> <volume> 17 </volume> <pages> 348-375, </pages> <month> March </month> <year> 1978. </year>
Reference-contexts: j e 1 e 2 j let x = e 1 in e 2 Here, the let statement is just a syntactic language construct equivalent to [e 1 =x]e 2 ; this additional structure is used to support ML's powerful polymorphic type system, developed independently by Hindley [Hin69] and Milner <ref> [Mil78] </ref>.
Reference: [MT91] <author> Robin Milner and Mads Tofte. </author> <title> Commentary on Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1991. </year>
Reference-contexts: Readers are referred to References [Har86, Ull93, Pau91] for a more complete introduction. The formal definition and commentary for SML can be found in References <ref> [MTH90, MT91] </ref>. 2.2.1 Basic expressions, values, and types SML is an expression language: the traditional statement constructs, such as blocks, conditionals, case statements, and assignment, are packaged as expressions. Every expression has a statically determined type and will only evaluate to values of that type. <p> TYPE-DIRECTED COMPILATION 37 if there are substructures) in the original structure, and their new types in the in-stantiation structure. For example, in Figure 9, U is bound to the result of matching structure S against signature SIG. Because signature matching in SML is transparent <ref> [MT91, Ler94, HL94] </ref>, f and p in the instantiation structure U respectively have type (real fl real) ! ((real fl real) fl (real fl real)) and real fl real (see Table 3). <p> These new types and their old types in structure S (shown in Table 3) will be recorded in its thinning function. * Abstraction is treated the same as signature matching. Because matching for abstraction is opaque <ref> [MT91, Ler94, HL94] </ref>, the elaboration phase also records the result signature in addition to the thinning function. For example, in Figure 9, V is an abstraction of structure S on signature SIG. <p> Here, the type 'a vec in the argument signature is flexible, and we do not know its exact data representation 4 Following the Definition and Commentary <ref> [MTH90, MT91] </ref>, all type constructor names, defined as type specification in signatures, are flexible; all other type constructor names are rigid. CHAPTER 3. TYPE-DIRECTED COMPILATION 44 until we know the actual instantiation of 'a vec at functor application time.
Reference: [MT94] <author> David B. MacQueen and Mads Tofte. </author> <title> A semantics for higher order functors. </title> <booktitle> In The 5th European Symposium on Programming, </booktitle> <pages> pages 409-423, </pages> <address> Berlin, </address> <month> April </month> <year> 1994. </year> <pages> Spinger-Verlag. </pages>
Reference-contexts: There are four module constructs where abstraction and instantiation may occur: signature matching, abstraction declaration, functor application, and functor signature matching (used by higher-order modules <ref> [Tof92, MT94] </ref>).
Reference: [MTH90] <author> Robin Milner, Mads Tofte, and Robert Harper. </author> <title> The Definition of Standard ML. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1990. </year> <note> BIBLIOGRAPHY 153 </note>
Reference-contexts: This dissertation concentrates on improving the performance of programs written in Standard ML (SML) <ref> [MTH90] </ref> on modern RISC machines. SML may not be the most representative or the most elegant higher-level language in today's world, but it serves as a great test bed to explore modern compilation technologies. <p> and one cdr field, the unrolled list reduces the memory used for links and significantly shortens the length of control-dependence and data-dependence chains in operations on lists. 1.2 Outline of this dissertation The development of this dissertation may be easier to follow for readers with some background in Standard ML <ref> [Ull93, Har86, MTH90] </ref> and basic compilation techniques for functional languages [App92, Pey87]. Chapter 2 contains a survey of various functional languages, an introduction to SML (which may be skipped if the reader is familiar with SML notation), and a review of several important aspects in compiling functional languages. <p> A more complete survey of the history of functional languages can be found in Hudak [Hud89]. This section only describes the core ML language and its polymorphic type system; a more detailed description of Standard ML <ref> [MTH90] </ref> is presented later in Section 2.2. 2.1.1 Lambda calculus The development of functional languages has been influenced from time to time by many sources, but none is as fundamental as the work of Church [Chu41] on the lambda calculus. <p> Damas and Milner [DM82] have shown that any expression that has a type in a given environment has a principal type in that environment, which is unique except for choice of bound type-variable names and can be inferred using the well-known type assignment algorithm "W " [DM82]. Standard ML <ref> [MTH90] </ref> is just core ML extended with constants, pattern matching, data type definitions, references and exceptions, and a sophisticated module system [Mac84]. <p> Readers are referred to References [Har86, Ull93, Pau91] for a more complete introduction. The formal definition and commentary for SML can be found in References <ref> [MTH90, MT91] </ref>. 2.2.1 Basic expressions, values, and types SML is an expression language: the traditional statement constructs, such as blocks, conditionals, case statements, and assignment, are packaged as expressions. Every expression has a statically determined type and will only evaluate to values of that type. <p> For statically typed languages such as Standard ML (SML) <ref> [MTH90] </ref>, there is sufficient type information at compile time to guarantee that primitive operators will never be applied to values of the wrong type. But, because of SML's parametric polymorphism, there are still contexts in which the types of (polymorphic) variables are not completely known. <p> TYPE-DIRECTED COMPILATION 33 forms. This phase elaborates all program declarations and specifications (e.g., modules, module interfaces, type and value declarations, etc.) into semantic objects according to the static semantics <ref> [MTH90] </ref>; the types of all program variables are inferred and checked using the ML type inference algorithm [DM82, MTH90]. The raw abstract syntax tree is rewritten into a more compact form called abstract syntax (Ab-syn). <p> TYPE-DIRECTED COMPILATION 33 forms. This phase elaborates all program declarations and specifications (e.g., modules, module interfaces, type and value declarations, etc.) into semantic objects according to the static semantics [MTH90]; the types of all program variables are inferred and checked using the ML type inference algorithm <ref> [DM82, MTH90] </ref>. The raw abstract syntax tree is rewritten into a more compact form called abstract syntax (Ab-syn). Each declaration in Absyn is annotated with its corresponding static semantic or type information calculated during elaboration. <p> TYPE-DIRECTED COMPILATION 35 3.4 Front end issues The main task of the front end (the first two phases in Figure 7) is parsing and elaboration. Elaboration determines whether the source program is well-typed and well-formed according to the Definition <ref> [MTH90] </ref>, and records relevant semantic or type information in the static environment. <p> Here, the type 'a vec in the argument signature is flexible, and we do not know its exact data representation 4 Following the Definition and Commentary <ref> [MTH90, MT91] </ref>, all type constructor names, defined as type specification in signatures, are flexible; all other type constructor names are rigid. CHAPTER 3. TYPE-DIRECTED COMPILATION 44 until we know the actual instantiation of 'a vec at functor application time. <p> Rigid constructor types, however, can only be concrete data types. This is because if a rigid constructor type is bound to a non-data-type SML type, it must be done through type abbreviation. But all type abbreviations are expanded during elaboration (see Definition <ref> [MTH90] </ref>). As we discussed in Section 3.2, concrete data types|whether they are polymorphic or not|always use the same data representations. <p> The well-known function map might be written as follows using pattern matching: fun map f = | m (x::r) = (f x) :: (m r) end 2 In Standard ML <ref> [MTH90] </ref>, lists are declared as datatype 'a list = nil | :: of 'a * 'a list. To simplify the presentation, we omit the type variable 'a by considering only integer lists. All the results described in this chapter easily carry to the polymorphic case. CHAPTER 6.
Reference: [Pau91] <author> Lawrence C. Paulson. </author> <title> ML for the Working Programmer. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge, </address> <year> 1991. </year>
Reference-contexts: Readers are referred to References <ref> [Har86, Ull93, Pau91] </ref> for a more complete introduction. The formal definition and commentary for SML can be found in References [MTH90, MT91]. 2.2.1 Basic expressions, values, and types SML is an expression language: the traditional statement constructs, such as blocks, conditionals, case statements, and assignment, are packaged as expressions. <p> Our benchmarks include: Life, the game of Life implemented using lists written by Reade [Rea89] (see Table 2 in Chapter 2); Ray, a simple ray tracer (see Table 2 in Chapter 2); Quicksort, sorting a list of 20000 real numbers using the quicksort algorithm (taken from Paulson <ref> [Pau91] </ref>); Samsort, sorting a list of 2000 real numbers using a variation of mergesort algorithm (taken from Paulson [Pau91]); Intset, "set" operations on sets of integers implemented with sorted lists; MMap, several runs of the map function on a long list. <p> (see Table 2 in Chapter 2); Ray, a simple ray tracer (see Table 2 in Chapter 2); Quicksort, sorting a list of 20000 real numbers using the quicksort algorithm (taken from Paulson <ref> [Pau91] </ref>); Samsort, sorting a list of 2000 real numbers using a variation of mergesort algorithm (taken from Paulson [Pau91]); Intset, "set" operations on sets of integers implemented with sorted lists; MMap, several runs of the map function on a long list.
Reference: [Pet89] <author> John Peterson. </author> <title> Untagged data in tagged environments: choosing optimal representations at compile time. </title> <booktitle> In The Fourth International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 89-99, </pages> <address> New York, </address> <month> September </month> <year> 1989. </year> <note> ACM Press. </note>
Reference-contexts: Actually, we have shown that "wrapper" eliminations do not have much effect on performance in a highly optimizing compiler such as SML/NJ, simply because a simple compile-time contraction can eliminate most of the wrap and unwrap pairs (see Section 3.6.3). Peterson <ref> [Pet89] </ref> presents a way to decide when to use boxed and unboxed representations using data flow analysis. It is not clear how much performance gain we can get from this kind of expensive analysis.
Reference: [Pey87] <editor> Simon L. Peyton Jones. </editor> <booktitle> The Implementation of Functional Programming Languages. </booktitle> <publisher> Prentice Hall, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: used for links and significantly shortens the length of control-dependence and data-dependence chains in operations on lists. 1.2 Outline of this dissertation The development of this dissertation may be easier to follow for readers with some background in Standard ML [Ull93, Har86, MTH90] and basic compilation techniques for functional languages <ref> [App92, Pey87] </ref>. Chapter 2 contains a survey of various functional languages, an introduction to SML (which may be skipped if the reader is familiar with SML notation), and a review of several important aspects in compiling functional languages. <p> For example, ML supports parametrized modules (i.e., functors) and module abstractions while Haskell does not. * The type system in Haskell also supports type-classes|a more general form of over loading [WB89]. The details on how to efficiently compile pure functional languages such as Haskell are discussed by Peyton Jones <ref> [Pey87, Pey92] </ref>.
Reference: [Pey92] <author> Simon L. Peyton Jones. </author> <title> Implementing lazy functional languages on stock hardware: </title> <journal> the Spineless Tagless G-machine. Journal of Functional Programming, </journal> <volume> 2(2) </volume> <pages> 127-202, </pages> <month> April </month> <year> 1992. </year>
Reference-contexts: For example, ML supports parametrized modules (i.e., functors) and module abstractions while Haskell does not. * The type system in Haskell also supports type-classes|a more general form of over loading [WB89]. The details on how to efficiently compile pure functional languages such as Haskell are discussed by Peyton Jones <ref> [Pey87, Pey92] </ref>.
Reference: [PL91] <author> Simon L. Peyton Jones and John Launchbury. </author> <title> Unboxed Values as First Class Citizens in a Non-Strict Functional Language. </title> <booktitle> In The Fifth International Conference on Functional Programming Languages and Computer Architecture, </booktitle> <pages> pages 636-666, </pages> <address> New York, </address> <month> August </month> <year> 1991. </year> <note> ACM Press. </note>
Reference-contexts: The representation analysis technique, first proposed by Leroy [Ler92] (for ML-like languages) and Peyton Jones and Launchbury <ref> [PL91] </ref> (for Haskell-like languages), allows data objects whose types are not polymorphic to use more efficient unboxed representations. Leroy [Ler92] has also implemented representation analysis in his Gallium compiler CHAPTER 3. <p> This does not mean that our algorithm cannot be applied to polymorphic languages; polymorphic expressions can be easily translated into a monomor-phically typed intermediate language by using representation analysis, a technique first proposed by Leroy [Ler92] and Peyton Jones <ref> [PL91] </ref>. <p> The idea of using special and more efficient representations for frequently used data objects (through type-based analysis) is originally from Leroy [Ler92] and Peyton Jones <ref> [PL91] </ref>. Both propose a type-based program transformation scheme that allows objects with monomorphic ML types to use special unboxed representations. When an unboxed object interacts with a boxed polymorphic object, appropriate coercions are inserted.
Reference: [Plo75] <author> Gordon D. Plotkin. </author> <title> Call-by-Name, Call-by-Value, and the -calculus. </title> <journal> Theoretical Computer Science, </journal> <volume> 1 </volume> <pages> 125-59, </pages> <year> 1975. </year>
Reference-contexts: Unlike linked closures, the nesting level of safely linked closures never exceeds two, so they still enjoy very fast variable access time. 4.3 Continuations and closures We will illustrate CPS-conversion (which is not new <ref> [Plo75, Ste78, Kra87, App92] </ref>), and our new closure analysis algorithm, on the example in Figure 16.
Reference: [Pou93] <author> Eigil Poulsen. </author> <title> Representation Analysis for Efficient Implementation of Poly-morphism. </title> <type> Master's thesis, </type> <institution> DIKU, University of Copenhagen, </institution> <year> 1993. </year>
Reference-contexts: Many people have worked on eliminating unnecessary "wrapper" functions introduced by representation analysis. Poulsen <ref> [Pou93] </ref> proposes a way to tag each type with a boxity annotation, and then statically determine when to use boxed representations and when to use unboxed representations. The major problem of his technique is that it is not easy to extend to the SML module system.
Reference: [RC86] <editor> J. Rees and W. Clinger. </editor> <title> Revised Report on the Algorithmic Language Scheme. </title> <journal> SIGPLAN Notices, </journal> <volume> 21(12) </volume> <pages> 37-79, </pages> <year> 1986. </year>
Reference-contexts: '1a val throw : 'a cont -&gt; 'a -&gt; 'b Here, cont is an abstract type constructor; "'1a" denotes a weak type variable (also used for typing references) [Mac88]; callcc is used to capture the current state (representing the "rest of the program"), just like the call-with-current-continuation function in Scheme <ref> [RC86] </ref>; the captured continuation can be later applied by using the throw function. First-class continuations can be used to support tasking, coroutines, exceptions, and so on. 2.2.7 Modules SML provides a powerful module system, which can be used to partition programs along clean interfaces. <p> CHAPTER 5. HEAP VS. STACK 115 data. In such a compiler, it is best to keep the top frame in callee-save registers and not in memory at all. 5.9 First-class continuations The notion of "first class continuations" using the call-with-current-continuation (call/cc) primitive originated in the Scheme language <ref> [RC86] </ref> and has since been adopted in other systems as well [DHM91]. First class continuations are useful for implementing coroutines [Wan80] and concurrency libraries [Rep91]. But call/cc is much harder to implement efficiently if there is a stack.
Reference: [Rea89] <author> Chris Reade. </author> <title> Elements of Functional Programming. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: Lexgen 1185 5 1 A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi [AMT89], processing the lexical de scription of Standard ML. Life 148 1 1 The game of Life, written by Chris Reade and described in his book <ref> [Rea89] </ref>, running 50 gen erations of a glider gun. Ray 874 5 5 A simple ray tracer written in C by Don Mitchell, translated into Standard ML by John Reppy. <p> To demonstrate the savings of execution time, we have compared the performance of several benchmarks under the standard representation (OSR) and the unrolled representation (NUR). Our benchmarks include: Life, the game of Life implemented using lists written by Reade <ref> [Rea89] </ref> (see Table 2 in Chapter 2); Ray, a simple ray tracer (see Table 2 in Chapter 2); Quicksort, sorting a list of 20000 real numbers using the quicksort algorithm (taken from Paulson [Pau91]); Samsort, sorting a list of 2000 real numbers using a variation of mergesort algorithm (taken from Paulson
Reference: [Rei94] <author> Mark B. Reinhold. </author> <title> Cache Performance of Garbage-Collected Programs. </title> <booktitle> In Proc. SIGPLAN '94 Symp. on Prog. Language Design and Implementation, </booktitle> <pages> pages 206-217. </pages> <publisher> ACM Press, </publisher> <month> June </month> <year> 1994. </year>
Reference-contexts: Stacks do have a much better write miss ratio, but not a much better read miss ratio. But on many modern machines, the write miss penalty is approximately zero <ref> [Jou93, DTM94, Rei94] </ref>. 3. The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. <p> But a cache line is usually larger than a single word; on a write miss, "traditional" (fetch-on-write) caches read the rest of the line from memory; this can 6 Reinhold <ref> [Rei94] </ref> makes similar observations about the interaction of garbage collection and caches, though not for a compiler with heap-allocated frames. CHAPTER 5. HEAP VS. <p> The simulations counted read misses, write misses, and total instruction count of SML programs compiled to the MIPS instruction set. The total instruction count also includes the instructions and cache misses of garbage collection. Diwan et al. [DTM94] measured a heap-only ML system; Reinhold <ref> [Rei94] </ref> measured a stack-frame Scheme system. In order to make a more direct comparison, we measured stack frames vs. heap frames in the same ML system. We simulated only the primary data cache. <p> Write-around caches do not need to stall the processor on a write miss, at least for the well behaved sequential writes performed by a heap allocator. Thus, the write miss cost will be zero; but since (almost) every newly written cache line will soon be fetched <ref> [SM94, Rei94] </ref>, we should expect the read-miss cost per frame for write-around caches to be similar to the cost per frame for fetch-on-write caches. <p> On the other hand, the simulation can capture the effect of "real" programs that cannot be analyzed in closed form like our three paradigmatic examples. Such programs will have interference effects from old objects and nonframe objects. Reinhold <ref> [Rei94] </ref> , however, finds that such interference does not much affect the cache behavior of recently allocated objects (such as, in our case, frames). Therefore, we cannot say with confidence whether the simulation or the analytical prediction more accurately characterizes the cache behavior. <p> Jouppi's measurements of C and fortran programs [Jou93] may perhaps be influential. He concludes that write-validate (that is, write-allocate, no-fetch-on-write) is the policy with best performance. This is exactly the policy that we and others <ref> [DTM94, Rei94, SM94] </ref> find best for garbage-collected strict functional programs. On the other hand, as Jouppi points out, write-validate is difficult|though not impossible|to implement on a shared-memory multiprocessor with cache coherence. Such machines require each writable cache line to have a single owner.
Reference: [Rep91] <author> John H. Reppy. </author> <title> CML: A Higher-order Concurrent Language. </title> <booktitle> In Proc. ACM SIGPLAN '91 Conf. on Prog. Lang. Design and Implementation, </booktitle> <pages> pages 293-305. </pages> <publisher> ACM Press, </publisher> <year> 1991. </year> <note> BIBLIOGRAPHY 154 </note>
Reference-contexts: Boyer 919 4 3 Standard theorem-prover benchmark [BM72], translated from the Gabriel benchmark [Gab85]. Sieve 1356 4 5 CML implementation of prime number gener ator written by John Reppy <ref> [Rep91] </ref>. KB-Comp 655 1 1 An implementation of the Knuth-Bendix completion algorithm, implemented by Gerard Huet, processing some axioms of geometry. Lexgen 1185 5 1 A lexical-analyzer generator, implemented by James S. Mattson and David R. Tarditi [AMT89], processing the lexical de scription of Standard ML. <p> First class continuations are useful for implementing coroutines [Wan80] and concurrency libraries <ref> [Rep91] </ref>. But call/cc is much harder to implement efficiently if there is a stack. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation.
Reference: [Rep93] <author> John H. Reppy. </author> <title> A High-Performance Garbage Collector for Standard ML. </title> <type> Technical memorandum, </type> <institution> AT&T Bell Laboratories, </institution> <address> Murray Hill, NJ, </address> <month> January </month> <year> 1993. </year>
Reference-contexts: In a type-based compiler, because we know the types of program variables, we can use much more efficient data representations, depending on how complicated a descriptor we CHAPTER 3. TYPE-DIRECTED COMPILATION 30 want to support at runtime 1 . For example, in the SML/NJ compiler <ref> [App90, Rep93, AM91] </ref>, the descriptor for runtime objects is just a kind tag plus the length of the object; each object may contain tagged/boxed objects, or untagged/unboxed objects, but not both. <p> This provides empirical evidence for the claim that sizing the allocation space to fit into cache can improve performance." <ref> [Rep93] </ref> Unfortunately, the measurements in this chapter were made using the older two-generation collector [App89]. <p> This is costly; but recursions this deep also begin to miss in the secondary cache! This is particularly so, since the size of the youngest generation should be less than the size of the secondary cache <ref> [Zor91, Rep93] </ref>. The secondary cache misses (which occur for both stacks and heaps) are probably just as important as the garbage-collection overhead. Summary: 0.06 instructions per frame.
Reference: [Roz84] <author> Guillermo Juan Rozas. </author> <title> Liar, an Algol-like Compiler for Scheme. </title> <type> S.B. thesis, </type> <institution> MIT Dept. of Computer Science and Electrical Engineering, </institution> <month> June </month> <year> 1984. </year>
Reference-contexts: The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques <ref> [Kra87, AS92, Ste78, Roz84, Han90, Joh85] </ref>, using a simple and general framework expressed in continuation-passing and closure-passing style [AJ89, AS92]. Our new algorithm extensively exploits the use of compile-time control and data flow information to optimize closure allocation strategies and representations. <p> This overhead is higher if more callee-save registers are used. 4.7 Related work Guy Steele's Rabbit compiler [Ste78] is the first compiler that uses the continuation-passing style as the intermediate language; it is also the first one that represents the "stack frames" using continuation closures. Rozas's Lias compiler <ref> [Roz84] </ref> used closure analysis to choose specialized representations for different kinds of closures; Kranz's Orbit compiler [KKR fl 86, Kra87] uses six different closure allocation strategies for different kinds of functions; Appel and Jim investigated closure-sharing strategies [AJ88] and proposed many alternative closure representations.
Reference: [RP86] <author> Barbara G. Ryder and Marvin C. Paull. </author> <title> Elimination Algorithms for Data Flow Analysis. </title> <journal> ACM Computing Surveys, </journal> <volume> 18(3) </volume> <pages> 277-316, </pages> <month> September </month> <year> 1986. </year>
Reference-contexts: Cycles in the graph imply loops or recursions (e.g., the path from h to J to Q). The nested hierarchies of loops and recursions in E can be revealed by running the Tarjan interval analysis algorithm <ref> [Tar74, RP86] </ref> on G, assuming G is a reducible flow graph. <p> Given a flow graph G, a Tarjan interval is essentially a single-entry, strongly connected subgraph of G; the interval analysis <ref> [RP86] </ref> partitions the set of nodes in G into disjoint intervals, with each interval representing a proper loop (or recursion) layer.
Reference: [RW93] <author> Colin Runciman and David Wakeling. </author> <title> Heap Profiling of Lazy Functional Programs. </title> <journal> Journal of Functional Programming, </journal> <volume> 3(2) </volume> <pages> 217-246, </pages> <month> April </month> <year> 1993. </year>
Reference-contexts: In a garbage-collected language, the garbage collector need not use such variables as "roots" of live data. Several implementors have independently discovered that this is really important: if the collector traverses too many dead variables, the memory use of the program can increase by a large factor <ref> [Bak76, Cha88, RW93, App92, Jon92] </ref>.
Reference: [SA92] <author> Zhong Shao and Andrew W. Appel. </author> <title> Smartest Recompilation. </title> <type> Technical Report CS-TR-395-92, </type> <institution> Princeton Univ. Dept. of Computer Science, Princeton, NJ, </institution> <month> October </month> <year> 1992. </year>
Reference-contexts: The comparison of stack-based and heap-based closure allocation scheme described in Chapter 5 previously appeared as Reference [AS94]. The unrolling lists technique described in Chapter 6 is previously published as Reference [SRA94]. Some of the ideas used in Chapter 3 are evolved from my work on smartest recompilation <ref> [SA93, SA92] </ref>, which is not described in this dissertation. Chapter 2 Background This chapter sets the stage for the presentations in Chapters 3 through 6.
Reference: [SA93] <author> Zhong Shao and Andrew W. Appel. </author> <title> Smartest Recompilation. </title> <booktitle> In Proc. Twentieth Annual ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, </booktitle> <pages> pages 439-450. </pages> <publisher> ACM Press, </publisher> <year> 1993. </year>
Reference-contexts: The comparison of stack-based and heap-based closure allocation scheme described in Chapter 5 previously appeared as Reference [AS94]. The unrolling lists technique described in Chapter 6 is previously published as Reference [SRA94]. Some of the ideas used in Chapter 3 are evolved from my work on smartest recompilation <ref> [SA93, SA92] </ref>, which is not described in this dissertation. Chapter 2 Background This chapter sets the stage for the presentations in Chapters 3 through 6.
Reference: [SA94] <author> Zhong Shao and Andrew W. Appel. </author> <title> Space-Efficient Closure Representations. </title> <booktitle> In 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 150-161, </pages> <address> New York, June 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: History The idea of allocating continuation closures in callee-save registers (described in Chapter 4) is first published as Reference [AS92]. The new closure conversion algorithm in Chapter 4 is developed recently, and published as Reference <ref> [SA94] </ref>. The measurement data used in Reference [SA94] is different from one in Chapter 4 because they are using different versions of the SML/NJ compiler. The comparison of stack-based and heap-based closure allocation scheme described in Chapter 5 previously appeared as Reference [AS94]. <p> History The idea of allocating continuation closures in callee-save registers (described in Chapter 4) is first published as Reference [AS92]. The new closure conversion algorithm in Chapter 4 is developed recently, and published as Reference <ref> [SA94] </ref>. The measurement data used in Reference [SA94] is different from one in Chapter 4 because they are using different versions of the SML/NJ compiler. The comparison of stack-based and heap-based closure allocation scheme described in Chapter 5 previously appeared as Reference [AS94]. The unrolling lists technique described in Chapter 6 is previously published as Reference [SRA94].
Reference: [Shi91] <author> Olin Shivers. </author> <title> Control-Flow Analysis of Higher-Order Languages. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon Univ., Pittsburgh, Pennsylvania, </institution> <month> May </month> <year> 1991. </year> <month> CMU-CS-91-145. </month>
Reference-contexts: For each function definition w in the expression E, we also define pred (w) as its predecessor set; i.e., the set of all variables v such that there is an edge from v to w in E's extended CPS call graph. 2 Shivers <ref> [Shi91] </ref> presents more sophisticated techniques that can find even better approximations of control flow information. CHAPTER 4.
Reference: [SM94] <author> Darko Stefanovic and J. Eliot B. Moss. </author> <title> Characterization of Object Behaviour in Standard ML of New Jersey. </title> <booktitle> In 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 43-54, </pages> <address> New York, June 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The collector itself helps to improve the locality of reference of the mutator. Thus, locality of reference in a large cache is basically a solved problem. Furthermore, activation records die especially young. It will be extremely rare for an activation record to be promoted to a higher generation <ref> [SM94] </ref>. Since only the higher generations can cause cache misses 5 , heap-allocated frames will (almost) never cause cache misses. <p> Write-around caches do not need to stall the processor on a write miss, at least for the well behaved sequential writes performed by a heap allocator. Thus, the write miss cost will be zero; but since (almost) every newly written cache line will soon be fetched <ref> [SM94, Rei94] </ref>, we should expect the read-miss cost per frame for write-around caches to be similar to the cost per frame for fetch-on-write caches. <p> Jouppi's measurements of C and fortran programs [Jou93] may perhaps be influential. He concludes that write-validate (that is, write-allocate, no-fetch-on-write) is the policy with best performance. This is exactly the policy that we and others <ref> [DTM94, Rei94, SM94] </ref> find best for garbage-collected strict functional programs. On the other hand, as Jouppi points out, write-validate is difficult|though not impossible|to implement on a shared-memory multiprocessor with cache coherence. Such machines require each writable cache line to have a single owner. <p> We use lifetime statistics 12 as reported by Stefanovic and Moss <ref> [SM94] </ref> to find those objects that survive G calls but not p G. (The proportion p = 0:57 is the proportion of frames to total heap allocation (see Table 21).) Because of the shape of the object-survival curve, such objects are rare (1 object in 1000 allocations). <p> Direct measurement of garbage collection To support our analytical calculations of garbage-collection overhead, we measured the garbage collection time for stack vs. heap frames on benchmark programs. Table 22 shows 12 The measurements done by Stefanovic and Moss <ref> [SM94] </ref> are based on an older version of the SML/NJ compiler which does not use the new closure conversion algorithm described in Chapter 4. CHAPTER 5. HEAP VS. STACK 112 garbage collection costs for the execution of the benchmark programs on a DEC 5000/240 computer.
Reference: [SRA94] <author> Zhong Shao, John H. Reppy, and Andrew W. Appel. </author> <title> Unrolling Lists. </title> <booktitle> In 1994 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 185-195, </pages> <address> New York, June 1994. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The comparison of stack-based and heap-based closure allocation scheme described in Chapter 5 previously appeared as Reference [AS94]. The unrolling lists technique described in Chapter 6 is previously published as Reference <ref> [SRA94] </ref>. Some of the ideas used in Chapter 3 are evolved from my work on smartest recompilation [SA93, SA92], which is not described in this dissertation. Chapter 2 Background This chapter sets the stage for the presentations in Chapters 3 through 6.
Reference: [SS80] <author> Guy L. Steele and Gerald Jay Sussman. </author> <title> The Dream of a Lifetime: A Lazy Variable Extent Mechanism. </title> <booktitle> In Proceedings of the 1980 LISP Conference, </booktitle> <pages> pages 163-172, </pages> <address> Stanford, </address> <year> 1980. </year>
Reference-contexts: This turns to be complicated to implement. Danvy [Dan87] proposed to use a free list of re-usable frames (or "quasi-stack") to support fast call/cc; but his method may incur extra overhead at each function call (or return). Both Chow [Cho88a] and Steele <ref> [SS80] </ref> observed that dataflow analysis can help decide whether to put variables in caller-save or callee-save registers. We are the first to show how to represent callee-save registers in continuation-passing style [AS92, App92] and how to use compile-time variable lifetime information to do a much better job of it.
Reference: [Sta89] <institution> Standards Performance Evaluation Corp. </institution> <note> SPEC Benchmark Suite Release 1.0, October 1989. BIBLIOGRAPHY 155 </note>
Reference-contexts: Nucleic 3307 1 1 The pseudoknot program that computes the three-dimensional structure of part of a nucleic acid molecule [FTL94], translated from Scheme into Standard ML by Peter Lee. CHAPTER 2. BACKGROUND 25 run as its final performance data (as recommended, for example, by the SPEC benchmark consortium <ref> [Sta89] </ref>). All compilers mentioned in this dissertation use a simple two-generation copying garbage collector [App89]. Available memory is divided into two half-spaces, and allocation occurs at the low end of the upper space (called new space). <p> Times were calculated by executing each benchmark command five times consecutively (from within the same Unix execution) and dividing by five. Ten runs of each such test were made, and the fastest taken (as recommended, for example, by the spec benchmark consortium <ref> [Sta89] </ref>). Time spent in the operating system is not shown, but was small in all cases (and did not much differ among the three versions of each program).
Reference: [Ste78] <author> Guy L. Steele. Rabbit: </author> <title> a compiler for Scheme. </title> <type> Technical Report AI-TR-474, </type> <institution> MIT, </institution> <address> Cambridge, MA, </address> <year> 1978. </year>
Reference-contexts: Before a function call, context information is saved from registers into a "frame." In a compiler based on Continuation-Passing Style (CPS), this "frame" is the closure of a continuation function <ref> [Ste78] </ref>. In a CPS-based compiler, a closure environment is constructed at each function (or continuation) definition site; it provides runtime access to bindings of variables free in the CHAPTER 4. SPACE-EFFICIENT CLOSURE REPRESENTATIONS 62 function (or continuation) body. <p> The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques [Ung86]. The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques <ref> [Kra87, AS92, Ste78, Roz84, Han90, Joh85] </ref>, using a simple and general framework expressed in continuation-passing and closure-passing style [AJ89, AS92]. Our new algorithm extensively exploits the use of compile-time control and data flow information to optimize closure allocation strategies and representations. <p> Unlike linked closures, the nesting level of safely linked closures never exceeds two, so they still enjoy very fast variable access time. 4.3 Continuations and closures We will illustrate CPS-conversion (which is not new <ref> [Plo75, Ste78, Kra87, App92] </ref>), and our new closure analysis algorithm, on the example in Figure 16. <p> Where there are more than three free variables, some of the callee-save arguments must be heap-allocated records containing several variables each; thus, the CR closure-record appears as J1 in the call on line 19. Previous closure conversion algorithms <ref> [Ste78, KKR fl 86, AJ89] </ref> require memory stores for each continuation function. <p> If y's last use is much earlier than w's or x's, then the record (w; x; y) might not obey the SSC rule. Most closure conversion algorithms <ref> [App92, Kra87, Ste78] </ref> start with a phase to gather the set of raw free variables for each function definition in E. <p> Notice that a variable can have different lut and fut numbers inside different function definitions (e.g., a in J and Q). 4.4.3 Closure strategy analysis Closure strategy analysis essentially determines where in the machine to allocate each closure. Unlike previous CPS compilers <ref> [Kra87, Ste78] </ref>, we do not do any escape analysis, 3 because we simply do not use a runtime stack. Our closure strategy analysis only decides how many slots (i.e., registers) each closure is going to use, denoted by S (f ) for each function f . <p> This overhead is higher if more callee-save registers are used. 4.7 Related work Guy Steele's Rabbit compiler <ref> [Ste78] </ref> is the first compiler that uses the continuation-passing style as the intermediate language; it is also the first one that represents the "stack frames" using continuation closures. <p> Some compilers <ref> [Ste78, KKR fl 86, Car84a] </ref> perform closure conversion and closure analyses as part of their translation from lambda calculus or continuation-passing style into machine code. <p> Updating activation records In order to guarantee that only "new" heap frames can be roots for garbage collection, it is necessary to prohibit any writes to frames after they have been allocated. Compilers using continuation-passing style (such as Rabbit <ref> [Ste78] </ref>, Orbit [KKR fl 86], and SML/NJ [AJ89]) naturally initialize frames as soon as they are allocated, and then never write to them again. In effect, they save up any changes in registers, then dump everything out all at once. <p> Here is the filter function: fun filter p = let fun f nil = nil | f (x::r) = if (p x) then x::(f r) else f r in f It turns out that this problem can be easily solved in the continuation-passing style (CPS) framework <ref> [Ste78, App92] </ref>, because we can specialize the return continuation on the length parity of the result, and make it have multiple entry points also.
Reference: [Ste84] <author> Guy L. Steele. </author> <title> The Common LISP: The Language. </title> <publisher> Digital Press, Digital Equipment Corporation, </publisher> <year> 1984. </year>
Reference-contexts: Actually, it is shown (by Turing [Tur37]) that those functions computable on Turing machines are exactly those definable functions in the lambda calculus. 2.1.2 Lisp Lisp <ref> [McC60, Ste84] </ref> was the first functional language in the world, developed by John McCarthy in 1950s. Although the core of Lisp is essentially the lambda calculus plus the constants, many new features in Lisp are now commonly used by almost all functional languages.
Reference: [TA90] <author> David R. Tarditi and Andrew W. Appel. ML-Yacc, </author> <title> version 2.0. Distributed with Standard ML of New Jersey, </title> <month> April </month> <year> 1990. </year>
Reference-contexts: VLIW 3658 24 2 A Very-Long-Instruction-Word instruc tion scheduler written by John Danskin. YACC 7432 56 26 A LALR (1) parser generator, implemented by David R. Tarditi <ref> [TA90] </ref>, processing the gram mar of Standard ML. MBrot 60 1 1 The Mandelbrot curve construction written by John Reppy. Nucleic 3307 1 1 The pseudoknot program that computes the three-dimensional structure of part of a nucleic acid molecule [FTL94], translated from Scheme into Standard ML by Peter Lee.
Reference: [Tar74] <author> Robert E. Tarjan. </author> <title> Testing flow graph reducibility. </title> <journal> Journal of Computer and System Science, </journal> <volume> 9(3) </volume> <pages> 355-365, </pages> <month> December </month> <year> 1974. </year>
Reference-contexts: Cycles in the graph imply loops or recursions (e.g., the path from h to J to Q). The nested hierarchies of loops and recursions in E can be revealed by running the Tarjan interval analysis algorithm <ref> [Tar74, RP86] </ref> on G, assuming G is a reducible flow graph.
Reference: [Tof92] <author> Mads Tofte. </author> <title> Principal Signatures for High-order ML Functors. </title> <booktitle> In Nineteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 189-199, </pages> <address> New York, Jan 1992. </address> <publisher> ACM Press. </publisher>
Reference-contexts: There are four module constructs where abstraction and instantiation may occur: signature matching, abstraction declaration, functor application, and functor signature matching (used by higher-order modules <ref> [Tof92, MT94] </ref>).
Reference: [Tur37] <author> Alan M. </author> <title> Turing. Computability and -definability. </title> <journal> J. Symbolic Logic, </journal> <volume> 2 </volume> <pages> 153-163, </pages> <year> 1937. </year>
Reference-contexts: The ability of the lambda calculus to simulate recursion in this way is the key to its power and accounts for its persistence as a useful model of computation. Actually, it is shown (by Turing <ref> [Tur37] </ref>) that those functions computable on Turing machines are exactly those definable functions in the lambda calculus. 2.1.2 Lisp Lisp [McC60, Ste84] was the first functional language in the world, developed by John McCarthy in 1950s.
Reference: [Ull93] <author> Jeffrey D. Ullman. </author> <title> Elements of ML Programming. </title> <publisher> Prentice Hall, </publisher> <address> Englewood Cliffs, NJ, </address> <year> 1993. </year>
Reference-contexts: and one cdr field, the unrolled list reduces the memory used for links and significantly shortens the length of control-dependence and data-dependence chains in operations on lists. 1.2 Outline of this dissertation The development of this dissertation may be easier to follow for readers with some background in Standard ML <ref> [Ull93, Har86, MTH90] </ref> and basic compilation techniques for functional languages [App92, Pey87]. Chapter 2 contains a survey of various functional languages, an introduction to SML (which may be skipped if the reader is familiar with SML notation), and a review of several important aspects in compiling functional languages. <p> Readers are referred to References <ref> [Har86, Ull93, Pau91] </ref> for a more complete introduction. The formal definition and commentary for SML can be found in References [MTH90, MT91]. 2.2.1 Basic expressions, values, and types SML is an expression language: the traditional statement constructs, such as blocks, conditionals, case statements, and assignment, are packaged as expressions.
Reference: [Ung86] <author> David M. Ungar. </author> <title> The Design and Evaluation of A High Performance Smalltalk System. </title> <publisher> MIT Press, </publisher> <address> Cambridge,MA, </address> <year> 1986. </year>
Reference-contexts: and the LTYs for F and F 0 are respectively s and t, then the LEXP expression for F 0 is f 0 = (coerce (s; t))(f ), and functor application F (S) is translated into APP (f 0 ; c (v)). 5 In order to support generational garbage collection <ref> [LH83, Ung86] </ref>, most compilers must do some bookkeeping at each update so that the pointers from older generation to youngest generation are correctly identified. <p> But on many modern machines, the write miss penalty is approximately zero [Jou93, DTM94, Rei94]. 3. The amortized cost of collection can be very low [App87] (also see Chapter 5), espe cially with modern generational garbage collection techniques <ref> [Ung86] </ref>. The major contribution of this chapter is a "safe for space" closure conversion algorithm that integrates and improves most previous closure analysis techniques [Kra87, AS92, Ste78, Roz84, Han90, Joh85], using a simple and general framework expressed in continuation-passing and closure-passing style [AJ89, AS92]. <p> One might think that it would be expensive to allocate, at every procedure call, heap storage that becomes garbage on return. But not necessarily [App87]: modern generational garbage-collection algorithms <ref> [Ung86] </ref> can reclaim dead frames efficiently, as cheap as the one-instruction cost to pop the stack. But there are other costs involved in creating, accessing, and destroying activation records|whether on a heap or a stack. <p> CHAPTER 5. HEAP VS. STACK 99 The analysis of cache behavior of garbage collected systems differs qualitatively depending on the size of the cache. Large Caches For large (e.g., secondary) caches, a generational garbage collection algorithm <ref> [Ung86] </ref> can keep its youngest generation entirely within the cache [WLM92, Zor91]. Only the (rare) objects that survive a collection (or two) will be promoted into an older generation where they can cause cache misses. The collector itself helps to improve the locality of reference of the mutator.
Reference: [Wad87] <author> Philip Wadler. </author> <title> Views: A way for pattern matching to cohabit with data abstraction. </title> <booktitle> In Fourteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 307-313, </pages> <address> New York, Jan 1987. </address> <publisher> ACM Press. </publisher>
Reference-contexts: The reason that we use the refinement types, on the other hand, is to do compile-time program transformations and optimizations. The refinement type declaration used in our scheme is embedded in the compiler, and is completely hidden from programmers. As in Wadler's views mechanism <ref> [Wad87] </ref>, the standard and unrolled representations of lists in our scheme can be linked together by a pair of in and out functions (e.g., the "ucons" and "uproj" function in Section 6.1).
Reference: [Wan80] <author> Mitchell Wand. </author> <title> Continuation-Based Multiprocessing. </title> <booktitle> In Conf. Record of the 1980 Lisp Conf., </booktitle> <pages> pages 19-28, </pages> <address> New York, </address> <month> August </month> <year> 1980. </year> <note> ACM Press. </note>
Reference-contexts: First class continuations are useful for implementing coroutines <ref> [Wan80] </ref> and concurrency libraries [Rep91]. But call/cc is much harder to implement efficiently if there is a stack. With an ordinary contiguous stack implementation, the entire stack must be copied on each creation or invocation of a first-class continuation.
Reference: [WB89] <author> P. Wadler and S. Blott. </author> <title> How to make ad hoc polymorphism less ad hoc. </title> <booktitle> In Sixteenth Annual ACM Symp. on Principles of Prog. Languages, </booktitle> <pages> pages 60-76, </pages> <address> New York, Jan 1989. </address> <publisher> ACM Press. </publisher>
Reference-contexts: For example, ML supports parametrized modules (i.e., functors) and module abstractions while Haskell does not. * The type system in Haskell also supports type-classes|a more general form of over loading <ref> [WB89] </ref>. The details on how to efficiently compile pure functional languages such as Haskell are discussed by Peyton Jones [Pey87, Pey92].
Reference: [Wil91] <author> Paul R. Wilson. </author> <title> Some Issues and Strategies in Heap Management and Memory Hierarchies. </title> <journal> SIGPLAN Notices, </journal> <volume> 26(3) </volume> <pages> 45-52, </pages> <month> March </month> <year> 1991. </year>
Reference-contexts: But there is a complication. Between collections, if the "high-water" frame is popped, the mark must be moved down to the next-lower frame <ref> [Wil91] </ref>. The simplest way to do this would be to test for the mark on every return, but this would be expensive. Instead, the mark consists of a "special" return address, which replaces the real return address of a frame.
Reference: [WLM92] <author> Paul R. Wilson, Michael S. Lam, and Thomas G. Moher. </author> <title> Caching Considerations for Generational Garbage Collection. </title> <booktitle> In 1992 ACM Conference on Lisp and Functional Programming, </booktitle> <pages> pages 32-42, </pages> <address> New York, June 1992. </address> <publisher> ACM Press. BIBLIOGRAPHY 156 </publisher>
Reference-contexts: CHAPTER 5. HEAP VS. STACK 99 The analysis of cache behavior of garbage collected systems differs qualitatively depending on the size of the cache. Large Caches For large (e.g., secondary) caches, a generational garbage collection algorithm [Ung86] can keep its youngest generation entirely within the cache <ref> [WLM92, Zor91] </ref>. Only the (rare) objects that survive a collection (or two) will be promoted into an older generation where they can cause cache misses. The collector itself helps to improve the locality of reference of the mutator.
Reference: [WM81] <author> D. Weinreb and D. Moon. </author> <title> Lisp Machine Manual. </title> <type> Technical report, </type> <institution> Symbolics Corp., </institution> <address> Cambridge, Mass., </address> <year> 1981. </year>
Reference-contexts: Cdr-coding solves the space-usage problem (and in the MIT version allows random access subscripting of lists [Gre77]), but makes the control-dependence problem even worse, as the cdr-coding tag of each car must be checked. Cdr-coding was popular on microcoded Lisp machines circa 1980 <ref> [WM81, Deu73] </ref>, but it is not an attractive solution on modern machines. Our new "compile-time cdr-coding" method works for statically typed languages such as ML. Our scheme allows a more compact runtime representation for lists, but does not require any runtime encoding at all. <p> CHAPTER 6. UNROLLING LISTS 138 Lisp machines <ref> [WM81, Deu73] </ref> to alleviate the high costs incurred by the runtime encoding bits. Since modern machines tend not to offer these kinds of special hardware support, the runtime cdr-coding technique quickly became obsolete in the 1980's.
Reference: [Zor91] <author> Benjamin Zorn. </author> <title> The Effect of Garbage Collection on Cache Performance. </title> <type> Technical Report CU-CS-528-91, </type> <institution> University of Colorado, Boulder, CO, </institution> <month> May </month> <year> 1991. </year>
Reference-contexts: CHAPTER 5. HEAP VS. STACK 99 The analysis of cache behavior of garbage collected systems differs qualitatively depending on the size of the cache. Large Caches For large (e.g., secondary) caches, a generational garbage collection algorithm [Ung86] can keep its youngest generation entirely within the cache <ref> [WLM92, Zor91] </ref>. Only the (rare) objects that survive a collection (or two) will be promoted into an older generation where they can cause cache misses. The collector itself helps to improve the locality of reference of the mutator. <p> This is costly; but recursions this deep also begin to miss in the secondary cache! This is particularly so, since the size of the youngest generation should be less than the size of the secondary cache <ref> [Zor91, Rep93] </ref>. The secondary cache misses (which occur for both stacks and heaps) are probably just as important as the garbage-collection overhead. Summary: 0.06 instructions per frame.
References-found: 126

