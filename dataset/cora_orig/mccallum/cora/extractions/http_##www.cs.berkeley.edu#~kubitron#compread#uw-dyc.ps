URL: http://www.cs.berkeley.edu/~kubitron/compread/uw-dyc.ps
Refering-URL: http://www.cs.berkeley.edu/~kubitron/compread/index.html
Root-URL: 
Email: -grant,mock,matthai,chambers,eggers-@cs.washington.edu  
Title: DyC: An Expressive Annotation-Directed Dynamic Compiler for C  
Author: Brian Grant, Markus Mock, Matthai Philipose, Craig Chambers, and Susan J. Eggers 
Web: http://www.cs.washington.edu/research/dyncomp/  
Note: Last Update: January 30, 1998  
Affiliation: Department of Computer Science and Engineering University of Washington  
Pubnum: Technical Report UW-CSE-97-03-03  
Abstract: We present the design of DyC, a dynamic-compilation system for C based on run-time specialization. Directed by a few declarative user annotations that specify the variables and code on which dynamic compilation should take place, a binding-time analysis computes the set of run-time constants at each program point in the annotated procedures control-ow graph; the analysis supports program-point-specific polyvariant division and specialization. The analysis results guide the construction of a specialized run-time specializer for each dynamically compiled region; the specializer supports various caching strategies for managing dynamically generated code and mixes of speculative and demand-driven specialization of dynamic branch successors. Most of the key cost/benefit trade-offs in the binding-time analysis and the run-time specializer are open to user control through declarative policy annotations. Our design has been implemented in the context of an existing optimizing compiler, and initial results are promising. The annotations appear to have sufficient expressiveness, the speedups we have obtained are good, and the dynamic-compilation overhead is among the lowest of any dynamic-compilation system. Moreover, we have demonstrated DyCs ability to dynamically compile larger applications than has been achieved with other dynamic-compilation systems. 
Abstract-found: 1
Intro-found: 1
Reference: [Andersen 92a] <author> L.O. Andersen. </author> <title> C Program Specialization. Technical Re * If run-time inlining through function pointers were available in DyC, analysis across those calls would be of comparable difficulty. </title> <type> port 92/14, </type> <month> May </month> <year> 1992. </year>
Reference-contexts: In contrast, DyC provides control over code growth by permitting variables to be specialized monovariantly or by specializing lazily on demand. C-mixs pure annotation corresponds to constant, and unfold fills the role of the inline pragma provided by most modern optimizing compilers. Andersens dynamic basic blocks (DBBs) <ref> [Andersen 92a] </ref> serve the same purpose as specialization units, to reduce overhead in the specializer; however, their boundaries are determined entirely differently. DyCs specialization units differ from C-mixs dynamic basic blocks in the following ways: DBBs are bounded by (and may not contain) dynamic control ow.
Reference: [Andersen 92b] <author> L.O. Andersen. </author> <title> Self-Applicable C Program Specialization. </title> <booktitle> pages 5461, </booktitle> <month> June </month> <year> 1992. </year>
Reference: [Andersen 94] <author> L.O. Andersen. </author> <title> Program Analysis and Specialization for the C Programming Language. </title> <type> Ph.D. thesis, </type> <year> 1994. </year> <note> DIKU Research Report 94/19. </note>
Reference-contexts: However, C-mixs analysis runs in near-linear time and is efficient enough to apply interprocedurally, while DyCs cubic-complexity analysis is only applied intraprocedurally. C-mix copes directly with unstructured code, but it appears to lack reachability analysis to identify static merges <ref> [Andersen 94] </ref>. C-mix handles partially static structures by splitting the structures into separate variables. C-mix includes support for automatic interprocedural call graph, alias, and side-effect analyses.
Reference: [Auslander et al. 96] <author> J. Auslander, M. Philipose, C. Chambers, S. Eggers, and B. Bershad. </author> <title> Fast, Effective Dynamic Compilation. </title> <journal> SIGPLAN Notices, </journal> <pages> pages 149159, </pages> <month> May </month> <year> 1996. </year> <booktitle> In Proceedings of the ACM SIG-PLAN 96 Conference on Programming Language Design and Implementation. </booktitle>
Reference-contexts: These systems offer great exibility and control to the programmer, but at the cost of significant programmer effort and debugging difficulty. Alternatively, Fabius [Leone & Lee 96], Tempo [Consel & Nol 96], and our previous system <ref> [Auslander et al. 96] </ref> take a declarative approach, employing user annotations to guide dynamic compilation. <p> Since Figure 4 is obtained by straightforward specialization of the interpreter, each reference to a virtual register in the interpreter results in a load to or a store from the array that implements the registers. Better code could be generated by adding register actions to DyC <ref> [Auslander et al. 96] </ref>. Register actions permit memory locations to be assigned registers through pre-planned local transformations. <p> Reachability conditions are computed at the same time as the BTA information, since they depend on the BTAs division and static variable analysis and inuence the BTA analysiss treatment of merge nodes. Further details on reachability analysis can be found in an earlier paper <ref> [Auslander et al. 96] </ref> * . 6 Generating the Run-Time Specializer Given the output of the BTA analysis, our compiler statically constructs the code and static data structures that, when executed at run time, will call the run-time specializer with the appropriate run-time constant arguments to produce and cache the run-time <p> The compiler separates the static operations (OpNodes whose right-hand-side expressions were computed to be static by the BTA analysis) and the dynamic operations into two separate, parallel control-ow subgraphs; in earlier work we called these subgraphs set-up code and template code, respectively <ref> [Auslander et al. 96] </ref>. Subsection 6.4 discusses some aspects of this separation in more detail. <p> We apply standard compiler optimizations, including instruction scheduling and register allocation, to each subgraph separately. (We perform higher-level, target-independent optimizations, such as common-subexpression elimination and loop optimizations, before our BTA analysis.) Performing these regular compiler optimizations over both statically compiled and dynamically compiled code is crucial for generating high-quality code <ref> [Auslander et al. 96] </ref>. Finally, each units ReduceAndResidualize function is produced. <p> Fabius does little cross-dynamic-statement optimization other than register allocation, since, unlike DyC, it does not explicitly construct an explicit dynamic subgraph that can then be optimized. Compared to our previous system <ref> [Auslander et al. 96] </ref>, DyC has a more exible and expressive annotation language, support for polyvariant division and better support for polyvariant specialization, support for nested and overlapping dynamic regions, support for demand-driven (lazy) specialization, support for interprocedural specialization, a much more efficient strategy for and optimizations of run-time specialization, and
Reference: [Consel & Nol 96] <author> C. Consel and F. Nol. </author> <title> A General Approach for Run-Time Specialization and its Application to C. </title> <booktitle> In Conference Record of POPL 96: 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, </booktitle> <pages> pages 145156, </pages> <address> St. Petersburg, Florida, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: These systems offer great exibility and control to the programmer, but at the cost of significant programmer effort and debugging difficulty. Alternatively, Fabius [Leone & Lee 96], Tempo <ref> [Consel & Nol 96] </ref>, and our previous system [Auslander et al. 96] take a declarative approach, employing user annotations to guide dynamic compilation. <p> Such a scheme could improve performance for applications in which it could be easily determined when to invalidate the current specialized version of each dynamic region. 8 Comparison To Related Work Tempo <ref> [Consel & Nol 96] </ref>, a compile-time and run-time specialization system for C, is most similar to DyC. The two differ chiey in the following ways: DyC may produce multiple divisions and specializations of program points, with the degree of division and specialization varying from point to point.
Reference: [Consel 93] <author> C. Consel. </author> <title> A Tour of Schism: A Partial Evaluation System for Higher-Order Applicative Languages. </title> <booktitle> pages 145154, </booktitle> <year> 1993. </year>
Reference-contexts: DBBs may overlap. Units currently cannot overlap, though that restriction could be relaxed, as described in the previous section. Schisms filters permit choices about whether to unfold or residualize a function and which arguments to generalize (i.e., make dynamic), given binding times for the functions parameters <ref> [Consel 93] </ref>. Because filters are executed by the binding-time analysis, only binding-time information can be used to make decisions. DyCs conditional specialization can use the results of arbitrary static or dynamic expressions to control all aspects of run-time specialization. Filters can be used to prevent unbounded unfolding and unbounded specialization.
Reference: [Consel et al. 96] <author> C. Consel, L. Hornof, F. Nol, J. Noy, and N. </author> <note> Volanschi. </note>
Reference-contexts: Tempo supports only function-level polyvariant division and specialization, with no additional division or specialization possible within the function, except for some limited support for loop unrolling. DyC performs analysis over arbitrary, potentially unstructured control-ow graphs. Tempo converts all instances of unstructured code to structured form <ref> [Erosa & Hendren 94, Consel et al. 96] </ref>, which introduces a number of additional tests and may also introduce loops. DyC allows dynamic-to-static promotions to occur anywhere within dynamically compiled code. Tempo requires such promotions to occur only at the entry point.
References-found: 7

