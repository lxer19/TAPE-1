URL: http://www.cs.ucla.edu/~inki/icassp97_1.ps
Refering-URL: http://www.cs.ucla.edu/~inki/publications.html
Root-URL: http://www.cs.ucla.edu
Title: MINIMIZING THE NUMBER OF OPERATIONS IN DSP COMPUTATIONS  
Author: Inki Hong and Miodrag Potkonjak 
Address: Los Angeles, CA 90095-1596, USA  
Affiliation: UCLA Computer Science Department,  
Abstract: Reduction of the number of operations optimizes the important design metrics such as area, cost, throughput, and power consumption for both custom ASIC and programmable processor implementations. We propose a novel technique to minimize the number of operations in DSP computations. The first step of the approach logically partitions a computation into strongly connected components. The second step optimizes each component separately. In the third step the components are merged to further optimize. Finally, the components are scheduled to minimize memory consumption. The effectiveness of our approach is demonstrated on real-life examples. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. S. </author> <title> Bhattacharyya et al,"A scheduling framework for minimizing memory requirements of multirate signal processing algorithms expressed as dataflow graphs,", </title> <booktitle> VLSI Signal Processing VI, </booktitle> <pages> pp. 188-196, </pages> <year> 1993. </year>
Reference-contexts: They should be scheduled so that memory requirements for code and data of a schedule are minimized. We observe that the unfolded subparts can be represented by multi-rate synchronous dataflow graph [5] and the works of <ref> [1] </ref> can be directly used. 4. EXPERIMENTAL RESULTS This section presents the experimental results of our technique for real-life examples, where Table 1 summarizes the results.
Reference: [2] <author> L. Guerra, M. Potkonjak, J. Rabaey, </author> <title> "Divide-and-Conquer Techniques for Global Throughput Optimization", </title> <booktitle> VLSI Signal Processing Workshop, </booktitle> <pages> pp. 137-146, </pages> <address> San Francisco, CA, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: Srivastava and Potkonjak [10] developed an approach for the minimization of the number of operations in linear computations using unfolding and the application of the maximally fast procedure. Guerra et al. <ref> [2] </ref> developed a divide and conquer approach for minimizing critical paths. 3. OPTIMIZATION APPROACH The core of the approach is presented in the pseudo-code of of the approach in more detail.
Reference: [3] <author> I. Hong, M. </author> <title> Potkonjak,"Minimizing the Number of Operations in DSP Computations", </title> <type> UCLA CSD Tech. Rep. </type> <note> (to appear). </note>
Reference-contexts: If there are no coefficients of 1 or 1 in the matrices A, B, C, and D, then closed-form for mula of the optimal unfolding factor i opt and of the number of operations for i times unfolded system can be obtained <ref> [3] </ref>. The formula are provided in Figure 8. While (there is improvement) For all possible merging candidates, Compute the gain; Merge the pair with the highest gain; Now, we can evaluate possible merging candidates. We propose two heuristic algorithms for SCC merging.
Reference: [4] <author> S. Kirkpatrick, C. Gelatt, M. Vecchi, </author> <title> "Optimization by Simulated Annealing," </title> <journal> Science, </journal> <volume> Vol. 220, No. 4598, </volume> <pages> pp. 671-680, </pages> <year> 1983. </year>
Reference-contexts: Experimental results for real-life examples The pseudo-code is provided in Figure 9. The algorithm is simple. Until there is no improvement, merge the pair of subparts which produces the highest gain. The other heuristic algorithm is based on a general combinatorial optimization technique known as simulated annealing <ref> [4] </ref>. Since the subparts of a computation are unfolded separately by different unfolding factors, we need to address the problem of scheduling of the subparts. They should be scheduled so that memory requirements for code and data of a schedule are minimized.
Reference: [5] <author> E. A. Lee and D. G. Messerschmitt, </author> <booktitle> "Synchronous dataflow" , Proceedings of the IEEE, </booktitle> <volume> Vol. 75, No. 9, </volume> <pages> pp. 1235-1245, </pages> <year> 1987. </year>
Reference-contexts: They should be scheduled so that memory requirements for code and data of a schedule are minimized. We observe that the unfolded subparts can be represented by multi-rate synchronous dataflow graph <ref> [5] </ref> and the works of [1] can be directly used. 4. EXPERIMENTAL RESULTS This section presents the experimental results of our technique for real-life examples, where Table 1 summarizes the results.
Reference: [6] <author> C. E. Leiserson, J. B. Saxe, </author> <title> "Retiming synchronous circuitry," </title> <journal> Algorithmica, </journal> <volume> Vol. 6, No. 1, </volume> <pages> pp. 5-35, </pages> <year> 1991. </year>
Reference-contexts: As a result, every output and state in a subpart depend only on the subpart's inputs and states. Note that this isolation is not affected by unfolding. In the next step, the number of delays in the computation is minimized using retiming by the Leiserson-Saxe algorithm <ref> [6] </ref>. It is obvious that smaller number of delays will require smaller number of operations since both the next states and outputs depend on the previous states. The SCCs are further classified as either linear or nonlinear.
Reference: [7] <author> M. Potkonjak, J. Rabaey, </author> <title> "Maximally Fast and Arbitrarily Fast Implementation of Linear Computations," </title> <booktitle> IEEE International Conference on Computer-Aided Design, </booktitle> <pages> pp. 304-308, </pages> <year> 1992. </year>
Reference-contexts: The number of operations per input sample is initially 2081 (We illustrate how the number of operations is calculated in a maximally fast procedure <ref> [7] </ref> using a simple linear computation with 2 states and 1 output which is described in Figure 2). Using the technique of [10] which unfolds the entire computation, the number can be reduced to 725 with an unfolding factor of 12. <p> Section 4. illustrates the effectiveness of the technique using real-life examples. Finally, Section 5. draws conclusions. 2. RELATED WORK In this section, we briefly review the related work on the minimization of the number of operations. Potkonjak and Rabaey <ref> [7] </ref> addressed the minimization of the number of multiplications and additions in linear computations in their maximally fast form so that the throughput is preserved. Potkonjak et al. [8] presented a set of techniques for minimization of the number of shifts and additions in linear computations. <p> We have used an approach of [10] for optimization of linear SCCs, which uses unfolding and the maximally fast procedure <ref> [7] </ref>. We note that instead of maximally fast procedure the ratio analysis by [9] can be used. [10] has provided the closed-form formula for the optimal unfolding factor with the assumption of dense linear computations which are provided in Figure 5.
Reference: [8] <author> M. Potkonjak et al, </author> <title> "Multiple constant multiplications: efficient and versatile framework and algorithms for exploring common subexpression elimination", </title> <journal> IEEE Trans. on CAD, </journal> <volume> Vol. 15, No. 2, </volume> <pages> pp. 151-165, </pages> <year> 1996. </year>
Reference-contexts: Potkonjak and Rabaey [7] addressed the minimization of the number of multiplications and additions in linear computations in their maximally fast form so that the throughput is preserved. Potkonjak et al. <ref> [8] </ref> presented a set of techniques for minimization of the number of shifts and additions in linear computations. Sheliga and Sha [9] presented an approach for minimization of the number of multiplications and additions in linear computations.
Reference: [9] <author> M. Sheliga, E.H.-M. Sha, </author> <title> "Global node reduction of linear systems using ratio analysis", </title> <booktitle> International Symposium on High-Level Synthesis, </booktitle> <pages> pp. 140-145, </pages> <year> 1994. </year>
Reference-contexts: Potkonjak et al. [8] presented a set of techniques for minimization of the number of shifts and additions in linear computations. Sheliga and Sha <ref> [9] </ref> presented an approach for minimization of the number of multiplications and additions in linear computations. Srivastava and Potkonjak [10] developed an approach for the minimization of the number of operations in linear computations using unfolding and the application of the maximally fast procedure. <p> We have used an approach of [10] for optimization of linear SCCs, which uses unfolding and the maximally fast procedure [7]. We note that instead of maximally fast procedure the ratio analysis by <ref> [9] </ref> can be used. [10] has provided the closed-form formula for the optimal unfolding factor with the assumption of dense linear computations which are provided in Figure 5. For sparse linear computations, they have proposed a heuristic which continues to unfold further until there is no improvement.
Reference: [10] <author> M. Srivastava, M. Potkonjak, </author> <title> "Power optimization in programmable processors and ASIC implementations of linear systems: transformation-based approach," </title> <booktitle> Design Automation Conference, </booktitle> <pages> pp. 343-348, </pages> <year> 1996. </year>
Reference-contexts: The number of operations per input sample is initially 2081 (We illustrate how the number of operations is calculated in a maximally fast procedure [7] using a simple linear computation with 2 states and 1 output which is described in Figure 2). Using the technique of <ref> [10] </ref> which unfolds the entire computation, the number can be reduced to 725 with an unfolding factor of 12. Our approach can optimize each subpart separately, which is enabled from isolating the subparts using pipeline delays. The Figure 3 shows the resulting computation after the isolation step. <p> We perform subparts merging to further optimize. If the subparts C and D are merged and optimized together, the number of operations is further reduced to 399.4. The approach has reduced the number of operations by a factor of 1.82 (5.2) from the previous technique of <ref> [10] </ref> (from the initial number of operations). The main technical innovation of the research presented in this paper is the first approach for the minimization of the number of operations in general computations. The approach does not treat just significantly wide set of computations than the other previously published techniques [10], <p> <ref> [10] </ref> (from the initial number of operations). The main technical innovation of the research presented in this paper is the first approach for the minimization of the number of operations in general computations. The approach does not treat just significantly wide set of computations than the other previously published techniques [10], but also outperforms or performs at least as well as other techniques on all examples. The rest of the paper is organized in the following way. In Section 2. we briefly review the related work on the minimization of the number of operations. <p> Potkonjak et al. [8] presented a set of techniques for minimization of the number of shifts and additions in linear computations. Sheliga and Sha [9] presented an approach for minimization of the number of multiplications and additions in linear computations. Srivastava and Potkonjak <ref> [10] </ref> developed an approach for the minimization of the number of operations in linear computations using unfolding and the application of the maximally fast procedure. Guerra et al. [2] developed a divide and conquer approach for minimizing critical paths. 3. <p> We have used an approach of <ref> [10] </ref> for optimization of linear SCCs, which uses unfolding and the maximally fast procedure [7]. We note that instead of maximally fast procedure the ratio analysis by [9] can be used. [10] has provided the closed-form formula for the optimal unfolding factor with the assumption of dense linear computations which are <p> We have used an approach of <ref> [10] </ref> for optimization of linear SCCs, which uses unfolding and the maximally fast procedure [7]. We note that instead of maximally fast procedure the ratio analysis by [9] can be used. [10] has provided the closed-form formula for the optimal unfolding factor with the assumption of dense linear computations which are provided in Figure 5. For sparse linear computations, they have proposed a heuristic which continues to unfold further until there is no improvement. <p> While (there is improvement) For all possible merging candidates, Compute the gain; Merge the pair with the highest gain; Now, we can evaluate possible merging candidates. We propose two heuristic algorithms for SCC merging. The first heuristic is based on greedy optimization approach. Design Init Ops <ref> [10] </ref> New Method Imp. DAC 2098 2098 1327.83 1.58 modem 213 213 148.83 1.43 GE controller 180 180 105.26 1.71 APCM receiver 2238 N/A 1444.19 1.55 Audio Filter 228 N/A 92.0 2.48 Video Filter 398 N/A 184.5 2.16 Table 1. <p> DAC, modem, and GE controller are linear computations and the rest are nonlinear computations. The fifth column of Table 1 provides only the improvement factor of our method from the initial number of operations since <ref> [10] </ref> is either ineffective or inapplicable for all examples. Our method has reduced the number of operations by an average factor of 1.82 (average 42.9 %) for the examples, which clearly indicates the effectiveness of our new method. 5.
Reference: [11] <author> R. E. Tarjan, </author> <title> "Depth first search and linear graph algorithms," </title> <journal> SIAM Journal on Computing, </journal> <volume> Vol. 1, No. 2, </volume> <pages> pp. 146-160, </pages> <year> 1972. </year>
Reference-contexts: OPTIMIZATION APPROACH The core of the approach is presented in the pseudo-code of of the approach in more detail. The first step of the approach is to identify the computation's strongly connected components (SCCs), using the standard depth-first search-based algorithm <ref> [11] </ref>. For any pair of operations A and B within a SCC, there exist both a path from A to B and one from B to A. The SCCs are isolated from each other using pipeline delays, which enables us to optimize each subpart separately. <p> It is easy to construct the matrices using the depth-first search <ref> [11] </ref>. The i times unfolded system can be represented by the state-space equations in Figure 7. From the equations, the total number of operations can be computed for i times unfolded subpart.
References-found: 11

