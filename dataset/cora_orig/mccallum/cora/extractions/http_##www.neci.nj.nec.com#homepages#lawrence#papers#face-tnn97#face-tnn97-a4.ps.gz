URL: http://www.neci.nj.nec.com/homepages/lawrence/papers/face-tnn97/face-tnn97-a4.ps.gz
Refering-URL: http://www.neci.nj.nec.com/homepages/lawrence/papers/face-tnn97/
Root-URL: http://www.neci.nj.nec.com
Email: flawrence,act,backg@elec.uq.edu.au, giles@research.nj.nec.com  
Phone: 1  2  
Title: Face Recognition: A Convolutional Neural Network Approach  
Author: Steve Lawrence ;fl C. Lee Giles y Ah Chung Tsoi Andrew D. Back 
Address: 4 Independence Way, Princeton, NJ 08540  St. Lucia, Australia  
Affiliation: NEC Research Institute,  Electrical and Computer Engineering, University of Queensland,  
Note: IEEE Transactions on Neural Networks, Special Issue on Neural Networks and Pattern Recognition, Volume 8, Number 1, pp. 98113, 1997. Copyright IEEE.  
Abstract: Faces represent complex, multidimensional, meaningful visual stimuli and developing a computational model for face recognition is difficult [43]. We present a hybrid neural network solution which compares favorably with other methods. The system combines local image sampling, a self-organizing map neural network, and a convolutional neural network. The self-organizing map provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides for partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-LoOEeve transform in place of the self-organizing map, and a multi-layer perceptron in place of the convolutional network. The Karhunen-LoOEeve transform performs almost as well (5.3% error versus 3.8%). The multi-layer perceptron performs very poorly (40% error versus 3.8%). The method is capable of rapid classification, requires only fast, approximate normalization and preprocessing, and consistently exhibits better classification performance than the eigenfaces approach [43] on the database considered as the number of images per person in the training database is varied from 1 to 5. With 5 images per person the proposed method and eigenfaces result in 3.8% and 10.5% error respectively. The recognizer provides a measure of confidence in its output and classification error approaches zero when rejecting as few as 10% of the examples. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze computational complexity and discuss how new classes could be added to the trained recognizer. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> S. </author> <title> Arya and D.M. Mount. Algorithms for fast vector quantization. </title> <editor> In J. A. Storer and M. Cohn, editors, </editor> <booktitle> Proceedings of DCC 93: Data Compression Conference, </booktitle> <pages> pages 381390. </pages> <publisher> IEEE Press, </publisher> <year> 1993. </year>
Reference-contexts: We note that the constant associated with the log factors may increase exponentially in the worst case (cf. neighbor searching in high dimensional spaces <ref> [1] </ref>).
Reference: [2] <author> Hans-Ulrich Bauer and Klaus R. Pawelzik. </author> <title> Quantifying the neighborhood preservation of Self-Organizing Feature Maps. </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> 3(4):570579, </volume> <year> 1992. </year>
Reference-contexts: The degree of invariance can be modified by adjusting the weight w ij connected to the central intensity component. 6 created at each location. 4.3 The Self-Organizing Map 4.3.1 Introduction Maps are an important part of both natural and artificial neural information processing systems <ref> [2] </ref>. Examples of maps in the nervous system are retinotopic maps in the visual cortex [31], tonotopic maps in the auditory cortex [18], and maps from the skin onto the somatosensoric cortex [32].
Reference: [3] <author> Yoshua Bengio, Y. Le Cun, and D. Henderson. </author> <title> Globally trained handwritten word recognizer using spatial representation, space displacement neural networks and hidden Markov models. </title> <booktitle> In Advances in Neural Information Processing Systems 6, </booktitle> <address> San Mateo CA, 1994. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: The use of shared weights also reduces the number of parameters in the system aiding generalization. Convolutional networks have been successfully applied to character recognition <ref> [24, 22, 23, 5, 3] </ref>. A typical convolutional network is shown in figure 5 [24]. The network consists of a set of layers each of which contains one or more planes. Approximately centered and normalized images enter at the input layer.
Reference: [4] <author> J.L. Blue, G.T. Candela, P.J. Grother, R. Chellappa, and C.L. Wilson. </author> <title> Evaluation of pattern classifiers for fingerprint and OCR applications. </title> <journal> Pattern Recognition, </journal> <volume> 27(4):485501, </volume> <month> April </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The requirement for reliable personal identification in computerized access control has resulted in an in creased interest in biometrics 1 . Biometrics being investigated include fingerprints <ref> [4] </ref>, speech [7], signature dynamics [36], and face recognition [8]. Sales of identity verification products exceed $100 million [29]. Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity.
Reference: [5] <author> L. Bottou, C. Cortes, J.S. Denker, H. Drucker, I. Guyon, L. Jackel, Y. Le Cun, U. Muller, E. Sackinger, P. Simard, and V.N. Vapnik. </author> <title> Comparison of classifier methods: A case study in handwritten digit recognition. </title> <booktitle> In Proceedings of the International Conference on Pattern Recognition, </booktitle> <address> Los Alamitos, CA, 1994. </address> <publisher> IEEE Computer Society Press. </publisher>
Reference-contexts: The use of shared weights also reduces the number of parameters in the system aiding generalization. Convolutional networks have been successfully applied to character recognition <ref> [24, 22, 23, 5, 3] </ref>. A typical convolutional network is shown in figure 5 [24]. The network consists of a set of layers each of which contains one or more planes. Approximately centered and normalized images enter at the input layer.
Reference: [6] <author> R. Brunelli and T. Poggio. </author> <title> Face recognition: Features versus templates. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <volume> 15(10):10421052, </volume> <month> October </month> <year> 1993. </year>
Reference-contexts: Brunelli and Poggio <ref> [6] </ref> compute a set of geometrical features such as nose width and length, mouth position, and chin shape. They report a 90% recognition rate on a database of 47 people. However, they show that a simple template matching scheme provides 100% recognition for the same database. <p> However, it may be limited because optimal performance requires a high degree of correlation between the pixel intensities of the training and test images. This limitation has been addressed by using extensive preprocessing to normalize the images. 3.3 Template Matching Template matching methods such as <ref> [6] </ref> operate by performing direct correlation of image segments. Template matching is only effective when the query images have the same scale, orientation, and illumination as the training images [9]. 3.4 Graph Matching Another approach to face recognition is the well known method of Graph Matching. <p> The various facial features could be ranked according to their importance in recognizing faces and separate modules could be introduced for various parts of the face, e.g. the eye region, the nose region, and the mouth region (Brunelli and Poggio <ref> [6] </ref> obtain very good performance using a simple template matching strategy on precisely these regions). 4. An ensemble of recognizers could be used.
Reference: [7] <author> D. K. Burton. </author> <title> Text-dependent speaker verification using vector quantization source coding. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing, </journal> <volume> 35(2):133, </volume> <year> 1987. </year>
Reference-contexts: 1 Introduction The requirement for reliable personal identification in computerized access control has resulted in an in creased interest in biometrics 1 . Biometrics being investigated include fingerprints [4], speech <ref> [7] </ref>, signature dynamics [36], and face recognition [8]. Sales of identity verification products exceed $100 million [29]. Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity.
Reference: [8] <author> R. Chellappa, C.L. Wilson, and S. Sirohey. </author> <title> Human and machine recognition of faces: A survey. </title> <booktitle> Proceedings of the IEEE, </booktitle> <address> 83(5):705740, </address> <year> 1995. </year>
Reference-contexts: 1 Introduction The requirement for reliable personal identification in computerized access control has resulted in an in creased interest in biometrics 1 . Biometrics being investigated include fingerprints [4], speech [7], signature dynamics [36], and face recognition <ref> [8] </ref>. Sales of identity verification products exceed $100 million [29]. Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity. <p> We want to identify particular people in real-time (e.g. in a security monitoring system, location tracking system, etc.), or we want to allow access to a group of people and deny access to all others (e.g. access to a building, computer, etc.) <ref> [8] </ref>. Multiple images per person are often available for training and real-time recognition is required. In this paper, we are primarily interested in the second case 2 . We are interested in recognition with varying facial detail, expression, pose, etc. <p> The system used extensive preprocessing for head location, feature detection, and normalization for the geometry of the face, translation, lighting, contrast, rotation, and scale. 4 A mugshot database typically contains side views where the performance of feature point methods is known to improve <ref> [8] </ref>. 4 Swets and Weng [42] present a method of selecting discriminant eigenfeatures using multi-dimensional linear discriminant analysis. They present methods for determining the Most Expressive Features (MEF) and the Most Discriminatory Features (MDF).
Reference: [9] <author> Ingemar J. Cox, Joumana Ghosn, and Peter N. Yianilos. </author> <title> Feature-based face recognition using mixture-distance. In Computer Vision and Pattern Recognition. </title> <publisher> IEEE Press, </publisher> <year> 1996. </year>
Reference-contexts: They report a 90% recognition rate on a database of 47 people. However, they show that a simple template matching scheme provides 100% recognition for the same database. Cox et al. <ref> [9] </ref> have recently introduced a mixture-distance technique which achieves a recognition rate of 95% using a query database of 95 images from a total of 685 individuals. Each face is represented by 30 manually extracted distances. 3 ... <p> Template matching is only effective when the query images have the same scale, orientation, and illumination as the training images <ref> [9] </ref>. 3.4 Graph Matching Another approach to face recognition is the well known method of Graph Matching. In [21], Lades et al. present a Dynamic Link Architecture for distortion invariant object recognition which employs elastic graph matching to find the closest stored graph.
Reference: [10] <author> David DeMers and G.W. Cottrell. </author> <title> Non-linear dimensionality reduction. </title> <editor> In S.J. Hanson, J.D. Cowan, and C. Lee Giles, editors, </editor> <booktitle> Advances in Neural Information Processing Systems 5, </booktitle> <pages> pages 580587, </pages> <address> San Mateo, CA, 1993. </address> <publisher> Morgan Kaufmann Publishers. </publisher>
Reference-contexts: The recognition time for this system was not given. 3.5 Neural Network Approaches Much of the present literature on face recognition with neural networks presents results with only a small number of classes (often below 20). We briefly describe a couple of approaches. In <ref> [10] </ref> the first 50 principal components of the images are extracted and reduced to 5 dimensions using an autoassociative neural network. The resulting representation is classified using a standard multi-layer perceptron.
Reference: [11] <author> H. Drucker, C. Cortes, L. Jackel, Y. Le Cun, and V.N. Vapnik. </author> <title> Boosting and other ensemble methods. </title> <booktitle> Neural Computation, </booktitle> <address> 6:12891301, </address> <year> 1994. </year>
Reference-contexts: An ensemble of recognizers could be used. These could be combined via simple methods such as a linear combination based on the performance of each network, or via a gating network and the Expectation-Maximization algorithm <ref> [16, 11] </ref>.
Reference: [12] <author> K. Fukunaga. </author> <title> Introduction to Statistical Pattern Recognition, Second Edition. </title> <publisher> Academic Press, </publisher> <address> Boston, MA, </address> <year> 1990. </year>
Reference-contexts: above node doubling strategy 5 . 5 This assumes that the topological order is optimal prior to each doubling step. 8 4.4 Karhunen-Lo OE eve Transform The optimal linear method 6 for reducing redundancy in a dataset is the Karhunen-LoOEeve (KL) transform or eigenvector expansion via Principle Components Analysis (PCA) <ref> [12] </ref>. PCA generates a set of orthogonal axes of projections known as the principal components, or the eigenvectors, of the input data distribution in the order of decreasing variance.
Reference: [13] <author> S. Haykin. </author> <title> Neural Networks, A Comprehensive Foundation. </title> <publisher> Macmillan, </publisher> <address> New York, NY, </address> <year> 1994. </year>
Reference-contexts: The network is trained with the usual backpropagation gradient-descent procedure <ref> [13] </ref>. A connection strategy can be used to reduce the number of weights in the network. <p> The number of planes in each layer, the dimensions of the planes, and the dimensions of the receptive fields are shown in table 1. The network was trained with backpropagation <ref> [13] </ref> for a total of 20,000 updates. Weights 11 in the network were updated after each pattern presentation, as opposed to batch update where weights are only updated once per pass through the training set. All inputs were normalized to lie in the range -1 to 1. <p> Weights were initialized on a node by node basis as uniformly distributed random numbers in the range (2:4=F i ; 2:4=F i ) where F i is the fan-in of neuron i <ref> [13] </ref>. Target outputs were -0.8 and 0.8 using the tanh output activation function 7 . The quadratic cost function was used.
Reference: [14] <author> S. Haykin. </author> <type> Personal communication, </type> <year> 1996. </year>
Reference-contexts: Note that the best performing KL parameters were used while the best performing SOM parameters were not. We note that it may be considered fairer to compare against an MLP with multiple hidden layers <ref> [14] </ref>, however selection of the appropriate number of nodes in each layer is difficult (e.g. we have tried a network with two hidden layers containing 100 and 50 nodes respectively which resulted in an error rate of 90%). 7.
Reference: [15] <author> D.H. Hubel and T.N. Wiesel. </author> <title> Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex. </title> <journal> Journal of Physiology (London), </journal> <volume> 160:106154, </volume> <year> 1962. </year>
Reference-contexts: Approximately centered and normalized images enter at the input layer. Each unit in a plane receives input from a small neighborhood in the planes of the previous layer. The idea of connecting units to local receptive fields dates back to the 1960s with the perceptron and Hubel and Wiesel's <ref> [15] </ref> discovery of locally sensitive, orientation-selective neurons in the cat's visual system [23]. The weights forming the receptive field for a plane are forced to be equal at all points in the plane.
Reference: [16] <author> R.A. Jacobs. </author> <title> Methods for combining experts' probability assessments. </title> <booktitle> Neural Computation, </booktitle> <address> 7:867888, </address> <year> 1995. </year>
Reference-contexts: An ensemble of recognizers could be used. These could be combined via simple methods such as a linear combination based on the performance of each network, or via a gating network and the Expectation-Maximization algorithm <ref> [16, 11] </ref>.
Reference: [17] <author> T. Kanade. </author> <title> Picture Processing by Computer Complex and Recognition of Human Faces. </title> <type> PhD thesis, </type> <institution> Kyoto University, </institution> <year> 1973. </year>
Reference-contexts: The images are greyscale with a resolution of 92 fi 112. 3 Related Work 3.1 Geometrical Features Many people have explored geometrical feature based methods for face recognition. Kanade <ref> [17] </ref> presented an automatic feature extraction method based on ratios of distances and reported a recognition rate of be 2 However, we have not performed any experiments where we have required the system to reject people that are not in a select group (important, for example, when allowing access to a
Reference: [18] <author> Hajime Kita and Yoshikazu Nishikawa. </author> <title> Neural network model of tonotopic map formation based on the temporal theory of auditory sensation. </title> <booktitle> In Proceedings of the World Congress on Neural Networks, </booktitle> <volume> WCNN 93, volume II, </volume> <pages> pages 413418, </pages> <address> Hillsdale, NJ, 1993. </address> <publisher> Lawrence Erlbaum. </publisher>
Reference-contexts: Examples of maps in the nervous system are retinotopic maps in the visual cortex [31], tonotopic maps in the auditory cortex <ref> [18] </ref>, and maps from the skin onto the somatosensoric cortex [32]. The self-organizing map, or SOM, introduced by Teuvo Kohonen [20, 19] is an unsupervised learning process which learns the distribution of a set of patterns without any class information.
Reference: [19] <author> T. Kohonen. </author> <title> The self-organizing map. </title> <booktitle> Proceedings of the IEEE, </booktitle> <address> 78:14641480, </address> <year> 1990. </year>
Reference-contexts: Examples of maps in the nervous system are retinotopic maps in the visual cortex [31], tonotopic maps in the auditory cortex [18], and maps from the skin onto the somatosensoric cortex [32]. The self-organizing map, or SOM, introduced by Teuvo Kohonen <ref> [20, 19] </ref> is an unsupervised learning process which learns the distribution of a set of patterns without any class information. A pattern is projected from an input space to a position in the map information is coded as the location of an activated node.
Reference: [20] <author> T. Kohonen. </author> <title> Self-Organizing Maps. </title> <publisher> Springer-Verlag, </publisher> <address> Berlin, Germany, </address> <year> 1995. </year>
Reference-contexts: Examples of maps in the nervous system are retinotopic maps in the visual cortex [31], tonotopic maps in the auditory cortex [18], and maps from the skin onto the somatosensoric cortex [32]. The self-organizing map, or SOM, introduced by Teuvo Kohonen <ref> [20, 19] </ref> is an unsupervised learning process which learns the distribution of a set of patterns without any class information. A pattern is projected from an input space to a position in the map information is coded as the location of an activated node. <p> image sample classification, for example, there may be a very large number of classes in which the transition from one class to the next is practically continuous (making it difficult to define hard class boundaries). 4.3.2 Algorithm We give a brief description of the SOM algorithm, for more details see <ref> [20] </ref>. The SOM defines a mapping from an input space R n onto a topologically ordered set of nodes, usually in a lower dimensional space. An example of a two-dimensional SOM is shown in figure 4. <p> A widely applied neighbourhood function is: h ci = ff (t) exp 2 ! where ff (t) is a scalar valued learning rate and oe (t) defines the width of the kernel. They are generally both monotonically decreasing with time <ref> [20] </ref>. The use of the neighbourhood function means that nodes which are topographically close in the SOM structure are moved towards the input pattern along with the winning node. This creates a smoothing effect which leads to a global ordering of the map. <p> Note that oe (t) should not be reduced too far as the map will lose its topographical order if neighbouring nodes are not updated along with the closest node. The SOM can be considered a non-linear projection of the probability density, p (x) <ref> [20] </ref>. size to h ci (t 3 ) over time. 4.3.3 Improving the Basic SOM The original self-organizing map is computationally expensive due to: 1. In the early stages of learning, many nodes are adjusted in a correlated manner. <p> We also experimented with training a standard multi-layer perceptron for comparison. 5.1 Simulation Details In this section we give the details of one of the best performing systems. For the SOM, training is split into two phases as recommended by Kohonen <ref> [20] </ref> an ordering phase, and a fine-adjustment phase. 100,000 updates are performed in the first phase, and 50,000 in the second. In the first phase, the neighborhood radius starts at two-thirds of the size of the map and reduces linearly to 1.
Reference: [21] <author> Martin Lades, Jan C. Vorbruggen, Joachim Buhmann, Jorg Lange, Christoph von der Malsburg, Rolf P. Wurtz, and Wolfgang Konen. </author> <title> Distortion invariant object recognition in the dynamic link architecture. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 42(3):300 311, </volume> <year> 1993. </year>
Reference-contexts: Template matching is only effective when the query images have the same scale, orientation, and illumination as the training images [9]. 3.4 Graph Matching Another approach to face recognition is the well known method of Graph Matching. In <ref> [21] </ref>, Lades et al. present a Dynamic Link Architecture for distortion invariant object recognition which employs elastic graph matching to find the closest stored graph.
Reference: [22] <author> Y. Le Cun. </author> <title> Generalisation and network design strategies. </title> <type> Technical Report CRG-TR-89-4, </type> <institution> Department of Computer Science, University of Toronto, </institution> <year> 1989. </year>
Reference-contexts: The use of shared weights also reduces the number of parameters in the system aiding generalization. Convolutional networks have been successfully applied to character recognition <ref> [24, 22, 23, 5, 3] </ref>. A typical convolutional network is shown in figure 5 [24]. The network consists of a set of layers each of which contains one or more planes. Approximately centered and normalized images enter at the input layer.
Reference: [23] <author> Y. Le Cun and Yoshua Bengio. </author> <title> Convolutional networks for images, speech, and time series. </title> <editor> In Michael A. Arbib, editor, </editor> <booktitle> The Handbook of Brain Theory and Neural Networks, </booktitle> <pages> pages 255258. </pages> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1995. </year>
Reference-contexts: Additionally, for MLP networks with the 2D images as input, there is no invariance to translation or local deformation of the images <ref> [23] </ref>. Convolutional networks (CN) incorporate constraints and achieve some degree of shift and deformation invariance using three ideas: local receptive fields, shared weights, and spatial subsampling. The use of shared weights also reduces the number of parameters in the system aiding generalization. <p> The use of shared weights also reduces the number of parameters in the system aiding generalization. Convolutional networks have been successfully applied to character recognition <ref> [24, 22, 23, 5, 3] </ref>. A typical convolutional network is shown in figure 5 [24]. The network consists of a set of layers each of which contains one or more planes. Approximately centered and normalized images enter at the input layer. <p> The idea of connecting units to local receptive fields dates back to the 1960s with the perceptron and Hubel and Wiesel's [15] discovery of locally sensitive, orientation-selective neurons in the cat's visual system <ref> [23] </ref>. The weights forming the receptive field for a plane are forced to be equal at all points in the plane.
Reference: [24] <author> Y. Le Cun, B. Boser, J.S. Denker, D. Henderson, R. Howard, W. Hubbard, and L. Jackel. </author> <title> Handwritten digit recognition with a backpropagation neural network. </title> <editor> In D. Touretzky, editor, </editor> <booktitle> Advances in Neural Information Processing Systems 2, </booktitle> <pages> pages 396404. </pages> <publisher> Morgan Kaufmann, </publisher> <address> San Mateo, CA, </address> <year> 1990. </year>
Reference-contexts: The use of shared weights also reduces the number of parameters in the system aiding generalization. Convolutional networks have been successfully applied to character recognition <ref> [24, 22, 23, 5, 3] </ref>. A typical convolutional network is shown in figure 5 [24]. The network consists of a set of layers each of which contains one or more planes. Approximately centered and normalized images enter at the input layer. <p> The use of shared weights also reduces the number of parameters in the system aiding generalization. Convolutional networks have been successfully applied to character recognition [24, 22, 23, 5, 3]. A typical convolutional network is shown in figure 5 <ref> [24] </ref>. The network consists of a set of layers each of which contains one or more planes. Approximately centered and normalized images enter at the input layer. Each unit in a plane receives input from a small neighborhood in the planes of the previous layer. <p> The network is trained with the usual backpropagation gradient-descent procedure [13]. A connection strategy can be used to reduce the number of weights in the network. For example, with reference to figure 5, Le Cun et al. <ref> [24] </ref> connect the feature maps in the second convolutional layer only to 1 or 2 of the maps in the first subsampling layer (the connection strategy was chosen manually). 6 In the least mean squared error sense. 9 5 System Details The system we have used for face recognition is a <p> The connection strategy used here is similar to that used by Le Cun et al. <ref> [24] </ref> for character recognition. However, as opposed to the manual connection strategy used by Le Cun et al., the connections between layers 2 and 3 are chosen randomly. <p> It is expected that an optimized version could be significantly faster. 9 Further Research We can identify the following avenues for improving performance: 21 1. More careful selection of the convolutional network architecture, e.g. by using the Optimal Brain Damage algorithm [25] as used by Le Cun et al. <ref> [24] </ref> to improve generalization and speedup hand written digit recognition. 2. More precise normalization of the images to account for translation, rotation, and scale changes. Any normalization would be limited by the desired recognition speed. 3.
Reference: [25] <author> Y. Le Cun, J.S. Denker, and S.A. Solla. </author> <title> Optimal Brain Damage. </title> <editor> In D.S. Touretzky, editor, </editor> <booktitle> Neural Information Processing Systems, </booktitle> <volume> volume 2, </volume> <pages> pages 598605, </pages> <address> San Mateo, 1990. (Denver 1989), </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: It is expected that an optimized version could be significantly faster. 9 Further Research We can identify the following avenues for improving performance: 21 1. More careful selection of the convolutional network architecture, e.g. by using the Optimal Brain Damage algorithm <ref> [25] </ref> as used by Le Cun et al. [24] to improve generalization and speedup hand written digit recognition. 2. More precise normalization of the images to account for translation, rotation, and scale changes. Any normalization would be limited by the desired recognition speed. 3.
Reference: [26] <author> Todd K. Leen. </author> <title> From data distributions to regularization in invariant learning. </title> <booktitle> Neural Computation, </booktitle> <address> 3(1):135143, </address> <year> 1991. </year>
Reference-contexts: Invariance to a group of desired transformations could be enhanced with the addition of pseudo-data to the training database i.e. the addition of new examples created from the current examples using translation, etc. Leen <ref> [26] </ref> shows that adding pseudo-data can be equivalent to adding a regularizer to the cost function where the regularizer penalizes changes in the output when the input goes under a transformation for which invariance is desired. 10 Conclusions We have presented a fast, automatic system for face recognition which is a
Reference: [27] <author> Stephen P. Luttrell. </author> <title> Hierarchical self-organizing networks. </title> <booktitle> In Proceedings of the 1st IEE Conference on Artificial Neural Networks, </booktitle> <pages> pages 26, </pages> <address> London, UK, </address> <year> 1989. </year> <journal> British Neural Network Society. </journal>
Reference-contexts: In the early stages of learning, many nodes are adjusted in a correlated manner. Luttrel <ref> [27] </ref> proposed a method, which is used here, that starts by learning in a small network, and doubles the size of the network periodically during training. When doubling, new nodes are inserted between the current nodes.
Reference: [28] <author> D. Marr. </author> <title> Vision. </title> <editor> W. H. </editor> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1982. </year>
Reference-contexts: for automatic location of feature points do not provide a high degree of accuracy and require considerable computational capacity [41]. 3.2 Eigenfaces High-level recognition tasks are typically modeled with many stages of processing as in the Marr paradigm of progressing from images to surfaces to three-dimensional models to matched models <ref> [28] </ref>. However, Turk and Pentland [43] argue that it is likely that there is also a recognition process based on low-level, two-dimensional image processing.
Reference: [29] <author> B. Miller. </author> <title> Vital signs of identity. </title> <journal> IEEE Spectrum, </journal> <pages> pages 2230, </pages> <month> February </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The requirement for reliable personal identification in computerized access control has resulted in an in creased interest in biometrics 1 . Biometrics being investigated include fingerprints [4], speech [7], signature dynamics [36], and face recognition [8]. Sales of identity verification products exceed $100 million <ref> [29] </ref>. Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity.
Reference: [30] <author> B. Moghaddam and A. Pentland. </author> <title> Face recognition using view-based and modular eigenspaces. In Automatic Systems for the Identification and Inspection of Humans, </title> <booktitle> SPIE, </booktitle> <volume> volume 2257, </volume> <year> 1994. </year>
Reference-contexts: It is difficult to draw broad conclusions as many of the images of the same people look very similar, and the database has accurate registration and alignment <ref> [30] </ref>. In Moghaddam and Pentland [30], very good results are reported with the FERET database only one mistake was made in classifying 150 frontal view images. <p> It is difficult to draw broad conclusions as many of the images of the same people look very similar, and the database has accurate registration and alignment <ref> [30] </ref>. In Moghaddam and Pentland [30], very good results are reported with the FERET database only one mistake was made in classifying 150 frontal view images. <p> They present methods for determining the Most Expressive Features (MEF) and the Most Discriminatory Features (MDF). We are not currently aware of the availability of results which are comparable with those of eigenfaces (e.g. on the FERET database as in Moghaddam and Pentland <ref> [30] </ref>). In summary, it appears that eigenfaces is a fast, simple, and practical algorithm. However, it may be limited because optimal performance requires a high degree of correlation between the pixel intensities of the training and test images.
Reference: [31] <author> K. Obermayer, Gary G. Blasdel, and K. Schulten. </author> <title> A neural network model for the formation and for the spatial structure of retinotopic maps, orientation and ocular dominance columns. </title> <editor> In Teuvo Kohonen, Kai Makisara, Olli Simula, and Jari Kangas, editors, </editor> <booktitle> Artificial Neural Networks, </booktitle> <pages> pages 505511, </pages> <address> Amsterdam, Netherlands, 1991. </address> <publisher> Elsevier. </publisher>
Reference-contexts: Examples of maps in the nervous system are retinotopic maps in the visual cortex <ref> [31] </ref>, tonotopic maps in the auditory cortex [18], and maps from the skin onto the somatosensoric cortex [32]. The self-organizing map, or SOM, introduced by Teuvo Kohonen [20, 19] is an unsupervised learning process which learns the distribution of a set of patterns without any class information.
Reference: [32] <author> K. Obermayer, H. Ritter, and K. Schulten. </author> <title> Large-scale simulation of a self-organizing neural network: Formation of a soma-totopic map. </title> <editor> In R. Eckmiller, G. Hartmann, and G. Hauske, editors, </editor> <booktitle> Parallel Processing in Neural Systems and Computers, </booktitle> <pages> pages 7174, </pages> <address> Amsterdam, Netherlands, 1990. </address> <publisher> North-Holland. </publisher>
Reference-contexts: Examples of maps in the nervous system are retinotopic maps in the visual cortex [31], tonotopic maps in the auditory cortex [18], and maps from the skin onto the somatosensoric cortex <ref> [32] </ref>. The self-organizing map, or SOM, introduced by Teuvo Kohonen [20, 19] is an unsupervised learning process which learns the distribution of a set of patterns without any class information.
Reference: [33] <author> A. Pentland, B. Moghaddam, and T. Starner. </author> <title> View-based and modular eigenspaces for face recognition. </title> <booktitle> In IEEE Conference on Computer Vision and Pattern Recognition, </booktitle> <year> 1994. </year>
Reference-contexts: Scale is renormalized to the eigenface size based on an estimate of the head size. The middle of the faces is accentuated, reducing any negative affect of changing hairstyle and backgrounds. In Pentland et al. <ref> [34, 33] </ref> good results are reported on a large database (95% recognition of 200 people from a database of 3,000). It is difficult to draw broad conclusions as many of the images of the same people look very similar, and the database has accurate registration and alignment [30].
Reference: [34] <author> A. Pentland, T. Starner, N. Etcoff, A. Masoiu, O. Oliyide, and M. Turk. </author> <title> Experiments with eigenfaces. </title> <booktitle> In Looking at People Workshop, International Joint Conference on Artificial Intelligence 1993, </booktitle> <address> Chamberry, France, </address> <year> 1993. </year>
Reference-contexts: We can identify at least two broad categories of face recognition systems: 1. We want to find a person within a large database of faces (e.g. in a police database). These systems typically return a list of the most likely people in the database <ref> [34] </ref>. Often only one image is available per person. It is usually not necessary for recognition to be done in real-time. 2. <p> Scale is renormalized to the eigenface size based on an estimate of the head size. The middle of the faces is accentuated, reducing any negative affect of changing hairstyle and backgrounds. In Pentland et al. <ref> [34, 33] </ref> good results are reported on a large database (95% recognition of 200 people from a database of 3,000). It is difficult to draw broad conclusions as many of the images of the same people look very similar, and the database has accurate registration and alignment [30].
Reference: [35] <author> Perret, </author> <title> Rolls, and Caan. Visual neurones responsive to faces in the monkey temporal cortex. Experimental Brain Research, </title> <address> 47:329342, </address> <year> 1982. </year>
Reference-contexts: Their argument is based on the early development and extreme rapidity of face recognition in humans, and on physiological experiments in monkey cortex which claim to have isolated neurons that respond selectively to faces <ref> [35] </ref>. However, it is not clear that these experiments exclude the sole operation of the Marr paradigm. Turk and Pentland [43] present a face recognition scheme in which face images are projected onto the principal components of the original set of training images.
Reference: [36] <author> Y.Y. Qi and B.R. Hunt. </author> <title> Signature verification using global and grid features. </title> <journal> Pattern Recognition, </journal> <volume> 27(12):16211629, </volume> <month> December </month> <year> 1994. </year>
Reference-contexts: 1 Introduction The requirement for reliable personal identification in computerized access control has resulted in an in creased interest in biometrics 1 . Biometrics being investigated include fingerprints [4], speech [7], signature dynamics <ref> [36] </ref>, and face recognition [8]. Sales of identity verification products exceed $100 million [29]. Face recognition has the benefit of being a passive, non-intrusive system for verifying personal identity.
Reference: [37] <author> Henry A. Rowley, Shumeet Baluja, and T. Kanade. </author> <title> Human face detection in visual scenes. </title> <type> Technical Report CMU-CS-95-158, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <address> Pittsburgh, PA, </address> <month> July </month> <year> 1995. </year>
Reference-contexts: We are interested in rapid classification and hence we do not assume that time is available for extensive preprocessing and normalization. Good algorithms for locating faces in images can be found in <ref> [43, 40, 37] </ref>. The remainder of this paper is organized as follows. The data we used is presented in section 2 and related work with this and other databases is discussed in section 3. The components and details of our system are described in sections 4 and 5 respectively. <p> Figure 16 shows the activation of the nodes in a sample convolutional network for a particular test image. ... ... most important for classification. Using the method of Baluja and Pomerleau as described in <ref> [37] </ref>, each of the input planes to the convolutional network was divided into 2 fi 2 segments (the input planes are 23 fi 28). Each of 168 (12 fi 14) segments was replaced with random noise, one segment at a time. The test performance was calculated at each step.
Reference: [38] <author> F.S. Samaria. </author> <title> Face Recognition using Hidden Markov Models. </title> <type> PhD thesis, </type> <institution> Trinity College, University of Cambridge, Cam-bridge, </institution> <year> 1994. </year>
Reference-contexts: Samaria also performed extensive tests using the popular eigenfaces algorithm [43] on the ORL database and reported a best error rate of around 10% when the number of eigenfaces was between 175 and 199. We implemented the eigenfaces algorithm and also observed around 10% error. In <ref> [38] </ref> Samaria extends the top-down HMM of [39] with pseudo two-dimensional HMMs. The error rate reduces to 5% at the expense of high computational complexity a single classification takes four minutes on a Sun Sparc II.
Reference: [39] <author> F.S. Samaria and A.C. Harter. </author> <title> Parameterisation of a stochastic model for human face identification. </title> <booktitle> In Proceedings of the 2nd IEEE workshop on Applications of Computer Vision, </booktitle> <address> Sarasota, Florida, </address> <year> 1994. </year>
Reference-contexts: There are 20 people in the database. A hierarchical neural network which is grown automatically and not trained with gradient-descent was used for face recognition by Weng and Huang [44]. They report good results for discrimination of ten distinctive subjects. 5 3.6 The ORL Database In <ref> [39] </ref> a HMM-based approach is used for classification of the ORL database images. The best model resulted in a 13% error rate. <p> We implemented the eigenfaces algorithm and also observed around 10% error. In [38] Samaria extends the top-down HMM of <ref> [39] </ref> with pseudo two-dimensional HMMs. The error rate reduces to 5% at the expense of high computational complexity a single classification takes four minutes on a Sun Sparc II. Samaria notes that although an increased recognition rate was achieved the segmentation obtained with the pseudo two-dimensional HMMs appeared quite erratic.
Reference: [40] <author> Kah-Kay Sung and T. Poggio. </author> <title> Learning human face detection in cluttered scenes. </title> <booktitle> In Computer Analysis of Images and Patterns, </booktitle> <pages> pages 432439, </pages> <year> 1995. </year>
Reference-contexts: We are interested in rapid classification and hence we do not assume that time is available for extensive preprocessing and normalization. Good algorithms for locating faces in images can be found in <ref> [43, 40, 37] </ref>. The remainder of this paper is organized as follows. The data we used is presented in section 2 and related work with this and other databases is discussed in section 3. The components and details of our system are described in sections 4 and 5 respectively.
Reference: [41] <author> K. Sutherland, D. Renshaw, and P.B. Denyer. </author> <title> Automatic face recognition. </title> <booktitle> In First International Conference on Intelligent Systems Engineering, </booktitle> <pages> pages 2934, </pages> <address> Piscataway, NJ, 1992. </address> <publisher> IEEE Press. </publisher>
Reference-contexts: For other applications, automatic identification of these points would be required, and the resulting system would be dependent on the accuracy of the feature location algorithm. Current algorithms for automatic location of feature points do not provide a high degree of accuracy and require considerable computational capacity <ref> [41] </ref>. 3.2 Eigenfaces High-level recognition tasks are typically modeled with many stages of processing as in the Marr paradigm of progressing from images to surfaces to three-dimensional models to matched models [28].
Reference: [42] <author> D.L. Swets and J.J. Weng. </author> <title> Using discriminant eigenfeatures for image retrieval. </title> <journal> IEEE Transactions on Pattern Analysis and Machine Intelligence, </journal> <note> to appear, </note> <year> 1996. </year>
Reference-contexts: The system used extensive preprocessing for head location, feature detection, and normalization for the geometry of the face, translation, lighting, contrast, rotation, and scale. 4 A mugshot database typically contains side views where the performance of feature point methods is known to improve [8]. 4 Swets and Weng <ref> [42] </ref> present a method of selecting discriminant eigenfeatures using multi-dimensional linear discriminant analysis. They present methods for determining the Most Expressive Features (MEF) and the Most Discriminatory Features (MDF).
Reference: [43] <author> M. Turk and A. Pentland. </author> <title> Eigenfaces for recognition. </title> <journal> J. of Cognitive Neuroscience, </journal> <volume> 3:7186, </volume> <year> 1991. </year>
Reference-contexts: We are interested in rapid classification and hence we do not assume that time is available for extensive preprocessing and normalization. Good algorithms for locating faces in images can be found in <ref> [43, 40, 37] </ref>. The remainder of this paper is organized as follows. The data we used is presented in section 2 and related work with this and other databases is discussed in section 3. The components and details of our system are described in sections 4 and 5 respectively. <p> However, Turk and Pentland <ref> [43] </ref> argue that it is likely that there is also a recognition process based on low-level, two-dimensional image processing. <p> However, it is not clear that these experiments exclude the sole operation of the Marr paradigm. Turk and Pentland <ref> [43] </ref> present a face recognition scheme in which face images are projected onto the principal components of the original set of training images. The resulting eigenfaces are classified by comparison with known individuals. <p> They report good results for discrimination of ten distinctive subjects. 5 3.6 The ORL Database In [39] a HMM-based approach is used for classification of the ORL database images. The best model resulted in a 13% error rate. Samaria also performed extensive tests using the popular eigenfaces algorithm <ref> [43] </ref> on the ORL database and reported a best error rate of around 10% when the number of eigenfaces was between 175 and 199. We implemented the eigenfaces algorithm and also observed around 10% error. In [38] Samaria extends the top-down HMM of [39] with pseudo two-dimensional HMMs. <p> We implemented two versions of the eigenfaces algorithm the first version creates vectors for each class in the training set by averaging the results of the eigenface representation over all images for the same person. This corresponds to the algorithm as described by Turk and Pentland <ref> [43] </ref>. However, we found that using separate training vectors for each training image resulted in better performance. We found that using between 40 to 100 eigenfaces resulted in similar performance. <p> Substitution of the Karhunen-LoOEeve transform for the self-organizing map produced similar but slightly worse results. The method is capable of rapid classification, requires only fast, approximate normalization and preprocessing, and consistently exhibits better classification performance than the eigenfaces approach <ref> [43] </ref> on the database considered as the number of images per person in the training database is varied from 1 to 5. With 5 images per person the proposed method and eigenfaces result in 3.8% and 10.5% error respectively.
Reference: [44] <author> J. Weng, N. Ahuja, and T.S. Huang. </author> <title> Learning recognition and segmentation of 3-d objects from 2-d images. </title> <booktitle> In Proceedings of the International Conference on Computer Vision, </booktitle> <volume> ICCV 93, </volume> <pages> pages 121128, </pages> <year> 1993. </year>
Reference-contexts: There are 20 people in the database. A hierarchical neural network which is grown automatically and not trained with gradient-descent was used for face recognition by Weng and Huang <ref> [44] </ref>. They report good results for discrimination of ten distinctive subjects. 5 3.6 The ORL Database In [39] a HMM-based approach is used for classification of the ORL database images. The best model resulted in a 13% error rate.
Reference: [45] <author> Laurenz Wiskott, Jean-Marc Fellous, Norbert Kruger, and Christoph von der Malsburg. </author> <title> Face recognition and gender determination. </title> <booktitle> In Proceedings of the International Workshop on Automatic Face and Gesture Recognition, </booktitle> <address> Zurich, </address> <year> 1995. </year> <month> 24 </month>
Reference-contexts: The matching process is computationally expensive, taking roughly 25 seconds to compare an image with 87 stored objects when using a parallel machine with 23 transputers. Wiskott et al. <ref> [45] </ref> use an updated version of the technique and compare 300 faces against 300 different faces of the same people taken from the FERET database. They report a recognition rate of 97.3%.
References-found: 45

