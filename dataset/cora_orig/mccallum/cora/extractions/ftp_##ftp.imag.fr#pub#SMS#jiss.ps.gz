URL: ftp://ftp.imag.fr/pub/SMS/jiss.ps.gz
Refering-URL: http://www-lmc.imag.fr/SMS/preprints.html
Root-URL: http://www.imag.fr
Title: Wavelets in Statistics: A Review  
Author: A. Antoniadis 
Keyword: and phrases: Wavelets, multiresolution analysis, nonparametric curve estimation, density estimation, regression, model selection, orthogonal series, thresholding, cross-validation, shrinkage, denoising.  
Note: Research supported by the IDOPT project (CNRS-INRIA-UJF-INPG).  
Date: February 1997  
Address: BP 53 38041 Grenoble Cedex 9 France  
Affiliation: Laboratoire IMAG-LMC, University Joseph Fourier  
Abstract:  
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Abramovich, F., Sapatinas, T. and Silverman, B. W. </author> <year> (1997). </year> <title> Wavelet thresholding via a Bayesian approach. </title> <institution> Technical report , University of Bristol, </institution> <address> England. </address> <month> 27 </month>
Reference-contexts: For such functions it is known that Fourier-based methods give very slow convergence rates (ff = 1). Therefore, wavelets are optimal bases for compressing and recovering functions in such spaces. In many practical situations, the functions involved are only defined on a compact interval, such as the interval <ref> [0; 1] </ref>, and to apply wavelets requires some modifications. Cohen et al. [25] have obtained the necessary boundary corrections to retain orthonor-mality, and their wavelets on [0; 1] also constitute unconditional bases for the Besov spaces on the interval with an associated multiresolution analysis structure. <p> In many practical situations, the functions involved are only defined on a compact interval, such as the interval <ref> [0; 1] </ref>, and to apply wavelets requires some modifications. Cohen et al. [25] have obtained the necessary boundary corrections to retain orthonor-mality, and their wavelets on [0; 1] also constitute unconditional bases for the Besov spaces on the interval with an associated multiresolution analysis structure. <p> Hence, for the above range of the parameters, the Besov space B s pq (R) can be defined as B s pq (R) = fg 2 L p (R ); J spq (g) &lt; 1g. An important fact is that Besov spaces can also be defined on the interval <ref> [0; 1] </ref> (see Triebel [81]). For the considered range of parameters p; q; s all Besov spaces over R and 6 [0; 1] are continuously embedded in L 1;loc , hence, consist of regular distributions only, and elements of B s pq ([0; 1]) are obtained by taking the usual pointwise <p> An important fact is that Besov spaces can also be defined on the interval <ref> [0; 1] </ref> (see Triebel [81]). For the considered range of parameters p; q; s all Besov spaces over R and 6 [0; 1] are continuously embedded in L 1;loc , hence, consist of regular distributions only, and elements of B s pq ([0; 1]) are obtained by taking the usual pointwise restriction on [0; 1] of a function defined Lebesgue-a.e. on R . <p> For the considered range of parameters p; q; s all Besov spaces over R and 6 <ref> [0; 1] </ref> are continuously embedded in L 1;loc , hence, consist of regular distributions only, and elements of B s pq ([0; 1]) are obtained by taking the usual pointwise restriction on [0; 1] of a function defined Lebesgue-a.e. on R . When restricted to an interval, the Besov norm for a function g 2 B s pq ([0; 1]) is related to the sequence space norm of the wavelet coefficients as follows J spq (ff; fi) = kff j 0 k p <p> To simplify the exposition we will only review here the case of the fixed design model. For the fixed design model, Antoniadis et al. [7] propose the estimator: ^g (t) = i=1 Z E J (t; s) ds; (10) where the A i = [s i1 ; s i <ref> [ are intervals that partition [0; 1] </ref> with t i 2 A i . This is a wavelet version of Gasser and Muller's [45] (convolution) kernel estimator or of Hardle's ([51], p. 9 51) orthogonal series estimator. <p> For the fixed design model, Antoniadis et al. [7] propose the estimator: ^g (t) = i=1 Z E J (t; s) ds; (10) where the A i = [s i1 ; s i [ are intervals that partition <ref> [0; 1] </ref> with t i 2 A i . This is a wavelet version of Gasser and Muller's [45] (convolution) kernel estimator or of Hardle's ([51], p. 9 51) orthogonal series estimator. <p> The computational complexity of the algorithm for a general design is of the order O (n 2 ) and does not really take advantage of the fast discrete wavelet transform. To obtain a faster computational algorithm in the fixed design model with equidistant nonrandom design points t i within <ref> [0; 1] </ref>, Antoniadis [7] used another linear method that takes advantage of the DWT transform. <p> In smoothing splines, a popular method for nonparametric regression problems such as the ones treated here a th order smoothing spline g (x) is defined to be that function with square integrable th derivative which minimizes over the Sobolev space H <ref> [0; 1] </ref> the "discrete" functional: 1 n1 X (Y i g (t i )) + 0 g () (t) dt; where g () indicates the th derivative of g (see for example Wahba [86]). <p> These works are motivated by the multiresolution decomposition associated with wavelet orthonormal bases and the localized character of wavelet expansions. Specialized versions of histograms constructed via Haar basis decompositions are described in Chapter 12 of Walter [88] and some interesting properties of such Haar-based estimators on the interval <ref> [0; 1] </ref> are discussed in Engel [41]. All these papers assume i.i.d. observations. <p> Let us now further describe the regression model and the methods of estimation. The data are discrete and follow the fixed equidistant design regression model on <ref> [0; 1] </ref>: Y i = f (t i ) + oe* i ; i = 1; : : : ; n = 2 N ; where t i = i=n, and the * i 's, the noise in the observations, are i.i.d. N (0; 1) random errors. <p> Again, a prior distribution is imposed on wavelet coefficients of the unknown response function, and the function is estimated by computing the mean of the resulting posterior distribution of wavelet coefficients. Recent work on this direction has been done by Abramovich et al. <ref> [1] </ref>, with a prior designed to capture the sparseness of the wavelet expansion and a Bayes rule corresponding to the posterior median. Moreover, in the last mentioned paper, the prior model for the underlying regression function is adjusted to give functions falling in any specific Besov space.
Reference: [2] <author> Amato, U. and Vuza, D. T. </author> <year> (1994). </year> <title> Wavelet Regularization for Smoothing Data. </title> <type> Technical report N. 108/94, </type> <institution> Instituto per Applicazioni della Matematica, Napoli. </institution>
Reference-contexts: Another class of linear wavelet estimators that used in literature is derived within the framework of regularization methods. Such estimators appear in Devore & Lucier [30], 11 in a 1993 technical report of Antoniadis recently publised ([5]) and in Amato & Vuza <ref> [2] </ref>. <p> In Antoniadis [5] as well as in Amato & Vuza <ref> [2] </ref> the particular choice p = 2 is made. This choice and the use of wavelet decompositions of f and g, allows one to find an optimal solution to the variational problem given in (11). <p> For each resolution j J 0 , the wavelet coefficients d j;k are shrinked by a factor 1=(1 + 2 2sj ) which is level dependent. Assuming that g is a periodic function, Amato & Vuza <ref> [2] </ref> use J 0 = 0 and choose as the minimizer of the "GCV" function V n () = h n1 Tr (I n R n ()) where R n () denotes this diagonal shrinkage operator.
Reference: [3] <author> Amato, U. and Vuza, D. T. </author> <year> (1996). </year> <title> An Alternate Proof of a Result of Johnstone and Silverman concerning Wavelet Thresholding Estimators for Data with Correlated Noise. </title> <journal> Revue Roumaine Math. Pures Appl. </journal> <volume> 41, </volume> <pages> 431-438. </pages>
Reference-contexts: When the noise is stationary, using appropriately chosen level dependent thresholds, they obtain asymptotic minimax results similar to the ones obtained for the white noise regression model. A simpler proof of the optimality of their thresholding procedure is given by Amato and Vuza <ref> [3] </ref>. Brillinger ([16], [17]) also presents some inferential aspects of the wavelet technique far a deterministic signal in the presence of additive stationary non necessarily Gaussian noise. Function estimation for nonparametric regression with long-range dependence errors is studied in Wang [90].
Reference: [4] <author> Antoniadis, A. </author> <year> (1994). </year> <title> Smoothing noisy data with coiflets. </title> <booktitle> Statistica Sinica 4(2), </booktitle> <pages> 651-678. </pages>
Reference: [5] <author> Antoniadis, A. </author> <year> (1994). </year> <title> Smoothing noisy data with tapered coiflets series. </title> <journal> Scand. Journal. of Statistics 23, </journal> <pages> 313-330. </pages>
Reference-contexts: In Antoniadis <ref> [5] </ref> as well as in Amato & Vuza [2] the particular choice p = 2 is made. This choice and the use of wavelet decompositions of f and g, allows one to find an optimal solution to the variational problem given in (11).
Reference: [6] <author> Antoniadis, A. and Carmona, R. </author> <year> (1991). </year> <title> Multiresolution analyses and wavelets for density estimation. </title> <type> Technical report, </type> <institution> University of California, Irvine. </institution>
Reference-contexts: the S-plus packages WaveThresh (Nason & Silverman [67]) or S+Wavelets (Bruce & Gao [18]) or in the Matlab package WaveLab (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon [40], Antoniadis and Carmona <ref> [6] </ref>, Kerkyacharian and Picard [56] and Walter [87] for density estimation and Doukhan and Leon [40], Antoniadis, Gregoire and McKeague [7] for nonparametric regression. <p> The idea to use a wavelet series expansion for the estimation of probability functions was first considered by Doukhan and Leon [40], Antoniadis and Carmona <ref> [6] </ref>, Kerkyacharian and Picard [56] and Walter [87]. These works are motivated by the multiresolution decomposition associated with wavelet orthonormal bases and the localized character of wavelet expansions. <p> Specialized versions of histograms constructed via Haar basis decompositions are described in Chapter 12 of Walter [88] and some interesting properties of such Haar-based estimators on the interval [0; 1] are discussed in Engel [41]. All these papers assume i.i.d. observations. In Antoniadis and Carmona <ref> [6] </ref>, the unknown density belongs to the Sobolev space B s 22 , s &gt; 0, whereas in Kerkyacharian and Picard [56] f belongs to the Besov space B s pp , p 1, s &gt; 0.
Reference: [7] <author> Antoniadis, A., Gr egoire, G. and McKeague, I. </author> <year> (1994). </year> <title> Wavelet methods for curve estimation. </title> <journal> J. Amer. Statist. Assoc. </journal> <volume> 89(428), </volume> <pages> 1340-1353. </pages>
Reference-contexts: (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon [40], Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter [87] for density estimation and Doukhan and Leon [40], Antoniadis, Gregoire and McKeague <ref> [7] </ref> for nonparametric regression. In the following subsection we will address first the performance of such wavelet estimators in the case of a single model for nonparametric regression in close analogy with the classical theory of curve estimation. <p> In the context of non-uniform stochastic design there is a variety of ways to construct a wavelet estimator of the unknown mean function g. In this case, the basic wavelet estimator considered in Antoniadis et al. <ref> [7] </ref> is of the product of f g, which is then corrected by dividing by an estimator of the design density f which is constructed by a simple wavelet estimator or a kernel estimator. To simplify the exposition we will only review here the case of the fixed design model. <p> To simplify the exposition we will only review here the case of the fixed design model. For the fixed design model, Antoniadis et al. <ref> [7] </ref> propose the estimator: ^g (t) = i=1 Z E J (t; s) ds; (10) where the A i = [s i1 ; s i [ are intervals that partition [0; 1] with t i 2 A i . <p> The problem of automatically selecting J is rather easier than the bandwidth selection problem for kernel estimators, since the bandwidth is essentially reduced to the form 2 J where J &lt; 1 2 log 2 n. The selection rule used in Antoniadis et al. <ref> [7] </ref> is to choose J as the minimizer of the cross validation function CV (J) = n 1 i=1 where ^g (i) (t) is the leave-one-out estimator obtained by evaluating ^g (as a function of J and t) with the ith data point removed. <p> To obtain a faster computational algorithm in the fixed design model with equidistant nonrandom design points t i within [0; 1], Antoniadis <ref> [7] </ref> used another linear method that takes advantage of the DWT transform. <p> These issues are addressed by Marron et al. [59] using the tools of exact risk analysis, which was developed in Gasser and Muller [45], and first applied to wavelet estimators by Antoniadis et al. <ref> [7] </ref>. <p> Function estimation for nonparametric regression with long-range dependence errors is studied in Wang [90]. Wavelet versions of estimators of a hazard rate function in the context of inference for a counting process multiplicative intensity model have been studied by Antoniadis et al. <ref> [7] </ref>. See also Antoniadis, Gregoire and Nason [12] for a contribution to the methodology available for estimating the density and the hazard rate from randomly censored data.
Reference: [8] <author> Antoniadis, A. and Pham, D. T. </author> <year> (1995). </year> <title> Wavelet regression for random or irregular design. </title> <type> Technical report. </type> <institution> University of Grenoble. </institution>
Reference-contexts: When p = p2 j the resulting estimator may be seen as a classical wavelet-based estimator applied to a preliminary binned data with binwidth proportional to p (see Antoniadis & Pham <ref> [8] </ref>). This is also the approach taken by by Antoniadis, Gregoire and Vial [10], to generalize the fast linear wavelet estimators to general design nonparametric regression and density estimation. There is a potential problem in using wavelets for density estimation.
Reference: [9] <author> Antoniadis, A. and Lavergne, C. </author> <year> (1995). </year> <title> Variance function estimation in regression with wavelet methods. </title> <editor> In A. Antoniadis and G. Oppenheim (eds.), </editor> <booktitle> Wavelets and Statistics, Lecture Notes in Statistics, </booktitle> <volume> 103, </volume> <publisher> Springer-Verlag. </publisher>
Reference-contexts: Antoniadis and Lavergne <ref> [9] </ref> extend the linear wavelet-based methods to data with heteroscedastic noise. More recently, an extension of Donoho and Johnstone's wavelet shrinkage smoothing technique to handle data with heteroscedastic noise has been given by Gao [44].
Reference: [10] <author> Antoniadis, A., Gr egoire, G. and Vial, P. </author> <year> (1997a). </year> <title> Random design wavelet curve smoothing. </title> <journal> Statistics and Prob. </journal> <note> Letters.. In press. </note>
Reference-contexts: When p = p2 j the resulting estimator may be seen as a classical wavelet-based estimator applied to a preliminary binned data with binwidth proportional to p (see Antoniadis & Pham [8]). This is also the approach taken by by Antoniadis, Gregoire and Vial <ref> [10] </ref>, to generalize the fast linear wavelet estimators to general design nonparametric regression and density estimation. There is a potential problem in using wavelets for density estimation. When using general scaling functions there is no guarantee that the estimates are positive or integrate to 1.
Reference: [11] <author> Antoniadis, A., Gijbels, I. and Gr egoire, G. </author> <year> (1997b). </year> <title> Model selection using wavelet decomposition and applications. </title> <journal> Biometrika. </journal> <note> To appear. </note>
Reference-contexts: and locating the jump points can be found in Vercken and Potier [74], Wang [89] and more recently in Antoniadis and Gijbels [13] and the thesis of Raimondo [75]. 25 Applications of wavelet decompositions in statistical hypothesis testing and model selection appear in particular Fan [42] and Antoniadis et al. <ref> [11] </ref>. Fan shows that traditional nonparametric tests have low power in detecting fine features such as sharp and short aberrant as well as global features such as high frequency components.These drawbacks are repaired via wavelet thresholding and the Neyman truncation test. Antoniadis et al. [11] discuss how to use wavelet decomposition <p> Fan [42] and Antoniadis et al. <ref> [11] </ref>. Fan shows that traditional nonparametric tests have low power in detecting fine features such as sharp and short aberrant as well as global features such as high frequency components.These drawbacks are repaired via wavelet thresholding and the Neyman truncation test. Antoniadis et al. [11] discuss how to use wavelet decomposition to select a regression model. Their methodology relies on a minimum description length criterion which is used to determine the number of non-zero coefficients in the vector of wavelet coefficients.
Reference: [12] <author> Antoniadis, A., Gr egoire, G. and Nason, G. </author> <year> (1997c). </year> <title> Density and hazard rate estimation for right censored data using wavelet methods. </title> <type> Technical report. </type> <institution> University of Grenoble. </institution>
Reference-contexts: Function estimation for nonparametric regression with long-range dependence errors is studied in Wang [90]. Wavelet versions of estimators of a hazard rate function in the context of inference for a counting process multiplicative intensity model have been studied by Antoniadis et al. [7]. See also Antoniadis, Gregoire and Nason <ref> [12] </ref> for a contribution to the methodology available for estimating the density and the hazard rate from randomly censored data. The problem of estimating the log spectrum of a stationary Gaussian time series by wavelet thresholding techniques has been addressed by Gao [43] in his thesis.
Reference: [13] <author> Antoniadis, A. and Gijbels, I. </author> <year> (1997). </year> <title> Detecting abrupt changes by wavelet methods. </title> <type> Technical report. </type> <institution> University of Grenoble. </institution>
Reference-contexts: Wavelet methods for detecting and locating the jump points can be found in Vercken and Potier [74], Wang [89] and more recently in Antoniadis and Gijbels <ref> [13] </ref> and the thesis of Raimondo [75]. 25 Applications of wavelet decompositions in statistical hypothesis testing and model selection appear in particular Fan [42] and Antoniadis et al. [11].
Reference: [14] <author> Averkamp, R. and Houdr e, C. </author> <year> (1996). </year> <title> Wavelet thresholding for non (necessarily) Gaussian noise: a preliminary report. </title> <type> Technical report, </type> <institution> Georgia Institute of Technology, Atlanta. </institution>
Reference-contexts: It is also proven that the 2 log n factor cannot be improved, that is lim inf n!1 2 log n (U) k 2 1: In his thesis, Gao [43], proves similar results for i.i.d. variables with exponential tails. Recently, Averkamp and Houdre <ref> [14] </ref>, obtained a stronger result of this type for a wider class of distributions.
Reference: [15] <author> Beran, R. </author> <year> (1994). </year> <title> Bootstrap variable selection and confidence sets. </title> <type> Technical report, </type> <institution> University of California, Berkeley. </institution> <month> 28 </month>
Reference-contexts: of the O (n) computational efficiency of wavelet decompositions are also highly desirable, since it is known that when the dimension of the unknown parameter exceeds that of the data, most classical (na ive) bootstrap methods for assessing the variability of the estimates and constructing confidence sets fail (see Beran <ref> [15] </ref>). The usual wavelet-based approach can be further enhanced by using wavelet packets, a generalization of wavelet bases (see e.g. Wickerhauser [92]). In wavelet packet analysis, a function g is represented as a sum of orthogonal wavelet packet functions W j;b;k at different scales j, oscillations b and location k.
Reference: [16] <author> Brillinger, D. R. </author> <year> (1994). </year> <title> Some River Wavelets. </title> <booktitle> Environmetrics 5, </booktitle> <pages> 211-220. </pages>
Reference: [17] <author> Brillinger, D. R. </author> <year> (1995). </year> <title> Some uses of Cumulants in Wavelet Analysis. </title> <journal> J. Non-param. Statistics 4. </journal>
Reference-contexts: When the noise is stationary, using appropriately chosen level dependent thresholds, they obtain asymptotic minimax results similar to the ones obtained for the white noise regression model. A simpler proof of the optimality of their thresholding procedure is given by Amato and Vuza [3]. Brillinger ([16], <ref> [17] </ref>) also presents some inferential aspects of the wavelet technique far a deterministic signal in the presence of additive stationary non necessarily Gaussian noise. Function estimation for nonparametric regression with long-range dependence errors is studied in Wang [90].
Reference: [18] <author> Bruce, A. G. and Gao, H.-Y. </author> <year> (1994). </year> <note> S+Wavelets, Users manual. StatSci, Seatle. </note>
Reference-contexts: n = 2 J for some positive J , both DWT and inverse DWT are performed by Mallat's [58] fast algorithm that requires only O (n) operations and is available in several standard implementations, for example in the S-plus packages WaveThresh (Nason & Silverman [67]) or S+Wavelets (Bruce & Gao <ref> [18] </ref>) or in the Matlab package WaveLab (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon [40], Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter [87] for density estimation and Doukhan and
Reference: [19] <author> Bruce, A. G. and Gao, H.-Y. </author> <year> (1996). </year> <title> Understanding WaveShrink: Variance and bias estimation. </title> <type> Biometrika 83 (4), </type> <pages> 727-746. </pages>
Reference-contexts: Finite sample performance of thresholded wavelet estimators has also been studied by Bruce and Gao <ref> [19] </ref>, where computationally efficient formulas for computing the exact pointwise bias, variance and L 2 risk of thresholded wavelet estimators in finite sample situations are derived, thus complementing the tools of simulation and asymptotic analysis.
Reference: [20] <author> Bruce, A. G. and Gao, H.-Y. </author> <year> (1997). </year> <title> WaveShrink with firm shrinkage. </title> <journal> Statistica Sinica, </journal> <note> to appear. </note>
Reference-contexts: To remedy these drawbacks, and paralleling the choice of shrinkage functions with that of influence functions in robust statistics, Bruce and Gao <ref> [20] </ref> introduce a general semisoft shrinkage function j 1 ; 2 (x) = &gt; &gt; &lt; 0 if jxj 1 2 (jxj 1 ) x if jxj &gt; 2 ; that offers some advantages over both hard shrinkage (uniformly smaller risk and less sensitivity to small perturbations in the data) and
Reference: [21] <author> Buckheit, J. B. and Donoho, D. </author> <year> (1995). </year> <editor> Wavelab and Reproducible research. In A. Antoniadis and G. Oppenheim (eds.), </editor> <booktitle> Wavelets and Statistics, Lecture Notes in Statistics, </booktitle> <volume> 103, </volume> <publisher> Springer-Verlag. </publisher>
Reference-contexts: DWT and inverse DWT are performed by Mallat's [58] fast algorithm that requires only O (n) operations and is available in several standard implementations, for example in the S-plus packages WaveThresh (Nason & Silverman [67]) or S+Wavelets (Bruce & Gao [18]) or in the Matlab package WaveLab (Buckheit et al. <ref> [21] </ref>). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon [40], Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter [87] for density estimation and Doukhan and Leon [40], Antoniadis, Gregoire and McKeague [7] for nonparametric regression.
Reference: [22] <author> Clyde, M., Parmigiani, G. and Vidakovic, B. </author> <year> (1995). </year> <title> Multiple shrinkage and subset selection in wavelets. </title> <type> Technical report DP 95-37, </type> <institution> Duke University. </institution>
Reference-contexts: The posterior means of the wavelet coefficients have the shape of standard soft wavelet thresholding rules and are used to estimate the unknown curve. Other papers considering wavelet shrinkage or thresholding within a Bayesian framework are those by Clyde et al. <ref> [22] </ref>, Chipman et al. [23]. Again, a prior distribution is imposed on wavelet coefficients of the unknown response function, and the function is estimated by computing the mean of the resulting posterior distribution of wavelet coefficients.
Reference: [23] <author> Chipman, H. A., Kolaczyk, E. D. and McCulloch, R. E. </author> <year> (1995). </year> <title> Adaptative Bayesian Wavelet Shrinkage. </title> <institution> Technical report , University of Chicago. </institution>
Reference-contexts: The posterior means of the wavelet coefficients have the shape of standard soft wavelet thresholding rules and are used to estimate the unknown curve. Other papers considering wavelet shrinkage or thresholding within a Bayesian framework are those by Clyde et al. [22], Chipman et al. <ref> [23] </ref>. Again, a prior distribution is imposed on wavelet coefficients of the unknown response function, and the function is estimated by computing the mean of the resulting posterior distribution of wavelet coefficients.
Reference: [24] <author> Chui, K. </author> <year> (1992). </year> <title> Wavelets: A Tutorial in Theory and Applications. </title> <publisher> Academic Press, </publisher> <address> Boston. </address>
Reference-contexts: For precise mathematical statements, clear definitions and detailed expositions we refer the reader to Meyer [62], Mallat [58], Daubechies [27], Chui <ref> [24] </ref>, Wickerhauser [92], Cohen and Ryan [26] and Holschneider [52]. 2 2.1 Wavelet analysis Wavelet analysis requires a description of two basic functions, the scaling function '(x) and the wavelet (x).
Reference: [25] <author> Cohen, A., Daubechies, I. and Vial, P. </author> <year> (1993). </year> <title> Wavelets on the interval and fast wavelet transforms. </title> <booktitle> Applied and Comp. Harmonic Analysis 1(1), </booktitle> <pages> 54-81. </pages>
Reference-contexts: Therefore, wavelets are optimal bases for compressing and recovering functions in such spaces. In many practical situations, the functions involved are only defined on a compact interval, such as the interval [0; 1], and to apply wavelets requires some modifications. Cohen et al. <ref> [25] </ref> have obtained the necessary boundary corrections to retain orthonor-mality, and their wavelets on [0; 1] also constitute unconditional bases for the Besov spaces on the interval with an associated multiresolution analysis structure.
Reference: [26] <author> Cohen, A. and Ryan, R. </author> <title> D (1995). Wavelets and Multiscale Signal Processing. </title> <publisher> Chapman & Hall, London. </publisher>
Reference-contexts: For precise mathematical statements, clear definitions and detailed expositions we refer the reader to Meyer [62], Mallat [58], Daubechies [27], Chui [24], Wickerhauser [92], Cohen and Ryan <ref> [26] </ref> and Holschneider [52]. 2 2.1 Wavelet analysis Wavelet analysis requires a description of two basic functions, the scaling function '(x) and the wavelet (x).
Reference: [27] <author> Daubechies, I. </author> <year> (1992). </year> <title> Ten Lectures on Wavelets. </title> <booktitle> CBMS-NSF regional conferences series in applied mathematics. </booktitle> <publisher> SIAM, </publisher> <address> Philadelphia. </address>
Reference-contexts: For precise mathematical statements, clear definitions and detailed expositions we refer the reader to Meyer [62], Mallat [58], Daubechies <ref> [27] </ref>, Chui [24], Wickerhauser [92], Cohen and Ryan [26] and Holschneider [52]. 2 2.1 Wavelet analysis Wavelet analysis requires a description of two basic functions, the scaling function '(x) and the wavelet (x). <p> Set X a k O (2 j x k); (8) where O is the indicator function of the interval [ 1 2 ; 1 2 [. Under certain conditions (see Daubechies <ref> [27] </ref>), the sequence of functions ' j converges pointwise to a limit function ' that satisfies the two-scale difference equation (1). <p> A first step towards the curve estimation method is to approximate the projection P V n by some operator n in terms of the sampled values g ( k 2 N ) and to then derive a reasonable estimator of the approximation n g. Using coiflets (see Daubechies <ref> [27] </ref>) that have L vanishing moments with L &gt; [s], such an estimator of n g is obtained by ^g n (t) = b n g (t) = 2 N=2 X Y k OE n;k (t) = 2 N=2 k=0 where the use of coiflets (wavelets for which the scaling function
Reference: [28] <author> Daubechies, I. D. and Lagarias, J. C. </author> <year> (1991). </year> <title> Two-scale difference equations: Existence and global regularity of solutions. </title> <journal> SIAM Journal on Math. Analysis. </journal> <volume> 22, </volume> <pages> 1388-1410. </pages>
Reference: [29] <author> Delyon, B. and Juditsky, A. </author> <year> (1996). </year> <title> On minimax wavelet estimators. </title> <booktitle> Applied and Comp. Harmonic Analysis 3, </booktitle> <pages> 215-228. </pages>
Reference-contexts: = log 2 nlog 2 (log n), j = A (j J 0 )=n, where A is some constant and J 0 is chosen according to the regularity of OE and the sample size, the thresholded estimator ^ f n in the papers cited above (see also Delyon and Judistsky <ref> [29] </ref>) is shown to be asymptotical optimal in the sense that, for s &gt; 1=p and p (1 + 2s)p, it attains the minimax L p 0 rate n 0 in the class of densities in the Besov space B s pq with J spq (f ) M , where M
Reference: [30] <author> DeVore, R. and Lucier, B. J. </author> <year> (1992). </year> <title> Fast wavelet techniques for near-optimal signal processing. </title> <booktitle> In IEEE Military Communication Conference, </booktitle> <pages> pp. 1129-1135. 29 </pages>
Reference-contexts: Once again the parameter j (n) governs the smoothness of the estimator. Another class of linear wavelet estimators that used in literature is derived within the framework of regularization methods. Such estimators appear in Devore & Lucier <ref> [30] </ref>, 11 in a 1993 technical report of Antoniadis recently publised ([5]) and in Amato & Vuza [2]. <p> The linear estimate suggested by Devore and Lucier <ref> [30] </ref> approximately minimizes the penalized functional (11) by a factor of 2 and is obtained by projecting the data vector on V K where K is chosen such that 2 2K = kgk 2 22 oe 2 : While a reasonable estimate of the unknown variance can be obtained, it seems
Reference: [31] <author> DeVore, R. , Jawerth, B. and Popov, V. </author> <year> (1988). </year> <title> Interpolation of Besov spaces. </title> <journal> Trans. Amer. Math. Soc. </journal> <volume> 305, </volume> <pages> 397-414. </pages>
Reference-contexts: Given that the norm of a function g usually depends only on the absolute value of its wavelet coefficients, one can show (see Devore et al. <ref> [31] </ref>) that the best approximation of a function g with M coefficients, is obtained by g M = j;k2fl M where fl M contains the indexes of the M largest in absolute value coefficients. Note that this approximation is nonlinear. <p> This is given by the largest positive exponent ff for which kg g M k = O (M ff ): (5) The question on how to find ff has been extensively studied in the area of nonlinear approximation and smoothness spaces. The main result (see Devore et al. <ref> [31] </ref>) says that if the normed space to which g belongs is a Besov space of smoothness index ff, then 5 (5) holds. We will give a precise mathematical definition of Besov spaces in the next subsection.
Reference: [32] <author> Donoho, D. </author> <year> (1994). </year> <title> Asymptotic risk for sup-norm loss: solution via optimal recovery. </title> <journal> Prob. Theory and Related Fields. </journal> <volume> 99, </volume> <pages> 145-170. </pages>
Reference-contexts: To end this subsection, we briefly mention an interesting result of Donoho <ref> [32] </ref> where a linear wavelet estimator for an equidistant regression model with independent Gaussian errors is shown to attain the best asymptotic minimax rate (n 1 log n) fi=(2fi+1) in the sup norm for the class of functions ff : sup jf m (x) f m (y)j x2 [0;1] for L
Reference: [33] <author> Donoho, D. L. and Johnstone, I. M. </author> <year> (1992). </year> <title> Minimax estimation via wavelet shrinkage. </title> <type> Technical report, </type> <institution> Stanford University. </institution>
Reference-contexts: It is easy to see that the wavelet estimator introduced by regularization appears as a particular diagonal linear shrinker (see Donoho and John-stone <ref> [33] </ref>). For each resolution j J 0 , the wavelet coefficients d j;k are shrinked by a factor 1=(1 + 2 2sj ) which is level dependent. <p> For functions that might not be smooth in the classical sense, nonlinear wavelet-based estimation methods provide levels of smoothing which automatically adapt to local variations of roughness of 18 the curve. Nonlinear wavelets methods in statistics were introduced by Donoho and John--stone <ref> [33] </ref>, [34], [36] and Donoho, Johnstone, Kerkyacharian and Picard [37], to cite only few of their papers. They permit two non-overlapping levels of smoothing, one global, via the frequency of the scaling function, and the other one local, via the scale of the wavelet function. <p> Another method for global thresholding proposed by Donoho and Johnstone <ref> [33] </ref> is labeled minimax thresholding. <p> The threshold fl n does not exist in analytical form but a numerical approximation for a range of sample sizes are given in Donoho and Johnstone <ref> [33] </ref>. <p> When it is known that the underlying regression function is Holder continuous an estimator as the one described in Section 3 can be used. Donoho and Johnstone <ref> [33] </ref> propose a robust estimate of oe by taking the median absolute deviation of the coefficients at the finest level of the empirical decomposition ^oe = median (jc N1;k median (jc N1;k )j) 0:6745 since typically there is also some signal present even at the finest level.
Reference: [34] <author> Donoho, D. L. and Johnstone, I. M. </author> <year> (1994a). </year> <title> Ideal spatial adaptation by wavelet shrinkage. </title> <journal> Biometrika 81, </journal> <pages> 425-455. </pages>
Reference-contexts: For functions that might not be smooth in the classical sense, nonlinear wavelet-based estimation methods provide levels of smoothing which automatically adapt to local variations of roughness of 18 the curve. Nonlinear wavelets methods in statistics were introduced by Donoho and John--stone [33], <ref> [34] </ref>, [36] and Donoho, Johnstone, Kerkyacharian and Picard [37], to cite only few of their papers. They permit two non-overlapping levels of smoothing, one global, via the frequency of the scaling function, and the other one local, via the scale of the wavelet function. <p> Some results on adaptative model selection using wavelet packets for white noise models already exist (see for example the papers by Donoho and Johnstone <ref> [34] </ref> and Saito [77]) but their extension to other types of noise are desirable. Many results in higher dimensions are still incomplete.
Reference: [35] <author> Donoho, D. L. and Johnstone, I. M. </author> <year> (1995). </year> <title> Adapting to unknown smoothness via wavelet shrinking. </title> <journal> J. Am. Statist. Assoc. </journal> <volume> 90, </volume> <pages> 1200-1224. </pages>
Reference-contexts: The latter functions are of statistical interest because they allow for better models of spatial inhomogeneity (e.g. Meyer [62], Donoho & Johnstone <ref> [35] </ref>). 2.3 Computational algorithms and the discrete wavelet trans form An algorithm described in Daubechies and Lagarias ([28], p. 17) (the cascade algorithm) allows the construction of orthogonal compactly supported wavelets as limits of step functions which are finer and finer scale approximations of '. <p> The estimators described above, while applicable to a wide range of variable frequency curves, usually provide an excessive amount of smoothing when applied to curves that are piecewise smooth. Their mean-squared errors are asymptotically dominated by bias. To address this problem, Donoho and Johnstone <ref> [35] </ref> look at a variant with level-dependent thresholds. The method, called Sureshrink employs an unbiased risk estimation that is due to Stein [78] and is shown in Ogden [70] to be in relation with Akaike's information criterion (AIC), introduced by Akaike for times series modeling.
Reference: [36] <author> Donoho, D. L. and Johnstone, I. M. </author> <year> (1994b). </year> <title> Ideal denoising in an orthonormal basis chosen from a library of bases. </title> <type> Compt. </type> <institution> Rend. Acad. Sci. Paris A 319, </institution> <month> 1317-1322. </month>
Reference-contexts: For functions that might not be smooth in the classical sense, nonlinear wavelet-based estimation methods provide levels of smoothing which automatically adapt to local variations of roughness of 18 the curve. Nonlinear wavelets methods in statistics were introduced by Donoho and John--stone [33], [34], <ref> [36] </ref> and Donoho, Johnstone, Kerkyacharian and Picard [37], to cite only few of their papers. They permit two non-overlapping levels of smoothing, one global, via the frequency of the scaling function, and the other one local, via the scale of the wavelet function.
Reference: [37] <author> Donoho, D. L., Johnstone, I. M., Kerkyacharian, G. and Picard, D. </author> <year> (1995). </year> <title> Wavelet shrinkage: asymptopia (with discussion)? J. </title> <journal> Roy. Statist. Soc., Ser. </journal> <volume> B 57(2), </volume> <pages> 301-370. </pages>
Reference-contexts: Nonlinear wavelets methods in statistics were introduced by Donoho and John--stone [33], [34], [36] and Donoho, Johnstone, Kerkyacharian and Picard <ref> [37] </ref>, to cite only few of their papers. They permit two non-overlapping levels of smoothing, one global, via the frequency of the scaling function, and the other one local, via the scale of the wavelet function. <p> Possible extensions that might be possible for a random design and other types of noise will be discussed later. The paper by Donoho, Johnstone, Kerkyacharian and Picard <ref> [37] </ref> is perhaps the most significant paper from both a mathematical and practical point of view for the existence of nonparametric function estimators that behave in a (near) asymptotic optimal way simultaneously for a broad range of function spaces (Besov or Triebel spaces) not considered before in statistics and a variety
Reference: [38] <author> Donoho, D. L., Johnstone, I. M., Kerkyacharian, G. and Picard, D. </author> <year> (1996). </year> <title> Density estimation by wavelet thresholding. </title> <journal> Ann. Statist. </journal> <volume> 24(2), </volume> <pages> 508-539. </pages>
Reference-contexts: For a detailed account and description of these methods the reader is referred to the papers by Nason ([66], [65]) or the book by Ogden [70]. 4.2 Density estimation Nonlinear wavelet-based density estimators in the i.i.d. setting were introduced by John-stone et al. [54] and Donoho et al. <ref> [38] </ref> and parallel exactly the results obtained for the regression case, although the proofs are entirely different.
Reference: [39] <author> Doukhan, P. </author> <year> (1990). </year> <title> Consistency of delta-sequence estimates of a density or of a regression function for a weakly dependent stationary sequence. </title> <type> Seminaire de Statis-tique d'Orsay, </type> <institution> Universite Paris Sud, </institution> <year> 1991. </year>
Reference: [40] <author> Doukhan, P. and L eon, J. </author> <year> (1990). </year> <institution> Deviation quadratique d'estimateurs de densite par projection orthogonale. Compt. Rend. Acad. Sci. Paris A 310, </institution> <month> 424-430. </month>
Reference-contexts: implementations, for example in the S-plus packages WaveThresh (Nason & Silverman [67]) or S+Wavelets (Bruce & Gao [18]) or in the Matlab package WaveLab (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon <ref> [40] </ref>, Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter [87] for density estimation and Doukhan and Leon [40], Antoniadis, Gregoire and McKeague [7] for nonparametric regression. <p> in the Matlab package WaveLab (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon <ref> [40] </ref>, Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter [87] for density estimation and Doukhan and Leon [40], Antoniadis, Gregoire and McKeague [7] for nonparametric regression. In the following subsection we will address first the performance of such wavelet estimators in the case of a single model for nonparametric regression in close analogy with the classical theory of curve estimation. <p> The idea to use a wavelet series expansion for the estimation of probability functions was first considered by Doukhan and Leon <ref> [40] </ref>, Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter [87]. These works are motivated by the multiresolution decomposition associated with wavelet orthonormal bases and the localized character of wavelet expansions.
Reference: [41] <author> Engel, J. </author> <year> (1990). </year> <title> Density estimation with Haar series. </title> <journal> Statistics and Probability Letters 9, </journal> <pages> 111-117. </pages>
Reference-contexts: Specialized versions of histograms constructed via Haar basis decompositions are described in Chapter 12 of Walter [88] and some interesting properties of such Haar-based estimators on the interval [0; 1] are discussed in Engel <ref> [41] </ref>. All these papers assume i.i.d. observations. In Antoniadis and Carmona [6], the unknown density belongs to the Sobolev space B s 22 , s &gt; 0, whereas in Kerkyacharian and Picard [56] f belongs to the Besov space B s pp , p 1, s &gt; 0.
Reference: [42] <author> Fan, J. </author> <year> (1996). </year> <title> Test of significance based on wavelet thresholding and Neyman's truncation. </title> <journal> J. Am. Statist. Assoc. </journal> <volume> 91, </volume> <pages> 674-688. </pages>
Reference-contexts: Wavelet methods for detecting and locating the jump points can be found in Vercken and Potier [74], Wang [89] and more recently in Antoniadis and Gijbels [13] and the thesis of Raimondo [75]. 25 Applications of wavelet decompositions in statistical hypothesis testing and model selection appear in particular Fan <ref> [42] </ref> and Antoniadis et al. [11]. Fan shows that traditional nonparametric tests have low power in detecting fine features such as sharp and short aberrant as well as global features such as high frequency components.These drawbacks are repaired via wavelet thresholding and the Neyman truncation test.
Reference: [43] <author> Gao, H.-Y. </author> <year> (1993). </year> <title> Wavelet estimation of Spectral denstities in Time series analysis. </title> <type> Ph. D. Thesis, </type> <institution> University of California, Berkeley. </institution>
Reference-contexts: It is also proven that the 2 log n factor cannot be improved, that is lim inf n!1 2 log n (U) k 2 1: In his thesis, Gao <ref> [43] </ref>, proves similar results for i.i.d. variables with exponential tails. Recently, Averkamp and Houdre [14], obtained a stronger result of this type for a wider class of distributions. <p> See also Antoniadis, Gregoire and Nason [12] for a contribution to the methodology available for estimating the density and the hazard rate from randomly censored data. The problem of estimating the log spectrum of a stationary Gaussian time series by wavelet thresholding techniques has been addressed by Gao <ref> [43] </ref> in his thesis. More generally Neumann [68] applied the thresholding procedure in the framework of spectral density estimation for a stationary, possibly non Gaussian time series.
Reference: [44] <author> Gao, H.-Y. </author> <year> (1997). </year> <title> Wavelet Shrinkage Smoothing For Heteroscedastic Data. </title> <type> Technical report, </type> <address> StatSci, Seatle. </address> <month> 30 </month>
Reference-contexts: Antoniadis and Lavergne [9] extend the linear wavelet-based methods to data with heteroscedastic noise. More recently, an extension of Donoho and Johnstone's wavelet shrinkage smoothing technique to handle data with heteroscedastic noise has been given by Gao <ref> [44] </ref>. Johnstone and Silverman [55] have considered the extension to more general noise models than the white noise model. When the noise is stationary, using appropriately chosen level dependent thresholds, they obtain asymptotic minimax results similar to the ones obtained for the white noise regression model.
Reference: [45] <author> Gasser, T. and M uller, H. </author> <year> (1979). </year> <title> Kernel estimation of regression functions. </title> <editor> In Gasser, T. and Muller, H. (eds), </editor> <title> Curve Estimation, </title> <publisher> Springer-Verlag, </publisher> <address> Heidelberg. </address>
Reference-contexts: This is a wavelet version of Gasser and Muller's <ref> [45] </ref> (convolution) kernel estimator or of Hardle's ([51], p. 9 51) orthogonal series estimator. It can be seen clearly that the kernel E J (t; s) is variable, since its form depends on t. <p> As with any asymptotic result, there remain doubts as to how well the asymptotics describe small sample behavior. These issues are addressed by Marron et al. [59] using the tools of exact risk analysis, which was developed in Gasser and Muller <ref> [45] </ref>, and first applied to wavelet estimators by Antoniadis et al. [7].
Reference: [46] <author> Good, I. J. and Gaskins, R. A. </author> <year> (1971). </year> <title> Density estimation and bump haunting by the penalized maximum likelihood method. </title> <journal> J. Am. Statist. Assoc. </journal> <volume> 75, </volume> <pages> 42-69. </pages>
Reference-contexts: Another approach used in the literature, that will be discussed further when nonlinear wavelet estimation methods will be presented, is to estimate the square root of the density and square back the estimate after. The idea of the above transformation can be found in Good & Gaskins <ref> [46] </ref> in the context of penalized likelihood methods. The condition R f (x)dx = 1 becomes R p f (x)) 1=2 dx = 1, so that p f 2 L 2 .
Reference: [47] <author> Hall, P. and Nason, G. P. </author> <year> (1996). </year> <title> On choosing a non-integer resolution level when using wavelet methods. </title> <type> Technical report, </type> <institution> University of Bristol. </institution>
Reference-contexts: A quantification of the advantages of non-integer resolution levels as well as some techniques for choosing the smoothing parameter by cross-validation as is done for kernel estimation is given in Hall & Nason <ref> [47] </ref>. When p = p2 j the resulting estimator may be seen as a classical wavelet-based estimator applied to a preliminary binned data with binwidth proportional to p (see Antoniadis & Pham [8]).
Reference: [48] <author> Hall, P. and Patil, P. </author> <year> (1995). </year> <title> On wavelet methods for estimating smooth functions. </title> <type> Bernoulli 1, </type> <pages> 41-58. </pages>
Reference-contexts: At non-dyadic points, the asymptotic variance of the estimator, while remaining bounded, oscillates and asymptotic normality cannot be obtained. This phenomenon of erratic oscillations in the variance was also observed by Hall & Patil <ref> [48] </ref>. consist of accelerometer readings taken through time in an experiment on the efficacy of crash helmets. For several reasons the time points are not regularly spaced. The cascade algorithm described in subsection 2.3 of Section 2 was used to compute the weights defining the estimator. <p> However, contrary to the case of classical kernel estimators, the terms representing bias and variance of wavelet-based density estimators oscillate erratically with a wavelength of the same order as 2 J . Indeed, as proved by Hall & Patil <ref> [48] </ref>, the classical pointwise bias and variance formulae, bias (t) = E ^ f n (t) f (t) ' a 1 (t)2 Js and variance (t) = varff n (t)g ' a 2 (t)2 J =n for smooth functions a 1 and a 2 are no longer valid. <p> One way to reduce these oscillations, thus resulting in a smaller mean-squared error, is to not insist on choosing a smoothing frequency that is a power of 2 for the wavelet estimator. Hall & Patil <ref> [48] </ref>, suggest using the family of orthonormal scaling functions OE k (x) = p 1=2 '(px + k) where p &gt; 0 denotes an arbitrary positive number. It is easy to see that when p = 2 J one has OE k = ' J;k .
Reference: [49] <author> Hall, P. and Patil, P. </author> <year> (1996a). </year> <title> Effect of threshold rules on performance of wavelet-based curve estimators. </title> <booktitle> Statistica Sinica 6, </booktitle> <pages> 331-345. </pages>
Reference-contexts: The method, called Sureshrink employs an unbiased risk estimation that is due to Stein [78] and is shown in Ogden [70] to be in relation with Akaike's information criterion (AIC), introduced by Akaike for times series modeling. Hall and Patil ([48], <ref> [49] </ref>, [50]) studied asymptotic wavelet shrinkage methods in non-parametric curve estimation from the different viewpoint of a fixed target function, as opposed to the minimax approach of Donoho et al..
Reference: [50] <author> Hall, P. and Patil, P. </author> <year> (1996b). </year> <title> On the choice of smoothing parameter, threshold and truncation in nonparametric regression by nonlinear wavelet methods. </title> <journal> J. Roy. Statist. Soc., Ser. </journal> <volume> B 58, </volume> <pages> 361-377. </pages>
Reference-contexts: The method, called Sureshrink employs an unbiased risk estimation that is due to Stein [78] and is shown in Ogden [70] to be in relation with Akaike's information criterion (AIC), introduced by Akaike for times series modeling. Hall and Patil ([48], [49], <ref> [50] </ref>) studied asymptotic wavelet shrinkage methods in non-parametric curve estimation from the different viewpoint of a fixed target function, as opposed to the minimax approach of Donoho et al..
Reference: [51] <author> H ardle, W. </author> <year> (1990). </year> <title> Applied nonparametric regression. </title> <publisher> Cambridge University Press, </publisher> <address> Cambridge. </address>
Reference: [52] <author> Holschneider, M. </author> <year> (1995). </year> <title> Wavelets: An analysis tool. </title> <publisher> Clarendon Press, Oxford. </publisher>
Reference-contexts: For precise mathematical statements, clear definitions and detailed expositions we refer the reader to Meyer [62], Mallat [58], Daubechies [27], Chui [24], Wickerhauser [92], Cohen and Ryan [26] and Holschneider <ref> [52] </ref>. 2 2.1 Wavelet analysis Wavelet analysis requires a description of two basic functions, the scaling function '(x) and the wavelet (x).
Reference: [53] <author> Jansen, M., Malfait, M. and Bultheel, A. </author> <year> (1997). </year> <title> Generalized cross-validation for wavelet thresholding. Signal Processing, </title> <type> 56 (1). </type> <note> To appear. </note>
Reference-contexts: Recently, Jansen et al. <ref> [53] </ref> have shown that, under appropriate conditions, this generalized cross-validation choice is asymptotically optimal, in the sense of yielding asymptotically the threshold that minimizes the expected mean squared error.
Reference: [54] <author> Johnstone, I. M., Kerkyacharian, G. and Picard, D. </author> <year> (1992). </year> <title> Estimation d'une densite de probabilite par methode d'ondelettes. </title> <type> Compt. </type> <institution> Rend. Acad. Sci. Paris A 315, </institution> <month> 211-216. </month>
Reference-contexts: For a detailed account and description of these methods the reader is referred to the papers by Nason ([66], [65]) or the book by Ogden [70]. 4.2 Density estimation Nonlinear wavelet-based density estimators in the i.i.d. setting were introduced by John-stone et al. <ref> [54] </ref> and Donoho et al. [38] and parallel exactly the results obtained for the regression case, although the proofs are entirely different.
Reference: [55] <author> Johnstone, I. and Silverman, B. </author> <title> W (1997). Wavelet threshold estimators for data with correlated noise. </title> <journal> J. Roy. Statist. Soc., Ser. B 59. </journal> <note> In press. </note>
Reference-contexts: Antoniadis and Lavergne [9] extend the linear wavelet-based methods to data with heteroscedastic noise. More recently, an extension of Donoho and Johnstone's wavelet shrinkage smoothing technique to handle data with heteroscedastic noise has been given by Gao [44]. Johnstone and Silverman <ref> [55] </ref> have considered the extension to more general noise models than the white noise model. When the noise is stationary, using appropriately chosen level dependent thresholds, they obtain asymptotic minimax results similar to the ones obtained for the white noise regression model.
Reference: [56] <author> Kerkyacharian, G. and Picard, D. </author> <year> (1992). </year> <title> Density estimation in Besov Spaces. </title> <journal> Statistics and Probability Letters 13, </journal> <pages> 15-24. </pages>
Reference-contexts: (Nason & Silverman [67]) or S+Wavelets (Bruce & Gao [18]) or in the Matlab package WaveLab (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon [40], Antoniadis and Carmona [6], Kerkyacharian and Picard <ref> [56] </ref> and Walter [87] for density estimation and Doukhan and Leon [40], Antoniadis, Gregoire and McKeague [7] for nonparametric regression. <p> The idea to use a wavelet series expansion for the estimation of probability functions was first considered by Doukhan and Leon [40], Antoniadis and Carmona [6], Kerkyacharian and Picard <ref> [56] </ref> and Walter [87]. These works are motivated by the multiresolution decomposition associated with wavelet orthonormal bases and the localized character of wavelet expansions. <p> All these papers assume i.i.d. observations. In Antoniadis and Carmona [6], the unknown density belongs to the Sobolev space B s 22 , s &gt; 0, whereas in Kerkyacharian and Picard <ref> [56] </ref> f belongs to the Besov space B s pp , p 1, s &gt; 0.
Reference: [57] <author> Kolaczyk, E. </author> <year> (1994). </year> <title> Wavelet methods for the inversion of some homogeneous linear operators in the presence of noisy data. </title> <type> Ph. D. Thesis, </type> <institution> Stanford University. </institution>
Reference-contexts: A generalization to the problem of recovering f from indirect data Y = Kf + *, where K is a known operator has been addressed by Kolaczyk <ref> [57] </ref> in the context of integration, fractional integration and tomography.
Reference: [58] <author> Mallat, S. G. </author> <year> (1989). </year> <title> A theory for multiresolution signal decomposition: the wavelet representation. </title> <journal> IEEE Trans. on Pattern Analysis and Machine Intelligence 11, </journal> <pages> 674-693. </pages>
Reference-contexts: For precise mathematical statements, clear definitions and detailed expositions we refer the reader to Meyer [62], Mallat <ref> [58] </ref>, Daubechies [27], Chui [24], Wickerhauser [92], Cohen and Ryan [26] and Holschneider [52]. 2 2.1 Wavelet analysis Wavelet analysis requires a description of two basic functions, the scaling function '(x) and the wavelet (x). <p> Such algorithms are referred to as a fast wavelet transform. Fast wavelet transforms are often obtained through multiresolu-tion analysis, a a framework developed by Mallat <ref> [58] </ref>, in which the wavelet coefficients &lt; g; j;k &gt; of a function g for a fixed j describe the difference between two approximations of g, one with resolution 2 j , and one with the coarser resolution 2 j1 . <p> In terms of W n;J 0 , fi = W n;J 0 f and f = W T n;J 0 fi. If n = 2 J for some positive J , both DWT and inverse DWT are performed by Mallat's <ref> [58] </ref> fast algorithm that requires only O (n) operations and is available in several standard implementations, for example in the S-plus packages WaveThresh (Nason & Silverman [67]) or S+Wavelets (Bruce & Gao [18]) or in the Matlab package WaveLab (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation
Reference: [59] <author> Marron, S. J., Adak, S., Johnstone, I., Neumann, M., and Patil, P. </author> <year> (1997). </year> <title> Exact risk analysis of wavelet regression. </title> <journal> Journal of Computational and Graphical Statistics. </journal> <note> In press. </note>
Reference-contexts: Most of the methods and results described above are asymptotic in character. As with any asymptotic result, there remain doubts as to how well the asymptotics describe small sample behavior. These issues are addressed by Marron et al. <ref> [59] </ref> using the tools of exact risk analysis, which was developed in Gasser and Muller [45], and first applied to wavelet estimators by Antoniadis et al. [7].
Reference: [60] <author> Masry, E. </author> <year> (1994). </year> <title> Probability density estimation from dependent observations using wavelet orthonormal bases. </title> <journal> Statistics and Probability Letters 21, </journal> <pages> 181-194. </pages>
Reference-contexts: linear wavelet estimators are respectively E kf ^ f n k 2 and p = O (n ps=(2s+1) ): A precise asymptotic expression for E kf ^ f n k 2 2 in the case of f 2 B s 22 , s &gt; 0 was given later by Masry <ref> [60] </ref> for more general stationary processes. In the i.i.d. case the asymptotic expression is shown to be exactly of the form n 2s=(2s+1) E kf ^ f n k 2 as n ! 1.
Reference: [61] <author> Masry, E. </author> <year> (1996). </year> <title> Multivariate probability density estimation by wavelet methods: strong consistency and rates for stationary time series. </title> <type> Technical report, </type> <institution> University of California, </institution> <address> San Diego. </address>
Reference-contexts: This rate cannot be attained with linear methods. Note, however, that when p ! 1, Masry <ref> [61] </ref> has shown that this rate is attained by linear estimators and thus nonlinear estimators do not improve the rate of convergence in this case.
Reference: [62] <author> Meyer, Y. </author> <year> (1990). </year> <title> Ondelettes et Operateurs I: Ondelettes. </title> <publisher> Hermann, </publisher> <address> Paris. </address>
Reference-contexts: For precise mathematical statements, clear definitions and detailed expositions we refer the reader to Meyer <ref> [62] </ref>, Mallat [58], Daubechies [27], Chui [24], Wickerhauser [92], Cohen and Ryan [26] and Holschneider [52]. 2 2.1 Wavelet analysis Wavelet analysis requires a description of two basic functions, the scaling function '(x) and the wavelet (x). <p> Of course the primary wavelet inherits the regularity of the scaling function. Moreover if is regular enough, the resulting wavelet orthonormal basis provides unconditional bases for a wide set of function spaces, such as Besov or Triebel spaces, see Meyer <ref> [62] </ref>. <p> The latter functions are of statistical interest because they allow for better models of spatial inhomogeneity (e.g. Meyer <ref> [62] </ref>, Donoho & Johnstone [35]). 2.3 Computational algorithms and the discrete wavelet trans form An algorithm described in Daubechies and Lagarias ([28], p. 17) (the cascade algorithm) allows the construction of orthogonal compactly supported wavelets as limits of step functions which are finer and finer scale approximations of '.
Reference: [63] <author> Michelli, C. A. and Rivlin, T. J. </author> <year> (1975). </year> <title> A survey of optimal recovery. </title> <editor> In Michelli, C. A. and Rivlin, T. J. (eds.), </editor> <title> Optimal estimation in Approximation theory , pp. </title> <address> 1-54, </address> <publisher> Plenum, </publisher> <address> New York. </address>
Reference-contexts: This is achieved by using the approximating properties of wavelet bases and the close relation between the problem of minimax estimation and the theory of optimal recovery, a survey of which can be found in a paper by Michelli and Rivlin <ref> [63] </ref>. The connection with deterministic optimal recovery problems is obtained by means of a simple but powerful thresholding device on the empirical wavelet coefficients, which works reasonably well in practice.
Reference: [64] <author> M uller, H. G. </author> <year> (1985). </year> <title> Empirical bandwidth choice for nonparametric kernel regression by means of pilot estimators. </title> <journal> Statist. </journal> <volume> Decisions 2, </volume> <pages> 193-206. </pages>
Reference-contexts: A possible choice for an estimate of the noise variance is the one suggested by Muller <ref> [64] </ref>: ^oe 2 = 3 (n 2) i=2 1 (Y i1 + Y i+1 )] 2 ; obtained by fitting constants to successive triples of the data.
Reference: [65] <author> Nason, G. P. </author> <year> (1996). </year> <title> Wavelet regression using cross-validation. </title> <journal> J. Roy. Statist. Soc., Ser. </journal> <volume> B 58, </volume> <pages> 463-479. </pages>
Reference-contexts: Other data-driven methods for the choice of the smoothing parameter (s) in thresholding wavelet estimators have also been proposed in the literature. For a detailed account and description of these methods the reader is referred to the papers by Nason ([66], <ref> [65] </ref>) or the book by Ogden [70]. 4.2 Density estimation Nonlinear wavelet-based density estimators in the i.i.d. setting were introduced by John-stone et al. [54] and Donoho et al. [38] and parallel exactly the results obtained for the regression case, although the proofs are entirely different.
Reference: [66] <author> Nason, G. J. </author> <year> (1995). </year> <title> Choice of the threshold parameter in wavelet function estimation. </title> <editor> In A. Antoniadis and G. Oppenheim (eds.), </editor> <booktitle> Wavelets and Statistics, </booktitle> <pages> pp. 261-280, </pages> <booktitle> Lecture Notes in Statistics, </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York. </address>
Reference: [67] <author> Nason, G. J. and Silverman, B. W. </author> <year> (1994). </year> <title> The discrete wavelet transform in S. </title> <journal> Journal of Computational and Graphical Statistics 3, </journal> <pages> 163-191. </pages>
Reference-contexts: If n = 2 J for some positive J , both DWT and inverse DWT are performed by Mallat's [58] fast algorithm that requires only O (n) operations and is available in several standard implementations, for example in the S-plus packages WaveThresh (Nason & Silverman <ref> [67] </ref>) or S+Wavelets (Bruce & Gao [18]) or in the Matlab package WaveLab (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon [40], Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter [87]
Reference: [68] <author> Neumann, M. H. </author> <year> (1994). </year> <title> Spectral density estimation via nonlinear wavelet methods for stationary non-Gaussian series. </title> <type> Technical report 99, </type> <institution> Institute for applied and stochastic analysis, </institution> <address> Berlin. </address>
Reference-contexts: The problem of estimating the log spectrum of a stationary Gaussian time series by wavelet thresholding techniques has been addressed by Gao [43] in his thesis. More generally Neumann <ref> [68] </ref> applied the thresholding procedure in the framework of spectral density estimation for a stationary, possibly non Gaussian time series. It has also been applied by von Sachs and Schneider [85] to the periodogram of a locally stationary process for the estimation of its evolutionary spectrum.
Reference: [69] <author> Neumann, M.H. and Spokoiny, V.G. </author> <year> (1993). </year> <title> On the efficiency of wavelet estimators under arbitrary error distributions. Discussion Paper No. </title> <type> 4, </type> <institution> Humboldt Uni-versitat zu Berlin. </institution>
Reference-contexts: For some particular non-Gaussian regression models a possible approach, using some large deviation results, is one proposed by Neumann and Spokoiny <ref> [69] </ref>, where a risk equivalence between some non-Gaussian regression models and Gaussian white noise models is established. The threshold fl n does not exist in analytical form but a numerical approximation for a range of sample sizes are given in Donoho and Johnstone [33].
Reference: [70] <author> Ogden, T. R. </author> <year> (1996). </year> <title> Essential wavelets for statistical applications and data analysis. </title> <publisher> Birkhauser, Basel. </publisher>
Reference-contexts: Their mean-squared errors are asymptotically dominated by bias. To address this problem, Donoho and Johnstone [35] look at a variant with level-dependent thresholds. The method, called Sureshrink employs an unbiased risk estimation that is due to Stein [78] and is shown in Ogden <ref> [70] </ref> to be in relation with Akaike's information criterion (AIC), introduced by Akaike for times series modeling. <p> Other data-driven methods for the choice of the smoothing parameter (s) in thresholding wavelet estimators have also been proposed in the literature. For a detailed account and description of these methods the reader is referred to the papers by Nason ([66], [65]) or the book by Ogden <ref> [70] </ref>. 4.2 Density estimation Nonlinear wavelet-based density estimators in the i.i.d. setting were introduced by John-stone et al. [54] and Donoho et al. [38] and parallel exactly the results obtained for the regression case, although the proofs are entirely different.
Reference: [71] <author> Oudshoorn, C. </author> <year> (1994). </year> <title> Wavelet-based nonparametric regression: optimal rate in the sup-norm. </title> <type> Technical report 848, </type> <institution> University Utrecht. </institution> <month> 32 </month>
Reference-contexts: A more elementary and transparent proof of his result is also given in the paper of Oudshoorn <ref> [71] </ref>. This result is interesting because it shows that with linear wavelet estimators one can attain minimimax rates for sup-norm loss. 13 3.2 Nonparametric density estimation The estimation of probability density functions from data is another example of basic problems in applied statistics.
Reference: [72] <author> Penev, S. and Dechevsky, L. </author> <year> (1997). </year> <title> On non-negative wavelet-based estima-tors. </title> <type> Technical report, </type> <institution> University of New South Wales. </institution> <note> To appear in J. </note> <institution> of Nonparam. Statistics. </institution>
Reference-contexts: To avoid negative values of the estimates Pinheiro and Vidakovic's [73] idea was used. Along the same lines, but using a different approach and different estimators, is the research completed by Penev & Dechevsky <ref> [72] </ref>. Since their method deals principally with nonlinear thresholding methods, it will be discussed in the next Section. 4 Nonlinear wavelet methods for curve estimation In the previous section the nonparametric estimation of regression functions and probability density functions has been restricted to the context of linear wavelet-based estimators. <p> Note, however, that when p ! 1, Masry [61] has shown that this rate is attained by linear estimators and thus nonlinear estimators do not improve the rate of convergence in this case. We have already mentioned the approach taken by Penev and Dechevsky <ref> [72] </ref>, to estimate first by wavelet methods the square root of the density before taking its square as the final estimate, in order to preserve the non-negativity while still retaining the asymptotic minimax properties.
Reference: [73] <author> Pinheiro, A. and Vidakovic, B. </author> <year> (1995). </year> <title> Estimating the square root of a density via compactly supported wavelets. </title> <type> Technical report DP 95-14, </type> <institution> Duke University. </institution>
Reference-contexts: The idea of the above transformation can be found in Good & Gaskins [46] in the context of penalized likelihood methods. The condition R f (x)dx = 1 becomes R p f (x)) 1=2 dx = 1, so that p f 2 L 2 . Pinheiro and Vidakovic <ref> [73] </ref> do exploit this idea of estimating the square root of the density in a wavelet setting, but, in order to get estimators of the needed wavelet coefficients they use a rough but consistent pre-estimator of the unknown density. <p> To avoid negative values of the estimates Pinheiro and Vidakovic's <ref> [73] </ref> idea was used. Along the same lines, but using a different approach and different estimators, is the research completed by Penev & Dechevsky [72]. <p> The advantage of the estimate they propose is that it can be normed to integrate to 1 very easily without numerical integration. Some data dependent methods for choosing J 0 (Tribouley [82]) and j have been proposed by Pinheiro and Vidakovic <ref> [73] </ref> and more recently by Vannucci and Vidakovic [83]. 5 Related topics The regression models discussed in the previous sections involve additive white noise of constant level, no weighting and most of the time normality. Antoniadis and Lavergne [9] extend the linear wavelet-based methods to data with heteroscedastic noise.
Reference: [74] <author> Potier, C. and Vercken, C. </author> <year> (1994). </year> <title> Spline fitting Numerous Noisy Data with discontinuities. </title> <editor> In Laurent et al. (eds.), </editor> <booktitle> Curves and Surfaces, </booktitle> <pages> pp. 477-480, </pages> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: Wavelet methods for detecting and locating the jump points can be found in Vercken and Potier <ref> [74] </ref>, Wang [89] and more recently in Antoniadis and Gijbels [13] and the thesis of Raimondo [75]. 25 Applications of wavelet decompositions in statistical hypothesis testing and model selection appear in particular Fan [42] and Antoniadis et al. [11].
Reference: [75] <author> Raimondo, M. </author> <year> (1996). </year> <editor> Situations non ergodiques et utilisations de methodes d'ondelettes. Ph. D. </editor> <booktitle> Thesis, </booktitle> <address> University Paris 7. </address>
Reference-contexts: Wavelet methods for detecting and locating the jump points can be found in Vercken and Potier [74], Wang [89] and more recently in Antoniadis and Gijbels [13] and the thesis of Raimondo <ref> [75] </ref>. 25 Applications of wavelet decompositions in statistical hypothesis testing and model selection appear in particular Fan [42] and Antoniadis et al. [11].
Reference: [76] <author> Ramlau-Hansen, H. </author> <year> (1983). </year> <title> Smoothing counting processes by means of kernel functions. </title> <journal> Ann. Statist. </journal> <volume> 11, </volume> <pages> 453-466. </pages>
Reference: [77] <author> Saito, N. </author> <year> (1994). </year> <title> Simultaneous noise suppression and signal compression using a library of orthonormal bases and the minimum description length criterion. </title> <editor> In Foufoula-Georgiou, E. and Kumar, P. (eds), </editor> <booktitle> Wavelets in Geophysics, </booktitle> <publisher> Academic Press, </publisher> <address> New York. </address>
Reference-contexts: Some results on adaptative model selection using wavelet packets for white noise models already exist (see for example the papers by Donoho and Johnstone [34] and Saito <ref> [77] </ref>) but their extension to other types of noise are desirable. Many results in higher dimensions are still incomplete.
Reference: [78] <author> Stein, C. </author> <year> (1981). </year> <title> Estimation of the mean of a multivariate normal distribution. </title> <journal> Ann. Statist. </journal> <volume> 10, </volume> <pages> 1135-1151. </pages>
Reference-contexts: Their mean-squared errors are asymptotically dominated by bias. To address this problem, Donoho and Johnstone [35] look at a variant with level-dependent thresholds. The method, called Sureshrink employs an unbiased risk estimation that is due to Stein <ref> [78] </ref> and is shown in Ogden [70] to be in relation with Akaike's information criterion (AIC), introduced by Akaike for times series modeling.
Reference: [79] <author> Sweldens, W. </author> <year> (1996). </year> <title> The lifting scheme: A custom-design construction of biorthogonal wavelets. </title> <booktitle> Applied and Comp. Harmonic Analysis 3, </booktitle> <pages> 186-200. </pages>
Reference-contexts: methods "naturally" to the general nonparametric regression setting. 26 A possibility to deal with non-uniform stochastic design would be to apply a discrete wavelet transform for unequally spaced data based on a basis particularly adapted to the irregular grid and constructed via the lifting scheme recently proposed by Sweldens ([80], <ref> [79] </ref>). Here one entirely abandons the idea of translation and dilation. This gives extra flexibility which can be used to construct wavelets adapted to irregular samples.
Reference: [80] <author> Sweldens, W. </author> <year> (1996). </year> <title> The lifting scheme: A construction of second generation wavelets. </title> <type> Technical report 1995:6, </type> <institution> Industrial Mathematics Initiative, Department of Mathematics, University of South Carolina. </institution>
Reference: [81] <author> Triebel, H. </author> <year> (1992). </year> <title> Theory of function spaces II.. </title> <publisher> Birkhauser, Basel. </publisher>
Reference-contexts: For a more detailed study we refer to Triebel <ref> [81] </ref>. We restrict the consideration to the range of parameters 1 p; q 1, s &gt; 0 and denote the respective Besov space by B s pq = B s pq (R). <p> An important fact is that Besov spaces can also be defined on the interval [0; 1] (see Triebel <ref> [81] </ref>).
Reference: [82] <author> Tribouley, K. </author> <year> (1995). </year> <title> Practical estimation of multivariate densities using wavelet methods. </title> <booktitle> Statistica Neerlandica 49, </booktitle> <pages> 41-62. </pages>
Reference-contexts: The level J chosen by Walter is the one at which the estimated error increases most rapidly when moving from a level to the next coarser. Another method that is considered to be optimal with respect to the IMSE criterion is the one discussed by Tribouley <ref> [82] </ref>. <p> The advantage of the estimate they propose is that it can be normed to integrate to 1 very easily without numerical integration. Some data dependent methods for choosing J 0 (Tribouley <ref> [82] </ref>) and j have been proposed by Pinheiro and Vidakovic [73] and more recently by Vannucci and Vidakovic [83]. 5 Related topics The regression models discussed in the previous sections involve additive white noise of constant level, no weighting and most of the time normality.
Reference: [83] <author> Vannucci, M. and Vidakovic, B. </author> <year> (1995). </year> <title> Preventing the Dirac disaster: wavelet based density estimation. </title> <type> Technical report DP 95-24, </type> <institution> Duke University. </institution>
Reference-contexts: are compactly supported within a known interval ]a; b [ and that are continuously differentiable, a method for choosing J involving the Fisher functional of the density f , defined by F (f ) = R f (t) d f (t) dt has been introduced recently by Vannuci and Vidakovic <ref> [83] </ref>. <p> The advantage of the estimate they propose is that it can be normed to integrate to 1 very easily without numerical integration. Some data dependent methods for choosing J 0 (Tribouley [82]) and j have been proposed by Pinheiro and Vidakovic [73] and more recently by Vannucci and Vidakovic <ref> [83] </ref>. 5 Related topics The regression models discussed in the previous sections involve additive white noise of constant level, no weighting and most of the time normality. Antoniadis and Lavergne [9] extend the linear wavelet-based methods to data with heteroscedastic noise.
Reference: [84] <author> Vidakovic, B. </author> <year> (1994). </year> <title> Nonlinear wavelet shrinkage with Bayes rules and Bayes factors. </title> <type> Technical report DP 94-24, </type> <institution> Duke University. </institution> <note> 33 [85] von Sachs, </note> <author> R. and Schneider, K. </author> <year> (1996). </year> <title> Wavelet smoothing of evolutionary spectra by nonlinear thresholding. </title> <booktitle> Applied and Comp. Harmonic Analysis 3(3), </booktitle> <pages> 268-282. </pages>
Reference-contexts: To end this section, let us mention some bayesian methods that have been proposed recently for nonparametric curve estimation, since they offer an interesting and useful alternative to the methods discussed earlier. In Vidakovic <ref> [84] </ref>, the wavelet coefficients fi j;k in the decomposition (17) as well as the unknown standard deviation oe of the noise are assumed to be independent random variables with an imposed prior distribution.
Reference: [86] <author> Wahba, G. </author> <year> (1990). </year> <title> Spline models for observational data. </title> <booktitle> CBMS-NSF regional conferences series in applied mathematics. </booktitle> <publisher> SIAM, </publisher> <address> Philadelphia. </address>
Reference-contexts: defined to be that function with square integrable th derivative which minimizes over the Sobolev space H [0; 1] the "discrete" functional: 1 n1 X (Y i g (t i )) + 0 g () (t) dt; where g () indicates the th derivative of g (see for example Wahba <ref> [86] </ref>). The "curvature" term R 1 i j 2 dt is a penalty term for lack of smoothness.
Reference: [87] <author> Walter, G. G. </author> <year> (1992). </year> <title> Approximation of the Delta Function by Wavelets. </title> <journal> J. Approx. Theory. </journal> <volume> 71, </volume> <pages> 329-343. </pages>
Reference-contexts: [67]) or S+Wavelets (Bruce & Gao [18]) or in the Matlab package WaveLab (Buckheit et al. [21]). 8 3 Linear wavelet methods for curve estimation Among the first to consider (linear) wavelet methods in statistics are Doukhan and Leon [40], Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter <ref> [87] </ref> for density estimation and Doukhan and Leon [40], Antoniadis, Gregoire and McKeague [7] for nonparametric regression. <p> The idea to use a wavelet series expansion for the estimation of probability functions was first considered by Doukhan and Leon [40], Antoniadis and Carmona [6], Kerkyacharian and Picard [56] and Walter <ref> [87] </ref>. These works are motivated by the multiresolution decomposition associated with wavelet orthonormal bases and the localized character of wavelet expansions.
Reference: [88] <author> Walter, G. G. </author> <year> (1994). </year> <title> Wavelets and Other Orthogonal Systems with Applications. </title> <publisher> CRC Press, </publisher> <address> Boca Raton, Florida. </address>
Reference-contexts: These works are motivated by the multiresolution decomposition associated with wavelet orthonormal bases and the localized character of wavelet expansions. Specialized versions of histograms constructed via Haar basis decompositions are described in Chapter 12 of Walter <ref> [88] </ref> and some interesting properties of such Haar-based estimators on the interval [0; 1] are discussed in Engel [41]. All these papers assume i.i.d. observations. <p> Several strategies for the automatic choice of the tuning parameter have been suggested in the literature. Walter <ref> [88] </ref> discusses an automatic algorithm to choose the most appropriate level J by using the integrated mean square error criterion IMSE = Z i j 2 The algorithm begins by computing the ^c K;k at a high and non optimal level, estimating the IMSE of the resulting estimate, and then recursively <p> Indeed, it does happens that they are often negative in the tails of the distribution. Moreover there is no easy way to norm the wavelet estimator, except to numerically integrate the estimate in order to work out the norming constant. Walter <ref> [88] </ref> considers estimating the density function indirectly, by using wavelets to estimate the Fourier transform of the density, and then transforming back but he points out that the rate of convergence of such an estimate may be relatively slow.
Reference: [89] <author> Wang, Y. </author> <year> (1995). </year> <title> Jump and Sharp Cusp Detection by wavelets. </title> <journal> Biometrika 82, </journal> <pages> 385-397. </pages>
Reference-contexts: Wavelet methods for detecting and locating the jump points can be found in Vercken and Potier [74], Wang <ref> [89] </ref> and more recently in Antoniadis and Gijbels [13] and the thesis of Raimondo [75]. 25 Applications of wavelet decompositions in statistical hypothesis testing and model selection appear in particular Fan [42] and Antoniadis et al. [11].
Reference: [90] <author> Wang, Y. </author> <year> (1996). </year> <title> Function estimation via wavelet shrinkage for long-memory data. </title> <journal> Ann. Statist. </journal> <volume> 24 (2), </volume> <pages> 466-484. </pages>
Reference-contexts: Brillinger ([16], [17]) also presents some inferential aspects of the wavelet technique far a deterministic signal in the presence of additive stationary non necessarily Gaussian noise. Function estimation for nonparametric regression with long-range dependence errors is studied in Wang <ref> [90] </ref>. Wavelet versions of estimators of a hazard rate function in the context of inference for a counting process multiplicative intensity model have been studied by Antoniadis et al. [7].
Reference: [91] <author> Weyrich, N and Warhola, G. T. </author> <year> (1995). </year> <title> Denoising using wavelets and cross-validation. </title> <editor> In Singh, S. P. (ed), </editor> <booktitle> Approximation Theory, wavelets and applications, NATO ASI series C, </booktitle> <pages> pp. 523-532. </pages>
Reference-contexts: A drawback of this semisoft rule is that it requires two thresholds, thus making threshold selection problems much harder and computationally more expensive for adaptive threshold selection. 23 One way to choose the thresholds is by generalized cross-validation proposed first for nonlinear wavelet series estimators by Weyrich and Warhola <ref> [91] </ref>. Recently, Jansen et al. [53] have shown that, under appropriate conditions, this generalized cross-validation choice is asymptotically optimal, in the sense of yielding asymptotically the threshold that minimizes the expected mean squared error.
Reference: [92] <author> Wickerhauser, M. V. </author> <year> (1994). </year> <title> Adapted Wavelet Analysis: From Theory to Software. AK Peters, </title> <address> Boston. </address> <month> 34 </month>
Reference-contexts: For precise mathematical statements, clear definitions and detailed expositions we refer the reader to Meyer [62], Mallat [58], Daubechies [27], Chui [24], Wickerhauser <ref> [92] </ref>, Cohen and Ryan [26] and Holschneider [52]. 2 2.1 Wavelet analysis Wavelet analysis requires a description of two basic functions, the scaling function '(x) and the wavelet (x). <p> The usual wavelet-based approach can be further enhanced by using wavelet packets, a generalization of wavelet bases (see e.g. Wickerhauser <ref> [92] </ref>). In wavelet packet analysis, a function g is represented as a sum of orthogonal wavelet packet functions W j;b;k at different scales j, oscillations b and location k.
References-found: 91

