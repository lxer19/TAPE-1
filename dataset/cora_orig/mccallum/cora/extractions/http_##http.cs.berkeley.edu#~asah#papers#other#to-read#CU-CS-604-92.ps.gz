URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/CU-CS-604-92.ps.gz
Refering-URL: http://http.cs.berkeley.edu/~asah/papers/other/to-read/
Root-URL: http://www.cs.berkeley.edu
Title: Empirical Measurements of Six Allocation-intensive C Programs  
Author: Benjamin Zorn Dirk Grunwald 
Date: July 1992  
Address: Campus Box #430  Boulder 80309-0430  Boulder  
Affiliation: Department of Computer Science  University of Colorado,  ffi University of Colorado at  
Pubnum: CU-CS-604-92  
Abstract: Technical Report CU-CS-604-92 Department of Computer Science Campus Box 430 University of Colorado Boulder, Colorado 80309 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. P. Batson and R. E. Brundage. </author> <title> Segment sizes and lifetimes in Algol-60 programs. </title> <journal> Communications of the ACM, </journal> <volume> 20(1) </volume> <pages> 36-44, </pages> <month> January </month> <year> 1977. </year>
Reference-contexts: Standish also mentions that Weinstock uses Batson's empirical data in comparing the performance of different DMM algorithms. In a later paper, Batson and Brundage present empirical data about segment sizes and holding times collected from Algol-60 programs <ref> [1] </ref>. More recently, in 1984 Bozman et al [3] compared the performance of a large number of DMM algorithms based on empirical data gathered from several days of execution on several different multiuser operating systems.
Reference: [2] <author> A. P. Batson, S. M. Ju, and D. C. Wood. </author> <title> Measurements of segment size. </title> <journal> Communications of the ACM, </journal> <volume> 13(3) </volume> <pages> 155-159, </pages> <month> March </month> <year> 1970. </year>
Reference-contexts: This empirical data has been used in subsequent DMM measurement studies, some as recent as 1985 [10]. Batson et al present empirical data concerning the distribution of program segment sizes in the B5500 operating system <ref> [2] </ref>. In his book Data Structure Techniques, Standish [11] presents data from Charles Weinstock's thesis [12] showing the distribution of size requests in the BLISS/11 compiler. Standish also mentions that Weinstock uses Batson's empirical data in comparing the performance of different DMM algorithms.
Reference: [3] <author> G. Bozman, W. Buco, T. P. Daly, and W. H. </author> <title> Tetzlaff. </title> <journal> Analysis of free-storage algorithms|revisited. IBM Systems Journal, </journal> <volume> 23(1) </volume> <pages> 44-64, </pages> <year> 1984. </year>
Reference-contexts: Standish also mentions that Weinstock uses Batson's empirical data in comparing the performance of different DMM algorithms. In a later paper, Batson and Brundage present empirical data about segment sizes and holding times collected from Algol-60 programs [1]. More recently, in 1984 Bozman et al <ref> [3] </ref> compared the performance of a large number of DMM algorithms based on empirical data gathered from several days of execution on several different multiuser operating systems.
Reference: [4] <author> R. P. Brent. </author> <title> Efficient implementation of a first-fit strategy for dynamic storage allocation. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> 11(3) </volume> <pages> 388-403, </pages> <month> July </month> <year> 1989. </year>
Reference-contexts: In the paper, they present the empirical data gathered, including the average inter-arrival time and holding time for each of the block sizes allocated. This data represents some of the most complete information published to date, and has been used in a 1989 performance evaluation of DMM algorithms <ref> [4] </ref>. Most recently, DeTreville has published the results of extensive empirical measurements of heap usage in the Topaz computing environment [5]. From this discussion, we can conclude two things. First, empirical measurements of actual programs are valuable in both designing and evaluating DMM algorithms.
Reference: [5] <author> John DeTreville. </author> <title> Heap usage in the Topaz environment. </title> <type> Technical Report 63, </type> <institution> Digital Equipment Corporation System Research Center, </institution> <address> Palo Alto, CA, </address> <month> August </month> <year> 1990. </year>
Reference-contexts: This data represents some of the most complete information published to date, and has been used in a 1989 performance evaluation of DMM algorithms [4]. Most recently, DeTreville has published the results of extensive empirical measurements of heap usage in the Topaz computing environment <ref> [5] </ref>. From this discussion, we can conclude two things. First, empirical measurements of actual programs are valuable in both designing and evaluating DMM algorithms. For as long as these algorithms have been proposed and evaluated, empirical data has been used in the measurement process.
Reference: [6] <author> Dirk Grunwald and Benjamin Zorn. </author> <title> CustoMalloc: Efficient synthesized memory allocators. </title> <type> Technical Report CS-CS-602-92, </type> <institution> Department of Computer Science, University of Colorado, Boulder, Boulder, CO, </institution> <month> July </month> <year> 1992. </year>
Reference-contexts: We have already used these programs for this purpose <ref> [6] </ref>. * Such data provides readers with insight into the allocation behavior of a broad class of programs. <p> Furthermore, 95% of the observed data is covered by at most 34 classes. Algorithms such as Oldehoeft's adaptive exact-fit allocator [10] and our own CustoMalloc <ref> [6] </ref> exploit this empirical behavior by adapting allocation policies to the most commonly observed object sizes. Interestingly, we observe that a small number IAT classes and HT classes also account for a large percentage of the allocation in many of the programs measured.
Reference: [7] <author> Raj Jain. </author> <title> The Art of Computer Systems Performance Evaluation. </title> <publisher> Wiley Professional Computing. John Wiley and Sons, Inc., </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: All times are measured in SPARC machine instructions. The quantile tables show the three distributions are greatly skewed. In particular, the median is a small fraction of the maximum in every case. As Jain points out <ref> [7] </ref>, such a skew suggests that the median value should used as a characterization of the central tendency of these distributions. As we have already seen, because a few small size classes dominate the size distributions of these programs, the quantile plot of object sizes is relatively uninteresting.
Reference: [8] <author> James R. Larus. </author> <title> Abstract execution: A technique for efficiently tracing programs. </title> <journal> Software| Practice and Experience, </journal> 20(12) 1241-1258, December 1990. 
Reference-contexts: In order to simplify the presentation here, we show data from only one of these input data sets. Data from all input sets is publically available via the internet. 3 The data was gathered by tracing the execution of each program using ae <ref> [8] </ref> on a Sun SPARC processor. ae is an efficient program tracing tool that captures all instruction and data references, as well as special indicators for calls to the malloc and free procedures used for memory allocation.
Reference: [9] <author> B. H. Margolin, R. P. Parmelee, and M. Schatzoff. </author> <title> Analysis of free-storage algorithms. </title> <journal> IBM Systems Journal, </journal> <volume> 10(4) </volume> <pages> 283-304, </pages> <year> 1971. </year>
Reference-contexts: This data is valuable to designers of dynamic memory management (DMM) algorithms for the following reasons: * It has been long observed that tailoring a DMM algorithm to the observed empirical behavior of programs results in a more efficient algorithm <ref> [9] </ref>. <p> In addition to comparing the performance of DMM algorithms, a number of these papers also present empirical measurements of the allocation behavior of particular programs or systems. In particular, in 1971 Margolin et al presented empirical measurements of the dynamic allocation patterns they observed in a time-sharing operating system <ref> [9] </ref>. This empirical data has been used in subsequent DMM measurement studies, some as recent as 1985 [10]. Batson et al present empirical data concerning the distribution of program segment sizes in the B5500 operating system [2].
Reference: [10] <author> Rodney R. Oldehoeft and Stephen J. Allan. </author> <title> Adaptive exact-fit storage management. </title> <journal> Communications of the ACM, </journal> <volume> 28(5) </volume> <pages> 506-511, </pages> <month> May </month> <year> 1985. </year>
Reference-contexts: In particular, in 1971 Margolin et al presented empirical measurements of the dynamic allocation patterns they observed in a time-sharing operating system [9]. This empirical data has been used in subsequent DMM measurement studies, some as recent as 1985 <ref> [10] </ref>. Batson et al present empirical data concerning the distribution of program segment sizes in the B5500 operating system [2]. In his book Data Structure Techniques, Standish [11] presents data from Charles Weinstock's thesis [12] showing the distribution of size requests in the BLISS/11 compiler. <p> In particular, Table 3 shows that at most two size classes are required to cover 50% of the observed data in all of the test programs. Furthermore, 95% of the observed data is covered by at most 34 classes. Algorithms such as Oldehoeft's adaptive exact-fit allocator <ref> [10] </ref> and our own CustoMalloc [6] exploit this empirical behavior by adapting allocation policies to the most commonly observed object sizes. Interestingly, we observe that a small number IAT classes and HT classes also account for a large percentage of the allocation in many of the programs measured.
Reference: [11] <author> Thomas Standish. </author> <title> Data Structures Techniques. </title> <publisher> Addison-Wesley Publishing Company, </publisher> <year> 1980. </year> <month> 11 </month>
Reference-contexts: This empirical data has been used in subsequent DMM measurement studies, some as recent as 1985 [10]. Batson et al present empirical data concerning the distribution of program segment sizes in the B5500 operating system [2]. In his book Data Structure Techniques, Standish <ref> [11] </ref> presents data from Charles Weinstock's thesis [12] showing the distribution of size requests in the BLISS/11 compiler. Standish also mentions that Weinstock uses Batson's empirical data in comparing the performance of different DMM algorithms.
Reference: [12] <author> Charles B. Weinstock. </author> <title> Dynamic Storage Allocation Techniques. </title> <type> PhD thesis, </type> <institution> Carnegie Mellon Uni--versity, </institution> <address> Pittsburgh, PA, </address> <year> 1976. </year>
Reference-contexts: Batson et al present empirical data concerning the distribution of program segment sizes in the B5500 operating system [2]. In his book Data Structure Techniques, Standish [11] presents data from Charles Weinstock's thesis <ref> [12] </ref> showing the distribution of size requests in the BLISS/11 compiler. Standish also mentions that Weinstock uses Batson's empirical data in comparing the performance of different DMM algorithms. In a later paper, Batson and Brundage present empirical data about segment sizes and holding times collected from Algol-60 programs [1].
Reference: [13] <author> Benjamin Zorn. </author> <title> The measured cost of conservative garbage collection. </title> <type> Technical Report CU-CS-573-92, </type> <institution> Department of Computer Science, University of Colorado, Boulder, Boulder, CO, </institution> <month> February </month> <year> 1992. </year>
Reference-contexts: This result has implications for generation-based garbage collection algorithms that might be used to collect these objects <ref> [13] </ref>. 4 Summary We have presented data from one input data set for each of the six programs measured. Using the trace extraction and reduction techniques described, we have collected similar data from at least two inputs to each of these programs.
Reference: [14] <author> Benjamin Zorn and Dirk Grunwald. </author> <title> Evaluating models of memory allocation. </title> <type> Technical Report CS-CS-603-92, </type> <institution> Department of Computer Science, University of Colorado, Boulder, Boulder, CO, </institution> <month> July </month> <year> 1992. </year> <month> 12 </month>
Reference-contexts: The intent of this paper is to make additional empirical measurements of allocation-intensive programs widely available. In a companion paper we investigate how different models of allocation behavior, based on empirical data as presented here, can be used to accurately evaluate DMM algorithms <ref> [14] </ref>. The remainder of this paper has the following organization: Section 2 describes the programs we have measured and Section 3 presents empirical measures of the programs, including distribution of object sizes, object holding times, and object interarrival times. <p> Using the trace extraction and reduction techniques described, we have collected similar data from at least two inputs to each of these programs. We have also collected other statistical characterizations of the test programs and compared the accuracy of different synthetic models of program allocation in a companion paper <ref> [14] </ref>. All of the collected data has been formated as a C program input file with declarations of the distributions of object size, holding time, etc. These C files can easily be compiled and linked with a program intended to manipulate the data.
References-found: 14

