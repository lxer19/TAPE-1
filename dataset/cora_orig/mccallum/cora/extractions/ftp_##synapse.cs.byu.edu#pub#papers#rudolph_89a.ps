URL: ftp://synapse.cs.byu.edu/pub/papers/rudolph_89a.ps
Refering-URL: ftp://synapse.cs.byu.edu/pub/papers/details.html
Root-URL: 
Title: DNA: A New ASOCS Model With Improved Implementation Potential  
Author: George L. Rudolph and Tony R. Martinez 
Address: Provo, Utah 84602  
Affiliation: Department of Computer Science Brigham Young University  
Note: In Proceedings of the IASTED International Symposium on Expert Systems and Neural Networks, pp. 12-15, 1989.  
Abstract: A new class of highspeed, self-adaptive, massively parallel computing models called ASOCS (Adaptive Self-Organizing Concurrent Systems) has been proposed. Current analysis suggests that there may be problems implementing ASOCS models in VLSI using the hierarchical network structures originally proposed. The problems are not inherent in the models, but rather in the technology used to implement them. This has led to the development of a new ASOCS model called DNA (Discriminant-Node ASOCS) that does not depend on a hierarchical node structure for success. Three areas of the DNA model are briefly discussed in this paper: DNA's flexible nodes, how DNA overcomes problems other models have allocating unused nodes, and how DNA operates during processing and learning. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Chang, J. and J.J. Vidal., </author> <title> "Inferencing in Hardware," </title> <booktitle> Proceedings of the MCC University Research Symposium, </booktitle> <address> Austin TX. </address> <month> July </month> <year> 1987. </year>
Reference-contexts: These present neural networks with fast, well-bounded learning algorithms using simple, asynchronous digital nodes [4] - [7]. One area of current ASOCS research focusses on building VLSI implementations of ASOCS using current technology. Chang and Vidal describe one possible implementation of an ASOCS model in <ref> [1] </ref>. More recent analysis of ASOCS shows that current ASOCS models may make inefficient use of limited network resources. This is not due to a problem inherent in the models, but in VLSI implementation.
Reference: [2] <author> Feng, Tse-yun, </author> <title> "A Survey of Interconnection Networks," </title> <journal> Computer, </journal> <volume> Vol. 14, #12. </volume> <pages> pp. 12-27. </pages> <month> December </month> <year> 1981. </year>
Reference-contexts: This distinguishes it from all previous models. Even though DNA is different, it still uses the ASOCS learning paradigm. Hence the name "Discriminant-Node ASOCS", or DNA. 4 Logic Gate . . . . . . Fig. 1 - General Structure of ASOCS node Both dynamic and static interconnect schemes <ref> [2] </ref> are found among current ASOCS models [3]. In considering a VLSI implementation of these hierarchical models, a problem associated with allocating unused nodes efficiently arises because the technology does not fit the models.
Reference: [3] <author> Martinez, T.R., </author> <title> Adaptive Self-Organizing Logic Networks., </title> <institution> UCLA, Ph.D.Dissertation. </institution> <month> May </month> <year> 1986. </year>
Reference-contexts: Introduction. A new class of highspeed, massively parallel, adaptive computational models called ASOCS (Adaptive Self-Organizing Concurrent System) has been proposed <ref> [3] </ref>. These present neural networks with fast, well-bounded learning algorithms using simple, asynchronous digital nodes [4] - [7]. One area of current ASOCS research focusses on building VLSI implementations of ASOCS using current technology. Chang and Vidal describe one possible implementation of an ASOCS model in [1]. <p> For simplicity, the instances presented in the discussion will be limited to a single output variable (i.e. all outputs will be Z or Z' only). Implementing multiple outputs is an easy extension of the ideas presented here <ref> [3] </ref>, but will not be addressed. The collection of instances presented to the network is the instance set. The instance set is not stored explicitly in most models. <p> It has been shown that the number of instance sets that potentially represent the same functional information is infinite, and that therefore instance sets are not unique <ref> [3] </ref>. Furthermore, internal representations for the same instance set are diferent for different models. A network is said to fulfill a given instance set when the function it computes matches that specified by tthat instance set. <p> Even though DNA is different, it still uses the ASOCS learning paradigm. Hence the name "Discriminant-Node ASOCS", or DNA. 4 Logic Gate . . . . . . Fig. 1 - General Structure of ASOCS node Both dynamic and static interconnect schemes [2] are found among current ASOCS models <ref> [3] </ref>. In considering a VLSI implementation of these hierarchical models, a problem associated with allocating unused nodes efficiently arises because the technology does not fit the models. <p> Each node, independent of all others, determines whether or not it matches the inputs, and thus whether or not to put its outputs on the output bus. Since the representation of a given instance set is consistent, the outputs will always be consistent <ref> [3] </ref>. In the case that the input is matched by no node, two choices are available: either the network can output a "don't know" state, or choose the output for the instance that most closely matches the input.
Reference: [4] <author> Martinez, T.R., </author> <title> "Models of Parallel Adaptive Logic," </title> <booktitle> Proceedings of the 1987IEEE Systems Man and Cybernetics Conference, </booktitle> <address> pp.290-296, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: Introduction. A new class of highspeed, massively parallel, adaptive computational models called ASOCS (Adaptive Self-Organizing Concurrent System) has been proposed [3]. These present neural networks with fast, well-bounded learning algorithms using simple, asynchronous digital nodes <ref> [4] </ref> - [7]. One area of current ASOCS research focusses on building VLSI implementations of ASOCS using current technology. Chang and Vidal describe one possible implementation of an ASOCS model in [1]. More recent analysis of ASOCS shows that current ASOCS models may make inefficient use of limited network resources.
Reference: [5] <author> Martinez, T.R., J.J. Vidal, </author> <title> "Adaptive Parallel Logic Networks," </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> Vol. 5, #1, </volume> <pages> pp. 26-58, </pages> <year> 1988. </year>
Reference: [6] <author> Martinez, T.R., </author> <title> "Digital Neural Networks," </title> <booktitle> Proceedings of the 1988 IEEE Systems Man and Cybernetics Conference, </booktitle> <pages> pp. 681-684, </pages> <month> August </month> <year> 1988. </year>
Reference: [7] <author> Martinez, T.R., </author> <title> "Memory Efficient Adaptive Logic," </title> <note> submitted. </note>
Reference-contexts: Introduction. A new class of highspeed, massively parallel, adaptive computational models called ASOCS (Adaptive Self-Organizing Concurrent System) has been proposed [3]. These present neural networks with fast, well-bounded learning algorithms using simple, asynchronous digital nodes [4] - <ref> [7] </ref>. One area of current ASOCS research focusses on building VLSI implementations of ASOCS using current technology. Chang and Vidal describe one possible implementation of an ASOCS model in [1]. More recent analysis of ASOCS shows that current ASOCS models may make inefficient use of limited network resources.
References-found: 7

