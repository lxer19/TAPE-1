URL: http://www.cs.ubc.ca/spider/cebly/Papers/noisy.ps
Refering-URL: http://www.cs.ubc.ca/spider/cebly/papers.html
Root-URL: 
Email: cebly@cs.ubc.ca  nir@cs.berkeley.edu  halpern@cs.cornell.edu  
Title: Belief Revision with Unreliable Observations  
Author: Craig Boutilier Nir Friedman yz Joseph Y. Halpern 
Address: Canada, V6T 1W5  387 Soda Hall  Berkeley, CA 94720  Ithaca, NY 14850  
Affiliation: Dept. Computer Science University of British Columbia Vancouver, British Columbia  Computer Science Division  University of California  Dept. Computer Science Cornell University  
Abstract: Research in belief revision has been dominated by work that lies firmly within the classic AGM paradigm, characterized by a well-known set of postulates governing the behavior of rational revision functions. A postulate that is rarely criticized is the success postulate: the result of revising by an observed proposition ' results in belief in '. This postulate, however, is often undesirable in settings where an agent's observations may be imprecise or noisy. We propose a semantics that captures a new ontology for studying revision functions, which can handle noisy observations in a natural way while retaining the classical AGM model as a special case. We present a characterization theorem for our semantics, and describe a number of natural special cases that allow ease of specification and reasoning with revision functions. In particular, by making the Markov assumption, we can easily specify and reason about revision. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> E. W. Adams. </author> <title> The Logic of Conditionals. </title> <address> D.Reidel, </address> <year> 1975. </year>
Reference-contexts: In fact, a -ranking can be interpreted as a semi-qualitative probability distribution. Using the "-semantics of Adams <ref> [1] </ref>, Goldszmidt and Pearl [19] show how one can interpret the values of propositions as order of magnitude probabilities.
Reference: [2] <author> C. Alchourron, P. Gardenfors, and D. Makinson. </author> <title> On the logic of theory change: Partial meet contraction and revision functions. </title> <journal> J. Sym. Logic, </journal> <volume> 50 </volume> <pages> 510-530, </pages> <year> 1985. </year>
Reference-contexts: One of the best known and most studied theories of belief change is the classic AGM theory of belief revision of Alchourron, Gardenfors and Makinson <ref> [2, 18] </ref>.
Reference: [3] <author> K. J. Astrom. </author> <title> Optimal Control of Markov Decision Processes with Incomplete State Estimation. </title> <journal> J. Math. Analysis and Applications, </journal> <volume> 10 </volume> <pages> 174-205, </pages> <year> 1965. </year>
Reference-contexts: In this sense, our proposal has more in common with probabilistic observation models that are standard in decision and control theory <ref> [3, 24] </ref>. A general way of thinking about iterated revision is not to think of revision functions as mapping from (belief set, observation) pairs to belief sets, but as mapping from finite observation sequences to belief sets. More precisely, assume that an agent's observations are drawn from language L. <p> It is also adopted implicitly in much work in reasoning about action, planning, control and probabilistic inference with respect to system dynamics. Although it plays a key role in the observation models adopted in control theory and probabilistic reasoning <ref> [3, 24] </ref>, it has received little attention in this respect within the qualitative planning literature. The Markov assumption is also very powerful, allowing us to specify a ranking over runs relatively compactly.
Reference: [4] <author> C. Boutilier. Normative, </author> <title> subjunctive and autoepistemic defaults: Adopting the Ramsey test. </title> <booktitle> In Proc. 3rd Inter. Conf. on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 685-696, </pages> <year> 1992. </year>
Reference-contexts: Recent years have seen many extensions and refinements of the AGM paradigm, including the distinction between revision and update [23, 32], the proposal of models that combine the two [8, 15], and the acceptance of the notion that epistemic states are much richer than simple belief sets <ref> [4, 17, 27, 29] </ref>. fl This work was supported by NSERC Research Grant OGP0121843 and IRIS-II Project IC-7, and was undertaken while the author was visiting the University of Toronto. <p> We insist that 1 (0) 6= ;, so that maximally plausible worlds are assigned rank 0. If (w) = 1, we say w is impossible. If U W , then (U ) = min u2U (u). Following <ref> [4, 16, 27, 29] </ref>, we distinguish the agent's epis-temic state from its belief set. We define the form of the epistemic state carefully in Section 3. For now we simply require that it includes a ranking . <p> It has been remarked by a number of authors that models of revision based on epistemic entrenchment or -rankings are not strong enough to adequately capture iterated revision <ref> [4, 16, 27, 29] </ref>. Specifically, while these models determine the content of a new belief set when ' is observed, given an epistemic state, they do not determine the new epistemic state (or ranking) associated with the new belief set.
Reference: [5] <author> C. Boutilier. </author> <title> Unifying default reasoning and belief revision in a modal framework. </title> <journal> Artificial Intelligence, </journal> <volume> 68 </volume> <pages> 33-85, </pages> <year> 1994. </year>
Reference-contexts: Semantically, an entrenchment relation (hence a revision function) can be modeled by associating with each set of possible worlds a plausibility, in any of a number of ways <ref> [5, 10, 17, 20] </ref>. For the purposes of this paper, we adopt Spohn's ordinal conditional functions or -rankings [19, 31]. A function : W ! N [ f1g assigns to each world a ranking reflecting its plausibility: if (w) &lt; (v) then w is more plausible than v. <p> It is normally assumed that [[']] " W 6= ; for every satisfiable ' thus every satisfiable proposition is accorded some degree of plausibility. It is well-known that this type of model induces the class of revision functions sanctioned by the AGM postulates <ref> [5, 19, 20] </ref>. We define conditional plausibility, for U; V W and (U ) 6= 1, as: Intuitively, this denotes the degree to which V would be considered plausible if U were believed. These notions are strongly reminiscent of standard concepts from probability theory.
Reference: [6] <author> C. Boutilier. </author> <title> Generalized update: Belief change in dynamic settings. </title> <booktitle> In Proc. 14th Inter. Joint Conf. on AI, </booktitle> <pages> pp. 1550-1556, </pages> <year> 1995. </year>
Reference-contexts: Two proposals impact strongly on this paper. Friedman and Halpern [16] use interpreted systems to model both revision and update, and examine the Markov assumption in this context. Boutilier <ref> [6, 8] </ref> develops a less general model for revision and update (taking the Markov assumption as given) and considers several methods for modeling noisy observations. All of this work (with the exception of [8]) essentially takes the success postulate as a given.
Reference: [7] <author> C. Boutilier. </author> <title> Iterated revision and minimal revision of conditional beliefs. </title> <journal> J. Phil. Logic, </journal> <volume> 25(3) </volume> <pages> 262-305, </pages> <year> 1996. </year>
Reference-contexts: To deal with iteration semantically, we need a way of determining a new epistemic state, given an observation <ref> [7, 9, 26, 30] </ref>. Spohn's conditioning operation [31] does just this. When an observation ' is made, all :'-worlds are deemed impossible and removed from the ranking (or set to 1).
Reference: [8] <author> C. Boutilier. </author> <title> A unified model of qualitative belief change: A dynamical systems perspective. </title> <journal> Artificial Intelligence, </journal> <volume> 98(1-2):281-316, </volume> <year> 1998. </year>
Reference-contexts: Recent years have seen many extensions and refinements of the AGM paradigm, including the distinction between revision and update [23, 32], the proposal of models that combine the two <ref> [8, 15] </ref>, and the acceptance of the notion that epistemic states are much richer than simple belief sets [4, 17, 27, 29]. fl This work was supported by NSERC Research Grant OGP0121843 and IRIS-II Project IC-7, and was undertaken while the author was visiting the University of Toronto. <p> Of course, the relationship between the propositions that talk about the robot's sensors and more interesting propositions that talk about what is actually true in the external world must be modeled if the robot is to draw useful inferences <ref> [8] </ref>. The relationship will generally be complicated because of sensor noise, unreliability, and so on. One may instead wish to model a situation of this type by assuming the robot can directly observe the truth values of external propositions, but that these direct observations may be corrupted. <p> Two proposals impact strongly on this paper. Friedman and Halpern [16] use interpreted systems to model both revision and update, and examine the Markov assumption in this context. Boutilier <ref> [6, 8] </ref> develops a less general model for revision and update (taking the Markov assumption as given) and considers several methods for modeling noisy observations. All of this work (with the exception of [8]) essentially takes the success postulate as a given. <p> Boutilier [6, 8] develops a less general model for revision and update (taking the Markov assumption as given) and considers several methods for modeling noisy observations. All of this work (with the exception of <ref> [8] </ref>) essentially takes the success postulate as a given. Spohn's method of ff-conditioning [31], a generalization of the notion of conditioning rankings defined above, was one of the first revision models to explicitly account for strength of evidence.
Reference: [9] <author> A. Darwiche and J. Pearl. </author> <title> On the logic of iterated belief revision. </title> <journal> Artificial Intelligence, </journal> <volume> 89 </volume> <pages> 1-29, </pages> <year> 1997. </year>
Reference-contexts: To deal with iteration semantically, we need a way of determining a new epistemic state, given an observation <ref> [7, 9, 26, 30] </ref>. Spohn's conditioning operation [31] does just this. When an observation ' is made, all :'-worlds are deemed impossible and removed from the ranking (or set to 1).
Reference: [10] <author> D. Dubois and H. Prade. </author> <title> Belief change and possibility theory. </title> <editor> In Peter Gardenfors, ed., </editor> <title> Belief Revision. </title> <publisher> Cambridge University Press, </publisher> <year> 1992. </year>
Reference-contexts: Semantically, an entrenchment relation (hence a revision function) can be modeled by associating with each set of possible worlds a plausibility, in any of a number of ways <ref> [5, 10, 17, 20] </ref>. For the purposes of this paper, we adopt Spohn's ordinal conditional functions or -rankings [19, 31]. A function : W ! N [ f1g assigns to each world a ranking reflecting its plausibility: if (w) &lt; (v) then w is more plausible than v.
Reference: [11] <author> D. Dubois and H. Prade. </author> <title> Belief revision with uncertain inputs in the possibilistic setting. </title> <booktitle> In Proc. 12th Conf. on Uncertainty in AI, </booktitle> <pages> pp. 236-243, </pages> <year> 1996. </year>
Reference-contexts: Indeed, it is remarkable how little work is needed to apply these intuitions in a qualitative setting. This emphasizes how small the gap is between belief revision and probability kinematics. We note, however, that our model differs from qualitative adaptations of Jef-frey's Rule [22] devised for belief revision <ref> [11, 19, 31] </ref> (see Section 2 for further discussion). The rest of this paper is organized as follows. In Section 2, we discuss the AGM model, and describe generalized revision functions for dealing with sequences of observations. <p> Rather than accepting an observed proposition ' with certainty, ' is accepted with degree ff, with :'-worlds retaining a certain plausibility. This model can be viewed as a way of dealing with noisy observations (and has been developed further in <ref> [11, 19] </ref>). In fact, this model is a qualitative analogue of Jeffrey's Rule [22] for probabilistic belief update. Jeffrey's rule is a generalization of conditioning where a piece of evidence can be accepted with a given probability.
Reference: [12] <author> R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. </author> <title> Reasoning about Knowledge. </title> <publisher> MIT Press, </publisher> <year> 1995. </year>
Reference-contexts: The framework is essentially that of Friedman and Halpern [17, 16], which in turn is based on the multi-agent framework of [21]. We briefly review the details here; further discussion and motivation can be found in <ref> [12] </ref>. The key assumption in the multi-agent system framework is that we can characterize the system by describing it in terms of a state that changes over time. Formally, we assume that at each point in time, the agent is in some local state. <p> : ; ' m i, then ' 1 ^ : : : ^ ' m is true 4 Observation systems are a special case of the belief change systems considered in [13, 16]. 5 This is analogous to the assumption of perfect recall in game theory [28] and distributed computing <ref> [12] </ref>. according to the truth assignment at r e (m). This requirement forces the observations to be accurate; if ' is observed, then it must be true of the world. It is precisely this requirement that we drop here to allow for noisy observations.
Reference: [13] <author> N. Friedman. </author> <title> Modeling Beliefs in Dynamic Systems. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <year> 1997. </year>
Reference-contexts: OSs: it is required that, in any run r, if r a (m) = h' 1 ; : : : ; ' m i, then ' 1 ^ : : : ^ ' m is true 4 Observation systems are a special case of the belief change systems considered in <ref> [13, 16] </ref>. 5 This is analogous to the assumption of perfect recall in game theory [28] and distributed computing [12]. according to the truth assignment at r e (m). This requirement forces the observations to be accurate; if ' is observed, then it must be true of the world.
Reference: [14] <author> N. Friedman and J. Y. Halpern. </author> <title> Belief revision: A critique. </title> <booktitle> In Proc. 6th Inter. Conf. on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 421-431, </pages> <year> 1996. </year>
Reference-contexts: Copyright 1998, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. All of these advances can be viewed as refinements of the AGM paradigm, for none contradict the basic, ifin retrospectsomewhat limited, view of revision profferred by AGM. However, as noted in <ref> [14] </ref>, there are reasons to question some of their rationality postulates, even some that have been viewed as beyond controversy. <p> Generally, this requires that, in order to accept ', the agent give up some of its old beliefs to remain consistent. As argued in <ref> [14] </ref>, to justify the success postulate (or any other postulate), we must carefully consider the particular process we hope to characterize as well as the ontology adopted in that characterization. Gardenfors [18] provides one interpretation of belief revision for which the success postulate is appropriate.
Reference: [15] <author> N. Friedman and J. Y. Halpern. </author> <title> A qualitative Markov assumption and its implications for belief change. </title> <booktitle> In Proc. 12th Conf. on Uncertainty in AI, </booktitle> <pages> pp. 263-273, </pages> <year> 1996. </year>
Reference-contexts: Recent years have seen many extensions and refinements of the AGM paradigm, including the distinction between revision and update [23, 32], the proposal of models that combine the two <ref> [8, 15] </ref>, and the acceptance of the notion that epistemic states are much richer than simple belief sets [4, 17, 27, 29]. fl This work was supported by NSERC Research Grant OGP0121843 and IRIS-II Project IC-7, and was undertaken while the author was visiting the University of Toronto.
Reference: [16] <author> N. Friedman and J. Y. Halpern. </author> <title> Modeling belief in dynamic systems. Part II: revision and update. </title> <note> Submitted for publication. A preliminary version appears in Proc. </note> <editor> 4th Inter. </editor> <booktitle> Conf. on Principles of Knowledge Representation and Reasoning, </booktitle> <year> 1994, </year> <pages> pp. 190-201. </pages>
Reference-contexts: The rest of this paper is organized as follows. In Section 2, we discuss the AGM model, and describe generalized revision functions for dealing with sequences of observations. In Section 3, we present our basic framework, which is taken from Friedman and Halpern <ref> [16, 17] </ref>. We define observation systems that allow unreliable observations, show how conditioning can be used to effect belief revision, and characterize the class of generalized revision functions determined by observation systems. <p> We insist that 1 (0) 6= ;, so that maximally plausible worlds are assigned rank 0. If (w) = 1, we say w is impossible. If U W , then (U ) = min u2U (u). Following <ref> [4, 16, 27, 29] </ref>, we distinguish the agent's epis-temic state from its belief set. We define the form of the epistemic state carefully in Section 3. For now we simply require that it includes a ranking . <p> It has been remarked by a number of authors that models of revision based on epistemic entrenchment or -rankings are not strong enough to adequately capture iterated revision <ref> [4, 16, 27, 29] </ref>. Specifically, while these models determine the content of a new belief set when ' is observed, given an epistemic state, they do not determine the new epistemic state (or ranking) associated with the new belief set. <p> The framework is essentially that of Friedman and Halpern <ref> [17, 16] </ref>, which in turn is based on the multi-agent framework of [21]. We briefly review the details here; further discussion and motivation can be found in [12]. <p> We stress again the difference between [[Obs m The former is the event of observing at time m; the latter is the event of being true. In the analysis of the AGM framework in <ref> [16] </ref>, an extra requirement is placed on OSs: it is required that, in any run r, if r a (m) = h' 1 ; : : : ; ' m i, then ' 1 ^ : : : ^ ' m is true 4 Observation systems are a special case of <p> OSs: it is required that, in any run r, if r a (m) = h' 1 ; : : : ; ' m i, then ' 1 ^ : : : ^ ' m is true 4 Observation systems are a special case of the belief change systems considered in <ref> [13, 16] </ref>. 5 This is analogous to the assumption of perfect recall in game theory [28] and distributed computing [12]. according to the truth assignment at r e (m). This requirement forces the observations to be accurate; if ' is observed, then it must be true of the world. <p> There is considerable related work that we survey in detail in a longer version of this paper. Lehmann [26] describes a model where observation sequences are treated as epis-temic states in order to deal effectively with iterated revision. Two proposals impact strongly on this paper. Friedman and Halpern <ref> [16] </ref> use interpreted systems to model both revision and update, and examine the Markov assumption in this context. Boutilier [6, 8] develops a less general model for revision and update (taking the Markov assumption as given) and considers several methods for modeling noisy observations.
Reference: [17] <author> N. Friedman and J. Y. Halpern. </author> <title> Modeling beliefs in dynamic systems. part I: Foundations. </title> <journal> Artificial Intelligence, </journal> <volume> 95 </volume> <pages> 257-316, </pages> <year> 1997. </year>
Reference-contexts: Recent years have seen many extensions and refinements of the AGM paradigm, including the distinction between revision and update [23, 32], the proposal of models that combine the two [8, 15], and the acceptance of the notion that epistemic states are much richer than simple belief sets <ref> [4, 17, 27, 29] </ref>. fl This work was supported by NSERC Research Grant OGP0121843 and IRIS-II Project IC-7, and was undertaken while the author was visiting the University of Toronto. <p> The rest of this paper is organized as follows. In Section 2, we discuss the AGM model, and describe generalized revision functions for dealing with sequences of observations. In Section 3, we present our basic framework, which is taken from Friedman and Halpern <ref> [16, 17] </ref>. We define observation systems that allow unreliable observations, show how conditioning can be used to effect belief revision, and characterize the class of generalized revision functions determined by observation systems. <p> Semantically, an entrenchment relation (hence a revision function) can be modeled by associating with each set of possible worlds a plausibility, in any of a number of ways <ref> [5, 10, 17, 20] </ref>. For the purposes of this paper, we adopt Spohn's ordinal conditional functions or -rankings [19, 31]. A function : W ! N [ f1g assigns to each world a ranking reflecting its plausibility: if (w) &lt; (v) then w is more plausible than v. <p> The framework is essentially that of Friedman and Halpern <ref> [17, 16] </ref>, which in turn is based on the multi-agent framework of [21]. We briefly review the details here; further discussion and motivation can be found in [12].
Reference: [18] <author> P. Gardenfors. </author> <title> Knowledge in Flux: Modeling the Dynamics of Epistemic States. </title> <publisher> MIT Press, </publisher> <year> 1988. </year>
Reference-contexts: One of the best known and most studied theories of belief change is the classic AGM theory of belief revision of Alchourron, Gardenfors and Makinson <ref> [2, 18] </ref>. <p> As argued in [14], to justify the success postulate (or any other postulate), we must carefully consider the particular process we hope to characterize as well as the ontology adopted in that characterization. Gardenfors <ref> [18] </ref> provides one interpretation of belief revision for which the success postulate is appropriate. Under this interpretation, the agent's beliefs consist of those propositions the agent accepts as being true and the agent revises by ' only if it accepts ' as being true. <p> We use K fl ' to denote the revision of K by '. Of interest here is the following: (R2) ' 2 K fl R2 is the success postulate mentioned in the introduction; it says that ' is believed after revising by '. We refer the reader to <ref> [18] </ref> for the remaining postulates and a discussion of the AGM theory. Unfortunately, while the postulates constrain possible revisions, they do not dictate the precise beliefs that should be retracted when ' is observed. An alternative model of revision, based on the notion of epistemic entrenchment [18], has a more constructive <p> refer the reader to <ref> [18] </ref> for the remaining postulates and a discussion of the AGM theory. Unfortunately, while the postulates constrain possible revisions, they do not dictate the precise beliefs that should be retracted when ' is observed. An alternative model of revision, based on the notion of epistemic entrenchment [18], has a more constructive nature. Given a belief set K, we can characterize the revision of K by ordering beliefs according to our willingness to give them up.
Reference: [19] <author> M. Goldszmidt and J. Pearl. </author> <title> Qualitative probabilities for default reasoning, belief revision, and causal modeling. </title> <journal> Artificial Intelligence, </journal> <volume> 84 </volume> <pages> 57-112, </pages> <year> 1996. </year>
Reference-contexts: Indeed, it is remarkable how little work is needed to apply these intuitions in a qualitative setting. This emphasizes how small the gap is between belief revision and probability kinematics. We note, however, that our model differs from qualitative adaptations of Jef-frey's Rule [22] devised for belief revision <ref> [11, 19, 31] </ref> (see Section 2 for further discussion). The rest of this paper is organized as follows. In Section 2, we discuss the AGM model, and describe generalized revision functions for dealing with sequences of observations. <p> Semantically, an entrenchment relation (hence a revision function) can be modeled by associating with each set of possible worlds a plausibility, in any of a number of ways [5, 10, 17, 20]. For the purposes of this paper, we adopt Spohn's ordinal conditional functions or -rankings <ref> [19, 31] </ref>. A function : W ! N [ f1g assigns to each world a ranking reflecting its plausibility: if (w) &lt; (v) then w is more plausible than v. We insist that 1 (0) 6= ;, so that maximally plausible worlds are assigned rank 0. <p> It is normally assumed that [[']] " W 6= ; for every satisfiable ' thus every satisfiable proposition is accorded some degree of plausibility. It is well-known that this type of model induces the class of revision functions sanctioned by the AGM postulates <ref> [5, 19, 20] </ref>. We define conditional plausibility, for U; V W and (U ) 6= 1, as: Intuitively, this denotes the degree to which V would be considered plausible if U were believed. These notions are strongly reminiscent of standard concepts from probability theory. <p> In fact, a -ranking can be interpreted as a semi-qualitative probability distribution. Using the "-semantics of Adams [1], Goldszmidt and Pearl <ref> [19] </ref> show how one can interpret the values of propositions as order of magnitude probabilities. It has been remarked by a number of authors that models of revision based on epistemic entrenchment or -rankings are not strong enough to adequately capture iterated revision [4, 16, 27, 29]. <p> Rather than accepting an observed proposition ' with certainty, ' is accepted with degree ff, with :'-worlds retaining a certain plausibility. This model can be viewed as a way of dealing with noisy observations (and has been developed further in <ref> [11, 19] </ref>). In fact, this model is a qualitative analogue of Jeffrey's Rule [22] for probabilistic belief update. Jeffrey's rule is a generalization of conditioning where a piece of evidence can be accepted with a given probability. <p> In fact, this model is a qualitative analogue of Jeffrey's Rule [22] for probabilistic belief update. Jeffrey's rule is a generalization of conditioning where a piece of evidence can be accepted with a given probability. Goldszmidt and Pearl <ref> [19] </ref> argue that Jeffrey's rule is unreasonable since it requires that the observation ' is associated with the agent's posterior degree of belief in '. <p> Of course, it is still non trivial to represent all this information. But this is precisely the same problem that arises in the probabilistic setting; we would expect the techniques that have proved so successful in the probabilistic setting (for example, Bayesian networks) to be applicable here as well <ref> [19] </ref>. 4.1 Expressive Power of Markovian Systems One property that immediately follows from the definition of a Markovian OS is the fact that the order in which the observations from a sequence are made does not influence the beliefs of the agent; only their presence and quantity do.
Reference: [20] <author> A. Grove. </author> <title> Two modellings for theory change. </title> <journal> J. Phil. Logic, </journal> <volume> 17 </volume> <pages> 157-170, </pages> <year> 1988. </year>
Reference-contexts: Semantically, an entrenchment relation (hence a revision function) can be modeled by associating with each set of possible worlds a plausibility, in any of a number of ways <ref> [5, 10, 17, 20] </ref>. For the purposes of this paper, we adopt Spohn's ordinal conditional functions or -rankings [19, 31]. A function : W ! N [ f1g assigns to each world a ranking reflecting its plausibility: if (w) &lt; (v) then w is more plausible than v. <p> It is normally assumed that [[']] " W 6= ; for every satisfiable ' thus every satisfiable proposition is accorded some degree of plausibility. It is well-known that this type of model induces the class of revision functions sanctioned by the AGM postulates <ref> [5, 19, 20] </ref>. We define conditional plausibility, for U; V W and (U ) 6= 1, as: Intuitively, this denotes the degree to which V would be considered plausible if U were believed. These notions are strongly reminiscent of standard concepts from probability theory.
Reference: [21] <author> J. Y. Halpern and R. Fagin. </author> <title> Modelling knowledge and action in distributed systems. </title> <journal> Distributed Computing, </journal> <volume> 3(4) </volume> <pages> 159-179, </pages> <year> 1989. </year>
Reference-contexts: The framework is essentially that of Friedman and Halpern [17, 16], which in turn is based on the multi-agent framework of <ref> [21] </ref>. We briefly review the details here; further discussion and motivation can be found in [12]. The key assumption in the multi-agent system framework is that we can characterize the system by describing it in terms of a state that changes over time.
Reference: [22] <author> R. C. Jeffrey. </author> <title> The Logic of Decision. </title> <publisher> University of Chicago Press, </publisher> <year> 1983. </year>
Reference-contexts: Indeed, it is remarkable how little work is needed to apply these intuitions in a qualitative setting. This emphasizes how small the gap is between belief revision and probability kinematics. We note, however, that our model differs from qualitative adaptations of Jef-frey's Rule <ref> [22] </ref> devised for belief revision [11, 19, 31] (see Section 2 for further discussion). The rest of this paper is organized as follows. In Section 2, we discuss the AGM model, and describe generalized revision functions for dealing with sequences of observations. <p> This model can be viewed as a way of dealing with noisy observations (and has been developed further in [11, 19]). In fact, this model is a qualitative analogue of Jeffrey's Rule <ref> [22] </ref> for probabilistic belief update. Jeffrey's rule is a generalization of conditioning where a piece of evidence can be accepted with a given probability.
Reference: [23] <author> H. Katsuno and A. O. Mendelzon. </author> <title> On the difference between updating a knowledge database and revising it. </title> <booktitle> In Proc. 2nd Inter. Conf. on Principles of Knowledge Representation and Reasoning, </booktitle> <pages> pp. 387-394, </pages> <year> 1991. </year>
Reference-contexts: One of the best known and most studied theories of belief change is the classic AGM theory of belief revision of Alchourron, Gardenfors and Makinson [2, 18]. Recent years have seen many extensions and refinements of the AGM paradigm, including the distinction between revision and update <ref> [23, 32] </ref>, the proposal of models that combine the two [8, 15], and the acceptance of the notion that epistemic states are much richer than simple belief sets [4, 17, 27, 29]. fl This work was supported by NSERC Research Grant OGP0121843 and IRIS-II Project IC-7, and was undertaken while the <p> We also assume that the environment state is a truth assignment for L, reflecting the actual state of the world. As observed by Katsuno and Mendelzon <ref> [23] </ref>, the AGM postulates assume that the world is static; to capture this, we require that the environment state does not change over time.
Reference: [24] <author> R. E. </author> <title> Kalman. A New Approach to Linear Filtering and Prediction Problems. </title> <journal> J. Basic Eng., </journal> <volume> 82 </volume> <pages> 35-45, </pages> <year> 1960. </year>
Reference-contexts: In this sense, our proposal has more in common with probabilistic observation models that are standard in decision and control theory <ref> [3, 24] </ref>. A general way of thinking about iterated revision is not to think of revision functions as mapping from (belief set, observation) pairs to belief sets, but as mapping from finite observation sequences to belief sets. More precisely, assume that an agent's observations are drawn from language L. <p> It is also adopted implicitly in much work in reasoning about action, planning, control and probabilistic inference with respect to system dynamics. Although it plays a key role in the observation models adopted in control theory and probabilistic reasoning <ref> [3, 24] </ref>, it has received little attention in this respect within the qualitative planning literature. The Markov assumption is also very powerful, allowing us to specify a ranking over runs relatively compactly.
Reference: [25] <author> J. G. Kemeny and J. L. Snell. </author> <title> Finite Markov Chains. </title> <publisher> Van Nostrand, </publisher> <year> 1960. </year>
Reference-contexts: likelihood of observing ' is independent of time, given the state of the world, i.e., for all m and m 0 , we have ([[Obs m (')]] j [[w]]) = ([[Obs m 0 The Markov assumption is standard in the probabilistic literature and has been argued to be widely applicable <ref> [25] </ref>. It is also adopted implicitly in much work in reasoning about action, planning, control and probabilistic inference with respect to system dynamics.
Reference: [26] <author> D. Lehmann. </author> <title> Belief revision, revised. </title> <booktitle> In Proc. 14th Inter. Joint Conf. on AI, </booktitle> <pages> pp. 1534-1540, </pages> <year> 1995. </year>
Reference-contexts: To deal with iteration semantically, we need a way of determining a new epistemic state, given an observation <ref> [7, 9, 26, 30] </ref>. Spohn's conditioning operation [31] does just this. When an observation ' is made, all :'-worlds are deemed impossible and removed from the ranking (or set to 1). <p> The ranking represents the agent's initial ranking of runs. Notice that in the previous section, the agent simply ranks possible worlds; here the agent ranks the relative plausibility 3 Our definition of generalized revision functions is similar to that of Lehmann <ref> [26] </ref>. of entire evolutions of both its local state and the environ-ment state. Of course, in general, it is infeasible for the agent to come up with a complete ranking over all possible runs. Later, we discuss some simplifying assumptions that make obtaining such a ranking more feasible. <p> The emphasis on semantics, as opposed to postulates, has allowed us to readily identify these assumptions and examine their consequences. There is considerable related work that we survey in detail in a longer version of this paper. Lehmann <ref> [26] </ref> describes a model where observation sequences are treated as epis-temic states in order to deal effectively with iterated revision. Two proposals impact strongly on this paper. Friedman and Halpern [16] use interpreted systems to model both revision and update, and examine the Markov assumption in this context.
Reference: [27] <author> I. Levi. </author> <title> Iteration of conditionals and the Ramsey test. </title> <journal> Synthese, </journal> <volume> 76(1) </volume> <pages> 49-81, </pages> <year> 1988. </year>
Reference-contexts: Recent years have seen many extensions and refinements of the AGM paradigm, including the distinction between revision and update [23, 32], the proposal of models that combine the two [8, 15], and the acceptance of the notion that epistemic states are much richer than simple belief sets <ref> [4, 17, 27, 29] </ref>. fl This work was supported by NSERC Research Grant OGP0121843 and IRIS-II Project IC-7, and was undertaken while the author was visiting the University of Toronto. <p> We insist that 1 (0) 6= ;, so that maximally plausible worlds are assigned rank 0. If (w) = 1, we say w is impossible. If U W , then (U ) = min u2U (u). Following <ref> [4, 16, 27, 29] </ref>, we distinguish the agent's epis-temic state from its belief set. We define the form of the epistemic state carefully in Section 3. For now we simply require that it includes a ranking . <p> It has been remarked by a number of authors that models of revision based on epistemic entrenchment or -rankings are not strong enough to adequately capture iterated revision <ref> [4, 16, 27, 29] </ref>. Specifically, while these models determine the content of a new belief set when ' is observed, given an epistemic state, they do not determine the new epistemic state (or ranking) associated with the new belief set.
Reference: [28] <author> M. J. Osborne and A. Rubinstein. </author> <title> A Course in Game Theory. </title> <publisher> MIT Press, </publisher> <year> 1994. </year>
Reference-contexts: 1 ; : : : ; ' m i, then ' 1 ^ : : : ^ ' m is true 4 Observation systems are a special case of the belief change systems considered in [13, 16]. 5 This is analogous to the assumption of perfect recall in game theory <ref> [28] </ref> and distributed computing [12]. according to the truth assignment at r e (m). This requirement forces the observations to be accurate; if ' is observed, then it must be true of the world. It is precisely this requirement that we drop here to allow for noisy observations.
Reference: [29] <author> H. Rott. </author> <title> Conditionals and theory change: Revisions, expansions, and additions. </title> <journal> Synthese, </journal> <volume> 81(1) </volume> <pages> 91-113, </pages> <year> 1989. </year>
Reference-contexts: Recent years have seen many extensions and refinements of the AGM paradigm, including the distinction between revision and update [23, 32], the proposal of models that combine the two [8, 15], and the acceptance of the notion that epistemic states are much richer than simple belief sets <ref> [4, 17, 27, 29] </ref>. fl This work was supported by NSERC Research Grant OGP0121843 and IRIS-II Project IC-7, and was undertaken while the author was visiting the University of Toronto. <p> We insist that 1 (0) 6= ;, so that maximally plausible worlds are assigned rank 0. If (w) = 1, we say w is impossible. If U W , then (U ) = min u2U (u). Following <ref> [4, 16, 27, 29] </ref>, we distinguish the agent's epis-temic state from its belief set. We define the form of the epistemic state carefully in Section 3. For now we simply require that it includes a ranking . <p> It has been remarked by a number of authors that models of revision based on epistemic entrenchment or -rankings are not strong enough to adequately capture iterated revision <ref> [4, 16, 27, 29] </ref>. Specifically, while these models determine the content of a new belief set when ' is observed, given an epistemic state, they do not determine the new epistemic state (or ranking) associated with the new belief set.
Reference: [30] <author> H. Rott. </author> <title> Belief change using generalized epistemic entrenchment. </title> <journal> J. Logic, Language and Information, </journal> <volume> 1(1) </volume> <pages> 45-78, </pages> <year> 1992. </year>
Reference-contexts: To deal with iteration semantically, we need a way of determining a new epistemic state, given an observation <ref> [7, 9, 26, 30] </ref>. Spohn's conditioning operation [31] does just this. When an observation ' is made, all :'-worlds are deemed impossible and removed from the ranking (or set to 1).
Reference: [31] <author> W. Spohn. </author> <title> Ordinal conditional functions: A dynamic theory of epistemic states. </title> <editor> In W.L. Harper and B. Skyrms, eds., </editor> <title> Causation in Decision, </title> <journal> Belief Change and Statistics, </journal> <volume> vol. 2, </volume> <pages> pp. 105-134. </pages> <address> D. </address> <publisher> Reidel, </publisher> <year> 1987. </year>
Reference-contexts: To use these ideas in the context of belief revision, we must use a more qualitative measure of uncertainty than probabilityhere we adopt Spohn's <ref> [31] </ref> ranking functions. Nevertheless, the basic intuitions are drawn from the standard probabilistic approach. Indeed, it is remarkable how little work is needed to apply these intuitions in a qualitative setting. This emphasizes how small the gap is between belief revision and probability kinematics. <p> Indeed, it is remarkable how little work is needed to apply these intuitions in a qualitative setting. This emphasizes how small the gap is between belief revision and probability kinematics. We note, however, that our model differs from qualitative adaptations of Jef-frey's Rule [22] devised for belief revision <ref> [11, 19, 31] </ref> (see Section 2 for further discussion). The rest of this paper is organized as follows. In Section 2, we discuss the AGM model, and describe generalized revision functions for dealing with sequences of observations. <p> Semantically, an entrenchment relation (hence a revision function) can be modeled by associating with each set of possible worlds a plausibility, in any of a number of ways [5, 10, 17, 20]. For the purposes of this paper, we adopt Spohn's ordinal conditional functions or -rankings <ref> [19, 31] </ref>. A function : W ! N [ f1g assigns to each world a ranking reflecting its plausibility: if (w) &lt; (v) then w is more plausible than v. We insist that 1 (0) 6= ;, so that maximally plausible worlds are assigned rank 0. <p> To deal with iteration semantically, we need a way of determining a new epistemic state, given an observation [7, 9, 26, 30]. Spohn's conditioning operation <ref> [31] </ref> does just this. When an observation ' is made, all :'-worlds are deemed impossible and removed from the ranking (or set to 1). <p> Boutilier [6, 8] develops a less general model for revision and update (taking the Markov assumption as given) and considers several methods for modeling noisy observations. All of this work (with the exception of [8]) essentially takes the success postulate as a given. Spohn's method of ff-conditioning <ref> [31] </ref>, a generalization of the notion of conditioning rankings defined above, was one of the first revision models to explicitly account for strength of evidence. However, ff-conditioning does not provide an account of how strength of evidence might be derived.
Reference: [32] <author> M. Winslett. </author> <title> Updating Logical Databases. </title> <publisher> Cambridge University Press, </publisher> <year> 1990. </year>
Reference-contexts: One of the best known and most studied theories of belief change is the classic AGM theory of belief revision of Alchourron, Gardenfors and Makinson [2, 18]. Recent years have seen many extensions and refinements of the AGM paradigm, including the distinction between revision and update <ref> [23, 32] </ref>, the proposal of models that combine the two [8, 15], and the acceptance of the notion that epistemic states are much richer than simple belief sets [4, 17, 27, 29]. fl This work was supported by NSERC Research Grant OGP0121843 and IRIS-II Project IC-7, and was undertaken while the
References-found: 32

