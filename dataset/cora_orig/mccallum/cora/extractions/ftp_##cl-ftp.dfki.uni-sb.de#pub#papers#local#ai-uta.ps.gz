URL: ftp://cl-ftp.dfki.uni-sb.de/pub/papers/local/ai-uta.ps.gz
Refering-URL: http://cl-www.dfki.uni-sb.de/cl/papers/cl-abstracts.html
Root-URL: 
Email: neumann@dfki.uni-sb.de  
Title: Interleaving Natural Language Parsing and Generation Through Uniform Processing  
Author: Gunter Neumann 
Address: Stuhlsatzenhausweg 3 66123 Saarbrucken, Germany  
Affiliation: Deutsches Forschungszentrum fur Kunstliche Intelligenz GmbH  
Abstract: We present a new model of natural language processing in which natural language parsing and generation are strongly interleaved tasks. Interleaving of parsing and generation is important if we assume that natural language understanding and production are not only performed in isolation but also can work together to obtain subsentential interactions in text revision or dialog systems. The core of the model is a new uniform agenda-driven tabular algorithm, called UTA. Although uniformly defined, UTA is able to configure itself dynamically for either parsing or generation, because it is fully driven by the structure of the actual input|a string for parsing and a semantic expression for generation. Efficient interleaving of parsing and generation is obtained through item sharing between parsing and generation. This novel processing strategy facilitates exchanging items (i.e., partial results) computed in one direction automatically to the other direction as well. The advantage of U TA in combination with the item sharing method is that we are able to extend the use of memoization techniques even to the case of an interleaved approach. In order to demonstrate U T A's utility for developing high-level performance methods, we present a new algorithm for incremental self-monitoring during natural language production. 
Abstract-found: 1
Intro-found: 1
Reference: [ Alshawi and Crouch, 1992 ] <author> H. Alshawi and R. Crouch. </author> <title> Monotonic semantic interpretation. </title> <booktitle> In 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Newark, Delaware, </address> <year> 1992. </year>
Reference: [ Appelt, 1987 ] <author> D. E. Appelt. </author> <title> Bidirectional grammars and the design of natural language gen-eration systems. </title> <editor> In Y. Wilks, editor, </editor> <booktitle> Theoretical Issues in Natural Language Processing-3, </booktitle> <pages> pages 185-191. </pages> <address> Hillsdale, N.J.: </address> <publisher> Erlbaum, </publisher> <year> 1987. </year>
Reference: [ Backofen and Weyers, 1993 ] <author> R. Backofen and C. Weyers. </author> <title> UDiNe|A Feature Constraint Solver with Distributed Disjunction and Classical Negation. </title> <type> Technical report, </type> <institution> DFKI, Saarbrucken, Germany, </institution> <year> 1993. </year> <month> Forthcoming. </month>
Reference-contexts: It uses the powerful constraint-solver UDiNe which is capable of dealing with distributed disjunctions over arbitrary structures, negative co-references, and full negation <ref> [ Backofen and Weyers, 1993 ] </ref> . Overview of the next sections In the next section we introduce the formal and linguistic background on which our approach is based.
Reference: [ Barnett, 1994 ] <author> J. Barnett. </author> <title> Bi-directional preferences. </title> <editor> In Tomek Strzalkowski, editor, </editor> <booktitle> Reversible Grammar in Natural Language Processing, </booktitle> <pages> pages 201-234. </pages> <publisher> Kluwer, </publisher> <year> 1994. </year>
Reference-contexts: In particular the on-line creation supports incremental processing for both parsing and generation, and even for the interleaved approach. In the same spirit, the agenda mechanism supports integration of preference- based strategies, e.g., along the lines of <ref> [ Barnett, 1994 ] </ref> or [ Erbach, 1995 ] . <p> Also the architecture of the item sharing approach has been designed to support preference-based control. 43 The strategies described in [ Uszkoreit, 1991 ] and <ref> [ Barnett, 1994 ] </ref> seem to be suitable candidates for the new uniform environment. <p> The work described in [ Uszkoreit, 1991 ] is of importance since the approach focusses on the integration of preferences with the feature system of a constraint-based grammar as an appropriate means for obtaining plausible performance models. In <ref> [ Barnett, 1994 ] </ref> a model is described that is able to handle specific preferences for parsing and generation, as well as shared preferences. It is reasonable to assume that both strategies (even together) can be integrated into the new uniform model.
Reference: [ Berg, 1986 ] <author> T. Berg. </author> <title> The problems of language control: Editing, monitoring and feedback. </title> <journal> Psychological Research, </journal> <volume> 48 </volume> <pages> 133-144, </pages> <year> 1986. </year>
Reference-contexts: For example, during generation integrated parsing can be used to monitor the generation process and to cause some kind of revision, e.g., to reduce the risk of misunderstandings. Research on monitoring and revision strategies is a very prominent area in cognitive science (cf. <ref> [ Berg, 1986; Levelt, 1989 ] </ref> ); however, currently there exists no algorithmic model of such a behaviour. A uniform architecture can be an important step in that direction. <p> In psycholinguistic research a similar strategy is known under the term self-monitoring. Here, there is no deny that people watch over what they are saying and how they are saying it <ref> [ Berg, 1986 ] </ref> . The basic task of monitoring is to gain information about processing which is not necessarily obvious, i.e., a device is called for which this information can be made available to the speaker or the hearer.
Reference: [ Bresnan, 1982 ] <author> J. Bresnan, </author> <title> editor. The Mental Representation of Grammatical Relations. </title> <publisher> MIT Press, </publisher> <year> 1982. </year>
Reference-contexts: This kind of duality is naturally captured if reversible grammars are used. 2.2 Constraint-logic programming Since the last decade a family of linguistic theories known under the term constraint- based grammar theories play an important role within the field of natural language processing, e.g., lfg <ref> [ Bresnan, 1982 ] </ref> , hpsg [ Pollard and Sag, 1994 ] . In the last few years constraint-based formalisms have undergone a rigorous formal investigation (consider for example [ Shieber, 1989; Smolka, 1988; Smolka, 1992 ] ).
Reference: [ Den, 1994 ] <author> Y. Den. </author> <title> Generalized chart algorithm: An efficient procedure for cost-based abduc-tion. </title> <booktitle> In 32th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> New Mexico, </address> <year> 1994. </year>
Reference: [ DeSmedt and Kempen, 1987 ] <author> K. DeSmedt and G. Kempen. </author> <title> Incremental sentence production, self-correction and coordination. </title> <editor> In G. Kempen, editor, </editor> <booktitle> Natural Language Generation, </booktitle> <pages> pages 365-376. </pages> <publisher> Martinus Nijhoff, </publisher> <address> Dordrecht, </address> <year> 1987. </year>
Reference-contexts: Most approaches that consider an integrated approach can be found in the areas of artificial intelligence or cognitive science, e.g., [ Jameson and Wahlster, 1982 ] , [ Vaughan and McDonald, 1986 ] , <ref> [ DeSmedt and Kempen, 1987 ] </ref> , [ Meteer and Shaked, 1988 ] , [ Levelt, 1989 ] , [ Wahlster et al., 1991 ] .
Reference: [ Earley, 1970 ] <author> J. Earley. </author> <title> An efficient context-free parsing algorithm. </title> <journal> Communications of the ACM, </journal> <volume> 13(2) </volume> <pages> 94-102, </pages> <year> 1970. </year>
Reference-contexts: equivalence classes so that necessary lookup opera <br>- tions are restricted only to an identifiable subset 3. using the same mechanism for both parsing and generation The idea of memoing derived clauses as well as defining equivalence classes for restricting lookup of possible candidates is not a new one (cf. <ref> [ Earley, 1970; Pereira and Warren, 1983; Kay, 1986 ] </ref> ) although with primarily emphasize on parsing. <p> interleaved perspective as followed in this paper has not been described in the literature, to the best of my knowledge. 6 For parsing, particular data structures have been developed for achieving efficient processing, most notably the chart developed by [ Kay, 1986 ] and the item set notation developed by <ref> [ Earley, 1970 ] </ref> . In both approaches the endpoints of a derived string are explicitly used for indexing stored phrases. Unfortunately, we cannot use these well-known approaches for generation directly, because the string is the output of a generator, not the input, of course.
Reference: [ Erbach, 1995 ] <author> Gregor Erbach. </author> <title> Bottom-Up Earley Deduction for Preference-Driven Natural Language Processing. </title> <type> PhD thesis, </type> <institution> Universitat des Saarlandes, Germany, </institution> <month> forthcoming </month> <year> 1995. </year>
Reference-contexts: In particular the on-line creation supports incremental processing for both parsing and generation, and even for the interleaved approach. In the same spirit, the agenda mechanism supports integration of preference- based strategies, e.g., along the lines of [ Barnett, 1994 ] or <ref> [ Erbach, 1995 ] </ref> . <p> The use of the essential feature Ef as the single parameter of U TA is comparable to Strzalkowski's essential argument approach [ Strzalkowski, 1994 ] . However, he uses this information only off-line during grammar compilation in order to obtain specific parsing and generation grammars. In <ref> [ Erbach, 1995 ] </ref> a uniform algorithm based on bottom-up Earley deduction is presented that makes use of a flexible indexing scheme, however mainly for the use of parsing. Erbach's approach is promising because he extends Earley deduction for application of preference-based strategies.
Reference: [ Frazier, 1982 ] <author> L. Frazier. </author> <title> Shared components of production and perception. </title> <editor> In M. A. Arbib et al., editor, </editor> <booktitle> Neural Models of Language Processes, </booktitle> <pages> pages 225-236. </pages> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1982. </year>
Reference: [ Gerdemann, 1991 ] <author> D. D. Gerdemann. </author> <title> Parsing and Generation of Unification Grammars. </title> <type> PhD thesis, </type> <institution> University of Illinois, Cognitive Science, </institution> <type> Technical Report CS-91-06, </type> <year> 1991. </year>
Reference-contexts: For parsing, for example, <ref> [ Shieber, 1988; Gerdemann, 1991 ] </ref> have used the leftmost selection strategy, where for generation [ Shieber et al., 1990; Gerdemann, 1991 ] use the semantic-head first selection function. <p> For parsing, for example, [ Shieber, 1988; Gerdemann, 1991 ] have used the leftmost selection strategy, where for generation <ref> [ Shieber et al., 1990; Gerdemann, 1991 ] </ref> use the semantic-head first selection function. <p> Thus, we are able to characterise parsing and generation in a fairly balanced way without the loss of efficient properties. Hence, we avoid the complications or restrictions that [ Shieber, 1988 ] and <ref> [ Gerdemann, 1991 ] </ref> are confronted with, because of their "parsing oriented" view of generation. In [ Neumann, 1994b ] we also show how U TA is extended to handle empty heads, which are used to describe verb second constructions in Germanic languages like Dutch and German.
Reference: [ Haas, 1989 ] <author> A. Haas. </author> <title> A parsing algorithm for unification grammars. </title> <journal> Computational Linguistics, </journal> <volume> 15(4) </volume> <pages> 219-232, </pages> <year> 1989. </year>
Reference-contexts: In the parsing literature abstraction has been introduced under the term restriction. More and detailed information on the definition and use of a abstraction/restriction function during parsing see e.g., [ Shieber, 1985 ] , <ref> [ Haas, 1989 ] </ref> , and [ Samuelsson, 1994 ] p-completion (P i) is: For every active item Ai 2 I idx : if = unify (sel (Ai), h) and 6= f ail then with reduced lemma Rl = [Ai sel (Ai)] do if body (Rl) 6= * then make new
Reference: [ Hohfeld and Smolka, 1988 ] <author> M. Hohfeld and G. Smolka. </author> <title> Definite relations over constraint lan-guages. </title> <type> Technical Report Technical Report No. </type> <institution> 53,LILOG IBM, Stuttgart, </institution> <year> 1988. </year>
Reference-contexts: If such a restriction is required additional constraints have to be added to the rule, for instance that substrings have to be combined by concatenation. A general characterisation of CLP is given in <ref> [ Hohfeld and Smolka, 1988 ] </ref> . Given a constraint language L and a set R of relation symbols, L is extended conservatively to a constraint language R (L) providing for relational atoms, the propositional connectives, and quantification. <p> The fundamental inference rule for definite clauses in R (L) is the following goal reduction rule (using a slightly different notation from that given in <ref> [ Hohfeld and Smolka, 1988 ] </ref> ) where p (~x) is the selected element of a goal and 7 p (~x) q 1 ; : : : ; q m ; is a variant of a clause of a definite clause specification S and is the result of unifying and (which <p> Furthermore, empty feature structures will not been shown explicitly. The feature structure encoding of the following list 2 Note, that we directly make use of the so called optimised goal reduction rule proven by <ref> [ Hohfeld and Smolka, 1988 ] </ref> for the general case. 3 Although we use only simple constructions in order to highlight the new results in a clean but simple way, the generalisation of Hohfeld and Smolka's scheme guarantees that the results of this thesis also carry over to more complex constraint <p> pred Lugen i 7 7 ; pred Peter i h pred Lugen i In Appendix A complete parsing and generation examples can be found. 4 Intermezzo: Some Properties of U T A U T A is an straight-forward extension of the optimized general SLD-resolution rule whose correctness is proven in <ref> [ Hohfeld and Smolka, 1988 ] </ref> . It also inherits this property (see [ Neumann, 1994b ] for more details).
Reference: [ Jacobs, 1988 ] <author> P. S. Jacobs. </author> <title> Achieving bidirectionality. </title> <booktitle> In Proceedings of the 12th International Conference on Computational Linguistics (COLING), </booktitle> <pages> pages 267-274, </pages> <address> Budapest, </address> <year> 1988. </year>
Reference: [ Jaffar and Lassez, 1987 ] <author> Joxan Jaffar and Jean-Louis Lassez. </author> <title> Constraint logic programming. </title> <booktitle> In Proceedings of the 14th ACM Symposium on Principles of Programming Languages, </booktitle> <address> Munich, Germany, </address> <pages> pages 111-119. </pages> <publisher> ACM, </publisher> <month> January </month> <year> 1987. </year> <month> 48 </month>
Reference-contexts: On the other hand it has been possible to combine constraint- based formalisms with logic programming, which fits into a new research area known under the term constraint logic programming (CLP) <ref> [ Jaffar and Lassez, 1987 ] </ref> .
Reference: [ Jameson and Wahlster, 1982 ] <author> A. Jameson and W. Wahlster. </author> <title> User modelling in anaphora gen--eration: Ellipsis and definite description. </title> <booktitle> In Proceedings of teh 1982 European Conference on Artificial Intelligence, </booktitle> <pages> pages 222-227, </pages> <address> Orsay, France, </address> <year> 1982. </year>
Reference-contexts: The basic idea of the afl model is the use of the system's natural language understanding part to anticipate the preferred users' interpretation of an utterance which the system plans to realize. In <ref> [ Jameson and Wahlster, 1982 ] </ref> a local afl model is used for the generation of elliptical utterances. <p> However, he only considers parsing, too. Neither of the above mentioned approaches use shared items, basically because they do not consider interleaving of parsing and generation. Most approaches that consider an integrated approach can be found in the areas of artificial intelligence or cognitive science, e.g., <ref> [ Jameson and Wahlster, 1982 ] </ref> , [ Vaughan and McDonald, 1986 ] , [ DeSmedt and Kempen, 1987 ] , [ Meteer and Shaked, 1988 ] , [ Levelt, 1989 ] , [ Wahlster et al., 1991 ] .
Reference: [ Johnson and Dorre, 1995 ] <author> M. Johnson and J. Dorre. </author> <title> Memoization of coroutined constraints. </title> <booktitle> In 33th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Cambridge, </address> <year> 1995. </year>
Reference-contexts: Passive-completion Let hh; *; idxi be an passive item P i. Then 8 Here, we follow an approach similar to the one described in <ref> [ Johnson and Dorre, 1995 ] </ref> , by gener- alising the value of only a small predefined set of constraints, namely those which are known to cause termination problems. <p> Erbach's approach is promising because he extends Earley deduction for application of preference-based strategies. For that reason it seems interesting to combine his approach with that of U TA. In <ref> [ Johnson and Dorre, 1995 ] </ref> an Earley deduction mechanism is presented that uses a mechanism which is able to coroutine between goals that depend on each others' partial solutions. However, they only consider parsing.
Reference: [ Kay, 1986 ] <author> M. Kay. </author> <title> Algorithm schemata and data structures in syntactic processing. </title> <editor> In B. J. Grosz, K. Sparck Jones, and B. L. Webber, editors, </editor> <booktitle> Natural Language Processing, </booktitle> <pages> pages 35-70. </pages> <publisher> Kaufmann, </publisher> <address> Los Altos, CA, </address> <year> 1986. </year>
Reference-contexts: equivalence classes so that necessary lookup opera <br>- tions are restricted only to an identifiable subset 3. using the same mechanism for both parsing and generation The idea of memoing derived clauses as well as defining equivalence classes for restricting lookup of possible candidates is not a new one (cf. <ref> [ Earley, 1970; Pereira and Warren, 1983; Kay, 1986 ] </ref> ) although with primarily emphasize on parsing. <p> However, considering memoization under a strict uniform and interleaved perspective as followed in this paper has not been described in the literature, to the best of my knowledge. 6 For parsing, particular data structures have been developed for achieving efficient processing, most notably the chart developed by <ref> [ Kay, 1986 ] </ref> and the item set notation developed by [ Earley, 1970 ] . In both approaches the endpoints of a derived string are explicitly used for indexing stored phrases.
Reference: [ Keene, 1989 ] <author> S. E. Keene. </author> <title> Object-Oriented Programming in COMMON LISP: A Programmer's Guide to CLOS. </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1989. </year>
Reference-contexts: We therefore directly make use of the CLOS-class definition, abbreviated where convenient. In <ref> [ Keene, 1989 ] </ref> and [ Winston and Horn, 1989 ] good introductions to CLOS can be found. 25 additional call of a function.
Reference: [ Kempen and Hoenkamp, 1987 ] <author> G. Kempen and E. Hoenkamp. </author> <title> An incremental procedural grammar for sentence formulation. </title> <journal> Cognitive Science, </journal> <volume> 11 </volume> <pages> 201-258, </pages> <year> 1987. </year>
Reference: [ Kempen, 1989 ] <author> G. Kempen. </author> <title> Language generation systems. </title> <editor> In I. S. Batori, W. Lenders, and W. Putschke, editors, </editor> <booktitle> Computational Linguistics - Computerlinguistik, </booktitle> <pages> pages 471-480. </pages> <publisher> de Gruyter, </publisher> <address> Berlin, </address> <year> 1989. </year>
Reference-contexts: The latter evaluates the generator's utterance from relevant viewpoints and informs (via the monitor) the strategic component of its diagnosis. This would establish the line of communication postulated by Danlos and others without complicating the generator's design | the parser is needed anyway." (cf. <ref> [ Kempen, 1989 ] </ref> , page 15). In all of the above cited approaches parsing and generation are assumed to work together on a very fine-grained level.
Reference: [ Levelt, 1989 ] <author> W. J. M. Levelt. </author> <title> Speaking: From Intention to Articulation. </title> <publisher> MIT Press, </publisher> <address> Cambridge, Massachusetts, </address> <year> 1989. </year>
Reference-contexts: For example, during generation integrated parsing can be used to monitor the generation process and to cause some kind of revision, e.g., to reduce the risk of misunderstandings. Research on monitoring and revision strategies is a very prominent area in cognitive science (cf. <ref> [ Berg, 1986; Levelt, 1989 ] </ref> ); however, currently there exists no algorithmic model of such a behaviour. A uniform architecture can be an important step in that direction. <p> The basic task of monitoring is to gain information about processing which is not necessarily obvious, i.e., a device is called for which this information can be made available to the speaker or the hearer. It has often been argued in cognitive psychology <ref> [ Levelt, 1989 ] </ref> that it is highly desirable to find a mechanism that is an integral and independently motivated part of the whole system and one that performs the monitoring function by its own nature. <p> If the flag is switched off further generation is automatically continued without monitoring. Using this mechanism it is possible to simulate an any-time mode of the incremental method. Limitations It should be clear that monitoring and revision involves more than the avoidance of ambiguities. <ref> [ Levelt, 1989 ] </ref> discusses also monitoring on the conceptual level and monitoring with respect to social standards, lexical errors, loudness, precision and others. Obviously, our approach is restricted in the sense that no changes to the input logical form are made. <p> Most approaches that consider an integrated approach can be found in the areas of artificial intelligence or cognitive science, e.g., [ Jameson and Wahlster, 1982 ] , [ Vaughan and McDonald, 1986 ] , [ DeSmedt and Kempen, 1987 ] , [ Meteer and Shaked, 1988 ] , <ref> [ Levelt, 1989 ] </ref> , [ Wahlster et al., 1991 ] .
Reference: [ Levine, 1992 ] <author> J. M. Levine. Pragma: </author> <title> A flexible bidirectional dialogue system. </title> <booktitle> In AAAI-90, </booktitle> <pages> pages 964-969, </pages> <address> Boston, </address> <year> 1992. </year>
Reference-contexts: Interleaved parsing and generation seems also promising for question-answering systems where question understanding and answering is performed simultaneously [ Robertson, 1994 ] and for bidirectional dialogue systems <ref> [ Levine, 1992 ] </ref> . Modelling such high-level performance methods on the basis of non-uniform approaches is problematic|if not impossible. For example, if two different grammars and algorithms are in use then additional translation operations are necessary in order for parsing and generation to exchange partial results.
Reference: [ Lloyd, 1987 ] <author> J. .W. Lloyd. </author> <title> Foundations of Logic Programming. Symbol Computation, </title> <publisher> Springer, </publisher> <address> Berlin, New York, </address> <year> 1987. </year>
Reference-contexts: Operational semantics Hohfeld and Smolka provide a generalisation of the SLD- resolution method known from standard logic programming (cf. <ref> [ Lloyd, 1987 ] </ref> ) to definite clauses in R (L).
Reference: [ Meteer and Shaked, 1988 ] <author> M. M. Meteer and V. Shaked. </author> <title> Strategies for effective paraphrasing. </title> <booktitle> In Proceedings of the 12th International Conference on Computational Linguistics (COLING), </booktitle> <address> Budapest, </address> <year> 1988. </year>
Reference-contexts: Most approaches that consider an integrated approach can be found in the areas of artificial intelligence or cognitive science, e.g., [ Jameson and Wahlster, 1982 ] , [ Vaughan and McDonald, 1986 ] , [ DeSmedt and Kempen, 1987 ] , <ref> [ Meteer and Shaked, 1988 ] </ref> , [ Levelt, 1989 ] , [ Wahlster et al., 1991 ] .
Reference: [ Meteer, 1990 ] <author> M. M. Meteer. </author> <title> The Generation Gap the problem of expressibility in text planning. </title> <type> PhD thesis, </type> <institution> University of Massachusetts, </institution> <year> 1990. </year>
Reference: [ Neumann and Finkler, 1990 ] <author> G. Neumann and W. Finkler. </author> <title> A head-driven approach to incre-mental and parallel generation of syntactic structures. </title> <booktitle> In Proceedings of the 13th International Conference on Computational Linguistics (COLING), </booktitle> <pages> pages 288-293, </pages> <address> Helsinki, </address> <year> 1990. </year>
Reference-contexts: Our strategy is an example of revision. Opti- mizations are useful when changes have to be done during the initial generation process. For example, in <ref> [ Neumann and Finkler, 1990 ] </ref> an incremental and parallel grammatical component is described that is able to handle under-specified input such that it detects and requests missing but necessary grammatical information. 7 Discussion and Future Extensions 7.1 Related work U T A can be seen as extension of Shieber's uniform
Reference: [ Neumann and van Noord, 1992 ] <author> G. Neumann and G. van Noord. </author> <title> Self-monitoring with re-versible grammars. </title> <booktitle> In Proceedings of the 14th International Conference on Computational Linguistics (COLING), </booktitle> <pages> pages 700-706, </pages> <address> Nantes, </address> <year> 1992. </year>
Reference: [ Neumann and van Noord, 1994 ] <author> G. Neumann and G. van Noord. </author> <title> Reversibility and selfmonitoring in natural language generation. </title> <editor> In Tomek Strzalkowski, editor, </editor> <booktitle> Reversible Grammar in Natural Language Processing, </booktitle> <pages> pages 59-96. </pages> <publisher> Kluwer, </publisher> <year> 1994. </year>
Reference: [ Neumann, 1994a ] <author> G. Neumann. </author> <title> Application of explanation-based learning for efficient process-ing of constraint-based grammars. </title> <booktitle> In Proceedings of the Tenth IEEE Conference on Artifical Intelligence for Applications, </booktitle> <pages> pages 208-215, </pages> <address> San Antonio, Texas, </address> <month> March </month> <year> 1994. </year>
Reference-contexts: Two of many possible ways which we started to investigate are briefly considered now. Explanation-based learning An important line of research will be the application of explanation-based learning (EBL) to speed up processing. In <ref> [ Neumann, 1994a ] </ref> we have described the application of EBL to efficient parsing of constraint-based grammars. The idea is to generalize the derivations of training instances created by normal parsing automatically and to use these generalized derivations (also called templates) during the run-time mode of the system.
Reference: [ Neumann, 1994b ] <author> Gunter Neumann. </author> <title> A Uniform Computational Model for Natural Language Parsing and Generation. </title> <type> PhD thesis, </type> <institution> Universitat des Saarlandes, Germany, </institution> <month> November </month> <year> 1994. </year> <month> 49 </month>
Reference-contexts: It also inherits this property (see <ref> [ Neumann, 1994b ] </ref> for more details). Since U TA prefers in each deduction step those clauses whose selected element's Ef is instantiated it has a very strong goal-directed as well as data-oriented behaviour in particular for the case of generation. <p> Thus, we are able to characterise parsing and generation in a fairly balanced way without the loss of efficient properties. Hence, we avoid the complications or restrictions that [ Shieber, 1988 ] and [ Gerdemann, 1991 ] are confronted with, because of their "parsing oriented" view of generation. In <ref> [ Neumann, 1994b ] </ref> we also show how U TA is extended to handle empty heads, which are used to describe verb second constructions in Germanic languages like Dutch and German.
Reference: [ Pereira and Shieber, 1987 ] <author> F. C. N. Pereira and S. M. Shieber. </author> <title> Prolog and Natural Language Analysis. Center for the Study of Language and Information Stanford, </title> <year> 1987. </year>
Reference-contexts: This is due to the fact, that the value of the essential feature is used for defining the indexes of the item sets. 3.3 Inference-rules The control logic of U TA is a generalisation of the Earley deduction scheme as introduced by [ Pereira and Warren, 1983 ] (see also <ref> [ Pereira and Shieber, 1987 ] </ref> ).
Reference: [ Pereira and Warren, 1983 ] <author> F. C. N. Pereira and D. Warren. </author> <title> Parsing as deduction. </title> <booktitle> In 21st Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Cambridge Massachusetts, </address> <year> 1983. </year>
Reference-contexts: At present, the first attempts are being made at uniform architectures which are based on the paradigm of natural language processing as deduction <ref> [ Pereira and Warren, 1983 ] </ref> , [ Shieber, 1988 ] . Here, grammatical processing is performed by means of the same underlying deduction mechanism, which can be parameterised for the specific tasks at hand. <p> along the following line: * data-driven selection function * uniform indexing mechanism * agenda-based control * item sharing between parsing and generation 11 The first idea is to use the same set of inference rules for parsing and generation basically we use the Earley deduction proof procedure as introduced in <ref> [ Pereira and Warren, 1983 ] </ref> but to use a data-driven selection function, so that the element to process next is determined on the basis of the current portion of the input (a string or semantic expression). <p> equivalence classes so that necessary lookup opera <br>- tions are restricted only to an identifiable subset 3. using the same mechanism for both parsing and generation The idea of memoing derived clauses as well as defining equivalence classes for restricting lookup of possible candidates is not a new one (cf. <ref> [ Earley, 1970; Pereira and Warren, 1983; Kay, 1986 ] </ref> ) although with primarily emphasize on parsing. <p> This is due to the fact, that the value of the essential feature is used for defining the indexes of the item sets. 3.3 Inference-rules The control logic of U TA is a generalisation of the Earley deduction scheme as introduced by <ref> [ Pereira and Warren, 1983 ] </ref> (see also [ Pereira and Shieber, 1987 ] ). <p> Whenever a new active lemma is added to one of the chart's item sets, one of its negative literals is selected by calling the selection function sf, i.e., a selected element is determined on-line. Following <ref> [ Pereira and Warren, 1983 ] </ref> we make use of the following inference rules: prediction and completion. Prediction is used to predict instantiations of grammar rules. Completion will be performed by three inference rules, namely passive completion, active completion, and scanning. <p> Thus, if a lexical entry can be unified with the selected element of the active item Ai then a new clause is constructed by deleting the unified element from the body of Ai's clause. Following <ref> [ Pereira and Warren, 1983 ] </ref> we call this operation reduction. The same will be performed for the two remaining completion rules, passive completion and active completion. <p> However, before the new item is added to that item set, it is checked whether there exists already an element in that item set which subsumes the new item. This test is known as the blocking test <ref> [ Pereira and Warren, 1983 ] </ref> . Although, we currently use the expensive subsumption operation for performing this test, our uniform indexing mechanism makes it possible to apply subsumption only on a small subset of all possible items already in the chart.
Reference: [ Pollard and Sag, 1994 ] <author> C. Pollard and I. M. Sag. </author> <title> Head-Driven Phrase Structure Grammar. Center for the Study of Language and Information Stanford, </title> <year> 1994. </year>
Reference-contexts: We discuss the new approach by comparison with related work in section 7 and outline future extensions. 2 Formal and Linguistic Background 2.1 A relational view on language It is widely accepted to consider linguistic objects (i.e., words and phrases) as utterance- meaning associations <ref> [ Pollard and Sag, 1994 ] </ref> . Thus viewed, a grammar is a formal statement of the relation between utterances of a natural language and representations 4 of their meanings in some logical or other artifical language, where such representations are usually called logical forms [ Shieber, 1993 ] . <p> kind of duality is naturally captured if reversible grammars are used. 2.2 Constraint-logic programming Since the last decade a family of linguistic theories known under the term constraint- based grammar theories play an important role within the field of natural language processing, e.g., lfg [ Bresnan, 1982 ] , hpsg <ref> [ Pollard and Sag, 1994 ] </ref> . In the last few years constraint-based formalisms have undergone a rigorous formal investigation (consider for example [ Shieber, 1989; Smolka, 1988; Smolka, 1992 ] ).
Reference: [ Ristad, 1993 ] <author> E. S. Ristad. </author> <title> The Language Complexity Game. </title> <publisher> MIT-Press, </publisher> <year> 1993. </year>
Reference: [ Robertson, 1994 ] <author> S. P. Robertson. Tsunami: </author> <title> Simultaneous understanding, answering, and memory interactions for questions. </title> <journal> Cognitive Science, </journal> <volume> 18 </volume> <pages> 51-85, </pages> <year> 1994. </year>
Reference-contexts: Interleaved parsing and generation seems also promising for question-answering systems where question understanding and answering is performed simultaneously <ref> [ Robertson, 1994 ] </ref> and for bidirectional dialogue systems [ Levine, 1992 ] . Modelling such high-level performance methods on the basis of non-uniform approaches is problematic|if not impossible.
Reference: [ Samuelsson, 1994 ] <author> C. Samuelsson. </author> <title> Fast Natural-Language Parsing Using Explanation-Based Learning. </title> <type> PhD thesis, </type> <institution> Swedish Institute of Computer Science, Kista, Sweden, </institution> <year> 1994. </year>
Reference-contexts: In the parsing literature abstraction has been introduced under the term restriction. More and detailed information on the definition and use of a abstraction/restriction function during parsing see e.g., [ Shieber, 1985 ] , [ Haas, 1989 ] , and <ref> [ Samuelsson, 1994 ] </ref> p-completion (P i) is: For every active item Ai 2 I idx : if = unify (sel (Ai), h) and 6= f ail then with reduced lemma Rl = [Ai sel (Ai)] do if body (Rl) 6= * then make new active item with Selem = sf
Reference: [ Shieber et al., 1983 ] <author> S. M. Shieber, H. Uszkoreit, F. C. N. Pereira, J. Robinson, and M. Tyson. </author> <title> The formalism and implementation of PATR-II. </title> <editor> In B. J. Grosz and M. E. Stickel, editors, </editor> <title> Research on Interactive Acquisition and Use of Knowledge. </title> <type> SRI report, </type> <year> 1983. </year>
Reference-contexts: All objects that fulfill at least these constraints are members of s objects. Note that there is no ordering presupposed for np and vp as is the case for unification-based formalisms that rely on a context-free backbone, e.g., <ref> [ Shieber et al., 1983 ] </ref> . If such a restriction is required additional constraints have to be added to the rule, for instance that substrings have to be combined by concatenation. A general characterisation of CLP is given in [ Hohfeld and Smolka, 1988 ] .
Reference: [ Shieber et al., 1990 ] <author> S. M. Shieber, F. C. N. Pereira, G. van Noord, and R. C. Moore. </author> <title> Semantichead-driven generation. </title> <journal> Computational Linguistics, </journal> <volume> 16(1), </volume> <year> 1990. </year>
Reference-contexts: For parsing, for example, [ Shieber, 1988; Gerdemann, 1991 ] have used the leftmost selection strategy, where for generation <ref> [ Shieber et al., 1990; Gerdemann, 1991 ] </ref> use the semantic-head first selection function. <p> It may be possible to restrict the context during the production of a partial utterance to grammatical properties, e.g. to the information associated with the head which selects the phrase dominating this partial utterance. Such an approach can be integrated in head-driven generators of the type described in <ref> [ Shieber et al., 1990 ] </ref> . <p> However, his degree of uniformity is restricted since he actually uses different indexing mechanisms for parsing and generation. U T A has a stronger goal-directed behaviour than the semantic head-driven algorithm described in <ref> [ Shieber et al., 1990 ] </ref> , because it uses a semantic-oriented selection for all rules of the grammar (where Shieber et al consider only a subset of the rules; all other rules are processed in a simple left-to-right top-down manner). Furthermore, they do not make use of a chart.
Reference: [ Shieber, 1985 ] <author> S. M. Shieber. </author> <title> Using restriction to extend parsing algorithms for complexfeature-based formalisms. </title> <booktitle> In 23th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Chicago, </address> <year> 1985. </year>
Reference-contexts: Here, the selected element of Ai and the rule's head element (the left-hand-side element) are unified and only if unification successed a new item will be created. Thus, prediction deduces a new item on the basis of an instantiated rule. As known from the work of <ref> [ Shieber, 1985 ] </ref> prediction can lead to arbitrary numbers of consequents through repeated application when used with a grammar with an infinite structured nonterminal domain. <p> In the parsing literature abstraction has been introduced under the term restriction. More and detailed information on the definition and use of a abstraction/restriction function during parsing see e.g., <ref> [ Shieber, 1985 ] </ref> , [ Haas, 1989 ] , and [ Samuelsson, 1994 ] p-completion (P i) is: For every active item Ai 2 I idx : if = unify (sel (Ai), h) and 6= f ail then with reduced lemma Rl = [Ai sel (Ai)] do if body (Rl)
Reference: [ Shieber, 1988 ] <author> S. M. Shieber. </author> <title> A uniform architecture for parsing and generation. </title> <booktitle> In Proceedings of the 12th International Conference on Computational Linguistics (COLING), </booktitle> <address> Budapest, </address> <year> 1988. </year>
Reference-contexts: At present, the first attempts are being made at uniform architectures which are based on the paradigm of natural language processing as deduction [ Pereira and Warren, 1983 ] , <ref> [ Shieber, 1988 ] </ref> . Here, grammatical processing is performed by means of the same underlying deduction mechanism, which can be parameterised for the specific tasks at hand. Natural language processing based on a uniform deduction process has a formal elegance and results in more compact systems. <p> For parsing, for example, <ref> [ Shieber, 1988; Gerdemann, 1991 ] </ref> have used the leftmost selection strategy, where for generation [ Shieber et al., 1990; Gerdemann, 1991 ] use the semantic-head first selection function. <p> It is similar to the one defined by <ref> [ Shieber, 1988 ] </ref> with the notable distinction that we use a dynamic selection function (where Shieber only uses the left-to-right selection function for both parsing and generation) and that we use a fairly uniform indexing mechanism 15 (where Shieber only uses indexing efficiently for the case of parsing because his <p> i else make new passive item: N i = hRl; *; head (Rl)=Ef i fi; create item set I index (Ni) if it does not exist; add-task-to-agenda (N i,prio (N i),Agenda) od. 3.4 Agenda-based control The inference rules will be embedded in an agenda-based control regime along the line of <ref> [ Shieber, 1988 ] </ref> . An agenda consists of a list of tasks and a policy for managing it. A task is simply an item. <p> The only relevant parameter our algorithm has with respect to parsing and generation is the difference in input structures. Thus, we are able to characterise parsing and generation in a fairly balanced way without the loss of efficient properties. Hence, we avoid the complications or restrictions that <ref> [ Shieber, 1988 ] </ref> and [ Gerdemann, 1991 ] are confronted with, because of their "parsing oriented" view of generation.
Reference: [ Shieber, 1989 ] <author> S. M. Shieber. </author> <title> Parsing and Type Inference for Natural and Computer Languages. </title> <type> PhD thesis, </type> <institution> Stanford University, </institution> <note> SRI International Technical note 460, </note> <year> 1989. </year>
Reference-contexts: In the last few years constraint-based formalisms have undergone a rigorous formal investigation (consider for example <ref> [ Shieber, 1989; Smolka, 1988; Smolka, 1992 ] </ref> ). This has led to a general characterisation of constraint-based formalisms where feature structures are considered to constitute a semantic domain and constraints are considered syntactic representations of such `semantic structures'. This logical view has several advantages.
Reference: [ Shieber, 1993 ] <author> S. M. Shieber. </author> <title> The problem of logical-form equivalence. </title> <journal> Computational Linguistics, </journal> <volume> 19 </volume> <pages> 179-190, </pages> <year> 1993. </year>
Reference-contexts: Thus viewed, a grammar is a formal statement of the relation between utterances of a natural language and representations 4 of their meanings in some logical or other artifical language, where such representations are usually called logical forms <ref> [ Shieber, 1993 ] </ref> .
Reference: [ Smolka, 1988 ] <author> G. Smolka. </author> <title> A feature logic with subsorts. </title> <type> Technical report, </type> <institution> IBM Deutschland GmbH, Germany, </institution> <year> 1988. </year> <note> Lilog-Report 33. </note>
Reference-contexts: In the last few years constraint-based formalisms have undergone a rigorous formal investigation (consider for example <ref> [ Shieber, 1989; Smolka, 1988; Smolka, 1992 ] </ref> ). This has led to a general characterisation of constraint-based formalisms where feature structures are considered to constitute a semantic domain and constraints are considered syntactic representations of such `semantic structures'. This logical view has several advantages.
Reference: [ Smolka, 1992 ] <author> G. Smolka. </author> <title> Feature constraint logics for unification grammars. </title> <journal> The Journal of Logic Programming, </journal> <volume> 12 </volume> <pages> 51-87, </pages> <year> 1992. </year>
Reference-contexts: In the last few years constraint-based formalisms have undergone a rigorous formal investigation (consider for example <ref> [ Shieber, 1989; Smolka, 1988; Smolka, 1992 ] </ref> ). This has led to a general characterisation of constraint-based formalisms where feature structures are considered to constitute a semantic domain and constraints are considered syntactic representations of such `semantic structures'. This logical view has several advantages. <p> Hohfeld and Smolka show that answers computed in that way are answers for the goal. Constraint language The constraint language we will use is based on the definition of <ref> [ Smolka, 1992 ] </ref> . Smolka provides us with a very expressive constraint language including feature equation, conjunction, disjunction, negation, and existential quantification. <p> For the purpose of this work it suffices to use only a small subset of Smolka's constructions, namely feature equation and conjunction. 3 We will not give a formal definition of the constraint language here since this has already be done (see <ref> [ Smolka, 1992; VanNoord, 1993 ] </ref> ).
Reference: [ Somers et al., 1990 ] <author> H. Somers, J. Tsujii, and D. Jones. </author> <title> Machine translation without a source text. </title> <booktitle> In Proceedings of the 13th International Conference on Computational Linguistics (COLING), </booktitle> <volume> volume 3, </volume> <pages> pages 271-276, </pages> <address> Helsinki, </address> <year> 1990. </year>
Reference-contexts: Thus if we refer to the whole task of language processing we use the terms understanding and production. 2 Ronnquist, 1993 ] , grammar and style checkers, on-line translation, in which the target-- language text is generated in parallel with the source-language text <ref> [ Somers et al., 1990 ] </ref> , and text revision [ Vaughan and McDonald, 1986 ] . Interleaved parsing and generation seems also promising for question-answering systems where question understanding and answering is performed simultaneously [ Robertson, 1994 ] and for bidirectional dialogue systems [ Levine, 1992 ] . <p> ] have argued that such a combined view on parsing and generation|in particular following a uniform approach| are worthwhile for exploring highly interactive text-processing facilities such as structure-editing operations, propagation of minimal grammatical changes, or on-line translations, in which the target-language text is generated in parallel with the source-language text <ref> [ Somers et al., 1990 ] </ref> .
Reference: [ Steele, 1990 ] <author> G. L. Steele. </author> <title> Common LISP: The Language (Second Edition). </title> <publisher> Digital Press, </publisher> <address> Burlington, MA, </address> <year> 1990. </year>
Reference-contexts: The only functions that are defined as specific methods for the parsing and generation classes are make-item and add-item, and they differ only with respect to one 10 The object-oriented extension of UTA has been implemented in CLOS, the Common Lisp Object System <ref> [ Steele, 1990 ] </ref> (you might want to call UTA now UTA++). We therefore directly make use of the CLOS-class definition, abbreviated where convenient. In [ Keene, 1989 ] and [ Winston and Horn, 1989 ] good introductions to CLOS can be found. 25 additional call of a function.
Reference: [ Strzalkowski, 1994 ] <author> T. Strzalkowski. </author> <title> A general computational method for grammar inversion. </title> <editor> In Tomek Strzalkowski, editor, </editor> <booktitle> Reversible Grammar in Natural Language Processing, </booktitle> <pages> pages 175-199. </pages> <publisher> Kluwer, </publisher> <year> 1994. </year> <month> 50 </month>
Reference-contexts: Van Noord [ 1993 ] has extended this algorithm also for head-corner parsing. A main problem with his approach is that it does not support incremental processing. The use of the essential feature Ef as the single parameter of U TA is comparable to Strzalkowski's essential argument approach <ref> [ Strzalkowski, 1994 ] </ref> . However, he uses this information only off-line during grammar compilation in order to obtain specific parsing and generation grammars.
Reference: [ Uszkoreit, 1991 ] <author> H. Uszkoreit. </author> <title> Strategies for adding control information to declarative gram--mars. </title> <booktitle> In 29th Annual Meeting of the Association for Computational Linguistics, </booktitle> <address> Berkeley, </address> <year> 1991. </year>
Reference-contexts: U TA's agenda mechanism, for example, is already an important pre-requisition for the incorporation of such strategies, since it allows processing of new items in any order. Also the architecture of the item sharing approach has been designed to support preference-based control. 43 The strategies described in <ref> [ Uszkoreit, 1991 ] </ref> and [ Barnett, 1994 ] seem to be suitable candidates for the new uniform environment. The work described in [ Uszkoreit, 1991 ] is of importance since the approach focusses on the integration of preferences with the feature system of a constraint-based grammar as an appropriate means <p> Also the architecture of the item sharing approach has been designed to support preference-based control. 43 The strategies described in <ref> [ Uszkoreit, 1991 ] </ref> and [ Barnett, 1994 ] seem to be suitable candidates for the new uniform environment. The work described in [ Uszkoreit, 1991 ] is of importance since the approach focusses on the integration of preferences with the feature system of a constraint-based grammar as an appropriate means for obtaining plausible performance models.
Reference: [ VanNoord, 1993 ] <author> G. J. M. VanNoord. </author> <title> Reversibility in Natural Language Processing. </title> <type> PhD thesis, </type> <institution> University of Utrecht, </institution> <address> The Netherlands, </address> <year> 1993. </year>
Reference-contexts: For the purpose of this work it suffices to use only a small subset of Smolka's constructions, namely feature equation and conjunction. 3 We will not give a formal definition of the constraint language here since this has already be done (see <ref> [ Smolka, 1992; VanNoord, 1993 ] </ref> ). <p> Note further that the same subset has also been used by <ref> [ VanNoord, 1993 ] </ref> (for the same reasons). 4 The only important thing to note here, that constraints are based on disjoint sets of variables, constants, and features, as well as descriptor equations, where a descriptor is a (possible empty) sequence of features starting with a variable or a constant.
Reference: [ Vaughan and McDonald, 1986 ] <author> M. M. Vaughan and D. D. McDonald. </author> <title> A model of revision in natural language generation. </title> <booktitle> In 24th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> pages 90-96, </pages> <year> 1986. </year>
Reference-contexts: refer to the whole task of language processing we use the terms understanding and production. 2 Ronnquist, 1993 ] , grammar and style checkers, on-line translation, in which the target-- language text is generated in parallel with the source-language text [ Somers et al., 1990 ] , and text revision <ref> [ Vaughan and McDonald, 1986 ] </ref> . Interleaved parsing and generation seems also promising for question-answering systems where question understanding and answering is performed simultaneously [ Robertson, 1994 ] and for bidirectional dialogue systems [ Levine, 1992 ] . <p> Neither of the above mentioned approaches use shared items, basically because they do not consider interleaving of parsing and generation. Most approaches that consider an integrated approach can be found in the areas of artificial intelligence or cognitive science, e.g., [ Jameson and Wahlster, 1982 ] , <ref> [ Vaughan and McDonald, 1986 ] </ref> , [ DeSmedt and Kempen, 1987 ] , [ Meteer and Shaked, 1988 ] , [ Levelt, 1989 ] , [ Wahlster et al., 1991 ] .
Reference: [ Wahlster et al., 1991 ] <author> W. Wahlster, E. Andre, W. Graf, and T. Rist. </author> <title> Designing illustrated texts: How language production is influenced by graphics generation. </title> <booktitle> In Fifth Conference of the European Chapter of the Association for Computational Linguistics, </booktitle> <pages> pages 8-14, </pages> <address> Berlin, </address> <year> 1991. </year>
Reference-contexts: consider an integrated approach can be found in the areas of artificial intelligence or cognitive science, e.g., [ Jameson and Wahlster, 1982 ] , [ Vaughan and McDonald, 1986 ] , [ DeSmedt and Kempen, 1987 ] , [ Meteer and Shaked, 1988 ] , [ Levelt, 1989 ] , <ref> [ Wahlster et al., 1991 ] </ref> . Neither of them however perform interleaving of parsing and generation with an comparable degree of granularity, nor do they consider uniform processing and item sharing. 7.2 Future extensions Of course, the interleaved approach can be and should be extended and improved.
Reference: [ Wahlster, 1991 ] <author> W. Wahlster. </author> <title> User and discourse models for multimodal communication. In Intelligent user interfaces, </title> <booktitle> chapter 3, </booktitle> <pages> pages 45-67. </pages> <publisher> ACM Press, </publisher> <year> 1991. </year>
Reference-contexts: Clearly, additional knowledge-based mechanisms are needed for realizing full functionality, so that interleaved parsing and generation is only one step into that direction |however a substantial one. During natural language production interleaved parsing is important to obtain hearer-adaptable production of utterances. <ref> [ Wahlster, 1991 ] </ref> has expressed this under the term anticipation feedback loop afl. The basic idea of the afl model is the use of the system's natural language understanding part to anticipate the preferred users' interpretation of an utterance which the system plans to realize.
Reference: [ Winston and Horn, 1989 ] <author> P. H. Winston and B. K. P. Horn. </author> <title> LISP: </title> <booktitle> Third Edition. </booktitle> <address> AddisonWesley, Reading, MA, </address> <year> 1989. </year>
Reference-contexts: We therefore directly make use of the CLOS-class definition, abbreviated where convenient. In [ Keene, 1989 ] and <ref> [ Winston and Horn, 1989 ] </ref> good introductions to CLOS can be found. 25 additional call of a function.
Reference: [ Wiren and Ronnquist, 1993 ] <author> Mats Wiren and Ralph Ronnquist. </author> <title> Fully Incremental Parsing. </title> <booktitle> In Proc. Third International Workshop on Parsing Technologies, </booktitle> <address> Tilburg, the Netherlands and Durbuy, Belgium, </address> <year> 1993. </year> <month> 51 </month>
Reference-contexts: In fact, <ref> [ Wiren and Ronnquist, 1993 ] </ref> have argued that such a combined view on parsing and generation|in particular following a uniform approach| are worthwhile for exploring highly interactive text-processing facilities such as structure-editing operations, propagation of minimal grammatical changes, or on-line translations, in which the target-language text is generated in parallel
References-found: 56

