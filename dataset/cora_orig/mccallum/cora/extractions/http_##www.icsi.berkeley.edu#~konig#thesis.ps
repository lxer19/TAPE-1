URL: http://www.icsi.berkeley.edu/~konig/thesis.ps
Refering-URL: http://www.icsi.berkeley.edu/~konig/resume.html
Root-URL: http://www.icsi.berkeley.edu
Title: REMAP: Recursive Estimation and Maximization of A Posteriori Probabilities in Transition-based Speech Recognition  
Author: by Yochai Konig 
Degree: 1990 A dissertation submitted in partial satisfaction of the requirements for the degree of Doctor of Philosophy in Computer Science in the GRADUATE DIVISION of the UNIVERSITY of CALIFORNIA at BERKELEY Committee in charge: Professor Nelson Morgan, Chair Professor Jerome Feldman Professor Charles Stone  
Date: 1996  
Affiliation: B.S. (Technion, Israel Institute of Technology)  
Abstract-found: 0
Intro-found: 1
Reference: <author> Bahl, L. R., P. F. Brown, P. V de Souza, & R. L. Mercer. </author> <year> 1986. </year> <title> Maximum mutual information estimation of hidden Markov model parameters. </title> <booktitle> In Proc. Int. Conf. on Acoust., Speech, and Signal Processing, </booktitle> <pages> 49-52, </pages> <address> Tokyo, Japan. </address>
Reference-contexts: It is obvious that (3.10) and (3.11) are discriminant criteria. In <ref> (Bahl et al. 1986) </ref> it is shown that it is possible to get some kind of re-estimation recursion of local probabilities but, unfortunately, there is no proof that the recursion converges and there is no guarantee that the new estimates of (e.g., transition) probabilities are positive.
Reference: <author> Baker, J. K., </author> <year> 1975. </year> <title> Stochastic Modeling as a Means of Automatic Speech Recognition. </title> <institution> Carnegie Mellon University dissertation. </institution>
Reference: <author> Baum, L. E. </author> <year> 1972. </year> <title> An inequality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes. Inequalities 3.1-8. </title> ||, & <editor> T. Petrie. </editor> <year> 1966. </year> <title> Statistical inference for probabilistic functions of finite state Markov chains. </title> <journal> The Annals of Mathematical Statistics 36.1554-1563. </journal> ||, <note> T. </note> <author> Pitrie, G. Soules, & N. Weiss. </author> <year> 1970. </year> <title> A maximization technique occurring in the statistical analysis of probabilistic functions in Markov chains. </title> <journal> The Annals of Mathematical Statistics 41.164-171. </journal>
Reference: <author> Bengio, Y., & P. Frasconi. </author> <year> 1995. </year> <title> An input output HMM architecture. </title> <booktitle> In Advances in Neural Information Processing Systems, </booktitle> <editor> ed. by G. Tesauro, D. Touretzky, & T. Leen, </editor> <volume> volume 7. </volume> <publisher> Cambridge: MIT press. </publisher> ||, <editor> R. De Mori, G. Flammia, & R. Kompe. </editor> <year> 1992. </year> <title> Global optimization of a neural network-hidden Markov model hybrid. </title> <journal> IEEE trans. on Neural Networks 3.252-258. </journal>
Reference-contexts: Similarly, REMAP increases the global posterior function during the M step (in the direction of targets that actually maximize that global function), rather than actually maximizing it. Recently, a similar approach was suggested for mapping input sequences to output sequences <ref> (Bengio & Frasconi 1995) </ref>. 6.3.6 Complexity Issues It is important the computational cost of REMAP, particularly in comparison to the standard approach of training hybrid HMM/MLP systems (Bourlard & Morgan 1994).
Reference: <author> Bourlard, H., Y. Konig, & N. Morgan. </author> <year> 1994. </year> <title> REMAP: Recursive estimation and maximization of a posteriori probabilities, application to transition-based connectionist speech recognition. </title> <type> Technical Report TR-94-064, </type> <institution> International Computer Science Institute, Berkeley, </institution> <address> CA. 86 ||, & N. </address> <publisher> Morgan. </publisher> <year> 1994. </year> <title> Connectionist Speech Recognition A Hybrid Approach. </title> <publisher> Kluwer Academic Publishers. </publisher> ||, & <editor> C. J. Wellekens. </editor> <year> 1989a. </year> <title> Links between Markov models and multilayer perceptrons. </title> <booktitle> In Advances in Neural Information Processing Systems 1 , ed. by D.J. Touretzky, </booktitle> <pages> 502-510, </pages> <address> San Mateo. </address> <publisher> Morgan Kaufmann. </publisher> ||, & ||. <year> 1989b. </year> <title> Speech pattern discrimination and multilayer perceptrons. </title> <booktitle> Computer, Speech, and Language 3.1-19. </booktitle>
Reference-contexts: Another solution would be to assume a parametric form for the trajectory, as was done by Deng. Reported here is a multi-layer perceptron (MLP) approach which, in our previous work at ICSI (as discussed in Section 2.3.3), has proved useful for such estimates <ref> (Bourlard & Morgan 1994) </ref>. 1 Formally the values of the state process are ordered pairs of the phone and the time-index. 39 4.3.5 An Implementation of the Time-Index Model In our model we define the emission probability of a state as P (xjq j ; ti) . <p> With 40 the exception of this final input feature, this net was the same as the hybrid HMM/MLP system as described in <ref> (Bourlard & Morgan 1994) </ref>. <p> In the next chapter we describe a new training algorithm that overcomes some of the problems. 5.2 Estimation of the Posterior Probability of Word Se quences In <ref> (Bourlard & Morgan 1994) </ref> it was shown that it is possible to compute the global posterior probability P (M jX; L; fi) of (2.5) and (2.6) as: P (M jX; L; fi) = j = j in which " j " represents a legal state sequence in M , see Section <p> In this section we show that it can be done while meeting the constraint specified in Equation (2.7), i.e., I X P (M i jX; L; fi) = 1 (5.16) where the sum over i represents the sum over all possible Markov models <ref> (Bourlard et al. 1994) </ref>. Here lies the difference between an ML and an MAP criterion. <p> As presented in the initial theory <ref> (Bourlard & Morgan 1994) </ref> the paradigm for training (and recognition) was to use the Viterbi approximation, i.e., to consider only the most probable state sequence in assigning phonetic labels to acoustic frames. The local discriminant probabilities (2.14) were estimated by an MLP as represented in Figure 5.2. <p> With the exception of these binary inputs, this net was the same as the hybrid HMM/MLP system as described in <ref> (Bourlard & Morgan 1994) </ref>. The baseline HMM/MLP system (Bourlard & Morgan 1994) had 36.3% phone error on this task. When evaluating the Discriminant HMM on this task the error rate was 40.4%. <p> With the exception of these binary inputs, this net was the same as the hybrid HMM/MLP system as described in <ref> (Bourlard & Morgan 1994) </ref>. The baseline HMM/MLP system (Bourlard & Morgan 1994) had 36.3% phone error on this task. When evaluating the Discriminant HMM on this task the error rate was 40.4%. This was 49 an intriguingly negative result; increasing the amount of input information led to a decrease in generalization performance. <p> However, in general, the nets will not be trained to their optimal minimum because of * "overlapping" of input patterns (e.g., two instances of the same pattern with two different classifications). * use of cross-validation (early stopping) <ref> (Bourlard & Morgan 1994) </ref> to avoid over fitting and to get better estimates of actual probabilities. Below we describe a training procedure for the MLP and a corresponding error criterion. We show that by minimizing this criterion we are maximizing the auxiliary function R (). <p> In principle, REMAP should ultimately provide improved recognition accuracy for practical systems. However, as with all other gradient-based optimization techniques, we will be vulnerable to potential difficulties with local minima. 59 6.3 REMAP Training 6.3.1 Introduction Since it is now well-known <ref> (Bourlard & Morgan 1994) </ref> how to train an MLP to lead to good estimates of posterior probabilities (whether the MLP targets are "1-from-K" binary vector or themselves estimates of posterior probabilities), the remaining problem is to find an efficient algorithm to express P (q n ` jX; q n1 k ; <p> Recently, a similar approach was suggested for mapping input sequences to output sequences (Bengio & Frasconi 1995). 6.3.6 Complexity Issues It is important the computational cost of REMAP, particularly in comparison to the standard approach of training hybrid HMM/MLP systems <ref> (Bourlard & Morgan 1994) </ref>. The computation of the MLP targets and the distribution of the previous state is done by running the forward and backward recurrences as described above. <p> In principle P ( i jM; L; fi) and P ( i jL; fi) can be estimated during training by dynamic programming techniques similar to our ff and fi recurrences <ref> (Bourlard et al. 1994) </ref>, and the ratio of these two terms represents the additional state transition information that is gained by knowing the specific word sequence. 67 Chapter 7 Experimental Results with REMAP 7.1 Isolated Speech Experiments In this section we report on experiments with isolated speech, where recognition was based <p> Note that the row entitled "Baseline Hybrid" refers to an ANN trained on targets of 1's and 0's that were obtained from a forced Viterbi procedure by our standard HMM/ANN system as described in <ref> (Bourlard & Morgan 1994) </ref>; the row entitled "DHMM, pre-REMAP" means a Discriminant HMM using the same training approach, with hard targets determined by the first system, and additional inputs to represent the previous state. <p> Modeling Extensions In this study although we could increase the complexity we have used a simple 1st order Markov model. The extension to an M-th order model is described in <ref> (Bourlard et al. 1994) </ref>. However, the increased complexity of the model requires more training data to reliably estimate the model parameters. Further, a more complex model has no guarantee to work better.
Reference: <author> Bridle, J. S. </author> <year> 1990. </year> <title> Alpha-nets: A recurrent "neural" network architecture with a hidden Markov model interpretation. Speech Communication 9.83-92. </title>
Reference-contexts: As a consequence, a local gradient ascent method is usually used for optimization and the standard (likelihood-based) forward-backward recurrences are used to estimate the gradient. This is similar to the Alpha-Nets presented in <ref> (Bridle 1990) </ref> in which the gradient of the mutual information criterion takes the form of the backward recurrence used in the Baum-Welch algorithm.
Reference: <author> Brown, P. F., </author> <year> 1987. </year> <title> The Acoustic-Modelling Problem in Automatic Speech Recognition. </title> <address> Pittsburgh, PA: CMU dissertation. </address>
Reference-contexts: of forcing discrimination, numerical problems that plague the classical HMM are avoided when using discriminant models: namely, the lack of balance between the transition probability values (which only depend on the topology of the model) and the emission probability values (which decrease with the dimension of the input feature space) <ref> (Brown 1987) </ref>. 5.4 Early Experiments and Error Analysis 5.4.1 Early Experiments Given the theoretical properties of the Discriminant HMM/MLP model described earlier, we felt that empirical evaluations of this model would be a good first step in improving our understanding of transition-based systems.
Reference: <author> Cohen, J. R., </author> <year> 1995. </year> <title> Informal Communication. </title>
Reference-contexts: Another possible extension is to apply REMAP to perceptually-motivated models such as SPAM (Morgan et al. 1994; Morgan et al. 1995). 8.3 Epilog In experimental science such as speech recognition, a division between data description and data modeling can be drawn <ref> (Cohen 1995) </ref>. Data description is taking an existing model and increasing its complexity, adding more exceptions to better fit the observed data; for instance, adding triphones to HMMs.
Reference: <author> Cole, R. A., M. Fanty, & T. Lander. </author> <year> 1994. </year> <title> Telephone speech corpus development at CSLU. </title> <booktitle> In Proceedings Int'l Conference on Spoken Language Processing, </booktitle> <address> Yokohama, Japan. </address>
Reference-contexts: For this purpose we chose the Numbers'93 corpus. It is a continuous-speech database collected by CSLU at the Oregon Graduate Institute. It consists of numbers spoken naturally over telephone lines on the public-switched network <ref> (Cole et al. 1994) </ref>. The Numbers'93 database consists of 2167 speech files of spoken numbers produced by 1132 callers. We used 877 of these utterances for training and 657 for cross-validation and testing (200 for cross-validation).
Reference: <author> Cover, T. M., & A. T. Joy. </author> <year> 1991. </year> <title> Elements of Information Theory. </title> <address> New York: </address> <publisher> John Wiley and Sons, Inc. </publisher>
Reference-contexts: best we can do is to optimize its ability to distinguish between the underlying classes, which is typically achieved by replacing the ML criterion by a discriminant one. 3.2.2 Maximum Mutual Information (MMI) Initially introduced in (Bahl et al. 1986; Brown 1987), this method aims at maximizing the mutual information <ref> (Cover & Joy 1991) </ref> between a set of (sentence) models M w j and the associated sequences of acoustic vectors X j . This mutual information is then defined as (Cover & Joy 1991): I (M w j ; X j jL; fi) = M w j ;X j p (M <p> Mutual Information (MMI) Initially introduced in (Bahl et al. 1986; Brown 1987), this method aims at maximizing the mutual information <ref> (Cover & Joy 1991) </ref> between a set of (sentence) models M w j and the associated sequences of acoustic vectors X j . This mutual information is then defined as (Cover & Joy 1991): I (M w j ; X j jL; fi) = M w j ;X j p (M w j ; X j jL; fi) (3.8) 30 ( p (M w j ; X j jL; fi) ) where fi is the whole parameter space (for all models) <p> Note that the relative entropy between two probability mass functions is always greater or equal to zero <ref> (Cover & Joy 1991) </ref>. Given that the targets are posterior probabilities, a network trained to the global minimum of error criterion (6.8) will estimate the posteriors. An important point is that previous state q n1 k is not one of the features that are extracted from the speech waveform.
Reference: <author> Dempster, A. P., N. M. Laird, & D. B. Rubin. </author> <year> 1977. </year> <title> Maximum likelihood from incomplete data via the EM algorithm. </title> <journal> Journal of the Royal Statistical Society, Series B 34.1-38. </journal>
Reference-contexts: Starting from initial guesses fi 0 , the model parameters are iteratively updated according to the "Forward-Backward" algorithm [or, equivalently, the Expectation-Maximization (EM) algorithm <ref> (Dempster et al. 1977) </ref>] so that (3.1) is maximized at each iteration. This kind of training algorithm, often referred to as Baum-Welch training in the particular case of HMMs, can also be interpreted in terms of gradient techniques (Levinson et al. 1983a; Levinson 1985). <p> We maximize the function using the estimated Y and we get a new set of parameters fi t+1 that lead to a new estimate of the missing data Y . The estimation and maximization steps are iterated until the guaranteed convergence to a local maximum <ref> (Dempster et al. 1977) </ref>. More precisely, following (Dempster et al. 1977), the goal is to maximize the following likelihood function L (X; fi), where fi is the set of the parameters of the function and X the observations. The function estimates the log-likelihood of producing the observations given fi. <p> The estimation and maximization steps are iterated until the guaranteed convergence to a local maximum <ref> (Dempster et al. 1977) </ref>. More precisely, following (Dempster et al. 1977), the goal is to maximize the following likelihood function L (X; fi), where fi is the set of the parameters of the function and X the observations. The function estimates the log-likelihood of producing the observations given fi. <p> theorem is how to find a new set of probabilities 2 that increases the value of the auxiliary function R () and, consequently, the posterior probability of the correct model (and therefore also minimizes the posterior probability of the rival models). 2 This auxiliary function is usually denoted Q () <ref> (Dempster et al. 1977) </ref>. <p> In this regards, it is reminiscent of the Estimation-Maximization (EM) algorithm as discussed in <ref> (Dempster et al. 1977) </ref>. The algorithm is illustrated in Figure 6.1. However, in the standard EM algorithm, the M step involves the actual maximization of the likelihood function.
Reference: <author> Deng, L. </author> <year> 1992. </year> <title> A generalized hidden Markov model with state-conditioned trend functions of time for the speech signal. Signal Processing 27.65-78. ||, & D.X. Sun. 1994. A statistical approach to automatic speech recognition using the atomic speech units constructed from overlapping articulatory features. </title> <journal> J. Acoustical Society of America 95.2702-2719. </journal>
Reference-contexts: The main idea behind the time-index model is that all the trajectories of a phone in the acoustic vector space share a stochastic dependency on the time elapsed since the beginning of the phone. This dependency can be modeled by a parametric distribution as in Deng's model <ref> (Deng 1992) </ref> or by using an MLP in our model. 4.3.2 Deng's Trended HMM Deng described a model that explicitly conditioned the emission probability of a state on the time index, i.e., on the number of frames between the current frame and the previous state transition. <p> Deng has coined his model the "trended HMM" <ref> (Deng 1992) </ref>.
Reference: <author> Digalakis, V. V., </author> <year> 1992. </year> <title> Segment-Based Stochastic Models of Spectral Dynamics for Continuous Speech Recognition. </title> <institution> Boston University dissertation. </institution> <note> 87 ||, J. </note> <author> R. Rohlicek, & M. Ostendorf. </author> <year> 1993. </year> <title> Segment-based stochastic models of spectral dynamics for continuous speech recognition. </title> <journal> IEEE trans. on Speech and Audio Processing 1.431-442. </journal>
Reference-contexts: Introduction In segment-based models the basic unit is a sequence of acoustic vectors emitted in a given speech unit (a "segment"), as opposed to a single acoustic vector as used for HMMs. The production of the acoustic vectors in a segment may be described as a three step procedure <ref> (Digalakis 1992) </ref>: 1. Select the length of the segment according to P (Ljs k ), where L is the random variable that denotes the length of the segment, and s k is a particular speech unit. 2.
Reference: <author> Duda, R. O., & P. E. Hart. </author> <year> 1973. </year> <title> Pattern Classification and Scene Analysis. </title> <publisher> John Wiley and Sons, Inc. </publisher>
Reference-contexts: system, such as the arguable assumptions of linearity and several types of invariance. 25 Chapter 3 Training Algorithms and Optimization Criteria 3.1 Likelihood Estimation and Training 3.1.1 Introduction Theoretically the optimal way to classify an input sequence is to choose the class with the highest posterior probability given this sequence <ref> (Duda & Hart 1973) </ref>. Therefore, at training we want to maximize the posterior probability of the correct model (sentence) given the evidence (sequence of acoustic vectors). An optimization criterion for parameter estimation that achieves this goal during training, is the Maximum a Posteriori (MAP) criterion.
Reference: <author> Efron, B. </author> <year> 1982. </year> <title> The jackknife, the bootstrap, and other resampling plans. </title> <institution> Society for Industrial and Applied Mathematics, </institution> <address> Philadelphia, Pa. </address>
Reference-contexts: The additive noise in these experiments was automotive sound that was recorded over a cellular telephone. Noise was randomly selected from this source and then added to the clean speech waveforms (10 dB S/N ratio). In order to better utilize the data we used a jackknife procedure <ref> (Efron 1982) </ref>. For each of four experiments, three fourths of the data was used for training and cross-validation, and one fourth was used for testing. Specifically, in each experiment there were 1720 utterances for training, 230 for cross-validation and 650 (from 50 speakers) for testing.
Reference: <author> Fujimura, O. </author> <year> 1975. </year> <title> Syllable as a unit of speech recognition. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing ASSP-23.82-87. </journal>
Reference: <author> Furui, S. </author> <year> 1986a. </year> <title> On the role of spectral transition for speech perception. </title> <journal> J. Acoustical Society of America 80.1016-1025. </journal> || <year> 1986b. </year> <title> Speaker independent isolated word recognizer using dynamic features of speech spectrum. </title> <journal> IEEE Trans. on Acoustics, Speech, and Signal Processing 34.52-59. </journal>
Reference-contexts: In a more recent study Furui has suggested that sufficient information for both vowel and consonant identification is contained across the same initial part of each syllable 36 <ref> (Furui 1986a) </ref>. This part includes the maximum spectral transition. He also verified that the steady-state portions of the formants are not the only key for either vowel or syllable perception.
Reference: <author> Garofolo, J. S., </author> <year> 1988. </year> <title> Getting Started with the DARPA TIMIT CD-ROM: an Acoustic Phonetic Continuous Speech Database. </title> <institution> National Institute of Standards and Technology (NIST), Gaithersburgh, Maryland. </institution>
Reference-contexts: During recognition however, the MLP outputs will have to be hypothesized for every possible previous state (possibly constrained by a particular HMM topology or a language model). The TIMIT corpus <ref> (Garofolo 1988) </ref> was chosen for the experiments because it is phonetically balanced and in addition there are time-aligned phonetic transcriptions of all the sentences in the database.
Reference: <author> Ghitza, O., & M. M. Sondhi. </author> <year> 1993. </year> <title> Hidden Markov models with templates as nonstationary states: an application to speech recognition. </title> <booktitle> Computer Speech and Language 2.101-119. </booktitle>
Reference-contexts: Their specific implementation had ten 14-dimensional vectors of cepstral coefficients. They used a multivariate Gaussian to 23 represent the entire segment, which can require a 140 by 140 full covariance matrix for each phone (assuming that feature dependence is accounted for). Ghitza and Sondhi developed a model <ref> (Ghitza & Sondhi 1993) </ref> that can also be viewed as a stochastic segment model with the following distinctions: * Their warping procedure is a dynamic time warping technique, instead of the linear time warping method used by Ostendorf and Roukos. * They used diphones as their sub-word units, as opposed to
Reference: <author> Gish, H. </author> <year> 1990. </year> <title> A probabilistic approach to the understanding and training of neural network classifiers. </title> <booktitle> In Proc. Int. Conf. on Acoust., Speech, and Signal Processing, </booktitle> <pages> 1361-1364, </pages> <address> Albuquerque, NM. </address>
Reference: <author> Glass, J. R., </author> <year> 1988. </year> <title> Finding Acoustic Regularities in Speech Applications to Phonetic Recognition. </title> <publisher> M.I.T dissertation. </publisher>
Reference-contexts: P (ti; phone j ) can be estimated by counting the relative frequencies in the training set. Given that there is an accurate estimate of the boundaries between the phones we can calculate P (tijx); otherwise an estimation of this probability is a difficult problem <ref> (Glass 1988) </ref>. 4.3.6 Experiments The Resource Management (RM) speaker independent task (Price et al. 1988) and the TIMIT database were used for initial experiments. In the RM experiments our training data consisted of 3990 read, continuous-speech sentences, and the 300-sentence Feb89 test set for network cross-validation and testing. <p> The first potential problem is missing transitions; implicitly the net is a transition detector because when it determines that the current state is different from the previous one it signals a transition, and transition detection between phonemes is known to be a hard problem (see <ref> (Glass 1988) </ref>). In order to test this assumption we compared the performance of the MLP described above on two kinds of acoustic frames: transition frames that start a new segment, i.e., their phonetic label is different from the previous frame, and all other frames, self-loop frames. <p> However, it is well known that estimating transitions accurately is a difficult problem <ref> (Glass 1988) </ref>. Due to the inertia of the articulators, the boundaries between phones are blurred and overlapped in continuous speech (Deng & Sun 1994). It is also likely that some time variability exists in the human perception of the onset of a new phonetic region.
Reference: <author> Goldenthal, W. D., </author> <year> 1994. </year> <title> Statistical Trajectory Models for Phonetic Recognition. M.I.T dissertation. </title> <note> 88 Haeb-Umbach, </note> <author> R., & H. Ney. </author> <year> 1992. </year> <title> Linear discriminant analysis for improved large vocabulary continuous speech recognition. </title> <booktitle> In Proc. Int. Conf. on Acoust., Speech, and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> 13-16, </pages> <address> San Francisco, USA. </address>
Reference-contexts: Experiments with the time-index model as described below established the necessary condition that accurate transition information can significantly improve recognition performance. These results were corroborated by a recent study by Goldenthal <ref> (Goldenthal 1994) </ref>. Goldenthal found a consistent improvement in phone recognition results when enhancing his segment-based models with explicit transition models. He used a set of 200 canonical transitions that were created by clustering all the transitions in the training set.
Reference: <author> Hermansky, H. </author> <year> 1990. </year> <title> Perceptual linear predictive (PLP) analysis of speech. </title> <journal> J. Acoustical Society of America 87. </journal>
Reference-contexts: There were 235 inputs to the net, including 234 that consisted of 9 frames of 26 features each (PLP12 + log gain + delta features for each of these 13) <ref> (Hermansky 1990) </ref>, and a final time-index input. With 40 the exception of this final input feature, this net was the same as the hybrid HMM/MLP system as described in (Bourlard & Morgan 1994). <p> There were 295 inputs to the net, including 234 that consisted of 9 frames of 26 features each (PLP12 + log gain + delta features for each of these 13) <ref> (Hermansky 1990) </ref>, and 61 binary inputs that represented the possible previous state. With the exception of these binary inputs, this net was the same as the hybrid HMM/MLP system as described in (Bourlard & Morgan 1994).
Reference: <author> Huang, X. D., Y. Ariki, & M. A. Jack. </author> <year> 1990. </year> <title> Hidden Markov Models For Speech Recognition. </title> <publisher> Edinburgh University Press. </publisher>
Reference: <author> Jelinek, F. </author> <year> 1976. </year> <title> Continuous speech recognition by statistical methods. </title> <booktitle> Proceedings of the IEEE 64.532-556. </booktitle> ||, & <editor> R. L. Mercer. </editor> <year> 1980. </year> <title> Interpolated estimation of Markov source parameters from sparse data. In Pattern Recognition in Practice, </title> <editor> ed. by E. S. Gelsema & L. N. Kanal, </editor> <address> 381-397. Amsterdam, The Netherlands: </address> <publisher> North-Holland Publishing Company. </publisher>
Reference: <author> Juang, B. H., & L. R. Rabiner. </author> <year> 1985. </year> <title> Mixture autoregressive hidden Markov models for speech signals. </title> <journal> IEEE ASSP Magazine 6.1404-1413. </journal>
Reference: <author> Katagiri, S., C. H. Lee, & Juang B. H. </author> <year> 1991. </year> <title> New discriminative training algorithms based on the generalized probabilistic decent method. </title> <booktitle> In Proc. of the IEEE Workshop on Neural Netwroks for Signal Processing, </booktitle> <editor> ed. </editor> <title> by B.H. </title> <type> Juang, S.Y. Kung, </type> & <address> C.A. </address> <publisher> Kamm, </publisher> <pages> 299-308. </pages>
Reference-contexts: GPD is actually very close in spirit to MMI, although it permits generalization to different kinds of training criteria <ref> (Katagiri et al. 1991) </ref>. The idea of GPD is simple and can be summarized as follows. Given the whole set of parameters 1 fi, define a discriminant function associated with each (word or sentence) model M i as g i (X; fi). <p> Given the whole set of parameters 1 fi, define a discriminant function associated with each (word or sentence) model M i as g i (X; fi). This discriminant function can be any differentiable distance function or probability distribution. Several instances of this are discussed in <ref> (Katagiri et al. 1991) </ref>, each of them leading to different interpretations (as is also the case for MMI and MAP training). <p> Here again, several measures can be used, each of them leading to different interpretations. However, one of the most general ones given in <ref> (Katagiri et al. 1991) </ref> is: d j (X; fi) = g j (X; fi) log 4 1 X exp (g i (X; fi)) 5 (3.14) in which I represents the total number of possible reference models.
Reference: <author> Kiang, N. Y. S. </author> <year> 1984. </year> <title> Peripheral neural processing of auditory information. In In Handbook of physiology the nervous system, volume III, sensory processes, part 2 , ed. </title> <editor> by J. M. Brookhart & V. </editor> <booktitle> Mountcastle, </booktitle> <pages> 639-674. </pages> <address> Bethesda: </address> <publisher> American Physiological Society. </publisher>

Reference: <author> Lee, K. F. </author> <year> 1989. </year> <title> Automatic Speech Recognition: The Development of the SPHINX System. </title> <publisher> Kluwer Academic Publishers. </publisher>
Reference: <author> Levelt, W. J. M., & L. Wheeldon. </author> <year> 1994. </year> <title> Do speakers have access to a mental syllabary? Cognition 50.239-269. </title>
Reference: <author> Levinson, S. E. </author> <year> 1985. </year> <title> Structural methods in automatic speech recognition. </title> <note> Proceedings of the IEEE 73.1625-1650. </note> ||, <author> L. R. Rabiner, & M. M. Sondhi. </author> <year> 1983a. </year> <title> An introduction to the application of the theory of probabilistic functions on a Markov process to automatic speech recognition. </title> <note> Bell System Technical Journal 62.243-272. </note> ||, <author> Lawrence R. Rabiner, & Man Mohan Sondhi. </author> <year> 1983b. </year> <title> An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition. </title> <institution> Bell Syst. Tech. J. 62.1035-1074. </institution>
Reference: <author> Lindblom, B. E. F., & M. Studdert-Kennedy. </author> <year> 1967. </year> <title> On the role of formant transitions in vowel recognition. </title> <journal> J. Acoustical Society of America 42.830-843. </journal>
Reference-contexts: For example, when vowels are co-articulated with consonants, the spectral pattern of the speech signal varies such that the acoustic targets found in isolated vowels are never fully realized in the changing spectrum. This is usually called "undershoot" <ref> (Lindblom & Studdert-Kennedy 1967) </ref>. Obviously, in humans this problem is normally coped with. The question whether human phonemic recognition is context-free or context-dependent has been addressed by Lindblom and Studdert-Kennedy among others (Lindblom & Studdert-Kennedy 1967). In their experiments, they tested the role of formant transitions in vowel recognition. <p> This is usually called "undershoot" <ref> (Lindblom & Studdert-Kennedy 1967) </ref>. Obviously, in humans this problem is normally coped with. The question whether human phonemic recognition is context-free or context-dependent has been addressed by Lindblom and Studdert-Kennedy among others (Lindblom & Studdert-Kennedy 1967). In their experiments, they tested the role of formant transitions in vowel recognition.
Reference: <author> Liporace, L. A. </author> <year> 1982. </year> <title> Maximum likelihood estimation for multivariate observations of markov sources. </title> <journal> IEEE Trans. on Information Theory IT-28.729-734. </journal>
Reference-contexts: One possible solution to these problems is to use a full MAP algorithm to find transition probabilities at each frame for all possible transitions with a forward-backward-like algorithm <ref> (Liporace 1982) </ref>, which takes all possible paths into account. Furthermore a MAP algorithm would increase the a posteriori probability of the correct model and reduce the posterior probabilities of all other models. Thus, it might improve the approximation to an optimal Bayes classifier.
Reference: <author> Lippmann, R. P. </author> <year> 1989. </year> <title> Review of neural networks for speech recognition. </title> <booktitle> Neural Computation 1.1-38. </booktitle>
Reference: <author> Lubensky, D. M., A. O. Asadi, & J. M. Naik. </author> <year> 1994. </year> <title> Connected digit recognition using connectionist probability estimators and mixture-gaussian densities. </title> <booktitle> In Proceedings Int'l Conference on Spoken Language Processing, </booktitle> <pages> 295-298, </pages> <address> Yokohama, Japan. </address>
Reference: <author> Lyon, R. F., & L. S. Yaeger. </author> <year> 1996. </year> <title> On-line hand-printing recognition with neural networks. </title> <booktitle> In MicroNeuro '96 Fifth International Conference on Microelectronics for Neural Networks and Fuzzy Systems, </booktitle> <pages> 201-212, </pages> <address> Lausanne, Switzerland. </address> <publisher> IEEE. </publisher> <address> 90 Merialdo, </address> <publisher> B. </publisher> <year> 1988. </year> <title> Phonetic recognition using hidden Markov models and maximum mutual information training. </title> <booktitle> In Proc. Int. Conf. on Acoust., Speech, and Signal Processing, </booktitle> <pages> 111-114, </pages> <address> New York. </address>
Reference-contexts: According to this estimated distribution of the previous state we would select the 77 pairs of acoustic vectors and previous states as described in Section 6.3. In other work, Lyon and Yaeger recently showed that explicit training on negative examples can improve recognition for on-line hand-recognition with ANNs <ref> (Lyon & Yaeger 1996) </ref>. Modeling Extensions In this study although we could increase the complexity we have used a simple 1st order Markov model. The extension to an M-th order model is described in (Bourlard et al. 1994).
Reference: <author> Morgan, N., H. Bourlard, S. Greenberg, & H. Hermansky. </author> <year> 1994. </year> <title> Stochastic perceptual auditory-event-based models for speech recognition. </title> <booktitle> In Proceedings Int'l Conference on Spoken Language Processing, </booktitle> <pages> 1943-1946, </pages> <address> Yokohama, </address> <note> Japan. </note> ||, <author> S. Wu, & H. Bourlard. </author> <year> 1995. </year> <title> Digit recognition with stochastic perceptual speech models. </title> <booktitle> In Proceedings of the Sixth European Conference on Speech Communication and Technology, </booktitle> <address> Madrid, Spain. </address>
Reference-contexts: See also <ref> (Konig & Morgan 1994) </ref>. 4.3.4 An Example the basic speech units. Only the last state in the model has a self loop. <p> Another solution would be to assume a parametric form for the trajectory, as was done by Deng. Reported here is a multi-layer perceptron (MLP) approach which, in our previous work at ICSI (as discussed in Section 2.3.3), has proved useful for such estimates <ref> (Bourlard & Morgan 1994) </ref>. 1 Formally the values of the state process are ordered pairs of the phone and the time-index. 39 4.3.5 An Implementation of the Time-Index Model In our model we define the emission probability of a state as P (xjq j ; ti) . <p> With 40 the exception of this final input feature, this net was the same as the hybrid HMM/MLP system as described in <ref> (Bourlard & Morgan 1994) </ref>. <p> In the next chapter we describe a new training algorithm that overcomes some of the problems. 5.2 Estimation of the Posterior Probability of Word Se quences In <ref> (Bourlard & Morgan 1994) </ref> it was shown that it is possible to compute the global posterior probability P (M jX; L; fi) of (2.5) and (2.6) as: P (M jX; L; fi) = j = j in which " j " represents a legal state sequence in M , see Section <p> As presented in the initial theory <ref> (Bourlard & Morgan 1994) </ref> the paradigm for training (and recognition) was to use the Viterbi approximation, i.e., to consider only the most probable state sequence in assigning phonetic labels to acoustic frames. The local discriminant probabilities (2.14) were estimated by an MLP as represented in Figure 5.2. <p> With the exception of these binary inputs, this net was the same as the hybrid HMM/MLP system as described in <ref> (Bourlard & Morgan 1994) </ref>. The baseline HMM/MLP system (Bourlard & Morgan 1994) had 36.3% phone error on this task. When evaluating the Discriminant HMM on this task the error rate was 40.4%. <p> With the exception of these binary inputs, this net was the same as the hybrid HMM/MLP system as described in <ref> (Bourlard & Morgan 1994) </ref>. The baseline HMM/MLP system (Bourlard & Morgan 1994) had 36.3% phone error on this task. When evaluating the Discriminant HMM on this task the error rate was 40.4%. This was 49 an intriguingly negative result; increasing the amount of input information led to a decrease in generalization performance. <p> However, in general, the nets will not be trained to their optimal minimum because of * "overlapping" of input patterns (e.g., two instances of the same pattern with two different classifications). * use of cross-validation (early stopping) <ref> (Bourlard & Morgan 1994) </ref> to avoid over fitting and to get better estimates of actual probabilities. Below we describe a training procedure for the MLP and a corresponding error criterion. We show that by minimizing this criterion we are maximizing the auxiliary function R (). <p> In principle, REMAP should ultimately provide improved recognition accuracy for practical systems. However, as with all other gradient-based optimization techniques, we will be vulnerable to potential difficulties with local minima. 59 6.3 REMAP Training 6.3.1 Introduction Since it is now well-known <ref> (Bourlard & Morgan 1994) </ref> how to train an MLP to lead to good estimates of posterior probabilities (whether the MLP targets are "1-from-K" binary vector or themselves estimates of posterior probabilities), the remaining problem is to find an efficient algorithm to express P (q n ` jX; q n1 k ; <p> Recently, a similar approach was suggested for mapping input sequences to output sequences (Bengio & Frasconi 1995). 6.3.6 Complexity Issues It is important the computational cost of REMAP, particularly in comparison to the standard approach of training hybrid HMM/MLP systems <ref> (Bourlard & Morgan 1994) </ref>. The computation of the MLP targets and the distribution of the previous state is done by running the forward and backward recurrences as described above. <p> Note that the row entitled "Baseline Hybrid" refers to an ANN trained on targets of 1's and 0's that were obtained from a forced Viterbi procedure by our standard HMM/ANN system as described in <ref> (Bourlard & Morgan 1994) </ref>; the row entitled "DHMM, pre-REMAP" means a Discriminant HMM using the same training approach, with hard targets determined by the first system, and additional inputs to represent the previous state.
Reference: <author> Nadas, A. </author> <year> 1983. </year> <title> A decision-theortic formulation of a training problem in speech recognition and a comparison of training by unconditional versus conditional maximum likelihood. </title> <journal> IEEE Transactions on Acoustics, Speech, and Signal Processing 31.814-817. </journal> <volume> NIST, </volume> <year> 1992. </year> <title> Switchboard Corpus: Recorded Telephone Conversations. National Institute of Standards and Technology Speech Disc 9-1.1 to 9-29.1, Collected by Texas Instruments. </title>
Reference: <author> Ostendorf, M., & S. Roukos. </author> <year> 1989. </year> <title> A stochastic segment model for phoneme-based continuous speech recognition. </title> <journal> IEEE ASSP trans. 37.1857-1869. </journal>
Reference-contexts: This transformation can be either linear or non-linear depending on the specific segmental model. Segmental Models These models differ in the form of the distribution (Y js k ) and in the time-warping transformation T L . Ostendorf and Roukos <ref> (Ostendorf & Roukos 1989) </ref> have used (among a number of methods) linear time sampling in their study, i.e., sampling Y in equal intervals along the time axis as their time warping procedure. Their specific implementation had ten 14-dimensional vectors of cepstral coefficients. <p> a stochastic segment model with the following distinctions: * Their warping procedure is a dynamic time warping technique, instead of the linear time warping method used by Ostendorf and Roukos. * They used diphones as their sub-word units, as opposed to the phones in Ostendorf and Roukos' stochastic segment model <ref> (Ostendorf & Roukos 1989) </ref>. * They maintained the HMM framework and assumed a semi-hidden Markov chain, i.e., each state has an explicit duration distribution. These stochastic segment models are not inherently subject to the constraints of the i.i.d. assumptions discussed earlier. However, there are some practical difficulties: 1.
Reference: <author> Poritz, A. B., & A. L. Richter. </author> <year> 1986. </year> <title> On hidden Markov models in isolated word recognition. </title> <booktitle> In Proc. Int. Conf. on Acoust., Speech, and Signal Processing, volume 1 of Tokyo, Japan, </booktitle> <pages> 705-708. </pages>
Reference: <author> Price, P., W. Fisher, J. Bernstein, & D. Pallet. </author> <year> 1988. </year> <title> The darpa 1000-word resource management database for continuous spee ch recognition. </title> <booktitle> In Proceedings IEEE Intl. Conf. on Acoustics, Speech, and Signal Processing, </booktitle> <volume> volume 1, </volume> <pages> 651-654, </pages> <address> New York. </address> <publisher> IEEE. </publisher>
Reference-contexts: Given that there is an accurate estimate of the boundaries between the phones we can calculate P (tijx); otherwise an estimation of this probability is a difficult problem (Glass 1988). 4.3.6 Experiments The Resource Management (RM) speaker independent task <ref> (Price et al. 1988) </ref> and the TIMIT database were used for initial experiments. In the RM experiments our training data consisted of 3990 read, continuous-speech sentences, and the 300-sentence Feb89 test set for network cross-validation and testing.
Reference: <author> Rabiner, </author> <title> L.R. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. </title> <booktitle> Proceedings of the IEEE 77.257-285. </booktitle>
Reference: <author> Renals, S., N. Morgan, & H. Bourlard. </author> <year> 1991. </year> <title> Probability estimation by feed-forward networks in continuous speech recognition. </title> <type> Technical Report TR-91-030, </type> <institution> International Computer Science Institute, 1947 Center St., </institution> <address> Suite 600, Berkeley, CA 94704. </address> <note> 91 ||, ||, ||, M. </note> <author> Cohen, & H. Franco. </author> <year> 1994. </year> <title> Connectionist probability estimators in HMM speech recognition. </title> <journal> IEEE Trans. </journal> <note> on Speech and Audio Processing 2.161-174. </note> ||, <author> N. Morgan, M. Cohen, H. Franco, & H. Bourlard. </author> <year> 1992. </year> <title> Connectionist probability estimation in the DECIPHER speech recognition system. </title> <booktitle> In Proc. Int. Conf. on Acoust., Speech, and Signal Processing, </booktitle> <pages> 601-604, </pages> <address> San Francisco, California. </address> <publisher> IEEE. </publisher>
Reference: <author> Richard, M. D., & R. P. Lippmann. </author> <year> 1991. </year> <title> Neural network classifiers estimate bayesian a posteriori probabilities. </title> <booktitle> Neural Computation 3.461-483. </booktitle>
Reference: <author> Robinson, A. J. </author> <year> 1994. </year> <title> An application of recurrent nets to phone probability estimation. </title> <journal> IEEE transactions on Neural Networks 5.298-305. </journal> ||, <note> L. </note> <author> Almeida, J.-M. Boite, H. Bourlard, F. Fallside, M. Hochberg, D. Ker-shaw, P. Kohn, Y. Konig, N. Morgan, J. P. Neto, S. Renals, M. Saerens, & C. Wooters. </author> <year> 1993. </year> <title> A neural network based, speaker independent, large vocabulary, continuous speech recognition system: The wernicke project. </title> <booktitle> In Proceedings Euro-pean Conf. on Speech Communication and Technology. (EUROSPEECH), </booktitle> <pages> 1941-1944, </pages> <address> Berlin, Germany. </address>
Reference-contexts: This simplifying assumption can be relaxed by replacing the MLP used in this study by a recurrent neural network <ref> (Robinson 1994) </ref>. A recurrent neural network encodes the past in its state units. Hence, the estimation of the transition probabilities is conditioned on the captured history of the utterance.
Reference: <author> Ruggero, M. </author> <year> 1994. </year> <title> Physiology and coding of sound in the auditory nerve. In The Mammalian Auditory Pathway: Neurophysiology, </title> <editor> ed. by A. Popper & R. </editor> <booktitle> Fay, </booktitle> <pages> 34-93. </pages> <address> New York, USA: </address> <publisher> Springer. </publisher>
Reference: <author> Rumelhart, D. E., G. E. Hinton, & R. J. Williams. </author> <year> 1986. </year> <title> Learning internal representations by error propagation. In Parallel Distributed Processing. Explorations of the Microstructure of Cognition, </title> <editor> ed. by D. E. Rumelhart & J. L. McClelland, </editor> <volume> volume 1: </volume> <booktitle> Foundations. </booktitle> <publisher> MIT Press. </publisher>
Reference: <author> Sachs, M. B., R. L. Winslow, & C. C. Blackburn. </author> <year> 1988. </year> <title> Representation of speech in the auditory periphery. In Auditory Function: Neurobiological Bases of Hearing, </title> <editor> ed. by G. M. Edelman, W. E. Gall, & W. M. Cowan, </editor> <address> 747-774. New York, USA: </address> <publisher> Wiley. </publisher>
Reference-contexts: Auditory physiologists have collected a vast amount of data describing the response of mammalian auditory-nerve fibers to simple signals (Kiang 1984; Ruggero 1994) as well as more complex signals such as synthetic speech <ref> (Sachs et al. 1988) </ref>. From these data it is clear that some sort of frequency analysis is performed and the dynamics of the response to non-steady-state signals is an important aspect of the auditory processing.
Reference: <author> Schwartz, R., & S. Austin. </author> <year> 1991. </year> <title> A comparison of several approximate algorithms for finding multiple (N-Best) sentence hypotheses. </title> <booktitle> In Proc. Int. Conf. on Acoust., Speech, and Signal Processing, </booktitle> <address> Toronto, Canada. 92 ||, & Y. Chow. </address> <year> 1990. </year> <title> The N-Best algorithm: An efficient and exact procedure for finding the n most likely sentence hyoptheses. </title> <booktitle> In Proc. Int. Conf. on Acoust., Speech, and Signal Processing, </booktitle> <address> New Mexico, USA. </address>
Reference: <author> Segui, J., E. Dupoux, & J. Mehler. </author> <year> 1980. </year> <title> The role of the syllable in speech segmentation, phoneme identification, and lexical access. </title> <booktitle> In Cognitive models of speech processing: Psycholinguistic and computational perspectives. ACL-MIT Press series in natural language processing, </booktitle> <editor> ed. by G. T. M. Altmann, </editor> <address> 263-280. Cambridge, MA, USA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Seneff, S. </author> <year> 1988. </year> <title> A joint synchrony/mean-rate model of auditory processing. </title> <journal> Journal of Phonetics 16.55-76. </journal>
Reference: <author> Smith, R., & J. J. Zwislocki. </author> <year> 1975. </year> <title> Short-term adaptation and incremental responses of single auditory-nerve fibers. </title> <journal> Biological Cybernetics 17.169-182. </journal>
Reference-contexts: The decrease in response rate is referred to as "adaptation." Usually there is a very rapid initial decay in rate immediately after the onset, followed by a slower decay to a steady-state level, about 50 ms after the onset <ref> (Smith & Zwislocki 1975) </ref>. 4.3 The Time-Index Model 4.3.1 Introduction Motivated by the studies mentioned above we decided to consider the following question: given accurate transition information between speech units can we significantly improve recognition performance? The model that we chose to answer this question is the time-index model.
Reference: <author> Stolcke, A., & S. Omohundro. </author> <year> 1993a. </year> <title> Best-first model merging for Hidden Markov Model induction. </title> <type> Technical report, </type> <institution> International Computer Science Institute, 1947 Center St. </institution> <address> Suite 600, Berkeley, CA. </address> ||, & ||. <year> 1993b. </year> <title> Hidden Markov Model induction by Bayesian model merging. </title> <booktitle> In Advances in Neural Information Processing Systems 5 , 11-18. </booktitle> <address> San Mateo, Ca.: </address> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Viterbi, A. J. </author> <year> 1967. </year> <title> Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. </title> <journal> IEEE Trans. on Information Theory 13.260-269. </journal>
Reference-contexts: For the preliminary tests the boundaries between the phones were determined by an automatic alignment (Viterbi) procedure on the known word string <ref> (Viterbi 1967) </ref>, also during recognition. This side information about the word sequence was used only to generate boundaries and no explicit phonetic information was preserved. Obviously during realistic recognition experiments the identity of the spoken sentence is not known.
Reference: <author> Waibel, A., Hanazawa T., Hinton G., S. Kiyohiro, & Lang K. J. </author> <year> 1989. </year> <title> Phoneme recognition using time-delay neural networks. </title> <journal> IEEE Trans. on Acoust., Speech, </journal> <note> Signal Processing 37.328-339. </note>
Reference: <author> Wooters, C., </author> <year> 1993. </year> <title> Lexical Modeling in a Speaker Independent Speech Understanding System. </title> <institution> Berkeley, CA: University of California dissertation. </institution>
Reference: <author> Zavaliagkos, G., Y. Zhao, R. Schwartz, & J. Makhoul. </author> <year> 1994. </year> <title> A hybrid segmental neural net/hidden Markov model system for continuous speech recognition. </title> <journal> IEEE Transactions on Speech and Audio Processing 2.151-160. </journal>
Reference-contexts: This problem is often referred to as the "lack of negative training example" problem and sometimes can be partially overcome by presenting additional negative training examples to the net <ref> (Zavaliagkos et al. 1994) </ref>. In order to test this hypothesis we computed the frame level performance of the net on the development set for the following two cases: 1. When the correct previous state is presented as input, the highest probability output was correct 79.4% of the time. 2.
References-found: 57

