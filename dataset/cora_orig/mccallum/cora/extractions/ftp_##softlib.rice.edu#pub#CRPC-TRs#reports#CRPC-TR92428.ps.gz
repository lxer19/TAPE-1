URL: ftp://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR92428.ps.gz
Refering-URL: http://www.crpc.rice.edu/CRPC/softlib/TRs_online.html
Root-URL: 
Title: ADIFOR Working Note #7: Extending Compile-Time Reverse Mode and Exploiting Partial Separability in ADIFOR  
Author: by Christian H. Bischof and Moe EL-Khadiri 
Date: 1992  
Affiliation: Argonne  
Pubnum: Technical Memorandum MCS-TM-163,  
Abstract: The numerical methods employed in the solution of many scientific computing problems require the computation of the gradient of a function f : R n ! R. ADIFOR is a source translator that, given a collection of subroutines to compute f, generates Fortran 77 code for computing the derivative of this function. Using the so-called torsion problem from the MINPACK-2 test collection as an example, this paper explores two issues in automatic differentiation: the efficient computation of derivatives for partial separable functions and the use of the compile-time reverse mode for the generation of derivatives. We show that orders of magnitudes of improvement are possible when exploiting partial separability and maximizing use of the reverse mode. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Brett Averick, Richard G. Carter, and Jorge J. </author> <title> More. The MINPACK-2 test problem collection (preliminary version). </title> <type> Technical Report ANL/MCS-TM-150, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1991. </year>
Reference-contexts: This formulation and the physical interpretation of the torsion problem are discussed in the test problem collection of MINPACK-2 <ref> [1] </ref>.
Reference: [2] <author> Christian Bischof, Alan Carle, George Corliss, and Andreas Griewank. ADIFOR: </author> <title> automatic differentiation in a source translator environment. </title> <note> ADIFOR Working Note #5, </note> <institution> MCS-P288-0192, Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1992. </year> <booktitle> Accepted for publication in Proceedings of International Symposium on Symbolic and Algebraic Computation. </booktitle> <volume> 18 19 20 </volume>
Reference-contexts: ADIFOR (Automatic Differentiation of Fortran) is a source translator that augments Fortran codes with statements for the computation of derivatives <ref> [3, 2] </ref>. ADIFOR employs a mixed forward/reverse mode paradigm. The forward mode propagates derivatives of intermediate variables with respect to the input variables; the reverse mode propagates derivatives of the final values with respect to intermediate variables [14].
Reference: [3] <author> Christian Bischof, Alan Carle, George Corliss, Andreas Griewank, and Paul Hovland. Adifor: </author> <title> Generating derivative codes from Fortran programs. </title> <note> ADIFOR Working Note #1, </note> <institution> MCS-P263-0991, Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1991. </year> <note> To appear in Scientific Programming. </note>
Reference-contexts: ADIFOR (Automatic Differentiation of Fortran) is a source translator that augments Fortran codes with statements for the computation of derivatives <ref> [3, 2] </ref>. ADIFOR employs a mixed forward/reverse mode paradigm. The forward mode propagates derivatives of intermediate variables with respect to the input variables; the reverse mode propagates derivatives of the final values with respect to intermediate variables [14]. <p> In accordance 3 fquad = 0.0 do 20 j = 0, ny k = nx*(j-1) + i vu = 0.0 if (i .lt. nx .and. j .gt. 0) vr = x (k+1) fquad=fquad + hyx*(vr-v)**2 + hxy*(vu-v)**2 10 continue 20 continue with the specification of ADIFOR (see <ref> [3] </ref>), g$p denotes the actual length of the derivative objects in a call to derivative code.
Reference: [4] <author> Christian Bischof, Alan Carle, George Corliss, Andreas Griewank, and Paul Hovland. ADIFOR: </author> <title> Fortran source translation for efficient derivatives. </title> <type> Preprint MCS-P278-1291, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <month> December </month> <year> 1991. </year> <note> ADIFOR Working Note # 4. </note>
Reference-contexts: An active variable is one that is on the computational path from independent to dependent variables (see <ref> [4] </ref>). Notice that in the ADIFOR-generated code, a loop of length g$p is associated with every assignment statement involving an active variable. Therefore the cost of floating-point operations can be approximated as (g$p fi f unction evaluation). The storage requirement for ADIFOR-generated code is (g$p fi number of active variables).
Reference: [5] <author> Christian Bischof and Paul Hovland. </author> <title> Using ADIFOR to compute dense and sparse Jacobians. </title> <type> Technical Memorandum ANL/MCS-TM-158, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, Argonne, Ill., </institution> <month> October </month> <year> 1991. </year> <note> ADIFOR Working Note # 2. </note>
Reference-contexts: By applying the chain rule @ f (g (t))j t=t 0 = @ f (s)j s=g (t 0 ) @ g (t)j t=t 0 (1) over and over again to the composition of those elementary operations, one can compute derivative information of f exactly and in a completely mechanical fashion <ref> [5] </ref>. ADIFOR transforms Fortran 77 programs using this approach. To illustrate automatic differentiation with current ADIFOR, we differentiate the subroutine torfcn for the torsion problem that maps an n-vector x into a scalar f. The vector x contains the independent variables, and the scalar f contains the dependent variable.
Reference: [6] <author> Kathy E. Brenan, Stephen L. Campbell, and Linda R. Petzold. </author> <title> Numerical Solution of Initial-Value Problems in Differential-Algebraic Equations. </title> <publisher> North-Holland, </publisher> <address> New York, </address> <year> 1989. </year>
Reference: [7] <author> John C. Butcher. </author> <title> The Numerical Analysis of Ordinary Differential Equations (Runge-Kutta and General Linear Methods). </title> <publisher> John Wiley and Sons, </publisher> <address> New York, </address> <year> 1987. </year>
Reference-contexts: Mathematically, the change can be modeled by the derivative of the system output with respect to a design parameter. Another application is the numerical solution of initial value problems in stiff ordinary differential equations (see, for example <ref> [7, 18] </ref>). Methods such as implicit Runge-Kutta and backward differentiation formula (BDF) methods require a Jacobian which is either supplied by the user or approximated by finite differences. In the context of optimization, one needs the derivatives of the objective function.
Reference: [8] <author> George F. Carrier and Carl E. Pearson. </author> <title> Partial Differential Equations. </title> <publisher> Academic Press, </publisher> <address> San Diego, California, </address> <year> 1988. </year>
Reference: [9] <author> T. F. Coleman, B. S. Garbow, and J. J. </author> <title> More. Software for estimating sparse Jacobian matrices. </title> <journal> ACM Trans. Math. Software, </journal> <volume> 10:329 - 345, </volume> <year> 1984. </year>
Reference-contexts: Partial Separability As was mentioned in the introduction, the torsion problem is a partially separable function f : R n ! R, in that it can be expressed as f (x) = i=1 This structure can also be used advantageously in computing the (usually dense) gradient rf of f (see <ref> [9] </ref>). <p> INDCOLQQS (I) SPARSEGF (COL) = SPARSEGF (COL) + + 0.25*G$FQQ (NGRPQQ (COL),ROW) END DO TEMP = -FORCE*HX*HY DO K = 1,N SPARSEGF (K) = SPARSEGF (K) + TEMP*G$FP (1,K) END DO After we have initialized some arrays determining the sparsity pattern of the Jacobian, we call the MINPACK subroutine DSM <ref> [9] </ref> to determine the proper coloring for the Jacobians of FQ and FQQ.
Reference: [10] <author> T. F. Coleman and J. J. </author> <title> More. Estimation of sparse Jacobian matrices and graph coloring problems. </title> <journal> SIAM Journal on Numerical Analysis, </journal> <volume> 20:187 - 209, </volume> <year> 1984. </year>
Reference-contexts: The key idea in computing sparse Jacobians is to identify so-called structurally orthogonal columns j i of J (see <ref> [10] </ref>), that is, columns whose inner product is always zero, independent of the numerical values of their nonzero entries. In our example, columns 1 and 2 are structurally orthogonal, and so are columns 3 and 4.
Reference: [11] <author> S. D. Conte and Carl de Boor. </author> <title> Elementary Numerical Analysis. </title> <publisher> McGraw-Hill, </publisher> <address> New York, </address> <year> 1980. </year>
Reference: [12] <author> John Dennis and R. Schnabel. </author> <title> Numerical Methods for Unconstrained Optimization and Nonlinear Equations. </title> <publisher> Prentice-Hall, </publisher> <address> Englewood Cliffs, N.J., </address> <year> 1983. </year>
Reference: [13] <author> Jack J. Dongarra, Jeremy Du Croz, Sven Hammarling, and Richard J. Hanson. </author> <title> An extended set of Fortran basic linear algebra subprograms. </title> <journal> ACM Transactions on Mathematical Software, </journal> <volume> 14(1) </volume> <pages> 1-17, </pages> <year> 1988. </year>
Reference-contexts: The resulting code is shown in Figure 5. The xbar vector contains dfquad dx and components k+1, k, and k+nx are updated in iteration k. After the loop, we apply the chain rule to compute rfquad = dfquad dx This matrix-vector multiplication is performed using the BLAS routine DGEMV <ref> [13] </ref>. To summarize, we exploited the fact that * loop iterations do not depend on each other, and * the result of each loop enters into the dependent variable (fquad) in an additive fashion.
Reference: [14] <author> Andreas Griewank. </author> <title> On automatic differentiation. </title> <booktitle> In Mathematical Programming: Recent Developments and Applications, </booktitle> <pages> pages 83-108, </pages> <address> Amsterdam, 1989. </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: ADIFOR employs a mixed forward/reverse mode paradigm. The forward mode propagates derivatives of intermediate variables with respect to the input variables; the reverse mode propagates derivatives of the final values with respect to intermediate variables <ref> [14] </ref>. <p> flow of execution of the original program, whereas the reverse mode of automatic differentiation requires the ability to access values generated in the execution of a program in reverse order, which is usually achieved by logging all values on a so-called tape, and then interpreting the tape in reverse order <ref> [14, 16, 15] </ref>. ADIFOR pioneered the use of the compile-time reverse mode where, instead of logging values at run time, we apply the reverse mode at compile time, thereby eliminating the storage requirements and run-time overhead of the tape scheme.
Reference: [15] <author> Andreas Griewank. </author> <title> Achieving logarithmic growth of temporal and spatial complexity in reverse automatic differentiation. </title> <journal> Optimization Methods & Software, </journal> <volume> 1(1) </volume> <pages> 35-54, </pages> <year> 1992. </year>
Reference-contexts: flow of execution of the original program, whereas the reverse mode of automatic differentiation requires the ability to access values generated in the execution of a program in reverse order, which is usually achieved by logging all values on a so-called tape, and then interpreting the tape in reverse order <ref> [14, 16, 15] </ref>. ADIFOR pioneered the use of the compile-time reverse mode where, instead of logging values at run time, we apply the reverse mode at compile time, thereby eliminating the storage requirements and run-time overhead of the tape scheme.
Reference: [16] <author> Andreas Griewank, David Juedes, and Jay Srinivasan. ADOL-C, </author> <title> a package for the automatic differentiation of algorithms written in C/C++. </title> <type> Technical Report MCS-P180-1190, </type> <institution> Mathematics and Computer Science Division, Argonne National Laboratory, </institution> <year> 1990. </year> <month> 21 </month>
Reference-contexts: flow of execution of the original program, whereas the reverse mode of automatic differentiation requires the ability to access values generated in the execution of a program in reverse order, which is usually achieved by logging all values on a so-called tape, and then interpreting the tape in reverse order <ref> [14, 16, 15] </ref>. ADIFOR pioneered the use of the compile-time reverse mode where, instead of logging values at run time, we apply the reverse mode at compile time, thereby eliminating the storage requirements and run-time overhead of the tape scheme.
Reference: [17] <author> Andreas Griewank and Philippe L. Toint. </author> <title> Partitioned variable metric updates for large struc-tured optimization problems. </title> <journal> Numerische Mathematik, </journal> <volume> 39 </volume> <pages> 119-137, </pages> <year> 1982. </year>
Reference: [18] <author> E. Hairer and G. Wanner. </author> <title> Solving Ordinary Differential Equations II (Stiff and Differential-Algebraic Problems), </title> <booktitle> volume 14 of Springer Series in Computational Mathematics. </booktitle> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1991. </year>
Reference-contexts: Mathematically, the change can be modeled by the derivative of the system output with respect to a design parameter. Another application is the numerical solution of initial value problems in stiff ordinary differential equations (see, for example <ref> [7, 18] </ref>). Methods such as implicit Runge-Kutta and backward differentiation formula (BDF) methods require a Jacobian which is either supplied by the user or approximated by finite differences. In the context of optimization, one needs the derivatives of the objective function.
Reference: [19] <author> Jorge J. </author> <title> More. On the performance of algorithms for large-scale bound constrained problems. </title> <editor> In T. F. Coleman and Y. Li, editors, </editor> <booktitle> Large-Scale Numerical Optimization, </booktitle> <pages> pages 32 - 45. </pages> <publisher> SIAM, </publisher> <year> 1991. </year>
Reference: [20] <author> Louis B. Rall. </author> <title> Automatic Differentiation: Techniques and Applications, </title> <booktitle> volume 120 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer Verlag, </publisher> <address> Berlin, </address> <year> 1981. </year>
Reference: [21] <author> Erich Zauderer. </author> <title> Partial Differential Equations of Applied Mathematics. </title> <publisher> John Wiley & Sons, </publisher> <address> Somerset, NJ, </address> <year> 1989. </year> <title> 22 APPENDICES: Code Listings for the Torsion Problem </title>
References-found: 21

