URL: http://www.bmc.riken.go.jp/sensor/Allan/ICA/files/easi.ps.gz
Refering-URL: http://www.bmc.riken.go.jp/sensor/Allan/ICA/index.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Equivariant adaptive source separation  
Author: Jean-Fran~cois Cardoso and Beate Laheld. 
Keyword: Source separation, blind array processing, multichannel equalization, signal copy, adaptive signal processing, high order statistics, equivariant estimation.  
Date: October 22, 1994 1  
Note: SUBMITTED TO THE IEEE TRANSACTIONS ON SIGNAL PROCESSING,  
Abstract: Source separation consists in recovering a set of independent signals when only mixtures with unknown coefficients are observed. This paper introduces a class of adaptive algorithms for source separation which implements an adaptive version of equivariant estimation and is henceforth called EASI (Equivariant Adaptive Separation via Independence). The EASI algorithms are based on the idea of serial updating: this specific form of matrix updates systematically yields algorithms with a simple, parallelizable structure, for both real and complex mixtures. Most importantly, the performance of an EASI algorithm does not depend on the mixing matrix. In particular, convergence rates, stability conditions and interference rejection levels depend only on the (normalized) distributions of the source signals. Close form expressions of these quantities are given via an asymptotic performance analysis. This is completed by some numerical experiments illustrating the effectiveness of the proposed approach. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Karim Abed Meraim, Adel Belouchrani, Jean-Fran~cois Cardoso, and Eric Moulines. </author> <title> Asymptotic performance of second order blind source separation. </title> <booktitle> In Proc. ICASSP, </booktitle> <volume> volume 4, </volume> <pages> pages 277-280, </pages> <month> April </month> <year> 1994. </year>
Reference-contexts: Before closing this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. [24], [25]; fourth-order-only is investigated in [5], [4]; purely second-order is possible if the sources have different spectra as investigated in [13], [21], <ref> [1] </ref>, [24] and also in [15] in an adaptive implementation. C. Equivariant source separation. Our approach to adaptive source separation may be motivated by first considering batch estimation.
Reference: [2] <author> Adel Belouchrani and Jean-Fran~cois Cardoso. </author> <title> Maximum likelihood source separation for discrete sources. </title> <booktitle> In Proc. EUSIPCO, </booktitle> <pages> pages 768-771, </pages> <address> Edinburgh, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: When the sources have a known differentiable density of probability (ddp), the maximum likelihood (ML) estimator is easily obtained in the i.i.d. case; the (asymptotically optimal) nonlinearities are the log derivatives of the ddp's [20]. See also <ref> [2] </ref> for an ML approach for with discrete sources in unknown Gaussian noise. Our starting point for finding a H () function required for serial updating is the idea of `orthogonal contrast functions'.
Reference: [3] <author> A. Benveniste, M. Metivier, and P Priouret. </author> <title> Adaptive algorithms and stochastic approximations. </title> <publisher> Springer Verlag, </publisher> <year> 1990. </year>
Reference-contexts: This approximation has negligible impact as checked in the experimental section VII. We informally recall some definitions and results (see <ref> [3] </ref>) about stochastic algorithms in the form t+1 = t t ( t ; x t ) (37) where x t is a stationary sequence of random variables and t a sequence of positive numbers.
Reference: [4] <author> Jean-Fran~cois Cardoso. </author> <title> Fourth-order cumulant structure forcing. Application to blind array processing. </title> <booktitle> In Proc. 6th SSAP workshop on statistical signal and array processing, </booktitle> <pages> pages 136-139, </pages> <month> October </month> <year> 1992. </year>
Reference-contexts: Before closing this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. [24], [25]; fourth-order-only is investigated in [5], <ref> [4] </ref>; purely second-order is possible if the sources have different spectra as investigated in [13], [21], [1], [24] and also in [15] in an adaptive implementation. C. Equivariant source separation. Our approach to adaptive source separation may be motivated by first considering batch estimation.
Reference: [5] <author> Jean-Fran~cois Cardoso. </author> <title> Iterative techniques for blind source separation using only fourth order cumulants. </title> <booktitle> In Proc. EUSIPCO, </booktitle> <pages> pages 739-742, </pages> <year> 1992. </year>
Reference-contexts: Before closing this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. [24], [25]; fourth-order-only is investigated in <ref> [5] </ref>, [4]; purely second-order is possible if the sources have different spectra as investigated in [13], [21], [1], [24] and also in [15] in an adaptive implementation. C. Equivariant source separation. Our approach to adaptive source separation may be motivated by first considering batch estimation.
Reference: [6] <author> Jean-Fran~cois Cardoso and Antoine Souloumiac. </author> <title> Blind beam-forming for non Gaussian signals. </title> <journal> IEE Proceedings-F, </journal> <volume> 140(6) </volume> <pages> 362-370, </pages> <month> December </month> <year> 1993. </year>
Reference-contexts: This orthogonal contrast is also arrived at by Gaeta and Lacoume [14] as a Gram-Charlier approximation of the likelihood. A similar (and asymptotically equivalent) contrast which can be efficiently optimized by a Jacobi-like algorithm, especially in the complex case, is described in <ref> [6] </ref>. When the sources have kurtosis of identical signs, simpler orthogonal contrasts may be exhibited. <p> III. Serial updates for orthogonal contrasts The contrast function 4 defined in (6) is in the form 4 = Ef (y) but must be optimized under the decorrela-tion constraint R y = Eyy T = I. Batch procedures for optimizing contrast functions under this constraint have been described in <ref> [6] </ref>, [9], [8]; they are based on factoring the separating matrix as B = U W where W an n fi m whitening matrix and U is an n fi n orthogonal matrix: there is an CARDOSO AND LAHELD: EQUIVARIANT ADAPTIVE SOURCE SEPARATION 5 - A W U Fig. 3.
Reference: [7] <author> A. Chichocki and L Moszczynski. </author> <title> New learning alforithms for blind separation of sources. </title> <journal> Electronic Letters, </journal> <volume> 28 </volume> <pages> 1986-1987, </pages> <year> 1992. </year>
Reference-contexts: Hence, any separating matrix is an equilibrium point of the algorithm. This kind of equilibrium condition also appears in [12]. The Jutten-Herault algorithm is inspired by a neuromimetic approach; this line is further followed by Karhunen [18] and Chicocki <ref> [7] </ref>. Nonlinear distortions of the output y also appear when the equilibrium condition stems from minimization of some measure of independence between the components of y. When independence is measured by the cancelation of some 4th-order cumulants of the output, cubic nonlinearities show up, as in [11], [19].
Reference: [8] <author> P. COMON. </author> <title> Independent Component Analysis, a new concept ? Signal Processing, </title> <publisher> Elsevier, </publisher> <pages> 36(3) 287-314, </pages> <month> April </month> <year> 1994. </year> <note> Special issue on Higher-Order Statistics. </note>
Reference-contexts: Batch procedures for optimizing contrast functions under this constraint have been described in [6], [9], <ref> [8] </ref>; they are based on factoring the separating matrix as B = U W where W an n fi m whitening matrix and U is an n fi n orthogonal matrix: there is an CARDOSO AND LAHELD: EQUIVARIANT ADAPTIVE SOURCE SEPARATION 5 - A W U Fig. 3.
Reference: [9] <author> Pierre Comon. </author> <title> Independent component analysis. </title> <booktitle> In Proc. Int. Workshop on Higher-Order Stat., Chamrousse, France, </booktitle> <pages> pages 111-120, </pages> <year> 1991. </year>
Reference-contexts: See also [2] for an ML approach for with discrete sources in unknown Gaussian noise. Our starting point for finding a H () function required for serial updating is the idea of `orthogonal contrast functions'. In the context of source separation, these were introduced by Comon <ref> [9] </ref> as functions of the distribution of y which are to be optimized under a whiteness constraint: R y = Eyy T = I. Comon suggest minimizing the squared cross-cumulants of the components of y. <p> Serial updates for orthogonal contrasts The contrast function 4 defined in (6) is in the form 4 = Ef (y) but must be optimized under the decorrela-tion constraint R y = Eyy T = I. Batch procedures for optimizing contrast functions under this constraint have been described in [6], <ref> [9] </ref>, [8]; they are based on factoring the separating matrix as B = U W where W an n fi m whitening matrix and U is an n fi n orthogonal matrix: there is an CARDOSO AND LAHELD: EQUIVARIANT ADAPTIVE SOURCE SEPARATION 5 - A W U Fig. 3.
Reference: [10] <author> Thomas M. Cover and Joy A. Thomas. </author> <title> Robust statistics. Wiley series in telecommunications. </title> <publisher> John Wiley, </publisher> <year> 1991. </year>
Reference-contexts: A. Serial update of a whitening matrix It is desired to adapt a matrix W such that it converges to a point where R z = I. This is obtained by minimizing a `distance' between R z and I. The Kullback-Leibler divergence <ref> [10] </ref> between two zero-mean normal distributions with covariance matrices equal to R z and I respectively is K (R z ) = Trace (R z ) log det (R z ) n: (19) Hence a whitening matrix is a minimizer of 2 (W ) = K (W R x W T
Reference: [11] <author> Nathalie Delfosse and Philippe Loubaton. </author> <title> Adaptive separation of independent sources: a deflation approach. </title> <booktitle> In Proc. ICASSP, </booktitle> <volume> volume 4, </volume> <pages> pages 41-44, </pages> <year> 1994. </year>
Reference-contexts: Nonlinear distortions of the output y also appear when the equilibrium condition stems from minimization of some measure of independence between the components of y. When independence is measured by the cancelation of some 4th-order cumulants of the output, cubic nonlinearities show up, as in <ref> [11] </ref>, [19]. When the sources have a known differentiable density of probability (ddp), the maximum likelihood (ML) estimator is easily obtained in the i.i.d. case; the (asymptotically optimal) nonlinearities are the log derivatives of the ddp's [20]. <p> This is a strongly reminiscent of 4th-order objectives used in blind equalization [23]. This contrast lends itself more easily to adaptive minimization since it is the expectation of a function of the output vector y. It is used in <ref> [11] </ref> where it is optimized by a deflation technique. The resulting adaptive algorithm can be proved to be asymptotically free of spurious attractors, but the implementation is not simple.
Reference: [12] <author> A. Din~c and Y. Bar-Ness. </author> <title> Bootstrap: A fast blind adaptive signal separator. </title> <booktitle> In Proc. ICASSP, </booktitle> <volume> volume 2, </volume> <pages> pages 325-328, </pages> <year> 1992. </year>
Reference-contexts: Hence, any separating matrix is an equilibrium point of the algorithm. This kind of equilibrium condition also appears in <ref> [12] </ref>. The Jutten-Herault algorithm is inspired by a neuromimetic approach; this line is further followed by Karhunen [18] and Chicocki [7]. Nonlinear distortions of the output y also appear when the equilibrium condition stems from minimization of some measure of independence between the components of y.
Reference: [13] <author> Luc Fety and J. P. Van Uffelen. </author> <title> New methods for signal separation. </title> <booktitle> In Proc. of 4th Int. Conf. on HF radio systems and techniques, </booktitle> <pages> pages 226-230, </pages> <address> London, April 1988. </address> <publisher> IEE. </publisher>
Reference-contexts: Before closing this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. [24], [25]; fourth-order-only is investigated in [5], [4]; purely second-order is possible if the sources have different spectra as investigated in <ref> [13] </ref>, [21], [1], [24] and also in [15] in an adaptive implementation. C. Equivariant source separation. Our approach to adaptive source separation may be motivated by first considering batch estimation.
Reference: [14] <author> Michel Gaeta and Jean-Louis Lacoume. </author> <title> Source separation without a priori knowledge: the maximum likelihood solution. </title> <booktitle> In Proc. EUSIPCO, </booktitle> <pages> pages 621-624, </pages> <year> 1990. </year>
Reference-contexts: Comon suggest minimizing the squared cross-cumulants of the components of y. This orthogonal contrast is also arrived at by Gaeta and Lacoume <ref> [14] </ref> as a Gram-Charlier approximation of the likelihood. A similar (and asymptotically equivalent) contrast which can be efficiently optimized by a Jacobi-like algorithm, especially in the complex case, is described in [6]. When the sources have kurtosis of identical signs, simpler orthogonal contrasts may be exhibited.
Reference: [15] <author> Stefan Van Gerven and Dirk Van Compernolle. </author> <title> On the use of decorrelation in scalar signal separation. </title> <booktitle> In Proc. ICASSP, </booktitle> <address> Ade-laide, Australia., </address> <year> 1994. </year>
Reference-contexts: this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. [24], [25]; fourth-order-only is investigated in [5], [4]; purely second-order is possible if the sources have different spectra as investigated in [13], [21], [1], [24] and also in <ref> [15] </ref> in an adaptive implementation. C. Equivariant source separation. Our approach to adaptive source separation may be motivated by first considering batch estimation.
Reference: [16] <author> Peter J. Huber. </author> <title> Robust statistics. Wiley series in probability and mathematical statistics. </title> <publisher> John Wiley, </publisher> <year> 1981. </year>
Reference-contexts: Equivariant estimation is in fact a broader notion which is relevant whenever the parameters to be estimated form a group. This is indeed the case here with the multiplicative group of invertible matrices. The equivariance property is quite natural in the context of source separation. For instance, M-estimators <ref> [16] </ref> which compute b A as the solution of an estimation equation in the form T 1 t=1;T are easily seen to be equivariant. The ML estimator in the i.i.d. case is an instance of M-estimator.
Reference: [17] <author> Christian Jutten and J. Herault. </author> <title> Independent component analysis versus PCA. </title> <booktitle> In Proc. EUSIPCO, </booktitle> <pages> pages 643-646, </pages> <year> 1988. </year>
Reference-contexts: The issue of indetermination is addressed at length in [24]. B. Approaches to source separation The seminal paper on source separation is <ref> [17] </ref>. Therein, the separating matrix B is parameterized as B = (I+W ) 1 and the off-diagonal entries of W are updated with a rule like w ij w ij f (y i )g (y j ) where f and g are odd functions. <p> On the scale indetermination. Because of the scaling indeterminations inherent to the source separation problem, some parameters have to be arbitrarily fixed. Quite often, this is achieved by constraining the separating matrix. For instance, its diagonal elements or those of its inverse are fixed to unity <ref> [17] </ref>, [19] or the rows of B t are normalized [20]. In contrast, EASI does not constrain the separating matrix; indeterminations are dealt with by requiring that the output signals have unit variance.
Reference: [18] <author> Juha Karhunen and Jyrki Joutsensalo. </author> <title> Representation and separation of signals using nonlinear PCA type learning. </title> <booktitle> Neural Networks, </booktitle> <volume> 7(1) </volume> <pages> 113-127, </pages> <year> 1993. </year>
Reference-contexts: Hence, any separating matrix is an equilibrium point of the algorithm. This kind of equilibrium condition also appears in [12]. The Jutten-Herault algorithm is inspired by a neuromimetic approach; this line is further followed by Karhunen <ref> [18] </ref> and Chicocki [7]. Nonlinear distortions of the output y also appear when the equilibrium condition stems from minimization of some measure of independence between the components of y.
Reference: [19] <author> Eric Moreau and Odile Macchi. </author> <title> New self-adaptive algorithms for source separation based on contrast functions. </title> <booktitle> In Proc. IEEE SP Workshop on Higher-Order Stat., </booktitle> <address> Lake Tahoe, USA, </address> <pages> pages 215-219, </pages> <year> 1993. </year>
Reference-contexts: Nonlinear distortions of the output y also appear when the equilibrium condition stems from minimization of some measure of independence between the components of y. When independence is measured by the cancelation of some 4th-order cumulants of the output, cubic nonlinearities show up, as in [11], <ref> [19] </ref>. When the sources have a known differentiable density of probability (ddp), the maximum likelihood (ML) estimator is easily obtained in the i.i.d. case; the (asymptotically optimal) nonlinearities are the log derivatives of the ddp's [20]. <p> On the scale indetermination. Because of the scaling indeterminations inherent to the source separation problem, some parameters have to be arbitrarily fixed. Quite often, this is achieved by constraining the separating matrix. For instance, its diagonal elements or those of its inverse are fixed to unity [17], <ref> [19] </ref> or the rows of B t are normalized [20]. In contrast, EASI does not constrain the separating matrix; indeterminations are dealt with by requiring that the output signals have unit variance.
Reference: [20] <author> Dinh Tuan Pham, Philippe Garrat, and Christian Jutten. </author> <title> Separation of a mixture of independent sources through a maximum likelihood approach. </title> <booktitle> In Proc. EUSIPCO, </booktitle> <pages> pages 771-774, </pages> <year> 1992. </year>
Reference-contexts: When the sources have a known differentiable density of probability (ddp), the maximum likelihood (ML) estimator is easily obtained in the i.i.d. case; the (asymptotically optimal) nonlinearities are the log derivatives of the ddp's <ref> [20] </ref>. See also [2] for an ML approach for with discrete sources in unknown Gaussian noise. Our starting point for finding a H () function required for serial updating is the idea of `orthogonal contrast functions'. <p> Quite often, this is achieved by constraining the separating matrix. For instance, its diagonal elements or those of its inverse are fixed to unity [17], [19] or the rows of B t are normalized <ref> [20] </ref>. In contrast, EASI does not constrain the separating matrix; indeterminations are dealt with by requiring that the output signals have unit variance.
Reference: [21] <author> D.T. Pham and P. Garat. </author> <title> Separation aveugle de sources tem-porellement correlees. </title> <booktitle> In Proc. GRETSI, </booktitle> <pages> pages 317-320, </pages> <year> 1993. </year>
Reference-contexts: Before closing this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. [24], [25]; fourth-order-only is investigated in [5], [4]; purely second-order is possible if the sources have different spectra as investigated in [13], <ref> [21] </ref>, [1], [24] and also in [15] in an adaptive implementation. C. Equivariant source separation. Our approach to adaptive source separation may be motivated by first considering batch estimation.
Reference: [22] <author> J. E. Potter. </author> <title> New statistical formulas. </title> <type> Technical report, </type> <institution> Instru-mentationn Laboratory, Mass. Inst. of Technology, </institution> <year> 1963. </year>
Reference-contexts: (R z I) = 2E [z t z T The serial adaptive whitener is obtained by deleting the expectation operator: W t+1 = W t t [ z t z T Interestingly enough, this rule can be shown to correspond the first order (in ) approximation of the Potter formula <ref> [22] </ref> for the recursive computation of the inverse square root of a covariance matrix estimated with an exponential window. In this instance, the serial approach is seen to correspond to an optimal solution. B.
Reference: [23] <author> O. Shalvi and E. Weinstein. </author> <title> New criteria for blind deconvolution of nonminimum phase systems (channels). </title> <journal> IEEE Tr. on IT, </journal> <volume> 36(2) </volume> <pages> 312-321, </pages> <year> 1990. </year>
Reference-contexts: This is a strongly reminiscent of 4th-order objectives used in blind equalization <ref> [23] </ref>. This contrast lends itself more easily to adaptive minimization since it is the expectation of a function of the output vector y. It is used in [11] where it is optimized by a deflation technique.
Reference: [24] <author> L. Tong, R. Liu, V.C. Soon, and Y. Huang. </author> <title> Indeterminacy and identifiabilityof blind identification. </title> <journal> IEEE Tr. on CS, </journal> <volume> 38(5) </volume> <pages> 499-509, </pages> <month> May </month> <year> 1991. </year>
Reference-contexts: The issue of indetermination is addressed at length in <ref> [24] </ref>. B. Approaches to source separation The seminal paper on source separation is [17]. <p> The resulting adaptive algorithm can be proved to be asymptotically free of spurious attractors, but the implementation is not simple. Before closing this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. <ref> [24] </ref>, [25]; fourth-order-only is investigated in [5], [4]; purely second-order is possible if the sources have different spectra as investigated in [13], [21], [1], [24] and also in [15] in an adaptive implementation. C. Equivariant source separation. <p> Before closing this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. <ref> [24] </ref>, [25]; fourth-order-only is investigated in [5], [4]; purely second-order is possible if the sources have different spectra as investigated in [13], [21], [1], [24] and also in [15] in an adaptive implementation. C. Equivariant source separation. Our approach to adaptive source separation may be motivated by first considering batch estimation.
Reference: [25] <author> Lang Tong, Yujiro Inouye, and Ruey-wen Liu. </author> <title> Waveform preserving blind estimation of multiple independent sources. </title> <journal> IEEE Tr. on SP, </journal> <volume> 41(7) </volume> <pages> 2461-2470, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: The resulting adaptive algorithm can be proved to be asymptotically free of spurious attractors, but the implementation is not simple. Before closing this section, other batch estimation techniques may be mentionned: higher-order cumulants are used together with a prewhitening strategy in Tong and al. [24], <ref> [25] </ref>; fourth-order-only is investigated in [5], [4]; purely second-order is possible if the sources have different spectra as investigated in [13], [21], [1], [24] and also in [15] in an adaptive implementation. C. Equivariant source separation. Our approach to adaptive source separation may be motivated by first considering batch estimation.
References-found: 25

