URL: http://iacoma.cs.uiuc.edu/iacoma-papers/excel.ps
Refering-URL: http://iacoma.cs.uiuc.edu/papers.html
Root-URL: http://www.cs.uiuc.edu
Title: Excel-NUMA: Toward Programmability, Simplicity and High Performance 1  
Author: Zheng Zhang, Marcelo Cintra, and Josep Torrellas 
Affiliation: University of Illinois at Urbana-Champaign  
Abstract: While hardware-coherent scalable shared-memory multiprocessors are relatively easy to program, they still require substantial programming effort to deliver high performance. Specifically, to minimize remote accesses, data must be carefully laid out in memory for locality and application working sets carefully tuned for caches. It has been claimed that this programming effort is less necessary in hardware COMA machines like Flat-COMA thanks to automatic line-based data migration. Unfortunately, Flat-COMA is complex to design. Consequently, we would like a machine as programmable as Flat-COMA, as simple as plain CC-NUMA and that outperforms both. This paper presents our proposal: Excel-NUMA (EX-NUMA). The idea is to exploit the fact that, after a memory line is written and cached, the storage that kept the line in memory is unutilized. We use that storage to temporarily hold remote data displaced from the local caches. This enables automatic data migration like in Flat-COMA, enhancing programmability. The hardware required to manage the system is a simple, local module added to a CC-NUMA; the global cache coherence protocol is not changed. Simulations of Splash2 applications show that EX-NUMA outperforms CC-NUMA and Flat-COMA in every single application and eliminates most of the conflict misses. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Convex Inc. </author> <title> Convex Exemplar Description. </title> <note> URL: http: //www.convex.com/prod serv/exemplar/exemplar.html. </note>
Reference: [2] <author> B. Falsafi and D. Wood. </author> <title> Reactive NUMA: A Design for Unifying S-COMA and CC-NUMA. </title> <booktitle> In Proceedings of the 24th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 229-240, </pages> <month> June </month> <year> 1997. </year>
Reference-contexts: Indeed, the presence of a remote cache, the associativity of the RDT, and a RDT receiving algorithm that favors replacements of non-exclusive lines, all make EX-NUMA very stable [10]. VI. Related Work Perhaps the closest work is R-NUMA, proposed by Fal-safi and Wood <ref> [2] </ref> concurrently with EX-NUMA. While R-NUMA is also a hybrid machine, its approach is very different. R-NUMA is a hybrid between CC-NUMA and Simple-COMA, the software incarnation of COMA. Data migrates at the page granularity, which is less effective.
Reference: [3] <author> S. Goldschmidt. </author> <title> Simulation of Multiprocessors: Accuracy and Performance. </title> <type> Ph.D. Thesis, </type> <institution> Stanford University, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: Consequently, we can use the unused directory bits to store the RDT tag and state of the incoming line. A design is presented in [9]. IV. Experimental Setup We perform execution-driven simulations of 32-node CC-NUMA, NUMA-RC, COMA and EX-NUMA architectures using Tangolite <ref> [3] </ref>. We refer to the CC-NUMA as NUMA. Each node includes a 200 MHz processor, two levels of cache, a memory controller, and a portion of the global memory and directory (Figure 2-(a)). The on-chip L1 cache is direct-mapped and has 16-byte lines.
Reference: [4] <author> D. Lenoski, J. Laudon, K. Gharachorloo, W. Weber, A. Gupta, J. Hennessy, M. Horowitz, and M. S. Lam. </author> <title> The Stanford Dash Multiprocessor. </title> <booktitle> IEEE Computer, </booktitle> <pages> pages 63-79, </pages> <month> March </month> <year> 1992. </year>
Reference-contexts: Specifically, the tags and state of the RDT entries dedicated to memory can be stored in the directory entries. This is possible if the machine uses a pointer-based directory scheme with invalidations <ref> [4] </ref>. In such schemes, after a memory line is written, the corresponding directory entry contains only one pointer. Consequently, we can use the unused directory bits to store the RDT tag and state of the incoming line. A design is presented in [9]. IV. <p> The remote cache in NUMA-RC and EX-NUMA and the extra memory in COMA have the same size. The small difference in tag space is neglected. Caches are kept coherent with the DASH protocol <ref> [4] </ref>. The memory bus is 64-bit wide and supports split transactions. The memories, RDTs and remote caches are pipelined and deliver the first word in 12 clocks. There is a global network with a fixed two-node latency of 100 cycles.
Reference: [5] <author> T. Lovett and R. Clapp. STiNG: </author> <title> A CC-NUMA Computer System for the Commercial Marketplace. </title> <booktitle> In Proceedings of the 23rd Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 308-317, </pages> <month> May </month> <year> 1996. </year>
Reference: [6] <institution> Silicon Graphics Inc. </institution> <note> Origin Servers. URL: http://www.sgi.com/ Products/hardware/servers. </note>
Reference: [7] <author> P. Stenstrom, T. Joe, and A. Gupta. </author> <title> Comparative Performance Evaluation of Cache-Coherent NUMA and COMA Architectures. </title> <booktitle> In Proceedings of the 19th Annual International Symposium on Computer Architecture, </booktitle> <pages> pages 80-91, </pages> <month> May </month> <year> 1992. </year>
Reference-contexts: For example, Simple-COMA may suffer from page unmapping, copying and remapping overheads induced by internal page fragmentation. Unfortunately, Flat-COMA is complicated to design. Its cache coherence protocol must ensure that last copies of lines are not lost <ref> [7] </ref>. This issue introduces corner cases in the protocol. In addition, some types of data access patterns do not use the COMA memory as well as they use a plain remote cache [11]. As a result, the performance may suffer. <p> We do not update home in COMA to minimize conflicts in the home memory. Aside from these performance issues, COMA has a higher design complexity than NUMA-RC because its cache coherence protocol has to ensure that last copies of lines are not lost <ref> [7] </ref>. This issue introduces corner cases in the protocol. Overall, we would like an architecture that combines all the advantages of both COMA and NUMA-RC: programmable as COMA, simple as NUMA-RC, and that handles the data in the best way, namely Mig as COMA and Repl as NUMA-RC.
Reference: [8] <author> B. Verghese, S. Devine, A. Gupta, and M. Rosenblum. </author> <title> Operating System Support for Improving Data Locality on CC-NUMA Compute Servers. </title> <booktitle> In Proceedings of the 7th International Conference on Architectural Support for Programming Languages and Operating Systems, </booktitle> <month> October </month> <year> 1996. </year>
Reference-contexts: Furthermore, there is a single (CC-NUMA) protocol under which all memory lines live, and there is no operating system overhead. No run-time feedback or interrupts are necessary. Other related work is operating system-induced migration and replication of pages based on run-time feedback, e.g. <ref> [8] </ref>. This technique has some of the effects of EX-NUMA, although migration is only supported at page granularity and there is operating system overhead. VII.
Reference: [9] <author> Z. Zhang. </author> <title> Architectural Alternatives to Reduce Remote Conflict Misses in Shared-Memory Multiprocessors. </title> <type> Ph.D. Thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> October </month> <year> 1996. </year>
Reference-contexts: The favorable scenario presented, where cells are created and filled uniformly across nodes, shows that EX-NUMA can handle MigRW for free, without using any MemOvhd. Ideally, remote-conf accesses appear only when: Repl+MigR &gt; MemOvhd MigR is, in fact, relatively uncommon <ref> [9] </ref>. Furthermore, Section III-D shows that EX-NUMA can be easily enhanced to handle MigR as well. Therefore, EX-NUMA can behave very much like COMA for Mig data. B. The Implementation of EX-NUMA The functionality described is supported with a module called Remote Data Table (RDT). <p> By giving low priority to exclusive, we try to avoid sending an owner home, which could in turn destroy a cell. However, we could be unfairly thrashing within Repl and MigR data. Other, fairer receiving algorithms are studied in <ref> [9] </ref>. In any case, the entry selected is filled and set to valid or exclusive depending on the state of the incoming line (receive transitions). When the L2 cache requests a remote line, if the RDT has a copy in a cell or in the remote cache, it supplies it. <p> However, we show in Section V that migration in EX-NUMA proceeds largely unimpeded. Finally, if all the data is MigR, EX-NUMA reverts to NUMA-RC and, therefore, has more remote-conf accesses than COMA. However, MigR data has little weight <ref> [9] </ref> and, in addition, Section III-D shows that it can also be handled by enhancing EX-NUMA. Finally, in all cases, the average stall time of a remote access in EX-NUMA is similar to NUMA-RC's and smaller than in COMA. <p> Finally, the design complexity of EX-NUMA is modest because all the modifications required to produce an EX-NUMA out of a NUMA-RC are local. In contrast to COMA, there are no changes to the global cache coherence protocol <ref> [9] </ref>. D. Advanced Implementation Issues The baseline EX-NUMA can be enhanced in several ways [10]. We briefly summarize them here. <p> In such schemes, after a memory line is written, the corresponding directory entry contains only one pointer. Consequently, we can use the unused directory bits to store the RDT tag and state of the incoming line. A design is presented in <ref> [9] </ref>. IV. Experimental Setup We perform execution-driven simulations of 32-node CC-NUMA, NUMA-RC, COMA and EX-NUMA architectures using Tangolite [3]. We refer to the CC-NUMA as NUMA.
Reference: [10] <author> Z. Zhang, M. Cintra, and J. Torrellas. Excel-NUMA: </author> <title> Toward Programmability, Simplicity, and High Performance. </title> <type> Technical Report CSRD-1544, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <month> November </month> <year> 1996. </year>
Reference-contexts: Finally, in all cases, the average stall time of a remote access in EX-NUMA is similar to NUMA-RC's and smaller than in COMA. The reason is that EX-NUMA does not suffer the line displacements from home memories that cause three-hop transactions in COMA. More detail can be found in <ref> [10] </ref>. The DRAM-based RDT does not need to slow down EX-NUMA relative to NUMA-RC. In NUMA-RC, after a L2 cache miss, the DRAM tags of the remote cache are accessed in parallel with the remote cache data. In EX-NUMA, we double the associativity of the search. <p> Furthermore, there are two schemes to reduce the DRAM needs. First, the RDT can have fewer entries dedicated to memory than memory lines. In this case, each RDT entry can identify one cell in a group of several memory lines. Consequently, we risk wasting cells <ref> [10] </ref>. The second scheme is the advanced RDT design discussed in Section III-D, which practically eliminates all DRAM needs. Finally, the design complexity of EX-NUMA is modest because all the modifications required to produce an EX-NUMA out of a NUMA-RC are local. <p> In contrast to COMA, there are no changes to the global cache coherence protocol [9]. D. Advanced Implementation Issues The baseline EX-NUMA can be enhanced in several ways <ref> [10] </ref>. We briefly summarize them here. Firstly, given that the RDT entries dedicated to memory and to the remote cache work in the same way, we can make the boundary that separates the two types of entries flexible. <p> This optimization helps support MigR data and is beneficial to MigRW data because cells are created as soon as the first read occurs. However, it hurts Repl data because a subsequent read by a second processor needs to fetch the data from the first reader processor <ref> [10] </ref>. Another way to increase the effectiveness of cells is to minimize the chances that, when an owner line is written back, it displaces the line in its cell. Such an event could cause another cell destruction downstream. <p> If the place that the owner goes into is not its default location, we mark the new location as its new home. This is called home relaxation. We present two designs to support it in <ref> [10] </ref>. A final performance optimization is high RDT associativity. With high associativity, cells retain more data, which reduces the pressure on the remote cache and results in fewer conflict misses. To tolerate the higher RDT busy time, we pipeline the RDT and memory access [10]. <p> two designs to support it in <ref> [10] </ref>. A final performance optimization is high RDT associativity. With high associativity, cells retain more data, which reduces the pressure on the remote cache and results in fewer conflict misses. To tolerate the higher RDT busy time, we pipeline the RDT and memory access [10]. We can also reduce RDT overheads. We chose the baseline RDT design to minimize the modifications to a NUMA-RC. However, if we are willing to redesign the directory to integrate it with the RDT, we can eliminate practically all of the RDT memory requirements. <p> Evaluating the Baseline EX-NUMA This section summarizes the evaluation in <ref> [10] </ref>. We compare a NUMA and three machines with 20% MemOvhd: NUMA-RC (N-RC20), COMA (COMA20) and EX-NUMA (EX-20). For reference purposes, we also consider an ideal EX-NUMA where the L2 cache unrealistically informs the RDT of displacements of lines in state non-exclusive. <p> Indeed, the presence of a remote cache, the associativity of the RDT, and a RDT receiving algorithm that favors replacements of non-exclusive lines, all make EX-NUMA very stable <ref> [10] </ref>. VI. Related Work Perhaps the closest work is R-NUMA, proposed by Fal-safi and Wood [2] concurrently with EX-NUMA. While R-NUMA is also a hybrid machine, its approach is very different. R-NUMA is a hybrid between CC-NUMA and Simple-COMA, the software incarnation of COMA.
Reference: [11] <author> Z. Zhang and J. Torrellas. </author> <title> Reducing Remote Conflict Misses: NUMA with Remote Cache versus COMA. </title> <booktitle> In Proceedings of the 3rd International Symposium on High-Performance Computer Architecture, </booktitle> <pages> pages 272-281, </pages> <month> February </month> <year> 1997. </year>
Reference-contexts: Its cache coherence protocol must ensure that last copies of lines are not lost [7]. This issue introduces corner cases in the protocol. In addition, some types of data access patterns do not use the COMA memory as well as they use a plain remote cache <ref> [11] </ref>. As a result, the performance may suffer. With this in mind, we would like an architecture that combines the advantages of both Flat-COMA and NUMA-RC. <p> MemOvhd is the remote cache in NUMA-RC and the extra memory for data replication in Flat-COMA. We neglect the small 2 difference in tag space. In the rest of the paper, we refer to Flat-COMA as COMA. Memory accesses can be loc, remote-cold, remote-coh or remote-conf <ref> [11] </ref>. Loc are those satisfied by the local caches and local memory. The other accesses are remote-cold, remote-coh or remote-conf depending on whether the miss is due to accessing a line for the processor's first time, data sharing or overflow in the local memory hierarchy respectively. <p> Under such conditions, we want to understand whether COMA or NUMA-RC suffers more remote-conf accesses. To this end, we identify two major data access patterns, namely data replication (Repl) and migration (Mig) <ref> [11] </ref>. Repl occurs when a line is accessed in a read-mostly manner by several processors. Mig occurs when a line allocated remotely is accessed largely by one processor at a time, and can be read-mostly (MigR) or read-write (MigRW). Mig is key to distinguishing COMA from NUMA-RC. <p> As a result, NUMA-RC suffers fewer remote-conf accesses. This effect particularly affects the data with the highest memory appetite, namely Repl. Overall, therefore, while COMA will likely have fewer remote-conf accesses if Mig dominates, NUMA-RC will likely have fewer remote-conf accesses if Repl dominates <ref> [11] </ref>. Note, however, that the performance difference between COMA and NUMA-RC is not only determined by the relative number of remote-conf accesses. It is also affected by how much processor stall time is induced by the average loc, remote-cold, remote-conf and remote-coh accesses as well. <p> It is also affected by how much processor stall time is induced by the average loc, remote-cold, remote-conf and remote-coh accesses as well. The average remote access latency tends to be higher in COMA than in NUMA-RC <ref> [11] </ref>. The reason is that the fraction of remote accesses that involve three-node hops instead of two, is higher in COMA than in NUMA-RC.
References-found: 11

