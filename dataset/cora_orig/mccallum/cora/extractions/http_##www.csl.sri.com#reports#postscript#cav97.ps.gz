URL: http://www.csl.sri.com/reports/postscript/cav97.ps.gz
Refering-URL: http://www.csl.sri.com/reports/postscript/
Root-URL: 
Email: cyrluk@csl.sri.com fmoeller,ruessg@ki.informatik.uni-ulm.de  
Title: An Efficient Decision Procedure for the Theory of Fixed-Sized Bit-Vectors (Extended Abstract, Submitted)  
Author: David Cyrluk Oliver Moller Harald Rue 
Address: Menlo Park, CA 94025, USA D-89069 Ulm, Germany  
Affiliation: Computer Science Laboratory Fakultat fur Informatik SRI International Universitat Ulm  
Abstract: In this paper we describe a decision procedure for the core theory of fixed-sized bit-vectors with extraction and composition than can readily be integrated into Shostak's procedure for deciding combinations of theories. Inputs to the solver are unquantified bit-vector equations t = u and the algorithm returns true if t = u is valid in the bit-vector theory, false if t = u is unsatisfiable, and a system of solved equations otherwise. The time complexity of the solver is O(j t j log n + n 2 ), where t is the length of the bit-vector term t and n denotes the number of bits on either side of the equation. Then, the solver for the core bit-vector theory is extended to handle other bit-vector operations like bitwise logical operations, shifting, and arithmetic interpretations of bit-vectors. We develop a BDD-like data-structure called bit-vector BDDs to represent bit-vectors, various operations on bit-vectors, and a solver on bit-vector BDDs. The overall procedure has been integrated with the decision procedures of the PVS prover. The implementation has been tested with typical lemmas from the domain of microprocessor verification. The implementation has also been applied to proofs found in the verification of a commercial microprocessor. By using our decision procedure for bit-vectors we have simplified a number of proofs by eliminating manual proof steps that were previously necessary for reasoning about bit-vectors.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> R.E. Bryant. </author> <title> Symbolic Boolean Manipulation with Ordered Binary Decision Diagrams. </title> <journal> ACM Computing Surveys, </journal> <volume> 24(3) </volume> <pages> 293-318, </pages> <month> September </month> <year> 1992. </year>
Reference-contexts: Slicing of the canonized equation above, for example, leads to the following equation. x [3] t 1 ^ (0; 0) t 2 ^ (4; 4) t 3 |-z 0 <ref> [1] </ref> t 5 |-z z [5] | -z - z [5] | -z - z [5] | -z - x [3] | -z - Obviously, this equation holds if and only if the conjunction of the equations in the set E holds. <p> In our running example, solving equations over simple terms yields the following new equations (possibly containing fresh variables). csolve (x [3] = x [3] ) = ? csolve (y [4] ^ (0; 0) = z [5] (4; 4)) = fy = a (1) <ref> [1] </ref> ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = <p> variables). csolve (x [3] = x [3] ) = ? csolve (y [4] ^ (0; 0) = z [5] (4; 4)) = fy = a (1) <ref> [1] </ref> ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) Thus, a call csolve (t = u) results in a set of equations which is empty, if t <p> (4; 4)) = fy = a (1) <ref> [1] </ref> ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) Thus, a call csolve (t = u) results in a set of equations which is empty, if t u, contains false , if and only if t and u are different constants, contains exactly one solved equation <p> c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) <ref> [1] </ref> a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) Thus, a call csolve (t = u) results in a set of equations which is empty, if t u, contains false , if and only if t and u are different constants, contains exactly one solved equation of the form x = s, with x 2 vars (t <p> In our running example we get the following three blocks. E x = j 0 <ref> [1] </ref> j a (5) [3] j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with <p> In our running example we get the following three blocks. E x = j 0 <ref> [1] </ref> j a (5) [3] j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . <p> In our running example we get the following three blocks. E x = j 0 <ref> [1] </ref> j a (5) [3] j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . No further propagation is necessary, since both variables are of kind-a variables. <p> In our running example we get the following three blocks. E x = j 0 <ref> [1] </ref> j a (5) [3] j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . No further propagation is necessary, since both variables are of kind-a variables. <p> j 0 <ref> [1] </ref> j a (5) [3] j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . No further propagation is necessary, since both variables are of kind-a variables. In the general case, however, propagation of constants in one column may trigger further propagations in other columns. <p> 0 <ref> [1] </ref> j a (5) [3] j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . No further propagation is necessary, since both variables are of kind-a variables. In the general case, however, propagation of constants in one column may trigger further propagations in other columns. <p> Applying propagation of constants, coarsest slicing, and propagation of equalities to the equalities of our running examples we obtain the following solved form for the equation in Example 5 : solve (E ) = f x [3] = 0 <ref> [1] </ref> a (5) [2] ; [3] c (1) z [5] = b (1) [1] 0 [3] g Altogether, it can be shown that solve in Figure 2 is indeed a correct and complete solver for the given bit-vector theory. <p> of constants, coarsest slicing, and propagation of equalities to the equalities of our running examples we obtain the following solved form for the equation in Example 5 : solve (E ) = f x [3] = 0 <ref> [1] </ref> a (5) [2] ; [3] c (1) z [5] = b (1) [1] 0 [3] g Altogether, it can be shown that solve in Figure 2 is indeed a correct and complete solver for the given bit-vector theory. Theorem 6. ` t = u if and only if solve (t = u) = true. <p> We now describe how to add the boolean bitwise operations, and call this new theory the extended theory of bit-vectors. The two basic requirements that we must satisfy when adding the boolean operations is canonicity and solvability. As will be seen binary decision diagrams (BDDs) <ref> [1] </ref> over bit-vectors satisfy both these criteria. A bit-vector BDD of size n is a BDD with bit-vector variables of size n as the internal nodes and the constant bit-vectors 1 [n] and 0 [n] as the terminals. <p> The meaning, for example, of the bit-vector BDD, ite (x [3] ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . <p> The meaning, for example, of the bit-vector BDD, ite (x [3] ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . <p> for example, of the bit-vector BDD, ite (x [3] ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . <p> [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] <p> [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use <p> [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use of bit-vector-BDDs permits <p> given by: ite (x [3] ^ (2; 2); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use of bit-vector-BDDs permits maintaining the paradigm of largest chunks possible that has already guided the development of <p> ite (y [3] ite (x [3] ^ (0; 0); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use of bit-vector-BDDs permits maintaining the paradigm of largest chunks possible that has already guided the development of the efficient solver for the core theory. The canonicity of BDDs immediately provides a canonical form for bit-vector BDDs. <p> ite (x [3] ^ (0; 0); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use of bit-vector-BDDs permits maintaining the paradigm of largest chunks possible that has already guided the development of the efficient solver for the core theory. The canonicity of BDDs immediately provides a canonical form for bit-vector BDDs. <p> ^ (0; 0); 1 <ref> [1] </ref> ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use of bit-vector-BDDs permits maintaining the paradigm of largest chunks possible that has already guided the development of the efficient solver for the core theory. The canonicity of BDDs immediately provides a canonical form for bit-vector BDDs.
Reference: 2. <author> D. Cyrluk, P. Lincoln, and N. Shankar. </author> <title> On Shostak's Decision Procedure for Combination of Theories. </title> <editor> In M. A. McRobbie and J. K. Slaney, editors, </editor> <booktitle> Proc. of CADE'96, volume 1104 of Lecture Notes in Artificial Intelligence, </booktitle> <pages> pages 463-477, </pages> <address> New Brunswick, NJ, July/August 1996. </address> <publisher> Springer-Verlag. </publisher>
Reference-contexts: However, in order to be effective, low-level verification needs to be as automatic as possible. In the PVS verification system this is accomplished through the use of a method due to Shostak <ref> [2, 7] </ref> for combining decision procedures. Currently any proof goal that can be proven by reasoning about equality, arrays, tuples, and linear arithmetic in PVS is proven automatically. <p> Moreover, this decision procedure can readily be incorporated into Shostak's procedure for combinations of theories [7], since our algorithm fulfills the requirements for component theories as stated in <ref> [2] </ref>. By way of introduction, consider the following true statement in the combined theory of equality and bit-vectors: (u [m] v [n] )XOR (x [m] y [n] ) = 0 [m+n] f (x [m] ; y [n] ) = f (u [m] ; v [n] ). <p> This decision proce dure can readily be integrated with Shostak's framework for deciding combinations of theories, since it is subdivided into a canonizer and a solver [7] which satisfy the requirements stated in <ref> [2] </ref>. 3.1 Canonizer The canonizer (t) in Appendix A computes the maximally connected composition normal form of t and is a straightforward transliteration of the equalities in Figure 1. <p> In the first phase ff (t) this canonizer normalizes a bit-vector term t to an equivalent term in composition normal form (see Section 2). The resulting composition normal form may still contain sub-terms such as c [n] c [m] or x <ref> [2] </ref> ^ (1; 1) x [2] ^ (0; 0), which can be further normalized to c [n+m] and x [2] respectively. These kinds of merging are accomplished in the second phase of canonization by the function fi (see Appendix A). <p> In the first phase ff (t) this canonizer normalizes a bit-vector term t to an equivalent term in composition normal form (see Section 2). The resulting composition normal form may still contain sub-terms such as c [n] c [m] or x <ref> [2] </ref> ^ (1; 1) x [2] ^ (0; 0), which can be further normalized to c [n+m] and x [2] respectively. These kinds of merging are accomplished in the second phase of canonization by the function fi (see Appendix A). <p> The resulting composition normal form may still contain sub-terms such as c [n] c [m] or x <ref> [2] </ref> ^ (1; 1) x [2] ^ (0; 0), which can be further normalized to c [n+m] and x [2] respectively. These kinds of merging are accomplished in the second phase of canonization by the function fi (see Appendix A). Altogether, (t) ::= fi (ff (t)) computes the maximally connected composition normal form for a bit-vector term t. <p> These kinds of merging are accomplished in the second phase of canonization by the function fi (see Appendix A). Altogether, (t) ::= fi (ff (t)) computes the maximally connected composition normal form for a bit-vector term t. Using this result one can prove that fulfills the requirements given in <ref> [2] </ref> for a canonizer in Shostak's framework. <p> Applying propagation of constants, coarsest slicing, and propagation of equalities to the equalities of our running examples we obtain the following solved form for the equation in Example 5 : solve (E ) = f x [3] = 0 [1] a (5) <ref> [2] </ref> ; [3] c (1) z [5] = b (1) [1] 0 [3] g Altogether, it can be shown that solve in Figure 2 is indeed a correct and complete solver for the given bit-vector theory. <p> Theorem 6. ` t = u if and only if solve (t = u) = true. Moreover, the bit-vector decision procedure solve can be readily used in Shostak's framework for deciding combinations of theories, since it fulfills, besides Theorem 6, Shostak's requirements for individual solvers as stated in <ref> [2] </ref>. Theorem 7. <p> (1) 1 ^ (31; 16) ^ (7; 0) x [32] ^ (23; 0) 2 6. ((fill [16] (nat2bv [10] (192) ^ (9)) fill [8] (nat2bv [10] (192) ^ (8))) nat2bv [10] (192) ^ (7; 0) OR fill [16] (x [16] ^ 15) x [16] ) ^ (7; 0) = fill <ref> [2] </ref> (1) x [16] ^ (5; 0) 65 7. (fill [16] (nat2bv [10] (511) ^ (9)) fill [8] (nat2bv [10] (511) ^ (8)) nat2bv [10] (511) ^ (7; 0)) = (fill [16] (0) fill [16] (1)) 22 8. (bv 2nat (fill [16] (x [16] ^ (15)) x [16] ) = 0)
Reference: 3. <author> D. Cyrluk, O. Moller, and H. Rue. </author> <title> An Efficient Decision Procedure for a Theory of Fixed-Sized Bitvectors with Composition and Extraction. </title> <type> Technical report, </type> <institution> Universitat Ulm, D-89069 Ulm, Oberer Eselsberg, </institution> <month> December </month> <year> 1996. </year>
Reference-contexts: A particular simple approach for solving equations t = u over fixed-sized bit-vectors proceeds by (see <ref> [3] </ref> for details) 1. replacing any bit-vector variable x [n] with x n1 : : : x 0 , where x i are (fresh) variables of sort bvec 1 , 2. computing the composition normal form of each side, 3. bitwise comparing the corresponding left-hand and right-hand sides of the equations, <p> In the sequel, we describe the basic ideas of a refined version of the brute force algorithm above by means of an example; pseudocode for the crucial parts of the algorithm can be found in Figure 2. Example 5. x <ref> [3] </ref> (y [4] z [5] ) ^ (5; 4) 0 [4] t ^ (2; 1) x [3] ) ^ (4; 0) z [5] x [3] ) ^ (10; 2) u Given an equation t = u, the bit-vector solver in Figure 2 first canonizes both sides of the equation to obtain <p> Example 5. x <ref> [3] </ref> (y [4] z [5] ) ^ (5; 4) 0 [4] t ^ (2; 1) x [3] ) ^ (4; 0) z [5] x [3] ) ^ (10; 2) u Given an equation t = u, the bit-vector solver in Figure 2 first canonizes both sides of the equation to obtain the equation (t) = (u) over the maximally connected composition normal forms (t ) and (u). <p> Example 5. x <ref> [3] </ref> (y [4] z [5] ) ^ (5; 4) 0 [4] t ^ (2; 1) x [3] ) ^ (4; 0) z [5] x [3] ) ^ (10; 2) u Given an equation t = u, the bit-vector solver in Figure 2 first canonizes both sides of the equation to obtain the equation (t) = (u) over the maximally connected composition normal forms (t ) and (u). <p> The equation in Example 5, for example, canonizes to x <ref> [3] </ref> y [4] ^ (4; 4) 0 [4] (t) ^ (2; 2) (u) The next step of the algorithm, called slicing, computes composition normal forms t 1 : : : t m and u 1 : : : u m of (u) and (t) respectively, such that each t i and <p> Slicing of the canonized equation above, for example, leads to the following equation. x <ref> [3] </ref> t 1 ^ (0; 0) t 2 ^ (4; 4) t 3 |-z 0 [1] t 5 |-z z [5] | -z - z [5] | -z - z [5] | -z - x [3] | -z - Obviously, this equation holds if and only if the conjunction of the <p> Slicing of the canonized equation above, for example, leads to the following equation. x <ref> [3] </ref> t 1 ^ (0; 0) t 2 ^ (4; 4) t 3 |-z 0 [1] t 5 |-z z [5] | -z - z [5] | -z - z [5] | -z - x [3] | -z - Obviously, this equation holds if and only if the conjunction of the equations in the set E holds. E ::= fx [3] = x [3] ; y [4] ^ (4; 4); z [5] ^ (3; 3); ^ (2; 0); ^ (2; 2)g Since E contains only equations <p> 4) t 3 |-z 0 [1] t 5 |-z z [5] | -z - z [5] | -z - z [5] | -z - x <ref> [3] </ref> | -z - Obviously, this equation holds if and only if the conjunction of the equations in the set E holds. E ::= fx [3] = x [3] ; y [4] ^ (4; 4); z [5] ^ (3; 3); ^ (2; 0); ^ (2; 2)g Since E contains only equations over simple terms, the problem of solving an equation over arbitrary terms is reduced to solving equations over simple terms by means of the function <p> |-z 0 [1] t 5 |-z z [5] | -z - z [5] | -z - z [5] | -z - x <ref> [3] </ref> | -z - Obviously, this equation holds if and only if the conjunction of the equations in the set E holds. E ::= fx [3] = x [3] ; y [4] ^ (4; 4); z [5] ^ (3; 3); ^ (2; 0); ^ (2; 2)g Since E contains only equations over simple terms, the problem of solving an equation over arbitrary terms is reduced to solving equations over simple terms by means of the function csolve in Appendix <p> In our running example, solving equations over simple terms yields the following new equations (possibly containing fresh variables). csolve (x <ref> [3] </ref> = x [3] ) = ? csolve (y [4] ^ (0; 0) = z [5] (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve <p> In our running example, solving equations over simple terms yields the following new equations (possibly containing fresh variables). csolve (x <ref> [3] </ref> = x [3] ) = ? csolve (y [4] ^ (0; 0) = z [5] (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = <p> x <ref> [3] </ref> ) = ? csolve (y [4] ^ (0; 0) = z [5] (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) Thus, a call csolve (t = u) results in a set of equations which is empty, if t u, contains false , if <p> fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 <ref> [3] </ref> = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) Thus, a call csolve (t = u) results in a set of equations which is empty, if t u, contains false , if and only if t and u are different constants, contains exactly one solved equation of the form <p> In our running example we get the following three blocks. E x = j 0 [1] j a (5) <ref> [3] </ref> j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . <p> In our running example we get the following three blocks. E x = j 0 [1] j a (5) <ref> [3] </ref> j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . No further propagation is necessary, since both variables are of kind-a variables. <p> In our running example we get the following three blocks. E x = j 0 [1] j a (5) <ref> [3] </ref> j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . No further propagation is necessary, since both variables are of kind-a variables. <p> a (5) <ref> [3] </ref> j c (1) c (1) [1] a (2) 00 b (1) [1] a (3) a (4) 0 [1] 0 [3] In this example, the constant 0 [3] in the last column of E z may be propagated by equalizing both a (4) 0 [1] [1] with 0 [3] . No further propagation is necessary, since both variables are of kind-a variables. In the general case, however, propagation of constants in one column may trigger further propagations in other columns. Moreover, propagation of constants may result in additional slicings, since block entries may well be compositions. <p> Applying propagation of constants, coarsest slicing, and propagation of equalities to the equalities of our running examples we obtain the following solved form for the equation in Example 5 : solve (E ) = f x <ref> [3] </ref> = 0 [1] a (5) [2] ; [3] c (1) z [5] = b (1) [1] 0 [3] g Altogether, it can be shown that solve in Figure 2 is indeed a correct and complete solver for the given bit-vector theory. <p> Applying propagation of constants, coarsest slicing, and propagation of equalities to the equalities of our running examples we obtain the following solved form for the equation in Example 5 : solve (E ) = f x <ref> [3] </ref> = 0 [1] a (5) [2] ; [3] c (1) z [5] = b (1) [1] 0 [3] g Altogether, it can be shown that solve in Figure 2 is indeed a correct and complete solver for the given bit-vector theory. Theorem 6. ` t = u if and only if solve (t = u) = true. <p> coarsest slicing, and propagation of equalities to the equalities of our running examples we obtain the following solved form for the equation in Example 5 : solve (E ) = f x <ref> [3] </ref> = 0 [1] a (5) [2] ; [3] c (1) z [5] = b (1) [1] 0 [3] g Altogether, it can be shown that solve in Figure 2 is indeed a correct and complete solver for the given bit-vector theory. Theorem 6. ` t = u if and only if solve (t = u) = true. <p> The intended meaning of such a bit-vector BDD is the conjunction of the constraints that the n BDDs impose on the n individual bits of the bit-vector variables. The meaning, for example, of the bit-vector BDD, ite (x <ref> [3] </ref> ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite <p> The intended meaning of such a bit-vector BDD is the conjunction of the constraints that the n BDDs impose on the n individual bits of the bit-vector variables. The meaning, for example, of the bit-vector BDD, ite (x <ref> [3] </ref> ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; <p> The intended meaning of such a bit-vector BDD is the conjunction of the constraints that the n BDDs impose on the n individual bits of the bit-vector variables. The meaning, for example, of the bit-vector BDD, ite (x <ref> [3] </ref> ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] <p> The intended meaning of such a bit-vector BDD is the conjunction of the constraints that the n BDDs impose on the n individual bits of the bit-vector variables. The meaning, for example, of the bit-vector BDD, ite (x <ref> [3] </ref> ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] <p> The meaning, for example, of the bit-vector BDD, ite (x <ref> [3] </ref> ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] <p> The meaning, for example, of the bit-vector BDD, ite (x <ref> [3] </ref> ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . <p> (x <ref> [3] </ref> ; ite (y [3] ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 <p> ite (y <ref> [3] </ref> ; 1 [3] ; 0 [3] ); 0 [3] ) (1) where ite (:; :; :) is the common if-then-else conditional, is given by: ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 <p> is the common if-then-else conditional, is given by: ite (x <ref> [3] </ref> ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] )^ ^ (1; 1); ite (y [3] ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use of bit-vector-BDDs permits maintaining the paradigm of largest chunks possible that <p> [1] )^ ^ (1; 1); ite (y <ref> [3] </ref> ite (x [3] ^ (0; 0); 1 [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x [3] ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use of bit-vector-BDDs permits maintaining the paradigm of largest chunks possible that has already guided the development of the efficient solver for the core theory. <p> [1] ; 0 [1] ); 0 [1] ) Now, consider the additional constraint x <ref> [3] </ref> ^ (0; 0) = 1 [1] . In this case, the example bit-vector BDD in (1) specializes to ite (x [3] ^ (2; 2); 1 [1] ; 0 [1] ); 0 [1] ) ite (y [3] Thus, the use of bit-vector-BDDs permits maintaining the paradigm of largest chunks possible that has already guided the development of the efficient solver for the core theory. The canonicity of BDDs immediately provides a canonical form for bit-vector BDDs.
Reference: 4. <author> O. Moller. </author> <note> Some Notes on Bit-Vectors. See: http://www.informatik.uni-ulm.de/ki/Personen/moeller/bitvector-e.html, 1996. </note>
Reference-contexts: In the sequel, we describe the basic ideas of a refined version of the brute force algorithm above by means of an example; pseudocode for the crucial parts of the algorithm can be found in Figure 2. Example 5. x [3] (y <ref> [4] </ref> z [5] ) ^ (5; 4) 0 [4] t ^ (2; 1) x [3] ) ^ (4; 0) z [5] x [3] ) ^ (10; 2) u Given an equation t = u, the bit-vector solver in Figure 2 first canonizes both sides of the equation to obtain the equation <p> Example 5. x [3] (y <ref> [4] </ref> z [5] ) ^ (5; 4) 0 [4] t ^ (2; 1) x [3] ) ^ (4; 0) z [5] x [3] ) ^ (10; 2) u Given an equation t = u, the bit-vector solver in Figure 2 first canonizes both sides of the equation to obtain the equation (t) = (u) over the maximally connected composition <p> The equation in Example 5, for example, canonizes to x [3] y <ref> [4] </ref> ^ (4; 4) 0 [4] (t) ^ (2; 2) (u) The next step of the algorithm, called slicing, computes composition normal forms t 1 : : : t m and u 1 : : : u m of (u) and (t) respectively, such that each t i and u i <p> The equation in Example 5, for example, canonizes to x [3] y <ref> [4] </ref> ^ (4; 4) 0 [4] (t) ^ (2; 2) (u) The next step of the algorithm, called slicing, computes composition normal forms t 1 : : : t m and u 1 : : : u m of (u) and (t) respectively, such that each t i and u i are of the same length; <p> E ::= fx [3] = x [3] ; y <ref> [4] </ref> ^ (4; 4); z [5] ^ (3; 3); ^ (2; 0); ^ (2; 2)g Since E contains only equations over simple terms, the problem of solving an equation over arbitrary terms is reduced to solving equations over simple terms by means of the function csolve in Appendix B. <p> In our running example, solving equations over simple terms yields the following new equations (possibly containing fresh variables). csolve (x [3] = x [3] ) = ? csolve (y <ref> [4] </ref> ^ (0; 0) = z [5] (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = <p> In our running example, solving equations over simple terms yields the following new equations (possibly containing fresh variables). csolve (x [3] = x [3] ) = ? csolve (y <ref> [4] </ref> ^ (0; 0) = z [5] (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) <p> Lemma Run-Time (in msec) 1. fill [32] (0) XOR x [32] = x [32] 7 2. (NOT (x [32] )) ^ (15; 0) = NOT (x [32] 3. (x [32] XOR y [32] ) ^ (15; 0) = x [32] ^ (15; 0) 26 4. (fill [12] ^ (0) nat2bv <ref> [4] </ref> (1)) = nat2bv [16] (1) 1 ^ (31; 16) ^ (7; 0) x [32] ^ (23; 0) 2 6. ((fill [16] (nat2bv [10] (192) ^ (9)) fill [8] (nat2bv [10] (192) ^ (8))) nat2bv [10] (192) ^ (7; 0) OR fill [16] (x [16] ^ 15) x [16] ) ^ <p> For this case, however, we can not expect to have a polynomial solver for the core theory, since, using a reduction from 3SAT, it can be shown that solvability is NP -complete in this case <ref> [4] </ref>. On the other hand, using these extensions, one could apply a combination of decision procedures | including the one for the bit-vector theory | to prove properties about fixed- but arbitrary-sized bit-vectors. Acknowledgments: Thanks to J. Skakkebaek for many useful comments, M.K.
Reference: 5. <author> S. Owre, J. Rushby, N. Shankar, and F. von Henke. </author> <title> Formal Verification for Fault-Tolerant Architectures: Prole-gomena to the Design of PVS. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> 21(2) </volume> <pages> 107-125, </pages> <month> February </month> <year> 1995. </year>
Reference-contexts: In the sequel, we describe the basic ideas of a refined version of the brute force algorithm above by means of an example; pseudocode for the crucial parts of the algorithm can be found in Figure 2. Example 5. x [3] (y [4] z <ref> [5] </ref> ) ^ (5; 4) 0 [4] t ^ (2; 1) x [3] ) ^ (4; 0) z [5] x [3] ) ^ (10; 2) u Given an equation t = u, the bit-vector solver in Figure 2 first canonizes both sides of the equation to obtain the equation (t) = <p> Example 5. x [3] (y [4] z <ref> [5] </ref> ) ^ (5; 4) 0 [4] t ^ (2; 1) x [3] ) ^ (4; 0) z [5] x [3] ) ^ (10; 2) u Given an equation t = u, the bit-vector solver in Figure 2 first canonizes both sides of the equation to obtain the equation (t) = (u) over the maximally connected composition normal forms (t ) and (u). <p> Slicing of the canonized equation above, for example, leads to the following equation. x [3] t 1 ^ (0; 0) t 2 ^ (4; 4) t 3 |-z 0 [1] t 5 |-z z <ref> [5] </ref> | -z - z [5] | -z - z [5] | -z - x [3] | -z - Obviously, this equation holds if and only if the conjunction of the equations in the set E holds. <p> Slicing of the canonized equation above, for example, leads to the following equation. x [3] t 1 ^ (0; 0) t 2 ^ (4; 4) t 3 |-z 0 [1] t 5 |-z z <ref> [5] </ref> | -z - z [5] | -z - z [5] | -z - x [3] | -z - Obviously, this equation holds if and only if the conjunction of the equations in the set E holds. E ::= fx [3] = x [3] ; y [4] ^ (4; 4); z [5] ^ (3; 3); ^ <p> Slicing of the canonized equation above, for example, leads to the following equation. x [3] t 1 ^ (0; 0) t 2 ^ (4; 4) t 3 |-z 0 [1] t 5 |-z z <ref> [5] </ref> | -z - z [5] | -z - z [5] | -z - x [3] | -z - Obviously, this equation holds if and only if the conjunction of the equations in the set E holds. E ::= fx [3] = x [3] ; y [4] ^ (4; 4); z [5] ^ (3; 3); ^ (2; 0); ^ (2; 2)g <p> | -z - z <ref> [5] </ref> | -z - z [5] | -z - x [3] | -z - Obviously, this equation holds if and only if the conjunction of the equations in the set E holds. E ::= fx [3] = x [3] ; y [4] ^ (4; 4); z [5] ^ (3; 3); ^ (2; 0); ^ (2; 2)g Since E contains only equations over simple terms, the problem of solving an equation over arbitrary terms is reduced to solving equations over simple terms by means of the function csolve in Appendix B. <p> In our running example, solving equations over simple terms yields the following new equations (possibly containing fresh variables). csolve (x [3] = x [3] ) = ? csolve (y [4] ^ (0; 0) = z <ref> [5] </ref> (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 <p> example, solving equations over simple terms yields the following new equations (possibly containing fresh variables). csolve (x [3] = x [3] ) = ? csolve (y [4] ^ (0; 0) = z <ref> [5] </ref> (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) Thus, a call csolve <p> yields the following new equations (possibly containing fresh variables). csolve (x [3] = x [3] ) = ? csolve (y [4] ^ (0; 0) = z <ref> [5] </ref> (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) Thus, a call csolve (t = u) results in a <p> = ? csolve (y [4] ^ (0; 0) = z <ref> [5] </ref> (4; 4)) = fy = a (1) [1] ; z = c (1) [4] g csolve (z [5] ^ (4; 4) = z [5] (3; 3)) = fz = b (1) [1] a (3) csolve (0 [3] = z [5] ^ (2; 0)) = fz = a (4) csolve (0 [1] = x [3] ^ (2; 2)) = fx = 0 [1] a (5) Thus, a call csolve (t = u) results in a set of equations which is empty, if t u, contains false , if and only if <p> Applying propagation of constants, coarsest slicing, and propagation of equalities to the equalities of our running examples we obtain the following solved form for the equation in Example 5 : solve (E ) = f x [3] = 0 [1] a (5) [2] ; [3] c (1) z <ref> [5] </ref> = b (1) [1] 0 [3] g Altogether, it can be shown that solve in Figure 2 is indeed a correct and complete solver for the given bit-vector theory. Theorem 6. ` t = u if and only if solve (t = u) = true. <p> examples that we have looked at, the amount of bit-wise manipulations are quite limited and we do not expect the manipulations described in this section to dominate the complete solver. 5 Experiments The bit-vector decision procedures described above have been implemented and integrated with the decision procedures of the PVS <ref> [5] </ref> proof system. Most of the examples we have dealt with so far have been extracted from the verification of the AAMP5 [8], an industrial-strength microprocessor.
Reference: 6. <author> H. Rue. </author> <title> Hierarchical Verification of Two-Dimensional High-Speed Multiplication in PVS: A Case Study. </title> <editor> In M.K. Srivas and A. Camilleri, editors, </editor> <booktitle> Formal Methods in Computer-Aided Design, volume 1166 of Lecture Notes in Computer Science. </booktitle> <publisher> Springer-Verlag, </publisher> <month> November </month> <year> 1996. </year>
Reference-contexts: Currently any proof goal that can be proven by reasoning about equality, arrays, tuples, and linear arithmetic in PVS is proven automatically. Experience with the verification of a commercial microprocessor [8], and the verification of multipliers <ref> [6] </ref> has shown that the lack of specialized decision procedures for notions related to bit-vectors is the main impediment to effective automation in theorem proving systems like PVS. This insight forms the starting point of this paper, and we develop an efficient decision procedure for a theory of fixed-sized bit-vectors.
Reference: 7. <author> R.E. Shostak. </author> <title> Deciding Combinations of Theories. </title> <journal> Journal of the ACM, </journal> <volume> 31(1) </volume> <pages> 1-12, </pages> <month> January </month> <year> 1984. </year>
Reference-contexts: However, in order to be effective, low-level verification needs to be as automatic as possible. In the PVS verification system this is accomplished through the use of a method due to Shostak <ref> [2, 7] </ref> for combining decision procedures. Currently any proof goal that can be proven by reasoning about equality, arrays, tuples, and linear arithmetic in PVS is proven automatically. <p> This insight forms the starting point of this paper, and we develop an efficient decision procedure for a theory of fixed-sized bit-vectors. Moreover, this decision procedure can readily be incorporated into Shostak's procedure for combinations of theories <ref> [7] </ref>, since our algorithm fulfills the requirements for component theories as stated in [2]. <p> The paper is organized as follows. In Section 2 we present the theory of fixed-sized bit-vectors with composition and extraction as a many-sorted conditional equational theory. Section 3 contains a description of a canonizer and a solver <ref> [7] </ref> for this bit-vector together with an analysis of their time complexities. <p> Bit-Vector Equations 3 Solving Bit-Vector Equations Now, we describe a decision procedure for the bit-vector theory as introduced above. This decision proce dure can readily be integrated with Shostak's framework for deciding combinations of theories, since it is subdivided into a canonizer and a solver <ref> [7] </ref> which satisfy the requirements stated in [2]. 3.1 Canonizer The canonizer (t) in Appendix A computes the maximally connected composition normal form of t and is a straightforward transliteration of the equalities in Figure 1.
Reference: 8. <author> M.K. Srivas and S.P. Miller. </author> <title> Formal Verification of the AAMP5 Microprocessor. </title> <editor> In M.G. Hinchey and J.P. Bowen, editors, </editor> <booktitle> Applications of Formal Methods, International Series in Computer Science, chapter 7, </booktitle> <pages> pages 125-180. </pages> <publisher> Prentice Hall, </publisher> <address> Hemel Hempstead, UK, </address> <year> 1995. </year>
Reference-contexts: Currently any proof goal that can be proven by reasoning about equality, arrays, tuples, and linear arithmetic in PVS is proven automatically. Experience with the verification of a commercial microprocessor <ref> [8] </ref>, and the verification of multipliers [6] has shown that the lack of specialized decision procedures for notions related to bit-vectors is the main impediment to effective automation in theorem proving systems like PVS. <p> Once this has been established equality reasoning shows that f (x [m] ; y [n] ) = f (u [m] ; v [n] ) This example is illustrative of the type of unnecessary reasoning that took place in <ref> [8] </ref>. The algorithm that we present below takes equations such as the one that appears in the hypothesis in the above example and solves for some of the variables in that equation in terms of the remaining variables. <p> The rest of Shostak's algorithm works roughly by using this solution to replace the solved variables with their solved form. We have successfully applied this solver to eliminate manual reasoning about bit-vectors in some of the proofs in <ref> [8] </ref>. The paper is organized as follows. In Section 2 we present the theory of fixed-sized bit-vectors with composition and extraction as a many-sorted conditional equational theory. Section 3 contains a description of a canonizer and a solver [7] for this bit-vector together with an analysis of their time complexities. <p> Most of the examples we have dealt with so far have been extracted from the verification of the AAMP5 <ref> [8] </ref>, an industrial-strength microprocessor. Figure 3 lists a collection of representative lemmas automatically proven using our bit-vector decision procedures together with the run-times (im milli-seconds) of the bit-vector decision procedures. <p> (x [32] XOR y [32] ) ^ (15; 0) = x [32] ^ (15; 0) 26 4. (fill [12] ^ (0) nat2bv [4] (1)) = nat2bv [16] (1) 1 ^ (31; 16) ^ (7; 0) x [32] ^ (23; 0) 2 6. ((fill [16] (nat2bv [10] (192) ^ (9)) fill <ref> [8] </ref> (nat2bv [10] (192) ^ (8))) nat2bv [10] (192) ^ (7; 0) OR fill [16] (x [16] ^ 15) x [16] ) ^ (7; 0) = fill [2] (1) x [16] ^ (5; 0) 65 7. (fill [16] (nat2bv [10] (511) ^ (9)) fill [8] (nat2bv [10] (511) ^ (8)) nat2bv <p> (nat2bv [10] (192) ^ (9)) fill <ref> [8] </ref> (nat2bv [10] (192) ^ (8))) nat2bv [10] (192) ^ (7; 0) OR fill [16] (x [16] ^ 15) x [16] ) ^ (7; 0) = fill [2] (1) x [16] ^ (5; 0) 65 7. (fill [16] (nat2bv [10] (511) ^ (9)) fill [8] (nat2bv [10] (511) ^ (8)) nat2bv [10] (511) ^ (7; 0)) = (fill [16] (0) fill [16] (1)) 22 8. (bv 2nat (fill [16] (x [16] ^ (15)) x [16] ) = 0) , (bv 2nat (x [16] ) = 0) 3500 Fig. 3.
References-found: 8

