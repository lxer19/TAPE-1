URL: http://www.wi.leidenuniv.nl/~jvhemert/csp-ea/erep.ps.gz
Refering-URL: http://www.wi.leidenuniv.nl/~jvhemert/csp-ea/
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Solving Combinatorial Problems Using Evolutionary Algorithms  
Author: Marco Vink 
Date: 4 June 1997  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> T. </author> <title> Back. Evolutionary Algorithms in Theory and Practice. </title> <publisher> Oxford United Press, </publisher> <year> 1996. </year>
Reference-contexts: The mutation operator is used to bring in information not present in the population. The selection operator imitates the natural selection mechanism: the fittest individuals survive. For more information on the topic the reader is referred to [25] and <ref> [1] </ref>. 1 In analogy with the recombination of chromosomes and the exchange of corresponding pieces of chro mosome couples. 2 In analogy with faults made during the doubling of a DNA molecule. 3 t = 0 initialize P (0) evaluate P (0) while stop condition not reached do P'(t) = recombine <p> More information on these operators can be found in [25]. 3.1.6 Survivor Selection In this thesis we will use the notation 1 from the Evolution Strategies <ref> [1] </ref>. The population size is denoted by , the offspring size by . Two major schemes for selecting the new population from the current population and its offspring exist. With preservative selection, the new population is selected from the combination of the current population and the offspring. <p> An overview on ESs, more formal than we present here, can be found in <ref> [1] </ref>. It also includes an overview on Evolutionary Programming (EP) and Genetic Algorithms (GAs). The ES algorithm fits in the general framework shown in figure 2.1. An important distinction with a classical Evolutionary Algorithm is the existence of a self adaption mechanism, which will be explained later on.
Reference: [2] <author> T. Back and M. Schutz. </author> <title> Intelligent mutation rate control in canonical genetic algorithms. </title> <editor> In Z.W.Ras and M.Michalewicz, editors, </editor> <booktitle> Foundations of Intelligent Systems, 9th International Symposium, ISMIS 96, LNAI 1079, </booktitle> <pages> pages 158-167. </pages> <publisher> Springer, </publisher> <year> 1996. </year>
Reference-contexts: We conclude that raising the maximum number of evaluations is not useful. Changing the mutation rate during a run can have a positive effect on the performance of an EA. Back and Schutz <ref> [2] </ref> suggested the following function to control the mutation rate: p m (t) = (2 + T max 1 Where L is the problem size, T max the maximum number of evaluations and t the time or generation counter.
Reference: [3] <author> Th. Back, M. Schutz, and S. Khuri. </author> <title> A comparative study of a penalty function, a repair heuristic, and stochastic operators with the set-covering problem. </title> <editor> In Alliot J.- M., Lutton E., Ronald E., Schoenauer M., and Snyers D., editors, </editor> <booktitle> Artificial Evolution, number 1063 in Lecture Notes in Computer Science, </booktitle> <pages> pages 320-332. </pages> <publisher> Springer, </publisher> <address> Berlin, </address> <year> 1996. </year>
Reference-contexts: The repair method outperforms the other two constraint handling approaches in the test cases where the feasible region of the search space was small, in the other cases the penalty function performs best. Another interesting comparative study is <ref> [3] </ref>, where a penalty method and a greedy heuristic (non EA) is compared to a simple repair method for the set covering problem. The repair method performs substantially better than the penalty approach and also encounters better solutions than the heuristic algorithm in most cases.
Reference: [4] <author> D. Corne, P. Ross, and H. Fang. </author> <title> Chapter 8: Evolving timetables. </title> <editor> In L. Chambers, editor, </editor> <booktitle> Practical Handbook of Genetic Algorithms, </booktitle> <pages> pages 219-276. </pages> <publisher> CRC Press, </publisher> <year> 1995. </year>
Reference-contexts: Examples of problems solved by EAs using a penalty function are Graph Colouring [31], which uses a decoder and adaptive penalty function, and Time Tabling <ref> [4] </ref> with an integer based representation, a number of specialized operators and a static penalty function. Scheduling problems often use an order based representation and decoder to handle their constraints. In [6] an example is given of a production line scheduler with permutation encoding and standard order based operators.
Reference: [5] <author> Charles Darwin. </author> <title> The Origin of Species. </title> <publisher> London: Oxford UP, </publisher> <pages> 1859. </pages>
Reference-contexts: given. 1 In a CSP the goal is to find a feasible solution, and methods like repairing (the whole individual) or feasibility preserving operators cannot be applied. 2 Chapter 2 Evolutionary Algorithms 2.1 Brief Overview The evolution theory of Charles Darwin, described in his famous book The Origin of Species <ref> [5] </ref>, is one of the most important theories in natural science, especially in biology. The heart of the evolutionary process is the mechanism of natural selection. Individuals of a species show some variation.
Reference: [6] <author> L. Davis. </author> <title> Handbook of Genetic Algorithms. </title> <publisher> Van Nostrand Reinhold, </publisher> <year> 1991. </year>
Reference-contexts: Scheduling problems often use an order based representation and decoder to handle their constraints. In <ref> [6] </ref> an example is given of a production line scheduler with permutation encoding and standard order based operators. Another example of scheduling can be found in [25], where a preference list representation together with a decoder and special operators are used.
Reference: [7] <author> M. Davis and H. Putnam. </author> <title> A computing procedure for quantification theory. </title> <journal> Jnl. Association for Computing Machinery, </journal> <volume> 7 </volume> <pages> 201-215, </pages> <year> 1960. </year>
Reference-contexts: Twelve instances for four different problem sizes n are examined. An overview of the problem instances is given in Table 6.1. 6.3 Algorithms on Satisfiability 6.3.1 Traditional Algorithms The algorithm DP by Davis and Putnam <ref> [7] </ref> is the best known complete algorithm, i.e., it is guaranteed to find a solution if one exists, on satisfiability. It has exponential time complexity and therefore several incomplete algorithms on SAT exist.
Reference: [8] <author> K.A. de Jong and W.M. Spears. </author> <title> Using genetic algorithms to solve NP-complete problems. </title> <booktitle> In Third International Conference on Genetic Algorithms, </booktitle> <pages> pages 124-132, </pages> <year> 1989. </year>
Reference-contexts: The weights are used in deciding which flip is chosen. WGSAT shows better performance than both GSAT and HSAT. 6.3.2 Evolutionary Algorithms Some examples of EAs on satisfiability are <ref> [8] </ref>, [16] and [22]. Recently, Eiben and Van der Hauw [11] proposed an EA with adaptive penalty function, which was very successful. They used a problem independent constraint handling mechanism, Stepwise Adaption of Weights (SAW). This mechanism substantially increases the performance of the EA.
Reference: [9] <author> A.E. Eiben, P-E. Raue, and Zs. Ruttkay. </author> <title> Repairing, adding constraints and learning as a means of improving GA performance on CSPs. </title> <booktitle> In Proceedings of the Dutch-Belgian Conference on Machine Learning, BENELEARN-94, </booktitle> <pages> pages 112-132. </pages> <publisher> Erasmus University Press, </publisher> <year> 1994. </year>
Reference-contexts: In Section 8.2 we give some suggestions to overcome this problem. 7.3 Steady State EA with SAW-ing on SAT 7.3.1 The SAW Mechanism The Stepwise Adaption of Weights (SAW) is an on-line weight adaption mechanism and was introduced in <ref> [9] </ref>. Is has been applied on graph colouring in [31], and satisfiability in [11]. The weight adaption mechanism is shown in figure 7.1. A weight, initially 1, is assigned to every constraint.
Reference: [10] <author> A.E. Eiben and Zs. Ruttkay. </author> <title> Constraint satisfaction problems. </title> <editor> In Th. Back, D. Fogel, and M. Michalewicz, editors, </editor> <booktitle> Handbook of Evolutionary Algorithms, pages C5.7:1-C5.7:8. </booktitle> <publisher> Oxford University Press, </publisher> <year> 1997. </year> <month> 67 </month>
Reference-contexts: A Free Optimization Problem (FOP) is an optimization problem without constraints. A formal framework of FOPs, CSPs and COPs can be found in <ref> [10] </ref>. 2.2.2 Approaches to Constraint Handling Several approaches to handling constraints exist.
Reference: [11] <author> A.E. Eiben and J.K. van der Hauw. </author> <title> Solving 3-SAT with adaptive Genetic Algorithms. </title> <booktitle> In Proceedings of the 4th IEEE Conference on Evolutionary Computation, </booktitle> <pages> pages 81-86. </pages> <publisher> IEEE Press, </publisher> <year> 1997. </year>
Reference-contexts: The penalty term is multiplied with a component which becomes larger in time. A more advanced method are the adaptive penalty functions. The adaptive penalty term uses feedback from the search process to adapt itself. The Stepwise Adaption of Weights <ref> [11] </ref>, which is used in this thesis on the satisfiability problem, is an example of an adaptive penalty function. It assigns a weight to every constraint, and if a constraint is violated during search, the corresponding weight is increased. <p> The weights are used in deciding which flip is chosen. WGSAT shows better performance than both GSAT and HSAT. 6.3.2 Evolutionary Algorithms Some examples of EAs on satisfiability are [8], [16] and [22]. Recently, Eiben and Van der Hauw <ref> [11] </ref> proposed an EA with adaptive penalty function, which was very successful. They used a problem independent constraint handling mechanism, Stepwise Adaption of Weights (SAW). This mechanism substantially increases the performance of the EA. <p> Is has been applied on graph colouring in [31], and satisfiability in <ref> [11] </ref>. The weight adaption mechanism is shown in figure 7.1. A weight, initially 1, is assigned to every constraint. After a period T p , the best individual in the population is selected and the the weights of those constraints it violates, are increased by 4w. <p> The EA has proven to be quite insensitive to the values of the new parameters T p and 4w. We will use the same values as in <ref> [11] </ref>, T p = 250 and 4w = 1. 7.3.2 Experimental Results In [11], it was concluded that mutation alone with a population size = 1 is powerful enough to solve 3-SAT with high success rate. <p> The EA has proven to be quite insensitive to the values of the new parameters T p and 4w. We will use the same values as in <ref> [11] </ref>, T p = 250 and 4w = 1. 7.3.2 Experimental Results In [11], it was concluded that mutation alone with a population size = 1 is powerful enough to solve 3-SAT with high success rate. Experiments in [31] show the asexual EA with = 1 outperforms an EA with recombination. <p> The EA scales up better than WGSat. WGSat is very similar to our asexual SSEA with SAW-ing. Both perform much better than the ESs. Research <ref> [11] </ref> showed our SSEA with SAW mechanism outperforms the same SSEA without SAW-ing. We conclude the Stepwise Adaption of Weights is a very powerful mechanism, which guides (or forces) the search algorithm in the right direction.
Reference: [12] <author> E. Falkenauer. </author> <title> A new representation and operators for genetic algorithms applied to grouping problems. </title> <journal> Journal of Evolutionary Computation, </journal> <volume> 2(2) </volume> <pages> 123-144, </pages> <year> 1994. </year>
Reference-contexts: They did not use problem specific knowledge or problem specific operators, only a straightforward fitness function with graded penalty. The results were disappointing: even the simple FFD heuristic outperforms the EA. EA with Feasibility Preserving Operators Falkenauer <ref> [12] </ref>, [13] and [14] developed a genetic algorithm concept for grouping problems, i.e., problems where a set of items has to be divided in a number of groups with each item in exactly one group. A realization of this concept is the Hybrid Grouping Genetic Algorithm (HGGA) for bin packing. <p> A local optimization is carried out, based on ideas by Martello and Toth, using these missing items to improve the bins already in the candidate solution. After the optimization, the remaining items are "first fit descending" (FFD) reinserted. In the first article <ref> [12] </ref>, Falkenauer compares the grouping GA without optimization to the EA by Reeves [29] and concludes the HGGA is superior 2 . In the other articles [13] and [14] the HGGA with optimization is compared to the reduction algorithms, on two problem classes.
Reference: [13] <author> E. Falkenauer. </author> <title> Setting new limits in bin packing with a grouping GA using reduction. </title> <type> Technical report, </type> <institution> CRIF Research Centre for Belgian Metalworking Industry, </institution> <year> 1994. </year> <note> Also available as http://www.dai.ed.ac.uk/groups/evalg/eag local copies of papers.body.html. </note>
Reference-contexts: They did not use problem specific knowledge or problem specific operators, only a straightforward fitness function with graded penalty. The results were disappointing: even the simple FFD heuristic outperforms the EA. EA with Feasibility Preserving Operators Falkenauer [12], <ref> [13] </ref> and [14] developed a genetic algorithm concept for grouping problems, i.e., problems where a set of items has to be divided in a number of groups with each item in exactly one group. A realization of this concept is the Hybrid Grouping Genetic Algorithm (HGGA) for bin packing. <p> After the optimization, the remaining items are "first fit descending" (FFD) reinserted. In the first article [12], Falkenauer compares the grouping GA without optimization to the EA by Reeves [29] and concludes the HGGA is superior 2 . In the other articles <ref> [13] </ref> and [14] the HGGA with optimization is compared to the reduction algorithms, on two problem classes. The performance of the HGGA with local optimization is impressive. It is much better than the reduction algorithm and is almost always successful, even on the hardest problem instances.
Reference: [14] <author> E. Falkenauer. </author> <title> A hybrid grouping genetic algorithm for bin packing. </title> <journal> Journal of Heuristics, </journal> <volume> 2 </volume> <pages> 5-30, </pages> <year> 1996. </year>
Reference-contexts: Four different standard approaches to handling constraints in an EA are investigated and compared for the bin packing problem. Also a comparison is made with a good traditional algorithm. Falkenauer <ref> [14] </ref> developed a genetic algorithm (GA) with problem specific representation, operators and optimization for the BPP. He argues that an encoding 1 and operators fitting the structure of the problem and a sophisticated local optimization is necessary to obtain a high performance GA. <p> In [25], a matrix representation with feasibility preserving operators is investigated for the linear and nonlinear transportation problem. The EA with feasibility preserving operators performs better than for example a gradient based technique. Another successful example of the use of feasibility preserving operators is <ref> [14] </ref>. <p> The triplets are so difficult because it is possible to place two big or three small objects in a bin, but this will lead to a waste of space and consequently a suboptimal solution. For more details on the generation of the triplets the reader is referred to <ref> [14] </ref>. Four problem sizes are available: 60, 120, 249, 501 items. There are 20 instances for each problem size. In the experiments we use representatives of both classes. <p> They did not use problem specific knowledge or problem specific operators, only a straightforward fitness function with graded penalty. The results were disappointing: even the simple FFD heuristic outperforms the EA. EA with Feasibility Preserving Operators Falkenauer [12], [13] and <ref> [14] </ref> developed a genetic algorithm concept for grouping problems, i.e., problems where a set of items has to be divided in a number of groups with each item in exactly one group. A realization of this concept is the Hybrid Grouping Genetic Algorithm (HGGA) for bin packing. <p> Next, the remaining items are first fit descending reinserted. The inversion operator inverts a part of the grouping part of the chromosome. We will give an example of the crossover operator (same as in <ref> [14] </ref>). Suppose we have two individuals, and their group parts are: (AjBCDjEF) and (abjcdj) with the crossing sites already selected. The bins between the crossover points from the second individual are injected into the first after the first crossover point: (AcdBCDEF). <p> After the optimization, the remaining items are "first fit descending" (FFD) reinserted. In the first article [12], Falkenauer compares the grouping GA without optimization to the EA by Reeves [29] and concludes the HGGA is superior 2 . In the other articles [13] and <ref> [14] </ref> the HGGA with optimization is compared to the reduction algorithms, on two problem classes. The performance of the HGGA with local optimization is impressive. It is much better than the reduction algorithm and is almost always successful, even on the hardest problem instances. <p> In the former case it is easier to improve the candidate solution by reassigning objects to decrease the used number of bins, and this situation is preferred. It can be proven that f yields the same optima as the original bin packing objective <ref> [14] </ref>. <p> The EA with feasibility preserving operators is the best representative of the asexual EAs without optimization, with good performance on the larger instances. 5.7.4 Comparison of the Different Approaches First of all we compare the reduction algorithm of Martello and Toth [24] and the sexual HGGA of Falkenauer <ref> [14] </ref> with our best EAs on the uniform items. We used the results presented in [14]. This is possible because we used the same maximum number of fitness evaluations for all problem sizes. The reduction algorithm is a deterministic algorithm: no random decisions are made. <p> EAs without optimization, with good performance on the larger instances. 5.7.4 Comparison of the Different Approaches First of all we compare the reduction algorithm of Martello and Toth [24] and the sexual HGGA of Falkenauer <ref> [14] </ref> with our best EAs on the uniform items. We used the results presented in [14]. This is possible because we used the same maximum number of fitness evaluations for all problem sizes. The reduction algorithm is a deterministic algorithm: no random decisions are made. One run is sufficient to obtain results. <p> An EA with only one of this two components shows substantially worse performance. 4 The best variants of each approach are compared. 44 The EA with the best performance is the sexual hybrid grouping GA (HGGA) of Falkenauer <ref> [14] </ref>, closely followed by its asexual variant, which is a simpler but still very successful approach. Surprisingly, the most successful asexual HGGA is a (1,1) selection strategy, which hardly can be seen as an EA. It is not the EA that does the work, but the mutation operator. <p> We have implemented and 60 tested an EA with repair and optimization. Although the success rate increases somewhat, the success rate still is low on the triplets. We therefore investigated an asexual variant of Falkenauers Hybrid Grouping GA (HGGA) <ref> [14] </ref>. The asexual HGGA performs very well, with a percentage of more than 90% of the hardest test cases solved, which is close to the performance of its sexual counterpart. Surprisingly, the best asexual HGGA uses a (1,1) selection strategy, and this algorithm can hardly be called an EA.
Reference: [15] <author> E. Falkenauer and A. Delchambre. </author> <title> A genetic algorithm for bin packing and line balancing. </title> <booktitle> In Proceedings of the IEEE 1992 Int. Conference on Robotics and Automation, </booktitle> <pages> pages 1186-1192. </pages> <publisher> IEEE Computer Society Press, </publisher> <year> 1992. </year>
Reference-contexts: In such a function, no distinction is made between individuals representing the same number of bins, resulting in an discontinuous fitness landscape with large plateaus that prevents gradual improvements of candidate solutions. In <ref> [15] </ref> the following cost function 1 was proposed: f = i=1 (F i =c) 2 Where B is the number of used bins in the candidate solution, F i the fill of bin i (its contents) and C the bin capacity.
Reference: [16] <author> C. Fleurent and J.A. Ferland. </author> <title> Object-oriented implementation of heuristic search methods for graph coloring, maximum clique, and satisfiability. </title> <editor> In M. A. Trick and D. S. Johnson, editors, </editor> <title> Second DIMACS Challenge, </title> <note> special issue, DIMACS Series in Discrete Mathematics and Theoretical Computer Science, 1996. to appear. </note>
Reference-contexts: The weights are used in deciding which flip is chosen. WGSAT shows better performance than both GSAT and HSAT. 6.3.2 Evolutionary Algorithms Some examples of EAs on satisfiability are [8], <ref> [16] </ref> and [22]. Recently, Eiben and Van der Hauw [11] proposed an EA with adaptive penalty function, which was very successful. They used a problem independent constraint handling mechanism, Stepwise Adaption of Weights (SAW). This mechanism substantially increases the performance of the EA.
Reference: [17] <author> J. Frank. </author> <title> Weighting for godot: Learning heuristics for GSAT. </title> <booktitle> In Proceedings of the AAAI, </booktitle> <year> 1996. </year> <note> Available by http://rainier.cs.ucdavis.edu/~frank/weighting .aaai96.ps. </note>
Reference-contexts: The variant of GSAT with the best performance is the HSAT algorithm. The only difference with GSAT is that HSAT uses a deterministic tabu-like restriction to pick a variable which was flipped the longest time ago. Frank <ref> [17] </ref> introduced a variant of GSAT called WGSAT with an adaptive weighting mechanism. A weight is associated with each clause. <p> This heuristic is directly implemented in WGSat and tested. It is also possible to determine the optimal number of evaluations before the algorithm restarts, given a certain problem size. Frank for example <ref> [17] </ref>, gives an optimal value of 125000 for n = 100. However, the situation is different here, because we want to compare WGSat on the same maximum number of evaluations the EAs used.
Reference: [18] <author> M.R. Garey and D.S. Johnson. </author> <title> Computers and Intractability, A Guide to the Theory of NP-Completeness. </title> <publisher> W.H.Freeman and company, </publisher> <year> 1979. </year>
Reference-contexts: The second problem which is investigated is Satisfiability (SAT), a Constraint Satisfaction Problem (CSP), which does not have an optimization component. Both problems belong to the class of NP-hard problems <ref> [18] </ref>, which implies no algorithms are known to exist, solving these problems in polynomial time. A detailed problem description will be presented later on. 1.3 Research Goals The most important objective in the thesis is comparing ways to deal with constraints when using an EA. <p> What is the optimal packing, i.e., the assignment of the objects to bins so that the total weight of the objects in a bin does not exceed c and the number of bins used is a minimum? The BPP is NP-hard <ref> [18] </ref>. We present a more formal definition: Problem instance: Given n objects and n bins with w j the weight of of item j and c the capacity of each bin. N = f1; 2; :::; ng. <p> Such a formula is a conjunction of clauses, and a clause is a disjunction of literals. In the 3-SAT version we examine, a clause consists of exactly three literals. SAT and also 3-SAT are NP-hard <ref> [18] </ref>. We give a more formal description of 3-SAT: Problem instance: A propositional formula ' in conjunctive normal form with n binary variables fv 1 ; v 2 ; :::; v n g.
Reference: [19] <author> I. Gent and T. Walsh. </author> <title> Unsatisfied variables in local search. </title> <editor> In J. Hallam, editor, </editor> <title> Hybrid Problems, Hybrid Solutions. </title> <publisher> IOS Press, </publisher> <year> 1995. </year>
Reference-contexts: It has exponential time complexity and therefore several incomplete algorithms on SAT exist. GSAT presented by Gent and Walsh <ref> [19] </ref> is a greedy random hill-climbing procedure with surprisingly good performance on hard random problems. A general framework called GenSAT, which captures GSAT and variants, is shown in figure 6.1. The function initial generates a random truth assignment.
Reference: [20] <author> D.E. Goldberg. </author> <title> Genetic Algorithms in Search, Optimization and Machine Learning. </title> <publisher> Addison-Wesley, </publisher> <year> 1989. </year>
Reference-contexts: A "building block" is a small piece of genetic information (partial solution) with high fitness. The crossover operator should direct genetic search towards finding building blocks and combine them to produce better overall solutions (see also <ref> [20] </ref>, "The building block hypothesis"). The mutation operator is used to bring in information not present in the population. The selection operator imitates the natural selection mechanism: the fittest individuals survive.
Reference: [21] <author> S. Hampson and D. Kibler. </author> <title> Plateaus and plateau search in boolean satisfiability problems: When to give up searching and start again. </title> <note> 1995. DIMACS Challenge 1995, Available by http://www.ics.uci.edu/~kibler/. </note>
Reference-contexts: Given a fixed number of search steps, it can be recommendable to restart the search process from a random initial point, instead of extensively searching plateaus in search space to escape them. In their article <ref> [21] </ref> Hampson and Kibler describe two possibilities to determine when to give up searching and start again for a greedy hill-climber. The hill-climb algorithm repeatedly flips a single bit, starting with the first and ending with the last, and checks if the number of satisfied clauses increases.
Reference: [22] <author> Jin-Kao Hao. </author> <title> A clausal genetic representation and its evolutionary procedures for satisfiability problems. </title> <booktitle> In Proceedings of the International Conference on Artificial Neural Networks and Genetic Algorithms, </booktitle> <address> France, </address> <month> April </month> <year> 1995. </year>
Reference-contexts: The weights are used in deciding which flip is chosen. WGSAT shows better performance than both GSAT and HSAT. 6.3.2 Evolutionary Algorithms Some examples of EAs on satisfiability are [8], [16] and <ref> [22] </ref>. Recently, Eiben and Van der Hauw [11] proposed an EA with adaptive penalty function, which was very successful. They used a problem independent constraint handling mechanism, Stepwise Adaption of Weights (SAW). This mechanism substantially increases the performance of the EA.
Reference: [23] <author> S. Khuri, M. Schutz, and J. Heitkotter. </author> <title> Evolutionary heuristics for the bin packing problem. In D.W. Pearson, N.C. </title> <editor> Steele, and R.F. Albrecht, editors, </editor> <booktitle> Proceedings of the 2nd International Conference on Artificial Neural Networks and Genetic Algorithms, </booktitle> <pages> pages 285-288, </pages> <address> France, April 1995. </address> <publisher> Springer, Wien. </publisher> <pages> 68 </pages>
Reference-contexts: Although there is a risk of getting stuck in a local optimum, in general the performance increases significantly. The EA is superior to a simple heuristic like first fit. 16 EA with Graded Penalty Khuri, Schutz and Heitkoter <ref> [23] </ref> used an integer based EA to solve the bin packing problem and compared it with the first fit descending heuristic. They did not use problem specific knowledge or problem specific operators, only a straightforward fitness function with graded penalty. <p> Bins with contents close to its capacity C are favored: f 1 = i=1 abs (F i c) The value on the example would be f 1 = 30:4. The second fitness function is the same as in the article by S. Khuri and others <ref> [23] </ref>. It minimizes the number of bins and adds a graded penalty term for over filled bins: f 2 = B + S (L + i=1 where S is 1 if the candidate solution is feasible, 0 otherwise, and L is the length of an individual.
Reference: [24] <author> S. Martello and P. Toth. </author> <title> Knapsack Problems: Algorithms and Computer Implemen--tations. </title> <publisher> Wiley, </publisher> <year> 1991. </year>
Reference-contexts: Four problem sizes are available: 120, 250, 500, 1000 items. There are 20 instances for each problem size. These instances proved to be difficult for the reduction algorithm of Martello and Toth <ref> [24] </ref>. The second class is called "triplets" and consists of integer objects with sizes drawn from the range 250 to 500, to be packed into bins of capacity 1000. The objects are drawn in such way that an optimal bin contains three objects, one big object and two small ones. <p> More information on these heuristics can be found in <ref> [24] </ref>. Reduction Algorithm A more complex approach is found in the Reduction Algorithm. This approximation algorithm is developed by Martello and Toth [24] and is one of the best BPP algorithms known. <p> More information on these heuristics can be found in <ref> [24] </ref>. Reduction Algorithm A more complex approach is found in the Reduction Algorithm. This approximation algorithm is developed by Martello and Toth [24] and is one of the best BPP algorithms known. A feasible set F is defined as a subset of all items, where the sum of the items in F is not larger than the bin size. <p> It is clear this is an approximation algorithm, i.e., it is not guaranteed to find an optimal solution. The time complexity is O (n 3 ). More information on the reduction algorithm can be found in <ref> [24] </ref>. 4.3.2 Evolutionary Algorithms EA with Decoder Reeves [29] uses an order based EA for the bin packing problem. Individuals in the population are permutations and are decoded using the next, first or best fit heuristic. The most successful heuristic is "best fit". <p> The EA with feasibility preserving operators is the best representative of the asexual EAs without optimization, with good performance on the larger instances. 5.7.4 Comparison of the Different Approaches First of all we compare the reduction algorithm of Martello and Toth <ref> [24] </ref> and the sexual HGGA of Falkenauer [14] with our best EAs on the uniform items. We used the results presented in [14]. This is possible because we used the same maximum number of fitness evaluations for all problem sizes.
Reference: [25] <author> Z. Michalewicz. </author> <title> Genetic Algorithms + Data structures = Evolution programs. </title> <publisher> Springer-Verlag, </publisher> <address> second edition, </address> <year> 1994. </year>
Reference-contexts: The mutation operator is used to bring in information not present in the population. The selection operator imitates the natural selection mechanism: the fittest individuals survive. For more information on the topic the reader is referred to <ref> [25] </ref> and [1]. 1 In analogy with the recombination of chromosomes and the exchange of corresponding pieces of chro mosome couples. 2 In analogy with faults made during the doubling of a DNA molecule. 3 t = 0 initialize P (0) evaluate P (0) while stop condition not reached do P'(t) <p> One of the most often investigated problems is probably the Traveling Salesman Problem. The objective of this problem is to find the shortest tour between a number of cities, without visiting the same city twice, given a number of cities and the distances between them. In Chapter 10 of <ref> [25] </ref> an overview is given which illustrates a number of approaches to handle constraints: an adjacency based representation with feasibility preserving operators, an order based representation with standard order based operators, an ordinal representation with decoder and some binary matrix based representations with special matrix operators and decoder. <p> Scheduling problems often use an order based representation and decoder to handle their constraints. In [6] an example is given of a production line scheduler with permutation encoding and standard order based operators. Another example of scheduling can be found in <ref> [25] </ref>, where a preference list representation together with a decoder and special operators are used. But also other problems such as bin packing [29], with an order based encoding and simple heuristic decoder, use the decoder approach. Repair seems to be somewhat less common than the previous two approaches. In [25] <p> <ref> [25] </ref>, where a preference list representation together with a decoder and special operators are used. But also other problems such as bin packing [29], with an order based encoding and simple heuristic decoder, use the decoder approach. Repair seems to be somewhat less common than the previous two approaches. In [25] a repair approach is compared to a penalty approach and a decoder approach for the knapsack problem. <p> The repair method performs substantially better than the penalty approach and also encounters better solutions than the heuristic algorithm in most cases. In <ref> [25] </ref>, a matrix representation with feasibility preserving operators is investigated for the linear and nonlinear transportation problem. The EA with feasibility preserving operators performs better than for example a gradient based technique. Another successful example of the use of feasibility preserving operators is [14]. <p> For bin packing the new value can be equal to the old, but for satisfiability, with a domain size of 2, a mutated gene is always flipped to a new value. More information on these operators can be found in <ref> [25] </ref>. Order Based Operators All order based operators work on permutations. Order Crossover (OX) generates offspring by choosing a subsequence of a permutation from one parent and preserving the relative order of the genes from the other parent. Order Crossover 2 (OX2) is a variant of this reproduction operator. <p> Often p m gives the probability of swapping a random pair of genes, but we will our use our own convention, because it is more similar to the integer based mutation rate. More information on these operators can be found in <ref> [25] </ref>. 3.1.6 Survivor Selection In this thesis we will use the notation 1 from the Evolution Strategies [1]. The population size is denoted by , the offspring size by . Two major schemes for selecting the new population from the current population and its offspring exist.
Reference: [26] <author> Z. Michalewicz and M. Schoenauer. </author> <title> Evolutionary algorithms for constrained parameter optimization problems. </title> <journal> Evolutionary Computation, </journal> <volume> 4 </volume> <pages> 1-1, </pages> <year> 1996. </year>
Reference-contexts: An extensive overview of constraint handling approaches can be found in <ref> [26] </ref>. Penalty Functions Many constraint handling methods are based on penalty functions. A constrained problem is transformed to a FOP, and an infeasible individual is penalized.
Reference: [27] <author> D. Mitchell, B. Selman, and H.J. Levesque. </author> <title> Hard and easy distributions of SAT problems. </title> <booktitle> In Proceedings of the AAAI, </booktitle> <pages> pages 459-465, </pages> <address> San Jose, CA, </address> <year> 1992. </year>
Reference-contexts: We use formulas forced satisfiable by the generator. The program has four inputs: the clause length c, the number of variables n, the number of clauses l, and a random seed r. Mitchell et al. <ref> [27] </ref> empirically found that the hardest instances are those where l n = 4:3. 1 We use instances generated on an indigo 2 unix based workstation.
Reference: [28] <author> H. Muhlenbein. </author> <title> How genetic algorithms really work: </title> <editor> I. mutation and hillclimbing. In R. Manner and B. Manderick, editors, </editor> <booktitle> Parallel Problem Solving from Nature - 2, </booktitle> <pages> pages 15-25, </pages> <address> Amsterdam, 1992. </address> <publisher> Elsevier. </publisher>
Reference-contexts: The swap operator is used as mutation. The population size is 200, as always in this thesis when using a sexual EA, and the mutation rate is 1 L . This is assumed to be a reasonable value <ref> [28] </ref>. The maximum number of evaluations T max is 134000 for the uniformly distributed items and 67000 for the triplets, the same values Falkenauer for his Hybrid Grouping GA. The results are given in Table 5.1.
Reference: [29] <author> C. Reeves. </author> <title> Hybrid genetic algorithms for bin-packing and related problems. </title> <note> In (Submitted to) Annals of Operations Research, </note> <year> 1993. </year>
Reference-contexts: Another example of scheduling can be found in [25], where a preference list representation together with a decoder and special operators are used. But also other problems such as bin packing <ref> [29] </ref>, with an order based encoding and simple heuristic decoder, use the decoder approach. Repair seems to be somewhat less common than the previous two approaches. In [25] a repair approach is compared to a penalty approach and a decoder approach for the knapsack problem. <p> It is clear this is an approximation algorithm, i.e., it is not guaranteed to find an optimal solution. The time complexity is O (n 3 ). More information on the reduction algorithm can be found in [24]. 4.3.2 Evolutionary Algorithms EA with Decoder Reeves <ref> [29] </ref> uses an order based EA for the bin packing problem. Individuals in the population are permutations and are decoded using the next, first or best fit heuristic. The most successful heuristic is "best fit". <p> After the optimization, the remaining items are "first fit descending" (FFD) reinserted. In the first article [12], Falkenauer compares the grouping GA without optimization to the EA by Reeves <ref> [29] </ref> and concludes the HGGA is superior 2 . In the other articles [13] and [14] the HGGA with optimization is compared to the reduction algorithms, on two problem classes. The performance of the HGGA with local optimization is impressive. <p> We have chosen a simple straightforward decoder, the best fit heuristic, since this heuristic showed the best results compared to the next fit and first fit heuristics in <ref> [29] </ref>. We give an examples.
Reference: [30] <author> Gilbert Syswerda. </author> <title> A study of reproduction in generational and steady-state genetic algorithms. </title> <booktitle> In Foundations of Genetic Algorithms - 1, </booktitle> <pages> pages 94-101, </pages> <year> 1992. </year>
Reference-contexts: optimization procedure is superior to one of the best known traditional bin packing algorithms. 7 Chapter 3 Characteristics of the Used EAs 3.1 Steady State EA 3.1.1 Algorithm The EA we use for the bin packing problem and the satisfiability problem belongs to the class of Steady State EAs (SSEA) <ref> [30] </ref>. This type of EA fits in the general framework shown in figure 2.1. In a SSEA only few members of the population are changed at a time, in contrast to a generational EA.
Reference: [31] <author> J.K. van der Hauw. </author> <title> Evaluating and Improving Steady State Evolutionary Algorithms on Constraint Satisfaction Problems. </title> <type> Master's thesis, </type> <institution> Leiden University, </institution> <year> 1996. </year>
Reference-contexts: He argues that an encoding 1 and operators fitting the structure of the problem and a sophisticated local optimization is necessary to obtain a high performance GA. We will verify his conclusion for the BPP. One of the main conclusions in previous research on graph colouring and satisfiability <ref> [31] </ref>, two constraint satisfaction problems, was that an asexual EA with population size 1 performs better than an EA with recombination. We will also verify this conclusion. <p> CSPs always use a penalty function, because they have no optimization component and the only way to distinguish between candidate solutions is to measure the 6 violation of the constraints. Examples of problems solved by EAs using a penalty function are Graph Colouring <ref> [31] </ref>, which uses a decoder and adaptive penalty function, and Time Tabling [4] with an integer based representation, a number of specialized operators and a static penalty function. Scheduling problems often use an order based representation and decoder to handle their constraints. <p> In Section 8.2 we give some suggestions to overcome this problem. 7.3 Steady State EA with SAW-ing on SAT 7.3.1 The SAW Mechanism The Stepwise Adaption of Weights (SAW) is an on-line weight adaption mechanism and was introduced in [9]. Is has been applied on graph colouring in <ref> [31] </ref>, and satisfiability in [11]. The weight adaption mechanism is shown in figure 7.1. A weight, initially 1, is assigned to every constraint. After a period T p , the best individual in the population is selected and the the weights of those constraints it violates, are increased by 4w. <p> We will use the same values as in [11], T p = 250 and 4w = 1. 7.3.2 Experimental Results In [11], it was concluded that mutation alone with a population size = 1 is powerful enough to solve 3-SAT with high success rate. Experiments in <ref> [31] </ref> show the asexual EA with = 1 outperforms an EA with recombination. We test a (1+1) selection strategy with MutOne operator, which always exactly changes one bit. Furthermore, we test two (1; ) selection strategies, with the same mutation 53 operator. <p> The most successful ES is a (15,100)-ES with global discrete recombination. The second EA approach investigated, was an asexual EA with population size 1 and adaptive weight mechanism in the penalty function. These settings were found to give the best performance in <ref> [31] </ref>. This mechanism, the Stepwise Adaption of Weights, assigns a weight to every constraint, and increases a weight after a certain period if the corresponding constraint is not satisfied. The SAW-ing EA shows good performance. <p> The SAW mechanism is very powerful, and substantially improves the performance of the tested algorithms. This mechanism is problem independent, and can directly be applied to CSPs. The SAW has proven to be successful on satisfiability and graph colouring (see also <ref> [31] </ref>). More research will have to show, if it also increases the performance of other CSPs. It will also be interesting to see if the SAW is applicable to COPs, constrained problems including an optimization component. <p> More research on asexual EAs with population size 1 could tell us more about its performance compared to classical sexual EAs. Not only are the asexual EAs in general better than the sexual EAs on bin packing as our research showed, the same holds for graph colouring and satisfiability <ref> [31] </ref>. More research is necessary to confirm our presumption, that asexual EAs could prove to be more efficient for a large class of problems than the sexual EAs.
Reference: [32] <author> G. von Laszewski. </author> <title> Intelligent strucural operators for the k-way graph partitioning problem. </title> <editor> In R.K. Belew and L.B. Booker, editors, </editor> <booktitle> Proceedings of the 4th International Conference on Genetic Algorithms, </booktitle> <pages> pages 45-52. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1991. </year>
Reference-contexts: The consequence of this approach is that new operators have to be developed. In this section we investigate a feasibility preserving crossover and mutation. They both use the best fit (descending) heuristic. The crossover is based on Von Laszewski's structural based crossover operator <ref> [32] </ref>, but is adapted to fit the bin packing problem. In his article [32], Von Laszewski presents a GA for the k-way graph partitioning problem. <p> In this section we investigate a feasibility preserving crossover and mutation. They both use the best fit (descending) heuristic. The crossover is based on Von Laszewski's structural based crossover operator <ref> [32] </ref>, but is adapted to fit the bin packing problem. In his article [32], Von Laszewski presents a GA for the k-way graph partitioning problem. The problem is to divide the graph into k disjoint subsets of nodes such that the sum of the weights of edges between nodes in different subsets is minimal, and the sizes of the subsets are nearly equal. <p> Instead of using standard operators, he uses a more intelligent crossover operator, which copies subsets of nodes. The representation is integer based, each value x i indicates to what subset node i belongs. The structural crossover of Von Laszewski <ref> [32] </ref> works as follows. One of the subsets in the parent string is chosen at random and copied into the other parent string. The copying process may destroy the constraint of equal partition sizes, therefore a repair procedure is applied.
Reference: [33] <author> D. Whitley, V.S. Gordon, and K. Mathias. </author> <title> Lamarckian evolution, the Baldwin effect and function optimization. </title> <editor> In H.-P. Schwefel Y. Davidor and R. Manner, editors, </editor> <booktitle> Proceedings of the 3rd Conference on Parallel Problem Solving from Nature, number 866 in Lecture Notes in Computer Science, </booktitle> <pages> pages 6-15. </pages> <publisher> Springer-Verlag, </publisher> <year> 1994. </year> <month> 69 </month>
Reference-contexts: So, in general, when there are not too much objects in the same bin, the optimal removal does not cost much (more than 5 objects in a bin is an exception). Whitley, Gordon and Mathias discuss two forms of hybrid genetic search in <ref> [33] </ref>. The first uses Lamarckian evolution; a local search is performed on an individual, and the locally optimized individual is put back in the population. The evolution is called Lamarckian. Lamarck thought obtained properties could be inherited.
References-found: 33

