URL: ftp://ftp.eecs.umich.edu/people/durfee/icmas95-gd.ps.Z
Refering-URL: http://ai.eecs.umich.edu/diag/RMM.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: piotr@cse.uta.edu, durfee@caen.engin.umich.edu  
Title: A Rigorous, Operational Formalization of Recursive Modeling  
Author: Piotr J. Gmytrasiewicz and Edmund H. Durfee 
Address: TX 76019-0015  Ann Arbor, Michigan 48109  
Affiliation: Department of Computer Science and Engineering University of Texas at Arlington, Arlington,  Department of Electrical Engineering and Computer Science University of Michigan  
Abstract: We present a formalization of the Recursive Modeling Method, which we have previously, somewhat informally, proposed as a method that autonomous artificial agents can use for intelligent coordination and communication with other agents. Our formalism is closely related to models proposed in the area of game theory, but contains new elements that lead to a different solution concept. The advantage of our solution method is that always yields the optimal solution, which is the rational action of the agent in a multi-agent environment, given the agent's state of knowledge and its preferences, and that it works in realistic cases when agents have only a finite amount of information about the agents they interact with. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Aumann, R. J., and Brandenburger, A. </author> <year> 1994. </year> <title> Epistemic conditions for Nash equilibrium. </title> <type> Working paper, </type> <institution> Harvard Business School, Harverd. </institution>
Reference-contexts: In this work, the state of an agent's knowledge, or its epistemic state, is represented as an agent's type, consisting, roughly speaking, of a payoff matrix and the probability distribution over the possible types of the other agents. This structure, called an interactive belief system in <ref> (Aumann & Branden-burger 1994) </ref>, represents the state of an agent's knowledge, very much like RMM's recursive model structure does.
Reference: <author> Ballim, A., and Wilks, Y. </author> <year> 1991. </year> <title> Artificial Believers. </title> <publisher> Earl-baum Associates, Inc. </publisher>
Reference-contexts: Another related work on nested belief, with an extensive formalism, is one by Ballim and Wilkes <ref> (Ballim & Wilks 1991) </ref> and by Korf (Korf 1989). The applications of game-theoretic techniques to the problem of decision-making in multi-agent domains have also received attention in the Distributed AI literature, for example in (Rosenschein & Breese 1989; Rosenschein & Genesereth 1985; Zlotkin & Rosenschein 1989; 1990a; 1990b).
Reference: <author> Bicchieri, C. </author> <year> 1993. </year> <title> Rationality and Coordination. </title> <publisher> Cam-bridge University Press. </publisher>
Reference: <author> Binmore, K. </author> <year> 1982. </year> <booktitle> Essays on Foundations of Game Theory. </booktitle> <publisher> Pitman. </publisher>
Reference-contexts: This matter is a subject of considerable debate in the field of game theory itself (Aumann & Brandenburger 1994; Bicchieri 1993; Binmore 1982; Brandenburger 1992; Geanakoplos 1992; Reny 1988; Tan & Werlang 1988). Binmore <ref> (Binmore 1982) </ref> and Brandenburger (Brandenburger 1992) both point out that the weakness of the assumption of common knowledge points directly to the need for an explicit model of the decision-making of the agents involved, given their states of knowledge. This is exactly our approach in RMM.
Reference: <author> Brandenburger, A., and Dekel, E. </author> <year> 1993. </year> <title> Hierarchies of beliefs and common knowledge. </title> <journal> Journal of Economic Theory 59 </journal> <pages> 189-198. </pages>
Reference: <author> Brandenburger, A. </author> <year> 1992. </year> <title> Knowledge and equilibrium in games. </title> <journal> Journal of Economic Perspectives 6 </journal> <pages> 83-101. </pages>
Reference-contexts: This matter is a subject of considerable debate in the field of game theory itself (Aumann & Brandenburger 1994; Bicchieri 1993; Binmore 1982; Brandenburger 1992; Geanakoplos 1992; Reny 1988; Tan & Werlang 1988). Binmore (Binmore 1982) and Brandenburger <ref> (Brandenburger 1992) </ref> both point out that the weakness of the assumption of common knowledge points directly to the need for an explicit model of the decision-making of the agents involved, given their states of knowledge. This is exactly our approach in RMM.
Reference: <author> Chernoff, H., and Moses, L. E. </author> <year> 1959. </year> <title> Elementary Decision Theory. </title> <address> New York: </address> <publisher> John Wiley. </publisher>
Reference: <author> Cohen, P. R., and Levesque, H. J. </author> <year> 1990a. </year> <title> Persistence , intention and commitment. </title> <editor> In Cohen, P. R.; Morgan, J.; and Pollack, M. E., eds., </editor> <title> Intentions in Communication. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Our approach also follows Dennett's formulation of the intentional stance (Den-nett 1986), and his idea of the ladder of agenthood (see (Narayanan 1988) for a succinct discussion), the first five levels of which we see as actually embodied in RMM. Cohen and Levesque <ref> (Cohen & Levesque 1990a) </ref> formalize intention and commitment, and apply it to issues of communication (Cohen & Levesque 1990b).
Reference: <author> Cohen, P. R., and Levesque, H. J. </author> <year> 1990b. </year> <title> Rational interaction as the basis for communication. </title> <editor> In Cohen, P. R.; Morgan, J.; and Pollack, M. E., eds., </editor> <title> Intentions in Communication. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Cohen and Levesque (Cohen & Levesque 1990a) formalize intention and commitment, and apply it to issues of communication <ref> (Cohen & Levesque 1990b) </ref>. These authors, as well as Perrault in (Perrault 1990), analyze the nestedness of beliefs so important in issues of communication, but rely on a notion of common belief, the justifiability of which (as with common knowledge) we find problematic (see also (Bic-chieri 1993) for related discussion).
Reference: <author> Dennett, D. </author> <year> 1986. </year> <title> Intentional systems. </title> <editor> In Dennett, D., ed., Brainstorms. </editor> <publisher> MIT Press. </publisher>
Reference-contexts: possible forms: M R j = &gt; &lt; IM R j the Intentional model, N M R j the No-Information model, SM R j the Sub-Intentional model. (4) The Intentional model corresponds to R i modeling R j as a rational agent, as advocated, for instance, by Daniel Dennett in <ref> (Dennett 1986) </ref>. It is defined as: 2 In game theory this construct is also called the agent's theory. IM R j = RM S R j ; (5) that is, it is the recursive model structure that agent R i ascribes to agent R j . <p> The Sub-Intentional model corresponds to treating the agent as not being rational. In realistic situations it may, for example, be unclear whether the agent is, in fact, a rational agent, or whether it is, say, a piece of furniture. As Dennett proposes <ref> (Dennett 1986) </ref>, the intentional stance is not the only one possible and useful.
Reference: <author> Doyle, J. </author> <year> 1992. </year> <title> Rationality and its role in reasoning. </title> <booktitle> Computational Intelligence 8 </booktitle> <pages> 376-409. </pages>
Reference: <author> Durfee, E. H.; Gmytrasiewicz, P.; and Rosenschein, J. </author> <year> 1994. </year> <title> The utility of embedded communications and the emergence of protocols. </title> <booktitle> In Proceedings of 13th International Distributed Artificial Intelligence Workshop. </booktitle>
Reference-contexts: Modeling Method (RMM) has provided a powerful decision-theoretic underpinning for coordination and communication decisionmaking, including decisions about synchronized plans (Gmytrasiewicz & Durfee 1992), about knowledge-oriented actions (Gmy-trasiewicz & Rosenschein 1993), about honesty and trust among self-interested agents (Gmytrasiewicz & Durfee 1993 to appear), and about the principled adoption of protocols <ref> (Durfee, Gmytrasiewicz, & Rosen-schein 1994) </ref>.
Reference: <author> Fagin, R. R.; Halpern, J. Y.; and Vardi, M. Y. </author> <year> 1991. </year> <title> A model-theoretic analysis of knowledge. </title> <journal> Journal of the ACM </journal> (2):382-428. 
Reference-contexts: Shoham's agent-oriented programming (AOP) (Shoham 1993) takes more of a programming-language perspective. However, while Shoham has proposed it as an extension, decision-theoretic rationality has not yet been included in AOP. The models investigated by Fagin and colleagues in <ref> (Fagin, Halpern, & Vardi 1991) </ref> are related to ours, and include a no-information extension (like the No-Information model in RMM, but containing infinite recursion) to handle the situation where an agent runs out of knowledge at a finite level of nesting.
Reference: <author> Forbus, K. </author> <year> 1980. </year> <title> Spatial and qualitative aspects of reasoning about motion. </title> <booktitle> In Proceedings of the First Annual National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: functions of a console controller board's components lead to its overall behavior (Hamscher 1986)), and the physical stance, which predicts behavior using the description of the physical state of what is being modeled along with knowledge of the laws of nature (like in the qualitative model of a bouncing ball <ref> (Forbus 1980) </ref>). For the purpose of this paper, we will assume that an agent can incorporate well-studied techniques such as model-based reasoning and qualitative physics to make predictions about the behavior of sub-intentional entities, resulting in a probability distribution over their alternative behaviors, as enumerated in the agent's payoff matrix.
Reference: <author> Geanakoplos, J. </author> <year> 1992. </year> <title> Common knowledge. </title> <booktitle> In Proceedings of the Conference on Theoretical Aspects of Reasoning about Knowladge, </booktitle> <pages> 255-315. </pages> <publisher> Morgan Kaufman. </publisher>
Reference: <author> Gmytrasiewicz, P. J., and Durfee, E. H. </author> <year> 1992. </year> <title> Decision-theoretic recursive modeling and the coordinated attack problem. </title> <booktitle> In Proceedings of the First International Conference on Artificial Intelligence Planning Systems | AIPS92, </booktitle> <pages> 88-95. </pages>
Reference-contexts: Introduction Since its initial conceptual development several years ago (Gmytrasiewicz, Durfee, & Wehe 1991a; 1991b), the Recursive Modeling Method (RMM) has provided a powerful decision-theoretic underpinning for coordination and communication decisionmaking, including decisions about synchronized plans <ref> (Gmytrasiewicz & Durfee 1992) </ref>, about knowledge-oriented actions (Gmy-trasiewicz & Rosenschein 1993), about honesty and trust among self-interested agents (Gmytrasiewicz & Durfee 1993 to appear), and about the principled adoption of protocols (Durfee, Gmytrasiewicz, & Rosen-schein 1994).
Reference: <author> Gmytrasiewicz, P. J., and Durfee, E. H. </author> <year> 1993, </year> <title> to appear. Toward a theory of honesty and trust among communicating autonomous agents. Group Decision and Negotiation. </title>
Reference-contexts: conceptual development several years ago (Gmytrasiewicz, Durfee, & Wehe 1991a; 1991b), the Recursive Modeling Method (RMM) has provided a powerful decision-theoretic underpinning for coordination and communication decisionmaking, including decisions about synchronized plans (Gmytrasiewicz & Durfee 1992), about knowledge-oriented actions (Gmy-trasiewicz & Rosenschein 1993), about honesty and trust among self-interested agents <ref> (Gmytrasiewicz & Durfee 1993 to appear) </ref>, and about the principled adoption of protocols (Durfee, Gmytrasiewicz, & Rosen-schein 1994).
Reference: <author> Gmytrasiewicz, P. J., and Rosenschein, J. S. </author> <year> 1993. </year> <title> The utility of embedded knowledge-oriented actions. </title> <booktitle> In Proceedings of the Twelveth International Workshop on Distributed Artifcial Intelligence. </booktitle>
Reference-contexts: conceptual development several years ago (Gmytrasiewicz, Durfee, & Wehe 1991a; 1991b), the Recursive Modeling Method (RMM) has provided a powerful decision-theoretic underpinning for coordination and communication decisionmaking, including decisions about synchronized plans (Gmytrasiewicz & Durfee 1992), about knowledge-oriented actions (Gmy-trasiewicz & Rosenschein 1993), about honesty and trust among self-interested agents <ref> (Gmytrasiewicz & Durfee 1993 to appear) </ref>, and about the principled adoption of protocols (Durfee, Gmytrasiewicz, & Rosen-schein 1994).
Reference: <author> Gmytrasiewicz, P. J.; Durfee, E. H.; and Wehe, D. K. </author> <year> 1991a. </year> <title> The utility of communication in coordinating intelligent agents. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 166-172. </pages>
Reference: <author> Gmytrasiewicz, P. J.; Durfee, E. H.; and Wehe, D. K. </author> <year> 1991b. </year> <title> A decision-theoretic approach to coordinating mul-tiagent interactions. </title> <booktitle> In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 62-68. </pages>
Reference: <author> Gmytrasiewicz, P. J.; Huang, H. H.; and Lewis, F. L. </author> <year> 1995. </year> <title> Combining operations research and agent-oriented techniques for agile manufacturing system design. </title> <booktitle> In To Appear in the Proceedings of the IASTED International Conference on Robotics and Manufacturing. </booktitle>
Reference-contexts: Initially developed for coordinating robots in a nuclear reactor, RMM has more recently been identified as a prime candidate for realizing agile manufacturing systems <ref> (Gmytrasiewicz, Huang, & Lewis 1995) </ref>, because it can unify operations research techniques (used for decades in factory automation and scheduling) and the agent-oriented paradigm emerging in artificial intelligence.
Reference: <author> Hamscher, W. C. </author> <year> 1986. </year> <title> Modeling digital circuits for troubleshooting. </title> <journal> Artificial Intelligence 51:1991. </journal>
Reference-contexts: As Dennett proposes (Dennett 1986), the intentional stance is not the only one possible and useful. There is the design stance, which predicts behavior using functionality (such as how the functions of a console controller board's components lead to its overall behavior <ref> (Hamscher 1986) </ref>), and the physical stance, which predicts behavior using the description of the physical state of what is being modeled along with knowledge of the laws of nature (like in the qualitative model of a bouncing ball (Forbus 1980)).
Reference: <author> Harsanyi, J. C. </author> <year> 1967. </year> <title> Games with incomplete information played by 'bayesian' players. </title> <booktitle> Management Science 14(3) </booktitle> <pages> 159-182. </pages>
Reference: <author> Horvitz, E. J.; Cooper, G. F.; and Heckerman, D. E. </author> <year> 1989. </year> <title> Reflection and action under scarce resources: </title> <booktitle> Theoretical principles and theoretical study. In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> 1121-1127. </pages>
Reference: <author> Korf, R. E. </author> <year> 1989. </year> <title> Multi-agent decision trees. </title> <booktitle> In Proceedings of the 1989 Distributed AI Workshop, </booktitle> <pages> 293-306. </pages>
Reference-contexts: Another related work on nested belief, with an extensive formalism, is one by Ballim and Wilkes (Ballim & Wilks 1991) and by Korf <ref> (Korf 1989) </ref>. The applications of game-theoretic techniques to the problem of decision-making in multi-agent domains have also received attention in the Distributed AI literature, for example in (Rosenschein & Breese 1989; Rosenschein & Genesereth 1985; Zlotkin & Rosenschein 1989; 1990a; 1990b).
Reference: <author> Mayerson, R. B. </author> <year> 1988. </year> <title> Incentive constraints and optimal communication systems. </title> <booktitle> In Proceedings of the Second Conference on Theoretical Aspects of Reasoning about Knowledge, </booktitle> <pages> 179-193. </pages> <editor> Mertens, and Zamir. </editor> <year> 1985. </year> <title> Formulation of bayesian analysis for games with incomplete information. </title> <journal> International Journal of Game Theory 14 </journal> <pages> 1-29. </pages>
Reference: <author> Narayanan, A. </author> <year> 1988. </year> <title> On Being a Machine. </title> <publisher> Ellis Horwood. </publisher>
Reference-contexts: Closely related is the concept of practical rationality in (Pollock 1989). Our approach also follows Dennett's formulation of the intentional stance (Den-nett 1986), and his idea of the ladder of agenthood (see <ref> (Narayanan 1988) </ref> for a succinct discussion), the first five levels of which we see as actually embodied in RMM. Cohen and Levesque (Cohen & Levesque 1990a) formalize intention and commitment, and apply it to issues of communication (Cohen & Levesque 1990b).
Reference: <author> Neapolitan, R. E. </author> <year> 1990. </year> <title> Probabilistic Reasoning in Expert Systems. </title> <publisher> John Wiley and Sons. </publisher>
Reference-contexts: The uniform probability distribution of the No-Information model contains no information <ref> (Neapolitan 1990) </ref> and thus precisely represents R i 's lack of knowledge in this case. The Sub-Intentional model corresponds to treating the agent as not being rational.
Reference: <author> Newell, A. </author> <year> 1981. </year> <title> The knowledge level. </title> <journal> AI Magazine 2(2) </journal> <pages> 1-20. </pages>
Reference-contexts: Our method, remaining true to artificial intelligence's knowledge-level perspective <ref> (Newell 1981) </ref>, postulates that a rational agent should apply all of its relevant knowledge to further its current goals. In recent game-theoretic literature (Aumann & Branden-burger 1994; Brandenburger 1992), this approach is also advocated, and called the decision-theoretic approach to game theory.
Reference: <author> Parikh, P. </author> <year> 1992. </year> <title> A game-theoretic account of implicature. </title> <booktitle> In Proceedings of the Conference on Theoretical Aspects of Reasoning about Knowladge, </booktitle> <pages> 85-93. </pages> <publisher> Morgan Kaufman. </publisher>
Reference-contexts: An approach to communication similar to ours, although more qualitative, is presented in (May-erson 1988). In a very similar spirit, Parikh gives an interesting utility-based approach to disambiguating certain kinds of implicatures <ref> (Parikh 1992) </ref>.
Reference: <author> Perrault, C. R. </author> <year> 1990. </year> <title> An application of default logic to speech act theory. </title> <editor> In Cohen, P. R.; Morgan, J.; and Pollack, M. E., eds., </editor> <title> Intentions in Communication. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Cohen and Levesque (Cohen & Levesque 1990a) formalize intention and commitment, and apply it to issues of communication (Cohen & Levesque 1990b). These authors, as well as Perrault in <ref> (Perrault 1990) </ref>, analyze the nestedness of beliefs so important in issues of communication, but rely on a notion of common belief, the justifiability of which (as with common knowledge) we find problematic (see also (Bic-chieri 1993) for related discussion).
Reference: <author> Pollock, J. L. </author> <year> 1989. </year> <title> How to Build a Person: A Prole-gomenon. </title> <publisher> MIT Press. </publisher>
Reference-contexts: Due to space limitations, we selectively mention the most germane publications. Horvitz's and Russell's work (Horvitz, Cooper, & Heckerman 1989; Russell & Wefald 1991) is concentrated on reasoning rationally under time pressure. Closely related is the concept of practical rationality in <ref> (Pollock 1989) </ref>. Our approach also follows Dennett's formulation of the intentional stance (Den-nett 1986), and his idea of the ladder of agenthood (see (Narayanan 1988) for a succinct discussion), the first five levels of which we see as actually embodied in RMM.
Reference: <author> Rasmusen, E. </author> <year> 1989. </year> <title> Games and Information. </title> <publisher> B. Blackwel. </publisher>
Reference: <author> Reny, P. J. </author> <year> 1988. </year> <title> Extensive games and common knowledge. </title> <booktitle> In Proceedings of the Conference on Theoretical Aspects of Reasoning about Knowladge, </booktitle> <volume> 395. </volume> <publisher> Morgan Kauf-man. </publisher>
Reference: <author> Rosenschein, J. S., and Breese, J. S. </author> <year> 1989. </year> <title> Communication-free interactions among rational agents: A probablistic approach. </title> <editor> In Gasser, L., and Huhns, M. N., eds., </editor> <booktitle> Distributed Artificial Intelligence, volume 2 of Research Notes in Artificial Intelligence. </booktitle> <publisher> Pitman. </publisher> <pages> 99-118. </pages>
Reference: <author> Rosenschein, J. S., and Genesereth, M. R. </author> <year> 1985. </year> <title> Deals among rational agents. </title> <booktitle> In Proceedings of the Ninth International Joint Conference on Artificial Intelligence, </booktitle> <pages> 91-99. </pages> <note> (Also published in Readings in Distributed Artificial Intelligence, </note> <editor> Alan H. Bond and Les Gasser, editors, </editor> <address> pages 227-234, </address> <publisher> Morgan Kaufmann, 1988.). </publisher>
Reference: <author> Russell, S., and Wefald, E. </author> <year> 1991. </year> <booktitle> Principles of metarea-soning. Artificial Intelligence 49 </booktitle> <pages> 361-395. </pages>
Reference: <author> Shoham, Y. </author> <year> 1993. </year> <title> Agent-oriented programming. </title> <booktitle> Artificial Intelligence 60(1) </booktitle> <pages> 51-92. </pages>
Reference-contexts: Shoham's agent-oriented programming (AOP) <ref> (Shoham 1993) </ref> takes more of a programming-language perspective. However, while Shoham has proposed it as an extension, decision-theoretic rationality has not yet been included in AOP.
Reference: <author> Tan, T. C., and Werlang, S. R. </author> <year> 1988. </year> <title> A guide to knowledge and games. </title> <booktitle> In Proceedings of the Second Conference on Theoretical Aspects of Reasoning about Knowledge. </booktitle>
Reference: <author> Wellman, M. P. </author> <year> 1991. </year> <title> The preferential semantics for goals. </title> <booktitle> In AAAI91, </booktitle> <pages> 698-703. </pages>
Reference-contexts: Intuitively, any purposeful agent has reason to prefer some actions (that further its purposes in the current situation) to others <ref> (Wellman 1991) </ref>. Our ability to represent agents' preferences over actions as payoffs follows directly from the axioms of utility theory, which postulate that ordinal preferences among actions in the current situation can be represented as cardinal, numeric values (Chernoff & Moses 1959; Doyle 1992).
Reference: <author> Zlotkin, G., and Rosenschein, J. S. </author> <year> 1989. </year> <title> Negotiation and task sharing among autonomous agents in cooperative domains. </title> <booktitle> In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <pages> 912-917. </pages>
Reference: <author> Zlotkin, G., and Rosenschein, J. S. </author> <year> 1990a. </year> <title> Blocks, lies, and postal freight: Nature of deception in negotiation. </title> <booktitle> In Proceedings of the 1990 Distributed AI Workshop. </booktitle>
Reference: <author> Zlotkin, G., and Rosenschein, J. S. </author> <year> 1990b. </year> <title> Negotiation and conflict resolution in non-cooperative domains. </title> <booktitle> In Proceedings of the National Conference on Artificial Intelligence, </booktitle> <pages> 100-105. </pages>
References-found: 43

