URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/Preprints/pub16.ps.gz
Refering-URL: http://www.cs.yale.edu/HTML/YALE/CS/HyPlans/douglas-craig/ccd-preprints.html
Root-URL: http://www.cs.yale.edu
Title: USING SYMMETRIES AND ANTISYMMETRIES TO ANALYZE A PARALLEL MULTIGRID ALGORITHM: THE ELLIPTIC BOUNDARY VALUE PROBLEM CASE  
Author: CRAIG C. DOUGLAS AND BARRY F. SMITH 
Keyword: Key words. partial differential equations, parallel multigrid, robust multigrid solver, domain decomposition, direct method, iterative method, convergence rates  
Note: AMS(MOS) subject classifications. 65W05, 65N15, 65N10  
Abstract: This paper is dedicated to Jim Douglas, Jr. on the occasion of his 60th birthday. Abstract. Symmetry and antisymmetry properties of a class of elliptic partial differential equations are exploited to prove when a particular parallel multilevel algorithm is a direct method rather than the usual iterative method. No smoothing is required for this result. Examples are presented, including variable coefficient ones. A connection between the algorithm in this article and domain decomposition is established, even though this algorithm is more general and different. The parallel algorithm is also analyzed when it is iterative and it is shown how to increase processor utilization. Hackbusch's robust multigrid algorithm is analyzed for some model problems and it is shown that the parallel algorithm in this article uses much less computer time with at most the same amount of storage. 1. The problem. In this paper, we approximate the solution to the elliptic 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> R. E. Alcouffe, A. Brandt, J. J. E. Dendy, and J. W. Painter, </author> <title> The multi-grid methods for the diffusion equation with strongly discontinuous coefficients, </title> <journal> SIAM J. Sci. Stat. Comp., </journal> <volume> 2 (1981), </volume> <pages> pp. 430-454. </pages>
Reference-contexts: We note that there are nonstandard multigrid methods that solve this problem (see <ref> [1] </ref> and [18]). In two dimensions, when s = 0 and a 1 = a 2 = 1, the subproblems are each block tridiagonal. When N is divisible by four, the block structures are V T 2 6 6 6 4 I T I . . . <p> When N is divisible by four, the block structures are V T 2 6 6 6 4 I T I . . . I S 7 7 7 7 ; where Q = <ref> [1; 4; 1] </ref> is the usual center block for the discretization of the original problem, S = T I , and T = Q 6 6 0 0 0 . . . 0 0 1 7 7 : The choice of signs in the definitions of S and T is given <p> We begin by re-investigating the model domain of x3.1.1 applied to the problem u (0) = u (1) = 0: Using a uniform mesh and either central differences or C 0 piecewise linear basis functions leads to a tridiagonal coefficient matrix A of the form A 1 = <ref> [ 1; 2; 1 ] </ref>:(4.2) We define a new set of restriction operators fT 0 ; T 1 g and fT 2 ; T 3 g.
Reference: [2] <author> R. E. Bank and C. C. Douglas, </author> <title> An efficient implementation of the SSOR and ILU preconditionings, </title> <journal> Appl. Numer. Math., </journal> <volume> 1 (1985), </volume> <pages> pp. </pages> <month> 489-492. </month> <title> [3] , Sharp estimates for multigrid rates of convergence with general smoothing and acceleration, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 22 (1985), </volume> <pages> pp. 617-633. </pages>
Reference-contexts: We begin by re-investigating the model domain of x3.1.1 applied to the problem u (0) = u (1) = 0: Using a uniform mesh and either central differences or C 0 piecewise linear basis functions leads to a tridiagonal coefficient matrix A of the form A 1 = <ref> [ 1; 2; 1 ] </ref>:(4.2) We define a new set of restriction operators fT 0 ; T 1 g and fT 2 ; T 3 g. <p> Many smoothers compute the residual as part of their algorithm (see <ref> [2] </ref>), in which case, C 1 = 0 whenever m &gt; 0. The value of depends on the solution method on level 1. If a band solver on a single processor is used, then = 1 for one-dimensional problems, and = 2 for two-dimensional problems.
Reference: [4] <author> A. Brandt and S. Ta'asan, </author> <title> Multigrid method for nearly singular and slightly indefinite problems, in Multigrid Methods II, </title> <editor> W. Hackbusch and U. Trottenberg, eds., </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1986, </year> <pages> pp. 100-121. 22 </pages>
Reference-contexts: In these papers, no attempt was made to use properties of the underlying problems; only abstract knowledge was used. Our parallel multilevel algorithms are not the only such algorithms. Brandt and Ta'asan <ref> [4] </ref>, Frederickson and McBryan [15], and Hackbusch [16] have recently proposed special cases of our algorithms. The difference is that we consider the construction of the subspaces as a variable part of the parallel algorithm, whereas they provide specific, but different rules, for the construction. <p> When N is divisible by four, the block structures are V T 2 6 6 6 4 I T I . . . I S 7 7 7 7 ; where Q = <ref> [1; 4; 1] </ref> is the usual center block for the discretization of the original problem, S = T I , and T = Q 6 6 0 0 0 . . . 0 0 1 7 7 : The choice of signs in the definitions of S and T is given
Reference: [5] <author> F. Brezzi, C. C. Douglas, and L. D. Marini, </author> <title> A parallel domain reduction method, Numer. Meth. for PDE, </title> <booktitle> 5 (1989), </booktitle> <pages> pp. 195-202. </pages>
Reference-contexts: The reader should be aware that significant extensions to the theory of x3 have occurred since this paper was written. In <ref> [5] </ref>, the two-dimensional example on a square (see Fig. 2) is solved using an eight-way technique. This is extended in [11] to a three-dimensional problem on a cube that is solved using 8, 60, and 64-way techniques.
Reference: [6] <author> H. C. Chen, </author> <title> The SAS domain decomposition method for structural analysis, </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, Urbana, Illinois, </institution> <year> 1988. </year>
Reference-contexts: Further, constructing a more parallel method that is iterative is simple and computationally attractive (both in time and storage). Acknowledgments. Since writing this paper, we have become aware that a different interpretation of the analysis of x3 was done independently by Chen, Kamath, and Sameh (see <ref> [6] </ref>, [7], and [17]). The reader should be aware that significant extensions to the theory of x3 have occurred since this paper was written. In [5], the two-dimensional example on a square (see Fig. 2) is solved using an eight-way technique.
Reference: [7] <author> H. C. Chen and A. H. Sameh, </author> <title> A matrix decomposition method for orthotropic elasticity problems, </title> <journal> SIAM J. Matrix Anal. Appl., </journal> <volume> 10 (1989), </volume> <pages> pp. 39-64. </pages>
Reference-contexts: Further, constructing a more parallel method that is iterative is simple and computationally attractive (both in time and storage). Acknowledgments. Since writing this paper, we have become aware that a different interpretation of the analysis of x3 was done independently by Chen, Kamath, and Sameh (see [6], <ref> [7] </ref>, and [17]). The reader should be aware that significant extensions to the theory of x3 have occurred since this paper was written. In [5], the two-dimensional example on a square (see Fig. 2) is solved using an eight-way technique.
Reference: [8] <author> C. C. Douglas, </author> <title> Multi-grid algorithms for elliptic boundary-value problems, </title> <type> PhD thesis, </type> <institution> Yale University, </institution> <month> May </month> <year> 1982. </year> <note> Also, </note> <institution> Computer Science Department, Yale University, </institution> <type> Technical Report 223. </type> <note> [9] , Multi-grid algorithms with applications to elliptic boundary-value problems, SIAM J. Numer. Anal., </note> <month> 21 </month> <year> (1984), </year> <pages> pp. 236-254. </pages>
Reference-contexts: Using a trick from <ref> [8] </ref> and [9], we can imbed each of T 0 , T 1 , T 2 , and T 3 in an N fi N matrix in which every other row is made up of zeros. <p> 0 0 0 0 0 0 0 3 7 7 7 7 7 5 2 IR NfiN : It is worth noting that ( T 0 ( T 0 A 1 T 0 ) + T 0 ) = (T 0 (T 0 A 1 T T 0 ) (see <ref> [8] </ref>).
Reference: [10] <author> C. C. Douglas, S. C. Ma, and W. L. Miranker, </author> <title> Generating parallel algorithms through multi-grid and aggregation/disaggregation techniques, in Computational Acoustics: Algorithms and Applications, </title> <editor> D. Lee, R. L. Sternberg, and M. H. Schultz, eds., </editor> <publisher> Elsevier, North-Holland, </publisher> <year> 1987, </year> <pages> pp. 133-147. </pages>
Reference-contexts: As a result, our algorithm can solve certain types of problems very well for which standard multigrid algorithms are not useful. This paper is a continuation of a series of papers <ref> [10] </ref>, [12], and [13]. In [12], we defined parallel algorithms based on serial multigrid and aggregation/disaggregation techniques. We analyzed them in a very abstract manner. In [10], we analyzed algorithms based on the nested iteration variant of multigrid and aggregation/disaggregation. <p> This paper is a continuation of a series of papers <ref> [10] </ref>, [12], and [13]. In [12], we defined parallel algorithms based on serial multigrid and aggregation/disaggregation techniques. We analyzed them in a very abstract manner. In [10], we analyzed algorithms based on the nested iteration variant of multigrid and aggregation/disaggregation. In [13], we explored how these algorithms would perform on different classes of parallel processors: coarse grained machines with either shared or local memory, as well as fine grained machines with local memories. <p> In fact, each of the steps may be viewed as a candidate for parallel processing on many processors. See <ref> [10] </ref> for more details. We allow general smoothers B : M ! M. Let ^w 2 M be defined by B ( ^w w) = f Lw:(2.5) The operator B must be simple in comparison to L to make (2.5) computationally attractive.
Reference: [11] <author> C. C. Douglas and J. Mandel, </author> <title> The domain reduction method: high way reduction in three dimensions and convergence with inexact solvers, </title> <booktitle> in Fourth Copper Mountain conference on multigrid methods, </booktitle> <editor> J. Mandel and S. F. McCormick, eds., </editor> <booktitle> Society for Industrial and Applied Mathematics, </booktitle> <address> Philadelphia, </address> <year> 1989. </year> <note> To appear. </note>
Reference-contexts: The reader should be aware that significant extensions to the theory of x3 have occurred since this paper was written. In [5], the two-dimensional example on a square (see Fig. 2) is solved using an eight-way technique. This is extended in <ref> [11] </ref> to a three-dimensional problem on a cube that is solved using 8, 60, and 64-way techniques. Finally, in [11], the analysis of this paper is extended to the case when the subproblems are solved inexactly (i.e., using iterative methods) and when the subspaces are not orthogonal. <p> In [5], the two-dimensional example on a square (see Fig. 2) is solved using an eight-way technique. This is extended in <ref> [11] </ref> to a three-dimensional problem on a cube that is solved using 8, 60, and 64-way techniques. Finally, in [11], the analysis of this paper is extended to the case when the subproblems are solved inexactly (i.e., using iterative methods) and when the subspaces are not orthogonal.
Reference: [12] <author> C. C. Douglas and W. L. Miranker, </author> <title> Constructive interference in parallel algorithms, </title> <journal> SIAM J. Numer. Anal., </journal> <volume> 25 (1988), </volume> <pages> pp. </pages> <month> 376-398. </month> <title> [13] , Some nontelescoping parallel algorithms based on serial multigrid/aggregation/dis-aggregation techniques, in Multigrid Methods: Theory, Applications, and Supercomputing, </title> <editor> S. F. McCormick, ed., </editor> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1988, </year> <pages> pp. 167-176. </pages>
Reference-contexts: As a result, our algorithm can solve certain types of problems very well for which standard multigrid algorithms are not useful. This paper is a continuation of a series of papers [10], <ref> [12] </ref>, and [13]. In [12], we defined parallel algorithms based on serial multigrid and aggregation/disaggregation techniques. We analyzed them in a very abstract manner. In [10], we analyzed algorithms based on the nested iteration variant of multigrid and aggregation/disaggregation. <p> As a result, our algorithm can solve certain types of problems very well for which standard multigrid algorithms are not useful. This paper is a continuation of a series of papers [10], <ref> [12] </ref>, and [13]. In [12], we defined parallel algorithms based on serial multigrid and aggregation/disaggregation techniques. We analyzed them in a very abstract manner. In [10], we analyzed algorithms based on the nested iteration variant of multigrid and aggregation/disaggregation. <p> Motivation in one dimension (see [3]). The error propagation operator C for the correction process is simply C = I j=1 j R j L (see <ref> [12] </ref>). When A and B are symmetric, positive definite, the energy norms, jjj jjj, of S and C are and d X P j A 1 where k k is the L 2 norm.
Reference: [14] <author> H. Foerster, K. Stuben, and U. Trottenberg, </author> <title> Non-standard multigrid techniques using checkered relaxation and intermediate grids, in Elliptic Problem Solvers, </title> <editor> M. H. Schultz, ed., </editor> <publisher> Academic Press, </publisher> <address> New York, </address> <year> 1981, </year> <pages> pp. 285-300. </pages>
Reference-contexts: We also exploit the composition of two classes of restriction operators to produce many smaller problems to solve. This is similar to the total reduction method variant of standard multigrid <ref> [14] </ref>. By using more, smaller problems, we speed up our parallel algorithm noticeably. In x5, we attempt to compare the running time of various flavors of the parallel multigrid algorithm. We do this using operation counts. We use two measures: total operation counts and wall clock time. <p> We analyze Hackbusch's robust multigrid algorithm [16] for some model problems. We also exploit the composition of two classes of restriction operators to produce many smaller problems to solve. This is similar to the total reduction method variant of standard multigrid <ref> [14] </ref>. By using more, smaller problems, we speed up Algorithm PMG considerably. 4.1. One dimensional problems.
Reference: [15] <author> P. Frederickson and O. McBryan, </author> <title> Parallel superconvergent multigrid, in Multigrid Methods: Theory, Applications, and Supercomputing, </title> <editor> S. F. McCormick, ed., </editor> <publisher> Marcel Dekker, </publisher> <address> New York, </address> <year> 1988, </year> <pages> pp. 195-210. </pages>
Reference-contexts: In these papers, no attempt was made to use properties of the underlying problems; only abstract knowledge was used. Our parallel multilevel algorithms are not the only such algorithms. Brandt and Ta'asan [4], Frederickson and McBryan <ref> [15] </ref>, and Hackbusch [16] have recently proposed special cases of our algorithms. The difference is that we consider the construction of the subspaces as a variable part of the parallel algorithm, whereas they provide specific, but different rules, for the construction.
Reference: [16] <author> W. Hackbusch, </author> <title> A new approach to robust multi-grid solvers, </title> <booktitle> in ICIAM'87: Proceedings of the First International Conference on Industrial and Applied Mathematics, Society for Industrial and Applied Mathematics, </booktitle> <address> Philadelphia, </address> <year> 1988, </year> <pages> pp. 114-126. </pages>
Reference-contexts: In these papers, no attempt was made to use properties of the underlying problems; only abstract knowledge was used. Our parallel multilevel algorithms are not the only such algorithms. Brandt and Ta'asan [4], Frederickson and McBryan [15], and Hackbusch <ref> [16] </ref> have recently proposed special cases of our algorithms. The difference is that we consider the construction of the subspaces as a variable part of the parallel algorithm, whereas they provide specific, but different rules, for the construction. In x2, we define the parallel multigrid algorithm and its auxiliary components. <p> For example, in two dimensions, if s = 1, a 1 = 10 5 , and a 2 = 10 5 , a standard multigrid algorithm with one Jacobi smoothing iteration has a contraction factor of .97 compared to zero for Algorithm PMG (see <ref> [16] </ref>). We note that there are nonstandard multigrid methods that solve this problem (see [1] and [18]). In two dimensions, when s = 0 and a 1 = a 2 = 1, the subproblems are each block tridiagonal. <p> Using a central difference discretization can result in a nonsymmetric matrix, which is not a problem. 4. An iterative method. In this section, we determine upper bounds on the convergence rates for Algorithm PMG when it is an iterative method. We analyze Hackbusch's robust multigrid algorithm <ref> [16] </ref> for some model problems. We also exploit the composition of two classes of restriction operators to produce many smaller problems to solve. This is similar to the total reduction method variant of standard multigrid [14]. By using more, smaller problems, we speed up Algorithm PMG considerably. 4.1.
Reference: [17] <author> C. Kamath and A. H. Sameh, </author> <title> A projection method for solving nonsymmetric linear systems on multiprocessors, </title> <booktitle> Parallel Comp., 9 (1989), </booktitle> <pages> pp. 291-312. </pages>
Reference-contexts: Further, constructing a more parallel method that is iterative is simple and computationally attractive (both in time and storage). Acknowledgments. Since writing this paper, we have become aware that a different interpretation of the analysis of x3 was done independently by Chen, Kamath, and Sameh (see [6], [7], and <ref> [17] </ref>). The reader should be aware that significant extensions to the theory of x3 have occurred since this paper was written. In [5], the two-dimensional example on a square (see Fig. 2) is solved using an eight-way technique.
Reference: [18] <author> J. W. Ruge and K. St uben, </author> <title> Algebraic multigrid, </title> <booktitle> in SIAM Frontiers on Applied Mathematics, Volume 3, Multigrid Methods, </booktitle> <editor> S. F. McCormick, ed., </editor> <publisher> SIAM, </publisher> <year> 1987, </year> <pages> pp. 73-130. </pages>
Reference-contexts: We note that there are nonstandard multigrid methods that solve this problem (see [1] and <ref> [18] </ref>). In two dimensions, when s = 0 and a 1 = a 2 = 1, the subproblems are each block tridiagonal. When N is divisible by four, the block structures are V T 2 6 6 6 4 I T I . . .
Reference: [19] <author> R. S. Varga, </author> <title> Matrix Iterative Analysis, </title> <publisher> Prentice-Hall, </publisher> <address> New York, </address> <year> 1962. </year> <month> 23 </month>
Reference-contexts: When = 1, we use a uniform mesh with N interior points. When &gt; 1, we use a tensor product mesh with N interior points. We discretize by central differences to obtain standard matrices A (see <ref> [19] </ref>).
References-found: 16

