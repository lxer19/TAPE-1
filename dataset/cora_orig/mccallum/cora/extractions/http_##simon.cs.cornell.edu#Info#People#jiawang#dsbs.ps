URL: http://simon.cs.cornell.edu/Info/People/jiawang/dsbs.ps
Refering-URL: http://simon.cs.cornell.edu/Info/People/jiawang/my_research.html
Root-URL: 
Title: DETECTING STATIC OBJECTS IN BUSY SCENES  
Author: Jia Wang and Wei-Tsang Ooi 
Address: Ithaca, NY 14853-7501, USA  
Affiliation: Department of Computer Science, Cornell University,  
Abstract: Detecting static objects in scenes containing significant number of moving objects has several applications in video surveillance. One example is the detection of suspicious packages which is left unattended in an airport terminal or railway station. This paper outlines an approach to automatically detect static objects from a video sequence of a busy scene. Our approach consists of two phase : foreground object extraction and object matching. In the first phase, we find the foreground objects in current video frame, using an image of a background as reference. In the object matching phase, we try to match the objects with objects that appears before in previous frames. Matching is done based on three parameter : shape and position, intensity and edge. Temporary occluded of objects is also handled. We built a system based on our approach. Preliminary experiments shows that our system are able to identify static objects in a busy scene in real time. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Dana H. Ballard and C. M. Brown, </author> <title> Computer Vision, </title> <publisher> Prentice Hall, </publisher> <year> 1982. </year>
Reference-contexts: To extract the foreground objects from the current frames, we first find the difference image between current frame and the background image by subtracting current frame from the background and then take the threshold value. The resulting image is then smoothed by applying morphology operation open and close <ref> [1, 5, 7] </ref>. The result is a bitmap with "blobs" of objects. We then find the connected components of the blobs, which is represented as a list of bounding boxes. Each bounding box represents some foreground ob jects in the scene.
Reference: [2] <author> Patrick Bouthemy and E. Francois, </author> <title> Motion Segmentation and Qualitative Dynamic Scene Analysis from an Image Sequence, </title> <journal> International Journal of Computer Vision (1993) 10:2, p157-182. </journal>
Reference: [3] <author> Jonathan D. </author> <title> Courtney, Automatic Video Indexing via Object Motion Analysis. </title>
Reference: [4] <author> D. Gibbins, G. N. Newsam and M. J. Brooks, </author> <title> Detecting Suspicious Background Changes in Video Surveillance of Busy Scenes. </title>
Reference: [5] <author> Rafael C. Gonzalez and R. E. Woods, </author> <title> Digital Image Processing, </title> <publisher> Addison-Wesley, </publisher> <year> 1992. </year>
Reference-contexts: To extract the foreground objects from the current frames, we first find the difference image between current frame and the background image by subtracting current frame from the background and then take the threshold value. The resulting image is then smoothed by applying morphology operation open and close <ref> [1, 5, 7] </ref>. The result is a bitmap with "blobs" of objects. We then find the connected components of the blobs, which is represented as a list of bounding boxes. Each bounding box represents some foreground ob jects in the scene.
Reference: [6] <author> Daniel P. Huttenlocher and W. J. Rucklidge, </author> <title> A Multi-Resolution Technique for Comparing Images Using the Hausdorff Distance. </title>
Reference-contexts: count the percentage of black pixels in the intersection. (2) similarity of intensity : computed by finding the sum of square differences in intensities of two objects. (3) similarity in edges : computed by first detecting the edge of the objects and then perform Hausdorff matching on the two images <ref> [6] </ref>. We say two objects match well if they perform excellently in these similarity tests. To detect static objects, each objects in the system has 2 attributes : age and type. age records the number of frames the object hasn't move. type represents the status of the objects.
Reference: [7] <author> Robert M. Haralick and L. G. Shapiro, </author> <title> Computer and Robert Vision, Volume II, </title> <publisher> Addison-Wesley, </publisher> <year> 1993. </year>
Reference-contexts: To extract the foreground objects from the current frames, we first find the difference image between current frame and the background image by subtracting current frame from the background and then take the threshold value. The resulting image is then smoothed by applying morphology operation open and close <ref> [1, 5, 7] </ref>. The result is a bitmap with "blobs" of objects. We then find the connected components of the blobs, which is represented as a list of bounding boxes. Each bounding box represents some foreground ob jects in the scene.
Reference: [8] <author> Amar Mitiche and P. Boutheny, </author> <title> Computation and Analysis of Image Motion: A Synopsis of Current Problems and Methods, </title> <booktitle> International Journal of Computer Vision (1996) 19(1), </booktitle> <address> p29-55. </address>
Reference: [9] <author> J. Serra, </author> <title> Image Analysis and Mathematical Morphology, </title> <publisher> Academic Press, </publisher> <year> 1982. </year>
Reference: [10] <author> Yuan-Liang Tang, and R. Kasturi, </author> <title> Tracking Moving Objects During Low Altitude Flight, </title> <booktitle> Machine Vision and Applications (1996) 9: </booktitle> <address> p20-31. </address>
Reference: [11] <author> Tina Yu Tian and M. Shah, </author> <title> Motion Estimation and Segmentation, </title> <booktitle> Machine Vision and Applications (1996) 9: </booktitle> <address> p32-42. </address>
References-found: 11

