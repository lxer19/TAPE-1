URL: http://www.cs.purdue.edu/research/PaCS/ps/icpp.ps
Refering-URL: http://www.cs.purdue.edu/research/PaCS/eclipse.html
Root-URL: http://www.cs.purdue.edu
Email: fknop,regog@cs.purdue.edu fvss,ferrarig@mathcs.emory.edu  
Title: FAILURE-RESILIENT COMPUTATIONS IN THE EcliPSe SYSTEM  
Author: Felipe Knop and Vernon Rego Vaidy Sunderam and Adam Ferrari 
Address: West Lafayette, Indiana 47907 Atlanta, Georgia 30322  
Affiliation: Department of Computer Sciences Department of Math and Computer Science Purdue University Emory University  
Abstract: Local or wide-area connected workstation cluster-based computation systems are inherently failure-prone, particularly for long running computations. In this work we introduce a variety of features for failure resilience in the EcliPSe system for replicative applications. Key characteristics of fault-tolerant EcliPSe are ease of use, low state-saving costs, system scalability and good performance. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> K.M. Chandy and L. Lamport. </author> <title> Distributed snapshots: Determining global states of distributed systems. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 3(1) </volume> <pages> 63-75, </pages> <month> February </month> <year> 1985. </year>
Reference-contexts: Despite significant attention in past years, fault-tolerant distributed systems are difficult to design and understand. Cristian [2] presents an overview of the subject. A particularly difficult task is the saving of distributed system state. This problem was described in [11], initially solved in <ref> [1] </ref>, and later addressed by a number of authors ([7, 10, 3], to mention a few). The diversity of papers stems partly from the different failure semantics [2] and architectures of distinct systems.
Reference: [2] <author> F. </author> <title> Cristian.Understanding fault-tolerant distributed systems. </title> <journal> Communications of the ACM, </journal> <volume> 34(2) </volume> <pages> 56-78, </pages> <month> February </month> <year> 1991. </year>
Reference-contexts: Our interest is in the design of transparent failure recovery procedures for hardware failures, or in the reporting of distributed software failures to cluster-computation users. Despite significant attention in past years, fault-tolerant distributed systems are difficult to design and understand. Cristian <ref> [2] </ref> presents an overview of the subject. A particularly difficult task is the saving of distributed system state. This problem was described in [11], initially solved in [1], and later addressed by a number of authors ([7, 10, 3], to mention a few). <p> A particularly difficult task is the saving of distributed system state. This problem was described in [11], initially solved in [1], and later addressed by a number of authors ([7, 10, 3], to mention a few). The diversity of papers stems partly from the different failure semantics <ref> [2] </ref> and architectures of distinct systems. A more thorough description of the related fl Research supported in part by NATO-CRG900108,NSF CCR-9102331, ONR-9310233, and ARO-93G0045. y Research supported by CNPq-Brazil process number 260059/91.9. work is presented in [6].
Reference: [3] <author> E.N. Elnozahy, D.B. Johnson, and W. Zwaenepoel. </author> <title> The performance of consistent checkpointing. </title> <booktitle> In IEEE 11th Symposium on Reliable Distributed Systems, </booktitle> <pages> pages 39-47, </pages> <year> 1992. </year>
Reference: [4] <author> G. Fox. </author> <title> Parallel computing comes of age: supercomputer level parallel computations at caltech. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 1 </volume> <pages> 63-103, </pages> <year> 1989. </year>
Reference-contexts: The toolkit is primarily geared towards replicative applications, namely those where a computation is replicated on distinct processors, and application-based interprocess communication is minimal. Typical examples include very general simulations (e.g., parallel discrete-event, stochastic or numerical) [12], or coarse-grained data-parallel computations (e.g., domain decomposition) <ref> [4] </ref>.
Reference: [5] <author> F. Knop, V. Rego, and V. Sunderam. </author> <title> EcliPSe: </title> <booktitle> A system for fault-tolerant replicative computations.In Proceedings of the IEEE/USP International Symposium on High-Performance Computing, </booktitle> <month> March </month> <year> 1994. </year>
Reference-contexts: The features we describe for fault-tolerance are embedded in EcliPSe <ref> [9, 12, 13, 5] </ref>, a toolkit for heterogeneous cluster computing. The toolkit is primarily geared towards replicative applications, namely those where a computation is replicated on distinct processors, and application-based interprocess communication is minimal. <p> EcliPSe provides a set of control mechanisms that prevent such serializing bottlenecks and network clogs from occurring. These include granularity control, multiple monitors, tree-combining, and data diffusing (explained in <ref> [5] </ref>). 3 BASIC FEATURES We have attempted to address most of the typical problems that occur during execution of a large-scale application and incorporated our solutions in the EcliPSe toolkit. Recovery is attempted whenever it is meaningful. The following is a list of problems detected, with corresponding actions. 1.
Reference: [6] <author> F. Knop, V. Rego, and V. Sunderam. </author> <title> Failure-resilient computations in the eclipse system. </title> <type> Technical report, </type> <institution> Purdue University, </institution> <year> 1994. </year>
Reference-contexts: The diversity of papers stems partly from the different failure semantics [2] and architectures of distinct systems. A more thorough description of the related fl Research supported in part by NATO-CRG900108,NSF CCR-9102331, ONR-9310233, and ARO-93G0045. y Research supported by CNPq-Brazil process number 260059/91.9. work is presented in <ref> [6] </ref>. A typical scheme for obtaining some level of fault-tolerance in a cluster-based software system involves the periodic saving of data during an application's execution (i.e. checkpointing) on a local disk. <p> A hard problem to tackle in the general case, detection of infinite loops is performed using some user-guided heuristics. Upon detection of such a situation, appropriate user action is taken, with the default being simply a warning message. Details are given in <ref> [6] </ref>. This section describes user-visible aspects of fault tolerance in EcliPSe, primarily focused on item (1) above. <p> See <ref> [6] </ref> for a description of how this is accomplished. <p> Moreover, message sequence numbers are used to allow the discarding of old messages that were in transit when the process failure occurred. In this manner we guarantee that the system is restored to a consistent state should a failure occur. Details are presented in <ref> [6] </ref>. 4.2 Application shutdown Some situations like network partitions may force a large fraction of EcliPSe engines to be unavailable. <p> More experiments with real-world applications are required, however, to assess the effectiveness of the approach described in this paper for decreasing checkpoint overhead. Lack of space prevents us from describing some relevant implementation details and some initial performance measurements. These are presented in <ref> [6] </ref>.
Reference: [7] <author> R. Koo and S. Toueg. </author> <title> Checkpointing and rollback-recovery for distributed systems. </title> <journal> IEEE Transactions on Software Engineering, </journal> <volume> SE-13(1):23-31, </volume> <month> January </month> <year> 1987. </year>
Reference: [8] <author> J. Leon, A.L. Fisher, and P. Steenkiste. </author> <title> Fail-safe PVM: a portable package for distributed programming with transparent recovery. </title> <type> Technical Report CMU-CS-93-124, </type> <institution> School of Computer Science, Carnegie Mellon University, </institution> <month> February </month> <year> 1993. </year>
Reference-contexts: An alternative to such application-dependent fault tolerance is application-independent fault tolerance, implemented at the message passing level. Used by Fail-safe PVM <ref> [8] </ref>, which adds fault tolerance to the PVM library [14], this approach has the obvious advantage of not requiring changes to the application code.
Reference: [9] <author> H. Nakanishi, V. Rego, and V. Sunderam. </author> <title> Superconcurrent simulation of polymer chains on heterogeneous networks. 1992 Gordon Bell Prize Paper, </title> <booktitle> Proceedings of the Fifth High-Performance Computing and Communications Conference: Supercomputing '92, </booktitle> <month> November </month> <year> 1992. </year>
Reference-contexts: The features we describe for fault-tolerance are embedded in EcliPSe <ref> [9, 12, 13, 5] </ref>, a toolkit for heterogeneous cluster computing. The toolkit is primarily geared towards replicative applications, namely those where a computation is replicated on distinct processors, and application-based interprocess communication is minimal.
Reference: [10] <author> M.L. Powell and D.L. Presotto. </author> <title> PUBLISHING: A reliable broadcast communication mechanism. </title> <journal> Operating Systems Review, </journal> <volume> 17(5) </volume> <pages> 100-109, </pages> <year> 1983. </year>
Reference-contexts: A recovered system state is defined to be consistent if such a state existed prior to a system failure. processes produce an array of 10 double precision numbers for the monitor. The declaration of this data item is done as follows: eclipse_decls - double type_result <ref> [10] </ref>; - The eclipse decls block defines the region the preprocessor must act on.
Reference: [11] <author> B. Randell. </author> <title> System structure for software fault-tolerance. </title> <journal> IEEE Transactionson Software Engineering, </journal> <volume> SE-1(2), </volume> <year> 1975. </year>
Reference-contexts: Despite significant attention in past years, fault-tolerant distributed systems are difficult to design and understand. Cristian [2] presents an overview of the subject. A particularly difficult task is the saving of distributed system state. This problem was described in <ref> [11] </ref>, initially solved in [1], and later addressed by a number of authors ([7, 10, 3], to mention a few). The diversity of papers stems partly from the different failure semantics [2] and architectures of distinct systems.
Reference: [12] <author> V. J. Rego and V. S. Sunderam. </author> <title> Experiments in Concurrent Stochastic Simulation: The eclipse Paradigm. </title> <journal> Journal of Parallel and Distributed Computing, </journal> <volume> 14(1) </volume> <pages> 66-84, </pages> <month> January </month> <year> 1992. </year>
Reference-contexts: The features we describe for fault-tolerance are embedded in EcliPSe <ref> [9, 12, 13, 5] </ref>, a toolkit for heterogeneous cluster computing. The toolkit is primarily geared towards replicative applications, namely those where a computation is replicated on distinct processors, and application-based interprocess communication is minimal. <p> The toolkit is primarily geared towards replicative applications, namely those where a computation is replicated on distinct processors, and application-based interprocess communication is minimal. Typical examples include very general simulations (e.g., parallel discrete-event, stochastic or numerical) <ref> [12] </ref>, or coarse-grained data-parallel computations (e.g., domain decomposition) [4].
Reference: [13] <author> V. S. Sunderam and V. J. Rego. </author> <title> EcliPSe: A system for High Performance Concurrent Simulation. </title> <journal> Software-Practice and Experience, </journal> <volume> 21(11) </volume> <pages> 1189-1219, </pages> <year> 1991. </year>
Reference-contexts: The features we describe for fault-tolerance are embedded in EcliPSe <ref> [9, 12, 13, 5] </ref>, a toolkit for heterogeneous cluster computing. The toolkit is primarily geared towards replicative applications, namely those where a computation is replicated on distinct processors, and application-based interprocess communication is minimal.
Reference: [14] <author> V.S. Sunderam. </author> <title> PVM: a framework for parallel distributed computing. </title> <journal> Concurrency: Practice and Experience, </journal> <volume> 2(4), </volume> <month> December </month> <year> 1990. </year>
Reference-contexts: An alternative to such application-dependent fault tolerance is application-independent fault tolerance, implemented at the message passing level. Used by Fail-safe PVM [8], which adds fault tolerance to the PVM library <ref> [14] </ref>, this approach has the obvious advantage of not requiring changes to the application code. But since the message passing library is oblivious to the application's doings, at least the entire memory image of each process must be saved at each checkpoint to allow for a proper rollback.
Reference: [15] <author> L.H. Turcotte. </author> <title> A survey of software environments for exploiting networked computing resources. </title> <type> Technical report, </type> <institution> Engineering Research Center for Computational Field Simulation, Mississippi State University, </institution> <month> June </month> <year> 1993. </year>
Reference-contexts: 1 INTRODUCTION Cluster computing, a low-cost alternative to supercomputers, involves the use of workstation clusters to solve compute-intensive problems with solutions that are amenable to distribution <ref> [15] </ref>. In recent years, this mode of computation has grown to envelop an increasing number of applications, mainly for scientific problems. At the present time, heterogeneous workstation clusters are not ideal replacements for supercomputers, mainly because of their low interconnection bandwidth and reliability.
References-found: 15

