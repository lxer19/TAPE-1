URL: http://www.cs.cmu.edu/afs/cs/usr/avrim/www/Papers/survey.ps.gz
Refering-URL: http://www.cs.cmu.edu/afs/cs.cmu.edu/user/avrim/www/ML98/home.html
Root-URL: 
Email: Email: avrim@cs.cmu.edu  
Title: On-Line Algorithms in Machine Learning  
Author: Avrim Blum 
Address: Pittsburgh PA 15213.  
Affiliation: Carnegie Mellon University,  
Abstract: The areas of On-Line Algorithms and Machine Learning are both concerned with problems of making decisions about the present based only on knowledge of the past. Although these areas differ in terms of their emphasis and the problems typically studied, there are a collection of results in Computational Learning Theory that fit nicely into the "on-line algorithms" framework. This survey article discusses some of the results, models, and open problems from Computational Learning Theory that seem particularly interesting from the point of view of on-line algorithms. The emphasis in this article is on describing some of the simpler, more intuitive results, whose proofs can be given in their entirity. Pointers to the literature are given for more sophisticated versions of these algorithms.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> D. Angluin. </author> <title> Queries and concept learning. </title> <journal> Machine Learning, </journal> <volume> 2(4) </volume> <pages> 319-342, </pages> <year> 1988. </year>
Reference-contexts: See [9] for details. 3.5 History The Winnow algorithm was developed by Littlestone in his seminal paper [24], which also gives a variety of extensions and introduces the Mistake-Bound learning model. The Mistake Bound model is equivalent to the "extended equivalence query" model of Angluin <ref> [1] </ref>, and is known to be strictly harder for polynomial-time algorithms than the PAC learning model of Valiant [34, 22] in which (among other differences) the adversary is required to select examples from a fixed distribution [6]. Agnostic learning is disussed in [23].
Reference: 2. <author> R. Armstrong, D. Freitag, T. Joachims, and T. Mitchell. Webwatcher: </author> <title> A learning apprentice for the world wide web. </title> <booktitle> In 1995 AAAI Spring Symposium on Information Gathering from Heterogeneous Distributed Environments, </booktitle> <month> March </month> <year> 1995. </year>
Reference-contexts: The Winnow algorithm has been shown to be quite successful in practical tasks as well, such as predicting links followed by users on the Web <ref> [2] </ref>, and a calendar scheduling application [7]. The algorithm presented for learning decision lists is based on Rivest's algorithm for the PAC model [31], adapted to the Mistake Bound model by Little-stone [25] and Helmbold, Sloan and Warmuth [20].
Reference: 3. <author> P. Auer and M.K. Warmuth. </author> <title> Tracking the best disjunction. </title> <booktitle> In Proceedings of the 36th Annual Symposium on Foundations of Computer Science, </booktitle> <pages> pages 312-321, </pages> <year> 1995. </year>
Reference-contexts: Agnostic learning is disussed in [23]. Littlestone [26] gives a variety of results on the behavior of Winnow in the presence of various kinds of noise. The improved bounds of Theorem 7 are from Auer and Warmuth <ref> [3] </ref>. The use of Winnow for learning changing concepts is folklore (and makes a good homework problem); Auer and Warmuth [3] provide a more sophisticated algorithm and analysis, achieving a stronger result than Theorem 8, in the style of Theorem 7. <p> The improved bounds of Theorem 7 are from Auer and Warmuth <ref> [3] </ref>. The use of Winnow for learning changing concepts is folklore (and makes a good homework problem); Auer and Warmuth [3] provide a more sophisticated algorithm and analysis, achieving a stronger result than Theorem 8, in the style of Theorem 7.
Reference: 4. <author> D. Blackwell. </author> <title> An analog of the minimax theorem for vector payoffs. </title> <journal> Pacific J. Math., </journal> <volume> 6 </volume> <pages> 1-8, </pages> <year> 1956. </year>
Reference-contexts: This problem and many variations and extensions have been addressed in a number of different communities, under names such as the "sequential compound decision problem" [32] <ref> [4] </ref>, "universal prediction" [16], "universal coding" [33], "universal portfolios" [13], and "prediction of individual sequences"; the notion of the competitiveness is also called the "min-max regret" of an algorithm. A web page uniting some of these communities and with a discussion of this general problem now exists at http://www-stat.wharton.upenn.edu/Seq96. <p> Freund and Schapire show that extensions of the randomized Weighted Majority Algorithm discussed above can be made to fit nicely into this scenario [19] (see also the classic work of Blackwell <ref> [4] </ref>). Another scenario fitting this framework would be a case where each expert is a page-replacement algorithm, and an operating system needs to decide which algorithm to use.
Reference: 5. <author> A. Blum. </author> <title> Learning boolean functions in an infinite attribute space. </title> <journal> Machine Learning, </journal> <volume> 9 </volume> <pages> 373-386, </pages> <year> 1992. </year>
Reference-contexts: The algorithm presented for learning decision lists is based on Rivest's algorithm for the PAC model [31], adapted to the Mistake Bound model by Little-stone [25] and Helmbold, Sloan and Warmuth [20]. The Infinite-Attribute model is defined in Blum <ref> [5] </ref> and Theorem 9 is from Blum, Hellerstein, and Littlestone [9]. 4 Open Problems 1.
Reference: 6. <author> A. Blum. </author> <title> Separating distribution-free and mistake-bound learning models over the boolean domain. </title> <journal> SIAM J. Computing, </journal> <volume> 23(5) </volume> <pages> 990-1000, </pages> <month> October </month> <year> 1994. </year>
Reference-contexts: The Mistake Bound model is equivalent to the "extended equivalence query" model of Angluin [1], and is known to be strictly harder for polynomial-time algorithms than the PAC learning model of Valiant [34, 22] in which (among other differences) the adversary is required to select examples from a fixed distribution <ref> [6] </ref>. Agnostic learning is disussed in [23]. Littlestone [26] gives a variety of results on the behavior of Winnow in the presence of various kinds of noise. The improved bounds of Theorem 7 are from Auer and Warmuth [3].
Reference: 7. <author> A. Blum. </author> <title> Empirical support for winnow and weighted-majority based algorithms: results on a calendar scheduling domain. </title> <booktitle> In Proceedings of the Twelfth International Conference on Machine Learning, </booktitle> <pages> pages 64-72, </pages> <month> July </month> <year> 1995. </year>
Reference-contexts: The Winnow algorithm has been shown to be quite successful in practical tasks as well, such as predicting links followed by users on the Web [2], and a calendar scheduling application <ref> [7] </ref>. The algorithm presented for learning decision lists is based on Rivest's algorithm for the PAC model [31], adapted to the Mistake Bound model by Little-stone [25] and Helmbold, Sloan and Warmuth [20].
Reference: 8. <author> A. Blum and C. Burch. </author> <title> On-line learning and the metrical task system problem. </title> <booktitle> In Proceedings of the 10th Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 45-53, </pages> <year> 1997. </year>
Reference-contexts: Nonetheless, as Computational Learning Theory moves to analyze more general sorts of learning problems, it seems inevitable that the notion of state will begin to play a larger role, and ideas from On-Line Algorithms will be crucial. Some work in this direction appears in <ref> [8] </ref>. Limiting the power of the adversary. In the On-Line Algorithms literature, it is usually assumed that the adversary has unlimited power to choose a worst-case sequence for the algorithm.
Reference: 9. <author> A. Blum, L. Hellerstein, and N. Littlestone. </author> <title> Learning in the presence of finitely or infinitely many irrelevant attributes. </title> <journal> J. Comp. Syst. Sci., </journal> <volume> 50(1) </volume> <pages> 32-40, </pages> <year> 1995. </year>
Reference-contexts: See <ref> [9] </ref> for details. 3.5 History The Winnow algorithm was developed by Littlestone in his seminal paper [24], which also gives a variety of extensions and introduces the Mistake-Bound learning model. <p> The algorithm presented for learning decision lists is based on Rivest's algorithm for the PAC model [31], adapted to the Mistake Bound model by Little-stone [25] and Helmbold, Sloan and Warmuth [20]. The Infinite-Attribute model is defined in Blum [5] and Theorem 9 is from Blum, Hellerstein, and Littlestone <ref> [9] </ref>. 4 Open Problems 1. Can the bounds of Corollary 3 be achieved and improved with a smooth algorithm? The bound of Corollary 3 is achieved using a "guess and double" algorithm that periodically throws out all it has learned so far and restarts using a new value of fi.
Reference: 10. <author> A. Blum and A. Kalai. </author> <title> Universal portfolios with and without transaction costs. </title> <booktitle> In Proceedings of the 10th Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 309-313, </pages> <year> 1997. </year>
Reference-contexts: This setting has the nice property that the market automatically adjusts the weights, so the algorithm itself just initially divides its funds equally among all infinitely-many CRPs and then lets it sit. A simple analysis of their algorithm with extensions to transaction costs is given in <ref> [10] </ref>. 3 On-Line Learning from Examples The previous section considered the problem of "learning from expert advice". We now broaden our focus to consider the more general scenario of on-line learning from examples. In this setting there is an example space X , typically f0; 1g n .
Reference: 11. <author> N. Cesa-Bianchi, Y. Freund, D. P. Helmbold, and M. Warmuth. </author> <title> On-line prediction and conversion strategies. </title> <booktitle> In Computational Learning Theory: Eurocolt '93, volume New Series Number 53 of The Institute of Mathematics and its Applications Conference Series, </booktitle> <pages> pages 205-216, </pages> <address> Oxford, 1994. </address> <publisher> Oxford University Press. </publisher>
Reference-contexts: Papers of Vovk [35, 36], Cesa-Bianchi et al. <ref> [12, 11] </ref>, and Foster and Vohra [17] describe optimal algorithms both for these specific loss functions and for a wide variety of general loss functions. A second extension of this framework is to broaden the class of algorithms against which the algorithm is competitive.
Reference: 12. <author> N. Cesa-Bianchi, Y. Freund, D.P. Helmbold, D. Haussler, R.E. Schapire, and M.K. Warmuth. </author> <title> How to use expert advice. </title> <booktitle> In Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 382-391, </pages> <year> 1993. </year>
Reference-contexts: The algorithms described above as well as Theorems 1 and 2 are from Littlestone and Warmuth [28], and Corollary 3, as well as a number of refinements, are from Cesa-Bianchi et al. <ref> [12] </ref>. Perhaps one of the key lessons of this work in comparison to work of a more statistical nature is that one can remove all statistical assumptions about the data and still achieve extremely tight bounds (see Freund [18]). <p> Papers of Vovk [35, 36], Cesa-Bianchi et al. <ref> [12, 11] </ref>, and Foster and Vohra [17] describe optimal algorithms both for these specific loss functions and for a wide variety of general loss functions. A second extension of this framework is to broaden the class of algorithms against which the algorithm is competitive. <p> It would seem more natural (and likely to work better in practice) to just smoothly adjust fi as we go along, never restarting from scratch. Can an algorithm of this form be shown to achieve this bound, preferably with even better constants? (See <ref> [12] </ref> for the precise constants.) 2.
Reference: 13. <author> T.M. </author> <title> Cover. Universal portfolios. </title> <journal> Mathematical Finance, </journal> <volume> 1(1) </volume> <pages> 1-29, </pages> <month> January </month> <year> 1991. </year>
Reference-contexts: This problem and many variations and extensions have been addressed in a number of different communities, under names such as the "sequential compound decision problem" [32] [4], "universal prediction" [16], "universal coding" [33], "universal portfolios" <ref> [13] </ref>, and "prediction of individual sequences"; the notion of the competitiveness is also called the "min-max regret" of an algorithm. A web page uniting some of these communities and with a discussion of this general problem now exists at http://www-stat.wharton.upenn.edu/Seq96.
Reference: 14. <author> T.M. Cover and E. Ordentlich. </author> <title> Universal portfolios with side information. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 42(2), </volume> <month> March </month> <year> 1996. </year>
Reference-contexts: Periodically the operating system computes losses for the various algorithms that it could have used and based on this information decides which algorithm to use next. Ordentlich and Cover <ref> [14] </ref> [30] describe strategies related to the randomized Weighted Majority algorithm for a problem of on-line portfolio selection. They give an on-line algorithm that is optimally competitive against the best "constant-rebalanced portfolio" (CRP).
Reference: 15. <author> A. DeSantis, G. Markowsky, and M. Wegman. </author> <title> Learning probabilistic prediction functions. </title> <booktitle> In Proceedings of the 29th IEEE Symposium on Foundations of Computer Science, </booktitle> <pages> pages 110-119, </pages> <month> Oct </month> <year> 1988. </year>
Reference-contexts: get the third line by noting that ln (1 x) &gt; x, and the fourth by using M = P t 2.3 History and Extensions Within the Computational Learning Theory community, the problem of predicting from expert advice was first studied by Littlestone and Warmuth [28], DeSantis, Markowsky and Wegman <ref> [15] </ref>, and Vovk [35]. The algorithms described above as well as Theorems 1 and 2 are from Littlestone and Warmuth [28], and Corollary 3, as well as a number of refinements, are from Cesa-Bianchi et al. [12].
Reference: 16. <author> M. Feder, N. Merhav, and M. Gutman. </author> <title> Universal prediction of individual sequences. </title> <journal> IEEE Transactions on Information Theory, </journal> <volume> 38 </volume> <pages> 1258-1270, </pages> <year> 1992. </year>
Reference-contexts: This problem and many variations and extensions have been addressed in a number of different communities, under names such as the "sequential compound decision problem" [32] [4], "universal prediction" <ref> [16] </ref>, "universal coding" [33], "universal portfolios" [13], and "prediction of individual sequences"; the notion of the competitiveness is also called the "min-max regret" of an algorithm. A web page uniting some of these communities and with a discussion of this general problem now exists at http://www-stat.wharton.upenn.edu/Seq96.
Reference: 17. <author> D.P. Foster and R.V. Vohra. </author> <title> A randomization rule for selecting forecasts. </title> <journal> Operations Research, </journal> <volume> 41 </volume> <pages> 704-709, </pages> <year> 1993. </year>
Reference-contexts: Papers of Vovk [35, 36], Cesa-Bianchi et al. [12, 11], and Foster and Vohra <ref> [17] </ref> describe optimal algorithms both for these specific loss functions and for a wide variety of general loss functions. A second extension of this framework is to broaden the class of algorithms against which the algorithm is competitive.
Reference: 18. <author> Y. Freund. </author> <title> Predicting a binary sequence almost as well as the optimal biased coin. </title> <booktitle> In Proceedings of the 9th Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 89-98, </pages> <year> 1996. </year>
Reference-contexts: Perhaps one of the key lessons of this work in comparison to work of a more statistical nature is that one can remove all statistical assumptions about the data and still achieve extremely tight bounds (see Freund <ref> [18] </ref>).
Reference: 19. <author> Y. Freund and R. Schapire. </author> <title> Game theory, on-line prediction and boosting. </title> <booktitle> In Proceedings of the 9th Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 325-332, </pages> <year> 1996. </year>
Reference-contexts: If we are playing repeatedly against some adversary, we then would get another opportunity to probabilistically select an expert to use and so forth. Freund and Schapire show that extensions of the randomized Weighted Majority Algorithm discussed above can be made to fit nicely into this scenario <ref> [19] </ref> (see also the classic work of Blackwell [4]). Another scenario fitting this framework would be a case where each expert is a page-replacement algorithm, and an operating system needs to decide which algorithm to use.
Reference: 20. <author> D. Helmbold, R. Sloan, and M. K. Warmuth. </author> <title> Learning nested differences of intersection closed concept classes. </title> <journal> Machine Learning, </journal> <volume> 5(2) </volume> <pages> 165-196, </pages> <year> 1990. </year>
Reference-contexts: The algorithm presented for learning decision lists is based on Rivest's algorithm for the PAC model [31], adapted to the Mistake Bound model by Little-stone [25] and Helmbold, Sloan and Warmuth <ref> [20] </ref>. The Infinite-Attribute model is defined in Blum [5] and Theorem 9 is from Blum, Hellerstein, and Littlestone [9]. 4 Open Problems 1.
Reference: 21. <author> M. Kearns. </author> <title> Efficient noise-tolerant learning from statistical queries. </title> <booktitle> In Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, </booktitle> <pages> pages 392-401, </pages> <year> 1993. </year>
Reference-contexts: Does this imply that there must exist a polynomial time algorithm B that succeeds in the same sense for all constant noise rates &lt; 1=2. (See Kearns <ref> [21] </ref> for related issues.) 7.
Reference: 22. <author> M. Kearns, M. Li, L. Pitt, and L. Valiant. </author> <title> On the learnability of boolean formulae. </title> <booktitle> In Proceedings of the Nineteenth Annual ACM Symposium on the Theory of Computing, </booktitle> <pages> pages 285-295, </pages> <address> New York, New York, </address> <month> May </month> <year> 1987. </year>
Reference-contexts: The Mistake Bound model is equivalent to the "extended equivalence query" model of Angluin [1], and is known to be strictly harder for polynomial-time algorithms than the PAC learning model of Valiant <ref> [34, 22] </ref> in which (among other differences) the adversary is required to select examples from a fixed distribution [6]. Agnostic learning is disussed in [23]. Littlestone [26] gives a variety of results on the behavior of Winnow in the presence of various kinds of noise.
Reference: 23. <author> M. Kearns, R. Schapire, and L. Sellie. </author> <title> Toward efficient agnostic learning. </title> <journal> Machine Learning, </journal> 17(2/3):115-142, 1994. 
Reference-contexts: Agnostic learning is disussed in <ref> [23] </ref>. Littlestone [26] gives a variety of results on the behavior of Winnow in the presence of various kinds of noise. The improved bounds of Theorem 7 are from Auer and Warmuth [3].
Reference: 24. <author> N. Littlestone. </author> <title> Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. </title> <journal> Machine Learning, </journal> <volume> 2 </volume> <pages> 285-318, </pages> <year> 1988. </year>
Reference-contexts: See [9] for details. 3.5 History The Winnow algorithm was developed by Littlestone in his seminal paper <ref> [24] </ref>, which also gives a variety of extensions and introduces the Mistake-Bound learning model.
Reference: 25. <author> N. Littlestone. </author> <title> personal communication (a mistake-bound version of Rivest's decision-list algorithm). </title> <year> 1989. </year>
Reference-contexts: The algorithm presented for learning decision lists is based on Rivest's algorithm for the PAC model [31], adapted to the Mistake Bound model by Little-stone <ref> [25] </ref> and Helmbold, Sloan and Warmuth [20]. The Infinite-Attribute model is defined in Blum [5] and Theorem 9 is from Blum, Hellerstein, and Littlestone [9]. 4 Open Problems 1.
Reference: 26. <author> N. Littlestone. </author> <title> Redundant noisy attributes, attribute errors, and linear-threshold learning using winnow. </title> <booktitle> In Proceedings of the Fourth Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 147-156, </pages> <address> Santa Cruz, California, 1991. </address> <publisher> Morgan Kaufmann. </publisher>
Reference-contexts: Agnostic learning is disussed in [23]. Littlestone <ref> [26] </ref> gives a variety of results on the behavior of Winnow in the presence of various kinds of noise. The improved bounds of Theorem 7 are from Auer and Warmuth [3].
Reference: 27. <author> N. Littlestone, P. M. Long, and M. K. Warmuth. </author> <title> On-line learning of linear functions. </title> <booktitle> In Proc. of the 23rd Symposium on Theory of Computing, </booktitle> <pages> pages 465-475. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1991. </year> <note> See also UCSC-CRL-91-29. </note>
Reference-contexts: A second extension of this framework is to broaden the class of algorithms against which the algorithm is competitive. For instance, Littlestone, Long, and Warmuth <ref> [27] </ref> show that modifications of the algorithms described above are constant-competitive with respect to the best linear combination of experts, when the squared loss measure is used.
Reference: 28. <author> N. Littlestone and M. K. Warmuth. </author> <title> The weighted majority algorithm. </title> <journal> Information and Computation, </journal> <volume> 108(2) </volume> <pages> 212-261, </pages> <year> 1994. </year>
Reference-contexts: M 1 fi Where we get the third line by noting that ln (1 x) &gt; x, and the fourth by using M = P t 2.3 History and Extensions Within the Computational Learning Theory community, the problem of predicting from expert advice was first studied by Littlestone and Warmuth <ref> [28] </ref>, DeSantis, Markowsky and Wegman [15], and Vovk [35]. The algorithms described above as well as Theorems 1 and 2 are from Littlestone and Warmuth [28], and Corollary 3, as well as a number of refinements, are from Cesa-Bianchi et al. [12]. <p> t 2.3 History and Extensions Within the Computational Learning Theory community, the problem of predicting from expert advice was first studied by Littlestone and Warmuth <ref> [28] </ref>, DeSantis, Markowsky and Wegman [15], and Vovk [35]. The algorithms described above as well as Theorems 1 and 2 are from Littlestone and Warmuth [28], and Corollary 3, as well as a number of refinements, are from Cesa-Bianchi et al. [12].
Reference: 29. <author> N. Merhav and M. Feder. </author> <title> Universal sequential learning and decisions from individual data sequences. </title> <booktitle> In Proc. 5th Annu. Workshop on Comput. Learning Theory, </booktitle> <pages> pages 413-427. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1992. </year>
Reference-contexts: For instance, Littlestone, Long, and Warmuth [27] show that modifications of the algorithms described above are constant-competitive with respect to the best linear combination of experts, when the squared loss measure is used. Merhav and Feder <ref> [29] </ref> show that one can be competitive with respect to the best off-line strategy that can be implemented by a finite state machine. Another variation on this problem is to remove all semantics associated with specific predictions by the experts and to simply talk about losses.
Reference: 30. <author> E. </author> <title> Ordentlich and T.M. Cover. On-line portfolio selection. </title> <booktitle> In COLT 96, </booktitle> <pages> pages 310-313, </pages> <year> 1996. </year> <note> A journal version is to be submitted to Mathematics of Operations Research. </note>
Reference-contexts: Periodically the operating system computes losses for the various algorithms that it could have used and based on this information decides which algorithm to use next. Ordentlich and Cover [14] <ref> [30] </ref> describe strategies related to the randomized Weighted Majority algorithm for a problem of on-line portfolio selection. They give an on-line algorithm that is optimally competitive against the best "constant-rebalanced portfolio" (CRP).
Reference: 31. <author> R.L. Rivest. </author> <title> Learning decision lists. </title> <journal> Machine Learning, </journal> <volume> 2(3) </volume> <pages> 229-246, </pages> <year> 1987. </year>
Reference-contexts: The Winnow algorithm has been shown to be quite successful in practical tasks as well, such as predicting links followed by users on the Web [2], and a calendar scheduling application [7]. The algorithm presented for learning decision lists is based on Rivest's algorithm for the PAC model <ref> [31] </ref>, adapted to the Mistake Bound model by Little-stone [25] and Helmbold, Sloan and Warmuth [20]. The Infinite-Attribute model is defined in Blum [5] and Theorem 9 is from Blum, Hellerstein, and Littlestone [9]. 4 Open Problems 1.
Reference: 32. <author> H. Robbins. </author> <title> Asymptotically subminimax solutions of compound statistical decision problems. </title> <booktitle> In Proc. 2nd Berkeley Symp. Math. Statist. Prob., </booktitle> <pages> pages 131-148, </pages> <year> 1951. </year>
Reference-contexts: This problem and many variations and extensions have been addressed in a number of different communities, under names such as the "sequential compound decision problem" <ref> [32] </ref> [4], "universal prediction" [16], "universal coding" [33], "universal portfolios" [13], and "prediction of individual sequences"; the notion of the competitiveness is also called the "min-max regret" of an algorithm. A web page uniting some of these communities and with a discussion of this general problem now exists at http://www-stat.wharton.upenn.edu/Seq96.
Reference: 33. <author> J. Shtarkov. </author> <title> Universal sequential coding of single measures. </title> <booktitle> Problems of Information Transmission, </booktitle> <pages> pages 175-185, </pages> <year> 1987. </year>
Reference-contexts: This problem and many variations and extensions have been addressed in a number of different communities, under names such as the "sequential compound decision problem" [32] [4], "universal prediction" [16], "universal coding" <ref> [33] </ref>, "universal portfolios" [13], and "prediction of individual sequences"; the notion of the competitiveness is also called the "min-max regret" of an algorithm. A web page uniting some of these communities and with a discussion of this general problem now exists at http://www-stat.wharton.upenn.edu/Seq96.
Reference: 34. <author> L.G. Valiant. </author> <title> A theory of the learnable. </title> <journal> Comm. ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <month> Novem-ber </month> <year> 1984. </year>
Reference-contexts: The Mistake Bound model is equivalent to the "extended equivalence query" model of Angluin [1], and is known to be strictly harder for polynomial-time algorithms than the PAC learning model of Valiant <ref> [34, 22] </ref> in which (among other differences) the adversary is required to select examples from a fixed distribution [6]. Agnostic learning is disussed in [23]. Littlestone [26] gives a variety of results on the behavior of Winnow in the presence of various kinds of noise.
Reference: 35. <author> V. Vovk. </author> <title> Aggregating strategies. </title> <booktitle> In Proceedings of the Third Annual Workshop on Computational Learning Theory, </booktitle> <pages> pages 371-383. </pages> <publisher> Morgan Kaufmann, </publisher> <year> 1990. </year>
Reference-contexts: line by noting that ln (1 x) &gt; x, and the fourth by using M = P t 2.3 History and Extensions Within the Computational Learning Theory community, the problem of predicting from expert advice was first studied by Littlestone and Warmuth [28], DeSantis, Markowsky and Wegman [15], and Vovk <ref> [35] </ref>. The algorithms described above as well as Theorems 1 and 2 are from Littlestone and Warmuth [28], and Corollary 3, as well as a number of refinements, are from Cesa-Bianchi et al. [12]. <p> Papers of Vovk <ref> [35, 36] </ref>, Cesa-Bianchi et al. [12, 11], and Foster and Vohra [17] describe optimal algorithms both for these specific loss functions and for a wide variety of general loss functions. A second extension of this framework is to broaden the class of algorithms against which the algorithm is competitive.
Reference: 36. <author> V. G. Vovk. </author> <title> A game of prediction with expert advice. </title> <booktitle> In Proceedings of the 8th Annual Conference on Computational Learning Theory, </booktitle> <pages> pages 51-60. </pages> <publisher> ACM Press, </publisher> <address> New York, NY, </address> <year> 1995. </year> <title> This article was processed using the L a T E X macro package with LLNCS style </title>
Reference-contexts: Papers of Vovk <ref> [35, 36] </ref>, Cesa-Bianchi et al. [12, 11], and Foster and Vohra [17] describe optimal algorithms both for these specific loss functions and for a wide variety of general loss functions. A second extension of this framework is to broaden the class of algorithms against which the algorithm is competitive.
References-found: 36

