URL: http://www.cs.rpi.edu/tr/98-3.ps
Refering-URL: http://www.cs.rpi.edu/tr/
Root-URL: http://www.cs.rpi.edu
Title: Case Study of a Learning Algorithm for the Longest Common Subsequence Problem  
Author: Eric A. Breimer and Mark K. Goldberg 
Affiliation: Rensselaer Polytechnic Institute  
Abstract: Based on the behavior of a supervisor-algorithm, we present a learning algorithm which designs an improved algorithm for solving the Longest Common Subsequence problem (LCS). The supervisor is the standard dynamic programming algorithm (DP) for LCS. The learning algorithm applies DP to inputs generated randomly according to a probability distribution D. The optimal solutions generated by DP are used to build a search area. The search area is then used to develop a new algorithm tailored for solving the LCS problem for inputs generated according to D. We present experiments showing the learning curve of the algorithm and the performance parameters of the new LCS-algorithm after a prescribed approximation ratio has being achieved. In particular, our experiments with two random 0,1-sequences of length n suggest that applying O(n 0:630 ) training samples guarantees an LCS-algorithm whose approximation ratio is 0.95 and the running time is O(n 1:654 ) (vs the quadratic time of DP). Our experiments also indicate a relationship between the distribution of the input symbols and the structure of the search area. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> A. V. Aho, J. Hopcroft, and J. D. Ulman, </author> <title> Data Structure and Algorithms, </title> <publisher> Addison-Wesley, </publisher> <address> Reading , MA, </address> <year> 1983. </year>
Reference: [2] <author> P. Bonizzoni, M. D`Alessandro, G. Della Vedova, and G. Mauri, </author> <booktitle> in Proceedings of "Algorithms and Experiments" (ALEX98), </booktitle> <address> Trento, Italy, </address> <month> Feb 9-11, </month> <year> 1998, </year> <editor> R. Battiti and A.A. Bertossi (Eds.) pp. </editor> <address> 96 -102. </address>
Reference-contexts: However, for many applications, such a running time is impractical, even if m is small (see [10]). This prompted a search for faster algorithms, possibly approximate, but with good performance bounds (see <ref> [2] </ref>, [4], [8]). In this paper, we present a learning algorithm which outputs an algorithm for LCS. For a given class of inputs, the algorithm builds a description of a search area based on the solutions produced by the dynamic programming algorithm. <p> Other experiments show the performance of the algorithm on inputs with multiple sequences, alphabets with more than two letters, and different probability distributions of the letters in the input sequences. We compare the performance of our LCS-algorithm with the algorithm Expansion described in <ref> [2] </ref>. Note that our learning algorithm producing an LCS-procedure can also be viewed as an LCS algorithm which improves its performance by alternating learning and testing. Further on in the paper, the following terminology is used. <p> The first set of experiments was to establish the learning curve and run-time performance of Approximate-DP for two equal-sized 0; 1-input strings. In the second set of experiments, we compared the performance of our algorithm with the algorithm Expansion described in <ref> [2] </ref>. In the third set of experiments, the learning algorithm was tested on classes of inputs with three strings; up to six letter alphabets; and strings generated with non-uniform distributions. <p> Since the run-time of the Expansion algorithm is O (mn 2 log n) <ref> [2] </ref>, the learning algorithm, which speeds up the algorithm with respect to n, runs significantly faster for larger input. Table 2 shows a sample of the 20 experiments. For the 5 experiments using four inputs, the learning algorithm generated a larger average LCS than the Expansion algorithm.
Reference: [3] <author> P. Bonizzoni, and A. Ehrenfeucht, </author> <title> Approximation of the shortest common supersequence with ratio less than the alphabet size. </title> <type> Technical Report TR 149-95, </type> <institution> Dipartimento di Scienze Della Informazione, Universita Degli Studi di Milano, </institution> <year> 1996. </year>
Reference: [4] <author> H. Buhrman, T. Jiang, M. Li, P. Vitanyi, </author> <title> New Applications of the Incompressibility Method, </title> <note> (to appear). </note>
Reference-contexts: However, for many applications, such a running time is impractical, even if m is small (see [10]). This prompted a search for faster algorithms, possibly approximate, but with good performance bounds (see [2], <ref> [4] </ref>, [8]). In this paper, we present a learning algorithm which outputs an algorithm for LCS. For a given class of inputs, the algorithm builds a description of a search area based on the solutions produced by the dynamic programming algorithm.
Reference: [5] <author> M.R. Garey, D.S. Johnson, </author> <title> Computer and Intractability- A Guide to the Theory of NP-Completeness, W.H. </title> <publisher> Freeman and Co., </publisher> <year> 1979. </year> <month> 10 </month>
Reference: [6] <author> T. Jiang and M. Li, </author> <title> On the approximation of shortest common supersequences and longest subsequences, </title> <journal> SIAM J. on Computing, </journal> <volume> 24(5), </volume> <pages> pp. 1122-1139, </pages> <year> 1995. </year>
Reference: [7] <author> D. Maier, </author> <title> The complexity of some problems on subsequences and supersequences, </title> <journal> Journal of the ACM, </journal> <volume> 25, </volume> <pages> pp. 322-336, </pages> <year> 1978. </year>
Reference: [8] <author> M. S. Paterson and V. Dancik, </author> <title> Longest common subsequences, </title> <editor> in Igor Pr ivara, Branislav Rovan and Peter Ruzicka, editors, </editor> <booktitle> Mathematical Foundations of Computer Science, 19 th International Symposium, vol. 841 of LNCS, </booktitle> <pages> pp. 127-142, </pages> <address> Kosice, Slovakia, </address> <year> 1994. </year>
Reference-contexts: However, for many applications, such a running time is impractical, even if m is small (see [10]). This prompted a search for faster algorithms, possibly approximate, but with good performance bounds (see [2], [4], <ref> [8] </ref>). In this paper, we present a learning algorithm which outputs an algorithm for LCS. For a given class of inputs, the algorithm builds a description of a search area based on the solutions produced by the dynamic programming algorithm.
Reference: [9] <author> D. Sanfoff and J. B. Kruskal, </author> <title> Time Wraps, SString Edits, and Macromolecules: The Theory and Practice of Sequence Comparions, </title> <publisher> Addison-Wesley, </publisher> <address> Reading, MA, </address> <year> 1983. </year>
Reference: [10] <author> T. F. Smith and M. S. Waterman, </author> <title> Identification of common molecular subsequences, </title> <journal> Journal of Molecular Biology, </journal> <volume> 147, </volume> <pages> pp. 195-197, </pages> <year> 1981. </year>
Reference-contexts: The standard dynamic programming algorithm (DP) ([12]) solves the problem in O (n m ) time, where n is the length of the longest sequence in the input. However, for many applications, such a running time is impractical, even if m is small (see <ref> [10] </ref>). This prompted a search for faster algorithms, possibly approximate, but with good performance bounds (see [2], [4], [8]). In this paper, we present a learning algorithm which outputs an algorithm for LCS.
Reference: [11] <author> L. G. Valiant, </author> <title> A theory of the learnable, </title> <journal> Communications of the ACM, </journal> <volume> 27(11) </volume> <pages> 1134-1142, </pages> <year> 1984. </year>
Reference: [12] <author> R. A. Wagner and M. J. Fisher, </author> <title> The string-to-string correction problem, </title> <journal> Journal of the ACM 21, </journal> <pages> pp. 168-173, </pages> <year> 1974. </year>
References-found: 12

