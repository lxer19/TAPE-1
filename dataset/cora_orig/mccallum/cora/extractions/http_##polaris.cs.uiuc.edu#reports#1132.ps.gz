URL: http://polaris.cs.uiuc.edu/reports/1132.ps.gz
Refering-URL: http://polaris.cs.uiuc.edu/tech_reports.html
Root-URL: http://www.cs.uiuc.edu
Title: Algorithms and Applications Research at CSRD  
Author: E. Gallopoulos 
Address: Urbana Champaign Urbana, Illinois 61801  
Affiliation: Center for Supercomputing Research and Development University of Illinois at  
Abstract-found: 0
Intro-found: 1
Reference: [1] <institution> The High-Performance Computing Initiative. Executive Office of the President: Office of Science and Technology, </institution> <month> September </month> <year> 1989. </year>
Reference-contexts: The vehicles for the experiments are Cedar and the GFDL ocean circulation code, adapted at IMGA (Mod-ena, Italy) for the simulation of the Mediterranean basin [58]. Computational ocean simulation is an important component of two of the Grand Challenges outlined recently in <ref> [1] </ref>. We hope that our work will lead to better understanding in those areas. Different partitionings and storage allocation for the data are being tried.
Reference: [2] <author> S. ASLAM, E. GALLOPOULOS, R. BRAMLEY, H.-C. CHEN, AND ET.AL, </author> <title> The advanced software development and commercialization project: </title> <type> Project Report 1, Tech. Report CSRD No. 1047, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> September </month> <year> 1990. </year> <institution> Also Argonne Nat'l Lab. Tech. </institution> <note> Memo. ANL/TM 484. </note>
Reference-contexts: Chen has been applied to a 3D 3D elasticity FEM code extracted from SAP IV. Another effort consists in the parallelization of the WHAMS-3D structural dynamics code for several multiprocessor architectures including Alliant, Cedar and Cray <ref> [2] </ref>. We are also working on the development of multiprocessed versions of COMMIX, an industrial strength, three-dimensional single-phase thermal hydraulics family of codes from Argonne National laboratory. <p> We evaluate the effect of several methods and preconditioning techniques for the solution steps and the role of automatic and manual parallelization techniques for the matrix construction steps on the performance of the code when used on Cray Y-MP and Alliant FX multiprocessors <ref> [2, 3] </ref>. A similar effort is being undertaken for N3S, a 3D FEM code for thermal hydraulic problems [19, 65]. 3.3 Ocean circulation Derose, Gallivan and Gallopoulos investigate the problem of mapping numerical simulations of ocean circulation onto parallel architectures [25, 26].
Reference: [3] <author> S. ASLAM, E. GALLOPOULOS, M. HAM, T. CANFIELD, M. MINKOFF, AND R. BLOMQUIST, </author> <title> Experiments in thermal hydraulics simulation: multiprocessing COMMIX, </title> <type> Tech. Report 1130, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> March </month> <year> 1991. </year> <note> Presented in Fifth SIAM Conf. Parallel Processing for Scientific Computing. To be published. </note>
Reference-contexts: We evaluate the effect of several methods and preconditioning techniques for the solution steps and the role of automatic and manual parallelization techniques for the matrix construction steps on the performance of the code when used on Cray Y-MP and Alliant FX multiprocessors <ref> [2, 3] </ref>. A similar effort is being undertaken for N3S, a 3D FEM code for thermal hydraulic problems [19, 65]. 3.3 Ocean circulation Derose, Gallivan and Gallopoulos investigate the problem of mapping numerical simulations of ocean circulation onto parallel architectures [25, 26].
Reference: [4] <author> O. AXELSSON AND V. EIJKHOUT, </author> <title> A nested recursive two-level factorization method for nine-point difference matrices, </title> <type> Tech. Report 8936, </type> <institution> Dept. of Mathematics of the University at Nijmegen, </institution> <address> The Netherlands, </address> <year> 1989. </year> <note> To appear in SIAM J. </note> <institution> of Sci. Stat. Computing. </institution> <month> 12 </month>
Reference-contexts: Eijkhout) We have investigated the occurence of zero, or small, pivots arising from the combination of modified incomplete factorizations with certain ordering strategies. Such phenomena occasionally surface in practical circumstances (see [27]). A code for the multilevel method in <ref> [4] </ref> for solving symmetric positive definite linear systems is currently being implemented on Cedar to explore the effectiveness of such a class of methods on shared memory multiprocessors with hierarchical organization. Furthermore, the above method is being extended to handle nonsymmetric linear systems.
Reference: [5] <author> M. BERRY, K. GALLIVAN, W. HARROD, W. JALBY, S.-S. LO, U. MEIER, B. PHILIPPE, AND A. SAMEH, </author> <title> Parallel algorithms on the Cedar system, </title> <booktitle> in Lecture Notes in Computer Science: Proc. </booktitle> <volume> CONPAR 86, </volume> <editor> W. Handler, ed., </editor> <volume> no. 237, </volume> <publisher> Springer-Verlag, </publisher> <year> 1986, </year> <pages> pp. 25-39. </pages>
Reference-contexts: this conference and [54]. 1 2 Current research in numerical algorithms Much of the algorithmic work during the first few years of CSRD was devoted in the study, formulation and design of algorithms for dense linear algebra computations on hierarchical memory multiprocessors, and in particular the one cluster of Cedar <ref> [5, 35, 53] </ref>. Much of this work also led to useful design principles for parallel programs on hierarchical memory machines [34, 33, 44, 30].
Reference: [6] <author> M. W. BERRY, </author> <title> Multiprocessor sparse SVD algorithms and applications, </title> <type> Tech. Report CSRD No. 1049, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> November </month> <year> 1990. </year>
Reference-contexts: Several parallel schemes have also been developed for handling sparse singular-value problems arising in information retrieval and nonlinear inverse problems in seismic reflection tomography applications. Four parallel algorithms have been developed for obtaining extreme singular values only or singular triplets, <ref> [6] </ref>. These are the single vector Lanczos algorithms with selective reorthogonalization, block Lanczos with complete reorthogonalization, Rutishauser's subspace iteration, and trace minimization [61]. Polynomial acceleration has played a vital role in producing effective parallel schemes. 2.7 Automatic program instrumentation with applications in performance and error analysis (B. Bliss, M.-C.
Reference: [7] <author> A. BJ ORCK AND T. ELFVING, </author> <title> Accelerated projection methods for computing pseu-doinverse solutions of systems for linear equations, </title> <journal> BIT, </journal> <volume> 19 (1979), </volume> <pages> pp. 145-163. </pages>
Reference-contexts: Two general classes of RP methods have been examined, the product or Kaczmarz [49] and sum or Cimmino [24] forms. Both iterative forms are accelerated using conjugate gradients, as initially suggested by in <ref> [7] </ref> and developed as effective parallel solvers for two-dimensional problems in [50]. 8 Apart from covering the theoretical foundation of the methods, we have developed an approach to finding row partitionings that allow parallelism in the computations [14].
Reference: [8] <author> B. BLISS, </author> <title> Instrumentation of Fortran programs for automatic roundoff error analysis and performance evaluation, </title> <type> master's thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <month> Jan. </month> <year> 1990. </year> <note> Also CSRD TR-936. </note>
Reference-contexts: Bliss, M.-C. Brunet, E. Gallopoulos) We have designed tools for the automatic instrumentation of Fortran programs for tasks such as performance, data flow and error analyses <ref> [8] </ref>. These tools were used in reporting floating point activity and utilization of vector hardware, generating computational graphs, and producing information about numerical quality based on deterministic and statistical techniques.
Reference: [9] <author> B. BLISS, M.-C. BRUNET, AND E. GALLOPOULOS, </author> <title> Automatic parallel program instrumentation with applications in performance and error analysis, </title> <type> Tech. Report 1025, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> June </month> <year> 1990. </year> <booktitle> Presented in 2nd ACM Conference on Expert Systems for Numerical Computing. </booktitle>
Reference-contexts: These tools were used in reporting floating point activity and utilization of vector hardware, generating computational graphs, and producing information about numerical quality based on deterministic and statistical techniques. These tools make possible the immediate application of previously hard to use techniques for investigating the numerical quality of algorithms <ref> [9] </ref>. 3 Design of large-scale applications on parallel architectures As mentioned in the introduction, our work has three primary objectives. The discussion till now has centered around the first objective, namely the design of parallel numerical algorithms.
Reference: [10] <author> R. BRAMLEY, </author> <title> Row Projection Methods for Linear Systems, </title> <type> PhD thesis, </type> <institution> University of Illinois Urbana-Champaign, </institution> <year> 1989. </year> <type> also Technical Report # 881, </type> <institution> Center for Supercomputing Research and Development. </institution> <month> [11] , RP-PACK: </month> <title> A tool for examining row projection methods, </title> <type> Tech. Report 1008, </type> <institution> Center for Supercomputing Research and Development, University of Illi-nois at Urbana-Champaign, </institution> <year> 1990. </year> <title> [12] , The block Cimmino method on Cedar, </title> <note> submitted to Inter. J. High Speed Computing, (submitted). </note>
Reference-contexts: This approach can also be used to solve large sparse unstructured least squares problems. 2.6.3 Block Projection Methods (R. Bramley, U. Meier, A. Sameh) In a series of papers <ref> [50, 51, 10, 14, 12, 11, 13, 15] </ref>, block projection methods have been developed as robust, parallel solvers for structured linear systems.
Reference: [13] <author> R. BRAMLEY AND A. SAMEH, </author> <title> A robust parallel solver for block tridiagonal systems, </title> <booktitle> in Proc. Int. Conf. on Supercomputing, ACM, </booktitle> <month> July </month> <year> 1988, </year> <pages> pp. </pages> <month> 39-54. </month> <title> [14] , Domain decomposition for parallel row projection algorithms, </title> <type> Tech. Report CSRD No. 958, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <year> 1990. </year> <note> To appear in Applied Numerical Mathematics. </note>
Reference-contexts: This approach can also be used to solve large sparse unstructured least squares problems. 2.6.3 Block Projection Methods (R. Bramley, U. Meier, A. Sameh) In a series of papers <ref> [50, 51, 10, 14, 12, 11, 13, 15] </ref>, block projection methods have been developed as robust, parallel solvers for structured linear systems.
Reference: [15] <author> R. BRAMLEY AND A. SAMEH, </author> <title> Domain decompositions for parallel row projection algorithms, Subm. for Publ. </title> <note> to Applied Numerical Mathematics, </note> <year> (1990). </year>
Reference-contexts: This approach can also be used to solve large sparse unstructured least squares problems. 2.6.3 Block Projection Methods (R. Bramley, U. Meier, A. Sameh) In a series of papers <ref> [50, 51, 10, 14, 12, 11, 13, 15] </ref>, block projection methods have been developed as robust, parallel solvers for structured linear systems. <p> Lou, A. Sameh, D. Semeraro) In view of our interest in computational fluid dynamics applications we have been working on methods for solving the indefinite system of equations arising from the discretization of the Stokes problem and other applications. For a survey of this work we point to <ref> [15] </ref> and [55]. 2.6.6 Sparse eigenvalue and singular-value problem solvers (M. Berry, A. Galick, A. Sameh) Rutishauser's subspace iteration was successfully applied to handle large symmetric generalized eigenvalue problems that arise from solving Schrodinger's equation which, in turn, arises from modeling semiconductor devices.
Reference: [16] <author> J. BUNCH AND K. KAUFMAN, </author> <title> Some stable methods for calculating inertia and solving symmetric linear systems, </title> <journal> Math. Comp., </journal> <volume> 31 (1977), </volume> <pages> pp. 162-179. </pages>
Reference-contexts: In particular, assume m is even and ff fi. Then (A ffI) + fiI is symmetric but non-Hermitian. For example, in the case of Pade, A ffI is symmetric positive definite, and a direct method (e.g. algorithm D of <ref> [16] </ref>) can be applied without pivoting [62]. In the case of uniform approximation, we note that whenever ff is larger than 0, thus possibly leading to a symmetric but indefinite matrix (A ffI), fi (the imaginary part of the shift) is not close to zero.
Reference: [17] <author> B. BUZBEE, G. GOLUB, AND C. NIELSON, </author> <title> On direct methods for solving Poisson's equation, </title> <journal> SIAM J. Numer. Anal., </journal> <month> 7 (December </month> <year> 1970), </year> <pages> pp. 627-656. </pages>
Reference-contexts: This result is in harmony with the asymptotic parallel complexity 3. All references to BCR correspond to the Buneman stabilized version <ref> [17] </ref>. 3 n + 1 1 cluster 2 cluster 4 cluster 32 .10 .13 .15 128 .50 .41 .22 512 5.09 3.44 1.93 Table 1: Domain decomposition on 1-, 2-, and 4-cluster Cedar: seconds/iteration result of O (log n) operations for scalar cyclic reduction instead of O (n) operations for Gaussian
Reference: [18] <author> A. J. CARPENTER, A. RUTTAN, AND R. S. VARGA, </author> <title> Extended numerical computations on the 1/9 conjecture in rational approximation theory, in Rational Approximation and Interpolation, </title> <editor> P. R. Graves-Morris, E. B. Saff, and R. S. Varga, eds., </editor> <volume> vol. </volume> <booktitle> 1105 of Lecture Notes in Mathematics, </booktitle> <publisher> Springer-Verlag, </publisher> <address> Berlin, </address> <year> 1984, </year> <pages> pp. 383-411. </pages>
Reference-contexts: Increasing the degree m improves the accuracy of the approximation. If A is symmetric, positive definite we can use rational uniform approximation to e z in the interval (1; 0) <ref> [18] </ref>. To solve systems with polynomial coefficient q m (At), the q m (z) is written in product form Q m i=1 (z i ), where i s are the poles of the ra tional approximation, which are evaluated numerically.
Reference: [19] <author> J. CHABARD, </author> <title> N3S code for fluid mechanics, theoretical manual, </title> <institution> Direction Des Etudes Et Recherches HE-41/89.1441/89.1441/89.1441/89.14, Electricite de France, </institution> <note> 6, quai Watier, 78400 Chatou, 1989. version 2.0 ed. </note>
Reference-contexts: A similar effort is being undertaken for N3S, a 3D FEM code for thermal hydraulic problems <ref> [19, 65] </ref>. 3.3 Ocean circulation Derose, Gallivan and Gallopoulos investigate the problem of mapping numerical simulations of ocean circulation onto parallel architectures [25, 26]. Our objective is to design algorithms which allow for more efficient and hence more detailed and accurate simulations.
Reference: [20] <author> H.-C. CHEN, </author> <title> The SAS Domain Decomposition Method, </title> <type> PhD thesis, </type> <institution> University of Illinois at Urbana-Champaign, </institution> <year> 1988. </year> <title> [21] , Two special classes of matrices, </title> <type> Tech. Report CSRD No. 979, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> March </month> <year> 1990. </year>
Reference-contexts: Chen) The symmetric and antisymmetric domain decomposition (SAS) introduced in <ref> [20] </ref> and [22, 23] for problems in structural mechanics is ideally suited for multiprocessors such as Cray Y-MP, Cray-2, Alliant FX/80, and Cedar.
Reference: [22] <author> H.-C. CHEN AND A. SAMEH, </author> <title> A matrix decomposition method for orthotropic elasticity problems, </title> <journal> SIAM J. on Matrix Analysis and Appl., </journal> <volume> 10 (1989), </volume> <pages> pp. </pages> <month> 39-64. </month> <title> [23] , A domain decomposition method for 3D elasticity problems, Applications of Supercomputers in Engineering: Fluid Flow and Stress Analysis Applications, </title> <month> (September </month> <year> 1989.), </year> <pages> pp. 171-188. </pages>
Reference-contexts: Chen) The symmetric and antisymmetric domain decomposition (SAS) introduced in [20] and <ref> [22, 23] </ref> for problems in structural mechanics is ideally suited for multiprocessors such as Cray Y-MP, Cray-2, Alliant FX/80, and Cedar.
Reference: [24] <author> G. </author> <type> CIMMINO, </type> <institution> Calcolo approssimato per le soluzioni dei sistemi di equazioni lineari, Ric. Sci. Progr. tecn. econom. naz., </institution> <month> 9 </month> <year> (1939), </year> <pages> pp. 326-333. </pages>
Reference-contexts: Two general classes of RP methods have been examined, the product or Kaczmarz [49] and sum or Cimmino <ref> [24] </ref> forms.
Reference: [25] <author> L. DEROSE, K. GALLIVAN, AND E. GALLOPOULOS, </author> <title> Trace analysis of the GFDL ocean circulation model: A preliminary study, </title> <type> Tech. Report 863, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <month> April </month> <year> 1989. </year>
Reference-contexts: A similar effort is being undertaken for N3S, a 3D FEM code for thermal hydraulic problems [19, 65]. 3.3 Ocean circulation Derose, Gallivan and Gallopoulos investigate the problem of mapping numerical simulations of ocean circulation onto parallel architectures <ref> [25, 26] </ref>. Our objective is to design algorithms which allow for more efficient and hence more detailed and accurate simulations. We study global and detailed regional circulation models, and determine mapping strategies suitable for different architectural configurations.
Reference: [26] <author> L. DEROSE, K. GALLIVAN, E. GALLOPOULOS, AND A. NAVARRA, </author> <title> Parallel ocean circulation modeling on Cedar, </title> <booktitle> in Proc. Fifth SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <editor> J. J. Dongarra, K. Kennedy, P. Messina, D. C. Sorensen, , and R. G. Voigt, eds., </editor> <address> Philadelphia, March 1991, </address> <publisher> SIAM, </publisher> <pages> pp. 401-405. </pages>
Reference-contexts: A similar effort is being undertaken for N3S, a 3D FEM code for thermal hydraulic problems [19, 65]. 3.3 Ocean circulation Derose, Gallivan and Gallopoulos investigate the problem of mapping numerical simulations of ocean circulation onto parallel architectures <ref> [25, 26] </ref>. Our objective is to design algorithms which allow for more efficient and hence more detailed and accurate simulations. We study global and detailed regional circulation models, and determine mapping strategies suitable for different architectural configurations.
Reference: [27] <author> I. DUFF AND G. MEURANT, </author> <title> The effect of ordering on preconditioned conjugate gradients, </title> <journal> BIT, </journal> <volume> 29 (1989), </volume> <pages> pp. 635-657. </pages>
Reference-contexts: Eijkhout) We have investigated the occurence of zero, or small, pivots arising from the combination of modified incomplete factorizations with certain ordering strategies. Such phenomena occasionally surface in practical circumstances (see <ref> [27] </ref>). A code for the multilevel method in [4] for solving symmetric positive definite linear systems is currently being implemented on Cedar to explore the effectiveness of such a class of methods on shared memory multiprocessors with hierarchical organization.
Reference: [28] <author> G. N. FRANK, </author> <title> Experiments on the Cedar multicluster with parallel block cyclic reduction and an application to domain decomposition methods, </title> <type> master's thesis, </type> <institution> Department of Computer Science, University of Illinois at Urbana-Champaign, </institution> <year> 1990. </year>
Reference-contexts: Table 1 shows the time per iteration when using a preconditioned CG method to solve a Poisson problem with Dirichlet boundary conditions on a T-shaped domain. Much of the above work is described in <ref> [28] </ref>. 2.4 Parallel parabolic solvers (E. Gallopoulos) Much of this work was conducted in collaboration with Y. Saad. The two methods under investigation are a Krylov subspace method and a method based upon high-order rational approximations of the exponential [43, 40, 42].
Reference: [29] <author> R. FREUND, </author> <title> On conjugate gradient type methods and polynomial preconditioners for a class of complex non-Hermitian matrices, </title> <journal> Numer. Math., </journal> <volume> 57 (1990), </volume> <pages> pp. 285-312. </pages>
Reference-contexts: For multi-dimensional problems, we use iterative methods. For A symmetric, we implemented on Cedar CG type schemes designed to handle complex symmetric systems (B + I)x = y <ref> [29] </ref>. <p> The timesteps considered were 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05 and 0.1. The problem was solved on Cedar, with one one system assigned per cluster. Each system is solved by means of the methods of <ref> [29] </ref>. At the beginning of each step (point B), the current state vector U (n) is in global memory. It is then copied into each cluster memory, and each cluster solves its corresponding linear system (point B.1).
Reference: [30] <author> K. GALLIVAN, D. GANNON, W. JALBY, A. MALONY, AND H. WIJSHOFF, </author> <title> Behavioral characterization of multiprocessor memory systems: A case study, </title> <journal> IEEE Trans. Softw. Eng., </journal> <month> 16 (Feb. </month> <year> 1990), </year> <pages> pp. 216-223. </pages>
Reference-contexts: Much of this work also led to useful design principles for parallel programs on hierarchical memory machines <ref> [34, 33, 44, 30] </ref>. Our current work is directed toward developing parallel algorithms for sparse matrix computations, ranging from sparse BLAS primitives ([66]) to novel iterative methods and algorithms for the parallel solution of partial differential equations.
Reference: [31] <author> K. GALLIVAN, G. HUNG, AND R. SALEH, </author> <title> Performance analysis of a relaxation-based circuit simulation algorithm. In preparation for submission to IEEE Transactions on CAD. [32] , Parallel circuit simulation using nonlinear relaxation. </title> <booktitle> Submitted to International Symposium on Circuits and Systems, </booktitle> <year> 1991. </year>
Reference-contexts: This code made use of the DSPACK sparse direct solver described in Section 2.5. The second parallel circuit simulation package is based on waveform relaxation and forms a natural complement to the above direct method <ref> [32, 31, 36, 46, 47, 59, 60, 67] </ref>. This work is directed by G.-C. Yang, K. Gallivan in collaboration with members of the Electrical and Computer Engineering Department. 3.2 SAP IV, WHAMS, COMMIX and N3S The SAS algorithm of H.-C.
Reference: [33] <author> K. GALLIVAN, W. JALBY, AND D. GANNON, </author> <title> On the problem of optimizing data transfers for complex memory systems, </title> <booktitle> Proc. of 1988 Int'l. Conf. on Supercomputing, </booktitle> <address> St. Malo, France, </address> <month> (July </month> <year> 1988), </year> <pages> pp. 238-253. 14 </pages>
Reference-contexts: Much of this work also led to useful design principles for parallel programs on hierarchical memory machines <ref> [34, 33, 44, 30] </ref>. Our current work is directed toward developing parallel algorithms for sparse matrix computations, ranging from sparse BLAS primitives ([66]) to novel iterative methods and algorithms for the parallel solution of partial differential equations.
Reference: [34] <author> K. GALLIVAN, W. JALBY, A. MALONY, AND H. WIJSHOFF, </author> <title> Performance prediction of loop constructs on multiprocessor hierarchical memory systems, </title> <booktitle> Proc. Third Int'l. Conf. on Supercomputing, </booktitle> <address> Crete, Greece, </address> <month> (June </month> <year> 1989), </year> <pages> pp. 433-442. </pages>
Reference-contexts: Much of this work also led to useful design principles for parallel programs on hierarchical memory machines <ref> [34, 33, 44, 30] </ref>. Our current work is directed toward developing parallel algorithms for sparse matrix computations, ranging from sparse BLAS primitives ([66]) to novel iterative methods and algorithms for the parallel solution of partial differential equations.
Reference: [35] <author> K. GALLIVAN, W. JALBY, U. MEIER, AND A. SAMEH, </author> <title> The impact of hierarchical memory systems on linear algebra algorithm design, </title> <journal> International J. Supercomputer Applications, </journal> <month> 2 </month> <year> (1988). </year>
Reference-contexts: this conference and [54]. 1 2 Current research in numerical algorithms Much of the algorithmic work during the first few years of CSRD was devoted in the study, formulation and design of algorithms for dense linear algebra computations on hierarchical memory multiprocessors, and in particular the one cluster of Cedar <ref> [5, 35, 53] </ref>. Much of this work also led to useful design principles for parallel programs on hierarchical memory machines [34, 33, 44, 30].
Reference: [36] <author> K. GALLIVAN, P. KOSS, S. LO, AND R. A. SALEH, </author> <title> Comparison of parallel relaxation-based circuit simulation techniques, in Professional Program Session Record 43: Simulation of Analog and Mixed-Mode Circuits, </title> <type> Electro '88, </type> <month> May </month> <year> 1988., </year> <pages> pp. 1-6. </pages>
Reference-contexts: This code made use of the DSPACK sparse direct solver described in Section 2.5. The second parallel circuit simulation package is based on waveform relaxation and forms a natural complement to the above direct method <ref> [32, 31, 36, 46, 47, 59, 60, 67] </ref>. This work is directed by G.-C. Yang, K. Gallivan in collaboration with members of the Electrical and Computer Engineering Department. 3.2 SAP IV, WHAMS, COMMIX and N3S The SAS algorithm of H.-C.
Reference: [37] <author> K. GALLIVAN, B. MARSOLF, AND H. WIJSHOFF, </author> <title> A large-grain parallel sparse system solver, </title> <booktitle> in Procs. Fourth SIAM Conf. Parallel Processing for Scientific Computing, </booktitle> <address> Chicago, IL, </address> <year> 1989. </year>
Reference-contexts: of time dependent problems on hierarchically organized parallel computers. 2.5 Sparse linear systems: Direct methods Gallivan, Marsolf and Wijshoff have investigated the use of a new hybrid ordering technique, and an associated factorization algorithm for unsymmetric unstructured sparse linear systems on multiprocessor architectures such as Cedar and the Cray 2 <ref> [37, 66] </ref>. This algorithm, called MCSPARSE, exploits large grain parallelism and divides the problem into partitions which are processed by each of the clusters or processors. On Cedar, finer granularity parallelism is also used within a cluster. For more details we refer to H. Wijshoff's presentation in this Conference.
Reference: [38] <author> K. GALLIVAN, A. SAMEH, AND Z. ZLATEV, </author> <title> A parallel hybrid sparse linear system solver, </title> <booktitle> Computing Systems in Engineering, </booktitle> <month> 1 (June </month> <year> 1990), </year> <pages> pp. </pages> <month> 183-195. </month> <title> [39] , Solving general sparse linear systems using conjugate gradient-type methods, </title> <booktitle> in Proc. of 1990 Int'l. Conference on Supercomputing, </booktitle> <address> Amsterdam, The Netherlands, </address> <month> June </month> <year> 1990, </year> <pages> pp. 132-139. </pages>
Reference-contexts: Gallivan, A. Sameh) In collaboration with Z. Zlatev, the use of a hybrid of direct and iterative method techniques to implement a robust sparse system solver for general sparse matrices was investigated, <ref> [39, 38] </ref>.The algorithm uses a combination of direct methods and preconditioned CG-type methods for unsymmetric systems. The preconditioners are generated via numerical dropping as opposed to the more standard positional dropping.

Reference: [44] <author> D. GANNON, W. JALBY, AND K. GALLIVAN, </author> <title> Strategies for cache and local memory management by global program transformation, </title> <booktitle> Jour. Parallel and Distributed Computing, </booktitle> <month> 5 (October </month> <year> 1988), </year> <pages> pp. 587-616. </pages>
Reference-contexts: Much of this work also led to useful design principles for parallel programs on hierarchical memory machines <ref> [34, 33, 44, 30] </ref>. Our current work is directed toward developing parallel algorithms for sparse matrix computations, ranging from sparse BLAS primitives ([66]) to novel iterative methods and algorithms for the parallel solution of partial differential equations.
Reference: [45] <author> D. HO, F. CHATELIN, AND M. BENNANI, </author> <title> Arnoldi-Tchebychev procedure for large scale nonsymmetric matrices. </title> <note> To appear in Math. Mod. Numer. Anal., </note> <year> 1988. </year>
Reference-contexts: Preliminary experiments show the effectiveness of the Chebyshev-Arnoldi scheme outlined in <ref> [45] </ref>. Several parallel schemes have also been developed for handling sparse singular-value problems arising in information retrieval and nonlinear inverse problems in seismic reflection tomography applications. Four parallel algorithms have been developed for obtaining extreme singular values only or singular triplets, [6].
Reference: [46] <author> G.-G. HUNG, </author> <title> Parallel circuit simulation using nonlinear relaxation, </title> <type> master's thesis, </type> <institution> University of Illinois at Urbana-Champaign, Department of Electrical and Computer Engineering, </institution> <month> January </month> <year> 1991. </year>
Reference-contexts: This code made use of the DSPACK sparse direct solver described in Section 2.5. The second parallel circuit simulation package is based on waveform relaxation and forms a natural complement to the above direct method <ref> [32, 31, 36, 46, 47, 59, 60, 67] </ref>. This work is directed by G.-C. Yang, K. Gallivan in collaboration with members of the Electrical and Computer Engineering Department. 3.2 SAP IV, WHAMS, COMMIX and N3S The SAS algorithm of H.-C.
Reference: [47] <author> G.-G. HUNG, Y.-C. WEN, K. GALLIVAN, AND R. SALEH, </author> <title> Parallel circuit simulation using hierarchical relaxation, </title> <booktitle> in Proc. 27th Design Automation Conference, </booktitle> <address> Orlando, FL, </address> <month> June </month> <year> 1990, </year> <pages> pp. 394-399. </pages> <note> (Also CSRD Report No. 1014). </note>
Reference-contexts: This code made use of the DSPACK sparse direct solver described in Section 2.5. The second parallel circuit simulation package is based on waveform relaxation and forms a natural complement to the above direct method <ref> [32, 31, 36, 46, 47, 59, 60, 67] </ref>. This work is directed by G.-C. Yang, K. Gallivan in collaboration with members of the Electrical and Computer Engineering Department. 3.2 SAP IV, WHAMS, COMMIX and N3S The SAS algorithm of H.-C.
Reference: [48] <author> J.-S. JWO, S. LAKSHMIVARAHAN, S. K. DHALL, AND J. M. LEWIS, </author> <title> Comparison of performance of three parallel versions of the block cyclic reduction algorithm for solving linear elliptic partial differential equations, </title> <journal> Comput. Math. Appl., </journal> <month> 24 (Sep. </month> <year> 1992), </year> <pages> pp. 83-101. 15 </pages>
Reference: [49] <author> S. KACZMARZ, Angenaherte auflosung von systemen linearer gleichungen, Bull. </author> <note> intern. </note> <institution> Acad. polonaise Sci. lettres (Cracouie); Class sci. math. natur.: Seira A. Sci. Math., </institution> <year> (1939), </year> <pages> pp. 355-357. </pages>
Reference-contexts: Two general classes of RP methods have been examined, the product or Kaczmarz <ref> [49] </ref> and sum or Cimmino [24] forms.
Reference: [50] <author> C. KAMATH, </author> <title> Solution of nonsymmetric systems of equations on a multiprocessor, </title> <type> Tech. Report 591, </type> <institution> Center for Supercomputing Research and Development, University of Illinois at Urbana-Champaign, </institution> <year> 1986. </year>
Reference-contexts: This approach can also be used to solve large sparse unstructured least squares problems. 2.6.3 Block Projection Methods (R. Bramley, U. Meier, A. Sameh) In a series of papers <ref> [50, 51, 10, 14, 12, 11, 13, 15] </ref>, block projection methods have been developed as robust, parallel solvers for structured linear systems. <p> Two general classes of RP methods have been examined, the product or Kaczmarz [49] and sum or Cimmino [24] forms. Both iterative forms are accelerated using conjugate gradients, as initially suggested by in [7] and developed as effective parallel solvers for two-dimensional problems in <ref> [50] </ref>. 8 Apart from covering the theoretical foundation of the methods, we have developed an approach to finding row partitionings that allow parallelism in the computations [14].
Reference: [51] <author> C. KAMATH AND A. SAMEH, </author> <title> A projection method for solving nonsymmetric linear systems on multiprocessors, </title> <booktitle> Parallel Computing, 9 (1988), </booktitle> <pages> pp. 291-312. </pages>
Reference-contexts: This approach can also be used to solve large sparse unstructured least squares problems. 2.6.3 Block Projection Methods (R. Bramley, U. Meier, A. Sameh) In a series of papers <ref> [50, 51, 10, 14, 12, 11, 13, 15] </ref>, block projection methods have been developed as robust, parallel solvers for structured linear systems.
Reference: [52] <author> T. KERKHOVEN, A. GALICK, J. ARENDS, U. RAVAIOLI, AND Y. SAAD, </author> <title> Efficient numerical simulation of electron states in quantum wires, 1989. </title> <journal> To appear in Journal of the American Physical Society. </journal> <note> Also CSRD Report 933. </note>
Reference-contexts: Berry, A. Galick, A. Sameh) Rutishauser's subspace iteration was successfully applied to handle large symmetric generalized eigenvalue problems that arise from solving Schrodinger's equation which, in turn, arises from modeling semiconductor devices. In such eigenvalue problems one seeks the smallest eigenpairs, e.g. see <ref> [52] </ref>. Related semiconductor device simulation problems give rise to nonsymmetric generalized eigenvalue problems Ax = Bx 9 where B is symmetric positive definite and A is a perturbed symmetric matrix where the nonsymmetric perturbation can be either of low rank or of small magnitude.
Reference: [53] <author> T. KERKHOVEN, A. GALICK, J. ARENDS, U. RAVAIOLI, AND Y. SAAD, </author> <title> Efficient numerical simulation of electron states in quantum wires, </title> <journal> To appear in Journal of the American Physical Society, </journal> <month> (October </month> <year> 1989). </year>
Reference-contexts: this conference and [54]. 1 2 Current research in numerical algorithms Much of the algorithmic work during the first few years of CSRD was devoted in the study, formulation and design of algorithms for dense linear algebra computations on hierarchical memory multiprocessors, and in particular the one cluster of Cedar <ref> [5, 35, 53] </ref>. Much of this work also led to useful design principles for parallel programs on hierarchical memory machines [34, 33, 44, 30].
Reference: [54] <author> D. J. KUCK, E. S. DAVIDSON, D. L. LAWRIE, AND A. H. SAMEH, </author> <title> Parallel supercomputing today and the Cedar approach, </title> <booktitle> Science, 231 (1986), </booktitle> <pages> pp. 967-974. </pages>
Reference-contexts: In the remainder of this paper we will review some of these activities and point to our collaborative research efforts. 1. For details about Cedar see the companion presentation of A. Veidenbaum in this conference and <ref> [54] </ref>. 1 2 Current research in numerical algorithms Much of the algorithmic work during the first few years of CSRD was devoted in the study, formulation and design of algorithms for dense linear algebra computations on hierarchical memory multiprocessors, and in particular the one cluster of Cedar [5, 35, 53].
Reference: [55] <author> G. LOU, </author> <title> Parallel methods for solving linear systems via decomposition, </title> <type> Tech. Report CSRD No. 1065, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> December </month> <year> 1990. </year>
Reference-contexts: Sameh, D. Semeraro) In view of our interest in computational fluid dynamics applications we have been working on methods for solving the indefinite system of equations arising from the discretization of the Stokes problem and other applications. For a survey of this work we point to [15] and <ref> [55] </ref>. 2.6.6 Sparse eigenvalue and singular-value problem solvers (M. Berry, A. Galick, A. Sameh) Rutishauser's subspace iteration was successfully applied to handle large symmetric generalized eigenvalue problems that arise from solving Schrodinger's equation which, in turn, arises from modeling semiconductor devices.
Reference: [56] <author> U. MEIER AND R. EIGENMANN, </author> <title> Parallelization and performance evaluation of some preconditioned conjugate gradient schemes on cedar, </title> <type> Tech. Report CSRD No. 1035, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <month> April </month> <year> 1991. </year>
Reference-contexts: In some cases the speedups were remarkable, e.g. greater than 4 from one to four clusters. Although the code from explicit manual parallelization is currently 50% faster than that from automatic paral-lelization, further work promises to yield performance close to that gained by manual redesign of the code <ref> [56] </ref>. 2.6.2 A Hybrid Sparse System Solver (K. Gallivan, A. Sameh) In collaboration with Z.
Reference: [57] <author> U. MEIER AND A. SAMEH, </author> <title> The behavior of conjugate gradient algorithms on a multivector processor with a hierarchical memory, </title> <journal> J. Comput. Appl. Math., </journal> <volume> 24 (1988), </volume> <pages> pp. 13-32. </pages>
Reference-contexts: Experiments on an Alliant FX/8 had shown that the performance of iterative methods on one cluster is limited by its cache size <ref> [57] </ref>. But the use of Cedar resulted in an improvement in performance. Cache misses could be decreased significantly by distributing the data across clusters and handling smaller chunks on each cluster.
Reference: [58] <author> N. PINARDI AND A. NAVARRA, </author> <title> A brief review of global Mediterranean wind-driven general circulation experiments, </title> <booktitle> in Proc. second POEM Workshop, </booktitle> <editor> A. R. Robinson, ed., Trieste, </editor> <address> Italy, </address> <year> 1989. </year>
Reference-contexts: The vehicles for the experiments are Cedar and the GFDL ocean circulation code, adapted at IMGA (Mod-ena, Italy) for the simulation of the Mediterranean basin <ref> [58] </ref>. Computational ocean simulation is an important component of two of the Grand Challenges outlined recently in [1]. We hope that our work will lead to better understanding in those areas. Different partitionings and storage allocation for the data are being tried.
Reference: [59] <author> R. SALEH, K. GALLIVAN, M. CHANG, I. HAJJ, D. SMART, AND T. </author> <title> TRICK, Parallel circuit simulation on supercomputers, </title> <booktitle> Proceedings of IEEE, </booktitle> <month> 77 (December </month> <year> 1989), </year> <pages> pp. 1915-1931. </pages> <note> (Also CSRD Report No. 898). </note>
Reference-contexts: This code made use of the DSPACK sparse direct solver described in Section 2.5. The second parallel circuit simulation package is based on waveform relaxation and forms a natural complement to the above direct method <ref> [32, 31, 36, 46, 47, 59, 60, 67] </ref>. This work is directed by G.-C. Yang, K. Gallivan in collaboration with members of the Electrical and Computer Engineering Department. 3.2 SAP IV, WHAMS, COMMIX and N3S The SAS algorithm of H.-C.
Reference: [60] <author> R. SALEH, D. WEBBER, E. XIA, AND A. SANGIOVANNI-VINCENTELLI, </author> <title> Parallel waveform-Newton algorithms for circuit simulation, </title> <booktitle> in Proc. International Conference on Computer Design, Port Chester, </booktitle> <address> New York, </address> <month> October </month> <year> 1987. </year>
Reference-contexts: This code made use of the DSPACK sparse direct solver described in Section 2.5. The second parallel circuit simulation package is based on waveform relaxation and forms a natural complement to the above direct method <ref> [32, 31, 36, 46, 47, 59, 60, 67] </ref>. This work is directed by G.-C. Yang, K. Gallivan in collaboration with members of the Electrical and Computer Engineering Department. 3.2 SAP IV, WHAMS, COMMIX and N3S The SAS algorithm of H.-C.
Reference: [61] <author> A. SAMEH AND J. WISNIEWSKI, </author> <title> A trace minimization algorithm for the generalized eigenvalue problem, </title> <journal> SIAM Journ. Numer. Anal., </journal> <month> 19 (December </month> <year> 1982.), </year> <pages> pp. 1243-1259. </pages>
Reference-contexts: Four parallel algorithms have been developed for obtaining extreme singular values only or singular triplets, [6]. These are the single vector Lanczos algorithms with selective reorthogonalization, block Lanczos with complete reorthogonalization, Rutishauser's subspace iteration, and trace minimization <ref> [61] </ref>. Polynomial acceleration has played a vital role in producing effective parallel schemes. 2.7 Automatic program instrumentation with applications in performance and error analysis (B. Bliss, M.-C. Brunet, E.
Reference: [62] <author> S. SERBIN, </author> <title> On factoring a class of complex symmetric matrices without pivoting, </title> <journal> Math. Comp., </journal> <volume> 35 (1980), </volume> <pages> pp. 1231-1234. </pages>
Reference-contexts: In particular, assume m is even and ff fi. Then (A ffI) + fiI is symmetric but non-Hermitian. For example, in the case of Pade, A ffI is symmetric positive definite, and a direct method (e.g. algorithm D of [16]) can be applied without pivoting <ref> [62] </ref>. In the case of uniform approximation, we note that whenever ff is larger than 0, thus possibly leading to a symmetric but indefinite matrix (A ffI), fi (the imaginary part of the shift) is not close to zero.
Reference: [63] <author> P. N. SWARZTRAUBER, </author> <title> Approximate cyclic reduction for solving Poisson's equation, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <month> 8 (May </month> <year> 1987), </year> <pages> pp. 199-209. </pages>
Reference: [64] <author> R. A. SWEET, </author> <title> A parallel and vector cyclic reduction algorithm, </title> <journal> SIAM J. Sci. Statist. Comput., </journal> <month> 9 (July </month> <year> 1988), </year> <pages> pp. 761-765. 16 </pages>
Reference-contexts: The notation (C; P; K) for Cedar implies the use of a maximum of C clusters of P processors each, with a total global memory of K Mbytes. 2 2.3 Rapid Elliptic Solvers (E. Gallopoulos and G. Frank) Parallel block cyclic reduction (PBCR) was introduced independently in [41] and <ref> [64] </ref>. It is a method which avoids the sequential bottleneck in the BCR algorithm 3 heavily utilized in packages such as FISHPAK to solve systems arising from the discretization of separable elliptic equations and domain decomposition.
Reference: [65] <author> B. </author> <type> THOMAS, </type> <institution> Projet N3S de mecanique des fluides, manuel d'utilisation de la version 3.0, Departement Mecaniqu et Modeles Numericques HI-72/70.38, Elec-tricite de France, Direction Des Etudes Et Recherches, 1, Avenue de General de Gaulle, </institution> <address> 92141 Clamart Cedex, </address> <year> 1990. </year>
Reference-contexts: A similar effort is being undertaken for N3S, a 3D FEM code for thermal hydraulic problems <ref> [19, 65] </ref>. 3.3 Ocean circulation Derose, Gallivan and Gallopoulos investigate the problem of mapping numerical simulations of ocean circulation onto parallel architectures [25, 26]. Our objective is to design algorithms which allow for more efficient and hence more detailed and accurate simulations.
Reference: [66] <author> H. WIJSHOFF, </author> <title> Symmetric orderings for unsymmetric sparse matrices, </title> <type> Tech. Report CSRD No. 901, </type> <institution> University of Illinois at Urbana-Champaign, Center for Supercomputing Research and Development, </institution> <year> 1989. </year> <note> Submitted to SIAM SISSC. </note>
Reference-contexts: of time dependent problems on hierarchically organized parallel computers. 2.5 Sparse linear systems: Direct methods Gallivan, Marsolf and Wijshoff have investigated the use of a new hybrid ordering technique, and an associated factorization algorithm for unsymmetric unstructured sparse linear systems on multiprocessor architectures such as Cedar and the Cray 2 <ref> [37, 66] </ref>. This algorithm, called MCSPARSE, exploits large grain parallelism and divides the problem into partitions which are processed by each of the clusters or processors. On Cedar, finer granularity parallelism is also used within a cluster. For more details we refer to H. Wijshoff's presentation in this Conference.
Reference: [67] <author> E. XIA AND R. SALEH, </author> <title> Parallel waveform-Newton algorithms for circuit simulation. </title> <note> To appear IEEE Trans. on CAD, Fall 1991. </note>
Reference-contexts: This code made use of the DSPACK sparse direct solver described in Section 2.5. The second parallel circuit simulation package is based on waveform relaxation and forms a natural complement to the above direct method <ref> [32, 31, 36, 46, 47, 59, 60, 67] </ref>. This work is directed by G.-C. Yang, K. Gallivan in collaboration with members of the Electrical and Computer Engineering Department. 3.2 SAP IV, WHAMS, COMMIX and N3S The SAS algorithm of H.-C.
Reference: [68] <author> G.-C. YANG, </author> <title> PARASPICE: A portable parallel circuit simulator, </title> <booktitle> in Advances in electrical Engineering software (ELECTROSOFT 90), Proceedings of the First Int'l. Conference on Elec. Eng. Analysis and Design, </booktitle> <address> Lowell, MA, </address> <publisher> S.-V. </publisher> <pages> P.P. </pages> <address> Sil-vester, </address> <publisher> Computational Mechanics Publications, ed., </publisher> <month> August </month> <year> 1990, </year> <pages> pp. 3-14. 17 </pages>
Reference-contexts: We next outline some current achievements. 3.1 Circuit simulation Two parallel circuit simulators were recently designed for the Alliant FX/80 and Cedar. The first is a parallel version of Berkeley's SPICE2G.6 <ref> [68] </ref>. The original code was completely redesigned to yield a speedup of 4.53 (out of a maximum of 8) compared to 10 SPICE2G.6 on 1 CE of the Alliant FX/80 for a collection of a standard set of benchmark circuits.
References-found: 57

