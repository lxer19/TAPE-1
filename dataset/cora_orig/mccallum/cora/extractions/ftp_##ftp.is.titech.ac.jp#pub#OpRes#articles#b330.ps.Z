URL: ftp://ftp.is.titech.ac.jp/pub/OpRes/articles/b330.ps.Z
Refering-URL: http://plato.la.asu.edu/guide.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Email: e-mail: fujisawa@is-mj.archi.kyoto-u.ac.jp  e-mail: mituhiro@is.titech.ac.jp  e-mail: kojima@is.titech.ac.jp  
Title: Numerical Evaluation of SDPA (SemiDefinite Programming Algorithm).  
Author: Katsuki Fujisawa Mituhiro Fukuda Masakazu Kojima Kazuhide Nakata 
Keyword: Key words Interior-Point Methods, Semidefinite Programming, Numerical Experiments, Sparsity  
Address: Honmati, Sakyou-ku, Kyoto, 606-8501, Japan.  ogy, 2-12-1 Oh-Okayama, Meguro-ku, Tokyo 152-8552, Japan.  ogy, 2-12-1 Oh-Okayama, Meguro-ku, Tokyo 152-8552, Japan.  K.K., Yoga, Setagaya-ku, Tokyo 1580-8633, Japan.  
Affiliation: Department of Architecture and Architectural Systems, Kyoto University, Yoshida  Department of Mathematical and Computing Sciences, Tokyo Institute of Technol  Department of Mathematical and Computing Sciences, Tokyo Institute of Technol  Nihon Sun Microsystems  
Date: September 1997 Revised on June 1998  
Abstract: SDPA (SemiDefinite Programming Algorithm) is a C++ implementation of a Mehrotra-type primal-dual predictor-corrector interior-point method for solving the standard form semidefinite program and its dual. We report numerical results of large scale problems to evaluate its performance, and investigate how major time-consuming parts of SDPA vary with the problem size, the number of constraints and the sparsity of data matrices. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> F. Alizadeh, J.-P.A. </author> <title> Haeberly and M.L. Overton, "Primal-dual interior-point methods for semidefinite programming," </title> <note> Working Paper, </note> <year> 1994. </year>
Reference-contexts: The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4. Although three types of search directions, the HRVW/KSH/M direction [11, 13, 16], the NT direction [18, 19, 21] and the AHO direction <ref> [1, 2] </ref> are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the method proposed by Fujisawa et al. [7]. <p> Let (X; y; Z) denote a current iterate satisfying X O and Z O, and (dX; dy; dZ) be a search direction. Then the primal step length ff p is computed as follows: ff p = maxfff 2 <ref> [0; 1] </ref> : X + ffdX - Og and ff p = fl ff p ; where fl 2 (0; 1) denotes a prescribed parameter. Applying the Cholesky factorization to the positive definite matrix X, we have an nfin lower triangular matrix L such that X = LL T . <p> Applying the Cholesky factorization to the positive definite matrix X, we have an nfin lower triangular matrix L such that X = LL T . Then we can rewrite ff p as ff p = maxfff 2 <ref> [0; 1] </ref> : I + ffL 1 dXL T - Og; = minf1=~ min ; 1g if ~ min &lt; 0; 1 otherwise, where ~ min denotes the minimum eigenvalue of L 1 dXL T , which coincides with the min imum eigenvalue of X 1 dX. <p> Note that X *Z=n coincides with the mean of all the (positive) eigenvalues of XZ and that it approaches 0 whenever (X; y; Z) tends to a solution of the SDP (1). If this measure exceeds a prescribed parameter ffi 2 <ref> [0; 1] </ref>, SDPA performs "a centering procedure." Note that the minimum eigenvalue of XZ coincides with the minimum eigenvalue of the symmetric matrix L T ZL, where X = LL T denotes the Cholesky factorization of X.
Reference: [2] <author> F. Alizadeh, J.-P.A. </author> <title> Haeberly and M.L. Overton, "Primal-dual interior-point methods for semidefinite programming: convergence rates, stability and numerical results," </title> <type> Report 721, </type> <institution> Computer Science Dept., </institution> <address> New York University, New York, </address> <month> May </month> <year> 1996, </year> <note> to appear in SIAM Journal on Optimization. </note>
Reference-contexts: The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4. Although three types of search directions, the HRVW/KSH/M direction [11, 13, 16], the NT direction [18, 19, 21] and the AHO direction <ref> [1, 2] </ref> are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the method proposed by Fujisawa et al. [7].
Reference: [3] <author> F. Alizadeh, J.-P.A. Haeberly, M.V. Nayakkankuppam, M.L. Overton and S. Schmieta, </author> <note> "SDPpack - User's Guide -," Comp. </note> <institution> Sci. Dept., </institution> <address> New York University, New York, </address> <month> June </month> <year> 1997. </year> <note> Available at http://cs.nyu.edu/cs/faculty/overton/sdppack/sdppack.html. </note>
Reference-contexts: 1. Introduction. The main purpose of this paper is to evaluate the performance of SDPA (SemiDefinite Programming Algorithm) [6] for semidefinite programs. Besides SDPA, there are some computer programs SDPpack <ref> [3] </ref>, SDPSOL [27], CSDP [5], SDPHA [20] and SDPT3 [22] for semidefinite programs which are available through the Internet. Among others, we mainly compare SDPA with SDPT3 through numerical experiments on several types of test problems. Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method.
Reference: [4] <author> S. J. Benson, Y. Ye and X. Zhang, </author> <title> "Solving large-scale sparse semidefinite programs for combinatorial optimization," </title> <institution> Applied Mathematics and Computer Sciences, The University of Iowa, </institution> <address> Iowa City, Iowa 52242, </address> <month> September </month> <year> 1997. </year>
Reference-contexts: See <ref> [4] </ref>. The SDP relaxation (11) of the graph equipartition problem involves n fi n matrices E ii (1 i n) having one nonzeros and the n fi n matrix E having all elements 1 in the constraint.
Reference: [5] <author> B. Borchers, "CSDP, </author> <title> a C library for semidefinite programming," </title> <institution> Department of Mathematics, New Mexico Institute of Mining and Technology, 801 Leroy Place Socorro, </institution> <address> New Mexico 87801, </address> <month> March </month> <year> 1997. </year> <note> Available at http://www.nmt.edu/~borchers/csdp.html. </note>
Reference-contexts: 1. Introduction. The main purpose of this paper is to evaluate the performance of SDPA (SemiDefinite Programming Algorithm) [6] for semidefinite programs. Besides SDPA, there are some computer programs SDPpack [3], SDPSOL [27], CSDP <ref> [5] </ref>, SDPHA [20] and SDPT3 [22] for semidefinite programs which are available through the Internet. Among others, we mainly compare SDPA with SDPT3 through numerical experiments on several types of test problems. Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method.
Reference: [6] <author> K. Fujisawa, M. Kojima and K. Nakata, </author> <title> "SDPA (Semidefinite Programming Algorithm) - User's Manual -," Technical Report B-308, </title> <institution> Department of Mathematical and Computing Sciences, Tokyo Institute of Technology, </institution> <address> Oh-Okayama, Meguro, Tokyo 152, Japan, </address> <month> December </month> <year> 1995, </year> <note> Revised August 1996. Available at ftp://ftp.is.titech.ac.jp/pub/OpRes/software/SDPA. </note>
Reference-contexts: 1. Introduction. The main purpose of this paper is to evaluate the performance of SDPA (SemiDefinite Programming Algorithm) <ref> [6] </ref> for semidefinite programs. Besides SDPA, there are some computer programs SDPpack [3], SDPSOL [27], CSDP [5], SDPHA [20] and SDPT3 [22] for semidefinite programs which are available through the Internet. Among others, we mainly compare SDPA with SDPT3 through numerical experiments on several types of test problems. <p> We report the number of iterations and the computation time required for an approximate solution with a relative duality gap less than a given accuracy between 10 5 and 10 8 . The second issue is a comparison between SDPA <ref> [6] </ref> and SDPT3 [22] through numerical experiments. Both software packages are based on the Mehrotra-type primal-dual predictor-corrector interior-point method although some parameters to control predictor search directions and step lengths are slightly different.
Reference: [7] <author> K. Fujisawa, M. Kojima and K. Nakata, </author> <title> "Exploiting sparsity in primal-dual interior-point methods for semidefinite programming," </title> <note> Mathematical Programming 79 (1997) 235-253. </note>
Reference-contexts: 19, 21] and the AHO direction [1, 2] are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the method proposed by Fujisawa et al. <ref> [7] </ref>. Monteiro et al. [17] recently showed that in theory, the NT direction requires less computation for dense matrices. However, their method needs large amount of computational memory and does not efficiently exploit the sparse data structures. <p> The main differences between SDPA and SDPT3 are: (a) The programming languages used for SDPA and SDPT3 are different; the former is written in C++ while the latter is written in MATLAB. (b) SDPA incorporates dense and sparse matrix data structures and an efficient method proposed by <ref> [7] </ref> for computing search directions when the problem is large scale and sparse. When the problem is dense, SDPA is a few times faster than SDPT3 mainly because of the reason (a). The feature (b) of SDPA is crucial in solving large scale sparse problems. <p> Therefore computing the coefficient matrix B is more crucial than solving Bdy = b in the entire computation of the HRVW/KSH/M direction. In their paper <ref> [7] </ref>, Fujisawa, Kojima and Nakata proposed three distinct formulae F 1 , F 2 and F 3 for computing B, and their efficient combination F fl . <p> They demonstrated through numerical experiments that the combined formula F fl worked very efficiently when some of A i (1 i m) are sparse. We incorporated their formula F fl into SDPA. See the paper <ref> [7] </ref> for more details. 2.2 Approximation of the Minimum Eigenvalue of a Symmetric Matrix. There are some places where we need to compute the minimum eigenvalue of a symmetric matrix in SDPA. One is the place where we compute the primal and dual step lengths. <p> For such sparse problems, the efficient method <ref> [7] </ref> referred in Section 2.1 is expected to work effectively. In fact, we observe that SDPA solved both types of problems much faster than SDPT3. <p> case, SDPA effectively utilizes the sparsity of data matrices A i (1 i m) for (I) computation of the m fi m dense positive definite matrix B to reduce the number of arithmetic operations to O (m 2 f 2 ) by applying formula F 3 proposed in the paper <ref> [7] </ref>, while SDPA still needs O (m 3 ), O (n 3 +mf ) and O (n 3 ) arithmetic operations for Table 17: Numerical results on maximum clique problems. time (sec.) iterations relative gap n m SDPA SDPT3 SDPA SDPT3 SDPA SDPT3 50 132 2.8 49.8 15 15 7.43e-09 6.37e-10 <p> A standard technique to resolve such a difficulty is to use the conjugate gradient method to solve the system Bdy = b of equations approximately; it is carried out without storing the entire matrix B (see Concluding Remark (C) of <ref> [7] </ref>, also [12, 15, 25, 26]). We report some preliminary but promising numerical results on the use of the conjugate gradient method in Table 19. We solved SDP relaxations of maximum clique problems with n = 100; 200; 400; 500 on DEC Alpha (CPU 21164-300MHz with 256MB memory).
Reference: [8] <author> P. Gahinet and A. </author> <title> Nemirovski, "The projective method for solving linear matrix inequalities.", </title> <note> Mathematical Programming 77 (1997) 163-190. </note>
Reference-contexts: This observation is due to C. Helmberg and S. Karisch. See [10] Other papers also observed the importance of exploiting different kinds of structure <ref> [8, 25] </ref>. Acknowledgment. Part of this paper was presented at the HPOPT workshop (August 19 - 22, 1997) which was held in Rotterdam, the Netherlands. Three of the authors, Fujisawa, Fukuda and Kojima attended the workshop.
Reference: [9] <author> G. H. Goulb and C. F. Van Loan, </author> <title> Matrix Computations (second edition), </title> <publisher> (The John Hopkins University Press, </publisher> <address> Baltimore, Maryland, </address> <year> 1989). </year>
Reference-contexts: Our method is known as the bisection method for finding eigenvalues of a symmetric tridiagonal matrix. Applying the Householder tridiagonalization to U , we first transform U to a symmetric tridiagonal matrix T having the same eigenvalues as U (see, for example, <ref> [9] </ref>). <p> We can compute p r () = det (T r I) by the following recursive formulae: p 0 () = 1; p 1 () = a 1 r p r2 () (2 r n): Theorem 2.1. Sturm Sequence Property <ref> [9, Theorem 8.4-1] </ref> Assume that b r 6= 0 (2 r n). (i) If p r () = 0 for some r 2 f1; 2; . . . ; n 1g, then p r+1 ()p r1 () &lt; 0 (ii) Let 2 R. <p> () if p r1 () 6= 0 and p r ()p r1 () 0 and that p r () has the same sign as p r1 () if p r1 () = 0 or p r ()p r1 () &gt; 0. 4 From the Gerschgorin circle theorem (see, for example, <ref> [9, Theorem 7.2-1] </ref>), we also know that min (T ) 2 [; ] where = min a i jb i j jb i+1 j and = max a i + jb i j + jb i+1 j: (8) Here we assume that b 1 = b n+1 = 0.
Reference: [10] <author> C. Helmberg and F. Rendl, </author> <title> "Solving quadratic (0; 1)-problems by semidefinite programming and cutting planes," </title> <address> SC-95-35, Konrad-Zuse-Zentrum Berlin, Berlin, Germany , 1995 </address>
Reference-contexts: This observation is due to C. Helmberg and S. Karisch. See <ref> [10] </ref> Other papers also observed the importance of exploiting different kinds of structure [8, 25]. Acknowledgment. Part of this paper was presented at the HPOPT workshop (August 19 - 22, 1997) which was held in Rotterdam, the Netherlands. Three of the authors, Fujisawa, Fukuda and Kojima attended the workshop.
Reference: [11] <author> C. Helmberg, F. Rendl, R.J. Vanderbei and H. Wolkowicz, </author> <title> "An interior-point method for semidefinite programming," </title> <note> SIAM Journal on Optimization 6 (1996) 342-361. </note>
Reference-contexts: Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method. The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4. Although three types of search directions, the HRVW/KSH/M direction <ref> [11, 13, 16] </ref>, the NT direction [18, 19, 21] and the AHO direction [1, 2] are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the <p> See <ref> [11, etc.] </ref> for more details. 3.6 Semidefinite Programming Relaxation of Graph Equiparti tion Problem. <p> See <ref> [11, etc.] </ref> for more details. 9 3.7 Semidefinite Relaxation of Maximum Clique Problem. <p> See <ref> [11, etc.] </ref> for more details. Note that this semidefinite program has m = n (n 1)=2 jEj + 1 equality constraints, where jEj denotes the cardinality of the edge set E.
Reference: [12] <author> M. Kojima, M. Shida and S. Shindoh, </author> <title> "Search directions in the SDP and the monotone SDLCP: generalization and inexact computation," </title> <note> to appear in Mathematical Programming. </note>
Reference-contexts: A standard technique to resolve such a difficulty is to use the conjugate gradient method to solve the system Bdy = b of equations approximately; it is carried out without storing the entire matrix B (see Concluding Remark (C) of [7], also <ref> [12, 15, 25, 26] </ref>). We report some preliminary but promising numerical results on the use of the conjugate gradient method in Table 19. We solved SDP relaxations of maximum clique problems with n = 100; 200; 400; 500 on DEC Alpha (CPU 21164-300MHz with 256MB memory).
Reference: [13] <author> M. Kojima, S. Shindoh and S. Hara, </author> <title> "Interior-point methods for the monotone semidef-inite linear complementarity problems," </title> <note> SIAM Journal on Optimization 7 (1997) 86-125. </note>
Reference-contexts: Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method. The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4. Although three types of search directions, the HRVW/KSH/M direction <ref> [11, 13, 16] </ref>, the NT direction [18, 19, 21] and the AHO direction [1, 2] are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the <p> Note that d dX 2 R nfin serves as an auxiliary variable matrix. Under the linear independence assumption on the set fA i : 1 i mg of constraint matrices, we know <ref> [13] </ref> that for any X O, Z O, p i 2 R (1 i m), D 2 S n , and K 2 R nfin , the system of equations (2), (3) and (4) has a unique solution (dX; dy; dZ). <p> Here P and D denote the primal and the dual objective values, respectively. If we detect that there is no feasible solution (X; y; Z) such that ! fl X 0 - X - O and ! fl Z 0 - Z - O; then stop the iteration. See <ref> [13] </ref> for details on how to get such information on infeasibility. Step 2 : (Predictor Step) Let fi p = 0 if the current iterate is feasible, fi otherwise.
Reference: [14] <author> S. Mehrotra, </author> <title> "On the implementation of a primal-dual interior point method," </title> <note> SIAM Journal on Optimization 2 (1992) 575-601. </note>
Reference-contexts: Among others, we mainly compare SDPA with SDPT3 through numerical experiments on several types of test problems. Either of them is an implementation of a Mehrotra-type <ref> [14] </ref> primal-dual predictor-corrector interior-point method. The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4.
Reference: [15] <author> C.-J. Lin and R. Saigal, </author> <title> "Semidefinite Programming and the Quadratic Assignment Problem," </title> <booktitle> 16th International Symposium on Mathematical Programming, </booktitle> <address> Lausanne, Switzerland, </address> <month> August </month> <year> 1997. </year>
Reference-contexts: A standard technique to resolve such a difficulty is to use the conjugate gradient method to solve the system Bdy = b of equations approximately; it is carried out without storing the entire matrix B (see Concluding Remark (C) of [7], also <ref> [12, 15, 25, 26] </ref>). We report some preliminary but promising numerical results on the use of the conjugate gradient method in Table 19. We solved SDP relaxations of maximum clique problems with n = 100; 200; 400; 500 on DEC Alpha (CPU 21164-300MHz with 256MB memory).
Reference: [16] <author> R.D.C. Monteiro, </author> <title> "Primal-dual path-following algorithms for semidefinite programming," </title> <note> SIAM Journal on Optimization 7 (1997) 663-678. </note>
Reference-contexts: Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method. The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4. Although three types of search directions, the HRVW/KSH/M direction <ref> [11, 13, 16] </ref>, the NT direction [18, 19, 21] and the AHO direction [1, 2] are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the
Reference: [17] <author> R.D.C. Monteiro, P.R. Zanjacomo, </author> <title> "Implementation of primal-dual methods for semidefinite programming based on Monteiro and Tsuchiya directions and thier variants," </title> <type> Technical Report, </type> <institution> School Industrial and Systems Engineering, Georgia Tech., </institution> <address> Atlanta, GA 30332, </address> <month> July </month> <year> 1997, </year> <note> Revised August 1997. </note>
Reference-contexts: Monteiro et al. <ref> [17] </ref> recently showed that in theory, the NT direction requires less computation for dense matrices. However, their method needs large amount of computational memory and does not efficiently exploit the sparse data structures. <p> Furthermore, the HRVW/KSH/M direction is faster than the NT direction on all problems. We can also observe the same tendency for the HRVW/KSH/M direction using SDPT3 [21, 22] excepting the ETP Problem. Monteiro and Zanjacomo <ref> [17] </ref> showed similar numerical results. Therefore, we mainly focus our attention on the HRVW/KSH/M direction in this paper. As we have already seen in Section 1, there exists some MATLAB implementations besides SDPT3.
Reference: [18] <author> Yu.E. Nesterov and M.J. Todd, </author> <title> "Self-scaled barriers and interior-point methods in convex programming," </title> <note> Mathematics of Operations Research 22 (1997) 1-42. </note>
Reference-contexts: Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method. The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4. Although three types of search directions, the HRVW/KSH/M direction [11, 13, 16], the NT direction <ref> [18, 19, 21] </ref> and the AHO direction [1, 2] are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the method proposed by Fujisawa et al.
Reference: [19] <author> Yu.E. Nesterov and M.J. Todd, </author> <title> "Primal-dual interior-point methods for self-scaled cones," </title> <note> SIAM J. on Optimization 8 (1988) 324-364. </note>
Reference-contexts: Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method. The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4. Although three types of search directions, the HRVW/KSH/M direction [11, 13, 16], the NT direction <ref> [18, 19, 21] </ref> and the AHO direction [1, 2] are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the method proposed by Fujisawa et al.
Reference: [20] <author> F.A. Potra, R. Sheng and N. Brixius, </author> <title> "SDPHA aMATLAB implementation of homogeneous interior-point algorithms for semidefinite programming," </title> <institution> Department of Mathematics, University of Iowa, </institution> <address> Iowa City, IA 52242, </address> <month> April </month> <year> 1997. </year> <note> Available at http://www.math.uiowa.edu/~rsheng/SDPHA/sdpha.html. </note>
Reference-contexts: 1. Introduction. The main purpose of this paper is to evaluate the performance of SDPA (SemiDefinite Programming Algorithm) [6] for semidefinite programs. Besides SDPA, there are some computer programs SDPpack [3], SDPSOL [27], CSDP [5], SDPHA <ref> [20] </ref> and SDPT3 [22] for semidefinite programs which are available through the Internet. Among others, we mainly compare SDPA with SDPT3 through numerical experiments on several types of test problems. Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method.
Reference: [21] <author> M.J. Todd, K.C. Toh and R.H. Tutuncu, </author> <title> "On the Nesterov-Todd direction in semidef-inite programming," </title> <type> Technical Report, </type> <institution> School of Operations Research and Industrial Engineering, Cornell University, </institution> <address> Ithaca, New York 14853-3801, USA, </address> <month> March </month> <year> 1996, </year> <note> Revised May 1996, to appear in SIAM Journal on Optimization. </note>
Reference-contexts: Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method. The choice of SDPT3 as a competitor of SDPA was based on the preliminary numerical experiments given in Section 4. Although three types of search directions, the HRVW/KSH/M direction [11, 13, 16], the NT direction <ref> [18, 19, 21] </ref> and the AHO direction [1, 2] are available in both of SDPA and SDPT3, we employed the HRVW/KSH/M direction in our numerical experiments because its computation is the cheapest among the three directions (particularly, for sparse data matrices) when we employ the method proposed by Fujisawa et al. <p> The required number of iterations when we employ the HRVW/KSH/M direction is almost the same as when we employ the NT direction. Furthermore, the HRVW/KSH/M direction is faster than the NT direction on all problems. We can also observe the same tendency for the HRVW/KSH/M direction using SDPT3 <ref> [21, 22] </ref> excepting the ETP Problem. Monteiro and Zanjacomo [17] showed similar numerical results. Therefore, we mainly focus our attention on the HRVW/KSH/M direction in this paper. As we have already seen in Section 1, there exists some MATLAB implementations besides SDPT3.
Reference: [22] <author> K.C. Toh, M.J. Todd and R.H. Tutuncu, </author> <title> "SDPT3 aMATLAB software package for semidefinite programming," </title> <institution> Dept. of Mathematics, National University of Singapore, 10 Kent Ridge Crescent, Singapore, </institution> <month> December </month> <year> 1996. </year> <note> Available at http://www.math.nus.sg/~mattohkc/index.html. </note>
Reference-contexts: 1. Introduction. The main purpose of this paper is to evaluate the performance of SDPA (SemiDefinite Programming Algorithm) [6] for semidefinite programs. Besides SDPA, there are some computer programs SDPpack [3], SDPSOL [27], CSDP [5], SDPHA [20] and SDPT3 <ref> [22] </ref> for semidefinite programs which are available through the Internet. Among others, we mainly compare SDPA with SDPT3 through numerical experiments on several types of test problems. Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method. <p> Step 5 : k k + 1 and go to Step 1. 3. Test Problems. We present 7 types of semidefinite programs in this section, and we show numerical results on those problems in the next two sections. 3.1 Randomly Generated Dense Semidefinite Program. The first example <ref> [22] </ref> is the standard form SDP (1) with dense data matrices A i 2 S n (1 i m). Using the standard normal distribution N (0; 1), we generate each element of A i (1 i m). <p> Then we choose A 0 2 S n and b 2 R m so that the SDP (1) has an interior feasible solution. 3.2 Norm Minimization Problem. Let F i 2 R qfir (0 i p). The norm minimization problem <ref> [22] </ref> is defined as: minimize fl fl fl p X F i y i fl fl subject to y i 2 R (1 i p): Here kCk denotes the 2-norm of C, i.e., kCk = max kuk=1 kCuk = the square root of the maximum eigenvalue of C T C. <p> This basis is derived by a modified Gram-Schmidt orthonormalization procedure with respect to the matrix inner product from the set fI; F 1 ; . . . ; F r g. This was suggested in <ref> [22, Section 5] </ref> (see also [23]), and we used the MATLAB function "chebymat.m" contained in the SDPT3 package to generate such Chebyshev approximation problems for our numerical experiments. 3.4 Semidefinite Program Arising from Control and System The ory. <p> The required number of iterations when we employ the HRVW/KSH/M direction is almost the same as when we employ the NT direction. Furthermore, the HRVW/KSH/M direction is faster than the NT direction on all problems. We can also observe the same tendency for the HRVW/KSH/M direction using SDPT3 <ref> [21, 22] </ref> excepting the ETP Problem. Monteiro and Zanjacomo [17] showed similar numerical results. Therefore, we mainly focus our attention on the HRVW/KSH/M direction in this paper. As we have already seen in Section 1, there exists some MATLAB implementations besides SDPT3. <p> We report the number of iterations and the computation time required for an approximate solution with a relative duality gap less than a given accuracy between 10 5 and 10 8 . The second issue is a comparison between SDPA [6] and SDPT3 <ref> [22] </ref> through numerical experiments. Both software packages are based on the Mehrotra-type primal-dual predictor-corrector interior-point method although some parameters to control predictor search directions and step lengths are slightly different.
Reference: [23] <author> K.C. Toh and L.N. Trefethen, </author> <title> "The Chebyshev polynomial of matrix", </title> <type> manuscript, </type> <institution> Center for Applied Mathematics, Cornell University, </institution> <address> Ithaca, NY, </address> <year> 1996. </year>
Reference-contexts: This basis is derived by a modified Gram-Schmidt orthonormalization procedure with respect to the matrix inner product from the set fI; F 1 ; . . . ; F r g. This was suggested in [22, Section 5] (see also <ref> [23] </ref>), and we used the MATLAB function "chebymat.m" contained in the SDPT3 package to generate such Chebyshev approximation problems for our numerical experiments. 3.4 Semidefinite Program Arising from Control and System The ory. Let P 2 R `fi` , Q 2 R `fik and R 2 R kfi` .
Reference: [24] <author> L. Vandenberghe and S. Boyd, </author> " <note> Semidefinite programming," SIAM Review 38 (1996) 49-95. </note>
Reference-contexts: This problem arises from an investigation into the existence of an invariant ellipsoid for the linear system with uncertain, time-varying, unity-bounded, diagonal feedback dx (t) = P x (t) + Qu (t); y (t) = Rx (t); ju i (t)j y i (t) (1 i k): See <ref> [24] </ref> for more details. We can reformulate the semidefinite program above as the dual problem of the standard form SDP (1) with m = `(` + 1)=2 + k + 1 and n = 2` + k.
Reference: [25] <author> L. Vandenberghe and S. Boyd, </author> <title> "A primal-dual potential reduction method for problems involving matrix inequalities," </title> <note> Mathematical Programming 69 (1995) 205-236. </note>
Reference-contexts: A standard technique to resolve such a difficulty is to use the conjugate gradient method to solve the system Bdy = b of equations approximately; it is carried out without storing the entire matrix B (see Concluding Remark (C) of [7], also <ref> [12, 15, 25, 26] </ref>). We report some preliminary but promising numerical results on the use of the conjugate gradient method in Table 19. We solved SDP relaxations of maximum clique problems with n = 100; 200; 400; 500 on DEC Alpha (CPU 21164-300MHz with 256MB memory). <p> This observation is due to C. Helmberg and S. Karisch. See [10] Other papers also observed the importance of exploiting different kinds of structure <ref> [8, 25] </ref>. Acknowledgment. Part of this paper was presented at the HPOPT workshop (August 19 - 22, 1997) which was held in Rotterdam, the Netherlands. Three of the authors, Fujisawa, Fukuda and Kojima attended the workshop.
Reference: [26] <author> H. Wolkowicz and Q. Zhao, </author> <title> "Semidefinite programming relaxations for the graph partitioning problem", </title> <type> CORR Report, </type> <institution> University of Waterloo, </institution> <address> Ontario, Canada, </address> <month> Oct. </month> <year> 1996. </year>
Reference-contexts: A standard technique to resolve such a difficulty is to use the conjugate gradient method to solve the system Bdy = b of equations approximately; it is carried out without storing the entire matrix B (see Concluding Remark (C) of [7], also <ref> [12, 15, 25, 26] </ref>). We report some preliminary but promising numerical results on the use of the conjugate gradient method in Table 19. We solved SDP relaxations of maximum clique problems with n = 100; 200; 400; 500 on DEC Alpha (CPU 21164-300MHz with 256MB memory).
Reference: [27] <author> S.-P. Wu and S. Boyd. "SDPSOL: </author> <title> a parser/solver for SDP and MAXDET problems with matrix structure", </title> <institution> Department of Electrical Engineering, Stanford University, </institution> <month> June, </month> <year> 1996. </year> <note> Available at http://www-isl.stanford.edu/people/boyd/SDPSOL.html 24 </note>
Reference-contexts: 1. Introduction. The main purpose of this paper is to evaluate the performance of SDPA (SemiDefinite Programming Algorithm) [6] for semidefinite programs. Besides SDPA, there are some computer programs SDPpack [3], SDPSOL <ref> [27] </ref>, CSDP [5], SDPHA [20] and SDPT3 [22] for semidefinite programs which are available through the Internet. Among others, we mainly compare SDPA with SDPT3 through numerical experiments on several types of test problems. Either of them is an implementation of a Mehrotra-type [14] primal-dual predictor-corrector interior-point method.
References-found: 27

