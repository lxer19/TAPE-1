URL: http://www.neci.nj.nec.com/homepages/giles/papers/IEEE.TKDE.rule.revision.rnns.ps.Z
Refering-URL: http://www.neci.nj.nec.com/homepages/giles/html/CLG_pub.html
Root-URL: 
Title: Rule Revision with Recurrent Neural Networks  
Author: Christian W. Omlin a;b and C.L. Giles a;c 
Keyword: Index Terms: Deterministic Finite-State Automata, Genuine and Incorrect Rules, Knowledge Insertion and Extraction, Recurrent Neural Networks, Regular Languages, Rule Revision.  
Note: Published in IEEE Trans. on Knowledge and Data Engineering, vol. 8, no. 1, p. 183, 1996. Copyright IEEE.  
Address: 4 Independence Way, Princeton, New Jersey  Troy, New York  College Park, Maryland  
Affiliation: a NEC Research Institute,  b Computer Science Department, Rensselaer Polytechnic Institute,  c Institute for Advanced Computer Studies, University of Maryland,  
Abstract: Recurrent neural networks readily process, recognize and generate temporal sequences. By encoding grammatical strings as temporal sequences, recurrent neural networks can be trained to behave like deterministic sequential finite-state automata. Algorithms have been developed for extracting grammatical rules from trained networks. Using a simple method for inserting prior knowledge (or rules) into recurrent neural networks, we show that recurrent neural networks are able to perform rule revision. Rule revision is performed by comparing the inserted rules with the rules in the finite-state automata extracted from trained networks. The results from training a recurrent neural network to recognize a known non-trivial, randomly generated regular grammar show that not only do the networks preserve correct rules but that they are able to correct through training inserted rules which were initially incorrect. (By incorrect, we mean that the rules were not the ones in the randomly generated grammar.) 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Abu-Mostafa, </author> <title> "Learning from hints in neural networks," </title> <journal> Journal of Complexity, </journal> <volume> vol. 6, </volume> <editor> p. </editor> <volume> 192, </volume> <year> 1990. </year>
Reference-contexts: This work demonstrates that recurrent networks can successfully revise rules, i.e. once rules have been inserted into a network, they can be verified and even be corrected! Inserting a priori knowledge has been shown useful in training feed-forward neural networks; for example see <ref> [1, 2, 3, 10, 25, 27, 30, 32] </ref>. The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. <p> We refer to the values of the hidden neurons collectively as a state vector S in the finite N -dimensional space <ref> [0; 1] </ref> N . A network accepts a time-ordered sequence of inputs and evolves with dynamics defined by the following equations (figure 1): S i = g (ffi i ); ffi i j;k (t) (t) where g (:) is a sigmoid discriminant function.
Reference: [2] <author> K. Al-Mashouq and I. Reed, </author> <title> "Including hints in training neural nets," </title> <journal> Neural Computation, </journal> <volume> vol. 3, no. 3, </volume> <pages> pp. 418-427, </pages> <year> 1991. </year>
Reference-contexts: This work demonstrates that recurrent networks can successfully revise rules, i.e. once rules have been inserted into a network, they can be verified and even be corrected! Inserting a priori knowledge has been shown useful in training feed-forward neural networks; for example see <ref> [1, 2, 3, 10, 25, 27, 30, 32] </ref>. The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29].
Reference: [3] <author> H. Berenji, </author> <title> "Refinement of approximate reasoning-based controllers by reinforcement learning," </title> <booktitle> in Machine Learning, Proceedings of the Eighth International International Workshop (L. </booktitle> <editor> Birnbaum and G. Collins, eds.), </editor> <address> (San Mateo, CA), p. 475, </address> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1991. </year>
Reference-contexts: This work demonstrates that recurrent networks can successfully revise rules, i.e. once rules have been inserted into a network, they can be verified and even be corrected! Inserting a priori knowledge has been shown useful in training feed-forward neural networks; for example see <ref> [1, 2, 3, 10, 25, 27, 30, 32] </ref>. The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29].
Reference: [4] <author> S. Das, C. Giles, and G. Sun, </author> <title> "Learning context-free grammars: Limitations of a recurrent neural network with an external stack memory," </title> <booktitle> in Proceedings of The Fourteenth Annual Conference of the Cognitive Science Society, </booktitle> <address> (San Mateo, CA), </address> <pages> pp. 791-795, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1992. </year>
Reference-contexts: In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed <ref> [4, 6, 7, 12, 15, 21] </ref>. It has been demonstrated [12, 21] that prior knowledge can significantly reduce the amount of training necessary for a network to correctly classify a training set of temporal sequences.
Reference: [5] <author> S. Das and M. Mozer, </author> <title> "A unified gradient-descent/clustering architecture for finite state machine induction," </title> <booktitle> in Advances in Neural Information Processing Systems 6 (J. </booktitle> <editor> Cowan, G. Tesauro, and J. Alspector, </editor> <booktitle> eds.), </booktitle> <pages> pp. 19-26, </pages> <address> San Mateo, CA: </address> <publisher> Morgan Kaufmann, </publisher> <year> 1994. </year>
Reference-contexts: The grammatical rules (the grammar) can be easily extracted from the trained neural network <ref> [5, 9, 22, 19, 31, 33] </ref>. We say a network is preserving a known rule if it appears in the extracted DFA. The network is permitted to change the programmed weights.
Reference: [6] <author> P. Frasconi, M. Gori, M. Maggini, and G. </author> <title> Soda, "A unified approach for integrating explicit knowledge and learning by example in recurrent networks," </title> <booktitle> in 1991 IEEE INNS International Joint Conference on Neural Networks Seattle, </booktitle> <volume> vol. </volume> <pages> 1, </pages> <address> (Piscataway, NJ), </address> <pages> pp. 811-816, </pages> <publisher> IEEE Press, </publisher> <year> 1991. </year>
Reference-contexts: In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed <ref> [4, 6, 7, 12, 15, 21] </ref>. It has been demonstrated [12, 21] that prior knowledge can significantly reduce the amount of training necessary for a network to correctly classify a training set of temporal sequences.
Reference: [7] <author> P. Frasconi, M. Gori, M. Maggini, and G. </author> <title> Soda, "Unified integration of explicit rules and learning by example in recurrent networks," </title> <journal> IEEE Transactions on Knowledge and Data Engineering, </journal> <volume> vol. 7, no. 2, </volume> <pages> pp. 340-346, </pages> <year> 1995. </year>
Reference-contexts: In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed <ref> [4, 6, 7, 12, 15, 21] </ref>. It has been demonstrated [12, 21] that prior knowledge can significantly reduce the amount of training necessary for a network to correctly classify a training set of temporal sequences.
Reference: [8] <author> C. Giles, D. Chen, C. Miller, H. Chen, G. Sun, and Y. Lee, </author> <title> "Second-order recurrent neural networks for grammatical inference," </title> <booktitle> in 1991 IEEE INNS International Joint Conference on Neural Networks, vol. II, </booktitle> <address> (Piscataway, NJ), </address> <pages> pp. 273-281, </pages> <publisher> IEEE Press, </publisher> <year> 1991. </year>
Reference-contexts: Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. In particular, they can be encoded [20, 18] and trained <ref> [8, 11, 16, 26, 31, 33] </ref> to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21].
Reference: [9] <author> C. Giles, D. Chen, C. Miller, H. Chen, G. Sun, and Y. Lee, </author> <title> "Second-order recurrent neural networks for grammatical inference," </title> <booktitle> in 1991 IEEE INNS International Joint Conference on Neural Networks, vol. II, </booktitle> <address> (Piscataway, NJ), </address> <pages> pp. 273-281, </pages> <publisher> IEEE Press, </publisher> <year> 1991. </year> <title> Reprinted in Artificial Neural Networks, </title> <editor> eds. E. Sanchez-Sinencia, C. Lau, </editor> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: The grammatical rules (the grammar) can be easily extracted from the trained neural network <ref> [5, 9, 22, 19, 31, 33] </ref>. We say a network is preserving a known rule if it appears in the extracted DFA. The network is permitted to change the programmed weights. <p> which generates the regular language L (M ). 3 RECURRENT NEURAL NETWORK The recurrent network used to learn regular languages consists of N recurrent neurons S j with bias b j , K nonrecurrent input neurons labeled I k , and N 2 fi K second-order weights labeled W ijk <ref> [9, 11, 26, 33] </ref>. The complexity of the network only grows as O (N 2 ) as long as the number of input neurons is small compared to the number of hidden neurons. <p> The extraction algorithm is based on the hypothesis that the outputs of the recurrent state neurons tend to cluster when the network is well-trained and that these clusters correspond to the states of the learned DFA <ref> [9, 11] </ref>. Thus, rule extraction is reduced to finding clusters in the output space of recurrent state neurons; transitions between clusters correspond to DFA state transitions. We employ a simple state space partitioning algorithm along with pruning heuristics to make the extraction computationally feasible.
Reference: [10] <author> C. Giles and T. Maxwell, </author> <title> "Learning, invariance, and generalization in high-order neural networks," </title> <journal> Applied Optics, </journal> <volume> vol. 26, no. 23, </volume> <pages> pp. 4972-4978, </pages> <year> 1987. </year> <month> 12 </month>
Reference-contexts: This work demonstrates that recurrent networks can successfully revise rules, i.e. once rules have been inserted into a network, they can be verified and even be corrected! Inserting a priori knowledge has been shown useful in training feed-forward neural networks; for example see <ref> [1, 2, 3, 10, 25, 27, 30, 32] </ref>. The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29].
Reference: [11] <author> C. Giles, C. Miller, D. Chen, H. Chen, G. Sun, and Y. Lee, </author> <title> "Learning and extracting finite state automata with second-order recurrent neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 4, no. 3, </volume> <pages> pp. 393-405, </pages> <year> 1992. </year>
Reference-contexts: Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. In particular, they can be encoded [20, 18] and trained <ref> [8, 11, 16, 26, 31, 33] </ref> to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21]. <p> which generates the regular language L (M ). 3 RECURRENT NEURAL NETWORK The recurrent network used to learn regular languages consists of N recurrent neurons S j with bias b j , K nonrecurrent input neurons labeled I k , and N 2 fi K second-order weights labeled W ijk <ref> [9, 11, 26, 33] </ref>. The complexity of the network only grows as O (N 2 ) as long as the number of input neurons is small compared to the number of hidden neurons. <p> Weight changes W ijk occur after the end of each input string; they are proportional to the gradient of the error function with respect to W ijk . For more detail see <ref> [11] </ref>. 4 RULE INSERTION Recall that a DFA M is a quintuple M =&lt; ; Q; R; F; ffi &gt; with alphabet = fa 1 ; : : : ; a N g, states Q = fs 1 ; : : :; s N Q g, a start state R, a <p> The extraction algorithm is based on the hypothesis that the outputs of the recurrent state neurons tend to cluster when the network is well-trained and that these clusters correspond to the states of the learned DFA <ref> [9, 11] </ref>. Thus, rule extraction is reduced to finding clusters in the output space of recurrent state neurons; transitions between clusters correspond to DFA state transitions. We employ a simple state space partitioning algorithm along with pruning heuristics to make the extraction computationally feasible.
Reference: [12] <author> C. Giles and C. Omlin, </author> <title> "Inserting rules into recurrent neural networks," in Neural Networks for Signal Processing II, </title> <booktitle> Proceedings of The 1992 IEEE Workshop (S. </booktitle> <editor> Kung, F. Fallside, J. A. Sorenson, and C. Kamm, eds.), </editor> <address> (Piscataway, NJ), </address> <pages> pp. 13-22, </pages> <publisher> IEEE Press, </publisher> <year> 1992. </year>
Reference-contexts: In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed <ref> [4, 6, 7, 12, 15, 21] </ref>. It has been demonstrated [12, 21] that prior knowledge can significantly reduce the amount of training necessary for a network to correctly classify a training set of temporal sequences. <p> In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21]. It has been demonstrated <ref> [12, 21] </ref> that prior knowledge can significantly reduce the amount of training necessary for a network to correctly classify a training set of temporal sequences.
Reference: [13] <author> A. Ginsberg, </author> <title> "Theory revision via prior operationalization," </title> <booktitle> in Proceedings of the Sixth National Conference on Artificial Intelligence, </booktitle> <address> p. 590, </address> <year> 1988. </year>
Reference-contexts: 1 MOTIVATION It is important to be able to revise rules in a rule-based system. A natural question is: what if the input data disagrees with the rules; how can the rules be changed? The problem of changing incorrect rules has been addressed for traditional rule-based systems <ref> [13, 23, 24] </ref>. The context of this work is the use of recurrent networks as tools for acquisition of knowledge which requires hidden-state information. In particular, we are interested in applications where a partial domain theory is available.
Reference: [14] <author> J. Hopcroft and J. Ullman, </author> <title> Introduction to Automata Theory, </title> <booktitle> Languages, and Computation. </booktitle> <address> Reading, MA: </address> <publisher> Addison-Wesley Publishing Company, Inc., </publisher> <year> 1979. </year>
Reference-contexts: Thus, they meet our criteria of good rule revisors. 2 2 FINITE STATE AUTOMATA & REGULAR GRAMMARS Regular languages represent the smallest class of formal languages in the Chomsky hierarchy <ref> [14] </ref>. Regular languages are generated by regular grammars. <p> We have empirical evidence that this model selection policy chooses among all possible DFA's the simplest model which also best describes the unknown finite-state source [22, 19]. (All extracted DFA are minimized in number of DFA states <ref> [14] </ref>.) 6 RULE REVISION 6.1 Random Grammar In order to explore the rule revising capability of recurrent neural networks, we used a non-trivial, randomly generated DFA with alphabet f0,1g (figure 2a).
Reference: [15] <author> R. Maclin and J. Shavlik, </author> <title> "Refining algorithms with knowledge-based neural networks: Improving the chou-fasman algorithm for protein folding," in Computational Learning Theory and Natural Learning Systems (S. </title> <editor> Hanson, G. Drastal, and R. Rivest, eds.), </editor> <publisher> MIT Press, </publisher> <year> 1992. </year>
Reference-contexts: In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed <ref> [4, 6, 7, 12, 15, 21] </ref>. It has been demonstrated [12, 21] that prior knowledge can significantly reduce the amount of training necessary for a network to correctly classify a training set of temporal sequences.
Reference: [16] <author> P. Manolios and R. Fanelli, </author> <title> "First order recurrent neural networks and deterministic finite state automata," </title> <journal> Neural Computation, </journal> <volume> vol. 6, no. 6, </volume> <pages> pp. 1154-1172, </pages> <year> 1994. </year>
Reference-contexts: Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. In particular, they can be encoded [20, 18] and trained <ref> [8, 11, 16, 26, 31, 33] </ref> to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21].
Reference: [17] <author> O. Nerrand, P. Roussel-Ragot, G. D. L. Personnaz, and S. Marcos, </author> <title> "Neural networks and non-linear adaptive filtering: Unifying concepts and new algorithms," </title> <journal> Neural Computation, </journal> <volume> vol. 5, </volume> <pages> pp. 165-197, </pages> <year> 1993. </year>
Reference-contexts: Note that the weights W ijk modify a product of the hidden S j and input I k neurons. This form directly represents the state transition diagrams of a state process | finput; stateg ) fnextstateg and can be considered as a canonical form of a DFA neural network <ref> [17] </ref>. The input neurons accept an encoding of one character of a string per discrete time step t. The above equation is then evaluated for each hidden neuron S i to compute the next state vector S of the hidden neurons at the next time step t + 1.
Reference: [18] <author> C. Omlin and C. Giles, </author> <title> "Constructing deterministic finite-state automata in recurrent neural networks," </title> <journal> Journal of the ACM. </journal> <note> accepted. </note>
Reference-contexts: The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. In particular, they can be encoded <ref> [20, 18] </ref> and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21]. <p> Our interpretation of rule revision consists of three stages: 1) insert all the available prior knowledge by programming some of the weights of a network (recently this has been shown to be experimentally [20] and theoretically <ref> [18] </ref> stable); 2) train a network on a data set; 3) compare the rules extracted in the form of a deterministic finite-state automaton (DFA) with the previously inserted rules. The grammatical rules (the grammar) can be easily extracted from the trained neural network [5, 9, 22, 19, 31, 33].
Reference: [19] <author> C. Omlin and C. Giles, </author> <title> "Extraction of rules from discrete-time recurrent neural networks," </title> <booktitle> Neural Networks, </booktitle> <volume> vol. 9, no. 1, </volume> <pages> pp. 41-52, </pages> <year> 1996. </year>
Reference-contexts: The grammatical rules (the grammar) can be easily extracted from the trained neural network <ref> [5, 9, 22, 19, 31, 33] </ref>. We say a network is preserving a known rule if it appears in the extracted DFA. The network is permitted to change the programmed weights. <p> We have empirical evidence that this model selection policy chooses among all possible DFA's the simplest model which also best describes the unknown finite-state source <ref> [22, 19] </ref>. (All extracted DFA are minimized in number of DFA states [14].) 6 RULE REVISION 6.1 Random Grammar In order to explore the rule revising capability of recurrent neural networks, we used a non-trivial, randomly generated DFA with alphabet f0,1g (figure 2a).
Reference: [20] <author> C. Omlin and C. Giles, </author> <title> "Stable encoding of large finite-state automata in recurrent neural networks with sigmoid discriminants," </title> <journal> Neural Computation, </journal> <volume> vol. 8, no. 4, </volume> <year> 1996. </year>
Reference-contexts: The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. In particular, they can be encoded <ref> [20, 18] </ref> and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21]. <p> Our interpretation of rule revision consists of three stages: 1) insert all the available prior knowledge by programming some of the weights of a network (recently this has been shown to be experimentally <ref> [20] </ref> and theoretically [18] stable); 2) train a network on a data set; 3) compare the rules extracted in the form of a deterministic finite-state automaton (DFA) with the previously inserted rules.
Reference: [21] <author> C. Omlin and C. Giles, </author> <title> "Training second-order recurrent neural networks using hints," </title> <booktitle> in Proceedings of the Ninth International Conference on Machine Learning (D. </booktitle> <editor> Sleeman and P. Edwards, eds.), </editor> <address> (San Mateo, CA), </address> <pages> pp. 363-368, </pages> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1992. </year> <month> 13 </month>
Reference-contexts: In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed <ref> [4, 6, 7, 12, 15, 21] </ref>. It has been demonstrated [12, 21] that prior knowledge can significantly reduce the amount of training necessary for a network to correctly classify a training set of temporal sequences. <p> In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21]. It has been demonstrated <ref> [12, 21] </ref> that prior knowledge can significantly reduce the amount of training necessary for a network to correctly classify a training set of temporal sequences.
Reference: [22] <author> C. Omlin, C. Giles, and C. Miller, </author> <title> "Heuristics for the extraction of rules from discrete-time recurrent neural networks," </title> <booktitle> in Proceedings International Joint Conference on Neural Networks 1992, </booktitle> <volume> vol. I, </volume> <pages> pp. 33-38, </pages> <month> June </month> <year> 1992. </year>
Reference-contexts: The grammatical rules (the grammar) can be easily extracted from the trained neural network <ref> [5, 9, 22, 19, 31, 33] </ref>. We say a network is preserving a known rule if it appears in the extracted DFA. The network is permitted to change the programmed weights. <p> We have empirical evidence that this model selection policy chooses among all possible DFA's the simplest model which also best describes the unknown finite-state source <ref> [22, 19] </ref>. (All extracted DFA are minimized in number of DFA states [14].) 6 RULE REVISION 6.1 Random Grammar In order to explore the rule revising capability of recurrent neural networks, we used a non-trivial, randomly generated DFA with alphabet f0,1g (figure 2a).
Reference: [23] <author> D. Oursten and R. Mooney, </author> <title> "Changing rules: A comprehensive approach to theory refinement," </title> <booktitle> in Proceedings of the Eighth National Conference on Artificial Intelligence, </booktitle> <address> p. 815, </address> <year> 1990. </year>
Reference-contexts: 1 MOTIVATION It is important to be able to revise rules in a rule-based system. A natural question is: what if the input data disagrees with the rules; how can the rules be changed? The problem of changing incorrect rules has been addressed for traditional rule-based systems <ref> [13, 23, 24] </ref>. The context of this work is the use of recurrent networks as tools for acquisition of knowledge which requires hidden-state information. In particular, we are interested in applications where a partial domain theory is available.
Reference: [24] <author> M. Pazzani, </author> <title> "Detecting and correcting errors of omission after explanation-based learning," </title> <booktitle> in Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, </booktitle> <address> p. 713, </address> <year> 1989. </year>
Reference-contexts: 1 MOTIVATION It is important to be able to revise rules in a rule-based system. A natural question is: what if the input data disagrees with the rules; how can the rules be changed? The problem of changing incorrect rules has been addressed for traditional rule-based systems <ref> [13, 23, 24] </ref>. The context of this work is the use of recurrent networks as tools for acquisition of knowledge which requires hidden-state information. In particular, we are interested in applications where a partial domain theory is available.
Reference: [25] <author> S. Perantonis and P. </author> <title> Lisboa, "Translation, rotation, and scale invariant pattern recognition by higher-order neural networks and moment classifiers," </title> <journal> IEEE Transactions on Neural Networks, </journal> <volume> vol. 3, no. 2, </volume> <editor> p. </editor> <volume> 241, </volume> <year> 1992. </year>
Reference-contexts: This work demonstrates that recurrent networks can successfully revise rules, i.e. once rules have been inserted into a network, they can be verified and even be corrected! Inserting a priori knowledge has been shown useful in training feed-forward neural networks; for example see <ref> [1, 2, 3, 10, 25, 27, 30, 32] </ref>. The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29].
Reference: [26] <author> J. Pollack, </author> <title> "The induction of dynamical recognizers," </title> <journal> Machine Learning, </journal> <volume> vol. 7, no. 2/3, </volume> <pages> pp. 227-252, </pages> <year> 1991. </year>
Reference-contexts: Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. In particular, they can be encoded [20, 18] and trained <ref> [8, 11, 16, 26, 31, 33] </ref> to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21]. <p> which generates the regular language L (M ). 3 RECURRENT NEURAL NETWORK The recurrent network used to learn regular languages consists of N recurrent neurons S j with bias b j , K nonrecurrent input neurons labeled I k , and N 2 fi K second-order weights labeled W ijk <ref> [9, 11, 26, 33] </ref>. The complexity of the network only grows as O (N 2 ) as long as the number of input neurons is small compared to the number of hidden neurons.
Reference: [27] <author> L. Pratt, </author> <title> "Non-literal transfer of information among inductive learners," in Neural Networks: Theory and Applications II (R. </title> <editor> Mammone and Y. Zeevi, eds.), </editor> <publisher> Academic Press, </publisher> <year> 1992. </year>
Reference-contexts: This work demonstrates that recurrent networks can successfully revise rules, i.e. once rules have been inserted into a network, they can be verified and even be corrected! Inserting a priori knowledge has been shown useful in training feed-forward neural networks; for example see <ref> [1, 2, 3, 10, 25, 27, 30, 32] </ref>. The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29].
Reference: [28] <author> J. W. Shavlik, </author> <title> "Combining symbolic and neural learning," </title> <journal> Machine Learning, </journal> <volume> vol. 14, no. 3, </volume> <pages> pp. 321-331, </pages> <year> 1994. </year>
Reference-contexts: It is an open question as how this approach will handle larger grammars and more complex rules and how other rule-extraction approaches [31, 33] will compare to this one. Another open question is the combination of rule insertion and extraction during training <ref> [28] </ref>.
Reference: [29] <author> H. Siegelmann and E. Sontag, </author> <title> "Turing computability with neural nets," </title> <journal> Applied Mathematics Letters, </journal> <volume> vol. 4, no. 6, </volume> <pages> pp. 77-80, </pages> <year> 1991. </year>
Reference-contexts: The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback <ref> [29] </ref>. In particular, they can be encoded [20, 18] and trained [8, 11, 16, 26, 31, 33] to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21].
Reference: [30] <author> S. Suddarth and A. Holden, </author> <title> "Symbolic neural systems and the use of hints for developing complex systems," </title> <journal> International Journal of Man-Machine Studies, </journal> <volume> vol. 34, </volume> <pages> pp. 291-311, </pages> <year> 1991. </year>
Reference-contexts: This work demonstrates that recurrent networks can successfully revise rules, i.e. once rules have been inserted into a network, they can be verified and even be corrected! Inserting a priori knowledge has been shown useful in training feed-forward neural networks; for example see <ref> [1, 2, 3, 10, 25, 27, 30, 32] </ref>. The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29].
Reference: [31] <author> P. Tino and J. Sajda, </author> <title> "Learning and extracting initial mealy machines with a modular neural network model," </title> <journal> Neural Computation, </journal> <volume> vol. 7, no. 4, </volume> <pages> pp. 822-844, </pages> <year> 1995. </year>
Reference-contexts: Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. In particular, they can be encoded [20, 18] and trained <ref> [8, 11, 16, 26, 31, 33] </ref> to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21]. <p> The grammatical rules (the grammar) can be easily extracted from the trained neural network <ref> [5, 9, 22, 19, 31, 33] </ref>. We say a network is preserving a known rule if it appears in the extracted DFA. The network is permitted to change the programmed weights. <p> The results we obtained for rule revision using second-order recurrent neural networks are promising. It is an open question as how this approach will handle larger grammars and more complex rules and how other rule-extraction approaches <ref> [31, 33] </ref> will compare to this one. Another open question is the combination of rule insertion and extraction during training [28].
Reference: [32] <author> G. Towell, M. Craven, and J. Shavlik, </author> <title> "Constructive induction using knowledge-based neural networks," </title> <booktitle> in Eighth International Machine Learning Workshop (L. </booktitle> <editor> Birnbaum and G. Collins, eds.), </editor> <address> (San Mateo, CA), p. 213, </address> <publisher> Morgan Kaufmann Publishers, </publisher> <year> 1990. </year>
Reference-contexts: This work demonstrates that recurrent networks can successfully revise rules, i.e. once rules have been inserted into a network, they can be verified and even be corrected! Inserting a priori knowledge has been shown useful in training feed-forward neural networks; for example see <ref> [1, 2, 3, 10, 25, 27, 30, 32] </ref>. The resulting networks usually performed better than networks that were trained without a priori knowledge. Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29].
Reference: [33] <author> R. Watrous and G. Kuhn, </author> <title> "Induction of finite-state languages using second-order recurrent networks," </title> <journal> Neural Computation, </journal> <volume> vol. 4, no. 3, </volume> <editor> p. </editor> <volume> 406, </volume> <year> 1992. </year>
Reference-contexts: Recurrent networks are inherently more powerful than feed-forward networks because they are able to dynamically store and use state information indefinitely due to the built-in feedback [29]. In particular, they can be encoded [20, 18] and trained <ref> [8, 11, 16, 26, 31, 33] </ref> to behave like deterministic, sequential finite-state automata. Methods for inserting prior knowledge into recurrent neural networks have been previously discussed [4, 6, 7, 12, 15, 21]. <p> The grammatical rules (the grammar) can be easily extracted from the trained neural network <ref> [5, 9, 22, 19, 31, 33] </ref>. We say a network is preserving a known rule if it appears in the extracted DFA. The network is permitted to change the programmed weights. <p> which generates the regular language L (M ). 3 RECURRENT NEURAL NETWORK The recurrent network used to learn regular languages consists of N recurrent neurons S j with bias b j , K nonrecurrent input neurons labeled I k , and N 2 fi K second-order weights labeled W ijk <ref> [9, 11, 26, 33] </ref>. The complexity of the network only grows as O (N 2 ) as long as the number of input neurons is small compared to the number of hidden neurons. <p> The results we obtained for rule revision using second-order recurrent neural networks are promising. It is an open question as how this approach will handle larger grammars and more complex rules and how other rule-extraction approaches <ref> [31, 33] </ref> will compare to this one. Another open question is the combination of rule insertion and extraction during training [28].
Reference: [34] <author> R. Williams and D. Zipser, </author> <title> "A learning algorithm for continually running fully recurrent neural networks," </title> <journal> Neural Computation, </journal> <volume> vol. 1, no. 2, </volume> <pages> pp. 270-280, </pages> <year> 1989. </year> <month> 14 </month>
Reference-contexts: The block marked '*' represent the operation W ijk fi S j fi I k . g () is the sigmoidal discriminant function. for recurrent neural networks <ref> [34] </ref>. A special neuron S 0 is selected as the output neuron of the network; this output neuron is used to define a quadratic error function.
References-found: 34

