URL: ftp://ftp.cs.utexas.edu/pub/mooney/papers/chill-mlw-97.ps.Z
Refering-URL: http://www.cs.utexas.edu/users/ml/abstracts.html
Root-URL: 
Email: (cthomp,mooney,rupert)@cs.utexas.edu  
Title: on Automata Induction, Grammatical Inference, and Language Acquisition Learning to Parse Natural Language Database Queries
Author: Cynthia A. Thompson and Raymond J. Mooney and Lappoon R. Tang 
Address: Austin, TX 78712-1188  
Affiliation: Department of Computer Sciences University of Texas  
Note: Appears in 1997 Workshop  
Abstract: For most natural language processing tasks, a parser that maps sentences into a semantic representation is significantly more useful than a grammar or automata that simply recognizes syntactically well-formed strings. This paper reviews our work on using inductive logic programming methods to learn deterministic shift-reduce parsers that translate natural language into a semantic representation. We focus on the task of mapping database queries directly into executable logical form. An overview of the system is presented followed by recent experimental results on corpora of Spanish geography queries and English job-search queries. 
Abstract-found: 1
Intro-found: 1
Reference: <author> Berwick, B. </author> <year> 1985. </year> <title> The Acquisition of Syntactic Knowledge. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: This would lead to all jobs being retrieved from the database, when in fact only a few were requested. This predicate is needed to maintain the flexibility of the query language, and investigation is needed to determine a way to improve this result. Related Work <ref> (Berwick 1985) </ref> also used the approach of treating language acquisition as a control learning problem, by learning control rules for a Marcus-style determinis tic parser (Marcus 1980).
Reference: <author> Black, E.; Jelineck, F.; Lafferty, J.; Magerman, D.; Mercer, R.; and Roukos, S. </author> <year> 1993. </year> <title> Towards history-based grammars: Using richer models for probabilistic parsing. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 31-37. </pages>
Reference: <author> Black, E.; Lafferty, J.; and Roukos, S. </author> <year> 1992. </year> <title> Development and evaluation of a broad-coverage probabilistic grammar of English-language computer manuals. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 185-192. </pages> <publisher> Borland International. </publisher> <year> 1988. </year> <title> Turbo Prolog 2.0 Reference Guide. </title> <address> Scotts Valley, CA: </address> <publisher> Borland International. </publisher>
Reference: <author> Brill, E. </author> <year> 1993. </year> <title> Automatic grammar induction and parsing free text: A transformation-based approach. </title> <booktitle> In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 259-265. </pages>
Reference: <author> Charniak, E., and Carroll, G. </author> <year> 1994. </year> <title> Context-sensitive statistics for improved grammatical language models. </title> <booktitle> In Proceedings of the Twelfth National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: Chill learns parsers that produce complete, labeled parse trees; other systems have learned to produced simple bracketings of input sentences (Periera & Shabes 1992; Brill 1993), or probabilistic language models that assign sentences probabilities <ref> (Charniak & Carroll 1994) </ref>. While Chill requires only a suitably annotated corpus, other approaches have utilized an existing, complex, hand-crafted grammar that over-generates (Black et al. 1993; Black, Lafferty, & Roukos 1992).
Reference: <author> Church, K., and Patil, R. </author> <year> 1982. </year> <title> Coping with syntactic ambiguity or how to put the block in the box on Appears in 1997 Workshop on Automata Induction, Grammatical Inference, and Language Acquisition the table. </title> <journal> American Journal of Computational Linguistics 8(3-4):139-149. </journal>
Reference-contexts: In fact, any standard syntactic English grammar will produce more than 2 n parses of sentences ending in n prepositional phrases, most of which are usually spurious <ref> (Church & Patil 1982) </ref>. A truly useful parser would produce a unique or limited number of parses that correspond to the meaningful interpretations of a sentence that a human would actually consider.
Reference: <author> Collins, M. J. </author> <year> 1996. </year> <title> A new statistical parser based on bigram lexical dependencies. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 184-191. </pages>
Reference: <author> Fillmore, C. J. </author> <year> 1968. </year> <title> The case for case. In Bach, </title> <editor> E., and Harms, R. T., eds., </editor> <booktitle> Universals in Linguistic Theory. </booktitle> <address> New York: </address> <publisher> Holt, Reinhart and Winston. </publisher>
Reference-contexts: The output is a shift-reduce parser in Prolog that maps sentences into parses. Chill outputs a simple deterministic, shift-reduce parser. The current parse state is represented by the contents of the parse stack and the remaining portion of the input buffer (Tomita 1986). Consider producing a case-role analysis <ref> (Fillmore 1968) </ref> of the sentence: "The man ate the pasta." Parsing begins with an empty stack and an input buffer containing the entire sentence.
Reference: <author> Goodman, J. </author> <year> 1996. </year> <title> Parsing algorithms and metrics. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 177-183. </pages>
Reference: <author> Kijsirikul, B.; Numao, M.; and Shimura, M. </author> <year> 1992. </year> <title> Discrimination-based constructive induction of logic programs. </title> <booktitle> In Proceedings of the Tenth National Conference on Artificial Intelligence, </booktitle> <pages> 44-49. </pages>
Reference-contexts: Chill's ILP algorithm combines elements from bottom-up techniques found in systems such as Cigol (Muggleton & Buntine 1988) and Golem (Muggleton & Feng 1992), and top-down methods from systems like Foil (Quinlan 1990), and is able to invent new predicates in a manner analogous to Champ <ref> (Kijsirikul, Numao, & Shimura 1992) </ref>. Details of the Chill induction algorithm together with experimental comparisons to Golem and Foil are presented by (Zelle & Mooney 1994) and (Zelle 1995).
Reference: <author> Lavrac, N., and Dzeroski, S. </author> <year> 1994. </year> <title> Inductive Logic Programming: Techniques and Applications. </title> <publisher> Ellis Horwood. </publisher>
Reference: <author> Magerman, D. M. </author> <year> 1994. </year> <title> Natural Lagnuage Parsing as Statistical Pattern Recognition. </title> <type> Ph.D. Dissertation, </type> <institution> Stanford University. </institution>
Reference: <author> Magerman, D. M. </author> <year> 1995. </year> <title> Statistical decision-tree models for parsing. </title> <booktitle> In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 276-283. </pages>
Reference: <author> Marcus, M.; Santorini, B.; and Marcinkiewicz, M. </author> <year> 1993. </year> <title> Building a large annotated corpus of English: The Penn treebank. </title> <booktitle> Computational Linguistics 19(2) </booktitle> <pages> 313-330. </pages>
Reference-contexts: This approach has been facilitated by the construction of large treebanks of human-produced syntactic parse trees for thousands of sentences, such as the Penn Treebank <ref> (Marcus, Santorini, & Marcinkiewicz 1993) </ref>, which consists primarily of analyses of sentences from the Wall Street Journal. Although useful, syntactic analysis is only part of the larger problem of natural language understanding.
Reference: <author> Marcus, M. </author> <year> 1980. </year> <title> A Theory of Syntactic Recognition for Natural Language. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference-contexts: Related Work (Berwick 1985) also used the approach of treating language acquisition as a control learning problem, by learning control rules for a Marcus-style determinis tic parser <ref> (Marcus 1980) </ref>. When the system came to a parsing impasse, a new rule was created by inferring the correct parsing action and creating a new rule using certain properties of the current parser state as trigger conditions for its application.
Reference: <author> McClelland, J. L., and Kawamoto, A. H. </author> <year> 1986. </year> <title> Mechanisms of sentence processing: Assigning roles to constituents of sentences. </title> <editor> In Rumelhart, D. E., and Mc-Clelland, J. L., eds., </editor> <booktitle> Parallel Distributed Processing, Vol. II. </booktitle> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher> <pages> 318-362. </pages>
Reference: <author> Miikkulainen, R. </author> <year> 1993. </year> <title> Subsymbolic Natural Language Processing: An Integrated Model of Scripts, Lexicon, and Memory. </title> <address> Cambridge, MA: </address> <publisher> MIT Press. </publisher>
Reference: <author> Miikkulainen, R. </author> <year> 1996. </year> <title> Subsymbolic case-role analysis of sentences with embedded clauses. </title> <booktitle> Cognitive Science 20(1) </booktitle> <pages> 47-73. </pages>
Reference: <author> Miller, S.; Bobrow, R.; Ingria, R.; and Schwartz, R. </author> <year> 1994. </year> <title> Hidden understanding models of natural language. </title> <booktitle> In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 25-32. </pages>
Reference-contexts: Magerman's system is hand-engineered for the particular representation being produced. Given this hand-crafting of features and rules, it is unclear how easily the approach could be adapted to differing representation schemes. One approach that learns more semantically oriented representations is the hidden understanding models of <ref> (Miller et al. 1994) </ref>. This system learns to parse into tree-structured meaning representations. These representations are similar to syntactic parse trees except that the nodes may be labeled by conceptual categories as in the analyses produced by semantic grammars.
Reference: <author> Miller, S.; Stallard, D.; Bobrow, R.; and Schwartz, R. </author> <year> 1996. </year> <title> A fully statistical approach to natural language interfaces. </title> <booktitle> In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 55-61. </pages>
Reference-contexts: These representations are similar to syntactic parse trees except that the nodes may be labeled by conceptual categories as in the analyses produced by semantic grammars. This approach was recently extended to construct a complete interface with separate statistically trained modules for syntactic, semantic and discourse analysis <ref> (Miller et al. 1996) </ref>. However, the mapping to a final semantic representation employs two separate modules, requiring each training sentence to be labeled with both a parse tree and a semantic frame. Chill maps directly into logical form and does not require annotating sentences with any additional intermediate representations.
Reference: <author> Muggleton, S., and Buntine, W. </author> <year> 1988. </year> <title> Machine invention of first-order predicates by inverting resolution. </title> <booktitle> In Proceedings of the Fifth International Conference on Machine Learning, </booktitle> <pages> 339-352. </pages>
Reference-contexts: There is no need to reduce this context to a predetermined, fixed set of features as required by propositional approaches such as neural-networks or decision trees. Chill's ILP algorithm combines elements from bottom-up techniques found in systems such as Cigol <ref> (Muggleton & Buntine 1988) </ref> and Golem (Muggleton & Feng 1992), and top-down methods from systems like Foil (Quinlan 1990), and is able to invent new predicates in a manner analogous to Champ (Kijsirikul, Numao, & Shimura 1992).
Reference: <author> Muggleton, S., and Feng, C. </author> <year> 1992. </year> <title> Efficient induction of logic programs. </title> <editor> In Muggleton, S., ed., </editor> <booktitle> Inductive Logic Programming. </booktitle> <address> New York: </address> <publisher> Academic Press. </publisher> <pages> 281-297. </pages>
Reference-contexts: There is no need to reduce this context to a predetermined, fixed set of features as required by propositional approaches such as neural-networks or decision trees. Chill's ILP algorithm combines elements from bottom-up techniques found in systems such as Cigol (Muggleton & Buntine 1988) and Golem <ref> (Muggleton & Feng 1992) </ref>, and top-down methods from systems like Foil (Quinlan 1990), and is able to invent new predicates in a manner analogous to Champ (Kijsirikul, Numao, & Shimura 1992).
Reference: <editor> Muggleton, S. H., ed. </editor> <booktitle> 1992. Inductive Logic Programming. </booktitle> <address> New York, NY: </address> <publisher> Academic Press. </publisher>
Reference-contexts: There is no need to reduce this context to a predetermined, fixed set of features as required by propositional approaches such as neural-networks or decision trees. Chill's ILP algorithm combines elements from bottom-up techniques found in systems such as Cigol (Muggleton & Buntine 1988) and Golem <ref> (Muggleton & Feng 1992) </ref>, and top-down methods from systems like Foil (Quinlan 1990), and is able to invent new predicates in a manner analogous to Champ (Kijsirikul, Numao, & Shimura 1992).
Reference: <author> Periera, F., and Shabes, Y. </author> <year> 1992. </year> <title> Inside-outside rees-timation from partially bracketed corpora. </title> <booktitle> In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, </booktitle> <pages> 128-135. </pages>
Reference: <author> Quinlan, J. </author> <year> 1990. </year> <title> Learning logical definitions from relations. </title> <booktitle> Machine Learning 5(3) </booktitle> <pages> 239-266. </pages>
Reference-contexts: Chill's ILP algorithm combines elements from bottom-up techniques found in systems such as Cigol (Muggleton & Buntine 1988) and Golem (Muggleton & Feng 1992), and top-down methods from systems like Foil <ref> (Quinlan 1990) </ref>, and is able to invent new predicates in a manner analogous to Champ (Kijsirikul, Numao, & Shimura 1992). Details of the Chill induction algorithm together with experimental comparisons to Golem and Foil are presented by (Zelle & Mooney 1994) and (Zelle 1995).
Reference: <author> Simmons, R. F., and Yu, Y. </author> <year> 1992. </year> <title> The acquisition and use of context dependent grammars for English. </title> <booktitle> Computational Linguistics 18(4) </booktitle> <pages> 391-418. </pages>
Reference-contexts: When the system came to a parsing impasse, a new rule was created by inferring the correct parsing action and creating a new rule using certain properties of the current parser state as trigger conditions for its application. In a similar vein, <ref> (Simmons & Yu 1992) </ref> controlled a simple shift-reduce parser by storing example contexts consisting of the syntactic categories of a fixed number of stack and input buffer locations.
Reference: <author> St. John, M. F., and McClelland, J. L. </author> <year> 1990. </year> <title> Learning and applying contextual constraints in sentence comprehension. </title> <booktitle> Artificial Intelligence 46 </booktitle> <pages> 217-257. </pages>
Reference: <author> Tomita, M. </author> <year> 1986. </year> <title> Efficient Parsing for Natural Language. </title> <address> Boston: </address> <publisher> Kluwer Academic Publishers. </publisher>
Reference-contexts: The output is a shift-reduce parser in Prolog that maps sentences into parses. Chill outputs a simple deterministic, shift-reduce parser. The current parse state is represented by the contents of the parse stack and the remaining portion of the input buffer <ref> (Tomita 1986) </ref>. Consider producing a case-role analysis (Fillmore 1968) of the sentence: "The man ate the pasta." Parsing begins with an empty stack and an input buffer containing the entire sentence.
Reference: <author> Zelle, J. M., and Mooney, R. J. </author> <year> 1993. </year> <title> Learning semantic grammars with constructive inductive logic programming. </title> <booktitle> In Proceedings of the Eleventh National Conference on Artificial Intelligence, </booktitle> <pages> 817-822. </pages>
Reference: <author> Zelle, J. M., and Mooney, R. J. </author> <year> 1994. </year> <title> Combining top-down and bottom-up methods in inductive logic programming. </title> <booktitle> In Proceedings of the Eleventh International Conference on Machine Learning, </booktitle> <pages> 343-351. </pages>
Reference-contexts: Details of the Chill induction algorithm together with experimental comparisons to Golem and Foil are presented by <ref> (Zelle & Mooney 1994) </ref> and (Zelle 1995). Given our running example, a control rule that can be learned for the reduce agt operator is op ([X,[Y,det:the]], [the|Z], A, B) :- animate (Y). animate (man). animate (boy). animate (girl) ....
Reference: <author> Zelle, J. M., and Mooney, R. J. </author> <year> 1996. </year> <title> Learning to parse database queries using inductive logic programming. </title> <booktitle> In Proceedings of the Thirteenth National Conference on Artificial Intelligence. </booktitle>
Reference-contexts: In particular, we have conducted experiments demonstrating that Chill learns parsers for answering English queries for a database on U.S. geography that are more accurate than an existing hand-built system for this application <ref> (Zelle & Mooney 1996) </ref>. 2 This paper presents an overview of our approach for learning parsers and presents new experimental results on Spanish geography queries and English job-search queries that demonstrate the robustness of the approach.
Reference: <author> Zelle, J. M. </author> <year> 1995. </year> <title> Using Inductive Logic Programming to Automate the Construction of Natural Language Parsers. </title> <type> Ph.D. Dissertation, </type> <institution> University of Texas, Austin, TX. </institution> <note> Also appears as Artificial Intelligence Laboratory Technical Report AI 96-249. </note>
Reference-contexts: SQL) that can be immediately executed to retrieve an answer to the question. Consequently, our recent research has focused on learning parsers that map natural language database queries into an executable logical form. The system we have developed, called Chill 1 <ref> (Zelle 1995) </ref>, uses inductive logic programming (ILP) (Muggleton 1992; Lavrac & Dzeroski 1994) to learn a deterministic shift-reduce Prolog parser. Chill has been demonstrated on learning parsers for each type of analysis represented 1 Constructive Heuristics Induction for Language Learning in Figure 1. <p> Details of the Chill induction algorithm together with experimental comparisons to Golem and Foil are presented by (Zelle & Mooney 1994) and <ref> (Zelle 1995) </ref>. Given our running example, a control rule that can be learned for the reduce agt operator is op ([X,[Y,det:the]], [the|Z], A, B) :- animate (Y). animate (man). animate (boy). animate (girl) .... Here the system has invented a new predicate to help explain the parsing decisions.
References-found: 32

