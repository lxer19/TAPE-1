URL: http://www.ececs.uc.edu/~sweaver/postscript/ISIC98.ps
Refering-URL: http://www.ececs.uc.edu/~sweaver/
Root-URL: 
Title: Preventing Unlearning During On-Line Training of Feedforward Networks 1  
Author: Scott Weaver ; Leemon Baird Marios Polycarpou 
Keyword: interference, unlearning, spatially local networks  
Note: 3 Wright-Patterson Air Force Base AFRL/SNAT 2241 Avionics  
Address: 45221-0030  WPAFB, Ohio 45433-7318  5000 Forbes Avenue  Pittsburgh, Pennsylvania 15213-3891  
Affiliation: 2 Department of Electrical and Computer Engineering University of Cincinnati Cincinnati, Ohio  Circle  Computer Science Department  Carnegie Mellon University  
Email: Email: scott.weaver@uc.edu  
Phone: 4  
Abstract: Interference in neural networks occurs when learning in one area of the input space causes unlearning in another area. These interference problems are especially prevalent in on-line applications where learning is directed by training data that is currently available rather than some optimal presentation schedule of the training data. We propose a procedure that enhances a learning algorithm by giving it the ability to make the network more local and hence, less likely to suffer from future interference. Through simulations using Radial Basis Function (RBF) networks and sigmoidal, multi-layer perceptron (MLP) networks it is shown that by optimizing a new cost function that penalizes non-locality, the approximation error is reduced more quickly than with standard back-propagation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> W. Baker and J. Farrell. </author> <title> An introduction to connectionist learning control systems. </title> <editor> In D. White and D. Sofge, editors, </editor> <booktitle> Handbook of Intelligent Control Neural, Fuzzy, and Adaptive Approaches, </booktitle> <pages> pages 35-63, </pages> <address> New York, NY, 1992. </address> <publisher> Van Nostrand Reinhold. </publisher>
Reference-contexts: This unlearning side effect, reffered to as interference, occurs when learning in one area of the input space causes unlearning in another area. Networks that are less susceptible to interference are typically referred to as spatially local networks <ref> [1] </ref>. Sofge and White [4] discuss characteristics of local networks and suggest that successful learning control of process dynamics requires the use of local neural network paradigms. A real-world problem, called Global Network Collapse [4], illustrates what can happen when using non-local networks. <p> Reducing this cost function reduces the effects of interference as well the approximation error as determined by the relative weighting of the two competing goals of (10) using - 2 <ref> [0; 1] </ref>. Using (3) we define I (x 0 ; x 00 ; ) based upon learning algorithm (8)-(9). <p> Explicitly, the (i; j) element of r 2 @ j @ i f (x 0 ; ). Next, we consider how each term in (11) affects the learning process. To control the weighting between the two goals that compete for the network's resources, we choose from the range <ref> [0, 1] </ref>. When - = 1:0, (11) reduces to the standard back-propagation on the mean squared error (8) and hence does not attempt any localization of the network. In this case, if the training points are randomly distributed and independent from one another, learning may take place quickly. <p> Again we compare standard back-propagation with the localizing algorithm. As the velocity with which the input moves throughout its domain, slows, learning with standard back-propagation also slows due to interference. Example 2 Consider the problem of learning f fl (x) = sin (2x) (14) in the domain X = <ref> [0; 1] </ref> using a single-input, single-output, two-hidden-layer multi-layer perceptron (MLP) network with 10 nodes in each of the two hidden layers and a bias combined into the input layer and each of the two hidden layers. <p> Learning in this environment is considerably more difficult as compared to the case of random inputs. For example learning to within an approximation error of 0.2 takes 165,000 timesteps as opposed to 2,500 timesteps when the values of x are chosen randomly from the domain X = <ref> [0; 1] </ref>. Figure 4 (a) plots the L 1 norm of the approximation error, given as R X je (x; )jdx, versus timestep which reaches a threshold of 0.2 considerably more quickly when - = 0:97 (solid curve) than when - = 1:0 (dashed curve).
Reference: [2] <author> J. Farrell. </author> <title> Approximators characteristics and their effect on training misbehavior in passive learning control. </title> <booktitle> In Proceedings of the 1996 IEEE International Symposium on Intelligent Control, </booktitle> <pages> pages 181-187, </pages> <year> 1996. </year>
Reference-contexts: When using dynamical systems, the system state and training samples can remain in a local region of the state space, and hence, over a short period of time, will be unrepresentative of the entire domain being learned. These problems have been explored by Farrell <ref> [2] </ref> who demonstrates that even if the desired function is learned in a small region of the domain, which might result in a state estimation error converging to zero, the function approximator fails to learn the desired function. <p> Each of the network's 141 adjustable weights is initialized randomly from a uniform probability distribution in <ref> [2; 2] </ref>. To simulate the passive learning scenario our training data is obtained from sampling the sinusoid found in (14).
Reference: [3] <author> J. Farrell and T. Berger. </author> <title> On the effects of the training sample density in passive learning control. </title> <booktitle> In Proceedings of the American Control Conference, </booktitle> <pages> pages 872-876, </pages> <year> 1995. </year>
Reference-contexts: Although the learning process can become inefficient for various reasons, we focus on situations that cause unlearning of previously learned data. One such situation called passive learning <ref> [3] </ref>, which occurs when the training samples cannot be preselected or reordered, often results in slower on-line learning because the incoming training data is not randomly (optimally) distributed.
Reference: [4] <author> D. Sofge and D. White. </author> <title> Applied learning: optimal control for manufacturing. </title> <editor> In D. White and D. Sofge, editors, </editor> <booktitle> Handbook of Intelligent Control Neural, Fuzzy, and Adaptive Approaches, </booktitle> <pages> pages 259-281, </pages> <address> New York, NY, 1992. </address> <publisher> Van Nostrand Reinhold. </publisher>
Reference-contexts: This unlearning side effect, reffered to as interference, occurs when learning in one area of the input space causes unlearning in another area. Networks that are less susceptible to interference are typically referred to as spatially local networks [1]. Sofge and White <ref> [4] </ref> discuss characteristics of local networks and suggest that successful learning control of process dynamics requires the use of local neural network paradigms. A real-world problem, called Global Network Collapse [4], illustrates what can happen when using non-local networks. <p> Networks that are less susceptible to interference are typically referred to as spatially local networks [1]. Sofge and White <ref> [4] </ref> discuss characteristics of local networks and suggest that successful learning control of process dynamics requires the use of local neural network paradigms. A real-world problem, called Global Network Collapse [4], illustrates what can happen when using non-local networks. For example, consider a stable dynamical system after it settles into a desired trajectory (which traces only a small portion of the input space).
Reference: [5] <author> S. Weaver, L. Baird, and M. Polycarpou. </author> <title> An analytical framework for local feedforward networks. </title> <journal> IEEE Trans. on Neural Net., </journal> <volume> 9(3) </volume> <pages> 473-482, </pages> <year> 1998. </year> <title> outputs denoted by the dashed curves. - = 0:5. starting with weights obtained from (a) Figure 2(a) and (b) Figure 2(b). entire domain) is shown in (b) with - = 0:97 (solid curve, supervised learning plus localization) and - = 1:0 (dashed curve, pure supervised learning, no localization). </title>
Reference-contexts: It should be noted that the ultimate goal of optimizing a network's locality is to speed learning by reducing unlearning. To develop such a localizing algorithm we augment the standard approximation error cost function with a term that measures interference. The interference measure, developed in <ref> [5] </ref>, characterizes the effect learning at one point in the domain has on another point. Reducing interference will tend to make a network less likely to suffer from future interference and hence make the network more local. <p> The usefulness of the localizing algorithm is then illustrated using simulations. The paper is organized as follows. In Section 2 we summarize definitions of interference and localization found in <ref> [5] </ref>. In Section 3, we develop the localizing algorithm by adding an interference term to the standard approximation error cost function. Section 4 provides simulations that illustrate network locality and the localizing algorithm's utility. Some concluding remarks are presented in Section 5. 2. <p> Some concluding remarks are presented in Section 5. 2. MEASURES OF INTERFERENCE AND LOCALIZATION In order to develop a localizing algorithm with the capability of making a network more immune to interference we begin with rigorous measures of interference and localization developed in <ref> [5] </ref> that are summarized below.
References-found: 5

