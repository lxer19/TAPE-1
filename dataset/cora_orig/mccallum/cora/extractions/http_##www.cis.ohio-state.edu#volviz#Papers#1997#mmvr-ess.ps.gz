URL: http://www.cis.ohio-state.edu/volviz/Papers/1997/mmvr-ess.ps.gz
Refering-URL: http://www.cis.ohio-state.edu/volviz/papers_subject.html
Root-URL: 
Phone: 2  3  4  5  
Title: A Volumetric Approach to Virtual Simulation of Functional Endoscopic Sinus Surgery  
Author: Gregory J. Wiet , Roni Yagel Don Stredney Petra Schmalbrock Dennis J. Sessanna Yair Kurzion Louis Rosenberg Michael Levin Kenneth Martin 
Address: Columbus, OH  Columbus, OH  Columbus, OH  Columbus, OH  San Jose, CA  
Affiliation: 1 Department of Otolaryngology, The Ohio State University Hospitals,  The Ohio Supercomputer Center,  Department of Computer and Information Science, The Ohio State University,  Department of Radiology, The Ohio State University Hospitals,  Immersion Corporation,  
Abstract: Advanced display technologies have made the virtual exploration of relatively complex models feasible in many applications. Unfortunately, only a few human interfaces allow natural interaction with the environment. Moreover, in surgical applications, such realistic interaction requires real-time rendering of volumetric data - placing an overwhelming performance burden on the system. We report on a collaboration of an interdisciplinary group developing a virtual reality system that provides intuitive interaction with volume data by employing real-time volume rendering and force feedback (haptic) sensations. We describe our rendering methods and the haptic devices and explain its utility of this system in the real-world application of Endoscopic Sinus Surgery (ESS) simulation. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Bizzi E., Accornero E, Chapple W., and Hogan N., </author> <title> Posture Control and Trajectory Formation During Arm Movement, </title> <journal> J. Neuroscience, </journal> <volume> 4 </volume> <pages> 2738-2744, </pages> <year> 1984. </year>
Reference: [2] <author> Cabral B., Cam N., and Foran J., </author> <title> Accelerated Volume Rendering and Tomographic Reconstruction Using Texture Mapping Hardware, </title> <booktitle> Proceedings of 1994 Symposium on Volume Visualization, </booktitle> <month> October </month> <year> 1994, </year> <pages> pp. 91-98 </pages>
Reference-contexts: It easily supports operations such as subtraction, addition, collision detection, and deformation. For a complete comparison see [7]. advance to the closest one. Although there are many methods for rendering volumes and various ways to accelerate and optimize these, we employ two algorithms: splatting [17] and slicing <ref> [2] </ref> which we briefly describe here. Splatting is based on transforming all voxels from their locations in the data coordinates to the viewing screen coordinates. <p> Each voxel is rendered to the screen not as a point. Instead, the energy of the voxels is distributed to a small neighborhood of pixels. The image a voxel creates by being smeared across pixel neighborhood is called a splat. The slicing algorithm is based on another observation <ref> [2] </ref>. If one embeds a plane in the space occupied by the volume and displays on the plane all the voxels it intersects, we have a slice through the volume. If this process repeats for multiple planes, we have something similar to what is shown in 4. <p> These three-dimensional rasters (called 3D texture maps) are mapped on polygons in 3D space using either zero order or first order interpolation. By rendering polygons slicing the volume and perpendicular to the view direction one generates a view of a rectangular volume data set <ref> [2] </ref>. Rendering these polygons from back to front and blending them into the frame buffer generates a correct image of the volume. Figure 5 shows an example image rendered by the Volume Slicer. Our implementation runs on SGI workstations with 3D texture capabilities.
Reference: [3] <author> Feldman A.G., Adamovich S.V., Ostry D.J., and Flanagan J.R., </author> <title> The Origin of Electromyograms -Explanations based on Equilibrium Point Hypothesis. In Multiple Muscle Systems: Biomechanics and Movement Organization, </title> <editor> Winters and Woo, eds. </editor> <publisher> Springer-Verlag, </publisher> <address> New York, </address> <year> 1990, </year> <pages> pp. 195-213. </pages>
Reference: [4] <author> Flash T., </author> <title> The Control of Hand Equilibrium Trajectories in Multi-joint Movements. </title> <journal> Biol. Cybern., 1987, </journal> <volume> 57 </volume> <pages> 257-274. </pages>
Reference: [5] <author> Ghez C., Hening W., and Gordon J., </author> <title> Organization of Voluntary Movement. </title> <journal> Curr. Opin. Neurobiol. </journal> <volume> 1 </volume> <pages> 664-671, </pages> <year> 1991. </year>
Reference-contexts: This mental representation will be modified with direct sensory information including visual, haptic, and information supplied by proprioreception of joints and visual feedback of user limb position <ref> [5] </ref>. In minimally invasive surgery, surgeons insert various tools through one or two small incisions. Their visual feedback is limited to the view they get through the eyepiece of an endoscope.
Reference: [6] <author> Graziono M.S. and Gross C.G., </author> <title> A Bimodal Map of Space: Tactile Receptive Fields in the Macaque Putamen with Corresponding Visual Receptive Fields. </title> <journal> Exp Brain Res. </journal> <volume> 97 </volume> <pages> 96-109, </pages> <year> 1993. </year>
Reference: [7] <author> Kaufman A., Cohen D., and Yagel R., </author> <title> Volumetric Graphics, </title> <journal> IEEE Computer, </journal> <volume> 26(7) </volume> <pages> 51-64, </pages> <month> July </month> <year> 1993. </year>
Reference-contexts: However, volumes have distinct advantages: they can represent the interior of objects. Rendering and processing does not depend on the objects complexity or type; they depend only on volume resolution. It easily supports operations such as subtraction, addition, collision detection, and deformation. For a complete comparison see <ref> [7] </ref>. advance to the closest one. Although there are many methods for rendering volumes and various ways to accelerate and optimize these, we employ two algorithms: splatting [17] and slicing [2] which we briefly describe here.
Reference: [8] <author> Kurzion Y. and Yagel R., </author> <title> Volume Deformation using Ray Deflectors, </title> <booktitle> The 6th Eurographics Workshop on Rendering, </booktitle> <address> Dublin, </address> <month> June </month> <year> 1995, </year> <pages> pp. 21-32. </pages>
Reference-contexts: The convergence of visual, auditory, and somatosensory inputs has been identified by Stein [17] in the superior colliculus. Bimodal neural involvement has been identified in the putamen, parietal area 7b, and inferior area 6 <ref> [8] </ref> and is presumed integral to the representation of extrapersonal space. Emphasis and value of this multimodal interaction are clearly evident in the cerebral area apportioned to visual and dexterous activity. Surgery is a human activity that employs visual and manual investigations. <p> We expect no penalty when running our implementation on a machine with larger texture memory as our implementation does not depend on the volume size. 5. Volume Deformation Our approach to deformation, first introduced in <ref> [8] </ref> applies the required shape transformation not to the objects in the scene but rather to the rendering agents. For example, one can render a 3D scene by sending sight rays from the eye and through each pixel on the screen.
Reference: [9] <author> Laur D. and Hanrahan P., </author> <title> Hierarchical Splatting: A Progressive Refinement Algorithm for Volume Rendering, </title> <journal> Computer Graphics, </journal> <volume> 25(4) </volume> <pages> 285-288, </pages> <month> July </month> <year> 1991. </year>
Reference-contexts: It traverses the fuzzy set in a back-to-front order. For each member of the set it renders a rectangle facing the viewer, textured with a splat texture. The splat texture contains an image of a fuzzy circle, with opaque center and transparent circumference <ref> [9] </ref>. We also implemented a faster version of the rendering algorithm in which, instead of rectangles, we render enlarged points on the screen.
Reference: [10] <author> Leslie A.M. and Keeble S., </author> <title> Do Six-Month-Old Infants Perceive Causality?, </title> <journal> Cognition, </journal> <volume> 25 </volume> <pages> 267-287, </pages> <year> 1987. </year>
Reference: [11] <author> Mcdonald J.S., Rosenberg L.B., Stredney D., </author> <title> Virtual Reality Technology Applied to Anesthesiology, Interactive Technology and the New Paradigm for Health Care, Proceedings Medicine Meets Virtual Reality III, R.M. </title> <editor> Satava, ed., </editor> <publisher> IOS Press Amesterdam, </publisher> <pages> 237-243, </pages> <year> 1995. </year>
Reference-contexts: Finally, to convey a sense of reality the system must deliver real-time realistic rendering of the 3D environment. Our previous work includes the development of a system to provide for the simulation of regional anaesthesia <ref> [11] </ref>. This system integrates visual, haptic, and speech recognition for simulating an epidural block, a regional anesthesia technique commonly used in obstetrics. In addition, our group has developed a real-time volumetric system for the use in preplanning the removal of brain and cranial base tumors [18].
Reference: [12] <author> Messerklinger W., </author> <title> Endoscopy of the Nose, Urban and Schwartzenburg, </title> <publisher> Inc. </publisher> <address> Baltimore, Maryland, </address> <year> 1978. </year>
Reference-contexts: Its rationale is based on the simple premise of improving the natural drainage of the sinuses into the nasal airway. Endoscopic sinus surgery was first popularized by Messerklinger <ref> [12] </ref> and furthered by Stamberger [15]. In the past, sinus surgery was composed of rather crude techniques including blind probing and removal of tissue without direct visualization or the creation of external facial incisions to gain direct access.
Reference: [13] <author> Rohlf J. and J., IRIS Performer: </author> <title> A High Performance Multiprocessing Toolkit for Real-Time 3D Graphics, </title> <booktitle> Proceedings of SIGGRAPH 94, </booktitle> <month> July </month> <year> 1994, </year> <pages> pp. 381-395. </pages>
Reference: [14] <author> Schmalbrock P., Pruski J., Sun L., Rao A., and Monroe J.W., </author> <title> Phased Array RF Coils for High Resolution Imaging of the Inner Ear and the Brain Stem, </title> <journal> J. Comp. Assist. Tom., </journal> <volume> 19 </volume> <pages> 8-14, </pages> <year> 1995. </year>
Reference: [15] <author> Stammberger, H., </author> <title> Functional Endoscopic Sinus Surgery. The Messerklinger Technique, </title> <editor> B. C. Decker, </editor> <address> Philadelphia, Pennsylvania. </address> <year> 1991. </year>
Reference-contexts: Its rationale is based on the simple premise of improving the natural drainage of the sinuses into the nasal airway. Endoscopic sinus surgery was first popularized by Messerklinger [12] and furthered by Stamberger <ref> [15] </ref>. In the past, sinus surgery was composed of rather crude techniques including blind probing and removal of tissue without direct visualization or the creation of external facial incisions to gain direct access.
Reference: [16] <author> Streri A., </author> <title> Seeing, Reaching, Touching -The Relations between Vision and Touch in Infancy, </title> <publisher> MIT Press 1993. </publisher>
Reference-contexts: Most computer interfaces suffer from lack of multisensory information, providing only a passive witnessing of information. The human capacities for manual and visual investigations are inherent and develop early, as is evident in infant object exploration before the development of locomotive skills required for navigation <ref> [16] </ref>. The convergence of visual, auditory, and somatosensory inputs has been identified by Stein [17] in the superior colliculus. Bimodal neural involvement has been identified in the putamen, parietal area 7b, and inferior area 6 [8] and is presumed integral to the representation of extrapersonal space.
Reference: [17] <author> Westover L., </author> <title> Footprint Evaluation for Volume Rendering, </title> <journal> Computer Graphics, </journal> <volume> 24(4) </volume> <pages> 367-376, </pages> <month> August </month> <year> 1990. </year>
Reference-contexts: The human capacities for manual and visual investigations are inherent and develop early, as is evident in infant object exploration before the development of locomotive skills required for navigation [16]. The convergence of visual, auditory, and somatosensory inputs has been identified by Stein <ref> [17] </ref> in the superior colliculus. Bimodal neural involvement has been identified in the putamen, parietal area 7b, and inferior area 6 [8] and is presumed integral to the representation of extrapersonal space. <p> It easily supports operations such as subtraction, addition, collision detection, and deformation. For a complete comparison see [7]. advance to the closest one. Although there are many methods for rendering volumes and various ways to accelerate and optimize these, we employ two algorithms: splatting <ref> [17] </ref> and slicing [2] which we briefly describe here. Splatting is based on transforming all voxels from their locations in the data coordinates to the viewing screen coordinates.
Reference: [18] <author> Wiet G.J., Schuller D.E., Goodman J., Stredney D.L., Bender C.F., Yagel R., Swan J.E., and Schmalbrock P., </author> <title> Virtual Simulations of Brain and Cranial Base Tumors, </title> <booktitle> Proceedings of the 98th Annual Meeting of the American Academy of Otolaryngology Head and Neck Surgery, </booktitle> <address> San Diego, California, </address> <month> September </month> <year> 1994. </year>
Reference-contexts: This system integrates visual, haptic, and speech recognition for simulating an epidural block, a regional anesthesia technique commonly used in obstetrics. In addition, our group has developed a real-time volumetric system for the use in preplanning the removal of brain and cranial base tumors <ref> [18] </ref>.
Reference: [19] <author> Yagel R. and Ray W., </author> <title> Visibility Computation for Efficient Walkthrough Complex Environments, PRESENCE, </title> <address> 5(1):1 16, </address> <month> Winter </month> <year> 1996. </year>
Reference-contexts: Progress is being made in this area in MRI [14][20]. This high resolution allows for a more complete visual display of the regional anatomy. Another disadvantage of the splatter is that its performance depends on the number of splats. We plan to incorporate more powerful visibility preprocessing tools <ref> [19] </ref> that can single out all voxels that are not visible from the current.
Reference: [20] <author> Ying K., Schmalbrock P., </author> <title> Clymer B.D., Echo-Time Reduction for Submillimeter Resolution Imaging with a Phase Encode Time Reduced Acquisition Method, Magn. </title> <journal> Reson. Med., </journal> <volume> 33 </volume> <pages> 82-87, </pages> <year> 1995. </year>
References-found: 20

