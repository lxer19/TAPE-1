URL: http://www.uni-paderborn.de/fachbereich/AG/agmadh/Scripts/GENERAL/Motwani-Approx.ps.gz
Refering-URL: http://www.uni-paderborn.de/fachbereich/AG/agmadh/WWW/english/scripts.html
Root-URL: http://www.aic.nrl.navy.mil/~aha/people.html
Title: Lecture Notes on Approximation Algorithms Volume I  
Author: Rajeev Motwani 
Note: Part of this work was supported by NSF Grant CCR-9010517, and grants from Mitsubishi and OTL.  
Address: Stanford, CA 94305-2140.  
Affiliation: Department of Computer Science Stanford University  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> R. Aharoni, P. Erdos and N. Linial, </author> <title> Optima of dual integer programs, </title> <journal> Combinatorica, </journal> <volume> 8 (1988), </volume> <pages> pp. 13-20. </pages>
Reference-contexts: We are required to pack them into bins of unit size so as to minimize the number of bins used. Thus, we have the following minimization problem. * [Instances] I = fs 1 ; s 2 ; . . . s n g, such that 8i; s i 2 <ref> [0; 1] </ref>. * [Solutions] A collection of subsets = fB 1 ; B 2 ; . . . <p> This problem is N P-complete and is defined as follows. An input instance consists of n positive integers, s 1 , . . ., s n , and a bag size B. A feasible solution solution consists of a subset X <ref> [1; . . . ; n] </ref> such that P i2X s i = B. The decision version of this problem is closely related to the BIN PACKING, SCHEDULING and KNAPSACK problems. Consider the algorithm DP [14] for PARTITION which is based on the paradigm of Dynamic Programming. <p> The basic idea behind DP is to construct the table T i;j , for 1 i n and 0 j B. The entries in the table are boolean values such that T i;j = T RU E if and only if there exists Y <ref> [1; . . . ; i] </ref> such that P l2Y s l = j. This table T is constructed in a row-by-row fashion as follows. 2.4. PSEUDO-POLYNOMIAL ALGORITHMS Page 45 Algorithm DP: Input: Bag size B and item sizes fs 1 ; . . . ; s n g. <p> Actually, the algorithm can be easily modified to solve the search problem of computing a set X. This can be done by storing the set X i;j at the position T i;j such that X i;j <ref> [1; . . . ; i] </ref> and l2X i;j s l = j. Note that there may not be a unique Do you see how to do this? X i;j but it suffices to store any one set at each position in T . <p> Definition 2.7: The boolean table T consists of entries T i;j , for 1 i n and 0 j nP , such that T i;j = T RU E if and only if there exists a set X i;j <ref> [1; . . . ; i] </ref> with size (X i;j ) B and prof it (X i;j ) = j. In this definition, the entry T i;j tells us if there is a subset of the first i items which is a feasible solution to KNAPSACK and has value j. <p> The second problem that we had mentioned can be easily handled once we have the following fact. The proof is obvious. Lemma 2.1: Let X, Y <ref> [1; . . . ; i] </ref> be such that prof it (X) = prof it (Y ) = j and size (X) size (Y ). Then, for all Z [i + 1; . . . ; n], it is the case that size (X [ Z) size (Y [ Z). <p> Definition 2.8: Consider any entry T i;j in the table T . If T i;j = F ALSE then X i;j = fl, where fl denotes that X i;j is undefined. If T i;j = T RU E, then X i;j is defined as the subset X <ref> [1; . . . ; i] </ref> of the smallest size which has size at most B and profit exactly j; when no such set exists the value of X i;j is undefined.
Reference: [2] <author> K. Appel and W. Haken, </author> <title> Every planar map is four colorable, Part I: </title> <journal> Discharging, Illinois Journal of Mathematics, </journal> <volume> 21 (1977), </volume> <pages> pp. 429-490. </pages>
Reference-contexts: Theorem 1.1: The problem of deciding whether a planar graph is 3-colorable is N P-complete. It is also well-known that any planar graph is 5-colorable. In fact, the (in)famous Four Color Theorem for planar maps <ref> [2, 3] </ref> tells us that every planar graph is 4-colorable. Consider the following approximation algorithm A for the planar coloring problem. It first checks if the graph is 2-colorable (or, bipartite) and computes the 2-coloring if possible. <p> In the special case of planar graphs, we can improve the ratio to 1:5 by noting that every planar graph can be 4-colored <ref> [2, 3] </ref>. We now observe that the approximate graph coloring algorithm of Wigderson [60] (which we will see in a later chapter) will color a graph using at most 2 p n colors provided it is triangle-free.
Reference: [3] <author> K. Appel, W. Haken and J. Koch, </author> <title> Every planar map is four col-orable, Part II: Reducibility, </title> <journal> Illinois Journal of Mathematics, </journal> <volume> 21 (1977), </volume> <pages> pp. 491-567. </pages>
Reference-contexts: Theorem 1.1: The problem of deciding whether a planar graph is 3-colorable is N P-complete. It is also well-known that any planar graph is 5-colorable. In fact, the (in)famous Four Color Theorem for planar maps <ref> [2, 3] </ref> tells us that every planar graph is 4-colorable. Consider the following approximation algorithm A for the planar coloring problem. It first checks if the graph is 2-colorable (or, bipartite) and computes the 2-coloring if possible. <p> In the special case of planar graphs, we can improve the ratio to 1:5 by noting that every planar graph can be 4-colored <ref> [2, 3] </ref>. We now observe that the approximate graph coloring algorithm of Wigderson [60] (which we will see in a later chapter) will color a graph using at most 2 p n colors provided it is triangle-free.
Reference: [4] <author> R. Bar-Yehuda and S. </author> <title> Even, A Linear Time Approximation Algorithm for the Weighted Vertex Cover Problem, </title> <journal> Journal of Algorithms, </journal> <volume> 2 (1981), </volume> <pages> pp. 198-203. </pages>
Reference-contexts: This implied a factor of 2 approximation for vertex cover. Both these results made extensive use of a linear programming formulation. The first purely combinatorial analysis was due to Bar-Yehuda and Even <ref> [4] </ref> and this was followed by the algorithm of Clarkson [11]. All of these algorithms have essentially the same performance ratio, i.e. asymptotically equal to 2. <p> The algorithm A is exactly the algorithm of Nemhauser and Trotter! 4.3.2. A Local Ratio Theorem We are now going to describe a new technique for obtaining an approximation algorithm for WVC, this is due to Bar-Yehuda and Even <ref> [4, 6] </ref>. We first show that any partition of the weight function gives two instances of WVC whose optimal solutions yield an optimal solution for original instance. <p> There is no need for an Algorithm A in this case. The following is an equivalent description of the resulting algorithm. This is exactly the linear time approximation algorithm with ratio 2 that was devised by Bar-Yehuda and Even <ref> [4] </ref>. Algorithm MLOCAL (EDGE): Input: Graph G (V; E) and weight function w on V .
Reference: [5] <author> R. Bar-Yehuda and S. </author> <title> Even, On Approximating a Vertex Cover for Planar Graphs, </title> <booktitle> Proceedings of 14th Annual ACM Symposium on Theory of Computing (1982), </booktitle> <pages> pp. 303-309. </pages>
Reference: [6] <author> R. Bar-Yehuda and S. </author> <title> Even, A Local-Ratio Theorem for Approximating the Weighted Vertex Cover Problem, </title> <journal> Annals of Discrete Mathematics, </journal> <volume> 25 (1985), </volume> <pages> pp. 27-45. </pages>
Reference-contexts: Some of these algorithms, e.g. the one due to Hochbaum [25], achieve a performance ratio of 2 f (n), where f (n) is a decreasing function of n. The best such algorithm is due to Bar-Yehuda and Even <ref> [6] </ref>, as well as Monien and Speckenmeyer [44], and it achieves a ratio of 2 O log log n . This marginal improvement turns out to be quite crucial as it leads to some strong results for graph coloring which will be presented later. <p> Their performance ratios are of the type 2f (n), where f (n) is some decreas ing function of n. The function f (n) could be 1= q (n) or 1=, where is the maximum degree in the input graph. The best such result is due to Bar-Yehuda and Even <ref> [6] </ref>, and Monien and Speckenmeyer [44]; they achieve a ratio of 2 log log n 2 log n . (This improvement may seem very minor but it leads to a significant improvement in the approximation ratio for the graph coloring problem which will be considered in a subsequent chapter.) For example, <p> The algorithm A is exactly the algorithm of Nemhauser and Trotter! 4.3.2. A Local Ratio Theorem We are now going to describe a new technique for obtaining an approximation algorithm for WVC, this is due to Bar-Yehuda and Even <ref> [4, 6] </ref>. We first show that any partition of the weight function gives two instances of WVC whose optimal solutions yield an optimal solution for original instance.
Reference: [7] <author> M.W. Bern, H.J. Karloff, P. Raghavan, and B. Schieber, </author> <title> Fast geometric approximation techniques and geometric embedding problems, </title> <booktitle> Proceedings of Fifth Annual Symposium on Computational Geometry (1989), </booktitle> <pages> pp. 292-301. </pages> <note> 127 CHAPTER 5. BIBLIOGRAPHY Page 128 </note>
Reference-contexts: This can now be generalized to the embedding of any graph, and not just the Hamiltonian cycle. Interesting approximation results of this type can be found in the work of Bern et al <ref> [7] </ref> and Hansen [23]. 1.3.4. Negative Results for Relative Approxima tion We have seen several problems which permit good approximation algorithms under the relative performance measure. However, there are a large number of problems which do not exhibit this behavior.
Reference: [8] <author> J.A. Bondy and U.S.R. Murty, </author> <title> Graph Theory with Applications, </title> <publisher> North-Holland (1976). </publisher>
Reference-contexts: Consider now the related problem of edge coloring. Here we have to color the edges of a graph with the smallest possible number of colors such that no two adjacent edges have the same color. The following theorem of Vizing <ref> [8] </ref> relates the maximum degree to the edge coloring number. Theorem 1.3: Every graph needs at least and at most + 1 colors to color its edges. fl We will not explicitly specify the various components of optimization problems in the rest of the book. CHAPTER 1.
Reference: [9] <author> N. Christofides, </author> <title> Worst-case analysis of a new heuristic for the travelling salesman problem, </title> <type> Technical Report, </type> <institution> Graduate School of Industrial Administration, Carnegie-Mellon University, </institution> <address> Pitts-burgh, PA (1976). </address>
Reference-contexts: This is the heuristic due to Christofides <ref> [9] </ref> which we will refer to as CH. The basic idea is to avoid doubling the edges in going from the MST to an Eulerian graph.
Reference: [10] <author> V. Chvatal, </author> <title> A Greedy Heuristic for the Set-Covering Problem, </title> <journal> Mathematics of Operations Research, </journal> <volume> 4 (1979), </volume> <pages> pp. 233-235. </pages>
Reference-contexts: As such, it cannot be expected to have a performance ratio better than that of G2, i.e. O (log n). However, this is still a very natural heuristic and not without any merit. In fact, Chvatal <ref> [10] </ref> has shown that it achieves this ratio, and no better, for the much more general problem of weighted hypergraph covering or weighted set covering. In the following sections we present several different approximation algorithms for WVC, all of these achieve the ratio 2. <p> The best known approximation algorithm has a performance ratio of O (log d), and this was independently discovered by Johnson [30] and Lovasz [43]. A similar result was achieved for the case of weighted hypergraphs by Chvatal <ref> [10] </ref>. We will present only the result for unweighted hypergraphs. The algorithm is essentially the greedy algorithm G2, as generalized to hypergraphs. We will also refer to this generalized algorithm as G2. Algorithm G2: Input: Hypergraph H (V; E). Output: Set cover C. 1. <p> Hochbaum [25] gives bounded ratio approximation algorithms for related problems, viz. independent sets and coloring in bounded degree graphs and planar graphs. A result that we did not cover is the approximation algorithm for weighted set cover due to Chvatal <ref> [10] </ref>. The algorithm is a generalization of the greedy algorithm described above for set cover. The result in the case of set cover may be viewed as bounding the ratio of optimal integral cover and fractional cover for hypergraphs.
Reference: [11] <author> K.L. Clarkson, </author> <title> A Modification of the Greedy Algorithm for Vertex Cover, </title> <journal> Information Processing Letters, </journal> <volume> 16 (1983), </volume> <pages> pp. 23-25. </pages>
Reference-contexts: This implied a factor of 2 approximation for vertex cover. Both these results made extensive use of a linear programming formulation. The first purely combinatorial analysis was due to Bar-Yehuda and Even [4] and this was followed by the algorithm of Clarkson <ref> [11] </ref>. All of these algorithms have essentially the same performance ratio, i.e. asymptotically equal to 2. Some of these algorithms, e.g. the one due to Hochbaum [25], achieve a performance ratio of 2 f (n), where f (n) is a decreasing function of n. <p> Unfortunately, this algorithm does not achieve any bounded ratio. But can anything be salvaged from this intuitively attractive heuristic? The answer is yes, and this is exactly the algorithm proposed by Clarkson <ref> [11] </ref>.
Reference: [12] <author> E.G. Coffman, M.R. Garey and D.S. Johnson, </author> <title> Approximation algorithms for bin packing an updated survey, in Algorithm Design for Computer System Design (ed. </title> <editor> G. Ausiello, M. Lucertini and P. Serafini), </editor> <publisher> Springer-Verlag (1984). </publisher>
Reference-contexts: Some examples are variable-sized bins and multi-dimensional bin packing. We refer the reader to the survey article by Coffman, Garey and John-son <ref> [12] </ref> for further details. It is possible to devise approximation schemes for some of these cases, generally based on the ideas described here. An example is the approximation scheme for the case of variable-sized bins due to Murgolo [45].
Reference: [13] <author> M.R. Garey and D.S. Johnson, </author> <title> Approximation algorithms for combinatorial problems: an annotated bibliography, in Algorithms and Complexity: New Directions and Recent Results (ed. </title> <editor> J.F. Traub), </editor> <publisher> Academic Press (1976). </publisher>
Reference-contexts: You could also refer to some of the other standard textbooks on combinatorial algorithms [27, 48]. Unfortunately neither of these is up-to-date and they only provide a very cursory description of 1.4. DISCUSSION Page 31 the work in this area. There are some survey articles on approximation algorithms <ref> [13, 30, 35] </ref> but again all of these are really old and outdated. A more recent article by Kannan and Korte [32] is much more useful. Problems 1-1 Using the fact that every planar graph has a vertex of degree at most 5, show that all planar graphs are 5-colorable.
Reference: [14] <author> M.R. Garey and D.S. Johnson, </author> <title> Strong NP-completeness Results: Motivations, Examples and Implications, </title> <journal> Journal of the ACM, </journal> <volume> 25 (1978), </volume> <pages> pp. 499-508. </pages>
Reference-contexts: A feasible solution solution consists of a subset X [1; . . . ; n] such that P i2X s i = B. The decision version of this problem is closely related to the BIN PACKING, SCHEDULING and KNAPSACK problems. Consider the algorithm DP <ref> [14] </ref> for PARTITION which is based on the paradigm of Dynamic Programming. The basic idea behind DP is to construct the table T i;j , for 1 i n and 0 j B. <p> This bound is valid for every "non-number" problem such as CLIQUE or HAM. We conclude that it is impossible to find pseudo-polynomial algorithms for such problems unless P = N P. This can be formalized as follows <ref> [14, 15] </ref>. Definition 2.9: Given any optimization problem , we define the problem poly as the problem restricted to only those instances I where M AX#(I) is polynomially bounded in LEN GT H (I). <p> Most reductions for number problems involve really large numbers and thus say nothing about the hardness of poly . The following theorem <ref> [14, 15] </ref> proves to be very helpful in this regard. Theorem 2.9: If 1 is strongly N P-hard, 2 is in N P, and there is a pseudo-polynomial reduction from 1 to 2 , then 2 is strongly N P-complete. <p> It seems plausible then to argue that we can find an FPAS for a problem only if it is not strongly N P-complete. This idea is formalized in the following result due to Garey and Johnson <ref> [14] </ref>. Theorem 2.10: Let be an optimization problem which has the property that for all instances I, OP T (I) is polynomially bounded in the LENGT H (I) and M AX#(I). If has a FPAS, then has a pseudo-polynomial algorithm. CHAPTER 2.
Reference: [15] <author> M.R. Garey and D.S. Johnson, </author> <title> Computers and Intractability: A Guide to the Theory of NP-Completeness, </title> <editor> W. H. </editor> <publisher> Freeman and Company (1979). </publisher>
Reference-contexts: In fact, the above definition uses the more general notion of Turing reducibility and this permits a wider applicability of the term N P-hardness. Refer to the book by Garey & Johnson <ref> [15] </ref> for a discussion of these issues. Given an N P-hard optimization problem , it is clear that we cannot find an algorithm which is guaranteed to compute an optimal solution in polynomial time for all input instances, unless P = N P. <p> The decision version of this problem is N P-hard even when restricted to graphs that are planar. We now show that the planar graph coloring problem has an absolute approximation algorithm. We first present the following theorem about the N P-hardness of the planar graph coloring <ref> [15] </ref>. Theorem 1.1: The problem of deciding whether a planar graph is 3-colorable is N P-complete. It is also well-known that any planar graph is 5-colorable. In fact, the (in)famous Four Color Theorem for planar maps [2, 3] tells us that every planar graph is 4-colorable. <p> Discussion We are following the notation of Garey and Johnson <ref> [15] </ref> which is now universally accepted. Their book is well-known as a good reference on the theory of N P-completeness. It also provides a great introduction to the area of approximation algorithms, although it is quite a bit outdated in this respect. <p> Thus, such algorithms are not really polynomially bounded in the length of the input. In this section we present a brief introduction to these notions. Refer to the book by Garey and Johnson <ref> [15] </ref> for a more thorough treatment of these concepts. We will also point out the connections between such algorithms and the construction of FPAS. We start off by defining the notion of a number problem. A combinatorial optimization problem consists of two components a combinatorial component and a numerical component. <p> We now define the following two functions which measure the size of the encoding of an input instance assuming some "reasonable" encoding scheme. z z We are presenting only an intuitive development here and the reader should refer to <ref> [15] </ref> for a more formal treatment. CHAPTER 2. APPROXIMATION SCHEMES Page 44 Definition 2.4: Given any optimization problem and a reasonable encoding of the input instance for , we define LEN GT H (I) and M AX#(I) as functions which map the input instances into positive integers. <p> This bound is valid for every "non-number" problem such as CLIQUE or HAM. We conclude that it is impossible to find pseudo-polynomial algorithms for such problems unless P = N P. This can be formalized as follows <ref> [14, 15] </ref>. Definition 2.9: Given any optimization problem , we define the problem poly as the problem restricted to only those instances I where M AX#(I) is polynomially bounded in LEN GT H (I). <p> Most reductions for number problems involve really large numbers and thus say nothing about the hardness of poly . The following theorem <ref> [14, 15] </ref> proves to be very helpful in this regard. Theorem 2.9: If 1 is strongly N P-hard, 2 is in N P, and there is a pseudo-polynomial reduction from 1 to 2 , then 2 is strongly N P-complete. <p> Once again we urge the reader to refer to the book of Garey and Johnson <ref> [15] </ref> for a more comprehensive treatment of these ideas. What does all this have to do with the approximation issue? It turns out that all known FPAS have been derived by the application of a scaling-like technique to a pseudo-polynomial algorithm, just as in the case of KNAPSACK. <p> Thus, obtaining ILP (M) requires time linear in n, given any instance M of cardinality n. How about solving ILP? Recall that the integer programming problem is N P-complete in general <ref> [15] </ref>. However, there is an algorithm due to Lenstra [41, 20, 56] which solves any integer linear program in time linear in the number of constraints, provided the number of variables is fixed. <p> This problem is one of the standard N P-complete problems <ref> [15] </ref>. As a matter of fact, the problem remains N P-complete even when the graph is planar [16]. There are more general versions of this problem where we allow G to be a hypergraph, or associate weights with vertices.
Reference: [16] <author> F. Gavril, </author> <note> cited in [15], page 134. </note>
Reference-contexts: This problem is one of the standard N P-complete problems [15]. As a matter of fact, the problem remains N P-complete even when the graph is planar <ref> [16] </ref>. There are more general versions of this problem where we allow G to be a hypergraph, or associate weights with vertices. <p> The "counter-intuitive" behavior of most approximation algorithms can be explained via the observation that it is trying to prove near-optimality. We now analyze the performance of M M ; this result is due to Gavril <ref> [16] </ref>. Theorem 4.1: Algorithm M M always computes a vertex cover in the input graph G. Moreover, R MM = 2.
Reference: [17] <author> P.C. Gilmore and R.E. Gomory, </author> <title> A linear programming approach to the cutting-stock problem, </title> <journal> Operations Research, </journal> <volume> 9 (1961), </volume> <pages> pp. 849-859. </pages>
Reference-contexts: However, it can be solved within an additive error of 1 in fully polynomial time. Moreover, the implementation of the separation oracle is in itself an approximation algorithm. The idea behind this is due to Gilmore and Gomory <ref> [17] </ref> who observed that, in the case of an infeasible proposed solution, a violated constraint can be computed via the solution of a knapsack problem. Since this is N P-complete, one must resort to the use of an approximation scheme for KNAPSACK.
Reference: [18] <author> R.L. Graham, </author> <title> Bounds for certain multiprocessing anomalies, </title> <journal> Bell Systems Technical Journal, </journal> <volume> 45 (1966), </volume> <pages> pp. 1563-1581. </pages>
Reference-contexts: Therefore it seems reasonable to relax the requirement for a "good approximation algorithm". We start by examining the problem of multiprocessor scheduling and use it to motivate the definition of relative performance guarantees. Interestingly enough, the whole field of approximation algorithms has its roots in the work of Graham <ref> [18] </ref> in 1966 on the problem of scheduling. In fact, scheduling problems probably have the most well-developed body of work from the point of view of approximation algorithms. <p> They are to be scheduled on m machines/processors so as to minimize the finish time. We have already seen some approximation algorithms with bounded ratios for this problem. We now present a PAS for this problem due to Graham <ref> [18] </ref>. Assume that n &gt; m, and that the run-times are arranged in nonincreasing order (i.e. i &lt; j implies that p i p j ). Note that the latter assumption can be easily fulfilled by sorting the jobs based on their run-times.
Reference: [19] <author> M. Grotschel, L. Lovasz and A. Schrijver, </author> <title> The ellipsoid method and its consequences in combinatorial optimization, </title> <journal> Combinatorica, </journal> <volume> 1 (1981), </volume> <pages> pp. 169-197. Page 129 </pages>
Reference-contexts: The reason is that the number of variables is still exponential in 1=*. All we have achieved is that we no longer need to solve an integer program. Karmakar and Karp showed how to get around this problem by resorting to the Ellipsoid method of Grotschel, Lovasz and Schri-jver <ref> [19, 20, 56] </ref>. In this method, it is possible to solve a linear program with an exponential number of constraints in time which is polynomial in the number of variables and the number sizes, given a separation oracle.
Reference: [20] <author> M. Grotschel, L. Lovasz and A. Schrijver, </author> <title> Geometric Algorithms and Combinatorial Optimization, </title> <publisher> Springer-Verlag (1987). </publisher>
Reference-contexts: Thus, obtaining ILP (M) requires time linear in n, given any instance M of cardinality n. How about solving ILP? Recall that the integer programming problem is N P-complete in general [15]. However, there is an algorithm due to Lenstra <ref> [41, 20, 56] </ref> which solves any integer linear program in time linear in the number of constraints, provided the number of variables is fixed. <p> The reason is that the number of variables is still exponential in 1=*. All we have achieved is that we no longer need to solve an integer program. Karmakar and Karp showed how to get around this problem by resorting to the Ellipsoid method of Grotschel, Lovasz and Schri-jver <ref> [19, 20, 56] </ref>. In this method, it is possible to solve a linear program with an exponential number of constraints in time which is polynomial in the number of variables and the number sizes, given a separation oracle.
Reference: [21] <author> L. Guibas, </author> <type> Personal communication, </type> <year> 1992. </year>
Reference: [22] <author> D. Gusfield and L. Pitt, </author> <title> Understanding approximations for node cover and other subset selection algorithms, </title> <type> Technical Report YaleU/DCS/TR-308, </type> <institution> Department of Computer Science, Yale University, </institution> <year> 1984. </year>
Reference-contexts: It should now be clear that the "counter-intuitive" part of the algorithm is actually a device for ensuring that the cover being produced does not stray too far from the optimal cover. For a further discussion on this point, refer to the article by Gusfield and Pitt <ref> [22] </ref>. Fact 4.4: For all vertices v 2 V and edges e 2 E W (v) 0 at all times during the execution of the algorithm. Proof: The second inequality is obvious since the only modification to the edge costs is the addition of a positive value. <p> A good example is M GA which actually reduces the weights of the neighbors of the vertices already in the cover, thus increasing the likelihood that these neighbors are also selected to be in the cover. See the paper by Gusfield and Pitt <ref> [22] </ref> for a partial explanation of why such algorithms actually perform better than more intuitive algorithms such as G2. This also gives a more unified view of most of the algorithms considered above.
Reference: [23] <author> M.D. Hansen, </author> <title> Approximation Algorithms for Geometric Embed-dings in the Plane with Applications to Parallel Processing Problems, </title> <booktitle> Proceedings of 30th Annual Symposium on Foundations of Computer Science (1989), </booktitle> <pages> pp. 604-611. </pages>
Reference-contexts: This can now be generalized to the embedding of any graph, and not just the Hamiltonian cycle. Interesting approximation results of this type can be found in the work of Bern et al [7] and Hansen <ref> [23] </ref>. 1.3.4. Negative Results for Relative Approxima tion We have seen several problems which permit good approximation algorithms under the relative performance measure. However, there are a large number of problems which do not exhibit this behavior.
Reference: [24] <author> D.S. Hochbaum, </author> <title> Approximation Algorithms for Set Covering and Vertex Cover Problems, </title> <journal> SIAM Journal on Computing, </journal> <volume> 11 (1982), </volume> <pages> pp. 555-556. </pages>
Reference-contexts: Some amount of history is in order at this point. The very first approximation algorithm for WVC was implicit in the work of Nemhauser and Trotter [46]. This algorithm was made explicit by Hochbaum [25]. Hochbaum <ref> [24] </ref> had devised an approximation algorithm for the set cover problem with a performance ratio equal to the size of the largest set. This implied a factor of 2 approximation for vertex cover. Both these results made extensive use of a linear programming formulation. <p> Clearly, this is merely an implementation detail and has no bearing on the ratio achieved. CHAPTER 4. VERTEX COVER AND SET COVER Page 114 Another application of the Local Ratio Theorem is in improving the performance ratio of the algorithm devised by Hochbaum <ref> [24] </ref>. Her algorithm was based on the following novel idea. First, run Algorithm N T to obtain an instance G [V 0 ] with an optimal solution of weight at least half of w (V 0 ). Suppose now that we can color the input graph G with k colors.
Reference: [25] <author> D.S. Hochbaum, </author> <title> Efficient Bounds for the Stable Set, Vertex Cover and Set Packing Problems, </title> <journal> Discrete Applied Mathematics, </journal> <volume> 6 (1983), </volume> <pages> pp. 243-254. </pages>
Reference-contexts: Some amount of history is in order at this point. The very first approximation algorithm for WVC was implicit in the work of Nemhauser and Trotter [46]. This algorithm was made explicit by Hochbaum <ref> [25] </ref>. Hochbaum [24] had devised an approximation algorithm for the set cover problem with a performance ratio equal to the size of the largest set. This implied a factor of 2 approximation for vertex cover. Both these results made extensive use of a linear programming formulation. <p> The first purely combinatorial analysis was due to Bar-Yehuda and Even [4] and this was followed by the algorithm of Clarkson [11]. All of these algorithms have essentially the same performance ratio, i.e. asymptotically equal to 2. Some of these algorithms, e.g. the one due to Hochbaum <ref> [25] </ref>, achieve a performance ratio of 2 f (n), where f (n) is a decreasing function of n. The best such algorithm is due to Bar-Yehuda and Even [6], as well as Monien and Speckenmeyer [44], and it achieves a ratio of 2 O log log n . <p> See the paper by Gusfield and Pitt [22] for a partial explanation of why such algorithms actually perform better than more intuitive algorithms such as G2. This also gives a more unified view of most of the algorithms considered above. Hochbaum <ref> [25] </ref> gives bounded ratio approximation algorithms for related problems, viz. independent sets and coloring in bounded degree graphs and planar graphs. A result that we did not cover is the approximation algorithm for weighted set cover due to Chvatal [10].
Reference: [26] <author> I. Holyer, </author> <title> The NP-completeness of edge coloring, </title> <journal> SIAM Journal of Computing, </journal> <volume> 10 (1981), </volume> <pages> pp. 718-720. </pages>
Reference-contexts: It is therefore amazing that even a very special case of the edge coloring problem is N P-hard, as described in the following theorem of Holyer <ref> [26] </ref>. Theorem 1.4: The problem of determining the number of colors needed for a 3-regular planar graph is N P-hard. Putting all this together we can construct another absolute approximation algorithm for an N P-hard optimization problem.
Reference: [27] <author> E. Horowitz and S. Sahni, </author> <title> Fundamentals of Computer Algorithms, </title> <publisher> Computer Science Press (1978). </publisher>
Reference-contexts: It also provides a great introduction to the area of approximation algorithms, although it is quite a bit outdated in this respect. You could also refer to some of the other standard textbooks on combinatorial algorithms <ref> [27, 48] </ref>. Unfortunately neither of these is up-to-date and they only provide a very cursory description of 1.4. DISCUSSION Page 31 the work in this area. There are some survey articles on approximation algorithms [13, 30, 35] but again all of these are really old and outdated.
Reference: [28] <author> O.H. Ibarra and C.E. Kim, </author> <title> Fast approximation algorithms for the knapsack and sum of subset problems, </title> <journal> Journal of the ACM, </journal> <volume> 22 (1975), </volume> <pages> pp. 463-468. </pages>
Reference-contexts: Let V = i p i . We derive an algorithm A * from A K by setting K = V * +1 ) n . This gives us an FPAS for KNAPSACK as proved in the following theorem <ref> [28] </ref>. The running time is polynomial in both the length of the input and the inverse of *. Theorem 2.5: The algorithm A * runs in time O * and has Proof: The running time is easily obtained from the above defini tions. <p> The proof of correctness is by means of a simple induction on i and is omitted. The following theorem results. Theorem 2.7: Algorithm P P solves KNAPSACK exactly in time O (n 3 P log SB). This result is due to Ibarra and Kim <ref> [28] </ref>, and a more efficient FPAS has been presented by Lawler [39]. CHAPTER 2. APPROXIMATION SCHEMES Page 48 2.5. Strong N P -completeness and FPAS Let us try to better understand the implications of a pseudo-polynomial algorithms for N P-complete problems.
Reference: [29] <author> D.S. Johnson, </author> <title> The NP-completeness column: an ongoing guide, </title> <journal> Journal of Algorithms, </journal> <volume> 3 (1982), </volume> <pages> pp. 288-300. </pages>
Reference-contexts: Near-Absolute Approximation We conclude by presenting a technique of Karmakar and Karp which gives an approximation algorithm with an error that is bounded by a slowly increasing function of OP T (I). This result is a step towards devising an absolute approximation algorithm for BIN PACKING. In fact, Johnson <ref> [29] </ref> had observed that the Vega-Lueker scheme could be modified to construct an approximation algorithm with a performance bounded by OP T (I) + O 1ffi , for some positive constant ffi, by letting the value of * depend on the instance I.
Reference: [30] <author> D.S. Johnson, </author> <title> Approximation algorithms for combinatorial problems, </title> <journal> Journal of Computer and System Sciences, </journal> <volume> 9 (1974), </volume> <pages> pp. 256-278. </pages>
Reference-contexts: You could also refer to some of the other standard textbooks on combinatorial algorithms [27, 48]. Unfortunately neither of these is up-to-date and they only provide a very cursory description of 1.4. DISCUSSION Page 31 the work in this area. There are some survey articles on approximation algorithms <ref> [13, 30, 35] </ref> but again all of these are really old and outdated. A more recent article by Kannan and Korte [32] is much more useful. Problems 1-1 Using the fact that every planar graph has a vertex of degree at most 5, show that all planar graphs are 5-colorable. <p> However, as we will see later, this algorithm is not totally useless. It will be shown that it always achieves the ratio O (log n) for the much more general problem of set cover <ref> [30, 43] </ref>, and hence also for vertex cover. We now describe a different heuristic which achieves a bounded ratio for the vertex cover problem. The basic idea is to modify G1 by placing both end-points of some uncovered edge into C. <p> In fact, there is some evidence to the effect that such an approximation is impossible to find in polynomial time. The best known approximation algorithm has a performance ratio of O (log d), and this was independently discovered by Johnson <ref> [30] </ref> and Lovasz [43]. A similar result was achieved for the case of weighted hypergraphs by Chvatal [10]. We will present only the result for unweighted hypergraphs. The algorithm is essentially the greedy algorithm G2, as generalized to hypergraphs. We will also refer to this generalized algorithm as G2. <p> See the paper by Aharoni, Erdos and Linial for a more general version of this result, i.e. a study of the ratio between the optimal fractional and integral solutions to a class of integer programs. A different version of the set cover was studied by Johnson <ref> [30] </ref>. Here, as before, the objective is to find a collection of vertices which cover all the edges but the value of a cover is now defined to be the sum of the degrees of the vertices in the cover, rather than the size of the cover.
Reference: [31] <author> D.S. Johnson, A. Demers, J.D. Ullman, M.R. Garey and R.L. Graham, </author> <title> Worst-case performance bounds for simple one-dimensional packing algorithms, </title> <journal> SIAM Journal on Computing, </journal> <volume> 3 (1974), </volume> <pages> pp. 299-325. </pages> <note> CHAPTER 5. BIBLIOGRAPHY Page 130 </note>
Reference-contexts: But the total size of all the items is also a lower bound on the value of the optimal solution. This gives the desired bound. 2 Actually, much stronger bounds were obtained for the First Fit algorithm by Johnson et al <ref> [31] </ref> in 1974. They established the following result. Theorem 1.10: R 1 FF = 1:7 and more precisely we have the following bounds. * 8I; F F (I) 1:7OP T (I) + 2 It is fairly easy to see an example where F F (I) 5 3 OP T (I).
Reference: [32] <author> R. Kannan and B. </author> <title> Korte, Approximative Combinatorial Algorithms, </title> <note> Mathematical Programming 1984 (ed. R.W. Cottle, M.L. </note> <editor> Kelmanson and B. </editor> <booktitle> Korte), </booktitle> <pages> pp. 195-248. </pages>
Reference-contexts: DISCUSSION Page 31 the work in this area. There are some survey articles on approximation algorithms [13, 30, 35] but again all of these are really old and outdated. A more recent article by Kannan and Korte <ref> [32] </ref> is much more useful. Problems 1-1 Using the fact that every planar graph has a vertex of degree at most 5, show that all planar graphs are 5-colorable.
Reference: [33] <author> N. Karmakar, </author> <title> A new polynomial-time algorithm for linear programming, </title> <journal> Combinatorica, </journal> <volume> 4 (1984), </volume> <pages> pp. 373-395. </pages>
Reference-contexts: The only problem is that it is not obvious that we can solve the linear program in fully polynomial time, even though there exist polynomial time algorithms for linear programming <ref> [33] </ref>, unlike the general problem of integer programming. The reason is that the number of variables is still exponential in 1=*. All we have achieved is that we no longer need to solve an integer program.
Reference: [34] <author> N. Karmakar and R.M. Karp, </author> <title> An Efficient Approximation Scheme For The One-Dimensional Bin Packing Problem, </title> <booktitle> Proceedings of 23rd Annual Symposium on Foundations of Computer Science (1982), </booktitle> <pages> pp. 312-320. </pages>
Reference-contexts: It was therefore a big shock when Vega and Lueker [59] presented an Asymptotic PAS for Bin Packing in 1981. This shock was compounded when Karmakar and Karp <ref> [34] </ref> transformed this result into an Asymptotic FPAS for BIN PACKING. These two results will be our next topic of discussion. In conclusion, we would like to offer some observations about the above development. Consider the SCHEDULING problem. <p> These may be summarized as follows: * Elimination of "small" items. * Interval Partitioning or Linear Grouping. * Rounding of "Fractional" Solutions. We then present the modification of this result due to Karmakar and Karp <ref> [34] </ref> which led to an AFPAS for BIN PACKING. They gave an approximation scheme with a performance guarantee similar to the one described above; the running time was improved to O * 8 . In fact, a variation of their ideas leads to a stronger result.
Reference: [35] <author> R.M. Karp, </author> <title> The fast approximate solution of hard combinatorial problems, </title> <booktitle> Proceedings of 6th Southeastern Conference on Combinatorics, Graph Theory and Computing, Utilitas Mathematics (1975), </booktitle> <pages> pp. 15-31. </pages>
Reference-contexts: You could also refer to some of the other standard textbooks on combinatorial algorithms [27, 48]. Unfortunately neither of these is up-to-date and they only provide a very cursory description of 1.4. DISCUSSION Page 31 the work in this area. There are some survey articles on approximation algorithms <ref> [13, 30, 35] </ref> but again all of these are really old and outdated. A more recent article by Kannan and Korte [32] is much more useful. Problems 1-1 Using the fact that every planar graph has a vertex of degree at most 5, show that all planar graphs are 5-colorable.
Reference: [36] <author> B. Korte and R. Schrader, </author> <title> On the existence of fast approximation schemes, Nonlinear Programming, </title> <booktitle> 4 (1980), </booktitle> <pages> pp. 415-437. </pages>
Reference-contexts: For constructing a PAS, the technique is k-enumeration whose applications have been demonstrated above. The techniques for FPAS are rounding/scaling and interval partitioning, some aspects of which were seen above and are further demonstrated in the algorithms for BIN PACKING that follow. An interesting result of Korte and Schrader <ref> [36] </ref> shows that essentially the only way to construct PAS/FPAS is by means of these techniques. This result is proved in the context of independence systems but appear to be reasonably powerful in their application.
Reference: [37] <author> L. Kucera, </author> <title> The complexity of clique finding algorithms, </title> <type> unpublished manuscript. </type>
Reference-contexts: It is not very hard to modify the proof of Theorem 1.7 to obtain the following hardness result for CLIQUE. A series of such results have been obtained by Nigmatullin [47] and Kucera <ref> [37] </ref>. Theorem 1.17: For all constants *, K &gt; 0, there is no approximation algorithm A for the CLIQUE problem such that jA (I) OP T (I)j K OP T (I) 1.3.
Reference: [38] <author> E.L. Lawler, </author> <title> Combinatorial Optimization: Networks and Matroids, </title> <publisher> Holt, Rinehart & Winston (1976). </publisher>
Reference-contexts: Since G is complete, there exists a matching for every set S. Moreover, using standard results <ref> [38] </ref>, the minimum-weight matching in G for S can be found in polynomial time. It is relatively easy to modify the MST heuristic to incorporate the ideas presented above. We obtain the following result for Christofides heuristic. <p> Note that the MST heuristic is very efficient since it runs in almost linear time. The heuristic due to Christofides is much more inefficient since finding a minimum weight matching <ref> [38] </ref> requires time O (n 3 ). An interesting open problem is to find a simple construction of a class of algorithms which allows a smooth trade-off between the running time and the performance ratio. <p> The WVC problem restricted to bipartite graphs is polynomially solvable via a reduction to the maximum CHAPTER 4. VERTEX COVER AND SET COVER Page 100 flow problem <ref> [38] </ref>. This works by constructing a directed network from B G . Introduce a source s into B G with an edge going to each vertex in L of capacity equal to the weight of that vertex.
Reference: [39] <author> E.L. Lawler, </author> <title> Fast Approximation Algorithms for Knapsack Problems, </title> <booktitle> Proceedings of 18th Annual Symposium on Foundations of Computer Science (1977), </booktitle> <pages> pp. 206-213. </pages>
Reference-contexts: The following theorem results. Theorem 2.7: Algorithm P P solves KNAPSACK exactly in time O (n 3 P log SB). This result is due to Ibarra and Kim [28], and a more efficient FPAS has been presented by Lawler <ref> [39] </ref>. CHAPTER 2. APPROXIMATION SCHEMES Page 48 2.5. Strong N P -completeness and FPAS Let us try to better understand the implications of a pseudo-polynomial algorithms for N P-complete problems.
Reference: [40] <author> E.L. Lawler, J.K. Lenstra, A.H.G. Rinnooy Kan and D.B. Shmoys, </author> <title> Sequencing and Scheduling: Algorithms and Complexity, </title> <booktitle> in Handbooks in Operations Research and Management Science, </booktitle> <volume> Vol. 4: </volume> <booktitle> Logistics of Production and Inventory (1990). </booktitle>
Reference-contexts: In fact, scheduling problems probably have the most well-developed body of work from the point of view of approximation algorithms. In this book, however, we will not be able to cover most of these results and the reader is referred to the survey article by Lawler et al <ref> [40] </ref> for further details. CHAPTER 1. INTRODUCTION Page 16 1.3.1. Multiprocessor Scheduling Consider the simplest version of the multiprocessor scheduling problem. The input consists of n jobs, J 1 ; J 2 ; . . . ; J n .
Reference: [41] <author> H.W. Lenstra, </author> <title> Integer programming with a fixed number of variables, </title> <journal> Mathematics of Operations Research, </journal> <volume> 8 (1983), </volume> <pages> pp. 538-548. </pages>
Reference-contexts: Thus, obtaining ILP (M) requires time linear in n, given any instance M of cardinality n. How about solving ILP? Recall that the integer programming problem is N P-complete in general [15]. However, there is an algorithm due to Lenstra <ref> [41, 20, 56] </ref> which solves any integer linear program in time linear in the number of constraints, provided the number of variables is fixed.
Reference: [42] <author> R.J. Lipton and R.E. Tarjan, </author> <title> Applications of a planar separator theorem, </title> <booktitle> Proceedings of the 18th Annual Symposium on Foundations of Computer Science (1977), </booktitle> <pages> pp. 162-170. Page 131 </pages>
Reference-contexts: For example, we will see shortly an approximation algorithm A for BIN PACKING where jA (I) OP T (I)j O (log 2 OP T (I)). Another example is the result of Lipton and Tar-jan <ref> [42] </ref> where it is shown that there is an approximation algorithm A for finding maximum independent sets in planar graphs such that jA (I) OP T (I)j O @ q 1 using the planar separator theorem.
Reference: [43] <author> L. Lovasz, </author> <title> On the Ratio of Optimal Integral and Fractional Covers, </title> <journal> Discrete Mathematics, </journal> <volume> 13 (1975), </volume> <pages> pp. 383-390. </pages>
Reference-contexts: However, as we will see later, this algorithm is not totally useless. It will be shown that it always achieves the ratio O (log n) for the much more general problem of set cover <ref> [30, 43] </ref>, and hence also for vertex cover. We now describe a different heuristic which achieves a bounded ratio for the vertex cover problem. The basic idea is to modify G1 by placing both end-points of some uncovered edge into C. <p> In fact, there is some evidence to the effect that such an approximation is impossible to find in polynomial time. The best known approximation algorithm has a performance ratio of O (log d), and this was independently discovered by Johnson [30] and Lovasz <ref> [43] </ref>. A similar result was achieved for the case of weighted hypergraphs by Chvatal [10]. We will present only the result for unweighted hypergraphs. The algorithm is essentially the greedy algorithm G2, as generalized to hypergraphs. We will also refer to this generalized algorithm as G2.
Reference: [44] <author> B. Monien and E. Speckenmeyer, </author> <title> Ramsey Numbers and an Approximation Algorithm for the Vertex Cover Problem, </title> <journal> Acta In-formatica, </journal> <volume> 22 (1985), </volume> <pages> pp. 115-123. </pages>
Reference-contexts: Some of these algorithms, e.g. the one due to Hochbaum [25], achieve a performance ratio of 2 f (n), where f (n) is a decreasing function of n. The best such algorithm is due to Bar-Yehuda and Even [6], as well as Monien and Speckenmeyer <ref> [44] </ref>, and it achieves a ratio of 2 O log log n . This marginal improvement turns out to be quite crucial as it leads to some strong results for graph coloring which will be presented later. <p> The function f (n) could be 1= q (n) or 1=, where is the maximum degree in the input graph. The best such result is due to Bar-Yehuda and Even [6], and Monien and Speckenmeyer <ref> [44] </ref>; they achieve a ratio of 2 log log n 2 log n . (This improvement may seem very minor but it leads to a significant improvement in the approximation ratio for the graph coloring problem which will be considered in a subsequent chapter.) For example, on graphs with at most
Reference: [45] <author> F.D. Murgolo, </author> <title> An efficient approximation scheme for variable-sized bin packing, </title> <journal> SIAM Journal on Computing, </journal> <volume> 16 (1987), </volume> <pages> pp. 149-161. </pages>
Reference-contexts: It is possible to devise approximation schemes for some of these cases, generally based on the ideas described here. An example is the approximation scheme for the case of variable-sized bins due to Murgolo <ref> [45] </ref>. Several open problems remain, most notably in the case of on-line bin packing and multi-dimensional bin packing. There is a big gap between the upper and lower bound on the achievable ratios for multi-dimensional bin packing it is exponential in the dimension. Problems 3.4.
Reference: [46] <author> G.L. Nemhauser and L.E. Trotter, Jr., </author> <title> Vertex Packing: Structural Properties and Algorithms, </title> <journal> Mathematical Programming, </journal> <volume> 8 (1975), </volume> <pages> pp. 232-248. </pages>
Reference-contexts: One is a simple intuitive algorithm which is not very efficient, while the other achieves efficiency at the cost of being more mystifying. Some amount of history is in order at this point. The very first approximation algorithm for WVC was implicit in the work of Nemhauser and Trotter <ref> [46] </ref>. This algorithm was made explicit by Hochbaum [25]. Hochbaum [24] had devised an approximation algorithm for the set cover problem with a performance ratio equal to the size of the largest set. This implied a factor of 2 approximation for vertex cover.
Reference: [47] <author> R.G. Nigmatullin, </author> <title> Complexity of the approximate solution of combinatorial problems, </title> <journal> Soviet Mathematical Doklady, </journal> <volume> 16 (1975), </volume> <pages> pp. 1199-1203. </pages>
Reference-contexts: It is not very hard to modify the proof of Theorem 1.7 to obtain the following hardness result for CLIQUE. A series of such results have been obtained by Nigmatullin <ref> [47] </ref> and Kucera [37]. Theorem 1.17: For all constants *, K &gt; 0, there is no approximation algorithm A for the CLIQUE problem such that jA (I) OP T (I)j K OP T (I) 1.3.
Reference: [48] <author> C.H. Papadimitriou and K. Steiglitz, </author> <title> Combinatorial Optimization: Algorithms and Complexity, </title> <publisher> Prentice Hall (1982). </publisher>
Reference-contexts: It also provides a great introduction to the area of approximation algorithms, although it is quite a bit outdated in this respect. You could also refer to some of the other standard textbooks on combinatorial algorithms <ref> [27, 48] </ref>. Unfortunately neither of these is up-to-date and they only provide a very cursory description of 1.4. DISCUSSION Page 31 the work in this area. There are some survey articles on approximation algorithms [13, 30, 35] but again all of these are really old and outdated. <p> To analyze the relationship between the fractional and integral solutions to any instance we will have to use some basic facts from the theory of linear programming. The uninitiated reader is referred to any standard text-book for a more complete treatment, e.g. see the book by Papadimitriou and Steiglitz <ref> [48] </ref>. Consider the system of linear equations implicit in the constraint fl ~x:A = ~n. Here we have m linear equations in q variables, where q is fl We will ignore the non-negativity constraints for now as they do not bear upon the following discussion. CHAPTER 3.
Reference: [49] <author> V.Th. Paschos, </author> <title> A Theorem on the Approximation of Set Cover and Vertex Cover, </title> <booktitle> to appear in Eleventh Conference on Foundations of Software Technology and Theoretical Computer Sci-enceai (FSTTCS 11), </booktitle> <address> New Delhi (India), </address> <year> 1991. </year>
Reference: [50] <author> L. Pitt, </author> <title> A Simple Probabilistic Approximation Algorithm for Vertex Cover, </title> <type> Technical Report YaleU/DCS/TR-404, </type> <institution> Department of Computer Science, Yale University, </institution> <year> 1985. </year>
Reference-contexts: Of course, it is entirely possible that one can find an approximation scheme for VC, but this is considered unlikely. We will provide some evidence for this later on. We conclude by describing a simple randomized algorithm due to Pitt <ref> [50] </ref> which also achieves the ratio 2 for VC, albeit in the expected sense. y One good reason for studying this algorithm is that it can be easily generalized to the case of weighted vertex cover to yield a simple approximation algorithm with an expected performance ratio of 2. <p> In the following sections we present several different approximation algorithms for WVC, all of these achieve the ratio 2. The first is a simple randomized algorithm due to Pitt <ref> [50] </ref>. In the subsequent sections 4.2. APPROXIMATING WEIGHTED VERTEX COVER Page 91 we describe two deterministic approximation algorithms for WVC. One is a simple intuitive algorithm which is not very efficient, while the other achieves efficiency at the cost of being more mystifying. <p> Thus, it is the ratio of the weight to the current degree which determines the chances of a vertex being selected at each stage. The following theorem is due to Pitt <ref> [50] </ref>. Theorem 4.3: Exp [W RA (G; w)] 2 c fl (G; w), and this bound is tight. The rest of this section is devoted to the proof of this theorem.
Reference: [51] <author> D.J. Rosenkrantz, R.E. Stearns and P.M. Lewis, </author> <title> An analysis of several heuristics for the traveling salesman problem, </title> <journal> SIAM Journal on Computing, </journal> <volume> 6 (1977), </volume> <pages> pp. 563-581. </pages>
Reference-contexts: Finally, the cycle is completed by returning to the starting vertex. This is a natural heuristic but its performance is very poor as demonstrated by the following result due to Rosenkrantz et al <ref> [51] </ref>. Theorem 1.12: Let n denote the number of vertices in an instance of TSP. Then, R 1 NN = fi (log n) However, it turns out that we can do much better by using more complex ideas. <p> Then, R 1 NN = fi (log n) However, it turns out that we can do much better by using more complex ideas. In fact, there are several heuristics known to achieve an asymptotic ratio of 2 <ref> [51] </ref>. Most of the good heuristics for TSP are based on finding an Eulerian tour and then using "short-cuts" to obtain a Hamiltonian tour. We start by reviewing the notion of an Eulerian tour (refer to any standard graph theory book for more details). 1.3.
Reference: [52] <author> C. Savage, </author> <title> Depth First Search and the Vertex Cover Problem, </title> <journal> Information Processing Letters, </journal> <month> 14 </month> <year> (1982). </year>
Reference-contexts: Exercise 4.2: Show that using a maximum matching instead of a maximal matching does not improve the worst-case performance of M M. Another algorithm which achieves a ratio of 2 for this problem is due to Savage <ref> [52] </ref>. This algorithm, which we call DF S, is as simple as 4.1. APPROXIMATING VERTEX COVER Page 87 the one outlined above. The basic idea is to find a depth-first search tree in the graph G. The cover C is then the set of non-leaf nodes in the tree.
Reference: [53] <author> S. Sahni, </author> <title> Approximate algorithms for the 0/1 knapsack problem, </title> <journal> Journal of the ACM, </journal> <volume> 22 (1975), </volume> <pages> pp. 115-124. </pages>
Reference-contexts: We leave the proof of the following theorem as an easy exercise. Theorem 2.3: R MGA = 2 In 1975, Sahni <ref> [53] </ref> came up with a PAS for this problem. The basic idea was quite similar to the one used for the scheduling problem. For all k, 0 k n, define the algorithm A k as follows.
Reference: [54] <author> S. Sahni, </author> <title> General Techniques for Combinatorial Approximation, </title> <journal> Operations Research, </journal> <volume> 25 (1977), </volume> <pages> pp. 920-936. </pages> <note> CHAPTER 5. BIBLIOGRAPHY Page 132 </note>
Reference-contexts: APPROXIMATION SCHEMES Page 52 cannot be even an Asymptotic FPAS (without leading to a FPAS and therefore a pseudo-polynomial algorithm) for SCHEDULING. This is in contrast to BIN PACKING which does not have a PAS, but does have an Asymptotic FPAS! 2.6. Discussion Sahni <ref> [54] </ref> gives general techniques for constructing PAS and FPAS. For constructing a PAS, the technique is k-enumeration whose applications have been demonstrated above. <p> Note that the reason this is an APAS, and not a PAS, is the additive error term of 1 in this bound. The basic techniques used in this result were similar to those used earlier for other problems such as Knapsack <ref> [54] </ref>. These may be summarized as follows: * Elimination of "small" items. * Interval Partitioning or Linear Grouping. * Rounding of "Fractional" Solutions. We then present the modification of this result due to Karmakar and Karp [34] which led to an AFPAS for BIN PACKING.
Reference: [55] <author> S. Sahni and T. Gonzalez, </author> <title> P-complete approximation problems, </title> <journal> Journal of the ACM, </journal> <volume> 23 (1976), </volume> <pages> pp. 555-565. </pages>
Reference-contexts: Finally, there are the really hard problems for which R MIN is unbounded. In the rest of this chapter we examine a few problems of the latter type. Consider the general TSP problem, i.e. without the triangle inequality. The following theorem due to Sahni and Gonzalez <ref> [55] </ref> shows that this is a really hard problem to approximate. Note that, as usual, the hardness of an approximation problem is predicated upon P and N P being different. Theorem 1.16: If P 6= N P then R MIN (T SP ) = 1.
Reference: [56] <author> A. Schrijver, </author> <title> Theory of Linear and Integer Programming, </title> <publisher> John Wiley & Sons (1986). </publisher>
Reference-contexts: Thus, obtaining ILP (M) requires time linear in n, given any instance M of cardinality n. How about solving ILP? Recall that the integer programming problem is N P-complete in general [15]. However, there is an algorithm due to Lenstra <ref> [41, 20, 56] </ref> which solves any integer linear program in time linear in the number of constraints, provided the number of variables is fixed. <p> The reason is that the number of variables is still exponential in 1=*. All we have achieved is that we no longer need to solve an integer program. Karmakar and Karp showed how to get around this problem by resorting to the Ellipsoid method of Grotschel, Lovasz and Schri-jver <ref> [19, 20, 56] </ref>. In this method, it is possible to solve a linear program with an exponential number of constraints in time which is polynomial in the number of variables and the number sizes, given a separation oracle.
Reference: [57] <author> P.M. Vaidya, </author> <title> Geometry helps in matching, </title> <journal> SIAM Journal on Computing, </journal> <volume> 18 (1989), </volume> <pages> pp. 1201-1225. </pages>
Reference-contexts: An interesting open problem is to find a simple construction of a class of algorithms which allows a smooth trade-off between the running time and the performance ratio. The results of Vaidya <ref> [57, 58] </ref> on exact and approximate minimum-weight matching (for points in the Euclidean plane) does give a tradeoff, but it would seem that better results should be possible.
Reference: [58] <author> P.M. Vaidya, </author> <title> Approximate minimum weight matching on points in k-dimensional space, </title> <note> Algorithmica (1990). </note>
Reference-contexts: An interesting open problem is to find a simple construction of a class of algorithms which allows a smooth trade-off between the running time and the performance ratio. The results of Vaidya <ref> [57, 58] </ref> on exact and approximate minimum-weight matching (for points in the Euclidean plane) does give a tradeoff, but it would seem that better results should be possible.
Reference: [59] <author> W. Fernandez de la Vega and G.S. Lueker, </author> <title> Bin Packing can be solved within 1 + * in Linear Time, </title> <journal> Combinatorica, </journal> <volume> 1 (1981), </volume> <pages> pp. 349-355. </pages>
Reference-contexts: In fact, most people had assumed that strong N P-completeness even implied that no Asymptotic PAS/FPAS could be be devised for the problem, unless P = N P. It was therefore a big shock when Vega and Lueker <ref> [59] </ref> presented an Asymptotic PAS for Bin Packing in 1981. This shock was compounded when Karmakar and Karp [34] transformed this result into an Asymptotic FPAS for BIN PACKING. These two results will be our next topic of discussion. <p> The first result that we present is due to Vega and Lueker <ref> [59] </ref>. They provide an APAS for BIN PACKING which runs in linear time and has A * (I) (1 + *) OP T (I) + 1. The running time is linear in 53 CHAPTER 3.
Reference: [60] <author> A. Wigderson, </author> <title> Improving the Performance Guarantee for Approximate Graph Coloring, </title> <journal> Journal of the ACM, </journal> <volume> 30 (1983), </volume> <pages> pp. 729-735. </pages>
Reference-contexts: In the special case of planar graphs, we can improve the ratio to 1:5 by noting that every planar graph can be 4-colored [2, 3]. We now observe that the approximate graph coloring algorithm of Wigderson <ref> [60] </ref> (which we will see in a later chapter) will color a graph using at most 2 p n colors provided it is triangle-free. This helps in improving the algorithm of Hochbaum, in conjunction with the use of the Local Ratio Corollary.
References-found: 60

