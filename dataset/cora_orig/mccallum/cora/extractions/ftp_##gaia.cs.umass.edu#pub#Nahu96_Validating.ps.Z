URL: ftp://gaia.cs.umass.edu/pub/Nahu96:Validating.ps.Z
Refering-URL: http://www-net.cs.umass.edu/papers/papers.html
Root-URL: 
Email: nahum@cs.umass.edu  
Title: Validating an Architectural Simulator  
Author: Erich M. Nahum 
Date: September 1996  96-40  
Address: Amherst  
Affiliation: Department of Computer Science University of Massachusetts at  Department of Computer Science  
Pubnum: Technical Report  
Abstract: This paper reports on our experiences in building an execution-driven architectural simulator that is meant to accurately capture performance costs of a machine for a particular class of software, namely, network protocol stacks such as TCP/IP. The simulator models a single processor of our Silicon Graphics Challenge shared-memory multiprocessor, which has 100 MHz MIPS R4400 chips and two levels of cache memory. We describe our validation approach, show accuracy results averaging within 5 percent, and present the lessons learned in validating an architectural simulator.
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Jean-Loup Baer and Wen-Hann Wang. </author> <title> On the inclusion property for multi-level cache hierarchies. </title> <booktitle> In Proceedings 15th International Symposium on Computer Architecture, </booktitle> <pages> pages 73-80, </pages> <address> Honolulu Hawaii, </address> <month> June </month> <year> 1988. </year>
Reference-contexts: Thus, an application executing in the simulator may experience conflicts between two lines in L2 that would not occur in the real system, and vice-versa. The impact on accuracy may be exacerbated by the inclusion property <ref> [1] </ref>, which requires that, for coherency reasons, all lines cached in L1 must be held in L2.
Reference: [2] <author> Robert C. Bedichek. Talisman: </author> <title> Fast and accurate multicomputer simulation. </title> <booktitle> In Proceedings of the ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems, </booktitle> <pages> pages 14-24, </pages> <address> Ottawa, Canada, </address> <month> May </month> <year> 1995. </year>
Reference-contexts: The primary goal of this simulator has been to accurately model performance costs for our SGI machine. Much of the simulation literature discusses the tradeoff between speed and accuracy, and describes techniques for making simulations fast. However, accuracy is rarely discussed (notable exceptions include <ref> [2, 4, 5] </ref>), and the tradeoff between accuracy and speed has not been quantitatively evaluated. Given that our simulator is meant to capture performance costs, it must be more than an emulator that duplicates the execution semantics of the hardware or counts events such as cache misses.
Reference: [3] <author> Edouard Bugnion, Jennifer M. Anderson, Todd C. Mowry, Mendel Rosenblum, and Monica S. Lam. </author> <title> Compiler-directed page coloring for multiprocessors. </title> <booktitle> In Proceedings of the Seventh International Symposium on Architectural Support for Programming Languages and Operating Systems (ASPLOS VII), </booktitle> <address> Cambridge MA, </address> <month> October </month> <year> 1996. </year>
Reference-contexts: However, in our SGI systems, the second-level cache is physically indexed. The mapping between virtual and physical addresses on the real system is determined by the IRIX operating system. It is reported that IRIX 5.3 uses page coloring <ref> [3, 9] </ref> as a virtual-to-physical mapping strategy. In page coloring, whenever a new virtual-to-physical mapping is created, the OS attempts to assign a free physical page so that both the virtual and physical addresses map to the same bin in a physically indexed cache.
Reference: [4] <author> Brad Calder, Dirk Grunwald, and Joel Emer. </author> <title> A system level perspective on branch architecture performance. </title> <booktitle> In Proceedings of the 28th Annual IEEE/ACM International Symposium on Microarchitecture, </booktitle> <pages> pages 199-206, </pages> <address> Ann Arbor, MI, </address> <month> November </month> <year> 1995. </year> <month> 13 </month>
Reference-contexts: The primary goal of this simulator has been to accurately model performance costs for our SGI machine. Much of the simulation literature discusses the tradeoff between speed and accuracy, and describes techniques for making simulations fast. However, accuracy is rarely discussed (notable exceptions include <ref> [2, 4, 5] </ref>), and the tradeoff between accuracy and speed has not been quantitatively evaluated. Given that our simulator is meant to capture performance costs, it must be more than an emulator that duplicates the execution semantics of the hardware or counts events such as cache misses.
Reference: [5] <author> Amer Diwan, David Tarditi, and Eliot Moss. </author> <title> Memory-system performance of programs with intensive heap allocation. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 13(3) </volume> <pages> 244-273, </pages> <year> 1995. </year>
Reference-contexts: The primary goal of this simulator has been to accurately model performance costs for our SGI machine. Much of the simulation literature discusses the tradeoff between speed and accuracy, and describes techniques for making simulations fast. However, accuracy is rarely discussed (notable exceptions include <ref> [2, 4, 5] </ref>), and the tradeoff between accuracy and speed has not been quantitatively evaluated. Given that our simulator is meant to capture performance costs, it must be more than an emulator that duplicates the execution semantics of the hardware or counts events such as cache misses.
Reference: [6] <author> Mile Galles and Eric Williams. </author> <title> Performance optimizations, implementation, and verification of the SGI Challenge multiprocessor. </title> <type> Technical report, </type> <institution> Silicon Graphics Inc., Mt. View, </institution> <address> CA, </address> <month> May </month> <year> 1994. </year>
Reference-contexts: 1 Introduction We have designed and implemented a execution-driven uniprocessor simulator for our 100 MHz R4400-based SGI Challenge <ref> [6] </ref>. The purpose of this simulator is to understand the performance costs of a network protocol stack running in user space on our SGI machine, and to guide us in identifying and reducing bottlenecks [11].
Reference: [7] <author> Joe Heinrich. </author> <title> MIPS R4000 Microprocessor Users Manual (2nd Ed.). MIPS Technologies, </title> <publisher> Inc., </publisher> <address> Mt. View, CA, </address> <year> 1994. </year>
Reference-contexts: in or Function Cycles div 75 divu 75 mult 2 multu 2 uspsema 113 usvsema 113 malloc 70 free 70 sginap 6000 gettimeofday 1580 Table 2: Instructions that take more than 1 cycle Unfortunately, only a small subset of timing values are available in the MIPS R4000 Microprocessor Users Manual <ref> [7] </ref>. For instructions not listed there, we needed to construct micro-benchmarks to determine their cycle times. Table 2 presents the cycle times of instructions, functions, and system calls used that do not follow the single-cycle instruction assumption. These values are fed into MINT via the cycle file.
Reference: [8] <author> John L. Hennessy and David A. Patterson. </author> <title> Computer Architecture: A Quantitative Approach (2nd Edition). </title> <publisher> Morgan Kaufmann Publishers Inc., </publisher> <address> San Francisco, CA, </address> <year> 1995. </year>
Reference-contexts: The single cycle assumption implies that the pipeline never stalls, which is not true under certain conditions. For example, if an instruction loads a value from memory into a register, and the subsequent instruction uses that register, the latter instruction will stall. This stalling is called a pipeline interlock <ref> [8] </ref>. MINT does not yet model pipeline interlocks. To accurately model load delay pipeline interlocks, we instead keep track of loads in the back end. In the R4000, loads have a 2-cycle load delay.
Reference: [9] <author> Richard E. Kessler and Mark D. Hill. </author> <title> Page placement algorithms for large real-indexed caches. </title> <journal> ACM Transactions on Computer Systems, </journal> <volume> 10(4) </volume> <pages> 338-359, </pages> <month> November </month> <year> 1992. </year>
Reference-contexts: However, in our SGI systems, the second-level cache is physically indexed. The mapping between virtual and physical addresses on the real system is determined by the IRIX operating system. It is reported that IRIX 5.3 uses page coloring <ref> [3, 9] </ref> as a virtual-to-physical mapping strategy. In page coloring, whenever a new virtual-to-physical mapping is created, the OS attempts to assign a free physical page so that both the virtual and physical addresses map to the same bin in a physically indexed cache.
Reference: [10] <author> Larry McVoy and Carl Staelin. LMBENCH: </author> <title> Portable tools for performance analysis. </title> <booktitle> In USENIX Technical Conference of UNIX and Advanced Computing Systems, </booktitle> <address> San Diego, CA, </address> <month> January </month> <year> 1996. </year>
Reference-contexts: Our protocol benchmarks have cache hit rates ranging from 75-100 percent, and spend between 15 and 75 percent of time waiting for memory. We also evaluate accuracy on memory-intensive microbenchmarks from LMBench <ref> [10] </ref>. We have not evaluated accuracy on numeric (i.e., floating-point) benchmarks such as the SPEC 95 FP suite. On the workloads that we have tested, we find that the simulator predicts latencies that are, on average, within 5 percent of the actual measured latencies. <p> This accurately covers the cost of both jump instructions and all taken branches, so that we do not need to change their cycle time values. 2.4 Modeling Memory References We used the memory striding benchmarks from LMBench <ref> [10] </ref> to measure the cache hit and miss latencies for all three levels of the memory hierarchy: L1, L2, and main memory. These in turn gave us values with which to parameterize the back-end cache simulator.
Reference: [11] <author> Erich M. Nahum, David J. Yates, James F. Kurose, and Don Towsley. </author> <title> Cache behavior of network protocols. </title> <note> In preparation, </note> <month> August </month> <year> 1996. </year>
Reference-contexts: The purpose of this simulator is to understand the performance costs of a network protocol stack running in user space on our SGI machine, and to guide us in identifying and reducing bottlenecks <ref> [11] </ref>. The primary goal of this simulator has been to accurately model performance costs for our SGI machine. Much of the simulation literature discusses the tradeoff between speed and accuracy, and describes techniques for making simulations fast.
Reference: [12] <author> Karl Pettis and Robert C. Hansen. </author> <title> Profile guided code positioning. </title> <booktitle> In ACM SIGPLAN `90 Conference on Programming Language Design and Implementation (PLDI), </booktitle> <pages> pages 16-27, </pages> <address> White Plains, NY, </address> <month> June </month> <year> 1990. </year>
Reference-contexts: Table 6 presents more accuracy results, this time modifying the protocol benchmarks by adding copies (COPY ON), or by executing the CORDed versions of the executables. CORD [13] is a binary re-writing tool that uses profile-guided code positioning <ref> [12] </ref> to reorganize executables for better instruction cache behavior. An original executable is run through Pixie [14] to determine its runtime behavior and profile which procedures are used most frequently. CORD uses this information to re-link the executable so that procedures used most frequently are grouped together.
Reference: [13] <institution> Silicon Graphics Inc. </institution> <note> Cord manual page, IRIX 5.3. </note>
Reference-contexts: Note the average error is within 5 percent, with the worst case error being about 15 percent. Table 6 presents more accuracy results, this time modifying the protocol benchmarks by adding copies (COPY ON), or by executing the CORDed versions of the executables. CORD <ref> [13] </ref> is a binary re-writing tool that uses profile-guided code positioning [12] to reorganize executables for better instruction cache behavior. An original executable is run through Pixie [14] to determine its runtime behavior and profile which procedures are used most frequently.
Reference: [14] <author> Michael D. Smith. </author> <title> Tracing with Pixie. </title> <type> Technical report, </type> <institution> Center for Integrated Systems, Stanford University, Stanford, </institution> <address> CA, </address> <month> April </month> <year> 1991. </year>
Reference-contexts: CORD [13] is a binary re-writing tool that uses profile-guided code positioning [12] to reorganize executables for better instruction cache behavior. An original executable is run through Pixie <ref> [14] </ref> to determine its runtime behavior and profile which procedures are used most frequently. CORD uses this information to re-link the executable so that procedures used most frequently are grouped together.
Reference: [15] <author> Jack E. Veenstra and Robert J. Fowler. MINT: </author> <title> A front end for efficient simulation of shared-memory multiprocessors. </title> <booktitle> In Proceedings 2nd International Workshop on Modeling, Analysis, </booktitle> <institution> and Simulation of Computer and Telecommunication Systems (MASCOTS), Durham, NC, </institution> <month> January </month> <year> 1994. </year> <month> 14 </month>
Reference-contexts: This paper reports on our experiences in constructing this simulator. We describe our simulator, enumerate our assumptions, show our approach to validation, and present accuracy results. We conclude with the lessons learned in validating an architectural simulator. 2 Architectural Simulator Our architectural simulator is built using MINT <ref> [15] </ref>, a toolkit for implementing multiprocessor memory reference simulators. MINT interprets a compiled binary directly and executes it, albeit much more slowly than if the binary was run on the native machine. This process is called direct execution.
References-found: 15

