URL: http://www.cs.ucsb.edu/~murat/WAIT-FREE.ps
Refering-URL: http://www.cs.ucsb.edu/~murat/
Root-URL: http://www.cs.ucsb.edu
Title: A Technique for Implementing Highly Concurrent Wait-free Objects for Shared Memory Multi-processors DRAFT  
Author: Murat Karaorman, John Bruno 
Affiliation: Department of Computer Science University of California, Santa Barbara  
Abstract-found: 0
Intro-found: 1
Reference: [1] <author> Lamport, L., </author> <title> Concurrent Reading and Writing. </title> <journal> Communications of the ACM. </journal> <volume> Vol. 20, No. 11, </volume> <month> November </month> <year> 1977, </year> <pages> pp. 806-811. </pages>
Reference-contexts: Typically support for critical sections is provided by using some form of locking [locks, spin-locks, semaphores, monitors, etc.,] or some other software solution providing mutual exclusion. L.Lamport <ref> [1] </ref> in 1977 has introduced the first example of an alternative approach to mutual exclusion, on a simple application which allowed concurrent reading and writing. His approach, however, is not general enough to be applicable to most concurrent algorithms.
Reference: [2] <author> Lamport, L., </author> <title> Concurrent Reading and Writing of Clocks. </title> <type> Technical Report. No 27. </type> <institution> Digital Corporation Systems Research Center, </institution> <month> April 1, </month> <year> 1988. </year>
Reference-contexts: As part of their implementation, Massalin and Pu also give non-blocking implementations of certain abstract data types such as stacks, queues and linked lists [7]. Lamport has given a non-blocking algorithm for concurrent reading and writing of clocks <ref> [2] </ref>. While these algorithms are ad-hoc, they do show a different way of thinking about doing updates without mutual exclusion. Jayanti Chandra and Toueg have studied the problem of tolerating object failures [14].
Reference: [3] <author> Herlihy, M. </author> <title> Wait-Free Synchronization. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 11, No. 1, </volume> <month> January </month> <year> 1991, </year> <pages> pp. 124-149. </pages>
Reference-contexts: L.Lamport [1] in 1977 has introduced the first example of an alternative approach to mutual exclusion, on a simple application which allowed concurrent reading and writing. His approach, however, is not general enough to be applicable to most concurrent algorithms. Later M.Herlihy <ref> [3] </ref> introduced wait-free synchronization technique as a general purpose alternative to the lock-based or other blocking concurrency techniques. <p> conditional (obj, new version): ) stores the value of new version at the address pointed to by 'obj' if the value at that address has not been modified since it was last read using load linked (obj) then return SUCCESS else return FAIL, leaving *obj unchanged. 2.1 M.Herlihy's work Herlihy <ref> [3] </ref> has presented a universal-object construction algorithm. This algorithm has been theoretically interesting but the proposed construction is regarded as being too inefficient to be practical. In [5] Herlihy proposed a methodology for transforming sequential specification for objects into non-blocking or wait-free implementations of concurrent objects. <p> Herlihy also proposed a wait-free method that uses a technique which he calls operation combining. This method is more expensive than the non-blocking one as it involves more overhead due to starvation prevention. Operation combining resembles the original 'wait-free' universal object construction of <ref> [3] </ref>. Different threads help finish an on-going operation even if the process who requested that operation has failed. Herlihy's non-blocking method for large objects can informally be summarized as: A large object is represented by a set of blocks linked by pointers.
Reference: [4] <author> Herlihy, M., Wing, J. </author> <title> Linearizability: A Correctness Condition for Concurrent Objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 12, No. 3, </volume> <month> July </month> <year> 1990, </year> <pages> pp. 463-492. </pages>
Reference-contexts: His approach, however, is not general enough to be applicable to most concurrent algorithms. Later M.Herlihy [3] introduced wait-free synchronization technique as a general purpose alternative to the lock-based or other blocking concurrency techniques. Wait-free synchronization is based on a correctness criteria called linearizability <ref> [4] </ref> which implies that the processes appear to be interleaved at the granularity of complete operations, and the real-time ordering of the non-overlapping operations are preserved. Herlihy has also shown that certain primitive atomic operations were required [to be supplied by the underlying hardware] to support wait-free synchronization.
Reference: [5] <author> Herlihy, M. </author> <title> A Methodology for Implementing Highly Concurrent Data Objects. </title> <journal> ACM Transactions on Programming Languages and Systems, </journal> <volume> Vol. 15, No. 5, </volume> <month> November </month> <year> 1993, </year> <pages> pp. 745-770. </pages>
Reference-contexts: Herlihy's universal-wait-free-object construction has been regarded as 'very expensive' to implement, and many researchers (including Herlihy) have proposed more efficient techniques based on a weaker synchronization technique called non-blocking <ref> [5] </ref>, [8], [15]. A non-blocking concurrent system guarantees that at least one process can complete any operation in a finite number of steps, regardless of the execution speeds of other processes. <p> This algorithm has been theoretically interesting but the proposed construction is regarded as being too inefficient to be practical. In <ref> [5] </ref> Herlihy proposed a methodology for transforming sequential specification for objects into non-blocking or wait-free implementations of concurrent objects. For performance reasons, he has two different approaches for dealing with small objects and large objects. Small objects are those that are small enough to be copied efficiently. <p> Cost of copying becomes a real problem when the sizes of the shared data objects are large. Also differences in process (or) speeds may require additional consistency checking (or validation) techniques to ensure memory coherence <ref> [5] </ref> even when dealing with small objects. 2. Retrying. Lost labor by the processes that 'lose' while trying to install their private copy of the object as the primary object. Those processes need to discard the work they have completed and recopy and re-do the operation and 'compete' once again. <p> There are some other problems that are related to 'retrying': First, when contention is high, performance degrades severely, this issue have been addressed (1) by using an adaptive backoff strategy <ref> [5] </ref>, and (2) by controlling the number of competing processes at any given time [21]. Despite these two optimizations, the high-contention performance favors the 'spin-lock' alternatives to non-blocking ones. <p> Despite these two optimizations, the high-contention performance favors the 'spin-lock' alternatives to non-blocking ones. The second issue is starvation, a weakness of most non-blocking methods because there are no guarantees that any given process will eventually succeed. As reported by Herlihy <ref> [5] </ref>, the starvation issue is a 'real' problem especially when long operations are competing against short operations, where short operations almost always beat longer ones since they finish earlier with a higher chance of installing their copy first.
Reference: [6] <author> Herlihy, M., Moss, J.E.B., </author> <title> Transactional Memory: Architectural Support for Lock-Free Data Structures. </title> <type> Technical Report. CRL 92/07, </type> <institution> Digital Equipment Corporation Cambridge Research Lab, </institution> <month> December 1, </month> <year> 1992. </year>
Reference-contexts: A non-blocking concurrent system guarantees that at least one process can complete any operation in a finite number of steps, regardless of the execution speeds of other processes. There has also been work which focuses on providing hardware support <ref> [6] </ref>, and operating-system support [21] to improve efficiency of wait-free or non-blocking techniques. Most of the recent research has been based on giving up the freedom of starvation-freeness of wait-free approach in exchange for improved performance in non-blocking implementations.
Reference: [7] <author> Massalin, H., Pu, C. </author> <title> A Lock-Free Multiprocessor OS Kernel. </title> <type> Technical Report. </type> <institution> CUCS-005-91, Columbia University, </institution> <month> June 19, </month> <year> 1991. </year>
Reference-contexts: As part of their implementation, Massalin and Pu also give non-blocking implementations of certain abstract data types such as stacks, queues and linked lists <ref> [7] </ref>. Lamport has given a non-blocking algorithm for concurrent reading and writing of clocks [2]. While these algorithms are ad-hoc, they do show a different way of thinking about doing updates without mutual exclusion. Jayanti Chandra and Toueg have studied the problem of tolerating object failures [14].
Reference: [8] <author> Barnes, G. </author> <title> A Method for Implementing Lock-free Shared Data Structures. </title> <booktitle> In Proceedings of ACM-SPAA '93 Conference (June 1993, </booktitle> <address> Velen, </address> <pages> Ger-many) pp. 261-270. </pages>
Reference-contexts: Herlihy's universal-wait-free-object construction has been regarded as 'very expensive' to implement, and many researchers (including Herlihy) have proposed more efficient techniques based on a weaker synchronization technique called non-blocking [5], <ref> [8] </ref>, [15]. A non-blocking concurrent system guarantees that at least one process can complete any operation in a finite number of steps, regardless of the execution speeds of other processes. <p> linked (obj ptr); 2. apply the sequential operation to the // logically distinct private versions. 3. store conditional the logically distinct version. // If this attemp fails, // restarts by going back to step 1. 2.2 Barnes's Approach Barnes's work attempts to derive lock-free (non-blocking) object implementations from sequential implementations <ref> [8] </ref>. His primary goal is to increase the copying efficiency in Herlihy's approach. Barnes employs a 2 part method: cooperative technique and caching method. The shared data is partitioned into disjoints sets called cells and each thread tries to claim the cells it will need to perform its sequential operation.
Reference: [9] <author> Karaorman, M. and Bruno, J. </author> <title> Introducing Con-currency to a Sequential Language. </title> <journal> Communications of the ACM. </journal> <month> 37(8) (September </month> <year> 1993), </year> <pages> pp. 103-116. </pages>
Reference-contexts: As reported in [20] there is an evolving trend favoring message passing architectures over shared memory machines mostly for performance reasons and supporting shared-memory programming model to program the multiprocessors. We are planning to relate our experiences with object-oriented concurrency <ref> [9] </ref> [11] [10] and operating systems [12] by utilizing the wait-free synchronization technique that is outlined in this paper. In particular, we are interested in using our wait-free synchronization technique in concurrent object-oriented programming as a general intra-object synchronization mechanism.
Reference: [10] <author> Karaorman, M. and Bruno, J. </author> <title> Design and Implementation Issues for Object-Oriented Concur-rency. </title> <booktitle> In Proceedings of OOPSLA '93 Workshop on Efficient Implementation of Concurrent Object-Oriented Languages(September 27, 1993, </booktitle> <address> Washington D.C.) </address> <booktitle> Distributed at the workshop. Edited by: L.V. Kale. </booktitle> <pages> pp. </pages>
Reference-contexts: As reported in [20] there is an evolving trend favoring message passing architectures over shared memory machines mostly for performance reasons and supporting shared-memory programming model to program the multiprocessors. We are planning to relate our experiences with object-oriented concurrency [9] [11] <ref> [10] </ref> and operating systems [12] by utilizing the wait-free synchronization technique that is outlined in this paper. In particular, we are interested in using our wait-free synchronization technique in concurrent object-oriented programming as a general intra-object synchronization mechanism.
Reference: [11] <author> Karaorman, M., and Bruno, J. </author> <title> A concurrency mechanism for sequential Eiffel. </title> <booktitle> In Proceedings of TOOLS USA '92 Conference(Aug. </booktitle> <address> 3-6 , Santa Barbara, Calif.). </address> <publisher> Prentice Hall 1992, pp.63-77. </publisher>
Reference-contexts: As reported in [20] there is an evolving trend favoring message passing architectures over shared memory machines mostly for performance reasons and supporting shared-memory programming model to program the multiprocessors. We are planning to relate our experiences with object-oriented concurrency [9] <ref> [11] </ref> [10] and operating systems [12] by utilizing the wait-free synchronization technique that is outlined in this paper. In particular, we are interested in using our wait-free synchronization technique in concurrent object-oriented programming as a general intra-object synchronization mechanism.
Reference: [12] <author> Probert, D., Bruno, J., Karaorman, M. </author> <title> SPACE: </title>
Reference-contexts: As reported in [20] there is an evolving trend favoring message passing architectures over shared memory machines mostly for performance reasons and supporting shared-memory programming model to program the multiprocessors. We are planning to relate our experiences with object-oriented concurrency [9] [11] [10] and operating systems <ref> [12] </ref> by utilizing the wait-free synchronization technique that is outlined in this paper. In particular, we are interested in using our wait-free synchronization technique in concurrent object-oriented programming as a general intra-object synchronization mechanism.
References-found: 12

