URL: http://www.cs.jhu.edu/~cowen/nc.ps
Refering-URL: http://www.cs.jhu.edu/~cowen/
Root-URL: http://www.cs.jhu.edu
Title: Low-Diameter Graph Decomposition is in NC  
Author: Baruch Awerbuch Bonnie Berger Lenore Cowen David Peleg 
Abstract: We obtain the first NC algorithm for the low-diameter graph decomposition problem on arbitrary graphs. Our algorithm runs in O(log 5 (n)) time, and uses O(n 2 ) processors. 
Abstract-found: 1
Intro-found: 1
Reference: [1] <author> Y. Afek and M. Riklin. Sparser: </author> <title> A paradigm for running distributed algorithms. </title> <editor> J. </editor> <booktitle> of Algorithms, </booktitle> <year> 1991. </year> <note> Accepted for publication. </note>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (poly log n). The graph decomposition problem was introduced in [3, 6] as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see <ref> [8, 7, 11, 4, 1, 14] </ref>. Linial and Saks [11] have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139. <p> We now use the Y i 's to set the r i so that they have the desired property. Let t be the most significant bit position in which Y i contains a 0. Set r i = N IL if t 2 <ref> [1; ::; log (1=ff)] </ref> = B otherwise. It should be clear that the values of the r i 's have the right probability distribution; however, we do need to argue that the r i 's are pairwise independent.
Reference: [2] <author> N. Alon, L. Babai, and A. Itai. </author> <title> A fast and simple randomized parallel algorithm for the maximal independent set problem. </title> <journal> J. of Algorithms, </journal> <volume> 7 </volume> <pages> 567-583, </pages> <year> 1986. </year>
Reference-contexts: We could however devise a quadratic size sample space which would give us pairwise independent r y 's with the right property (see <ref> [10, 12, 2] </ref>). Unfortunately, this approach would require O (n 5 ) processors: the benefit function must be evaluated on O (n 2 ) different processors simultaneously.
Reference: [3] <author> Baruch Awerbuch. </author> <title> Complexity of network synchronization. </title> <journal> J. of the ACM, </journal> <volume> 32(4) </volume> <pages> 804-823, </pages> <month> Oc-tober </month> <year> 1985. </year>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (poly log n). The graph decomposition problem was introduced in <ref> [3, 6] </ref> as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see [8, 7, 11, 4, 1, 14]. Linial and Saks [11] have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139.
Reference: [4] <author> Baruch Awerbuch, Bonnie Berger, Lenore Cowen, and David Peleg. </author> <title> Fast distributed network decomposition. </title> <booktitle> In Proc. 11th ACM Symp. on Principles of Distributed Computing, </booktitle> <month> August </month> <year> 1992. </year> <month> 11 </month>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (poly log n). The graph decomposition problem was introduced in [3, 6] as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see <ref> [8, 7, 11, 4, 1, 14] </ref>. Linial and Saks [11] have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139.
Reference: [5] <author> Baruch Awerbuch, Bonnie Berger, Lenore Cowen, and David Peleg. </author> <title> Near-linear cost constructions of neighborhood covers in sequential and distributed environments and their applications. </title> <booktitle> In Proc. 34rd IEEE Symp. on Foundations of Computer Science. IEEE, </booktitle> <month> November </month> <year> 1993. </year> <note> to appear. </note>
Reference-contexts: Our (deterministic) NC algorithm runs in O (log 5 (n)) time and uses O (n 2 ) processors. The (; d)-decomposition problem is related to the sparse t-neighborhood cover problem [8], which has applications to sequential approximation algorithms for all-pairs shortest paths <ref> [5, 9] </ref> and finding small edge cuts in planar graphs [15]. We believe the NC algorithm in this paper will also have applications to parallel graph algorithms. 2 The Algorithm In this section, we construct a deterministic NC algorithm for low-diameter graph decomposition.
Reference: [6] <author> Baruch Awerbuch, Andrew Goldberg, Michael Luby, and Serge Plotkin. </author> <title> Network decomposition and locality in distributed computation. </title> <booktitle> In Proc. 30th IEEE Symp. on Foundations of Computer Science, </booktitle> <month> May </month> <year> 1989. </year>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (poly log n). The graph decomposition problem was introduced in <ref> [3, 6] </ref> as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see [8, 7, 11, 4, 1, 14]. Linial and Saks [11] have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139.
Reference: [7] <author> Baruch Awerbuch and David Peleg. </author> <title> Network synchronization with polylogarithmic overhead. </title> <booktitle> In Proc. 31st IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 514-522, </pages> <year> 1990. </year>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (poly log n). The graph decomposition problem was introduced in [3, 6] as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see <ref> [8, 7, 11, 4, 1, 14] </ref>. Linial and Saks [11] have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139.
Reference: [8] <author> Baruch Awerbuch and David Peleg. </author> <title> Sparse partitions. </title> <booktitle> In Proc. 31st IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 503-513, </pages> <year> 1990. </year>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (poly log n). The graph decomposition problem was introduced in [3, 6] as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see <ref> [8, 7, 11, 4, 1, 14] </ref>. Linial and Saks [11] have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139. <p> Our (deterministic) NC algorithm runs in O (log 5 (n)) time and uses O (n 2 ) processors. The (; d)-decomposition problem is related to the sparse t-neighborhood cover problem <ref> [8] </ref>, which has applications to sequential approximation algorithms for all-pairs shortest paths [5, 9] and finding small edge cuts in planar graphs [15].
Reference: [9] <author> Edith Cohen. </author> <title> Fast algorithms for constructing t-spanners and paths with stretch t. </title> <booktitle> In Proc. 34rd IEEE Symp. on Foundations of Computer Science. IEEE, </booktitle> <month> November </month> <year> 1993. </year> <note> to appear. </note>
Reference-contexts: Our (deterministic) NC algorithm runs in O (log 5 (n)) time and uses O (n 2 ) processors. The (; d)-decomposition problem is related to the sparse t-neighborhood cover problem [8], which has applications to sequential approximation algorithms for all-pairs shortest paths <ref> [5, 9] </ref> and finding small edge cuts in planar graphs [15]. We believe the NC algorithm in this paper will also have applications to parallel graph algorithms. 2 The Algorithm In this section, we construct a deterministic NC algorithm for low-diameter graph decomposition.
Reference: [10] <author> R. M. Karp and A. Wigderson. </author> <title> A fast parallel algorithm for the maximal independent set problem. </title> <journal> J. of the ACM, </journal> <volume> 32(4) </volume> <pages> 762-773, </pages> <month> October </month> <year> 1985. </year>
Reference-contexts: This is achieved by modifying an RNC algorithm of Linial-Saks to depend only on pairwise independence, and then removing the randomness. To get our newly-devised pairwise independent benefit function <ref> [10, 13] </ref> to work, we have to employ a non-trivial scaling technique. Scaling has been used previously only on the simple measure of node degree in a graph. 2.1 The RNC Algorithm of Linial-Saks Linial and Saks's randomized algorithm [11] emulates the following simple greedy procedure. Pick a color. <p> It should be clear that the values of the r i 's have the right probability distribution; however, we do need to argue that the r i 's are pairwise independent. It is easy to see <ref> [10, 13] </ref> that, for all k, the kth bits of all the Y i 's are pairwise independent if ! (k) is generated randomly; and thus the Y i 's are pairwise independent. <p> We could however devise a quadratic size sample space which would give us pairwise independent r y 's with the right property (see <ref> [10, 12, 2] </ref>). Unfortunately, this approach would require O (n 5 ) processors: the benefit function must be evaluated on O (n 2 ) different processors simultaneously.
Reference: [11] <author> N. Linial and M. Saks. </author> <title> Decomposing graphs into regions of small diameter. </title> <booktitle> In Proc. 2nd ACM-SIAM Symp. on Discrete Algorithms, </booktitle> <pages> pages 320-330. </pages> <address> ACM/SIAM, </address> <month> January </month> <year> 1991. </year>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (poly log n). The graph decomposition problem was introduced in [3, 6] as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see <ref> [8, 7, 11, 4, 1, 14] </ref>. Linial and Saks [11] have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139. <p> The graph decomposition problem was introduced in [3, 6] as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see [8, 7, 11, 4, 1, 14]. Linial and Saks <ref> [11] </ref> have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139. Supported by Air Force Contract TNDGAFOSR-86-0078, ARO contract DAAL03-86-K-0171, NSF contract CCR8611442, DARPA contract N00014-92-J-1799, and a special grant from IBM. y Dept. of Mathematics and Lab. for Computer Science, M.I.T., Cambridge, MA 02139. <p> To get our newly-devised pairwise independent benefit function [10, 13] to work, we have to employ a non-trivial scaling technique. Scaling has been used previously only on the simple measure of node degree in a graph. 2.1 The RNC Algorithm of Linial-Saks Linial and Saks's randomized algorithm <ref> [11] </ref> emulates the following simple greedy procedure. Pick a color. <p> The diameter of the resulting clusters is therefore bounded by 2B. Setting B = O (log n), they can expect to color a constant fraction of the remaining nodes at each phase. So their algorithm uses O (log n) colors. (See their paper <ref> [11] </ref> for a discussion of trade-offs between diameter and number of colors. <p> For each iteration i of a phase, set ff = 2 i =(3). Each node y selects an integer radius r y pairwise independently at random according to the truncated geometric distribution scaled by ff (defined in Section 2.2). We can assume every node has a unique ID <ref> [11] </ref>. Each node y broadcasts (r y ; ID y ) to all nodes that are within distance r y of it. <p> Linial and Saks <ref> [11] </ref> have lower bounded this probability for their algorithm's phases by summing over all possible winners of y, and essentially calculating the probability that a given winner captures y and no other winners of higher ID capture y.
Reference: [12] <author> M. Luby. </author> <title> A simple parallel algorithm for the maximal independent set problem. </title> <journal> SIAM J. on Comput., </journal> <volume> 15(4) </volume> <pages> 1036-1053, </pages> <month> November </month> <year> 1986. </year>
Reference-contexts: We could however devise a quadratic size sample space which would give us pairwise independent r y 's with the right property (see <ref> [10, 12, 2] </ref>). Unfortunately, this approach would require O (n 5 ) processors: the benefit function must be evaluated on O (n 2 ) different processors simultaneously.
Reference: [13] <author> M. Luby. </author> <title> Removing randomness in parallel computation without a processor penalty. </title> <booktitle> In Proc. 29th IEEE Symp. on Foundations of Computer Science, </booktitle> <pages> pages 162-173. </pages> <publisher> IEEE, </publisher> <month> October </month> <year> 1988. </year>
Reference-contexts: This is achieved by modifying an RNC algorithm of Linial-Saks to depend only on pairwise independence, and then removing the randomness. To get our newly-devised pairwise independent benefit function <ref> [10, 13] </ref> to work, we have to employ a non-trivial scaling technique. Scaling has been used previously only on the simple measure of node degree in a graph. 2.1 The RNC Algorithm of Linial-Saks Linial and Saks's randomized algorithm [11] emulates the following simple greedy procedure. Pick a color. <p> It should be clear that the values of the r i 's have the right probability distribution; however, we do need to argue that the r i 's are pairwise independent. It is easy to see <ref> [10, 13] </ref> that, for all k, the kth bits of all the Y i 's are pairwise independent if ! (k) is generated randomly; and thus the Y i 's are pairwise independent. <p> Unfortunately, this approach would require O (n 5 ) processors: the benefit function must be evaluated on O (n 2 ) different processors simultaneously. Alternatively, we will use a variant of a method of Luby <ref> [13] </ref> to binary search a pairwise independent distribution for a good sample point. We can in fact naively apply this method because our benefit function is a sum of terms depending on one or two variables each; i.e.
Reference: [14] <author> Alessandro Pasconesi and Aravind Srinivasan. </author> <title> Improved algorithms for network decompositions. </title> <booktitle> In Proc. 24th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 581-592, </pages> <year> 1992. </year>
Reference-contexts: A (; d)-decomposition is said to be low-diameter if and d are both O (poly log n). The graph decomposition problem was introduced in [3, 6] as a means of partitioning a network into local regions. For further work on graph decomposition and the distributed computing model, see <ref> [8, 7, 11, 4, 1, 14] </ref>. Linial and Saks [11] have given the only algorithm that fl Lab. for Computer Science, M.I.T., Cambridge, MA 02139.
Reference: [15] <author> Satish Rao. </author> <title> Finding small edge cuts in planar graphs. </title> <booktitle> In Proc. 24th ACM Symp. on Theory of Computing, </booktitle> <pages> pages 229-240, </pages> <year> 1992. </year> <month> 12 </month>
Reference-contexts: The (; d)-decomposition problem is related to the sparse t-neighborhood cover problem [8], which has applications to sequential approximation algorithms for all-pairs shortest paths [5, 9] and finding small edge cuts in planar graphs <ref> [15] </ref>. We believe the NC algorithm in this paper will also have applications to parallel graph algorithms. 2 The Algorithm In this section, we construct a deterministic NC algorithm for low-diameter graph decomposition.
References-found: 15

