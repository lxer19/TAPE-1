URL: http://www.isi.edu/~pedro/PUBLICATIONS/cocoon96.ps.Z
Refering-URL: http://www.isi.edu/~pedro/PUBLICATIONS/cocoon96.html
Root-URL: http://www.isi.edu
Email: fibarra,pedro,marting@cs.ucsb.edu  
Title: On the Complexity of Commutativity Analysis  
Author: Oscar Ibarra Pedro Diniz and Martin Rinard 
Address: Santa Barbara, CA 93106  
Affiliation: Department of Computer Science University of California, Santa Barbara  
Abstract: Two operations commute if they generate the same result regardless of the order in which they execute. Commutativity is an important property | commuting operations enable significant optimizations in the fields of parallel computing, optimizing compilers, parallelizing compilers and database concurrency control. Algorithms that statically decide if operations commute can be an important component of systems in these fields because they enable the automatic application of these optimizations. In this paper we define the commutativity decision problem and establish its complexity for a variety of basic instructions and control constructs. Although deciding commutativity is, in general, undecidable or computationally intractable, we believe that efficient algorithms exist that can solve many of the cases that arise in practice.
Abstract-found: 1
Intro-found: 1
Reference: 1. <author> A. Aho, J. Hopcroft and J. Ullman. </author> <title> Data Structures and Algorithms. </title> <publisher> Addison-Wesley, </publisher> <year> 1982. </year>
Reference-contexts: If neither method writes an instance variable the other method either reads or writes, the method are independent. Clearly this algorithm can be implemented in polynomial time with respect to both the method's length and the number of instance variables using set representation techniques <ref> [1] </ref>. 4.2 Reduction A common operation in many applications is to reduce many values into one accumulator variable by applying a commutative and associative operator such as + or fl.
Reference: 2. <author> J. Barnes and P. Hut. </author> <title> A hierarchical O(NlogN) force-calculation algorithm. </title> <booktitle> Nature, </booktitle> <pages> pages 446-449, </pages> <month> December </month> <year> 1976. </year>
Reference-contexts: The algorithms handle both scalar and array variables [13]. 5 Applications in Parallelizing Compilers We have identified several complete scientific applications whose computations are structured as commuting updates to dynamic pointer-based data structures. These applications include the Barnes-Hut <ref> [2] </ref> hierarchical N-body algorithm and the molecular dynamics code Water 1 . In the Barnes-Hut application, the algorithm maintains and performs multiple traversals on a spatial pointer-based tree data structure.
Reference: 3. <author> M. Berry et al. </author> <title> The PERFECT Club Benchmarks: Effective Performance Evaluation of Supercomputers. </title> <type> Technical Report CSRD-827, </type> <institution> Center for Supercomputing Research and Development, University of Illinois, Urbana, IL, </institution> <month> May, </month> <year> 1989. </year>
Reference-contexts: Our practical experience developing a compiler that uses commutativity analysis as its basic analysis framework supports this belief. 1 A FORTRAN language variant of the Water code used in our analysis can be found in the PERFECT Benchmark <ref> [3] </ref> set of applications under the name MDG.
Reference: 4. <author> W. Blume and R. </author> <title> Eigenmann Symbolic Range Propagation. </title> <booktitle> In Proceedings of the Ninth IEEE Int. Parallel Processing Symposium, </booktitle> <pages> pp. 357-363, </pages> <month> April, </month> <year> 1995 </year>
Reference-contexts: Despite this worst-case scenario we do not expect the analysis to exhibit this exponential behavior in practice. Other research that uses related symbolic analysis techniques supports this hypothesis <ref> [4] </ref>. We have developed algorithms that use symbolic execution and symbolic expression manipulation to reason about commutativity of operations with conditional constructs.
Reference: 5. <author> E. Gurari and O. Ibarra. </author> <title> The Complexity of the Equivalence Problem for Simple Programs. </title> <journal> In Journal of the ACM, </journal> <volume> 28(3) </volume> <pages> 535-560, </pages> <month> July </month> <year> 1981. </year>
Reference-contexts: Commutativity over zero input is polynomial-time decidable for C-programs with no nesting of loops, where t denotes a "forward" label not in the scope of any do-loop (do-statements however can be labeled) <ref> [5] </ref>. 3.3 PSPACE-Hard Problems If in result #7 we allow "forward" labels to be inside the do-loops, then the problem becomes PSPACE-hard. In fact, we can show the following by coding the computation of a deterministic linear-bounded automaton. Result #8.
Reference: 6. <author> M. Garey and D. Johnson. </author> <title> Computer and Intractability. A Guide to the Theory of NP-Completeness. </title> <publisher> Freeman, </publisher> <address> San Francisco, </address> <year> 1979. </year>
Reference-contexts: Sloan Research Fellowship. tivity analysis. We identify classes of programs for which commutativity anal-ysis is undecidable, PSPACE-hard, NP-hard, polynomial, and probabilistically polynomial-time decidable (see <ref> [6] </ref> for definitions and motivations). For some cases we also show the class of programs to be complete for the corresponding complexity class. The results presented here rely on known complexity results from the area of theoretical computer science. They serve two purposes.
Reference: 7. <author> O. Ibarra and S. Moran. </author> <title> Probabilistic Algorithms for Deciding Equivalence of Straight-Line Programs. </title> <journal> In Journal of the ACM, </journal> <volume> 30(1) </volume> <pages> 217-228, </pages> <month> January </month> <year> 1983. </year>
Reference-contexts: Result #12. Let C = fx 1; x y + z; x y z; x y fl zg. Over D = finite subset of Z with at least two elements, commutativity with ZERO is NP-hard for C-programs <ref> [7] </ref>. Note that the non-commutativity problem for the above programs is clearly in NP. We also have the following result. Result #13. Let C = fx x fl c; x x=2g and input domain D = N . <p> Result #15. Let C = fx 1; x y + z; x y z; x y fl zg. Over D = Z or D = R, the commutativity problem for C-programs is decidable in probabilistic polynomial time <ref> [7] </ref>. One can show that, if in result #12, D has exactly one element, then the commutativity problem is probabilistically decidable in polynomial time [7]. 4 Practical Algorithms for Commutativity Analysis Despite the undecidable/intractable results presented in the previous section, we believe it is possible to develop algorithms that can recognize <p> Over D = Z or D = R, the commutativity problem for C-programs is decidable in probabilistic polynomial time <ref> [7] </ref>. One can show that, if in result #12, D has exactly one element, then the commutativity problem is probabilistically decidable in polynomial time [7]. 4 Practical Algorithms for Commutativity Analysis Despite the undecidable/intractable results presented in the previous section, we believe it is possible to develop algorithms that can recognize many of the commuting operations that occur in practice.
Reference: 8. <author> O. Ibarra and B. Leininger. </author> <title> On the Simplification and Equivalence Problems for Straight-Line Programs. </title> <journal> In Journal of the ACM, </journal> <volume> 30(3) </volume> <pages> 641-656, </pages> <month> July </month> <year> 1983. </year>
Reference-contexts: The proofs are similar to the ones in <ref> [8] </ref> for proving the undecidability of program equivalence. Result #1. Let C = fx 1; x x + y; x x=yg and input domain D = Z. It is undecidable to determine, given a C-program P with three input variables and nine auxiliary variables, whether it commutes with ONE.
Reference: 9. <author> O. Ibarra and B. Leininger. </author> <title> On the Zero-Inequivalence Problem for Loop Programs. </title> <journal> In Journal of Computer and System Sciences , 26(1) </journal> <pages> 47-64, </pages> <month> February </month> <year> 1983. </year>
Reference-contexts: Result #11. Let C = fx 1; x x + y; x x yg. Over D = N , commu-tativity with ZERO is NP-hard for C-programs with one input variable and two auxiliary variables <ref> [9] </ref>. Considering now commutativity of programs over a limited range of inputs, we get NP-hardness, even for a very simple class of codes. Result #12. Let C = fx 1; x y + z; x y z; x y fl zg.
Reference: 10. <author> O. Ibarra, B. Leininger, and S. Moran. </author> <title> On the Complexity of Simple Arithmetic Expressions. </title> <booktitle> In Theoretical Computer Science , 19 </booktitle> <pages> 17-28, </pages> <year> 1982. </year>
Reference-contexts: It is NP-hard to decide, given two C-programs P 1 and P 2 and a positive integer m, whether P 1 and P 2 commute for all non-negative integer values of x &lt; m <ref> [10] </ref>. In this result, the complexity is with respect to the maximum of the length of P 1 , length of P 2 , and length of the binary representation of m. <p> Let C = fx x fl c; x x=2g and input domain D = N . There is a polynomial-time algorithm to decide, given two C-programs P 1 and P 2 whether P 1 and P 2 commute <ref> [10] </ref>. 3.5 Probabilistic Polynomial-Time Problems If in result #12, D is the set of all integers or the set of all rational numbers, commutativity is probabilistically decidable in polynomial time. Result #15. Let C = fx 1; x y + z; x y z; x y fl zg.
Reference: 11. <author> O. Ibarra, B. Leininger, and L. Rosier. </author> <title> A Note on the Complexity of Program Evaluation. </title> <journal> In Mathematical Systems Theory, </journal> <volume> 17 </volume> <pages> 85-96, </pages> <year> 1984. </year>
Reference-contexts: The lower bound holds even for five-variable programs <ref> [11] </ref>. If we replace x x + y and x x y by simpler constructs, we can show the following: Result #7. Let C = fx 0; x x + 1; x x 1; x y; if x = 0 then goto t; goto t; do x endg. <p> Commutativity with ONE over zero input is PSPACE-hard for C-programs with no nesting of loops. This result also holds for C = fx 0; x x + 1; x x 1; if x = 0 then y 1; do x endg <ref> [11] </ref>. 3.4 NP-Hard Problems The proofs of the NP-hardness results in this subsection use a rather complex encoding of the satisfiability problem for Boolean expressions and the fact that this latter problem is NP-hard. Result #9.
Reference: 12. <author> O. Ibarra and B. Leininger. </author> <title> The Complexity of the Equivalence Problem for Simple Loop-Free Programs. </title> <journal> In SIAM Journal on Computing, </journal> <volume> 11(1) </volume> <pages> 15-27, </pages> <month> February </month> <year> 1982. </year>
Reference-contexts: Result #9. Let C = fx 2x; x x=2; x x + yg and input domain D = Z. The commutativity problem for C-programs with one input variable and one auxiliary variable is NP-hard. The result also holds when x x + y is replaced by x x y <ref> [12] </ref>. Commutativity, nevertheless, is decidable. <p> It can be shown that the non-commutativity problem for C + -programs is in NP <ref> [12] </ref>. Thus commutativity can be decided in exponential time. Next, we have Result #10. Let C = fx 0; x x=2; x x yg and input domain D = Z. Commutativity with ZERO for C-programs with one input variable and two auxiliary variables is NP-hard [12]. Result #11. <p> + -programs is in NP <ref> [12] </ref>. Thus commutativity can be decided in exponential time. Next, we have Result #10. Let C = fx 0; x x=2; x x yg and input domain D = Z. Commutativity with ZERO for C-programs with one input variable and two auxiliary variables is NP-hard [12]. Result #11. Let C = fx 1; x x + y; x x yg. Over D = N , commu-tativity with ZERO is NP-hard for C-programs with one input variable and two auxiliary variables [9].
Reference: 13. <author> M. Rinard and P. Diniz. </author> <title> Commutativity Analysis: A New Analysis Framework for Parallelizing Compilers. </title> <booktitle> In Proceedings of the SIGPLAN '96 Conference on Program Language Design and Implementation, </booktitle> <address> Philadelphia, PA, </address> <month> May </month> <year> 1996. </year>
Reference-contexts: In the context of parallel computing commuting operations enable concurrent execution because they can execute in any order without changing the final result [15, 14]. Parallelizing compilers that recognize commuting operations can exploit this property to automatically generate parallel code for computations that consist only of commuting operations <ref> [13] </ref>. In the area of databases, exploiting commuting operations can improve the performance of concurrency control algorithms by increasing the amount of concurrency in the transaction schedule [16]. This broad range of applications motivates the design of static analysis techniques capable of automatically detecting commuting operations | commuta-tivity analysis. <p> Other research that uses related symbolic analysis techniques supports this hypothesis [4]. We have developed algorithms that use symbolic execution and symbolic expression manipulation to reason about commutativity of operations with conditional constructs. The algorithms handle both scalar and array variables <ref> [13] </ref>. 5 Applications in Parallelizing Compilers We have identified several complete scientific applications whose computations are structured as commuting updates to dynamic pointer-based data structures. These applications include the Barnes-Hut [2] hierarchical N-body algorithm and the molecular dynamics code Water 1 . <p> The algorithm computes all pairs of interactions between the molecules. Each intermolecular interaction performs an accumulation of values in each of the intervening molecule data structures. A compiler using commutativity analysis can exploit these opportunities to automatically and effectively parallelize both of these applications <ref> [13] </ref>. 6 Conclusions In this paper we have established the complexity of commutativity analysis. We have shown that, in general, the commutativity problem is undecidable or com-putationally intractable.
Reference: 14. <author> J. Solworth and B. Reagan. </author> <title> Arbitrary order operations on trees. </title> <booktitle> In Languages and Compilers for Parallel Computing, Fourth International Workshop, </booktitle> <address> Portland, OR, </address> <month> August </month> <year> 1993. </year>
Reference-contexts: Knowledge of commuting operations is of practical significance. In the context of parallel computing commuting operations enable concurrent execution because they can execute in any order without changing the final result <ref> [15, 14] </ref>. Parallelizing compilers that recognize commuting operations can exploit this property to automatically generate parallel code for computations that consist only of commuting operations [13].
Reference: 15. <author> G. Steele. </author> <title> Making asynchronous parallelism safe for the world. </title> <booktitle> In Proceedings of the Seventeenth Annual ACM Symposium on the Principles of Programming Languages, </booktitle> <pages> pages 218-231, </pages> <address> San Francisco, CA, </address> <month> January </month> <year> 1990. </year>
Reference-contexts: Knowledge of commuting operations is of practical significance. In the context of parallel computing commuting operations enable concurrent execution because they can execute in any order without changing the final result <ref> [15, 14] </ref>. Parallelizing compilers that recognize commuting operations can exploit this property to automatically generate parallel code for computations that consist only of commuting operations [13].
Reference: 16. <author> W. Weihl. </author> <title> Commutativity-based concurrency control for abstract data types. </title> <journal> IEEE Transactions on Computers, </journal> <volume> 37(12) </volume> <pages> 1488-1505, </pages> <month> December </month> <year> 1988. </year> <title> This article was processed using the L A T E X macro package with LLNCS style </title>
Reference-contexts: In the area of databases, exploiting commuting operations can improve the performance of concurrency control algorithms by increasing the amount of concurrency in the transaction schedule <ref> [16] </ref>. This broad range of applications motivates the design of static analysis techniques capable of automatically detecting commuting operations | commuta-tivity analysis.
References-found: 16

